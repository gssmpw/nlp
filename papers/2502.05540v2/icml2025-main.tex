%%%%%%%% ICML 2025 EXAMPLE LATEX SUBMISSION FILE %%%%%%%%%%%%%%%%%

\documentclass{article}

% Recommended, but optional, packages for figures and better typesetting:
\usepackage{microtype}
\usepackage{graphicx}
\usepackage{subfigure}
\usepackage{booktabs} % for professional tables

% hyperref makes hyperlinks in the resulting PDF.
% If your build breaks (sometimes temporarily if a hyperlink spans a page)
% please comment out the following usepackage line and replace
% \usepackage{icml2025} with \usepackage[nohyperref]{icml2025} above.
\usepackage{hyperref}


% Attempt to make hyperref and algorithmic work together better:
\newcommand{\theHalgorithm}{\arabic{algorithm}}

% Use the following line for the initial blind version submitted for review:
% \usepackage{icml2025}

% If accepted, instead use the following line for the camera-ready submission:
\usepackage[accepted]{icml2025}

% For theorems and such
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{mathtools}
\usepackage{amsthm}

% customized packages
\usepackage{makecell}
\usepackage{multirow}
\usepackage{graphicx}
\usepackage{subcaption}
\usepackage{float}
\usepackage{subfloat}
\usepackage{bm}
\usepackage{xcolor}
% \definecolor{red}{rgb}{0.5529411764705883, 0.1843137254901961, 0.1450980392156863}  % RGB值为 (255, 0, 0)
\definecolor{mygreen}{rgb}{0.4392156862745098, 0.6745098039215687, 0.27450980392156865}  % RGB值为 (255, 0, 0)
\definecolor{myblue}{rgb}{0, 0.6862745098039216, 0.9411764705882353}
\input{addon}

% if you use cleveref..
\usepackage[capitalize,noabbrev]{cleveref}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% THEOREMS
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\theoremstyle{plain}
\newtheorem{theorem}{Theorem}[section]
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{corollary}[theorem]{Corollary}
\theoremstyle{definition}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{assumption}[theorem]{Assumption}
\theoremstyle{remark}
\newtheorem{remark}[theorem]{Remark}

% Todonotes is useful during development; simply uncomment the next line
%    and comment out the line below the next line to turn off comments
%\usepackage[disable,textsize=tiny]{todonotes}
\usepackage[textsize=tiny]{todonotes}


% The \icmltitle you define below is probably too long as a header.
% Therefore, a short form for the running title is supplied here:
\icmltitlerunning{Demystifying Catastrophic Forgetting in Two-Stage Incremental Object Detector}

\begin{document}

\twocolumn[
\icmltitle{Demystifying Catastrophic Forgetting in Two-Stage Incremental Object Detector
% Delving into Catastrophic Forgetting in Two-Stage Continual Object Detector
% Delving deep into the Catastrophic Forgetting of Two-Stage Continual Object Detector
}
% Regulating Classifier is all you need in Continual Object Detection
% 
% Revisiting Catastrophic forgetting in Continual Object Detection.

% It is OKAY to include author information, even for blind
% submissions: the style file will automatically remove it for you
% unless you've provided the [accepted] option to the icml2025
% package.

% List of affiliations: The first argument should be a (short)
% identifier you will use later to specify author affiliations
% Academic affiliations should list Department, University, City, Region, Country
% Industry affiliations should list Company, City, Region, Country

% You can specify symbols, otherwise they are numbered in order.
% Ideally, you should not use this facility. Affiliations will be numbered
% in order of appearance and this is the preferred way.
\icmlsetsymbol{equal}{*}

\begin{icmlauthorlist}
\icmlauthor{Qirui Wu}{nwpu}
\icmlauthor{Shizhou Zhang}{nwpu}
\icmlauthor{De Cheng}{xdu}
\icmlauthor{Yinghui Xing}{nwpu}
\icmlauthor{Di Xu}{huawei}
\icmlauthor{Peng Wang}{nwpu}
\icmlauthor{Yanning Zhang}{nwpu}
%\icmlauthor{}{sch}
%\icmlauthor{}{sch}
%\icmlauthor{}{sch}
\end{icmlauthorlist}

\icmlaffiliation{nwpu}{School of Computer Science, Northwestern Polytechnical Unviersity, Xi'an, China}
\icmlaffiliation{xdu}{School of Telecommunication and Engineering, Xidian University, Xi'an, China}
\icmlaffiliation{huawei}{Huawei Technologies Ltd}

\icmlcorrespondingauthor{Shizhou Zhang}{szzhang@nwpu.edu.cn}
\icmlcorrespondingauthor{De Cheng}{dcheng@xidian.edu.cn}
% \icmlcorrespondingauthor{Firstname2 Lastname2}{first2.last2@www.uk}

% You may provide any keywords that you
% find helpful for describing your paper; these are used to populate
% the "keywords" metadata in the PDF but will not be shown in the document
\icmlkeywords{Machine Learning, ICML}

\vskip 0.3in
]

% this must go after the closing bracket ] following \twocolumn[ ...

% This command actually creates the footnote in the first column
% listing the affiliations and the copyright notice.
% The command takes one argument, which is text to display at the start of the footnote.
% The \icmlEqualContribution command is standard text for equal contribution.
% Remove it (just {}) if you do not need this facility.

\printAffiliationsAndNotice{}  % leave blank if no need to mention equal contribution
% \printAffiliationsAndNotice{\icmlEqualContribution} % otherwise use the standard text.

\begin{abstract}
% Incremental object detection (IOD) aims to enable detectors to learn new classes without forgetting previous ones. However, catastrophic forgetting remains a major challenge. 
% While existing methods address forgetting through instance replay or knowledge distillation, they fail to identify its root cause. 
% In this paper, through an in-depth analysis of Faster R-CNN, we pinpoint the RoI Head classifier as the primary source of forgetting while the regressors exhibit minimal forgetting.  To specifically address this issue, we developed a simple yet effective framework called {NSGP-RePRE} composed with \textbf{Re}gional \textbf{P}rototype \textbf{RE}play ({RePRE}) and \textbf{N}ull \textbf{S}pace \textbf{G}radient \textbf{P}rojection ({NSGP}). {RePRE} replays each class's regional prototypes to prevent the classifier from forgetting. To prevent the pre-stored prototypes from misaligning with the RoI features in the current stage, {NSGP} strategy are introduced to the feature extractor. Further, we propose a Fine-grained Regional Prototype Replay ({RePRE++}) that samples fine-grained regional prototypes as complementary to the coarse regional prototype in {RePRE}. Extensive experiments are conducted on both Pascal VOC and MS COCO benchmarks. Our methods outperform current state-of-the-art methods under various settings.

% Incremental object detection (IOD) aims to equip models to learn new classes without forgetting previously acquired knowledge, yet catastrophic forgetting remains a critical bottleneck. 
Catastrophic forgetting is a critical chanllenge for incremental object detection (IOD).
Most existing methods treat the detector monolithically, relying on instance replay or knowledge distillation without analyzing component-specific forgetting. 
% analyzing component-specific forgetting patterns. 
Through 
% an in-depth analysis
dissection 
of Faster R-CNN, we reveal a key insight: \textit{Catastrophic forgetting is predominantly localized to the RoI Head classifier, while regressors retain robustness across incremental stages.} This finding challenges conventional assumptions, 
motivating us to develop a framework termed NSGP-RePRE.
% and bridges incremental classification and detection. 
% To tackle forgetting in classifier, we build a simple yet effective framework: NSGP-RePRE.
% Regional Prototype Replay (RePRE) mitigates catastrophic forgetting in the classifier via replay of two types of prototypes. Class-wise coarse prototypes anchors core semantic centers of RoI features, while fine-grained prototypes 
Regional Prototype Replay (RePRE) mitigates classifier forgetting via replay of two types of prototypes: coarse prototypes represent class-wise semantic centers of RoI features, while fine-grained prototypes 
% semantically augmenting coarse prototypes to 
model intra-class variations.
% stabilize the classifier by replaying class-specific coarse and fine-grained regional prototypes, where coarse prototypes preserve centeral information of a class's RoI features and fine-grained one serve as a semantic augmentation to capture the full spectrum of the feature space. 
% To mitigate 
% misalignment between prototypes and features caused by incremental updates, 
% prototype-feature misalignment from incremental updates,
% we complement RePRE with Null Space Gradient Projection (NSGP), 
% a strategy that constrains feature extractor updates orthogonal to the old inputs,
Null Space Gradient Projection (NSGP) is further introduced to eliminate prototype-feature misalignment by updating the feature extractor in directions orthogonal to subspace of old inputs via gradient projection, 
% which updates the feature extractor orthogonally to old inputs,
aligning RePRE with incremental learning dynamics.
Our simple yet effective design allows NSGP-RePRE to achieve state-of-the-art performance on the Pascal VOC and MS COCO datasets under various settings.
% Extensive experiments on Pascal VOC and MS COCO indicate state-of-the-art performance. 
Our work not only advances IOD methodology but also
provide pivotal insights for catastrophic forgetting mitigation in IOD.
% establishing a bridge between incremental classification and detection.
Code will be available soon.

% Catastrophic forgetting remains a critical challenge in incremental object detection (IOD), where neural networks struggle to retain prior knowledge when learning new categories. While existing IOD methods predominantly employ holistic approaches through instance replay or knowledge distillation, they overlook the distinct forgetting patterns across detector components. Through systematic analysis of Faster R-CNN, we reveal a pivotal finding: catastrophic forgetting is primarily localized in the RoI Head classifier, while regression components exhibit inherent robustness during incremental learning. This discovery bridges the gap between incremental classification and detection tasks, challenging conventional assumptions about uniform forgetting across networks.  
% To address this, we propose **NSGP-RePRE**, a dual-component framework with two technical innovations:  
% 1. **Regional Prototype Replay (RePRE)** decomposes prototype preservation into:  
%    - *Coarse prototypes* capturing class-wise semantic centers  
%    - *Fine-grained prototypes* modeling intra-class variations  
%    This dual replay mechanism maintains discriminative feature distributions across incremental stages.  
% 2. **Null Space Gradient Projection (NSGP)** enforces feature extractor updates to lie in the orthogonal space of historical input features, resolving prototype-feature misalignment during continual adaptation.  
% Extensive evaluations on Pascal VOC and COCO benchmarks demonstrate state-of-the-art performance. Our component-specific analysis and modular design provide new insights for catastrophic forgetting mitigation in complex vision systems. Code will be released for reproducibility.  

\end{abstract}

\section{Introduction}

% 开篇段落，说一下背景，从目标检测说起到持续目标检测的重要性。
As one of the most fundamental tasks in computer vision, significant progress has been made in the field of object detection~\cite{fasterrcnn,sota2,sota3}. 
Traditional methods mostly solve the object detection task under a static closed-world setting, where all to-be-detected object classes and annotations are fully available before training.
Nevertheless, real-world applications frequently encompass dynamic environments where new object categories appear progressively over time. 
Detectors should possess the capability to adjust to novel tasks through sequential learning, while simultaneously preserving the knowledge gained from detecting previous classes. 
%To this end, incremental object detection (IOD) has emerged as a critical task, which aims to detect novel classes without compromising the detector's performance on seen classes.

% 最近的持续目标检测的进展，但是他们都没有真正的定位到目标检测器真正的遗忘来源。
Conventional object detectors~\cite{fasterrcnn, detr, gfl} often suffer from catastrophic forgetting during incremental learning, which significantly hampers their performance in previously learned classes when new tasks are introduced. 
Unlike incremental learning in classification tasks, incremental object detection (IOD) is more challenging than classification as it requires the simultaneous classification and location of a set of objects in the image.
To obtain an incremental object detector with excellent performance, many research efforts have been devoted by introducing knowledge distillation or data replay techniques~\cite{cermelli2022modeling,yuyang2023augmented,mo2024bridge} into popular detection frameworks.


Current research in the IOD field usually treats the detector as a whole, and few works pay attention to whether catastrophic forgetting mainly comes from a certain component or whether all modules contribute roughly the same.
%Unlike incremental learning in classification tasks, incremental object detection (IOD) is more challenging than classification as it requires the simultaneous classification and location of a set of objects in the image.
Demystifying catastrophic forgetting in a sophisticated detector is necessary and helpful not only to establish a bridge between incremental learning in classification and object detection, but also to provide principled guidance for designing simpler and more effective IOD methods.
In this study, we chose the widely adopted two-stage Faster R-CNN~\cite{fasterrcnn} detector as a pioneering research object.

%Therefore, current popular detectors consist of sophisticated architectures compared with the model architecture in classification task.

%Although most studies on continual learning are based on image classification, the issue has also gained attention in dense tasks such as object detection~\cite{cermelli2022modeling, yuyang2023augmented, mo2024bridge} and semantic segmentation~\cite{clseg1, clseg2, clseg3}. 
%For instance, ABR~\cite{yuyang2023augmented} stores cropped foreground instances and replays them by pasting these instances on images from novel tasks. 
%BPF~\cite{mo2024bridge} bridges with the past through pseudo-labeling and with the future through potential object estimation. 

%Although significant advances have been made in incremental object detection, current research treats the detector as a ``black box''. Our study seeks to demystify catastrophic forgetting in this black box by thoroughly analyzing the Faster R-CNN~\cite{fasterrcnn} model.

% 本文通过ablation study，对Faster R-CNN进行了精细的研究，最终发现真正的遗忘源是分类器
Faster R-CNN is composed of a backbone, neck, region proposal network (RPN) and region of interest head (RoI Head), each of which is crucial to the detector's performance.
Our primary focus is on the RPN and RoI Head, known for their key roles in object detection. 
% These components comprise two branches: one dedicated to classification and the other to regression, both critical functions specific to the domain of object detection. 
Through a systematic analysis of its core components, we uncover several important insights. 
% 1) The RPN exhibits minimal forgetting when transitioning to new tasks. 
1) RPN's recall ability remains consistent when transitioning to new tasks.
2) RPN's forgetting has an insignificant impact on overall performance. 
% 1. In sequential tasks, the stability of the RPN recall ability is largely maintained.
% 2. RPN's minimal forgetting has a negligible impact on the overall performance.
% 3. The RoI Head classifier suffers severely from catastrophic forgetting, while the regressor can efficiently retain its knowledge.
3) Forgetting mainly occurs in the RoI Head's classifier, while the regressor component efficiently retains its knowledge.
These findings challenge conventional assumptions and inspire us to propose a novel simple yet effective IOD framework.
%provide the foundation for our framework. NSGP-RePRE.

% 本文从发现出发，把方法给引出来。
% Based on our findings, we propose a simple yet effective framework named {NSGP-RePRE},
In this paper, we propose NSGP-RePRE, which is composed of two components: {Re}gional {P}rototype {RE}play ({RePRE}) and {N}ull {S}pace {G}radient {P}rojection ({NSGP}).
% RePRE
To address catastrophic forgetting in the RoI Head classifier, RePRE alleviates forgetting by replaying stored regional prototypes, including coarse regional prototypes and fine-grained regional prototypes of each class. 
% RePRE preserves prior knowledge by maintaining and replaying both coarse regional prototypes and fine-grained regional prototypes for each class. 
Coarse prototypes act as stable semantic centers, representing the core structure of the RoI feature space. Fine-grained prototypes complement these as a semantic augmentation by capturing intra-class diversity, ensuring a more holistic modeling of the feature distribution. By jointly leveraging these components, RePRE strengthens the capacity of the RoI Head classifier to retain learned knowledge across tasks while accommodating new knowledge, significantly improving incremental learning performance.
% Coarse regional prototypes represent the fundamental semantic tokens that are the center of the RoI feature space. Fine-grained regional prototypes serve as a semantic augmentation to the coarse regional prototypes, thereby capturing the feature space of the class more comprehensively. This method enhances the RoI Head classifier's ability to maintain prior knowledge.
% While RePRE can help the classifier retain prior classification knowledge, changes in the feature extractor may cause shifts in RoI features, leading to a misalignment between the replayed prototypes and the evolving RoI feature distribution. This misalignment could detrimentally affect the detector's ability to retain crucial information. 
% NSGP
To prevent toxic replay with misaligned prototypes due to the drift of RoI features caused by updates to the feature extractor, we introduce NSGP to manipulate the gradient in the feature extractor. 
By projecting gradients into the null space of previous examples, RoI feature distortion is greatly minimized, ensuring prototype and RoI feature alignment.
Our approach achieves state-of-the-art results on the PASCAL VOC and COCO datasets under various single and multi-step settings.

Our main contributions are three-fold:
\begin{itemize}
    % \item Through a thorough analysis of each component of Faster R-CNN, we have identified the source of catastrophic forgetting in the detector as the classifier in the RoI Head. 
    % \item Our thorough anatomy of Faster R-CNN reveals that forgetting is predominantly localized to the RoI Head classifier while regressor has minor forgetting, providing principled guidance for IOD method design.
    \item We comprehensively studied the key components of Faster R-CNN and identified RoI Head classifier as the primary cause of catastrophic forgetting, providing principled guidance for IOD method design.
    % \item Our thorough anatomy of Faster R-CNN identified RoI Head classifier as the primary cause of catastrophic forgetting while regressor exhibits minimal forgetting.
    % \item We comprehensively studied the key components of Faster R-CNN and identified the primary cause of catastrophic forgetting: RoI Head classifier significantly contributes to it while regressor has minor forgetting.
    % providing principled guidance for IOD method design.
    % Our work is pioneering in locating the source of forgetting in Faster R-CNN.
    % \item Based on our findings, we propose the {NSGP-RePRE} framework to alleviate forgetting caused by misclassification of old tasks.
    % \item Motivated by our findings, NSGP-RePRE is proposed to alleviate forgetting by regional prototype replay complemented with feature anti-drifting using NSGP.
    \item Based on our finding,  we propose NSGP-RePRE to alleviate forgetting of RoI Head classifier by Regional Prototype Replay complemented with Null Space Gradient Projection for RoI feature anti-drifting. 
        % \item Our method outperforms state-of-the-art methods across multiple datasets and settings, demonstrating the effectiveness of the proposed approaches.
    \item Our method not only achieves state-of-the-art performance across multiple datasets under various single and multi-step settings, but also provides pivotal insights for mitigating forgetting in IOD. 
\end{itemize}

\section{Related Work}
% Incremental learning, also known as continual learning, emphasizes progressively acquiring new knowledge without forgetting past information. This method is classified into task-incremental, class-incremental, and domain-incremental learning issues. Among these, class-incremental learning is regarded the most applicable yet the most difficult, and is also the primary focus of this paper.

Incremental learning, or continual learning, progressively learn new knowledge while retaining previous information. It is categorized into task-incremental, class-incremental, and domain-incremental challenges. The most challenging class-incremental learning is the primary focus of this paper.

\subsection{Incremental Learning for Classification}
Most influential incremental learning studies have focused on classification tasks. 
These methods can be categorized into regularization-based, structure-based, and replay-based methods. 
Some regularization-based methods enforce the stability of logits~\cite{lwf, slca} or intermediate features~\cite{geodl} to preserve the learned knowledge, while others apply restrictions on the weight of the model~\cite{ewc} or on gradients during optimization~\cite{gem, adamnscl}. 
Structure-based methods are dedicated to learning specific parameters for different tasks, with a dynamically expanding architecture~\cite{rusu2016progressive} or grouped parameters in a static model~\cite{pathnet}. 
For replay-based methods, they can be divided into experience replay~\cite{der, pass,yono} and generative replay methods~\cite{lifelonggan,kemker2017fearnet}, depending on the examples stored in a buffer or generated with a model. 
Recently, incremental learning based on foundation models such as CLIP~\cite{clip} has also attracted attention. 
Research works such as L2P~\cite{l2p}, O-LoRA~\cite{olora}, and VPT-NSP\textsuperscript{2}~\cite{lu2024visual} attempt to learn continuously based on the parameter-efficient transfer learning technique~\cite{coop, vpt, dpt} have achieved superior performance.

\begin{figure*}[t]
    \centering
    \begin{minipage}[t]{0.27\linewidth}
        \centering
        \includegraphics[width=\linewidth]{figs/RPNRecall/rpn_iou_recall_1.pdf}
        \vspace{-0.8cm} % 减小间距
        \caption*{(a) RPN's recall on $\mathcal{D}_1^{test}$.}
        \vspace{-0.8cm} % 减小间距
        \label{fig:sub1}
    \end{minipage}
    \hspace{-0.7cm}
    \begin{minipage}[t]{0.27\linewidth}
        \centering
        \includegraphics[width=\linewidth]{figs/RPNRecall/rpn_iou_recall_2.pdf}
        \vspace{-0.8cm} % 减小间距
        \caption*{(b) RPN's recall on $\mathcal{D}_2^{test}$.}
        \vspace{-0.8cm} % 减小间距
        \label{fig:sub2}
    \end{minipage}
    \hspace{-0.7cm}
    \begin{minipage}[t]{0.27\linewidth}
        \centering
        \includegraphics[width=\linewidth]{figs/RPNRecall/rpn_iou_recall_3.pdf}
        \vspace{-0.8cm} % 减小间距
        \caption*{(c) RPN's recall on $\mathcal{D}_3^{test}$.}
        \vspace{-0.8cm} % 减小间距
        \label{fig:sub3}
    \end{minipage}
    \hspace{-0.7cm}
    \begin{minipage}[t]{0.27\linewidth}
        \centering
        \includegraphics[width=\linewidth]{figs/RPNRecall/rpn_iou_recall_4.pdf}
        \vspace{-0.8cm} % 减小间距
        \caption*{(d) RPN's recall on $\mathcal{D}_4^{test}$.}
        \vspace{-0.8cm} % 减小间距
        \label{fig:sub4}
    \end{minipage}
    \caption{Recall-Objectness curve of RPN's prediction. IoU threshold is set to 0.5. 
    {\color{blue}Blue}: ${\cal M}_j$ has been trained with training images of $\mathcal{D}_i$ in earlier stages. 
    {\color{green}Green}: ${\cal M}_j$ is just fine-tuned on $\mathcal{D}_i$.
    {\color{red}Red}: ${\cal M}_j$ has not seen the training set of $\mathcal{D}_i$ before. 
    {\color{gray}Gray}: ${\cal M}_{joint}$ is trained jointly on all training images of $\cal D$. 
    %For example, in (a), {\color{green}${\cal M}_1$} is freshly fine-tuned on $\mathcal{D}_1$, while {\color{blue}${\cal M}_2$} to {\color{blue}${\cal M}_4$} have seen $\mathcal{D}_1$ in previous training stage. In (d), {\color{red}${\cal M}_1$} to {\color{red}${\cal M}_3$} have not seen $\mathcal{D}_4$ before.
    }
    \label{fig:rpnrecall}
\end{figure*}

\subsection{Incremental Learning for Object Detection}
Incremental object detection presents unique challenges compared with the classification task. 
IOD are required to locate and classify the visual objects in images. 
It also faces a distinctive missing annotation problem where potential instances not belonging to the classes of the current learning stage are labeled as background. 
Most existing IOD works can be summarized into two categories. 
One is knowledge distillation based methods~\cite{mo2024bridge, cermelli2022modeling}. BPF~\cite{mo2024bridge} bridges past and future with pseudo-labeling and potential object estimation to align models across stages, ensuring a consistent optimization direction. 
MMA~\cite{cermelli2022modeling} consolidates the background and all old classes into one entity to minimize the conflict between optimization objects between previous and current tasks. 
The other is to preserve knowledge through a replay of previous data stored in images~\cite{cldetr}, instances~\cite{yuyang2023augmented}, or features~\cite{acharya2020rodeo}. 
ABR~\cite{yuyang2023augmented} replayed foreground objects from previous tasks stored in a buffer to reinforce the learned knowledge.  RODEO~\cite{acharya2020rodeo} stored compressed representations in a fixed-capacity memory buffer to incrementally perform object detection in a streaming fashion.
Unlike existing methods, we delve into analyzing where the forgetting originated for the two-stage incremental object detector.
Then we tailor a method specifically designed to combat the crux forgetting module, \textit{i.e.} RoI Head classifier, by replaying RoI features from previously seen tasks to preserve the classification performance.





\section{Anatomy of Faster R-CNN}

\subsection{Preliminary}
\textbf{Problem Formulation of Incremental Object Detection.}
In Incremental Object Detection, training is structured across n sequential learning stages, with each stage incorporating a new set of classes to be detected. 
Let \(\mathcal{C} = \{\mathcal{C}_1, \mathcal{C}_2, \ldots, \mathcal{C}_t, \ldots, \mathcal{C}_n \}\) represent the entire class set that the detector \(\mathcal{M}\) incrementally acquires, with \(\mathcal{C}_i \cap \mathcal{C}_j = \emptyset\) for all \(i \neq j\). 
The dataset \(\mathcal{D}_t = \{\mathcal{X}_{t}, \mathcal{Y}_t \}\) comprises images and annotations for the \(t\)-th learning stage. 
%At the \(t\)-th stage of training, a subset \(\mathcal{C}_t\) is introduced to the detector \(\mathcal{M}_{t-1}\) to yield the updated model \(\mathcal{M}_t\), . 
Each image in \(\mathcal{X}_{t} \) could feature multiple objects of various classes from \(\mathcal{C}\), though only those in \(\mathcal{C}_t\) are annotated. 
The main challenge in IOD is to update the detector from \(\mathcal{M}_{t-1}\) to \(\mathcal{M}_t\) using \(\mathcal{D}_t\) solely, without access to earlier datasets \(\{\mathcal{D}_1, \dots, \mathcal{D}_{t-1}\}\), while preserving or enhancing the detector's performance on previously learned classes \(\{\mathcal{C}_1, \dots, \mathcal{C}_{t-1}\}\).





% 点出来Faster R-CNN好处，为什么要在这个架构下去做。
\textbf{Faster R-CNN Architecture.}
Our study utilizes the two-stage object detector Faster R-CNN, which involves four primary components: a backbone network \( f_b \), a neck \( f_n \), a Region Proposal Network (RPN) \( f_{\text{RPN}} \), and a Region of Interest (RoI) Head \( f_{\text{RoI}} \). 
The backbone and neck modules are responsible for feature extraction, and their combination is represented as $f_{nb}=f_n\circ f_b$. 
The RPN generates object proposal boxes accompanied by objectness scores, which express the likelihood of each box containing a target object. 
Following this, proposals with higher objectness scores \( \vP \) are chosen for RoI feature extraction using RoI Align. 
The RoI Head is divided into two branches: the classification branch $f_{cls}$ and the regression branch $f_{bbox}$. 
The obtained RoI features \( \vP \)  are fed into these branches to classify and adjust the positions of the bounding boxes.

% \subsection{Hypothesis and Verifications}
\subsection{Rationale for Anatomy}
% 小问题要回答什么大问题？
% In Faster R-CNN, the RPN and RoI Head are responsible for object localization and classification. 
% RPN functions as an initial object localizer, and its recall rate plays a critical role in the overall performance of the detector, even though it does not generate the final prediction. 
% The RoI Head is tasked with making the detector's ultimate prediction, covering both classification and localization. 
% Its robustness is vital for determining the detector's performance, particularly when faced with an underperforming RPN. 

When adapting Faster R-CNN to sequential learning tasks, catastrophic forgetting is the primary limitation. The central question driving this work is: \textit{Which component predominantly leads to catastrophic forgetting, or do all components have a contributing role?}
To systematically address this, we decompose the ultimate question into three interconnected sub-questions:
1. Can RPN retain its recall ability in incremental learning?
RPN functions as an initial object localizer and its recall rate plays a critical role in the overall performance of the detector. 
2. How much does RPN's forgetting affect the final performance of the detector?
RPN doesn't produce final predictions on classification nor localization, it is crucial to investigate the actual impact caused by its degradation.
3. Which branch of the RoI Head predominantly accounts for forgetting?
The RoI Head is responsible for the ultimate prediction of the detector, its dual role in classification and modifying the bounding box potentially makes it sensitive to task-specific changes. 
To answer these questions, we conduct a series of analytical experiments in the following section from a statistical perspective, as the detector learns sequentially.

Our analytical experiments are conducted on the PASCAL VOC dataset, starting with five classes and incrementally adding five classes across three additional stages. 
We employ pseudo-labeling as a basic strategy to mitigate the missing annotation issue and top 1,000 proposals are selected to provide a sufficient number for our investigation.
% 展开要investgate的问题。
In the following sections, we evaluate the RPN and RoI Head within the detectors learned on all stages and a jointly trained detector, \ie ${\cal M}_1$ to ${\cal M}_4$ and ${\cal M}_{joint}$, on the test set of each learning stage, \ie $\mathcal{D}_1^{test}$ to $\mathcal{D}_4^{test}$.

To clarify, we use various colors to depict the performance of Model ${\cal M}_t$ on test set of $\mathcal{D}_i^{test}$ across different training stages. 
{\color{green}Green} indicates ${\cal M}_t$ when it is just fine-tuned in its corresponding stage with the training set of $\mathcal{D}_i$ ($t=i$), displaying peak performance on test set of $\mathcal{D}_i^{test}$. 
{\color{blue}Blue} represents ${\cal M}_t$ that has encountered training set of $\mathcal{D}_i$ in earlier stages ($t>i$), demonstrating the phenomenon of forgetting after multiple training stages. 
{\color{red}Red} illustrates ${\cal M}_t$ that has not been fed with training images of $\mathcal{D}_i$ before ($t<i$), highlighting the model's generalization capability.

\subsection{Anatomy of Faster R-CNN}

% 斜体点出来问句的答案。
\indent \textbf{RPN's recall ability remains consistent across sequential tasks.} 
RPN allows the detector to generate possible RoIs and deterioration in proposal quality will hamper the detector's final performance. 
It is essential to examine the RPN's recall rate from a statistical view, as it can reflect the knowledge-preserving ability of RPN.
We perform experiments on the RPNs within the detectors learned on all the four stages and the jointly learned detector, \ie ${\cal M}_1$ to ${\cal M}_4$ and ${\cal M}_{joint}$, by using Recall-Objectness curves on all the four test sets of each training stage $\mathcal{D}_1^{test}$ to $\mathcal{D}_4^{test}$. Note that the threshold of IoU between the proposals and GTs is set to 0.5.
%Figure~\ref{fig:rpnrecall} illustrates the curve of Objectness-Recall on $\mathcal{D}_i$ of 4 training stages. 
As shown in Figure~\ref{fig:rpnrecall} (a), the blue curves represent the recall ability of RPNs within ${\cal M}_2$ to ${\cal M}_4$ which have been previously tuned on training set of $\mathcal{D}_1$. 
The green curve shows the recall of ${\cal M}_1$, which has just been fine-tuned on $\mathcal{D}_1$. 
It can be clearly seen that the blue curves show a slight reduction compared to the green curve. 
As the objectness score approaches 0, the recall rates of various models improve to similar outcomes close to 100\%. (Note that only top 1,000 proposals are selected in our experiments.) 
The slight reduction between the blue and green curves highlights that the RPN experiences little forgetting after multiple sequential learning stages. 
This trend is also observed in Figure~\ref{fig:rpnrecall} (b) and (c).

\begin{figure}[t]
    \centering
    \begin{minipage}[t]{0.245\linewidth}
        \centering
        \includegraphics[width=\linewidth]{figs/RoIRecall/RoIRecall1.pdf}
        \vspace{-0.8cm} % 减小间距
        \caption*{(a) On $\mathcal{D}_1^{test}$}
        \vspace{-0.8cm} % 减小间距
        \label{fig:sub1}
    \end{minipage}
    \hspace{-0.2cm}
    \begin{minipage}[t]{0.245\linewidth}
        \centering
        \includegraphics[width=\linewidth]{figs/RoIRecall/RoIRecall2.pdf}
        \vspace{-0.8cm} % 减小间距
        \caption*{(b) On $\mathcal{D}_2^{test}$}
        \vspace{-0.8cm} % 减小间距
        \label{fig:sub2}
    \end{minipage}
    \hspace{-0.2cm}
    \begin{minipage}[t]{0.245\linewidth}
        \centering
        \includegraphics[width=\linewidth]{figs/RoIRecall/RoIRecall3.pdf}
        \vspace{-0.8cm} % 减小间距
        \caption*{(c) On $\mathcal{D}_3^{test}$}
        \vspace{-0.8cm} % 减小间距
        \label{fig:sub3}
    \end{minipage}
    \hspace{-0.2cm}
    \begin{minipage}[t]{0.245\linewidth}
        \centering
        \includegraphics[width=\linewidth]{figs/RoIRecall/RoIRecall4.pdf}
        \vspace{-0.8cm} % 减小间距
        \caption*{(d) On $\mathcal{D}_4^{test}$}
        \vspace{-0.8cm} % 减小间距
        \label{fig:sub4}
    \end{minipage}
    \caption{Results of ${\cal M}_i$ on $\mathcal{D}_i$ with different proposals. $\vP_j$ are produced by corresponding ${\cal M}_j$. 
    % {\color{red}Red}: ${\cal M}_j$ has not seen $\mathcal{D}_i$ before. {\color{green}Green}: ${\cal M}_j$ is just fine-tuned on $\mathcal{D}_i$. {\color{blue}Blue}: ${\cal M}_j$ has seen $\mathcal{D}_i$. For example, in (a), ${\cal M}_1$'s RoI Head takes $\vP_1$ to $\vP_4$ that is generated by ${\cal M}_1$ to ${\cal M}_4$ as proposal, and {\color{green}${\cal M}_1$} is just fine-tuned on $\mathcal{D}_1$, while {\color{blue}${\cal M}_2$} to {\color{blue}${\cal M}_4$} have seen $\mathcal{D}_1$ in previous training stage. In (d), {\color{red}${\cal M}_1$} to {\color{red}${\cal M}_3$} have not seen $\mathcal{D}_4$ before.
    }
    \label{fig:switch-proposals}
\end{figure}


\begin{figure}[t]
    \centering
    \begin{minipage}[t]{0.32\linewidth}
        \centering
        \includegraphics[width=\linewidth]{figs/RoIRecallFixedProposals/RoIRecallFixedProposals1.pdf}
        \vspace{-0.8cm} % 减小间距
        \caption*{(a) On $\mathcal{D}_1^{test}$}
        \vspace{-0.8cm} % 减小间距
        \label{fig:sub1}
    \end{minipage}
    \hspace{-0.1cm}
    \begin{minipage}[t]{0.32\linewidth}
        \centering
        \includegraphics[width=\linewidth]{figs/RoIRecallFixedProposals/RoIRecallFixedProposals2.pdf}
        \vspace{-0.8cm} % 减小间距
        \caption*{(b) On $\mathcal{D}_2^{test}$}
        \vspace{-0.8cm} % 减小间距
        \label{fig:sub2}
    \end{minipage}
    \hspace{-0.1cm}
    \begin{minipage}[t]{0.32\linewidth}
        \centering
        \includegraphics[width=\linewidth]{figs/RoIRecallFixedProposals/RoIRecallFixedProposals3.pdf}
        \vspace{-0.8cm} % 减小间距
        \caption*{(c) On $\mathcal{D}_3^{test}$}
        \vspace{-0.8cm} % 减小间距
        \label{fig:sub3}
    \end{minipage}
    \caption{Results of ${\cal M}_i$ on various $\mathcal{D}_i$ by using a fixed set of proposals. ``- -'' indicates the classification results of each proposal is designated by {\color{green}Model freshly trained on the corresponding $\mathcal{D}$}. ``---'' indicates the predicted classification results for the corresponding model in the x-axis.} 
    \label{fig:fixed-proposals}
\end{figure}

\indent \textbf{RPN's minimal forgetting negligibly affects overall performance.} 
To assess the actual impact of RPN's forgetting on the detector's final performance, we adopt proposals generated from models of subsequent training stages (${\cal M}_{i+1}$ to ${\cal M}_n$) to the current model on the current stage ${\cal M}_i$, to test the final performance of ${\cal M}_i$. 
\( \vP_i \) denotes the proposals generated by ${\cal M}_i$.
As depicted in Figure~\ref{fig:switch-proposals} (a), ${\cal M}_1$ is evaluated on test set of $\mathcal{D}_1^{test}$ with varying sets of proposals. $\vP_1$ demonstrates the optimal performance of ${\cal M}_1$ since $\vP_1$ is generated with the RPN of  ${\cal M}_1$, \ie zero forgetting. 
Although $\vP_2$ to $\vP_4$ exhibit some forgetting compared to $\vP_1$, the performance deterioration of ${\cal M}_1$ with $\vP_2$ to $\vP_4$ is minimal, with only a 1.3\% reduction in mAP observed on $\mathcal{D}_1$, from $\vP_1$ (77.4\%) to $\vP_4$ (76.1\%). 
This minor decrease suggests that RPN's forgetting has minor impact on the detector's final performance. 
Consistent conclusion can be obtained from Figure~\ref{fig:switch-proposals} (b) and (c).



\indent \textbf{The RoI Head classifier exhibits severe catastrophic forgetting.} 
As discussed previously, RPN contributes minimally to the detector's forgetting. 
To investigate the crux of forgetting, we fixed the proposals \( \vP_i \) generated with ${\cal M}_i$ and fed them into RoI Heads of detectors in subsequent stages ${\cal M}_{i+1}$ to ${\cal M}_n$.
By designating the classification results of each proposal with ${\cal M}_i$'s results, we can isolate the forgetting caused by the regression branch and the classification branch. As shown in Figure~\ref{fig:fixed-proposals} (a), the dashed line represents the mAP of models designated with the ${\cal M}_1$'s classification results, while the solid line represents the classification results produced by the corresponding models on the x-axis. 
In Figure~\ref{fig:fixed-proposals} (a), the dashed line remains almost unchanged, suggesting the forgetting caused by the regressor is minor. 
The solid line deteriorates rapidly as more stages have been trained on the detector, indicating that the classification head primarily causes the forgetting. 
The same trend in Figure~\ref{fig:fixed-proposals} (b) and (c) further confirms the conclusion.

Interestingly, our findings also reveal that RPN effectively generalizes to previously unseen classes as can be seen from the red curves shown in Figure~\ref{fig:switch-proposals} and Figure~\ref{fig:fixed-proposals}. More detailed analysis are presented in the appendix. We note that the reason for minimal forgetting in regression and large forgetting in classifier is unclear. We infer that it may be due to the absence of task conflicts in the detector regression branches, while it is severe in the classification task~\cite{clsinterference1, clsinterference2} for incremental learning. 

% Our findings indicate that RPN successfully generalizes to unseen classes, as illustrated in Figures~\ref{fig:fixed-proposals} and \ref{fig:switch-proposals}. Further analysis is presented in the appendix. The cause of minimal forgetting in regression and significant forgetting in the classifier remains uncertain. We suggest this may result from the lack of task conflicts in detector regression branches, in contrast to the classification task~\cite{clsinterference1, clsinterference2} during incremental learning.

\begin{figure*}[t]
    \centering
    \includegraphics[width=1.0\linewidth]{figs/Framework_Small.pdf}
    \caption{The overall architecture of our {NSGP-RePRE} framework. This framework incorporates {RePRE} to mitigate forgetting within the RoI Head's classifier. {NSGP} is introduced to counteract the shifts induced by the evolving feature extractor. 
    % Additionally, 
    % {RePRE++} is proposed to cover the RoI feature space more comprehensively.
    }
    \label{fig:framework}
\end{figure*}


% 在这个位置需要把结论给列出来
% Above all, the classifier in the RoI Head is the main component responsible for the forgetting in incremental Faster R-CNN, while RPN and RoI Head regressor can retain previously learned knowledge effectively.
\subsection{Key Findings}

Through statistical evaluation and systematic analysis, we demonstrate three key findings:
\begin{itemize}
    \item RPN Recall Stability: In sequential tasks, the stability of the RPN recall ability is largely maintained.
    \item RPN's Impact on Performance: RPN's minimal forgetting has a negligible impact on overall performance. 
    % This suggests that catastrophic forgetting is not inherently propagated from the proposal stage.
    \item RoI Head Classifier Vulnerability: The RoI Head classifier suffers severely from catastrophic forgetting, while the regressor can efficiently retain its knowledge.
\end{itemize}
Our analysis reveals that \textit{Catastrophic forgetting in Faster R-CNN stems predominantly from the instability of the RoI Head’s classifier, rather than degradation in  RPN’s recall capability or the regression branch of RoI Head}. Our analyses demonstrate minimal forgetting in regression, building a bridge between classical incremental classification and two-stage incremental object detector. 
This offers fundamental insights for developing simpler and more efficient IOD methods. Consequently, we present a straightforward and effective approach to address forgetting in the RoI Head classifier, thereby reducing forgetting in the detector.
% We infer that it may be due to the absence of task conflicts in the detector regression branches, while it is severe in the classification task~\cite{clsinterference1, clsinterference2} for successive learning stages. 
% The regression head exhibits minimal forgetting due to shifts in RoI features.
% 明确写出来启示，然后引出来我们的方法。   

% \begin{figure*}
%     \centering
%     \includegraphics[width=1.0\linewidth]{}
%     \caption{The overall framework.}
%     \label{fig:enter-label}
% \end{figure*}






\section{Method}

\indent \textbf{Overview of Framework.} 
Earlier discussions have pinpointed that the crux of catastrophic forgetting in Faster R-CNN mainly stems from the classification branch of the RoI Head, establishing a bridge between incremental classification and incremental object detection.
% The purpose of this work is to propose a simple yet effective IOD framework according to our previous analytical results.
% Previous works treat the classification and regression equally, through image/box replay or pseudo-labeling to regulate both classification and regression. 
Based on our previous analytical results, we propose a simple yet effective Regional Prototype Replay (RePRE) incorporated with {N}ull {S}pace {G}radient {P}rojection ({NSGP}) framework termed NSGP-RePRE specifically targeting the forgetting in RoI Head classifier. 
% To mitigate catastrophic forgetting within the RoI Head classifier, it is straightforward to utilize a RoI feature replay mechanism to combat forgetting of the RoI Head classifier. 
% However, the updates in the feature extractor could distort the RoI feature space, leading to misalignment.

As depicted in Figure~\ref{fig:framework}, NSGP-RePRE employs NSGP for regulating the backbone and neck, while RePRE manages the RoI Head. RePRE creates coarse regional prototypes from RoI features of each class, along with fine-grained regional prototypes to enhance semantic diversity. These prototypes are replayed via the RoI Head's classification branch. Unlike previous works~\cite{yuyang2023augmented, mo2024bridge}, RePRE provides consistent guidance with minimal prototype storage per class to prevent forgetting specifically on RoI Head classifier. Addressing the issue of prototype-feature misalignment identified in prior research~\cite{sdc, driftcomp}, {NSGP} is introduced to restrict changes in RoI features, ensuring prototype's alignment with the evolving RoI feature distributions.
%Furthermore, we propose a Fine-grained Regional Prototype Replay strategy. This approach incorporates supplementary fine-grained prototypes derived from fine-grained feature space of the RoI features specific to each class, augmenting the coarse regional prototypes utilized in RePRE. This improvement enables prototypes to more fully span the feature space of the RoI features, thereby improving the final performance


\subsection{RePRE} 

{RePRE} retains the previously learned classification knowledge by replaying regional prototypes from the past. 
Specifically, to obtain coarse regional prototypes for the {RePRE} in the next training stage $t+1$, we extract RoI features $\mathcal{O}_t=\{\vo_{i}^c \mid i\in \mathbb{N}, c\in \mathbb{N}, 1\leq i \leq n_c, \Bar{N}_{t-1}\leq c \leq \Bar{N}_t\}$ from the feature maps as 
\begin{equation}
    \vo_{i}^c = \operatorname{RoIAlign}(\vP_{i}^c, f_{nb}(\vx_{i}^c)),    
\end{equation}
where $\vP_{i}^c$ are the proposals covering class $c$, $\vx_{i}^c$ is the image containing objects of $c$ and $n_c$ is the number of proposals that cover object from class $c$, $\Bar{N}_{t}$ represents the total class number of $\mathcal{C}_{old} = \{\mathcal{C}_1, \cdots, \mathcal{C}_{t}\}$. 
The generation of $\vP_i^c$ can be expressed as
\begin{equation}
    \vP_i^c = f_{rpn}(f_{nb}(\vx_{i}^c)).
\end{equation}
Next, we compute and store a single prototype for each class given by
\begin{equation}
    \vmu_{c} = \frac{1}{n_{c}}\sum^{n_{c}}_{i=1}\vo_{i}^c.
\end{equation}
The resulting $\vmu_{c}$ will be appended to 
$\mathcal{R}_{t-1}=\{\vmu_k \mid k\in \mathbb{N}, 1\leq k \leq \Bar{N}_{t-1}\}$
to form $\mathcal{R}_{t}$, which stores prototypes from past stages.

To capture the entire spectrum of useful information on the distribution of RoI features. We introduce complementary fine-grained regional prototypes chosen through a density-aware prototype selection strategy.
Specifically, we first calculate the cosine similarity between RoI features extracted via RoI Align:
\begin{equation}
    s_{i,j}^c = \frac{\vo_i^c\vo_j^c}{||\vo_i^c||||\vo_j^c||}, 1\leq i,j \leq n_c
\end{equation}
For each RoI feature , we define a hypersphere with radius 
$r$, centered at $\vo_j^c$ , that contains neighboring features 
$\mathcal{S}_j^c = \{\vo_i^c \mid s_{i,j}^c > r, 1\leq i \leq n_c\}$.
The importance of a hypersphere is quantified by its cardinality (i.e. the number of RoI features it contains).
% We then select the top-$K$ most important hyperspheres $\{\mathcal{S}_j^c \mid 1 \leq j \leq K\}$. 
% To ensure diversity and avoid redundancy, we iteratively select hyperspheres such that no two centers lie within hyperspheres of higher importance. 
To ensure diversity and avoid redundancy, we greedily select the top-$K$ hyperspheres $\{\mathcal{S}_j^c \mid 1 \leq j \leq K\}$ in descending order of importance. 
During selection, any candidate hypersphere whose center lies within the radius $r$ of a previously selected (more important) hypersphere is excluded.
The fine-grained regional prototypes are computed by averaging all features in their corresponding hypersphere:
\begin{equation}
\vmu_{c,j}^\prime = \frac{1}{|\mathcal{S}_j^c|} \sum_{\vo \in \mathcal{S}_j^c}{\vo},
\end{equation}
and these prototypes are added to the fine-grained prototype buffer $\mathcal{R}^\prime_{t-1}=\{\vmu_{k,j}^\prime \mid k,j\in \mathbb{N}, 1\leq k \leq \Bar{N}_{t-1}, 1\leq j\leq K\}$.

To replay these prototypes, at stage $t+1$, a regional prototype $\vmu_k$ is fed into the classification branch of the RoI Head to predict the class probabilities as
\begin{equation}
    \hat{\vy}_{k} = \operatorname{Softmax}(f_{cls}(\vmu_k)).
\end{equation}
The replay loss $\calL_{re}$ is computed as 
\begin{equation}
    \calL_{re} = - \sum_{\vy_k \in C_{old}} \vy_k \log \hat{\vy}_k - \sum_{\vy_k \in C_{old}}\sum_{i=1}^K \vy_k \log \hat{\vy}_{k,i}^\prime,
\end{equation}
where $\vy_k$ represents the ground-truth label associated with the coarse prototype $\vmu_k$ and fine-grained prototype $\vmu_{k,i}^\prime$. The overall loss function for the detector is then formulated as:
\begin{equation}
    \calL=\calL_{cls}+\calL_{bbox}+\calL_{re},
\end{equation}
where $\calL_{cls}$ and $\calL_{bbox}$ correspond to the classification and bounding box regression losses for the current stage $t$.

\subsection{NSGP for RoI Features Anti-drifting}

When using regional prototype replays that stabilize the RoI Head, the continuously updating feature extractor may cause the features of previous classes to drift. 
The drift results in a misalignment between the stored prototypes and the RoI features in the current training stage, which will hamper the model to retain its knowledge. 
To reduce distortions in the RoI feature space during learning new tasks, we introduce a Null-Space Gradient Projection (NSGP) strategy to prevent updating of the backbone and neck from interfering with the features of previously seen tasks. 
{RePRE} and {NSGP} work together to form an exquisite incremental object detector, with {RePRE} managing the RoI Head and {NSGP} governing the backbone and neck.

Denote the parameters of the Convolution/FC layer in the backbone and neck as $\vW$, and the gradient $\vG$ is calculated by the backward pass. 
To ensure that updating based on $\vG$ will not change previous tasks, NSGP projects $\vG$ into the null space of the previous samples~\cite{adamnscl}, to obtain $\Delta \vW$. 
This projection ensures that $\Delta \vW$ remains orthogonal to the inputs of the old tasks $\cal X$. 
Consequently, the update can be formulated as 
\begin{equation}
    \vW_{t+1} = \vW_t - \alpha\Delta \vW_t,
\end{equation}
in the time step $t$, where $\alpha$ is learning rate.
The orthogonality condition between $\cal X$ and $\Delta \vW_t$ ensures 
\begin{equation}
    {\cal X} (\vW_t - \alpha\Delta \vW_t) = {\cal X}\vW_t
\end{equation}
is satisfied, effectively preventing drifts in the feature extractor's updates.
We adjusted the projection matrix in NSGP to enhance its compatibility with Faster R-CNN.
Additional details can be found in the Appendix.

In general, the NSGP will control the $\vG$ of the backbone and neck, ensuring that they are projected into the null space corresponding to input from previous examples. This approach stabilizes the RoI features, thus improving not only the classification accuracy but also the minimal forgetting in regression. 


% \subsection{RePRE++} 
\begin{table*}[!ht]
    \centering
    \footnotesize
    \caption{mAP@0.5 results on single incremental step on PASCAL VOC 2007. The best performance in each is presented with \textbf{bold}, and the second best is presented with \underline{underline}. }
    \resizebox{\linewidth}{!}{
        \begin{tabular}{l||cccc|cccc|cccc|cccc}
        \toprule
            ~ & \multicolumn{4}{c|}{\textbf{19-1}} & \multicolumn{4}{c|}{\textbf{15-5}} & \multicolumn{4}{c|}{\textbf{10-10}} & \multicolumn{4}{c}{\textbf{5-15}} \\ 
            \textbf{Method} & \textbf{1-19} & \textbf{20} & \textbf{1-20} & \textbf{Avg} & \textbf{1-15} & \textbf{16-20} & \textbf{1-20} & \textbf{Avg} & \textbf{1-10} & \textbf{11-20} & \textbf{1-20} & \textbf{Avg} & \textbf{1-5} & \textbf{5-15} & \textbf{1-20} & \textbf{Avg} \\ 
            \midrule
            \midrule
            Joint & 76.4  & 76.4  & 76.4  & 76.4  & 78.3  & 70.7  & 76.4  & 74.5  & 76.9  & 76.0  & 76.4  & 76.4  & 73.6  & 77.4  & 76.4  & 75.5  \\ 
            Fine-tuning & 12.0  & 62.8  & 14.5  & 37.4  & 14.2  & 59.2  & 25.4  & 36.7  & 9.5  & 62.5  & 36.0  & 36.0  & 6.9  & 63.1  & 49.1  & 35.0  \\ 
            \midrule
            ORE~\cite{ore} & 69.4  & 60.1  & 68.9  & 64.7  & 71.8  & 58.7  & 68.5  & 65.2  & 60.4  & 68.8  & 64.6  & 64.6  & - & - & - & - \\ 
            OW-DETR~\cite{owdetr} & 70.2  & 62.0  & 69.8  & 66.1  & 72.2  & 59.8  & 69.1  & 66.0  & 63.5  & 67.9  & 65.7  & 65.7  & - & - & - & - \\ 
            ILOD-Meta~\cite{ilodmeta} & 70.9  & 57.6  & 70.2  & 64.2  & 71.7  & 55.9  & 67.8  & 63.8  & 68.4  & 64.3  & 66.3  & 66.3  & - & - & - & - \\ 
            ABR~\cite{yuyang2023augmented} & 71.0  & \textbf{69.7}  & 70.9  & \underline{70.4}  & 73.0  & \textbf{65.1}  & 71.0  & 69.1  & 71.2  & \underline{72.8}  & 72.0  & 72.0  & 64.7  & 71.0  & 69.4  & 67.9  \\ 
            \midrule
            FasterILOD~\cite{fasterrcnn} & 68.9  & 61.1  & 68.5  & 65.0  & 71.6  & 56.9  & 67.9  & 64.3  & 69.8  & 54.5  & 62.1  & 62.1  & 62.0  & 37.1  & 43.3  & 49.6  \\ 
            PPAS~\cite{ppas} & 70.5  & 53.0  & 69.2  & 61.8  & - & - & - & - & 63.5  & 60.0  & 61.8  & 61.8  & - & - & - & - \\ 
            MVC~\cite{mvc} & 70.2  & 60.6  & 69.7  & 65.4  & 69.4  & 57.9  & 66.5  & 63.7  & 66.2  & 66.0  & 66.1  & 66.1 & - & - & - & - \\ 
            PROB~\cite{prob} & 73.9  & 48.5  & 72.6  & 61.5  & 73.5  & 60.8  & 70.1  & 67.0  & 66.0  & 67.2  & 66.5  & 66.5 & - & - & - & - \\ 
            PseudoRM~\cite{pseudorm} & 72.9  & 67.3  & 72.6  & 70.1  & 73.4  & 60.9  & 70.3  & 66.9  & 69.1  & 68.6  & 68.9  & 68.9 & - & - & - & - \\ 
            MMA~\cite{cermelli2022modeling} & 71.1  & 63.4  & 70.7  & 67.2  & 73.0  & 60.5  & 69.9  & 66.7  & 69.3  & 63.9  & 66.6  & 66.6  & \underline{66.8}  & 57.2  & 59.6  & 62.0  \\ 
            BPF~\cite{mo2024bridge} & \underline{74.5}  & 65.3  & \underline{74.1}  & 69.9  & \underline{75.9} & \underline{63.0}  & \underline{72.7}  & \underline{69.5}  & \underline{71.7}  & \textbf{74.0}  & \underline{72.9}  & \underline{72.9}  & 66.4  & \textbf{75.3}  & \underline{73.0}  & \underline{70.9}  \\ 
            \midrule
            % {NSGP-RePRE} & \underline{76.2}  & 66.5  & \underline{75.8}  & \underline{71.4}  & \underline{77.1}  & 62.0  & \underline{73.4}  & \underline{69.6}  & \underline{73.7}  & \underline{73.2}  & \underline{73.4}  & \underline{73.5}  & \underline{68.4}  & \underline{74.5}  & \textbf{73.0}  & \textbf{71.5}  \\ 
            {NSGP-RePRE} & \textbf{76.3}  & \underline{69.0}  & \textbf{76.0}  & \textbf{72.7}  & \textbf{77.5}  & 61.8  & \textbf{73.6}  & \textbf{69.7}  & \textbf{75.3}  & 72.7  & \textbf{74.0} & \textbf{74.0}  & \textbf{68.5}  & \underline{74.5}  & \textbf{73.0}  & \textbf{71.5} \\ 
            \bottomrule
        \end{tabular}
    }
    \label{tab:single_incre_main}
\end{table*}


\begin{table*}[!ht]
    \centering
    \footnotesize
    \caption{mAP@0.5 results on multiple incremental steps on PASCAL VOC 2007. The best performance in each is presented with \textbf{bold}, and the second best is presented with \underline{underline}. }
    \resizebox{\linewidth}{!}{
        \begin{tabular}{l||ccc|ccc|ccc|ccc|ccc}
            \toprule
            ~ & \multicolumn{3}{c|}{\textbf{10-5(3tasks)}} & \multicolumn{3}{c|}{\textbf{5-5(4tasks)}} & \multicolumn{3}{c|}{\textbf{10-2(6tasks)}} & \multicolumn{3}{c|}{\textbf{15-1(6tasks)}} & \multicolumn{3}{c}{\textbf{10-1(11tasks)}} \\ 
            \textbf{Method} & \textbf{1-10} & \textbf{11-20} & \textbf{1-20} & \textbf{1-5} & \textbf{6-20} & \textbf{1-20} & \textbf{1-10} & \textbf{11-20} & \textbf{1-20} & \textbf{1-15} & \textbf{16-20} & \textbf{1-20} & \textbf{1-10} & \textbf{11-20} & \textbf{1-20} \\ 
            \midrule
            \midrule
            Joint & 76.9  & 76.0  & 76.4  & 73.6  & 77.4  & 76.4  & 76.9  & 76.0  & 76.4  & 78.3  & 70.7  & 76.4  & 76.9  & 76.0  & 76.4  \\ 
            Fine-tuning & 5.3  & 30.6  & 18.0  & 0.5  & 18.3  & 13.8  & 3.8  & 13.6  & 8.7  & 0.0  & 10.5  & 5.3  & 0.0  & 5.1  & 2.6  \\ 
            \midrule
            ABR~\cite{yuyang2023augmented} & 68.7  & 67.1  & 67.9  & \textbf{64.7}  & 56.4  & 58.4  & 67.0  & \underline{58.1}  & \underline{62.6}  & 68.7  & \textbf{56.7}  & 65.7  & 62.0  & \textbf{55.7}  & \textbf{58.9}  \\ 
            \midrule
            FasterILOD~\cite{fasterrcnn} & 68.3  & 57.9  & 63.1  & 55.7  & 16.0  & 25.9  & 64.2  & 48.6  & 56.4  & 66.9  & 44.5  & 61.3  & 52.9  & 41.5  & 47.2  \\ 
            MMA~\cite{cermelli2022modeling} & 66.7  & 61.8  & 64.2  & 62.3  & 31.2  & 38.9  & 65.0  & 53.1  & 59.1  & 68.3  & 54.3  & 64.1  & 59.2  & 48.3  & 53.8  \\ 
            BPF~\cite{mo2024bridge} & \underline{69.1}  & \textbf{68.2}  & \underline{68.7}  & 60.6  & \underline{63.1}  & \underline{62.5}  & \underline{68.7}  & 56.3  & 62.5  & \underline{71.5}  & 53.1  & \underline{66.9}  & \underline{62.2}  & 48.3  & 55.2  \\ 
            \midrule
            % {NSGP-RePRE} & \underline{71.9}  & 66.2  & \underline{69.1}  & \textbf{65.9}  & \underline{63.8}  & \underline{64.3}  & \underline{68.7}  & 54.8  & 61.8  & \underline{77.0}  & 53.9  & \underline{71.2}  & \textbf{71.2}  & 50.6  & \underline{60.9}  \\ 
            {NSGP-RePRE} & \textbf{72.4}  & \underline{67.6}  & \textbf{70.0}  & \underline{64.6}  & \textbf{66.1}  & \textbf{65.7}  & \textbf{70.1}  & \textbf{58.8}  & \textbf{64.4}  & \textbf{77.7}  & \underline{55.0}  & \textbf{72.0}  & \underline{69.9}  & \underline{55.1}  & \textbf{62.5} \\ 
            \bottomrule
        \end{tabular}
    }
    \label{tab:multi_incre_main}
\end{table*}


\begin{table}[t]
    \centering
    \caption{mAP results on MS COCO 2017 at different IoU. The best performance in each is presented with \textbf{bold}, and the second best is presented with \underline{underline}.}
    \resizebox{\linewidth}{!}{
        \begin{tabular}{l||ccc|ccc}
            \toprule
            Method & \multicolumn{3}{c|}{\textbf{40-40}} & \multicolumn{3}{c}{\textbf{70-10}} \\ 
            ~ & \textbf{AP} & \textbf{AP50} & \textbf{AP75} & \textbf{AP} & \textbf{AP50} & \textbf{AP75} \\ 
            \midrule
            \midrule
            Joint & 36.7  & 57.8  & 39.8  & 36.7  & 57.8  & 39.8  \\
            Fine-tuning & 19.0  & 31.2  & 20.4  & 5.6  & 8.6  & 6.2  \\ 
            \midrule
            ILOD-Meta~\cite{ilodmeta} & 23.8  & 40.5  & 24.4  & - & - & - \\ 
            ABR~\cite{yuyang2023augmented} & \underline{34.5}  & \textbf{57.8}  & 35.2  & 31.1  & 52.9  & 32.7  \\ 
            \midrule
            FasterILOD~\cite{fasterrcnn} & 20.6  & 40.1  & - & 21.3  & 39.9  & - \\ 
            PseudoRM~\cite{pseudorm} & 25.3  & 44.4  & - & - & - & - \\ 
            MMA~\cite{cermelli2022modeling} & 33.0  & \underline{56.6}  & 34.6  & 30.2  & 52.1  & 31.5  \\ 
            BPF~\cite{mo2024bridge} & 34.4  & 54.3  & \underline{37.3}  & \underline{36.2}  & \textbf{56.8}  & \underline{38.9}  \\ 
            \midrule
            % {NSGP-RePRE} & \underline{35.2} & 55.3 & \underline{38.1} & \underline{36.3}  & 55.8  & \underline{39.6}  \\ 
            {NSGP-RePRE} & \textbf{35.4} & 55.3 & \textbf{38.6} & \textbf{36.5}  & \underline{56.0}  & \textbf{39.8} \\ 
            \bottomrule
        \end{tabular}
    }
    \label{tab:single_coco_main}
    \vspace{-0.3cm}
\end{table}

\section{Experiments}

\subsection{Experimental Settings}

\indent \textbf{Datasets and Evaluation Metrics.} Following the same protocols as in previous works~\cite{yuyang2023augmented,mo2024bridge}, we evaluate our method on the PASCAL VOC 2007~\cite{voc} and MS COCO 2017~\cite{coco} datasets. 
PASCAL VOC 2007 contains 20 different classes, including 9,963 annotated images. 
MS COCO 2017 dataset comprises 80 classes, with around 118k images for training and 5,000 images for validation. 
The mean average precision at the 0.5 IoU threshold (mAP@0.5) is used as the primary evaluation metric for VOC dataset, and the mean average precision ranging from 0.5 to 0.95 is the main evaluation metric for the COCO dataset. 
% In the catastrophic forgetting analysis on bbox regression of RPN and RoI Head, we use mean average recall at the 0.5 IoU threshold as our main evaluation metric.
For each incremental setting (A-B), the first number A denotes the number of classes in the first task, while the second number B represents the number of classes in the subsequent tasks.

\indent \textbf{Implementation Details.} 
Similar to previous works~\cite{yuyang2023augmented,mo2024bridge}, we build our incremental  Faster R-CNN~\cite{fasterrcnn} with R50~\cite{resnet}. 
% We name our framework incorporated with {RePRE++} as {NSGP-RePRE++}. 
In our method, we incorporate a pseudo-labeling strategy to solve the missing annotation problem as in BPF~\cite{mo2024bridge}. 
More implementation details can be found in the appendix.

\subsection{Quantitative Evaluation}
Following previous works~\cite{yuyang2023augmented, mo2024bridge}, our method is evaluated on various settings including single-step and multi-step increments.
We compare our method against two baselines: Joint Training, which involves training the model on the complete dataset using all annotations, and Fine-Tunning, where the model is incrementally trained on new data without any regularization strategy or data replay.




\subsubsection{PASCAL VOC 2007}
On the PASCAL VOC 2007 dataset, we assess our approaches using a single-step incremental task setting, which includes 19-1, 15-5, 10-10, and 5-15 tasks. 
We also examine a multi-step incremental task setting, covering settings such as 10-5, 5-5, 10-2, 15-1, and 10-1.

\indent \textbf{Single-step Increments.}
In Table~\ref{tab:single_incre_main}, we make a comparison between our proposed method and existing approaches. 
Our method frequently surpasses others in a range of settings, particularly in the base classes in the initial learning stage, demonstrating its superior ability to mitigate catastrophic forgetting.
Specifically, NSGP-RePRE exceeds the previous leading replay-based approach ABR, by an average of 4.4\% in the initial class set. It also exceeds the previous SOTA method BPF by 2.3\% in the initial class set, bolstering our assertion regarding the superior anti-forgetting capability of our approach. NSGP-RePRE exceeds ABR by 3.3\% and BPF by 1\% in all 20 classes, underscoring the effectiveness of our method. The Avg metric equally average base and new classes mAP, showing stability and plasticity balance without the influence of the number of classes. In Avg, our method surpasses ABR and BPF by 2.1\% and 1.2\%, respectively, demonstrating that our method prevails in balance between stability and plasticity in all methods.


\indent \textbf{Multi-step Increments.}
The issue of catastrophic forgetting becomes more challenging in longer incremental settings. 
As demonstrated in Table~\ref{tab:multi_incre_main}, fine-tuning nearly completely forgets the initial classes. {NSGP-RePRE} shows a 4.7\% improvement over ABR in initial classes across all 5 settings, and a 4.2\% improvement in all 1-20 classes. Our method exceeds the performance of BPF by 4.5\% in the base classes and 2.3\% in the 1-20 classes. 
In the particularly demanding 10-1 settings, our method is 3.6\% better than ABR, highlighting the efficacy of our proposed approaches. The improvements observed in more complex multi-step increment settings further validate the effectiveness of our proposed methods.



\begin{table}[t]
\footnotesize
    \centering
    \caption{Ablation study on each component. Where ``Coarse'' indicates coarse prototypes replay only, ``Fine'' indicates fine-grained regional prototypes are also incorporated. }
    \resizebox{\linewidth}{!}{
        \begin{tabular}{c|ccc|ccccc}
            \toprule
            ~ & \multirow{2}{*}{{\makecell[c]{NSGP}}} & \multirow{2}{*}{\makecell[c]{{\makecell[c]{Coarse}}}} & \multirow{2}{*}{\makecell[c]{{\makecell[c]{Fine}}}} & \multicolumn{5}{c}{\textbf{VOC(5-5)}} \\ 
            Model & ~ & ~ & ~ & \textbf{1-5} & \textbf{6-10} & \textbf{11-15} & \textbf{16-20} & \textbf{1-20} \\ 
            \midrule
            \midrule
            (a) & ~ & ~ & ~ & 46.6 & 56.5 & 71.1& \underline{59.6} & 58.4 \\ 
            (b) & \checkmark & ~ & ~ & 62.3 & 60.4 & 73.1 & 57.4 & 63.3 \\ 
            (c) & ~ & \checkmark & ~ & 49.8 & 61.0 & \underline{73.5} & \textbf{60.5} & 61.2 \\ 
            (d) & \checkmark & \checkmark & ~ & \textbf{65.9}  & \underline{61.6} & \textbf{73.8} & 56.0 & \underline{64.3} \\ 
            (e) & \checkmark & \checkmark & \checkmark & \underline{64.6} & \textbf{66.2} & 73.1 & 59.0 & \textbf{65.7} \\ 
            \bottomrule
        \end{tabular}
    }
    \label{tab:component}
\end{table}

\subsubsection{MS COCO 2017}

On MS COCO 2017 dataset, we performed experiments on 40-40 and 70-10 settings using the same protocol in comparison methods. 
As shown in Table~\ref{tab:single_coco_main}, fine-tuning suffers from catastrophic forgetting in both settings. 
While previous approaches have been enhanced with fine-tuning, NSGP-RePRE increased the average AP by 1.0\% over the previous state-of-the-art in the 40-40 configuration. 
In the 70-10 scenario, the performance is close to that of joint training, with our method yielding 0.3\% improvements over the previous SOTA BPF. 
These experimental results demonstrate the efficacy of our approach.



\subsection{Further Analysis}

\indent \textbf{Effectiveness of Each Component.}
In Table~\ref{tab:component}, we analyze the effectiveness of {NSGP}, {Coarse}, and {Fine} under the VOC 5-5 setting, where ``Coarse'' indicates that only coarse prototypes are adopted during replay while ``Fine'' shows the results incorporated with fine-grained regional prototypes. Variant a denotes our baseline model using pseudo-labeling. Variant b denotes that NSGP is employed to solve the feature drift based upon a, which significantly reduces the catastrophic forgetting of old classes, thus markedly improving old class detection over a. 
Variant c incorporates RePRE with coarse prototypes only to mitigate catastrophic forgetting.
However, performance remains suboptimal due to the feature shift from the updating of the feature extractor. 
The variant d denotes our NSGP-RePRE with coarse prototypes only, which substantially reduces catastrophic forgetting and demonstrates the efficacy of the method. 
NSGP-RePRE achieves the highest performance among all models, exceeding d by 1.4\% in the 1-20 division, underscoring the effectiveness of our method. 
As shown in Table~\ref{tab:component}, each adopted component independently reduces forgetting and reaches peak performance when used together.

\indent \textbf{Anti-forgetting in RoI Head's classifier.} As we intend to minimize the classification error caused by the forgetting in RoI Head's classifier, we demonstrate that our method can effectively solve the problem. As shown in Figure~\ref{fig:ours-fixed-proposals}, we fixed a set of proposals predicted by the ${\cal M}_1$ as the proposals for all $\cal M$. Fixed cls indicates that the model classification results are designated by ${\cal M}_1$. The baseline is the detector only applied with a pseudo-labeling strategy. ${\cal M}_1$ is the ideal upper bound in $\mathcal{D}_1^{test}$ as it is freshly trained on $\mathcal{D}_1$. From Figure~\ref{fig:ours-fixed-proposals}, we can draw some conclusions:
1. By comparing the red curves, we can see that our method has a better classification performance, suggesting the effectiveness of our proposed method.
2. Suggested by the light blue area, NSGD can further reduce the already minimal forgetting in regression.
3. Though the classifier specifically focuses on reducing classification error, the extra components introduced by the method will not disrupt the observation that the regressor exhibits minimal forgetting.

% Although the regressor in RoI Head shows minimal forgetting, it has a slight effect on the detector's efficacy. NSGP also minimizes the regressor's forgetting, as depicted by the light blue gap in Figure~\ref{fig:ours-fixed-proposals}, where fixed cls signifies each proposal's classification aligns with ${\cal M}_1$'s prediction. But
% as our expectation, the improvement is minor because both of the results are near the upper bound for the forgetting in the RoI Head is insignificant.  The findings also indicate that our classifier-only strategy does not disrupt the observation that the regressor exhibits minimal forgetting.
\begin{figure}
    \centering
    \includegraphics[width=1.0\linewidth]{figs/OursVsBaselineFixedProposals.pdf}
    \caption{mAP of different model on $\mathcal{D}_1^{test}$ in VOC(5-5) settings. To better demonstrate the impact of our method on the classifier, $P_1$ is fixed to all models. Fixed cls indicates the models classification results is designated by ${\cal M}_1$.}
    \label{fig:ours-fixed-proposals}
\end{figure}

\section{Conclusion}

This study investigates Faster R-CNN as the representative two-stage incremental object detector and demonstrates that catastrophic forgetting primarily originates from the RoI Head's classifier while regressor exhibits minimal forgetting. 
The finding can provide principled guidelines for 
designing simple yet effective IOD method. Consequently, we introduce the NSGP-RePRE framework to mitigate forgetting in the RoI Head classifier complemented with NSGP on the feature extractor.
Our extensive experimental results demonstrate the efficacy of the proposed methods.
We hope that our research will offer significant insights into IOD, facilitating progress in this area.
% In the unusual situation where you want a paper to appear in the
% references without citing it in the main text, use \nocite
\nocite{langley00}

\bibliography{reference}
\bibliographystyle{icml2025}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% APPENDIX
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newpage
\appendix
\onecolumn

\section{Implementation Details.}
Similar to previous works, we use the Faster R-CNN architecture with a Resnet-50~\cite{resnet} backbone pre-trained in ImageNet~\cite{imagenet}. On PASCAL VOC dataset, we train the network with SGD optimizer, momentum of 0.9 and weight decay of 10e-4. We use a learning rate of 0.02 for all tasks.  
For MS COCO, we adopt AdamW as the optimizer, weight deacy of 0.01 and learning rate of 5e-5.
Batch size is set to 16 for both datasets. In {NSGP}, we follow the adaptive selecting stategy proposed in ~\cite{lu2024visual} to keep the singular vaules.
% For fine-grained regional prototypes, 
We sample 9 extra fine-grained prototypes to complement the coarse prototype, 10 prototypes are used in total. The radius $r$ is set to 0.6. 
% We name our framework incorporated with RePRE++ as {NSGP-RePRE++}. 
In our method, we incorporate a pseudo-labeling strategy to solve the foreground shift problem as implemented in BPF~\cite{mo2024bridge}.
All of our experiments were conducted on 2 RTX 3090 GPU.

\section{Generalization on unseen classes of RPN.} 

Interestingly, our findings reveal that RPN effectively generalizes to previously unseen classes. 
As depicted in Figure~\ref{fig:rpnrecall}, the red lines represent the RPN's recall for objects belonging to unseen classes. 
Figure~\ref{fig:rpnrecall} (d) illustrates how RPNs of ${\cal M}_1$ to ${\cal M}_3$ successfully recall certain objects belonging to classes in the 4-th stage. 
It can be clearly seen that the recall ability of ${\cal M}_1$ to ${\cal M}_3$ on test set of ${\cal D}_4^{test}$ can be consistently improved after sequential learning. 
%Additionally, zero-shot detection by ${\cal M}$ improves with more training data, as shown by better proposal quality from ${\cal M}_1$ to ${\cal M}_3$. 
A similar trend is seen in Figure~\ref{fig:rpnrecall} (b) and (c), suggesting RPN's potential to enhance zero-shot detection with sufficient training data. 
%Generalized proposals are also usable by the RoI Head. 
In Figure~\ref{fig:switch-proposals} (d), the red dots represent the outcomes of testing ${\cal M}_4$ on the test set of $\mathcal{D}_4^{test}$ employing proposals $\vP_1$ to $\vP_3$, which were generated by models that have not encountered the classes within $\mathcal{C}_4$. Despite this, ${\cal M}_4$ is still able to identify unseen objects with high mAP, showcasing the impressive zero-shot ability of the RPN.

\section{Is the RoI Head robust to low-quality proposals?} 

\begin{figure}[h]
    \centering
    \includegraphics[width=0.6\linewidth]{figs/pruneHighQuality1.pdf}
    \caption{{\color{mygreen}Plot:} Results of ${\cal M}_{joint}$ after removing high-quality proposals with varying IoU threshold. {\color{myblue}Bar:} The distribution of the proposals generated with ${\cal M}_{joint}$ over IoU. The number on the bar indicates the count of proposals.}
    \label{fig:prune-high-quality}
\end{figure}

A robust RoI head is capable of effectively offsetting RPN's forgetting.
To evaluate the robustness of the RoI Head, we manually removed high-quality proposals during inference, \ie high IoU with GTs, to assess the mAP result of the detector.
As shown in Figure~\ref{fig:prune-high-quality}, when removing the proposals with IoU above 0.7, comparable final results can still be obtained (74.5\% to 76.4\%).
In particular, the detector still manages to detect some instances and achieves noticeable results when removing proposals with IoU above 0.5, showing the strong robustness of the RoI Head.
The robustness of the RoI Head can be attributed to the training process, where the RoI Head is trained to refine coarse proposals which have a very broad IoU range from a given value, 0.7 for example, to 1. 
The training with coarse proposals enables the RoI Head to refine rather low-quality proposals, leading to a robust performance of the RoI Head.

\section{Null Space Gradient Projection Details.}

We introduced {NSGP} to alleviate the RoI feature shift caused by the evolution of the feature extractor. It is crucial for the {NSGP} to obtain a projection matrix that can project the gradient $G$ into the null space of the old example ${\cal X}_t=\{x_{t, i} \mid i\in \mathbb{N}, 1\leq i\leq M_t\}$, where $M_t$ is the total number of inputs in the $t$-th training stages. An overview of {NSGP} are provided in Figure~\ref{fig:nsgp}.

\begin{figure}[h]
    \centering
    \includegraphics[width=0.6\linewidth]{figs/NSGP.pdf}
    \caption{An overview of {NSGP}.}
    \label{fig:nsgp}
\end{figure}

To obtain the projection matrix of an FC layer or a convolution layer with parameters $W$, we first compute the uncentered covariance of ${\cal X}_{t}$. Specifically, we can accumulate uncentered covariance matrix in $t$-th stage ${\cal T}_{t}$ as:
\begin{equation}
    {\cal T}_{t} = \frac{1}{N_t-1}\sum_{i=1}^{N_t} {x}_{t,i}^\top{x}_{t,i}.
\end{equation}
After obtaining the uncentered covariance in $t$. The uncentered covariance of all previous training stages can be updated as
\begin{equation}
    \Bar{\cal T}_{t} = \frac{\Bar{M}_{t-1}}{\Bar{M}_{t}}\Bar{\cal T}_{t-1} + \frac{M_{t}}{\Bar{M}_{t}}{\cal T}_{t}.
\end{equation}
Here, $\Bar{M}_t = \Bar{M}_{t-1} + M_t$.
Then SVD is performed to obtain $U_{t}, \Lambda_t, (U_{t})^\top$ as 
\begin{equation}
    U_{t}, \Lambda_t, (U_{t})^\top = SVD(\Bar{\cal T}_{t-1})
\end{equation}
Following ~\cite{lu2024visual}, we adaptively determine the nullity $R$ and retain $U_{t}^\prime$ correspond to $R$ smallest diagonal singular vaules $\lambda$ in $\Lambda_t$. Finally, the projection matrix for $(t+1)$-th training stage is obtained by
\begin{equation}
    {\cal B} = U_{t}^\prime(U_{t}^\prime)^\top,
\end{equation}
and the gradient $G$ is projected to the null space of ${\cal X}_t$ as
\begin{equation}
    \Delta W = G{\cal B}.
\end{equation}
It is a common practice in previous works~\cite{adamnscl, lu2024visual} to normalize the $\cal B$ as 
\begin{equation}
    {\cal B}^\prime = \frac{\cal B}{||{\cal B}||_F}.
\end{equation}
Unlike previous works, we adopt $\cal B$ as normalized ${\cal B}^\prime$ will decrease the update stride of the model, leading to a slow and difficult optimization. The slow learner is beneficial to the classification task, as shown in SLCA~\cite{slca}, but it is not applicable to components in Faster R-CNN except backbone. Thus we only apply ${\cal B}^\prime$ to the backbone, adopting $\cal B$ to the rest of the components in the detector. EWC~\cite{ewc} is adopted to regulate the update of parameterized normalization layers.
\begin{table}[t]
    \centering
    \caption{The experimental results of {NSGP} in different components with projection matrix $\cal B$ or ${\cal B}^\prime$. The dataset we adopted is VOC (5-5).}
    \begin{tabular}{ccccc}
    \hline
        \toprule
        ~ & Backbone & +Neck & +RPN & +RoI Head \\
        \midrule
        $\cal B$ & 62.6 & 60.3 & 59.0 & 41.9 \\
        ${\cal B}^\prime$ & 62.6 & \textbf{63.3} & 63.0 & 63.2 \\
        \bottomrule
    \label{tab:nsgp}
    \end{tabular}
\end{table}

To justify our choice of only applying {NSGP} to the backbone and neck, we conduct experiments on all components of the detector, as show in Table~\ref{tab:nsgp}.  $\cal B$ or ${\cal B}^\prime$ indicates that the gradient of component, except the backbone, is projected by $\cal B$ or ${\cal B}^\prime$. Our experiments suggest that adopting {NSGP} in different components leads to results without significant fluctuations, suggesting the detector is not sensitive to the {NSGP}. Comparing $\cal B$ and ${\cal B}^\prime$ suggests that lower scale for the update stride in neck, RPN and RoI Head leads to a significant decrease in performance. These results justify our choice of $\cal B$ instead of $\cal B^\prime$.


\section{Different strategy generating fine-grained prototypes.}

To evaluate the effectiveness of the proposed fine-grained prototype generation process, we compared our method with clustering algorithms: K-Means and DBSCAN. To justify our choice of prototype instead of instances, we selected the center of the hypersphere instead of the averaging of the RoI features included in the hypersphere and named this method Instance. As shown in Table~\ref{tab:complement-prototypes}, our results outperform K-Means and DBSCAN by 0.7\% on average, suggesting the effectiveness of the proposed method. Our prototypes surpass Instance by 1.4\%, justifying the choice of the prototype instead of instances.

\begin{table}[h]
    \centering
    \caption{Different strategy generating complementary prototypes of our method.}
    \begin{tabular}{c|ccc}
        \toprule
        ~ & \multicolumn{3}{c}{VOC(5-5)} \\ 
        Method & 1-5 & 6-20 & 1-20 \\ 
        \midrule
        K-Means & 62.7 & 65.6 & 64.9 \\ 
        DBSCAN & 63.6 & 65.5 & 65.1 \\ 
        Instance & 63.2  & 64.6  & 64.3  \\ 
        Ours & \textbf{64.6} & \textbf{66.1} & \textbf{65.7} \\ 
        \bottomrule
    \end{tabular}
    \label{tab:complement-prototypes}
\end{table}


\section{RePRE Performance with Coarse Regional Prototype Only.}

Our RePRE can surpass previous works even with only coarse prototype being replayed. We name NSGP-RePRE incorporated with coarse prototype only as the NSGP-RePRE-Coarse.

\indent \textbf{PASCAL VOC Single-step Increments.} In Table~\ref{tab:single_incre_main_coarse}, we make a comparison between our proposed method and existing approaches. NSGP-RePRE-Coarse surpasses previous state-of-the-art BPF by 1.7\% in base classes and by 0.7\% in all 20 classes, underscoring the effectiveness of our approach. 

\indent \textbf{PASCAL VOC Multi-step Increments.} The increases in initial classes indicate reduced forgetting with only coarse prototypes, while the improvements in 1-20 and the average reflect that our method achieves the optimal balance between stability and plasticity compared with previous methods.
In Table~\ref{tab:multi_incre_main_coarse}, NSGP-RePRE-Coarse shows a 4.7\% improvement over ABR in the initial classes in all 5 settings and a 2. 8\% improvement in the 1-20 classes. Our method exceeds the performance of BPF by 4.5\% in the base classes and 2.3\% in the 1-20 classes. 

\indent \textbf{MS COCO Single Increments.} In Table~\ref{tab:single_coco_main_coarse}, NSGP-RePRE-Coarse increased the average AP by 0.8\% over the previous state-of-the-art in the 40-40 configuration. 
In the 70-10 scenario, the performance is close to that of joint training, with our method yielding results comparable to the previous SOTA BPF. 
These experimental results demonstrate the efficacy of NSGP-RePRE-Coarse.



\begin{table*}[!ht]
    \centering
    \footnotesize
    \caption{mAP@0.5 results on single incremental step on PASCAL VOC 2007. The best performance in each is presented with \textbf{bold}, and the second best is presented with \underline{underline}. }
    \resizebox{\linewidth}{!}{
        \begin{tabular}{l||cccc|cccc|cccc|cccc}
        \toprule
            ~ & \multicolumn{4}{c|}{\textbf{19-1}} & \multicolumn{4}{c|}{\textbf{15-5}} & \multicolumn{4}{c|}{\textbf{10-10}} & \multicolumn{4}{c}{\textbf{5-15}} \\ 
            \textbf{Method} & \textbf{1-19} & \textbf{20} & \textbf{1-20} & \textbf{Avg} & \textbf{1-15} & \textbf{16-20} & \textbf{1-20} & \textbf{Avg} & \textbf{1-10} & \textbf{11-20} & \textbf{1-20} & \textbf{Avg} & \textbf{1-5} & \textbf{5-15} & \textbf{1-20} & \textbf{Avg} \\ 
            \midrule
            \midrule
            Joint & 76.4  & 76.4  & 76.4  & 76.4  & 78.3  & 70.7  & 76.4  & 74.5  & 76.9  & 76.0  & 76.4  & 76.4  & 73.6  & 77.4  & 76.4  & 75.5  \\ 
            Fine-tuning & 12.0  & 62.8  & 14.5  & 37.4  & 14.2  & 59.2  & 25.4  & 36.7  & 9.5  & 62.5  & 36.0  & 36.0  & 6.9  & 63.1  & 49.1  & 35.0  \\ 
            \midrule
            ORE~\cite{ore} & 69.4  & 60.1  & 68.9  & 64.7  & 71.8  & 58.7  & 68.5  & 65.2  & 60.4  & 68.8  & 64.6  & 64.6  & - & - & - & - \\ 
            OW-DETR~\cite{owdetr} & 70.2  & 62.0  & 69.8  & 66.1  & 72.2  & 59.8  & 69.1  & 66.0  & 63.5  & 67.9  & 65.7  & 65.7  & - & - & - & - \\ 
            ILOD-Meta~\cite{ilodmeta} & 70.9  & 57.6  & 70.2  & 64.2  & 71.7  & 55.9  & 67.8  & 63.8  & 68.4  & 64.3  & 66.3  & 66.3  & - & - & - & - \\ 
            ABR~\cite{yuyang2023augmented} & 71.0  & \textbf{69.7}  & 70.9  & 70.4  & 73.0  & \textbf{65.1}  & 71.0  & 69.1  & 71.2  & 72.8  & 72.0  & 72.0  & 64.7  & 71.0  & 69.4  & 67.9  \\ 
            \midrule
            FasterILOD~\cite{fasterrcnn} & 68.9  & 61.1  & 68.5  & 65.0  & 71.6  & 56.9  & 67.9  & 64.3  & 69.8  & 54.5  & 62.1  & 62.1  & 62.0  & 37.1  & 43.3  & 49.6  \\ 
            PPAS~\cite{ppas} & 70.5  & 53.0  & 69.2  & 61.8  & - & - & - & - & 63.5  & 60.0  & 61.8  & 61.8  & - & - & - & - \\ 
            MVC~\cite{mvc} & 70.2  & 60.6  & 69.7  & 65.4  & 69.4  & 57.9  & 66.5  & 63.7  & 66.2  & 66.0  & 66.1  & 66.1 & - & - & - & - \\ 
            PROB~\cite{prob} & 73.9  & 48.5  & 72.6  & 61.5  & 73.5  & 60.8  & 70.1  & 67.0  & 66.0  & 67.2  & 66.5  & 66.5 & - & - & - & - \\ 
            PseudoRM~\cite{pseudorm} & 72.9  & 67.3  & 72.6  & 70.1  & 73.4  & 60.9  & 70.3  & 66.9  & 69.1  & 68.6  & 68.9  & 68.9 & - & - & - & - \\ 
            MMA~\cite{cermelli2022modeling} & 71.1  & 63.4  & 70.7  & 67.2  & 73.0  & 60.5  & 69.9  & 66.7  & 69.3  & 63.9  & 66.6  & 66.6  & 66.8  & 57.2  & 59.6  & 62.0  \\ 
            BPF~\cite{mo2024bridge} & 74.5  & 65.3  & 74.1  & 69.9  & 75.9  & \underline{63.0}  & 72.7  & 69.5  & 71.7  & \textbf{74.0}  & 72.9  & 72.9  & 66.4  & \textbf{75.3}  & 73.0  & 70.9  \\ 
            \midrule
            {NSGP-RePRE-Coarse} & \underline{76.2}  & 66.5  & \underline{75.8}  & \underline{71.4}  & \underline{77.1}  & 62.0  & \underline{73.4}  & \underline{69.6}  & \underline{73.7}  & \underline{73.2}  & \underline{73.4}  & \underline{73.5}  & \underline{68.4}  & \underline{74.5}  & \textbf{73.0}  & \textbf{71.5}  \\ 
            {NSGP-RePRE} & \textbf{76.3}  & \underline{69.0}  & \textbf{76.0}  & \textbf{72.7}  & \textbf{77.5}  & 61.8  & \textbf{73.6}  & \textbf{69.7}  & \textbf{75.3}  & 72.7  & \textbf{74.0} & \textbf{74.0}  & \textbf{68.5}  & \underline{74.5}  & \textbf{73.0}  & \textbf{71.5} \\ 
            \bottomrule
        \end{tabular}
    }
    \label{tab:single_incre_main_coarse}
\end{table*}


\begin{table*}[!ht]
    \centering
    \footnotesize
    \caption{mAP@0.5 results on multiple incremental steps on PASCAL VOC 2007. The best performance in each is presented with \textbf{bold}, and the second best is presented with \underline{underline}. }
    \resizebox{\linewidth}{!}{
        \begin{tabular}{l||ccc|ccc|ccc|ccc|ccc}
            \toprule
            ~ & \multicolumn{3}{c|}{\textbf{10-5(3tasks)}} & \multicolumn{3}{c|}{\textbf{5-5(4tasks)}} & \multicolumn{3}{c|}{\textbf{10-2(6tasks)}} & \multicolumn{3}{c|}{\textbf{15-1(6tasks)}} & \multicolumn{3}{c}{\textbf{10-1(11tasks)}} \\ 
            \textbf{Method} & \textbf{1-10} & \textbf{11-20} & \textbf{1-20} & \textbf{1-5} & \textbf{6-20} & \textbf{1-20} & \textbf{1-10} & \textbf{11-20} & \textbf{1-20} & \textbf{1-15} & \textbf{16-20} & \textbf{1-20} & \textbf{1-10} & \textbf{11-20} & \textbf{1-20} \\ 
            \midrule
            \midrule
            Joint & 76.9  & 76.0  & 76.4  & 73.6  & 77.4  & 76.4  & 76.9  & 76.0  & 76.4  & 78.3  & 70.7  & 76.4  & 76.9  & 76.0  & 76.4  \\ 
            Fine-tuning & 5.3  & 30.6  & 18.0  & 0.5  & 18.3  & 13.8  & 3.8  & 13.6  & 8.7  & 0.0  & 10.5  & 5.3  & 0.0  & 5.1  & 2.6  \\ 
            \midrule
            ABR~\cite{yuyang2023augmented} & 68.7  & 67.1  & 67.9  & \underline{64.7}  & 56.4  & 58.4  & 67.0  & \underline{58.1}  & \underline{62.6}  & 68.7  & \textbf{56.7}  & 65.7  & 62.0  & \textbf{55.7}  & 58.9  \\ 
            \midrule
            FasterILOD~\cite{fasterrcnn} & 68.3  & 57.9  & 63.1  & 55.7  & 16.0  & 25.9  & 64.2  & 48.6  & 56.4  & 66.9  & 44.5  & 61.3  & 52.9  & 41.5  & 47.2  \\ 
            MMA~\cite{cermelli2022modeling} & 66.7  & 61.8  & 64.2  & 62.3  & 31.2  & 38.9  & 65.0  & 53.1  & 59.1  & 68.3  & 54.3  & 64.1  & 59.2  & 48.3  & 53.8  \\ 
            BPF~\cite{mo2024bridge} & 69.1  & \textbf{68.2}  & 68.7  & 60.6  & 63.1  & 62.5  & 68.7  & 56.3  & 62.5  & 71.5  & 53.1  & 66.9  & 62.2  & 48.3  & 55.2  \\ 
            \midrule
            {NSGP-RePRE-Coarse} & \underline{71.9}  & 66.2  & \underline{69.1}  & \textbf{65.9}  & \underline{63.8}  & \underline{64.3}  & \underline{68.7}  & 54.8  & 61.8  & \underline{77.0}  & 53.9  & \underline{71.2}  & \textbf{71.2}  & 50.6  & \underline{60.9}  \\ 
            {NSGP-RePRE} & \textbf{72.4}  & \underline{67.6}  & \textbf{70.0}  & 64.6  & \textbf{66.1}  & \textbf{65.7}  & \textbf{70.1}  & \textbf{58.8}  & \textbf{64.4}  & \textbf{77.7}  & \underline{55.0}  & \textbf{72.0}  & \underline{69.9}  & \underline{55.1}  & \textbf{62.5} \\ 
            \bottomrule
        \end{tabular}
    }
    \label{tab:multi_incre_main_coarse}
\end{table*}

\begin{table}[!ht]
    \centering
    \caption{mAP results on MS COCO 2017 at different IoU. The best performance in each is presented with \textbf{bold}, and the second best is presented with \underline{underline}.}
        \begin{tabular}{l||ccc|ccc}
            \toprule
            Method & \multicolumn{3}{c|}{\textbf{40-40}} & \multicolumn{3}{c}{\textbf{70-10}} \\ 
            ~ & \textbf{AP} & \textbf{AP50} & \textbf{AP75} & \textbf{AP} & \textbf{AP50} & \textbf{AP75} \\ 
            \midrule
            \midrule
            Joint & 36.7  & 57.8  & 39.8  & 36.7  & 57.8  & 39.8  \\
            Fine-tuning & 19.0  & 31.2  & 20.4  & 5.6  & 8.6  & 6.2  \\ 
            \midrule
            ILOD-Meta~\cite{ilodmeta} & 23.8  & 40.5  & 24.4  & - & - & - \\ 
            ABR~\cite{yuyang2023augmented} & 34.5  & \textbf{57.8}  & 35.2  & 31.1  & 52.9  & 32.7  \\ 
            \midrule
            FasterILOD~\cite{fasterrcnn} & 20.6  & 40.1  & - & 21.3  & 39.9  & ~ \\ 
            PseudoRM~\cite{pseudorm} & 25.3  & 44.4  & - & - & - & - \\ 
            MMA~\cite{cermelli2022modeling} & 33.0  & \underline{56.6}  & 34.6  & 30.2  & 52.1  & 31.5  \\ 
            BPF~\cite{mo2024bridge} & 34.4  & 54.3  & 37.3  & 36.2  & \textbf{56.8}  & 38.9  \\ 
            \midrule
            {NSGP-RePRE-Coarse} & \underline{35.2} & 55.3 & \underline{38.1} & \underline{36.3}  & 55.8  & \underline{39.6}  \\ 
            {NSGP-RePRE} & \textbf{35.4} & 55.3 & \textbf{38.6} & \textbf{36.5}  & \underline{56.0}  & \textbf{39.8} \\ 
            \bottomrule
        \end{tabular}
    \label{tab:single_coco_main_coarse}
    \vspace{-0.3cm}
\end{table}

% \indent \textbf{BBox+Cls Replay v.s. Cls Replay.} Elaborated a lot about bbox replay is not necessary, I think it is still necessary to include experiments that replay cls+bbox compared with cls replay.
% \begin{table}[!ht]
%     \centering
%     \caption{Results when replaying all RoI features. Bbox/Cls represents wheather to replay regression/classification loss.}
%     \begin{tabular}{c|ccc}
%         \toprule
%         ~ & \multicolumn{3}{c}{VOC(5-5)} \\ 
%         Loss & 1-5 & 6-20 & 1-20 \\ 
%         \midrule
%         Bbox+Cls.Distill & 68.8 & 67.0 & 67.5 \\ 
%         Cls.Distill & 68.2 & 68.5 & 68.4 \\ 
%         Bbox+Cls.Replay & 53.5 & 60.0 & 58.3 \\
%         Cls.Replay & 63.2 & 65.6 & 65.0 \\
%         \bottomrule
%     \end{tabular}
% \end{table}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\end{document}


% This document was modified from the file originally made available by
% Pat Langley and Andrea Danyluk for ICML-2K. This version was created
% by Iain Murray in 2018, and modified by Alexandre Bouchard in
% 2019 and 2021 and by Csaba Szepesvari, Gang Niu and Sivan Sabato in 2022.
% Modified again in 2023 and 2024 by Sivan Sabato and Jonathan Scarlett.
% Previous contributors include Dan Roy, Lise Getoor and Tobias
% Scheffer, which was slightly modified from the 2010 version by
% Thorsten Joachims & Johannes Fuernkranz, slightly modified from the
% 2009 version by Kiri Wagstaff and Sam Roweis's 2008 version, which is
% slightly modified from Prasad Tadepalli's 2007 version which is a
% lightly changed version of the previous year's version by Andrew
% Moore, which was in turn edited from those of Kristian Kersting and
% Codrina Lauth. Alex Smola contributed to the algorithmic style files.
