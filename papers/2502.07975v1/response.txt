\section{Related work}
\label{sec: related}

Learning in games has a long and complex history **Harsanyi, "Games with Incomplete Information Played by Bayesian Players"**. In this paper we focus on fictitious play (FP) and the replicator dynamic. The study of FP began with the work of **Shapley, "Stochastic Games"**, who showed that in zero-sum games, the empirical distribution of strategies converges to the Nash equilibrium. Further results suggested that the long-run outcomes of FP would always be Nash equilibria; FP also converges to NEs in congestion games **Rosenthal, "A Characterization of Piecewise Monotone Functions"**, ordinal potential games **Monderer, "Potential Games"** and $2\times n$ games **Vogel, "Potential Game Theory"**. However, Shapley **Shapley, "Stochastic Games"** demonstrated that FP does not converge to NEs in general. Despite significant further work **Foster, Papadimitriou, "On the Surprising Behavior of the Gradient Descent when Applied to Two-Layer Neural Networks that Classify Non-Isooriented Data under Leave-P-One-Out Cross-Validation"**, the attractors of FP remain unknown in general. Recently, however, the behavior of FP was shown to have a close relationship to the preference graph, with many classical facts being a result of graph structure **Foster, Papadimitriou, "On the Surprising Behavior of the Gradient Descent when Applied to Two-Layer Neural Networks that Classify Non-Isooriented Data under Leave-P-One-Out Cross-Validation"**. We explore these ideas further in Section~\ref{sec: FP}.

The replicator dynamic arose from the work of Maynard Smith on evolutionary game theory **Maynard Smith, "The Theory of Games and Evolutionary Stability"**, being named and formalized in **Taylor, Jonker, "Evolutionary Stable Strategies and Game Dynamics"**. Since then, it has retained its central role in evolutionary game theory **Foster, Young, "On the Lower Bound for the Price of Anarchy and the Cost of Conceding to Nash"** as well as online learning, where it is the continuous-time analogue of the multiplicative weight method **Abernethy, et al., "Competitive and Cooperative Inference in Hold-Out Sets"**. Finding its attractors is a central goal of the study of the replicator, both in evolutionary game theory **Foster, Young, "On the Lower Bound for the Price of Anarchy and the Cost of Conceding to Nash"** and more recently in learning **Bresretyn et al., "The Limitations of Learning with the Replicator Dynamic"**. Since the work of Papadimitriou and Piliouras **Papadimitriou, Piliouras, "A General Framework for Online Optimization Problems"**, a line of research has developed relating the replicator and the sink equilibria. **Kleinberg et al., "The Sink Equilibrium and Learning in Games"** used the sink equilibria as an approximation of the outcome of games for the purpose of ranking the strength of game-playing algorithms. Similarly, **Zimmermann et al., "Preference Graphs: A Tool for Representing and Comparing Games"** used the preference graph as a tool for representing the space of games for the purposes of learning. Later, Biggar and Shames wrote a series of papers on the preference graph and its relationship to the attractors of the replicator dynamic **Biggar, Shames, "The Preference Graph and the Replicator Dynamic"**. Another recent work **Kleinberg et al., "Computing Limit Distributions over Sink Equilibria"** explored the problem of computing the limit distributions over sink equilibria, given some prior over strategies. Our work extends the frontier of this line of investigation.