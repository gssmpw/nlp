\documentclass{article}
\usepackage{booktabs} % For formal tables
\usepackage[ruled]{algorithm2e} % For algorithms
\renewcommand{\algorithmcfname}{ALGORITHM}
\SetAlFnt{\small}
\SetAlCapFnt{\small}
\SetAlCapNameFnt{\small}
\SetAlCapHSkip{0pt}
\IncMargin{-\parindent}


%\usepackage{natbib}
\input{preamble}

%\newcommand{\exptu}{\mathbb{U}}

\newcommand{\toprove}[1]{\todo[color=green]{#1}}
\DeclareMathOperator{\cl}{cl}

\title{Sink equilibria and the attractors of learning in games}
\author{Oliver Biggar and Christos Papadimitriou}
\date{}

\begin{document}
\maketitle

\begin{abstract}
\noindent Characterizing the limit behavior --- that is, the attractors --- of learning dynamics is one of the most fundamental open questions in game theory. In recent work in this front, it was conjectured that the attractors of the replicator dynamic are in one-to-one correspondence with the \emph{sink equilibria} of the game --- the sink strongly connected components of a game's \emph{preference graph} ---, and it was established that they do stand in at least one-to-many correspondence with them.  We make threefold progress on the problem of characterizing attractors. First, we show through a topological construction that the one-to-one conjecture is false. Second, we make progress on the attractor characterization problem for two-player games by establishing that the one-to-one conjecture is true in the absence of a local pattern called a \emph{weak local source} --- a pattern that is absent from zero-sum games. Finally, we look  --- for the first time in this context --- at \emph{fictitious play}, the longest-studied learning dynamic, and examine to what extent the conjecture generalizes there. We establish that under fictitious play, sink equilibria always contain attractors (sometimes strictly), and every attractor corresponds to a strongly connected set of nodes in the preference graph.
\end{abstract}

\section{Introduction} \label{sec:intro}

What are the possible outcomes of a collection of jointly-learning rational agents? This is a fundamental --- arguably \emph{the} fundamental --- problem in the study of learning in games, with consequences for machine learning, economics and evolutionary biology.  The question has received decades of study by mathematicians, economists and computer scientists \cite{zeeman_population_1980,milgrom_adaptive_1991,hofbauer_evolutionary_1996,sandholm2010population,papadimitriou_game_2019} --- and yet, it remains broadly unanswered.

One reason for the lack of progress has been the historical focus on Nash equilibria as the outcome of a game~\cite{myerson1997game}. Over time this approach was found to be problematic \cite{kleinberg_beyond_2011} --- not only do standard learning algorithms not converge to Nash equilibria in general games \cite{benaim_perturbations_2012,milionis_impossibility_2023}, but Nash equilibria are also intractable to compute~\cite{daskalakis_complexity_2009}.  Non-convergence to Nash equilibria has been traditionally viewed as a limitation of game dynamics. In a departure, Papadimitriou and Piliouras \cite{papadimitriou_game_2019} argued the opposite: non-convergence of learning to Nash equilibria could instead be viewed as yet another limitation of the Nash equilibrium concept. Instead, the outcomes of learning --- whatever they may be --- should be the fundamental object of interest in game theory.

Of course, determining the limit behavior of dynamics in games is a very difficult problem. Even the \emph{replicator dynamic} \cite{taylor_evolutionary_1978,smith1973logic} --- the continuous-time analog of the multiplicative weights algorithm \cite{arora2012multiplicative} and the flagship dynamic of evolutionary game theory \cite{hofbauer_evolutionary_2003,sandholm2010population} --- can have extremely complex long-run behaviors \cite{sato_chaos_2002}. The problem is further complicated by the emergence of chaos and the sensitive dependence on initial conditions. However, Papadimitriou and Piliouras \cite{papadimitriou_game_2019} suggested a possible path forward; they hypothesized that the behavior of the replicator (and possibly of dynamics in general) can be well-approximated by a simple combinatorial tool, called the \emph{preference graph} of a game \cite{biggar_preference_2025}.
\begin{figure}
    \centering
    \includestandalone{figs/shapley_square}
    \caption{The preference graph of \emph{Shapley's game} \cite{shapley_topics_1964}. It has a unique sink equilibrium, which is the highlighted 6-cycle.}
    \label{fig:shapley}
\end{figure}

The preference graph is a graphical representation of the underlying structure of the preferences in a normal-form game \cite{biggar_graph_2023} (see Figure~\ref{fig:shapley}). While it has only recently become the subject of study in its own right, it plays an implicit role in many of milestone results across the history of game theory \cite{biggar_preference_2025}. By definition, pure Nash equilibria (PNEs) are sinks in the preference graph. This observation tempts one to generalize PNEs in a direction different from the one that Nash pursued, namely to consider the \emph{sink equilibria}, the sink strongly connected components of the preference graph, as a novel solution concept, and indeed one that is not incompatible with learning dynamics. Papadimitriou and Piliouras \cite{papadimitriou_game_2019} proposed a dramatic hypothesis: the sink equilibria are good proxies for the attractors of the replicator. We call this the {\em attractor--sink equilibrium correspondence} hypothesis.

If true, this hypothesis would be extremely useful for analyzing the outcome of games. Sink equilibria are a simple and easily-computable object which is robust to small changes in the payoff structure of the game. This would finally open a path to predicting strategic interactions between realistic learning agents. On the other hand, finding nontrivial mathematical connections between attractors and sink equilibria is difficult. The first significant progress on this hypothesis appeared in \cite{biggar_replicator_2023}, where it was proved that every attractor of the replicator must contain a sink equilibrium, proving sinks are indeed a sort of `skeleton' for the attractors of the replicator. They strengthened the attractor-sink equilibrium hypothesis to a conjecture:
\begin{conj} \label{conj: content conjecture}
    The attractors of the replicator in any game are in one-to-one correspondence with the sink equilibria.
\end{conj}

They also proposed a yet stronger form of the conjecture:
\begin{conj} \label{conj: strong content conjecture}
    The attractors of the replicator in any game are are exactly the \emph{content} (see Definition~\ref{def: content}) of the sink equilibria.
\end{conj}
These conjectures are known to be true in some special cases of sink equilibria \cite{biggar_replicator_2023}, including PNEs and attracting subgames (those where the sink equilibrium profiles are a subgame of the game). Some games, such as ordinal potential games \cite{monderer_potential_1996} and weakly acyclic games \cite{young_evolution_1993} have only PNEs as sink equilibria, so all these games satisfy the conjecture. It was subsequently proved that the stronger Conjecture~\ref{conj: strong content conjecture} also holds for the sink equilibria of zero-sum games \cite{biggar_attractor_2024}.

\subsection*{Our contributions} We investigate the attractor-sink equilibrium hypothesis and make significant progress towards a more general understanding of the outcomes of learning in games. First, in Section~\ref{sec: counterexamples} we show through a topological argument and construction that both Conjecture~\ref{conj: content conjecture} and Conjecture ~\ref{conj: strong content conjecture} \emph{fail} in general games, and in fact even in two-player games.

Next, we use insights from these counterexamples to attack the problem of characterizing the attractors {\em in two-player games.} In a two-player game, the only reason why a sink equilibrium may not be an attractor is that it can have a \emph{weak local source} (Definition~\ref{def: weak source}), a simple local pattern of the preference graph that lies at the roots of our counterexamples. In fact, we establish here that any sink equilibrium devoid of weak local sources is an attractor. This theorem generalizes all previously known sufficient conditions for a sink equilibrium to be an attractor, and holds much promise to eventually lead to a full characterization of the attractors of the replicator dynamic for two-player games.

The attractor--sink equilibrium hypothesis should apply to many learning algorithms, not only the replicator. Little is currently known in this direction, with a major obstacle being that Theorem~5.2 of \cite{biggar_replicator_2023} --- our tool for bounding attractors using sink equilibria --- does not generalize to all no-regret dynamics. In Section~\ref{sec: FP} we examine \emph{fictitious play} (FP) \cite{brown1949some}, an equally well-studied learning algorithm for games. We prove that, unlike the replicator dynamic, attractors of FP may be strict subsets of sink equilibria or even disjoint from them. However, we prove two results which suggest that, despite everything, there remain fundamental connections between FP and the structure of the preference graph: (1) every sink equilibrium \emph{contains} an FP  attractor (as we call the analog of the attractor in Section~\ref{sec: FP} on FP), and (2) every FP attractor corresponds to a \emph{strongly connected} subgraph of the preference graph. We argue that a joint understanding of the replicator and FP provides a new path to understanding the limit behavior of both. Overall we find that while the attractor--sink equilibrium hypothesis fails in general, a broad correspondence between attractors and the \emph{preference graph} does seem to hold, and this insight opens many new paths to understanding learning in games. 

We conclude with a discussion of open problems inspired by our work (Section~\ref{sec: conclusions}).

\subsection*{Related work} \label{sec: related}

Learning in games has a long and complex history \cite{cesa2006prediction}. In this paper we focus on fictitious play (FP) and the replicator dynamic. The study of FP began with the work of \cite{brown1949some,robinson_iterative_1951}, who showed that in zero-sum games, the empirical distribution of strategies converges to the Nash equilibrium. Further results suggested that the long-run outcomes of FP would always be Nash equilibria; FP also converges to NEs in congestion games \cite{rosenthal_class_1973}, ordinal potential games \cite{berger_two_2007,monderer_potential_1996} and $2\times n$ games \cite{berger_fictitious_2005}. However, Shapley \cite{shapley_topics_1964} demonstrated that FP does not converge to NEs in general. Despite significant further work \cite{gaunersdorfer_fictitious_1995,hofbauer_time_2009,benaim_learning_2009,benaim_perturbations_2012,viossat_no-regret_2013}, the attractors of FP remain unknown in general. Recently, however, the behavior of FP was shown to have a close relationship to the preference graph, with many classical facts being a result of graph structure \cite{biggar_preference_2025}. We explore these ideas further in Section~\ref{sec: FP}.

The replicator dynamic arose from the work of Maynard Smith on evolutionary game theory \cite{smith1973logic}, being named and formalized in \cite{taylor_evolutionary_1978}. Since then, it has retained its central role in evolutionary game theory \cite{sandholm2010population,hofbauer_evolutionary_2003} as well as online learning, where it is the continuous-time analogue of the multiplicative weight method \cite{arora_multiplicative_2012}. Finding its attractors is a central goal of the study of the replicator, both in evolutionary game theory \cite{zeeman_population_1980,sandholm2010population} and more recently in learning \cite{papadimitriou2016nash,papadimitriou_nash_2018}. Since the work of Papadimitriou and Piliouras \cite{papadimitriou_game_2019}, a line of research has developed relating the replicator and the sink equilibria. \cite{omidshafiei_-rank_2019} used the sink equilibria as an approximation of the outcome of games for the purpose of ranking the strength of game-playing algorithms. Similarly, \cite{omidshafiei_navigating_2020} used the preference graph as a tool for representing the space of games for the purposes of learning. Later, Biggar and Shames wrote a series of papers on the preference graph and its relationship to the attractors of the replicator dynamic \cite{biggar_graph_2023,biggar_replicator_2023,biggar_attractor_2024}. Another recent work \cite{hakim2024swim} explored the problem of computing the limit distributions over sink equilibria, given some prior over strategies. Our work extends the frontier of this line of investigation.

\subsection*{Preliminaries} \label{sec: prelims}

We study normal-form games with a finite number $N$ of players and finitely many strategies $S_1,S_2,\dots,S_N$ for each player \cite{myerson1997game}. The payoffs in the game are defined by a utility function $u : \prod_{i=1}^{N}S_i \to \real^N$. We call a game with $|S_1|= m_1, |S_2| = m_2, \dots, |S_N| = m_N$ an $m_1\times m_2 \times \dots \times m_N$ game. For simplicity, we define $Z := \prod_{i=1}^{N}S_i$ as the set \emph{strategy profiles} (an $N$-tuple consisting of a strategy for each player). We use $p_{-i}$ to denote an assignment of strategies to all players other than $i$. %, and we denote the set of all $i$-antiprofiles by $\bar Z_{-i}$. 
This allows us to write a strategy profile $p$ as a combination of a strategy $s\in S_i$ for player $i$ and the remaining strategies $p_{-i}$, which we denote by $(s ; p_{-i})$. A \emph{subgame} is the game resulting from restricting each player to a subset of their strategies.

A \emph{mixed strategy} is a distribution over a player's pure strategies, and a \emph{mixed profile} is an assignment of a mixed strategy to each player. We also refer to strategies as \emph{pure strategies} and profiles as \emph{pure profiles} to distinguish them the mixed cases. For a mixed profile $x$, we write $x^i$ for the distribution over player $i$'s strategies, and $x^i_s$ for the $s$-entry of player $i$'s distribution, where $s\in S_i$. The \emph{strategy space} of the game is the set of mixed profiles, which is given by $\prod_{i=1}^N \Delta_{|S_i|}$ where $\Delta_{|S_i|}$ are the simplices in $\real^{|S_i|}$. We denote $\prod_{i=1}^N \Delta_{|S_i|}$ by $X$. This is the mixed analogue of $Z$.

Any mixed profile $x$ defines a product distribution over profiles, which we denote by 
\begin{equation} \label{product}
    z = x^1 \otimes x^2 \otimes \dots \otimes z^N.
\end{equation} That is, if $p = (s_1,s_2,\dots,s_N)$ is a strategy profile, and $x$ is a mixed strategy, then $z_p = x^1_{s_1}x^2_{s_2}\dots x^N_{s_N}$ is the $p$-entry of the distribution $z$.

The utility function can be naturally extended to mixed profiles, by taking the expectation over strategies. We denote this by $\exptu : X \to \real^N$, defined by
\begin{equation} \label{def: expected utility}
\exptu_i(x) = \sum_{s_1\in S_1} \sum_{s_2\in S_2} 
    \dots\sum_{s_N\in S_N} \left(\prod_{j = 1}^N x^j_{s_j}\right) u_i(s_1,s_2,\dots,s_N)
\end{equation}

A \emph{Nash equilibrium} of a game is a mixed profile $x$ where no player can increase their expected payoff by a unilateral deviation of strategy. More precisely, a Nash equilibrium is a point where for each player $i$ and strategy $s\in S_i$,
\begin{equation} \label{def: nash equilibrium}
\exptu_i(x) \geq \exptu_i(s;x_{-i})
\end{equation}
A Nash equilibrium is \emph{pure} (a PNE) if $x$ is a pure profile.

Much of this paper concerns two-player games. In this context we often use much simper notation. We define an $n\times m$ game by a pair of $n\times m$ matrices $(A,B)$ where $A_{i,j}$ defines the payoff to the first player in the profile $(i,j)$. We use $x$ and $y$ to denote mixed strategies for the first and second player respectively, so their expected payoffs are $Ay$ and $x^T B$ respectively.

The \emph{replicator dynamic} is a continuous-time dynamical system~\cite{sandholm2010population,hofbauer2003evolutionary} defined as the solution of the following ordinary differential equation.  
\[
\dot x_s^i = x_s^i\left(\exptu_i(s; x_{-i}) - \sum_{r\in S_i} x_r^i \exptu_i(r; x_{-i}) \right)
,\]
where $x$ is a mixed profile, $i$ a player and $s$ a strategy.  It is known to be the limit of the multiplicative weights update algorithm \cite{arora_multiplicative_2012} when the time step goes to zero.

A central notion in dynamical systems is the concept of an attractor \cite{strogatz2018nonlinear}. First, fix a dynamic. An \emph{attracting set} under that dynamic is a set $S$ of points with these two properties: (1) there is a neighborhood $N\supset S, N\neq S$ that is closed under the dynamic (if the dynamic starts in $N$ it will stay there), and all points of $N$ converge to $S$ under the dynamic. An attracting set is an \emph{attractor} if it is minimal, that is, no proper subset of it is attracting.

{\em Fictitious play (FP)} is a simple algorithm for learning in games, and the historically first learning dynamic \cite{brown1949some}. In its simplest (two-player, discrete-time) form, FP is the following procedure: at each time step, each player plays a strategy which is a pure best response to the empirical distribution of the other player. In this paper we study FP in its two-player, continuous-time form, following \cite{berger_two_2007}, as this allows us to discuss the attractors of this dynamic as well. 

\begin{defn}[Two-player continuous-time fictitious play \cite{berger_two_2007}] \label{def: FP}
    Let $(A,B)$ be a two-player game. A \emph{fictitious play path} is a map $\real_+ \to S_1\times S_2$, $t\mapsto (x(t),y(t))$ whose points of discontinuity have no finite accumulation point in $\real$, such that $x(t) \in \arg\max(Av)$ and $y(t) \in \arg\max(Bu)$ where $(u,v) = \frac{1}{t}\int_0^t (x(s),y(s)) \mathrm{d}s$.
\end{defn}
That is, a FP path is a piecewise constant function dictating which strategy each player selects at a given point in time. Each player 
has a cumulative score vector $u$ and $v$ which records the empirical distribution of the strategies selected by the other player. Given this score vector, each player selects a strategy which is a best-response to this distribution. A different way to conceptualize this path is that in each interval $t\in (\tau_0,\tau_1)$ where both players play fixed pure strategies $(s,r)\in S_1\times S_2$, each strategy accrues payoff at a rate given by $A\mathbf{e}_r$ and $B\mathbf{e}_s$ respectively, where $\mathbf{e}_i$ represents the $i$-th standard basis vector. A player changes their strategy when the accrued payoff of a given strategy overtakes the currently-selected one.

\subsubsection*{Preference graphs} \label{sec: preference graphs}

The \emph{preference graph} of a game \cite{biggar_preference_2025} is a directed graph %\cite{diestel2016graph} 
whose nodes are the profiles of the game. Two profiles are $i$-\emph{comparable} if they differ in the strategy of player $i$ only, and they are \emph{comparable} if they are $i$-comparable for some $i$. There is an arc between two profiles if they are comparable, and the arc is directed towards the profile where that player receives higher payoff.

The arcs in the preference graph can be given non-negative weights, in a canonical way \cite{biggar_graph_2023,biggar_preference_2025}, which gives us the \emph{weighted preference graph}. Specifically, if $p$ and $q$ are $i$-comparable, then the arc $\arc{p}{q}$ is weighted by $u_i(q) - u_i(p) \geq 0$. We define 
\begin{equation} \label{eq: W}
    W_{q,p} := u_i(q) - u_i(p)
\end{equation} and we depict a weighted arc by $\arc[W_{q,p}]{p}{q}$ \cite{biggar_attractor_2024}.

Finally, the  {\em sink  equilibria} of a game are the sink strongly connected components of the preference graph of the game.

\section{Refuting the Conjectures} \label{sec: counterexamples}

As we discussed in the introduction, the attractor--sink equilibrium hypothesis originates in \cite{papadimitriou_game_2019} who proposed the sink equilibria as a proxy for attractors. From a technical perspective, the first connection between these concepts was shown in \cite{biggar_replicator_2023} who proved that every attractor of the replicator dynamic contains the \emph{content} of some sink equilibrium. This is our starting point for this paper.

\begin{defn}[\cite{biggar_replicator_2023}] \label{def: content} Let $H$ be a set of profiles in a game. The \emph{content} of $H$, denoted $\content(H)$, is the set of all mixed profiles $x$ where all profiles in the support of $z := \bigotimes_i x^i$ (Eq.~\eqref{product}) are in $H$.\end{defn}

In particular, this implies that the attractors of the replicator dynamic are finite in number (this was not known before). Moreover, this result is not too specific to the replicator. In fact, it applies to any of the class of FTRL dynamics which obey the \emph{subgame-independence} property. 
\begin{defn}[Subgame-independence]
    Let $x$ be a mixed profile, and $f(x)$ a game dynamic that is a function of $x$. The dynamic $f$ is \emph{subgame-independent} if (1) strategies at probability zero remain so for all time and (2) $f$ is a function of only the strategies played with positive probability.
\end{defn}

The first criterion states that we do not leave any subgame we enter. The second criterion asserts that $f$ is unaffected by the payoffs of unplayed strategies, since they will never again by played. Both of these properties are satisfied by the replicator \cite{sandholm2010population,biggar_replicator_2023}, and they are also satisfied by a more general class of dynamics called \emph{steep FTRL} \cite{vlatakis-gkaragkounis_no-regret_2020}.
Minimal adaptation of Theorem~5.2 of \cite{biggar_replicator_2023} establishes the following\footnote{This statement is not present in \cite{biggar_replicator_2023}, but the authors point out that it is true and requires only minor changes to their proof.}:
\begin{thm}\label{ftrl and sinks}
    If $f$ is a subgame-independent FTRL dynamic, then every attractor contains the content of a sink equilibrium.
\end{thm}

This theorem establishes sink equilibria as an easily-computable tool for reasoning about attractors of the replicator. However, Conjecture~\ref{conj: strong content conjecture} goes further, stating that the content of the sink equilibrium characterizes the attractors exactly.
In the next subsection we provide the first refutation of this conjecture in general games by constructing a game with where the content of the sink equilibrium is not an attractor. We also refute Conjecture~\ref{conj: content conjecture}, the more general the `one-to-one' form of the conjecture.

Our counterexamples make use of a common building block, \emph{local sources}, which will also form the basis of Theorem~\ref{weak source stability}. As a concrete example, we will consider the game in Figure~\ref{fig:cog game}.
\begin{figure}
    \centering
    \includestandalone{figs/coggame}
    \caption{A preference graph with a local source. The point $\hat x$ is a Nash equilibrium of the $2\times 2$ subgame in the top left. The presence of the local source at $a$ implies that any attractor containing $a$ contains $\hat x$.}
    \label{fig:cog game}
\end{figure}

\begin{defn} \label{def:corner}
	Let $\{\alpha,\beta\}\times \{\gamma,\delta\}$ be a $2\times 2$ subgame of the game. If \emph{exactly three} of the profiles in this subgame are contained in a sink equilibrium $K$, we call this subgame a \emph{corner} of $K$.
\end{defn}
\begin{figure}
    \centering
    \begin{subfigure}{.25\textwidth}
        \centering
        \includestandalone{figs/corner}
        \caption{}
        \label{fig:corner 1}
    \end{subfigure}
    \quad 
    \begin{subfigure}{.25\textwidth}
        \centering
        \includestandalone{figs/corner2}
        \caption{}
        \label{fig:corner 2}
    \end{subfigure}
    \quad 
    \begin{subfigure}{.25\textwidth}
        \centering
        \includestandalone{figs/corner3}
        \caption{}
        \label{fig:corner 3}
    \end{subfigure}
    \caption{A \emph{corner} (Def.~\ref{def:corner}) of a sink equilibrium $K$, where $x\not\in K$ and $w,y,z\in K$. Because $x\not\in K$, the arcs at $x$ are necessarily directed towards $y$ and $z$ respectively. Up to symmetry, there are three cases, shown in Figs.~\ref{fig:corner 1},~\ref{fig:corner 2} and~\ref{fig:corner 3}.}
    \label{fig:corners}
\end{figure}

Figure~\ref{fig:corners} shows the three possible graphs of the corner of a sink equilibrium $K$, where in each case $x$ is outside the sink equilibrium and where $a$ and $b$ are the weights on the associated edges. 
Type \ref{fig:corner 3} demonstrates a problem: {\em despite being inside the sink equilibrium, $w$ is locally (in one $2\times 2$ subgame) a source}. We call this a \emph{local source} of $K$ (Def.~\ref{def: weak source}). Sink equilibria can have such corners, for instance in the top left subgame of Figure~\ref{fig:cog game}. It turns out (though it is less obvious) that type~\ref{fig:corner 1} can (indirectly) lead to the same effect when $a > b$, in which case we call it a \emph{weak local source}. Weak local sources will be the topic of Theorem~\ref{weak source stability}, while in this section local sources are sufficient to demonstrate counterexamples.

\begin{defn}[Local sources of sink equilibria] \label{def: weak source}
    Let $w = (\alpha,\beta)$ be a profile in a sink equilibrium $K$\footnote{This definition assumes we are working in a two-player game. Generalizing to more players is straightforward, but we formalize the two-player case as it is the setting for Theorem~\ref{weak source stability}.}, and $x = (\gamma,\delta)$ be another profile outside $K$ such that the subgame $\{\alpha,\gamma\}\times\{\beta,\delta\}$ is a corner of $K$. We say that $w$ is \emph{local source} of $K$ if there are arcs $\arc{w}{(\alpha,\delta)}$ and $\arc{w}{(\gamma,\beta)}$ \emph{i.e.} $W_{(\gamma,\beta),(\alpha,\beta)} > 0$ and $W_{(\alpha,\delta),(\alpha, \beta)} > 0$ (recall Eq.~\ref{eq: W}). We call $w$ a \emph{weak local source} of $K$ if $W_{(\gamma,\beta),(\alpha,\beta)} + W_{(\alpha,\delta),(\alpha, \beta)} > 0$.
\end{defn}
Using the language of Figure~\ref{fig:corners}, $w$ is a local source if the corner is type \ref{fig:corner 3}, and it is a weak local source if either it is a local source or the corner is type \ref{fig:corner 1} \emph{and} $a>b$. That is, in this subgame, the \emph{net} gain from deviations from $w$ is positive.

Sink equilibria which are subgames have no local sources, as they have no corners at all. It is straightforward to show that sink equilibria in zero-sum games have no local sources \cite{biggar_graph_2023}. It is also true --- though less obvious --- that sink equilibria in zero-sum games also have no \emph{weak} local sources.
\begin{lem}\cite{biggar_attractor_2024}
    The sink equilibria of zero-sum games have no weak local sources.
\end{lem}\begin{proof}
     Let $w = (\alpha,\beta)$ be a profile in a sink equilibrium $K$, and $x = (\gamma,\delta)$ be another profile outside $K$ such that the subgame $\{\alpha,\gamma\}\times\{\beta,\delta\}$ is a corner of $K$. Because $x\not\in H$, there are arcs $\arc{(\gamma,\delta)}{(\gamma,\beta)}$ and $\arc{(\gamma,\delta)}{(\alpha, \delta)}$ and so $W_{(\gamma,\beta),(\gamma,\delta)} > 0$ and $W_{(\alpha, \delta),(\gamma,\delta)} > 0$. Lemma~4.7 of \cite{biggar_attractor_2024} establishes that $W_{(\gamma,\beta),(\gamma,\delta)}  + W_{(\alpha, \delta),(\gamma,\delta)} =  -(W_{(\gamma,\beta),(\alpha, \beta)} + W_{(\alpha,\delta),(\alpha, \beta)})$, so $W_{(\gamma,\beta),(\alpha,\beta)} + W_{(\alpha,\delta),(\alpha, \beta)} < 0$, thus this is not a weak local source.
\end{proof}
Thus, the known cases of sink equilibrium stability do not contain weak local sources. In the next section we prove that when sink equilibria have no weak local sources, then their content is \emph{always} an attractor.

Armed with the definition of a local source, we return to Conjecture~\ref{conj: strong content conjecture}. In Figure~\ref{fig:cog game}, the node $a$ is a local source of the top left corner subgame. The game is a $2\times 2$ coordination game, where we know a trajectory exists from each source (in this case $a$) to the Nash equilibrium in the interior of this subgame ($\hat x$) \cite{papadimitriou2016nash}. However $\hat x$ is not in the content of the sink equilibrium. The existence of this trajectory implies that the any attracting set containing $a$ must also contain $\hat x$, contradicting Conjecture~\ref{conj: strong content conjecture}.


Refuting Conjecture~\ref{conj: content conjecture} is more difficult. We will first demonstrate it in game with at least three players; the two-player case is more subtle, and we defer it to Section~\ref{sec: 2p counter}.

\subsection{Games with three players} \label{sec: 3p counter}

\begin{figure}
    \centering
    \begin{subfigure}{.4\textwidth}
        \centering
        \includestandalone{figs/3player_counter}
        \caption{}
        \label{fig:big_3player}
    \end{subfigure}
    \quad
    \begin{subfigure}{.4\textwidth}
        \centering
        \includestandalone{figs/3player_counter_small}
        \caption{}
        \label{fig:small_3player}
    \end{subfigure}
    \caption{A 3-player counterexample. We show that a replicator trajectory exists from $a$ to $\hat x$ (a fully-mixed Nash equilibrium of the subgame in \ref{fig:small_3player}) and also from $\hat x$ to $b$, implying that any attractor containing $a$ must also contain $b$.}
    \label{fig:3player counterexample}
\end{figure}

Consider a game which possessing the preference graph in Figure~\ref{fig:big_3player}. This game has three players with 3, 3 and 2 strategies respectively. Its preference graph has two sink equilibria $H_a$ and $H_b$, which we have each highlighted in gray. We have named two nodes $a$ and $b$, the former in $H_a$ and the latter in $H_b$. The critical features of the example lie in one $2\times2\times 2$ subgame, which we isolate in Figure~\ref{fig:small_3player}. The remainder of the graph serves to ensure that $H_a$ is a sink equilibrium of the game.

In this subgame, node $a$ is a source and node $b$ is a sink. This is exactly the $2\times 2\times 2$ generalization of a local source: $a$ is part of a sink equilibrium yet locally (in this subgame) it is a source. Because $b$ is in a different sink equilibrium to $a$, there are necessarily no paths from $a$ to $b$ in this subgraph. However, it is not possible for an attractor to contain $a$ and not $b$.
\begin{lem}
    In Figure~\ref{fig:3player counterexample}, any attracting set of the replicator containing $a$ must contain $b$.
\end{lem}
\begin{proof}
    We will focus on the $2\times 2\times 2$ subgame in Figure~\ref{fig:small_3player} (recall that the replicator is subgame-independent), and we assume the weight on every arc in this subgame is one. Each player has exactly two strategies in this subgame, and we will change make a change of variables to represent these by a single variable each. From here, $x_1,x_2,x_3$ represent the proportion that each player plays one of their strategies, such that $a=(0,0,0)$ and $b=(1,1,1)$. This subgame also contains a Nash equilibrium at $\hat x = (0.5,0.5,0.5)$, which is the only fixed point of the replicator in the interior of this subgame. 

    Because of the unit payoffs, a simple expansion of the replicator equation on this subgame gives us:
    \[
    \dot x_1 = x_1(1-x_1)\left ((1-x_2)(1-x_3) - x_2(1-x_3) - (1-x_2)x_3 + x_2x_3\right )
    \]
    The equations for $\dot x_2$ and $\dot x_3$ follow by symmetry. Consider the one-dimensional diagonal subspace which contains $a$, $b$ and $\hat x$. This is defined by $x_1=x_2=x_3$. Because of symmetry, this subspace is closed---if we start in this subspace, we remain there. Hence, on this subspace we can express the behavior of the replicator by a one-dimensional dynamical system. Defining $w = x_1=x_2=x_3$ gives
    \[
    \dot w = w(1-w)\left ((1-w)^2 - w(1-w) - (1-w)w + w^2\right )
    \]
    This factorizes to:
    \[
    \dot w = w(1-w)(2w-1)^2
    \]
    This is always non-negative, with fixed points at 0 ($a$), $0.5$ ($\hat x$) and 1 ($b$). Thus there is a trajectory from any neighborhood of $a$ to $\hat x$, and similarly there is a trajectory from any neighborhood of $\hat x$ to $b$. Any attracting set containing $a$ must also contain $\hat x$, and hence also $b$.
\end{proof}

\subsection{Games with two players} \label{sec: 2p counter}

The previous technique does not work in two-player games. The reason is that every two-player game containing a source and a sink necessarily has a path in the preference graph from the source to the sink. In the example above, our construction used a subgame (Figure~\ref{fig:small_3player}) containing both a source ($a$) and sink ($b$) but with no path between them.

It turns out that the conjecture still fails in two-player games, though the argument is more subtle. We will use the graph in Figure~\ref{fig:2player counterexample}.
\begin{figure}
    \centering
    \begin{subfigure}{.4\textwidth}
        \centering
        \includestandalone{figs/2player_counter}
        \caption{}
        \label{fig:2player big}
    \end{subfigure}
    \quad
    \begin{subfigure}{.4\textwidth}
        \centering
        \includestandalone{figs/2player_small}
        \caption{}
        \label{fig:2player small}
    \end{subfigure}
    \caption{A two-player counterexample. We show that replicator trajectories exist from $a$ to $\hat x$ to $\hat y$ to $c$ to $b$, meaning that $b$ must be in any attractor containing $a$, despite it being in a different sink equilibrium.}
    \label{fig:2player counterexample}
\end{figure}
Like before, we have a game containing two nodes $a$ and $b$, where there are no paths from $a$ to $b$ in the graph. The node $a$ is contained in a sink equilibrium $H_a$ and $b$ is contained in a different sink equilibrium $H_b$. We have highlighted these in gray. For clarity we have omitted some arcs from the graph, where they are implied by the fact that $H_a$ and $H_b$ are sink equilibria.

Despite the apparent complexity, the key step can be reduced to a much smaller subgame, shown in Figure~\ref{fig:2player small}. The points $\hat x$, $\hat y$ and $\hat z$ are fixed points of the replicator dynamic in $2\times 2$ subgames---that is they are Nash equilibria in their respective subgame. By the same argument we used to disprove Conjecture~\ref{conj: strong content conjecture}, we know that there is a trajectory from $a$ to $\hat x$. We will show that, for some choices of arc weights, there is also a trajectory from $\hat x$ to $\hat y$. Repeating this argument will give another trajectory from $\hat y$ to $\hat z$, and hence to $c$ and finally $b$.

Let the arcs in Figure~\ref{fig:2player small} be weighted such that $\hat y$ is a Nash equilibrium (this implies that $\hat x$ is not a Nash equilibrium in this subgame).
\begin{lem}
    In Figure~\ref{fig:2player small} with $\hat y$ a Nash equilibrium of this subgame, there is a trajectory of the replicator dynamic from $\hat x$ to $\hat y$.
\end{lem}
\begin{proof}
The game is $2\times 3$, so the strategy space is three-dimensional, and homeomorphic to the ball in three dimensions. This game has two PNEs, which we call $p$ and $q$, both of which are attractors of the replicator. Further, because every attractor must contain a sink equilibrium \cite{biggar_replicator_2023}, these must be the only attractors.

Some points in the game have limit set $p$ and others have limit set $q$. By continuity of the replicator flow, the sets of points whose limits are $p$ and $q$ respectively must be open sets. In particular, there is a closed set $\beta$ of points whose limit sets are neither $p$ nor $q$. Because $\hat x$ and $\hat y$ both have points in every neighborhood which converge to $p$ and $q$, both $\hat x$ and $\hat y$ must be in $\beta$. Similarly, the two source nodes are also in $\beta$, by the same argument.

By Proposition~5.1 of \cite{hofbauer_time_2009}, the limit set of an interior point within $\beta$ must be a closed set which is invariant under the best-response dynamics. No such sets exist in the interior of a generic $2\times 3$ game, and all limit points of such a point must be on the intersection of $\beta$ and the boundary of the strategy space.

This intersection is a well-behaved set --- it is homeomorphic to the circle, and consists of the sources, the points $\hat x$ and $\hat y$ and the trajectories joining them. All points which approach this boundary in the limit must converge to one of these fixed points, but only $\hat y$ is a Nash equilibrium, so this is the only possible limit. Finally, observe that every neighborhood of $\hat x$ contains a point in $\beta$ which is in the interior of the strategy space, and so whose limit must be $\hat y$. We conclude that any attracting set containing $\hat x$ must also contain $\hat y$.
\end{proof}

\section{Sink equilibria without weak local sources are attractors} \label{sec: sink stability}

Our understanding of stability under the replicator dynamic is becoming clearer. When the sink equilibrium has a very simple structure, such as a subgame, its content is an attractor. PNEs are a special case of this. These sinks have no corners, and hence no local sources. Sink equilibria of zero-sum games can have non-trivial structure, but they never have weak local sources  \cite{biggar_graph_2023}, so again their content is an attractor \cite{biggar_attractor_2024}. On the other hand, the counterexamples above demonstrate that the presence of local sources can cause sink equilibria to not exactly define attractors. It is natural to therefore conjecture that (weak) local sources are \emph{necessary} for the content to not be an attractor. This turns out to be true for two-player games, as we now show (Theorem~\ref{weak source stability}).
To prove this we will need some novel formalisms and lemmas.



\begin{defn}[Product matrix]
    Let $u$ be a $m_1\times m_2 \times \dots\times m_N$ game. The \emph{product matrix} of $u$ is the following matrix $M\in \real^{(\prod_i m_i)\times (\prod_i m_i)}$, indexed by profiles $p$ and $q$ in $Z$:
\[
M_{q,p} = \sum_{i=1}^N \left ( u_i(q_i;p) - u_i(p) \right ) = \sum_{i=1}^N W_{(q_i;p_{-i}),p}
\]
\end{defn}
Note that when $p$ and $q$ are $i$-comparable, $M_{q,p} = u_i(q) - u_i(p) = W_{q,p}$. The product matrix allows for a significantly simpler presentation of the replicator equation in the product space of the game (Lemma~\ref{product replicator}). This idea comes from \cite{biggar_attractor_2024}, who introduced this construction in two-player zero-sum games. Here we generalize it to $n$-player games. While straightforward, this transformation is critical for our results and we believe it is a useful fact for analyzing the replicator in other contexts as well.
\begin{lem} \label{product replicator}
Let $u$ be a $N$-player game, $M$ the product matrix of $u$ and $p = (s_1,s_2,\dots,s_N)$ a profile. With $z_p := \prod_{i=1}^N x^i_{s_i}$ (Eq.~\eqref{product}), then under the replicator dynamic:
\[ \dot z_p = z_p (M z)_p \]
\end{lem}
\begin{proof}
By Lemma~A.1 of \cite{biggar_replicator_2023}, the replicator equation can be written
\begin{align*}
    \dot x^i_s &= x_s^i\sum_{r\in S_i} x_r^i \sum_{p_{-i} \in Z_{-i}} z_{p_{-i}} \left (u_i(s;p_{-i}) - u_i(r;p_{-i}) \right ) \\
    &= x_s^i\sum_{p_{-i} \in Z_{-i}} \sum_{r\in S_i} x_r^iz_{p_{-i}}\left (u_i(s;p_{-i}) - u_i(r;p_{-i}) \right ) \\
    &= x_s^i\sum_{p_{-i} \in Z_{-i}} \sum_{r\in S_i} z_{(r;p_{-i})} \left (u_i(s;p_{-i}) - u_i(r;p_{-i}) \right ) \\
    &= x_s^i\sum_{p\in Z} z_p \left (u_i(s;p_{-i}) - u_i(p) \right)
\end{align*}

Now we observe that for $q = (q_1,q_2,\dots,q_N)$,
\begin{align*}
    \dot x_q &= \ddt (\prod_{i=1}^N x^i_{q_i})
    = z_q \sum_{i=1}^N \frac{\dot x^i_{q_i}}{x^i_{q_i}} \quad \text{(product rule)} \\
    &= z_q \sum_{i=1}^N  \sum_{p\in Z} z_p \left (u_i(q_i;p_{-i}) - u_i(p) \right) \quad \text{(by above)}\\
    &= z_q \sum_{p\in Z} z_p \sum_{i=1}^N \left ( u_i(q_i;\bar p) - u_i(p) \right) 
    =  z_q \sum_{p\in Z} z_p M_{q,p} \\
    &=  z_q (M z)_q
\end{align*}
\end{proof}

\begin{thm}\label{weak source stability}
    If a sink equilibrium of a two-player game has no weak local sources, then its content is an attractor of the replicator.
\end{thm}
\begin{proof}
    Let $H$ be a sink equilibrium, which we assume has no weak local sources. We will show it is asymptotically stable by a Lyapunov argument, using a similar structure to Theorem~4.3 of\cite{biggar_attractor_2024}. First, we define $z_H := \sum_{h\in H} z_h$. That is, $z$ is the cumulative total distributed over the profiles in $H$ in the product distribution $z$ (Eq.~\ref{product}). Note that $z_H = 1$ if and only if $x \in \content(H)$. $z_H$ is uniformly continuous, and so to prove that $\content(H)$ is an attractor it is sufficient to show that $\dot z_H > 0$ in some neighborhood of $\content(H)$. Now fix some small $1> \epsilon > 0$. We will assume that $z_H = 1 - \epsilon$, and we will show that for small enough $\epsilon$, $\dot z_H > 0$.

    From Lemma~\ref{product replicator} we have that $\dot z_H = \sum_{h\in H} z_h(M z)_h = \sum_{p\in Z}\sum_{h\in H} z_p z_h M_{h,p}$. Each term in this sum corresponds to a pair of profiles $p$ and $h$ with $h\in H$. First, we divide this sum into comparable and non-comparable pairs of profiles:
    \[
    \dot z_H  = \sum_{p,h\in H \text{ comparable}} z_p z_h M_{h,p} + \sum_{p,h\in H \text{ not comparable}} z_p z_h M_{h,p}
    \]
    If $p$ and $h$ are comparable and $p\in H$, then the first sum contains the terms $z_pz_h M_{p,h}$ and $z_pz_h M_{h,p}$. Because they are comparable, $M_{p,h} = W_{p,h} = - W_{h,p} = - M_{h,p}$ (Definition~\ref{product}), so these terms cancel. The sum becomes
    \[
    \dot x_H  = \sum_{p\not\in H,h\in H \text{ comparable}} z_p z_h M_{h,p} + \sum_{p,h\in H \text{ not comparable}} z_p z_h M_{h,p}
    \]
    If $p$ and $h$ are comparable, and $p\not\in H$ and $h\in H$, $M_{h,p} > 0$ because the arc $\arc{p}{h}$ is necessarily directed into $h$ ($H$ is a sink component). Hence all terms in the first sum are non-negative.
    
    Now consider the case where $p$ and $h$ are non-comparable. Suppose $p = (\alpha,\beta)$ and $h= (\gamma,\delta)$ where none of these are equal, because $p$ and $h$ are not comparable. Let $a := (\alpha,\delta)$ and $b := (\gamma,\beta)$ be the other two profiles in this $2\times 2$ subgame. First observe that $z_p z_h = x_\alpha y_\beta x_\gamma y_\delta = z_a z_b$. So, for instance, if $z_pz_hM_{h,p}$ and $z_az_bM_{a,b}$ are both in the sum, we can combine them into a single term $z_pz_h(M_{h,p} + M_{a,b})$. We will now group all such terms with common $z$-coefficients. Which of these pairs actually appear in the sum depends on which of $p,a,b,h$ are in $H$. We know $h\in H$, so the remaining cases are:
    \begin{enumerate}
        \item All of $p,a,b,h$ are in $H$: The sum contains all of the terms $M_{p,h} + M_{h,p} + M_{a,b} + M_{b,a}$. Expanding this by Definition~\ref{product} gives $W_{a,p} + W_{b,p} + W_{a,h} + W_{b,h} + W_{p,b} + W_{h,b} + W_{h,a} + W_{p,a} = 0$, because each term $W_{i,j} = -W_{j,i}$. Hence if all are in $H$, these terms cancel in the sum.
        \item Three are in $H$---we assume w.l.o.g. that $p\not\in H$ and $a,b,h\in H$. Then the terms in the sum are $M_{h,p} + M_{a,b} + M_{b,a}$. By the same argument as above, $M_{h,p} + M_{a,b} + M_{b,a} = -M_{p,h}$, which is equal to $M_{p,h} = W_{a,h} + W_{b,h}$. Hence, $M_{p,h}$ is positive \emph{if and only if} $h$ is a weak local source of $H$. By assumption, there are no weak local sources, so $-W_{p,h} = M_{h,p} + M_{a,b} + M_{b,a}$ is non-negative.
        \item Two are in $H$---assume w.l.o.g. that $p,a\not\in H$ and $b,h\in H$. The sum therefore contains the terms $M_{h,p}$ and $M_{b,a}$. By Definition~\ref{product}, $M_{h,p} + M_{b,a} = W_{p,a} + W_{h,a} + W_{a,p} + W_{b,p} = W_{h,a} + W_{b,p}$. Since $b$ and $h$ are in $H$ and $q$ and $b$ are not, the arcs $\arc{a}{h}$ and $\arc{p}{b}$ must be directed into the component, so $W_{h,a} > 0$ and $W_{b,p} > 0$. Hence this term is also non-negative.
        \item Only $h$ is in $H$. This last case is the most difficult, because here the terms can be negative. Each such pair contains only the term $z_pz_h M_{h,p}$. However, note that because $a,b \not \in  H$, $z_a,z_b <\epsilon$. Hence $z_pz_h = z_az_b < \epsilon^2$. Thus all negative terms in $\dot x_H$ have coefficient at most $\epsilon^2$.
    \end{enumerate}

    We have now grouped the terms in this sum by their distinct $z$-coefficients, so each term has the form $x_\alpha y_\beta x_\gamma y_\delta(M_{i,j} + \dots)$. For simplicity, we write $K_{\alpha,\beta,\gamma,\delta} := \sum M_{i,j}$ where $z_iz_j = x_\alpha y_\beta x_\gamma y_\delta$. We now define $\mu := \min \{ K_{\alpha,\beta,\gamma,\delta}\ :\ K_{\alpha,\beta,\gamma,\delta} > 0\}$ and similarly $m := \max \{ |K_{\alpha,\beta,\gamma,\delta}|\ :\ K_{\alpha,\beta,\gamma,\delta} < 0\}$. These are the smallest and largest positive and negative terms respectively. There are at most $N^2$ terms in this sum, where $N$ is the number of profiles. By the above, each negative term has coefficient at most $\epsilon^2$, so the total sum of negative terms is at most $-mN^2\epsilon^2$. 
     Now select an $h\in H$ where $z_h \geq (1 - \epsilon)/|H|$. Since $z_H = 1-\epsilon$, such a node must exist. Then:
     \[
    \dot x_H \geq \sum_{\substack{p\not\in H \\ z_pz_h = x_\alpha y_\beta x_\gamma y_\delta \\ K_{\alpha,\beta,\gamma,\delta}>0}} z_pz_h \mu - mN^2\epsilon^2 = \mu z_h \sum_{\substack{p\not\in H\\ z_pz_h = x_\alpha y_\beta x_\gamma y_\delta\\ K_{\alpha,\beta,\gamma,\delta}>0}} z_p - mN^2\epsilon^2
    \]
    This inequality holds because we have retained the contribution from all negative terms (in the $mN^2\epsilon^2$ term), and reduced the set of positive terms. Specifically we have included terms where the coefficient equals $z_pz_h$ for our fixed $h$ and where $p\not\in H$. Now we must determine the sum $\sum z_p$ over these $p$. The total sum over $z_p$ with $p\not\in H$ is $\epsilon$, but some $z_p$ are not included in this sum, if they correspond to a negative term $z_wz_h K_{\alpha,\beta,\gamma,\delta} < 0$. However, by the argument above, this occurs only in case (4). There, the remaining profiles $a$ and $b$ are not in $H$, and so contribute two positive terms $z_az_h W_{h,a}$ and $z_bz_h W_{h,b}$ to this sum. By this argument, at least 2/3 of the terms in this sum must be positive. Also, each such $z_p$ has $z_p <\epsilon^2$. We obtain 
    \begin{align*}
        \dot z_H
        &\geq  k ((1-\epsilon)/|H|)(\epsilon - (1 - |H|)\epsilon^2/3) - mN^2\epsilon^2 \\
        &\geq k\epsilon/|H| - o(\epsilon^2)
    \end{align*}
    Thus, for small enough $\epsilon>0$, this term is strictly positive. 
\end{proof}


We believe that this result is a major step towards our ultimate goal: a polynomial-time algorithm which, given a two-player game in normal form, identifies its attractors. In the absence of weak sources, we know the attractors: they are the sink equilibria. But if a weak source exists in a sink component, one needs to determine where exactly the replicator ``escapes'' from the content of the component --- if it does at all. These `escape points' are not necessarily weak local sources, however. The power of this theorem is that the absence of weak local sources (a $2\times 2$ property) is sufficient to guarantee, non-constructively, that no such escaping trajectories exist. If weak local sources exist, the proof of the theorem does not seem to provide guidance on where to look for these trajectories. Analyzing the attractors of two-player games in the presence of weak sources is an important open research problem left by this work.

\section{Fictitious play} \label{sec: FP}


Currently, our understanding of the attractor--sink equilibrium correspondence is largely confined to the replicator dynamic and its generalizations, such as subgame-independent dynamics.
A major obstacle that prevents extensions to other dynamics is that Theorem~5.2 of \cite{biggar_replicator_2023} --- our tool for bounding attractors using sink equilibria --- does not generalize to all no-regret dynamics.
 
Fictitious play is the oldest game dynamic, originating with the work of \cite{brown1949some,robinson_iterative_1951}, and has inspired key developments through the history of game theory~\cite{shapley_topics_1964,monderer_potential_1996,young_evolution_1993,milgrom_rationalizability_1990,milgrom_adaptive_1991}. FP is extremely simple; the game is played repeatedly, and at each round each player plays a strategy that is a best-response to the opponent's \emph{empirical history of play}. We will focus on FP in the two-player continuous-time setting, where each player selects a pure strategy best-response at each point in time and accrue payoff at a rate given by the utility of that strategy profile (see Definition~\ref{def: FP}).

The convergence behavior of FP can differ significantly from that of the
replicator dynamics. For instance, FP converges to NE in all zero-sum games \cite{robinson_iterative_1951} and $2\times n$ games \cite{berger_fictitious_2005}. In both cases the Nash equilibria are a \emph{strict subset} of the sink equilibria. The replicator dynamic, by contrast, approaches the NE and orbits at a fixed distance in these games. However, despite these differences, the long-run behavior of FP also turns out to be closely connected to the preference graph and its sink equilibria \cite{biggar_preference_2025}. In this section we show how some simple graph-theoretic insights on FP paths lead to surprising new descriptions of possible limit behavior.

As in the previous sections, we are interested in understanding the limit behavior of FP using insights from the preference graph. The convergence criteria in FP is somewhat complex --- the strategy profile played at any time is pure, so we do not converge to mixed profiles in the same sense as the replicator. When examining convergence to Nash equilibria, the standard approach is to show asymptotic stability of the \emph{empirical distributions of play}. In this setting we shall define an FP attractor as a simpler, combinatorial object: we call a set $H$ of profiles a {\em FP attractor} if there exists an open set of starting points (cumulative payoffs $(u,v)$) where $H$ is the set of profiles visited infinitely often by each FP path originating in this set. If the empirical distribution of play does converge, this is its support. In what follows, we shall prove three simple results about FP attractors, illustrating that the dynamics of FP can be rather different to that of the replicator, and yet the concepts of the preference graph and sink equilibria are helpful in fathoming them. For the sake of narrative, we first state the three results without proof, and provide the proofs later.

\begin{thm} \label{sink stability under FP}
Every sink equilibrium contains at least one FP attractor.
\end{thm}

Notice that the results of Section~\ref{sec: counterexamples} showed that this fact is not true for the replicator.
Also, this result is false in three-player games, and the counterexample is exactly Figure~\ref{fig:3player counterexample}; from node $a$, if all players switch simultaneously it is possible for them to switch to node $b$.

\begin{thm} \label{strong connectedness}
An FP attractor induces a strongly connected subgraph of the preference graph.
\end{thm}

The graph in Figure~\ref{fig:shapley} illustrates the utility of this result. This graph (called the \emph{Shapley graph} \cite{biggar_preference_2025}) arises from a famous game due to Shapley \cite{shapley_topics_1964}. Its sink equilibrium is a 6-cycle. By Theorem~\ref{sink stability under FP} this sink is asymptotically stable. Because no proper subset of these profiles is strongly connected (Theorem~\ref{strong connectedness}), the sink equilibrium must be an FP attractor. In fact, no other set of profiles is strongly connected, so this must be the only attractor.

This result gives us a necessary condition for stability of any given set of profiles. If the empirical joint behavior of FP converges to such a set, then it must be strongly connected. One such example is a \emph{correlated} or \emph{coarse correlated equilibrium}. We know that the replicator and FP\footnote{While discrete-time FP is not a no-regret dynamic, the continuous form we consider here is no-regret \cite{viossat_no-regret_2013}.} converge to the set of coarse correlated equilibrium. If they converge to one in particular, what can we say about it?
\begin{thm} \label{equilibria strong connectedness}
Let $x^*$ be a (coarse) correlated equilibrium to which the joint empirical behavior of FP converges. Then the induced subgraph of the support of $x^*$ is strongly connected.
\end{thm}
In other words, strong connectedness of the support is a necessary condition for any such equilibrium to be an attractor of FP. The same is true for Nash equilibria, if we require that the joint empirical behavior converge to the Nash equilibrium in correlated space.

These three results are rather direct consequences of two lemmas, originally due to \cite{monderer_fictitious_1997} and \cite{berger_two_2007}.
\begin{defn}[\cite{berger_two_2007}]
    Let $(x(t),y(t))$ be a FP path (Definition~\ref{def: FP}). We say that $(x(t),y(t))$ \emph{switches} from a profile $(a,b)$ to $(c,d) \neq (a,b)$ at time $\tau$ if there exists $\epsilon > 0$ such that $(x(t),y(t)) = (a,b)$ for $[\tau - \epsilon, \tau)$ and $(x(t),y(t)) = (c,d)$ for $(\tau, \tau + \epsilon]$.
\end{defn}
Recall that an FP path is a piecewise constant function which selects a strategy for both players. The path \emph{switches} if it moves between two distinct profiles for a non-zero amount of time.
\begin{lem}[\cite{monderer_fictitious_1997,berger_two_2007}] \label{lem: 1st ip}
    If an FP path switches from $(a,b)$ to $(c,d)$, then $u_1(c,b) - u_1(a,b) \geq 0$ and $u_2(a,d) - u_2(a,b) \geq 0$.
\end{lem}
In preference graph terms, this means the following: if $(a,b)$ and $(c,d)$ are comparable ($a=c$ or $b=d$), then there is an arc $\arc{(a,b)}{(c,b)}$ in the preference graph. In other words, when only one player switches at once, \emph{the sequence of profiles in the FP path is a path in the preference graph}. Hence an FP path could only deviate from the preference graph when both players switch strategies simultaneously, in which case there is a pair of arcs $\arc{(a,b)}{(c,b)}$ and $\arc{(a,b)}{(a,d)}$. This property was first used to prove that FP converges to Nash equilibria in  $2\times 3$ games \cite{monderer_fictitious_1997}. Lemma~\ref{lem: 2nd ip} presents a complementary result:

\begin{lem}[\cite{berger_two_2007}] \label{lem: 2nd ip}
    If an FP path switches from $(a,b)$ to $(c,d)$, then $W_{(c,b),(c,d)} \geq 0$ and $W_{(a,d),(c,d)} \geq 0$.
\end{lem}

This bounds the possible deviations from the preference graph --- if both players deviate simultaneously then the structure must be as in Figure~\ref{fig:fp switching}. In particular, we cannot leave a strongly connected component via this mechanism, and so the possible FP paths are constrained by paths in the preference graph.
\begin{figure}
    \centering
    \includestandalone{figs/switching}
    \caption{Under FP, both players could simultaneously deviate from $(a,b)$ to $(c,d)$. However the preference graph must have this structure (Lemmas~\ref{lem: 1st ip} and \ref{lem: 2nd ip}), so the FP path cannot escape the strongly connected component.}
    \label{fig:fp switching}
\end{figure}

These lemmas establish a fundamental link between preference graphs and FP paths. They were first used by Berger \cite{berger_two_2007} to prove that FP converges to Nash equilibria in ordinal potential games \cite{monderer_potential_1996}. Ordinal potential games are exactly those whose preference graphs are acyclic \cite{biggar_graph_2023}; because FP follows paths in the graph, it must arrive at the sinks (PNEs) in finite time. We can now complete the proofs of Theorems~\ref{sink stability under FP}, \ref{strong connectedness} and \ref{equilibria strong connectedness}.

\begin{proof}[Proof of Theorem \ref{sink stability under FP}.]
Start a FP path within a strongly connected component of the preference graph.  By the two lemmas, the path cannot leave the sink equilibrium, and hence the resulting FP attractor will be a subset of the sink equilibrium. 
\end{proof}


\begin{figure}
    \centering
    \includestandalone{figs/2x3_dominance}
    \caption{A cycle in the preference graph which is an FP attractor, but which does not include the entire connected component \cite{biggar_preference_2025}.}
    \label{fig:2x3 dominance}
\end{figure}

\begin{proof}[Proof of Theorem \ref{strong connectedness}.]
Since every profile in an FP attractor must be visited infinitely often by an FP path. In this path, and for any two profiles $u, V$ of the attractor, there must be times $t_1<t_2<t_3$ such as $u$ is visited at times $t_1,t_3$ and u is visited at time $t_2$.  By induction on the number of intermediate nodes between these visits and applying the two lemmata, there must be paths in the preference graph from $u$ to $v$ and from $u$ to $v$.

However, there is one further step. If a simultaneous switches (from $(a,b)$ to $(c,d)$ with $a\neq b$ and $c\neq d$, as in Figure~\ref{fig:fp switching}) happened infinitely often, we could arrive at a scenario where the support of the FP attractor contained $(a,b)$ and $(c,d)$ but neither $(a,d)$ nor $(c,b)$, and so was not strongly connected. We show that this cannot happen generically. Given current cumulative payoff vector $u$, player 1 switches from $a$ to $c$ at time $t_1$ when $u_a + A_{a,b} t_1 = u_c + A_{c,b} t_1$. Similarly, given current cumulative payoff vector $v$, player 2 switches from $b$ to $d$ at time $t_2$ when $v_b + B_{a,b} t_2 = u_d + B_{a,d} t_2$. For both players to switch simultaneously, both equations must hold, meaning that $t_1 = t_2$. This happens on a lower-dimensional subspace. In particular, it doesn't hold for any open set of starting points.

To complete the argument, we need to show that from any open set of starting points, we do not generically switch simultaneously at any point where the FP path reaches $(a,b)$. This follows from the fact that FP is piecewise linear in the space of cumulative payoffs, and so maps open sets to open sets (see Lemma~1 of \cite{krishna_convergence_1998}).
\end{proof}
\begin{proof}[Proof of Theorem~\ref{equilibria strong connectedness}]
    This result follows from Theorem~\ref{strong connectedness}. If we converge to $\hat x$ from an open set of starting points under FP path, then the profiles in the support of $\hat x$ must be visited infinitely often by the path, with the average proportion of time spent in each node equaling its weight in the distribution $\hat x$.
\end{proof}



\section{Conclusions and open problems} \label{sec: conclusions}

Let us return to our original goal: to understand, and ultimately compute, the possible long-run outcomes of game dynamics by exploiting their relationship to sink equilibria. We have made significant progress on these questions for two important dynamics, FP and the replicator dynamic. We showed that while the preference graph has significant influence on the attractors of both dynamics, the picture is a little more complicated than exactly the sink equilibria. For the replicator dynamic, the presence of weak sources can lead to attractors that are larger than the sink equilibria, sometimes merging two or more sink equilibria. For FP, the attractors must be strongly connected subgraphs of the preference graph, but they may not be sink connected components.  However, any sink component contains an attractor.

This work opens up a number of important open problems.

\paragraph{Weak local sources and paths.} We know that the presence of local sources can lead to trajectories which escape sink equilibria. Yet local sources too possess a specific graph-theoretic structure --- we believe that a broader combinatorial framework generalizing the preference graph could incorporate this case, and thus potentially characterize the ultimate structure of the attractors of a game.  

\paragraph{Attractor cycles under FP} Some strongly connected sets of profiles can be attractors of FP, though there may be arcs in the preference graph which leave this set. When can this happen? Understanding this phenomenon is key to identifying FP attractors, beyond the sink and Nash equilibria.

\paragraph{Unifying the limit behaviors of the replicator dynamic, FP, and beyond.}  While we have studied these two dynamics somewhat separately in this paper, we believe that further work will unify our understanding of both cases, and the differences between them will become less significant. There are some good reasons for this belief. First, while attractors of FP can be strictly smaller than attractors of the replicator, the replicator \emph{also converges} to these smaller sets---it just does not do so uniformly \cite{biggar_attractor_2024,biggar_preference_2025}. This lack of uniformity follows as a consequence of subgame-independence. Figure~\ref{fig:2x3 dominance} gives a concrete example, where the replicator converges non-uniformly to a subset of the sink equilibrium, which is the FP attractor of the game. Further, there is a long line of work establishing connections between the limit behavior of FP (and its generalization, the \emph{best-response dynamics}) and the behavior of `smoothed best-response dynamics', like the replicator \cite{gaunersdorfer_fictitious_1995,benaim_learning_2009,hofbauer_time_2009,benaim_perturbations_2012,viossat_no-regret_2013}. Our hope is that a general theory will emerge which captures the limit behaviors of a very broad class of game dynamics.

\paragraph{Algorithmic problems.} The ultimate goal of this research program is a polynomial-time algorithm which, given a game in normal form, will output the combinatorial structure of its attractors, and do this for a wide range of learning dynamics. For the case of the replicator dynamic we have made reasonable progress: for two-player games, we proved a result that seems one step away from a polynomial algorithm for computing the attractors; the missing piece is determining whether a weak source in a sink equilibrium is of the escaping kind.  For three or more players, the preference graph seems inadequate, and a generalization appears to be needed.  

Beyond the replicator, we have made limited progress on FP, and a hierarchy of novel algorithmic problems remain in our path:
\begin{enumerate}
\item Given a finite FP path, determine if the induced subgraph of the preference graph defines an FP attractor. We believe that this problem may have an efficient solution.  

\item Given a strongly connected set of profiles in the preference graph, determine if they define an FP attractor. This is more difficult than the first problem, because many FP paths could result in the same set of profiles.

\item Given a preference graph, identify all FP attractors (that is, detect all subgraphs that pass the test (2) above). This looks like a formidable problem, which may even be NP-hard.
\end{enumerate}

\paragraph{Large games.}  The limit behavior of learning in {\em large} multi-player games is of great interest in economics --- however, we know that even the most modest algorithmic goals related to sink equilibria are PSPACE-complete for many succinct representations of games \cite{fabrikant2008complexity}. It would be very interesting to make progress in characterizing and computing the attractor structure of a game, for the replicator and FP, for the case of {\em symmetric} multi-player games.

\bibliographystyle{plain}
\bibliography{refs}

\end{document}