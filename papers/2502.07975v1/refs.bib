@inproceedings{kleinberg_beyond_2011,
	title = {Beyond the {Nash} {Equilibrium} {Barrier}.},
	author = {Kleinberg, Robert D and Ligett, Katrina and Piliouras, Georgios and Tardos, \'Eva},
        booktitle={ICS},
	year = {2011},
	pages = {125--140},
	file = {Kleinberg et al. - 2011 - Beyond the Nash Equilibrium Barrier..pdf:/Users/oliverbiggar/Zotero/storage/9PT947WC/Kleinberg et al. - 2011 - Beyond the Nash Equilibrium Barrier..pdf:application/pdf},
}

@article{freund_adaptive_1999,
	title = {Adaptive game playing using multiplicative weights},
	volume = {29},
	issn = {0899-8256},
	number = {1-2},
	journal = {Games and Economic Behavior},
	author = {Freund, Yoav and Schapire, Robert E},
	year = {1999},
	note = {Publisher: Elsevier},
	pages = {79--103},
	file = {Freund and Schapire - 1999 - Adaptive game playing using multiplicative weights.pdf:/Users/oliverbiggar/Zotero/storage/N36CTY43/Freund and Schapire - 1999 - Adaptive game playing using multiplicative weights.pdf:application/pdf},
}


@book{boyd2004convex,
  title={Convex optimization},
  author={Boyd, Stephen and Vandenberghe, Lieven},
  year={2004},
  publisher={Cambridge university press}
}
@article{hannan1957approximation,
  title={Approximation to Bayes risk in repeated play},
  author={Hannan, James},
  journal={Contributions to the Theory of Games},
  volume={3},
  number={2},
  pages={97--139},
  year={1957}
}

@article{miyazawa1961convergence,
  title={On the convergence of the learning process in a 2$\times$ 2 non-zero-sum two-person game. Econometric Research Program, Princeton University},
  author={Miyazawa, K},
  journal={Research Memorandum},
  volume={25},
  number={33},
  pages={6},
  year={1961}
}
@article{milgrom_adaptive_1991,
	title = {Adaptive and sophisticated learning in normal form games},
	volume = {3},
	issn = {0899-8256},
	url = {https://www.sciencedirect.com/science/article/pii/089982569190006Z},
	doi = {10.1016/0899-8256(91)90006-Z},
	abstract = {In a class of games including some Cournot and Bertrand games, a sequence of plays converges to the unique Nash equilibrium if and only if the sequence is “consistent with adaptive learning” according to the new definition we propose. In the Arrow-Debreu model with gross substitutes, a sequence of prices converges to the competitive equilibrium if and only if the sequence is consistent with adaptive learning by price-setting market makers for the individual goods. Similar results are obtained for “sophisticated” learning. All the familiar learning algorithms generate play that is consistent with adaptive learning. Journal of Economic Literature Classification Numbers: 026, 021.},
	number = {1},
	urldate = {2024-04-24},
	journal = {Games and Economic Behavior},
	author = {Milgrom, Paul and Roberts, John},
	month = feb,
	year = {1991},
	keywords = {GEB},
	pages = {82--100},
	file = {Milgrom and Roberts - 1991 - Adaptive and sophisticated learning in normal form.pdf:/Users/oliverbiggar/Zotero/storage/VSNYSSDH/Milgrom and Roberts - 1991 - Adaptive and sophisticated learning in normal form.pdf:application/pdf;ScienceDirect Snapshot:/Users/oliverbiggar/Zotero/storage/VRZHYATB/089982569190006Z.html:text/html},
}

@article{szabo_evolutionary_2016,
	title = {Evolutionary potential games on lattices},
	volume = {624},
	issn = {0370-1573},
	journal = {Physics Reports},
	author = {Szabó, György and Borsos, István},
	year = {2016},
	note = {Publisher: Elsevier},
	pages = {1--60},
	file = {Szabó and Borsos - 2016 - Evolutionary potential games on lattices.pdf:/Users/oliverbiggar/Zotero/storage/L2TE8T6C/Szabó and Borsos - 2016 - Evolutionary potential games on lattices.pdf:application/pdf},
}

@article{boros2009minimal,
  title={Minimal and locally minimal games and game forms},
  author={Boros, Endre and Gurvich, Vladimir and Makino, Kazuhisa},
  journal={Discrete mathematics},
  volume={309},
  number={13},
  pages={4456--4468},
  year={2009},
  publisher={Elsevier}
}

@article{boros2016sufficient,
  title={Sufficient conditions for the existence of Nash equilibria in bimatrix games in terms of forbidden $2\times 2$ subgames},
  author={Boros, Endre and Elbassioni, Khaled and Gurvich, Vladimir and Makino, Kazuhisa and Oudalov, Vladimir},
  journal={International journal of game theory},
  volume={45},
  pages={1111--1131},
  year={2016},
  publisher={Springer}
}
@article{viossat2013no,
  title={No-regret dynamics and fictitious play},
  author={Viossat, Yannick and Zapechelnyuk, Andriy},
  journal={Journal of Economic Theory},
  volume={148},
  number={2},
  pages={825--842},
  year={2013},
  publisher={Elsevier}
}

@article{papadimitriou_game_2019,
	title = {Game dynamics as the meaning of a game},
	volume = {16},
	issn = {1551-9031},
	number = {2},
	journal = {ACM SIGecom Exchanges},
	author = {Papadimitriou, Christos and Piliouras, Georgios},
	year = {2019},
	note = {Publisher: ACM New York, NY, USA},
	pages = {53--63},
	file = {Papadimitriou and Piliouras - 2019 - Game dynamics as the meaning of a game.pdf:/Users/oliverbiggar/Zotero/storage/MWGSDX5Q/Papadimitriou and Piliouras - 2019 - Game dynamics as the meaning of a game.pdf:application/pdf},
}

@article{allamigeon_what_2021,
	title = {What tropical geometry tells us about the complexity of linear programming},
	volume = {63},
	issn = {0036-1445},
	number = {1},
	journal = {SIAM review},
	author = {Allamigeon, Xavier and Benchimol, Pascal and Gaubert, Stéphane and Joswig, Michael},
	year = {2021},
	note = {Publisher: SIAM},
	pages = {123--164},
	file = {Allamigeon et al. - 2021 - What tropical geometry tells us about the complexi.pdf:/Users/oliverbiggar/Zotero/storage/Q4URTP3B/Allamigeon et al. - 2021 - What tropical geometry tells us about the complexi.pdf:application/pdf},
}

@article{morris_best_2004,
	title = {Best response equivalence},
	volume = {49},
	issn = {08998256},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0899825604000132},
	doi = {10.1016/j.geb.2003.12.004},
	abstract = {Two games are best-response equivalent if they have the same best-response correspondence. We provide a characterization of when two games are best-response equivalent. The characterizations exploit a dual relationship between payoﬀ diﬀerences and beliefs. Some “potential game” arguments (cf. Monderer and Shapley, 1996, Games Econ. Behav. 14, 124–143) rely only on the property that potential games are best-response equivalent to identical interest games. Our results show that a large class of games are best-response equivalent to identical interest games, but are not potential games. Thus we show how some existing potential game arguments can be extended.},
	language = {en},
	number = {2},
	urldate = {2023-06-27},
	journal = {Games and Economic Behavior},
	author = {Morris, Stephen and Ui, Takashi},
	month = nov,
	year = {2004},
	pages = {260--287},
	file = {Morris and Ui - 2004 - Best response equivalence.pdf:/Users/oliverbiggar/Zotero/storage/VE5FPG5Y/Morris and Ui - 2004 - Best response equivalence.pdf:application/pdf},
}

@article{lanctot_openspiel_2019,
	title = {{OpenSpiel}: {A} framework for reinforcement learning in games},
	journal = {arXiv preprint arXiv:1908.09453},
	author = {Lanctot, Marc and Lockhart, Edward and Lespiau, Jean-Baptiste and Zambaldi, Vinicius and Upadhyay, Satyaki and Pérolat, Julien and Srinivasan, Sriram and Timbers, Finbarr and Tuyls, Karl and Omidshafiei, Shayegan},
	year = {2019},
	file = {Lanctot et al. - 2019 - OpenSpiel A framework for reinforcement learning .pdf:/Users/oliverbiggar/Zotero/storage/LR85HDHI/Lanctot et al. - 2019 - OpenSpiel A framework for reinforcement learning .pdf:application/pdf},
}

@article{tuyls_symmetric_2018,
	title = {Symmetric decomposition of asymmetric games},
	volume = {8},
	issn = {2045-2322},
	number = {1},
	journal = {Scientific reports},
	author = {Tuyls, Karl and Pérolat, Julien and Lanctot, Marc and Ostrovski, Georg and Savani, Rahul and Leibo, Joel Z and Ord, Toby and Graepel, Thore and Legg, Shane},
	year = {2018},
	note = {Publisher: Springer},
	pages = {1--20},
	file = {Tuyls et al. - 2018 - Symmetric decomposition of asymmetric games.pdf:/Users/oliverbiggar/Zotero/storage/I772MQNZ/Tuyls et al. - 2018 - Symmetric decomposition of asymmetric games.pdf:application/pdf},
}

@article{biggar_preference_2025,
	title = {Preference graphs: a combinatorial tool for game theory},
	journal = {arXiv preprint arXiv:2502.03546},
	author = {Biggar, Oliver and Shames, Iman},
	year = {2025},
}

@article{hao_skew-symmetric_2018,
	title = {On skew-symmetric games},
	volume = {355},
	issn = {0016-0032},
	number = {6},
	journal = {Journal of the Franklin Institute},
	author = {Hao, Yaqi and Cheng, Daizhan},
	year = {2018},
	note = {Publisher: Elsevier},
	pages = {3196--3220},
}

@article{yang_overview_2020,
	title = {An overview of multi-agent reinforcement learning from game theoretical perspective},
	journal = {arXiv preprint arXiv:2011.00583},
	author = {Yang, Yaodong and Wang, Jun},
	year = {2020},
	file = {Yang and Wang - 2020 - An overview of multi-agent reinforcement learning .pdf:/Users/oliverbiggar/Zotero/storage/BGN85NBG/Yang and Wang - 2020 - An overview of multi-agent reinforcement learning .pdf:application/pdf},
}

@inproceedings{hennes_neural_2020,
	title = {Neural replicator dynamics: {Multiagent} learning via hedging policy gradients},
	author = {Hennes, Daniel and Morrill, Dustin and Omidshafiei, Shayegan and Munos, Rémi and Perolat, Julien and Lanctot, Marc and Gruslys, Audrunas and Lespiau, Jean-Baptiste and Parmas, Paavo and Duéñez-Guzmán, Edgar},
	year = {2020},
	pages = {492--501},
	file = {Hennes et al. - 2020 - Neural replicator dynamics Multiagent learning vi.pdf:/Users/oliverbiggar/Zotero/storage/99BEFXLD/Hennes et al. - 2020 - Neural replicator dynamics Multiagent learning vi.pdf:application/pdf},
}

@article{bravo_robustness_2017,
	title = {On the robustness of learning in games with stochastically perturbed payoff observations},
	volume = {103},
	issn = {0899-8256},
	journal = {Games and Economic Behavior},
	author = {Bravo, Mario and Mertikopoulos, Panayotis},
	year = {2017},
	note = {Publisher: Elsevier},
	pages = {41--66},
	file = {Bravo and Mertikopoulos - 2017 - On the robustness of learning in games with stocha.pdf:/Users/oliverbiggar/Zotero/storage/8T2WKIG4/Bravo and Mertikopoulos - 2017 - On the robustness of learning in games with stocha.pdf:application/pdf},
}

@article{hernandez-leal_survey_2019,
	title = {A survey and critique of multiagent deep reinforcement learning},
	volume = {33},
	issn = {1387-2532},
	number = {6},
	journal = {Autonomous Agents and Multi-Agent Systems},
	author = {Hernandez-Leal, Pablo and Kartal, Bilal and Taylor, Matthew E},
	year = {2019},
	note = {Publisher: Springer},
	pages = {750--797},
	file = {Hernandez-Leal et al. - 2019 - A survey and critique of multiagent deep reinforce.pdf:/Users/oliverbiggar/Zotero/storage/4T5MZ2U4/Hernandez-Leal et al. - 2019 - A survey and critique of multiagent deep reinforce.pdf:application/pdf},
}

@inproceedings{bailey_multiplicative_2018,
	title = {Multiplicative weights update in zero-sum games},
	author = {Bailey, James P and Piliouras, Georgios},
	year = {2018},
	pages = {321--338},
	file = {Bailey and Piliouras - 2018 - Multiplicative weights update in zero-sum games.pdf:/Users/oliverbiggar/Zotero/storage/7R8B3QWB/Bailey and Piliouras - 2018 - Multiplicative weights update in zero-sum games.pdf:application/pdf},
}

@article{hofbauer_evolutionary_1996,
	title = {Evolutionary dynamics for bimatrix games: {A} {Hamiltonian} system?},
	volume = {34},
	issn = {0303-6812},
	journal = {Journal of mathematical biology},
	author = {Hofbauer, Josef},
	year = {1996},
	note = {Publisher: Springer},
	pages = {675--688},
	file = {Hofbauer - 1996 - Evolutionary dynamics for bimatrix games A Hamilt.pdf:/Users/oliverbiggar/Zotero/storage/LKNKGN2G/Hofbauer - 1996 - Evolutionary dynamics for bimatrix games A Hamilt.pdf:application/pdf},
}

@inproceedings{kleinberg_multiplicative_2009,
	title = {Multiplicative updates outperform generic no-regret learning in congestion games},
	author = {Kleinberg, Robert and Piliouras, Georgios and Tardos, Éva},
	year = {2009},
	pages = {533--542},
	file = {Kleinberg et al. - 2009 - Multiplicative updates outperform generic no-regre.pdf:/Users/oliverbiggar/Zotero/storage/Q76IXB6Y/Kleinberg et al. - 2009 - Multiplicative updates outperform generic no-regre.pdf:application/pdf},
}

@article{piliouras_evolutionary_2022,
	title = {Evolutionary {Dynamics} and {Phi}-{Regret} {Minimization} in {Games}},
	volume = {74},
	issn = {1076-9757},
	journal = {Journal of Artificial Intelligence Research},
	author = {Piliouras, Georgios and Rowland, Mark and Omidshafiei, Shayegan and Elie, Romuald and Hennes, Daniel and Connor, Jerome and Tuyls, Karl},
	year = {2022},
	pages = {1125--1158},
	file = {Piliouras et al. - 2022 - Evolutionary Dynamics and Phi-Regret Minimization .pdf:/Users/oliverbiggar/Zotero/storage/D7VPMKBG/Piliouras et al. - 2022 - Evolutionary Dynamics and Phi-Regret Minimization .pdf:application/pdf},
}

@article{cai_uncoupled_2023,
	title = {Uncoupled and {Convergent} {Learning} in {Two}-{Player} {Zero}-{Sum} {Markov} {Games}},
	journal = {arXiv preprint arXiv:2303.02738},
	author = {Cai, Yang and Luo, Haipeng and Wei, Chen-Yu and Zheng, Weiqiang},
	year = {2023},
	file = {Cai et al. - 2023 - Uncoupled and Convergent Learning in Two-Player Ze.pdf:/Users/oliverbiggar/Zotero/storage/HJ47QFXD/Cai et al. - 2023 - Uncoupled and Convergent Learning in Two-Player Ze.pdf:application/pdf},
}

@inproceedings{cheung_vortices_2019,
	title = {Vortices instead of equilibria in minmax optimization: {Chaos} and butterfly effects of online learning in zero-sum games},
	isbn = {2640-3498},
	publisher = {PMLR},
	author = {Cheung, Yun Kuen and Piliouras, Georgios},
	year = {2019},
	pages = {807--834},
	file = {Cheung and Piliouras - 2019 - Vortices instead of equilibria in minmax optimizat.pdf:/Users/oliverbiggar/Zotero/storage/K64FYF9T/Cheung and Piliouras - 2019 - Vortices instead of equilibria in minmax optimizat.pdf:application/pdf},
}

@article{arora_multiplicative_2012,
	title = {The multiplicative weights update method: a meta-algorithm and applications},
	volume = {8},
	issn = {1557-2862},
	number = {1},
	journal = {Theory of computing},
	author = {Arora, Sanjeev and Hazan, Elad and Kale, Satyen},
	year = {2012},
	note = {Publisher: Theory of Computing Exchange},
	pages = {121--164},
	file = {Arora et al. - 2012 - The multiplicative weights update method a meta-a.pdf:/Users/oliverbiggar/Zotero/storage/26E3CQ93/Arora et al. - 2012 - The multiplicative weights update method a meta-a.pdf:application/pdf},
}

@article{von_stengel_zero-sum_2023,
	title = {Zero-sum games and linear programming duality},
	issn = {0364-765X},
	journal = {Mathematics of Operations Research},
	author = {von Stengel, Bernhard},
	year = {2023},
	note = {Publisher: INFORMS},
	file = {von Stengel - 2023 - Zero-sum games and linear programming duality.pdf:/Users/oliverbiggar/Zotero/storage/JRXCI8TF/von Stengel - 2023 - Zero-sum games and linear programming duality.pdf:application/pdf},
}

@article{balduzzi_re-evaluating_2018,
	title = {Re-evaluating evaluation},
	volume = {31},
	journal = {Advances in Neural Information Processing Systems},
	author = {Balduzzi, David and Tuyls, Karl and Perolat, Julien and Graepel, Thore},
	year = {2018},
	file = {Balduzzi et al. - 2018 - Re-evaluating evaluation.pdf:/Users/oliverbiggar/Zotero/storage/4TS8ZHPX/Balduzzi et al. - 2018 - Re-evaluating evaluation.pdf:application/pdf},
}

@article{cheung_chaos_2020,
	title = {Chaos, extremism and optimism: {Volume} analysis of learning in games},
	volume = {33},
	journal = {Advances in Neural Information Processing Systems},
	author = {Cheung, Yun Kuen and Piliouras, Georgios},
	year = {2020},
	pages = {9039--9049},
	file = {Cheung and Piliouras - 2020 - Chaos, extremism and optimism Volume analysis of .pdf:/Users/oliverbiggar/Zotero/storage/RYEDILIX/Cheung and Piliouras - 2020 - Chaos, extremism and optimism Volume analysis of .pdf:application/pdf},
}

@inproceedings{balduzzi_open-ended_2019,
	title = {Open-ended learning in symmetric zero-sum games},
	isbn = {2640-3498},
	publisher = {PMLR},
	author = {Balduzzi, David and Garnelo, Marta and Bachrach, Yoram and Czarnecki, Wojciech and Perolat, Julien and Jaderberg, Max and Graepel, Thore},
	year = {2019},
	pages = {434--443},
	file = {Balduzzi et al. - 2019 - Open-ended learning in symmetric zero-sum games.pdf:/Users/oliverbiggar/Zotero/storage/PLL8K754/Balduzzi et al. - 2019 - Open-ended learning in symmetric zero-sum games.pdf:application/pdf},
}

@article{bloembergen_evolutionary_2015,
	title = {Evolutionary dynamics of multi-agent learning: {A} survey},
	volume = {53},
	issn = {1076-9757},
	journal = {Journal of Artificial Intelligence Research},
	author = {Bloembergen, Daan and Tuyls, Karl and Hennes, Daniel and Kaisers, Michael},
	year = {2015},
	pages = {659--697},
	file = {Bloembergen et al. - 2015 - Evolutionary dynamics of multi-agent learning A s.pdf:/Users/oliverbiggar/Zotero/storage/KC3AF4XP/Bloembergen et al. - 2015 - Evolutionary dynamics of multi-agent learning A s.pdf:application/pdf},
}

@inproceedings{mcmahan_follow--regularized-leader_2011,
	title = {Follow-the-regularized-leader and mirror descent: {Equivalence} theorems and l1 regularization},
	publisher = {JMLR Workshop and Conference Proceedings},
	author = {McMahan, Brendan},
	year = {2011},
	pages = {525--533},
	file = {McMahan - 2011 - Follow-the-regularized-leader and mirror descent .pdf:/Users/oliverbiggar/Zotero/storage/HK34CBXN/McMahan - 2011 - Follow-the-regularized-leader and mirror descent .pdf:application/pdf},
}

@article{parise_graphon_2023,
	title = {Graphon games: {A} statistical framework for network games and interventions},
	volume = {91},
	issn = {0012-9682},
	number = {1},
	journal = {Econometrica},
	author = {Parise, Francesca and Ozdaglar, Asuman},
	year = {2023},
	note = {Publisher: Wiley Online Library},
	pages = {191--225},
	file = {Parise and Ozdaglar - 2023 - Graphon games A statistical framework for network.pdf:/Users/oliverbiggar/Zotero/storage/C7LHYIPR/Parise and Ozdaglar - 2023 - Graphon games A statistical framework for network.pdf:application/pdf},
}

@article{lim_hodge_2020,
	title = {Hodge {Laplacians} on graphs},
	volume = {62},
	issn = {0036-1445},
	number = {3},
	journal = {Siam Review},
	author = {Lim, Lek-Heng},
	year = {2020},
	note = {Publisher: SIAM},
	pages = {685--715},
	file = {Lim - 2020 - Hodge Laplacians on graphs.pdf:/Users/oliverbiggar/Zotero/storage/LMMWK84P/Lim - 2020 - Hodge Laplacians on graphs.pdf:application/pdf},
}

@inproceedings{wei_non-stationary_2021,
	title = {Non-stationary reinforcement learning without prior knowledge: {An} optimal black-box approach},
	isbn = {2640-3498},
	publisher = {PMLR},
	author = {Wei, Chen-Yu and Luo, Haipeng},
	year = {2021},
	pages = {4300--4354},
	file = {Wei and Luo - 2021 - Non-stationary reinforcement learning without prio.pdf:/Users/oliverbiggar/Zotero/storage/TLVQM3UW/Wei and Luo - 2021 - Non-stationary reinforcement learning without prio.pdf:application/pdf},
}

@article{brown_is_2023,
	title = {Is {Learning} in {Games} {Good} for the {Learners}?},
	journal = {arXiv preprint arXiv:2305.19496},
	author = {Brown, William and Schneider, Jon and Vodrahalli, Kiran},
	year = {2023},
	file = {Brown et al. - 2023 - Is Learning in Games Good for the Learners.pdf:/Users/oliverbiggar/Zotero/storage/BG7AX2W9/Brown et al. - 2023 - Is Learning in Games Good for the Learners.pdf:application/pdf},
}

@inproceedings{canaan_diverse_2019,
	title = {Diverse agents for ad-hoc cooperation in hanabi},
	isbn = {1-72811-884-0},
	publisher = {IEEE},
	author = {Canaan, Rodrigo and Togelius, Julian and Nealen, Andy and Menzel, Stefan},
	year = {2019},
	pages = {1--8},
	file = {Canaan et al. - 2019 - Diverse agents for ad-hoc cooperation in hanabi.pdf:/Users/oliverbiggar/Zotero/storage/KBMIZRDB/Canaan et al. - 2019 - Diverse agents for ad-hoc cooperation in hanabi.pdf:application/pdf},
}

@article{milionis_nash_2022,
	title = {Nash, conley, and computation: {Impossibility} and incompleteness in game dynamics},
	journal = {arXiv preprint arXiv:2203.14129},
	author = {Milionis, Jason and Papadimitriou, Christos and Piliouras, Georgios and Spendlove, Kelly},
	year = {2022},
	file = {Milionis et al. - 2022 - Nash, conley, and computation Impossibility and i.pdf:/Users/oliverbiggar/Zotero/storage/5XVJLUM4/Milionis et al. - 2022 - Nash, conley, and computation Impossibility and i.pdf:application/pdf},
}

@article{kalies_lattice_2021,
	title = {Lattice structures for attractors {III}},
	issn = {1040-7294},
	journal = {Journal of Dynamics and Differential Equations},
	author = {Kalies, William D and Mischaikow, Konstantin and Vandervorst, Robert CAM},
	year = {2021},
	note = {Publisher: Springer},
	pages = {1--40},
	file = {Kalies et al. - 2021 - Lattice structures for attractors III.pdf:/Users/oliverbiggar/Zotero/storage/GYLKZ7IL/Kalies et al. - 2021 - Lattice structures for attractors III.pdf:application/pdf},
}

@article{kohlberg_strategic_1986,
	title = {On the strategic stability of equilibria},
	issn = {0012-9682},
	journal = {Econometrica: Journal of the Econometric Society},
	author = {Kohlberg, Elon and Mertens, Jean-Francois},
	year = {1986},
	note = {Publisher: JSTOR},
	pages = {1003--1037},
	file = {Kohlberg and Mertens - 1986 - On the strategic stability of equilibria.pdf:/Users/oliverbiggar/Zotero/storage/EH5FNPMG/Kohlberg and Mertens - 1986 - On the strategic stability of equilibria.pdf:application/pdf},
}

@article{omidshafiei_-rank_2019,
	title = {$\alpha$-{Rank}: {Multi}-{Agent} {Evaluation} by {Evolution}},
	volume = {9},
	issn = {2045-2322},
	shorttitle = {$\alpha$-{Rank}},
	url = {https://www.nature.com/articles/s41598-019-45619-9},
	doi = {10.1038/s41598-019-45619-9},
	abstract = {Abstract
            
              We introduce
              $\alpha$
              -
              Rank
              , a principled evolutionary dynamics methodology, for the
              evaluation
              and
              ranking
              of agents in large-scale multi-agent interactions, grounded in a novel dynamical game-theoretic solution concept called
              Markov
              -
              Conley chains
              (MCCs). The approach leverages continuous-time and discrete-time evolutionary dynamical systems applied to empirical games, and scales tractably in the number of agents, in the type of interactions (beyond dyadic), and the type of empirical games (symmetric and asymmetric). Current models are fundamentally limited in one or more of these dimensions, and are not guaranteed to converge to the desired game-theoretic solution concept (typically the Nash equilibrium).
              $\alpha$
              -Rank automatically provides a ranking over the set of agents under evaluation and provides insights into their strengths, weaknesses, and long-term dynamics in terms of basins of attraction and sink components. This is a direct consequence of the correspondence we establish to the dynamical MCC solution concept when the underlying evolutionary model’s ranking-intensity parameter,
              $\alpha$
              , is chosen to be large, which exactly forms the basis of
              $\alpha$
              -Rank. In contrast to the Nash equilibrium, which is a static solution concept based solely on fixed points, MCCs are a dynamical solution concept based on the Markov chain formalism, Conley’s Fundamental Theorem of Dynamical Systems, and the core ingredients of dynamical systems: fixed points, recurrent sets, periodic orbits, and limit cycles. Our
              $\alpha$
              -Rank method runs in polynomial time with respect to the total number of pure strategy profiles, whereas computing a Nash equilibrium for a general-sum game is known to be intractable. We introduce mathematical proofs that not only provide an overarching and unifying perspective of existing continuous- and discrete-time evolutionary evaluation models, but also reveal the formal underpinnings of the
              $\alpha$
              -Rank methodology. We illustrate the method in canonical games and empirically validate it in several domains, including AlphaGo, AlphaZero, MuJoCo Soccer, and Poker.},
	language = {en},
	number = {1},
	urldate = {2023-07-18},
	journal = {Scientific Reports},
	author = {Omidshafiei, Shayegan and Papadimitriou, Christos and Piliouras, Georgios and Tuyls, Karl and Rowland, Mark and Lespiau, Jean-Baptiste and Czarnecki, Wojciech M. and Lanctot, Marc and Perolat, Julien and Munos, Remi},
	month = jul,
	year = {2019},
	pages = {9937},
	file = {Omidshafiei et al. - 2019 - $\alpha$-Rank Multi-Agent Evaluation by Evolution.pdf:/Users/oliverbiggar/Zotero/storage/AC74B7FK/Omidshafiei et al. - 2019 - $\alpha$-Rank Multi-Agent Evaluation by Evolution.pdf:application/pdf;Omidshaﬁei et al. - $\alpha$-Rank Multi-Agent Evaluation by Evolution (Suppl.pdf:/Users/oliverbiggar/Zotero/storage/SHIYG53X/Omidshaﬁei et al. - $\alpha$-Rank Multi-Agent Evaluation by Evolution (Suppl.pdf:application/pdf},
}

@article{benaim_perturbations_2012,
	title = {Perturbations of set-valued dynamical systems, with applications to game theory},
	volume = {2},
	issn = {2153-0785},
	journal = {Dynamic Games and Applications},
	author = {Benaïm, Michel and Hofbauer, Josef and Sorin, Sylvain},
	year = {2012},
	note = {Publisher: Springer},
	pages = {195--205},
	file = {Benaïm et al. - 2012 - Perturbations of set-valued dynamical systems, wit.pdf:/Users/oliverbiggar/Zotero/storage/WVTHKH8A/Benaïm et al. - 2012 - Perturbations of set-valued dynamical systems, wit.pdf:application/pdf},
}

@article{shalev2012online,
  title={Online learning and online convex optimization},
  author={Shalev-Shwartz, Shai and others},
  journal={Foundations and Trends{\textregistered} in Machine Learning},
  volume={4},
  number={2},
  pages={107--194},
  year={2012},
  publisher={Now Publishers, Inc.}
}

@article{viossat2007replicator,
  title={The replicator dynamics does not lead to correlated equilibria},
  author={Viossat, Yannick},
  journal={Games and Economic Behavior},
  volume={59},
  number={2},
  pages={397--407},
  year={2007},
  publisher={Elsevier}
}
@book{cesa2006prediction,
  title={Prediction, learning, and games},
  author={Cesa-Bianchi, Nicolo and Lugosi, G{\'a}bor},
  year={2006},
  publisher={Cambridge university press}
}

@article{papadimitriou_nash_2018,
	title = {From nash equilibria to chain recurrent sets: {An} algorithmic solution concept for game theory},
	volume = {20},
	issn = {1099-4300},
	number = {10},
	journal = {Entropy},
	author = {Papadimitriou, Christos and Piliouras, Georgios},
	year = {2018},
	note = {Publisher: MDPI},
	pages = {782},
	file = {Papadimitriou and Piliouras - 2018 - From nash equilibria to chain recurrent sets An a.pdf:/Users/oliverbiggar/Zotero/storage/FXMHB7MK/Papadimitriou and Piliouras - 2018 - From nash equilibria to chain recurrent sets An a.pdf:application/pdf},
}

@article{barany_classification_1992,
	title = {Classification of two-person ordinal bimatrix games},
	volume = {21},
	issn = {0020-7276},
	journal = {International Journal of Game Theory},
	author = {Barany, Imre and Lee, Jon and Shubik, Martin},
	year = {1992},
	note = {Publisher: Springer},
	pages = {267--290},
	file = {Barany et al. - 1992 - Classification of two-person ordinal bimatrix game.pdf:/Users/oliverbiggar/Zotero/storage/RXCBF9GX/Barany et al. - 1992 - Classification of two-person ordinal bimatrix game.pdf:application/pdf},
}

@inproceedings{conitzer_complexity_2005,
	title = {Complexity of (iterated) dominance},
	author = {Conitzer, Vincent and Sandholm, Tuomas},
	year = {2005},
	pages = {88--97},
	file = {Conitzer and Sandholm - 2005 - Complexity of (iterated) dominance.pdf:/Users/oliverbiggar/Zotero/storage/UDQKHKD9/Conitzer and Sandholm - 2005 - Complexity of (iterated) dominance.pdf:application/pdf},
}

@article{brandt_symmetries_2009,
	title = {Symmetries and the complexity of pure {Nash} equilibrium},
	volume = {75},
	issn = {0022-0000},
	number = {3},
	journal = {Journal of computer and system sciences},
	author = {Brandt, Felix and Fischer, Felix and Holzer, Markus},
	year = {2009},
	note = {Publisher: Elsevier},
	pages = {163--177},
	file = {Brandt et al. - 2009 - Symmetries and the complexity of pure Nash equilib.pdf:/Users/oliverbiggar/Zotero/storage/EBV4ALGC/Brandt et al. - 2009 - Symmetries and the complexity of pure Nash equilib.pdf:application/pdf},
}

@article{gilboa_nash_1989,
	title = {Nash and correlated equilibria: {Some} complexity considerations},
	volume = {1},
	issn = {0899-8256},
	number = {1},
	journal = {Games and Economic Behavior},
	author = {Gilboa, Itzhak and Zemel, Eitan},
	year = {1989},
	note = {Publisher: Elsevier},
	pages = {80--93},
	file = {Gilboa and Zemel - 1989 - Nash and correlated equilibria Some complexity co.pdf:/Users/oliverbiggar/Zotero/storage/SRVZDKS3/Gilboa and Zemel - 1989 - Nash and correlated equilibria Some complexity co.pdf:application/pdf},
}

@article{wilson_computing_1971,
	title = {Computing equilibria of n-person games},
	volume = {21},
	issn = {0036-1399},
	number = {1},
	journal = {SIAM Journal on Applied Mathematics},
	author = {Wilson, Robert},
	year = {1971},
	note = {Publisher: SIAM},
	pages = {80--87},
	file = {Wilson - 1971 - Computing equilibria of n-person games.pdf:/Users/oliverbiggar/Zotero/storage/7YQ76D3M/Wilson - 1971 - Computing equilibria of n-person games.pdf:application/pdf},
}

@article{daskalakis_complexity_2009,
	title = {The complexity of computing a {Nash} equilibrium},
	volume = {52},
	issn = {0001-0782},
	url = {https://doi.org/10.1145/1461928.1461951},
	doi = {10.1145/1461928.1461951},
	abstract = {How long does it take until economic agents converge to an equilibrium? By studying the complexity of the problem of computing a mixed Nash equilibrium in a game, we provide evidence that there are games in which convergence to such an equilibrium takes prohibitively long. Traditionally, computational problems fall into two classes: those that have a polynomial-time algorithm and those that are NP-hard. However, the concept of NP-hardness cannot be applied to the rare problems where "every instance has a solution"---for example, in the case of games Nash's theorem asserts that every game has a mixed equilibrium (now known as the Nash equilibrium, in honor of that result). We show that finding a Nash equilibrium is complete for a class of problems called PPAD, containing several other known hard problems; all problems in PPAD share the same style of proof that every instance has a solution.},
	number = {2},
	urldate = {2023-07-18},
	journal = {Communications of the ACM},
	author = {Daskalakis, Constantinos and Goldberg, Paul W. and Papadimitriou, Christos H.},
	month = feb,
	year = {2009},
	pages = {89--97},
	file = {Submitted Version:/Users/oliverbiggar/Zotero/storage/3XZJT5WK/Daskalakis et al. - 2009 - The complexity of computing a Nash equilibrium.pdf:application/pdf},
}

@inproceedings{fabrikant_complexity_2004,
	address = {New York, NY, USA},
	series = {{STOC} '04},
	title = {The complexity of pure {Nash} equilibria},
	isbn = {978-1-58113-852-8},
	url = {https://doi.org/10.1145/1007352.1007445},
	doi = {10.1145/1007352.1007445},
	abstract = {We investigate from the computational viewpoint multi-player games that are guaranteed to have pure Nash equilibria. We focus on congestion games, and show that a pure Nash equilibrium can be computed in polynomial time in the symmetric network case, while the problem is PLS-complete in general. We discuss implications to non-atomic congestion games, and we explore the scope of the potential function method for proving existence of pure Nash equilibria.},
	urldate = {2023-07-17},
	booktitle = {Proceedings of the thirty-sixth annual {ACM} symposium on {Theory} of computing},
	publisher = {Association for Computing Machinery},
	author = {Fabrikant, Alex and Papadimitriou, Christos and Talwar, Kunal},
	month = jun,
	year = {2004},
	keywords = {complexity, congestion games, games, local search, PLS, PLS-completeness, pure Nash equilibria},
	pages = {604--612},
	file = {Fabrikant et al. - 2004 - The complexity of pure Nash equilibria.pdf:/Users/oliverbiggar/Zotero/storage/2XBPTBD8/Fabrikant et al. - 2004 - The complexity of pure Nash equilibria.pdf:application/pdf},
}

@inproceedings{goldberg_reducibility_2006,
	address = {New York, NY, USA},
	series = {{STOC} '06},
	title = {Reducibility among equilibrium problems},
	isbn = {978-1-59593-134-4},
	url = {https://doi.org/10.1145/1132516.1132526},
	doi = {10.1145/1132516.1132526},
	abstract = {We address the fundamental question of whether the Nash equilibria of a game can be computed in polynomial time. We describe certain efficient reductions between this problem for normal form games with a fixed number of players and graphical games with fixed degree. Our main result is that the problem of solving a game for any constant number of players, is reducible to solving a 4-player game.},
	urldate = {2023-07-17},
	booktitle = {Proceedings of the thirty-eighth annual {ACM} symposium on {Theory} of {Computing}},
	publisher = {Association for Computing Machinery},
	author = {Goldberg, Paul W. and Papadimitriou, Christos H.},
	month = may,
	year = {2006},
	keywords = {Nash equilibrium},
	pages = {61--70},
	file = {reducibility amond equilibria.pdf:/Users/oliverbiggar/Zotero/storage/FWCMAGWQ/reducibility amond equilibria.pdf:application/pdf;Submitted Version:/Users/oliverbiggar/Zotero/storage/9SSMF4N3/Goldberg and Papadimitriou - 2006 - Reducibility among equilibrium problems.pdf:application/pdf},
}

@article{benisch_algorithms_2010,
	title = {Algorithms for {Closed} {Under} {Rational} {Behavior} ({CURB}) {Sets}},
	volume = {38},
	copyright = {Copyright (c)},
	issn = {1076-9757},
	url = {https://www.jair.org/index.php/jair/article/view/10660},
	doi = {10.1613/jair.3070},
	abstract = {We provide a series of algorithms demonstrating that solutions according to the fundamental game-theoretic solution concept of closed under rational behavior (CURB) sets in two-player, normal-form games can be computed in polynomial time (we also discuss extensions to n-player games). First, we describe an algorithm that identifies all of a players best responses conditioned on the belief that the other player will play from within a given subset of its strategy space. This algorithm serves as a subroutine in a series of polynomial-time algorithms for finding all minimal CURB sets, one minimal CURB set, and the smallest minimal CURB set in a game. We then show that the complexity of finding a Nash equilibrium can be exponential only in the size of a games smallest CURB set. Related to this, we show that the smallest CURB set can be an arbitrarily small portion of the game, but it can also be arbitrarily larger than the supports of its only enclosed Nash equilibrium. We test our algorithms empirically and find that most commonly studied academic games tend to have either very large or very small minimal CURB sets.},
	language = {en},
	urldate = {2023-07-18},
	journal = {Journal of Artificial Intelligence Research},
	author = {Benisch, M. and Davis, G. B. and Sandholm, T.},
	month = aug,
	year = {2010},
	pages = {513--534},
	file = {CURB sets.pdf:/Users/oliverbiggar/Zotero/storage/GY3R63JR/CURB sets.pdf:application/pdf;Full Text PDF:/Users/oliverbiggar/Zotero/storage/BQ9WRWAU/Benisch et al. - 2010 - Algorithms for Closed Under Rational Behavior (CUR.pdf:application/pdf},
}

@article{basu_strategy_1991,
	title = {Strategy subsets closed under rational behavior},
	volume = {36},
	issn = {0165-1765},
	url = {https://www.sciencedirect.com/science/article/pii/016517659190179O},
	doi = {10.1016/0165-1765(91)90179-O},
	abstract = {A set of strategy profiles is here said to be closed under rational behavior (curb) if it contains all its best replies. Each curb set contains the support of at least one Nash equilibrium in mixed strategies, but there are perfect Nash equilibria that are not contained in any minimal curb set. It is shown that every game with compact strategy sets and continuous payoff functions possesses at least one minimal curb set, that every minimal curb set is identical with its best replies and that it is contained in the set of rationalizable strategy profiles.},
	language = {en},
	number = {2},
	urldate = {2023-07-18},
	journal = {Economics Letters},
	author = {Basu, Kaushik and Weibull, Jörgen W.},
	month = jun,
	year = {1991},
	pages = {141--146},
	file = {curb sets-BW.pdf:/Users/oliverbiggar/Zotero/storage/E6T85WB4/curb sets-BW.pdf:application/pdf;ScienceDirect Snapshot:/Users/oliverbiggar/Zotero/storage/GAR2KCKS/016517659190179O.html:text/html;Submitted Version:/Users/oliverbiggar/Zotero/storage/UF9CYMJT/Basu and Weibull - 1991 - Strategy subsets closed under rational behavior.pdf:application/pdf},
}

@article{voorneveld_axiomatization_2005,
	title = {An axiomatization of minimal curb sets},
	volume = {33},
	issn = {1432-1270},
	url = {https://doi.org/10.1007/s00182-005-0208-6},
	doi = {10.1007/s00182-005-0208-6},
	abstract = {Norde et al. [Games Econ. Behav. 12 (1996) 219] proved that none of the equilibrium concepts in the literature on equilibrium selection in finite strategic games satisfying existence is consistent. A transition to set-valued solution concepts overcomes the inconsistency problem: there is a multiplicity of consistent set-valued solution concepts that satisfy nonemptiness and recommend utility maximization in one-player games. The minimal curb sets of Basu and Weibull [Econ. Letters 36 (1991) 141] constitute one such solution concept; this solution concept is axiomatized in this article.},
	language = {en},
	number = {4},
	urldate = {2023-07-18},
	journal = {International Journal of Game Theory},
	author = {Voorneveld, Mark and Kets, Willemien and Norde, Henk},
	month = nov,
	year = {2005},
	keywords = {C72, Consistency, Minimal curb set},
	pages = {479--490},
	file = {Full Text PDF:/Users/oliverbiggar/Zotero/storage/VB6L9CNM/Voorneveld et al. - 2005 - An axiomatization of minimal curb sets.pdf:application/pdf},
}

@article{chotibut_route_2020,
	title = {The route to chaos in routing games: {When} is price of anarchy too optimistic?},
	volume = {33},
	journal = {Advances in Neural Information Processing Systems},
	author = {Chotibut, Thiparat and Falniowski, Fryderyk and Misiurewicz, Michał and Piliouras, Georgios},
	year = {2020},
	pages = {766--777},
	file = {Chotibut et al. - 2020 - The route to chaos in routing games When is price.pdf:/Users/oliverbiggar/Zotero/storage/PUVUQ9EI/Chotibut et al. - 2020 - The route to chaos in routing games When is price.pdf:application/pdf},
}

@incollection{mertikopoulos_cycles_2018,
	series = {Proceedings},
	title = {Cycles in {Adversarial} {Regularized} {Learning}},
	url = {https://epubs.siam.org/doi/abs/10.1137/1.9781611975031.172},
	abstract = {Regularized learning is a fundamental technique in online optimization, machine learning, and many other fields of computer science. A natural question that arises in this context is how regularized learning algorithms behave when faced against each other. We study a natural formulation of this problem by coupling regularized learning dynamics in zero-sum games. We show that the system's behavior is Poincaré recurrent, implying that almost every trajectory revisits any (arbitrarily small) neighborhood of its starting point infinitely often. This cycling behavior is robust to the agents’ choice of regularization mechanism (each agent could be using a different regularizer), to positive-affine transformations of the agents’ utilities, and it also persists in the case of networked competition (zero-sum polymatrix games).},
	urldate = {2023-07-18},
	booktitle = {Proceedings of the 2018 {Annual} {ACM}-{SIAM} {Symposium} on {Discrete} {Algorithms} ({SODA})},
	publisher = {Society for Industrial and Applied Mathematics},
	author = {Mertikopoulos, Panayotis and Papadimitriou, Christos and Piliouras, Georgios},
	month = jan,
	year = {2018},
	doi = {10.1137/1.9781611975031.172},
	pages = {2703--2717},
	file = {Full Text PDF:/Users/oliverbiggar/Zotero/storage/SPDJGJIJ/Mertikopoulos et al. - 2018 - Cycles in Adversarial Regularized Learning.pdf:application/pdf},
}

@article{candogan_dynamics_2013,
	title = {Dynamics in near-potential games},
	volume = {82},
	issn = {0899-8256},
	url = {https://www.sciencedirect.com/science/article/pii/S0899825613000948},
	doi = {10.1016/j.geb.2013.07.001},
	abstract = {We consider discrete-time learning dynamics in finite strategic form games, and show that games that are close to a potential game inherit many of the dynamical properties of potential games. We first study the evolution of the sequence of pure strategy profiles under better/best response dynamics. We show that this sequence converges to a (pure) approximate equilibrium set whose size is a function of the “distance” to a given nearby potential game. We then focus on logit response dynamics, and provide a characterization of the limiting outcome in terms of the distance of the game to a given potential game and the corresponding potential function. Finally, we turn attention to fictitious play, and establish that in near-potential games the sequence of empirical frequencies of player actions converges to a neighborhood of (mixed) equilibria, where the size of the neighborhood increases according to the distance to the set of potential games.},
	language = {en},
	urldate = {2023-07-18},
	journal = {Games and Economic Behavior},
	author = {Candogan, Ozan and Ozdaglar, Asuman and Parrilo, Pablo A.},
	month = nov,
	year = {2013},
	keywords = {Best response dynamics, Dynamics in games, Fictitious play, Logit response dynamics, Near-potential games},
	pages = {66--90},
	file = {ScienceDirect Snapshot:/Users/oliverbiggar/Zotero/storage/QWLQGU2P/S0899825613000948.html:text/html;Submitted Version:/Users/oliverbiggar/Zotero/storage/I2HF9MQN/Candogan et al. - 2013 - Dynamics in near-potential games.pdf:application/pdf},
}

@inproceedings{vlatakis-gkaragkounis_no-regret_2020,
	title = {No-{Regret} {Learning} and {Mixed} {Nash} {Equilibria}: {They} {Do} {Not} {Mix}},
	volume = {33},
	shorttitle = {No-{Regret} {Learning} and {Mixed} {Nash} {Equilibria}},
	url = {https://proceedings.neurips.cc/paper/2020/hash/0ed9422357395a0d4879191c66f4faa2-Abstract.html},
	abstract = {Understanding the behavior of no-regret dynamics in general N-player games is
a fundamental question in online learning and game theory. A folk result in the
field states that, in finite games, the empirical frequency of play under no-regret
learning converges to the game’s set of coarse correlated equilibria. By contrast,
our understanding of how the day-to-day behavior of the dynamics correlates to the game’s Nash equilibria is much more limited, and only partial results are known
for certain classes of games (such as zero-sum or congestion games). In this paper, we study the dynamics of follow the regularized leader (FTRL), arguably the most well-studied class of no-regret dynamics, and we establish a sweeping negative result showing that the notion of mixed Nash equilibrium is antithetical to no-regret learning. Specifically, we show that any Nash equilibrium which is not strict (in that every player has a unique best response) cannot be stable and attracting under the dynamics of FTRL. This result has significant implications for predicting the outcome of a learning process as it shows unequivocally that only strict (and hence, pure) Nash equilibria can emerge as stable limit points thereof.},
	urldate = {2023-07-18},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	publisher = {Curran Associates, Inc.},
	author = {Vlatakis-Gkaragkounis, Emmanouil-Vasileios and Flokas, Lampros and Lianeas, Thanasis and Mertikopoulos, Panayotis and Piliouras, Georgios},
	year = {2020},
	pages = {1380--1391},
	file = {Full Text PDF:/Users/oliverbiggar/Zotero/storage/ADUH27CT/Vlatakis-Gkaragkounis et al. - 2020 - No-Regret Learning and Mixed Nash Equilibria They.pdf:application/pdf},
}

@inproceedings{boone_darwin_2019,
	address = {Cham},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {From {Darwin} to {Poincaré} and von {Neumann}: {Recurrence} and {Cycles} in {Evolutionary} and {Algorithmic} {Game} {Theory}},
	isbn = {978-3-030-35389-6},
	shorttitle = {From {Darwin} to {Poincaré} and von {Neumann}},
	doi = {10.1007/978-3-030-35389-6_7},
	abstract = {Replicator dynamics, the continuous-time analogue of Multiplicative Weights Updates, is the main dynamic in evolutionary game theory. In simple evolutionary zero-sum games, such as Rock-Paper-Scissors, replicator dynamic is periodic [39], however, its behavior in higher dimensions is not well understood. We provide a complete characterization of its behavior in zero-sum evolutionary games. We prove that, if and only if, the system has an interior Nash equilibrium, the dynamics exhibit Poincaré recurrence, i.e., almost all orbits come arbitrary close to their initial conditions infinitely often. If no interior equilibria exist, then all interior initial conditions converge to the boundary. Specifically, the strategies that are not in the support of any equilibrium vanish in the limit of all orbits. All recurrence results furthermore extend to a class of games that generalize both graphical polymatrix games as well as evolutionary games, establishing a unifying link between evolutionary and algorithmic game theory. We show that two degrees of freedom, as in Rock-Paper-Scissors, is sufficient to prove periodicity.},
	language = {en},
	booktitle = {Web and {Internet} {Economics}},
	publisher = {Springer International Publishing},
	author = {Boone, Victor and Piliouras, Georgios},
	editor = {Caragiannis, Ioannis and Mirrokni, Vahab and Nikolova, Evdokia},
	year = {2019},
	pages = {85--99},
	file = {Full Text PDF:/Users/oliverbiggar/Zotero/storage/HH9C6AC9/Boone and Piliouras - 2019 - From Darwin to Poincaré and von Neumann Recurrenc.pdf:application/pdf},
}

@inproceedings{andrade_learning_2021,
	title = {Learning in {Matrix} {Games} can be {Arbitrarily} {Complex}},
	url = {https://proceedings.mlr.press/v134/andrade21a.html},
	abstract = {Many multi-agent systems with strategic interactions have their desired functionality encoded as the Nash equilibrium of a game, e.g. machine learning architectures such as Generative Adversarial Networks. Directly computing a Nash equilibrium of these games is often impractical or impossible in practice, which has led to the development of numerous learning algorithms with the goal of iteratively converging on a Nash equilibrium. Unfortunately, the dynamics generated by the learning process can be very intricate and instances failing to converge become hard to interpret. In this paper we show that, in a strong sense, this dynamic complexity is inherent to games. Specifically, we prove that replicator dynamics, the continuous-time analogue of Multiplicative Weights Update, even when applied in a very restricted class of games–known as finite matrix games–is rich enough to be able to approximate arbitrary dynamical systems. In the context of machine learning, our results are positive in the sense that they show the nearly boundless dynamic modelling capabilities of current machine learning practices, but also negative in implying that these capabilities may come at the cost of interpretability. As a concrete example, we show how replicator dynamics can effectively reproduce the well-known strange attractor of Lonrenz dynamics (the “butterfly effect") while achieving no regret.},
	language = {en},
	urldate = {2023-07-18},
	booktitle = {Proceedings of {Thirty} {Fourth} {Conference} on {Learning} {Theory}},
	publisher = {PMLR},
	author = {Andrade, Gabriel P. and Frongillo, Rafael and Piliouras, Georgios},
	month = jul,
	year = {2021},
	note = {ISSN: 2640-3498},
	pages = {159--185},
	file = {Full Text PDF:/Users/oliverbiggar/Zotero/storage/SKUFQRFQ/Andrade et al. - 2021 - Learning in Matrix Games can be Arbitrarily Comple.pdf:application/pdf},
}

@article{hart_uncoupled_2003,
	title = {Uncoupled {Dynamics} {Do} {Not} {Lead} to {Nash} {Equilibrium}},
	volume = {93},
	issn = {0002-8282},
	url = {https://www.aeaweb.org/articles?id=10.1257/000282803322655581},
	doi = {10.1257/000282803322655581},
	language = {en},
	number = {5},
	urldate = {2023-07-18},
	journal = {American Economic Review},
	author = {Hart, Sergiu and Mas-Colell, Andreu},
	month = dec,
	year = {2003},
	keywords = {Game Theory and Bargaining Theory: General},
	pages = {1830--1836},
	file = {Hart and Mas-Colell - 2003 - Uncoupled Dynamics Do Not Lead to Nash Equilibrium.pdf:/Users/oliverbiggar/Zotero/storage/PQZB4E24/Hart and Mas-Colell - 2003 - Uncoupled Dynamics Do Not Lead to Nash Equilibrium.pdf:application/pdf},
}

@article{durieu_ordinal_2007,
	title = {Ordinal games},
	copyright = {http://rightsstatements.org/page/InC-NC/1.0/, info:eu-repo/semantics/openAccess},
	url = {http://hdl.handle.net/20.500.11850/150171},
	doi = {10.3929/ETHZ-A-005502934},
	abstract = {We study strategic games where players’ preferences are weak orders which need not admit utility representations. First of all, we extend Voorneveld’s concept of best-response potential from cardinal to ordinal games and derive the analogue of his characterization result: An ordinal game is a best-response potential game if and only if it does not have a best-response cycle. Further, Milgrom and Shannon’s concept of quasisupermodularity is extended from cardinal games to ordinal games. We ﬁnd that under certain compactness and semicontinuity assumptions, the ordinal Nash equilibria of a quasi-supermodular game form a nonempty complete lattice. Finally, we extend several set-valued solution concepts from cardinal to ordinal games in our sense.},
	language = {en},
	urldate = {2023-07-18},
	author = {Durieu, Jacques and Haller, Hans and Querou, Nicolas and Solal, Philippe},
	month = oct,
	year = {2007},
	note = {Artwork Size: 50 p.
Medium: application/pdf
Publisher: ETH Zurich},
	keywords = {Ordinal games, Economics, info:eu-repo/classification/ddc/330, Potential games, Quasi-supermodularity, Rationalizable sets, Sets closed under behavior correspondences},
	pages = {50 p.},
	file = {Durieu et al. - 2007 - Ordinal games.pdf:/Users/oliverbiggar/Zotero/storage/Y3YMJLYD/Durieu et al. - 2007 - Ordinal games.pdf:application/pdf},
}

@article{cruz_ordinal_2000,
	title = {Ordinal {Games} and {Generalized} {Nash} and {Stackelberg} {Solutions}},
	volume = {107},
	issn = {1573-2878},
	url = {https://doi.org/10.1023/A:1026476425031},
	doi = {10.1023/A:1026476425031},
	abstract = {The traditional theory of cardinal games deals with problems where the players are able to assess the relative performance of their decisions (or controls) by evaluating a payoff (or utility function) that maps the decision space into the set of real numbers. In that theory, the objective of each player is to determine a decision that minimizes its payoff function taking into account the decisions of all other players. While that theory has been very useful in modeling simple problems in economics and engineering, it has not been able to address adequately problems in fields such as social and political sciences as well as a large segment of complex problems in economics and engineering. The main reason for this is the difficulty inherent in defining an adequate payoff function for each player in these types of problems.},
	language = {en},
	number = {2},
	urldate = {2023-07-18},
	journal = {Journal of Optimization Theory and Applications},
	author = {Cruz, J. B. and Simaan, M. A.},
	month = nov,
	year = {2000},
	keywords = {Nash solution, nonzero-sum games, ordinal games, ordinal optimization, Stackelberg solution},
	pages = {205--222},
	file = {Full Text PDF:/Users/oliverbiggar/Zotero/storage/XQFI6F8V/Cruz and Simaan - 2000 - Ordinal Games and Generalized Nash and Stackelberg.pdf:application/pdf},
}

@article{mertens_ordinality_2004,
	title = {Ordinality in non cooperative games},
	volume = {32},
	issn = {1432-1270},
	url = {https://doi.org/10.1007/s001820400166},
	doi = {10.1007/s001820400166},
	abstract = {We first analyse what a conceptual definition of ordinality for non cooperative games should be. The resulting concept is highly abstract and apparently unmanageable. Nevertheless we obtain in a second part a very simple and fully operational characterization. In the last part, this is used to check the ordinality of a number of concepts that have been proposed in the literature.},
	language = {en},
	number = {3},
	urldate = {2023-07-18},
	journal = {International Journal of Game Theory},
	author = {Mertens, Jean-François},
	month = jun,
	year = {2004},
	keywords = {Conceptual Definition, Cooperative Game, Operational Characterization},
	pages = {387--430},
	file = {Full Text PDF:/Users/oliverbiggar/Zotero/storage/2FZWUMUP/Mertens - 2004 - Ordinality in non cooperative games.pdf:application/pdf},
}

@article{candogan_flows_2011,
	title = {Flows and {Decompositions} of {Games}: {Harmonic} and {Potential} {Games}},
	volume = {36},
	issn = {0364-765X},
	shorttitle = {Flows and {Decompositions} of {Games}},
	url = {https://pubsonline.informs.org/doi/abs/10.1287/moor.1110.0500},
	doi = {10.1287/moor.1110.0500},
	abstract = {In this paper we introduce a novel flow representation for finite games in strategic form. This representation allows us to develop a canonical direct sum decomposition of an arbitrary game into three components, which we refer to as the potential, harmonic, and nonstrategic components. We analyze natural classes of games that are induced by this decomposition, and in particular, focus on games with no harmonic component and games with no potential component. We show that the first class corresponds to the well-known potential games. We refer to the second class of games as harmonic games, and demonstrate that this new class has interesting properties which contrast with properties of potential games. Exploiting the decomposition framework, we obtain explicit expressions for the projections of games onto the subspaces of potential and harmonic games. This enables an extension of the equilibrium properties of potential and harmonic games to “nearby” games.},
	number = {3},
	urldate = {2023-07-18},
	journal = {Mathematics of Operations Research},
	author = {Candogan, Ozan and Menache, Ishai and Ozdaglar, Asuman and Parrilo, Pablo A.},
	month = aug,
	year = {2011},
	note = {Publisher: INFORMS},
	keywords = {potential games, decomposition of games, harmonic games, strategic equivalence},
	pages = {474--503},
	file = {Submitted Version:/Users/oliverbiggar/Zotero/storage/5IKT8DL3/Candogan et al. - 2011 - Flows and Decompositions of Games Harmonic and Po.pdf:application/pdf},
}

@article{omidshafiei_navigating_2020,
	title = {Navigating the landscape of multiplayer games},
	volume = {11},
	copyright = {2020 The Author(s)},
	issn = {2041-1723},
	url = {https://www.nature.com/articles/s41467-020-19244-4},
	doi = {10.1038/s41467-020-19244-4},
	abstract = {Multiplayer games have long been used as testbeds in artificial intelligence research, aptly referred to as the Drosophila of artificial intelligence. Traditionally, researchers have focused on using well-known games to build strong agents. This progress, however, can be better informed by characterizing games and their topological landscape. Tackling this latter question can facilitate understanding of agents and help determine what game an agent should target next as part of its training. Here, we show how network measures applied to response graphs of large-scale games enable the creation of a landscape of games, quantifying relationships between games of varying sizes and characteristics. We illustrate our findings in domains ranging from canonical games to complex empirical games capturing the performance of trained agents pitted against one another. Our results culminate in a demonstration leveraging this information to generate new and interesting games, including mixtures of empirical games synthesized from real world games.},
	language = {en},
	number = {1},
	urldate = {2023-07-18},
	journal = {Nature Communications},
	author = {Omidshafiei, Shayegan and Tuyls, Karl and Czarnecki, Wojciech M. and Santos, Francisco C. and Rowland, Mark and Connor, Jerome and Hennes, Daniel and Muller, Paul and Pérolat, Julien and Vylder, Bart De and Gruslys, Audrunas and Munos, Rémi},
	month = nov,
	year = {2020},
	note = {Number: 1
Publisher: Nature Publishing Group},
	keywords = {Applied mathematics, Complex networks, Computer science, Information technology},
	pages = {5603},
	file = {Full Text PDF:/Users/oliverbiggar/Zotero/storage/BBKVTSNQ/Omidshafiei et al. - 2020 - Navigating the landscape of multiplayer games.pdf:application/pdf},
}

@inproceedings{mirrokni_complexity_2009,
	address = {New York, NY, USA},
	series = {{EC} '09},
	title = {On the complexity of nash dynamics and sink equilibria},
	isbn = {978-1-60558-458-4},
	url = {https://doi.org/10.1145/1566374.1566376},
	doi = {10.1145/1566374.1566376},
	abstract = {Studying Nash dynamics is an important approach for analyzing the outcome of games with repeated selfish behavior of self-interested agents. Sink equilibria has been introduced by Goemans, Mirrokni, and Vetta for studying social cost on Nash dynamics over pure strategies in games. However, they do not address the complexity of sink equilibria in these games. Recently, Fabrikant and Papadimitriou initiated the study of the complexity of Nash dynamics in two classes of games. In order to completely understand the complexity of Nash dynamics in a variety of games, we study the following three questions for various games: (i) given a state in game, can we verify if this state is in a sink equilibrium or not? (ii) given an instance of a game, can we verify if there exists any sink equilibrium other than pure Nash equilibria? and (iii) given an instance of a game, can we verify if there exists a pure Nash equilibrium (i.e, a sink equilibrium with one state)? In this paper, we almost answer all of the above questions for a variety of classes of games with succinct representation, including anonymous games, player-specific and weighted congestion games, valid-utility games, and two-sided market games. In particular, for most of these problems, we show that (i) it is PSPACE-hard to verify if a given state is in a sink equilibrium, (ii) it is NP-hard to verify if there exists a pure Nash equilibrium in the game or not, (iii) it is PSPACE-hard to verify if there exists any sink equilibrium other than pure Nash equilibria. To solve these problems, we illustrate general techniques that could be used to answer similar questions in other classes of games.},
	urldate = {2023-07-17},
	booktitle = {Proceedings of the 10th {ACM} conference on {Electronic} commerce},
	publisher = {Association for Computing Machinery},
	author = {Mirrokni, Vahab S. and Skopalik, Alexander},
	month = jul,
	year = {2009},
	keywords = {potential games, nash equilibria, sink equilibria},
	pages = {1--10},
	file = {Submitted Version:/Users/oliverbiggar/Zotero/storage/9KAI5BLU/Mirrokni and Skopalik - 2009 - On the complexity of nash dynamics and sink equili.pdf:application/pdf},
}

@inproceedings{goemans_sink_2005,
	title = {Sink equilibria and convergence},
	doi = {10.1109/SFCS.2005.68},
	abstract = {We introduce the concept of a sink equilibrium. A sink equilibrium is a strongly connected component with no outgoing arcs in the strategy profile graph associated with a game. The strategy profile graph has a vertex set induced by the set of pure strategy profiles; its arc set corresponds to transitions between strategy profiles that occur with nonzero probability. (Here our focus will just be on the special case in which the strategy profile graph is actually a best response graph; that is, its arc set corresponds exactly to best response moves that result from myopic or greedy behaviour). We argue that there is a natural convergence process to sink equilibria in games where agents use pure strategies. This leads to an alternative measure of the social cost of a lack of coordination, the price of sinking, which measures the worst case ratio between the value of a sink equilibrium and the value of the socially optimal solution. We define the value of a sink equilibrium to be the expected social value of the steady state distribution induced by a random walk on that sink. We illustrate the value of this measure in three ways. Firstly, we show that it may more accurately reflects the inefficiency of uncoordinated solutions in competitive games when the use of pure strategies is the norm. In particular, we give an example (a valid-utility game) in which the game converges to solutions which are a factor n worse than socially optimal. The price of sinking is indeed n, but the price of anarchy is close to 1. Secondly, sink equilibria always exist. Thus, even in games in which pure strategy Nash equilibria (PSNE) do not exist, we can still calculate the price of sinking. Thirdly, we show that bounding the price of sinking can have important implications for the speed of convergence to socially good solutions in games where the agents make best response moves in a random order. We present two examples to illustrate our ideas. (i) Unsplittable selfish routing (and weighted congestion games):we prove that the price of sinking for the weighted unsplittable flow version of the selfish routing problem (for bounded-degree polynomial latency functions) is at most O(2/sup 2d/ d/sup 2d + 3/). In comparison, we give instances of these games without any PSNE. Moreover, our proof technique implies fast convergence to socially good (approximate) solutions. This is in contrast to the negative result of Fabrikant, Papadimitriou, and Talwar (2004) showing the existence of exponentially long best-response paths. (ii) Valid-utility games: we show that for valid-utility games the price of sinking is at most n+1; thus the worst case price of sinking in a valid-utility game is between it and n+1. We use our proof to show fast convergence to constant factor approximate solutions in basic-utility games. In addition, we present a hardness result which shows that, in general, there might be states that are exponentially far from any sink equilibrium in valid-utility games. We prove this by showing that the problem of finding a sink equilibrium (or a PSNE) in valid-utility games is PLS-complete.},
	booktitle = {46th {Annual} {IEEE} {Symposium} on {Foundations} of {Computer} {Science} ({FOCS}'05)},
	author = {Goemans, M. and Mirrokni, Vahab and Vetta, A.},
	month = oct,
	year = {2005},
	note = {ISSN: 0272-5428},
	keywords = {Nash equilibrium, Computer science, Control systems, Convergence, Cost function, Delay, Performance analysis, Polynomials, Routing, Steady-state},
	pages = {142--151},
	file = {Goemans et al. - 2005 - Sink equilibria and convergence.pdf:/Users/oliverbiggar/Zotero/storage/M5B67ZHK/Goemans et al. - 2005 - Sink equilibria and convergence.pdf:application/pdf;IEEE Xplore Abstract Record:/Users/oliverbiggar/Zotero/storage/WNGR6E3H/1530709.html:text/html},
}

@inproceedings{fabrikant_structure_2010,
	address = {Berlin, Heidelberg},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {On the {Structure} of {Weakly} {Acyclic} {Games}},
	isbn = {978-3-642-16170-4},
	doi = {10.1007/978-3-642-16170-4\_12},
	abstract = {The class of weakly acyclic games, which includes potential games and dominance-solvable games, captures many practical application domains. Informally, a weakly acyclic game is one where natural distributed dynamics, such as better-response dynamics, cannot enter inescapable oscillations. We establish a novel link between such games and the existence of pure Nash equilibria in subgames. Specifically, we show that the existence of a unique pure Nash equilibrium in every subgame implies the weak acyclicity of a game. In contrast, the possible existence of multiple pure Nash equilibria in every subgame is insufficient for weak acyclicity.},
	language = {en},
	booktitle = {Algorithmic {Game} {Theory}},
	publisher = {Springer},
	author = {Fabrikant, Alex and Jaggard, Aaron D. and Schapira, Michael},
	editor = {Kontogiannis, Spyros and Koutsoupias, Elias and Spirakis, Paul G.},
	year = {2010},
	keywords = {Congestion Game, Consensus Problem, Edit Distance, Potential Game, Strategy Space},
	pages = {126--137},
	file = {Full Text PDF:/Users/oliverbiggar/Zotero/storage/YQFU9NWQ/Fabrikant et al. - 2010 - On the Structure of Weakly Acyclic Games.pdf:application/pdf},
}

@article{papadimitriou_computing_2008,
	title = {Computing correlated equilibria in multi-player games},
	volume = {55},
	issn = {0004-5411},
	url = {https://doi.org/10.1145/1379759.1379762},
	doi = {10.1145/1379759.1379762},
	abstract = {We develop polynomial-time algorithms for finding correlated equilibria—a well-studied notion of rationality that generalizes the Nash equilibrium—in a broad class of succinctly representable multiplayer games, encompassing graphical games, anonymous games, polymatrix games, congestion games, scheduling games, local effect games, as well as several generalizations. Our algorithm is based on a variant of the existence proof due to Hart and Schmeidler, and employs linear programming duality, the ellipsoid algorithm, Markov chain steady state computations, as well as application-specific methods for computing multivariate expectations over product distributions. For anonymous games and graphical games of bounded tree-width, we provide a different polynomial-time algorithm for optimizing an arbitrary linear function over the set of correlated equilibria of the game. In contrast to our sweeping positive results for computing an arbitrary correlated equilibrium, we prove that optimizing over correlated equilibria is NP-hard in all of the other classes of games that we consider.},
	number = {3},
	urldate = {2023-07-18},
	journal = {Journal of the ACM},
	author = {Papadimitriou, Christos H. and Roughgarden, Tim},
	month = aug,
	year = {2008},
	keywords = {complexity of equilibria, Correlated equilibria, Nash equilibria},
	pages = {14:1--14:29},
	file = {Papadimitriou and Roughgarden - 2008 - Computing correlated equilibria in multi-player ga.pdf:/Users/oliverbiggar/Zotero/storage/6ATA6ES8/Papadimitriou and Roughgarden - 2008 - Computing correlated equilibria in multi-player ga.pdf:application/pdf},
}

@article{nash_non-cooperative_1951,
	title = {Non-{Cooperative} {Games}},
	volume = {54},
	issn = {0003-486X},
	url = {https://www.jstor.org/stable/1969529},
	doi = {10.2307/1969529},
	number = {2},
	urldate = {2023-07-18},
	journal = {Annals of Mathematics},
	author = {Nash, John},
	year = {1951},
	note = {Publisher: Annals of Mathematics},
	pages = {286--295},
	file = {JSTOR Full Text PDF:/Users/oliverbiggar/Zotero/storage/VVFR5GW7/Nash - 1951 - Non-Cooperative Games.pdf:application/pdf},
}

@article{quint_theorem_1997,
	title = {A theorem on the number of {Nash} equilibria in a bimatrix game},
	volume = {26},
	issn = {1432-1270},
	url = {https://doi.org/10.1007/BF01263276},
	doi = {10.1007/BF01263276},
	abstract = {We show that ify is an odd integer between 1 and 2n − 1, there is ann × n bimatrix game with exactlyy Nash equilibria (NE). We conjecture that this 2n − 1 is a tight upper bound on the number of NEs in a “nondegenerate”n × n game.},
	language = {en},
	number = {3},
	urldate = {2023-07-18},
	journal = {International Journal of Game Theory},
	author = {Quint, Thomas and Shubik, Martin},
	month = oct,
	year = {1997},
	keywords = {Economic Theory, Game Theory, Nash Equilibrium},
	pages = {353--359},
	file = {Full Text PDF:/Users/oliverbiggar/Zotero/storage/4ATERPKD/Quint and Shubik - 1997 - A theorem on the number of Nash equilibria in a bi.pdf:application/pdf},
}

@article{hwang_strategic_2020,
	title = {Strategic decompositions of normal form games: {Zero}-sum games and potential games},
	volume = {122},
	issn = {0899-8256},
	shorttitle = {Strategic decompositions of normal form games},
	url = {https://www.sciencedirect.com/science/article/pii/S0899825620300725},
	doi = {10.1016/j.geb.2020.05.003},
	abstract = {We introduce new classes of games, called zero-sum equivalent games and zero-sum equivalent potential games, and prove decomposition theorems involving these classes of games. Two games are “strategically equivalent” if, for every player, the payoff differences between two strategies (holding other players' strategies fixed) are identical. A zero-sum equivalent game is a game that is strategically equivalent to a zero-sum game; a zero-sum equivalent potential game is a potential game that is strategically equivalent to a zero-sum game. We also call a game “normalized” if the sum of one player's payoffs, given the other players' strategies, is zero. One of our main decomposition results shows that any normal form game, whether the strategy set is finite or continuous, can be uniquely decomposed into a zero-sum normalized game, a zero-sum equivalent potential game, and an identical interest normalized game, each with distinctive equilibrium properties.},
	language = {en},
	urldate = {2023-07-18},
	journal = {Games and Economic Behavior},
	author = {Hwang, Sung-Ha and Rey-Bellet, Luc},
	month = jul,
	year = {2020},
	keywords = {Potential games, Decomposition, Zero-sum games},
	pages = {370--390},
	file = {Accepted Version:/Users/oliverbiggar/Zotero/storage/ZQSRPQSJ/Hwang and Rey-Bellet - 2020 - Strategic decompositions of normal form games Zer.pdf:application/pdf;ScienceDirect Snapshot:/Users/oliverbiggar/Zotero/storage/TG8475G4/S0899825620300725.html:text/html},
}

@article{hwang_simple_2020,
	title = {Simple characterizations of potential games and zero-sum equivalent games},
	volume = {31},
	issn = {1229-2893},
	number = {1},
	journal = {Journal of Economic Theory and Econometrics},
	author = {Hwang, Sung-Ha and Rey-Bellet, Luc},
	year = {2020},
	note = {Publisher: Korean Econometric Society},
	pages = {1--13},
	file = {Hwang and Rey-Bellet - 2020 - Simple characterizations of potential games and ze.pdf:/Users/oliverbiggar/Zotero/storage/UDX5243W/Hwang and Rey-Bellet - 2020 - Simple characterizations of potential games and ze.pdf:application/pdf},
}

@inproceedings{balduzzi_mechanics_2018,
	title = {The {Mechanics} of n-{Player} {Differentiable} {Games}},
	url = {https://proceedings.mlr.press/v80/balduzzi18a.html},
	abstract = {The cornerstone underpinning deep learning is the guarantee that gradient descent on an objective converges to local minima. Unfortunately, this guarantee fails in settings, such as generative adversarial nets, where there are multiple interacting losses. The behavior of gradient-based methods in games is not well understood – and is becoming increasingly important as adversarial and multi-objective architectures proliferate. In this paper, we develop new techniques to understand and control the dynamics in general games. The key result is to decompose the second-order dynamics into two components. The first is related to potential games, which reduce to gradient descent on an implicit function; the second relates to Hamiltonian games, a new class of games that obey a conservation law, akin to conservation laws in classical mechanical systems. The decomposition motivates Symplectic Gradient Adjustment (SGA), a new algorithm for finding stable fixed points in general games. Basic experiments show SGA is competitive with recently proposed algorithms for finding local Nash equilibria in GANs – whilst at the same time being applicable to – and having guarantees in – much more general games.},
	language = {en},
	urldate = {2023-07-18},
	booktitle = {Proceedings of the 35th {International} {Conference} on {Machine} {Learning}},
	publisher = {PMLR},
	author = {Balduzzi, David and Racaniere, Sebastien and Martens, James and Foerster, Jakob and Tuyls, Karl and Graepel, Thore},
	month = jul,
	year = {2018},
	note = {ISSN: 2640-3498},
	pages = {354--363},
	file = {Full Text PDF:/Users/oliverbiggar/Zotero/storage/QU9YSVBE/Balduzzi et al. - 2018 - The Mechanics of n-Player Differentiable Games.pdf:application/pdf;Supplementary PDF:/Users/oliverbiggar/Zotero/storage/EZGRL6MU/Balduzzi et al. - 2018 - The Mechanics of n-Player Differentiable Games.pdf:application/pdf},
}

@inproceedings{bielawski_follow--regularized-leader_2021,
	title = {Follow-the-{Regularized}-{Leader} {Routes} to {Chaos} in {Routing} {Games}},
	url = {https://proceedings.mlr.press/v139/bielawski21a.html},
	abstract = {We study the emergence of chaotic behavior of Follow-the-Regularized Leader (FoReL) dynamics in games. We focus on the effects of increasing the population size or the scale of costs in congestion games, and generalize recent results on unstable, chaotic behaviors in the Multiplicative Weights Update dynamics to a much larger class of FoReL dynamics. We establish that, even in simple linear non-atomic congestion games with two parallel links and {\textbackslash}emph\{any\} fixed learning rate, unless the game is fully symmetric, increasing the population size or the scale of costs causes learning dynamics to becomes unstable and eventually chaotic, in the sense of Li-Yorke and positive topological entropy. Furthermore, we prove the existence of novel non-standard phenomena such as the coexistence of stable Nash equilibria and chaos in the same game. We also observe the simultaneous creation of a chaotic attractor as another chaotic attractor gets destroyed. Lastly, although FoReL dynamics can be strange and non-equilibrating, we prove that the time average still converges to an {\textbackslash}emph\{exact\} equilibrium for any choice of learning rate and any scale of costs.},
	language = {en},
	urldate = {2023-07-18},
	booktitle = {Proceedings of the 38th {International} {Conference} on {Machine} {Learning}},
	publisher = {PMLR},
	author = {Bielawski, Jakub and Chotibut, Thiparat and Falniowski, Fryderyk and Kosiorowski, Grzegorz and Misiurewicz, Michał and Piliouras, Georgios},
	month = jul,
	year = {2021},
	note = {ISSN: 2640-3498},
	pages = {925--935},
	file = {Full Text PDF:/Users/oliverbiggar/Zotero/storage/V7GEV399/Bielawski et al. - 2021 - Follow-the-Regularized-Leader Routes to Chaos in R.pdf:application/pdf;Supplementary PDF:/Users/oliverbiggar/Zotero/storage/IMXPJPDS/Bielawski et al. - 2021 - Follow-the-Regularized-Leader Routes to Chaos in R.pdf:application/pdf},
}

@incollection{piliouras_optimization_2013,
	series = {Proceedings},
	title = {Optimization {Despite} {Chaos}: {Convex} {Relaxations} to {Complex} {Limit} {Sets} via {Poincaré} {Recurrence}},
	isbn = {978-1-61197-338-9},
	shorttitle = {Optimization {Despite} {Chaos}},
	url = {https://epubs.siam.org/doi/abs/10.1137/1.9781611973402.64},
	abstract = {It is well understood that decentralized systems can, through network interactions, give rise to complex behavior patterns that do not reflect their equilibrium properties. The challenge of any analytic investigation is to identify and characterize persistent properties despite the inherent irregularities of such systems and to do so efficiently. We develop a novel framework to address this challenge.
Our setting focuses on evolutionary dynamics in network extensions of zero-sum games. Such dynamics have been shown analytically to exhibit chaotic behavior which traditionally has been thought of as an overwhelming obstacle to algorithmic inquiry. We circumvent these issues as follows: First, we combine ideas from dynamical systems and game theory to produce topological characterizations of system trajectories. Trajectories capture the time evolution of the system given an initial starting state. They are complex, and do not necessarily converge to limit points or even limit cycles. We provide tractable approximations of such limit sets. These relaxed descriptions involve simplices, and can be computed in polynomial time. Next, we apply standard optimization techniques to compute extremal values of system features (e.g. expected utility of an agent) within these relaxations. Finally, we use information theoretic conservation laws along with Poincaré recurrence theory to argue about tightness and optimality of our relaxation techniques.},
	urldate = {2023-07-18},
	booktitle = {Proceedings of the 2014  {Annual} {ACM}-{SIAM} {Symposium} on {Discrete} {Algorithms} ({SODA})},
	publisher = {Society for Industrial and Applied Mathematics},
	author = {Piliouras, Georgios and Shamma, Jeff S.},
	month = dec,
	year = {2013},
	doi = {10.1137/1.9781611973402.64},
	pages = {861--873},
	file = {Full Text PDF:/Users/oliverbiggar/Zotero/storage/2XHSVLVE/Piliouras and Shamma - 2013 - Optimization Despite Chaos Convex Relaxations to .pdf:application/pdf},
}

@misc{czechowski_poincare-bendixson_2022,
	title = {Poincar{\textbackslash}'\{e\}-{Bendixson} {Limit} {Sets} in {Multi}-{Agent} {Learning}},
	url = {http://arxiv.org/abs/2102.00053},
	doi = {10.48550/arXiv.2102.00053},
	abstract = {A key challenge of evolutionary game theory and multi-agent learning is to characterize the limit behavior of game dynamics. Whereas convergence is often a property of learning algorithms in games satisfying a particular reward structure (e.g., zero-sum games), even basic learning models, such as the replicator dynamics, are not guaranteed to converge for general payoffs. Worse yet, chaotic behavior is possible even in rather simple games, such as variants of the Rock-Paper-Scissors game. Although chaotic behavior in learning dynamics can be precluded by the celebrated Poincar{\textbackslash}'e-Bendixson theorem, it is only applicable to low-dimensional settings. Are there other characteristics of a game that can force regularity in the limit sets of learning? We show that behavior consistent with the Poincar{\textbackslash}'e-Bendixson theorem (limit cycles, but no chaotic attractor) can follow purely from the topological structure of the interaction graph, even for high-dimensional settings with an arbitrary number of players and arbitrary payoff matrices. We prove our result for a wide class of follow-the-regularized leader (FoReL) dynamics, which generalize replicator dynamics, for binary games characterized interaction graphs where the payoffs of each player are only affected by one other player (i.e., interaction graphs of indegree one). Since chaos occurs already in games with only two players and three strategies, this class of non-chaotic games may be considered maximal. Moreover, we provide simple conditions under which such behavior translates into efficiency guarantees, implying that FoReL learning achieves time-averaged sum of payoffs at least as good as that of a Nash equilibrium, thereby connecting the topology of the dynamics to social-welfare analysis.},
	urldate = {2023-07-18},
	publisher = {arXiv},
	author = {Czechowski, Aleksander and Piliouras, Georgios},
	month = feb,
	year = {2022},
	note = {arXiv:2102.00053 [cs]},
	keywords = {91A22, 91A26, Computer Science - Computer Science and Game Theory, Computer Science - Multiagent Systems},
	file = {arXiv Fulltext PDF:/Users/oliverbiggar/Zotero/storage/8LAJARZD/Czechowski and Piliouras - 2022 - Poincar' e -Bendixson Limit Sets in Multi-Agent L.pdf:application/pdf;arXiv.org Snapshot:/Users/oliverbiggar/Zotero/storage/FUQWGD2I/2102.html:text/html},
}

@article{akin_evolutionary_1984,
	title = {Evolutionary dynamics of zero-sum games},
	volume = {20},
	issn = {0303-6812},
	journal = {Journal of mathematical biology},
	author = {Akin, Ethan and Losert, Viktor},
	year = {1984},
	note = {Publisher: Citeseer},
	pages = {231--258},
	file = {Akin and Losert - 1984 - Evolutionary dynamics of zero-sum games.pdf:/Users/oliverbiggar/Zotero/storage/GENW9PML/Akin and Losert - 1984 - Evolutionary dynamics of zero-sum games.pdf:application/pdf},
}

@article{debreu_topological_1959,
	title = {Topological methods in cardinal utility theory},
	author = {Debreu, Gerard},
	year = {1959},
	file = {Debreu - 1959 - Topological methods in cardinal utility theory.pdf:/Users/oliverbiggar/Zotero/storage/JPWJKVUH/Debreu - 1959 - Topological methods in cardinal utility theory.pdf:application/pdf},
}

@misc{pieroth_alpha-rank-collections_2022,
	title = {\${\textbackslash}alpha\$-{Rank}-{Collections}: {Analyzing} {Expected} {Strategic} {Behavior} with {Uncertain} {Utilities}},
	shorttitle = {\${\textbackslash}alpha\$-{Rank}-{Collections}},
	url = {http://arxiv.org/abs/2211.10317},
	doi = {10.48550/arXiv.2211.10317},
	abstract = {Game theory largely rests on the availability of cardinal utility functions. In contrast, only ordinal preferences are elicited in fields such as matching under preferences. The literature focuses on mechanisms with simple dominant strategies. However, many real-world applications do not have dominant strategies, so intensities between preferences matter when participants determine their strategies. Even though precise information about cardinal utilities is unavailable, some data about the likelihood of utility functions is typically accessible. We propose to use Bayesian games to formalize uncertainty about decision-makers utilities by viewing them as a collection of normal-form games where uncertainty about types persist in all game stages. Instead of searching for the Bayes-Nash equilibrium, we consider the question of how uncertainty in utilities is reflected in uncertainty of strategic play. We introduce \${\textbackslash}alpha\$-Rank-collections as a solution concept that extends \${\textbackslash}alpha\$-Rank, a new solution concept for normal-form games, to Bayesian games. This allows us to analyze the strategic play in, for example, (non-strategyproof) matching markets, for which we do not have appropriate solution concepts so far. \${\textbackslash}alpha\$-Rank-collections characterize a range of strategy-profiles emerging from replicator dynamics of the game rather than equilibrium point. We prove that \${\textbackslash}alpha\$-Rank-collections are invariant to positive affine transformations, and that they are efficient to approximate. An instance of the Boston mechanism is used to illustrate the new solution concept.},
	urldate = {2023-07-19},
	publisher = {arXiv},
	author = {Pieroth, Fabian R. and Bichler, Martin},
	month = nov,
	year = {2022},
	note = {arXiv:2211.10317 [cs, econ]},
	keywords = {Computer Science - Computer Science and Game Theory, Computer Science - Multiagent Systems, Economics - Theoretical Economics},
	file = {arXiv Fulltext PDF:/Users/oliverbiggar/Zotero/storage/KQSLXXDD/Pieroth and Bichler - 2022 - \$alpha\$-Rank-Collections Analyzing Expected Stra.pdf:application/pdf;arXiv.org Snapshot:/Users/oliverbiggar/Zotero/storage/L8VEXY9G/2211.html:text/html},
}

@article{hofbauer_evolutionary_2003,
	title = {Evolutionary game dynamics},
	volume = {40},
	issn = {0273-0979, 1088-9485},
	url = {https://www.ams.org/bull/2003-40-04/S0273-0979-03-00988-1/},
	doi = {10.1090/S0273-0979-03-00988-1},
	abstract = {Advancing research. Creating connections.},
	language = {en},
	number = {4},
	urldate = {2023-07-19},
	journal = {Bulletin of the American Mathematical Society},
	author = {Hofbauer, Josef and Sigmund, Karl},
	year = {2003},
	pages = {479--519},
	file = {Full Text PDF:/Users/oliverbiggar/Zotero/storage/FNVFRMJK/Hofbauer and Sigmund - 2003 - Evolutionary game dynamics.pdf:application/pdf},
}

@book{dresher_advances_2016,
	title = {Advances in {Game} {Theory}. ({AM}-52), {Volume} 52},
	isbn = {978-1-4008-8201-4},
	abstract = {The description for this book, Advances in Game Theory. (AM-52), Volume 52, will be forthcoming.},
	language = {en},
	publisher = {Princeton University Press},
	author = {Dresher, Melvin and Shapley, Lloyd S. and Tucker, Albert William},
	month = mar,
	year = {2016},
	note = {Google-Books-ID: X9zTCwAAQBAJ},
	keywords = {Mathematics / Game Theory},
	file = {Dresher et al. - 2016 - Advances in Game Theory. (AM-52), Volume 52.pdf:/Users/oliverbiggar/Zotero/storage/JDUWDR7V/Dresher et al. - 2016 - Advances in Game Theory. (AM-52), Volume 52.pdf:application/pdf},
}

@inproceedings{papadimitriou_public_2021,
	address = {New York, NY, USA},
	series = {{EC} '21},
	title = {Public {Goods} {Games} in {Directed} {Networks}},
	isbn = {978-1-4503-8554-1},
	url = {https://dl.acm.org/doi/10.1145/3465456.3467616},
	doi = {10.1145/3465456.3467616},
	abstract = {Public goods games in undirected networks are generally known to have pure Nash equilibria, which are easy to find. In contrast, we prove that, in directed networks, a broad range of public goods games have intractable equilibrium problems: The existence of pure Nash equilibria is NP-hard to decide, and mixed Nash equilibria are PPAD-hard to find. We define general utility public goods games, and prove a complexity dichotomy result for finding pure equilibria, and a PPAD-completeness proof for mixed Nash equilibria. Even in the divisible goods variant of the problem, where existence is easy to prove, finding the equilibrium is PPAD-complete. Finally, when the treewidth of the directed network is appropriately bounded, we prove that polynomial-time algorithms are possible.},
	urldate = {2023-07-18},
	booktitle = {Proceedings of the 22nd {ACM} {Conference} on {Economics} and {Computation}},
	publisher = {Association for Computing Machinery},
	author = {Papadimitriou, Christos and Peng, Binghui},
	month = jul,
	year = {2021},
	keywords = {equilibrium computation, network game, public goods game},
	pages = {745--762},
	file = {Full Text PDF:/Users/oliverbiggar/Zotero/storage/BJ5ZLK24/Papadimitriou and Peng - 2021 - Public Goods Games in Directed Networks.pdf:application/pdf},
}

@misc{govindan_refinements_2005,
	address = {Rochester, NY},
	type = {{SSRN} {Scholarly} {Paper}},
	title = {Refinements of {Nash} {Equilibrium}},
	url = {https://papers.ssrn.com/abstract=772081},
	doi = {10.2139/ssrn.772081},
	abstract = {This paper describes ways that the definition of an equilibrium among players' strategies in a game can be sharpened by invoking additional criteria derived from decision theory. Refinements of John Nash's 1950 definition aim primarily to distinguish equilibria in which implicit commitments are credible due to incentives. One group of refinements requires sequential rationality as the game progresses. Another ensures credibility by considering perturbed games in which every contingency occurs with positive probability, which has the further advantage of excluding weakly dominated strategies.},
	language = {en},
	urldate = {2023-07-19},
	author = {Govindan, Srihari and Wilson, Robert},
	month = jul,
	year = {2005},
	keywords = {economic theory},
	file = {Full Text PDF:/Users/oliverbiggar/Zotero/storage/JI6HU683/Govindan and Wilson - 2005 - Refinements of Nash Equilibrium.pdf:application/pdf},
}

@article{hofbauer_time_2009,
	title = {Time {Average} {Replicator} and {Best}-{Reply} {Dynamics}},
	volume = {34},
	issn = {0364-765X},
	url = {https://pubsonline.informs.org/doi/abs/10.1287/moor.1080.0359},
	doi = {10.1287/moor.1080.0359},
	abstract = {Using an explicit representation in terms of the logit map, we show, in a unilateral framework, that the time average of the replicator dynamics is a perturbed solution of the best-reply dynamics.},
	number = {2},
	urldate = {2023-07-19},
	journal = {Mathematics of Operations Research},
	author = {Hofbauer, Josef and Sorin, Sylvain and Viossat, Yannick},
	month = may,
	year = {2009},
	note = {Publisher: INFORMS},
	keywords = {attractor, best-reply dynamics, internally chain transitive set, logit map, perturbed differential inclusion, replicator dynamics},
	pages = {263--269},
	file = {Submitted Version:/Users/oliverbiggar/Zotero/storage/QBJXJIKC/Hofbauer et al. - 2009 - Time Average Replicator and Best-Reply Dynamics.pdf:application/pdf},
}

@article{brandt_ordinal_2016,
	title = {An ordinal minimax theorem},
	volume = {95},
	issn = {0899-8256},
	url = {https://www.sciencedirect.com/science/article/pii/S0899825615001670},
	doi = {10.1016/j.geb.2015.12.010},
	abstract = {In the early 1950s Lloyd Shapley proposed an ordinal and set-valued solution concept for zero-sum games called weak saddle. We show that all weak saddles of a given zero-sum game are interchangeable and equivalent. As a consequence, every such game possesses a unique set-based value.},
	language = {en},
	urldate = {2023-07-19},
	journal = {Games and Economic Behavior},
	author = {Brandt, Felix and Brill, Markus and Suksompong, Warut},
	month = jan,
	year = {2016},
	keywords = {Zero-sum games, Minimax theorem, Saddles, Shapley},
	pages = {107--112},
	file = {ScienceDirect Snapshot:/Users/oliverbiggar/Zotero/storage/CDHFIQBU/S0899825615001670.html:text/html;Submitted Version:/Users/oliverbiggar/Zotero/storage/YAK3TB5A/Brandt et al. - 2016 - An ordinal minimax theorem.pdf:application/pdf},
}

@misc{czechowski_safe_2023,
	title = {Safe {Multi}-agent {Learning} via {Trapping} {Regions}},
	url = {http://arxiv.org/abs/2302.13844},
	doi = {10.48550/arXiv.2302.13844},
	abstract = {One of the main challenges of multi-agent learning lies in establishing convergence of the algorithms, as, in general, a collection of individual, self-serving agents is not guaranteed to converge with their joint policy, when learning concurrently. This is in stark contrast to most single-agent environments, and sets a prohibitive barrier for deployment in practical applications, as it induces uncertainty in long term behavior of the system. In this work, we apply the concept of trapping regions, known from qualitative theory of dynamical systems, to create safety sets in the joint strategy space for decentralized learning. We propose a binary partitioning algorithm for verification that candidate sets form trapping regions in systems with known learning dynamics, and a heuristic sampling algorithm for scenarios where learning dynamics are not known. We demonstrate the applications to a regularized version of Dirac Generative Adversarial Network, a four-intersection traffic control scenario run in a state of the art open-source microscopic traffic simulator SUMO, and a mathematical model of economic competition.},
	urldate = {2023-07-19},
	publisher = {arXiv},
	author = {Czechowski, Aleksander and Oliehoek, Frans A.},
	month = may,
	year = {2023},
	note = {arXiv:2302.13844 [cs]},
	keywords = {Computer Science - Multiagent Systems, Computer Science - Artificial Intelligence},
	file = {arXiv Fulltext PDF:/Users/oliverbiggar/Zotero/storage/MYN52WGD/Czechowski and Oliehoek - 2023 - Safe Multi-agent Learning via Trapping Regions.pdf:application/pdf;arXiv.org Snapshot:/Users/oliverbiggar/Zotero/storage/XV9JL8XP/2302.html:text/html},
}

@inproceedings{barasz_new_2010,
	title = {A {New} {Approach} to {Strongly} {Polynomial} {Linear} {Programming}.},
	author = {Bárász, Mihály and Vempala, Santosh S},
	year = {2010},
	pages = {42--48},
	file = {Bárász and Vempala - 2010 - A New Approach to Strongly Polynomial Linear Progr.pdf:/Users/oliverbiggar/Zotero/storage/QDK9GKFP/Bárász and Vempala - 2010 - A New Approach to Strongly Polynomial Linear Progr.pdf:application/pdf},
}

@misc{kwon_continuous-time_2014,
	title = {A continuous-time approach to online optimization},
	url = {http://arxiv.org/abs/1401.6956},
	doi = {10.48550/arXiv.1401.6956},
	abstract = {We consider a family of learning strategies for online optimization problems that evolve in continuous time and we show that they lead to no regret. From a more traditional, discrete-time viewpoint, this continuous-time approach allows us to derive the no-regret properties of a large class of discrete-time algorithms including as special cases the exponential weight algorithm, online mirror descent, smooth fictitious play and vanishingly smooth fictitious play. In so doing, we obtain a unified view of many classical regret bounds, and we show that they can be decomposed into a term stemming from continuous-time considerations and a term which measures the disparity between discrete and continuous time. As a result, we obtain a general class of infinite horizon learning strategies that guarantee an \${\textbackslash}mathcal\{O\}(n{\textasciicircum}\{-1/2\})\$ regret bound without having to resort to a doubling trick.},
	urldate = {2023-07-19},
	publisher = {arXiv},
	author = {Kwon, Joon and Mertikopoulos, Panayotis},
	month = feb,
	year = {2014},
	note = {arXiv:1401.6956 [cs, math, stat]},
	keywords = {Computer Science - Machine Learning, Mathematics - Optimization and Control, Statistics - Machine Learning},
	file = {arXiv Fulltext PDF:/Users/oliverbiggar/Zotero/storage/JL6HSJYK/Kwon and Mertikopoulos - 2014 - A continuous-time approach to online optimization.pdf:application/pdf;arXiv.org Snapshot:/Users/oliverbiggar/Zotero/storage/S2EZUW26/1401.html:text/html},
}

@misc{muthukumar_impossibility_2022,
	title = {On the {Impossibility} of {Convergence} of {Mixed} {Strategies} with {No} {Regret} {Learning}},
	url = {http://arxiv.org/abs/2012.02125},
	doi = {10.48550/arXiv.2012.02125},
	abstract = {We study the limiting behavior of the mixed strategies that result from optimal no-regret learning strategies in a repeated game setting where the stage game is any 2 by 2 competitive game. We consider optimal no-regret algorithms that are mean-based and monotonic in their argument. We show that for any such algorithm, the limiting mixed strategies of the players cannot converge almost surely to any Nash equilibrium. This negative result is also shown to hold under a broad relaxation of these assumptions, including popular variants of Online-Mirror-Descent with optimism and/or adaptive step-sizes. Finally, we conjecture that the monotonicity assumption can be removed, and provide partial evidence for this conjecture. Our results identify the inherent stochasticity in players' realizations as a critical factor underlying this divergence in outcomes between using the opponent's mixtures and realizations to make updates.},
	urldate = {2023-07-19},
	publisher = {arXiv},
	author = {Muthukumar, Vidya and Phade, Soham and Sahai, Anant},
	month = mar,
	year = {2022},
	note = {arXiv:2012.02125 [cs, stat]},
	keywords = {Computer Science - Computer Science and Game Theory, Statistics - Machine Learning},
	file = {arXiv Fulltext PDF:/Users/oliverbiggar/Zotero/storage/UJV7YSSI/Muthukumar et al. - 2022 - On the Impossibility of Convergence of Mixed Strat.pdf:application/pdf;arXiv.org Snapshot:/Users/oliverbiggar/Zotero/storage/9HFKLYFL/2012.html:text/html},
}

@inproceedings{syrgkanis_fast_2015,
	title = {Fast {Convergence} of {Regularized} {Learning} in {Games}},
	volume = {28},
	url = {https://proceedings.neurips.cc/paper/2015/hash/7fea637fd6d02b8f0adf6f7dc36aed93-Abstract.html},
	urldate = {2023-07-19},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	publisher = {Curran Associates, Inc.},
	author = {Syrgkanis, Vasilis and Agarwal, Alekh and Luo, Haipeng and Schapire, Robert E},
	year = {2015},
	file = {Full Text PDF:/Users/oliverbiggar/Zotero/storage/U7KMCFVT/Syrgkanis et al. - 2015 - Fast Convergence of Regularized Learning in Games.pdf:application/pdf},
}

@inproceedings{palaiopanos_multiplicative_2017,
	title = {Multiplicative {Weights} {Update} with {Constant} {Step}-{Size} in {Congestion} {Games}: {Convergence}, {Limit} {Cycles} and {Chaos}},
	volume = {30},
	shorttitle = {Multiplicative {Weights} {Update} with {Constant} {Step}-{Size} in {Congestion} {Games}},
	url = {https://proceedings.neurips.cc/paper_files/paper/2017/hash/e93028bdc1aacdfb3687181f2031765d-Abstract.html},
	urldate = {2023-07-19},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	publisher = {Curran Associates, Inc.},
	author = {Palaiopanos, Gerasimos and Panageas, Ioannis and Piliouras, Georgios},
	year = {2017},
	file = {Full Text PDF:/Users/oliverbiggar/Zotero/storage/B7JQW9FV/Palaiopanos et al. - 2017 - Multiplicative Weights Update with Constant Step-S.pdf:application/pdf},
}

@article{gaunersdorfer_fictitious_1995,
	title = {Fictitious {Play}, {Shapley} {Polygons}, and the {Replicator} {Equation}},
	volume = {11},
	issn = {0899-8256},
	url = {https://www.sciencedirect.com/science/article/pii/S0899825685710524},
	doi = {10.1006/game.1995.1052},
	abstract = {For many normal form games, the limiting behavior of fictitious play and the time-averaged replicator dynamics coincide. In particular, we show this for three examples, where this limit is not a Nash equilibrium, but a Shapley polygon. Journal of Economic Literature Classification Numbers: C72, C73.},
	language = {en},
	number = {2},
	urldate = {2023-07-19},
	journal = {Games and Economic Behavior},
	author = {Gaunersdorfer, Andrea and Hofbauer, Josef},
	month = nov,
	year = {1995},
	pages = {279--303},
	file = {Gaunersdorfer and Hofbauer - 1995 - Fictitious Play, Shapley Polygons, and the Replica.pdf:/Users/oliverbiggar/Zotero/storage/4FEC2CS3/Gaunersdorfer and Hofbauer - 1995 - Fictitious Play, Shapley Polygons, and the Replica.pdf:application/pdf;ScienceDirect Snapshot:/Users/oliverbiggar/Zotero/storage/7YXIMXE8/S0899825685710524.html:text/html},
}

@article{shamma_dynamic_2005,
	title = {Dynamic fictitious play, dynamic gradient play, and distributed convergence to {Nash} equilibria},
	volume = {50},
	issn = {1558-2523},
	doi = {10.1109/TAC.2005.843878},
	abstract = {We consider a continuous-time form of repeated matrix games in which player strategies evolve in reaction to opponent actions. Players observe each other's actions, but do not have access to other player utilities. Strategy evolution may be of the best response sort, as in fictitious play, or a gradient update. Such mechanisms are known to not necessarily converge. We introduce a form of "dynamic" fictitious and gradient play strategy update mechanisms. These mechanisms use derivative action in processing opponent actions and, in some cases, can lead to behavior converging to Nash equilibria in previously nonconvergent situations. We analyze convergence in the case of exact and approximate derivative measurements of the dynamic update mechanisms. In the ideal case of exact derivative measurements, we show that convergence to Nash equilibrium can always be achieved. In the case of approximate derivative measurements, we derive a characterization of local convergence that shows how the dynamic update mechanisms can converge if the traditional static counterparts do not. We primarily discuss two player games, but also outline extensions to multiplayer games. We illustrate these methods with convergent simulations of the well known Shapley and Jordan counterexamples.},
	number = {3},
	journal = {IEEE Transactions on Automatic Control},
	author = {Shamma, J.S. and Arslan, G.},
	month = mar,
	year = {2005},
	note = {Conference Name: IEEE Transactions on Automatic Control},
	keywords = {Nash equilibrium, Convergence, Adders, Aerospace engineering, Conference proceedings, Frequency, Probability distribution},
	pages = {312--327},
	file = {IEEE Xplore Abstract Record:/Users/oliverbiggar/Zotero/storage/LNYGD2AA/1406126.html:text/html},
}

@article{jagadeesan_learning_2023,
	title = {Learning {Equilibria} in {Matching} {Markets} with {Bandit} {Feedback}},
	volume = {70},
	issn = {0004-5411},
	url = {https://dl.acm.org/doi/10.1145/3583681},
	doi = {10.1145/3583681},
	abstract = {Large-scale, two-sided matching platforms must find market outcomes that align with user preferences while simultaneously learning these preferences from data. Classical notions of stability (Gale and Shapley, 1962; Shapley and Shubik, 1971) are, unfortunately, of limited value in the learning setting, given that preferences are inherently uncertain and destabilizing while they are being learned. To bridge this gap, we develop a framework and algorithms for learning stable market outcomes under uncertainty. Our primary setting is matching with transferable utilities, where the platform both matches agents and sets monetary transfers between them. We design an incentive-aware learning objective that captures the distance of a market outcome from equilibrium. Using this objective, we analyze the complexity of learning as a function of preference structure, casting learning as a stochastic multi-armed bandit problem. Algorithmically, we show that “optimism in the face of uncertainty,” the principle underlying many bandit algorithms, applies to a primal-dual formulation of matching with transfers and leads to near-optimal regret bounds. Our work takes a first step toward elucidating when and how stable matchings arise in large, data-driven marketplaces.},
	number = {3},
	urldate = {2023-07-20},
	journal = {Journal of the ACM},
	author = {Jagadeesan, Meena and Wei, Alexander and Wang, Yixin and Jordan, Michael I. and Steinhardt, Jacob},
	month = may,
	year = {2023},
	keywords = {learning equilibria, Multi-armed bandits, preference structure, stable matchings},
	pages = {19:1--19:46},
	file = {Full Text PDF:/Users/oliverbiggar/Zotero/storage/C6KVKV6S/Jagadeesan et al. - 2023 - Learning Equilibria in Matching Markets with Bandi.pdf:application/pdf},
}

@inproceedings{anagnostides_last-iterate_2022,
	title = {On {Last}-{Iterate} {Convergence} {Beyond} {Zero}-{Sum} {Games}},
	url = {https://proceedings.mlr.press/v162/anagnostides22a.html},
	abstract = {Most existing results about last-iterate convergence of learning dynamics are limited to two-player zero-sum games, and only apply under rigid assumptions about what dynamics the players follow. In this paper we provide new results and techniques that apply to broader families of games and learning dynamics. First, we show that in a class of games that includes constant-sum polymatrix and strategically zero-sum games, the trajectories of dynamics such as optimistic mirror descent (OMD) exhibit a boundedness property, which holds even when players employ different algorithms and prediction mechanisms. This property enables us to obtain ��(1/��‾‾√)O(1/T)O(1/{\textbackslash}sqrt\{T\}) rates and optimal ��(1)O(1)O(1) regret bounds. Our analysis also reveals a surprising property: OMD either reaches arbitrarily close to a Nash equilibrium or it outperforms the robust price of anarchy in efficiency. Moreover, for potential games we establish convergence to an ��ϵ{\textbackslash}epsilon-equilibrium after ��(1/��2)O(1/ϵ2)O(1/{\textbackslash}epsilon{\textasciicircum}2) iterations for mirror descent under a broad class of regularizers, as well as optimal ��(1)O(1)O(1) regret bounds for OMD variants. Our framework also extends to near-potential games, and unifies known analyses for distributed learning in Fisher’s market model. Finally, we analyze the convergence, efficiency, and robustness of optimistic gradient descent (OGD) in general-sum continuous games.},
	language = {en},
	urldate = {2023-07-20},
	booktitle = {Proceedings of the 39th {International} {Conference} on {Machine} {Learning}},
	publisher = {PMLR},
	author = {Anagnostides, Ioannis and Panageas, Ioannis and Farina, Gabriele and Sandholm, Tuomas},
	month = jun,
	year = {2022},
	note = {ISSN: 2640-3498},
	pages = {536--581},
	file = {Full Text PDF:/Users/oliverbiggar/Zotero/storage/VW3ACM5Q/Anagnostides et al. - 2022 - On Last-Iterate Convergence Beyond Zero-Sum Games.pdf:application/pdf},
}

@article{guo_leveraging_2023,
	title = {Leveraging {Reviews}: {Learning} to {Price} with {Buyer} and {Seller} {Uncertainty}},
	journal = {arXiv preprint arXiv:2302.09700},
	author = {Guo, Wenshuo and Haghtalab, Nika and Kandasamy, Kirthevasan and Vitercik, Ellen},
	year = {2023},
}

@misc{sakos_discovering_2023,
	title = {Discovering {How} {Agents} {Learn} {Using} {Few} {Data}},
	url = {http://arxiv.org/abs/2307.06640},
	doi = {10.48550/arXiv.2307.06640},
	abstract = {Decentralized learning algorithms are an essential tool for designing multi-agent systems, as they enable agents to autonomously learn from their experience and past interactions. In this work, we propose a theoretical and algorithmic framework for real-time identification of the learning dynamics that govern agent behavior using a short burst of a single system trajectory. Our method identifies agent dynamics through polynomial regression, where we compensate for limited data by incorporating side-information constraints that capture fundamental assumptions or expectations about agent behavior. These constraints are enforced computationally using sum-of-squares optimization, leading to a hierarchy of increasingly better approximations of the true agent dynamics. Extensive experiments demonstrated that our approach, using only 5 samples from a short run of a single trajectory, accurately recovers the true dynamics across various benchmarks, including equilibrium selection and prediction of chaotic systems up to 10 Lyapunov times. These findings suggest that our approach has significant potential to support effective policy and decision-making in strategic multi-agent systems.},
	urldate = {2023-07-21},
	publisher = {arXiv},
	author = {Sakos, Iosif and Varvitsiotis, Antonios and Piliouras, Georgios},
	month = jul,
	year = {2023},
	note = {arXiv:2307.06640 [cs, math]},
	keywords = {Computer Science - Computer Science and Game Theory, Computer Science - Machine Learning, Mathematics - Optimization and Control},
	file = {arXiv Fulltext PDF:/Users/oliverbiggar/Zotero/storage/EX6SDB9B/Sakos et al. - 2023 - Discovering How Agents Learn Using Few Data.pdf:application/pdf;arXiv.org Snapshot:/Users/oliverbiggar/Zotero/storage/27C4V88U/2307.html:text/html},
}

@misc{maiti_logarithmic_2023,
	title = {Logarithmic {Regret} for {Matrix} {Games} against an {Adversary} with {Noisy} {Bandit} {Feedback}},
	url = {http://arxiv.org/abs/2306.13233},
	doi = {10.48550/arXiv.2306.13233},
	abstract = {This paper considers a variant of zero-sum matrix games where at each timestep the row player chooses row \$i\$, the column player chooses column \$j\$, and the row player receives a noisy reward with mean \$A\_\{i,j\}\$. The objective of the row player is to accumulate as much reward as possible, even against an adversarial column player. If the row player uses the EXP3 strategy, an algorithm known for obtaining \${\textbackslash}sqrt\{T\}\$ regret against an arbitrary sequence of rewards, it is immediate that the row player also achieves \${\textbackslash}sqrt\{T\}\$ regret relative to the Nash equilibrium in this game setting. However, partly motivated by the fact that the EXP3 strategy is myopic to the structure of the game, O'Donoghue et al. (2021) proposed a UCB-style algorithm that leverages the game structure and demonstrated that this algorithm greatly outperforms EXP3 empirically. While they showed that this UCB-style algorithm achieved \${\textbackslash}sqrt\{T\}\$ regret, in this paper we ask if there exists an algorithm that provably achieves \${\textbackslash}text\{polylog\}(T)\$ regret against any adversary, analogous to results from stochastic bandits. We propose a novel algorithm that answers this question in the affirmative for the simple \$2 {\textbackslash}times 2\$ setting, providing the first instance-dependent guarantees for games in the regret setting. Our algorithm overcomes two major hurdles: 1) obtaining logarithmic regret even though the Nash equilibrium is estimable only at a \$1/{\textbackslash}sqrt\{T\}\$ rate, and 2) designing row-player strategies that guarantee that either the adversary provides information about the Nash equilibrium, or the row player incurs negative regret. Moreover, in the full information case we address the general \$n {\textbackslash}times m\$ case where the first hurdle is still relevant. Finally, we show that EXP3 and the UCB-based algorithm necessarily cannot perform better than \${\textbackslash}sqrt\{T\}\$.},
	urldate = {2023-07-21},
	publisher = {arXiv},
	author = {Maiti, Arnab and Jamieson, Kevin and Ratliff, Lillian J.},
	month = jun,
	year = {2023},
	note = {arXiv:2306.13233 [cs]},
	keywords = {Computer Science - Computer Science and Game Theory, Computer Science - Machine Learning},
	file = {arXiv Fulltext PDF:/Users/oliverbiggar/Zotero/storage/Q52HZNFU/Maiti et al. - 2023 - Logarithmic Regret for Matrix Games against an Adv.pdf:application/pdf;arXiv.org Snapshot:/Users/oliverbiggar/Zotero/storage/VG2HXN2G/2306.html:text/html},
}

@inproceedings{kanellopoulos_meta-learning_2020,
	title = {A {Meta}-{Learning} and {Bounded} {Rationality} {Framework} for {Repeated} {Games} in {Adversarial} {Environments}},
	doi = {10.1109/CDC42340.2020.9303995},
	abstract = {In this work, a meta-learning framework for games between adapting players is proposed. An agent with increased cognitive abilities is augmented with a structure that allows them to identify the way that their opponents learn during the game. This is achieved via approximators that are tuned online leveraging only observed actions from the environment. We show that knowledge of the utilities of the opponents enable asymptotic convergence of the approximation weights. We, then, extend the framework via backpropagation through time such that knowledge of the utilities is not necessary and we show convergence of the errors to a residual set. Finally, simulations of players learning in a penny matching game demonstrate the efficacy of our approach.},
	booktitle = {2020 59th {IEEE} {Conference} on {Decision} and {Control} ({CDC})},
	author = {Kanellopoulos, Aris and Fotiadis, Filippos and Vamvoudakis, Kyriakos G. and Gupta, Vijay},
	month = dec,
	year = {2020},
	note = {ISSN: 2576-2370},
	keywords = {Convergence, Adaptation models, back-propagation, bounded rationality, deception, Games, Heuristic algorithms, IP networks, Learning in games, security, Tools, Vehicle dynamics},
	pages = {1640--1645},
	file = {IEEE Xplore Abstract Record:/Users/oliverbiggar/Zotero/storage/I79L9N56/9303995.html:text/html},
}

@article{vundurthy_intelligent_2023,
	title = {Intelligent {Players} in a {Fictitious} {Play} {Framework}},
	issn = {1558-2523},
	doi = {10.1109/TAC.2023.3266505},
	abstract = {Fictitious play is a popular learning algorithm in which players that utilize the history of actions played by the players and the knowledge of their own payoff matrix can converge to the Nash equilibrium under certain conditions on the game. We consider the presence of an intelligent player that has access to the entire payoff matrix for the game. We show that by not conforming to fictitious play, such a player can achieve a better payoff than the one at the Nash Equilibrium. This result can be viewed both as a fragility of the fictitious play algorithm to a strategic intelligent player and an indication that players should not throw away additional information they may have, as suggested by classical fictitious play.},
	journal = {IEEE Transactions on Automatic Control},
	author = {Vundurthy, Bhaskar and Kanellopoulos, Aris and Gupta, Vijay and Vamvoudakis, Kyriakos G.},
	year = {2023},
	note = {Conference Name: IEEE Transactions on Automatic Control},
	keywords = {Nash equilibrium, Convergence, Games, IP networks, Absorption, Standards, Trajectory},
	pages = {1--8},
	file = {Submitted Version:/Users/oliverbiggar/Zotero/storage/74WXYFKT/Vundurthy et al. - 2023 - Intelligent Players in a Fictitious Play Framework.pdf:application/pdf},
}

@article{amiet_when_2021,
	title = {When “{Better}” is better than “{Best}”},
	volume = {49},
	issn = {0167-6377},
	number = {2},
	journal = {Operations Research Letters},
	author = {Amiet, Ben and Collevecchio, Andrea and Hamza, Kais},
	year = {2021},
	note = {Publisher: Elsevier},
	pages = {260--264},
	file = {Amiet et al. - 2021 - When “Better” is better than “Best”.pdf:/Users/oliverbiggar/Zotero/storage/2QPQJB9A/Amiet et al. - 2021 - When “Better” is better than “Best”.pdf:application/pdf},
}

@inproceedings{chen_new_2019,
	title = {A {New} {Algorithm} for {Non}-stationary {Contextual} {Bandits}: {Efficient}, {Optimal} and {Parameter}-free},
	shorttitle = {A {New} {Algorithm} for {Non}-stationary {Contextual} {Bandits}},
	url = {https://proceedings.mlr.press/v99/chen19b.html},
	abstract = {We propose the first contextual bandit algorithm that is parameter-free, efficient, and optimal in terms of dynamic regret. Specifically, our algorithm achieves (min\{������‾‾‾‾‾√,��13Δ13��23\})O(min\{KST,K13Δ13T23\}){\textbackslash}mathcal\{O\}({\textbackslash}min{\textbackslash}\{{\textbackslash}sqrt\{KST\}, K{\textasciicircum}\{{\textbackslash}frac\{1\}\{3\}\}{\textbackslash}Delta {\textasciicircum}\{{\textbackslash}frac\{1\}\{3\}\}T{\textasciicircum}\{{\textbackslash}frac\{2\}\{3\}\}{\textbackslash}\}) dynamic regret for a contextual bandit problem with ��TT rounds, ��KK actions, ��SS switches and ΔΔ{\textbackslash}Delta total variation in data distributions. Importantly, our algorithm is adaptive and does not need to know ��SS or ΔΔ{\textbackslash}Delta ahead of time, and can be implemented efficiently assuming access to an ERM oracle. Our results strictly improve the (min\{��14��34,Δ15��45\})O(min\{S14T34,Δ15T45\}){\textbackslash}mathcal\{O\} ({\textbackslash}min {\textbackslash}\{S{\textasciicircum}\{{\textbackslash}frac\{1\}\{4\}\}T{\textasciicircum}\{{\textbackslash}frac\{3\}\{4\}\}, {\textbackslash}Delta{\textasciicircum}\{{\textbackslash}frac\{1\}\{5\}\}T{\textasciicircum}\{{\textbackslash}frac\{4\}\{5\}\}{\textbackslash}\}) bound of (Luo et al., 2018), and greatly generalize and improve the (����‾‾‾√)O(ST){\textbackslash}mathcal\{O\}({\textbackslash}sqrt\{ST\}) result of (Auer et al., 2018) that holds only for the two-armed bandit problem without contextual information. The key novelty of our algorithm is to introduce \{{\textbackslash}it replay phases\}, in which the algorithm acts according to its previous decisions for a certain amount of time in order to detect non-stationarity while maintaining a good balance between exploration and exploitation.},
	language = {en},
	urldate = {2023-07-25},
	booktitle = {Proceedings of the {Thirty}-{Second} {Conference} on {Learning} {Theory}},
	publisher = {PMLR},
	author = {Chen, Yifang and Lee, Chung-Wei and Luo, Haipeng and Wei, Chen-Yu},
	month = jun,
	year = {2019},
	note = {ISSN: 2640-3498},
	pages = {696--726},
	file = {Full Text PDF:/Users/oliverbiggar/Zotero/storage/DGFSP3VB/Chen et al. - 2019 - A New Algorithm for Non-stationary Contextual Band.pdf:application/pdf},
}

@misc{mertikopoulos_riemannian_2018,
	title = {Riemannian game dynamics},
	url = {http://arxiv.org/abs/1603.09173},
	doi = {10.48550/arXiv.1603.09173},
	abstract = {We study a class of evolutionary game dynamics defined by balancing a gain determined by the game's payoffs against a cost of motion that captures the difficulty with which the population moves between states. Costs of motion are represented by a Riemannian metric, i.e., a state-dependent inner product on the set of population states. The replicator dynamics and the (Euclidean) projection dynamics are the archetypal examples of the class we study. Like these representative dynamics, all Riemannian game dynamics satisfy certain basic desiderata, including positive correlation and global convergence in potential games. Moreover, when the underlying Riemannian metric satisfies a Hessian integrability condition, the resulting dynamics preserve many further properties of the replicator and projection dynamics. We examine the close connections between Hessian game dynamics and reinforcement learning in normal form games, extending and elucidating a well-known link between the replicator dynamics and exponential reinforcement learning.},
	urldate = {2023-07-25},
	publisher = {arXiv},
	author = {Mertikopoulos, Panayotis and Sandholm, WIlliam H.},
	month = apr,
	year = {2018},
	note = {arXiv:1603.09173 [cs, math]},
	keywords = {Computer Science - Computer Science and Game Theory, Mathematics - Optimization and Control, Mathematics - Dynamical Systems, Primary 91A22, 92D25, secondary 91A26, 37N40},
	file = {arXiv Fulltext PDF:/Users/oliverbiggar/Zotero/storage/N7V9TY9H/Mertikopoulos and Sandholm - 2018 - Riemannian game dynamics.pdf:application/pdf;arXiv.org Snapshot:/Users/oliverbiggar/Zotero/storage/T7RTIHPV/1603.html:text/html},
}

@inproceedings{neu_explore_2015,
	title = {Explore no more: {Improved} high-probability regret bounds for non-stochastic bandits},
	volume = {28},
	shorttitle = {Explore no more},
	url = {https://proceedings.neurips.cc/paper/2015/hash/e5a4d6bf330f23a8707bb0d6001dfbe8-Abstract.html},
	urldate = {2023-07-25},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	publisher = {Curran Associates, Inc.},
	author = {Neu, Gergely},
	year = {2015},
	file = {Full Text PDF:/Users/oliverbiggar/Zotero/storage/AD3G8CI8/Neu - 2015 - Explore no more Improved high-probability regret .pdf:application/pdf},
}

@article{auer_nonstochastic_2002,
	title = {The {Nonstochastic} {Multiarmed} {Bandit} {Problem}},
	volume = {32},
	issn = {0097-5397},
	url = {https://epubs.siam.org/doi/abs/10.1137/S0097539701398375},
	doi = {10.1137/S0097539701398375},
	abstract = {We introduce and study a partial-information model of online learning, where a decision maker repeatedly chooses from a finite set of actions and observes some subset of the associated losses. This setting naturally models several situations where knowing the loss of one action provides information on the loss of other actions. Moreover, it generalizes and interpolates between the well-studied full-information setting (where all losses are revealed) and the bandit setting (where only the loss of the action chosen by the player is revealed). We provide several algorithms addressing different variants of our setting and provide tight regret bounds depending on combinatorial properties of the information feedback structure.},
	number = {1},
	urldate = {2023-07-25},
	journal = {SIAM Journal on Computing},
	author = {Auer, Peter and Cesa-Bianchi, Nicolò and Freund, Yoav and Schapire, Robert E.},
	month = jan,
	year = {2002},
	note = {Publisher: Society for Industrial and Applied Mathematics},
	pages = {48--77},
	file = {Full Text PDF:/Users/oliverbiggar/Zotero/storage/DY7PFP2E/Auer et al. - 2002 - The Nonstochastic Multiarmed Bandit Problem.pdf:application/pdf},
}

@inproceedings{marsden_efficient_2022,
	title = {Efficient {Convex} {Optimization} {Requires} {Superlinear} {Memory}},
	url = {https://proceedings.mlr.press/v178/marsden22a.html},
	abstract = {We show that any memory-constrained, first-order algorithm which minimizes ��dd-dimensional, 111-Lipschitz convex functions over the unit ball to 1/poly(��)1/poly(d)1/{\textbackslash}mathrm\{poly\}(d) accuracy using at most ��1.25−��d1.25−δd{\textasciicircum}\{1.25 - {\textbackslash}delta\} bits of memory must make at least Ω(��1+(4/3)��)Ω(d1+(4/3)δ){\textbackslash}Omega(d{\textasciicircum}\{1 + (4/3){\textbackslash}delta\}) first-order queries (for any constant ��∈[0,1/4]δ∈[0,1/4]{\textbackslash}delta {\textbackslash}in [0, 1/4]). Consequently, the performance of such memory-constrained algorithms are a polynomial factor worse than the optimal ��̃ (��)O{\textasciitilde}(d){\textbackslash}tilde\{O\}(d) query bound for this problem obtained by cutting plane methods that use ��̃ (��2)O{\textasciitilde}(d2){\textbackslash}tilde\{O\}(d{\textasciicircum}2) memory. This resolves one of the open problems in the COLT 2019 open problem publication of Woodworth and Srebro.},
	language = {en},
	urldate = {2023-07-25},
	booktitle = {Proceedings of {Thirty} {Fifth} {Conference} on {Learning} {Theory}},
	publisher = {PMLR},
	author = {Marsden, Annie and Sharan, Vatsal and Sidford, Aaron and Valiant, Gregory},
	month = jun,
	year = {2022},
	note = {ISSN: 2640-3498},
	pages = {2390--2430},
	file = {Full Text PDF:/Users/oliverbiggar/Zotero/storage/5HMW4G88/Marsden et al. - 2022 - Efficient Convex Optimization Requires Superlinear.pdf:application/pdf},
}

@inproceedings{kleinberg_multiplicative_2009-1,
	title = {Multiplicative updates outperform generic no-regret learning in congestion games},
	author = {Kleinberg, Robert and Piliouras, Georgios and Tardos, \'Eva},
	year = {2009},
	pages = {533--542},
}

@misc{noauthor_ebscohost_nodate,
	title = {{EBSCOhost} {\textbar} 146122759 {\textbar} {Replicator} dynamics: {Old} and new.},
	url = {https://web.s.ebscohost.com/abstract?direct=true&profile=ehost&scope=site&authtype=crawler&jrnl=21646066&AN=146122759&h=xlILjBIBJKShelSFlgD7MHXWH3eIQ91NTWtSwuUnqox5XrvTUXudM5SnyQaFL%2bWC4MvA0ywWbccWZbWkS%2bcUMw%3d%3d&crl=c&resultNs=AdminWebAuth&resultLocal=ErrCrlNotAuth&crlhashurl=login.aspx%3fdirect%3dtrue%26profile%3dehost%26scope%3dsite%26authtype%3dcrawler%26jrnl%3d21646066%26AN%3d146122759},
	urldate = {2023-07-26},
	file = {EBSCOhost | 146122759 | Replicator dynamics\: Old and new.:/Users/oliverbiggar/Zotero/storage/D5TBAG8U/abstract.html:text/html},
}

@article{sorin_no-regret_2023,
	title = {No-regret algorithms in on-line learning, games and convex optimization},
	issn = {1436-4646},
	url = {https://doi.org/10.1007/s10107-023-01927-7},
	doi = {10.1007/s10107-023-01927-7},
	abstract = {The purpose of this article is to underline the links between some no-regret algorithms used in on-line learning, games and convex optimization and to compare the continuous and discrete time versions.},
	language = {en},
	urldate = {2023-07-26},
	journal = {Mathematical Programming},
	author = {Sorin, Sylvain},
	month = mar,
	year = {2023},
	keywords = {68T05, 68W27, 68W50, 90C25, 91A26},
	file = {Full Text PDF:/Users/oliverbiggar/Zotero/storage/QQ3YJWZG/Sorin - 2023 - No-regret algorithms in on-line learning, games an.pdf:application/pdf},
}

@article{bailey_fast_2019,
	title = {Fast and furious learning in zero-sum games: {Vanishing} regret with non-vanishing step sizes},
	volume = {32},
	journal = {Advances in Neural Information Processing Systems},
	author = {Bailey, James and Piliouras, Georgios},
	year = {2019},
}

@inproceedings{leibo_scalable_2021,
	title = {Scalable {Evaluation} of {Multi}-{Agent} {Reinforcement} {Learning} with {Melting} {Pot}},
	url = {https://proceedings.mlr.press/v139/leibo21a.html},
	abstract = {Existing evaluation suites for multi-agent reinforcement learning (MARL) do not assess generalization to novel situations as their primary objective (unlike supervised learning benchmarks). Our contribution, Melting Pot, is a MARL evaluation suite that fills this gap and uses reinforcement learning to reduce the human labor required to create novel test scenarios. This works because one agent’s behavior constitutes (part of) another agent’s environment. To demonstrate scalability, we have created over 80 unique test scenarios covering a broad range of research topics such as social dilemmas, reciprocity, resource sharing, and task partitioning. We apply these test scenarios to standard MARL training algorithms, and demonstrate how Melting Pot reveals weaknesses not apparent from training performance alone.},
	language = {en},
	urldate = {2023-07-26},
	booktitle = {Proceedings of the 38th {International} {Conference} on {Machine} {Learning}},
	publisher = {PMLR},
	author = {Leibo, Joel Z. and Dueñez-Guzman, Edgar A. and Vezhnevets, Alexander and Agapiou, John P. and Sunehag, Peter and Koster, Raphael and Matyas, Jayd and Beattie, Charlie and Mordatch, Igor and Graepel, Thore},
	month = jul,
	year = {2021},
	note = {ISSN: 2640-3498},
	pages = {6187--6199},
	file = {Full Text PDF:/Users/oliverbiggar/Zotero/storage/M79J6AE8/Leibo et al. - 2021 - Scalable Evaluation of Multi-Agent Reinforcement L.pdf:application/pdf;Supplementary PDF:/Users/oliverbiggar/Zotero/storage/LSHAW4PJ/Leibo et al. - 2021 - Scalable Evaluation of Multi-Agent Reinforcement L.pdf:application/pdf},
}

@inproceedings{perez-nieves_modelling_2021,
	title = {Modelling {Behavioural} {Diversity} for {Learning} in {Open}-{Ended} {Games}},
	url = {https://proceedings.mlr.press/v139/perez-nieves21a.html},
	abstract = {Promoting behavioural diversity is critical for solving games with non-transitive dynamics where strategic cycles exist, and there is no consistent winner (e.g., Rock-Paper-Scissors). Yet, there is a lack of rigorous treatment for defining diversity and constructing diversity-aware learning dynamics. In this work, we offer a geometric interpretation of behavioural diversity in games and introduce a novel diversity metric based on {\textbackslash}emph\{determinantal point processes\} (DPP). By incorporating the diversity metric into best-response dynamics, we develop {\textbackslash}emph\{diverse fictitious play\} and {\textbackslash}emph\{diverse policy-space response oracle\} for solving normal-form games and open-ended games. We prove the uniqueness of the diverse best response and the convergence of our algorithms on two-player games. Importantly, we show that maximising the DPP-based diversity metric guarantees to enlarge the {\textbackslash}emph\{gamescape\} – convex polytopes spanned by agents’ mixtures of strategies. To validate our diversity-aware solvers, we test on tens of games that show strong non-transitivity. Results suggest that our methods achieve at least the same, and in most games, lower exploitability than PSRO solvers by finding effective and diverse strategies.},
	language = {en},
	urldate = {2023-07-26},
	booktitle = {Proceedings of the 38th {International} {Conference} on {Machine} {Learning}},
	publisher = {PMLR},
	author = {Perez-Nieves, Nicolas and Yang, Yaodong and Slumbers, Oliver and Mguni, David H. and Wen, Ying and Wang, Jun},
	month = jul,
	year = {2021},
	note = {ISSN: 2640-3498},
	pages = {8514--8524},
	file = {Full Text PDF:/Users/oliverbiggar/Zotero/storage/BIBFIRZ7/Perez-Nieves et al. - 2021 - Modelling Behavioural Diversity for Learning in Op.pdf:application/pdf;Supplementary PDF:/Users/oliverbiggar/Zotero/storage/9VHKZR7G/Perez-Nieves et al. - 2021 - Modelling Behavioural Diversity for Learning in Op.pdf:application/pdf},
}

@inproceedings{czarnecki_real_2020,
	title = {Real {World} {Games} {Look} {Like} {Spinning} {Tops}},
	volume = {33},
	url = {https://proceedings.neurips.cc/paper/2020/hash/ca172e964907a97d5ebd876bfdd4adbd-Abstract.html},
	abstract = {This paper investigates the geometrical properties of real world games (e.g. Tic-Tac-Toe, Go, StarCraft II).
We hypothesise that their geometrical structure resembles a spinning top, with the upright axis representing transitive strength, and the radial axis representing the non-transitive dimension, which corresponds to the number of cycles that exist at a particular transitive strength. 
We prove the existence of this geometry for a wide class of real world games by exposing their temporal nature.
Additionally, we show that this unique structure also has consequences for learning - it clarifies why populations of strategies are necessary for training of agents, and how population size relates to the structure of the game.
Finally, we empirically validate these claims by using a selection of nine real world two-player zero-sum symmetric games, showing 1) the spinning top structure is revealed and can be easily reconstructed by using a new method of Nash clustering to measure the interaction between transitive and cyclical strategy behaviour, and 2) the effect that population size has on the convergence of learning in these games.},
	urldate = {2023-07-26},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	publisher = {Curran Associates, Inc.},
	author = {Czarnecki, Wojciech M. and Gidel, Gauthier and Tracey, Brendan and Tuyls, Karl and Omidshafiei, Shayegan and Balduzzi, David and Jaderberg, Max},
	year = {2020},
	pages = {17443--17454},
	file = {Full Text PDF:/Users/oliverbiggar/Zotero/storage/T7CVMNQC/Czarnecki et al. - 2020 - Real World Games Look Like Spinning Tops.pdf:application/pdf},
}

@inproceedings{jordan_evaluating_2020,
	title = {Evaluating the {Performance} of {Reinforcement} {Learning} {Algorithms}},
	url = {https://proceedings.mlr.press/v119/jordan20a.html},
	abstract = {Performance evaluations are critical for quantifying algorithmic advances in reinforcement learning. Recent reproducibility analyses have shown that reported performance results are often inconsistent and difficult to replicate. In this work, we argue that the inconsistency of performance stems from the use of flawed evaluation metrics. Taking a step towards ensuring that reported results are consistent, we propose a new comprehensive evaluation methodology for reinforcement learning algorithms that produces reliable measurements of performance both on a single environment and when aggregated across environments. We demonstrate this method by evaluating a broad class of reinforcement learning algorithms on standard benchmark tasks.},
	language = {en},
	urldate = {2023-07-26},
	booktitle = {Proceedings of the 37th {International} {Conference} on {Machine} {Learning}},
	publisher = {PMLR},
	author = {Jordan, Scott and Chandak, Yash and Cohen, Daniel and Zhang, Mengxue and Thomas, Philip},
	month = nov,
	year = {2020},
	note = {ISSN: 2640-3498},
	pages = {4962--4973},
	file = {Full Text PDF:/Users/oliverbiggar/Zotero/storage/35KRLYIW/Jordan et al. - 2020 - Evaluating the Performance of Reinforcement Learni.pdf:application/pdf;Supplementary PDF:/Users/oliverbiggar/Zotero/storage/BF8KJCNY/Jordan et al. - 2020 - Evaluating the Performance of Reinforcement Learni.pdf:application/pdf},
}

@article{letcher_dierentiable_nodate,
	title = {Diﬀerentiable {Game} {Mechanics}},
	abstract = {Deep learning is built on the foundational guarantee that gradient descent on an objective function converges to local minima. Unfortunately, this guarantee fails in settings, such as generative adversarial nets, that exhibit multiple interacting losses. The behavior of gradient-based methods in games is not well understood – and is becoming increasingly important as adversarial and multi-objective architectures proliferate. In this paper, we develop new tools to understand and control the dynamics in n-player diﬀerentiable games. The key result is to decompose the game Jacobian into two components. The ﬁrst, symmetric component, is related to potential games, which reduce to gradient descent on an implicit function. The second, antisymmetric component, relates to Hamiltonian games, a new class of games that obey a conservation law akin to conservation laws in classical mechanical systems. The decomposition motivates Symplectic Gradient Adjustment (SGA), a new algorithm for ﬁnding stable ﬁxed points in diﬀerentiable games. Basic experiments show SGA is competitive with recently proposed algorithms for ﬁnding stable ﬁxed points in GANs – while at the same time being applicable to, and having guarantees in, much more general cases.},
	language = {en},
	author = {Letcher, Alistair and Balduzzi, David and Racaniere, Sebastien and Martens, James and Foerster, Jakob and Tuyls, Karl and Graepel, Thore},
	file = {Letcher et al. - Diﬀerentiable Game Mechanics.pdf:/Users/oliverbiggar/Zotero/storage/476VKW4E/Letcher et al. - Diﬀerentiable Game Mechanics.pdf:application/pdf},
}

@inproceedings{rowland_multiagent_2019,
	title = {Multiagent {Evaluation} under {Incomplete} {Information}},
	volume = {32},
	url = {https://proceedings.neurips.cc/paper_files/paper/2019/hash/510f2318f324cf07fce24c3a4b89c771-Abstract.html},
	urldate = {2023-07-26},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	publisher = {Curran Associates, Inc.},
	author = {Rowland, Mark and Omidshafiei, Shayegan and Tuyls, Karl and Perolat, Julien and Valko, Michal and Piliouras, Georgios and Munos, Remi},
	year = {2019},
	file = {Full Text PDF:/Users/oliverbiggar/Zotero/storage/GFWDV3AI/Rowland et al. - 2019 - Multiagent Evaluation under Incomplete Information.pdf:application/pdf},
}

@article{yan_learning_2022,
	title = {Learning to {Identify} {Top} {Elo} {Ratings}: {A} {Dueling} {Bandits} {Approach}},
	volume = {36},
	copyright = {Copyright (c) 2022 Association for the Advancement of Artificial Intelligence},
	issn = {2374-3468},
	shorttitle = {Learning to {Identify} {Top} {Elo} {Ratings}},
	url = {https://ojs.aaai.org/index.php/AAAI/article/view/20860},
	doi = {10.1609/aaai.v36i8.20860},
	abstract = {The Elo rating system is widely adopted to evaluate the skills of (chess) game and sports players. Recently it has been also integrated into machine learning algorithms in evaluating the performance of computerised AI agents. However, an accurate estimation of the Elo rating (for the top players) often requires many rounds of competitions, which can be expensive to carry out. In this paper, to minimize the number of comparisons and to improve the sample efficiency of the Elo evaluation (for top players), we propose an efficient online match scheduling algorithm. Specifically, we identify and match the top players through a dueling bandits framework and tailor the bandit algorithm to the gradient-based update of Elo. We show that it reduces the per-step memory and time complexity to constant, compared to the traditional likelihood maximization approaches requiring O(t) time. Our algorithm has a regret guarantee that is sublinear in the number of competition rounds and has been extended to the multidimensional Elo ratings for handling intransitive games. We empirically demonstrate that our method achieves superior convergence speed and time efficiency on a variety of gaming tasks.},
	language = {en},
	number = {8},
	urldate = {2023-07-26},
	journal = {Proceedings of the AAAI Conference on Artificial Intelligence},
	author = {Yan, Xue and Du, Yali and Ru, Binxin and Wang, Jun and Zhang, Haifeng and Chen, Xu},
	month = jun,
	year = {2022},
	note = {Number: 8},
	keywords = {Multiagent Systems (MAS)},
	pages = {8797--8805},
	file = {Full Text PDF:/Users/oliverbiggar/Zotero/storage/5TB5ATUP/Yan et al. - 2022 - Learning to Identify Top Elo Ratings A Dueling Ba.pdf:application/pdf},
}

@misc{timbers_approximate_2022,
	title = {Approximate exploitability: {Learning} a best response in large games},
	shorttitle = {Approximate exploitability},
	url = {http://arxiv.org/abs/2004.09677},
	doi = {10.48550/arXiv.2004.09677},
	abstract = {Researchers have demonstrated that neural networks are vulnerable to adversarial examples and subtle environment changes, both of which one can view as a form of distribution shift. To humans, the resulting errors can look like blunders, eroding trust in these agents. In prior games research, agent evaluation often focused on the in-practice game outcomes. While valuable, such evaluation typically fails to evaluate robustness to worst-case outcomes. Prior research in computer poker has examined how to assess such worst-case performance, both exactly and approximately. Unfortunately, exact computation is infeasible with larger domains, and existing approximations rely on poker-specific knowledge. We introduce ISMCTS-BR, a scalable search-based deep reinforcement learning algorithm for learning a best response to an agent, thereby approximating worst-case performance. We demonstrate the technique in several two-player zero-sum games against a variety of agents, including several AlphaZero-based agents.},
	urldate = {2023-07-26},
	publisher = {arXiv},
	author = {Timbers, Finbarr and Bard, Nolan and Lockhart, Edward and Lanctot, Marc and Schmid, Martin and Burch, Neil and Schrittwieser, Julian and Hubert, Thomas and Bowling, Michael},
	month = nov,
	year = {2022},
	note = {arXiv:2004.09677 [cs, stat]},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
	file = {arXiv Fulltext PDF:/Users/oliverbiggar/Zotero/storage/5BTMTY45/Timbers et al. - 2022 - Approximate exploitability Learning a best respon.pdf:application/pdf;arXiv.org Snapshot:/Users/oliverbiggar/Zotero/storage/HDVGY7P2/2004.html:text/html},
}

@inproceedings{bertrand_limitations_2023,
	title = {On the {Limitations} of the {Elo}, {Real}-{World} {Games} are {Transitive}, not {Additive}},
	url = {https://proceedings.mlr.press/v206/bertrand23a.html},
	abstract = {The Elo score has been extensively used to rank players by their skill or strength in competitive games such as chess, go, or StarCraft II. The Elo score implicitly assumes games have a strong additive—hence transitive—component. In this paper, we investigate the challenge of identifying transitive components in games. As a starting point, we show that the Elo score provably fails to extract the transitive component of some elementary transitive games. Based on this observation, we propose an alternative ranking system which properly extracts the transitive components in these games. Finally, we conduct an in-depth empirical validation on real-world game payoff matrices: it shows significant prediction performance improvements compared to the Elo score.},
	language = {en},
	urldate = {2023-07-26},
	booktitle = {Proceedings of {The} 26th {International} {Conference} on {Artificial} {Intelligence} and {Statistics}},
	publisher = {PMLR},
	author = {Bertrand, Quentin and Czarnecki, Wojciech Marian and Gidel, Gauthier},
	month = apr,
	year = {2023},
	note = {ISSN: 2640-3498},
	pages = {2905--2921},
	file = {Full Text PDF:/Users/oliverbiggar/Zotero/storage/AZMVF8WS/Bertrand et al. - 2023 - On the Limitations of the Elo, Real-World Games ar.pdf:application/pdf},
}

@article{rashid_estimating_2021,
	title = {Estimating $\alpha$-{Rank} by {Maximizing} {Information} {Gain}},
	volume = {35},
	copyright = {Copyright (c) 2021 Association for the Advancement of Artificial Intelligence},
	issn = {2374-3468},
	url = {https://ojs.aaai.org/index.php/AAAI/article/view/16712},
	doi = {10.1609/aaai.v35i6.16712},
	abstract = {Game theory has been increasingly applied in settings where the game is not known outright, but has to be estimated by sampling.
For example, meta-games that arise in multi-agent evaluation can only be accessed by running a succession of expensive experiments that may involve simultaneous deployment of several agents.
In this paper, we focus on $\alpha$-rank, a popular game-theoretic solution concept designed to perform well in such scenarios.
We aim to estimate the $\alpha$-rank of the game using as few samples as possible.
Our algorithm maximizes information gain between an epistemic belief over the $\alpha$-ranks and the observed payoff. This approach has two main benefits. 
First, it allows us to focus our sampling on the entries that matter the most for identifying the $\alpha$-rank. Second, the Bayesian formulation provides a facility to build in modeling assumptions by using a prior over game payoffs.
We show the benefits of using information gain as compared to the confidence interval criterion of ResponseGraphUCB, 
and provide theoretical results justifying our method.},
	language = {en},
	number = {6},
	urldate = {2023-07-26},
	journal = {Proceedings of the AAAI Conference on Artificial Intelligence},
	author = {Rashid, Tabish and Zhang, Cheng and Ciosek, Kamil},
	month = may,
	year = {2021},
	note = {Number: 6},
	keywords = {Imperfect Information},
	pages = {5673--5681},
	file = {Full Text PDF:/Users/oliverbiggar/Zotero/storage/VAJ6RRQX/Rashid et al. - 2021 - Estimating $\alpha$-Rank by Maximizing Information Gain.pdf:application/pdf},
}

@misc{marris_game_2022,
	title = {Game {Theoretic} {Rating} in {N}-player general-sum games with {Equilibria}},
	url = {http://arxiv.org/abs/2210.02205},
	doi = {10.48550/arXiv.2210.02205},
	abstract = {Rating strategies in a game is an important area of research in game theory and artificial intelligence, and can be applied to any real-world competitive or cooperative setting. Traditionally, only transitive dependencies between strategies have been used to rate strategies (e.g. Elo), however recent work has expanded ratings to utilize game theoretic solutions to better rate strategies in non-transitive games. This work generalizes these ideas and proposes novel algorithms suitable for N-player, general-sum rating of strategies in normal-form games according to the payoff rating system. This enables well-established solution concepts, such as equilibria, to be leveraged to efficiently rate strategies in games with complex strategic interactions, which arise in multiagent training and real-world interactions between many agents. We empirically validate our methods on real world normal-form data (Premier League) and multiagent reinforcement learning agent evaluation.},
	urldate = {2023-07-26},
	publisher = {arXiv},
	author = {Marris, Luke and Lanctot, Marc and Gemp, Ian and Omidshafiei, Shayegan and McAleer, Stephen and Connor, Jerome and Tuyls, Karl and Graepel, Thore},
	month = oct,
	year = {2022},
	note = {arXiv:2210.02205 [cs]},
	keywords = {Computer Science - Computer Science and Game Theory, Computer Science - Multiagent Systems, Computer Science - Machine Learning},
	file = {arXiv Fulltext PDF:/Users/oliverbiggar/Zotero/storage/UXIV3GHG/Marris et al. - 2022 - Game Theoretic Rating in N-player general-sum game.pdf:application/pdf;arXiv.org Snapshot:/Users/oliverbiggar/Zotero/storage/FWYE5GDY/2210.html:text/html},
}

@misc{yan_evaluation_2022,
	title = {Evaluation and {Learning} in {Two}-{Player} {Symmetric} {Games} via {Best} and {Better} {Responses}},
	url = {http://arxiv.org/abs/2204.12791},
	doi = {10.48550/arXiv.2204.12791},
	abstract = {Artificial intelligence and robotic competitions are accompanied by a class of game paradigms in which each player privately commits a strategy to a game system which simulates the game using the collected joint strategy and then returns payoffs to players. This paper considers the strategy commitment for two-player symmetric games in which the players' strategy spaces are identical and their payoffs are symmetric. First, we introduce two digraph-based metrics at a meta-level for strategy evaluation in two-agent reinforcement learning, grounded on sink equilibrium. The metrics rank the strategies of a single player and determine the set of strategies which are preferred for the private commitment. Then, in order to find the preferred strategies under the metrics, we propose two variants of the classical learning algorithm self-play, called strictly best-response and weakly better-response self-plays. By modeling learning processes as walks over joint-strategy response digraphs, we prove that the learnt strategies by two variants are preferred under two metrics, respectively. The preferred strategies under both two metrics are identified and adjacency matrices induced by one metric and one variant are connected. Finally, simulations are provided to illustrate the results.},
	urldate = {2023-07-26},
	publisher = {arXiv},
	author = {Yan, Rui and Zhang, Weixian and Deng, Ruiliang and Duan, Xiaoming and Shi, Zongying and Zhong, Yisheng},
	month = apr,
	year = {2022},
	note = {arXiv:2204.12791 [cs]},
	keywords = {Computer Science - Computer Science and Game Theory},
	file = {arXiv Fulltext PDF:/Users/oliverbiggar/Zotero/storage/GJU3D9HV/Yan et al. - 2022 - Evaluation and Learning in Two-Player Symmetric Ga.pdf:application/pdf;arXiv.org Snapshot:/Users/oliverbiggar/Zotero/storage/QWMYZAEC/2204.html:text/html},
}

@misc{vadori_ordinal_2023,
	title = {Ordinal {Potential}-based {Player} {Rating}},
	url = {http://arxiv.org/abs/2306.05366},
	doi = {10.48550/arXiv.2306.05366},
	abstract = {A two-player symmetric zero-sum game is transitive if for any pure strategies \$x\$, \$y\$, \$z\$, if \$x\$ is better than \$y\$, and \$y\$ is better than \$z\$, then \$x\$ is better than \$z\$. It was recently observed that the Elo rating fails at preserving transitive relations among strategies and therefore cannot correctly extract the transitive component of a game. Our first contribution is to show that the Elo rating actually does preserve transitivity when computed in the right space. Precisely, using a suitable invertible mapping \${\textbackslash}varphi\$, we first apply \${\textbackslash}varphi\$ to the game, then compute Elo ratings, then go back to the original space by applying \${\textbackslash}varphi{\textasciicircum}\{-1\}\$. We provide a characterization of transitive games as a weak variant of ordinal potential games with additively separable potential functions. Leveraging this insight, we introduce the concept of transitivity order, the minimum number of invertible mappings required to transform the payoff of a transitive game into (differences of) its potential function. The transitivity order is a tool to classify transitive games, with Elo games being an example of transitive games of order one. Most real-world games have both transitive and non-transitive (cyclic) components, and we use our analysis of transitivity to extract the transitive (potential) component of an arbitrary game. We link transitivity to the known concept of sign-rank: transitive games have sign-rank two; arbitrary games may have higher sign-rank. Using a neural network-based architecture, we learn a decomposition of an arbitrary game into transitive and cyclic components that prioritises capturing the sign pattern of the game. In particular, a transitive game always has just one component in its decomposition, the potential component. We provide a comprehensive evaluation of our methodology using both toy examples and empirical data from real-world games.},
	urldate = {2023-07-26},
	publisher = {arXiv},
	author = {Vadori, Nelson and Savani, Rahul},
	month = jun,
	year = {2023},
	note = {arXiv:2306.05366 [cs]},
	keywords = {Computer Science - Computer Science and Game Theory, Computer Science - Machine Learning},
	file = {arXiv Fulltext PDF:/Users/oliverbiggar/Zotero/storage/L99LPSW5/Vadori and Savani - 2023 - Ordinal Potential-based Player Rating.pdf:application/pdf;arXiv.org Snapshot:/Users/oliverbiggar/Zotero/storage/BQ9ITBP9/2306.html:text/html},
}

@inproceedings{lanctot_unified_2017,
	title = {A {Unified} {Game}-{Theoretic} {Approach} to {Multiagent} {Reinforcement} {Learning}},
	volume = {30},
	url = {https://proceedings.neurips.cc/paper/2017/hash/3323fe11e9595c09af38fe67567a9394-Abstract.html},
	abstract = {There has been a resurgence of interest in multiagent reinforcement learning (MARL), due partly to the recent success of deep neural networks. The simplest form of MARL is independent reinforcement learning (InRL), where each agent treats all of its experience as part of its (non stationary) environment. In this paper, we first observe that policies learned using InRL can overfit to the other agents' policies during training, failing to sufficiently generalize during execution. We introduce a new metric, joint-policy correlation, to quantify this effect. We describe a meta-algorithm for general MARL, based on approximate best responses to mixtures of policies generated using deep reinforcement learning, and empirical game theoretic analysis to compute meta-strategies for policy selection. The meta-algorithm generalizes previous algorithms such as InRL, iterated best response, double oracle, and fictitious play. Then, we propose a scalable implementation which reduces the memory requirement using decoupled meta-solvers. Finally, we demonstrate the generality of the resulting policies in three partially observable settings: gridworld coordination problems, emergent language games, and poker.},
	urldate = {2023-07-31},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	publisher = {Curran Associates, Inc.},
	author = {Lanctot, Marc and Zambaldi, Vinicius and Gruslys, Audrunas and Lazaridou, Angeliki and Tuyls, Karl and Perolat, Julien and Silver, David and Graepel, Thore},
	year = {2017},
	keywords = {DeepMind},
	file = {Full Text PDF:/Users/oliverbiggar/Zotero/storage/Z4G8ANCL/Lanctot et al. - 2017 - A Unified Game-Theoretic Approach to Multiagent Re.pdf:application/pdf},
}

@misc{foerster_learning_2018,
	title = {Learning with {Opponent}-{Learning} {Awareness}},
	url = {http://arxiv.org/abs/1709.04326},
	doi = {10.48550/arXiv.1709.04326},
	abstract = {Multi-agent settings are quickly gathering importance in machine learning. This includes a plethora of recent work on deep multi-agent reinforcement learning, but also can be extended to hierarchical RL, generative adversarial networks and decentralised optimisation. In all these settings the presence of multiple learning agents renders the training problem non-stationary and often leads to unstable training or undesired final results. We present Learning with Opponent-Learning Awareness (LOLA), a method in which each agent shapes the anticipated learning of the other agents in the environment. The LOLA learning rule includes a term that accounts for the impact of one agent's policy on the anticipated parameter update of the other agents. Results show that the encounter of two LOLA agents leads to the emergence of tit-for-tat and therefore cooperation in the iterated prisoners' dilemma, while independent learning does not. In this domain, LOLA also receives higher payouts compared to a naive learner, and is robust against exploitation by higher order gradient-based methods. Applied to repeated matching pennies, LOLA agents converge to the Nash equilibrium. In a round robin tournament we show that LOLA agents successfully shape the learning of a range of multi-agent learning algorithms from literature, resulting in the highest average returns on the IPD. We also show that the LOLA update rule can be efficiently calculated using an extension of the policy gradient estimator, making the method suitable for model-free RL. The method thus scales to large parameter and input spaces and nonlinear function approximators. We apply LOLA to a grid world task with an embedded social dilemma using recurrent policies and opponent modelling. By explicitly considering the learning of the other agent, LOLA agents learn to cooperate out of self-interest. The code is at github.com/alshedivat/lola.},
	urldate = {2023-07-31},
	publisher = {arXiv},
	author = {Foerster, Jakob N. and Chen, Richard Y. and Al-Shedivat, Maruan and Whiteson, Shimon and Abbeel, Pieter and Mordatch, Igor},
	month = sep,
	year = {2018},
	note = {arXiv:1709.04326 [cs]},
	keywords = {Computer Science - Computer Science and Game Theory, Computer Science - Artificial Intelligence},
	file = {arXiv Fulltext PDF:/Users/oliverbiggar/Zotero/storage/6LG2G5JL/Foerster et al. - 2018 - Learning with Opponent-Learning Awareness.pdf:application/pdf;arXiv.org Snapshot:/Users/oliverbiggar/Zotero/storage/E4I5YLV4/1709.html:text/html},
}

@article{strang_network_2022,
	title = {The network {HHD}: {Quantifying} cyclic competition in trait-performance models of tournaments},
	volume = {64},
	issn = {0036-1445},
	number = {2},
	journal = {SIAM Review},
	author = {Strang, Alexander and Abbott, Karen C and Thomas, Peter J},
	year = {2022},
	note = {Publisher: SIAM},
	pages = {360--391},
	file = {Strang et al. - 2022 - The network HHD Quantifying cyclic competition in.pdf:/Users/oliverbiggar/Zotero/storage/A66DDXQ7/Strang et al. - 2022 - The network HHD Quantifying cyclic competition in.pdf:application/pdf},
}

@inproceedings{tuyls_generalised_2018,
	address = {Richland, SC},
	series = {{AAMAS} '18},
	title = {A {Generalised} {Method} for {Empirical} {Game} {Theoretic} {Analysis}},
	abstract = {This paper provides theoretical bounds for empirical game theoretical analysis of complex multi-agent interactions. We provide insights in the empirical meta game showing that a Nash equilibrium of the meta-game is an approximate Nash equilibrium of the true underlying game. We investigate and show how many data samples are required to obtain a close enough approximation of the underlying game. Additionally, we extend the meta-game analysis methodology to asymmetric games. The state-of-the-art has only considered empirical games in which agents have access to the same strategy sets and the payoff structure is symmetric, implying that agents are interchangeable. Finally, we carry out an empirical illustration of the generalised method in several domains, illustrating the theory and evolutionary dynamics of several versions of the AlphaGo algorithm (symmetric), the dynamics of the Colonel Blotto game played by human players on Facebook (symmetric), and an example of a meta-game in Leduc Poker (asymmetric), generated by the PSRO multi-agent learning algorithm.},
	urldate = {2023-07-31},
	booktitle = {Proceedings of the 17th {International} {Conference} on {Autonomous} {Agents} and {MultiAgent} {Systems}},
	publisher = {International Foundation for Autonomous Agents and Multiagent Systems},
	author = {Tuyls, Karl and Perolat, Julien and Lanctot, Marc and Leibo, Joel Z. and Graepel, Thore},
	month = jul,
	year = {2018},
	keywords = {replicator dynamics, asymmetric games, empirical games},
	pages = {77--85},
	file = {Tuyls et al. - 2018 - A Generalised Method for Empirical Game Theoretic .pdf:/Users/oliverbiggar/Zotero/storage/GGTB38GN/Tuyls et al. - 2018 - A Generalised Method for Empirical Game Theoretic .pdf:application/pdf},
}

@inproceedings{foerster_learning_2016,
	title = {Learning to {Communicate} with {Deep} {Multi}-{Agent} {Reinforcement} {Learning}},
	volume = {29},
	url = {https://proceedings.neurips.cc/paper_files/paper/2016/hash/c7635bfd99248a2cdef8249ef7bfbef4-Abstract.html},
	abstract = {We consider the problem of multiple agents sensing and acting in environments with the goal of maximising their shared utility. In these environments, agents must learn communication protocols in order to share information that is needed to solve the tasks. By embracing deep neural networks, we are able to demonstrate end-to-end learning of protocols in complex environments inspired by communication riddles and multi-agent computer vision problems with partial observability. We propose two approaches for learning in these domains: Reinforced Inter-Agent Learning (RIAL) and Differentiable Inter-Agent Learning (DIAL). The former uses deep Q-learning, while the latter exploits the fact that, during learning, agents can backpropagate error derivatives through (noisy) communication channels. Hence, this approach uses centralised learning but decentralised execution. Our experiments introduce new environments for studying the learning of communication protocols and present a set of engineering innovations that are essential for success in these domains.},
	urldate = {2023-08-01},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	publisher = {Curran Associates, Inc.},
	author = {Foerster, Jakob and Assael, Ioannis Alexandros and de Freitas, Nando and Whiteson, Shimon},
	year = {2016},
	file = {Full Text PDF:/Users/oliverbiggar/Zotero/storage/2AS2V8XP/Foerster et al. - 2016 - Learning to Communicate with Deep Multi-Agent Rein.pdf:application/pdf},
}

@inproceedings{sukhbaatar_learning_2016,
	title = {Learning {Multiagent} {Communication} with {Backpropagation}},
	volume = {29},
	url = {https://proceedings.neurips.cc/paper/2016/hash/55b1927fdafef39c48e5b73b5d61ea60-Abstract.html},
	abstract = {Many tasks in AI require the collaboration of multiple agents. Typically, the communication protocol between agents is manually specified and not altered during training. In this paper we explore a simple neural model, called CommNet, that uses continuous communication for fully cooperative tasks. The model consists of multiple agents and the communication between them is learned alongside their policy. We apply this model to a diverse set of tasks, demonstrating the ability of the agents to learn to communicate amongst themselves, yielding improved performance over non-communicative agents and baselines. In some cases, it is possible to interpret the language devised by the agents, revealing simple but effective strategies for solving the task at hand.},
	urldate = {2023-08-01},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	publisher = {Curran Associates, Inc.},
	author = {Sukhbaatar, Sainbayar and szlam, arthur and Fergus, Rob},
	year = {2016},
	file = {Full Text PDF:/Users/oliverbiggar/Zotero/storage/V5F4VIMS/Sukhbaatar et al. - 2016 - Learning Multiagent Communication with Backpropaga.pdf:application/pdf},
}

@inproceedings{foerster_stabilising_2017,
	title = {Stabilising {Experience} {Replay} for {Deep} {Multi}-{Agent} {Reinforcement} {Learning}},
	url = {https://proceedings.mlr.press/v70/foerster17b.html},
	abstract = {Many real-world problems, such as network packet routing and urban traffic control, are naturally modeled as multi-agent reinforcement learning (RL) problems. However, existing multi-agent RL methods typically scale poorly in the problem size. Therefore, a key challenge is to translate the success of deep learning on single-agent RL to the multi-agent setting. A major stumbling block is that independent Q-learning, the most popular multi-agent RL method, introduces nonstationarity that makes it incompatible with the experience replay memory on which deep Q-learning relies. This paper proposes two methods that address this problem: 1) using a multi-agent variant of importance sampling to naturally decay obsolete data and 2) conditioning each agent’s value function on a fingerprint that disambiguates the age of the data sampled from the replay memory. Results on a challenging decentralised variant of StarCraft unit micromanagement confirm that these methods enable the successful combination of experience replay with multi-agent RL.},
	language = {en},
	urldate = {2023-08-01},
	booktitle = {Proceedings of the 34th {International} {Conference} on {Machine} {Learning}},
	publisher = {PMLR},
	author = {Foerster, Jakob and Nardelli, Nantas and Farquhar, Gregory and Afouras, Triantafyllos and Torr, Philip H. S. and Kohli, Pushmeet and Whiteson, Shimon},
	month = jul,
	year = {2017},
	note = {ISSN: 2640-3498},
	pages = {1146--1155},
	file = {Full Text PDF:/Users/oliverbiggar/Zotero/storage/7L77XBY8/Foerster et al. - 2017 - Stabilising Experience Replay for Deep Multi-Agent.pdf:application/pdf},
}

@inproceedings{omidshafiei_deep_2017,
	title = {Deep {Decentralized} {Multi}-task {Multi}-{Agent} {Reinforcement} {Learning} under {Partial} {Observability}},
	url = {https://proceedings.mlr.press/v70/omidshafiei17a.html},
	abstract = {Many real-world tasks involve multiple agents with partial observability and limited communication. Learning is challenging in these settings due to local viewpoints of agents, which perceive the world as non-stationary due to concurrently-exploring teammates. Approaches that learn specialized policies for individual tasks face problems when applied to the real world: not only do agents have to learn and store distinct policies for each task, but in practice identities of tasks are often non-observable, making these approaches inapplicable. This paper formalizes and addresses the problem of multi-task multi-agent reinforcement learning under partial observability. We introduce a decentralized single-task learning approach that is robust to concurrent interactions of teammates, and present an approach for distilling single-task policies into a unified policy that performs well across multiple related tasks, without explicit provision of task identity.},
	language = {en},
	urldate = {2023-08-01},
	booktitle = {Proceedings of the 34th {International} {Conference} on {Machine} {Learning}},
	publisher = {PMLR},
	author = {Omidshafiei, Shayegan and Pazis, Jason and Amato, Christopher and How, Jonathan P. and Vian, John},
	month = jul,
	year = {2017},
	note = {ISSN: 2640-3498},
	pages = {2681--2690},
	file = {Full Text PDF:/Users/oliverbiggar/Zotero/storage/V4PV7ZNF/Omidshafiei et al. - 2017 - Deep Decentralized Multi-task Multi-Agent Reinforc.pdf:application/pdf;Supplementary PDF:/Users/oliverbiggar/Zotero/storage/9KWNGYGA/Omidshafiei et al. - 2017 - Deep Decentralized Multi-task Multi-Agent Reinforc.pdf:application/pdf},
}

@misc{lanctot_openspiel_2020,
	title = {{OpenSpiel}: {A} {Framework} for {Reinforcement} {Learning} in {Games}},
	shorttitle = {{OpenSpiel}},
	url = {http://arxiv.org/abs/1908.09453},
	doi = {10.48550/arXiv.1908.09453},
	abstract = {OpenSpiel is a collection of environments and algorithms for research in general reinforcement learning and search/planning in games. OpenSpiel supports n-player (single- and multi- agent) zero-sum, cooperative and general-sum, one-shot and sequential, strictly turn-taking and simultaneous-move, perfect and imperfect information games, as well as traditional multiagent environments such as (partially- and fully- observable) grid worlds and social dilemmas. OpenSpiel also includes tools to analyze learning dynamics and other common evaluation metrics. This document serves both as an overview of the code base and an introduction to the terminology, core concepts, and algorithms across the fields of reinforcement learning, computational game theory, and search.},
	urldate = {2023-08-01},
	publisher = {arXiv},
	author = {Lanctot, Marc and Lockhart, Edward and Lespiau, Jean-Baptiste and Zambaldi, Vinicius and Upadhyay, Satyaki and Pérolat, Julien and Srinivasan, Sriram and Timbers, Finbarr and Tuyls, Karl and Omidshafiei, Shayegan and Hennes, Daniel and Morrill, Dustin and Muller, Paul and Ewalds, Timo and Faulkner, Ryan and Kramár, János and De Vylder, Bart and Saeta, Brennan and Bradbury, James and Ding, David and Borgeaud, Sebastian and Lai, Matthew and Schrittwieser, Julian and Anthony, Thomas and Hughes, Edward and Danihelka, Ivo and Ryan-Davis, Jonah},
	month = sep,
	year = {2020},
	note = {arXiv:1908.09453 [cs]},
	keywords = {Computer Science - Computer Science and Game Theory, Computer Science - Multiagent Systems, Computer Science - Artificial Intelligence, Computer Science - Machine Learning},
	file = {arXiv Fulltext PDF:/Users/oliverbiggar/Zotero/storage/EMLDGFWG/Lanctot et al. - 2020 - OpenSpiel A Framework for Reinforcement Learning .pdf:application/pdf;arXiv.org Snapshot:/Users/oliverbiggar/Zotero/storage/E33QE4L5/1908.html:text/html},
}

@article{leonardos_exploration-exploitation_2022,
	title = {Exploration-exploitation in multi-agent learning: {Catastrophe} theory meets game theory},
	volume = {304},
	issn = {0004-3702},
	journal = {Artificial Intelligence},
	author = {Leonardos, Stefanos and Piliouras, Georgios},
	year = {2022},
	note = {Publisher: Elsevier},
	pages = {103653},
}

@misc{yang_alphaalpha-rank_2020,
	title = {\${\textbackslash}alpha{\textasciicircum}\{{\textbackslash}alpha\}\$-{Rank}: {Practically} {Scaling} \${\textbackslash}alpha\$-{Rank} through {Stochastic} {Optimisation}},
	shorttitle = {\${\textbackslash}alpha{\textasciicircum}\{{\textbackslash}alpha\}\$-{Rank}},
	url = {http://arxiv.org/abs/1909.11628},
	doi = {10.48550/arXiv.1909.11628},
	abstract = {Recently, \${\textbackslash}alpha\$-Rank, a graph-based algorithm, has been proposed as a solution to ranking joint policy profiles in large scale multi-agent systems. \${\textbackslash}alpha\$-Rank claimed tractability through a polynomial time implementation with respect to the total number of pure strategy profiles. Here, we note that inputs to the algorithm were not clearly specified in the original presentation; as such, we deem complexity claims as not grounded, and conjecture solving \${\textbackslash}alpha\$-Rank is NP-hard. The authors of \${\textbackslash}alpha\$-Rank suggested that the input to \${\textbackslash}alpha\$-Rank can be an exponentially-sized payoff matrix; a claim promised to be clarified in subsequent manuscripts. Even though \${\textbackslash}alpha\$-Rank exhibits a polynomial-time solution with respect to such an input, we further reflect additional critical problems. We demonstrate that due to the need of constructing an exponentially large Markov chain, \${\textbackslash}alpha\$-Rank is infeasible beyond a small finite number of agents. We ground these claims by adopting amount of dollars spent as a non-refutable evaluation metric. Realising such scalability issue, we present a stochastic implementation of \${\textbackslash}alpha\$-Rank with a double oracle mechanism allowing for reductions in joint strategy spaces. Our method, \${\textbackslash}alpha{\textasciicircum}{\textbackslash}alpha\$-Rank, does not need to save exponentially-large transition matrix, and can terminate early under required precision. Although theoretically our method exhibits similar worst-case complexity guarantees compared to \${\textbackslash}alpha\$-Rank, it allows us, for the first time, to practically conduct large-scale multi-agent evaluations. On \$10{\textasciicircum}4 {\textbackslash}times 10{\textasciicircum}4\$ random matrices, we achieve \$1000x\$ speed reduction. Furthermore, we also show successful results on large joint strategy profiles with a maximum size in the order of \${\textbackslash}mathcal\{O\}(2{\textasciicircum}\{25\})\$ (\${\textbackslash}approx 33\$ million joint strategies) -- a setting not evaluable using \${\textbackslash}alpha\$-Rank with reasonable computational budget.},
	urldate = {2023-08-01},
	publisher = {arXiv},
	author = {Yang, Yaodong and Tutunov, Rasul and Sakulwongtana, Phu and Ammar, Haitham Bou},
	month = mar,
	year = {2020},
	note = {arXiv:1909.11628 [cs]},
	keywords = {Computer Science - Multiagent Systems, Computer Science - Machine Learning},
	file = {arXiv Fulltext PDF:/Users/oliverbiggar/Zotero/storage/KDHS3DIM/Yang et al. - 2020 - \$alpha^ alpha \$-Rank Practically Scaling \$alph.pdf:application/pdf;arXiv.org Snapshot:/Users/oliverbiggar/Zotero/storage/UALI96RS/1909.html:text/html},
}

@inproceedings{du_estimating_2021,
	title = {Estimating \$$\alpha$\$-{Rank} from {A} {Few} {Entries} with {Low} {Rank} {Matrix} {Completion}},
	url = {https://proceedings.mlr.press/v139/du21e.html},
	abstract = {Multi-agent evaluation aims at the assessment of an agent’s strategy on the basis of interaction with others. Typically, existing methods such as ��$\alpha${\textbackslash}alpha-rank and its approximation still require to exhaustively compare all pairs of joint strategies for an accurate ranking, which in practice is computationally expensive. In this paper, we aim to reduce the number of pairwise comparisons in recovering a satisfying ranking for ��nn strategies in two-player meta-games, by exploring the fact that agents with similar skills may achieve similar payoffs against others. Two situations are considered: the first one is when we can obtain the true payoffs; the other one is when we can only access noisy payoff. Based on these formulations, we leverage low-rank matrix completion and design two novel algorithms for noise-free and noisy evaluations respectively. For both of these settings, we theorize that ��(����log��)O(nrlog⁡n)O(nr {\textbackslash}log n) (��nn is the number of agents and ��rr is the rank of the payoff matrix) payoff entries are required to achieve sufficiently well strategy evaluation performance. Empirical results on evaluating the strategies in three synthetic games and twelve real world games demonstrate that strategy evaluation from a few entries can lead to comparable performance to algorithms with full knowledge of the payoff matrix.},
	language = {en},
	urldate = {2023-08-01},
	booktitle = {Proceedings of the 38th {International} {Conference} on {Machine} {Learning}},
	publisher = {PMLR},
	author = {Du, Yali and Yan, Xue and Chen, Xu and Wang, Jun and Zhang, Haifeng},
	month = jul,
	year = {2021},
	note = {ISSN: 2640-3498},
	pages = {2870--2879},
	file = {Full Text PDF:/Users/oliverbiggar/Zotero/storage/SZWWEZ2P/Du et al. - 2021 - Estimating \$$\alpha$\$-Rank from A Few Entries with Low Ra.pdf:application/pdf;Supplementary PDF:/Users/oliverbiggar/Zotero/storage/SABWBKJQ/Du et al. - 2021 - Estimating \$$\alpha$\$-Rank from A Few Entries with Low Ra.pdf:application/pdf},
}

@misc{noauthor_heterogeneity_nodate,
	title = {Heterogeneity {Breaks} the {Game}: {Evaluating} {Cooperation}-{Competition} with {Multisets} of {Agents} {\textbar} {SpringerLink}},
	url = {https://link.springer.com/chapter/10.1007/978-3-031-26412-2_11},
	urldate = {2023-08-01},
	file = {Heterogeneity Breaks the Game Evaluating Cooperat.pdf:/Users/oliverbiggar/Zotero/storage/A5U35EW7/Heterogeneity Breaks the Game Evaluating Cooperat.pdf:application/pdf;Heterogeneity Breaks the Game\: Evaluating Cooperation-Competition with Multisets of Agents | SpringerLink:/Users/oliverbiggar/Zotero/storage/V4KINCUP/978-3-031-26412-2_11.html:text/html},
}

@article{gorsane_towards_2022,
	title = {Towards a {Standardised} {Performance} {Evaluation} {Protocol} for {Cooperative} {MARL}},
	volume = {35},
	url = {https://proceedings.neurips.cc/paper_files/paper/2022/hash/249f73e01f0a2bb6c8d971b565f159a7-Abstract-Conference.html},
	language = {en},
	urldate = {2023-08-01},
	journal = {Advances in Neural Information Processing Systems},
	author = {Gorsane, Rihab and Mahjoub, Omayma and de Kock, Ruan John and Dubb, Roland and Singh, Siddarth and Pretorius, Arnu},
	month = dec,
	year = {2022},
	pages = {5510--5521},
	file = {Full Text PDF:/Users/oliverbiggar/Zotero/storage/AXUKLE7F/Gorsane et al. - 2022 - Towards a Standardised Performance Evaluation Prot.pdf:application/pdf},
}

@article{liu_unified_2022,
	title = {A {Unified} {Diversity} {Measure} for {Multiagent} {Reinforcement} {Learning}},
	volume = {35},
	url = {https://proceedings.neurips.cc/paper_files/paper/2022/hash/435cce71b4007699041dfffa4f034079-Abstract-Conference.html},
	language = {en},
	urldate = {2023-08-01},
	journal = {Advances in Neural Information Processing Systems},
	author = {Liu, Zongkai and Yu, Chao and Yang, Yaodong and Sun, Peng and Wu, Zifan and Li, Yuan},
	month = dec,
	year = {2022},
	pages = {10339--10352},
	file = {Full Text PDF:/Users/oliverbiggar/Zotero/storage/XH59GCNX/Liu et al. - 2022 - A Unified Diversity Measure for Multiagent Reinfor.pdf:application/pdf},
}

@inproceedings{vezhnevets_options_2020,
	title = {{OPtions} as {REsponses}: {Grounding} behavioural hierarchies in multi-agent reinforcement learning},
	shorttitle = {{OPtions} as {REsponses}},
	url = {https://proceedings.mlr.press/v119/vezhnevets20a.html},
	abstract = {This paper investigates generalisation in multi-agent games, where the generality of the agent can be evaluated by playing against opponents it hasn’t seen during training. We propose two new games with concealed information and complex, non-transitive reward structure (think rock-paper-scissors). It turns out that most current deep reinforcement learning methods fail to efficiently explore the strategy space, thus learning policies that generalise poorly to unseen opponents. We then propose a novel hierarchical agent architecture, where the hierarchy is grounded in the game-theoretic structure of the game – the top level chooses strategic responses to opponents, while the low level implements them into policy over primitive actions. This grounding facilitates credit assignment across the levels of hierarchy. Our experiments show that the proposed hierarchical agent is capable of generalisation to unseen opponents, while conventional baselines fail to generalise whatsoever.},
	language = {en},
	urldate = {2023-08-01},
	booktitle = {Proceedings of the 37th {International} {Conference} on {Machine} {Learning}},
	publisher = {PMLR},
	author = {Vezhnevets, Alexander and Wu, Yuhuai and Eckstein, Maria and Leblond, Rémi and Leibo, Joel Z.},
	month = nov,
	year = {2020},
	note = {ISSN: 2640-3498},
	pages = {9733--9742},
	file = {Full Text PDF:/Users/oliverbiggar/Zotero/storage/K48G2CI4/Vezhnevets et al. - 2020 - OPtions as REsponses Grounding behavioural hierar.pdf:application/pdf},
}

@inproceedings{ma_normalizing_2020,
	address = {Cham},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Normalizing {Flow} {Policies} for {Multi}-agent {Systems}},
	isbn = {978-3-030-64793-3},
	doi = {10.1007/978-3-030-64793-3_15},
	abstract = {Stochastic policy gradient methods using neural representations have had considerable success in single-agent domains with continuous action spaces. These methods typically use networks that output the parameters of a diagonal Gaussian distribution from which the resulting action is sampled. In multi-agent contexts, however, better policies may require complex multimodal action distributions. Based on recent progress in density modeling, we propose an alternative for policy representation in the form of conditional normalizing flows. This approach allows for greater flexibility in action distribution representation beyond mixture models. We demonstrate their advantage over standard methods on a set of tasks including human behavior modeling and reinforcement learning in multi-agent settings.},
	language = {en},
	booktitle = {Decision and {Game} {Theory} for {Security}},
	publisher = {Springer International Publishing},
	author = {Ma, Xiaobai and Gupta, Jayesh K. and Kochenderfer, Mykel J.},
	editor = {Zhu, Quanyan and Baras, John S. and Poovendran, Radha and Chen, Juntao},
	year = {2020},
	keywords = {Continuous actions, Continuous security games, Density modeling, Multi-modality, Stochastic policies},
	pages = {277--296},
	file = {Full Text PDF:/Users/oliverbiggar/Zotero/storage/WX9Y7QRS/Ma et al. - 2020 - Normalizing Flow Policies for Multi-agent Systems.pdf:application/pdf},
}

@article{barfuss_dynamical_2022,
	title = {Dynamical systems as a level of cognitive analysis of multi-agent learning},
	volume = {34},
	issn = {1433-3058},
	url = {https://doi.org/10.1007/s00521-021-06117-0},
	doi = {10.1007/s00521-021-06117-0},
	abstract = {A dynamical systems perspective on multi-agent learning, based on the link between evolutionary game theory and reinforcement learning, provides an improved, qualitative understanding of the emerging collective learning dynamics. However, confusion exists with respect to how this dynamical systems account of multi-agent learning should be interpreted. In this article, I propose to embed the dynamical systems description of multi-agent learning into different abstraction levels of cognitive analysis. The purpose of this work is to make the connections between these levels explicit in order to gain improved insight into multi-agent learning. I demonstrate the usefulness of this framework with the general and widespread class of temporal-difference reinforcement learning. I find that its deterministic dynamical systems description follows a minimum free-energy principle and unifies a boundedly rational account of game theory with decision-making under uncertainty. I then propose an on-line sample-batch temporal-difference algorithm which is characterized by the combination of applying a memory-batch and separated state-action value estimation. I find that this algorithm serves as a micro-foundation of the deterministic learning equations by showing that its learning trajectories approach the ones of the deterministic learning equations under large batch sizes. Ultimately, this framework of embedding a dynamical systems description into different abstraction levels gives guidance on how to unleash the full potential of the dynamical systems approach to multi-agent learning.},
	language = {en},
	number = {3},
	urldate = {2023-08-01},
	journal = {Neural Computing and Applications},
	author = {Barfuss, Wolfram},
	month = feb,
	year = {2022},
	keywords = {Evolutionary game theory, Levels of analysis, Multi-agent learning, Temporal-difference reinforcement learning},
	pages = {1653--1671},
	file = {Full Text PDF:/Users/oliverbiggar/Zotero/storage/YWJA8MND/Barfuss - 2022 - Dynamical systems as a level of cognitive analysis.pdf:application/pdf},
}

@inproceedings{hernandez_metagame_2020,
	title = {Metagame {Autobalancing} for {Competitive} {Multiplayer} {Games}},
	doi = {10.1109/CoG47356.2020.9231762},
	abstract = {Automated game balancing has often focused on single-agent scenarios. In this paper we present a tool for balancing multi-player games during game design. Our approach requires a designer to construct an intuitive graphical representation of their meta-game target, representing the relative scores that high-level strategies (or decks, or character types) should experience. This permits more sophisticated balance targets to be defined beyond a simple requirement of equal win chances. We then find a parameterization of the game that meets this target using simulation-based optimization to minimize the distance to the target graph. We show the capabilities of this tool on examples inheriting from Rock-Paper-Scissors, and on a more complex asymmetric fighting game.},
	booktitle = {2020 {IEEE} {Conference} on {Games} ({CoG})},
	author = {Hernandez, Daniel and Toyin Gbadamosi, Charles Takashi and Goodman, James and Walker, James Alfred},
	month = aug,
	year = {2020},
	note = {ISSN: 2325-4289},
	keywords = {Games, Tools, Cognition, Reinforcement learning, Sociology, Statistics, Testing},
	pages = {275--282},
	file = {Accepted Version:/Users/oliverbiggar/Zotero/storage/LV4RGJUH/Hernandez et al. - 2020 - Metagame Autobalancing for Competitive Multiplayer.pdf:application/pdf;IEEE Xplore Abstract Record:/Users/oliverbiggar/Zotero/storage/U9NBYEEV/9231762.html:text/html},
}

@article{yan_policy_2022,
	title = {Policy {Evaluation} and {Seeking} for {Multiagent} {Reinforcement} {Learning} via {Best} {Response}},
	volume = {67},
	issn = {1558-2523},
	doi = {10.1109/TAC.2021.3085171},
	abstract = {Multiagent policy evaluation and seeking are long-standing challenges in developing theories for multiagent reinforcement learning (MARL), due to multidimensional learning goals, nonstationary environment, and scalability issues in the joint policy space. This article introduces two metrics grounded on a game-theoretic solution concept called sink equilibrium, for the evaluation, ranking, and computation of policies in multiagent learning. We adopt strict best response dynamics (SBRDs) to model selfish behaviors at a meta-level for MARL. Our approach can deal with dynamical cyclical behaviors (unlike approaches based on Nash equilibria and Elo ratings), and is more compatible with single-agent reinforcement learning than $\alpha$-rank, which relies on weakly better responses. We first consider settings where the difference between the largest and second largest equilibrium metric has a known lower bound. With this knowledge, we propose a class of perturbed SBRD with the following property: only policies with maximum metric are observed with nonzero probability for a broad class of stochastic games with finite memory. We then consider settings where the lower bound for the difference is unknown. For this setting, we propose a class of perturbed SBRD such that the metrics of the policies observed with nonzero probability differ from the optimal by any given tolerance. The proposed perturbed SBRD addresses the scalability issue and opponent-induced nonstationarity by fixing the strategies of others for the learning agent, and uses empirical game-theoretic analysis to estimate payoffs for each strategy profile obtained due to the perturbation.},
	number = {4},
	journal = {IEEE Transactions on Automatic Control},
	author = {Yan, Rui and Duan, Xiaoming and Shi, Zongying and Zhong, Yisheng and Marden, Jason R. and Bullo, Francesco},
	month = apr,
	year = {2022},
	note = {Conference Name: IEEE Transactions on Automatic Control},
	keywords = {Nash equilibrium, Convergence, Games, Heuristic algorithms, Best response, Measurement, multiagent reinforcement learning, Perturbation methods, policy evaluation and seeking, Scalability, sink equilibrium, stochastic stability},
	pages = {1898--1913},
	file = {IEEE Xplore Abstract Record:/Users/oliverbiggar/Zotero/storage/25KFVYVQ/9444583.html:text/html;Submitted Version:/Users/oliverbiggar/Zotero/storage/BWHKNSKI/Yan et al. - 2022 - Policy Evaluation and Seeking for Multiagent Reinf.pdf:application/pdf},
}

@article{wirth_survey_2017,
	title = {A survey of preference-based reinforcement learning methods},
	volume = {18},
	issn = {1532-4435},
	number = {136},
	journal = {Journal of Machine Learning Research},
	author = {Wirth, Christian and Akrour, Riad and Neumann, Gerhard and Fürnkranz, Johannes},
	year = {2017},
	note = {Publisher: Journal of Machine Learning Research/Massachusetts Institute of Technology …},
	pages = {1--46},
}

@article{chotibut_family_2021,
	title = {Family of chaotic maps from game theory},
	volume = {36},
	issn = {1468-9367},
	url = {https://doi.org/10.1080/14689367.2020.1795624},
	doi = {10.1080/14689367.2020.1795624},
	abstract = {From a two-agent, two-strategy congestion game where both agents apply the multiplicative weights update algorithm, we obtain a two-parameter family of maps of the unit square to itself. Interesting dynamics arise on the invariant diagonal, on which a two-parameter family of bimodal interval maps exhibits periodic orbits and chaos. While the fixed point b corresponding to a Nash equilibrium of such map f is usually repelling, it is globally Cesàro attracting on the diagonal, that is, limn→∞1n∑k=0n−1fk(x)=b for every x∈(0,1). This solves a known open question whether there exists a ‘natural’ nontrivial smooth map other than x↦axe−x with centres of mass of all periodic orbits coinciding. We also study the dependence of the dynamics on the two parameters.},
	number = {1},
	urldate = {2023-08-02},
	journal = {Dynamical Systems},
	author = {Chotibut, Thiparat and Falniowski, Fryderyk and Misiurewicz, Michał and Piliouras, Georgios},
	month = jan,
	year = {2021},
	note = {Publisher: Taylor \& Francis
\_eprint: https://doi.org/10.1080/14689367.2020.1795624},
	keywords = {37E05, 91A05, centre of mass, Chaos, congestion game, interval maps, multiplicative weights},
	pages = {48--63},
	file = {Submitted Version:/Users/oliverbiggar/Zotero/storage/Z4PSQCYY/Chotibut et al. - 2021 - Family of chaotic maps from game theory.pdf:application/pdf},
}

@misc{muller_generalized_2020,
	type = {Proceedings paper},
	title = {A {Generalized} {Training} {Approach} for {Multiagent} {Learning}},
	copyright = {open},
	url = {https://openreview.net/group?id=ICLR.cc/2020/Conference},
	abstract = {This paper investigates a population-based training regime based on game-theoretic principles called Policy-Spaced Response Oracles (PSRO). PSRO is general in the sense that it (1) encompasses well-known algorithms such as fictitious play and double oracle as special cases, and (2) in principle applies to general-sum, many-player games. Despite this, prior studies of PSRO have been focused on two-player zero-sum games, a regime where in Nash equilibria are tractably computable. In moving from two-player zero-sum games to more general settings, computation of Nash equilibria quickly becomes infeasible.  Here, we extend the theoretical underpinnings of PSRO by considering an alternative solution concept, $\alpha$-Rank, which is unique (thus faces no equilibrium selection issues, unlike Nash) and applies readily to general-sum, many-player settings. We establish convergence guarantees in several games classes, and identify links between Nash equilibria and $\alpha$-Rank. We demonstrate the competitive performance of $\alpha$-Rank-based PSRO against an exact Nash solver-based PSRO in 2-player Kuhn and Leduc Poker. We then go beyond the reach of prior PSRO applications by considering 3- to 5-player poker games, yielding instances where $\alpha$-Rank achieves faster convergence than approximate Nash solvers, thus establishing it as a favorable general games solver. We also carry out an initial empirical validation in MuJoCo soccer, illustrating the feasibility of the proposed approach in another complex domain.},
	language = {eng},
	urldate = {2023-08-02},
	journal = {ICLR},
	author = {Muller, P. and Omidshafiei, S. and Rowland, M. and Tuyls, K. and Pérolat, J. and Liu, S. and Hennes, D. and Marris, L. and Lanctot, M. and Hughes, E. and Wang, Z. and Lever, G. and Heess, N. and Graepel, T. and Munos, R.},
	year = {2020},
	note = {Conference Name: 8th International Conference on Learning Representations, ICLR 2020
Meeting Name: 8th International Conference on Learning Representations, ICLR 2020
Pages: 1-35
Publisher: ICLR},
	file = {Full Text PDF:/Users/oliverbiggar/Zotero/storage/Y7RWQWEC/Muller et al. - 2020 - A Generalized Training Approach for Multiagent Lea.pdf:application/pdf;Snapshot:/Users/oliverbiggar/Zotero/storage/GLLPXGLZ/10109593.html:text/html},
}

@book{conley_isolated_1978,
	title = {Isolated invariant sets and the {Morse} index},
	isbn = {0-8218-1688-8},
	publisher = {American Mathematical Soc.},
	author = {Conley, Charles C},
	year = {1978},
	note = {Issue: 38},
}

@misc{noauthor_concept_nodate,
	title = {On the concept of attractor {\textbar} {SpringerLink}},
	url = {https://link.springer.com/article/10.1007/BF01212280},
	urldate = {2023-08-02},
	file = {On the concept of attractor  SpringerLink.pdf:/Users/oliverbiggar/Zotero/storage/EEFF7K59/On the concept of attractor  SpringerLink.pdf:application/pdf;On the concept of attractor | SpringerLink:/Users/oliverbiggar/Zotero/storage/R3GFCEUT/BF01212280.html:text/html},
}

@article{ritzberger_evolutionary_1995,
	title = {Evolutionary {Selection} in {Normal}-{Form} {Games}},
	volume = {63},
	issn = {0012-9682},
	url = {https://www.jstor.org/stable/2171774},
	doi = {10.2307/2171774},
	abstract = {This paper investigates stability properties of evolutionary selection dynamics in normal-form games. The analysis is focused on deterministic dynamics in continuous time and on asymptotic stability of sets of population states, more precisely of faces of the mixed-strategy space. The main result is a characterization of those faces which are asymptotically stable in all dynamics from a certain class, and we show that every such face contains an essential component of the set of Nash equilibria, and hence a strategically stable set in the sense of Kohlberg and Mertens (1986).},
	number = {6},
	urldate = {2023-08-02},
	journal = {Econometrica},
	author = {Ritzberger, Klaus and Weibull, Jörgen W.},
	year = {1995},
	note = {Publisher: [Wiley, Econometric Society]},
	pages = {1371--1399},
	file = {JSTOR Full Text PDF:/Users/oliverbiggar/Zotero/storage/U6MLSB8F/Ritzberger and Weibull - 1995 - Evolutionary Selection in Normal-Form Games.pdf:application/pdf},
}

@article{schuster_replicator_1983,
	title = {Replicator dynamics},
	volume = {100},
	issn = {0022-5193},
	url = {https://www.sciencedirect.com/science/article/pii/0022519383904459},
	doi = {10.1016/0022-5193(83)90445-9},
	abstract = {Several evolutionary models in distinct biological fields—population genetics, population ecology, early biochemical evolution and sociobiology—lead independently to the same class of replicator dynamics.},
	language = {en},
	number = {3},
	urldate = {2023-08-02},
	journal = {Journal of Theoretical Biology},
	author = {Schuster, Peter and Sigmund, Karl},
	month = feb,
	year = {1983},
	pages = {533--538},
	file = {ScienceDirect Full Text PDF:/Users/oliverbiggar/Zotero/storage/KW464HS6/Schuster and Sigmund - 1983 - Replicator dynamics.pdf:application/pdf;ScienceDirect Snapshot:/Users/oliverbiggar/Zotero/storage/KMPGNDIM/0022519383904459.html:text/html},
}

@inproceedings{zeeman_population_1980,
	address = {Berlin, Heidelberg},
	series = {Lecture {Notes} in {Mathematics}},
	title = {Population dynamics from game theory},
	isbn = {978-3-540-38312-3},
	doi = {10.1007/BFb0087009},
	language = {en},
	booktitle = {Global {Theory} of {Dynamical} {Systems}},
	publisher = {Springer},
	author = {Zeeman, E. C.},
	editor = {Nitecki, Zbigniew and Robinson, Clark},
	year = {1980},
	keywords = {Evolutionarily Stable Strategy, Hopf Bifurcation, Periodic Orbit, Phase Portrait, Unique Fixed Point},
	pages = {471--497},
	file = {Full Text PDF:/Users/oliverbiggar/Zotero/storage/FKRXZT66/Zeeman - 1980 - Population dynamics from game theory.pdf:application/pdf},
}

@article{taylor_evolutionary_1978,
	title = {Evolutionary stable strategies and game dynamics},
	volume = {40},
	issn = {0025-5564},
	url = {https://www.sciencedirect.com/science/article/pii/0025556478900779},
	doi = {10.1016/0025-5564(78)90077-9},
	abstract = {We consider a class of matrix games in which successful strategies are rewarded by high reproductive rates, so become more likely to participate in subsequent playings of the game. Thus, over time, the strategy mix should evolve to some type of optimal or stable state. Maynard Smith and Price (1973) have introduced the concept of ESS (evolutionarily stable strategy) to describe a stable state of the game. We attempt to model the dynamics of the game both in the continuous case, with a system of non-linear first-order differential equations, and in the discrete case, with a system of non-linear difference equations. Using this model, we look at the notions of stability and asymptotic behavior. Our notion of stable equilibrium for the continuous dynamic includes, but is somewhat more general than, the notion of ESS.},
	language = {en},
	number = {1},
	urldate = {2023-08-02},
	journal = {Mathematical Biosciences},
	author = {Taylor, Peter D. and Jonker, Leo B.},
	month = jul,
	year = {1978},
	pages = {145--156},
	file = {ScienceDirect Full Text PDF:/Users/oliverbiggar/Zotero/storage/FR92RNWL/Taylor and Jonker - 1978 - Evolutionary stable strategies and game dynamics.pdf:application/pdf;ScienceDirect Snapshot:/Users/oliverbiggar/Zotero/storage/UHTKYGCH/0025556478900779.html:text/html},
}

@article{chotibut_family_2021-1,
	title = {Family of chaotic maps from game theory},
	volume = {36},
	issn = {1468-9367},
	url = {https://doi.org/10.1080/14689367.2020.1795624},
	doi = {10.1080/14689367.2020.1795624},
	abstract = {From a two-agent, two-strategy congestion game where both agents apply the multiplicative weights update algorithm, we obtain a two-parameter family of maps of the unit square to itself. Interesting dynamics arise on the invariant diagonal, on which a two-parameter family of bimodal interval maps exhibits periodic orbits and chaos. While the fixed point b corresponding to a Nash equilibrium of such map f is usually repelling, it is globally Cesàro attracting on the diagonal, that is, limn→∞1n∑k=0n−1fk(x)=b for every x∈(0,1). This solves a known open question whether there exists a ‘natural’ nontrivial smooth map other than x↦axe−x with centres of mass of all periodic orbits coinciding. We also study the dependence of the dynamics on the two parameters.},
	number = {1},
	urldate = {2023-08-02},
	journal = {Dynamical Systems},
	author = {Chotibut, Thiparat and Falniowski, Fryderyk and Misiurewicz, Michał and Piliouras, Georgios},
	month = jan,
	year = {2021},
	note = {Publisher: Taylor \& Francis
\_eprint: https://doi.org/10.1080/14689367.2020.1795624},
	keywords = {37E05, 91A05, centre of mass, Chaos, congestion game, interval maps, multiplicative weights},
	pages = {48--63},
	file = {Submitted Version:/Users/oliverbiggar/Zotero/storage/BQG5UEU9/Chotibut et al. - 2021 - Family of chaotic maps from game theory.pdf:application/pdf},
}

@article{kandori_learning_1993,
	title = {Learning, {Mutation}, and {Long} {Run} {Equilibria} in {Games}},
	volume = {61},
	issn = {0012-9682},
	url = {https://www.jstor.org/stable/2951777},
	doi = {10.2307/2951777},
	abstract = {We analyze an evolutionary model with a finite number of players and with noise or mutations. The expansion and contraction of strategies is linked--as usual--to their current relative success, but mutations--which perturb the system away from its deterministic evolution--are present as well. Mutations can occur in every period, so the focus is on the implications of ongoing mutations, not a one-shot mutation. The effect of these mutations is to drastically reduce the set of equilibria to what we term "long-run equilibria." For 2 × 2 symmetric games with two symmetric strict Nash equilibria the equilibrium selected satisfies (for large populations) Harsanyi and Selten's (1988) criterion of risk-dominance. In particular, if both strategies have equal security levels, the Pareto dominant Nash equilibrium is selected, even though there is another strict Nash equilibrium.},
	number = {1},
	urldate = {2023-08-03},
	journal = {Econometrica},
	author = {Kandori, Michihiro and Mailath, George J. and Rob, Rafael},
	year = {1993},
	note = {Publisher: [Wiley, Econometric Society]},
	pages = {29--56},
	file = {JSTOR Full Text PDF:/Users/oliverbiggar/Zotero/storage/H7DMZYGN/Kandori et al. - 1993 - Learning, Mutation, and Long Run Equilibria in Gam.pdf:application/pdf},
}

@inproceedings{p_andrade_no-regret_2023,
	address = {New York, NY, USA},
	series = {{EC} '23},
	title = {No-{Regret} {Learning} in {Games} is {Turing} {Complete}},
	isbn = {9798400701047},
	url = {https://dl.acm.org/doi/10.1145/3580507.3597714},
	doi = {10.1145/3580507.3597714},
	abstract = {Many multi-agent machine learning settings can be modeled as games, from social or economic systems with algorithmic decision-makers to popular learning architectures such as generative adversarial networks (GANs). Desired outcomes in these settings are often encoded as equilibrium concepts, and therefore a primary goal is identifying machine learning algorithms with provable convergence to these equilibria. However, a growing body of negative results casts doubt on this goal by uncovering games exhibiting non-convergence, chaos, and even essentially arbitrary behaviour [Andrade et al. 2021; Benaïm et al. 2012; Cheung and Piliouras 2019; Chotibut et al. 2020; Flokas et al. 2020; Letcher 2021; Milionis et al. 2022; Wibisono et al. 2022].},
	urldate = {2023-08-06},
	booktitle = {Proceedings of the 24th {ACM} {Conference} on {Economics} and {Computation}},
	publisher = {Association for Computing Machinery},
	author = {P. Andrade, Gabriel and Frongillo, Rafael and Piliouras, Georgios},
	month = jul,
	year = {2023},
	pages = {111},
	file = {Full Text PDF:/Users/oliverbiggar/Zotero/storage/2WMDWNLG/P. Andrade et al. - 2023 - No-Regret Learning in Games is Turing Complete.pdf:application/pdf},
}

@inproceedings{farach-colton_graph_2023,
	address = {New York, NY, USA},
	series = {{EC} '23},
	title = {Graph {Ranking} and the {Cost} of {Sybil} {Defense}},
	isbn = {9798400701047},
	url = {https://dl.acm.org/doi/10.1145/3580507.3597782},
	doi = {10.1145/3580507.3597782},
	abstract = {Ranking functions such as PageRank assign numeric values (ranks) to nodes of graphs, most notably the web graph. Node rankings are an integral part of Internet search algorithms, since they can be used to order the results of queries. However, these ranking functions are famously subject to attacks by spammers, who modify the web graph in order to give their own pages more rank. We characterize the interplay between rankers and spammers as a game. We define the two critical features of this game, spam resistance and distortion, based on how spammers spam and how rankers protect against spam. We observe that all the ranking functions that are well-studied in the literature, including the original formulation of PageRank, have poor spam resistance, poor distortion, or both. Finally, we study Min-PPR, the form of PageRank used at Google itself, but which has received no (theoretical or empirical) treatment in the literature. We prove that Min-PPR has low distortion and high spam resistance. A secondary benefit is that Min-PPR comes with an explicit cost function on nodes that shows how important they are to the spammer; thus a ranker can focus their spam-detection capacity on these vulnerable nodes. Both Min-PPR and its associated cost function are straightforward to compute.},
	urldate = {2023-08-06},
	booktitle = {Proceedings of the 24th {ACM} {Conference} on {Economics} and {Computation}},
	publisher = {Association for Computing Machinery},
	author = {Farach-Colton, Gwendolyn and Farach-Colton, Martin and Goldberg, Leslie Ann and Komlos, Hanna and Lapinskas, John and Levi, Reut and Medina, Moti and Mosteiro, Miguel A.},
	month = jul,
	year = {2023},
	pages = {586--625},
	file = {Full Text PDF:/Users/oliverbiggar/Zotero/storage/UZFC9CFR/Farach-Colton et al. - 2023 - Graph Ranking and the Cost of Sybil Defense.pdf:application/pdf},
}

@inproceedings{frongillo_agreement_2023,
	address = {New York, NY, USA},
	series = {{EC} '23},
	title = {Agreement {Implies} {Accuracy} for {Substitutable} {Signals}},
	isbn = {9798400701047},
	url = {https://dl.acm.org/doi/10.1145/3580507.3597679},
	doi = {10.1145/3580507.3597679},
	abstract = {Inspired by Aumann's agreement theorem, Aaronson [2005] studied the amount of communication necessary for two Bayesian experts to approximately agree on the expectation of a random variable. Aaronson showed that, remarkably, the number of bits does not depend on the amount of information available to each expert. However, in general the agreed-upon estimate may be inaccurate: far from the estimate they would settle on if they were to share all of their information. We show that if the experts' signals are substitutes---meaning the experts' information has diminishing marginal returns---then it is the case that if the experts are close to agreement then they are close to the truth. We prove this result for a broad class of agreement and accuracy measures that includes squared distance and KL divergence. Additionally, we show that although these measures capture fundamentally different kinds of agreement, Aaronson's agreement result generalizes to them as well.},
	urldate = {2023-08-06},
	booktitle = {Proceedings of the 24th {ACM} {Conference} on {Economics} and {Computation}},
	publisher = {Association for Computing Machinery},
	author = {Frongillo, Rafael and Neyman, Eric and Waggoner, Bo},
	month = jul,
	year = {2023},
	keywords = {agreement, communication protocols, information structures, informational substitutes},
	pages = {702--733},
	file = {Full Text PDF:/Users/oliverbiggar/Zotero/storage/3YQP6TKQ/Frongillo et al. - 2023 - Agreement Implies Accuracy for Substitutable Signa.pdf:application/pdf},
}

@inproceedings{piliouras_multi-agent_2023,
	address = {New York, NY, USA},
	series = {{EC} '23},
	title = {Multi-agent {Performative} {Prediction}: {From} {Global} {Stability} and {Optimality} to {Chaos}},
	isbn = {9798400701047},
	shorttitle = {Multi-agent {Performative} {Prediction}},
	url = {https://dl.acm.org/doi/10.1145/3580507.3597759},
	doi = {10.1145/3580507.3597759},
	abstract = {The recent framework of performative prediction [Perdomo et al. 2020] is aimed at capturing settings where predictions influence the outcome they want to predict. In this paper, we introduce a natural multi-agent version of this framework, where multiple decision makers try to predict the same outcome. We showcase that such competition can result in interesting phenomena by proving the possibility of phase transitions from stability to instability and eventually chaos. Specifically, we present settings of multi-agent performative prediction where under sufficient conditions their dynamics lead to global stability and optimality. In the opposite direction, when the agents are not sufficiently cautious in their learning/updates rates, we show that instability and in fact formal chaos is possible. We complement our theoretical predictions with simulations showcasing the predictive power of our results.},
	urldate = {2023-08-06},
	booktitle = {Proceedings of the 24th {ACM} {Conference} on {Economics} and {Computation}},
	publisher = {Association for Computing Machinery},
	author = {Piliouras, Georgios and Yu, Fang-Yi},
	month = jul,
	year = {2023},
	keywords = {bifurcation, exponentiated gradient, li-yorke chaos, performative prediction},
	pages = {1047--1074},
	file = {Full Text PDF:/Users/oliverbiggar/Zotero/storage/6N6TNRD9/Piliouras and Yu - 2023 - Multi-agent Performative Prediction From Global S.pdf:application/pdf},
}

@article{gorsane_towards_2022-1,
	title = {Towards a {Standardised} {Performance} {Evaluation} {Protocol} for {Cooperative} {MARL}},
	volume = {35},
	url = {https://proceedings.neurips.cc/paper_files/paper/2022/hash/249f73e01f0a2bb6c8d971b565f159a7-Abstract-Conference.html},
	language = {en},
	urldate = {2023-08-07},
	journal = {Advances in Neural Information Processing Systems},
	author = {Gorsane, Rihab and Mahjoub, Omayma and de Kock, Ruan John and Dubb, Roland and Singh, Siddarth and Pretorius, Arnu},
	month = dec,
	year = {2022},
	pages = {5510--5521},
	file = {Full Text PDF:/Users/oliverbiggar/Zotero/storage/PIG76PII/Gorsane et al. - 2022 - Towards a Standardised Performance Evaluation Prot.pdf:application/pdf},
}

@article{fukuda_criss-cross_1997,
	title = {Criss-cross methods: {A} fresh view on pivot algorithms},
	volume = {79},
	issn = {1436-4646},
	shorttitle = {Criss-cross methods},
	url = {https://doi.org/10.1007/BF02614325},
	doi = {10.1007/BF02614325},
	abstract = {Criss-cross methods are pivot algorithms that solve linear programming problems in one phase starting with any basic solution. The first finite criss-cross method was invented by Chang, Terlaky and Wang independently. Unlike the simplex method that follows a monotonic edge path on the feasible region, the trace of a criss-cross method is neither monotonic (with respect to the objective function) nor feasibility preserving. The main purpose of this paper is to present mathematical ideas and proof techniques behind finite criss-cross pivot methods. A recent result on the existence of a short admissible pivot path to an optimal basis is given, indicating shortest pivot paths from any basis might be indeed short for criss-cross type algorithms. The origins and the history of criss-cross methods are also touched upon.},
	language = {en},
	number = {1},
	urldate = {2023-08-13},
	journal = {Mathematical Programming},
	author = {Fukuda, Komei and Terlaky, Tamás},
	month = oct,
	year = {1997},
	keywords = {Criss-cross method, Cycling, Linear complementarity problems, Linear programming, Oriented matroids, Pivot rules, Quadratic programming, Recursion},
	pages = {369--395},
	file = {Full Text PDF:/Users/oliverbiggar/Zotero/storage/JFNIRMQT/Fukuda and Terlaky - 1997 - Criss-cross methods A fresh view on pivot algorit.pdf:application/pdf},
}

@article{yan_evaluation_2023,
	title = {Evaluation and {Learning} in {Two}-{Player} {Symmetric} {Games} via {Best} and {Better} {Responses}},
	issn = {0020-0255},
	url = {https://www.sciencedirect.com/science/article/pii/S0020025523010447},
	doi = {10.1016/j.ins.2023.119459},
	abstract = {This paper focuses on filling the gap between strategy evaluation and strategy learning in two-player symmetric games, as a learning algorithm may converge to the strategies not preferred by an evaluation metric. When a player determines its strategies, it needs to first evaluate candidate strategies without knowing the opponents' decisions. Then, based on the result of the evaluation, a preferred strategy is selected. On the contrary, many multi-agent reinforcement learning algorithms are constructed provided that the strategies of other players are known in each training episode. In this paper, we first introduce two graph-based metrics grounded on sink equilibrium to characterize the preferred strategies of the players in strategy evaluation. These metrics can be regarded as generalized solution concepts in games. Then, we propose two variants of the classical self-play algorithm, named strictly best-response and weakly better-response self-plays, to learn the strategies for the players. By modeling the learning processes as walks over joint-strategy response digraphs, we prove that under some conditions, the learned strategies by two variants are the preferred strategies under two metrics, respectively, which thus fills the evaluation–learning gap, and ensures that the preferred strategies are learned. We also investigate the relationship between the two metrics.},
	urldate = {2023-08-15},
	journal = {Information Sciences},
	author = {Yan, Rui and Zhang, Weixian and Deng, Ruiliang and Duan, Xiaoming and Shi, Zongying and Zhong, Yisheng},
	month = aug,
	year = {2023},
	keywords = {best and better responses, game theory, multi-agent reinforcement learning, self-play, strategy evaluation},
	pages = {119459},
	file = {ScienceDirect Snapshot:/Users/oliverbiggar/Zotero/storage/IX4436JZ/S0020025523010447.html:text/html;Yan et al. - 2023 - Evaluation and Learning in Two-Player Symmetric Ga.pdf:/Users/oliverbiggar/Zotero/storage/BB2F3JXX/Yan et al. - 2023 - Evaluation and Learning in Two-Player Symmetric Ga.pdf:application/pdf},
}

@article{adler_equivalence_2013,
	title = {The equivalence of linear programs and zero-sum games},
	volume = {42},
	issn = {1432-1270},
	url = {https://doi.org/10.1007/s00182-012-0328-8},
	doi = {10.1007/s00182-012-0328-8},
	abstract = {In 1951, Dantzig showed the equivalence of linear programming problems and two-person zero-sum games. However, in the description of his reduction from linear programs to zero-sum games, he noted that there was one case in which the reduction does not work. This also led to incomplete proofs of the relationship between the Minimax Theorem of game theory and the Strong Duality Theorem of linear programming. In this note, we fill these gaps.},
	language = {en},
	number = {1},
	urldate = {2023-08-20},
	journal = {International Journal of Game Theory},
	author = {Adler, Ilan},
	month = feb,
	year = {2013},
	keywords = {Zero-sum games, Minimax theorem, Linear programming, Farkas’ lemma, Strong duality, Villes’ theorem},
	pages = {165--177},
	file = {Full Text PDF:/Users/oliverbiggar/Zotero/storage/RRHG22CS/Adler - 2013 - The equivalence of linear programs and zero-sum ga.pdf:application/pdf},
}

@inproceedings{daskalakis_limit_2018,
	title = {The {Limit} {Points} of ({Optimistic}) {Gradient} {Descent} in {Min}-{Max} {Optimization}},
	volume = {31},
	url = {https://proceedings.neurips.cc/paper/2018/hash/139c3c1b7ca46a9d4fd6d163d98af635-Abstract.html},
	abstract = {Motivated by applications in Optimization, Game Theory, and the training of Generative Adversarial Networks, the convergence properties of first order methods in min-max problems have received extensive study. It has been recognized that they may cycle, and there is no good understanding of their limit points when they do not. When they converge, do they converge to local min-max solutions? We characterize the limit points of two basic first order methods, namely Gradient Descent/Ascent (GDA) and Optimistic Gradient Descent Ascent (OGDA).  We show that both dynamics avoid unstable critical points for almost all initializations. Moreover, for small step sizes and under mild assumptions, the set of  OGDA-stable critical points is a superset of GDA-stable critical points, which is a superset of local min-max solutions (strict in some cases). The connecting thread is that the behavior of these dynamics can be studied from a dynamical systems perspective.},
	urldate = {2023-08-20},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	publisher = {Curran Associates, Inc.},
	author = {Daskalakis, Constantinos and Panageas, Ioannis},
	year = {2018},
	file = {Full Text PDF:/Users/oliverbiggar/Zotero/storage/6IWCBVLY/Daskalakis and Panageas - 2018 - The Limit Points of (Optimistic) Gradient Descent .pdf:application/pdf},
}

@inproceedings{daskalakis_complexity_2021,
	address = {New York, NY, USA},
	series = {{STOC} 2021},
	title = {The complexity of constrained min-max optimization},
	isbn = {978-1-4503-8053-9},
	url = {https://dl.acm.org/doi/10.1145/3406325.3451125},
	doi = {10.1145/3406325.3451125},
	abstract = {Despite its important applications in Machine Learning, min-max optimization of objective functions that are nonconvex-nonconcave remains elusive. Not only are there no known first-order methods converging to even approximate local min-max equilibria (a.k.a. approximate saddle points), but the computational complexity of identifying them is also poorly understood. In this paper, we provide a characterization of the computational complexity as well as of the limitations of first-order methods in this problem. Specifically, we show that in linearly constrained min-max optimization problems with nonconvex-nonconcave objectives an approximate local min-max equilibrium of large enough approximation is guaranteed to exist, but computing such a point is PPAD-complete. The same is true of computing an approximate fixed point of the (Projected) Gradient Descent/Ascent update dynamics, which is computationally equivalent to computing approximate local min-max equilibria. An important byproduct of our proof is to establish an unconditional hardness result in the Nemirovsky-Yudin 1983 oracle optimization model, where we are given oracle access to the values of some function f : P → [−1, 1] and its gradient ∇ f, where P ⊆ [0, 1]d is a known convex polytope. We show that any algorithm that uses such first-order oracle access to f and finds an ε-approximate local min-max equilibrium needs to make a number of oracle queries that is exponential in at least one of 1/ε, L, G, or d, where L and G are respectively the smoothness and Lipschitzness of f. This comes in sharp contrast to minimization problems, where finding approximate local minima in the same setting can be done with Projected Gradient Descent using O(L/ε) many queries. Our result is the first to show an exponential separation between these two fundamental optimization problems in the oracle model.},
	urldate = {2023-08-20},
	booktitle = {Proceedings of the 53rd {Annual} {ACM} {SIGACT} {Symposium} on {Theory} of {Computing}},
	publisher = {Association for Computing Machinery},
	author = {Daskalakis, Constantinos and Skoulakis, Stratis and Zampetakis, Manolis},
	month = jun,
	year = {2021},
	keywords = {black-box lower bounds, computational complexity, min-max optimization, PPAD, TFNP},
	pages = {1466--1478},
	file = {Full Text PDF:/Users/oliverbiggar/Zotero/storage/TJEPMJB9/Daskalakis et al. - 2021 - The complexity of constrained min-max optimization.pdf:application/pdf},
}

@incollection{daskalakis_near-optimal_2011,
	series = {Proceedings},
	title = {Near-{Optimal} {No}-{Regret} {Algorithms} for {Zero}-{Sum} {Games}},
	isbn = {978-0-89871-993-2},
	url = {https://epubs.siam.org/doi/abs/10.1137/1.9781611973082.21},
	abstract = {We propose a new no-regret learning algorithm. When used against an adversary, our algorithm achieves average regret that scales as  with the number T of rounds. This regret bound is optimal but not rare, as there are a multitude of learning algorithms with this regret guarantee. However, when our algorithm is used by both players of a zero-sum game, their average regret scales as , guaranteeing a near-linear rate of convergence to the value of the game. This represents an almost-quadratic improvement on the rate of convergence to the value of a game known to be achieved by any no-regret learning algorithm, and is essentially optimal as we show a lower bound of . Moreover, the dynamics produced by our algorithm in the game setting are strongly-uncoupled in that each player is oblivious to the payoff matrix of the game and the number of strategies of the other player, has limited private storage, and is not allowed funny bit arithmetic that can trivialize the problem; instead he only observes the performance of his strategies against the actions of the other player and can use private storage to remember past played strategies and observed payoffs, or cumulative information thereof. Here, too, our rate of convergence is nearly-optimal and represents an almost-quadratic improvement over the best previously known strongly-uncoupled dynamics.},
	urldate = {2023-08-20},
	booktitle = {Proceedings of the 2011 {Annual} {ACM}-{SIAM} {Symposium} on {Discrete} {Algorithms} ({SODA})},
	publisher = {Society for Industrial and Applied Mathematics},
	author = {Daskalakis, Constantinos and Deckelbaum, Alan and Kim, Anthony},
	month = jan,
	year = {2011},
	doi = {10.1137/1.9781611973082.21},
	pages = {235--254},
	file = {Full Text PDF:/Users/oliverbiggar/Zotero/storage/SQNIJWYH/Daskalakis et al. - 2011 - Near-Optimal No-Regret Algorithms for Zero-Sum Gam.pdf:application/pdf},
}

@incollection{cai_minmax_2011,
	series = {Proceedings},
	title = {On {Minmax} {Theorems} for {Multiplayer} {Games}},
	isbn = {978-0-89871-993-2},
	url = {https://epubs.siam.org/doi/abs/10.1137/1.9781611973082.20},
	abstract = {We prove a generalization of von Neumann's minmax theorem to the class of separable multiplayer zero-sum games, introduced in [Bregman and Fokin 1998]. These games are polymatrix—that is, graphical games in which every edge is a two-player game between its endpoints—in which every outcome has zero total sum of players’ payoffs. Our generalization of the minmax theorem implies convexity of equilibria, polynomial-time tractability, and convergence of no-regret learning algorithms to Nash equilibria. Given that Nash equilibria in 3-player zero-sum games are already PPAD-complete, this class of games, i.e. with pairwise separable utility functions, defines essentially the broadest class of multi-player constant-sum games to which we can hope to push tractability results. Our result is obtained by establishing a certain game-class collapse, showing that separable constant-sum games are payoff equivalent to pairwise constant-sum polymatrix games—polymatrix games in which all edges are constant-sum games, and invoking a recent result of [Daskalakis, Papadimitriou 2009] for these games.
We also explore generalizations to classes of non-constant-sum multi-player games. A natural candidate is polymatrix games with strictly competitive games on their edges. In the two player setting, such games are minmax solvable and recent work has shown that they are merely affine transformations of zero-sum games [Adler, Daskalakis, Papadimitriou 2009]. Surprisingly we show that a polymatrix game comprising of strictly competitive games on its edges is PPAD-complete to solve, proving a striking difference in the complexity of networks of zero-sum and strictly competitive games. Finally, we look at the role of coordination in networked interactions, studying the complexity of polymatrix games with a mixture of coordination and zero-sum games. We show that finding a pure Nash equilibrium in coordination-only polymatrix games is PLS-complete; hence, computing a mixed Nash equilibrium is in PLS ∩ PPAD, but it remains open whether the problem is in P. If, on the other hand, coordination and zero-sum games are combined, we show that the problem becomes PPAD-complete, establishing that coordination and zero-sum games achieve the full generality of PPAD.},
	urldate = {2023-08-20},
	booktitle = {Proceedings of the 2011 {Annual} {ACM}-{SIAM} {Symposium} on {Discrete} {Algorithms} ({SODA})},
	publisher = {Society for Industrial and Applied Mathematics},
	author = {Cai, Yang and Daskalakis, Constantinos},
	month = jan,
	year = {2011},
	doi = {10.1137/1.9781611973082.20},
	pages = {217--234},
	file = {Full Text PDF:/Users/oliverbiggar/Zotero/storage/7QUTTS7H/Cai and Daskalakis - 2011 - On Minmax Theorems for Multiplayer Games.pdf:application/pdf},
}

@inproceedings{abernethy_faster_2018,
	title = {Faster {Rates} for {Convex}-{Concave} {Games}},
	url = {https://proceedings.mlr.press/v75/abernethy18a.html},
	abstract = {We consider the use of no-regret algorithms to compute equilibria for particular classes of convex-concave games. While standard regret bounds would lead to convergence rates on the order of ��(��−1/2)O(T−1/2)O(T{\textasciicircum}\{-1/2\}), recent work {\textbackslash}citep\{RS13,SALS15\} has established ��(1/��)O(1/T)O(1/T) rates by taking advantage of a particular class of optimistic prediction algorithms. In this work we go further, showing that for a particular class of games one achieves a ��(1/��2)O(1/T2)O(1/T{\textasciicircum}2) rate, and we show how this applies to the Frank-Wolfe method and recovers a similar bound {\textbackslash}citep\{D15\}. We also show that such no-regret techniques can even achieve a linear rate, ��(exp(−��))O(exp⁡(−T))O({\textbackslash}exp(-T)), for equilibrium computation under additional curvature assumptions.},
	language = {en},
	urldate = {2023-08-20},
	booktitle = {Proceedings of the 31st  {Conference} {On} {Learning} {Theory}},
	publisher = {PMLR},
	author = {Abernethy, Jacob and Lai, Kevin A. and Levy, Kfir Y. and Wang, Jun-Kun},
	month = jul,
	year = {2018},
	note = {ISSN: 2640-3498},
	pages = {1595--1625},
	file = {Full Text PDF:/Users/oliverbiggar/Zotero/storage/NS29XCM6/Abernethy et al. - 2018 - Faster Rates for Convex-Concave Games.pdf:application/pdf},
}

@misc{noauthor_constant_nodate,
	title = {Constant rank bimatrix games are {PPAD}-hard {\textbar} {Proceedings} of the forty-sixth annual {ACM} symposium on {Theory} of computing},
	url = {https://dl.acm.org/doi/abs/10.1145/2591796.2591835},
	urldate = {2023-08-20},
	file = {Constant rank bimatrix games are PPAD-hard | Proceedings of the forty-sixth annual ACM symposium on Theory of computing:/Users/oliverbiggar/Zotero/storage/627EW6N9/2591796.html:text/html},
}

@inproceedings{daskalakis_counter-example_2014,
	title = {A {Counter}-example to {Karlin}'s {Strong} {Conjecture} for {Fictitious} {Play}},
	doi = {10.1109/FOCS.2014.10},
	abstract = {Fictitious play is a natural dynamic for equilibrium play in zero-sum games, proposed by Brown [6], and shown to converge by Robinson [33]. Samuel Karlin conjectured in 1959 that fictitious play converges at rate O(t-1/2) with respect to the number of steps t. We disprove this conjecture by showing that, when the payoff matrix of the row player is the n × n identity matrix, fictitious play may converge (for some tie-breaking) at rate as slow as Ω(t-1/n).},
	booktitle = {2014 {IEEE} 55th {Annual} {Symposium} on {Foundations} of {Computer} {Science}},
	author = {Daskalakis, Constantinos and Pan, Qinxuan},
	month = oct,
	year = {2014},
	note = {ISSN: 0272-5428},
	keywords = {Nash equilibrium, Convergence, Games, Heuristic algorithms, Linear programming, fictitious play, Karlin's conjecture, Vectors, zero-sum games},
	pages = {11--20},
	file = {Full Text:/Users/oliverbiggar/Zotero/storage/LWFPEYLC/Daskalakis and Pan - 2014 - A Counter-example to Karlin's Strong Conjecture fo.pdf:application/pdf},
}

@article{papadimitriou_algorithms_2014,
	title = {Algorithms, complexity, and the sciences},
	volume = {111},
	url = {https://www.pnas.org/doi/abs/10.1073/pnas.1416954111},
	doi = {10.1073/pnas.1416954111},
	abstract = {Algorithms, perhaps together with Moore’s law, compose the engine of the information technology revolution, whereas complexity—the antithesis of algorithms—is one of the deepest realms of mathematical investigation. After introducing the basic concepts of algorithms and complexity, and the fundamental complexity classes P (polynomial time) and NP (nondeterministic polynomial time, or search problems), we discuss briefly the P vs. NP problem. We then focus on certain classes between P and NP which capture important phenomena in the social and life sciences, namely the Nash equlibrium and other equilibria in economics and game theory, and certain processes in population genetics and evolution. Finally, an algorithm known as multiplicative weights update (MWU) provides an algorithmic interpretation of the evolution of allele frequencies in a population under sex and weak selection. All three of these equivalences are rife with domain-specific implications: The concept of Nash equilibrium may be less universal—and therefore less compelling—than has been presumed; selection on gene interactions may entail the maintenance of genetic variation for longer periods than selection on single alleles predicts; whereas MWU can be shown to maximize, for each gene, a convex combination of the gene’s cumulative fitness in the population and the entropy of the allele distribution, an insight that may be pertinent to the maintenance of variation in evolution.},
	number = {45},
	urldate = {2023-08-20},
	journal = {Proceedings of the National Academy of Sciences},
	author = {Papadimitriou, Christos},
	month = nov,
	year = {2014},
	note = {Publisher: Proceedings of the National Academy of Sciences},
	pages = {15881--15887},
	file = {Full Text PDF:/Users/oliverbiggar/Zotero/storage/Z9CSSXXV/Papadimitriou - 2014 - Algorithms, complexity, and the sciences.pdf:application/pdf},
}

@article{daskalakis_non-concave_2022,
	title = {Non-{Concave} {Games}: {A} {Challenge} for {Game} {Theory}’s {Next} 100 {Years}},
	journal = {Cowles Preprints},
	author = {Daskalakis, Constantinos},
	year = {2022},
}

@article{allamigeon_tropical_2023,
	title = {Tropical {Complementarity} {Problems} and {Nash} {Equilibria}},
	issn = {0895-4801},
	url = {https://epubs.siam.org/doi/full/10.1137/21M1446861},
	doi = {10.1137/21M1446861},
	abstract = {The linear complementarity problem (q, A) is to find, for a given real square matrix A of order n and a real column vector q of order n, a nonnegative vector z such that A z + q {\textbackslash}geq 0\$ and zt(A z + q) =0. It is known that when A is a positive semidefinite matrix, one can use a principal pivoting method to compute a solution to (q, A) if it has one and to conclude that the problem has no solution otherwise. Cottle, Pang, and Venkateswaran [Linear Algebra Appl., 114/115 (1989), pp. 231--249] introduced the class of sufficient matrices and widened the scope of a principal pivoting algorithm to solve linear complementarity problems with row sufficient matrices. Our main result in this article is to show that this algorithm can be extended to solve even the problems with column sufficient matrices.},
	urldate = {2023-08-20},
	journal = {SIAM Journal on Discrete Mathematics},
	author = {Allamigeon, Xavier and Gaubert, Stéphane and Meunier, Frédéric},
	month = sep,
	year = {2023},
	note = {Publisher: Society for Industrial and Applied Mathematics},
	pages = {1645--1665},
	file = {Full Text PDF:/Users/oliverbiggar/Zotero/storage/BY934ZK3/Allamigeon et al. - 2023 - Tropical Complementarity Problems and Nash Equilib.pdf:application/pdf},
}

@article{brooks_canonical_2023,
	title = {A canonical game—75 years in the making—showing the equivalence of matrix games and linear programming},
	issn = {2196-1093},
	url = {https://doi.org/10.1007/s40505-023-00252-8},
	doi = {10.1007/s40505-023-00252-8},
	abstract = {According to Dantzig (Econometrica, 17, p.200, 1949), von Neumann was the first to observe that for any finite two-person zero-sum game, there is a feasible linear programming (LP) problem whose saddle points yield equilibria of the game, thus providing an immediate proof of the minimax theorem from the strong duality theorem. We provide an analogous construction going in the other direction. For any LP problem, we define a game and, with a brief and elementary proof, show that every equilibrium either yields a saddle point of the LP problem or certifies that one of the primal or dual programs is infeasible and the other is infeasible or unbounded. We thus obtain an immediate proof of the strong duality theorem from the minimax theorem. Taken together, von Neumann’s and our results provide a succinct and elementary demonstration that matrix games and linear programming are “equivalent” in a classical sense.},
	language = {en},
	urldate = {2023-08-20},
	journal = {Economic Theory Bulletin},
	author = {Brooks, Benjamin and Reny, Philip J.},
	month = jun,
	year = {2023},
	keywords = {C72, Linear programming, C61, D00, Equivalence, Matrix games},
	file = {Full Text PDF:/Users/oliverbiggar/Zotero/storage/WJ8IMGPX/Brooks and Reny - 2023 - A canonical game—75 years in the making—showing th.pdf:application/pdf},
}

@article{shapley_topics_1964,
	title = {Some topics in two-person games},
	volume = {52},
	journal = {Advances in game theory},
	author = {Shapley, Lloyd},
	year = {1964},
	pages = {1--29},
	file = {Shapley - 1964 - Some topics in two-person games.pdf:/Users/oliverbiggar/Zotero/storage/M5DUQHFV/Shapley - 1964 - Some topics in two-person games.pdf:application/pdf},
}

@article{von_stengel_computing_2002,
	title = {Computing equilibria for two-person games},
	volume = {3},
	issn = {1574-0005},
	journal = {Handbook of game theory with economic applications},
	author = {Von Stengel, Bernhard},
	year = {2002},
	note = {Publisher: Elsevier},
	pages = {1723--1759},
	file = {Von Stengel - 2002 - Computing equilibria for two-person games.pdf:/Users/oliverbiggar/Zotero/storage/QI7TGRIB/Von Stengel - 2002 - Computing equilibria for two-person games.pdf:application/pdf},
}

@inproceedings{chastain_multiplicative_2013,
	address = {New York, NY, USA},
	series = {{ITCS} '13},
	title = {Multiplicative updates in coordination games and the theory of evolution},
	isbn = {978-1-4503-1859-4},
	url = {https://doi.org/10.1145/2422436.2422444},
	doi = {10.1145/2422436.2422444},
	abstract = {In this paper we point out a new and unexpected connection between three fields: Evolution Theory, Game Theory, and Algorithms. In particular, we study the standard equations of population genetics for Evolution, in the presence of recombination (sex), focusing on the important special case of weak selection [1,2] in which all fitness values are assumed to be close to one another. Weak selection is the mathematical regime capturing the widely accepted Neutral Theory proposed by Kimura in the 1970s [3], hypothesizing that evolution proceeds for the most part not by substantial increases in fitness but by essentially random drift. We show that in this regime evolution through natural selection and sex is tantamount to a game played through the multiplicative weight updates game dynamics [4]. The players of the game are the genes (genetic loci), the strategies available to each player are the alleles of the gene, and the probabilities whereby a player plays a strategy is the strategy's frequency in the population. The utility to each player/gene of each strategy profile is the fitness of the corresponding genotype (organism). That is, the game is a coordination game between genes, in which the players' interests are perfectly aligned. Importantly, the utility maximized in this game, as well as the amount by which each allele is boosted, is precisely the allele's mixability, or average fitness, a quantity recently proposed in [5] as a novel concept that is crucial in understanding natural selection under sex, thus providing a rigorous demonstration of that insight. We also establish a result regarding the maintenance of genetic diversity (multiplicity of alleles per gene). We prove that the equilibria in two-person coordination games are likely to have large supports, and thus genetic diversity need not suffer much at equilibrium. Establishing large supports involves answering through a novel technique the following question: what is the probability that for a random square matrix \$A\$ (with entries drawn independently from smooth distributions that are symmetric around zero) both systems Ax=1 and ATy=1 have positive solutions? The proof is through a simple potential function argument. Both the question and the technique may be of broader interest. It has often seemed astonishing --- even to experienced students of Evolution, Darwin included --- that the crude mechanism of natural selection is responsible for producing the dazzling variety of Life around us. The present mathematical connection of Evolution with the multiplicative weight updates algorithm --- a technique that has surprised our field time and again with its fantastic effectiveness and versatility --- may carry some explanatory force in this regard.},
	urldate = {2023-08-30},
	booktitle = {Proceedings of the 4th conference on {Innovations} in {Theoretical} {Computer} {Science}},
	publisher = {Association for Computing Machinery},
	author = {Chastain, Erick and Livnat, Adi and Papadimitriou, Christos and Vazirani, Umesh},
	month = jan,
	year = {2013},
	keywords = {algorithmic game theory, multiplicative weight updates, theory of evolution},
	pages = {57--58},
	file = {Submitted Version:/Users/oliverbiggar/Zotero/storage/9HGKERXB/Chastain et al. - 2013 - Multiplicative updates in coordination games and t.pdf:application/pdf},
}

@article{plotkin_fast_1995,
	title = {Fast approximation algorithms for fractional packing and covering problems},
	volume = {20},
	issn = {0364-765X},
	number = {2},
	journal = {Mathematics of Operations Research},
	author = {Plotkin, Serge A and Shmoys, David B and Tardos, \'Eva},
	year = {1995},
	note = {Publisher: INFORMS},
	pages = {257--301},
}

@article{plotkin_fast_1995-1,
	title = {Fast {Approximation} {Algorithms} for {Fractional} {Packing} and {Covering} {Problems}},
	volume = {20},
	issn = {0364-765X},
	url = {https://pubsonline.informs.org/doi/abs/10.1287/moor.20.2.257},
	doi = {10.1287/moor.20.2.257},
	abstract = {This paper presents fast algorithms that find approximate solutions for a general class of problems, which we call fractional packing and covering problems. The only previously known algorithms for solving these problems are based on general linear programming techniques. The techniques developed in this paper greatly outperform the general methods in many applications, and are extensions of a method previously applied to find approximate solutions to multicommodity flow problems. Our algorithm is a Lagrangian relaxation technique; an important aspect of our results is that we obtain a theoretical analysis of the running time of a Lagrangian relaxation-based algorithm.

We give several applications of our algorithms. The new approach yields several orders of magnitude of improvement over the best previously known running times for algorithms for the scheduling of unrelated parallel machines in both the preemptive and the nonpreemptive models, for the job shop problem, for the Held and Karp bound for the traveling salesman problem, for the cutting-stock problem, for the network embedding problem, and for the minimum-cost multicommodity flow problem.},
	number = {2},
	urldate = {2023-08-31},
	journal = {Mathematics of Operations Research},
	author = {Plotkin, Serge A. and Shmoys, David B. and Tardos, \'Eva},
	month = may,
	year = {1995},
	note = {Publisher: INFORMS},
	keywords = {approximation algorithm, Lagrangian relaxation, packing and covering},
	pages = {257--301},
	file = {Submitted Version:/Users/oliverbiggar/Zotero/storage/X8A4GERW/Plotkin et al. - 1995 - Fast Approximation Algorithms for Fractional Packi.pdf:application/pdf},
}

@article{goldberg_complexity_2013,
	title = {The complexity of the homotopy method, equilibrium selection, and {Lemke}-{Howson} solutions},
	volume = {1},
	issn = {2167-8375},
	number = {2},
	journal = {ACM Transactions on Economics and Computation (TEAC)},
	author = {Goldberg, Paul W and Papadimitriou, Christos H and Savani, Rahul},
	year = {2013},
	note = {Publisher: ACM New York, NY, USA},
	pages = {1--25},
}

@article{goldberg_complexity_2013-1,
	title = {The {Complexity} of the {Homotopy} {Method}, {Equilibrium} {Selection}, and {Lemke}-{Howson} {Solutions}},
	volume = {1},
	issn = {2167-8375},
	url = {https://doi.org/10.1145/2465769.2465774},
	doi = {10.1145/2465769.2465774},
	abstract = {We show that the widely used homotopy method for solving fixpoint problems, as well as the Harsanyi-Selten equilibrium selection process for games, are PSPACE-complete to implement. Extending our result for the Harsanyi-Selten process, we show that several other homotopy-based algorithms for finding equilibria of games are also PSPACE-complete to implement. A further application of our techniques yields the result that it is PSPACE-complete to compute any of the equilibria that could be found via the classical Lemke-Howson algorithm, a complexity-theoretic strengthening of the result in Savani and von Stengel [2006]. These results show that our techniques can be widely applied and suggest that the PSPACE-completeness of implementing homotopy methods is a general principle.},
	number = {2},
	urldate = {2023-09-08},
	journal = {ACM Transactions on Economics and Computation},
	author = {Goldberg, Paul W. and Papadimitriou, Christos H. and Savani, Rahul},
	month = may,
	year = {2013},
	keywords = {game theory, equilibria, Fixpoint problems, homotopy methods, Lemke-Howson algorithm},
	pages = {9:1--9:25},
	file = {Full Text:/Users/oliverbiggar/Zotero/storage/TKPB55NM/Goldberg et al. - 2013 - The Complexity of the Homotopy Method, Equilibrium.pdf:application/pdf},
}

@article{demichelis_evolutionary_2003,
	title = {From evolutionary to strategic stability},
	volume = {113},
	issn = {0022-0531},
	number = {1},
	journal = {Journal of Economic Theory},
	author = {Demichelis, Stefano and Ritzberger, Klaus},
	year = {2003},
	note = {Publisher: New York: Academic Press.},
	pages = {51--75},
	file = {Demichelis and Ritzberger - 2003 - From evolutionary to strategic stability.pdf:/Users/oliverbiggar/Zotero/storage/S6L45KRA/Demichelis and Ritzberger - 2003 - From evolutionary to strategic stability.pdf:application/pdf},
}

@article{demichelis_knots_2002,
	title = {On (un)knots and dynamics in games},
	volume = {41},
	issn = {0899-8256},
	url = {https://www.sciencedirect.com/science/article/pii/S089982560200009X},
	doi = {10.1016/S0899-8256(02)00009-X},
	abstract = {We extend Kohlberg and Mertens' (1986. On the strategic stability of equilibria. Econometrica 54, 1003–1037) structure theorem on the Nash correspondence to show that its graph is not only homeomorphic to the underlying space of games, but that the homeomorphism extends to the ambient space of games times strategies, thus implying the graph is unknotted. This has several consequences for dynamics whose rest points are Nash equilibria. In particular, a homotopy property is established that allows to determine whether Nash equilibria or components of Nash equilibria—based directly on their local geometry on the graph—may be stable under a wide class of dynamics.},
	number = {1},
	urldate = {2023-09-20},
	journal = {Games and Economic Behavior},
	author = {Demichelis, Stefano and Germano, Fabrizio},
	month = oct,
	year = {2002},
	keywords = {Degree, Dynamics, Geometry of Nash equilibria, Index, Knots, Learning mixed equilibria, Stability},
	pages = {46--60},
	file = {Demichelis and Germano - 2002 - On (un)knots and dynamics in games.pdf:/Users/oliverbiggar/Zotero/storage/V83CZR6S/Demichelis and Germano - 2002 - On (un)knots and dynamics in games.pdf:application/pdf;ScienceDirect Snapshot:/Users/oliverbiggar/Zotero/storage/KHQ5674B/S089982560200009X.html:text/html},
}

@article{demichelis_indices_2000,
	title = {On the {Indices} of {Zeros} of {Nash} {Fields}},
	volume = {94},
	issn = {0022-0531},
	url = {https://www.sciencedirect.com/science/article/pii/S0022053100926693},
	doi = {10.1006/jeth.2000.2669},
	abstract = {We show a fundamental property of dynamics whose zeros are essentially the Nash equilibria of underlying games; namely, the indices of zeros coincide with the degrees of the projection from the graph of the Nash correspondence onto the underlying space of games. This is important since it implies that for a wide class of dynamics local stability properties of zeros are determined by the geometry of the Nash correspondence, providing further links between learning or evolutionary game theory, the theory of equilibrium refinements, and the geometry of Nash equilibrium. The result extends beyond general n-player games e.g. to Walrasian equilibrium theory. Journal of Economic Literature Classification Numbers: C62, C72, D50.},
	number = {2},
	urldate = {2023-09-20},
	journal = {Journal of Economic Theory},
	author = {DeMichelis, Stefano and Germano, Fabrizio},
	month = oct,
	year = {2000},
	keywords = {degree, dynamics, geometry of equilibrium correspondences, index, stability},
	pages = {192--217},
	file = {ScienceDirect Snapshot:/Users/oliverbiggar/Zotero/storage/KJ4VHS97/S0022053100926693.html:text/html},
}

@article{samuelson_evolutionary_1992,
	title = {Evolutionary stability in asymmetric games},
	volume = {57},
	issn = {0022-0531},
	url = {https://www.sciencedirect.com/science/article/pii/002205319290041F},
	doi = {10.1016/0022-0531(92)90041-F},
	abstract = {We examine dynamic models of evolutionary selection processes on asymmetric two-player games. Conditions are established under which dynamic selection processes will yield outcomes that respect iterated strict dominance. The addition of a stability requirement ensures that outcomes will be Nash equilibria. However, we find that stable outcomes need not respect weak dominance, and hence need not yield perfect equilibria. We conclude that evolutionary arguments readily motivate such equilibrium oncepts as rationalizability and Nash equilibrium, but appear to provide little basis for even such simple refinements of Nash equilibrium as the recommendation that dominated strategies not be played.},
	number = {2},
	urldate = {2023-09-20},
	journal = {Journal of Economic Theory},
	author = {Samuelson, Larry and Zhang, Jianbo},
	month = aug,
	year = {1992},
	pages = {363--391},
	file = {ScienceDirect Snapshot:/Users/oliverbiggar/Zotero/storage/RZ7IPB36/002205319290041F.html:text/html},
}

@article{morse_singular_1929,
	title = {Singular {Points} of {Vector} {Fields} {Under} {General} {Boundary} {Conditions}},
	volume = {51},
	issn = {0002-9327},
	url = {https://www.jstor.org/stable/2370703},
	doi = {10.2307/2370703},
	number = {2},
	urldate = {2023-09-24},
	journal = {American Journal of Mathematics},
	author = {Morse, Marston},
	year = {1929},
	note = {Publisher: Johns Hopkins University Press},
	pages = {165--178},
	file = {JSTOR Full Text PDF:/Users/oliverbiggar/Zotero/storage/QUWRR6P2/Morse - 1929 - Singular Points of Vector Fields Under General Bou.pdf:application/pdf},
}

@inproceedings{chastain_multiplicative_2013-1,
	address = {New York, NY, USA},
	series = {{ITCS} '13},
	title = {Multiplicative updates in coordination games and the theory of evolution},
	isbn = {978-1-4503-1859-4},
	url = {https://doi.org/10.1145/2422436.2422444},
	doi = {10.1145/2422436.2422444},
	abstract = {In this paper we point out a new and unexpected connection between three fields: Evolution Theory, Game Theory, and Algorithms. In particular, we study the standard equations of population genetics for Evolution, in the presence of recombination (sex), focusing on the important special case of weak selection [1,2] in which all fitness values are assumed to be close to one another. Weak selection is the mathematical regime capturing the widely accepted Neutral Theory proposed by Kimura in the 1970s [3], hypothesizing that evolution proceeds for the most part not by substantial increases in fitness but by essentially random drift. We show that in this regime evolution through natural selection and sex is tantamount to a game played through the multiplicative weight updates game dynamics [4]. The players of the game are the genes (genetic loci), the strategies available to each player are the alleles of the gene, and the probabilities whereby a player plays a strategy is the strategy's frequency in the population. The utility to each player/gene of each strategy profile is the fitness of the corresponding genotype (organism). That is, the game is a coordination game between genes, in which the players' interests are perfectly aligned. Importantly, the utility maximized in this game, as well as the amount by which each allele is boosted, is precisely the allele's mixability, or average fitness, a quantity recently proposed in [5] as a novel concept that is crucial in understanding natural selection under sex, thus providing a rigorous demonstration of that insight. We also establish a result regarding the maintenance of genetic diversity (multiplicity of alleles per gene). We prove that the equilibria in two-person coordination games are likely to have large supports, and thus genetic diversity need not suffer much at equilibrium. Establishing large supports involves answering through a novel technique the following question: what is the probability that for a random square matrix \$A\$ (with entries drawn independently from smooth distributions that are symmetric around zero) both systems Ax=1 and ATy=1 have positive solutions? The proof is through a simple potential function argument. Both the question and the technique may be of broader interest. It has often seemed astonishing --- even to experienced students of Evolution, Darwin included --- that the crude mechanism of natural selection is responsible for producing the dazzling variety of Life around us. The present mathematical connection of Evolution with the multiplicative weight updates algorithm --- a technique that has surprised our field time and again with its fantastic effectiveness and versatility --- may carry some explanatory force in this regard.},
	urldate = {2023-09-24},
	booktitle = {Proceedings of the 4th conference on {Innovations} in {Theoretical} {Computer} {Science}},
	publisher = {Association for Computing Machinery},
	author = {Chastain, Erick and Livnat, Adi and Papadimitriou, Christos and Vazirani, Umesh},
	month = jan,
	year = {2013},
	keywords = {algorithmic game theory, multiplicative weight updates, theory of evolution},
	pages = {57--58},
	file = {Submitted Version:/Users/oliverbiggar/Zotero/storage/PX5PII2N/Chastain et al. - 2013 - Multiplicative updates in coordination games and t.pdf:application/pdf},
}

@inproceedings{mehta_natural_2015,
	address = {New York, NY, USA},
	series = {{ITCS} '15},
	title = {Natural {Selection} as an {Inhibitor} of {Genetic} {Diversity}: {Multiplicative} {Weights} {Updates} {Algorithm} and a {Conjecture} of {Haploid} {Genetics} [{Working} {Paper} {Abstract}]},
	isbn = {978-1-4503-3333-7},
	shorttitle = {Natural {Selection} as an {Inhibitor} of {Genetic} {Diversity}},
	url = {https://doi.org/10.1145/2688073.2688118},
	doi = {10.1145/2688073.2688118},
	abstract = {In a recent series of papers a surprisingly strong connection was discovered between standard evolutionary models of natural selection and Multiplicative Weights Updates Algorithm, a ubiquitous model of online learning and optimization. These papers establish that, under specific assumptions, mathematical models of biological evolution can be reduced to studying discrete replicator dynamics, a close variant of MWUA, in coordination games. This connection allows for introducing insights from game theoretic dynamics into the field of mathematical biology. Using these results as a stepping stone, we show that mathematical models of haploid evolution imply the extinction of genetic diversity in the long term limit, a widely believed conjecture in genetics. In game theoretic terms we show that in the case of coordination games, under minimal genericity assumptions, discrete replicator dynamics converge to pure Nash equilibria for all but a zero measure of initial conditions. This result holds despite the fact that mixed Nash equilibria can be exponentially (or even uncountably) many, completely dominating in number the set of pure Nash equilibria. Thus, in haploid organisms the long term preservation of genetic diversity needs to be safeguarded by other evolutionary mechanisms such as mutations and speciation.},
	urldate = {2023-09-24},
	booktitle = {Proceedings of the 2015 {Conference} on {Innovations} in {Theoretical} {Computer} {Science}},
	publisher = {Association for Computing Machinery},
	author = {Mehta, Ruta and Panageas, Ioannis and Piliouras, Georgios},
	month = jan,
	year = {2015},
	keywords = {replicator dynamics, algorithmic game theory, multiplicative weight updates, evolution, stability of equilibria},
	pages = {73},
	file = {Accepted Version:/Users/oliverbiggar/Zotero/storage/RZMPKVSI/Mehta et al. - 2015 - Natural Selection as an Inhibitor of Genetic Diver.pdf:application/pdf},
}

@article{peixe_persistent_2022,
	title = {Persistent strange attractors in {3D} polymatrix replicators},
	volume = {438},
	issn = {0167-2789},
	url = {https://www.sciencedirect.com/science/article/pii/S0167278922001130},
	doi = {10.1016/j.physd.2022.133346},
	abstract = {We introduce a one-parameter family of polymatrix replicators defined in a three-dimensional cube and study its bifurcations. For a given interval of parameters, each element of the family can be C2-approximated by a vector field whose flow exhibits suspended horseshoes and persistent strange attractors. The proof relies on the numerically observed Shilnikov homoclinic cycle to the interior equilibrium. We also describe the phenomenological steps responsible for the transition from regular to chaotic dynamics in the family (route to chaos).},
	urldate = {2023-09-24},
	journal = {Physica D: Nonlinear Phenomena},
	author = {Peixe, Telmo and Rodrigues, Alexandre},
	month = oct,
	year = {2022},
	keywords = {Bifurcations, Observable chaos, Polymatrix replicator, Shilnikov homoclinic cycle, Strange attractors},
	pages = {133346},
	file = {ScienceDirect Full Text PDF:/Users/oliverbiggar/Zotero/storage/WNA5WYQ2/Peixe and Rodrigues - 2022 - Persistent strange attractors in 3D polymatrix rep.pdf:application/pdf;ScienceDirect Snapshot:/Users/oliverbiggar/Zotero/storage/496IZZJM/S0167278922001130.html:text/html},
}

@article{sato_chaos_2002,
	title = {Chaos in learning a simple two-person game},
	volume = {99},
	issn = {0027-8424, 1091-6490},
	url = {https://pnas.org/doi/full/10.1073/pnas.032086299},
	doi = {10.1073/pnas.032086299},
	abstract = {We investigate the problem of learning to play the game of rock–paper–scissors. Each player attempts to improve her/his average score by adjusting the frequency of the three possible responses, using reinforcement learning. For the zero sum game the learning process displays Hamiltonian chaos. Thus, the learning trajectory can be simple or complex, depending on initial conditions. We also investigate the non-zero sum case and show that it can give rise to chaotic transients. This is, to our knowledge, the first demonstration of Hamiltonian chaos in learning a basic two-person game, extending earlier findings of chaotic attractors in dissipative systems. As we argue here, chaos provides an important self-consistency condition for determining when players will learn to behave as though they were fully rational. That chaos can occur in learning a simple game indicates one should use caution in assuming real people will learn to play a game according to a Nash equilibrium strategy.},
	language = {en},
	number = {7},
	urldate = {2023-09-26},
	journal = {Proceedings of the National Academy of Sciences},
	author = {Sato, Yuzuru and Akiyama, Eizo and Farmer, J. Doyne},
	month = apr,
	year = {2002},
	pages = {4748--4751},
	file = {Available Version (via Google Scholar):/Users/oliverbiggar/Zotero/storage/CUPMFC6M/pnas.html:text/html;Full Text:/Users/oliverbiggar/Zotero/storage/YI4E9R7U/Sato et al. - 2002 - Chaos in learning a simple two-person game.pdf:application/pdf},
}

@article{farmer_economy_2009,
	title = {The economy needs agent-based modelling},
	volume = {460},
	copyright = {2009 Springer Nature Limited},
	issn = {1476-4687},
	url = {https://www.nature.com/articles/460685a},
	doi = {10.1038/460685a},
	abstract = {The leaders of the world are flying the economy by the seat of their pants, say J. Doyne Farmer and Duncan Foley. There is, however, a better way to help guide financial policies.},
	language = {en},
	number = {7256},
	urldate = {2023-10-10},
	journal = {Nature},
	author = {Farmer, J. Doyne and Foley, Duncan},
	month = aug,
	year = {2009},
	note = {Number: 7256
Publisher: Nature Publishing Group},
	keywords = {Humanities and Social Sciences, multidisciplinary, Science},
	pages = {685--686},
	file = {Full Text PDF:/Users/oliverbiggar/Zotero/storage/A9EMP5LQ/Farmer and Foley - 2009 - The economy needs agent-based modelling.pdf:application/pdf},
}

@article{pangallo_best_2019,
	title = {Best reply structure and equilibrium convergence in generic games},
	volume = {5},
	url = {https://www.science.org/doi/full/10.1126/sciadv.aat1328},
	doi = {10.1126/sciadv.aat1328},
	abstract = {Game theory is widely used to model interacting biological and social systems. In some situations, players may converge to an equilibrium, e.g., a Nash equilibrium, but in other situations their strategic dynamics oscillate endogenously. If the system is not designed to encourage convergence, which of these two behaviors can we expect a priori? To address this question, we follow an approach that is popular in theoretical ecology to study the stability of ecosystems: We generate payoff matrices at random, subject to constraints that may represent properties of real-world games. We show that best reply cycles, basic topological structures in games, predict nonconvergence of six well-known learning algorithms that are used in biology or have support from experiments with human players. Best reply cycles are dominant in complicated and competitive games, indicating that in this case equilibrium is typically an unrealistic assumption, and one must explicitly model the dynamics of learning.},
	number = {2},
	urldate = {2023-10-10},
	journal = {Science Advances},
	author = {Pangallo, Marco and Heinrich, Torsten and Doyne Farmer, J.},
	month = feb,
	year = {2019},
	note = {Publisher: American Association for the Advancement of Science},
	pages = {eaat1328},
	file = {Full Text PDF:/Users/oliverbiggar/Zotero/storage/FVI4XW99/Pangallo et al. - 2019 - Best reply structure and equilibrium convergence i.pdf:application/pdf},
}

@article{galla_complex_2013,
	title = {Complex dynamics in learning complicated games},
	volume = {110},
	url = {https://www.pnas.org/doi/abs/10.1073/pnas.1109672110},
	doi = {10.1073/pnas.1109672110},
	abstract = {Game theory is the standard tool used to model strategic interactions in evolutionary biology and social science. Traditionally, game theory studies the equilibria of simple games. However, is this useful if the game is complicated, and if not, what is? We define a complicated game as one with many possible moves, and therefore many possible payoffs conditional on those moves. We investigate two-person games in which the players learn based on a type of reinforcement learning called experience-weighted attraction (EWA). By generating games at random, we characterize the learning dynamics under EWA and show that there are three clearly separated regimes: (i) convergence to a unique fixed point, (ii) a huge multiplicity of stable fixed points, and (iii) chaotic behavior. In case (iii), the dimension of the chaotic attractors can be very high, implying that the learning dynamics are effectively random. In the chaotic regime, the total payoffs fluctuate intermittently, showing bursts of rapid change punctuated by periods of quiescence, with heavy tails similar to what is observed in fluid turbulence and financial markets. Our results suggest that, at least for some learning algorithms, there is a large parameter regime for which complicated strategic interactions generate inherently unpredictable behavior that is best described in the language of dynamical systems theory.},
	number = {4},
	urldate = {2023-10-11},
	journal = {Proceedings of the National Academy of Sciences},
	author = {Galla, Tobias and Farmer, J. Doyne},
	month = jan,
	year = {2013},
	note = {Publisher: Proceedings of the National Academy of Sciences},
	pages = {1232--1236},
	file = {Full Text PDF:/Users/oliverbiggar/Zotero/storage/KEJFR6WH/Galla and Farmer - 2013 - Complex dynamics in learning complicated games.pdf:application/pdf},
}

@misc{panageas_exponential_2023,
	title = {Exponential {Lower} {Bounds} for {Fictitious} {Play} in {Potential} {Games}},
	url = {http://arxiv.org/abs/2310.02387},
	doi = {10.48550/arXiv.2310.02387},
	abstract = {Fictitious Play (FP) is a simple and natural dynamic for repeated play with many applications in game theory and multi-agent reinforcement learning. It was introduced by Brown (1949,1951) and its convergence properties for two-player zero-sum games was established later by Robinson (1951). Potential games Monderer and Shapley (1996b) is another class of games which exhibit the FP property (Monderer and Shapley (1996a)), i.e., FP dynamics converges to a Nash equilibrium if all agents follows it. Nevertheless, except for two-player zero-sum games and for specific instances of payoff matrices (Abernethy et al. (2021)) or for adversarial tie-breaking rules (Daskalakis and Pan (2014)), the convergence rate of FP is unknown. In this work, we focus on the rate of convergence of FP when applied to potential games and more specifically identical payoff games. We prove that FP can take exponential time (in the number of strategies) to reach a Nash equilibrium, even if the game is restricted to two agents and for arbitrary tie-breaking rules. To prove this, we recursively construct a two-player coordination game with a unique Nash equilibrium. Moreover, every approximate Nash equilibrium in the constructed game must be close to the pure Nash equilibrium in \${\textbackslash}ell\_1\$-distance.},
	urldate = {2023-10-11},
	publisher = {arXiv},
	author = {Panageas, Ioannis and Patris, Nikolas and Skoulakis, Stratis and Cevher, Volkan},
	month = oct,
	year = {2023},
	note = {arXiv:2310.02387 [cs]},
	keywords = {Computer Science - Computer Science and Game Theory},
	file = {arXiv Fulltext PDF:/Users/oliverbiggar/Zotero/storage/ETTGC53N/Panageas et al. - 2023 - Exponential Lower Bounds for Fictitious Play in Po.pdf:application/pdf;arXiv.org Snapshot:/Users/oliverbiggar/Zotero/storage/6HFXP4W5/2310.html:text/html},
}

@misc{johnston_game_2023,
	title = {Game {Connectivity} and {Adaptive} {Dynamics}},
	url = {http://arxiv.org/abs/2309.10609},
	doi = {10.48550/arXiv.2309.10609},
	abstract = {We analyse the typical structure of games in terms of the connectivity properties of their best-response graphs. In particular, we show that almost every 'large' generic game that has a pure Nash equilibrium is connected, meaning that every non-equilibrium action profile can reach every pure Nash equilibrium via best-response paths. This has implications for dynamics in games: many adaptive dynamics, such as the best-response dynamic with inertia, lead to equilibrium in connected games. It follows that there are simple, uncoupled, adaptive dynamics for which period-by-period play converges almost surely to a pure Nash equilibrium in almost every 'large' generic game that has one. We build on recent results in probabilistic combinatorics for our characterisation of game connectivity.},
	urldate = {2023-10-11},
	publisher = {arXiv},
	author = {Johnston, Tom and Savery, Michael and Scott, Alex and Tarbush, Bassel},
	month = oct,
	year = {2023},
	note = {arXiv:2309.10609 [cs, econ, math]},
	keywords = {Computer Science - Computer Science and Game Theory, Economics - Theoretical Economics, Mathematics - Combinatorics},
	file = {arXiv Fulltext PDF:/Users/oliverbiggar/Zotero/storage/2QW29MT9/Johnston et al. - 2023 - Game Connectivity and Adaptive Dynamics.pdf:application/pdf;arXiv.org Snapshot:/Users/oliverbiggar/Zotero/storage/T9XU7S8L/2309.html:text/html},
}

@inproceedings{mirrokni_convergence_2004,
	address = {Berlin, Heidelberg},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Convergence {Issues} in {Competitive} {Games}},
	isbn = {978-3-540-27821-4},
	doi = {10.1007/978-3-540-27821-4\_17},
	abstract = {We study the speed of convergence to approximate solutions in iterative competitive games. We also investigate the value of Nash equilibria as a measure of the cost of the lack of coordination in such games. Our basic model uses the underlying best response graph induced by the selfish behavior of the players. In this model, we study the value of the social function after multiple rounds of best response behavior by the players. This work therefore deviates from other attempts to study the outcome of selfish behavior of players in non-cooperative games in that we dispense with the insistence upon only evaluating Nash equilibria. A detailed theoretical and practical justification for this approach is presented. We consider non-cooperative games with a submodular social utility function; in particular, we focus upon the class of valid-utility games introduced in [13]. Special cases include basic-utility games and market sharing games which we examine in depth. On the positive side we show that for basic-utility games we obtain extremely quick convergence. After just one round of iterative selfish behavior we are guaranteed to obtain a solution with social value at least \${\textbackslash}frac13\$that of optimal. For n-player valid-utility games, in general, after one round we obtain a \${\textbackslash}frac\{1\}\{2n\}\$-approximate solution. For market sharing games we prove that one round of selfish response behavior of players gives \${\textbackslash}Omega(\{1{\textbackslash}over {\textbackslash}ln n\})\$-approximate solutions and this bound is almost tight. On the negative side we present an example to show that even in games in which every Nash equilibrium has high social value (at least half of optimal), iterative selfish behavior may “converge” to a set of extremely poor solutions (each being at least a factor n from optimal). In such games Nash equilibria may severely underestimate the cost of the lack of coordination in a game, and we discuss the implications of this.},
	language = {en},
	booktitle = {Approximation, {Randomization}, and {Combinatorial} {Optimization}. {Algorithms} and {Techniques}},
	publisher = {Springer},
	author = {Mirrokni, Vahab S. and Vetta, Adrian},
	editor = {Jansen, Klaus and Khanna, Sanjeev and Rolim, José D. P. and Ron, Dana},
	year = {2004},
	keywords = {Congestion Game, Potential Game, Nash Equilibrium, Pure Nash Equilibrium, Query Rate},
	pages = {183--194},
	file = {Full Text PDF:/Users/oliverbiggar/Zotero/storage/4TMV96L3/Mirrokni and Vetta - 2004 - Convergence Issues in Competitive Games.pdf:application/pdf},
}

@article{mckelvey_quantal_1995,
	title = {Quantal {Response} {Equilibria} for {Normal} {Form} {Games}},
	volume = {10},
	issn = {0899-8256},
	url = {https://www.sciencedirect.com/science/article/pii/S0899825685710238},
	doi = {10.1006/game.1995.1023},
	abstract = {We investigate the use of standard statistical models for quantal choice in a game theoretic setting. Players choose strategies based on relative expected utility and assume other players do so as well. We define a quantal response equilibrium (ORE) as a fixed point of this process and establish existence. For a logit specification of the error structure, we show that as the error goes to zero, QRE approaches a subset of Nash equilibria and also implies a unique selection from the set of Nash equilibria in generic games. We fit the model to a variety of experimental data sets by using maximum likelihood estimation. Journal of Economic Literature Classification Numbers: C19, C44, C72, C92.},
	number = {1},
	urldate = {2023-10-12},
	journal = {Games and Economic Behavior},
	author = {McKelvey, Richard D. and Palfrey, Thomas R.},
	month = jul,
	year = {1995},
	pages = {6--38},
	file = {ScienceDirect Full Text PDF:/Users/oliverbiggar/Zotero/storage/LKVPS6CK/McKelvey and Palfrey - 1995 - Quantal Response Equilibria for Normal Form Games.pdf:application/pdf;ScienceDirect Snapshot:/Users/oliverbiggar/Zotero/storage/USLR4VU3/S0899825685710238.html:text/html},
}

@misc{kearns_graphical_2013,
	title = {Graphical {Models} for {Game} {Theory}},
	url = {https://arxiv.org/abs/1301.2281v2},
	abstract = {In this work, we introduce graphical modelsfor multi-player game theory, and give powerful algorithms for computing their Nash equilibria in certain cases. An n-player game is given by an undirected graph on n nodes and a set of n local matrices. The interpretation is that the payoff to player i is determined entirely by the actions of player i and his neighbors in the graph, and thus the payoff matrix to player i is indexed only by these players. We thus view the global n-player game as being composed of interacting local games, each involving many fewer players. Each player's action may have global impact, but it occurs through the propagation of local influences.Our main technical result is an efficient algorithm for computing Nash equilibria when the underlying graph is a tree (or can be turned into a tree with few node mergings). The algorithm runs in time polynomial in the size of the representation (the graph and theassociated local game matrices), and comes in two related but distinct flavors. The first version involves an approximation step, and computes a representation of all approximate Nash equilibria (of which there may be an exponential number in general). The second version allows the exact computation of Nash equilibria at the expense of weakened complexity bounds. The algorithm requires only local message-passing between nodes (and thus can be implemented by the players themselves in a distributed manner). Despite an analogy to inference in Bayes nets that we develop, the analysis of our algorithm is more involved than that for the polytree algorithm in, owing partially to the fact that we must either compute, or select from, an exponential number of potential solutions. We discuss a number of extensions, such as the computation of equilibria with desirable global properties (e.g. maximizing global return), and directions for further research.},
	language = {en},
	urldate = {2023-10-12},
	journal = {arXiv.org},
	author = {Kearns, Michael and Littman, Michael L. and Singh, Satinder},
	month = jan,
	year = {2013},
	file = {Full Text PDF:/Users/oliverbiggar/Zotero/storage/XZZRE6IE/Kearns et al. - 2013 - Graphical Models for Game Theory.pdf:application/pdf},
}

@article{apt_classification_2015,
	title = {A classification of weakly acyclic games},
	volume = {78},
	issn = {1573-7187},
	url = {https://doi.org/10.1007/s11238-014-9436-1},
	doi = {10.1007/s11238-014-9436-1},
	abstract = {Weakly acyclic games form a natural generalization of the class of games that have the finite improvement property (FIP). In such games one stipulates that from any initial joint strategy some finite improvement path exists. We classify weakly acyclic games using the concept of a scheduler introduced in Simon and Apt (Choosing products in social networks, 2012). We also show that finite games that can be solved by the iterated elimination of never best response strategies are weakly acyclic. Finally, we explain how the schedulers allow us to improve the bounds on finding a Nash equilibrium in a weakly acyclic game.},
	language = {en},
	number = {4},
	urldate = {2023-10-12},
	journal = {Theory and Decision},
	author = {Apt, Krzysztof R. and Simon, Sunil},
	month = apr,
	year = {2015},
	keywords = {Classification, Game theory, Scheduler, Weakly acyclic games},
	pages = {501--524},
	file = {Full Text PDF:/Users/oliverbiggar/Zotero/storage/YXNGRSAH/Apt and Simon - 2015 - A classification of weakly acyclic games.pdf:application/pdf},
}

@inproceedings{christodoulou_convergence_2006,
	address = {Berlin, Heidelberg},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Convergence and {Approximation} in {Potential} {Games}},
	isbn = {978-3-540-32288-7},
	doi = {10.1007/11672142\_28},
	abstract = {We study the speed of convergence to approximately optimal states in two classes of potential games. We provide bounds in terms of the number of rounds, where a round consists of a sequence of movements, with each player appearing at least once in each round. We model the sequential interaction between players by a best-response walk in the state graph, where every transition in the walk corresponds to a best response of a player. Our goal is to bound the social value of the states at the end of such walks. In this paper, we focus on two classes of potential games: selfish routing games, and cut games (or party affiliation games [7]).},
	language = {en},
	booktitle = {{STACS} 2006},
	publisher = {Springer},
	author = {Christodoulou, George and Mirrokni, Vahab S. and Sidiropoulos, Anastasios},
	editor = {Durand, Bruno and Thomas, Wolfgang},
	year = {2006},
	keywords = {Congestion Game, Nash Equilibrium, Approximation Ratio, Pure Strategy, State Graph},
	pages = {349--360},
	file = {Full Text PDF:/Users/oliverbiggar/Zotero/storage/CTNNEZ2A/Christodoulou et al. - 2006 - Convergence and Approximation in Potential Games.pdf:application/pdf},
}

@article{wiese_frequency_2022,
	title = {The {Frequency} of {Convergent} {Games} under {Best}-{Response} {Dynamics}},
	volume = {12},
	issn = {2153-0793},
	url = {https://doi.org/10.1007/s13235-021-00401-3},
	doi = {10.1007/s13235-021-00401-3},
	abstract = {We calculate the frequency of games with a unique pure strategy Nash equilibrium in the ensemble of n-player, m-strategy normal-form games. To obtain the ensemble, we generate payoff matrices at random. Games with a unique pure strategy Nash equilibrium converge to the Nash equilibrium. We then consider a wider class of games that converge under a best-response dynamic, in which each player chooses their optimal pure strategy successively. We show that the frequency of convergent games with a given number of pure Nash equilibria goes to zero as the number of players or the number of strategies goes to infinity. In the 2-player case, we show that for large games with at least 10 strategies, convergent games with multiple pure strategy Nash equilibria are more likely than games with a unique Nash equilibrium. Our novel approach uses an n-partite graph to describe games.},
	language = {en},
	number = {2},
	urldate = {2023-10-12},
	journal = {Dynamic Games and Applications},
	author = {Wiese, Samuel C. and Heinrich, Torsten},
	month = jun,
	year = {2022},
	keywords = {91A06, 91A10, Best-response dynamics, Pure Nash equilibrium, Random games},
	pages = {689--700},
	file = {Full Text PDF:/Users/oliverbiggar/Zotero/storage/LKUJ4D4R/Wiese and Heinrich - 2022 - The Frequency of Convergent Games under Best-Respo.pdf:application/pdf},
}

@article{monderer_potential_1996,
	title = {Potential {Games}},
	volume = {14},
	issn = {0899-8256},
	url = {https://www.sciencedirect.com/science/article/pii/S0899825696900445},
	doi = {10.1006/game.1996.0044},
	abstract = {We define and discuss several notions of potential functions for games in strategic form. We characterize games that have a potential function, and we present a variety of applications.Journal of Economic LiteratureClassification Numbers:C72, C73.},
	number = {1},
	urldate = {2023-10-12},
	journal = {Games and Economic Behavior},
	author = {Monderer, Dov and Shapley, Lloyd S.},
	month = may,
	year = {1996},
	pages = {124--143},
	file = {ScienceDirect Full Text PDF:/Users/oliverbiggar/Zotero/storage/A2T98PXV/Monderer and Shapley - 1996 - Potential Games.pdf:application/pdf;ScienceDirect Snapshot:/Users/oliverbiggar/Zotero/storage/WVSJIRAD/S0899825696900445.html:text/html},
}

@article{bayer_best-response_2023,
	title = {Best-response dynamics in directed network games},
	volume = {213},
	issn = {0022-0531},
	url = {https://www.sciencedirect.com/science/article/pii/S0022053123001163},
	doi = {10.1016/j.jet.2023.105720},
	abstract = {We study public goods games played on networks with possibly non-reciprocal relationships between players. These include one-sided relationships, mutual but unequal relationships, and parasitism. It is known that many learning processes converge to the game's Nash equilibrium if interactions are reciprocal, but this is not true in general for directed networks. Under one-sided and parasitic relationships, best-response dynamics may cycle. The production of the locally public good of players may fail to converge to an equilibrium, making static analysis less insightful in an applied setting. In this paper we show that the strong convergence results of the undirected case are retained for two economically relevant classes of directed networks: those with transitive relative importance of players and those rescalable into networks with weak externalities.},
	urldate = {2023-10-12},
	journal = {Journal of Economic Theory},
	author = {Bayer, Péter and Kozics, György and Szőke, Nóra Gabriella},
	month = oct,
	year = {2023},
	keywords = {Potential games, Directed networks, Externalities, Public goods},
	pages = {105720},
	file = {ScienceDirect Full Text PDF:/Users/oliverbiggar/Zotero/storage/GLZYW9ID/Bayer et al. - 2023 - Best-response dynamics in directed network games.pdf:application/pdf;ScienceDirect Snapshot:/Users/oliverbiggar/Zotero/storage/EKQ63ZXN/S0022053123001163.html:text/html},
}

@misc{daskalakis_near-optimal_2023,
	title = {Near-{Optimal} {No}-{Regret} {Learning} in {General} {Games}},
	url = {http://arxiv.org/abs/2108.06924},
	doi = {10.48550/arXiv.2108.06924},
	abstract = {We show that Optimistic Hedge -- a common variant of multiplicative-weights-updates with recency bias -- attains \$\{{\textbackslash}rm poly\}({\textbackslash}log T)\$ regret in multi-player general-sum games. In particular, when every player of the game uses Optimistic Hedge to iteratively update her strategy in response to the history of play so far, then after \$T\$ rounds of interaction, each player experiences total regret that is \$\{{\textbackslash}rm poly\}({\textbackslash}log T)\$. Our bound improves, exponentially, the \$O(\{T\}{\textasciicircum}\{1/2\})\$ regret attainable by standard no-regret learners in games, the \$O(T{\textasciicircum}\{1/4\})\$ regret attainable by no-regret learners with recency bias (Syrgkanis et al., 2015), and the \$\{O\}(T{\textasciicircum}\{1/6\})\$ bound that was recently shown for Optimistic Hedge in the special case of two-player games (Chen \& Pen, 2020). A corollary of our bound is that Optimistic Hedge converges to coarse correlated equilibrium in general games at a rate of \${\textbackslash}tilde\{O\}{\textbackslash}left({\textbackslash}frac 1T{\textbackslash}right)\$.},
	urldate = {2023-10-13},
	publisher = {arXiv},
	author = {Daskalakis, Constantinos and Fishelson, Maxwell and Golowich, Noah},
	month = jan,
	year = {2023},
	note = {arXiv:2108.06924 [cs]},
	keywords = {Computer Science - Machine Learning},
	file = {arXiv Fulltext PDF:/Users/oliverbiggar/Zotero/storage/97FJIKQ7/Daskalakis et al. - 2023 - Near-Optimal No-Regret Learning in General Games.pdf:application/pdf;arXiv.org Snapshot:/Users/oliverbiggar/Zotero/storage/LG28BPZQ/2108.html:text/html},
}

@article{axelrod_evolution_1981,
	title = {The {Evolution} of {Cooperation}},
	volume = {211},
	url = {https://www.science.org/doi/abs/10.1126/science.7466396},
	doi = {10.1126/science.7466396},
	abstract = {Cooperation in organisms, whether bacteria or primates, has been a difficulty for evolutionary theory since Darwin. On the assumption that interactions between pairs of individuals occur on a probabilistic basis, a model is developed based on the concept of an evolutionarily stable strategy in the context of the Prisoner's Dilemma game. Deductions from the model, and the results of a computer tournament show how cooperation based on reciprocity can get started in an asocial world, can thrive while interacting with a wide range of other strategies, and can resist invasion once fully established. Potential applications include specific aspects of territoriality, mating, and disease.},
	number = {4489},
	urldate = {2023-10-13},
	journal = {Science},
	author = {Axelrod, Robert and Hamilton, William D.},
	month = mar,
	year = {1981},
	note = {Publisher: American Association for the Advancement of Science},
	pages = {1390--1396},
}

@article{kokubu_users_nodate,
	title = {A {User}’s {Guide} to the {Conley}-{Morse} {Database}},
	abstract = {The past few decades of dynamical systems theory have established that multiparameter nonlinear dynamical systems can exhibit extremely complex behavior with respect to both the system variables and parameters. Such complex behavior proven in theoretical work has to be contrasted with the capabilities of application; in the case of modeling multiscale processes, for instance, measurements may be of limited precision, parameters are rarely known exactly and nonlinearities are often not derived from ﬁrst principles. This contrast suggests that extracting robust features which persist over a range of parameter values is of greater importance than a detailed understanding of the ﬁne structure at some particular parameter. That is, the resolution at which one analyzes the problem is of fundamental importance. The goal of this paper is to present an overview of an approach to dynamics which accounts for the role of resolution. This approach is used to obtain a coarse yet robust description of the global dynamics at a resolution speciﬁed a priori. A crude but rigorous characterization of the local dynamics is given via the Conley Index - an algebraic topological invariant. Foremost, we wish to convey these ideas to a general audience, casting the theory in a simple combinatorial framework to provide what one needs to know to become a ‘user’.},
	language = {en},
	author = {Kokubu, Hiroshi and Spendlove, Kelly},
	file = {Kokubu and Spendlove - A User’s Guide to the Conley-Morse Database.pdf:/Users/oliverbiggar/Zotero/storage/HWTKSZZD/Kokubu and Spendlove - A User’s Guide to the Conley-Morse Database.pdf:application/pdf},
}

@article{milionis_impossibility_2023,
	title = {An impossibility theorem in game dynamics},
	volume = {120},
	url = {https://www.pnas.org/doi/abs/10.1073/pnas.2305349120},
	doi = {10.1073/pnas.2305349120},
	abstract = {The Nash equilibrium—a, combination of choices by the players of a game from which no self-interested player would deviate—is the predominant solution concept in game theory. Even though every game has a Nash equilibrium, it is not known whether there are deterministic behaviors of the players who play a game repeatedly that are guaranteed to converge to a Nash equilibrium of the game from all starting points. If one assumes that the players’ behavior is a discrete-time or continuous-time rule whereby the current mixed strategy profile is mapped to the next, this question becomes a problem in the theory of dynamical systems. We apply this theory, and in particular Conley index theory, to prove a general impossibility result: There exist games, for which all game dynamics fail to converge to Nash equilibria from all starting points. The games which help prove this impossibility result are degenerate, but we conjecture that the same result holds, under computational complexity assumptions, for nondegenerate games. We also prove a stronger impossibility result for the solution concept of approximate Nash equilibria: For a set of games of positive measure, no game dynamics can converge to the set of approximate Nash equilibria for a sufficiently small yet substantial approximation bound. Our results establish that, although the notions of Nash equilibrium and its computation-inspired approximations are universally applicable in all games, they are fundamentally incomplete as predictors of long-term player behavior.},
	number = {41},
	urldate = {2023-10-13},
	journal = {Proceedings of the National Academy of Sciences},
	author = {Milionis, Jason and Papadimitriou, Christos and Piliouras, Georgios and Spendlove, Kelly},
	month = oct,
	year = {2023},
	note = {Publisher: Proceedings of the National Academy of Sciences},
	pages = {e2305349120},
	file = {Full Text PDF:/Users/oliverbiggar/Zotero/storage/P4XAJTK5/Milionis et al. - 2023 - An impossibility theorem in game dynamics.pdf:application/pdf},
}

@article{ban_computational_2006,
	title = {A {Computational} {Approach} to {Conley}’s {Decomposition} {Theorem}},
	volume = {1},
	issn = {1555-1415, 1555-1423},
	url = {https://asmedigitalcollection.asme.org/computationalnonlinear/article/1/4/312/475324/A-Computational-Approach-to-Conleys-Decomposition},
	doi = {10.1115/1.2338651},
	abstract = {The discrete dynamics generated by a continuous map can be represented combinatorially by an appropriate multivalued map on a discretization of the phase space such as a cubical grid or triangulation. In this paper we provide explicit algorithms and computational complexity bounds for computing dynamical structures for the resulting combinatorial multivalued maps. Speciﬁcally we focus on the computation attractor-repeller pairs and Lyapunov functions for Morse decompositions. These discrete Lyapunov functions are weak Lyapunov functions and well-approximate a continuous Lyapunov function for the underlying map.},
	language = {en},
	number = {4},
	urldate = {2023-10-14},
	journal = {Journal of Computational and Nonlinear Dynamics},
	author = {Ban, Hyunju and Kalies, William D.},
	month = oct,
	year = {2006},
	pages = {312--319},
	file = {Ban and Kalies - 2006 - A Computational Approach to Conley’s Decomposition.pdf:/Users/oliverbiggar/Zotero/storage/HJ63VD2D/Ban and Kalies - 2006 - A Computational Approach to Conley’s Decomposition.pdf:application/pdf},
}

@inproceedings{piliouras_learning_2018,
	address = {Dagstuhl, Germany},
	series = {Leibniz {International} {Proceedings} in {Informatics} ({LIPIcs})},
	title = {Learning {Dynamics} and the {Co}-{Evolution} of {Competing} {Sexual} {Species}},
	volume = {94},
	isbn = {978-3-95977-060-6},
	url = {http://drops.dagstuhl.de/opus/volltexte/2018/8363},
	doi = {10.4230/LIPIcs.ITCS.2018.59},
	urldate = {2023-10-14},
	booktitle = {9th {Innovations} in {Theoretical} {Computer} {Science} {Conference} ({ITCS} 2018)},
	publisher = {Schloss Dagstuhl–Leibniz-Zentrum fuer Informatik},
	author = {Piliouras, Georgios and Schulman, Leonard J.},
	editor = {Karlin, Anna R.},
	year = {2018},
	note = {ISSN: 1868-8969},
	keywords = {Potential Game, Boolean Functions, Dynamical Systems, Replicator Dynamics, Team Zero-Sum Game},
	pages = {59:1--59:3},
	file = {Full Text PDF:/Users/oliverbiggar/Zotero/storage/PY7VSHBE/Piliouras and Schulman - 2018 - Learning Dynamics and the Co-Evolution of Competin.pdf:application/pdf;Snapshot:/Users/oliverbiggar/Zotero/storage/V8TE96ZI/8363.html:text/html},
}

@article{rosenthal_class_1973,
	title = {A class of games possessing pure-strategy {Nash} equilibria},
	volume = {2},
	issn = {0020-7276},
	journal = {International Journal of Game Theory},
	author = {Rosenthal, Robert W},
	year = {1973},
	note = {Publisher: Physica-Verlag},
	pages = {65--67},
	file = {Rosenthal - 1973 - A class of games possessing pure-strategy Nash equ.pdf:/Users/oliverbiggar/Zotero/storage/BBDV9CK5/Rosenthal - 1973 - A class of games possessing pure-strategy Nash equ.pdf:application/pdf},
}

@inproceedings{panageas_average_2016,
	address = {New York, NY, USA},
	series = {{EC} '16},
	title = {Average {Case} {Performance} of {Replicator} {Dynamics} in {Potential} {Games} via {Computing} {Regions} of {Attraction}},
	isbn = {978-1-4503-3936-0},
	url = {https://dl.acm.org/doi/10.1145/2940716.2940784},
	doi = {10.1145/2940716.2940784},
	abstract = {What does it mean to fully understand the behavior of a network of adaptive agents? The golden standard typically is the behavior of learning dynamics in potential games, where many evolutionary dynamics, e.g., replicator dynamics, are known to converge to sets of equilibria. Even in such classic settings many questions remain unanswered. We examine issues such as: Point-wise convergence: Does the system always equilibrate, even in the presence of continuums of equilibria? Computing regions of attraction: Given point-wise convergence can we compute the region of asymptotic stability of each equilibrium (e.g., estimate its volume, geometry)? System invariants: Invariant functions remain constant along every system trajectory. This notion is orthogonal to the game theoretic concept of a potential function, which always strictly increases/decreases along system trajectories. Do dynamics in potential games exhibit invariant functions? If so, how many? How do these functions look like? Based on these geometric characterizations, we propose a novel quantitative framework for analyzing the efficiency of potential games with many equilibria. The predictions of different equilibria are weighted by their probability to arise under evolutionary dynamics given uniformly random initial conditions. This average case analysis is shown to offer novel insights in classic game theoretic challenges, including quantifying the risk dominance in stag-hunt games and allowing for more nuanced performance analysis in networked coordination and congestion games with large gaps between price of stability and price of anarchy. CCS Concepts: rTheory of computation! Solution concepts in game theory; Convergence and learning in games;},
	urldate = {2023-10-18},
	booktitle = {Proceedings of the 2016 {ACM} {Conference} on {Economics} and {Computation}},
	publisher = {Association for Computing Machinery},
	author = {Panageas, Ioannis and Piliouras, Georgios},
	month = jul,
	year = {2016},
	keywords = {congestion games, dynamical systems, price of anarchy, replicator},
	pages = {703--720},
	file = {Full Text PDF:/Users/oliverbiggar/Zotero/storage/ZLZRHHAQ/Panageas and Piliouras - 2016 - Average Case Performance of Replicator Dynamics in.pdf:application/pdf},
}

@article{hart_simple_2000,
	title = {A {Simple} {Adaptive} {Procedure} {Leading} to {Correlated} {Equilibrium}},
	volume = {68},
	copyright = {Econometric Society 2000},
	issn = {1468-0262},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/1468-0262.00153},
	doi = {10.1111/1468-0262.00153},
	abstract = {We propose a new and simple adaptive procedure for playing a game: ‘regret-matching.’ In this procedure, players may depart from their current play with probabilities that are proportional to measures of regret for not having used other strategies in the past. It is shown that our adaptive procedure guarantees that, with probability one, the empirical distributions of play converge to the set of correlated equilibria of the game.},
	language = {en},
	number = {5},
	urldate = {2023-10-24},
	journal = {Econometrica},
	author = {Hart, Sergiu and Mas-Colell, Andreu},
	year = {2000},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/1468-0262.00153},
	keywords = {Adaptive procedure, correlated equilibrium, no regret, regret-matching, simple strategies.},
	pages = {1127--1150},
	file = {Hart and Mas-Colell - 2000 - A Simple Adaptive Procedure Leading to Correlated .pdf:/Users/oliverbiggar/Zotero/storage/ENUJ5PS4/Hart and Mas-Colell - 2000 - A Simple Adaptive Procedure Leading to Correlated .pdf:application/pdf;Snapshot:/Users/oliverbiggar/Zotero/storage/J4LQE6TS/1468-0262.html:text/html},
}

@article{amiet_pure_2021,
	title = {Pure {Nash} {Equilibria} and {Best}-{Response} {Dynamics} in {Random} {Games}},
	volume = {46},
	issn = {0364-765X},
	url = {https://pubsonline.informs.org/doi/10.1287/moor.2020.1102},
	doi = {10.1287/moor.2020.1102},
	abstract = {In finite games, mixed Nash equilibria always exist, but pure equilibria may fail to exist. To assess the relevance of this nonexistence, we consider games where the payoffs are drawn at random. In particular, we focus on games where a large number of players can each choose one of two possible strategies and the payoffs are independent and identically distributed with the possibility of ties. We provide asymptotic results about the random number of pure Nash equilibria, such as fast growth and a central limit theorem, with bounds for the approximation error. Moreover, by using a new link between percolation models and game theory, we describe in detail the geometry of pure Nash equilibria and show that, when the probability of ties is small, a best-response dynamics reaches a pure Nash equilibrium with a probability that quickly approaches one as the number of players grows. We show that various phase transitions depend only on a single parameter of the model, that is, the probability of having ties.},
	number = {4},
	urldate = {2023-11-03},
	journal = {Mathematics of Operations Research},
	author = {Amiet, Ben and Collevecchio, Andrea and Scarsini, Marco and Zhong, Ziwen},
	month = nov,
	year = {2021},
	note = {Publisher: INFORMS},
	keywords = {best response dynamics, percolation, Primary: 91A10, Primary: Games/group decisions: noncooperative; secondary: probability: Markov processes, pure Nash equilibrium, random game, secondary: 91A06, 60K35},
	pages = {1552--1572},
	file = {Submitted Version:/Users/oliverbiggar/Zotero/storage/9ZVIYTHP/Amiet et al. - 2021 - Pure Nash Equilibria and Best-Response Dynamics in.pdf:application/pdf},
}

@article{pangallo_best-response_2021,
	title = {Best-{Response} {Dynamics}, {Playing} {Sequences}, {And} {Convergence} {To} {Equilibrium} {In} {Random} {Games}},
	url = {https://ideas.repec.org//p/amz/wpaper/2021-02.html},
	abstract = {We show that the playing sequence–the order in which players update their actions–is a crucial determinant of whether the best-response dynamic converges to a Nash equilibrium. Specifically, we analyze the probability that the best-response dynamic converges to a pure Nash equilibrium in random n-player m-action games under three distinct playing sequences: clockwork sequences (players take turns according to a fixed cyclic order), random sequences, and simultaneous updating by all players. We analytically characterize the convergence properties of the clockwork sequence best-response dynamic. Our key asymptotic result is that this dynamic almost never converges to a pure Nash equilibrium when n and m are large. By contrast, the random sequence best-response dynamic converges almost always to a pure Nash equilibrium when one exists and n and m are large. The clockwork best-response dynamic deserves particular attention: we show through simulation that, compared to random or simultaneous updating, its convergence properties are closest to those exhibited by three popular learning rules that have been calibrated to human game-playing in experiments (reinforcement learning, fictitious play, and replicator dynamics).},
	language = {en},
	urldate = {2023-11-03},
	journal = {INET Oxford Working Papers},
	author = {Pangallo, Marco and Heinrich, Torsten and Jang, Yoojin and Scott, Alex and Tarbush, Bassel and Wiese, Samuel and Mungo, Luca},
	month = jan,
	year = {2021},
	note = {Number: 2021-02
Publisher: Institute for New Economic Thinking at the Oxford Martin School, University of Oxford},
	keywords = {Best-response dynamics, equilibrium convergence, learning models in games, random games},
	file = {Fullext PDF:/Users/oliverbiggar/Zotero/storage/6ACJRGL9/Pangallo et al. - 2021 - Best-Response Dynamics, Playing Sequences, And Con.pdf:application/pdf;Snapshot:/Users/oliverbiggar/Zotero/storage/53M9TZRL/2021-02.html:text/html},
}

@article{boone_equivalence_2023,
	title = {The equivalence of dynamic and strategic stability under regularized learning in games},
	journal = {arXiv preprint arXiv:2311.02407},
	author = {Boone, Victor and Mertikopoulos, Panayotis},
	year = {2023},
}

@misc{boone_equivalence_2023-1,
	title = {The equivalence of dynamic and strategic stability under regularized learning in games},
	url = {http://arxiv.org/abs/2311.02407},
	doi = {10.48550/arXiv.2311.02407},
	abstract = {In this paper, we examine the long-run behavior of regularized, no-regret learning in finite games. A well-known result in the field states that the empirical frequencies of no-regret play converge to the game's set of coarse correlated equilibria; however, our understanding of how the players' actual strategies evolve over time is much more limited - and, in many cases, non-existent. This issue is exacerbated further by a series of recent results showing that only strict Nash equilibria are stable and attracting under regularized learning, thus making the relation between learning and pointwise solution concepts particularly elusive. In lieu of this, we take a more general approach and instead seek to characterize the {\textbackslash}emph\{setwise\} rationality properties of the players' day-to-day play. To that end, we focus on one of the most stringent criteria of setwise strategic stability, namely that any unilateral deviation from the set in question incurs a cost to the deviator - a property known as closedness under better replies (club). In so doing, we obtain a far-reaching equivalence between strategic and dynamic stability: a product of pure strategies is closed under better replies if and only if its span is stable and attracting under regularized learning. In addition, we estimate the rate of convergence to such sets, and we show that methods based on entropic regularization (like the exponential weights algorithm) converge at a geometric rate, while projection-based methods converge within a finite number of iterations, even with bandit, payoff-based feedback.},
	urldate = {2023-12-01},
	publisher = {arXiv},
	author = {Boone, Victor and Mertikopoulos, Panayotis},
	month = nov,
	year = {2023},
	note = {arXiv:2311.02407 [cs, math]},
	keywords = {Computer Science - Computer Science and Game Theory, Computer Science - Machine Learning, Mathematics - Optimization and Control, Primary 91A10, 91A26, secondary 68Q32, 62L20},
	file = {arXiv Fulltext PDF:/Users/oliverbiggar/Zotero/storage/C3PCHK6G/Boone and Mertikopoulos - 2023 - The equivalence of dynamic and strategic stability.pdf:application/pdf;arXiv.org Snapshot:/Users/oliverbiggar/Zotero/storage/89X2YN85/2311.html:text/html},
}

@article{myerson_refinements_1978,
	title = {Refinements of the {Nash} equilibrium concept},
	volume = {7},
	issn = {1432-1270},
	url = {https://doi.org/10.1007/BF01753236},
	doi = {10.1007/BF01753236},
	abstract = {Selten's concept of perfect equilibrium for normal form games is reviewed, and a new concept of proper equilibrium is defined. It is shown that the proper equilibria form a nonempty subset of the perfect equilibria, which in turn form a subset of the Nash equilibria. An example is given to show that these inclusions may be strict.},
	language = {en},
	number = {2},
	urldate = {2023-12-05},
	journal = {International Journal of Game Theory},
	author = {Myerson, R. B.},
	month = jun,
	year = {1978},
	keywords = {Economic Theory, Game Theory, Nash Equilibrium, Nonempty Subset, Normal Form},
	pages = {73--80},
	file = {Full Text PDF:/Users/oliverbiggar/Zotero/storage/DUIIJ4ZI/Myerson - 1978 - Refinements of the Nash equilibrium concept.pdf:application/pdf},
}

@article{quint_bound_1995,
	title = {A bound on the number of {Nash} equilibria in a coordination game},
	author = {Quint, Thomas and Shubik, Martin},
	year = {1995},
	file = {Quint and Shubik - 1995 - A bound on the number of Nash equilibria in a coor.pdf:/Users/oliverbiggar/Zotero/storage/EKYGG7EW/Quint and Shubik - 1995 - A bound on the number of Nash equilibria in a coor.pdf:application/pdf},
}

@article{quint_number_1994,
	title = {On the {Number} of {Nash} {Equilibria} in a {Bimatrix} {Game}},
	url = {https://elischolar.library.yale.edu/cowles-discussion-paper-series/1332},
	journal = {Cowles Foundation Discussion Papers},
	author = {Quint, Thomas and Shubik, Martin},
	month = dec,
	year = {1994},
	file = {"On the Number of Nash Equilibria in a Bimatrix Game" by Thomas Quint and Martin Shubik:/Users/oliverbiggar/Zotero/storage/FDNP38IH/1332.html:text/html;Quint and Shubik - 1994 - On the Number of Nash Equilibria in a Bimatrix Gam.pdf:/Users/oliverbiggar/Zotero/storage/UIJVNPLL/Quint and Shubik - 1994 - On the Number of Nash Equilibria in a Bimatrix Gam.pdf:application/pdf},
}

@incollection{shapley_note_1974,
	address = {Berlin, Heidelberg},
	series = {Mathematical {Programming} {Studies}},
	title = {A note on the {Lemke}-{Howson} algorithm},
	isbn = {978-3-642-00758-3},
	url = {https://doi.org/10.1007/BFb0121248},
	abstract = {The Lemke-Howson algorithm for bimatrix games provides both an elementary proof of the existence of equilibrium points and an efficient computational method for finding at least one equilibrium point. The first half of this paper presents a geometrical view of the algorithm that makes its operation especially easy to visualize. Several illustrations are given, including Wilson’s example of “inaccessible” equilibrium points. The second half presents an orientation theory for the equilibrium points of (nondegenerate) bimatrix games and the Lemke-Howson paths that interconnect them; in particular, it is shown that there is always one more “negative” than “positive” equilibrium point.},
	language = {en},
	urldate = {2023-12-06},
	booktitle = {Pivoting and {Extension}: {In} honor of {A}.{W}. {Tucker}},
	publisher = {Springer},
	author = {Shapley, Lloyd S.},
	editor = {Balinski, M. L.},
	year = {1974},
	doi = {10.1007/BFb0121248},
	keywords = {Pure Strategy, Equilibrium Point, Large Game, Node Pair, Simplicial Complex},
	pages = {175--189},
	file = {Full Text PDF:/Users/oliverbiggar/Zotero/storage/9WZQCKII/Shapley - 1974 - A note on the Lemke-Howson algorithm.pdf:application/pdf},
}

@article{nash_equilibrium_1950,
	title = {Equilibrium points in n-person games},
	volume = {36},
	url = {https://www.pnas.org/doi/abs/10.1073/pnas.36.1.48},
	doi = {10.1073/pnas.36.1.48},
	number = {1},
	urldate = {2023-12-06},
	journal = {Proceedings of the National Academy of Sciences},
	author = {Nash, John F.},
	month = jan,
	year = {1950},
	note = {Publisher: Proceedings of the National Academy of Sciences},
	pages = {48--49},
	file = {Full Text PDF:/Users/oliverbiggar/Zotero/storage/NMUPDPBG/Nash - 1950 - Equilibrium points in n-person games.pdf:application/pdf},
}

@article{shapley_stochastic_1953,
	title = {Stochastic {Games}*},
	volume = {39},
	url = {https://www.pnas.org/doi/abs/10.1073/pnas.39.10.1095},
	doi = {10.1073/pnas.39.10.1095},
	number = {10},
	urldate = {2023-12-06},
	journal = {Proceedings of the National Academy of Sciences},
	author = {Shapley, L. S.},
	month = oct,
	year = {1953},
	note = {Publisher: Proceedings of the National Academy of Sciences},
	pages = {1095--1100},
	file = {Full Text PDF:/Users/oliverbiggar/Zotero/storage/LMKNQZ4W/Shapley - 1953 - Stochastic Games.pdf:application/pdf},
}

@article{berger_browns_2007,
	title = {Brown's original fictitious play},
	volume = {135},
	issn = {0022-0531},
	url = {https://www.sciencedirect.com/science/article/pii/S0022053106000299},
	doi = {10.1016/j.jet.2005.12.010},
	abstract = {What modern game theorists describe as “fictitious play” is not the learning process George W. Brown defined in his 1951 paper. Brown's original version differs in a subtle detail, namely the order of belief updating. In this note we revive Brown's original fictitious play process and demonstrate that this seemingly innocent detail allows for an extremely simple and intuitive proof of convergence in an interesting and large class of games: nondegenerate ordinal potential games.},
	number = {1},
	urldate = {2023-12-06},
	journal = {Journal of Economic Theory},
	author = {Berger, Ulrich},
	month = jul,
	year = {2007},
	keywords = {Fictitious play, Learning process, Ordinal potential games},
	pages = {572--578},
	file = {ScienceDirect Snapshot:/Users/oliverbiggar/Zotero/storage/SEV7G5D4/S0022053106000299.html:text/html;Submitted Version:/Users/oliverbiggar/Zotero/storage/4GDSVAUQ/Berger - 2007 - Brown's original fictitious play.pdf:application/pdf},
}

@article{young_evolution_1993,
	title = {The {Evolution} of {Conventions}},
	volume = {61},
	issn = {0012-9682},
	url = {https://www.jstor.org/stable/2951778},
	doi = {10.2307/2951778},
	abstract = {Consider an n-person game that is played repeatedly, but by different agents. In each period, n players are drawn at random from a large finite population. Each player chooses an optimal strategy based on a sample of information about what others players have done in the past. The sampling defines a stochastic process that, for a large class of games that includes coordination games and common interest games, converges almost surely to a pure strategy Nash equilibrium. Such an equilibrium can be interpreted as the "conventional" way of playing the game. If, in addition, the players sometimes experiment or make mistakes, then society occasionally switches from one convention to another. As the likelihood of mistakes goes to zero, only some conventions (equilibria) have positive probability in the limit. These are known as stochastically stable equilibria. They are essentially the same as the risk dominant equilibria in 2 × 2 games, but for general games the two concepts differ. The stochastically stable equilibria are computed by finding a path of least resistance from every equilibrium to every other, and then finding the equilibrium that has lowest overall resistance. This is a special case of a general theorem on perturbed Markov processes that characterizes their stochastically stable states graph-theoretically.},
	number = {1},
	urldate = {2023-12-06},
	journal = {Econometrica},
	author = {Young, H. Peyton},
	year = {1993},
	note = {Publisher: [Wiley, Econometric Society]},
	pages = {57--84},
	file = {JSTOR Full Text PDF:/Users/oliverbiggar/Zotero/storage/YR85BMHU/Young - 1993 - The Evolution of Conventions.pdf:application/pdf},
}

@article{crawford_evolutionary_1991,
	title = {An “evolutionary” interpretation of {Van} {Huyck}, {Battalio}, and {Beil}'s experimental results on coordination},
	volume = {3},
	issn = {0899-8256},
	url = {https://www.sciencedirect.com/science/article/pii/089982569190004X},
	doi = {10.1016/0899-8256(91)90004-X},
	abstract = {This paper proposes an adaptive interpretation of the results of some recent experiments with repeated tacit coordination games. These experiments revealed several behavioral regularities, including a systematic discrimination between strict Nash equilibria in certain games, that appear to be driven by strategic uncertainty, and are not explained by traditional equilibrium refinements. The observed patterns of discrimination correspond closely to predictions based on Maynard Smith's notion of evolutionary stability. An adaptive model, in the spirit of the evolutionary dynamics but recognizing the important differences between learning in human populations and evolution, promises to yield a unified explanation of the results. Journal of Economic Literature Classification Numbers: 020, 026.},
	number = {1},
	urldate = {2023-12-06},
	journal = {Games and Economic Behavior},
	author = {Crawford, Vincent P},
	month = feb,
	year = {1991},
	pages = {25--59},
	file = {ScienceDirect Snapshot:/Users/oliverbiggar/Zotero/storage/GS35L5KX/089982569190004X.html:text/html;Submitted Version:/Users/oliverbiggar/Zotero/storage/7XP5MPLJ/Crawford - 1991 - An “evolutionary” interpretation of Van Huyck, Bat.pdf:application/pdf},
}

@article{milchtaich_congestion_1996,
	title = {Congestion {Games} with {Player}-{Specific} {Payoff} {Functions}},
	volume = {13},
	issn = {0899-8256},
	url = {https://www.sciencedirect.com/science/article/pii/S0899825696900275},
	doi = {10.1006/game.1996.0027},
	abstract = {A class of noncooperative games in which the players share a common set of strategies is described. The payoff a player receives for playing a particular strategy depends only on the total number of players playing the same strategy and decreases with that number in a manner which is specific to the particular player. It is shown that each game in this class possesses at least one Nash equilibrium in pure strategies. Best-reply paths in which players, one at a time, shift to best-reply strategies may be cyclic. But there is always at least one such path that connects an arbitrary initial point to an equilibrium.Journal of Economic LiteratureClassification Number: C72.},
	number = {1},
	urldate = {2023-12-06},
	journal = {Games and Economic Behavior},
	author = {Milchtaich, Igal},
	month = mar,
	year = {1996},
	pages = {111--124},
	file = {Milchtaich - 1996 - Congestion Games with Player-Specific Payoff Funct.pdf:/Users/oliverbiggar/Zotero/storage/T8S447TD/Milchtaich - 1996 - Congestion Games with Player-Specific Payoff Funct.pdf:application/pdf;ScienceDirect Snapshot:/Users/oliverbiggar/Zotero/storage/R83Z4SZN/S0899825696900275.html:text/html},
}

@article{milchtaich_congestion_1996-1,
	title = {Congestion {Games} with {Player}-{Specific} {Payoff} {Functions}},
	volume = {13},
	issn = {08998256},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0899825696900275},
	doi = {10.1006/game.1996.0027},
	language = {en},
	number = {1},
	urldate = {2023-12-06},
	journal = {Games and Economic Behavior},
	author = {Milchtaich, Igal},
	month = mar,
	year = {1996},
	pages = {111--124},
	file = {Milchtaich - 1996 - Congestion Games with Player-Specific Payoff Funct.pdf:/Users/oliverbiggar/Zotero/storage/F3EAXGVC/Milchtaich - 1996 - Congestion Games with Player-Specific Payoff Funct.pdf:application/pdf},
}

@article{blume_statistical_1993,
	title = {The {Statistical} {Mechanics} of {Strategic} {Interaction}},
	volume = {5},
	issn = {0899-8256},
	url = {https://www.sciencedirect.com/science/article/pii/S0899825683710237},
	doi = {10.1006/game.1993.1023},
	abstract = {I study strategic interaction among players who live on a lattice. Each player interacts directly with only a finite set of neighbors, but any two players indirectly interact through a finite chain of direct interactions. I examine various stochastic strategy revision processes, including (myopic) best response and stochastic choice. I discuss both stationary distributions and the limit behavior of these Markov processes. Stationary distributions are partially characterized, and the asymptotic behavior of stochastic choice for those processes whose choice rule is nearly best-response is related to equilibrium selection in symmetric 2 × 2 and n × n coordination games. Journal of Economic Literature Classification Number: C78.},
	number = {3},
	urldate = {2023-12-06},
	journal = {Games and Economic Behavior},
	author = {Blume, Lawrence E.},
	month = jul,
	year = {1993},
	pages = {387--424},
	file = {Blume - 1993 - The Statistical Mechanics of Strategic Interaction.pdf:/Users/oliverbiggar/Zotero/storage/F4ZBF424/Blume - 1993 - The Statistical Mechanics of Strategic Interaction.pdf:application/pdf;ScienceDirect Snapshot:/Users/oliverbiggar/Zotero/storage/VBCZI8BF/S0899825683710237.html:text/html},
}

@article{berger_two_2007,
	title = {Two more classes of games with the continuous-time fictitious play property},
	volume = {60},
	issn = {0899-8256},
	url = {https://www.sciencedirect.com/science/article/pii/S0899825606001734},
	doi = {10.1016/j.geb.2006.10.008},
	abstract = {Fictitious Play is the oldest and most studied learning process for games. Since the already classical result for zero-sum games, convergence of beliefs to the set of Nash equilibria has been established for several classes of games, including weighted potential games, supermodular games with diminishing returns, and 3×3 supermodular games. Extending these results, we establish convergence of Continuous-time Fictitious Play for ordinal potential games and quasi-supermodular games with diminishing returns. As a by-product we obtain convergence for 3×m and 4×4 quasi-supermodular games.},
	number = {2},
	urldate = {2023-12-06},
	journal = {Games and Economic Behavior},
	author = {Berger, Ulrich},
	month = aug,
	year = {2007},
	keywords = {Fictitious play, Learning process, Ordinal potential games, Quasi-supermodular games},
	pages = {247--261},
	file = {ScienceDirect Snapshot:/Users/oliverbiggar/Zotero/storage/NC2Q6LXM/S0899825606001734.html:text/html;Submitted Version:/Users/oliverbiggar/Zotero/storage/VZTJWH6S/Berger - 2007 - Two more classes of games with the continuous-time.pdf:application/pdf},
}

@article{berger_fictitious_2005,
	title = {Fictitious play in 2×n games},
	volume = {120},
	issn = {0022-0531},
	url = {https://www.sciencedirect.com/science/article/pii/S0022053104000626},
	doi = {10.1016/j.jet.2004.02.003},
	abstract = {It is known that every discrete-time fictitious play process approaches equilibrium in nondegenerate 2×2 games, and that every continuous-time fictitious play process approaches equilibrium in nondegenerate 2×2 and 2×3 games. It has also been conjectured that convergence to the set of equilibria holds generally for nondegenerate 2×n games. We give a simple geometric proof of this for the continuous-time process, and also extend the result to discrete-time fictitious play.},
	number = {2},
	urldate = {2023-12-06},
	journal = {Journal of Economic Theory},
	author = {Berger, Ulrich},
	month = feb,
	year = {2005},
	keywords = {Fictitious play, Learning process, 2× Games},
	pages = {139--154},
	file = {Berger - 2005 - Fictitious play in 2×n games.pdf:/Users/oliverbiggar/Zotero/storage/U2EJREAP/Berger - 2005 - Fictitious play in 2×n games.pdf:application/pdf;ScienceDirect Snapshot:/Users/oliverbiggar/Zotero/storage/FXHHPL4J/S0022053104000626.html:text/html},
}

@article{berger_learning_2008,
	title = {Learning in games with strategic complementarities revisited},
	volume = {143},
	issn = {0022-0531},
	url = {https://www.sciencedirect.com/science/article/pii/S0022053108000574},
	doi = {10.1016/j.jet.2008.01.007},
	abstract = {Fictitious play is a classical learning process for games, and games with strategic complementarities are an important class including many economic applications. Knowledge about convergence properties of fictitious play in this class of games is scarce, however. Beyond games with a unique equilibrium, global convergence has only been claimed for games with diminishing returns [V. Krishna, Learning in games with strategic complementarities, HBS Working Paper 92-073, Harvard University, 1992]. This result remained unpublished, and it relies on a specific tie-breaking rule. Here we prove an extension of it by showing that the ordinal version of strategic complementarities suffices. The proof does not rely on tie-breaking rules and provides some intuition for the result.},
	number = {1},
	urldate = {2023-12-06},
	journal = {Journal of Economic Theory},
	author = {Berger, Ulrich},
	month = nov,
	year = {2008},
	keywords = {Fictitious play, Learning process, Ordinal complementarities, Strategic complementarities},
	pages = {292--301},
	file = {ScienceDirect Snapshot:/Users/oliverbiggar/Zotero/storage/7GCEVAPV/S0022053108000574.html:text/html;Submitted Version:/Users/oliverbiggar/Zotero/storage/D899ZX59/Berger - 2008 - Learning in games with strategic complementarities.pdf:application/pdf},
}

@article{monderer_fictitious_1996,
	title = {Fictitious {Play} {Property} for {Games} with {Identical} {Interests}},
	volume = {68},
	issn = {0022-0531},
	url = {https://www.sciencedirect.com/science/article/pii/S0022053196900149},
	doi = {10.1006/jeth.1996.0014},
	abstract = {Ann-person game has identical interests if it is best response equivalent in mixed strategies to a game with identical payoff functions. It is proved that every such game has the fictitious play property.Journal of Economic LiteratureClassification Numbers: C72, C73.},
	number = {1},
	urldate = {2023-12-06},
	journal = {Journal of Economic Theory},
	author = {Monderer, Dov and Shapley, Lloyd S.},
	month = jan,
	year = {1996},
	pages = {258--265},
	file = {ScienceDirect Full Text PDF:/Users/oliverbiggar/Zotero/storage/DEARVUMI/Monderer and Shapley - 1996 - Fictitious Play Property for Games with Identical .pdf:application/pdf;ScienceDirect Snapshot:/Users/oliverbiggar/Zotero/storage/JR8FMSCN/S0022053196900149.html:text/html},
}

@article{monderer_fictitious_1997,
	title = {Fictitious play and no-cycling conditions},
	journal = {None},
	author = {Monderer, Dov and Sela, Aner},
	year = {1997},
	file = {Monderer and Sela - 1997 - Fictitious play and no-cycling conditions.pdf:/Users/oliverbiggar/Zotero/storage/N9IETFQV/Monderer and Sela - 1997 - Fictitious play and no-cycling conditions.pdf:application/pdf},
}

@inproceedings{brandt_rate_2010,
	address = {Berlin, Heidelberg},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {On the {Rate} of {Convergence} of {Fictitious} {Play}},
	isbn = {978-3-642-16170-4},
	doi = {10.1007/978-3-642-16170-4_10},
	abstract = {Fictitious play is a simple learning algorithm for strategic games that proceeds in rounds. In each round, the players play a best response to a mixed strategy that is given by the empirical frequencies of actions played in previous rounds. There is a close relationship between fictitious play and the Nash equilibria of a game: if the empirical frequencies of fictitious play converge to a strategy profile, this strategy profile is a Nash equilibrium. While fictitious play does not converge in general, it is known to do so for certain restricted classes of games, such as constant-sum games, non-degenerate 2×n games, and potential games. We study the rate of convergence of fictitious play and show that, in all the classes of games mentioned above, fictitious play may require an exponential number of rounds (in the size of the representation of the game) before some equilibrium action is eventually played. In particular, we show the above statement for symmetric constant-sum win-lose-tie games.},
	language = {en},
	booktitle = {Algorithmic {Game} {Theory}},
	publisher = {Springer},
	author = {Brandt, Felix and Fischer, Felix and Harrenstein, Paul},
	editor = {Kontogiannis, Spyros and Koutsoupias, Elias and Spirakis, Paul G.},
	year = {2010},
	keywords = {Potential Game, Nash Equilibrium, Exponential Number, Learning Sequence, Strategic Game},
	pages = {102--113},
	file = {Full Text PDF:/Users/oliverbiggar/Zotero/storage/VJ8F2PNP/Brandt et al. - 2010 - On the Rate of Convergence of Fictitious Play.pdf:application/pdf},
}

@article{foster_nonconvergence_1998,
	title = {On the {Nonconvergence} of {Fictitious} {Play} in {Coordination} {Games}},
	volume = {25},
	issn = {0899-8256},
	url = {https://www.sciencedirect.com/science/article/pii/S0899825697906266},
	doi = {10.1006/game.1997.0626},
	abstract = {It is shown by example that learning rules of the fictitious play type fail to converge in certain kinds of coordination games. Variants of fictitious play in which past actions are eventually forgotten and that incorporate small stochastic perturbations are better behaved for this class of games: over the long run, players coordinate with probability one.Journal of Economic LiteratureClassification Numbers: C70, C72.},
	number = {1},
	urldate = {2023-12-11},
	journal = {Games and Economic Behavior},
	author = {Foster, Dean P and Young, H. Peyton},
	month = oct,
	year = {1998},
	keywords = {fictitious play, coordination game, cycles, learning, Shapley example},
	pages = {79--96},
	file = {ScienceDirect Full Text PDF:/Users/oliverbiggar/Zotero/storage/PDF8FD8K/Foster and Young - 1998 - On the Nonconvergence of Fictitious Play in Coordi.pdf:application/pdf;ScienceDirect Snapshot:/Users/oliverbiggar/Zotero/storage/G2BM5NP2/S0899825697906266.html:text/html},
}

@article{milgrom_rationalizability_1990,
	title = {Rationalizability, {Learning}, and {Equilibrium} in {Games} with {Strategic} {Complementarities}},
	volume = {58},
	issn = {0012-9682},
	url = {https://www.jstor.org/stable/2938316},
	doi = {10.2307/2938316},
	abstract = {We study a rich class of noncooperative games that includes models of oligopoly competition, macroeconomic coordination failures, arms races, bank runs, technology adoption and diffusion, R\&D competition, pretrial bargaining, coordination in teams, and many others. For all these games, the sets of pure strategy Nash equilibria, correlated equilibria, and rationalizable strategies have identical bounds. Also, for a class of models of dynamic adaptive choice behavior that encompasses both best-response dynamics and Bayesian learning, the players' choices lie eventually within the same bounds. These bounds are shown to vary monotonically with certain exogenous parameters.},
	number = {6},
	urldate = {2023-12-19},
	journal = {Econometrica},
	author = {Milgrom, Paul and Roberts, John},
	year = {1990},
	note = {Publisher: [Wiley, Econometric Society]},
	pages = {1255--1277},
	file = {JSTOR Full Text PDF:/Users/oliverbiggar/Zotero/storage/QB6ZBZV6/Milgrom and Roberts - 1990 - Rationalizability, Learning, and Equilibrium in Ga.pdf:application/pdf},
}

@article{benaim_mixed_1999,
	title = {Mixed {Equilibria} and {Dynamical} {Systems} {Arising} from {Fictitious} {Play} in {Perturbed} {Games}},
	volume = {29},
	issn = {0899-8256},
	url = {https://www.sciencedirect.com/science/article/pii/S0899825699907170},
	doi = {10.1006/game.1999.0717},
	abstract = {Fictitious play in infinitely repeated, randomly perturbed games is investigated. Dynamical systems theory is used to study the Markov process \{xk\}, whose state vector xk lists the empirical frequencies of player's actions in the first k games. For 2×2 games with countably many Nash distribution equilibria, we prove that sample paths converge almost surely. But for Jordan's 3×2 matching game, there are robust parameter values giving probability 0 of convergence. Applications are made to coordination and anticoordination games and to general theory. Proofs rely on results in stochastic approximation and dynamical systems. Journal of Economic Literature Classification Numbers: C72, C73.},
	number = {1},
	urldate = {2024-01-02},
	journal = {Games and Economic Behavior},
	author = {Benaı̈m, Michel and Hirsch, Morris W},
	month = oct,
	year = {1999},
	pages = {36--72},
	file = {Benaı̈m and Hirsch - 1999 - Mixed Equilibria and Dynamical Systems Arising fro.pdf:/Users/oliverbiggar/Zotero/storage/CTYMPCFG/Benaı̈m and Hirsch - 1999 - Mixed Equilibria and Dynamical Systems Arising fro.pdf:application/pdf;ScienceDirect Snapshot:/Users/oliverbiggar/Zotero/storage/95BEKWRA/S0899825699907170.html:text/html},
}

@article{hofbauer_global_2002,
	title = {On the {Global} {Convergence} of {Stochastic} {Fictitious} {Play}},
	volume = {70},
	copyright = {The Econometric Society 2002},
	issn = {1468-0262},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1468-0262.2002.00440.x},
	doi = {10.1111/j.1468-0262.2002.00440.x},
	abstract = {We establish global convergence results for stochastic fictitious play for four classes of games: games with an interior ESS, zero sum games, potential games, and supermodular games. We do so by appealing to techniques from stochastic approximation theory, which relate the limit behavior of a stochastic process to the limit behavior of a differential equation defined by the expected motion of the process. The key result in our analysis of supermodular games is that the relevant differential equation defines a strongly monotone dynamical system. Our analyses of the other cases combine Lyapunov function arguments with a discrete choice theory result: that the choice probabilities generated by any additive random utility model can be derived from a deterministic model based on payoff perturbations that depend nonlinearly on the vector of choice probabilities.},
	language = {en},
	number = {6},
	urldate = {2024-01-02},
	journal = {Econometrica},
	author = {Hofbauer, Josef and Sandholm, William H.},
	year = {2002},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/j.1468-0262.2002.00440.x},
	keywords = {chain recurrence, discrete choice theory, learning in games, stochastic approximation theory, stochastic fictitious play, supermodular games},
	pages = {2265--2294},
	file = {Snapshot:/Users/oliverbiggar/Zotero/storage/WZQGH8JW/j.1468-0262.2002.00440.html:text/html;Submitted Version:/Users/oliverbiggar/Zotero/storage/4HTNV7PD/Hofbauer and Sandholm - 2002 - On the Global Convergence of Stochastic Fictitious.pdf:application/pdf},
}

@article{robinson_iterative_1951,
	title = {An {Iterative} {Method} of {Solving} a {Game}},
	volume = {54},
	issn = {0003-486X},
	url = {https://www.jstor.org/stable/1969530},
	doi = {10.2307/1969530},
	number = {2},
	urldate = {2024-03-01},
	journal = {Annals of Mathematics},
	author = {Robinson, Julia},
	year = {1951},
	note = {Publisher: Annals of Mathematics},
	pages = {296--301},
	file = {JSTOR Full Text PDF:/Users/oliverbiggar/Zotero/storage/PKC72F6C/Robinson - 1951 - An Iterative Method of Solving a Game.pdf:application/pdf},
}

@article{krishna_convergence_1998,
	title = {On the {Convergence} of {Fictitious} {Play}},
	volume = {23},
	issn = {0364-765X},
	url = {https://www.jstor.org/stable/3690523},
	abstract = {We study the Brown-Robinson fictitious play process for non-zero sum games. We show that, in general, fictitious play cannot converge cyclically to a mixed strategy equilibrium in which both players use more than two pure strategies.},
	number = {2},
	urldate = {2024-03-01},
	journal = {Mathematics of Operations Research},
	author = {Krishna, Vijay and Sjöström, Tomas},
	year = {1998},
	note = {Publisher: INFORMS},
	pages = {479--511},
	file = {JSTOR Full Text PDF:/Users/oliverbiggar/Zotero/storage/9G568HYL/Krishna and Sjöström - 1998 - On the Convergence of Fictitious Play.pdf:application/pdf},
}

@article{swenson_best-response_2018,
	title = {On {Best}-{Response} {Dynamics} in {Potential} {Games}},
	volume = {56},
	issn = {0363-0129},
	url = {https://epubs.siam.org/doi/abs/10.1137/17M1139461},
	doi = {10.1137/17M1139461},
	abstract = {We present a novel variant of fictitious play dynamics combining classical fictitious play with \$Q\$-learning for stochastic games and analyze its convergence properties in two-player zero-sum stochastic games. Our dynamics involves players forming beliefs on the opponent strategy and their own continuation payoff (\$Q\$-function), and playing a  greedy best response by using the estimated continuation payoffs. Players update their beliefs from observations of opponent actions. A key property of the learning dynamics is that update of the beliefs on \$Q\$-functions occurs at a slower timescale than update of the beliefs on strategies. We show that in both the model-based and model-free cases (without knowledge of player payoff functions and state transition probabilities), the beliefs on strategies converge to a stationary mixed Nash equilibrium of the zero-sum stochastic game.},
	number = {4},
	urldate = {2024-03-07},
	journal = {SIAM Journal on Control and Optimization},
	author = {Swenson, Brian and Murray, Ryan and Kar, Soummya},
	month = jan,
	year = {2018},
	note = {Publisher: Society for Industrial and Applied Mathematics},
	pages = {2734--2767},
	file = {Submitted Version:/Users/oliverbiggar/Zotero/storage/C4KMLUE4/Swenson et al. - 2018 - On Best-Response Dynamics in Potential Games.pdf:application/pdf},
}

@article{viossat_no-regret_2013,
	title = {No-regret dynamics and fictitious play},
	volume = {148},
	issn = {0022-0531},
	url = {https://www.sciencedirect.com/science/article/pii/S0022053113000112},
	doi = {10.1016/j.jet.2012.07.003},
	abstract = {Potential based no-regret dynamics are shown to be related to fictitious play. Roughly, these are ε-best reply dynamics where ε is the maximal regret, which vanishes with time. This allows for alternative and sometimes much shorter proofs of known results on convergence of no-regret dynamics to the set of Nash equilibria.},
	number = {2},
	urldate = {2024-03-07},
	journal = {Journal of Economic Theory},
	author = {Viossat, Yannick and Zapechelnyuk, Andriy},
	month = mar,
	year = {2013},
	keywords = {Nash equilibrium, Fictitious play, Best-reply dynamics, Curb set, Hannan set, No-regret strategy, Regret minimization},
	pages = {825--842},
	file = {ScienceDirect Snapshot:/Users/oliverbiggar/Zotero/storage/CKXXQIUV/S0022053113000112.html:text/html;Submitted Version:/Users/oliverbiggar/Zotero/storage/BG27KVS6/Viossat and Zapechelnyuk - 2013 - No-regret dynamics and fictitious play.pdf:application/pdf},
}

@article{benaim_learning_2009,
	title = {Learning in games with unstable equilibria},
	volume = {144},
	issn = {0022-0531},
	url = {https://www.sciencedirect.com/science/article/pii/S0022053108001324},
	doi = {10.1016/j.jet.2008.09.003},
	abstract = {We propose a new concept for the analysis of games, the TASP, which gives a precise prediction about non-equilibrium play in games whose Nash equilibria are mixed and are unstable under fictitious play-like learning. We show that, when players learn using weighted stochastic fictitious play and so place greater weight on recent experience, the time average of play often converges in these “unstable” games, even while mixed strategies and beliefs continue to cycle. This time average, the TASP, is related to the cycle identified by Shapley [L.S. Shapley, Some topics in two person games, in: M. Dresher, et al. (Eds.), Advances in Game Theory, Princeton University Press, Princeton, 1964]. The TASP can be close to or quite distinct from Nash equilibrium.},
	number = {4},
	urldate = {2024-03-07},
	journal = {Journal of Economic Theory},
	author = {Benaïm, Michel and Hofbauer, Josef and Hopkins, Ed},
	month = jul,
	year = {2009},
	keywords = {Best response dynamics, Games, Learning, Mixed strategy equilibria, Stochastic fictitious play, TASP},
	pages = {1694--1709},
	file = {Accepted Version:/Users/oliverbiggar/Zotero/storage/TEVMX235/Benaïm et al. - 2009 - Learning in games with unstable equilibria.pdf:application/pdf;ScienceDirect Snapshot:/Users/oliverbiggar/Zotero/storage/UWZKUNMV/S0022053108001324.html:text/html},
}

@article{sparrow_fictitious_2008,
	title = {Fictitious play in 3×3{\textless}math{\textgreater}{\textless}mn is="true"{\textgreater}3{\textless}/mn{\textgreater}{\textless}mo is="true"{\textgreater}×{\textless}/mo{\textgreater}{\textless}mn is="true"{\textgreater}3{\textless}/mn{\textgreater}{\textless}/math{\textgreater} games: {The} transition between periodic and chaotic behaviour},
	volume = {63},
	issn = {0899-8256},
	shorttitle = {Fictitious play in 3×3{\textless}math{\textgreater}{\textless}mn is="true"{\textgreater}3{\textless}/mn{\textgreater}{\textless}mo is="true"{\textgreater}×{\textless}/mo{\textgreater}{\textless}mn is="true"{\textgreater}3{\textless}/mn{\textgreater}{\textless}/math{\textgreater} games},
	url = {https://www.sciencedirect.com/science/article/pii/S089982560700142X},
	doi = {10.1016/j.geb.2007.08.005},
	abstract = {In the 1960s Shapley provided an example of a two-player fictitious game with periodic behaviour. In this game, player A aims to copy B's behaviour and player B aims to play one ahead of player A. In this paper we generalise Shapley's example by introducing an external parameter. We show that the periodic behaviour in Shapley's example at some critical parameter value disintegrates into unpredictable (chaotic) behaviour, with players dithering a huge number of times between different strategies. At a further critical parameter the dynamics becomes periodic again, but now both players aim to play one ahead of the other. In this paper we adopt a geometric (dynamical systems) approach. Here we prove rigorous results on continuity of the dynamics and on the periodic behaviour, while in the sequel to this paper we shall describe the chaotic behaviour.},
	number = {1},
	urldate = {2024-03-07},
	journal = {Games and Economic Behavior},
	author = {Sparrow, Colin and van Strien, Sebastian and Harris, Christopher},
	month = may,
	year = {2008},
	keywords = {Chaos, Learning process, Bifurcation, Fictitious pay},
	pages = {259--291},
	file = {ScienceDirect Snapshot:/Users/oliverbiggar/Zotero/storage/VYKLZLDM/S089982560700142X.html:text/html;Submitted Version:/Users/oliverbiggar/Zotero/storage/UJUPGJ9M/Sparrow et al. - 2008 - Fictitious play in 3×33m.pdf:application/pdf},
}

@article{shamma_unified_2004,
	title = {Unified convergence proofs of continuous-time fictitious play},
	volume = {49},
	issn = {1558-2523},
	url = {https://ieeexplore.ieee.org/abstract/document/1310468},
	doi = {10.1109/TAC.2004.831143},
	abstract = {We consider a continuous-time version of fictitious play (FP), in which interacting players evolve their strategies in reaction to their opponents' actions without knowledge of their opponents' utilities. It is known that FP need not converge, but that convergence is possible in certain special cases including zero-sum games, identical interest games, and two-player/two-move games. We provide a unified proof of convergence in all of these cases by showing that a Lyapunov function previously introduced for zero-sum games also can establish stability in the other special cases. We go on to consider a two-player game in which only one player has two-moves and use properties of planar dynamical systems to establish convergence.},
	number = {7},
	urldate = {2024-03-07},
	journal = {IEEE Transactions on Automatic Control},
	author = {Shamma, J.S. and Arslan, G.},
	month = jul,
	year = {2004},
	note = {Conference Name: IEEE Transactions on Automatic Control},
	keywords = {Nash equilibrium, Convergence, Adders, Frequency, Stability, Game theory, Lyapunov method, Military computing, Multi-stage noise shaping, Transmission line matrix methods},
	pages = {1137--1141},
	file = {IEEE Xplore Abstract Record:/Users/oliverbiggar/Zotero/storage/Z3GINJ4N/1310468.html:text/html;Submitted Version:/Users/oliverbiggar/Zotero/storage/V4TVPRAW/Shamma and Arslan - 2004 - Unified convergence proofs of continuous-time fict.pdf:application/pdf},
}

@inproceedings{krishna_learning_1997,
	address = {Berlin, Heidelberg},
	series = {{NATO} {ASI} {Series}},
	title = {Learning in {Games}: {Fictitious} {Play} {Dynamics}},
	isbn = {978-3-642-60454-6},
	shorttitle = {Learning in {Games}},
	doi = {10.1007/978-3-642-60454-6_17},
	abstract = {We present a selective survey of recent work on the Brown-Robinson learning process known as “fictitious play.” We study the continuous time version of the process and report convergence results for specific classes of games.},
	language = {en},
	booktitle = {Cooperation: {Game}-{Theoretic} {Approaches}},
	publisher = {Springer},
	author = {Krishna, Vijay and Sjöström, Tomas},
	editor = {Hart, Sergiu and Mas-Colell, Andreu},
	year = {1997},
	keywords = {fictitious play, dynamical systems, learning, Equilibrium},
	pages = {257--273},
}

@article{berger_non-algebraic_2012,
	title = {Non-algebraic {Convergence} {Proofs} for {Continuous}-{Time} {Fictitious} {Play}},
	volume = {2},
	issn = {2153-0793},
	url = {https://doi.org/10.1007/s13235-011-0033-4},
	doi = {10.1007/s13235-011-0033-4},
	abstract = {In this technical note we use insights from the theory of projective geometry to provide novel and non-algebraic proofs of convergence of continuous-time fictitious play for a class of games. As a corollary we obtain a kind of equilibrium selection result, whereby continuous-time fictitious play converges to a particular equilibrium contained in a continuum of equivalent equilibria for symmetric 4×4 zero-sum games.},
	language = {en},
	number = {1},
	urldate = {2024-03-07},
	journal = {Dynamic Games and Applications},
	author = {Berger, Ulrich},
	month = mar,
	year = {2012},
	keywords = {Best response dynamics, Learning, Continuous-time fictitious play, Projective geometry},
	pages = {4--17},
	file = {Accepted Version:/Users/oliverbiggar/Zotero/storage/U9AN9KZF/Berger - 2012 - Non-algebraic Convergence Proofs for Continuous-Ti.pdf:application/pdf},
}

@article{pettie_optimal_2002,
	title = {An optimal minimum spanning tree algorithm},
	volume = {49},
	issn = {0004-5411},
	url = {https://dl.acm.org/doi/10.1145/505241.505243},
	doi = {10.1145/505241.505243},
	abstract = {We establish that the algorithmic complexity of the minimum spanning tree problem is equal to its decision-tree complexity. Specifically, we present a deterministic algorithm to find a minimum spanning tree of a graph with n vertices and m edges that runs in time O(T*(m,n)) where T* is the minimum number of edge-weight comparisons needed to determine the solution. The algorithm is quite simple and can be implemented on a pointer machine.Although our time bound is optimal, the exact function describing it is not known at present. The current best bounds known for T* are T*(m,n) = Ω(m) and T*(m,n) = O(m ∙ $\alpha$(m,n)), where $\alpha$ is a certain natural inverse of Ackermann's function.Even under the assumption that T* is superlinear, we show that if the input graph is selected from Gn,m, our algorithm runs in linear time with high probability, regardless of n, m, or the permutation of edge weights. The analysis uses a new martingale for Gn,m similar to the edge-exposure martingale for Gn,p.},
	number = {1},
	urldate = {2024-03-19},
	journal = {Journal of the ACM},
	author = {Pettie, Seth and Ramachandran, Vijaya},
	month = jan,
	year = {2002},
	keywords = {Graph algorithms, minimum spanning tree, optimal complexity},
	pages = {16--34},
	file = {Full Text PDF:/Users/oliverbiggar/Zotero/storage/J4UX9WCG/Pettie and Ramachandran - 2002 - An optimal minimum spanning tree algorithm.pdf:application/pdf},
}

@article{pettie_new_2004,
	series = {Automata, {Languages} and {Programming}},
	title = {A new approach to all-pairs shortest paths on real-weighted graphs},
	volume = {312},
	issn = {0304-3975},
	url = {https://www.sciencedirect.com/science/article/pii/S030439750300402X},
	doi = {10.1016/S0304-3975(03)00402-X},
	abstract = {We present a new all-pairs shortest path algorithm that works with real-weighted graphs in the traditional comparison-addition model. It runs in O(mn+n2loglogn) time, improving on the long-standing bound of O(mn+n2logn) derived from an implementation of Dijkstra's algorithm with Fibonacci heaps. Here m and n are the number of edges and vertices, respectively. Our algorithm is rooted in the so-called component hierarchy approach to shortest paths invented by Thorup for integer-weighted undirected graphs, and generalized by Hagerup to integer-weighted directed graphs. The technical contributions of this paper include a method for approximating shortest path distances and a method for leveraging approximate distances in the computation of exact ones. We also provide a simple, one line characterization of the class of hierarchy-type shortest path algorithms. This characterization leads to some pessimistic lower bounds on computing single-source shortest paths with a hierarchy-type algorithm.},
	number = {1},
	urldate = {2024-03-19},
	journal = {Theoretical Computer Science},
	author = {Pettie, Seth},
	month = jan,
	year = {2004},
	keywords = {All-pairs shortest paths, Comparison-addition model, Real weights},
	pages = {47--74},
	file = {ScienceDirect Snapshot:/Users/oliverbiggar/Zotero/storage/R29WUWF4/S030439750300402X.html:text/html},
}

@article{pettie_shortest_2005,
	title = {A {Shortest} {Path} {Algorithm} for {Real}-{Weighted} {Undirected} {Graphs}},
	volume = {34},
	issn = {0097-5397},
	url = {https://epubs.siam.org/doi/abs/10.1137/S0097539702419650},
	doi = {10.1137/S0097539702419650},
	abstract = {Let \$G = (V,E)\$ be an undirected unweighted graph on \$n\$ vertices. A subgraph \$H\$ of \$G\$ is called a purely additive spanner of \$G\$ with stretch \${\textbackslash}beta\$ if for each \$(u,v) {\textbackslash}in V {\textbackslash}times V\$, the \$u\$-\$v\$ distance in \$H\$ is at most \${\textbackslash}delta\_G(u,v) + {\textbackslash}beta\$. We currently know sparse purely additive spanners with \${\textbackslash}beta = O(1)\$ only for \${\textbackslash}beta = 2,4,6\$. When \${\textbackslash}beta = 2\$, the size of the spanner is \$O(n{\textasciicircum}\{3/2\})\$; when \${\textbackslash}beta = 4\$, the size of the spanner is \$O(n{\textasciicircum}\{1.4\}{\textbackslash}log{\textasciicircum}\{0.2\}n)\$; and when \${\textbackslash}beta = 6\$, the size of the spanner is \$O(n{\textasciicircum}\{4/3\})\$. The following is a natural relaxation of the above problem: we care for only certain distances, these are captured by the set \${\textbackslash}mathcal\{P\} {\textbackslash}subseteq V {\textbackslash}times V\$, and the problem is to construct a sparse subgraph \$H\$ (also called a \${\textbackslash}mathcal\{P\}\$-spanner), where for every \$(u,v) {\textbackslash}in {\textbackslash}mathcal\{P\}\$, the \$u\$-\$v\$ distance in \$H\$ is at most \${\textbackslash}delta\_G(u,v) + {\textbackslash}beta\$. In this paper we show algorithms to construct the following for \${\textbackslash}beta = 2\$: a \${\textbackslash}mathcal\{P\}\$-spanner of size \${\textbackslash}tilde\{O\}(n{\textbar}{\textbackslash}mathcal\{P\}{\textbar}{\textasciicircum}\{1/3\})\$ for any \${\textbackslash}mathcal\{P\}{\textbackslash}subseteq V{\textbackslash}times V\$ and a \${\textbackslash}mathcal\{P\}\$-spanner of size \${\textbackslash}tilde\{O\}(n{\textbar}{\textbackslash}mathcal\{P\}{\textbar}{\textasciicircum}\{1/4\})\$ when \${\textbackslash}mathcal\{P\} = S {\textbackslash}times V\$, where \$S {\textbackslash}subseteq V\$. Our \${\textbackslash}mathcal\{P\}\$-spanner with additive stretch 2 leads to a simple deterministic construction of a purely additive spanner with stretch 4 and size \$O(n{\textasciicircum}\{1.4\}{\textbackslash}log{\textasciicircum}\{0.2\}n)\$. We also consider a variant of the \${\textbackslash}mathcal\{P\}\$-spanner problem where the set \${\textbackslash}mathcal\{P\}\$ is implicitly given via a distance threshold \$D\$. That is, \${\textbackslash}mathcal\{P\} = {\textbackslash}\{(u,v): {\textbackslash}delta\_G(u,v) {\textbackslash}ge D{\textbackslash}\}\$. We refer to such a \${\textbackslash}mathcal\{P\}\$-spanner as an approximate \$D\$-preserver. A \$D\$-preserver is a subgraph where distances \${\textbackslash}ge D\$ are exactly preserved and \$D\$-preservers of size \$O(n{\textasciicircum}2/D)\$ are known. For a given \$D {\textbackslash}in {\textbackslash}mathbb\{Z\}{\textasciicircum}+\$ and any integer \$k {\textbackslash}ge 1\$, we construct an \${\textbackslash}tilde\{O\}(n{\textasciicircum}\{3/2\}/D{\textasciicircum}\{k/(2k+2)\})\$-sized subgraph where distances \${\textbackslash}ge D\$ are approximated with an additive stretch of \$4k\$. In particular, when \$k = {\textbackslash}lfloor{\textbackslash}log D{\textbackslash}rfloor\$, this subgraph has size \${\textbackslash}tilde\{O\}(n{\textbackslash}cdot{\textbackslash}sqrt\{n/D\})\$.},
	number = {6},
	urldate = {2024-03-19},
	journal = {SIAM Journal on Computing},
	author = {Pettie, Seth and Ramachandran, Vijaya},
	month = jan,
	year = {2005},
	note = {Publisher: Society for Industrial and Applied Mathematics},
	pages = {1398--1431},
	file = {Submitted Version:/Users/oliverbiggar/Zotero/storage/9JUP8NI4/Pettie and Ramachandran - 2005 - A Shortest Path Algorithm for Real-Weighted Undire.pdf:application/pdf},
}

@article{alon_exponent_1997,
	title = {On the {Exponent} of the {All} {Pairs} {Shortest} {Path} {Problem}},
	volume = {54},
	issn = {0022-0000},
	url = {https://www.sciencedirect.com/science/article/pii/S002200009791388X},
	doi = {10.1006/jcss.1997.1388},
	abstract = {The upper bound on the exponent,ω, of matrix multiplication over a ring that was three in 1968 has decreased several times and since 1986 it has been 2.376. On the other hand, the exponent of the algorithms known for the all pairs shortest path problem has stayed at three all these years even for the very special case of directed graphs with uniform edge lengths. In this paper we give an algorithm of timeO(nνlog3n),ν=(3+ω)/2, for the case of edge lengths in \{−1, 0, 1\}. Thus, for the current known bound onω, we get a bound on the exponent,ν{\textless}2.688. In case of integer edge lengths with absolute value bounded above byM, the time bound isO((Mn)νlog3n) and the exponent is less than 3 forM=O(n$\alpha$), for$\alpha${\textless}0.116 and the current bound onω.},
	number = {2},
	urldate = {2024-03-19},
	journal = {Journal of Computer and System Sciences},
	author = {Alon, Noga and Galil, Zvi and Margalit, Oded},
	month = apr,
	year = {1997},
	pages = {255--262},
	file = {ScienceDirect Snapshot:/Users/oliverbiggar/Zotero/storage/92AZ5M7J/S002200009791388X.html:text/html},
}

@article{pettie_single-source_nodate,
	title = {Single-{Source} {Shortest} {Paths}},
	language = {en},
	author = {Pettie, Seth},
	file = {Pettie - Single-Source Shortest Paths.pdf:/Users/oliverbiggar/Zotero/storage/8WPRZ67W/Pettie - Single-Source Shortest Paths.pdf:application/pdf},
}

@misc{noauthor_undirected_nodate,
	title = {Undirected single-source shortest paths with positive integer weights in linear time {\textbar} {Journal} of the {ACM}},
	url = {https://dl.acm.org/doi/abs/10.1145/316542.316548},
	urldate = {2024-03-19},
	file = {Undirected single-source shortest paths with positive integer weights in linear time | Journal of the ACM:/Users/oliverbiggar/Zotero/storage/E4AKKP52/316542.html:text/html},
}

@article{thorup_undirected_1999,
	title = {Undirected single-source shortest paths with positive integer weights in linear time},
	volume = {46},
	issn = {0004-5411},
	url = {https://dl.acm.org/doi/10.1145/316542.316548},
	doi = {10.1145/316542.316548},
	abstract = {The single-source shortest paths problem (SSSP) is one of the classic problems in algorithmic graph theory: given a positively weighted graph G with a source vertex s, find the shortest path from s to all other vertices in the graph. Since 1959, all theoretical developments in SSSP for general directed and undirected graphs have been based on Dijkstra's algorithm, visiting the vertices in order of increasing distance from s. Thus, any implementation of Dijkstra's algorithm sorts the vertices according to their distances from s. However, we do not know how to sort in linear time. Here, a deterministic linear time and linear space algorithm is presented for the undirected single source shortest paths problem with positive integer weights. The algorithm avoids the sorting bottleneck by building a hierarchical bucketing structure, identifying vertex pairs that may be visited in any order.},
	number = {3},
	urldate = {2024-03-19},
	journal = {Journal of the ACM},
	author = {Thorup, Mikkel},
	month = may,
	year = {1999},
	keywords = {RAM algorithms, shortest paths},
	pages = {362--394},
	file = {Full Text PDF:/Users/oliverbiggar/Zotero/storage/ZECBSVVS/Thorup - 1999 - Undirected single-source shortest paths with posit.pdf:application/pdf},
}

@article{berger_non-algebraic_2012-1,
	title = {Non-algebraic {Convergence} {Proofs} for {Continuous}-{Time} {Fictitious} {Play}},
	volume = {2},
	issn = {2153-0793},
	url = {https://doi.org/10.1007/s13235-011-0033-4},
	doi = {10.1007/s13235-011-0033-4},
	abstract = {In this technical note we use insights from the theory of projective geometry to provide novel and non-algebraic proofs of convergence of continuous-time fictitious play for a class of games. As a corollary we obtain a kind of equilibrium selection result, whereby continuous-time fictitious play converges to a particular equilibrium contained in a continuum of equivalent equilibria for symmetric 4×4 zero-sum games.},
	language = {en},
	number = {1},
	urldate = {2024-03-19},
	journal = {Dynamic Games and Applications},
	author = {Berger, Ulrich},
	month = mar,
	year = {2012},
	keywords = {Best response dynamics, Learning, Continuous-time fictitious play, Projective geometry},
	pages = {4--17},
	file = {Accepted Version:/Users/oliverbiggar/Zotero/storage/RWXNLZ5D/Berger - 2012 - Non-algebraic Convergence Proofs for Continuous-Ti.pdf:application/pdf},
}

@misc{chen_convergence_2022,
	title = {On the {Convergence} of {Fictitious} {Play}: {A} {Decomposition} {Approach}},
	shorttitle = {On the {Convergence} of {Fictitious} {Play}},
	url = {http://arxiv.org/abs/2205.01469},
	doi = {10.48550/arXiv.2205.01469},
	abstract = {Fictitious play (FP) is one of the most fundamental game-theoretical learning frameworks for computing Nash equilibrium in \$n\$-player games, which builds the foundation for modern multi-agent learning algorithms. Although FP has provable convergence guarantees on zero-sum games and potential games, many real-world problems are often a mixture of both and the convergence property of FP has not been fully studied yet. In this paper, we extend the convergence results of FP to the combinations of such games and beyond. Specifically, we derive new conditions for FP to converge by leveraging game decomposition techniques. We further develop a linear relationship unifying cooperation and competition in the sense that these two classes of games are mutually transferable. Finally, we analyze a non-convergent example of FP, the Shapley game, and develop sufficient conditions for FP to converge.},
	urldate = {2024-03-19},
	publisher = {arXiv},
	author = {Chen, Yurong and Deng, Xiaotie and Li, Chenchen and Mguni, David and Wang, Jun and Yan, Xiang and Yang, Yaodong},
	month = may,
	year = {2022},
	note = {arXiv:2205.01469 [cs]},
	keywords = {Computer Science - Computer Science and Game Theory, Computer Science - Multiagent Systems, Computer Science - Artificial Intelligence, Computer Science - Machine Learning},
	file = {arXiv Fulltext PDF:/Users/oliverbiggar/Zotero/storage/XNKXZ6DA/Chen et al. - 2022 - On the Convergence of Fictitious Play A Decomposi.pdf:application/pdf;arXiv.org Snapshot:/Users/oliverbiggar/Zotero/storage/DFR9C6EL/2205.html:text/html},
}

@misc{wellman_empirical_2024,
	title = {Empirical {Game}-{Theoretic} {Analysis}: {A} {Survey}},
	shorttitle = {Empirical {Game}-{Theoretic} {Analysis}},
	url = {http://arxiv.org/abs/2403.04018},
	doi = {10.48550/arXiv.2403.04018},
	abstract = {In the empirical approach to game-theoretic analysis (EGTA), the model of the game comes not from declarative representation, but is derived by interrogation of a procedural description of the game environment. The motivation for developing this approach was to enable game-theoretic reasoning about strategic situations too complex for analytic specification and solution. Since its introduction over twenty years ago, EGTA has been applied to a wide range of multiagent domains, from auctions and markets to recreational games to cyber-security. We survey the extensive methodology developed for EGTA over the years, organized by the elemental subproblems comprising the EGTA process. We describe key EGTA concepts and techniques, and the questions at the frontier of EGTA research. Recent advances in machine learning have accelerated progress in EGTA, and promise to significantly expand our capacities for reasoning about complex game situations.},
	urldate = {2024-03-19},
	publisher = {arXiv},
	author = {Wellman, Michael P. and Tuyls, Karl and Greenwald, Amy},
	month = mar,
	year = {2024},
	note = {arXiv:2403.04018 [cs]},
	keywords = {Computer Science - Computer Science and Game Theory},
	file = {arXiv Fulltext PDF:/Users/oliverbiggar/Zotero/storage/Y849XGPP/Wellman et al. - 2024 - Empirical Game-Theoretic Analysis A Survey.pdf:application/pdf;arXiv.org Snapshot:/Users/oliverbiggar/Zotero/storage/ITW7N53L/2403.html:text/html},
}
@book{luce1959individual,
  title={Individual choice behavior},
  author={Luce, R Duncan},
  volume={4},
  year={1959},
  publisher={Wiley New York}
}

@article{mertikopoulos2016learning,
  title={Learning in games via reinforcement and regularization},
  author={Mertikopoulos, Panayotis and Sandholm, William H},
  journal={Mathematics of Operations Research},
  volume={41},
  number={4},
  pages={1297--1324},
  year={2016},
  publisher={INFORMS}
}

@article{takahashi2002pure,
  title={The pure Nash equilibrium property and the quasi-acyclic condition},
  author={Takahashi, Satoru and Yamamori, Tetsuo},
  journal={Economics bulletin},
  volume={3},
  number={22},
  pages={1--6},
  year={2002}
}

@misc{khan_two-person_2024,
	title = {Two-{Person} adversarial games are zero-sum: {A} resolution of the {Luce}-{Raiffa}-{Aumann} ({LRA}) conjecture},
	shorttitle = {Two-{Person} adversarial games are zero-sum},
	url = {http://arxiv.org/abs/2403.04029},
	doi = {10.48550/arXiv.2403.04029},
	abstract = {This letter: (i) reformulates the theorems of Adler-Daskalakis-Papadimitriou (2009) and Raimondo (2023) on two-player adversarial games as a generalized result with a simplified proof, (ii) forges connections to work on strategically zero-sum games by Moulin-Vial (1978), and on axiomatizations of multi-linear utilities of n-person games by Fishburn-Roberts (1976, 1978). The simplification and the connections on offer give prominence to two-person zero-sum games studied by Aumann (1961), Shapley (1964) and Rosenthal (1974), and also to recent algorithmic work in computer science. We give a productive reorientation to the subject by bringing the two communities together under the rubric of adversarial games.},
	urldate = {2024-03-19},
	publisher = {arXiv},
	author = {Khan, M. Ali and Pedersen, Arthur Paul and Schrittesser, David},
	month = mar,
	year = {2024},
	note = {arXiv:2403.04029 [econ]},
	keywords = {Economics - Theoretical Economics, 91A05, 91A10, 91A30},
	file = {arXiv Fulltext PDF:/Users/oliverbiggar/Zotero/storage/GT2A55UK/Khan et al. - 2024 - Two-Person adversarial games are zero-sum A resol.pdf:application/pdf;arXiv.org Snapshot:/Users/oliverbiggar/Zotero/storage/EBRVCYET/2403.html:text/html},
}

@article{harris_rate_1998,
	title = {On the {Rate} of {Convergence} of {Continuous}-{Time} {Fictitious} {Play}},
	volume = {22},
	issn = {0899-8256},
	url = {https://www.sciencedirect.com/science/article/pii/S0899825697905820},
	doi = {10.1006/game.1997.0582},
	abstract = {This paper shows, first, that continuous-time fictitious play converges (in both payoff and strategy terms) uniformly at ratet−1in any finite two-person zero-sum game. The proof is, in essence, a simple Lyapunov-function argument. The convergence of discrete-time fictitious play is a straightforward corollary of this result. The paper also shows that continuous-time fictitious play converges in all finite weighted-potential games. In this case, the convergence is not uniform. It is conjectured, however, that any given continuous-time fictitious play of a finite weighted-potential game converges (in both payoff and strategy terms) at ratet−1.Journal of Economic LiteratureClassification Numbers: C6, C7.},
	number = {2},
	urldate = {2024-03-20},
	journal = {Games and Economic Behavior},
	author = {Harris, Christopher},
	month = feb,
	year = {1998},
	pages = {238--259},
	file = {Harris - 1998 - On the Rate of Convergence of Continuous-Time Fict.pdf:/Users/oliverbiggar/Zotero/storage/FEW4FA2Z/Harris - 1998 - On the Rate of Convergence of Continuous-Time Fict.pdf:application/pdf;ScienceDirect Snapshot:/Users/oliverbiggar/Zotero/storage/QKNSMVKB/S0899825697905820.html:text/html},
}

@article{jordan_three_1993,
	title = {Three {Problems} in {Learning} {Mixed}-{Strategy} {Nash} {Equilibria}},
	volume = {5},
	issn = {0899-8256},
	url = {https://www.sciencedirect.com/science/article/pii/S0899825683710225},
	doi = {10.1006/game.1993.1022},
	abstract = {This paper discusses three problems that can prevent the convergence of learning mechanisms to mixed-strategy Nash equilibria. First, while players′ expectations may converge to a mixed equilibrium, the strategies played typically fail to converge. Second, even in 2 × 2 games, fictitious play can produce a sequence of frequency distributions in which the marginal frequencies converge to equilibrium mixed strategies but the joint frequencies violate independence. Third, in a three-player matching-pennies game with a unique equilibrium, it is shown that if players learn as Bayesian statisticians then the equilibrium is locally unstable. Journal of Economic Literature Classification Numbers: C72, C73, D83.},
	number = {3},
	urldate = {2024-04-02},
	journal = {Games and Economic Behavior},
	author = {Jordan, J. S.},
	month = jul,
	year = {1993},
	pages = {368--386},
	file = {Jordan - 1993 - Three Problems in Learning Mixed-Strategy Nash Equ.pdf:/Users/oliverbiggar/Zotero/storage/2HR34PE5/Jordan - 1993 - Three Problems in Learning Mixed-Strategy Nash Equ.pdf:application/pdf;ScienceDirect Snapshot:/Users/oliverbiggar/Zotero/storage/B5GRQ5HL/S0899825683710225.html:text/html},
}

@article{sanders_prevalence_2018,
	title = {The prevalence of chaotic dynamics in games with many players},
	volume = {8},
	copyright = {2018 The Author(s)},
	issn = {2045-2322},
	url = {https://www.nature.com/articles/s41598-018-22013-5},
	doi = {10.1038/s41598-018-22013-5},
	abstract = {We study adaptive learning in a typical p-player game. The payoffs of the games are randomly generated and then held fixed. The strategies of the players evolve through time as the players learn. The trajectories in the strategy space display a range of qualitatively different behaviours, with attractors that include unique fixed points, multiple fixed points, limit cycles and chaos. In the limit where the game is complicated, in the sense that the players can take many possible actions, we use a generating-functional approach to establish the parameter range in which learning dynamics converge to a stable fixed point. The size of this region goes to zero as the number of players goes to infinity, suggesting that complex non-equilibrium behaviour, exemplified by chaos, is the norm for complicated games with many players.},
	language = {en},
	number = {1},
	urldate = {2024-04-02},
	journal = {Scientific Reports},
	author = {Sanders, James B. T. and Farmer, J. Doyne and Galla, Tobias},
	month = mar,
	year = {2018},
	note = {Publisher: Nature Publishing Group},
	keywords = {Applied mathematics, Nonlinear phenomena, Statistical physics},
	pages = {4902},
	file = {Full Text PDF:/Users/oliverbiggar/Zotero/storage/ZPMTA2YJ/Sanders et al. - 2018 - The prevalence of chaotic dynamics in games with m.pdf:application/pdf},
}

@article{amiet_pure_2021-1,
	title = {Pure {Nash} {Equilibria} and {Best}-{Response} {Dynamics} in {Random} {Games}},
	volume = {46},
	issn = {0364-765X},
	url = {https://pubsonline.informs.org/doi/abs/10.1287/moor.2020.1102},
	doi = {10.1287/moor.2020.1102},
	abstract = {In finite games, mixed Nash equilibria always exist, but pure equilibria may fail to exist. To assess the relevance of this nonexistence, we consider games where the payoffs are drawn at random. In particular, we focus on games where a large number of players can each choose one of two possible strategies and the payoffs are independent and identically distributed with the possibility of ties. We provide asymptotic results about the random number of pure Nash equilibria, such as fast growth and a central limit theorem, with bounds for the approximation error. Moreover, by using a new link between percolation models and game theory, we describe in detail the geometry of pure Nash equilibria and show that, when the probability of ties is small, a best-response dynamics reaches a pure Nash equilibrium with a probability that quickly approaches one as the number of players grows. We show that various phase transitions depend only on a single parameter of the model, that is, the probability of having ties.},
	number = {4},
	urldate = {2024-04-02},
	journal = {Mathematics of Operations Research},
	author = {Amiet, Ben and Collevecchio, Andrea and Scarsini, Marco and Zhong, Ziwen},
	month = nov,
	year = {2021},
	note = {Publisher: INFORMS},
	keywords = {best response dynamics, percolation, Primary: 91A10, Primary: Games/group decisions: noncooperative; secondary: probability: Markov processes, pure Nash equilibrium, random game, secondary: 91A06, 60K35},
	pages = {1552--1572},
	file = {Submitted Version:/Users/oliverbiggar/Zotero/storage/ABQRXN2P/Amiet et al. - 2021 - Pure Nash Equilibria and Best-Response Dynamics in.pdf:application/pdf},
}

@article{heinrich_best-response_2023,
	title = {Best-response dynamics, playing sequences, and convergence to equilibrium in random games},
	volume = {52},
	issn = {1432-1270},
	url = {https://doi.org/10.1007/s00182-023-00837-4},
	doi = {10.1007/s00182-023-00837-4},
	abstract = {We analyze the performance of the best-response dynamic across all normal-form games using a random games approach. The playing sequence—the order in which players update their actions—is essentially irrelevant in determining whether the dynamic converges to a Nash equilibrium in certain classes of games (e.g. in potential games) but, when evaluated across all possible games, convergence to equilibrium depends on the playing sequence in an extreme way. Our main asymptotic result shows that the best-response dynamic converges to a pure Nash equilibrium in a vanishingly small fraction of all (large) games when players take turns according to a fixed cyclic order. By contrast, when the playing sequence is random, the dynamic converges to a pure Nash equilibrium if one exists in almost all (large) games.},
	language = {en},
	number = {3},
	urldate = {2024-04-02},
	journal = {International Journal of Game Theory},
	author = {Heinrich, Torsten and Jang, Yoojin and Mungo, Luca and Pangallo, Marco and Scott, Alex and Tarbush, Bassel and Wiese, Samuel},
	month = sep,
	year = {2023},
	keywords = {C72, Best-response dynamics, Random games, C62, C73, D83, Equilibrium convergence},
	pages = {703--735},
	file = {Full Text PDF:/Users/oliverbiggar/Zotero/storage/P5MRPSRJ/Heinrich et al. - 2023 - Best-response dynamics, playing sequences, and con.pdf:application/pdf},
}

@article{bielawski_memory_2024,
	title = {Memory loss can prevent chaos in games dynamics},
	volume = {34},
	issn = {1054-1500},
	url = {https://doi.org/10.1063/5.0184318},
	doi = {10.1063/5.0184318},
	abstract = {Recent studies have raised concerns on the inevitability of chaos in congestion games with large learning rates. We further investigate this phenomenon by exploring the learning dynamics in simple two-resource congestion games, where a continuum of agents learns according to a simplified experience-weighted attraction algorithm. The model is characterized by three key parameters: a population intensity of choice (learning rate), a discount factor (recency bias or exploration parameter), and the cost function asymmetry. The intensity of choice captures agents’ economic rationality in their tendency to approximately best respond to the other agent’s behavior. The discount factor captures a type of memory loss of agents, where past outcomes matter exponentially less than the recent ones. Our main findings reveal that while increasing the intensity of choice destabilizes the system for any discount factor, whether the resulting dynamics remains predictable or becomes unpredictable and chaotic depends on both the memory loss and the cost asymmetry. As memory loss increases, the chaotic regime gives place to a periodic orbit of period 2 that is globally attracting except for a countable set of points that lead to the equilibrium. Therefore, memory loss can suppress chaotic behaviors. The results highlight the crucial role of memory loss in mitigating chaos and promoting predictable outcomes in congestion games, providing insights into designing control strategies in resource allocation systems susceptible to chaotic behaviors.},
	number = {1},
	urldate = {2024-04-02},
	journal = {Chaos: An Interdisciplinary Journal of Nonlinear Science},
	author = {Bielawski, Jakub and Chotibut, Thiparat and Falniowski, Fryderyk and Misiurewicz, Michał and Piliouras, Georgios},
	month = jan,
	year = {2024},
	pages = {013146},
	file = {Snapshot:/Users/oliverbiggar/Zotero/storage/5BGVUEWV/Memory-loss-can-prevent-chaos-in-games-dynamics.html:text/html},
}

@misc{hussain_asymptotic_2023,
	title = {Asymptotic {Convergence} and {Performance} of {Multi}-{Agent} {Q}-{Learning} {Dynamics}},
	url = {http://arxiv.org/abs/2301.09619},
	doi = {10.48550/arXiv.2301.09619},
	abstract = {Achieving convergence of multiple learning agents in general \$N\$-player games is imperative for the development of safe and reliable machine learning (ML) algorithms and their application to autonomous systems. Yet it is known that, outside the bounds of simple two-player games, convergence cannot be taken for granted. To make progress in resolving this problem, we study the dynamics of smooth Q-Learning, a popular reinforcement learning algorithm which quantifies the tendency for learning agents to explore their state space or exploit their payoffs. We show a sufficient condition on the rate of exploration such that the Q-Learning dynamics is guaranteed to converge to a unique equilibrium in any game. We connect this result to games for which Q-Learning is known to converge with arbitrary exploration rates, including weighted Potential games and weighted zero sum polymatrix games. Finally, we examine the performance of the Q-Learning dynamic as measured by the Time Averaged Social Welfare, and comparing this with the Social Welfare achieved by the equilibrium. We provide a sufficient condition whereby the Q-Learning dynamic will outperform the equilibrium even if the dynamics do not converge.},
	urldate = {2024-04-02},
	publisher = {arXiv},
	author = {Hussain, Aamal Abbas and Belardinelli, Francesco and Piliouras, Georgios},
	month = jan,
	year = {2023},
	note = {arXiv:2301.09619 [cs, math]},
	keywords = {Computer Science - Computer Science and Game Theory, Computer Science - Multiagent Systems, Computer Science - Artificial Intelligence, Mathematics - Dynamical Systems, 93A16, 91A26, 91A68, 58K35, F.2.2, G.3, J.4},
	file = {arXiv Fulltext PDF:/Users/oliverbiggar/Zotero/storage/V6S8Z2E5/Hussain et al. - 2023 - Asymptotic Convergence and Performance of Multi-Ag.pdf:application/pdf;arXiv.org Snapshot:/Users/oliverbiggar/Zotero/storage/U3HS4R2M/2301.html:text/html},
}

@article{wiese_frequency_2022-1,
	title = {The {Frequency} of {Convergent} {Games} under {Best}-{Response} {Dynamics}},
	volume = {12},
	issn = {2153-0793},
	url = {https://doi.org/10.1007/s13235-021-00401-3},
	doi = {10.1007/s13235-021-00401-3},
	abstract = {We calculate the frequency of games with a unique pure strategy Nash equilibrium in the ensemble of n-player, m-strategy normal-form games. To obtain the ensemble, we generate payoff matrices at random. Games with a unique pure strategy Nash equilibrium converge to the Nash equilibrium. We then consider a wider class of games that converge under a best-response dynamic, in which each player chooses their optimal pure strategy successively. We show that the frequency of convergent games with a given number of pure Nash equilibria goes to zero as the number of players or the number of strategies goes to infinity. In the 2-player case, we show that for large games with at least 10 strategies, convergent games with multiple pure strategy Nash equilibria are more likely than games with a unique Nash equilibrium. Our novel approach uses an n-partite graph to describe games.},
	language = {en},
	number = {2},
	urldate = {2024-04-02},
	journal = {Dynamic Games and Applications},
	author = {Wiese, Samuel C. and Heinrich, Torsten},
	month = jun,
	year = {2022},
	keywords = {91A06, 91A10, Best-response dynamics, Pure Nash equilibrium, Random games},
	pages = {689--700},
	file = {Full Text PDF:/Users/oliverbiggar/Zotero/storage/HH2ZAKFB/Wiese and Heinrich - 2022 - The Frequency of Convergent Games under Best-Respo.pdf:application/pdf},
}

@misc{yongacoglu_paths_2024,
	title = {Paths to {Equilibrium} in {Normal}-{Form} {Games}},
	url = {http://arxiv.org/abs/2403.18079},
	doi = {10.48550/arXiv.2403.18079},
	abstract = {In multi-agent reinforcement learning (MARL), agents repeatedly interact across time and revise their strategies as new data arrives, producing a sequence of strategy profiles. This paper studies sequences of strategies satisfying a pairwise constraint inspired by policy updating in reinforcement learning, where an agent who is best responding in period \$t\$ does not switch its strategy in the next period \$t+1\$. This constraint merely requires that optimizing agents do not switch strategies, but does not constrain the other non-optimizing agents in any way, and thus allows for exploration. Sequences with this property are called satisficing paths, and arise naturally in many MARL algorithms. A fundamental question about strategic dynamics is such: for a given game and initial strategy profile, is it always possible to construct a satisficing path that terminates at an equilibrium strategy? The resolution of this question has implications about the capabilities or limitations of a class of MARL algorithms. We answer this question in the affirmative for mixed extensions of finite normal-form games.\%},
	urldate = {2024-04-02},
	publisher = {arXiv},
	author = {Yongacoglu, Bora and Arslan, Gürdal and Pavel, Lacra and Yüksel, Serdar},
	month = mar,
	year = {2024},
	note = {arXiv:2403.18079 [cs]},
	keywords = {Computer Science - Computer Science and Game Theory, Computer Science - Artificial Intelligence, Computer Science - Machine Learning},
	file = {arXiv Fulltext PDF:/Users/oliverbiggar/Zotero/storage/CU58KI8S/Yongacoglu et al. - 2024 - Paths to Equilibrium in Normal-Form Games.pdf:application/pdf;arXiv.org Snapshot:/Users/oliverbiggar/Zotero/storage/TB74EQLW/2403.html:text/html},
}

@misc{hussain_stability_2024,
	title = {On the {Stability} of {Learning} in {Network} {Games} with {Many} {Players}},
	url = {http://arxiv.org/abs/2403.15848},
	doi = {10.48550/arXiv.2403.15848},
	abstract = {Multi-agent learning algorithms have been shown to display complex, unstable behaviours in a wide array of games. In fact, previous works indicate that convergent behaviours are less likely to occur as the total number of agents increases. This seemingly prohibits convergence to stable strategies, such as Nash Equilibria, in games with many players. To make progress towards addressing this challenge we study the Q-Learning Dynamics, a classical model for exploration and exploitation in multi-agent learning. In particular, we study the behaviour of Q-Learning on games where interactions between agents are constrained by a network. We determine a number of sufficient conditions, depending on the game and network structure, which guarantee that agent strategies converge to a unique stable strategy, called the Quantal Response Equilibrium (QRE). Crucially, these sufficient conditions are independent of the total number of agents, allowing for provable convergence in arbitrarily large games. Next, we compare the learned QRE to the underlying NE of the game, by showing that any QRE is an \${\textbackslash}epsilon\$-approximate Nash Equilibrium. We first provide tight bounds on \${\textbackslash}epsilon\$ and show how these bounds lead naturally to a centralised scheme for choosing exploration rates, which enables independent learners to learn stable approximate Nash Equilibrium strategies. We validate the method through experiments and demonstrate its effectiveness even in the presence of numerous agents and actions. Through these results, we show that independent learning dynamics may converge to approximate Nash Equilibria, even in the presence of many agents.},
	urldate = {2024-04-03},
	publisher = {arXiv},
	author = {Hussain, Aamal and Leonte, Dan and Belardinelli, Francesco and Piliouras, Georgios},
	month = mar,
	year = {2024},
	note = {arXiv:2403.15848 [cs]},
	keywords = {Computer Science - Computer Science and Game Theory, 93A16, 91A26, 91A68, 58K35, F.2.2, G.3, J.4},
	file = {arXiv Fulltext PDF:/Users/oliverbiggar/Zotero/storage/AS9NFY8I/Hussain et al. - 2024 - On the Stability of Learning in Network Games with.pdf:application/pdf;arXiv.org Snapshot:/Users/oliverbiggar/Zotero/storage/5NKCM3FK/2403.html:text/html},
}

@article{sanders_prevalence_2018-1,
	title = {The prevalence of chaotic dynamics in games with many players},
	volume = {8},
	copyright = {2018 The Author(s)},
	issn = {2045-2322},
	url = {https://www.nature.com/articles/s41598-018-22013-5},
	doi = {10.1038/s41598-018-22013-5},
	abstract = {We study adaptive learning in a typical p-player game. The payoffs of the games are randomly generated and then held fixed. The strategies of the players evolve through time as the players learn. The trajectories in the strategy space display a range of qualitatively different behaviours, with attractors that include unique fixed points, multiple fixed points, limit cycles and chaos. In the limit where the game is complicated, in the sense that the players can take many possible actions, we use a generating-functional approach to establish the parameter range in which learning dynamics converge to a stable fixed point. The size of this region goes to zero as the number of players goes to infinity, suggesting that complex non-equilibrium behaviour, exemplified by chaos, is the norm for complicated games with many players.},
	language = {en},
	number = {1},
	urldate = {2024-04-04},
	journal = {Scientific Reports},
	author = {Sanders, James B. T. and Farmer, J. Doyne and Galla, Tobias},
	month = mar,
	year = {2018},
	note = {Publisher: Nature Publishing Group},
	keywords = {Applied mathematics, Nonlinear phenomena, Statistical physics},
	pages = {4902},
	file = {Full Text PDF:/Users/oliverbiggar/Zotero/storage/YM9GSPBC/Sanders et al. - 2018 - The prevalence of chaotic dynamics in games with m.pdf:application/pdf},
}

@article{galla_cycles_2011,
	title = {Cycles of cooperation and defection in imperfect learning},
	volume = {2011},
	issn = {1742-5468},
	url = {https://dx.doi.org/10.1088/1742-5468/2011/08/P08007},
	doi = {10.1088/1742-5468/2011/08/P08007},
	abstract = {We investigate a model of learning the iterated prisoner’s dilemma game. Players have the choice between three strategies: always defect (ALLD), always cooperate (ALLC) and tit-for-tat (TFT). The only strict Nash equilibrium in this situation is ALLD. When players learn to play this game convergence to the equilibrium is not guaranteed, for example we find cooperative behaviour if players discount observations in the distant past. When agents use small samples of observed moves to estimate their opponent’s strategy the learning process is stochastic, and sustained oscillations between cooperation and defection can emerge. These cycles are similar to those found in stochastic evolutionary processes, but the origin of the noise sustaining the oscillations is different and lies in the imperfect sampling of the opponent’s strategy. Based on a systematic expansion technique, we are able to predict the properties of these learning cycles, providing an analytical tool with which the outcome of more general stochastic adaptation processes can be characterised.},
	language = {en},
	number = {08},
	urldate = {2024-04-04},
	journal = {Journal of Statistical Mechanics: Theory and Experiment},
	author = {Galla, Tobias},
	month = aug,
	year = {2011},
	pages = {P08007},
	file = {Submitted Version:/Users/oliverbiggar/Zotero/storage/GTV3TFUJ/Galla - 2011 - Cycles of cooperation and defection in imperfect l.pdf:application/pdf},
}

@article{sorin2024no,
  title={No-regret algorithms in on-line learning, games and convex optimization},
  author={Sorin, Sylvain},
  journal={Mathematical Programming},
  volume={203},
  number={1},
  pages={645--686},
  year={2024},
  publisher={Springer}
}
@article{hofbauer2011survival,
  title={Survival of dominated strategies under evolutionary dynamics},
  author={Hofbauer, Josef and Sandholm, William H},
  journal={Theoretical Economics},
  volume={6},
  number={3},
  pages={341--377},
  year={2011},
  publisher={Wiley Online Library}
}

@article{papadimitriou2008computing,
  title={Computing correlated equilibria in multi-player games},
  author={Papadimitriou, Christos H and Roughgarden, Tim},
  journal={Journal of the ACM (JACM)},
  volume={55},
  number={3},
  pages={1--29},
  year={2008},
  publisher={ACM New York, NY, USA}
}

@article{pangallo_towards_2022,
	title = {Towards a taxonomy of learning dynamics in 2 × 2 games},
	volume = {132},
	issn = {0899-8256},
	url = {https://www.sciencedirect.com/science/article/pii/S0899825621001615},
	doi = {10.1016/j.geb.2021.11.015},
	abstract = {Do boundedly rational players learn to choose equilibrium strategies as they play a game repeatedly? A large literature in behavioral game theory has proposed and experimentally tested various learning algorithms, but a comparative analysis of their equilibrium convergence properties is lacking. In this paper we analyze Experience-Weighted Attraction (EWA), which generalizes fictitious play, best-response dynamics, reinforcement learning and also replicator dynamics. Studying 2×2 games for tractability, we recover some well-known results in the limiting cases in which EWA reduces to the learning rules that it generalizes, but also obtain new results for other parameterizations. For example, we show that in coordination games EWA may only converge to the Pareto-efficient equilibrium, never reaching the Pareto-inefficient one; that in Prisoner Dilemma games it may converge to fixed points of mutual cooperation; and that limit cycles or chaotic dynamics may be more likely with longer or shorter memory of previous play.},
	urldate = {2024-04-04},
	journal = {Games and Economic Behavior},
	author = {Pangallo, Marco and Sanders, James B. T. and Galla, Tobias and Farmer, J. Doyne},
	month = mar,
	year = {2022},
	keywords = {Convergence, Chaos, Equilibrium, Behavioural game theory, EWA learning},
	pages = {1--21},
	file = {ScienceDirect Snapshot:/Users/oliverbiggar/Zotero/storage/8FMSHJGI/S0899825621001615.html:text/html;Submitted Version:/Users/oliverbiggar/Zotero/storage/6BZKFFA3/Pangallo et al. - 2022 - Towards a taxonomy of learning dynamics in 2 × 2 g.pdf:application/pdf},
}

@article{galla_complex_2013-1,
	title = {Complex dynamics in learning complicated games},
	volume = {110},
	url = {https://www.pnas.org/doi/full/10.1073/pnas.1109672110},
	doi = {10.1073/pnas.1109672110},
	abstract = {Game theory is the standard tool used to model strategic interactions in evolutionary biology and social science. Traditionally, game theory studies the equilibria of simple games. However, is this useful if the game is complicated, and if not, what is? We define a complicated game as one with many possible moves, and therefore many possible payoffs conditional on those moves. We investigate two-person games in which the players learn based on a type of reinforcement learning called experience-weighted attraction (EWA). By generating games at random, we characterize the learning dynamics under EWA and show that there are three clearly separated regimes: (i) convergence to a unique fixed point, (ii) a huge multiplicity of stable fixed points, and (iii) chaotic behavior. In case (iii), the dimension of the chaotic attractors can be very high, implying that the learning dynamics are effectively random. In the chaotic regime, the total payoffs fluctuate intermittently, showing bursts of rapid change punctuated by periods of quiescence, with heavy tails similar to what is observed in fluid turbulence and financial markets. Our results suggest that, at least for some learning algorithms, there is a large parameter regime for which complicated strategic interactions generate inherently unpredictable behavior that is best described in the language of dynamical systems theory.},
	number = {4},
	urldate = {2024-04-04},
	journal = {Proceedings of the National Academy of Sciences},
	author = {Galla, Tobias and Farmer, J. Doyne},
	month = jan,
	year = {2013},
	note = {Publisher: Proceedings of the National Academy of Sciences},
	pages = {1232--1236},
	file = {Full Text PDF:/Users/oliverbiggar/Zotero/storage/UHG4898X/Galla and Farmer - 2013 - Complex dynamics in learning complicated games.pdf:application/pdf},
}

@article{biggar_graph_2023,
	title = {The graph structure of two-player games},
	volume = {13},
	copyright = {2023 The Author(s)},
	issn = {2045-2322},
	url = {https://www.nature.com/articles/s41598-023-28627-8},
	doi = {10.1038/s41598-023-28627-8},
	abstract = {In this paper, we analyse two-player games by their response graphs. The response graph has nodes which are strategy profiles, with an arc between profiles if they differ in the strategy of a single player, with the direction of the arc indicating the preferred option for that player. Response graphs, and particularly their sink strongly connected components, play an important role in modern techniques in evolutionary game theory and multi-agent learning. We show that the response graph is a simple and well-motivated model of strategic interaction which captures many non-trivial properties of a game, despite not depending on cardinal payoffs. We characterise the games which share a response graph with a zero-sum or potential game respectively, and demonstrate a duality between these sets. This allows us to understand the influence of these properties on the response graph. The response graphs of Matching Pennies and Coordination are shown to play a key role in all two-player games: every non-iteratively-dominated strategy takes part in a subgame with these graph structures. As a corollary, any game sharing a response graph with both a zero-sum game and potential game must be dominance-solvable. Finally, we demonstrate our results on some larger games.},
	language = {en},
	number = {1},
	urldate = {2024-04-16},
	journal = {Scientific Reports},
	author = {Biggar, Oliver and Shames, Iman},
	month = feb,
	year = {2023},
	note = {Publisher: Nature Publishing Group},
	keywords = {Engineering, Mathematics and computing},
	pages = {1833},
	file = {Full Text PDF:/Users/oliverbiggar/Zotero/storage/HBYM3NKE/Biggar and Shames - 2023 - The graph structure of two-player games.pdf:application/pdf},
}

@inproceedings{biggar_replicator_2023,
	title = {The {Replicator} {Dynamic}, {Chain} {Components} and the {Response} {Graph}},
	url = {https://proceedings.mlr.press/v201/biggar23a.html},
	abstract = {In this paper we examine the relationship between the flow of the replicator dynamic, the continuum limit of Multiplicative Weights Update, and a game’s {\textbackslash}emph\{response graph\}. We settle an open problem establishing that under the replicator, {\textbackslash}emph\{sink chain components\}—a topological notion of long-run outcome of a dynamical system—always exist and are approximated by the {\textbackslash}emph\{sink connected components\} of the game’s response graph. More specifically, each sink chain component contains a sink connected component of the response graph, as well as all mixed strategy profiles whose support consists of pure profiles in the same connected component, a set we call the {\textbackslash}emph\{content\} of the connected component. As a corollary, all profiles are chain recurrent in games with strongly connected response graphs. In any two-player game sharing a response graph with a zero-sum game, the sink chain component is unique. In two-player zero-sum and potential games the sink chain components and sink connected components are in a one-to-one correspondence, and we conjecture that this holds in all games.},
	language = {en},
	urldate = {2024-04-16},
	booktitle = {Proceedings of {The} 34th {International} {Conference} on {Algorithmic} {Learning} {Theory}},
	publisher = {PMLR},
	author = {Biggar, Oliver and Shames, Iman},
	month = feb,
	year = {2023},
	note = {ISSN: 2640-3498},
	pages = {237--258},
	file = {Full Text PDF:/Users/oliverbiggar/Zotero/storage/H3DHZ7ZI/Biggar and Shames - 2023 - The Replicator Dynamic, Chain Components and the R.pdf:application/pdf},
}

@InProceedings{biggar_attractor_2024,
  title = {The {Attractor} of the {Replicator} {Dynamic} in {Zero}-{Sum} {Games}},
  author =       {Biggar, Oliver and Shames, Iman},
  booktitle = 	 {Proceedings of The 35th International Conference on Algorithmic Learning Theory},
  pages = 	 {161--178},
  year = 	 {2024},
  editor = 	 {Vernade, Claire and Hsu, Daniel},
  volume = 	 {237},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {25--28 Feb},
  publisher =    {PMLR},
  pdf = 	 {https://proceedings.mlr.press/v237/biggar24a/biggar24a.pdf},
  url = 	 {https://proceedings.mlr.press/v237/biggar24a.html},
  abstract = 	 {In this paper we characterise the long-run behaviour of the replicator dynamic in zero-sum games (symmetric or non-symmetric). Specifically, we prove that every zero-sum game possesses a unique global replicator attractor, which we then characterise. Most surprisingly, this attractor depends only on each player’s preference order over their own strategies and not on the cardinal payoff values, defined by a finite directed graph we call the game’s preference graph. When the game is symmetric, this graph is a tournament whose nodes are strategies; when the game is not symmetric, this graph is the game’s response graph. We discuss the consequences of our results on chain recurrence and Nash equilibria.}
}

@article{nash1951non,
  title={Non-cooperative games},
  author={Nash, John},
  journal={Annals of mathematics},
  pages={286--295},
  year={1951},
  publisher={JSTOR}
}

@article{aumann1987correlated,
  title={Correlated equilibrium as an expression of Bayesian rationality},
  author={Aumann, Robert J},
  journal={Econometrica: Journal of the Econometric Society},
  pages={1--18},
  year={1987},
  publisher={JSTOR}
}
@article{basu1991strategy,
  title={Strategy subsets closed under rational behavior},
  author={Basu, Kaushik and Weibull, J{\"o}rgen W},
  journal={Economics Letters},
  volume={36},
  number={2},
  pages={141--146},
  year={1991},
  publisher={Elsevier}
}

@book{von2007theory,
  title={Theory of games and economic behavior},
  author={Von Neumann, John and Morgenstern, Oskar},
  year={1944},
  publisher={Princeton university press}
}

@article{papadimitriou2019game,
  title={Game dynamics as the meaning of a game},
  author={Papadimitriou, Christos and Piliouras, Georgios},
  journal={ACM SIGecom Exchanges},
  volume={16},
  number={2},
  pages={53--63},
  year={2019},
  publisher={ACM New York, NY, USA}
}

@article{papadimitriou2018nash,
  title={From nash equilibria to chain recurrent sets: An algorithmic solution concept for game theory},
  author={Papadimitriou, Christos and Piliouras, Georgios},
  journal={Entropy},
  volume={20},
  number={10},
  pages={782},
  year={2018},
  publisher={Multidisciplinary Digital Publishing Institute}
}
@inproceedings{mertikopoulos2018cycles,
  title={Cycles in adversarial regularized learning},
  author={Mertikopoulos, Panayotis and Papadimitriou, Christos and Piliouras, Georgios},
  booktitle={Proceedings of the Twenty-Ninth Annual ACM-SIAM Symposium on Discrete Algorithms},
  pages={2703--2717},
  year={2018},
  organization={SIAM}
}
@inproceedings{boone2019darwin,
  title={From Darwin to Poincar{\'e} and von Neumann: Recurrence and cycles in evolutionary and algorithmic game theory},
  author={Boone, Victor and Piliouras, Georgios},
  booktitle={International Conference on Web and Internet Economics},
  pages={85--99},
  year={2019},
  organization={Springer}
}
@article{czechowski2021poincar,
  title={Poincar\'e-Bendixson Limit Sets in Multi-Agent Learning},
  author={Czechowski, Aleksander and Piliouras, Georgios},
  journal={arXiv preprint arXiv:2102.00053},
  year={2021}
}
@article{smith1973logic,
  title={The logic of animal conflict},
  author={Smith, J Maynard and Price, George R},
  journal={Nature},
  volume={246},
  number={5427},
  pages={15--18},
  year={1973},
  publisher={Nature Publishing Group}
}
@article{chen2009settling,
  title={Settling the complexity of computing two-player Nash equilibria},
  author={Chen, Xi and Deng, Xiaotie and Teng, Shang-Hua},
  journal={Journal of the ACM (JACM)},
  volume={56},
  number={3},
  pages={1--57},
  year={2009},
  publisher={ACM New York, NY, USA}
}
@article{arora2012multiplicative,
  title={The multiplicative weights update method: a meta-algorithm and applications},
  author={Arora, Sanjeev and Hazan, Elad and Kale, Satyen},
  journal={Theory of computing},
  volume={8},
  number={1},
  pages={121--164},
  year={2012},
  publisher={Theory of Computing Exchange}
}
@article{young1993evolution,
  title={The evolution of conventions},
  author={Young, H Peyton},
  journal={Econometrica: Journal of the Econometric Society},
  pages={57--84},
  year={1993},
  publisher={JSTOR}
}
@article{daskalakis2013complexity,
  title={On the complexity of approximating a Nash equilibrium},
  author={Daskalakis, Constantinos},
  journal={ACM Transactions on Algorithms (TALG)},
  volume={9},
  number={3},
  pages={1--35},
  year={2013},
  publisher={ACM New York, NY, USA}
}
@book{gratzer2002general,
  title={General lattice theory},
  author={Gr{\"a}tzer, George},
  year={2002},
  publisher={Springer Science \& Business Media}
}
@article{myerson1978refinements,
  title={Refinements of the Nash equilibrium concept},
  author={Myerson, Roger B},
  journal={International journal of game theory},
  volume={7},
  number={2},
  pages={73--80},
  year={1978},
  publisher={Springer}
}
@book{hubbard2015vector,
  title={Vector calculus, linear algebra, and differential forms: a unified approach},
  author={Hubbard, John H and Hubbard, Barbara Burke},
  year={2015},
  publisher={Matrix Editions}
}
@article{milchtaich1996congestion,
  title={Congestion games with player-specific payoff functions},
  author={Milchtaich, Igal},
  journal={Games and economic behavior},
  volume={13},
  number={1},
  pages={111--124},
  year={1996},
  publisher={Elsevier}
}
@article{li2020verification,
  title={Verification and Design of Zero-Sum Potential Games},
  author={Li, Changxi and He, Fenghua and Hao, Ning},
  journal={IFAC-PapersOnLine},
  volume={53},
  number={2},
  pages={16932--16937},
  year={2020},
  publisher={Elsevier}
}
@book{rapoport1970prisoner,
  title={Prisoner's dilemma: A study in conflict and cooperation},
  author={Rapoport, Anatol and Chammah, Albert M},
  volume={165},
  year={1970},
  publisher={University of Michigan press}
}
@book{pareto1919manuale,
  title={Manuale di economia politica: con una introduzione alla scienza sociale},
  author={Pareto, Vilfredo},
  volume={13},
  year={1919},
  publisher={Societ{\`a} editrice libraria}
}
@article{coddington1955poincare,
  title={The Poincar{\'e}--Bendixson theory of two-dimensional autonomous systems},
  author={Coddington, EA and Levinson, N},
  journal={Theory of Ordinary Differential Equations},
  pages={389--403},
  year={1955},
  publisher={McGraw-Hill New York}
}
@article{H1881,
author = {Henri Poincaré},
journal = {Journal de Mathématiques Pures et Appliquées},
language = {fre},
pages = {375-422},
title = {Mémoire sur les courbes définies par une équation différentielle (I) },
url = {http://eudml.org/doc/235914},
volume = {7},
year = {1881},
}
@book{brualdi2008combinatorial,
  title={A combinatorial approach to matrix theory and its applications},
  author={Brualdi, Richard A and Cvetkovic, Dragos},
  year={2008},
  publisher={Chapman and Hall/CRC}
}
@article{perron1907theorie,
  title={Zur theorie der matrices},
  author={Perron, Oskar},
  journal={Mathematische Annalen},
  volume={64},
  number={2},
  pages={248--263},
  year={1907},
  publisher={Springer}
}
@article{frobenius1912matrizen,
  title={{\"U}ber Matrizen aus nicht negativen Elementen},
  author={Frobenius, Georg},
  year={1912},
  publisher={K{\"o}nigliche Akademie der Wissenschaften Sitzungsber, K{\"o}n}
}
@article{quint1997theorem,
  title={A theorem on the number of Nash equilibria in a bimatrix game},
  author={Quint, Thomas and Shubik, Martin},
  journal={International Journal of Game Theory},
  volume={26},
  number={3},
  pages={353--359},
  year={1997},
  publisher={Springer}
}
@inproceedings{chen2006settling,
  title={Settling the complexity of two-player Nash equilibrium},
  author={Chen, Xi and Deng, Xiaotie},
  booktitle={2006 47th Annual IEEE Symposium on Foundations of Computer Science (FOCS'06)},
  pages={261--272},
  year={2006},
  organization={IEEE}
}
@inproceedings{papadimitriou2016nash,
  title={From Nash equilibria to chain recurrent sets: Solution concepts and topology},
  author={Papadimitriou, Christos and Piliouras, Georgios},
  booktitle={Proceedings of the 2016 ACM Conference on Innovations in Theoretical Computer Science},
  pages={227--235},
  year={2016}
}
@article{milionis2022nash,
  title={Nash, Conley, and Computation: Impossibility and Incompleteness in Game Dynamics},
  author={Milionis, Jason and Papadimitriou, Christos and Piliouras, Georgios and Spendlove, Kelly},
  journal={arXiv preprint arXiv:2203.14129},
  year={2022}
}

@book{sandholm2010population,
  title={Population games and evolutionary dynamics},
  author={Sandholm, William H},
  year={2010},
  publisher={MIT press}
}

@book{alongi2007recurrence,
  title={Recurrence and topology},
  author={Alongi, John M and Nelson, Gail Susan},
  volume={85},
  year={2007},
  publisher={American Mathematical Soc.}
}

@article{monderer1996potential,
  title={Potential games},
  author={Monderer, Dov and Shapley, Lloyd S},
  journal={Games and economic behavior},
  volume={14},
  number={1},
  pages={124--143},
  year={1996},
  publisher={Elsevier}
}
@article{omidshafiei2019alpha,
  title={$\alpha$-rank: Multi-agent evaluation by evolution},
  author={Omidshafiei, Shayegan and Papadimitriou, Christos and Piliouras, Georgios and Tuyls, Karl and Rowland, Mark and Lespiau, Jean-Baptiste and Czarnecki, Wojciech M and Lanctot, Marc and Perolat, Julien and Munos, Remi},
  journal={Scientific reports},
  volume={9},
  number={1},
  pages={1--29},
  year={2019},
  publisher={Nature Publishing Group}
}

@book{conley1978isolated,
  title={Isolated invariant sets and the Morse index},
  author={Conley, Charles C},
  number={38},
  year={1978},
  publisher={American Mathematical Soc.}
}

@book{myerson1997game,
  title={Game theory: analysis of conflict},
  author={Myerson, Roger B},
  year={1997},
  publisher={Harvard university press}
}
@article{neumann1928theorie,
  title={Zur theorie der gesellschaftsspiele},
  author={Neumann, J v},
  journal={Mathematische annalen},
  volume={100},
  number={1},
  pages={295--320},
  year={1928},
  publisher={Springer}
}

@book{sen2017collective,
  title={Collective choice and social welfare},
  author={Sen, Amartya},
  year={2017},
  publisher={Harvard University Press}
}

@article{candogan2011flows,
  title={Flows and decompositions of games: Harmonic and potential games},
  author={Candogan, Ozan and Menache, Ishai and Ozdaglar, Asuman and Parrilo, Pablo A},
  journal={Mathematics of Operations Research},
  volume={36},
  number={3},
  pages={474--503},
  year={2011},
  publisher={INFORMS}
}

@inproceedings{goemans2005sink,
  title={Sink equilibria and convergence},
  author={Goemans, Michel and Mirrokni, Vahab and Vetta, Adrian},
  booktitle={46th Annual IEEE Symposium on Foundations of Computer Science (FOCS'05)},
  pages={142--151},
  year={2005},
  organization={IEEE}
}

@book{roughgarden2005selfish,
  title={Selfish routing and the price of anarchy},
  author={Roughgarden, Tim},
  year={2005},
  publisher={MIT press}
}
@article{hofbauer2003evolutionary,
  title={Evolutionary game dynamics},
  author={Hofbauer, Josef and Sigmund, Karl},
  journal={Bulletin of the American mathematical society},
  volume={40},
  number={4},
  pages={479--519},
  year={2003}
}
@inproceedings{kleinberg2011beyond,
  title={Beyond the Nash Equilibrium Barrier.},
  author={Kleinberg, Robert D and Ligett, Katrina and Piliouras, Georgios and Tardos, {\'E}va},
  booktitle={ICS},
  pages={125--140},
  year={2011}
}
@article{hart2003uncoupled,
  title={Uncoupled dynamics do not lead to Nash equilibrium},
  author={Hart, Sergiu and Mas-Colell, Andreu},
  journal={American Economic Review},
  volume={93},
  number={5},
  pages={1830--1836},
  year={2003}
}
@article{mertens2004ordinality,
  title={Ordinality in non cooperative games},
  author={Mertens, Jean-Fran{\c{c}}ois},
  journal={International Journal of Game Theory},
  volume={32},
  number={3},
  pages={387--430},
  year={2004},
  publisher={Springer}
}
@article{morris2004best,
  title={Best response equivalence},
  author={Morris, Stephen and Ui, Takashi},
  journal={Games and Economic Behavior},
  volume={49},
  number={2},
  pages={260--287},
  year={2004},
  publisher={Elsevier}
}

@article{barany1992classification,
  title={Classification of two-person ordinal bimatrix games},
  author={Barany, Imre and Lee, Jon and Shubik, Martin},
  journal={International Journal of Game Theory},
  volume={21},
  number={3},
  pages={267--290},
  year={1992},
  publisher={Springer}
}
@article{cruz2000ordinal,
  title={Ordinal games and generalized Nash and Stackelberg solutions},
  author={Cruz, JB and Simaan, Marwan A},
  journal={Journal of optimization theory and applications},
  volume={107},
  number={2},
  pages={205--222},
  year={2000},
  publisher={Springer}
}
@article{ben2017equilibria,
  title={Equilibria in ordinal games: A framework based on possibility theory},
  author={Ben Amor, Nahla and Fargier, H{\'e}lene and Sabbadin, R{\'e}gis},
  year={2017},
  booktitle={IJCAI},
  publisher={AAAI Press}
}
@article{hwang2020simple,
  title={Simple Characterizations of Potential Games and Zero-sum Equivalent Games},
  author={Hwang, Sung-Ha and Rey-Bellet, Luc},
  journal={Journal of Economic Theory and Econometrics},
  volume={31},
  number={1},
  pages={1--13},
  year={2020},
  publisher={Korean Econometric Society}
}
@inproceedings{balduzzi2018mechanics,
  title={The mechanics of n-player differentiable games},
  author={Balduzzi, David and Racaniere, Sebastien and Martens, James and Foerster, Jakob and Tuyls, Karl and Graepel, Thore},
  booktitle={International Conference on Machine Learning},
  pages={354--363},
  year={2018},
  organization={PMLR}
}
@article{vlatakis2020no,
  title={No-regret learning and mixed nash equilibria: They do not mix},
  author={Vlatakis-Gkaragkounis, Emmanouil-Vasileios and Flokas, Lampros and Lianeas, Thanasis and Mertikopoulos, Panayotis and Piliouras, Georgios},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={1380--1391},
  year={2020}
}
@article{durieu2008ordinal,
  title={Ordinal games},
  author={Durieu, Jacques and Haller, Hans and Qu{\'e}rou, Nicolas and Solal, Philippe},
  journal={International Game Theory Review},
  volume={10},
  number={02},
  pages={177--194},
  year={2008},
  publisher={World Scientific}
}

@article{roughgarden2010algorithmic,
  title={Algorithmic game theory},
  author={Roughgarden, Tim},
  journal={Communications of the ACM},
  volume={53},
  number={7},
  pages={78--86},
  year={2010},
  publisher={ACM New York, NY, USA}
}

@article{candogan2013dynamics,
  title={Dynamics in near-potential games},
  author={Candogan, Ozan and Ozdaglar, Asuman and Parrilo, Pablo A},
  journal={Games and Economic Behavior},
  volume={82},
  pages={66--90},
  year={2013},
  publisher={Elsevier}
}
@article{akin1984evolutionary,
  title={Evolutionary dynamics of zero-sum games},
  author={Akin, Ethan and Losert, Viktor},
  journal={Journal of Mathematical Biology},
  volume={20},
  number={3},
  pages={231--258},
  year={1984},
  publisher={Springer-Verlag}
}

@article{hwang2020strategic,
  title={Strategic decompositions of normal form games: Zero-sum games and potential games},
  author={Hwang, Sung-Ha and Rey-Bellet, Luc},
  journal={Games and Economic Behavior},
  volume={122},
  pages={370--390},
  year={2020},
  publisher={Elsevier}
}

@inproceedings{mirrokni2009complexity,
  title={On the complexity of Nash dynamics and sink equilibria},
  author={Mirrokni, Vahab S and Skopalik, Alexander},
  booktitle={Proceedings of the 10th ACM conference on Electronic commerce},
  pages={1--10},
  year={2009}
}
@inproceedings{fabrikant2008complexity,
  title={The complexity of game dynamics: BGP oscillations, sink equilibria, and beyond.},
  author={Fabrikant, Alex and Papadimitriou, Christos H},
  booktitle={SODA},
  volume={8},
  pages={844--853},
  year={2008},
  organization={Citeseer}
}

@article{omidshafiei2020navigating,
  title={Navigating the landscape of multiplayer games},
  author={Omidshafiei, Shayegan and Tuyls, Karl and Czarnecki, Wojciech M and Santos, Francisco C and Rowland, Mark and Connor, Jerome and Hennes, Daniel and Muller, Paul and P{\'e}rolat, Julien and Vylder, Bart De and others},
  journal={Nature communications},
  volume={11},
  number={1},
  pages={1--17},
  year={2020},
  publisher={Nature Publishing Group}
}

@book{fudenberg1991game,
  title={Game Theory},
  author={Fudenberg, Drew and Tirole, Jean},
  year={1991},
  publisher={MIT press}
}
@book{hammack2011handbook,
  title={Handbook of product graphs},
  author={Hammack, Richard H and Imrich, Wilfried and Klav{\v{z}}ar, Sandi},
  volume={2},
  year={2011},
  publisher={CRC press}
}
@book{strogatz2018nonlinear,
  title={Nonlinear dynamics and chaos: with applications to physics, biology, chemistry, and engineering},
  author={Strogatz, Steven H},
  year={2018},
  publisher={CRC press}
}
@article{diestel2016graph,
  title={Graph theory},
  author={Diestel, Reinhard},
  journal={Graduate Texts in Mathematics},
  edition = {Fifth},
  volume={173},
  year={2016}
}
@article{harsanyi1988general,
  title={A general theory of equilibrium selection in games},
  author={Harsanyi, John C and Selten, Reinhard and others},
  journal={MIT Press Books},
  volume={1},
  year={1988},
  publisher={The MIT Press}
}

@inproceedings{koutsoupias1999worst,
  title={Worst-case equilibria},
  author={Koutsoupias, Elias and Papadimitriou, Christos},
  booktitle={Annual symposium on theoretical aspects of computer science},
  pages={404--413},
  year={1999},
  organization={Springer}
}

@inproceedings{conitzer2005complexity,
  title={Complexity of (iterated) dominance},
  author={Conitzer, Vincent and Sandholm, Tuomas},
  booktitle={Proceedings of the 6th ACM Conference on Electronic Commerce},
  pages={88--97},
  year={2005}
}
@article{daskalakis2009complexity,
  title={The complexity of computing a Nash equilibrium},
  author={Daskalakis, Constantinos and Goldberg, Paul W and Papadimitriou, Christos H},
  journal={SIAM Journal on Computing},
  volume={39},
  number={1},
  pages={195--259},
  year={2009},
  publisher={SIAM}
}

@article{wagner1937eigenschaft,
  title={{\"U}ber eine Eigenschaft der ebenen Komplexe},
  author={Wagner, Klaus},
  journal={Mathematische Annalen},
  volume={114},
  number={1},
  pages={570--590},
  year={1937},
  publisher={Springer}
}
@article{benaim2012perturbations,
  title={Perturbations of set-valued dynamical systems, with applications to game theory},
  author={Bena{\"\i}m, Michel and Hofbauer, Josef and Sorin, Sylvain},
  journal={Dynamic Games and Applications},
  volume={2},
  number={2},
  pages={195--205},
  year={2012},
  publisher={Springer}
}
@inproceedings{piliouras2014optimization,
  title={Optimization despite chaos: Convex relaxations to complex limit sets via Poincar{\'e} recurrence},
  author={Piliouras, Georgios and Shamma, Jeff S},
  booktitle={Proceedings of the twenty-fifth annual ACM-SIAM Symposium on Discrete Algorithms},
  pages={861--873},
  year={2014},
  organization={SIAM}
}

@phdthesis{biggarthesis,

title = {Preference games and sink equilibria},
author = {Biggar, Oliver},
year = {2022},
school = {Australian National University},
type = {{B.Sc. Thesis}}

}
@article{biggar2023graph,
  title={The graph structure of two-player games},
  author={Biggar, Oliver and Shames, Iman},
  journal={Scientific Reports},
  volume={13},
  number={1},
  pages={1833},
  year={2023},
  publisher={Nature Publishing Group UK London}
}

@inproceedings{hakim2024swim,
  title={Swim till You Sink: Computing the Limit of a Game},
  author={Hakim, Rashida and Milionis, Jason and Papadimitriou, Christos and Piliouras, Georgios},
  booktitle={International Symposium on Algorithmic Game Theory},
  pages={205--222},
  year={2024},
  organization={Springer}
}

@article{vives1990nash,
  title={Nash equilibrium with strategic complementarities},
  author={Vives, Xavier},
  journal={Journal of Mathematical Economics},
  volume={19},
  number={3},
  pages={305--321},
  year={1990},
  publisher={Elsevier}
}

@book{krishna1992learning,
  title={Learning in games with strategic complementarities},
  author={Krishna, Vijay},
  year={1992},
  publisher={Harvard Business School}
}

@book{shoham2008multiagent,
  title={Multiagent systems: Algorithmic, game-theoretic, and logical foundations},
  author={Shoham, Yoav and Leyton-Brown, Kevin},
  year={2008},
  publisher={Cambridge University Press}
}
@article{yang2020overview,
  title={An overview of multi-agent reinforcement learning from game theoretical perspective},
  author={Yang, Yaodong and Wang, Jun},
  journal={arXiv preprint arXiv:2011.00583},
  year={2020}
}
@article{goodfellow2020generative,
  title={Generative adversarial networks},
  author={Goodfellow, Ian and Pouget-Abadie, Jean and Mirza, Mehdi and Xu, Bing and Warde-Farley, David and Ozair, Sherjil and Courville, Aaron and Bengio, Yoshua},
  journal={Communications of the ACM},
  volume={63},
  number={11},
  pages={139--144},
  year={2020},
  publisher={ACM New York, NY, USA}
}

@article{lanctot2019openspiel,
  title={OpenSpiel: A framework for reinforcement learning in games},
  author={Lanctot, Marc and Lockhart, Edward and Lespiau, Jean-Baptiste and Zambaldi, Vinicius and Upadhyay, Satyaki and P{\'e}rolat, Julien and Srinivasan, Sriram and Timbers, Finbarr and Tuyls, Karl and Omidshafiei, Shayegan and others},
  journal={arXiv preprint arXiv:1908.09453},
  year={2019}
}

@article{hernandez2019survey,
  title={A survey and critique of multiagent deep reinforcement learning},
  author={Hernandez-Leal, Pablo and Kartal, Bilal and Taylor, Matthew E},
  journal={Autonomous Agents and Multi-Agent Systems},
  volume={33},
  number={6},
  pages={750--797},
  year={2019},
  publisher={Springer}
}
@article{silver2016mastering,
  title={Mastering the game of Go with deep neural networks and tree search},
  author={Silver, David and Huang, Aja and Maddison, Chris J and Guez, Arthur and Sifre, Laurent and Van Den Driessche, George and Schrittwieser, Julian and Antonoglou, Ioannis and Panneershelvam, Veda and Lanctot, Marc and others},
  journal={Nature},
  volume={529},
  number={7587},
  pages={484--489},
  year={2016},
  publisher={Nature Publishing Group}
}
@article{silver2017mastering,
  title={Mastering the game of go without human knowledge},
  author={Silver, David and Schrittwieser, Julian and Simonyan, Karen and Antonoglou, Ioannis and Huang, Aja and Guez, Arthur and Hubert, Thomas and Baker, Lucas and Lai, Matthew and Bolton, Adrian and others},
  journal={Nature},
  volume={550},
  number={7676},
  pages={354--359},
  year={2017},
  publisher={Nature Publishing Group}
}
@article{silver2018general,
  title={A general reinforcement learning algorithm that masters chess, shogi, and Go through self-play},
  author={Silver, David and Hubert, Thomas and Schrittwieser, Julian and Antonoglou, Ioannis and Lai, Matthew and Guez, Arthur and Lanctot, Marc and Sifre, Laurent and Kumaran, Dharshan and Graepel, Thore and others},
  journal={Science},
  volume={362},
  number={6419},
  pages={1140--1144},
  year={2018},
  publisher={American Association for the Advancement of Science}
}
@book{rasmusen1989games,
  title={Games and Information},
  author={Rasmusen, Eric},
  volume={13},
  year={1989},
  publisher={Basil Blackwell Oxford}
}
@article{kalies2021lattice,
  title={Lattice structures for attractors III},
  author={Kalies, William D and Mischaikow, Konstantin and Vandervorst, Robert CAM},
  journal={Journal of Dynamics and Differential Equations},
  pages={1--40},
  year={2021},
  publisher={Springer}
}
@book{hatcher2002algebraic,
  title={Algebraic Topology},
  author={Hatcher, Allen},
  year={2002},
  publisher={Cambridge University Press}
}
@article{hofbauer1996evolutionary,
  title={Evolutionary dynamics for bimatrix games: A Hamiltonian system?},
  author={Hofbauer, Josef},
  journal={Journal of Mathematical Biology},
  volume={34},
  number={5},
  pages={675--688},
  year={1996},
  publisher={Springer}
}
@article{eshel1983coevolutionary,
  title={Coevolutionary instability of mixed Nash solutions},
  author={Eshel, Ilan and Akin, Ethan and others},
  journal={Journal of Mathematical Biology},
  volume={18},
  number={2},
  pages={123--133},
  year={1983}
}
@incollection{selten1988note,
  title={A note on evolutionarily stable strategies in asymmetric animal conflicts},
  author={Selten, Reinhard},
  booktitle={Models of Strategic Rationality},
  pages={67--75},
  year={1988},
  publisher={Springer}
}
@article{piliouras2022evolutionary,
  title={Evolutionary Dynamics and Phi-Regret Minimization in Games},
  author={Piliouras, Georgios and Rowland, Mark and Omidshafiei, Shayegan and Elie, Romuald and Hennes, Daniel and Connor, Jerome and Tuyls, Karl},
  journal={Journal of Artificial Intelligence Research},
  volume={74},
  pages={1125--1158},
  year={2022}
}
@inproceedings{andrade2021learning,
  title={Learning in matrix games can be arbitrarily complex},
  author={Andrade, Gabriel P and Frongillo, Rafael and Piliouras, Georgios},
  booktitle={Conference on Learning Theory},
  pages={159--185},
  year={2021},
  organization={PMLR}
}
@article{chotibut2020route,
  title={The route to chaos in routing games: When is price of anarchy too optimistic?},
  author={Chotibut, Thiparat and Falniowski, Fryderyk and Misiurewicz, Micha{\l} and Piliouras, Georgios},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={766--777},
  year={2020}
}

@inproceedings{bailey2018multiplicative,
  title={Multiplicative weights update in zero-sum games},
  author={Bailey, James P and Piliouras, Georgios},
  booktitle={Proceedings of the 2018 ACM Conference on Economics and Computation},
  pages={321--338},
  year={2018}
}

@inproceedings{cheung2019vortices,
  title={Vortices instead of equilibria in minmax optimization: Chaos and butterfly effects of online learning in zero-sum games},
  author={Cheung, Yun Kuen and Piliouras, Georgios},
  booktitle={Conference on Learning Theory},
  pages={807--834},
  year={2019},
  organization={PMLR}
}

@article{cheung2020chaos,
  title={Chaos, extremism and optimism: Volume analysis of learning in games},
  author={Cheung, Yun Kuen and Piliouras, Georgios},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={9039--9049},
  year={2020}
}

@article{moulin1978strategically,
  title={Strategically zero-sum games: the class of games whose completely mixed equilibria cannot be improved upon},
  author={Moulin, Herv{\'e} and Vial, J-P},
  journal={International Journal of Game Theory},
  volume={7},
  number={3},
  pages={201--221},
  year={1978},
  publisher={Springer}
}
@book{hofbauer1998evolutionary,
  title={Evolutionary games and population dynamics},
  author={Hofbauer, Josef and Sigmund, Karl},
  year={1998},
  publisher={Cambridge university press}
}
@article{freund1999adaptive,
  title={Adaptive game playing using multiplicative weights},
  author={Freund, Yoav and Schapire, Robert E},
  journal={Games and Economic Behavior},
  volume={29},
  number={1-2},
  pages={79--103},
  year={1999},
  publisher={Elsevier}
}
@article{milnor1985concept,
  title={On the concept of attractor},
  author={Milnor, John},
  journal={Communications in Mathematical Physics},
  volume={99},
  pages={177--195},
  year={1985},
  publisher={Springer}
}
@incollection{gale20167,
  title={On Symmetric Games},
  author={Gale, David and Kuhn, Harold W and Tucker, Albert W},
  booktitle={Contributions to the Theory of Games (AM-24), Volume I},
  pages={81--88},
  year={1950},
  publisher={Princeton University Press}
}
@book{robinson1998dynamical,
  title={Dynamical systems: stability, symbolic dynamics, and chaos},
  author={Robinson, Clark},
  year={1998},
  publisher={CRC press}
}
@incollection{zeeman1980population,
  title={Population dynamics from game theory},
  author={Zeeman, E Christopher},
  booktitle={Global theory of dynamical systems},
  pages={471--497},
  year={1980},
  publisher={Springer}
}
@inproceedings{biggar2023replicator,
  title={The Replicator Dynamic, Chain Components and the Response Graph},
  author={Biggar, Oliver and Shames, Iman},
  booktitle={International Conference on Algorithmic Learning Theory},
  pages={237--258},
  year={2023},
  organization={PMLR}
}

@article{taylor1978evolutionary,
  title={Evolutionary stable strategies and game dynamics},
  author={Taylor, Peter D and Jonker, Leo B},
  journal={Mathematical biosciences},
  volume={40},
  number={1-2},
  pages={145--156},
  year={1978},
  publisher={Elsevier}
}

@article{schuster1983replicator,
  title={Replicator dynamics},
  author={Schuster, Peter and Sigmund, Karl},
  journal={Journal of theoretical biology},
  volume={100},
  number={3},
  pages={533--538},
  year={1983},
  publisher={Elsevier}
}
@book{weibull1997evolutionary,
  title={Evolutionary game theory},
  author={Weibull, J{\"o}rgen W},
  year={1997},
  publisher={MIT press}
}
@book{fudenberg1998theory,
  title={The theory of learning in games},
  author={Fudenberg, Drew and Levine, David K},
  volume={2},
  year={1998},
  publisher={MIT press}
}
@article{tarjan1972depth,
  title={Depth-first search and linear graph algorithms},
  author={Tarjan, Robert},
  journal={SIAM journal on computing},
  volume={1},
  number={2},
  pages={146--160},
  year={1972},
  publisher={SIAM}
}
@article{ritzberger1995evolutionary,
  title={Evolutionary selection in normal-form games},
  author={Ritzberger, Klaus and Weibull, J{\"o}rgen W},
  journal={Econometrica: Journal of the Econometric Society},
  pages={1371--1399},
  year={1995},
  publisher={JSTOR}
}
@article{sato2002chaos,
  title={Chaos in learning a simple two-person game},
  author={Sato, Yuzuru and Akiyama, Eizo and Farmer, J Doyne},
  journal={Proceedings of the National Academy of Sciences},
  volume={99},
  number={7},
  pages={4748--4751},
  year={2002},
  publisher={National Acad Sciences}
}
@article{hofbauer2009time,
  title={Time average replicator and best-reply dynamics},
  author={Hofbauer, Josef and Sorin, Sylvain and Viossat, Yannick},
  journal={Mathematics of Operations Research},
  volume={34},
  number={2},
  pages={263--269},
  year={2009},
  publisher={INFORMS}
}
@book{cormen2022introduction,
  title={Introduction to algorithms},
  author={Cormen, Thomas H and Leiserson, Charles E and Rivest, Ronald L and Stein, Clifford},
  year={2022},
  publisher={MIT press}
}

@book{kemeny1969finite,
  title={Finite markov chains},
  author={Kemeny, John G and Snell, J Laurie and others},
  volume={26},
  year={1969},
  publisher={van Nostrand Princeton, NJ}
}

@article{moulin_dominance_1984,
	title = {Dominance solvability and cournot stability},
	volume = {7},
	issn = {0165-4896},
	url = {https://www.sciencedirect.com/science/article/pii/0165489684900908},
	doi = {10.1016/0165-4896(84)90090-8},
	abstract = {In normal form games with single-valued best reply functions it is shown that dominance-solvability (resulting from successive elimination of dominated strategies) implies the global stability of the Cournot tatonnement process. When only two players are present, and the strategy spaces are one dimensional, these two notions actually coincide. A computational characterization of the two properties is given in a local sense as well as a sufficient condition for global dominance-solvability: an application to the Cournot-oligopoly model is proposed.},
	number = {1},
	urldate = {2024-05-01},
	journal = {Mathematical Social Sciences},
	author = {Moulin, Herve},
	month = feb,
	year = {1984},
	keywords = {Cournot stability oligopoly model., Dominance solvability},
	pages = {83--102},
}

@book{cournot1838recherches,
  title={Recherches sur les principes math{\'e}matiques de la th{\'e}orie des richesses},
  author={Cournot, Antoine Augustin},
  volume={48},
  year={1838},
  publisher={L. Hachette}
}

@book{brown1949some,
  title={Some notes on computation of games solutions},
  author={Brown, George W},
  year={1949},
  publisher={Rand Corporation}
}

@article{topkis1979equilibrium,
  title={Equilibrium points in nonzero-sum n-person submodular games},
  author={Topkis, Donald M},
  journal={Siam Journal on control and optimization},
  volume={17},
  number={6},
  pages={773--787},
  year={1979},
  publisher={SIAM}
}

@book{miyasawa1961convergence,
  title={On the convergence of the learning process in a 2 x 2 non-zero-sum two-person game},
  author={Miyasawa, Koichi},
  year={1961},
  publisher={Princeton University Princeton}
}