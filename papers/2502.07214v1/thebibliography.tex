% ---- Bibliography ----
%
% BibTeX users should specify bibliography style 'splncs04'.
% References will then be sorted and formatted in the correct style.
%
% \bibliographystyle{splncs04}
% \bibliography{mybibliography}
%
\begin{thebibliography}{8}

\bibitem{mothilal2020explaining}
Mothilal, R.K., Sharma, A., Tan, C.: Explaining machine learning classifiers through diverse counterfactual explanations. In: Proceedings of the 2020 Conference on Fairness, Accountability, and Transparency, pp. 607--617 (2020)

\bibitem{gabow1984scaling}
Gabow, H.N., Bentley, J.L., Tarjan, R.E.: Scaling and related techniques for geometry problems. In: Proceedings of the Sixteenth Annual ACM Symposium on Theory of Computing, pp. 135--143 (1984)

\bibitem{preparata2012computational}
Preparata, F.P., Shamos, M.I.: Computational Geometry: An Introduction. 2nd edn. Springer Science \& Business Media, (2012)

\bibitem{karlsson1988scanline}
Karlsson, R.G., Overmars, M.H.: Scanline algorithms on a grid. BIT Numerical Mathematics \textbf{28}, 227--241 (1988)

\bibitem{bellman1958routing}
Bellman, R.: On a routing problem. Quarterly of Applied Mathematics \textbf{16}(1), 87--90 (1958)

\bibitem{agarwal2005geometric}
Agarwal, P.K., Har-Peled, S., Varadarajan, K.R., et al.: Geometric approximation via coresets. Combinatorial and Computational Geometry \textbf{52}(1), 1--30 (2005)

\bibitem{haussler1986epsilon}
Haussler, D., Welzl, E.: Epsilon-nets and simplex range queries. In: Proceedings of the Second Annual Symposium on Computational Geometry, pp. 61--71 (1986)

\bibitem{jiang2011free}
Jiang, P., Chen, Y.: Free lunches on the discrete Lipschitz class. Theoretical Computer Science \textbf{412}(17), 1614--1628 (2011)

\bibitem{daston2021objectivity}
Daston, L., Galison, P.: Objectivity. Princeton University Press, (2021)

\bibitem{chen2020simple}
Chen, T., Kornblith, S., Norouzi, M., Hinton, G.: A simple framework for contrastive learning of visual representations. In: International Conference on Machine Learning, pp. 1597--1607. PMLR (2020)

\bibitem{lundberg2018consistent}
Lundberg, S.M., Erion, G.G., Lee, S.I.: Consistent individualized feature attribution for tree ensembles. arXiv preprint arXiv:1802.03888 (2018)

\bibitem{lundberg2018explainable}
Lundberg, S.M., et al.: Explainable machine-learning predictions for the prevention of hypoxaemia during surgery. Nature Biomedical Engineering \textbf{2}(10), 749--760 (2018)

\bibitem{tang2022perception}
Tang, Y., et al.: Perception and navigation in autonomous systems in the era of learning: A survey. IEEE Transactions on Neural Networks and Learning Systems (2022)

\bibitem{kingma2013auto}
Kingma, D.P., Welling, M.: Auto-encoding variational bayes. arXiv preprint arXiv:1312.6114 (2013)

\bibitem{doersch2016tutorial}
Doersch, C.: Tutorial on variational autoencoders. arXiv preprint arXiv:1606.05908 (2016)

\bibitem{fang2020independent}
Fang, S., Zhu, Q.: Independent Gaussian distributions minimize the Kullback-Leibler (KL) divergence from independent Gaussian distributions. arXiv preprint arXiv:2011.02560 (2020)

\bibitem{zhai2018autoencoder}
Zhai, J., Zhang, S., Chen, J., He, Q.: Autoencoder and its various variants. In: 2018 IEEE International Conference on Systems, Man, and Cybernetics (SMC), pp. 415--419. IEEE (2018)

\bibitem{monti2019fake}
Monti, F., Frasca, F., Eynard, D., Mannion, D., Bronstein, M.M.: Fake news detection on social media using geometric deep learning. arXiv preprint arXiv:1902.06673 (2019)

\bibitem{wang2018deep}
Wang, C., Han, D., Liu, Q., Luo, S.: A deep learning approach for credit scoring of peer-to-peer lending using attention mechanism LSTM. IEEE Access \textbf{7}, 2161--2168 (2018)

\bibitem{kim2023help}
Kim, S.S.Y., Watkins, E.A., Russakovsky, O., Fong, R., Monroy-Hernández, A.: "Help Me Help the AI": Understanding how explainability can support human-AI interaction. In: Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems, pp. 1--17 (2023)

\bibitem{turay2022toward}
Turay, T., Vladimirova, T.: Toward performing image classification and object detection with convolutional neural networks in autonomous driving systems: A survey. IEEE Access \textbf{10}, 14076--14119 (2022)

\bibitem{danilevsky2020survey}
Danilevsky, M., et al.: A survey of the state of explainable AI for natural language processing. arXiv preprint arXiv:2010.00711 (2020)

\bibitem{wu2022graph}
Wu, S., et al.: Graph neural networks in recommender systems: a survey. ACM Computing Surveys \textbf{55}(5), 1--37 (2022)

\bibitem{wang2021deep}
Wang, M., Deng, W.: Deep face recognition: A survey. Neurocomputing \textbf{429}, 215--244 (2021)

\bibitem{zhao2019object}
Zhao, Z.Q., Zheng, P., Xu, S., Wu, X.: Object detection with deep learning: A review. IEEE Transactions on Neural Networks and Learning Systems \textbf{30}(11), 3212--3232 (2019)

\bibitem{otter2020survey}
Otter, D.W., Medina, J.R., Kalita, J.K.: A survey of the usages of deep learning for natural language processing. IEEE Transactions on Neural Networks and Learning Systems \textbf{32}(2), 604--624 (2020)

\bibitem{voynov2020unsupervised}
Voynov, A., Babenko, A.: Unsupervised discovery of interpretable directions in the GAN latent space. In: International Conference on Machine Learning, pp. 9786--9796. PMLR (2020)

\bibitem{goodfellow2014generative}
Goodfellow, I., et al.: Generative adversarial nets. Advances in Neural Information Processing Systems \textbf{27} (2014)

\bibitem{ho2020denoising}
Ho, J., Jain, A., Abbeel, P.: Denoising diffusion probabilistic models. Advances in Neural Information Processing Systems \textbf{33}, 6840--6851 (2020)

\bibitem{baldi2012autoencoders}
Baldi, P.: Autoencoders, unsupervised learning, and deep architectures. In: Proceedings of ICML Workshop on Unsupervised and Transfer Learning, pp. 37--49. JMLR Workshop and Conference Proceedings (2012)

\bibitem{luo2022understanding}
Luo, C.: Understanding diffusion models: A unified perspective. arXiv preprint arXiv:2208.11970 (2022)

\bibitem{bank2023autoencoders}
Bank, D., Koenigstein, N., Giryes, R.: Autoencoders. Machine Learning for Data Science Handbook: Data Mining and Knowledge Discovery Handbook, pp. 353--374. Springer (2023)

\bibitem{blei2017variational}
Blei, D.M., Kucukelbir, A., McAuliffe, J.D.: Variational inference: A review for statisticians. Journal of the American Statistical Association \textbf{112}(518), 859--877 (2017)

\bibitem{yang2017understanding}
Yang, X.: Understanding the variational lower bound. Variational lower bound, ELBO, hard attention \textbf{22}, 1--4 (2017)

\bibitem{bishop1998latent}
Bishop, C.M.: Latent variable models. In: Learning in Graphical Models, pp. 371--403. Springer, Heidelberg (1998)

\bibitem{ramesh2022hierarchical}
Ramesh, A., Dhariwal, P., Nichol, A., Chu, C., Chen, M.: Hierarchical text-conditional image generation with clip latents. arXiv preprint arXiv:2204.06125 \textbf{1}(2), 3 (2022)

\bibitem{wu2023brief}
Wu, T., He, S., Liu, J., Sun, S., Liu, K., Han, Q.-L., Tang, Y.: A brief overview of ChatGPT: The history, status quo and potential future development. IEEE/CAA Journal of Automatica Sinica \textbf{10}(5), 1122--1136 (2023)

\bibitem{koh2017understanding}
Koh, P.W., Liang, P.: Understanding black-box predictions via influence functions. In: International Conference on Machine Learning, pp. 1885--1894. PMLR (2017)

\bibitem{sundararajan2020many}
Sundararajan, M., Najmi, A.: The many Shapley values for model explanation. In: International Conference on Machine Learning, pp. 9269--9278. PMLR (2020)

\bibitem{winter2002shapley}
Winter, E.: The Shapley value. Handbook of Game Theory with Economic Applications \textbf{3}, 2025--2054. Elsevier (2002)

\bibitem{hart1989shapley}
Hart, S.: Shapley value. In: Game Theory, pp. 210--216. Springer, Heidelberg (1989)

\bibitem{roth1988introduction}
Roth, A.E.: Introduction to the Shapley value. The Shapley Value, pp. 1--27. University of Cambridge Press, Cambridge (1988)

\bibitem{shapley1953value}
Shapley, L.S.: A value for n-person games. Princeton University Press, Princeton (1953)

\bibitem{pouyanfar2018survey}
Pouyanfar, S., Sadiq, S., Yan, Y., Tian, H., Tao, Y., Reyes, M.P., Shyu, M.L., Chen, S.C., Iyengar, S.S.: A survey on deep learning: Algorithms, techniques, and applications. ACM Computing Surveys (CSUR) \textbf{51}(5), 1--36 (2018)

\bibitem{slack2020fooling}
Slack, D., Hilgard, S., Jia, E., Singh, S., Lakkaraju, H.: Fooling lime and shap: Adversarial attacks on post hoc explanation methods. In: AAAI/ACM Conference on AI, Ethics, and Society, pp. 180--186. (2020)

\bibitem{zhang2019should}
Zhang, Y., Song, K., Sun, Y., Tan, S., Udell, M.: "Why Should You Trust My Explanation?" Understanding Uncertainty in LIME Explanations. arXiv preprint arXiv:1904.12991 (2019)

\bibitem{ray2023chatgpt}
Ray, P.P.: ChatGPT: A comprehensive review on background, applications, key challenges, bias, ethics, limitations and future scope. Internet of Things and Cyber-Physical Systems. Elsevier (2023)

\bibitem{castelvecchi2016can}
Castelvecchi, D.: Can we open the black box of AI? Nature News \textbf{538}(7623), 20 (2016)

\bibitem{guidotti2018survey}
Guidotti, R., Monreale, A., Ruggieri, S., Turini, F., Giannotti, F., Pedreschi, D.: A survey of methods for explaining black box models. ACM Computing Surveys (CSUR) \textbf{51}(5), 1--42 (2018)

\bibitem{yu2023antifake}
Yu, Z., Zhai, S., Zhang, N.: AntiFake: Using Adversarial Audio to Prevent Unauthorized Speech Synthesis. In: ACM SIGSAC Conference on Computer and Communications Security, pp. 460--474. (2023)

\bibitem{arrieta2020explainable}
Arrieta, A.B., Díaz-Rodríguez, N., Del Ser, J., Bennetot, A., Tabik, S., Barbado, A., García, S., Gil-López, S., Molina, D., Benjamins, R., others: Explainable Artificial Intelligence (XAI): Concepts, taxonomies, opportunities and challenges toward responsible AI. Information Fusion \textbf{58}, 82--115 (2020)

\bibitem{stepin2021survey}
Stepin, I., Alonso, J.M., Catala, A., Pereira-Fariña, M.: A survey of contrastive and counterfactual explanation generation methods for explainable artificial intelligence. IEEE Access \textbf{9}, 11974--12001 (2021)

\bibitem{verma2020counterfactual}
Verma, S., Boonsanong, V., Hoang, M., Hines, K.E., Dickerson, J.P., Shah, C.: Counterfactual explanations and algorithmic recourses for machine learning: A review. arXiv preprint arXiv:2010.10596 (2020)

\bibitem{goyal2019counterfactual}
Goyal, Y., Wu, Z., Ernst, J., Batra, D., Parikh, D., Lee, S.: Counterfactual visual explanations. In: International Conference on Machine Learning, pp. 2376--2384. PMLR (2019)

\bibitem{van2008visualizing}
Van der Maaten, L., Hinton, G.: Visualizing data using t-SNE. Journal of Machine Learning Research \textbf{9}(11) (2008)

\bibitem{dong2019variable}
Dong, J., Rudin, C.: Variable importance clouds: A way to explore variable importance for the set of good models. arXiv preprint arXiv:1901.03209 (2019)

\bibitem{shwartz2017opening}
Shwartz-Ziv, R., Tishby, N.: Opening the black box of deep neural networks via information. arXiv preprint arXiv:1703.00810 (2017)

\bibitem{mackiewicz1993principal}
Maćkiewicz, A., Ratajczak, W.: Principal components analysis (PCA). Computers \& Geosciences \textbf{19}(3), 303--342 (1993)

\bibitem{ribeiro2018anchors}
Ribeiro, M.T., Singh, S., Guestrin, C.: Anchors: High-precision model-agnostic explanations. In: AAAI conference on artificial intelligence \textbf{32}(1) (2018)

\bibitem{lundberg2017unified}
Lundberg, S.M., Lee, S.I.: A unified approach to interpreting model predictions. Advances in Neural Information Processing Systems \textbf{30} (2017)

\bibitem{dwivedi2023explainable}
Dwivedi, R., Dave, D., Naik, H., Singhal, S., Omer, R., Patel, P., Qian, B., Wen, Z., Shah, T., Morgan, G., others: Explainable AI (XAI): Core ideas, techniques, and solutions. ACM Computing Surveys \textbf{55}(9), 1--33 (2023)

\bibitem{angelov2020towards}
Angelov, P., Soares, E.: Towards explainable deep neural networks (xDNN). Neural Networks \textbf{130}, 185--194 (2020)

\bibitem{ribeiro2016should}
Ribeiro, M.T., Singh, S., Guestrin, C.: "Why should i trust you?" Explaining the predictions of any classifier. In: ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, pp. 1135--1144. (2016)

\bibitem{miller2023explainable}
Miller, T.: Explainable ai is dead, long live explainable ai! hypothesis-driven decision support. arXiv preprint arXiv:2302.12389 (2023)

\bibitem{jacovi2023trends}
Jacovi, A.: Trends in Explainable AI (XAI) Literature. arXiv preprint arXiv:2301.05433 (2023)

\bibitem{wang2022disentangled}
Wang, X., Chen, H., Tang, S., Wu, Z., Zhu, W.: Disentangled representation learning. arXiv preprint arXiv:2211.11695 (2022)

\bibitem{alzubaidi2021review}
Alzubaidi, L., Zhang, J., Humaidi, A.J., Al-Dujaili, A., Duan, Y., Al-Shamma, O., Santamaría, J., Fadhel, M.A., Al-Amidie, M., Farhan, L.: Review of deep learning: Concepts, CNN architectures, challenges, applications, future directions. Journal of Big Data \textbf{8}, 1--74 (2021)

\bibitem{gunning2019xai}
Gunning, D., Stefik, M., Choi, J., Miller, T., Stumpf, S., Yang, G.Z.: XAI—Explainable artificial intelligence. Science Robotics \textbf{4}(37), eaay7120 (2019)


\end{thebibliography}
