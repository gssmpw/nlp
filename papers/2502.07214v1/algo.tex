Our approach involves handling the minimization of cost for a single edge, which can be analogized to the concept of finding the shortest path. We manage this by maintaining and updating a table to capture the trade-offs among various types of costs. This table is instrumental in recording and managing the interplay of different cost criteria on different paths. In the following, we assume the model $h$ is deterministic but the algorithms and all the analysis can be applied to the stochastic model too.

Users are allowed to decide on the properties of the target instance - counterfactual. Under what circumstances is it considered a successful flip? What would be the criteria for a feasible path? The customized cost functions can be very flexible as long as they are metric functions. After that, the edges of the actionability graph are constructed by iterating through each pair of vertices in the input set $V$, checking if there is a possible action between them, and calculating the multi-cost. Unlike simple graphs, each constructed edge has several costs.

\subsubsection{Algorithm} we use the dynamic programming and modify Bellman-Ford algorithm~\cite{bellman1958routing} to find all the pareto optimal paths. The main goal is to handle the minimum cost within all considered criteria. A hyperparameter $\eta, 1 \leq \eta \leq n-1$ is introduced here to decide the maximum number of edges in a feasible path (i.e., the length of the path in terms of the number of hops). In reality, a path with too many edges may be redundant and hard to interpret. 

\begin{algorithm}
\caption{Pareto-shortest-path}
\label{algo:pareto-shortest}
\begin{algorithmic}[1]
    \Function{Pareto-paths}{$G = \{E,V\}, s$}
        \ForEach {$v \in V$}
        %\For{each $V$ in $G$}
            \State $D^0_v \gets \phi$ \Comment{Initialization}
        \EndFor
        \State$D^0_{s} \gets \{ <0,0,\cdots 0> \}$     
          
        \For{$\ell \gets 1$ to $\eta$}
            \ForEach{$(u,v) \in E$}
                \State update($D^\ell_v, (D^{\ell-1}_u, W_{uv})$) %\Comment{Update path on $\ell$ rounds}
            \EndFor
        \EndFor
        \State \Return $\{D^\eta_t| t\in V \text{ and } h(t)=1\}$
    \EndFunction
\end{algorithmic}
\end{algorithm}

\begin{comment}
\begin{figure}[ht!]
\centering
\includegraphics[width=50mm]{suv.pdf}
\caption{An instance to show use vertex $u$ to relax the multi-cost of the path from $s$ to $v$.}
\label{fig:update operation}
\vspace{0.3cm}
\end{figure}
\end{comment}

Algorithm~\ref{algo:pareto-shortest} computes the shortest paths from a given source vertex to all other vertices in a graph. $D^\ell_v$ denotes the Pareto table of $v$ that represents the set of current Pareto paths in iteration $\ell$ for reaching vertex $v$ from the source vertex. Line 2 to Line 5 are initialize steps. All items in $D^0_v$ are empty except for the source vertex. We set the distance to itself $D^0_s$ as zero for all cost dimensions. Line 6 to Line 11 uses Dynamic Programming to iteratively find all the Pareto paths. It iterates over the vertices excluding the source and conducts a tailored merging process, for each edge $(u, v)$ in the graph, performs the update operation. The update operation extends $D^{\ell-1}_v$ to $D^{\ell}_v$ by first concatenating the distance from the vertex $u$ with the multi-cost $W_{uv}$ and then pruning the dominated path. The concatenating step is the same as the standard operation in Bellman-Ford except each path in $D^{\ell-1}_u$ has multi-cost. The operation time here increased by at most $k$ times. The prune operation is employed to refine the multi-cost estimate of paths in $D^\ell_v$ by comparing the paths between $D_v^{\ell-1}$ and $D_u^{\ell-1}+W_{uv}$ and only record the non-dominated paths into $D_v^{\ell}$. Finally, Line 11 reports all the Pareto paths for all possible recourse points $t$, where $h(t)=1$.


%\todo {whether we need to add table size control}
%Additionally, if the size of the pruned distance list exceeds a specified limit, the prune function further reduces the list by sampling a fixed number of points at equal intervals, preserving the overall shape of the cost curve while limiting its size. This sampling process helps manage the size of the distance lists and ensures efficiency in subsequent calculations.
% Once all edges have been processed, the algorithm returns the list of distance $D$. These distance capture the trade-offs between different cost criteria and can be used for efficient decision-making in various scenarios, such as transportation or communication networks, where multiple cost factors influence path selection.

% \begin{algorithm}
% \caption{Backtracking Algorithm}
% \label{algo:backtracking}
% \begin{algorithmic}[1]
%     \Function{backtracking}{$S, T, D$}
%         \State paths$\gets$[]
%         \For{$u$ belongs to $D_T$}
%             \State path$\gets$[]
%             \State$v \gets T$
%             \While{$v \neq S$}
%                 \State path.add($u$)
%                 \State cost$\gets$get edge cost($v, u$)
%                 \For{each $i$ belongs to $D_u$}
%                     \If{cost $v=$cost$u +$cost}
%                         \State find parent if cost$v ==$cost$u +$cost
%                         \State$v \gets u$
%                         \State$u \gets i$
%                     \EndIf
%                 \EndFor
%             \EndWhile
%             \State paths.add(path)
%         \EndFor
%         \State \Return paths
%     \EndFunction
% \end{algorithmic}
% \end{algorithm}

% \paragraph{Backtracking algorithm(optional)} Algorithm~\ref{algo:backtracking} is used to find paths in a graph from a target vertex back to a source vertex without storing the whole paths but the parent vertex only. This can be space efficient since it reduces $O(n)$ space when running algorithm~\ref{algo:pareto-shortest}. Algorithm~\ref{algo:backtracking} operates by exploring possible paths starting from each vertex in a set of destination vertices $T$, backtracking to the source vertex $s$. For each destination vertex $u$ in the set $T$, the algorithm initiates a search for a path by traversing edges backward from $u$ to $s$. It does so by iterative examining edges and their associated costs, identifying the parent vertex that minimizes the total cost to reach $u$ from $s$. This process continues until the source vertex $s$ is reached. The algorithm then records the discovered path and proceeds to explore paths from other destination vertices. Once all possible paths have been explored, the algorithm returns the collected paths. %This approach is useful for various applications, including finding optimal routes in transportation networks or identifying dependencies in computational tasks.

\subsubsection{Analysis} In Algorithm~\ref{algo:pareto-shortest}, the time complexity analysis involves two main steps: concatenate and prune, which are repeated for at most $\eta$ iterations. Denote $\tau$ as the maximum size among all Pareto tables and $\gamma$ as the maximum degree among all vertices. In the concatenation step, for each vertex $v$, all the incoming neighbors $u$ of $v$ have been concatenated via $w_{uv}$, which takes at most $O(\gamma \tau)$. In the pruning step, $D_v$ is updated to keep the Pareto paths only. This is related to finding the maxima of a point set problem~\cite{preparata2012computational}. Naively, we can check all pairs of paths with each criterion to remove the dominated ones, which takes $O(k\gamma^2 \tau^2)$. However, since we are not taking an arbitrary point set but merging Pareto tables from all the incoming neighbors. During the pruning steps, the Pareto table is maintained via lexicographic orders. Thus, the running time can speed up, depending on the number of the cost functions $k$. When $k=2$, since the first cost is always ordered we can compare the second cost directly, which takes $O(\gamma \tau)$. When $k=3$, one can use basic sorting to remove dominated paths, which takes $O(\gamma \tau \log \gamma \tau)$. This can be further sped up by using the data structure of van Emde Boas tree~\cite{karlsson1988scanline}, takes $O(\gamma \tau \log \log \gamma \tau)$. When $k>3$, one can sort the rest of the criteria with lexicographic order, which increases the time complexity to $O(\gamma \tau \log^{k-4}\log\log \gamma \tau)$~\cite{gabow1984scaling}. Overall, the time complexity of Algorithm~\ref{algo:pareto-shortest} is $O(\gamma \tau \log^{k-4}\log\log \gamma \tau * \eta |E|)$, where $|E|$ represents the number of the edges. 

In reality, the size of the Pareto table $\tau$ is bounded by the number of different paths in the graph, this may vary depending on the specific problem instance and the number of criteria considered. Thus, one may face the scalability issue when the graph is large with high degrees. We address this issue in Section~\ref{sec: scalability} and provide a solution under those circumstances, the correctness of Algorithm~\ref{algo:pareto-shortest} is provided in the full version of this work. 

\begin{comment}
Lastly, let us prove the correctness of Algorithm~\ref{algo:pareto-shortest}. Given a recourse point $t$, we need to establish two key points:

\begin{enumerate}
    \item  All pareto optimal paths from $s$ to $t$ are present in the pareto table $D^\eta_t$.
    \item  All paths in the pareto table $D^\eta_t$ are pareto optimal.
\end{enumerate}

The second statement is clearly true since the prune step is to compare the path one by one and delete the path if it is dominated. To prove the first statement, consider a path $Q$ which is pareto optimal but it is not included in $D^\eta_t$ in the end. If the number of edges in $Q$ is one, in the first iteration it must can be found when examining $(s,t)$ of line 7 and be included in $D^1_t$. It would not be deleted in $D^\ell_t$ in any iteration $\ell, \ell>1$ neither. The reason is that all the cost functions are aggregation functions and each cost only monotonically increase. Thus, if $Q$ is pareto optimal in the end, it is still pareto optimal in any iterations too. Now, assume the statement is true for path $Q$ with the number of edges less than $a,a>1$. Consider the case when path $Q$ with $a+1$ number of edges, say $i$ is the second last point in $Q$. If the subpath $s \rightsquigarrow i$ is not pareto optimal, we must can find one path that dominates this subpath in table $D^{a}_i$ since it records all pareto optimal paths from $s$ to $i$. Thus, by replacing the subpath to the pareto optimal one, we only decrease the cost of $Q$ for any cost function, which shows $Q$ is dominates by this new path, which is a contradiction. On the other hand, If the subpath $s \rightsquigarrow i$ is pareto optimal, it must be included in $D^{a}_i$ and would not be pruned in $D^{a+1}_i$ because the pareto optimality of $Q$. Thus, the first argument is proved by induction.



%\textbf{Convergence property}\\
%If $s \rightsquigarrow u \rightarrow v$ is shortest path in $G$ for some $u,v \in V$ ,and if $u.d = \delta(s,u)$ at any time prior to relaxing $edge(u,v)$, then $v.d = \delta(s,v)$ at all times afterward.\\
\end{comment}
\begin{theorem}
    Algorithm~\ref{algo:pareto-shortest} finds all the Pareto optimal paths from the source to any endpoint $t$, where $h(t)=1$.
\end{theorem}

