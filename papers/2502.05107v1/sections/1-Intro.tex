\section{Introduction}
In recent years, the application of machine learning in drug discovery has gained significant traction~\citep{AIDDsurvey}, achieving substantial advancements in tasks such as molecular property prediction~\citep{PropPred,PropPred2,PropPredSurvey}, protein structure prediction~\citep{AlphaFold2,RoseTTAfold,ESMFold}, and drug molecular design~\citep{Reinvent,AR,ReinforcedGA,MolDesignSurvey,MolDesignSurvey2}. These developments hold the promise of dramatically enhancing the efficiency of drug development processes~\citep{AIDDsurvey2}. Notably, the transformer architecture, which has seen breakthroughs in natural language processing (NLP)~\citep{BERT,GPT-3}, has been successfully adapted for molecular representation learning~\citep{Uni-Mol,DrugClip}, protein-ligand interaction prediction~\citep{PLIntSurvey,AlphaFold3}, and molecular generation tasks~\citep{MolGPT,MolRL-MGPT}.

Structure-based drug discovery (SBDD) is one of the most critical strategies in drug discovery practices, relying on theories of drug-receptor interactions to study the complexes formed between protein pockets and small molecule ligands~\citep{SBDDsurvey}. SBDD encompasses two core tasks: (1) protein-ligand binding pose prediction (docking), which involves predicting the 3D binding conformation of a ligand given the 3D structure of a protein and the 2D representation of the ligand~\citep{DockingSurvey}, and (2) pocket-aware 3D drug design, which entails designing 3D drug molecules that bind well (with low binding energy) to a given pocket target on a protein structure~\citep{SBDDsurvey2,SBDDsurvey3}. These two tasks are inherently dual, and one is predictive, while the other is generative.

However, as of now, the application of machine learning in these two SBDD tasks remains widely recognized as a challenge~\citep{SBDDChallenge}. The accuracy and generalization of protein-ligand docking methods are still unsatisfactory~\citep{DockingChallenge}, and pocket-aware 3D drug design approaches have not achieved obvious improvements by explicitly utilizing 3D structural information compared to 2D methods~\citep{DrugDesignChallenge}. This predicament can be attributed to three primary reasons:
\begin{itemize}[leftmargin=*]
    \item \textbf{Underutilized duality}: Protein-ligand docking and pocket-aware 3D drug design are naturally dual tasks, and improvements in docking performance could directly benefit drug design. However, since these two tasks are different in type (predictive vs. generative), this duality has unfortunately not been leveraged by previous machine learning approaches.
    \item \textbf{Challenges in modeling 3D information}: Modeling 3D information is a key difficulty in SBDD, as protein sequences and small molecule graphs contain only discrete information, whereas 3D coordinates are continuous values. Merging these two modalities of information has proven challenging~\citep{2D+3D}. 
    \item \textbf{Limited data}: Ground-truth data on protein-ligand complexes are scarce. Currently, the largest dataset, PDBbind~\citep{PDBbind}, contains fewer than 20,000 complexes, which is insufficient for training a robust machine learning model.
\end{itemize}

To address these challenges, we propose 3DMolFormer, a unified transformer-based framework for both of the two SBDD tasks. 
First, to fulfill the input-output causal relationships essential for both docking and 3D drug design, we introduce a parallel sequence format to represent a 3D complex of a protein pocket and a small molecule ligand, as shown in Figure~\ref{PocketSeq} and~\ref{LigandSeq}, which comprises a token sequence for discrete protein atoms and small molecule SMILES, alongside a numerical sequence for 3D coordinates.
Subsequently, we construct the 3DMolFormer model based on this parallel sequence, as illustrated in Figure~\ref{Overview}, augmenting the GPT architecture~\citep{GPT-2} with a numerical head corresponding to the token head, enabling the model to be directly applied for autoregressive generation of the parallel sequences.

Due to data limitations, we utilize a "pre-training + fine-tuning" approach~\citep{DeepLearning} in NLP for 3DMolFormer, as large-scale pre-training helps mitigate these data challenges.
During the pre-training phase, the model undergoes large-batch training~\citep{large-batch-training} on a large-scale mixed dataset, which includes data on protein pockets, ligands, and pocket-ligand complexes. A composite loss function is employed for autoregressive training of the parallel sequence, where cross-entropy loss applies to the token sequence and mean squared error loss applies to the numerical sequence. 
For the protein-ligand docking task, we perform supervised fine-tuning on the ground-truth pocket-ligand complexes, using the mean squared error of the numerical sequences corresponding to the ligand's 3D coordinates as the loss function. Moreover, to utilize the duality between the two SBDD tasks, for the pocket-aware drug design task, we apply a regularized maximum likelihood estimation loss for reinforcement learning fine-tuning, and leverage the weights fine-tuned for docking to generate the 3D coordinates of the small molecules.

Experimental results for protein-ligand docking demonstrate that 3DMolFormer outperforms all search-based and deep-learning docking baselines in binding pose prediction accuracy, particularly showing a reduction in samples with large prediction errors. Results for pocket-aware 3D drug design indicate that through a carefully designed composite reward function, 3DMolFormer can generate drug candidates that meet satisfactory levels of binding affinity (docking score), drug-likeness, and synthesizability during the reinforcement learning process, in particular significantly surpassing existing state-of-the-art baselines in terms of binding affinity and success rates in meeting multi-objective criteria. These results reflect the outstanding performance of the 3DMolFormer framework in structure-based drug discovery.

In summary, our main contributions include:
\begin{itemize}[leftmargin=*]
    \item We propose 3DMolFormer, the first unified framework applicable to both protein-ligand docking and pocket-aware 3D drug design.
    \item We design a parallel sequence format for pocket-ligand complexes and establish a dual-channel transformer architecture to autoregressively generate this format, effectively addressing the challenges of modeling 3D information in SBDD.
    \item Through large-scale pre-training and respective fine-tuning, 3DMolFormer outperforms various previous baselines in both SBDD tasks.
\end{itemize}
