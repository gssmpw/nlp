\section{Related Work}
\label{sec:related work}

\subsection{Generative AI-based Data Synthesis}

Recently, many mainstream data synthesis methods have relied on generative AI models, including VAE-based \cite{shi2019variational,  Child2020VeryDV,vahdat2020nvae}, GAN-based \cite{Example-Guided, Controllable_Person, esser2021taming}, and DM-based \cite{kim2023dcface,zhang2023adding,li2024generative,ma2024latte} methods. With the emergence of large generative models such as DALLE-3, Stable Diffusion 3, and Sora, synthetic images and videos have achieved astonishing visual effects regarding diversity and authenticity.

In addition to merely use generative models to synthesize visually appealing images, previous works\cite{gaidon2016virtual,kar2019meta,devaranjan2020meta} have leveraged 3D graphics engines to generate labeled datasets. However, The scene diversity and authenticity of these synthetic datasets are still very limited. To make the scene more realistic, some studies \cite{datasetgan,bigdatasetgan} focus on GAN-based models to produce images via image translation to avoid the domain gap brought by graphics rendering. Inspired by the success of the diffusion model in image generation, recent work has begun to explore its potential in dataset synthesis with pixel-wise labels. DiffuMask \cite{diffumask} automatically obtains synthesized images and semantic masks through text-driven diffusion models. To accommodate various downstream tasks, DatasetDM \cite{datasetdm} employs a pre-trained diffusion model with a multi-task decoder to synthesize different perception annotations. Different from existing generative models designed for RGB data, our work focuses on the generation of higher-dimensional HSI data in the field of remote sensing.

% Different from existing generative models designed for RGB data, the high dimensionality of spectral characteristics makes HSI data synthesis more challenging. In this paper, we focus on the generation of HSI data.

\subsection{Hyperspectral Data Synthesis}
Due to the high-dimensional characteristics of HSI data, generating large-scale datasets has always been an extremely challenging task. Previous works can be roughly divided into three categories: physical simulation based on imaging systems \cite{physics,verrelst2015optical}, augmentation based on affine transformation \cite{affine,zhang2023features,wang2023multistage}, and spectral super-resolution reconstruction \cite{he2023spectral,cai2022mask,cai2022mst++}. These methods provide a feasible solution to the persistent data shortage, while they can not produce truly new samples. 

More recently, some explorers have introduced Diffusion models into HSI data synthesis.
Considering the spectral properties, UnmixDiff \cite{yu2024unmixdiff} has performed the diffusion process in the abundance domain of HSI. Unmixing Before Fusion \cite{yu2024unmixing} has gone one step further and designed a pipeline for synthesizing HSI that couples the multi-source unmixing model and diffusion model, utilizing rich RGB images to guide the model to learn the spatial distribution characteristics of real scenes and improve the diversity of generation. To obtain more precise and reliable HSI data, HSIGene \cite{hsigene} has employed LDM with multiple control conditions. Meanwhile, to enhance the spatial diversity, HSIGene has appended a super-resolution model to achieve data augmentation after the generation. However, the synthetic data obtained by the mentioned approaches above is only suitable for tasks that do not require annotation costs (such as denoising and super-resolution) and some downstream tasks with low manual annotation costs, such as scene classification, which only requires image-level annotations. Different from existing approaches, our work firstly generates joint pairs of HSI data with pixel-wise labels, which can be applicable in dense perception task predictions, such as semantic segmentation and change detection.
% 不同于现有的高光谱数据生成模型只能生成图像，我们的工作还可以生成像素级的语义标签用于下游任务的监督学习

\subsection{Semantic Segmentation and Change Detection}
Semantic segmentation and change detection are typical tasks in the field of HSI remote sensing understanding. The former aims to assign a semantic category to each pixel of an image, while the latter aims to detect changes in objects by using images in different time phases. Compared with natural image datasets, HSI satellite images face unique dilemmas \cite{he2017recent,li2019deep}: relatively small training set compared to the high-dimensional spectra, which adversely affects the performance of segmentation and detection models. 

To address such challenges, many deep learning-based methods \cite{chen2016deep, sun2019hyperspectral} are dedicated to exploring dimensionality reduction or band selection techniques to reduce the impact of redundant information. Although significant progress has been made, the development of these two tasks is severely restricted by the availability of HSI data \cite{li2019deep,liu2019review}. 
% For example, it is necessary to obtain the spectral characteristics of each pixel for change detection in the same scene at different times, but the large-scale HSI data distribution policy for the change detection is still unclear \cite{liu2019review}. At the same time, the dense labels required for these data are difficult to obtain, and manual annotation is costly. 
To alleviate the pressure of annotation, some works \cite{10354413, Gao_2021_CVPR,manas2021seasonal} have explored unsupervised learning, but the performance has significantly declined. Therefore, we propose to directly generate joint image-label pairs through the generative model and verify the effectiveness of the synthetic datasets in improving the accuracy of semantic segmentation and change detection.