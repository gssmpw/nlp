\begin{figure*}[t]
    \centering
    \includegraphics[width=\linewidth]{figs/Approach2.pdf}
    \vspace{-10mm}
    \caption{\textbf{Overview of our approach.} (a) In the \textbf{training} stage, we design a two-stream VAE to compress HSIs and corresponding masks from pixel space to latent space, and then train a denoising U-Net on the joint representations. The latent representation is split to feed forward to corresponding decoders to complete the reconstruction. (b) In the \textbf{inference} stage, after training the generator $\mathcal G$, we start from the noised sample $z_T$ and obtain the synthetic image-mask pairs through decoders, to augment the original real dataset when training the downstream task models.}
    \label{fig:approach}
\end{figure*}
\begin{abstract}
In hyperspectral remote sensing field, some downstream dense prediction tasks, such as semantic segmentation (SS) and change detection (CD), rely on supervised learning to improve model performance and require a large amount of manually annotated data for training. However, due to the needs of specific equipment and special application scenarios, the acquisition and annotation of hyperspectral images (HSIs) are often costly and time-consuming. To this end, our work explores the potential of generative diffusion model in synthesizing HSIs with pixel-level annotations. The main idea is to utilize a two-stream VAE to learn the latent representations of images and corresponding masks respectively, learn their joint distribution during the diffusion model training, and finally obtain the image and mask through their respective decoders. To the best of our knowledge, it is the first work to generate high-dimensional HSIs with annotations. Our proposed approach can be applied in various kinds of dataset generation. We select two of the most widely used dense prediction tasks: semantic segmentation and change detection, and generate datasets suitable for these tasks. Experiments demonstrate that our synthetic datasets have a positive impact on the improvement of these downstream tasks.
\end{abstract}