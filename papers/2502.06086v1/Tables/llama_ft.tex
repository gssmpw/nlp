\begin{table*}[ht!]
\resizebox{\linewidth}{!}{
\begin{tabular}{lccccccccc}
\Xhline{1.2pt} 
&\multicolumn{6}{c}{\textbf{\textsc{Property Induction}}}&\multicolumn{3}{c}{\textbf{\textsc{Noun Phrase Completion}}}\\\cline{2-10}
&\multicolumn{3}{c}{\textbf{(1) \textsc{Emergent}}}&\multicolumn{3}{c}{\textbf{(2) \textsc{Canceled}}}&\multicolumn{3}{c}{\textbf{(3) \textsc{Emergent}}}\\\cline{2-10}
&$R_{\mathcal{H},\mathcal{M},\mathcal{P}}$\downarrow&$R_{\mathcal{N},\mathcal{P}}$\uparrow&$\mathcal{E}$\uparrow&$R_{\mathcal{H},\mathcal{M},\mathcal{P}}$\uparrow&$R_{\mathcal{N},\mathcal{P}}$\downarrow&$\mathcal{C}$\uparrow&$R_{\mathcal{H},\mathcal{M},\mathcal{P}}$\downarrow&$R_{\mathcal{N},\mathcal{P}}$\uparrow&$\mathcal{E}$\uparrow\\\hline
\textbf{\textit{LLaMa-3.1-8B}}&40 $\pm$ 1.3&66 $\pm$ 0.3&33 $\pm$ 0.6&&&&48 $\pm$ 2.5&57 $\pm$ 1.9&18 $\pm$ 1.2 \\
+ QLoRA (NF4, r=16)&41 $\pm$ 0.8&63 $\pm$ 1.7&32 $\pm$ 1.7&&&&57 $\pm$ 2.5&69 $\pm$ 2.7&19 $\pm$ 1.9 \\
+ Full&&&&&&&&& \\\midrule
\textbf{\textit{LLaMa-3.1-70B}}&41 $\pm$ 0.5&81 $\pm$ 0.8&43 $\pm$ 1.1&&&&49 $\pm$ 1.7&68 $\pm$ 1.0&23 $\pm$ 1.2 \\
+ QLoRA (NF4, r=16)&40 $\pm$ 0.5&82 $\pm$ 0.5&45 $\pm$ 0.6&&&&39 $\pm$ 0.2 &66 $\pm$ 1.4&32 $\pm$ 0.5 \\\midrule
\textbf{\textit{Gold}}&25&92&67&92&6&86&25&92&67 \\\Xhline{1.2pt} 
\end{tabular}
}
\caption{Generative results of LLaMA-3.1~\cite{dubey2024llama} baseline models across two sizes are presented for property induction and noun phrase completion tasks. For the full-parameter setting, models are fine-tuned using fp32 precision scaling.}
\label{table:llama_ft}
\vspace{-5mm}
\end{table*}