\section{Introduction}
\label{introduction}
Text-to-image generative models \cite{Rombach_2022_CVPR, Betker2023ImprovingImageGeneration, team2023gemini, esser2024scaling, hurst2024gpt, zhang2023adding, zhang2023text, hintersdorf2024finding} have transformed creative industries by producing detailed visuals from text prompts. However, these models have been found to sometimes memorize and reproduce content from their training data \cite{carlini2023extracting,somepalli2023diffusion, ren2024copyright, wang2024replication, shi2024rlcp, shi2024copyright, zhang2024forget}. This raises significant concerns about copyright infringement, especially when the generated images closely resemble existing copyrighted works. According to U.S. law \cite{roth_greeting_cards_wikipedia}, also referenced by most countries, a work can be considered infringing if it constitutes \textit{substantial similarity} to another work \footnote{Determining infringement also requires proving that the infringer had access to the copyrighted content, which is not the focus of our discussion in this paper.}. Therefore, determining whether AI-generated images infringe on copyright requires a clear and reliable method to compare them with copyrighted materials to identify substantial similarity.

However, identifying substantial similarity is not a trivial task. There are already some methods to assess image similarity through distance-based metrics, e.g., $L_2$ norm \cite{carlini2023extracting}. However, we found that these manually designed metrics do not always align with the human judgment for infringement determination. Additionally, it often suffer from insufficient generalization ability and lack interpretable results. This motivates the need for an approach that better measures substantial similarity, one that is more \textit{human-centered}, \textit{interpretable}, and \textit{generalized} to handle copyright infringement identification in AI-generated images.

 % In practice, courts often adopt an \textit{abstraction test} method \cite{lehman1995intellectual, sid1977krofft}. Specifically,  the works are abstractly deconstructed to exclude elements not protected by copyright, such as public domain expressions (e.g., basic geometric shapes like circles or squares that are commonly used in design) or specific functional expressions (e.g., interface icons like a magnifying glass representing a search function). The remaining unique expressions are then compared for similarity. Ultimately, the results are assessed by the judge based on the test outcomes from multiple individuals. This process requires significant human involvement, and we aim to leverage intelligent agents to assist in the \textit{automated} infringement identification process, thereby reducing the burden on human evaluators.

Recently, large-scale models have already been successfully applied as judges in fields such as finance, education, and healthcare \cite{gu2024survey, li2024llms, zhuge2024agent}. In this paper, we attempt to leverage large vision-language models (LVLMs) to model the practical court decisions on substantial similarity. However, directly applying large models for infringement identification may face unreliable outputs due to their limited comprehension or potential misinterpretation. To address this, we propose \textit{CopyJudge}, an automated abstraction-filtration-comparison framework with multi-LVLM debate to reliably follow the court decision process on identifying substantial similarity. 

Specifically, referring to the software abstraction test \cite{abramson2002promoting}, we decompose the image into different layers or elements, such as composition, color, and theme, to distinguish between the basic concepts of the image and its specific expressions. Then, we filter out parts that are not copyright-protected, such as public and functional expressions. Finally, we compare the filtered portions to assess whether there is substantial similarity. To enhance the reliability of the judgment, we employ a \textit{multi-agent debate} \cite{du2023improving, chan2023chateval} method where multiple LVLMs discuss and score the similarity. Each LVLM can make judgments based on the scores and reasons provided by other LVLMs. Ultimately, another LVLM-based meta-judge gives the final score and rationale based on the consensus of the debate. To enhance the consistency with human preferences, we inject human priors into each LVLM via few-shot demonstrations \cite{agarwal2024many}. 

% We further tested the possibility of exploiting our detection method. We simulate an attacker with a LVLM exploiting the identification results to modify prompts in order to generate images with high infringement scores. We applied our attack on both artwork and cartoon IPs, demonstrating that our method can effectively generate highly similar infringing images that are difficult to detect by existing methods, even under implicit conditions (where sensitive information such as the work's title is not included in the prompt). Additionally, we found that the modified prompts have high transferability, which significantly addresses the high cost issue of previous retrieval-based attack methods \cite{webster2023reproducible, carlini2023extracting}.

Given the judging results, we further explore how to mitigate infringement issues in text-to-image diffusion models. Utilizing our \textit{CopyJudge}, we propose an automated black-box infringement mitigation strategy that leverages a defense LVLM to iteratively optimize the input infringing prompts. This process avoids generating sensitive infringing expressions by querying supporting infringement rationales, while preserving the integrity of the original content. Moreover, if the input latent of the diffusion model is controllable, we could further enhance the mitigation approach by exploring specific non-infringing noise vectors within the latent space in a reinforcement manner, with the reward being reducing the predicted infringement score. This helps avoid infringement while maintaining the desired output characteristics, even without changing the original prompts. 

% Our method has been tested on datasets containing varying degrees of infringement risk, including multilevel similarity and IP resemblance. The results demonstrate that our idenfication approach achieves performance comparable to state-of-the-art methods, but with superior generalization capabilities and better interpretability. Additionally, extensive tests conducted on both open-source and commercial text-to-image models reveal that our method is effective in preventing copyright infringement, requiring only minimal alterations to the original content. 

In summary, our contributions are as follows:
\begin{itemize}
\item We propose \textit{CopyJudge}, an automated abstraction-filtration-comparison framework powered by a multi-LVLM debate mechanism, designed to efficiently detect copyright-infringing images generated by text-to-image diffusion models. 
\item Given the judgment, we introduce an adaptive mitigation strategy that automatically optimizes prompts and explores non-infringing latent noise vectors of diffusion models, effectively mitigating copyright violations while preserving non-infringing expressions.
\item Extensive experiments demonstrate that our identification method matches state-of-the-art performance, with improved generalization and interpretability, while our mitigation approach more effectively prevents infringement without losing non-infringing expressions.
\end{itemize}
