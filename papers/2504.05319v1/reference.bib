@inproceedings{Du_Copilot_24,
	editor = {},
	author = {Du, Changyu and  Nousias, Stavros and  Borrmann, Andr{\'{e}}},
	title = {Towards a copilot in {BIM} authoring tool using large language model based agent for intelligent human-machine interaction},
	booktitle = {Proc. of the 31th Int. Conference on Intelligent Computing in Engineering (EG-ICE)},
	year = {2024},
	month = {Jul},
	volume = {},
	publisher = {},
	organization = {},
	series = {},
	number = {},
	pages = {},
	isbn = {},
	doi = {},
	language = {},
	abstract = {},
	keywords = {BIM; LOCenter; },
	note = {},
	url = {},
}

@inproceedings{Du:2024:command_recommender,
	editor = {},
	author = {Du, C. and  Deng, Z and  Nousias, S and  Borrmann, Andr{\'{e}}},
	title = {Towards commands recommender system in BIM authoring tool using transformers},
	booktitle = {Proc. of the 31th Int. Conference on Intelligent Computing in Engineering (EG-ICE)},
	year = {2024},
	month = {Jul},
	volume = {},
	publisher = {},
	organization = {},
	series = {},
	number = {},
	pages = {},
	isbn = {},
	doi = {},
	language = {},
	abstract = {},
	keywords = {BIM; LOCenter; },
	note = {},
	url = {https://mediatum.ub.tum.de/doc/1743922/1743922.pdf},
}

@article{arm,
  title={Discovery, analysis, and presentation of strong rules},
  author={Piatetsky-Shapiro, Gregory},
  journal={Knowledge Discovery in Data-bases},
  pages={229--248},
  year={1991},
  publisher={AAAI Press}
}

@article{RAG,
  title={Retrieval-augmented generation for knowledge-intensive nlp tasks},
  author={Lewis, Patrick and Perez, Ethan and Piktus, Aleksandra and Petroni, Fabio and Karpukhin, Vladimir and Goyal, Naman and K{\"u}ttler, Heinrich and Lewis, Mike and Yih, Wen-tau and Rockt{\"a}schel, Tim and others},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={9459--9474},
  year={2020}
}

@article{pan2020_log_mining,
title = {BIM log mining: Learning and predicting design commands},
journal = {Automation in Construction},
volume = {112},
pages = {103107},
year = {2020},
issn = {0926-5805},
doi = {https://doi.org/10.1016/j.autcon.2020.103107},
url = {https://www.sciencedirect.com/science/article/pii/S0926580519312701},
author = {Yue Pan and Limao Zhang},
keywords = {BIM, Log data mining, Long short-term memory neural network, Design command prediction},
abstract = {This paper develops a framework to learn and predict design commands based upon building information modeling (BIM) event log data stored in Autodesk Revit journal files, which has the potential to improve the modeling efficiency. BIM design logs, which automatically keep detailed records on the modeling process, are the basis of data acquisition and data mining. Long Short-Term Memory Neural Network (LSTM NN), as a probabilistic deep learning model for learning sequential data with varying lengths from logs, is established to provide designers with predictions about the possible design command class in the next step. To demonstrate the feasibility of this method, a case study runs at large design logs over 4 GB from an international design firm for command class prediction. To begin with, useful data retrieved from logs is cleaned and saved in a 320 MB Comma Separated Values (CSV) file with totally 352,056 lines of commands over 289 projects. Subsequently, various design commands are categorized into 14 classes according to their effects and given numerical labels, which are then fed into LSTM NN for training and testing. As a result, the overall accuracy of this particular case study can reach 70.5% in the test set, which outperforms some classical machine learning methods, like k nearest neighbor, random forest and support vector machine. This research contributes to applying a probabilistic LSTM NN with optimal parameters to learn features from designers' subjective behaviors effectively and predict the next possible design command class intelligently towards automation of the design process. Moreover, the three most possible command classes will be offered as the recommendations under the assumption that the correct class tends to appear owning the top three highest probabilities, which can possibly enhance the reliability of predictions.}
}

@article{DBSCAN2,
  title={DBSCAN revisited, revisited: why and how you should (still) use DBSCAN},
  author={Schubert, Erich and Sander, J{\"o}rg and Ester, Martin and Kriegel, Hans Peter and Xu, Xiaowei},
  journal={ACM Transactions on Database Systems (TODS)},
  volume={42},
  number={3},
  pages={1--21},
  year={2017},
  publisher={Acm New York, NY, USA}
}
@inproceedings{DBSCAN1,
  title={A density-based algorithm for discovering clusters in large spatial databases with noise},
  author={Ester, Martin and Kriegel, Hans-Peter and Sander, J{\"o}rg and Xu, Xiaowei and others},
  booktitle={kdd},
  volume={96},
  number={34},
  pages={226--231},
  year={1996}
}

@article{GPT4,
  title={Gpt-4 technical report},
  author={Achiam, Josh and Adler, Steven and Agarwal, Sandhini and Ahmad, Lama and Akkaya, Ilge and Aleman, Florencia Leoni and Almeida, Diogo and Altenschmidt, Janko and Altman, Sam and Anadkat, Shyamal and others},
  journal={arXiv preprint arXiv:2303.08774},
  year={2023}
}

@article{GoogleTranslate,
  title={Google’s multilingual neural machine translation system: Enabling zero-shot translation},
  author={Johnson, Melvin and Schuster, Mike and Le, Quoc V and Krikun, Maxim and Wu, Yonghui and Chen, Zhifeng and Thorat, Nikhil and Vi{\'e}gas, Fernanda and Wattenberg, Martin and Corrado, Greg and others},
  journal={Transactions of the Association for Computational Linguistics},
  volume={5},
  pages={339--351},
  year={2017},
  publisher={MIT Press One Rogers Street, Cambridge, MA 02142-1209, USA journals-info~…}
}

@article{BPE,
  title={Neural machine translation of rare words with subword units},
  author={Sennrich, Rico},
  journal={arXiv preprint arXiv:1508.07909},
  year={2015}
}

@article{gpt-2,
  title={Language models are unsupervised multitask learners},
  author={Radford, Alec and Wu, Jeffrey and Child, Rewon and Luan, David and Amodei, Dario and Sutskever, Ilya and others},
  journal={OpenAI blog},
  volume={1},
  number={8},
  pages={9},
  year={2019}
}

#---------------------------------------------------------------------------------#

@misc{wang2023multitaskdeeprecommendersystems,
      title={Multi-Task Deep Recommender Systems: A Survey}, 
      author={Yuhao Wang and Ha Tsz Lam and Yi Wong and Ziru Liu and Xiangyu Zhao and Yichao Wang and Bo Chen and Huifeng Guo and Ruiming Tang},
      year={2023},
      eprint={2302.03525},
      archivePrefix={arXiv},
      primaryClass={cs.IR},
      url={https://arxiv.org/abs/2302.03525}, 
}

@article{GAO2021103967,
title = {A data structure for studying 3D modeling design behavior based on event logs},
journal = {Automation in Construction},
volume = {132},
pages = {103967},
year = {2021},
issn = {0926-5805},
doi = {https://doi.org/10.1016/j.autcon.2021.103967},
url = {https://www.sciencedirect.com/science/article/pii/S0926580521004180},
author = {Wen Gao and Chenglin Wu and Weixin Huang and Borong Lin and Xia Su},
keywords = {3D modeling, Architectural design, Process mining, Event log},
abstract = {In recent years, with the increase of large-scale and complex architecture projects, the architecture, engineering and construction (AEC) industries are changing rapidly towards intelligent and databased direction. As the by-product, 3D modeling event logs could provide quantitative and traceable data for early design stages that can produce butterfly-effect on the later construction stages. In this study, new data structure of command-object graph retrieved from 3D modeling event logs was proposed. It reflects the cause-and-effect relationship between commands and objects to accommodate 3D modeling process. A case study was conducted on 110 students' event logs generated from solving a well-defined façade model. As result: an average trial-and-error ratio was calculated at 0.3357 based on original and simplified graphs. Four main types of ‘modeling bubble’ were summarized base on unit-tag graphs. Key commands were found by graph centrality. Auto-prediction of same-group objects was developed with mis-group rate less than 0.9%.}
}

@article{GAO2022104026,
title = {Command prediction based on early 3D modeling design logs by deep neural networks},
journal = {Automation in Construction},
volume = {133},
pages = {104026},
year = {2022},
issn = {0926-5805},
doi = {https://doi.org/10.1016/j.autcon.2021.104026},
url = {https://www.sciencedirect.com/science/article/pii/S0926580521004775},
author = {Wen Gao and Xuanming Zhang and Qiushi He and Borong Lin and Weixin Huang},
keywords = {Process mining, Machine learning, Architectural design, BIM logs},
abstract = {Command prediction based on BIM logs is an important computer-aided design (CAD) method to help avoiding design errors especially on early design stages in architecture, engineering and construction (AEC). On this issue, methods for data preprocessing, predictive model training and model evaluation are three primary questions to answer. In this study, a data augmentation method is developed to prepare high quality data input for 3D modeling event logs. A standard Transformer model is trained with the augmented data as input. Six predictive models on three different input data are compared for evaluating the method. In this case, the most accurate of the six models is Transformer with 94% accuracy on top one command prediction. As results, the data augmentation method proposed in this study improves the accuracy of the predictive models up to 1.75 times. Intelligent CAD tool for command prediction with high accuracy during 3D modeling design can be further developed.}
}

@article{JANG2023102079,
title = {Lexicon-based content analysis of BIM logs for diverse BIM log mining use cases},
journal = {Advanced Engineering Informatics},
volume = {57},
pages = {102079},
year = {2023},
issn = {1474-0346},
doi = {https://doi.org/10.1016/j.aei.2023.102079},
url = {https://www.sciencedirect.com/science/article/pii/S1474034623002070},
author = {Suhyung Jang and Ghang Lee and Sanghyun Shin and Hyunsung Roh},
keywords = {building information modeling (BIM), BIM log mining, BIM log, Lexicon-based content analysis, Supportability},
abstract = {This study conducted a lexicon-based content analysis of building information modeling (BIM) logs from four major BIM authoring tools and four custom-developed BIM loggers to understand whether the BIM logs satisfy the information requirements for various BIM log mining use cases, as well as to assess their potential for future development and research. First, through a critical review of previous studies, 19 different ways of using BIM logs were identified, including authoring and collaborative pattern discovery, authoring process modeling, collaboration pattern analysis, command predictions, and team optimization; however, most of the uses concerned process discovery. The analysis also revealed that BIM log mining has mainly been used for the design phase, with a few examples of being used for the construction phase. For BIM log mining, various techniques ranging from simple frequency analyses via social network analyses to advanced pattern discovery were deployed. In terms of BIM log sources, native BIM logs from Revit were dominantly used almost in all studies, aside from a few studies that used custom-developed BIM logs. The content analysis of BIM logs showed that the contents of native BIM logs provided by major BIM authoring tools varied, but commonly lacked model-element-specific information; this limitation prevents in-depth analyses of BIM processes. Overall, the current disproportionate focus on process discovery in the design phase of BIM log mining suggests that the application of BIM log mining is still in its early stages and holds significant potential for other project phases if adding model-element-specific information is incorporated.}
}

@article{LSTM,
author = {Hochreiter, Sepp and Schmidhuber, J\"{u}rgen},
title = {Long Short-Term Memory},
year = {1997},
issue_date = {November 15, 1997},
publisher = {MIT Press},
address = {Cambridge, MA, USA},
volume = {9},
number = {8},
issn = {0899-7667},
url = {https://doi.org/10.1162/neco.1997.9.8.1735},
doi = {10.1162/neco.1997.9.8.1735},
abstract = {Learning to store information over extended time intervals by recurrent backpropagation takes a very long time, mostly because of insufficient, decaying error backflow. We briefly review Hochreiter's (1991) analysis of this problem, then address it by introducing a novel, efficient, gradient based method called long short-term memory (LSTM). Truncating the gradient where this does not do harm, LSTM can learn to bridge minimal time lags in excess of 1000 discrete-time steps by enforcing constant error flow through constant error carousels within special units. Multiplicative gate units learn to open and close access to the constant error flow. LSTM is local in space and time; its computational complexity per time step and weight is O. 1. Our experiments with artificial data involve local, distributed, real-valued, and noisy pattern representations. In comparisons with real-time recurrent learning, back propagation through time, recurrent cascade correlation, Elman nets, and neural sequence chunking, LSTM leads to many more successful runs, and learns much faster. LSTM also solves complex, artificial long-time-lag tasks that have never been solved by previous recurrent network algorithms.},
journal = {Neural Comput.},
month = nov,
pages = {1735–1780},
numpages = {46}
}

@article{GRU,
  title={Empirical evaluation of gated recurrent neural networks on sequence modeling},
  author={Chung, Junyoung and Gulcehre, Caglar and Cho, KyungHyun and Bengio, Yoshua},
  journal={arXiv preprint arXiv:1412.3555},
  year={2014}
}

@inproceedings{transformer,
 author = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, \L ukasz and Polosukhin, Illia},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {I. Guyon and U. Von Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {Attention is All you Need},
 url = {https://proceedings.neurips.cc/paper_files/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf},
 volume = {30},
 year = {2017}
}

@inproceedings{CommunityCommands,
author = {Matejka, Justin and Li, Wei and Grossman, Tovi and Fitzmaurice, George},
title = {CommunityCommands: command recommendations for software applications},
year = {2009},
isbn = {9781605587455},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1622176.1622214},
doi = {10.1145/1622176.1622214},
abstract = {We explore the use of modern recommender system technology to address the problem of learning software applications. Before describing our new command recommender system, we first define relevant design considerations. We then discuss a 3 month user study we conducted with professional users to evaluate our algorithms which generated customized recommendations for each user. Analysis shows that our item-based collaborative filtering algorithm generates 2.1 times as many good suggestions as existing techniques. In addition we present a prototype user interface to ambiently present command recommendations to users, which has received promising initial user feedback.},
booktitle = {Proceedings of the 22nd Annual ACM Symposium on User Interface Software and Technology},
pages = {193–202},
numpages = {10},
keywords = {recommender},
location = {Victoria, BC, Canada},
series = {UIST '09}
}

@inproceedings{ijcai2019p883,
  title     = {Sequential Recommender Systems: Challenges, Progress and Prospects},
  author    = {Wang, Shoujin and Hu, Liang and Wang, Yan and Cao, Longbing and Sheng, Quan Z. and Orgun, Mehmet},
  booktitle = {Proceedings of the Twenty-Eighth International Joint Conference on
               Artificial Intelligence, {IJCAI-19}},
  publisher = {International Joint Conferences on Artificial Intelligence Organization},
  pages     = {6332--6338},
  year      = {2019},
  month     = {7},
  doi       = {10.24963/ijcai.2019/883},
  url       = {https://doi.org/10.24963/ijcai.2019/883},
}

@inproceedings{t4rec,
author = {de Souza Pereira Moreira, Gabriel and Rabhi, Sara and Lee, Jeong Min and Ak, Ronay and Oldridge, Even},
title = {Transformers4Rec: Bridging the Gap between NLP and Sequential / Session-Based Recommendation},
year = {2021},
isbn = {9781450384582},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3460231.3474255},
doi = {10.1145/3460231.3474255},
abstract = {Much of the recent progress in sequential and session-based recommendation has been driven by improvements in model architecture and pretraining techniques originating in the field of Natural Language Processing. Transformer architectures in particular have facilitated building higher-capacity models and provided data augmentation and training techniques which demonstrably improve the effectiveness of sequential recommendation. But with a thousandfold more research going on in NLP, the application of transformers for recommendation understandably lags behind. To remedy this we introduce Transformers4Rec, an open-source library built upon HuggingFace’s Transformers library with a similar goal of opening up the advances of NLP based Transformers to the recommender system community and making these advancements immediately accessible for the tasks of sequential and session-based recommendation. Like its core dependency, Transformers4Rec is designed to be extensible by researchers, simple for practitioners, and fast and robust in industrial deployments. In order to demonstrate the usefulness of the library and the applicability of Transformer architectures in next-click prediction for user sessions, where sequence lengths are much shorter than those commonly found in NLP, we have leveraged Transformers4Rec to win two recent session-based recommendation competitions. In addition, we present in this paper the first comprehensive empirical analysis comparing many Transformer architectures and training approaches for the task of session-based recommendation. We demonstrate that the best Transformer architectures have superior performance across two e-commerce datasets while performing similarly to the baselines on two news datasets. We further evaluate in isolation the effectiveness of the different training techniques used in causal language modeling, masked language modeling, permutation language modeling and replacement token detection for a single Transformer architecture, XLNet. We establish that training XLNet with replacement token detection performs well across all datasets. Finally, we explore techniques to include side information such as item and user context features in order to establish best practices and show that the inclusion of side information uniformly improves recommendation performance. Transformers4Rec library is available at https://github.com/NVIDIA-Merlin/Transformers4Rec/},
booktitle = {Proceedings of the 15th ACM Conference on Recommender Systems},
pages = {143–153},
numpages = {11},
location = {Amsterdam, Netherlands},
series = {RecSys '21}
}


@inproceedings{devlin-etal-2019-bert,
    title = "{BERT}: Pre-training of Deep Bidirectional Transformers for Language Understanding",
    author = "Devlin, Jacob  and
      Chang, Ming-Wei  and
      Lee, Kenton  and
      Toutanova, Kristina",
    editor = "Burstein, Jill  and
      Doran, Christy  and
      Solorio, Thamar",
    booktitle = "Proceedings of the 2019 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)",
    month = jun,
    year = "2019",
    address = "Minneapolis, Minnesota",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/N19-1423/",
    doi = "10.18653/v1/N19-1423",
    pages = "4171--4186",
    abstract = "We introduce a new language representation model called BERT, which stands for Bidirectional Encoder Representations from Transformers. Unlike recent language representation models (Peters et al., 2018a; Radford et al., 2018), BERT is designed to pre-train deep bidirectional representations from unlabeled text by jointly conditioning on both left and right context in all layers. As a result, the pre-trained BERT model can be fine-tuned with just one additional output layer to create state-of-the-art models for a wide range of tasks, such as question answering and language inference, without substantial task-specific architecture modifications. BERT is conceptually simple and empirically powerful. It obtains new state-of-the-art results on eleven natural language processing tasks, including pushing the GLUE score to 80.5 (7.7 point absolute improvement), MultiNLI accuracy to 86.7{\%} (4.6{\%} absolute improvement), SQuAD v1.1 question answering Test F1 to 93.2 (1.5 point absolute improvement) and SQuAD v2.0 Test F1 to 83.1 (5.1 point absolute improvement)."
}

@article{T5,
  author  = {Colin Raffel and Noam Shazeer and Adam Roberts and Katherine Lee and Sharan Narang and Michael Matena and Yanqi Zhou and Wei Li and Peter J. Liu},
  title   = {Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer},
  journal = {Journal of Machine Learning Research},
  year    = {2020},
  volume  = {21},
  number  = {140},
  pages   = {1--67},
  url     = {http://jmlr.org/papers/v21/20-074.html}
}

@article{openai2024embedding,
  title={New embedding models and API updates},
  author={{OpenAI}},
  year={2024},
  month={January},
  url={https://openai.com/index/new-embedding-models-and-api-updates/}
}

@misc{zhang2023advanceschallengesmultitasklearning,
      title={Advances and Challenges of Multi-task Learning Method in Recommender System: A Survey}, 
      author={Mingzhu Zhang and Ruiping Yin and Zhen Yang and Yipeng Wang and Kan Li},
      year={2023},
      eprint={2305.13843},
      archivePrefix={arXiv},
      primaryClass={cs.IR},
      url={https://arxiv.org/abs/2305.13843}, 
}

@ARTICLE{focal_loss,
  author={Lin, Tsung-Yi and Goyal, Priya and Girshick, Ross and He, Kaiming and Dollár, Piotr},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence}, 
  title={Focal Loss for Dense Object Detection}, 
  year={2020},
  volume={42},
  number={2},
  pages={318-327},
  keywords={Detectors;Training;Object detection;Entropy;Proposals;Convolutional neural networks;Feature extraction;Computer vision;object detection;machine learning;convolutional neural networks},
  doi={10.1109/TPAMI.2018.2858826}}

@misc{jiang2023mistral7b,
      title={Mistral 7B}, 
      author={Albert Q. Jiang and Alexandre Sablayrolles and Arthur Mensch and Chris Bamford and Devendra Singh Chaplot and Diego de las Casas and Florian Bressand and Gianna Lengyel and Guillaume Lample and Lucile Saulnier and Lélio Renard Lavaud and Marie-Anne Lachaux and Pierre Stock and Teven Le Scao and Thibaut Lavril and Thomas Wang and Timothée Lacroix and William El Sayed},
      year={2023},
      eprint={2310.06825},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2310.06825}, 
}

@misc{grattafiori2024llama3herdmodels,
      title={The Llama 3 Herd of Models}, 
      author={Aaron Grattafiori et al.},
      year={2024},
      eprint={2407.21783},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2407.21783}, 
}

@misc{su2023roformerenhancedtransformerrotary,
      title={RoFormer: Enhanced Transformer with Rotary Position Embedding}, 
      author={Jianlin Su and Yu Lu and Shengfeng Pan and Ahmed Murtadha and Bo Wen and Yunfeng Liu},
      year={2023},
      eprint={2104.09864},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2104.09864}, 
}

@inbook{rmsnorm,
author = {Zhang, Biao and Sennrich, Rico},
title = {Root mean square layer normalization},
year = {2019},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {Layer normalization (LayerNorm) has been successfully applied to various deep neural networks to help stabilize training and boost model convergence because of its capability in handling re-centering and re-scaling of both inputs and weight matrix. However, the computational overhead introduced by LayerNorm makes these improvements expensive and significantly slows the underlying network, e.g. RNN in particular. In this paper, we hypothesize that re-centering invariance in LayerNorm is dispensable and propose root mean square layer normalization, or RMSNorm. RMSNorm regularizes the summed inputs to a neuron in one layer according to root mean square (RMS), giving the model re-scaling invariance property and implicit learning rate adaptation ability. RMSNorm is computationally simpler and thus more efficient than LayerNorm. We also present partial RMSNorm, or pRMSNorm where the RMS is estimated from p\% of the summed inputs without breaking the above properties. Extensive experiments on several tasks using diverse network architectures show that RMSNorm achieves comparable performance against LayerNorm but reduces the running time by 7\%~64\% on different models. Source code is available at https://github.com/bzhangGo/rmsnorm.},
booktitle = {Proceedings of the 33rd International Conference on Neural Information Processing Systems},
articleno = {1110},
numpages = {12}
}

@misc{shazeer2020gluvariantsimprovetransformer,
      title={GLU Variants Improve Transformer}, 
      author={Noam Shazeer},
      year={2020},
      eprint={2002.05202},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2002.05202}, 
}

@misc{hendrycks2023gaussianerrorlinearunits,
      title={Gaussian Error Linear Units (GELUs)}, 
      author={Dan Hendrycks and Kevin Gimpel},
      year={2023},
      eprint={1606.08415},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/1606.08415}, 
}

@inproceedings{10.5555/3157382.3157612,
author = {Goyal, Anirudh and Lamb, Alex and Zhang, Ying and Zhang, Saizheng and Courville, Aaron and Bengio, Yoshua},
title = {Professor forcing: a new algorithm for training recurrent networks},
year = {2016},
isbn = {9781510838819},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {The Teacher Forcing algorithm trains recurrent networks by supplying observed sequence values as inputs during training and using the network's own one-step-ahead predictions to do multi-step sampling. We introduce the Professor Forcing algorithm, which uses adversarial domain adaptation to encourage the dynamics of the recurrent network to be the same when training the network and when sampling from the network over multiple time steps. We apply Professor Forcing to language modeling, vocal synthesis on raw waveforms, handwriting generation, and image generation. Empirically we find that Professor Forcing acts as a regularizer, improving test likelihood on character level Penn Treebank and sequential MNIST. We also find that the model qualitatively improves samples, especially when sampling for a large number of time steps. This is supported by human evaluation of sample quality. Trade-offs between Professor Forcing and Scheduled Sampling are discussed. We produce T-SNEs showing that Professor Forcing successfully makes the dynamics of the network during training and sampling more similar.},
booktitle = {Proceedings of the 30th International Conference on Neural Information Processing Systems},
pages = {4608–4616},
numpages = {9},
location = {Barcelona, Spain},
series = {NIPS'16}
}

@article{10.1145/1970378.1970380,
author = {Li, Wei and Matejka, Justin and Grossman, Tovi and Konstan, Joseph A. and Fitzmaurice, George},
title = {Design and evaluation of a command recommendation system for software applications},
year = {2011},
issue_date = {June 2011},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {18},
number = {2},
issn = {1073-0516},
url = {https://doi.org/10.1145/1970378.1970380},
doi = {10.1145/1970378.1970380},
abstract = {We examine the use of modern recommender system technology to aid command awareness in complex software applications. We first describe our adaptation of traditional recommender system algorithms to meet the unique requirements presented by the domain of software commands. A user study showed that our item-based collaborative filtering algorithm generates 2.1 times as many good suggestions as existing techniques. Motivated by these positive results, we propose a design space framework and its associated algorithms to support both global and contextual recommendations. To evaluate the algorithms, we developed the CommunityCommands plug-in for AutoCAD. This plug-in enabled us to perform a 6-week user study of real-time, within-application command recommendations in actual working environments. We report and visualize command usage behaviors during the study, and discuss how the recommendations affected users behaviors. In particular, we found that the plug-in successfully exposed users to new commands, as unique commands issued significantly increased.},
journal = {ACM Trans. Comput.-Hum. Interact.},
month = jul,
articleno = {6},
numpages = {35},
keywords = {command recommender system, Collaborative filtering}
}

@mastersthesis{radnia2021sequence,
  title={Sequence Prediction Applied to BIM Log Data, an Approach to Develop a Command Recommender System for BIM Software Application},
  author={Radnia, Ashkan},
  year={2021},
  school={The University of North Carolina at Charlotte}
}

@article{PAN2022101758,
title = {Modeling and analyzing dynamic social networks for behavioral pattern discovery in collaborative design},
journal = {Advanced Engineering Informatics},
volume = {54},
pages = {101758},
year = {2022},
issn = {1474-0346},
doi = {https://doi.org/10.1016/j.aei.2022.101758},
url = {https://www.sciencedirect.com/science/article/pii/S1474034622002166},
author = {Yue Pan and Limao Zhang},
keywords = {Dynamic social network analysis (SNA), Building Information Modeling (BIM), Collaborative pattern discovery, Node influence measurement, Human behavior evaluation},
abstract = {As a newly-developed information exchange and management platform, Building Information Modeling (BIM) is altering the way of collaboration among multi-engineers for civil engineering projects. During the BIM implementation, a large number of event logs are automatically generated and accumulated to record details of the model evolution. For knowledge discovery from huge logs, a novel BIM event log mining approach based on the dynamic social network analysis is presented to examine designers’ performance objectively, which has been verified in BIM event logs about an ongoing year-long design project. Relying on meaningful information extracted from time-stamped logs, networks on the monthly interval are built to graphically represent information and knowledge sharing among designers. Special emphasis is put on measuring designers’ influence by a defined new metric called “impact score”, which combines the k-shell method and 1-step neighbors to achieve comparatively low computational cost and high accurate ranking. Besides, an emerging machine learning algorithm named CatBoost is utilized to predict designers’ influence intelligently by learning features from both network structure and human behavior. It has been found that twelve networks can be easily distinguished into two collaborative patterns, whose characteristics in both network structures and designers’ behaviors are significantly different. The most influential designers are similar within the same group but varied from different groups. Extensive analytical results confirm that the method can potentially serve as month-by-month feedback to monitor the complex modeling process, which further supports managers to realize data-driven decision making for better leadership and work plan towards an optimized collaborative design.}
}

@article{GAO2023104804,
title = {Impact of 3D modeling behavior patterns on the creativity of sustainable building design through process mining},
journal = {Automation in Construction},
volume = {150},
pages = {104804},
year = {2023},
issn = {0926-5805},
doi = {https://doi.org/10.1016/j.autcon.2023.104804},
url = {https://www.sciencedirect.com/science/article/pii/S092658052300064X},
author = {Wen Gao and Shuai Lu and Xuanming Zhang and Qiushi He and Weixin Huang and Borong Lin},
keywords = {Design performance, Process mining, Event data, Machine learning},
abstract = {Study area of process mining exhibits great potential in explaining the design performance and behavior pattern in architecture, engineering and construction industries based on event data. However, research into creativity-related behavior pattern in sustainable building design through process mining remains blank. With the global climate change and energy crisis, creativity-driven problem-solving design process is becoming crucial. Based on >41-million lines of event data from 115 participants from a green building design competition, this study explored four dimensions on creative design behavioral pattern: 1) frequently used commands; 2) frequently used objects; 3) duration of used commands and 4) experience with the tool. Secondly, this study establishes and trains artificial neural network models according to the four dimensions to evaluate level of creativity of design works. Training results prove the effectiveness of the discoveries and realize a preliminary screening on creativity for large amount of data in sustainable building design.}
}

@article{YARMOHAMMADI201717,
title = {Mining implicit 3D modeling patterns from unstructured temporal BIM log text data},
journal = {Automation in Construction},
volume = {81},
pages = {17-24},
year = {2017},
issn = {0926-5805},
doi = {https://doi.org/10.1016/j.autcon.2017.04.012},
url = {https://www.sciencedirect.com/science/article/pii/S0926580516302825},
author = {Saman Yarmohammadi and Reza Pourabolghasem and Daniel Castro-Lacouture},
keywords = {Building information modeling, Data mining, Sequential pattern analysis, Design log files, Performance management},
abstract = {Building information modeling is instrumental in documenting design, enhancing customer experience, and improving product functionality in capital projects. However, good building models do not happen by accident, but rather as a result of a managed process that involves several participants from different disciplines and backgrounds. Effective management of this process requires an ability to closely monitor the modeling process and correctly measure modelers' performance. Nevertheless, existing methods of performance monitoring in building design practices lack an objective measurement system to quantify modeling progress. The widespread utilization of Building Information Modeling (BIM) tools presents a unique opportunity to retrieve granular design process data and conduct accurate performance measurements. As a building's 3D model is gradually developed, model generation software packages, such as Autodesk Revit, automatically create log files that record design activities. This paper investigates what information these log files contain and how one can extract and further analyze the information to provide insight into the design modeling process. The specific objectives of this study were to: (1) investigate the presence of implicit patterns in 3-D design log files; and (2) to empirically characterize the performance of modelers based on the time it takes them to execute similar modeling tasks. To fulfill these objectives, design log files provided by an international architecture and design firm were analyzed. Using a tailored text file parser, user-model interaction data including modeler characteristics, command type, and command time were extracted from the journal files. To identify implicit command execution patterns, a sequence mining algorithm based on Generalized Suffix Trees (GST) was implemented. It was shown that there is a statistically significant difference between the average time it takes modelers to execute each command sequence. This study extends the existing knowledge by proposing a novel methodology to extract meaningful patterns from time-stamped unstructured design log data. This research contributes to the state of practice by providing a better understanding of information embedded in design log files.}
}

@article{PAN2020102997,
title = {BIM log mining: Exploring design productivity characteristics},
journal = {Automation in Construction},
volume = {109},
pages = {102997},
year = {2020},
issn = {0926-5805},
doi = {https://doi.org/10.1016/j.autcon.2019.102997},
url = {https://www.sciencedirect.com/science/article/pii/S0926580519308040},
author = {Yue Pan and Limao Zhang},
keywords = {Building information modeling, Log data mining, Efficient fuzzy Kohonen clustering network (EFKCN)},
abstract = {A clustering-based building information modeling (BIM) log mining method is developed in this research to provide a data-driven knowledge discovery about the design productivity characteristics from a huge amount of BIM design log data. Since design behaviors are non-deterministic and subjective, a novel clustering algorithm named efficient fuzzy Kohonen clustering network (EFKCN) is utilized to produce informative clusters of different features. First, datasets are pulled out from the raw design logs and transformed into understandable forms for computers. Then, EFKCN clustering algorithm is performed in datasets at both individual and team level. Finally, analysis and prediction methods, like time analysis, regression and others, will further investigate the extracted clusters, which help managers to figure out the design preference and productivity of different designers. A case study is conducted in the real BIM design logs from an international architecture design firm with 853,520 records to illustrate the effectiveness of the proposed method. From a view of individuals, the personal design behaviors hidden in different clusters are served to arrange proper design work rationally during particular time periods. From a team perspective, the design productivity of different designers can be approximately evaluated as high, medium, and low levels in an objective and efficient manner. In the comparison of EFKCN with other popular clustering methods, EFKCN takes less time and iterations to complete the clustering process, and its clustering results achieve great compactness and separation according to the value of cluster validity indices (CVIs). Hence, this research contributes to performing the novel clustering-based BIM log mining, which acts as a powerful decision-making tool in evaluating design productivity and drawing up personalized work arrangements for a more efficient modeling process.}
}

@article{ZHANG201831,
title = {BIM log mining: Discovering social networks},
journal = {Automation in Construction},
volume = {91},
pages = {31-43},
year = {2018},
issn = {0926-5805},
doi = {https://doi.org/10.1016/j.autcon.2018.03.009},
url = {https://www.sciencedirect.com/science/article/pii/S0926580517308178},
author = {Limao Zhang and Baabak Ashuri},
keywords = {Social network, BIM, Log mining, Collaborative design, Revit, Production},
abstract = {This research develops a systematic methodology to deeply mine tremendous volumes of design logs (that are generated from Building Information Model (BIM) design process) to discover social networks in BIM-based collaborative design practices and examine the relationship between the characteristics of the design social network and production performance of designers. Firstly, a data extraction procedure consisting of data harvesting, parsing, and cleaning is proposed to obtain BIM design logs in a Comma Separated Values (CSV) format from several designers over the course of working on multiple projects. Secondly, a metric of working together on joint cases is proposed to build up a weighted sociogram that is consisting of performers P, relations R, and weights W. Lastly, a number of indicators are defined to measure and analyze structural characteristics of the discovered BIM-based collaborative network at macro-, meso-, and micro- levels. A dataset of design logs that involves 51 designers working on 82 projects with 620,492 lines of commands, provided by a major international design firm, is used as a case study to demonstrate the feasibility and applicability of the developed approach in this research. Results indicate that: (i) Strong positive correlations exist across all centrality measures calculated based on the discovered social network of BIM-based collaborative design where designers located in the center of the interaction map (with the greatest degree centralities), such as designers “#2” and “#24”, are generally those who provide the shortest communication channels (with highest betweenness centralities) and are most reachable for others (with highest closeness centralities); and (ii) All the node centrality measures are significantly and positively related to the production performance of designers in the BIM-based collaborative network. Particularly, the measured node degree centrality by weight is capable of explaining the greatest percentage of variations (71.13%) in the production performance of designers. This research contributes to: (a) The state of knowledge by proposing a novel methodology that is capable of capturing and modeling collaborations among designers from tremendous event logs to discover social networks; and (b) The state of practice by providing insight into a better understanding of relationships between sociological network characteristics and production performance of designers within a design firm.}
}


@inproceedings{10.1145/3357384.3357895,
author = {Sun, Fei and Liu, Jun and Wu, Jian and Pei, Changhua and Lin, Xiao and Ou, Wenwu and Jiang, Peng},
title = {BERT4Rec: Sequential Recommendation with Bidirectional Encoder Representations from Transformer},
year = {2019},
isbn = {9781450369763},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3357384.3357895},
doi = {10.1145/3357384.3357895},
abstract = {Modeling users' dynamic preferences from their historical behaviors is challenging and crucial for recommendation systems. Previous methods employ sequential neural networks to encode users' historical interactions from left to right into hidden representations for making recommendations. Despite their effectiveness, we argue that such left-to-right unidirectional models are sub-optimal due to the limitations including: begin enumerate* [label=seriesitshapealph*upshape)] item unidirectional architectures restrict the power of hidden representation in users' behavior sequences; item they often assume a rigidly ordered sequence which is not always practical. end enumerate* To address these limitations, we proposed a sequential recommendation model called BERT4Rec, which employs the deep bidirectional self-attention to model user behavior sequences. To avoid the information leakage and efficiently train the bidirectional model, we adopt the Cloze objective to sequential recommendation, predicting the random masked items in the sequence by jointly conditioning on their left and right context. In this way, we learn a bidirectional representation model to make recommendations by allowing each item in user historical behaviors to fuse information from both left and right sides. Extensive experiments on four benchmark datasets show that our model outperforms various state-of-the-art sequential models consistently.},
booktitle = {Proceedings of the 28th ACM International Conference on Information and Knowledge Management},
pages = {1441–1450},
numpages = {10},
keywords = {bidirectional sequential model, cloze, sequential recommendation},
location = {Beijing, China},
series = {CIKM '19}
}

@inproceedings{10.1145/3523227.3546777,
author = {Rashed, Ahmed and Elsayed, Shereen and Schmidt-Thieme, Lars},
title = {Context and Attribute-Aware Sequential Recommendation via Cross-Attention},
year = {2022},
isbn = {9781450392785},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3523227.3546777},
doi = {10.1145/3523227.3546777},
abstract = {In sparse recommender settings, users’ context and item attributes play a crucial role in deciding which items to recommend next. Despite that, recent works in sequential and time-aware recommendations usually either ignore both aspects or only consider one of them, limiting their predictive performance. In this paper, we address these limitations by proposing a context and attribute-aware recommender model (CARCA) that can capture the dynamic nature of the user profiles in terms of contextual features and item attributes via dedicated multi-head self-attention blocks that extract profile-level features and predict item scores. Also, unlike many of the current state-of-the-art sequential item recommendation approaches that use a simple dot-product between the most recent item’s latent features and the target items embeddings for scoring, CARCA uses cross-attention between all profile items and the target items to predict their final scores. This cross-attention allows CARCA to harness the correlation between old and recent items in the user profile and their influence on deciding which item to recommend next. Experiments on four real-world recommender system datasets show that the proposed model significantly outperforms all state-of-the-art models in the task of item recommendation and achieving improvements of up to 53\% in Normalized Discounted Cumulative Gain (NDCG) and Hit-Ratio. Results also show that CARCA outperformed several state-of-the-art dedicated image-based recommender systems by merely utilizing image attributes extracted from a pre-trained ResNet50 in a black-box fashion.},
booktitle = {Proceedings of the 16th ACM Conference on Recommender Systems},
pages = {71–80},
numpages = {10},
keywords = {Attribute-Aware Recommendation, Context-Aware Recommendation, Cross Multi-Head Attention, Sequential Recommendation},
location = {Seattle, WA, USA},
series = {RecSys '22}
}

@inbook{xlnet,
author = {Yang, Zhilin and Dai, Zihang and Yang, Yiming and Carbonell, Jaime and Salakhutdinov, Ruslan and Le, Quoc V.},
title = {XLNet: generalized autoregressive pretraining for language understanding},
year = {2019},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {With the capability of modeling bidirectional contexts, denoising autoencoding based pretraining like BERT achieves better performance than pretraining approaches based on autoregressive language modeling. However, relying on corrupting the input with masks, BERT neglects dependency between the masked positions and suffers from a pretrain-finetune discrepancy. In light of these pros and cons, we propose XLNet, a generalized autoregressive pretraining method that (1) enables learning bidirectional contexts by maximizing the expected likelihood over all permutations of the factorization order and (2) overcomes the limitations of BERT thanks to its autoregressive formulation. Furthermore, XLNet integrates ideas from Transformer-XL, the state-of-the-art autoregressive model, into pretraining. Empirically, under comparable experiment setting, XLNet outperforms BERT on 20 tasks, often by a large margin, including question answering, natural language inference, sentiment analysis, and document ranking.},
booktitle = {Proceedings of the 33rd International Conference on Neural Information Processing Systems},
articleno = {517},
numpages = {11}
}

@INPROCEEDINGS{8594844,
  author={Kang, Wang-Cheng and McAuley, Julian},
  booktitle={2018 IEEE International Conference on Data Mining (ICDM)}, 
  title={Self-Attentive Sequential Recommendation}, 
  year={2018},
  volume={},
  number={},
  pages={197-206},
  keywords={Adaptation models;Context modeling;Task analysis;Recommender systems;Markov processes;Recurrent neural networks;Predictive models;Sequential Recommendation;Collaborative Filtering},
  doi={10.1109/ICDM.2018.00035}}

@article{sanseviero2023mixture,
  author       = {Sanseviero, Omar and Tunstall, Leandro and Schmid, Patrick and Mangrulkar, Suraj and Belkada, Younes and Cuenca, Pedro},
  title        = {Mixture of Experts Explained},
  journal      = {Hugging Face Blog},
  year         = {2023},
  url          = {https://huggingface.co/blog/moe},
  note         = {Accessed: 28 January 2025}
}

@misc{jiang2024mixtralexperts,
      title={Mixtral of Experts}, 
      author={Albert Q. Jiang and Alexandre Sablayrolles and Antoine Roux and Arthur Mensch and Blanche Savary and Chris Bamford and Devendra Singh Chaplot and Diego de las Casas and Emma Bou Hanna and Florian Bressand and Gianna Lengyel and Guillaume Bour and Guillaume Lample and Lélio Renard Lavaud and Lucile Saulnier and Marie-Anne Lachaux and Pierre Stock and Sandeep Subramanian and Sophia Yang and Szymon Antoniak and Teven Le Scao and Théophile Gervet and Thibaut Lavril and Thomas Wang and Timothée Lacroix and William El Sayed},
      year={2024},
      eprint={2401.04088},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2401.04088}, 
}

@article{NI2025105992,
title = {What makes a good BIM design? Quantifying the link between design behavior and quality},
journal = {Automation in Construction},
volume = {171},
pages = {105992},
year = {2025},
issn = {0926-5805},
doi = {https://doi.org/10.1016/j.autcon.2025.105992},
url = {https://www.sciencedirect.com/science/article/pii/S0926580525000329},
author = {Xiang-Rui Ni and Peng Pan and Jia-Rui Lin},
keywords = {BIM, Design quality, Design behavior, Machine learning, Model interpretation},
abstract = {In the Architecture Engineering & Construction (AEC) industry, how design behaviors impact design quality remains unclear. This paper proposes an approach that firstly unveils and quantitatively describes the relationship between design behaviors and design quality based on Building Information Modeling (BIM). Real-time collection and log mining are integrated to collect raw data related to design behaviors. Feature engineering and various machine learning models are then utilized for quantitative modeling and interpretation. Results confirm a clear quantifiable relationship between behaviors and quality which can be learned by various models. The best model using Extremely Random Trees achieved an R2 value of 0.88 on the test set. Behavioral features related to designer's skill level and changes of design intentions are identified as having significant impacts on design quality. These findings deepen our understanding of the design process and can help us create BIM designs of better quality.}
}

@article{ROUSSEEUW198753,
title = {Silhouettes: A graphical aid to the interpretation and validation of cluster analysis},
journal = {Journal of Computational and Applied Mathematics},
volume = {20},
pages = {53-65},
year = {1987},
issn = {0377-0427},
doi = {https://doi.org/10.1016/0377-0427(87)90125-7},
url = {https://www.sciencedirect.com/science/article/pii/0377042787901257},
author = {Peter J. Rousseeuw},
keywords = {Graphical display, cluster analysis, clustering validity, classification},
abstract = {A new graphical display is proposed for partitioning techniques. Each cluster is represented by a so-called silhouette, which is based on the comparison of its tightness and separation. This silhouette shows which objects lie well within their cluster, and which ones are merely somewhere in between clusters. The entire clustering is displayed by combining the silhouettes into a single plot, allowing an appreciation of the relative quality of the clusters and an overview of the data configuration. The average silhouette width provides an evaluation of clustering validity, and might be used to select an ‘appropriate’ number of clusters.}
}

@inproceedings{10.5555/2999325.2999464,
author = {Snoek, Jasper and Larochelle, Hugo and Adams, Ryan P.},
title = {Practical Bayesian optimization of machine learning algorithms},
year = {2012},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {The use of machine learning algorithms frequently involves careful tuning of learning parameters and model hyperparameters. Unfortunately, this tuning is often a "black art" requiring expert experience, rules of thumb, or sometimes brute-force search. There is therefore great appeal for automatic approaches that can optimize the performance of any given learning algorithm to the problem at hand. In this work, we consider this problem through the framework of Bayesian optimization, in which a learning algorithm's generalization performance is modeled as a sample from a Gaussian process (GP). We show that certain choices for the nature of the GP, such as the type of kernel and the treatment of its hyperparameters, can play a crucial role in obtaining a good optimizer that can achieve expertlevel performance. We describe new algorithms that take into account the variable cost (duration) of learning algorithm experiments and that can leverage the presence of multiple cores for parallel experimentation. We show that these proposed algorithms improve on previous automatic procedures and can reach or surpass human expert-level optimization for many algorithms including latent Dirichlet allocation, structured SVMs and convolutional neural networks.},
booktitle = {Proceedings of the 26th International Conference on Neural Information Processing Systems - Volume 2},
pages = {2951–2959},
numpages = {9},
location = {Lake Tahoe, Nevada},
series = {NIPS'12}
}

@article{BOKA2024102427,
title = {A survey of sequential recommendation systems: Techniques, evaluation, and future directions},
journal = {Information Systems},
volume = {125},
pages = {102427},
year = {2024},
issn = {0306-4379},
doi = {https://doi.org/10.1016/j.is.2024.102427},
url = {https://www.sciencedirect.com/science/article/pii/S0306437924000851},
author = {Tesfaye Fenta Boka and Zhendong Niu and Rama Bastola Neupane},
keywords = {Deep learning, Sequential recommendation, Evaluation, Recommender systems},
abstract = {Recommender systems are powerful tools that successfully apply data mining and machine learning techniques. Traditionally, these systems focused on predicting a single interaction, such as a rating between a user and an item. However, this approach overlooks the complexity of user interactions, which often involve multiple interactions over time, such as browsing, adding items to a cart, and more. Recent research has shifted towards leveraging this richer data to build more detailed user profiles and uncover complex user behavior patterns. Sequential recommendation systems have gained significant attention recently due to their ability to model users’ evolving preferences over time. This survey explores how these systems utilize interaction history to make more accurate and personalized recommendations. We provide an overview of the techniques employed in sequential recommendation systems, discuss evaluation methodologies, and highlight future research directions. We categorize existing approaches based on their underlying principles and evaluate their effectiveness in various application domains. Additionally, we outline the challenges and opportunities in sequential recommendation systems.}
}

@misc{nvidia_nvtabular,
  author       = {NVIDIA Corporation},
  title        = {NVTabular: Scalable Feature Engineering and Preprocessing for Recommender Systems},
  year         = {2024},
  url          = {https://nvidia-merlin.github.io/NVTabular/stable/Introduction.html},
  note         = {Accessed: 2024-02-04}
}

@software{NVIDIA_Corporation_Triton_Inference_Server,
author = {{NVIDIA Corporation}},
title = {{Triton Inference Server: An Optimized Cloud and Edge Inferencing Solution.}},
url = {https://github.com/triton-inference-server/server}
}

@article{10.1145/582415.582418,
author = {J\"{a}rvelin, Kalervo and Kek\"{a}l\"{a}inen, Jaana},
title = {Cumulated gain-based evaluation of IR techniques},
year = {2002},
issue_date = {October 2002},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {20},
number = {4},
issn = {1046-8188},
url = {https://doi.org/10.1145/582415.582418},
doi = {10.1145/582415.582418},
abstract = {Modern large retrieval environments tend to overwhelm their users by their large output. Since all documents are not of equal relevance to their users, highly relevant documents should be identified and ranked first for presentation. In order to develop IR techniques in this direction, it is necessary to develop evaluation approaches and methods that credit IR methods for their ability to retrieve highly relevant documents. This can be done by extending traditional evaluation methods, that is, recall and precision based on binary relevance judgments, to graded relevance judgments. Alternatively, novel measures based on graded relevance judgments may be developed. This article proposes several novel measures that compute the cumulative gain the user obtains by examining the retrieval result up to a given ranked position. The first one accumulates the relevance scores of retrieved documents along the ranked result list. The second one is similar but applies a discount factor to the relevance scores in order to devaluate late-retrieved documents. The third one computes the relative-to-the-ideal performance of IR techniques, based on the cumulative gain they are able to yield. These novel measures are defined and discussed and their use is demonstrated in a case study using TREC data: sample system run results for 20 queries in TREC-7. As a relevance base we used novel graded relevance judgments on a four-point scale. The test results indicate that the proposed measures credit IR methods for their ability to retrieve highly relevant documents and allow testing of statistical significance of effectiveness differences. The graphs based on the measures also provide insight into the performance IR techniques and allow interpretation, for example, from the user point of view.},
journal = {ACM Trans. Inf. Syst.},
month = oct,
pages = {422–446},
numpages = {25},
keywords = {cumulated gain, Graded relevance judgments}
}

@inproceedings{wu-etal-2020-attentive,
    title = "Attentive Pooling with Learnable Norms for Text Representation",
    author = "Wu, Chuhan  and
      Wu, Fangzhao  and
      Qi, Tao  and
      Cui, Xiaohui  and
      Huang, Yongfeng",
    editor = "Jurafsky, Dan  and
      Chai, Joyce  and
      Schluter, Natalie  and
      Tetreault, Joel",
    booktitle = "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics",
    month = jul,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2020.acl-main.267/",
    doi = "10.18653/v1/2020.acl-main.267",
    pages = "2961--2970",
    abstract = "Pooling is an important technique for learning text representations in many neural NLP models. In conventional pooling methods such as average, max and attentive pooling, text representations are weighted summations of the L1 or L{\ensuremath{\infty}} norm of input features. However, their pooling norms are always fixed and may not be optimal for learning accurate text representations in different tasks. In addition, in many popular pooling methods such as max and attentive pooling some features may be over-emphasized, while other useful ones are not fully exploited. In this paper, we propose an Attentive Pooling with Learnable Norms (APLN) approach for text representation. Different from existing pooling methods that use a fixed pooling norm, we propose to learn the norm in an end-to-end manner to automatically find the optimal ones for text representation in different tasks. In addition, we propose two methods to ensure the numerical stability of the model training. The first one is scale limiting, which re-scales the input to ensure non-negativity and alleviate the risk of exponential explosion. The second one is re-formulation, which decomposes the exponent operation to avoid computing the real-valued powers of the input and further accelerate the pooling operation. Experimental results on four benchmark datasets show that our approach can effectively improve the performance of attentive pooling."
}

@article{asce_log_mining,
author = {Limao Zhang  and Ming Wen  and Baabak Ashuri },
title = {BIM Log Mining: Measuring Design Productivity},
journal = {Journal of Computing in Civil Engineering},
volume = {32},
number = {1},
pages = {04017071},
year = {2018},
doi = {10.1061/(ASCE)CP.1943-5487.0000721},
}

@article{voyage3large2025,
  title = {voyage-3-large: the new state-of-the-art general-purpose embedding model},
  author = {{Voyage AI}},
  journal = {Voyage AI Blog},
  year = {2025},
  month = {January},
  url = {https://blog.voyageai.com/2025/01/07/voyage-3-large/}
}

@inproceedings{10.1145/3539618.3591718,
author = {Yang, Heeyoon and Choi, YunSeok and Kim, Gahyung and Lee, Jee-Hyong},
title = {LOAM: Improving Long-tail Session-based Recommendation via Niche Walk Augmentation and Tail Session Mixup},
year = {2023},
isbn = {9781450394086},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3539618.3591718},
doi = {10.1145/3539618.3591718},
abstract = {Session-based recommendation aims to predict the user's next action based on anonymous sessions without using side information. Most of the real-world session datasets are sparse and have long-tail item distribution. Although long-tail item recommendation plays a crucial role in improving user satisfaction, only a few methods have been proposed to take the long-tail session recommendation into consideration. Previous works in handling data sparsity problems are mostly limited to self-supervised learning techniques with heuristic augmentation which can ruin the original characteristic of session datasets, sequential and co-occurrences, and make noisier short sessions by dropping items and cropping sequences. We propose a novel method, LOAM, improving LOng-tail session-based recommendation via niche walk Augmentation and tail session Mixup, that alleviates popularity bias and enhances long-tail recommendation performance. LOAM consists of two modules, Niche Walk Augmentation (NWA) and Tail Session Mixup (TSM). NWA can generate synthetic sessions considering long-tail distribution which are likely to be found in original datasets, unlike previous heuristic methods, and expose a recommender model to various item transitions with global information. This improves the item coverage of recommendations. TSM makes the model more generalized and robust by interpolating sessions at the representation level. It encourages the recommender system to predict niche items with more diversity and relevance. We conduct extensive experiments with four real-world datasets and verify that our methods greatly improve tail performance while balancing overall performance.},
booktitle = {Proceedings of the 46th International ACM SIGIR Conference on Research and Development in Information Retrieval},
pages = {527–536},
numpages = {10},
keywords = {data augmentation, long-tail recommendation, session-based recommendation},
location = {Taipei, Taiwan},
series = {SIGIR '23}
}

@article{radford2018improving,
  title={Improving language understanding by generative pre-training},
  author={Radford, Alec and Narasimhan, Karthik and Salimans, Tim and Sutskever, Ilya},
  year={2018},
  url={https://cdn.openai.com/research-covers/language-unsupervised/language_understanding_paper.pdf}
}

@article{DBLP:journals/corr/BaKH16,
  author       = {Lei Jimmy Ba and
                  Jamie Ryan Kiros and
                  Geoffrey E. Hinton},
  title        = {Layer Normalization},
  journal      = {CoRR},
  volume       = {abs/1607.06450},
  year         = {2016},
  url          = {http://arxiv.org/abs/1607.06450},
  eprinttype    = {arXiv},
  eprint       = {1607.06450},
  timestamp    = {Tue, 23 Jul 2019 17:33:23 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/BaKH16.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@inbook{doi:10.1061/9780784482865.033,
author = {Yue Pan  and Limao Zhang },
title = {Sequential Design Command Prediction Using BIM Event Logs},
booktitle = {Construction Research Congress 2020},
chapter = {},
pages = {306-315},
doi = {10.1061/9780784482865.033},
URL = {https://ascelibrary.org/doi/abs/10.1061/9780784482865.033},
eprint = {https://ascelibrary.org/doi/pdf/10.1061/9780784482865.033},
    abstract = { A method of sequential design commands prediction is developed based on the recurrent neural network (RNN), providing a unique opportunity to discover the hidden knowledge behind the building information modeling (BIM) event logs. The modeling process will generate huge amounts of data, which will be documented automatically in BIM logs in chronological order. To fully understand a series of design commands in logs, RNN with the sequential memory is constructed to learn features of extracted sequential data from logs and predict the next possible design commands. The proposed RNN-based command prediction approach is tested in a real dataset of BIM event logs in journal file “Create” containing totally 57,915 command records, which are split in 80\%–20\% for the training set and testing set. Acting as a multi-classification task, hundreds of design commands are categorized into six classes and labeled by number 1–6. Ultimately, the RNN with 1 hidden layer and 64 hidden neurons will be trained to reach an overall accuracy of 63.86\%. Based on the performance measurements: confusion matrix, receiver operating characteristics (ROC) curve, and area under the curve (AUC), all the six design command classes can be well distinguished from each other in the RNN model, verifying its great classification ability. The novelty of this research lies in: (a) The state of knowledge by exploiting RNN in event log data mining to predict the design command sequence accurately; (b) The state of practice by providing an intelligent modeling solution for designers to improve the efficiency and quality of the design process. }
}

@inproceedings{jang2021logging,
  title={Logging Modeling Events to Enhance the Reproducibility of a Modeling Process},
  author={Jang, Suhyung and Shin, Sanghyun and Lee, Ghang},
  booktitle={ISARC. Proceedings of the International Symposium on Automation and Robotics in Construction},
  volume={38},
  pages={256--263},
  year={2021},
  organization={IAARC Publications}
}
