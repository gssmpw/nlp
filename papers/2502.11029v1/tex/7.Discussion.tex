\section{Discussion}~\label{sec:dis}
\noindent\textbf{Burdensome human efforts reduction by \hawkeye.} \hawkeye can reduce the burdensome human efforts of dynamic profiling from two aspects: (1) model designers can statically profile the communication cost of one model on multiple MPL frameworks without manually implementing the model in the MPL frameworks. Thus, the static profiling process in \hawkeye can significantly reduce human efforts. (2) \hawkeye offers an Autograd library whose model construction interfaces are fully consistent with those of \texttt{PyTorch} and integrates our proposed static communication cost profiling method. The Autograd library of \hawkeye can significantly reduce human efforts of implementing models in \hawkeye and inserting test instruments.

% \smallskip
\noindent\textbf{Local computation cost optimization.}
Local computation cost optimization~\cite{watson22piranha, cryptGPU} is another important research topic in the field of MPL. However, because communication cost is still the main performance bottleneck of MPL, we mainly consider profiling the communication cost of models in this paper. Watson et al.~\cite{watson22piranha} also show that with the acceleration of GPU, even in the LAN setting, the local computation time is significantly smaller than the communication time. In the WAN setting, the local computation time is negligible compared with the communication time. Therefore, the communication cost is the main optimization goal of studies on the optimization of MPC-friendly models~\cite{li2023mpcformer, ganesan2022efficient, MPCViT}. In addition, the communication optimization and local computation optimization are orthogonal. These two optimizations can improve the efficiency of MPL in different ways.

% \smallskip
\noindent\textbf{\wqruan{The adaptive protocol assignment for mixed-protocol frameworks.}} \wqruan{The mixed-protocol MPL frameworks (i.e., \texttt{CrypTen}, \texttt{Cheetah}, \texttt{Deep-MPC} and \texttt{Delphi}) involved in our experiments use static protocol assignments introduced in Section~\ref{subsec:label_interface}, i.e., model designers specify the protocol assignment and configure the communication cost of corresponding non-linear operations in \texttt{HawkEye}.}

\wqruan{However, emerging mixed-protocol MPL frameworks (e.g., \texttt{Silph}~\cite{10179397}) can adaptively assign protocols to efficiently perform non-linear operations according to circuit structures. \hawkeye can be extended to profile the communication cost of these frameworks that employ the adaptive protocol assignment when model designers provide protocol assignment strategies. Concretely, we can deliver the circuit structure information (e.g., the number of non-linear operators to be computed in parallel) in the parameters of the operation communication cost functions. Then, model designers can adaptively adjust the communication cost of non-linear operations according to the delivered circuit structure information.}
% Therefore, model designers can use \hawkeye to accurately profile the communication costs of mixed-protocol frameworks that employ the adaptive protocol assignment.   }
