
\section{Static Communication Cost Profiling Method}~\label{sec:analysis} 
% \subsection{Overview}~\label{subsec:profiling_overview}
As is shown in Figure~\ref{fig:workflow}, the workflow of our proposed static communication cost profiling method compromises four steps: (1) Model designers choose an MPL framework to perform MPL tasks and configure the communication cost of the MPL framework with the communication cost configuration interface of \hawkeye. (2) Given an \textit{mpc} program, model designers label the functions in the \textit{mpc} program they want to profile with the function labeling interface of \hawkeye. (3) \hawkeye generates the instruction block tree of the labeled \textit{mpc} program and assigns each generated instruction block a label that corresponds to the labeled function based on a prefix structure. (4) \hawkeye analyzes the labeled block tree and outputs the profiling results. Note that we have labeled forward and derivative computation functions of operators that require communication in the Autograd library of \hawkeye. Thus, model designers can directly apply \hawkeye to profile the model communication cost in \texttt{PyTorch} without manually labeling the model components.

\subsection{Communication Cost Configuration and Function Labeling Interfaces }~\label{subsec:label_interface}
\noindent \textbf{Communication cost configuration interface.} 
The communication cost of one basic operation typically depends on the following five parameters: bit length $k$, statistical security parameter $\kappa_s$, computational security parameter $\kappa$, bit length $f$ of a fixed-point number's fractional part, the number of parties $m$. The five parameters should be set according to practical requirements. As shown in Listing~\ref{list:cost}, in \hawkeye, the communication cost of instruction is expressed as an anonymous function that takes $k$, $\kappa_s$, $\kappa$, $f$, and $m$ as inputs and outputs a tuple that contains online communication size, online communication round, offline communication size, offline communication round. \wqruan{Some operations could have extra parameters. For example, the communication cost function of secure multiplication has three extra parameters: the degree of HE polynomial $\mathit{deg}$, HE prime coefficients modulus $\mathit{mod}$, and $\mathit{size}$ that indicates the number of multiplication operations executed in parallel. We describe them in detail in Appendix~\ref{appendix:protocol_config}.}
% For the basic instruction corresponding to Matrix\_Multiplication, its communication cost also depends on the shape of input matrices. Therefore, the communication cost function of Matrix\_Multiplication has three extra parameters: $p$, $q$, and $r$, representing the row number and the column number of the first input matrix and the column number of the second input matrix, respectively. 
% Note that the communication cost of basic operations is typically analyzed in the original paper of the corresponding MPL framework. Therefore, model designers can configure the communication cost for basic operations of one MPL framework according to the original paper of the MPL framework.
% The communication cost configuration process should be much easier than implementing MPC-friendly models for MPL frameworks. 
\begin{lstlisting}[mathescape,xleftmargin=2em,framexleftmargin=2em, caption = {Communication cost configuration for part of basic operations of $\texttt{ABY3}$~\cite{mohassel2018aby3} framework. One basic operation corresponds to one basic instruction in cost\_function\_dict}, columns=fullflexible, label = {list:cost}]
class ABY3(Cost):
  cost_func_dict = {
    "share": lambda $k$, $\kappa_s$, $\kappa$, $f$, $m$: (3*$k$, 1, 0, 0),
    "reveal": lambda $k$, $\kappa_s$, $\kappa$, $f$, $m$: (3*$k$, 1, 0, 0)
    "muls": lambda $k$, $\kappa_s$, $\kappa$, $f$, $m$, $\mathit{size}$, $\mathit{deg}$, $\mathit{mod}$: 
    (3*$k$*$\mathit{size}$, 1, 0, 0)
\end{lstlisting}


In addition to the above basic operations, complicated operations, \wqruanother{e.g.,} truncation or exponentiation, are implemented by composing basic operations by default in \hawkeye. However, if model designers use an MPL framework with special optimizations for some complicated operations (\wqruan{e.g., the comparison operation based on mixed protocols}), they can configure the communication cost of the complicated operations. \wqruan{For example, many mixed-protocol MPL frameworks~\cite{aby, mohassel2018aby3, mishra2020delphi, crypten2020} implement the non-linear operations by converting arithmetic shares to boolean shares or Yao shares. To handle this type of MPL framework, model designers can specify the protocol assignments for the non-linear operations and configure their communication cost, which includes the communication cost of share conversion and boolean circuit evaluation. We further discuss how to adaptively assign protocols for non-linear operations of mixed-protocol frameworks in Section~\ref{sec:dis}.}

\wqruan{The communication cost of MPL frameworks can be configured through the following three methods: (1) Analyzing the communication costs of basic operations according to the description of the original paper. (2) Running the basic operations with open-source codes of MPL frameworks to test the communication costs of basic operations. (3) Asking the framework developers on open-source platforms to further align the communication cost configuration with the concrete MPL framework implementations. The above three methods can be solely used or combined to obtain accurate communication cost configuration. In addition, once the communication cost for one MPL framework is configured, the configuration can be shared with other users through open-source platforms.}

\wqruan{In \hawkeye, to assist model designers in profiling model communication cost on multiple MPL frameworks, we have configured the communication cost of ten MPL frameworks (e.g., \texttt{ABY3}~\cite{mohassel2018aby3}). Thus, model designers can directly apply \hawkeye to profile model communication costs on the ten MPL frameworks. We show the communication cost configuration of the ten MPL frameworks in Appendix~\ref{appendix:protocol_config}.}

\wqruan{Besides, when setting the value of $k$ and $f$, model designers should be careful about the impact of the truncation method. In particular, local truncation, i.e., the truncation method used by \texttt{SecureML}~\cite{DBLP:conf/sp/MohasselZ17} and \texttt{ABY3}~\cite{mohassel2018aby3}, requires additional bits (slack bits) to maintain the desired truncation failure rate. Otherwise, the truncation results would suffer the sign bit flip error with a relatively high probability. Therefore, if using \texttt{ABY3/SecureML}-style truncation, model designers should preserve slack bits when setting the value of $k$ and $f$.}

\begin{lstlisting}[mathescape,xleftmargin=2em,framexleftmargin=2em, caption = {An example program whose functions are labeled using the function labeling interface of \hawkeye.},columns=fullflexible, label = {list:function_labeling}]
@buildingblock("mul") #label mul function
def mul(a, b):
    return a*b   
@buildingblock("test") #label test function
def test(a, b):
    c = mul(a,b)
    n = reveal(c)
    return n
x = sint(1), y = sint(2)
test(x, y)
\end{lstlisting}

\noindent \textbf{Function labeling interface.} \hawkeye provides a function decorator (\wqruanother{i.e.,} @buildingblock) for model designers to label the functions. By adding @buildingblock(``\textit{func1}'') before the declaration of a function, model designers can assign the label ``\textit{func1}'' to the function. For example, as is shown in Listing~\ref{list:function_labeling}, we assign labels ``mul'' and ``test'' to \textit{mul} and \textit{test} functions with the function decorator. In the main body of the program, we call the \textit{test} function with two secret shared integers as inputs. When the bit length is 64 and model designers apply \hawkeye to profile the program shown in Listing~\ref{list:function_labeling} with the communication cost configuration shown in Listing~\ref{list:cost}, the profiling result outputted by \hawkeye would be \{ ``initial-test'': (192, 1, 0, 0), ``initial-test-mul'': (192, 1, 0, 0) \}. The four numbers in tuples of the above dictionary represent online communication bits, online communication round numbers, offline communication bits, and offline communication round numbers, respectively. 
In the above dictionary, the communication cost of \textit{test} function is the sum of all items whose labels contain ``test'', and the same goes for \textit{mul} function. The format of the profiling result originated from our proposed blocking labeling methods, which are described in Section~\ref{subsec:block_label_analysis}.

\subsection{Block Labeling and Tree Analysis Method}~\label{subsec:block_label_analysis}
After model designers label the functions in an \textit{mpc} program with the function labeling interface of \hawkeye, \hawkeye generates and labels instruction blocks to obtain the labeled block tree. Then, \hawkeye analyzes the labeled block tree to obtain the communication cost profiling results. 

% \smallskip
\noindent\textbf{Block labeling method.} To label instruction blocks for accurate communication cost profiling, we need to resolve the following issue: one labeled function could call another labeled function. In this situation, directly using the label of the called function to label generated instruction blocks would cause the information of the function call chain to be lost.  To resolve the issue, we propose a prefix structure to record the information of the function calling relations. Specifically, we maintain a global label. When compiling a labeled function, we append the label of the function to the global label and use it to label the generated instruction blocks. After generating instructions corresponding to the function, we remove its label from the end of the global label. In this way, when a labeled function calls another labeled function, the information of the calling function would be recorded in the global label. 
% Meanwhile, the communication cost of one labeled function would be the sum of all items in profiling results whose keys contain its label.


As shown in Algorithm~\ref{alg:block_label}, \hawkeye labels instruction blocks in a recursive manner. We first define two functions, Compile\_S\_List and Compile\_Func. Compile\_S\_List (Line 4-9) receives a statement list S\_List, the block tree $\mathcal{T}$, and the global label g\_label as inputs. It compiles the statements of S\_List as instruction blocks and labels generated instruction blocks with g\_label. The inputs of Compile\_Func (Line 10-23) contain a function $func$,  $\mathcal{T}$, g\_label, and S\_List. During the instruction generation process, Compile\_Func enumerates statements of $func$. If one statement $s$ does not call a labeled function $f_{sub}$, Compile\_Func appends $s$ into S\_List (Line 19). Otherwise, Compile\_Func first compiles the statements stored in the S\_List (Line 14). Then, Compile\_Func appends the label of $f_{sub}$ to the end of g\_label (Line 15). Without loss of generality, we assume that $s$ is a call to $f_{sub}$ and does not perform other computations. After that, Compile\_Func calls Compile\_Func with $f_{sub}$, $\mathcal{T}$, and g\_label as inputs and then removes the label of $f_{sub}$ from the end of g\_label (Line 16-17). Compile\_Func clears S\_List by calling Compile\_S\_List (Line 22). Finally, after initializing g\_label, $\mathcal{T}$, and S\_List, block labeling process is completed by calling Compile\_Func with $p$, $\mathcal{T}$, g\_label and S\_List as inputs (Line 2). Note that in Algorithm~\ref{alg:block_label}, we view the input program $p$ as a function that contains a sequence of statements.


% \smallskip
\noindent\textbf{Block tree analysis method.} We profile the communication cost of an \textit{mpc} program by analyzing its corresponding labeled block tree $\mathcal{T}$ outputted by Algorithm~\ref{alg:block_label}. 
As is shown in Algorithm~\ref{alg:block_analysisl}, the aggregate function of a ReqNode instance receives a dictionary $d_1$ as the input and updates $d_1$ with the communication cost profiling results of the block tree whose root node is the ReqNode instance. For a ReqNode instance, its aggregate function first calculates the communication cost of each instruction block in its instruction block list (Line 5-12). Given an instruction block $b$, the aggregate function enumerates each instruction $i$ in $b$ and computes the communication cost of $i$ by calling its communication cost function defined in the communication cost configuration dictionary (Line 8). Then, the aggregate function adds the cost function output to $d_1$ according to the label of $b$ (Line 9). After calculating the communication cost of the ReqNode instance itself, its aggregate function calls the aggregate function of its children with $d_1$ as the input (Line 13-15).

\begin{algorithm}[htbp]
\small
\caption{Block labeling algorithm that generates and labels instruction blocks. }
\label{alg:block_label}
 \begin{algorithmic}[1]
    \REQUIRE An \textit{mpc} program $p$ that represents as a sequence of statements. The functionality \textit{Compile\_Statements} receives a statement list and the block tree $\mathcal{T}$ as input and compiles these statements into instruction blocks that are inserted into $\mathcal{T}$. The \mpspdz compiler provides it.
    \ENSURE The labeled block tree $\mathcal{T}$.
    \STATE \textbf{Initialization}: initialize the global label as g\_label = `initial', the block tree $\mathcal{T}$ as an empty ReqNode instance, a statement list S\_List as []. 
    \STATE Compile\_Func(p, $\mathcal{T}$, g\_label, S\_List)
    \RETURN $\mathcal{T}$
    \STATE\textbf{Function Compile\_S\_List(}S\_List, $\mathcal{T}$, g\_label\textbf{):}
    \begin{ALC@g}
    \STATE blocks = \textit{Compile\_Statements}(S\_List, $\mathcal{T}$)
    \FOR{block $b$ in blocks}
    \STATE b.label = g\_label
    \ENDFOR
    \STATE S\_List = []
    \end{ALC@g}
    \STATE \textbf{End Function}
    \STATE\textbf{Function Compile\_Func}(\textit{func}, $\mathcal{T}$, g\_label, S\_List\textbf{):}
    \begin{ALC@g}
    \FOR{statement $s$ in \textit{func}}
    \IF{$s$ calls a labeled function $f_{sub}$}
    \STATE Compile\_S\_List(S\_List, $\mathcal{T}$, g\_label)
    \STATE g\_label = g\_label + `-$f_{sub}$.label'
    \STATE Compile\_Func($f_{sub}$, $\mathcal{T}$, g\_label, S\_List)
    \STATE g\_label = g\_label - `-$f_{sub}$.label'
    \ELSE
    \STATE S\_List.append($s$)
    \ENDIF
    \ENDFOR
    \STATE Compile\_S\_List(S\_List, $\mathcal{T}$, g\_label)
    \end{ALC@g}
    \STATE\textbf{End Function}
\end{algorithmic}
\end{algorithm}


The aggregate function of a ReqChild instance receives a dictionary $d_1$ as the input. It processes the communication cost profiling results outputted by its children with its aggregator function and updates $d_1$ with the process results.  For a ReqChild instance, its aggregate function first initializes an empty dictionary \textit{tmp\_d} (Line 18). Then, the aggregate function of the ReqChild instance calls the aggregate functions of its children one by one with \textit{tmp\_d} as the input (Line 19-21). After that, for each pair in \textit{tmp\_d}, the aggregate function processes the item of the pair with its aggregator function and adds the result to $d_1$ according to the label of the pair (Line 22-24). Finally, the block tree analysis process is completed by initializing an empty dictionary $d$ and calling the aggregate function of \textit{root} with $d$ as input, where \textit{root} is the root ReqNode of the labeled block tree $\mathcal{T}$ (Line 1-3).
\begin{algorithm}[htbp]
\small
\caption{Block tree analysis algorithm that analyzes the labeled block tree to profile the communication cost of an \textit{mpc} program. The addition between two tuples outputs a new tuple whose elements are the sum of two input tuples' corresponding elements}
\label{alg:block_analysisl}
 \begin{algorithmic}[1]
    \REQUIRE The root node \textit{root} of the labeled block tree $\mathcal{T}$ and a \textit{cost\_func\_dict} stores communication cost functions of basic operations of the used MPL framework.
    \ENSURE A dictionary $d$ that stores the profiling result.
    \STATE \textbf{Initialization:}  Initialize an empty dictionary $d$
    \STATE \textit{root}.aggregate($d$)
    \RETURN $d$
    \STATE\textbf{Function ReqNode: aggregate(}self, $d_1$\textbf{):}
    \begin{ALC@g}
    \FOR{block $b$ in self.blocks}
    \FOR{instructions $i$ in $b$}
        \IF{$i$ requires communication}
          \STATE  i\_cost = \textit{cost\_func\_dict}[$i$.name]($i$.args) 
            \STATE   $d_1$[$b$.label] = $d_1$[$b$.label] + i\_cost
        \ENDIF
    \ENDFOR
    \ENDFOR
    \FOR{child $c$ in self.children}
      \STATE  $c$.aggregate($d_1$)
    \ENDFOR
    \end{ALC@g}
    \STATE \textbf{End Function}
    \STATE\textbf{Function ReqChild: aggregate(}self, $d_1$\textbf{):}
    \begin{ALC@g}
    \STATE Initialize an empty dictionary \textit{tmp\_d}
    \FOR{node $n$ in self.children}
      \STATE  $n$.aggregate(\textit{tmp\_d})
    \ENDFOR
    \FOR{label, item in \textit{tmp\_d}}
            \STATE   $d_1$[label] =  $d_1$[label] + self.aggregator(item)
    \ENDFOR
    \end{ALC@g} 
    \STATE \textbf{End Function}
\end{algorithmic}
\end{algorithm}


\noindent\textbf{Accuracy analysis.} Because of the security requirements of MPL, the communication cost profiling results outputted by the static communication cost profiling method are consistent with those obtained by dynamic profiling. Concretely, to rigorously guarantee the data security of MPL frameworks, the program execution flow of MPL frameworks must be input-independent~\cite{10.1145/28395.28416}. Therefore, the execution flow of each labeled function, which can be viewed as a sequence of instructions, must remain unchanged as input data changes. As a result, given an \textit{mpc} program that contains labeled functions, as long as model designers correctly configure the communication cost for basic operations of MPL frameworks, \hawkeye can accurately profile the communication cost of the \textit{mpc} program.

