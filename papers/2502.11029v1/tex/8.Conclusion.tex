\section{Conclusion and Future Work}~\label{sec:conclu}
In this paper, we propose \hawkeye, a static communication cost profiling framework to enable model designers to \wqruanother{get} the accurate communication cost of models in MPL frameworks without dynamic profiling. \hawkeye contributes two folders: a static communication cost profiling method and an Autograd library. The static communication cost profiling method statically profiles model communication cost by breaking high-level components as compositions of basic operations. Meanwhile, the Autograd library has model construction interfaces that are fully consistent with those of \texttt{PyTorch} and integrates the static communication cost profiling method to profile the communication cost of models in \texttt{PyTorch}. Finally, we conduct a series of experiments to compare the static profiling results outputted by \hawkeye with the dynamic profiling results from two MPL frameworks. The experimental results show that \hawkeye can accurately profile the model communication cost. As a result, \hawkeye can effectively help model designers optimize the structures of MPC-friendly models in MPL frameworks.

In the future,  we will extend \hawkeye to \wqruanother{profile the communication costs of MPL frameworks that employ adaptive protocol assignments} and the local computation cost of models in MPL frameworks, such that model designers can obtain more comprehensive information when they design and optimize MPC-friendly models.