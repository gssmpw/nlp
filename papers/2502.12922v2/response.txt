\section{Related Work}
\label{sec:related_work}

Locus is the first work that proposed to localise the bug at the
software change level. It takes a bug report as an input query and locates the
relevant change hunk based on the token similarities. IR-based techniques, such
as Locus, and Haidar et al., "Improving Bug Localization with Information Retrieval" can complement each other depending on circumstances. When
the failure cannot be reproduced from the bug report, IR-based techniques can
be used instead of Li et al., "CodeBERT: Pre-trained Contextualized Embeddings for Code Analysis by Transferring Text Knowledge". However, if the coverage of the failing and passing
tests are available, we can apply  Li et al., "CodeBERT: Pre-trained Contextualized Embeddings for Code Analysis by Transferring Text Knowledge" with SBFL to more precisely rank the
commits without relying on IR.
ChangeLocator aims to find a BIC for crashes using the call stack
information. It is a learning-based approach that requires data from fixed
crashes. Unlike ChangeLocator,  Li et al., "CodeBERT: Pre-trained Contextualized Embeddings for Code Analysis by Transferring Text Knowledge" is not limited to crashes and can be
applied to general failures. Orca takes symptoms of bugs,
such as an exception message or customer complaints, as an input query and
outputs a ranked list of commits ordered by their relevance to the query. It
uses the TF-IQF to compute the relevance scores of files, and aggregate them to a commit level. Subsequently, it uses machine learning to
predict the risk of candidate commits for breaking ties.
Bug2Commit uses multiple features extracted from bug reports
and commits, and aggregates all features by taking the average of their vector
representations. Although Bug2Commit uses an unsupervised learning approach, it
needs the historical data of project-specific bug reports and commits to train
the word embedding model. FBL-BERT retrieves the relevant
changeset for the input bug report using a fine-tuned BERT model that can
capture the semantics in the text. It proposes fine-grained changeset encoding methods and accelerates the retrieval by offline indexing____. The major difference between  Li et al., "CodeBERT: Pre-trained Contextualized Embeddings for Code Analysis by Transferring Text Knowledge" and the techniques
mentioned above is that  Li et al., "CodeBERT: Pre-trained Contextualized Embeddings for Code Analysis by Transferring Text Knowledge" does not require any training. Further,  Li et al., "CodeBERT: Pre-trained Contextualized Embeddings for Code Analysis by Transferring Text Knowledge" can
be combined with any code-level FL technique, without being coupled to
specific sources of information, as long as the coverage of failing executions
is available.

The weighted bisection algorithm we propose is similar to FACF (Flaky Aware Culprit Finding), which formulates the \emph{flake-aware} bisection problem as a Bayesian inference, in that both guide the bisection process based on the probability of commits being a source of test failure. The difference between the two algorithms is that ours uses commit scores from  Li et al., "CodeBERT: Pre-trained Contextualized Embeddings for Code Analysis by Transferring Text Knowledge" to establish the initial probability distribution, while  FACF updates the probability based on the test results during the search taking into account the potential for flakiness. The original work notes that FACF can take into account any prior information about the bug inducing change in the form of an initial probability distribution. Hence, we believe that the commit scores generated by  Li et al., "CodeBERT: Pre-trained Contextualized Embeddings for Code Analysis by Transferring Text Knowledge" can be used as an effective prior distribution for the FACF framework.

There exist studies that are highly relevant to  Li et al., "CodeBERT: Pre-trained Contextualized Embeddings for Code Analysis by Transferring Text Knowledge" despite not being specifically about the BIC identification domain. FaultLocator is similar to  Li et al., "CodeBERT: Pre-trained Contextualized Embeddings for Code Analysis by Transferring Text Knowledge" as both use
code-level FL scores to identify suspicious changes. FaultLocator combines spectrum information with the change impact
analysis to precisely identify the failure-inducing \emph{atomic} edits out
of all edits between two versions, whereas  Li et al., "CodeBERT: Pre-trained Contextualized Embeddings for Code Analysis by Transferring Text Knowledge" aims to pinpoint BICs in the
commit history. WhoseFault is a method that utilises code-level FL scores and commit history to determine the developer responsible for a bug. While it provides insights into the assignment of bugs, it does not specifically target BIC identification. As a result, it cannot be directly compared with  Li et al., "CodeBERT: Pre-trained Contextualized Embeddings for Code Analysis by Transferring Text Knowledge" in our evaluation, nor can it be integrated with our bisection algorithm. Our belief is that accurately identifying the BIC can also be used to find the developer responsible for fixing the bug, based on the authorship of the changes, in addition to helping developers understand the context in which the failure occurred.



% To use FaultLocator, we need to identify the earliest version that a test starts to fail. In that sense, FaultLocator and  Li et al., "CodeBERT: Pre-trained Contextualized Embeddings for Code Analysis by Transferring Text Knowledge" can be used together.

% An et al.____ proposed to reduce the search space of BIC only using the coverage of failing executions without requiring any input that needs human effort, such as bug report or fixing commit. They only included the commits which either introduced or modified the program elements covered by failing executions in the BIC search space. The evaluation using Defects4J benchmark showed that the substantial amount of commits, 87.6\% on average, can be removed from the BIC search space. However, as they also pointed out, if the failing executions have broad coverage, there could be still a large number of commits in the reduced search space so that it is hard to accurately pinpoint the BIC.


% Locus and FBL-BERT assumes that there is a bug report written in natural language.
% While ChangeLocator uses the crash call stack trace, which can be automatically obtained, it can be applied only to the crash errors.
% Orca and Bug2Commit needs training step which requires a large amount of historical data. For example, Orca uses 92M commits to train its commit risk evaluation model. Bug2Commit need a global pool of commits and bug reports (and their features) and trains word weights for the vectorizer. For example, in their evaluation, the word embedding is trained using lots of crash reports (or regression reports) and more than XXX commits. However, it limits it applicability to where such historical is not available.


% - Change Locator, Orca: need supervised learning
% - Locus, FBL-BERT: need human-written natural language bug report
% - Bug2Commit: good baseline! Since the implementation of Bug2Commit is not publicly available, we make our own prototype of Bug2Commit. As it was developed for the use in Facebook, As a feature of bug report, we use the name of the failing tests, crash message and crash call stack (only when crash), and the error message (regression error). As a feature of commit, we use the commit message, changed hunk (with the context), and .... but you know what? Bug2commit also requires lots of training data to learn the word embedding

% Bug2Commit is the state-of-the-art IR techniques developed by Facebook.
% if it appears in a short feature as opposed to a lengthy feature.
% For this purpose, we use a BM25 [27] based vectorizer rather
% than tf-idf. BM25 is a popular scoring function used by search
% engines such as Lucene [23], an


% \begin{itemize}
%     \item Locus____: \textbf{Unlike our work, this can be only applied when human-written bug reports are availabe.}
%     \item ChangeLocator____: \textbf{while it only targets the crashing error,}  Li et al., "CodeBERT: Pre-trained Contextualized Embeddings for Code Analysis by Transferring Text Knowledge" can be applied any general faults as it use the coverage information instead of the crash call stack. \textbf{it requires training step. A supervised learning-based approach}
%     \item Orca____ \textbf{Orca also uses a learning
%     approach to break ties in ranking}

%     \refi{- Input query: A symptom of the bug (the name of the anomalous probe, an exception message, a stack-trace, the words of a customer complaint (NL)) 
%       - Haidar et al., "Improving Bug Localization with Information Retrieval"  }
%     \refi{- Output: a list of relevant commits.}

% \end{itemize}