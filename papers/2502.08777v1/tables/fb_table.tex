
\begin{table*}[t]
\setlength\tabcolsep{3pt}
\centering
\begin{tabular}{l c c c | c c c | c c | c c c}
\toprule
\multirow{2}{*}{\textbf{Model}} 
  & \multicolumn{3}{c|}{\textbf{Unified}} 
  & \multicolumn{3}{c|}{\textbf{Hybrid}} 
  & \multicolumn{2}{c|}{\textbf{\(\Delta\) Hyb.-SOTA}} 
  & \multicolumn{3}{c}{\textbf{\(\Delta\) Hyb.-Unif.}} \\
\cmidrule(lr){2-4}\cmidrule(lr){5-7}\cmidrule(lr){8-9}\cmidrule(lr){10-12}
  & \textbf{Full} & \textbf{Author} & \textbf{Nest}
  & \textbf{Full} & \textbf{Author} & \textbf{Nest}
  & \textbf{Full} & \textbf{Author}
  & \textbf{Full} & \textbf{Author} & \textbf{Nest} \\
\midrule
\multicolumn{12}{c}{\textit{Previous / Fine-Tuned SOTA \citep{murzaku-rambow-2024-beleaf}}} \\
\midrule
GPT-3 (Fine-tuned) 
  & 65.8 & 76.0 & -- 
  & 65.8 & 76.0 & -- 
  & -- & -- 
  & -- & -- & -- \\
Flan-T5-XL         
  & 69.5 & 76.6 & -- 
  & 69.5 & 76.6 & -- 
  & -- & -- 
  & -- & -- & -- \\
\midrule
\multicolumn{12}{c}{\textit{Zero-Shot LLM Systems}} \\
\midrule
GPT-4o
  & 60.2 & 65.9 & 20.2
  & 68.7 & 73.2 & 22.9
  & \textcolor{red}{-0.8} & \textcolor{red}{-3.4}
  & {\textcolor{ForestGreen}{+8.5}} & {\textcolor{ForestGreen}{+7.3}} & {\textcolor{ForestGreen}{+2.7}} \\
o1\,\small\reasoning
  & 65.0 & \textbf{73.2} & 18.9
  & 70.3 & \textbf{78.9}\textsuperscript{$\dagger$} & 19.2
  & \textcolor{ForestGreen}{+0.8} & \textcolor{ForestGreen}{+2.3}
  & {\textcolor{ForestGreen}{+5.3}} & {\textcolor{ForestGreen}{+5.7}} & {\textcolor{ForestGreen}{+0.3}} \\
DeepSeek r1\,\small\reasoning\,\small\openmodel
  & \textbf{66.1} & 71.1 & \textbf{24.1}
  & \textbf{72.0}\textsuperscript{$\dagger$} & 77.6 & \textbf{25.3}\textsuperscript{$\dagger$}
  & \textcolor{ForestGreen}{+2.5} & \textcolor{ForestGreen}{+1.0}
  & {\textcolor{ForestGreen}{+5.9}} & {\textcolor{ForestGreen}{+6.5}} & {\textcolor{ForestGreen}{+1.2}} \\
o3-mini\,\small\reasoning
  & 62.4 & 70.9 & 15.6
  & 65.5 & 75.2 & 17.0
  & \textcolor{red}{-4.0} & \textcolor{red}{-1.4}
  & {\textcolor{ForestGreen}{+3.1}} & {\textcolor{ForestGreen}{+4.3}} & {\textcolor{ForestGreen}{+1.4}} \\
Claude 3.5
  & 63.2 & 69.7 & 19.7
  & 70.4 & 77.6 & 21.4
  & \textcolor{ForestGreen}{+0.9} & \textcolor{ForestGreen}{+1.0}
  & {\textcolor{ForestGreen}{+7.2}} & {\textcolor{ForestGreen}{+7.9}} & {\textcolor{ForestGreen}{+1.7}} \\
LLaMA 3.3\,\small\openmodel
  & 53.1 & 60.4 & 14.4
  & 58.8 & 66.0 & 19.9
  & \textcolor{red}{-10.7} & \textcolor{red}{-10.6}
  & {\textcolor{ForestGreen}{+5.7}} & {\textcolor{ForestGreen}{+5.6}} & {\textcolor{ForestGreen}{+5.5}} \\
DeepSeek-v3\,\small\openmodel
  & 56.3 & 61.4 & 17.1
  & 60.5 & 65.3 & 18.2
  & \textcolor{red}{-9.0} & \textcolor{red}{-11.3}
  & {\textcolor{ForestGreen}{+4.2}} & {\textcolor{ForestGreen}{+3.9}} & {\textcolor{ForestGreen}{+1.1}} \\
\bottomrule
\end{tabular}
\caption{\textbf{Unified} vs. \textbf{Hybrid} approaches with different LLMs. We report Micro F1 (Full), Author Micro F1 (Author), and Nested Micro F1 (Nest) scores (in \%). \textbf{\(\Delta\) Hyb.-SOTA} denotes the difference between the \textbf{Hybrid} result vs. the fine-tuned SOTA. The best scores are highlighted in \textbf{bold} and new state-of-the-art (SOTA) results are denoted by $\dagger$. \(\Delta\)~\textbf{Hyb.-Unif.} highlight the \textbf{Hybrid}-\textbf{Unified} difference for Full, Author, and Nest F1s. {\small\openmodel} indicates open models and {\small\reasoning} indicates reasoning models.
}
\label{tab:fb-results}
\end{table*}
