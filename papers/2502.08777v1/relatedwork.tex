\section{Related Work}
\label{sec:relwork}
\noindent\textbf{Corpora } Many corpora explore the notion of belief on the sentence level. FactBank is one of the first corpora to do this, annotating source-and-target belief: both the belief presented by the author towards an event and the belief towards events by sources mentioned inside of the text \citep{sauri2009factbank}.
Other corpora annotate only the author's belief towards events: these corpora include LU \cite{diab-etal-2009-committed}, UW \cite{lee-etal-2015-event}, LDCCB \citep{prabhakaran-etal-2015-new}, MEANTIME \citep{minard-etal-2016-meantime}, MegaVeridicality \cite{white-etal-2018-lexicosyntactic},  UDS-IH2 \citep{rudinger-etal-2018-neural-models}, CommitmentBank \citep{de2019commitmentbank}, and RP \citep{ross-pavlick-2019-well}. Two recent corpora for event factuality are Maven-Fact \citep{li-etal-2024-maven} which contains a large-scale corpus of event and supporting evidence annotations, 
and ModaFact \citep{rovera-etal-2025-modafact}, which is an Italian author belief corpus that annotates in a similar style and inspiration as FactBank. 

\noindent\textbf{Methods} Previous methods for author belief prediction mainly involve fine-tuning: \citet{rudinger-etal-2018-neural-models} fine-tune multi-task LSTMs; \citet{pouran-ben-veyseh-etal-2019-graph} fine-tune a graph convolutional network with BERT \citep{devlin-etal-2019-bert} representations; \citet{jiang-de-marneffe-2021-thinks, murzaku-etal-2022-examining} fine-tune RoBERTa \citep{liu2019roberta} with span representations; \citet{li-etal-2024-maven} fine-tune RoBERTa and Flan-T5 \citep{chung2024scaling}, and also explore four LLMs predictions using few-shot learning; \citet{rovera-etal-2025-modafact} fine-tune BERT, mT5-XXL \citep{xue-etal-2021-mt5}, Aya23-8B \citep{aryabumi2024aya}, and Minerva-3B \citep{orlando2024minerva}.

There has been much less focus on the complete source-and-target belief task: \citet{murzaku-etal-2023-towards, murzaku-rambow-2024-beleaf} both fine-tune a Flan-T5 model, with the latter optimizing for the structure of belief represented as a tree.