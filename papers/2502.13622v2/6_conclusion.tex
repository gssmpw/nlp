\section{Conclusion}
In this study, we introduced REFIND, a novel framework for detecting hallucinated spans in LLM-generated outputs by leveraging retrieved documents to compute the Context Sensitivity Ratio (CSR) at the token level. REFIND was rigorously evaluated on the multilingual SemEval 2025 Task 3: Mu-SHROOM dataset, demonstrating superior performance across nine languages, including low-resource settings, compared to baseline approaches. By directly integrating retrieved context into the token probability calculation, REFIND effectively identifies hallucinated spans with greater precision and efficiency.

Our experimental results highlight the robustness and scalability of REFIND in multilingual environments, offering a promising solution for enhancing the factuality of LLM outputs. Moreover, the streamlined detection process avoids the complexities associated with multi-step frameworks, enabling practical deployment in real-world applications.

For future work, we aim to extend REFIND by exploring adaptive thresholding mechanisms to further optimize the balance between precision and recall in hallucination detection. 
% Additionally, future research is required to investigate how detected hallucinations can guide the decoding process to improve the quality of generated outputs, potentially enabling iterative refinement during generation.
