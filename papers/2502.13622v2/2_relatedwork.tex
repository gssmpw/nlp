\section{Related Work}

\paragraph{Detection of Hallucinated Responses} Several studies have proposed methods to detect whether a response contains hallucinated information. \citet{Farquhar2024Detecting, han2024semantic, arteaga2024hallucination} leveraged semantic entropy \cite{kuhn2023semantic} to estimate uncertainty and identify hallucinations. These approaches utilize entropy-based metrics to assess the reliability of generated responses.
SelfCheckGPT \cite{manakul-etal-2023-selfcheckgpt} introduces a method that employs the language model itself to sample multiple responses and detect inconsistencies among them, thus identifying hallucinated outputs. However, this method relies solely on the internal knowledge of the language model, making it less effective when the model's knowledge is limited or incomplete.

\paragraph{Detection of Hallucinated Spans} Beyond identifying whether a response is hallucinated, other works aim to detect specific spans of hallucinated content within a response of LLMs. Token-level classification approaches \cite{liu-etal-2022-token} utilized pre-trained language models to classify individual tokens as factual or hallucinated. These methods focus on analyzing attention patterns, demonstrating that query input tokens (defined as constraint tokens) exhibit strong correlations with factual answer tokens \cite{yuksekgonul2024attention}.

FAVA \cite{mishra2024finegrained-FAVA} proposes a retrieval-augmented pipeline that integrates retrieval, comparison, and editing steps to identify and correct hallucinated spans. While effective, the multi-step process introduces complexity and alignment challenges, particularly in ensuring that the corrected responses remain consistent with the semantics of the original output.

% In summary, prior researches have laid a solid foundation for detecting hallucinated responses and spans. However, challenges such as reliance on internal model knowledge, computational complexity, and limited applicability to multilingual or low-resource settings remain. Our work builds upon these insights by proposing a novel framework that addresses these gaps through token-level context sensitivity analysis.
