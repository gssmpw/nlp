\section{Related Work}
\label{relatedwork}

\textbf{Alternative machine learning strategies to accelerate conformational analysis of small molecules.}
In this work, we analyze models that seek to shortcut expensive conformational analyses by predicting properties of expensive-to-simulate conformer ensembles from cheaper molecular representations. We emphasize that this approach is not the only ML strategy that has been proposed to accelerate or otherwise circumvent traditional analyses. Most notable are works that train neural network potentials (NNPs) to serve as a drop-in replacement for DFT-based energy/force evaluations, thereby permitting faster geometry optimizations ____. Auto3D ____, for instance, employs NNPs to rapidly optimize conformer ensembles at the $\omega$B97x/6-31G$^*$ level of theory. However, such NNPs do not natively replace the initial conformer search. To this end, many ML-based conformer generators have been proposed to accelerate or improve the coverage of traditional conformer generation ____, particularly for small drug-like molecules. Finally, varied studies train ML surrogate models to replace DFT-based property calculations (e.g., given a known geometry) ____, which is most helpful if computing properties from a given geometry is relatively expensive compared to obtaining the geometry itself. In principle, combining all three strategies into one end-to-end workflow could vastly accelerate traditional conformational analysis without needing shortcuts.

\textbf{Predicting properties of conformer ensembles from cheaper 3D molecular representations.}
Multiple studies have considered training ML surrogate models to predict properties of conformer ensembles from encodings of cheap 3D molecular structures. In general, prior work can be categorized based on (1) whether the ground-truth property labels are experimentally derived (and hence an implicit function of the unknown experimental conformer ensemble), or are derived from explicitly simulated conformer ensembles (our case); (2) whether the models encode single conformer instances or sets of conformers via multi-instance learning ____; and (3) whether the encoded conformers are of the same geometric quality as the ground truth simulated ensembles. For instance, ____ all train ML models to predict experimental observables (e.g., ligand bioactivity, catalyst selectivity, or solvation free energies) from sets of simulated conformers. In contrast, ____ and ____ train ML-based set-encoders to predict properties of simulated conformer ensembles. Both studies primarily consider models that encode the same conformer ensembles (or subsets thereof) as the ensembles from which the target properties were originally derived. ____ and ____ also predict experimental observables (molecular toxicitiy or $^{13}$C NMR chemical shifts), but use 3D models that encode a single conformer that is optimized with xTB or MMFF94, respectively. Finally, ____ predict reaction activation barriers that were originally simulated at a high level of theory (CCSD(T)-F12a) using 3D ML models that encode (single) conformers of the reactant and product molecules, which were optimized with either xTB or DFT. Notably, whereas ____ found that using MMFF94-level conformers instead of DFT-level conformers did not practically affect model accuracy in $^{13}$C chemical shift prediction, ____ found that in two tasks related to activation energy prediction, encoding DFT-level geometries improved model accuracy versus encoding xTB-level geometries.