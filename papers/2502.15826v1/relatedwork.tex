\section{Related Work}
\subsection{Knowledge Editing}
% Knowledge editing involves correcting erroneous information embedded in a model at a lower cost than retraining the entire model~\cite{wang2023knowledge,zhang2024comprehensive}. 
Existing knowledge editing methods can generally be divided into two categories: preserve and modify parameters.
One involves editing a model's knowledge without directly modifying its parameters. SERAC~\cite{mitchell2022memorybased} stores corrections in external memory and adjusts the model’s responses as needed. 
% highlights the resource-intensive nature of existing methods for knowledge editing in LLMs and 
IKE~\cite{zheng2023edit} proposes a solution based on in-context learning, which enables knowledge modification without parameter updates. GRACE~\cite{hartvigsen2023aging} maps keys to the latent space of the model without changing the weights, constructing a local codebook for knowledge editing. While these methods are resilient to catastrophic forgetting due to the lack of parameter modifications, they require additional memory, which increases with the number of knowledge updates.

Early approaches that modify model parameters for knowledge editing often relied on fine-tuning techniques using multi-loss optimization, as proposed by \citet{sinitsin2020editable}. However, fine-tuning methods can lead to overfitting, prompting the development of hyperparameter-based optimization methods. Knowledge editor (KE)~\cite{decao2021editing} addresses this by utilizing a hypernetwork to edit specific knowledge without affecting unrelated knowledge. ROME~\cite{meng2023locating} identifies the multi-layer perceptrons (MLPs) where factual knowledge is stored and inserts new key-value pairs into those MLPs to modify the model’s knowledge. MEMIT~\cite{meng2023massediting} extends this approach, allowing the insertion of large volumes of knowledge simultaneously. PMET~\cite{li2024pmet} further optimizes the hidden states of both the multi-head self-attention (MHSA) and feed-forward network (FFN) layers to update the feed-forward weights efficiently.

\subsection{Unlearning}
The concept of machine unlearning, introduced by \citet{cao2015towards}, focuses on the removal of knowledge that has already been learned by a model. 
% Although unlearning has been extensively studied in traditional machine learning, its application in the context of LLMs remains underexplored~\cite{bourtoule2020machineunlearning}. 
\citet{jang2022knowledge} employ gradient ascent to perform unlearning with the goal of alleviating privacy concerns, while \citet{eldan2023s} demonstrate unlearning by erasing specific knowledge related to the Harry Potter books from a model. \citet{chen2023unlearn} proposes freezing the LLM and introducing an unlearning layer to construct a forgotten model. \citet{yao-etal-2024-machine} presents a comprehensive framework for performing unlearning in LLMs using gradient ascent and KL divergence. \citet{hu2024separate} utilize parameter-efficient modules to preserve general model capabilities while removing untruthful or toxic information from LLMs.

% Traditional knowledge editing approaches often retain erroneous knowledge in the model, which can lead to confusion between pre-existing and new information~\cite{li2024unveilingpitfallsknowledgeediting}. 
% \citet{ni2024forgettinglearningutilizingparametric} propose an approach that first forgets existing knowledge before performing knowledge editing, though this method is prone to overfitting due to its reliance on fine-tuning. In contrast, our approach involves searching for the parameters where knowledge is stored and optimizing them for model updates. We develop a framework that applies unlearning to effectively remove outdated knowledge before editing the model with new information, integrating this into existing state-of-the-art editing techniques.

\citet{ni2024forgettinglearningutilizingparametric} propose an approach that performs unlearning of existing knowledge before knowledge editing. However, this method is prone to overfitting due to its reliance on fine-tuning. In contrast, our approach is applied to state-of-the-art model editing methods that address such issues. By effectively removing outdated knowledge during the injection of new information, we mitigate conflicts between the two processes.