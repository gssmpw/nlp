Building internet-scale agents requires a diverse scaffold of tasks and environment configurations beyond what can be attained via manually curated examples annotated by humans. We develop a pipeline to efficiently harness vast quantities of sites on the Internet that aims to facilitate Internet-Scale Training for Agents, shortened to InSTA. Our pipeline uses pretrained language models to generate, attempt, and evaluate synthetic web navigation tasks for a more diverse pool of sites than current efforts that rely on tasks designed by researchers \citep{Mind2Web,WebArena,AgentQ,VisualWebArena,VisualWebBench,WebLINX,AndroidInTheWild,WebVoyager}. Human data is a valuable resource, but can be inefficient to gather. Our work shows that language models can be as accurate as human annotators. By removing human data from the agent pipeline, we can improve the safety and reliability of tasks, and efficiently scale task generation to 1M sites.

\subsection{Language Model Task Proposer}
\label{sec:proposer}

In the first stage, we scale the generation of web navigation tasks to 1M diverse websites using a \textbf{Language Model Task Proposer}. Shown in Figure~\ref{fig:pipeline-stage-one}, the task proposer serves two key functions in the pipeline: (1) filtering out harmful content and websites that cannot be safely annotated, and (2) proposing realistic web navigation tasks that a hypothetical user might want to accomplish.

\begin{figure*}
    \centering
    \includegraphics[width=\linewidth]{assets/icml2025_insta_pipeline_stage_one.pdf}
    \vspace{-0.3cm}
    \caption{\small \textbf{Task proposal and filtering for 150k live websites.} Starting from 1,000,000 websites, we employ a pretrained language model that marks sites as safe/unsafe for annotation, and assigns a realistic task that a hypothetical user might want to accomplish on each site. The task proposer aggressively filters out 85\% of websites from the pipeline, resulting in 150k safe websites annotated with realistic tasks.}
    \vspace{-0.2cm}
    \label{fig:pipeline-stage-one}
\end{figure*}

\paragraph{Model Details.} We utilize pretrained and frozen language models that conform to a chat interface and accept a system prompt $\mathbf{x}_{\text{sys}}$, and a series of in-context examples through interleaved user and assistant prompts $\mathbf{x}_{\text{usr}}$ and $\mathbf{x}_{\text{ast}}$. The system prompt used for task generation is shown in Figure~\ref{fig:pipeline-stage-one}, and outlines all cases for which sites are considered unsafe for annotation. We consider the Llama 3.1 family of LLMs from Meta \citep{Llama3,Llama2,Llama}, the GPT family of LLMs from OpenAI, and the Gemini family of LLMs from Google. Inference is served using vLLM \citep{vLLM} for the Llama series of models. We employ a sampling temperature of 0.5, and a maximum budget of 64 newly generated tokens; all other parameters are kept as defaults in the OpenAI chat completions API, which is used to make inference calls to all LLMs. 

\paragraph{Prompt Details.} The goal of the task proposer is to accurately detect unsafe websites and generate realistic web navigation tasks when appropriate. We prompt the task proposer with the system prompt in Figure~\ref{fig:pipeline-stage-one}, a series of in-context examples (listed in Appendix~\ref{appendix:stage-one}), and a final user prompt containing just the URL of the target website. We instruct the LLM via the system prompt to provide a task for the target website or to return ``N/A'' and mark the website as not suitable for annotation. This format produces a throughput of 20 websites per second for \textit{Llama 3.1 70B} served on 16 GPUs with vLLM, processing 1M sites in 14 hours. The efficiency of stage one aids in scaling to large numbers of sites on the Internet, but we must not compromise safety and reliability for efficiency. To understand the trade-offs presented by our task proposal approach, we compare against typical human annotators at detecting safe websites for annotation and creating realistic agent tasks.

\begin{wrapfigure}{r}{0.48\textwidth}
    \centering
    \vspace{-1.3cm}
    \begin{tabular}{l|rrr}
    \toprule
    \textbf{Method} & \textbf{Acc.} & \textbf{Prec.} & \textbf{Recall} \\
    \midrule
    \midrule
     \textit{Llama 3.1 70B} & 85\% & 0.77 & \textbf{1.00} \\
     \textit{GPT-4o} & 95\% & 0.91 & \textbf{1.00} \\
     \textit{Gemini 1.5 Pro} & \textbf{97}\% & \textbf{0.96} & 0.98 \\
     \midrule
     Human Baseline & 75\% & 0.71 & 0.84 \\
    \bottomrule
    \end{tabular}
    \caption{\small \textbf{Accuracy for detecting harmful sites.} We select 100 website domains, where 50 are safe, and 50 are unsafe based on the criteria in Figure~\ref{fig:pipeline-stage-one}. Pretrained language models exceed the accuracy and recall of human annotators at detecting harmful sites that are unsuitable for training agents safely.}
    \label{tab:safety-experiment}
    \vspace{-0.3cm}
\end{wrapfigure}

\subsection{Improving Safety}
\label{sec:safety}

Language models \textit{beat single pass non-expert annotators} at detecting websites suitable for annotation. To evaluate detection performance, we employ the task proposer as a classifier and consider sites where the task proposer returns ``N/A'' as the positive class. We curate 50 safe and 50 unsafe domains, based on the filtering conditions outlined in the system prompt in Figure~\ref{fig:pipeline-stage-one} (selected websites and their URLs are listed in Appendix~\ref{appendix:stage-one}). We generate task proposals for each site and measure the accuracy, precision, and recall of our safety filter compared to human annotators. The annotators are asked to classify each site as suitable or unsuitable for annotation based on the website URL, and the criteria listed in the system prompt the same observations given to the task proposer to ensure a fair comparison. Results are presented in Table~\ref{tab:safety-experiment}. 

\paragraph{Understanding The Results.} Language models outperform human annotators by 29.3\% in accuracy, 35.2\% in precision, and  31.0\% in recall at detecting harmful sites. While larger models like \textit{Gemini 1.5 Pro} show the best overall accuracy, smaller models like \textit{Llama 3.1 70B} display high recall with a minor decrease in accuracy. Recall matters most for safety filters, and these results suggest that \textit{Llama 3.1 70B} is sufficient to detect most harmful sites with high confidence.

\subsection{Improving Reliability}
\label{sec:reliability}

Language models are \textit{more reliable than human annotators} at creating realistic web navigation tasks. To evaluate reliability, we measure the rate at which human workers are able to perform web navigation tasks generated by our pipeline. We curate a set of 100 safe website domains (different from the safety experiment, refer to Appendix~\ref{appendix:stage-one}), generate task proposals using our pipeline, and measure the rate of self-reported task completion for human workers performing tasks. Workers start from the initial website URL in their browser and navigate pages using their mouse and keyboard while staying on the original site, reporting once the task is complete or once they believe the task is not feasible on the current site. We compare the feasibility rates for tasks generated by our pipeline and tasks written by human annotators given the criteria listed in Figure~\ref{fig:pipeline-stage-one}. Results are shown in Table~\ref{tab:reliability-experiment}.

\begin{wrapfigure}{r}{0.48\textwidth}
    \centering
    \vspace{-0.4cm}
    \begin{tabular}{l|r}
    \toprule
    \textbf{Method} & \textbf{Feasibility Rate} \\
    \midrule
    \midrule
     \textit{Llama 3.1 70B} & 75\% \\
     \textit{GPT-4o} & 85\% \\
     \textit{Gemini 1.5 Pro} & \textbf{89}\% \\
     \midrule
     Human Baseline & 54\% \\
    \bottomrule
    \end{tabular}
    \caption{\small \textbf{Expert feasibility of proposed tasks.} We generate tasks for 100 safe websites (listed in Appendix~\ref{appendix:stage-one}), and measure the completion rates of human workers attempting to perform the generated tasks in their browser. Language models exceed the performance of human annotators at creating feasible web navigation tasks for agents.}
    \label{tab:reliability-experiment}
    \vspace{-0.1cm}
\end{wrapfigure}

\paragraph{Understanding The Results.} Language models outperform human annotators by 64.8\% at creating feasible web navigation tasks. Larger models like \textit{Gemini 1.5 Pro} display the best feasibility rates, but the smaller model \textit{Llama 3.1 70B} still outperforms the human annotators by 38.9\%. To understand the relationship between the popularity of the site being annotated and the reliability of human-written tasks, we conduct an experiment in Figure~\ref{fig:reliability-experiment-pagerank} comparing PageRank values \citep{PageRank} of sites according to the official June 2024 host-level web graph from \citet{CommonCrawl}, versus the feasibility rates of the proposed tasks from Table~\ref{tab:reliability-experiment}.

Although human annotators match the reliability of LLMs at creating feasible web navigation tasks for popular sites, LLMs outperform human annotators by 157.1\% for less popular sites with low PageRank values. As obscurity increases, human annotators are less familiar with the sites, and the reliability of their task proposals decreases by 55.7\%, whereas the reliability of tasks generated by LLMs remains relatively constant. This difference suggests that we should employ language models to ensure that task proposals are reliable as we begin to scale agents to vast numbers of sites on the Internet. However, where do we acquire this large and diverse set of websites to process for annotation?

\begin{wrapfigure}{r}{0.48\textwidth}
    \centering
    \vspace{-1.4cm}
    \includegraphics[width=\linewidth]{assets/reliability_success_rates.pdf}
    \vspace{-0.7cm}
    \caption{\small \textbf{Feasibility rates vs PageRank values.} We visualize PageRank values, a proxy for the popularity of websites, versus the expert feasibility rates of proposed web tasks. Human-written tasks perform on par with LLMs for popular sites, but as target sites become less popular and annotators are less familiar with them, LLMs begin to outperform human annotators at creating feasible tasks for agents.}
    \label{fig:reliability-experiment-pagerank}
    \vspace{-0.2cm}
\end{wrapfigure}

\subsection{Scaling To 150,000 Sites}
\label{sec:scaling-task-generation}

We propose to leverage open-source crawls of the internet for large-scale task generation. As of June, 2024, the web graph released by \citet{CommonCrawl} contains more than 300 million unique hosts, which we adapt to a data source for agents. In particular, we sort hosts by their PageRank values, and select the top 1M sites for task generation. CommonCrawl is likely to contain many sites not suitable for annotation, and the experiments in Section \ref{sec:safety} illustrate that the safety filter in the task proposer can detect and remove them effectively. In our configuration, task generation with \textit{Llama 3.1 70B} takes 14 hours for 1M sites served with vLLM \citep{vLLM} on two 8-GPU nodes. Sections \ref{sec:safety} and \ref{sec:reliability} show \textit{Llama 3.1 70B} outperforms human annotators in safety and reliability, and we can serve it locally at significantly reduced cost compared to proprietary LLMs with a marginal loss in quality. The distribution of tasks generated with \textit{Llama 3.1 70B} for the top 1M sites in the CommonCrawl PageRank are visualized in Figure~\ref{fig:task-distribution}.

\paragraph{Understanding The Data.} The task proposer filters out 85\% of the sites in CommonCrawl, resulting in 150k sites that can be safely assigned tasks for agents. Visualized in Figure~\ref{fig:task-distribution}, our distribution is denser than human-written tasks, has a wide coverage of real-world sites, and diverse categories of tasks. We automatically label task categories (procedure in Appendix~\ref{appendix:stage-one}) and find that 89\% of categories have fewer than the mean of 16.9 tasks per category. Top categories include \textit{news search}, \textit{recipe search}, \textit{product lookup}, \textit{tutorial search}, \textit{event schedules}, \textit{health information}, and many more. Refer to Appendix~\ref{appendix:stage-one} for the top categories. Empowered by this large and diverse collection of tasks across the internet, we can start building internet-scale agents.

\begin{wrapfigure}{r}{0.48\textwidth}
    \centering
    \vspace{-1.8cm}
    \includegraphics[width=\linewidth]{assets/insta_vs_mind2web_distributon.pdf}
    \vspace{-0.7cm}
    \caption{\small \textbf{Distribution of 150k tasks.} We compare the distribution of tasks generated by our pipeline (\textit{blue} points) to the Mind2Web \citep{Mind2Web} dataset (\textit{orange} points) via textual features extracted by a sentence embedding model, and projected in 2D with UMAP \citep{UMAP}. Our distribution is denser than human-written tasks, and has broad coverage of diverse real-world sites and  tasks.}
    \vspace{-0.1cm}
    \label{fig:task-distribution}
\end{wrapfigure}