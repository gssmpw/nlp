\section{INTRODUCTION} 

% focusing on the practical side 

% key message: 

% 1. P1: 
%     1. what’s the goal of code summarization, who can benefit from code summarization;
%     2. the necessity of large-scale and high-quality datasets for learning based models 
%     3. Many datasets mined from real-world project repositories (GitHub) has been constructed. Models are trained and evaluated on them. 
% 2. P2: 
%     1. the datasets contain noise, from **differences in coding conventions and assumptions employed in modern programming languages and IDEs, as well as ad hoc nature of development processes and practices [54]**
%     2. e.g., multi-lingual natural languages → increasing the complexity of understanding the code 
%     3. existing studies confirmed some types of noise: such as auto-generated code [30], TODO comments [14], and incomplete comments [60]. 
%     4. Particularly, Steidl et al 
% 3. Motivation: to investigate the concern of data quality for code summarization
%     1. systematic study to **assess and improve the quality of four datasets** 
%     2. research methodology overview: four steps  
%         1. a taxonomy of 12 noisy types 
%         2. rule-based cleaning tool 
%         3. asses the dataset quality 
%         4. impact of noises on three code summarization models 
%         5.



% 
% In the first paragraph, we introduce what's the goal of code review, who benefit from code review. 
% The intention of code review has 
% can we add some examples to make it concrete 

%P1: introduce the significance of automate code review and the source of construcing datasets 
xx has shown that code review is useful for practitioners to identify the deep logic bugs, improve software quality and beneficial for knowledge transfer. 
At the core part of the code review, reviewer's feedback as expressed in natural language serve as the bridge to realise this. However, this process is often time-consuming and takes a lot of effort. xx has reported that developers spend xx of their time for code review. 
To reduce the burden of human reviewers, recent work in has been focusing on automating code review comment generation by training neural models on large-scale datasets. 
These datasets are often constructed from real-life projects in open-source platforms such as GitHub. 
For example, Li et al., (2022) mined xxK datasets over xx projects and Tufano et al., (2021) mined xx instances from Gerrit. Many follow-up models has been trained and evaluated based on these datasets. 

%P2: Introduce the problem of dataset quality: noise exist in datasets and what's the consequence or concern
% TODO: need defintion for noisy 

Although much effort has been put into cleaning the datasets, such as removing bots, filtering out noisy comments using heuristics, xx and xx. 
However, recent work (Tufano et al., 2024) raised concerns about the quality of three popularly used datasets and pointed out that the noise persistent in these datasets. 
This is not ideal. As these datasets are used to train and evaluate models. 
Correspondingly, models trained on noisy data will capture the noise inside the data, and generate comments that are less practically useful when being used in real-life by practitioners. 
On the other hand, existing works rely on human review comments as ground truth to evaluate the performance of code review comment generation models, while the existence of noisy comments means that the evaluation will not reflect the true needs of practitioners. 

%P3: point out the challenge of identifying noisy comments. 
Although many has been shown that the high-quality dataset has big impact on training high-performing neural models in various context [xx]. Identifying the noise code review comments remains to be a challenge as it requires deep understanding of both the code changes, natural language comments and the interaction between them. Understanding the code changes involve prior knowledge in both code and potentially project specific knowledge, while understanding the semantics in review comments is also a challenge as it could be ambiguous, requiring inference. 

Inspiring by the recent advancements in large-language models that are pre-trained on multiple sources datasets such as text-corpora and code, they has shown promising performance on understanding the both code and language on various benchmarks []. Many recent work has been shown that LLMs can be used for data annotation. 
In this paper, we propose to leverage the power of large-language models to clean noisy data and then assess the impact of noisy data on comment generation models. 


% However, recent work (Tufano et al., 2024) pointed out that these datasets are noisy due to various reasons, such as
% not asking for code changes, 


% concerns: 
% existing works using human comments as ground truth to evaluate model performance 
% however, as xx pointed out, the quality of code review comments vary, many noisy comments exist. 
% This raises concerns regarding in evaluation, because we don't know what we really want our model to generate. 

% On the other hand, 

% Code review comments are important for practitioners. If our trained model only generate meaningless or unreliable comments, which will not be 

% On the other side, the quality of code review comments is also important for training models to 
% In this study, we 
% Due to this, the performance of classification may degrade [14].


% \section{Approach}

Our main contributions are: 
\begin{itemize}
    \item We found the 36\% comments in the code reviewer dataset are noisy and show that 11.5\% - 21.4\% noisy in code review comments can be effectively removed by leveraging the recent large-language models. Our cleaned dataset will be publicised for future research. 
    \item We empirically show that by removing noisy comments can improve models' performance on code review comment generation models. {\color{blue} emphasise the codeT5 vs CodeReviewer.}. 
    \item Our deep analysis on the generated comments on original and cleaned datasets show that xx types of comments benefited most, highlighting the importance of high-qualiy dataset.
\end{itemize}

\textbf{Open Science} To support future work on , the replication package, including the data we cleaned using large langauge models, the experimental results and scripts are available at [TODO].


\textbf{Open Science:} To facilitate reproducibility and foster further research, we provide the replication package at [TODO]. This package includes cleaned datasets, experimental results, and scripts, enabling researchers to build upon our work in advancing automated code review.

\textbf{Paper Organization:} The remainder of this paper is structured as follows: Section~\ref{sec:study_design} outlines the overview of our study design. In Section~\ref{sec:identifying_noisy_comments_rq1} presents our approach to identifying noisy comments in code review datasets. Section~\ref{sec:noise_impact_on_comment_generation_models_rq2} explores the impact of these noisy comments on machine learning models, while Section~\ref{sec:noisy_impact_on_generated_comment_quality_rq3} evaluates the quality of comments generated by models trained on cleaned datasets. We discuss our findings and their implications in Section~\ref{sec:discussion}. Section~\ref{sec:related_work} contextualizes our work within the existing literature, and Section~\ref{sec:threats_to_validity} addresses potential threats to the validity of our study. Finally, Section~\ref{sec:conclusion} draws the conclusions. 



\begin{table*}[h]
\small 
\centering
\caption{Model Performance on Comment Generation Models.}
\label{table:comment_gen_main_results}
% \resizebox{\textwidth}{!}{%
\begin{tabular}{l|lcc|ccc|ccc}
\toprule 
\textbf{Model} & \textbf{Data Set} & \textbf{\#Training } & \textbf{\#Valid} &  \multicolumn{3}{c}{\textbf{BLEU-4}}  & \multicolumn{3}{c}{\textbf{BLEU-4 (W/O Stop) }}\\ 
~& ~ & ~ & ~ & \textbf{Test$\uparrow$} & \textbf{Valid$\uparrow$} & \textbf{Noisy$\downarrow$} & \textbf{Test$\uparrow$} & \textbf{Valid$\uparrow$} & \textbf{Noisy$\downarrow$} \\ \midrule
Transformer-b & \multirow{8}{*}{Origin} & \multirow{8}{*}{117739} & \multirow{8}{*}{10319} & 4.76 & - & - & - & - & - \\ 
Tufano et al. &  &  &  & 4.39 & - & - & - & - & - \\ 
CodeT5 &  &  &  & 4.83 & - & - & - & - & - \\ 
CommentFinder &  &  &  & 3.82 & - & - & - & - & - \\ 
CodeReviewer (Reported) &  &  &  & 5.32 & - & - & - & - & - \\ 
LLaMA-Reviewer-Prefix  &  &  &  & 5.16 & - & - & - & - & - \\ 
LLaMA-Reviewer-LoRA  &  &  &  & 5.70 & - & - & - & - & - \\ 
CCT5 (Lin et al., 2023) &  &  &  & \textbf{6.30} & - & - & - & - & - \\ \midrule 
\multirow{5}{*}{CodeReviewer} & Origin & 117739 & 10319 & 5.73 & 7.12 & 5.60 & 7.33 & 9.55 & 7.75 \\ 
 & Clean\_Llama3 & 87872 & 7571 & 5.97 & \underline{7.71} & 5.14 & \textbf{7.44} & \textbf{10.25} & 6.52 \\ 
 & Control\_Llama3 & - & - & 5.63 & 7.45 & 5.86 & 7.22 & 9.67 & 7.34 \\ 
 & Clean\_GPT-3.5 & 39625 & 3395 & \underline{6.04} & \textbf{7.99} & 4.83 & \underline{7.41} & \underline{10.07} & 5.98 \\ 
 & Control\_GPT-3.5 & - & - & 5.63 & 7.39 & 5.70 & 7.26 & 9.54 & 8.21 \\ \midrule 
\multirow{5}{*}{CodeT5} & Origin & 117739 & 10319 & 5.19 & 5.85 & 6.03 & 6.64 & 6.83 & 7.79 \\ 
 & Clean\_Llama3 & 87872 & 7571 & 5.54 & 6.09 & 5.46 & 6.87 & 7.76 & 6.79 \\ 
 & Control\_Llama3 & - & - & 5.21 & 5.38 & 5.01 & 6.45 & 6.70 & 6.06 \\ 
 & Clean\_GPT-3.5 & 39625 & 3395 & 5.67 & 6.06 & 5.15 & 6.79 & 7.41 & 5.54 \\ 
 & Control\_GPT-3.5 & - & - & 5.20 & 5.45 & 5.41 & 6.45 & 7.03 & 6.29 \\ \bottomrule 
\end{tabular}%
% }
\end{table*}







% \begin{table*}[h]
% \small 
% \centering
% \caption{Model Performance on Comment Generation Models.}
% \label{table:comment_gen_main_results}
% \setlength{\tabcolsep}{0.8pt}  % Adjust the spacing between columns here
% \resizebox{0.98\textwidth}{!}{
% \begin{tabular}{ll|lllllll|lllllll}
% \toprule 
% \textbf{$M$} & \textbf{Dataset} &  \multicolumn{7}{c|}{\textbf{BLEU-4}} & \multicolumn{7}{c}{\textbf{BLEU-4 (W/O Stop)}} \\ 
% ~ & ~ & \textbf{Test} & \textbf{Valid} & \textbf{Noisy} & \textbf{Valid$_{\text{T}}$} & \textbf{Noisy$_{\text{T}}$} & \textbf{Valid$_{\text{C}}$} & \textbf{Noisy$_{\text{C}}$} & \textbf{Test} & \textbf{Valid} & \textbf{Noisy} & \textbf{Valid$_{\text{T}}$} & \textbf{Noisy$_{\text{T}}$} & \textbf{Valid$_{\text{C}}$} & \textbf{Noisy$_{\text{C}}$} \\ \midrule
% \multirow{5}{*}{\rotatebox{90}{CodeReviewer}} & Origin & 5.73 & 5.45 & 5.17 & 7.12 & 5.60 & 6.17 & 5.41 & 7.33 & 6.80 & 6.32 & 9.55 & 7.75 & 8.04 & 6.96 \\
% ~ & Clean\_Llama3 & \underline{5.97} \ 4.2\%↑ & 5.64 \ 3.5\%↑& 5.11 \ 1.2\%↓ & \underline{7.71} \ 8.3\%↑ & 5.14  \ 8.2\%↓ & \underline{6.63} \ 7.5\%↑ & 5.18 \ 4.3\%↓ & \textbf{7.44} \ 1.5\%↑ & 7.02 \ 3.2\%↑ & 6.49 \ 2.7\%↑ & \textbf{10.25} \ 7.3\%↑ & 6.52 \ 15.9\%↓ & \underline{8.57} \ 6.6\%↑ & 6.56 \ 5.7\%↓ \\
% ~ & Control\_Llama3 & 5.63 & 5.12 & 5.36 & 7.45 & 5.86 & 6.18 & 5.66 & 7.22 & 6.48 & 6.77 & 9.67 & 7.34 & 7.95 & 7.06 \\
% ~ & Clean\_GPT-3.5&  \textbf{6.04} \ 5.4\%↑ & \textbf{5.93} \ 8.8\%↑ & 5.19 \ 0.4\%↑ & \textbf{7.99} \ 12.2\%↑ & 4.83 \ 13.8\%↓ & \textbf{6.97} \ 13.0\%↑ & 5.02 \ 7.2\%↓ & \underline{7.41} \ 1.1\%↑ & \textbf{7.40} \ 8.8\%↑ & 6.17 \ 2.4\%↓ & \underline{10.07} \ 5.4\%↑ & 5.98  \ 22.8\%↓ & \textbf{8.75} \ 8.8\%↑ & 6.08 \ 12.6\%↓\\
% ~ & Control\_GPT-3.5 & 5.63 & 5.21 & 5.13 & 7.39 & 5.70 & 6.20 & 5.43 & 7.26 & 6.48 & 6.63 & 9.54 & 8.21 & 7.89 & 7.37 \\ \midrule 
% \multirow{5}{*}{\rotatebox{90}{CodeT5}} & Origin&  5.19 & 4.84 & 5.09 & 5.85 & 6.03 & 5.34 & 5.04 & 6.64 & 5.82 & 6.88 & 6.83 & 7.79 & 6.59 & 6.75 \\ 
% ~ & Clean\_Llama3& 5.54 \ 6.7\%↑ & 5.32 \ 9.9\%↑& 5.14 \ 1.0\%↑ & 6.09 \ 4.1\%↑ & 5.46 \ 9.5\%↓ & 5.74 \ 7.5\%↑ & 5.33 \ 5.8\%↑ & 6.87 \ 3.5\%↑ & 6.63 \ 13.9\%↑ & 6.10 \ 11.3\%↓ & 7.76 \ 13.6\%↑ & 6.79 \ 12.8\%↓ & 7.24 \ 9.9\%↑ & 6.52 \ 3.4\%↓\\
% ~ & Control\_Llama3& 5.21 & 4.95 & 5.26 & 5.38 & 5.01 & 5.19 & 5.12 & 6.45 & 5.66 & 6.98 & 6.70 & 6.06 & 6.20 & 6.55 \\
% ~ & Clean\_GPT-3.5 & 5.67 \ 9.2\%↑ & \underline{5.88} \ 21.5\%↑ & 5.27 \ 3.5\%↑ & 6.06 \ 3.6\%↑ & 5.15 \ 14.6\%↓ & 6.00 \ 12.4\%↑ & 5.23 \ 3.8\%↑ & 6.79 \ 2.3\%↑ & \underline{7.17} \ 23.2\%↑ & 5.92 \ 14.0\%↓ & 7.41 \ 8.5\%↑ & 5.54 \ 28.9\%↓ & 7.32 \ 11.1\%↑ & 5.76 \ 14.7\%↓ \\
% ~ & Control\_GPT-3.5 & 5.20 & 5.17 & 5.39 & 5.45 & 5.41 & 5.34 & 5.30 & 6.45 & 6.20 & 6.68 & 7.03 & 6.29 & 6.67 & 6.33 \\ \bottomrule 
% \end{tabular}
% }
% \end{table*}




% \begin{table}[!t]
% % \small 
% \setlength{\tabcolsep}{4.5pt}
% \centering
% \begin{tabular}[width=0.45\textwidth]{l|cc|ccc}
% \toprule
% \multirow{2}{*}{\textbf{Training Set}} & \multicolumn{2}{c|}{\textbf{Information }} & \multicolumn{3}{c}{\textbf{Relevance }}  \\
% % \cline{2-8}
% % \midrule
% \cmidrule(lr){2-6} %\cmidrule(lr){5-8}
% & Valid & Noisy  & Valid & Noisy  &Test (all) \\
% \midrule
% \textsc{Original} & 3.50 & 3.40 &  2.43 & 2.54  & 3.69 \\
% \textsc{Clean\_Llama3} & 4.08 & 4.10 & 2.70 & \textbf{2.74}  & 3.85 \\
% \textsc{Control\_GPT-3.5} & \textbf{4.28} & \textbf{4.26} & \textbf{2.80} & \textbf{2.74}  & \textbf{4.38} \\
% \bottomrule
% \end{tabular}
% \caption{Information and Relevance Scores for Different Training Sets on CodeReviewer model.}
% \label{table:information_relevance_scores}
% \end{table}



\begin{table*}[h]
        \small 
        \centering
        \caption{Model Performance on Comment Generation Models.}
        \label{table:comment_gen_main_results}
        \setlength{\tabcolsep}{3pt}  % Adjust the spacing between columns here
        % \resizebox{0.98\textwidth}{!}{
        \begin{tabular}{ll|l|ll|ll|ll}
        \toprule 
        % \textbf{$M$} & \textbf{Dataset} &  \multicolumn{7}{c}{\textbf{BLEU-4}} \\ 
        \textbf{$M$} & \textbf{Dataset} & \textbf{Test} & \textbf{Valid$_{\text{our}}$} & \textbf{Noisy$_{\text{our}}$} & \textbf{Valid$_{\text{T}}$} & \textbf{Noisy$_{\text{T}}$} & \textbf{Valid$_{\text{C}}$} & \textbf{Noisy$_{\text{C}}$}  \\ \midrule
          \multicolumn{9}{c@{}}{\textbf{BLEU-4 }} \\ \midrule 
        \multirow{5}{*}{\rotatebox{90}{CodeReviewer}} & \textsc{Origin} & 5.73 & 5.45 & 5.17 & 7.12 & 5.60 & 6.17 & 5.41  \\
        ~ & \textsc{Clean\_Llama3} & \underline{5.97} \ 4.2\%↑ & 5.64 \ 3.5\%↑& 5.11 \ 1.2\%↓ & \underline{7.71} \ 8.3\%↑ & 5.14  \ 8.2\%↓ & \underline{6.63} \ 7.5\%↑ & 5.18 \ 4.3\%↓ \\
        ~ & \textsc{Control\_Llama3} & 5.63 & 5.12 & 5.36 & 7.45 & 5.86 & 6.18 & 5.66\\
        ~ & \textsc{Clean\_GPT-3.5} &  \textbf{6.04} \ 5.4\%↑ & \textbf{5.93} \ 8.8\%↑ & 5.19 \ 0.4\%↑ & \textbf{7.99} \ 12.2\%↑ & 4.83 \ 13.8\%↓ & \textbf{6.97} \ 13.0\%↑ & 5.02 \ 7.2\%↓ \\
        ~ & Control\_GPT-3.5 & 5.63 & 5.21 & 5.13 & 7.39 & 5.70 & 6.20 & 5.43 \\ \midrule 
        \multirow{5}{*}{\rotatebox{90}{CodeT5}} & \textsc{Origin}&  5.19 & 4.84 & 5.09 & 5.85 & 6.03 & 5.34 & 5.04  \\ 
        ~ & \textsc{Clean\_Llama3}& 5.54 \ 6.7\%↑ & 5.32 \ 9.9\%↑& 5.14 \ 1.0\%↑ & 6.09 \ 4.1\%↑ & 5.46 \ 9.5\%↓ & 5.74 \ 7.5\%↑ & 5.33 \ 5.8\%↑ \\
        ~ & \textsc{Control\_Llama3}& 5.21 & 4.95 & 5.26 & 5.38 & 5.01 & 5.19 & 5.12 \\
        ~ & \textsc{Clean\_GPT-3.5} & 5.67 \ 9.2\%↑ & \underline{5.88} \ 21.5\%↑ & 5.27 \ 3.5\%↑ & 6.06 \ 3.6\%↑ & 5.15 \ 14.6\%↓ & 6.00 \ 12.4\%↑ & 5.23 \ 3.8\%↑ \\
        ~ & \textsc{Control\_GPT-3.5} & 5.20 & 5.17 & 5.39 & 5.45 & 5.41 & 5.34 & 5.30  \\  \midrule \midrule
           \multicolumn{9}{c@{}}{\textbf{BLEU-4 (W/O Stop Words)}}  \\ 
         \cmidrule(lr){1-9}  % This line adds the horizontal rule
        \multirow{5}{*}{\rotatebox{90}{CodeReviewer}} & \textsc{Origin} & 7.33 & 6.80 & 6.32 & 9.55 & 7.75 & 8.04 & 6.96 \\
        ~ & \textsc{Clean\_Llama3}  & \textbf{7.44} \ 1.5\%↑ & 7.02 \ 3.2\%↑ & 6.49 \ 2.7\%↑ & \textbf{10.25} \ 7.3\%↑ & 6.52 \ 15.9\%↓ & \underline{8.57} \ 6.6\%↑ & 6.56 \ 5.7\%↓ \\
        ~ & \textsc{Control\_Llama3} & 7.22 & 6.48 & 6.77 & 9.67 & 7.34 & 7.95 & 7.06 \\
        ~ & \textsc{Clean\_GPT-3.5} &  \underline{7.41} \ 1.1\%↑ & \textbf{7.40} \ 8.8\%↑ & 6.17 \ 2.4\%↓ & \underline{10.07} \ 5.4\%↑ & 5.98  \ 22.8\%↓ & \textbf{8.75} \ 8.8\%↑ & 6.08 \ 12.6\%↓\\
        ~ & Control\_GPT-3.5 &  7.26 & 6.48 & 6.63 & 9.54 & 8.21 & 7.89 & 7.37 \\ \midrule 
        \multirow{5}{*}{\rotatebox{90}{CodeT5}} &  \textsc{ORIGIN} &  6.64 & 5.82 & 6.88 & 6.83 & 7.79 & 6.59 & 6.75 \\ 
        ~ & \textsc{Clean\_Llama3}& 6.87 \ 3.5\%↑ & 6.63 \ 13.9\%↑ & 6.10 \ 11.3\%↓ & 7.76 \ 13.6\%↑ & 6.79 \ 12.8\%↓ & 7.24 \ 9.9\%↑ & 6.52 \ 3.4\%↓\\
        ~ & \textsc{Control\_Llama3}&  6.45 & 5.66 & 6.98 & 6.70 & 6.06 & 6.20 & 6.55 \\
        ~ & \textsc{Clean\_GPT-3.5} & 6.79 \ 2.3\%↑ & \underline{7.17} \ 23.2\%↑ & 5.92 \ 14.0\%↓ & 7.41 \ 8.5\%↑ & 5.54 \ 28.9\%↓ & 7.32 \ 11.1\%↑ & 5.76 \ 14.7\%↓ \\
        ~ & \textsc{Control\_GPT-3.5} &  6.45 & 6.20 & 6.68 & 7.03 & 6.29 & 6.67 & 6.33 \\ \bottomrule 
        \end{tabular}
        % }
        \end{table*}