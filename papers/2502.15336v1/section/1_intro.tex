\section{Introduction}
\label{sec:intro}

Embodied intelligence, the idea that cognition arises from physical interaction with the environment, emerged as a critique of traditional cognitive theories. Rodney Brooks' 1991 paper \cite{brooks1991intelligence}, ``Intelligence Without Representation,'' argued that intelligent behavior can emerge without relying on internal representations, focusing instead on environmental interaction. This idea was further developed by Varela, Thompson, and Rosch in The Embodied Mind (1991) \cite{varela2017embodied}, which highlighted the role of bodily experience in shaping cognition. Similarly, Lakoff and Johnson's Philosophy in the Flesh (1999) emphasized that cognition is grounded in sensory-motor experiences \cite{lakoff1999review}. The concept also found practical applications in robotics, as seen in the Cog Project, which explored how robots could develop cognition through bodily interaction with the world \cite{brooks1998cog}. Thus, embodied intelligence bridges cognitive science, philosophy, and robotics, offering a more integrated view of mind and body.

With the rapid advancement of large model technology, embodied intelligence is increasingly being integrated with these models. This is a relatively new concept, where researchers seek to apply principles of embodied cognition to large-scale pre-trained models. The aim is to explore how Artificial Intelligence (AI) can develop more flexible and adaptive capabilities through interactions with the environment. The term ``Embodied Multimodal Large Models'' (EMLMs) refers to a class of models that combine multiple modalities of data (e.g., vision, language, and action) with embodied capabilities (e.g., perception and interaction within physical environments). These models are also known by various other names, such as ``Large Embodied Multimodal Models,'' ``Embodied Large Models,'' and ``Large Embodied Models.'' While these terms are often used interchangeably, they all highlight the integration of multimodal understanding with the ability to perceive and interact with the world in a physically embodied manner. In this paper, we adopt the term EMLMs to encompass all such variations. We provide a comprehensive exploration of the development, datasets, and challenges associated with these models, offering a detailed analysis of their current state and future potential.

EMLMs are an exciting and rapidly evolving area within the fields of AI and robotics. Unlike traditional AI systems, EMLMs integrate diverse sensory modalities, such as vision, language, and audio, into agents capable of perceiving and interacting with their physical environments. EMLMs aim to bridge the gap between AIâ€™s abstract reasoning abilities and the real-world complexities, allowing intelligent systems to perceive, act, and learn in ways that are more closely aligned with human cognition. These models can simultaneously process multimodal input and generate outputs that influence the physical world, making them critical for applications such as robotic manipulation, autonomous navigation, human-robot interaction, and immersive virtual environments.

\begin{figure*}[t]
	\centering
	%\fbox{\rule{0pt}{2in} \rule{0.9\linewidth}{0pt}}
	\includegraphics[width=1.0\linewidth, trim={5 65 10 60}, clip]{pictures/TIMELINE.pdf}
	
	\caption{A timeline of research progress in the field of Embodied Perception, Navigation and Interaction.}
	\label{fig:Section3}
\end{figure*}

In recent years, the integration of large models with multimodal perception systems, such as embodied agents, has led to the development of breakthrough models capable of tackling increasingly complex tasks. However, the field of embodied intelligence with large models remains in its early stages, and several challenges persist. These include enhancing model scalability and generalization, improving the ability to handle complex tasks, and advancing the capacity of embodied agents to interact more effectively with their environments.

Although significant progress has been made in this field, several key issues persist in the current review papers on EMLMs. First, most existing reviews primarily focus on traditional large models in natural language processing, such as LLMs \cite{zhao2023survey} \cite{chang2024survey} \cite{naveed2023comprehensive}, large vision models, and language-vision models \cite{li2024multimodal}, rather than explaining the integration of embodied agents with large models. Second, even some reviews do focus on this integration, the scope is often too broad. For instance, papers \cite{wu2024embodied} \cite{du2024advancements} \cite{liu2024aligning} \cite{roy2021machine} concentrate on the entire development process of embodied intelligence, including both software and hardware, without delving deeply into the role of multimodal large models in the evolution of embodied intelligence. Additionally, some prior works \cite{firoozi2023foundation} \cite{duan2022survey} \cite{xi2023rise} were published before the most recent rapid advancements in the field, limiting their ability to capture the state-of-the-art developments. Some papers focus solely on specific big model technologies within the embodied intelligence full stack, rather than addressing the big model technologies across each link of the stack. For instance, the paper \cite{ma2024survey} primarily examines the big model in the intelligent agent operation segment, but does not consider the big model in the navigation component.

To address these gaps, this paper provides a comprehensive review of recent developments in EMLMs, focusing on four key areas: (1) technical advancements in foundational large models, such as LLM and LVMs, which are driving the development of EMLMs, (2) the current technical roadmap for EMLMs across various tasks, including perception, navigation, interaction, and simulation, (3) the impact of multimodal datasets on model performance, and (4) challenges and opportunities for the future development of EMLMs. Our aim is to offer a thorough overview of existing progress and identify potential future directions. We hope that this review will serve as a valuable reference and a source of inspiration for researchers in this field.

The main contributions of this paper are summarized as follows:

\begin{enumerate}
    \item First Systematic Review of Research Progress in EMLMs: To the best of our knowledge, this paper is the first to systematically review the research progress in the field of EMLMs, addressing a significant gap in the existing literature.
    \item Comprehensive Full-Stack Analysis: This study analyzes 300 research papers and conducts a comprehensive full-stack analysis of EMLMs, covering basic big models, embodied perception big models, embodied navigation big models, embodied interaction big models, simulation techniques, and datasets. Through in-depth analysis, readers can have a comprehensive understanding of the development of EMLMs.
    \item Benchmark datasets and Collection Methods: We summarize the benchmark datasets used in EMLMs, detailing their collection methods. Additionally, we analyze the key features of these datasets, including data format, functionality, applicable platforms, as well as their advantages and limitations.
    \item Main Findings and Future Research Directions: Finally, we discuss the primary findings of this review, provide insights into the application of EMLMs in embodied agents, and outline promising directions for future research in this rapidly evolving field.
\end{enumerate}

The remainder of this paper is organized as follows: In Section \ref{sec:LM}, we explore the development of large models, and other emerging architectures, outlining their contributions to the EMLMs. Section \ref{sec:EMLM} delves into the development of EMLMs, discussing key components, such as embodied perception, navigation, interaction, and simulation, which are critical for enabling EMLMs to engage with and respond to real-world environments. Section \ref{sec:DATA} provides an overview of the datasets used to train and evaluate EMLMs, highlighting the challenges and importance of high-quality, diverse data for effective learning. In Section \ref{sec:CFD}, we address the major challenges faced by the field, including scalability, generalization, real-time decision-making, and the seamless integration of different modalities. Additionally, we identify promising future research directions. Finally, Section \ref{sec:CON} concludes the paper by summarizing the key findings and offering insights into the future trajectory of EMLMs.
%\kai{Check whether we put abbreviations here or in the abstract.}

% \indent Through this review, we aim to offer a comprehensive understanding of the current landscape of EMLMs, and to inspire further research that can overcome existing challenges and push the boundaries of Embodied Artificial Intelligence.

