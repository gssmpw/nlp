\section{Related Work}
\begin{figure*}[tb]
\centering
\includegraphics[scale=0.65]{figures/mainfig.pdf}
\caption{The proposed framework.~\ourmethod~generates a set of natural language property descriptions from data, i.e., documents (1a); then estimates the compatibility between each data point and each property (1b), and perform correlation-based grouping of properties to discover latent factors (2). The compatibility between each property is efficiently computed using a distilled dense text representation model. We provide additional details and examples in~\Cref{fig:our_framework_detailed} and~\Cref{sec:our_framework_detailed}.
}
\label{fig:our_framework}
\vspace{-2mm}
\end{figure*}




\paragraph{Latent Factor Models}
Latent factor models (LFMs) assume observed data in a dataset are governed by a set of latent factors. 
Traditional algorithms for estimating latent factors from data such as LDA~\cite{Blei2009LatentDA}, PCA~\cite{Jolliffe2016PrincipalCA}, and Autoencoders~\cite{Rumelhart1986LearningIR}. 
Oftentimes, practitioners gain insight into the dataset by interpreting the learned factors, such as reading the topics in an LDA model or generating samples from the latent space of a variational autoencoder~\cite{Kingma2013AutoEncodingVB}.


\paragraph{LLMs for Insight Mining}
Recently, there have been some successes in using LLM-based systems for analyzing textual documents, such as using LLMs to discover topics from documents~\cite{pham-etal-2024-topicgpt} or clustering documents~\cite{wang-etal-2023-goal}.
The most relevant framework to our work is TopicGPT~\cite{pham-etal-2024-topicgpt}, which uses LLM to propose potential topics by sequentially iterating over the dataset and generating new topics based on prior outputs.


\paragraph{Key Differences} While drawing insprirations from the above areas,~\ourmethod~is the first work to combine LLMs' instruction-following ability with statistical models for goal-conditioned latent factor discovery.
In contrast to pure-LLM-based frameworks, our method only rely on LLMs to document interesting properties from data, which is less reliant on LLMs' reasoning ability.
By combining these LLM-proposed, goal-oriented properties with statistical-model-based latent factor models, we later show in our experiments that~\ourmethod~is the only method that can discover informative patterns from noisy data such as conversation and embodied navigation logs.
We provide further discussion on other related research areas in~\Cref{sec:further_related_work}.