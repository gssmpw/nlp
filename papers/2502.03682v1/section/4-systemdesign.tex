\begin{table}[t]
    \small
    \centering
    \caption{OS-level and physical signals analyzed by \sys to detect \ipvact.}\label{tab:modalitycontent}
    \begin{tabular}{@{}lll@{}}
    \toprule
    \textbf{Category}                      & \textbf{Modality}                      & \textbf{Description}                     \\ \midrule
    \multirow{8}{*}{IMU}                   & \multirow{5}{*}{Motion Data}           & Gyroscope                                \\
                                           &                                         & Accelerometer                            \\
                                           &                                         & Linear accelerometer                     \\
                                           &                                         & Magnetometer                             \\
                                           &                                         & Rotation vector sensor                   \\ \cmidrule{2-3}
                                           & \multirow{3}{*}{Environment Data}      & Proximity sensor                         \\
                                           &                                         & Pressure sensor                          \\
                                           &                                         & Light sensor                             \\ \midrule
    \multirow{7}{*}{Systems (SYS)}               & \multirow{2}{*}{Network Traffic}       & Upstream Bandwidth                       \\
                                           &                                         & Downstream Bandwidth                     \\ \cmidrule{2-3}
                                           & \multirow{3}{*}{Energy Consumption}    & Current                                  \\
                                           &                                         & Voltage                                  \\
                                           &                                         & Temperature                              \\ \cmidrule{2-3}
                                           & \multirow{2}{*}{Memory Utilization}    & Memory used                              \\
                                           &                                         & \#App usages in memory                   \\ \midrule
     \multirow{2}{*}{Interaction (INT)}                            & \multirow{2}{*}{Screen Interaction}    & Interaction rate                         \\
                                           &                                         & Interaction event                        \\ \midrule
    Application (APP)                            & Application Activeness                 & Foreground app name                      \\ \bottomrule
    \end{tabular}
\end{table}








\section{\sys~Design}\label{sec-4-sysdesign}

%In this section, first we introduce the funcationality of \sys~, followed by the chanllenges that need to be overcome for optimal performance. We also describe our solutions. Subsequently, we focus on each of its core components.

\subsection{Challenges and Solutions}
\label{subsec:design_challenges_solutions}

Our vision for \sys is an ``invisible'' digital forensic tool that records a digital footprint of evidence of IPI on the victim's smartphone. To accomplish this, \sys runs continuously in the background, quietly collecting standard system traces from the phone for 1) \textit{user identification} to verify whether the user is the legitimate owner and 2) \textit{behavior detection}. Finally, based on our proposed taxonomy (Table~\ref{tab:actionsubaction}), \sys determines whether or not the behavior is potentially IPI related. If an IPI behavior is detected, the natural next step is to send an alert, but this may be visible to the attacker if s/he is still accessing the phone, or if the notification is not cleared before the attacker accesses the phone again. As such, we do not send any alerts, and instead record the event on the victim's smartphone, leaving the analysis of detected IPI events for health and IPV professionals in security clinics. However, designing \sys presents the following challenges:

%It runs continuously on user's mobile smartphone, collecting time-series data needed for further inspection in the background. Local machine learning model  utilizes these data to achieve 1) user authentication: to verify whether the legitimate user is on the phone and 2) behavioral detection: to justify whether the current user has IPV-related actions on the phone. By integrating these two detection phases, \sys~ aims to effectively identify IPV alerts within the smartphone.


\noindent\textbf{IPI behavior detection across different contexts and users.} Detecting behaviors that indicate IPV is complex for several reasons. First, behaviors are subjective and can often be interpreted differently depending on the context. For instance, sharing devices among family members may seem common in some countries, while in others, it is perceived as a privacy risk. Second, IPI behaviors differ significantly across different apps and media, ranging from direct online social media harassment to tracking victims unknowingly with spyware. The diversity of platforms and the subtlety of some actions require a detection system to accommodate the wide variability in how IPV manifests across different contexts. Lastly, different people often exhibit slight to significant differences when performing the same action, highlighting the need for a system that can adapt to different users.

%although the same behavior across different users share some commom patterns, there are still nuances which would lead to the recognition failure, highlighting a need for the system to be adapted to learn different users' activity patterns.


%\noindent\textbf{How to make standardized detection across different device contexts and user patterns?} This is difficult due to the inherent comlexity of detecting IPV behaviors from serveral aspects. First, the understanding of different IPV behaviors is subjective, as such behaviors can be interpretted differently across various contexts. For instance, sharing devices among family members may seem common in some countries, while in others, it is perceived as a risk of privacy violence. Second, IPV behaviors are prevalent across different media, ranging from online social media harassment to local spyware tracking, exhibiting high variances that make automatic detection more challenging. Lastly, although the same behavior across different users share some commom patterns, there are still nuances which would lead to the recognition failure, highlighting a need for the system to be adapted to learn different users' activity patterns.

\noindent\textbf{Solution.} To create a solution that scales across different users, we propose a dual-module architecture that performs 1) user identification and 2) detects potential IPI behaviors of the current user. For identifying the phone's owner, we propose an encoder-decoder architecture, where the encoder is trained on a diverse set of users to extract salient features conducive for recognizing user identity, while the decoder is fine-tuned to a specific user and their personal device during a short calibration phase. For the behavior detection module, we employ an LSTM-CNN-based classifier trained on a diverse interaction dataset, allowing robust detection of behaviors indicative of potential IPV risks across various apps. 


%Over time, we continuously update the models on-device to mitigate model drift. \textcolor{red}{Stephen: Is model drift talked about anywhere in the implementation?}\textcolor{red}{Weisi: Actually no, could we move it to future direction?}


%We design an adaptive approach to ensure great scalability across different users and devices. First, we construct with a standard data collector using the Android API, which can gather the same types of multi-modal data across various Android smartphones. To enhance the scalability of our detection mechanism, we propose an encoder-decoder architecture. The encoder is pretrained on a diverse set of users to ensure generalization, and then the decoder is fine-tuned on the specific user's data for IPV detection when deployed on smartphones. Continuous on-device learning is utilized to mitigate the issue of model drift.


\noindent\textbf{Enabling safety and stealthiness.} Because IPV abusers often share the same physical and digital access to spaces and devices as the victim, it is imperative for \sys to remain ``invisible'' to avoid escalation if \sys or other anti-IPV measures are discovered~\cite{freed2019my,havron2019clinical,tseng2022care}. Additionally, data privacy must be taken into consideration. Although we collect no personal information, there is still a possibility of leaking behavioral patterns (e.g., app usage).


%As an automatic system for harmful IPV behavior detection, it should maintain high invisibility to the abusers. Due to the nature of IPV, it is imperative for the users to avoid extra harm, since there would be an increase in the violence if their anti-IPV actions are discovered by the abusers \cite{freed2019my,havron2019clinical,tseng2022care}. Moreover, data privacy must be taken into consideration. Although we collect no personal information for detection, there is still a chance of the leakage of other biometric information (e.g., App Usage) which could bring about some concerns. 

\noindent\textbf{Solution.} We take the following actions to ensure the system's stealth and safety. First, we review the sensitive data involved during collection and exclude any that pose privacy risks to our users. Second, we apply UI deception by disguising \sys's entry point with an unrelated but common interface, such as a weather report, to hide \sys from potential abusers who might open the app accidentally. Third, we perform all inference and fine-tuning locally to prevent data leakage during transmission to a remote server. Finally, \textit{we do not provide any alerts} to any user on the phone, unlike most timely applications (e.g., email and messaging). Instead, data is stored securely on the phone, until it can be sent over to a security clinic (e.g., during a consultation), where the traces detected by \sys can be analyzed in a safe setting. Details about how we implemented our solution are discussed in Section~\ref{subsec:stealthy_functioning}.

\noindent\textbf{Efficient computation.} During the implementation of \sys, we observed significant energy consumption from both 1) sampling at a high rate and 2) performing local inference continuously. This adversely affects not only the battery but also cause the phone to overheat and lag, leading to decreased user experience.

\noindent\textbf{Solution.} To reduce energy consumption and impact on user experience we take advantage of our safe design choice of \textit{not alerting} users and employ an asynchronous detection mechanism. Data signals are collected during the day but processed at night, when the user is sleeping and the phone is not in use. Because \sys does not send timely alerts to users to avoid discovery, there is no need to process data immediately. Moving model inference to nighttime reduces energy consumption, overheating, and lag that is caused by continuous model inference during the daytime when users are likely interfacing with their smartphones. 

%2) When fine-tuning the model for adapting new user, \textcolor{red}{we adopt a selection algorithm based on pair-wise similarity between training samples to significantly reduce the number of samples needed for tuning (Stephen: Is this discussed somewhere?)}. In \ref{sec-5-sub-power}, we further optimize \sys sampling rate, while maintaining accurate performance.




\begin{figure*}[t]
    \centering\includegraphics[width=2\columnwidth]{figure/workflow.png}%
\caption{\sys workflow and system architecture. The output report remains invisible to the victim until their next visit. However, it is shared with the Security Clinic experts as a forensic support for further analysis. For privacy protection, when the user identification module recognizes the owner, no information about the application name, behaviors will be revealed. }\label{fig:workflow}
\end{figure*}

\subsection{Workflow Overview}
%\takeaway{Describe the system overview by showing a system architecture,
%which shows our design principals are (1) Scalable and adaptive; (2) Silent and safe.
%All stages happen on local mobile machine, so it is very privacy preserving.}
% Please add the following required packages to your document preamble:
% \usepackage{multirow}
% \usepackage[table,xcdraw]{xcolor}
% Beamer presentation requires \usepackage{colortbl} instead of \usepackage[table,xcdraw]{xcolor}


Figure~\ref{fig:workflow} shows \sys's workflow, which contains three phases: \textbf{data collection}, \textbf{module inferencing}, and \textbf{analysis report generation}. %This end-to-end pipeline is designed to deliver robust \ipvact and analysis while ensuring computational efficiency and adaptability for diverse users and environments.

During collection phase, \sys samples and records time-series multi-modal data signals from the smartphone in the background (Table~\ref{tab:modalitycontent}). \sys collects 4 categories of modalities to obtain a comprehensive view of how the user is interacting with the phone. Among these, \textit{IMU} and \textit{Sys} play a critical role in the User Identification Module. Meanwhile, \textit{Int} and \textit{App} data are relevant to the Behavior Module for detecting suspicious behaviors associated with IPI. Intuitively, incorporating all data sources should result in the best performance due to more available information. However, our ablation studies (Section~\ref{subsec:ablation_study}) reveal that there is a clear divide in the importance of each data type for each task; incorporating more information often reduces performance due to a lack of expressive power of a small model to generalize to redundant and higher dimensional inputs that results.

The User Identification Module employs a pretrained AutoEncoder to extract embeddings from user data, which are then used to train a Support Vector Machine (SVM) classifier that adapts to the target user. This adapted module performs identity verification, determining whether the current user is the authorized device owner. Meanwhile, the Behavior Detection Module utilizes a hybrid model combining Long Short-Term Memory (LSTM) networks and Convolutional Neural Networks (CNNs) to recognize and classify user activities into one of 27 IPI subactions, shown in Table~\ref{tab:actionsubaction}. To ensure reliability, results from both modules are refined through a post-processing step, which enhances stability and accuracy.

%This structured approach ensures that both user-level and behavior-level signals are captured effectively.

%The user identification modul

%Input data is analyzed across two domains: User Identity and Interaction Behavior, managed by the User Authentication Module and the Behavior Detection Module, respectively. The User Authentication Module employs a pretrained AutoEncoder to extract embeddings from user data, which are then used to train a Support Vector Machine (SVM) classifier that adapts to the target user. This adapted module performs identity verification, determining whether the current user is the authorized device owner. Meanwhile, the Behavior Detection Module utilizes a hybrid model combining Long Short-Term Memory (LSTM) networks and Convolutional Neural Networks (CNNs) to recognize and classify user activities into one of the \textcolor{red}{X IPI subactions shown in Table~\ref{tab:actionsubaction}}. By analyzing interaction patterns and application usage, it provides insights that go beyond identity verification by detecting suspicious behaviors. To ensure reliability, results from both modules are refined through an Output Tuning mechanism, which enhances stability and accuracy.

These results are consolidated into a report that provides key details such as the time of detection, the app involved, the user's status (e.g., owner or non-owner), the most likely behaviors detected (e.g., benign or suspicious actions in Table~\ref{tab:actionsubaction}), and the overall risk assessment based on confidence measures output from each module. For instance, the report might highlight that a verified user performed benign activities on one app. At another point in time, the report may detect an anomalous user engaging in actions like "Alter Account Setting," leading to an "IPV Risk Detected" classification. The report remains securely stored on the device until it is analyzed by health, safety, or security professionals.

As we will see later in this section and in the evaluation, detecting phone behaviors in an ``invisible'' manner is much different than traditional human activity recognition that aim to detect physical body movements with the IMU on a smartphone, smartwatch, or other wearable. The signals available to us are limited, can only indirectly capture activities of interest, and different behaviors have similar traces; For example, changing an account password or searching for a YouTube video both involve typing and tapping on the screen. As such, \sys logs the top-k most probable behaviors from non-owners for security professionals to analyze.


%By combining outputs from these modules, \sys provides a comprehensive understanding of smartphone usage patterns and potential IPV-related risks. 





Next, we detail the implementation design of \sys, and further discuss training mechanisms to improve adaptability to different users in Section~\ref{scalable} and safety mechanisms in Section~\ref{subsec:stealthy_functioning}. Section~\ref{subsec:efficient_computing} discusses optimization strategies for \sys, focusing on efficient computing for real-world use.

%When the first level of Inference Processor finds an illegal user access, the second level lunches and performs multi-class classifications on the multi-modal time series data to determine the behavior the user displays when using the devices. If classification result is “Benign”, it means that the illegal user has no harmful intention, otherwise specific category of IPV would be indicated.

%few-shot learning


\begin{comment}
\begin{figure}[htbp]
    \centering\includegraphics[width=0.7\columnwidth]{figure/adaptation.png}%
\caption{Pretraining and fine-tuning for adapting to new phone users. We analyze and evaluate different selection methods to build the fine-tuning dataset in Section~\ref{Level 1 eval}.}\label{fig:adaptability}
\end{figure}
\end{comment}

\subsection{Enhancing Scalability and Adaptability of the System}\label{scalable}
%\takeaway{(1) scalability: multi-modal and high-sampling rate; (2) adaptive: 
%few-shot and continous learning. }

\noindent
\textbf{Adapting to different users.} While similar actions may result in similar system traces, there is variability between different users, much like in traditional Human Action Recognition (HAR). Moreover, it is difficult to train a one-for-all model that can distinguish between any user. As such, we adopt a fine-tuning scheme for user identification that adapts to the phone's owner.

First, we pretrain an LSTM-based AutoEncoder using a corpus of diverse user data. This pretraining process allows the model to learn general patterns and representations of phone activity and user behavior. AutoEncoders are particularly suitable for this task as they excel at learning patterns and representations from unlabeled and limited amounts of data.


Second, when the owner installs the application for the first time, \sys guides the owner through a short calibration procedure of 5 minutes, where the owner uses the device naturally. This session provides sufficient data fine-tuning the classifier to adapt to the owner's unique behavioral patterns. The fine-tuning dataset is constructed by selecting a subset of the data newly collected from the owner and a subset of data from other users as negative examples. To ensure balance during classifier training, we maintain a 1:1 ratio between the selected samples from the owner and other users. We explore different methods for selecting and constructing the full fine-tuning dataset in our evaluation, specifically Section~\ref{Level 1 eval}. %The dataset is carefully balanced, maintaining a 1:1 ratio of target-user to non-target-user data. This dataset is then used to fine-tune the classifier, allowing it to adapt to and "remember" the unique behavior of the current user while distinguishing them from others.

Finally, the backbone of our user identification module takes inspiration from KedyAuth\cite{huh2023long}, a state-of-art user authentication architecture for mobile platforms. We adopt a similar encoder-decoder structure as shown in Figure~\ref{fig:Mod1}, except we replace the encoder backbone with an 8-head LSTM Layer (4 units per head), instead of using CNN layers, to better adapt to the multimodal time series data being processed. The outputs are concatenated and projected through a dense layer to produce a compact 16-dimensional latent representation. The decoder reconstructs the original input by first expanding the latent representation back to the input shape using a RepeatVector layer, followed by an LSTM layer for the reconstruction task. Once pretrained, the features extracted by the autoencoder are used as input into a lightweight SVM classifier with Radial Basis Function (RBF) kernel, to distinguish between use by the owner or a non-owner.

 %This architecture choice prioritizes temporal pattern recognition while maintaining mobile-friendly computational requirements.


\begin{figure}[h!]
    \centering
    % Subfigure 1
    \begin{subfigure}[b]{0.5\textwidth}
        \centering
        \includegraphics[width=\textwidth]{figure/Mod1Model.png}
        \caption{Module-1: User Identification.}
        \label{fig:Mod1}
    \end{subfigure}
    \hfill
    % Subfigure 2
    \begin{subfigure}[b]{0.5\textwidth}
        \centering
        \includegraphics[width=\textwidth]{figure/Mod2Model.png}
        \caption{Module-1: Classifying \ipvact.}
        \label{fig:Mod2}
    \end{subfigure}
    \caption{\sys's model architectures for a) identifying the phone's owner and b) detecting \ipvact.}
    \label{fig:ModelArchitecture}
\end{figure}

\noindent
\textbf{Scaling to many \ipvact.} While there is significant work in the area of human activity recognition (HAR) on smartphones, detecting \ipvact is significantly different. Rather than viewing phones and wearables as a system that a person interacts with, HAR leverages these devices as a general-purpose sensor to detect motions and actions (e.g., step counting, motion tracking) \textit{while a person is not directly interfacing with the smartphone}. This often involves heavy use of physical sensors on the on the device (e.g., camera and IMU). In contrast, determining \ipvact involves \textit{detecting actions a user performs while interfacing directly with the phone} (e.g., changing passwords or installing malware). As such, the modalities and techniques used need to be adjusted. To the best of our knowledge, \textbf{there are no prior works that attempt to detect IPV-related actions users take while interfacing with smartphones.}

To detect \ipvact, \textit{we focus on interaction data (Int.) and app usage signals (App.) captured by the operating system} (Figure~\ref{fig:workflow}). These modalities provide critical insights into how users engage with the device, such as navigating apps, interacting with the screen, or performing specific actions, which is indicative of IPI. \textit{We show through ablation studies in Section~\ref{subsec:ablation_study} that these two classes of signals enable the greatest performance, instead of relying solely on motion data, commonly used in traditional HAR}.

Given the challenges of obtaining labeled data post-installation, we implement a server-side training architecture while deploying only the detection components on-device. Recent advances in HAR have explored various architectures, from CNNs\cite{wan2020deep} and LSTMs\cite{mekruksavanich2021deep} to Transformers\cite{ek2022lightweight}. Inspired by the success of hybrid models in HAR\cite{zhang2022deep}, we develop an LSTM-CNN architecture for classifying \ipvact. As shown in Figure~\ref{fig:Mod2}, our model processes input sequences through parallel paths: an LSTM layer with 64 units and a one-dimensional convolutional layer (kernel size=3, 64 filters). The CNN output undergoes max pooling and flattening before concatenation with the LSTM output. The combined features pass through two dropout-dense blocks for multi-class behavior classification.

\noindent
\textbf{Post Processing.}  To further enhance the reliability of the system, we introduce a post processing method tailored to the objectives of Module 1 (user identification) and Module 2 (behavior classification). 

\noindent
\textit{Module 1 (User Identification)}: Outputs are refined using a clustering-based post-processing approach. We extract temporal features (rolling mean and standard deviation) from prediction scores, which are input into a k-means clustering model (k = 2) that partitions the prediction space into regions corresponding to true users and potential abusers. A temporal voting mechanism aggregates predictions within a sliding window to ensure classification stability and mitigate transient errors. This approach significantly reduces false positives while maintaining high detection sensitivity, which we will show in our experiments.

\noindent
\textit{Module 2 (Behavior Classification)}: Post-processing for behavior classification adopts a simpler rolling window average to smooth fluctuations in predictions and reduce temporal variations. By adding post-processing techniques to each module, the system achieves both high accuracy across diverse tasks.


%We implemented serveral key techniques on the system to increse its scalability and adaptability. We first illustrate our measures for improving system scalability. In order to quantitatively detect IPV behaviors, Operating System traits are necessary to capture the digital description of user activity. \sys~leverages multi-modal data acquired from mobile smartphone to realize the comprehensive modeling of current activity status. For instance, with sensor data, we can acquire the orientation and motion of the mobile device; with network and interaction data, we gain insights into the user activity pattern. Various data modalities serve as OS-level references in IPV behavior detection beyond subjective judgement. Moreover, we designed the system with a variable sampling rate supporting frequencies up to 100Hz, enabling the capture of abundant information within a short time window. With standard sensing data, we could achieve the detection on different user devices, showing significant scalability.

%On top of great scalability, our system design also focus on enhancing the adaptability. As different users have diverse patterns in using mobile smartphones, it is impractical to train a one-for-all model which can recognise all users or intruders, so model needs the ability to learn the specific owner's using habit when it is deployed to different devices. Therefore, we implement pretraining during model deployment, as shown in Figure \ref{fig:adaptability}. The pretrained model has learned to recognise general pattern representations from a small set of user samples, then we leverage few-shot learning in the registration stage to fine-tune the model to learn finer details of the mobile device owner's using habits. Few-shot learning aims to train the model with only few samples \cite{wang2020generalizing}, this is adopted due to practical consideration that we may have insufficient time for owner registration, in other words, we can only collect few samples for fine-tuning. Besides, with few learning data, the training time is shortened so the implemented pretrained model can come into effect more quickly. Combined with fine-tuning for generalizing the model for specific user, the traning overhead on mobile device will be further reduced, so there is no need to re-train the entire model for each user on each mobile device. After fine-tuning the model with authentic user data, it has memorised the pattern of true user and other general users, so it can detect the access from anomalous group even if it has never seen the data of the new user before. Since user behavior pattern may change eventually over time, so these approaches are crucial to mitigate potential data drift, and to achieve this \sys~will continuously update the model with newly received data.


% On top the general architecture, other designs are implemented to enhance the system. We adopted UI-deception so that the real interface is hidden from the abuser if the abuser happens to open the application. The application runs totally in the background unobtrusively without showing up in system app switcher page, increasing its invisibility and safety. The system supports feature-subscription, which has a high flexibility in choosing specific modalities under different conditions for optimized accuracy and power consumption. Additionally, fine-tuning is implemented in our inference models, by which we can learn the pattern and adjust the pre-trained models on device when a new user is registered, reducing the risk of data leakage if training on a remote server is required.



\subsection{Maintaining Safety and Stealth}
\label{subsec:stealthy_functioning}

%\takeaway{Efforts to make it stealthy: (1) a lot of UI deceptive techniques; (2) late night inference; (3) specially notification approach. }
%\takeaway{What if the attacker is aware of this detection approach? E.g., cutting the logger is already a red flag. 
%add more approaches here.}


\begin{comment}
 \begin{table*}[htbp]
     \centering\caption{Android APIs not used in \sys due to safety risks.}
     \label{tb-riskyapi}
     \begin{tabular}{llccc}
     \hline
     Modality          & API                 & \makecell{Background\\running} & \makecell{Sensitive\\data} & \makecell{Mandatory\\Notification} \\ \hline
     Touch information & MotionEvent         & \checkmark         & \checkmark     & \checkmark              \\
     Camera            & Camera2 API         & $\times$         & \checkmark &                 \\
     Recorder          & MediaRecorder API   & $\times$         & \checkmark &                   \\
     Position          & LocationManager API & \checkmark  & \checkmark  & \checkmark                      \\ \hline
     \end{tabular}
     \end{table*}
\textcolor{red}{examples: camera, recorder, touch, GPS}
\end{comment}

\noindent\textbf{Review of risky data sources.} As discussed in Section~\ref{subsec:design_challenges_solutions}, \sys should be ``invisible'' to abusers while also being privacy sensitive towards the owner of the phone. As such, we discard data streams only available through APIs that violate these principles. We identified four such signals, which are not present in \sys:

\noindent
1. \underline{Touch information}, available through the MotionEvent API, provides information about the coordinates of a user's touch, swipe direction, pressure etc. However, accessing this API in the background places a floating icon on the screen and triggers a mandatory system alert.

\noindent
2. The \underline{Camera} of the phone can provide significant amounts of information about the current user and environment. However, camera records highly sensitive information, such as the user’s face, which, if leaked, could result in severe privacy breaches. Additionally, activating the camera in the background triggers mandatory notifications on the screen, potentially alerting an abuser to the monitoring and escalating the situation. Continuous use of the camera is also impractical due to significant power consumption, leading to device overheating and impacting the user’s normal experience.

\noindent
3. \underline{Audio} can be obtained through the MediaRecorder API. However, similar to the camera, using audio through the MediaRecorder API raises significant privacy concerns, as sensitive conversations or environmental sounds could be recorded and potentially leaked. Additionally, activating audio recording triggers mandatory on-screen notifications, compromising the invisibility of the system and potentially alerting an abuser.

\noindent
4. A user's \underline{position} can be obtained from GPS and wireless signals through the LocationManager API. While location tracking via GPS or wireless signals could provide useful information, it can reveal sensitive details about the user’s movements or frequent locations, which could put them at risk. Additionally, like camera and audio recording, system notifications and battery drain from continuous tracking further make this option unsuitable for our needs.



%To avoid detection from abusers, we do not collect data streams that cannot be accessed through \textit{background processes} or provide a \textit{mandatory alert}. We also eliminate modalities that capture \textit{sensitive data}, which could be used to personally identify users, in case of data leaks. For example, touch information is available through the MotionEvent API, which can obtain the coordinates of a user's touch, swipe direction, pressure etc., which is helpful for identifying \ipvact. However, this API does not allow background operation, and even though it can run in the background using a floating window, it will trigger a mandatory system alert. Moreover, if leaked, the location of screen touches can be used to guess the owner's password. %\textcolor{red}{On the other hand, motion data captured by the phone's accelerometer is used in \sys because it can provide insight that the user is typing, but not enough to reliably decipher full passwords.}

%We discarded those that posed potential data safety risks. Table \ref{tb-riskyapi} shows the risky API which we considered at first but finally discarded. For example, by using the MotionEvent API, touch information can be obtained, such as the coordinates of the user's touch on the phone screen, touch pressure, number of touch points, and swipe direction. This information is significantly helpful in identifying users involved in intimate partner violence. However, this API does not allow background operation, even though it can be run in the background to some extent using a floating window, it will trigger a mandatory system alert. Additionally, the data type is quite sensitive, and if leaked, it could pose substantial risks. For instance, it could capture a few touch coordinates to infer important information such as account passwords while the user is typing. Therefore, we did not use this API for data collection in the final system construction. 

%Similarly, cameras, recorders, and location information also pose sensitivity issues. For cameras and recorders, background operation is not possible, compromising the visual stealth of the system. By selecting low-sensitivity, background-allowable, and non-alert-triggering multimodal information, the security of the detection system is enhanced.

\noindent\textbf{User-interface deception.}  We crafted our Android application to blend in as a conventional smartphone application (e.g., a weather app), which significantly reduces the chances of discovery by the abuser. Furthermore, the first page of the application is disguised (e.g., the weather report).%, with special entrance to its real detection page only known to the device owner. 

Second, we leverage the Accessibility Service~\cite{google2024accessibility}, a built-in function of Android OS that enables \sys to launch without clicking on the application icon. This enables \sys to begin running, while remaining absent from the ``Recent Apps'' page to enhance stealthiness and prevent abusers from terminating \sys from here.


\noindent\textbf{Local inference.} \sys performs inference and fine-tuning on-device, which eliminates the need to send data to a remote server, reduces the chance of data leaks, and enhances data privacy. Furthermore, we take advantage of the IPV context to further reduce \sys's energy footprint. Because we avoid alerting users to prevent discovery by abusers, \textit{\sys does not need to provide insights continuously and in real-time}. As such, during the day, the Data Streaming Hub collects and logs traces, while the inference processor analyzes the collected data at night, when the device is idle and connected to power, while the user is likely asleep. This reduces the computational load on the phone when users are more likely to interface with their phones, improving battery life, overheating, and phone lag that can result from continuous inference.


%It is noticeable that detection phase is separated from collection phase. When the device is active, only the Data Stream Hub runs, collecting status data for further IPV detection. Late-night inference executes the most intensive task when the device is idle and connected to power, allowing the preservation of battery life. This approach is maintained while more resources could be used for complex models to produce more accurate results. If Inference Processor runs at the same time, real-time detection is achieved, but this leads to quicker battery drianage, potential overheating, and lagging, which is more likely to be noticed by the abuser or disrupt the user's daily activities, raising safety concerns. 

\noindent\textbf{What if \sys is detected by the abuser?} Although the average IPV attacker may not have the same technical background of a cyber attacker, there is a chance that abusers may become aware of \sys, even with the safety measures employed. Here we discuss scenarios reflecting the degree of awareness. 



At the most basic level of awareness, the abuser only knows the existence of \sys, but not its location on the device. In this case, \sys~is still feasible, as the abuser cannot prevent \sys from running, and it is difficult to subconsciously mimic and change one's phone's habits.


A more informed level of awareness for the abuser is knowing the exact location of \sys. The most direct response from the abuser might to delete \sys, or force the phone to stop by altering background settings. Regardless of the approach, any attempt to interfere with \sys already reveals a clear intention of IPV behaviors, which can be used to inform victims, security, and health professionals.


The most severe scenario, mentioned in \ref{sec-3-threatModel}, is a deterioration in the relationship, where physical violence is likely to occur. This scenario is beyond the scope of \sys and requires external intervention, such as from police and law enforcement.

\subsection{Efficient Computing}
\label{subsec:efficient_computing}
\noindent\textbf{Asynchronous detection.} Deep learning models are effective for accurate detection but can be computationally demanding, which poses challenges for resource-constrained mobile devices. Running these models continuously may consume excessive computational resources, lead to overheating, and negatively impact the user experience. To maintain invisibility, \sys does not send alerts immediately when a suspicious IPV intrusion is detected, as this could notify the abuser. Unlike traditional user authentication systems, which prioritize real-time processing, \sys processes data asynchronously during nighttime when the device is idle and charging. This approach eliminates performance lags during the day (the only overhead being logging data from the phone), ensuring an improved user experience.

%By deferring model inference to periods when the device is not in active use, \sys optimizes resource utilization. Nighttime processing takes advantage of idle computational resources and ensures a stable power supply, as the phone is typically in charging mode. The only daytime overhead is a lightweight data streaming hub that continuously collects and stores user behavior data for later analysis. Asynchronous detection ensures that \sys remains both efficient and unobtrusive, preserving user privacy and device performance.

\begin{comment}
\begin{figure}[htbp!]
    \centering\includegraphics[width=\columnwidth]{figure/pretraining.png}%
\caption{Illustrating Pretraining in the embedding space.}\label{fig:pretraining}
\end{figure}
\end{comment}

\noindent\textbf{Few-Shot Learning for Efficient Adaptation.} Model training is typically resource-intensive and time-consuming. In our dual-module architecture, the behavior detection module performs inference using a trained model, while the user authentication module requires fine-tuning for user adaptation. To minimize this overhead, we implement a few-shot learning scheme \cite{wang2020generalizing} that enables efficient adaptation with minimal data. During pretraining, the model is trained on a diverse dataset, capturing general patterns of mobile interaction. This knowledge enables the model to rapidly adapt to a new user's specific interaction patterns through fine-tuning. Our evaluation demonstrates that random sampling of just 20 samples during the calibration session is sufficient for fine-tuning, achieving high detection accuracy. This eliminates the need to process the full dataset, significantly reducing computational and time costs. The resulting system is both practical and efficient for real-world deployment.







% To resolve this, we developed the application that can run with sampling rate up to 100hz, which is sufficient to acquire enough data 
% within a short time. Additionally, we focus on the refining of the architecture to reduce its computation while maintaing its accuracy,
% by creating "2-phase" detection and model optimization.