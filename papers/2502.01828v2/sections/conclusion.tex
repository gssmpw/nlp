\section{Conclusion}
In this work, we investigate the problem of policy steering for multi-modal generative policies. We propose a novel framework \textbf{FOREWARN} that unlocks Vision Language Models (VLMs) to serve as open-vocabulary verifiers for run-time policy steering. 
Our method decouples the steering problem as future prediction (foresight) and outcome assessment (forethought). Through an explicit world model and a latent-space alignment strategy, we enable VLMs to reason about sensorimotor data using natural language. Our experiments across diverse manipulation tasks confirm that \textbf{FOREWARN} not only provides interpretable and reliable failure detection, but also significantly enhances policy success rates through flexible, generalizable steering. These results highlight the promise of combining learned dynamics models with language-based reasoning to improve test-time performance of robot policies.

