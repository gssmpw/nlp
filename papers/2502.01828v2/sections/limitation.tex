\section{Limitations}
While \textbf{FOREWARN} exhibits strong policy steering across diverse task settings, it is not without limitations. First, it assumes base policy is sufficiently competent—i.e., already containing the correct behavior. Future work should investigate how to detect if none of the policy’s generated action plans are suitable for the deployment context, and how to improve the base policy via targeted fine-tuning data.
A second limitation lies in modeling real-world interaction dynamics. Our component-level analysis in App.~\ref{sec:appendix_sup_exp_ana} revealed that our system’s primary failures stem from the world model’s imprecise ``imagination'', exacerbated by our limited training data. More advanced visual features (e.g., DINO features~\citep{oquabdinov2}) might improve the world model’s robustness to visual distractors. Ongoing research on large-scale, generalizable world models~\citep{wu2024ivideogpt} for manipulation may also inform future extension of this framework.
Finally, our VLM is built upon an open-source LLama-3.2-11B-Vision-Instruct model, whose visual reasoning capabilities lag behind its language-based commonsense reasoning. A stronger backbone could yield higher-quality behavior descriptions, especially if it excels at video captioning tasks. 
