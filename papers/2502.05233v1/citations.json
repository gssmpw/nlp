[
  {
    "index": 0,
    "papers": [
      {
        "key": "Yin23",
        "author": "Fangyuan Yin and Jesse Vig and Philippe Laban, Shafiq Joty and Caiming Xiong and Chien-Sheng Wu",
        "title": "Did You Read the Instructions? Rethinking the Effectiveness of Task Definitions in Instruction Learning"
      }
    ]
  },
  {
    "index": 1,
    "papers": [
      {
        "key": "Rubin22",
        "author": "Or Hon Rubin and Jonathan Herzig and Jonathan Berant",
        "title": "Learning to Retrieve Prompts for In-Context Learning"
      },
      {
        "key": "Wan23",
        "author": "Xiaodong Wan and Ruiqi Sun and Hootan Nakhost and Hanjun Dai and Jose M. Eisenschlos and Sercan O. Arik, Thomas Pfister",
        "title": "Universal Self-Adaptive Prompting"
      },
      {
        "key": "Wan23a",
        "author": "Xiaodong Wan and Ruiqi Sun and Hanjun Dai and Sercan O. Arik and Thomas Pfister",
        "title": "Better Zero-Shot Reasoning with Self-Adaptive Prompting"
      }
    ]
  },
  {
    "index": 2,
    "papers": [
      {
        "key": "Ye22",
        "author": "Sungjin Ye and Donghwan Kim and Jiho Jang and Janghoon Shin and Minjoon Seo",
        "title": "Guess the Instruction! Flipped Learning Makes Language Models Stronger Zero-Shot Learners"
      }
    ]
  },
  {
    "index": 3,
    "papers": [
      {
        "key": "Ye22",
        "author": "Sungjin Ye and Donghwan Kim and Jiho Jang and Janghoon Shin and Minjoon Seo",
        "title": "Guess the Instruction! Flipped Learning Makes Language Models Stronger Zero-Shot Learners"
      }
    ]
  },
  {
    "index": 4,
    "papers": [
      {
        "key": "Min22",
        "author": "Sewon Min and Mike Lewis and Hannaneh Hajishirzi and Luke Zettlemoyer",
        "title": "Noisy Channel Language Model Prompting for Few-Shot Text Classification"
      }
    ]
  },
  {
    "index": 5,
    "papers": [
      {
        "key": "Xu22",
        "author": "Baiqiang Xu and Qi Wang and Zifan Mao and Yixin Lyu and Qian She and Yichen Zhang",
        "title": "KNN Prompting: Beyond-Context Learning with Calibration-Free Nearest Neighbor Inference"
      }
    ]
  },
  {
    "index": 6,
    "papers": [
      {
        "key": "Yang24",
        "author": "Jing Yang and Binghui Hui and Mingqiang Yang and Bin Li and Fei Huang and Yining Li",
        "title": "Iterative Forward Tuning Boosts In-Context Learning in Language Models"
      }
    ]
  },
  {
    "index": 7,
    "papers": [
      {
        "key": "Hendel23",
        "author": "Ronen Hendel and Mor Geva and Amir Globerson",
        "title": "In-Context Learning Creates Task Vectors"
      }
    ]
  },
  {
    "index": 8,
    "papers": [
      {
        "key": "Turner23",
        "author": "Alec Turner and Leon Thiergart and David Udell and Graeme Leech and Umang Mini and Malachy MacDiarmid",
        "title": "Activation Addition: Steering Language Models Without Optimization"
      }
    ]
  },
  {
    "index": 9,
    "papers": [
      {
        "key": "Zou23",
        "author": "Allen Zou and Long Phan and Sheng Chen and John Campbell and Ping Guo and Rui Ren and Albert Pan and Xinyi Yin and Matas Mazeika and Alexandra-Kate Dombrowski and others",
        "title": "Representation Engineering: A Top-Down Approach to AI Transparency"
      }
    ]
  },
  {
    "index": 10,
    "papers": [
      {
        "key": "Burns22",
        "author": "Cameron Burns and Huadong Ye and Dan Klein and Jacob Steinhardt",
        "title": "Discovering Latent Knowledge in Language Models Without Supervision"
      }
    ]
  },
  {
    "index": 11,
    "papers": [
      {
        "key": "Mini23",
        "author": "Umang Mini and Peter Grietzer and Mukund Sharma and Alex Meek and Malachy MacDiarmid and Alec M. Turner",
        "title": "Understanding and Controlling a Maze-Solving Policy Network"
      }
    ]
  },
  {
    "index": 12,
    "papers": [
      {
        "key": "Li22",
        "author": "Ke Li and Andrew K. Hopkins and David Bau and Fernanda Vi{\\'e}gas and Hanspeter Pfister and Martin Wattenberg",
        "title": "Emergent World Representations: Exploring a Sequence Model Trained on a Synthetic Task"
      }
    ]
  },
  {
    "index": 13,
    "papers": [
      {
        "key": "Lu22",
        "author": "Yian Lu and Massimo Bartolo and Alastair Moore and Sebastian Riedel and Pontus Stenetorp",
        "title": "Fantastically Ordered Prompts and Where to Find Them: Overcoming Few-Shot Prompt Order Sensitivity"
      },
      {
        "key": "Shin22",
        "author": "Seongmin Shin and Sungmin Lee and Hyeonseo Ahn and Sangwoo Kim and Hyunsoo Kim and Byoungjun Kim and Kyunghyun Cho and Gyuwan Lee and Woosung Park and Jangwon Ha and others",
        "title": "On the Effect of Pretraining Corpora on In-Context Learning by a Large-Scale Language Model"
      }
    ]
  },
  {
    "index": 14,
    "papers": [
      {
        "key": "Xie21",
        "author": "Shengjia M. Xie and Aditi Raghunathan and Percy Liang and Tengyu Ma",
        "title": "An Explanation of In-Context Learning as Implicit Bayesian Inference"
      }
    ]
  },
  {
    "index": 15,
    "papers": [
      {
        "key": "Wei23",
        "author": "Jason Wei and Jeffrey Wei and Yi Tay and Dai Tran and Adam Webson and Yian Lu and Xiaodong Chen and Hao Liu and Dianqiang Huang and Denny Zhou and others",
        "title": "Larger Language Models Do In-Context Learning Differently"
      },
      {
        "key": "Akyurek22",
        "author": "Ekin Aky{\\\"u}rek and Dale Schuurmans and Jacob Andreas and Tengyu Ma and Denny Zhou",
        "title": "What Learning Algorithm Is In-Context Learning? Investigations with Linear Models"
      }
    ]
  }
]