\begin{algorithm}[h]
    \caption{ARSQ Action Selection with Double Q Network}
    \label{pse:med-alg-act}
\begin{algorithmic}
    \STATE \textbf{Input:} parameter $\theta_{1, 2}$ for $A^{\theta_i}$, state $\mathbf{s}_t$
    \STATE \textbf{Output:} action $\mathbf{a}_t$
    \STATE Initialize output action $\mathbf{a}_t = \emptyset$
    \FOR{each action dimension $d$}
        \STATE Compute $A^{d, \theta_i}(\mathbf{s}_t, \mathbf{a}_t, a^d )$ for each $a^d$ (\ref{eq:med-alg-cons})
        \STATE Compute $A^{d}(a^d ) = \min_i A^{d, \theta_i}(\mathbf{s}_t, \mathbf{a}_t, a^d )$
        \STATE Compute $\tilde{\pi}^d(a^d)= \text{exp} \left( \frac{1}{\alpha} A^{d}(a^d ) \right)$ (\ref{eq:med-sa-pi})
        \STATE Normalize $\tilde{\pi}^d$ by $\pi^d(a^d)=\frac{\tilde{\pi}^d (a^d)}{\sum_{a^{d'}} \tilde{\pi}^d(a^{d'})} $
        \STATE Sample discrete action at dimension $d$ with $\pi^d(a^d)$
        \STATE Append action $\mathbf{a}_t = \mathbf{a}_t \cup \{ a^d \}$
    \ENDFOR
\end{algorithmic}
\end{algorithm}