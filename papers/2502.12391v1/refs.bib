@article{greenwade93,
    author  = "George D. Greenwade",
    title   = "The {C}omprehensive {T}ex {A}rchive {N}etwork ({CTAN})",
    year    = "1993",
    journal = "TUGBoat",
    volume  = "14",
    number  = "3",
    pages   = "342--351"
}

@article{
  liu2024offlinesaferl,
  title={Datasets and Benchmarks for Offline Safe Reinforcement Learning},
  author={Zuxin Liu and Zijian Guo and Haohong Lin and Yihang Yao and Jiacheng Zhu and Zhepeng Cen and Hanjiang Hu and Wenhao Yu and Tingnan Zhang and Jie Tan and Ding Zhao},
  journal={Journal of Data-centric Machine Learning Research},
  year={2024}
}


@inproceedings{fujimoto2019off,
  title={Off-policy deep reinforcement learning without exploration},
  author={Fujimoto, Scott and Meger, David and Precup, Doina},
  booktitle={International conference on machine learning},
  pages={2052--2062},
  year={2019},
  organization={PMLR}
}

@inproceedings{liu2023meta,
  title={Meta inverse constrained reinforcement learning: Convergence guarantee and generalization analysis},
  author={Liu, Shicheng and Zhu, Minghui},
  booktitle={The Twelfth International Conference on Learning Representations},
  year={2023}
}
@article{liu2022distributed,
  title={Distributed inverse constrained reinforcement learning for multi-agent systems},
  author={Liu, Shicheng and Zhu, Minghui},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={33444--33456},
  year={2022}
}
@inproceedings{xu2019learning,
  title={Learning a prior over intent via meta-inverse reinforcement learning},
  author={Xu, Kelvin and Ratner, Ellis and Dragan, Anca and Levine, Sergey and Finn, Chelsea},
  booktitle={International conference on machine learning},
  pages={6952--6962},
  year={2019},
  organization={PMLR}
}

@inproceedings{
grigsby2024amago,
title={{AMAGO}: Scalable In-Context Reinforcement Learning for Adaptive Agents},
author={Jake Grigsby and Linxi Fan and Yuke Zhu},
booktitle={The Twelfth International Conference on Learning Representations},
year={2024}
}


@inproceedings{malagon2024selfcomp,
  title={Self-Composing Policies for Scalable Continual Reinforcement Learning},
  author={Malagon, Mikel and Ceberio, Josu and Lozano, Jose A},
  booktitle={International Conference on Machine Learning (ICML)},
  year={2024}
}
@inproceedings{sel2023learning,
  title={Learning-to-learn to guide random search: Derivative-free meta blackbox optimization on manifold},
  author={Sel, Bilgehan and Tawaha, Ahmad and Ding, Yuhao and Jia, Ruoxi and Ji, Bo and Lavaei, Javad and Jin, Ming},
  booktitle={Learning for Dynamics and Control Conference},
  pages={38--50},
  year={2023},
  organization={PMLR}
}
@inproceedings{nagabandi2018neural,
  title={Neural network dynamics for model-based deep reinforcement learning with model-free fine-tuning},
  author={Nagabandi, Anusha and Kahn, Gregory and Fearing, Ronald S and Levine, Sergey},
  booktitle={2018 IEEE international conference on robotics and automation (ICRA)},
  pages={7559--7566},
  year={2018},
  organization={IEEE}
}

@inproceedings{wang2020striving,
  title={Striving for simplicity and performance in off-policy DRL: Output normalization and non-uniform sampling},
  author={Wang, Che and Wu, Yanqiu and Vuong, Quan and Ross, Keith},
  booktitle={International Conference on Machine Learning},
  pages={10070--10080},
  year={2020},
  organization={PMLR}
}

@inproceedings{zhang2024metadiff,
  title={Metadiff: Meta-learning with conditional diffusion for few-shot learning},
  author={Zhang, Baoquan and Luo, Chuyao and Yu, Demin and Li, Xutao and Lin, Huiwei and Ye, Yunming and Zhang, Bowen},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={38},
  number={15},
  pages={16687--16695},
  year={2024}
}

@article{ho2020denoising,
  title={Denoising diffusion probabilistic models},
  author={Ho, Jonathan and Jain, Ajay and Abbeel, Pieter},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={6840--6851},
  year={2020}
}

@article{song2020denoising,
  title={Denoising diffusion implicit models},
  author={Song, Jiaming and Meng, Chenlin and Ermon, Stefano},
  journal={arXiv preprint arXiv:2010.02502},
  year={2020}
}
@article{efroni2021provable,
  title={Provable rl with exogenous distractors via multistep inverse dynamics},
  author={Efroni, Yonathan and Misra, Dipendra and Krishnamurthy, Akshay and Agarwal, Alekh and Langford, John},
  journal={arXiv preprint arXiv:2110.08847},
  year={2021}
}
@article{stolz2024excluding,
  title={Excluding the Irrelevant: Focusing Reinforcement Learning through Continuous Action Masking},
  author={Stolz, Roland and Krasowski, Hanna and Thumm, Jakob and Eichelbeck, Michael and Gassert, Philipp and Althoff, Matthias},
  journal={arXiv preprint arXiv:2406.03704},
  year={2024}
}
@article{rahimi2007random,
  title={Random features for large-scale kernel machines},
  author={Rahimi, Ali and Recht, Benjamin},
  journal={Advances in neural information processing systems},
  volume={20},
  year={2007}
}



@article{furnkranz2012preference,
  title={Preference-based reinforcement learning: a formal framework and a policy iteration algorithm},
  author={F{\"u}rnkranz, Johannes and H{\"u}llermeier, Eyke and Cheng, Weiwei and Park, Sang-Hyeun},
  journal={Machine learning},
  volume={89},
  pages={123--156},
  year={2012},
  publisher={Springer}
}

@article{lu2022dpm,
  title={Dpm-solver: A fast ode solver for diffusion probabilistic model sampling in around 10 steps},
  author={Lu, Cheng and Zhou, Yuhao and Bao, Fan and Chen, Jianfei and Li, Chongxuan and Zhu, Jun},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={5775--5787},
  year={2022}
}

@article{cully2015robots,
  title={Robots that can adapt like animals},
  author={Cully, Antoine and Clune, Jeff and Tarapore, Danesh and Mouret, Jean-Baptiste},
  journal={Nature},
  volume={521},
  number={7553},
  pages={503--507},
  year={2015},
  publisher={Nature Publishing Group UK London}
}


@incollection{chatzilygeroudis2021quality,
  title={Quality-diversity optimization: a novel branch of stochastic optimization},
  author={Chatzilygeroudis, Konstantinos and Cully, Antoine and Vassiliades, Vassilis and Mouret, Jean-Baptiste},
  booktitle={Black Box Optimization, Machine Learning, and No-Free Lunch Theorems},
  pages={109--135},
  year={2021},
  publisher={Springer}
}

@article{kostrikov2021offline,
  title={Offline reinforcement learning with implicit q-learning},
  author={Kostrikov, Ilya and Nair, Ashvin and Levine, Sergey},
  journal={arXiv preprint arXiv:2110.06169},
  year={2021}
}


@article{chen2022offline,
  title={Offline reinforcement learning via high-fidelity generative behavior modeling},
  author={Chen, Huayu and Lu, Cheng and Ying, Chengyang and Su, Hang and Zhu, Jun},
  journal={arXiv preprint arXiv:2209.14548},
  year={2022}
}
@article{gu2024review,
  title={A Review of Safe Reinforcement Learning: Methods, Theories and Applications},
  author={Gu, Shangding and Yang, Long and Du, Yali and Chen, Guang and Walter, Florian and Wang, Jun and Knoll, Alois},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},
  year={2024},
  publisher={IEEE}
}

@article{hansen2023idql,
  title={Idql: Implicit q-learning as an actor-critic method with diffusion policies},
  author={Hansen-Estruch, Philippe and Kostrikov, Ilya and Janner, Michael and Kuba, Jakub Grudzien and Levine, Sergey},
  journal={arXiv preprint arXiv:2304.10573},
  year={2023}
}


@article{chandak2022off,
  title={Off-policy evaluation for action-dependent non-stationary environments},
  author={Chandak, Yash and Shankar, Shiv and Bastian, Nathaniel and da Silva, Bruno and Brunskill, Emma and Thomas, Philip S},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={9217--9232},
  year={2022}
}


@article{levine2018reinforcement,
  title={Reinforcement learning and control as probabilistic inference: Tutorial and review},
  author={Levine, Sergey},
  journal={arXiv preprint arXiv:1805.00909},
  year={2018}
}

@article{lipman2022flow,
  title={Flow matching for generative modeling},
  author={Lipman, Yaron and Chen, Ricky TQ and Ben-Hamu, Heli and Nickel, Maximilian and Le, Matt},
  journal={arXiv preprint arXiv:2210.02747},
  year={2022}
}


@article{song2023consistency,
  title={Consistency models},
  author={Song, Yang and Dhariwal, Prafulla and Chen, Mark and Sutskever, Ilya},
  journal={arXiv preprint arXiv:2303.01469},
  year={2023}
}



@article{chi2023diffusion,
  title={Diffusion policy: Visuomotor policy learning via action diffusion},
  author={Chi, Cheng and Xu, Zhenjia and Feng, Siyuan and Cousineau, Eric and Du, Yilun and Burchfiel, Benjamin and Tedrake, Russ and Song, Shuran},
  journal={The International Journal of Robotics Research},
  pages={02783649241273668},
  year={2023},
  publisher={SAGE Publications Sage UK: London, England}
}

@article{song2020score,
  title={Score-based generative modeling through stochastic differential equations},
  author={Song, Yang and Sohl-Dickstein, Jascha and Kingma, Diederik P and Kumar, Abhishek and Ermon, Stefano and Poole, Ben},
  journal={arXiv preprint arXiv:2011.13456},
  year={2020}
}


@article{shribak2024diffusion,
  title={Diffusion Spectral Representation for Reinforcement Learning},
  author={Shribak, Dmitry and Gao, Chen-Xiao and Li, Yitong and Xiao, Chenjun and Dai, Bo},
  journal={arXiv preprint arXiv:2406.16121},
  year={2024}
}

@article{fang2024diffusion,
  title={Diffusion Actor-Critic: Formulating Constrained Policy Iteration as Diffusion Noise Regression for Offline Reinforcement Learning},
  author={Fang, Linjiajie and Liu, Ruoxue and Zhang, Jing and Wang, Wenjia and Jing, Bing-Yi},
  journal={arXiv preprint arXiv:2405.20555},
  year={2024}
}
@article{zhu2023diffusion,
  title={Diffusion models for reinforcement learning: A survey},
  author={Zhu, Zhengbang and Zhao, Hanye and He, Haoran and Zhong, Yichao and Zhang, Shenyu and Yu, Yong and Zhang, Weinan},
  journal={arXiv preprint arXiv:2311.01223},
  year={2023}
}

@article{hafner2019dream,
  title={Dream to control: Learning behaviors by latent imagination},
  author={Hafner, Danijar and Lillicrap, Timothy and Ba, Jimmy and Norouzi, Mohammad},
  journal={arXiv preprint arXiv:1912.01603},
  year={2019}
}

@inproceedings{chen2023playfusion,
  title={Playfusion: Skill acquisition via diffusion from language-annotated play},
  author={Chen, Lili and Bahl, Shikhar and Pathak, Deepak},
  booktitle={Conference on Robot Learning},
  pages={2012--2029},
  year={2023},
  organization={PMLR}
}
@article{an2023direct,
  title={Direct preference-based policy optimization without reward modeling},
  author={An, Gaon and Lee, Junhyeok and Zuo, Xingdong and Kosaka, Norio and Kim, Kyung-Min and Song, Hyun Oh},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  pages={70247--70266},
  year={2023}
}


@article{chen2021decision,
  title={Decision transformer: Reinforcement learning via sequence modeling},
  author={Chen, Lili and Lu, Kevin and Rajeswaran, Aravind and Lee, Kimin and Grover, Aditya and Laskin, Misha and Abbeel, Pieter and Srinivas, Aravind and Mordatch, Igor},
  journal={Advances in neural information processing systems},
  volume={34},
  pages={15084--15097},
  year={2021}
}
@inproceedings{efroni2022sample,
  title={Sample-efficient reinforcement learning in the presence of exogenous information},
  author={Efroni, Yonathan and Foster, Dylan J and Misra, Dipendra and Krishnamurthy, Akshay and Langford, John},
  booktitle={Conference on Learning Theory},
  pages={5062--5127},
  year={2022},
  organization={PMLR}
}

@article{li2020focal,
  title={Focal: Efficient fully-offline meta-reinforcement learning via distance metric learning and behavior regularization},
  author={Li, Lanqing and Yang, Rui and Luo, Dijun},
  journal={arXiv preprint arXiv:2010.01112},
  year={2020}
}


@inproceedings{ni2022optimal,
  title={Optimal estimation of policy gradient via double fitted iteration},
  author={Ni, Chengzhuo and Zhang, Ruiqi and Ji, Xiang and Zhang, Xuezhou and Wang, Mengdi},
  booktitle={International Conference on Machine Learning},
  pages={16724--16783},
  year={2022},
  organization={PMLR}
}

@inproceedings{ren2022free,
  title={A free lunch from the noise: Provable and practical exploration for representation learning},
  author={Ren, Tongzheng and Zhang, Tianjun and Szepesv{\'a}ri, Csaba and Dai, Bo},
  booktitle={Uncertainty in Artificial Intelligence},
  pages={1686--1696},
  year={2022},
  organization={PMLR}
}

@inproceedings{yuan2019cover,
  title={COVER: A cluster-based variance reduced method for online learning},
  author={Yuan, Kun and Ying, Bicheng and Sayed, Ali H},
  booktitle={ICASSP 2019-2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  pages={3102--3106},
  year={2019},
  organization={IEEE}
}

@inproceedings{gu2024balance,
  title={Balance reward and safety optimization for safe reinforcement learning: A perspective of gradient manipulation},
  author={Gu, Shangding and Sel, Bilgehan and Ding, Yuhao and Wang, Lu and Lin, Qingwei and Jin, Ming and Knoll, Alois},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={38},
  number={19},
  pages={21099--21106},
  year={2024}
}

@article{dorfman2021offline,
  title={Offline Meta Reinforcement Learning--Identifiability Challenges and Effective Data Collection Strategies},
  author={Dorfman, Ron and Shenfeld, Idan and Tamar, Aviv},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={4607--4618},
  year={2021}
}

@inproceedings{wang2023offline,
  title={Offline meta reinforcement learning with in-distribution online adaptation},
  author={Wang, Jianhao and Zhang, Jin and Jiang, Haozhe and Zhang, Junyu and Wang, Liwei and Zhang, Chongjie},
  booktitle={International Conference on Machine Learning},
  pages={36626--36669},
  year={2023},
  organization={PMLR}
}

@article{eysenbach2022contrastive,
  title={Contrastive learning as goal-conditioned reinforcement learning},
  author={Eysenbach, Benjamin and Zhang, Tianjun and Levine, Sergey and Salakhutdinov, Russ R},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={35603--35620},
  year={2022}
}

@article{chen2024diffusion,
  title={Diffusion Policies creating a Trust Region for Offline Reinforcement Learning},
  author={Chen, Tianyu and Wang, Zhendong and Zhou, Mingyuan},
  journal={arXiv preprint arXiv:2405.19690},
  year={2024}
}
@inproceedings{le2019batch,
  title={Batch policy learning under constraints},
  author={Le, Hoang and Voloshin, Cameron and Yue, Yisong},
  booktitle={International Conference on Machine Learning},
  pages={3703--3712},
  year={2019},
  organization={PMLR}
}
@inproceedings{lin2023safe,
  title={Safe offline reinforcement learning with real-time budget constraints},
  author={Lin, Qian and Tang, Bo and Wu, Zifan and Yu, Chao and Mao, Shangqin and Xie, Qianlong and Wang, Xingxing and Wang, Dong},
  booktitle={International Conference on Machine Learning},
  pages={21127--21152},
  year={2023},
  organization={PMLR}
}
@inproceedings{liu2023constrained,
  title={Constrained decision transformer for offline safe reinforcement learning},
  author={Liu, Zuxin and Guo, Zijian and Yao, Yihang and Cen, Zhepeng and Yu, Wenhao and Zhang, Tingnan and Zhao, Ding},
  booktitle={International Conference on Machine Learning},
  pages={21611--21630},
  year={2023},
  organization={PMLR}
}

@inproceedings{xu2022constraints,
  title={Constraints penalized q-learning for safe offline reinforcement learning},
  author={Xu, Haoran and Zhan, Xianyuan and Zhu, Xiangyu},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={36},
  number={8},
  pages={8753--8760},
  year={2022}
}

@article{lee2022coptidice,
  title={Coptidice: Offline constrained reinforcement learning via stationary distribution correction estimation},
  author={Lee, Jongmin and Paduraru, Cosmin and Mankowitz, Daniel J and Heess, Nicolas and Precup, Doina and Kim, Kee-Eung and Guez, Arthur},
  journal={arXiv preprint arXiv:2204.08957},
  year={2022}
}
@article{liu2023datasets,
  title={Datasets and benchmarks for offline safe reinforcement learning},
  author={Liu, Zuxin and Guo, Zijian and Lin, Haohong and Yao, Yihang and Zhu, Jiacheng and Cen, Zhepeng and Hu, Hanjiang and Yu, Wenhao and Zhang, Tingnan and Tan, Jie and others},
  journal={arXiv preprint arXiv:2306.09303},
  year={2023}
}

@inproceedings{xu2021crpo,
  title={Crpo: A new approach for safe reinforcement learning with convergence guarantee},
  author={Xu, Tengyu and Liang, Yingbin and Lan, Guanghui},
  booktitle={International Conference on Machine Learning},
  pages={11480--11491},
  year={2021},
  organization={PMLR}
}

@article{chen2023score,
  title={Score regularized policy optimization through diffusion behavior},
  author={Chen, Huayu and Lu, Cheng and Wang, Zhengyi and Su, Hang and Zhu, Jun},
  journal={arXiv preprint arXiv:2310.07297},
  year={2023}
}
@inproceedings{yuan2022robust,
  title={Robust task representations for offline meta-reinforcement learning via contrastive learning},
  author={Yuan, Haoqi and Lu, Zongqing},
  booktitle={International Conference on Machine Learning},
  pages={25747--25759},
  year={2022},
  organization={PMLR}
}
@inproceedings{zhang2022making,
  title={Making linear mdps practical via contrastive representation learning},
  author={Zhang, Tianjun and Ren, Tongzheng and Yang, Mengjiao and Gonzalez, Joseph and Schuurmans, Dale and Dai, Bo},
  booktitle={International Conference on Machine Learning},
  pages={26447--26466},
  year={2022},
  organization={PMLR}
}

@article{he2024diffusion,
  title={Diffusion model is an effective planner and data synthesizer for multi-task reinforcement learning},
  author={He, Haoran and Bai, Chenjia and Xu, Kang and Yang, Zhuoran and Zhang, Weinan and Wang, Dong and Zhao, Bin and Li, Xuelong},
  journal={Advances in neural information processing systems},
  volume={36},
  year={2024}
}

@article{yang2023learning,
  title={Learning interactive real-world simulators},
  author={Yang, Mengjiao and Du, Yilun and Ghasemipour, Kamyar and Tompson, Jonathan and Schuurmans, Dale and Abbeel, Pieter},
  journal={arXiv preprint arXiv:2310.06114},
  year={2023}
}

@article{zhang2023provable,
  title={Provable Representation with Efficient Planning for Partially Observable Reinforcement Learning},
  author={Zhang, Hongming and Ren, Tongzheng and Xiao, Chenjun and Schuurmans, Dale and Dai, Bo},
  journal={arXiv preprint arXiv:2311.12244},
  year={2023}
}

@article{janner2022planning,
  title={Planning with diffusion for flexible behavior synthesis},
  author={Janner, Michael and Du, Yilun and Tenenbaum, Joshua B and Levine, Sergey},
  journal={arXiv preprint arXiv:2205.09991},
  year={2022}
}

@article{duan2016rl,
  title={ $\text{RL}^2$: Fast reinforcement learning via slow reinforcement learning},
  author={Duan, Yan and Schulman, John and Chen, Xi and Bartlett, Peter L and Sutskever, Ilya and Abbeel, Pieter},
  journal={arXiv preprint arXiv:1611.02779},
  year={2016}
}

@article{mishra2017simple,
  title={A simple neural attentive meta-learner},
  author={Mishra, Nikhil and Rohaninejad, Mostafa and Chen, Xi and Abbeel, Pieter},
  journal={arXiv preprint arXiv:1707.03141},
  year={2017}
}

@article{zintgraf2019varibad,
  title={Varibad: A very good method for bayes-adaptive deep rl via meta-learning},
  author={Zintgraf, Luisa and Shiarlis, Kyriacos and Igl, Maximilian and Schulze, Sebastian and Gal, Yarin and Hofmann, Katja and Whiteson, Shimon},
  journal={arXiv preprint arXiv:1910.08348},
  year={2019}
}

@article{ma2024skill,
  title={Skill transfer and discovery for sim-to-real learning: A representation-based viewpoint},
  author={Ma, Haitong and Ren, Zhaolin and Dai, Bo and Li, Na},
  journal={arXiv preprint arXiv:2404.05051},
  year={2024}
}

@article{chen2021randomized,
  title={Randomized ensembled double q-learning: Learning fast without a model},
  author={Chen, Xinyue and Wang, Che and Zhou, Zijian and Ross, Keith},
  journal={arXiv preprint arXiv:2101.05982},
  year={2021}
}

@inproceedings{haarnoja2018soft,
  title={Soft actor-critic: Off-policy maximum entropy deep reinforcement learning with a stochastic actor},
  author={Haarnoja, Tuomas and Zhou, Aurick and Abbeel, Pieter and Levine, Sergey},
  booktitle={International conference on machine learning},
  pages={1861--1870},
  year={2018},
  organization={PMLR}
}

@article{liu2023policy,
  title={Policy ensemble gradient for continuous control problems in deep reinforcement learning},
  author={Liu, Guoqiang and Chen, Gang and Huang, Victoria},
  journal={Neurocomputing},
  volume={548},
  pages={126381},
  year={2023},
  publisher={Elsevier}
}

@article{khattar2024cmdp,
  title={A CMDP-within-online framework for meta-safe reinforcement learning},
  author={Khattar, Vanshaj and Ding, Yuhao and Sel, Bilgehan and Lavaei, Javad and Jin, Ming},
  journal={arXiv preprint arXiv:2405.16601},
  year={2024}
}
@article{sener2020learning,
  title={Learning to guide random search},
  author={Sener, Ozan and Koltun, Vladlen},
  journal={arXiv preprint arXiv:2004.12214},
  year={2020}
}
@misc{
melo2022transformers,
title={Transformers are Meta-Reinforcement Learners},
author={Luckeciano Carvalho Melo},
year={2022},
url={https://openreview.net/forum?id=H7Edu1_IZgR}
}
@inproceedings{
zheng2024safe,
title={Safe Offline Reinforcement Learning with Feasibility-Guided Diffusion Model},
author={Yinan Zheng and Jianxiong Li and Dongjie Yu and Yujie Yang and Shengbo Eben Li and Xianyuan Zhan and Jingjing Liu},
booktitle={The Twelfth International Conference on Learning Representations},
year={2024}
}

@inproceedings{
wu2024offpolicy,
title={Off-Policy Primal-Dual Safe Reinforcement Learning},
author={Zifan Wu and Bo Tang and Qian Lin and Chao Yu and Shangqin Mao and Qianlong Xie and Xingxing Wang and Dong Wang},
booktitle={The Twelfth International Conference on Learning Representations},
year={2024}
}


@article{vaswani2017attention,
  title={Attention is all you need},
  author={Vaswani, A},
  journal={Advances in Neural Information Processing Systems},
  year={2017}
}


@article{wachi2024stepwise,
  title={Stepwise Alignment for Constrained Language Model Policy Optimization},
  author={Wachi, Akifumi and Tran, Thien Q and Sato, Rei and Tanabe, Takumi and Akimoto, Yohei},
  journal={arXiv preprint arXiv:2404.11049},
  year={2024}
}

@article{tripuraneni2020theory,
  title={On the theory of transfer learning: The importance of task diversity},
  author={Tripuraneni, Nilesh and Jordan, Michael and Jin, Chi},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={7852--7862},
  year={2020}
}

@article{lyu2022mildly,
  title={Mildly conservative q-learning for offline reinforcement learning},
  author={Lyu, Jiafei and Ma, Xiaoteng and Li, Xiu and Lu, Zongqing},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={1711--1724},
  year={2022}
}

@article{wu2019behavior,
  title={Behavior regularized offline reinforcement learning},
  author={Wu, Yifan and Tucker, George and Nachum, Ofir},
  journal={arXiv preprint arXiv:1911.11361},
  year={2019}
}

@inproceedings{achiam2017constrained,
  title={Constrained policy optimization},
  author={Achiam, Joshua and Held, David and Tamar, Aviv and Abbeel, Pieter},
  booktitle={International conference on machine learning},
  pages={22--31},
  year={2017},
  organization={PMLR}
}

@article{de2022convergence,
  title={Convergence of denoising diffusion models under the manifold hypothesis},
  author={De Bortoli, Valentin},
  journal={arXiv preprint arXiv:2208.05314},
  year={2022}
}

@article{schulman2015trust,
  title={Trust Region Policy Optimization},
  author={Schulman, John},
  journal={arXiv preprint arXiv:1502.05477},
  year={2015}
}


@inproceedings{zhou2023gradient,
  title={Gradient-adaptive pareto optimization for constrained reinforcement learning},
  author={Zhou, Zixian and Huang, Mengda and Pan, Feiyang and He, Jia and Ao, Xiang and Tu, Dandan and He, Qing},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={37},
  number={9},
  pages={11443--11451},
  year={2023}
}


@inproceedings{calian2020balancing,
  title={Balancing constraints and rewards with meta-gradient d4pg},
  author={Calian, Dan A and Mankowitz, Daniel J and Zahavy, Tom and Xu, Zhongwen and Oh, Junhyuk and Levine, Nir and Mann, Timothy},
  booktitle={International Conference on Learning Representations},
  year={2020}
}


@article{ray2019benchmarking,
  title={Benchmarking safe exploration in deep reinforcement learning},
  author={Ray, Alex and Achiam, Joshua and Amodei, Dario},
  journal={arXiv preprint arXiv:1910.01708},
  volume={7},
  number={1},
  pages={2},
  year={2019}
}

@article{ajay2022conditional,
  title={Is conditional generative modeling all you need for decision-making?},
  author={Ajay, Anurag and Du, Yilun and Gupta, Abhi and Tenenbaum, Joshua and Jaakkola, Tommi and Agrawal, Pulkit},
  journal={arXiv preprint arXiv:2211.15657},
  year={2022}
}

@article{chow2018risk,
  title={Risk-constrained reinforcement learning with percentile risk criteria},
  author={Chow, Yinlam and Ghavamzadeh, Mohammad and Janson, Lucas and Pavone, Marco},
  journal={Journal of Machine Learning Research},
  volume={18},
  number={167},
  pages={1--51},
  year={2018}
}



@techreport{gronauer2022bullet,
	author = {Gronauer, Sven},
	institution = {mediaTUM},
	title = {Bullet-Safety-Gym: A Framework for Constrained Reinforcement Learning},
	year = {2022},
	doi = {10.14459/2022md1639974},
	bdsk-url-1 = {https://mediatum.ub.tum.de/1639974}
}



@article{sutton1988learning,
  title={Learning to predict by the methods of temporal differences},
  author={Sutton, Richard S},
  journal={Machine learning},
  volume={3},
  pages={9--44},
  year={1988},
  publisher={Springer}
}
@article{agarwal2021theory,
  title={On the theory of policy gradient methods: Optimality, approximation, and distribution shift},
  author={Agarwal, Alekh and Kakade, Sham M and Lee, Jason D and Mahajan, Gaurav},
  journal={Journal of Machine Learning Research},
  volume={22},
  number={98},
  pages={1--76},
  year={2021}
}
@article{kingma2013auto,
  title={Auto-encoding variational bayes},
  author={Kingma, Diederik P},
  journal={arXiv preprint arXiv:1312.6114},
  year={2013}
}

@article{gu2024enhancing,
  title={Enhancing Efficiency of Safe Reinforcement Learning via Sample Manipulation},
  author={Gu, Shangding and Shi, Laixi and Ding, Yuhao and Knoll, Alois and Spanos, Costas and Wierman, Adam and Jin, Ming},
  journal={NeurIPS},
  year={2024}
}

@inproceedings{chen2019information,
  title={Information-theoretic considerations in batch reinforcement learning},
  author={Chen, Jinglin and Jiang, Nan},
  booktitle={International Conference on Machine Learning},
  pages={1042--1051},
  year={2019},
  organization={PMLR}
}

@inproceedings{kakade2002approximately,
  title={Approximately optimal approximate reinforcement learning},
  author={Kakade, Sham and Langford, John},
  booktitle={Proceedings of the Nineteenth International Conference on Machine Learning},
  pages={267--274},
  year={2002}
}

@article{fujimoto2021minimalist,
  title={A minimalist approach to offline reinforcement learning},
  author={Fujimoto, Scott and Gu, Shixiang Shane},
  journal={Advances in neural information processing systems},
  volume={34},
  pages={20132--20145},
  year={2021}
}

@article{sohn2015learning,
  title={Learning structured output representation using deep conditional generative models},
  author={Sohn, Kihyuk and Lee, Honglak and Yan, Xinchen},
  journal={Advances in neural information processing systems},
  volume={28},
  year={2015}
}


@article{ganai2024iterative,
  title={Iterative reachability estimation for safe reinforcement learning},
  author={Ganai, Milan and Gong, Zheng and Yu, Chenning and Herbert, Sylvia and Gao, Sicun},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@article{yang2020projection,
  title={Projection-based constrained policy optimization},
  author={Yang, Tsung-Yen and Rosca, Justinian and Narasimhan, Karthik and Ramadge, Peter J},
  journal={arXiv preprint arXiv:2010.03152},
  year={2020}
}





@article{wang2018exponentially,
  title={Exponentially weighted imitation learning for batched historical data},
  author={Wang, Qing and Xiong, Jiechao and Han, Lei and Liu, Han and Zhang, Tong and others},
  journal={Advances in Neural Information Processing Systems},
  volume={31},
  year={2018}
}

@book{csiszar2011information,
  title={Information theory: coding theorems for discrete memoryless systems},
  author={Csisz{\'a}r, Imre and K{\"o}rner, J{\'a}nos},
  year={2011},
  publisher={Cambridge University Press}
}

@article{hao2019bootstrapping,
  title={Bootstrapping upper confidence bound},
  author={Hao, Botao and Abbasi Yadkori, Yasin and Wen, Zheng and Cheng, Guang},
  journal={Advances in neural information processing systems},
  volume={32},
  year={2019}
}

@inproceedings{stooke2020responsive,
  title={Responsive safety in reinforcement learning by pid lagrangian methods},
  author={Stooke, Adam and Achiam, Joshua and Abbeel, Pieter},
  booktitle={International Conference on Machine Learning},
  pages={9133--9143},
  year={2020},
  organization={PMLR}
}


@inproceedings{thrun2014issues,
  title={Issues in using function approximation for reinforcement learning},
  author={Thrun, Sebastian and Schwartz, Anton},
  booktitle={Proceedings of the 1993 connectionist models summer school},
  pages={255--263},
  year={2014},
  organization={Psychology Press}
}

@article{cen2022fast,
  title={Fast global convergence of natural policy gradient methods with entropy regularization},
  author={Cen, Shicong and Cheng, Chen and Chen, Yuxin and Wei, Yuting and Chi, Yuejie},
  journal={Operations Research},
  volume={70},
  number={4},
  pages={2563--2578},
  year={2022},
  publisher={INFORMS}
}


@inproceedings{lu2023contrastive,
  title={Contrastive energy prediction for exact energy-guided diffusion sampling in offline reinforcement learning},
  author={Lu, Cheng and Chen, Huayu and Chen, Jianfei and Su, Hang and Li, Chongxuan and Zhu, Jun},
  booktitle={International Conference on Machine Learning},
  pages={22825--22855},
  year={2023},
  organization={PMLR}
}

@article{wang2022diffusion,
  title={Diffusion policies as an expressive policy class for offline reinforcement learning},
  author={Wang, Zhendong and Hunt, Jonathan J and Zhou, Mingyuan},
  journal={arXiv preprint arXiv:2208.06193},
  year={2022}
}

@inproceedings{sohl2015deep,
  title={Deep unsupervised learning using nonequilibrium thermodynamics},
  author={Sohl-Dickstein, Jascha and Weiss, Eric and Maheswaranathan, Niru and Ganguli, Surya},
  booktitle={International conference on machine learning},
  pages={2256--2265},
  year={2015},
  organization={PMLR}
}

@article{paternain2022safe,
  title={Safe policies for reinforcement learning via primal-dual methods},
  author={Paternain, Santiago and Calvo-Fullana, Miguel and Chamon, Luiz FO and Ribeiro, Alejandro},
  journal={IEEE Transactions on Automatic Control},
  volume={68},
  number={3},
  pages={1321--1336},
  year={2022},
  publisher={IEEE}
}

@inproceedings{ding2021provably,
  title={Provably efficient safe exploration via primal-dual policy optimization},
  author={Ding, Dongsheng and Wei, Xiaohan and Yang, Zhuoran and Wang, Zhaoran and Jovanovic, Mihailo},
  booktitle={International conference on artificial intelligence and statistics},
  pages={3304--3312},
  year={2021},
  organization={PMLR}
}


@article{kumar2019stabilizing,
  title={Stabilizing off-policy q-learning via bootstrapping error reduction},
  author={Kumar, Aviral and Fu, Justin and Soh, Matthew and Tucker, George and Levine, Sergey},
  journal={Advances in neural information processing systems},
  volume={32},
  year={2019}
}

@article{gu2022review,
  title={A review of safe reinforcement learning: Methods, theories and applications},
  author={Gu, Shangding and Yang, Long and Du, Yali and Chen, Guang and Walter, Florian and Wang, Jun and Knoll, Alois},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},
  year={2024}
}

@article{levine2020offline,
  title={Offline reinforcement learning: Tutorial, review, and perspectives on open problems},
  author={Levine, Sergey and Kumar, Aviral and Tucker, George and Fu, Justin},
  journal={arXiv preprint arXiv:2005.01643},
  year={2020}
}


@article{sun2024bbox,
  title={BBox-Adapter: Lightweight Adapting for Black-Box Large Language Models},
  author={Sun, Haotian and Zhuang, Yuchen and Wei, Wei and Zhang, Chao and Dai, Bo},
  journal={arXiv preprint arXiv:2402.08219},
  year={2024}
}

@article{ding2020natural,
  title={Natural policy gradient primal-dual method for constrained markov decision processes},
  author={Ding, Dongsheng and Zhang, Kaiqing and Basar, Tamer and Jovanovic, Mihailo},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={8378--8390},
  year={2020}
}

@inproceedings{ying2022dual,
  title={A dual approach to constrained markov decision processes with entropy regularization},
  author={Ying, Donghao and Ding, Yuhao and Lavaei, Javad},
  booktitle={International Conference on Artificial Intelligence and Statistics},
  pages={1887--1909},
  year={2022},
  organization={PMLR}
}

@inproceedings{liu2022constrained,
  title={Constrained variational policy optimization for safe reinforcement learning},
  author={Liu, Zuxin and Cen, Zhepeng and Isenbaev, Vladislav and Liu, Wei and Wu, Steven and Li, Bo and Zhao, Ding},
  booktitle={International Conference on Machine Learning},
  pages={13644--13668},
  year={2022},
  organization={PMLR}
}

@article{tessler2018reward,
  title={Reward constrained policy optimization},
  author={Tessler, Chen and Mankowitz, Daniel J and Mannor, Shie},
  journal={arXiv preprint arXiv:1805.11074},
  year={2018}
}

@inproceedings{yangprojection,
  title={Projection-Based Constrained Policy Optimization},
  author={Yang, Tsung-Yen and Rosca, Justinian and Narasimhan, Karthik and Ramadge, Peter J},
  booktitle={International Conference on Learning Representations},
  year={2020}
}

@book{altman2021constrained,
  title={Constrained Markov decision processes},
  author={Altman, Eitan},
  year={2021},
  publisher={Routledge}
}