%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%% ATTENTION %%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

@inproceedings{vaswani2017attention,
 title = {Attention is All you Need}, 
 author = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, \L ukasz and Polosukhin, Illia},
 booktitle = {Advances in Neural Information Processing Systems},
 pages = {6000–6010},
 volume = {30},
 year = {2017}
}

@article{devlin2018bert,
  title={Bert: Pre-training of deep bidirectional transformers for language understanding},
  author={Devlin, Jacob},
  journal={arXiv preprint arXiv:1810.04805},
  year={2018}
}

@article{brown2020gpt3,
  title={Language models are few-shot learners},
  author={Brown, Tom and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared D and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and others},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={1877--1901},
  year={2020}
}

@inproceedings{katharopoulos2020transformers_are_rnns,
  title={Transformers are rnns: Fast autoregressive transformers with linear attention},
  author={Katharopoulos, Angelos and Vyas, Apoorv and Pappas, Nikolaos and Fleuret, Fran{\c{c}}ois},
  booktitle={International conference on machine learning},
  pages={5156--5165},
  year={2020},
  organization={PMLR}
}

@inproceedings{ahn2024linear_maybe,
title={Linear attention is (maybe) all you need (to understand Transformer optimization)},
author={Kwangjun Ahn and Xiang Cheng and Minhak Song and Chulhee Yun and Ali Jadbabaie and Suvrit Sra},
booktitle={The Twelfth International Conference on Learning Representations},
year={2024}
}
% url={https://openreview.net/forum?id=0uI5415ry7}
}

@article{Tay2022efficient,
author = {Tay, Yi and Dehghani, Mostafa and Bahri, Dara and Metzler, Donald},
title = {Efficient Transformers: A Survey},
year = {2022},
issue_date = {June 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {55},
number = {6},
issn = {0360-0300},
doi = {10.1145/3530811},
journal = {ACM Comput. Surv.},
month = dec,
articleno = {109},
numpages = {28}
}
% url = {https://doi.org/10.1145/3530811},
}

@article{lin2022transformers_survey,
title = {A survey of transformers},
author = {Tianyang Lin and Yuxin Wang and Xiangyang Liu and Xipeng Qiu},
journal = {AI Open},
volume = {3},
pages = {111-132},
year = {2022},
issn = {2666-6510},
doi = {https://doi.org/10.1016/j.aiopen.2022.10.001},
}

@article{khan2022transformers_vision_survey,
author = {Khan, Salman and Naseer, Muzammal and Hayat, Munawar and Zamir, Syed Waqas and Khan, Fahad Shahbaz and Shah, Mubarak},
title = {Transformers in Vision: A Survey},
year = {2022},
issue_date = {January 2022},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {54},
number = {10s},
issn = {0360-0300},
doi = {10.1145/3505244},
journal = {ACM Comput. Surv.},
month = sep,
articleno = {200},
numpages = {41}
}
% url = {https://doi.org/10.1145/3505244},
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%% SSM %%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

@article{kalman1960new,
  title={A new approach to linear filtering and prediction problems [J]},
  author={Kalman, Rudolph Emil and others},
  journal={Journal of basic Engineering},
  volume={82},
  number={1},
  pages={35--45},
  year={1960}
}

@article{gu2020hippo,
  title={Hippo: Recurrent memory with optimal polynomial projections},
  author={Gu, Albert and Dao, Tri and Ermon, Stefano and Rudra, Atri and R{\'e}, Christopher},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={1474--1487},
  year={2020}
}

@article{gu2021ssm,
  title={Combining recurrent, convolutional, and continuous-time models with linear state space layers},
  author={Gu, Albert and Johnson, Isys and Goel, Karan and Saab, Khaled and Dao, Tri and Rudra, Atri and R{\'e}, Christopher},
  journal={Advances in neural information processing systems},
  volume={34},
  pages={572--585},
  year={2021}
}

@article{gu2022s4,
  title={Efficiently modeling long sequences with structured state spaces},
  author={Gu, Albert and Goel, Karan and R{\'e}, Christopher},
  journal={In International Conference on Learning Representations},
  year={2022}
}

@article{gu2022s4d,
  title={On the parameterization and initialization of diagonal state space models},
  author={Gu, Albert and Goel, Karan and Gupta, Ankit and R{\'e}, Christopher},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={35971--35983},
  year={2022}
}

@inproceedings{smith2023s5,
title={Simplified State Space Layers for Sequence Modeling},
author={Jimmy T.H. Smith and Andrew Warrington and Scott Linderman},
booktitle={The Eleventh International Conference on Learning Representations },
year={2023}
}
% url={https://openreview.net/forum?id=Ai8Hw3AXqks}
}

@inproceedings{poli2023hyena,
  title={Hyena hierarchy: Towards larger convolutional language models},
  author={Poli, Michael and Massaroli, Stefano and Nguyen, Eric and Fu, Daniel Y and Dao, Tri and Baccus, Stephen and Bengio, Yoshua and Ermon, Stefano and R{\'e}, Christopher},
  booktitle={International Conference on Machine Learning},
  pages={28043--28078},
  year={2023},
  organization={PMLR}
}

@inproceedings{gu2024mamba,
title={Mamba: Linear-Time Sequence Modeling with Selective State Spaces},
author={Albert Gu and Tri Dao},
booktitle={First Conference on Language Modeling},
year={2024}
}
% url={https://openreview.net/forum?id=tEYskw1VY2}
}

@inproceedings{dao2024transformers_are_ssms,
    title = {Transformers are SSMs: generalized models and efficient algorithms through structured state space duality},
    author = {Dao, Tri and Gu, Albert},
    booktitle = {Proceedings of the 41st International Conference on Machine Learning},
    pages={10041--10071},
    year = {2024},
    publisher = {JMLR.org},
}

@article{tustin1947method,
  title={A method of analysing the behaviour of linear systems in terms of time series},
  author={Tustin, Arnold},
  journal={Journal of the Institution of Electrical Engineers-Part IIA: Automatic Regulators and Servo Mechanisms},
  volume={94},
  number={1},
  pages={130--142},
  year={1947},
  publisher={IET}
}

@inproceedings{anonymous2025hope,
title={{HOPE} for a Robust Parameterization of Long-memory State Space Models},
author={Anonymous},
booktitle={The Thirteenth International Conference on Learning Representations},
year={2025}
}
% url={https://openreview.net/forum?id=RZwtbg3qYD}
}

@inproceedings{wang2024stablessm,
title={Stable{SSM}: Alleviating the Curse of Memory in State-space Models through Stable Reparameterization},
author={Shida Wang and Qianxiao Li},
booktitle={Forty-first International Conference on Machine Learning},
year={2024}
}

@book{toth2010lpv,
  title={Modeling and identification of linear parameter-varying systems},
  author={T{\'o}th, Roland},
  volume={403},
  year={2010},
  publisher={Springer}
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%% GENERALIZATION %%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

@book{vershynin2018high,
  title={High-dimensional probability: An introduction with applications in data science},
  author={Vershynin, Roman},
  volume={47},
  year={2018},
  publisher={Cambridge university press}
}

@book{shalev2014understanding,
  title={Understanding machine learning: From theory to algorithms},
  author={Shalev-Shwartz, Shai and Ben-David, Shai},
  year={2014},
  publisher={Cambridge university press}
}

@article{dudley1967sizes,
  title={The sizes of compact subsets of Hilbert space and continuity of Gaussian processes},
  author={Dudley, Richard M},
  journal={Journal of Functional Analysis},
  volume={1},
  number={3},
  pages={290--330},
  year={1967},
  publisher={Elsevier}
}

@article{karpinski1997polynomial,
  title={Polynomial bounds for VC dimension of sigmoidal and general Pfaffian neural networks},
  author={Karpinski, Marek and Macintyre, Angus},
  journal={Journal of Computer and System Sciences},
  volume={54},
  number={1},
  pages={169--176},
  year={1997},
  publisher={Elsevier}
}

@article{koiran1997neural,
  title={Neural networks with quadratic VC dimension},
  author={Koiran, Pascal and Sontag, Eduardo D},
  journal={journal of computer and system sciences},
  volume={54},
  number={1},
  pages={190--198},
  year={1997},
  publisher={Elsevier}
}

@article{sontag1998learning,
  title={A learning result for continuous-time recurrent neural networks},
  author={Sontag, Eduardo D},
  journal={Systems \& control letters},
  volume={34},
  number={3},
  pages={151--158},
  year={1998},
  publisher={Elsevier}
}

@article{baum1988size,
  title={What size net gives valid generalization?},
  author={Baum, Eric and Haussler, David},
  journal={Advances in neural information processing systems},
  volume={1},
  year={1988}
}

@article{bartlett1998size,
  author={Bartlett, P.L.},
  journal={IEEE Transactions on Information Theory}, 
  title={The sample complexity of pattern classification with neural networks: the size of the weights is more important than the size of the network}, 
  year={1998},
  volume={44},
  number={2},
  pages={525-536},
  doi={10.1109/18.661502}}

@article{bartlett1998almost,
  title={Almost linear VC dimension bounds for piecewise polynomial networks},
  author={Bartlett, Peter and Maiorov, Vitaly and Meir, Ron},
  journal={Advances in neural information processing systems},
  volume={11},
  year={1998}
}

@article{bartlett1999svm,
  title={Generalization performance of support vector machines and other pattern classifiers},
  author={Bartlett, Peter and Shawe-Taylor, John},
  journal={Advances in Kernel methods—support vector learning},
  pages={43--54},
  year={1999},
  publisher={Citeseer}
}

@article{bartlett2017spectrally,
  title={Spectrally-normalized margin bounds for neural networks},
  author={Bartlett, Peter L and Foster, Dylan J and Telgarsky, Matus J},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}

@inproceedings{edelman2022inductive,
  title={Inductive biases and variable creation in self-attention mechanisms},
  author={Edelman, Benjamin L and Goel, Surbhi and Kakade, Sham and Zhang, Cyril},
  booktitle={International Conference on Machine Learning},
  pages={5793--5831},
  year={2022},
  organization={PMLR}
}

@article{truong2024rank,
  title={On Rank-Dependent Generalisation Error Bounds for Transformers},
  author={Truong, Lan V},
  journal={arXiv preprint arXiv:2410.11500},
  year={2024}
}

@inproceedings{racz2024length,
  title={Length independent generalization bounds for deep SSM architectures},
  author={R{\'a}cz, D{\'a}niel and Petreczky, Mih{\'a}ly and Dar{\'o}czy, B{\'a}lint},
  booktitle={Next Generation of Sequence Modeling Architectures Workshop at ICML 2024},
  year={2024}
}

@article{racz2024lpv,
  title={A finite-sample generalization bound for stable LPV systems},
  author={Racz, Daniel and Gonzalez, Martin and Petreczky, Mihaly and Benczur, Andras and Daroczy, Balint},
  journal={arXiv preprint arXiv:2405.10054},
  year={2024}
}

@inproceedings{chen2019generalization_rnn,
  title={On Generalization Bounds of a Family of Recurrent Neural Networks},
  author={Chen, Minshuo and Li, Xingguo and Zhao, Tuo},
  booktitle={International Conference on Artificial Intelligence and Statistics (AISTATS), 2020},
  year={2020}
}

@inproceedings{zhang2018stabilizing,
  title={Stabilizing gradients for deep neural networks via efficient svd parameterization},
  author={Zhang, Jiong and Lei, Qi and Dhillon, Inderjit},
  booktitle={International Conference on Machine Learning},
  pages={5806--5814},
  year={2018},
  organization={PMLR}
}

@inproceedings{tu2020understanding,
  title={Understanding generalization in recurrent neural networks},
  author={Tu, Zhuozhuo and He, Fengxiang and Tao, Dacheng},
  booktitle={International Conference on Learning Representations},
  year={2020}
}

@article{cheng2024risk_rnn,
  title={Generalization and risk bounds for recurrent neural networks},
  author={Cheng, Xuewei and Huang, Ke and Ma, Shujie},
  journal={Neurocomputing},
  pages={128825},
  year={2024},
  publisher={Elsevier}
}

@inproceedings{hanson2021recurrent_nonlinear,
  title={Learning recurrent neural net models of nonlinear systems},
  author={Hanson, Joshua and Raginsky, Maxim and Sontag, Eduardo},
  booktitle={Learning for Dynamics and Control},
  pages={425--435},
  year={2021},
  organization={PMLR}
}


@InProceedings{hanson2024neural_ode_rademacher,
  title = 	 {{R}ademacher complexity of neural {ODE}s via {C}hen-{F}liess series},
  author =       {Hanson, Joshua and Raginsky, Maxim},
  booktitle = 	 {Proceedings of the 6th Annual Learning for Dynamics &amp; Control Conference},
  pages = 	 {758--769},
  year = 	 {2024},
  volume = 	 {242},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {15--17 Jul},
  publisher =    {PMLR}
}
% url = 	 {https://proceedings.mlr.press/v242/hanson24a.html}
}

@inproceedings{trauger2024length_independent_transformer,
  title={Sequence length independent norm-based generalization bounds for transformers},
  author={Trauger, Jacob and Tewari, Ambuj},
  booktitle={International Conference on Artificial Intelligence and Statistics},
  pages={1405--1413},
  year={2024},
  organization={PMLR}
}

@inproceedings{liu2024generalization,
author = {Liu, Fusheng and Li, Qianxiao},
title = {From generalization analysis to optimization designs for state space models},
year = {2024},
publisher = {JMLR.org},
booktitle = {Proceedings of the 41st International Conference on Machine Learning},
articleno = {1267},
numpages = {23},
location = {Vienna, Austria},
series = {ICML'24}
}

@article{liu2024autocorrelation,
  title={Autocorrelation Matters: Understanding the Role of Initialization Schemes for State Space Models},
  author={Liu, Fusheng and Li, Qianxiao},
  journal={arXiv preprint arXiv:2411.19455},
  year={2024}
}

@inproceedings{maas2011imdb,
  title={Learning word vectors for sentiment analysis},
  author={Maas, Andrew and Daly, Raymond E and Pham, Peter T and Huang, Dan and Ng, Andrew Y and Potts, Christopher},
  booktitle={Proceedings of the 49th annual meeting of the association for computational linguistics: Human language technologies},
  pages={142--150},
  year={2011}
}

@inproceedings{tay2021long_range_arena,
title={Long Range Arena : A Benchmark for Efficient Transformers },
author={Yi Tay and Mostafa Dehghani and Samira Abnar and Yikang Shen and Dara Bahri and Philip Pham and Jinfeng Rao and Liu Yang and Sebastian Ruder and Donald Metzler},
booktitle={International Conference on Learning Representations},
year={2021}
}
% url={https://openreview.net/forum?id=qVyeW-grC2k}
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%% OTHER %%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

@article{chen2021hyperparameter,
  title={Hyperparameter tuning is all you need for LISTA},
  author={Chen, Xiaohan and Liu, Jialin and Wang, Zhangyang and Yin, Wotao},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={11678--11689},
  year={2021}
}

@inproceedings{liu2018dyan,
  title={Dyan: A dynamical atoms-based network for video prediction},
  author={Liu, Wenqian and Sharma, Abhishek and Camps, Octavia and Sznaier, Mario},
  booktitle={Proceedings of the European Conference on Computer Vision (ECCV)},
  pages={170--185},
  year={2018}
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


@article{zhang2002covering,
  title={Covering number bounds of certain regularized linear function classes},
  author={Zhang, Tong},
  journal={Journal of Machine Learning Research},
  volume={2},
  number={Mar},
  pages={527--550},
  year={2002}
}

@article{pisier1981maurey,
  title={Remarques sur un r{\'e}sultat non publi{\'e} de B. Maurey},
  author={Pisier, Gilles},
  journal={S{\'e}minaire d'Analyse fonctionnelle (dit" Maurey-Schwartz")},
  pages={1--12},
  year={1981}
}

@misc{mohri2018foundations_machine_learning,
  title={Foundations of machine learning},
  author={Mohri, Mehryar},
  year={2018},
  publisher={MIT press}
}

@misc{keller2024regularization,
  author       = {Keller, Yannik},
  title        = {Solving vanishing gradients from model parameter collapse},
  howpublished = {\url{https://yannikkeller.substack.com/p/solving-vanishing-gradients-from?r=3avwpj&triedRedirect=true}},
  year         = {2024}
}

@misc{SridharanNotes,
  author       = {Karthik Sridharan},
  title        = {Note on Refined Dudley Integral Covering Number Bound},
  note         = {Lecture notes}  
}
% url          = {https://home.ttic.edu/~karthik/dudley.pdf},
}

@inproceedings{cirone2024theoretical_selective_ssm,
title={Theoretical Foundations of Deep Selective State-Space Models},
author={Nicola Muca Cirone and Antonio Orvieto and Benjamin Walker and Cristopher Salvi and Terry Lyons},
booktitle={The Thirty-eighth Annual Conference on Neural Information Processing Systems},
year={2024}
}
% url={https://openreview.net/forum?id=3SzrqwupUx}
}

@inproceedings{liu2024diffusion_vision_transformer,
  title={Solving Masked Jigsaw Puzzles with Diffusion Vision Transformers},
  author={Liu, Jinyang and Teshome, Wondmgezahu and Ghimire, Sandesh and Sznaier, Mario and Camps, Octavia},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={23009--23018},
  year={2024}
}

@inproceedings{dosovitskiy2020vision_transformer,
title={An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale},
author={Alexey Dosovitskiy and Lucas Beyer and Alexander Kolesnikov and Dirk Weissenborn and Xiaohua Zhai and Thomas Unterthiner and Mostafa Dehghani and Matthias Minderer and Georg Heigold and Sylvain Gelly and Jakob Uszkoreit and Neil Houlsby},
booktitle={International Conference on Learning Representations},
year={2021}
}
% url={https://openreview.net/forum?id=YicbFdNTTy}
}

@inproceedings{peebles2023scalable_diffusion_transformer,
  title={Scalable diffusion models with transformers},
  author={Peebles, William and Xie, Saining},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={4195--4205},
  year={2023}
}

@book{tunstall2022natural,
  title={Natural language processing with transformers},
  author={Tunstall, Lewis and Von Werra, Leandro and Wolf, Thomas},
  year={2022},
  publisher={" O'Reilly Media, Inc."}
}