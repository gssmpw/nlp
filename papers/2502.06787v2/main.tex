\documentclass[10pt,twocolumn,letterpaper]{article}
\usepackage[pagenumbers]{cvpr} % Arxiv version
% \usepackage{cvpr}
\usepackage[accsupp]{axessibility}

\input{preamble}

\definecolor{cvprblue}{rgb}{0.21,0.49,0.74}
\usepackage[pagebackref,breaklinks,colorlinks,allcolors=cvprblue]{hyperref}


\definecolor{myyellow}{RGB}{255, 250, 205}
\definecolor{myblue}{RGB}{68, 114, 196}
\definecolor{myred}{RGB}{220, 20, 60}
\definecolor{mygreen}{RGB}{46, 139, 87}
\definecolor{myorange}{RGB}{237, 125, 49}
\definecolor{dpurple}{RGB}{128, 0, 128}
\definecolor{lpurple}{RGB}{235, 232, 242}
\definecolor{lblue}{rgb}{0.94, 0.96, 1.0}
\definecolor{grey}{RGB}{128, 128, 128}
\definecolor{lred}{RGB}{255,114,118}
\definecolor{mypurple}{RGB}{75,0,130}
\hypersetup{
    colorlinks=true,
    linkcolor=dpurple,
    filecolor=cvprblue,      
    urlcolor=cvprblue,
    citecolor=cvprblue,
}
\captionsetup[figure]{hypcap=false}
\usepackage{comment}
\usepackage{multirow}

\usepackage{xspace}
\usepackage{wrapfig}
\usepackage{amsfonts}
\usepackage{bbm}

% PAR COMMAND
\newcommand{\mypar}[1]{\vspace{1mm}\noindent\textbf{#1}}
\newcommand{\myparit}[1]{\vspace{1mm}\noindent\emph{#1}}

% METHOD COMMAND
\def\method{VADAR\xspace}
\def\ourbench{\textsc{Omni3D-Bench}\xspace}
\def\clevr{\textsc{CLEVR}\xspace}

% OTHER METHOD COMMANDS
\def\gpt4o{GPT4o\xspace}
\def\llama{Llama3.2\xspace}
\def\gemini{Gemini\xspace}
\def\claude{Claude-Sonnet\xspace}
\def\viper{ViperGPT\xspace}
\def\visprog{VisProg\xspace}
\def\leftm{LEFT\xspace}

% BOLD
\newcommand\bp[1]{\textcolor{mypurple}{\textbf{#1}}}


\title{Visual Agentic AI for Spatial Reasoning with a Dynamic API}
\author{%
  Damiano Marsili$^{*}$ \quad 
  Rohun Agrawal$^{*}$ \quad 
  Yisong Yue \quad
  Georgia Gkioxari \smallskip \smallskip\\
  California Institute of Technology \\
}

\begin{document}

\twocolumn[{%
\renewcommand\twocolumn[1][]{#1}%
\maketitle
\begin{center}
    \vspace{-10mm}
    \centering
    \includegraphics[width=0.94\linewidth]{figures/figure1.png}
    \vspace{-4mm}
    \captionof{figure}{Spatial reasoning in 3D is challenging as it requires multiple steps of grounding and inference. We introduce a benchmark for 3D understanding with complex queries; an example is shown here. To tackle these queries we propose a training-free agentic approach, \method, that dynamically generates new skills in Python and thus can handle a wider range of queries compared to prior methods.} 
    \label{fig:fig1}
\end{center}%
}]
\input{sec/abstract}
\vspace{-4mm}
\begin{minipage}{\textwidth}
\makeatletter\def\Hy@Warning#1{}\makeatother
\footnotetext{$^*$Equal contribution.}
\end{minipage}
\input{sec/intro}
\input{sec/related_work}
\input{sec/method}
\vspace{-1mm}
\input{sec/experiments}
\input{sec/conclusion}
\input{sec/acknowledgements}

{
    \small
    \bibliographystyle{ieeenat_fullname}
    \bibliography{main}
}

\input{sec/appendix}

\end{document}
