\begin{figure*}[t]
\begin{psmall}
Implement a method given a docstring and method signature, using the API specification as necessary.
Current API:
{predef_signatures}
{generated_signatures}
Here are some examples of how to implement a method given its docstring and signature:
<docstring>
\"\"\" Locates objects that are on the left of the reference object.
Args:
    image (IMAGE): Image to search.
    ref_x (int): X coordinate of reference object in pixel space.
    ref_y (int): Y coordinate of reference object in pixel space.
Returns:
    points (list): list of [x, y] coordinates for objects in pixel space matching description to the left.
\"\"\"
</docstring>
<signature>def objects_left(image, ref_x, ref_y):</signature><implementation>
objects_left = []
all_objects = loc(image, object_prompt='objects')
for object_point in all_objects:
    x, y = object_point
    if same_object(image, ref_x, ref_y, x, y):
        continue
    if x < ref_x:
        objects_left.append(object_point)
return objects_left </implementation>
<docstring>
\"\"\" Gets the material of the given object.
Args:
    image (IMAGE): Image that the object is contained in.
    ref_x (int): X coordinate of reference object in pixel space.
    ref_y (int): Y coordinate of reference object in pixel space.
Returns:
    str: Material of the object.
\"\"\"
</docstring>
<signature>def object_material(image, ref_x, ref_y):</signature><implementation>
return vqa(image=image, question='What material is this object?', x=ref_x, y=ref_y) </implementation>
<docstring>
\"\"\" Checks if an object 1 is in front of object 2.
Args:
    image (IMAGE): Image that the object is contained in.
    x_1 (int): X coordinate of object 1 in pixel space.
    y_1 (int): Y coordinate of object 1 in pixel space.
    x_2 (int): X coordinate of object 2 in pixel space.
    y_2 (int): Y coordinate of object 2 in pixel space.
Returns:
    bool: True if object 1 is in front of object 2, False otherwise
\"\"\"
</docstring>
<signature>def in_front_of(image, x_1, y_1, x_2, y_2):</signature> <implementation>
depth_1, depth_2 = depth(image, x_1, y_1), depth(image, x_2, y_2)
return depth_1 < depth_2 </implementation>
<docstring>
\"\"\" Checks if object1 has the same size as object2
Args:
    image (IMAGE): Image that the object is contained in.
    x_1 (int): X coordinate of object 1 in pixel space.
    y_1 (int): Y coordinate of object 1 in pixel space.
    x_2 (int): X coordinate of object 2 in pixel space.
    y_2 (int): Y coordinate of object 2 in pixel space.
    epsilon (float): Acceptable margin of error in sizes.
Returns:
    bool: True if object 1 has the same size as object 2, False otherwise
\"\"\"
</docstring>
<signature>def same_size(image, x_1, y_1, x_2, y_2, epsilon):</signature> <implementation>
object_1_height, object_1_width = get_2D_object_size(image, x_1, y_1)
object_2_height, object_2_width = get_2D_object_size(image, x_2, y_2)
return abs(object_1_height - object_2_height) < epislon and abs(object_1_width - object_2_width) < epsilon </implementation>
<docstring>
\"\"\" Returns a list of objects in the images
Args:
    image (IMAGE): Image to search for objects in
Returns:
    list: List of strings corresponding to all of the objects in the image.
\"\"\"
</docstring>
<signature>def get_object_list(image):</signature> <implementation>
objects = []
object_points = loc(image, object_prompt='objects')
for object_point in object_coords:
    obj_x, obj_y = object_point
    objects.append(vqa(image, "What is this object?", obj_x, obj_y))
return objects </implementation> 
Here are some helpful definitions:
1) 2D distance/size refers to distance/size in pixel space. 2) 3D distance/size refers to distance/size in the real world. 3D size is equal to 2D size times the depth of the object. 3) "On" is defined as the closest object ABOVE another object. Only use this definition for "on". 4) "Next to" is defined as the closest object. 5) Width is the same as length. 6) "Depth" measures distance from the camera in 3D. 
Here are some helpful tips: 
1) When you need to search over objects satisfying a condition, remember to check all the objects that satisfy the condition and don't just return the first one. 2) You already have an initialized variable named "image" - no need to initialize it yourself! 3) When searching for objects to compare to a reference object, make sure to remove the reference object from the retrieved objects. You can check if two objects are the same with the same_object method. 4) Do not assume that the objects you see in these questions are all of the objects you will see, keep the methods general. 5) If two objects have the same 2D width, then the object with the largest depth has the largest 3D width. 6) If two objects have the same 2D height, then the object with the largest depth has the largest 3D height. 7) 2D sizes convey the height and width in IMAGE SPACE. To convert to height and width in 3D space, it needs to be multiplied by the depth! 8) If you are given a reference size, scale your output predicted size accordingly! Do not define new methods here, simply solve the problem using the existing methods. Now, given the following docstring and signature, implement the method, using the API specification as necessary. Output the implementation inside <implementation></implementation>. Again, Output the implementation inside <implementation></implementation>.
<docstring>
{docstring}
</docstring>
<signature>{signature}</signature>
\end{psmall}
\vspace{-3mm}
\caption{\textbf{Implementation Agent Prompt for \ourbench.} The prompt features \emph{Weak ICL} examples illustrating correct usage of the pre-defined modules, as well as \emph{Pseudo ICL} in the form of natural language instructions and definitions.}
\label{fig:implementation_prompt_omni3d}
\end{figure*}