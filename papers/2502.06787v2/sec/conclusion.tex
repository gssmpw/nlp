\section{Limitations \& Future Work}
\label{sec:conclusion}
We introduce \method, an agentic approach that leverages LLM agents to dynamically create and expand a Pythonic API for complex 3D visual reasoning tasks. Our agents autonomously generate and implement functions, which are then utilized by the Program Agent to produce programs. This reuse of functions results in more accurate programs for complex queries.
There is an extensive list of future directions to address current limitations of \method.
\begin{itemize}
\item \method often struggles with queries that require 5 or more inference steps, \eg \emph{“There is a yellow cylinder to the right of the cube that is behind the purple block; is there a brown object in front of it?”}. We provide the programs for these complex cases in the Appendix. Addressing such queries can be improved by leveraging advanced prompting strategies, an active research area that includes methods like CoT~\cite{cot} and prompt chaining~\cite{promptchainer, aichains}.
\item We show that \method attains high program accuracy (\eg, 83.0\% on \clevr) but lower execution accuracy (53.6\%) due to errors from the vision specialists. A potential enhancement would be to enable \method to dynamically choose its vision modules from a pool of available options based on empirical performance. Integrating the selection process with reinforcement learning or self-improvement mechanisms is a promising future direction.
\item \method creates a program based solely on the input query, utilizing the image only during execution. Incorporating the image into the program synthesis process could improve accuracy, potentially improving performance on queries requiring five or more inference steps.
\end{itemize}
% \textbf{We release the benchmark and code for \method to foster future research in this direction.}