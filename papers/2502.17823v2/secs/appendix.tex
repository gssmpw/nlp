\newpage

\appendix

\section{ReFT}
\label{appd:reft}

The figure of ReFT is shown in Figure~\ref{fig:reft}.

\begin{figure}[t]
\centering
  \includegraphics[width=\linewidth]{pics/reft.png}
  \caption{An overall of the framework ReFT. }
  \label{fig:reft}
  \vspace{-0.1in}
\end{figure}

\section{Hyper-parameters}

\subsection{Choosing layers for GRUN}
\label{appd:layer}

We find that when the layers are too close, it is possible to influence the each other's training. For example, when we use the last two layers for GRUN, the unlearning performance of Llama increases to 0.4 for GD. Thus, we use interval layers.

\subsection{The coefficient $c$ for sequential unlearning}
\label{appd:seq_c}

In our experiments, we tune the hyper-parameter $c$ to get the best utility while maintaining the unlearning. This is reasonable since the LLM builder have the target data which can be used to search the best hyper-parameters.

\section{Experimental settings.}
\label{appd:settings}

\subsection{Metrics}
\label{appd:metrics}

For Probability, TOFU uses the normalized likelihood for target and retaining data. For real authors and world facts, we follow their settings use the probability between correct answer and paraphrased answer (wrong answers). Please refer the details to \citet{maini2024tofu}.

\subsection{Other implementation details.}
\label{appd:details}

GRUN is trained for 40 epochs on NPO and IDK. All the learning rates are 1e-5. The time cost is tested on A6000 GPUs.

\section{Additional experiments}
\label{appd:g_output}

\begin{table}[t]
    \centering
    \resizebox{\linewidth}{!}{
    \begin{tabular}{cccccccc}
    \toprule
        \multirow{2}{*}{$L_{\text{G}}$} & \multirow{2}{*}{$L_{\text{u}}$} & \multicolumn{2}{c}{Gate 1 ($l=20$)} & \multicolumn{2}{c}{Gate 2 ($l=25$)} & \multicolumn{2}{c}{Gate 3 ($l=31$)} \\ 
        & & target $\uparrow$ & retain $\downarrow$ & target $\uparrow$ & retain $\downarrow$ & target $\uparrow$ & retain $\downarrow$ \\ \midrule
        \multirow{3}{*}{No} & GD &0.00&0.00& 0.99 & 0.08 & 1.00 & 0.05 \\ 
        & NPO & 1.00 & 1.00 & 1.00 & 1.00 & 1.00 & 1.00 \\ 
        & IDK & 1.00 & 1.00 &0.00&0.00&0.00&0.00\\ \midrule
        \multirow{3}{*}{Yes} & GD& 0.93 & 0.24 & 1.00 & 0.03 & 0.92 & 0.02 \\ 
        & NPO & 0.99 & 0.09 & 1.00 & 0.02 & 1.00 & 0.02 \\ 
        & IDK & 0.99 & 0.09 & 1.00 & 0.02 & 1.00 & 0.01 \\ \bottomrule
    \end{tabular}
    }
    \caption{Outputs of gate functions. $l=20, 25, 31$ represents the last 12th, last 7th and last layer respectively. The arrow $\uparrow$ (or $\downarrow$) means the output is expected to be close to 1 (or 0).}
  \label{tab:gate_output}
\end{table}


To further examine the different behaviors of the gate function with and without $L_{\text{G}}$, we present the gate function outputs for target and retaining data in Table~\ref{tab:gate_output}. 
% \yue{The following looks not well organized. Please list the observations with an index. Also, please refer to the detailed numbers in the table. In addition, if the exceptions are not good but not significant/interesting, we can just ignore them.}
With $L_{\text{G}}$, the gate function behaves as expected—opening for target data while closing for retaining data. Even in the absence of explicit guidance from $L_{\text{G}}$, the gate can still differentiate effectively, as seen in Gate 2 and Gate 3 of GD.  
For IDK, the gate function helps identify the optimal layer for ReFT and adjusts by closing redundant layers.
% \yue{Cannot understand this. Need to refer to some numbers and add more explanations}. 
A special case arises with NPO when $L_{\text{G}}$ is absent: all gates remain open for both target and retaining data. Although this structure appears similar to ReFT-only, it has significantly enhanced unlearning effectiveness compared with ReFT-only. We conjecture that the soft gate influences the optimization process. In the case of ReFT-only, retaining data may compete with target data due to their reversed losses.  
For GRUN without $L_{\text{G}}$, the gate may prioritize forgetting data early in training, as the loss on retaining data has limited room to decrease—having already converged before unlearning. This hypothesis is supported by the observation that, within the first 10 steps, the forgetting loss of GRUN without $L_{\text{G}}$ is lower than that of ReFT-only.
