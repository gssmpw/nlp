\section{Related works}
\label{sec:related_works}

\textbf{LLM unlearning.} Machine unlearning focused on vision models in the early research~\cite{cao2015towards, warnecke2021machine, bourtoule2021machine, kurmanji2024towards, ren2024copyright, li2021online}, but more recently, it has been extended to LLMs~\cite{eldan2023s, yao2023large, shi2024muse, liu2024rethinking}. % TODO
Fine-tuning-based methods represent a key category of unlearning but raise concerns regarding their impact on model utility~\cite{thaker2024position, deeb2024unlearning, doshi2024does, lynch2024eight}. Alternative approaches enable unlearning during inference~\cite{wang2024machine, eldan2023s, ji2024reversing, thaker2024guardrail, liu2024large}. In this work, we focus on fine-tuning methods, as they are widely adopted.

\textbf{Representation Fine-tuning (ReFT).} ReFT \cite{wu2024reft} is a recently proposed parameter-efficient fine-tuning method. Unlike traditional fine-tuning approaches, which primarily adjust model weights, ReFT focuses on fine-tuning representations, leveraging the rich semantic information embedded in the representation space to influence subsequent generation. Building on the linear representation hypothesis~\cite{park2023linear}, which posits that concepts are encoded within linear subspaces of representations, ReFT learns low-rank linear transformations to refine representations. It achieves this by substituting the intermediate representations—i.e., the outputs of specific Transformer layers—at selected layers and tokens.
