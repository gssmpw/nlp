\section{Experiment}
\label{sec:exp}

\begin{table*}[t]
  \centering
  \resizebox{0.99\textwidth}{!}{
  \begin{tabular}{lccccc|cc|cc}
    \toprule
        \multirow{2}{*}{$L_{\text{u}}$} & \multirow{2}{*}{LLM} & \multirow{2}{*}{$p_{\text{tgt}}$} & \multirow{2}{*}{Method} & \multirow{2}{*}{$p_{\text{size}}$} & \multirow{2}{*}{Hours} & \multicolumn{2}{c|}{ROUGE-L Recall} & \multicolumn{2}{c}{Prob.} \\
        & & & & & & \multicolumn{1}{c}{Unlearn{$\downarrow$}}  & \multicolumn{1}{c|}{Utility{\small(Retain/Fact/World)}{$\uparrow$}} & Unlearn{$\downarrow$} & Utility{\small(Retain/Fact/World)}{$\uparrow$} \\ \midrule
        % \multicolumn{9}{c}{\textbf{Llama 3.1}} \\ \midrule
        & \multirow{2}{*}{Llama} & 5\% & \multirow{2}{*}{\makecell{Clean}} & \multirow{2}{*}{N/A} & \multirow{2}{*}{N/A} & 0.991 & \multirow{2}{*}{0.939   {\small(0.992/0.939/0.890)}} & 0.995 & \multirow{2}{*}{0.566  {\small(0.993/0.448/0.485)}} \\ 
        & & 10\% & & & & 0.992 & & 0.995 & \\ \cmidrule(lr){2-10}
        & \multirow{2}{*}{Mistral} & 5\% & \multirow{2}{*}{\makecell{Clean}} & \multirow{2}{*}{N/A} & \multirow{2}{*}{N/A} & 0.990 & \multirow{2}{*}{0.710  {\small(0.994/0.515/0.622)}} & 0.994 & \multirow{2}{*}{0.610  {\small(0.995/0.401/0.433)}} \\ 
        & & 10\% & & & & 0.988 & & 0.990 &  \\ 
        \midrule
        
        \multirow{8}{*}{GD} & \multirow{4}{*}{Llama} & \multirow{2}{*}{5\%} & Vanilla & 100\% & 3.19 & 0.005 & 0.703  {\small(0.493/0.854/0.762)} & 0.000 & 0.605  {\small(0.575/0.622/0.619)} \\
        & ~ & ~ & GRUN & \textbf{0.001\%} & \textbf{0.02} & \textbf{0.002} & \textbf{0.843}  {\small(0.888/0.843/0.798)} & \textbf{0.000} & 0.584  {\small(0.874/0.432/0.446)} \\ 
        & ~ & \multirow{2}{*}{10\%} & Vanilla & 100\% & 6.33 & 0.005 & 0.695  {\small(0.483/0.818/0.785)} & 0.000 & 0.554  {\small(0.654/0.496/0.513)} \\ 
        & ~ & ~ & GRUN & \textbf{0.001\%} & \textbf{0.02} & 0.016 & \textbf{0.832}  {\small(0.906/0.729/0.862)} & 0.006 & \textbf{0.592}  {\small(0.912/0.402/0.462)} \\ \cmidrule(lr){2-10}
        
        & \multirow{4}{*}{Mistral} & \multirow{2}{*}{5\%} & Vanilla & 100\% & 3.01 & 0.004 & 0.568  {\small(0.742/0.360/0.601)} & 0.000 & 0.581  {\small(0.829/0.448/0.466)} \\
        & ~ & ~ & GRUN & \textbf{0.045\%} &\textbf{0.06} & \textbf{0.000} & \textbf{0.660}  {\small(0.956/0.485/0.539)} & \textbf{0.000} & \textbf{0.588}  {\small(0.955/0.417/0.391)} \\ 
        & ~ & \multirow{2}{*}{10\%} & Vanilla & 100\% & 6.07 & 0.001 & 0.396  {\small(0.687/0.099/0.403)} & 0.000 & 0.558  {\small(0.830/0.358/0.485)} \\ 
        & ~ & ~ & GRUN & \textbf{0.045\%} &\textbf{0.18} & \textbf{0.000} & \textbf{0.595}  {\small(0.891/0.390/0.504)} & \textbf{0.000} & 0.545  {\small(0.886/0.354/0.395)} \\ \midrule
        
        \multirow{8}{*}{NPO} & \multirow{4}{*}{Llama} & \multirow{2}{*}{5\%} & Vanilla & 100\% & 3.96 & 0.201 & 0.751  {\small(0.616/0.756/0.883)} & 0.016 & 0.645  {\small(0.766/0.546/0.623)} \\
        & ~ & ~ & GRUN & \textbf{0.001\%} & \textbf{0.19} & \textbf{0.020} & \textbf{0.886}  {\small(0.973/0.857/0.828)} & \textbf{0.000} & 0.634  {\small(0.977/0.447/0.477)} \\
        & ~ & \multirow{2}{*}{10\%} & Vanilla & 100\% & 7.93 & 0.197 & 0.738  {\small(0.551/0.811/0.851)} & 0.025 & 0.599  {\small(0.730/0.465/0.602)} \\ 
        & ~ & ~ & GRUN & \textbf{0.001\%} & \textbf{0.38} & \textbf{0.029} & \textbf{0.862}  {\small(0.928/0.849/0.811)} &\textbf{ 0.000} & \textbf{0.599}  {\small(0.911/0.441/0.446)} \\ \cmidrule(lr){2-10}
        
        & \multirow{4}{*}{Mistral} & \multirow{2}{*}{5\%} & Vanilla & 100\% & 3.50 & 0.163 & 0.530  {\small(0.820/0.256/0.514)} & 0.030 & 0.558  {\small(0.912/0.364/0.399)} \\
        & ~ & ~ & GRUN & \textbf{0.045\%} &\textbf{0.16} & \textbf{0.000} & \textbf{0.675}  {\small(0.984/0.485/0.555)} & \textbf{0.000} & \textbf{0.596}  {\small(0.980/0.394/0.414)} \\
        & ~ & \multirow{2}{*}{10\%} & Vanilla & 100\% & 6.99 & 0.127 & 0.542  {\small(0.842/0.290/0.494)} & 0.024 & 0.567  {\small(0.923/0.360/0.419)} \\ 
        & ~ & ~ & GRUN & \textbf{0.045\%} &\textbf{0.34} & \textbf{0.000} & \textbf{0.637}  {\small(0.893/0.445/0.573)} & \textbf{0.000} & 0.531  {\small(0.890/0.342/0.362)} \\ \midrule
        
        \multirow{8}{*}{IDK} & \multirow{4}{*}{Llama} & \multirow{2}{*}{5\%} & Vanilla & 100\% & 1.65 & 0.023 & 0.672  {\small(0.578/0.627/0.812)} & 0.468 & 0.623  {\small(0.871/0.479/0.520)} \\ 
        & ~ & ~ & GRUN & \textbf{0.001\%} & \textbf{0.08} & \textbf{0.021} & \textbf{0.905}  {\small(0.980/0.882/0.853)} & \textbf{0.261} & \textbf{0.625}  {\small(0.984/0.434/0.458)} \\
        & ~ & \multirow{2}{*}{10\%} & Vanilla & 100\% & 3.33 & 0.023 & 0.547  {\small(0.570/0.353/0.718)} & 0.532 & 0.614  {\small(0.871/0.459/0.512)} \\ 
        & ~ & ~ & GRUN & \textbf{0.001\%} & \textbf{0.18} & \textbf{0.023} & \textbf{0.865}  {\small(0.892/0.879/0.823)} & \textbf{0.291} & 0.605  {\small(0.938/0.435/0.441)} \\ \cmidrule(lr){2-10}
        
        & \multirow{4}{*}{Mistral} & \multirow{2}{*}{5\%} & Vanilla & 100\% & 1.53 & 0.023 & 0.435  {\small(0.785/0.122/0.399)} & 0.533 & 0.574  {\small(0.962/0.366/0.395)} \\ 
        & ~ & ~ & GRUN & \textbf{0.045\%} &\textbf{0.09} & \textbf{0.022} & \textbf{0.683}  {\small(0.975/0.480/0.593)} & {0.570} & \textbf{0.606}  {\small(0.987/0.401/0.430)} \\
        & ~ & \multirow{2}{*}{10\%} & Vanilla & 100\% & 3.07 & 0.023 & 0.489  {\small(0.856/0.145/0.466)} & 0.657 & 0.595  {\small(0.975/0.392/0.417)} \\ 
        & ~ & ~ & GRUN & \textbf{0.045\%} &\textbf{0.20} & {0.040} & \textbf{0.605}  {\small(0.914/0.430/0.469)} & \textbf{0.490} & 0.577  {\small(0.953/0.394/0.386)} \\ \bottomrule
    \end{tabular}
    }
    \caption{Results of TOFU. $p_{\text{tgt}}$ represents the proportion of target data within the entire synthetic dataset. $p_{\text{size}}$ is the percentage of fine-tuned parameters relative to the entire LLM. ``Unlearn'' refers to the unlearning effectiveness, and ``Clean'' refers to the model before unlearning. The {improved} performance is highlighted in \textbf{bold}.}
  \label{tab:tofu}
  \vspace{-0.2in}
\end{table*}

In this section, we first conduct the experiments across different models and {datasets} in Section~\ref{exp:main}. Then we test the performance under different scenarios including sequential unlearning and attacks in Sec.~\ref{exp:seq}, and conduct ablations studies in Section~\ref{exp:abla} and Appendix~\ref{sec:exp}. 
% Next,
% we first introduce the experimental settings.

\subsection{Experimental settings}
\label{sec:settings}

\noindent\textbf{Models, baselines and datasets.} We use Llama 3.1 (8B)~\cite{dubey2024llama} and Mistral v0.1 (7B)~\cite{jiang2023mistral}. We experiment on two datasets TOFU (unlearn fine-tuning knowledge) and WMDP (unlearn pre-training knowledge). Following the original settings~\cite{maini2024tofu}, we use GD, NPO, and IDK as baselines (using both vanilla and LoRA fine-tuning) in TOFU. Following \citet{liwmdp}, we use RMU as the baseline in WMDP.
GD and NPO are GA-based, while IDK and RMU are suppression-based.

\noindent\textbf{Metrics.} For TOFU, we use ROUGE-L Recall and Probability following~\citet{maini2024tofu}. ROUGE-L Recall assesses correctness of the output text, while Probability reflects the likelihood of generating correct responses (Appendix~\ref{appd:metrics} for details). WMDP consists of multi-choice Q\&A, therefore, we use the accuracy as the metric to access whether the model can correctly answer the questions following~\citet{liwmdp}. For all the three metrics, lower scores on target data indicate better erasing, while higher scores on normal data indicates better utility.
Time cost is measured in GPU hours (number of GPUs $\times$ training hours).

\noindent\textbf{Implementation details.} 
For baselines, GD, NPO and IDK follow \citet{fan2024simplicity}, while RMU follows \citet{liwmdp}. For GRUN, adapted NPO, IDK, and RMU are trained for fixed epochs, while GD uses early stop when $L_{\text{f}}$ in Eq.~\eqref{eq:ga} exceeds the threshold. We use linear regression as gate for Llama and 3-layer MLP for Mistral.
Both LoRA and GRUN use rank of 4. All other details are in Appendix~\ref{appd:details}. 

% \yue{[Missing details about GD, NPO, IDK, RMU. Also need to mention whether they are GA-based algorithms or suppression-based.]}

\subsection{Main results}
\label{exp:main}

% From Tab.~\ref{tab:main}, we can see that, for all the three unlearning methods on TOFU dataset, our method can improve it in both unlearning ability and model utility. For example, NPO can only reduce the forget data to around 0.2, but GRUN-NPO can reduce it to almost 0, meanwhile GUN-NPO can keep better model utility.

% In this subsection, we present the results of TOFU and WMDP and compare the time cost of GRUN with vanilla fine-tuning and LoRA. The unlearning assessment consists of two aspects: (1) the extent to which the target data can be removed/unlearned, and (2) the preservation of model utility. To avoid ambiguity, we use the term \textit{unlearning effectiveness} to specifically refer to the extent of target data removal/unlearning \yue{(not utility)}, in all subsequent sections, figures, and tables.

In this subsection, we present the results of TOFU and WMDP and compare the time cost of GRUN with vanilla fine-tuning and LoRA. The unlearning assessment consists of two aspects: (1) the extent to which the target data can be removed/unlearned (\textit{unlearning effectiveness}), and (2) the preservation of model \textit{utility}.

\noindent\textbf{TOFU.} To evaluate on TOFU, we compare unlearning effectiveness, utility, and time cost against three baselines on two LLMs in Table~\ref{tab:tofu}. The LLMs are first fine-tuned on TOFUâ€™s synthetic dataset, after which a portion of the dataset is designated as the target data for unlearning, while the remaining synthetic data serves as the retaining data for utility. Utility is assessed on {three sets of data}: retained data, Q\&A about real authors, and Q\&A about world facts, with the overall utility being their average. From Table~\ref{tab:tofu}, our method consistently outperforms the baselines of vanilla fine-tuning. 

Specifically, for \textit{GD}, GRUN has similar unlearning effectiveness as the vanilla baseline,
while significantly improving the utility, particularly in ROUGE-L Recall, where it achieves an increase of around 20\% for both Llama 3.1 and Mistral v0.1.
% \yue{[can echo some materials from previous sections, e.g., why their performance has issue, and why our method is better.]}. 

For \textit{NPO}, our method substantially enhances its unlearning effectiveness while also achieving even higher utility. For example, on Llama, our approach reduces NPOâ€™s ROUGE-L Recall on the target data from approximately 0.2 to 0.02 while increasing utility by around 17.5\%. 

As for \textit{IDK}, which is suppression-based, its vanilla version has a more severe impact on the utility of author-related Q\&A (both synthetic and real) than GA-based methods. However, our method significantly improves utility performance, increasing ROUGE-L Recall by more than 25\% in most cases. 

From Table~\ref{tab:tofu}, we also observe that GRUN is more efficient, requiring fewer parameters and lower training costs. We defer the discussion to following Table~\ref{tab:LoRA} for LoRA experiments.

\begin{table}[t]
    \centering
    \resizebox{\linewidth}{!}{
    \begin{tabular}{cccccc}
    \toprule
        RMU & \multicolumn{2}{c}{Llama 3.1} & \multicolumn{2}{c}{Mistral v0.1}  \\
         & Bio/Cyber$\downarrow$ & MMLU$\uparrow$ & Bio/Cyber$\downarrow$ & MMLU$\uparrow$ \\ \midrule
        Before & 0.696/0.418 & 0.611 & 0.668/0.437 & 0.581 \\
        Vanilla & 0.494/0.337 & 0.581 & \textbf{0.256}/\textbf{0.252} & 0.529 \\
        GRUN & \textbf{0.372}/\textbf{0.293} & 0.577 & 0.293/0.278 & 0.535 \\ \bottomrule
    \end{tabular}
    }
    \vspace{-0.1in}
    \caption{Unlearning results on WMDP}
    \vspace{-0.25in}
  \label{tab:wmdp}
\end{table}

\noindent\textbf{WMDP.} Table~\ref{tab:wmdp} presents the results of removing pre-training knowledge in WMDP. WMDP evaluates unlearning by erasing harmful biological and cyber knowledge while assessing utility using the benign Q\&A dataset {MMLU~\cite{hendrycks2020measuring}}. WMDP uses a 4-choice Q\&A to measure the knowledge. We adjust the unlearning strength to maintain similar utility between vanilla RMU and GRUN, and only compare the unlearning effectiveness. In Table~\ref{tab:wmdp}, our approach significantly improves performance on Llama 3.1 and maintains a random-guessing accuracy on Mistral v0.1.

\begin{table}[t]
    \centering
    \resizebox{\linewidth}{!}{
    \begin{tabular}{ccccccccc}
    \toprule
        & & & \multirow{2}{*}{$p_{\text{size}}$} & \multirow{2}{*}{Hours} & \multicolumn{2}{c}{ROUGE-L} & \multicolumn{2}{c}{Prob.} \\  
 & & & & unlearn & utility & unlearn & utility \\ \midrule
        % \multicolumn{8}{c}{\textbf{Llama 3.1}} \\ \midrule
        \multirow{6}{*}{Llama 3.1} & \multirow{2}{*}{GD} & LoRA & 0.130\% & 1.27 & 0.375 & 0.623 & 0.059 & 0.067 \\ 
        & ~ & GRUN & \textbf{0.001\%} & \textbf{0.02} & \textbf{0.000} & \textbf{0.840} & \textbf{0.000} & \textbf{0.582} \\ 
        & \multirow{2}{*}{NPO} & LoRA & 0.130\% & 0.77 & 0.255 & 0.886 & 0.103 & 0.315 \\ 
        & ~ & GRUN & \textbf{0.001\%} & \textbf{0.08} & \textbf{0.020} & \textbf{0.896} & \textbf{0.000} & \textbf{0.634} \\
        & \multirow{2}{*}{IDK} & LoRA & 0.130\% & 1.33 & 0.054 & 0.782 & 0.849 & 0.346 \\ 
        & ~ & GRUN & \textbf{0.001\%} & \textbf{0.19} & \textbf{0.021} & \textbf{0.915} & \textbf{0.262} & \textbf{0.625} \\
        % \multicolumn{8}{c}{\textbf{Mistral v0.1}} \\ \midrule
        % \multirow{6}{*}{Mistral v0.1} & \multirow{2}{*}{GD} & LoRA & 0.145\% & 0.50 & 0.302 & 0.122 & 0.122 & 0.121 \\ 
        % & ~ & GRUN & \textbf{0.045\%} & \textbf{0.06} & \textbf{0.000} & \textbf{0.660} & \textbf{0.000} & \textbf{0.588} \\ 
        % & \multirow{2}{*}{NPO} & LoRA & 0.145\% & 0.80 & 0.293 & 0.119 & 0.119 & 0.328 \\ 
        % & ~ & GRUN & \textbf{0.045\%} & \textbf{0.09} & \textbf{0.000} & \textbf{0.675} & \textbf{0.000} & \textbf{0.596} \\
        % & \multirow{2}{*}{IDK} & LoRA & 0.145\% & 1.20 & 0.073 & 0.871 & 0.871 & 0.363 \\ 
        % & ~ & GRUN & \textbf{0.045\%} & \textbf{0.16} & \textbf{0.022} & \textbf{0.570} & \textbf{0.570} & \textbf{0.606} \\ 
        \bottomrule
    \end{tabular}
    }
    \vspace{-0.1in}
    \caption{Comparison with LoRA}
  \label{tab:LoRA}
  \vspace{-0.25in}
\end{table}

\noindent\textbf{LoRA.} We compare GRUN with LoRA to further demonstrate its superiority in efficiency. As shown in Table~\ref{tab:LoRA}, our method requires fewer parameters while achieving better performance across all unlearning and utility metrics, regardless of the model or fine-tuning loss. Additionally, GRUN reduces training time by 95\% compared to vanilla training (Table~\ref{tab:tofu}) and by 85\% compared to LoRA. This efficiency gain is attributed to two key factors:
\begin{itemize}
    \item \textit{Fewer parameters to update.} GRUN updates less than 0.05\% (even 0.001\% for Llama) of the parameters compared to the full LLM.
    \item \textit{A significantly shorter gradient backpropagation path.} GRUN is applied only to the last few layers, eliminating the computational cost of backpropagating gradients through the earlier layers. (LoRA updates fewer parameters, but has to backpropagate the entire network.)
\end{itemize}

\subsection{Different unlearning scenarios}
\label{exp:seq}

\begin{figure}[t]
    \centering
    \begin{subfigure}[b]{0.499\linewidth}
        \centering
        \includegraphics[width=\textwidth]{pics/seq_forget.png}
        \vspace{-0.25in}
        \caption{Unlearning effectiveness}
        \label{fig:seq_forget}
    \end{subfigure}\hfill
    \begin{subfigure}[b]{0.499\linewidth}
        \centering
        \includegraphics[width=\textwidth]{pics/seq_utility.png}
        \vspace{-0.25in}
        \caption{Model utility}
        \label{fig:seq_utility}
    \end{subfigure}
    \vspace{-0.25in}
    \caption{Sequential unlearning}
    \label{fig:seq}
    % \vspace{-0.25in}
\end{figure}

\begin{table}[t]
    \centering
    \resizebox{0.9\linewidth}{!}{
    \begin{tabular}{lcccc}
    \toprule
        \multirow{2}{*}{Effectiveness} & \multicolumn{2}{c}{Paraphrase} & \multicolumn{2}{c}{Quantization} \\
        ~ & Llama & Mistral & Llama & Mistral \\ \midrule
        GD (GRUN) & 0.006 & 0.005 & 0.002 & 0.000 \\
        NPO (GRUN) & 0.019 & 0.000 & 0.021 & 0.000 \\
        IDK (GRUN) & 0.044 & 0.040 & 0.038 & 0.034 \\ \bottomrule
    \end{tabular}
    }
    \caption{Unlearning effectiveness under attacks}
  \label{tab:robust}
\end{table}

In this subsection, we evaluate GRUNâ€™s performance under sequential unlearning and assess its robustness against two attacksâ€”prompt paraphrasing and model quantizationâ€”to validate its effectiveness across various unlearning scenarios.

\noindent\textbf{Sequential unlearning.} In Figure~\ref{fig:seq}, {we first fine-tune the models with all the synthetic data of TOFU, and then simulate sequential unlearning by issuing six unlearning requests, each targeting a different forget set containing 5\% synthetic data.} As shown in Figure\ref{fig:seq_forget}, the unlearning effectiveness remains consistent across both baselines and our method. However, in Figure~\ref{fig:seq_utility}, our approach significantly outperforms the baselines in utility when multiple requests are processed.

\noindent\textbf{Robustness.} In Table.~\ref{tab:robust}, we evaluate the robustness of GRUN by attacking the unlearned model to recover the removed knowledge through prompt paraphrasing and model quantization. We use GPT-4 to paraphrase the questions to bypass GRUNâ€™s distinguishing mechanism. Our method remains stable, preserving the original unlearning effectiveness. \citet{zhang2024catastrophic} reports that quantization may negate unlearning; however, our approach effectively recognizes and removes quantized representations with no loss in effectiveness.

\subsection{Ablation study}
\label{exp:abla}

\begin{figure}[t]
    \centering
    \begin{subfigure}[b]{0.499\linewidth}
        \centering
        \includegraphics[width=\textwidth]{pics/no_gate_forget.png}
        \vspace{-0.35in}
        \caption{Unlearning effectiveness}
        \label{fig:llama_gd}
    \end{subfigure}\hfill
    \begin{subfigure}[b]{0.499\linewidth}
        \centering
        \includegraphics[width=\textwidth]{pics/no_gate_utility.png}
        \vspace{-0.35in}
        \caption{Model utility}
        \label{fig:llama_npo}
    \end{subfigure}
    \caption{Contributions of each components}
    \vspace{-0.05in}
    \label{fig:abl_component}
\end{figure}

In this subsection, we conduct ablation studies to analyze the effects of each component of GRUN, i.e., ReFT, the soft gate, and the gate loss ($L_{\text{G}}$).

We compare vanilla fine-tuning along with three variants of GRUN to evaluate the contribution of each component: (1) ReFT-only (without the gate or $L_{\text{G}}$), (2) GRUN without $L_{\text{G}}$ (maintaining the same structure as GRUN but trained solely with $L_{\text{u}}$), and (3) the complete GRUN. 

\textit{ReFT-only.} In Figure \ref{fig:abl_component}, switching from vanilla fine-tuning to ReFT-only increases utility but reduces unlearning effectiveness. This suggests that ReFT enhances utility by freezing model parameters as expected but has limited capability in distinguishing target data due to its simple structure.

\textit{GRUN without} $L_{\text{G}}$. Adding the gate function (without $L_{\text{G}}$), improves unlearning effectiveness, particularly for NPO. This indicates that even in the absence of $L_{\text{G}}$, the gate function can automatically aid in distinguishing target data during optimization. (More empirical analysis in Appendix~\ref{appd:g_output}.)

\textit{The complete GRUN}. The complete GRUN model further enhances both unlearning effectiveness and utility. This demonstrates that explicitly guiding GRUN with $L_{\text{G}}$ fundamentally strengthens fine-tuning-based methods.


\section{Conclusions}

Unlearning aims to remove copyrighted and privacy-sensitive data from LLMs, but often degrades model utility. We propose GRUN, a general framework to enhances fine-tuning-based unlearning. GRUN leverages the shared mechanism between GA-based and suppression-based methods. It uses a soft gate function for distinguishing and a ReFT-based suppression module to adjust representations. GRUN improves both unlearning effectiveness and utility, and enables efficient unlearning.


