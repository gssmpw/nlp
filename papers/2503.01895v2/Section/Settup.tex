% \vspace{-1mm}
\section{\method: A Suite of Evaluating Reasoning Strategies for Zero-Shot TSF }
\method consists of four core modules: Datasets, Reasoning Strategies, Models, and Evaluations. We introduce these modules one by one in this section. More details are provided in Section~???\ref{sec:detail_bench}.
\subsection{Dataset module} The dataset module includes datasets from eight different domains, all containing both numerical time series and aligned textual context series, providing unified data support for downstream time series forecasting. As detailed in Table~\ref{tab:series}, these verified datasets~\cite{liu2025time,lin2024decoding} cover key domains such as Agriculture, Climate, Economy, Energy, Health, Security, Employment, and Traffic, with weekly and monthly frequencies. The textual context series consists of keyword-based web summaries, aligned by date with the numerical series. As shown in Figure~\ref{fig:OT_visualize}, these datasets exhibit diverse characteristics, enabling comprehensive evaluation. 
\subsection{Reasoning Strategies Module} As shown in Figure~\ref{fig:reason_strategy}, \method systematically includes three mainstream approaches for reasoning, following existing works \cite{pan2023automatically,plaat2024reasoning,xu2025towards}: (1) Direct System 1 Reasoning – directly using generative models such as GPT-4o for reasoning. (2) Test-Time-Enhanced System 1 Reasoning – incorporating techniques such as Chain-of-Thought \cite{wei2022chain}, Self-Consistency \cite{wang2022self}, and Self-Correction \cite{madaan2023self}. These approaches improve reasoning beyond System 1’s intuitive responses by performing additional computations during inference without modifying the model’s pre-trained weights. (3) Post-Training-Enabled System 2 Reasoning – such as DeepSeek-R1 \cite{guo2025deepseek}. Unlike test-time-enhanced System 1, System 2 reasoning is typically achieved through reinforcement learning and reasoning data during the post-training phase. System 2 has built-in reasoning capabilities, which are typically characterized by automatic long-chain thinking.

Specifically, Chain-of-Thought (CoT) prompts the model to break down complex problems into a series of logical steps before providing a final answer, mimicking human reasoning processes. The Self-Consistency method further enhances reasoning diversity by generating multiple reasoning paths in parallel and selecting the most consistent result. In contrast, the Self-Correction approach iteratively refines the model’s output through feedback, aiming to improve overall accuracy and reliability. For the System 2 strategies, also known as large reasoning models \cite{xu2025towards}, \method includes the closed-source o1-mini from OpenAI\footnote{\url{https://openai.com/index/openai-o1-mini-advancing-cost-efficient-reasoning/}} and Gemini-2.0-flash-thinking from Google\footnote{\url{https://cloud.google.com/vertex-ai/generative-ai/docs/thinking}}, as well as the open-source DeepSeek-R1 from DeepSeek. Compared to o1-Mini, which employs Proximal Policy Optimization (PPO) \cite{schulman2017proximal} by training two models simultaneously—a policy model for generating responses and a critic model for evaluating them—DeepSeek-R1 adopts Group Relative Policy Optimization (GRPO) \cite{shao2024deepseekmath}, which eliminates the need for a separate critic model by ranking multiple responses at once.
\subsection{Models Module} 

\method covers three series of foundational models, including both closed- and open-source models. Each series provides System 1 and System 2 versions. \uline{Note that since reasoning strategies for foundational time-series models have not yet been studied and are difficult to implement directly, reusing foundational language models for zero-shot TSF—which have been widely validated by existing works—is currently the best choice}~\cite{xue2023promptcast,gruver2023large,liu2024lstprompt,jintime,caotempo}.

Specifically, \method includes OpenAI's GPT-4o and o1-mini, Google's Gemini-2.0-Flash and Gemini-2.0-Flash-Thinking, and DeepSeek's DeepSeek-V3 and DeepSeek-R1 as the corresponding System 1 and System 2 pairs, respectively. Inspired by recent research~\cite{wang2024tabletime,hoo2025tabular,hu2025contextalignment}, we reformulate numerical time series into a tabular format, i.e., "timestamp : numerical value", to enable LLMs as powerful time-series analysts.
\subsection{Evaluation Module}
We comprehensively consider the following four common settings: unimodal short-term, unimodal long-term, multi-modal short-term, and multi-modal long-term. In multi-modal TSF, both numerical series and aligned textual context series are used as inputs, whereas unimodal TSF uses only numerical series. The forecasting period for long-term TSF is the next six months whereas the short-term TSF is the next three months. We follow most existing TSF works~\cite{wu2021autoformer,wutimesnet,nietime} by setting the lookback window length to 96 by default. 
We use Mean Squared Error (MSE) as the evaluation metric. To avoid data contamination—meaning the evaluation dataset may have been seen during the foundation model's pretraining—we use horizon windows after October 2023, which is the knowledge cutoff date of selected foundation models.






