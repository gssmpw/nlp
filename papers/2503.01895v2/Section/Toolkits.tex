\section{Open-Source Toolkits: Evaluation Suite, Test-Time Scaling Law, and Datasets}
We provide three key open-source toolkits to support future research on foundational TSF reasoning models. Specifically, these include our \method as an easy-to-use evaluation suite with experiment logs, a newly verified test-time scaling law on foundation time-series models for zero-shot TSF, and the first TSF dataset with reasoning annotations distilled from six advanced foundation models, named \data. All resources are publicly accessible at: \url{https://github.com/AdityaLab/OpenTimeR}
% \subsection{Released Evaluation Suite}
\vspace{0.1in}
\par\noindent\textbf{Released Evaluation Suite.}
We fully release \method as an easy-to-use evaluation suite to facilitate future research, including the code, documents, and experiment logs. The released code supports batch experiments, unified selection of reasoning strategy with LLMs, and automated saving and extraction of experimental results. We provide the hyperparameters and model outputs of about 1500 experiments in our benchmarking.
\vspace{0.05in}

% \subsection{Test-Time Scaling Law Verification}
\begin{figure}[t]
    \centering
    % \vspace{-0.05in}
    \includegraphics[width=0.5\textwidth]{picture/chronos_exp.jpg} \\
    \includegraphics[width=0.5\textwidth]{picture/moirai_exp.jpg}
    \caption{Verified test-time scaling law on foundation time-series models inspired by our insights. MSE and MAE are normalized based on the performance of one sampled path. The performance of Chronos and Moirai continuously improves as the number of sampled reasoning paths in the self-consistency reasoning strategy increases.}
    \label{fig:mse-exp}
\end{figure}

\par\noindent\textbf{Test-Time Scaling Law Verification.} We further generalize our empirical insights to foundation time-series models. Since the implementation of the GRPO-empowered reasoning model remains in the exploratory stage, we only focus on the self-consistency reasoning strategy. Specifically, we treat the sampling number of probabilistic foundation time-series models, including Moirai~\cite{woo2024unifiedtraininguniversaltime} and Chronos~\cite{ansari2024chronos}, as the number of sampled reasoning paths in self-consistency, and we use the median as the most consistent reasoning path. We use multiple well-adopted unimodal time-series datasets~\cite{wutimesnet}, and more experimental settings are detailed in Section~\ref{sec:SCALE}. As shown in Figure~\ref{fig:mse-exp}, we clearly demonstrate a new and simple test-time scaling law for TSF. We observe that with an increase in the number of sampled reasoning paths at test time, the performance of both foundation TSF models improves consistently and significantly, reducing the MSE error by at least 20\% and up to 50\%. We also observe that the model performance gradually converges at about 32 sampled reasoning paths. Our verified scaling law provides promising evidence and improvement room for reasoning-empowered TSF.

\vspace{0.05in}

% \subsection{Reasoning-Annotated TSF Datasets}
\par\noindent\textbf{Reasoning-Annotated TSF Datasets}
Inspired by recent research in post-training large reasoning models~\cite{zhou2023lima,wang2024deep,muennighoff2025s1}, we realized that another obstacle for foundation TSF reasoning models research, aside from evaluation suites and scaling laws, is the lack of a reasoning-annotated dataset. To this end, we curate the first reasoning-annotated TSF dataset, named \data, which pairs TSF task queries and answers with reasoning traces. Specifically, we adopt six advanced and diverse foundation models, including GPT-4o, o1-mini, Gemini-2.0-flash, Gemini-2.0-flash-thinking, DeepSeek-V3, and DeepSeek-R1, and record both the visible final output and the intermediate reasoning chain (if available) for TSF tasks. We set an appropriate temperature for each model and repeat the sampling, covering all datasets and settings in \method.  
We present more details and demos with reasoning trajectories in Appendix~\ref{data_detail}.
