% \vspace{-0.05in}
\section{Introduction}\label{sec:intro}

Reasoning capabilities are fundamental to solving challenging tasks and have been the focus of research for decades~\cite{gebhardt1997reasoning, wustenberg2012complex}. Recent advancements in foundation models, particularly the rise of large language models (LLMs), have brought reasoning strategy research into the era of artificial intelligence~\cite{wei2022chain, wang2022self, pan2023automatically}. By integrating designed reasoning strategies with powerful foundation models, these models have demonstrated remarkable success in tackling complex real-world challenges, including math, planning, and engineering~\cite{bai2023qwen, song2023llm, sun2023adaplanner, jin2024llms}. Despite these advancements in extensive domains, the application of reasoning strategies in zero-shot time-series forecasting (TSF) remains largely unexplored. While recent time-series foundation models have initially demonstrated the feasibility of zero-shot TSF~\cite{das2024decoder, goswami2024moment, ansari2024chronos, shi2024time}, they primarily rely on the memory of large-scale time series data from the pre-training phase rather than employing explicit reasoning for zero-shot TSF.

However, reasoning is not only natural but also essential for zero-shot TSF. On the one hand, time-series data inherently contains rich causal relationships, making it a natural domain for reasoning-based approaches~\cite{moraffah2021causal, runge2023causal}. For instance, in epidemiological forecasting, the outbreak of a pandemic naturally reasons a subsequent increase in infections—an essential target for flu prediction~\cite{mathis2024evaluation}. On the other hand, and more critically, reasoning plays an important role in zero-shot TSF. Unlike conventional supervised TSF, which ``memorizes'' underlying correlation structures from training data, zero-shot TSF—designed as the primary objective for most time-series foundation models—depends on reasoning capabilities to ``interpret'' the pattern correlations within limited historical data, which have never been ``memorized,'' in order to infer future values. Nevertheless, existing time-series foundation models have yet to fully exploit them by incorporating effective reasoning strategies. 



Therefore, a natural twofold research question (RQ) for reasoning strategies on zero-shot TSF arises: \textbf{``RQ1: Can zero-shot TSF benefit from enhanced reasoning ability?''} While reasoning is an integral part of time-series analysis, such as used in feature selection and statistical analysis~\cite{sun2015using, chen2004analyzing}, its effectiveness has yet to be systematically validated in zero-shot TSF with foundation models. Furthermore, if reasoning is indeed beneficial (as demonstrated later in our work), a subsequent question emerges: \textbf{``RQ2: What kind of reasoning strategies does zero-shot TSF need?''}  

Existing reasoning strategies are often categorized into two cognitive systems: Reasoning enhanced System 1, which enables fast and direct thinking, and System 2, which involves deep and analytical reasoning~\cite{kahneman2011thinking} built-in the foundation model. These two approaches differ distinctly in their implementation. Reasoning enhanced System 1 typically occurs during the inference stage, such as Chain-of-Thought (CoT) reasoning, possibly being further enhanced through self-consistency and self-correction~\cite{wei2022chain, wang2022self, pan2023automatically, kumar2024training}. In contrast, System 2 reasoning asks the model itself to promote deeper, structured thinking by incorporating incentives and rewards during post-training~\cite{ouyang2022training, guo2025deepseek}. Given the fundamental differences between System 1 and System 2 reasoning strategies in foundation models, addressing \textbf{RQ2} requires an in-depth investigation into their effectiveness for time-series forecasting. However, such studies remain unexplored, and a systematic benchmark to assess the impact of different reasoning strategies in TSF is still lacking. 

To bridge this gap and address the proposed twofold research questions, we introduce \method, a benchmark designed to systematically evaluate the effectiveness of various popular reasoning strategies in zero-shot TSF. To the best of our knowledge, this is the first benchmark study to investigate these questions. Our main contributions are summarized as follows:  
\begin{itemize}
    \item \textbf{New Research Direction:} We introduce a novel research direction focused on reasoning strategies for zero-shot TSF.  This research aims to understand when, what, and how reasoning strategies impact zero-shot TSF tasks.  
    \item \textbf{Comprehensive Benchmark:} We systematically evaluate the effectiveness of existing reasoning strategies for zero-shot TSF, conducting about 1,500 experiments. Our analysis covers both reasoning-enhanced System 1 and System 2 reasoning strategies across six foundation models.  
    \item \textbf{In-depth Insights:}  Our benchmark provides in-depth insights, revealing that self-consistency is the current most effective reasoning-enhanced System 1 strategy, and group-relative policy optimization is the current most suitable System 2 approach. Furthermore, we show that reasoning strategies are generally more effective in multimodal zero-shot TSF than unimodal zero-shot TSF. 
     \item \textbf{Open-Source Toolkits:} We release three key toolkits, including the evaluation suite, scaling law and reasoning data to comprehensively initiate future research on reasoning models for TSF. Specifically, we fully release \method as an easy-to-use evaluation suite, including the code, documents and experiment logs. we validate a new and simple test-time scaling law for zero-shot TSF with foundation time-series models enabled by self-consistency reasoning. Additionally, we introduce \data, the first TSF dataset with reasoning trajectories. 
\end{itemize}


