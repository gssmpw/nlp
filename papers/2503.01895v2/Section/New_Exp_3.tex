\begin{table*}[t] 
    \centering
    \caption{Results with DeepSeek's System 1 (DeepSeek-V3) and 2 (DeepSeek-R1) Models. We report the mean MSE and standard deviation over three repeated experiments. Reasoning strategies that outperform the direct System 1 are highlighted in \better{green}, while those that perform worse or have similar performance (due to higher computational cost) are marked in \worse{red}. In "Win System 1," we present the probability of each reasoning strategy outperforming System 1 across datasets. We observe that \better{the self-consistency still consistently works}. We find that \better{\uline{DeepSeek-R1 is the only System 2 model that is effective}} for TSF, which we attribute to its Group Relative Policy Optimization approach aligning well with the TSF task.}
    \vspace{-3mm}
\begin{subtable}{\textwidth}
\centering
\caption{Results of Unimodal Short-term TSF Settings. We use numerical series only to forecast the next three months.}
\begin{tabular}{c|c|ccc|c} 
\hline
\multirow{2}{*}{Dataset}           & System 1    & \multicolumn{3}{c|}{~System 1 with~Test-time Reasoning Enhancement} & System~~~~ 2  \\ 
\cline{2-6}
                                   & DeepSeek-V3      & with CoT     & with Self-Consistency & with Self-Correction  & DeepSeek-R1       \\ 
\hline
 Agriculture & 0.038$\pm$0.032 & \better{0.019$\pm$0.001} & \worse{0.046$\pm$0.015} & \better{0.013$\pm$0.003} & \better{0.016$\pm$0.010} \\
 Climate & 1.216$\pm$0.202 & \worse{2.650$\pm$0.905} & \better{1.207$\pm$0.197} & \worse{1.246$\pm$0.081} & \worse{1.541$\pm$0.397} \\
 Economy & 0.406$\pm$0.218 & \worse{0.433$\pm$0.031} & \better{0.284$\pm$0.227} & \worse{0.441$\pm$0.161} & \worse{0.583$\pm$0.001} \\
 Energy & 0.736$\pm$0.752 & \better{0.212$\pm$0.022} & \better{0.187$\pm$0.011} & \better{0.182$\pm$0.063} & \better{0.189$\pm$0.021} \\
 Flu & 1.464$\pm$1.031 & \worse{1.650$\pm$0.236} & \better{0.980$\pm$0.445} & \worse{1.682$\pm$0.292} & \better{1.298$\pm$1.330} \\
 Security & 0.283$\pm$0.140 & \better{0.218$\pm$0.093} & \better{0.185$\pm$0.052} & \better{0.116$\pm$0.012} & \better{0.247$\pm$0.017} \\
 Employment & 0.036$\pm$0.019 & \better{0.020$\pm$0.006} & \better{0.035$\pm$0.019} & \better{0.018$\pm$0.007} & \better{0.012$\pm$0.005} \\
Traffic & 0.066±0.031 & \worse{0.201±0.001} & \worse{0.109±0.028} & \worse{0.107±0.067} & \worse{0.113±0.073} \\
\hline
Win System 1 & NA & \worse{4/8} & \better{6/8} & \worse{4/8} & \better{5/8}\\
\hline
\end{tabular}
\end{subtable}

\begin{subtable}{\textwidth}
\centering
\caption{Results of Multimodal Short-term TSF Settings. We use numerical series with textual context series to forecast the next three months.}
\begin{tabular}{c|c|ccc|c} 
\hline
\multirow{2}{*}{Dataset}           & System 1    & \multicolumn{3}{c|}{~System 1 with~Test-time Reasoning Enhancement} & System~~~~ 2  \\ 
\cline{2-6}
                                   & DeepSeek-V3      & with CoT     & with Self-Consistency & with Self-Correction  & DeepSeek-R1       \\ 
\hline
 Agriculture & 0.032$\pm$0.012 & \better{0.027$\pm$0.006} & \better{0.023$\pm$0.001} & \worse{0.042$\pm$0.025} & \worse{2.712$\pm$0.001} \\
 Climate & 1.428$\pm$0.432 & \worse{1.857$\pm$0.431} & \better{1.371$\pm$0.001} & \better{1.411$\pm$0.258} & \worse{2.235$\pm$0.850} \\
 Economy & 0.427$\pm$0.174 & \worse{0.598$\pm$0.069} & \better{0.306$\pm$0.005} & \better{0.369$\pm$0.128} & \worse{0.615$\pm$0.101} \\
 Energy & 0.253$\pm$0.089 & \worse{0.486$\pm$0.318} & \better{0.197$\pm$0.001} & \worse{0.505$\pm$0.339} & \worse{0.731$\pm$0.777} \\
 Flu & 1.073$\pm$0.447 & \worse{1.564$\pm$0.982} & \better{0.362$\pm$0.161} & \better{0.441$\pm$0.173} & \worse{1.329$\pm$1.306} \\
 Security & 0.186$\pm$0.001 & \worse{0.206$\pm$0.010} & \worse{0.187$\pm$0.001} & \better{0.130$\pm$0.018} & \better{0.161$\pm$0.051} \\
 Employment & 0.016$\pm$0.001 & \worse{0.022$\pm$0.003} & \worse{0.016$\pm$0.001} & \worse{0.016$\pm$0.001} & \worse{0.114$\pm$0.139} \\
Traffic & 0.201$\pm$0.001 & \worse{0.201$\pm$0.001} & \worse{0.201$\pm$0.001} & \better{0.114$\pm$0.063} & \better{0.153$\pm$0.069} \\
\hline
Win System 1 & NA & $\worse{1/8}$ & $\better{5/8}$ & $\better{5/8}$ & $\worse{2/8}$ \\
\hline
\end{tabular}
\end{subtable}

\begin{subtable}{\textwidth}
\centering
\caption{Results of Unimodal Long-term TSF Settings. We use numerical series only to forecast the next six months.}
\begin{tabular}{c|c|ccc|c} 
\hline
\multirow{2}{*}{Dataset}           & System 1    & \multicolumn{3}{c|}{~System 1 with~Test-time Reasoning Enhancement} & System~~~~ 2  \\ 
\cline{2-6}
                                   & DeepSeek-V3      & with CoT     & with Self-Consistency & with Self-Correction  & DeepSeek-R1       \\ 
\hline
 Agriculture & 0.216$\pm$0.049 & \better{0.102$\pm$0.034} & \better{0.103$\pm$0.014} & \better{0.121$\pm$0.065} & \better{0.091$\pm$0.019} \\
 Climate & 0.902$\pm$0.001 & \worse{1.383$\pm$0.227} & \better{0.786$\pm$0.153} & \worse{0.913$\pm$0.078} & \better{0.662$\pm$0.051} \\
 Economy & 0.613$\pm$0.776 & \better{0.540$\pm$0.386} & \better{0.393$\pm$0.113} & \worse{0.948$\pm$0.589} & \better{0.359$\pm$0.001} \\
 Energy & 0.603$\pm$0.359 & \better{0.575$\pm$0.452} & \worse{0.923$\pm$0.265} & \better{0.332$\pm$0.150} & \worse{1.396$\pm$0.001} \\
 Flu & 0.841$\pm$0.215 & \better{0.658$\pm$0.227} & \better{0.538$\pm$0.021} & \worse{0.939$\pm$0.328} & \worse{0.972$\pm$0.533} \\
 Security & 0.275$\pm$0.060 & \better{0.245$\pm$0.039} & \worse{0.280$\pm$0.004} & \better{0.186$\pm$0.033} & \better{0.168$\pm$0.028} \\
 Employment & 0.051$\pm$0.013 & \better{0.021$\pm$0.002} & \better{0.039$\pm$0.006} & \better{0.023$\pm$0.003} & \better{0.021$\pm$0.001} \\
Traffic & 0.414$\pm$0.001 & \better{0.209$\pm$0.145} & \worse{94.305$\pm$66.620} & \better{0.306$\pm$0.153} & \better{0.158$\pm$0.181} \\
\hline
Win System 1 & NA & \better{7/8} & \better{5/8} & \better{5/8} & \better{6/8} \\
\hline
\end{tabular}
\end{subtable}

\begin{subtable}{\textwidth}
\centering
\caption{Results of Multimodal Long-term TSF Settings. We use numerical series with textual context series to forecast the next six months.}
\begin{tabular}{c|c|ccc|c} 
\hline
\multirow{2}{*}{Dataset}           & System 1    & \multicolumn{3}{c|}{~System 1 with~Test-time Reasoning Enhancement} & System~~~~ 2  \\ 
\cline{2-6}
                                   & DeepSeek-V3      & with CoT     & with Self-Consistency & with Self-Correction  & DeepSeek-R1       \\ 
\hline
 Agriculture & 0.088$\pm$0.058 & \better{0.063$\pm$0.022} & \worse{0.136$\pm$0.080} & \worse{0.119$\pm$0.078} & \better{0.019$\pm$0.010} \\
 Climate & 0.897$\pm$0.001 & \worse{2.193$\pm$0.330} & \worse{0.897$\pm$0.001} & \worse{0.939$\pm$0.074} & \worse{1.849$\pm$0.570} \\
 Economy & 0.629$\pm$0.147 & \better{0.558$\pm$0.282} & \better{0.486$\pm$0.074} & \better{0.623$\pm$0.218} & \worse{0.806$\pm$0.354} \\
 Energy & 0.995$\pm$0.139 & \worse{1.286$\pm$0.568} & \better{0.809$\pm$0.241} & \better{0.493$\pm$0.112} & \better{0.746$\pm$0.459} \\
 Flu & 2.624$\pm$2.400 & \better{0.974$\pm$0.446} & \better{0.644$\pm$0.488} & \better{1.135$\pm$0.643} & \better{1.560$\pm$0.957} \\
 Security & 0.179$\pm$0.002 & \worse{0.250$\pm$0.024} & \better{0.156$\pm$0.027} & \worse{0.274$\pm$0.071} & \better{0.134$\pm$0.055} \\
 Employment & 0.034$\pm$0.001 & \better{0.029$\pm$0.008} & \worse{0.034$\pm$0.001} & \better{0.030$\pm$0.005} & \worse{0.105$\pm$0.115} \\
Traffic & 0.414$\pm$0.001 & \worse{0.414$\pm$0.001} & \worse{0.414$\pm$0.001} & \better{0.192$\pm$0.157} & \better{0.152$\pm$0.185} \\
\hline
Win System 1 & NA & $\worse{4/8}$ & $\worse{4/8}$ & $\better{5/8}$ & $\better{5/8}$ \\
\hline
\end{tabular}
\end{subtable}
\label{tab:deepseek-3}
\end{table*}

\clearpage
\begin{figure}[t]
    \centering
    \includegraphics[width=0.5\textwidth]{picture/KDD25_Reason_Result.pdf}  % 或 tsf_comparison.pdf
    \vspace{-3mm}
    \caption{The average win rate of reasoning strategies compared to corresponding direct System 1 across all datasets and settings. We observe the consistent and significant effectiveness of self-consistency, as well as the unique effectiveness of DeepSeek-R1 among System 2 strategies.}
    \label{fig:tsf_comparison-A}
        \vspace{-5mm}
\end{figure}
\section{Experimental Results and Insights}
Based on the constructed \method suite, we conduct experiments to evaluate reasoning strategies for zero-shot TSF across eight datasets and four settings. We repeat each experiment three times, reporting the average MSE and standard deviation. We detail the experimental results in Table~\ref{tab:GPT-A}, ~\ref{tab:Gemini-2}, and ~\ref{tab:deepseek-3} corresponding to OpenAI's, Google's, and DeepSeek's foundation models. We visualize the average win rate of different reasoning strategies relative to the direct System 1, where 50\% means a tie, in Figure~\ref{fig:tsf_comparison-A}. We then discuss the two research questions raised in Section~\ref{sec:intro} one by one, following the structure of Answer – Evidence – Analysis. 
\subsection{RQ1: Can TSF Benefit from Reasoning?}
\observationbox{Overall Answer: TSF can benefit from enhanced reasoning ability}{We observe that in all four TSF scenarios, at least two reasoning strategies are effective, by outperforming the corresponding System 1 models in over 50\% of case; at least one reasoning strategy is significant, by surpassing the corresponding System 1 model in over 60\% cases.} 

\observationbox{From Short-term vs. Long-term Perspective: Long-term TSF benefits more consistently.}{We observe that long-term TSF, in both unimodal and multimodal settings, consistently benefits from all three System 1-based reasoning strategies across datasets and methods. Specifically, the CoT, Self-Consistency, and Self-Correction strategies outperform System 1 models in 52.08\%, 58.33\%, and 54.17\% cases, respectively. In contrast, short-term TSF only consistently benefits from the Self-Consistency strategy. This aligns with TSF, where long-term forecasting requires more consideration of temporal and event influences, while short-term forecasting is more similar to the lookback window.} 

\observationbox{From Unimodal vs. Multimodal Perspective: Multimodal TSF benefits more significantly.}{We observe that multimodal TSF, in both long-term and short-term settings, benefits more significantly from reasoning enhancement. Specifically, the Self-Consistency and Self-Correction strategies outperform System 1 models in  66.67\% and 56.25\% cases, respectively. In contrast, unimodal TSF only significantly benefits from the Self-Consistency strategy. This aligns with the intuition that multimodal TSF, which provides textual context for forecasting, requires more reasoning.} 

\subsection{RQ2: What Reasoning Strategies TSF Need?}
\observationbox{Overall Answer: self-consistency is the current best.}{We observe that the self-consistency strategy is effective and outperforms the System 1 model at a rate of 60\% to 80\%. We believe that self-consistency works by selecting the most coherent reasoning path from various options, which follows the inherent logic of TSF: to consider multiple possible future scenarios and choose the most likely one for prediction.}

\rejectionbox{From System 1 vs System 2 Perspective: Reasoning Enhanced System 1 win}{We observe that System 1 with test-time reasoning enhancement achieves an average effectiveness of 66.67\%, which is much higher than the 33.33\% of System 2. This suggests that pure System 2 reasoning may not be the correct answer for TSF. In contrast, reasoning-enhanced System 1 is more suitable, as it combines quick responses with slow thinking in line with TSF, which also combines superfacial pattern recognition, especially periodicity and trends~\cite{cleveland1990stl,liu2024lstprompt}, and deep reasoning, especially event influence~\cite{liu2025time}}

\observationbox{From System 2 Perspective: DeepSeek-R1 is the only effective reasoning model.}{We observe that DeepSeek-R1 is the only effective model, while the other two, o1-mini and Gemini-2.0-Flash-Thinking, are ineffective. DeepSeek-R1 shows significant improvements in three out of four settings, surpassing the System 1 model (DeepSeek-V3) in 60\% cases. We believe this is due to DeepSeek-R1's unique reinforcement learning approach, called Group Relative Policy Optimization (GRPO)~\cite{guo2025deepseek}, which focuses solely on outcomes rather than on labeled reasoning paths. Clearly, for TSF, relying on precise reasoning paths to forecast uncertain future numerical series is also not rational.}
