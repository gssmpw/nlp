\section{Limitations and Future Work}
Since reasoning strategies for foundational time-series models have not yet been studied and are difficult to implement directly, we have to reuse foundational language models to explore effective TSF reasoning strategies. We envision that our benchmark and insights offer promising potential for future research on understanding and designing effective reasoning strategies for zero-shot TSF. First, our results show that only limited existing System 2 approaches benefit zero-shot TSF. This can be interpreted as a distinction in reasoning logic between time-series analysis or zero-shot TSF, and other types of reasoning that are inherently learned by most System 2 models. This finding encourages future studies to design reasoning strategies more tailored to time-series data and zero-shot TSF tasks. Second, in validating the effectiveness of reasoning in zero-shot TSF, our open-source toolkit—comprising both \method and \data—provides guidelines for future research. Specifically, we validate the scaling law of zero-shot TSF by incorporating reasoning within \method, paving the way for future work on large-scale foundation TSF models with reasoning capabilities. Additionally, we provide \data, the first TSF dataset with reasoning annotations, enabling deeper investigation and understanding of reasoning strategies in zero-shot TSF.

\section{Conclusion}
In this work, we introduce \method, the first comprehensive benchmark to evaluate the effectiveness of existing reasoning strategies in zero-shot TSF tasks. Through \method’s evaluations, we address two key questions: whether (RQ1) reasoning benefits zero-shot TSF, and what (RQ2) reasoning strategy is most effective. Our findings demonstrate that zero-shot TSF can indeed benefit from reasoning, and moreover, further demonstrate that self-consistency reasoning provides the most significant advantage in zero-shot TSF.
\section*{Acknowledgements}
This paper was supported in part by the NSF (Expeditions CCF-1918770, CAREER IIS-2028586, Medium IIS-1955883, Medium IIS-2106961, Medium IIS-2403240, PIPP CCF-2200269), CDC MInD program, Meta faculty gift, and funds/computing resources from Georgia Tech and GTRI. 
