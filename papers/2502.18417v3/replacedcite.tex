\section{Related Work}
\paragraph{Face swap}
There are a large number of face-swapping methods. Conceptually, they can be divided into several different groups. Methods from the first group ____ extract the identity vector and some other features of the source face and use a generative model to blend them with the attributes of the target. Often, such models rely on the ArcFace ____ model and a 3D shape-aware identity extractor, which allows encoding the 3D geometry of the face.
There are also approaches ____ based on StyleGAN2 ____. They propose inverting the source and driving images into the latent space and feeding them into the StyleGAN2 generator to perform the swap. This approach allows for higher-resolution results but is sensitive to input data and does not perform well on strong rotations or small details of images.
With the development of diffusion models, approaches to face replacement using this method have emerged ____. Diffusion models allow for high-quality results, but they are typically slow and require significant computational power and sufficient VRAM.

\paragraph{Head swap}
The task of head swap is covered by a limited number of works. DeepFaceLab ____ is the first approach enabling this capability. However, it requires a large amount of source data for training, and poorly performs color transfer and fusion of generated head with the background. StylePoseGAN ____ performs head swap by conditioning StyleGAN ____ on pose and combined texture map, with body parts taken from target and head â€” from source. 
Still, it tends to modify the background and skin color of the target. HeSer ____ tackles these issues by designing a separate module for each task. First, it uses head reenactment model based on ____ to align source head with target in pose and expression. In the second stage a reference is created for skin color transfer based on correlation between pixels from the same head parts. Together with background inpainting prior, it is used to condition blending UNet ____ which fuses the head with background. While this method outperforms the competitors, it suffers from identity leakage of target and is unable to color head parts present in source image but absent in the driving one.  
While previous methods are based on GANs ____, there have been attempts ____ to use diffusion models ____ instead. However, currently these approaches face issues of pose controllability, preservation of target skin color and overall realism of generated head.


\vspace{-8pt}
\paragraph{Head reenactment} 
Head reenactment methods can be generally categorized as either warping-based ____ or reconstruction-based ____. Warping-based approaches utilize motion and facial expression descriptors of the target to deform source image. These descriptors can be based on keypoints ____, blendshapes from parametric models ____ or latent representations. The latter usually achieves better expressiveness, however, it requires careful disentanglemet of motion from the appearance of the target. This can be achieved via the use of special losses ____ or additional regularization embedded into the architecture ____. However, warping-based approaches generally perform well only if the difference between source and target poses is small.
Reconstruction-based methods ____ construct latent model of source head, and therefore are robust to larger pose deviations. These methods often utilize implicit representations such as TriPlanes ____ and NeRF ____, or explicit  ones, such as voxels ____, point clouds ____ and meshes ____, with particularly photorealistic results achieved recently with Gaussian splatting ____. However, reconstruction with these approaches requires an additional step of per-frame estimation of camera parameters, which increases runtime. Also, due to high computational cost of rendering, the resolution of output images does not exceed $256 \times 256$ and upsampling to higher resolutions is performed by an additional network.