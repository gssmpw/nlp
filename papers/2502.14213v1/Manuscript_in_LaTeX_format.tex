\documentclass[final,3p,times]{elsarticle}
%% The amssymb package provides various useful mathematical symbols
\usepackage{amssymb}
%% The amsmath package provides various useful equation environments.
\usepackage{amsmath}
%% The amsthm package provides extended theorem environments
\usepackage{amsthm}

\journal{Applied Mathematics and Computation}

\begin{document}

\begin{frontmatter}
\title{Asynchronous Stochastic Block Projection Algorithm for Solving Linear Systems under Predefined Communication Patterns\tnoteref{label1}}
\tnotetext[label1]{This work was supported by the National Natural Science Foundation of China Joint Fund Project Key Support Project under Grant U22B2049.}

%% use optional labels to link authors explicitly to addresses:
\author{Yanchen~Yin$^{a,}$\corref{cor1}}
\author{Yongli~Wang$^{a,}$\corref{cor1}}

\affiliation{organization={Academy of Mathematics and Systems Science, Shandong University of Science and Technology},
                      addressline={},
                      city={Qingdao},
                      postcode={266590},
                      state={Shandong},
                      country={China}}
\cortext[cor1]{Corresponding author: \texttt{wangyongli@sdkd.net.cn}, \texttt{yinyanchen352@gmail.com}}


 

%% Abstract
\begin{abstract}
Distributed computation over networks is now receiving an increasing  attention in many fields such as engineering and machine learning, where the solution of a linear system of equations is a basic task. This paper presents an asynchronous distributed randomized block Kaczmarz projection algorithm for solving large-scale linear systems over a multi-agent networks, where each agent only holds a part of the problem data. An event-triggered communication mechanism is integrated to minimize the communication overhead and reduce the overall communication costs. This communication mechanism allows each agent to update independently in an asynchronous environment and dynamically regulate communication frequency. In addition, this article analyzes the inefficiency caused by communication in asynchronous algorithms, explores the potential of event triggering mechanisms in alleviating these problems, and provides general conditions for global convergence in such environments. Moreover, a modified stochastic block Kaczmarz algorithm is used for each agent to update their local estimate. Through rigorous mathematical analysis, the exponential convergence rate of the proposed algorithm is established for a consistent system and its computational efficiency, robustness, and communication efficiency is validated through extensive numerical experiments. Furthermore, to address inconsistent systems, the algorithm introduces auxiliary variables to facilitate convergence toward an approximate least-squares solution, accompanied by a formal error analysis. The experimental results demonstrate that the algorithm maintains stability even under extreme asynchrony, communication failures, and node failures, while achieving significantly lower communication overhead and faster convergence rates compared to traditional methods.
\end{abstract}


% %%Graphical abstract
% \begin{graphicalabstract}
% % \includegraphics{grabs}
% \end{graphicalabstract}

%%Research highlights
% \begin{highlights}
% \item Research highlight 1
% \item Research highlight 2
% \end{highlights}

%% Keywords
\begin{keyword}
Asynchronous Distributed \sep Random Block Projection \sep Event-Triggered Communication \sep Communication Overhead
\end{keyword}

\end{frontmatter}

%% Add \usepackage{lineno} before \begin{document} and uncomment 
%% following line to enable line numbers
%%\linenumbers

%% main text
\section{Introduction}

Distributed computing has become an area of growing interest among researchers, driving the development of distributed algorithms to address large-scale computational problems. These algorithms have been widely applied in fields such as optimization~\cite{Yang2019A}, deep learning~\cite{10.1145/3320060, 10.1145/3363554}, robotics~\cite{halsted2021surveydistributedoptimizationmethods}, and power systems~\cite{7990560}, etc. Among these challenges, solving linear systems of equations with the form $Ax = b$, where $A$ is a matrix and $b$ is a column vector, remains a fundamental and extensively studied problem. Traditional solvers, including the Jacobi Method, Gauss-Seidel Method, Conjugate Gradient (CG), and Multigrid Method, often struggle with large-scale linear systems, motivating researchers to explore distributed alternatives.

 In this paper, we are interested in the multi-agent network. One of the most widely studied distributed strategies is row-wise partitioning, where the global system is decomposed into several local subproblems, each assigned to a separate agent. Specifically, given a global system $Ax=b$, where $A \in \mathbb{R}^{m\times n}$ and $b \in \mathbb{R}^{m}$. Suppose there are $N$ agents and each agent only holds a subset of the rows of $(A,b)$. Denote the subset that agent i holds as $(A_i,b_i),i=1,2,\cdots,N$, where $A_i\in\mathbb{R}^{m_i\times n} $ and $b_i \in \mathbb{R}^{m_i}$  with $\sum_{i=1}^{N}m_i =m.$ Then the global system can be represented as: 
\[
 \begin{pmatrix}A_1  \\ \vdots \\ A_N \end{pmatrix}x=\begin{pmatrix}b_1 \\ \vdots \\ b_N\end{pmatrix}.
\]
Each agent has a local estimate $x_i\in \mathbb{R}^{n}$ of the global solution and communicates with its neighbors to exchange information. By integrating the shared updates from its neighbors with its local state, each agent refines its estimate through a specially designed iterative process. The ultimate goal of the algorithm is to ensure that all agents’ local estimates converge to a solution of the global system.

Over the past decades, there has been considerable interest in developing distributed algorithms over multi-agent networks, specifically, in distributed linear equations. Notably, Liu and Mou conducted a comprehensive study on the distributed solution of consistent linear systems $Ax = b$, introducing a series of projection-based distributed algorithms in which each agent updates its state via projection operations. Among these works,~\cite{Mou2013A}  proposed a distributed algorithm for a discrete-time linear system and established the algorithm convergence  under fixed communication topologies. An asynchronous variant is developed in~\cite{Liu2013An}. In~\cite{Liu2014Stability},the theoretical framework is further refined  by presenting new connectivity conditions, as well as a necessary and sufficient criteria for the exponential convergence. Then, an extended approach to time-varying communication graphs is proposed in~\cite{Mou2015A} and the convergence rate is improved in~\cite{Mou2015B}. Later, the discrete-time algorithm proposed in~\cite{Mou2013A} is reformulated into a continuous-time linear system in~\cite{Liu2016A}.

Based on these foundations, Wang et al.~\cite{Wang2016A} refined the initialization strategy of Liu and Mou’s method and  developed a distributed algorithm capable of starting from arbitrary initial conditions. They also proposed parameter tuning techniques to optimize convergence rates and analyzed the conditions of the convergence to a minimum-norm solution~\cite{Wang2017Improvement,Wang2017A}. Recent advancements in this domain also include the acceleration of the distributed projection method by utilizing historical data, proposed by Hu et al. in 2020~\cite{Hu2020Accelerated}, as well as a finite-time distributed algorithm designed for privacy-preserving applications~\cite{Gade2020A}. In addition, Yi et al.~\cite{Yi2020Distributed} developed a stochastic projection method on random graphs, while Ref.~\cite{Zhu2023A} analyzed the convergence behavior of these algorithms in Byzantine environments. Alternative perspectives have also emerged. Alaviani et al.~\cite{9144422}  addressed the problem using the stochastic Krasnoselskii-Mann iterative algorithm under random network topologies. In contrast, Ref.~\cite{Yang2015A} and~\cite{8028633} took a non-projection-based approach, leveraging Lagrangian and Lyapunov functions to model algorithms as continuous-time linear systems in a gradient descent-like manner. More recently, Huang~\cite{Huang2024Distributed} and Wang~\cite{Wang2020Scalable} extended this approach by developing scalable distributed continuous-time and discrete-time algorithms that utilize a bilevel network structure, enabling agents to function without requiring full row or column information.

It should be noted that most existing research on distributed algorithms including the aboved mentioned methods focused on synchronous patterns. As we know, the distributed solution of large-scale linear system of equations involves extensive communication between agents. The synchronization process requires all proxy communications to be completed before proceeding to the next step, which will inevitably result in significant delays. To mitigate this, several studies~\cite{7943430, 7587861, Yin2020Securely, Liu2020Communication-Efficient} have proposed to reduce communication overhead by transmitting only partial data, thereby decreasing idle time. For instance, Ref.~\cite{Wang2018Communication-efficient} introduced two low communication-cost algorithms for solving linear systems with a Laplacian sparse structure—based on gradient descent and Newton method repectively, which transmits only local and neighbor information per iteration and achieves faster convergence. However, these approaches remain constrained by synchronous execution.
%Further improvements were made in ~\cite{Liu2018Asynchronous}, where a novel approach is proposed to enhance the asynchronous distributed projection algorithm. 
As highlighted in~\cite{Liu2013An, Liu2018Asynchronous}, asynchronous distributed algorithms offer a compelling advantage: agents under asynchronous environment can operate independently without waiting for others and effectively treat communication delays as system latencies. This flexibility enables more efficient utilization of computational resources. Furthermore, our observations indicate that achieving convergence does not require excessive communication, a well-designed information exchange strategy is usually enough. Motivated by these insights and considering the successful application of the stochatic block Kaczmarz algorithm in solving linear systems of equations, we propose an asynchronous distributed stochatic block Kaczmarz projection algorithm based on an event-triggered communication strategy that reduces unnecessary communication while maintaining convergence property. In our approach, each agent can independently update its states using a modified random block Kaczmarz algorithm according to a predefined protocol. Communication events are triggered based on specific conditions, prompting an agent to transmit information to its neighbors. By adjusting the event triggering mechanism, users can fine-tune the trade-off between communication efficiency and computational accuracy.

Besides, robustness under extreme conditions is a fundamental concern in distributed computing. Beyond addressing irregular communication patterns and potential agent failures, asynchronous algorithms must also account for the effects of asynchrony on convergence. To this end, we conduct extensive experiments to validate not only the algorithm's convergence and communication efficiency but also its robustness against extreme asynchrony, communication failures, and agent disruptions. For theoretical validation, we employ mathematical tools from~\cite{doi:10.1137/060657005,Cao2008Reaching} and adopt the proof strategies used in~\cite{Liu2018Asynchronous, Yi2020Distributed}. Specifically, we decompose the state transition equation of the error vector, as defined in~\cite{Liu2018Asynchronous}, and provide a more general proof demonstrating convergence to an arbitrary solution.

%In this paper, all vectors are treated as column vectors. Let nn and mm be arbitrary integers, with Rn\mathbb{R}^n representing an nn-dimensional Euclidean space and Rm×n\mathbb{R}^{m \times n} representing the space of m×nm \times n matrices. Unless otherwise specified, ‖\|\cdot\| denotes the 2-norm of a vector or its corresponding matrix operator norm, and \|\cdot\|_\infty\|\cdot\|_\infty refers to the infinity norm of a vector or its corresponding matrix operator norm. Definitions for other norms are provided in the paper.

%We define \otimes\otimes as the Kronecker product of matrices.

%For an m \times nm \times n matrix AA, expressed as a set of row vectors, A = \Big[\alpha_1^T, \cdots, \alpha_m^T\Big]^TA = \Big[\alpha_1^T, \cdots, \alpha_m^T\Big]^T, the linear space \text{Row}(A) = \text{span}(\alpha_1, \cdots, \alpha_m)\text{Row}(A) = \text{span}(\alpha_1, \cdots, \alpha_m) is the row space of AA, and \text{Row}_\perp(A)\text{Row}_\perp(A) denotes its orthogonal complement, which is equivalent to the null space of AA.

%Consider the set of row vectors \Big\{\alpha_1^T, \cdots, \alpha_m^T\Big\}\Big\{\alpha_1^T, \cdots, \alpha_m^T\Big\} for the m \times nm \times n matrix AA, and define \mathbf{m}\mathbf{m} as the index set of these row vectors, \mathbf{m} = \Big\{1, \cdots, m\Big\}\mathbf{m} = \Big\{1, \cdots, m\Big\}. If AA is partitioned into NN blocks as A_i = \Big[\alpha_{m_{i-1}+1}^T, \cdots, \alpha_{m_i}^T\Big]^TA_i = \Big[\alpha_{m_{i-1}+1}^T, \cdots, \alpha_{m_i}^T\Big]^T, then define \mathbf{m}_i\mathbf{m}_i as the index set of the row vectors of A_iA_i, \mathbf{m}_i = \Big\{m_{i-1}+1, \cdots, m_i\Big\}\mathbf{m}_i = \Big\{m_{i-1}+1, \cdots, m_i\Big\}, and the union of all these sets is N⋃i=1mi=m\overset{N}{\bigcup\limits_{i=1}} \mathbf{m}_i = \mathbf{m}.

Throughout this paper, all vectors are column vectors. We denote $\mathbb{R}^n$ as the $n$-dimensional vector space and $ \mathbb{R}^{m\times n} $  as the space of $m\times n$ matrices. Unless otherwise specified, $\|\cdot\|$ denotes the 2-norm of  a vector or its corresponding matrix norm, and $\|\cdot\|_\infty$ refers to the infinity norm. We define $\otimes$ as the Kronecker product of matrices. For a matrix $A\in\mathbb {R}^{m\times n}$, we denote $ A^\dagger$ as its Moore-Penrose Psudoinverse and  $A^T$ as its transpose. We use $\alpha_i^T$ to denote the $i-th$ row vector of matrix $A$.
Denote the row space of matrix $A$ as Row$(A)=\{A^Tx|x\in\mathbb{R}^m\} $, then Row$(A)=span\{\alpha_1,\alpha_2,\cdots,\alpha_m\}$. Row$_{\perp}(A)$ is the orthogonal complement of Row$(A)$, which is equivalent to the null space of $A$. The index set corresponding to the rows of matrix $A$ is denoted as $\mathbf{m}=\{1,2,\cdots,m\}$, while $\mathbf{m}_i,(i=1,2,\cdots,N)$ represents the subset of $\mathbf{m}$, satisfying $\overset{N}{\bigcup\limits_{i=1}}\mathbf{m}_i=\mathbf{m}$ and $\overset{N}{\bigcap\limits_{i=1}}\mathbf{m}_i=\emptyset$. Specifically, $\mathbf{m}_i$ represents the index set of rows of $A_i$ in this paper.

The remainder of this paper is organized as follows. Section I provides the introduction. details The proposed algorithm is detailed in Section II. Section III presents the main theoretical results. Section IV discusses numerical experiments. The conclusion is given in Section V and the complete proofs of the theoretical results are included in the appendix.

\section{The Proposed Algorithm}

This section begins by presenting the distributed asynchronous stochastic block projection iterative algorithm for both compatible and incompatible problems, followed by a discussion on the communication overhead and communication strategies in asynchronous algorithms.

First, we define some basic concepts. Let the $n$-dimensional vector sequence $\{x_i(t_{i,k})\}_{k=0}^{+\infty}$ represent the sequence of solution estimates for agent $i$, where $t_{i,k}$ is the time at which agent $i$ completes the $k$-th iteration, and $x_i(t_{i,k})$ is the solution estimate of agent $i$ at that time. The initial estimate is given by $x_i(t_{i,0})$. To model the information exchange process between agents in the asynchronous environment, we treat the change in agent $i$'s solution estimate as a continuous vector-valued function of time $t$. We define $x_i(t) = x_i(t_{i,k})$ for $t \in \left[t_{i,k}, t_{i,k+1}\right)$.

\subsection{Consistent Systems}

As defined in~\cite{Liu2018Asynchronous}, if $Ax = b$ is consistent, the asynchronous distributed projection algorithm can be described as a discrete-time system with randomly bounded delays:
\begin{equation}
A_ix_i(t_{i,0})=b_i, \ \  w_i(t_{i,k})=\sum_{j \in \mathcal{N}_i\left(t_{i,k}\right)} x_j\Big(t_{i,k}-\delta_{j,i}(t_{i,k})\Big),\ \ x_i\left(t_{i,k+1}\right)=x_i\left(t_{i,k}\right)-P_i\Big(x_i\left(t_{i,k}\right)-\frac{1}{d_i\left(t_{i,k}\right)}w_i(t_{i,k})\Big),
\label{eq:The initial iterative method.}
\end{equation}
where $P_i$ is the projection operator associated with agent $i$. As defined in~\cite{Liu2018Asynchronous}, it corresponds to the orthogonal projection onto the null space of $A_i$ and is given by $P_i = I_n - A_i^\dagger A_i$. The set $\mathcal{N}_i(t_{i,k})$ represents the neighborhood of agent $i$ at time $t_{i,k}$, meaning that if agent $i$ incorporates information from agent $j$ in its $(k+1)$-th iteration, then $j \in \mathcal{N}_i(t_{i,k})$. The term $\delta_{j,i}(t_{i,k})$ represents the delay in information transmission from agent $j$ to agent $i$, which arises in asynchronous settings. If agent $i$ utilizes the solution estimate $x_j(t_{j,h_{j,i}^k})$ from agent $j$'s $h_{j,i}^k$-th iteration, then the delay is given by $\delta_{j,i}(t_{i,k}) = t_{i,k} - t_{j,h_{j,i}^k}$. The quantity $d_i(t_{i,k})$ denotes the number of neighbors of agent $i$ at time $t_{i,k}$, i.e., $\left|\mathcal{N}_i(t_{i,k})\right|$.

There are two important details that should be noted. First, in each iteration, agent $i$ incorporates its own previous solution estimate, ensuring that $i \in \mathcal{N}_i(t_{i,k})$ and $t_{i,h_{i,i}^k} = t_{i,k}$, leading to $\delta_{i,i}(t_{i,k}) = 0$. Besides, if agent $j$ transmits multiple updates to agent $i$ within a single iteration, agent $i$ only selects the most recent solution estimate from agent $j$.

%In this section, we modify the projection method.
In~\cite{Wang2017Improvement}, an improvement was given for \eqref{eq:The initial iterative method.}, where the initialization step that requires each agent i to be capable of finding an exact solution to $ A_ix=b_i$ is eliminated, and allows $x_i(t_{i,0})$ to be an arbitrary vector in $\mathbb{R}^n$. Thus the update
 for each agent i at $t_{i,k+1}$ is modified as follows:
\begin{equation}
    x_i\left(t_{i,k+1}\right) = x_i  \left(t_{i,k}\right) - P_i\Big(x_i\left(t_{i,k}\right) - \frac{1}{d_i\left(t_{i,k}\right)} w_i(t_{i,k})\Big) - A_i^T (A_i A_i^T)^{-1} (A_i w_i(t_{i,k}) - b_i)
    \label{eq:The modified iterative format.}
\end{equation}
Note that if $A_i$ is rank-deficient, $A_i^\dagger$ can be used as a substitute, hence  \eqref{eq:The modified iterative format.}  can be simplified as :
\begin{equation}
    \begin{aligned}
        x_i\left(t_{i,k+1}\right) = P_i\left(\frac{1}{d_i\left(t_{i,k}\right)} w_i(t_{i,k})\right) + A_i^\dagger b_i.
    \end{aligned}
    \label{eq:This paper introduces modifications to the previous iterative format.}
\end{equation}
%This method can be viewed as applying the block Kaczmarz iteration using the block (Aibi)\begin{pmatrix} A_i & b_i \end{pmatrix}. 
However, computing the pseudo-inverse $A_i^\dagger$ may be computationally prohibitive and requires access to the complete block $A_i$ of agent i. To overcome this and reduce the computation burden, inspired by the idea of the randomized block Kaczmarz algorithm~\cite{du2020randomizedextendedblockkaczmarz}, we propose an improved projection operator based on a stochastic block projection strategy. Instead of using the entire $\begin{pmatrix} A_i & b_i \end{pmatrix}$ at each iteration, only a subset of its rows $\begin{pmatrix} A_i(t_{i,k}) & b_i(t_{i,k}) \end{pmatrix}$ is selected for computation and the projection operator is  then defined as $P_i(t_{i,k})=I_n - A_i^\dagger(t_{i,k}) A_i(t_{i,k})$. This can significantly reduce the computation and communication network scale at each iteration and is particularly well-suited for scenarios where $A_i$ is dynamically generated or acquired incrementally. Compared to row-wise updates, random block selection enhances computational efficiency. Moreover, this modification allows the algorithm to flexibly adjust when the initial condition $A_i x_i(t_{i,0}) = b_i$ is not satisfied by an incremental update mechanism. Based on this strategy, the algorithm \eqref{eq:The initial iterative method.} can be modified as follows:
\begin{equation}
x_i\left(t_{i,k+1}\right) = P_i(t_{i,k}) \left( \frac{1}{d_i\left(t_{i,k}\right)} w_i(t_{i,k}) \right) + A_i^\dagger(t_{i,k}) b_i(t_{i,k}).
\label{eq:The iterative format for solving the compatibility problem.}
\end{equation}

%The proof of convergence for the iteration format \eqref{eq:The iterative format for solving the compatibility problem.} will be presented in the appendix.



\subsection{Inconsistent Systems}
Now, we come to discuss the case where the linear system $Ax = b$ is inconsistent. We observe that in this case, the algorithm \eqref{eq:The iterative format for solving the compatibility problem.} no longer converges. The reason is that, if $Ax = b$ is consistent and $x^* = A^\dagger b$, then $A_i(t_{i,k}) x^{\mathbf{*}} = b_i(t_{i,k})$.  Hence, it follows from \eqref{eq:The iterative format for solving the compatibility problem.} that 
\begin{equation}
    \begin{aligned}
        x_i(t_{i,k+1}) - x^{\mathbf{*}} = \frac{1}{d_i(t_{i,k})} w_i(t_{i,k}) - x^{\mathbf{*}} - & A_i^\dagger(t_{i,k}) A_i(t_{i,k}) \left( \frac{1}{d_i(t_{i,k})} w_i(t_{i,k}) - x^{\mathbf{*}} \right) + A_i^\dagger(t_{i,k}) b_i(t_{i,k}) - A_i^\dagger(t_{i,k}) A_i(t_{i,k}) x^{\mathbf{*}} \\
        & = P_i(t_{i,k}) \left( \frac{1}{d_i(t_{i,k})} w_i(t_{i,k}) - x^{\mathbf{*}} \right).
    \end{aligned}
    \label{eq:Time-varying autonomous discrete linear system.}
\end{equation}
In control theory, this represents a simple time-varying autonomous discrete linear system with time delays. In the appendix, we focus on the maximum possible delay sequence, which simplifies \eqref{eq:Time-varying autonomous discrete linear system.} into a delay-free linear system. By analyzing the spectral radius of its state transition matrix, we can prove the convergence of \eqref{eq:The iterative format for solving the compatibility problem.}. However, if $Ax = b$ is inconsistent, there must exist a residual vector $\Tilde{b}(t_{i,k})$ such that $\Tilde{b}(t_{i,k}) = b_i(t_{i,k}) - A_i(t_{i,k}) x^{\mathbf{*}} \neq 0$. In this case, \eqref{eq:Time-varying autonomous discrete linear system.} will include a disturbance term $A_i^\dagger(t_{i,k}) \Tilde{b}_i(t_{i,k})$, which disrupts the convergence of \eqref{eq:The iterative format for solving the compatibility problem.}. To address this issue and maintain the algorithm's random block-based operation, we aim to develop a new mechanism that eliminates $\Tilde{b}_i(t_{i,k})$ during the iteration process. To achieve this, we introduce an augmented system by adding an $m$-dimensional vector $\epsilon$ and modify $Ax = b$ as:
\begin{equation}
    \begin{pmatrix} A & \Lambda \end{pmatrix} \begin{pmatrix} x \\ \epsilon \end{pmatrix} = b.
    \label{eq:Augmented system.}
\end{equation}
Here, $\Lambda = \text{diag} (\lambda_1, \cdots, \lambda_m)$ is a diagonal matrix with its diagonal elements $\lambda_i>0,i=1,\cdots,m $,
( non-negative that are not equal to zero,) 
designed to approximate the least squares solution for $Ax = b$. Solving this problem is equivalent to solving a linear system in an $n + m$-dimensional space. However, if we directly use the pseudoinverse method from \eqref{eq:The iterative format for solving the compatibility problem.} to compute the augmented $P_i(t_{i,k})$, the computational cost will be prohibitively high. Therefore, we need to modify the iteration format in \eqref{eq:The iterative format for solving the compatibility problem.}.

For the inconsistent system $Ax = b$, suppose $A_i(t_{i,k})$ has $m_i(t_{i,k})$ row vectors and denote its index set as $\mathbf{m}_i(t_{i,k}) = \Big\{i_1, \cdots, i_{m_i(t_{i,k})}\Big\}$, where $\mathbf{m}_i(t_{i,k}) \subseteq \mathbf{m}_i$. Then, define:
\[
    A_i(t_{i,k}) = \Big[ \alpha_{i_1}(t_{i,k}), \cdots, \alpha_{i_{m_i(t_{i,k})}}(t_{i,k})\Big]^T, \ b_i(t_{i,k}) = \Big[ b_{i_1}(t_{i,k}), \cdots, b_{i_{m_i(t_{i,k})}}(t_{i,k})\Big]^T.
\]

Let $\epsilon^i(t)$ denote the estimate maintained by agent $i$ for $\epsilon$, and let $\epsilon_{j}^i(t)$ represent its $j$-th component. First, we define the scalar function $r_{i_j}(t_{i,k}): \mathbb{R}^n \to \mathbb{R}$, for any $x \in \mathbb{R}^n$:
\begin{equation}
    r_{i_j}(t_{i,k})(x) = \frac{\Big(\alpha_{i_j}(t_{i,k})^T x + \lambda_{i_j} \epsilon^i_{i_j}(t_{i,k}) - b_{i_j}(t_{i,k})\Big)}{\|\alpha_{i_j}(t_{i,k})\|^2 + \lambda_{i_j}^2},
    \label{eq:Row projection function of the augmented system.}
\end{equation}
Next, define the  function $R_{i_j}(t_{i,k}): \mathbb{R}\times\mathbb{R}^n \to \mathbb{R}$, for any $\epsilon \in \mathbb{R}$, $x \in \mathbb{R}^n$:
\begin{equation}
    R_{i_j}(t_{i,k})(\epsilon, \ x) = \epsilon - \lambda_{i_j} r_{i_j}(t_{i,k})(x),
    \label{eq:Correction update function.}
\end{equation}
and the vector function $P_{i_j}(t_{i,k}): \mathbb{R}^n \to \mathbb{R}^n$, for any $x \in \mathbb{R}^n$
\begin{equation}
    P_{i_j}(t_{i,k})(x) = x - r_{i_j}(t_{i,k})(x) \alpha_{i_j}(t_{i,k}).
    \label{eq:State update function.}
\end{equation}

Whenever agent $i$ obtains $\begin{pmatrix}A_i(t_{i,k}) & b_i(t_{i,k})\end{pmatrix}$ during an iteration, set $x_i^0(t_{i,k}) = w_i(t_{i,k})$. For $j = 1$ to $j = m_i(t_{i,k})$, iteratively perform the following:
\begin{equation}
    x_i^j\left(t_{i,k}\right) = P_{i_j}(t_{i,k})\left(x_i^{j-1}\left(t_{i,k}\right)\right), \ \ \epsilon^i_{i_j}\left(t_{i,k+1}\right) = R_{i_j}(t_{i,k})\left(\epsilon^i_{i_j}\left(t_{i,k}\right), \ x_i^{j-1}\left(t_{i,k}\right)\right).
    \label{eq:The iterative format for solving the incompatibility problem.}
\end{equation}
Finally, let $x_i\left(t_{i,k+1}\right) = x_i^{m_i(t_{i,k})}\left(t_{i,k}\right)$. The design of \eqref{eq:The iterative format for solving the incompatibility problem.} preserves the random block structure, ensuring the algorithm's efficiency while avoiding the computational cost of large-scale pseudoinverse calculations, thus preventing computational overload.


\subsection{Communication Strategy}

In this section, we identify the shortcomings of previous communication strategies, explore the potential to reduce communication costs by optimizing communication protocols, and propose our solution.

In nearly all related works, information exchange between agents was essential for ensuring that distributed algorithms could converge to the solution of the target system of equations. One traditional and intuitive communication rule is that each agent immediately sends updates to its neighboring nodes after completing its current computation. References~\cite{Liu2018Asynchronous} adopted this strategy and demonstrated the system’s convergence using the theory from ~\cite{Cao2008Reaching}.
However, in large-scale distributed algorithms,the data transmitted through communication is often large, and the time spent on communication often far exceeds the time required for the algorithm’s iterations. The dense information passed during communication is often not used in time by the agents, and outdated information can negatively impact the convergence of the algorithm. In ~\cite{Liu2018Asynchronous}, each agent only uses the latest information received from other agents, which results in a large amount of communication data being wasted and incurs unnecessary overhead.

To elaborate further, if the communication process between agents lacks an efficient control mechanism, agent $i$ may receive multiple updates from agent $j$ in a single iteration. In the iteration formats \eqref{eq:The iterative format for solving the compatibility problem.} and \eqref{eq:The iterative format for solving the incompatibility problem.}, each iteration of agent $j$ involves projecting onto the affine subspace $\{x\in\mathbb{R}^n|A_i(t_{i,k})x = b_i(t_{i,k})\}$. In other words, each iteration adds new information from the equation blocks to the local solution estimate. Newer updates typically carry more comprehensive information from the equation system, which has a greater effect on accelerating system convergence. For example, as illustrated in Figure~\ref{fig:1}, each iteration of different agents can be viewed as nodes. Node $\mathbf{A}$ integrates information from other nodes and itself and sends updates to the next iteration nodes, $\mathbf{B}$ and $\mathbf{C}$. Node $\mathbf{B}$ then further integrates information from $\mathbf{A}$ and itself, sending the updated result to $\mathbf{C}$. Clearly, compared to the path $\mathbf{A} \to \mathbf{C}$, the path $\mathbf{B} \to \mathbf{C}$ provides more comprehensive information, whereas the path $\mathbf{A} \to \mathbf{C}$ has become redundant in this case. Without an effective communication protocol, the accumulation of redundant information leads to a waste of communication resources. This issue is especially pronounced in large-scale distributed systems but can be mitigated through well-designed communication strategies.

\begin{figure}[h]
    \centering
    \includegraphics[width=0.26\textwidth, height=5cm]{Communication_graph.png}
    \caption{Schematic diagram of communication relationships between nodes}
    \label{fig:1}
\end{figure}

Hence, in this paper, we propose a communication strategy based on a predefined set of events. Let $\mathcal{N}(t)$ denote the set of agents participating in communication at time $t$, and let $T_k$ represent the $k$-th time when $|\mathcal{N}(t)| \neq 0$. By introducing a set of event time points $\mathcal{T}_S = \{T_k\}_{k=1}^{+\infty}$, communication events occur at time $T_k$, where the relevant agents engage in communication. The design of $\mathcal{T}_S$ enables effective regulation of the communication process.

As discussed in ~\cite{Liu2018Asynchronous}, if there exist positive constants $\overline{T}_i$ and $T_i$ such that for all $k \geq 1$ and for all communication delays $\Delta t$ in the system, the following conditions hold:
\begin{equation}
    \overline{T}_i \geq t_{i,k} - t_{i,k-1} \geq T_i, \ \ \Delta t \leq \Delta T,
\label{eq:Assumptions on communication prerequisites.}
\end{equation}
then it follows that all delays $\delta_{j,i}(t_{i,k})$ are bounded. This property enables the delayed discrete system to be transformed into an equivalent synchronous system, simplifying the analysis. A similar discussion is presented in this paper, where $\overline{T} = \max\limits_{i}\left\{\overline{T}_i\right\}$. Suppose agent $i$ receives information from agent $j$ at time $\tau$. The delay can then be expressed as $$\delta_{j,i}(t_{i,k}) = t_{i,k} - \tau + \tau - t_{j,h_{j,i}^k}.$$ Since $\tau \in \left[t_{i,k-1}, t_{i,k}\right)$, it follows that $t_{i,k} - \tau \leq \overline{T}$, and $\tau - t_{j,h_{j,i}^k} \leq \Delta T$.
 Therefore, from \eqref{eq:Assumptions on communication prerequisites.}, we obtain $\delta_{j,i}(t_{i,k}) \leq \Delta T + \overline{T}$.

In the case where assumption \eqref{eq:Assumptions on communication prerequisites.} holds, we discuss the design of the set $\mathcal{T}_S$. 

Let $\Delta T_{broadcast} = \min\limits_{k\geq 1} \ T_k - T_{k-1}$. If $\Delta T_{broadcast} \geq 2\Delta T + \overline{T}$, the following applies. Suppose a system communication command occurs at time $T_s$, agent $j$ receives the broadcast command at time $\tau$, and then passes the information to agent $i$. The time interval from the system command time $T_s$ to the time $t_{i,k}$ when agent $i$ uses the information can be written as $\Delta t = t_{i,k} - \tau + \tau - T_s$.

 By definition, $\tau \in \left[t_{j,h_{j,i}^k}, t_{j,h_{j,i}^k+1}\right)$, so $$t_{i,k} - \tau \leq t_{i,k} - t_{j,h_{j,i}^k} \leq \overline{T} + \Delta T.$$
Additionally, from \eqref{eq:Assumptions on communication prerequisites.}, we have $\tau - T_s \leq \Delta T$, and since $T_k - T_{k-1} \geq 2\Delta T + \overline{T}$, it follows that$$\Delta t \leq 2\Delta T + \overline{T} \leq T_{s+1} - T_s.$$ 
This result implies that, under the given constraints, each communication process completes before the next one starts. In other words, the communication process triggered by a system command at time $T_s$ is temporally independent, and there will be no logical conflicts or interference between consecutive system communication events. Based on this analysis, if the design of $\mathcal{T}_S = \{T_k\}_{k=1}^{+\infty}$ meets the above conditions, the redundant communication situation shown in Figure \ref{fig:1} will not occur, ensuring a clear and efficient communication process and avoiding resource waste. However, if $\Delta T_{broadcast}$ is too large, the convergence speed of the information exchange algorithm will noticeably decrease. This means that $\Delta T_{broadcast}$ needs to be carefully designed.

In this paper, we propose two design schemes for $\mathcal{T}_S$ in our experiments. The first scheme introduces a global \textbf{broadcast clock}, where a communication command is sent to all agents' communication processes at fixed time intervals $\Delta T$, and agents receiving the command then forward information to other agents. The second scheme, following the approach in ~\cite{Liu2018Asynchronous}, does not use a global broadcast control mechanism. Instead, for each agent, it broadcasts information to other agents after every $\Delta k$ iterations.

 It is important to note that, due to the fully asynchronous nature of the agents, communication between them inherently involves asynchrony and uncertainty. Thus, while we design $\mathcal{T}_S$, it does not mean that the actual $\mathcal{T}_S$ will exactly match the design. Our goal is to increase efficiency through reasonable design.



\section{Main Results}


In this section, we will present the convergence results of the proposed algorithm, for which certain concepts and tools need to be defined. 

Let $\mathcal{T}_i = \{t_{i,k}\}_{k=1}^{+\infty}$ denote the iteration time sequence of agent $i$, and define the global time set as $\mathcal{T} = \overset{N}{\bigcup\limits_{i=1}} \mathcal{T}_i$. The elements of the set $\mathcal{T}$ are arranged in increasing order. For any time point $\tau \in \mathcal{T}$, the communication graph at time $\tau$ is defined as $\mathcal{G}(\tau) = (\mathcal{N}, \mathcal{V}(\tau))$, where $\mathcal{N} = \{1, 2, \dots, N\}$ is the set of nodes, and $\mathcal{V}(\tau) = \{(j, i) \mid j \in \mathcal{N}_i(\tau)\}$ is the set of edges. Specifically, each node in the communication graph $\mathcal{G}(\tau)$ contains a self-loop. The collection of communication graphs over the time set $\mathcal{T}$ is denoted by $\mathbf{G} = \{\mathcal{G}(\tau)\}_{\tau \in \mathcal{T}}$. Different designs of $\mathcal{T}_S$ will result in different $\mathbf{G}$. The question to discuss is under what conditions the resulting $\mathbf{G}$ ensures the convergence of the algorithm.

To account for the long-term cumulative effect of communication graphs at different times, we introduce the graph combination operation. Let the adjacency matrix of $\mathcal{G}(\tau)$ be denoted by $\mathcal{A}(\mathcal{G}(\tau))$, and define the combination operation "$\circ$" of two graphs as follows: if the adjacency matrices of two graphs, $\mathcal{G}_1$ and $\mathcal{G}_2$, are $\mathcal{A}(\mathcal{G}_1)$ and $\mathcal{A}(\mathcal{G}_2)$, respectively, then the adjacency matrix of the combined graph $\mathcal{G}_1 \circ \mathcal{G}_2$ is given by $\mathcal{A}(\mathcal{G}_1)\mathcal{A}(\mathcal{G}_2)$. This combination operation will be used in the subsequent analysis to describe the connectivity of communication graphs over continuous time intervals.

Through theoretical analysis, this paper demonstrates that as long as the communication process controlled manually generates a $\mathbf{G}$ that satisfies the joint strong connectivity condition, the algorithm will converge, regardless of how $\mathcal{T}_S$ is designed. To derive the results, we define two events here. $\bf {Event\  1:}$
\begin{equation}
    \mathcal{C}(l) =  \Big\{\forall \tau_1 \in \mathcal{T}, \forall \Delta l \geq l \ \text{Graph combination} \ \mathcal{G}(\tau_{\Delta l}) \circ \cdots \mathcal{G}(\tau_2) \circ \mathcal{G}(\tau_1) \ \text{is a strongly connected directed graph}\Big\},
    \label{eq:Connectivity event.}
\end{equation}
and  $\bf {Event\  2:}$
\begin{equation}
        \mathcal{C}(\infty) =  \Big\{\forall \tau_1 \in \mathcal{T}, \forall l \geq 1 \ \text{Graph combination} \ \mathcal{G}(\tau_{\Delta l}) \circ \cdots \mathcal{G}(\tau_2) \circ \mathcal{G}(\tau_1) \ \text{is not a strongly connected directed graph}\Big\},
    \label{eq:Communication failure event.}
\end{equation}
where $l \geq 1$, and $\tau_1, \cdots, \tau_{\Delta t}$ is a set of consecutive time points in $\mathcal{T}$. Based on these definitions, we first give the conergence result of the algorithm  \eqref{eq:The iterative format for solving the compatibility problem.} in the consistent system as follows.

\textbf{Theorem 1}:If the probability of event $\mathcal{C}(\infty)$ occurring is zero, then the algorithm \eqref{eq:The iterative format for solving the compatibility problem.} in the consistent system almost surely converges to a solution of the global linear system of equations $Ax=b$ at an exponential rate.

Here, we need say something about the condition of this theorem. Event $\mathcal{C}(\infty)$ indicates that there is a long-term barrier in the communication between agents, preventing certain agents from exchanging information with others. This corresponds to the extreme case of complete communication failure in the system. Therefore, the theorem states that the algorithm will converge only when the communication network maintains a certain level of connectivity (i.e., event $\mathcal{C}(\infty)$ does not occur). If communication between agents remains in a failure state for an extended period, the algorithm will fail to converge as expected. On the other hand, the condition of Theorem 1 also  tells us that, regardless of the characteristics of matrix $A$, as long as specific conditions are met, the algorithm in \eqref{eq:The iterative format for solving the compatibility problem.} will converge.

We now present the following theorem to describe the convergence result of \eqref{eq:The iterative format for solving the incompatibility problem.} in the inconsistent system:

\textbf{Theorem 2}: If the probability of event $\mathcal{C}(\infty)$ occurring is zero, then the algorithm \eqref{eq:The iterative format for solving the incompatibility problem.} in the inconsistent system almost surely converges to an approximation $\Tilde{x}^*$ of the least-squares solution $x^*$ of the inconsistent system $Ax = b$ at an exponential rate. Moreover, let $\lambda_{max}$ be the maximum value of the diagonal elements of $\Lambda$, and $\sigma_{min}$ be the smallest singular value of $A$. Then, the relative error estimate is given by:
\[
\frac{\|x^* - \Tilde{x}^*\|}{\|x^*\|} \leq \frac{1}{\frac{1}{\left(\frac{\sigma_{min}}{\lambda_{max}}\right)^2}+1}.
\]

We give a brief analysis of Theorem 2. Note that the theorem is about the convergence of  \eqref{eq:The iterative format for solving the incompatibility problem.} to an approximate least-squares solution of the inconsistent system  $Ax = b$, where  an auxiliary vector $\epsilon$ is introduced to counteract the effect of the residual vector $\Tilde{b}_i(t_{i,k})$. From the relative error estimate, we can see that if $\sigma_{min}$ is large, a larger $\lambda_{max}$ can be chosen to ensure the accuracy of the algorithm and guarantee the efficiency of eliminating $\Tilde{b}_i(t_{i,k})$ as well. Conversely, if  $\sigma_{min}$ is small, in which case matrix $A$  may be ill-conditioned, $\Lambda$ can be configured accordingly to reduce the error. However, setting $\lambda_{max}$ to a very small value in an attempt to infinitely approach $x^*$ is not advisable. First, due to the behavior of the function $\frac{1}{x+1}$, the improvement in accuracy becomes negligible as $\lambda_{max}$ decreases. Second, a very small $\lambda_{max}$ will drastically reduce the efficiency of removing $\Tilde{b}_i(t_{i,k})$, resulting in low efficiency or even failure of the algorithm. Hence, the convergence result of the inconsistent system may be affected by the characteristic of matrix $A$.

The detailed proof of both Theorem 1 and Theorem 2 will be given in the appendix.


% if have a single appendix:
%\appendix[Proof of the Zonklar Equations]
% or
%\appendix  % for no appendix heading
% do not use \section anymore after \appendix, only \section*
% is possibly needed

% use appendices with more than one appendix
% then use \section to start each appendix
% you must declare a \section before using any
% \subsection or using \label (\appendices by itself
% starts a section numbered zero.)

\section{Numerical Experiments}

In this section, the results of numerical experiments are presented. The experiments are mainly designed to verify the convergence of the iteration formats \eqref{eq:The iterative format for solving the compatibility problem.} and \eqref{eq:The iterative format for solving the incompatibility problem.}, evaluate the robustness of the algorithm, assess the convergence speed and communication cost of the algorithm under different communication strategies and confirm the feasibility of the proposed communication strategy as well.

 All experiments were conducted on the same device, with the code written in \textbf{Python 3.12}. Matrix operations were performed using the \textbf{NumPy} library, and the simulation of the asynchronous distributed computing environment was implemented using the \textbf{MultiProcessing} library, which enabled efficient inter-process data exchange.

All the experiments use randomly generated linear systems $Ax = b$ to evaluate the algorithm’s performance. The agent iteration and communication processes are separated, meaning the agent communication logic is independent of the iteration logic. This ensures that different designs of $\mathcal{T}_S$ do not affect the algorithm's iteration speed due to variations in communication frequency. To better validate the algorithm’s practical applicability, communication instructions are designed as short signal pulses. When the relevant agents’ communication processes detect this pulse, they execute the communication. This experimental setup is closer to real-world applications.

In the appendix, it is proven that the algorithm’s final convergence depends on the initial solution estimates of the agents, $x_i(t_{i,0})$. If $x_i(t_{i,0}) \in \text{Row} (A)$, the algorithm will converge to the minimum-norm solution $x^*$. Therefore, in this paper, each agent’s initial solution is initialized as $x_i(t_{i,0}) = 0$.

\subsection{Convergence Experiment}

Now, we first verify the convergence of the iteration formats \eqref{eq:The iterative format for solving the compatibility problem.} and \eqref{eq:The iterative format for solving the incompatibility problem.} across different problems. In this experiment, the \textbf{broadcast clock} scheme is used  to design $\mathcal{T}_S$, with $\Delta T = 0.5s$. The probability of communication failure between agents is set to $0.3$, simulating the effects of typical network fluctuations on agent communication. All agents begin work simultaneously.

A linear system of equations with different characteristics is solved using \eqref{eq:The iterative format for solving the compatibility problem.} and \eqref{eq:The iterative format for solving the incompatibility problem.},repectively. For the consistent system, where the iteration\eqref{eq:The iterative format for solving the compatibility problem.} is used, 15 agents are used to solve a $50000 \times 5000$ system of equations with rank $4900$ and a sparse system of the same size with a density of $0.1$. Each agent stops when $\|x_i - x^*\|_\infty$ reaches $10^{-3}$. For the experiment of iteration \eqref{eq:The iterative format for solving the incompatibility problem.}, the same number of agents are used to solve the above problems with a disturbance being added to the right-hand side $b$ to make the system inconsistent.In this case,all the agents run for $60s$ before stopping and the changes in $\|x_i - x^*\|_\infty$ for some agents are recorded and visualized in Figure \ref{fig:2}.
\begin{figure}[h]
    \centering
    \includegraphics[width=1\linewidth]{Results_of_the_convergence_verification_experiment.pdf}
    \caption{Convergence Results of the proposed Algorithm}
    \label{fig:2}
\end{figure}

After performing multiple trials, the average computation time for each agent to solve the non-sparse compatibility problem is approximately $3.5s$, with no significant difference when solving the sparse problem. Upon closer inspection of Figure \ref{fig:2}, it is evident that the number of iterations varies among different agents, reflecting the asynchronous nature of the algorithm. Further analysis of the \eqref{eq:The iterative format for solving the incompatibility problem.} experiment results in Figure \ref{fig:2} shows that \eqref{eq:The iterative format for solving the incompatibility problem.} can stably converge on regular inconsistent equations and approximate the solution $x^*$. With the same number of iterations, \eqref{eq:The iterative format for solving the incompatibility problem.} achieves performance similar to \eqref{eq:The iterative format for solving the compatibility problem.}, and the changes in \eqref{eq:Augmented system.} do not lead to a loss of efficiency. In contrast, \eqref{eq:The iterative format for solving the incompatibility problem.} does not stably converge on sparse inconsistent equations but still manages to find an approximation to $x^*$. As iterations progress, it becomes clear that the algorithm is gradually reducing the error. However, due to the ill-conditioning of the system, $\epsilon$ becomes less effective at eliminating the impact of $\Tilde{b}_i(t_{i,k})$, requiring more time for the algorithm to stabilize.


\subsection{Robustness Experiment}

As we know, algorithm design in asynchronous environments usually focuses more on making algorithms adaptable to the highly complex environment brought by asynchrony, and making them highly robust.  If an algorithm demonstrates strong robustness in the presence of issues such as communication failures or agent faults, it typically exhibits high practical value. To test the robustness of the algorithm proposed in this paper, we simulated three complex scenarios encountered in the actual running environment: high asynchrony in agent computation, communication failures due to instability in the communication environment, and agent exits from system communication caused by agent failures.  This paper focuses only on the robustness of \eqref{eq:The iterative format for solving the compatibility problem.}, as \eqref{eq:The iterative format for solving the incompatibility problem.} and \eqref{eq:The iterative format for solving the compatibility problem.} share similar structures.

\subsubsection{High Asynchrony Environment}

In an asynchronous environment, where the execution order and timing of tasks are unpredictable, the algorithm must be able to adapt to unsynchronized inputs and uncertain execution delays. To evaluate the adaptability of \eqref{eq:The iterative format for solving the compatibility problem.} to asynchronous environments, this experiment designs the agents to start sequentially at random time intervals. In the convergence experiment, all agents were initially synchronized, but since the agents operate independently, Figure \ref{fig:2} shows that the agents are asynchronous, and the algorithm still converges in this mild asynchronous environment. When agents are designed to start at random time intervals, the asynchronous effect becomes more pronounced. If the algorithm still converges, it then demonstrates the algorithm's robustness to asynchronous environments. In this experiment, 15 agents are still used to solve the same $50000 \times 5000$ system with rank $4900$ as in the \textit{Convergence Experiment}. Each agent stops when its error norm reaches $10^{-3}$, and the variations in $\|x_i\|_\infty$ and $\|x_i - x^*\|_\infty$ for selected agents are plotted, along with the time taken for each agent to meet the stopping criterion, as shown in Figure \ref{fig:3}. The remaining design is consistent with that of the \textit{Convergence Experiment}.

\begin{figure}[h]
\centering
\includegraphics[width=1\linewidth]{Results_of_the_asynchronous_start_experiment.pdf}
\caption{Agent behavior in a highly asynchronous environment. The bar chart represents the runtime from an agent's activation to meeting the stopping criterion, excluding idle times. The x-axis in the infinity norm plots indicates the number of iterations taken from an agent's activation to its termination.}
\label{fig:3}
\end{figure}

The results show that the algorithm can still converge in high asynchrony environments. The norm and error variation plots in Figure \ref{fig:3} indicate that agents who start early are unable to converge to the global solution, as they cannot access information from agents that have not yet started. As more agents gradually join the communication network, the agents continuously adjust their solutions through information exchange, ultimately causing the algorithm to converge to the global solution. Comparing this with the same problem in the \textit{Convergence Experiment}, it is found that the late joiners took approximately $2.1s$ to converge, which is even faster than the $3.5s$ taken by the synchronously started agents. This is because the late joiners benefit from better states provided by the early agents through communication. These states have been refined by the early agents through both communication and their own iterations, making them of higher quality and enabling the late joiners to more effectively adjust their solution estimates.

\subsubsection{Unstable Communication Environment}

Although the global broadcast clock makes the design of $\mathcal{T}_S$ highly efficient, in real-world applications, the communication environment is not always stable. Therefore, it is important to verify whether the algorithm remains feasible under extreme communication conditions. To assess the algorithm's robustness in such environments, this experiment simulates both stable and unstable communication environments. In the unstable environment, agents have a $0.9$ probability of failure when sending information to a fixed agent, with delays ranging from 0 to 0.5 seconds. The stable environment follows the same setup as in the \textit{Convergence Experiment}. The experiment still uses 15 agents to solve a $50000 \times 5000$ system with rank $4900$. All agents start simultaneously, and each stops when $\|x_i - x^*\|_\infty$ reaches $10^{-3}$. The variations in $\|x_i - x^*\|_\infty$ for some agents, as well as the communication paths between agents, are plotted, with thicker paths indicating more frequent information transmission. The results are visualized in Figure \ref{fig:4}. The remaining design follows that of the \textit{Convergence Experiment}.
\begin{figure}[h]
\centering
\includegraphics[width=1\linewidth]{Results_of_the_communication_instability_experiment.pdf}
\caption{Comparison of Algorithm Convergence in Stable vs. Unstable Communication Environments. In the network diagram, thicker paths indicate more frequent transmissions.}
\label{fig:4}
\end{figure}

In a normal communication environment, the average runtime for each agent is approximately $3.5s$, which corresponds to the conclusions of the convergence experiment. In contrast, in an unstable communication environment, the runtime increases to $4.6s$. From Figure \ref{fig:4}, we can see that in an extremely unstable communication environment, the algorithm’s convergence speed is impacted, but it still converges. Examining the communication graph, it is evident that in the unstable communication environment, the communication intensity between agents is noticeably reduced. With less information exchange and a more disordered flow of information, the convergence becomes slower. However, since the communication graph remains connected, the algorithm still converges.

\subsubsection{Agent Failure}

In practical applications of distributed algorithms, it is not uncommon for agents to exit the computation midway, whether due to failure or human intervention. In the theory of asynchronous algorithms, an agent $i$ exiting midway can be interpreted as having a $k$ in $\mathcal{T}_i$ such that $t_{i,k+1} - t_{i,k}$ is large or infinite. Studying asynchronous algorithms that maintain robustness and efficiency in such scenarios is essential for improving fault tolerance in distributed systems and enhancing the operability of real-world applications. In this experiment, a random pause mechanism is introduced to simulate the potential failures that agents may encounter during operation. Some agents are randomly paused for a certain period with a certain probability. During the pause, these agents do not participate in communication, and any communication attempts are treated as failures. The remaining active agents continue the computation. In this experiment, 15 agents collaborate to solve a problem with rank 4900 and size $50000 \times 5000$. Half of the agents may fail, while the other half continue running. All agents start synchronously, and the computation stops when the error norm reaches $10^{-3}$. The variations in $\|x_i - x^*\|_\infty$ and $\|x_i\|_\infty$, the communication graph between agents, and the bar chart of agent runtimes are visualized in Figure \ref{fig:5}. The rest of the experimental design follows the setup of the \textit{Convergence Experiment}.

\begin{figure}[h]
\centering
\includegraphics[width=1\linewidth]{Results_of_the_agent_failure_experiment.pdf}
\caption{Experimental results under agent failure scenarios. Red nodes in the communication graph denote failed agents. In the bar chart, red bars represent failed agents, with their downtime excluded from the runtime.}
\label{fig:5}
\end{figure}

The experimental results indicate that, due to the lack of information or outdated information from failed agents, the remaining active agents take longer to run. In contrast to the control group in the \textit{Unstable Communication Environment} experiment, when the failed agents rejoin the iteration, they receive improved solution estimates from the active agents, which results in shorter runtimes. Examining the communication graph, although the exit of the failed agents reduces the exchange of information, the communication graph remains connected, and the agents still converge, demonstrating the algorithm’s strong robustness.

The experiment highlights that, in addition to its strong robustness, this characteristic of the algorithm allows users to pause agents as needed in specific scenarios while the algorithm continues to run. For example, if multiple users provide filtered data to the agents according to their requirements, and no further data input is needed, the agents can exit the system at an appropriate time. The algorithm can still integrate the available information through communication and find the optimal global solution based on this information, greatly enhancing the system's operability for users.

\subsection{Comparison Experiment}

In the convergence experiment, the design of the broadcast clock endows the algorithm with strong exponential convergence properties. As mentioned earlier, the design of $\mathcal{T}_S$ has a significant impact on both the convergence speed and communication overhead of the algorithm. An overly dense $\mathcal{T}_S$ design results in wasted communication resources, while a sparser design may fail to ensure the connectivity of the communication graph. This experiment aims to design different $\mathcal{T}_S$ strategies and compare the convergence behavior and communication overhead of the algorithm under each design. We evaluate the algorithm's convergence capability by measuring the average time taken for each agent to reach an error norm of $10^{-3}$, referred to as the average convergence time. Let $Num_{i,j}$ denote the number of times agent $i$ transmits information to agent $j$ during the algorithm’s execution. We define $Num = \frac{\overset{N}{\sum\limits_{i=1}}\sum\limits_{j \neq i} Num_{i,j}}{N(N-1)}$ as the average number of successful transmissions on each directed edge, which quantifies the algorithm's communication overhead. It is  called the average transmission count.

In this experiment, we use two different $\mathcal{T}_S$ design approaches discussed earlier. Each approach is tested with 5 different parameter sets, resulting in a total of 10 experiments for comparison. Each experiment involves 15 agents solving the same $50000 \times 5000$ problem with rank 4900. First, using the \textbf{broadcast clock} approach, which is refered to as the centralized broadcasting, we set $\Delta T$ to $5, 1, 0.5, 0.1, 0.05$ seconds and compare the algorithm's average convergence time and average transmission count. Second, using the approach from literature~\cite{Liu2018Asynchronous}, we set $\Delta k = 99, 49, 9, 4, 0$ iterations to correspond to broadcasting information after each set of iterations, which is called as the decentralized broadcasting. An interval of 0 means that each agent broadcasts information after every iteration, following the design in literature~\cite{Liu2018Asynchronous}. Finally, all results are visualized in Figure \ref{fig:6}.


\begin{figure}[h]
\centering
\includegraphics[width=1\linewidth]{Summary_of_the_results_from_the_comparison_experiment.pdf}
\caption{Comparison of Convergence Time and Communication Overhead}
\label{fig:6}
\end{figure}

It is clear that a well-designed $\mathcal{T}_S$ can simultaneously enhance the algorithm's convergence capability and reduce communication costs between agents. For example, in centralized broadcasting with $\Delta T = 0.5$, there is a good balance between convergence ability and communication cost. If the $\mathcal{T}_S$ is designed too sparse, even though communication costs are minimal, the joint strong connectivity condition of the communication network becomes harder to maintain, resulting in reduced convergence performance. For instance, with $\Delta T = 5s$ in centralized broadcasting, the convergence performance declines. However, an overly dense design of $\mathcal{T}_S$ is the most detrimental, not only causing a decline in the convergence ability of the algorithm, but also wasting a lot of communication resources, such as $\Delta T=0.05s $ in centralized broadcasting and $\Delta k=0 $ in decentralized broadcasting. This is because, when the design of $\mathcal{T}_S$ is too dense, the information received by the agent is also dense, and each iteration takes longer to process. This highlights that unreasonable communication strategies increase both communication costs and computational overhead.

In addition to the centralized broadcasting scheme with $\Delta T = 0.5$, Figure \ref{fig:6} also presents several other well-designed $\mathcal{T}_S$ schemes. For instance, in decentralized broadcasting, when agents broadcast information every $99$ or $49$ iterations, this approach is more feasible in practical applications compared to the "broadcast clock" design.

\section{Conclusion}

This paper presents an asynchronous distributed stochastic block Kaczmarz projection algorithm for solving  large-scale linear system of equations, which is suited for the multi-agent networks. An event-triggered communication mechanism is designed to reduce communication overhead and  the overall communication costs in an asynchronous environment, while maintaining the global convergence of the algorithm. Through mathematical analysis, the paper demonstrates the algorithm's exponential convergence in consistent systems and extends it to inconsistent systems by introducing auxiliary variables, ensuring convergence to an approximate least-squares solution. Numerical experiments validate the algorithm's computational efficiency, robustness, and communication efficiency, showing that it remains stable in extreme asynchronous conditions, communication failures, and node faults. Compared to traditional methods, it achieves faster convergence. Moreover,this study's exploration and attempt in communication strategies for distributedly solving large-scale linear systems provides new insights for further optimizing communication strategies and enhancing algorithm adaptability in the future.

In addition, all the numerical experiments designed 15 agents to solve a system of equations with dimensions of $50000 \times 5000$, where on average, each agent needs to process $3333$ equations.This mainly considers the data processing capability of a single agent, the convergence conditions and all possible uncertainties that may occur.It must be pointed out that the number of agents involved in the computation has a significant impact on the efficiency of problem solving, which is directly related to the scale of the problem. Determining the appropriate number of agents based on the scale of the problem, and devising communication strategies when the information allocated to each agent is imbalanced, as well as a more efficient algorithm for inconsistent system without auxiliary variables, are topics that we need to further investigate in the future. 


%% The Appendices part is started with the command \appendix;
%% appendix sections are then done as normal sections
\appendix
\section{Proof of Theorems}
\label{app1}

This part is devoted to the proof of Theorem 1 and Theorem 2.
We begin with some explications about our proof.

Ref.~\cite{Liu2018Asynchronous} and~\cite{Yi2020Distributed} respectively provide convergence proofs for asynchronous algorithms and random projection algorithms. Besides,in ~\cite{Liu2017Exponential}, the authors use the graph-related work discussed in ~\cite{doi:10.1137/060657005} and apply control theory to prove the convergence of the algorithm. In fact,the asynchronous algorithm discussed in ~\cite{Liu2018Asynchronous} can be seen as an extension of the synchronous case presented in ~\cite{Liu2017Exponential}. Based on this fact and the proof idea presented in the aforementioned article, by utilizing \eqref{eq:Time-varying autonomous discrete linear system.}, we can  transform the iteration format \eqref{eq:The iterative format for solving the compatibility problem.} into a nonlinear time-varying autonomous discrete system with random delays. Then, using the boundedness of $\delta_{j,i}(t_{i,k})$, the system can be transformed into a standard linear discrete system that analyzes the maximum possible length of the delay sequence. In the communication graph, one agent represents a node, but in this case, each agent represents multiple nodes, with the various nodes representing the agent's states under different time delays. For example, for a given $\tau_s \in \mathcal{T}$, we consider a fixed-length state sequence $\{x_i(\tau_s), x_i(\tau_s-1), \cdots, x_i(\tau_{s-d+1})\}$ for agent $i$, with the sequence length accounting for all possible values of $\delta_{j,i}(t_{i,k})$. Each state in this sequence corresponds to a node. We refer to this sequence as the \textbf{delay sequence} at time $\tau_s$.

If the delay sequence length is $d$, the transformed system is similar to the system discussed in ~\cite{Yi2020Distributed}, which focuses on random projection consensus for a system of $dN$ nodes. This requires an analysis on the joint connectivity of this extended communication graph and a method  is provided in Ref.~\cite{Cao2008Reaching} for analyzing the joint connectivity of graphs composed of such node sequences.
%, and ~\cite{Yi2020Distributed} proves the convergence of the random projection algorithm.
 Our proof utilizes parts of their methods. Before proving the theorem, we first present some necessary preparations: \textit{state-space equations}, \textit{strict contraction conditions}, and the \textit{expanded delay graph}, followed by the unified proof of the two theorems.

\subsection{State-Space Equations}

First, we express the iteration format \eqref{eq:The iterative format for solving the compatibility problem.} as two time-varying discrete linear systems, which provides the state transition equations for the delay sequence. Here, we attempt to decompose the original system and present a more general proof of convergence. The original iteration format \eqref{eq:The iterative format for solving the compatibility problem.} is defined in $\mathbb{R}^{Nn}$, focusing on the entire delay sequence, and we define the state space as $\mathbb{R}^{dNn}$. Let $x^{\mathbf{*}} = A^\dagger b$, which ensures that \eqref{eq:Time-varying autonomous discrete linear system.} holds.

We now introduce a series of definitions. Denote
\[
    P_i(\tau) =
    \begin{cases}
        P_i(t_{i,k}), & \text{if } t_{i,k} = \tau, \\
        I_n, & \text{otherwise.}
    \end{cases}
\]
Let $P(\tau)=\text{diag}\left(P_1(\tau), \dots, P_N(\tau)\right)$ and define the block diagonal projection matrix 
$$\mathbf{P}(\tau_k) = \text{diag}\left(P(\tau_k), \dots, P(\tau_{k-d-1})\right).$$
 It is easy to verify that $\mathbf{P}^2(\tau_k) = \mathbf{P}(\tau_k)$. Let $e_i(\tau) = x_i(\tau) - x^{\mathbf{*}}$, and define the error vector $e(\tau) = \left[e_1(\tau)^T, \dots, e_N(\tau)^T\right]^T$, and the error vector for the delay sequence as $\mathbf{e}(\tau) = \left[e^T(\tau), \dots, e^T(\tau - d + 1)\right]^T$, where $e(\tau) \in \mathbb{R}^{Nn}$ and $\mathbf{e}(\tau) \in \mathbb{R}^{dNn}$. The subsequent proof will focus on the convergence of $\mathbf{e}(\tau)$. Finally, we define the information exchange matrix for the delay sequence as $W(\tau)$, where the elements of $W(\tau)$ are defined as follows:
\[
    W_{i,j}(\tau) =
        \begin{cases}
        \frac{1}{m_i(\tau)}, & \text{if } i \in \{1, 2, \cdots, N\}, \ \exists k \text{ such that } t_{i,k}  = \tau, \text{ and } j \in \mathcal{N}_i(\tau), \text{ and } i \text{ receives}  \text{information from } j \\
        & \quad \quad \quad \quad \quad \text{ at time } \tau - \frac{s-j}{N} + 1, 1, \text{if } i \in \{1, 2, \cdots, N\}, \ i = j, \text{ and } \forall k,  t_{i,k} \neq \tau, \\
        1, & \text{if } i = s + ln, \ j = s + (l-1)n, \ \text{for } s \in \{1, 2, \cdots, N\}, \text{ and } l \in \{1, 2 , \cdots, d-1\}, \\
        0, & \text{otherwise}.
    \end{cases}
\]
Here, $W(\tau)$ is defined similarly as in the literature~\cite{Liu2018Asynchronous}, and the graph formed by this link matrix corresponds to the extended delay graph discussed there.

Based on the above definitions, we rewrite \eqref{eq:The iterative format for solving the compatibility problem.} as:
\begin{equation}
    \mathbf{e}(\tau_{k+1}) = \mathbf{P}(\tau_k) \left(W(\tau_k) \otimes I_n\right) \mathbf{P}(\tau_{k-1}) \mathbf{e}(\tau_k).
    \label{eq:Undecomposed system.}
\end{equation}
Equation \eqref{eq:Undecomposed system.} represents a time-varying autonomous discrete system, where the sequence $\tau_0, \cdots, \tau_{k-1}, \tau_k, \tau_{k+1}, \cdots$ belongs to the set $\mathcal{T}$.

Considering the generality of $A$, we decompose \eqref{eq:Undecomposed system.} to facilitate a partial analysis of convergence. We decompose the space of $e_i$ as $\mathbb{R}^n = \text{Row}(A) \oplus \text{Row}_\perp(A)$, and similarly, $\mathbb{R}^{dNn}$ can be decomposed as $\left[\text{Row}(A)\right]^{dN} \oplus \left[\text{Row}_\perp(A)\right]^{dN}$. Thus, $\mathbf{e}(\tau) = \mathbf{e}_1(\tau) + \mathbf{e}_2(\tau)$, where $\mathbf{e}_1(\tau) \in \left[\text{Row}(A)\right]^{dN}$ and $\mathbf{e}_2(\tau) \in \left[\text{Row}_\perp(A)\right]^{dN}$. Therefore, the system \eqref{eq:Undecomposed system.} is decomposed into the following subsystems:
\begin{equation}
    \mathbf{e}_1(\tau_{k+1}) = \mathbf{P}(\tau_k) \left(W(\tau_k) \otimes I_n\right) \mathbf{P}(\tau_{k-1}) \mathbf{e}_1(\tau_k), \text{ and }
    \label{eq:Decomposition 1.}
\end{equation}
\begin{equation}
    \mathbf{e}_2(\tau_{k+1}) = \mathbf{P}(\tau_k) \left(W(\tau_k) \otimes I_n\right) \mathbf{P}(\tau_{k-1}) \mathbf{e}_2(\tau_k)
    \label{eq:Decomposition 2.}.
\end{equation}
Since $\text{Row}_\perp(A)$ is the null space of $A$, for any $\mathbf{y} \in \text{Row}_\perp(A)$ and any block $A_{\mathcal{I}}$ of $A$, we have $\left(I_n - A_{\mathcal{I}}^\dagger A_{\mathcal{I}}\right)\mathbf{y} = \mathbf{y}$. Therefore, using the definition of $\mathbf{P}(\tau_k)$, we simplify the system \eqref{eq:Decomposition 2.} as follows:
\begin{equation}
    \mathbf{e}_2(\tau_{k+1}) = \left(W(\tau_k) \otimes I_n\right)\mathbf{e}_2(\tau_k)
    \label{eq:Standard consensus system.}.
\end{equation}
Let $P_A(\tau_k)$ denote the restriction of $P(\tau_k)$ onto $\text{Row}(A)$, and define $\mathbf{P}_A(\tau_k) = \text{diag}\left(P_A(\tau_k), \dots, P(\tau_{k-d-1})\right)$. It is easy to observe that $\mathbf{P}_A(\tau_k)$ is the restriction on $\left[\text{Row}(A)\right]^{dN}$, so we rewrite system \eqref{eq:Decomposition 1.} in a more convenient form for analysis:
\begin{equation}
    \mathbf{e}_1(\tau_{k+1}) = \mathbf{P}_A(\tau_k) \left(W(\tau_k) \otimes I_n\right) \mathbf{P}_A(\tau_{k-1}) \mathbf{e}_1(\tau_k).
    \label{eq:Projection consensus system.}
\end{equation}
The system \eqref{eq:Standard consensus system.} can be analyzed by examining the connectivity of the graph generated by $W(\tau_k)$, while \eqref{eq:Projection consensus system.} can be studied by analyzing the spectrum of the following matrix for convergence. 
\begin{equation}
    M_A = \mathbf{P}_A(\tau_s) \left(W(\tau_s) \otimes I_n\right) \mathbf{P}_A(\tau_{s-1}) \left(W(\tau_{s-1}) \otimes I_n\right) \cdots \mathbf{P}_A(\tau_{1}) \left(W(\tau_{1}) \otimes I_n\right) \mathbf{P}_A(\tau_0),
    \label{eq:State transition matrix.}
\end{equation}
Here, $M_A$ is a block matrix composed of the product of projection matrices on the restriction to $\text{Row}(A)$.

\subsection{Strict Contraction Condition}

A mixed matrix norm has been discussed in the literature~\cite{Liu2017Exponential, Liu2018Asynchronous} and ~\cite{Yi2020Distributed} for constructing system convergence. Its construction is as follows: Let $A = \left[A_{ij}\right]_{dm \times dm}$, where $A_{ij}$ is an $n$-dimensional square matrix. Then,the mixed norm of matrix $A$ is defined as $\left\| A\right\|_{mix} = \left\|\left[\left\|A_{ij}\right\|_2\right]\right\|_\infty$. This norm, in combination with Lemma 2 from~\cite{Liu2018Asynchronous}, plays a critical role in the proof. The basic idea is to construct a product of orthogonal projection matrices that include all the sub-blocks generated by $A$ for each row block in $M_A$. However, Lemma 2 in ~\cite{Liu2018Asynchronous} has a limitation that it assumes $A$ is full-rank. Although the non-full-rank case is discussed, no clear mathematical proof is given. This paper aims to extend the definition of $\left\|\cdot\right\|_{mix}$ and provide a general proof.

To this end, we define the mixed matrix norm on $\left[\text{Row}(A)\right]^{dN}$ as $\left\|\cdot\right\|^A_{mix}$. Let $\left\|\cdot\right\|_2^A$ be the derived matrix 2-norm on $\text{Row}(A)$, i.e., $$\left\|P\right\|_2^A = \max\left\{\left\|Px\right\| : x \in Row(A), \|x\| = 1\right\}.$$
 Let $P = \left[P_{ij}\right]_{dm \times dm}$, where $P_{ij}$ is an $n$-dimensional square matrix, then $\left\| P\right\|^A_{mix} = \left\|\left[\left\|P_{ij}\right\|_2^A\right]\right\|_\infty$.

Using functional analysis theory, it is easy to verify that $\left\|\cdot\right\|^A_{mix}$ satisfies all properties of the operator norm on $\left[\text{Row}(A)\right]^{dN}$. 
The mixed matrix norm in~\cite{Liu2018Asynchronous} is clearly the operator norm on $\mathbb{R}^{dNn}$, and by functional analysis theory, it corresponds to a vector norm $\left\|\cdot\right\|_{mix}$.
It can be shown that for any $x \in \mathbb{R}^{dNn}$, if $x = \left[x_1^T, x_2^T, \dots, x_{dN}^T\right]^T$, then $\left\|x\right\|_{mix} = \max\limits_i \|x_i\|$, and if $x \in [\text{Row}(A)]^{dN}$, $\|x\|_{mix}^A = \|x\|$. Therefore, the vector norm corresponding to $\left\|\cdot\right\|_A$ is also of the above form. Next, we extend some tools defined in~\cite{Liu2018Asynchronous}.

Let $P_{\mathcal{I}} = I_n - A_{\mathcal{I}}^\dagger A_{\mathcal{I}}$, where $\mathcal{I} \subseteq \mathbf{m}_i$, and $A_{\mathcal{I}}$ represents the corresponding row block matrix. Let $P_{\mathcal{I}}^A$ be the restriction of $P_{\mathcal{I}}$ on $\text{Row}(A)$. Define the projection matrix polynomial on $\text{Row}(A)$ as:
\[
\mu = \sum_{q=1}^c \lambda_q P_{\mathcal{I}_{q(1)}}^A P_{\mathcal{I}_{q(2)}}^A \cdots P_{\mathcal{I}_{q(p_q)}}^A.
\]
Here, $c$ represents the number of terms in the polynomial, and $\lambda_q$ is the coefficient of the $q$-th term. Each term consists of the product of a series of projection matrices $P_{\mathcal{I}_{q(i)}}^A$. The index $i$ ranges from 1 to $p_q$, where $p_q$ is the number of projection matrices in the $q$-th term, and $\mathcal{I}_{q(i)}$ refers to the subset of row vector indices corresponding to the $i$-th projection matrix in the $q$-th term. Define $\lceil \mu \rceil = \sum_{q=1}^c \lambda_q$, and for any $\mu_1$ and $\mu_2$, we have $\lceil \mu_1 \mu_2 \rceil = \lceil \mu_1 \rceil \lceil \mu_2 \rceil$, and $\lceil \mu_1 + \mu_2 \rceil = \lceil \mu_1 \rceil + \lceil \mu_2 \rceil$. Additionally, for any $\mu$, we have $\|\mu\|_2^A \leq \lceil \mu \rceil$. Let $\mathcal{L}(A)$ be the set composed of all the index sets of the largest linearly independent combinations of row vectors of $A$, where for each element $S \in \mathcal{L}(A)$, we have $S \subseteq \mathbf{m}$, and  it corresponds to a maximal linearly independent group of row vectors of $A$. %To ensure the inequality is strictly less, 
Now, we present an extension of Lemma 2 in~\cite{Liu2018Asynchronous}.

\textbf{Lemma 1:} Let \( \mathbb{I} \) be a set composed of some subsets of index set \( \mathbf{m} \), and \( \mathcal{I} \in \mathbb{I} \). If there exists \( S \in \mathcal{L}(A) \) such that \( S \subseteq \bigcup\limits_{\mathcal{I} \in \mathbb{I}} \mathcal{I} \), then:
\[
\left\|\prod\limits_{\mathcal{I} \in \mathbb{I}} P_{\mathcal{I}}^A \right\|_2^A < 1.
\]

\begin{proof}
For any \( S \in \mathcal{L}(A) \), it holds that \( \text{Row}(A) = \text{span} \left\{ \alpha_h \ \middle| \ h \in S \right\} \).  
By the non-expansive property of projection operators, for any \( x \in \text{Row}(A) \) with \( \|x\|_2=1 \), we have:
\[
\left\|\left( \prod\limits_{\mathcal{I} \in \mathbf{I}} P_{\mathcal{I}}^A \right) x \right\|_2 \leq 1.
\]

Define \( \prod\limits_{\mathcal{I} \in \mathbf{I}} P_{\mathcal{I}}^A=P_{\mathcal{I}_l}^A\cdots P_{\mathcal{I}_1}^A \).  
If the equal sign in the above inequality holds, then due to the non-increasing nature of projection operators, for any \( 2 \leq s \leq l \), we must have:
\[
\left\|\left(\overset{s}{\prod\limits_{t=1}}P_{\mathcal{I}_t}^A\right)x\right\|_2=\left\|\left(\overset{s-1}{\prod\limits_{t=1}}P_{\mathcal{I}_t}^A\right)x\right\|_2=\|x\|_2=1.
\]
We now use induction to show that in this case,with \( x \in \text{Row}(A) \) and \( \|x\|_2=1 \), it must have $x\perp\alpha_h, h\in\overset{l}{\bigcup\limits_{t=1}}\mathcal{I}_t $.


First, for $s=1$, we can immediately obtain that  $x\perp\alpha_h, \\ h\in\mathcal{I}_1$.  
Now assume that for some \( s-1 \), we have $$x\perp\alpha_h,h\in\overset{s-1}{\bigcup\limits_{t=1}}\mathcal{I}_t.$$  
Then it follows from 
$\left\|\left(\overset{s}{\prod\limits_{t=1}}P_{\mathcal{I}_t}^A\right)x\right\|_2=\left\|\left(\overset{s-1}{\prod\limits_{t=1}}P_{\mathcal{I}_t}^A\right)x\right\|_2$
 that  
\[
\left(\left(\overset{s-1}{\prod\limits_{t=1}}P_{\mathcal{I}_t}^A\right)x\right)\perp\alpha_h, h\in\mathcal{I}_s.
\]
Note that  \( \left(\overset{s-1}{\prod\limits_{t=1}}P_{\mathcal{I}_t}^A\right)x = x \), it then follows 
%\[
 $x\perp\alpha_h,h\in\mathcal{I}_s.$
%\]
Hence, $x\perp\alpha_h,h\in\overset{s}{\bigcup\limits_{t=1}}\mathcal{I}_t.$
By induction, the claim follows.  

Since \( S \subseteq \bigcup\limits_{\mathcal{I} \in \mathbf{I}}\mathcal{I} \), it follows that  
\[
x \in \text{Row}(A)\cap \text{Row}_\perp(A),
\]
which implies \( x=0 \), this is  a contradiction.  
Thus, for any \( x \in \text{Row}(A) \) with \( \|x\|_2=1 \), we obtain:
\[
\left\|\left( \prod\limits_{\mathcal{I} \in \mathbf{I}} P_{\mathcal{I}}^A \right) x \right\|_2 < 1.
\]
Hence,  
\[
\left\|\prod\limits_{\mathcal{I} \in \mathbf{I}} P_{\mathcal{I}}^A \right\|_2^{A} < 1.
\]\end{proof}


\textbf{Lemma 1} indicates that \( \|\mu\|_2^A < \lceil \mu \rceil \) if and only if there is a component of \( \mu \) for which the row blocks of \( A \) used to construct it contain a maximal linearly independent set of rows from \( A \). Such projection matrix polynomials are termed complete. Define \( \mathcal{P}^i \) as the set of all projection matrices derived from the possible row blocks of \( A_i \). A sequence in \( \mathcal{P}^i \) is considered complete if the row vectors generating it include a maximal linearly independent set for \( A_i \). Let \( n \) be an integer, and let \( \mathcal{P}^i_n \) denote the subset of sequences in \( \mathcal{P}^i \) such that every subsequence of length \( n \) is complete. It is evident that \( n_1 \leq n_2 \) implies \( \mathcal{P}^i_{n_1} \subseteq \mathcal{P}^i_{n_2} \).

Additionally, define the projection polynomial matrix \( U = \left[\mu_{ij}\right]_{dm \times dm} \), with \( \lceil U \rceil = \left[\lceil \mu_{ij}\rceil\right]_{dm \times dm} \). Using the identities \( \lceil \mu_1 \mu_2 \rceil = \lceil \mu_1 \rceil \lceil \mu_2 \rceil \) and \( \lceil \mu_1 + \mu_2 \rceil = \lceil \mu_1 \rceil + \lceil \mu_2 \rceil \), it is straightforward to verify \( \lceil U_1 U_2 \rceil = \lceil U_1 \rceil \lceil U_2 \rceil \).

Based on the above definitions, we introduce a result analogous to Proposition 1 from~\cite{Liu2018Asynchronous}, aimed at establishing the strict contraction property of \( M \):

\textbf{Proposition 1:} \( \|U\|^A_{mix} < \|\lceil U \rceil\|_\infty \iff \) every row block of \( U \) contains at least one complete projection matrix polynomial.
\begin{proof}
    By \textbf{Lemma 1}, this condition is equivalent to requiring that in \( \left[\left\|P_{ij}\right\|_2^A\right]_{dm \times dm} \), each row has at least one element strictly less than the corresponding element in \( \lceil U \rceil \). Hence, the proposition is straightforward to verify.
\end{proof}
Given that \( \lceil U_1 U_2 \rceil = \lceil U_1 \rceil \lceil U_2 \rceil \) and \( \lceil P \rceil = I_{dm \times dm} \), it follows that \( \lceil M_A \rceil = \lceil W(\tau_s) W(\tau_{s-1}) \cdots W(\tau_1) \rceil \). Since \( W(\tau_s) W(\tau_{s-1}) \cdots W(\tau_1) \) is a row-stochastic matrix, we deduce \( \Big\|\lceil M_A \rceil\Big\|_\infty = 1 \). Therefore, according to Proposition 1, if \( M_A \) satisfies \( \|M_A\|^A_{mix} < 1 \), and if this condition remains valid over time, the system \eqref{eq:Projection consensus system.} will converge.

\subsection{Extended Delay Graph}

This section presents the graph-theoretical framework for establishing convergence conditions, with a focus on the generating graph of \( W(\tau_k) \), referred to as the \textit{extended delay graph} in ~\cite{Liu2018Asynchronous}. This graph models the interactions and information exchange between agents based on their delay sequences. While the complete theory of the extended delay graph is elaborated in~\cite{Cao2008Reaching}, a brief overview is provided here for clarity.

Define \( \mathcal{G}_d(\tau) = \left(\mathcal{N}_d, \mathcal{V}_d(\tau)\right) \) as the extended delay graph of the system at time \( \tau \), where \( \mathcal{N}_d \) represents the set of nodes and \( \mathcal{V}_d(\tau) \) represents the set of edges. For a system with a bounded delay \( d \), the node set \( \mathcal{N}_i = \left\{i_0, i_1, \dots, i_{d-1}\right\} \) corresponds to the states in the delay sequence of agent \( i \). Specifically, \( i_s \) represents the \( s+1 \)-th state in the sequence, and \( i_0 = i \), where \( i \in \mathcal{N} \). Thus, \( \mathcal{N}_d = \bigcup\limits_{i \in \mathcal{N}(\tau)} \mathcal{N}_i \).

The edge set \( \mathcal{V}_d(\tau) \) is constructed as follows: Given \( \mathcal{A}(\mathcal{G}(\tau)) = W(\tau_k) \), the edges include \( (i_s, i_{s+1}) \) to represent transitions within an agent's delay sequence, \( (i, i) \) as self-loops, and \( (j_s, i) \) if agent \( i \) at time \( \tau \) depends on the \( s+1 \)-th state of agent \( j \)'s delay sequence.

This section introduces several fundamental concepts associated with the extended delay graph.

We first define the \textit{agent subgraph} and \textit{quotient graph}, as presented in~\cite{Cao2008Reaching}. The quotient graph \( \mathcal{Q}(\tau) \) of \( \mathcal{G}_d(\tau) \) is a directed graph with a node set \( \mathcal{N} \). For any nodes \( i \) and \( j \), if there exists \( i_s \in \mathcal{N}_i \) and \( j_t \in \mathcal{N}_j \) such that \( i_s \) is connected to \( j_t \), then \( (i, j) \) is an edge in \( \mathcal{Q}(\tau) \). Meanwhile, the agent subgraph \( \mathcal{D}(\tau) \) is the subgraph induced by the subset \( \mathcal{N} \) within \( \mathcal{N}_d \).

Next, consider the concept of a \textit{root}, as defined in~\cite{Cao2008Reaching}. A node \( v \) in a directed graph \( \mathcal{G} \) is termed a \textit{root} if there exists a path from \( v \) to every other node in \( \mathcal{G} \). A directed graph \( \mathcal{G} \) is a \textit{hierarchical graph} if its nodes \( \{v_1, v_2, \cdots, v_n\} \) can be ordered such that \( v_1 \) is a root, and for any two nodes \( v_i \) and \( v_j \), the existence of a path from \( v_i \) to \( v_j \) implies \( j > i \). In this hierarchy, \( v_i \) is ranked higher than \( v_j \), and \( \{v_1, v_2, \cdots, v_n\} \) is referred to as the \textit{hierarchical structure} of \( \mathcal{G} \).

The definition of paths in a graph sequence, as outlined in~\cite{Yi2020Distributed}, is introduced here. In a sequence of directed graphs \( \mathcal{G}_1, \mathcal{G}_2, \cdots, \mathcal{G}_s \), a sequence of nodes \( j = v_{i_0}, v_{i_1}, \cdots, v_{i_s} = i \) is considered a path if and only if \( (v_{i_{k-1}}, v_{i_k}) \) is an edge in \( \mathcal{G}_k \). Reference~\cite{Yi2020Distributed} further states that if \( j = v_{i_0}, v_{i_1}, \cdots, v_{i_s} = i \) forms a path across \( \mathcal{G}_1, \mathcal{G}_2, \cdots, \mathcal{G}_s \), then the composed graph \( \mathcal{G}_s \circ \cdots \circ \mathcal{G}_2 \circ \mathcal{G}_1 \) includes the edge \( (i, j) \). Using this definition, ~\cite{Yi2020Distributed} derives the following lemma.

The concept of joint strong connectivity is also introduced. For a positive integer \( l \), a sequence of directed graphs \( \mathcal{G}_1, \mathcal{G}_2, \cdots, \mathcal{G}_k \) is defined as \( l \)-strongly connected if, for every consecutive subsequence of length \( l \), \( \mathcal{G}_{s+1}, \mathcal{G}_{s+2}, \cdots, \mathcal{G}_{s+l} \), the composed graph \( \mathcal{G}_{s+l} \circ \cdots \circ \mathcal{G}_{s+2} \circ \mathcal{G}_{s+1} \) is strongly connected.

The following lemmas are stated without proof, as they have been rigorously demonstrated in~\cite{Cao2008Reaching, Liu2018Asynchronous, Yi2020Distributed}.

\textbf{Lemma 2:}  
The composition of at least \( d-1 \) extended delay graphs is guaranteed to possess a strong root hierarchy.

\textbf{Lemma 3:}  
Let \( \mathcal{G}_d^p \) and \( \mathcal{G}_d^q \) represent extended delay graphs. If \( \mathcal{G}_d^p \)'s quotient graph is strongly connected and \( \mathcal{G}_d^q \) has a strong root hierarchy, then their composite graph \( \mathcal{G}_d^p \circ \mathcal{G}_d^q \) will contain a strongly connected agent subgraph.

\textbf{Lemma 4:}  
A composite graph formed by more than \( N-1 \) strongly connected directed graphs, each consisting of \( N \) nodes with self-loops at every node, is guaranteed to be fully connected.

\textbf{Lemma 5:}  
If \( n \geq (N-1)d \), the composition of \( n \) extended delay graphs with strongly connected quotient graphs must result in a complete agent subgraph.

\textbf{Lemma 6:}  
When more than \( d(n-1)^2 + d - 1 \) extended delay graphs are combined, the resulting composition is guaranteed to have a strong root structure.

\textbf{Lemma 7:}  
In the sequence of extended delay graphs \( \mathcal{G}_d(\tau_0), \mathcal{G}_d(\tau_1), \cdots, \mathcal{G}_d(\tau_s) \), if there exists a path \( {v^0}_{d_0}, {v^1}_{d_1}, \cdots, {v^s}_{d_s} \), then the entry in the \( d_sN + v^s \)-th row and \( d_0N + v^0 \)-th column of the matrix \( M_A \) contains the product \( \overset{s}{\prod\limits_{t=0}}P^A_{v^t}(\tau_{t-d_t}) \).

\subsection{Proof of Theorem 1}
Building on the tools discussed earlier, we now present the following proposition to establish the convergence of system  \eqref{eq:Projection consensus system.}.

\textbf{Proposition 2:}  
For a sequence of extended delay graphs \( \mathcal{G}_d(\tau_0), \mathcal{G}_d(\tau_1), \cdots, \mathcal{G}_d(\tau_s) \), suppose that the sequence is \( l \)-strongly connected and there exists \( \kappa \geq 1 \). Define \( \varrho \) as the least common multiple of \( \kappa \) and \( dl \), and let \( \omega = N\varrho \). For any \( i \in \mathcal{N} \), consider the sequence of projection matrices \( P_i^A(\tau_0), P_i^A(\tau_1), \cdots, P_i^A(\tau_s) \). If the subsequences \( P_i^A(\tau_{(j-1)\omega+1}), \cdots, P_i^A(\tau_{(j-1)\omega+\varrho}) \) \( (j \in \{1, 2, \dots, N\}) \), denoted as \( \mathcal{P}^{i,j} \), satisfy \( \mathcal{P}^{i,j} \in \mathcal{P}^i_\kappa \subseteq \mathcal{P}^i_\varrho \), then for \( s \geq ((N-1)N+2)\varrho \), the matrix \( M_A \) is guaranteed to be strictly contractive.

\begin{proof}
First, partition the graph sequence \( \mathcal{G}_d(\tau_1), \mathcal{G}_d(\tau_2), \cdots, \mathcal{G}_d(\tau_s) \) into subsets \( \mathbf{G}_i = \{\mathcal{G}_d(\tau_{(i-1)\omega+1}), \cdots, \mathcal{G}_d(\tau_{i\omega})\} \), where \( i \in \{1, 2, \cdots, N-1\} \), and \( \mathbf{G}_0 = \{\mathcal{G}_d(\tau_{(N-1)\omega+1}), \cdots,\mathcal{G}_d(\tau_s)\} \). Then further divide each \( \mathbf{G}_i \)  into \( \mathbf{G}_i^1 = \{\mathcal{G}_d(\tau_{(i-1)\omega+1}),\\ \cdots, \mathcal{G}_d(\tau_{(i-1)\omega+\varrho})\} \) and \( \mathbf{G}_i^2 = \{\mathcal{G}_d(\tau_{(i-1)\omega+\varrho+1}), \cdots, \mathcal{G}_d(\tau_{i\omega})\} \).

Consider \( \mathbf{G}_i^2 \) first. Since the original sequence is \( l \)-strongly connected, \textbf{Lemma 3} and \textbf{Lemma 4} guarantee that for any \( j \in \{1, 2, \cdots, N-1\} \), the composition \( \mathcal{G}_d(\tau_{(i-1)\omega+(j+1)\varrho}) \circ \cdots \circ \mathcal{G}_d(\tau_{(i-1)\omega+j\varrho+1}) \) contains a strongly connected agent subgraph. Furthermore, \textbf{Lemma 5} implies that the overall composition \( \mathcal{G}_d(\tau_{i\omega}) \circ \cdots \circ \mathcal{G}_d(\tau_{(i-1)\omega+\varrho+1}) \) results in a complete agent subgraph. Therefore, for any pair of agents \( g \) and \( h \) in \( \mathcal{N} \), there must exist a path \( \mathcal{O}_{i2}^{g,h} \) within \( \mathbf{G}_i^2 \), connecting \( g \) to \( h \). This path can be expressed as \( h = v_{(i-1)\omega+j\varrho}, v_{(i-1)\omega+j\varrho+1}, \cdots, v_{(i-1)\omega+(j+1)\varrho} = g \).

Next, consider \( \mathbf{G}_i^1 \). Since the subset \( \mathcal{N} \) of nodes in the extended delay graph contains self-loops, every node \( g \in \mathcal{N} \) has a path within \( \mathbf{G}_i^1 \) that begins and ends at \( g \), with all intermediate nodes also being \( g \). This path, denoted as \( \mathcal{O}_{i1}^g \), has a length of \( \varrho + 1 \).

Now, consider \( \mathbf{G}_0 \). Divide it into \( \mathbf{G}_0^1 = \{\mathcal{G}_d(\tau_{(N-1)\omega+1}), \cdots, \mathcal{G}_d(\tau_{(N-1)\omega+\varrho})\} \) and \( \mathbf{G}_0^2 = \{\mathcal{G}_d(\tau_{(N-1)\omega+\varrho+1}), \cdots, \mathcal{G}_d(\tau_s)\} \). The properties of \( \mathbf{G}_0^1 \) mirror those of \( \mathbf{G}_i^1 \): for every \( h \in \mathcal{N} \), there exists a path within \( \mathbf{G}_0^1 \) that traverses only \( h \), with a length of \( \varrho + 1 \). This path is denoted as \( \mathcal{O}_{01}^h \).

For \( \mathbf{G}_0^2 \), since its length is greater than \( d-1 \), \textbf{Lemma 2} guarantees that the composition \( \mathcal{G}_d(\tau_s) \circ \cdots \circ \mathcal{G}_d(\tau_{(N-1)\omega+\varrho+1}) \) forms an extended delay graph with a strong root hierarchy. Consequently, for any \( h \in \mathcal{N} \) and any \( h_s \in \mathcal{N}_h \), there exists a path within \( \mathbf{G}_0^2 \), denoted as \( \mathcal{O}_{02}^{h,h_s} \), connecting \( h \) to \( h_s \). This path can be written as \( h = v_{s_0+(N-1)\omega+\varrho}, v_{s_0+(N-1)\omega+\varrho+1}, \cdots,\\ v_{s_0+\tau} = h_s \).
 
Consequently, for any \( g \in \mathcal{N} \) and \( s \in \{1, 2, \cdots, d-1\} \), select \( h \neq g \) and arrange the remaining elements of \( \mathcal{N} \) arbitrarily. Place \( h \) at the beginning and \( g \) at the end of the sequence to construct a permutation \( h = i_1, i_2, \cdots, i_N = g \) of \( \{1, 2, \cdots, N\} \). According to prior discussions, for \( k \in \{1, 2, \cdots, N-1\} \), a path \( \mathcal{O}_{i1}^{i_k} \) can be found within \( \mathbf{G}_k^1 \), and a path \( \mathcal{O}_{i2}^{i_k, i_{k+1}} \) exists in \( \mathbf{G}_k^2 \). Additionally, a path \( \mathcal{O}_{01}^{i_N} \) is present in \( \mathbf{G}_0^1 \), and \( \mathcal{O}_{02}^{i_N, i_{Ns}} \) can be located in \( \mathbf{G}_0^2 \). By combining these paths, the sequence becomes \( \mathcal{O}_{11}^{i_1}, \mathcal{O}_{12}^{i_1, i_2}, \cdots, \mathcal{O}_{i1}^{i_{N-1}}, \mathcal{O}_{i2}^{i_{N-1}, i_N}, \mathcal{O}_{01}^{i_N}, \mathcal{O}_{02}^{i_N, i_{Ns}} \).

\textbf{Lemma 7} ensures that the element of matrix \( M_A \) at row \( sN + g \) and column \( h \) contains:
\[
    \prod_{k=1}^{\varrho} P_{i_1}^A(\tau_k) \cdots \prod_{k=(j-1)\omega+1}^{\varrho} P_{i_j}^A(\tau_k) \cdots \prod_{k=(N-2)\omega+1}^{\varrho} P_{i_{N-1}}^A(\tau_k) \prod_{k=(N-1)\omega+1}^{\varrho} P_{i_N}^A(\tau_k) \cdots
\]
Since \( \mathcal{P}^{i,j} \in \mathcal{P}_\kappa^i \subseteq \mathcal{P}_\varrho^i \), and \( g \) and \( s \) are arbitrary, Proposition 1 guarantees \( \|M_A\|_A < 1 \), confirming that \( M_A \) has a spectral radius less than 1. As the graph sequence and projection matrix sequence are drawn from finite sets, a specific contraction factor \( \lambda \) can be identified:
\[
    \lambda = \sup\limits_{\mathbf{G}_1^1} \cdots \sup\limits_{\mathbf{G}_{N-1}^1} \sup\limits_{\mathbf{G}_1^2} \cdots \sup\limits_{\mathbf{G}_{N-1}^2} \sup\limits_{\mathbf{G}_0^1} \sup\limits_{\mathbf{G}_0^2} \Big\|\mathbf{P}_A(\tau_s) \left(W(\tau_s) \otimes I_n\right) \mathbf{P}_A(\tau_{s-1}) \left(W(\tau_{s-1}) \otimes I_n\right) \cdots \mathbf{P}_A(\tau_1) \left(W(\tau_1) \otimes I_n\right) \mathbf{P}_A(\tau_0)\Big\| < 1.
\]
This ensures the strict contraction property and establishes convergence.
\end{proof}

We now turn to the convergence of \eqref{eq:Standard consensus system.}, which models a consensus problem with \( N \) agents and delay \( d \) in \( \mathbb{R}^n \). Such problems have been widely studied in the literature~\cite{doi:10.1137/060657005} and ~\cite{Cao2008Reaching}. The current formulation allows us to interpret system \eqref{eq:Standard consensus system.} as a Markov process, with \( \left(W(\tau_k) \otimes I_n\right) \) serving as the state transition matrix. By examining the matrix product \( \overset{s}{\prod\limits_{k=1}}\left(W(\tau_k) \otimes I_n\right) \), we can derive the convergence properties of system \eqref{eq:Standard consensus system.}. Previous discussions in~\cite{doi:10.1137/060657005} have established that the convergence is tied to the joint root structure of \( \mathcal{G}_d(\tau_k) \). To formalize this, we restate the following lemma:

\textbf{Lemma 8:}
For a row-stochastic matrix \( S(t) \) whose associated graph possesses a strong root structure, there exists a vector \( \mathbf{c} \) uniquely determined by the infinite product \( \cdots S(t) \cdots S(2)S(1) \). The vector \( \mathbf{c} \) has non-negative entries summing to 1 and the matrix product satisfies:
\[
\lim\limits_{t\to \infty} (S(t) \otimes I) \cdots (S(1) \otimes I) = \mathbf{1}\mathbf{c}^T \otimes I
\]
with an exponential convergence rate.

This lemma, derived directly from  the theorem in~\cite{doi:10.1137/060657005}, confirms the convergence of \eqref{eq:Standard consensus system.} and highlights that its outcome is influenced by the initial state \( \mathbf{e}_2(\tau_0) \). Moreover, the relevant agent states are confined to \( Row_\perp(A) \). If the initial states \( x_i(t_{i,0}) \) are selected such that \( e_i(t_{i,0}) = 0 \), the effect of \eqref{eq:Standard consensus system.} can be ignored. Consequently, if \eqref{eq:Projection consensus system.} converges, the algorithm is guaranteed to converge to \( x^* \). A straightforward choice for ensuring this is to initialize \( x_i(t_{i,0}) \in Row(A) \).

To support the subsequent proof, we invoke the well-known Borel-Cantelli lemma from probability theory:

\textbf{Lemma 9: [Borel-Cantelli]}
(i) If a sequence of events \( \{A_n\} \) satisfies \( \sum_{n=1}^\infty P(A_n) < \infty \), then almost surely, only finitely many events \( A_n \) will occur:

\[
P\left( \limsup_{n \to \infty} A_n \right) = 0
\]

(ii) If the events \( \{A_n\} \) are independent and satisfy \( \sum_{n=1}^\infty P(A_n) = \infty \), then almost surely, infinitely many events \( A_n \) will occur:

\[
P\left( \limsup_{n \to \infty} A_n \right) = 1
\]

For our analysis, only part (ii) is required. It guarantees that when the series \( \sum_{n=1}^\infty P(A_n) \) diverges, infinitely many events \( A_n \) will almost surely occur.

 Now we come to prove \textbf{Theorem 1}.
\begin{proof}
We first establish the convergence of system \eqref{eq:Standard consensus system.}.
Define $\sigma = d(n-1)^2 + d - 1$ and $S_n = W(\tau_{n\sigma}) \cdots W(\tau_{(n-1)\sigma+1})$. According to \textbf{Lemma 8}, the graph produced by $S_n$ possesses a strong root structure. Hence, there exists a vector $\mathbf{c} \in \mathbb{R}^n$ such that:
\[
\lim\limits_{n\to \infty} (S_n\otimes I) \cdots (S_1 \otimes I) = \mathbf{1}\mathbf{c}^T \otimes I.
\]
Let $n$ be the quotient when dividing $s$ by $\sigma$  with a remainder, it then yields that
\[
\mathbf{e}_2(\tau_{s+1}) = \left[\left(W(\tau_s)\cdots W(\tau_{n\sigma+1}) \ S_n\cdots S_1 W(\tau_0)\right) \otimes I_n\right]\mathbf{e}_2(\tau_{0}).
\]
Note that as $s \to \infty$, $n \to \infty$, and the condition $W(\tau_s)\cdots W(\tau_{n\sigma+1}) \ \mathbf{1}\mathbf{c}^T = \mathbf{1}\mathbf{c}^T$ holds.Therefore, there exists some $x_0 \in \text{Row}_\perp(A)$ such that $\lim\limits_{s \to \infty} \mathbf{e}_2(\tau_s) = x_0 \otimes \mathbf{1}$ and the convergence is exponential.

We now discuss system \eqref{eq:Projection consensus system.}. To harmonize \textbf{Proposition 2} and \textbf{Lemma 9}, we propose constructing a sequence of random events on $\mathcal{T}$ that satisfy the condition stated in \textbf{Lemma 9 (ii)}. The occurrence of each event guarantees the strict convergence property of $M_A$. Consequently, the limiting event is certain to occur, ensuring the convergence of the algorithm.

If the probability of $\mathcal{C}(\infty)$ is zero, it follows that:
\[
\overset{\infty}{\bigcup\limits_{l=1}}\mathcal{C}(l) = \left(\overset{\infty}{\bigcap\limits_{l=1}}\left(\mathcal{C}(l)\right)^c\right)^c = \left(\mathcal{C}(\infty)\right)^c, \text{ and thus } P\left(\overset{\infty}{\bigcup\limits_{l=1}}\mathcal{C}(l)\right) = 1 - P\left(\mathcal{C}(\infty)\right) = 1.
\]

This demonstrates that the event $\overset{\infty}{\bigcup\limits_{l=1}}\mathcal{C}(l)$ almost surely occurs. Therefore, there exists at least one $l$ such that $\mathcal{C}(l)$ holds, ensuring that the graph sequence $\mathcal{G}_d(\tau_s), \cdots, \mathcal{G}_d(\tau_0)$ almost surely satisfies $l$-strong connectivity.

Under the condition that $\mathcal{C}(l)$ occurs, let $\eta = \max\{m_1, m_2, \cdots, m_N\}$ and define $\mathcal{T}_i(\tau_k) = \{t_{i,k} : \tau_k < t_{i,k} \leq \tau_k + \eta \overline{T}\}$. Here, $\mathcal{T}_i(\tau_k)$ is a finite set. According to Equation \eqref{eq:Assumptions on communication prerequisites.}, agent $i$ selects block $A_i$ exactly $\eta$ times over $\mathcal{T}_i(\tau_k)$. Define $\mathcal{T}(\tau_k) = \overset{N}{\bigcup\limits_{i=1}} \mathcal{T}_i(\tau_k)$, which satisfies $|\mathcal{T}(\tau_k)| < \infty$ for any $\tau_k$. Therefore, there exists a positive integer $\kappa$ such that $|\mathcal{T}(\tau_k)| \leq \kappa$. Let $\varrho$ represent the least common multiple of $\kappa$ and $dl$.

Now define $\mathcal{P}_i(\tau_k)$ as the set of random orthogonal projections for agent $i$ over $\mathcal{T}(\tau_k)$. Construct the random event $\mathcal{J}(\tau_k) = \{\forall i, \mathcal{P}_i(\tau_k) \in \mathcal{P}_\kappa \subseteq \mathcal{P}_\varrho\}$. Because the random selection of blocks by agents at different times is independent and unrelated to inter-agent communication, we have:
\[
    \quad \quad \mathbb{P}\left(\mathcal{J}(\tau_k)\middle|\mathcal{C}(l)\right) = \mathbb{P}\left(\mathcal{J}(\tau_k)\right) \geq \overset{N}{\prod\limits_{i=1}}\frac{\eta!}{m_i!(\eta-m_i)!}.
\]

The above equation can be interpreted as follows: each agent performs $\eta$ selections on its local data $\begin{pmatrix}A_i & b_i\end{pmatrix}$ over $\mathcal{T}(\tau_k)$. Since selections by different agents are independent, and selections by the same agent are also independent, if all local equations are selected at least once, the agent must select a set of maximally linearly independent rows from $A_i$. Hence, the probability of the event $\mathcal{J}(t)$ has the lower bound given earlier, denoted here by $p$.

Let $\omega = N\varrho$ and $\vartheta = (N(N-1)+1)\varrho$. By \textbf{Proposition 2}, the event $$\left\|\mathbf{e}_1(\tau_{n\vartheta})\right\|^2 \leq \lambda \left\|\mathbf{e}_1(\tau_{(n-1)\vartheta+1})\right\|^2$$ occurs whenever the event $$\{\mathcal{J}(\tau_{(n-1)\vartheta}), \mathcal{J}(\tau_{(n-1)\vartheta+\omega}), \cdots, \mathcal{J}(\tau_{(n-1)\vartheta+(N-1)\omega})\}$$ occurs. Denote this event by $\mathcal{B}(n)$, and define $\mathcal{H}(n) = \{\left\|\mathbf{e}_1(\tau_{n\vartheta})\right\|^2 \leq \lambda \left\|\mathbf{e}_1(\tau_{(n-1)\vartheta+1})\right\|^2\}$. Then:
\[
    \mathbb{P}\left(\mathcal{H}(n)\middle|\mathcal{C}(l)\right) = \mathbb{P}\left(\mathcal{B}(n)\middle|\mathcal{C}(l)\right)
    = \mathbb{P}\left(\{\mathcal{J}(\tau_{(n-1)\vartheta}), \cdots, \mathcal{J}(\tau_{(n-1)\vartheta+(N-1)\omega})\}\right).
\]
Due to the independence of events, we have:
\[
    \mathbb{P}\left(\{\mathcal{J}(\tau_{(n-1)\vartheta}), \cdots, \mathcal{J}(\tau_{(n-1)\vartheta+(N-1)\omega})\}\right) = \mathbb{P}\left(\mathcal{J}(\tau_{(n-1)\vartheta})\right) \cdots \mathbb{P}\left(\mathcal{J}(\tau_{(n-1)\vartheta+(N-1)\omega})\right) \geq p^N.
\]
We conclude that $\mathbb{P}\left(\mathcal{H}(n) \middle| \mathcal{C}(l)\right) \geq p^N > 0$, which implies $\overset{\infty}{\sum\limits_{l=0}} \mathbb{P}\left(\mathcal{H}(n) \middle| \mathcal{C}(l)\right) = \infty$. Applying \textbf{Lemma 9}, it follows that $\mathbb{P}\left(\limsup\limits_{n \to \infty} \mathcal{H}(n) \middle| \mathcal{C}(l)\right) = 1$. Since $\left\{\limsup\limits_{n \to \infty} \mathcal{H}(n) \middle| \mathcal{C}(l)\right\} = \left\{\left(\overset{\infty}{\bigcap\limits_{i=0}} \overset{\infty}{\bigcup\limits_{j=i}} \mathcal{H}(j)\right) \middle| \mathcal{C}(l)\right\}$, this shows that, conditioned on $\mathcal{C}(l)$, the event $\mathcal{H}(n)$ occurs infinitely often almost surely.

Define $\mathcal{A} = \{\lim\limits_{s \to \infty} \left\|\mathbf{e}_1(\tau_s)\right\|^2 = 0\}$. From the above result, we have $\mathbb{P}\left(\mathcal{A} \middle| \mathcal{C}(l)\right) = 1$. Additionally, since $\mathbb{P}\left(\left(\mathcal{A}\right)^c \cap \mathcal{C}(l)\right) = 0$, we derive:
\[
    \mathbb{P}\left(\mathcal{A}\right) \geq \mathbb{P}\left(\mathcal{A} \cap \overset{\infty}{\bigcup\limits_{l=1}} \mathcal{C}(l)\right) = \mathbb{P}\left(\overset{\infty}{\bigcup\limits_{l=1}} \mathcal{A} \cap \mathcal{C}(l)\right) = \mathbb{P}\left(\overset{\infty}{\bigcup\limits_{l=1}} \mathcal{C}(l)\right) - \mathbb{P}\left(\overset{\infty}{\bigcup\limits_{l=1}} \left(\mathcal{A}\right)^c \cap \mathcal{C}(l)\right) = \mathbb{P}\left(\overset{\infty}{\bigcup\limits_{l=1}} \mathcal{C}(l)\right) = 1,
\]
leading to $\mathbb{P}\left(\mathcal{A}\right) = 1$. This establishes that the algorithm converges almost surely.

We now establish the exponential convergence rate of the algorithm. It is straightforward to confirm that $\left\|\mathbf{P}(\tau_k) \left(W(\tau_k) \otimes I_n\right) \mathbf{P}(\tau_{k-1})\right\|_A \leq 1$, which implies that for all $s \geq k$, $\left\|\mathbf{e}_1(\tau_s)\right\|^2 \leq \left\|\mathbf{e}_1(\tau_k)\right\|^2$. Since the event $\overset{\infty}{\bigcup\limits_{l=1}}\mathcal{C}(l)$ almost surely occurs, for any sample point, there almost surely exists an $l$ such that $\mathcal{C}(l)$ is satisfied. With this, we define $\vartheta$ and find:
\[
\begin{aligned}
    \mathbb{E}\left[\left\|\mathbf{e}_1(\tau_{n\vartheta})\right\|^2 \right] & = \mathbb{E}\left[\left\|\mathbf{e}_1(\tau_{n\vartheta})\right\|^2 \middle| \mathcal{B}(n)\right]\mathbb{P}\left(\mathcal{B}(n)\right) + \mathbb{E}\left[\|\mathbf{e}_1(\tau_{n\vartheta})\|^2 \middle| \mathcal{B}(n)^c\right]\left(1-\mathbb{P}\left(\mathcal{B}(n)\right)\right) \\
    & \leq \left(1-(1-\lambda^2)\mathbb{P}\left(\mathcal{B}(n)\right)\right)\mathbb{E}\left[\|\mathbf{e}_1(\tau_0+(n-1)\vartheta)\|^2\right] \\
    & \leq \left(1-(1-\lambda^2)p^N\right)\mathbb{E}\left[\|\mathbf{e}_1(\tau_0+(n-1)\vartheta)\|^2 \right] \\
    & \leq \left(1-(1-\lambda^2)p^N\right)^n\mathbb{E}\left[\|\mathbf{e}_1(\tau_0)\|^2 \right].
\end{aligned}
\]
Let $\mu := \left(1-(1-\lambda^2)p^N\right)$, where $\mu < 1$ is clearly satisfied. For any $s \geq \vartheta$, let $\varsigma$ denote the quotient obtained when dividing $s$ by $\vartheta$ with remainder, satisfying $\varsigma \geq \frac{s}{\vartheta} - 1$. Based on this relationship, it follows that every execution of the algorithm achieves an exponential convergence rate:
\[
    \mathbb{E}\left[\|\mathbf{e}_1(\tau_s)\|^2 \right] \leq \mu^{\left(\frac{\tau}{\vartheta}-1\right)}\mathbb{E}\left[\|\mathbf{e}_1(\tau_0)\|^2\right] = \mu^{\left(\frac{\tau}{(N(N-1)+1)\varrho}-1\right)}\mathbb{E}\left[\|\mathbf{e}_1(\tau_0)\|^2\right].
\]

This demonstrates that both \eqref{eq:Standard consensus system.} and \eqref{eq:Projection consensus system.} exhibit exponential convergence rates. The vector $\mathbf{e}_2$ converges to $x_0 \otimes \mathbf{1}$ within $\left[\text{Row}_\perp(A)\right]^{dN}$. Define $x_i = x_{i1} + x_{i2}$ and $x^* = x_{1}^* + x_{2}^*$, where $x_{i1}, x_{1}^* \in \text{Row}(A)$ and $x_{i2}, x_{2}^* \in \text{Row}_\perp(A)$. Since $x^*$ is the minimum norm solution, it follows that $x_{1}^* = x^*$ and $x_2^* = 0$. From the definition of the norm $\|\cdot\|$, we derive $\lim\limits_{s \to \infty} x_{i2}(\tau_s) - x_2^* = x_0$, which implies $\lim\limits_{s \to \infty} x_{i2}(\tau_s) = x_0$. Similarly, $\lim\limits_{s \to \infty} x_{i1}(\tau_s) - x_1^* = 0$, so $\lim\limits_{s \to \infty} x_{i1}(\tau_s) = x^*$. Consequently, $\lim\limits_{s \to \infty} x_i(\tau_s) = x^* + x_0$, and this convergence occurs at an exponential rate. If the initial condition $x_i(t_{i,0}) \in \text{Row}(A)$ is satisfied, then $\lim\limits_{s \to \infty} x_i(\tau_s) = x^*$.
\end{proof}

\subsection{Proof of Theorem 2}

For the inconsistent system $Ax = b$, the modification in \eqref{eq:Augmented system.} guarantees consistency, as the diagonal elements of $\Lambda$ are strictly positive. By rewriting the iterative format of \eqref{eq:The iterative format for solving the incompatibility problem.}, we define $B = \begin{pmatrix}A & \Lambda\end{pmatrix}$ and $B_i(t_{i,k}) = \begin{pmatrix}A_i(t_{i,k}) & \Lambda_i(t_{i,k})\end{pmatrix}$, where $B_i(t_{i,k})$ represents the random block selected by agent $i$ at time $t_{i,k}$. Expressing $B_i(t_{i,k})$ in terms of its row vectors:
\[
B_i(t_{i,k}) = \Big[ \beta_{i_1}(t_{i,k}), \cdots, \beta_{i_{m_i(t_{i,k})}}(t_{i,k}) \Big]^T,
\]
with each row $\beta_{i_j}(t_{i,k})$ expressed as $\Big[ \alpha^T_{i_j}(t_{i,k}), \lambda_{i_j}\mathbf{1}_{i_j}^T \Big]^T$. Using $\beta_{i_j}(t_{i,k})$, we construct the projection matrix:
\[
\widetilde{P}_{i_j}(t_{i,k}) = I_{n+m} - \frac{\beta_{i_j}(t_{i,k})\beta^T_{i_j}(t_{i,k})}{\|\alpha_{i_j}(t_{i,k})\|^2 + \lambda_{i_j}^2}.
\]
Applying this projection matrix and $b_{i_j}(t_{i,k})$ in the form of \eqref{eq:The iterative format for solving the compatibility problem.} to any vector $\Big[x^T, \epsilon^T\Big]^T$, we derive the iterative function $P_{i_j}(t_{i,k})$ for the $x$ component. Given the specific structure of $\beta_{i_j}(t_{i,k})$ with respect to the $\epsilon$ component, the iteration for $\epsilon$ can be reduced to consider only the relevant component. This results in the iterative function $R_{i_j}(t_{i,k})$, where the updates to $\epsilon$ components are independent across $j$. Thus, the iterative operation associated with $\beta_{i_j}(t_{i,k})$ can be expressed in the form of \eqref{eq:The iterative format for solving the incompatibility problem.}.

Following the above discussion and drawing a direct analogy to the constructions in \eqref{eq:Undecomposed system.}, define $\widetilde{P}_i(t_{t,k}) = \widetilde{P}_{i_{m_i(t_{i,k})}} \cdots \widetilde{P}_{i_1} = \overset{m_i(t_{i,k})}{\prod\limits_{j=1}}\widetilde{P}_{i_j}(t_{i,k})$. With this, \eqref{eq:The iterative format for solving the incompatibility problem.} can be expressed as:
\[
\mathbf{e}(\tau_{k+1}) = \mathbf{\widetilde{P}}(\tau_k) \left(W(\tau_k) \otimes I_n\right) \mathbf{\widetilde{P}}(\tau_{k-1}) \mathbf{e}(\tau_k).
\]
The definitions of $\mathbf{e}(t)$ and $\mathbf{\widetilde{P}}(t)$ remain consistent with those in \eqref{eq:Undecomposed system.}, and will not be reiterated here. Using the conclusions from \textbf{Theorem 1}, the convergence of \eqref{eq:The iterative format for solving the incompatibility problem.} can be directly established. If the initialization satisfies $\Big[x^T_i(t_{i,0}), \epsilon^T_i(t_{i,0})\Big]^T \in \text{Row}(B)$, then each $x_i(t)$ converges to the $x$ component $\widetilde{x}^*$ of the least squares solution $B^\dagger b$.

Performing the singular value decomposition (SVD) of $A$, where $A = U \Sigma V^T$, gives the pseudoinverse $B^\dagger$ as:
\[
\begin{pmatrix}
    V &  \\  & U
\end{pmatrix}
\begin{pmatrix}
    (I_n + \Sigma^T \Lambda^{-2} \Sigma)^{-1} \Sigma^T \Lambda^{-2} \\
    I_m - \Sigma (I_n + \Sigma^T \Lambda^{-2} \Sigma)^{-1} \Sigma^T \Lambda^{-1}
\end{pmatrix}
U^T.
\]
Thus, $\Tilde{x}^* = V (I_n + \Sigma^T \Lambda^{-2} \Sigma)^{-1} \Sigma^T \Lambda^{-2} U^T b$. Define $\widetilde{\Sigma}^\dagger = (I_n + \Sigma^T \Lambda^{-2} \Sigma)^{-1} \Sigma^T \Lambda^{-2}$. If $\Sigma = \text{diag}(\sigma_1, \cdots, \sigma_r, 0, \cdots)$, where $r$ is the rank of $A$, then $$\widetilde{\Sigma}^\dagger = \text{diag}\left(\frac{\sigma_1}{\sigma_1^2+\lambda_1^2}, \cdots, \frac{\sigma_r}{\sigma_r^2+\lambda_r^2}, 0, \cdots\right).$$ 
Let $\Sigma_0 = \text{diag}\left(\frac{\lambda_1^2}{\lambda_1^2+\sigma_1^2}, \cdots, \frac{\lambda_r^2}{\lambda_r^2+\sigma_r^2}, 0, \cdots\right)$ be an $n$-dimensional diagonal matrix. The absolute error can then be estimated as:
\[
    \|x^* - \Tilde{x}^*\| = \|V(\Sigma^\dagger-\widetilde{\Sigma}^\dagger)U^T b\| \vspace{2em} = \|\Sigma_0 A^\dagger b\| \leq \frac{1}{\frac{1}{\left(\frac{\sigma_{min}}{\lambda_{max}}\right)^2}+1} \|x^*\|.
\]
From this, the relative error can be estimated as:
\[
\frac{\|x^* - \Tilde{x}^*\|}{\|x^*\|} \leq \frac{1}{\frac{1}{\left(\frac{\sigma_{min}}{\lambda_{max}}\right)^2}+1}.
\]
This completes the proof.

%% bibitems
\bibliographystyle{elsarticle-num} 
\bibliography{references}

\end{document}