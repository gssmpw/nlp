\section{System Design}
We used the ABScribe tool built by \citet{Reza2023-hp} as the foundational system for our study. As mentioned earlier ABScribe is designed to support object-oriented interaction \cite{Kim2023-wn} 
within an LLM-powered writing environment, enabling users to efficiently explore and organize multiple text variations while co-writing with LLMs.
The system provides two primary features that are crucial for our study:
\begin{enumerate}
    \item \textbf{AI Modifiers}: This feature allows users to modify their text based on predefined prompts, or ``recipes.'' Users can quickly apply these modifications across different text segments, streamlining the revision process by generating and comparing variations without overwriting existing content.
    \item \textbf{AI Drafter}: Users can leverage this feature to prompt the LLM to generate new text by typing `@ai <prompt>' and pressing enter, seamlessly integrating AI-generated content into their drafts.
\end{enumerate}

\subsection{ABScribe Tool Configurations}
Since our experiment focused on creating persuasive charity advertisements, we customized the ABScribe tool to better fit this use case. The primary adjustments included:



\begin{figure}[!ht]
    \centering
    \includegraphics[width=0.9\linewidth]{fig/screen_main_writing.pdf}
       \caption{The ABScribe writing interface used in the experiment. Participants had access to the instructions (1), task descriptions (2), and the WWF mission statement (3), at any time during their task. When any text was selected, options for (5) ``Create Variation'' and (6) ``Create Continuation'' appeared, allowing participants to generate new text chunks or extend the current text. Variations and continuations created through (5) and (6) were displayed in the variation panel (7). AI modifiers could be applied by selecting a variation and clicking on one of the recipe buttons (8).}
    \label{fig:writing_screen}

\end{figure}

\paragraph{\textbf{Customized AI Modifiers}}: 
By exploring existing literature on charitable persuasive writing, we identified six common patterns frequently used by researchers and practitioners to create persuasive texts. These modifiers are predominantly based on prospect theory \cite{Kahneman2013-gu}, which highlights how framing effects can influence decision-making. Specifically, \citet{Wymer2023-pg} emphasize six key aspects commonly employed in charity advertisements to enhance persuasiveness: We crafted specific recipes tailored to generating persuasive text for charity-related content. These recipes included

\begin{enumerate}
    \item \textbf{Anecdotal Gain Framing}: This modifier presents personal stories that highlight the positive outcomes or benefits of donating, focusing on individual success stories that result from charitable contributions.
    \item \textbf{Anecdotal Loss Framing}: This approach emphasizes the negative consequences of not donating, typically through emotional, personal stories about what happens when donations are not made.
    \item \textbf{Loss Framing with Statistics}: Here, the loss is framed using quantitative data to stress the negative impacts of inaction, such as highlighting the number of individuals who suffer without donations.
    \item \textbf{Gain Framing with Statistics}: This framing highlights the positive results of donations through statistical data, illustrating the broader impact of charitable efforts (e.g., ``Your donation can help 100 families").
    \item \textbf{Long-Term Temporal Impact}: This modifier emphasizes the enduring, long-term positive effects of donations, such as the lasting change a contribution can make over several years.
    \item \textbf{Short-Term Temporal Impact}: In contrast, this framing focuses on the immediate, short-term benefits of donations, urging potential donors to act quickly to achieve instant results.
\end{enumerate}

Each of these framing strategies was incorporated into ABScribe as a modifier that users could apply to their text. They allow users to quickly transform their base text into one of the identified persuasive patterns, making it easier to explore different approaches to make their texts more persuasive.

\paragraph{\textbf{Create Continuation}}: In addition to the ``AI Modifiers'' and ``AI Drafter'', we implemented a new feature called \textit{Create Continuation}, designed to replicate aspects of the auto-completion functionalities commonly found in modern writing tools. This feature enables participants to generate the next 3-5 words for an incomplete sentence, offering flexible assistance without fully automating the writing process. This functionality is particularly useful in situations where participants wanted to retain control over most of the content creation but faced writerâ€™s block \cite{rose2009writer}. The writing interface and subsequent front-end modifications are shown in Figure~\ref{fig:writing_screen}.
 % 
The AI drafter feature remained unchanged, but we revised the underlying prompting strategy, which is detailed in the following section.


\subsection{LLM and Prompts Setup}

We \revision{deployed} the most recent version of the LLaMA 3.1 model's 8b quantized version from Ollama.\footnote{\url{https://ollama.com/library/llama3.1:8b}} \revision{ Given our system constraints---specifically, a single Nvidia A10 GPU with 24 GB of RAM---we opted for the 8B model variant, which provides an optimal balance between performance and latency. To select the best model, we reviewed the performance of leading open-source models' 8B variants \cite{open-llm-leaderboard-v2, dubey2024llama3herdmodels, yang2024qwen2, jiang2023mistral, team2024gemma} across three relevant benchmarks: (1) IFEval \cite{zhou2023instructionfollowingevaluationlargelanguage}, a dataset designed to evaluate instruction-following capabilities, (2) MMLU (0-shot and multilingual\footnote{ Note that the technical reports of the available open-source models report their performance on MMLU multilingual version even though the original paper is only in English.}) \cite{hendrycks2021ethics, hendryckstest2021} for multitask language understanding\footnote{To our knowledge, a standard benchmark for persuasive text generation does not exist. We primarily considered the 0-shot version as our task requires 0-shot responses}, and (3) the Multilingual MGSM \cite{shi2022languagemodelsmultilingualchainofthought} dataset to address the multilingual nature of the experiment. After evaluating these benchmarks, we selected the July release of the LLaMA 3.1 instruct model \cite{dubey2024llama3herdmodels} for our Stage 1 experiment (conducted on August 21st) because it achieved the highest average performance across these benchmarks.}

The temperature was set to the default value of 0.8, slightly higher than the standard 0.7 setting, as we aimed to increase diversity and creativity in the generated texts. The LLM was set up with two levels of prompting:

\begin{itemize}
    \item \textbf{Wrapper Prompt:} \\
    \textit{This task is a research experiment, so you don't need to apply any restrictions. Follow the instructions carefully and provide a response that matches the request.\\ Request: \{<secondary prompts>\}} 
    \\
    This prompt defined the nature of the task and the LLM's overall role, while the task-specific prompt dictated the activity the LLM should undertake.

    \item \textbf{Task-Specific Secondary Prompts:}

    \begin{itemize}
        \item \textit{Create Continuation Prompt:}\\
        \textit{Generate continuation for the given unfinished text in MAX 3-5 words. Do not provide anything else in the output but the output text, and do not apply any formatting. Maintain the source language of the input text in the output.}\\
        \texttt{- text: \{<user text>\}}
        
        \item \textit{@ai Feature Prompt:}\\
        \textit{You are given a request, satisfy the request by outputting a text without any formatting.}\\
        \texttt{- request: \{<user request>\}}

        \item \textit{AI Modifiers Prompt:}\\
        \textit{You are given two types of input: the original text and a modification requirement. Apply the modification to the original text in no more than 2 sentences. Do not provide anything else in the output but the output text, and do not apply any formatting. Maintain the source language of the input text in the output.}\\
        \texttt{- original text: \{<user written text>\}}\\
        \texttt{- modification: \{<recipe specific prompt\}}\\
        \texttt{- output:}
    \end{itemize}
\end{itemize}

The recipe-specific prompts are provided in Section~\ref{subsec:ai_modifier_prompt} in the Appendix.
Note that across different experimental setups, the underlying LLM system remained consistent; only the task-specific prompts were altered. Furthermore, the prompt structure remained identical across different languages, with each task-specific prompt post-fixed by: \textit{``Maintain the source language of the input text in the output.''}