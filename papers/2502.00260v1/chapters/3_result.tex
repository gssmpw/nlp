% We assume that, without loss of generality, $\ps(h, \vpr_h) \ge \ps(\ell, \vpr_{\ell})$. If the reverse holds, our theoretical results hold by switching $h$ and $\ell$.  
% \Qishen{We should probably add some $\varepsilon$ results in the peer prediction scenario. We now have several incremental results, but they are probably enough.}
Our theoretical results focus on the collusive behavior in the peer prediction mechanisms. While the mechanism is known to be prone to collusions, \citet{Shnayder2016practcal} empirically shows that there is a lower bound for collusion to be profitable. With our new solution concepts, our theoretical results specify the exact threshold. 
For both equilibria, we find the largest group size $\kde$ ($\kdq$, respectively) such that truthful reporting is an equilibrium. Moreover, for any $\kd$ larger than $\kde$ ($\kdq$, respectively), truthful reporting fails to be an equilibrium. We first present the result of the ex-ante Bayesian $\kd$-strong equilibrium. 

\begin{theorem}
\label{thm:pp_exante}
    In the peer prediction mechanism, for any $n \ge 2$ and any strictly proper scoring rule $\ps$, truthful reporting $\stgp^*$ is an ex-ante Bayesian $\kde$-strong equilibrium, where 
    \begin{small}
        \begin{align*}
        \kde^h =& \begin{cases}
           \left\lfloor\frac{(\ag - 1)\cdot \Ex_{\sigi\sim \vpr_{\ell}}[\ps(\sigi, \vpr_{\ell}) - \ps(\sigi, \vpr_{h})]}{\ps(h, \vpr_h) - \ps(\ell, \vpr_h)}  \right\rfloor + 1 & \text{if}\ \ps(h, \vpr_h) > \ps(\ell, \vpr_h) \\
           n & \text{otherwise}
        \end{cases}\\
        \kde^\ell =& \begin{cases}
           \left\lfloor\frac{(\ag - 1)\cdot \Ex_{\sigi\sim \vpr_{h}}[\ps(\sigi, \vpr_{h}) - \ps(\sigi, \vpr_{\ell})]}{\ps(\ell, \vpr_\ell) - \ps(h, \vpr_\ell)}\right\rfloor + 1 & \text{if}\ \ps(\ell, \vpr_\ell) > \ps(h, \vpr_\ell)\\
           n & \text{otherwise}
        \end{cases}\\
        \kde =&  \min(\kde^h, \kde^{\ell}, n). 
    \end{align*}
    \end{small}
    
    For all $n\ge k > \kde$, truthful reporting is NOT an ex-ante Bayesian $\kd$-strong equilibrium. 
\end{theorem}

While a proof sketch is presented below, here we give a brief explanation of the thresholds. $\kde^h$ and $\kde^\ell$ are characterized by comparing the ex-ante expected utility of a deviator between truthful reporting and all the deviators always report $h$ ($\ell$, respectively). Take $\kde^h$ as an example. The numerator  $\Ex_{\sigi\sim \vpr_{\ell}}[\ps(\sigi, \vpr_{\ell}) - \ps(\sigi, \vpr_{h})]$ is proportional to the loss that the deviator suffers in his expected rewards from the truthful reporters in switching from truthful reporting to always reporting $h$. The denominator $\ps(h, \vpr_h) - \ps(\ell, \vpr_h)$ is proportional to the amount that, for a deviator, the expected reward gain from other deviators exceeds the expected reward loss from truthful reporting. If $\ps(h, \vpr_h) - \ps(\ell, \vpr_h) < 0$, the extra gain never compensates for the loss, so the deviation cannot succeed for any $\kd \le n$. Otherwise, a group size of $\kd > \kde^h$ is required for the deviation to succeed.

% After the deviation, the expected reward of a deviator from a truthful reporter decreases, because he/she reports $h$ even when his/her signal is $\ell$.  The numerator  $\Ex_{\sigi\sim \vpr_{\ell}}[\ps(\sigi, \vpr_{\ell}) - \ps(\sigi, \vpr_{h})]$ is proportional to the loss that the deviator suffers in his expected rewards from the truthful reporters. To make the deviation succeed, the deviators should gain extra rewards from each other. When $\ps(h, \vpr_h) - \ps(\ell, \vpr_h)\le 0$, the rewards between deviators are never enough to fill the gap, and the deviation cannot succeed for any $\kd$. Otherwise, 

% The thresholds $\kde^h$ and $\kde^\ell$ are characterized by comparing the ex-ante expected utility between truthful reporting and all the deviators always report $h$ ($\ell$, respectively). Take $\kde^h$ as an example.
% After the deviation, the expected reward of a deviator from a truthful reporter decreases proportional to $\ag - \kd$ and $\Ex_{\sigi\sim \vpr_{\ell}}[\ps(\sigi, \vpr_{\ell}) - \ps(\sigi, \vpr_{h})]$.\Qishen{explain this more} To make the deviation succeed, the deviators should gain extra rewards from each other. When $\ps(h, \vpr_h) - \ps(\ell, \vpr_h)\le 0$, the rewards between deviators are never enough to fill the gap, and the deviation cannot succeed for any $\kd$. When $\ps(h, \vpr_h) - \ps(\ell, \vpr_h) > 0$, the amount the extra expected reward between deviators exceeds the expected reward loss from truthful reporting is proportional to $\kd$ and $\ps(h, \vpr_h) - \ps(\ell, \vpr_h)$. Therefore, a group size of $\kd > \kde^h$ is required to make the deviation succeed. 
% \Qishen{Instead of giving sketch, try to explain the result itself. what is the num/denom? tell the reader what's happenning."while we have sketch below, here..."}

\begin{example}
\label{ex:ex-ante}
    We calculate the threshold for ex-ante Bayesian $\kd$-strong equilibrium for the instance in Example~\ref{ex:setting}. For $\kde^h$, the numerator equals to $\pr(h \mid \ell) \cdot (0.28 - 0.92) + \pr(\ell \mid \ell)\cdot (0.68 + 0.28) = 0.32$. The denominator, according to the Brier scoring rule, equals to $\ps(h, \vpr_h) - \ps(\ell, \vpr_h) = 2\cdot (\pr(h \mid h) - \pr(\ell \mid h)) = 1.2$. Therefore, $\kde^h = \lfloor \frac{4}{15}\cdot (\ag-1)\rfloor + 1$. Similarly, we calculate that $\kde^\ell = \lfloor \frac{4}{5}\cdot (\ag-1)\rfloor + 1$. Therefore, when $\ag = 100$, a deviation group needs at least $\lfloor \frac{4}{15}\times 99\rfloor + 1 = 27$ deviators to succeed. This aligns with Example~\ref{ex:difference}, where a 40-agent group succeeds. 
\end{example}

Similarly, Theorem~\ref{thm:pp_qi} characterizes the threshold under Bayesian $\kd$-strong equilibrium. 

\begin{theorem}
\label{thm:pp_qi}
    In the peer prediction mechanism, there exists an $\ag_0$ such that for every $\ag \ge \ag_0$ and any strictly proper scoring rule $\ps$, truthful reporting $\stgp^*$ is a Bayesian $\kd$-strong equilibrium in peer prediction, where 
    \begin{align*}
        \kdq^h =& \begin{cases}
         \left\lceil \frac{(\ag -1)\cdot \Ex_{\sigi\sim \vpr_{\ell}}[\ps(\sigi, \vpr_{\ell}) - \ps(\sigi, \vpr_{h})]}{\pr(\ell \mid \ell)\cdot (\ps(h, \vpr_h) - \ps(\ell, \vpr_h))} \right\rceil  & \text{if}\ \ps(h, \vpr_h) > \ps(\ell, \vpr_h)\\
           n & \text{otherwise}
        \end{cases}\\
        \kdq^\ell =& \begin{cases}
          \left\lceil \frac{(\ag - 1)\cdot \Ex_{\sigi\sim \vpr_{h}}[\ps(\sigi, \vpr_{h}) - \ps(\sigi, \vpr_{\ell})]}{\pr(h\mid h)\cdot (\ps(\ell, \vpr_\ell) - \ps(h, \vpr_\ell))} \right\rceil & \text{if}\ \ps(\ell, \vpr_\ell) > \ps(h, \vpr_\ell)\\
           n & \text{otherwise}
        \end{cases}\\
        \kdq =&\  \min(\kdq^h, \kdq^{\ell}, n). 
        \end{align*}
    For all $n\ge \kd > \kdq $, truthful reporting is NOT a Bayesian $\kd$-strong equilibrium. 
    
\end{theorem}

The lower bound $\ag_0$ on $\ag$ is characterized by the common prior $\pr$ and the scoring rule $\ps$ and is independent of $\ag$. The explicit expression on $\ag_0$ is in Appendix~\ref{apx:qi}.

The thresholds for the Bayesian $\kd$-strong equilibrium $\kdq^h$ and $\kdq^\ell$ are larger than those for the ex-ante Bayesian $\kd$-strong equilibrium $\kde^h$ and $\kde^\ell$ respectively. This is because, for example, $\kdq^h$ is characterized by comparing the interim utility of a deviator conditioned on signal $\ell$ between truthful reporting and all deviators reporting $h$. In ex-ante, the deviator $i$ has a probability of $\pr(\ell)$ to report untruthfully and suffer a loss on expected reward from truthful reporters. When $i$ has a private signal $\ell$, such probability becomes 1. Therefore, the deviator suffers more loss in the interim expected utility than in the ex-ante expected utility in the expected reward from truthful reporters. On the other hand, $i$ gets the same extra gain in the reward from other deviators as in the ex-ante expected utility. Therefore, a larger group is needed to make the deviation succeed. 

\begin{example}
    \label{ex:qi}
    We calculate the threshold for Bayesian $\kd$-strong equilibrium for the instance in Example~\ref{ex:setting}. For $\kdq^h$, the numerator equals to $0.32$.
    The denominator is multiplied by $\pr(\ell \mid \ell) = 0.6$ compared with $\kde^h$ and equals to $1.2 \times 0.6 = 0.72$. Therefore, $\kde^h = \lceil \frac{4}{9}\cdot (\ag-1)\rceil$. Similarly, we calculate that $\kde^\ell = \lceil \ag - 1 \rceil$. Therefore, when $\ag = 100$, a deviation group needs at least $45$ deviators to succeed. This also aligns with Example~\ref{ex:difference}, where a 40-agent group fails in deviation.  
\end{example}

Theorem~\ref{thm:pp_exante} and \ref{thm:pp_qi} imply that the ex-ante Bayesian $\kd$-strong equilibrium and the Bayesian $\kd$-strong equilibrium are natural criteria to evaluate the robustness against collusion for a peer prediction mechanism. If truth-telling is an equilibrium with a larger $\kd$, the mechanism is more robust against collusion. If an information collector aims to prevent collusion in a peer prediction task, he/she could carefully select the mechanism and the scoring rule to maximize the threshold $\kd$ under which truth-telling becomes an equilibrium.  

\begin{example}
    \label{ex:log_vs_brier}
    If we change the scoring rule from the Brier scoring rule Example~\ref{ex:setting} to the log scoring rule with base $e$ in and follow the calculation in Example~\ref{ex:ex-ante}, we have $\kde = \lfloor 0.275 (\ag - 1)\rfloor + 1$. When $\ag = 100$, a group of at least 28 agents is needed to perform a successful deviation. Therefore, the log scoring rule is more robust than the Brier scoring rule in this instance. 
\end{example}

\subsection{Proof Sketch of Theorem~\ref{thm:pp_exante}}
The proof consists of two steps.
In Step 1, $\kde$ is characterized by comparing the ex-ante expected utility of a deviator when every agent reports truthfully and when all $\kd$ deviators always report $h$ (and always report $\ell$, respectively). The two deviations bring a deviator higher expected utility if and only if $\kd > \kde$. In Step 2, we show that for any $\kd \le \kde$ and any deviating strategy profile $\stgp'$, the average expected utility among all the deviators when $\stgp'$ is played will not exceed the expected utility when every agent reports truthfully. Therefore, either no deviators have strictly increasing expected utility or some deviators have strictly decreasing utility after deviation, and the deviation cannot succeed.
The full proof is in Appendix~\ref{apx:exante}. 

\noindent\textbf{Step 1: determine $\kde$.} We show how $\kde^h$ is determined by comparing truthful reporting strategy profile $\stgp^*$ and the deviating strategy profile $\stgp$ where all $\kd$ deviators always report $h$, i.e., $\stg = (1, 1)$. The reasoning for $\kde^\ell$ is similar. The condition that a deviator $i$ is willing to deviate is $\ut_i(\stgp) > \ut_i(\stgp^*)$. The inequality should be strict because all deviators have equal expected utility in $\stgp$.

$\ut_i(\stgp)$ can be viewed as a linear combination of the expected utility $i$ gets from the truthful agents, denoted by $\ut_i(\stgp \mid \jtruthful)$, and the expected utility $i$ gets from other deviators, denoted by $\ut_i(\stgp \mid \jdeviate)$. In $\stgp$, there are $\ag - \kd$ truthful reporters and $\kd - 1$ deviators other than $i$. Therefore, $\ut_i(\stgp) = \frac{\ag - \kd}{\ag - 1}\cdot \ut_i(\stgp \mid \jtruthful) + \frac{\kd - 1}{\ag - 1}\cdot \ut_i(\stgp \mid \jdeviate).$
Let $\dut_d = \ut_i(\stgp^*) -\ut_i(\stgp\mid \jdeviate)$, and $\dut_t = \ut_i(\stgp^*) -\ut_i(\stgp\mid \jtruthful)$. Then $\ut_i(\stgp) > \ut_i(\stgp^*)$ is equivalent to
$\frac{\kd-1}{\ag -1} \cdot\dut_d + \frac{\ag -\kd}{\ag -1} \cdot \dut_t< 0.$

The ex-ante expected reward of deviator $i$ from truthful reporters can be divided into two parts, one conditioned on $i$'s private signal being $h$, the other on $i$'s signal being $\ell$. When $i$'s signal is $h$, $i$ reports $h$ both in $\stgp^*$ and in $\stgp$, and the expected rewards from truthful reporters in this part are the same. When $i$'s signal is $\ell$, $i$ reports $\ell$ in $\stgp^*$ and $h$ in $\stgp$, and the expected rewards make a difference. Therefore, $\dut_t = \pr(\ell)\cdot  \Ex_{\sigi\sim \vpr_{\ell}}[\ps(\sigi, \vpr_{\ell}) - \ps(\sigi, \vpr_{h})]. $ According to the properness of $\ps$, $\dut_t > 0$.  Therefore, when $\dut_t > \dut_d$, $\ut_i(\stgp) > \ut_i(\stgp^*)$ is equivalent to
\begin{equation*}
    \kd > \frac{\dut_t}{\dut_t - \dut_d}\cdot (n-1) + 1. 
\end{equation*}
When $\dut_t \le \dut_d$, the condition does not hold for any $k$, and the deviation will never succeed. 

From the calculation, $\dut_t - \dut_d = \pr(\ell)\cdot   (\ps(h, \vpr_h) - \ps(\ell, \vpr_h))$. Therefore, when $\ps(h, \vpr_h) > \ps(\ell, \vpr_h)$, $\dut_t > \dut_d$, and $\ut_i(\stgp) > \ut_i(\stgp^*)$ is equivalent to 
\begin{equation*}
   \kd >\frac{\Ex_{\sigi\sim \vpr_{\ell}}[\ps(\sigi, \vpr_{\ell}) - \ps(\sigi, \vpr_{h})]}{\ps(h, \vpr_h) > \ps(\ell, \vpr_h)} \cdot (n-1) + 1. 
\end{equation*}

And when $\ps(h, \vpr_h) \le \ps(\ell, \vpr_h)$, $\dut_t \le \dut_d$, and $\ut_i(\stgp) > \ut_i(\stgp^*)$ does not hold for any $\kd$. This is how $\kde^h$ is determined. $\kde^\ell$ is determined in a similar reasoning. 

\noindent\textbf{Step 2: Deviations cannot succeed for $\kd \le \kde$.} For $k = 1$, the statement holds from the truthfulness of the mechanism. Suppose $2\le \kd \le \kde$, and $\stgp$ be an arbitrary deviating strategy. Let $\ut(\stgp^*)$ be the expected utility of truthful reporting, which is equal for all agents. For each deviator $i$, let $\stg_i = (\bpl^i, \bph^i)$ denote $i$'s strategy in $\stgp$.  We show that $\frac{1}{\kd} \sum_{i \in D} \ut_i(\stgp) \le \ut(\stgp^*)$. Therefore, either there exists some deviator $i$ such that $\ut_i(\stgp) < \ut(\stgp^*)$, or for all the deviator $i$ there is $\ut_i(\stgp) = \ut(\stgp^*)$. In either case, the deviation fails. 

Now let $\astg = (\abpl, \abph) = \frac{1}{\kd} \sum_{i \in D} \stg_i$ be the average of the deviator's strategies, and $\astgp$ be the strategy profile where all agents in $D$ plays $\astg$ and all other agents report truthfully. $\ut_i(\astgp)$ is equal among all the deviators $i$ due to symmetricity (and denoted by $\ut(\astgp)$). We first show that $\frac{1}{\kd} \sum_{i \in D} \ut_i(\stgp) \le \ut(\astgp)$ (the average expected utility of deviators playing $\stgp$ will not exceed the expected utility when each deviator plays $\astg$) and then that $\ut(\astgp) \le \ut(\stgp^*)$ (the expected utility that each deviator play $\astg$ will not exceed the truthful expected utility). 

To show $\frac{1}{\kd} \sum_{i \in D} \ut_i(\stgp) \le \ut(\astgp)$, we compare the expected reward from truthful agents and deviators separately. For a deviator $i$, $\ut_i(\stgp \mid \jtruthful)$ is independent of the strategy of other deviators and is linear on $\bpl$ and $\bph$. Therefore, $\frac{1}{\kd} \sum_{i \in D} \ut_i(\stgp \mid  \jtruthful) = \ut(\astgp \mid \jtruthful)$. 

For the deviator's part, $\ut_i(\stgp \mid \jdeviate)$ is the average of $i$'s expected reward from comparing the report with all other deviators $j \in D$. Such expected reward is linear on $j$'s strategy given a fixed $i$'s strategy and linear on $i$'s strategy given a fixed $j$'s strategy. Therefore, the average expected reward from agents with different strategies equals to the reward from a peer playing the average strategy, and $\ut_i(\stgp \mid \jdeviate)$ equals to $i$'s expected reward from an agent playing the average strategy $\astg$ minus a share of $i$'s expected reward from an agent playing $\stg_i$. Given a strategy $\stg = (\bpl, \bph)$, let $\func(\bpl, \bph)$ be the expected reward of an agent playing $\stg$ from another agents also playing $\stg$. Then
\begin{equation*}
    \frac{1}{\kd}\sum_{i \in D} \ut_i(\stgp\mid \jdeviate) = \frac{\kd}{\kd-1} \func(\abpl, \abph) - \frac{1}{(\kd-1)\kd} \sum_{i\in D} \func(\bpl^i, \bph^i).
\end{equation*}

It turns out that $\func$ is a convex function. Therefore, $ \frac{1}{\kd}\sum_{i \in D} \ut_i(\stgp\mid \jdeviate) \le \func(\abpl, \abph) = \ut(\astgp \mid \jdeviate)$. Combining the truthful part and the deviator part, we show that $\frac{1}{\kd} \sum_{i \in D} \ut_i(\stgp) \le \ut(\astgp)$. 

Finally, we show that $\ut(\astgp) \le \ut(\stgp^*)$. Note that $\ut(\astgp)$ can be viewed as a convex function on $\abpl$ and $\abph$. This is because $\ut(\astgp \mid \jtruthful)$ is linear on $\astg$, and $\ut(\astgp \mid \jdeviate) = \func(\abpl, \abph)$ is convex on $\abpl$ and $\abph$. Therefore, it is sufficient to show that $\ut(\astgp) \le \ut(\stgp^*)$ on the four corner cases of $\astg$: truthful reporting: $\astg = (0, 1)$, always reporting $h$: $ \astg(1,1)$, always reporting $\ell$: $\astg = (0, 0)$, and always tell a lie $\astg = (1, 0)$. 
When $\astg = (0, 1)$, all the deviator also report truthfully, and $\astgp = \stgp^*$. For $\astg = (0, 0)$ and $\astg = (1, 1)$, $\kd \le \kde$ guarantees that $\ut(\astgp) \le \ut(\stgp^*)$. Finally, when $\astg = (1, 0)$, similar reasoning to Step 1 shows that such deviation cannot succeed. \qed

\subsection{Proof Sketch of Theorem~\ref{thm:pp_qi}.}
The steps of the proof resemble the steps of the proof of Theorem~\ref{thm:pp_exante}, yet the techniques are different. In Step 1, we determine $\kdq$ by comparing the \qi{} expected utilities of a deviator when every agent reports truthfully and when all $\kd$ deviators always report $h$ ($\ell$, respectively).
In Step 2, we show that for any $\kd \le \kde$ and any deviating strategy profile $\astgp$ where all the deviators play the same strategy $\astg$, the expected utility of a deviator on $\astgp$ will not exceed the expected utility when every agent reports truthfully. In Step 3, we show that for sufficiently large $\ag$, any $\kd \le \kdq$, and any deviating strategy profile $\stgp$, there exists a deviator whose expected utility is strictly smaller than the expected utility when every agent reports truthfully. The full proof is in Appendix~\ref{apx:qi}. 

The main technical difficulty lies in Step 2 and Step 3. Let $\ut(\astgp \mid h)$ and $\ut(\astgp \mid \ell)$ be the interim expected utility of a deviator conditioned on his/her signal being $h$ and $\ell$, respectively,  when $\astgp$ is played. $\ut(\astgp \mid h)$ and $\ut(\astgp \mid \ell)$ can still be viewed as functions on $\abpl$ and $\abph$. However, unlike the ex-ante $\ut(\astgp)$, they are not convex. Therefore, we cannot get $\frac{1}{\kd} \sum_{i \in D} \ut_i(\stgp \mid h) \le \ut(\astgp \mid h)$ or $\ut(\astgp \mid h) \le \ut(\stgp^* \mid h)$ (or the $\ell$ side) directly from similar reasoning with those in Theorem~\ref{thm:pp_exante}. 

\textbf{In Step 2}, we instead show that for any $\astgp$, either $\ut(\astgp \mid h) \le \ut(\stgp^* \mid h)$ or $\ut(\astgp \mid \ell) \le \ut(\stgp^* \mid \ell)$ holds. Although $\ut(\astgp \mid h)$ is not convex, the convexity (or linearity) still holds in certain directions. Here we slightly abuse the notation to write $\ut(\astgp \mid h)$ as $\ut(\abpl, \abph \mid h)$. The following properties hold. (1) When $\abpl$ is fixed, $\ut(\abpl, \abph \mid h)$ is convex on $\abph$. (2) When $\abph$ is fixed, $\ut(\abpl, \abph \mid h)$ is linear on $\abpl$. (3) When $\abpl = \frac{\pr(h \mid h)}{\pr(\ell \mid h)}\cdot ( 1- \abph)$, $\ut(\abpl, \abph \mid h)$ is linear on $\abph$ and increases when $\abph$ increases. With these properties, we show that $\ut(\abpl, \abph \mid h) \le \ut(\stgp^* \mid h)$ holds in a triangle area as the following lemma indicates.

\begin{lemma}
\label{lem:subspace_h}
    For any $(\abpl, \abph) \in \mathbb{R}^2$ satisfying (1) $\abpl \ge 0$, (2) $\abph \ge 0$, and (3) $\abph + \frac{\pr(\ell \mid h)}{\pr (h \mid h)}\cdot \abpl \le 1$, it always holds that $ \ut(\abpl, \abph \mid h) \le \ut(\stgp^* \mid h)$, and the equality holds only when $\abpl = 0$ and $\abph = 1$. 
\end{lemma}
A similar triangle characterization also applies to the $|\ell$ side. 
\begin{lemma}
\label{lem:subspace_l}
    For any $(\abpl, \abph) \in \mathbb{R}^2$ satisfying (1) $\abpl \le 1$, (2) $\abph \le 1$, and (3) $\abph + \frac{\pr(\ell \mid \ell)}{\pr (h \mid \ell)}\cdot \abpl \ge 1$, it always holds that $ \ut(\abpl, \abph \mid \ell) \le \ut(\stgp^*\mid \ell )$, and the equality holds only when $\abpl = 0$ and $\abph = 1$. 
\end{lemma}

The union of the two triangles covers $[0, 1]^2$, as $\frac{\pr(\ell \mid h)}{\pr(h \mid h)} < \frac{\pr(\ell \mid \ell)}{\pr(h \mid \ell)}$. Therefore, for any $\astg \neq (0, 1)$, the \qi{} expected utility of the deviators will be strictly lower than that of truthful reporting conditioned on at least one of the signals. 

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.9\linewidth]{figures/qi_lemma.pdf}
    \caption{The illustration of Lemma~\ref{lem:subspace_h} and~\ref{lem:subspace_l}. The X-axis and Y-axis denote $\abpl$ and $\abph$ respectively. The two half-planes characterized by two lines cover the $[0,1]^2$ area, so there always exists agents with a certain signal that do not wish to deviate. Two lines are not necessarily located above/below point (1, 0). }
    \label{fig:qi_lemma}
    \Description{The union of the two triangles covers $[0, 1]^2$.}
\end{figure}

\textbf{Step 3} consists of three parts. Here we present the reasoning conditioned on private signal being $h$. The reasoning of the $\ell$ side is similar. Given a deviating strategy $\stgp$, let $\astgp$ be the strategy where all the deviators play the average strategy $\astg = \frac1k \sum_{i \in D} \stg_i$ in $\stgp$. $\astg$ will be located in the area characterized by Lemma~\ref{lem:subspace_h}. In the first part, we show that when the deviators switch from $\astgp$ to $\stgp$, there exists some agent $i$ whose expected utility will not increase by $\frac{C}{\ag - 1}$, where $C$ is a constant related to the scoring rule. Formally, $\ut_i(\stgp \mid h) \le \ut(\astgp \mid h) + \frac{C}{\ag - 1}$. This comes from the fact that $\ut_i(\stgp \mid h) - \ut(\astgp \mid h)$ can be written in the form of $\ut_i(\stgp \mid h) - \ut(\astgp \mid h) = M(\astgp) \cdot (\bph^i - \abph) + O(\frac{1}{\ag - 1})$, where $M$ is a function of $\astgp$. Therefore, for any fixed $\astgp$, either an agent $i$ with $\bph^i \le \abph$ or with $bph^i \ge \abph$ satisfies $\ut_i(\stgp \mid h) \le \ut(\astgp \mid h) + \frac{C}{\ag - 1}$.
In the second part, with similar reasoning for Lemma~\ref{lem:subspace_h}, we show that for sufficiently large $\ag$ and any $\astg$ in the triangle range, $\ut(\astgp \mid h) \ge \ut(\stgp^* \mid h) - \frac{C}{\ag - 1}$ only if $\astg$ is close to $(0, 1)$ or $(0, 0)$. In all other cases, the upper bound of the gain from switching from $\astgp$ to $\stgp$ is insufficient to fill the gap between $\astgp$ and truth-telling $\stgp^*$ ($\ut_i(\stgp \mid h) \le \ut(\astgp \mid h) + \frac{C}{\ag - 1} < \ut(\stgp^* \mid h)$). Finally, we show that in the corner cases, there is a deviator $i$ such that $\ut_i(\stgp \mid h) < \ut(\stgp^* \mid h)$. \qed

% \begin{proof}
%     The reasoning for the \qi{} BNE is similar to that for the ex-ante BNE. We consider the interim expected utility conditioned on $\ell$ and $h$ simultaneously. The proof proceeds in three steps. In the first step, we show a deviation where all agents always report $h$ (or $\ell$) to succeed if and only if $\kd > \kdq$. In the second step, we show that any {\em symmetric} deviation, i.e., all the deviators play the same strategy, with no more than $\kdq$ deviators cannot succeed. Finally, we extend the second step from symmetric deviation to all deviation with no more than $\kdq$ deviators. 
    
    
%     We still follow the two-step procedure. In the first step, we show a deviation where all agents always report $h$ (or $\ell$) to succeed if and only if $\kd > \kdq$. And in the second step, we show that for all $\kd\le \kdq$, any deviation cannot succeed. 

%     \noindent\textbf{Step 1: characterizing $\kdq$.}
    
%     Consider a deviating group $D$ of $k$ agents. In the deviating strategy profile $\stgp$, all the deviators always report $h$, i.e. $\stg = (1, 1)$. We fix an arbitrary deviator $i \in D$. In the \qi{} setting, the condition for the deviation is successful is $\ut_i(\stgp\mid h) \ge \ut_i(\stgp^*\mid h)$ and $\ut_i(\stgp\mid \ell) \ge \ut_i(\stgp^*\mid \ell)$ hold, and at least one of the inequality is strict. 

%     Similar to the ex-ante's proof, let $\ut_i(\stgp\mid \sigi_i, \jdeviate)$ $\ut_i(\stgp\mid \sigi_i, \jtruthful)$ be the average expected utility from all other deviators (truthful agents, respectively) conditioned on $i$'s signal being $\sigi_i$. And let $\dut_{d\mid \sigi_i} = \ut_i(\stgp^* \mid \sigi_i) - \ut_i(\stgp\mid \sigi_i, \jdeviate)$ and $\dut_{t\mid \sigi_i} = \ut_i(\stgp^* \mid \sigi_i) - \ut_i(\stgp\mid \sigi_i, \jtruthful)$. 

%     For expected utility on $\stgp^*$, we have
% \begin{align*}
%     \ut_i(\stgp^* \mid h) = &\ \pr(h \mid h) \cdot \ps(h, \vpr_h) + \pr(\ell \mid h) \cdot \ps(\ell, \vpr_h),\\
%     \ut_i(\stgp^* \mid \ell) = &\ \pr(h \mid \ell) \cdot \ps(h, \vpr_\ell) + \pr(\ell \mid \ell) \cdot \ps(\ell, \vpr_\ell). 
% \end{align*}
%     And for expected utility of $\stgp$, we have 
% \begin{align*}
%     \ut_i(\stgp\mid h, \jtruthful) = &\ \pr(h \mid h) \cdot \ps(h, \vpr_h) + \pr(\ell \mid h) \cdot \ps(\ell, \vpr_h)\\
%      \ut_i(\stgp\mid \ell, \jtruthful) =&\ \pr(h \mid \ell) \cdot \ps(h, \vpr_h) + \pr(\ell \mid \ell) \cdot \ps(\ell, \vpr_h). 
% \end{align*}
% Therefore, $\ut_i(\stgp^* \mid h) = \ut_i(\stgp\mid h, \jtruthful)$, and $\dut_{t\mid h} = 0$. Also for the $\ell$ side, $\dut_{t\mid \ell} = \Ex_{\sigi\sim \vpr_{\ell}}[\ps(\sigi, \vpr_{\ell}) - \ps(\sigi, \vpr_{h})]$. 

% For the deviator's part, we have $\ut_i(\stgp\mid h, \jdeviate) = \ut_i(\stgp\mid \ell, \jdeviate) = \ps(h, \vpr_h)$. 

% Then we have 
% \begin{align*}
%     \dut_{t\mid h} - \dut_{d\mid h} =&\ \pr(\ell \mid h) \cdot (\ps(h, \vpr_h) - \ps(\ell, \vpr_h)).\\
%     \dut_{t\mid \ell} - \dut_{d\mid \ell} =&\ \pr(\ell \mid \ell) \cdot (\ps(h, \vpr_h) - \ps(\ell, \vpr_h)).
% \end{align*}

% When $\ps(h, \vpr_h) \le  \ps(\ell, \vpr_h)$, neither agents with private signal $h$ nor those with $\ell$ can get strictly positive expected utility via deviation, and the deviation cannot succeed. When $\ps(h, \vpr_h) >  \ps(\ell, \vpr_h)$, for the $h$ side, the condition for deviation to achieve non-negative expected utility (not strictly positive!) is
% \begin{equation*}
%     k \ge \frac{\dut_{t\mid h}}{\dut_{t\mid h} - \dut_{d\mid h}}\cdot (n-1) + 1 = 1,
% \end{equation*}
% and for the $\ell$ side, the condition is
% \begin{equation*}
%     k \ge \frac{\dut_{t\mid \ell}}{\dut_{t\mid \ell} - \dut_{d\mid \ell}}\cdot (n-1) + 1 = \frac{\Ex_{\sigi\sim \vpr_{\ell}}[\ps(\sigi, \vpr_{\ell}) - \ps(\sigi, \vpr_{h})]}{ \pr(\ell \mid \ell) \cdot (\ps(h, \vpr_h) - \ps(\ell, \vpr_h))}\cdot (n-1) + 1 > 1.
% \end{equation*}

% When $k \ge \frac{\Ex_{\sigi\sim \vpr_{\ell}}[\ps(\sigi, \vpr_{\ell}) - \ps(\sigi, \vpr_{h})]}{ \pr(\ell \mid \ell) \cdot (\ps(h, \vpr_h) - \ps(\ell, \vpr_h))}\cdot (n-1) + 1$, deviators with signal $h$ get strictly higher expected utility, and deviators with $\ell$ get non-decreasing expected utility. Therefore, the deviation will succeed. 
% This is how $\kdq^h$ is defined.
% $\kdq^\ell$ is defined similarly by consider strategy $(0, 0)$. 
% Therefore, for all $k \le \kdq$, both deviations of always reporting $h$ and always reporting $\ell$ cannot succeed.

% \noindent\textbf{Step 2: Symmetric deviaton cannot succeed for $\kd \le \kdq.$}

% We first introduce a function that will be widely applied in Step 2 and 3. Let $\func^h(\bph', (\bpl, \bph)): \mathbb{R} \times \mathbb{R}^2 \to \mathbb{R}$ be the expected reward of an agent $i$ who has signal $h$ and will report $h$ with probability $\bph'$, given that $i$'s peer $j$ plays the strategy $\stg = (\bpl, \bph)$. 

% \begin{align*}
%     \func^h(\bph', (\bpl, \bph)) = &\ \Ex_{\rp_i \sim \bph'} \Ex_{\sigi_j \sim \vpr_{h}, \rp_j \sim (\bpl,\bph)} \ps(\rp_j, \vpr_{\rp_i})\\
%     =&\ \bph'((\pr(h\mid h)\cdot \bph + \pr(\ell\mid h)\cdot \beta_\ell)\cdot \ps(h, \vpr_h)\\
%     &\ + (1 -  \pr(h\mid h)\cdot \bph - \pr(\ell\mid h)\cdot \beta_\ell)\cdot \ps(\ell,\vpr_h))\\
%      + &\ (1 - \bph')\cdot ((\pr(h\mid h)\cdot \bph + \pr(\ell\mid h)\cdot \beta_\ell)\cdot \ps(h, \vpr_\ell)\\
%     &\ + (1 -  \pr(h\mid h)\cdot \bph - \pr(\ell\mid h)\cdot \beta_\ell)\cdot \ps(\ell,\vpr_\ell)). 
% \end{align*}

% Similarly, we define $\func^{\ell}$. 
% \begin{align*}
%     \func^\ell(\bpl', (\bpl, \bph)) = &\ \Ex_{\rp_i \sim \bph'} \Ex_{\sigi_j \sim \vpr_{h}, \rp_j \sim (\bpl,\bph)} \ps(\rp_j, \vpr_{\rp_i})\\
%     =&\ \bpl'((\pr(h\mid \ell)\cdot \bph + \pr(\ell\mid \ell)\cdot \beta_\ell)\cdot \ps(h, \vpr_h)\\
%      + &\ (1 -  \pr(h\mid \ell)\cdot \bph - \pr(\ell\mid \ell)\cdot \beta_\ell)\cdot \ps(\ell,\vpr_h))\\
%     &\ + (1 - \bpl')\cdot ((\pr(h\mid \ell)\cdot \bph + \pr(\ell\mid \ell)\cdot \beta_\ell)\cdot \ps(h, \vpr_\ell)\\
%     &\ + (1 -  \pr(h\mid \ell)\cdot \bph - \pr(\ell\mid \ell)\cdot \beta_\ell)\cdot \ps(\ell,\vpr_\ell)). 
% \end{align*}

% Moreover, let $\gunc^h(\bpl, \bph) = \func^h(\bph, (\bpl, \bph))$, and $\gunc^\ell(\bpl, \bph) = \func^\ell(\bpl, (\bpl, \bph))$. $\gunc^h$ and $\gunc^\ell$ cover the special case where $i$ and $j$ play the same strategy and will be largely applied in Step 2. 

% \begin{claim}
% We claim that $\func^h$ and $\gunc^h$ has the following properties. 
%     \begin{enumerate}
%         \item $\frac{\partial^2\gunc^h}{\partial \bph^2} = 2\pr(h\mid h)\cdot (\ps(h, \vpr_h) - \ps(h, \vpr_\ell) - \ps(\ell,\vpr_h) + \ps(\ell, \vpr_\ell)) > 0$. 
%         \item $\frac{\partial^2\gunc^h}{\partial \bpl^2} = 0$. 
%         \item Let $\alpha_h = \frac{\pr(h\mid h)}{\pr(\ell \mid h)}$, and let $b_h \ge 0$ be a constant. When fixing $\bpl = \alpha_h \cdot (b_h - \bph)$, then 
%         \begin{equation*}
%             \frac{\partial\func^h(\bph', (\alpha_h(b_h - \bph), \bph))}{\partial \bph'} = b_h\cdot \pr(h\mid h)\cdot (\ps(h, \vpr_h) - \ps(h, \vpr_\ell)) + (1 - b_h\cdot \pr(h\mid h))\cdot (\ps(\ell, \vpr_h) - \ps(\ell, \vpr_\ell)). 
%         \end{equation*}
%         Specifically, when $b_h=1$, $\frac{\partial\func^h(\bph', (\alpha_h(b_h - \bph), \bph))}{\partial \bph'} = \Ex_{\sigi\sim \vpr_{h}}[\ps(\sigi, \vpr_{h}) - \ps(\sigi, \vpr_{\ell})] > 0$.
%     \end{enumerate}
% \end{claim}

% \begin{claim}
% We claim that $\func^\ell$ and $\gunc^\ell$ has the following properties. 
%     \begin{enumerate}
%         \item $\frac{\partial^2\gunc^\ell}{\partial \bpl^2} = 2\pr(\ell\mid \ell)\cdot (\ps(h, \vpr_h) - \ps(h, \vpr_\ell) - \ps(\ell,\vpr_h) + \ps(\ell, \vpr_\ell)) > 0$. 
%         \item $\frac{\partial^2\gunc^\ell}{\partial \bph^2} = 0$. 
%         \item Let $\alpha_\ell = \frac{\pr(\ell \mid \ell)}{\pr(h \mid \ell)}$, and let $b_\ell \ge 0$ be a constant. When fixing $\bph = (b_\ell - \alpha_\ell 
%  \cdot\bpl)$, then 
%         \begin{equation*}
%         \frac{\partial\func^\ell(\bpl', (\bpl, (b_\ell - \alpha_\ell 
%         \cdot\bpl)))}{\partial \bpl'} = b_\ell \cdot \pr(h\mid \ell)\cdot (\ps(h, \vpr_h) - \ps(h, \vpr_\ell)) + (1 - b_\ell \cdot \pr(h\mid \ell))\cdot (\ps(\ell, \vpr_h) - \ps(\ell, \vpr_\ell)). 
%         \end{equation*}
%         Specifically, when $b_\ell =1$, $\frac{\partial\func^\ell(\bpl', (\bpl, (b_\ell - \alpha_\ell 
%  \cdot\bpl)))}{\partial \bpl'} = \Ex_{\sigi\sim \vpr_{\ell}}[\ps(\sigi, \vpr_{h}) - \ps(\sigi, \vpr_{\ell})] < 0$.
%     \end{enumerate}
% \end{claim}

% Now we start to characterize the deviation.
% We fix an arbitrary $\kd$. Let $\astg = (\abpl, \abph)$ be the strategy on all deviators. Since all the deviators play the same strategy, they receive the same  For truthful reporting, agents with the same signal have the same expected utility. 

% The expected utility of deviator with private signal $h$ conditioned on his/her peer $j$ is a truthful agent is $\ut(\abpl, \abph \mid h, \jtruthful) = \func^h(\abph, (0, 1))$, and that conditioned on $j$ is also a deviator is $\ut(\abpl, \abph \mid h, \jdeviate) = \func^h(\abph, (\abpl, \abph)) = \gunc^h(\abpl, \abph)$. Similarly, for the $\ell$ side we have $\ut(\abpl, \abph \mid \ell, \jtruthful) = \func^\ell(\abpl, (0, 1))$ and $\ut(\abpl, \abph \mid \ell, \jdeviate) = \func^\ell(\abpl, (\abpl, \abph)) = \gunc^l(\abpl, \abph)$. Therefore, the expected reward of deviation can be represented by the following function. 
% \begin{align*}
%     \ut(\abpl, \abph \mid h) = \frac{\ag-\kd}{\ag - 1} \cdot \ut(\abpl, \abph \mid h, \jtruthful) + \frac{\kd - 1}{\ag - 1} \cdot \ut(\abpl, \abph \mid h, \jdeviate),\\
%      \ut(\abpl, \abph \mid \ell) =  \frac{\ag-\kd}{\ag - 1} \cdot \ut(\abpl, \abph \mid \ell, \jtruthful) + \frac{\kd - 1}{\ag - 1} \cdot \ut(\abpl, \abph \mid \ell, \jdeviate).
% \end{align*}

% Now we show that for any $\astg = (\abpl, \abph) \in [0, 1]^2$, either $ \ut(\abpl, \abph \mid h) \le \ut(\stgp^* \mid h)$ or $ \ut(\abpl, \abph \mid \ell) \le \ut(\stgp^* \mid \ell)$. 

% \begin{lemma}
% \label{lem:subspace_h}
%     For any $(\abpl, \abph) \in \mathbb{R}^2$ satisfying (1) $\abpl \ge 0$, (2) $\abph \ge 0$, and (3) $\abph + \frac{\pr(\ell \mid h)}{\pr (h \mid h)}\cdot \abpl \le 1$, it always holds that $ \ut(\abpl, \abph \mid h) \le \ut(\stgp^* \mid h)$. 
% \end{lemma}

% \begin{proof}[Proof of Lemma~\ref{lem:subspace_h}]
%     The proof proceeds in three steps. First, we show that $\ut(0, \abph \mid h) \le \ut(\stgp^* \mid h)$ for any $\bph$. This holds for the following three reasons. First, $\ut(0, 1 \mid h) =  \ut(\stgp^* \mid h)$, as in this case all the deviators report truthfully and no deviation happens. Second, $\ut(0, 0 \mid h) \le  \ut(\stgp^* \mid h)$ is guaranteed by $\kd \le \kdq$. Finally, since $\ut(\abpl, \abph \mid h, \jtruthful)$ is linear and $\ut(\abpl, \abph \mid h, \jdeviate)$ is convex on $\abph$, $\ut(0, \abph \mid h)$ is also convex on $\abph$. The convexity bound the expected utility for every $0 < \abph < 1$. 

%     Second, we show that $\ut(\abpl, \abph \mid h) \le \ut(\stgp^* \mid h)$ when $\abpl = \frac{\pr(h\mid h)}{\pr(\ell \mid h)}(1 - \abph)$ for any $\abph \in [0, 1]$. This is because the derivative 
%     \begin{align*}
%         \frac{\partial \ut(\frac{\pr(h\mid h)}{\pr(\ell \mid h)}(1 - \abph), \abph \mid h)}{\partial \abph} =&\  \frac{\ag-\kd}{\ag - 1} \cdot \frac{\partial \func^h(\abph, (0, 1))}{\partial \abph} + \frac{\kd - 1}{\ag - 1} \cdot \frac{\partial \gunc^h(\frac{\pr(h\mid h)}{\pr(\ell \mid h)}(1 - \abph), \abph))}{\partial \abph}\\
%         =&\ \Ex_{\sigi\sim \vpr_{h}}[\ps(\sigi, \vpr_{h}) - \ps(\sigi, \vpr_{\ell})]\\
%         > &\ 0.
%     \end{align*}
%     Therefore, For any $(\abpl, \abph)$ with $\abph\le 1$ and $\abpl = \frac{\pr(h\mid h)}{\pr(\ell \mid h)}(1 - \abph)$, $\ut(\abpl, \abph \mid h) \le \ut(0, 1 \mid h) = \ut(\stgp^* \mid h)$.

%     Finally, we extend the result to any $(\abpl, \abph)$ in the area. For any $\abph \in [0, 1]$, we have shown that  $\ut(0, \abph \mid h) \le \ut(\stgp^*\mid h)$ and $\ut(\frac{\pr(h\mid h)}{\pr(\ell \mid h)}(1 - \abph), \abph \mid h) \le \ut(\stgp^*\mid h)$. Then by the linearity of $\ut(\abpl, \abph \mid h)$ on $\abpl$, $\ut(\abpl, \abph \mid h) \le \ut(\stgp^* \mid h)$ for any $\abpl \in [0, \frac{\pr(h\mid h)}{\pr(\ell \mid h)}(1 - \abph)]$, which finishes the proof. 
% \end{proof}

% Similarly, for $\ell$ side, we have 

% \begin{lemma}
% \label{lem:subspace_l}
%     For any $(\abpl, \abph) \in \mathbb{R}^2$ satisfying (1) $\abpl \le 1$, (2) $\abph \le 1$, and (3) $\abph + \frac{\pr(\ell \mid \ell)}{\pr (h \mid \ell)}\cdot \abpl \ge 1$, it always holds that $ \ut(\abpl, \abph \mid \ell) \le \ut(\stgp^*\mid \ell )$. 
% \end{lemma}

% \begin{proof}[Proof of Lemma~\ref{lem:subspace_l}]
%     The proof follows the proof of Lemma~\ref{lem:subspace_h}. First, $\ut(\abpl, 1 \mid \ell) \le \ut(\stgp^* \mid \ell)$ for any $\abpl \in [0, 1]$ due to the convexity of $\ut(\abpl, \abph \mid \ell)$ on $\abpl$. Secondly, $\ut(\abpl, \abph \mid \ell) \le \ut(\stgp^* \mid \ell)$ when $\abph + \frac{\pr(\ell \mid \ell)}{\pr (h \mid \ell)}\cdot \abpl = 1$, the derivative 
%     \begin{align*}
%         \frac{\partial \ut(\abpl, 1 - \frac{\pr(\ell \mid \ell)}{\pr (h \mid \ell)}\cdot \abpl \mid \ell)}{\partial \abpl} =&\  \frac{\ag-\kd}{\ag - 1} \cdot \frac{\partial \func^\ell(\abpl, (0, 1))}{\partial \abpl} + \frac{\kd - 1}{\ag - 1} \cdot \frac{\partial \gunc^\ell(\abpl, 1 - \frac{\pr(\ell \mid \ell)}{\pr (h \mid \ell)}\cdot \abpl)}{\partial \abpl}\\
%         =&\ \Ex_{\sigi\sim \vpr_{\ell}}[\ps(\sigi, \vpr_{h}) - \ps(\sigi, \vpr_{\ell})]\\
%         < &\ 0.
%     \end{align*}
%     Therefore, for any $\abpl\ge 0$ on the line, the expected reward does not exceed $\ut(\stgp^* \mid \ell)$. Finally, for any other $(\abpl, \abph)$ in the area, we apply the linearity of $\ut(\abpl, \abph \mid \ell)$ on $\abph$. 
% \end{proof}

% Note that for any pair of $(\abpl, \abph) \in [0, 1]^2$, at least one of $\abph + \frac{\pr(\ell \mid h)}{\pr (h \mid h)}\cdot \abpl \le 1$ and $\abph + \frac{\pr(\ell \mid \ell)}{\pr (h \mid \ell)}\cdot \abpl \ge 1$ holds. This comes from $\pr(h\mid h) > \pr(h \mid \ell)$ and $\pr(\ell \mid \ell) > \pr(\ell \mid h)$. Therefore, we can apply either Lemma~\ref{lem:subspace_h} or~\ref{lem:subspace_l} to show that the deviation cannot succeed. 

% \noindent{\bf Step 3: General deviation cannot succeed for $k \le k_Q$. }

% In this section, we assume $\ag$ to be sufficiently large ($n >> \max \Delta PS$. TBD).
% Let $\maxdps$ be the largest difference in the positional scoring rule. 
% Step 3 proceeds as follows. First, when deviators play asymmetrically, we compare the worst expected utility among the agent with the expected utility when all deviators play their "average" strategy $\astg = \sum_{i\in D} \frac{1}{k} \stg_i$. We show that the reward of the worst agent cannot be better than the reward of the average strategy by $O (\frac{\maxdps}{n - 1})$. Then we show that the reward of the average strategy is no less than the truthful reward by $\Theta (\frac{\maxdps}{n - 1})$ only when $\astg$ is close to $(0, 1)$ or $(0, 0)$. Finally, we deal with the corner cases and show that in this case, the worst agent cannot be better than the truthful reward. We will give the proof on the $h$ side (or specifically, conditioned on an agent having private signal $h$). The $\ell$ side follows similar reasoning. 

% Only in step step, let $\dpsh = \ps(h, \vpr_h) - \ps(h, \vpr_\ell)$, and $\dpsl = \ps(\ell, \vpr_{\ell}) - \pr(\ell, \vpr_h)$. From Lemma~\ref{lem:pr_psr}, we have $\dpsh > 0$ and $\dpsl > 0$. 

% Now let $\astg = (\abpl, \abph)$ be the {\em average strategy} of all the deviators, i.e. $\astg = \frac{1}{k} \sum_{j\in D} \stg_j$. And $\stg_i = (\bpl^i, \bph^i)$ be the strategy of a deviator $i\in D$. We represent the expected utility of $i$ with $\func^h$, $\func^\ell$, $\gunc^h$, and $\gunc^\ell$. 

% The expected utility of $i$ conditioned on his/her peer $j$ is a truthful agent is $\ut(\bpl^i, \bph^i \mid h, \jtruthful) = \func^h(\bph^i, (0, 1))$. and that conditioned on $j$ is also a deviator is 

% \begin{align*}
%     \ut(\bpl^i, \bph^i \mid h, \jdeviate) = \frac{1}{\kd - 1} \sum_{j \in D, j\neq i} f(\bph^i, (\bpl^j, \bph^j)). 
% \end{align*}

% An important observation is that for a fixed $\bph'$, $\func^h(\bph', (\bpl, \bph)$ is linear on $\bpl$ and $\bph$. Therefore, 

% \begin{align*}
%     \ut(\bpl^i, \bph^i \mid h, \jdeviate) =&\ \frac{\kd}{\kd - 1} f(\bph^i, (\abpl, \abph)) - \frac{1}{\kd-1} f(\bph^i, (\bpl^i, \bph^i))\\
%     =&\ f(\bph^i, (\abpl, \abph)) + \frac{1}{\kd-1} (f(\bph^i, (\abpl, \abph)) - f(\bph^i, (\bpl^i, \bph^i))).
% \end{align*}

% Adding two parts together, we have
% \begin{align*}
%     \ut(\bpl^i, \bph^i \mid h) = \frac{\ag-\kd}{\ag - 1} \cdot \ut(\bpl^i, \bph^i \mid h, \jtruthful) + \frac{\kd - 1}{\ag - 1} \cdot \ut(\bpl^i, \bph^i \mid h, \jdeviate).
% \end{align*}

% Then we consider the difference of agent $i$'s utility between when all the deviators play the average strategy $\astg$ and when the deviators play differently with $i$ playing $\stg_i$. 

% \begin{align*}
%     \ut(\bpl^i, \bph^i \mid h) - \ut(\abpl, \abph \mid h) = &\frac{\ag-\kd}{\ag - 1} \cdot (\func^h(\bph^i, (0, 1)) - \func^h(\abph, (0, 1))) \\
%     &\ + \frac{\kd - 1}{\ag - 1} (f(\bph^i, (\abpl, \abph)) - f(\abph, (\abpl, \abph)))\\
%     &\ +\frac{\kd - 1}{\ag - 1} \cdot \frac{1}{\kd-1} (f(\bph^i, (\abpl, \abph)) - f(\bph^i, (\bpl^i, \bph^i)))\\
%     =&\ \frac{\ag-\kd}{\ag - 1} \cdot \func^h(\bph^i - \abph, (0, 1)) + \frac{\kd - 1}{\ag - 1} f(\bph^i - \abph, (\abpl, \abph))\\
%     &\ +\frac{1}{\ag-1} (f(\bph^i, (\abpl, \abph)) - f(\bph^i, (\bpl^i, \bph^i))).
% \end{align*}
% The second equality comes from the fact that $\func^h(\bph', (\bpl, \bph))$ is linear on $\bph'$ for any fixed $(\bpl, \bph)$. Given a fixed $\astg = (\abpl, \abph)$, the term
% $$\frac{\ag-\kd}{\ag - 1} \cdot \func^h(\bph^i - \abph, (0, 1)) + \frac{\kd - 1}{\ag - 1} f(\bph^i - \abph, (\abpl, \abph)) $$
% equals to 0 when $\bph^i = \abph$ and is linear on $\bph^i$. Therefore, either when $\bph^i \le \abph$ or $\bpl^i \le \abpl$, the term will be no larger than zero. 

% On the other hand, the third term $\frac{1}{\ag-1} (f(\bph^i, (\abpl, \abph)) - f(\bph^i, (\bpl^i, \bph^i))) \le \frac{\maxdps}{\ag - 1}$
% Therefore, there exists a deviator $i$ such that $\ut(\bpl^i, \bph^i \mid h) - \ut(\abpl, \abph \mid h) \le \frac{\maxdps}{\ag - 1}$. 

% Then we show that for sufficiently large $\ag$, for all $(\abpl, \abph)$ not close to $(0,1)$ or $(0, 0)$, $\ut(\stgp^* \mid h) - \ut(\abpl, \abph \mid h) \ge \frac{\maxdps}{\ag - 1}$. 

% \begin{lemma}
%     \label{lem:corner}
%     Let $\dut(\abpl, \abph \mid h) = \ut(\stgp^* \mid h) - \ut(\abpl, \abph \mid h)$. Then for any $\abph \in [0, 1]$ and $\abpl \in [0, \frac{\pr(h\mid h)}{\pr(\ell \mid h)} \cdot ( 1- \abph)]$ (i.e., the range in Lemma~\ref{lem:subspace_h}), $\dut(\abpl, \abph \mid h) \le \frac{\maxdps}{\ag - 1}$ only if one of the following two holds: (1) $\abph \ge 1 - \bphth$, or (2) $\abph \le \bphth$ and $\abpl \le \frac{\pr(h \mid h)}{\pr(\ell \mid h)} \cdot \bphth$, where 
%     \begin{equation*}
%    \bphth = \frac{4\maxdps\cdot (\dpsh + \dpsl + \ps(\ell, \vpr_{\ell}) - \ps(h, \vpr_\ell))}{ (\ag - 1)\cdot (\dpsh +\dpsl)\cdot  \Ex_{\sigi \sim \vpr_h}[\ps(\sigi, \vpr_h) - \pr(\sigi, \vpr_\ell)]}.
% \end{equation*}
% \end{lemma}


% We first consider the case when $\abpl = 0$. Note that $\dut(0, \abph \mid h)$ is a quadratic function of $\abph$ satisfying (1) $\dut (0, 1 \mid h) = 0$, (2) $\frac{\partial^2\dut (\abph, 0 \mid h)}{\partial \abph^2} = -\frac{2(\kd - 1)}{\ag - 1}\cdot \pr(h\mid h)\cdot (\dpsh + \dpsl) < 0$, and (3) another root other than $1$, denoted by $\bph''$, satisfies $\bph'' \le  0$. If (3) does not hold, we will have $\dut(0, 0 \mid h) < 0$, which is a contradiction. 

% According to the property of the quadratic function, $\dut(\abpl, \abph \mid h)$ is maximized at $\frac{1 + \bph''}{2} = $
% $$\frac{(\kd -1)\cdot (\dpsl + \pr(h\mid h)\cdot (\ps(\ell, \vpr_{\ell}) - \ps(h, \vpr_\ell)) + (\ag - \kd)\cdot (\pr(h\mid h)\cdot (-\dpsh) + \pr(\ell \mid h) \cdot \dpsl)}{2(\kd - 1)\cdot (\pr(h\mid h) \cdot (\dpsh + \dpsl))}$$ 
% with value 
% \begin{align*}
%     &\ \frac{\kd - 1}{4(\ag - 1)}\cdot \pr(h\mid h)\cdot (\dpsh + \dpsl) \cdot (1 - \bph'')^2\\
%     \ge &\ \frac{\kd - 1}{4(\ag - 1)}\cdot \pr(h\mid h)\cdot (\dpsh + \dpsl). 
% \end{align*}

% We consider three different cases

% Firstly, when $\ps(\ell, \vpr_{\ell}) - \ps(h, \vpr_\ell) \le 0$. In this case, we show that $\ut(0, 0 \mid h)$ is faraway from $\ut(\stgp*\mid h)$. Therefore, $\ut(\stgp^* \mid h) - \ut(0, \abph \mid h) < \frac{\maxdps}{\ag - 1}$ only if $\abph$ is close to 1. Note that in this case, 
% \begin{align*}
%     \ut(0, 0\mid h, \jdeviate) = &\ \ps(\ell, \vpr_\ell)\\
%     \le &\ \pr(h\mid h) \cdot \pr(\ell, \vpr_h) + \pr(\ell\mid h) \cdot \ps(\ell, \vpr_\ell). 
% \end{align*}

% Therefore, 
% \begin{align*}
%     \dut(0, 0 \mid h) = &\ \ut(\stgp^* \mid h) - \ut(0, 0\mid h)\\
%     \ge &\ \pr(h\mid h) \cdot \dpsh - \pr(\ell\mid h) \cdot \dpsl\\
%     =&\ \Ex_{\sigi \sim \vpr_h}[\ps(\sigi, \vpr_h) - \pr(\sigi, \vpr_\ell)]\\
%     > &\ 0. 
% \end{align*}

% Then, give that $\dut(0, \abph \mid h)$ is convex on $\abph$, for all $\abph \in [0, 1]$, 
% $$\dut(0, \abph \mid h) \ge (1 - \abph) \cdot \Ex_{\sigi \sim \vpr_h}[\ps(\sigi, \vpr_h) - \pr(\sigi, \vpr_\ell)]. $$

% Therefore, $\dut(0, \abph \mid h) \ge \frac{\maxdps}{ \ag - 1}$ for any $0 \le  \abph \le 1 - \frac{\maxdps}{ (\ag - 1)\cdot \Ex_{\sigi \sim \vpr_h}[\ps(\sigi, \vpr_h) - \pr(\sigi, \vpr_\ell)]}$. 

% Secondly, when $\ps(\ell, \vpr_{\ell}) - \ps(h, \vpr_\ell) \le 0$ and $\frac{1 + \bph''}{2} \le 0$, we still prove that $\ut(0, 0 \mid h)$ is faraway from $\ut(\stgp*\mid h)$. Note that when $\frac{1 + \bph''}{2} \le 0$, the condition holds that 
% \begin{equation*}
%     \kd \le \frac{\Ex_{\sigi \sim \vpr_h}[\ps(\sigi, \vpr_h) - \pr(\sigi, \vpr_\ell)]}{\pr(h\mid h) \cdot (\dpsh + \dpsl + \ps(\ell, \vpr_{\ell}) - \ps(h, \vpr_\ell))}\cdot (n-1) + 1. 
% \end{equation*}

% Then, 
% \begin{align*}
%     \dut(0, 0 \mid h) = &\ \frac{1}{\ag - 1} ((\kd - 1)\cdot (\ut(0, 0\mid h, \jtruthful) -  \ut(0, 0\mid h, \jdeviate))\\
%     &\ + (\ag - 1)\cdot (\ut(\stgp^* \mid h) -  \ut(0, 0\mid h, \jtruthful)))\\
%     \ge &\ \frac{1}{\pr(h \mid h)(\dpsh + \dpsl + \ps(\ell, \vpr_{\ell}) - \ps(h, \vpr_\ell))}\\
%     &\ \cdot (-\Ex_{\sigi \sim \vpr_h}[\ps(\sigi, \vpr_h) - \pr(\sigi, \vpr_\ell)] \cdot \pr(h \mid h) \cdot (\ps(\ell, \vpr_\ell) - \ps(h, \vpr_\ell))\\
%     &\ + \pr(h\mid h)\cdot (\dpsh + \dpsl + \ps(\ell, \vpr_{\ell}) - \ps(h, \vpr_\ell)) \cdot \Ex_{\sigi \sim \vpr_h}[\ps(\sigi, \vpr_h) - \pr(\sigi, \vpr_\ell)])\\
%     =&\  \frac{(\dpsh + \dpsl) \cdot \Ex_{\sigi \sim \vpr_h}[\ps(\sigi, \vpr_h) - \pr(\sigi, \vpr_\ell)]}{(\dpsh + \dpsl + \ps(\ell, \vpr_{\ell}) - \ps(h, \vpr_\ell))}\\
%     > &\ 0. 
% \end{align*}

% Therefore,  $\dut(0, \abph \mid h) \ge \frac{\maxdps}{ \ag - 1}$ for any $0 \le  \abph \le 1 - \frac{\maxdps\cdot (\dpsh + \dpsl + \ps(\ell, \vpr_{\ell}) - \ps(h, \vpr_\ell))}{ (\ag - 1)\cdot (\dpsh +\dpsl)\cdot  \Ex_{\sigi \sim \vpr_h}[\ps(\sigi, \vpr_h) - \pr(\sigi, \vpr_\ell)]}$. 

% Thirdly, when $\ps(\ell, \vpr_{\ell}) - \ps(h, \vpr_\ell) \le 0$ and $\frac{1 + \bph''}{2} > 0$,  
% \begin{equation*}
%     \kd > \frac{\Ex_{\sigi \sim \vpr_h}[\ps(\sigi, \vpr_h) - \pr(\sigi, \vpr_\ell)]}{\pr(h\mid h) \cdot (\dpsh + \dpsl + \ps(\ell, \vpr_{\ell}) - \ps(h, \vpr_\ell))}\cdot (n-1) + 1. 
% \end{equation*}

% Therefore, For any $\bph \in [\frac{1 + \bph''}{2}, 1]$, 
% \begin{align*}
%    \dut(0, \abph \mid h) \ge&\  (1 - \abph) \cdot \frac{\kd - 1}{4(\ag - 1)}\cdot \pr(h\mid h)\cdot (\dpsh + \dpsl)\\
%    \ge &\ (1 - \abph) \cdot  \frac{\Ex_{\sigi \sim \vpr_h}[\ps(\sigi, \vpr_h) - \pr(\sigi, \vpr_\ell)]\cdot (\dpsh + \dpsl)}{4 (\dpsh + \dpsl + \ps(\ell, \vpr_{\ell}) - \ps(h, \vpr_\ell))}
% \end{align*}

% Similarly, for any $\bph \in [0, \frac{1 + \bph''}{2}]$, 
% \begin{equation*}
%    \dut(0, \abph \mid h)
%    \ge \abph \cdot  \frac{\Ex_{\sigi \sim \vpr_h}[\ps(\sigi, \vpr_h) - \pr(\sigi, \vpr_\ell)]\cdot (\dpsh + \dpsl)}{4 (\dpsh + \dpsl + \ps(\ell, \vpr_{\ell}) - \ps(h, \vpr_\ell))}.
% \end{equation*}

% Therefore, $\dut(0, \abph \mid h) \ge \frac{\maxdps}{ \ag - 1}$ for any 
% $\bphth \le  \abph \le 1 - \bphth$, 
% where $$\bphth = \frac{4\maxdps\cdot (\dpsh + \dpsl + \ps(\ell, \vpr_{\ell}) - \ps(h, \vpr_\ell))}{ (\ag - 1)\cdot (\dpsh +\dpsl)\cdot  \Ex_{\sigi \sim \vpr_h}[\ps(\sigi, \vpr_h) - \pr(\sigi, \vpr_\ell)]}.$$

% Then we consider when $\abpl = \frac{\pr(h\mid h)}{\pr(\ell \mid h)} \cdot (1 - \abph)$. From Lemma~\ref{lem:subspace_h}, $$\frac{\partial \ut(\frac{\pr(h\mid h)}{\pr(\ell \mid h)}(1 - \abph), \abph \mid h)}{\partial \abph} = \Ex_{\sigi\sim \vpr_{h}}[\ps(\sigi, \vpr_{h}) - \ps(\sigi, \vpr_{\ell})] > 0.$$ 

% Therefore, for any $0\le \abph\le 1 - \frac{\maxdps}{ (\ag - 1)\cdot \Ex_{\sigi \sim \vpr_h}[\ps(\sigi, \vpr_h) - \pr(\sigi, \vpr_\ell)]}$,  $\dut(\frac{\pr(h\mid h)}{\pr(\ell \mid h)} \cdot (1 - \abph), \abph \mid h) \ge \frac{\maxdps}{ \ag - 1}$.

% Then, by the linearity of $\dut (\abpl, \abph \mid h)$ on $\abpl$, we know that for any $\bphth \le  \abph \le 1 - \bphth$ and any $0\le \abpl \le \frac{\pr(h\mid h)}{\pr(\ell \mid h)} \cdot (1 - \abph)$, $\dut(\abpl, \abph \mid h) \ge \frac{\maxdps}{ \ag - 1}$, the threshold comes out that $\bphth$ is the largest among all the threshold.  

% Then we consider $0\le \abph \le \bphth$.
% We have \begin{equation*}
%    \dut(0, \abph \mid h)
%    \ge \abph \cdot  \frac{\Ex_{\sigi \sim \vpr_h}[\ps(\sigi, \vpr_h) - \pr(\sigi, \vpr_\ell)]\cdot (\dpsh + \dpsl)}{4 (\dpsh + \dpsl + \ps(\ell, \vpr_{\ell}) - \ps(h, \vpr_\ell))}
% \end{equation*}
% and
% \begin{align*}
%    \dut(\frac{\pr(h\mid h)}{\pr(\ell \mid h)} \cdot (1 - \abph), \abph \mid h) =&\ ( 1- \abph)\cdot \Ex_{\sigi\sim \vpr_{h}}[\ps(\sigi, \vpr_{h}) - \ps(\sigi, \vpr_{\ell})]\\
%    \ge &\ ( 1- \abph)\cdot\frac{\Ex_{\sigi \sim \vpr_h}[\ps(\sigi, \vpr_h) - \pr(\sigi, \vpr_\ell)]\cdot (\dpsh + \dpsl)}{4 (\dpsh + \dpsl + \ps(\ell, \vpr_{\ell}) - \ps(h, \vpr_\ell))}.
% \end{align*}
% Therefore, for any $0\le \abpl \le \frac{\pr(h\mid h)}{\pr(\ell \mid h)} \cdot (1 - \abph)$, 

% \begin{align*}
%     \dut(\abpl, \abph \mid h) = &\ \left (1 -\frac{\abpl \cdot \pr(\ell\mid h)}{\pr(h\mid h)\cdot ( 1- \abph)}\right)\cdot \dut(0, \abph \mid h) +  \frac{\abpl \cdot \pr(\ell\mid h)}{\pr(h\mid h)\cdot ( 1- \abph)} \cdot \dut(\frac{\pr(h\mid h)}{\pr(\ell \mid h)} \cdot (1 - \abph), \abph \mid h)\\
%     \ge &\ \left( \abph + \abpl\cdot \frac{\pr(\ell \mid h)\cdot (1 - 2\abph)}{\pr(h\mid h)\cdot (1 - \abph)}\right)\cdot\frac{\Ex_{\sigi \sim \vpr_h}[\ps(\sigi, \vpr_h) - \pr(\sigi, \vpr_\ell)]\cdot (\dpsh + \dpsl)}{4 (\dpsh + \dpsl + \ps(\ell, \vpr_{\ell}) - \ps(h, \vpr_\ell))}\\
%     \ge &\ (\abph + \frac{\pr(\ell \mid h)}{\pr(h\mid h)} \cdot \abpl \cdot (1 - 2\abph)) \cdot\frac{\Ex_{\sigi \sim \vpr_h}[\ps(\sigi, \vpr_h) - \pr(\sigi, \vpr_\ell)]\cdot (\dpsh + \dpsl)}{4 (\dpsh + \dpsl + \ps(\ell, \vpr_{\ell}) - \ps(h, \vpr_\ell))}.
% \end{align*}

% Therefore, for 
% $$\abpl \ge \frac{\pr(h\mid h)}{\pr(\ell \mid h)\cdot (1 - 2\abph)} \cdot (\bphth - \abph),$$ $\dut(\abpl, \abph\mid h) \ge \frac{\maxdps}{\ag - 1}$. Given that $\bphth < \frac12$, the RHS is maximized at $\abph = 0.$ 
% Therefore, for any $0\le \abph \le \bphth$ and any $\abpl \ge \frac{\pr(h\mid h)}{\pr(\ell \mid h)}\cdot \bphth$, $\dut(\abpl, \abph\mid h) \ge \frac{\maxdps}{\ag - 1}$. 

% So far we have proved Lemma~\ref{lem:corner}. Finally, for the area close to $(0,0)$ or $(0, 1)$, i.e. (1) $\abph \ge 1 - \bphth$, and (2) $\abph \le \bphth$ and $\abpl \le \frac{\pr(h \mid h)}{\pr(\ell \mid h)} \cdot \bphth$, we show that we can always find a deviator $i$ such that $\ut(\bpl^i, \bph^i \mid h) \le \ut(\stgp^* \mid h)$. 
% Let 
% \begin{align*}
%   \nbph = &\ \frac{1}{\kd - 1} \sum_{j\in D, j\neq i} \bph^j  = \abph + \frac{1}{\kd - 1} (\abph - \bph^i)\\
%   \nbpl = &\ \frac{1}{\kd - 1} \sum_{j\in D, j\neq i} \bpl^j  = \abpl + \frac{1}{\kd - 1} (\abpl - \bpl^i)
% \end{align*} 
% be the average strategy of all the deviators other than $i$. It is satisfied that $(\nbpl, \nbph) \in [0, 1]^2$.

% We pick a deviator $i$ and characterize the $\kd$ such that $\ut(\bpl^i, \bph^i \mid h) \ge \ut(\stgp^* \mid h)$. More precisely, 
% $$\kd \ge \frac{\ut(\stgp^* \mid h) - \ut(\bpl^i, \bph^i \mid h, \jtruthful)}{(\ut(\stgp^* \mid h) - \ut(\bpl^i, \bph^i \mid h, \jtruthful)) - (\ut(\stgp^* \mid h) - \ut(\bpl^i, \bph^i \mid h, \jdeviate))}\cdot (n - 1) + 1$$ when the denominator $(\ut(\stgp^* \mid h) - \ut(\bpl^i, \bph^i \mid h, \jtruthful)) - (\ut(\stgp^* \mid h) - \ut(\bpl^i, \bph^i \mid h, \jdeviate)) \ge 0$ or $\kd$ does not exists when the denominator equals to or is less than $0$. 
% We will show that this $\kd > \kdq$ in both corner cases. 

% The numerator of RHS is  
% \begin{align*}
%     \ut(\stgp^* \mid h) - \ut(\bpl^i, \bph^i \mid h, \jtruthful) = (1 - \bph^i)\cdot \Ex_{\sigi\sim \vpr_{h}}[\ps(\sigi, \vpr_{h}) - \ps(\sigi, \vpr_{\ell})]. 
% \end{align*}

% The denominator is 
% \begin{align*}
%     &\ \ut(\bpl^i, \bph^i \mid h, \jdeviate) - \ut(\bpl^i, \bph^i \mid h, \jtruthful)\\
%     =&\ \bph^i \cdot ( (\pr(h\mid h)\cdot (\nbph  - 1) + \pr(\ell \mid h) \cdot \nbpl)\cdot \ps(h, \vpr_h)\\
%     &\ + (\pr(h\mid h)\cdot (1 - \nbph) - \pr(\ell \mid h) \cdot \nbpl)\cdot \ps(\ell, \vpr_h))\\
%     =&\ ( 1 - \bph^i ) \cdot ( (\pr(h\mid h)\cdot (\nbph  - 1) + \pr(\ell \mid h) \cdot \nbpl)\cdot \ps(h, \vpr_\ell)\\
%     &\ + (\pr(h\mid h)\cdot (1 - \nbph) - \pr(\ell \mid h) \cdot \nbpl)\cdot \ps(\ell, \vpr_\ell))\\
%     =&\ (\pr(h\mid h)\cdot (1 - \nbph) - \pr(\ell \mid h) \cdot \nbpl)\\
%     &\ \cdot (\bph^i  \cdot (\ps(\ell, \vpr_h) - \ps(h, \vpr_h)) + ( 1- \bph^i) \cdot (\ps(\ell, \vpr_\ell) - \ps(h, \vpr_\ell))). 
% \end{align*} 

% We first consider $\abph \le \bphth$ and $\abpl \le \frac{\pr(h \mid h)}{\pr(\ell \mid h)} \cdot \bphth$. In this case, we pick a deviator $i$ such that $\bph^i \le \abph$. 

% Firstly, there must be $(\pr(h\mid h)\cdot (1 - \nbph) - \pr(\ell \mid h) \cdot \nbpl) > 0$ for all sufficiently large $\ag$. This is because $\abph \le \bphth = \Theta(\frac{\maxdps}{\ag - 1})$ and $\abpl \le \frac{\pr(h\mid h)}{\pr(\ell \mid h)}\cdot \bphth$. Moreover, $\nbph \le 2 \abph$ and $\nbpl \le 2\abpl$ by the property of the average. Therefore, for sufficiently large $\ag$ such that $\bphth < \frac14$, $(\pr(h\mid h)\cdot (1 - \nbph) - \pr(\ell \mid h) \cdot \nbpl) > 0$. 

% If $\ps(\ell, \vpr_\ell) - \ps(h, \vpr_\ell) \le 0$, there must be $(\ps(\ell, \vpr_h) - \ps(h, \vpr_h)) < 0$. In this case $\ut(\bpl^i, \bph^i \mid h, \jdeviate) - \ut(\bpl^i, \bph^i \mid h, \jtruthful) < 0$, and for any $\kd \ge 2$, $i$'s reward will be strictly lower than the truthful reward. 

% Suppose $\ps(\ell, \vpr_\ell) - \ps(h, \vpr_\ell) > 0$. In this case, the condition 
% \begin{align*}
%     \kd \ge \frac{(1 - \bph^i)\cdot \Ex_{\sigi\sim \vpr_{h}}[\ps(\sigi, \vpr_{h}) - \ps(\sigi, \vpr_{\ell})]}{(\pr(h\mid h)\cdot (1 - \nbph) - \pr(\ell \mid h) \cdot \nbpl)\cdot (\bph^i  \cdot (\ps(\ell, \vpr_h) - \ps(h, \vpr_h)) + ( 1- \bph^i) \cdot (\ps(\ell, \vpr_\ell) - \ps(h, \vpr_\ell)))}\cdot (n - 1) + 1.
% \end{align*}

% We show this $\kd > \kdq$. 
% Recall that 
% $$\kdq \le \frac{\Ex_{\sigi\sim \vpr_{h}}[\ps(\sigi, \vpr_{h}) - \ps(\sigi, \vpr_{\ell})]}{\pr(h\mid h)\cdot (\ps(\ell, \vpr_\ell) - \ps(h, \vpr_\ell))}\cdot (n - 1) + 1$$

% Therefore, it is sufficient to show that 

% \begin{align*}
%     \frac{(1 - \bph^i)\cdot \pr(h\mid h)\cdot (\ps(\ell, \vpr_\ell) - \ps(h, \vpr_\ell))}{(\pr(h\mid h)\cdot (1 - \nbph) - \pr(\ell \mid h) \cdot \nbpl)\cdot (\bph^i  \cdot (\ps(\ell, \vpr_h) - \ps(h, \vpr_h)) + ( 1- \bph^i) \cdot (\ps(\ell, \vpr_\ell) - \ps(h, \vpr_\ell)))} > 1.
% \end{align*}

% Firstly, given that $\bph^i \le \abph$, there is $\bph^i \le \nbph$. Therefore, 
% \begin{align*}
%     (\pr(h\mid h)\cdot (1 - \nbph) - \pr(\ell \mid h) \cdot \nbpl) \le &\ \pr(h\mid h)\cdot (1 - \nbph) \\
%     \le &\ (1 - \bph^i)\cdot \pr(h\mid h). 
% \end{align*}

% Secondly, by Lemma~\ref{lem:pr_psr} we have $\ps(\ell, \vpr_h) - \ps(h, \vpr_h) < \ps(\ell, \vpr_\ell) - \ps(h, \vpr_\ell)$. Therefore, $\ps(\ell, \vpr_h) - \ps(h, \vpr_h)) + ( 1- \bph^i) \cdot (\ps(\ell, \vpr_\ell) - \ps(h, \vpr_\ell)) \le \ps(\ell, \vpr_\ell) - \ps(h, \vpr_\ell)$. 

% By combining two parts, we show that the threshold for $i$'s reward exceeds the truthful reward $\kd > \kdq$. Therefore, for all $\kd < \kdq$, $i$'s reward is strictly lower than the truthful reward. 

% We then consider $\abph \ge 1 - \bphth$.
% When $\ps(h, \vpr_h) \le \ps(\ell, \vpr_h)$, we we pick an $i$ such that $\bph^i \le \abph$ and compare $i$'s reward with the truthful reward. In this case, $ 0\le \ps(\ell, \vpr_h) - \ps(h, \vpr_h) < \ps(\ell, \vpr_\ell) - \ps(h, \vpr_\ell)$. If $\pr(h\mid h)\cdot (1 - \nbph) - \pr(\ell \mid h) \cdot \nbpl \le 0$, the denominator is non-positive, and for any $\kd \ge 2$, $i$'s reward cannot exceed the truthful reward. If $\pr(h\mid h)\cdot (1 - \nbph) - \pr(\ell \mid h) \cdot \nbpl > 0$, the denominator is positive. Following similar reasoning for $(\abpl, \abph)$ close to $(0, 0)$ shows that the threshold $\kd > \kdq$. 

% % If there exists a deviator $i$ such that 
% % $\bph^i \le \abph$ and $(\pr(h\mid h)\cdot (1 - \nbph) > \pr(\ell \mid h) \cdot \nbpl$, we pick this $i$, and the proof follows the close to $(0, 0)$ case.

% Otherwise, when $\ps(h, \vpr_h) > \ps(\ell, \vpr_h)$, we compare $i$'s reward with the reward of average strategy $(\abpl, \abph)$. Recall that 
% \begin{align*}
%     \ut(\bpl^i, \bph^i \mid h) - \ut(\abpl, \abph \mid h) 
%     =&\ \frac{\ag-\kd}{\ag - 1} \cdot \func^h(\bph^i - \abph, (0, 1)) + \frac{\kd - 1}{\ag - 1} f(\bph^i - \abph, (\abpl, \abph))\\
%     &\ +\frac{1}{\ag-1} (f(\bph^i, (\abpl, \abph)) - f(\bph^i, (\bpl^i, \bph^i)))\\
%     =&\ (\bph^i - \abph)\cdot (\Ex_{\sigi\sim \vpr_{h}}[\ps(\sigi, \vpr_{h}) - \ps(\sigi, \vpr_{\ell})] \\
%     &\ -\frac{\kd - 1}{\ag - 1} \cdot (\pr(h \mid h)\cdot ( 1- \abph) - \pr(\ell \mid h) \cdot \abpl) \cdot (\dpsh + \dpsl))\\
%     &\ + \frac{1}{\ag - 1} \cdot (\pr(h \mid h) \cdot (\abph - \bph^i) + \pr(\ell \mid h) \cdot (\abpl - \bpl^i))\\
%     &\ \cdot (\bph^i \cdot (\ps(h, \vpr_h) - \ps(\ell, \vpr_h)) + ( 1- \bph^i) \cdot (\ps(h, \vpr_\ell) - \ps(\ell, \vpr_\ell))). 
% \end{align*}

% We will assume that $\ag$ is sufficiently large so that $((1 - \bphth) \cdot (\ps(h, \vpr_h) - \ps(\ell, \vpr_h)) + \bphth \cdot (\ps(h, \vpr_\ell) - \ps(\ell, \vpr_\ell)) \ge 0$. (Recall that $\bphth = \Theta(\frac{1}{\ag - 1})$). 

% Note that for the second line, $(\pr(h \mid h)\cdot ( 1- \abph) - \pr(\ell \mid h) \cdot \abpl) \cdot (\dpsh + \dpsl)\le  \pr(h \mid h)\cdot \bphth \cdot (\dpsh + \dpsl).$ Therefore, for sufficiently large $\ag$, 
% \begin{align*}
%     &\ (\bph^i - \abph)\cdot (\Ex_{\sigi\sim \vpr_{h}}[\ps(\sigi, \vpr_{h}) - \ps(\sigi, \vpr_{\ell})] -\frac{\kd - 1}{\ag - 1} \cdot (\pr(h \mid h)\cdot ( 1- \abph) - \pr(\ell \mid h) \cdot \abpl) \cdot (\dpsh + \dpsl)) \ge 0. 
% \end{align*}


% Let 
% \begin{align*}
%     \munc_1 = &\ (\Ex_{\sigi\sim \vpr_{h}}[\ps(\sigi, \vpr_{h}) - \ps(\sigi, \vpr_{\ell})] \\
%     &\ -\frac{\kd - 1}{\ag - 1} \cdot (\pr(h \mid h)\cdot ( 1- \abph) - \pr(\ell \mid h) \cdot \abpl) \cdot (\dpsh + \dpsl))\\
%     \munc_2(\bph^i) = &\ (\bph^i \cdot (\ps(h, \vpr_h) - \ps(\ell, \vpr_h)) + ( 1- \bph^i) \cdot (\ps(h, \vpr_\ell) - \ps(\ell, \vpr_\ell))). 
% \end{align*}

% Then
% \begin{align*}
%     \ut(\bpl^i, \bph^i \mid h) - \ut(\abpl, \abph \mid h) =&\ (\bph^i - \abph)\cdot \munc_1 + \frac{1}{\ag - 1} \cdot (\pr(h \mid h) \cdot (\abph - \bph^i) + \pr(\ell \mid h) \cdot (\abpl - \bpl^i)) \cdot \munc_2(\bph^i)\\
%     =&\ (\bph^i - \abph)\cdot(\munc_1 - \frac{1}{\ag - 1} \cdot \pr(h \mid h)\cdot \munc_2(\bph^i)) + \frac{1}{\ag - 1} \cdot \pr(\ell \mid h) \cdot (\abpl - \bpl^i) \cdot \munc_2(\bph^i).
% \end{align*}

% Note that $\munc_1 > 0$ and $\frac{\partial\munc_2}{\partial \bph^i} = \dpsh + \dpsl > 0$. 

% If there exists a deviator $i$ such that $\bph^i \le \abph$ and $\ut(\bpl^i, \bph^i \mid h) - \ut(\abpl, \abph \mid h) < 0$, we just pick this $i$. Otherwise, if all deviators $j$ with $\bph^j \le \abph$ has $\ut(\bpl^i, \bph^i \mid h) - \ut(\abpl, \abph \mid h) \ge 0$, then the range of $j$'s strategy $(\bpl^j, \bph^j)$ satisfies
% \begin{equation*}
%     (\bph^j - \abph)\cdot(\munc_1 - \frac{1}{\ag - 1} \cdot \pr(h \mid h)\cdot \munc_2(\bph^j)) + \frac{1}{\ag - 1} \cdot \pr(\ell \mid h) \cdot (\abpl - \bpl^j) \cdot \munc_2(\bph^j) \ge 0
% \end{equation*}

% This directly implies that $\bpl^j < \abpl$ for any $j$ with $\bph^j \le \abph$. 

% Now we pick another deviator $i$ such that (1) $\bph^i \ge \abph$ and (2) for some deviator $j$ with $\bph^j < \abph$, $(\bph^i - \abph)(\abpl - \bpl^j) \le (\bpl^i - \abpl)(\abph - \bph^j).$ If such $i$ does not exist, then for any $i$ with $\bph^i > \abph$ and any $j$ with $\bph^j \le \abph$, there is $(\bph^i - \abph)(\abpl - \bpl^j) > (\bpl^i - \abpl)(\abph - \bph^j).$ Then, 
% \begin{align*}
%     0 = &\ \sum_{i\in D, \bph^i > \abph} (\bph^i - \abph) + \sum_{j\in D, \bph^i \le \abph} (\bph^j - \abph)\\
%     > &\ \sum_{i\in D, \bph^i > \abph} \frac{\bpl^i - \abpl}{\sum_{j\in D, \bph^i \le \abph} (\bpl^j - \abpl)}\cdot\sum_{j\in D, \bph^i \le \abph} (\bph^j - \abph) + \sum_{j\in D, \bph^i \le \abph} (\bph^j - \abph)\\
%     = &\ \frac{\sum_{j\in D, \bph^i \le \abph} (\bph^j - \abph)}{\sum_{j\in D, \bph^i \le \abph} (\bpl^j - \abpl)} \cdot \left(\sum_{i\in D, \bph^i > \abph}(\bpl^i - \abpl) +  \sum_{j\in D, \bph^i \le \abph} (\bpl^j - \abpl) \right)\\
%     =&\ 0,
% \end{align*}
% which is a contradiction. 
% Therefore, the deviator $i$ we pick always exists. 

% Now we compare $i$'s reward with the reward of the average strategy. Note that since $\bph^i > \abph \ge \bph^j$, $\munc_2(\bph^i) > \munc_2(\bph^j)$. 

% \begin{align*}
% &\ \ut(\bpl^i, \bph^i \mid h) - \ut(\abpl, \abph \mid h)\\
%     =&\ (\bph^i - \abph)\cdot(\munc_1 - \frac{1}{\ag - 1} \cdot \pr(h \mid h)\cdot \munc_2(\bph^i)) + \frac{1}{\ag - 1} \cdot \pr(\ell \mid h) \cdot (\abpl - \bpl^i) \cdot \munc_2(\bph^i)\\
%     < &\ (\bph^i - \abph)\cdot(\munc_1 - \frac{1}{\ag - 1} \cdot \pr(h \mid h)\cdot \munc_2(\bph^j)) + \frac{1}{\ag - 1} \cdot \pr(\ell \mid h) \cdot (\abpl - \bpl^i) \cdot \munc_2(\bph^j)\\
%     \le &\ \frac{\bpl^i - \abpl}{\abpl - \bpl^j}\cdot (\abph - \bph^j) \cdot (\munc_1 - \frac{1}{\ag - 1} \cdot \pr(h \mid h)\cdot \munc_2(\bph^j)) + \frac{1}{\ag - 1} \cdot \pr(\ell \mid h) \cdot (\abpl - \bpl^i) \cdot \munc_2(\bph^j)\\
%     =&\ - \frac{\bpl^i - \abpl}{\abpl - \bpl^j}\cdot \left(  (\bph^j - \abph)\cdot(\munc_1 - \frac{1}{\ag - 1} \cdot \pr(h \mid h)\cdot \munc_2(\bph^j)) + \frac{1}{\ag - 1} \cdot \pr(\ell \mid h) \cdot (\abpl - \bpl^j) \cdot \munc_2(\bph^j)\right)\\
%     \le &\ 0. 
% \end{align*}

% Therefore, we find an $i$ such that $\ut(\bpl^i, \bph^i \mid h) < \ut(\abpl, \abph \mid h) \le \ut(\stgp^* \mid h)$.

% Consequently, for any $\ag$ satisfying:
% \begin{enumerate}
%     \item $\bphth = \frac{4\maxdps\cdot (\dpsh + \dpsl + \ps(\ell, \vpr_{\ell}) - \ps(h, \vpr_\ell))}{ (\ag - 1)\cdot (\dpsh +\dpsl)\cdot  \Ex_{\sigi \sim \vpr_h}[\ps(\sigi, \vpr_h) - \pr(\sigi, \vpr_\ell)]} < \frac14$, 
%     \item If $\ps(h, \vpr_h) > \ps(\ell, \vpr_h)$, then $\bphth \le \frac{\ps(h, \vpr_h) - \ps(\ell, \vpr_h)}{\dpsh + \dpsl}$, 
%     \item $\bphth \le \frac{\Ex_{\sigi \sim \vpr_h}[\ps(\sigi, \vpr_h) - \pr(\sigi, \vpr_\ell)]}{\pr(h\mid h)\cdot (\dpsh + \dpsl)}$,
% \end{enumerate}
% for any deviation with no more than $\kdq$ deviators and the average strategy in the area of Lemma~\ref{lem:subspace_h}, there exists a deviator $i$ with private signal $h$ whose reward is strictly worse than the truthful reward. Therefore, such deviation cannot succeed. 

% Similarly, for the $\ell$ side, for any $\ag$ such that
% \begin{enumerate}
%     \item $\bphtl = \frac{4\maxdps\cdot (\dpsh + \dpsl + \ps(h, \vpr_{h}) - \ps(\ell, \vpr_h))}{ (\ag - 1)\cdot (\dpsh +\dpsl)\cdot  \Ex_{\sigi \sim \vpr_\ell}[\ps(\sigi, \vpr_\ell) - \pr(\sigi, \vpr_h)]} < \frac14$, 
%     \item If $\ps(\ell, \vpr_{\ell}) > \ps(h, \vpr_\ell)$, then $\bphth \le \frac{\ps(\ell, \vpr_{\ell}) - \ps(h, \vpr_\ell)}{\dpsh + \dpsl}$, 
%     \item $\bphth \le \frac{\Ex_{\sigi \sim \vpr_\ell}[\ps(\sigi, \vpr_\ell) - \pr(\sigi, \vpr_h)]}{\pr(\ell \mid \ell)\cdot (\dpsh + \dpsl)}$,
% \end{enumerate}
% for any deviation with no more than $\kdq$ deviators and the average strategy in the area of Lemma~\ref{lem:subspace_l}, there exists a deviator $i$ with private signal $\ell$ whose reward is strictly worse than the truthful reward. Therefore, such deviation cannot succeed. 

% Therefore, truthful reporting is an $\kdq$-strong \qi{} BNE. 

% % Then we consider the third type of deviation where all the deviators always tell lies, i.e. $\stg = (1, 0)$. Let $\stgp$ be this deviating strategy profile, and we consider the condition to make this deviation succeed. Still, we calculate the expected utility first. When the peer $j$ is a truthful agent,

% % \begin{align*}
% %     \ut_i(\stgp\mid h, \jtruthful) = &\ \pr(h \mid h) \cdot \ps(h, \vpr_\ell) + \pr(\ell \mid h) \cdot \ps(\ell, \vpr_\ell)\\
% %      \ut_i(\stgp\mid \ell, \jtruthful) =&\ \pr(h \mid \ell) \cdot \ps(h, \vpr_h) + \pr(\ell \mid \ell) \cdot \ps(\ell, \vpr_h). 
% % \end{align*}

% % And when $j$ is also a deviator, 
% % \begin{align*}
% %     \ut_i(\stgp\mid h, \jdeviate) = &\ \pr(h \mid h) \cdot \ps(\ell, \vpr_\ell) + \pr(\ell \mid h) \cdot \ps(h, \vpr_\ell)\\
% %      \ut_i(\stgp\mid \ell, \jdeviate) =&\ \pr(h \mid \ell) \cdot \ps(\ell, \vpr_h) + \pr(\ell \mid \ell) \cdot \ps(h, \vpr_h). 
% % \end{align*}

% % Let $\dut_{t|\sigi_i}$ and $\dut_{d|\sigi_i}$ be defined similarly. Then we have 

% % \begin{align*}
% %     \dut_{t\mid h} =&\ \Ex_{\sigi\sim \vpr_{h}}[\ps(\sigi, \vpr_{h}) - \ps(\sigi, \vpr_{\ell})].\\
% %     \dut_{t\mid \ell} =&\ \Ex_{\sigi\sim \vpr_{\ell}}[\ps(\sigi, \vpr_{\ell}) - \ps(\sigi, \vpr_{h})].
% % \end{align*}

% % And
% % \begin{align*}
% %     \dut_{t\mid h} - \dut_{d\mid h} =&\ (\pr(h\mid h) - \pr(\ell \mid h))\cdot(\ps(\ell, \vpr_{\ell}) - \ps(h, \vpr_{\ell})).\\
% %     \dut_{t\mid \ell} - \dut_{d\mid \ell} =&\ (\pr(\ell\mid \ell) - \pr(h \mid \ell))\cdot(\ps(h, \vpr_{h}) - \ps(\ell, \vpr_{h})).
% % \end{align*}

% % Then we will show that for all $\kd \le \kdq$, such deviation will not succeed. 

% % When $\ps(h, \vpr_{h}) > \ps(\ell, \vpr_{h})$, we consider the expected utility of a deviator $i$ with private signal $\ell$. If $\dut_{t\mid \ell} - \dut_{d\mid \ell} \le 0$, then $i$ cannot benefit from deviating to $\stgp$ for any $k\le n$. If $\dut_{t\mid \ell} - \dut_{d\mid \ell} > 0$, the condition for $i$ to benefit from deviating is 
% % \begin{align*}
% %     \kd \ge &\ \frac{\Ex_{\sigi\sim \vpr_{\ell}}[\ps(\sigi, \vpr_{\ell}) - \ps(\sigi, \vpr_{h})]}{(\pr(\ell \mid \ell) - \pr(h \mid \ell))\cdot (\ps(h, \vpr_h) - \ps(\ell, \vpr_h))} \cdot (n-1) + 1 \\
% %     >&\ \left\lceil\frac{\Ex_{\sigi\sim \vpr_{\ell}}[\ps(\sigi, \vpr_{\ell}) - \ps(\sigi, \vpr_{h})]}{\pr(\ell \mid \ell)\cdot (\ps(h, \vpr_h) - \ps(\ell, \vpr_h))} \cdot (n-1)\right\rceil\\
% %     = &\ \kdq^h\\
% %     \ge &\  \kdq
% % \end{align*}
% % Therefore, when $k\le k_Q$, $i$ cannot benefit from $\stgp$. 

% % When $\ps(h, \vpr_{h}) \le \ps(\ell, \vpr_{h})$, by Lemma~\ref{lem:pr_psr} we know that the other side $\ps(\ell, \vpr_{\ell}) > \ps(h, \vpr_{\ell})$ must hold. Therefore, by similar reasoning, a deviator with private signal $h$ will not benefit from deviation for all $k\le k_Q$. 

% % \noindent\textbf{Step 2: Equlibrium holds for $\kd \le \kdq.$}

% % We fix an arbitrary $\kd$. We define the strategy of deviators as in the proof of Theorem~\ref{thm:pp_exante}. Let $\stgp$ be the deviating strategy and $\stg_i = (\bpl^i, \bph^i)$ be the strategy agent $i$ plays in $\stgp$. Let $\astg = (\abpl, \abph) = \frac{1}{\kd} \sum_{i \in D} \stg_i$ be the average strategy on all deviators. 

% % For truthful reporting, agents with the same signal have the same expected utility. Therefore, $\aut(\stgp^*\mid h) = \ut_i(\stgp^*\mid h)$, and $\aut(\stgp^*\mid \ell) = \ut_i(\stgp^*\mid \ell)$. 

% % The expected utility of deviator $i$ with private signal $h$ conditioned on his/her peer $j$ is a truthful agent is 
% % \begin{align*}
% %     \ut_i(\stgp \mid h, \jtruthful) =&\  \frac{1}{n-\kd}\sum_{j \in [n]\setminus D} \Ex_{\rp_i \sim \stg_i(h)} \Ex_{\sigi_j \sim \vpr_{h}} \ps(\sigi_j, \vpr_{\rp_i})\\
% %     =&\ \Ex_{\rp_i \sim \stg_i(h)} \Ex_{\sigi_j \sim \vpr_{h}} \ps(\sigi_j, \vpr_{\rp_i})
% % \end{align*}
% % The average on this expected utility when an agent has private signal $h$ and a truthful peer $j$ is
% % \begin{align*}
% %     \aut(\stgp\mid h, \jtruthful) =&\ \frac{1}{\kd} \sum_{i \in D}  \ut_i(\stgp\mid h, \jtruthful)\\
% %     =&\ \Ex_{\rp \sim \astg(h)} \Ex_{\sigi_j \sim \vpr_{h}} \ps(\sigi_j, \vpr_{\rp}). 
% % \end{align*}

% % Therefore, the difference between $\aut(\stgp\mid h, \jtruthful)$ and $\aut(\stgp^*\mid h)$ is a linear function of $\abph$. 
% % \begin{align*}
% %     \dut_t^h(\abph) =&\ \aut(\stgp^*\mid h) - \aut(\stgp \mid h, \jtruthful)\\
% %     =&\ (1 - \abph) \cdot (\pr(h\mid h) \cdot (\ps(h, \vpr_h) - \ps(h, \vpr_{\ell}))  + \pr(\ell \mid h) \cdot (\ps(\ell, \vpr_h) - \ps(\ell, \vpr_\ell))). 
% % \end{align*}

% % Similarly, we can define that difference on $\ell$. 
% % \begin{align*}
% %     \dut_t^\ell(\abpl) =&\ \aut(\stgp^*\mid \ell) - \aut(\stgp \mid \ell, \jtruthful)\\
% %     =&\ \abpl \cdot (\pr(h\mid \ell) \cdot (\ps(h, \vpr_\ell) - \ps(h, \vpr_{h})) + \pr(\ell \mid \ell) \cdot (\ps(\ell, \vpr_\ell) - \ps(\ell, \vpr_h))).
% % \end{align*}

% % $ \dut_t^h(\abph)$ and $\dut_t^\ell(\abpl)$ are guaranteed to be positive by the properness of the scoring rule. 

% % For the deviator's side, we have
% % \begin{align*}
% %     \ut_i(\stgp \mid h, \jdeviate) =&\  \frac{1}{\kd-1}\sum_{j \in D\setminus\{i\}} \Ex_{\rp_i \sim \stg_i(h)} \Ex_{\sigi_j \sim \vpr_{h}, \rp_j \sim \stg_j(\sigi_j)} \ps(\rp_j, \vpr_{\rp_i}).
% % \end{align*}

% % And $\aut(\stgp\mid h, \jdeviate) = \frac{1}{\kd} \sum_{i\in D} \ut_i(\stgp\mid h, \jdeviate)$. The $\ell$ side is defined similarly. 
% % \begin{align*}
% %     \ut_i(\stgp \mid \ell, \jdeviate) =&\  \frac{1}{\kd-1}\sum_{j \in D\setminus\{i\}} \Ex_{\rp_i \sim \stg_i(\ell)} \Ex_{\sigi_j \sim \vpr_{\ell}, \rp_j \sim \stg_j(\sigi_j)} \ps(\rp_j, \vpr_{\rp_i}).\\
% %     \aut(\stgp\mid \ell, \jdeviate) =&\ \frac{1}{\kd} \sum_{i\in D} \ut_i(\stgp\mid \ell, \jdeviate)
% % \end{align*}

% % Similar to the proof of Theorem~\ref{thm:pp_exante}, we find upper bounds of $\aut(\stgp\mid h, \jdeviate)$ and $\aut(\stgp\mid \ell, \jdeviate)$ respectively parameterized by $\abph$ and $\abpl$. We do the $h$ side first. 

% % \begin{align*}
% %     \aut(\stgp\mid h, \jdeviate) = &\ \frac{\kd}{\kd - 1} \Ex_{\rp' \sim \astg(h)} \Ex_{\sigi \sim \vpr_{h}, \rp \sim \astg(\sigi)} \ps(\rp, \vpr_{\rp'})\\
% %     & - \frac{1}{(\kd - 1)k} \sum_{i \in D} \Ex_{\rp_i \sim \stg_i(h)} \Ex_{\sigi \sim \vpr_{h}, \rp \sim \stg_i(\sigi)} \ps(\rp, \vpr_{\rp_i}).
% % \end{align*}

% % Let $\func_h: [0, 1]^2 \to \mathbb{R}$. For a strategy $\stg = (\bpl, \bph)$, let
% % \begin{align*}
% %     \func_h(\bpl, \bph) =&\ \Ex_{\rp' \sim \stg(\sigi)} \Ex_{\sigi \sim \vpr_{h}, \rp \sim \stg(\sigi)} \ps(\rp, \vpr_{\rp'}). 
% % \end{align*}

% % Then we can represent $ \aut(\stgp\mid \jdeviate)$ in the form of $\func$. 
% % \begin{equation*}
% %      \aut(\stgp\mid h, \jdeviate) = \frac{\kd}{\kd-1} \func_h(\abpl, \abph) - \frac{1}{(\kd-1)\kd} \sum_{i\in D} \func_h(\bpl^i, \bph^i). 
% % \end{equation*}

% % % \begin{claim}
% % %     \label{claim:fh}
% % %     $\func_h(\bpl, \bph)$ is convex on $[0, 1]^2$.  
% % % \end{claim}

% % % \begin{proof}
% % %      Note that 
% % %     \begin{align*}
% % %         \frac{\partial^2 \func}{\partial\bpl^2} =&\ 0, \\
% % %         \frac{\partial^2 \func}{\partial\bph^2} =&\ 2\cdot \pr(h \mid h) \cdot (\ps(h, \vpr_h) + \ps(\ell, \vpr_{\ell}) - \ps(h, \vpr_{\ell}) - \ps(\ell, \vpr_h)),\\
% % %         \frac{\partial^2 \func}{\partial\bpl \partial\bph} =&\ \pr(\ell \mid h) \cdot (\ps(h, \vpr_h) + \ps(\ell, \vpr_{\ell}) - \ps(h, \vpr_{\ell}) - \ps(\ell, \vpr_h)),\\
% % %         \frac{\partial^2 \func}{\partial\bph \partial\bpl} =&\ \pr(\ell \mid h) \cdot (\ps(h, \vpr_h) + \ps(\ell, \vpr_{\ell}) - \ps(h, \vpr_{\ell}) - \ps(\ell, \vpr_h)).
% % %     \end{align*}
% % % \end{proof}
% % % Let \begin{equation*}
% % %     H = 
% % %         \begin{bmatrix}
% % %             0 & \pr(\ell) \cdot \pr(\ell \mid h) + \pr(h)\cdot \pr(\ell \mid h)\\
% % %             \pr(\ell) \cdot \pr(\ell \mid h) + \pr(h)\cdot \pr(\ell \mid h) & 2\pr(h) \cdot \pr(h \mid h) 
% % %         \end{bmatrix}. 
% % %     \end{equation*}
% \end{proof}