\section{Voting with antagonistic Voters}
\subsection{Setting}
$\ag$ agents vote for two candidates $\bA$ and $\bR$. The majority rule with threshold $\Thd$ is applied, so the candidates with more than $\Thd \cdot \ag$ votes becomes the winner. There is a world state (ground truth) $\Wosrv \in \{L, H\}$ that affects the preferences of the agents. The common prior on the world state is denoted by $P_H$ and $P_L$. The world state is not directly observable. Instead, each agents receives private signals $\sig \in \{\ell, h\}$ whose distribution depends on the world states. The signals of different agents are i.i.d conditioned on the world state. We use $P_{hH}$ to denote the probability that an agent receives $h$ signal when the world state is $H$. Other probabilities are defined similarly. We assume that $P_{hH} > P_{hL}$. Let $\infdif = P_{hH} - P_{hL} = P_{\ell L} - P_{\ell H} = P_{hH}\cdot P_{\ell L} - P_{hL}\cdot P_{\ell H}$. 

For each agent $i$, the utility function $\vt_i: \{H, L\}\times \{\bA, \bR\} \to \{0, 1, \cdots, B\}$ characterizes the preference of the agent. There are two types of agents, whose preferences depends on the world state. The majority type prefer $\bA$ in world state $H$ ($\vt(H,\bA) > \vt(H, \bR)$) and $\bR$ in world state $L$ ($\vt(L,\bA) < \vt(L, \bR)$), and the minority type prefer $\bR$ in world state $H$ ($\vt(H,\bA) < \vt(H, \bR)$) and $\bA$ in world state $L$ ($\vt(L,\bA) > \vt(L, \bR)$). Let $\alpha > 0.5$ be the fraction of the majority agents.
% Agents can be categorized into four types based on their preferences under different world states. There are two types of pre-determined agents. A friendly agent always prefers $\bA$, and an unfriendly agent always prefers $\bR$. There are two types of contingent agents. A majority contingent agent (abbreviated as a majority agent) prefers $\bA$ in world state $H$ and $\bR$ in world state $L$, and a minority contingent agent (abbreviated as a minority agent) prefers $\bR$ in world state $H$ and $\bA$ in world state $L$. The constraint on the utility for each type of agents is in Table~\ref{tbl:utility}.

% Let $\agf$, $\agu$, $\aga$, and $\agi$ be the (approximated) fraction of friendly, unfriendly, majority, and minority agents, respectively. For a setting of $\ag$ agents, $\lfloor \agf \cdot \ag\rfloor$ agents are friendly, $\lfloor \agu \cdot \ag\rfloor$ agents are unfriendly, $\lfloor \aga \cdot \ag \rfloor$ agents are majority type, and the rest agents are minority type. 

% \begin{table}[htbp]
% \begin{tabular}{@{}llllll@{}}
% \toprule
% \multicolumn{2}{l}{Type} & Fraction & \begin{tabular}[c]{@{}l@{}}Preference\\ in state $H$\end{tabular} & \begin{tabular}[c]{@{}l@{}}Preferences \\ in state $L$\end{tabular} & Utility constraint \\ \midrule
% % \multirow{2}{*}{Pre-determined} & Friendly & $\agf$ & $\bA$ & $\bA$ & \begin{tabular}[c]{@{}l@{}}$\vt(H,\bA) > \vt(H, \bR)$\\ $\vt(L,\bA) > \vt(L, \bR)$\end{tabular} \\ \cmidrule(l){2-6} 
% %  & Unfriendly & $\agu$ & $\bR$ & $\bR$ & \begin{tabular}[c]{@{}l@{}}$\vt(H,\bA) < \vt(H, \bR)$\\ $\vt(L,\bA) < \vt(L, \bR)$\end{tabular} \\ \midrule
% \multirow{2}{*}{Contingent} & Majority & $\aga$ & $\bA$ & $\bR$ & \begin{tabular}[c]{@{}l@{}}$\vt(H,\bA) > \vt(H, \bR)$\\ $\vt(L,\bA) < \vt(L, \bR)$\end{tabular} \\ \cmidrule(l){2-6} 
%  & Minority & $\agi$ & $\bR$ & $\bA$ & \begin{tabular}[c]{@{}l@{}}$\vt(H,\bA) < \vt(H, \bR)$\\ $\vt(L,\bA) > \vt(L, \bR)$\end{tabular} \\ \bottomrule
% \end{tabular}
% \caption{\label{tbl:utility} fraction, preference, and utility constraints on four types of agents.}
% \end{table}

A strategy $\stg$ of an agent $i$ maps their signal to a distribution on $\{\bA,\bR\}$, denoting their action. An agent vote informatively if they always vote for $\bA$ when receiving signal $h$ and always vote for $\bR$ when receiving signal $\ell$. A strategy profile $\stgp$ is a vector of the strategies of all the agents. For an agent $i$, let $\bpl^i$ and $\bph^i$ be the probability that $i$ votes for $\bA$ when his/her private signal is $\ell$ and $h$, respectively. 

The {\em informed majority decision} is the decision to be made if all the agent know the world state. In this setting, the informed majority decision follows the majority type agents' preference: the informed majority decision is $\bA$ in the world state $H$ and $\bR$ in the world state $L$.
% We assume that $\agf + \aga > \Thd$ and $\agu + \aga > 1 - \Thd$. This assumption implies that $\aga > \agi$, i.e., the``majority type'' agents are the majority in the contingent agents. In this case, the informed majority decision is $\bA$ in the world state $H$ and $\bR$ in the world state $L$. We believe such assumption is reasonable. If exactly one of the two inequalities hold, the informed majority decision will be the same alternative in both world states, and reaching such a decision is trivial. If both inequalities are violated, the minority type agents become the majority of the contingent agents, the informed majority decision is $\bA$ in the world state $H$ and $\bR$ in the world state $L$, which is symmetric to the scenario under the assumption. 

The {\em fidelity} of a strategy profile is the likelihood that the candidate preferred by the agents becomes the winner under this strategy profile. That is, $\bA$ becomes the winner when the world state is $H$, and $\ell$ become the winner when the world state is $\ell$. Let $\lp_{\Wosrv}^{\bA}(\stgp)$ and $\lp_{\Wosrv}^{\bR}(\stgp)$ be the probability that $\bA$ ($\bR$, respectively) becomes the winner when the world state is $W$ and the strategy profile is $\stgp$. Then the fidelity in the voting game is in the following form. 
\begin{equation*}
    \acc(\stgp) = P_H\cdot \lp_H^{\bA}(\stgp) + P_L\cdot \lp_L^{\bR}(\stgp). 
\end{equation*}

Similarly, we can define the (ex-ante) expected utility of an agent $i$ under a strategy profile $\stgp$: 
\begin{equation*}
    \ut_{i}(\stgp) =P_{L}(\lp_{L}^{\bA}(\stgp)\cdot\vt_{i}(L, \bA) + \lp_{L}^{\bR}(\stgp)\cdot \vt_{i}(L, \bR)) +  P_{H}(\lp_{H}^{\bA}(\stgp)\cdot\vt_{i}(H, \bA) + \lp_{H}^{\bR}(\stgp)\cdot \vt_{i}(H, \bR)). 
\end{equation*}

Similarly, for an agent $i$, let $\lp_{\Wosrv}^{\bA}(\stgp \mid \sigi)$ and $\lp_{\Wosrv}^{\bR}(\stgp\mid \sigi)$ be the probability that $\bA$ ($\bR$, respectively) becomes the winner when the world state is $W$, the strategy profile is $\stgp$, and agent $i$ receives signal $\sigi$. The formula does not contain $i$ because of the symmetricity of agents. Then we can define the interim expected utility of an agent $i$ with private signal $\sigi$ under strategy profile $\stgp$. 
\begin{equation*}
    \ut_{i}(\stgp) =\Pr[L\mid \sigi] \cdot (\lp_{L}^{\bA}(\stgp \mid \sigi)\cdot\vt_{i}(L, \bA) + \lp_{L}^{\bR}(\stgp\mid \sigi)\cdot \vt_{i}(L, \bR)) +  \Pr[H\mid \sigi](\lp_{H}^{\bA}(\stgp \mid \sigi)\cdot\vt_{i}(H, \bA) + \lp_{H}^{\bR}(\stgp \mid \sigi)\cdot \vt_{i}(H, \bR)). 
\end{equation*}

\paragraph{Sequence of Environments.} An \textinst{} $\instance$  contains the agent number $\ag$, the world state prior distribution $(P_L, P_H)$, the signal distributions $(P_{hH}, P_{lH})$ and $(P_{hL}, P_{lL})$, the utility functions $\{\vt_i\}_{i=1}^\ag$, and the approximated fraction of each type of agents $(\agf, \agu, \aga, \agi)$. Let $\{\instance_\ag\}_{\ag=1}^{\infty}$ (or $\{\instance_\ag\}$ for short) be a sequence of \textinst{}s, where each $\instance_\ag$ is an \textinst{} with $\ag$ agents.
The \textinst{}s in a sequence share the same prior distributions, signal distributions, and approximated fractions of each type. There are no additional assumptions on the utility functions. 

\subsubsection{Non-dominated strategies}

In the rest of this section, we will focus on strategy profiles where no agents play weakly dominated strategy. 

\begin{definition}
    A strategy $\stg_i$ is an (ex-ante) weakly dominated strategy for agent $i$ if there exists a strategy $\stg'_i$ such that, no matter what other agents play $\stgp_{-i}$, $\ut_i((\stg_i, \stgp_{-i})) \le \ut_i((\stg_i, \stgp_{-i}))$, and there exists a $\stgp_{-i}$ such that $\ut_i((\stg_i, \stgp_i)) < \ut_i((\stg_i, \stgp_{-i}))$. 
\end{definition}

We believe this restriction is mild and reasonable. Firstly, an agent playing a dominated strategy has incentives to deviate to a non-dominated strategy, which brings no utility loss at any circumstances and utility gain in some circumstances. Secondly, as shown in the following lemma, whether a strategy is (weakly) dominated can be easily determined, and playing non-dominated strategy does not bring extra computational cost and difficulties to the agents. 

\begin{lemma}
\label{lem:dominated}
    For an arbitrary agent $i$, a strategy $\stg = (\bpl, \bph)$ is NOT a weakly dominated strategy if and only if the following condition hold. 
    \begin{itemize}
        % \item If $i$ is a friendly agent: $\bpl = \bph = 1$. 
        % \item If $i$ is an unfriendly agent: $\bpl = \bph = 0$. 
        \item If $i$ is a majority agent: $\bpl = 0$ or $\bph = 1$. 
        \item If $i$ is a minority agent: $\bpl = 1$ or $\bph = 0$. 
    \end{itemize}
\end{lemma}

\begin{proof}
    Suppose the strategies other agents play is $\stgp_{-i}$. The only scenario where $i$'s vote can change the outcome is the pivotal case, where both alternatives need exactly one vote to pass their threshold. Therefore, different strategies $i$ plays only affect his/her expected utility conditioned on $i$ being pivotal. The ex-ante expected utility of $i$ with strategy profile $\stgp = (\stg, \stgp_{-i})$ conditioned on him/her being pivotal is as follows. Note that the posterior belief on the world state conditioned on $i$ being pivotal does not depend on $i$'s strategy. 
    \begin{align*}
        \ut_{i}(\stgp \mid \piv) =&\ \Pr[L\mid \piv, \stgp_{-i}] \cdot ((P_{hL}\cdot \bph + P_{\ell L}\cdot \bpl)\cdot\vt_{i}(L, \bA) + (P_{hL}\cdot (1-\bph) + P_{\ell L}\cdot (1-\bpl))\cdot \vt_{i}(L, \bR)) \\
        &\ +  \Pr[H\mid \piv, \stgp_{-i}]\cdot ((P_{hH}\cdot \bph + P_{\ell H}\cdot \bpl)\cdot\vt_{i}(H, \bA) + (P_{hH}\cdot (1-\bph) + P_{\ell H}\cdot (1-\bpl))\cdot \vt_{i}(H, \bR)). 
    \end{align*}

    When agent $i$ plays a different strategy $\stg' = (\bpl', \bph')$, the expected utility conditioned on pivotal can be written in the similar form. Let $\stgp' = (\stg', \stgp_{-i})$. Then, the difference between the expected utility when $i$ plays $\stg$ and $\stg'$ is exactly the expected utility difference conditioned on $i$ being pivotal.

    \begin{align*}
        \ut_i(\stgp') - \ut_i(\stgp) = &\ \ut_i(\stgp' \mid \piv) - \ut_i(\stgp \mid \piv) \\
        =&\ \Pr[L \mid \piv, \stgp_{-i}] \cdot ((P_{hL} \cdot (\bph' - \bph) + P_{\ell L} \cdot (\bpl' - \bpl))\cdot (\vt_i(L, \bA) - \vt_i(L, \bR))\\
        &\ + \Pr[H \mid \piv, \stgp_{-i}] \cdot ((P_{hH} \cdot (\bph' - \bph) + P_{\ell H} \cdot (\bpl' - \bpl))\cdot (\vt_i(H, \bA) - \vt_i(H, \bR)). 
    \end{align*}

% For friendly agents, $\vt_i(L, \bA) - \vt_i(L, \bR) > 0$ and $\vt_i(H, \bA) - \vt_i(H, \bR) > 0$. When $\bph < 1$ or $\bpl < 1$, let $\bph' = \bpl' = 1$. Then $\ut_i(\stgp') - \ut_i(\stgp) > 0$, and $\stg$ is weakly dominated by $\stg'$. On the other hand, when $\bpl = \bph = 1$, for any $\stg'$, $\ut_i(\stgp') - \ut_i(\stgp) \le 0$, and $\stg$ is not a weakly dominated strategy. The reasoning for unfriendly agents resembles that for friendly agents. 

For majority contingent agents, $\vt_i(L, \bA) - \vt_i(L, \bR) < 0$ and $\vt_i(H, \bA) - \vt_i(H, \bR) > 0$. When $\bph < 1$ and $\bpl > 0$, let $\bph' = \bph + \varepsilon$ and $\bpl' = \bpl - \varepsilon\cdot \frac{P_{hL} + P_{hH}}{P_{\ell L} + P_{\ell H}}$, where $\varepsilon > 0$ is a small constant that guarantees $\bph \le 1$ and $\bpl \ge 0$. Then we have $P_{hL} \cdot (\bph' - \bph) + P_{\ell L} \cdot (\bpl' - \bpl) < 0$ and $P_{hH} \cdot (\bph' - \bph) + P_{\ell H} \cdot (\bpl' - \bpl) > 0$, which implies that $\ut_i(\stgp') - \ut_i(\stgp) > 0$ and that $\stg$ is dominated by $\stg'$. Now, without loss of genearlity, suppose $\bph = 1$. In this case, for all $\stg' \neq \stg$, either $P_{hL} \cdot (\bph' - \bph) + P_{\ell L} \cdot (\bpl' - \bpl) > 0$ or $P_{hH} \cdot (\bph' - \bph) + P_{\ell H} \cdot (\bpl' - \bpl) < 0$ hold. (If $P_{hH} \cdot (\bph' - \bph) + P_{\ell H} \cdot (\bpl' - \bpl) < 0$ does not hold and $\stg' \neq \stg$, then $\bpl' > \bpl$ must hold. Combined with the fact that $P_{hH} > P_{hL}$ and $P_{\ell H} < P_{\ell L}$, $P_{hL} \cdot (\bph' - \bph) + P_{\ell L} \cdot (\bpl' - \bpl) > 0$ holds.) Therefore, by constructing $\stgp_{-i}$ so that $\Pr[L \mid \piv, \stgp_{-i}]$ is sufficiently close to 0 or 1, we can find a scenario where $\ut_i(\stgp') - \ut_i(\stgp) < 0$, which implies that $\stgp$ is not weakly dominated by $\stgp'$. 
The reasoning for $\bpl = 0$ and that for the minority contingent agents resembles the reasoning above. 
\end{proof}

% \subsection{Setting}
% $\ag$ agents vote for two candidates $\bA$ and $\bR$. The majority rule is applied, so the candidates with more than $\frac{n}{2}$ votes becomes the winner. There is a world state (ground truth) $\Wosrv \in \{L, H\}$ that affects the preferences of the agents. The common prior on the world state is denoted by $P_H$ and $P_L$. The world state is not directly observable. Instead, each agents receives private signals $\sig \in \{\ell, h\}$ whose distribution depends on the world states. The signals of different agents are i.i.d conditioned on the world state. We use $P_hH$ to denote the probability that an agent receives $h$ signal when the world state is $H$> Other probabilities are defined similarly. 

% For each agent $i$, the utility function $\vt_i: \{H, L\}\times \{\bA, \bR\} \to \{0, 1, \cdots, B\}$ characterizes the preference of the agent. There are two types of agents, whose preferences depends on the world state. The majority type prefer $\bA$ in world state $H$ and $\bR$ in world state $L$, and the minority type prefer $\bR$ in world state $H$ and $\bA$ in world state $L$. Let $\alpha > 0.5$ be the fraction of the majority agents. 

% A strategy $\stg$ of an agent $i$ maps their signal to a distribution on $\{\bA,\bR\}$, denoting their action. An agent vote informatively if they always vote for $\bA$ when receiving signal $h$ and always vote for $\bR$ when receiving signal $\ell$. A strategy profile $\stgp$ is a vector of the strategies of all the agents. For an agent $i$, let $\bpl^i$ and $\bph^i$ be the probability that $i$ votes for $\bA$ when his/her private signal is $\ell$ and $h$, respectively. 

% The {\em fidelity} of a strategy profile is the likelihood that the candidate preferred by the agents becomes the winner under this strategy profile. That is, $\bA$ becomes the winner when the world state is $H$, and $\ell$ become the winner when the world state is $\ell$. Let $\lp_{\Wosrv}^{\bA}(\stgp)$ and $\lp_{\Wosrv}^{\bR}(\stgp)$ be the probability that $\bA$ ($\bR$, respectively) becomes the winner when the world state is $W$ and the strategy profile is $\stgp$. Then the fidelity in the voting game is in the following form. 
% \begin{equation*}
%     \acc(\stgp) = P_H\cdot \lp_H^{\bA}(\stgp) + P_L\cdot \lp_L^{\bR}(\stgp). 
% \end{equation*}

% Similarly, we can define the (ex-ante) expected utility of an agent $i$ under a strategy profile $\stgp$: 
% \begin{equation*}
%     \ut_{i}(\stgp) =P_{L}(\lp_{L}^{\bA}(\stgp)\cdot\vt_{i}(L, \bA) + \lp_{L}^{\bR}(\stgp)\cdot \vt_{i}(L, \bR)) +  P_{H}(\lp_{H}^{\bA}(\stgp)\cdot\vt_{i}(H, \bA) + \lp_{H}^{\bR}(\stgp)\cdot \vt_{i}(H, \bR)). 
% \end{equation*}

% Similarly, for an agent $i$, let $\lp_{\Wosrv}^{\bA}(\stgp \mid \sigi)$ and $\lp_{\Wosrv}^{\bR}(\stgp\mid \sigi)$ be the probability that $\bA$ ($\bR$, respectively) becomes the winner when the world state is $W$, the strategy profile is $\stgp$, and agent $i$ receives signal $\sigi$. The formula does not contain $i$ because of the symmetricity of agents. Then we can define the interim expected utility of an agent $i$ with private signal $\sigi$ under strategy profile $\stgp$. 
% \begin{equation*}
%     \ut_{i}(\stgp) =\Pr[L\mid \sigi] \cdot (\lp_{L}^{\bA}(\stgp \mid \sigi)\cdot\vt_{i}(L, \bA) + \lp_{L}^{\bR}(\stgp\mid \sigi)\cdot \vt_{i}(L, \bR)) +  \Pr[H\mid \sigi](\lp_{H}^{\bA}(\stgp \mid \sigi)\cdot\vt_{i}(H, \bA) + \lp_{H}^{\bR}(\stgp \mid \sigi)\cdot \vt_{i}(H, \bR)). 
% \end{equation*}

Before going to the proof, we introduce the following notion theorem from~\citep{han2023wisdom}, which serves as a useful tool to characterizes fidelities of strategy profiles. 
Given a world state $\wos$, the \exshare{} is the expected vote share the informed majority decision alternative attracts under state $\wos$ minus the threshold of the alternative. 
\begin{definition}[\bf{Excess expected vote share}]
   Given an instance of $\ag$ agents, and a strategy profile $\stgp$, let random variable $\xrv_{i}^{\ag}$ be "agent $i$ votes for $\bA$":  $\xrv_{i}^{\ag} = 1$ if agent $i$ votes for $\bA$, and $\xrv_{i}^{\ag} = 0$ if $i$ votes for $\bR$. Then the \exshare{} is defined as follows: 
\begin{align}
    \thd^{\ag}_{H} =& \frac{1}{\ag}\sum_{i=1}^{\ag}E[\xrv_{i}^{\ag}\mid H] - 1/2.\label{eq:hthdh}
\end{align}
\begin{align}
    \thd^{\ag}_{L} =&  \frac{1}{\ag}\sum_{i=1}^{\ag}E[1-\xrv_{i}^{\ag}\mid L] - 1/2\label{eq:hthdl}. 
\end{align}
Specifically, $\thd_H^{\ag}$ is the \exshare\ of $\bA$ conditioned on world state $H$, and $\thd_L^{\ag}$ is the \exshare\ of $\bR$ conditioned on world state $L$. For technical convenience, we define $\thd^{\ag} = \min(\thd^{\ag}_H, \thd^{\ag}_L).$ 
\end{definition}

\begin{theorem}
\label{thm:arbitrary}
Given an arbitrary sequence of instances and arbitrary sequence of strategy profiles $\{\stgp_{\ag}\}_{\ag=1}^\infty$, let $\thd^\ag$ be the \exshare{} for each $\stgp_{\ag}$.
\begin{itemize}
     \item If $\liminf_{\ag\to\infty} \sqrt{\ag}\cdot \thd^{\ag} = +\infty$, the fidelity of $\stgp_{\ag}$ converges to 1 , i.e., $\lim_{\ag\to\infty} \acc(\stgp_{\ag}) = 1$. 
     \item If $\liminf_{\ag\to\infty} \sqrt{\ag}\cdot \thd^{\ag} < 0$ (including $-\infty$), $\acc(\stgp_{\ag})$ does NOT converge to 1. 
     \item If $\liminf_{\ag\to\infty} \sqrt{\ag}\cdot \thd^{\ag} \ge 0$ (not including $+\infty$), and the variance of $\sum_{i=1}^{\ag} \xrv_{i}^{\ag}$ is at least proportional to $\ag$,  $\acc(\stgp_{\ag})$ does NOT converge to 1. 
\end{itemize}
\end{theorem}

\subsection{Results}

While we know that when $\kd \le 0.5\cdot \ag$, all agents always vote for $\bA$ is both an ex-ante Bayesian $\kd$-strong equilibrium and Bayesian $\kd$-strong equilibrium, we show that, for $\kd > 0.5\cdot \ag$, all equilibrium (if exists) has fidelity converging to 1. 

\begin{prop}
\label{prop:k>0.5}
    Let $\kd = \xi \cdot \ag$ where $\xi > 0.5$. For any $\stgp$, if $\stgp$ is an $\varepsilon$-ex-ante Bayesian $\kd$-strong equilibrium where $\varepsilon \to 0$, then $\acc(\stgp) \to 1$. 
\end{prop}
% The proposition directly leads to the following corollary. 
% \begin{coro}
%     Let $\kd = \xi \cdot \ag$ where $\xi > 0.5$. For any $\stgp$, if $\stgp$ is an $\varepsilon$-ex-ante Bayesian $\kd$-strong equilibrium where $\varepsilon \to 0$, then $\acc(\stgp) \to 1$. 
% \end{coro}

\Qishen{I have a non-trivial method to show the same result for Bayesian $\kd$-strong equilibrium. Is there a easier way? For example, if $\lp_H^{\bA}(\stgp)$ does not converge to 1, $\lp_H(\stgp \mid h)$ and $\lp_H(\stgp \mid L)$ can be bounded away from 1 as well.}

\begin{proof}
    Let $\stgp$ be a strategy profile such that $\acc(\stgp)$ does not converges to 1. Without loss of generality, suppose $\lp_{H}^{\bA}(\stgp) < 1 - \delta$ for some $\delta > 0$. Then we show that a group of majority type agents have incentives to deviate. Let $\stgp'$ denote the deviating strategy profile.

    Let $D$ be the deviating group that contains $|D| = \min(\alpha\cdot \ag, \kd)$ majority type agents.
    Let $\astg = \sum_{i\not\in D} \stg_i = (\abpl, \abph)$ be the average of strategies of non-deviators. The expected votes for $\bA$ from all the non-deviators under world state $H$ is $(\ag - |D|)\cdot (P_{hH}\cdot \abph + P_{\ell H}\cdot \abpl)$, and the expected votes for $\bR$ from all the non-deviators under world state $L$ is $(\ag - |D|)\cdot (1 - P_{hL}\cdot \abph - P_{\ell L}\cdot \abpl)$.
    % \begin{align*}
    %     \thd_H =&\ (\ag - |D|)\cdot (P_{hH}\cdot \abph + P_{\ell H}\cdot \abpl).\\
    %     \thd_L = &\ (\ag - |D|)\cdot (1 - P_{hL}\cdot \abph - P_{\ell L}\cdot \abpl).
    % \end{align*}
    
    % It is guaranteed that $0\le \thd_H \le \ag - |D|$ and $0 \le \thd_H \le \ag - |D|$. 

    Now we consider the deviating strategy of $D$. Without loss of genearlity, suppose $P_{hH} + P_{hL} \le 1.$ Among $|D|$ deviators, $\ag - |D|$ deviators ``offset'' the votes from non-deviators by playing $\bpl = 1 - \abpl$ and $\bph = 1 - \abph$. The rest $2|D| - \ag$ deviators play the ``optimal'' strategy $\bph = 1$ and $\bpl = \frac12 \cdot (1 - \frac{P_{hL} + P_{hH}}{P_{\ell L} + P_{\ell H}})$ to distinguish the two world states. Then we calculate the \exshare{} for $\bA$ when the deviating strategy $\stgp'$ is played. When the world state is $H$, 
    \begin{align*}
        \thd_H' =&\ (1 - \frac{|D|}{\ag})\cdot (P_{hH}\cdot (\abph + 1 - \abph) + P_{\ell H}\cdot (\abpl + 1 - \abpl))\\
        &\ + (\frac{2|D|}{\ag} - 1) \cdot (P_{hH} + P_{\ell H}\cdot \frac12 \cdot (1 - \frac{P_{hL} + P_{hH}}{P_{\ell L} + P_{\ell H}})) - 1/2\\
        =&\ (1 - \frac{|D|}{\ag}) + (\frac{2|D|}{\ag} - 1)\cdot(P_{hH} + \frac12 P_{\ell H}\cdot (1 - \frac{P_{hL} + P_{hH}}{P_{\ell L} + P_{\ell H}})) - 1/2\\
        \ge&\ \frac{1}{2} + (\frac{2|D|}{\ag} - 1) \cdot (P_{hH} + \frac12 P_{\ell H}\cdot (1 - \frac{P_{hL} + P_{hH}}{P_{\ell L} + P_{\ell H}}) - \frac12) - 1/2\\
        =&\ \frac12(\frac{2|D|}{\ag} - 1) \cdot (P_{hH} - \frac{P_{hL} + P_{hH}}{P_{\ell L} + P_{\ell H}})\\
        =&\ \frac12(\frac{2|D|}{\ag} - 1)\cdot \frac{P_{hH} \cdot P_{\ell L} - P_{\ell H}\cdot P_{hL}}{P_{\ell L} + P_{\ell H}} \\
        >&\ 0.
    \end{align*}
    Similarly, we can show that $\thd_L' > 0$. Therefore, by applying the Hoeffding Inequality, $\lp_H^{\bA}(\stgp')\ge 1 - 2 \exp(-\Theta(\ag))$ and $\lp_L^{\bR}(\stgp') \ge 1 - 2\exp(-\Theta(\ag))$. 

    Therefore, a deviator's expected utility increases by a constant by deviating from $\stgp$ to $\stgp$'.
    \begin{align*}
        \ut_{i}(\stgp') - \ut_{i}(\stgp) =&\ P_H(\lp_{H}^{\bA}(\stgp') - \lp_{H}^{\bA}(\stgp))(\vt_{i}(H, \bA) - \vt_{i}(H, \bR)) + P_L (\lp_{L}^{\bR}(\stgp') - \lp_{L}^{\bR}(\stgp))(\vt_{i}(L, \bR) - \vt_{i}(L, \bA)) \\
        \ge &\ P_{H}\cdot \delta\cdot 1 - P_{L}\cdot\exp(-\Theta(n)) \cdot B\\
        > &\  \frac12 P_H\cdot \delta.
    \end{align*}

    Therefore, $\stgp$ is NOT a $\varepsilon$-ex-ante Bayesian $\kd$-strong equilibrium where $\varepsilon = \frac12 P_{H}\cdot \delta$. 
\end{proof}

\Qishen{Refer to previous work here.}
Let the threshold of the majority type be $\thdmaj = \frac{1}{2M}$, where 
\begin{equation*}
    M = 
    \begin{cases}
        \frac{P_{\ell L}}{P_{\ell L} + P_{\ell H}}, &\ if P_{hH} +P_{\ell H} \le 1,\\
        \frac{P_{hH}}{P_{hH} + P_{hL}}, &\ otherwise.
    \end{cases}
\end{equation*}

% On the other hand, when $\alpha \le \thdmaj$, we show the threshold that a good $\kd$-strong equilibrium exists is exactly $\kd = (1 - \thdmaj) \cdot \ag$. 

\begin{theorem}
\label{thm:thresholdk}
Let $\kd = \xi\cdot \ag$. Let $\xi^*$ be defined as follows: 
\begin{itemize}
    \item When $\alpha > \thdmaj$, $\xi^* = +\infty$.
    \item When $\thdmaj \ge \alpha \ge \frac{\infdif}{1 - \thdmaj}$, $\xi^* = 1 - \thdmaj$.
    \item When $\frac{\infdif}{1 - \thdmaj} > \alpha > 0.5$, $\xi^* = \infdif\cdot \alpha$. 
\end{itemize}

For any $\xi < \xi^*$, there exists a sequence of strategy profile $\{\stgp_\ag\}$ such that,
    \begin{enumerate}
        \item For all $\ag$, no agents play weakly dominated strategies in $\stgp_\ag$,
        \item the fidelity $\acc(\stgp_\ag)$ converges to 1, and
        \item for all $\ag$, $\stgp_\ag$ is an $\varepsilon$-ex-ante Bayesian $\kd$ strong equilibrium, where $\varepsilon$ converges to 0.
    \end{enumerate}
    For $\xi^* < + \infty$, when $\xi = \xi^*$, no such sequence of profile exists. 
\end{theorem}

\subsection{Proof of Theorem~\ref{thm:thresholdk}.}

Throughout the proof we assume that $P_{hH} \le P_{\ell L}$. In this case, $\thdmaj = \frac12 + \frac{P_{\ell H}}{2P_{\ell L}}$, and $\frac{\infdif}{1 - \thdmaj} = \frac12 + \frac{P_{hL}}{2P_{\ell L}} = \frac{1}{2P_{\ell L}}$. It is not hard to verify that $\thdmaj \ge \frac{\infdif}{1 - \thdmaj}$. 

% \subsubsection{Lemmas}
% We start from the following useful lemma. We apply this lemma to construct strategies profiles where no agents play weakly dominated strategy while we only care about the average of their strategies to calculate fidelity. 
% \begin{lemma}
% \label{lem:avg_dominated}
%     (Majority agents.) Let $A'$ be a group of majority agents such that $|A'| = \Theta (\ag)$ and no agents play weakly dominated strategy. Let $\abpl = \frac{1}{|A'|}=\sum_{i \in A'} \bpl^i$ and $\abph = \frac{1}{|A'|}=\sum_{i \in A'} \bph^i$ be the average strategy played by agents in $A'$. Then for any $\bpl \le \bph$, there exists a set of strategies $(\stg_i)_{i\in A'}$ such that $|\bpl - \abpl| = O(\frac1{\ag})$ and $|\bph - \abph| = O(\frac1{\ag})$. 

%     (Minority agents.) Let $I'$ be a group of minority agents such that $|I'| = \Theta (\ag)$ and no agents play weakly dominated strategy. Let $\abpl = \frac{1}{|I'|}=\sum_{i \in I'} \bpl^i$ and $\abph = \frac{1}{|I'|}=\sum_{i \in I'} \bph^i$ be the average strategy played by agents in $I'$. Then for any $\bpl \le \bph$, there exists a set of strategies $(\stg_i)_{i\in I'}$ such that $|\bpl - \abpl| = O(\frac1{\ag})$ and $|\bph - \abph| = O(\frac1{\ag})$. 
% \end{lemma}

% \begin{proof}
%     We show the proof for majority agents. The reason for minority agents will be similar. Consider the following strategy set: $\lfloor \bpl \cdot |A'| \rfloor$ agents play $(1, 1)$ (always vote for $\bA$, $\lfloor (1 - \bph)\cdot |A'| \rfloor$ agents play $(0, 0)$ (always vote for $\bR$, and other agents play $(0, 1)$ (vote informatively). Then it is not hard to verify that $|\bpl - \abpl| = O(\frac1{\ag})$ and $|\bph - \abph| = O(\frac1{\ag})$. 
% \end{proof}

\subsubsection{Case 1: $\alpha > \thdmaj$.}
With a direct application from the previous work, the following corollary shows that when the fraction of the majority type agents is above the threshold, a good equilibrium always exists. \Qishen{Add ``optimal'' strategy here.}

\begin{coro}
\label{coro:extoacc}
    When the fraction of the majority $\alpha > \thdmaj$, for any $1 \le \kd \le \ag$, any strategy profile where all the majority type agents play the optimal strategy profile forms a $\varepsilon$-ex-ante Bayesian $\kd$-strong equilibrium with $\varepsilon$ converges to 1. Such equilibrium leads to the informed majority decision with probability converging to 1. 
\end{coro}

By Lemma~\ref{lem:dominated}, the optimal strategy majority agents play is not weakly dominated. Therefore, when minority agents play any non-weakly-dominated strategy, such equilibrium satisfies the constraint where no agents play weakly dominated strategy. 

\subsubsection{Case 2: $\thdmaj \ge \alpha \ge \frac{\infdif}{1 - \thdmaj}$.} In this section, it is sufficient to show the following two statements. Claim~\ref{claim:upper} shows that when $\alpha \le \thdmaj$ and $\kd = (1 - \thdmaj)\cdot \ag$, even constraint (2) and (3) are not compatible. Claim~\ref{claim:lower} shows that when $\alpha \ge \frac{\infdif}{1 - \thdmaj}$ and $\kd < (1 - \thdmaj)\cdot \ag$, a strategy profile satisfying all three constraints exists. 

\begin{claim}
\label{claim:upper}
    For all $\alpha \le \thdmaj$, for any profile sequence $\{\stgp_\ag\}$ such that $\acc(\stgp_\ag)$ converges to 1 and no agents play weakly dominated strategies, there is a constant $\varepsilon > 0$ and constantly many $\ag$ such that $\stgp_\ag$ is NOT an $\varepsilon$-ex-ante Bayesian $\kd$-strong equilibrium, where $\kd = (1 - \thdmaj)\cdot \ag$. 
\end{claim}
\begin{proof}[Proof for Claim~\ref{claim:upper}.] 
    In this case, we show that a group of $(1 - \thdmaj)\cdot \ag$ of minority type agents can successfully deviate by always voting for $\bA$ or always voting for $\bR$ simultaneously. Suppose $\{\stgp\}$ is a strategy profile sequence such that $\acc(\stgp)$ converges to 1. We take an arbitrary $\ag$. Let $D$ be the deviate group contains $(1 - \thdmaj)\cdot \ag$ minority type agents. Let $\astg = \sum_{i\not\in D} \stg_i = (\abpl, \abph)$ be the average of strategies of non-deviators, and
    let $\hthd_H$ and $\hthd_{L}$ be expected vote share for $\bA$ from all the non-deviators under world state $H$ and $L$, respectively. Then,
    \begin{align*}
        \hthd_H =&\ \thdmaj\cdot (P_{hH}\cdot \abph + P_{\ell H}\cdot \abpl).\\
        \hthd_L = &\ \thdmaj\cdot (P_{hL}\cdot \abph + P_{\ell L}\cdot \abpl).
    \end{align*}
    If $\hthd_H \le \frac{1}{2}$, all the deviators can always vote for $\bR$, and the expected votes for $\bA$ in the deviating strategy $\stgp'$ will be no more than $\frac{1}{2}$. Then by applying the Hoeffding Inequality or Berry Esseen Theorem, We can show that $\lp_{H}^{\bA}(\stgp') \le 1 - \delta$ from some constant $\delta$, and the minority type deviator can gain a constant utility from deviation. 

    Now suppose $\hthd_H > \frac{1}{2}$, we show that $\hthd_L + (1 - \thdmaj) > \frac12$ so that the deviation can succeed by all the deviators always voting for $\bA$. Given that $\thdmaj = \frac{1}{2M}$, where $M = \frac{P_{\ell L}}{P_{\ell L} + P_{\ell H}}$, this is equivalent to show that 
    \begin{equation*}
        \hthd'_L = P_{hL} \cdot \abph + P_{\ell L}\cdot \abpl > \frac{P_{\ell H}}{P_{\ell L} + P_{\ell H}}
    \end{equation*}
    under the condition that
    \begin{equation*}
        \hthd'_H = P_{hH} \cdot \abph + P_{\ell H}\cdot \abpl > \frac{P_{\ell L}}{P_{\ell L} + P_{\ell H}}.
    \end{equation*}

    Now, let function $\gunc(\bph) = P_{hL} \cdot \bph + P_{\ell L}\cdot \frac{\hthd'_H - P_{hH}\cdot \bph}{P_{\ell H}} - \frac{P_{\ell L}}{P_{\ell L} + P_{\ell H}}$. Then it is sufficient to show that $\gunc(\abph) > 0. $

    Firstly, $\frac{d \gunc}{d \bph} = \frac{P_{hL}\cdot P_{\ell H} - P_{hH}\cdot P_{\ell L}}{P_{\ell H}} < 0$. Therefore, $\gunc(\bph)$ is minimized when $\bph$ is maximized. 
    Therefore, 
    \begin{align*}
        \gunc(\abph) \ge &\ \gunc(1)\\
        =&\ P_{hL} + P_{\ell L}\cdot \frac{\hthd'_H - P_{hH}\cdot \bph}{P_{\ell H}} - \frac{P_{\ell L}}{P_{\ell L} + P_{\ell H}}.
    \end{align*}
    Recall that $\hthd'_H > M$. Therefore,  
    \begin{align*}
        \hthd'_H - P_{hH}\cdot \bph > &\ \frac{P_{\ell L}}{P_{\ell L} + P_{\ell H}} - P_{hH}\\
        =&\ \frac{(P_{\ell L} -P_{hH} \cdot P_{\ell L}) - P_{hH}\cdot P_{\ell H}}{P_{\ell L} + P_{\ell H}}\\
        =&\ \frac{P_{\ell L}\cdot P_{\ell H} - P_{hH}\cdot P_{\ell H}}{P_{\ell L} + P_{\ell H}}\\
        =&\ \frac{(P_{\ell L} - P_{hH})\cdot P_{\ell H}}{P_{\ell L} + P_{\ell H}}.
    \end{align*}
    Therefore, 
    \begin{align}
        \gunc(\abph) > &\ \frac{P_{\ell L}}{P_{\ell H}}\cdot \frac{(P_{\ell L} - P_{hH})\cdot P_{\ell H}}{P_{\ell L} + P_{\ell H}} + (P_{hL} - \frac{P_{\ell L}}{P_{\ell L} + P_{\ell H}})\\
        =&\  \frac{(P_{\ell L} - P_{hH})\cdot P_{\ell L}}{P_{\ell L} + P_{\ell H}} + \frac{(P_{h L} - P_{\ell H})\cdot P_{\ell L}}{P_{\ell L} + P_{\ell H}}\\
        =&\ 0. 
    \end{align}
    Therefore, $\hthd'_L > \frac{P_{\ell H}}{P_{\ell L} + P_{\ell H}}$. Then by applying the Hoeffding Inequality, We can show that $\lp_{L}^{\bR}(\stgp') \le 1 - \delta$ from some constant $\delta$, and the minority type deviator can gain a constant utility from deviation. 
\end{proof}

\begin{claim}
\label{claim:lower}
    For all $\alpha \ge \frac{\infdif}{1 - \thdmaj}$, for any $\xi < 1 - \thdmaj$ and $\kd = \xi\cdot \ag$, there exists a strategy profile sequence that satisfies all three constraints. 
\end{claim}

\begin{proof}[Proof for Claim~\ref{claim:lower}.]
    For each $\ag$, let $\stgp_\ag$ be the following. All the minority agents always vote for $\bA$. The majority agents play the following strategy.
    \begin{align*}
        \bpl^{\maj}  =&\ \frac1{\alpha} (\alpha - \frac12 - \frac{P_{hL}}{\infdif}\cdot \xi) - \delta \cdot (P_{h H} + P_{h L}).\\
        \bph^{\maj}  =&\ \frac1{\alpha} (\alpha - \frac12 + \frac{P_{\ell L}}{\infdif}\cdot \xi) +  \delta \cdot (P_{\ell H} + P_{\ell L}).
    \end{align*}
    Here $\delta > 0$ is a constant such that $1 \ge \bpl^{\maj} \ge 0$ and $1 \ge \bph^{\maj} \ge 0$, and at least one of $\bpl^{\maj} = 0$ and $\bph^{\maj} = 1$ holds. We first show that such $\delta$ exists. 

    For $\bpl^{\maj}$, $\frac1{\alpha} (\alpha - \frac12 - \frac{P_{hL}}{\infdif}\cdot \xi) <\frac1{\alpha} \cdot \alpha < 1$. 
    Since $\alpha \ge \frac{\infdif}{1 - \thdmaj} = \frac{1}{2} + \frac{P_{hL}}{2P_{\ell L}}$,  there is $\frac{\alpha - 1/2}{P_{hL}} \ge \frac{1}{2P_{\ell L}}$. 
    Moreover, given that $\xi < 1- \thdmaj = \frac12 - \frac{P_{\ell H}}{2P_{\ell L}} = \frac{\infdif}{2P_{\ell L}}$, 
    \begin{align*}
        \alpha - \frac12 - \frac{P_{hL}}{\infdif}\cdot \xi >&\ \alpha - \frac12 - \frac{P_{hL}}{\infdif}\cdot  \frac{\Delta}{2P_{\ell L}}\\
        =&\ \alpha - \frac12-  \frac{P_{hL}}{2P_{\ell L}}\\
        \ge&\ 0. 
    \end{align*}

    For $\bph^{\maj}$, $\alpha - \frac12 + \frac{P_{\ell L}}{\infdif}\cdot \xi \ge \alpha - \frac12 > 0$. Given that $\alpha \ge \frac{1}{2} + \frac{P_{hL}}{2P_{\ell L}}$ and that $\xi < \frac{\infdif}{2P_{\ell L}}$, 
    \begin{align*}
        \frac1{\alpha} (\alpha - \frac12 + \frac{P_{\ell L}}{\infdif}\cdot \xi) < \frac{1}{\alpha}(\alpha - \frac12 +  \frac{P_{\ell L}}{2P_{\ell L}}) = \frac{1}{\alpha}\cdot \alpha = 1.
    \end{align*}
    Therefore, such $\delta  > 0$ exists. 

    Now we are ready to show that the sequence $\{\stgp_\ag\}$ satisfies all three constraints. According to Lemma~\ref{lem:dominated}, it is not hard to verify that all agents are playing non-weakly dominated strategy. For the fidelity, we compute the \exshare{} of the profile. 
    \begin{align*}
        \thd_H^\ag = &\ \alpha \cdot \delta \cdot \infdif + \xi > 0.\\
        \thd_L^\ag = &\ \alpha \cdot \delta \cdot \infdif > 0. 
    \end{align*}
    Therefore, by applying Hoeffding Inequality, both $\lp_H^{\bA}(\stgp_\ag) \ge 1 - 2\exp(-(\alpha \cdot \delta \cdot \infdif)^2 \cdot \ag)$ and $\lp_L^{\bR}(\stgp_\ag) \ge 1 - 2\exp(-(\alpha \cdot \delta \cdot \infdif)^2 \cdot \ag)$. This implies that the fidelity of $\stgp_\ag$ converges to 1. 

    Now we show that $\stgp_\ag$ is an equilibrium. Let $e = 2\exp(-(\alpha \cdot \delta \cdot \infdif)^2 \cdot \ag)$, and $\stgp'_\ag$  be a different strategy profile such that at most $\xi\cdot \ag$ agents deviate. The difference on the ex-ante expected utility of agent $i$ under two strategy profiles is 
    \begin{align*}
        \ut_{i}(\stgp'_\ag) - \ut_{i}(\stgp_\ag) = &\ P_H\cdot (\lp_{H}^{\bA}(\stgp'_\ag) - \lp_{H}^{\bA}(\stgp_\ag))(\vt_{i}(H, \bA) - \vt_{i}(H,\bR))+ P_L\cdot (\lp_{L}^{\bR}(\stgp'_\ag) - \lp_{L}^{\bR}(\stgp_\ag))(\vt_{i}(L, \bR) - \vt_{i}(L,\bA)).
    \end{align*}
    
    We discuss on different cases on the fidelity of $\stgp'_\ag$. 

    Suppose $\acc(\stgp'_\ag) \ge 1 -  \frac{(B+1)e}{P_H\cdot P_L}$. For a majority agent $i$, $\ut_{i}(\stgp'_\ag) - \ut_{i}(\stgp_\ag) \le P_H\cdot e\cdot B + P_L\cdot e\cdot B = Be.$ For a minority agent $i$, $\ut_{i}(\stgp'_\ag) - \ut_{i}(\stgp_\ag) \le P_H\cdot \frac{(B+1)e}{P_H^2\cdot P_L}\cdot B + P_L\cdot \frac{(B+1)e}{P_H\cdot P_L^2}\cdot B = \frac{2B(B+1)e}{P_H\cdot P_L}.$
    Therefore, no agent can get expected utility gain more than $\frac{2B(B+1)e}{P_H\cdot P_L}$. 

    Suppose $\acc(\stgp'_\ag) < 1 - \frac{(B+1)e}{P_H\cdot P_L}$. We first show that majority agents will not join the deviating group. Then we show that at most $\xi\cdot \ag$ minority agents cannot successfully deviate. $\acc(\stgp'_\ag) < 1 - \frac{(B+1)e}{P_H\cdot P_L}$, at least one of $\lp_H^{\bA}(\stgp'_\ag) < 1 - \frac{(B+1)e}{P_H\cdot P_L}$ and $\lp_L^{\bR}(\stgp'_\ag) < 1 - \frac{(B+1)e}{P_H\cdot P_L}$ holds. When $\lp_H^{\bA}(\stgp'_\ag) < 1 - \frac{(B+1)e}{P_H\cdot P_L}$, the utility difference of a majority agent $i$ will be $\ut_{i}(\stgp'_\ag) - \ut_{i}(\stgp_\ag) < P_H\cdot (e - \frac{(B+1)e}{P_H\cdot P_L} )\cdot 1 + P_L\cdot e\cdot B < (P_H - 1)\cdot e + (P_L -1)\cdot B \cdot e < 0.$ When $\lp_L^{\bR}(\stgp'_\ag) < 1 - \frac{(B+1)e}{P_H\cdot P_L}$ holds, the utility difference of a majority agent $i$ is also strictly negative according to similar reasoning. Therefore, a majority agent has no incentives to join the deviation group. 

    Now suppose the deviation group $D$ contains only minority types of agents. Let $\thd_L'$ and $\thd_H'$ be the \exshare{} of $\stgp'_\ag$. Since in $\stgp_\ag$ all minorities always vote for $\bA$, any deviation will increase the vote share of $\bR$. Therefore, $\thd_L' \ge \thd_L^\ag = \alpha \cdot \delta\ cdot \infdif$. Moreover, since there are at most $\xi\cdot \ag$ deviators, $\thd_H' \ge \thd_H^\ag - \xi = \alpha \cdot \delta \cdot \infdif$. By the Hoeffding Inequality, $\lp_H^{\bA}(\stgp'_\ag) \ge 1 - e$ and $\lp_L^{\bR}(\stgp'_\ag) \ge 1 - e$. Therefore, $\acc(\stgp'_\ag) \ge 1 - e$, which contradicts the assumption that $\acc(\stgp'_\ag) < 1 - \frac{(B+1)e}{P_H\cdot P_L}$. Therefore, such deviation cannot succeed, and $\stgp_\ag$ is an $\frac{2B(B+1)e}{P_HP_L}$-ex-ante Bayesian $\kd$-strong equilibrium. 
\end{proof}

\subsubsection{Case 3; $\frac{\infdif}{1 - \thdmaj} > \alpha \ge \frac12 + \frac{P_{hL}}{2(\infdif + P_{\ell L})}$.}

\begin{claim}
\label{claim:lower2}
    For all $0.5 < \alpha \le \frac{\infdif}{1 - \thdmaj}$, for any $\xi < \frac{\infdif \cdot (\alpha - 1/2)}{P_{hL}}$ and $\kd = \xi\cdot \ag$, there exists a strategy profile sequence that satisfies all three constraints. 
\end{claim}

\begin{proof}[Proof for Claim~\ref{claim:lower}.]
    For each $\ag$, let $\stgp_\ag$ be the following. All the minority agents always vote for $\bA$. The majority agents play the following strategy.
    \begin{align*}
        \bpl^{\maj}  =&\ \frac1{\alpha} (\alpha - \frac12 - \frac{P_{hL}}{\infdif}\cdot \xi) - \delta \cdot (P_{h H} + P_{h L}).\\
        \bph^{\maj}  =&\ \frac1{\alpha} (\alpha - \frac12 + \frac{P_{\ell L}}{\infdif}\cdot \xi) +  \delta \cdot (P_{\ell H} + P_{\ell L}).
    \end{align*}
    Here $\delta > 0$ is a constant such that $1 \ge \bpl^{\maj} \ge 0$ and $1 \ge \bph^{\maj} \ge 0$, and at least one of $\bpl^{\maj} = 0$ and $\bph^{\maj} = 1$ holds. We first show that such $\delta$ exists. 

    For $\bpl^{\maj}$, $\frac1{\alpha} (\alpha - \frac12 - \frac{P_{hL}}{\infdif}\cdot \xi) <\frac1{\alpha} \cdot \alpha < 1$. 
    Given that $\xi < \frac{\infdif \cdot (\alpha - 1/2)}{P_{hL}}$, 
    \begin{align*}
        \alpha - \frac12 - \frac{P_{hL}}{\infdif}\cdot \xi >&\ \alpha - \frac12 - \frac{P_{hL}}{\infdif}\cdot  \frac{\infdif \cdot (\alpha - 1/2)}{P_{hL}}\\
        =&\ \alpha - \frac12-  \alpha + \frac12\\
        =&\ 0. 
    \end{align*}

    For $\bph^{\maj}$, $\alpha - \frac12 + \frac{P_{\ell L}}{\infdif}\cdot \xi \ge \alpha - \frac12 > 0$. Given that $\alpha \ge \frac{1}{2} + \frac{P_{hL}}{2P_{\ell L}}$ and that $\xi < \frac{\infdif \cdot (\alpha - 1/2)}{P_{hL}} \le \frac{\infdif}{2P_{\ell L}}$ ($\frac{\infdif \cdot (\alpha - 1/2)}{P_{hL}} \le \frac{\infdif}{2P_{\ell L}}$ comes from that $\alpha \le \frac{\infdif}{1 -\thdmaj}$), 
    \begin{align*}
        \frac1{\alpha} (\alpha - \frac12 + \frac{P_{\ell L}}{\infdif}\cdot \xi) < \frac{1}{\alpha}(\alpha - \frac12 +  \frac{P_{\ell L}}{2P_{\ell L}}) = \frac{1}{\alpha}\cdot \alpha = 1.
    \end{align*}
    Therefore, such $\delta  > 0$ exists. 

    Now we are ready to show that the sequence $\{\stgp_\ag\}$ satisfies all three constraints. According to Lemma~\ref{lem:dominated}, it is not hard to verify that all agents are playing non-weakly dominated strategy. For the fidelity, we compute the \exshare{} of the profile. 
    \begin{align*}
        \thd_H^\ag = &\ \alpha \cdot \delta \cdot \infdif + \xi > 0.\\
        \thd_L^\ag = &\ \alpha \cdot \delta \cdot \infdif > 0. 
    \end{align*}
    Therefore, by applying Hoeffding Inequality, both $\lp_H^{\bA}(\stgp_\ag) \ge 1 - 2\exp(-(\alpha \cdot \delta \cdot \infdif)^2 \cdot \ag)$ and $\lp_L^{\bR}(\stgp_\ag) \ge 1 - 2\exp(-(\alpha \cdot \delta \cdot \infdif)^2 \cdot \ag)$. This implies that the fidelity of $\stgp_\ag$ converges to 1. 

    The rest of the proof resemeble that of Claim~\ref{claim:lower}. We show that $\stgp_\ag$ is an equilibrium. Let $e = 2\exp(-(\alpha \cdot \delta \cdot \infdif)^2 \cdot \ag)$, and $\stgp'_\ag$  be a different strategy profile such that at most $\xi\cdot \ag$ agents deviate. The difference on the ex-ante expected utility of agent $i$ under two strategy profiles is 
    \begin{align*}
        \ut_{i}(\stgp'_\ag) - \ut_{i}(\stgp_\ag) = &\ P_H\cdot (\lp_{H}^{\bA}(\stgp'_\ag) - \lp_{H}^{\bA}(\stgp_\ag))(\vt_{i}(H, \bA) - \vt_{i}(H,\bR))+ P_L\cdot (\lp_{L}^{\bR}(\stgp'_\ag) - \lp_{L}^{\bR}(\stgp_\ag))(\vt_{i}(L, \bR) - \vt_{i}(L,\bA)).
    \end{align*}
    
    We discuss on different cases on the fidelity of $\stgp'_\ag$. 

    Suppose $\acc(\stgp'_\ag) \ge 1 -  \frac{(B+1)e}{P_H\cdot P_L}$. For a majority agent $i$, $\ut_{i}(\stgp'_\ag) - \ut_{i}(\stgp_\ag) \le P_H\cdot e\cdot B + P_L\cdot e\cdot B = Be.$ For a minority agent $i$, $\ut_{i}(\stgp'_\ag) - \ut_{i}(\stgp_\ag) \le P_H\cdot \frac{(B+1)e}{P_H^2\cdot P_L}\cdot B + P_L\cdot \frac{(B+1)e}{P_H\cdot P_L^2}\cdot B = \frac{2B(B+1)e}{P_H\cdot P_L}.$
    Therefore, no agent can get expected utility gain more than $\frac{2B(B+1)e}{P_H\cdot P_L}$. 

    Suppose $\acc(\stgp'_\ag) < 1 - \frac{(B+1)e}{P_H\cdot P_L}$. We first show that majority agents will not join the deviating group. Then we show that at most $\xi\cdot \ag$ minority agents cannot successfully deviate. $\acc(\stgp'_\ag) < 1 - \frac{(B+1)e}{P_H\cdot P_L}$, at least one of $\lp_H^{\bA}(\stgp'_\ag) < 1 - \frac{(B+1)e}{P_H\cdot P_L}$ and $\lp_L^{\bR}(\stgp'_\ag) < 1 - \frac{(B+1)e}{P_H\cdot P_L}$ holds. When $\lp_H^{\bA}(\stgp'_\ag) < 1 - \frac{(B+1)e}{P_H\cdot P_L}$, the utility difference of a majority agent $i$ will be $\ut_{i}(\stgp'_\ag) - \ut_{i}(\stgp_\ag) < P_H\cdot (e - \frac{(B+1)e}{P_H\cdot P_L} )\cdot 1 + P_L\cdot e\cdot B < (P_H - 1)\cdot e + (P_L -1)\cdot B \cdot e < 0.$ When $\lp_L^{\bR}(\stgp'_\ag) < 1 - \frac{(B+1)e}{P_H\cdot P_L}$ holds, the utility difference of a majority agent $i$ is also strictly negative according to similar reasoning. Therefore, a majority agent has no incentives to join the deviation group. 

    Now suppose the deviation group $D$ contains only minority types of agents. Let $\thd_L'$ and $\thd_H'$ be the \exshare{} of $\stgp'_\ag$. Since in $\stgp_\ag$ all minorities always vote for $\bA$, any deviation will increase the vote share of $\bR$. Therefore, $\thd_L' \ge \thd_L^\ag = \alpha \cdot \delta\cdot \infdif$. Moreover, since there are at most $\xi\cdot \ag$ deviators, $\thd_H' \ge \thd_H^\ag - \xi = \alpha \cdot \delta \cdot \infdif$. By the Hoeffding Inequality, $\lp_H^{\bA}(\stgp'_\ag) \ge 1 - e$ and $\lp_L^{\bR}(\stgp'_\ag) \ge 1 - e$. Therefore, $\acc(\stgp'_\ag) \ge 1 - e$, which contradicts the assumption that $\acc(\stgp'_\ag) < 1 - \frac{(B+1)e}{P_H\cdot P_L}$. Therefore, such deviation cannot succeed, and $\stgp_\ag$ is an $\frac{2B(B+1)e}{P_HP_L}$-ex-ante Bayesian $\kd$-strong equilibrium. 
\end{proof}

\begin{claim}
\label{claim:upper2}
    For all $\frac{\infdif}{1 - \thdmaj} > \alpha \ge \frac{1}{1 + P_{\ell L}}$, for any profile sequence $\{\stgp_\ag\}$ such that $\acc(\stgp_\ag)$ converges to 1 and that no agents play weakly dominated strategies, there is a constant $\varepsilon > 0$ and constantly many $\ag$ such that $\stgp_\ag$ is NOT an $\varepsilon$-ex-ante Bayesian $\kd$-strong equilibrium, where $\kd = \frac{\infdif \cdot (\alpha - 1/2)}{P_{hL}}\cdot \ag$. 
\end{claim}

\begin{proof}
    Let $\fone$ and $\fz$ be the fraction of minority agents playing $\bpl = 1$ and $\bph = 0$, respectively. We specifically regulate that agents playing $\bpl = 1$ and $\bph = 0$ simultaneously only counted in $\fz$. Note that $\fone + \fz = 1 - \alpha$. Let $\xi = \frac{\infdif \cdot (\alpha - 1/2)}{P_{hL}}$. We consider three cases: $\fz \le \xi$, $\fone \le \xi$, and both $\fz$ and $\fone$ is larger than $\xi$. 

    We first consider $\fz \le \xi$. In this case, let the deviating group $D$ contains $\xi\cdot \ag$ agents, including all the $\bph = 0$ agents and $(\xi - \fz)\cdot \ag$ of $\bpl = 1$ agents. Let $\bph^{\mino}$ and $\bpl^{\mino}$ be the average strategy of all the non-deviating minority agents, then there must be $\bpl^{\mino} = 1$. Similarly, let $\bph^{\maj}$ and $\bpl^{\maj}$ be the average strategy of all the majority agents. Then the expected vote share of $\bA$ for all the \textbf{non-deviators} is 
    \begin{align*}
        \hthd_H =&\ \alpha\cdot (P_{hH}\cdot \bph^{\maj} + P_{\ell H}\cdot \bpl^{\maj}) +  (1 - \alpha - \xi)\cdot (P_{hH}\cdot \bph^{\mino} + P_{\ell H}\cdot \bpl^{\mino}).\\
        \hthd_L =&\ \alpha\cdot (P_{hL}\cdot \bph^{\maj} + P_{\ell L}\cdot \bpl^{\maj}) +  (1 - \alpha - \xi)\cdot (P_{hL}\cdot \bph^{\mino} + P_{\ell L}\cdot \bpl^{\mino}).
    \end{align*}

    It is not hard to verify that, when $\bpl^{\maj} = 0$ and $\bph^{\maj} = \frac{1/2 + P_{\ell H} \cdot \xi / \infdif - (1 -\alpha-\xi) \cdot \bph^{\mino}}{\alpha}$, $\hthd^H = \frac12$ and $\hthd_L = \frac12 - \xi$. Then we show that for any majority's strategies, either $\hthd_H \le \frac12$ or $\hthd_L \ge \frac12 - \xi$ holds.

    Denote $\frac{1/2 + P_{\ell H} \cdot \xi / \infdif - (1 -\alpha-\xi) \cdot \bph^{\mino}}{\alpha}$ as $\bph^*$. Then the expected vote share can be rewritten as 
    \begin{align*}
        \hthd_H =&\ \frac12 + \alpha\cdot (P_{hH}\cdot (\bph^{\maj} - \bph^*) + P_{\ell H}\cdot \bpl^{\maj}).\\
        \hthd_L =&\ \frac12 - \xi + \alpha\cdot (P_{hL}\cdot (\bph^{\maj} - \bph^*) + P_{\ell L}\cdot \bpl^{\maj}).
    \end{align*}
    If $\hthd_H > \frac12$, there must be $P_{hH}\cdot (\bph^{\maj} - \bph^*) + P_{\ell H}\cdot \bpl^{\maj} > 0$. By $P_{hH} > P_{hL}$ and $P_{\ell L} > P_{\ell H}$, there must be $ (P_{hL}\cdot (\bph^{\maj} - \bph^*) + P_{\ell L}\cdot \bpl^{\maj}) > 0$. Therefore, $\hthd_L \ge \frac12 - \xi$. Therefore, similar to Claim~\ref{claim:upper}, we can show that the fidelity after deviation can be smaller than 1 by a constant, and agents in $D$ have incentives (constant expected utility gain) to deviate.  

    When $\fone \le \xi$, let deviating group $D$ contains all the $\bpl = 1$ agents and $(\xi - \fone)\cdot \ag$ of $\bph = 0$ agents. Then for the non-deivating minority agents there must be $\bph^{\min} = 0$. Therefore, When $\bph^{\mino} = 0$, the solution $(\bpl^*, \bph^*)$ that makes $\hthd^H = \frac12$ and $\hthd_L = \frac12 - \xi$ satisfies that $\bph^* = \frac{1/2 + P_{\ell H} \cdot \xi /\infdif}{\alpha} >  1$. Therefore, that for any majority's strategies, either $\hthd_H \le \frac12$ or $\hthd_L \ge \frac12 - \xi$ holds. Therefore, similar to Claim~\ref{claim:upper}, we can show that the fidelity after deviation can be smaller than 1 by a constant, and agents in $D$ have incentives (constant expected utility gain) to deviate. 

    Now consider $\fz > \xi$ and $\fone > \xi$. For minority agents with $\bpl = 1$, let $\bph^1$ be their average probability voting for $\bA$ when receiving $h$ signal. For minority agents with $\bph = 0$, let $\bpl^0$ be their average probability voting for $\bA$ when receiving $\ell$ signal. The expected vote share for $\bA$ of \textbf{all agents} can be rewritten as follows.   
    \begin{align*}
        \hthd_H = &\ \alpha\cdot (P_{hH}\cdot \bph^{\maj} + P_{\ell H}\cdot \bpl^{\maj}) +  \fone \cdot  (P_{hH} \cdot \bph^1+ P_{\ell H} ) + \fz \cdot P_{\ell H} \cdot \bpl^0.\\
        \hthd_L = &\ \alpha\cdot(P_{hL}\cdot \bph^{\maj} + P_{\ell L}\cdot \bpl^{\maj})+ \fone \cdot  (P_{hL} \cdot \bph^1+ P_{\ell L} ) + \fz \cdot P_{\ell L} \cdot \bpl^0.
    \end{align*}
     Consider two possible deviating: (1) $\xi\cdot \ag$ minority agents playing $\bpl = 1$ with largest $\bph$ deviate to always voting for $\bR$, and (2) $\xi\cdot \ag$ minority agents playing $\bph = 0$ with smallest $\bpl$ deviate to always voting for $\bA$. We show that one of the two deviations will succeed.

     For the first deviation, the expected vote share for $\bA$ under world state $H$ is  $\hthd'_H \le \hthd_H - \xi \cdot (P_{hH} \cdot \bph^1+ P_{\ell H})\le $
     $$\alpha\cdot (P_{hH}\cdot \bph^{\maj} + P_{\ell H}\cdot \bpl^{\maj}) +  \fone \cdot  (P_{hH} \cdot \bph^1+ P_{\ell H} ) + \fz \cdot P_{\ell H} \cdot \bpl^0.$$
     
    . For the second deviation the expected vote share for $bA$ under world state $L$ is 
     $\hthd'_L \ge \hthd_L + \xi \cdot (1 - P_{\ell L} \cdot \bpl^0)$. Then the solution to \begin{align*}
         \hthd_H - \xi \cdot (P_{hH} \cdot \bph^1+ P_{\ell H}) =&\ \frac12.\\
          \hthd_L + \xi\cdot (1 - P_{\ell L} \cdot \bpl^0)  =&\ \frac12.
     \end{align*}
    is 
    
    
    The solution to $\hthd_H = \frac12 + \xi$ or $\hthd_L = \frac12 - \xi$. is $\bph^* = \frac1\alpha \cdot (\frac12 + \frac{\xi}{\infdif} - \fone)$ and $\bpl^* = \frac1\alpha \cdot (\frac12 - \frac{\xi}{\infdif} - \fone)$. Note that $\fz + \fone = 1 - \alpha$. When $\fz \le \frac{1 \alpha}{2}$, 
    \begin{align*}
        \bph^* \ge&\ \frac{1/2 + (\alpha - 1/2) / P_{hL} - (1 - \alpha) / 2}{\alpha}\\
        =&\ \frac12 + \frac{1 - 1 / (2\alpha)}{P_{hL}}. 
    \end{align*}
    Since $\alpha \ge \frac{1}{1 + P_{\ell L}}$, $\frac{1 - 1 / (2\alpha)}{P_{hL}} \ge \frac12$, and $\bph^* \ge 1$. 

    And When $\fone \le \frac{1 \alpha}{2}$, 
    \begin{align*}
        \bpl^* \le&\ \frac{1/2 - (\alpha - 1/2) / P_{hL} - (1 - \alpha) / 2}{\alpha}\\
        =&\ \frac12 - \frac{1 - 1 / (2\alpha)}{P_{hL}}. 
    \end{align*}
    Since $\alpha \ge \frac{1}{1 + P_{\ell L}}$, $\frac{1 - 1 / (2\alpha)}{P_{hL}} \ge \frac12$, and $\bpl^* \le 0$. Therefore, that for any minority's strategies such that $\fz \ge \xi$ and $\fone \ge \xi$ and any majority's strategies, either $\hthd_H \le \frac12 + \xi$ or $\hthd_L \ge \frac12 - \xi$ holds.

    If $\hthd_H \le \frac12 + \xi$, let $D$ be $\xi\cdot \ag$ 
    % Let $D$ contains as fewer agents with $\bph = 0 $ as possible. Then there must be $\bph^{\mino} \le \max(\frac{1 - \alpha - 2\xi}{1 - \alpha - \xi}, 0)$. When $\bph^{\mino} = 0$, the solution $(\bpl^*, \bph^*)$ that makes $\hthd^H = \frac12$ and $\hthd_L = \frac12 - \xi$ satisfies that $\bph^* = \frac{1/2 + P_{\ell H} \cdot \xi /\infdif}{\alpha} >  1$. Therefore, that for any majority's strategies, either $\hthd_H \le \frac12$ or $\hthd_L \ge \frac12 - \xi$ holds.
    
    % When $\bph^{\mino} = \frac{1 - \alpha - 2\xi}{1 - \alpha - \xi}$, the solution $\bph^* = \frac{(2\alpha - 1)\cdot (P_{hH} + P_{\ell L})}{2P_{hL}}$. Given that  $\alpha \ge \frac12 + \frac{P_{hL}}{2(\infdif + P_{\ell L})}$, $\bph^* \ge 1$. Therefore, that for any majority's strategies, either $\hthd_H \le \frac12$ or $\hthd_L \ge \frac12 - \xi$ holds. 
    % Therefore, we can show that the fidelity after deviation can be smaller than 1 by a constant, and agents in $D$ have incentives (constant expected utility gain) to deviate.  
\end{proof}

\subsubsection{Case 4: $\frac12 + \frac{P_{hL}}{2(\infdif + P_{\ell L})} > alpha > 0.5$.} 

\begin{claim}
    \label{claim:lower3}
    For all $0.5 < \alpha < \frac12 + \frac{P_{hL}}{2(\infdif + P_{\ell L})}$, for any $\xi < \frac{\infdif \cdot \alpha}{P_{\ell L } + P_{hH}}$ and $\kd = \xi\cdot \ag$, there exists a strategy profile sequence that satisfies all three constraints. 
\end{claim}

\begin{proof}
    For each $\ag$, let $\stgp_\ag$ be the following strategy profile. All majority agents play $\bph^{\maj} = 1$ and $\bpl^{\maj} = 0$. For minority agents, a fraction (with $O(\frac1\ag)$ rounding error) of $\fz = \frac12 - \alpha \cdot \frac{P_{\ell L}}{P_{\ell L} + P_{hH}}$ agents always vote for $\bR$, and a fraction of $\fone = \frac12 - \alpha \cdot \frac{P_{hH}}{P_{\ell L} + P_{hH}}$ agents always vote for $\bA$. (Note that $\fz + \fone = 1 - \alpha$). It is not hard to verify that, when $\alpha < \frac12 + \frac{P_{hL}}{2(\infdif + P_{\ell L})}$, both $\fz > \xi$ and $\fone > \xi$ holds. 

    Now we are ready to show that the sequence $\{\stgp_\ag\}$ satisfies all three constraints. According to Lemma~\ref{lem:dominated}, it is not hard to verify that all agents are playing non-weakly dominated strategy. For the fidelity, we compute the \exshare{} of the profile. 
    \begin{align*}
        \thd_H^\ag = &\ \alpha \cdot \delta \cdot \infdif + \xi > 0.\\
        \thd_L^\ag = &\ \alpha \cdot \delta \cdot \infdif > 0. 
    \end{align*}
    Therefore, by applying Hoeffding Inequality, both $\lp_H^{\bA}(\stgp_\ag) \ge 1 - 2\exp(-(\alpha \cdot \delta \cdot \infdif)^2 \cdot \ag)$ and $\lp_L^{\bR}(\stgp_\ag) \ge 1 - 2\exp(-(\alpha \cdot \delta \cdot \infdif)^2 \cdot \ag)$. This implies that the fidelity of $\stgp_\ag$ converges to 1. 

    The rest of the proof resemble that of Claim~\ref{claim:lower}. We show that $\stgp_\ag$ is an equilibrium.
\end{proof}

% \begin{prop}
% \label{prop:goodex}
%     Suppose $\alpha \le \thdmaj$, and $\kd = \xi \cdot \ag$. 
%     \begin{itemize}
%         \item If $\xi < 1 - \thdmaj$, the strategy profile $\stgp^*$ where all the agents play the optimal strategy profile forms a $\varepsilon$-ex-ante Bayesian $\kd$-strong equilibrium with $\varepsilon$ converges to 1. Such equilibrium leads to the informed majority decision with probability converging to 1.

%         \item If $\xi \ge 1 - \thdmaj$, any strategy profile $\stgp$ such that $\acc(\stgp) \to 1$ is NOT a $\varepsilon$-ex-ante Bayesian $\kd$-strong equilibrium with $\varepsilon$ converges to 1.
%     \end{itemize}
% \end{prop}

% \begin{proof}
% Without loss of generality, assume  $P_{hH} + P_{hL} < 1$. 
% \paragraph{Case 1: $\xi < 1 - \thdmaj$}
%     The optimal strategy is $\bph = 1$ and $\bpl = \frac12 \cdot (1 - \frac{P_{hL} + P_{hH}}{P_{\ell L} + P_{\ell H}})$. In this case, the minimum expected vote for $\bA$ by $\ag - \kd$ the world state $H$, which is reached when all deviators always report $\bR$, is 
%    \begin{align*}
%        &\ \frac12(1 +\frac{P_{hH} \cdot P_{\ell L} - P_{\ell H}\cdot P_{hL}}{P_{\ell L} + P_{\ell H}})\cdot (\ag  - \kd)\\
%        =&\ \frac12(1 +\frac{P_{hH} \cdot P_{\ell L} - P_{\ell H}\cdot P_{hL}}{P_{\ell L} + P_{\ell H}})\cdot (1 - \xi) \cdot \ag\\
%        > &\ \frac12(1 +\frac{P_{hH} \cdot P_{\ell L} - P_{\ell H}\cdot P_{hL}}{P_{\ell L} + P_{\ell H}})\cdot \thdmaj \cdot \ag\\
%        =&\ \frac{\ag}2. 
%    \end{align*}
%    And the maximum expected vote for $\bA$ in the world state $L$, which is reached by all deviators voting for $\bA$, is strictly smaller than $\frac{\ag}{2}$. 
%     Therefore, no matter what deviators play, the expected votes for $\bA$ under $H$ state $\thd_H > \frac{\ag}2$, and the expected votes under $L$ state $\thd_L < \frac{\ag}{2}$ Then by the Hoeffding Inequality, for any deviating strategy profile $\stgp'$ (including the original strategy profile $\stgp^*$), $\lp_H^{\bA}(\stgp') \ge 1 - 2(\exp(-\Theta(\ag))$ and $\lp_L^{\bR}(\stgp') \ge 1 - 2(\exp(-\Theta(\ag))$. This implies that the fidelity of $\stgp^*$ converges to 1. 

%     Therefore, for any possible deviation, no agent shall gain an expected utility of more than $2B\cdot \exp(-\Theta(\ag))$. Let $\varepsilon = B\cdot \exp(-\Theta(\ag))$, which converges to 0 as $\ag$ goes to infinity. This implies that $\stgp^*$ is a $\varepsilon$-ex-ante Bayesian $\kd$-strong equilibrium. 

%     \paragraph{Case 2: $\xi \ge 1 - \thdmaj$} In this case, we show that a group of $(1 - \thdmaj)\cdot \ag$ of minority type agents can successfully deviate by always voting for $\bA$ or always voting for $\bR$ simultaneously. Suppose $\stgp$ is a strategy profile such that $\acc(\stgp)$ converges to 1. Let $D$ be the deviate group contains $(1 - \thdmaj)\cdot \ag$ minority type agents. LLet $\astg = \sum_{i\not\in D} \stg_i = (\abpl, \abph)$ be the average of strategies of non-deviators, and
%     let $\thd_H$ and $\thd_{L}$ be expected votes for $\bA$ from all the non-deviators under world state $H$ and $L$, respectively. Then,
%     \begin{align*}
%         \thd_H =&\ \thdmaj\cdot (P_{hH}\cdot \abph + P_{\ell H}\cdot \abpl)\cdot \ag.\\
%         \thd_L = &\ \thdmaj\cdot (P_{hL}\cdot \abph + P_{\ell L}\cdot \abpl)\cdot \ag.
%     \end{align*}
%     If $\thd_H \le \frac{\ag}{2}$, all the deviators can always vote for $\bR$, and the expected votes for $\bA$ in the deviating strategy $\stgp'$ will be no more than $\frac{\ag}{2}$. Then by applying the Hoeffding Inequality or Berry Esseen Theorem, We can show that $\stgp_{H}^{\bA}(\stgp') \le 1 - \delta$ from some constant $\delta$, and the minority type deviator can gain a constant utility from deviation. 

%     Now suppose $\thd_H > \frac{\ag}{2}$, we show that $\thd_L + (1 - \thdmaj) \ge \frac12$ so that the deviation can succeed by all the deviators always voting for $\bA$. Given that $\thdmaj = \frac{1}{2M}$, where $M = \frac{P_{\ell L}}{P_{\ell L} + P_{\ell H}}$, this is equivlent to show that 
%     \begin{equation*}
%         \hthd'_L = P_{hL} \cdot \abph + P_{\ell L}\cdot \abpl \ge \frac{P_{\ell H}}{P_{\ell L} + P_{\ell H}}
%     \end{equation*}
%     under the condition that
%     \begin{equation*}
%         \thd'_H = P_{hH} \cdot \abph + P_{\ell H}\cdot \abpl > \frac{P_{\ell L}}{P_{\ell L} + P_{\ell H}}.
%     \end{equation*}

%     Now, let function $\gunc(\bph) = P_{hL} \cdot \bph + P_{\ell L}\cdot \frac{\thd'_H - P_{hH}\cdot \bph}{P_{\ell H}} - \frac{P_{\ell L}}{P_{\ell L} + P_{\ell H}}$. Then it is sufficient to show that $\gunc(\abph) > 0. $

%     Firstly, $\frac{d \gunc}{d \bph} = \frac{P_{hL}\cdot P_{\ell H} - P_{hH}\cdot P_{\ell L}}{P_{\ell H}} < 0$. Therefore, $\gunc(\bph)$ is minimized when $\bph$ is maximized. 
%     Therefore, 
%     \begin{align*}
%         \gunc(\abph) \ge &\ \gunc(1)\\
%         =&\ P_{hL} + P_{\ell L}\cdot \frac{\thd'_H - P_{hH}\cdot \bph}{P_{\ell H}} - \frac{P_{\ell L}}{P_{\ell L} + P_{\ell H}}.
%     \end{align*}
%     Recall that $\thd'_J > M$. Therefore,  
%     \begin{align*}
%         \thd'_H - P_{hH}\cdot \bph > &\ \frac{P_{\ell L}}{P_{\ell L} + P_{\ell H}} - P_{hH}\\
%         =&\ \frac{(P_{\ell L} -P_{hH} \cdot P_{\ell L}) - P_{hH}\cdot P_{\ell H}}{P_{\ell L} + P_{\ell H}}\\
%         =&\ \frac{P_{\ell L}\cdot P_{\ell H} - P_{hH}\cdot P_{\ell H}}{P_{\ell L} + P_{\ell H}}\\
%         =&\ \frac{(P_{\ell L} - P_{hH})\cdot P_{\ell H}}{P_{\ell L} + P_{\ell H}}.
%     \end{align*}
%     Therefore, 
%     \begin{align}
%         \gunc(\abph) > &\ \frac{P_{\ell L}}{P_{\ell H}}\cdot \frac{(P_{\ell L} - P_{hH})\cdot P_{\ell H}}{P_{\ell L} + P_{\ell H}} + (P_{hL} - \frac{P_{\ell L}}{P_{\ell L} + P_{\ell H}})\\
%         =&\  \frac{(P_{\ell L} - P_{hH})\cdot P_{\ell L}}{P_{\ell L} + P_{\ell H}} + \frac{(P_{h L} - P_{\ell H})\cdot P_{\ell L}}{P_{\ell L} + P_{\ell H}}\\
%         =&\ 0. 
%     \end{align}
%     Therefore, $\thd'_L > \frac{P_{\ell H}}{P_{\ell L} + P_{\ell H}}$. Then by applying the Hoeffding Inequality or Berry Esseen Theorem, We can show that $\stgp_{L}^{\bR}(\stgp') \le 1 - \delta$ from some constant $\delta$, and the minority type deviator can gain a constant utility from deviation. 
% \end{proof}

\subsection{Result for Bayesian strong equilibrium.}

