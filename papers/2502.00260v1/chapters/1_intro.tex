The Bayesian game model~\citep{Harsanyi67} is a powerful theoretical tool for analyzing agents' strategic behavior with incomplete information. It has been applied to a wide range of real-world scenarios, including auctions, eliciting information, marketing, and collective decision-making, just to name a few. %The Bayesian game model is a famous game-theoretical model to study the strategic behavior of agents with incomplete information. 
In a Bayesian game, rational agents receive private information (named {\em types}) and act strategically to optimize the outcome in expectations conditioned on their types. 

In Bayesian games, rational and self-interested agents may behave strategically and deviate from the intentions of the mechanisms. Moreover, in many real-world scenarios, agents may coordinate their strategic behavior to collectively benefit. For example, bidders may coordinate to place low bids in the auction and drive down prices, voters may collaborate to cast votes strategically, and agents may conspire to gain a higher payment in peer prediction systems. 
% Coordinated agents are more powerful than a single agent in strategic behaviors and have stronger impacts on the outcome of the game. 

\begin{example}[{\bf Group strategic behavior in peer prediction}{}]
\label{ex:motive}
%In this paper, we use information elicitation without verification, a.k.a. peer prediction as a representative of Bayesian games. 
Consider an online crowdsourcing (for example, image labeling) group. %Workers are required to report their private signals (for example, labels towards pictures). 
A peer prediction mechanism is applied to evaluate the quality of worker reports and calculate their rewards. The reward of a worker is calculated by comparing his/her report with another worker's (called a peer) report. 

In a peer prediction mechanism, a worker usually gets a higher reward when his/her report has higher agreement with the peer's report. Therefore, a group of workers can benefit by colluding in advance and reporting the same answer to receive higher payments.  However, the information collector desires to design a mechanism to prevent collusion and collect truthful reports from agents. %How can you predict the behavior of these strategic workers with the possibility of group collusion?
\end{example}

Therefore, the importance lies in answering the following research question:
% in predicting the strategic behaviors and the outcome of agents in Bayesian games with group strategic behaviors, and we propose the research question.
\begin{center}
   {\bf How can we predict the outcome of Bayesian games with group strategic behaviors?} 
\end{center}

Previous literature~\citep{ichiishi1996bayesian,schoenebeck21wisdom,guo2022robust} have developed ``strong'' or ``coalitional'' equilibria, in an analogy of strong Nash equilibrium~\citep{Aumann59:Acceptable}, to predict group strategic behaviors in the Bayesian game model, in which no group of agents shall benefit from strategic deviation.
However, most solution concepts allow an arbitrary size of the strategic group and fall into the same criticism of ``being too strong'' as the strong Nash equilibrium. For example, \citet{Gao2019incentivizing} show that truth-telling cannot be a strong equilibrium in many peer prediction mechanisms, and \citet{han2023wisdom} show that a strong equilibrium may not exist in majority voting with incomplete information.

On the other hand, group strategic behaviors usually happen with a bounded size in real life. For example, a player will only collude with his/her friends or trusted players, and a mechanism that prevents deviations from a bounded size of groups is sufficient to collect truthful reports in most cases~\citep{Shnayder2016practcal}. Moreover, instead of the ``all-or-nothing'' characterizations, studying equilibria with coalitions of a bounded size provides richer structures that enable more constructive solutions to many economic problems.
However, whether a bounded size of group deviation exists is not characterized by the ``strong'' equilibria in the previous work. 

% \Biaoshuai{I added the following paragraph.}\Qishen{Does this overlap the previous paragraph?}

% As mentioned above, strong equilibria with unlimited deviating group sizes are typically too strong to exist in many problems.



\subsection{Our Contribution}

We propose two solution concepts in which group strategic behaviors with a bounded number of agents are considered.
In an ex-ante Bayesian $\kd$-strong equilibrium, no group with at most $\kd$ agents can deviate from the equilibrium strategy so that every group member gets a higher ex-ante expected utility, i.e., the expected utility before agents know their types. In a Bayesian $\kd$-strong equilibrium, no group with at most $\kd$ agents can deviate from the equilibrium strategy so that every group member gets a higher expected utility conditioned on every type. 

The difference between the two solution concepts is how agents calculated their expected utilities when contemplating whether a deviation is beneficial. 
We interpret this difference as different attitudes of agents towards deviations.
In the ex-ante Bayesian $\kd$-strong equilibrium, a group of agents deviates once the deviation is profitable in the ex-ante expectation. In the Bayesian $\kd$-strong equilibrium, an agent is assumed to be more conservative towards deviation and will deviate only when the deviation is profitable conditioned on every possible type. 
Proposition~\ref{prop:etoq} shows that an ex-ante Bayesian $\kd$-strong equilibrium implies a Bayesian $\kd$-strong equilibrium.

Our technical contributions lie in the study of the collusion problem in peer prediction mechanisms, as a representative of group strategic behavior in Bayesian games, with our solution concepts. We exactly characterize the group sizes $\kd$ where the truthful reporting in the peer prediction mechanism by~\citep{Miller05:Eliciting} is an ex-ante Bayesian $\kd$-strong equilibrium (Theorem~\ref{thm:pp_exante}) and a Bayesian $\kd$-strong equilibrium (Theorem~\ref{thm:pp_qi}), respectively.  In each case, we show a threshold so that group sizes below this threshold cannot benefit by deviating while group sizes above this threshold can.  In general, these thresholds are different for the two types of equilibria we consider.   
Our thresholds are characterized by the parameters of the game, including the number of agents, common prior, and the scoring adopted by the mechanism. Our result implies that our equilibria parameterized by $\kd$ are natural criteria to evaluate the robustness against collusion for a peer prediction mechanism. If truth-telling is an equilibrium with a larger $\kd$, the mechanism is more robust against collusion. In the application of the peer prediction mechanism, the scoring rule and the mechanism that maximizes the threshold could be chosen to prevent a wider range of collusion. 

We also discuss two other possible scenarios where our solution concept may apply. In the voting scenario where voters only have partial information about the alternatives, it is known that strong equilibria with unlimited coalition sizes may fail to exist when there is a sufficiently large group of voters whose preferences are not aligned with the rest of the voters~\cite{deng2024aggregation}. However, the sizes of the deviating groups are typically large in those non-equilibria. Given that it is unlikely for large numbers of voters to collaborate in large elections, it is therefore appealing to study equilibria with bounded deviating groups and obtain more informative results. In the private Blotto game~\citep{donahue2023private}, social media users with noisy information choose to annotate for/against one of the multiple posts. Agents aim to maximize the overall influence of their type on the posts. Our notion interpolates the centralized Colonel Blotto game and the decentralized private Blotto game. The parameter $\kd$ becomes an evaluation to characterize scenarios where agents have different centralization levels, where a higher $\kd$ represents a higher ability for agents to coordinate and for their type.

\subsection{Related Work}
Previous work studies group strategic behavior in Bayesian games under different scenarios. \citet{hahn2001coalitional} and \citet{safronov2018coalition} study coalitional implementation problems under an exchange economy with a strong equilibrium. \citet{ichiishi1996bayesian} and \citet{ichiishicooperative} propose the Bayesian strong equilibrium and study its relationship with cooperative game theory.  \citet{schoenebeck21wisdom}, \citet{han2023wisdom}, and \citet{deng2024aggregation} adopt an approximated version of strong equilibrium to study information aggregation and voting with incomplete information. Nevertheless, none of these works characterizes group strategic behaviors with a bounded size of the group. 
\citet{guo2022robust} proposed a coalitional interim equilibrium in which the set of admissible coalitions can be arbitrarily exogenously given. Their solution concept covers a wider range of admissible coalitions than our paper. However, truthful reporting is such an equilibrium only when agents are also coalitionally truthful when they know the report of all other agents, which does not hold for most peer prediction mechanisms. In our setting, truthful reporting fails to be such an equilibrium even with a constant coalition size under mild assumptions (Appendix~\ref{apx:guo}).
\citet{Abraham2008:lower} proposes a $k$-coalitional equilibrium where the deviators are allowed to arbitrarily share private information, which may not be applied to many real-world scenarios. For example, the organizer can randomly assign tasks or set limited response periods to prevent agents from arbitrary communication. Moreover, truthful reporting also fails to be such an equilibrium even with a constant coalition size, as signal sharing updates the deviators' beliefs and drives them to different strategies. 
Our ex-ante Bayesian $\kd$-strong equilibrium is related to the equilibrium in~\citep{schoenebeck21wisdom, han2023wisdom,deng2024aggregation}, and our Bayesian $\kd$-strong equilibrium is an extension of the Bayesian strong equilibrium in~\citep{ichiishi1996bayesian}. In the game with complete information, \citet{Aumann59:Acceptable} propose the strong Nash equilibrium in which no group of agents has an incentive to deviate. The strong Nash equilibrium (and its variants) has been applied to study group strategic behavior in many scenarios such as congesting game~\citep{holzman1997strong,yin2011nash,harks2012existence}, voting~\citep{desmedt2010equilibria, barbera2001voting,rabinovich2015analysis}, and Markov game~\citep{clempner2015computing,clempner2020finding}. \citet{Abraham2006:distributed} studies $\kd$-coalitional strategic behavior under games with complete information. However, a strong Nash equilibrium does not apply to Bayesian games where the information is incomplete. 


Our paper is also related to studying the collusion problem in peer prediction mechanisms.  Because the appropriate theoretical definitions have not been available, collusion has not been studied explicitly in theoretical peer prediction work. However, many works touch on related concepts.  Intuitively, equilibrium selection is related to collusion because agents can coordinate to choose an equilibrium that is bad for the mechanism.  \citet{Gao2014trick} empirically showed this to be a problem, while \citet{Gao2019incentivizing} shows that agents may also coordinate on a low-effort signal.   The problem of equilibrium selection is exacerbated by the inevitable existence of uninformative equilibria~\citep{Jurca07:Collusion,Jurca2009mechanism,Waggoner2014output}.  Many papers address the problem by developing mechanisms where truthful reporting is more profitable than uninformative collusions~\citep{Jurca07:Collusion,Jurca2009mechanism,Dasgupta2013crowd, witkowski2013learning,kong18selection,radanovic2015incentive,prelec2004bayesian}.  More powerfully, works have shown that the truthful equilibrium has the highest possible payments either among all equilibrium \citep{Kong16put} or even among all strategies profiles~\citep{shnayder2016informed,KongS19,ZhangS2023multitask}. However, all the latter results consider multi-task peer prediction, while no single-task peer prediction mechanisms have been discovered to have the same merit. Moreover, none of these works study the collusion problem from the perspective of strong equilibrium. \citet{SchoenebeckYZ2021WWW} studied a more extreme case where the goal was to design peer prediction mechanisms that are robust against an adversary that controls a constant fraction of the nodes.  The present work is different because the deviating groups are required to be strategic and not purely malicious. 
% These latter results show that agents cannot gain by colluding ex-ante.   However, the particular definitions of the mechanism/games do not permit agents to share information, and in these mechanisms, agents may still be able to benefit by colluding to share information. 

Several works study collusion using simulations and measuring how many agents must deviate before truth-telling fails to be the best response for the remaining agents~\citep{Shnayder2016practcal,BurrellS2021measurement} or so that certain dynamics fail to converge back to truth-telling~\citep{Shnayder2016measuring}.  This shows that while the problem is interesting, the theoretical tools available for prior work were insufficient.   

% In multi-task peer prediction, \citet{shnayder2016informed} propose a mechanism that guarantees truth-telling to have the highest payments, which rules out the possibility of collusion and is experimentally supported by


% Collusion has become a major barrier to peer prediction mechanisms for practical use~\citep{Gao2014trick}. The inevitable existence of uninformative equilibria~\citep{Jurca07:Collusion,Jurca2009mechanism,Waggoner2014output} hinders the elicitation of truthful information. In multi-task peer prediction, \citet{shnayder2016informed} propose a mechanism that guarantees truth-telling to have the highest payments, which rules out the possibility of collusion and is experimentally supported by \citep{Shnayder2016practcal}  However, no single-task peer prediction mechanisms have been discovered to satisfy the same property. \citet{Kong16put} propose a single-task mechanism that guarantees truth-telling to the equilibrium with the highest reward among all equilibria. However, the mechanism itself is still prone to group deviation. \citet{Gao2019incentivizing} shows the negative result that when agents have multiple private information, no detail-free peer prediction mechanism can reward truthful agents more than collusive agents. Many other papers address the problem by developing mechanisms where truthful reporting is more profitable than uninformative collusions~\citep{Jurca07:Collusion,Jurca2009mechanism,Dasgupta2013crowd, witkowski2013learning,kong18selection,radanovic2015incentive}. None of these works study the collusion problem from the perspective of strong equilibrium. 