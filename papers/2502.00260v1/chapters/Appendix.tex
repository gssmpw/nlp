\section{Properties of proper scoring rule.}

For a scoring rule $PS$, we define $\eps: \Delta_{\Sigset}\times \Delta_{\Sigset} \to \mathbb{R}$ such that for two distributions $\vpr_1$ and $\vpr_2$, $\eps(\vpr_1; \vpr_2) = \Ex_{\sigi \sim \vpr_1}[\ps(\sigi, \vpr_2)]$.

Proper scoring rules have the following properties. 
\begin{theorem}
    \label{thm:psr}
    [\citep{hendrickson1971score}]
    A scoring rule $\ps$ is (strictly) proper if and only if there exists a (strictly) convex function $G: \Delta_{\Sigset} \to \mathbb{R}$, such that for any $\vpr$, $G(\vpr) = \eps(\vpr; \vpr)$, and $PS(\sigi, \vpr) =G(\vpr) + dG (\vpr) (\delta_{\sigi} - \vpr),$ where $dG$ is a subgradient of $G$, and $\delta_{\sigi}$ is the distribution that putting probability 1 on $\sigi$.
\end{theorem}

We use this property to prove the following Lemma.

\begin{lemma}
    \label{lem:pr_psr}
    Given the assumptions, the following inequalities hold. 
    (1) $\ps(h, \vpr_h) > \ps(h,  \vpr_{\ell})$. (2) $\ps(\ell, \vpr_{\ell}) > \ps(\ell, \vpr_h)$.  
\end{lemma}

\begin{proof}[Proof of Lemma~\ref{lem:pr_psr}]
    % (1) holds by the following conditional probability: $\pr(h) \cdot \pr(\ell \mid h) = \pr(\ell) \cdot \pr (h \mid \ell)$. Since we assume $\pr(h) \ge \pr(\ell)$, there are $\pr(\ell \mid h) \le \pr(h \mid \ell)$ and $\pr(h\mid h) \ge \pr(\ell \mid \ell)$. 
Suppose $G$ and $dG$ are the convex function and the subgradient satisfying Theorem~\ref{thm:psr} regarding $\ps$. Then we have 
    \begin{align*}
        \ps(h, \vpr_h) = &\ G(\vpr_h) + dG(\vpr_h)\cdot(\ds_h - \vpr_h). \\
        \ps(h, \vpr_{\ell}) = &\ G(\vpr_{\ell}) + dG(\vpr_{\ell})\cdot(\ds_h - \vpr_{\ell}). 
    \end{align*}
    $\ds_h$ is the distribution on $\Sigset$ that putting probability 1 on $h$. 

    Since $dG$ is a subgradient of $G$, it satisfies $G(y) \ge G(x) + dG(x) \cdot (y - x)$ for any $x, y \in \Delta_{\Sigset}$. Consequently, $(dG(y) - dG(x))\cdot (y - x) \ge 0$ for any $x, y \in \Delta_{\Sigset}$. 
    Then we have 
    \begin{align*}
        \ps(h, \vpr_h) - \ps(h, \vpr_{\ell}) =&\ G(\vpr_h) - G(\vpr_{\ell}) + dG(\vpr_h)\cdot(\ds_h - \vpr_h) - dG(\vpr_{\ell})\cdot(\ds_h - \vpr_{\ell})\\
        \ge&\ dG(\vpr_{\ell})\cdot (\vpr_h - \vpr_{\ell})+ dG(\vpr_h)\cdot(\ds_h - \vpr_h) - dG(\vpr_{\ell})\cdot(\ds_h - \vpr_{\ell})\\
        =&\ (dG(\vpr_h) - dG(\vpr_{\ell}))\cdot (\ds_h - \vpr_{h}). 
    \end{align*}
    Note that $(\ds_h - \vpr_{h})(h) = 1 - \pr(h\mid h) = \pr(\ell \mid h)$, and $(\ds_h - \vpr_{h})(\ell) =-\pr(\ell \mid h)$. On the other hand, $(\vpr_h - \vpr_{\ell})(h) = -(\vpr_h - \vpr_{\ell})(\ell) = \pr(h \mid h) - \pr(h \mid \ell) > 0$. Therefore, 
    \begin{align*}
        \ps(h, \vpr_h) - \ps(h, \vpr_{\ell}) =&\ (dG(\vpr_h) - dG(\vpr_{\ell}))\cdot (\ds_h - \vpr_{h})\\
        =&\ \frac{\pr(\ell \mid h)}{\pr(h\mid h) - \pr(h \mid \ell)} \cdot (dG(\vpr_h) - dG(\vpr_{\ell}))\cdot (\vpr_h - \vpr_{\ell})\\
        \ge &\ 0,
    \end{align*}
    With similar reasoning we have $\ps(\ell, \vpr_{\ell}) - \ps(\ell, \vpr_h) \ge 0$.
    % And for (3), we will combine (1) and (2) together. Let $\bar{\ds} = \frac12(\ds_h + \ds_\ell)$ be the (discrete) uniform distribution on $\Sigset$.  Then
    % \begin{align*}
    %     &\ \ps(h, \vpr_h) + \ps(\ell, \vpr_h) - \ps(h, \vpr_{\ell}) - \ps(\ell, \vpr_{\ell})\\
    %     =&\ 2G(\vpr_h) - 2G(\vpr_\ell) + dG(\vpr_h)\cdot (\ds_h + \ds_\ell - 2\vpr_h) - dG(\vpr_\ell)\cdot (\ds_h + \ds_\ell - 2\vpr_\ell)\\
    %     \ge &\ 2dG(\vpr_\ell)\cdot (\vpr_h - \vpr_\ell) + 2dG(\vpr_h)\cdot (\bar{\ds} - \vpr_h) - 2dG(\vpr_\ell)\cdot (\bar{\ds} - \vpr_\ell)\\
    %     =&\ 2(dG(\vpr_h) - dG(\vpr_\ell))\cdot (\bar{\ds} - \vpr_h). 
    % \end{align*}
    % Similarly, we have $(\bar{\ds} - \vpr_h)(h) = (\bar{\ds} - \vpr_h)(\ell) = \pr(h \mid h) - \frac12)$
    Then note that since $\ps$ is a strictly proper scoring rule, 
    \begin{align*}
        &\ \eps(\vpr_h; \vpr_h) - \eps(\vpr_h, \vpr_\ell)\\ = &\ \pr(h\mid h)\cdot (\ps(h, \vpr_h) - \ps(h, \vpr_\ell)) + \pr(\ell \mid h) \cdot(\ps(\ell, \vpr_h) - \ps(\ell, \vpr_\ell))\\
        >&\  0. 
    \end{align*}
    Therefore, $\ps(h, \vpr_h) - \ps(h, \vpr_\ell) > 0$.
    The proof of (2) follows a similar reasoning as (1). 
\end{proof}

\section{Equivalence with Bayesian Nash Equilibrium}
\label{apx:equiv}

In this section, we show that when $k = 1$, both ex-ante Bayesian $\kd$-strong equilibrium and Bayesian $\kd$-strong equilibrium are equivalent to the classical Bayesian Nash Equilibrium~\cite{Harsanyi67}. 

\begin{definition}[Bayesian Nash equilibrium]
    A strategy profile $\stgp = (\stg_i)_{i\in [\ag]}$ is a Bayesian Nash equilibrium (BNE) if for every agent $i$, every $i$'s strategy $\stg_i'$, and every type $\sigi_i \in \Sigset_i$, $\ut_i (\stgp \mid \sigi_i) \ge \ut_i((\stg_i', \stgp_{-i}) \mid \sigi_i)$, where $\stgp_{-i}$ is the strategies all other agents play in $\stgp$. 
\end{definition}

The following propositions shows the equivalence among solution concepts. 

\begin{prop}
\label{prop:BNE_to_exante}
    If a strategy profile $\stgp$ is a Bayesian Nash equilibrium, then $\stgp$ is an ex-ante Bayesian $1$-strong equilibrium. 
\end{prop}
\begin{proof}
    Suppose $\stgp$ is a Bayesian Nash equilibrium, then for every agent $i$, every $i$'s strategy $\stg_i'$, and every type $\sigi_i \in \Sigset_i$, $\ut_i (\stgp \mid \sigi_i) \ge \ut_i((\stg_i', \stgp_{-i}) \mid \sigi_i)$. Then from the law of total probability, adding up all the types in $\Sigset$, $\ut_i(\stgp) \ge \ut_i((\stg_i', \stgp_{-i}))$. This implies that $\stgp$ is an ex-ante Bayesian $1$-strong equilibrium. 
\end{proof}

\begin{prop}
\label{prop:qi_to_BNE}
    If a strategy profile $\stgp$ is a Bayesian 1-strong equilibrium, then $\stgp$ is a Bayesian Nash equilibrium. 
\end{prop}
\begin{proof}
    Suppose $\stgp$ is NOT a Bayesian Nash equilibrium, and for agent $i$, strategy $\stg'_i$, and type $\sigi_i$.  $\ut_i (\stgp \mid \sigi_i) < \ut_i((\stg_i', \stgp_{-i}) \mid \sigi_i)$. Now consider the strategy $\stg_i''$ such that for all $\sigi_i' \in \Sigset_i$ and $\sigi_i' \neq \sigi_i$, $\stg_i''(\sigi') = \stg_i(\sigi')$, and $\stg_i''(\sigi_i) = \stg_i'(\sigi)$. Then we have $\ut_i (\stgp \mid \sigi_i) < \ut_i((\stg_i'', \stgp_{-i}) \mid \sigi_i)$ and $\ut_i (\stgp \mid \sigi_i)  = \ut_i((\stg_i', \stgp_{-i}) \mid \sigi_i)$ for all $\sigi_i' \in \Sigset_i$ and $\sigi_i' \neq \sigi_i$.  This implies that $\stgp$ is a Bayesian $1$-strong equilibrium. 
\end{proof}

Proposition~\ref{prop:BNE_to_exante}, Proposition~\ref{prop:qi_to_BNE}, and Proposition~\ref{prop:etoq} when $\kd = 1$ form a cycle of equivalence.

\section{Proof of Theorem~\ref{thm:pp_exante}}
\label{apx:exante}
    The proof consists of two steps. In Step 1, we characterize $\kde$ by comparing the ex-ante expected utility of a deviator when every agent reports truthfully and when all $\kd$ deviators always report $h$ (and always report $\ell$, respectively). At least one of the two deviations brings a deviator higher expected utility if and only if $\kd > \kde$. In Step 2, we show that for any $\kd \le \kde$ and any deviating strategy profile $\stgp'$, the average expected utility among all the deviators when $\stgp'$ is played will not exceed the expected utility when every agent reports truthfully. Therefore, there exists a deviator whose expected utility will decrease after the deviation, and the deviation cannot succeed. 
    


    \noindent\textbf{Step 1: characterizing $\kde$. } 

    Consider a deviating group $D$ of $k$ agents. In the deviating strategy profile $\stgp$, all the deviators always report $h$, i.e. $\stg = (1, 1)$. (The reasoning for all deviators reporting $\ell$ will be similar.) We fix an arbitrary deviator $i \in D$ and characterize the condition of $k$ such that $\ut_i(\stgp) > \ut_i(\stgp^*). $ Due to the symmetricity of the strategy profile, this implies that the expected utility of every deviator is higher in deviation than in truth-telling, and the deviation is successful. 

    % While $\ut_i(\stgp^*)$ is independent of $k$, $\ut_i(\stgp)$ relies on $k$. Let $\afrac = \frac{k-1}{n-1}$ be the fraction of the deviators among all the agents except for $i$. 
    To compare the expected utilities, we divide $\ut_i(\stgp)$. One part is the average expected utility from all other deviators $j \in D\setminus{i}$, denoted by $\ut_i(\stgp\mid \jdeviate)$. The other part is the average expected utility from all truthful agents $j \in [n]\setminus D$, denoted by $\ut_i(\stgp\mid \jtruthful)$. 
    \begin{align*}
    \ut_i(\stgp) =&\
    \frac{1}{\ag -1}\left(\sum_{j \in D\setminus{i}} \Ex[\rwd_i(\rp_j)] + \sum_{j \in [n]\setminus D} \Ex[\rwd_i(\rp_j)]\right)\\ 
     =&\  \frac{\kd-1}{\ag -1}\cdot\ut_i(\stgp\mid \jdeviate) + \frac{\ag - \kd}{\ag -1}\cdot \ut_i(\stgp\mid \jtruthful).  
\end{align*}

With the truthfulness of the peer prediction mechanism, $\ut_i(\stgp\mid \jtruthful)$ is maximized when $i$ reports truthfully, and $i$ cannot increase his/her expected utility by deviation in this part. Therefore, agent $i$ should gain a higher expected utility in the deviation part. 

Let $\dut_d = \ut_i(\stgp^*) -\ut_i(\stgp\mid \jdeviate)$, and $\dut_t = \ut_i(\stgp^*) -\ut_i(\stgp\mid \jtruthful)$. Our goal is to find the condition on $\kd$ such that
\begin{equation*}
    \frac{\kd-1}{\ag -1} \cdot\dut_d + \frac{\ag -\kd}{\ag -1} \cdot \dut_t< 0. 
\end{equation*}
Note that when in $\stgp$ all agents $i$ have equal expected utility. Therefore, the inequality should be strict.
When $\dut_t > \dut_d$, this is equivalent to
\begin{equation*}
    \kd > \frac{\dut_t}{\dut_t - \dut_d}\cdot (n-1) + 1. 
\end{equation*}
And when $\dut_t \le \dut_d$, the condition does not hold for any $k$, and the deviation will never succeed. 

We first calculate the truthful expected utility. Note that when everyone plays the same strategy, the expected utility equals the expectation on $\rwd_i(\rp_j)$.
\begin{align*}
    \ut_i(\stgp^*) = &\ \pr(h) \cdot(\pr(h \mid h) \cdot \ps(h, \vpr_h) + \pr(\ell \mid h) \cdot \ps(\ell, \vpr_h))\\
    &\ + \pr(\ell) \cdot(\pr(h \mid \ell) \cdot \ps(h, \vpr_\ell) + \pr(\ell \mid \ell) \cdot \ps(\ell, \vpr_\ell)). 
\end{align*}

Then we calculate $\ut_i(\stgp\mid \jtruthful)$.
\begin{align*}
    \ut_i(\stgp\mid \jtruthful) = &\ \pr(h) \cdot(\pr(h \mid h) \cdot \ps(h, \vpr_h) + \pr(\ell \mid h) \cdot \ps(\ell, \vpr_h))\\
    &\ + \pr(\ell) \cdot(\pr(h \mid \ell) \cdot \ps(h, \vpr_h) + \pr(\ell \mid \ell) \cdot \ps(\ell, \vpr_h)). 
\end{align*}
Therefore, the first part of the difference is
\begin{align*}
   \dut_t = &\ \pr(\ell) \cdot(\pr(h \mid \ell) \cdot (\ps(h, \vpr_\ell) -\ps(h, \vpr_h)) + \pr(\ell \mid \ell) \cdot (\ps(\ell, \vpr_\ell) - \ps(\ell, \vpr_h)))\\
    =&\ \pr(\ell)\cdot \Ex_{\sigi\sim \vpr_{\ell}}[\ps(\sigi, \vpr_{\ell}) - \ps(\sigi, \vpr_{h})]
\end{align*}
From the property of the strict proper scoring rule, we know that $\dut_t > 0$. 

And when $j$ is a deviator always reporting $h$, the utility of $i$ will always be $\ps(h, \vpr_h)$. Therefore, the second part of the difference is
\begin{align*}
    \dut_d = &\pr(\ell) \cdot(\pr(h \mid \ell) \cdot (\ps(h, \vpr_\ell) -\ps(h, \vpr_h)) + \pr(\ell \mid \ell) \cdot (\ps(\ell, \vpr_\ell) - \ps(h, \vpr_h)))\\ 
    &\ + \pr(h)\cdot \pr(\ell \mid h) \cdot (\ps(\ell, \vpr_h) - \ps(h, \vpr_h)).
\end{align*}

% Since we assume that $\ps(h, \vpr_h) \ge \ps(\ell, \vpr_\ell)$, and according to Lemma~\ref{lem:pr_psr} and the assumption that $\ps(h, \vpr_h) \ge \ps(\ell, \vpr_\ell)$, we have $\dut_t > 0$ and $\dut_d \le 0$. 
And 
\begin{align*}
    \dut_t - \dut_d = &\ \pr(\ell) \cdot \pr(\ell \mid \ell) (\ps(h, \vpr_h) - \ps(\ell, \vpr_h)) - \pr(h)\cdot \pr(\ell \mid h) (\ps(\ell, \vpr_h) - \ps(h, \vpr_h))\\
    =& \pr(\ell)\cdot   (\ps(h, \vpr_h) - \ps(\ell, \vpr_h)). 
\end{align*}

Therefore, when $\ps(h, \vpr_h) - \ps(\ell, \vpr_h) > 0$, the condition for the deviation to succeed is $\kd > \frac{\Ex_{\sigi\sim \vpr_{\ell}}[\ps(\sigi, \vpr_{\ell}) - \ps(\sigi, \vpr_{h})]}{\ps(h, \vpr_h) - \ps(\ell, \vpr_h)} \cdot (n-1) + 1$. And when $\ps(h, \vpr_h) - \ps(\ell, \vpr_h) \le 0$, the deviation will never succeed. This is how $\kde^h$ is defined. 

Similarly, for deviation where all deviators always report $\ell$, the condition for the deviation to succeed is $\kd >\frac{\Ex_{\sigi\sim \vpr_{h}}[\ps(\sigi, \vpr_{h}) - \ps(\sigi, \vpr_{\ell})]}{\ps(\ell, \vpr_\ell) - \ps(h, \vpr_\ell)} \cdot (n-1) + 1$ when $\ps(\ell, \vpr_\ell) - \ps(h, \vpr_\ell) > 0$, and the deviation can never succeed when $\ps(\ell, \vpr_\ell) - \ps(h, \vpr_\ell) \le 0$. This is how $\kde^{\ell}$ is defined. 

Also, note that by Lemma~\ref{lem:pr_psr}, at least one of $\ps(h, \vpr_h) - \ps(\ell, \vpr_h) > 0$ and $\ps(\ell, \vpr_\ell) - \ps(h, \vpr_\ell) > 0$ holds. 

Therefore, for all $\kd\le \kde$, both deviations cannot succeed. 

% Therefore, for all $\kd > \frac{\Ex_{\sigi\sim \vpr_{\ell}}[\ps(\sigi, \vpr_{\ell}) - \ps(\sigi, \vpr_{h})]}{\ps(h, \vpr_h) - \ps(\ell, \vpr_h)} \cdot n + 1$, agent $i$ gets higher expected utility in deviation. 
% Since $\kd$ is always an integer. This condition is equivalent to $\kd > \kde$. Therefore, for any $\kd > \kde$, truthful reporting is NOT a $\kde$-strong ex-ante BNE. 
% And for all $\kd\le \kde$, $i$'s expected utility is at most as good as in the truthful profile $\stgp^*$. 

\noindent\textbf{Step 2: Equlibrium holds for $\kd \le \kde.$}

We fix an arbitrary $2\le \kd \le \kde$. (For $\kd = 1$, the ex-ante Bayesian $1$-strong equilibrium is equivalent to BNE, which is guaranteed by the truthfulness of the peer prediction mechanism.) Let $\stgp$ be the deviating strategy and $\stg_i = (\bpl^i, \bph^i)$ be the strategy agent $i$ plays in $\stgp$. $\ut_i(\stgp \mid \jtruthful)$ and $\ut_i(\stgp \mid \jdeviate)$ still denote the expected utility $i$ gain from truthful agents and deviators, respectively. In this part, we consider the average on the expected utility of all agents $i \in D$. Let $\astg = (\abpl, \abph) = \frac{1}{\kd} \sum_{i \in D} \stg_i$ be the average strategy on all deviators. 

For the truthful side, we have 
\begin{align*}
    \ut_i(\stgp \mid \jtruthful) =&\  \frac{1}{n-\kd}\sum_{j \in [n]\setminus D} \Ex_{\sigi_i \sim \prQ
    , \rp_i \sim \stg_i(\sigi_i)} \Ex_{\sigi_j \sim \vpr_{\sigi_i}} \ps(\sigi_j, \vpr_{\rp_i})\\
    =&\ \Ex_{\sigi_i \sim \prQ
    , \rp_i \sim \stg_i(\sigi_i)} \Ex_{\sigi_j \sim \vpr_{\sigi_i}} \ps(\sigi_j, \vpr_{\rp_i})
\end{align*}
Let
\begin{align*}
    \aut(\stgp\mid\jtruthful) =&\ \frac{1}{\kd} \sum_{i \in D}  \ut_i(\stgp\mid\jtruthful)\\
    =&\ \Ex_{\sigi \sim \prQ
    , \rp \sim \astg(\sigi)} \Ex_{\sigi_j \sim \vpr_{\sigi}} \ps(\sigi_j, \vpr_{\rp}). 
\end{align*}
The equation comes from the fact that $\bph^j$ and $\bpl^j$ are linear in the expected utility. Note that when everyone reports truthfully, everyone has equal expected utility, i.e. $\aut(\stgp^*) = \ut_i(\stgp^*)$.  Then the difference between truthful reporting and deviation is a function of $\abpl$ and $\abph$.
\begin{align*}
    &\ \dut_t (\abpl, \abph)\\ =&\ \aut(\stgp^*) - \aut(\stgp \mid \jtruthful)\\
    =&\ \pr(h) \cdot (1 - \abph) \cdot (\pr(h\mid h) \cdot (\ps(h, \vpr_h) - \ps(h, \vpr_{\ell}))  + \pr(\ell \mid h) \cdot (\ps(\ell, \vpr_h) - \ps(\ell, \vpr_\ell)))\\
    &\ +  \pr(\ell) \cdot \abpl \cdot (\pr(h\mid \ell) \cdot (\ps(h, \vpr_\ell) - \ps(h, \vpr_{h})) + \pr(\ell \mid \ell) \cdot (\ps(\ell, \vpr_\ell) - \ps(\ell, \vpr_h))).
\end{align*}
$\dut_t (\abpl, \abph) \ge 0$ and the equation holds when $\abph = 1$ and $\abpl = 0$ is guaranteed by the property of the strict proper scoring rule. 

For the deviator side, we have 
\begin{align*}
    \ut_i(\stgp \mid \jdeviate) =&\  \frac{1}{\kd-1}\sum_{j \in D\setminus\{i\}} \Ex_{\sigi_i \sim \prQ
    , \rp_i \sim \stg_i(\sigi_i)} \Ex_{\sigi_j \sim \vpr_{\sigi_i}, \rp_j \sim \stg_j(\sigi_j)} \ps(\rp_j, \vpr_{\rp_i}).
\end{align*}

And $\aut(\stgp\mid \jdeviate) = \frac{1}{\kd} \sum_{i\in D} \ut_i(\stgp\mid \jdeviate)$. 

To better characterize $\aut(\stgp\mid \jdeviate)$, we find an upper bound parameterized only by $\astg$. Note that
\begin{align*}
    \ut_i(\stgp \mid \jdeviate) =&\  \frac{\kd}{\kd-1} \Ex_{\sigi_i \sim \prQ
    , \rp_i \sim \stg_i(\sigi_i)} \Ex_{\sigi \sim \vpr_{\sigi_i}, \rp \sim \astg(\sigi)} \ps(\rp, \vpr_{\rp_i}) \\
    &\ - \frac{1}{\kd - 1} \Ex_{\sigi_i \sim \prQ
    , \rp_i \sim \stg_i(\sigi_i)} \Ex_{\sigi \sim \vpr_{\sigi_i}, \rp \sim \stg_i(\sigi)} \ps(\rp, \vpr_{\rp_i}).
\end{align*}
The first term can be viewed as adding an independent deviator that plays the same strategy $\stg_i$ as $i$ into the deviator set $D$. Then the average can be represented as 
\begin{align*}
    \aut(\stgp\mid \jdeviate) = &\ \frac{\kd}{\kd - 1} \Ex_{\sigi' \sim \prQ
    , \rp' \sim \astg(\sigi')} \Ex_{\sigi \sim \vpr_{\sigi'}, \rp \sim \astg(\sigi)} \ps(\rp, \vpr_{\rp'})\\
    & - \frac{1}{(\kd - 1)k} \sum_{i \in D} \Ex_{\sigi_i \sim \prQ
    , \rp_i \sim \stg_i(\sigi_i)} \Ex_{\sigi \sim \vpr_{\sigi_i}, \rp \sim \stg_i(\sigi)} \ps(\rp, \vpr_{\rp_i}).
\end{align*}

Let $\func: [0, 1]^2 \to \mathbb{R}$. For a strategy $\stg = (\bpl, \bph)$, let
\begin{equation*}
    \func(\bpl, \bph) = \Ex_{\sigi' \sim \prQ
    , \rp' \sim \stg(\sigi')} \Ex_{\sigi \sim \vpr_{h}, \rp \sim \stg(\sigi)} \ps(\rp, \vpr_{\rp'}). 
\end{equation*}

Then we can represent $ \aut(\stgp\mid \jdeviate)$ in the form of $\func$. 
\begin{equation*}
     \aut(\stgp\mid \jdeviate) = \frac{\kd}{\kd-1} \func(\abpl, \abph) - \frac{1}{(\kd-1)\kd} \sum_{i\in D} \func(\bpl^i, \bph^i). 
\end{equation*}

\begin{claim}
\label{claim:fconvex}
   $\func(\bpl, \bph)$ is convex on $[0, 1]^2$.  
\end{claim}

\begin{proof}
    Note that 
    \begin{align*}
        \frac{\partial^2 \func}{\partial\bpl^2} =&\ 2\pr(\ell) \cdot \pr(\ell \mid \ell) \cdot (\ps(h, \vpr_h) + \ps(\ell, \vpr_{\ell}) - \ps(h, \vpr_{\ell}) - \ps(\ell, \vpr_h)), \\
        \frac{\partial^2 \func}{\partial\bph^2} =&\ 2\pr(h) \cdot \pr(h \mid h) \cdot (\ps(h, \vpr_h) + \ps(\ell, \vpr_{\ell}) - \ps(h, \vpr_{\ell}) - \ps(\ell, \vpr_h)),\\
        \frac{\partial^2 \func}{\partial\bpl \partial\bph} =&\ (\pr(\ell) \cdot \pr(h \mid \ell) + \pr(h)\cdot \pr(\ell \mid h)) (\ps(h, \vpr_h) + \ps(\ell, \vpr_{\ell}) - \ps(h, \vpr_{\ell}) - \ps(\ell, \vpr_h)),\\
        \frac{\partial^2 \func}{\partial\bph \partial\bpl} =&\ (\pr(\ell) \cdot \pr(h \mid \ell) + \pr(h)\cdot \pr(\ell \mid h)) (\ps(h, \vpr_h) + \ps(\ell, \vpr_{\ell}) - \ps(h, \vpr_{\ell}) - \ps(\ell, \vpr_h)).
    \end{align*}
    Let \begin{equation*}
    H = 
        \begin{bmatrix}
            2\pr(\ell) \cdot \pr(\ell \mid \ell) & \pr(\ell) \cdot \pr(h \mid \ell) + \pr(h)\cdot \pr(\ell \mid h)\\
            \pr(\ell) \cdot \pr(h \mid \ell) + \pr(h)\cdot \pr(\ell \mid h) & 2\pr(h) \cdot \pr(h \mid h) 
        \end{bmatrix}. 
    \end{equation*}
        Then the Hermitian matrix of $\func$ is 
    \begin{equation*}
        H(\func) =  (\ps(h, \vpr_h) + \ps(\ell, \vpr_{\ell}) - \ps(h, \vpr_{\ell}) - \ps(\ell, \vpr_h)) \cdot H. 
    \end{equation*}
To show the convexity of $\func$, it is sufficient to show that $H(\func)$ is positive semi-definite. From Lemma~\ref{lem:pr_psr} we know that $(\ps(h, \vpr_h) + \ps(\ell, \vpr_{\ell}) - \ps(h, \vpr_{\ell}) - \ps(\ell, \vpr_h)) > 0$. Therefore, it is sufficient to show that $H$ is positive semidefinite. We leverage the following lemma. 

\begin{lemma}\cite[(7.6.12)]{Meyer2000:Matrix}.
    \label{lem:sylvester}
    A real symmetric matrix $A$ is positive semidefinite if and only if all principal minors of $A$ are non-negative. 
\end{lemma}

Therefore, it is sufficient to show that all principal minors of $H$ are non-negative. 

First, $|H_{1\times 1}| = 2\pr(\ell) \cdot \pr(\ell \mid \ell) > 0$, and $|H_{2\times 2} |= 2\pr(h) \cdot \pr(h \mid h) > 0$. Note that $\pr(\ell)\cdot \pr(h \mid \ell) = \pr(h)\cdot \pr(\ell \mid h)$. Therefore, 
\begin{equation*}
    |H| = 4\pr(h)\cdot \pr(\ell) \cdot (\pr(\ell\mid\ell)\cdot \pr(h\mid h) - \pr(h\mid \ell)\cdot \pr(\ell \mid h)) > 0.
\end{equation*}
Therefore, the Hessian matrix of $\func$ is positive semidefinite. Consequently, $\func$ is convex. 
\end{proof}
By the convexity, $\frac{1}{\kd} \sum_{i\in D} \func(\bpl^i, \bph^i) \ge \func(\abpl, \abph)$. Therefore, $\aut(\stgp\mid \jdeviate) \le \func(\abpl, \abph)$, and the equality holds if all the agents $i\in D$ plays the same strategy. 

We use $\func(\abpl, \abph)$ as an upper bound of $\aut(\stgp\mid \jdeviate)$. Let $\dut_d (\abpl, \abph) = \aut(\stgp^*) - \aut(\stgp\mid \jdeviate)$, and $\dut_d' (\abpl, \abph) = \aut(\stgp^*) - \func(\abpl, \abph)$. Then $\dut_d (\abpl, \abph) \ge \dut_d' (\abpl, \abph)$ always holds. 

Now we are ready to show that truthful reporting $\stgp^*$ is more profitable than any deviation $\stgp$ for $k \le \kde$. 

Let $\dut(\abpl, \abph) = \frac{\kd-1}{\ag -1} \cdot\dut_d' (\abpl, \abph) + \frac{\ag -\kd}{\ag -1} \cdot \dut_t(\abpl, \abph)$. Then it's sufficient to show that $\dut(\abpl, \abph) \ge 0$ on any $(\abpl, \abph) \in [0, 1]^2$. 

First, notice that $\dut(\abpl, \abph)$ is a  concave function. This is because $\dut_t(\abpl, \abph)$ is linear on $\abpl$ and $\abph$, and $\dut_d' (\abpl, \abph)$ is a concave function according to Claim~\ref{claim:fconvex}. Therefore, it is sufficient to show that $\dut(\abpl, \abph) \ge 0$ on any $(\abpl, \abph) \in \{0, 1\}^2$, i.e. the corner points. Note that $\astg = (\abpl, \abph)$ is the average strategy of all the deviators. $\abpl$ ($\abph$, respectively) equals to $0$ (or $1$) means that for all $i\in D$, $\bpl^i$ ($\bph^i$, respectively) equals to $0$ (or $1$, respectively). Therefore, in the corner points, $\dut_d' = \dut_d$. 

When $\abpl = 0$ and $\abph = 1$, $\stgp = \stgp^*$, and all the deviators also report truthfully. In this case, $\dut_t = \dut_d' = 0$ since the two strategies are the same. Therefore, $\dut(0, 1) = 0$. 

When $\abpl = \abph = 1$, all the deviators always report $h$. In Step 1 we have shown that such deviation cannot succeed for any $k \le \kde$. Therefore, $\dut(1, 1) \ge 0$. 

When $\abpl = \abph = 0$, all the deviators always report $\ell$.  In Step 1 we have shown that such deviation cannot succeed for any $k \le \kde$. Therefore, $\dut(0, 0) \ge 0$. 

And when $\abpl = 1$ and $\abph = 0$, all the deviators always tell a lie. We follow a similar reasoning as in step 1. 
First, we have 
\begin{align*}
    \dut_t (1, 0)
    =&\ \pr(h) \cdot (\pr(h\mid h) \cdot (\ps(h, \vpr_h) - \ps(h, \vpr_{\ell}))  + \pr(\ell \mid h) \cdot (\ps(\ell, \vpr_h) - \ps(\ell, \vpr_\ell)))\\
    &\ +  \pr(\ell)  \cdot (\pr(h\mid \ell) \cdot (\ps(h, \vpr_\ell) - \ps(h, \vpr_{h})) + \pr(\ell \mid \ell) \cdot (\ps(\ell, \vpr_\ell) - \ps(\ell, \vpr_h)))\\
    =& \pr(h)\cdot \Ex_{\sigi\sim \vpr_{h}}[\ps(\sigi, \vpr_{h}) - \ps(\sigi, \vpr_{\ell})] + \pr(\ell) \cdot \Ex_{\sigi\sim \vpr_{\ell}}[\ps(\sigi, \vpr_{\ell}) - \ps(\sigi, \vpr_{h})]. 
\end{align*}
$\dut_t(1, 0) \ge 0$ is guaranteed by the property of the proper scoring rule.

And 
\begin{align*}
    &\ \dut_t(1, 0) - \dut_d'(1, 0)\\
    =&\ \pr(h) \cdot (\pr(h\mid h) \cdot (\ps(\ell, \vpr_\ell) - \ps(h, \vpr_{\ell}))  + \pr(\ell \mid h) \cdot (\ps(h, \vpr_\ell) - \ps(\ell, \vpr_\ell)))\\
    &\ +  \pr(\ell)  \cdot (\pr(h\mid \ell) \cdot (\ps(\ell, \vpr_h) - \ps(h, \vpr_{h})) + \pr(\ell \mid \ell) \cdot (\ps(h, \vpr_h) - \ps(\ell, \vpr_h)))\\
    =&\ \pr(h)\cdot (\pr(h\mid h) - \pr(\ell \mid h)) \cdot (\ps(\ell, \vpr_\ell) - \ps(h, \vpr_{\ell}))\\
    &\ + \pr(\ell) \cdot (\pr(\ell\mid \ell) - \pr(h\mid \ell))\cdot (\ps(h, \vpr_h) - \ps(\ell, \vpr_h))).
\end{align*}

If $\dut_t(1, 0) - \dut_d'(1, 0) \le 0$, $\dut(1, 0)\ge 0$ for every $k$. If $\dut_t(1, 0) - \dut_d'(1, 0) > 0$, $\dut(1, 0) < 0$ if and only if 
\begin{smallblock}
\begin{equation*}
      \kd > \frac{\pr(h)\cdot \Ex_{\sigi\sim \vpr_{h}}[\ps(\sigi, \vpr_{h}) - \ps(\sigi, \vpr_{\ell})] + \pr(\ell) \cdot \Ex_{\sigi\sim \vpr_{\ell}}[\ps(\sigi, \vpr_{\ell}) - \ps(\sigi, \vpr_{h})]}{\pr(h)\cdot (\pr(h\mid h) - \pr(\ell \mid h)) \cdot (\ps(\ell, \vpr_\ell) - \ps(h, \vpr_{\ell})) +  \pr(\ell) \cdot (\pr(\ell\mid \ell) - \pr(h\mid \ell))\cdot (\ps(h, \vpr_h) - \ps(\ell, \vpr_h))} + 1.   
\end{equation*}

\end{smallblock}
    
Denote this threshold as $\kd'$. We claim that $\kd' \ge \kde$, and therefore $\dut(1, 0) \ge 0$ for all $\kd \le \kde$. 
We consider the following three cases. 
\begin{enumerate}
    \item $\ps(\ell, \vpr_\ell) - \ps(h, \vpr_{\ell}) > 0$ and $\ps(h, \vpr_h) - \ps(\ell, \vpr_h) > 0$. In this case, $\kd'$ is between $\kde^h$ and $\kde^{\ell}$, and cannot be smaller than $\kde$. 
    \item  $\ps(\ell, \vpr_\ell) - \ps(h, \vpr_{\ell}) \le 0$ but $\ps(h, \vpr_h) - \ps(\ell, \vpr_h) > 0$. 
    If $\pr(h\mid h) \ge \pr(\ell \mid h)$, the first term in the denominator is non-positive, and it's not hard to verify that $\kd' > \kde$. If $\pr(h\mid h) < \pr(\ell \mid h)$, note that we have $\ps(h, \vpr_h) > \ps(h, \vpr_{\ell}) \ge \ps(\ell, \vpr_\ell) > \ps(\ell, \vpr_h)$ according to Lemma~\ref{lem:pr_psr}.
    Therefore, the denominator is no more than $(\pr(\ell)\cdot \pr(\ell \mid \ell) - \pr(h)\cdot \pr(h\mid h))\cdot \ps(h, \vpr_h) - \ps(\ell, \vpr_h))$, which is smaller than $\pr(\ell)$ times the denominator in the $\kde^h$. On the other hand, the nominator in $\kd'$ is larger than $\pr(\ell)$ times the nominator in $\kde$. Therefore, $\kd' \ge \kde$. 
    \item $\ps(\ell, \vpr_\ell) - \ps(h, \vpr_{\ell}) > 0$ but $\ps(h, \vpr_h) - \ps(\ell, \vpr_h) \le 0$. This case follows the second case due to symmetricity. 
\end{enumerate}
Therefore, $\dut(1, 0) \ge 0$ for all $\kd \le \kde$.

% $\dut_t(1, 0) \ge 0$ is guaranteed by the property of the proper scoring rule.  We show that $\dut_d'(1, 0) \ge 0$. 
% \begin{align*}
%     \dut_d'(1, 0) = &\ \aut(\stgp^*) - \func(1, 0)\\
%     =&\pr(h) \cdot(\pr(h \mid h) \cdot (\ps(h, \vpr_h) - \ps(\ell, \vpr_{\ell})) + \pr(\ell \mid h) \cdot (\pr(\ell, \vpr_h) - \pr(h, \vpr_{\ell}))\\
%     &\ + \pr(\ell) \cdot(\pr(h \mid \ell) \cdot (\ps(h, \vpr_\ell) - \ps(\ell, \vpr_h)) + \pr(\ell \mid \ell) \cdot (\pr(\ell, \vpr_\ell) - \pr(h, \vpr_h)))\\
%     =&\ (\pr(h) \cdot \pr(h\mid h) - \pr(\ell)\cdot \pr(\ell\mid\ell))\cdot (\ps(h, \vpr_h) - \ps(\ell, \vpr_{\ell})).
% \end{align*}
% From Lemma~\ref{lem:pr_psr}, we know that $\pr(h\mid h) \ge \pr(\ell\mid\ell)$. And from the assumption, we know that $\pr(h) \ge \pr(\ell)$ and $\ps(h, \vpr_h) \ge \ps(\ell, \vpr_{\ell})$. Therefore, $\dut_d'(1, 0) \ge 0$, which implies $\dut(1, 0)\ge 0$.

Therefore, we prove that for any $k\le \kde$ and any strategy profile, the average (ex-ante) expected utility of the deviators will not exceed the expected utility when all the agents report truthfully. Therefore, one of the following cases occurs. 
\begin{enumerate}
    \item There exists an agent $i$ such that $i$'s expected utility in deviation is strictly lower than in $\stgp^*$. Therefore, the second condition of the deviating group is violated. 
    \item All the agents have exactly the same expected utility in deviation and $\stgp^*$. The third condition of a deviating group to have an agent strictly better off is violated. 
\end{enumerate}
Therefore, any deviation cannot succeed, and truth-telling $\stgp^*$ is an ex-ante Bayesian $\kde$-strong equilibrium. 

\section{Proof of Theorem~\ref{thm:pp_qi}}
\label{apx:qi}
The steps of the proof resemble the steps of the proof of Theorem~\ref{thm:pp_exante}, yet the techniques are different. In Step 1, we determine $\kdq$ by comparing the \qi{} expected utility of a deviator conditioned on his/her signal being $h$ and $\ell$ respectively when every agent reports truthfully and when all $\kd$ deviators always report $h$ (and always report $\ell$, respectively).
In Step 2, we show that for any $\kd \le \kde$ and any deviating strategy profile $\astgp$ where all the deviators play the same strategy $\astg$, the average expected utility among all the deviators when $\astgp$ is played will not exceed the expected utility when every agent reports truthfully. In Step 3, we show that for sufficiently large $\ag$, any $\kd \le \kdq$, and any deviating strategy profile $\stgp$, there exists a deviator whose expected utility is strictly smaller than the expected utility when every agent reports truthfully.

Let $\maxdps$ be the largest difference in the positional scoring rule. Let $\dpsh = \ps(h, \vpr_h) - \ps(h, \vpr_\ell)$, and $\dpsl = \ps(\ell, \vpr_{\ell}) - \pr(\ell, \vpr_h)$. From Lemma~\ref{lem:pr_psr}, we have $\dpsh > 0$ and $\dpsl > 0$. We first explicitly give the lower bound of $\ag$:

\begin{enumerate}
    \item $\bphth = \frac{4\maxdps\cdot (\dpsh + \dpsl + \ps(\ell, \vpr_{\ell}) - \ps(h, \vpr_\ell))}{ (\ag - 1)\cdot (\dpsh +\dpsl)\cdot  \Ex_{\sigi \sim \vpr_h}[\ps(\sigi, \vpr_h) - \pr(\sigi, \vpr_\ell)]} < \frac14$, 
    \item If $\ps(h, \vpr_h) > \ps(\ell, \vpr_h)$, then $\bphth \le \frac{\ps(h, \vpr_h) - \ps(\ell, \vpr_h)}{\dpsh + \dpsl}$, 
    \item $\bphth \le \frac{\Ex_{\sigi \sim \vpr_h}[\ps(\sigi, \vpr_h) - \pr(\sigi, \vpr_\ell)]}{\pr(h\mid h)\cdot (\dpsh + \dpsl)}$,
    \item $\bphtl = \frac{4\maxdps\cdot (\dpsh + \dpsl + \ps(h, \vpr_{h}) - \ps(\ell, \vpr_h))}{ (\ag - 1)\cdot (\dpsh +\dpsl)\cdot  \Ex_{\sigi \sim \vpr_\ell}[\ps(\sigi, \vpr_\ell) - \pr(\sigi, \vpr_h)]} < \frac14$, 
    \item If $\ps(\ell, \vpr_{\ell}) > \ps(h, \vpr_\ell)$, then $\bphth \le \frac{\ps(\ell, \vpr_{\ell}) - \ps(h, \vpr_\ell)}{\dpsh + \dpsl}$, 
    \item $\bphth \le \frac{\Ex_{\sigi \sim \vpr_\ell}[\ps(\sigi, \vpr_\ell) - \pr(\sigi, \vpr_h)]}{\pr(\ell \mid \ell)\cdot (\dpsh + \dpsl)}$.
\end{enumerate}

    \noindent\textbf{Step 1: characterizing $\kdq$.}
    
    Consider a deviating group $D$ of $k$ agents. In the deviating strategy profile $\stgp$, all the deviators always report $h$, i.e. $\stg = (1, 1)$. We fix an arbitrary deviator $i \in D$. In the \qi{} setting, the condition for the deviation is successful is $\ut_i(\stgp\mid h) \ge \ut_i(\stgp^*\mid h)$ and $\ut_i(\stgp\mid \ell) \ge \ut_i(\stgp^*\mid \ell)$ hold, and at least one of the inequality is strict. 

    Similar to the ex-ante's proof, let $\ut_i(\stgp\mid \sigi_i, \jdeviate)$ $\ut_i(\stgp\mid \sigi_i, \jtruthful)$ be the average expected utility from all other deviators (truthful agents, respectively) conditioned on $i$'s signal being $\sigi_i$. And let $\dut_{d\mid \sigi_i} = \ut_i(\stgp^* \mid \sigi_i) - \ut_i(\stgp\mid \sigi_i, \jdeviate)$ and $\dut_{t\mid \sigi_i} = \ut_i(\stgp^* \mid \sigi_i) - \ut_i(\stgp\mid \sigi_i, \jtruthful)$. 

    For expected utility on $\stgp^*$, we have
\begin{align*}
    \ut_i(\stgp^* \mid h) = &\ \pr(h \mid h) \cdot \ps(h, \vpr_h) + \pr(\ell \mid h) \cdot \ps(\ell, \vpr_h),\\
    \ut_i(\stgp^* \mid \ell) = &\ \pr(h \mid \ell) \cdot \ps(h, \vpr_\ell) + \pr(\ell \mid \ell) \cdot \ps(\ell, \vpr_\ell). 
\end{align*}
    And for expected utility of $\stgp$, we have 
\begin{align*}
    \ut_i(\stgp\mid h, \jtruthful) = &\ \pr(h \mid h) \cdot \ps(h, \vpr_h) + \pr(\ell \mid h) \cdot \ps(\ell, \vpr_h)\\
     \ut_i(\stgp\mid \ell, \jtruthful) =&\ \pr(h \mid \ell) \cdot \ps(h, \vpr_h) + \pr(\ell \mid \ell) \cdot \ps(\ell, \vpr_h). 
\end{align*}
Therefore, $\ut_i(\stgp^* \mid h) = \ut_i(\stgp\mid h, \jtruthful)$, and $\dut_{t\mid h} = 0$. Also for the $\ell$ side, $\dut_{t\mid \ell} = \Ex_{\sigi\sim \vpr_{\ell}}[\ps(\sigi, \vpr_{\ell}) - \ps(\sigi, \vpr_{h})] > 0$. 

For the deviator's part, we have $\ut_i(\stgp\mid h, \jdeviate) = \ut_i(\stgp\mid \ell, \jdeviate) = \ps(h, \vpr_h)$. 

Then we have 
\begin{align*}
    \dut_{t\mid h} - \dut_{d\mid h} =&\ \pr(\ell \mid h) \cdot (\ps(h, \vpr_h) - \ps(\ell, \vpr_h)).\\
    \dut_{t\mid \ell} - \dut_{d\mid \ell} =&\ \pr(\ell \mid \ell) \cdot (\ps(h, \vpr_h) - \ps(\ell, \vpr_h)).
\end{align*}

When $\ps(h, \vpr_h) \le  \ps(\ell, \vpr_h)$, neither agents with private signal $h$ nor those with $\ell$ can get strictly positive expected utility via deviation, and the deviation cannot succeed. When $\ps(h, \vpr_h) >  \ps(\ell, \vpr_h)$, for the $h$ side, the condition for deviation to achieve non-negative expected utility (not strictly positive!) is
\begin{equation*}
    k \ge \frac{\dut_{t\mid h}}{\dut_{t\mid h} - \dut_{d\mid h}}\cdot (n-1) + 1 = 1,
\end{equation*}
and for the $\ell$ side, the condition is
\begin{equation*}
    k \ge \frac{\dut_{t\mid \ell}}{\dut_{t\mid \ell} - \dut_{d\mid \ell}}\cdot (n-1) + 1 = \frac{\Ex_{\sigi\sim \vpr_{\ell}}[\ps(\sigi, \vpr_{\ell}) - \ps(\sigi, \vpr_{h})]}{ \pr(\ell \mid \ell) \cdot (\ps(h, \vpr_h) - \ps(\ell, \vpr_h))}\cdot (n-1) + 1 > 1.
\end{equation*}

When $k \ge \frac{\Ex_{\sigi\sim \vpr_{\ell}}[\ps(\sigi, \vpr_{\ell}) - \ps(\sigi, \vpr_{h})]}{ \pr(\ell \mid \ell) \cdot (\ps(h, \vpr_h) - \ps(\ell, \vpr_h))}\cdot (n-1) + 1$, deviators with signal $h$ get strictly higher expected utility, and deviators with $\ell$ get non-decreasing expected utility. Therefore, the deviation will succeed. 
This is how $\kdq^h$ is defined.
$\kdq^\ell$ is defined similarly by consider strategy $(0, 0)$. 
Therefore, for all $k \le \kdq$, both deviations of always reporting $h$ and always reporting $\ell$ cannot succeed.

\noindent\textbf{Step 2: Symmetric deviaton cannot succeed for $\kd \le \kdq.$}

We first introduce a function that will be widely applied in Step 2 and 3. Let $\func^h(\bph', (\bpl, \bph)): \mathbb{R} \times \mathbb{R}^2 \to \mathbb{R}$ be the expected reward of an agent $i$ who has signal $h$ and will report $h$ with probability $\bph'$, given that $i$'s peer $j$ plays the strategy $\stg = (\bpl, \bph)$. 

\begin{align*}
    \func^h(\bph', (\bpl, \bph)) = &\ \Ex_{\rp_i \sim \bph'} \Ex_{\sigi_j \sim \vpr_{h}, \rp_j \sim (\bpl,\bph)} \ps(\rp_j, \vpr_{\rp_i})\\
    =&\ \bph'((\pr(h\mid h)\cdot \bph + \pr(\ell\mid h)\cdot \beta_\ell)\cdot \ps(h, \vpr_h)\\
    &\ + (1 -  \pr(h\mid h)\cdot \bph - \pr(\ell\mid h)\cdot \beta_\ell)\cdot \ps(\ell,\vpr_h))\\
     + &\ (1 - \bph')\cdot ((\pr(h\mid h)\cdot \bph + \pr(\ell\mid h)\cdot \beta_\ell)\cdot \ps(h, \vpr_\ell)\\
    &\ + (1 -  \pr(h\mid h)\cdot \bph - \pr(\ell\mid h)\cdot \beta_\ell)\cdot \ps(\ell,\vpr_\ell)). 
\end{align*}

Similarly, we define $\func^{\ell}$. 
\begin{align*}
    \func^\ell(\bpl', (\bpl, \bph)) = &\ \Ex_{\rp_i \sim \bpl'} \Ex_{\sigi_j \sim \vpr_{\ell}, \rp_j \sim (\bpl,\bph)} \ps(\rp_j, \vpr_{\rp_i})\\
    =&\ \bpl'((\pr(h\mid \ell)\cdot \bph + \pr(\ell\mid \ell)\cdot \beta_\ell)\cdot \ps(h, \vpr_h)\\
     + &\ (1 -  \pr(h\mid \ell)\cdot \bph - \pr(\ell\mid \ell)\cdot \beta_\ell)\cdot \ps(\ell,\vpr_h))\\
    &\ + (1 - \bpl')\cdot ((\pr(h\mid \ell)\cdot \bph + \pr(\ell\mid \ell)\cdot \beta_\ell)\cdot \ps(h, \vpr_\ell)\\
    &\ + (1 -  \pr(h\mid \ell)\cdot \bph - \pr(\ell\mid \ell)\cdot \beta_\ell)\cdot \ps(\ell,\vpr_\ell)). 
\end{align*}

Moreover, let $\gunc^h(\bpl, \bph) = \func^h(\bph, (\bpl, \bph))$, and $\gunc^\ell(\bpl, \bph) = \func^\ell(\bpl, (\bpl, \bph))$. $\gunc^h$ and $\gunc^\ell$ cover the special case where $i$ and $j$ play the same strategy and will be largely applied in Step 2. 

\begin{claim}
We claim that $\func^h$ and $\gunc^h$ has the following properties. 
    \begin{enumerate}
        \item $\frac{\partial^2\gunc^h}{\partial \bph^2} = 2\pr(h\mid h)\cdot (\ps(h, \vpr_h) - \ps(h, \vpr_\ell) - \ps(\ell,\vpr_h) + \ps(\ell, \vpr_\ell)) > 0$. 
        \item $\frac{\partial^2\gunc^h}{\partial \bpl^2} = 0$. 
        \item Let $\alpha_h = \frac{\pr(h\mid h)}{\pr(\ell \mid h)}$, and let $b_h \ge 0$ be a constant. When fixing $\bpl = \alpha_h \cdot (b_h - \bph)$, then 
        \begin{align*}
            &\ \frac{\partial\gunc^h(\alpha_h(b_h - \bph), \bph)}{\partial \bph} = \frac{\partial\func^h(\bph', (\alpha_h(b_h - \bph), \bph))}{\partial \bph'}\\ =&\ b_h\cdot \pr(h\mid h) (\ps(h, \vpr_h) - \ps(h, \vpr_\ell)) + (1 - b_h\cdot \pr(h\mid h))(\ps(\ell, \vpr_h) - \ps(\ell, \vpr_\ell)). 
        \end{align*}
        Specifically, when $b_h=1$, $\frac{\partial\func^h(\bph', (\alpha_h(b_h - \bph), \bph))}{\partial \bph'} = \Ex_{\sigi\sim \vpr_{h}}[\ps(\sigi, \vpr_{h}) - \ps(\sigi, \vpr_{\ell})] > 0$.
    \end{enumerate}
\end{claim}

\begin{claim}
We claim that $\func^\ell$ and $\gunc^\ell$ has the following properties. 
    \begin{enumerate}
        \item $\frac{\partial^2\gunc^\ell}{\partial \bpl^2} = 2\pr(\ell\mid \ell)\cdot (\ps(h, \vpr_h) - \ps(h, \vpr_\ell) - \ps(\ell,\vpr_h) + \ps(\ell, \vpr_\ell)) > 0$. 
        \item $\frac{\partial^2\gunc^\ell}{\partial \bph^2} = 0$. 
        \item Let $\alpha_\ell = \frac{\pr(\ell \mid \ell)}{\pr(h \mid \ell)}$, and let $b_\ell \ge 0$ be a constant. When fixing $\bph = (b_\ell - \alpha_\ell 
 \cdot\bpl)$, then 
        \begin{align*}
        &\ \frac{\partial\gunc^\ell(\bpl, (b_\ell - \alpha_\ell 
        \cdot\bpl))}{\partial \bpl}= \frac{\partial\func^\ell(\bpl', (\bpl, (b_\ell - \alpha_\ell 
        \cdot\bpl)))}{\partial \bpl'}\\ =& b_\ell \cdot \pr(h\mid \ell)(\ps(h, \vpr_h) - \ps(h, \vpr_\ell)) + (1 - b_\ell \cdot \pr(h\mid \ell)) (\ps(\ell, \vpr_h) - \ps(\ell, \vpr_\ell)). 
        \end{align*}
        Specifically, when $b_\ell =1$, $\frac{\partial\func^\ell(\bpl', (\bpl, (b_\ell - \alpha_\ell 
 \cdot\bpl)))}{\partial \bpl'} = \Ex_{\sigi\sim \vpr_{\ell}}[\ps(\sigi, \vpr_{h}) - \ps(\sigi, \vpr_{\ell})] < 0$.
    \end{enumerate}
\end{claim}

Now we start to characterize the deviation.
We fix an arbitrary $\kd$. Let $\astg = (\abpl, \abph)$ be the strategy on all deviators. Since all the deviators play the same strategy, they receive the same expected utility conditioned on the same signal. 

The expected utility of deviator with private signal $h$ conditioned on his/her peer $j$ is a truthful agent is $\ut(\abpl, \abph \mid h, \jtruthful) = \func^h(\abph, (0, 1))$, and that conditioned on $j$ is also a deviator is $\ut(\abpl, \abph \mid h, \jdeviate) = \func^h(\abph, (\abpl, \abph)) = \gunc^h(\abpl, \abph)$. Similarly, for the $\ell$ side we have $\ut(\abpl, \abph \mid \ell, \jtruthful) = \func^\ell(\abpl, (0, 1))$ and $\ut(\abpl, \abph \mid \ell, \jdeviate) = \func^\ell(\abpl, (\abpl, \abph)) = \gunc^l(\abpl, \abph)$. Therefore, the expected reward of deviation can be represented by the following function. 
\begin{align*}
    \ut(\abpl, \abph \mid h) = \frac{\ag-\kd}{\ag - 1} \cdot \ut(\abpl, \abph \mid h, \jtruthful) + \frac{\kd - 1}{\ag - 1} \cdot \ut(\abpl, \abph \mid h, \jdeviate),\\
     \ut(\abpl, \abph \mid \ell) =  \frac{\ag-\kd}{\ag - 1} \cdot \ut(\abpl, \abph \mid \ell, \jtruthful) + \frac{\kd - 1}{\ag - 1} \cdot \ut(\abpl, \abph \mid \ell, \jdeviate).
\end{align*}

Now we show that for any $\astg = (\abpl, \abph) \in [0, 1]^2$, either $ \ut(\abpl, \abph \mid h) \le \ut(\stgp^* \mid h)$ or $ \ut(\abpl, \abph \mid \ell) \le \ut(\stgp^* \mid \ell)$. 

\begin{lemnb}{lem:subspace_h}
    For any $(\abpl, \abph) \in \mathbb{R}^2$ satisfying (1) $\abpl \ge 0$, (2) $\abph \ge 0$, and (3) $\abph + \frac{\pr(\ell \mid h)}{\pr (h \mid h)}\cdot \abpl \le 1$, it always holds that $ \ut(\abpl, \abph \mid h) \le \ut(\stgp^* \mid h)$, and the equality holds only when $\abpl = 0$ and $\abph = 1$. 
\end{lemnb}

\begin{proof}[Proof of Lemma~\ref{lem:subspace_h}]
    The proof proceeds in three steps. 
    
    First, we show that $\ut(0, \abph \mid h) \le \ut(\stgp^* \mid h)$ for any $\abph$. This holds for the following three reasons. First, $\ut(0, 1 \mid h) =  \ut(\stgp^* \mid h)$, as in this case all the deviators report truthfully and no deviation happens. Second, $\ut(0, 0 \mid h) < \ut(\stgp^* \mid h)$ is guaranteed by $\kd \le \kdq$. Finally, since $\ut(\abpl, \abph \mid h, \jtruthful)$ is linear and $\ut(\abpl, \abph \mid h, \jdeviate)$ is strictly convex on $\abph$, $\ut(0, \abph \mid h)$ is also convex on $\abph$. The convexity bound the expected utility for every $0 < \abph < 1$. 

    Second, we show that $\ut(\abpl, \abph \mid h) \le \ut(\stgp^* \mid h)$ when $\abpl = \frac{\pr(h\mid h)}{\pr(\ell \mid h)}(1 - \abph)$ for any $\abph \in [0, 1]$. This is because the derivative 
    \begin{align*}
        \frac{\partial \ut(\frac{\pr(h\mid h)}{\pr(\ell \mid h)}(1 - \abph), \abph \mid h)}{\partial \abph} =&\  \frac{\ag-\kd}{\ag - 1} \cdot \frac{\partial \func^h(\abph, (0, 1))}{\partial \abph} + \frac{\kd - 1}{\ag - 1} \cdot \frac{\partial \gunc^h(\frac{\pr(h\mid h)}{\pr(\ell \mid h)}(1 - \abph), \abph))}{\partial \abph}\\
        =&\ \Ex_{\sigi\sim \vpr_{h}}[\ps(\sigi, \vpr_{h}) - \ps(\sigi, \vpr_{\ell})]\\
        > &\ 0.
    \end{align*}
    Therefore, For any $(\abpl, \abph)$ with $\abph < 1$ and $\abpl = \frac{\pr(h\mid h)}{\pr(\ell \mid h)}(1 - \abph)$, $\ut(\abpl, \abph \mid h) < \ut(0, 1 \mid h) = \ut(\stgp^* \mid h)$.

    Finally, we extend the result to any $(\abpl, \abph)$ in the area. For any $\abph \in [0, 1)$, we have shown that  $\ut(0, \abph \mid h) \le \ut(\stgp^*\mid h)$ and $\ut(\frac{\pr(h\mid h)}{\pr(\ell \mid h)}(1 - \abph), \abph \mid h) < \ut(\stgp^*\mid h)$. Then by the linearity of $\ut(\abpl, \abph \mid h)$ on $\abpl$, $\ut(\abpl, \abph \mid h) < \ut(\stgp^* \mid h)$ for any $\abpl \in (0, \frac{\pr(h\mid h)}{\pr(\ell \mid h)}(1 - \abph))$, which finishes the proof. 
\end{proof}

Similarly, for $\ell$ side, we have 

% \begin{lemnb}{lem:subspace_l}
%     For any $(\abpl, \abph) \in \mathbb{R}^2$ satisfying (1) $\abpl \le 1$, (2) $\abph \le 1$, and (3) $\abph + \frac{\pr(\ell \mid \ell)}{\pr (h \mid \ell)}\cdot \abpl \ge 1$, it always holds that $ \ut(\abpl, \abph \mid \ell) \le \ut(\stgp^*\mid \ell )$, and the equality holds only when $\abpl = 0$ and $\abph = 1$. 
% \end{lemnb}

\begin{lemnb}{lem:subspace_l}
    For any $(\abpl, \abph) \in \mathbb{R}^2$ satisfying (1) $\abpl \le 1$, (2) $\abph \le 1$, and (3) $\abph + \frac{\pr(\ell \mid \ell)}{\pr (h \mid \ell)}\cdot \abpl \ge 1$, it always holds that $ \ut(\abpl, \abph \mid \ell) \le \ut(\stgp^*\mid \ell )$, and the equality holds only when $\abpl = 0$ and $\abph = 1$. 
\end{lemnb}

\begin{proof}[Proof of Lemma~\ref{lem:subspace_l}]
    The proof follows the proof of Lemma~\ref{lem:subspace_h}. First, $\ut(\abpl, 1 \mid \ell) < \ut(\stgp^* \mid \ell)$ for any $\abpl \in [0, 1]$ due to the convexity of $\ut(\abpl, \abph \mid \ell)$ on $\abpl$. Secondly, $\ut(\abpl, \abph \mid \ell) < \ut(\stgp^* \mid \ell)$ when $\abph + \frac{\pr(\ell \mid \ell)}{\pr (h \mid \ell)}\cdot \abpl = 1$ and $\abpl > 0$, the derivative 
    \begin{align*}
        \frac{\partial \ut(\abpl, 1 - \frac{\pr(\ell \mid \ell)}{\pr (h \mid \ell)}\cdot \abpl \mid \ell)}{\partial \abpl} =&\  \frac{\ag-\kd}{\ag - 1} \cdot \frac{\partial \func^\ell(\abpl, (0, 1))}{\partial \abpl} + \frac{\kd - 1}{\ag - 1} \cdot \frac{\partial \gunc^\ell(\abpl, 1 - \frac{\pr(\ell \mid \ell)}{\pr (h \mid \ell)}\cdot \abpl)}{\partial \abpl}\\
        =&\ \Ex_{\sigi\sim \vpr_{\ell}}[\ps(\sigi, \vpr_{h}) - \ps(\sigi, \vpr_{\ell})]\\
        < &\ 0.
    \end{align*}
    Therefore, for any $\abpl\ge 0$ on the line, the expected reward does not exceed $\ut(\stgp^* \mid \ell)$. Finally, for any other $(\abpl, \abph)$ in the area, we apply the linearity of $\ut(\abpl, \abph \mid \ell)$ on $\abph$. 
\end{proof}

Note that for any pair of $(\abpl, \abph) \in [0, 1]^2$, at least one of $\abph + \frac{\pr(\ell \mid h)}{\pr (h \mid h)}\cdot \abpl \le 1$ and $\abph + \frac{\pr(\ell \mid \ell)}{\pr (h \mid \ell)}\cdot \abpl \ge 1$ holds. This comes from $\pr(h\mid h) > \pr(h \mid \ell)$ and $\pr(\ell \mid \ell) > \pr(\ell \mid h)$. Therefore, the two triangle areas cover the whole $[0, 1]^2$, and we can apply either Lemma~\ref{lem:subspace_h} or~\ref{lem:subspace_l} to show that the deviation cannot succeed for any $\astgp$. 

\noindent{\bf Step 3: General deviation cannot succeed for $\kd \le \kdq$. }

Let $\maxdps$ be the largest difference in the positional scoring rule. Let $\dpsh = \ps(h, \vpr_h) - \ps(h, \vpr_\ell)$, and $\dpsl = \ps(\ell, \vpr_{\ell}) - \pr(\ell, \vpr_h)$. From Lemma~\ref{lem:pr_psr}, we have $\dpsh > 0$ and $\dpsl > 0$. Then we explicitly give the lower bound of $\ag$:

\begin{enumerate}
    \item $\bphth = \frac{4\maxdps\cdot (\dpsh + \dpsl + \ps(\ell, \vpr_{\ell}) - \ps(h, \vpr_\ell))}{ (\ag - 1)\cdot (\dpsh +\dpsl)\cdot  \Ex_{\sigi \sim \vpr_h}[\ps(\sigi, \vpr_h) - \pr(\sigi, \vpr_\ell)]} < \frac14$, 
    \item If $\ps(h, \vpr_h) > \ps(\ell, \vpr_h)$, then $\bphth \le \frac{\ps(h, \vpr_h) - \ps(\ell, \vpr_h)}{\dpsh + \dpsl}$, 
    \item $\bphth \le \frac{\Ex_{\sigi \sim \vpr_h}[\ps(\sigi, \vpr_h) - \pr(\sigi, \vpr_\ell)]}{\pr(h\mid h)\cdot (\dpsh + \dpsl)}$,
    \item $\bphtl = \frac{4\maxdps\cdot (\dpsh + \dpsl + \ps(h, \vpr_{h}) - \ps(\ell, \vpr_h))}{ (\ag - 1)\cdot (\dpsh +\dpsl)\cdot  \Ex_{\sigi \sim \vpr_\ell}[\ps(\sigi, \vpr_\ell) - \pr(\sigi, \vpr_h)]} < \frac14$, 
    \item If $\ps(\ell, \vpr_{\ell}) > \ps(h, \vpr_\ell)$, then $\bphth \le \frac{\ps(\ell, \vpr_{\ell}) - \ps(h, \vpr_\ell)}{\dpsh + \dpsl}$, 
    \item $\bphth \le \frac{\Ex_{\sigi \sim \vpr_\ell}[\ps(\sigi, \vpr_\ell) - \pr(\sigi, \vpr_h)]}{\pr(\ell \mid \ell)\cdot (\dpsh + \dpsl)}$.
\end{enumerate}


Step 3 proceeds as follows. First, when deviators play asymmetrically, we compare the worst expected utility among the agent with the expected utility when all deviators play their "average" strategy $\astg = \sum_{i\in D} \frac{1}{k} \stg_i$. We show that the reward of the worst agent cannot be better than the reward of the average strategy by $O (\frac{\maxdps}{n - 1})$. Then we show that the reward of the average strategy is no less than the truthful reward by $\Theta (\frac{\maxdps}{n - 1})$ only when $\astg$ is close to $(0, 1)$ or $(0, 0)$. Finally, we deal with the corner cases and show that in this case, the worst agent cannot be better than the truthful reward. We will give the proof on the $h$ side (or specifically, conditioned on an agent having private signal $h$). The $\ell$ side follows similar reasoning. 

Now let $\astg = (\abpl, \abph)$ be the {\em average strategy} of all the deviators, i.e. $\astg = \frac{1}{k} \sum_{j\in D} \stg_j$. And $\stg_i = (\bpl^i, \bph^i)$ be the strategy of a deviator $i\in D$. We represent the expected utility of $i$ with $\func^h$, $\func^\ell$, $\gunc^h$, and $\gunc^\ell$. 

The expected utility of $i$ conditioned on his/her peer $j$ is a truthful agent is $\ut(\bpl^i, \bph^i \mid h, \jtruthful) = \func^h(\bph^i, (0, 1))$. and that conditioned on $j$ is also a deviator is 

\begin{align*}
    \ut(\bpl^i, \bph^i \mid h, \jdeviate) = \frac{1}{\kd - 1} \sum_{j \in D, j\neq i} f(\bph^i, (\bpl^j, \bph^j)). 
\end{align*}

An important observation is that for a fixed $\bph'$, $\func^h(\bph', (\bpl, \bph))$ is linear on $\bpl$ and $\bph$. Therefore, 

\begin{align*}
    \ut(\bpl^i, \bph^i \mid h, \jdeviate) =&\ \frac{\kd}{\kd - 1} f(\bph^i, (\abpl, \abph)) - \frac{1}{\kd-1} f(\bph^i, (\bpl^i, \bph^i))\\
    =&\ f(\bph^i, (\abpl, \abph)) + \frac{1}{\kd-1} (f(\bph^i, (\abpl, \abph)) - f(\bph^i, (\bpl^i, \bph^i))).
\end{align*}

Adding two parts together, we have
\begin{align*}
    \ut(\bpl^i, \bph^i \mid h) = \frac{\ag-\kd}{\ag - 1} \cdot \ut(\bpl^i, \bph^i \mid h, \jtruthful) + \frac{\kd - 1}{\ag - 1} \cdot \ut(\bpl^i, \bph^i \mid h, \jdeviate).
\end{align*}

Then we consider the difference of agent $i$'s utility between when all the deviators play the average strategy $\astg$ and when the deviators play differently with $i$ playing $\stg_i$. 

\begin{align*}
    \ut(\bpl^i, \bph^i \mid h) - \ut(\abpl, \abph \mid h) = &\frac{\ag-\kd}{\ag - 1} \cdot (\func^h(\bph^i, (0, 1)) - \func^h(\abph, (0, 1))) \\
    &\ + \frac{\kd - 1}{\ag - 1} (f(\bph^i, (\abpl, \abph)) - f(\abph, (\abpl, \abph)))\\
    &\ +\frac{\kd - 1}{\ag - 1} \cdot \frac{1}{\kd-1} (f(\bph^i, (\abpl, \abph)) - f(\bph^i, (\bpl^i, \bph^i)))\\
    =&\ \frac{\ag-\kd}{\ag - 1} \cdot \func^h(\bph^i - \abph, (0, 1)) + \frac{\kd - 1}{\ag - 1} f(\bph^i - \abph, (\abpl, \abph))\\
    &\ +\frac{1}{\ag-1} (f(\bph^i, (\abpl, \abph)) - f(\bph^i, (\bpl^i, \bph^i))).
\end{align*}
The second equality comes from the fact that $\func^h(\bph', (\bpl, \bph))$ is linear on $\bph'$ for any fixed $(\bpl, \bph)$. Given a fixed $\astg = (\abpl, \abph)$, the term
$$\frac{\ag-\kd}{\ag - 1} \cdot \func^h(\bph^i - \abph, (0, 1)) + \frac{\kd - 1}{\ag - 1} f(\bph^i - \abph, (\abpl, \abph)) $$
equals to 0 when $\bph^i = \abph$ and is linear on $\bph^i$. Therefore, in at least on of $\bph^i \le \abph$ or $\bpl^i \le \abpl$, the term will be no larger than zero. 

On the other hand, the third term $\frac{1}{\ag-1} (f(\bph^i, (\abpl, \abph)) - f(\bph^i, (\bpl^i, \bph^i))) \le \frac{\maxdps}{\ag - 1}$.
Therefore, there exists a deviator $i$ such that $\ut(\bpl^i, \bph^i \mid h) - \ut(\abpl, \abph \mid h) \le \frac{\maxdps}{\ag - 1}$. 

Then we show that for sufficiently large $\ag$, for all $(\abpl, \abph)$ not close to $(0,1)$ or $(0, 0)$, $\ut(\stgp^* \mid h) - \ut(\abpl, \abph \mid h) > \frac{\maxdps}{\ag - 1}$. 

\begin{lemma}
    \label{lem:corner}
    Let $\dut(\abpl, \abph \mid h) = \ut(\stgp^* \mid h) - \ut(\abpl, \abph \mid h)$. Then for any $\abph \in [0, 1]$ and $\abpl \in [0, \frac{\pr(h\mid h)}{\pr(\ell \mid h)} \cdot ( 1- \abph)]$ (i.e., the range in Lemma~\ref{lem:subspace_h}), $\dut(\abpl, \abph \mid h) \le \frac{\maxdps}{\ag - 1}$ only if one of the following two holds: (1) $\abph \ge 1 - \bphth$, or (2) $\abph \le \bphth$ and $\abpl \le \frac{\pr(h \mid h)}{\pr(\ell \mid h)} \cdot \bphth$, where 
    \begin{equation*}
   \bphth = \frac{4\maxdps\cdot (\dpsh + \dpsl + \ps(\ell, \vpr_{\ell}) - \ps(h, \vpr_\ell))}{ (\ag - 1)\cdot (\dpsh +\dpsl)\cdot  \Ex_{\sigi \sim \vpr_h}[\ps(\sigi, \vpr_h) - \pr(\sigi, \vpr_\ell)]}.
\end{equation*}
\end{lemma}


We first consider the case when $\abpl = 0$. Note that $\dut(0, \abph \mid h)$ is a quadratic function of $\abph$ satisfying (1) $\dut (0, 1 \mid h) = 0$, (2) $\frac{\partial^2\dut (\abph, 0 \mid h)}{\partial \abph^2} = -\frac{2(\kd - 1)}{\ag - 1}\cdot \pr(h\mid h)\cdot (\dpsh + \dpsl) < 0$, and (3) another root other than $1$, denoted by $\bph''$, satisfies $\bph'' \le  0$. If (3) does not hold, we will have $\dut(0, 0 \mid h) < 0$, which is a contradiction. 

According to the property of the quadratic function, $\dut(\abpl, \abph \mid h)$ is maximized at $\frac{1 + \bph''}{2} = $
\begin{equation*}
\frac{(\kd -1)\cdot (\dpsl + \pr(h\mid h)\cdot (\ps(\ell, \vpr_{\ell}) - \ps(h, \vpr_\ell)) + (\ag - \kd)\cdot (\pr(h\mid h)\cdot (-\dpsh) + \pr(\ell \mid h) \cdot \dpsl)}{2(\kd - 1)\cdot (\pr(h\mid h) \cdot (\dpsh + \dpsl))} 
\end{equation*}

with value 
\begin{align*}
    &\ \frac{\kd - 1}{4(\ag - 1)}\cdot \pr(h\mid h)\cdot (\dpsh + \dpsl) \cdot (1 - \bph'')^2\\
    \ge &\ \frac{\kd - 1}{4(\ag - 1)}\cdot \pr(h\mid h)\cdot (\dpsh + \dpsl). 
\end{align*}

We consider three different cases

Firstly, when $\ps(\ell, \vpr_{\ell}) - \ps(h, \vpr_\ell) \le 0$. In this case, we show that $\ut(0, 0 \mid h)$ is faraway from $\ut(\stgp^*\mid h)$. Therefore, $\ut(\stgp^* \mid h) - \ut(0, \abph \mid h) \le \frac{\maxdps}{\ag - 1}$ only if $\abph$ is close to 1. Note that in this case, 
\begin{align*}
    \ut(0, 0\mid h, \jdeviate) = &\ \ps(\ell, \vpr_\ell)\\
    \le &\ \pr(h\mid h) \cdot \pr(\ell, \vpr_h) + \pr(\ell\mid h) \cdot \ps(\ell, \vpr_\ell). 
\end{align*}

Therefore, 
\begin{align*}
    \dut(0, 0 \mid h) = &\ \ut(\stgp^* \mid h) - \ut(0, 0\mid h)\\
    \ge &\ \pr(h\mid h) \cdot \dpsh - \pr(\ell\mid h) \cdot \dpsl\\
    =&\ \Ex_{\sigi \sim \vpr_h}[\ps(\sigi, \vpr_h) - \pr(\sigi, \vpr_\ell)]\\
    > &\ 0. 
\end{align*}

Then, give that $\dut(0, \abph \mid h)$ is convex on $\abph$, for all $\abph \in [0, 1]$, 
$$\dut(0, \abph \mid h) \ge (1 - \abph) \cdot \Ex_{\sigi \sim \vpr_h}[\ps(\sigi, \vpr_h) - \pr(\sigi, \vpr_\ell)]. $$

Therefore, $\dut(0, \abph \mid h) > \frac{\maxdps}{ \ag - 1}$ for any $0 \le  \abph < 1 - \frac{\maxdps}{ (\ag - 1)\cdot \Ex_{\sigi \sim \vpr_h}[\ps(\sigi, \vpr_h) - \pr(\sigi, \vpr_\ell)]}$. 

Secondly, when $\ps(\ell, \vpr_{\ell}) - \ps(h, \vpr_\ell) \ge 0$ and $\frac{1 + \bph''}{2} \le 0$, we still prove that $\ut(0, 0 \mid h)$ is faraway from $\ut(\stgp^*\mid h)$. Note that when $\frac{1 + \bph''}{2} \le 0$, the deviating group size $\kd$ must satisfy
\begin{equation*}
    \kd \le \frac{\Ex_{\sigi \sim \vpr_h}[\ps(\sigi, \vpr_h) - \pr(\sigi, \vpr_\ell)]}{\pr(h\mid h) \cdot (\dpsh + \dpsl + \ps(\ell, \vpr_{\ell}) - \ps(h, \vpr_\ell))}\cdot (n-1) + 1. 
\end{equation*}

Then, 
\begin{align*}
    \dut(0, 0 \mid h) = &\ \frac{1}{\ag - 1} ((\kd - 1)\cdot (\ut(0, 0\mid h, \jtruthful) -  \ut(0, 0\mid h, \jdeviate))\\
    &\ + (\ag - 1)\cdot (\ut(\stgp^* \mid h) -  \ut(0, 0\mid h, \jtruthful)))\\
    \ge &\ \frac{1}{\pr(h \mid h)(\dpsh + \dpsl + \ps(\ell, \vpr_{\ell}) - \ps(h, \vpr_\ell))}\\
    &\ \cdot (-\Ex_{\sigi \sim \vpr_h}[\ps(\sigi, \vpr_h) - \pr(\sigi, \vpr_\ell)] \cdot \pr(h \mid h) \cdot (\ps(\ell, \vpr_\ell) - \ps(h, \vpr_\ell))\\
    &\ + \pr(h\mid h)\cdot (\dpsh + \dpsl + \ps(\ell, \vpr_{\ell}) - \ps(h, \vpr_\ell)) \cdot \Ex_{\sigi \sim \vpr_h}[\ps(\sigi, \vpr_h) - \pr(\sigi, \vpr_\ell)])\\
    =&\  \frac{(\dpsh + \dpsl) \cdot \Ex_{\sigi \sim \vpr_h}[\ps(\sigi, \vpr_h) - \pr(\sigi, \vpr_\ell)]}{(\dpsh + \dpsl + \ps(\ell, \vpr_{\ell}) - \ps(h, \vpr_\ell))}\\
    > &\ 0. 
\end{align*}

Therefore,  $\dut(0, \abph \mid h) > \frac{\maxdps}{ \ag - 1}$ for any $0 \le  \abph < 1 - \frac{\maxdps\cdot (\dpsh + \dpsl + \ps(\ell, \vpr_{\ell}) - \ps(h, \vpr_\ell))}{ (\ag - 1)\cdot (\dpsh +\dpsl)\cdot  \Ex_{\sigi \sim \vpr_h}[\ps(\sigi, \vpr_h) - \pr(\sigi, \vpr_\ell)]}$. 

Thirdly, when $\ps(\ell, \vpr_{\ell}) - \ps(h, \vpr_\ell) \ge 0$ and $\frac{1 + \bph''}{2} > 0$, the group size $\kd$ must satisfy
\begin{equation*}
    \kd > \frac{\Ex_{\sigi \sim \vpr_h}[\ps(\sigi, \vpr_h) - \pr(\sigi, \vpr_\ell)]}{\pr(h\mid h) \cdot (\dpsh + \dpsl + \ps(\ell, \vpr_{\ell}) - \ps(h, \vpr_\ell))}\cdot (n-1) + 1. 
\end{equation*}

Therefore, For any $\bph \in [\frac{1 + \bph''}{2}, 1]$, 
\begin{align*}
   \dut(0, \abph \mid h) \ge&\  (1 - \abph) \cdot \frac{\kd - 1}{4(\ag - 1)}\cdot \pr(h\mid h)\cdot (\dpsh + \dpsl)\\
   \ge &\ (1 - \abph) \cdot  \frac{\Ex_{\sigi \sim \vpr_h}[\ps(\sigi, \vpr_h) - \pr(\sigi, \vpr_\ell)]\cdot (\dpsh + \dpsl)}{4 (\dpsh + \dpsl + \ps(\ell, \vpr_{\ell}) - \ps(h, \vpr_\ell))}
\end{align*}

Similarly, for any $\bph \in [0, \frac{1 + \bph''}{2}]$, 
\begin{equation*}
   \dut(0, \abph \mid h)
   \ge \abph \cdot  \frac{\Ex_{\sigi \sim \vpr_h}[\ps(\sigi, \vpr_h) - \pr(\sigi, \vpr_\ell)]\cdot (\dpsh + \dpsl)}{4 (\dpsh + \dpsl + \ps(\ell, \vpr_{\ell}) - \ps(h, \vpr_\ell))}.
\end{equation*}

Therefore, $\dut(0, \abph \mid h) > \frac{\maxdps}{ \ag - 1}$ for any 
$\bphth <  \abph < 1 - \bphth$, 
where $$\bphth = \frac{4\maxdps\cdot (\dpsh + \dpsl + \ps(\ell, \vpr_{\ell}) - \ps(h, \vpr_\ell))}{ (\ag - 1)\cdot (\dpsh +\dpsl)\cdot  \Ex_{\sigi \sim \vpr_h}[\ps(\sigi, \vpr_h) - \pr(\sigi, \vpr_\ell)]}.$$

Then we consider when $\abpl = \frac{\pr(h\mid h)}{\pr(\ell \mid h)} \cdot (1 - \abph)$. From Lemma~\ref{lem:subspace_h}, $$\frac{\partial \ut(\frac{\pr(h\mid h)}{\pr(\ell \mid h)}(1 - \abph), \abph \mid h)}{\partial \abph} = \Ex_{\sigi\sim \vpr_{h}}[\ps(\sigi, \vpr_{h}) - \ps(\sigi, \vpr_{\ell})] > 0.$$ 

Therefore, for any $0\le \abph< 1 - \frac{\maxdps}{ (\ag - 1)\cdot \Ex_{\sigi \sim \vpr_h}[\ps(\sigi, \vpr_h) - \pr(\sigi, \vpr_\ell)]}$,  $\dut(\frac{\pr(h\mid h)}{\pr(\ell \mid h)} \cdot (1 - \abph), \abph \mid h) > \frac{\maxdps}{ \ag - 1}$.

Then, by the linearity of $\dut (\abpl, \abph \mid h)$ on $\abpl$, we know that for any $\bphth < \abph < 1 - \bphth$ and any $0\le \abpl < \frac{\pr(h\mid h)}{\pr(\ell \mid h)} \cdot (1 - \abph)$, $\dut(\abpl, \abph \mid h) > \frac{\maxdps}{ \ag - 1}$, the threshold comes out that $\bphth$ is the largest among all the threshold.  

Then we consider $0\le \abph \le \bphth$.
We have \begin{equation*}
   \dut(0, \abph \mid h)
   \ge \abph \cdot  \frac{\Ex_{\sigi \sim \vpr_h}[\ps(\sigi, \vpr_h) - \pr(\sigi, \vpr_\ell)]\cdot (\dpsh + \dpsl)}{4 (\dpsh + \dpsl + \ps(\ell, \vpr_{\ell}) - \ps(h, \vpr_\ell))}
\end{equation*}
and
\begin{align*}
   \dut(\frac{\pr(h\mid h)}{\pr(\ell \mid h)} \cdot (1 - \abph), \abph \mid h) =&\ ( 1- \abph)\cdot \Ex_{\sigi\sim \vpr_{h}}[\ps(\sigi, \vpr_{h}) - \ps(\sigi, \vpr_{\ell})]\\
   \ge &\ ( 1- \abph)\cdot\frac{\Ex_{\sigi \sim \vpr_h}[\ps(\sigi, \vpr_h) - \pr(\sigi, \vpr_\ell)]\cdot (\dpsh + \dpsl)}{4 (\dpsh + \dpsl + \ps(\ell, \vpr_{\ell}) - \ps(h, \vpr_\ell))}.
\end{align*}
Therefore, for any $0\le \abpl \le \frac{\pr(h\mid h)}{\pr(\ell \mid h)} \cdot (1 - \abph)$, 

\begin{align*}
    \dut(\abpl, \abph \mid h) = &\ \left (1 -\frac{\abpl \cdot \pr(\ell\mid h)}{\pr(h\mid h)\cdot ( 1- \abph)}\right)\cdot \dut(0, \abph \mid h)\\
    &\ +  \frac{\abpl \cdot \pr(\ell\mid h)}{\pr(h\mid h)\cdot ( 1- \abph)} \cdot \dut(\frac{\pr(h\mid h)}{\pr(\ell \mid h)} \cdot (1 - \abph), \abph \mid h)\\
    \ge &\ \left( \abph + \abpl\cdot \frac{\pr(\ell \mid h)\cdot (1 - 2\abph)}{\pr(h\mid h)\cdot (1 - \abph)}\right)\cdot\frac{\Ex_{\sigi \sim \vpr_h}[\ps(\sigi, \vpr_h) - \pr(\sigi, \vpr_\ell)]\cdot (\dpsh + \dpsl)}{4 (\dpsh + \dpsl + \ps(\ell, \vpr_{\ell}) - \ps(h, \vpr_\ell))}\\
    \ge &\ (\abph + \frac{\pr(\ell \mid h)}{\pr(h\mid h)} \cdot \abpl \cdot (1 - 2\abph)) \cdot\frac{\Ex_{\sigi \sim \vpr_h}[\ps(\sigi, \vpr_h) - \pr(\sigi, \vpr_\ell)]\cdot (\dpsh + \dpsl)}{4 (\dpsh + \dpsl + \ps(\ell, \vpr_{\ell}) - \ps(h, \vpr_\ell))}.
\end{align*}

Therefore, for
\begin{equation*}
    \abpl > \frac{\pr(h\mid h)}{\pr(\ell \mid h)\cdot (1 - 2\abph)} \cdot (\bphth - \abph),
\end{equation*}
$\dut(\abpl, \abph\mid h) > \frac{\maxdps}{\ag - 1}$. Given that $\bphth < \frac12$, the RHS is maximized at $\abph = 0.$ 
Therefore, for any $0\le \abph \le \bphth$ and any $\abpl > \frac{\pr(h\mid h)}{\pr(\ell \mid h)}\cdot \bphth$, $\dut(\abpl, \abph\mid h) > \frac{\maxdps}{\ag - 1}$. 

So far we have proved Lemma~\ref{lem:corner}, which ends the second part.

In the third part, for the area close to $(0,0)$ or $(0, 1)$, i.e. (1) $\abph \ge 1 - \bphth$, and (2) $\abph \le \bphth$ and $\abpl \le \frac{\pr(h \mid h)}{\pr(\ell \mid h)} \cdot \bphth$, we show that we can always find a deviator $i$ such that $\ut(\bpl^i, \bph^i \mid h) < \ut(\stgp^* \mid h)$. 
Let 
\begin{align*}
  \nbph = &\ \frac{1}{\kd - 1} \sum_{j\in D, j\neq i} \bph^j  = \abph + \frac{1}{\kd - 1} (\abph - \bph^i)\\
  \nbpl = &\ \frac{1}{\kd - 1} \sum_{j\in D, j\neq i} \bpl^j  = \abpl + \frac{1}{\kd - 1} (\abpl - \bpl^i)
\end{align*} 
be the average strategy of all the deviators other than $i$. It is satisfied that $(\nbpl, \nbph) \in [0, 1]^2$.

We pick a deviator $i$ and characterize the $\kd$ such that $\ut(\bpl^i, \bph^i \mid h) \ge \ut(\stgp^* \mid h)$. More precisely, 
\begin{equation*}
    \kd \ge \frac{\ut(\stgp^* \mid h) - \ut(\bpl^i, \bph^i \mid h, \jtruthful)}{(\ut(\stgp^* \mid h) - \ut(\bpl^i, \bph^i \mid h, \jtruthful)) - (\ut(\stgp^* \mid h) - \ut(\bpl^i, \bph^i \mid h, \jdeviate))}\cdot (n - 1) + 1
\end{equation*}
when the denominator $(\ut(\stgp^* \mid h) - \ut(\bpl^i, \bph^i \mid h, \jtruthful)) - (\ut(\stgp^* \mid h) - \ut(\bpl^i, \bph^i \mid h, \jdeviate)) > 0$ or $\kd$ does not exist when the denominator equals to or is less than $0$. 
We will show that this $\kd > \kdq$ in both corner cases. 

The numerator of RHS is  
\begin{align*}
    \ut(\stgp^* \mid h) - \ut(\bpl^i, \bph^i \mid h, \jtruthful) = (1 - \bph^i)\cdot \Ex_{\sigi\sim \vpr_{h}}[\ps(\sigi, \vpr_{h}) - \ps(\sigi, \vpr_{\ell})]. 
\end{align*}

The denominator is 
\begin{align*}
    &\ \ut(\bpl^i, \bph^i \mid h, \jdeviate) - \ut(\bpl^i, \bph^i \mid h, \jtruthful)\\
    =&\ \bph^i \cdot ( (\pr(h\mid h)\cdot (\nbph  - 1) + \pr(\ell \mid h) \cdot \nbpl)\cdot \ps(h, \vpr_h)\\
    &\ + (\pr(h\mid h)\cdot (1 - \nbph) - \pr(\ell \mid h) \cdot \nbpl)\cdot \ps(\ell, \vpr_h))\\
    =&\ ( 1 - \bph^i ) \cdot ( (\pr(h\mid h)\cdot (\nbph  - 1) + \pr(\ell \mid h) \cdot \nbpl)\cdot \ps(h, \vpr_\ell)\\
    &\ + (\pr(h\mid h)\cdot (1 - \nbph) - \pr(\ell \mid h) \cdot \nbpl)\cdot \ps(\ell, \vpr_\ell))\\
    =&\ (\pr(h\mid h)\cdot (1 - \nbph) - \pr(\ell \mid h) \cdot \nbpl)\\
    &\ \cdot (\bph^i  \cdot (\ps(\ell, \vpr_h) - \ps(h, \vpr_h)) + ( 1- \bph^i) \cdot (\ps(\ell, \vpr_\ell) - \ps(h, \vpr_\ell))). 
\end{align*} 

We first consider $\abph \le \bphth$ and $\abpl \le \frac{\pr(h \mid h)}{\pr(\ell \mid h)} \cdot \bphth$. In this case, we pick a deviator $i$ such that $\bph^i \le \abph$. 

Firstly, there must be $(\pr(h\mid h)\cdot (1 - \nbph) - \pr(\ell \mid h) \cdot \nbpl) > 0$ for all sufficiently large $\ag$. This is because $\abph \le \bphth = \Theta(\frac{\maxdps}{\ag - 1})$ and $\abpl \le \frac{\pr(h\mid h)}{\pr(\ell \mid h)}\cdot \bphth$. Moreover, $\nbph \le 2 \abph$ and $\nbpl \le 2\abpl$ by the property of the average. Therefore, for sufficiently large $\ag$ such that $\bphth < \frac14$, $(\pr(h\mid h)\cdot (1 - \nbph) - \pr(\ell \mid h) \cdot \nbpl) > 0$. 

If $\ps(\ell, \vpr_\ell) - \ps(h, \vpr_\ell) \le 0$, there must be $(\ps(\ell, \vpr_h) - \ps(h, \vpr_h)) < 0$. In this case $\ut(\bpl^i, \bph^i \mid h, \jdeviate) - \ut(\bpl^i, \bph^i \mid h, \jtruthful) < 0$, and for any $\kd \ge 2$, $i$'s reward will be strictly lower than the truthful reward. 

Suppose $\ps(\ell, \vpr_\ell) - \ps(h, \vpr_\ell) > 0$. In this case, the condition for  $\ut(\bpl^i, \bph^i \mid h) \ge \ut(\stgp^* \mid h)$ is equivalent to $\kd - 1 \ge$
\begin{smallblock}
    \begin{align*}
    \frac{(1 - \bph^i)\cdot \Ex_{\sigi\sim \vpr_{h}}[\ps(\sigi, \vpr_{h}) - \ps(\sigi, \vpr_{\ell})]}{(\pr(h\mid h)\cdot (1 - \nbph) - \pr(\ell \mid h) \cdot \nbpl)\cdot (\bph^i  \cdot (\ps(\ell, \vpr_h) - \ps(h, \vpr_h)) + ( 1- \bph^i) \cdot (\ps(\ell, \vpr_\ell) - \ps(h, \vpr_\ell)))}\cdot (n - 1).
\end{align*}
\end{smallblock}


We show this lower bound is larger than $\kdq$. 
Recall that 
\begin{equation*}
    \kdq \le \frac{\Ex_{\sigi\sim \vpr_{h}}[\ps(\sigi, \vpr_{h}) - \ps(\sigi, \vpr_{\ell})]}{\pr(h\mid h)\cdot (\ps(\ell, \vpr_\ell) - \ps(h, \vpr_\ell))}\cdot (n - 1) + 1
\end{equation*}

Therefore, it is sufficient to show that 
\begin{smallblock}
   \begin{align*}
    \frac{(1 - \bph^i)\cdot \pr(h\mid h)\cdot (\ps(\ell, \vpr_\ell) - \ps(h, \vpr_\ell))}{(\pr(h\mid h)\cdot (1 - \nbph) - \pr(\ell \mid h) \cdot \nbpl)\cdot (\bph^i  \cdot (\ps(\ell, \vpr_h) - \ps(h, \vpr_h)) + ( 1- \bph^i) \cdot (\ps(\ell, \vpr_\ell) - \ps(h, \vpr_\ell)))} > 1.
\end{align*}
\end{smallblock}


Firstly, given that $\bph^i \le \abph$, there is $\bph^i \le \nbph$. Therefore, 
\begin{align*}
    (\pr(h\mid h)\cdot (1 - \nbph) - \pr(\ell \mid h) \cdot \nbpl) \le &\ \pr(h\mid h)\cdot (1 - \nbph) \\
    \le &\ (1 - \bph^i)\cdot \pr(h\mid h). 
\end{align*}

Secondly, by Lemma~\ref{lem:pr_psr} we have $\ps(\ell, \vpr_h) - \ps(h, \vpr_h) < \ps(\ell, \vpr_\ell) - \ps(h, \vpr_\ell)$. Therefore, $\bph^i\cdot (\ps(\ell, \vpr_h) - \ps(h, \vpr_h)) + ( 1- \bph^i) \cdot (\ps(\ell, \vpr_\ell) - \ps(h, \vpr_\ell)) \le \ps(\ell, \vpr_\ell) - \ps(h, \vpr_\ell)$. 

By combining two parts, we show that every part in the denominator is smaller than the corresponding part in the nominator. Therefore, the threshold for $i$'s reward exceeds the truthful reward $\kd \ge \kdq$, and the equality holds only when $\bph^i = \nbph = \nbpl = 0$. When the equality holds, all other deviators play $(0, 0)$. If $\bpl^i = 0$, the case is covered by Step 2. Otherwise, we consider a different deviator $i$. Then the threshold for the new $i$ will be strictly larger than $\kdq$. Therefore, for all $\kd \le \kdq$, $i$'s reward is strictly lower than the truthful reward. 

We then consider the second area $\abph \ge 1 - \bphth$.
When $\ps(h, \vpr_h) \le \ps(\ell, \vpr_h)$, we we pick an $i$ such that $\bph^i \le \abph$ and compare $i$'s reward with the truthful reward. In this case, $ 0\le \ps(\ell, \vpr_h) - \ps(h, \vpr_h) < \ps(\ell, \vpr_\ell) - \ps(h, \vpr_\ell)$. If $\pr(h\mid h)\cdot (1 - \nbph) - \pr(\ell \mid h) \cdot \nbpl \le 0$, the denominator is non-positive, and for any $\kd \ge 2$, $i$'s reward cannot exceed the truthful reward. If $\pr(h\mid h)\cdot (1 - \nbph) - \pr(\ell \mid h) \cdot \nbpl > 0$, the denominator is positive. Following similar reasoning for $(\abpl, \abph)$ close to $(0, 0)$ shows that the threshold $\kd > \kdq$. 

% If there exists a deviator $i$ such that 
% $\bph^i \le \abph$ and $(\pr(h\mid h)\cdot (1 - \nbph) > \pr(\ell \mid h) \cdot \nbpl$, we pick this $i$, and the proof follows the close to $(0, 0)$ case.

Otherwise, when $\ps(h, \vpr_h) > \ps(\ell, \vpr_h)$, we compare $i$'s reward with the reward of average strategy $(\abpl, \abph)$. Recall that 
\begin{align*}
    &\ \ut(\bpl^i, \bph^i \mid h) - \ut(\abpl, \abph \mid h)\\ 
    =&\ \frac{\ag-\kd}{\ag - 1} \cdot \func^h(\bph^i - \abph, (0, 1)) + \frac{\kd - 1}{\ag - 1} f(\bph^i - \abph, (\abpl, \abph))\\
    &\ +\frac{1}{\ag-1} (f(\bph^i, (\abpl, \abph)) - f(\bph^i, (\bpl^i, \bph^i)))\\
    =&\ (\bph^i - \abph)\cdot (\Ex_{\sigi\sim \vpr_{h}}[\ps(\sigi, \vpr_{h}) - \ps(\sigi, \vpr_{\ell})] \\
    &\ -\frac{\kd - 1}{\ag - 1} \cdot (\pr(h \mid h)\cdot ( 1- \abph) - \pr(\ell \mid h) \cdot \abpl) \cdot (\dpsh + \dpsl))\\
    &\ + \frac{1}{\ag - 1} \cdot (\pr(h \mid h) \cdot (\abph - \bph^i) + \pr(\ell \mid h) \cdot (\abpl - \bpl^i))\\
    &\ \cdot (\bph^i \cdot (\ps(h, \vpr_h) - \ps(\ell, \vpr_h)) + ( 1- \bph^i) \cdot (\ps(h, \vpr_\ell) - \ps(\ell, \vpr_\ell))). 
\end{align*}

We will assume that $\ag$ is sufficiently large so that $((1 - \bphth) \cdot (\ps(h, \vpr_h) - \ps(\ell, \vpr_h)) + \bphth \cdot (\ps(h, \vpr_\ell) - \ps(\ell, \vpr_\ell)) > 0$. (Recall that $\bphth = \Theta(\frac{1}{\ag - 1})$). 

Note that for the second line, $(\pr(h \mid h)\cdot ( 1- \abph) - \pr(\ell \mid h) \cdot \abpl) \cdot (\dpsh + \dpsl)\le  \pr(h \mid h)\cdot \bphth \cdot (\dpsh + \dpsl).$ Therefore, for sufficiently large $\ag$, 
\begin{align*}
    &\ (\bph^i - \abph)\cdot (\Ex_{\sigi\sim \vpr_{h}}[\ps(\sigi, \vpr_{h}) - \ps(\sigi, \vpr_{\ell})] \\&\ -\frac{\kd - 1}{\ag - 1} \cdot (\pr(h \mid h)\cdot ( 1- \abph) - \pr(\ell \mid h) \cdot \abpl) \cdot (\dpsh + \dpsl)) \ge 0. 
\end{align*}


Let 
\begin{align*}
    \munc_1 = &\ (\Ex_{\sigi\sim \vpr_{h}}[\ps(\sigi, \vpr_{h}) - \ps(\sigi, \vpr_{\ell})] \\
    &\ -\frac{\kd - 1}{\ag - 1} \cdot (\pr(h \mid h)\cdot ( 1- \abph) - \pr(\ell \mid h) \cdot \abpl) \cdot (\dpsh + \dpsl))\\
    \munc_2(\bph^i) = &\ (\bph^i \cdot (\ps(h, \vpr_h) - \ps(\ell, \vpr_h)) + ( 1- \bph^i) \cdot (\ps(h, \vpr_\ell) - \ps(\ell, \vpr_\ell))). 
\end{align*}

Then
\begin{align*}
    &\ \ut(\bpl^i, \bph^i \mid h) - \ut(\abpl, \abph \mid h)\\ =&\ (\bph^i - \abph)\cdot \munc_1 + \frac{1}{\ag - 1} \cdot (\pr(h \mid h) \cdot (\abph - \bph^i) + \pr(\ell \mid h) \cdot (\abpl - \bpl^i)) \cdot \munc_2(\bph^i)\\
    =&\ (\bph^i - \abph)\cdot(\munc_1 - \frac{1}{\ag - 1} \cdot \pr(h \mid h)\cdot \munc_2(\bph^i)) + \frac{1}{\ag - 1} \cdot \pr(\ell \mid h) \cdot (\abpl - \bpl^i) \cdot \munc_2(\bph^i).
\end{align*}

Note that $\munc_1 > 0$ and $\frac{\partial\munc_2}{\partial \bph^i} = \dpsh + \dpsl > 0$. 

If there exists a deviator $i$ such that $\bph^i \le \abph$ and $\ut(\bpl^i, \bph^i \mid h) - \ut(\abpl, \abph \mid h) < 0$, we just pick this $i$. Otherwise, if all deviators $j$ with $\bph^j \le \abph$ has $\ut(\bpl^i, \bph^i \mid h) - \ut(\abpl, \abph \mid h) \ge 0$, then the range of $j$'s strategy $(\bpl^j, \bph^j)$ satisfies
\begin{equation*}
    (\bph^j - \abph)\cdot(\munc_1 - \frac{1}{\ag - 1} \cdot \pr(h \mid h)\cdot \munc_2(\bph^j)) + \frac{1}{\ag - 1} \cdot \pr(\ell \mid h) \cdot (\abpl - \bpl^j) \cdot \munc_2(\bph^j) \ge 0
\end{equation*}

This directly implies that $\bpl^j < \abpl$ for any $j$ with $\bph^j \le \abph$. 

Now we pick another deviator $i$ such that (1) $\bph^i \ge \abph$ and (2) for some deviator $j$ with $\bph^j < \abph$, $(\bph^i - \abph)(\abpl - \bpl^j) \le (\bpl^i - \abpl)(\abph - \bph^j).$ If such $i$ does not exist, then for any $i$ with $\bph^i > \abph$ and any $j$ with $\bph^j \le \abph$, there is $(\bph^i - \abph)(\abpl - \bpl^j) > (\bpl^i - \abpl)(\abph - \bph^j).$ Then, 
\begin{align*}
    0 = &\ \sum_{i\in D, \bph^i > \abph} (\bph^i - \abph) + \sum_{j\in D, \bph^i \le \abph} (\bph^j - \abph)\\
    > &\ \sum_{i\in D, \bph^i > \abph} \frac{\bpl^i - \abpl}{\sum_{j\in D, \bph^i \le \abph} (\bpl^j - \abpl)}\cdot\sum_{j\in D, \bph^i \le \abph} (\bph^j - \abph) + \sum_{j\in D, \bph^i \le \abph} (\bph^j - \abph)\\
    = &\ \frac{\sum_{j\in D, \bph^i \le \abph} (\bph^j - \abph)}{\sum_{j\in D, \bph^i \le \abph} (\bpl^j - \abpl)} \cdot \left(\sum_{i\in D, \bph^i > \abph}(\bpl^i - \abpl) +  \sum_{j\in D, \bph^i \le \abph} (\bpl^j - \abpl) \right)\\
    =&\ 0,
\end{align*}
which is a contradiction. 
Therefore, the deviator $i$ we pick always exists. 

Now we compare $i$'s reward with the reward of the average strategy. Note that since $\bph^i > \abph \ge \bph^j$, $\munc_2(\bph^i) > \munc_2(\bph^j)$. 

\begin{align*}
&\ \ut(\bpl^i, \bph^i \mid h) - \ut(\abpl, \abph \mid h)\\
    =&\ (\bph^i - \abph)\cdot(\munc_1 - \frac{1}{\ag - 1} \cdot \pr(h \mid h)\cdot \munc_2(\bph^i)) + \frac{1}{\ag - 1} \cdot \pr(\ell \mid h) \cdot (\abpl - \bpl^i) \cdot \munc_2(\bph^i)\\
    < &\ (\bph^i - \abph)\cdot(\munc_1 - \frac{1}{\ag - 1} \cdot \pr(h \mid h)\cdot \munc_2(\bph^j)) + \frac{1}{\ag - 1} \cdot \pr(\ell \mid h) \cdot (\abpl - \bpl^i) \cdot \munc_2(\bph^j)\\
    \le &\ \frac{\bpl^i - \abpl}{\abpl - \bpl^j} (\abph - \bph^j) \cdot (\munc_1 - \frac{1}{\ag - 1} \cdot \pr(h \mid h)\cdot \munc_2(\bph^j)) + \frac{1}{\ag - 1} \cdot \pr(\ell \mid h) \cdot (\abpl - \bpl^i) \cdot \munc_2(\bph^j)\\
    =&\ - \frac{\bpl^i - \abpl}{\abpl - \bpl^j} \left(  (\bph^j - \abph)(\munc_1 - \frac{1}{\ag - 1} \pr(h \mid h)\cdot \munc_2(\bph^j)) + \frac{1}{\ag - 1}  \pr(\ell \mid h) \cdot (\abpl - \bpl^j) \cdot \munc_2(\bph^j)\right)\\
    \le &\ 0. 
\end{align*}

Therefore, we find an $i$ such that $\ut(\bpl^i, \bph^i \mid h) < \ut(\abpl, \abph \mid h) \le \ut(\stgp^* \mid h)$.

Consequently, for any $\ag$ satisfying:
\begin{enumerate}
    \item $\bphth = \frac{4\maxdps\cdot (\dpsh + \dpsl + \ps(\ell, \vpr_{\ell}) - \ps(h, \vpr_\ell))}{ (\ag - 1)\cdot (\dpsh +\dpsl)\cdot  \Ex_{\sigi \sim \vpr_h}[\ps(\sigi, \vpr_h) - \pr(\sigi, \vpr_\ell)]} < \frac14$, 
    \item If $\ps(h, \vpr_h) > \ps(\ell, \vpr_h)$, then $\bphth \le \frac{\ps(h, \vpr_h) - \ps(\ell, \vpr_h)}{\dpsh + \dpsl}$, 
    \item $\bphth \le \frac{\Ex_{\sigi \sim \vpr_h}[\ps(\sigi, \vpr_h) - \pr(\sigi, \vpr_\ell)]}{\pr(h\mid h)\cdot (\dpsh + \dpsl)}$,
\end{enumerate}
for any deviation with no more than $\kdq$ deviators and the average strategy in the area of Lemma~\ref{lem:subspace_h}, there exists a deviator $i$ with private signal $h$ whose reward is strictly worse than the truthful reward. Therefore, such deviation cannot succeed. 

Similarly, for the $\ell$ side, for any $\ag$ such that
\begin{enumerate}
    \item $\bphtl = \frac{4\maxdps\cdot (\dpsh + \dpsl + \ps(h, \vpr_{h}) - \ps(\ell, \vpr_h))}{ (\ag - 1)\cdot (\dpsh +\dpsl)\cdot  \Ex_{\sigi \sim \vpr_\ell}[\ps(\sigi, \vpr_\ell) - \pr(\sigi, \vpr_h)]} < \frac14$, 
    \item If $\ps(\ell, \vpr_{\ell}) > \ps(h, \vpr_\ell)$, then $\bphth \le \frac{\ps(\ell, \vpr_{\ell}) - \ps(h, \vpr_\ell)}{\dpsh + \dpsl}$, 
    \item $\bphth \le \frac{\Ex_{\sigi \sim \vpr_\ell}[\ps(\sigi, \vpr_\ell) - \pr(\sigi, \vpr_h)]}{\pr(\ell \mid \ell)\cdot (\dpsh + \dpsl)}$,
\end{enumerate}
for any deviation with no more than $\kdq$ deviators and the average strategy in the area of Lemma~\ref{lem:subspace_l}, there exists a deviator $i$ with private signal $\ell$ whose reward is strictly worse than the truthful reward. Therefore, such deviation cannot succeed. 

Therefore, truthful reporting is an Bayesian $\kdq$-strong equilibrium. 

% Then we consider the third type of deviation where all the deviators always tell lies, i.e. $\stg = (1, 0)$. Let $\stgp$ be this deviating strategy profile, and we consider the condition to make this deviation succeed. Still, we calculate the expected utility first. When the peer $j$ is a truthful agent,

% \begin{align*}
%     \ut_i(\stgp\mid h, \jtruthful) = &\ \pr(h \mid h) \cdot \ps(h, \vpr_\ell) + \pr(\ell \mid h) \cdot \ps(\ell, \vpr_\ell)\\
%      \ut_i(\stgp\mid \ell, \jtruthful) =&\ \pr(h \mid \ell) \cdot \ps(h, \vpr_h) + \pr(\ell \mid \ell) \cdot \ps(\ell, \vpr_h). 
% \end{align*}

% And when $j$ is also a deviator, 
% \begin{align*}
%     \ut_i(\stgp\mid h, \jdeviate) = &\ \pr(h \mid h) \cdot \ps(\ell, \vpr_\ell) + \pr(\ell \mid h) \cdot \ps(h, \vpr_\ell)\\
%      \ut_i(\stgp\mid \ell, \jdeviate) =&\ \pr(h \mid \ell) \cdot \ps(\ell, \vpr_h) + \pr(\ell \mid \ell) \cdot \ps(h, \vpr_h). 
% \end{align*}

% Let $\dut_{t|\sigi_i}$ and $\dut_{d|\sigi_i}$ be defined similarly. Then we have 

% \begin{align*}
%     \dut_{t\mid h} =&\ \Ex_{\sigi\sim \vpr_{h}}[\ps(\sigi, \vpr_{h}) - \ps(\sigi, \vpr_{\ell})].\\
%     \dut_{t\mid \ell} =&\ \Ex_{\sigi\sim \vpr_{\ell}}[\ps(\sigi, \vpr_{\ell}) - \ps(\sigi, \vpr_{h})].
% \end{align*}

% And
% \begin{align*}
%     \dut_{t\mid h} - \dut_{d\mid h} =&\ (\pr(h\mid h) - \pr(\ell \mid h))\cdot(\ps(\ell, \vpr_{\ell}) - \ps(h, \vpr_{\ell})).\\
%     \dut_{t\mid \ell} - \dut_{d\mid \ell} =&\ (\pr(\ell\mid \ell) - \pr(h \mid \ell))\cdot(\ps(h, \vpr_{h}) - \ps(\ell, \vpr_{h})).
% \end{align*}

% Then we will show that for all $\kd \le \kdq$, such deviation will not succeed. 

% When $\ps(h, \vpr_{h}) > \ps(\ell, \vpr_{h})$, we consider the expected utility of a deviator $i$ with private signal $\ell$. If $\dut_{t\mid \ell} - \dut_{d\mid \ell} \le 0$, then $i$ cannot benefit from deviating to $\stgp$ for any $k\le n$. If $\dut_{t\mid \ell} - \dut_{d\mid \ell} > 0$, the condition for $i$ to benefit from deviating is 
% \begin{align*}
%     \kd \ge &\ \frac{\Ex_{\sigi\sim \vpr_{\ell}}[\ps(\sigi, \vpr_{\ell}) - \ps(\sigi, \vpr_{h})]}{(\pr(\ell \mid \ell) - \pr(h \mid \ell))\cdot (\ps(h, \vpr_h) - \ps(\ell, \vpr_h))} \cdot (n-1) + 1 \\
%     >&\ \left\lceil\frac{\Ex_{\sigi\sim \vpr_{\ell}}[\ps(\sigi, \vpr_{\ell}) - \ps(\sigi, \vpr_{h})]}{\pr(\ell \mid \ell)\cdot (\ps(h, \vpr_h) - \ps(\ell, \vpr_h))} \cdot (n-1)\right\rceil\\
%     = &\ \kdq^h\\
%     \ge &\  \kdq
% \end{align*}
% Therefore, when $k\le k_Q$, $i$ cannot benefit from $\stgp$. 

% When $\ps(h, \vpr_{h}) \le \ps(\ell, \vpr_{h})$, by Lemma~\ref{lem:pr_psr} we know that the other side $\ps(\ell, \vpr_{\ell}) > \ps(h, \vpr_{\ell})$ must hold. Therefore, by similar reasoning, a deviator with private signal $h$ will not benefit from deviation for all $k\le k_Q$. 

% \noindent\textbf{Step 2: Equlibrium holds for $\kd \le \kdq.$}

% We fix an arbitrary $\kd$. We define the strategy of deviators as in the proof of Theorem~\ref{thm:pp_exante}. Let $\stgp$ be the deviating strategy and $\stg_i = (\bpl^i, \bph^i)$ be the strategy agent $i$ plays in $\stgp$. Let $\astg = (\abpl, \abph) = \frac{1}{\kd} \sum_{i \in D} \stg_i$ be the average strategy on all deviators. 

% For truthful reporting, agents with the same signal have the same expected utility. Therefore, $\aut(\stgp^*\mid h) = \ut_i(\stgp^*\mid h)$, and $\aut(\stgp^*\mid \ell) = \ut_i(\stgp^*\mid \ell)$. 

% The expected utility of deviator $i$ with private signal $h$ conditioned on his/her peer $j$ is a truthful agent is 
% \begin{align*}
%     \ut_i(\stgp \mid h, \jtruthful) =&\  \frac{1}{n-\kd}\sum_{j \in [n]\setminus D} \Ex_{\rp_i \sim \stg_i(h)} \Ex_{\sigi_j \sim \vpr_{h}} \ps(\sigi_j, \vpr_{\rp_i})\\
%     =&\ \Ex_{\rp_i \sim \stg_i(h)} \Ex_{\sigi_j \sim \vpr_{h}} \ps(\sigi_j, \vpr_{\rp_i})
% \end{align*}
% The average on this expected utility when an agent has private signal $h$ and a truthful peer $j$ is
% \begin{align*}
%     \aut(\stgp\mid h, \jtruthful) =&\ \frac{1}{\kd} \sum_{i \in D}  \ut_i(\stgp\mid h, \jtruthful)\\
%     =&\ \Ex_{\rp \sim \astg(h)} \Ex_{\sigi_j \sim \vpr_{h}} \ps(\sigi_j, \vpr_{\rp}). 
% \end{align*}

% Therefore, the difference between $\aut(\stgp\mid h, \jtruthful)$ and $\aut(\stgp^*\mid h)$ is a linear function of $\abph$. 
% \begin{align*}
%     \dut_t^h(\abph) =&\ \aut(\stgp^*\mid h) - \aut(\stgp \mid h, \jtruthful)\\
%     =&\ (1 - \abph) \cdot (\pr(h\mid h) \cdot (\ps(h, \vpr_h) - \ps(h, \vpr_{\ell}))  + \pr(\ell \mid h) \cdot (\ps(\ell, \vpr_h) - \ps(\ell, \vpr_\ell))). 
% \end{align*}

% Similarly, we can define that difference on $\ell$. 
% \begin{align*}
%     \dut_t^\ell(\abpl) =&\ \aut(\stgp^*\mid \ell) - \aut(\stgp \mid \ell, \jtruthful)\\
%     =&\ \abpl \cdot (\pr(h\mid \ell) \cdot (\ps(h, \vpr_\ell) - \ps(h, \vpr_{h})) + \pr(\ell \mid \ell) \cdot (\ps(\ell, \vpr_\ell) - \ps(\ell, \vpr_h))).
% \end{align*}

% $ \dut_t^h(\abph)$ and $\dut_t^\ell(\abpl)$ are guaranteed to be positive by the properness of the scoring rule. 

% For the deviator's side, we have
% \begin{align*}
%     \ut_i(\stgp \mid h, \jdeviate) =&\  \frac{1}{\kd-1}\sum_{j \in D\setminus\{i\}} \Ex_{\rp_i \sim \stg_i(h)} \Ex_{\sigi_j \sim \vpr_{h}, \rp_j \sim \stg_j(\sigi_j)} \ps(\rp_j, \vpr_{\rp_i}).
% \end{align*}

% And $\aut(\stgp\mid h, \jdeviate) = \frac{1}{\kd} \sum_{i\in D} \ut_i(\stgp\mid h, \jdeviate)$. The $\ell$ side is defined similarly. 
% \begin{align*}
%     \ut_i(\stgp \mid \ell, \jdeviate) =&\  \frac{1}{\kd-1}\sum_{j \in D\setminus\{i\}} \Ex_{\rp_i \sim \stg_i(\ell)} \Ex_{\sigi_j \sim \vpr_{\ell}, \rp_j \sim \stg_j(\sigi_j)} \ps(\rp_j, \vpr_{\rp_i}).\\
%     \aut(\stgp\mid \ell, \jdeviate) =&\ \frac{1}{\kd} \sum_{i\in D} \ut_i(\stgp\mid \ell, \jdeviate)
% \end{align*}

% Similar to the proof of Theorem~\ref{thm:pp_exante}, we find upper bounds of $\aut(\stgp\mid h, \jdeviate)$ and $\aut(\stgp\mid \ell, \jdeviate)$ respectively parameterized by $\abph$ and $\abpl$. We do the $h$ side first. 

% \begin{align*}
%     \aut(\stgp\mid h, \jdeviate) = &\ \frac{\kd}{\kd - 1} \Ex_{\rp' \sim \astg(h)} \Ex_{\sigi \sim \vpr_{h}, \rp \sim \astg(\sigi)} \ps(\rp, \vpr_{\rp'})\\
%     & - \frac{1}{(\kd - 1)k} \sum_{i \in D} \Ex_{\rp_i \sim \stg_i(h)} \Ex_{\sigi \sim \vpr_{h}, \rp \sim \stg_i(\sigi)} \ps(\rp, \vpr_{\rp_i}).
% \end{align*}

% Let $\func_h: [0, 1]^2 \to \mathbb{R}$. For a strategy $\stg = (\bpl, \bph)$, let
% \begin{align*}
%     \func_h(\bpl, \bph) =&\ \Ex_{\rp' \sim \stg(\sigi)} \Ex_{\sigi \sim \vpr_{h}, \rp \sim \stg(\sigi)} \ps(\rp, \vpr_{\rp'}). 
% \end{align*}

% Then we can represent $ \aut(\stgp\mid \jdeviate)$ in the form of $\func$. 
% \begin{equation*}
%      \aut(\stgp\mid h, \jdeviate) = \frac{\kd}{\kd-1} \func_h(\abpl, \abph) - \frac{1}{(\kd-1)\kd} \sum_{i\in D} \func_h(\bpl^i, \bph^i). 
% \end{equation*}

% % \begin{claim}
% %     \label{claim:fh}
% %     $\func_h(\bpl, \bph)$ is convex on $[0, 1]^2$.  
% % \end{claim}

% % \begin{proof}



\section{Truthful Reporting is not a coalitional interim equilibrium}
\label{apx:guo}

In this section, we introduce the coalitional interim equilibrium in \citep{guo2022robust}.

\begin{definition}
\label{def:interim}
    Given the set of all admissible deviating groups $\mathcal{D}$, a strategy profile $\stgp$ is an  interim $\mathcal{D}$ equilibrium if there does not exist a group of agent $D \in \mathcal{D}$, a set of types $\sigi_D = (\sigi_i)_{i \in D}$, and a different strategy profile $\stgp' = (\stg'_{\sag})$ such that 
    \begin{enumerate}
    \item for all agent $i \not \in D$, $\stg'_{\sag} = \stg_{\sag}$; 
    \item for all $\sag\in D$, $ \ut_i(\stgp' \mid \sigi_D) > \ut_i(\stgp \mid \sigi_D)$,
\end{enumerate}
where $\ut_i(\stgp \mid \sigi_D)$ is $i$'s expected utility conditioned on he/she knows the types of all the deviators in $D$. 
\end{definition}

When $\mathcal{D} = \{\{i\}\mid i \in [n]\}$ contains only singletons, interim $\mathcal{D}$ equilibrium is exactly the Bayesian Nash equilibrium. On the other hand, we show that for any $\mathcal{D}$ containing a group of at least two agents, truthful reporting fails to be an interim $\mathcal{D}$ equilibrium. 

\begin{prop}
    In the peer prediction mechanism, assume $\ps(h, \vpr_h) > \ps(\ell, \vpr_h)$ and $\ps(\ell, \vpr_\ell) > \ps(h, \vpr_\ell)$. Then for any constant $d \ge 2$ any $\mathcal{D}$ such that there exists a $D\in \mathcal{D}$ with $|D|=d$, and for all sufficiently large $\ag$, truthful reporting is NOT an interim $\mathcal{D}$ equilibrium.
\end{prop}

\begin{proof}
    Let $D\in \mathcal{D}$ such that $|D| = d$ be a deviate group. Suppose there are $d_1 > 0$ agents with signal $h$ and $d_2 > 0$ agents with signal $\ell$. $d_1 + d_2 = |D|$. 

    Now consider the expected utility when every agent reports truthfully. For agent $i$ with signal $h$, $i$'s reward from other deviators is $\frac{d_1 -1}{\ag -1}\cdot \ps(h, \vpr_h) + \frac{d_2}{\ag - 1}\cdot \ps(\ell, \vpr_h)$. And $i$'s reward from truthful reporter is $\frac{\ag - |D|}{\ag - 1} \cdot (\pr(h\mid \sigi_D)\cdot \ps(h, \vpr_h) + \pr(\ell \mid \sigi_D)\cdot \ps(\ell, \vpr_h))$. Similarly, with agent $i$ with signal $\ell$, $i$'s reward from other deviators is $\frac{d_1}{\ag -1}\cdot \ps(h, \vpr_\ell) + \frac{d_2 - 1}{\ag - 1}\cdot \ps(\ell, \vpr_\ell)$. And $i$'s reward from truthful reporter is $\frac{\ag - |D|}{\ag - 1} \cdot (\pr(h\mid \sigi_D)\cdot \ps(h, \vpr_\ell) + \pr(\ell \mid \sigi_D)\cdot \ps(\ell, \vpr_\ell))$.

    Now we consider the deviating strategy. If $\pr(h\mid \sigi_D)\cdot \ps(h, \vpr_h) + \pr(\ell \mid \sigi_D)\cdot \ps(\ell, \vpr_h) > \pr(h\mid \sigi_D)\cdot \ps(h, \vpr_\ell) + \pr(\ell \mid \sigi_D)\cdot \ps(\ell, \vpr_\ell)$, then all the deviators report $h$. If $\pr(h\mid \sigi_D)\cdot \ps(h, \vpr_h) + \pr(\ell \mid \sigi_D)\cdot \ps(\ell, \vpr_h) < \pr(h\mid \sigi_D)\cdot \ps(h, \vpr_\ell) + \pr(\ell \mid \sigi_D)\cdot \ps(\ell, \vpr_\ell)$, then all the deviators report $\ell$. If $\pr(h\mid \sigi_D)\cdot \ps(h, \vpr_h) + \pr(\ell \mid \sigi_D)\cdot \ps(\ell, \vpr_h) = \pr(h\mid \sigi_D)\cdot \ps(h, \vpr_\ell) + \pr(\ell \mid \sigi_D)\cdot \ps(\ell, \vpr_\ell)$, all the deviators report $h$ if $\ps(h, \vpr_h)\ge \ps(\ell, \vpr_\ell)$ and report $\ell$ otherwise. 
    We show that in this case, the deviation succeeds. 

    \noindent\textbf{Case 1.} Suppose $\pr(h\mid \sigi_D)\cdot \ps(h, \vpr_h) + \pr(\ell \mid \sigi_D)\cdot \ps(\ell, \vpr_h) > \pr(h\mid \sigi_D)\cdot \ps(h, \vpr_\ell) + \pr(\ell \mid \sigi_D)\cdot \ps(\ell, \vpr_\ell)$.
    We consider the changes on the expected utility after the deviators switch from truthful reporting to the deviating strategy. 
    Then for agents with signal $h$, the expected utility from the truthful reporters is unchanged, and the expected utility from other deviators becomes $\frac{d - 1}{\ag - 1}\ps(h, \vpr_h)$, which has been strictly increased. For agents with signal $\ell$, the expected utility from the truthful reporters strictly increases by a constant factor, while the changes in expected utility from other deviators is $\Theta(\frac{d}{\ag}) = \frac{1}{\ag})$. Therefore, the sufficiently large $\ag$, the expected utility for agents with signal $\ell$ also strictly increases. 

    \noindent\textbf{Case 2} follows similar reasoning to Case 1.

    \noindent\textbf{Case 3}. Suppose $\pr(h\mid \sigi_D)\cdot \ps(h, \vpr_h) + \pr(\ell \mid \sigi_D)\cdot \ps(\ell, \vpr_h) = \pr(h\mid \sigi_D)\cdot \ps(h, \vpr_\ell) + \pr(\ell \mid \sigi_D)\cdot \ps(\ell, \vpr_\ell)$ In this case, for both type of agents, the expected utility from truthful reporters is unchanged, and the expected utility from other deviators strictly increases. 

    Therefore, we show that in all cases, there exists a group of agents in $\mathcal{D}$ wish to deviate. Therefore, truthful reporting is not an interim $\mathcal{D}$ equilibrium.  
\end{proof}
