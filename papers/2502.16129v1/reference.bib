@inproceedings{wang2022dpcnet,
  title={DPCNet: Dual Path Multi-Excitation Collaborative Network for Facial Expression Representation Learning in Videos},
  author={Wang, Yan and Sun, Yixuan and Song, Wei and Gao, Shuyong and Huang, Yiwen and Chen, Zhaoyu and Ge, Weifeng and Zhang, Wenqiang},
  booktitle={Proceedings of the 30th ACM International Conference on Multimedia},
  pages={101--110},
  year={2022}
}

@inproceedings{jiang2020dfew,
  title={Dfew: A large-scale database for recognizing dynamic facial expressions in the wild},
  author={Jiang, Xingxun and Zong, Yuan and Zheng, Wenming and Tang, Chuangao and Xia, Wanchuang and Lu, Cheng and Liu, Jiateng},
  booktitle={Proceedings of the 28th ACM International Conference on Multimedia},
  pages={2881--2889},
  year={2020}
}

@article{li2022intensity,
  title={Intensity-Aware Loss for Dynamic Facial Expression Recognition in the Wild},
  author={Li, Hanting and Niu, Hongjing and Zhu, Zhaoqing and Zhao, Feng},
  journal={arXiv preprint arXiv:2208.10335},
  year={2022}
}

@article{ma2022spatio,
  title={Spatio-Temporal Transformer for Dynamic Facial Expression Recognition in the Wild},
  author={Ma, Fuyan and Sun, Bin and Li, Shutao},
  journal={arXiv preprint arXiv:2205.04749},
  year={2022}
}

@article{li2022nr,
  title={NR-DFERNet: Noise-Robust Network for Dynamic Facial Expression Recognition},
  author={Li, Hanting and Sui, Mingzhe and Zhu, Zhaoqing and others},
  journal={arXiv preprint arXiv:2206.04975},
  year={2022}
}

@inproceedings{zhao2021former,
  title={Former-dfer: Dynamic facial expression recognition transformer},
  author={Zhao, Zengqun and Liu, Qingshan},
  booktitle={Proceedings of the 29th ACM International Conference on Multimedia},
  pages={1553--1561},
  year={2021}
}

@inproceedings{wang2022ferv39k,
  title={FERV39k: A Large-Scale Multi-Scene Dataset for Facial Expression Recognition in Videos},
  author={Wang, Yan and Sun, Yixuan and Huang, Yiwen and Liu, Zhongying and Gao, Shuyong and Zhang, Wei and Ge, Weifeng and Zhang, Wenqiang},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={20922--20931},
  year={2022}
}

@INPROCEEDINGS{8756551,
  author={Lee, Min Kyu and Yoon Choi, Dong and Kim, Dae Ha and Cheol Song, Byung},
  booktitle={2019 14th IEEE International Conference on Automatic Face \& Gesture Recognition (FG 2019)}, 
  title={Visual Scene-aware Hybrid Neural Network Architecture for Video-based Facial Expression Recognition}, 
  year={2019},
  volume={},
  number={},
  pages={1-8},
  doi={10.1109/FG.2019.8756551}
}

@inproceedings{10.1145/3242969.3264992,
author = {Lu, Cheng and Zheng, Wenming and Li, Chaolong and Tang, Chuangao and Liu, Suyuan and Yan, Simeng and Zong, Yuan},
title = {Multiple Spatio-Temporal Feature Learning for Video-Based Emotion Recognition in the Wild},
year = {2018},
isbn = {9781450356923},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3242969.3264992},
doi = {10.1145/3242969.3264992},
booktitle = {Proceedings of the 20th ACM International Conference on Multimodal Interaction},
pages = {646–652},
numpages = {7},
keywords = {spatio-temporal information, 3d convolutional neural networks (3d cnn), convolutional neural networks (cnn), long short-term memory (lstm), emotion recognition},
location = {Boulder, CO, USA},
series = {ICMI '18}
}
@inproceedings{wang2019multi,
  title={Multi-attention fusion network for video-based emotion recognition},
  author={Wang, Yanan and Wu, Jianming and Hoashi, Keiichiro},
  booktitle={2019 International Conference on Multimodal Interaction},
  pages={595--601},
  year={2019}
}

@article{zhang2018spatial,
  title={Spatial--temporal recurrent neural network for emotion recognition},
  author={Zhang, Tong and Zheng, Wenming and Cui, Zhen and Zong, Yuan and Li, Yang},
  journal={IEEE transactions on cybernetics},
  volume={49},
  number={3},
  pages={839--847},
  year={2018},
  publisher={IEEE}
}

@inproceedings{fan2016video,
  title={Video-based emotion recognition using CNN-RNN and C3D hybrid networks},
  author={Fan, Yin and Lu, Xiangju and Li, Dian and Liu, Yuanliu},
  booktitle={Proceedings of the 18th ACM international conference on multimodal interaction},
  pages={445--450},
  year={2016}
}

@inproceedings{lee2019context,
  title={Context-aware emotion recognition networks},
  author={Lee, Jiyoung and Kim, Seungryong and Kim, Sunok and Park, Jungin and Sohn, Kwanghoon},
  booktitle={Proceedings of the IEEE/CVF international conference on computer vision},
  pages={10143--10152},
  year={2019}
}

@article{gadermayr2022multiple,
  title={Multiple Instance Learning for Digital Pathology: A Review on the State-of-the-Art, Limitations \& Future Potential},
  author={Gadermayr, Michael and Tschuchnig, Maximilian},
  journal={arXiv preprint arXiv:2206.04425},
  year={2022}
}

@inproceedings{feng2022weakly,
  title={Weakly Supervised Rotation-Invariant Aerial Object Detection Network},
  author={Feng, Xiaoxu and Yao, Xiwen and Cheng, Gong and Han, Junwei},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={14146--14155},
  year={2022}
}

@inproceedings{tang2017multiple,
  title={Multiple instance detection network with online instance classifier refinement},
  author={Tang, Peng and Wang, Xinggang and Bai, Xiang and Liu, Wenyu},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={2843--2851},
  year={2017}
}

@inproceedings{zhao2020predicting,
  title={Predicting lymph node metastasis using histopathological images based on multiple instance learning with deep graph convolution},
  author={Zhao, Yu and Yang, Fan and Fang, Yuqi and Liu, Hailing and Zhou, Niyun and Zhang, Jun and Sun, Jiarui and Yang, Sen and Menze, Bjoern and Fan, Xinjuan and others},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={4837--4846},
  year={2020}
}

@inproceedings{zhang2022dtfd,
  title={DTFD-MIL: Double-Tier Feature Distillation Multiple Instance Learning for Histopathology Whole Slide Image Classification},
  author={Zhang, Hongrun and Meng, Yanda and Zhao, Yitian and Qiao, Yihong and Yang, Xiaoyun and Coupland, Sarah E and Zheng, Yalin},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={18802--18812},
  year={2022}
}

@inproceedings{luo2020weakly,
  title={Weakly-supervised action localization with expectation-maximization multi-instance learning},
  author={Luo, Zhekun and Guillory, Devin and Shi, Baifeng and Ke, Wei and Wan, Fang and Darrell, Trevor and Xu, Huijuan},
  booktitle={European conference on computer vision},
  pages={729--745},
  year={2020},
  organization={Springer}
}

@article{van2008visualizing,
  title={Visualizing data using t-SNE.},
  author={Van der Maaten, Laurens and Hinton, Geoffrey},
  journal={Journal of machine learning research},
  volume={9},
  number={11},
  year={2008}
}

@inproceedings{tran2015learning,
  title={Learning spatiotemporal features with 3d convolutional networks},
  author={Tran, Du and Bourdev, Lubomir and Fergus, Rob and Torresani, Lorenzo and Paluri, Manohar},
  booktitle={Proceedings of the IEEE international conference on computer vision},
  pages={4489--4497},
  year={2015}
}

@inproceedings{qiu2017learning,
  title={Learning spatio-temporal representation with pseudo-3d residual networks},
  author={Qiu, Zhaofan and Yao, Ting and Mei, Tao},
  booktitle={proceedings of the IEEE International Conference on Computer Vision},
  pages={5533--5541},
  year={2017}
}

@inproceedings{carreira2017quo,
  title={Quo vadis, action recognition? a new model and the kinetics dataset},
  author={Carreira, Joao and Zisserman, Andrew},
  booktitle={proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={6299--6308},
  year={2017}
}

@inproceedings{tran2018closer,
  title={A closer look at spatiotemporal convolutions for action recognition},
  author={Tran, Du and Wang, Heng and Torresani, Lorenzo and Ray, Jamie and LeCun, Yann and Paluri, Manohar},
  booktitle={Proceedings of the IEEE conference on Computer Vision and Pattern Recognition},
  pages={6450--6459},
  year={2018}
}

@inproceedings{hara2018can,
  title={Can spatiotemporal 3d cnns retrace the history of 2d cnns and imagenet?},
  author={Hara, Kensho and Kataoka, Hirokatsu and Satoh, Yutaka},
  booktitle={Proceedings of the IEEE conference on Computer Vision and Pattern Recognition},
  pages={6546--6555},
  year={2018}
}

@article{wang2022systematic,
  title={A systematic review on affective computing: Emotion models, databases, and recent advances},
  author={Wang, Yan and Song, Wei and Tao, Wei and Liotta, Antonio and Yang, Dawei and Li, Xinlei and Gao, Shuyong and Sun, Yixuan and Ge, Weifeng and Zhang, Wei and others},
  journal={Information Fusion},
  year={2022},
  publisher={Elsevier}
}

@article{gao2022weakly,
  title={Weakly-Supervised Salient Object Detection Using Point Supervison},
  author={Gao, Shuyong and Zhang, Wei and Wang, Yan and Guo, Qianyu and Zhang, Chenglong and He, Yangji and Zhang, Wenqiang},
  journal={arXiv preprint arXiv:2203.11652},
  year={2022}
}

@article{liu2022opo,
  title={OPO-FCM: A Computational Affection Based OCC-PAD-OCEAN Federation Cognitive Modeling Approach},
  author={Liu, Feng and Wang, Han-Yang and Shen, Si-Yuan and Jia, Xun and Hu, Jing-Yi and Zhang, Jia-Hao and Wang, Xi-Yi and Lei, Ying and Zhou, Ai-Min and Qi, Jia-Yin and others},
  journal={IEEE Transactions on Computational Social Systems},
  year={2022},
  publisher={IEEE}
}

@article{liu2022lgcct,
  title={LGCCT: A Light Gated and Crossed Complementation Transformer for Multimodal Speech Emotion Recognition},
  author={Liu, Feng and Shen, Si-Yuan and Fu, Zi-Wang and Wang, Han-Yang and Zhou, Ai-Min and Qi, Jia-Yin},
  journal={Entropy},
  volume={24},
  number={7},
  pages={1010},
  year={2022},
  publisher={MDPI}
}










@article{
doi:10.34133/icomputing.0073,
author = {Siyuan Shen  and Feng Liu  and Hanyang Wang  and Yunlong Wang  and Aimin Zhou },
title = {Temporal Shift Module with Pretrained Representations for Speech Emotion Recognition},
journal = {Intelligent Computing},
volume = {3},
number = {},
pages = {0073},
year = {2024},
doi = {10.34133/icomputing.0073},
URL = {https://spj.science.org/doi/abs/10.34133/icomputing.0073},
eprint = {https://spj.science.org/doi/pdf/10.34133/icomputing.0073},
abstract = {Recent advances in self-supervised models have led to effective pretrained speech representations in downstream speech emotion recognition tasks. However, previous research has primarily focused on exploiting pretrained representations by simply adding a linear head on top of the pretrained model, while overlooking the design of the downstream network. In this paper, we propose a temporal shift module with pretrained representations to integrate channel-wise information without introducing additional parameters or floating-point operations per second. By incorporating the temporal shift module, we developed corresponding shift variants for 3 baseline building blocks: ShiftCNN, ShiftLSTM, and Shiftformer. Furthermore, we propose 2 technical strategies, placement and proportion of shift, to balance the trade-off between mingling and misalignment. Our family of temporal shift models outperforms state-of-the-art methods on the benchmark Interactive Emotional Dyadic Motion Capture dataset in fine-tuning and feature-extraction scenarios. In addition, through comprehensive experiments using wav2vec 2.0 and Hidden-Unit Bidirectional Encoder Representations from Transformers representations, we identified the behavior of the temporal shift module in downstream models, which may serve as an empirical guideline for future exploration of channel-wise shift and downstream network design.}}

@misc{lautman2022use,
  title={The Use of Smart Devices for Mental Health Diagnosis and Care},
  author={Lautman, Ziv and Lev-Ari, Shahar},
  journal={Journal of Clinical Medicine},
  volume={11},
  number={18},
  pages={5359},
  year={2022},
  publisher={MDPI}
}

@article{li2021novel,
  title={A novel learning model of driver fatigue features representation for steering wheel angle},
  author={Li, Zuojin and Chen, Liukui and Nie, Ling and Yang, Simon X},
  journal={IEEE Transactions on Vehicular Technology},
  volume={71},
  number={1},
  pages={269--281},
  year={2021},
  publisher={IEEE}
}

@inproceedings{fang2021metahuman,
  title={MetaHuman Creator The starting point of the metaverse},
  author={Fang, Zhixin and Cai, Libai and Wang, Gang},
  booktitle={2021 International Symposium on Computer Technology and Information Science (ISCTIS)},
  pages={154--157},
  year={2021},
  organization={IEEE}
}

@article{liu2022evogan,
  title={EvoGAN: An evolutionary computation assisted GAN},
  author={Liu, Feng and Wang, Hanyang and Zhang, Jiahao and Fu, Ziwang and Zhou, Aimin and Qi, Jiayin and Li, Zhibin},
  journal={Neurocomputing},
  volume={469},
  pages={81--90},
  year={2022},
  publisher={Elsevier}
}

@inproceedings{li2022towards,
  title={Towards Semi-Supervised Deep Facial Expression Recognition with An Adaptive Confidence Margin},
  author={Li, Hangyu and Wang, Nannan and Yang, Xi and Wang, Xiaoyu and Gao, Xinbo},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={4166--4175},
  year={2022}
}

@inproceedings{wang2020suppressing,
  title={Suppressing uncertainties for large-scale facial expression recognition},
  author={Wang, Kai and Peng, Xiaojiang and Yang, Jianfei and Lu, Shijian and Qiao, Yu},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={6897--6906},
  year={2020}
}

@inproceedings{luo2018differentiable,
  title={Differentiable Learning-to-Normalize via Switchable Normalization},
  author={Luo, Ping and Ren, Jiamin and Peng, Zhanglin and Zhang, Ruimao and Li, Jingyu},
  booktitle={International Conference on Learning Representations},
  year={2018}
}

@inproceedings{lin2019tsm,
  title={Tsm: Temporal shift module for efficient video understanding},
  author={Lin, Ji and Gan, Chuang and Han, Song},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={7083--7093},
  year={2019}
}

@article{chang2017active,
  title={Active bias: Training more accurate neural networks by emphasizing high variance samples},
  author={Chang, Haw-Shiuan and Learned-Miller, Erik and McCallum, Andrew},
  journal={Advances in Neural Information Processing Systems},
  volume={30},
  year={2017}
}

@inproceedings{zhang2021dualgraph,
  title={Dualgraph: A graph-based method for reasoning about label noise},
  author={Zhang, HaiYang and Xing, XiMing and Liu, Liang},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={9654--9663},
  year={2021}
}

@inproceedings{arazo2019unsupervised,
  title={Unsupervised label noise modeling and loss correction},
  author={Arazo, Eric and Ortego, Diego and Albert, Paul and O’Connor, Noel and McGuinness, Kevin},
  booktitle={International conference on machine learning},
  pages={312--321},
  year={2019},
  organization={PMLR}
}

@inproceedings{song2019selfie,
  title={Selfie: Refurbishing unclean samples for robust deep learning},
  author={Song, Hwanjun and Kim, Minseok and Lee, Jae-Gil},
  booktitle={International Conference on Machine Learning},
  pages={5907--5915},
  year={2019},
  organization={PMLR}
}

@inproceedings{chen2021beyond,
  title={Beyond class-conditional assumption: A primary attempt to combat instance-dependent label noise},
  author={Chen, Pengfei and Ye, Junjie and Chen, Guangyong and Zhao, Jingwei and Heng, Pheng-Ann},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={35},
  number={13},
  pages={11442--11450},
  year={2021}
}

@article{han2018co,
  title={Co-teaching: Robust training of deep neural networks with extremely noisy labels},
  author={Han, Bo and Yao, Quanming and Yu, Xingrui and Niu, Gang and Xu, Miao and Hu, Weihua and Tsang, Ivor and Sugiyama, Masashi},
  journal={Advances in neural information processing systems},
  volume={31},
  year={2018}
}

@inproceedings{jiang2018mentornet,
  title={Mentornet: Learning data-driven curriculum for very deep neural networks on corrupted labels},
  author={Jiang, Lu and Zhou, Zhengyuan and Leung, Thomas and Li, Li-Jia and Fei-Fei, Li},
  booktitle={International conference on machine learning},
  pages={2304--2313},
  year={2018},
  organization={PMLR}
}

@inproceedings{yu2019does,
  title={How does disagreement help generalization against label corruption?},
  author={Yu, Xingrui and Han, Bo and Yao, Jiangchao and Niu, Gang and Tsang, Ivor and Sugiyama, Masashi},
  booktitle={International Conference on Machine Learning},
  pages={7164--7173},
  year={2019},
  organization={PMLR}
}

@article{2023Facial,
  title={Facial optical flow estimation via neural non-rigid registration},
  author={ Peng, Zhuang  and  Jiang, Boyi  and  Xu, Haofei  and  Feng, Wanquan  and  Zhang, Juyong },
  journal={Computational Visual Media},
  volume={9},
  number={1},
  pages={109-122},
  year={2023},
}

@inproceedings{wei2020combating,
  title={Combating noisy labels by agreement: A joint training method with co-regularization},
  author={Wei, Hongxin and Feng, Lei and Chen, Xiangyu and An, Bo},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={13726--13735},
  year={2020}
}

@article{wei2021robust,
  title={Robust long-tailed learning under label noise},
  author={Wei, Tong and Shi, Jiang-Xin and Tu, Wei-Wei and Li, Yu-Feng},
  journal={arXiv preprint arXiv:2108.11569},
  year={2021}
}

@article{karthik2021learning,
  title={Learning from long-tailed data with noisy labels},
  author={Karthik, Shyamgopal and Revaud, Jerome and Chidlovskii, Boris},
  journal={arXiv preprint arXiv:2108.11096},
  year={2021}
}

@inproceedings{yi2022identifying,
  title={Identifying Hard Noise in Long-Tailed Sample Distribution},
  author={Yi, Xuanyu and Tang, Kaihua and Hua, Xian-Sheng and Lim, Joo-Hwee and Zhang, Hanwang},
  booktitle={Computer Vision--ECCV 2022: 17th European Conference, Tel Aviv, Israel, October 23--27, 2022, Proceedings, Part XXVI},
  pages={739--756},
  year={2022},
  organization={Springer}
}

@article{malach2017decoupling,
  title={Decoupling" when to update" from" how to update"},
  author={Malach, Eran and Shalev-Shwartz, Shai},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}

@inproceedings{10.1145/3551876.3554813,
author = {Wu, Yang and Zhang, Zhenyu and Peng, Pai and Zhao, Yanyan and Qin, Bing},
title = {Leveraging Multi-Modal Interactions among the Intermediate Representations of Deep Transformers for Emotion Recognition},
year = {2022},
isbn = {9781450394840},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3551876.3554813},
doi = {10.1145/3551876.3554813},
pages = {101–109},
numpages = {9},
keywords = {multi-modal emotion recognition, multi-modal fusion},
location = {Lisboa, Portugal},
series = {MuSe' 22}
}

@inproceedings{10.1145/3503161.3547936,
author = {Chen, Yuedong and Yang, Xu and Cham, Tat-Jen and Cai, Jianfei},
title = {Towards Unbiased Visual Emotion Recognition via Causal Intervention},
year = {2022},
isbn = {9781450392037},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3503161.3547936},
doi = {10.1145/3503161.3547936},
pages = {60–69},
numpages = {10},
keywords = {image emotion recognition, causal intervention, dataset bias, facial expression recognition, backdoor adjustment},
location = {Lisboa, Portugal},
series = {MM '22}
}

@inproceedings{10.1145/3503161.3547754,
author = {Yang, Dingkang and Huang, Shuai and Kuang, Haopeng and Du, Yangtao and Zhang, Lihua},
title = {Disentangled Representation Learning for Multimodal Emotion Recognition},
year = {2022},
isbn = {9781450392037},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3503161.3547754},
doi = {10.1145/3503161.3547754},
booktitle = {Proceedings of the 30th ACM International Conference on Multimedia},
pages = {1642–1651},
numpages = {10},
keywords = {disentangled representation learning, multimodal fusion, adversarial learning, emotion recognition},
location = {Lisboa, Portugal},
series = {MM '22}
}

@inproceedings{10.1145/3503161.3548243,
author = {Li, Rui and Wang, Yiting and Zheng, Wei-Long and Lu, Bao-Liang},
title = {A Multi-View Spectral-Spatial-Temporal Masked Autoencoder for Decoding Emotions with Self-Supervised Learning},
year = {2022},
isbn = {9781450392037},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3503161.3548243},
doi = {10.1145/3503161.3548243},
booktitle = {Proceedings of the 30th ACM International Conference on Multimedia},
pages = {6–14},
numpages = {9},
keywords = {self-supervised learning, eeg-based emotion recognition, affective computing, cnn-transformer},
location = {Lisboa, Portugal},
series = {MM '22}
}

@inproceedings{10.1145/3503161.3551572,
author = {Gr\'{o}sz, Tam\'{a}s and Porjazovski, Dejan and Getman, Yaroslav and Kadiri, Sudarsana and Kurimo, Mikko},
title = {Wav2vec2-Based Paralinguistic Systems to Recognise Vocalised Emotions and Stuttering},
year = {2022},
isbn = {9781450392037},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3503161.3551572},
doi = {10.1145/3503161.3551572},
booktitle = {Proceedings of the 30th ACM International Conference on Multimedia},
pages = {7026–7029},
numpages = {4},
keywords = {stuttering, wav2vec2, data augmentation, challenge, computational paralinguistics, vocalisations},
location = {Lisboa, Portugal},
series = {MM '22}
}

@inproceedings{wang2023rethinking,
  title={Rethinking the learning paradigm for dynamic facial expression recognition},
  author={Wang, Hanyang and Li, Bo and Wu, Shuang and Shen, Siyuan and Liu, Feng and Ding, Shouhong and Zhou, Aimin},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={17958--17968},
  year={2023}
}

@INPROCEEDINGS{10094303,
  author={Zhao, Yaochi and Chen, Sen and Chen, Qiong and Hu, Zhuhua},
  booktitle={ICASSP 2023 - 2023 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}, 
  title={Combining Loss Reweighting and Sample Resampling for Long-Tailed Instance Segmentation}, 
  year={2023},
  volume={},
  number={},
  pages={1-5},
  keywords={Training data;Tail;Signal processing;Probabilistic logic;Sampling methods;Acoustics;Speech processing;Computer Vision;Instance Segmentation;Long-tailed Distribution;Reweighting;Resampling},
  doi={10.1109/ICASSP49357.2023.10094303}}

@ARTICLE{9325065,
  author={Liu, Xinda and Min, Weiqing and Mei, Shuhuan and Wang, Lili and Jiang, Shuqiang},
  journal={IEEE Transactions on Image Processing}, 
  title={Plant Disease Recognition: A Large-Scale Benchmark Dataset and a Visual Region and Loss Reweighting Approach}, 
  year={2021},
  volume={30},
  number={},
  pages={2003-2015},
  keywords={Diseases;Agriculture;Plants (biology);Visualization;Image recognition;Feature extraction;Medical diagnosis;Plant disease recognition;fine-grained visual classification;reweighting approach;feature aggregation},
  doi={10.1109/TIP.2021.3049334}}

@ARTICLE{10516662,
  author={Chen, Mingcai and Zhao, Yu and He, Bing and Han, Zongbo and Huang, Junzhou and Wu, Bingzhe and Yao, Jianhua},
  journal={IEEE Transactions on Neural Networks and Learning Systems}, 
  title={Learning With Noisy Labels Over Imbalanced Subpopulations}, 
  year={2024},
  volume={},
  number={},
  pages={1-12},
  keywords={Noise measurement;Noise;Training;Tail;Optimization;Predictive models;Estimation;Distributionally robust optimization (DRO);label refurbishment;learning with noisy labels (LNLs);subpopulation imbalance},
  doi={10.1109/TNNLS.2024.3389676}}

@ARTICLE{10443531,
  author={Liu, Huafeng and Sheng, Mengmeng and Sun, Zeren and Yao, Yazhou and Hua, Xian-Sheng and Shen, Heng-Tao},
  journal={IEEE Transactions on Multimedia}, 
  title={Learning With Imbalanced Noisy Data by Preventing Bias in Sample Selection}, 
  year={2024},
  volume={26},
  number={},
  pages={7426-7437},
  keywords={Noise measurement;Training;Tail;Predictive models;Data models;Sun;Self-supervised learning;Imbalanced label noise;class-balance-based sample selection;confidence-based sample augmentation;consistency regularization;average confidence margin},
  doi={10.1109/TMM.2024.3368910}}

@article{Zhang2017FacialER,
  title={Facial Expression Recognition Based on Deep Evolutional Spatial-Temporal Networks},
  author={Kaihao Zhang and Yongzhen Huang and Yong Du and Liang Wang},
  journal={IEEE Transactions on Image Processing},
  year={2017},
  volume={26},
  pages={4193-4203},
  url={https://api.semanticscholar.org/CorpusID:2609831}
}

@article{Liu2024, 
author = {Feng Liu},
title = {Artificial Intelligence in Emotion Quantification : A Prospective Overview},
year = {2024},
journal = {CAAI Artificial Intelligence Research},
volume = {3},
pages = {9150040},
keywords = {affect quantification, multi-modal emotion recognition, computational affection, computational psychiatry},
url = {https://www.sciopen.com/article/10.26599/AIR.2024.9150040},
doi = {10.26599/AIR.2024.9150040},
abstract = {The field of Artificial Intelligence (AI) is witnessing a rapid evolution in the field of emotion quantification. New possibilities for understanding and parsing human emotions are emerging from advances in this technology. Multi-modal data sources, including facial expressions, speech, text, gestures, and physiological signals, are combined with machine learning and deep learning methods in modern emotion recognition systems. These systems achieve accurate recognition of emotional states in a wide range of complex environments. This paper provides a comprehensive overview of research advances in multi-modal emotion recognition techniques. This serves as a foundation for an in-depth discussion combining the field of AI with the quantification of emotion, a focus of attention in the field of psychology. It also explores the privacy and ethical issues faced during the processing and analysis of emotion data, and the implications of these challenges for future research directions. In conclusion, the objective of this paper is to adopt a forward-looking perspective on the development trajectory of AI in the field of emotion quantification, and also point out the potential value of emotion quantification research in a number of areas, including emotion quantification platforms and tools, computational psychology, and computational psychiatry.}
}

@article{Wang2023HTNetFM,
  title={HTNet for micro-expression recognition},
  author={Zhifeng Wang and Kaihao Zhang and Wenhan Luo and Ramesh S. Sankaranarayana},
  journal={ArXiv},
  year={2023},
  volume={abs/2307.14637},
  url={https://api.semanticscholar.org/CorpusID:257749888}
}

@inproceedings{zhang2025generalizable,
 title={Generalizable Facial Expression Recognition},
 author={Zhang, Yuhang and Zheng, Xiuqi and Liang, Chenyi and Hu, Jiani and Deng, Weihong},
 booktitle={European Conference on Computer Vision},
 pages={231--248},
 year={2025},
 organization={Springer}
}


@article{LIU2024101452,
title = {Artificial intelligence in mental health: innovations brought by artificial intelligence techniques in stress detection and interventions of building resilience},
journal = {Current Opinion in Behavioral Sciences},
volume = {60},
pages = {101452},
year = {2024},
issn = {2352-1546},
doi = {https://doi.org/10.1016/j.cobeha.2024.101452},
url = {https://www.sciencedirect.com/science/article/pii/S2352154624001037},
author = {Feng Liu and Qianqian Ju and Qijian Zheng and Yujia Peng},
abstract = {The last few decades have witnessed a revolution in the field of mental health, brought about by state-of-the-art techniques of artificial intelligence (AI). Here, we review the evidence for the systematic application of AI for the detection and intervention of stress-related mental health problems. We first explore the potential application of AI in stress detection and screening through advanced computational techniques of machine learning algorithms that analyze biomarkers of stress and anxiety. Building on the accurate detection of mental health problems, we further review the evidence for AI-based stress interventions and propose the promising prospect of applying decoded neurofeedback as a personalized resilience-building intervention. Together, the current review assesses the effectiveness and major challenges of AI technologies in real-world applications and demonstrates the transforming impact of AI on the field of mental health.}
}

@article{zhang2024leave,
 title={Leave no stone unturned: mine extra knowledge for imbalanced facial expression recognition},
 author={Zhang, Yuhang and Li, Yaqi and Liu, Xuannan and Deng, Weihong and others},
 journal={Advances in Neural Information Processing Systems},
 volume={36},
 year={2024}
}

@inproceedings{zhang2024open,
 title={Open-set facial expression recognition},
 author={Zhang, Yuhang and Yao, Yue and Liu, Xuannan and Qin, Lixiong and Wang, Wenjing and Deng, Weihong},
 booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
 volume={38},
 number={1},
 pages={646--654},
 year={2024}
}

@InProceedings{10.1007/978-3-031-19809-0_24,
author="Zhang, Yuhang
and Wang, Chengrui
and Ling, Xu
and Deng, Weihong",
editor="Avidan, Shai
and Brostow, Gabriel
and Ciss{\'e}, Moustapha
and Farinella, Giovanni Maria
and Hassner, Tal",
title="Learn from All: Erasing Attention Consistency for Noisy Label Facial Expression Recognition",
booktitle="Computer Vision -- ECCV 2022",
year="2022",
publisher="Springer Nature Switzerland",
address="Cham",
pages="418--434"
}

@inproceedings{NEURIPS2021_9332c513,
 author = {Zhang, Yuhang and Wang, Chengrui and Deng, Weihong},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {M. Ranzato and A. Beygelzimer and Y. Dauphin and P.S. Liang and J. Wortman Vaughan},
 pages = {17616--17627},
 publisher = {Curran Associates, Inc.},
 title = {Relative Uncertainty Learning for Facial Expression Recognition},
 url = {https://proceedings.neurips.cc/paper_files/paper/2021/file/9332c513ef44b682e9347822c2e457ac-Paper.pdf},
 volume = {34},
 year = {2021}
}