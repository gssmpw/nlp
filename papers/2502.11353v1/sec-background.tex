\section{Background}
\label{sec-spz-background}

%This section provides background on recent matrix ISA extensions and three
%common SpGEMM dataflows: inner-product, outer-product, and row-wise-product.
This section provides background on recent matrix ISA extensions and common
SpGEMM algorithms.

\subsection{Matrix ISA Extensions for Dense GEMM}

The importance of GEMM has led to an emergence of matrix extensions in
contemporary ISAs.
Arm recently released its SME extension that introduces a new instruction
performing an outer product of two vectors and accumulating its results into a
new two-dimensional accumulator register~\cite{arm-sme-web}.
IBM took a similar approach in its MMA extension for the Power
ISA~\cite{ibm-mmx-assist-web}.
Intel introduced a new AMX extension that adds several matrix registers called
tile registers and a new matrix-matrix multiply instruction on two tile
registers~\cite{intel-amx-web,nassif-intel-sapphire-isscc2022}.
The RISC-V community recently proposed a matrix extension that is similar to
Intel AMX's approach~\cite{riscv-mtx-ext-proposal-web}.
One common micro-architecture for accelerating dense-dense GEMM is a systolic
array, a grid of multiply-add processing elements (PEs) connected in a mesh
network~\cite{jouppi-datacenter-isca2017,jeong-rasa-dac2021,nassif-intel-sapphire-isscc2022}.
A systolic array can support either input-, weight-, or output-stationary
dataflows, depending on which input or output matrix stays inside the array
throughout the computation.

\subsection{SpGEMM Dataflows}

The inner-product dataflow computes each element in the output matrix by
performing a dot product between a row in the first input matrix and a
corresponding column in the second input matrix.
Multiple dot product operations for different output elements can happen in
parallel.
For highly sparse matrices, one major downside of this dataflow is that a dot
product of two highly sparse vectors is likely to produce a zero, which is
wasted.

The outer-product dataflow performs an outer product between a column in the
first input matrix and a corresponding row in the second input matrix to
produce a partial output matrix.
Multiple partial output matrices are then merged into a single matrix.
This dataflow avoids the wasted computation incurred in the inner-product
dataflow at the cost of highly complex merging operation of multiple matrices
and potentially significant memory space for storing partial matrices.

The row-wise-product dataflow (Gustavson algorithm) computes each row
of an output matrix by multiplying a row in the first input matrix with the
entire second input matrix (vector-matrix multiplication).
Similar to the outer-product dataflow, this row-wise-product dataflow is
work-efficient for highly sparse matrices since it processes only non-zero
input elements that contribute to non-zero output elements.
The vector-matrix multiplication involves merging multiple sparse vectors into
a single vector, which is less complex than merging multiple sparse matrices as
in the outer-product dataflow.
In addition, unlike both inner-product and outer-product dataflows, the
row-wise-product dataflow does not require two input matrices to be stored in
two different formats: CSR and CSC.
All input and output matrices can be consistently stored in CSR, so there is no
need for converting between different sparse matrix formats.
In this work, we target the row-wise-product dataflow.
