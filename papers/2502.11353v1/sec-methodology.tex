%=========================================================================
% SparseZipper: Evaluation methodology
%=========================================================================

\section{Evaluation Methodology}
\label{sec-spz-methodology}

In this section, we describe our simulated systems, cycle-level modeling
methodology, and matrix datasets used to evaluate the performance of
SparseZipper.

\subsection{Simulated Systems}
\input{tab-gem5}
\input{tab-datasets}

% gem5
We use gem5~\cite{binkert-gem5-sigarch2011, lowe-gem5-2020,
  ta-simulating-riscv-gem5-2018} to evaluate the performance of
SparseZipper. We use gem5's out-of-order core and configure it to model
an aggressive high-performance out-of-order Intel CPU with
state-of-the-art SIMD extensions (see Table~\ref{tbl-spz-gem5} for
baseline configuration). We model two 512-bit-wide SIMD execution units
integrated into the CPU pipeline with support for speculative
out-of-order execution of vector instructions. The simulated cache
subsystem is based on the Arm AMBA 5 CHI cache model provided in
gem5~\cite{chi-gem5}.

% for accelerating compute-intensive workloads like GEMM in high-end
% servers and data centers

% baseline matrix engine
\BF{Baseline systolic array for dense-dense GEMM --} As in previous
work~\cite{jeong-rasa-dac2021}, we model a systolic array with
16$\times$16 PEs similar in spirit to an implementation of Intel AMX in
Intel Saphhire Rapids~\cite{nassif-intel-sapphire-isscc2022}. Each PE
consists of a single-precision multiply-accumulate (MAC) unit with a
latency of four CPU cycles. There are 16 physical matrix registers, each
storing 16$\times$16 32-bit data.
% for a total of 1KB.
The baseline matrix register file supports two read ports and one write
port.
% Matrix registers can be renamed to avoid false dependencies.
% for matrix-matrix multiply instruction.
Since matrix registers are quite large, a reasonably area-efficient physical
implementation would include per-matrix-register 1r1w SRAMs and enough
crossbars for supporting two concurrent read and write accesses to two
different matrix registers.

% SparseZipper extension
%   - non-speculative instructions
%   - second write port
%   - indexed matrix load/store
\BF{Extended systolic array for SparseZipper --}
We model non-speculative execution of stream sorting and merging instructions
to simplify the hardware implementation.
% of special-purpose registers and systolic-array states.
These instructions wait until they are at the head of the ROB
% (i.e., no longer speculative)
before they are issued to the systolic array for execution. Once issued,
those instructions are placed into a retirement queue
% waiting for their
% execution (i.e., with no possible exception) to finish,
and subsequent instructions can continue to commit. We model extending
the matrix register file's crossbar to support the second write port. We
model a latency of one CPU cycle in each PE to process one pair of input
data when the PE executes the sorting and merging instructions since
those instructions do not use the PE's long-latency floating-point
multipler. Indexed matrix load and store instructions are broken into
row-wise micro-ops that are executed by the core's load-store unit.

\subsection{SpGEMM Implementations}

\BF{Scalar SpGEMM --} We evaluate two scalar row-wise implementations of
SpGEMM: \IT{scl-array} using dense
arrays~\cite{gilbert-sparse-matlab-1992} and \IT{scl-hash} using a hash
table with linear
probing~\cite{anh-hash-spgemm-2016,deveci-multithreaded-spgemm-2018} for
accumulating intermediate non-zero values in each output matrix row.
% In \IT{scl-hash}, we use with linear probing to solve hash collision.
% In both \IT{scl-array} and \IT{scl-hash},
After all intermediate non-zeros are accumulated for each output row,
they are sorted using a quick sort algorithm.

\BF{Vectorized Expand-Sort-Compress (ESC) SpGEMM --} We ported a
vectorized ESC implementation of SpGEMM, called \IT{vec-radix}, from
prior work~\cite{fevre-spgemm-rvv-2023}. The ESC algorithm was initially
proposed for performing SpGEMM on
GPUs~\cite{dalton-spgemm-gpu-2015,winter-adaptive-spgemm-gpu-ppopp2019}
and later adopted to vector
architectures~\cite{fevre-spgemm-rvv-2023,li-spgemm-vector-arch-mchpc2019}.
In ESC, multiple output rows are processed together to increase the
amount of parallelism, and the computation happens in three steps. First,
in the expansion step, results of multiplications are expanded in triples
of row index, column index, and value. Second, The list of triples are
sorted by their row and then column indices. This sorting step is often
vectorized using a fast radix sort~\cite{zaha-vector-rsort-sc1991}.
% which is vector-friendly.
Third, triples with duplicate keys (i.e., same row and column indices) are
compressed into one entry by accumulating the values.
In \IT{vec-radix}, there is a preprocessing step that calculates the amount of
work per block of output rows, determines the best block size, and allocates
enough temporary space for all intermediate results in a block.
Smaller block sizes limit the amount of parallelism,
% that can be vectorized
while larger block sizes can lead to thrashing the caches. We sweep the
block size for each input matrix and report the best performing
configuration.

\BF{Merge-based SpGEMM using SparseZipper --}
We implemented two versions of the merge-based row-wise dataflow SpGEMM using
the SparseZipper ISA extension: \IT{spz} and \IT{spz-rsort}.
In both versions, a preprocessing step calculates the amount of work for each
output row to allocate enough temporary memory space for intermediate results.
\IT{spz-rsort} additionally sorts row indices by the amount of
work calculated in the preprocessing step so that output rows with similar
amount of work can be processed together.
Only row indices are sorted, and the underlying matrix data is unchanged.
Once all output rows are computed, they are re-ordered by their row indices.
The sorting is done using a quick sort routine from the C++ standard library.
In both \IT{spz} and \IT{spz-rsort}, the expansion phase is vectorized using
the RISC-V vector extension while the merge phase is implemented using the
proposed SparseZipper instructions.

\subsection{Matrix Datasets}

We evaluate SparseZipper using matrices from
SuiteSparse~\cite{davis-suitesparse-2011} across multiple domains such as
road networks, scientific simulations, and social networks (see
Table~\ref{tab-spz-datasets}). This collection of matrices represents a
variety of sparsity levels and patterns. As in prior
work~\cite{srivastava-matraptor-micro2020, pal-outerspace-hpca2018,
  zhang-gamma-asplos2021}, we multiply each matrix with itself.
Table~\ref{tab-spz-datasets} reports the amount of work (i.e., the number
of multiplications needed) for each output row and for each group of 16
output rows. The table also shows the avarage number of non-zeros in
output matrices. The ratio of avarage work to the number of non-zeros per
row shows the degree in which duplicates in a stream of intermediate
non-zero values are compressed into a final stream of unique non-zero
values per output row.
