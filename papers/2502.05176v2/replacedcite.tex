\section{Related Work}
\label{sec:related}


% \subsection{Radiance Fields for Novel View Synthesis}
\noindent {\bf NeRF.}
Neural Radiance Fields (NeRF)____ revolutionized novel view synthesis via differentiable volume rendering____ and positional encoding____. NeRF models improved in efficiency____, rendering quality____, handling dynamic scenes____, and data efficiency____. Despite excelling at view synthesis, NeRF’s implicit representation complicates scene editing. Recent work on object manipulation____, stylization____, and inpainting____ struggles with 3D consistency and structural priors, especially in unbounded scenes.
% Neural Radiance Fields (NeRF)____ revolutionized novel view synthesis, enabling photorealistic scene reconstruction via differentiable volume rendering____ and positional encoding____. NeRF-based models have since improved in efficiency____, rendering quality____, and data efficiency____. While NeRF excels in view synthesis, its implicit volumetric representation complicates scene editing. Recent works on object manipulation____, stylization____, and inpainting____ face challenges in 3D inpainting in unbounded environments, as NeRF struggles with 3D consistency and leveraging explicit structural priors.


\vspace{3pt}
\noindent {\bf 3D Gaussian Splatting.}
3D Gaussian Splatting (3DGS)____ efficiently represents scenes with explicit 3D Gaussians, enabling faster rendering, easier training, and flexible editing____. Recent extensions like Scaffold-GS____ enhance efficiency with dynamic anchors, while 2DGS____ refines multi-view geometry. 3DGS has also expanded to dynamic scenes____ and semantic representations____, supporting advanced editing and novel view synthesis____. Gaussian-based methods thus offer strong potential for explicit 3D inpainting.
% 3D Gaussian Splatting (3DGS)____ is an efficient alternative to NeRF, representing scenes with explicit 3D Gaussians for faster rendering, easier training, and more flexible scene editing____. Recent extensions include Scaffold-GS____, which improves rendering efficiency with dynamic anchor points, and 2DGS____, which refines multi-view reconstructions for view-consistent geometry. 3DGS has also been extended to dynamic environments____ and semantic-aware representations____, advancing scene manipulation and novel view synthesis____. These advancements highlight the potential of Gaussian-based representations for explicit scene editing, making them well-suited for 3D inpainting tasks.

% \subsection{2D Image Inpainting}
% \paragraph{Traditional methods.}
% Image inpainting has evolved from early PDE-based techniques ____ to exemplar-based methods ____. Texture synthesis ____ and patch-based approaches like PatchMatch ____ further advanced the field. Despite limitations with large missing regions and complex textures ____, these methods established principles now incorporated into learning-based approaches ____. Their computational efficiency remains valuable in resource-constrained scenarios ____.

% \vspace{-3mm}
% \paragraph{Deep learning-based methods.}
% Deep learning has revolutionized image inpainting, with CNNs like Context Encoders ____ pioneering the field. GANs ____ and models like DeepFillv2 ____ further improved results. Large Mask Inpainting (LaMa) ____ addressed large missing regions. Recently, diffusion models____, particularly Stable Diffusion____, have demonstrated remarkable inpainting capabilities, leveraging complex data distributions____. Beyond text-to-image generation, diffusion models are commonly used for image-to-image tasks, including image editing and inpainting. SDEdit____ leverages diffusion models for semantic editing by injecting Gaussian noise into input images and performing iterative denoising, ensuring structural coherence while modifying visual content. To further improve image manipulation fidelity, Noise Inversion techniques such as DDIM Inversion____ enable precise latent code inference through deterministic reverse diffusion sampling. This approach retains finer details of the original image, making it particularly effective for manipulating real images within diffusion-based generative models. In the context of inpainting, models like SDXL-Inpainting have been developed by fine-tuning diffusion models specifically for inpainting tasks. While these methods have significantly improved image inpainting quality, Stable Diffusion-based inpainting often introduces scene-inconsistent artifacts within the inpainted regions. This challenge becomes even more pronounced when leveraging 2D diffusion priors for 3D inpainting, as it can lead to multi-view inconsistencies—a major limitation for 3D scene reconstruction____. The success of diffusion-based inpainting has inspired extensions to 3D inpainting tasks____, though adapting 2D approaches to 3D presents additional challenges, such as geometry misalignment, depth inconsistencies, and occlusion handling____.



% \vspace{-3mm}
% \paragraph{Reference-based methods.}
% Reference-based inpainting methods ____ enhance traditional inpainting by incorporating visual context from reference images, improving content accuracy and consistency. LeftRefill ____ uses a two-stage architecture with feature matching and refinement networks, enabling inpainting from different viewpoints based on reference information ____. While these methods show promise in various applications ____, challenges remain in seamless integration and reference selection ____, particularly when views diverge significantly from the reference. The success of these approaches has also inspired 3D inpainting extensions ____, though adapting to 3D introduces additional complexities ____.

% \vspace{-2mm}

% \subsection{Image Inpainting}
\vspace{3pt}
\noindent {\bf Traditional and learning-based image inpainting.}
Early image inpainting techniques, including PDE-based____, exemplar-based____, and PatchMatch____, were effective for small regions but struggled with complex textures and large gaps____. Deep learning advanced the field significantly, starting with Context Encoders____ and GAN-based methods like DeepFill____, improving content synthesis and coherence. Recent models such as LaMa____ use Fourier convolutional networks to address large masks. Diffusion models____, notably Stable Diffusion____, introduced iterative refinement capabilities, providing more flexible and structurally consistent inpainting compared to GANs____.
% Early image inpainting techniques, including PDE-based____, exemplar-based____, and patch-based methods like PatchMatch____, were effective for small missing regions but struggled with complex textures and large gaps____. Deep learning brought significant advancements, starting with CNN-based models like Context Encoders____ and GANs such as DeepFill____, which improved content synthesis and structural coherence. More recent models like Large Mask Inpainting (LaMa)____ further enhanced quality by using Fourier convolutional networks for large masked regions. The rise of diffusion models____, notably Stable Diffusion____, introduced powerful text-to-image and image-to-image capabilities, enabling more flexible and structurally consistent inpainting by iteratively refining missing regions, unlike GANs____.

% \vspace{-4mm}

\vspace{3pt}
\noindent {\bf Diffusion models for image editing and inpainting.}
Beyond direct inpainting, diffusion models are widely used for image editing. SDEdit____ injects Gaussian noise and iteratively denoises, enabling semantic edits while preserving global structure. Noise inversion techniques____, such as DDIM Inversion____, further improve editing fidelity by enabling precise latent inference through deterministic reverse diffusion.
Inpainting-specific diffusion models like SDXL-Inpainting____ enhance image reconstruction by fine-tuning Stable Diffusion. Reference-based methods____, such as LeftRefill____, use diffusion models for reference-guided synthesis but struggle in regions distant from reference views.
Despite advancements, Stable Diffusion-based inpainting____ still suffers from inconsistent artifacts in scene-dependent contexts, causing multi-view inconsistencies problematic for 3D scenes____. This motivates our use of SDEdit and DDIM Inversion to preserve structural information and ensure multi-view coherence.
% Beyond direct inpainting, diffusion models are widely used for image editing. SDEdit____ injects controlled Gaussian noise followed by iterative denoising, enabling semantic modifications while preserving global structure. To improve editing fidelity, Noise Inversion techniques____ like DDIM Inversion____ allow precise latent code inference through deterministic reverse diffusion sampling. By inverting an image to a specific noise level and denoising it back, Noise-Inversion provides finer control over content preservation, making it highly effective for inpainting real images while minimizing distortion during denoising.
% % 
% Inpainting-specific diffusion models like SDXL-Inpainting____ enhance the process by fine-tuning Stable Diffusion models for image reconstruction. Reference-based method____ such as LeftRefill____ uses pre-trained diffusion models for reference-guided synthesis, stitching reference and target views to enable contextual inpainting, view synthesis, and image completion via task-specific prompt tuning. However, LeftRefill struggles in regions far from the reference view, where alignment becomes less reliable.
% % 
% Despite these advancements, Stable Diffusion-based inpainting____ often produces inconsistent artifacts, particularly in scene-dependent contexts. When applied to 3D inpainting, these artifacts lead to multi-view inconsistencies, a critical limitation for scene reconstruction and object removal____. This motivates our use of SDEdit and DDIM Inversion for 3D inpainting, ensuring that denoising preserves critical structural information while maintaining coherence across viewpoints.  

% Although diffusion-based inpainting has inspired 3D inpainting extensions____, adapting 2D methods to 3D introduces challenges like geometry misalignment, depth inconsistencies, and occlusion handling.



% \subsection{3D Scene Inpainting}
% \paragraph{Methods without multi-view background knowledge.}
% As 3D scene representation and reconstruction techniques have advanced, the need for 3D inpainting methods has grown. Early approaches to 3D scene inpainting often relied on single-view or limited-view information, attempting to extend 2D inpainting concepts into the 3D domain without leveraging extensive multi-view knowledge.
% One category of methods focuses on direct 3D shape completion. These approaches typically operate on point clouds or voxel representations. For instance, PCN (Point Completion Network) introduced by ____ uses an encoder-decoder architecture to complete partial point clouds. While effective for object-level completion, these methods often struggle with complex, large-scale scene inpainting.
% Another approach involves using 2.5D representations, where depth information is incorporated alongside RGB data. Depth-aware inpainting methods, such as the work by ____, extend 2D inpainting techniques by considering depth as an additional channel. These methods can produce more geometrically consistent results but are limited by their reliance on a single viewpoint.
% Some researchers have explored the use of generative models for 3D inpainting. 3D-GAN, proposed by ____, generates 3D shapes from a probabilistic space, which can be adapted for inpainting tasks. However, these methods often struggle with fine details and scene-level consistency.
% In the context of neural rendering, early attempts at NeRF editing and inpainting also fall into this category. Methods like EditNeRF by ____ allow for object-level editing in NeRF scenes but are limited in their ability to handle large-scale scene modifications or inpainting of complex structures.
% Standalone NeRF inpainting methods, such as NeRF-In by ____, attempt to inpaint 3D scenes represented as Neural Radiance Fields. These approaches often rely on 2D inpainting results as supervision, projecting them back into the 3D space. While they can produce plausible results for small edits, they struggle with view consistency and large-scale modifications.
% A common limitation of these single-view or limited-view methods is their inability to fully leverage the 3D structure of the scene. They often produce results that are inconsistent across different viewpoints or fail to capture the true geometry of occluded regions ____. Additionally, these methods may struggle with understanding the global context of the scene, leading to inpainted content that doesn't align well with the overall scene structure ____.
% Despite these limitations, these methods have laid important groundwork for 3D scene inpainting. They have highlighted the challenges specific to 3D inpainting, such as maintaining geometric consistency and handling occlusions, which have informed the development of more advanced, multi-view aware techniques ____.
% Existing 3D inpainting approaches____ extended 2D concepts to 3D without extensive multi-view knowledge. These include direct 3D shape completion methods like PCN ____, 2.5D representations ____, and generative models like 3D-GAN ____. In the field of neural rendering, EditNeRF ____ and NeRF-In ____ pioneered NeRF editing and inpainting. These methods often struggle with view consistency ____ and global context ____. Despite limitations, they laid groundwork for more advanced, multi-view aware techniques ____. 

% Existing 3D inpainting approaches用在NeRf上____ 因為nerf implicit representation的特性，通常都是leverage 2d inpainter to 3d, 像spinnerf____用一個lpips loss來減緩muli-view inpainting 的inconcsitency. 而reference-based method, 為了要進一步解決multi-view inconsitency的問題，他們提出想要只使用少數的reference image來代表要inpaint的區域。然而他們通常只能能render的novel view角度很小, 局限在forward facing scene, 很能利用到unbounded 360 scene上。InNeRF360____雖然可以使用在360場景，使用Hallucinating Density Removal來清除inconsistency造成的flaoters, 但卻一樣是利用將object先inpaint掉在拿去train nerf的方式, 沒辦法利用原有場景資訊。

% 而得天GaussianSplatting explict的特性, GaussianGrouping可以將semantic 資訊加到每一顆Gaussian上, InFusion [citation] approaches 3D Gaussian inpainting by leveraging depth completion and progressive reference view synthesis. While achieving efficient results, the method's limitations include manual view selection requirements and potential inaccuracies in depth completion for complex geometries, 而且他們的depth completion model需奧finetuning. GScream leverages 3D Gaussian Splatting for object removal by integrating monocular depth guidance and cross-attention feature propagation between visible and in-painted regions to achieve consistent geometry and textures. However, it's hard to extend to unbounded 360 scene 因為他一樣是reference-based method. 而我們的方法...


\vspace{3pt}
\noindent {\bf 3D scene inpainting.}
Existing 3D inpainting methods for NeRF____ typically adapt 2D models to NeRF’s implicit representation. For instance, SPIn-NeRF____ employs perceptual loss to improve multi-view consistency. Reference-based methods____ enhance consistency using reference images but remain limited to small-angle view rendering, restricting their use in 360° scenes. NeRFiller____ iteratively refines consistency with grid prior but struggles with fine-grained textures due to image downsampling. InNeRF360____ handles 360° scenes via density hallucination but has limited scene utilization.
% 
Gaussian Splatting-based methods like Gaussian Grouping____ inject semantic information, while InFusion____ employs depth completion but requires manual view selection. GScream____ integrates Scaffold-GS but faces difficulties in unbounded 360° scenes. Our method addresses these issues by enhancing multi-view consistency and depth-aware inpainting in 360° scenarios using Gaussian Splatting.
% Existing 3D inpainting approaches for NeRF____ often extend 2D inpainting models into 3D due to NeRF’s implicit representation. For example, SPIn-NeRF____ uses perceptual loss to reduce multi-view inpainting inconsistencies. Reference-based methods____ aim to further reduce these inconsistencies by using a few reference images to represent the inpainting area. However, these methods are generally restricted to rendering novel views from small angles, making them less suitable for unbounded 360° environments. NeRFiller____ improves multi-view consistency with Grid Prior, extends it to Joint Multi-View Inpainting, and refines missing regions iteratively via Dataset Update, ensuring 3D structural coherence without reference images or object masks. Yet, its reliance on image downsampling limits high-frequency detail reconstruction, reducing effectiveness for fine-grained textures. InNeRF360____ adapts to 360° scenes using Hallucinating Density Removal to address view inconsistencies but remains limited by its object inpainting approach before NeRF training, restricting full scene utilization.
% % 
% Gaussian Splatting enables precise inpainting, as seen in Gaussian Grouping____, which injects semantic information into each Gaussian. InFusion____ enhances 3D Gaussian inpainting with depth completion and progressive reference synthesis but is limited by manual view selection and fine-tuning. GScream integrates Scaffold-GS____ for object removal, using monocular depth and cross-attention for consistency but struggles with 360° unbounded scenes due to fixed reference views. Our method addresses these challenges by improving multi-view consistency in 360° environments, leveraging Gaussian Splatting for explicit scene manipulation and depth-aware inpainting.




% Previous work such as SPIn-NeRF that integrates 2d inpainting model with perceptual loss and depth inpainting guidance to reconstruct Inpainted Neural Radiance Fields (NeRF). OR-NeRF Removing Objects From NeRF use confidence-based view selection automatically removes inconsistent views from the optimization preventing unwanted artefacts in the final result.MVIP-NeRF utilizes a multi-view approach to perform 3D inpainting on NeRF scenes by employing diffusion priors, where it jointly optimizes RGB and normal map completion through an iterative Score Distillation Sampling (SDS) process, ensuring consistent appearance and geometry alignment across multiple views while leveraging a multi-view scoring mechanism to distill generative priors from different perspectives. 然而這些方法並沒有透過leverage 已有場景資訊來進行inpainting. Reference-guided controllable inpainting, as presented by Mirzaei et al. (2023), leverages reference images and view-dependent effects to guide the inpainting process in 3D scenes, enabling consistent and visually coherent completions across multiple perspectives while handling challenges like disocclusions and geometric consistency. GScream introduces a robust framework for object removal in 3D scenes by optimizing Gaussian primitives' positions for geometric consistency and utilizing a cross-attention feature propagation mechanism to enhance texture coherence, effectively restoring both geometry and texture across visible and occluded areas. 
% Reference-guided inpainting in NeRF  

% 先nerf方法, 指出雖然..., 他們1需要非常精確的object mask來remov場景的objec, 但又inplcit-method, 所以沒辦法很好的透出場景資訊
% 在講道






% \vspace{-3mm}
% \paragraph{Methods leveraging multi-view information.}
% As the limitations of single-view 3D inpainting methods became apparent, researchers began to explore approaches that leverage multi-view information. These methods aim to produce more consistent and geometrically accurate results by utilizing the rich information available from multiple viewpoints of a scene.
% One of the pioneering works in this direction is SPIn-NeRF by ____. This method combines Neural Radiance Fields (NeRF) with multi-view image inpainting to remove objects from 3D scenes. SPIn-NeRF uses a two-stage approach: first, it inpaints each input view using a 2D inpainting method, then it optimizes a NeRF to fit these inpainted views. By leveraging multi-view consistency, SPIn-NeRF can produce more coherent results across different viewpoints than single-view methods.
% Another significant contribution in this area is the work by ____ on object removal for image-based rendering. Their method uses multi-view stereo to reconstruct the scene geometry and then performs inpainting in both color and depth spaces across multiple views. This approach demonstrates the importance of considering both appearance and geometry in multi-view 3D inpainting.
% Inpaint3D, proposed by ____, takes a different approach by training a 3D-aware inpainting network on a large dataset of indoor scenes. This method can leverage the learned 3D priors to produce geometrically consistent inpaintings across multiple views, even for large missing regions.
% Recent advancements in NeRF-based representations have led to more sophisticated multi-view inpainting methods. For instance, InpaintNeRF360 by ____ extends inpainting capabilities to 360-degree scenes. This method uses a combination of 2D inpainting guidance and 3D consistency optimization to handle the challenges of inpainting in omnidirectional environments.
% Gaussian Grouping, introduced by ____, presents a novel approach to 3D scene editing using 3D Gaussian Splatting. While not specifically designed for inpainting, this method demonstrates how multi-view information can be leveraged to segment and manipulate 3D scenes represented by Gaussians, opening new possibilities for 3D inpainting tasks.
% A common thread among these multi-view methods is their ability to maintain consistency across different viewpoints, a crucial aspect of 3D scene inpainting. By leveraging information from multiple views, these approaches can better understand the underlying 3D structure of the scene and produce inpainted results that are coherent with the global scene geometry ____.
% However, challenges remain. Many of these methods still struggle with large-scale occlusions or complex geometric structures ____. The computational cost of processing multiple views can also be significant, especially for high-resolution or large-scale scenes ____. Additionally, balancing the influence of different views and handling potential inconsistencies between them remains an active area of research ____.
% Despite these challenges, multi-view 3D inpainting methods have significantly advanced the state of the art, enabling more realistic and consistent scene editing and completion. As research progresses, we can expect to see further improvements in the quality and efficiency of these techniques, potentially leading to new applications in fields such as virtual reality, augmented reality, and digital twin technologies ____.

% Multi-view 3D inpainting methods address the limitations of single-view approaches. SPIn-NeRF ____ combines NeRF with multi-view image inpainting. ____ use multi-view stereo for object removal in image-based rendering. Inpaint3D ____ leverages learned 3D priors. InpaintNeRF360 ____ extends to 360-degree scenes, while Gaussian Grouping ____ uses 3D Gaussian Splatting. These methods maintain consistency across viewpoints ____ but face challenges with large-scale occlusions ____, computational costs ____, and view inconsistencies ____. Despite challenges, they advance scene editing and completion, potentially leading to new applications ____.