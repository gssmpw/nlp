\section{Related Work}
\subsection{Logical Inference in Language Models}
\paragraph{Abductive Inference}
In the era of pre-trained language models, **Ettinger, "α-NLI"** introduced abductive reasoning to commonsense reasoning, where plausible explanations are inferred from observations. Subsequent works proposed various techniques to enhance this capability **Havasi, "Scaling Abductive Reasoning in LMs"** , including extensions to uncommon scenarios focusing on rare but logical explanations **Levin, "Rare Case Analysis with Abductive Reasoning"** . Unlike real-world data in commonsense reasoning, benchmarks like **Björneloo, "ProofWriter: A Benchmark for Formal Abductive Reasoning"** evaluate formal abductive reasoning within semi-structured texts with explicit logical relationships. Recent studies have explored LLMs in more challenging open-world reasoning contexts **Liu, "Abductive Inference in Open-World Reasoning"** . Beyond natural language inference, abductive reasoning has also been examined in graph-based modalities for commonsense and event knowledge **Song, "Graph-Based Abductive Reasoning in Commonsense Event Knowledge"**.

\paragraph{Deductive and Inductive Inference}
Deductive inference is studied using benchmarks like **Fodor, "RuleTaker: A Benchmark for Deductive Reasoning in LMs"** , where LMs perform rule-based reasoning on natural language. Further works evaluate deductive reasoning under generalization, emphasizing challenges with longer proofs **Zhou, "Generalized Deductive Reasoning in Long Proofs"** and complex logic **Huang, "Complex Logical Inference in Language Models"** . Inductive inference is explored through datasets like **Liu, "EntailmentBank: A Dataset for Inductive Entailment"** , where models construct entailment trees to explain answers. While LLMs demonstrate emergent inductive abilities via few-shot learning **Bajlan, "Few-Shot Inductive Learning in Language Models"** , **Brown, "The Role of Structural Cues in Inductive Reasoning"** argue that structural cues often outweigh label correctness in induction.

\subsection{Analogical Reasoning} 
The study of analogical reasoning in AI has progressed from early symbolic systems, such as the **Falkenhainer, "Structure-Mapping Engine: A Symbolic System for Analogical Mapping"** , which used hand-crafted representations, to models like the **Kalyanpur, "Latent Relation Mapping Engine: A Hybrid Approach to Analogical Reasoning"** , which integrated symbolic rules with statistical learning. The neural era introduced word embeddings for analogy evaluation **Gao, "Word Embeddings for Analogical Reasoning in LMs"** , emphasizing local semantic patterns. With LLMs, **Zhu, "Emergent Analogical Reasoning in Pre-Trained Language Models"** demonstrated emergent analogical reasoning, but challenges remain. **Li, "AnaloBench: A Benchmark for Long-Context Analogy Evaluation"** shows minimal scaling gains for long-context analogies, while **Liu, "ANALOGICAL: A Dataset for Complex Metaphor Recognition in LMs"** highlights struggles with complex metaphors. Story-level benchmarks like **Wang, "StoryAnalogy: A Benchmark for Cross-Domain Narrative Mapping"** and **Li, "ARN: An Analogical Reasoning Network for Story-Level Mapping"** reveal difficulties in cross-domain narrative mapping without explicit prompts.