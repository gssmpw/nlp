\section{Related Work}
\subsection{Logical Inference in Language Models}
\paragraph{Abductive Inference}
In the era of pre-trained language models, $\alpha$\textbf{-NLI} ____ introduced abductive reasoning to commonsense reasoning, where plausible explanations are inferred from observations. Subsequent works proposed various techniques to enhance this capability ____, including extensions to uncommon scenarios focusing on rare but logical explanations ____. Unlike real-world data in commonsense reasoning, benchmarks like \textbf{ProofWriter} ____ evaluate formal abductive reasoning within semi-structured texts with explicit logical relationships. Recent studies have explored LLMs in more challenging open-world reasoning contexts ____. Beyond natural language inference, abductive reasoning has also been examined in graph-based modalities for commonsense and event knowledge ____.

\paragraph{Deductive and Inductive Inference}
Deductive inference is studied using benchmarks like \textbf{RuleTaker} ____, where LMs perform rule-based reasoning on natural language. Further works evaluate deductive reasoning under generalization, emphasizing challenges with longer proofs ____ and complex logic ____. Inductive inference is explored through datasets like \textbf{EntailmentBank} ____, where models construct entailment trees to explain answers. While LLMs demonstrate emergent inductive abilities via few-shot learning ____, ____ argue that structural cues often outweigh label correctness in induction.

\subsection{Analogical Reasoning} 
The study of analogical reasoning in AI has progressed from early symbolic systems, such as the \textbf{Structure-Mapping Engine} ____, which used hand-crafted representations, to models like the \textbf{Latent Relation Mapping Engine} ____, which integrated symbolic rules with statistical learning. The neural era introduced word embeddings for analogy evaluation ____, emphasizing local semantic patterns. With LLMs, ____ demonstrated emergent analogical reasoning, but challenges remain. \textbf{AnaloBench} ____ shows minimal scaling gains for long-context analogies, while \textbf{ANALOGICAL} ____ highlights struggles with complex metaphors. Story-level benchmarks like \textbf{StoryAnalogy} ____ and \textbf{ARN} ____ reveal difficulties in cross-domain narrative mapping without explicit prompts.