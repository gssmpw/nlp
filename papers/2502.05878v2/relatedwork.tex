\section{Related Work}
% \subsection{Retrieval-augmented LLMs}
% To enhance reasoning and prediction capabilities of LLM by retrieving relevant information from vast datasets, numerous retrieval methods have been proposed~\citep{fan2024survey}. Early approaches primarily relied on keyword frequency, with many studies directly applying BM25 for passage-level retrieval in RAG~\citep{chen2017reading,jiang2023active,ram2023context,xu2024recomp,zhong2022training,zhoudocprompting}. These passages were represented as bags of words and ranked using term frequency-inverse document frequency (TF-IDF)~\citep{izacard2021leveraging}. Subsequently, methods based on semantic similarity emerged, which encode queries and passages into a shared vector space to train embeddings that align queries closely with relevant factual passages~\citep{li2023mot,ludynamic,milios2023context,poesiasynchromesh,rubin2022learning,ye2023compositional}. However, these approaches are not well-suited for time-series retrieval tasks, such as predicting stock price movements, where no fixed factual passages exist for retrieval. Furthermore, the highly similar nature of time-series data poses challenges for semantic similarity-based methods, as they struggle to effectively distinguish between similar patterns. Therefore, a specialized retrieval method for time-series data is required, which our model provides.

\subsection{Stock Movement Prediction}
\textbf{Non-LLM Methods.}
Traditional approaches to stock movement prediction have focused on various aspects of financial data. One prominent category of methods analyzes stock price sequences and their corresponding technical indicators~\citep{qin2017dual,feng2018enhancing} to identify patterns in historical data for predicting future movements. However, due to the complexity of factors influencing stock prices, subsequent methods have incorporated additional contextual information, such as news articles~\citep{ding2015deep,liu2018hierarchical}  or social media posts~\citep{xu2018stock,wu2018hybrid}. Despite efforts, these methods are highly susceptible to noise and struggle to analyze the vast and diverse nature of financial information effectively.

\noindent
\textbf{LLM-based Methods.}
Recent studies have explored using LLMs for financial prediction tasks, either by fine-tuning open-source models or prompting advanced models like GPT-4. However, even state-of-the-art models, including GPT-4, have achieved only random-guessing-level accuracy in stock movement prediction~\citep{xie2023pixiu,xie2024finben,xie2023wall}. This highlights the inherent challenges in identifying and analyzing meaningful patterns in a domain as volatile and multifaceted as stock market prediction.

\subsection{Time-series forecasting with LLMs}
% LLMs have been increasingly applied to time-series forecasting, particularly in tasks requiring the alignment of temporal and textual data. Several approaches focus on improving this alignment through different strategies. 
\textbf{Non-retrieval Methods.}
To enhance the performance of LLMs in time-series forecasting, existing methods have primarily focused on aligning temporal and textual data, either by transforming time-series into textual formats or by encoding both modalities into a unified vector space.
For instance, a study~\citep{jin2023time} reprograms time-series data into textual representations suitable for LLMs, enhancing prediction accuracy via declarative prompts. Similarly, some other studies~\citep{yu2023temporal,liu2024timecma} explore cross-modal alignment: the former applies LLMs to financial forecasting by integrating stock prices with news data, while the latter introduces a cross-modality framework to align time-series with text for improved predictive performance. % Building on this, a method~\citep{pan2024s} maps time-series and text into a shared semantic space, further boosting LLM performance through strengthened data alignment. 
% Despite these advancements, efficient methods for retrieving large-scale time-series data remain underexplored, presenting a key challenge for future research.
While these advancements improve alignment, existing methods often struggle to process large-scale time-series data comprehensively due to LLM input limitations. As a result, effectively leveraging extensive historical data remains a challenge. This highlights the need for retrieval-augmented methods, a gap our approach directly addresses.

\noindent
\textbf{RAG Methods.}
With the rapid advancement of RAG techniques in various applications of LLMs, recent research has begun exploring RAG for time-series forecasting. For instance, TimeRAG~\citep{yang2024timerag} integrates RAG into time-series forecasting by combining Dynamic Time Warping (DTW) with LLMs to improve prediction accuracy. However, relying solely on numeric similarity is insufficient for financial time-series forecasting, as it fails to capture deeper semantic relationships. This underscores the need for a more targeted retrieval framework tailored to the complexities of financial data, a challenge our framework effectively addresses.