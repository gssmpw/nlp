\section{Limitations}

Owing to resource constraints, our training data is limited to several hundred hours. It would be preferable to implement our method in larger-scale experiments to facilitate comparison with existing strong Speech LLMs such as Qwen-Audio~\cite{Qwen2-Audio} on a more comprehensive benchmark like AirBench~\cite{yang2024air}.Additionally, we train the PaM module from scratch using a predefined list of audio encoders. It would be beneficial to investigate the addition of new encoders to an already trained Speech LLM to enhance its performance on new tasks or in new domains. We leave this for future work.