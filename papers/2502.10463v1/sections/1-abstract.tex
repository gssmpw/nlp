\begin{abstract}

%两种思路：
%（1）从state space model这个数学模型出来，可以把network描述成一个SSM，network layer之间的interaction正好和SSM的hidden state更新相似；
% Pros: 更有开创性；Cons:但是是提出一个新问题，容易被challenge；
%（2）从layer interaction出发，指出现有的high-performance model通常具有deep layer sequence，很适合通过SSM来解决这个long sequence modeling的问题；
% Pros：是基于现有的工作，比较好写；Cons: contribution显得小一些，是基于以前工作的A+B


  Recently, state space models have gained traction across various fields, particularly in long-sequence modeling tasks. 
  %
  While most contemporary studies leverage state space models as standalone backbones, there is a notable gap in research that explores the integration of state space models with neural network architecture design.
  % While many contemporary studies leverage state space models as standalone backbones, there is a notable gap in research that explores the integration of state space models with traditional convolutional neural networks (CNNs) and transformers. 
  %
  To address this gap, our paper introduces a novel \textit{State-Space-Interaction Layer} (SSIL) model.
  %
  This innovative approach utilizes conventional transformers or CNNs as the foundational architecture while aggregating the outputs from each layer. 
  %
  The aggregated output is then fed into a state space model, generating a new sequence that enriches the model's understanding and representation of the data. 
  %
  We applied our SSAL model to both classification and detection tasks within the realm of computer vision. 
  %
  Extensive experiments demonstrated that our model not only surpassed standard models but also outperformed several existing interaction layer fusion techniques on benchmark datasets. 
  %
  This advancement highlights the potential of combining state space models with established neural network architectures, paving the way for more effective and efficient solutions in CV classification and detection tasks. 
\end{abstract}