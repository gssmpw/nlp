\section{Preliminaries}
\label{sec:background}

\subsection{Problem Formulation}
\label{subsec:problem}
Modern uncertainty quantification (UQ) for black-box LLMs operates through two sequential stages: similarity measurement between responses and uncertainty estimation from these similarities. Let $\mathcal{M}$ denote a black-box LLM generating $n$ responses $\{A^1,\ldots,A^n\}$ to input $Q$. The UQ task estimates confidence $U $ through:


\begin{equation}
U = f(\mathbf{S}), \quad \mathbf{S} \in \mathbb{R}^{n\times n}
\end{equation}

\noindent where $\mathbf{S}$ is the similarity matrix with the $(i, j)$-th entry capturing the proximity  of responses $A^i$ and $A^j$, and $f$ represents the estimation strategy. This formulation enables UQ without accessing internal model probabilities.

\subsection{Measuring Response Similarities}
\label{subsec:similarities}
The foundation of reliable UQ lies in effective similarity measurement. We analyze two complementary approaches capturing different aspects of response quality.

\subsubsection{Semantic Dimension}
\label{subsubsec:semantic}
Semantic similarity focuses on surface-level consistency between responses. The Jaccard index \citep{lin2023generating} offers simple lexical comparison:

\begin{equation}
s_{ij} = \frac{|A^i \cap A^j|}{|A^i \cup A^j|}
\end{equation}

While computationally efficient, Jaccard ignores word order and semantics. For deeper analysis, there is another common way to compute the semantic similarity, which uses DeBERTa's NLI capabilities~\citep{he2021deberta}:

\begin{equation}
s_{ij} = \frac{1}{2}\left(P_{\text{entail}}(A^i,A^j) + P_{\text{entail}}(A^j,A^i)\right)
\end{equation}

Where $P_{\text{entail}}(A^i,A^j)$ the probability of $A^i$ entails $A^j$ that is output from the NLI model.

Compared with the Jaccard index, NLI-based scoring better captures semantic equivalence but remains sensitive to syntactic variation. For instance, paraphrased factual statements may receive low scores despite equivalent meaning. To the question \textit{How many students became heroes}, The response \textit{These three became heroes} and the response \textit{Andrew Willis, Chris Willis, Reece Galea} share the factual knowledge that three students became heroes while their similarity from NLI models will be low as 0.015. Therefore, relying solely on responses from the semantic dimension may result in information loss.

\subsubsection{Knowledge Dimension} 
\label{subsubsec:knowledge}

The knowledge dimension operates through a structured pipeline that transforms raw responses into factual representations. 
Given a question $Q$ and its original response $A^i$, a knowledge representation $K^i$ could be generated through a knowledge mapping process by extracting explicit claims: $K^i = \mathcal{M}_{\text{aux}}(Q, A^i)$ and augmenting the response, where  $\mathcal{M}_{\text{aux}}$ denotes for an auxiliary LLM. Specifically, we could use an LLM to augment with prompts taking into the question and original response:

\begin{tcolorbox}[colback=gray!5!white, colframe=gray!75!green, title=\textbf{Prompt Example for Knowledge Mapping}] 

 \ding{182}: Extract all factual claims from this response $\langle A^i \rangle$, phrased as standalone statements independent of specific wording. 

 \ding{183}: Include only information directly relevant to answering the question: $\langle Q \rangle$.

\end{tcolorbox}

This claim extraction disentangles implicit knowledge from surface semantics and removes stylistic variations while preserving core factual content.




\subsection{Estimating Uncertainty}
\label{subsec:estimation}
With similarity matrices constructed, existing UQ methods employ two principal ways to estimate uncertainty, each offering unique advantages and limitations.

\subsubsection{Number of Semantic Sets (UNumSet)}
\label{subsubsec:numset}
Proposed by \citet{kuhn2023semantic}, this method groups responses into equivalence classes using bidirectional entailment checks from an NLI model. Formally, responses $A^i$ and $A^j$ are merged into the same semantic set if:
\begin{equation}
P_{\text{entail}}(A^i, A^j) > P_{\text{contra}}(A^i, A^j) \quad \text{and} \quad P_{\text{entail}}(A^j, A^i) > P_{\text{contra}}(A^j, A^i).
\end{equation}
The uncertainty measure $U_{\text{NumSet}}$ equals the number of resulting semantic sets. This approach aligns with spectral graph theory. Because when using binary adjacency matrices ($W_{ij} \in {0,1}$), the number of zero eigenvalues in the graph Laplacian corresponds to the number of connected components \citep{von2007tutorial}. While this method discretizes continuous semantic relationships, it fails to capture partial meaning overlaps.

\subsubsection{Graph Laplacian}
\label{subsubsec:laplacian}
Building on spectral graph principles \citep{agaskar2013spectral,lin2023generating}, this method quantifies uncertainty through the eigenvalues ${\lambda_k}$ of the normalized graph Laplacian $L = I - D^{-1/2}WD^{-1/2}$:
\begin{equation}
U_{\text{EigV}} = \sum_{k=1}^n \max(0, 1 - \lambda_k).
\end{equation}

Here, eigenvalues $\lambda_k$ encode connectivity. fragmented graphs (low consistency in responses and thus high uncertainty) have more small eigenvalues. Compared with $U_{\text{NumSet}}$, this method is able to capture possible overlapping semantic relationships.


\subsection{Dimensional Analysis}
Now, we compare the difference between similarity matrices from knowledge and semantic dimensions. In detail, we use the NLI model to obtain the similarity matrix. In \cref{tab:similarity_matrix_stat}, we present the mean values and the proportion of similarity scores greater than 0.55 in the similarity matrices. The results show that similarity matrices in the knowledge dimension have more large value as well as a larger mean value. This reveals the knowledge dimensions' superior consistency. These results highlight the importance of multi-dimensional analysis since semantic features capture response variability, while knowledge features track factual consistency hidden behind the semantic features. Our tensor decomposition effectively combines these complementary signals.

\begin{table}[t!]
    \centering
    \begin{tabular}{lcc}
        \toprule
        Dataset & Proportion (\%) & Mean Value \\
        \midrule
        \multicolumn{3}{c}{\textbf{Semantic Similarity}} \\
        \midrule
        Coqa & 52.97 & 0.5430 \\
        nq\_open & 17.11 & 0.1839 \\
        Trivialqa & 51.15 & 0.5154 \\
        \midrule
        \multicolumn{3}{c}{\textbf{Knowledge Similarity}} \\
        \midrule
        Coqa & 57.40 & 0.5723 \\
        nq\_open & 31.16 & 0.3281 \\
        Trivialqa & 60.17 & 0.6058 \\
        \bottomrule
    \end{tabular}
    \caption{Proportion of similarity values greater than 0.55 and mean similarity values for the similarity matrices in the semantic space and the knowledge space. The results show that the knowledge similarity matrix has larger values.}
    \vspace{-10mm}
    \label{tab:similarity_matrix_stat}
\end{table}