


\section{Introduction}

Large Language Models (LLMs) have demonstrated exceptional capabilities in tasks ranging from code generation to clinical decision support \citep{du2024evaluating,cascella2023evaluating}. However, their deployment in high-stakes domains requires rigorous reliability verification, as studies reveal persistent hallucination and overconfidence issues \citep{huang2024trustllm,yao2023llm}. This challenge intensifies with commercial LLMs like GPT-4, Claude, and Gemini \citep{achiam2023gpt-4,anthropic2024claude, team2023gemini}, where black-box access to architectures and parameters prevents internal confidence measurement.

While uncertainty quantification (UQ) methods form the foundation of reliable AI systems \citep{wang2025aleatoric}, existing approaches face fundamental limitations in natural language generation (NLG). Traditional UQ techniques for classification \citep{gal2016dropout} or regression \citep{ye2024uncertainty} fail to address NLG's unique challenges: semantic equivalence despite lexical variation \citep{kuhn2023semantic}, and knowledge coherence beyond surface patterns \citep{choi2024fact}. Current LLM UQ methods exacerbate these issues by focusing on single uncertainty dimensions—either semantic entropy requiring white-box access \citep{kuhn2023semantic} or knowledge-augmented approaches that propagate redundancy \citep{da2024llm}.

\begin{figure}[h]
    \centering
    \includegraphics[width=0.48\textwidth]{images/example_knowledge.pdf}
    \caption{An example from CoQA illustrates that responses based on the knowledge dimension can extract implicit information from semantic responses while still preserving common data. Therefore, an entangled relationship between semantic and knowledge dimensions is necessary.}
    \vspace{-5mm}
    \label{fig:Knowledge_example}
\end{figure}




Effective uncertainty quantification requires analyzing complementary semantic and knowledge dimensions: (1) Semantic equivalence captures meaning consistency across paraphrased responses, while (2) Knowledge consistency verifies factual alignment with external evidence. Single-dimensional approaches prove inadequate—semantic entropy fails to detect knowledge contradictions in meaning-preserving responses \citep{da2024llm}, while knowledge-augmented methods cannot distinguish factual redundancy from semantic novelty \citep{hu2024decomposition}. This multi-dimensional nature of LLM uncertainty necessitates joint analysis of semantic and knowledge coherence features.
\begin{figure}[h]
    \centering
    \includegraphics[width=0.48\textwidth]{images/draw_relationship.pdf}
    \caption{An example from CoQA illustrates the dynamic relationship between semantic dimension and knowledge dimension. The example shows that we need to consider both dimensions of responses.}
    \vspace{-7mm}
    \label{fig:dynamic_example}
\end{figure}
The development of such multi-dimensional UQ faces two fundamental challenges:
(1) \textbf{Semantic-Knowledge Entanglement}: Current methods conflate semantic equivalence with knowledge consistency, failing to distinguish between meaning-preserving variations and factual contradictions. We show an example in \cref{fig:Knowledge_example}. To the question \textit{How many students become heroes?}, two responses \textit{Andrew Willis, Chris Willis, Reece
Galea} and \textit{These three became heroes} differ significantly in their semantic representation, as one lists specific names while the other generalizes the information. However, they convey the same underlying knowledge: three persons became heroes.  On the other hand, the response \textit{These three became heroes} and the response \textit{Three students became heroes} exhibit similarity in both semantic and knowledge dimensions. Therefore, it is crucial to disentangle these two dimensions.
(2) \textbf{Dynamic Relationship}: The relative importance of semantic and knowledge dimensions varies across conversational contexts.  We show an example from CoQA in \cref{fig:dynamic_example}. In CoQA, questions like \textit{"What was in it"} rely heavily on semantic equivalence to ensure coherence with prior turns and knowledge extraction might misunderstand the response \textit{a note, a reply} to there are two things in it. In contrast, questions such as \textit{"What did they do with the note"} demand knowledge consistency to verify alignment with evidence in the passage. Therefore, Static fusion strategies fail to adapt to such dynamic shifts, leading to suboptimal uncertainty estimates.


To address these challenges, We propose \ours, a \textbf{M}ulti-\textbf{D}imensional \textbf{U}ncertainty \textbf{Q}uantification framework that integrates multiple dimensions of uncertainty and adaptively fuses them into a unified measure. Specifically, to integrate and disentangle information from multiple uncertainty dimensions, our method first concatenates similarity matrices from each dimension and then applies tensor decomposition to generate reconstruction errors through orthogonal analysis. Additionally, to account for dynamic inter-dimensional relationships, we adaptively ensemble reconstruction errors obtained from different tensor decomposition methods, ensuring robust and accurate uncertainty estimation across diverse tasks. Extensive experiments demonstrate the effectiveness of multi-dimensional analysis and show that our framework achieves superior performance, particularly on challenging datasets. In summary, the contributions of this paper are:

\begin{itemize}
    \item We are the first to propose an uncertainty quantification framework that integrates multiple dimensions of uncertainty, including semantic and knowledge coherence. Our method captures complementary uncertainty signals by combining information from implicit knowledge and original responses, enabling a more comprehensive analysis of black-box LLM outputs.
    \item We develop a novel tensor decomposition approach to orthogonally analyze multi-dimensional data and represent uncertainty using reconstruction errors. This process separates repeated information, reduces estimation bias, and disentangles semantic and knowledge features effectively.
    \item Extensive experimental results on CoQA~\cite{reddy2019coqa}, NQ\_Open~\cite{kwiatkowski2019natural} and HotpotQA~\cite{yang2018hotpotqa} datasets show that compared with state-of-the-art methods, our framework consistently performs better under various settings.
    
\end{itemize}
