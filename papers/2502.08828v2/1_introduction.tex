\vspace{-0.4cm}
\section{Introduction}

In modern machine learning, models have become increasingly large and effective, but the high cost of GPUs presents a challenge. Data-centric AI (DCAI) offers an alternative by enhancing data quality and representation to improve AI performance, even when using simpler models~\cite{kumar2024opportunities}.
Among different data types, tabular data remains one of the most fundamental and widely used formats, with applications spanning healthcare, finance, marketing, etc~\cite{liu2024calorie,safriandono2024analyzing,lu2020traumatic}. Unlike unstructured data, such as images and text, tabular data is characterized by complex feature dependencies, high dimensionality, and stringent interpretability requirements. Additionally, its availability is often more restricted compared to vision and language datasets, making it challenging to develop generalizable AI solutions. As a key area of DCAI, tabular learning aims to transform a given tabular dataset into an optimal representation by leveraging feature knowledge convergence. These factors necessitate advanced transformation techniques that maximize the utility of tabular data.

% \begin{figure}[t]
%     \centering
%     \includegraphics[width=0.9\linewidth]{figures/survey_focus.pdf}
%     \caption{Real-world applications produce large volumes of tabular data, making Data-Centric AI crucial for performance optimization.}
%     \label{fig:survey_focus}
%     \vspace{-0.5cm}
% \end{figure}

Feature engineering is essential for extracting meaningful patterns from tabular datasets, significantly impacting the performance of machine learning models~\cite{heaton2016empirical}. It comprises two fundamental tasks: feature selection and feature generation. Feature selection~\cite{mrmr,biesiada2008feature,ding2014identification,lasso1996} aims to identify the most relevant features by eliminating redundancy and irrelevant information, thereby enhancing model interpretability, efficiency, and generalization. Feature generation~\cite{chen2021techniques,kusiak2001feature,kanter2015deep,azim2024feature}, on the other hand, focuses on constructing new features that capture complex interactions and domain-specific patterns, enriching the input representation for better predictive performance. 

Among these innovations, reinforcement learning (RL)~\cite{sutton2018reinforcement} and generative models~\cite{ruthotto2021introduction} have emerged as powerful frameworks for optimizing tabular learning. RL-based techniques employ reward-driven exploration to iteratively refine feature selection and transformation strategies, allowing models to learn adaptive feature representations that improve downstream predictive tasks. By dynamically exploring various feature combinations, RL enables data-driven optimization of feature spaces without the need for manual intervention. Generative models, in contrast, learn latent feature representations that facilitate intelligent feature construction, capturing intricate relationships within data. These models can generate synthetic features that preserve underlying statistical properties, thereby enhancing model robustness and generalization. Moreover, generative approaches enable systematic knowledge transfer by reusing learned feature representations across different datasets, reducing the need for extensive labeled data in new tasks.
\begin{figure*}[t]
    \centering
\includegraphics[width=1.0\linewidth]{figures/advanced_tabular.pdf}
    \vspace{-0.5cm}
    \caption{A taxonomy overview of RL-based and generative techniques in tabular data-centric AI.}
    \label{fig:overview}
    \vspace{-0.5cm}
\end{figure*}

To advance research in this area, this survey systematically reviews existing feature selection and generation techniques, with a particular focus on RL-based optimization and generative AI approaches (see \textbf{Figure~\ref{fig:overview}}). We explore the unique challenges posed by tabular data, examine how advanced AI methodologies address these challenges, and provide comparative insights into different transformation strategies. Additionally, we discuss emerging trends that are shaping the future of automated feature engineering. Through this comprehensive analysis, we aim to provide researchers and practitioners with a deeper understanding of cutting-edge methodologies and their implications for real-world applications.