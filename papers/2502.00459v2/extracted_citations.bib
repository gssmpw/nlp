@inproceedings{abnar2020quantifying,
  title={Quantifying attention flow in transformers},
  author={Abnar, Samira and Zuidema, Willem},
  booktitle={Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics},
  pages={4190--4197},
  year={2020},
  organization={Association for Computational Linguistics}
}

@article{akman2024audio,
  title={Audio Explainable Artificial Intelligence: A Review},
  author={Akman, Alican and Schuller, Bj{\"o}rn W},
  journal={Intelligent Computing},
  volume={2},
  pages={0074},
  year={2024},
  publisher={AAAS}
}

@article{becker2018interpreting,
  title={Interpreting and explaining deep neural networks for classification of audio signals},
  author={Becker, S{\"o}ren and Ackermann, Marcel and Lapuschkin, Sebastian and M{\"u}ller, Klaus-Robert and Samek, Wojciech},
  journal={arXiv preprint arXiv:1807.03418},
  year={2018}
}

@inproceedings{chefer2021generic,
  title={Generic attention-model explainability for interpreting bi-modal and encoder-decoder transformers},
  author={Chefer, Hila and Gur, Shir and Wolf, Lior},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={397--406},
  year={2021}
}

@article{deiseroth2023atman,
  title={AtMan: Understanding transformer predictions through memory efficient attention manipulation},
  author={Deiseroth, Bj{\"o}rn and Deb, Mayukh and Weinbach, Samuel and Brack, Manuel and Schramowski, Patrick and Kersting, Kristian},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2023}
}

@inproceedings{frommholz2023xai,
  title={XAI-based Comparison of Input Representations for Audio Event Classification},
  author={Frommholz, Annika and Seipel, Fabian and Lapuschkin, Sebastian and Samek, Wojciech and Vielhaben, Johanna},
  booktitle = {Proceedings of the International Conference on Content-Based Multimedia Indexing},
  pages = {126–132},
  year={2023}
}

@misc{haunschmid2020audiolime,
    title={{audioLIME: Listenable Explanations Using Source Separation}},
    author={Verena Haunschmid and Ethan Manilow and Gerhard Widmer},
    year={2020},
    eprint={2008.00582},
    archivePrefix={arXiv},
    primaryClass={cs.SD},
    howpublished={Proceedings of the International Workshop on Machine Learning and Music}
}

@inproceedings{kreuk2022audiogen,
  title={Audiogen: Textually guided audio generation},
  author={Kreuk, Felix and Synnaeve, Gabriel and Polyak, Adam and Singer, Uriel and D{\'e}fossez, Alexandre and Copet, Jade and Parikh, Devi and Taigman, Yaniv and Adi, Yossi},
  booktitle={Proceedings of the International Conference on Learning Representations},
  year={2023}
}

@inproceedings{liu2023audioldm,
  title={Audioldm: Text-to-audio generation with latent diffusion models},
  author={Liu, Haohe and Chen, Zehua and Yuan, Yi and Mei, Xinhao and Liu, Xubo and Mandic, Danilo and Wang, Wenwu and Plumbley, Mark D},
  booktitle = {Proceedings of the International Conference on Machine Learning},
  pages = {21450--21474},
  year = {2023},
}

@article{lundberg2017unified,
  title={A unified approach to interpreting model predictions},
  author={Lundberg, Scott M and Lee, Su-In},
  journal={Advances in Neural Information Processing Systems},
  volume={30},
  year={2017}
}

@article{nagahisarchoghaei2023empirical,
  title={An empirical survey on explainable ai technologies: Recent trends, use-cases, and categories from technical and application perspectives},
  author={Nagahisarchoghaei, Mohammad and Nur, Nasheen and Cummins, Logan and Nur, Nashtarin and Karimi, Mirhossein Mousavi and Nandanwar, Shreya and Bhattacharyya, Siddhartha and Rahimi, Shahram},
  journal={Electronics},
  volume={12},
  number={5},
  pages={1092},
  year={2023},
  publisher={MDPI}
}

@inproceedings{ribeiro2016should,
  title={``Why should I trust you?'' Explaining the predictions of any classifier},
  author={Ribeiro, Marco Tulio and Singh, Sameer and Guestrin, Carlos},
  booktitle={Proceedings of the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
  pages={1135--1144},
  year={2016}
}

@article{samek2017explainable,
  title={Explainable artificial intelligence: Understanding, visualizing and interpreting deep learning models},
  author={Samek, Wojciech and Wiegand, Thomas and M{\"u}ller, Klaus-Robert},
  journal={arXiv preprint arXiv:1708.08296},
  year={2017}

}

@article{schneider2023mo,
  title={Moûsai: Text-to-music generation with long-context latent diffusion},
  author={Schneider, Flavio and Kamal, Ojasv and Jin, Zhijing and Sch{\"o}lkopf, Bernhard},
  journal={arXiv preprint arXiv:2301.11757},
  year={2023}
}

@inproceedings{selvaraju2017grad,
  title={Grad-cam: Visual explanations from deep networks via gradient-based localization},
  author={Selvaraju, Ramprasaath R and Cogswell, Michael and Das, Abhishek and Vedantam, Ramakrishna and Parikh, Devi and Batra, Dhruv},
  booktitle={Proceedings of the IEEE International Conference on Computer Vision},
  pages={618--626},
  year={2017}
}

@inproceedings{sundararajan2017axiomatic,
  title={Axiomatic attribution for deep networks},
  author={Sundararajan, Mukund and Taly, Ankur and Yan, Qiqi},
  booktitle={Proceedings of the International Conference on Machine Learning},
  pages={3319--3328},
  year={2017}
}

@article{yang2023diffsound,
  title={Diffsound: Discrete diffusion model for text-to-sound generation},
  author={Yang, Dongchao and Yu, Jianwei and Wang, Helin and Wang, Wen and Weng, Chao and Zou, Yuexian and Yu, Dong},
  journal={IEEE/ACM Transactions on Audio, Speech, and Language Processing},
  year={2023},
  volume={31},
  pages={1720-1733},
  publisher={IEEE}
}

@inproceedings{ziv2024masked,
  title={Masked Audio Generation using a Single Non-Autoregressive Transformer},
  author={Ziv, Alon and Gat, Itai and Lan, Gael Le and Remez, Tal and Kreuk, Felix and D{\'e}fossez, Alexandre and Copet, Jade and Synnaeve, Gabriel and Adi, Yossi},
  booktitle={Proceedings of the International Conference on Learning Representations},
  year={2024},
}

