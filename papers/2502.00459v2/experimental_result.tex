\section{Experimental Results}

\begin{figure}
    \center
    \includegraphics[width=1.0 \linewidth]{fig/research_question1.pdf}
    \caption{Visualization of \mname{} and other methods.}
    \label{experiment}
\end{figure}

\subsection{RQ 1: Does \mname{} Generate Faithful Explanations?}

We evaluate the generated explanations by \mname{} based on factual and counterfactual reasoning, as presented in Table~\ref{table:main}. \mname{} achieves the best performance across the metrics $Fid_{F},$ $Fid_{CF}$, $KL_{F}$, and $KL_{CF}$, while also maintaining the smallest size ($Size$), demonstrating that our explanations are both simple and effective. The baseline, denoted as $N_{audio}=5$, generates audio conditioned on the same textual input five times to observe the inherent variance, serving as the lower bound for $Fid_{F}$, $KL_{F}$. \mname{}'s factual audio nearly reaches the lower bound, indicating high performance. Furthermore, significant changes in $Fid_{CF}$ and $KL_{CF}$ under counterfactual perturbations confirm that the explanations are both sufficient and necessary. The \mname{} with factual and counterfactual losses in Eq.\eqref{total}, outperforms the variants \mname \ w/ Eq.~\eqref{fact} and \mname \ w/ Eq.~\eqref{cfact}, which apply only factual or counterfactual loss with a regularization term. This indicates that the two losses complement each other, enhancing overall performance. Furthermore, we evaluate \mname \ w/ Eq.~\eqref{audioexpl} using an averaged explanation mask, showing the robustness of explainability in describing the entire audio. In contrast, other baselines fail to generate meaningful counterfactual audio, lacking the optimization properties needed to enforce counterfactual explanations. 

The strong performance highlights the effectiveness of leveraging latent embedding vectors to generate explanations. While most baselines are designed to explain supervised learning models, they rely on vectors that represent the probability distribution of the final audio token. This approach, however, does not align well with the inference process of audio generation models. In extreme cases, such as top-$k$ sampling ($k$=250), the 250-th audio token could be sampled, leading to significant discrepancies between the gradients or probability-related information the token most likely predicted by the model. In contrast, our approach avoids dependency on the sampling process, allowing the model to produce more faithful explanations.

\subsection{RQ 2: How Well Do the Explanations from \mname{} Reflect the Generated Audio?}

We visualize the explanations generated by \mname{} and other baselines, as shown in Figure~\ref{experiment}. \mname{} demonstrates a clear advantage in focusing on key audio elements. Unlike other baselines, which often assign relatively high importance scores to less important tokens like `A' and `with', \mname{} consistently assigns higher importance scores to crucial tokens such as `ticktocks' and `music'. For instance, \mname{} assigns a notably high importance score of 0.96 to `music', emphasizing its ability to focus on significant input tokens. In contrast, other models like $\text{Grad-CAM-e}$ and AtMan distribute importance more broadly, including less relevant tokens. These results show that \mname{} consistently provides faithful explanations, aligning the generated audio with the essential components of the input text.

\begin{figure}
    \center
    \includegraphics[width=1.0 \linewidth]{fig/research_question2-2.pdf}
    \caption{Explanation generated by \mname{} for two audios created from a single prompt. (a) includes bird sounds, while (b) does not.}
    \label{rq2}
\end{figure}

Furthermore, when generating audio from a prompt containing multiple concepts, some words may be less prominently reflected. In such case, \mname{} provides adequate explanations for each specific audio, indicating whether each word from the prompt has been incorporated into the generated audio. As illustrated in Figure~\ref{rq2}, the difference between the two audios is that bird sounds are present in Figure~\ref{rq2}-(a) but absent in Figure~\ref{rq2}-(b).
\mname{} effectively describes the audios by assigning high importance scores of 0.98 and 0.99 to the token `Water,' which is the primary sound in both audios. \mname{} assigns a score of 0.54 to `birds,' while it assigns a score of 0.14, accurately reflecting the different audio characteristics in each case. These results show that \mname{} can provide explanations that are well-suited to the corresponding audio. Furthermore, these explanations serve as valuable insights for editing generated audio to better align with user intention. 

\subsection{RQ 3: How Can Explanations Help Understand AudioGen Behavior?} 

We explore the output patterns of AudioGen using the explanations generated by \mname{}. First, we investigate whether AudioGen can effectively handle sentences containing negations and double negations, as shown in Figure~\ref{rq3}. The explanations of the generated audios are presented in response to input prompts containing `without thunder' and `without no thunder.' In both cases, the generated audio includes the sound of thunder along with the rain. Using \mname{}, we observe that `without' and `without no' have lower importance compared to 'thunder' in the explanations. We hypothesize that this occurs because the training dataset lacks sufficient examples of negation and double negation. An examination of the AudioCaps dataset reveals a scarcity of such cases. Additionally, by aggregating tokens from the explanations, we identify the top and bottom 50 tokens in Table~\ref{tabler3} in the Appendix. Tokens with high importance are predominantly nouns, such as `thunder,' while those with low importance include sound descriptors like `distant,' as well as sequential expressions like `before.' Such analyses could be used to debug TAG models or to identify potential inherent biases in their behavior. 

\begin{figure}
    \center
    \includegraphics[width=1.0 \linewidth]{fig/research_question3-1.pdf}
    \caption{Explanations generated from negated prompts: (a) single negation, (b) double negation.}
    \label{rq3}
\end{figure}

\subsection{RQ 4: Does \mname{} Generate Explanations Efficiently?}

\begin{table}[!ht]
\centering
\begin{tabular}{lrr}
\toprule
Method& Memory (MB)$\downarrow$& Time (s)$\downarrow$ \\
\midrule
    $\text{Grad-CAM-e}$ & 8641.306 & 49.038  \\
    $\text{Grad-CAM-a}$ & 41655.848 & 62.276  \\
    AtMan & \textbf{5081.957} & \textbf{7.295}  \\
    Chefer et al. & 41684.969 & 52.166 \\ \hline
    \mname \ w/ Eq.~\eqref{fact} & 11980.894 & 36.639 \\
    \mname \ w/ Eq.~\eqref{cfact} & 11981.114 & 37.373 \\
    \mname \ w/ Eq.~\eqref{audioexpl} & 12001.931 & 63.198 \\
    \mname & 12001.931 & 63.198 \\
\bottomrule
\end{tabular}
\caption{Efficiency analysis of \mname{} and other baseline methods. The best results are highlighted in \textbf{bold}.}
\label{table:eff}
\end{table}

We evaluate the efficiency of explanation methods based on the average time and total GPU memory usage per explanation, as shown in Table~\ref{table:eff}. For GPU memory efficiency, the results rank in the following order: AtMan, $\text{Grad-CAM-e}$, \mname{}, $\text{Grad-CAM-a}$, and Chefer et al. For time efficiency, the order is AtMan, $\text{Grad-CAM-e}$, Chefer et al., $\text{Grad-CAM-a}$, and \mname{}. Although AtMan is the most efficient, its performance remains subpar due to its simplistic approach. $\text{Grad-CAM-e}$ demonstrates greater memory efficiency compared to $\text{Grad-CAM-a}$ and Chefer et al., as it tracks a shallower layer. While \mname{} requires additional computational time to train explanation masks, it achieves memory efficiency by reducing GPU storage and operates with $\mathcal{O}(Lk)$ complexity, ensuring linear scalability for large-scale tasks.