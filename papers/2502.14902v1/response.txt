\section{Related Work}
\textbf{Text-based RAG}.
To improve text quality **Vaswani, "Attention Is All You Need"** and mitigate hallucination effects **Hermann et al., "Teaching Machines to Read and Comprehend"**, retrieval-augmented generation (RAG) is widely used in large language models (LLMs) by leveraging external databases. These databases primarily store data in textual form, containing a vast amount of domain knowledge that LLMs can directly retrieve. We refer to such systems as text-based RAG. Based on different retrieval mechanisms **Guu et al., "REALM: Retrieval-Augmented Language Model Pre-Training"**, text-based RAG can be broadly classified into two categories: \textbf{sparse vector retrieval} **Karpukhin et al., "Dense Passage Retriever"** and \textbf{dense vector retrieval} **Chen et al., "Retrieval Augmented Language Model Pre-Training"}. Sparse vector retrieval typically identifies the most representative words in each text segment by word frequency, and retrieves relevant text for a specific query based on keyword matching. In contrast, dense vector retrieval addresses issues like lexical mismatches and synonyms by encoding both query terms and text into vector embeddings. It then retrieves relevant content based on the similarity between these embeddings. However, most text-based RAG methods use a flat organization of text segments, and fail to capture essential relationships between chunks (\textit{e.g.,} the contextual dependencies), limiting the quality of LLM-generated responses **Bajaj et al., "Retrieval-Augmented Generation with Latent Retrieval"**.

\textbf{KG-RAG}.
Besides text databases, researchers have proposed retrieving information from knowledge graphs (KGs), known as KG-RAG **Yao et al., "Knowledge Graph Augmented Generative Adversarial Network"**. These methods can utilize existing KGs **Dong et al., "Knowledge Graph Question Answering by Reasoning over a Single Knowledge Base"** or their optimized versions **Zhang et al., "Optimized Knowledge Graph Embeddings for Multi-Task Learning"**, and enable LLMs to retrieve information of relevant entities and their relationships. Specifically, KG-RAG methods typically extract a local subgraph from the KG **Ji et al., "Knowledge Graph Augmented Generative Adversarial Network with Attention"**, such as the immediate neighbors of the entity mentioned in a query. However, most KG-RAG methods focus on addressing questions that can be answered with a single entity or relation in the KG **Yao et al., "Knowledge Graph Question Answering by Reasoning over a Single Knowledge Base"** , narrowing the scope of their applicability.

\textbf{Graph-based RAG}. Instead of utilizing pre-constructed KGs,
graph-based RAG **Kuo et al., "Graph-Based Retrieval-Augmented Generation Model"** typically organizes text databases as text-associated graphs, and focuses on global-level questions that need the information from multiple segments across a database. The graph construction process often involves extracting entities from the text and identifying relationships between these entities. Also, contextual information is included as descriptive text to minimize the information loss during the text-to-graph conversion. GraphRAG **Zhang et al., "Graph-Based Retrieval-Augmented Generation with Latent Retrieval"** first applies community detection algorithms on the graph, and then gradually aggregates the information from sub-communities to form higher-level community information. LightRAG **Kuo et al., "Lightweight Retrieval-Augmented Generation Model"** adopts a dual-stage retrieval framework to accelerate the retrieval process. First, it extracts both local and global keywords from the question. Then, it retrieves relevant nodes and edges using these keywords, treating the ego-network information of the retrieved nodes as the final retrieval results. This approach simplifies the retrieval process and effectively handles global-level tasks. However, the retrieved information covers all immediate neighbors of relevant nodes, which may introduce noise harming the answer quality. We also notice a concurrent work MiniRAG **Zhang et al., "Mini-Graph Retrieval-Augmented Generation Model"** that leverages path information to assist retrieval. But they focus on addressing questions that can be answered by the information of a specific node, and thus explore paths between query-related and answer-related nodes like KG reasoning **Yao et al., "Knowledge Graph Question Answering by Reasoning over a Single Knowledge Base"** . Their implementation details such as path discovery and integration are also quite different from ours.