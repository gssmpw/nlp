\section{Conclusion and Future Work}
In this work, we introduce AISafetyLab, a comprehensive framework and resource for advancing AI safety evaluation and improvement. For users who prefer not to modify the internal code, AISafetyLab offers broad method and model coverage, simple interfaces, and diverse examples to facilitate quick experimentation and application. For developers interested in implementing new methods, our structured design aims to minimize effort and streamline integration.

We are committed to continuously maintaining and enhancing AISafetyLab. Some of our future plans include: \begin{itemize}
    \item Adding an explainability module to improve understanding of AI safety mechanisms.
    \item Implementing methods for multimodal safety.
    \item Implementing methods for agent safety.
    \item Integrate more methods for LLM safety. 
    \item Regularly updating the paper list for AI safety.
    \item Maintaining and improving the codebase by addressing bugs and issues.
    
\end{itemize}
We are dedicated to executing these plans and warmly welcome community suggestions and contributions, as collaborative efforts will be instrumental in advancing AI safety.