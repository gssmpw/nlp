

\begin{algorithm}[!t]
\textbf{Inputs:}
$\mathcal{M}$: hallucination detection model; 
$\mathit{tokenizer}$: tokenizer for $\mathcal{M}$; $\mathit{q}$: a query submitted by users;
$\mathit{context}$: the context to answer the question; retrieved from vector data storage;
$a$: the answer returned by an LLM for the question; \textit{inference}\_\textit{prompt}\_\textit{template}: see Figure~\ref{fig: training_data_example}. 



\nl{\bf Function $\boldsymbol{\mathit{inference}(\mathcal{M}, \mathit{q}, \mathit{context}, a, k)}$} \nllabel{ln:inference}
\Begin{


\nl $\mathit{prompt}\leftarrow$\textit{inference}\_\textit{prompt}\_\textit{template}($\mathit{q}$, $\mathit{context}$, $a$)

\nl $\mathit{tokenized}\_\mathit{prompt}\leftarrow \mathit{tokenizer}$($\mathit{prompt}$)

\nl $\mathit{halu}\_\mathit{res}\leftarrow$ 
$\mathcal{M}$.$\mathit{generate}$($\mathit{tokenized}\_\mathit{prompt}$)

\nl $\mathit{first}\_\mathit{word}\_\mathit{logits}\leftarrow \mathit{halu}\_\mathit{res}$.$\mathit{logits}$[0], 

\nl$\mathit{results}\leftarrow\mathit{softmax}$($\mathit{first}\_\mathit{word}\_\mathit{logits}$)

\nl $\mathit{top\_k\_probs}\leftarrow \mathit{top}$($\mathit{results}$, $k$)

\nl $P_{\mathit{halu}}(a)\leftarrow \mathit{compute}\_\mathit{halu}\_\mathit{prob}(\mathit{top}\_k\_\mathit{probs})$ 

% \\\Comment{See Definition~\ref{def:halu_prob}}


\nl \lIf{$P(a)\geq 0.5$}{\textbf{return} True}

\nl{\textbf{return} False}
}

\caption{Hallucination detection model inference.}
\label{alg:inference}
\end{algorithm}
