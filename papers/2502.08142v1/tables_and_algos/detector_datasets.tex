\begin{table*}[htbp]
% \centering
\small
\caption{Dataset Overview}
\label{tab:exp_datasets}
\begin{center}


\begin{tabular}{cccccp{8.4cm}}
\toprule
\textbf{Dataset} & \textbf{Data size} & \textbf{Train} & \textbf{Validation} & \textbf{Test} & \textbf{Description} \\
\midrule

\multicolumn{6}{c}{\cellcolor[HTML]{EFEFEF}\textbf{\detection~Training Data}} \\ 

HEx-PHI~\citep{anonymous2024finetuning} & 330 & 330 & 0 & 0 & Harmful instructions of 11 prohibited categories.\\
%330 harmful instructions (30 examples x 11 prohibited categories) for LLM harmfulness evaluation. \\

OpenAI Moderation~\citep{openai-data-paper} & 1680 & 160 & 1,500 & 0 & Prompts annotated with OpenAI taxonomy. \\

Hotpot QA~\citep{yang2018hotpotqa} & 113k & 3,000 & 2,500 & 500 & QA pairs based on Wikipedia knowledge. \\

Truthful QA~\citep{lin2021truthfulqa} & 827 & 500 & 100 & 100 & Questions spanning 38 categories, including health, law, politics, etc. \\

Awesome GPT Prompts~\citep{awesome-chatgpt-prompts} & 153 & 0 & 150 & 0 & Awesome prompt examples to be used with ChatGPT. \\

Jigsaw Unintended-Bias~\citep{jigsaw-unintended-bias-in-toxicity-classification} & 2M & 100,000 & 2,000 & 300 & Comment data that contains labels for unsafe content. \\

GPT-Jailbreak~\citep{ChatGPT-Jailbreak-Prompts} & 79 & 0 & 78 & 0 & ChatGPT jailbreak prompts. \\

Jailbreak~\citep{jailbreak-classification} & 1.3k & 400 & 0 & 70 & A dataset that contains jailbreak prompts and benign prompts. \\

Personalization Prompt~\citep{filtered_personalization_prompt_response} & 10.4k & 1,000 & 800 & 200 & Prompt-response pairs for personalized interactions with LLMs. \\

QA-Chat Prompts~\citep{qa-chat-prompts} & 200 & 0 & 200 & 0 & A QA dataset. \\

ChatGPT Prompts~\citep{ChatGPT-prompts} & 360 & 350 & 0 & 0 & Human prompts and ChatGPT responses. \\

10k-Prompts Ranked~\citep{10k_prompts_ranked} & 10.3k & 500 & 500 & 200 & Prompts with quality rankings created by 314 members of the open-source ML community using Argilla, an open-source tool to label data. \\

Iterative Prompt~\citep{iterative-prompt-v1-iter1-20K} & 20k & 500 & 500 & 200 & A dataset of user prompts. \\

Instruction Following~\citep{instruction-following} & 514 & 200 & 340 & 0 & An instruction dataset. \\

\multicolumn{6}{c}{\cellcolor[HTML]{EFEFEF}\textbf{\detection~Evaluation Data}} \\ 

ToxicChat~\citep{lin2023toxicchat} & 10.2k%165 
& - & - & - &  Unsafe content dataset for evaluation. \\


\multicolumn{6}{c}{\cellcolor[HTML]{EFEFEF}\textbf{\grounding~Evaluation Data}} \\ 

E-Commerce~\citep{e_commerce_dataset} & 65 &-&- & -& Use the ``faq'' subset that contains QA pairs between users and agents. \\

PatientDoctor~\citep{patient-doctor-chat-data} & 379k&-&- & - & Dialogue data between doctors and patients. \\

ChatDoctor dataset~\citep{ChatDoctor-dataset} & 119.4k&-&- & - & Dialogue data between doctors and patients. \\


\multicolumn{6}{c}{\cellcolor[HTML]{EFEFEF}\textbf{\fixing~Wrapper Evaluation Data}} \\ 


E-Commerce~\citep{e_commerce_dataset} & 1.89k &-&- & -& Use the ``faq'' and the ``product'' subsets that contains product descriptions. \\

RedditSYACURL Dataset~\citep{reddit-url-data} & 8.61k &-&- & -& A dataset that contains titles, summaries, and links of articles. \\


\multicolumn{6}{c}{\cellcolor[HTML]{EFEFEF}\textbf{\detection~Hallucination Detection  Data}} \\ 
HaluEval-qa~\citep{li2023halueval} & 10k &8,000&1,500 & 500& 
\multirow{4}{8.6cm}{A hallucination dataset with 3 subsets: 1) ``qa'' with question, right answer, hallucinated answer, and knowledge; 2) ``dialogue'' with dialogue history, right response, hallucinated response, and knowledge; and
3) ``summarization'' with document, right summary, and hallucinated summary.}\\
HaluEval-dialogue~\citep{li2023halueval} & 10k &8,000&1,500 & 500& \\
HaluEval-summarization~\citep{li2023halueval} & 10k &8,000&1,500 & 500& \\
\\


\multicolumn{6}{c}{\cellcolor[HTML]{EFEFEF}\textbf{\fixing~Hallucination Correction Data}} \\ 
HaluEval-qa~\citep{li2023halueval} & 10k &8,000&1,000 & 1,000& 
\multirow{3}{8.6cm}{%The hallucination fixing data were integrated with a column ``hallucination reason'' that was generated based on the hallucination detection results in \detection. 
The hallucination correction dataset was augmented with a \texttt{hallucination\char`_reason} column, derived from the detection results of \detection. 
}
\\
HaluEval-dialogue~\citep{li2023halueval} & 10k &8,000&1,000 & 1,000& \\
HaluEval-summarization~\citep{li2023halueval} & 10k &8,000&1,000 & 1,000& \\

\bottomrule
\end{tabular}
\end{center}
\end{table*}


