%%%%%%%% ICML 2025 EXAMPLE LATEX SUBMISSION FILE %%%%%%%%%%%%%%%%%

\documentclass{article}

% Recommended, but optional, packages for figures and better typesetting:
\usepackage{microtype}
\usepackage{graphicx}
\usepackage{booktabs} % for professional tables

% hyperref makes hyperlinks in the resulting PDF.
% If your build breaks (sometimes temporarily if a hyperlink spans a page)
% please comment out the following usepackage line and replace
% \usepackage{icml2025} with \usepackage[nohyperref]{icml2025} above.
\usepackage{hyperref}


% Attempt to make hyperref and algorithmic work together better:
\newcommand{\theHalgorithm}{\arabic{algorithm}}

% Use the following line for the initial blind version submitted for review:
% \usepackage{icml2025}
 
% If accepted, instead use the following line for the camera-ready submission:
\usepackage[accepted]{icml2025}

% For theorems and such
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{mathtools}
\usepackage{amsthm}

% if you use cleveref..
\usepackage[capitalize,noabbrev]{cleveref}
% \usepackage{hyperref} 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% THEOREMS
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\theoremstyle{plain}
\newtheorem{theorem}{Theorem}[section]
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{corollary}[theorem]{Corollary}
\theoremstyle{definition}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{assumption}[theorem]{Assumption}
\theoremstyle{remark}
\newtheorem{remark}[theorem]{Remark}

% Todonotes is useful during development; simply uncomment the next line
%    and comment out the line below the next line to turn off comments
%\usepackage[disable,textsize=tiny]{todonotes}
\usepackage[textsize=tiny]{todonotes}

\usepackage{listings}
\usepackage{enumitem}
\usepackage{subfig}
% \usepackage{subcaption}
% \usepackage{multicol}
\usepackage{tcolorbox}

% Fix the algorithm line reference
\newcommand{\alglinelabel}{%
  \addtocounter{ALC@line}{-1}% Reduce line counter by 1
  \refstepcounter{ALC@line}% Increment line counter with reference capability
  \label% Regular \label
}


% The \icmltitle you define below is probably too long as a header.
% Therefore, a short form for the running title is supplied here:
\icmltitlerunning{Accelerating Unbiased LLM Evaluation via Synthetic Feedback}

\input{notations}

\begin{document}
\twocolumn[
\icmltitle{Accelerating Unbiased LLM Evaluation via Synthetic Feedback}

% It is OKAY to include author information, even for blind
% submissions: the style file will automatically remove it for you
% unless you've provided the [accepted] option to the icml2025
% package.

% List of affiliations: The first argument should be a (short)
% identifier you will use later to specify author affiliations
% Academic affiliations should list Department, University, City, Region, Country
% Industry affiliations should list Company, City, Region, Country

% You can specify symbols, otherwise they are numbered in order.
% Ideally, you should not use this facility. Affiliations will be numbered
% in order of appearance and this is the preferred way.
\icmlsetsymbol{equal}{*}

\begin{icmlauthorlist}
\icmlauthor{Zhaoyi Zhou}{CMU}
\icmlauthor{Yuda Song}{CMU}
\icmlauthor{Andrea Zanette}{CMU}
\end{icmlauthorlist}

\icmlaffiliation{CMU}{Carnegie Mellon University}

\icmlcorrespondingauthor{Zhaoyi Zhou}{zhaoyiz@andrew.cmu.edu}

% You may provide any keywords that you
% find helpful for describing your paper; these are used to populate
% the "keywords" metadata in the PDF but will not be shown in the document
\icmlkeywords{Machine Learning, ICML}

\vskip 0.3in
]

% this must go after the closing bracket ] following \twocolumn[ ...

% This command actually creates the footnote in the first column
% listing the affiliations and the copyright notice.
% The command takes one argument, which is text to display at the start of the footnote.
% The \icmlEqualContribution command is standard text for equal contribution.
% Remove it (just {}) if you do not need this facility.

%\printAffiliationsAndNotice{}  % leave blank if no need to mention equal contribution
\printAffiliationsAndNotice{} % otherwise use the standard text.

\begin{abstract}
When developing new large language models (LLMs), a key step is evaluating their final performance, often by computing the win-rate against a reference model based on external feedback. Human feedback is the gold standard, particularly for capturing nuanced qualities like coherence, readability, and alignment with human expectations. However, human evaluations are costly --- even for large tech companies --- and when conducted with active users, they may negatively impact user experience.
A promising alternative is synthetic feedback, where evaluations are conducted by other large language models, including reward models. While this eliminates the need for costly human annotations, it introduces biases that may distort the evaluation process.
In this work, we propose a statistically principled framework that integrates human and synthetic feedback to reduce reliance on human annotations while maintaining unbiased win-rate calculations. 
Our experiments demonstrate a reduction in human annotations by up to 12.2\% with an off-the-shelf synthetic evaluator and up to 24.8\% with a finetuned variant. Apart from being generalizable, scalable, and free of hyper-parameter tuning, our method offers predictable annotation savings, which can be estimated based on data-dependent characteristics.
\end{abstract}

\vspace{-5mm}
\section{Introduction}\label{sec:intro}
\input{introduction}

\section{Related Work}\label{sec:related}
\input{related}

\section{Preliminaries}\label{sec:prelim}
\input{preliminary}

\section{Efficient LLM Evaluation via Control Variates}\label{sec:method}
\input{method}

\section{Experiments}\label{sec:experiment}
\input{experiment}

\section{Conclusion}
\input{conclusion}

\section*{Impact Statement}
This work seeks to accelerate LLM evaluation while preserving its unbiasedness. The societal and ethical impact aligns with that of most LLM evaluation research, which has been widely discussed.


\bibliography{rlaihf}
\bibliographystyle{icml2025}

\newpage
\appendix
\onecolumn
\section{Proof of \Cref{prop:ctrl_var}}
\label{sec:proof}
Note that all expectations, variances, covariances and correlation coefficients in this section are taken under the distribution $x \sim \mathrm{Uniform}(\mathcal{X})$, $y^1 \sim \ell^1(\cdot \mid x)$, $y^2 \sim \ell^2(\cdot \mid x)$.
\paragraph{Proof of unbiasedness}
We have 
\begin{align*}
    \E_{x,y^1,y^2}\Mp{z^{\mathsf{cv}, \alpha}} 
    & = \E_{x,y^1,y^2}\Mp{z-\alpha\Sp{\hat z - \mu_{\hat z}}}\\
    & = \E_{x,y^1,y^2}[z] - \alpha\Sp{\E_{x,y^1,y^2}[\hat z] - \mu_{\hat z}} \\
    & = \E_{x,y^1,y^2}[z] \\
    & = p\Sp{\ell^1 \succ \ell^2}.
\end{align*}
\paragraph{Proof of variance reduction} We have 
\begin{align*}
    \var_{x,y^1,y^2}\Mp{z^{\mathsf{cv}, \alpha}} 
    & = \var_{x,y^1,y^2}\Mp{z-\alpha\Sp{\hat z - \mu_{\hat z}}}\\
    & = \var_{x,y^1,y^2}\Mp{z} - 2\alpha \cov_{x,y^1,y^2}\Mp{z, \Sp{\hat z - \mu_{\hat z}}} + \alpha^2 \var_{x,y^1,y^2}\Mp{\hat z - \mu_{\hat z}} \\
    & = \var_{x,y^1,y^2}\Mp{z} - 2\alpha \cov_{x,y^1,y^2}\Mp{z, \hat z} + \alpha^2 \var_{x,y^1,y^2}\Mp{\hat z} \\
    & = \var_{x,y^1,y^2}\Mp{\hat z} \Sp{\alpha - \frac{\cov_{x,y^1,y^2}\Mp{z, \hat z}}{\var_{x,y^1,y^2}\Mp{\hat z}}}^2 + \var_{x,y^1,y^2}\Mp{z} - \frac{\Sp{\cov_{x,y^1,y^2}\Mp{z, \hat z}}^2}{\var_{x,y^1,y^2}\Mp{\hat z} } \\
    & \geq \var_{x,y^1,y^2}\Mp{z} - \frac{\Sp{\cov_{x,y^1,y^2}\Mp{z, \hat z}}^2}{\var_{x,y^1,y^2}\Mp{\hat z} }.
\end{align*}
The equality holds if and only if $\alpha = \frac{\cov_{x,y^1,y^2}\Mp{z, \hat z}}{\var_{x,y^1,y^2}\Mp{\hat z}}$.
To further simplify the formula, recall that  
\begin{align*}
    \rho^2 = \Sp{\corr_{x,y^1,y^2}\Mp{z, \hat z}}^2 = \frac{\Sp{\cov_{x,y^1,y^2}\Mp{z, \hat z}}^2}{\var_{x,y^1,y^2}[z]\cdot \var_{x,y^1,y^2}[\hat z]}.
\end{align*}
Therefore we have 
\begin{align*}
    \var_{x,y^1,y^2}\Mp{z^{\mathsf{cv}, \alpha}} 
    & \geq \var_{x,y^1,y^2}\Mp{z} - \frac{\Sp{\cov_{x,y^1,y^2}\Mp{z, \hat z}}^2}{\var_{x,y^1,y^2}\Mp{\hat z} } \\
    & = \var_{x,y^1,y^2}\Mp{z} - \rho^2 \var_{x,y^1,y^2}\Mp{z} \\
    & = (1-\rho^2) \var_{x,y^1,y^2}\Mp{z}.
\end{align*}
The optimality point is $\alpha^* = \frac{\cov_{x,y^1,y^2}\Mp{z, \hat z}}{\var_{x,y^1,y^2}\Mp{\hat z}}$.

\paragraph{Proof of human annotation saving}
Since all samples are i.i.d., we have 
\begin{align*}
\var\Mp{\frac{1}{m}\sum_{j=1}^m z^{\mathsf{cv}; \alpha}_{i_j}} 
& = \frac{1}{m} \var_{x,y^1,y^2}[z^{\mathsf{cv}, \alpha^*}] \\
& = \frac{1}{m} (1-\rho^2) \var_{x,y^1,y^2}[z] \\
& = \frac{1}{n} (1-\rho^2) \var_{x,y^1,y^2}[z] \\
& = \var\Mp{\frac{1}{n}\sum_{i=1}^n z_{i}}.
\end{align*}

\section{Experiment Details}
\subsection{Hyperparameters}
The Control Variates Evaluation \Cref{alg:cv} has no hyperparameters except for the optional finetuning procedure. When finetuning Skywork-8B and GRM-2B on Chatbot Arena and MT Bench, we use global batch size 32 and train for 1 epoch. The finetuning of GRM-2B on Chatbot Arena uses learning rate 1e-6, others all use learning rate 3e-6.

To determine the optimal hyperparameters for finetuning, we conduct a systematic search over a range of learning rates and batch sizes. For instance, when we finetune Skywork-8B on Chatbot Arena, we follow these steps:
\begin{enumerate}[label=(\arabic*)]
\item We sort the LLM models in Chatbot Arena in alphabetical order and select the first model, RMKV-4-Raven-14B, as the holdout model to split train and test dataset.
\item We tested learning rates in $\{1\times10^{-7},3\times 10^{-7},1\times10^{-6},3\times 10^{-6}, 1\times10^{-5},3\times 10^{-5}\}$ and batch sizes in
$\{32,64,128\}$. For each hyperparameter combination, we finetune for one epoch and record the final test accuracy.
\item The combination yielding the highest final test accuracy is selected as the optimal hyperparameter setting. We use the chosen hyperparameter setting to finetune Skywork-8B on all other holdout models.
\end{enumerate}
The similar procedure applies when we finetune other synthetic evaluators on other benchmarks.

\subsection{Hardware}
The experiments are run on H100 GPUs. Finetuning Skywork-8B requires 4 GPUs. Finetuning GRM-2B as well as the collection of synthetic annotations can all be done on 1 GPU. 
\subsection{Prompt Template}
We use the GPT-4 annotations for MT-Bench from the Hugging Face repository \url{https://huggingface.co/datasets/lmsys/mt_bench_human_judgments/viewer/default/gpt4_pair}.

We follow the prompt template in \citep[Figure 5, Appendix A]{zheng2023judging} to get GPT-4 annotations in Chatbot Arena.

\section{Additional Experiment Results}
\subsection{Bias of Synthetic Evaluation}
As described in \Cref{sec:bootstrap}, we measure the averaged mean square error of Human Evaluation, Synthetic Evaluation and Control Variates Evaluation on different evaluators and datasets, as shown in \Cref{fig:bias_full}. The Synthetic Evaluation has a significantly high bias, while the error of both Human Evaluation and Control Variates Evaluation converge to zero.
\begin{figure}[ht]
    \centering
    \subfloat[Chatbot Arena, ArmoRM-8B]{
    \centering
    \includegraphics[width=0.235\linewidth]{chatbot-arena_armorm_pretrained_err.png}
    }
    \hfill
    \subfloat[Chatbot Arena, GRM-2B]{
    \centering
    \includegraphics[width=0.235\linewidth]{chatbot-arena_gemma_pretrained_err.png}
    }
    \hfill
    \subfloat[Chatbot Arena, Skywork-8B]{
    \centering
    \includegraphics[width=0.235\linewidth]{chatbot-arena_skywork_pretrained_err.png}
    }
    \hfill
    \subfloat[Chatbot Arena, GPT-4]{
    \centering
    \includegraphics[width=0.235\linewidth]{chatbot-arena_gpt4_pretrained_err.png}
    }
    \hfill

    \subfloat[MT Bench, ArmoRM-8B]{
    \centering
    \includegraphics[width=0.235\linewidth]{mt-bench_armorm_pretrained_err.png}
    }
    \hfill
    \subfloat[MT Bench, GRM-2B]{
    \centering
    \includegraphics[width=0.235\linewidth]{mt-bench_gemma_pretrained_err.png}
    }
    \hfill
    \subfloat[MT Bench, Skywork-8B]{
    \centering
    \includegraphics[width=0.235\linewidth]{mt-bench_skywork_pretrained_err.png}
    }
    \hfill
    \subfloat[MT Bench, GPT-4]{
    \centering
    \includegraphics[width=0.235\linewidth]{mt-bench_gpt4_pretrained_err.png}
    }
    \hfill

    \subfloat[Chatbot Arena, GRM-2B (ft)]{
    \centering
    \includegraphics[width=0.235\linewidth]{chatbot-arena_gemma_finetuned_err.png}
    }
    \hfill
    \subfloat[MT Bench, GRM-2B (ft)]{
    \centering
    \includegraphics[width=0.235\linewidth]{mt-bench_gemma_finetuned_err.png}
    }
    \hfill
    \subfloat[Chatbot Arena, Skywork-8B (ft)]{
    \centering
    \includegraphics[width=0.235\linewidth]{chatbot-arena_skywork_finetuned_err.png}
    }
    \hfill
    \subfloat[MT Bench, Skywork-8B (ft)]{
    \centering
    \includegraphics[width=0.235\linewidth]{mt-bench_skywork_finetuned_err.png}
    }
    \hfill
    \caption{Averaged mean square error of Human Evaluation, Synthetic Evaluation and Control Variates Evaluation on different evaluators and datasets. The Synthetic Evaluation has a significantly high bias, while the error of both Human Evaluation and Control Variates Evaluation converge to zero. }
    \label{fig:bias_full}
\end{figure}

\subsection{Human Annotation Saving Ratio Matches Variance Reduction in Practice}
\label{sec:var_full}
As described in \Cref{sec:exp_cv_human}, we measure the averaged mean square error versus number of samples for different evaluators on different datasets. The $x$-coordinate of curves ``Human'' and ``Control Variates'' correspond to the number of human annotations \citep{zheng2023judging}. The curve ``Control Variates (shifted)'' is derived by horizontally scaling the Control Variates curve by $1/(1-s)$, in which $s$ is the averaged human annotation saving ratio in \Cref{tab:result_save}. The human annotation saving ratio aligns perfectly with the actual variance relationship between Human Evaluation and Control Variates Evaluation. 

\begin{figure}[ht]
    \centering
    \subfloat[Chatbot Arena, GRM-2B]{
    \centering
    \includegraphics[width=0.235\linewidth]{chatbot-arena_gemma_pretrained_var.png}
    }
    \hfill
    \subfloat[Chatbot Arena, ArmoRM-8B]{
    \centering
    \includegraphics[width=0.235\linewidth]{chatbot-arena_armorm_pretrained_var.png}
    }
    \hfill
    \subfloat[Chatbot Arena, Skywork-8B]{
    \centering
    \includegraphics[width=0.235\linewidth]{chatbot-arena_skywork_pretrained_var.png}
    }
    \hfill
    \subfloat[Chatbot Arena, GPT-4]{
    \centering
    \includegraphics[width=0.235\linewidth]{chatbot-arena_gpt4_pretrained_var.png}
    }
    \hfill

    \subfloat[MT Bench, ArmoRM-8B]{
    \centering
    \includegraphics[width=0.235\linewidth]{mt-bench_armorm_pretrained_var.png}
    }
    \hfill
    \subfloat[MT Bench, GRM-2B]{
    \centering
    \includegraphics[width=0.235\linewidth]{mt-bench_gemma_pretrained_var.png}
    }
    \hfill
    \subfloat[MT Bench, Skywork-8B]{
    \centering
    \includegraphics[width=0.235\linewidth]{mt-bench_skywork_pretrained_var.png}
    }
    \hfill
    \subfloat[MT Bench, GPT-4]{
    \centering
    \includegraphics[width=0.235\linewidth]{mt-bench_gpt4_pretrained_var.png}
    }
    \hfill

    \subfloat[Chatbot Arena, GRM-2B (ft)]{
    \centering
    \includegraphics[width=0.235\linewidth]{chatbot-arena_gemma_finetuned_var.png}
    }
    \hfill
    \subfloat[MT Bench, GRM-2B (ft)]{
    \centering
    \includegraphics[width=0.235\linewidth]{mt-bench_gemma_finetuned_var.png}
    }
    \hfill
    \subfloat[Chatbot Arena, Skywork-8B (ft)]{
    \centering
    \includegraphics[width=0.235\linewidth]{chatbot-arena_skywork_finetuned_var.png}
    }
    \hfill
    \subfloat[MT Bench, Skywork-8B (ft)]{
    \centering
    \includegraphics[width=0.235\linewidth]{mt-bench_skywork_finetuned_var.png}
    }
    \hfill
    \caption{Averaged mean square error versus number of samples for different evaluators on different datasets. The $x$-coordinate of curves ``Human'' and ``Control Variates'' correspond to the number of human annotations \citep{zheng2023judging}. The curve ``Control Variates (shifted)'' is derived by horizontally scaling the Control Variates curve by $1/(1-s)$, in which $s$ is the averaged human annotation saving ratio in \Cref{tab:result_save}. The human annotation saving ratio aligns perfectly with the actual variance relationship between Human Evaluation and Control Variates Evaluation. }
    \label{fig:var_full}
\end{figure}

\subsection{Human Annotation Saving Ratio on Each LLM pair}
\label{sec:app_saving}
We visualize the human annotation ratio (in percentage) on each LLM pair that we use to compute the averaged human annotation saving ratio in \Cref{tab:result_save}. The results are shown in \Cref{fig:heatmap_chatbot,fig:heatmap_mtbench}. For a pretrained evaluator, each entry of the matrix is the human annotation saving ratio (in percentage) on that LLM pair. For a finetuned evaluator, each entry of the matrix is the human annotation saving ratio (in percentage) on the corresponding LLM pair, in which the LLM on the row is the left-out LLM, while the LLM on the column is used in finetuning. Please refer to \Cref{sec:exp_setup} for the details of finetuning procedure. Therefore, the matrices for pretrained evaluators are symmetric, while they are asymmetric for finetuned evaluators. The diagonal entries are white and do not have values becuase measuring human annotation saving ratio on identical LLMs is meaningless.

Note that there are some additional white entries with no values when testing GPT-4 as the synthetic evaluator. This is because GPT-4 cannot always follow the prompt template, so that sometimes we cannot extract a valid preference out of the output. In case that there are too few samples in an LLM pair, it is likely that we cannot compute a valid human annotation saving ratio.

\begin{figure}[ht]
    \centering
    \subfloat[Chatbot Arena, GRM-2B]{
    \centering
    \includegraphics[width=0.4\linewidth]{chatbot-arena_gemma_pretrained_saving.png}
    }
    \hfill
    \subfloat[Chatbot Arena, GRM-2B (ft)]{
    \centering
    \includegraphics[width=0.4\linewidth]{chatbot-arena_gemma_finetuned_saving.png}
    }
    \hfill

    \subfloat[Chatbot Arena, Skywork-8B]{
    \centering
    \includegraphics[width=0.4\linewidth]{chatbot-arena_skywork_pretrained_saving.png}
    }
    \hfill
    \subfloat[Chatbot Arena, Skywork-8B (ft)]{
    \centering
    \includegraphics[width=0.4\linewidth]{chatbot-arena_skywork_finetuned_saving.png}
    }
    \hfill
    
    \subfloat[Chatbot Arena, ArmoRM-8B]{
    \centering
    \includegraphics[width=0.4\linewidth]{chatbot-arena_armorm_pretrained_saving.png}
    }
    \hfill
    \subfloat[Chatbot Arena, GPT-4]{
    \centering
    \includegraphics[width=0.4\linewidth]{chatbot-arena_gpt4_pretrained_saving.png}
    }
    \hfill
    \caption{Human annotation saving ratio (in percentage) on each LLM pair for different evaluators on Chatbot Arena. Diagonal entries are white and do not have values because it is meaningless to compute the human annotation saving ratio on two identical LLMs. Non-diagonal white entries in (f) imply an invalid result, because sometimes valid preference cannot be extracted from GPT-4's response. }
    \label{fig:heatmap_chatbot}
\end{figure}

\begin{figure}
    \centering
    \subfloat[MT Bench, GRM-2B]{
    \centering
    \includegraphics[width=0.4\linewidth]{mt-bench_gemma_pretrained_saving.png}
    }
    \hfill
    \subfloat[MT Bench, GRM-2B (ft)]{
    \centering
    \includegraphics[width=0.4\linewidth]{mt-bench_gemma_finetuned_saving.png}
    }
    \hfill

    \subfloat[MT Bench, Skywork-8B]{
    \centering
    \includegraphics[width=0.4\linewidth]{mt-bench_skywork_pretrained_saving.png}
    }
    \hfill
    \subfloat[MT Bench, Skywork-8B (ft)]{
    \centering
    \includegraphics[width=0.4\linewidth]{mt-bench_skywork_finetuned_saving.png}
    }
    \hfill
    
    \subfloat[MT Bench, ArmoRM-8B]{
    \centering
    \includegraphics[width=0.4\linewidth]{mt-bench_armorm_pretrained_saving.png}
    }
    \hfill
    \subfloat[MT Bench, GPT-4]{
    \centering
    \includegraphics[width=0.4\linewidth]{mt-bench_gpt4_pretrained_saving.png}
    }
    \hfill
    \caption{Human annotation saving ratio (in percentage) on each LLM pair for different evaluators on MT Bench. Diagonal entries are white and do not have values because it is meaningless to compute the human annotation saving ratio on two identical LLMs.}
    \label{fig:heatmap_mtbench}
\end{figure}


\end{document}


% This document was modified from the file originally made available by
% Pat Langley and Andrea Danyluk for ICML-2K. This version was created
% by Iain Murray in 2018, and modified by Alexandre Bouchard in
% 2019 and 2021 and by Csaba Szepesvari, Gang Niu and Sivan Sabato in 2022.
% Modified again in 2023 and 2025 by Sivan Sabato and Jonathan Scarlett.
% Previous contributors include Dan Roy, Lise Getoor and Tobias
% Scheffer, which was slightly modified from the 2010 version by
% Thorsten Joachims & Johannes Fuernkranz, slightly modified from the
% 2009 version by Kiri Wagstaff and Sam Roweis's 2008 version, which is
% slightly modified from Prasad Tadepalli's 2007 version which is a
% lightly changed version of the previous year's version by Andrew
% Moore, which was in turn edited from those of Kristian Kersting and
% Codrina Lauth. Alex Smola contributed to the algorithmic style files.