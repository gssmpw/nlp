\begin{center}
{\Large \bf Supplemental Material for `Fat-Tree QRAM: A High-Bandwidth Shared Quantum Random Access Memory for Parallel Queries'}
\end{center}

\section{Appendix}
\label{sec:appendix}


\subsection{Step-by-step Query Procedure}
\label{subsec:BBdetail}

We formally define the elementary QRAM instructions as follows with Figure~\ref{fig:instruction} providing a visual representation of the operations


\begin{enumerate}
    \item \emph{\texttt{LOAD} (L)}: Load operation involves loading a new qubit through the escape to the input qubit of a root router in Fat-Tree QRAM. This operation only happens in the root node of QRAM.
    \item \emph{\texttt{TRANSPORT} (T)}: Transport operation uses a \texttt{SWAP} gate to move a qubit from a router's output qubit to the next level's input qubit
    \item \emph{\texttt{ROUTE} (R)}: Route uses \texttt{CSWAP} gates to route a qubit from the router's input to the outputs according to the state of router qubit. Generally, it is implemented using two \texttt{CSWAP} gates (controlled on the router qubit being 0 and 1), but our computations assume it costs a single circuit layer to simplify complexity and fidelity calculations. Regardless of the implementation, the asymptotic results will remain the same.
    \item \emph{\texttt{STORE} (S)}: Store operation refers to storing an input qubit by swapping it from the quantum router's input qubit to the router qubit. This operation only happens at the highest unloaded layer of a QRAM, and increases the depth of the loaded tree by one.
    \item \emph{\texttt{CLASSICAL-GATES} (CG)}: Performs classically controlled gates to modify the output qubits of the last QRAM level according to values in the classical database.
\end{enumerate}




\algblock{Parallel}{EndParallel}
\begin{algorithm}[t]
\caption{\textsc{Load Layer}}\label{alg:load}
\begin{algorithmic}[1]
    \State \textbf{Require: } $loaded$ as number of address qubits loaded
    \State \textbf{Require: }  $s$ as next address depth to be stored
    \State \textbf{Require: } $k$ as the current QRAM copy being used
    \State \textbf{Initialize: } $loaded \leftarrow 0, s \leftarrow 0, k \leftarrow 0$ $\forall$ new queries
    \newline    
    \Parallel
        \State \texttt{TRANSPORT} $(i, j, k) \; \forall \;i \in [\max(1, loaded - n), s]$
        \If {$loaded \leq n$}
            \State \texttt{LOAD}
        \EndIf
    \EndParallel
    \State $loaded \leftarrow loaded + 1$
    \newline
    \Parallel
        \State \texttt{ROUTE} $(i, j, k)  \; \forall \;i \in [\max(0, loaded - n - 1), s - 1]$
        \State \texttt{STORE} $(s, j, k)$
    \EndParallel
    \newline
    \Parallel
        \State \texttt{TRANSPORT} $(i, j, k) \; \forall \; i \in [\max(1, loaded - n), s]$
        \If {$loaded \leq n$}
            \State \texttt{LOAD}
        \EndIf
    \EndParallel
    \State $loaded \leftarrow loaded + 1$
    \newline
    \Parallel
        \State \texttt{ROUTE} $(i, j, k)   \; \forall \;i \in [\max(0, loaded - n - 1), s]$
    \EndParallel
    \State $s \leftarrow s + 1$
\end{algorithmic}
\end{algorithm}



Similarly, we define the inverse of the operations as \emph{\texttt{UNLOAD} (L')}, \emph{\texttt{UNTRANSPORT} (T')}, \emph{\texttt{UNROUTE} (R')}, and \emph{\texttt{UNSTORE} (S')} respectively. Note that the gates for the last three operations are identical to their reversed counterparts (e.g. \texttt{TRANSPORT} and \texttt{UNTRANSPORT} are both a \texttt{SWAP} gate), but are conceptually different in their role.

Using these instructions, we provide step-by-step algorithmic descriptions of the query procedure. We decompose it into into the following subroutines: Alg.~\ref{alg:query} for the overall Fat-Tree QRAM procedure, Alg.~\ref{alg:load} for address loading and Alg.~\ref{alg:unload} for address unloading. The latter two can also be applied to BB QRAM, and are referenced by Alg.~\ref{alg:query}.


\begin{figure*}[t]
         \centering
         \includegraphics[width=0.98\linewidth]{Figures/Operations.pdf}
         \caption{A step-by-step pipelining diagram for three capacity-8 queries using the instruction set defined in Sec. \ref{subsec:BBdetail}. Numbers in the operations refer to the information being moved by the operation with address qubits numbered 1 to 3 and $B$ denoting the bus (e.g. $S1$ represents storing the first address qubit). Columns indicate the circuit layer of the operation and rows denote the qubit in which the operation occurs. Similar to Fig. \ref{fig:fullpip}, colors indicate the conceptual QRAM $k$ being used and the type of SWAP-I/II. Note that the query pipelines all align and there is no conflicting usage of qubits.}
         \label{fig:detailbb}
\end{figure*}

\begin{figure}[t]
         \centering
         \includegraphics[width=\linewidth]{Figures/instructions.pdf}
         \caption{Diagram depicting the effects of the first four fundamental operations: \texttt{LOAD}, \texttt{TRANSPORT}, \texttt{ROUTE}, \texttt{STORE}. The router highlighted in green denotes the router the operation is performed on. The orange qubit depicts where the information is and how the operation moves it while the blue router qubit simply indicates that an address is loaded inside the router.}
         \label{fig:instruction}
\end{figure}


\subsection{Proof of FIFO Scheduling Optimality }
\label{subsec:greedyproof}

\begin{algorithm}[t]
\caption{\textsc{Unload Layer}}\label{alg:unload}
\begin{algorithmic}[1]
    \State \textbf{Require: } $loaded$ as number of address qubits loaded
    \State \textbf{Require: }  $s$ as next address depth to be stored
    \State \textbf{Require: } $k$ as the current QRAM copy being used
    \State \textbf{Ensure: } runs only after data retrieval
    \newline
    \State $s \leftarrow s - 1$
    \Parallel
        \State \texttt{UNROUTE} $(i, j, k)   \; \forall \;i \in [\max(0, loaded - n - 1), s]$
    \EndParallel
    \newline
    \State $loaded \leftarrow loaded - 1$
    \Parallel
        \State \texttt{UNTRANSPORT} $(i, j, k) \; \forall \;i \in [\max(1, loaded - n), s]$
        \If {$loaded \leq n$}
            \State \texttt{UNLOAD}
        \EndIf
    \EndParallel
    \newline
    \Parallel
        \State \texttt{UNROUTE} $(i, j, k) \; \forall \;i \in [\max(0, loaded - n - 1), s - 1]$
        \State \texttt{UNSTORE} $(s, j, k)$
    \EndParallel
    \newline
    \State $loaded \leftarrow loaded - 1$
    \Parallel
        \State \texttt{UNTRANSPORT} $(i, j, k) \; \forall \;i \in [\max(1, loaded - n), s]$
        \If {$loaded \leq n$}
            \State \texttt{UNLOAD}
        \EndIf
    \EndParallel
\end{algorithmic}
\end{algorithm}

Using a greedy exchange proof, we show that for Fat-Tree QRAM, FIFO scheduling is optimal regarding overall query latency for both offline and online cases.

Consider a scheduling of queries $q_1, q_2, ..., q_n$ which are all requested at times $t_1, t_2, ..., t_n$ respectively. Let $s_i$ also denote the time that $q_i$ begins computing ($t_i \leq s_i$ since we can only start a query after it is requested and $s_i < s_j$ for all $i \leq j$) and $L_i = (s_i + T) - t_i$ denote the latency of $q_i$ where $T$ is the amount of time it takes to process a query (constant across all queries).

Suppose there is some optimal solution that does not follow our greedy FIFO scheduling. That is, there must exist two consecutive queries $q_x$ and $q_{x + 1}$ such that $t_{x + 1} \leq t_x$ (i.e. we schedule $q_x$ before $q_{x + 1}$ even though it is requested later). We show that swapping $q_x$ and $q_{x + 1}$ so they are scheduled in the order of their request times will result in a latency $L'$ no worse than the optimal (i.e. $L' \leq L$). We have that the total latency in the optimal scheduling is $L = \sum_{i} L_i = L_x + L_{x + 1} + \sum_{i \neq x, x + 1} L_i$.

If we swap $q_x$ and $q_{x + 1}$, the other queries' latencies will not change meaning $\sum_{i \neq x, x + 1} L'_i = \sum_{i \neq x, x + 1} L_i$. We can start $q_x$ at time $s_{x + 1}$ and $q_{x + 1}$ at time $s_x$ as the QRAM is available during both those times (otherwise it would not be available in the original scheduling) and the queries are still only started after being requested ($t_{x + 1} \leq t_x \leq s_{x} < s_{x + 1}$). This results in new latencies of $L'_x = (s_{x + 1} + T) - t_x$ and $L'_{x + 1} = (s_x + T) - t_{x + 1}$. It is easy to show that $L'_x + L'_{x + 1} = L_x + L_{x + 1}$ by rearranging the terms. Thus, $L = (L_x + L_{x + 1}) + \sum_{i \neq x, x + 1} L_i = (L'_x + L'_{x + 1}) + \sum_{i \neq x, x + 1} L'_i = L'$.


If we continually swap all pairs of such $q_x$ and $q_{x + 1}$ where $t_{x + 1} \leq t_x$, we can incrementally transform the optimal solution into our greedy FIFO scheduling. Since at each step our latency is no worse than before, the final latency of our FIFO scheduling is no worse than the optimal solution, making it another optimal solution as well. This completes the proof that a FIFO scheduling always minimizes the total latency.


