\section{Results}
\label{sec:results}


\subsection{Resource Estimation and Comparison}
Table \ref{tab:resource} presents a comprehensive comparison of different shared QRAM implementations with various parameters, including qubit count, query parallelism, and query latency. All numbers in the table are precise counts for a QRAM with capacity $N$. Baseline BB is a sequential query architecture suffering from $O(\log^2(N))$ overhead in query latency.  Comparing Fat-Tree QRAM to the same-qubit-count baseline, Virtual, the overall query latency for parallel queries is asymptotically slower than Fat-Tree QRAM, due to the large single query latency in Virtual, namely $O(\log^2(N))$ for Virtual QRAM vs $O(\log(N))$ for BB. In particular, the Virtual architecture decomposes the total address space $N$ into $K= \log(N)/2$ pages, where each page has size $M= N/\log(N)$ and requires a native Multi-Control-X (MCX) gate to implement. Baseline D-BB has low query latency while requiring asymptotically more resources. It is asymptotically slower in multiple-query tasks compared to the same-qubit-count baseline D-Fat-Tree QRAM. Consequently, under the same resource constraints, the Fat-Tree QRAM asymptotically outperforms state-of-the-art QRAM architectures regarding overall query latency for parallel query requests. All our resource estimation in Table \ref{tab:resource} based on realistic hardware parameters under the recent improvement in the implementation of native \texttt{CSWAP} gates, offering a $\tau=1\mu s$ gate time~\cite{weiss2024quantum}, or equivalently clock speed $1/\tau= 10^6$ CLOPS~\cite{amico2023defining}. The intra-node SWAP gate is even faster with gate time $T_{\textrm{SWAP}}=125 ns$~\cite{liu2024quantum,weiss2024quantum}.

\begin{table*}[t]
\small
    \centering
    % \begin{tabular}{ p{3cm}||p{3.8cm}|p{1.8cm}|p{1.8cm}|p{4.7cm}}
    \begin{tabular}{ c||c|c|c|c|c}
     \hline
     \hline
       & Fat-Tree & D-Fat-Tree & BB \cite{giovannetti2008architectures} & D-BB & Virtual \cite{xu2023systems} \\
     \hline
     \makecell[l]{Qubits} & $16N$ & $16N\log(N)$ & $8N$  & $8N\log(N)$ & $16N$  \\
     \hline
     Query parallelism $m$ & $\log(N)$ & $\log^2(N)$ & $1$ & $\log(N)$ & $\log(N)$\\
     \hline
     \makecell[l]{Query latency for \\ single query $t_1$} & \makecell[l]{$8.25\log(N)$ \\ $- 0.125$} & \makecell[l]{$8.25\log(N)$ \\ $- 0.125$} & $8\log(N) + 0.125$ & \makecell[l]{$8\log(N) + 0.125$} & \makecell[l]{$4\log^2(N) + 4.0625\log(N)$\\$- 4\log(N)\log(\log(N))$} \\
     \hline
     \makecell[l]{Query latency for \\$\log(N)$-parallel \\ queries $t_{\log(N)}$ } & \makecell[l]{$16.5\log(N)$ \\ $- 8.375$} & \makecell[l]{$16.5 - \frac{8.375}{\log(N)} \;^*$} & \makecell[l]{$8\log^2(N)$\\$+ 0.125\log(N)$} & \makecell[l]{$8\log(N) + 0.125$} & \makecell[l]{$4\log^2(N) + 4.0625\log(N)$\\$- 4\log(N)\log(\log(N))$} \\
     \hline
     \makecell[l]{Amortized Single \\ Query Latency} & $8.25$ & $\frac{8.25}{\log(N)}$ & $8\log(N) + 0.125$ & $8 + \frac{0.125}{\log(N)}$ & \makecell[l]{$4\log(N) + 4.0625$\\$- 4\log(\log(N))$} \\
     \hline
    \end{tabular}
    \caption{Space (i.e., qubit number) and time (i.e., query latency) resource comparison across different shared QRAM models with classical memory size $N$. Latency is calculated with intra-node and classical gates, taking only an eighth of the time as a standard circuit layer. Compared to BB QRAM, Fat-Tree QRAM achieves an asymptotic reduction in query latencies for $\log(N)$ parallel queries at the cost of constant overhead (i.e., doubling) in qubits. Note that $t_{\log(N)}$ for D-Fat-Tree is the amortized time for $\log(N)$ queries since D-Fat-Tree has a higher parallelism than $\log(N)$ queries (i.e. $\log(N)$ queries is insufficient to fully utilize D-Fat-Tree).}
    \label{tab:resource}
\end{table*}


\begin{table*}[t]
    \small
    \centering
    \begin{tabular}{c||c|c|c|c|c}
     \hline
     \hline
       & Fat-Tree & D-Fat-Tree & BB \cite{giovannetti2008architectures} & D-BB & Virtual \cite{xu2023systems}  \\
     \hline
     \makecell[l]{QRAM bandwidth \\ (qubit/sec)} & $1.21 \times 10^5$ & \makecell[l]{$1.21\log(N) \times 10^5$} & $\frac{1.25\times 10^5}{\log(N)} + 8 \times 10^6$ & \makecell[l]{$\frac{10^6 \log(N)}{8\log(N) + 0.125}$} & $\frac{10^6}{4\log(N) + 4.0625 - 4\log(\log(N))}$ \\
     \hline
     \makecell[l]{Space-time Volume \\ per query } & $132N$ & $132N$ & $64N \log(N) + N$ & 64N $\log(N) + N$ & \makecell[l]{$64N\log(N) + 65N $\\$- 64N\log(\log(N))$} \\
     \hline
     \makecell[l]{Time budget for classical \\ memory swap ($\mu s$) } & $8.25$ & $8.25$ & $8\log(N) + 0.125$ & $8\log(N) + 0.125$ & \makecell[l]{$4\log^2(N) + 4.0625\log(N)$\\$- 4\log(\log(N))$} \\
     \hline
    \end{tabular}
    \caption{Bandwidth, memory access rate, and space-time volume comparison across different shared QRAM models with classical memory size $N$. The \texttt{CSWAP} gate time is estimated at $1 \mu s$ \cite{weiss2024quantum}, which leads to QRAM clock speed at $1 \times 10^6$ circuit layer operations per second (CLOPS) \cite{amico2023defining}. Fat-Tree QRAM achieves a high bandwidth and memory access rate that is independent of the memory size $N$, and requires asymptotically less space-time volume than other QRAM models.}
    \label{tab:bandwidth}
\end{table*}


\subsection{QRAM Bandwidth}

Table \ref{tab:bandwidth} includes a comparison of QRAM \emph{bandwidth} for all the QRAM architectures. Recall that in Sec.~\ref{sec:eval}, we define bandwidth as the rate at which data qubits can be provided to the QPUs. Fig.~\ref{fig:bandwidth} provides a fine-grained, accurate scaling of QRAM bandwidth and space-time comparison under the same gate parameters in resource estimation.

As shown in Table~\ref{tab:bandwidth}, Fat-Tree QRAM achieves a \emph{constant} bandwidth (i.e., independent of the QRAM size $N$), giving it an asymptotic advantage compared to all other architectures that use the same resources. Though the bandwidth of Baseline D-BB is also constant, it achieves constant scaling at the price of $\log(N)$ copies of the hardware. The bandwidth is also related with \emph{quantum volume per query}, defined as the amortized $\textrm{qubit} \cdot \textrm{circuit depth}$ per query, quantifying the cost of implementing a single query. Fat-Tree QRAM, under the same resource constraints, asymptotically outperforms BB and Virtual QRAM.

Another related metric is \emph{memory access rate} which quantifies the rate at which classical data is read by the QRAM hardware. While this rate is consistent with the bus qubit throughput quantified by bandwidth, the duty rate of shared QRAMs can be simply calculated by $(\textrm{bandwidth} \cdot N)$. 

Finally, we estimate the time budget for classical memory swap using the time interval between two separate queries' data retrieval. While classical memory changes were neglected in previous analyses, large memory shifts can introduce delays in practice if the swap time budget is insufficient. We observed that different architectures pose different classical memory challenges: Fat-Tree requires rapid swapping with constant intervals; in contrast, D-BB requires parallel memory swapping, as the classical memory cells are also copied and distributed for D-BB QRAM. 

\subsection{Enabling Parallel Algorithms}
One of the most significant applications for Fat-Tree QRAM is supporting parallel quantum algorithms requiring parallel queries. In particular, we removed all the dependencies on other parameters by setting them as constant values, such as deviation $\epsilon$ and Hamiltonian sparsity $d$. Hence, the resulting asymptotic scaling only depends on problem size $N$ (capacity of QRAM). Compared to Baselines BB and Virtual, Fat-Tree QRAM achieves the following asymptotic reduction in circuit depth: 
\begin{itemize}
    \item Grover's algorithm: $O(\log^2(N)\sqrt{N})$ to $O(\log(N)\sqrt{N})$
    \item $k$-sum algorithm: $O(\log^2(N)(N/\log(N))^{k/k+1})$ to \newline $O(\log(N)(N/\log(N))^{k/k+1})$
    \item Hamiltonian sim.: $O(\log(N)\log(\log((N))+\log^2(N))$ to $O(\log(N)\log(\log((N))+\log(N))$.
    \item Quantum Signal Processing (QSP): $O(poly(d))$ to \\ $O(poly(d) /\log(N))$, where $d$ is the degree of polynomial encoded in the unitary transformed by QSP.
\end{itemize}

To put the savings into context, Fig.~\ref{fig:parallelalg} presents concrete examples of overall algorithmic circuit depth reduction (by up to a factor 10) on practical problems with medium-scale memory $N=2^{10}$.

\begin{figure}[t]
         \centering
         \includegraphics[width=0.96\linewidth]{Figures/bandwidth.pdf}
         \caption{Bandwidth comparison for different QRAM architectures. Fat-Tree achieves a capacity-independent constant bandwidth.}
         \label{fig:bandwidth}
\end{figure}



\begin{figure}[t]
         \centering
         \includegraphics[width=\linewidth, trim=0 1em 0 0]{Figures/results.pdf}
         \caption{Overall circuit depth for running parallel algorithms, assuming memory size $N=2^{10}$. For QSP, we assume $d=30$ and $poly(d)=d^2$. Fat-Tree QRAM achieves up to a factor of 10 reduction compared to baselines BB and Virtual.}
         \label{fig:parallelalg}
\end{figure}


\begin{figure}[t]
         \centering
         \includegraphics[width=0.97\linewidth]{Figures/utilization.pdf}
         \caption{(a1/2) Overall algorithm depth of synthetic algorithm in BB/Fat-Tree QRAM. (b1/2) QRAM utilization of synthetic algorithm in BB/Fat-Tree QRAM. Fat-Tree QRAM balances processing/query ratio and parallel algorithms count, significantly reducing the overall algorithm depth.}
         \label{fig:utilization}
\end{figure}

\subsection{QRAM Hardware Utilization}
\label{sec:utibench}
As discussed in Sec.~\ref{sec:schedule}, to maximize the utilization without queries bottlenecking, an ideal strategy is to allocate a proper number of parallel algorithms to one Fat-Tree QRAM. Fig.~\ref{fig:utilization} presents the result of the synthetic algorithms introduced in Sec.~\ref{sec:eval} and compares the performance of BB with Fat-Tree QRAM on the dependency of processing/query ratio and parallel algorithm count. 
The BB QRAM meets the memory bandwidth bound even with a small increment in parallel algorithm count, resulting in a large overhead in the overall algorithm depth. Our Fat-Tree QRAM, however, is capable of balancing parallel algorithm count and the processing/query ratio, which significantly decreases the depth of synthetic algorithms.
