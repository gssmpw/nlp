\section{Shared QRAM Architecture}
\label{sec:arch}

\begin{figure}[t]
         \centering
         \includegraphics[width=0.48\textwidth]{Figures/Fattree.pdf}
         \caption{Layout of a Fat-Tree QRAM with capacity $N=32$ (Similar H-tree layout for BB QRAM appeared in \cite{xu2023systems}). Classical data are located at the leaves and the internal nodes contain multiplexed quantum routers. Colors of the routers and wires are used to indicate connection. The size of an internal node (i.e., number of qubits) increases \emph{linearly} as we go up the tree. 
         }
         \label{fig:fat}
\end{figure}

We introduce the new Fat-Tree QRAM architecture in the following three subsections: Sec.~\ref{subsec:fattree} describes a Fat-Tree architecture to increase the query parallelism. Sec.~\ref{subsec:nodes} provides both modular and on-chip hardware demonstrations of Fat-Tree QRAM using well-established techniques in NISQ systems. Finally, operations within the architecture and the query pipeline diagram are presented in Sec.~\ref{subsec:operation}.

\subsection{Fat-Tree Architecture}
\label{subsec:fattree}

Fat-Tree QRAM is built on a complete binary tree, where $N$ leaf nodes connect to size-$N$ classical memory. Each tree level consists of quantum routers, with the $i^{\text{th}}$ level (indexed from 0) containing $2^i$ routers, as in BB QRAM. To pipeline $n=\log(N)$ queries with address width $n$, routers at level $i$ are duplicated $n-i-1$ times. Thus, Fat-Tree QRAM adopts a 2D H-tree layout similar to BB QRAM, replacing each router at level $i$ with a Fat-Tree node containing $n-i$ routers. Fig.~\ref{fig:fat} illustrates this structure, where circles inside square nodes denote quantum routers. 

We use a 3-tuple $(i,j,k)$ to index routers and qubits: $i\in [0, n-1]$ represents the level, $j\in [0, 2^i-1]$ denotes the node index, and $k\in [0, n-i-1]$ identifies the router copy in node $(i,j)$. In BB QRAM, routers correspond to $(i,j,n-1)$. The parameter $k$ determines multiplexing, extending BB QRAM into the Fat-Tree model. Individual qubits within each router are categorized as input, router, and L/R output qubits (e.g., the input qubit of router $(1,1,3)$ in Fig.~\ref{fig:fat}).

Increased router duplication raises inter-node connectivity. BB QRAM links parent-child nodes with a single wire (Fig.~\ref{fig:bg}), whereas Fat-Tree QRAM connects nodes with $k$ wires per node. Starting with $n$ wires at the root, the count decreases by 1 per level until reaching a single wire at the leaves, matching BB QRAM. This enhanced connectivity enables higher-bandwidth inter-node communication and multiple parallel gates between nodes.

As discussed in Sec.~\ref{sec:app}, the resource overhead from duplicating higher BB QRAM levels remains moderate. The qubit count per Fat-Tree node scales \emph{linearly} with its height. The router count follows $\sum_{i=0}^{n - 1} (n - i)2^i = 2N - 2 - n$, only doubling that of BB QRAM. The following sections demonstrate that Fat-Tree QRAM significantly improves parallel query latency over sequential BB QRAM queries, with minimal qubit and connectivity overhead.

 \begin{figure*}[t]
         \centering
         \includegraphics[width=0.95\textwidth]{Figures/hardware.pdf}
         \caption{Internal structure of a Fat-Tree node. (a) An example node $(i=1,j=0)$ in a capacity-32 Fat-Tree QRAM, containing 4 routers, 4 incoming wires from the top, and two sets of 3 outgoing wires to its left and right children. (b) A tunable coupler to coaxial wire for inter-node connections in modular design (Sec.~\ref{subsubsec:modular}). (c) The internal structure of a multiplexed router based on superconducting cavities. Transmon-attached input qubit and router qubit ensure native (cavity-controlled) \texttt{CSWAP} gate implementation \cite{weiss2024quantum}. Beam splitters between routers provide intra-node connectivity for local swapping operations. (Sec.~\ref{subsec:operation}) Inset (c1) is an alternative implementation of the router unit enclosed in dashed box that uses more cavities to reduce the connectivity requirement. (d) On-chip two-layer architecture for Fat-Tree QRAM. (Sec.~\ref{subsubsec:onchip}) (e) Sectional view of on-chip design in (d). Inter-plane connection is achieved by the Through-Substrate-Vias (TSVs) technology.}
         \label{fig:hardware}
\end{figure*}

\begin{figure}[t]
         \centering
         \includegraphics[width=0.485\textwidth]{Figures/smallqram.pdf}
         \caption{An alternative conceptual interpretation of Fat-Tree QRAM as a composition of multiple BB QRAMs of variable size (Sec.~\ref{subsec:operation}).}
         \label{fig:small}
\end{figure}

\subsection{Implementing Fat-Tree QRAM Nodes}
\label{subsec:nodes}
When choosing a hardware platform for implementing QRAM, we need to consider several essential requirements: (i) efficient encoding of quantum router  (e.g., $\ket{W}, \ket{0}, \ket{1}$), (ii) parallel routing operations (e.g., \texttt{SWAP} and \texttt{CSWAP} gates), (iii) parallel writing of classical data into the state of the bus. 

In this section, we consider implementing a multiplexed Fat-Tree node $(i,j)$ based on superconducting cavities. With rapid advances in superconducting devices, the key elements required in Fat-Tree QRAM have already been proposed, e.g., \texttt{CSWAP} operations between superconducting cavities \cite{gao2019entanglement, xue2023hybrid} and transmon devices \cite{miao2023implementation}. These advances in hardware enable two possible hardware implementations of QRAM, using well-established encodings of qubits (i.e., transmons and cavities), beam-splitters, wires, and tunable couplers. 

For Fat-Tree QRAM, it is important to also consider the intra- and inter-node connectivity caused by the extra routers. For example, in Fig.~\ref{fig:hardware}(c), we provide the internal structure of node $(1,j)$ in a capacity-$N=32$ Fat-Tree QRAM from Fig.~\ref{fig:fat}. In this node, there are four routers, each with four input wires and two sets of three output wires allocated to both child nodes, denoted as L and R. When multiple routers are positioned in a Fat-Tree node, the two output qubits from each router must be routed towards the two external output interfaces (i.e., L and R directions), resulting in possible wire crossings. However, the connectivity constraint for Fat-Tree QRAM is \emph{not} all-to-all. Instead, we show that a \emph{bi-planar nearest-neighbor} connectivity is sufficient. This important observation leads to the efficient implementations of Fat-Tree QRAM using readily available technologies in superconducting circuits, one of the platforms with the most restrictive connectivity constraints. We illustrate this by introducing modular and on-chip architectures for Fat-Tree nodes.

\subsubsection{Fat-Tree Node: Modular Implementation}
\label{subsubsec:modular}
The modular implementation allows us to manufacture all the nodes as independent modules and link them with superconducting coaxial cables \cite{zhong2021deterministic}. Fig.~\ref{fig:hardware} proposes a possible implementation consisting of two fundamental components: (1) tunable couplers with coaxial wires to provide inter-node connectivity and (2) quantum routers inside the module for executing \texttt{CSWAP} gates. Within the module, routers are arranged side by side, with the last router lacking output qubits and serving as a transient storage for queries, resulting in one fewer output wires compared to inputs. Within each quantum router, qubits are constructed by cavities, featuring a transmon coupled to the input cavity for native \texttt{CSWAP} gates implementation~\cite{weiss2024quantum,chapman2023high}. Additionally, horizontal nearest-neighbour connectivity among routers is implemented by beam splitters, enabling swap gates between adjacent routers within Fat-Tree nodes via manipulation of nearest-neighbor coupled qubits along the line. Since the router qubit having four beam splitters attached may cause hardware manufacturing challenges, we provide an alternative implementation to reduce connectivity requirements by adding one extra cavity in Fig.~\ref{fig:hardware}(c1).

The tunable couplers are aligned to the top and bottom of the chip, coupled with the input and output qubits as ports to inter-node wires. Since the coaxial wires can be twisted to any shape, the crossing of routings inside a node is reduced to the crossing of wires connecting different nodes, with no crossings inside the module, as shown in Fig.~\ref{fig:hardware}.

\subsubsection{Fat-Tree Node: On-chip Implementation}
\label{subsubsec:onchip}
In contrast to modular designs, an on-chip implementation of shared QRAM integrates all components onto a single chip, resulting in a significantly reduced size. This approach offers multiple advantages, including faster cooling, reduced energy dissipation, and enhanced fidelity, at the expense of connectivity constraints~\cite{ganjam2024surpassing}. Instead, qubits and wires must be arranged in a planar layout without overlapping. While achieving this in a single-layer chip poses challenges, we demonstrate that the connectivity graph of a Fat-Tree QRAM can be effectively decomposed into two planar subgraphs. Consequently, a thickness-2 chip, consisting of two edge-disjoint layers, can be implemented, as shown in Fig.~\ref{fig:hardware}(d). Although a single-layer chip is preferable for hardware simplicity, employing two layers may still be feasible, as couplers and their control lines can be attached to the top and bottom of the chip. The connection between the two planes can be facilitated with the TSVs technique introduced in Sec.~\ref{sec:background}.

Fig.~\ref{fig:hardware}(e) depicts a sectional view of the on-chip TSVs implementation with the vertical dashed line between the two planes. A single node, implemented by the routers and couplers discussed in the modular design, resides fully in a single plane. However, only one of its child nodes resides in the same plane, while the other resides in the opposite, as the L/R output qubits of quantum routers direct to the chip's opposite/same plane respectively. This alternating plane configuration ensures that wires do not intersect within any single plane, providing an efficient two-plane decomposition.


\subsection{Operations in Fat-Tree QRAM}
\label{subsec:operation}
With the hardware architecture defined, we now describe the efficient operations in Fat-Tree QRAM to implement quantum queries. In this section, we specify the step-by-step inter- and intra-node operations in Fat-Tree QRAM to realize $O(\log(N))$ quantum queries in $O(\log^2(N))$ circuit depth. 

To appreciate the benefits of the proposed architecture, it is useful to consider an alternative interpretation of Fat-Tree QRAM. As shown in Fig.~\ref{fig:small}, if we look at the routers of different colors in isolation, a Fat-Tree QRAM is equivalent to a composition of multiple ``sub-component QRAMs'' of varying sizes (each with address width ranging from $n$ to 1, which we denote by parameter $k$). Fig.~\ref{fig:small} shows the largest QRAM corresponding to $k=n-1$, while the smallest is parameterized by $k=0$. In the Fat-Tree, we index routers belonging to QRAM $k$ as $(i,j,k)$, where each node $(i,j)$ in Fat-Tree incorporates exactly one router from QRAM $k$ if $i \leq k$, and no router if $i > k$. 

Each quantum query involves routing and swapping among the sub-component QRAMs: starting from the smallest-size QRAM at the initial step of the query, we transition to the QRAM larger by one size every time a level of routers is loaded. This can be realized by introducing a \emph{swap step} between consecutive \emph{gate steps} within the original QRAM circuit, as illustrated in Fig.~\ref{fig:fullpip}. 

In Fig.~\ref{fig:fullpip}, the gate steps, highlighted in a white background, load/unload a single layer in the QRAM through a series of \texttt{CSWAP}s, the same as those in a conventional BB QRAM address loading circuit, taking 4 circuit layers each. Meanwhile, the newly introduced swap steps, on a gray background, perform two distinct functions: (i) During the address loading (unloading) stage, the entire query is swapped to a larger (smaller) sub-component QRAM, taking a single circuit layer. All swap gates can be performed in parallel within a Fat-Tree node. (ii) Data retrieval operations are executed during a swap step as well. Data retrieval, similar to in BB QRAM, takes 1 circuit layer for the classically controlled gates. However, in practice, each circuit layer in a swap step takes only a fraction of the time as other circuit layers since intra-node and classical gates are much faster.

For Fat-Tree QRAM, additional time for swapping classical memory might be required for executing multiple distinct queries. We quantify the time budget for classical memory swap without causing query slowdown in Sec.~\ref{sec:results}.


\subsubsection{Pipelining Details}

Fat-Tree QRAM introduces \emph{query-level pipelining}, unlike the bit-level pipelining of BB QRAMs, enabling greater parallelism without additional resources. We illustrate this pipelining process by integrating circuit gates with additional swap operations in Fig.~\ref{fig:fullpip}.  

QRAM swapping, while seemingly complex, is efficiently executed via \emph{local swapping}, where each node independently swaps internal qubits. Since quantum queries involve all QRAM branches in superposition, local swapping provides a constant-depth solution by performing swaps within each node $(i,j)$ rather than requiring inter-node communication. Specifically, swapping QRAMs $k$ and $k+1$ involves each node $(i,j)$ swapping router $(i, j, k)$'s input and router qubits with those in $(i,j,k+1)$.  

Fig.~\ref{fig:fullpip} defines two local swapping types:  
- \texttt{SWAP-I}: Even-indexed routers $(i,j,k) \Leftrightarrow (i,j,k+1)$ for even $k$.  
- \texttt{SWAP-II}: Odd-indexed routers $(i,j,k) \Leftrightarrow (i,j,k+1)$ for odd $k$.  

The smallest QRAM ($k=0$) does not undergo Type-II swaps, and the largest QRAM ($k=n-1$) swaps only once, depending on the parity of $n$. Alternating \texttt{SWAP-I} and \texttt{SWAP-II} enables seamless query movement across QRAM sizes, facilitating both loading and unloading. Additionally, local swapping maintains sequential qubit allocation with only nearest-neighbor connectivity, simplifying hardware design (Fig.~\ref{fig:hardware}(c)).  

Local swapping requires only a single circuit layer and can run concurrently with classical data retrieval(note that only one type of local swapping will be associated with data retrieval, with the type depending on the parity of $n$). The pipeline interval spans 10 circuit layers, structured as: gate step (4) + \texttt{SWAP-I} (1) + gate step (4) + \texttt{SWAP-II} (1), ensuring efficient scheduling regardless of $n$â€™s parity.  

We summarize the $\log(N)$-pipelined query procedure in Alg.~\ref{alg:query} and visualize it in Fig.~\ref{fig:fullpip}. A detailed breakdown with elementary operations appears in Appendix Fig.~\ref{fig:detailbb}. The key conceptual steps are as follows:


\begin{enumerate}[label= (\alph*)]
    \item Start a new query and execute one gate step of address loading/unloading for all existing queries.
    \item Apply Type-I swap step, together with classical data retrieval for the leaves of Fat-Tree QRAM if address loading is finished for one of the ongoing queries.
    \item Apply one gate step of address loading/unloading for existing queries. 
    \item Apply swap step Type-II, with data retrieval if needed.
    \item Repeat (a-d) until all the query requests are served.
\end{enumerate}

\begin{figure*}[t]
         \centering
         \includegraphics[width=0.75\textwidth]{Figures/fullpip.pdf}
         \caption{Pipeline schedule of a capacity-8 Fat-Tree QRAM running 3 concurrent queries. Colors indicate which conceptual QRAM $k$ in Fig.~\ref{fig:small} is being used at the hardware level. No conflicting colors in the same layer ensures no concurrent access to the same quantum routers. The latency overhead for each single query of Fat-Tree QRAM compared to the original BB QRAM (query latency 29:25 in the case $n=3$) comes from additional swap steps except the one coinciding with data retrieval, as it is included in BB QRAM's latency.}
         \label{fig:fullpip}
\end{figure*}



\begin{algorithm}[h]
\caption{Pipeline $\log(N)$ Quantum Queries with size-$N$ Fat-Tree Shared QRAM.}\label{alg:query}
\begin{algorithmic}[1]

\State \textbf{Require: } $\ket{\psi_{A}^{j}} = \sum^{N-1}_{i=0} \alpha_i^j\ket{i}$
\Comment{address of the $j$th query}
\State \textbf{Require: } $0 \leq j \leq n-1$ 
\Comment{query index}
\State \textbf{Require: } $ n=log(N) \geq 1$
\Comment {QRAM height/total queries}

\State \textbf{Ensure: } $\ket{\psi_{AB}^{j}} = \sum_{i=0}^{N-1}\alpha_i^j\ket{i}_A\ket{x^j_i}_B$
\Comment{$j$th query}

\For{$t = 1, 2, ...$ until queries are finished}
\If{$t$ is odd}
    \If{$t \equiv 1\mod 4$}
        \State Start next query $\ket{\psi_{A}^{(t - 1) / 4}}$  
    \EndIf
    \State Load/Unload Layer (Alg. \ref{alg:load} \& \ref{alg:unload}) $\forall$ existing queries
\Else  
    \If{$t \equiv 2\mod 4$}
        \State \texttt{SWAP-I}: $(i,j,k) \Leftrightarrow(i,j,k+1)$ $\forall$ even $k$
        \If{$n$ is odd}
            \State \texttt{CLASSICAL-GATES}
            \State {} \Comment{Data retrieval for fully loaded query}
        \EndIf
    \Else
        \State \texttt{SWAP-II}: $(i,j,k) \Leftrightarrow(i,j,k+1)$ $\forall$ odd $k$
        \If{$n$ is even}
            \State \texttt{CLASSICAL-GATES} 
            \State {} \Comment{Data retrieval for fully loaded query}
        \EndIf
    \EndIf
\EndIf
\EndFor
\end{algorithmic}
\end{algorithm}



