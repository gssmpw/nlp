\section{Introduction}

% Write up the main results and text linearly, then focus the remaining time on deriving results for the examples and on patching up the $L^2$ decisions thing. 

% \begin{itemize}
%     \item[x] Rise of OT in AM + short description of OT
%     \item[x] Appearance in ML, practice and statistical learning theory
%     \item[x] Sequential/Online learning remains a blind spot of the LT literature
%     \item[x] Brief Setting: online stochastic, regret based evaluation of performance. 
%     \item[$\sim$] Explanation of introduced challenges: correlated samples, evaluation during learning and  exploration-exploitation trade-off
%     \item[x] Motivation of the problem of online transport by practical applications 
%     \item[x] Objective 
%     \item[x] Motivation of the learning problem from a theoretical perspective: infinite dimensional parameter space (relate to RKHS methods), use of the geometry of the OT problem to induce regularity. Proximity to a linear bandit problem, but without the usual LS tools used to construct confidence sets. Quote main challenges here
%     \item[?] relation to robust transport and transport in the face of Uncertainty. Brief mention of prior work on online transport
%     \item[x] Relation to linear bandits. 
%     \item[x] main contributions (low regret), efficient learning leveraging intrinsic regularity structures of the problem. 
%     \item[x] Organisation
% \end{itemize}
% in total, about 1.5 pages

Originally, Optimal Transport (OT) was developed as a mathematical theory to optimise the transportation and logistics of goods \citep{monge1781memoire,kantorovich_translocation_2006}. However; this theory has experienced a meteoric rise in applied mathematics over the last two decades, due to a sustained series of major breakthroughs \citep{villani_topics_2003,villani_optimal_2009}.
One can think of the constraints  as requiring satisfaction of a supply and a demand of a resource, with the objective being to most efficiently distribution of units of this resource\footnote{From a formal standpoint, this problem concerns the minimisations of functionals of measures under constraints imposed by their marginals.}. 

Historically, this economic interpretation has been the main application for the theory, see e.g.\ \citep{galichon_unreasonable_2021,kreinovich_applications_2024}, but the recent theoretical progress has renewed interest for new domains of applications, such as machine learning. Indeed, many have noticed that the ability to quantify and minimise ``distances'' between probability measures parallels key questions in problems such as generative modelling \citep{arjovsky_wasserstein_2017} or domain adaptation \citep{courty_joint_2017}. As these developments have matured, they have percolated into statistical learning theory to create the rich literature of statistical optimal transport, recently surveyed by~\cite{chewi_statistical_2024}.

In spite of this ongoing activity, the field of \emph{sequential} learning remains a blind spot of this emerging field. Barring a handful of exceptions, all existing works consider static (\emph{batch}) i.i.d.\ datasets and traditional statistical estimation. This is despite the many applications of optimal transport that are naturally sequential. Assignment problems are a classical example: matching students to universities is repeated yearly. Classical examples 
include kidney donors to recipients \citep{glorie_allocation_2014}, doctors to hospitals \citep{hatfield_matching_2005}, etc. In these examples the number of assignments is finite, but as it becomes large the OT problem is best modelled by an infinite-dimensional problem, see e.g.\ \cite{cao_connecting_2024,carlier_optimal_2010}. Optimal transport finds countless other naturally sequential applications across economics and operations research, which motivates the study of sequential learning of OT. 

In sequential learning tasks, samples are highly correlated which introduces significant new complexities relative to the batch setting. Moreover, sequential learning tasks are more naturally evaluated during the learning process, rather than at the end. This \emph{online} evaluation creates a trade-off between exploration (statistical efficiency) and exploitation (online performance).

Consequently, this paper sets out to investigate the question of the online learnability of the general OT problem in a stochastic partial feedback setting known as a \emph{stochastic bandit}.

In this setting (see \cref{sec: setting} for details), an agent is given the constraints of an optimal transport problem, but not the cost function. It must partake in a repeated game in which it submits a transport plan (i.e.\ an admissible point) at each round, and receives a noisy reward estimate of the cost of the submitted plan. Importantly, this feedback is \emph{bandit}: it gives no information about the outcome of any plan other than the one played. We measure the performance of the agent by its \emph{regret}, i.e.\ its cumulative loss compared to the optimal plan.

This setting raises intriguing connections to classical work in bandit problems.
First, since optimal transport functionals are linear functionals, this problem appears an extension of linear bandits \citep{auer_using_2003}. Closer inspection however reveals that classical tools break down because the cost function which must be learned does not live in the same space as the actions. Second, the infinite-dimensionality of the cost function  draws a connection to kernel bandits \citep{valko_finite-time_2013}. In kernel bandits, the regularity of the hypothesis space is what allows transformation to a linear problem. In contrast, we will see that the regularity of the OT problem is intrinsic to its geometry  and we can thus work with much larger hypothesis spaces despite this problem not being a linear bandit.

As a result of our investigation, we establish the first regret bounds for learning the general stochastic bandit OT problem. We show this problem is online learnable by giving general $\tilde\Oc(\sqrt{T})$ regret bounds under near-minimal assumptions, in the spirit of~\cite{abbasi-yadkori_online_2012}. As these bounds depend on infinite dimensional quantities, we also demonstrate that these regret bounds can be specified into rates between $\tilde\Oc(\sqrt{T})$ and $\tilde\Oc(T)$, depending on the regularity of the target cost function. 
These results are obtained by leveraging the intrinsic regularity of the OT problem and advanced mathematical tools to construct infinite-dimensional least-squares estimators and confidence sets by extending the classical (separable) Hilbert space theory. 

\mypar{Organisation} Owing to the intricate technicalities of the setting, we devote \cref{sec: setting} to clearly defining the Bandit Optimal Transport (BOT) problem we study. Then, in \cref{sec:RWCC}, we discuss high-level insights, related work regarding learning of OT problems, and detail our contributions. Thereafter, we focus \cref{sec: Preliminaries} on the technicalities of our solution to the learning problem, and then give general regret bounds in \cref{sec: regret of learning}. We conclude by touching on some promising open directions in \cref{sec: directions}. Appendices extend these discussion and contain rigourous details of technical contributions and proofs.




% \subsection{Motivating example (?)}

% This setting arises naturally in applications. For instance,consider a logistics company which must supply the same firms from the same depots on a daily basis. The logistics company will seek to minimise the cost of deliveries. Without advanced telemetry and in the presence of noisy measurements (e.g. fluctuating traffic congestion), it would have no other choice but to look at the overall expenditure each day to try and improve its transport offering. 

% Another example can be seen in supply chain logistics: a manager can assign contractor firms to perform steps of the manufacturing, but only receives the final product for distribution. 


