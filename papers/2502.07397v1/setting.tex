\section{Setting}\label{sec: setting}
\subsection{The decision problem of optimal transport}\label{subsec:decision problem setting}


Consider a pair of probability measures $(\mu,\nu)\in\Ps(\Mc_\mu\times\Mc_\nu)$ on two topological measurable spaces $(\Mc_\mu,\Fc_\mu)$, $(\Mc_\nu,\Fc_\nu)$, as well as a cost function $c:\Mc_\mu\x\Mc_\nu\to\Rb$. For ease of exposition, we consider $\state:=\muspace\x\nuspace\subset\Rb^d$, $d\in\Nb$, but the problems below are also defined on highly esoteric spaces $(\Mc_\mu,\Mc_\nu)$ such as a graph or a space of curves.

\mypar{The Kantorovich formulation} of the OT problem \citep{kantorovich_translocation_2006} asks for the optimal way to transport all the mass from $\mu$ to $\nu$, where the cost of moving an infinitesimal unit of mass from $x\in\Mc_\mu$ to $y\in\Mc_\nu$ is captured by $c(x,y)$. If $c(x,y)=\norm{x-y}$, the cost of transporting $x$ to $y$ is just the distance between the source and the destination. However, the ability to roll arbitrarily complex considerations into $c$ is what makes OT highly versatile in applications.  

Formally, the \emph{Kantorovich} (optimal transport) problem is defined as
\begin{align}
    \kant(\mu,\nu,c):= \inf_{\pi\in\Pi(\mu,\nu)}\int c(x,y)\de \pi(x,y)
    \label{eq: kantorovich def}
\end{align}
in which
$ 
    \Pi(\mu,\nu):=\{\pi\in\Ps(\Mc_\mu\x\Mc_\nu): \pi(\cdot,\Mc_\nu)=\mu, \pi(\Mc_\mu,\cdot)=\nu\}
$
is the set of all \textit{couplings} of $\mu$ and $\nu$, i.e.\ any joint distribution whose marginals over $\Mc_\mu$ and $\Mc_\nu$ are $\mu$ and $\nu$, respectively. Importantly, the Kantorovich problem allows mass located at $x$ to be split and sent to several $y$, and vice-versa, but a set $S\in\Fc_\mu$ may not give more mass that $\mu(S)$, just as $S'\in\Fc_\nu$ may only receive $\nu(S')$ mass. In fact $\Pi$ imposes that they give and receive \emph{exactly} this amount of mass.

Divisibility of mass was absent in the original formulation of OT, which rendered the problem highly difficult (see \cref{subsec: Monge pb}). In contrast, the Kantorovich problem is a linear program and is solvable when $c$ is lower semi-continuous and bounded below, see~\cite[Thm.~4.1]{villani_optimal_2009}. The generality of this result\footnote{One might notice that the provided reference in fact uses even weaker conditions.} explains its adoption as the core problem of OT theory.

 The \emph{linearity} of the optimal transport functional functional refers to the fact that the map $\pi\mapsto \int c(x,y)\de\pi(x,y)$
is linear in $\pi$. In fact, this functional is a bilinear form which can be represented as a duality pairing $\langle c\vert\pi\rangle$ (see \cref{subsec: measure valued actions}) so that~\eqref{eq: kantorovich def} can be rewritten as
\begin{align}
    \kant(\mu,\nu,c):= \inf_{\pi\in\Pi(\mu,\nu)}\langle c\vert\pi\rangle\,.
    \label{eq: kantorovich def 2}
\end{align} 
This pairing is not an inner product however, as $c$ is a function while $\pi$ is a measure. 

Nevertheless, linearity speaks in favour of the regularity of \cref{eq: kantorovich def}. Intuitively, it behaves like an infinite-dimensional linear program. Indeed, $\langle c\vert\cdot\rangle$ is linear and $\Pi(\mu,\nu)$ is defined by linear (integral) constraints, and, in fact, $\Pi(\mu,\nu)$ is convex and compact \citep[Cor.~2.9]{ambrosio_lectures_2021}. However, unlike in finite-dimensional linear programs, the optimisation domain $\Pi(\mu,\nu)$ is neither a vector space nor flat. This is the source of significant technical difficulties in the resolution of~\eqref{eq: kantorovich def}, which appears a difficult roadblock to the application of standard learning methods. 

\mypar{The entropic formulation} of the OT problem is a regularisation of the linear problem of Kantorovich by a strictly convex functional over the space $\Ps(\state)$. Let $\varrho\in\Ps(\state)$ be a reference measure, the relative entropy (a.k.a. Kullback-Leibler divergence) of $\pi$ with respect to $\varrho$ is 
\begin{align}
    \entropy(\pi\vert\varrho):= \begin{cases} \displaystyle\int \log\frac{\de\pi}{\de\varrho}\de\pi \mbox{ if } \pi\ll\varrho\\ +\infty \mbox{ if } \pi\not\ll\varrho\end{cases}\,\label{eq: def entropy}
\end{align}
in which $\pi\ll\varrho$ means that $\pi$ is absolutely continuous with respect to $\varrho$, which is sufficient for the density $\de\pi/\de\varrho$ to exist (by Radon-Nikodym). 
The \emph{entropic} optimal transport problem is then formally defined as
\begin{align}
    \ent(\mu,\nu,c,\ve) := \inf_{\pi\in\Pi(\mu,\nu)} \langle c\vert \pi\rangle + \ve\entropy(\pi\vert\varrho)\,.\label{eq: entropic OT def}
\end{align}

In~\eqref{eq: entropic OT def}, relative entropy penalises concentration of measure on sets to which $\varrho$ assigns low mass, which one can interpret as forcing the transport to be more spread out on the support of $\varrho$. For example, if $\varrho=\mu\tensor\nu$, the independent coupling\footnote{So called because it is the joint law of random variables $X\sim\mu$ and $Y\sim\nu$ which are independent.} of $\mu$ and $\nu$, then the entropic regularisation forbids the mass from any $x$ from being sent wholly to a single $y$ (and vice-versa). 

The increased regularity of~\eqref{eq: entropic OT def} explains why the practical algorithm of choice for approximate resolution of OT problems, Sinkhorn's algorithm \citep{sinkhorn_concerning_1967,cuturi_sinkhorn_2013,peyre_computational_2020}, relies on the entropic formulation rather than the one of Kantorovich. 


\subsection{The learning problem}
% \lc{ this section is mostly good, the motivating example needs to be modified and give explicit examples of the measures etc. Add the goal again as high probability regret and existing lower bounds}

% Example for motivation:
% \begin{itemize}
%     \item should include $\pi_t$, $\mu,\nu$ and $c^*$. 
% \end{itemize}

% As an example to illustrate the learning problem, consider a manager who must assign workers to tasks on a production line. The manager knows how many workers and tasks there are, i.e.\ the marginals $(\mu,\nu)$, but not the efficiency of each worker on each task and thus not the cost function $c^*$ of any assignment of workers to tasks. Every day the manager assigns tasks to workers, and at the end of the day measures the quantity of product (which fluctuates due to exogenous randomness) but not the contribution of each worker. Nevertheless, the manager strives to learn the best assignments, while sustaining profitability during the learning process. 


Formally, we consider the following learning game: at each round $t\in\Nb:=\{1,2,\ldots\}$, the agent submits a transport plan $\pi_t\in\Pi(\mu,\nu)$, and receives a noisy reward feedback
\[ 
    R_t := \int c^*(x,y)\de\pi_t(x,y) + \xi_t\,,
\]
in which ${(\xi_t)}_{t\in\Nb}$ is a sequence of random variables and $c^*$ is the \emph{unknown} true cost function. Henceforth, we work on a suitable probability space filtered by the natural filtration of ${(\xi_t)}_{t\in\Nb}$.
In our formulation, we consider that $(\Mc_\mu, \Mc_\nu,\mu,\nu)$ are known ahead of time. This is an important distinction from some works in statistical optimal transport which attempt to study OT only through samples of $\mu$ and $\nu$. %While it is possible to estimate the constraint set $\Pi(\mu,\nu)$ from samples, the main question if one does not know $\mu,\nu$ is ``what to do with inadmissible actions?'' Since we are interested primarily in the way the geometry of the OT functional can be exploited to learn $c^*$, we set this question aside in this work but touch upon it in \cref{subsec: Monge pb}.

In order to assess its performance, we assimilate the algorithm of any learning agent to its action sequence $\actions:={(\pi_t)}_{t\in\Nb}$. We evaluate the quality of $\actions$ \emph{online} (i.e.\ during the learning rather than at the end) using the classical tool of regret. Dependent on if the problem of interest is the Kantorovich~\eqref{eq: kantorovich def} or the entropic OT~\eqref{eq: entropic OT def} problem, one may consider two types of regret: the \emph{Kantorovich regret}
\begin{align}
    \regret_T(\actions)&:= \sum_{t=1}^T R_t -\kant(\mu,\nu,c) \qquad\mbox{ for }\quad T\in\Nb\label{eq: kantorovich regret}
    \intertext{or the \emph{entropic regret}}
    \regret_T^{\entropy,\ve}(\actions)&:= \sum_{t=1}^T \left( R_t + \ve\entropy(\pi_t\vert\varrho) \right)-\ent(\mu,\nu,c,\ve)\qquad\mbox{ for }\quad T\in\Nb\label{eq: entropic regret}
\end{align}
for a reference measure $\varrho$. In the following we take $\varrho$ to be the independent coupling $\mu\tensor\nu$. Which regret is most appropriate depends on the problem at hand, but their analyses are closely related.

Low (sub-linear) regret requires performance during learning, which is not the case in classical learning settings. This is due to the appearance of an \emph{exploration-exploitation} trade-off, as the agent must balance between exploring to learn $c^*$ and exploiting its current knowledge to minimise its cost. 

Note that regret is a decision-theoretic criterion: it measures the quality of the decision $\pi_t$ in terms of the OT problem, not the quality of any estimation of $c^*$. Achieving low regret thus requires only learning the structure of $c^*$ that is relevant to finding its minimum over $\Pi(\mu,\nu)$. The structure of the OT problem itself can thus facilitate learning even with minimal assumptions on $c^*$.

Our goal is to design a learning algorithm $\actions$ which achieves the slowest regret growth (as a function of $T$) as possible, in a high-probability sense. This is the standard approach in stochastic bandit problems, with any sub-linear in $T$ regret growth implying convergence to the optimal value of the problem, and a regret of $\tilde\Oc(\sqrt{T})$ (i.e.\ growing slower than $\sqrt{T}\mathrm{polylog}(T)$) being the standard parametric rate, see e.g.\ \citep[Thm.~9.1, Thm.~19.2, Thm.~38.6]{lattimore_bandit_2020}. 


% \subsection{Example applications}

%     \begin{enumerate}
%         \item Matching/assignment. 
        

%         \item Mean-field limit of assignment problems.
%         \item Semi-discrete example: optimal pickups of bins (discrete target continuous/MF sites), or optimal distribution of logistics (vaccine roll-out, aid in disaster situations, military logistics).
%         \item 


%         \item As classical application of this kind of Optimal Transport problem, consider the following job assignment problem. A manager has a team of workers, who fall into different categories (\emph{types} in economics) represented by elements of $\Mc_\mu$. The team can be represented as a probability measure $\mu$ on $\Mc_\mu$. To complete a project, the manager must assign the workers to some tasks, represented by a probability measure $\nu$ on the set of possible tasks $\Mc_\nu$. Whether a worker (type) can complete only one, or more than one, kind of task determines whether a Monge or Kantorovich formulation is more appropriate.
        
%         When $\Mc_\mu$ and $\Mc_\nu$ are finite, the problem can be represented as a bipartite graph, with weights associated to the cost of assigning each worker to each task, and this problem is well-known as the \emph{assignment} or \emph{matching} problem in Economics. \ltodo{could add a figure for bipartite matching here}

%         The setting we consider arises naturally from the partial information of the manager. On a production line, i.e.\ with $(\mu,\nu)$ fixed and known, the same item  is manufactured (the ``project') repeatedly. The factory manager can inspect the final item but not the contribution of each worker. How can they adjust the assignment of workers to tasks in this case? Mathematically, they are trying to learn the optimal assignment (Monge or Kantorovich) absent knowledge of the cost function $c$, under bandit feedback (with no counterfactual information). 

%         Note that assignment with infinite types has natural applications to large-scale instances of this problem, such as the assignment of workers to tasks in a large company, or the assignment of students to schools in a large city. This is generally considered from a mean-field limit perspective. 

%         \item 

%     \end{enumerate}


%Ex: Can use two graphs for the spaces so we can optimally transfer a graph to another. 

