
\section{Challenges, related work, and contributions}\label{sec:RWCC}
Giving an exhaustive account of the vast literature of Optimal Transport would be outside the scope of this article. As it focuses on aspects of online learning, we will limit our attention to this narrow view. Nevertheless, we provide the curious reader a modest bibliography in \cref{app: biblio}.

\subsection{On optimal transport and learning}\label{subsec: OT and learning RW}
        \paragraph{Estimation of OT functionals}
        Much of the early work in statistical OT focused on estimating the value of the functional $\kant(\mu,\nu,c)$ when $(\mu,\nu)$ are unknown, but $c$ is known and highly regular, e.g.\ \citep{horowitz_mean_1994,weed_sharp_2019}. These regularity assumptions are motivated by the study of Wasserstein distances between probability measures (i.e.\ $c=\norm{\cdot-\cdot}^p$, $p\ge1$) via sampling. With the increased interest in the entropic OT problem, many works have asked the same questions about $\ent(\mu,\nu,c,\ve)$, e.g.\ \citep{rigollet_sample_2022,stromme_minimum_2024}.   

        This line of work is orthogonal to our investigation, as we know $(\mu,\nu)$ but not $c^*$. The critical object in this line of work is the regularity structure of $\kant(\mu,\cdot,c)$, when $c$ is strongly regular. For our problem, the relevant geometry is that of the transport functional $\pi\in\Pi(\mu,\nu)\mapsto \langle c^*\vert \pi\rangle$.

        \paragraph{Online matchings}
        Concurrently, Matching (discrete marginal OT), has been actively studied by computer scientists and economists. These works, such as \citep{perrot_mapping_2016}, are often directly inspired by applications, and have yielded many creative extensions to the OT problem:~\cite{alon_learning_2004} aims to learn an optimal matching using queries to an oracle;~\cite{johari_matching_2021} to identify \emph{types} of nodes;~\cite{min_learn_2022} to design a welfare-maximising social planner; etc.

        The common thread amongst these works is the nature of the \emph{market} on which they work: at each time $t$, a new supply becomes available to \emph{match} (i.e.\ transport from), and the agent must decide to which of its available demands to transport it. This decision problem is fundamentally different from our repeated OT problem as mistakes in the matching are permanent, while we replay a whole matching at each step.
        Furthermore, the information structure is different. \cite{jagadeesan_learning_2021,sentenac_pure_2021,sentenac_learning_2023} (amongst others) have highlighted that this problem is a combinatorial semi-bandit problem, in which there is feedback about each connection made. In our problem the agent receives feedback only about the matching as a whole (full bandit). These two differences make the problems seem superficially similar, but they are fundamentally different.
                          
        \paragraph{Online Learning to Transport}
        The first paper to take interest in online learning of optimal transport itself appears to be \citep{guo_online_2022-1}. In this article, the authors take an Online Convex Optimisation (OCO) approach to the problem, meaning that an adversary chooses a cost function $c_t$ at each round $t$ from a class of suitably regular (convex) functions. The learner aims to choose a sequence of transport plans $\pi_t$ which has a small regret with respect to the best fixed transport plan in hindsight. While this work pioneered the study of online (repeated) optimal transport, there are no direct reductions between this paper and their work.

        Most of the work of~\cite{guo_online_2022-1} is done under a full-information adversarial setting (as is typical in OCO): the transport problem changes at each round and is completely revealed after a coupling $\pi_t$ is played. However, in section 3, the authors provide a $0$-order semi-bandit scheme based on a discretisation of $\state$. In contrast, our work is directed at a stochastic setting under complete bandit feedback (only $\int c\de \pi_t$ is observed, with some noise).
        
        Due to the use of OCO techniques, as well as PDE-based optimal transport tools based on the work of~\cite{brenier_least_1989}, the results of~\cite{guo_online_2022-1} are only valid under strong assumptions on the regularity of the cost functional (and thus the cost function) and the marginals. In contrast, we work without specific assumptions on the cost function and marginals, beyond the minimal ones for~\eqref{eq: kantorovich def} to be well-defined. This difference arises because they consider general functionals on the Wasserstein space, while our work focuses on the specific regularity of OT functionals.

        This work was followed by~\cite{zhu_semidiscrete_2023} which considers the first online learning problem in semi-discrete optimal transport (i.e.\ $\mu$ discrete, $\nu$ continuous). They construct a semi-myopic algorithm with forced exploration which can learn to behave as the optimal plan from samples of the continuous marginal. Unfortunately, they do not study a general problem but rather only the case in which the cost $c^*$ is a linear parametric model. This choice obfuscates a large part of the complexity of the general problem and dilutes any insights about the geometry of the problem.
        Moreover, \cite{zhu_semidiscrete_2023} do not provide direct regret bounds, but rather performance metrics which may be converted into regret bounds. Sadly, these metrics fail to generalise to the continuous marginal case, and their analysis breaks down in the general setting.

\subsection{Bandit Algorithms}

As \cref{subsec: OT and learning RW} shows, bandits and optimal transport have been in peripheral contact repeatedly. Nevertheless, despite its interest in many optimisation problems, the bandit literature has remained  uninterested in the general optimal transport problem. Still, let us highlight the key elements of this theory on which we can build to solve the bandit optimal transport problem. 

\mypar{Multi-armed bandits}. The classical bandit problem \citep{thompson1933likelihood,lai_asymptotically_1985,auer_finite-time_2002} considered the issue of choosing the best amongst a finite set of arms based on bandit feedback about arm rewards. Since then, bandit theorists have taken some interest in higher-dimensional optimisation problems either linear or non-linear. 
For instance, \cite{tran-thanh_functional_2014} show regret bounds for learning a general functional using bandit feedback but sadly still considers only finitely many arms. While a general theory of bandits for functionals remains elusive \citep{wang_beyond_2022}, bandits under weak assumptions on the set of arms have been studied.

\mypar{Lipschitz bandits}. Several papers \citep{bubeck_lipschitz_2011,magureanu_lipschitz_2014,kleinberg_bandits_2019} have leveraged Lipschitz reward functions to provide regret bounds and algorithms, even on arbitrary metric spaces. Unfortunately, the bounds for general Lipschitz functions using these methodology are of the order of $\Theta(T^{{(d+1)}/{(d+2)}})$, in dimension $d\in\Nb$ \citep{kleinberg_bandits_2019}. In the case of the continuous optimal transport problem, this dimension is infinite, and the regret bounds become vacuous. The infinite dimensional nature of our problem also prevents the practical usability of most discretisations, even sophisticated ones like the tree-based scheme of~\cite{bubeck2011X-armed}. 

\mypar{Linear bandits}. In the hope of circumventing this problem, we can take inspiration from Kantorovich and recall that~\eqref{eq: kantorovich def} is linear program. Indeed, linear functions have much stronger global regularity than Lipschitz ones, meaning that linear bandits may escape vacuity even when $d=+\infty$.   

The setting of linear bandits was introduced by~\cite{auer_using_2003}, and refined by many subsequent works \citep{abeille_linear_2017,vernade_linear_2020,hao_high-dimensional_2020}, most notably for us~\cite{abbasi-yadkori_improved_2011}. In his doctoral thesis, Y.~\cite{abbasi-yadkori_online_2012} includes a version of this article in which the technical results are given not just for $\Rb^d$, but for an arbitrary Hilbert space. These works all use the celebrated Optimism in the Face of Uncertainty (OFU) principle to tackle the previously mentioned exploration-exploitation dilemma.

Nevertheless, in spite of its generality,~\cite{abbasi-yadkori_online_2012} is not sufficient to solve the bandit optimal transport problem, because the action space of our bandit is not a Hilbert space, and in fact the actions do not live in the same space as $c^*$. This fundamentally breaks the assumptions of this work, in spite of the fact that the duality product $\langle c\vert \pi \rangle$ defining $\kant$ is a linear form. 

\mypar{Kernel bandits.} Kernel methods intrinsically consider infinite-dimensional linear rewards, and may appear, at first, an ideal solution for solving bandit optimal transport. Kernel bandits have seen extensive work \citep{chowdhury_kernelized_2017,janz_bandit_2020,takemori_approximation_2021},  including~\cite{valko_finite-time_2013} which comes closest to our approach by introducing a kernelised OFU algorithm. These methods posit a particular structure for the reward function $c^*$, and then use the representer theorem to reduce the problem to a linear problem. Our problem, in contrast, is already linear so it should not require any such assumptions. 

One place where kernel methods shine is in making infinite-dimensional problems computationally tractable. While they can be used for this purpose in our setting, we will show that we can obtain similar bounds directly from the regularity of $c^*$ without assuming an RKHS structure. 

  
\subsection{Challenges and contributions}

\paragraph{Challenges} The specificities and challenges of the general BOT problem, can be summarised in three main points. 

\textbf{A)} The actions of this bandit problem are probability measures. In the discrete optimal transport (matching) problems previously studied in the literature, probability measures remain finite dimensional and can be represented using an inner product. This hides the true complexity of the general case in which one must confront a continuum of infinite-dimensional actions which require sophisticated tools to analyse. Moreover, this is compounded by the fact that the space of probability measures has a difficult geometry. 

\textbf{B)} The cost function $c^*$, which plays the role of a ``parameter'' to estimate, is a continuous function. Since the optimal transport problem only requires minimal integrability assumptions on $c^*$, the natural hypothesis classes for $c^*$ will be large function spaces\footnote{Circumventing this difficulty by parametrising $c^*$ as in~\cite{zhu_semidiscrete_2023} would dilute any insight about the geometry of the problem.} such as $L^2$.  This creates a significant difficulty for estimation and thus for bandit algorithms based on least-squares. The construction of estimators and confidence sets that permit the use of OFU algorithms is  challenged by the infinite dimensionality of $c^*$. 

\textbf{C)} Even if estimators for $c^*$ can be constructed, they must face the infinite-dimensionality of $c^*$. This raises the challenge of efficient approximation of infinite-dimensional estimators under weak assumptions, and of their associated regrets.

\paragraph{Contributions} This paper is the first study of the general stochastic bandit optimal transport problem. It provides a general framework for further work in this area, by showing that the problem is learnable under weak assumptions. Beyond this, the technical contributions can be summarised as follows.

\textbf{1)} To overcome challenge \textbf{A}, we construct a phase-space representation of the optimal transport problem which allows us to transform the problem into a linear bandit on a Hilbert space. This is enabled by the regularity of the entropic problem and tools from the Fourier analysis of measures.  

\textbf{2)} Combining \textbf{1} with the framework of~\cite{abbasi-yadkori_online_2012} we are able to construct the necessary confidence sets and estimators to estimate $c^*$ and address challenge \textbf{B}. By regularising optimism by entropy, and using the dual problem of~\eqref{eq: entropic OT def}, we are able to ensure our algorithm maintains the validity of the phase-space representation as it learns, unlocking regret analysis. In the regret analysis, we leverage the regularity of the entropic problem to prove bounds on the Kantorovich regret through the entropic one.

\textbf{3)} To face the infinite-dimensional quantities which arise in the general regret bounds, we construct a general estimation method based on the regularity of the cost function. This method addresses challenge \textbf{C} by allowing us to obtain regret bounds of order $\tilde\Oc(\sqrt{T})$ in simple cases, and an interpolation up to $\tilde\Oc(T)$ dependent on the regularity of $c^*$. 

