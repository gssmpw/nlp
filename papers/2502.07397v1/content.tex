\section{Technical solutions to the learning problem}\label{sec: Preliminaries}

This section covers the key technical contributions of contributions \textbf{1} and \textbf{2} above, which go into designing our learning algorithm and guaranteeing, before we study its regret and contribution \textbf{3} in the next section. We postpone the proofs and most lemma statements to the appendices.

\subsection{The problem of measure-valued actions}\label{subsec: measure valued actions}

The technical issue in challenge \textbf{A} is that the bilinear form $\langle\cdot\vert\cdot\rangle$ of~\eqref{eq: kantorovich def 2} is not an inner product. This prevents us from applying standard linear bandit tools. Recall that, formally, $\langle\cdot\vert\cdot\rangle$ is the duality pairing between continuous functions vanishing at infinity and finite measures.
To reconcile these two types of objects, we leverage Fourier analysis and represent them both in phase-space. 
To ensure the Fourier transform and the transport problems are well defined, let us assume \cref{asmp: L2 case}, in which $L^p(\Rb^d;\varrho)$ for $p\ge1$ is the Lebesgue space associated with a reference measure $\varrho\in\Ps(\Rb^d)$. Note that $L^2(\Rb^d;\varrho)$ is a Hilbert space. 

\begin{assumption}\label{asmp: L2 case}
    The true cost function $c^*$ is continuous and belongs to $L^2(\Rb^d;\varrho)$.
\end{assumption}

Let $\fourier$ denote the Fourier transform operator that acts on $L^2(\Rb^d;\varrho)$ or on measures, using the formulae
\begin{align*}
    \fourier: \phi\in L^2(\Rb^d;\varrho)\mapsto\int \phi(x)e^{-2\pi i\langle x\vert \cdot\rangle_2}\de\varrho(x) \mbox{ and } \fourier:\gamma\in \Ps(\Rb^d)\mapsto \int e^{-2\pi i\langle x\vert\cdot\rangle_2}\de\gamma(x) \,.
\end{align*}
when these are well defined (see \cref{app: fourier} for rigourous constructions of this section). In particular, since a coupling $\pi$ is a finite measure, $\fourier\pi$ is ($\varrho$-a.e.) bounded and thus $L^2(\Rb^d;\varrho)$. The operator $\fourier$ is an isometry on $L^2(\Rb^d;\varrho)$, and thus we can write
\begin{align}
    \langle c^*\vert\pi\rangle = \langle \fourier c^*(-\cdot)\vert\fourier\pi\rangle_{L^2(\Rb^d;\varrho)}:=\int \fourier c^*(-z)\overline{\fourier\pi}(z)\de \varrho(z) \,.\label{eq: fourier transform of the L2 product}
\end{align} 
This approach relies on formal calculation, and to guarantee that the right-hand sides of~\eqref{eq: fourier transform of the L2 product} are well defined, we need to ensure that $\fourier\pi$ is in $L^2(\Rb^d;\varrho)$. This turns out to be equivalent to requiring that $\pi$ have a density $\de\pi/\de\varrho$ with respect to $\varrho$ which is itself in $L^2(\Rb^d;\varrho)$ (see \cref{lemma: fundamental facts about fourier transform of measure}). 
%
In general, there is no meaningful choice of $\varrho$ which can ensure this for any coupling $\pi$. However, by repurposing entropic regularisation, recall~\eqref{eq: entropic OT def}, we can give a large class of couplings which do have a density with respect to $\varrho$. Let 
\begin{align}
    \entf:(c,\pi)\in L^2(\Rb^d;\varrho)\times\Pi(\mu,\nu)\mapsto \langle c\vert\pi\rangle + \ve\entropy(\pi\vert\varrho)\,,\label{eq: entropic functional}
\end{align}
denote the entropic transport functional, so that $\ent(\mu,\nu,c,\ve)=\inf_{\pi\in\Pi(\mu,\nu)}\entf(c,\pi)$. By definition, see~\eqref{eq: def entropy}, $\entf(c,\pi)$ is finite precisely when $\pi$ has a density with respect to $\varrho$. We will see that careful algorithmic design (see \cref{subsec: entropy regularised optimism}) can ensure that the algorithm only plays couplings with $L^2(\Rb^d,\varrho)$ densities ensuring~\eqref{eq: fourier transform of the L2 product} is valid in the regret analysis of \cref{sec: regret of learning}.

Altogether, the phase-space representation and the entropic problem allow us to move the problem from the duality product $\langle\cdot\vert\cdot\rangle$ to a Hilbert space inner product $\langle\cdot\vert\cdot\rangle_{L^2(\Rb^d;\varrho)}$, which unlocks regularised least-squares confidence constructions for learning. 


%As a result, we know that \eqref{eq: fourier transform of the L2 product} is valid on any admissible point of the entropic problem. Furthermore, existing results allow us to quantify the difference between $\kant$ and $\ent$ problems, see \cref{lemma carlier pegon lipschitz UB}. All together, we can use the phase-space representation to move the problem $\kant$ to $\ent$ and then apply Hilbert space linear bandit tools. This enables us to adapt them to  enable learning (see \cref{subsec: algorithmic design}) in the BOT problem. 

% \begin{itemize}
%     \item[x] Remind the challenge of the measure-valued action space (the Kantorovich objective is a bilinear form, but the actions and parameters are not in the same space.) This prevents us from applying standard linear bandits for Hilbert spaces.
%     \item[x] because the transport function is a linear form over probability measures, and due to duality of $C_0$, it is a bilinear form. + duality pairing
%     \item[x] Existence of a suitably regular density with respect to a reference measure allows us to write the functional as an inner product in the Hilbert space $L^2$. 
%     \item[x] The most elegant way to represent this is by transforming the problem into the phase space by using the Fourier transform of $L^2$ functions and measures. So that in one space you retain the transport problem with its coupling and compact set of constraints, and in the other you have an inner product on $L^2$.
%     \item No: Definition of the Fourier transform, on $L^2$ and $\Ms$.
%     \item No: Definition of the equality of the brackets
%     \item[x] Assumption 1
%     \item[x] discussion of Assumption 1
%     \item[x] Emphasise need for the algorithm to play a regular pi in the analysis, but let's pretend it does for the sake of the next section.
% \end{itemize}

\subsection{Infinite dimensional estimation for of the cost function}\label{subsec: algorithmic design}

With our problem reframed onto $\ffset:=L^2(\Rb^d;\varrho)$, we can construct an optimistic algorithm by using the general methodology of~\cite{abbasi-yadkori_online_2012}. The fact that this methodology is applied in phase space is non-standard, but the arguments remain standard, hence we defer them to \cref{app: technical details}. The validity of this methodology relies on the standard \cref{asmp: estimate + subG}. 

\begin{assumption}\label{asmp: estimate + subG}
    An \textit{a priori} scale estimate $\ubnorm\ge \norm{c^*}_{L^2(\Rb^d;\varrho)}$ is known. The sequence ${(\xi_t)}_{t\in\Nb}$ is $\sigma^2$-sub-Gaussian for some $\sigma\in(0,+\infty)$.
\end{assumption}

In the remainder of this section we introduce the quantities needed to establish our algorithm.
Given a history ${(a_s,R_s)}_{s\le t}$ of actions ($a_s:=\fourier\pi_s\in\ffset$) and rewards, a strongly convex regulariser $\Lambda$ (e.g.\ $\norm{\cdot}^2_{L^2(\Rb^d;\varrho)}$), and $\lambda>0$, the least-squares estimator $\hat f_t^\lambda$ of $f^*:=\fourier c^*$ in $\ffset$ is
\begin{align}
    f_t^\lambda\in \argmin_{f\in\ffset}\sum_{s=1}^t\norm{R_s - \langle f\vert a_s\rangle_{L^2(\Rb^d;\varrho)}}^2_2 + \lambda\Lambda[f] \,.\label{eq: RLS estimator}
\end{align}
One can also characterise $f_t^\lambda$ through a closed form expression, see \cref{prop: least squares estimator}. 
Like in the finite dimensional problem, the confidence sets requires the definition of the feature operator
\begin{align}
    M_t: f\in \ffset \mapsto {(\langle f\vert a_s \rangle_{L^2(\Rb^d;\varrho)})}_{s=1}^t\in\Rb^t\,, \label{eq: Mt and adjoint}
\end{align}
its adjoint $M_t^*$, and the design operator $D_t^\lambda:=M_t^*M_t + \lambda\De\Lambda$ ($\De$ denoting Fr√©chet differentiation). Given $\delta\in[0,1]$ the confidence set is then defined as
\begin{align}
    \confset_t(\delta):=\left\{f\in\ffset: \norm{f-\hat f_t^\lambda}_{\designl_t}\le \width_t(\delta)\right\}\,,\label{eq: confidence set}
\end{align}
with its width $\beta_t(\delta)$ is chosen as
\begin{align}
    \width_t(\delta):=\sigma\sqrt{\log\left(\frac{4\det(\De\Lambda+\lambda^{-1}M_t M^*_t)}{\delta^2}\right)} +{\left(\frac{\lambda}{\norm{\De\Lambda}_{\op}}\right)}^{\frac12}\ubnorm\,. \label{eq: confidence set width def}
\end{align}

We defer the proofs of the validity of these confidence sets to \cref{app: technical details}. Performing least-squares in the phase space is a novel technique, but the arguments remain standard. 


\subsection{Entropy regularised optimism}\label{subsec: entropy regularised optimism}

With confidence sets in hand, to define an OFU algorithm, one needs only an optimism step. In our phase-space construction, this usually straightforward step requires care: we need to ensure that the actions ${(\pi_t)}_{t\in\Nb}$ taken by the algorithm satisfy $\pi_t\ll\varrho$, lest they break~\eqref{eq: fourier transform of the L2 product} and thus the confidence sets. For instance, being optimistic with respect to the Kantorovich problem fails on this point.

Remarkably, the regularity of the entropic problem can be exploited (again) to bypass this issue. This is shown by leveraging the (strong) dual form of the Kantorovich problem
\begin{align}
    \ent(\mu,\nu,c,\ve) = \sup_{(\varphi,\psi)\in\Xi} \left\{\int \varphi\de\mu + \int \psi\de\nu - \ve\int e^{\ve^{-1}(\varphi+\psi-c)}\de(\varrho) + \ve\right\}\,,\label{eq: entropic dual}
\end{align}
wherein $\Xi=\{(\varphi,\psi)\in L^1(\mu), L^1(\mu) :\varphi\oplus\psi\le c \}$ with  $\varphi\oplus\psi:(x,y)\mapsto \varphi(x)+\psi(y)$. From a dual solution $(\varphi^*,\psi^*)\in\Xi$, one may recover (see e.g.\ \citet[Thm.~4.2]{nutz_introduction_2022}) a primal solution $\pi^*$ with density 
\[ 
    \frac{\de\pi^*}{\de\varrho}=e^{\frac{\varphi^*\oplus\psi^*-c}\ve}<+\infty\,.
\]  
By~\eqref{eq: entropic dual}, a solution to the entropic problem is a transport plan (an action) with an $L^\infty(\Rb^d;\varrho)\subset L^2(\Rb^d;\varrho)$ density. Consequently, an optimistic algorithm which chooses a belief-action pair
\begin{align}
    (\tilde\pi_t,\tilde c_t)\in\argmin\left\{  \langle c\vert\pi\rangle +\ve_t\entropy(\pi\vert\varrho): \pi\in\Pi(\mu,\nu)\,,\, c\in\fourier^{-1}\confset_t(\delta)\right\}\,,\label{eq: optimistic planning}
\end{align}
guarantees the validity of the construction of \cref{subsec: measure valued actions} and unlocks standard regret analysis. 


The combination of these three technical elements (phase-space representation of the problem, infinite-dimensional estimation, and entropy regularised optimism) into the OFU framework yields \Cref{alg: alg shared}. We underline that the key contribution is the repeated exploitation of the geometry of the entropic OT problem, whose strong regularity properties allow us to ensure that the algorithm preserves the validity of the phase-space representation it uses to learn. By leveraging the regularity of the OT problem, we show in the next section that \cref{alg: alg shared} can achieve low regret in spite of the apparent difficulty of the BOT problem.

\begin{algorithm}
    \caption{\namealgone{}\label{alg: alg shared}}
    \SetKwFunction{approxpi}{ApproximateAction}
    \KwData{Confidence $\delta$, regularization level $\lambda$, entropy penalisation ${(\ve_t)}_{t\in\Nb}$.}
    \For{$t\in\Nb$}{
            Compute the RLS estimator $\hat f_t^\lambda$ using~\eqref{eq: RLS estimator} or~\eqref{eq: reg least squares estimator}\;
            Construct the confidence set $\confset_t(\delta)$ using~\eqref{eq: confidence set} and~\eqref{eq: confidence set width def}\;
            Optimism: pick $ (\tilde\pi_t,\tilde c_t)$ according to~\eqref{eq: optimistic planning}\;
        Play $\pi_t=\tilde\pi_t$ if $t>0$, else $\pi_0=\mu\tensor\nu$; receive feedback $R_t$\;
    }
\end{algorithm}



\section{Regret analysis}\label{sec: regret of learning}

\Cref{alg: alg shared} has sub-linear regret with respect to both regret definitions. We will begin with the entropic regret, then show how we can leverage approximation results of the Kantorovich problem by the entropic one to obtain a sub-linear bound on the Kantorovich regret. Finally, we discuss how to control the infinite-dimensional quantities in the regret bounds using efficient learning methods.

\subsection{Entropic and Kantorovich regret}\label{subsec: regrets}

When the $\ve$-entropic problem is the objective of the bandit problem, \cref{alg: alg shared} can be configured with a fixed entropy level of $\ve$ and the following regret bound holds.

\begin{restatable}{theorem}{ThmEntropicRegret}\label{thm: entropic regret}
    Under \cref{asmp: L2 case,asmp: estimate + subG}, for any $\ve>0$, $\delta>0$, $\lambda>0$, and $T\in\Nb$, the regret of \cref{alg: alg shared} with ${(\ve_t)}_{t\in\Nb}={(\ve)}_{t\in\Nb}$, denoted by $\Ac$, satisfies
    \begin{align*}
        \regret_T^{\entropy,\ve} (\Ac)\le  \sigma\sqrt{2T\log\left(\frac2\delta\right)}+ 2\ubnorm\width_T(\delta)\sqrt{T\log\det\left(\Id + \frac{1}{2\lambda\ubnorm}M_T{(\De\Lambda)}^{-1}M_T^*\right)}
    \end{align*}
    with probability at least $1-\delta$. Note that $M_T$ (thus also $\width_T(\delta)$) depends implicitly on $\ve$.
\end{restatable}

{
    \flushleft\mypar{Proof sketch}. Having done the technical work in \cref{sec: Preliminaries} to ensure that the phase space construction is valid, the proof now follows the standard OFU methodology. One first isolates the noise of the estimations and controls it using concentration theory and \cref{asmp: estimate + subG}. Then one uses optimism and the high-probability validity  of ${(\confset_t(\delta))}_{t\in\Nb}$ to move from $c^*$ to the beliefs ${(\tilde c_t)}_{t\in\Nb}$. Finally, one uses the width of the confidence sets to control the regret. The full proof is given in \cref{subsec: entropic regret}.
}

When trying to solve the Kantorovich problem, using \cref{alg: alg shared} with any fixed $\ve$ would incur an incompressible error. However, we can leverage existing results, namely \cref{lemma carlier pegon lipschitz UB} \citep{carlier_convergence_2023}, on the convergence of the entropic problem to the Kantorovich problem to choose ${(\ve_t)}_{t\in\Nb}$ of the correct order and obtain a sub-linear regret bound.

\begin{restatable}{theorem}{ThmKantorovichRegret}\label{thm: regret Kantorovich}
    Under \cref{asmp: L2 case,asmp: estimate + subG}, if $c^*$ is $L$-Lipschitz on $\supp(\mu)\x\supp(\nu)\subset\Rb^d$, then for any $\delta>0$, $\lambda>0$, $\alpha\in(0,1)$, and $T\in\Nb$, the regret of \cref{alg: alg shared} with ${(\ve_t)}_{t\in\Nb}={(\alpha t^{-\alpha})}_{t\in\Nb}$, denoted $\Bc$, satisfies
    \begin{align*}
        \regret_T(\Bc) &\le \sigma\sqrt{2T\log\left(\frac2\delta\right)} + 2\ubnorm\width_T(\delta)\sqrt{T\log\det\left(\Id + \frac{1}{2\lambda\ubnorm}M_T{(\De\Lambda)}^{-1}M_T^*\right)}\\
        &\quad +\frac{\kappa\alpha}{1-\alpha}\left(T^{1-\alpha}\log(T) + \frac{\alpha}{2^\alpha}\log(6)\right)
    \end{align*}
    with probability at least $1-\delta$, in which $\kappa$ depends only on $(C,L,\mu,\nu)$.
\end{restatable}
{
    \flushleft\mypar{Proof sketch}. One modifies the proof of \cref{thm: entropic regret} by using the approximation result of \cref{lemma carlier pegon lipschitz UB} to move to the entropic regret up to an approximation term. The key step in the proof here is the use of the entropic optimism (\cref{subsec: entropy regularised optimism}) as the proof requires $\entf(c^*,\cdot)$ be controlled at the actions taken by the algorithm, which will fail if the construction of \cref{subsec: measure valued actions} is not respected. The choice of a suitable ${(\ve_t)}_{t\in\Nb}$ then completes the proof. The full proof can be found in \cref{subsec: kantorovich regret}. 
}

\Cref{thm: entropic regret,thm: regret Kantorovich} match the regret rate of~\cite{abbasi-yadkori_online_2012}, showing the problem is learnable in the same way as a linear bandit. However, one must exercise care in controlling the determinant term, as $M_T$ is infinite-dimensional so the confidence sets may be unbounded. 
