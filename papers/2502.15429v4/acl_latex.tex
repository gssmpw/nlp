% This must be in the first 5 lines to tell arXiv to use pdfLaTeX, which is strongly recommended.
\pdfoutput=1
% In particular, the hyperref package requires pdfLaTeX in order to break URLs across lines.

\documentclass[11pt]{article}

\usepackage{todonotes}
% Change "review" to "final" to generate the final (sometimes called camera-ready) version.
% Change to "preprint" to generate a non-anonymous version with page numbers.
\usepackage[final]{acl}

% Standard package includes
\usepackage{times}
\usepackage{latexsym}

% For proper rendering and hyphenation of words containing Latin characters (including in bib files)
\usepackage[T1]{fontenc}
% For Vietnamese characters
% \usepackage[T5]{fontenc}
% See https://www.latex-project.org/help/documentation/encguide.pdf for other character sets

% This assumes your files are encoded as UTF8
\usepackage[utf8]{inputenc}

% This is not strictly necessary, and may be commented out,
% but it will improve the layout of the manuscript,
% and will typically save some space.
\usepackage{microtype}

% This is also not strictly necessary, and may be commented out.
% However, it will improve the aesthetics of text in
% the typewriter font.
\usepackage{inconsolata}

%Including images in your LaTeX document requires adding
%additional package(s)
\usepackage{graphicx}
\usepackage{amsmath}

% custom package
\usepackage{subfig}
\usepackage{threeparttable}
\usepackage{multirow}
\usepackage{booktabs}
\usepackage[most]{tcolorbox}
\usepackage{url}
\usepackage{array, xcolor}
\usepackage{pifont}
\usepackage{colortbl}
\usepackage{adjustbox}
\usepackage{fontawesome}

\newcommand{\FTnote}[1]{\textcolor{brown}{\textbf{FT:} #1}}
\newcommand{\FT}[1]{\textcolor{brown}{ #1}}

\newcommand{\gf}[1]{\textcolor{orange}{\textbf{GF:} #1}}
\newcommand{\todoCemre}[1]{\todo[color=green!40]{#1}}

\tcbset{
    colback=blue!5,  % Light blue background
    colframe=blue!50, % Blue border
    boxrule=0.5pt,   % Border thickness
    rounded corners,
    width=\linewidth,
}

% If the title and author information does not fit in the area allocated, uncomment the following
%
%\setlength\titlebox{<dim>}
%
% and set <dim> to something 5cm or larger.

\title{\texttt{Pub-Guard-LLM}: Detecting Fraudulent Biomedical Articles \\ with Reliable Explanations}

% Author information can be set in various styles:
% For several authors from the same institution:
% \author{Author 1 \and ... \and Author n \\
%         Address line \\ ... \\ Address line}
% if the names do not fit well on one line use
%         Author 1 \\ {\bf Author 2} \\ ... \\ {\bf Author n} \\
% For authors from different institutions:
% \author{Author 1 \\ Address line \\  ... \\ Address line
%         \And  ... \And
%         Author n \\ Address line \\ ... \\ Address line}
% To start a separate ``row'' of authors use \AND, as in
% \author{Author 1 \\ Address line \\  ... \\ Address line
%         \AND
%         Author 2 \\ Address line \\ ... \\ Address line \And
%         Author 3 \\ Address line \\ ... \\ Address line}

\author{
Lihu Chen\textsuperscript{\rm 1},
Shuojie Fu\textsuperscript{\rm 1}, 
Gabriel Freedman\textsuperscript{\rm 1}, 
Cemre Zor\textsuperscript{\rm 2}, 
Guy Martin\textsuperscript{\rm 3}, \\
\bf James Kinross\textsuperscript{\rm 1},
Uddhav Vaghela\textsuperscript{\rm 1},
Ovidiu Serban\textsuperscript{\rm 1},
Francesca Toni\textsuperscript{\rm 1}\\
\textsuperscript{\rm 1} Imperial College London, UK \\
\textsuperscript{\rm 2} Amazon Web Services, UK \\
\textsuperscript{\rm 3} National Health Service, UK \\
}

%\author{
%  \textbf{First Author\textsuperscript{1}},
%  \textbf{Second Author\textsuperscript{1,2}},
%  \textbf{Third T. Author\textsuperscript{1}},
%  \textbf{Fourth Author\textsuperscript{1}},
%\\
%  \textbf{Fifth Author\textsuperscript{1,2}},
%  \textbf{Sixth Author\textsuperscript{1}},
%  \textbf{Seventh Author\textsuperscript{1}},
%  \textbf{Eighth Author \textsuperscript{1,2,3,4}},
%\\
%  \textbf{Ninth Author\textsuperscript{1}},
%  \textbf{Tenth Author\textsuperscript{1}},
%  \textbf{Eleventh E. Author\textsuperscript{1,2,3,4,5}},
%  \textbf{Twelfth Author\textsuperscript{1}},
%\\
%  \textbf{Thirteenth Author\textsuperscript{3}},
%  \textbf{Fourteenth F. Author\textsuperscript{2,4}},
%  \textbf{Fifteenth Author\textsuperscript{1}},
%  \textbf{Sixteenth Author\textsuperscript{1}},
%\\
%  \textbf{Seventeenth S. Author\textsuperscript{4,5}},
%  \textbf{Eighteenth Author\textsuperscript{3,4}},
%  \textbf{Nineteenth N. Author\textsuperscript{2,5}},
%  \textbf{Twentieth Author\textsuperscript{1}}
%\\
%\\
%  \textsuperscript{1}Affiliation 1,
%  \textsuperscript{2}Affiliation 2,
%  \textsuperscript{3}Affiliation 3,
%  \textsuperscript{4}Affiliation 4,
%  \textsuperscript{5}Affiliation 5
%\\
%  \small{
%    \textbf{Correspondence:} \href{mailto:email@domain}{email@domain}
%  }
%}

\begin{document}
\maketitle
\begin{abstract}
A significant and growing number of published scientific articles is found to involve fraudulent practices, posing a serious threat to the credibility and safety of research in fields such as medicine. 
We propose \texttt{Pub-Guard-LLM}, 
the first large language model-based system tailored 
to fraud detection of biomedical scientific articles. We provide three application modes for deploying \texttt{Pub-Guard-LLM}: 
 Vanilla Reasoning, Retrieval-Augmented Generation, and Multi-Agent Debate, by allowing for textual explanations of prediction in each mode.
To assess the performance of our system, we introduce 
an open-source benchmark, \emph{PubMed Retraction}, comprising over 11K real-world biomedical articles, including metadata and retraction labels. We show that across all modes, \texttt{Pub-Guard-LLM} consistently surpasses the performance of various baselines and provides more \emph{reliable} explanations, namely explanations which are 
deemed more \emph{relevant} and \emph{coherent} than those generated by the baselines when evaluated by multiple assessment methods. By enhancing both 
detection performance and explainability in 
scientific fraud detection, \texttt{Pub-Guard-LLM} contributes to safeguarding research integrity 
with a novel, effective, open-source tool. 
Our code is available at \faGithub~ \url{https://github.com/tigerchen52/pub_guard_llm}
\end{abstract}



\begin{figure*}
    \centering
    \scalebox{0.85}{
    \includegraphics[width=0.98\textwidth]{figures/framework.pdf}}
    \caption{%An illustration 
    Workflow of the proposed Pub-Guard-LLM (Details in Section~\ref{sec:pubguardLLM})}
    \label{fig:framework}
\end{figure*}





\section{Introduction}

A considerable proportion of published scientific articles has been found to involve fraudulent practices. It is estimated that between 1.5 and 2\% of all scientific papers published in 2022 closely resemble content produced by paper-mills \cite{fakepaper2023nature}, and about 8,000 papers were retracted from Hindawi journals due to their fraudulent origins in paper mills in 2023 \cite{parker2024paper}. Even more concerning, generative %artificial intelligence 
AI tools including those built on large language models (LLMs) can produce highly convincing fraudulent articles that have the potential to bypass existing detection mechanisms~\cite{majovsky2023artificial, kendall2024risks}. This indicates that fraud in this area is constantly adapting %, which learns 
and learning to circumvent existing detectors~\cite{majovsky2023artificial,perkins2023academic}. 

%Across all fields% of fraud
%, 
Fraudulence of \emph{biomedical} publications %are
is more pronounced than in other fields~\cite{grieneisen2012comprehensive, bik2016prevalence}, with a recent finding revealing that over a fifth of newly published medical articles are at least partially fraudulent \cite{sabel2023fake}. Moreover, the problem of fraudulent article detection is not confined to 
%a particular subset of 
a specific set of offending author institutions. In fact, recent high-profile cases have uncovered academic fraud from %such seemingly 
credible sources such as Harvard Medical School \cite{fortune2024harvard}.  This widespread %fraud 
trend poses a serious threat to public health, as misleading medical research can directly influence clinical decisions, leading to ineffective or even harmful treatments for patients.

Prior attempts addressing this challenge mainly rely on relatively primitive heuristic  techniques~\cite{parker2022experts, shepperd2023analysis,feng2024citation}, 
%and subsequent studies adopt
including some based on argument quality 
%language models for fraud detection 
\cite{freedman2024detecting}. While the threat of fraudulent articles is likely to grow in the future, the NLP community has yet to give this issue the attention it deserves. This lack of focus is partly due to two key challenges% that remain to be addressed
. First, there is no standard benchmark dataset for evaluating and comparing various fraud detection systems. Second, there are no open-source systems leveraging on LLMs
 specially designed for this task.
%\todo{Third, existing baselines...are not explainable? when they are explainable not reliable???}

To %mitigate this gap
address these challenges, we %first 
introduce \emph{PubMed Retraction}, the first large-scale open-source benchmark for fraud detection in biomedical research, including %around 12K 
over 11K \emph{real-world} articles. Our benchmark is designed to consider the diversity across various types of academic misconduct, rather than focusing solely on specific issues like plagiarism or machine-generated text. 
The main goal of this benchmark is to flag potentially fraudulent articles with minimum %textual
information\footnote{Complex features, such as tables and images, are not the focus of %this 
the current version of our benchmark% dataset
.}. %Second
Also, we release the first LLM%s
-based system, \texttt{Pub-Guard-LLM}, dedicated to the task of fraud detection%, which is shown to significantly outperform various competitors while providing relevant and coherent explanations.
%Furthermore, we provide three application modes for \texttt{Pub-Guard-LLM}
. \texttt{Pub-Guard-LLM} can be deployed in three application modes (see %overview in
Figure~\ref{fig:framework}): Vanilla Reasoning, Retrieval-Augmented generation, and Multi-Agent Debate, each making use of external knowledge and fine-tuning and each %allowing for 
returning (textual) explanations of predictions. 
We show that \texttt{Pub-Guard-LLM} can significantly outperform %various
baselines while generating more \emph{reliable} explanations, by being more \emph{relevant} to the explanandum %, in the spirit of~
\cite{kotonya2024towards} and more \emph{coherent} %, in the spirit of~
\cite{kotonya2020explainable}.
The three
application modes provide options for users to focus on depending on their needs, balancing key factors such as precision and recall of predictions, reliability of explanations% explainability
, and inference speed. 
%This ensures that users can prioritize either high-%accuracy
%performance detection, comprehensive fraud identification, interpretable results, or fast processing, depending on the demands of their task. 
This adaptability makes %the system 
\texttt{Pub-Guard-LLM} highly versatile, accommodating a wide range of use cases in fraudulent article detection.

With the introduction of the first publicly available benchmark and an open-source LLM specifically designed for fraudulent article detection, our work aims to serve as a foundational step for future research in this field. However, while technological solutions can help address this issue, the root of the problem lies within academic evaluation systems themselves. Researchers face immense pressure to publish to secure funding and career advancements. As long as these systems prioritize metrics and publication counts over genuine scientific contributions, the arms race between fraud makers and detectors will persist.

\section{Related Work}
%In the academic literature, 
% The %prevalence 
% presence of fraudulent academic articles is increasing, with thousands of fake manuscripts being published in peer-reviewed journals every year~\cite{fakepaper2023nature,parker2024paper}. 
The increasing scientific fraud presents a serious challenge to both the research community and society at large. Previous studies addressing this challenge primarily focus on rule-based heuristics%. These methods are 
, based on analyzing indicators such as author affiliations~\cite{sabel2023fake}, citation patterns~\cite{shepperd2023analysis,feng2024citation}, journal impact factors and author networks~\cite{perez2022threats}. 
Recently, traditional machine learning techniques~\cite{dadkhah2023detection, cabanac2022problematic} as well as BERT-based models~\cite{freedman2024detecting} have been proposed to help with fraudulent article detection. 
%More recently, machine learning techniques such as Decision Trees~\cite{dadkhah2023detection}, trained to distinguish human-written vs. AI-generated text, and BERT-based models~\cite{freedman2024detecting}, %which are specifically trained to distinguish human-written vs. AI-generated text, or 
%trained to distinguish retracted vs accepted manuscripts, have %significantly advanced the field by enhancing 
%been proposed to help with %the accuracy and efficiency of 
%fraud detection.


However,  %Despite 
the rapid growth in the number of fraudulent articles %, there has not been sufficient 
has not been matched by dedicated attention within the NLP field % devoted  to this problem
~\cite{byrne2024call}%, particularly within the NLP research field
. Currently, there is an urgent need for more research into two key aspects.  (1) \emph{Benchmarks}.  
%The current largest open-source dataset related to this task is Retraction Watch~\cite{RetractionWatchDatabase}, which brings together about 50,000 retracted articles in various fields. 
Existing studies generally employ Retraction Watch~\cite{RetractionWatchDatabase}, a blog that monitors and reports on retractions of scientific papers, to analyze retraction behaviors~\cite{shepperd2023analysis, byrne2022protection, freedman2024detecting}.
The Retraction Watch provides a collection of retracted records, but it does not constitute a benchmark on its own for comparing existing methods.
While benchmarks exist for specific fraud types, such as plagiarism~\cite{wahle2021neural} and machine-generated text~\cite{mosca2023distinguishing, abdalla2023benchmark, liyanage2022benchmark}, there is currently no standardized benchmark including diverse fraud types using real-world articles.
(2) \emph{Open-Source Tools}. While some systems for detecting fraudulent articles %already 
exist, they are often proprietary and controlled by commercial entities that are reluctant to share their technologies~\cite{christopher2021raw}.
Even though some LLM-based applications have been developed to address news misinformation~\cite{cao2024can} and plagiarism~\cite{wahle2022large}, there is a need for open-source LLMs specifically tailored to scientific fraud detection.
Such models would enhance transparency and foster collaboration in the fight against scientific fraud.

Note that the development of open-source tools alone is not sufficient; effective fraud detection systems must also be transparent and interpretable. The necessity for systems to provide explanations for their outputs in tasks such as fact-checking~\cite{kotonya2020explainable} and misinformation detection~\cite{explain-misinformation} is well-acknowledged. 
While previous research has explored incorporating explainable AI to explain decision-making processes~\cite{explainLLMs, kotonya2024towards}, the study of explainability in fraud detection systems remains limited.



%\todo[inline]{should we add also relations to debate-based frameworks?}
\begin{table*}[htbp] 
        \centering
        \small
	\setlength{\tabcolsep}{1.8mm}{
		\begin{threeparttable} 
			\begin{tabular}{c|ccc|cccc}  
				\toprule 
                    &\multicolumn{3}{c|}{General}&\multicolumn{4}{c}{Cancer}\cr
                    Dataset &\textbf{\underline{\texttt{Train}}}&\textbf{\underline{\texttt{Validation}}}& \textbf{\underline{\texttt{Test}}}  &\textbf{\underline{\texttt{Breast}}} &\textbf{\underline{\texttt{Lung}}}
                    &\textbf{\underline{\texttt{Ovarian}}}
                    &\textbf{\underline{\texttt{Colorectal}}}\cr
				\midrule
                    Sample &10,000&500&500&300&300&292&300\cr
                    %Retraction 
                    Fraudulence Rate & 24.5\% & 25.6\% & 22.4\%& 25.0\%& 38.7\%& 38.0\%&33.0\%\cr
                    High Profile Rate & 34.0\%&  35.9\% &  33.9\%& 38.7\%& 22.4\%& 29.7\%&28.3\%\cr
				\bottomrule
			\end{tabular}
			\caption{Basic statistics of  \emph{Pubmed Retraction}.
            High Profile Rate refers to the articles deemed fraudulent despite their meta-data being ranked high (details in Appendix~\ref{sec:app_benchmark}). 	\label{tab:stat_pubmed_retraction}}
		\end{threeparttable}
	}
	%\end{minipage}%
 \vspace{-10pt}
\end{table*}

\section{\emph{PubMed Retraction} Benchmark% Construction
} 
\label{sec:bench}
%\todo{Are explanations part of benchmark or not?} NO
To address the lack of a standardized benchmark for evaluating and comparing fraudulent article detection methods, we curate a large open-source benchmark for biomedical articles, \emph{PubMed Retraction}, comprising %nearly 12K\todo{over 11K? we should consistently use one or the other} 
over 11K real-world biomedical articles, including both legitimate and retracted publications. We select the biomedical domain %is selected 
due to the higher prevalence of fraudulent publications therein %, which is more pronounced 
%in this domain 
than in other fields
~\cite{grieneisen2012comprehensive, bik2016prevalence}, as well as the significant %downstream 
impact of this type of fraud in patient safety, clinical decision-making, and public trust in medical research. 
% To this end, we introduce \emph{PubMed Retraction}, a benchmark dataset comprising nearly 12K biomedical articles, including both legitimate and retracted publications.


To construct \emph{PubMed Retraction}, we use the PubMed database~\cite{wheeler2007database} and retrieve articles using the Unix command-line tool EDirect~\cite{kans2024entrez}. To ensure relevance and avoid outdated data, we focus on articles published between 2000 and 2025. Our goal is to promote the use of minimal textual information for fraud detection, so we design the %dataset 
benchmark to include only %the 
title, abstract, and metadata while excluding more complex features such as full text and images% \FT{in the articles}
. Specifically, each article in \emph{PubMed Retraction} is structured to include seven key attributes: 
\textit{Pubmed ID, Title, Abstract, Authors, Affiliations, Journal, Is
Fraudulent},
with the latter a binary indicator (Yes or No). 
An article is labeled as %retracted 
\textit{fraudulent} if the keyword ``retracted'' appears in its publication type attribute. 
 Note that while retracted articles are not always explicitly fraudulent, they often contain errors, misconduct or unreliable findings~\cite{grieneisen2012comprehensive}, indicating potential fraud that 
%would need 
needs 
to be surfaced by fraudulent article detection.
To maintain a realistic distribution, we include a lower number of fraudulent articles than legitimate
ones, which is aligned with real-world cases. %As a result, the final dataset 
Overall, the benchmark consists of 11,192 articles.
 
To evaluate generalization capabilities of models, we partition articles based on keywords to create two subsets as described below. This partitioning strategy is designed for a fair assessment of a model’s ability to handle out-of-distribution samples, a critical aspect for real-world applications where models encounter unseen data.
(1) \emph{General Set}. This set comprises articles covering various diseases and is used for model fine-tuning. It is further split into Train, Validation, and Test subsets. (2) \emph{Cancer Set}. This set consists exclusively of articles related to four types of cancer: Breast, Lung, Ovarian, and Colorectal. Articles of these four categories are %entirely 
excluded from the General Set, which means that %they
these cancers %remain as 
are unseen diseases during fine-tuning and validation. 
Additionally, our benchmark includes high-profile fraudulent cases, which makes this task particularly challenging (details in Appendix~\ref{sec:app_benchmark}).


Formally, %the dataset
ignoring the partitions, \emph{PubMed Retraction}
can be represented by $\mathcal{D} = \{(x_i, y_i)\}_{i=1}^{N}$, where each $x_i$ is an article (title, abstract and metadata) and $y_i$ is the binary label% to indicate the legitimacy
.
The basic statistics of \emph{Pubmed Retraction} %\FT{and its partitions} 
are given in Table~\ref{tab:stat_pubmed_retraction}.



\section{\texttt{Pub-Guard-LLM}}
\label{sec:pubguardLLM}
%After constructing the benchmark, \emph{PubMed Retraction}, we introduce an 
\texttt{Pub-Guard-LLM} is an end-to-end %framework 
system for fraudulent article detection. Figure~\ref{fig:framework} provides an overview: First,
the input data is enriched %by augmenting 
with external knowledge. Second, explanations to support article labels (\textit{fraudulent} or \textit{not}) are obtained by distilling a strong LLM (\textit{Teacher Model}) via zero-shot prompting. Finally,  using the %extracted 
article attributes and external knowledge as inputs, and distilled explanations with article labels as outputs, we fine-tune an LLM to create \texttt{Pub-Guard-LLM}.  We propose three application modes for \texttt{Pub-Guard-LLM}, resulting in different performances as concerns F1, %precision, 
recall, reliability of explanations, and inference speed.%, as we discuss next %(See Appendix~\ref{app:expl} for input-output examples for each mode). 

\subsection{External Knowledge Workflow}\label{sec:external_knowledge}


To complement the seven %existing 
input attributes (see Section~\ref{sec:bench}) and incorporate task-specific knowledge, we augment external knowledge into 
%the workflow
\texttt{Pub-Guard-LLM}, improving LLM reasoning—a widely adopted strategy in %the
NLP% field
~\cite{pan2024unifying}. For this, we identify three  fundamental factors to assess an article's legitimacy: (1) author credibility, (2) affiliation reputation, and (3) journal reputation, and use the relevant external knowledge to enrich the  %the input data 
input.


\paragraph{Author Credibility.} In order to evaluate the credibility of authors,
we use the Semantic Scholar database~\cite{lo2019s2orc}, which contains millions of articles with extensive metadata and citation information%,
, as an external knowledge source. To quantify author reputation, we use the h-index% as an indicator
. Since LLMs are not inherently sensitive to numerical values, we map h-index scores into five reputation levels
(\textit{very low, low, medium, high, very high} )
using a predefined piecewise function (see Appendix~\ref{sec:app_benchmark}), 
e.g., 
 \textit{Geoffrey Hinton (author h-index: 188, %Leading Expert
 very high)}.

\paragraph{Affiliation Reputation.}  As an indicator of the reputation of an author's affiliation, we use the average citation count per institution% is utilized
, determined with %For this, 
OpenAlex~\cite{priem2022openalex} as external knowledge source. This is a fully open index of scholarly works, which provides comprehensive data on the total publications and citations of institutions%, is used as an external knowledge source
. The calculated average citation count is then mapped into five reputation levels (\textit{very low, low, medium, high, very high}), e.g., \textit{Harvard University (institution average citation: 64,
very high).} 

\paragraph{Journal Reputation.} We use the ImpactFactor library\footnote{\url{%https://
impact-factor.readthedocs.io/en/latest/}} to obtain the Journal Citation Reports (JCR) partition, which serves as an indicator of a journal’s reputation. To enhance interpretability, we assign a human-readable categorized label (\textit{low, medium, high} or \textit{very high}) to each journal based on its JCR ranking, e.g., \textit{Nature (journal JCR: Q1, 
%Top Level Journal
very high).}

The knowledge retrieved from external resources is integrated into the 
benchmark $\mathcal{D}$ for reducing duplicated queries, 
formally resulting in
$\mathcal{D}' = \{(x_i, k_i, y_i)\}_{i=1}^{N}$ where $k_i$ is the external information for
$(x_i,y_i)\in \mathcal{D}$. 
Note that if the inquired knowledge is missing from the external knowledge sources, we use, as $k_i$, the keyword \textit{``null''} to indicate the absence. We choose to %include the ``null" keyword in our pipeline, 
do so rather than omitting the field entirely, as we found it does generally indicate a lower article quality and improves the downstream performance.

\subsection{%Knowledge 
Explanation Distillation}

%After augmenting the input, the next step focuses on refining the output to achieve interpretability and improved performance in the model that will be trained on the enhanced input-output pairs. 

The %constructed 
\emph{PubMed Retraction} benchmark %in its initial form 
provides only a binary label (\textit{%retracted
fraudulent} or \textit{not}% %\textit{%legitimate
%not Fraudulent}
) as a target. To construct a model that classifies articles accurately while offering reliable explanations, it is essential to incorporate either human-annotated or machine-generated explanations into the ground truth. Given the high cost of human annotation, we opt for %machine-generated explanations 
the latter
as a more scalable and efficient alternative.

Recent research shows that distilling reasoning capabilities from larger (language) models can significantly enhance the performance of smaller models with fewer learning examples~\cite{li2022explanations, hsieh2023distilling, shridhar2023distilling}: teacher model rationales provide richer insights into why an input is mapped to a specific output label, capturing task-relevant knowledge missing from the %original 
input. 
%To leverage this, we 
We use a teacher model to generate explanations for each article via prompting, resulting in
$\mathcal{D}''=\{(x_i, k_i,e_i, y_i)\}_{i=1}^{N}$ where $e_i$ is the corresponding distilled explanations with regard to $(x_i, k_i, y_i)\in \mathcal{D}'$. 
\iffalse This additional distilled knowledge is then %added to the output, which originally consists only of a binary label, to be 
used in the %training 
\FT{fine-tuning} of 
%our 
a smaller model
to obtain \texttt{Pub-Guard-LLM}.
\fi

%We observe 
Note that instruction-aligned LLMs tend to classify all articles as \textit{not fraudulent}, likely to avoid controversial responses. 
This behavior arises because many LLMs, when fine-tuned for alignment and safety, may become overly conservative and ignore contextually relevant information~\cite{rottger2024xstest}. 
To mitigate this issue, it is crucial to assign a clear stance to the teacher model. For example, when evaluating a retracted article, we include the prompt: \textit{``You are tasked with providing explanations and making a firm case for why it has issues and should be retracted. You should have a clear stance.''}. This ensures strong, rationale-driven explanations instead of the default neutral or overly cautious responses (see Table~\ref{tab:prompt_explanation} in Appendix for an example prompt).


\subsection{Fine-Tuning}
We leverage the samples in \emph{PubMed Retraction} %and 
augmented with the external information and distilled explanations ($\mathcal{D}''$) to fine-tune \texttt{Pub-Guard-LLM}.
\iffalse
Formally, %the dataset
\FT{\emph{PubMed Retraction}}
can be represented as $\mathcal{D} = \{(x_i, y_i)\}_{i=1}^{N}$, where each $x_i$ is an article (title, abstract and metadata) and $y_i$ is the binary label% to indicate the legitimacy
.
Through the workflow of accessing external knowledge, we %can  add this knowledge into each article
\FT{obtain}  $(x_i, k_i, y_i)$, where $k_i$ is the external information \FT{(e.g. drawn from} %such as 
the h-index of authors% and JCR ranking of the journal
\FT{, as discussed earlier)}.
%Since binary label learning is not sufficient, 
We \FT{then} integrate explanations from \FT{the} teacher model %into this learning process and then the input can be denoted as
\FT{to obtain augmented samples} $(x_i, k_i, e_i, y_i)$, where $e_i$ is the corresponding generated explanations with regard to $(x_i, k_i, y_i)$.
We apply a curated template to each input for querying the model, but omit its notation here for legibility.\todo{I would drop this last sentence - if anything it should go in the previous section}
\fi 
%
To encourage \texttt{Pub-Guard-LLM} to learn both labels and explanations, we introduce a multi-task learning objective. Suppose we have a base model $f_{\theta}$ %, which is
 able to generate label $y$ and explanation $e$ given article $x$ with external information $k$ , i.e., $f_{\theta}(x, k) = (y, e)$. Then, %and
our goal is to optimize $\theta$ for this task.

The model is 
fine-tuned on $y$ to understand how to identify fraudulent articles via a binary classification task  with%loss the \todo{averaged?} cross entropy between the ground truth and predicted label
:
\begin{equation}
    \mathcal{L}_{\text{cls}} = \frac{1}{N} \sum_{i=1}^{N} \ell \big(f_{\theta}(x_i, k_i), y_i \big)
\end{equation}
where %$\mathcal{L}$
$\ell$ is the cross entropy between the ground truth and the predicted label. To encourage the model to output explanations behind the decision, we introduce a next-token prediction task with% loss the averaged cross entropy between the generated tokens and the distilled explanation from the teacher model
:
\begin{equation}
    \mathcal{L}_{\text{explanation}} = \frac{1}{N} \sum_{i=1}^{N} \ell \big(f_{\theta}(x_i, k_i), e_i \big)
\end{equation}
where %$\mathcal{L}$  
$\ell$ is the averaged cross entropy between the generated tokens and the distilled explanation from %a
the teacher model.

During fine-tuning, %we make 
the model learns to predict both label $y$ %with
and explanation $e$ given an article:
\begin{equation}\label{eq:multi_task}
    \mathcal{L} = \mathcal{L}_{\text{cls}} +\lambda\mathcal{L}_{\text{explanation}}
\end{equation}
where $\lambda$ is a hyper-parameter that controls the balance between the two objectives. 
This learning process helps \texttt{Pub-Guard-LLM} acquire knowledge beyond simple binary labels, which results in strong performance with well-reasoned explanations.

\begin{figure}
    \centering
    
    \includegraphics[width=0.48\textwidth]{figures/debate_pub_guard_llm.pdf}
    \caption{Debate application mode for \texttt{Pub-Guard-LLM} }
    \label{fig:debate_framework}
\end{figure}

\subsection{Application Modes}
After fine-tuning, the model $f_\theta$ can be leveraged to identify fraudulent articles while providing explanations. To showcase its usability% applicability
, we introduce three distinct %usage 
application modes %\FT{, for augmented inputs $(x,k)$} 
(see Appendix~\ref{app:expl} for input-output examples for each mode).



\paragraph{Vanilla Reasoning.} 
This refers to %a model's ability to perform 
 reasoning without requiring additional in-context learning samples (\textit{Zero-Shot Reasoning}),  which makes predictions solely based on the article: $f_{\theta}(x, k)$.

\paragraph{Retrieval-Augmented Generation (RAG).}  %LLMs cannot
$f_{\theta}(x, k)$ does not store all articles within %their
its parameters, and, in some cases, an input article’s main argument may lack support from existing publications. This suggests that the article's findings could be controversial and potentially fraudulent. To address this, we retrieve relevant top-$l$ articles $\mathcal{A}$ (\textit{all legitimate}) to the input article $x$ from PubMed and use them to validate the claims made in $x$
by passing them as input into the model: $f_{\theta}(x, k, \mathcal{A})$ (see details in Appendix~\ref{sec:app_rag}).




\paragraph{Debate.} Recent research has shown that Multi-Agent Debate can enhance both factual accuracy and explainability in LLMs~\cite{liang2023encouraging, duimproving, freedman2024argumentative}. The core idea involves multiple agents presenting their arguments, while a judge oversees %the debate process 
to reach a final decision. 

%
To generate the debate process in our setting (Figure~\ref{fig:debate_framework}), we train two specialized \texttt{Pub-Guard-LLM}s:
(1) a support reviewer $f_{\theta}^{s%upport
}$, trained on legitimate articles, generates supporting arguments $arg^{+}$;
(2) an attack reviewer $f_{\theta}^{a%ttack
}$, trained on retracted articles, generates attacking arguments $arg^{-}$.
Thus, given input article $(x, k)$, the support reviewer $f_{\theta}^{s%upport
}$ consistently provides arguments in favor of the article while the attack reviewer $f_{\theta}^{a%ttack
}$ presents counterarguments highlighting potential issues.
Following this debate,  we introduce a meta-reviewer $f_{\theta}^{meta}$ that is responsible for making the final decision based on the arguments presented by both reviewers.
To train the meta-reviewer, we use a teacher model to generate debate-based explanations $\hat{e}$, which are then used to fine-tune $f_{\theta}^{meta}$ by reusing the multi-task learning in Equation~\ref{eq:multi_task}. %Finally, 
Overall, the debate-based detection framework is formulated as: $f_{\theta}^{meta}(x, k, arg^{+}, arg^{-})$, where the meta-reviewer makes a decision by considering both the supporting and attacking arguments.


\begin{table*}[tb] 
	\centering
        \scriptsize
	\setlength{\tabcolsep}{3.5mm}{
		\begin{threeparttable} 
			\begin{tabular}{cc|c|cccc|c}
                \toprule
                    %&&\multicolumn{1}{c|}{\textbf{\underline{\texttt{General Set}}}}&\multicolumn{4}{c|}{\textbf{\underline{\texttt{Cancer Set}}}}&\cr
                    Model& $|\theta|$ &\texttt{Test}&\texttt{Breast}& \texttt{Lung} &\texttt{Ovarian} & \texttt{Colorectal} &Avg\cr
				\midrule
                    \multicolumn{7}{c}{\textit{Fine-Tuning Binary Classifiers}}\cr
                    \midrule
                    SciBERT  &110M&60.9&56.1&74.0&67.2&71.5&66.0\cr
                    BioLinkBERT  &340M&58.1&57.7&75.4&71.0&72.2&66.9\cr
                    Gatortron  &345M&57.6&58.6&71.2&70.9&67.0&65.1\cr
                    Llama-3.1  &8B&60.9&63.2&76.5&72.3&68.3&68.2\cr
                    Bio-Llama  &8B&56.4&61.7&63.9&66.7&61.6&62.1\cr
                    BioLinkBERT + PEARL  &210M&67.6&69.6&79.0&70.5&69.8&71.3\cr
                    Gatortron + PEARL &445M&66.3&69.3&78.3&76.2&70.8&72.2\cr
                     \midrule
                    \multicolumn{7}{c}{\textit{Few-Shot Reasoning}}\cr
                    \midrule
                    Llama-3.1-Instruct  &8B&29.8&20.0&46.2&43.3&43.6&36.6\cr
                    OpenScholar  &8B&11.5&18.8&20.3&19.9&14.1&16.9\cr
                    Bio-Llama  &8B&37.7&40.7&56.7&59.3&47.9&48.5\cr
                    PMC-Llama  &13B&36.0&36.4&56.7&23.3&25.8&35.6\cr
                    % Mistral  &7B&0.0&0.0&0.0&0.0&0.0&0.0\cr
                    % Mistral-Large  &123B&0.0&0.0&0.0&0.0&0.0&0.0\cr
                    % GPT-4o  &-&0.0&0.0&0.0&0.0&0.0&0.0\cr
                    \midrule
                    \multicolumn{7}{c}{\textit{Ours}}\cr
                    \midrule
                    Pub-Guard-LLM (\textit{Vanilla})
                     &8B &\textbf{70.7}&72.8&79.2&78.3&75.6&75.3\cr
                    Pub-Guard-LLM (\textit{RAG}) &8B &69.8&\textbf{76.1}&\textbf{82.3}&\textbf{79.5}&\textbf{76.4}&\textbf{76.8}\cr
                    Pub-Guard-LLM (\textit{Debate}) &8B &70.1&71.5&81.1&78.0&75.7&75.3\cr
				\bottomrule
			\end{tabular}
			\caption{Performance %Comparisons of different models 
            in detecting fraudulent articles. We report %the
            average F1 scores over three seeds.} \label{tab:overall}
		\end{threeparttable}
	}
	%\end{minipage}%
	\vspace{-10pt}
\end{table*}



\begin{table}[!htbp] 
	\centering
        \scriptsize
	\setlength{\tabcolsep}{1.8mm}{
		\begin{threeparttable} 
			\begin{tabular}{ccccccc}  
				\toprule 
                     & \textbf{\underline{\texttt{Test}}}  &\textbf{\underline{\texttt{Breast}}} &\textbf{\underline{\texttt{Lung}}}       &\textbf{\underline{\texttt{Ovarian}}}&\textbf{\underline{\texttt{Colorectal}}}&\textbf{\underline{\texttt{Avg}}}\cr
				\midrule
                    Vanilla &84.8&88.5&89.2&85.9&69.7&83.6\cr
                    RAG & 66.9& 82.7& 87.9 & 85.6&\textbf{81.8}&81.0\cr
                    Debate & \textbf{90.7} & \textbf{92.2} & \textbf{94.6}& \textbf{89.9}& 75.9&\textbf{88.7} \cr
				\bottomrule
			\end{tabular}
			\caption{%Comparisons of 
            Recall (average over 3 seeds)  across %three
            modes } 	\label{tab:recall}
		\end{threeparttable}
	}
	%\end{minipage}%
 \vspace{-10pt}
\end{table}

\section{Experimental Set-Up}

\subsection{Baselines}
We compare our approach to the following% baselines
:

(1) \emph{Fine-tuning Binary Classifiers}. This method appends a classification head—a linear layer—on top of a language model
 to handle fraud detection% tasks
.  However, this method can only output binary labels (no explanations). The title, abstract, and metadata are concatenated using a special token, [SEP], and this combined textual input is fed into the classifier.  %The following language models are used  for comparison
Specifically, we use language models: SciBERT~\cite{beltagy2019scibert}, BioLinkBERT~\cite{yasunaga2022linkbert}, Gatortron~\cite{yang2022gatortron}, Llama-3.1~\cite{dubey2024llama} and Bio-Llama~\cite{ContactDoctor_Bio-Medical-Llama-3-8B}.
%
We also find that introducing additional models to represent metadata separately can be beneficial. Thus, we apply a lightweight short-text model, PEARL~\cite{chen2024learning}, to represent metadata and obtain embeddings for authors, affiliations, and journal. We continue to use the original language model to represent the title and abstract. Subsequently, these embeddings are concatenated and fed into the classification head. We denote %this
the resulting variant of language model \textit{X}  as \textit{``X + PEARL''}.

(2) \emph{Few-shot Reasoning}. LLMs are generally known as few-shot reasoners, meaning they can perform powerful reasoning with few learning examples~\cite{brown2020language, kojima2022large}. 
Compared to binary classifiers, LLMs can offer answers with explanations.
We provide LLMs with a certain number of learning examples and prompt %it 
them to obtain binary answers with explanations. Here, we use the following instruction-aligned LLMs:
Llama-3.1-Instruct~\cite{dubey2024llama}, OpenScholar~\cite{asai2024openscholar}, Bio-Llama~\cite{ContactDoctor_Bio-Medical-Llama-3-8B} and PMC-Llama~\cite{wu2024pmc}.

\subsection{Implementation Details}
All approaches are implemented with PyTorch \cite{paszke2019pytorch} and HuggingFace~\cite{wolf2020transformers}. 
We use Amazon EC2 \textit{g5.12xlarge} instances with 4$\times$24 GiB for all experiments.
The Teacher model used for distilling explanations is Mistral-Large~\cite{mistral_large_2024} on Amazon Bedrock. Our model fine-tunes Llama-3.1-8B~\cite{dubey2024llama} using LoRA~\cite{hulora} adapters (r=128, lora\_alpha=128, lora\_dropout=0.1). We train on the train set in the \textit{General} partition for one epoch and AdamW 8-bit optimizer with a learning rate of 1e-4, batch size 4, gradient accumulation of 4 and the $\lambda$ is 1.  

All baseline binary classifiers are fine-tuned %using 
with three different seeds: we report their performance based on the best validation set score.
For few-shot reasoning, we set the sample size to zero (\textit{zero-shot reasoning}) since adding contextual examples provides only minimal benefits (1–2 percentage points).




\section{Results}

% We evaluate overall performance (Section~\ref{sec:overall}) by reporting F1 scores and recall
% using fraudulent articles as the target class.
% We also evaluate the reliability of explanations for our system and baselines that produce explanations(Section~\ref{sec:expl}).
% Further, we assess the impact of %credibility 
% high-levels of the metadata (Section~\ref{sec:credibility}). Finally, we describe a small user study with medics as candidate users of our system to  explore take-up of explanations (Section~\ref{sec:user}).
% Lihu: comment the above to save space 

\subsection{Overall Performance}
\label{sec:overall}
Table~\ref{tab:overall} gives the results of the comparison of %compare 
\texttt{Pub-Guard-LLM} with %various 
the baselines%, and present the results  in Table~\ref{tab:overall}
.

First, we note that \texttt{Pub-Guard-LLM}, across all three modes, consistently outperforms the baselines%, which demonstrates the effectiveness of our proposed methodology
.
The performances %of 
across the three mode%l
s do not exhibit significant differences, but the RAG mode achieves the best score on average, which shows that introducing relevant articles is beneficial to verify the claim quality in abstracts. 
On the other hand, a key advantage of the debate mode is its notably higher recall, as shown in Table~\ref{tab:recall}. Achieving high recall is crucial in the fraud detection task, as %our
its primary goal is to flag suspected fraud and provide warnings to end-users.

Second, BERT-based models prove to be cost-effective while achieving competitive performance comparable to larger counterparts in domain-specific tasks, which aligns with prior findings~\cite{lehman2023we, chen2024role}. For instance, \textit{Gatortron + PEARL} ranks second overall%, attaining an average F1 score of 72.2 IN THE TABLE ALREADY - WASTED SPACE
.
Additionally, leveraging top-layer representations of decoder-only models to train classifiers appears suboptimal, %which 
as it does not perform better than BERT-based models.
Existing LLMs struggle in the few-shot setting, suggesting that domain adaptation is necessary for this task.
\emph{Note that we do not report the performance of GPT-4o and Mistral-Large because these large instruction-aligned models frequently classify all articles as legitimate to avoid controversial conclusions.}  

In summary, all three modes of \texttt{Pub-Guard-LLM} effectively detect fraudulent articles and each offers distinct advantages. The %Naive model 
Vanilla Reasoning mode is efficient and user-friendly, the RAG %model
mode achieves the best overall performance, and the Debate %model 
mode excels in recall. %Users can make trade-offs based on their needs.
This variability makes %the system 
\texttt{Pub-Guard-LLM} highly versatile, accommodating a wide range of possible user needs in fraudulent article detection.
Additionally, we conduct an ablation study to validate the effect of each component in our system, such as \textit{base LLM}, \textit{Teacher Model}, \textit{External Knowledge}%, etc
. The results are %shown 
in Table~\ref{tab:ablation} in the Appendix.

\begin{figure}[!htbp]
    \centering
    \includegraphics[width=0.48\textwidth]{figures/eval_explanation.pdf}
    \caption{Explanation
    % evaluations 
    reliability using 
   LLM-as-a-Judge (average over three runs)}
    \label{fig:eval_explanation}
\end{figure}

\begin{figure*}[t]%
	\centering
	\subfloat[\centering Author Credibility\label{fig:author_impact}]{{\includegraphics[width=0.33\textwidth]{figures/author_impact.pdf} }}%
	%\qquad
	\subfloat[\centering Affiliation Reputation \label{fig:affiliation_impact}]{{\includegraphics[width=0.33\textwidth]{figures/affiliation_impact.pdf} }}%
    \subfloat[\centering Journal Reputation]{{\includegraphics[width=0.33\textwidth]{figures/journal_impact.pdf} }}%
	\caption{Performance on the combined test sets (test plus cancer) of
    \texttt{Pub-Guard-LLM} (Vanilla) depending on the %credibility level of 
    metadata levels. The horizontal line in each figure represents the F1 score achieved using corresponding heuristic features
    %, e.g., using %high-profile 
    %authors with very high credibility as an indicator of %legitimacy
    %non-fraudulence 
    (see details in Appendix~\ref{sec:heuristics}).}
	\label{fig:impact_reputation}%
 \vspace{-10pt}
\end{figure*}

\begin{figure}[!htbp]
    \centering
    \includegraphics[width=0.48\textwidth]{figures/user_study.pdf}
    \caption{Comparison of explanation reliability and label-explanation agreement in the user study (see details in Appendix~\ref{sec:app_user_study}).}
    \label{fig:user_study}
\end{figure}

\subsection{Explanation %Evaluation
Reliability}
\label{sec:expl}
Compared to BERT-based models, a distinct benefit of \texttt{Pub-Guard-LLM} is the %reliable 
explanations. 
To evaluate the reliability of LLM-generated explanations, we consider two dimensions introduced, for different settings, in prior work~\cite{kotonya2020explainable,kotonya2024towards, valentino2024introductory}.
(1) \emph{Relevance}. A relevant explanation should highlight the particular features and patterns within the article that the model identified as indicative of fraud or not. The model should only reference information that is present in the article, avoiding hallucinations. (2) \emph{Coherence}. 
%A coherent explanation 
This refers to the logical consistency and clarity of the explanation provided by the model for its predictions. Coherence ensures that the explanation flows logically, %and the narrative is easy to follow, 
thereby enhancing the user's understanding of why an article is classified as fraudulent or not. 
To measure these properties, we adopt the LLM-as-a-Judge paradigm, which has been shown to align with both controlled and crowdsourced human preferences when using strong LLM judges like GPT-4 ~\cite{zheng2023judging}.
%To evaluate explanation quality, 
We design prompts (see Appendices \ref{tab:relevance_prompt} and 
\ref{tab:coherence_prompt}) for these two dimensions and ask GPT-4o to assess the provided explanations, which assigns a score between 1 and 10. 
%To mitigate randomness, we conduct three evaluation rounds for each explanation and report the average score. 
The results, presented in Figure~\ref{fig:eval_explanation}, show that our explanations outperform those of other LLMs, with the exception of OpenScholar.
While OpenScholar demonstrates strong explanation quality, its fraud detection capability is significantly lower than other LLMs, with an average F1 score of just 16.9 (see Table~\ref{tab:overall}).
%Additionally, 
Also, note that the debate mode can reduce %hallucinated
irrelevant explanations by achieving higher relevance scores than the another two modes.
These findings validate that \texttt{Pub-Guard-LLM} not only achieves powerful performance but also provides reliable explanations.


\subsection{%Assessing the Impact of Metadata Credibility
Impact of  Metadata Levels}
\label{sec:credibility}
We explore whether the
external knowledge we use to assess 
levels of the metadata can provide useful heuristics for fraud detection. 
To test this, we compare \texttt{Pub-Guard-LLM} (Vanilla) to heuristic methods, e.g., using the credibility of authors %or institutions 
as indicators (see Appendix \ref{sec:heuristics}).
The results are shown in Figure~\ref{fig:impact_reputation}.
First, we observe that relying solely on heuristic features is insufficient for fraud detection since \texttt{Pub-Guard-LLM} significantly outperforms heuristics on average. 
Second, prestigious researchers, institutions and journals should not be blindly trusted, and these high-profile frauds are harder to detect, as shown by the performance declines on \textit{high} and \textit{very high} groups in Figure~\ref{fig:author_impact} and Figure~\ref{fig:affiliation_impact}. 
Additionally, \textit{null} is an indicator of low-level credibility and \texttt{Pub-Guard-LLM} is robust against missing information.
In summary, high-profile cases pose a significant challenge to fraud detection.
In the future, we plan %it is necessary 
to investigate features beyond metadata such as images. %and full texts for future studies
%\FT{to help address this issue}.


\subsection{User Study}
\label{sec:user}
We conducted a pilot user study to evaluate whether the outputs of \texttt{Pub-Guard-LLM} align with users' needs. To achieve this, we designed questionnaires covering our three application modes and gathered feedback from three experienced doctors (see details in Appendix~\ref{sec:app_user_study}).
The questionnaire focused on two key aspects: (1) \textit{Reliability:} is the explanation coherent and relevant?  (2) \textit{Agreement:} do users %you
agree with the predicted label and the explanation?
Figure~\ref{fig:user_study} presents the user study results. The feedback suggests that doctors find our model’s explanations reliable, but there is a discrepancy between expert opinions and machine-generated predictions regarding the debate mode. However, due to the limited number of participants, it is difficult to determine which application mode performs better.


\section{Conclusion}
In this work, we contribute to fraudulent academic articles by introducing a publicly available benchmark and the first open-source LLM-based system tailored for this task. Our \texttt{Pub-Guard-LLM} not only surpasses existing baselines but also delivers reliable, well-grounded explanations. We aim to raise awareness of academic fraud within the research community and drive further advancements to tackle this growing issue.

We emphasize the need for broader efforts to combat academic fraud in the following key areas. %Moreover, we highlight efforts to mitigate academic fraud in the following areas.
First, high-profile publications should not be blindly trusted, as fraudulent publications may still exist within them. 
Detecting such cases requires more than analyzing metadata and abstracts, and  
future studies should also investigate full texts and images to identify frauds.
Second, as we develop technological solutions to detect fraud, entities like paper mills continuously improve their methods to circumvent detection. This ongoing arms race requires continuous adaptation of detection techniques.
Finally, addressing scientific fraud fundamentally depends on human and societal factors. Researchers should adhere to scientific integrity, and our academic evaluation system should prioritize genuine value creation over mere quantitative metrics.


\section*{Limitations}
While our study makes contributions to fraudulent article detection, we acknowledge two primary limitations:
(1) Catastrophic forgetting. 
\texttt{Pub-Guard-LLM} is a task-specific model that may not perform well in general-purpose reasoning due to catastrophic forgetting~\cite{mccloskey1989catastrophic}—a phenomenon where a neural model loses previously acquired knowledge upon learning new information.
(2) Limited participants in user study.
Our user study involved a small number of participants, which limits the ability to systematically compare the three application modes. A more comprehensive study with a larger participant pool is necessary for thorough evaluation.


% Bibliography entries for the entire Anthology, followed by custom entries
%\bibliography{anthology,custom}
% Custom bibliography entries only
\bibliography{custom}



\clearpage
\newpage
\appendix
\setcounter{table}{0}   
\setcounter{figure}{0}
\renewcommand{\thetable}{A\arabic{table}}
\renewcommand{\thefigure}{A\arabic{figure}}
\setcounter{equation}{0}
\setcounter{subsection}{0}
\renewcommand{\theequation}{A.\arabic{equation}}


\section{Details of Benchmark and External Knowledge}
\label{sec:app_benchmark}
\paragraph{Author Credibility}
To categorize authors based on their reputation, we define a piecewise function that maps h-index values into discrete reputation levels. This approach ensures that LLMs can interpret author credibility effectively by using textual labels instead of raw numerical values. The categorization is as follows:
\begin{itemize}
    \item Emerging Researcher (very low): \( 0 \leq h\text{-index} \leq 5 \)
    \item Early Career Researcher (low): \( 6 \leq h\text{-index} \leq 15 \)
    \item Established Researcher (medium): \( 16 \leq h\text{-index} \leq 30 \)
    \item Influential Researcher (high): \( 31 \leq h\text{-index} \leq 45 \)
    \item Leading Expert (very high): \( h\text{-index} > 45 \)
\end{itemize}

\paragraph{Affiliation Reputation}
To assess the reputation of an author's affiliation, we use the average citation count per institution, which serves as a key indicator of an institution’s scholarly influence. Likewise, we map these values into five distinct reputation levels:
\begin{itemize}
    \item Developing Institution (very low): \( 0 \leq \) average citations \( \leq 5 \)
    \item Emerging Institution (low): \( 6 \leq \) average citations \( \leq 15 \)
    \item Established Institution (medium): \( 16 \leq \) average citations \( \leq 30 \)
    \item Reputable Institution (high): \( 31 \leq \) average citations \( \leq 45 \)
    \item World-Class Institution (very high): \( \) average citations \( > 45 \)
\end{itemize}


\paragraph{Journal Reputation}
To assess the reputation of a journal, we use the JCR, which classifies journals into four quartiles based on their impact factor. To enhance interpretability, we map JCR quartiles into human-readable reputation levels:
\begin{itemize}
    \item Top-Level Journal (very high): JCR Q1
    \item High-Level Journal (high): JCR Q2
    \item Moderate-Level Journal (medium): JCR Q3
    \item Low-Level Journal (low): JCR Q4
\end{itemize}

\paragraph{Definition of High Profile}
We define an article as high-profile if its metadata includes at least one leading expert (very high) author, or one world-class (very high) affiliation, or is published in a top-level (very high) journal. This definition aligns with our intuition, as articles produced by renowned researchers, prestigious institutions, or highly reputable venues are generally perceived as more trustworthy. We compute the high profile rate of fraud in each subset by: $| \textit{High Profile Articles}| / | \textit{Fraudulent Articles}|$. These high-profile cases are hard to detect, which makes the task particularly challenging.

\paragraph{Missing Rate}
In our analysis of the PubMed Retraction dataset, we observed that certain external information may be absent from specific databases. For instance, a journal might not be indexed by the JCR.
To quantify this, we computed the missing rates for each feature within our dataset:
\begin{itemize}
    \item Author Credibility: 10.6\% missing
    \item Affiliation Reputation: 33.4\% missing
    \item Journal Reputation: Journal Indexing: 41.5\% missing
\end{itemize}

\section{Details of \texttt{Pub-Guard-LLM}}
\subsection{Prompts}\label{sec:app_prompt}
Here, we list the prompts used in this work: (1) Explanation Distillation, Table~\ref{tab:prompt_explanation}; 
(2) Prompt of Detecting Fraudulent Articles, Table~\ref{tab:query_prompt}; (3) Prompt of Relevance Evaluation, Table~\ref{tab:relevance_prompt};
(4) Prompt of Relevance Coherence, Table~\ref{tab:coherence_prompt}.


\subsection{RAG Mode}\label{sec:app_rag}
We retrieve relevant top-$l$ articles $\mathcal{A}$ (\textit{all legitimate}) to the input article $x$ from PubMed and use them to validate the claims made in $x$.
In our experiment, the value $l$ is 5 and the PubMed database is MedRAG PubMed\footnote{\url{https://huggingface.co/NeuML/pubmedbert-base-embeddings}} with 3.5M articles. The retriever here is PubMedBERT and we use cosine similarity to compute the semantic relatedness.

\subsection{Output Examples}\label{app:expl}
We provide an input-output example for each application mode:
Vanilla Reasoning (Table~\ref{tab:example_vanilla}); RAG (Table~\ref{tab:example_rag}); Debate (Table~\ref{tab:example_debate}).

\section{Details of Experiments}
%\subsection{Baselines}
\subsection{Heuristic Features}\label{sec:heuristics}
Since we incorporate external knowledge to represent metadata levels, these fine-grained features can serve as indicators for fraud detection. To leverage this, we design three heuristics based on different metadata attributes. 
The intuition is that articles from prestigious researchers or well-known institutions are generally perceived as more trustworthy.
To classify articles as fraudulent or not, we establish a threshold-based approach using metadata credibility scores. 
For example, if an article's highest author credibility falls within [\textit{medium, high, very high}], we classify it as legitimate.
Author credibility and affiliation reputation are categorized into six levels (including null). We define the three lower levels as indicators of fraudulence and the three higher levels as indicators of legitimacy.
Journal reputation, which consists of five levels, is categorized similarly: the three lower levels indicate potential fraud, while the higher levels suggest legitimacy.


\subsection{User Study}\label{sec:app_user_study}
In the user study, we prepared three questionnaires to evaluate the  %Naive 
Vanilla Reasoning, RAG and Debate modes independently. Using the Vanilla Reasoning mode, we generated explanations for 300 papers. We randomly selected five fraudulent papers and five legitimate papers from the result and again randomized the order of the paper to create the questionnaire. For each paper, we added 1) the information of the paper as it was in the model prompt; and 2) the explanations generated by the model. Three questions were asked for each paper: 1) whether the explanation was coherent and relevant; 2) %asked the user 
to infer the predicted label from the given explanation; and 3) whether the user agreed with the actual %\FT{actual}
%\todo{or the predicted by the user?} 
prediction. %This process was repeated to create 
% \FT{The same process was followed for}
The same process was followed for the other two questionnaires for the Debate and RAG models, except that, for the Debate model, the information of a supporting viewer and an attacking reviewer was added to the paper description. In total, 30 distinct papers were selected for evaluation by three clinicians.
% \FT{by three clinicians}.

Given the disagreement between human experts and model-generated outputs regarding the debate mode, we present the first three comments below. We hope these critical insights will be valuable for future studies.
\begin{itemize}
    \item \textit{I still don't understand what or who the "attacking reviewer" is. Is this a real world person who has completed a peer review? I feel that labelling this as fraudulent without more detailed evidence of actual fraud is not correct. This is very different from this simply being "not very good" science. I don't think it is fair to effectively discredit an author simply because they have a low H factor. Everyone has to start somewhere. Moreover,   the interpretation does not provide any evidence at all that the authors have either falsified data, that they have a track record of falsifying data, that the authors are affiliated with authors suspected activity or that they have links to governmental or state actors that may want to push falsified data. There is no comment on funding or conflicts of interest which I would expect to be in this analysis and which is missing. The critique argues that "specific" data is missing from the abstract, but then it does not state what this is and what would be required for the abstract to be robust. In summary, this LLM suggests this is research fraud, when as presented, the data suggest that more simply the quality of the abstract is low. This is an important distinction, that could lead to legal proceedings. }
    \item \textit{I think this LLM review is a false positive. I think the criticism of the abstract is not founded. They have performed in vivo and in vitro validation studies, and knock out experiments. While detail is missing, this is an overly harsh critique of a piece of basic science, that is not pretending to be clinical data. Again, what data is missing form the author's institutions? It doesn't actually state which part of this data is important and why. We know they are from a reputable Japanese university, which seems enough to me. Again, to call in to question the credibility of the scientist is libellous. This would need much stronger evidence of criminal or fraudulent behaviour which is clearly missing. So,  I think this is just a case of a not very well written abstract, that has been mis labelled as fraud.}
    \item \textit{The LLM is written in an overly cautious manner, which makes me lack trust in it. Firstly, there is a paradox in its explanation. It states the authors have a high H index, but the institution is emerging... so which are we to judge as being more important? This to me is biasing smaller organisations that may produce outstanding work. We need this model to identify EXCELLENCE in science and to promote it where it exists irrespective of the institution. The factors these models are basing their analysis on e.g. H factor, institutional reputation and author details are not important. I want to understand patterns of publishing behaviours, previous track records of fraud, history of COIs... etc. etc.. and most importantly a robust analysis of the QUALITY of the science. The LLM really provides no insights on this. }
\end{itemize}


\subsection{Ablation Study}
To validate the effect of different components in our methodology, we either vary or remove them and observe their impact on model performance, as measured by F1@Val in Table~\ref{tab:ablation}.
First, we observe that fine-tuning is the most important component, as its removal causes a dramatic performance drop. This indicates it is necessary to adapt LLMs to this task of fraud detection.
External knowledge is very beneficial, and the removal leads to a significant decrease. 
Meanwhile, other components can provide meaningful benefits, which confirms the effectiveness of our methodology.

\begin{table}[t] 
	\centering
        \small
	\setlength{\tabcolsep}{1.8mm}{
		\begin{threeparttable} 
			\begin{tabular}{ccc}  
				\toprule 
                    &F1@Val&$\Delta$\cr
                    \midrule
                    Pub-Guard-LLM (\textit{Vanilla})&69.5&-\cr
                    \midrule
                    \multicolumn{3}{c}{\textit{Varying the Base LLM}}\cr
                    \midrule
                    Bio-Llama&68.6&-0.9\cr
                    Mistral&67.8&-1.7\cr
                    \midrule
                    \multicolumn{3}{c}{\textit{Varying the Teacher Model}}\cr
                    \midrule
                    GPT-4o&68.3&-1.2\cr
                    Llama-70B&66.4&-3.1\cr
                    \midrule
                    \multicolumn{3}{c}{\textit{Removing Components}}\cr
                    \midrule
                    \textit{without} Fine-tuning &29.9&-39.6\cr
                    \textit{without} Explanation &68.5&-1.0\cr
                    \textit{without} External Knowledge &59.8&-9.7\cr
                     
				\bottomrule
			\end{tabular}
			\caption{Ablation study results
            } 	\label{tab:ablation}
		\end{threeparttable}
	}
 \vspace{-10pt}
\end{table}


\begin{table*}[ht]
    \centering
    \small
    \renewcommand{\arraystretch}{1.3}
    \setlength{\tabcolsep}{5pt}
    \begin{tabular}{m{14cm}}
        \toprule
        \rowcolor{gray!10} \centering \textbf{Prompt of Explanation Distillation}\cr
        \midrule
        This following article is a \{\texttt{label}\} article.\\
        You are tasked with providing explanations and making a firm case for why it has issues and should be \{\texttt{label}\}.\\ 
        This is the given article:\\
        Title: \{\texttt{Title}\}\\
        Abstract: \{\texttt{Abstract}\}\\
        Authors: \{\texttt{Authors}\}\\
        Affiliations: \{\texttt{Affiliations}\}\\
        Journal: \{\texttt{Journal}\}\\
        Based on the provided information, give a very short and concise explanation why it should be \{\texttt{label}\}\\
        Here are some factors to consider: \\
        (1) the reputation of the journal (whether it is a top journal with a rigorous peer review process)\\
        (2) the reputation of the authors and their affiliations (whether the authors have a history of misconduct in their research)\\
        (3) the integrity of the title and abstract (e.g., controversial topic, using made-up data, plagiarism, etc)\\
        In addition, if check if Email addresses are provided, check if it conforms to institutional format. Otherwise, no need to make comments about the Email adresses.\\
        Only provide the key reason briefly (in \{\texttt{Token}\} words) and do not repeat the title and sentences of abstract.\\
        Note that we use the token 'null' to indicate that additional information is missing from the corresponding databases.\\
        Write a separate sentence for each feature to avoid creating long and complex sentences.\\
        \bottomrule
    \end{tabular}
    \caption{Example prompt used for distilling explanations}
    \label{tab:prompt_explanation}
\end{table*}



\begin{table*}[ht]
    \centering
    \small
    \renewcommand{\arraystretch}{1.3}
    \setlength{\tabcolsep}{5pt}
    \begin{tabular}{m{14cm}}
        \toprule
        \rowcolor{gray!10} \centering \textbf{Prompt of Detecting Fraudulent Articles}\cr
        \midrule
        You are tasked with determining whether a given research paper should be retracted.\\
        To make this judgment, analyze the provided title, abstract, author information, 
        institutional affiliation, and publishing journal.\\
        Here are some factors to consider: \\
        (1) the reputation of the journal (whether it is a top journal with a rigorous peer review process)\\
        (2) the reputation of the authors and their affiliations (whether the authors have a history of misconduct in their research)\\
        (3) the integrity of the title and abstract (e.g., controversial topic, using made-up data, plagiarism, etc)\\
        In addition, if check if Email addresses are provided, check if it conforms to institutional format. Otherwise, no need to make comments about the Email adresses.\\
        
        ---------------------------------------\\
        Use the examples below as guidance:\\
        Example:\\
        Title: \{\texttt{Title}\}\\
        Abstract: \{\texttt{Abstract}\}\\
        Authors: \{\texttt{Authors}\}\\
        Affiliations: \{\texttt{Affiliations}\}\\
        Journal: \{\texttt{Journal}\}\\
        ---------------------------------------\\
        
        This is the given article:\\
        Title: \{\texttt{Title}\}\\
        Abstract: \{\texttt{Abstract}\}\\
        Authors: \{\texttt{Authors}\}\\
        Affiliations: \{\texttt{Affiliations}\}\\
        Journal: \{\texttt{Journal}\}\\
        Please first provide your prediction of whether this paper should be retracted and then provide your assessment and explanation.\\
        Label (answer Yes or No): \\
   
        \bottomrule
    \end{tabular}
    \caption{The prompt used to query LLMs.}
    \label{tab:query_prompt}
\end{table*}



\begin{table*}[ht]
    \centering
    \small
    \renewcommand{\arraystretch}{1.3}
    \setlength{\tabcolsep}{5pt}
    \begin{tabular}{m{14cm}}
        \toprule
        \rowcolor{gray!10} \centering \textbf{Prompt of Relevance Evaluation}\cr
        \midrule
        Evaluate the relevance of explanation provided for the model's prediction of the fraudulent articles.\\ 
        Consider the following criteria:\\
        Fidelity: Does the explanation highlight specific features and patterns within the article?\\
        Accuracy: Does the explanation avoid mentioning elements that do not exist in the article? The model should not make hallucinated explanations.\\
        Based on these criteria, rate the explanation's relevance on a scale from 1 to 10.\\
        -----------------------------------\\
        This is the given article:\\
        Title: \{\texttt{Title}\}\\
        Abstract: \{\texttt{Abstract}\}\\
        Authors: \{\texttt{Authors}\}\\
        Affiliations: \{\texttt{Affiliations}\}\\
        Journal: \{\texttt{Journal}\}\\
         -----------------------------------\\
        This is the prediction and explanation:\\
        Prediction and Explanation: \{\texttt{explanation}\}\\
        Rate the relevance, only provide the score:\\
         
        \bottomrule
    \end{tabular}
    \caption{Example prompt used for evaluating the relevance of explanations}
    \label{tab:relevance_prompt}
\end{table*}

\begin{table*}[ht]
    \centering
    \small
    \renewcommand{\arraystretch}{1.3}
    \setlength{\tabcolsep}{5pt}
    \begin{tabular}{m{14cm}}
        \toprule
        \rowcolor{gray!10} \centering \textbf{Prompt of Coherence Evaluation}\cr
        \midrule
        Evaluate the coherence of the explanation provided for the model's prediction of fraudulent articles.
        Consider the following criteria:\\
        Coherence: Does the explanation maintain logical consistency and clarity in its reasoning?\\
        Structure: Is the explanation well-organized, with ideas flowing logically from one to another?\\
        Based on these criteria, rate the explanation's coherence on a scale from 1 to 10.\\
        -----------------------------------\\
        This is the given article:\\
        Title: \{\texttt{Title}\}\\
        Abstract: \{\texttt{Abstract}\}\\
        Authors: \{\texttt{Authors}\}\\
        Affiliations: \{\texttt{Affiliations}\}\\
        Journal: \{\texttt{Journal}\}\\
         -----------------------------------\\
        This is the prediction and explanation:\\
        Prediction and Explanation: \{\texttt{explanation}\}\\
        Rate the coherence, only provide the score:\\
         
        \bottomrule
    \end{tabular}
    \caption{Example prompt used for evaluating the coherence of explanations}
    \label{tab:coherence_prompt}
\end{table*}

\begin{table*}[ht]
    \centering
    \small
    \renewcommand{\arraystretch}{1.3}
    \setlength{\tabcolsep}{5pt}
    \begin{tabular}{m{14cm}}
        \toprule
        \rowcolor{gray!10} \centering \textbf{An Example of the Vanilla Reasoning Mode}\cr
        \midrule
        \textbf{User Query with External Knowledge:}\\
        \textit{Title:} Changes and Influencing Factors of Cognitive Impairment in Patients with Breast Cancer\\
        \textit{Abstract:} To investigate the changes in cognitive function and its influencing factors in patients with breast cancer after chemotherapy,
        to provide a scientific basis for further cognitive correction therapy. In this study, general information on age,
        marital status, and chemotherapy regimen was collected from 172 breast cancer chemotherapy patients.
        172 patients with breast cancer undergoing chemotherapy were investigated by convenience sampling method,
        and the subjects were tested one-on-one using the Chinese version of the MATRICS Consensus Cognitive Battery (MCCB) computer system.\\

        \textit{Authors:} Cui (author h-index: 6, Early Career Researcher);
        Song (author h-index: 1, Emerging Researcher); Zhang (author h-index: 7, Early Career Researcher)\\

        \textit{Institutions:} College of Nursing, Jinzhou Medical University, Jinzhou, Liaoning 121001, China. (institution average citation: 9.0, Emerging Institution); Department of Intensive Care Medicine, Liaocheng People's Hospital, Liaocheng, Shandong 252000, China. (institution average citation: 10.0, Emerging Institution);\\

        \textit{Journal:} evidence-based complementary and alternative medicine : ecam (null)\\

        \textbf{Pub-Guard-LLM:}\\
        \textit{Prediction:} \\
        Yes (\textit{Fraudulent})\\ 
        \textit{Explanation:}\\
         The article should be retracted due to concerns about the integrity of the study. The authors' affiliations are inconsistent, with some listed multiple times, suggesting a potential error or lack of proper collaboration. The journal in which it was published is not specified, making it difficult to assess the rigor of the peer review process. The study's sample size is relatively small, which may limit the generalizability of the findings. Additionally, the abstract does not provide sufficient detail about the methods used, making it difficult to assess the validity of the results.\\
        
        \bottomrule
    \end{tabular}
    \caption{An input-output example of the Vanilla Reasoning mode}
    \label{tab:example_vanilla}
\end{table*}


\begin{table*}[ht]
    \centering
    \small
    \renewcommand{\arraystretch}{1.3}
    \setlength{\tabcolsep}{5pt}
    \begin{tabular}{m{14cm}}
        \toprule
        \rowcolor{gray!10} \centering \textbf{An Example of the RAG Mode}\cr
        \midrule
        \textbf{User Query with External Knoledge:}\\
        \textit{Title:} Changes and Influencing Factors of Cognitive Impairment in Patients with Breast Cancer\\
        \textit{Abstract:} To investigate the changes in cognitive function and its influencing factors in patients with breast cancer after chemotherapy,
        to provide a scientific basis for further cognitive correction therapy. In this study, general information on age,
        marital status, and chemotherapy regimen was collected from 172 breast cancer chemotherapy patients.
        172 patients with breast cancer undergoing chemotherapy were investigated by convenience sampling method,
        and the subjects were tested one-on-one using the Chinese version of the MATRICS Consensus Cognitive Battery (MCCB) computer system.\\

        \textit{Authors:} Cui (author h-index: 6, Early Career Researcher);
        Song (author h-index: 1, Emerging Researcher); Zhang (author h-index: 7, Early Career Researcher)\\

        \textit{Institutions:} College of Nursing, Jinzhou Medical University, Jinzhou, Liaoning 121001, China. (institution average citation: 9.0, Emerging Institution); Department of Intensive Care Medicine, Liaocheng People's Hospital, Liaocheng, Shandong 252000, China. (institution average citation: 10.0, Emerging Institution);\\

        \textit{Journal:} evidence-based complementary and alternative medicine : ecam (null)\\

        \textbf{RAG Results:}\\
        In the meantime, a set of legitimate papers is provided, each containing highly relevant articles.
        Use these articles as evidence to assess whether the given paper is potentially fraudulent.
        Look for indicators such as controversial topics, unsupported claims, or inconsistencies.
        Below are examples of relevant papers:\\
        Example 1:\\
        Title: \{\texttt{Title}\}
        Abstract: \{\texttt{Abstract}\}\\
        ......\\
        
        \textbf{Pub-Guard-LLM:}\\
        \textit{Prediction:} \\
        Yes (\textit{Fraudulent})\\ 
        \textit{Explanation:}\\
         The article should be retracted due to the lack of reputation of the journal, as it is not listed in the provided information. Additionally, the authors have relatively low h-index scores, indicating a lack of established reputation in their field. Furthermore, the study's sample size is small, and the results may not be generalizable to a larger population. Lastly, the article lacks information on the study's methodology and statistical analysis, raising concerns about the validity of the findings\\
        
        \bottomrule
    \end{tabular}
    \caption{An input-output example for the RAG mode}
    \label{tab:example_rag}
\end{table*}


\begin{table*}[ht]
    \centering
    \small
    \renewcommand{\arraystretch}{1.3}
    \setlength{\tabcolsep}{5pt}
    \begin{tabular}{m{14cm}}
        \toprule
        \rowcolor{gray!10} \centering \textbf{An Example of the Debate Mode}\cr
        \midrule
        \textbf{User Query with External Knowledge:}\\
        \textit{Title:} Changes and Influencing Factors of Cognitive Impairment in Patients with Breast Cancer\\
        \textit{Abstract:} To investigate the changes in cognitive function and its influencing factors in patients with breast cancer after chemotherapy,
        to provide a scientific basis for further cognitive correction therapy. In this study, general information on age,
        marital status, and chemotherapy regimen was collected from 172 breast cancer chemotherapy patients.
        172 patients with breast cancer undergoing chemotherapy were investigated by convenience sampling method,
        and the subjects were tested one-on-one using the Chinese version of the MATRICS Consensus Cognitive Battery (MCCB) computer system.\\

        \textit{Authors:} Cui (author h-index: 6, Early Career Researcher);
        Song (author h-index: 1, Emerging Researcher); Zhang (author h-index: 7, Early Career Researcher)\\

        \textit{Institutions:} College of Nursing, Jinzhou Medical University, Jinzhou, Liaoning 121001, China. (institution average citation: 9.0, Emerging Institution); Department of Intensive Care Medicine, Liaocheng People's Hospital, Liaocheng, Shandong 252000, China. (institution average citation: 10.0, Emerging Institution);\\

        \textit{Journal:} evidence-based complementary and alternative medicine : ecam (null)\\

        \textbf{Supporting Reviewer:}\\
        The article appears legitimate based on the following factors:\\
        1. Journal Reputation: The article is published in evidence-based complementary and alternative medicine : ecam, a journal dedicated to complementary and alternative medicine, suggesting a focus on rigorous scientific research in this field.
        2. Author Reputation: The authors are affiliated with recognized institutions, and their h-index scores, though relatively low, indicate they have published and been cited in other academic works.
        3. Title and Abstract Integrity: The title and abstract present a clear research question, methodology, and findings, with no apparent signs of controversial topics, made-up data, or plagiarism.
        4. Institutional Affiliation: The authors are associated with various departments and colleges within recognized universities, suggesting a multidisciplinary approach to the research.
        5. Missing Information: The 'null' values indicate missing information, but this does not necessarily delegitimize the article, as it may simply be a database issue.\\

        \textbf{Attacking Reviewer:}\\
        The article should be retracted due to the lack of reputation of the journal, as it is not specified and could indicate a lack of rigorous peer review. The authors have relatively low h-indices, suggesting they are early in their careers or have not yet produced highly impactful research. The study's findings may not be reliable as the sample size is not specified, and the results could be biased due to the convenience sampling method used. Additionally, the absence of information about the Department of Radiation Oncology at Jinzhou Medical University raises concerns about the credibility of the research.\\
        
        \textbf{Pub-Guard-LLM:}\\
        \textit{Prediction:} \\
        Yes (\textit{Fraudulent})\\ 
        \textit{Explanation:}\\
         The article should be retracted due to concerns about the credibility of the research. The journal's reputation is questionable as it is not specified, suggesting a lack of rigorous peer review. The authors' relatively low h-indices and the absence of information about one of the institutions raise questions about their expertise and the validity of the research. Furthermore, the study's findings may not be reliable due to the lack of information about the sample size and the use of convenience sampling, which could introduce bias.\\
        
        \bottomrule
    \end{tabular}
    \caption{An input-output example for the Debate mode}
    \label{tab:example_debate}
\end{table*}


\end{document}
