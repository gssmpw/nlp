\section{Method\label{sec:method}}
To achieve our objective of automatically converting the nonlinear system description \eqref{eq:nl_dyn} into a global LPV embedding given by \eqref{eq:lpv_dyn} with $p(t) = \eta(x(t), u(t))$, we leverage the \emph{Second Fundamental Theorem of Calculus} (FTC)~\citep{apostolCalculus1Onevariable1980} for function factorization as proposed in~\citep[Appendix~C.1]{koelewijnAnalysisControlNonlinear2023}.

Consider a function $g(z) = [g_1(z) \ \cdots \ g_m(z)]^\top$ where $g_i(z) : \R^{n} \rightarrow \R^{m}$ for $i = 1,\dots,m$ and $z \in \R^{n}$. For $z, \, z_{\ast} \in \R^\mathrm{n}$, we define the auxiliary function
%
\begin{equation}
	\label{eq:auxiliary}
	\bar{g}_i(\lambda) = g_i(z_{\ast} + \lambda(z - z_{\ast})),
\end{equation}
%
for $i = 1,\dots,m$ and $\lambda \in [0, 1]$. Then by the FTC, we have that
%
\begin{equation}
	\label{eq:FTC}
	\bar{g}_i(1) - \bar{g}_i(0) = \int_{0}^{1} \frac{d \bar{g}_i}{d \lambda}(\lambda) \, d \lambda,
\end{equation}
%
and using the relations $\bar{g}_i(1)=g_i(z)$ and $\bar{g}_i(0) =  g_i(z_{\ast})$, obtained by evaluating \eqref{eq:auxiliary} at $\lambda = \{0, 1\}$, it follows that
%
\begin{equation}
	\label{eq:FTC2}
	g_i(z) - g_i(z_{\ast}) = \int_{0}^{1} \frac{d \bar{g}_i}{d \lambda}(\lambda) \, d \lambda.
\end{equation}
%
Now, by taking the chain rule of the integrand in \eqref{eq:FTC2}:
%
\begin{equation}
	\label{eq:chain_rule}
	\frac{d \bar{g}_i}{d \lambda} = \frac{\partial g_i}{\partial z} \frac{d \bar{g}_i}{d \lambda} = \frac{\partial g_i}{\partial z}(z_{\ast} + \lambda(z - z_{\ast}))(z - z_{\ast}),
\end{equation}
%
where $\frac{\partial g_i}{\partial z}$ is the transpose of the gradient of $g_i$, and by substituting \eqref{eq:chain_rule} into \eqref{eq:FTC2}, we end up with
%
\begin{equation}
	g_i(z) - g_i(z_{\ast}) = \int_{0}^{1} \frac{\partial g_i}{\partial z}(z_{\ast} + \lambda(z - z_{\ast})) \, d \lambda \, (z - z_{\ast}),
\end{equation}
%
for $i = 1,\dots,m$. Then, combining the elements, $g$ is expressed as
\begin{align}
	\label{eq:fun_factorization}
	g(z) - g(z_{\ast}) & = \begin{bmatrix}
		                      g_1(z) - g_1(z_{\ast}) \\
		                      \vdots                \\
		                      g_m(z) - g_m(z_{\ast})
	                      \end{bmatrix}; \notag                                                                                         \\
	                  & = \begin{bmatrix}
		                      \int_{0}^{1} \frac{\partial g_1}{\partial z}(z_{\ast} + \lambda(z - z_{\ast})) \, d \lambda \, (z - z_{\ast}) \\
		                      \vdots                                                                                       \\
		                      \int_{0}^{1} \frac{\partial g_m}{\partial z}(z_{\ast} + \lambda(z - z_{\ast})) \, d \lambda \, (z - z_{\ast})
	                      \end{bmatrix}; \notag \\
	                  & = \int_{0}^{1} \frac{\partial g}{\partial z}(z_{\ast} + \lambda(z - z_{\ast})) \, d \lambda \, (z - z_{\ast}),
\end{align}
where $\frac{\partial g}{\partial z}(z_{\ast} + \lambda(z - z_{\ast})) \in \R^{m \times n}$ is the Jacobian of $g$ evaluated at $z_{\ast} + \lambda(z - z_{\ast})$ and the integral of the Jacobian is taken element-wise.


Now, we can apply \eqref{eq:fun_factorization} to factorize the functions $f$ and $h$ in \eqref{eq:nl_dyn} as follows:
\begin{subequations}
	\label{eq:factorized_nl}
	\begin{align}
		f(x, u) - f(\bar{x}, \bar{u}) & = \bar{A}(x, u) (x - \bar{x}) + \bar{B}(x, u) (u - \bar{u}); \\
		h(x, u) - h(\bar{x}, \bar{u}) & = \bar{C}(x, u) (x - \bar{x}) + \bar{D}(x, u) (u - \bar{u}),
	\end{align}
	where
	\begin{align*}
		\bar{A}(x, u) & = \int_{0}^{1} \frac{\partial f}{\partial x}\left(\bar{x} + \lambda (x - \bar{x}), \bar{u} + \lambda (u - \bar{u})\right) \, d \lambda;  \\
		\bar{B}(x, u) & = \int_{0}^{1} \frac{\partial f}{\partial u}\left(\bar{x} + \lambda (x - \bar{x}) , \bar{u} + \lambda (u - \bar{u})\right) \, d \lambda; \\
		\bar{C}(x, u) & = \int_{0}^{1} \frac{\partial h}{\partial x}\left(\bar{x} + \lambda (x - \bar{x}), \bar{u} + \lambda (u - \bar{u})\right) \, d \lambda;  \\
		\bar{D}(x, u) & = \int_{0}^{1} \frac{\partial h}{\partial u}\left(\bar{x} + \lambda (x - \bar{x}), \bar{u} + \lambda (u - \bar{u})\right) \, d \lambda.
	\end{align*}
\end{subequations}

Moreover, it is often the case that $f(0, 0) = 0$ and {$h(0, 0) = 0$}, i.e., that the origin is an equilibrium point of the system. Otherwise, we can perform a coordinate transformation to ensure this property. In these cases, we can further simplify \eqref{eq:factorized_nl} by taking $\bar{x} = 0$ and $\bar{u} = 0$, resulting in:
%
\begin{subequations}
	\label{eq:simplified_factorized_nl}
	\begin{align}
		f(x, u) & = \bar{A}(x, u) x + \bar{B}(x, u) u, \\
		h(x, u) & = \bar{C}(x, u) x + \bar{D}(x, u) u,
	\end{align}
	where
	\begin{align*}
		\bar{A}(x, u) \hspace{-1pt} & = \hspace{-2pt} \int_{0}^{1} \! \frac{\partial f}{\partial x}(\lambda x, \lambda u) \, d \lambda, \
		\bar{B}(x, u)  = \hspace{-2pt} \int_{0}^{1} \! \frac{\partial f}{\partial u}(\lambda x, \lambda u) \, d \lambda,                  \\
		\bar{C}(x, u) \hspace{-1pt} & = \hspace{-2pt} \int_{0}^{1} \! \frac{\partial h}{\partial x}(\lambda x, \lambda u) \, d \lambda, \
		\bar{D}(x, u)  = \hspace{-2pt} \int_{0}^{1} \! \frac{\partial h}{\partial u}(\lambda x, \lambda u) \, d \lambda.
	\end{align*}
\end{subequations}
%
To obtain an LPV form \eqref{eq:lpv_dyn} for a given factorization of $f$ and $h$ in \eqref{eq:simplified_factorized_nl}, a 
%Given the factorization of $f$ and $h$ in \eqref{eq:simplified_factorized_nl}, we can now define the 
scheduling map $\eta$ in terms of \eqref{eq:scheduling_map} is constructed  
%
%\begin{equation}
	%\label{eq:embedding_scheduling_map}
	%p = \eta(x, u) = \psi(x, u),
%\end{equation} 
such that the matrix functions $A,B,C,D$ resulting from \eqref{eq:LPV_realization} via 
\begin{equation}
	\begin{aligned}
		\label{eq:lpv_matrices}
		A(\overbrace{\eta(x,u)}^{p}) & = \bar{A}(x, u), & B(\overbrace{\eta(x,u)}^{p}) & = \bar{B}(x, u), \\
		D(\underbrace{\eta(x,u)}_p) & = \bar{C}(x, u), & D(\underbrace{\eta(x,u)}_p) & = \bar{D}(x, u).
	\end{aligned}
\end{equation}
%$A(\eta(x,u))=\bar{A}(x,u)$, \ldots, $D(\eta(x,u))=\bar{D}(x,u)$ 
have a  
%
%where $\psi : \R^{\nx} \times \R^{\dnu} \rightarrow \R^{\np}$ is a function that can be chosen based on the 
desired type of scheduling dependency, e.g., affine, polynomial, or rational. An LPV representation with an affine scheduling dependency can for example be obtained by choosing $\eta$ to contain the nonlinear elements of the matrix functions $\bar{A},\, \bar{B},\, \bar{C}$, and $\bar{D}$. 

Through this process, the nonlinear system represented by \eqref{eq:nl_dyn} is directly embedded into a global LPV model of the form \eqref{eq:lpv_dyn} with \eqref{eq:scheduling_map} satisfying \eqref{eq:LPV_realization} via \eqref{eq:simplified_factorized_nl} and \eqref{eq:lpv_matrices} and hence achieving $\mathcal{B} \subseteq \mathcal{B}_{\text{LPV}}$.
An important property of factorization \eqref{eq:simplified_factorized_nl}, compared to other conversion methods, is that there is no approximation involved; hence, embedding of the complete nonlinear behavior $\mathcal{B}$ is guaranteed on the target sets $\mathcal{X}\times\mathcal{U}$. Also, no decisions are required to be made that which functional terms are split or substituted in which order as in other conversion concepts (e.g., \cite{Kwiatkowski06}). Furthermore, the factorization \eqref{eq:simplified_factorized_nl}, i.e., the matrix functions $\bar{A},\ldots,\bar{D}$ are well defined for $x=0$ and $u=0$, because \[\lim_{(x,u)\rightarrow (0,0)} \bar{A}(x,u)=\lim_{\tau \rightarrow 0} \int_{0}^{\tau} \! \frac{\partial f}{\partial x}(\lambda x, \lambda u) \, d \lambda = \frac{\partial f}{\partial x}(0, 0),\]
which exists for all $\bar{A},\ldots,\bar{D}$ as $f,h\in\mathcal{C}_1$. 

In addition to the advantages of the embedding process, a clear price to pay for automatic conversion is that the required information for the scheduling map $\eta$ cannot be controlled during the conversion. For real-world applications, the matrix functions $\bar{A},\ldots,\bar{D}$ often only depend on certain elements of $x$ and $u$, therefore only those elements are required for the scheduling map $\eta$. This will also be exemplified in Section \ref{sec:examples}. On the other hand, mathematically it is possible that the entire $(x,u)$ vector is required to compute the resulting $p$. Furthermore, the resulting dimension of $p$, that is, $n_\mathrm{p}$, depends on the chosen dependency class of $A,\ldots,B$. The more simplistic dependence, e.g., affine, is chosen for these matrix functions, the more complex and higher dimensional the resulting scheduling map $\eta$ becomes. These disadvantages can be efficiently mitigated by recently introduced scheduling reduction techniques, such as \cite{Toth20ACC,Toth16TCST,8431912}, which can often provide dramatic reduction of $n_\mathrm{p}$ without a significant loss of accuracy of the representation; see \cite{olucha2024reductionlinearparametervaryingstatespace} for a comparative study.         

In the next section, we provide the details of the implementation of the proposed method in the \textsc{LPVcore} toolbox.