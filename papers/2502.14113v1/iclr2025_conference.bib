@incollection{Bengio+chapter2007,
author = {Bengio, Yoshua and LeCun, Yann},
booktitle = {Large Scale Kernel Machines},
publisher = {MIT Press},
title = {Scaling Learning Algorithms Towards {AI}},
year = {2007}
}

@article{Hinton06,
author = {Hinton, Geoffrey E. and Osindero, Simon and Teh, Yee Whye},
journal = {Neural Computation},
pages = {1527--1554},
title = {A Fast Learning Algorithm for Deep Belief Nets},
volume = {18},
year = {2006}
}
@misc{li2022elevaterbenchmarktoolkitevaluating,
      title={ELEVATER: A Benchmark and Toolkit for Evaluating Language-Augmented Visual Models}, 
      author={Chunyuan Li and Haotian Liu and Liunian Harold Li and Pengchuan Zhang and Jyoti Aneja and Jianwei Yang and Ping Jin and Houdong Hu and Zicheng Liu and Yong Jae Lee and Jianfeng Gao},
      year={2022},
      eprint={2204.08790},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2204.08790}, 
}
@misc{zhao2023vlchecklistevaluatingpretrainedvisionlanguage,
      title={VL-CheckList: Evaluating Pre-trained Vision-Language Models with Objects, Attributes and Relations}, 
      author={Tiancheng Zhao and Tianqi Zhang and Mingwei Zhu and Haozhan Shen and Kyusong Lee and Xiaopeng Lu and Jianwei Yin},
      year={2023},
      eprint={2207.00221},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2207.00221}, 
}
@misc{liu2024tagalignimprovingvisionlanguagealignment,
      title={TagAlign: Improving Vision-Language Alignment with Multi-Tag Classification}, 
      author={Qinying Liu and Wei Wu and Kecheng Zheng and Zhan Tong and Jiawei Liu and Yu Liu and Wei Chen and Zilei Wang and Yujun Shen},
      year={2024},
      eprint={2312.14149},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2312.14149}, 
}
@misc{mu2021slipselfsupervisionmeetslanguageimage,
      title={SLIP: Self-supervision meets Language-Image Pre-training}, 
      author={Norman Mu and Alexander Kirillov and David Wagner and Saining Xie},
      year={2021},
      eprint={2112.12750},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2112.12750}, 
}
@misc{li2023factualbenchmarkfaithfulconsistent,
      title={FACTUAL: A Benchmark for Faithful and Consistent Textual Scene Graph Parsing}, 
      author={Zhuang Li and Yuyang Chai and Terry Yue Zhuo and Lizhen Qu and Gholamreza Haffari and Fei Li and Donghong Ji and Quan Hung Tran},
      year={2023},
      eprint={2305.17497},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2305.17497}, 
}

@book{goodfellow2016deep,
title={Deep learning},
author={Goodfellow, Ian and Bengio, Yoshua and Courville, Aaron and Bengio, Yoshua},
volume={1},
year={2016},
publisher={MIT Press}
}
@article{tschannen2023image,
  title={Image Captioners Are Scalable Vision Learners Too},
  author={Tschannen, Michael and Kumar, Manoj and Steiner, Andreas and Zhai, Xiaohua and Houlsby, Neil and Beyer, Lucas},
  journal={arXiv preprint arXiv:2306.07915},
  year={2023}
}
@inproceedings{sharma-etal-2018-conceptual,
    title = "Conceptual Captions: A Cleaned, Hypernymed, Image Alt-text Dataset For Automatic Image Captioning",
    author = "Sharma, Piyush  and
      Ding, Nan  and
      Goodman, Sebastian  and
      Soricut, Radu",
    editor = "Gurevych, Iryna  and
      Miyao, Yusuke",
    booktitle = "Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = jul,
    year = "2018",
    address = "Melbourne, Australia",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/P18-1238/",
    doi = "10.18653/v1/P18-1238",
    pages = "2556--2565",
    abstract = "We present a new dataset of image caption annotations, Conceptual Captions, which contains an order of magnitude more images than the MS-COCO dataset (Lin et al., 2014) and represents a wider variety of both images and image caption styles. We achieve this by extracting and filtering image caption annotations from billions of webpages. We also present quantitative evaluations of a number of image captioning models and show that a model architecture based on Inception-ResNetv2 (Szegedy et al., 2016) for image-feature extraction and Transformer (Vaswani et al., 2017) for sequence modeling achieves the best performance when trained on the Conceptual Captions dataset."
}

@inproceedings{pushkarna2022data,
  title={Data cards: Purposeful and transparent dataset documentation for responsible ai},
  author={Pushkarna, Mahima and Zaldivar, Andrew and Kjartansson, Oddur},
  booktitle={2022 ACM Conference on Fairness, Accountability, and Transparency},
  pages={1776--1826},
  year={2022}
}

@article{Deng2009ImageNetAL,
  title={ImageNet: A large-scale hierarchical image database},
  author={Jia Deng and Wei Dong and Richard Socher and Li-Jia Li and K. Li and Li Fei-Fei},
  journal={2009 IEEE Conference on Computer Vision and Pattern Recognition},
  year={2009},
  pages={248-255}
}

@article{bianchi2022easily,
  title={Easily accessible text-to-image generation amplifies demographic stereotypes at large scale},
  author={Bianchi, Federico and Kalluri, Pratyusha and Durmus, Esin and Ladhak, Faisal and Cheng, Myra and Nozza, Debora and Hashimoto, Tatsunori and Jurafsky, Dan and Zou, James and Caliskan, Aylin},
  journal={arXiv preprint arXiv:2211.03759},
  year={2022}
}

@article{cho2022dall,
  title={Dall-eval: Probing the reasoning skills and social biases of text-to-image generative transformers},
  author={Cho, Jaemin and Zala, Abhay and Bansal, Mohit},
  journal={arXiv preprint arXiv:2202.04053},
  year={2022}
}

@article{ramesh2022hierarchical,
  title={Hierarchical text-conditional image generation with clip latents},
  author={Ramesh, Aditya and Dhariwal, Prafulla and Nichol, Alex and Chu, Casey and Chen, Mark},
  journal={arXiv preprint arXiv:2204.06125},
  year={2022}
}

@inproceedings{rombach2022high,
  title={High-resolution image synthesis with latent diffusion models},
  author={Rombach, Robin and Blattmann, Andreas and Lorenz, Dominik and Esser, Patrick and Ommer, Bj{\"o}rn},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={10684--10695},
  year={2022}
}

@article{chen2022pali,
  title={Pali: A jointly-scaled multilingual language-image model},
  author={Chen, Xi and Wang, Xiao and Changpinyo, Soravit and Piergiovanni, AJ and Padlewski, Piotr and Salz, Daniel and Goodman, Sebastian and Grycner, Adam and Mustafa, Basil and Beyer, Lucas and others},
  journal={arXiv preprint arXiv:2209.06794},
  year={2022}
}

@article{alayrac2022flamingo,
  title={Flamingo: a visual language model for few-shot learning},
  author={Alayrac, Jean-Baptiste and Donahue, Jeff and Luc, Pauline and Miech, Antoine and Barr, Iain and Hasson, Yana and Lenc, Karel and Mensch, Arthur and Millican, Katherine and Reynolds, Malcolm and others},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={23716--23736},
  year={2022}
}

@inproceedings{li2023blip2,
      title={{BLIP-2:} Bootstrapping Language-Image Pre-training with Frozen Image Encoders and Large Language Models}, 
      author={Junnan Li and Dongxu Li and Silvio Savarese and Steven Hoi},
      year={2023},
      booktitle={ICML},
}

@article{diwan2022winoground,
  title={Why is Winoground Hard? Investigating Failures in Visuolinguistic Compositionality},
  author={Diwan, Anuj and Berry, Layne and Choi, Eunsol and Harwath, David and Mahowald, Kyle},
  journal={arXiv preprint arXiv:2211.00768},
  year={2022}
}

@article{ross2021tailor,
  title={Tailor: Generating and perturbing text with semantic controls},
  author={Ross, Alexis and Wu, Tongshuang and Peng, Hao and Peters, Matthew E and Gardner, Matt},
  journal={arXiv preprint arXiv:2107.07150},
  year={2021}
}

@article{gururangan-etal-2018-annotation,
  title={Annotation artifacts in natural language inference data},
  author={Gururangan, Suchin and Swayamdipta, Swabha and Levy, Omer and Schwartz, Roy and Bowman, Samuel R and Smith, Noah A},
  journal={arXiv preprint arXiv:1803.02324},
  year={2018}
}



@inproceedings{morris2020textattack,
  title={TextAttack: A Framework for Adversarial Attacks, Data Augmentation, and Adversarial Training in NLP},
  author={Morris, John and Lifland, Eli and Yoo, Jin Yong and Grigsby, Jake and Jin, Di and Qi, Yanjun},
  booktitle={Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations},
  pages={119--126},
  year={2020}
}

@article{gadre2023datacomp,
  title={DataComp: In search of the next generation of multimodal datasets},
  author={Gadre, Samir Yitzhak and Ilharco, Gabriel and Fang, Alex and Hayase, Jonathan and Smyrnis, Georgios and Nguyen, Thao and Marten, Ryan and Wortsman, Mitchell and Ghosh, Dhruba and Zhang, Jieyu and others},
  journal={arXiv preprint arXiv:2304.14108},
  year={2023}
}

@article{reif2023fighting,
  title={Fighting Bias with Bias: Promoting Model Robustness by Amplifying Dataset Biases},
  author={Reif, Yuval and Schwartz, Roy},
  journal={arXiv preprint arXiv:2305.18917},
  year={2023}
}
@inproceedings{
tang2023when,
title={When are Lemons Purple? The Concept Association Bias of Vision-Language Models},
author={Yingtian Tang and Yutaro Yamada and Yoyo Minzhi Zhang and Ilker Yildirim},
booktitle={The 2023 Conference on Empirical Methods in Natural Language Processing},
year={2023},
url={https://openreview.net/forum?id=5sGLPiG1vE}
}
@inproceedings{le2020adversarial,
  title={Adversarial filters of dataset biases},
  author={Le Bras, Ronan and Swayamdipta, Swabha and Bhagavatula, Chandra and Zellers, Rowan and Peters, Matthew and Sabharwal, Ashish and Choi, Yejin},
  booktitle={International Conference on Machine Learning},
  pages={1078--1088},
  year={2020},
  organization={PMLR}
}

@article{sakaguchi2021winogrande,
  title={Winogrande: An adversarial winograd schema challenge at scale},
  author={Sakaguchi, Keisuke and Bras, Ronan Le and Bhagavatula, Chandra and Choi, Yejin},
  journal={Communications of the ACM},
  volume={64},
  number={9},
  pages={99--106},
  year={2021},
  publisher={ACM New York, NY, USA}
}

@article{zellers2018swag,
  title={Swag: A large-scale adversarial dataset for grounded commonsense inference},
  author={Zellers, Rowan and Bisk, Yonatan and Schwartz, Roy and Choi, Yejin},
  journal={arXiv preprint arXiv:1808.05326},
  year={2018}
}

@article{chatgpt,
  title={ChatGPT},
  author={OpenAI},
  year={2022}
}

@inproceedings{lin2014microsoft,
  title={Microsoft coco: Common objects in context},
  author={Lin, Tsung-Yi and Maire, Michael and Belongie, Serge and Hays, James and Perona, Pietro and Ramanan, Deva and Doll{\'a}r, Piotr and Zitnick, C Lawrence},
  booktitle={Computer Vision--ECCV 2014: 13th European Conference, Zurich, Switzerland, September 6-12, 2014, Proceedings, Part V 13},
  pages={740--755},
  year={2014},
  organization={Springer}
}

@software{ilharco_gabriel_2021_5143773,
  author       = {Ilharco, Gabriel and
                  Wortsman, Mitchell and
                  Wightman, Ross and
                  Gordon, Cade and
                  Carlini, Nicholas and
                  Taori, Rohan and
                  Dave, Achal and
                  Shankar, Vaishaal and
                  Namkoong, Hongseok and
                  Miller, John and
                  Hajishirzi, Hannaneh and
                  Farhadi, Ali and
                  Schmidt, Ludwig},
  title        = {OpenCLIP},
  month        = jul,
  year         = 2021,
  publisher    = {Zenodo},
  version      = {0.1},
  doi          = {10.5281/zenodo.5143773},
  url          = {https://doi.org/10.5281/zenodo.5143773}
}


@article{li2023blip,
  title={Blip-2: Bootstrapping language-image pre-training with frozen image encoders and large language models},
  author={Li, Junnan and Li, Dongxu and Savarese, Silvio and Hoi, Steven},
  journal={arXiv preprint arXiv:2301.12597},
  year={2023}
}

@inproceedings{li2022blip,
      title={BLIP: Bootstrapping Language-Image Pre-training for Unified Vision-Language Understanding and Generation}, 
      author={Junnan Li and Dongxu Li and Caiming Xiong and Steven Hoi},
      year={2022},
      booktitle={ICML},
}

@inproceedings{Singh2023CoarsetoFineCL,
  title={Coarse-to-Fine Contrastive Learning in Image-Text-Graph Space for Improved Vision-Language Compositionality},
  author={Harman Singh and Pengchuan Zhang and Qifan Wang and Mengjiao Wang and Wenhan Xiong and Jingfei Du and Yu Chen},
  year={2023}
}

@inproceedings{doveh2023teaching,
  title={Teaching Structured Vision \& Language Concepts to Vision \& Language Models},
  author={Doveh, Sivan and Arbelle, Assaf and Harary, Sivan and Schwartz, Eli and Herzig, Roei and Giryes, Raja and Feris, Rogerio and Panda, Rameswar and Ullman, Shimon and Karlinsky, Leonid},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={2657--2668},
  year={2023}
}

@inproceedings{liu-etal-2022-wanli,
    title = "{WANLI}: Worker and {AI} Collaboration for Natural Language Inference Dataset Creation",
    author = "Liu, Alisa  and
      Swayamdipta, Swabha  and
      Smith, Noah A.  and
      Choi, Yejin",
    booktitle = "Findings of the Association for Computational Linguistics: EMNLP 2022",
    month = dec,
    year = "2022",
    address = "Abu Dhabi, United Arab Emirates",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.findings-emnlp.508",
    pages = "6826--6847",
}

@article{liu2023vera,
  title={Vera: A General-Purpose Plausibility Estimation Model for Commonsense Statements},
  author={Liu, Jiacheng and Wang, Wenya and Wang, Dianzhuo and Smith, Noah A and Choi, Yejin and Hajishirzi, Hannaneh},
  journal={arXiv preprint arXiv:2305.03695},
  year={2023}
}

@article{hu2023tifa,
  title={TIFA: Accurate and Interpretable Text-to-Image Faithfulness Evaluation with Question Answering},
  author={Hu, Yushi and Liu, Benlin and Kasai, Jungo and Wang, Yizhong and Ostendorf, Mari and Krishna, Ranjay and Smith, Noah A},
  journal={arXiv preprint arXiv:2303.11897},
  year={2023}
}

@misc{shipard2023diversity,
      title={Diversity is Definitely Needed: Improving Model-Agnostic Zero-shot Classification via Stable Diffusion}, 
      author={Jordan Shipard and Arnold Wiliem and Kien Nguyen Thanh and Wei Xiang and Clinton Fookes},
      year={2023},
      eprint={2302.03298},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@InProceedings{Rombach_2022_CVPR,
    author    = {Rombach, Robin and Blattmann, Andreas and Lorenz, Dominik and Esser, Patrick and Ommer, Bj\"orn},
    title     = {High-Resolution Image Synthesis With Latent Diffusion Models},
    booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
    month     = {June},
    year      = {2022},
    pages     = {10684-10695}
}

@article{ma2022crepe,
  title={CREPE: Can Vision-Language Foundation Models Reason Compositionally?},
  author={Ma, Zixian and Hong, Jerry and Gul, Mustafa Omer and Gandhi, Mona and Gao, Irena and Krishna, Ranjay},
  journal={arXiv preprint arXiv:2212.07796},
  year={2022}
}


@article{santurkar2022caption,
  title={Is a Caption Worth a Thousand Images? A Controlled Study for Representation Learning},
  author={Santurkar, Shibani and Dubois, Yann and Taori, Rohan and Liang, Percy and Hashimoto, Tatsunori},
  journal={arXiv preprint arXiv:2207.07635},
  year={2022}
}
@misc{kalantidis2020hardnegativemixingcontrastive,
      title={Hard Negative Mixing for Contrastive Learning}, 
      author={Yannis Kalantidis and Mert Bulent Sariyildiz and Noe Pion and Philippe Weinzaepfel and Diane Larlus},
      year={2020},
      eprint={2010.01028},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2010.01028}, 
}
@misc{doveh2023teachingstructuredvisionlanguageconcepts,
      title={Teaching Structured Vision\&Language Concepts to Vision\&Language Models}, 
      author={Sivan Doveh and Assaf Arbelle and Sivan Harary and Rameswar Panda and Roei Herzig and Eli Schwartz and Donghyun Kim and Raja Giryes and Rogerio Feris and Shimon Ullman and Leonid Karlinsky},
      year={2023},
      eprint={2211.11733},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2211.11733}, 
}
@misc{burgess2019monetunsupervisedscenedecomposition,
      title={MONet: Unsupervised Scene Decomposition and Representation}, 
      author={Christopher P. Burgess and Loic Matthey and Nicholas Watters and Rishabh Kabra and Irina Higgins and Matt Botvinick and Alexander Lerchner},
      year={2019},
      eprint={1901.11390},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/1901.11390}, 
}
@misc{wu2023slotdiffusionobjectcentricgenerativemodeling,
      title={SlotDiffusion: Object-Centric Generative Modeling with Diffusion Models}, 
      author={Ziyi Wu and Jingyu Hu and Wuyue Lu and Igor Gilitschenski and Animesh Garg},
      year={2023},
      eprint={2305.11281},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2305.11281}, 
}
@misc{eslami2016attendinferrepeatfast,
      title={Attend, Infer, Repeat: Fast Scene Understanding with Generative Models}, 
      author={S. M. Ali Eslami and Nicolas Heess and Theophane Weber and Yuval Tassa and David Szepesvari and Koray Kavukcuoglu and Geoffrey E. Hinton},
      year={2016},
      eprint={1603.08575},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/1603.08575}, 
}
@misc{seitzer2023bridginggaprealworldobjectcentric,
      title={Bridging the Gap to Real-World Object-Centric Learning}, 
      author={Maximilian Seitzer and Max Horn and Andrii Zadaianchuk and Dominik Zietlow and Tianjun Xiao and Carl-Johann Simon-Gabriel and Tong He and Zheng Zhang and Bernhard Schölkopf and Thomas Brox and Francesco Locatello},
      year={2023},
      eprint={2209.14860},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2209.14860}, 
}

@misc{greff2020multiobjectrepresentationlearningiterative,
      title={Multi-Object Representation Learning with Iterative Variational Inference}, 
      author={Klaus Greff and Raphaël Lopez Kaufman and Rishabh Kabra and Nick Watters and Chris Burgess and Daniel Zoran and Loic Matthey and Matthew Botvinick and Alexander Lerchner},
      year={2020},
      eprint={1903.00450},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/1903.00450}, 
}

@inproceedings{NEURIPS2023_e3cdc587,
 author = {Webb, Taylor and Mondal, Shanka Subhra and Cohen, Jonathan D},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {A. Oh and T. Naumann and A. Globerson and K. Saenko and M. Hardt and S. Levine},
 pages = {72030--72043},
 publisher = {Curran Associates, Inc.},
 title = {Systematic Visual Reasoning through Object-Centric Relational Abstraction},
 url = {https://proceedings.neurips.cc/paper_files/paper/2023/file/e3cdc587873dd1d00ac78f0c1f9aa60c-Paper-Conference.pdf},
 volume = {36},
 year = {2023}
}

@misc{mondal2024slotabstractorsscalableabstract,
      title={Slot Abstractors: Toward Scalable Abstract Visual Reasoning}, 
      author={Shanka Subhra Mondal and Jonathan D. Cohen and Taylor W. Webb},
      year={2024},
      eprint={2403.03458},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2403.03458}, 
}
@inproceedings{osrt,
 author = {Sajjadi, Mehdi S. M. and Duckworth, Daniel and Mahendran, Aravindh and van Steenkiste, Sjoerd and Pavetic, Filip and Lucic, Mario and Guibas, Leonidas J and Greff, Klaus and Kipf, Thomas},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {S. Koyejo and S. Mohamed and A. Agarwal and D. Belgrave and K. Cho and A. Oh},
 pages = {9512--9524},
 publisher = {Curran Associates, Inc.},
 title = {Object Scene Representation Transformer},
 url = {https://proceedings.neurips.cc/paper_files/paper/2022/file/3dc83fcfa4d13e30070bd4b230c38cfe-Paper-Conference.pdf},
 volume = {35},
 year = {2022}
}
@inproceedings{savi++,
 author = {Elsayed, Gamaleldin and Mahendran, Aravindh and van Steenkiste, Sjoerd and Greff, Klaus and Mozer, Michael C and Kipf, Thomas},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {S. Koyejo and S. Mohamed and A. Agarwal and D. Belgrave and K. Cho and A. Oh},
 pages = {28940--28954},
 publisher = {Curran Associates, Inc.},
 title = {SAVi++: Towards End-to-End Object-Centric Learning from Real-World Videos},
 url = {https://proceedings.neurips.cc/paper_files/paper/2022/file/ba1a6ba05319e410f0673f8477a871e3-Paper-Conference.pdf},
 volume = {35},
 year = {2022}
}

@InProceedings{pmlr-v177-assouel22a,
  title = 	 {{VIM}: Variational Independent Modules for Video Prediction},
  author =       {Assouel, Rim and Castrejon, Lluis and Courville, Aaron and Ballas, Nicolas and Bengio, Yoshua},
  booktitle = 	 {Proceedings of the First Conference on Causal Learning and Reasoning},
  pages = 	 {70--89},
  year = 	 {2022},
  editor = 	 {Schölkopf, Bernhard and Uhler, Caroline and Zhang, Kun},
  volume = 	 {177},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {11--13 Apr},
  publisher =    {PMLR},
  pdf = 	 {https://proceedings.mlr.press/v177/assouel22a/assouel22a.pdf},
  url = 	 {https://proceedings.mlr.press/v177/assouel22a.html},
  abstract = 	 {We introduce a variational inference model called VIM, for Variational Independent Modules, for sequential data that learns and infers latent representations as a set of objects and discovers modular causal mechanisms over these objects. These mechanisms - which we call modules - are independently parametrized, define the stochastic transitions of entities and are shared across entities.  At each time step, our model infers from a low-level input sequence a high-level sequence of categorical latent variables to select which transition modules to apply to which high-level object. We evaluate this model in video prediction tasks where the goal is to predict multi-modal future events given previous observations. We demonstrate empirically that VIM can model 2D visual sequences in an interpretable way and is able to identify the underlying dynamically instantiated mechanisms of the generation process.  We additionally show that the learnt modules can be composed at test time to generalize to out-of-distribution observations.}
}


@article{zhao2022vl,
  title={VL-CheckList: Evaluating Pre-trained Vision-Language Models with Objects, Attributes and Relations},
  author={Zhao, Tiancheng and Zhang, Tianqi and Zhu, Mingwei and Shen, Haozhan and Lee, Kyusong and Lu, Xiaopeng and Yin, Jianwei},
  journal={arXiv preprint arXiv:2207.00221},
  year={2022}
}

@inproceedings{Parcalabescu_2022,
   title={VALSE: A Task-Independent Benchmark for Vision and Language Models Centered on Linguistic Phenomena},
   url={http://dx.doi.org/10.18653/v1/2022.acl-long.567},
   DOI={10.18653/v1/2022.acl-long.567},
   booktitle={Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
   publisher={Association for Computational Linguistics},
   author={Parcalabescu, Letitia and Cafagna, Michele and Muradjan, Lilitta and Frank, Anette and Calixto, Iacer and Gatt, Albert},
   year={2022},
   pages={8253–8280} }
@inproceedings{thrush2022winoground,
  title={Winoground: Probing Vision and Language Models for Visio-Linguistic Compositionality},
  author={Thrush, Tristan and Jiang, Ryan and Bartolo, Max and Singh, Amanpreet and Williams, Adina and Kiela, Douwe and Ross, Candace},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={5238--5248},
  year={2022}
}

@article{conwell2022testing,
  title={Testing Relational Understanding in Text-Guided Image Generation},
  author={Conwell, Colin and Ullman, Tomer D},
  journal={arXiv preprint arXiv:2208.00005},
  year={2022}
}

% Flickr30k
@article{young2014image,
  title={From image descriptions to visual denotations: New similarity metrics for semantic inference over event descriptions},
  author={Young, Peter and Lai, Alice and Hodosh, Micah and Hockenmaier, Julia},
  journal={Transactions of the Association for Computational Linguistics},
  volume={2},
  pages={67--78},
  year={2014},
  publisher={MIT Press}
}

@inproceedings{singh2022flava,
  title={Flava: A foundational language and vision alignment model},
  author={Singh, Amanpreet and Hu, Ronghang and Goswami, Vedanuj and Couairon, Guillaume and Galuba, Wojciech and Rohrbach, Marcus and Kiela, Douwe},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={15638--15650},
  year={2022}
}


@article{krishna2017visual,
  title={Visual genome: Connecting language and vision using crowdsourced dense image annotations},
  author={Krishna, Ranjay and Zhu, Yuke and Groth, Oliver and Johnson, Justin and Hata, Kenji and Kravitz, Joshua and Chen, Stephanie and Kalantidis, Yannis and Li, Li-Jia and Shamma, David A and others},
  journal={International journal of computer vision},
  volume={123},
  number={1},
  pages={32--73},
  year={2017},
  publisher={Springer}
}
@misc{oquab2024dinov2learningrobustvisual,
      title={DINOv2: Learning Robust Visual Features without Supervision}, 
      author={Maxime Oquab and Timothée Darcet and Théo Moutakanni and Huy Vo and Marc Szafraniec and Vasil Khalidov and Pierre Fernandez and Daniel Haziza and Francisco Massa and Alaaeldin El-Nouby and Mahmoud Assran and Nicolas Ballas and Wojciech Galuba and Russell Howes and Po-Yao Huang and Shang-Wen Li and Ishan Misra and Michael Rabbat and Vasu Sharma and Gabriel Synnaeve and Hu Xu and Hervé Jegou and Julien Mairal and Patrick Labatut and Armand Joulin and Piotr Bojanowski},
      year={2024},
      eprint={2304.07193},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2304.07193}, 
}
@misc{awal2024visminvisualminimalchangeunderstanding,
      title={VisMin: Visual Minimal-Change Understanding}, 
      author={Rabiul Awal and Saba Ahmadi and Le Zhang and Aishwarya Agrawal},
      year={2024},
      eprint={2407.16772},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2407.16772}, 
}

@misc{locatello2020objectcentriclearningslotattention,
      title={Object-Centric Learning with Slot Attention}, 
      author={Francesco Locatello and Dirk Weissenborn and Thomas Unterthiner and Aravindh Mahendran and Georg Heigold and Jakob Uszkoreit and Alexey Dosovitskiy and Thomas Kipf},
      year={2020},
      eprint={2006.15055},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2006.15055}, 
}

@inproceedings{WuInvertedAttentionTC,
  title={Inverted-Attention Transformers can Learn Object Representations: Insights from Slot Attention},
  author={Yi-Fu Wu and Klaus Greff and Google Deepmind and Gamaleldin F. Elsayed and Michael C. Mozer and Thomas Kipf and Sjoerd van Steenkiste},
  url={https://api.semanticscholar.org/CorpusID:266090680}
}

@misc{darcet2024visiontransformersneedregisters,
      title={Vision Transformers Need Registers}, 
      author={Timothée Darcet and Maxime Oquab and Julien Mairal and Piotr Bojanowski},
      year={2024},
      eprint={2309.16588},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2309.16588}, 
}



@article{saharia2022photorealistic,
  title={Photorealistic Text-to-Image Diffusion Models with Deep Language Understanding},
  author={Saharia, Chitwan and Chan, William and Saxena, Saurabh and Li, Lala and Whang, Jay and Denton, Emily and Ghasemipour, Seyed Kamyar Seyed and Ayan, Burcu Karagol and Mahdavi, S Sara and Lopes, Rapha Gontijo and others},
  journal={arXiv preprint arXiv:2205.11487},
  year={2022}
}

@article{yu2022scaling,
  title={Scaling autoregressive models for content-rich text-to-image generation},
  author={Yu, Jiahui and Xu, Yuanzhong and Koh, Jing Yu and Luong, Thang and Baid, Gunjan and Wang, Zirui and Vasudevan, Vijay and Ku, Alexander and Yang, Yinfei and Ayan, Burcu Karagol and others},
  journal={arXiv preprint arXiv:2206.10789},
  year={2022}
}


@inproceedings{
brendel2019approximating,
title={Approximating {CNN}s with Bag-of-local-Features models works surprisingly well on ImageNet},
author={Wieland Brendel and Matthias Bethge},
booktitle={International Conference on Learning Representations},
year={2019},
url={https://openreview.net/forum?id=SkfMWhAqYQ},
}


@inproceedings{hessel2021effective,
  title={How effective is BERT without word ordering? Implications for language understanding and data privacy},
  author={Hessel, Jack and Schofield, Alexandra},
  booktitle={Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 2: Short Papers)},
  pages={204--211},
  year={2021}
}


@inproceedings{o2021context,
    title = "What Context Features Can Transformer Language Models Use?",
    author = "O{'}Connor, Joe  and
      Andreas, Jacob",
    booktitle = "Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)",
    month = aug,
    year = "2021",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.acl-long.70",
    doi = "10.18653/v1/2021.acl-long.70",
    pages = "851--864",
}

@inproceedings{karpathy2015deep,
  title={Deep visual-semantic alignments for generating image descriptions},
  author={Karpathy, Andrej and Fei-Fei, Li},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={3128--3137},
  year={2015}
}

@article{nguyen2022,
  author = {Nguyen, Thao and Ilharco, Gabriel and Wortsman, Mitchell and Oh, Sewoong and Schmidt, Ludwig},
   journal={arXiv preprint arXiv:2208.05516},
  
  title = {Quality Not Quantity: On the Interaction between Dataset Design and Robustness of CLIP},
  
  publisher = {arXiv},
  
  year = {2022},
  
  copyright = {Creative Commons Attribution 4.0 International}
}

@article{fang2022data,
  title={Data Determines Distributional Robustness in Contrastive Language Image Pre-training (CLIP)},
  author={Fang, Alex and Ilharco, Gabriel and Wortsman, Mitchell and Wan, Yuhao and Shankar, Vaishaal and Dave, Achal and Schmidt, Ludwig},
  journal={arXiv preprint arXiv:2205.01397},
  year={2022}
}


@inproceedings{pham2020out,
    title = "Out of Order: How important is the sequential order of words in a sentence in Natural Language Understanding tasks?",
    author = "Pham, Thang  and
      Bui, Trung  and
      Mai, Long  and
      Nguyen, Anh",
    booktitle = "Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021",
    month = aug,
    year = "2021",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.findings-acl.98",
    doi = "10.18653/v1/2021.findings-acl.98",
    pages = "1145--1160",
}




@article{zerroug2022benchmark,
  title={A Benchmark for Compositional Visual Reasoning},
  author={Zerroug, Aimen and Vaishnav, Mohit and Colin, Julien and Musslick, Sebastian and Serre, Thomas},
  journal={arXiv preprint arXiv:2206.05379},
  year={2022}
}

@inproceedings{hudson2019gqa,
  title={Gqa: A new dataset for real-world visual reasoning and compositional question answering},
  author={Hudson, Drew A and Manning, Christopher D},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={6700--6709},
  year={2019}
}

@article{marcus2022very,
  title={A very preliminary analysis of DALL-E 2},
  author={Marcus, Gary and Davis, Ernest and Aaronson, Scott},
  journal={arXiv preprint arXiv:2204.13807},
  year={2022}
}


@article{wang2022image,
  title={Image as a Foreign Language: BEiT Pretraining for All Vision and Vision-Language Tasks},
  author={Wang, Wenhui and Bao, Hangbo and Dong, Li and Bjorck, Johan and Peng, Zhiliang and Liu, Qiang and Aggarwal, Kriti and Mohammed, Owais Khan and Singhal, Saksham and Som, Subhojit and others},
  journal={arXiv preprint arXiv:2208.10442},
  year={2022}
}

@article{wang2022omnivl,
  title={OmniVL: One Foundation Model for Image-Language and Video-Language Tasks},
  author={Wang, Junke and Chen, Dongdong and Wu, Zuxuan and Luo, Chong and Zhou, Luowei and Zhao, Yucheng and Xie, Yujia and Liu, Ce and Jiang, Yu-Gang and Yuan, Lu},
  journal={arXiv preprint arXiv:2209.07526},
  year={2022}
}

@article{ettinger2020bert,
  title={What BERT is not: Lessons from a new suite of psycholinguistic diagnostics for language models},
  author={Ettinger, Allyson},
  journal={Transactions of the Association for Computational Linguistics},
  volume={8},
  pages={34--48},
  year={2020},
  publisher={MIT Press}
}

@inproceedings{sinha2021masked,
  title={Masked Language Modeling and the Distributional Hypothesis: Order Word Matters Pre-training for Little},
  author={Koustuv Sinha and Robin Jia and Dieuwke Hupkes and Jo{\"e}lle Pineau and Adina Williams and Douwe Kiela},
  booktitle={EMNLP},
  year={2021}
}


@inproceedings{wolfe2022,
author = {Wolfe, Robert and Caliskan, Aylin},
title = {American == White in Multimodal Language-and-Image AI},
year = {2022},
isbn = {9781450392471},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3514094.3534136},
doi = {10.1145/3514094.3534136},
booktitle = {Proceedings of the 2022 AAAI/ACM Conference on AI, Ethics, and Society},
pages = {800–812},
numpages = {13},
keywords = {multimodal models, visual semantics, bias in ai, racial bias},
location = {Oxford, United Kingdom},
series = {AIES '22}
}

@inproceedings{frank-etal-2021-vision,
    title = "Vision-and-Language or Vision-for-Language? {O}n Cross-Modal Influence in Multimodal Transformers",
    author = "Frank, Stella and Bugliarello, Emanuele and
      Elliott, Desmond",
    booktitle = "Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing (EMNLP 2021)",
    month = "nov",
    year = "2021",
    publisher = "Association for Computational Linguistics",
    url = "https://arxiv.org/abs/2109.04448",
}

@inproceedings{parcalabescu-etal-2021-seeing,
    title = "Seeing past words: Testing the cross-modal capabilities of pretrained {V}{\&}{L} models on counting tasks",
    author = "Parcalabescu, Letitia  and
      Gatt, Albert  and
      Frank, Anette  and
      Calixto, Iacer",
    booktitle = "Proceedings of the 1st Workshop on Multimodal Semantic Representations (MMSR)",
    month = jun,
    year = "2021",
    address = "Groningen, Netherlands (Online)",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.mmsr-1.4",
    pages = "32--44",

}


@article{tejankar2021fistful,
  title={A fistful of words: Learning transferable visual models from bag-of-words supervision},
  author={Tejankar, Ajinkya and Wu, Bichen and Xie, Saining and Khabsa, Madian and Pirsiavash, Hamed and Firooz, Hamed},
  journal={arXiv preprint arXiv:2112.13884},
  year={2021}
}

@article{geirhos2020shortcut,
  title={Shortcut learning in deep neural networks},
  author={Geirhos, Robert and Jacobsen, J{\"o}rn-Henrik and Michaelis, Claudio and Zemel, Richard and Brendel, Wieland and Bethge, Matthias and Wichmann, Felix A},
  journal={Nature Machine Intelligence},
  volume={2},
  number={11},
  pages={665--673},
  year={2020},
  publisher={Nature Publishing Group}
}

@inproceedings{zhai2022lit,
  title={Lit: Zero-shot transfer with locked-image text tuning},
  author={Zhai, Xiaohua and Wang, Xiao and Mustafa, Basil and Steiner, Andreas and Keysers, Daniel and Kolesnikov, Alexander and Beyer, Lucas},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={18123--18133},
  year={2022}
}


@InProceedings{zeng22c,
  title = 	 {Multi-Grained Vision Language Pre-Training: Aligning Texts with Visual Concepts},
  author =       {Zeng, Yan and Zhang, Xinsong and Li, Hang},
  booktitle = 	 {Proceedings of the 39th International Conference on Machine Learning},
  pages = 	 {25994--26009},
  year = 	 {2022},
  editor = 	 {Chaudhuri, Kamalika and Jegelka, Stefanie and Song, Le and Szepesvari, Csaba and Niu, Gang and Sabato, Sivan},
  volume = 	 {162},
  series = 	 {Proceedings of Machine Learning Research},
  publisher =    {PMLR},
}


@unpublished{spacy2,
    AUTHOR = {Honnibal, Matthew and Montani, Ines},
    TITLE  = {{spaCy 2}: Natural language understanding with {B}loom embeddings, convolutional neural networks and incremental parsing},
    YEAR   = {2017},
    Note   = {To appear}
}

@inproceedings{wolf-etal-2020-transformers,
    title = "Transformers: State-of-the-Art Natural Language Processing",
    author = "Wolf, Thomas  and
      Debut, Lysandre  and
      Sanh, Victor  and
      Chaumond, Julien  and
      Delangue, Clement  and
      Moi, Anthony  and
      Cistac, Pierric  and
      Rault, Tim  and
      Louf, Remi  and
      Funtowicz, Morgan  and
      Davison, Joe  and
      Shleifer, Sam  and
      von Platen, Patrick  and
      Ma, Clara  and
      Jernite, Yacine  and
      Plu, Julien  and
      Xu, Canwen  and
      Le Scao, Teven  and
      Gugger, Sylvain  and
      Drame, Mariama  and
      Lhoest, Quentin  and
      Rush, Alexander",
    booktitle = "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations",
    month = oct,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2020.emnlp-demos.6",
    doi = "10.18653/v1/2020.emnlp-demos.6",
    pages = "38--45",
}

@inproceedings{harwood2017smart,
  title={Smart mining for deep metric learning},
  author={Harwood, Ben and Kumar BG, Vijay and Carneiro, Gustavo and Reid, Ian and Drummond, Tom},
  booktitle={Proceedings of the IEEE International Conference on Computer Vision},
  pages={2821--2829},
  year={2017}
}

@inproceedings{wu2017sampling,
  title={Sampling matters in deep embedding learning},
  author={Wu, Chao-Yuan and Manmatha, R and Smola, Alexander J and Krahenbuhl, Philipp},
  booktitle={Proceedings of the IEEE international conference on computer vision},
  pages={2840--2848},
  year={2017}
}


@inproceedings{ge2018deep,
  title={Deep metric learning with hierarchical triplet loss},
  author={Ge, Weifeng},
  booktitle={Proceedings of the European Conference on Computer Vision (ECCV)},
  pages={269--285},
  year={2018}
}




@article{wang2018glue,
  title={GLUE: A multi-task benchmark and analysis platform for natural language understanding},
  author={Wang, Alex and Singh, Amanpreet and Michael, Julian and Hill, Felix and Levy, Omer and Bowman, Samuel R},
  journal={arXiv preprint arXiv:1804.07461},
  year={2018}
}

@article{zhang2020contrastive,
  title={Contrastive learning of medical visual representations from paired images and text},
  author={Zhang, Yuhao and Jiang, Hang and Miura, Yasuhide and Manning, Christopher D and Langlotz, Curtis P},
  journal={arXiv preprint arXiv:2010.00747},
  year={2020}
}

@article{bogin2021covr,
  title={COVR: A test-bed for visually grounded compositional generalization with real images},
  author={Bogin, Ben and Gupta, Shivanshu and Gardner, Matt and Berant, Jonathan},
  journal={arXiv preprint arXiv:2109.10613},
  year={2021}
}



@inproceedings{
geirhos2018imagenettrained,
title={ImageNet-trained {CNN}s are biased towards texture; increasing shape bias improves accuracy and robustness.},
author={Robert Geirhos and Patricia Rubisch and Claudio Michaelis and Matthias Bethge and Felix A. Wichmann and Wieland Brendel},
booktitle={International Conference on Learning Representations},
year={2019},
url={https://openreview.net/forum?id=Bygh9j09KX},
}

@article{lin2024revisiting,
  title={Revisiting the Role of Language Priors in Vision-Language Models},
  author={Lin, Zhiqiu and Chen, Xinyue and Pathak, Deepak and Zhang, Pengchuan and Ramanan, Deva},
  journal={arXiv preprint arXiv:2306.01879},
  year={2024}
}

@inproceedings{vqa2,
  title={Making the {V} in {VQA} matter: Elevating the role of image understanding in visual question answering},
  author={Goyal, Yash and Khot, Tejas and Summers-Stay, Douglas and Batra, Dhruv and Parikh, Devi},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={6904--6913},
  year={2017}
}

@inproceedings{
  yuksekgonul2023when,
  title={When and why Vision-Language Models behave like  Bags-of-Words, and what to do about it?},
  author={Mert Yuksekgonul and Federico Bianchi and Pratyusha   Kalluri and Dan Jurafsky and James Zou},
  booktitle={International Conference on Learning Representations},
  year={2023},
  url={https://openreview.net/forum?id=KRLUvxh8uaX}
}


@article{DBLP:journals/corr/abs-2110-11316,
  author    = {Andreas F{\"{u}}rst and
               Elisabeth Rumetshofer and
               Viet Tran and
               Hubert Ramsauer and
               Fei Tang and
               Johannes Lehner and
               David P. Kreil and
               Michael Kopp and
               G{\"{u}}nter Klambauer and
               Angela Bitto{-}Nemling and
               Sepp Hochreiter},
  title     = {{CLOOB:} Modern Hopfield Networks with InfoLOOB Outperform {CLIP}},
  journal   = {CoRR},
  volume    = {abs/2110.11316},
  year      = {2021},
  url       = {https://arxiv.org/abs/2110.11316},
  eprinttype = {arXiv},
  eprint    = {2110.11316},
  timestamp = {Sun, 02 Oct 2022 15:32:27 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2110-11316.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}


@article{goel2022cyclip,
  title={Cyclip: Cyclic contrastive language-image pretraining},
  author={Goel, Shashank and Bansal, Hritik and Bhatia, Sumit and Rossi, Ryan A and Vinay, Vishwa and Grover, Aditya},
  journal={arXiv preprint arXiv:2205.14459},
  year={2022}
}

@inproceedings{Desai021,
  author    = {Karan Desai and
               Justin Johnson},
  title     = {VirTex: Learning Visual Representations From Textual Annotations},
  booktitle = {{IEEE} Conference on Computer Vision and Pattern Recognition, {CVPR}
               2021, virtual, June 19-25, 2021},
  pages     = {11162--11173},
  publisher = {Computer Vision Foundation / {IEEE}},
  year      = {2021},
  url       = {https://openaccess.thecvf.com/content/CVPR2021/html/Desai\_VirTex\_Learning\_Visual\_Representations\_From\_Textual\_Annotations\_CVPR\_2021\_paper.html},
  doi       = {10.1109/CVPR46437.2021.01101},
  timestamp = {Mon, 18 Jul 2022 16:47:41 +0200},
  biburl    = {https://dblp.org/rec/conf/cvpr/Desai021.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}




@inproceedings{ChenLYK0G0020,
  author    = {Yen{-}Chun Chen and
               Linjie Li and
               Licheng Yu and
               Ahmed El Kholy and
               Faisal Ahmed and
               Zhe Gan and
               Yu Cheng and
               Jingjing Liu},
  editor    = {Andrea Vedaldi and
               Horst Bischof and
               Thomas Brox and
               Jan{-}Michael Frahm},
  title     = {{UNITER:} UNiversal Image-TExt Representation Learning},
  booktitle = {Computer Vision - {ECCV} 2020 - 16th European Conference, Glasgow,
               UK, August 23-28, 2020, Proceedings, Part {XXX}},
  series    = {Lecture Notes in Computer Science},
  volume    = {12375},
  pages     = {104--120},
  publisher = {Springer},
  year      = {2020},
  url       = {https://doi.org/10.1007/978-3-030-58577-8\_7},
  doi       = {10.1007/978-3-030-58577-8\_7},
  timestamp = {Sun, 02 Oct 2022 15:59:30 +0200},
  biburl    = {https://dblp.org/rec/conf/eccv/ChenLYK0G0020.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}


@inproceedings{
zhang2022glipv,
title={{GLIP}v2: Unifying Localization and Vision-Language Understanding },
author={Haotian Zhang and Pengchuan Zhang and Xiaowei Hu and Yen-Chun Chen and Liunian Harold Li and Xiyang Dai and Lijuan Wang and Lu Yuan and Jenq-Neng Hwang and Jianfeng Gao},
booktitle={Advances in Neural Information Processing Systems},
editor={Alice H. Oh and Alekh Agarwal and Danielle Belgrave and Kyunghyun Cho},
year={2022},
url={https://openreview.net/forum?id=wiBEFdAvl8L}
}

@inproceedings{LiSGJXH21,
  author    = {Junnan Li and
               Ramprasaath R. Selvaraju and
               Akhilesh Gotmare and
               Shafiq R. Joty and
               Caiming Xiong and
               Steven Chu{-}Hong Hoi},
  editor    = {Marc'Aurelio Ranzato and
               Alina Beygelzimer and
               Yann N. Dauphin and
               Percy Liang and
               Jennifer Wortman Vaughan},
  title     = {Align before Fuse: Vision and Language Representation Learning with
               Momentum Distillation},
  booktitle = {Advances in Neural Information Processing Systems 34: Annual Conference
               on Neural Information Processing Systems 2021, NeurIPS 2021, December
               6-14, 2021, virtual},
  pages     = {9694--9705},
  year      = {2021},
  url       = {https://proceedings.neurips.cc/paper/2021/hash/505259756244493872b7709a8a01b536-Abstract.html},
  timestamp = {Tue, 03 May 2022 16:20:47 +0200},
  biburl    = {https://dblp.org/rec/conf/nips/LiSGJXH21.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}




@inproceedings{LiLZCOSYY22,
  author    = {Yangguang Li and
               Feng Liang and
               Lichen Zhao and
               Yufeng Cui and
               Wanli Ouyang and
               Jing Shao and
               Fengwei Yu and
               Junjie Yan},
  title     = {Supervision Exists Everywhere: {A} Data Efficient Contrastive Language-Image
               Pre-training Paradigm},
  booktitle = {The Tenth International Conference on Learning Representations, {ICLR}
               2022, Virtual Event, April 25-29, 2022},
  publisher = {OpenReview.net},
  year      = {2022},
  url       = {https://openreview.net/forum?id=zq1iJkNk3uN},
  timestamp = {Sat, 20 Aug 2022 01:15:42 +0200},
  biburl    = {https://dblp.org/rec/conf/iclr/LiLZCOSYY22.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}




@inproceedings{WuCZGGV22,
  author    = {Bichen Wu and
               Ruizhe Cheng and
               Peizhao Zhang and
               Tianren Gao and
               Joseph E. Gonzalez and
               Peter Vajda},
  title     = {Data Efficient Language-Supervised Zero-Shot Recognition with Optimal
               Transport Distillation},
  booktitle = {The Tenth International Conference on Learning Representations, {ICLR}
               2022, Virtual Event, April 25-29, 2022},
  publisher = {OpenReview.net},
  year      = {2022},
  url       = {https://openreview.net/forum?id=G89-1yZLFHk},
  timestamp = {Sat, 20 Aug 2022 01:15:42 +0200},
  biburl    = {https://dblp.org/rec/conf/iclr/WuCZGGV22.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}






@article{ThomeeSFENPBL16,
  author    = {Bart Thomee and
               David A. Shamma and
               Gerald Friedland and
               Benjamin Elizalde and
               Karl Ni and
               Douglas Poland and
               Damian Borth and
               Li{-}Jia Li},
  title     = {{YFCC100M:} the new data in multimedia research},
  journal   = {Commun. {ACM}},
  volume    = {59},
  number    = {2},
  pages     = {64--73},
  year      = {2016},
  url       = {http://doi.acm.org/10.1145/2812802},
  doi       = {10.1145/2812802},
  timestamp = {Wed, 14 Nov 2018 10:22:35 +0100},
  biburl    = {https://dblp.org/rec/journals/cacm/ThomeeSFENPBL16.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}




@inproceedings{laion5b,
  title={{LAION}-5B: An open large-scale dataset for training next generation image-text models},
  author={Christoph Schuhmann and
          Romain Beaumont and
          Richard Vencu and
          Cade W Gordon and
          Ross Wightman and
          Mehdi Cherti and
          Theo Coombes and
          Aarush Katta and
          Clayton Mullis and
          Mitchell Wortsman and
          Patrick Schramowski and
          Srivatsa R Kundurthy and
          Katherine Crowson and
          Ludwig Schmidt and
          Robert Kaczmarczyk and
          Jenia Jitsev},
  booktitle={Thirty-sixth Conference on Neural Information Processing Systems Datasets and Benchmarks Track},
  year={2022},
  url={https://openreview.net/forum?id=M3Y74vmsMcY}
}


@inproceedings{MuK0X22,
  author    = {Norman Mu and
               Alexander Kirillov and
               David A. Wagner and
               Saining Xie},
  editor    = {Shai Avidan and
               Gabriel J. Brostow and
               Moustapha Ciss{\'{e}} and
               Giovanni Maria Farinella and
               Tal Hassner},
  title     = {{SLIP:} Self-supervision Meets Language-Image Pre-training},
  booktitle = {Computer Vision - {ECCV} 2022 - 17th European Conference, Tel Aviv,
               Israel, October 23-27, 2022, Proceedings, Part {XXVI}},
  series    = {Lecture Notes in Computer Science},
  volume    = {13686},
  pages     = {529--544},
  publisher = {Springer},
  year      = {2022},
  url       = {https://doi.org/10.1007/978-3-031-19809-0\_30},
  doi       = {10.1007/978-3-031-19809-0\_30},
  timestamp = {Thu, 03 Nov 2022 14:17:21 +0100},
  biburl    = {https://dblp.org/rec/conf/eccv/MuK0X22.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}



@inproceedings{0001LXH22,
  author    = {Junnan Li and
               Dongxu Li and
               Caiming Xiong and
               Steven C. H. Hoi},
  editor    = {Kamalika Chaudhuri and
               Stefanie Jegelka and
               Le Song and
               Csaba Szepesv{\'{a}}ri and
               Gang Niu and
               Sivan Sabato},
  title     = {{BLIP:} Bootstrapping Language-Image Pre-training for Unified Vision-Language
               Understanding and Generation},
  booktitle = {International Conference on Machine Learning, {ICML} 2022, 17-23 July
               2022, Baltimore, Maryland, {USA}},
  series    = {Proceedings of Machine Learning Research},
  volume    = {162},
  pages     = {12888--12900},
  publisher = {{PMLR}},
  year      = {2022},
  url       = {https://proceedings.mlr.press/v162/li22n.html},
  timestamp = {Tue, 12 Jul 2022 17:36:52 +0200},
  biburl    = {https://dblp.org/rec/conf/icml/0001LXH22.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{norelli2022asif,
  title={ASIF: Coupled Data Turns Unimodal Models to Multimodal Without Training},
  author={Norelli, Antonio and Fumero, Marco and Maiorca, Valentino and Moschella, Luca and Rodol{\`a}, Emanuele and Locatello, Francesco},
  journal={arXiv preprint arXiv:2210.01738},
  year={2022}
}


@article{krizhevsky2009learning,
  title={Learning multiple layers of features from tiny images},
  author={Krizhevsky, Alex and Hinton, Geoffrey and others},
  year={2009},
  publisher={Toronto, ON, Canada}
}

@article{DiHT,
  author    = {Filip Radenovic and
               Abhimanyu Dubey and
               Abhishek Kadian and
               Todor Mihaylov and
               Simon Vandenhende and
               Yash Patel and
               Yi Wen and
               Vignesh Ramanathan and
               Dhruv Mahajan},
  title     = {Filtering, Distillation, and Hard Negatives for Vision-Language Pre-Training},
  journal   = {CoRR},
  volume    = {abs/2301.02280},
  year      = {2023},
  url       = {https://doi.org/10.48550/arXiv.2301.02280},
  doi       = {10.48550/arXiv.2301.02280},
  eprinttype = {arXiv},
  eprint    = {2301.02280},
  timestamp = {Tue, 10 Jan 2023 15:10:12 +0100},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2301-02280.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}


@article{HeZRS15,
  author    = {Kaiming He and
               Xiangyu Zhang and
               Shaoqing Ren and
               Jian Sun},
  title     = {Deep Residual Learning for Image Recognition},
  journal   = {CoRR},
  volume    = {abs/1512.03385},
  year      = {2015},
  url       = {http://arxiv.org/abs/1512.03385},
  eprinttype = {arXiv},
  eprint    = {1512.03385},
  timestamp = {Wed, 25 Jan 2023 11:01:16 +0100},
  biburl    = {https://dblp.org/rec/journals/corr/HeZRS15.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@misc{greff2020bindingproblemartificialneural,
      title={On the Binding Problem in Artificial Neural Networks}, 
      author={Klaus Greff and Sjoerd van Steenkiste and Jürgen Schmidhuber},
      year={2020},
      eprint={2012.05208},
      archivePrefix={arXiv},
      primaryClass={cs.NE},
      url={https://arxiv.org/abs/2012.05208}, 
}
@article{bert,
  author    = {Jacob Devlin and
               Ming{-}Wei Chang and
               Kenton Lee and
               Kristina Toutanova},
  title     = {{BERT:} Pre-training of Deep Bidirectional Transformers for Language
               Understanding},
  journal   = {CoRR},
  volume    = {abs/1810.04805},
  year      = {2018},
  url       = {http://arxiv.org/abs/1810.04805},
  eprinttype = {arXiv},
  eprint    = {1810.04805},
  timestamp = {Tue, 30 Oct 2018 20:39:56 +0100},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1810-04805.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}


@InProceedings{Baldrati_2022_CVPR,
    author    = {Baldrati, Alberto and Bertini, Marco and Uricchio, Tiberio and Del Bimbo, Alberto},
    title     = {Conditioned and Composed Image Retrieval Combining and Partially Fine-Tuning CLIP-Based Features},
    booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) Workshops},
    month     = {June},
    year      = {2022},
    pages     = {4959-4968}
}


@inproceedings{ChenK0H20,
  author    = {Ting Chen and
               Simon Kornblith and
               Mohammad Norouzi and
               Geoffrey E. Hinton},
  title     = {A Simple Framework for Contrastive Learning of Visual Representations},
  booktitle = {Proceedings of the 37th International Conference on Machine Learning,
               {ICML} 2020, 13-18 July 2020, Virtual Event},
  series    = {Proceedings of Machine Learning Research},
  volume    = {119},
  pages     = {1597--1607},
  publisher = {{PMLR}},
  year      = {2020},
  url       = {http://proceedings.mlr.press/v119/chen20j.html},
  timestamp = {Tue, 15 Dec 2020 17:40:18 +0100},
  biburl    = {https://dblp.org/rec/conf/icml/ChenK0H20.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}


@inproceedings{He0WXG20,
  author    = {Kaiming He and
               Haoqi Fan and
               Yuxin Wu and
               Saining Xie and
               Ross B. Girshick},
  title     = {Momentum Contrast for Unsupervised Visual Representation Learning},
  booktitle = {2020 {IEEE/CVF} Conference on Computer Vision and Pattern Recognition,
               {CVPR} 2020, Seattle, WA, USA, June 13-19, 2020},
  pages     = {9726--9735},
  publisher = {Computer Vision Foundation / {IEEE}},
  year      = {2020},
  url       = {https://doi.org/10.1109/CVPR42600.2020.00975},
  doi       = {10.1109/CVPR42600.2020.00975},
  timestamp = {Tue, 31 Aug 2021 14:00:04 +0200},
  biburl    = {https://dblp.org/rec/conf/cvpr/He0WXG20.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}




@inproceedings{KalantidisSPWL20,
  author    = {Yannis Kalantidis and
               Mert B{\"{u}}lent Sariyildiz and
               No{\'{e}} Pion and
               Philippe Weinzaepfel and
               Diane Larlus},
  editor    = {Hugo Larochelle and
               Marc'Aurelio Ranzato and
               Raia Hadsell and
               Maria{-}Florina Balcan and
               Hsuan{-}Tien Lin},
  title     = {Hard Negative Mixing for Contrastive Learning},
  booktitle = {Advances in Neural Information Processing Systems 33: Annual Conference
               on Neural Information Processing Systems 2020, NeurIPS 2020, December
               6-12, 2020, virtual},
  year      = {2020},
  url       = {https://proceedings.neurips.cc/paper/2020/hash/f7cade80b7cc92b991cf4d2806d6bd78-Abstract.html},
  timestamp = {Tue, 19 Jan 2021 15:56:57 +0100},
  biburl    = {https://dblp.org/rec/conf/nips/KalantidisSPWL20.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}


@inproceedings{ZhangCDL18,
  author    = {Hongyi Zhang and
               Moustapha Ciss{\'{e}} and
               Yann N. Dauphin and
               David Lopez{-}Paz},
  title     = {mixup: Beyond Empirical Risk Minimization},
  booktitle = {6th International Conference on Learning Representations, {ICLR} 2018,
               Vancouver, BC, Canada, April 30 - May 3, 2018, Conference Track Proceedings},
  publisher = {OpenReview.net},
  year      = {2018},
  url       = {https://openreview.net/forum?id=r1Ddp1-Rb},
  timestamp = {Thu, 25 Jul 2019 14:25:50 +0200},
  biburl    = {https://dblp.org/rec/conf/iclr/ZhangCDL18.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}


@inproceedings{RobinsonCSJ21,
  author    = {Joshua David Robinson and
               Ching{-}Yao Chuang and
               Suvrit Sra and
               Stefanie Jegelka},
  title     = {Contrastive Learning with Hard Negative Samples},
  booktitle = {9th International Conference on Learning Representations, {ICLR} 2021,
               Virtual Event, Austria, May 3-7, 2021},
  publisher = {OpenReview.net},
  year      = {2021},
  url       = {https://openreview.net/forum?id=CR1XOQ0UTh-},
  timestamp = {Wed, 23 Jun 2021 17:36:39 +0200},
  biburl    = {https://dblp.org/rec/conf/iclr/RobinsonCSJ21.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}


@inproceedings{HuynhKWMK22,
  author    = {Tri Huynh and
               Simon Kornblith and
               Matthew R. Walter and
               Michael Maire and
               Maryam Khademi},
  title     = {Boosting Contrastive Self-Supervised Learning with False Negative Cancellation},
  booktitle = {{IEEE/CVF} Winter Conference on Applications of Computer Vision, {WACV}
               2022, Waikoloa, HI, USA, January 3-8, 2022},
  pages     = {986--996},
  publisher = {{IEEE}},
  year      = {2022},
  url       = {https://doi.org/10.1109/WACV51458.2022.00106},
  doi       = {10.1109/WACV51458.2022.00106},
  timestamp = {Thu, 17 Feb 2022 14:51:17 +0100},
  biburl    = {https://dblp.org/rec/conf/wacv/HuynhKWMK22.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}



@inproceedings{ShahSCC22,
  author    = {Anshul Shah and
               Suvrit Sra and
               Rama Chellappa and
               Anoop Cherian},
  title     = {Max-Margin Contrastive Learning},
  booktitle = {Thirty-Sixth {AAAI} Conference on Artificial Intelligence, {AAAI}
               2022, Thirty-Fourth Conference on Innovative Applications of Artificial
               Intelligence, {IAAI} 2022, The Twelveth Symposium on Educational Advances
               in Artificial Intelligence, {EAAI} 2022 Virtual Event, February 22
               - March 1, 2022},
  pages     = {8220--8230},
  publisher = {{AAAI} Press},
  year      = {2022},
  url       = {https://ojs.aaai.org/index.php/AAAI/article/view/20796},
  timestamp = {Mon, 11 Jul 2022 16:09:32 +0200},
  biburl    = {https://dblp.org/rec/conf/aaai/ShahSCC22.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}



@article{negativesnotequal,
  author    = {Tiffany Tianhui Cai and
               Jonathan Frankle and
               David J. Schwab and
               Ari S. Morcos},
  title     = {Are all negatives created equal in contrastive instance discrimination?},
  journal   = {CoRR},
  volume    = {abs/2010.06682},
  year      = {2020},
  url       = {https://arxiv.org/abs/2010.06682},
  eprinttype = {arXiv},
  eprint    = {2010.06682},
  timestamp = {Mon, 02 Nov 2020 10:37:33 +0100},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2010-06682.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}



@article{mocov2,
  author    = {Xinlei Chen and
               Haoqi Fan and
               Ross B. Girshick and
               Kaiming He},
  title     = {Improved Baselines with Momentum Contrastive Learning},
  journal   = {CoRR},
  volume    = {abs/2003.04297},
  year      = {2020},
  url       = {https://arxiv.org/abs/2003.04297},
  eprinttype = {arXiv},
  eprint    = {2003.04297},
  timestamp = {Tue, 10 Mar 2020 13:33:48 +0100},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2003-04297.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}




@inproceedings{SoricutDSG18,
  author    = {Piyush Sharma and
               Nan Ding and
               Sebastian Goodman and
               Radu Soricut},
  editor    = {Iryna Gurevych and
               Yusuke Miyao},
  title     = {Conceptual Captions: {A} Cleaned, Hypernymed, Image Alt-text Dataset
               For Automatic Image Captioning},
  booktitle = {Proceedings of the 56th Annual Meeting of the Association for Computational
               Linguistics, {ACL} 2018, Melbourne, Australia, July 15-20, 2018, Volume
               1: Long Papers},
  pages     = {2556--2565},
  publisher = {Association for Computational Linguistics},
  year      = {2018},
  url       = {https://aclanthology.org/P18-1238/},
  doi       = {10.18653/v1/P18-1238},
  timestamp = {Tue, 16 Aug 2022 23:04:35 +0200},
  biburl    = {https://dblp.org/rec/conf/acl/SoricutDSG18.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}


@inproceedings{changpinyo2021conceptual,
  title={Conceptual 12m: Pushing web-scale image-text pre-training to recognize long-tail visual concepts},
  author={Changpinyo, Soravit and Sharma, Piyush and Ding, Nan and Soricut, Radu},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={3558--3568},
  year={2021}
}


@article{thomee2016yfcc100m,
  title={YFCC100M: The new data in multimedia research},
  author={Thomee, Bart and Shamma, David A and Friedland, Gerald and Elizalde, Benjamin and Ni, Karl and Poland, Douglas and Borth, Damian and Li, Li-Jia},
  journal={Communications of the ACM},
  volume={59},
  number={2},
  pages={64--73},
  year={2016},
  publisher={ACM New York, NY, USA}
}



@article{dosovitskiy2020image,
  title={An image is worth 16x16 words: Transformers for image recognition at scale},
  author={Dosovitskiy, Alexey and Beyer, Lucas and Kolesnikov, Alexander and Weissenborn, Dirk and Zhai, Xiaohua and Unterthiner, Thomas and Dehghani, Mostafa and Minderer, Matthias and Heigold, Georg and Gelly, Sylvain and others},
  journal={arXiv preprint arXiv:2010.11929},
  year={2020}
}




@inproceedings{wang2020understanding,
  title={Understanding contrastive representation learning through alignment and uniformity on the hypersphere},
  author={Wang, Tongzhou and Isola, Phillip},
  booktitle={International Conference on Machine Learning},
  pages={9929--9939},
  year={2020},
  organization={PMLR}
}



@inproceedings{chen2020simple,
  title={A simple framework for contrastive learning of visual representations},
  author={Chen, Ting and Kornblith, Simon and Norouzi, Mohammad and Hinton, Geoffrey},
  booktitle={International conference on machine learning},
  pages={1597--1607},
  year={2020},
  organization={PMLR}
}

@inproceedings{crowson2022vqgan,
  title={Vqgan-clip: Open domain image generation and editing with natural language guidance},
  author={Crowson, Katherine and Biderman, Stella and Kornis, Daniel and Stander, Dashiell and Hallahan, Eric and Castricato, Louis and Raff, Edward},
  booktitle={Computer Vision--ECCV 2022: 17th European Conference, Tel Aviv, Israel, October 23--27, 2022, Proceedings, Part XXXVII},
  pages={88--105},
  year={2022},
  organization={Springer}
}


@inproceedings{ramesh2021zero,
  title={Zero-shot text-to-image generation},
  author={Ramesh, Aditya and Pavlov, Mikhail and Goh, Gabriel and Gray, Scott and Voss, Chelsea and Radford, Alec and Chen, Mark and Sutskever, Ilya},
  booktitle={International Conference on Machine Learning},
  pages={8821--8831},
  year={2021},
  organization={PMLR}
}




@inproceedings{DBLP:conf/iclr/YaoHHLNXLLJX22,
  author    = {Lewei Yao and
               Runhui Huang and
               Lu Hou and
               Guansong Lu and
               Minzhe Niu and
               Hang Xu and
               Xiaodan Liang and
               Zhenguo Li and
               Xin Jiang and
               Chunjing Xu},
  title     = {{FILIP:} Fine-grained Interactive Language-Image Pre-Training},
  booktitle = {The Tenth International Conference on Learning Representations, {ICLR}
               2022, Virtual Event, April 25-29, 2022},
  publisher = {OpenReview.net},
  year      = {2022},
  url       = {https://openreview.net/forum?id=cpDhcsEDC2},
  timestamp = {Tue, 31 Jan 2023 15:18:38 +0100},
  biburl    = {https://dblp.org/rec/conf/iclr/YaoHHLNXLLJX22.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{DBLP:conf/icml/JiaYXCPPLSLD21,
  author    = {Chao Jia and
               Yinfei Yang and
               Ye Xia and
               Yi{-}Ting Chen and
               Zarana Parekh and
               Hieu Pham and
               Quoc V. Le and
               Yun{-}Hsuan Sung and
               Zhen Li and
               Tom Duerig},
  editor    = {Marina Meila and
               Tong Zhang},
  title     = {Scaling Up Visual and Vision-Language Representation Learning With
               Noisy Text Supervision},
  booktitle = {Proceedings of the 38th International Conference on Machine Learning,
               {ICML} 2021, 18-24 July 2021, Virtual Event},
  series    = {Proceedings of Machine Learning Research},
  volume    = {139},
  pages     = {4904--4916},
  publisher = {{PMLR}},
  year      = {2021},
  url       = {http://proceedings.mlr.press/v139/jia21b.html},
  timestamp = {Wed, 25 Aug 2021 17:11:17 +0200},
  biburl    = {https://dblp.org/rec/conf/icml/JiaYXCPPLSLD21.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{DBLP:journals/cviu/Fei-FeiFP07,
  author    = {Li Fei{-}Fei and
               Robert Fergus and
               Pietro Perona},
  title     = {Learning generative visual models from few training examples: An incremental
               Bayesian approach tested on 101 object categories},
  journal   = {Comput. Vis. Image Underst.},
  volume    = {106},
  number    = {1},
  pages     = {59--70},
  year      = {2007},
  url       = {https://doi.org/10.1016/j.cviu.2005.09.012},
  doi       = {10.1016/j.cviu.2005.09.012},
  timestamp = {Wed, 15 Sep 2021 14:13:01 +0200},
  biburl    = {https://dblp.org/rec/journals/cviu/Fei-FeiFP07.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{DBLP:conf/cvpr/DengDSLL009,
  author    = {Jia Deng and
               Wei Dong and
               Richard Socher and
               Li{-}Jia Li and
               Kai Li and
               Li Fei{-}Fei},
  title     = {ImageNet: {A} large-scale hierarchical image database},
  booktitle = {2009 {IEEE} Computer Society Conference on Computer Vision and Pattern
               Recognition {(CVPR} 2009), 20-25 June 2009, Miami, Florida, {USA}},
  pages     = {248--255},
  publisher = {{IEEE} Computer Society},
  year      = {2009},
  url       = {https://doi.org/10.1109/CVPR.2009.5206848},
  doi       = {10.1109/CVPR.2009.5206848},
  timestamp = {Wed, 15 Sep 2021 14:13:01 +0200},
  biburl    = {https://dblp.org/rec/conf/cvpr/DengDSLL009.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{hu2022your,
  title={Your Contrastive Learning Is Secretly Doing Stochastic Neighbor Embedding},
  author={Hu, Tianyang and Liu, Zhili and Zhou, Fengwei and Wang, Wenjia and Huang, Weiran},
  journal={arXiv preprint arXiv:2205.14814},
  year={2022}
}

@article{ma2023deciphering,
  title={Deciphering the Projection Head: Representation Evaluation Self-supervised Learning},
  author={Ma, Jiajun and Hu, Tianyang and Wang, Wenjia},
  journal={arXiv preprint arXiv:2301.12189},
  year={2023}
}

@article{pedregosa2011scikit,
  title={Scikit-learn: Machine learning in Python},
  author={Pedregosa, Fabian and Varoquaux, Ga{\"e}l and Gramfort, Alexandre and Michel, Vincent and Thirion, Bertrand and Grisel, Olivier and Blondel, Mathieu and Prettenhofer, Peter and Weiss, Ron and Dubourg, Vincent and others},
  journal={the Journal of machine Learning research},
  volume={12},
  pages={2825--2830},
  year={2011},
  publisher={JMLR. org}
}

@inproceedings{DBLP:conf/iccv/PlummerWCCHL15,
  author    = {Bryan A. Plummer and
               Liwei Wang and
               Chris M. Cervantes and
               Juan C. Caicedo and
               Julia Hockenmaier and
               Svetlana Lazebnik},
  title     = {Flickr30k Entities: Collecting Region-to-Phrase Correspondences for
               Richer Image-to-Sentence Models},
  booktitle = {2015 {IEEE} International Conference on Computer Vision, {ICCV} 2015,
               Santiago, Chile, December 7-13, 2015},
  pages     = {2641--2649},
  publisher = {{IEEE} Computer Society},
  year      = {2015},
  url       = {https://doi.org/10.1109/ICCV.2015.303},
  doi       = {10.1109/ICCV.2015.303},
  timestamp = {Wed, 16 Oct 2019 14:14:51 +0200},
  biburl    = {https://dblp.org/rec/conf/iccv/PlummerWCCHL15.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{coco,
  author    = {Tsung{-}Yi Lin and
               Michael Maire and
               Serge J. Belongie and
               James Hays and
               Pietro Perona and
               Deva Ramanan and
               Piotr Doll{\'{a}}r and
               C. Lawrence Zitnick},
  editor    = {David J. Fleet and
               Tom{\'{a}}s Pajdla and
               Bernt Schiele and
               Tinne Tuytelaars},
  title     = {Microsoft {COCO:} Common Objects in Context},
  booktitle = {Computer Vision - {ECCV} 2014 - 13th European Conference, Zurich,
               Switzerland, September 6-12, 2014, Proceedings, Part {V}},
  series    = {Lecture Notes in Computer Science},
  volume    = {8693},
  pages     = {740--755},
  publisher = {Springer},
  year      = {2014},
  url       = {https://doi.org/10.1007/978-3-319-10602-1\_48},
  doi       = {10.1007/978-3-319-10602-1\_48},
  timestamp = {Thu, 23 Jun 2022 19:55:44 +0200},
  biburl    = {https://dblp.org/rec/conf/eccv/LinMBHPRDZ14.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@misc{ray2023cola,
      title={COLA: How to adapt vision-language models to Compose Objects Localized with Attributes?}, 
      author={Arijit Ray and Filip Radenovic and Abhimanyu Dubey and Bryan A. Plummer and Ranjay Krishna and Kate Saenko},
      year={2023},
      eprint={2305.03689},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@misc{cascantebonilla2023going,
      title={Going Beyond Nouns With Vision \& Language Models Using Synthetic Data}, 
      author={Paola Cascante-Bonilla and Khaled Shehada and James Seale Smith and Sivan Doveh and Donghyun Kim and Rameswar Panda and Gül Varol and Aude Oliva and Vicente Ordonez and Rogerio Feris and Leonid Karlinsky},
      year={2023},
      eprint={2303.17590},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}
% Conceptual Material on Compositionality 
@article{cresswell1973logics,
  title={Logics and Languages},
  author={Cresswell, MJ},
  year={1973}
}
@incollection{janssen1997compositionality,
  title={Compositionality},
  author={Janssen, Theo MV and Partee, Barbara H},
  booktitle={Handbook of logic and language},
  pages={417--473},
  year={1997},
  publisher={Elsevier}
}
@article{hupkes2020compositionality,
  title={Compositionality decomposed: How do neural networks generalise?},
  author={Hupkes, Dieuwke and Dankers, Verna and Mul, Mathijs and Bruni, Elia},
  journal={Journal of Artificial Intelligence Research},
  volume={67},
  pages={757--795},
  year={2020}
}
@article{bottou2014machine,
  title={From machine learning to machine reasoning},
  author={Bottou, L{\'e}on},
  journal={Machine learning},
  volume={94},
  number={2},
  pages={133--149},
  year={2014},
  publisher={Springer}
}
@article{chomsky1965some,
  title={Some controversial questions in phonological theory},
  author={Chomsky, Noam and Halle, Morris},
  journal={Journal of linguistics},
  volume={1},
  number={2},
  pages={97--138},
  year={1965},
  publisher={Cambridge University Press}
}
@article{biederman1987recognition,
  title={Recognition-by-components: a theory of human image understanding.},
  author={Biederman, Irving},
  journal={Psychological review},
  volume={94},
  number={2},
  pages={115},
  year={1987},
  publisher={American Psychological Association}
}
@inproceedings{ji2020action,
          title={Action Genome: Actions As Compositions of Spatio-Temporal Scene Graphs},
          author={Ji, Jingwei and Krishna, Ranjay and Fei-Fei, Li and Niebles, Juan Carlos},
          booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
          pages={10236--10247},
          year={2020}
}
@inproceedings{schuster2015generating,
  title={Generating semantically precise scene graphs from textual descriptions for improved image retrieval},
  author={Schuster, Sebastian and Krishna, Ranjay and Chang, Angel and Fei-Fei, Li and Manning, Christopher D},
  booktitle={Proceedings of the fourth workshop on vision and language},
  pages={70--80},
  year={2015}
}
@inproceedings{lu2016visual,
  title={Visual relationship detection with language priors},
  author={Lu, Cewu and Krishna, Ranjay and Bernstein, Michael and Fei-Fei, Li},
  booktitle={Computer Vision--ECCV 2016: 14th European Conference, Amsterdam, The Netherlands, October 11--14, 2016, Proceedings, Part I 14},
  pages={852--869},
  year={2016},
  organization={Springer}
}
@inproceedings{GrundeMcLaughlin2021AGQA,
title={AGQA: A Benchmark for Compositional Spatio-Temporal Reasoning},
author={Grunde-McLaughlin, Madeleine and Krishna, Ranjay and Agrawala, Maneesh},
booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
year={2021}
}

% Use this file for citations not found in the ACL Anthology (contained in "anthology.bib").

@book{Aho:72,
    author  = {Alfred V. Aho and Jeffrey D. Ullman},
    title   = {The Theory of Parsing, Translation and Compiling},
    year    = "1972",
    volume  = "1",
    publisher = {Prentice-Hall},
    address = {Englewood Cliffs, NJ}
}

@book{APA:83,
    author  = {{American Psychological Association}},
    title   = {Publications Manual},
    year    = "1983",
    publisher = {American Psychological Association},
    address = {Washington, DC}
}

@misc{chatgpt,
  title = {ChatGPT},
  howpublished = {\url{https://openai.com/blog/chatgpt/}},
  author      = {OpenAI},
year        = {2023}
  
}


@book{morgan2015counterfactuals,
  title={Counterfactuals and causal inference},
  author={Morgan, Stephen L and Winship, Christopher},
  year={2015},
  publisher={Cambridge University Press}
}

@inproceedings{diwan2022winoground,
  title={Why is Winoground Hard? Investigating Failures in Visuolinguistic Compositionality},
  author={Diwan, Anuj and Berry, Layne and Choi, Eunsol and Harwath, David and Mahowald, Kyle},
  booktitle={EMNLP 2023},
  year={2022}
}


@article{lin2023visualgptscore,
  title={VisualGPTScore: Visio-Linguistic Reasoning with Multimodal Generative Pre-Training Scores},
  author={Lin, Zhiqiu and Chen, Xinyue and Pathak, Deepak and Zhang, Pengchuan and Ramanan, Deva},
  journal={arXiv preprint arXiv:2306.01879},
  year={2023}
}



@inproceedings{chen2020uniter,
  title={Uniter: Universal image-text representation learning},
  author={Chen, Yen-Chun and Li, Linjie and Yu, Licheng and El Kholy, Ahmed and Ahmed, Faisal and Gan, Zhe and Cheng, Yu and Liu, Jingjing},
  booktitle={ECCV 2020},
  pages={104--120},
  year={2020},
  organization={Springer}
}



@inproceedings{
chen2023pali,
title={Pa{LI}: A Jointly-Scaled Multilingual Language-Image Model},
author={Xi Chen and Xiao Wang and Soravit Changpinyo and AJ Piergiovanni and Piotr Padlewski and Daniel Salz and Sebastian Goodman and Adam Grycner and Basil Mustafa and Lucas Beyer and Alexander Kolesnikov and Joan Puigcerver and Nan Ding and Keran Rong and Hassan Akbari and Gaurav Mishra and Linting Xue and Ashish V Thapliyal and James Bradbury and Weicheng Kuo and Mojtaba Seyedhosseini and Chao Jia and Burcu Karagol Ayan and Carlos Riquelme Ruiz and Andreas Peter Steiner and Anelia Angelova and Xiaohua Zhai and Neil Houlsby and Radu Soricut},
booktitle={ICLR 2023},
year={2023},
url={https://openreview.net/forum?id=mWVoBz4W0u}
}



@inproceedings{zhang2021vinvl,
  title={Vinvl: Revisiting visual representations in vision-language models},
  author={Zhang, Pengchuan and Li, Xiujun and Hu, Xiaowei and Yang, Jianwei and Zhang, Lei and Wang, Lijuan and Choi, Yejin and Gao, Jianfeng},
  booktitle={CVPR 2021},
  pages={5579--5588},
  year={2021}
}





@article{chen2015microsoft,
  title={Microsoft coco captions: Data collection and evaluation server},
  author={Chen, Xinlei and Fang, Hao and Lin, Tsung-Yi and Vedantam, Ramakrishna and Gupta, Saurabh and Doll{\'a}r, Piotr and Zitnick, C Lawrence},
  journal={arXiv preprint arXiv:1504.00325},
  year={2015}
}





@inproceedings{alayrac2022flamingo,
  title={Flamingo: a visual language model for few-shot learning},
  author={Alayrac, Jean-Baptiste and Donahue, Jeff and Luc, Pauline and Miech, Antoine and Barr, Iain and Hasson, Yana and Lenc, Karel and Mensch, Arthur and Millican, Katherine and Reynolds, Malcolm and others},
  booktitle={NeurIPS 2022},
  year={2022}
}



@inproceedings{herzig2023incorporating,
  title={Incorporating structured representations into pretrained vision \& language models using scene graphs},
  author={Herzig, Roei and Mendelson, Alon and Karlinsky, Leonid and Arbelle, Assaf and Feris, Rogerio and Darrell, Trevor and Globerson, Amir},
  booktitle={EMNLP 2023},
  year={2023}
}


@inproceedings{paiss2023teaching,
  title={Teaching clip to count to ten},
  author={Paiss, Roni and Ephrat, Ariel and Tov, Omer and Zada, Shiran and Mosseri, Inbar and Irani, Michal and Dekel, Tali},
  booktitle={ICCV 2023},
  year={2023}
}


@inproceedings{doveh2023teaching,
  title={Teaching structured vision \& language concepts to vision \& language models},
  author={Doveh, Sivan and Arbelle, Assaf and Harary, Sivan and Schwartz, Eli and Herzig, Roei and Giryes, Raja and Feris, Rogerio and Panda, Rameswar and Ullman, Shimon and Karlinsky, Leonid},
  booktitle={CVPR 2023},
  pages={2657--2668},
  year={2023}
}



@article{doveh2023dense,
  title={Dense and aligned captions (dac) promote compositional reasoning in vl models},
  author={Doveh, Sivan and Arbelle, Assaf and Harary, Sivan and Herzig, Roei and Kim, Donghyun and Cascante-Bonilla, Paola and Alfassy, Amit and Panda, Rameswar and Giryes, Raja and Feris, Rogerio and others},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  pages={76137--76150},
  year={2023}
}




@inproceedings{
yarom2023what,
title={What You See is What You Read? Improving Text-Image Alignment Evaluation},
author={Michal Yarom and Yonatan Bitton and Soravit Changpinyo and Roee Aharoni and Jonathan Herzig and Oran Lang and Eran Ofek and Idan Szpektor},
booktitle={Thirty-seventh Conference on Neural Information Processing Systems},
year={2023},
url={https://openreview.net/forum?id=j5AoleAIru}
}



  @inproceedings{cai2023vipllava,
    author      = {Cai, Mu and Liu, Haotian and Mustikovela,  Siva Karthik and Meyer, Gregory P. and Chai, Yuning and Park, Dennis and Lee, Yong Jae},
    title       = {Making Large Multimodal Models Understand Arbitrary Visual Prompts},
    booktitle   = {CVPR 2024},
    year        = {2024}
  }




  @article{liu2023llava,
    author      = {Liu, Haotian and Li, Chunyuan and Wu, Qingyang and Lee, Yong Jae},
    title       = {Visual Instruction Tuning},
    journal   = {NeurIPS 2023},
    year        = {2023}
  }






@inproceedings{jia2021scaling,
  title={Scaling up visual and vision-language representation learning with noisy text supervision},
  author={Jia, Chao and Yang, Yinfei and Xia, Ye and Chen, Yi-Ting and Parekh, Zarana and Pham, Hieu and Le, Quoc and Sung, Yun-Hsuan and Li, Zhen and Duerig, Tom},
  booktitle={International conference on machine learning},
  pages={4904--4916},
  year={2021},
  organization={PMLR}
}




@article{touvron2023llama,
  title={Llama: Open and efficient foundation language models},
  author={Touvron, Hugo and Lavril, Thibaut and Izacard, Gautier and Martinet, Xavier and Lachaux, Marie-Anne and Lacroix, Timoth{\'e}e and Rozi{\`e}re, Baptiste and Goyal, Naman and Hambro, Eric and Azhar, Faisal and others},
  journal={arXiv preprint arXiv:2302.13971},
  year={2023}
}


@article{Chandra:81,
	author = {Ashok K. Chandra and Dexter C. Kozen and Larry J. Stockmeyer},
	year = "1981",
	title = {Alternation},
	journal = {Journal of the Association for Computing Machinery},
	volume = "28",
	number = "1",
	pages = "114--133",
	doi = "10.1145/322234.322243",
}

@inproceedings{andrew2007scalable,
  title={Scalable training of {L1}-regularized log-linear models},
  author={Andrew, Galen and Gao, Jianfeng},
  booktitle={Proceedings of the 24th International Conference on Machine Learning},
  pages={33--40},
  year={2007},
}

@book{Gusfield:97,
    author  = {Dan Gusfield},
    title   = {Algorithms on Strings, Trees and Sequences},
    year    = "1997",
    publisher = {Cambridge University Press},
    address = {Cambridge, UK}
}

@inproceedings{10.5555/3618408.3619222,
author = {Li, Junnan and Li, Dongxu and Savarese, Silvio and Hoi, Steven},
title = {BLIP-2: bootstrapping language-image pre-training with frozen image encoders and large language models},
year = {2023},
publisher = {JMLR.org},
abstract = {The cost of vision-and-language pre-training has become increasingly prohibitive due to end-to-end training of large-scale models. This paper proposes BLIP-2, a generic and efficient pretraining strategy that bootstraps vision-language pre-training from off-the-shelf frozen pretrained image encoders and frozen large language models. BLIP-2 bridges the modality gap with a lightweight Querying Transformer, which is pretrained in two stages. The first stage bootstraps vision-language representation learning from a frozen image encoder. The second stage bootstraps vision-to-language generative learning from a frozen language model. BLIP-2 achieves state-of-the-art performance on various vision-language tasks, despite having significantly fewer trainable parameters than existing methods. For example, our model outperforms Flamingo80B by 8.7\% on zero-shot VQAv2 with 54x fewer trainable parameters. We also demonstrate the model's capabilities of zero-shot image-to-text generation that can follow natural language instructions.},
booktitle = {Proceedings of the 40th International Conference on Machine Learning},
articleno = {814},
numpages = {13},
location = {Honolulu, Hawaii, USA},
series = {ICML'23}
}



@article{rasooli-tetrault-2015,
    author    = {Mohammad Sadegh Rasooli and Joel R. Tetreault},
    title     = {Yara Parser: {A} Fast and Accurate Dependency Parser},
    journal   = {Computing Research Repository},
    volume    = {arXiv:1503.06733},
    year      = {2015},
    url       = {http://arxiv.org/abs/1503.06733},
    note    = {version 2}
}

@article{Ando2005,
	Acmid = {1194905},
	Author = {Ando, Rie Kubota and Zhang, Tong},
	Issn = {1532-4435},
	Issue_Date = {12/1/2005},
	Journal = {Journal of Machine Learning Research},
	Month = dec,
	Numpages = {37},
	Pages = {1817--1853},
	Publisher = {JMLR.org},
	Title = {A Framework for Learning Predictive Structures from Multiple Tasks and Unlabeled Data},
	Volume = {6},
	Year = {2005}
}

@misc{plummer2016flickr30k,
      title={Flickr30k Entities: Collecting Region-to-Phrase Correspondences for Richer Image-to-Sentence Models}, 
      author={Bryan A. Plummer and Liwei Wang and Chris M. Cervantes and Juan C. Caicedo and Julia Hockenmaier and Svetlana Lazebnik},
      year={2016},
      eprint={1505.04870},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@misc{young2014flickr30k,
    title={From image descriptions to visual denotations: New similarity metrics for semantic inference over event descriptions},
    author={Peter Young and Alice Lai and Micah Hodosh and Julia Hockenmaier},
    year={2014},
    journal={Transactions of the Association for Computational Linguistics},
    volume={2(Feb):67-78},
    url={https://shannon.cs.illinois.edu/DenotationGraph/}
}

@inproceedings{li2023gligen,
      title={GLIGEN: Open-Set Grounded Text-to-Image Generation}, 
      author={Yuheng Li and Haotian Liu and Qingyang Wu and Fangzhou Mu and Jianwei Yang and Jianfeng Gao and Chunyuan Li and Yong Jae Lee},
      year={2023},
      booktitle={CVPR 2023}
}

@misc{openai2023gpt4,
      title={GPT-4 Technical Report}, 
      author={OpenAI},
      year={2023},
      eprint={2303.08774},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{openai2023GPT4V,
    title={GPT-4V(ision) System Card},
    author={OpenAI},
    year={2023},
    url={https://cdn.openai.com/papers/GPTV_System_Card.pdf}
}

@article{hertz2022prompt,
  title={Prompt-to-prompt image editing with cross attention control},
  author={Hertz, Amir and Mokady, Ron and Tenenbaum, Jay and Aberman, Kfir and Pritch, Yael and Cohen-Or, Daniel},
  journal={ICLR 2023},
  year={2023}
}



@inproceedings{le2023cococounterfactuals,
      title={COCO-Counterfactuals: Automatically Constructed Counterfactual Examples for Image-Text Pairs}, 
      author={Tiep Le and Vasudev Lal and Phillip Howard},
      year={2023},
      booktitle={NeurIPS 2023}
}

@misc{openai2023DALLE3,
    title={Improving Image Generation with Better Captions},
    author={James Betker and Gabriel Goh and Li Jing and Tim Brooks and Jianfeng Wang and Linjie Li and Long Ouyang and Juntang Zhuang and Joyce Lee and Yufei Guo and Wesam Manassra and Prafulla Dhariwal and Casey Chu and Yunxin Jiao and Aditya Ramesh},
    year={2023},
    url={https://cdn.openai.com/papers/dall-e-3.pdf}
}

@misc{ilharco2021openclip,
        author={Gabriel Ilharco and Mitchell Wortsman and Ross Wightman and Cade Gordon and Nicholas Carlini and Rohan Taori and Achal Dave and Vaishaal Shankar and Hongseok Namkoong and John Miller and Hannaneh Hajishirzi and Ali Farhadi and Ludwig Schmidt},
        title={OpenCLIP},
        year={2021},
        version={0.1},
        doi={10.5281/zenodo.5143773},
        url={https://doi.org/10.5281/zenodo.5143773}
}



@misc{schuhmann2022laion5b,
      title={LAION-5B: An open large-scale dataset for training next generation image-text models}, 
      author={Christoph Schuhmann and Romain Beaumont and Richard Vencu and Cade Gordon and Ross Wightman and Mehdi Cherti and Theo Coombes and Aarush Katta and Clayton Mullis and Mitchell Wortsman and Patrick Schramowski and Srivatsa Kundurthy and Katherine Crowson and Ludwig Schmidt and Robert Kaczmarczyk and Jenia Jitsev},
      year={2022},
      eprint={2210.08402},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@inproceedings{liu2023improved,
      title={Improved Baselines with Visual Instruction Tuning}, 
      author={Haotian Liu and Chunyuan Li and Yuheng Li and Yong Jae Lee},
      year={2023},
      booktitle={CVPR 2024}
}

@inproceedings{hsieh2023sugarcrepe,
      title={SugarCrepe: Fixing Hackable Benchmarks for Vision-Language Compositionality}, 
      author={Cheng-Yu Hsieh and Jieyu Zhang and Zixian Ma and Aniruddha Kembhavi and Ranjay Krishna},
      year={2023},
      booktitle={NeurIPS 2023}
}

@misc{mani2022point,
      title={Point and Ask: Incorporating Pointing into Visual Question Answering}, 
      author={Arjun Mani and Nobline Yoo and Will Hinthorn and Olga Russakovsky},
      year={2022},
      eprint={2011.13681},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@inproceedings{lin2015microsoft,
      title={Microsoft COCO: Common Objects in Context}, 
      author={Tsung-Yi Lin and Michael Maire and Serge Belongie and Lubomir Bourdev and Ross Girshick and James Hays and Pietro Perona and Deva Ramanan and C. Lawrence Zitnick and Piotr Dollár},
      year={2014},
      booktitle={ECCV 2014}
}


@misc{liu2024llavanext,
    title={LLaVA-NeXT: Improved reasoning, OCR, and world knowledge},
    url={https://llava-vl.github.io/blog/2024-01-30-llava-next/},
    author={Liu, Haotian and Li, Chunyuan and Li, Yuheng and Li, Bo and Zhang, Yuanhan and Shen, Sheng and Lee, Yong Jae},
    month={January},
    year={2024}
}

@INPROCEEDINGS{Hendrycks2021-mf,
  title           = "Natural Adversarial Examples",
  booktitle       = "CVPR 2021",
  author          = "Hendrycks, Dan and Zhao, Kevin and Basart, Steven and
                     Steinhardt, Jacob and Song, Dawn",
  publisher       = "IEEE",
  month           =  jun,
  year            =  2021,
  conference      = "2021 IEEE/CVF Conference on Computer Vision and Pattern
                     Recognition (CVPR)",
  location        = "Nashville, TN, USA"
}

@INPROCEEDINGS{Ginger_undated-uz,
  title     = "Are we ready for Autonomous Driving?",
  booktitle = "CVPR 2021",
  author    = "Ginger, Andreas and Lenz, Philip and Urtasun, Raquel",
  year = 2021
}

@ARTICLE{Helber2019-gi,
  title     = "{EuroSAT}: A novel dataset and deep learning benchmark for land
               use and land cover classification",
  author    = "Helber, Patrick and Bischke, Benjamin and Dengel, Andreas and
               Borth, Damian",
  journal   = "IEEE J. Sel. Top. Appl. Earth Obs. Remote Sens.",
  publisher = "Institute of Electrical and Electronics Engineers (IEEE)",
  volume    =  12,
  number    =  7,
  pages     = "2217--2226",
  month     =  jul,
  year      =  2019,
  copyright = "https://ieeexplore.ieee.org/Xplorehelp/downloads/license-information/IEEE.html"
}

@ARTICLE{Everingham2015-lg,
  title     = "The pascal visual object classes challenge: A retrospective",
  author    = "Everingham, Mark and Eslami, S M Ali and Van Gool, Luc and
               Williams, Christopher K I and Winn, John and Zisserman, Andrew",
  journal   = "Int. J. Comput. Vis.",
  publisher = "Springer Science and Business Media LLC",
  volume    =  111,
  number    =  1,
  pages     = "98--136",
  month     =  jan,
  year      =  2015,
  language  = "en"
}
@misc{kamath2023whatsupvisionlanguagemodels,
      title={What's "up" with vision-language models? Investigating their struggle with spatial reasoning}, 
      author={Amita Kamath and Jack Hessel and Kai-Wei Chang},
      year={2023},
      eprint={2310.19785},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2310.19785}, 
}
@misc{hsieh2023sugarcrepefixinghackablebenchmarks,
      title={SugarCrepe: Fixing Hackable Benchmarks for Vision-Language Compositionality}, 
      author={Cheng-Yu Hsieh and Jieyu Zhang and Zixian Ma and Aniruddha Kembhavi and Ranjay Krishna},
      year={2023},
      eprint={2306.14610},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2306.14610}, 
}

@inproceedings{radford2021learning,
  title={Learning transferable visual models from natural language supervision},
  author={Radford, Alec and Kim, Jong Wook and Hallacy, Chris and Ramesh, Aditya and Goh, Gabriel and Agarwal, Sandhini and Sastry, Girish and Askell, Amanda and Mishkin, Pamela and Clark, Jack and others},
  booktitle={International conference on machine learning},
  pages={8748--8763},
  year={2021},
  organization={PMLR}
}
@misc{yuksekgonul2023visionlanguagemodelsbehavelike,
      title={When and why vision-language models behave like bags-of-words, and what to do about it?}, 
      author={Mert Yuksekgonul and Federico Bianchi and Pratyusha Kalluri and Dan Jurafsky and James Zou},
      year={2023},
      eprint={2210.01936},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2210.01936}, 
}
@misc{zhang2024countercurateenhancingphysicalsemantic,
      title={CounterCurate: Enhancing Physical and Semantic Visio-Linguistic Compositional Reasoning via Counterfactual Examples}, 
      author={Jianrui Zhang and Mu Cai and Tengyang Xie and Yong Jae Lee},
      year={2024},
      eprint={2402.13254},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2402.13254}, 
}
@INPROCEEDINGS{bordes2023pugphotorealisticsemanticallycontrollable,
 author = {Bordes, Florian and Shekhar, Shashank and Ibrahim, Mark and Bouchacourt, Diane and Vincent, Pascal and Morcos, Ari},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {A. Oh and T. Naumann and A. Globerson and K. Saenko and M. Hardt and S. Levine},
 pages = {45020--45054},
 publisher = {Curran Associates, Inc.},
 title = {PUG: Photorealistic and Semantically Controllable Synthetic Data for Representation Learning},
 url = {https://proceedings.neurips.cc/paper_files/paper/2023/file/8d352fd0f07fde4a74f9476603b3773b-Paper-Datasets_and_Benchmarks.pdf},
 volume = {36},
 year = {2023}
}

@article{Johnson2016CLEVRAD,
  title={CLEVR: A Diagnostic Dataset for Compositional Language and Elementary Visual Reasoning},
  author={Justin Johnson and Bharath Hariharan and Laurens van der Maaten and Li Fei-Fei and C. Lawrence Zitnick and Ross B. Girshick},
  journal={2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2016},
  pages={1988-1997},
  url={https://api.semanticscholar.org/CorpusID:15458100}
}
@misc{zhang2024contrastingintramodalrankingcrossmodal,
      title={Contrasting Intra-Modal and Ranking Cross-Modal Hard Negatives to Enhance Visio-Linguistic Compositional Understanding}, 
      author={Le Zhang and Rabiul Awal and Aishwarya Agrawal},
      year={2024},
      eprint={2306.08832},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2306.08832}, 
}


@misc{zeng2022multigrainedvisionlanguagepretraining,
      title={Multi-Grained Vision Language Pre-Training: Aligning Texts with Visual Concepts}, 
      author={Yan Zeng and Xinsong Zhang and Hang Li},
      year={2022},
      eprint={2111.08276},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2111.08276}, 
}
@misc{schuhmann2022laion5bopenlargescaledataset,
      title={LAION-5B: An open large-scale dataset for training next generation image-text models}, 
      author={Christoph Schuhmann and Romain Beaumont and Richard Vencu and Cade Gordon and Ross Wightman and Mehdi Cherti and Theo Coombes and Aarush Katta and Clayton Mullis and Mitchell Wortsman and Patrick Schramowski and Srivatsa Kundurthy and Katherine Crowson and Ludwig Schmidt and Robert Kaczmarczyk and Jenia Jitsev},
      year={2022},
      eprint={2210.08402},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2210.08402}, 
}
@misc{changpinyo2021conceptual12mpushingwebscale,
      title={Conceptual 12M: Pushing Web-Scale Image-Text Pre-Training To Recognize Long-Tail Visual Concepts}, 
      author={Soravit Changpinyo and Piyush Sharma and Nan Ding and Radu Soricut},
      year={2021},
      eprint={2102.08981},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2102.08981}, 
}

@misc{liu2023visualinstructiontuning,
      title={Visual Instruction Tuning}, 
      author={Haotian Liu and Chunyuan Li and Qingyang Wu and Yong Jae Lee},
      year={2023},
      eprint={2304.08485},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2304.08485}, 
}

@misc{dai2023instructblipgeneralpurposevisionlanguagemodels,
      title={InstructBLIP: Towards General-purpose Vision-Language Models with Instruction Tuning}, 
      author={Wenliang Dai and Junnan Li and Dongxu Li and Anthony Meng Huat Tiong and Junqi Zhao and Weisheng Wang and Boyang Li and Pascale Fung and Steven Hoi},
      year={2023},
      eprint={2305.06500},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2305.06500}, 
}
@misc{beyer2024paligemmaversatile3bvlm,
      title={PaliGemma: A versatile 3B VLM for transfer}, 
      author={Lucas Beyer and Andreas Steiner and André Susano Pinto and Alexander Kolesnikov and Xiao Wang and Daniel Salz and Maxim Neumann and Ibrahim Alabdulmohsin and Michael Tschannen and Emanuele Bugliarello and Thomas Unterthiner and Daniel Keysers and Skanda Koppula and Fangyu Liu and Adam Grycner and Alexey Gritsenko and Neil Houlsby and Manoj Kumar and Keran Rong and Julian Eisenschlos and Rishabh Kabra and Matthias Bauer and Matko Bošnjak and Xi Chen and Matthias Minderer and Paul Voigtlaender and Ioana Bica and Ivana Balazevic and Joan Puigcerver and Pinelopi Papalampidi and Olivier Henaff and Xi Xiong and Radu Soricut and Jeremiah Harmsen and Xiaohua Zhai},
      year={2024},
      eprint={2407.07726},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2407.07726}, 
}
@misc{chen2023palijointlyscaledmultilinguallanguageimage,
      title={PaLI: A Jointly-Scaled Multilingual Language-Image Model}, 
      author={Xi Chen and Xiao Wang and Soravit Changpinyo and AJ Piergiovanni and Piotr Padlewski and Daniel Salz and Sebastian Goodman and Adam Grycner and Basil Mustafa and Lucas Beyer and Alexander Kolesnikov and Joan Puigcerver and Nan Ding and Keran Rong and Hassan Akbari and Gaurav Mishra and Linting Xue and Ashish Thapliyal and James Bradbury and Weicheng Kuo and Mojtaba Seyedhosseini and Chao Jia and Burcu Karagol Ayan and Carlos Riquelme and Andreas Steiner and Anelia Angelova and Xiaohua Zhai and Neil Houlsby and Radu Soricut},
      year={2023},
      eprint={2209.06794},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2209.06794}, 
}
@misc{zhai2022litzeroshottransferlockedimage,
      title={LiT: Zero-Shot Transfer with Locked-image text Tuning}, 
      author={Xiaohua Zhai and Xiao Wang and Basil Mustafa and Andreas Steiner and Daniel Keysers and Alexander Kolesnikov and Lucas Beyer},
      year={2022},
      eprint={2111.07991},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2111.07991}, 
}
@misc{metzen2024autoclipautotuningzeroshotclassifiers,
      title={AutoCLIP: Auto-tuning Zero-Shot Classifiers for Vision-Language Models}, 
      author={Jan Hendrik Metzen and Piyapat Saranrittichai and Chaithanya Kumar Mummadi},
      year={2024},
      eprint={2309.16414},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2309.16414}, 
}

@misc{gao2021clipadapterbettervisionlanguagemodels,
      title={CLIP-Adapter: Better Vision-Language Models with Feature Adapters}, 
      author={Peng Gao and Shijie Geng and Renrui Zhang and Teli Ma and Rongyao Fang and Yongfeng Zhang and Hongsheng Li and Yu Qiao},
      year={2021},
      eprint={2110.04544},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2110.04544}, 
}

@misc{podell2023sdxlimprovinglatentdiffusion,
      title={SDXL: Improving Latent Diffusion Models for High-Resolution Image Synthesis}, 
      author={Dustin Podell and Zion English and Kyle Lacey and Andreas Blattmann and Tim Dockhorn and Jonas Müller and Joe Penna and Robin Rombach},
      year={2023},
      eprint={2307.01952},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2307.01952}, 
}
@misc{abdal2021clip2styleganunsupervisedextractionstylegan,
      title={CLIP2StyleGAN: Unsupervised Extraction of StyleGAN Edit Directions}, 
      author={Rameen Abdal and Peihao Zhu and John Femiani and Niloy J. Mitra and Peter Wonka},
      year={2021},
      eprint={2112.05219},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2112.05219}, 
}

@misc{saharia2022photorealistictexttoimagediffusionmodels,
      title={Photorealistic Text-to-Image Diffusion Models with Deep Language Understanding}, 
      author={Chitwan Saharia and William Chan and Saurabh Saxena and Lala Li and Jay Whang and Emily Denton and Seyed Kamyar Seyed Ghasemipour and Burcu Karagol Ayan and S. Sara Mahdavi and Rapha Gontijo Lopes and Tim Salimans and Jonathan Ho and David J Fleet and Mohammad Norouzi},
      year={2022},
      eprint={2205.11487},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2205.11487}, 
}

@proceedings{hessel-etal-2021-clipscore,
    title = "{CLIPS}core: A Reference-free Evaluation Metric for Image Captioning",
    author = "Hessel, Jack  and
      Holtzman, Ari  and
      Forbes, Maxwell  and
      Le Bras, Ronan  and
      Choi, Yejin",
    editor = "Moens, Marie-Francine  and
      Huang, Xuanjing  and
      Specia, Lucia  and
      Yih, Scott Wen-tau",
    booktitle = "Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing",
    month = nov,
    year = "2021",
    address = "Online and Punta Cana, Dominican Republic",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.emnlp-main.595",
    doi = "10.18653/v1/2021.emnlp-main.595",
    pages = "7514--7528",
    abstract = "Image captioning has conventionally relied on reference-based automatic evaluations, where machine captions are compared against captions written by humans. This is in contrast to the reference-free manner in which humans assess caption quality. In this paper, we report the surprising empirical finding that CLIP (Radford et al., 2021), a cross-modal model pretrained on 400M image+caption pairs from the web, can be used for robust automatic evaluation of image captioning without the need for references. Experiments spanning several corpora demonstrate that our new reference-free metric, CLIPScore, achieves the highest correlation with human judgements, outperforming existing reference-based metrics like CIDEr and SPICE. Information gain experiments demonstrate that CLIPScore, with its tight focus on image-text compatibility, is complementary to existing reference-based metrics that emphasize text-text similarities. Thus, we also present a reference-augmented version, RefCLIPScore, which achieves even higher correlation. Beyond literal description tasks, several case studies reveal domains where CLIPScore performs well (clip-art images, alt-text rating), but also where it is relatively weaker in comparison to reference-based metrics, e.g., news captions that require richer contextual knowledge.",
}
@misc{xu2022groupvitsemanticsegmentationemerges,
      title={GroupViT: Semantic Segmentation Emerges from Text Supervision}, 
      author={Jiarui Xu and Shalini De Mello and Sifei Liu and Wonmin Byeon and Thomas Breuel and Jan Kautz and Xiaolong Wang},
      year={2022},
      eprint={2202.11094},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2202.11094}, 
}
@misc{zhai2023sigmoidlosslanguageimage,
      title={Sigmoid Loss for Language Image Pre-Training}, 
      author={Xiaohua Zhai and Basil Mustafa and Alexander Kolesnikov and Lucas Beyer},
      year={2023},
      eprint={2303.15343},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2303.15343}, 
}
@misc{cho2023finegrainedimagecaptioningclip,
      title={Fine-grained Image Captioning with CLIP Reward}, 
      author={Jaemin Cho and Seunghyun Yoon and Ajinkya Kale and Franck Dernoncourt and Trung Bui and Mohit Bansal},
      year={2023},
      eprint={2205.13115},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2205.13115}, 
}

@inproceedings{changpinyo2021cc12m,
  title = {{Conceptual 12M}: Pushing Web-Scale Image-Text Pre-Training To Recognize Long-Tail Visual Concepts},
  author = {Changpinyo, Soravit and Sharma, Piyush and Ding, Nan and Soricut, Radu},
  booktitle = {CVPR},
  year = {2021},
}

@article{finiimproved,
  title={Improved baselines for vision-language pre-training},
  author={Fini, Enrico and Astolfi, Pietro and Romero-Soriano, Adriana and Verbeek, Jakob and Drozdzal, Michal},
  year={2023},
  journal={Transactions on Machine Learning Research}
}

@article{bordes2024introduction,
  title={An introduction to vision-language modeling},
  author={Bordes, Florian and Pang, Richard Yuanzhe and Ajay, Anurag and Li, Alexander C and Bardes, Adrien and Petryk, Suzanne and Ma{\~n}as, Oscar and Lin, Zhiqiu and Mahmoud, Anas and Jayaraman, Bargav and others},
  journal={arXiv preprint arXiv:2405.17247},
  year={2024}
}