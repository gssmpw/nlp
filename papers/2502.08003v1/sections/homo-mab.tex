\section{Warm-up: Single Cluster (Homogeneous Clients)}\label{sec:homo}

This section studies the single-cluster multi-agent MAB, focusing on in-cluster learning and serving as a didactic warm-up for the multi-cluster scenarios discussed in later sections. Here, all clients belong to the same cluster and share a homogeneous reward environment. Although there is existing work on homogeneous multi-agent multi-armed bandits \citep{wang2023achieve,wang2020optimal}, our model introduces a time-varying random graph $G_t$, which has not yet been studied.
In this homogeneous setting, all clients have the same reward distribution for each arm. Consequently, observations from different clients can be combined to improve the estimation of an arm's reward distribution, leading to a more efficient exploration-exploitation trade-off compared to the single-agent case.
We first present a simple UCB algorithm in Section~\ref{subsec:homo-ucb}, followed by its regret upper bound in Section~\ref{subsec:homo-ucb-bound}.




\subsection{Algorithm}\label{subsec:homo-ucb}

Since clients are homogeneous, we propose a simple cooperative Upper Confidence Bounds (UCB) algorithm. Over the whole learning process, every client \(m\) maintains the UCB index for each arm \(k\) as follows, $u_{k,t}\upbra{m} \coloneqq \hat{\mu}_{k,t}\upbra{m} + \sqrt{\nicefrac{\log t}{\tilde N_{k,t}\upbra{m}}},$
where \(
\tilde N_{k,t}\upbra{m} =
N_{k,t}\upbra{m}
+ \sum_{m'\in\mathcal{M}\setminus \{m\}} N_{k,\tau_t\upbra{m\leftrightarrow m'}}\upbra{m'}
\)
% \todo{consider the impact of message propagation from multi-hop. Maybe directly give a \(N_{k,t}\upbra{-m}\) to roughly represent all received the messages due to propagation.}
is the total number of observations of arm \(k\) that client \(m\) collects, including its own \(N_{k,t}\upbra{m}\) local observations and the \(N_{k,\tau_t\upbra{m\leftrightarrow m'}}\upbra{m'}\) observations collected from its neighbors \(m'\in\mathcal{M}\setminus \{m\}\) at the latest communication time slot \(\tau_t\upbra{m\leftrightarrow m'}\) between these two clients \(m\) and \(m'\) on or before time slot \(t\).
The empirical mean \(\hat\mu_{k,t}\upbra{m}\) is also the average of all \(\tilde N_{k,t}\upbra{m}\) observations of arm \(k\) that client \(m\) collects. The clients pull the arm with the highest UCB index, i.e. $a_m^t = argmax_{k}u_{k,t}^m$, and receive the reward.

\iffalse
\begin{algorithm2e}[tp]
    \SetAlgoLined
    \caption{Single Cluster (Homogeneous) UCB}\label{alg:homo-ucb}
    \textbf{Initialization:}\par
    \For{$t = 1, \ldots,T$}{
    \For(\tcp*[f]{UCB}){each client m}{
        $a_m^t = \argmax_i \Tilde{\mu}_{m,i}(t) + F(m,i,t)$\;
        Pull arm $a_m^t$ and receive reward $r_{m,a_m^t}(t)$\;
    }
    The environment generates a sample graph $G_t = (V,E_t)$ based on SBM;\tcp*[f]{Env} \par
    Each client $m$ sends $r_i^m(t),N_{j,i}(t),\bar{\mu}_i^m(t), \Tilde{\mu}_i^m(t)$ to each client in $\mathcal{N}_m(t)$;\label{line:send}\par
    Each client $m$ receives $r_i^j(t),N_{j,i}(t),\bar{\mu}_i^j(t), \Tilde{\mu}_i^j(t)$ from all clients $j \in \mathcal{N}_m(t)$ and stores them as $\hat{\mu}_{i,j}^{m}(t),\hat{N}_{i,j}^{m}(t),\hat{\bar{\mu}}_{i,j}^{m}(t), \hat{\Tilde{\mu}}_{i,j}^{m}(t)$; \tcp*[f]{Transmission}\par
    %given a limited time period\;
    %\For{$i=1,\ldots,K$}{
    %$\tilde{r}_i(t)$ is estimated by $\frac{\sum_{j\in \mathcal{N}_M} r_{j,i}(t) \cdot \mathds{1}_{a_j^t = i}}{\sum_{j\in \mathcal{N}_M} 1 \cdot \mathds{1}_{a_j^t = i}}$\;
    %}
    \For{each client m}{
    \For{ $i =1, \ldots, K$}{
    %$\hat{\mu}_{m,i}(t) = \frac{\hat{\mu}_{m,i}(t) \cdot n_{m,a_m^t}(t) + \tilde{r}_{i}(t) \cdot \mathds{1}_{\{\exists j \in {\mathcal{N}_m}, a_j^t = i\}}}{n_{m,i}(scre)}$\;
    %$n_{m,i}(t+1) = n_{m,i}(t) + \mathds{1}_{\{\exists j \in {\mathcal{N}_m}, a_j^t = i\}}$
    Update $P_t$ for $1 \leq j \leq M$ by $P_t(m,j) = \frac{(t-1)P_{t-1}(m,j)+X_{m,j}^t}{t}$\;\par
    Update $P_t^{\prime}$ for $1 \leq j \leq M$ by $
        P_t^{\prime}(m,j) =
        \begin{cases}
            1 & \text{if } P_t(m,j) > 0 \\
            0 & \text{if } P_t(m,j) = 0
        \end{cases}$\;\par
    \eIf{$t \mod \tau = 0$ }{ Update $n_{m,i}(t), N_{m,i}(t), \Tilde{N}_{m,i}(t)$ and $\Tilde{\mu}^m_i(t)$ based on \textbf{Rule 1} or \textbf{Rule 2}}
    {  Update $n_{m,i}(t)$ as $n_{m,i}(t) = n_{m,i}(t) + 1_{a_m^t = i}$
    }
    }}
    }
\end{algorithm2e}
\fi 

\subsection{Regret Analysis}\label{subsec:homo-ucb-bound}

%Theorem~\ref{thm:homo-ucb} presents the regret upper bound of the method.

\begin{theorem}\label{thm:homo-ucb}
    Executing the above algorithm leads to $ \mathbb{E}[R_T] \le O\left(\sum_{k\neq k^*} \frac{\log T}{M\Delta_k}
        + \frac{K}{p^{M^2}} 
        \right).~\refstepcounter{equation}(\theequation)\label{eq:homo-ucb}$ 
\end{theorem}
\vspace{-5mm}
\begin{proof}[Proof Sketch]
    The full proof is in Appendix \ref{app:proof}; the main intuition is as follows. Fix a suboptimal arm \(k\). After the total number of observations for this arm \(k\) exceeds the sample complexity threshold, in expectation, it takes \(\frac{1}{p^{M^2}}\) time slots for all agents to get the information of this arm \(k\).
    After that, no more regret will be incurred on this arm \(k\). As a result, the proof first makes an assumption to reduce the problem to a standard cooperative UCB for homogeneous agents residing on a complete graph with communication delays.
    Then, we show that this assumption can be fulfilled in the single cluster scenario.
\end{proof}

The leading \(O(\log T)\) term of the total regret $R_T^M = M \cdot R_T$ by multiplying $M$ and ~\eqref{eq:homo-ucb} is independent of the number of agents \(M\), highlighting the advantage of multi-agent cooperation. Meanwhile, it is worth noting that in heterogeneous setting in \citep{xu2023decentralized}, the upper bound of the total regret $R_T^M$ is of order $O(M^2\log{T})$ (though it is not tight as illustrated in Section \ref{sec:heter}), rather than $O(\log{T})$ which emphasizes the regret reduction by our analysis in homogeneous settings. The second term of~\eqref{eq:homo-ucb}, however, has a dependence of \(p^{-M}\) where $p = p(m,m)$. It suggests the importance of the edge generation probability \(p\), which will be thoroughly addressed in Section \ref{sec:heter} and Section \ref{sec:heter-unknown}.


%\paragraph{$l$-periodically connected}

% the regret without communication is at most \(O(MK\log T)\) which is much lower than the \(O(MT)\) regret in federated multi-armed bandits. Hence, the requirement of communication period \(T_0\) (\tdmark~can we make \(T_0\) constant by adding a lower bound to \(p\).) is much weaker than that of the federated case. Setting period \(T_0 = \log_{\frac{1}{1-p}} T\) with corresponding high probability \(1 - \frac{1}{T}\) is enough. That leads to
% The current regret upper bound is not satisfactory in two perspectives: \begin{itemize}
%     \item[\tdmark] The \(\log \frac{1}{1-p}\) term is artificial: when \(p\to  1\), the problem becomes much easier, but the regret upper bound becomes much larger.
%     \item[\tdmark] The \(M\log T\) term is due to the delayed communication. But that delay is much smaller than the doubling grid whose gap can be as large as \(T/2\). So, some approaches should also exist to reduce the \(M\log T\) term.
%           \begin{itemize}
%               \item Need to search for some communication technique that the remove the dependence on delay.
%           \end{itemize}
%     \item
% \end{itemize}

% Other potential challenges:
% \begin{itemize}
%     \item[\tdmark] As the communication is random between agents, how each agent can get \(O(M)\) other agents' information with high probability needs another stochastic analysis.
% \end{itemize}


% The following results seems problematic: Especially the Step 2 in the proof induces a \(T^{-\Delta_{\min}^2}\) failure probability, which, after union bound over all batches, becomes to large to cancel out a \(KM\log T/\Delta_{\min}\) regret bound.


% \[
%     p \ge 1 - \exp(-\Delta_{\min}^4)
% \]

% Proof Sketch:

% \paragraph{Step 1: Split the \(T\) time horizon into multiple batches, each with \(\frac{\log T}{\log (1-p)^{-1/\Delta_{\min}^2}}\)}

% \paragraph{Step 2: Inside each batch, there is at least one communication betten any two agents with high probability}

% \paragraph{Step 3: These uniform batch based communication grid is more informative than the \(\log T\) geometric grid; Espeically, the first batch does not hurt the final \(O(K\log T)\) regret.}
