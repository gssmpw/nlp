\section{Conclusion}
This work aims to improve the tool execution of the LLM agent workflow for scientific applications, especially those requires heavy computing. 
Using MD simulation as the example task, we designed and tested two different Parsl implementation on both local workstation and HPC system. 
With Parsl, we can work on the high-level Python language, and express the parallelism with simple decorators and safe execution. 
The Parsl parallelism was implemented at different layers of tool execution in these two setups.  
It resulted in difference in the application, compatibility and ease-to-use between two implementation. 

The first implementation incorporated Parsl parallel execution in the tool node layer. 
Therefore, all the invoked tool functions were converted into a Parsl python function and submited to the workers. 
This setup requires no change to the tool functions. 
But all the tool functions that bound with the LLM agent, are executed with Parsl, including the download functions in our application. 
This is adequate for the workflow on the local workstation, where all tasks are carried out with local resource and a simple universal computing environment. 

Once implemented this setup on the Polaris system, we noticed the LLM agent had an upper call limits for the tools, and different system environments on the login and computing node also affected the workflow execution. 
For example, the computing node had no internet access by default, and the queue time was long on the HPC system despite the workload of the task. 
Therefore, it is unnecessary to execute all tools on the computing queue. 

We then developed the second implementation of Parsl ensemble tool function, where the Parsl parallelism was only set up for the expensive simulation functions. 
Instead of calling a function to run one simulation, the simulation function now invokes a simulation ensemble that ran multiple simulation concurrently. 
This gives more flexibilities of how and where the tasks are executed. 
However, it is now the user's responsibility to develop the simulation ensemble function with Parsl. 

We also implemented two workflows for scientific tasks with different requirements of external information. 
When exact information, such as file path or PDB ID for MD simulation, is present, the AI workflow can identify from the given prompts and invoke the simulation functions. 
Additional information is essential when only generic instruction is included in the prompt. 

Our implementation enables the LLM agent to access any compatible computing resource through Parsl.
Both setups add to the ability of LLM agent to call and assign right function arguments to the tools, of distributing the task execution via Parsl to the system computing resource (GPUs in our applications). 
Due to the LLM tool call limitation and computing system requirement, it still requires tailoring of the tool call setup depending on the tasks and computing platforms. 

Designing the tool function is another important requirement for the LLM agent workflow. 
The scientific application is the combination of flexible AI calls/executions and rigid step-by-step scientific protocol. 
The former enables the workflow to make decision on which function to call and assigning the right function arguments. 
The latter is well-defined in the practice of many scientific domains. 
For example, the MD simulation requires the setup of topology that includes all the molecular interactions. 
We can merge the topology building and simulation function, as they are always execution sequentially. 
This end-to-end design is less dependent on the LLM agents, and less likely to err, but too rigid for more sophisticated tasks. 
For the analysis step, it requires independent functions to carry out different methods, such RMSD, RMSF, radius of gyration, et al. 
The splitting of the scientific protocol into LLM agent tool steps is crucial for designing versatile LLM agent workflow for scientific applications. 

The future work will focus on how to make more capable LLM agent workflow for scientific research application. 
For example, AI-enhanced sampling of molecular simulations~\cite{ma2020deep_ddmd,brace2022coupling_ddmd,lee2019deepdrivemd_ddmd} can be implemented with Parsl-enabled LLM agent network, with more carefully designed workflows, agents and tools~\cite{nadeem2024optimizing_policy}. 
With Parsl to manage the computing tasks and resource, the workflow can leverage the current HPC platform, such as Aurora/ALCF, frontier/OLCF, etc. 
Furthermore, the human-in-loop design can also give the real-time user feedback or intervention to the workflow. 
We are also working on the expanding the capability of the workflow, by reducing the user interaction with Parsl, implementing function environment management, improving logging and checkpointing, and enabling asynchronous execution of different tool functions. 




% - two different implementations 
% - injection of Parsl 
% - design of the tools
% - compatibility with the computing
% - LLM agents as workflow manager