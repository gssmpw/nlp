\section{Related Work}
\subsection{Scene Flow Estimation Methods}
Scene flow estimation in autonomous driving, while sharing similarities with object registration methods like DifFlow3D \cite{liu2024difflow3d} and \cite{wang20233d} that achieve millimeter-level precision on small-scale datasets like ShapeNet \cite{Chang_Funkhouser_Guibas_Hanrahan_Huang_Li_Savarese_Savva_Song_Su_etal._2015} and FlyingThings3D \cite{mayer2016large}, faces unique challenges when processing scenes from datasets like Argoverse 2 \cite{argoverse2} and Waymo \cite{waymo} containing 80k-177k points per frame, where substantial downsampling compromises practicality \cite{Jund_Sweeney_Abdo_Chen_Shlens_2022}. For such large-scale data, voxel-based encoding with efficient feature refinement emerges as the preferred approach to balance efficiency and feature preservation.

Many existing methods adopt flow embedding-based approaches \cite{liu2019flownet3d,zhang2024deflow,Jund_Sweeney_Abdo_Chen_Shlens_2022,lin2024icp}, establishing soft correspondences by concatenating spatial features from consecutive frames. However, this indirect feature correlation with two-frame input has been increasingly recognized as suboptimal for capturing temporal dynamics. Following successful practices in 3D detection \cite{vedder2022sparse}, scene flow estimation has evolved towards multi-frame approaches. For example, Flow4D \cite{kim2024flow4d} processes five frames for more robust estimation. Most recently, EulerFlow \cite{vedder2024scene} reformulates scene flow as a continuous space-time PDE. However, to effectively exploit temporal dynamics while avoiding the computational complexity of continuous streams, we follow Flow4D's framework by adopting five consecutive frames as input with voxel-based encoding.

Recently, self-supervised methods have gained popularity due to the difficulty of obtaining scene flow ground truth. SeFlow \cite{zhang2024seflow} addresses key challenges through efficient dynamic classification and internal cluster consistency, while ICP-Flow \cite{lin2024icp} incorporates rigid-motion assumptions via histogram-based initialization and ICP alignment. However, precise motion estimation remains critical for autonomous driving safety, and state-of-the-art self-supervised methods like EulerFlow still show limitations in static background estimation, which could be catastrophic for autonomous driving systems. Although reducing annotation costs is appealing, the investment in labeled datasets is justified and necessary given the safety-critical nature of autonomous driving. We maintain a supervised architecture while incorporating insights from self-supervised approaches and proposed a scene-adaptive loss function, which automatically extracts motion statistics from velocity histograms for better generalization without empirical thresholds.

\subsection{State Space Model}
SSMs \cite{ssm2,ssm3,ssm5} have gained attention as an efficient alternative to attention mechanisms and Transformer architectures, particularly for capturing long-term dependencies through hidden states. The Structured State Space Sequence (S4) \cite{ssm2} efficiently models long-range dependencies through diagonal parameterization, addressing computational bottlenecks in attention-based approaches. Building upon S4, researchers developed enhanced architectures such as S5 \cite{ssm3} and H3 \cite{ssm5}. Notably, Mamba \cite{gu2023mamba} represents a significant breakthrough by introducing a data-dependent selective scan mechanism and integrating hardware-aware parallel scanning algorithms, establishing a novel paradigm distinct from CNNs and Transformers while maintaining linear computational complexity.

The linear complexity capability of Mamba has inspired extensive exploration in both vision \cite{visionmamba,efficientvmamba} and point cloud processing \cite{mamba3d,liang2024pointmamba,mambamos} domains. In 3D point cloud domain, recent works have demonstrated significant advances in adapting Mamba for various tasks. Mamba3D \cite{mamba3d} introduced local norm pooling for geometric features and a bidirectional SSM design for enhanced both local and global feature representation. PointMamba \cite{liang2024pointmamba} is one of the pioneers in applying state space models to point cloud analysis by utilizing space-filling curves for point tokenization with a non-hierarchical Mamba encoder, establishing a simple yet effective baseline for 3D vision applications. 
% For large-scale processing, 3D-MambaIPF \cite{3dmambaipf} leveraged selective scan mechanism while introducing differentiable rendering constraints.
MambaMos \cite{mambamos} further explored SSM's potential in point cloud sequence modeling by adapting Mamba's selective scan mechanism for motion understanding, demonstrating that SSM's strong contextual modeling capabilities are particularly effective for capturing temporal correlations in moving object segmentation. These successes in achieving linear complexity while maintaining robust feature learning suggest promising potential for achieving fine-grained devoxelization in scene flow estimation.

Building upon these insights, we try to integrate the Mamba architecture into the the scene for estimation network for to maintains real-time performance while avoiding the quadratic complexity of transformer-based approaches.
% Building upon these insights, we propose MambaFlow for scene flow estimation, which leverages Mamba's selective scan mechanism for voxel-to-point patterns learning and efficient point-wise feature differentiation. This design maintains real-time performance while avoiding the quadratic complexity of transformer-based approaches.