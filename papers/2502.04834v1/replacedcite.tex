\section{Related Work}
\label{sec:related}

The task of visual speech recognition has been under active research for several decades.
In order to tackle the problem, the paradigm typically followed by the literature splits it into simpler sub-problems and involves a series of steps.
Initially, a spatial processing step aims to extract high-dimensional feature representations from the input.
Subsequently, a sequential modeling step interprets the temporal inter-relations between the feature representations of each time-step of the sequence.
Finally, a classification step aims to correctly predict the spoken word depicted in the frames.

Earlier works commonly employed simple image transform techniques such as \textit{Principal Component Analysis} or \textit{Discrete Cosine Transform} for visual feature extraction from lip area images, while \textit{Support Vector Machines} or \textit{Hidden Markov Models} were used as classifiers ____.
Their vocabularies consisted of few words or single digits and as a result their applicability in real-life scenarios was rather limited.
Furthermore, the available hardware at the time was insufficient to handle the non-trivial computational overhead, constraining the deployment and application of such methods.
With recent progress in both of these domains, research efforts have been increased and powerful models achieving impressive results have been developed.

Due to the remarkable advances in machine learning research of the last decade, the commonly-followed approach employs deep neural networks for the two initial steps, and a single densely-connected layer for the latter, since these architectures have demonstrated high performance on such tasks.
For visual feature extraction, \textit{Convolutional Neural Networks} (CNN) have been established as the primary model of choice due to their ability to extract strong representations when trained on sufficient amounts of data.
For the second step, the models used for sequential processing of the extracted features have been predominantly based on recurrent architectures, such as \textit{Long Short-Term Networks} (LSTM) ____ and \textit{Gated Recurrent Units} (GRU) ____.
The RNNs that are employed are typically set as \textit{bi-directional} where they also process the reverse of the sequence, and subsequently their outputs are fused by concatenation.

More recently, variants of \textit{Temporal Convolution Networks} (TCN) ____ have been proposed as alternatives to recurrent neural networks for sequential tasks, offering higher performance.
Such architectures are gradually replacing recurrent ones due to their favorable characteristics regarding training stability and model simplicity ____.
An approach that utilizes several convolutions with different kernel sizes in each block of the standard TCN architecture is introduced in ____.
This model leverages the different effective receptive fields of the convolution kernels to increase its representation capabilities by incorporating more features across the time domain and has been adopted by several recent works (e.g., ____).
A more complex model building upon the multi-kernel approach is proposed in ____, where dense connections are added in the architecture.
In this way, more features are utilized per stage, increasing the model's depth and expressiveness at the cost of its size and required calculations.

For single word recognition, while a few works utilize only the visual stream (e.g., ____), others propose methods that utilize both streams in a complementary fashion to boost performance (e.g., ____). 
Typically, modality fusion mechanisms of various complexities are employed to seamlessly integrate information from the video and audio streams.
For instance, while a simple concatenation operation is used in ____, ____ propose a hybrid fusion network that utilizes features from both audio and video modalities with a decision fusion mechanism to predict the final word.

The majority of published works focuses on improving word recognition accuracy without considering the associated computational overhead that is a consequence of using sizable models that integrate several, oftentimes complex, components in their architectures.
Consequently, the proposed models cannot be utilized in a resource-restricted environment due to the significant hardware requirements.
In comparison, research aimed at lowering model complexity and improving efficiency has not received as much attention and remains at an early stage, with fewer works appearing recently.

Models intended for applications by low-power hardware such as mobile devices were proposed in ____, where the authors design low cost networks by following lightweight convolutional neural network principles.
More specifically, a compact spatio-temporal module is introduced in order to improve the performance of video recognition.
It is combined with an architecture for visual feature extraction that is designed to be efficient by combining blocks with residual connections and depth-wise convolutions.
A scaling factor controls the balance between performance and accuracy by adjusting the network size.
To further improve the running speed and lower memory-intensity of the proposed models, a simple sequential network based on temporal convolutions is adopted for modeling the extracted features of the entire sequence.

In order to reduce the computational complexity of the entire visual speech recognition process, ____ propose changing each component used for feature extraction and sequence modeling.
Using the model from ____ as a baseline, a lightweight convolutional neural network is used for visual feature extraction reducing the hardware requirements in terms of parameters and processing operations.
Then, to further reduce the overall model's overhead, a lightweight block is introduced to the TCN architecture, replacing its standard operations with the commonplace \textit{depthwise-separable} design paradigm of lightweight CNNs (e.g., ____).
Finally, to recover some of the accuracy lost due to the drop in network capacity, a form of knowledge distillation is used to train the models.

A large study benchmarking several deep learning architectures for extraction as well as sequence modeling was performed in ____.
The authors train and evaluate an extensive selection of recently-proposed models on a variety of publicly available datasets for both English and Chinese languages.
The architectures used in their experiments cover a wide range of networks for feature extraction as well as sequence modeling, such as convolutional, vision transformers and temporal convolution networks.

A more recent approach ____ involves applying a parameter sharing technique to compress the components of VSR systems leading to more compact models without compromising accuracy.
More specifically, the convolutional layers employed by both components in the VSR pipeline (i.e., feature extractor and sequential model) are replaced equivalent layers following a formulation that exploits a sum of Kronecker products to enable parameter sharing, greatly reducing the required size of each layer.
The models achieve significant reductions in size and parameters for a minor performance penalty, which becomes more pronounced for higher rates of compression.