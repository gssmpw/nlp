\section{Real-World Evaluation}
\label{sec:real_world_evaluation}

\label{sec:real_exp}

\begin{figure*}[htbp]
\centering
\begin{minipage}{\textwidth}
    \centering
    \includegraphics[width=\textwidth]{figures/real_world_imgs.pdf} 
    \caption{The images show the tasks for real-world experiments. The upper row and lower row show the process of each task from a third-person perspective and a robot-perception perspective respectively.}
    \label{fig:real_world_scenarios}
\end{minipage}

\vspace{1em} 

\begin{minipage}{\textwidth}
    \centering
    \renewcommand\arraystretch{1.05}
    %\setlength{\tabcolsep}{1.0pt}
    \captionof{table}[Real-World Scenarios]{Summary of experimental results from real-world scenarios. The metrics include success rate (SR), mean and standard deviation of task duration (MSD), number of expert labels (NEL), and cumulative training time (CT). CT is measured in hours, MSD measured in minutes, and NEL is at the scale of $\times 10^{4}$.}
    \label{tab:real_scenarios}
    \resizebox{\textwidth}{!}{ 
    %\begin{large}
    \begin{tabular}{l|cccc|cccc|cccc}
        \hline
        & \multicolumn{4}{c|}{Block Stacking} & \multicolumn{4}{c|}{Drawer Assembling} & \multicolumn{4}{c}{Drawer Interaction} \\
        \cline{2-13}
         & SR & MSD & NEL & CT & SR & MSD & NEL & CT & SR & MSD & NEL & CT \\
        \hline
                    % (sec) 25.61 \pm 2.94 48659
        BC & $0.97$ & $\mathbf{0.41 \pm 0.04}$ & $4.86$ & $4.45$ 
                    % 105.61 \pm 12.70 120842
            & $0.40$ & $1.76 \pm 0.21$ & $12.08$ & $14.50$
                    % 56.82 \pm 6.71 48236
            & $0.83$ & $0.94 \pm 0.11$ & $4.82$ & $3.99$ \\ 

                    % 25.19 \pm 2.53 42225
        HG & $\mathbf{1.00}$ & $0.42 \pm 0.04$ & $\mathbf{4.22}$ & $4.35$
                    % 91.78  \pm 10.86 100134
            & $\mathbf{0.77}$ & $\mathbf{1.52  \pm 0.18}$ & $10.21$ & $14.21$
                    % 50.57 \pm 6.06 39474
            & $0.90$ & $0.85 \pm 0.12$ & $\mathbf{3.94}$ & $3.87$\\ 

                    % 26.30 \pm 3.43 43147
        D(L) & $\mathbf{1.00}$ & $0.43 \pm 0.05$ & $4.31$ & $4.19$
                    % 93.42  \pm 12.06 102919
            & $0.67$ & $1.55  \pm 0.20$ & $10.29$ & $13.81$
                    % 53.67 \pm 6.90 40453
            & $0.87$ & $0.89 \pm 0.11$ & $4.04$ & $3.73$\\ 

                    % 35.18 \pm 3.56 45794
        D(LR) & $0.53$ & $0.58 \pm 0.05$ & $4.57$ & $4.23$
                    % 130.84 \pm 14.71 121134
            & $0.20$ & $2.18 \pm 0.24$ & $12.11$ & $14.04$ 
                    % 65.59 \pm 10.94 45394
            & $0.37$ & $1.09 \pm 0.18$ & $4.53$ & $3.79$\\ 

                         % 25.80 \pm 3.37 42571
        D(RR) & $\mathbf{1.00}$ & $0.43 \pm 0.05$ & $4.25$ & $\mathbf{4.03}$ 
                        % 95.12 \pm 9.20 102185
            & $0.73$ & $1.58 \pm 0.15$ & $\mathbf{10.01}$ & $\mathbf{13.28}$
                        % 51.30 \pm 7.21 40851
            & $\mathbf{0.93}$ & $\mathbf{0.84 \pm 0.10}$ & $4.08$ & $\mathbf{3.59}$\\ 
        \hline
    \end{tabular}
    %\end{large}
    }
\end{minipage}

\end{figure*}

To further validate the proposed DRIFT framework, we deploy DRIFT-DAgger in three real-world tasks, using a human teleoperator as the expert. The robotic system for these experiments, illustrated in Fig. \ref{fig:real_world_system}, mirrors the setup used in the simulated MVS tasks. The system comprises two UFactory xArm7 robots mounted on linear motors, with a gripper attached to one arm and a camera to the other. This configuration enables simultaneous manipulation and viewpoint adjustment. The state-action space is a reduced end-effector space, with the orientation of the camera automatically updated via an additional IK objective.

The real-world tasks, depicted in Fig. \ref{fig:real_world_scenarios}, include block stacking, which involves placing a non-cuboid block on top of another; drawer assembling, which involves inserting two drawer boxes into a drawer container; and drawer interaction, which requires the agent to first get rid of a visual occlusion (cardboard box), grasp a red cube from a cluttered area, place it in the drawer, and then close the drawer. The blocks and drawer components are 3D-printed using models from \cite{lee2021beyond} and \cite{heo2023furniturebench}. Training configurations for each task are detailed in Table \ref{tab:exp_config}, and the trained policies from each method are evaluated over 30 rollouts.

We use the success rate, mean and standard deviation of task duration, number of expert labels, and cumulative training time as metrics for the real-world experiments. The cumulative training time only measures the active computation during training, and not includes any other events between two training epochs, such as resetting the robot or recording the demonstration interactively. 

Results, summarized in Table \ref{tab:real_scenarios}, show trends consistent with the simulation experiments. All DRIFT-DAgger variants show noticeable reduction in cumulative training time. Interactive IL methods, except the DRIFT-DAgger variant with LoRA and rank scheduler, achieve similar or superior performance to BC, with improved sample efficiency, as indicated by a reduced number of expert labels. Despite using reduced-rank training, the other two DRIFT-DAgger variants perform comparably to HG-DAgger, which trains in a full-rank manner. The advantage of interactive methods becomes more pronounced for longer-duration tasks. For example, in the block stacking task, which has a mean duration of around 0.45 minutes, interactive methods improve sample efficiency by 11.32\% to 13.17\%. In contrast, for the drawer assembling task, with a mean duration of approximately 1.72 minutes, sample efficiency improves by 14.82\% to 17.14\%.

These real-world experiments validate that the DRIFT framework is effective in real-world settings, offering reduced training time, improved sample efficiency and robust performance despite employing reduced-rank training.