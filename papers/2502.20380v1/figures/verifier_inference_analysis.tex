% \begin{figure*}[ht]
%     \centering
%     \includegraphics[width=0.9\textwidth]{assets/ablation_plot_final_scaleddown3.png}
%     \caption{
%     (Left) Report BoN accuracy of generated rollouts up to every turn on HumanEval and MBPP dataset. In contrast to multi-turn baselines Llama-3.1-1B-Instruct (Base), \MSTaR, and \MSTaRP, our method \method showed improvement with turns showing the ability of learned generator to incorporate execution feedback. 
%     (Middle) Study test-time scaling with different values of candidate solutions~$N$ to estimate BoN in \method. Interestingly, performance improves across benchmarks with larger inference budget.
%     (Right) We present importance of using a learned verifier in \method by showing that a random selection at each turn was detrimental and training the verifiers with on-policy samples of generator was performing best.
%     }
% \label{fig:ablation_plots}
% \end{figure*}