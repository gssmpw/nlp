% \begin{table}[t]
% \centering
% \begin{tabular}{l|cc|cc}
% \toprule
% \multirow{1}{*}{\textbf{Approach}} 
% & \multicolumn{2}{c|}{\itshape MBPP} 
% & \multicolumn{2}{c}{\itshape HumanEval} \\
% & P@1 & BoN & P@1 & BoN \\
% % \midrule
% % \multicolumn{2}{c}{} & \multicolumn{4}{c}{\textit{Llama-3.2-1B-Instruct}} \\
% \midrule
% % \MSTaRP & 1 & 38.1 & 42.9 & 33.1 & 37.2 \\
% \MSTaRP & 32.9 & 37.6 & 33.3 & 35.2 \\
% % \midrule
% % \method & 1 & \textbf{44.0} & \textbf{49.6} & 36.3 & 41.3\\
% \method & \textbf{42.2} & \textbf{47.2} & \textbf{40.0} & \textbf{45.5}\\
% % \midrule
% % \method (LV+OV) & 1 & 41.3 & 46.8 & 33.2 & 38.8 \\
% \method (LV+OV) & 38.6 & 45.1 & 37.4 & \textbf{45.5} \\
% \bottomrule
% \end{tabular}
% \caption{Comparison of relabeling with learned verifier~(LV) and oracle verifier~(OV). Our baseline~\MSTaRP uses OV and \method uses LV. \method~(OV+LV) aggregates a dataset from both verifiers for fine-tuning the generator. Note that \method~(OV+LV) performs better than \MSTaRP. However, \method outperforms other variants, thereby demonstrating the benefits of the learned verifier for training the generator.}
% \label{tab:results_rs_gt}
% \end{table}

\begin{figure}[h]
\centering
% \includegraphics[width=.9\linewidth]
% {figures/qualitative.png}
\includegraphics[width=\linewidth]{assets/bar_plot_verifier_new.png}
\vspace{-20pt}
\caption{
Comparison of relabeling with learned verifier~(LV) and oracle verifier~(OV) with the 1B model. The variant OV+LV aggregates a dataset from both verifiers for fine-tuning the generator. Note that OV+LV performs better than OV. However, relabeling with LV outperforms on MBPP and performs comparably on HumanEval, thereby demonstrating the benefits of leveraging the learned verifier for training the generator.
}
\label{fig:verifier_for_expert}
\end{figure}

\begin{figure}[h]
\centering
\includegraphics[width=\linewidth]{assets/varying_generator_new.png}
\vspace{-15pt}
\caption{
Comparison of \method and baselines with 1B models on the ability of the learned generator to incorporate execution feedback at each turn.
We observe that \method consistently improves the BoN accuracy across turns on both datasets, whereas the baselines show marginal improvements with turns.
}
\label{fig:varying_generator}
\end{figure}
