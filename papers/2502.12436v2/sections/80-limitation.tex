\section*{Limitation}
This study can evaluate through real-time Diplomacy games to test whether our approach could help trigger friction in human players and if it could, how useful it is. We limit our evaluation space to Diplomacy, and we could gain a better understanding of deception if we expand to broader areas like negotiation in trading. Our approach, \textbf{CTRL-D}, relies on a tool (\abr{amr}) to transform texts into logical forms. Its representation could sometimes be invalid and undermine accuracy deception detection. Our detection can only predict those negotiations with explicit actions, missing opportunities where deception occurs in other forms.

\section*{Ethical Considerations}
 % talk about detecting and understanding deception helps people deal withand understand real existing llm harms. Can also emphasize none of our data are new human experiments.
Our study uses existing data sets so we do not experiment or collect new data from humans. This paper highlights deception detection which will be necessary for dealing with existing and future harms of AI and LLMs.  As a double-edged sword, acknowledging this deception may make future systems better at masking their deception.


\section*{Acknowledgments}
We thank Meta for granting access to over 40,000 games played on the online platform \url{webdiplomacy.net} and for open sourcing Llama 3 and \cicero{}. 
Our thanks also go to Ulf Hermjakob and Tess Wood for Diplomacy \abr{amr} Annotation Dictionary.
We thank Alex Hedges for LLM Diplomacy setup and Sadra Sabouri for valuable feedback.
This research is supported by the U.S. Defense Advanced Research Projects Agency (DARPA) Other Transaction award HR00112490374 from the Friction for Accountability in Conversational Transactions (FACT) program.
%
Any opinions, findings, conclusions, or recommendations expressed here are those of the authors and
do not necessarily reflect the view of the sponsors.