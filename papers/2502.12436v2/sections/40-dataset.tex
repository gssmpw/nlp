\section{Recall-Oriented Lie Detection for Friction}
\label{sec:setup}
This section explores deception detection and its role in creating strategic friction, i.e., deliberate decision-making in human-\abr{ai} interactions. Section \ref{sec:denis_data} analyzes human-only Diplomacy games~\citep{peskov2020takes} to categorize deceptive messages and select messages for training and evaluation. Section \ref{sec:friction} extends this analysis to a larger dataset within human-\abr{ai} settings, testing whether our framework can introduce friction against deceptive proposals. Our goal is not to optimize $F_1$-Score but rather to flag \textit{possible} deception for users, introducing friction to help them detect deception. In other words, our goal is to maximize recall.
% To evaluate its effectiveness, we compare samples from both datasets against an LLM baseline, \textbf{LLM for Friction}, in mitigating deceptive strategies.
%
% \fgcomment{not defined}
% \wwcomment{ok added!}
% \fgcomment{change to section ref \wwcomment{done}}
\subsection{Alignment to Human Lies}
\label{sec:denis_data}
To understand human deception, we use the twelve Diplomacy games\footnote{Github: \href{https://github.com/DenisPeskoff/2020_acl_diplomacy}{It Takes Two to Lie: One to Lie, and One to Listen}} annotated by~\citet{peskov2020takes} containing human strategy through orders and communication from private messages. The dataset contains annotations from players at per-message granularity, indicating whether or not the content of their message contained a lie (Table~\ref{fig:lie_annotation}). \jmcomment{unclear if the rest of this graf is needed \wwcomment{I removed it to save space :)}} 
% These human lie annotations are important for training the classifier (BERT and neural networks) in Section \ref{sec:dec_prop} and important to evaluate our approach against deceptive proposals. Overall, this dataset serves as a proof of concept for assessing the effectiveness of our approach in detecting human lies.
\input{tables/lie_annotation}
\input{tables/denis_lies_category}
To best select training and evaluation data, first we breakdown lie messages---natural language texts generated by humans---in \citeauthor{peskov2020takes}'s dataset into categories (Table~\ref{tab:denis_lies}), where the category that is closest to our interest is \textbf{Deceptive Moves}.\footnote{For more category details, see Appendix~\ref{sec:denis_lie_cat}} Deceptive moves are rare, constituting fewer than 1.7\% of all messages; therefore, we sample data for training and evaluation:
\begin{itemize}
    \item \textbf{For training data,} we focus on messages 
    % that have human \abr{amr} annotations (gold-\abr{amr}) and those 
    with human-annotated negotiations---logical form of negotiations annotated by experts---specifically for player \(i\) or player \(j\). 
    %The high-quality \abr{amr} tokens makes proposed moves more accurate than using predictive \abr{amr} model. 
    % For messages where \amr{propose-01} appears in gold-\abr{amr} and those with proposed moves specifically for player \(i\) or player \(j\), we can calculate \textit{deceptive values} \(U_1, U_2\) and \(U_3\) which are numerical features for neural networks in our classifier. If there is no proposal, \textit{deceptive values} are \([-1, -1, -1]\). 
    In total, there are 344 messages with human-annotated negotiations containing 59 lies and 28 proposals. We sample additional 1,500 messages, though without human annotation, we retrieve logical forms of negotiations as discussed in Section \ref{sec:overall_method}. \jmcomment{This seems like an engineering detail regarding a system that hasn't been explained. It's usually a bad idea to put an actual vector of numbers in the text of a paper. On the whole I'm unclear what this section is trying to communicate.\wwcomment{simplify this too engineering step and try to connect each paragraph better. I will improve this more}}
    \item \textbf{For evaluation,} we simply sample 1,000 messages containing 80 lies from the rest of dataset without any further selection.
\end{itemize}

% Now we know that there are 286 messages with deceptive moves, we keep only messages that propose unit moves \(p_{j\to i} \) (i.e contains an \abr{amr}-token like \amr{propose-01} and \amr{move-01}) and propose at least \textbf{one unit move} either player \(i\) or player \(j\), i.e. player \(j\) asks to player \(i\) to commit \( \hat{a}_i = (\hat{a}_{i,1}) \) or player \(j\) promises to commit \( \hat{a}_j = (\hat{a}_{j,1}) \). This is to make sure that we will train/test our approach mostly on \textit{deceptive proposals}, avoid testing on lies that are not in our focus.  

\subsection{Friction for Humans} 
\label{sec:friction}
While the data from \citet{peskov2020takes} confirms our approach, \textbf{CTRL-D}, has a desired recall, it is small. Thus, we next test generalization on Meta's dataset\footnote{\href{https://ai.meta.com/research/request-for-proposal/towards-human-AI-cooperation/}{AI@Meta: Towards Human-AI Cooperation RFP}} of Diplomacy, which contains 40,000 games, 13 million natural language interactions from humans and \cicero players. Although these data lack thorough deception annotation, we can ex post facto validate precision through human verification. 

% Since this work does not directly evaluate real-time friction responses, we appoint our approach CTRL-D to create \textit{friction} when it believes that human player is being deceived. 

% To alleviate \abr{ai} deception, we evaluate our approach even more on both humans and \abr{ai} generated texts, extending testing data beyond human-only texts from~\citet{peskov2020takes}. 
% We use Meta's Diplomacy dataset,\footnote{\href{https://ai.meta.com/research/request-for-proposal/towards-human-AI-cooperation/}{AI@Meta: Towards Human-AI Cooperation RFP}
% } which contains 40,000 games and 13 million natural language messages. This large dataset contains games where \cicero was a player but did not reveal its identity. The data set can be useful in confirming our deception detection approach generalizes beyond evaluation in the corpus collected by ~\citet{peskov2020takes}. However, unlike \citeauthor{peskov2020takes}'s data set, Meta's set does not contain human deception annotations. 
% As a workaround, we retrieve only those messages that our models predict as deceptive, then manually vet them, enabling us to accurately measure \textit{precision}.
% We follow human-\cicero games setup from the prior works, in which players are either humans or \cicero \wwcomment{change to Meta games}, where humans are 4-7 players while \cicero and Albert\footnote{\href{https://sites.google.com/site/diplomacyai/}{Diplomacy AI - Albert with DAIDE communication}} fill in the rest~\citep{wongkamjan-etal-2024-victories}. 

% \jmcomment{Since this paper won't directly evaluate human friction responses, }
% \wwcomment{thank you!}

% This experimental data can serve as a way to testify our approach in real-world whether it is effective against \textit{deceptive proposals} in assisting humans creating \textit{friction} through \textit{counterfactual \abr{rl}}.
\input{sections/41-baseline}








