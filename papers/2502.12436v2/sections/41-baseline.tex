
\section{Baselines for Deception}
\label{sec:llama}
% \wwcomment{Yanze llama process (shortly is fine!)}

Deception is not only about the offer on the table: \citet{niculae-etal-2015-linguistic} show language changes before a betrayal occurs in Diplomacy, and \citet{lai2020chicago} demonstrate that this also holds true even in online reviews.

Thus, we compare our approach to language only baselines. Specifically, we implement an LLM-based baseline, using \amr{LLaMA\,3.1-8B-Instruct} as our primary model, to detect and mitigate deception in Diplomacy negotiations. Our objective is to determine whether a large language model can identify suspicious messages without relying on reinforcement learning (\abr{rl}). We adopt two complementary criteria for evaluating deception: \emph{Direct Judgment} and \emph{Alignment Judgment}. Detailed prompts are provided in Figure \ref{fig:prompt_llama}.

\paragraph{Direct Judgment}
In the \emph{Direct Judgment} approach, we prompt the baseline to decide whether a negotiation message is deceptive by examining its textual content together with relevant contextual information. For each negotiation round, we provide:
\begin{enumerate}
    \item \textbf{Current board state:} A concise summary of each player's positions and units (e.g., which territories are occupied by which units).
    \item \textbf{Negotiation message:} The specific proposal, plan or statement made by player~\(j\) to player~\(i\).
    \item \textbf{Predicted Orders \(\tilde{a}_j\):} The orders \cicero would issue for player~\(j\) under a dialogue-free RL policy, indicating how \cicero believes player~\(j\) will actually move.
\end{enumerate}
Given this information, the baseline determines whether the message from player~\(j\) is deceptive, returning a binary label. We do not impose a strict threshold at this stage; instead, we rely on the modelâ€™s ability to integrate textual cues and board-state context.

\paragraph{Alignment Judgment}
Because \emph{Direct Judgment} alone results in nearly half of the messages being flagged as deceptive, we propose \emph{Alignment Judgment}, which applies a more structured, threshold-based process, to measure consistency between \cicero's predicted orders and the orders proposed in the negotiation message.

For each player~\(j\), \cicero predicts orders~\(\tilde{a}_j\) using a dialogue-free RL policy. These predicted orders are then compared to the actions stated in the negotiation message. If player~\(j\) proposes \(p_{j \to i}\) with actions \( \hat{a}_i\) and \( \hat{a}_j\), but \cicero predicts alternative actions~\(\tilde{a}_j\) that differ from \(\hat{a}_j\), this inconsistency may indicate deception. The baseline is used to identify these inconsistencies. We define two sets: the number of misaligned orders \( O_m = \sum_k \boldsymbol{1}[\tilde{a}_{j,k} \neq \hat{a}_{j,k}] \), and the number of aligned orders \( O_a = \sum_k \boldsymbol{1}[\tilde{a}_{j,k} = \hat{a}_{j,k}] \), where \(k\) is the number of the units of player \(j\).
If \( O_m \geq O_a \), the message is classified as deceptive. Once flagged, the baseline triggers a \emph{risk alert}, informing player~\(i\) of the misaligned orders. This prompts players to re-evaluate their decisions before finalizing their moves.
