% abstract
\begin{abstract}
  % \sscomment{Don't motivate it by AI deception. The main idea here is to find deception (no matter from AI or humans) using AI.}

An increasingly prevalent socio-technical problem is people being taken in by offers that sound ``too good to be true'', where persuasion and trust shape decision-making.
This paper investigates how \abr{ai} can help detect these deceptive scenarios.
We analyze how humans strategically deceive each other in \textit{Diplomacy}, a board game that requires both natural language communication and strategic reasoning.
This requires extracting logical forms of proposed agreements in player communications and computing the relative rewards of the proposal using agents' value functions.
Combined with text-based features, this can improve our deception detection.
Our method detects human deception with a high precision when compared to a Large Language Model approach that flags many true messages as deceptive.
Future human-\abr{ai} interaction tools can build on our methods for
deception detection by triggering \textit{friction} to give users a
chance of interrogating suspicious proposals.
%
%
% Experiments show that, 
% \wwcomment{experiments! \jbgcomment{put results before prev sentence {\wwcomment{done!}}}}
% \fgcomment{perhaps: we analyze how human ... datasets by examining players negotiate, collaborate, and betray each other using Diplomacy as a testbed. (not sure how would "framing speculative futures as persuasive formulations" fit here)}
% \wwcomment{ok let me try!}
\end{abstract}
