\section{Related works}
\textbf{Deception in Human Behaviors.}
Research on deception has highlighted key behavioral and cognitive cues, such as micro-expressions and inconsistencies from mental strain~\cite{ekman2003, vrij2008}. Multimodal analyses integrating verbal and nonverbal signals have further enhanced detection accuracy~\cite{depaulo2003}. Linguistic cues linked to betrayal in the game Diplomacy offer insights closely aligned with our study~\cite{niculae-etal-2015-linguistic}. 
Moreover, computational models using language cues have shown promise in detecting deception in text, though evaluations have been limited to small datasets and specific scenarios~\cite{deception_algorithm, hazra-majumder-2024-tell}. Despite progress, the complex dynamics of deception in human behavior remain underexplored.

\textbf{\abr{ai} Deception in Texts.}
With the rise of \abr{ai}-generated content, detecting textual deception is crucial. Linguistic and psycholinguistic analysis aids detection, while transformer models improve accuracy~\cite{ott2011, perozosas2015, zhang2019}.
Prior work focuses on detecting \abr{ai} deception using external and internal methods~\cite{park2024ai}. External techniques like ``\textit{consistency checks}''~\cite{fluri2024evaluating} analyze \abr{ai} behavior for inconsistencies, while internal methods examine embeddings to detect dishonesty~\cite{azaria-mitchell-2023-internal, burns2024discoveringlatentknowledgelanguage}. Closely related to our work is \citet{fluri2024evaluating}, which uses Monte-Carlo Tree Search to check chess moves for logical inconsistencies.

% \textbf{Human--\abr{ai} Cooperation.}
% Successful Human–\abr{ai} collaboration requires transparency, adaptability, and ethical alignment. Human-centered design enhances decision-making through usability, feedback, and societal considerations~\cite{rahwan2018, amershi2019,shneiderman2020}. Research in human-\abr{ai} collaboration and multi-agent reinforcement learning has defined tasks that require strategic coordination, such as decision-oriented dialogues~\cite{lin-etal-2024-decision} or the game Diplomacy~\cite{meta2022human}. In these settings, user signals--—like human feedback or natural language—--optimize collaboration~\cite{hadfield2016cooperative,jeon2020reward,lin2022inferring}. Our work focuses on using signals from Diplomacy to enhance human-\abr{ai} interactions and cooperation.


