@article{agarwal2024many,
  title={Many-Shot In-Context Learning},
  author={Agarwal, Rishabh and Singh, Avi and Zhang, Lei M and Bohnet, Bernd and Chan, Stephanie and Anand, Ankesh and Abbas, Zaheer and Nova, Azade and Co-Reyes, John D and Chu, Eric and others},
  journal={arXiv preprint arXiv:2404.11018},
  year={2024}
}

@article{bertran2024scalable,
  title={Scalable membership inference attacks via quantile regression},
  author={Bertran, Martin and Tang, Shuai and Roth, Aaron and Kearns, Michael and Morgenstern, Jamie H and Wu, Steven Z},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@article{brown2020language,
  title={Language models are few-shot learners},
  author={Brown, Tom and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared D and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and others},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={1877--1901},
  year={2020}
}

@inproceedings{carlini2022membership,
  title={Membership inference attacks from first principles},
  author={Carlini, Nicholas and Chien, Steve and Nasr, Milad and Song, Shuang and Terzis, Andreas and Tramer, Florian},
  booktitle={2022 IEEE Symposium on Security and Privacy (SP)},
  pages={1897--1914},
  year={2022},
  organization={IEEE}
}

@article{chaudhary2024quantitative,
  title={Quantitative Certification of Bias in Large Language Models},
  author={Chaudhary, Isha and Hu, Qian and Kumar, Manoj and Ziyadi, Morteza and Gupta, Rahul and Singh, Gagandeep},
  journal={arXiv preprint arXiv:2405.18780},
  year={2024}
}

@article{cherepanova2024talking,
  title={Talking Nonsense: Probing Large Language Models' Understanding of Adversarial Gibberish Inputs},
  author={Cherepanova, Valeriia and Zou, James},
  journal={arXiv preprint arXiv:2404.17120},
  year={2024}
}

@article{chu2023survey,
  title={A survey of chain of thought reasoning: Advances, frontiers and future},
  author={Chu, Zheng and Chen, Jingchang and Chen, Qianglong and Yu, Weijiang and He, Tao and Wang, Haotian and Peng, Weihua and Liu, Ming and Qin, Bing and Liu, Ting},
  journal={arXiv preprint arXiv:2309.15402},
  year={2023}
}

@article{deng2023rephrase,
  title={Rephrase and respond: Let large language models ask better questions for themselves},
  author={Deng, Yihe and Zhang, Weitong and Chen, Zixiang and Gu, Quanquan},
  journal={arXiv preprint arXiv:2311.04205},
  year={2023}
}

@article{dhuliawala2023chain,
  title={Chain-of-verification reduces hallucination in large language models},
  author={Dhuliawala, Shehzaad and Komeili, Mojtaba and Xu, Jing and Raileanu, Roberta and Li, Xian and Celikyilmaz, Asli and Weston, Jason},
  journal={arXiv preprint arXiv:2309.11495},
  year={2023}
}

@inproceedings{duan2023diffusion,
  title={Are diffusion models vulnerable to membership inference attacks?},
  author={Duan, Jinhao and Kong, Fei and Wang, Shiqi and Shi, Xiaoshuang and Xu, Kaidi},
  booktitle={International Conference on Machine Learning},
  pages={8717--8730},
  year={2023},
  organization={PMLR}
}

@article{geiping2024coercing,
  title={Coercing LLMs to do and reveal (almost) anything},
  author={Geiping, Jonas and Stein, Alex and Shu, Manli and Saifullah, Khalid and Wen, Yuxin and Goldstein, Tom},
  journal={arXiv preprint arXiv:2402.14020},
  year={2024}
}

@article{hu2022membership,
  title={Membership inference attacks on machine learning: A survey},
  author={Hu, Hongsheng and Salcic, Zoran and Sun, Lichao and Dobbie, Gillian and Yu, Philip S and Zhang, Xuyun},
  journal={ACM Computing Surveys (CSUR)},
  volume={54},
  number={11s},
  pages={1--37},
  year={2022},
  publisher={ACM New York, NY}
}

@article{hui2024pleak,
  title={PLeak: Prompt Leaking Attacks against Large Language Model Applications},
  author={Hui, Bo and Yuan, Haolin and Gong, Neil and Burlina, Philippe and Cao, Yinzhi},
  journal={arXiv preprint arXiv:2405.06823},
  year={2024}
}

@article{jagielski2023combine,
  title={How to combine membership-inference attacks on multiple updated machine learning models},
  author={Jagielski, Matthew and Wu, Stanley and Oprea, Alina and Ullman, Jonathan and Geambasu, Roxana},
  journal={Proceedings on Privacy Enhancing Technologies},
  year={2023}
}

@article{kadavath2022language,
  title={Language models (mostly) know what they know},
  author={Kadavath, Saurav and Conerly, Tom and Askell, Amanda and Henighan, Tom and Drain, Dawn and Perez, Ethan and Schiefer, Nicholas and Hatfield-Dodds, Zac and DasSarma, Nova and Tran-Johnson, Eli and others},
  journal={arXiv preprint arXiv:2207.05221},
  year={2022}
}

@article{kang2024c,
  title={C-rag: Certified generation risks for retrieval-augmented language models},
  author={Kang, Mintong and G{\"u}rel, Nezihe Merve and Yu, Ning and Song, Dawn and Li, Bo},
  journal={arXiv preprint arXiv:2402.03181},
  year={2024}
}

@article{kojima2022large,
  title={Large language models are zero-shot reasoners},
  author={Kojima, Takeshi and Gu, Shixiang Shane and Reid, Machel and Matsuo, Yutaka and Iwasawa, Yusuke},
  journal={Advances in neural information processing systems},
  volume={35},
  pages={22199--22213},
  year={2022}
}

@article{kumar2024certifying,
  title={Certifying LLM Safety against Adversarial Prompting. arXiv 2024},
  author={Kumar, Aounon and Agarwal, Chirag and Srinivas, Suraj and Li, AJ and Feizi, S and Lakkaraju, H},
  journal={arXiv preprint arXiv:2309.02705},
  year={2024}
}

@article{li2023large,
  title={Large language models understand and can be enhanced by emotional stimuli},
  author={Li, Cheng and Wang, Jindong and Zhang, Yixuan and Zhu, Kaijie and Hou, Wenxin and Lian, Jianxun and Luo, Fang and Yang, Qiang and Xie, Xing},
  journal={arXiv preprint arXiv:2307.11760},
  year={2023}
}

@article{liu2023pre,
  title={Pre-train, prompt, and predict: A systematic survey of prompting methods in natural language processing},
  author={Liu, Pengfei and Yuan, Weizhe and Fu, Jinlan and Jiang, Zhengbao and Hayashi, Hiroaki and Neubig, Graham},
  journal={ACM Computing Surveys},
  volume={55},
  number={9},
  pages={1--35},
  year={2023},
  publisher={ACM New York, NY}
}

@article{lu2021fantastically,
  title={Fantastically ordered prompts and where to find them: Overcoming few-shot prompt order sensitivity},
  author={Lu, Yao and Bartolo, Max and Moore, Alastair and Riedel, Sebastian and Stenetorp, Pontus},
  journal={arXiv preprint arXiv:2104.08786},
  year={2021}
}

@article{madaan2024self,
  title={Self-refine: Iterative refinement with self-feedback},
  author={Madaan, Aman and Tandon, Niket and Gupta, Prakhar and Hallinan, Skyler and Gao, Luyu and Wiegreffe, Sarah and Alon, Uri and Dziri, Nouha and Prabhumoye, Shrimai and Yang, Yiming and others},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@article{maini2021dataset,
  title={Dataset inference: Ownership resolution in machine learning},
  author={Maini, Pratyush and Yaghini, Mohammad and Papernot, Nicolas},
  journal={arXiv preprint arXiv:2104.10706},
  year={2021}
}

@misc{maini2024llm,
      title={LLM Dataset Inference: Did you train on my dataset?}, 
      author={Pratyush Maini and Hengrui Jia and Nicolas Papernot and Adam Dziedzic},
      year={2024},
      eprint={2406.06443},
      archivePrefix={arXiv},
}

@inproceedings{matsumoto2023membership,
  title={Membership inference attacks against diffusion models},
  author={Matsumoto, Tomoya and Miura, Takayuki and Yanai, Naoto},
  booktitle={2023 IEEE Security and Privacy Workshops (SPW)},
  pages={77--83},
  year={2023},
  organization={IEEE}
}

@article{morris2023language,
  title={Language model inversion},
  author={Morris, John X and Zhao, Wenting and Chiu, Justin T and Shmatikov, Vitaly and Rush, Alexander M},
  journal={arXiv preprint arXiv:2311.13647},
  year={2023}
}

@misc{ng2023neurips,
title={Application Development using Large Language Models},
author={Andrew Ng and Isa Fulford},
year={2023},
howpublished={NeurIPS 2023 Tutorials},
}

@article{press2022measuring,
  title={Measuring and narrowing the compositionality gap in language models},
  author={Press, Ofir and Zhang, Muru and Min, Sewon and Schmidt, Ludwig and Smith, Noah A and Lewis, Mike},
  journal={arXiv preprint arXiv:2210.03350},
  year={2022}
}

@article{radford2019language,
  title={Language models are unsupervised multitask learners},
  author={Radford, Alec and Wu, Jeffrey and Child, Rewon and Luan, David and Amodei, Dario and Sutskever, Ilya and others},
  journal={OpenAI blog},
  volume={1},
  number={8},
  pages={9},
  year={2019}
}

@inproceedings{sablayrolles2019white,
  title={White-box vs black-box: Bayes optimal strategies for membership inference},
  author={Sablayrolles, Alexandre and Douze, Matthijs and Schmid, Cordelia and Ollivier, Yann and J{\'e}gou, Herv{\'e}},
  booktitle={International Conference on Machine Learning},
  pages={5558--5567},
  year={2019},
  organization={PMLR}
}

@article{salem2018ml,
  title={Ml-leaks: Model and data independent membership inference attacks and defenses on machine learning models},
  author={Salem, Ahmed and Zhang, Yang and Humbert, Mathias and Berrang, Pascal and Fritz, Mario and Backes, Michael},
  journal={arXiv preprint arXiv:1806.01246},
  year={2018}
}

@article{scao2021many,
  title={How many data points is a prompt worth?},
  author={Scao, Teven Le and Rush, Alexander M},
  journal={arXiv preprint arXiv:2103.08493},
  year={2021}
}

@article{sha2024prompt,
  title={Prompt Stealing Attacks Against Large Language Models},
  author={Sha, Zeyang and Zhang, Yang},
  journal={arXiv preprint arXiv:2402.12959},
  year={2024}
}

@inproceedings{shokri2017membership,
  title={Membership inference attacks against machine learning models},
  author={Shokri, Reza and Stronati, Marco and Song, Congzheng and Shmatikov, Vitaly},
  booktitle={2017 IEEE symposium on security and privacy (SP)},
  pages={3--18},
  year={2017},
  organization={IEEE}
}

@inproceedings{song2021systematic,
  title={Systematic evaluation of privacy risks of machine learning models},
  author={Song, Liwei and Mittal, Prateek},
  booktitle={30th USENIX Security Symposium (USENIX Security 21)},
  pages={2615--2632},
  year={2021}
}

@article{team2023gemini,
  title={Gemini: a family of highly capable multimodal models},
  author={Team, Gemini and Anil, Rohan and Borgeaud, Sebastian and Wu, Yonghui and Alayrac, Jean-Baptiste and Yu, Jiahui and Soricut, Radu and Schalkwyk, Johan and Dai, Andrew M and Hauth, Anja and others},
  journal={arXiv preprint arXiv:2312.11805},
  year={2023}
}

@article{wang2023rolellm,
  title={Rolellm: Benchmarking, eliciting, and enhancing role-playing abilities of large language models},
  author={Wang, Zekun Moore and Peng, Zhongyuan and Que, Haoran and Liu, Jiaheng and Zhou, Wangchunshu and Wu, Yuhan and Guo, Hongcheng and Gan, Ruitong and Ni, Zehao and Zhang, Man and others},
  journal={arXiv preprint arXiv:2310.00746},
  year={2023}
}

@article{wei2022chain,
  title={Chain-of-thought prompting elicits reasoning in large language models},
  author={Wei, Jason and Wang, Xuezhi and Schuurmans, Dale and Bosma, Maarten and Xia, Fei and Chi, Ed and Le, Quoc V and Zhou, Denny and others},
  journal={Advances in neural information processing systems},
  volume={35},
  pages={24824--24837},
  year={2022}
}

@article{wen2022canary,
  title={Canary in a coalmine: Better membership inference with ensembled adversarial queries},
  author={Wen, Yuxin and Bansal, Arpit and Kazemi, Hamid and Borgnia, Eitan and Goldblum, Micah and Geiping, Jonas and Goldstein, Tom},
  journal={arXiv preprint arXiv:2210.10750},
  year={2022}
}

@article{wen2024hard,
  title={Hard prompts made easy: Gradient-based discrete optimization for prompt tuning and discovery},
  author={Wen, Yuxin and Jain, Neel and Kirchenbauer, John and Goldblum, Micah and Geiping, Jonas and Goldstein, Tom},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@article{weng2022large,
  title={Large language models are better reasoners with self-verification},
  author={Weng, Yixuan and Zhu, Minjun and Xia, Fei and Li, Bin and He, Shizhu and Liu, Shengping and Sun, Bin and Liu, Kang and Zhao, Jun},
  journal={arXiv preprint arXiv:2212.09561},
  year={2022}
}

@article{xue2023rcot,
  title={Rcot: Detecting and rectifying factual inconsistency in reasoning by reversing chain-of-thought},
  author={Xue, Tianci and Wang, Ziqi and Wang, Zhenhailong and Han, Chi and Yu, Pengfei and Ji, Heng},
  journal={arXiv preprint arXiv:2305.11499},
  year={2023}
}

@article{yang2024prsa,
  title={PRSA: Prompt Reverse Stealing Attacks against Large Language Models},
  author={Yang, Yong and Zhang, Xuhong and Jiang, Yi and Chen, Xi and Wang, Haoyu and Ji, Shouling and Wang, Zonghui},
  journal={arXiv preprint arXiv:2402.19200},
  year={2024}
}

@article{yasunaga2023large,
  title={Large language models as analogical reasoners},
  author={Yasunaga, Michihiro and Chen, Xinyun and Li, Yujia and Pasupat, Panupong and Leskovec, Jure and Liang, Percy and Chi, Ed H and Zhou, Denny},
  journal={arXiv preprint arXiv:2310.01714},
  year={2023}
}

@article{ye2023explanation,
  title={Explanation selection using unlabeled data for chain-of-thought prompting},
  author={Ye, Xi and Durrett, Greg},
  journal={arXiv preprint arXiv:2302.04813},
  year={2023}
}

@inproceedings{yeom2018privacy,
  title={Privacy risk in machine learning: Analyzing the connection to overfitting},
  author={Yeom, Samuel and Giacomelli, Irene and Fredrikson, Matt and Jha, Somesh},
  booktitle={2018 IEEE 31st computer security foundations symposium (CSF)},
  pages={268--282},
  year={2018},
  organization={IEEE}
}

@article{zhang2022automatic,
  title={Automatic chain of thought prompting in large language models},
  author={Zhang, Zhuosheng and Zhang, Aston and Li, Mu and Smola, Alex},
  journal={arXiv preprint arXiv:2210.03493},
  year={2022}
}

@article{zhang2024effective,
    author = {Yiming Zhang and Nicholas Carlini and Daphne Ippolito},
    title = {Effective Prompt Extraction from Language Models},
    journal = {arXiv preprint arXiv:2303.08493}, 
    url = {https://arxiv.org/pdf/2307.06865}
}

@inproceedings{zhao2021calibrate,
  title={Calibrate before use: Improving few-shot performance of language models},
  author={Zhao, Zihao and Wallace, Eric and Feng, Shi and Klein, Dan and Singh, Sameer},
  booktitle={International conference on machine learning},
  pages={12697--12706},
  year={2021},
  organization={PMLR}
}

@article{zheng2023helpful,
  title={Is" A Helpful Assistant" the Best Role for Large Language Models? A Systematic Evaluation of Social Roles in System Prompts},
  author={Zheng, Mingqian and Pei, Jiaxin and Jurgens, David},
  journal={arXiv preprint arXiv:2311.10054},
  year={2023}
}

@article{zheng2023take,
  title={Take a step back: Evoking reasoning via abstraction in large language models},
  author={Zheng, Huaixiu Steven and Mishra, Swaroop and Chen, Xinyun and Cheng, Heng-Tze and Chi, Ed H and Le, Quoc V and Zhou, Denny},
  journal={arXiv preprint arXiv:2310.06117},
  year={2023}
}

@article{zhou2023thread,
  title={Thread of thought unraveling chaotic contexts},
  author={Zhou, Yucheng and Geng, Xiubo and Shen, Tao and Tao, Chongyang and Long, Guodong and Lou, Jian-Guang and Shen, Jianbing},
  journal={arXiv preprint arXiv:2311.08734},
  year={2023}
}

@article{zou2023universal,
  title={Universal and transferable adversarial attacks on aligned language models},
  author={Zou, Andy and Wang, Zifan and Kolter, J Zico and Fredrikson, Matt},
  journal={arXiv preprint arXiv:2307.15043},
  year={2023}
}

