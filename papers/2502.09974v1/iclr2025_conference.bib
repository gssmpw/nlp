@article{zou2023universal,
  title={Universal and transferable adversarial attacks on aligned language models},
  author={Zou, Andy and Wang, Zifan and Kolter, J Zico and Fredrikson, Matt},
  journal={arXiv preprint arXiv:2307.15043},
  year={2023}
}

@article{cherepanova2024talking,
  title={Talking Nonsense: Probing Large Language Models' Understanding of Adversarial Gibberish Inputs},
  author={Cherepanova, Valeriia and Zou, James},
  journal={arXiv preprint arXiv:2404.17120},
  year={2024}
}

@article{press2022measuring,
  title={Measuring and narrowing the compositionality gap in language models},
  author={Press, Ofir and Zhang, Muru and Min, Sewon and Schmidt, Ludwig and Smith, Noah A and Lewis, Mike},
  journal={arXiv preprint arXiv:2210.03350},
  year={2022}
}

@article{deng2023rephrase,
  title={Rephrase and respond: Let large language models ask better questions for themselves},
  author={Deng, Yihe and Zhang, Weitong and Chen, Zixiang and Gu, Quanquan},
  journal={arXiv preprint arXiv:2311.04205},
  year={2023}
}

@article{li2023large,
  title={Large language models understand and can be enhanced by emotional stimuli},
  author={Li, Cheng and Wang, Jindong and Zhang, Yixuan and Zhu, Kaijie and Hou, Wenxin and Lian, Jianxun and Luo, Fang and Yang, Qiang and Xie, Xing},
  journal={arXiv preprint arXiv:2307.11760},
  year={2023}
}

@article{zheng2023helpful,
  title={Is" A Helpful Assistant" the Best Role for Large Language Models? A Systematic Evaluation of Social Roles in System Prompts},
  author={Zheng, Mingqian and Pei, Jiaxin and Jurgens, David},
  journal={arXiv preprint arXiv:2311.10054},
  year={2023}
}

@article{wang2023rolellm,
  title={Rolellm: Benchmarking, eliciting, and enhancing role-playing abilities of large language models},
  author={Wang, Zekun Moore and Peng, Zhongyuan and Que, Haoran and Liu, Jiaheng and Zhou, Wangchunshu and Wu, Yuhan and Guo, Hongcheng and Gan, Ruitong and Ni, Zehao and Zhang, Man and others},
  journal={arXiv preprint arXiv:2310.00746},
  year={2023}
}

@article{dhuliawala2023chain,
  title={Chain-of-verification reduces hallucination in large language models},
  author={Dhuliawala, Shehzaad and Komeili, Mojtaba and Xu, Jing and Raileanu, Roberta and Li, Xian and Celikyilmaz, Asli and Weston, Jason},
  journal={arXiv preprint arXiv:2309.11495},
  year={2023}
}

@article{weng2022large,
  title={Large language models are better reasoners with self-verification},
  author={Weng, Yixuan and Zhu, Minjun and Xia, Fei and Li, Bin and He, Shizhu and Liu, Shengping and Sun, Bin and Liu, Kang and Zhao, Jun},
  journal={arXiv preprint arXiv:2212.09561},
  year={2022}
}

@article{yuan2023scaling,
  title={Scaling relationship on learning mathematical reasoning with large language models},
  author={Yuan, Zheng and Yuan, Hongyi and Li, Chengpeng and Dong, Guanting and Tan, Chuanqi and Zhou, Chang},
  journal={arXiv preprint arXiv:2308.01825},
  year={2023}
}

@article{xue2023rcot,
  title={Rcot: Detecting and rectifying factual inconsistency in reasoning by reversing chain-of-thought},
  author={Xue, Tianci and Wang, Ziqi and Wang, Zhenhailong and Han, Chi and Yu, Pengfei and Ji, Heng},
  journal={arXiv preprint arXiv:2305.11499},
  year={2023}
}

@article{madaan2024self,
  title={Self-refine: Iterative refinement with self-feedback},
  author={Madaan, Aman and Tandon, Niket and Gupta, Prakhar and Hallinan, Skyler and Gao, Luyu and Wiegreffe, Sarah and Alon, Uri and Dziri, Nouha and Prabhumoye, Shrimai and Yang, Yiming and others},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@article{kadavath2022language,
  title={Language models (mostly) know what they know},
  author={Kadavath, Saurav and Conerly, Tom and Askell, Amanda and Henighan, Tom and Drain, Dawn and Perez, Ethan and Schiefer, Nicholas and Hatfield-Dodds, Zac and DasSarma, Nova and Tran-Johnson, Eli and others},
  journal={arXiv preprint arXiv:2207.05221},
  year={2022}
}

@article{chu2023survey,
  title={A survey of chain of thought reasoning: Advances, frontiers and future},
  author={Chu, Zheng and Chen, Jingchang and Chen, Qianglong and Yu, Weijiang and He, Tao and Wang, Haotian and Peng, Weihua and Liu, Ming and Qin, Bing and Liu, Ting},
  journal={arXiv preprint arXiv:2309.15402},
  year={2023}
}

@article{zhou2023thread,
  title={Thread of thought unraveling chaotic contexts},
  author={Zhou, Yucheng and Geng, Xiubo and Shen, Tao and Tao, Chongyang and Long, Guodong and Lou, Jian-Guang and Shen, Jianbing},
  journal={arXiv preprint arXiv:2311.08734},
  year={2023}
}

@article{team2023gemini,
  title={Gemini: a family of highly capable multimodal models},
  author={Team, Gemini and Anil, Rohan and Borgeaud, Sebastian and Wu, Yonghui and Alayrac, Jean-Baptiste and Yu, Jiahui and Soricut, Radu and Schalkwyk, Johan and Dai, Andrew M and Hauth, Anja and others},
  journal={arXiv preprint arXiv:2312.11805},
  year={2023}
}

@article{zhang2022automatic,
  title={Automatic chain of thought prompting in large language models},
  author={Zhang, Zhuosheng and Zhang, Aston and Li, Mu and Smola, Alex},
  journal={arXiv preprint arXiv:2210.03493},
  year={2022}
}

@article{yasunaga2023large,
  title={Large language models as analogical reasoners},
  author={Yasunaga, Michihiro and Chen, Xinyun and Li, Yujia and Pasupat, Panupong and Leskovec, Jure and Liang, Percy and Chi, Ed H and Zhou, Denny},
  journal={arXiv preprint arXiv:2310.01714},
  year={2023}
}

@article{zheng2023take,
  title={Take a step back: Evoking reasoning via abstraction in large language models},
  author={Zheng, Huaixiu Steven and Mishra, Swaroop and Chen, Xinyun and Cheng, Heng-Tze and Chi, Ed H and Le, Quoc V and Zhou, Denny},
  journal={arXiv preprint arXiv:2310.06117},
  year={2023}
}

@article{kojima2022large,
  title={Large language models are zero-shot reasoners},
  author={Kojima, Takeshi and Gu, Shixiang Shane and Reid, Machel and Matsuo, Yutaka and Iwasawa, Yusuke},
  journal={Advances in neural information processing systems},
  volume={35},
  pages={22199--22213},
  year={2022}
}

@article{wei2022chain,
  title={Chain-of-thought prompting elicits reasoning in large language models},
  author={Wei, Jason and Wang, Xuezhi and Schuurmans, Dale and Bosma, Maarten and Xia, Fei and Chi, Ed and Le, Quoc V and Zhou, Denny and others},
  journal={Advances in neural information processing systems},
  volume={35},
  pages={24824--24837},
  year={2022}
}

@article{zhang2023igniting,
  title={Igniting Language Intelligence: The Hitchhiker's Guide From Chain-of-Thought Reasoning to Language Agents},
  author={Zhang, Zhuosheng and Yao, Yao and Zhang, Aston and Tang, Xiangru and Ma, Xinbei and He, Zhiwei and Wang, Yiming and Gerstein, Mark and Wang, Rui and Liu, Gongshen and others},
  journal={arXiv preprint arXiv:2311.11797},
  year={2023}
}

@article{zhang2022active,
  title={Active example selection for in-context learning},
  author={Zhang, Yiming and Feng, Shi and Tan, Chenhao},
  journal={arXiv preprint arXiv:2211.04486},
  year={2022}
}

@article{li2023unified,
  title={Unified demonstration retriever for in-context learning},
  author={Li, Xiaonan and Lv, Kai and Yan, Hang and Lin, Tianyang and Zhu, Wei and Ni, Yuan and Xie, Guotong and Wang, Xiaoling and Qiu, Xipeng},
  journal={arXiv preprint arXiv:2305.04320},
  year={2023}
}

@article{li2023finding,
  title={Finding support examples for in-context learning},
  author={Li, Xiaonan and Qiu, Xipeng},
  journal={arXiv preprint arXiv:2302.13539},
  year={2023}
}

@article{jiang2020can,
  title={How can we know what language models know?},
  author={Jiang, Zhengbao and Xu, Frank F and Araki, Jun and Neubig, Graham},
  journal={Transactions of the Association for Computational Linguistics},
  volume={8},
  pages={423--438},
  year={2020},
  publisher={MIT Press One Rogers Street, Cambridge, MA 02142-1209, USA journals-info~…}
}

@article{jiang2020can,
  title={How can we know what language models know?},
  author={Jiang, Zhengbao and Xu, Frank F and Araki, Jun and Neubig, Graham},
  journal={Transactions of the Association for Computational Linguistics},
  volume={8},
  pages={423--438},
  year={2020},
  publisher={MIT Press One Rogers Street, Cambridge, MA 02142-1209, USA journals-info~…}
}

@article{kim2022self,
  title={Self-generated in-context learning: Leveraging auto-regressive language models as a demonstration generator},
  author={Kim, Hyuhng Joon and Cho, Hyunsoo and Kim, Junyeob and Kim, Taeuk and Yoo, Kang Min and Lee, Sang-goo},
  journal={arXiv preprint arXiv:2206.08082},
  year={2022}
}

@article{su2022selective,
  title={Selective annotation makes language models better few-shot learners},
  author={Su, Hongjin and Kasai, Jungo and Wu, Chen Henry and Shi, Weijia and Wang, Tianlu and Xin, Jiayi and Zhang, Rui and Ostendorf, Mari and Zettlemoyer, Luke and Smith, Noah A and others},
  journal={arXiv preprint arXiv:2209.01975},
  year={2022}
}

@article{liu2021makes,
  title={What Makes Good In-Context Examples for GPT-$3 $?},
  author={Liu, Jiachang and Shen, Dinghan and Zhang, Yizhe and Dolan, Bill and Carin, Lawrence and Chen, Weizhu},
  journal={arXiv preprint arXiv:2101.06804},
  year={2021}
}

@article{ye2023explanation,
  title={Explanation selection using unlabeled data for chain-of-thought prompting},
  author={Ye, Xi and Durrett, Greg},
  journal={arXiv preprint arXiv:2302.04813},
  year={2023}
}

@article{lu2021fantastically,
  title={Fantastically ordered prompts and where to find them: Overcoming few-shot prompt order sensitivity},
  author={Lu, Yao and Bartolo, Max and Moore, Alastair and Riedel, Sebastian and Stenetorp, Pontus},
  journal={arXiv preprint arXiv:2104.08786},
  year={2021}
}

@inproceedings{zhao2021calibrate,
  title={Calibrate before use: Improving few-shot performance of language models},
  author={Zhao, Zihao and Wallace, Eric and Feng, Shi and Klein, Dan and Singh, Sameer},
  booktitle={International conference on machine learning},
  pages={12697--12706},
  year={2021},
  organization={PMLR}
}

@article{vstefanik2022can,
  title={Can In-context Learners Learn a Reasoning Concept from Demonstrations?},
  author={{\v{S}}tef{\'a}nik, Michal and Kadl{\v{c}}{\'\i}k, Marek},
  journal={arXiv preprint arXiv:2212.01692},
  year={2022}
}

@article{si2023measuring,
  title={Measuring inductive biases of in-context learning with underspecified demonstrations},
  author={Si, Chenglei and Friedman, Dan and Joshi, Nitish and Feng, Shi and Chen, Danqi and He, He},
  journal={arXiv preprint arXiv:2305.13299},
  year={2023}
}

@article{bansal2022rethinking,
  title={Rethinking the role of scale for in-context learning: An interpretability-based case study at 66 billion scale},
  author={Bansal, Hritik and Gopalakrishnan, Karthik and Dingliwal, Saket and Bodapati, Sravan and Kirchhoff, Katrin and Roth, Dan},
  journal={arXiv preprint arXiv:2212.09095},
  year={2022}
}

@article{radford2019language,
  title={Language models are unsupervised multitask learners},
  author={Radford, Alec and Wu, Jeffrey and Child, Rewon and Luan, David and Amodei, Dario and Sutskever, Ilya and others},
  journal={OpenAI blog},
  volume={1},
  number={8},
  pages={9},
  year={2019}
}

@Misc{Claude3,
  title={Claude 3 Model Family: Opus, Sonnet, Haiku},
  author={Anthropic},
  howpublished = {\url{https://www.anthropic.com/news/claude-3-family}},
  year={2024},
  note = {Accessed: June 14, 2024}
}

@Misc{anthropic_prompt_library, author = {Anthropic}, title = {Prompt Library}, howpublished = {\url{https://docs.anthropic.com/en/prompt-library/library}}, year = {2024}, note = {Accessed: June 14, 2024}, }

@Misc{openai_prompt_engineering, author = {OpenAI}, title = {Prompt Engineering Guide}, howpublished = {\url{https://platform.openai.com/docs/guides/prompt-engineering}}, year = {2023}, note = {Accessed: June 14, 2024}, }

@article{scao2021many,
  title={How many data points is a prompt worth?},
  author={Scao, Teven Le and Rush, Alexander M},
  journal={arXiv preprint arXiv:2103.08493},
  year={2021}
}

@article{zhang2024effective,
    author = {Yiming Zhang and Nicholas Carlini and Daphne Ippolito},
    title = {Effective Prompt Extraction from Language Models},
    journal = {arXiv preprint arXiv:2303.08493}, 
    url = {https://arxiv.org/pdf/2307.06865}
}

@inproceedings{shokri2017membership,
  title={Membership inference attacks against machine learning models},
  author={Shokri, Reza and Stronati, Marco and Song, Congzheng and Shmatikov, Vitaly},
  booktitle={2017 IEEE symposium on security and privacy (SP)},
  pages={3--18},
  year={2017},
  organization={IEEE}
}

@article{brown2020language,
  title={Language models are few-shot learners},
  author={Brown, Tom and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared D and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and others},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={1877--1901},
  year={2020}
}
@article{dong2022survey,
  title={A survey on in-context learning},
  author={Dong, Qingxiu and Li, Lei and Dai, Damai and Zheng, Ce and Wu, Zhiyong and Chang, Baobao and Sun, Xu and Xu, Jingjing and Sui, Zhifang},
  journal={arXiv preprint arXiv:2301.00234},
  year={2022}
}

@article{liu2023pre,
  title={Pre-train, prompt, and predict: A systematic survey of prompting methods in natural language processing},
  author={Liu, Pengfei and Yuan, Weizhe and Fu, Jinlan and Jiang, Zhengbao and Hayashi, Hiroaki and Neubig, Graham},
  journal={ACM Computing Surveys},
  volume={55},
  number={9},
  pages={1--35},
  year={2023},
  publisher={ACM New York, NY}
}

@article{sha2024prompt,
  title={Prompt Stealing Attacks Against Large Language Models},
  author={Sha, Zeyang and Zhang, Yang},
  journal={arXiv preprint arXiv:2402.12959},
  year={2024}
}

@article{yang2024prsa,
  title={PRSA: Prompt Reverse Stealing Attacks against Large Language Models},
  author={Yang, Yong and Zhang, Xuhong and Jiang, Yi and Chen, Xi and Wang, Haoyu and Ji, Shouling and Wang, Zonghui},
  journal={arXiv preprint arXiv:2402.19200},
  year={2024}
}

@article{hu2022membership,
  title={Membership inference attacks on machine learning: A survey},
  author={Hu, Hongsheng and Salcic, Zoran and Sun, Lichao and Dobbie, Gillian and Yu, Philip S and Zhang, Xuyun},
  journal={ACM Computing Surveys (CSUR)},
  volume={54},
  number={11s},
  pages={1--37},
  year={2022},
  publisher={ACM New York, NY}
}

@article{wen2024hard,
  title={Hard prompts made easy: Gradient-based discrete optimization for prompt tuning and discovery},
  author={Wen, Yuxin and Jain, Neel and Kirchenbauer, John and Goldblum, Micah and Geiping, Jonas and Goldstein, Tom},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@inproceedings{carlini2022membership,
  title={Membership inference attacks from first principles},
  author={Carlini, Nicholas and Chien, Steve and Nasr, Milad and Song, Shuang and Terzis, Andreas and Tramer, Florian},
  booktitle={2022 IEEE Symposium on Security and Privacy (SP)},
  pages={1897--1914},
  year={2022},
  organization={IEEE}
}

@article{reimers2019sentence,
  title={Sentence-bert: Sentence embeddings using siamese bert-networks},
  author={Reimers, Nils and Gurevych, Iryna},
  journal={arXiv preprint arXiv:1908.10084},
  year={2019}
}

@book{good2013permutation,
  title={Permutation tests: a practical guide to resampling methods for testing hypotheses},
  author={Good, Phillip},
  year={2013},
  publisher={Springer Science \& Business Media}
}

@misc{akin2023awesome,
  author       = {Fatih Kadir Akın},
  title        = {awesome-chatgpt-prompts},
  year         = {2023},
  url          = {https://github.com/f/awesome-chatgpt-prompts},
  note         = {GitHub repository}
}

@article{touvron2023llama,
  title={Llama 2: Open foundation and fine-tuned chat models},
  author={Touvron, Hugo and Martin, Louis and Stone, Kevin and Albert, Peter and Almahairi, Amjad and Babaei, Yasmine and Bashlykov, Nikolay and Batra, Soumya and Bhargava, Prajjwal and Bhosale, Shruti and others},
  journal={arXiv preprint arXiv:2307.09288},
  year={2023}
}

@article{jiang2023mistral,
  title={Mistral 7B},
  author={Jiang, Albert Q and Sablayrolles, Alexandre and Mensch, Arthur and Bamford, Chris and Chaplot, Devendra Singh and Casas, Diego de las and Bressand, Florian and Lengyel, Gianna and Lample, Guillaume and Saulnier, Lucile and others},
  journal={arXiv preprint arXiv:2310.06825},
  year={2023}
}

@article{jiang2024mixtral,
  title={Mixtral of experts},
  author={Jiang, Albert Q and Sablayrolles, Alexandre and Roux, Antoine and Mensch, Arthur and Savary, Blanche and Bamford, Chris and Chaplot, Devendra Singh and Casas, Diego de las and Hanna, Emma Bou and Bressand, Florian and others},
  journal={arXiv preprint arXiv:2401.04088},
  year={2024}
}

@article{achiam2023gpt,
  title={Gpt-4 technical report},
  author={Achiam, Josh and Adler, Steven and Agarwal, Sandhini and Ahmad, Lama and Akkaya, Ilge and Aleman, Florencia Leoni and Almeida, Diogo and Altenschmidt, Janko and Altman, Sam and Anadkat, Shyamal and others},
  journal={arXiv preprint arXiv:2303.08774},
  year={2023}
}

@article{agarwal2024many,
  title={Many-Shot In-Context Learning},
  author={Agarwal, Rishabh and Singh, Avi and Zhang, Lei M and Bohnet, Bernd and Chan, Stephanie and Anand, Ankesh and Abbas, Zaheer and Nova, Azade and Co-Reyes, John D and Chu, Eric and others},
  journal={arXiv preprint arXiv:2404.11018},
  year={2024}
}

@article{morris2023language,
  title={Language model inversion},
  author={Morris, John X and Zhao, Wenting and Chiu, Justin T and Shmatikov, Vitaly and Rush, Alexander M},
  journal={arXiv preprint arXiv:2311.13647},
  year={2023}
}

@article{hui2024pleak,
  title={PLeak: Prompt Leaking Attacks against Large Language Model Applications},
  author={Hui, Bo and Yuan, Haolin and Gong, Neil and Burlina, Philippe and Cao, Yinzhi},
  journal={arXiv preprint arXiv:2405.06823},
  year={2024}
}

@article{geiping2024coercing,
  title={Coercing LLMs to do and reveal (almost) anything},
  author={Geiping, Jonas and Stein, Alex and Shu, Manli and Saifullah, Khalid and Wen, Yuxin and Goldstein, Tom},
  journal={arXiv preprint arXiv:2402.14020},
  year={2024}
}

@misc{ng2023neurips,
title={Application Development using Large Language Models},
author={Andrew Ng and Isa Fulford},
year={2023},
howpublished={NeurIPS 2023 Tutorials},
}

@misc{schulhoff2024prompt,
      title={The Prompt Report: A Systematic Survey of Prompting Techniques}, 
      author={Sander Schulhoff and Michael Ilie and Nishant Balepur and Konstantine Kahadze and Amanda Liu and Chenglei Si and Yinheng Li and Aayush Gupta and HyoJung Han and Sevien Schulhoff and Pranav Sandeep Dulepet and Saurav Vidyadhara and Dayeon Ki and Sweta Agrawal and Chau Pham and Gerson Kroiz and Feileen Li and Hudson Tao and Ashay Srivastava and Hevander Da Costa and Saloni Gupta and Megan L. Rogers and Inna Goncearenco and Giuseppe Sarli and Igor Galynker and Denis Peskoff and Marine Carpuat and Jules White and Shyamal Anadkat and Alexander Hoyle and Philip Resnik},
      year={2024},
      eprint={2406.06608},
      archivePrefix={arXiv},
}

@article{jagielski2023combine,
  title={How to combine membership-inference attacks on multiple updated machine learning models},
  author={Jagielski, Matthew and Wu, Stanley and Oprea, Alina and Ullman, Jonathan and Geambasu, Roxana},
  journal={Proceedings on Privacy Enhancing Technologies},
  year={2023}
}

@misc{maini2024llm,
      title={LLM Dataset Inference: Did you train on my dataset?}, 
      author={Pratyush Maini and Hengrui Jia and Nicolas Papernot and Adam Dziedzic},
      year={2024},
      eprint={2406.06443},
      archivePrefix={arXiv},
}

@article{bertran2024scalable,
  title={Scalable membership inference attacks via quantile regression},
  author={Bertran, Martin and Tang, Shuai and Roth, Aaron and Kearns, Michael and Morgenstern, Jamie H and Wu, Steven Z},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@inproceedings{duan2023diffusion,
  title={Are diffusion models vulnerable to membership inference attacks?},
  author={Duan, Jinhao and Kong, Fei and Wang, Shiqi and Shi, Xiaoshuang and Xu, Kaidi},
  booktitle={International Conference on Machine Learning},
  pages={8717--8730},
  year={2023},
  organization={PMLR}
}

@inproceedings{matsumoto2023membership,
  title={Membership inference attacks against diffusion models},
  author={Matsumoto, Tomoya and Miura, Takayuki and Yanai, Naoto},
  booktitle={2023 IEEE Security and Privacy Workshops (SPW)},
  pages={77--83},
  year={2023},
  organization={IEEE}
}

@inproceedings{yeom2018privacy,
  title={Privacy risk in machine learning: Analyzing the connection to overfitting},
  author={Yeom, Samuel and Giacomelli, Irene and Fredrikson, Matt and Jha, Somesh},
  booktitle={2018 IEEE 31st computer security foundations symposium (CSF)},
  pages={268--282},
  year={2018},
  organization={IEEE}
}

@inproceedings{sablayrolles2019white,
  title={White-box vs black-box: Bayes optimal strategies for membership inference},
  author={Sablayrolles, Alexandre and Douze, Matthijs and Schmid, Cordelia and Ollivier, Yann and J{\'e}gou, Herv{\'e}},
  booktitle={International Conference on Machine Learning},
  pages={5558--5567},
  year={2019},
  organization={PMLR}
}

@article{salem2018ml,
  title={Ml-leaks: Model and data independent membership inference attacks and defenses on machine learning models},
  author={Salem, Ahmed and Zhang, Yang and Humbert, Mathias and Berrang, Pascal and Fritz, Mario and Backes, Michael},
  journal={arXiv preprint arXiv:1806.01246},
  year={2018}
}

@inproceedings{song2021systematic,
  title={Systematic evaluation of privacy risks of machine learning models},
  author={Song, Liwei and Mittal, Prateek},
  booktitle={30th USENIX Security Symposium (USENIX Security 21)},
  pages={2615--2632},
  year={2021}
}

@article{wen2022canary,
  title={Canary in a coalmine: Better membership inference with ensembled adversarial queries},
  author={Wen, Yuxin and Bansal, Arpit and Kazemi, Hamid and Borgnia, Eitan and Goldblum, Micah and Geiping, Jonas and Goldstein, Tom},
  journal={arXiv preprint arXiv:2210.10750},
  year={2022}
}

@article{maini2021dataset,
  title={Dataset inference: Ownership resolution in machine learning},
  author={Maini, Pratyush and Yaghini, Mohammad and Papernot, Nicolas},
  journal={arXiv preprint arXiv:2104.10706},
  year={2021}
}
@article{chaudhary2024quantitative,
  title={Quantitative Certification of Bias in Large Language Models},
  author={Chaudhary, Isha and Hu, Qian and Kumar, Manoj and Ziyadi, Morteza and Gupta, Rahul and Singh, Gagandeep},
  journal={arXiv preprint arXiv:2405.18780},
  year={2024}
}

@article{kumar2024certifying,
  title={Certifying LLM Safety against Adversarial Prompting. arXiv 2024},
  author={Kumar, Aounon and Agarwal, Chirag and Srinivas, Suraj and Li, AJ and Feizi, S and Lakkaraju, H},
  journal={arXiv preprint arXiv:2309.02705},
  year={2024}
}
@article{kang2024c,
  title={C-rag: Certified generation risks for retrieval-augmented language models},
  author={Kang, Mintong and G{\"u}rel, Nezihe Merve and Yu, Ning and Song, Dawn and Li, Bo},
  journal={arXiv preprint arXiv:2402.03181},
  year={2024}
}