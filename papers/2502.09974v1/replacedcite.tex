\section{Related Work}
\label{sec:related-work}

%\rl{We need to be a bit careful w this sentence bc the main contributions of the Carlini paper sort of boil down to a confidence score model -- still different from us as it works by checking how similar a given extracted candidate is to other candidates and giving confidence scores.} 

% To our knowledge, our work is the first to address ways for prompt owners to detect if their proprietary system prompt has been stolen. We contextualize our analysis and methods within the scope of prior work on topics such as the value of prompt engineering, feasibility of prompt theft, and the framing of membership inference techniques.
% \subsection{Prompt Engineering}
% Prompt engineering has emerged as an accessible approach to adapt LLMs for specific user needs ____.
% % leveraging their remarkable in-context learning capabilities ____.
% In-context learning ____ allows LLMs to acquire new skills by providing exemplars within the prompt, without retraining. A prominent technique is few-shot prompting ____, where the design of exemplars, such as their selection, ordering, and formatting, significantly impacts output quality ____, and many-shot prompting can even match the power of fine-tuning ____. Another line of work focuses on chain-of-thought prompting ____ which encourages LLMs to express their thought process before delivering the final answer, often leading to improved performance on reasoning tasks ____. 
% % Numerous variations of chain-of-thought prompting have been proposed, including zero-shot ____, automatic ____, uncertainty-routed ____, and others ____.
% Similarly, self-criticism techniques improve language models by encouraging them to criticize and refine their own outputs ____.

% % such as self-calibration ____, self-refinement ____, reverse chain-of-thought ____, self-verification ____, and chain-of-verification ____.

% Zero-shot prompting techniques, closely related to system prompts, include role prompting ____, emotion prompting ____, rephrase and respond ____, and self-ask ____. System prompts play a crucial role in shaping LLM outputs and driving performance in application domains ____.

% with tuned system prompts often being valuable enough to be sold at online marketplaces.\footnote{See \url{https://prompti.ai/chatgpt-prompt/}, \url{https://promptbase.com/}.}

\subsection{Prompt extraction attacks}
\looseness=-1
Prompt engineering has emerged as an accessible approach to adapt LLMs for specific user needs ____, with system prompts playing a crucial role in shaping LLM outputs and driving performance across application domains ____.
% Given the value of prompts, we can reasonably expect efforts to steal them. 
Prior work has proposed several prompt extraction attacks, which deduce the content of a proprietary system prompt by interacting with a model, both for language models ____ and for image generation models ____. 
____ frame the problem as model inversion, where they deduce the prompt given next token probabilities.
Similarly, ____ propose a method to extract prompts from sampled generative model outputs. 
Furthermore, ____ describe a way to uncover system prompts using context and response pairs.
Additionally, ____ present an evaluation of prompt extraction attacks for a variety of modern LLMs. 
In contrast to the works on inversion style methods, one can also find adversarial inputs that jailbreak LLMs ____ and even lead them to eliciting the system prompt in the response. Both ____ and ____ use optimization over prompt tokens to provoke LLMs to respond by quoting their own system prompts. Prompt reconstruction methods can also be adapted to solve the problem of prompt verification through comparing the reconstructed prompt to the reference prompt, however, their high computational cost ____, the need to access model gradients ____, and imperfect reconstruction success rate ____ motivate the development of methods specifically tailored to the problem of prompt reuse verification.
% This body of work convinces us that prompts can be stolen, and those developing valuable prompts should be interested in methods to detect such theft. 
% \valeriia{position our paper here}

\subsection{Data membership inference and extraction attacks on language models}

In the evolving discussion on data privacy, a significant topic is membership inference, which involves determining whether a particular data point is part of a model's training set ____. 
% Nonetheless, we are motivated by research on training data membership inference as methods that work in that setting may be interesting directions for those concerned with prompt membership inference.
____ and ____ both propose methods to determine membership in the training data based on the idea that models tend to behave differently on their training data than on other data. ____ further propose a more effective method and alleviate the need to know the target model's architecture, while ____ propose perturbing the query data to improve accuracy of their attack. 
____ consider the setting where the system includes an ensemble of models that may be updated over time. Other works explore training data membership inference in image generation models ____. Additionally, dataset inference techniques explore settings where the whole training set is considered rather than single data points ____.
Compared to the standard membership inference setting, our work addresses a related but distinct question: whether a given text is part of the LLM input context, thus exploring prompt membership inference. 
% While the goal differs between training data membership and prompt membership attacks, the problem formulation remains similar.
%Finally, while we focus on system prompt verification, statistical methods have been widely applied to verify LLM behaviors across various contexts ____.