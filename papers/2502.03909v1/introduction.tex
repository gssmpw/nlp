\section{Introduction}
In order to develop anomaly-based network intrusion detection systems (NIDS), proper labelled, representative, and diverse datasets are essential. The recent years of IDS research brought up many datasets, which can be used to train and evaluate traffic classification models. But still, there is a lack of properly labelled data with recent attacks. The cybersecurity sector is changing very fast, new attack mechanisms evolve and due to the use of encryption, it gets harder to analyze traffic on the application layer. Therefore, it is important to create new datasets that can cover a diverse range of attacks and traffic characteristics, to enable researchers to develop and evaluate defense mechanisms, such as NIDS.

However, it is very difficult to obtain or create such datasets. When collecting real-world traffic, for example in a company or university network, high privacy standards make it almost impossible to collect datasets containing payload data. Besides this issue, the labelling problem of such datasets is even more impactful. The data needs to be manually labelled and inspected, since using a pattern-based intrusion detection system could miss malicious traffic or unknown attacks, where the system does not have any pattern for. Such labelling processes are very time-consuming and result in small sample numbers. For training machine learning models, however, large sample numbers are needed to cover a wide variety and avoid overfitting. Uneven represented classes and too small sample numbers are a problem observed in popular NIDS datasets \cite{Leung_Leckie,Portnoy01intrusiondetection}. Large datasets ensure model robustness by covering diverse attack scenarios and reducing the likelihood of overfitting to specific traffic patterns.

In several popular datasets widely used in intrusion detection research, overfitting is a big issue due to small sample sizes of certain attacks or the aggregation of such attacks into taxonomy super classes~\cite{zoghi2024unsw}. Without careful analysis and debugging of new models, such issues may not be visible, especially when solving the binary intrusion detection problem, where the samples need to be classified into benign and attack samples. For such debugging, accurate and fine-grained labels are needed, i.e., having only class labels indicating that traffic was malicious or not is not sufficient. Even taxonomy classes, such as \emph{DoS}, \emph{probe}, etc., are not fine-grained enough and may introduce further issues. This problem was already identified by John McHugh in his critiques of the DARPA dataset. He criticizes the grouping of certain attacks, e.g., in the \emph{DoS} category, summarizes types of attacks which are anatomically different \cite{mchugh2000testing}. The particular attack-types with an accurate description of how the attacks were performed are needed to enable domain experts to perform an insightful model performance analysis~\cite{10223401}.

Tackling the aforementioned issues, we developed a traffic generator, which is highly modular and configurable. We generate a dataset that includes a diverse range of attacks, fine-grained labels, and realistic traffic characteristics, addressing the key limitations of existing datasets. Additionally, the dataset includes several web attack types that are typically underrepresented in other datasets~\cite{ring2019survey}, along with corresponding benign actions targeting the same network services. This ensures that the dataset aligns with real-world traffic patterns, where benign and malicious actions coexist.