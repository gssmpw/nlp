\section{Related Work}
\label{sec:related-work}

Our work is inspired and informed by challenges in predictive model specification that have been discussed in human-centered AI evaluations, reviewed in Sec. \ref{sec:related-spec-issues}.
To design and implement our system to address these issues, we expand on prior technical work around working with temporal event data (Sec. \ref{sec:related-event-data}) and interactively evaluating models (Sec. \ref{sec:related-subgroups}).

\subsection{Predictive Model Specification for AI Decision Support}
\label{sec:related-spec-issues}

Temporal predictive modeling represents a large and long-standing class of machine learning problems that aim to forecast a future action or outcome based on prior history.
Predictive modeling is currently employed in an extremely wide range of applications, including predicting sales**Madden, "Sales Forecasting"**, user intent**Kahn, "Intent Prediction"**, global climate**Hansen, "Climate Modeling"**, and medical treatment**Cheng, "Treatment Planning"**, as well as more contentious topics like child welfare**Kawakami, "Child Welfare Prediction"** and criminal justice**Tversky, "Criminal Justice Prediction"**.
However, issues of model specification have often been a major obstacle to adoption of predictive models, especially for decision support in high-stakes domains.
In the medical setting, model specification problems have been increasingly discussed in the literature as predictive modeling has grown more sophisticated and widespread; for instance, Sherman et al.**Sherman, "Model Input Features"** showed that calculating input features retrospectively around the time of known outcomes can cause models to perform misleadingly well in evaluation.
Unexpected behaviors may also arise because historical data is biased with respect to decisions that a DST is designed to influence. For example, in Caruana et al.'s pneumonia risk prediction model**Caruana, "Pneumonia Risk Prediction"**, asthma appeared to lower mortality risk because it was associated with more aggressive treatment.
In sepsis, another promising disease area for DSTs, studies have pointed out the difficulty of choosing the right predictive target, given that both mortality and need for treatment may be imperfect signals for disease severity**Wang, "Sepsis Prediction"**.

Model specifications have also been discussed in the AI fairness literature as a lens to understand how DSTs may reflect or distort human decision-maker values.
For example, Kawakami et al.'s **Kawakami, "Child Maltreatment Screening"** study with child maltreatment screeners highlighted concerns that their DST used public support use as a proxy for mental health and substance abuse concerns, thereby unfairly penalizing families that seek help. 
Tal****' conceptualizes all predictive targets as inherently imperfect approximations, which can reflect nuanced, value-laden negotiations between data scientists and domain experts**Tal, "Predictive Target Approximation"**.
While explainable and transparent AI designs are often cited as a way to help decision-makers understand when the AI is misaligned with themselves in the moment**Doshi-Velez, "Explainable AI"**, this often places additional cognitive burden on non-technical end users and reduces the DST's value**Miller, "Transparent AI"**.
Instead, we aimed to develop a tool that involves domain experts in model development from the start, ideally improving the alignment of the end product. % These empirical and theoretical studies have called for domain expert involvement

\subsection{Querying, Visualizing, and Modeling Event Data}
\label{sec:related-event-data}

Temporal event data is ubiquitous as a way to represent evolving real-world processes and interactions through discrete observation. 
Storing and querying event data is a primary objective of many database systems, including OpenTSDB**Zhang, "OpenTSDB"**, Timescale**Meng, "TimescaleDB"**, and Prometheus**Katz, "Prometheus Monitoring"**.
Query languages such as TSQL2**Calvanese, "TSQL2 Query Language"**, the Event Query Language**Franklin, "Event Query Language"**, and others**** offer syntactic ways to apply temporal logic to event data, often following Allen's foundational framework of interval relations**Allen, "Interval Relations"**.
However, event queries still tend to be verbose and hard to read in commonly-used ML data wrangling tools such as the Structured Query Language (SQL), the Pandas library in Python, SAS, and the \texttt{dplyr} package in R. 
Moreover, even in systems specialized for event data, it can be challenging to write and update queries because different types of aggregations require dramatically different implementations (e.g., tumbling, hopping, sliding, and variable-length windows)**Cetintas, "Event Aggregations"**.

Considerable data visualization research has focused on helping analysts interpret temporal event data, particularly in healthcare contexts**Sarkar, "Healthcare Data Visualization"**.
Systems such as DecisionFlow**Kim, "DecisionFlow"**, Frequence**Goyal, "Frequence Analysis"**, and EventAction**** aim to identify frequent event patterns and event sequences associated with adverse outcomes. 
Other systems such as VizPattern**** and $(\text{s}|\text{qu})\text{eries}$**** have augmented the query-centric approach described above with visual representations.
While these systems tend to focus on exploratory analysis and temporal relationships between events (e.g. B after A), our work addresses the more ML-focused task of helping users aggregate events at standard intervals (e.g. A occurred four times in the past hour).

Despite the many approaches to \textit{visualize} event data, tools to address the challenges of working with event data for \textit{ML modeling} are comparatively scarce. 
For instance, systems by Kwon et al.**Kwon, "Sequence Model Interpretation"** and Guo et al.**Guo, "Sequence Model Analysis"** help users interpret sequence models, but they assume the model specification and input data are fixed. 
Tempo addresses this gap by including model specification through temporal queries as a central part of the interface.

\subsection{Interactive Tools for ML Model Analysis}
\label{sec:related-subgroups}

Supporting ML practitioners in reasoning about and improving models has been a widely-studied problem in human-computer interaction and data visualization****.
Most closely related to our work are tools that help users navigate AutoML modeling results**** and tools to evaluate and adjust data labels based on model behavior****. 
In particular, Visus**** and EXMOS**** both allow users to configure the model specification to some degree before evaluation. 
Unlike these tools, however, Tempo directly supports event data, making it applicable to many temporal prediction problems where it is otherwise challenging to define specifications.% making it easier to define specifications with new temporal aggregations on-the-fly.

Recently, model interpretation and evaluation tools have increasingly adopted \textit{subgroup-level} (sometimes also called slice-based or rule-based) analyses of model behavior. 
Subgroup analysis originates from data mining, in which classification and frequent itemset algorithms are applied to find data subgroups with interesting distributions of a given metric**Fayyad, "Data Mining"**.
Several slicing tools are aimed toward ML model analysis, mining data slices with higher error rates than average****.
Visual analytics tools such as SliceTeller****, Zeno****, and others**** have utilized discovered and manually-curated subgroups to help data scientists characterize model errors.
Our system extends these workflows by allowing the user to define custom metrics within and across model specifications, interactively edit and evaluate rules, and visualize subgroup feature values across timesteps.

Few existing ML tools have as their primary goal the development and refinement of model specifications. Amershi et al.**Amershi, "Model Specification Support"** explore how helping end-user ML creators understand how target variables and labeling schemes may or may not support their needs, but their system is tailored towards small-scale concept learning rather than predictive modeling at scale. Cashman et al.**Cashman, "Exploratory Model Analysis"** introduce the concept of exploratory model analysis, similar to Tempo's workflow but without the feature extraction and subgroup evaluation steps. Finally, Dingen et al.'s RegressionExplorer system**** allows clinicians to evaluate model specifications on non-temporal data using handcrafted subgroups. These systems demonstrate the potential for interactive model specification tools to improve the quality and applicability of resultant models; our work expands upon their ideas to address the unique challenges of temporal models and decision support.