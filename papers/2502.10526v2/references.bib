
@article{Liu2017a,
	title = {Towards better analysis of machine learning models: {A} visual analytics perspective},
		issn = {2468502X},
	url = {http://dx.doi.org/10.1016/j.visinf.2017.01.006},
	doi = {10.1016/j.visinf.2017.01.006},
	abstract = {Interactive model analysis, the process of understanding, diagnosing, and refining a machine learning model with the help of interactive visualization, is very important for users to efficiently solve real-world artificial intelligence and data mining problems. Dramatic advances in big data analytics have led to a wide variety of interactive model analysis tasks. In this paper, we present a comprehensive analysis and interpretation of this rapidly developing area. Specifically, we classify the relevant work into three categories: understanding, diagnosis, and refinement. Each category is exemplified by recent influential work. Possible future research opportunities are also explored and discussed.},
	number = {1},
	journal = {Visual Informatics},
	author = {Liu, Shixia and Wang, Xiting and Liu, Mengchen and Zhu, Jun},
	year = {2017},
	note = {arXiv: 1702.01226
Publisher: Elsevier B.V.},
	keywords = {Diagnosis, Interactive model analysis, Interactive visualization, Machine learning, Refinement, Understanding},
	pages = {48--56},
	file = {PDF:/Users/vsivaram/Zotero/storage/GY4YRG6H/1-s2.0-S2468502X17300086-main.pdf:application/pdf},
}

@article{amershi_modeltracker_2015,
	title = {{ModelTracker} : {Redesigning} {Performance} {Analysis} {Tools} for {Machine} {Learning}},
	author = {Amershi, Saleema and Chickering, Max and Drucker, Steven M and Lee, Bongshin and Simard, Patrice and Suh, Jina},
	year = {2015},
	note = {ISBN: 9781450331456},
	pages = {337--346},
	file = {PDF:/Users/vsivaram/Zotero/storage/PKM5G45K/2702123.2702509.pdf:application/pdf},
}

@article{Jin2020,
	title = {{CarePre}: {An} intelligent clinical decision assistance system},
		issn = {2691-1957},
	doi = {10.1145/3344258},
	abstract = {Clinical decision support systems are widely used to assist with medical decision making. However, clinical decision support systems typically require manually curated rules and other data that are difficult to maintain and keep up to date. Recent systems leverage advanced deep learning techniques and electronic health records to provide a more timely and precise result. Many of these techniques have been developed with a common focus on predicting upcoming medical events. However, although the prediction results from these approaches are promising, their value is limited by their lack of interpretability. To address this challenge, we introduce CarePre, an intelligent clinical decision assistance system. The system extends a state-of-the-art deep learning model to predict upcoming diagnosis events for a focal patient based on his or her historical medical records. The system includes an interactive framework together with intuitive visualizations designed to support diagnosis, treatment outcome analysis, and the interpretation of the analysis results. We demonstrate the effectiveness and usefulness of the CarePre system by reporting results from a quantities evaluation of the prediction algorithm, two case studies, and interviews with senior physicians and pulmonologists.},
	number = {1},
	journal = {ACM Transactions on Computing for Healthcare},
	author = {Jin, Zhuochen and Cui, Shuyuan and Guo, Shunan and Gotz, David and Sun, Jimeng and Cao, Nan},
	year = {2020},
	pages = {1--20},
	file = {PDF:/Users/vsivaram/Zotero/storage/HNGBFFEP/3344258.pdf:application/pdf},
}

@article{zhang_manifold_2019,
	title = {Manifold: {A} {Model}-{Agnostic} {Framework} for {Interpretation} and {Diagnosis} of {Machine} {Learning} {Models}},
	volume = {25},
	issn = {19410506},
	doi = {10.1109/TVCG.2018.2864499},
	abstract = {Interpretation and diagnosis of machine learning models have gained renewed interest in recent years with breakthroughs in new approaches. We present Manifold, a framework that utilizes visual analysis techniques to support interpretation, debugging, and comparison of machine learning models in a more transparent and interactive manner. Conventional techniques usually focus on visualizing the internal logic of a specific model type (i.e., deep neural networks), lacking the ability to extend to a more complex scenario where different model types are integrated. To this end, Manifold is designed as a generic framework that does not rely on or access the internal logic of the model and solely observes the input (i.e., instances or features) and the output (i.e., the predicted result and probability distribution). We describe the workflow of Manifold as an iterative process consisting of three major phases that are commonly involved in the model development and diagnosis process: inspection (hypothesis), explanation (reasoning), and refinement (verification). The visual components supporting these tasks include a scatterplot-based visual summary that overviews the models' outcome and a customizable tabular view that reveals feature discrimination. We demonstrate current applications of the framework on the classification and regression tasks and discuss other potential machine learning use scenarios where Manifold can be applied.},
	number = {1},
	journal = {IEEE Transactions on Visualization and Computer Graphics},
	author = {Zhang, Jiawei and Wang, Yang and Molino, Piero and Li, Lezhi and Ebert, David S.},
	year = {2019},
	pmid = {30130197},
	note = {arXiv: 1808.00196},
	keywords = {Interactive machine learning, model comparison, model debugging, performance analysis},
	pages = {364--373},
	file = {PDF:/Users/vsivaram/Zotero/storage/S4YKWEB2/1808.00196.pdf:application/pdf},
}

@book{yuan_isea_2022,
	title = {{iSEA}: {An} {Interactive} {Pipeline} for {Semantic} {Error} {Analysis} of {NLP} {Models}},
		isbn = {978-1-4503-9144-3},
	abstract = {Error analysis in NLP models is essential to successful model development and deployment. One common approach for diagnosing errors is to identify subpopulations in the dataset where the model produces the most errors. However, existing approaches typically define subpopulations based on pre-defined features, which requires users to form hypotheses of errors in advance. To complement these approaches, we propose iSEA, an Interactive Pipeline for Semantic Error Analysis in NLP Models, which automatically discovers semantically-grounded subpopulations with high error rates in the context of a human-in-the-loop interactive system. iSEA enables model developers to learn more about their model errors through discovered subpopulations, validate the sources of errors through interactive analysis on the discovered subpopulations, and test hypotheses about model errors by defining custom subpopulations. The tool supports semantic descriptions of error-prone subpopulations at the token and concept level, as well as pre-defined higher-level features. Through use cases and expert interviews, we demonstrate how iSEA can assist error understanding and analysis.},
	publisher = {Association for Computing Machinery},
	author = {Yuan, Jun and Vig, Jesse and Rajani, Nazneen},
	year = {2022},
	doi = {10.1145/3490099.3511146},
	note = {arXiv: 2203.04408v1
Publication Title: International Conference on Intelligent User Interfaces, Proceedings IUI
Issue: 1},
	keywords = {Error Analysis, xAI},
	file = {PDF:/Users/vsivaram/Zotero/storage/AFH5IF5S/2203.04408.pdf:application/pdf},
}

@article{wu_errudite_2020,
	title = {Errudite: {Scalable}, reproducible, and testable error analysis},
	doi = {10.18653/v1/p19-1073},
	abstract = {Though error analysis is crucial to understanding and improving NLP models, the common practice of manual, subjective categorization of a small sample of errors can yield biased and incomplete conclusions. This paper codifies model and task agnostic principles for informative error analysis, and presents Errudite, an interactive tool for better supporting this process. First, error groups should be precisely defined for reproducibility; Errudite supports this with an expressive domain-specific language. Second, to avoid spurious conclusions, a large set of instances should be analyzed, including both positive and negative examples; Errudite enables systematic grouping of relevant instances with filtering queries. Third, hypotheses about the cause of errors should be explicitly tested; Errudite supports this via automated counterfactual rewriting. We validate our approach with a user study, finding that Errudite (1) enables users to perform high quality and reproducible error analyses with less effort, (2) reveals substantial ambiguities in prior published error analyses practices, and (3) enhances the error analysis experience by allowing users to test and revise prior beliefs.},
	journal = {ACL 2019 - 57th Annual Meeting of the Association for Computational Linguistics, Proceedings of the Conference},
	author = {Wu, Tongshuang and Ribeiro, Marco Tulio and Heer, Jeffrey and Weld, Daniel S.},
	year = {2020},
	note = {ISBN: 9781950737482},
	pages = {747--763},
	file = {PDF:/Users/vsivaram/Zotero/storage/464X4LM2/P19-1073.pdf:application/pdf},
}

@article{cito_explaining_2021,
	title = {Explaining mispredictions of machine learning models using rule induction},
	doi = {10.1145/3468264.3468614},
	abstract = {While machine learning (ML) models play an increasingly prevalent role in many software engineering tasks, their prediction accuracy is often problematic. When these models do mispredict, it can be very difficult to isolate the cause. In this paper, we propose a technique that aims to facilitate the debugging process of trained statistical models. Given an ML model and a labeled data set, our method produces an interpretable characterization of the data on which the model performs particularly poorly. The output of our technique can be useful for understanding limitations of the training data or the model itself; it can also be useful for ensembling if there are multiple models with different strengths. We evaluate our approach through case studies and illustrate how it can be used to improve the accuracy of predictive models used for software engineering tasks within Facebook.},
	journal = {ESEC/FSE 2021 - Proceedings of the 29th ACM Joint Meeting European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
	author = {Cito, Jürgen and Dillig, Isil and Kim, Seohyun and Murali, Vijayaraghavan and Chandra, Satish},
	year = {2021},
	note = {ISBN: 9781450385626},
	keywords = {explainability, machine learning, rule induction},
	pages = {716--727},
	file = {PDF:/Users/vsivaram/Zotero/storage/BXQSFKNC/3468264.3468614.pdf:application/pdf},
}

@article{sagadeeva_sliceline_2021,
	title = {{SliceLine}: {Fast}, {Linear}-{Algebra}-based {Slice} {Finding} for {ML} {Model} {Debugging}},
	issn = {07308078},
	doi = {10.1145/3448016.3457323},
	abstract = {Slice finding - -a recent work on debugging machine learning (ML) models - -aims to find the top-K data slices (e.g., conjunctions of predicates such as gender female and degree PhD), where a trained model performs significantly worse than on the entire training/test data. These slices may be used to acquire more data for the problematic subset, add rules, or otherwise improve the model. In contrast to decision trees, the general slice finding problem allows for overlapping slices. The resulting search space is huge as it covers all subsets of features and their distinct values. Hence, existing work primarily relies on heuristics and focuses on small datasets that fit in memory of a single node. In this paper, we address these scalability limitations of slice finding in a holistic manner from both algorithmic and system perspectives. We leverage monotonicity properties of slice sizes, errors and resulting scores to facilitate effective pruning. Additionally, we present an elegant linear-algebra-based enumeration algorithm, which allows for fast enumeration and automatic parallelization on top of existing ML systems. Experiments with different real-world regression and classification datasets show that effective pruning and efficient sparse linear algebra renders exact enumeration feasible, even for datasets with many features, correlations, and data sizes beyond single node memory.},
	journal = {Proceedings of the ACM SIGMOD International Conference on Management of Data},
	author = {Sagadeeva, Svetlana and Boehm, Matthias},
	year = {2021},
	note = {ISBN: 9781450383431},
	keywords = {data coverage, frequent itemset mining, large-scale machine learning, linear algebra, model debugging, slice finding},
	pages = {2290--2299},
	file = {PDF:/Users/vsivaram/Zotero/storage/FHIQRHDQ/sigmod2021b_sliceline.pdf:application/pdf},
}

@article{cabrera_fairvis_2019,
	title = {{FAIRVIS}: {Visual} {Analytics} for {Discovering} {Intersectional} {Bias} in {Machine} {Learning}},
	doi = {10.1109/VAST47406.2019.8986948},
	abstract = {The growing capability and accessibility of machine learning has led to its application to many real-world domains and data about people. Despite the benefits algorithmic systems may bring, models can reflect, inject, or exacerbate implicit and explicit societal biases into their outputs, disadvantaging certain demographic subgroups. Discovering which biases a machine learning model has introduced is a great challenge, due to the numerous definitions of fairness and the large number of potentially impacted subgroups. We present FAIRVIS, a mixed-initiative visual analytics system that integrates a novel subgroup discovery technique for users to audit the fairness of machine learning models. Through FAIRVIS, users can apply domain knowledge to generate and investigate known subgroups, and explore suggested and similar subgroups. FAIRVIS's coordinated views enable users to explore a high-level overview of subgroup performance and subsequently drill down into detailed investigation of specific subgroups. We show how FAIRVIS helps to discover biases in two real datasets used in predicting income and recidivism. As a visual analytics system devoted to discovering bias in machine learning, FAIRVIS demonstrates how interactive visualization may help data scientists and the general public understand and create more equitable algorithmic systems.},
	journal = {2019 IEEE Conference on Visual Analytics Science and Technology, VAST 2019 - Proceedings},
	author = {Cabrera, Angel Alexander and Epperson, Will and Hohman, Fred and Kahng, Minsuk and Morgenstern, Jamie and Chau, Duen Horng},
	year = {2019},
	note = {arXiv: 1904.05419
ISBN: 9781728122847},
	keywords = {intersectional bias, Machine learning fairness, subgroup discovery, visual analytics},
	pages = {46--56},
	file = {PDF:/Users/vsivaram/Zotero/storage/SWJJT2BI/1904.05419.pdf:application/pdf},
}

@article{kahng_visual_2016,
	title = {Visual exploration of machine learning results using data cube analysis},
	doi = {10.1145/2939502.2939503},
	abstract = {As complex machine learning systems become more widely adopted, it becomes increasingly challenging for users to understand models or interpret the results generated from the models. We present our ongoing work on developing interactive and visual approaches for exploring and understanding machine learning results using data cube analysis. We propose MLCube, a data cube inspired framework that enables users to define instance subsets using feature conditions and computes aggregate statistics and evaluation metrics over the subsets. We also design MLCube Explorer, an interactive visualization tool for comparing models' performances over the subsets. Users can interactively specify operations, such as drilling down to specific instance subsets, to perform more in-depth exploration. Through a usage scenario, we demonstrate how MLCube Explorer works with a public advertisement click log data set, to help a user build new advertisement click prediction models that advance over an existing model.},
	journal = {HILDA 2016 - Proceedings of the Workshop on Human-In-the-Loop Data Analytics},
	author = {Kahng, Minsuk and Fang, Dezhi and Chau, Duen Horng},
	year = {2016},
	note = {ISBN: 9781450342070},
	keywords = {Data cube, Data visualization, Interactive data analysis, Machine learning},
	file = {PDF:/Users/vsivaram/Zotero/storage/8XYV3GF6/2939502.2939503.pdf:application/pdf},
}

@article{perer_frequence_2014,
	title = {Frequence: {Interactive} mining and visualization of temporal frequent event sequences},
	doi = {10.1145/2557500.2557508},
	abstract = {Extracting insights from temporal event sequences is an important challenge. In particular, mining frequent patterns from event sequences is a desired capability for many domains. However, most techniques for mining frequent patterns are ineffective for real-world data that may be lowresolution, concurrent, or feature many types of events, or the algorithms may produce results too complex to interpret. To address these challenges, we propose Frequence, an intelligent user interface that integrates data mining and visualization in an interactive hierarchical information exploration system for finding frequent patterns from longitudinal event sequences. Frequence features a novel frequent sequence mining algorithm to handle multiple levels-of-detail, temporal context, concurrency, and outcome analysis. Frequence also features a visual interface designed to support insights, and support exploration of patterns of the level-of-detail relevant to users. Frequence's effectiveness is demonstrated with two use cases: Medical research mining event sequences from clinical records to understand the progression of a disease, and social network research using frequent sequences from Foursquare to understand the mobility of people in an urban environment. © 2014 ACM.},
	journal = {International Conference on Intelligent User Interfaces, Proceedings IUI},
	author = {Perer, Adam and Wang, Fei},
	year = {2014},
	note = {ISBN: 9781450321846},
	keywords = {Frequent Sequence Mining, Temporal Visualization, Visual Analytics},
	pages = {153--162},
	file = {PDF:/Users/vsivaram/Zotero/storage/3AD42FL6/2557500.2557508.pdf:application/pdf},
}


@article{zhang_sliceteller_2022,
	title = {{SliceTeller}: {A} {Data} {Slice}-{Driven} {Approach} for {Machine} {Learning} {Model} {Validation}},
	volume = {29},
	issn = {19410506},
	doi = {10.1109/TVCG.2022.3209465},
	abstract = {Real-world machine learning applications need to be thoroughly evaluated to meet critical product requirements for model release, to ensure fairness for different groups or individuals, and to achieve a consistent performance in various scenarios. For example, in autonomous driving, an object classification model should achieve high detection rates under different conditions of weather, distance, etc. Similarly, in the financial setting, credit-scoring models must not discriminate against minority groups. These conditions or groups are called as \&\#x201C;{\textless}italic{\textgreater}Data Slices{\textless}/italic{\textgreater}\&\#x201D;. In product MLOps cycles, product developers must identify such critical data slices and adapt models to mitigate data slice problems. {\textless}italic{\textgreater}Discovering{\textless}/italic{\textgreater} where models fail, {\textless}italic{\textgreater}understanding{\textless}/italic{\textgreater} why they fail, and {\textless}italic{\textgreater}mitigating{\textless}/italic{\textgreater} these problems, are therefore essential tasks in the MLOps life-cycle. In this paper, we present {\textless}bold{\textgreater}{\textless}italic{\textgreater}SliceTeller{\textless}/italic{\textgreater}{\textless}/bold{\textgreater} , a novel tool that allows users to debug, compare and improve machine learning models driven by {\textless}italic{\textgreater}critical{\textless}/italic{\textgreater} data slices. {\textless}italic{\textgreater}SliceTeller{\textless}/italic{\textgreater} automatically discovers problematic slices in the data, helps the user understand why models fail. More importantly, we present an efficient algorithm, {\textless}bold{\textgreater}{\textless}italic{\textgreater}SliceBoosting{\textless}/italic{\textgreater}{\textless}/bold{\textgreater}, to estimate trade-offs when prioritizing the optimization over certain slices. Furthermore, our system empowers model developers to compare and analyze different model versions during model iterations, allowing them to choose the model version best suitable for their applications. We evaluate our system with three use cases, including two real-world use cases of {\textless}italic{\textgreater}product development{\textless}/italic{\textgreater}, to demonstrate the power of {\textless}italic{\textgreater}SliceTeller{\textless}/italic{\textgreater} in the debugging and improvement of product-quality ML models.},
	number = {1},
	journal = {IEEE Transactions on Visualization and Computer Graphics},
	author = {Zhang, Xiaoyu and Ono, Jorge Piazentin and Song, Huan and Gou, Liang and Ma, Kwan Liu and Ren, Liu},
	year = {2022},
	note = {Publisher: IEEE},
	keywords = {Adaptation models, Analytical models, Computational modeling, Data models, Data Slicing, Data Validation, Data-Centric AI, Human-in-the-loop, Model Evaluation, Model Validation, Optimization, Predictive models, Training},
	pages = {842--852},
	file = {PDF:/Users/vsivaram/Zotero/storage/W6IFDB62/SliceTeller_A_Data_Slice-Driven_Approach_for_Machine_Learning_Model_Validation.pdf:application/pdf},
}


@article{chung_automated_2020,
	title = {Slice {Finder}: {Automated} {Data} {Slicing} for {Model} {Validation}},
	volume = {32},
	issn = {15582191},
	doi = {10.1109/TKDE.2019.2916074},
	abstract = {As machine learning systems become democratized, it becomes increasingly important to help users easily debug their models. However, current data tools are still primitive when it comes to helping users trace model performance problems all the way to the data. We focus on the particular problem of slicing data to identify subsets of the validation data where the model performs poorly. This is an important problem in model validation because the overall model performance can fail to reflect that of the smaller subsets, and slicing allows users to analyze the model performance on a more granular-level. Unlike general techniques (e.g., clustering) that can find arbitrary slices, our goal is to find interpretable slices (which are easier to take action compared to arbitrary subsets) that are problematic and large. We propose mathsf\{Slice Finder\}SliceFinder, which is an interactive framework for identifying such slices using statistical techniques. Applications include diagnosing model fairness and fraud detection, where identifying slices that are interpretable to humans is crucial. This research is part of a larger trend of Big data and Artificial Intelligence (AI) integration and opens many opportunities for new research.},
	number = {12},
	journal = {IEEE Transactions on Knowledge and Data Engineering},
	author = {Chung, Yeounoh and Kraska, Tim and Polyzotis, Neoklis and Tae, Ki Hyun and Whang, Steven Euijong},
	year = {2020},
	note = {arXiv: 1807.06068},
	keywords = {Data slicing, model analysis, model validation},
	pages = {2284--2296},
	file = {PDF:/Users/vsivaram/Zotero/storage/DWGD4EXD/Slice_Finder_Automated_Data_Sclicing_for_Model_Val.pdf:application/pdf},
}


@article{jain_distilling_2022,
	title = {Distilling {Model} {Failures} as {Directions} in {Latent} {Space}},
	url = {http://arxiv.org/abs/2206.14754},
	abstract = {Existing methods for isolating hard subpopulations and spurious correlations in datasets often require human intervention. This can make these methods labor-intensive and dataset-specific. To address these shortcomings, we present a scalable method for automatically distilling a model's failure modes. Specifically, we harness linear classifiers to identify consistent error patterns, and, in turn, induce a natural representation of these failure modes as directions within the feature space. We demonstrate that this framework allows us to discover and automatically caption challenging subpopulations within the training dataset. Moreover, by combining our framework with off-the-shelf diffusion models, we can generate images that are especially challenging for the analyzed model, and thus can be used to perform synthetic data augmentation that helps remedy the model's failure modes. Code available at https://github.com/MadryLab/failure-directions},
	author = {Jain, Saachi and Lawrence, Hannah and Moitra, Ankur and Madry, Aleksander},
	year = {2022},
	note = {arXiv: 2206.14754},
	file = {PDF:/Users/vsivaram/Zotero/storage/Y5VS9LTE/2206.14754.pdf:application/pdf},
}

@article{deon_spotlight_2022,
	title = {The {Spotlight}: {A} {General} {Method} for {Discovering} {Systematic} {Errors} in {Deep} {Learning} {Models}},
	doi = {10.1145/3531146.3533240},
	abstract = {Supervised learning models often make systematic errors on rare subsets of the data. When these subsets correspond to explicit labels in the data (e.g., gender, race) such poor performance can be identified straightforwardly. This paper introduces a method for discovering systematic errors that do not correspond to such explicitly labelled subgroups. The key idea is that similar inputs tend to have similar representations in the final hidden layer of a neural network. We leverage this structure by "shining a spotlight"on this representation space to find contiguous regions in which the model performs poorly. We show that the Spotlight surfaces semantically meaningful areas of weakness in a wide variety of existing models spanning computer vision, NLP, and recommender systems, and we verify its performance through quantitative experiments.},
	journal = {ACM International Conference Proceeding Series},
	author = {D'Eon, Greg and D'Eon, Jason and Wright, James R. and Leyton-Brown, Kevin},
	year = {2022},
	note = {arXiv: 2107.00758
ISBN: 9781450393522},
	keywords = {auditing, deep learning, distributional robustness, fairness},
	pages = {1962--1981},
	file = {PDF:/Users/vsivaram/Zotero/storage/5PAYL6XD/2107.00758.pdf:application/pdf},
}


@inproceedings{zhu_generating_2022,
	title = {Generating {Interpretable} {Data}-{Based} {Explanations} for {Fairness} {Debugging} using {Gopher}},
		isbn = {978-1-4503-9249-5},
	abstract = {Machine learning (ML) models, while increasingly being used to make life-altering decisions, are known to reinforce systemic bias and discrimination. Consequently, practitioners and model developers need tools to facilitate debugging for bias in ML models. We introduce Gopher, a system that generates compact, interpretable and causal explanations for ML model bias. Gopher identifies the top-k coherent subsets of the training data that are root causes for model bias by quantifying the extent to which removing or updating a subset can resolve the bias. We describe the architecture of Gopher and will walk the audience through real-world use cases to highlight how Gopher generates explanations that enable data scientists to understand how subsets of the training data contribute to the bias of a machine learning (ML) model. Gopher is available as open-source software; The code and the demonstration video are available at https://gopher-sys.github.io/.},
	booktitle = {Proceedings of the {ACM} {SIGMOD} {International} {Conference} on {Management} of {Data}},
	publisher = {Association for Computing Machinery},
	author = {Zhu, Jiongli and Pradhan, Romila and Glavic, Boris and Salimi, Babak},
	year = {2022},
	doi = {10.1145/3514221.3520170},
	note = {arXiv: 2112.09745v2
Publication Title: Proceedings of the ACM SIGMOD International Conference on Management of Data
Issue: 1
ISSN: 07308078},
	keywords = {data debugging, explanations, fairness, interpretability},
	file = {PDF:/Users/vsivaram/Zotero/storage/BX988AKL/2112.09745.pdf:application/pdf},
}


@article{eyuboglu_domino_2022,
	title = {Domino: {Discovering} {Systematic} {Errors} with {Cross}-{Modal} {Embeddings}},
	url = {http://arxiv.org/abs/2203.14960},
	abstract = {Machine learning models that achieve high overall accuracy often make systematic errors on important subsets (or slices) of data. Identifying underperforming slices is particularly challenging when working with high-dimensional inputs (e.g. images, audio), where important slices are often unlabeled. In order to address this issue, recent studies have proposed automated slice discovery methods (SDMs), which leverage learned model representations to mine input data for slices on which a model performs poorly. To be useful to a practitioner, these methods must identify slices that are both underperforming and coherent (i.e. united by a human-understandable concept). However, no quantitative evaluation framework currently exists for rigorously assessing SDMs with respect to these criteria. Additionally, prior qualitative evaluations have shown that SDMs often identify slices that are incoherent. In this work, we address these challenges by first designing a principled evaluation framework that enables a quantitative comparison of SDMs across 1,235 slice discovery settings in three input domains (natural images, medical images, and time-series data). Then, motivated by the recent development of powerful cross-modal representation learning approaches, we present Domino, an SDM that leverages cross-modal embeddings and a novel error-aware mixture model to discover and describe coherent slices. We find that Domino accurately identifies 36\% of the 1,235 slices in our framework - a 12 percentage point improvement over prior methods. Further, Domino is the first SDM that can provide natural language descriptions of identified slices, correctly generating the exact name of the slice in 35\% of settings.},
	author = {Eyuboglu, Sabri and Varma, Maya and Saab, Khaled and Delbrouck, Jean-Benoit and Lee-Messer, Christopher and Dunnmon, Jared and Zou, James and Ré, Christopher},
	year = {2022},
	note = {arXiv: 2203.14960},
	pages = {1--28},
	file = {PDF:/Users/vsivaram/Zotero/storage/DFF4QQM3/2203.14960.pdf:application/pdf},
}

@article{chen_mandoline_2021,
	title = {Mandoline: {Model} {Evaluation} under {Distribution} {Shift}},
	url = {http://arxiv.org/abs/2107.00643},
	abstract = {Machine learning models are often deployed in different settings than they were trained and validated on, posing a challenge to practitioners who wish to predict how well the deployed model will perform on a target distribution. If an unlabeled sample from the target distribution is available, along with a labeled sample from a possibly different source distribution, standard approaches such as importance weighting can be applied to estimate performance on the target. However, importance weighting struggles when the source and target distributions have non-overlapping support or are high-dimensional. Taking inspiration from fields such as epidemiology and polling, we develop Mandoline, a new evaluation framework that mitigates these issues. Our key insight is that practitioners may have prior knowledge about the ways in which the distribution shifts, which we can use to better guide the importance weighting procedure. Specifically, users write simple "slicing functions" - noisy, potentially correlated binary functions intended to capture possible axes of distribution shift - to compute reweighted performance estimates. We further describe a density ratio estimation framework for the slices and show how its estimation error scales with slice quality and dataset size. Empirical validation on NLP and vision tasks shows that {\textbackslash}name can estimate performance on the target distribution up to \$3{\textbackslash}times\$ more accurately compared to standard baselines.},
	author = {Chen, Mayee and Goel, Karan and Sohoni, Nimit and Poms, Fait and Fatahalian, Kayvon and Ré, Christopher},
	year = {2021},
	note = {arXiv: 2107.00643},
	pages = {1--33},
	file = {PDF:/Users/vsivaram/Zotero/storage/P6482GGB/2107.00643.pdf:application/pdf},
}


@inproceedings{robertson_angler_2023,
	title = {Angler : {Helping} {Machine} {Translation} {Practitioners} {Prioritize} {Model} {Improvements}},
		doi = {10.1145/3544548.3580790},
	booktitle = {Proceedings of the 2023 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems} ({CHI} '23)},
	publisher = {Association for Computing Machinery},
	author = {Robertson, Samantha and Wang, Zijie J and Moritz, Dominik and Kery, Mary Beth and Hohman, Fred},
	year = {2023},
	doi = {10.1145/3544548.3580790},
	keywords = {acm reference format, dominik moritz, machine translation, mary beth kery, model evaluation, Model evaluation, machine translation, visual anal, samantha robertson, visual analytics, wang, zijie j},
	file = {PDF:/Users/vsivaram/Zotero/storage/RA4MKCBZ/23_translate_chi.pdf:application/pdf},
}

@inproceedings{hedderich_label-descriptive_2022,
	title = {Label-{Descriptive} {Patterns} and {Their} {Application} to {Characterizing} {Classification} {Errors}},
	url = {https://proceedings.mlr.press/v162/hedderich22a.html},
	abstract = {State-of-the-art deep learning methods achieve human-like performance on many tasks, but make errors nevertheless. Characterizing these errors in easily interpretable terms gives insight into whether a classifier is prone to making systematic errors, but also gives a way to act and improve the classifier. We propose to discover those feature-value combinations (i.e., patterns) that strongly correlate with correct resp. erroneous predictions to obtain a global and interpretable description for arbitrary classifiers. We show this is an instance of the more general label description problem, which we formulate in terms of the Minimum Description Length principle. To discover a good pattern set, we develop the efficient Premise algorithm. Through an extensive set of experiments we show it performs very well in practice on both synthetic and real-world data. Unlike existing solutions, it ably recovers ground truth patterns, even on highly imbalanced data over many features. Through two case studies on Visual Question Answering and Named Entity Recognition, we confirm that Premise gives clear and actionable insight into the systematic errors made by modern NLP classifiers.},
	language = {en},
	urldate = {2023-11-13},
	booktitle = {Proceedings of the 39th {International} {Conference} on {Machine} {Learning}},
	publisher = {PMLR},
	author = {Hedderich, Michael A. and Fischer, Jonas and Klakow, Dietrich and Vreeken, Jilles},
	month = jun,
	year = {2022},
	note = {ISSN: 2640-3498},
	pages = {8691--8707},
	file = {Full Text PDF:/Users/vsivaram/Zotero/storage/KIH3AVDC/Hedderich et al. - 2022 - Label-Descriptive Patterns and Their Application t.pdf:application/pdf},
}

@misc{suzuki_rule_2023,
	title = {Rule {Mining} for {Correcting} {Classification} {Models}},
	url = {http://arxiv.org/abs/2310.06446},
	abstract = {Machine learning models need to be continually updated or corrected to ensure that the prediction accuracy remains consistently high. In this study, we consider scenarios where developers should be careful to change the prediction results by the model correction, such as when the model is part of a complex system or software. In such scenarios, the developers want to control the specification of the corrections. To achieve this, the developers need to understand which subpopulations of the inputs get inaccurate predictions by the model. Therefore, we propose correction rule mining to acquire a comprehensive list of rules that describe inaccurate subpopulations and how to correct them. We also develop an efficient correction rule mining algorithm that is a combination of frequent itemset mining and a unique pruning technique for correction rules. We observed that the proposed algorithm found various rules which help to collect data insufficiently learned, directly correct model outputs, and analyze concept drift.},
	urldate = {2023-11-13},
	publisher = {arXiv},
	author = {Suzuki, Hirofumi and Iwashita, Hiroaki and Takagi, Takuya and Fujishige, Yuta and Hara, Satoshi},
	month = oct,
	year = {2023},
	note = {arXiv:2310.06446 [cs]},
	keywords = {Computer Science - Machine Learning, Computer Science - Software Engineering},
	file = {arXiv.org Snapshot:/Users/vsivaram/Zotero/storage/EHTMITF3/2310.html:text/html;Full Text PDF:/Users/vsivaram/Zotero/storage/WEU83WBP/Suzuki et al. - 2023 - Rule Mining for Correcting Classification Models.pdf:application/pdf},
}

@article{piorkowski_aimee_2023,
	title = {{AIMEE}: {An} {Exploratory} {Study} of {How} {Rules} {Support} {AI} {Developers} to {Explain} and {Edit} {Models}},
	volume = {7},
	issn = {2573-0142},
	shorttitle = {{AIMEE}},
	url = {https://dl.acm.org/doi/10.1145/3610046},
	doi = {10.1145/3610046},
	abstract = {In real-world applications when deploying Machine Learning (ML) models, initial model development includes close analysis of the model results and behavior by a data scientist. Once trained, however, models may need to be retrained with new data or updated to adhere to new rules or regulations. This presents two challenges. First, how to communicate how a model is making its decisions before and after retraining, and second how to support model editing to take into account new requirements. To address these needs, we built AIMEE (AI Model Explorer and Editor), a tool created to address these challenges by providing interactive methods to explain, visualize, and modify model decision boundaries using rules. Rules should benefit model builders by providing a layer of abstraction for understanding and manipulating the model and reduces the need to modify individual rows of data directly. To evaluate if this was the case, we conducted a pair of user studies totaling 23 participants to evaluate AIMEE's rules-based approach for model explainability and editing. We found that participants correctly interpreted rules and report on their perspectives of how rules are beneficial (and not), ways that rules could support collaboration, and provide a usability evaluation of the tool.},
	language = {en},
	number = {CSCW2},
	urldate = {2023-12-05},
	journal = {Proceedings of the ACM on Human-Computer Interaction},
	author = {Piorkowski, David and Vejsbjerg, Inge and Cornec, Owen and Daly, Elizabeth M. and Alkan, Öznur},
	month = sep,
	year = {2023},
	pages = {1--25},
	file = {Full Text PDF:/Users/vsivaram/Zotero/storage/R8C9JY5F/Piorkowski et al. - 2023 - AIMEE An Exploratory Study of How Rules Support A.pdf:application/pdf},
}

@article{bogl_visual_2013,
	title = {Visual {Analytics} for {Model} {Selection} in {Time} {Series} {Analysis}},
	volume = {19},
	issn = {1077-2626},
	url = {http://ieeexplore.ieee.org/document/6634112/},
	doi = {10.1109/TVCG.2013.222},
	abstract = {Model selection in time series analysis is a challenging task for domain experts in many application areas such as epidemiology, economy, or environmental sciences. The methodology used for this task demands a close combination of human judgement and automated computation. However, statistical software tools do not adequately support this combination through interactive visual interfaces. We propose a Visual Analytics process to guide domain experts in this task. For this purpose, we developed the TiMoVA prototype that implements this process based on user stories and iterative expert feedback on user experience. The prototype was evaluated by usage scenarios with an example dataset from epidemiology and interviews with two external domain experts in statistics. The insights from the experts’ feedback and the usage scenarios show that TiMoVA is able to support domain experts in model selection tasks through interactive visual interfaces with short feedback cycles.},
	language = {en},
	number = {12},
	urldate = {2024-01-15},
	journal = {IEEE Transactions on Visualization and Computer Graphics},
	author = {Bogl, Markus and Aigner, Wolfgang and Filzmoser, Peter and Lammarsch, Tim and Miksch, Silvia and Rind, Alexander},
	month = dec,
	year = {2013},
	pages = {2237--2246},
	file = {Bogl et al. - 2013 - Visual Analytics for Model Selection in Time Serie.pdf:/Users/vsivaram/Zotero/storage/C2DBQJXS/Bogl et al. - 2013 - Visual Analytics for Model Selection in Time Serie.pdf:application/pdf},
}

@article{bernard_visual-interactive_2019,
	title = {Visual-{Interactive} {Preprocessing} of {Multivariate} {Time} {Series} {Data}},
	volume = {38},
	issn = {1467-8659},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/cgf.13698},
	doi = {10.1111/cgf.13698},
	abstract = {Pre-processing is a prerequisite to conduct effective and efficient downstream data analysis. Pre-processing pipelines often require multiple routines to address data quality challenges and to bring the data into a usable form. For both the construction and the refinement of pre-processing pipelines, human-in-the-loop approaches are highly beneficial. This particularly applies to multivariate time series, a complex data type with multiple values developing over time. Due to the high specificity of this domain, it has not been subject to in-depth research in visual analytics. We present a visual-interactive approach for preprocessing multivariate time series data with the following aspects. Our approach supports analysts to carry out six core analysis tasks related to pre-processing of multivariate time series. To support these tasks, we identify requirements to baseline toolkits that may help practitioners in their choice. We characterize the space of visualization designs for uncertainty-aware pre-processing and justify our decisions. Two usage scenarios demonstrate applicability of our approach, design choices, and uncertainty visualizations for the six analysis tasks. This work is one step towards strengthening the visual analytics support for data pre-processing in general and for uncertainty-aware pre-processing of multivariate time series in particular.},
	language = {en},
	number = {3},
	urldate = {2024-01-29},
	journal = {Computer Graphics Forum},
	author = {Bernard, Jürgen and Hutter, Marco and Reinemuth, Heiko and Pfeifer, Hendrik and Bors, Christian and Kohlhammer, Jörn},
	year = {2019},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/cgf.13698},
	keywords = {• Human-centered computing → Visual analytics, CCS Concepts, Mathematics of computing → Time series analysis},
	pages = {401--412},
	file = {Full Text PDF:/Users/vsivaram/Zotero/storage/NUNASBML/Bernard et al. - 2019 - Visual-Interactive Preprocessing of Multivariate T.pdf:application/pdf;Snapshot:/Users/vsivaram/Zotero/storage/GWEM8Z59/cgf.html:text/html},
}

@inproceedings{sun_dfseer_2020,
	address = {Honolulu HI USA},
	title = {{DFSeer}: {A} {Visual} {Analytics} {Approach} to {Facilitate} {Model} {Selection} for {Demand} {Forecasting}},
	isbn = {978-1-4503-6708-0},
	shorttitle = {{DFSeer}},
	url = {https://dl.acm.org/doi/10.1145/3313831.3376866},
	doi = {10.1145/3313831.3376866},
	language = {en},
	urldate = {2024-01-29},
	booktitle = {Proceedings of the 2020 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {ACM},
	author = {Sun, Dong and Feng, Zezheng and Chen, Yuanzhe and Wang, Yong and Zeng, Jia and Yuan, Mingxuan and Pong, Ting-Chuen and Qu, Huamin},
	month = apr,
	year = {2020},
	pages = {1--13},
	file = {Full Text PDF:/Users/vsivaram/Zotero/storage/RSMHL5LA/Sun et al. - 2020 - DFSeer A Visual Analytics Approach to Facilitate .pdf:application/pdf},
}

@inproceedings{xu_mtseer_2021,
	address = {Yokohama Japan},
	title = {{mTSeer}: {Interactive} {Visual} {Exploration} of {Models} on {Multivariate} {Time}-series {Forecast}},
	isbn = {978-1-4503-8096-6},
	shorttitle = {{mTSeer}},
	url = {https://dl.acm.org/doi/10.1145/3411764.3445083},
	doi = {10.1145/3411764.3445083},
	language = {en},
	urldate = {2024-01-29},
	booktitle = {Proceedings of the 2021 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {ACM},
	author = {Xu, Ke and Yuan, Jun and Wang, Yifang and Silva, Claudio and Bertini, Enrico},
	month = may,
	year = {2021},
	pages = {1--15},
	file = {Full Text PDF:/Users/vsivaram/Zotero/storage/33BGDXMK/Xu et al. - 2021 - mTSeer Interactive Visual Exploration of Models o.pdf:application/pdf},
}

@article{liu_patterns_2017,
	title = {Patterns and {Sequences}: {Interactive} {Exploration} of {Clickstreams} to {Understand} {Common} {Visitor} {Paths}},
	volume = {23},
	issn = {1077-2626},
	shorttitle = {Patterns and {Sequences}},
	url = {http://ieeexplore.ieee.org/document/7539341/},
	doi = {10.1109/TVCG.2016.2598797},
	abstract = {Modern web clickstream data consists of long, high-dimensional sequences of multivariate events, making it difﬁcult to analyze. Following the overarching principle that the visual interface should provide information about the dataset at multiple levels of granularity and allow users to easily navigate across these levels, we identify four levels of granularity in clickstream analysis: patterns, segments, sequences and events. We present an analytic pipeline consisting of three stages: pattern mining, pattern pruning and coordinated exploration between patterns and sequences. Based on this approach, we discuss properties of maximal sequential patterns, propose methods to reduce the number of patterns and describe design considerations for visualizing the extracted sequential patterns and the corresponding raw sequences. We demonstrate the viability of our approach through an analysis scenario and discuss the strengths and limitations of the methods based on user feedback.},
	language = {en},
	number = {1},
	urldate = {2024-01-29},
	journal = {IEEE Transactions on Visualization and Computer Graphics},
	author = {Liu, Zhicheng and Wang, Yang and Dontcheva, Mira and Hoffman, Matthew and Walker, Seth and Wilson, Alan},
	month = jan,
	year = {2017},
	pages = {321--330},
	file = {Liu et al. - 2017 - Patterns and Sequences Interactive Exploration of.pdf:/Users/vsivaram/Zotero/storage/D5PX8K8X/Liu et al. - 2017 - Patterns and Sequences Interactive Exploration of.pdf:application/pdf},
}

@inproceedings{du_interactive_2020,
	address = {Honolulu HI USA},
	title = {Interactive {Event} {Sequence} {Prediction} for {Marketing} {Analysts}},
	isbn = {978-1-4503-6819-3},
	url = {https://dl.acm.org/doi/10.1145/3334480.3382971},
	doi = {10.1145/3334480.3382971},
	abstract = {Timestamped event sequences are analyzed to tackle varied problems but have unique challenges in interpretation and analysis. Especially in event sequence prediction, it is difﬁcult to convey the results due to the added uncertainty and complexity introduced by predictive models. In this work, we design and develop ProFlow, a visual analytics system for supporting analysts’ workﬂow of exploring and predicting event sequences. Through an evaluation conducted with four data analysts in a real-world marketing scenario, we discuss the applicability and usefulness of ProFlow as well as its limitations and future directions.},
	language = {en},
	urldate = {2024-01-29},
	booktitle = {Extended {Abstracts} of the 2020 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {ACM},
	author = {Du, Fan and Guo, Shunan and Malik, Sana and Koh, Eunyee and Kim, Sungchul and Liu, Zhicheng},
	month = apr,
	year = {2020},
	pages = {1--8},
	file = {Du et al. - 2020 - Interactive Event Sequence Prediction for Marketin.pdf:/Users/vsivaram/Zotero/storage/2DBE4UX8/Du et al. - 2020 - Interactive Event Sequence Prediction for Marketin.pdf:application/pdf},
}

@inproceedings{guo_visualizing_2019,
	address = {Glasgow Scotland Uk},
	title = {Visualizing {Uncertainty} and {Alternatives} in {Event} {Sequence} {Predictions}},
	isbn = {978-1-4503-5970-2},
	url = {https://dl.acm.org/doi/10.1145/3290605.3300803},
	doi = {10.1145/3290605.3300803},
	language = {en},
	urldate = {2024-01-29},
	booktitle = {Proceedings of the 2019 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {ACM},
	author = {Guo, Shunan and Du, Fan and Malik, Sana and Koh, Eunyee and Kim, Sungchul and Liu, Zhicheng and Kim, Donghyun and Zha, Hongyuan and Cao, Nan},
	month = may,
	year = {2019},
	pages = {1--12},
	annote = {This paper provides evidence that people want to see both future temporal events (actions or states) and outcomes. This is one of the main things that flexibility about the outcome variable in our system allows.
},
	file = {Full Text PDF:/Users/vsivaram/Zotero/storage/UA8HXR8R/Guo et al. - 2019 - Visualizing Uncertainty and Alternatives in Event .pdf:application/pdf},
}

@article{cho_stroscope_2014,
	title = {Stroscope: {Multi}-{Scale} {Visualization} of {Irregularly} {Measured} {Time}-{Series} {Data}},
	volume = {20},
	issn = {1077-2626},
	shorttitle = {Stroscope},
	url = {http://ieeexplore.ieee.org/document/6702502/},
	doi = {10.1109/TVCG.2013.2297933},
	abstract = {For irregularly measured time-series data, the measurement frequency or interval is as crucial information as measurements are. A well-known time-series visualization such as the line graph is good at showing an overall temporal pattern of change; however, it is not so effective in revealing the measurement frequency/interval while likely giving illusory conﬁdence in values between measurements. In contrast, the bar graph is more effective in showing the frequency/interval, but less effective in showing an overall pattern than the line graph. We integrate the line graph and bar graph in a uniﬁed visualization model, called a ripple graph, to take the beneﬁts of both of them with enhanced graphical integrity. Based on the ripple graph, we implemented an interactive timeseries data visualization tool, called Stroscope, which facilitates multi-scale visualizations by providing users with a graphical widget to interactively control the integrated visualization model. We evaluated the visualization model (i.e., the ripple graph) through a controlled user study and Stroscope through long-term case studies with neurologists exploring large blood pressure measurement data of stroke patients. Results from our evaluations demonstrate that the ripple graph outperforms existing time-series visualizations, and that Stroscope has the efﬁcacy and potential as an effective visual analysis tool for (irregularly) measured time-series data.},
	language = {en},
	number = {5},
	urldate = {2024-01-29},
	journal = {IEEE Transactions on Visualization and Computer Graphics},
	author = {Cho, Myoungsu and Kim, Bohyoung and Bae, Hee-Joon and Seo, Jinwook},
	month = may,
	year = {2014},
	pages = {808--821},
	file = {Cho et al. - 2014 - Stroscope Multi-Scale Visualization of Irregularl.pdf:/Users/vsivaram/Zotero/storage/ACDKDR5S/Cho et al. - 2014 - Stroscope Multi-Scale Visualization of Irregularl.pdf:application/pdf},
}

@incollection{costabile_representing_2005,
	address = {Berlin, Heidelberg},
	title = {Representing {Unevenly}-{Spaced} {Time} {Series} {Data} for {Visualization} and {Interactive} {Exploration}},
	volume = {3585},
	isbn = {978-3-540-28943-2 978-3-540-31722-7},
	url = {http://link.springer.com/10.1007/11555261_66},
	abstract = {Visualizing time series is useful to support discovery of relations and patterns in financial, genomic, medical and other applications. Often, measurements are equally spaced over time. We discuss the challenges of unevenly-spaced time series and present four representation methods: sampled events, aggregated sampled events, event index and interleaved event index. We developed these methods while studying eBay auction data with TimeSearcher. We describe the advantages, disadvantages, choices for algorithms and parameters, and compare the different methods for different tasks. Interaction issues such as screen resolution, response time for dynamic queries, and learnability are governed by these decisions.},
	language = {en},
	urldate = {2024-01-29},
	booktitle = {Human-{Computer} {Interaction} - {INTERACT} 2005},
	publisher = {Springer Berlin Heidelberg},
	author = {Aris, Aleks and Shneiderman, Ben and Plaisant, Catherine and Shmueli, Galit and Jank, Wolfgang},
	editor = {Costabile, Maria Francesca and Paternò, Fabio},
	year = {2005},
	doi = {10.1007/11555261_66},
	note = {Series Title: Lecture Notes in Computer Science},
	pages = {835--846},
	file = {Aris et al. - 2005 - Representing Unevenly-Spaced Time Series Data for .pdf:/Users/vsivaram/Zotero/storage/ABV6IGSR/Aris et al. - 2005 - Representing Unevenly-Spaced Time Series Data for .pdf:application/pdf},
}

@misc{yuan_visual_2022,
	title = {Visual {Exploration} of {Machine} {Learning} {Model} {Behavior} with {Hierarchical} {Surrogate} {Rule} {Sets}},
	url = {http://arxiv.org/abs/2201.07724},
	abstract = {One of the potential solutions for model interpretation is to train a surrogate model: a more transparent model that approximates the behavior of the model to be explained. Typically, classification rules or decision trees are used due to the intelligibility of their logic-based expressions. However, decision trees can grow too deep and rule sets can become too large to approximate a complex model. Unlike paths on a decision tree that must share ancestor nodes (conditions), rules are more flexible. However, the unstructured visual representation of rules makes it hard to make inferences across rules. To address these issues, we present a workflow that includes novel algorithmic and interactive solutions. First, we present Hierarchical Surrogate Rules (HSR), an algorithm that generates hierarchical rules based on user-defined parameters. We also contribute SuRE, a visual analytics (VA) system that integrates HSR and interactive surrogate rule visualizations. Particularly, we present a novel feature-aligned tree to overcome the shortcomings of existing rule visualizations. We evaluate the algorithm in terms of parameter sensitivity, time performance, and comparison with surrogate decision trees and find that it scales reasonably well and outperforms decision trees in many respects. We also evaluate the visualization and the VA system by a usability study with 24 volunteers and an observational study with 7 domain experts. Our investigation shows that the participants can use feature-aligned trees to perform non-trivial tasks with very high accuracy. We also discuss many interesting observations that can be useful for future research on designing effective rule-based VA systems.},
	urldate = {2024-02-02},
	publisher = {arXiv},
	author = {Yuan, Jun and Barr, Brian and Overton, Kyle and Bertini, Enrico},
	month = jan,
	year = {2022},
	note = {arXiv:2201.07724 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Human-Computer Interaction, Computer Science - Machine Learning},
	file = {arXiv.org Snapshot:/Users/vsivaram/Zotero/storage/DLCQFXIR/2201.html:text/html;Full Text PDF:/Users/vsivaram/Zotero/storage/JYUV3YHE/Yuan et al. - 2022 - Visual Exploration of Machine Learning Model Behav.pdf:application/pdf},
}

@inproceedings{bhattacharya_exmos_2024,
author = {Bhattacharya, Aditya and Stumpf, Simone and Gosak, Lucija and Stiglic, Gregor and Verbert, Katrien},
title = {EXMOS: Explanatory Model Steering through Multifaceted Explanations and Data Configurations},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3642106},
doi = {10.1145/3613904.3642106},
abstract = {Explanations in interactive machine-learning systems facilitate debugging and improving prediction models. However, the effectiveness of various global model-centric and data-centric explanations in aiding domain experts to detect and resolve potential data issues for model improvement remains unexplored. This research investigates the influence of data-centric and model-centric global explanations in systems that support healthcare experts in optimising models through automated and manual data configurations. We conducted quantitative (n=70) and qualitative (n=30) studies with healthcare experts to explore the impact of different explanations on trust, understandability and model improvement. Our results reveal the insufficiency of global model-centric explanations for guiding users during data configuration. Although data-centric explanations enhanced understanding of post-configuration system changes, a hybrid fusion of both explanation types demonstrated the highest effectiveness. Based on our study results, we also present design implications for effective explanation-driven interactive machine-learning systems.},
booktitle = {Proceedings of the CHI Conference on Human Factors in Computing Systems},
articleno = {314},
numpages = {27},
keywords = {Explainable AI, Explanatory Interactive Learning, Human-centered AI, IML, Interactive Machine Learning, Interpretable AI, Model Steering, Responsible AI, XAI},
location = {Honolulu, HI, USA},
series = {CHI '24}
}

@inproceedings{amershi_examining_2010,
	address = {Atlanta Georgia USA},
	title = {Examining multiple potential models in end-user interactive concept learning},
	isbn = {978-1-60558-929-9},
	url = {https://dl.acm.org/doi/10.1145/1753326.1753531},
	doi = {10.1145/1753326.1753531},
	language = {en},
	urldate = {2024-02-05},
	booktitle = {Proceedings of the {SIGCHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {ACM},
	author = {Amershi, Saleema and Fogarty, James and Kapoor, Ashish and Tan, Desney},
	month = apr,
	year = {2010},
	pages = {1357--1360},
	file = {Full Text PDF:/Users/vsivaram/Zotero/storage/P5SCFVJV/Amershi et al. - 2010 - Examining multiple potential models in end-user in.pdf:application/pdf},
}

@inproceedings{kulesza_principles_2015,
	address = {Atlanta Georgia USA},
	title = {Principles of {Explanatory} {Debugging} to {Personalize} {Interactive} {Machine} {Learning}},
	isbn = {978-1-4503-3306-1},
	url = {https://dl.acm.org/doi/10.1145/2678025.2701399},
	doi = {10.1145/2678025.2701399},
	abstract = {How can end users eﬃciently inﬂuence the predictions that machine learning systems make on their behalf? This paper presents Explanatory Debugging, an approach in which the system explains to users how it made each of its predictions, and the user then explains any necessary corrections back to the learning system. We present the principles underlying this approach and a prototype instantiating it. An empirical evaluation shows that Explanatory Debugging increased participants’ understanding of the learning system by 52\% and allowed participants to correct its mistakes up to twice as eﬃciently as participants using a traditional learning system.},
	language = {en},
	urldate = {2024-02-05},
	booktitle = {Proceedings of the 20th {International} {Conference} on {Intelligent} {User} {Interfaces}},
	publisher = {ACM},
	author = {Kulesza, Todd and Burnett, Margaret and Wong, Weng-Keen and Stumpf, Simone},
	month = mar,
	year = {2015},
	pages = {126--137},
	file = {Kulesza et al. - 2015 - Principles of Explanatory Debugging to Personalize.pdf:/Users/vsivaram/Zotero/storage/L78SGIR3/Kulesza et al. - 2015 - Principles of Explanatory Debugging to Personalize.pdf:application/pdf},
}

@misc{guo_survey_2020,
	title = {Survey on {Visual} {Analysis} of {Event} {Sequence} {Data}},
	url = {http://arxiv.org/abs/2006.14291},
	abstract = {Event sequence data record series of discrete events in the time order of occurrence. They are commonly observed in a variety of applications ranging from electronic health records to network logs, with the characteristics of large-scale, high-dimensional, and heterogeneous. This high complexity of event sequence data makes it difficult for analysts to manually explore and find patterns, resulting in ever-increasing needs for computational and perceptual aids from visual analytics techniques to extract and communicate insights from event sequence datasets. In this paper, we review the state-of-the-art visual analytics approaches, characterize them with our proposed design space, and categorize them based on analytical tasks and applications. From our review of relevant literature, we have also identified several remaining research challenges and future research opportunities.},
	urldate = {2024-02-06},
	publisher = {arXiv},
	author = {Guo, Yi and Guo, Shunan and Jin, Zhuochen and Kaul, Smiti and Gotz, David and Cao, Nan},
	month = jun,
	year = {2020},
	note = {arXiv:2006.14291 [cs]},
	keywords = {Computer Science - Human-Computer Interaction},
	file = {arXiv.org Snapshot:/Users/vsivaram/Zotero/storage/YZPP3RPT/2006.html:text/html;Full Text PDF:/Users/vsivaram/Zotero/storage/9TDWT735/Guo et al. - 2020 - Survey on Visual Analysis of Event Sequence Data.pdf:application/pdf},
}

@article{wu_modeling_2018,
	title = {Modeling asynchronous event sequences with {RNNs}},
	volume = {83},
	issn = {15320464},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S1532046418300996},
	doi = {10.1016/j.jbi.2018.05.016},
	abstract = {Sequences of events have often been modeled with computational techniques, but typical preprocessing steps and problem settings do not explicitly address the ramiﬁcations of timestamped events. Clinical data, such as is found in electronic health records (EHRs), typically comes with timestamp information. In this work, we deﬁne event sequences and their properties: synchronicity, evenness, and co-cardinality; we then show how asynchronous, uneven, and multi-cardinal problem settings can support explicit accountings of relative time. Our evaluation uses the temporally sensitive clinical use case of pediatric asthma, which is a chronic disease with symptoms (and lack thereof) evolving over time. We show several approaches to explicitly incorporating relative time into a recurrent neural network (RNN) model that improve the overall classiﬁcation of patients into those with no asthma, those with persistent asthma, those in long-term remission, and those who have experienced relapse. We also compare and contrast these results with those in an inpatient intensive care setting.},
	language = {en},
	urldate = {2024-02-06},
	journal = {Journal of Biomedical Informatics},
	author = {Wu, Stephen and Liu, Sijia and Sohn, Sunghwan and Moon, Sungrim and Wi, Chung-il and Juhn, Young and Liu, Hongfang},
	month = jul,
	year = {2018},
	pages = {167--177},
	file = {Wu et al. - 2018 - Modeling asynchronous event sequences with RNNs.pdf:/Users/vsivaram/Zotero/storage/WC44S84W/Wu et al. - 2018 - Modeling asynchronous event sequences with RNNs.pdf:application/pdf},
}

@article{monroe_temporal_2013,
	title = {Temporal {Event} {Sequence} {Simplification}},
	volume = {19},
	issn = {1941-0506},
	url = {https://ieeexplore.ieee.org/abstract/document/6634100},
	doi = {10.1109/TVCG.2013.200},
	abstract = {Electronic Health Records (EHRs) have emerged as a cost-effective data source for conducting medical research. The difficulty in using EHRs for research purposes, however, is that both patient selection and record analysis must be conducted across very large, and typically very noisy datasets. Our previous work introduced EventFlow, a visualization tool that transforms an entire dataset of temporal event records into an aggregated display, allowing researchers to analyze population-level patterns and trends. As datasets become larger and more varied, however, it becomes increasingly difficult to provide a succinct, summarizing display. This paper presents a series of user-driven data simplifications that allow researchers to pare event records down to their core elements. Furthermore, we present a novel metric for measuring visual complexity, and a language for codifying disjoint strategies into an overarching simplification framework. These simplifications were used by real-world researchers to gain new and valuable insights from initially overwhelming datasets.},
	number = {12},
	urldate = {2024-02-20},
	journal = {IEEE Transactions on Visualization and Computer Graphics},
	author = {Monroe, Megan and Lan, Rongjian and Lee, Hanseung and Plaisant, Catherine and Shneiderman, Ben},
	month = dec,
	year = {2013},
	note = {Conference Name: IEEE Transactions on Visualization and Computer Graphics},
	keywords = {Complexity theory, Data mining, Data visualization, electronic heath records, Electronic medical records, Event sequences, Market research, simplification, temporal query},
	pages = {2227--2236},
	file = {IEEE Xplore Abstract Record:/Users/vsivaram/Zotero/storage/73B7DIR2/6634100.html:text/html;IEEE Xplore Full Text PDF:/Users/vsivaram/Zotero/storage/KWF7FQFI/Monroe et al. - 2013 - Temporal Event Sequence Simplification.pdf:application/pdf},
}

@incollection{simoff_datajewel_2008,
	address = {Berlin, Heidelberg},
	title = {{DataJewel}: {Integrating} {Visualization} with {Temporal} {Data} {Mining}},
	volume = {4404},
	isbn = {978-3-540-71079-0 978-3-540-71080-6},
	shorttitle = {{DataJewel}},
	url = {http://link.springer.com/10.1007/978-3-540-71080-6_19},
	abstract = {In this chapter we describe DataJewel, a new temporal data mining architecture. DataJewel tightly integrates a visualization component, an algorithmic component and a database component. We introduce a new visualization technique called CalendarView as an implementation of the visualization component, and we introduce a data structure that supports temporal mining of large databases. In our architecture, algorithms can be tightly integrated with the visualization component and most existing temporal data mining algorithms can be leveraged by embedding them into DataJewel. This integration is achieved by an interface that is used by both the user and the algorithms to assign colors to events. The user interactively assigns colors to incorporate domain knowledge or to formulate hypotheses. The algorithm assigns colors based on discovered patterns. The same visualization technique is used for displaying both data and patterns to make it more intuitive for the user to identify useful patterns while exploring data interactively or while using algorithms to search for patterns. Our experiments in analyzing several large datasets from the airplane maintenance domain demonstrate the usefulness of our approach and we discuss its applicability to domains like homeland security, market basket analysis and web mining.},
	language = {en},
	urldate = {2024-02-20},
	booktitle = {Visual {Data} {Mining}},
	publisher = {Springer Berlin Heidelberg},
	author = {Ankerst, Mihael and Kao, Anne and Tjoelker, Rodney and Wang, Changzhou},
	editor = {Simoff, Simeon J. and Böhlen, Michael H. and Mazeika, Arturas},
	year = {2008},
	doi = {10.1007/978-3-540-71080-6_19},
	note = {ISSN: 0302-9743, 1611-3349
Series Title: Lecture Notes in Computer Science},
	pages = {312--330},
	file = {Ankerst et al. - 2008 - DataJewel Integrating Visualization with Temporal.pdf:/Users/vsivaram/Zotero/storage/KHWUKCJQ/Ankerst et al. - 2008 - DataJewel Integrating Visualization with Temporal.pdf:application/pdf},
}

@article{du_coping_2017,
	title = {Coping with {Volume} and {Variety} in {Temporal} {Event} {Sequences}: {Strategies} for {Sharpening} {Analytic} {Focus}},
	volume = {23},
	issn = {1077-2626},
	shorttitle = {Coping with {Volume} and {Variety} in {Temporal} {Event} {Sequences}},
	url = {http://ieeexplore.ieee.org/document/7429778/},
	doi = {10.1109/TVCG.2016.2539960},
	abstract = {The growing volume and variety of data presents both opportunities and challenges for visual analytics. Addressing these challenges is needed for big data to provide valuable insights and novel solutions for business, security, social media, and healthcare. In the case of temporal event sequence analytics it is the number of events in the data and variety of temporal sequence patterns that challenges users of visual analytic tools. This paper describes 15 strategies for sharpening analytic focus that analysts can use to reduce the data volume and pattern variety. Four groups of strategies are proposed: (1) extraction strategies, (2) temporal folding, (3) pattern simpliﬁcation strategies, and (4) iterative strategies. For each strategy, we provide examples of the use and impact of this strategy on volume and/or variety. Examples are selected from 20 case studies gathered from either our own work, the literature, or based on email interviews with individuals who conducted the analyses and developers who observed analysts using the tools. Finally, we discuss how these strategies might be combined and report on the feedback from 10 senior event sequence analysts.},
	language = {en},
	number = {6},
	urldate = {2024-02-20},
	journal = {IEEE Transactions on Visualization and Computer Graphics},
	author = {Du, Fan and Shneiderman, Ben and Plaisant, Catherine and Malik, Sana and Perer, Adam},
	month = jun,
	year = {2017},
	pages = {1636--1649},
	file = {Du et al. - 2017 - Coping with Volume and Variety in Temporal Event S.pdf:/Users/vsivaram/Zotero/storage/B8SXIB4A/Du et al. - 2017 - Coping with Volume and Variety in Temporal Event S.pdf:application/pdf},
}

@inproceedings{tseng_collaborative_2023,
	address = {Chicago IL USA},
	title = {Collaborative {Machine} {Learning} {Model} {Building} with {Families} {Using} {Co}-{ML}},
	isbn = {9798400701313},
	url = {https://dl.acm.org/doi/10.1145/3585088.3589356},
	doi = {10.1145/3585088.3589356},
	language = {en},
	urldate = {2024-02-25},
	booktitle = {Proceedings of the 22nd {Annual} {ACM} {Interaction} {Design} and {Children} {Conference}},
	publisher = {ACM},
	author = {Tseng, Tiffany and King Chen, Jennifer and Abdelrahman, Mona and Kery, Mary Beth and Hohman, Fred and Hilliard, Adriana and Shapiro, R. Benjamin},
	month = jun,
	year = {2023},
	pages = {40--51},
	file = {Full Text PDF:/Users/vsivaram/Zotero/storage/U7YWN2XN/Tseng et al. - 2023 - Collaborative Machine Learning Model Building with.pdf:application/pdf},
}

@inproceedings{fiebrink_human_2011,
	address = {Vancouver BC Canada},
	title = {Human model evaluation in interactive supervised learning},
	isbn = {978-1-4503-0228-9},
	url = {https://dl.acm.org/doi/10.1145/1978942.1978965},
	doi = {10.1145/1978942.1978965},
	language = {en},
	urldate = {2024-02-25},
	booktitle = {Proceedings of the {SIGCHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {ACM},
	author = {Fiebrink, Rebecca and Cook, Perry R. and Trueman, Dan},
	month = may,
	year = {2011},
	pages = {147--156},
	file = {Full Text:/Users/vsivaram/Zotero/storage/ALEHBBDK/Fiebrink et al. - 2011 - Human model evaluation in interactive supervised l.pdf:application/pdf},
}

@inproceedings{guerdan_groundless_2023,
	address = {Chicago IL USA},
	title = {Ground(less) {Truth}: {A} {Causal} {Framework} for {Proxy} {Labels} in {Human}-{Algorithm} {Decision}-{Making}},
	isbn = {9798400701924},
	shorttitle = {Ground(less) {Truth}},
	url = {https://dl.acm.org/doi/10.1145/3593013.3594036},
	doi = {10.1145/3593013.3594036},
	language = {en},
	urldate = {2024-02-25},
	booktitle = {2023 {ACM} {Conference} on {Fairness}, {Accountability}, and {Transparency}},
	publisher = {ACM},
	author = {Guerdan, Luke and Coston, Amanda and Wu, Zhiwei Steven and Holstein, Kenneth},
	month = jun,
	year = {2023},
	pages = {688--704},
	file = {Full Text PDF:/Users/vsivaram/Zotero/storage/KBCSRM3B/Guerdan et al. - 2023 - Ground(less) Truth A Causal Framework for Proxy L.pdf:application/pdf},
}

@inproceedings{gerchick_devil_2023,
	address = {Chicago IL USA},
	title = {The {Devil} is in the {Details}: {Interrogating} {Values} {Embedded} in the {Allegheny} {Family} {Screening} {Tool}},
	isbn = {9798400701924},
	shorttitle = {The {Devil} is in the {Details}},
	url = {https://dl.acm.org/doi/10.1145/3593013.3594081},
	doi = {10.1145/3593013.3594081},
	language = {en},
	urldate = {2024-02-25},
	booktitle = {2023 {ACM} {Conference} on {Fairness}, {Accountability}, and {Transparency}},
	publisher = {ACM},
	author = {Gerchick, Marissa and Jegede, Tobi and Shah, Tarak and Gutierrez, Ana and Beiers, Sophie and Shemtov, Noam and Xu, Kath and Samant, Anjana and Horowitz, Aaron},
	month = jun,
	year = {2023},
	pages = {1292--1310},
	file = {Full Text PDF:/Users/vsivaram/Zotero/storage/V42PAXNI/Gerchick et al. - 2023 - The Devil is in the Details Interrogating Values .pdf:application/pdf},
}

@inproceedings{zhang_resilience_2023,
	address = {Sydney NSW Australia},
	title = {Resilience {Through} {Appropriation}: {Pilots}’ {View} on {Complex} {Decision} {Support}},
	isbn = {9798400701061},
	shorttitle = {Resilience {Through} {Appropriation}},
	url = {https://dl.acm.org/doi/10.1145/3581641.3584056},
	doi = {10.1145/3581641.3584056},
	language = {en},
	urldate = {2024-02-25},
	booktitle = {Proceedings of the 28th {International} {Conference} on {Intelligent} {User} {Interfaces}},
	publisher = {ACM},
	author = {Zhang, Zelun Tony and Storath, Cara and Liu, Yuanting and Butz, Andreas},
	month = mar,
	year = {2023},
	pages = {397--409},
	file = {Full Text PDF:/Users/vsivaram/Zotero/storage/FKKNDRAY/Zhang et al. - 2023 - Resilience Through Appropriation Pilots’ View on .pdf:application/pdf},
}

@article{mozannar_effective_nodate,
	title = {Effective {Human}-{AI} {Teams} via {Learned} {Natural} {Language} {Rules} and {Onboarding}},
	abstract = {People are relying on AI agents to assist them with various tasks. The human must know when to rely on the agent, collaborate with the agent, or ignore its suggestions. In this work, we propose to learn rules grounded in data regions and described in natural language that illustrate how the human should collaborate with the AI. Our novel region discovery algorithm finds local regions in the data as neighborhoods in an embedding space that corrects the human prior. Each region is then described using an iterative and contrastive procedure where a large language model describes the region. We then teach these rules to the human via an onboarding stage. Through user studies on object detection and question-answering tasks, we show that our method can lead to more accurate human-AI teams. We also evaluate our region discovery and description algorithms separately.},
	language = {en},
	author = {Mozannar, Hussein and Lee, Jimin J and Wei, Dennis and Sattigeri, Prasanna and Das, Subhro and Sontag, David},
	file = {Mozannar et al. - Effective Human-AI Teams via Learned Natural Langu.pdf:/Users/vsivaram/Zotero/storage/WNZNVFJQ/Mozannar et al. - Effective Human-AI Teams via Learned Natural Langu.pdf:application/pdf},
}

@inproceedings{du_eventaction_2016,
	address = {Baltimore, MD, USA},
	title = {{EventAction}: {Visual} analytics for temporal event sequence recommendation},
	isbn = {978-1-5090-5661-3},
	shorttitle = {{EventAction}},
	url = {http://ieeexplore.ieee.org/document/7883512/},
	doi = {10.1109/VAST.2016.7883512},
	language = {en},
	urldate = {2024-02-26},
	booktitle = {2016 {IEEE} {Conference} on {Visual} {Analytics} {Science} and {Technology} ({VAST})},
	publisher = {IEEE},
	author = {Du, Fan and Plaisant, Catherine and Spring, Neil and Shneiderman, Ben},
	month = oct,
	year = {2016},
	pages = {61--70},
	file = {Du et al. - 2016 - EventAction Visual analytics for temporal event s.pdf:/Users/vsivaram/Zotero/storage/V3LF2GUR/Du et al. - 2016 - EventAction Visual analytics for temporal event s.pdf:application/pdf},
}

@article{kwon_retainvis_2019,
	title = {{RetainVis}: {Visual} {Analytics} with {Interpretable} and {Interactive} {Recurrent} {Neural} {Networks} on {Electronic} {Medical} {Records}},
	volume = {25},
	issn = {1077-2626, 1941-0506, 2160-9306},
	shorttitle = {{RetainVis}},
	url = {http://arxiv.org/abs/1805.10724},
	doi = {10.1109/TVCG.2018.2865027},
	abstract = {We have recently seen many successful applications of recurrent neural networks (RNNs) on electronic medical records (EMRs), which contain histories of patients' diagnoses, medications, and other various events, in order to predict the current and future states of patients. Despite the strong performance of RNNs, it is often challenging for users to understand why the model makes a particular prediction. Such black-box nature of RNNs can impede its wide adoption in clinical practice. Furthermore, we have no established methods to interactively leverage users' domain expertise and prior knowledge as inputs for steering the model. Therefore, our design study aims to provide a visual analytics solution to increase interpretability and interactivity of RNNs via a joint effort of medical experts, artificial intelligence scientists, and visual analytics researchers. Following the iterative design process between the experts, we design, implement, and evaluate a visual analytics tool called RetainVis, which couples a newly improved, interpretable and interactive RNN-based model called RetainEX and visualizations for users' exploration of EMR data in the context of prediction tasks. Our study shows the effective use of RetainVis for gaining insights into how individual medical codes contribute to making risk predictions, using EMRs of patients with heart failure and cataract symptoms. Our study also demonstrates how we made substantial changes to the state-of-the-art RNN model called RETAIN in order to make use of temporal information and increase interactivity. This study will provide a useful guideline for researchers that aim to design an interpretable and interactive visual analytics tool for RNNs.},
	number = {1},
	urldate = {2024-02-26},
	journal = {IEEE Transactions on Visualization and Computer Graphics},
	author = {Kwon, Bum Chul and Choi, Min-Je and Kim, Joanne Taery and Choi, Edward and Kim, Young Bin and Kwon, Soonwook and Sun, Jimeng and Choo, Jaegul},
	month = jan,
	year = {2019},
	note = {arXiv:1805.10724 [cs, stat]},
	keywords = {Computer Science - Human-Computer Interaction, Computer Science - Machine Learning, Statistics - Machine Learning},
	pages = {299--309},
	annote = {Comment: Accepted at IEEE VIS 2018. To appear in IEEE Transactions on Visualization and Computer Graphics in January 2019},
	file = {arXiv.org Snapshot:/Users/vsivaram/Zotero/storage/V65A7JBM/1805.html:text/html;Full Text PDF:/Users/vsivaram/Zotero/storage/Z3TKKKSJ/Kwon et al. - 2019 - RetainVis Visual Analytics with Interpretable and.pdf:application/pdf},
}


@inproceedings{kwon_peekquence_2016,
	title = {Peekquence: {Visual} {Analytics} for {Event} {Sequence} {Data}},
	abstract = {Exploring event sequences in big data is challenging. Though many mining algorithms have been developed to derive the most frequently occurring and the most meaningful sequential patterns, it is yet diﬃcult to make sense of the results. To tackle the problem, we introduce a visual analytics approach, Peekquence. In this paper, we describe the design of Peekquence, which aims to increase the interpretability of machine learning-based sequence mining algorithms.},
	language = {en},
	author = {Kwon, Bum Chul and Verma, Janu and Perer, Adam},
	year = {2016},
	file = {Kwon et al. - Peekquence Visual Analytics for Event Sequence Da.pdf:/Users/vsivaram/Zotero/storage/KFXB5FCA/Kwon et al. - Peekquence Visual Analytics for Event Sequence Da.pdf:application/pdf},
}


@article{nguyen_understanding_2019,
	title = {Understanding {User} {Behaviour} through {Action} {Sequences}: {From} the {Usual} to the {Unusual}},
	volume = {25},
	issn = {1077-2626, 1941-0506, 2160-9306},
	shorttitle = {Understanding {User} {Behaviour} through {Action} {Sequences}},
	url = {https://ieeexplore.ieee.org/document/8419283/},
	doi = {10.1109/TVCG.2018.2859969},
	abstract = {Action sequences, where atomic user actions are represented in a labelled, timestamped form, are becoming a fundamental data asset in the inspection and monitoring of user behaviour in digital systems. Although the analysis of such sequences is highly critical to the investigation of activities in cyber security applications, existing solutions fail to provide a comprehensive understanding due to the complex semantic and temporal characteristics of these data. This paper presents a visual analytics approach that aims to facilitate a user-involved, multi-faceted decision making process during the identiﬁcation and the investigation of “unusual” action sequences. We ﬁrst report the results of the task analysis and domain characterisation process. Then we describe the components of our multi-level analysis approach that comprises of constraint-based sequential pattern mining and semantic distance based clustering, and multi-scalar visualisations of users and their sequences. Finally, we demonstrate the applicability of our approach through a case study that involves tasks requiring effective decision-making by a group of domain experts. Although our solution here is tightly informed by a user-centred, domain-focused design process, we present ﬁndings and techniques that are transferable to other applications where the analysis of such sequences is of interest.},
	language = {en},
	number = {9},
	urldate = {2024-02-26},
	journal = {IEEE Transactions on Visualization and Computer Graphics},
	author = {Nguyen, Phong H. and Turkay, Cagatay and Andrienko, Gennady and Andrienko, Natalia and Thonnard, Olivier and Zouaoui, Jihane},
	month = sep,
	year = {2019},
	pages = {2838--2852},
	file = {Nguyen et al. - 2019 - Understanding User Behaviour through Action Sequen.pdf:/Users/vsivaram/Zotero/storage/J33R2ADG/Nguyen et al. - 2019 - Understanding User Behaviour through Action Sequen.pdf:application/pdf},
}

@article{gotz_decisionflow_2014,
	title = {{DecisionFlow}: {Visual} {Analytics} for {High}-{Dimensional} {Temporal} {Event} {Sequence} {Data}},
	volume = {20},
	issn = {1077-2626, 1941-0506, 2160-9306},
	shorttitle = {{DecisionFlow}},
	url = {https://ieeexplore.ieee.org/document/6875996/},
	doi = {10.1109/TVCG.2014.2346682},
	abstract = {Temporal event sequence data is increasingly commonplace, with applications ranging from electronic medical records to ﬁnancial transactions to social media activity. Previously developed techniques have focused on low-dimensional datasets (e.g., with less than 20 distinct event types). Real-world datasets are often far more complex. This paper describes DecisionFlow, a visual analysis technique designed to support the analysis of high-dimensional temporal event sequence data (e.g., thousands of event types). DecisionFlow combines a scalable and dynamic temporal event data structure with interactive multi-view visualizations and ad hoc statistical analytics. We provide a detailed review of our methods, and present the results from a 12-person user study. The study results demonstrate that DecisionFlow enables the quick and accurate completion of a range of sequence analysis tasks for datasets containing thousands of event types and millions of individual events.},
	language = {en},
	number = {12},
	urldate = {2024-02-26},
	journal = {IEEE Transactions on Visualization and Computer Graphics},
	author = {Gotz, David and Stavropoulos, Harry},
	month = dec,
	year = {2014},
	pages = {1783--1792},
	file = {Gotz and Stavropoulos - 2014 - DecisionFlow Visual Analytics for High-Dimensiona.pdf:/Users/vsivaram/Zotero/storage/E5WWIUI8/Gotz and Stavropoulos - 2014 - DecisionFlow Visual Analytics for High-Dimensiona.pdf:application/pdf},
}

@inproceedings{zgraggen_squeries_2015,
	address = {Seoul Republic of Korea},
	title = {(s{\textbar}qu)eries: {Visual} {Regular} {Expressions} for {Querying} and {Exploring} {Event} {Sequences}},
	isbn = {978-1-4503-3145-6},
	shorttitle = {(s{\textbar}qu)eries},
	url = {https://dl.acm.org/doi/10.1145/2702123.2702262},
	doi = {10.1145/2702123.2702262},
	language = {en},
	urldate = {2024-02-26},
	booktitle = {Proceedings of the 33rd {Annual} {ACM} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {ACM},
	author = {Zgraggen, Emanuel and Drucker, Steven M. and Fisher, Danyel and DeLine, Robert},
	month = apr,
	year = {2015},
	pages = {2683--2692},
	file = {Full Text PDF:/Users/vsivaram/Zotero/storage/GKZYA93S/Zgraggen et al. - 2015 - (squ)eries Visual Regular Expressions for Queryi.pdf:application/pdf},
}

@inproceedings{wongsuphasawat_finding_2009,
	address = {Atlantic City, NJ, USA},
	title = {Finding comparable temporal categorical records: {A} similarity measure with an interactive visualization},
	isbn = {978-1-4244-5283-5},
	shorttitle = {Finding comparable temporal categorical records},
	url = {http://ieeexplore.ieee.org/document/5332595/},
	doi = {10.1109/VAST.2009.5332595},
	abstract = {An increasing number of temporal categorical databases are being collected: Electronic Health Records in healthcare organizations, trafﬁc incident logs in transportation systems, or student records in universities. Finding similar records within these large databases requires effective similarity measures that capture the searcher’s intent. Many similarity measures exist for numerical time series, but temporal categorical records are different. We propose a temporal categorical similarity measure, the M\&M (Match \& Mismatch) measure, which is based on the concept of aligning records by sentinel events, then matching events between the target and the compared records. The M\&M measure combines the time differences between pairs of events and the number of mismatches. To accommodate customization of parameters in the M\&M measure and results interpretation, we implemented Similan, an interactive search and visualization tool for temporal categorical records. A usability study with 8 participants demonstrated that Similan was easy to learn and enabled them to ﬁnd similar records, but users had difﬁculty understanding the M\&M measure. The usability study feedback, led to an improved version with a continuous timeline, which was tested in a pilot study with 5 participants.},
	language = {en},
	urldate = {2024-02-26},
	booktitle = {2009 {IEEE} {Symposium} on {Visual} {Analytics} {Science} and {Technology}},
	publisher = {IEEE},
	author = {Wongsuphasawat, Krist and Shneiderman, Ben},
	year = {2009},
	pages = {27--34},
	file = {Wongsuphasawat and Shneiderman - 2009 - Finding comparable temporal categorical records A.pdf:/Users/vsivaram/Zotero/storage/RV6PDQ5N/Wongsuphasawat and Shneiderman - 2009 - Finding comparable temporal categorical records A.pdf:application/pdf},
}

@article{damour_underspecication_nodate,
	title = {Underspeciﬁcation {Presents} {Challenges} for {Credibility} in {Modern} {Machine} {Learning}},
	abstract = {Machine learning (ML) systems often exhibit unexpectedly poor behavior when they are deployed in real-world domains. We identify underspeciﬁcation in ML pipelines as a key reason for these failures. An ML pipeline is the full procedure followed to train and validate a predictor. Such a pipeline is underspeciﬁed when it can return many distinct predictors with equivalently strong test performance. Underspeciﬁcation is common in modern ML pipelines that primarily validate predictors on held-out data that follow the same distribution as the training data. Predictors returned by underspeciﬁed pipelines are often treated as equivalent based on their training domain performance, but we show here that such predictors can behave very diﬀerently in deployment domains. This ambiguity can lead to instability and poor model behavior in practice, and is a distinct failure mode from previously identiﬁed issues arising from structural mismatch between training and deployment domains. We provide evidence that underspecﬁcation has substantive implications for practical ML pipelines, using examples from computer vision, medical imaging, natural language processing, clinical risk prediction based on electronic health records, and medical genomics. Our results show the need to explicitly account for underspeciﬁcation in modeling pipelines that are intended for real-world deployment in any domain.},
	language = {en},
	author = {D’Amour, Alexander and Heller, Katherine and Moldovan, Dan and Adlam, Ben and Alipanahi, Babak and Beutel, Alex and Chen, Christina and Deaton, Jonathan and Eisenstein, Jacob and Hoﬀman, Matthew D and Hormozdiari, Farhad and Houlsby, Neil and Hou, Shaobo and Jerfel, Ghassen and Karthikesalingam, Alan and Lucic, Mario and Ma, Yian and McLean, Cory and Mincu, Diana and Mitani, Akinori and Montanari, Andrea and Nado, Zachary and Natarajan, Vivek and Nielson, Christopher and Osborne, Thomas F and Raman, Rajiv and Ramasamy, Kim and Sayres, Rory and Schrouﬀ, Jessica and Seneviratne, Martin and Sequeira, Shannon and Suresh, Harini and Veitch, Victor and Vladymyrov, Max and Wang, Xuezhi and Webster, Kellie and Yadlowsky, Steve and Yun, Taedong and Zhai, Xiaohua and Sculley, D},
	file = {D’Amour et al. - Underspeciﬁcation Presents Challenges for Credibil.pdf:/Users/vsivaram/Zotero/storage/7929YBND/D’Amour et al. - Underspeciﬁcation Presents Challenges for Credibil.pdf:application/pdf},
}

@inproceedings{tal_target_2023,
	address = {Montr\'{e}al QC Canada},
	title = {Target specification bias, counterfactual prediction, and algorithmic fairness in healthcare},
	isbn = {9798400702310},
	url = {https://dl.acm.org/doi/10.1145/3600211.3604678},
	doi = {10.1145/3600211.3604678},
	language = {en},
	urldate = {2024-02-26},
	booktitle = {Proceedings of the 2023 {AAAI}/{ACM} {Conference} on {AI}, {Ethics}, and {Society}},
	publisher = {ACM},
	author = {Tal, Eran},
	month = aug,
	year = {2023},
	pages = {312--321},
	file = {Full Text PDF:/Users/vsivaram/Zotero/storage/64PLWCR4/Tal - 2023 - Target specification bias, counterfactual predicti.pdf:application/pdf},
}

@inproceedings{jacobs_measurement_2021,
	title = {Measurement and {Fairness}},
	url = {http://arxiv.org/abs/1912.05511},
	doi = {10.1145/3442188.3445901},
	abstract = {We propose measurement modeling from the quantitative social sciences as a framework for understanding fairness in computational systems. Computational systems often involve unobservable theoretical constructs, such as socioeconomic status, teacher effectiveness, and risk of recidivism. Such constructs cannot be measured directly and must instead be inferred from measurements of observable properties (and other unobservable theoretical constructs) thought to be related to them -- i.e., operationalized via a measurement model. This process, which necessarily involves making assumptions, introduces the potential for mismatches between the theoretical understanding of the construct purported to be measured and its operationalization. We argue that many of the harms discussed in the literature on fairness in computational systems are direct results of such mismatches. We show how some of these harms could have been anticipated and, in some cases, mitigated if viewed through the lens of measurement modeling. To do this, we contribute fairness-oriented conceptualizations of construct reliability and construct validity that unite traditions from political science, education, and psychology and provide a set of tools for making explicit and testing assumptions about constructs and their operationalizations. We then turn to fairness itself, an essentially contested construct that has different theoretical understandings in different contexts. We argue that this contestedness underlies recent debates about fairness definitions: although these debates appear to be about different operationalizations, they are, in fact, debates about different theoretical understandings of fairness. We show how measurement modeling can provide a framework for getting to the core of these debates.},
	urldate = {2024-02-26},
	booktitle = {Proceedings of the 2021 {ACM} {Conference} on {Fairness}, {Accountability}, and {Transparency}},
	author = {Jacobs, Abigail Z. and Wallach, Hanna},
	month = mar,
	year = {2021},
	note = {arXiv:1912.05511 [cs]},
	keywords = {Computer Science - Computers and Society, Computer Science - Machine Learning},
	pages = {375--385},
	annote = {Comment: 11 pages, 1 figure. To be published in the proceedings of the ACM Conference on Fairness, Accountability, and Transparency (FAccT '21)},
	file = {arXiv.org Snapshot:/Users/vsivaram/Zotero/storage/26G5RUBU/1912.html:text/html;Full Text PDF:/Users/vsivaram/Zotero/storage/P47I4QQ4/Jacobs and Wallach - 2021 - Measurement and Fairness.pdf:application/pdf},
}

@inproceedings{passi_problem_2019,
	address = {Atlanta GA USA},
	title = {Problem {Formulation} and {Fairness}},
	isbn = {978-1-4503-6125-5},
	url = {https://dl.acm.org/doi/10.1145/3287560.3287567},
	doi = {10.1145/3287560.3287567},
	language = {en},
	urldate = {2024-02-26},
	booktitle = {Proceedings of the {Conference} on {Fairness}, {Accountability}, and {Transparency}},
	publisher = {ACM},
	author = {Passi, Samir and Barocas, Solon},
	month = jan,
	year = {2019},
	pages = {39--48},
	annote = {This paper gives an ethnographic account of the process of developing a problem formulation/specification for machine learning. The data scientists say that the teams expect “magic” from them, and the target variable shifts as people become aware of and discuss the issues with each option.
},
	file = {Full Text PDF:/Users/vsivaram/Zotero/storage/F3CJMHLL/Passi and Barocas - 2019 - Problem Formulation and Fairness.pdf:application/pdf},
}

@article{fazelpour_algorithmic_2021,
	title = {Algorithmic bias: {Senses}, sources, solutions},
	volume = {16},
	issn = {1747-9991},
	shorttitle = {Algorithmic bias},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/phc3.12760},
	doi = {10.1111/phc3.12760},
	abstract = {Data-driven algorithms are widely used to make or assist decisions in sensitive domains, including healthcare, social services, education, hiring, and criminal justice. In various cases, such algorithms have preserved or even exacerbated biases against vulnerable communities, sparking a vibrant field of research focused on so-called algorithmic biases. This research includes work on identification, diagnosis, and response to biases in algorithm-based decision-making. This paper aims to facilitate the application of philosophical analysis to these contested issues by providing an overview of three key topics: What is algorithmic bias? Why and how can it occur? What can and should be done about it? Throughout, we highlight connections—both actual and potential—with philosophical ideas and concerns.},
	language = {en},
	number = {8},
	urldate = {2024-02-26},
	journal = {Philosophy Compass},
	author = {Fazelpour, Sina and Danks, David},
	year = {2021},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/phc3.12760},
	pages = {e12760},
	file = {Full Text PDF:/Users/vsivaram/Zotero/storage/Q8UIMIXT/Fazelpour and Danks - 2021 - Algorithmic bias Senses, sources, solutions.pdf:application/pdf;Snapshot:/Users/vsivaram/Zotero/storage/PQBHWTLR/phc3.html:text/html},
}

@article{schwartz_clinician_2021,
	title = {Clinician involvement in research on machine learning–based predictive clinical decision support for the hospital setting: {A} scoping review},
	volume = {28},
	issn = {1067-5027},
	shorttitle = {Clinician involvement in research on machine learning–based predictive clinical decision support for the hospital setting},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7936403/},
	doi = {10.1093/jamia/ocaa296},
	abstract = {Objective
The study sought to describe the prevalence and nature of clinical expert involvement in the development, evaluation, and implementation of clinical decision support systems (CDSSs) that utilize machine learning to analyze electronic health record data to assist nurses and physicians in prognostic and treatment decision making (ie, predictive CDSSs) in the hospital.

Materials and Methods
A systematic search of PubMed, CINAHL, and IEEE Xplore and hand-searching of relevant conference proceedings were conducted to identify eligible articles. Empirical studies of predictive CDSSs using electronic health record data for nurses or physicians in the hospital setting published in the last 5 years in peer-reviewed journals or conference proceedings were eligible for synthesis. Data from eligible studies regarding clinician involvement, stage in system design, predictive CDSS intention, and target clinician were charted and summarized.

Results
Eighty studies met eligibility criteria. Clinical expert involvement was most prevalent at the beginning and late stages of system design. Most articles (95\%) described developing and evaluating machine learning models, 28\% of which described involving clinical experts, with nearly half functioning to verify the clinical correctness or relevance of the model (47\%).

Discussion
Involvement of clinical experts in predictive CDSS design should be explicitly reported in publications and evaluated for the potential to overcome predictive CDSS adoption challenges.

Conclusions
If present, clinical expert involvement is most prevalent when predictive CDSS specifications are made or when system implementations are evaluated. However, clinical experts are less prevalent in developmental stages to verify clinical correctness, select model features, preprocess data, or serve as a gold standard.},
	number = {3},
	urldate = {2024-02-26},
	journal = {Journal of the American Medical Informatics Association : JAMIA},
	author = {Schwartz, Jessica M and Moy, Amanda J and Rossetti, Sarah C and Elhadad, Noémie and Cato, Kenrick D},
	month = jan,
	year = {2021},
	pmid = {33325504},
	pmcid = {PMC7936403},
	pages = {653--663},
	file = {Full Text PDF:/Users/vsivaram/Zotero/storage/VCZRGZSV/Schwartz et al. - 2021 - Clinician involvement in research on machine learn.pdf:application/pdf},
}

@inproceedings{santos_visus_2019,
	address = {Amsterdam Netherlands},
	title = {Visus: {An} {Interactive} {System} for {Automatic} {Machine} {Learning} {Model} {Building} and {Curation}},
	isbn = {978-1-4503-6791-2},
	shorttitle = {Visus},
	url = {https://dl.acm.org/doi/10.1145/3328519.3329134},
	doi = {10.1145/3328519.3329134},
	language = {en},
	urldate = {2024-02-27},
	booktitle = {Proceedings of the {Workshop} on {Human}-{In}-the-{Loop} {Data} {Analytics}},
	publisher = {ACM},
	author = {Santos, Aécio and Castelo, Sonia and Felix, Cristian and Ono, Jorge Piazentin and Yu, Bowen and Hong, Sungsoo Ray and Silva, Cláudio T. and Bertini, Enrico and Freire, Juliana},
	month = jul,
	year = {2019},
	pages = {1--7},
	file = {Full Text PDF:/Users/vsivaram/Zotero/storage/DC3W8VKE/Santos et al. - 2019 - Visus An Interactive System for Automatic Machine.pdf:application/pdf},
}

@article{cashman_user-based_2019,
	title = {A {User}-based {Visual} {Analytics} {Workflow} for {Exploratory} {Model} {Analysis}},
	volume = {38},
	issn = {1467-8659},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/cgf.13681},
	doi = {10.1111/cgf.13681},
	abstract = {Many visual analytics systems allow users to interact with machine learning models towards the goals of data exploration and insight generation on a given dataset. However, in some situations, insights may be less important than the production of an accurate predictive model for future use. In that case, users are more interested in generating of diverse and robust predictive models, verifying their performance on holdout data, and selecting the most suitable model for their usage scenario. In this paper, we consider the concept of Exploratory Model Analysis (EMA), which is defined as the process of discovering and selecting relevant models that can be used to make predictions on a data source. We delineate the differences between EMA and the well-known term exploratory data analysis in terms of the desired outcome of the analytic process: insights into the data or a set of deployable models. The contributions of this work are a visual analytics system workflow for EMA, a user study, and two use cases validating the effectiveness of the workflow. We found that our system workflow enabled users to generate complex models, to assess them for various qualities, and to select the most relevant model for their task.},
	language = {en},
	number = {3},
	urldate = {2024-02-27},
	journal = {Computer Graphics Forum},
	author = {Cashman, Dylan and Humayoun, Shah Rukh and Heimerl, Florian and Park, Kendall and Das, Subhajit and Thompson, John and Saket, Bahador and Mosca, Abigail and Stasko, John and Endert, Alex and Gleicher, Michael and Chang, Remco},
	year = {2019},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/cgf.13681},
	keywords = {• Computing methodologies → Model development and analysis, • Human-centered computing → Visual analytics, • Mathematics of computing → Exploratory data analysis, CCS Concepts},
	pages = {185--199},
	file = {Snapshot:/Users/vsivaram/Zotero/storage/MY84N58M/cgf.html:text/html;Submitted Version:/Users/vsivaram/Zotero/storage/AF253Q3V/Cashman et al. - 2019 - A User-based Visual Analytics Workflow for Explora.pdf:application/pdf},
}

@article{krause_infuse_2014,
	title = {{INFUSE}: {Interactive} {Feature} {Selection} for {Predictive} {Modeling} of {High} {Dimensional} {Data}},
	volume = {20},
	issn = {1077-2626},
	shorttitle = {{INFUSE}},
	url = {http://ieeexplore.ieee.org/document/6876047/},
	doi = {10.1109/TVCG.2014.2346482},
	abstract = {Predictive modeling techniques are increasingly being used by data scientists to understand the probability of predicted outcomes. However, for data that is high-dimensional, a critical step in predictive modeling is determining which features should be included in the models. Feature selection algorithms are often used to remove non-informative features from models. However, there are many different classes of feature selection algorithms. Deciding which one to use is problematic as the algorithmic output is often not amenable to user interpretation. This limits the ability for users to utilize their domain expertise during the modeling process. To improve on this limitation, we developed INFUSE, a novel visual analytics system designed to help analysts understand how predictive features are being ranked across feature selection algorithms, cross-validation folds, and classiﬁers. We demonstrate how our system can lead to important insights in a case study involving clinical researchers predicting patient outcomes from electronic medical records.},
	language = {en},
	number = {12},
	urldate = {2024-02-29},
	journal = {IEEE Transactions on Visualization and Computer Graphics},
	author = {Krause, Josua and Perer, Adam and Bertini, Enrico},
	month = dec,
	year = {2014},
	pages = {1614--1623},
	file = {Krause et al. - 2014 - INFUSE Interactive Feature Selection for Predicti.pdf:/Users/vsivaram/Zotero/storage/SB2D7B36/Krause et al. - 2014 - INFUSE Interactive Feature Selection for Predicti.pdf:application/pdf},
}

@article{dziorny_clinical_2022,
	title = {Clinical {Decision} {Support} in the {PICU}: {Implications} for {Design} and {Evaluation}*},
	volume = {23},
	issn = {1529-7535},
	shorttitle = {Clinical {Decision} {Support} in the {PICU}},
	url = {https://journals.lww.com/pccmjournal/abstract/2022/08000/clinical_decision_support_in_the_picu_.19.aspx},
	doi = {10.1097/PCC.0000000000002973},
	abstract = {OBJECTIVES: 
          To assess the current landscape of clinical decision support (CDS) tools in PICUs in order to identify priority areas of focus in this field.
          DESIGN: 
          International, quantitative, cross-sectional survey.
          SETTING: 
          Role-specific, web-based survey administered in November and December 2020.
          SUBJECTS: 
          Medical directors, bedside nurses, attending physicians, and residents/advanced practice providers at Pediatric Acute Lung Injury and Sepsis Network-affiliated PICUs.
          INTERVENTIONS: 
          None.
          MEASUREMENTS AND MAIN RESULTS: 
          The survey was completed by 109 respondents from 45 institutions, primarily attending physicians from university-affiliated PICUs in the United States. The most commonly used CDS tools were people-based resources (93\% used always or most of the time) and laboratory result highlighting (86\%), with order sets, order-based alerts, and other electronic CDS tools also used frequently. The most important goal providers endorsed for CDS tools were a proven impact on patient safety and an evidence base for their use. Negative perceptions of CDS included concerns about diminished critical thinking and the burden of intrusive processes on providers. Routine assessment of existing CDS was rare, with infrequent reported use of observation to assess CDS impact on workflows or measures of individual alert burden.
          CONCLUSIONS: 
          Although providers share some consensus over CDS utility, we identified specific priority areas of research focus. Consensus across practitioners exists around the importance of evidence-based CDS tools having a proven impact on patient safety. Despite broad presence of CDS tools in PICUs, practitioners continue to view them as intrusive and with concern for diminished critical thinking. Deimplementing ineffective CDS may mitigate this burden, though postimplementation evaluation of CDS is rare.},
	language = {en-US},
	number = {8},
	urldate = {2024-03-02},
	journal = {Pediatric Critical Care Medicine},
	author = {Dziorny, Adam C. and Heneghan, Julia A. and Bhat, Moodakare Ashwini and Karavite, Dean J. and Sanchez-Pinto, L. Nelson and McArthur, Jennifer and Muthu, Naveen},
	month = aug,
	year = {2022},
	pages = {e392},
}


@article{Khairat2018,
	title = {Reasons for physicians not adopting clinical decision support systems: {Critical} analysis},
	volume = {20},
	issn = {22919694},
	doi = {10.2196/medinform.8912},
	abstract = {Background: Clinical decision support systems (CDSSs) are an integral component of today's health information technologies. They assist with interpretation, diagnosis, and treatment. A CDSS can be embedded throughout the patient safety continuum providing reminders, recommendations, and alerts to health care providers. Although CDSSs have been shown to reduce medical errors and improve patient outcomes, they have fallen short of their full potential. User acceptance has been identified as one of the potential reasons for this shortfall. Objective: The purpose of this paper was to conduct a critical review and task analysis of CDSS research and to develop a new framework for CDSS design in order to achieve user acceptance. Methods: A critical review of CDSS papers was conducted with a focus on user acceptance. To gain a greater understanding of the problems associated with CDSS acceptance, we conducted a task analysis to identify and describe the goals, user input, system output, knowledge requirements, and constraints from two different perspectives: the machine (ie, the CDSS engine) and the user (ie, the physician). Results: Favorability of CDSSs was based on user acceptance of clinical guidelines, reminders, alerts, and diagnostic suggestions. We propose two models: (1) the user acceptance and system adaptation design model, which includes optimizing CDSS design based on user needs/expectations, and (2) the input-process-output-engagemodel, which reveals to users the processes that govern CDSS outputs. Conclusions: This research demonstrates that the incorporation of the proposed models will improve user acceptance to support the beneficial effects of CDSSs adoption. Ultimately, if a user does not accept technology, this not only poses a threat to the use of the technology but can also pose a threat to the health and well-being of patients.},
	number = {4},
	journal = {JMIR Medical Informatics},
	author = {Khairat, Saif and Marc, David and Crosby, William and Al Sanousi, Ali},
	year = {2018},
	keywords = {Attitude to computers, Clinical, Computer-assisted, Decision making, Decision support systems},
	file = {PDF:/Users/vsivaram/Zotero/storage/7WQADJK6/PDF.pdf:application/pdf},
}


@inproceedings{Sivaraman2023,
	title = {Ignore, {Trust}, or {Negotiate}: {Understanding} {Clinician} {Acceptance} of {AI}-{Based} {Treatment} {Recommendations} in {Health} {Care}},
		isbn = {978-1-4503-9421-5},
	abstract = {Artificial intelligence (AI) in healthcare has the potential to improve patient outcomes, but clinician acceptance remains a critical barrier. We developed a novel decision support interface that provides interpretable treatment recommendations for sepsis, a life-threatening condition in which decisional uncertainty is common, treatment practices vary widely, and poor outcomes can occur even with optimal decisions. This system formed the basis of a mixed-methods study in which 24 intensive care clinicians made AI-assisted decisions on real patient cases. We found that explanations generally increased confidence in the AI, but concordance with specific recommendations varied beyond the binary acceptance or rejection described in prior work. Although clinicians sometimes ignored or trusted the AI, they also often prioritized aspects of the recommendations to follow, reject, or delay in a process we term "negotiation."These results reveal novel barriers to adoption of treatment-focused AI tools and suggest ways to better support differing clinician perspectives.},
	publisher = {Association for Computing Machinery},
	author = {Sivaraman, Venkatesh and Bukowski, Leigh A. and Levin, Joel and Kahn, Jeremy M. and Perer, Adam},
	year = {2023},
	doi = {10.1145/3544548.3581075},
	note = {arXiv: 2302.00096
Publication Title: Conference on Human Factors in Computing Systems - Proceedings
Issue: 1},
	keywords = {healthcare, human-AI interaction, interpretability, visualization},
	file = {PDF:/Users/vsivaram/Zotero/storage/5XUZ48T4/chi23-392-tagged.pdf:application/pdf},
}


@article{Kawakami2022partnerships,
    author = "Kawakami, Anna and Sivaraman, Venkatesh and Cheng, Hao-Fei and Stapleton, Logan and Cheng, Yanghuidi and Qing, Diana and Perer, Adam and Wu, Zhiwei Steven and Zhu, Haiyi and Holstein, Kenneth",
    abstract = "AI-based decision support tools (ADS) are increasingly used to augment human decision-making in high-stakes, social contexts. As public sector agencies begin to adopt ADS, it is critical that we understand workers' experiences with these systems in practice. In this paper, we present findings from a series of interviews and contextual inquiries at a child welfare agency, to understand how they currently make AI-assisted child maltreatment screening decisions. Overall, we observe how workers' reliance upon the ADS is guided by (1) their knowledge of rich, contextual information beyond what the AI model captures, (2) their beliefs about the ADS's capabilities and limitations relative to their own, (3) organizational pressures and incentives around the use of the ADS, and (4) awareness of misalignments between algorithmic predictions and their own decision-making objectives. Drawing upon these findings, we discuss design implications towards supporting more effective human-AI decision-making.",
    archivePrefix = "arXiv",
    arxivId = "2204.02310",
    booktitle = "Conference on Human Factors in Computing Systems - Proceedings",
    eprint = "2204.02310",
    file = ":Users/vsivaram/Documents/papers/3491102.3517439.pdf:pdf",
    keywords = "algorithm-assisted decision making,child welfare,contextual,decision suppo,decision support,inquiry,this work is licensed,under a creative commons",
    mendeley-groups = "AI Clinician/Cognitive Mini,AI Clinician",
    title = "{Improving Human-AI Partnerships in Child Welfare: Understanding Worker Practices, Challenges, and Desires for Algorithmic Decision Support}",
    year = "2022"
}

@inproceedings{Kawakami2022dis,
    author = {Kawakami, Anna and Sivaraman, Venkatesh and Stapleton, Logan and Cheng, Hao-Fei and Perer, Adam and Wu, Zhiwei Steven and Zhu, Haiyi and Holstein, Kenneth},
    title = {“Why Do I Care What’s Similar?” Probing Challenges in AI-Assisted Child Welfare Decision-Making through Worker-AI Interface Design Concepts},
    year = {2022},
    isbn = {9781450393584},
    publisher = {Association for Computing Machinery},
    address = {New York, NY, USA},
    url = {https://doi.org/10.1145/3532106.3533556},
    doi = {10.1145/3532106.3533556},
    abstract = {Data-driven AI systems are increasingly used to augment human decision-making in complex, social contexts, such as social work or legal practice. Yet, most existing design knowledge regarding how to best support AI-augmented decision-making comes from studies in comparatively well-defined settings. In this paper, we present findings from design interviews with 12 social workers who use an algorithmic decision support tool (ADS) to assist their day-to-day child maltreatment screening decisions. We generated a range of design concepts, each envisioning different ways of redesigning or augmenting the ADS interface. Overall, workers desired ways to understand the risk score and incorporate contextual knowledge, which move beyond existing notions of AI interpretability. Conversations around our design concepts also surfaced more fundamental concerns around the assumptions underlying statistical prediction, such as inference based on similar historical cases and statistical notions of uncertainty. Based on our findings, we discuss how ADS may be better designed to support the roles of human decision-makers in social decision-making contexts.},
    booktitle = {Proceedings of the 2022 ACM Designing Interactive Systems Conference},
    pages = {454–470},
    numpages = {17},
    keywords = {AI-assisted decision-making, algorithmic decision support, child welfare, design, social work},
    location = {Virtual Event, Australia},
    series = {DIS '22}
}


@article{Kuo2023,
	title = {Understanding {Frontline} {Workers}' and {Unhoused} {Individuals}' {Perspectives} on {AI} {Used} in {Homeless} {Services}},
	doi = {10.1145/3544548.3580882},
	abstract = {Recent years have seen growing adoption of AI-based decision-support systems (ADS) in homeless services, yet we know little about stakeholder desires and concerns surrounding their use. In this work, we aim to understand impacted stakeholders' perspectives on a deployed ADS that prioritizes scarce housing resources. We employed AI lifecycle comicboarding, an adapted version of the comicboarding method, to elicit stakeholder feedback and design ideas across various components of an AI system's design. We elicited feedback from county workers who operate the ADS daily, service providers whose work is directly impacted by the ADS, and unhoused individuals in the region. Our participants shared concerns and design suggestions around the AI system's overall objective, specific model design choices, dataset selection, and use in deployment. Our findings demonstrate that stakeholders, even without AI knowledge, can provide specific and critical feedback on an AI system's design and deployment, if empowered to do so.},
	journal = {Conference on Human Factors in Computing Systems - Proceedings},
	author = {Kuo, Tzu Sheng and Shen, Hong and Geum, Jisoo and Jones, Nev and Hong, Jason I. and Zhu, Haiyi and Holstein, Kenneth},
	year = {2023},
	note = {ISBN: 9781450394215},
	keywords = {AI-based decision support, comicboarding, homelessness, public algorithms},
	file = {PDF:/Users/vsivaram/Zotero/storage/7CHQH8ZP/3544548.3580882.pdf:application/pdf},
}


@article{Beede2020,
	title = {A {Human}-{Centered} {Evaluation} of a {Deep} {Learning} {System} {Deployed} in {Clinics} for the {Detection} of {Diabetic} {Retinopathy}},
	doi = {10.1145/3313831.3376718},
	abstract = {Deep learning algorithms promise to improve clinician workflows and patient outcomes. However, these gains have yet to be fully demonstrated in real world clinical settings. In this paper, we describe a human-centered study of a deep learning system used in clinics for the detection of diabetic eye disease. From interviews and observation across eleven clinics in Thailand, we characterize current eye-screening workflows, user expectations for an AI-assisted screening process, and post-deployment experiences. Our findings indicate that several socio-environmental factors impact model performance, nursing workflows, and the patient experience. We draw on these findings to reflect on the value of conducting human-centered evaluative research alongside prospective evaluations of model accuracy.},
	journal = {Conference on Human Factors in Computing Systems - Proceedings},
	author = {Beede, Emma and Baylor, Elizabeth and Hersch, Fred and Iurchenko, Anna and Wilcox, Lauren and Ruamviboonsuk, Paisan and Vardoulakis, Laura M.},
	year = {2020},
	note = {ISBN: 9781450367080},
	keywords = {deep learning, diabetes, health, human-centered ai},
	pages = {1--12},
	file = {PDF:/Users/vsivaram/Zotero/storage/XPJWKLLH/3313831.3376718.pdf:application/pdf},
}

@article{Wang2021,
	title = {Brilliant ai doctor in rural clinics: {Challenges} in ai-powered clinical decision support system deployment},
	doi = {10.1145/3411764.3445432},
	abstract = {Artifcial intelligence (AI) technology has been increasingly used in the implementation of advanced Clinical Decision Support Systems (CDSS). Research demonstrated the potential usefulness of AI-powered CDSS (AI-CDSS) in clinical decision making scenarios. However, post-adoption user perception and experience remain understudied, especially in developing countries. Through observations and interviews with 22 clinicians from 6 rural clinics in China, this paper reports the various tensions between the design of an AI-CDSS system (Brilliant Doctor) and the rural clinical context, such as the misalignment with local context and workfow, the technical limitations and usability barriers, as well as issues related to transparency and trustworthiness of AI-CDSS. Despite these tensions, all participants expressed positive attitudes toward the future of AI-CDSS, especially acting as a doctor's AI assistant to realize a Human-AI Collaboration future in clinical settings. Finally we draw on our fndings to discuss implications for designing AI-CDSS interventions for rural clinical contexts in developing countries.},
	journal = {Conference on Human Factors in Computing Systems - Proceedings},
	author = {Wang, Dakuo and Wang, Liuping and Zhang, Zhan},
	year = {2021},
	note = {ISBN: 9781450380966},
	keywords = {Ai, Ai deployment, Cdss, China, Clinical decision making, Collaborative ai, Decision making, Developing country, Future of work, Healthcare, Human ai collaboration, Human ai interaction, Implementation, Rural clinic, Trust ai, Workfow},
	file = {PDF:/Users/vsivaram/Zotero/storage/ZHKWZ6VE/3411764.3445432.pdf:application/pdf},
}


@article{Grgic-Hlaca2018,
	title = {Human perceptions of fairness in algorithmic decision making: {A} case study of criminal risk prediction},
	issn = {23318422},
	abstract = {As algorithms are increasingly used to make important decisions that affect human lives, ranging from social benefit assignment to predicting risk of criminal recidivism, concerns have been raised about the fairness of algorithmic decision making. Most prior works on algorithmic fairness normatively prescribe how fair decisions ought to be made. In contrast, here, we descriptively survey users for how they perceive and reason about fairness in algorithmic decision making. A key contribution of this work is the framework we propose to understand why people perceive certain features as fair or unfair to be used in algorithms. Our framework identifies eight properties of features, such as relevance, volitionality and reliability, as latent considerations that inform people's moral judgments about the fairness of feature use in decision-making algorithms. We validate our framework through a series of scenario-based surveys with 576 people. We find that, based on a person's assessment of the eight latent properties of a feature in our exemplar scenario, we can accurately ({\textgreater} 85\%) predict if the person will judge the use of the feature as fair. Our findings have important implications. At a high-level, we show that people's unfairness concerns are multi-dimensional and argue that future studies need to address unfairness concerns beyond discrimination. At a low-level, we find considerable disagreements in people's fairness judgments. We identify root causes of the disagreements, and note possible pathways to resolve them.},
	journal = {arXiv},
	author = {Grgić-Hlača, Nina and Redmiles, Elissa M. and Gummadi, Krishna P. and Weller, Adrian},
	year = {2018},
	note = {ISBN: 9781450356398},
	keywords = {Algorithmic Discrimination, Algorithmic Fairness, Fair Feature Selection, Fairness in Machine Learning, Procedural Fairness},
	file = {PDF:/Users/vsivaram/Zotero/storage/JFY9FM6P/3178876.3186138.pdf:application/pdf},
}


@inproceedings{cabrera_zeno_2023,
	address = {Hamburg Germany},
	title = {Zeno: {An} {Interactive} {Framework} for {Behavioral} {Evaluation} of {Machine} {Learning}},
	isbn = {978-1-4503-9421-5},
	shorttitle = {Zeno},
	url = {https://dl.acm.org/doi/10.1145/3544548.3581268},
	doi = {10.1145/3544548.3581268},
	language = {en},
	urldate = {2024-03-02},
	booktitle = {Proceedings of the 2023 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {ACM},
	author = {Cabrera, Ángel Alexander and Fu, Erica and Bertucci, Donald and Holstein, Kenneth and Talwalkar, Ameet and Hong, Jason I. and Perer, Adam},
	month = apr,
	year = {2023},
	pages = {1--14},
	file = {Full Text PDF:/Users/vsivaram/Zotero/storage/N7G43IJU/Cabrera et al. - 2023 - Zeno An Interactive Framework for Behavioral Eval.pdf:application/pdf},
}


@article{Gellad2023,
	title = {Development and validation of an overdose risk prediction tool using prescription drug monitoring program data},
	volume = {246},
	issn = {18790046},
	url = {https://doi.org/10.1016/j.drugalcdep.2023.109856},
	doi = {10.1016/j.drugalcdep.2023.109856},
	abstract = {Objectives: To develop and validate a machine-learning algorithm to predict fatal overdose using Pennsylvania Prescription Drug Monitoring Program (PDMP) data. Methods: The training/testing (n = 3020,748) and validation (n = 2237,701) cohorts included Pennsylvania residents with a prescription dispensing from February 2018-September 2021. Potential predictors (n = 222) were measured in the 6 months prior to a random index date. Using a gradient boosting machine, we developed a 20-variable model to predict risk of fatal drug overdose in the 6 months after the index date. Results: Beneficiaries in the training (n = 1,812,448), testing (n = 1,208,300), and validation (n = 2,237,701) samples had similar age, with low rates of fatal overdose during 6-month follow up (0.12\%, 0.12\%, 0.04\%, respectively). The validation c-statistic was 0.86 for predicting fatal overdose using 20 PDMP variables. When ranking individuals based on risk score, the prediction model more accurately identified fatal overdose at 6 months compared to using opioid dosage or opioid/benzodiazepine overlap, although the percentage of individuals in the highest risk percentile who died at 6 months was less than 1\%. Conclusions and policy implications: A gradient boosting machine algorithm predicting fatal overdose derived from twenty variables performed well in discriminating risk across testing and validation samples, improving on single factor risk measures like opioid dosage},
	number = {November 2022},
	journal = {Drug and Alcohol Dependence},
	author = {Gellad, Walid F. and Yang, Qingnan and Adamson, Kayleigh M. and Kuza, Courtney C. and Buchanich, Jeanine M. and Bolton, Ashley L. and Murzynski, Stanley M. and Goetz, Carrie Thomas and Washington, Terri and Lann, Michael F. and Chang, Chung Chou H. and Suda, Katie J. and Tang, Lu},
	year = {2023},
	pmid = {37001323},
	note = {Publisher: Elsevier B.V.},
	keywords = {Surveillance, Overdose prevention, Risk prediction, State policy},
	pages = {109856},
	file = {PDF:/Users/vsivaram/Zotero/storage/UBWV9T2H/1-s2.0-S0376871623000947-main.pdf:application/pdf},
}


@article{Vaithianathan2019,
	title = {Developing predictive risk models to support child maltreatment hotline screening decisions},
	author = {{Allegheny County} and Vaithianathan, Rhema and Jiang, Nan and Maloney, Tim and Nand, Parma and Putnam-Hornstein, Emily and Dare, Tim and Gambrill, Eileen},
	year = {2019},
	file = {PDF:/Users/vsivaram/Zotero/storage/ABZDV5K7/16-ACDHS-26_PredictiveRisk_Package_050119_FINAL-2.pdf:application/pdf},
}


@article{yang_re-examining_2020,
	title = {Re-examining {Whether}, {Why}, and {How} {Human}-{AI} {Interaction} {Is} {Uniquely} {Difficult} to {Design}},
	doi = {10.1145/3313831.3376301},
	abstract = {Artificial Intelligence (AI) plays an increasingly important role in improving HCI and user experience. Yet many challenges persist in designing and innovating valuable human-AI interactions. For example, AI systems can make unpredictable errors, and these errors damage UX and even lead to undesired societal impact. However, HCI routinely grapples with complex technologies and mitigates their unintended consequences. What makes AI different? What makes human-AI interaction appear particularly difficult to design? This paper investigates these questions. We synthesize prior research, our own design and research experience, and our observations when teaching human-AI interaction. We identify two sources of AI's distinctive design challenges: 1) uncertainty surrounding AI's capabilities, 2) AI's output complexity, spanning from simple to adaptive complex. We identify four levels of AI systems. On each level, designers encounter a different subset of the design challenges. We demonstrate how these findings reveal new insights for designers, researchers, and design tool makers in productively addressing the challenges of human-AI interaction going forward.},
	journal = {Conference on Human Factors in Computing Systems - Proceedings},
	author = {Yang, Qian and Steinfeld, Aaron and Rosé, Carolyn and Zimmerman, John},
	year = {2020},
	note = {ISBN: 9781450367080},
	keywords = {artificial intelligence, prototyping, sketching, user experience},
	pages = {1--13},
	file = {PDF:/Users/vsivaram/Zotero/storage/QDIPIF7K/3313831.3376301.pdf:application/pdf},
}


@article{Zytek2021,
	title = {Sibyl: {Understanding} and {Addressing} the {Usability} {Challenges} of {Machine} {Learning} {In} {High}-{Stakes} {Decision} {Making}},
	issn = {1077-2626},
	url = {http://arxiv.org/abs/2103.02071},
	doi = {10.1109/tvcg.2021.3114864},
	abstract = {Machine learning (ML) is being applied to a diverse and ever-growing set of domains. In many cases, domain experts - who often have no expertise in ML or data science - are asked to use ML predictions to make high-stakes decisions. Multiple ML usability challenges can appear as result, such as lack of user trust in the model, inability to reconcile human-ML disagreement, and ethical concerns about oversimplification of complex problems to a single algorithm output. In this paper, we investigate the ML usability challenges that present in the domain of child welfare screening through a series of collaborations with child welfare screeners. Following the iterative design process between the ML scientists, visualization researchers, and domain experts (child screeners), we first identified four key ML challenges and honed in on one promising explainable ML technique to address them (local factor contributions). Then we implemented and evaluated our visual analytics tool, Sibyl, to increase the interpretability and interactivity of local factor contributions. The effectiveness of our tool is demonstrated by two formal user studies with 12 non-expert participants and 13 expert participants respectively. Valuable feedback was collected, from which we composed a list of design implications as a useful guideline for researchers who aim to develop an interpretable and interactive visualization tool for ML prediction models deployed for child welfare screeners and other similar domain experts.},
	number = {Ml},
	author = {Zytek, Alexandra and Liu, Dongyu and Vaithianathan, Rhema and Veeramachaneni, Kalyan},
	year = {2021},
	note = {arXiv: 2103.02071},
	file = {PDF:/Users/vsivaram/Zotero/storage/Z4CSMDB8/v-full-1492.pdf:application/pdf},
}


@inproceedings{caruana_intelligible_2015,
	address = {Sydney NSW Australia},
	title = {Intelligible {Models} for {HealthCare}: {Predicting} {Pneumonia} {Risk} and {Hospital} 30-day {Readmission}},
	isbn = {978-1-4503-3664-2},
	shorttitle = {Intelligible {Models} for {HealthCare}},
	url = {https://dl.acm.org/doi/10.1145/2783258.2788613},
	doi = {10.1145/2783258.2788613},
	language = {en},
	urldate = {2024-03-04},
	booktitle = {Proceedings of the 21th {ACM} {SIGKDD} {International} {Conference} on {Knowledge} {Discovery} and {Data} {Mining}},
	publisher = {ACM},
	author = {Caruana, Rich and Lou, Yin and Gehrke, Johannes and Koch, Paul and Sturm, Marc and Elhadad, Noemie},
	month = aug,
	year = {2015},
	pages = {1721--1730},
	file = {Full Text PDF:/Users/vsivaram/Zotero/storage/3JWBC4BU/Caruana et al. - 2015 - Intelligible Models for HealthCare Predicting Pne.pdf:application/pdf},
}


@article{Sendak2020,
	title = {“{The} human body is a black box”: {Supporting} clinical decision-making with deep learning},
	doi = {10.1145/3351095.3372827},
	abstract = {Machine learning technologies are increasingly developed for use in healthcare. While research communities have focused on creating state-of-the-art models, there has been less focus on real world implementation and the associated challenges to fairness, transparency, and accountability that come from actual, situated use. Serious questions remain underexamined regarding how to ethically build models, interpret and explain model output, recognize and account for biases, and minimize disruptions to professional expertise and work cultures. We address this gap in the literature and provide a detailed case study covering the development, implementation, and evaluation of Sepsis Watch, a machine learning-driven tool that assists hospital clinicians in the early diagnosis and treatment of sepsis. Sepsis is a severe infection that can lead to organ failure or death if not treated in time and is the leading cause of inpatient deaths in US hospitals. We, the team that developed and evaluated the tool, discuss our conceptualization of the tool not as a model deployed in the world but instead as a socio-technical system requiring integration into existing social and professional contexts. Rather than focusing solely on model interpretability to ensure fair and accountable machine learning, we point toward four key values and practices that should be considered when developing machine learning to support clinical decision-making: rigorously define the problem in context, build relationships with stakeholders, respect professional discretion, and create ongoing feedback loops with stakeholders. Our work has significant implications for future research regarding mechanisms of institutional accountability and considerations for responsibly designing machine learning systems. Our work underscores the limits of model interpretability as a solution to ensure transparency, accuracy, and accountability in practice. Instead, our work demonstrates other means and goals to achieve FATML values in design and in practice.},
	journal = {FAT* 2020 - Proceedings of the 2020 Conference on Fairness, Accountability, and Transparency},
	author = {Sendak, Mark and Elish, Madeleine Clare and Gao, Michael and Futoma, Joseph and Ratliff, William and Nichols, Marshall and Bedoya, Armando and Balu, Suresh and O'Brien, Cara},
	year = {2020},
	note = {arXiv: 1911.08089
ISBN: 9781450369367},
	keywords = {trust, interpretability, acm reference format, deep learning, medicine, expertise, joseph futoma, madeleine elish, mark sendak, michael gao, william},
	pages = {99--109},
	file = {PDF:/Users/vsivaram/Zotero/storage/24F44S7H/1911.08089.pdf:application/pdf},
}


@article{allen_maintaining_1983,
	title = {Maintaining knowledge about temporal intervals},
	volume = {26},
	issn = {0001-0782, 1557-7317},
	url = {https://dl.acm.org/doi/10.1145/182.358434},
	doi = {10.1145/182.358434},
	abstract = {An interval-based temporal logic is introduced, together with a computationally effective reasoning algorithm based on constraint propagation. This system is notable in offering a delicate balance between expressive power and the efficiency of its deductive engine. A notion of reference intervals is introduced which captu{\textasciitilde}s the temporal hierarchy implicit in many domains, and which can be used to precisely control the amount of deduction performed automatically by the system. Examples are provided for a database containing historical data, a database used for modeling processes and proce{\textasciitilde} interaction, and a database for an interactive system where the present moment is continually being updated.},
	language = {en},
	number = {11},
	urldate = {2024-03-04},
	journal = {Communications of the ACM},
	author = {Allen, James F.},
	month = nov,
	year = {1983},
	pages = {832--843},
	file = {Allen - 1983 - Maintaining knowledge about temporal intervals.pdf:/Users/vsivaram/Zotero/storage/MJTAWZH9/Allen - 1983 - Maintaining knowledge about temporal intervals.pdf:application/pdf},
}

@inproceedings{jin_interactive_2010,
	title = {Interactive {Querying} of {Temporal} {Data} {Using} {A} {Comic} {Strip} {Metaphor}},
	abstract = {Finding patterns in temporal data is an important data analysis task in many domains. Static visualizations can help users easily see certain instances of patterns, but are not specially designed to support systematic analysis tasks, such as ﬁnding all instances of a pattern automatically. VizPattern is an interactive visual query environment that uses a comic strip metaphor to enable users to easily and quickly deﬁne and locate complex temporal patterns. Evaluations provide evidence that VizPattern is applicable in many domains, and that it enables a wide variety of users to answer questions about temporal data faster and with fewer errors than existing state-of-the-art visual analysis systems.},
	language = {en},
	author = {Jin, Jing and Szekely, Pedro},
	year = {2010},
	file = {Jin and Szekely - Interactive Querying of Temporal Data Using A Comi.pdf:/Users/vsivaram/Zotero/storage/YQQ4RF69/Jin and Szekely - Interactive Querying of Temporal Data Using A Comi.pdf:application/pdf},
}


@article{Hohman2019,
	title = {Visual {Analytics} in {Deep} {Learning}: {An} {Interrogative} {Survey} for the {Next} {Frontiers}},
	volume = {25},
	issn = {19410506},
	doi = {10.1109/TVCG.2018.2843369},
	abstract = {Deep learning has recently seen rapid development and received significant attention due to its state-of-the-art performance on previously-thought hard problems. However, because of the internal complexity and nonlinear structure of deep neural networks, the underlying decision making processes for why these models are achieving such performance are challenging and sometimes mystifying to interpret. As deep learning spreads across domains, it is of paramount importance that we equip users of deep learning with tools for understanding when a model works correctly, when it fails, and ultimately how to improve its performance. Standardized toolkits for building neural networks have helped democratize deep learning; visual analytics systems have now been developed to support model explanation, interpretation, debugging, and improvement. We present a survey of the role of visual analytics in deep learning research, which highlights its short yet impactful history and thoroughly summarizes the state-of-the-art using a human-centered interrogative framework, focusing on the Five W's and How (Why, Who, What, How, When, and Where). We conclude by highlighting research directions and open research problems. This survey helps researchers and practitioners in both visual analytics and deep learning to quickly learn key aspects of this young and rapidly growing body of research, whose impact spans a diverse range of domains.},
	number = {8},
	journal = {IEEE Transactions on Visualization and Computer Graphics},
	author = {Hohman, Fred and Kahng, Minsuk and Pienta, Robert and Chau, Duen Horng},
	year = {2019},
	note = {arXiv: 1801.06889},
	keywords = {Deep learning, visual analytics, neural networks, information visualization},
	pages = {2674--2693},
	file = {PDF:/Users/vsivaram/Zotero/storage/ZUAWF33X/sqBHVK-Visual_Analytics_in_Deep_Learning_An_Interrogative_Survey_for_the_Next_Frontiers.pdf:application/pdf},
}


@article{hohman_understanding_2020,
	title = {Understanding and {Visualizing} {Data} {Iteration} in {Machine} {Learning}},
	doi = {10.1145/3313831.3376177},
	abstract = {Successful machine learning (ML) applications require iterations on both modeling and the underlying data. While prior visualization tools for ML primarily focus on modeling, our interviews with 23 ML practitioners reveal that they improve model performance frequently by iterating on their data (e.g., collecting new data, adding labels) rather than their models. We also identify common types of data iterations and associated analysis tasks and challenges. To help attribute data iterations to model performance, we design a collection of interactive visualizations and integrate them into a prototype, Chameleon, that lets users compare data features, training/testing splits, and performance across data versions. We present two case studies where developers apply {\textbackslash}system to their own evolving datasets on production ML projects. Our interface helps them verify data collection efforts, find failure cases stretching across data versions, capture data processing changes that impacted performance, and identify opportunities for future data iterations.},
	journal = {Conference on Human Factors in Computing Systems - Proceedings},
	author = {Hohman, Fred and Wongsuphasawat, Kanit and Kery, Mary Beth and Patel, Kayur},
	year = {2020},
	note = {ISBN: 9781450367080},
	keywords = {visual analytics, data iteration, evolving datasets, interactive interfaces, machine learning iteration},
	pages = {1--13},
	file = {PDF:/Users/vsivaram/Zotero/storage/CGDHIHIZ/3313831.3376177.pdf:application/pdf},
}

@article{ono2020pipelineprofiler,
  title={Pipelineprofiler: A visual analytics tool for the exploration of automl pipelines},
  author={Ono, Jorge Piazentin and Castelo, Sonia and Lopez, Roque and Bertini, Enrico and Freire, Juliana and Silva, Claudio},
  journal={{IEEE} Transactions on Visualization and Computer Graphics},
  volume={27},
  number={2},
  pages={390--400},
  year={2020},
}


@article{sherman_leveraging_2018,
	title = {Leveraging {Clinical} {Time}-{Series} {Data} for {Prediction}: {A} {Cautionary} {Tale}},
	volume = {2017},
	issn = {1942-597X},
	shorttitle = {Leveraging {Clinical} {Time}-{Series} {Data} for {Prediction}},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5977714/},
	abstract = {In healthcare, patient risk stratification models are often learned using time-series data extracted from electronic health records. When extracting data for a clinical prediction task, several formulations exist, depending on how one chooses the time of prediction and the prediction horizon. In this paper, we show how the formulation can greatly impact both model performance and clinical utility. Leveraging a publicly available ICU dataset, we consider two clinical prediction tasks: in-hospital mortality, and hypokalemia. Through these case studies, we demonstrate the necessity of evaluating models using an outcome-independent reference point, since choosing the time of prediction relative to the event can result in unrealistic performance. Further, an outcome-independent scheme outperforms an outcome-dependent scheme on both tasks (In-Hospital Mortality AUROC .882 vs. .831; Serum Potassium: AUROC .829 vs. .740) when evaluated on test sets that mimic real-world use.},
	urldate = {2024-03-07},
	journal = {AMIA Annual Symposium Proceedings},
	author = {Sherman, Eli and Gurm, Hitinder and Balis, Ulysses and Owens, Scott and Wiens, Jenna},
	month = apr,
	year = {2018},
	pmid = {29854227},
	pmcid = {PMC5977714},
	pages = {1571--1580},
	file = {Full Text PDF:/Users/vsivaram/Zotero/storage/UZUL56WI/Sherman et al. - 2018 - Leveraging Clinical Time-Series Data for Predictio.pdf:application/pdf},
}


@article{epperson_dead_2023,
	title = {Dead or {Alive}: {Continuous} {Data} {Profiling} for {Interactive} {Data} {Science}},
	issn = {1077-2626, 1941-0506, 2160-9306},
	shorttitle = {Dead or {Alive}},
	url = {https://ieeexplore.ieee.org/document/10301695/},
	doi = {10.1109/TVCG.2023.3327367},
	abstract = {Profiling data by plotting distributions and analyzing summary statistics is a critical step throughout data analysis. Currently, this process is manual and tedious since analysts must write extra code to examine their data after every transformation. This inefficiency may lead to data scientists profiling their data infrequently, rather than after each transformation, making it easy for them to miss important errors or insights. We propose continuous data profiling as a process that allows analysts to immediately see interactive visual summaries of their data throughout their data analysis to facilitate fast and thorough analysis. Our system, AutoProfiler, presents three ways to support continuous data profiling: (1) it automatically displays data distributions and summary statistics to facilitate data comprehension; (2) it is live, so visualizations are always accessible and update automatically as the data updates; (3) it supports follow up analysis and documentation by authoring code for the user in the notebook. In a user study with 16 participants, we evaluate two versions of our system that integrate different levels of automation: both automatically show data profiles and facilitate code authoring, however, one version updates reactively (“live”) and the other updates only on demand (“dead”). We find that both tools, dead or alive, facilitate insight discovery with 91\% of user-generated insights originating from the tools rather than manual profiling code written by users. Participants found live updates intuitive and felt it helped them verify their transformations while those with on-demand profiles liked the ability to look at past visualizations. We also present a longitudinal case study on how AutoProfiler helped domain scientists find serendipitous insights about their data through automatic, live data profiles. Our results have implications for the design of future tools that offer automated data analysis support.},
	language = {en},
	urldate = {2024-03-11},
	journal = {IEEE Transactions on Visualization and Computer Graphics},
	author = {Epperson, Will and Gorantla, Vaishnavi and Moritz, Dominik and Perer, Adam},
	year = {2023},
	pages = {1--11},
	file = {Epperson et al. - 2023 - Dead or Alive Continuous Data Profiling for Inter.pdf:/Users/vsivaram/Zotero/storage/6V8GAN3H/Epperson et al. - 2023 - Dead or Alive Continuous Data Profiling for Inter.pdf:application/pdf},
}


@inproceedings{kandel_profiler_2012,
	address = {Capri Island Italy},
	title = {Profiler: integrated statistical analysis and visualization for data quality assessment},
	isbn = {978-1-4503-1287-5},
	shorttitle = {Profiler},
	url = {https://dl.acm.org/doi/10.1145/2254556.2254659},
	doi = {10.1145/2254556.2254659},
	abstract = {Data quality issues such as missing, erroneous, extreme and duplicate values undermine analysis and are time-consuming to ﬁnd and ﬁx. Automated methods can help identify anomalies, but determining what constitutes an error is context-dependent and so requires human judgment. While visualization tools can facilitate this process, analysts must often manually construct the necessary views, requiring signiﬁcant expertise. We present Proﬁler, a visual analysis tool for assessing quality issues in tabular data. Proﬁler applies data mining methods to automatically ﬂag problematic data and suggests coordinated summary visualizations for assessing the data in context. The system contributes novel methods for integrated statistical and visual analysis, automatic view suggestion, and scalable visual summaries that support real-time interaction with millions of data points. We present Proﬁler’s architecture — including modular components for custom data types, anomaly detection routines and summary visualizations — and describe its application to motion picture, natural disaster and water quality data sets.},
	language = {en},
	urldate = {2024-03-11},
	booktitle = {Proceedings of the {International} {Working} {Conference} on {Advanced} {Visual} {Interfaces}},
	publisher = {ACM},
	author = {Kandel, Sean and Parikh, Ravi and Paepcke, Andreas and Hellerstein, Joseph M. and Heer, Jeffrey},
	month = may,
	year = {2012},
	pages = {547--554},
	file = {Kandel et al. - 2012 - Profiler integrated statistical analysis and visu.pdf:/Users/vsivaram/Zotero/storage/ZCCPJMQL/Kandel et al. - 2012 - Profiler integrated statistical analysis and visu.pdf:application/pdf},
}


@inproceedings{chen_xgboost_2016,
	address = {New York, NY, USA},
	series = {{KDD} '16},
	title = {{XGBoost}: {A} {Scalable} {Tree} {Boosting} {System}},
	isbn = {978-1-4503-4232-2},
	shorttitle = {{XGBoost}},
	url = {https://dl.acm.org/doi/10.1145/2939672.2939785},
	doi = {10.1145/2939672.2939785},
	abstract = {Tree boosting is a highly effective and widely used machine learning method. In this paper, we describe a scalable end-to-end tree boosting system called XGBoost, which is used widely by data scientists to achieve state-of-the-art results on many machine learning challenges. We propose a novel sparsity-aware algorithm for sparse data and weighted quantile sketch for approximate tree learning. More importantly, we provide insights on cache access patterns, data compression and sharding to build a scalable tree boosting system. By combining these insights, XGBoost scales beyond billions of examples using far fewer resources than existing systems.},
	urldate = {2024-03-11},
	booktitle = {Proceedings of the 22nd {ACM} {SIGKDD} {International} {Conference} on {Knowledge} {Discovery} and {Data} {Mining}},
	publisher = {Association for Computing Machinery},
	author = {Chen, Tianqi and Guestrin, Carlos},
	month = aug,
	year = {2016},
	keywords = {large-scale machine learning},
	pages = {785--794},
	file = {Full Text PDF:/Users/vsivaram/Zotero/storage/2599FSNZ/Chen and Guestrin - 2016 - XGBoost A Scalable Tree Boosting System.pdf:application/pdf},
}


@article{pastor_looking_2021,
	title = {Looking for {Trouble}: {Analyzing} {Classifier} {Behavior} via {Pattern} {Divergence}},
	issn = {07308078},
	doi = {10.1145/3448016.3457284},
	abstract = {Machine learning models may perform differently on different data subgroups, which we represent as itemsets (i.e., conjunctions of simple predicates). The identification of these critical data subgroups plays an important role in many applications, for example model validation and testing, or evaluation of model fairness. Typically, domain expert help is required to identify relevant (or sensitive) subgroups. We propose the notion of divergence over itemsets as a measure of different classification behavior on data subgroups, and the use of frequent pattern mining techniques for their identification. A quantification of the contribution of different attribute values to divergence, based on the mathematical foundations provided by Shapley values, allows us to identify both critical and peculiar behaviors of attributes. Extended experiments show the effectiveness of the approach in identifying critical subgroup behaviors.},
	journal = {Proceedings of the ACM SIGMOD International Conference on Management of Data},
	author = {Pastor, Eliana and De Alfaro, Luca and Baralis, Elena},
	year = {2021},
	note = {ISBN: 9781450383431},
	keywords = {bias detection, classifier validation, fairness in machine learning, machine-learning model debugging, shapley value},
	pages = {1400--1412},
	file = {PDF:/Users/vsivaram/Zotero/storage/JQ4DSVG6/DivExplorer.pdf:application/pdf},
}


@inproceedings{holstein_improving_2019,
	address = {Glasgow Scotland Uk},
	title = {Improving {Fairness} in {Machine} {Learning} {Systems}: {What} {Do} {Industry} {Practitioners} {Need}?},
	isbn = {978-1-4503-5970-2},
	shorttitle = {Improving {Fairness} in {Machine} {Learning} {Systems}},
	url = {https://dl.acm.org/doi/10.1145/3290605.3300830},
	doi = {10.1145/3290605.3300830},
	language = {en},
	urldate = {2024-03-11},
	booktitle = {Proceedings of the 2019 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {ACM},
	author = {Holstein, Kenneth and Wortman Vaughan, Jennifer and Daumé, Hal and Dudik, Miro and Wallach, Hanna},
	month = may,
	year = {2019},
	pages = {1--16},
	file = {Full Text PDF:/Users/vsivaram/Zotero/storage/EJHTLMZ2/Holstein et al. - 2019 - Improving Fairness in Machine Learning Systems Wh.pdf:application/pdf},
}


@incollection{green_subgroup_2021,
	address = {Cambridge},
	title = {Subgroup {Analysis}: {Pitfalls}, {Promise}, and {Honesty}},
	isbn = {978-1-108-47850-2},
	shorttitle = {Subgroup {Analysis}},
	url = {https://www.cambridge.org/core/books/advances-in-experimental-political-science/subgroup-analysis-pitfalls-promise-and-honesty/0FA22B419390CA59E5F5D8C1BCA4F210},
	abstract = {Experiments often focus on recovering an average effect of a treatment on an outcome. A subgroup analysis involves identifying subgroups of observations for which the treatment is particularly efficacious or deleterious. Since these subgroups are not preregistered but instead discovered from the data, significant inferential issues emerge. We discuss methods for conduct honest inference on subgroups, meaning generating valid p-values and confidence intervals which account for the fact that the subgroups were not specified a priori. Central to this approach is the split-sample strategy, where half the data is used to identify effects and the other half to test them. After an intuitive and formal discussion of these issues, we provide simulation evidence and two examples illustrating these concepts in practice.},
	urldate = {2024-03-13},
	booktitle = {Advances in {Experimental} {Political} {Science}},
	publisher = {Cambridge University Press},
	author = {Ratkovic, Marc},
	editor = {Green, Donald P. and Druckman, James N.},
	year = {2021},
	doi = {10.1017/9781108777919.020},
	keywords = {causal inference, heterogeneous treatment effects, machine learning, split sample, subgroup analysis},
	pages = {271--288},
	file = {Full Text PDF:/Users/vsivaram/Zotero/storage/3WHQYJ75/Ratkovic - 2021 - Subgroup Analysis Pitfalls, Promise, and Honesty.pdf:application/pdf;Snapshot:/Users/vsivaram/Zotero/storage/23SRS3A4/0FA22B419390CA59E5F5D8C1BCA4F210.html:text/html},
}


@article{goeman_multiple_2011,
	title = {Multiple {Testing} for {Exploratory} {Research}},
	volume = {26},
	issn = {0883-4237},
	url = {https://projecteuclid.org/journals/statistical-science/volume-26/issue-4/Multiple-Testing-for-Exploratory-Research/10.1214/11-STS356.full},
	doi = {10.1214/11-STS356},
	abstract = {Motivated by the practice of exploratory research, we formulate an approach to multiple testing that reverses the conventional roles of the user and the multiple testing procedure. Traditionally, the user chooses the error criterion, and the procedure the resulting rejected set. Instead, we propose to let the user choose the rejected set freely, and to let the multiple testing procedure return a conﬁdence statement on the number of false rejections incurred. In our approach, such conﬁdence statements are simultaneous for all choices of the rejected set, so that post hoc selection of the rejected set does not compromise their validity. The proposed reversal of roles requires nothing more than a review of the familiar closed testing procedure, but with a focus on the non-consonant rejections that this procedure makes. We suggest several shortcuts to avoid the computational problems associated with closed testing.},
	language = {en},
	number = {4},
	urldate = {2024-03-14},
	journal = {Statistical Science},
	author = {Goeman, Jelle J. and Solari, Aldo},
	month = nov,
	year = {2011},
	file = {Goeman and Solari - 2011 - Multiple Testing for Exploratory Research.pdf:/Users/vsivaram/Zotero/storage/PHYNJNTM/Goeman and Solari - 2011 - Multiple Testing for Exploratory Research.pdf:application/pdf},
}


@article{perkel_why_2018,
	title = {Why {Jupyter} is data scientists’ computational notebook of choice},
	volume = {563},
	url = {https://www.nature.com/articles/d41586-018-07196-1},
	doi = {https://doi.org/10.1038/d41586-018-07196-1},
	urldate = {2024-03-14},
	journal = {Nature Toolbox},
	author = {Perkel, Jeffrey M.},
	month = oct,
	year = {2018},
	pages = {145--146},
	file = {Why Jupyter is data scientists’ computational notebook of choice:/Users/vsivaram/Zotero/storage/8SY746F6/d41586-018-07196-1.html:text/html},
}


@article{Komorowski2018,
	title = {The {Artificial} {Intelligence} {Clinician} learns optimal treatment strategies for sepsis in intensive care},
	volume = {24},
	issn = {1546170X},
	url = {http://dx.doi.org/10.1038/s41591-018-0213-5},
	doi = {10.1038/s41591-018-0213-5},
	abstract = {Sepsis is the third leading cause of death worldwide and the main cause of mortality in hospitals 1–3 , but the best treatment strategy remains uncertain. In particular, evidence suggests that current practices in the administration of intravenous fluids and vasopressors are suboptimal and likely induce harm in a proportion of patients 1,4–6 . To tackle this sequential decision-making problem, we developed a reinforcement learning agent, the Artificial Intelligence (AI) Clinician, which extracted implicit knowledge from an amount of patient data that exceeds by many-fold the life-time experience of human clinicians and learned optimal treatment by analyzing a myriad of (mostly suboptimal) treatment decisions. We demonstrate that the value of the AI Clinician’s selected treatment is on average reliably higher than human clinicians. In a large validation cohort independent of the training data, mortality was lowest in patients for whom clinicians’ actual doses matched the AI decisions. Our model provides individualized and clinically interpretable treatment decisions for sepsis that could improve patient outcomes.},
	number = {11},
	journal = {Nature Medicine},
	author = {Komorowski, Matthieu and Celi, Leo A. and Badawi, Omar and Gordon, Anthony C. and Faisal, A. Aldo},
	year = {2018},
	pmid = {30349085},
	note = {arXiv: 1902.03271
Publisher: Springer US},
	pages = {1716--1720},
	file = {PDF:/Users/vsivaram/Zotero/storage/4XAMZ9AE/s41591-018-0213-5.pdf:application/pdf},
}


@book{snodgrass_tsql2_2012,
	title = {The {TSQL2} {Temporal} {Query} {Language}},
	isbn = {978-1-4615-2289-8},
	abstract = {Temporal databases have been an active research topic for at least fifteen years. During this time, several dozen temporal query languages have been proposed. Many within the temporal database research community perceived that the time had come to consolidate approaches to temporal data models and calculus based query languages, to achieve a consensus query language and associated data model upon which future research can be based. While there were many query language proposals, with a diversity of language and modeling constructs, common themes kept resurfacing. However, the community was quite frag mented, with each research project being based on a particular and different set of assumptions and approaches. Often these assumptions were not germane to the research per se, but were made simply because the research required a data model or query language with certain characteristics, with the partic ular one chosen rather arbitrarily. It would be better in such circumstances for research projects to choose the same language. Unfortunately, no existing language had attracted a following large enough to become the one of choice. In April, 1992 Richard Snodgrass circulated a white paper that proposed that a temporal extension to SQL be produced by the research community. Shortly thereafter, the temporal database community organized the "ARPA/NSF In ternational Workshop on an Infrastructure for Temporal Databases," which was held in Arlington, TX, in June, 1993.},
	language = {en},
	publisher = {Springer Science \& Business Media},
	author = {Snodgrass, Richard T.},
	month = dec,
	year = {2012},
	note = {Google-Books-ID: eEnVBwAAQBAJ},
	keywords = {Computers / Information Technology, Computers / Information Theory, Computers / Programming / Algorithms},
}

@inproceedings{bry_high-level_2006,
	address = {Chicago, IL, USA},
	title = {A {High}-{Level} {Query} {Language} for {Events}},
	isbn = {978-0-7695-2681-2},
	url = {http://ieeexplore.ieee.org/document/4027010/},
	doi = {10.1109/SCW.2006.2},
	abstract = {Nowadays events are omnipresent and exchanged as messages over networks. Characteristic for applications involving advanced (or complex) event processing is the need to (1) utilize data contained in the events, (2) detect patterns made up of multiple events (so-called composite events), (3) reason about temporal and causal relationships of events, (4) accumulate events for negation and data aggregation.},
	language = {en},
	urldate = {2024-03-25},
	booktitle = {2006 {IEEE} {Services} {Computing} {Workshops}},
	publisher = {IEEE},
	author = {Bry, Francois and Eckert, Michael},
	month = sep,
	year = {2006},
	pages = {31--38},
	file = {Bry and Eckert - 2006 - A High-Level Query Language for Events.pdf:/Users/vsivaram/Zotero/storage/LG5LWINN/Bry and Eckert - 2006 - A High-Level Query Language for Events.pdf:application/pdf},
}

@inproceedings{bai_rfid_2007,
	address = {Istanbul, Turkey},
	title = {{RFID} {Data} {Processing} with a {Data} {Stream} {Query} {Language}},
	isbn = {978-1-4244-0802-3},
	url = {http://ieeexplore.ieee.org/document/4221767/},
	doi = {10.1109/ICDE.2007.368977},
	abstract = {RFID technology provides significant advantages over traditional object-tracking technologies and is increasingly adopted and deployed in real applications. RFID applications generate large volume of streaming data, which have to be automatically filtered, processed, and transformed into semantic data, and integrated into business applications. Indeed, RFID data are highly temporal, and RFID observations form complex temporal event patterns which can be very differentfor various RFID applications. Thus, it is desirable to have a general RFID data processing framework with a powerful language, for the end users to express a variety of queries on RFID data streams, as well as detecting complex events patterns. While data stream management systems (DSMSs) are emerging for optimized stream data processing, they usually lack the language construct support for temporal event detection. In this paper; we discuss a stream query language to provide comprehensive temporal event detection, through temporal operators and extension of sliding-window constructs. With the integration of temporal event detection, a DSMS has the capability to serve as a powerful system for RFID data processing.},
	language = {en},
	urldate = {2024-03-25},
	booktitle = {2007 {IEEE} 23rd {International} {Conference} on {Data} {Engineering}},
	publisher = {IEEE},
	author = {Bai, Yijian and Wang, Fusheng and Liu, Peiya and Zaniolo, Carlo and Liu, Shaorong},
	year = {2007},
	pages = {1184--1193},
	file = {Bai et al. - 2007 - RFID Data Processing with a Data Stream Query Lang.pdf:/Users/vsivaram/Zotero/storage/IA2KR8JU/Bai et al. - 2007 - RFID Data Processing with a Data Stream Query Lang.pdf:application/pdf},
}

@book{rozsnyai_sari-sql_2009,
	title = {{SARI}-{SQL}: {Event} query language for event analysis},
	shorttitle = {{SARI}-{SQL}},
	abstract = {Complex event processing (CEP) systems are capable of processing large amounts of events, utilizing them to monitor, steer and optimize business in real time. The lack of tracking events and maintaining the causal relationships and traceability between those events, as well as aggregating them to higher-level events, is a problem that is currently investigated by many research groups. In this paper, we present SARI-SQL, which is a domain-specific event-query language, (EQL) that is designed for business analysts to easily gain insight into business events. SARI-SQL enables the retrieval of near real-time events and can process historical events, metrics and scores for analytical purposes. We introduce the SARI-SQL syntax and show infrastructural components for the query engine. We further show examples to illustrate the query language, and propose a reference implementation for the query engine.},
	author = {Rozsnyai, Szabolcs and Schiefer, Josef and Roth, Heinz},
	month = jul,
	year = {2009},
	doi = {10.1109/CEC.2009.14},
	note = {Journal Abbreviation: 2009 IEEE Conference on Commerce and Enterprise Computing, CEC 2009
Pages: 32
Publication Title: 2009 IEEE Conference on Commerce and Enterprise Computing, CEC 2009},
	file = {Full Text PDF:/Users/vsivaram/Zotero/storage/NCZK5AUB/Rozsnyai et al. - 2009 - SARI-SQL Event query language for event analysis.pdf:application/pdf},
}

@inproceedings{bohlen_how_2006,
	address = {Budapest, Hungary},
	title = {How {Would} {You} {Like} to {Aggregate} {Your} {Temporal} {Data}?},
	isbn = {978-0-7695-2617-1},
	url = {http://ieeexplore.ieee.org/document/1635990/},
	doi = {10.1109/TIME.2006.17},
	abstract = {Real-world data management applications generally manage temporal data, i.e., they manage multiple states of time-varying data. Many contributions have been made by the research community for how to better model, store, and query temporal data. In particular, several dozen temporal data models and query languages have been proposed.},
	language = {en},
	urldate = {2024-03-25},
	booktitle = {Thirteenth {International} {Symposium} on {Temporal} {Representation} and {Reasoning} ({TIME}'06)},
	publisher = {IEEE},
	author = {Bohlen, M.H. and Gamper, J. and Jensen, C.S.},
	year = {2006},
	pages = {121--136},
	file = {Bohlen et al. - 2006 - How Would You Like to Aggregate Your Temporal Data.pdf:/Users/vsivaram/Zotero/storage/CCN6FZP9/Bohlen et al. - 2006 - How Would You Like to Aggregate Your Temporal Data.pdf:application/pdf},
}


@misc{wolf_introducing_2019,
	title = {Introducing {Event} {Query} {Language}},
    note = {\url{https://www.elastic.co/blog/introducing-event-query-language}},
	url = {https://www.elastic.co/blog/introducing-event-query-language},
	abstract = {Adversarial activity is no longer described purely in terms of static Indicators of Compromise (IOCs). Focusing solely on IOCs leads to detections which are brittle and ineffective at discovering unkn...},
	language = {en-us},
	urldate = {2024-03-25},
	journal = {Elastic Blog},
	author = {Wolf, Ross},
	month = jun,
	year = {2019},
	file = {Snapshot:/Users/vsivaram/Zotero/storage/8XRSHTNI/introducing-event-query-language.html:text/html},
}


@misc{timescale,
	title = {Timescale {Docs}},
	url = {https://docs.timescale.com/},
note = {\url{https://docs.timescale.com/}},
	abstract = {Time-series data simplified {\textbar} Timescale},
	language = {en},
	urldate = {2024-03-25},
	author = {Timescale},
	file = {Snapshot:/Users/vsivaram/Zotero/storage/6BZFISHK/docs.timescale.com.html:text/html},
}


@misc{prometheus,
	title = {Querying basics {\textbar} {Prometheus}},
    note = {\url{https://prometheus.io/docs/prometheus/latest/querying/basics/}},
	url = {https://prometheus.io/docs/prometheus/latest/querying/basics/},
	abstract = {An open-source monitoring system with a dimensional data model, flexible query language, efficient time series database and modern alerting approach.},
	language = {en},
	urldate = {2024-03-25},
	author = {Prometheus},
	file = {Snapshot:/Users/vsivaram/Zotero/storage/LIU6M9CW/basics.html:text/html},
}

@misc{opentsdb,
	title = {{OpenTSDB} - {A} {Distributed}, {Scalable} {Monitoring} {System}},
	url = {http://opentsdb.net/},
	urldate = {2024-03-25},
	author = {OpenTSDB Authors},
	file = {OpenTSDB - A Distributed, Scalable Monitoring System:/Users/vsivaram/Zotero/storage/FYS7F476/opentsdb.net.html:text/html},
}


@article{sivaraman_emblaze_2022,
	title = {Emblaze: {Illuminating} {Machine} {Learning} {Representations} through {Interactive} {Comparison} of {Embedding} {Spaces}},
	doi = {10.1145/3490099.3511137},
	abstract = {Modern machine learning techniques commonly rely on complex, high-dimensional embedding representations to capture underlying structure in the data and improve performance. In order to characterize model flaws and choose a desirable representation, model builders often need to compare across multiple embedding spaces, a challenging analytical task supported by few existing tools. We first interviewed nine embedding experts in a variety of fields to characterize the diverse challenges they face and techniques they use when analyzing embedding spaces. Informed by these perspectives, we developed a novel system called Emblaze that integrates embedding space comparison within a computational notebook environment. Emblaze uses an animated, interactive scatter plot with a novel Star Trail augmentation to enable visual comparison. It also employs novel neighborhood analysis and clustering procedures to dynamically suggest groups of points with interesting changes between spaces. Through a series of case studies with ML experts, we demonstrate how interactive comparison with Emblaze can help gain new insights into embedding space structure.},
	journal = {International Conference on Intelligent User Interfaces, Proceedings IUI},
	author = {Sivaraman, Venkatesh and Wu, Yiwei and Perer, Adam},
	year = {2022},
	note = {arXiv: 2202.02641
ISBN: 9781450391443},
	keywords = {visualization, dimensionality reduction, machine learning, animation, embedding space comparison},
	pages = {418--432},
	file = {PDF:/Users/vsivaram/Zotero/storage/DRUIY3ZB/3490099.3511137.pdf:application/pdf},
}


@inproceedings{hohman_gamut_2019,
	address = {New York, NY, USA},
	series = {{CHI} '19},
	title = {Gamut: {A} {Design} {Probe} to {Understand} {How} {Data} {Scientists} {Understand} {Machine} {Learning} {Models}},
	isbn = {978-1-4503-5970-2},
	shorttitle = {Gamut},
	url = {https://dl.acm.org/doi/10.1145/3290605.3300809},
	doi = {10.1145/3290605.3300809},
	abstract = {Without good models and the right tools to interpret them, data scientists risk making decisions based on hidden biases, spurious correlations, and false generalizations. This has led to a rallying cry for model interpretability. Yet the concept of interpretability remains nebulous, such that researchers and tool designers lack actionable guidelines for how to incorporate interpretability into models and accompanying tools. Through an iterative design process with expert machine learning researchers and practitioners, we designed a visual analytics system, Gamut, to explore how interactive interfaces could better support model interpretation. Using Gamut as a probe, we investigated why and how professional data scientists interpret models, and how interface affordances can support data scientists in answering questions about model interpretability. Our investigation showed that interpretability is not a monolithic concept: data scientists have different reasons to interpret models and tailor explanations for specific audiences, often balancing competing concerns of simplicity and completeness. Participants also asked to use Gamut in their work, highlighting its potential to help data scientists understand their own data.},
	urldate = {2024-03-25},
	booktitle = {Proceedings of the 2019 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Hohman, Fred and Head, Andrew and Caruana, Rich and DeLine, Robert and Drucker, Steven M.},
	month = may,
	year = {2019},
	keywords = {data visualization, design probe, interactive interfaces, machine learning interpretability, visual analytics},
	pages = {1--13},
	file = {Full Text PDF:/Users/vsivaram/Zotero/storage/ZFLNQ7HB/Hohman et al. - 2019 - Gamut A Design Probe to Understand How Data Scien.pdf:application/pdf},
}


@misc{CentersforDiseaseControlandPrevention2021,
	title = {What is sepsis?},
	author = {{Centers for Disease Control and Prevention}},
	year = {2021},
}


@misc{johnson2020mimic,
	title = {{MIMIC}-{IV} (version 1.0)},
	publisher = {PhysioNet},
	author = {Johnson, A and Bulgarelli, L and Pollard, T and Horng, S and Celi, L A and Mark, R},
	year = {2020},
}


@article{herrera_overview_2011,
	title = {An overview on subgroup discovery: foundations and applications},
	volume = {29},
	copyright = {http://www.springer.com/tdm},
	issn = {0219-1377, 0219-3116},
	shorttitle = {An overview on subgroup discovery},
	url = {http://link.springer.com/10.1007/s10115-010-0356-2},
	doi = {10.1007/s10115-010-0356-2},
	abstract = {Subgroup discovery is a data mining technique which extracts interesting rules with respect to a target variable. An important characteristic of this task is the combination of predictive and descriptive induction. An overview related to the task of subgroup discovery is presented. This review focuses on the foundations, algorithms, and advanced studies together with the applications of subgroup discovery presented throughout the specialised bibliography.},
	language = {en},
	number = {3},
	urldate = {2024-03-29},
	journal = {Knowledge and Information Systems},
	author = {Herrera, Franciso and Carmona, Cristóbal José and González, Pedro and Del Jesus, María José},
	month = dec,
	year = {2011},
	pages = {495--525},
	file = {Herrera et al. - 2011 - An overview on subgroup discovery foundations and.pdf:/Users/vsivaram/Zotero/storage/XY7BGE75/Herrera et al. - 2011 - An overview on subgroup discovery foundations and.pdf:application/pdf},
}


@inproceedings{lam_model_2023,
	address = {Hamburg Germany},
	title = {Model {Sketching}: {Centering} {Concepts} in {Early}-{Stage} {Machine} {Learning} {Model} {Design}},
	isbn = {978-1-4503-9421-5},
	shorttitle = {Model {Sketching}},
	url = {https://dl.acm.org/doi/10.1145/3544548.3581290},
	doi = {10.1145/3544548.3581290},
	language = {en},
	urldate = {2024-07-02},
	booktitle = {Proceedings of the 2023 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {ACM},
	author = {Lam, Michelle S. and Ma, Zixian and Li, Anne and Freitas, Izequiel and Wang, Dakuo and Landay, James A. and Bernstein, Michael S.},
	month = apr,
	year = {2023},
	pages = {1--24},
	file = {Full Text PDF:/Users/vsivaram/Zotero/storage/5P5GNNLI/Lam et al. - 2023 - Model Sketching Centering Concepts in Early-Stage.pdf:application/pdf},
}

@incollection{van_kuijk_preparing_2019,
	address = {Cham (CH)},
	title = {Preparing {Data} for {Predictive} {Modelling}},
	copyright = {Copyright 2019, The Author(s).},
	isbn = {978-3-319-99712-4 978-3-319-99713-1},
	url = {http://www.ncbi.nlm.nih.gov/books/NBK543522/},
	abstract = {This is the first chapter of five that cover an introduction to developing and validating models for predicting outcomes for the individual patient. Such prediction models can be used for predicting the occurrence or recurrence of an event, or of the most likely value on a continuous outcome. We will mainly focus on the prediction of binary outcomes, such as the occurrence of a complication, recurrence of disease, the presence of metastases, remission, survival, etc. This chapter deals with the selection of an appropriate study design for a study on prediction, and on methods to manipulate the data before the statistical modelling can begin.},
	language = {eng},
	urldate = {2024-08-09},
	booktitle = {Fundamentals of {Clinical} {Data} {Science}},
	publisher = {Springer},
	author = {van Kuijk, Sander M. J. and Dankers, Frank J. W. M. and Traverso, Alberto and Wee, Leonard},
	editor = {Kubben, Pieter and Dumontier, Michel and Dekker, Andre},
	year = {2019},
	pmid = {31314242},
	file = {Printable HTML:/Users/vsivaram/Zotero/storage/662TDTTN/NBK543522.html:text/html},
}

@article{labarere_how_2014,
	title = {How to derive and validate clinical prediction models for use in intensive care medicine},
	volume = {40},
	issn = {1432-1238},
	url = {https://doi.org/10.1007/s00134-014-3227-6},
	doi = {10.1007/s00134-014-3227-6},
	abstract = {Clinical prediction models are formal combinations of historical, physical examination and laboratory or radiographic test data elements designed to accurately estimate the probability that a specific illness is present (diagnostic model), will respond to a form of treatment (therapeutic model) or will have a well-defined outcome (prognostic model) in an individual patient. They are derived and validated using empirical data and used to assist physicians in their clinical decision-making that requires a quantitative assessment of diagnostic, therapeutic or prognostic probabilities at the bedside.},
	language = {en},
	number = {4},
	urldate = {2024-08-09},
	journal = {Intensive Care Medicine},
	author = {Labarère, José and Bertrand, Renaud and Fine, Michael J.},
	month = apr,
	year = {2014},
	keywords = {Clinical decision rule, Clinical prediction models, Intensive care, Prognosis, Severity of illness index},
	pages = {513--527},
	file = {Full Text PDF:/Users/vsivaram/Zotero/storage/BB39KI2D/Labarère et al. - 2014 - How to derive and validate clinical prediction mod.pdf:application/pdf},
}

@article{neff_critique_2017,
	title = {Critique and {Contribute}: {A} {Practice}-{Based} {Framework} for {Improving} {Critical} {Data} {Studies} and {Data} {Science}},
	volume = {5},
	issn = {2167-6461},
	shorttitle = {Critique and {Contribute}},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5515123/},
	doi = {10.1089/big.2016.0050},
	abstract = {What would data science look like if its key critics were engaged to help improve it, and how might critiques of data science improve with an approach that considers the day-to-day practices of data science? This article argues for scholars to bridge the conversations that seek to critique data science and those that seek to advance data science practice to identify and create the social and organizational arrangements necessary for a more ethical data science. We summarize four critiques that are commonly made in critical data studies: data are inherently interpretive, data are inextricable from context, data are mediated through the sociomaterial arrangements that produce them, and data serve as a medium for the negotiation and communication of values. We present qualitative research with academic data scientists, “data for good” projects, and specialized cross-disciplinary engineering teams to show evidence of these critiques in the day-to-day experience of data scientists as they acknowledge and grapple with the complexities of their work. Using ethnographic vignettes from two large multiresearcher field sites, we develop a set of concepts for analyzing and advancing the practice of data science and improving critical data studies, including (1) communication is central to the data science endeavor; (2) making sense of data is a collective process; (3) data are starting, not end points, and (4) data are sets of stories. We conclude with two calls to action for researchers and practitioners in data science and critical data studies alike. First, creating opportunities for bringing social scientific and humanistic expertise into data science practice simultaneously will advance both data science and critical data studies. Second, practitioners should leverage the insights from critical data studies to build new kinds of organizational arrangements, which we argue will help advance a more ethical data science. Engaging the insights of critical data studies will improve data science. Careful attention to the practices of data science will improve scholarly critiques. Genuine collaborative conversations between these different communities will help push for more ethical, and better, ways of knowing in increasingly datum-saturated societies.},
	number = {2},
	urldate = {2024-08-09},
	journal = {Big Data},
	author = {Neff, Gina and Tanweer, Anissa and Fiore-Gartland, Brittany and Osburn, Laura},
	month = jun,
	year = {2017},
	pmid = {28632445},
	pmcid = {PMC5515123},
	pages = {85--97},
	annote = {TO READ
},
	file = {Full Text PDF:/Users/vsivaram/Zotero/storage/79I7FIV5/Neff et al. - 2017 - Critique and Contribute A Practice-Based Framewor.pdf:application/pdf},
}

@article{passi_trust_2018,
	title = {Trust in {Data} {Science}: {Collaboration}, {Translation}, and {Accountability} in {Corporate} {Data} {Science} {Projects}},
	volume = {2},
	issn = {2573-0142},
	shorttitle = {Trust in {Data} {Science}},
	url = {https://dl.acm.org/doi/10.1145/3274405},
	doi = {10.1145/3274405},
	abstract = {The trustworthiness of data science systems in applied and real-world settings emerges from the resolution of specific tensions through situated, pragmatic, and ongoing forms of work. Drawing on research in CSCW, critical data studies, and history and sociology of science, and six months of immersive ethnographic fieldwork with a corporate data science team, we describe four common tensions in applied data science work: (un)equivocal numbers, (counter)intuitive knowledge, (in)credible data, and (in)scrutable models. We show how organizational actors establish and re-negotiate trust under messy and uncertain analytic conditions through practices of skepticism, assessment, and credibility. Highlighting the collaborative and heterogeneous nature of real-world data science, we show how the management of trust in applied corporate data science settings depends not only on pre-processing and quantification, but also on negotiation and translation. We conclude by discussing the implications of our findings for data science research and practice, both within and beyond CSCW.},
	language = {en},
	number = {CSCW},
	urldate = {2024-08-09},
	journal = {Proceedings of the ACM on Human-Computer Interaction},
	author = {Passi, Samir and Jackson, Steven J.},
	month = nov,
	year = {2018},
	pages = {1--28},
	annote = {TO READ

},
	file = {Full Text PDF:/Users/vsivaram/Zotero/storage/RIPAPYQA/Passi and Jackson - 2018 - Trust in Data Science Collaboration, Translation,.pdf:application/pdf},
}

@article{schrock_what_2017,
	title = {What {Communication} {Can} {Contribute} to {Data} {Studies}: {Three} {Lenses} on {Communication} and {Data}},
	abstract = {We are awash in predictions about our data-driven future. Enthusiasts believe big data imposes new ways of knowing, while critics worry it will enable powerful regimes of institutional control. This debate has been of keen interest to communication scholars. To encourage conceptual clarity, this article draws on communication scholarship to suggest three lenses for data epistemologies. I review the common social scientific perspective of communication as data. A data as discourse lens interrogates the meanings that data carries. Communication around data describes moments where data are constructed. By employing multiple perspectives, we might understand how data operate as a complex structure of dominance.},
	language = {en},
	author = {Schrock, Andrew},
	year = {2017},
	file = {Schrock - 2017 - What Communication Can Contribute to Data Studies.pdf:/Users/vsivaram/Zotero/storage/TKGZ5A29/Schrock - 2017 - What Communication Can Contribute to Data Studies.pdf:application/pdf},
}

@article{moats_you_2019,
	title = {“{You} {Social} {Scientists} {Love} {Mind} {Games}”: {Experimenting} in the “divide” between data science and critical algorithm studies},
	volume = {6},
	issn = {2053-9517},
	shorttitle = {“{You} {Social} {Scientists} {Love} {Mind} {Games}”},
	url = {https://doi.org/10.1177/2053951719833404},
	doi = {10.1177/2053951719833404},
	abstract = {In recent years, many qualitative sociologists, anthropologists, and social theorists have critiqued the use of algorithms and other automated processes involved in data science on both epistemological and political grounds. Yet, it has proven difficult to bring these important insights into the practice of data science itself. We suggest that part of this problem has to do with under-examined or unacknowledged assumptions about the relationship between the two fields?ideas about how data science and its critics can and should relate. Inspired by recent work in Science and Technology Studies on interventions, we attempted to stage an encounter in which practicing data scientists were asked to analyze a corpus of critical social science literature about their work, using tools of textual analysis such as co-word and topic modelling. The idea was to provoke discussion both about the content of these texts and the possible limits of such analyses. In this commentary, we reflect on the planning stages of the experiment and how responses to the exercise, from both data scientists and qualitative social scientists, revealed some of the tensions and interactions between the normative positions of the different fields. We argue for further studies which can help us understand what these interdisciplinary tensions turn on?which do not paper over them but also do not take them as given.},
	number = {1},
	urldate = {2024-08-09},
	journal = {Big Data \& Society},
	author = {Moats, David and Seaver, Nick},
	month = jan,
	year = {2019},
	note = {Publisher: SAGE Publications Ltd},
	pages = {2053951719833404},
	file = {Full Text PDF:/Users/vsivaram/Zotero/storage/NKXV6CH6/Moats and Seaver - 2019 - “You Social Scientists Love Mind Games” Experimen.pdf:application/pdf},
}

@article{grimmer_we_2015,
	title = {We {Are} {All} {Social} {Scientists} {Now}: {How} {Big} {Data}, {Machine} {Learning}, and {Causal} {Inference} {Work} {Together}},
	volume = {48},
	issn = {1049-0965, 1537-5935},
	shorttitle = {We {Are} {All} {Social} {Scientists} {Now}},
	url = {http://www.journals.cambridge.org/abstract_S1049096514001784},
	doi = {10.1017/S1049096514001784},
	abstract = {Clinton and Jackman 2009; Patty and Penn 2015). Extensive validations suggest, however, that the measures are capturing variation in legislators’ expressed ideology (Clinton, Jackman, and Rivers 2004; Poole 1984; Poole and Rosenthal 1985; 1997).},
	language = {en},
	number = {01},
	urldate = {2024-08-11},
	journal = {PS: Political Science \& Politics},
	author = {Grimmer, Justin},
	month = jan,
	year = {2015},
	pages = {80--83},
	file = {Grimmer - 2015 - We Are All Social Scientists Now How Big Data, Ma.pdf:/Users/vsivaram/Zotero/storage/79LYDYQM/Grimmer - 2015 - We Are All Social Scientists Now How Big Data, Ma.pdf:application/pdf},
}

@article{van_den_broek_when_2021,
	title = {When the {Machine} {Meets} the {Expert}: {An} {Ethnography} of {Developing} {Ai} for {Hiring}},
	volume = {45},
	issn = {02767783},
	shorttitle = {When the {Machine} {Meets} the {Expert}},
	url = {https://search.ebscohost.com/login.aspx?direct=true&AuthType=ip,sso&db=buh&AN=152360587&site=ehost-live&scope=site&custid=s8368349},
	doi = {10.25300/MISQ/2021/16559},
	abstract = {The introduction of machine learning (ML) in organizations comes with the claim that algorithms will produce insights superior to those of experts by discovering the "truth" from data. Such a claim gives rise to a tension between the need to produce knowledge independent of domain experts and the need to remain relevant to the domain the system serves. This two-year ethnographic study focuses on how developers managed this tension when building an ML system to support the process of hiring job candidates at a large international organization. Despite the initial goal of getting domain experts "out the loop," we found that developers and experts arrived at a new hybrid practice that relied on a combination of ML and domain expertise. We explain this outcome as resulting from a process of mutual learning in which deep engagement with the technology triggered actors to reflect on how they produced knowledge. These reflections prompted the developers to iterate between excluding domain expertise from the ML system and including it. Contrary to common views that imply an opposition between ML and domain expertise, our study foregrounds their interdependence and as such shows the dialectic nature of developing ML. We discuss the theoretical implications of these findings for the literature on information technologies and knowledge work, information system development and implementation, and human-ML hybrids.},
	number = {3},
	urldate = {2024-08-12},
	journal = {MIS Quarterly},
	author = {van den Broek, Elmira and Sergeeva, Anastasia and Huysman, Marleen},
	month = sep,
	year = {2021},
	note = {Publisher: MIS Quarterly},
	keywords = {artificial intelligence, ARTIFICIAL intelligence in business, EMPLOYEE selection, ethnography, EXPERTISE, hiring, human resources, HUMAN-artificial intelligence interaction, human-ML hybrids, information system development, knowledge production, knowledge work, learning algorithms, Machine learning, MACHINE learning, mutual learning},
	pages = {1557--1580},
	file = {EBSCO Full Text:/Users/vsivaram/Zotero/storage/RERBM3LH/van den Broek et al. - 2021 - When the Machine Meets the Expert An Ethnography .pdf:application/pdf},
}

@article{university_of_helsinki_high_2019,
	title = {High {Reliability} in {Digital} {Organizing}: {Mindlessness}, the {Frame} {Problem}, and {Digital} {Operations}},
	volume = {43},
	issn = {02767783, 21629730},
	shorttitle = {High {Reliability} in {Digital} {Organizing}},
	url = {https://misq.org/high-reliability-in-digital-organizing-mindlessness-the-frame-problem-and-digital-operatoins.html},
	doi = {10.25300/MISQ/2019/14577},
	language = {en},
	number = {2},
	urldate = {2024-08-12},
	journal = {MIS Quarterly},
	author = {{University of Helsinki} and Salovaara, Antti and Lyytinen, Kalle and {Case Western Reserve University} and Penttinen, Esko and {Aalto University}},
	month = jan,
	year = {2019},
	pages = {555--578},
	file = {University of Helsinki et al. - 2019 - High Reliability in Digital Organizing Mindlessne.pdf:/Users/vsivaram/Zotero/storage/I8H2HLHB/University of Helsinki et al. - 2019 - High Reliability in Digital Organizing Mindlessne.pdf:application/pdf},
}

@article{gallagher_reframing_2007,
	title = {Reframing {Information} {System} {Design} as {Learning} {Across} {Communities} of {Practice}},
	abstract = {This article frames the requirements definition phase of systems design as a problem of knowledge transfer and learning between two communities of practice: IS designers and system users. The theoretical basis for the proposed approach is Wenger’s (1998) framework for social learning, which involves three dimensions: alignment, imagination, and engagement. The article treats the requirements definition task in systems design as a set of activities involving mutual learning and knowledge transfer between two communities of practice (CoP) along these three dimensions. In taking this approach, the article maps the results of past research on the systems design process onto this CoP framework and illustrates that the proposed framework encompasses the same activities used by traditional methods of requirements definition. However, this approach focuses attention on the learning that must take place between the two CoPs and thereby helps resolve some of the inherent shortcomings of prior efforts and approaches. The framework provides both a more encompassing conceptual lens for research on improving the requirements definition task and practical guidance for managers who are charged with a systems design project.},
	language = {en},
	journal = {International Journal of Technology and Human Interaction},
	author = {Gallagher, Kevin and Mason, Robert M},
	year = {2007},
	file = {Gallagher and Mason - 2007 - reframing Information System design as learning Ac.pdf:/Users/vsivaram/Zotero/storage/56UUEZR7/Gallagher and Mason - 2007 - reframing Information System design as learning Ac.pdf:application/pdf},
}

@article{ramesh_agile_2010,
	title = {Agile requirements engineering practices and challenges: an empirical study},
	volume = {20},
	copyright = {http://onlinelibrary.wiley.com/termsAndConditions\#vor},
	issn = {1350-1917, 1365-2575},
	shorttitle = {Agile requirements engineering practices and challenges},
	url = {https://onlinelibrary.wiley.com/doi/10.1111/j.1365-2575.2007.00259.x},
	doi = {10.1111/j.1365-2575.2007.00259.x},
	abstract = {This paper describes empirical research into agile requirements engineering (RE) practices. Based on an analysis of data collected in 16 US software development organizations, we identify six agile practices. We also identify seven challenges that are created by the use of these practices. We further analyse how this collection of practices helps mitigate some, while exacerbating other risks in RE. We provide a framework for evaluating the impact and appropriateness of agile RE practices by relating them to RE risks. Two risks that are intractable by agile RE practices emerge from the analysis. First, problems with customer inability and a lack of concurrence among customers signiﬁcantly impact agile development. Second, risks associated with the neglecting non-functional requirements such as security and scalability are a serious concern. Developers should carefully evaluate the risk factors in their project environment to understand whether the beneﬁts of agile RE practices outweigh the costs imposed by the challenges.},
	language = {en},
	number = {5},
	urldate = {2024-08-12},
	journal = {Information Systems Journal},
	author = {Ramesh, Balasubramaniam and Cao, Lan and Baskerville, Richard},
	month = sep,
	year = {2010},
	pages = {449--480},
	file = {Ramesh et al. - 2010 - Agile requirements engineering practices and chall.pdf:/Users/vsivaram/Zotero/storage/9EHJ8EAA/Ramesh et al. - 2010 - Agile requirements engineering practices and chall.pdf:application/pdf},
}

@inproceedings{selbst_fairness_2019,
	address = {Atlanta GA USA},
	title = {Fairness and {Abstraction} in {Sociotechnical} {Systems}},
	isbn = {978-1-4503-6125-5},
	url = {https://dl.acm.org/doi/10.1145/3287560.3287598},
	doi = {10.1145/3287560.3287598},
	language = {en},
	urldate = {2024-08-12},
	booktitle = {Proceedings of the {Conference} on {Fairness}, {Accountability}, and {Transparency}},
	publisher = {ACM},
	author = {Selbst, Andrew D. and Boyd, Danah and Friedler, Sorelle A. and Venkatasubramanian, Suresh and Vertesi, Janet},
	month = jan,
	year = {2019},
	pages = {59--68},
	file = {Full Text PDF:/Users/vsivaram/Zotero/storage/HBCL3HU6/Selbst et al. - 2019 - Fairness and Abstraction in Sociotechnical Systems.pdf:application/pdf},
}

@article{giannini_machine_2019,
	title = {A {Machine} {Learning} {Algorithm} to {Predict} {Severe} {Sepsis} and {Septic} {Shock}: {Development}, {Implementation} and {Impact} on {Clinical} {Practice}},
	volume = {47},
	issn = {0090-3493},
	shorttitle = {A {Machine} {Learning} {Algorithm} to {Predict} {Severe} {Sepsis} and {Septic} {Shock}},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8635476/},
	doi = {10.1097/CCM.0000000000003891},
	abstract = {OBJECTIVE
Develop and implement a machine learning algorithm to predict severe sepsis and septic shock and evaluate the impact on clinical practice and patient outcomes

DESIGN
Retrospective cohort for algorithm derivation and validation, pre-post impact evaluation

SETTING
Tertiary teaching hospital system in Philadelphia, PA

PATIENTS
All non-ICU admissions; algorithm derivation July 2011-June 2014 (n= 162,212); algorithm validation October-December 2015 (n=10,448); silent versus alert comparison January 2016-February 2017 (silent n= 22,280; alert n= 32,184).

INTERVENTIONS
A random-forest classifier, derived and validated using electronic health record data, was deployed both silently and later with an alert to notify clinical teams of sepsis prediction.

MEASUREMENT and MAIN RESULT
Patients identified for training the algorithm were required to have ICD9 codes for severe sepsis or septic shock and a positive blood culture during their hospital encounter with either a lactate {\textgreater} 2.2 mmol/L or a systolic blood pressure {\textless} 90 mm Hg. The algorithm demonstrated a sensitivity of 26\% and specificity of 98\%, with a positive predictive value of 29\% and positive likelihood ratio of 13. The alert resulted in a small statistically significant increase in lactate testing and intravenous fluid administration. There was no significant difference in mortality, discharge disposition, or transfer to ICU, although there was a reduction in time-to-ICU transfer.

CONCLUSIONS
Our machine learning algorithm can predict, with low sensitivity but high specificity, the impending occurrence of severe sepsis and septic shock. Algorithm-generated predictive alerts modestly impacted clinical measures. Next steps include describing clinical perception of this tool, and optimizing algorithm design and delivery.},
	number = {11},
	urldate = {2024-08-15},
	journal = {Critical care medicine},
	author = {Giannini, Heather M. and Ginestra, Jennifer C. and Chivers, Corey and Draugelis, Michael and Hanish, Asaf and Schweickert, William D. and Fuchs, Barry D. and Meadows, Laurie and Lynch, Michael and Donnelly, Patrick J. and Pavan, Kimberly and Fishman, Neil O. and Hanson, C. William and Umscheid, Craig A.},
	month = nov,
	year = {2019},
	pmid = {31389839},
	pmcid = {PMC8635476},
	pages = {1485--1492},
	file = {PubMed Central Full Text PDF:/Users/vsivaram/Zotero/storage/HQKPHSU3/Giannini et al. - 2019 - A Machine Learning Algorithm to Predict Severe Sep.pdf:application/pdf},
}

@article{paxton_developing_2013,
	title = {Developing {Predictive} {Models} {Using} {Electronic} {Medical} {Records}: {Challenges} and {Pitfalls}},
	volume = {2013},
	issn = {1942-597X},
	shorttitle = {Developing {Predictive} {Models} {Using} {Electronic} {Medical} {Records}},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3900132/},
	abstract = {While Electronic Medical Records (EMR) contain detailed records of the patient-clinician encounter — vital signs, laboratory tests, symptoms, caregivers’ notes, interventions prescribed and outcomes — developing predictive models from this data is not straightforward. These data contain systematic biases that violate assumptions made by off-the-shelf machine learning algorithms, commonly used in the literature to train predictive models. In this paper, we discuss key issues and subtle pitfalls specific to building predictive models from EMR. We highlight the importance of carefully considering both the special characteristics of EMR as well as the intended clinical use of the predictive model and show that failure to do so could lead to developing models that are less useful in practice. Finally, we describe approaches for training and evaluating models on EMR using early prediction of septic shock as our example application.},
	urldate = {2024-08-16},
	journal = {AMIA Annual Symposium Proceedings},
	author = {Paxton, Chris and Niculescu-Mizil, Alexandru and Saria, Suchi},
	month = nov,
	year = {2013},
	pmid = {24551396},
	pmcid = {PMC3900132},
	pages = {1109--1115},
	file = {PubMed Central Full Text PDF:/Users/vsivaram/Zotero/storage/WE4TCDZI/Paxton et al. - 2013 - Developing Predictive Models Using Electronic Medi.pdf:application/pdf},
}


@article{Ginestra2019,
	title = {Clinician {Perception} of a {Machine} {Learning}-{Based} {Early} {Warning} {System} {Designed} to {Predict} {Severe} {Sepsis} and {Septic} {Shock}},
	volume = {47},
	doi = {10.1097/CCM.0000000000003803},
	number = {11},
	journal = {Critical Care Medicine},
	author = {Ginestra, Jennifer C. and Giannini, Heather M. and Schweickert, William D. and Meadows, Laurie and Lynch, Michael J. and Pavan, Kimberly and Chivers, Corey J. and Draugelis, Michael and Donnelly, Patrick J. and Fuchs, Barry D. and Umscheid, Craig A.},
	year = {2019},
	note = {ISBN: 2163684814},
	pages = {1--18},
	file = {PDF:/Users/vsivaram/Zotero/storage/APA8QPCP/nihms-1527406.pdf:application/pdf},
}


@article{guidi_clinician_2015,
	title = {Clinician {Perception} of the {Effectiveness} of an {Automated} {Early} {Warning} and {Response} {System} for {Sepsis} in an {Academic} {Medical} {Center}},
	volume = {12},
	issn = {2329-6933},
	url = {https://www.atsjournals.org/doi/10.1513/AnnalsATS.201503-129OC},
	doi = {10.1513/AnnalsATS.201503-129OC},
	abstract = {Rationale: We implemented an electronic early warning and response system (EWRS) to improve detection of and response to severe sepsis. Sustainability of such a system requires stakeholder acceptance. We hypothesized that clinicians receiving such alerts perceive them to be useful and effective.

Objectives: To survey clinicians after EWRS notification about perceptions of the system.

Methods: For a 6-week study period 1 month after EWRS implementation in a large tertiary referral medical center, bedside clinicians, including providers (physicians, advanced practice providers) and registered nurses (RNs), were surveyed confidentially within 2 hours of an alert.

Measurements and Main Results: For the 247 alerts that triggered, 127 providers (51\%) and 105 RNs (43\%) completed the survey. Clinicians perceived most patients as stable before and after the alert. Approximately half (39\% providers, 48\% RNs) felt the alert provided new information, and about half (44\% providers, 56\% RNs) reported changes in management as a result of the alert, including closer monitoring and additional interventions. Over half (54\% providers, 65\% RNs) felt the alert was appropriately timed. Approximately one-third found the alert helpful (33\% providers, 40\% RNs) and fewer felt it improved patient care (24\% providers, 35\% RNs).

Conclusions: A minority of responders perceived the EWRS to be useful, likely related to the perception that most patients identified were stable. However, management was altered half the time after an alert. These results suggest further improvements to the system are needed to enhance clinician perception of the system’s utility.},
	number = {10},
	urldate = {2024-08-19},
	journal = {Annals of the American Thoracic Society},
	author = {Guidi, Jessica L. and Clark, Katherine and Upton, Mark T. and Faust, Hilary and Umscheid, Craig A. and Lane-Fall, Meghan B. and Mikkelsen, Mark E. and Schweickert, William D. and Vanzandbergen, Christine A. and Betesh, Joel and Tait, Gordon and Hanish, Asaf and Smith, Kirsten and Feeley, Denise and Fuchs, Barry D.},
	month = oct,
	year = {2015},
	note = {Publisher: American Thoracic Society - AJRCCM},
	keywords = {early warning systems, electronic medical record, sepsis and shock, survey design},
	pages = {1514--1519},
	file = {Full Text PDF:/Users/vsivaram/Zotero/storage/TTRZ9E8A/Guidi et al. - 2015 - Clinician Perception of the Effectiveness of an Au.pdf:application/pdf},
}


@inproceedings{subramonyam_solving_2022,
	address = {New Orleans LA USA},
	title = {Solving {Separation}-of-{Concerns} {Problems} in {Collaborative} {Design} of {Human}-{AI} {Systems} through {Leaky} {Abstractions}},
	isbn = {978-1-4503-9157-3},
	url = {https://dl.acm.org/doi/10.1145/3491102.3517537},
	doi = {10.1145/3491102.3517537},
	language = {en},
	urldate = {2024-07-01},
	booktitle = {{CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {ACM},
	author = {Subramonyam, Hariharan and Im, Jane and Seifert, Colleen and Adar, Eytan},
	month = apr,
	year = {2022},
	pages = {1--21},
}



@techreport{chapman_crisp-dm_2000,
	title = {{CRISP}-{DM} 1.0: {Step}-by-step data mining guide},
	url = {https://www.kde.cs.uni-kassel.de/wp-content/uploads/lehre/ws2012-13/kdd/files/CRISPWP-0800.pdf},
    institution = {CRISP-DM Consortium},
	urldate = {2024-08-28},
	author = {Chapman, Pete and Clinton, Julian and Kerber, Randy and Khabaza, Thomas and Reinartz, Thomas and Shearer, Colin and Wirth, Rüdiger},
	year = {2000},
	file = {CRISPWP-0800.pdf:/Users/vsivaram/Zotero/storage/FYSYJ4ZX/CRISPWP-0800.pdf:application/pdf},
}


@inproceedings{yildirim_sketching_2024,
	address = {Honolulu HI USA},
	title = {Sketching {AI} {Concepts} with {Capabilities} and {Examples}: {AI} {Innovation} in the {Intensive} {Care} {Unit}},
	isbn = {9798400703300},
	shorttitle = {Sketching {AI} {Concepts} with {Capabilities} and {Examples}},
	url = {https://dl.acm.org/doi/10.1145/3613904.3641896},
	doi = {10.1145/3613904.3641896},
	language = {en},
	urldate = {2024-07-02},
	booktitle = {Proceedings of the {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {ACM},
	author = {Yildirim, Nur and Zlotnikov, Susanna and Sayar, Deniz and Kahn, Jeremy M. and Bukowski, Leigh A and Amin, Sher Shah and Riman, Kathryn A. and Davis, Billie S. and Minturn, John S. and King, Andrew J. and Ricketts, Dan and Tang, Lu and Sivaraman, Venkatesh and Perer, Adam and Preum, Sarah M. and McCann, James and Zimmerman, John},
	month = may,
	year = {2024},
	pages = {1--18},
	file = {Full Text PDF:/Users/vsivaram/Zotero/storage/SE7LB2GA/Yildirim et al. - 2024 - Sketching AI Concepts with Capabilities and Exampl.pdf:application/pdf},
}


@article{rong_towards_2024,
	title = {Towards {Human}-{Centered} {Explainable} {AI}: {A} {Survey} of {User} {Studies} for {Model} {Explanations}},
	volume = {46},
	copyright = {https://creativecommons.org/licenses/by/4.0/legalcode},
	issn = {0162-8828, 2160-9292, 1939-3539},
	shorttitle = {Towards {Human}-{Centered} {Explainable} {AI}},
	url = {https://ieeexplore.ieee.org/document/10316181/},
	doi = {10.1109/TPAMI.2023.3331846},
	abstract = {Explainable AI (XAI) is widely viewed as a sine qua non for ever-expanding AI research. A better understanding of the needs of XAI users, as well as human-centered evaluations of explainable models are both a necessity and a challenge. In this paper, we explore how human-computer interaction (HCI) and AI researchers conduct user studies in XAI applications based on a systematic literature review. After identifying and thoroughly analyzing 97 core papers with human-based XAI evaluations over the past ﬁve years, we categorize them along the measured characteristics of explanatory methods, namely trust, understanding, usability, and human-AI collaboration performance. Our research shows that XAI is spreading more rapidly in certain application domains, such as recommender systems than in others, but that user evaluations are still rather sparse and incorporate hardly any insights from cognitive or social sciences. Based on a comprehensive discussion of best practices, i.e., common models, design choices, and measures in user studies, we propose practical guidelines on designing and conducting user studies for XAI researchers and practitioners. Lastly, this survey also highlights several open research directions, particularly linking psychological science and human-centered XAI.},
	language = {en},
	number = {4},
	urldate = {2024-07-02},
	journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
	author = {Rong, Yao and Leemann, Tobias and Nguyen, Thai-Trang and Fiedler, Lisa and Qian, Peizhu and Unhelkar, Vaibhav and Seidel, Tina and Kasneci, Gjergji and Kasneci, Enkelejda},
	month = apr,
	year = {2024},
	pages = {2104--2122},
	file = {Rong et al. - 2024 - Towards Human-Centered Explainable AI A Survey of.pdf:/Users/vsivaram/Zotero/storage/DPV9GQWZ/Rong et al. - 2024 - Towards Human-Centered Explainable AI A Survey of.pdf:application/pdf},
}


@article{amann_explain_2022,
	title = {To explain or not to explain?—{Artificial} intelligence explainability in clinical decision support systems},
	volume = {1},
	doi = {10.1371/journal.pdig.0000016},
	abstract = {Explainability for artificial intelligence (AI) in medicine is a hotly debated topic. Our paper presents a review of the key arguments in favor and against explainability for AI-powered Clinical Decision Support System (CDSS) applied to a concrete use case, namely an AI-powered CDSS currently used in the emergency call setting to identify patients with life-threatening cardiac arrest. More specifically, we performed a normative analysis using socio-technical scenarios to provide a nuanced account of the role of explainability for CDSSs for the concrete use case, allowing for abstractions to a more general level. Our analysis focused on three layers: technical considerations, human factors, and the designated system role in decision-making. Our findings suggest that whether explainability can provide added value to CDSS depends on several key questions: technical feasibility, the level of validation in case of explainable algorithms, the characteristics of the context in which the system is implemented, the designated role in the decision-making process, and the key user group(s). Thus, each CDSS will require an individualized assessment of explainability needs and we provide an example of how such an assessment could look like in practice.},
	number = {2},
	journal = {PLOS Digital Health},
	author = {Amann, Julia and Vetter, Dennis and Blomberg, Stig Nikolaj and Christensen, Helle Collatz and Coffee, Megan and Gerke, Sara and Gilbert, Thomas K. and Hagendorff, Thilo and Holm, Sune and Livne, Michelle and Spezzatti, Andy and Strümke, Inga and Zicari, Roberto V. and Madai, Vince Istvan},
	year = {2022},
	note = {ISBN: 1111111111},
	pages = {e0000016},
	file = {PDF:/Users/vsivaram/Zotero/storage/C7X87JMX/journal.pdig.0000016.pdf:application/pdf},
}


@article{Bussone2015,
	title = {The role of explanations on trust and reliance in clinical decision support systems},
	url = {http://openaccess.city.ac.uk/1189/},
	abstract = {Clinical decision support systems (CDSS) are increasingly used by healthcare professionals for evidence-based diagnosis and treatment support. However, research has suggested that users often over-rely on system suggestions – even if the suggestions are wrong. Providing explanations could potentially mitigate misplaced trust in the system and over- reliance. In this paper, we explore how explanations are related to user trust and reliance, as well as what information users would find helpful to better understand the reliability of a system's decision-making. We investigated these questions through an exploratory user study in which healthcare professionals were observed using a CDSS prototype to diagnose hypothetic cases using fictional patients suffering from a balance- related disorder. Our results show that the amount of system confidence had only a slight effect on trust and reliance. More importantly, giving a fuller explanation of the facts used in making a diagnosis had a positive effect on trust but also led to over-reliance issues, whereas less detailed explanations made participants question the system's reliability and led to self- reliance problems. To help them in their assessment of the reliability of the system's decisions, study participants wanted better explanations to help them interpret the system's confidence, to verify that the disorder fit the suggestion, to better understand the reasoning chain of the decision model, and to make differential diagnoses. Our work is a first step toward improved CDSS design that better supports clinicians in making correct diagnoses.},
	journal = {Conference on Healthcare Informatics},
	author = {Bussone, Adrian and Stumpf, Simone and O'Sullivan, Dympna},
	year = {2015},
	note = {ISBN: 0896920507084},
	file = {PDF:/Users/vsivaram/Zotero/storage/V4LYAJTV/ICHI_2015_CameraReady.pdf:application/pdf},
}

@ARTICLE{guidotti_2019,
  author={Guidotti, Riccardo and Monreale, Anna and Giannotti, Fosca and Pedreschi, Dino and Ruggieri, Salvatore and Turini, Franco},
  journal={IEEE Intelligent Systems}, 
  title={Factual and Counterfactual Explanations for Black Box Decision Making}, 
  year={2019},
  volume={34},
  number={6},
  pages={14-23},
  keywords={Genetic algorithms;Intelligent systems;Decision making;Decision trees;Machine learning algorithms;Prediction algorithms;Data models;Explainable AI;Interpretable Machine Learning;Open the Black Box;Explanation Rules;Counterfactuals},
  doi={10.1109/MIS.2019.2957223}}

@inproceedings{kandel_wrangler_2011,
author = {Kandel, Sean and Paepcke, Andreas and Hellerstein, Joseph and Heer, Jeffrey},
title = {Wrangler: interactive visual specification of data transformation scripts},
year = {2011},
isbn = {9781450302289},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1978942.1979444},
doi = {10.1145/1978942.1979444},
abstract = {Though data analysis tools continue to improve, analysts still expend an inordinate amount of time and effort manipulating data and assessing data quality issues. Such "data wrangling" regularly involves reformatting data values or layout, correcting erroneous or missing values, and integrating multiple data sources. These transforms are often difficult to specify and difficult to reuse across analysis tasks, teams, and tools. In response, we introduce Wrangler, an interactive system for creating data transformations. Wrangler combines direct manipulation of visualized data with automatic inference of relevant transforms, enabling analysts to iteratively explore the space of applicable operations and preview their effects. Wrangler leverages semantic data types (e.g., geographic locations, dates, classification codes) to aid validation and type conversion. Interactive histories support review, refinement, and annotation of transformation scripts. User study results show that Wrangler significantly reduces specification time and promotes the use of robust, auditable transforms instead of manual editing.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3363–3372},
numpages = {10},
keywords = {wrangler, visualization, transformation, data cleaning, data analysis},
location = {Vancouver, BC, Canada},
series = {CHI '11}
}

@misc{cheng_2024_aha,
      title={Algorithm-Assisted Decision Making and Racial Disparities in Housing: A Study of the Allegheny Housing Assessment Tool}, 
      author={Lingwei Cheng and Cameron Drayton and Alexandra Chouldechova and Rhema Vaithianathan},
      year={2024},
      eprint={2407.21209},
      archivePrefix={arXiv},
      primaryClass={cs.HC},
      url={https://arxiv.org/abs/2407.21209}, 
}
@Comment{jabref-meta: databaseType:bibtex;}


@article{dingen_regressionexplorer_2019,
	title = {{RegressionExplorer}: {Interactive} {Exploration} of {Logistic} {Regression} {Models} with {Subgroup} {Analysis}},
	volume = {25},
	issn = {1941-0506},
	shorttitle = {{RegressionExplorer}},
	url = {https://ieeexplore.ieee.org/document/8464305/?arnumber=8464305},
	doi = {10.1109/TVCG.2018.2865043},
	abstract = {We present RegressionExplorer, a Visual Analytics tool for the interactive exploration of logistic regression models. Our application domain is Clinical Biostatistics, where models are derived from patient data with the aim to obtain clinically meaningful insights and consequences. Development and interpretation of a proper model requires domain expertise and insight into model characteristics. Because of time constraints, often a limited number of candidate models is evaluated. RegressionExplorer enables experts to quickly generate, evaluate, and compare many different models, taking the workflow for model development as starting point. Global patterns in parameter values of candidate models can be explored effectively. In addition, experts are enabled to compare candidate models across multiple subpopulations. The insights obtained can be used to formulate new hypotheses or to steer model development. The effectiveness of the tool is demonstrated for two uses cases: prediction of a cardiac conduction disorder in patients after receiving a heart valve implant and prediction of hypernatremia in critically ill patients.},
	number = {1},
	urldate = {2024-09-02},
	journal = {IEEE Transactions on Visualization and Computer Graphics},
	author = {Dingen, Dennis and van't Veer, Marcel and Houthuizen, Patrick and Mestrom, Eveline H. J. and Korsten, Erik H.H.M. and Bouwman, Arthur R.A. and van Wijk, Jarke},
	month = jan,
	year = {2019},
	note = {Conference Name: IEEE Transactions on Visualization and Computer Graphics},
	keywords = {Analytical models, Biological system modeling, Data models, Exploratory data analysis, Logistics, Mathematical model, Multivariate statistics, Predictive visual analytics, Regression analysis, Subgroup analysis, Variable selection, Visual analytics},
	pages = {246--255},
	file = {IEEE Xplore Abstract Record:/Users/vsivaram/Zotero/storage/XJI2SJZT/8464305.html:text/html;IEEE Xplore Full Text PDF:/Users/vsivaram/Zotero/storage/YF33H8Z7/Dingen et al. - 2019 - RegressionExplorer Interactive Exploration of Log.pdf:application/pdf},
}

@inproceedings{divisi,
	title = {{Divisi: Interactive Search and Visualization for Scalable Exploratory Subgroup Analysis}},
	author = {Sivaraman, Venkatesh and Li, Zexuan and Perer, Adam},
	year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713103},
doi = {10.1145/3706598.3713103},
booktitle = {Proceedings of the CHI Conference on Human Factors in Computing Systems},
numpages = {17},
location = {Yokohama, Japan},
series = {CHI '25}
}



@article{landers_future_2016,
	title = {The {Future} of {Home} {Health} {Care}: {A} {Strategic} {Framework} for {Optimizing} {Value}},
	volume = {28},
	issn = {1084-8223},
	shorttitle = {The {Future} of {Home} {Health} {Care}},
	doi = {10.1177/1084822316666368},
	abstract = {The Future of Home Health project sought to support transformation of home health and home-based care to meet the needs of patients in the evolving U.S. health care system. Interviews with key thought leaders and stakeholders resulted in key themes about the future of home health care. By synthesizing this qualitative research, a literature review, case studies, and the themes from a 2014 Institute of Medicine and National Research Council workshop on "The Future of Home Health Care," the authors articulate a vision for home-based care and recommend a bold framework for the Medicare-certified home health agency of the future. The authors also identify challenges and recommendations for achievement of this framework.},
	language = {eng},
	number = {4},
	journal = {Home Health Care Management \& Practice},
	author = {Landers, Steven and Madigan, Elizabeth and Leff, Bruce and Rosati, Robert J. and McCann, Barbara A. and Hornbake, Rodney and MacMillan, Richard and Jones, Kate and Bowles, Kathryn and Dowding, Dawn and Lee, Teresa and Moorhead, Tracey and Rodriguez, Sally and Breese, Erica},
	month = nov,
	year = {2016},
	pmid = {27746670},
	pmcid = {PMC5052697},
	keywords = {home health, home-based care, hospice, hospital at home, palliative care, quality, technology, workforce},
	pages = {262--278},
	file = {Full Text:/Users/vsivaram/Zotero/storage/VHRJ8ASS/Landers et al. - 2016 - The Future of Home Health Care A Strategic Framew.pdf:application/pdf},
}

@techreport{donnelly_id_2016,
	title = {'{I}'d prefer to stay at home but {I} don't have a choice': {Meeting} {Older} {People}'s {Preference} for {Care}: {Policy}, but what about practice?},
	shorttitle = {'{I}'d prefer to stay at home but {I} don't have a choice'},
	url = {http://hdl.handle.net/10197/7670},
	abstract = {Background: Research indicates that most older people would prefer to live in their own homes and have support services provided to enable them to do so for as long as possible (Barry, 2010). However, there is an evident tension between this objective and the promotion of 'ageing in place', with the consequent heavy reliance on the Nursing Home Support Scheme (NHSS) in the Irish context (Donnelly and O¿Loughlin, 2015). This study set out to explore the perspectives and experiences of social workers in Republic of Ireland working with older people to identify issues/barriers in accessing community supports and to examine older people's involvement in decision-making, including those with a cognitive impairment/dementia. Methods: A mixed methods study design was adapted and the study consisted of two phases: Phase 1 consisted of an on-line survey of social workers using Survey Monkey. Phase 2 consisted of in-depth semi-structured telephone interviews with at least two social workers from each Community Health Office area. Results: Geographical inconsistencies were revealed in social workers ability to access community supports and clear tensions were found as home supports are only delivered within the framework of what is available. A growing emphasis on responding only to those with the most severe level of need, coupled with increased budgetary constraints, means that little or no support can be accessed through home help services to assist older people with domestic tasks.Social workers also reported that many older people with a mental health issue and/or dementia were excluded from decision-making processes related to their care. Conclusions: Older people's preference for receiving care and support in their home and community is not being realised often resulting in unnecessary or premature admission to nursing home care.},
	language = {en},
	urldate = {2024-09-08},
	institution = {University College Dublin. School of Social Policy, Social Work and Social Justice},
	author = {Donnelly, Sarah and O'Brien, Marita and Begley, Emer and Brennan, John},
	month = jun,
	year = {2016},
	file = {Full Text PDF:/Users/vsivaram/Zotero/storage/KPBYF975/Donnelly et al. - 2016 - 'I'd prefer to stay at home but I don't have a cho.pdf:application/pdf},
}

@article{jones_characteristics_2012,
	title = {Characteristics and use of home health care by men and women aged 65 and over},
	issn = {2164-8344},
	abstract = {OBJECTIVE: This report presents national estimates on differences in the use of home health care between men and women aged 65 years and over.
METHODS: Estimates are based on data from the 2007 National Home and Hospice Care Survey, conducted by the Centers for Disease Control and Prevention's National Center for Health Statistics.
RESULTS: In the United States, men aged 65 years and over used home health care at a lower rate than women. Among home health care patients 65 years and over, women were more likely to be 85 years and over while men were more likely to be married and receive home health care as post-acute care. Women 65 years and over who received home health care were less likely than males to receive wound care and physical therapy, and more likely to receive homemaker services. Among home health care patients who were 65 years and over, cancer was more prevalent among men, and essential hypertension was more common among women.},
	language = {eng},
	number = {52},
	journal = {National Health Statistics Reports},
	author = {Jones, Adrienne L. and Harris-Kojetin, Lauren and Valverde, Roberto},
	month = apr,
	year = {2012},
	pmid = {22808696},
	keywords = {Aged, Aged, 80 and over, Chronic Disease, Female, Home Care Services, Humans, Male, Sex Factors, United States},
	pages = {1--7},
}

@article{bahr_nurse_2020,
	title = {Nurse {Continuity} at {Discharge} and {Return} to {Hospital}},
	volume = {69},
	issn = {1538-9847},
	doi = {10.1097/NNR.0000000000000417},
	abstract = {BACKGROUND: Promoting continuity of nurse assignment during discharge care has the potential to increase patient readiness for discharge-which has been associated with fewer readmissions and emergency department visits. The few studies that examined nurse continuity during acute care hospitalizations did not focus on discharge or postdischarge outcomes.
OBJECTIVES: The aim of this research was to examine the association of continuity in nurse assignment to patients prior to hospital discharge with return to hospital (readmission and emergency department or observation visits), including exploration of the mediating pathway through patient readiness for discharge and moderating effects of unit environment and unit nurse characteristics.
METHODS: In a sample of 18,203 adult, medical-surgical patients from 31 Magnet hospitals, a correlational path analysis design was used in a secondary analysis to evaluate the effect of nurse continuity on readmissions and emergency department or observation visits within 30 days after hospital discharge. The mediating pathway through discharge readiness measured by patient self-report and nurse assessments was also assessed. Moderating effects of unit environment and nursing characteristics were examined across quartiles of unit environment (nurse staffing hours per patient day) and unit nurse characteristics (education and experience). Analyses were adjusted for patient characteristics, unit fixed effects, and clustering at the unit level.
RESULTS: Continuous nurse assignment on the last 2 days of hospitalization was observed in 6,441 (35.4\%) patient discharges and was associated with a 0.85 absolute percentage point reduction (7.8\% relative reduction) in readmissions. There was no significant association with emergency department or observation visits. Sensitivity analysis revealed a stronger effect in patients with higher Elixhauser Comorbidity Indexes. Readiness for discharge was not a mediator of the effect of continuity on return to hospital. Unit characteristics were not associated with nurse continuity. No moderation effect was evident for unit environment and nurse characteristics.
DISCUSSION: Continuity of nurse assignment on the last 2 days of hospitalization can reduce readmissions. Staffing for continuity may benefit patients and healthcare systems, with greater benefits for high-comorbidity patients. Nurse continuity prior to hospital discharge should be a priority consideration in assigning acute care nurses to augment readmission reduction efforts.},
	language = {eng},
	number = {3},
	journal = {Nursing Research},
	author = {Bahr, Sarah J. and Bang, James and Yakusheva, Olga and Bobay, Kathleen L. and Krejci, Janet and Costa, Linda and Hughes, Ronda G. and Hamilton, Morris and Siclovan, Danielle M. and Weiss, Marianne E.},
	year = {2020},
	pmid = {31934945},
	keywords = {Adult, Aged, Continuity of Patient Care, Female, Humans, Male, Middle Aged, Nursing Evaluation Research, Nursing Staff, Hospital, Patient Discharge, Patient Readmission},
	pages = {186--196},
	file = {Submitted Version:/Users/vsivaram/Zotero/storage/IL8BJEK7/Bahr et al. - 2020 - Nurse Continuity at Discharge and Return to Hospit.pdf:application/pdf},
}

@article{naylor_transitional_2004,
	title = {Transitional care of older adults hospitalized with heart failure: a randomized, controlled trial},
	volume = {52},
	issn = {0002-8614},
	shorttitle = {Transitional care of older adults hospitalized with heart failure},
	doi = {10.1111/j.1532-5415.2004.52202.x},
	abstract = {OBJECTIVES: To examine the effectiveness of a transitional care intervention delivered by advanced practice nurses (APNs) to elders hospitalized with heart failure.
DESIGN: Randomized, controlled trial with follow-up through 52 weeks postindex hospital discharge.
SETTING: Six Philadelphia academic and community hospitals.
PARTICIPANTS: Two hundred thirty-nine eligible patients were aged 65 and older and hospitalized with heart failure.
INTERVENTION: A 3-month APN-directed discharge planning and home follow-up protocol.
MEASUREMENTS: Time to first rehospitalization or death, number of rehospitalizations, quality of life, functional status, costs, and satisfaction with care.
RESULTS: Mean age of patients (control n=121; intervention n=118) enrolled was 76; 43\% were male, and 36\% were African American. Time to first readmission or death was longer in intervention patients (log rank chi(2)=5.0, P=.026; Cox regression incidence density ratio=1.65, 95\% confidence interval=1.13-2.40). At 52 weeks, intervention group patients had fewer readmissions (104 vs 162, P=.047) and lower mean total costs (\$7,636 vs \$12,481, P=.002). For intervention patients, only short-term improvements were demonstrated in overall quality of life (12 weeks, P{\textless}.05), physical dimension of quality of life (2 weeks, P{\textless}.01; 12 weeks, P{\textless}.05) and patient satisfaction (assessed at 2 and 6 weeks, P{\textless}.001).
CONCLUSION: A comprehensive transitional care intervention for elders hospitalized with heart failure increased the length of time between hospital discharge and readmission or death, reduced total number of rehospitalizations, and decreased healthcare costs, thus demonstrating great promise for improving clinical and economic outcomes.},
	language = {eng},
	number = {5},
	journal = {Journal of the American Geriatrics Society},
	author = {Naylor, Mary D. and Brooten, Dorothy A. and Campbell, Roberta L. and Maislin, Greg and McCauley, Kathleen M. and Schwartz, J. Sanford},
	month = may,
	year = {2004},
	pmid = {15086645},
	keywords = {Aftercare, Aged, Aged, 80 and over, Black or African American, Comorbidity, Confidence Intervals, Continuity of Patient Care, Costs and Cost Analysis, Female, Follow-Up Studies, Heart Failure, Home Care Services, Hospitalization, Humans, Male, Patient Readmission, Patient Satisfaction, Quality of Life, Regression Analysis, Socioeconomic Factors, Time Factors, Treatment Outcome, White People},
	pages = {675--684},
}


@article{Lundberg2017,
	title = {A unified approach to interpreting model predictions},
	volume = {2017-Decem},
	issn = {10495258},
	abstract = {Understanding why a model makes a certain prediction can be as crucial as the prediction's accuracy in many applications. However, the highest accuracy for large modern datasets is often achieved by complex models that even experts struggle to interpret, such as ensemble or deep learning models, creating a tension between accuracy and interpretability. In response, various methods have recently been proposed to help users interpret the predictions of complex models, but it is often unclear how these methods are related and when one method is preferable over another. To address this problem, we present a unified framework for interpreting predictions, SHAP (SHapley Additive exPlanations). SHAP assigns each feature an importance value for a particular prediction. Its novel components include: (1) the identification of a new class of additive feature importance measures, and (2) theoretical results showing there is a unique solution in this class with a set of desirable properties. The new class unifies six existing methods, notable because several recent methods in the class lack the proposed desirable properties. Based on insights from this unification, we present new methods that show improved computational performance and/or better consistency with human intuition than previous approaches.},
	number = {Section 2},
	journal = {Advances in Neural Information Processing Systems},
	author = {Lundberg, Scott M. and Lee, Su In},
	year = {2017},
	note = {arXiv: 1705.07874},
	pages = {4766--4775},
	file = {PDF:/Users/vsivaram/Zotero/storage/FIUH836P/1705.07874.pdf:application/pdf},
}

@article{Caruccio2015,
title = {Understanding user intent on the web through interaction mining},
journal = {Journal of Visual Languages \& Computing},
volume = {31},
pages = {230-236},
year = {2015},
note = {Special Issue on DMS2015},
issn = {1045-926X},
doi = {https://doi.org/10.1016/j.jvlc.2015.10.022},
url = {https://www.sciencedirect.com/science/article/pii/S1045926X15000798},
author = {Loredana Caruccio and Vincenzo Deufemia and Giuseppe Polese},
keywords = {User intent understanding, HCI features, Web search, User behavior mining, Query classification},
abstract = {Predicting the goals of internet users can be extremely useful in e-commerce, online entertainment, and many other internet-based applications. One of the crucial steps to achieve this is to classify internet queries based on available features, such as contextual information, keywords and their semantic relationships. Beyond these methods, in this paper we propose to mine user interaction activities to predict the intent of the user during a navigation session. However, since in practice it is necessary to use a suitable mix of all such methods, it is important to exploit all the mentioned features in order to properly classify users based on their common intents. To this end, we have performed several experiments aiming to empirically derive a suitable classifier based on the mentioned features.}
}


@article{tsoumakas_survey_2019,
	title = {A survey of machine learning techniques for food sales prediction},
	volume = {52},
	issn = {1573-7462},
	url = {https://doi.org/10.1007/s10462-018-9637-z},
	doi = {10.1007/s10462-018-9637-z},
	abstract = {Food sales prediction is concerned with estimating future sales of companies in the food industry, such as supermarkets, groceries, restaurants, bakeries and patisseries. Accurate short-term sales prediction allows companies to minimize stocked and expired products inside stores and at the same time avoid missing sales. This paper reviews existing machine learning approaches for food sales prediction. It discusses important design decisions of a data analyst working on food sales prediction, such as the temporal granularity of sales data, the input variables to use for predicting sales and the representation of the sales output variable. In addition, it reviews machine learning algorithms that have been applied to food sales prediction and appropriate measures for evaluating their accuracy. Finally, it discusses the main challenges and opportunities for applied machine learning in the domain of food sales prediction.},
	number = {1},
	journal = {Artificial Intelligence Review},
	author = {Tsoumakas, Grigorios},
	month = jun,
	year = {2019},
	pages = {441--447},
}

@Article{Dueben2018,
AUTHOR = {Dueben, P. D. and Bauer, P.},
TITLE = {Challenges and design choices for global weather and climate models based on machine learning},
JOURNAL = {Geoscientific Model Development},
VOLUME = {11},
YEAR = {2018},
NUMBER = {10},
PAGES = {3999--4009},
URL = {https://gmd.copernicus.org/articles/11/3999/2018/},
DOI = {10.5194/gmd-11-3999-2018}
}


@article{dingen_roa_2024,
	title = {{RoA}: visual analytics support for deconfounded causal inference in observational studies},
	volume = {4},
	issn = {2773-0689},
	shorttitle = {{RoA}},
	doi = {10.52933/jdssv.v4i3.72},
	abstract = {The gold standard in medical research to estimate the causal effect of a treatment is the Randomized Controlled Trial (RCT), but in many cases these are not feasible due to ethical, financial or practical issues. Observational studies are an alternative, but can easily lead to doubtful results, because of unbalanced selection bias and confounding. Moreover, RCTs often only apply to a specific subgroup and cannot readily be extrapolated. In response, we present Rod of Asclepius (RoA), a novel visual analytics method that integrates modern techniques designed for identification of causal effects and effect size estimation with subgroup analysis. The result is an interactive display designed to combine exploratory analysis with a robust set of techniques, including causal do-calculus, propensity score weighting, and effect estimation. It enables analysts to conduct observational studies in an exploratory, yet robust way. This is demonstrated by means of a use case involving patients undergoing surgery, for which we collaborated closely with clinical researchers.},
	number = {3},
	journal = {Journal of Data Science, Statistics, and Visualisation},
	author = {Dingen, Dennis and van 't Veer, Marcel and Bakkes, Tom H.G.F. and Korsten, H.H.M (Erik) and Bouwman, R. Arthur and van Wijk, Jack J.},
	month = jun,
	year = {2024},
	keywords = {causal inference, confounding, exploratory data analysisexploratory data analysis, observational study, visual analytics},
	file = {Full Text:/Users/vsivaram/Zotero/storage/F94385ZF/Dingen et al. - 2024 - RoA visual analytics support for deconfounded cau.pdf:application/pdf},
}

@article{moller_designing_2024,
author = {Lynge Asbjørn Møller},
title = {Designing Algorithmic Editors: How Newspapers Embed and Encode Journalistic Values into News Recommender Systems},
journal = {Digital Journalism},
volume = {12},
number = {7},
pages = {926--944},
year = {2024},
publisher = {Routledge},
doi = {10.1080/21670811.2023.2215832},
URL = {https://doi.org/10.1080/21670811.2023.2215832},
eprint = {https://doi.org/10.1080/21670811.2023.2215832}
}


@InProceedings{korbak_pretraining_2023,
  title = 	 {Pretraining Language Models with Human Preferences},
  author =       {Korbak, Tomasz and Shi, Kejian and Chen, Angelica and Bhalerao, Rasika Vinayak and Buckley, Christopher and Phang, Jason and Bowman, Samuel R. and Perez, Ethan},
  booktitle = 	 {Proceedings of the 40th International Conference on Machine Learning},
  pages = 	 {17506--17533},
  year = 	 {2023},
  editor = 	 {Krause, Andreas and Brunskill, Emma and Cho, Kyunghyun and Engelhardt, Barbara and Sabato, Sivan and Scarlett, Jonathan},
  volume = 	 {202},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {23--29 Jul},
  publisher =    {PMLR},
  pdf = 	 {https://proceedings.mlr.press/v202/korbak23a/korbak23a.pdf},
  url = 	 {https://proceedings.mlr.press/v202/korbak23a.html},
  abstract = 	 {Language models (LMs) are pretrained to imitate text from large and diverse datasets that contain content that would violate human preferences if generated by an LM: falsehoods, offensive comments, personally identifiable information, low-quality or buggy code, among others. Here, we explore alternative objectives for pretraining LMs in a way that also guides them to generate text aligned with human preferences. We benchmark five objectives for pretraining with human feedback across three tasks and study how they affect the alignment and capabilities of pretrained LMs. We find a Pareto-optimal and simple approach among those we explored: conditional training, or learning distribution over tokens conditional on their human preference scores. Conditional training reduces the rate of undesirable content by up to an order of magnitude, both when generating without a prompt and with an adversarially-chosen prompt. Moreover, conditional training maintains the downstream task performance of standard LM pretraining, both before and after task-specific finetuning. Pretraining with human feedback results in much better preference satisfaction than standard LM pretraining followed by finetuning with feedback, i.e., learning and then unlearning undesirable behavior. Our results suggest that we should move beyond imitation learning when pretraining LMs and incorporate human preferences from the start of training.}
}
