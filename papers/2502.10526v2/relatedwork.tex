\section{Related Work}
\label{sec:related-work}

Our work is inspired and informed by challenges in predictive model specification that have been discussed in human-centered AI evaluations, reviewed in Sec. \ref{sec:related-spec-issues}.
To design and implement our system to address these issues, we expand on prior technical work around working with temporal event data (Sec. \ref{sec:related-event-data}) and interactively evaluating models (Sec. \ref{sec:related-subgroups}).

\subsection{Predictive Model Specification for AI Decision Support}
\label{sec:related-spec-issues}

Temporal predictive modeling represents a large and long-standing class of machine learning problems that aim to forecast a future action or outcome based on prior history.
Predictive modeling is currently employed in an extremely wide range of applications, including predicting sales~\cite{tsoumakas_survey_2019}, user intent~\cite{Caruccio2015}, global climate~\cite{Dueben2018}, and medical treatment~\cite{Sivaraman2023}, as well as more contentious topics like child welfare~\cite{Kawakami2022partnerships} and criminal justice~\cite{Grgic-Hlaca2018}.
However, issues of model specification have often been a major obstacle to adoption of predictive models, especially for decision support in high-stakes domains.
In the medical setting, model specification problems have been increasingly discussed in the literature as predictive modeling has grown more sophisticated and widespread; for instance, Sherman et al.~\cite{sherman_leveraging_2018} showed that calculating input features retrospectively around the time of known outcomes can cause models to perform misleadingly well in evaluation.
Unexpected behaviors may also arise because historical data is biased with respect to decisions that a DST is designed to influence. For example, in Caruana et al.'s pneumonia risk prediction model~\cite{caruana_intelligible_2015}, asthma appeared to lower mortality risk because it was associated with more aggressive treatment.
In sepsis, another promising disease area for DSTs, studies have pointed out the difficulty of choosing the right predictive target, given that both mortality and need for treatment may be imperfect signals for disease severity~\cite{Sivaraman2023,Sendak2020}.

Model specifications have also been discussed in the AI fairness literature as a lens to understand how DSTs may reflect or distort human decision-maker values.
For example, Kawakami et al.'s \cite{Kawakami2022partnerships} study with child maltreatment screeners highlighted concerns that their DST used public support use as a proxy for mental health and substance abuse concerns, thereby unfairly penalizing families that seek help. 
Tal~\cite{tal_target_2023} conceptualizes all predictive targets as inherently imperfect approximations, which can reflect nuanced, value-laden negotiations between data scientists and domain experts~\cite{passi_problem_2019}.
While explainable and transparent AI designs are often cited as a way to help decision-makers understand when the AI is misaligned with themselves in the moment~\cite{Zytek2021,Kawakami2022dis}, this often places additional cognitive burden on non-technical end users and reduces the DST's value~\cite{Sivaraman2023}.
Instead, we aimed to develop a tool that involves domain experts in model development from the start, ideally improving the alignment of the end product. % These empirical and theoretical studies have called for domain expert involvement

\subsection{Querying, Visualizing, and Modeling Event Data}
\label{sec:related-event-data}

Temporal event data is ubiquitous as a way to represent evolving real-world processes and interactions through discrete observation. 
Storing and querying event data is a primary objective of many database systems, including OpenTSDB~\cite{opentsdb}, Timescale~\cite{timescale}, and Prometheus~\cite{prometheus}.
Query languages such as TSQL2~\cite{bohlen_how_2006}, the Event Query Language~\cite{wolf_introducing_2019}, and others~\cite{rozsnyai_sari-sql_2009,bry_high-level_2006} offer syntactic ways to apply temporal logic to event data, often following Allen's foundational framework of interval relations~\cite{allen_maintaining_1983}.
However, event queries still tend to be verbose and hard to read in commonly-used ML data wrangling tools such as the Structured Query Language (SQL), the Pandas library in Python, SAS, and the \texttt{dplyr} package in R. 
Moreover, even in systems specialized for event data, it can be challenging to write and update queries because different types of aggregations require dramatically different implementations (e.g., tumbling, hopping, sliding, and variable-length windows)~\cite{bohlen_how_2006}.

Considerable data visualization research has focused on helping analysts interpret temporal event data, particularly in healthcare contexts~\cite{guo_survey_2020}.
Systems such as DecisionFlow~\cite{gotz_decisionflow_2014}, Frequence~\cite{perer_frequence_2014}, and EventAction~\cite{du_eventaction_2016} aim to identify frequent event patterns and event sequences associated with adverse outcomes. 
Other systems such as VizPattern~\cite{jin_interactive_2010} and $(\text{s}|\text{qu})\text{eries}$~\cite{zgraggen_squeries_2015} have augmented the query-centric approach described above with visual representations.
While these systems tend to focus on exploratory analysis and temporal relationships between events (e.g. B after A), our work addresses the more ML-focused task of helping users aggregate events at standard intervals (e.g. A occurred four times in the past hour).

Despite the many approaches to \textit{visualize} event data, tools to address the challenges of working with event data for \textit{ML modeling} are comparatively scarce. 
For instance, systems by Kwon et al.~\cite{kwon_retainvis_2019} and Guo et al.~\cite{guo_visualizing_2019} help users interpret sequence models, but they assume the model specification and input data are fixed. 
Tempo addresses this gap by including model specification through temporal queries as a central part of the interface.

\subsection{Interactive Tools for ML Model Analysis}
\label{sec:related-subgroups}

Supporting ML practitioners in reasoning about and improving models has been a widely-studied problem in human-computer interaction and data visualization~\cite{Hohman2019}. 
Most closely related to our work are tools that help users navigate AutoML modeling results~\cite{ono2020pipelineprofiler,santos_visus_2019} and tools to evaluate and adjust data labels based on model behavior~\cite{amershi_modeltracker_2015,bhattacharya_exmos_2024,fiebrink_human_2011}. 
In particular, Visus~\cite{santos_visus_2019} and EXMOS~\cite{bhattacharya_exmos_2024} both allow users to configure the model specification to some degree before evaluation. 
Unlike these tools, however, Tempo directly supports event data, making it applicable to many temporal prediction problems where it is otherwise challenging to define specifications.% making it easier to define specifications with new temporal aggregations on-the-fly.

Recently, model interpretation and evaluation tools have increasingly adopted \textit{subgroup-level} (sometimes also called slice-based or rule-based) analyses of model behavior. 
Subgroup analysis originates from data mining, in which classification and frequent itemset algorithms are applied to find data subgroups with interesting distributions of a given metric~\cite{herrera_overview_2011}.
Several slicing tools are aimed toward ML model analysis, mining data slices with higher error rates than average~\cite{chung_automated_2020,eyuboglu_domino_2022}.
Visual analytics tools such as SliceTeller~\cite{zhang_sliceteller_2022}, Zeno~\cite{cabrera_zeno_2023}, and others~\cite{kahng_visual_2016,zhang_manifold_2019} have utilized discovered and manually-curated subgroups to help data scientists characterize model errors.
Our system extends these workflows by allowing the user to define custom metrics within and across model specifications, interactively edit and evaluate rules, and visualize subgroup feature values across timesteps.

Few existing ML tools have as their primary goal the development and refinement of model specifications. Amershi et al.~\cite{amershi_examining_2010} explore how helping end-user ML creators understand how target variables and labeling schemes may or may not support their needs, but their system is tailored towards small-scale concept learning rather than predictive modeling at scale. Cashman et al.~\cite{cashman_user-based_2019} introduce the concept of exploratory model analysis, similar to Tempo's workflow but without the feature extraction and subgroup evaluation steps. Finally, Dingen et al.'s RegressionExplorer system~\cite{dingen_regressionexplorer_2019} allows clinicians to evaluate model specifications on non-temporal data using handcrafted subgroups. These systems demonstrate the potential for interactive model specification tools to improve the quality and applicability of resultant models; our work expands upon their ideas to address the unique challenges of temporal models and decision support.