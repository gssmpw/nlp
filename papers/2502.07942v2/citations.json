[
  {
    "index": 0,
    "papers": [
      {
        "key": "zhou2023webarena",
        "author": "Zhou, Shuyan and Xu, Frank F and Zhu, Hao and Zhou, Xuhui and Lo, Robert and Sridhar, Abishek and Cheng, Xianyi and Ou, Tianyue and Bisk, Yonatan and Fried, Daniel and others",
        "title": "Webarena: A realistic web environment for building autonomous agents"
      },
      {
        "key": "deng2023mind2web",
        "author": "Xiang Deng and Yu Gu and Boyuan Zheng and Shijie Chen and Samuel Stevens and Boshi Wang and Huan Sun and Yu Su",
        "title": "Mind2Web: Towards a Generalist Agent for the Web"
      },
      {
        "key": "yao2023webshop",
        "author": "Shunyu Yao and Howard Chen and John Yang and Karthik Narasimhan",
        "title": "WebShop: Towards Scalable Real-World Web Interaction with Grounded Language Agents"
      },
      {
        "key": "pan2024webcanvas",
        "author": "Yichen Pan and Dehan Kong and Sida Zhou and Cheng Cui and Yifei Leng and Bing Jiang and Hangyu Liu and Yanyi Shang and Shuyan Zhou and Tongshuang Wu and Zhengyang Wu",
        "title": "WebCanvas: Benchmarking Web Agents in Online Environments"
      },
      {
        "key": "levy2024stwebagentbench",
        "author": "Ido Levy and Ben Wiesel and Sami Marreed and Alon Oved and Avi Yaeli and Segev Shlomov",
        "title": "ST-WebAgentBench: A Benchmark for Evaluating Safety and Trustworthiness in Web Agents"
      },
      {
        "key": "dechezelles2024browsergym",
        "author": "Thibault Le Sellier De Chezelles and Maxime Gasse and Alexandre Drouin and Massimo Caccia and L\u00e9o Boisvert and Megh Thakkar and Tom Marty and Rim Assouel and Sahar Omidi Shayegan and Lawrence Keunho Jang and Xing Han L\u00f9 and Ori Yoran and Dehan Kong and Frank F. Xu and Siva Reddy and Quentin Cappart and Graham Neubig and Ruslan Salakhutdinov and Nicolas Chapados and Alexandre Lacoste",
        "title": "The BrowserGym Ecosystem for Web Agent Research"
      }
    ]
  },
  {
    "index": 1,
    "papers": [
      {
        "key": "koh2024tree",
        "author": "Koh, Jing Yu and McAleer, Stephen and Fried, Daniel and Salakhutdinov, Ruslan",
        "title": "Tree search for language model agents"
      },
      {
        "key": "putta2024agentq",
        "author": "Pranav Putta and Edmund Mills and Naman Garg and Sumeet Motwani and Chelsea Finn and Divyansh Garg and Rafael Rafailov",
        "title": "Agent Q: Advanced Reasoning and Learning for Autonomous AI Agents"
      },
      {
        "key": "yu2025exact",
        "author": "Xiao Yu and Baolin Peng and Vineeth Vajipey and Hao Cheng and Michel Galley and Jianfeng Gao and Zhou Yu",
        "title": "ExACT: Teaching AI Agents to Explore with Reflective-MCTS and Exploratory Learning"
      }
    ]
  },
  {
    "index": 2,
    "papers": [
      {
        "key": "Gou_2021",
        "author": "Gou, Jianping and Yu, Baosheng and Maybank, Stephen J. and Tao, Dacheng",
        "title": "Knowledge Distillation: A Survey"
      },
      {
        "key": "xu2024survey",
        "author": "Xiaohan Xu and Ming Li and Chongyang Tao and Tao Shen and Reynold Cheng and Jinyang Li and Can Xu and Dacheng Tao and Tianyi Zhou",
        "title": "A Survey on Knowledge Distillation of Large Language Models"
      }
    ]
  },
  {
    "index": 3,
    "papers": [
      {
        "key": "hinton2015distilling",
        "author": "Geoffrey Hinton and Oriol Vinyals and Jeff Dean",
        "title": "Distilling the Knowledge in a Neural Network"
      },
      {
        "key": "anand2023gpt4all",
        "author": "Anand, Yuvanesh and Nussbaum, Zach and Duderstadt, Brandon and Schmidt, Benjamin and Mulyar, Andriy",
        "title": "GPT4All: Training an Assistant-style Chatbot with Large Scale Data\nDistillation from GPT-3.5-Turbo"
      },
      {
        "key": "hsieh2023distilling",
        "author": "Cheng-Yu Hsieh and Chun-Liang Li and Chih-Kuan Yeh and Hootan Nakhost and Yasuhisa Fujii and Alexander Ratner and Ranjay Krishna and Chen-Yu Lee and Tomas Pfister",
        "title": "Distilling Step-by-Step! Outperforming Larger Language Models with Less Training Data and Smaller Model Sizes"
      }
    ]
  },
  {
    "index": 4,
    "papers": [
      {
        "key": "yin2024agent",
        "author": "Yin, Da and Brahman, Faeze and Ravichander, Abhilasha and Chandu, Khyathi and Chang, Kai-Wei and Choi, Yejin and Lin, Bill Yuchen",
        "title": "Agent lumos: Unified and modular training for open-source language agents"
      },
      {
        "key": "hong2024cogagent",
        "author": "Hong, Wenyi and Wang, Weihan and Lv, Qingsong and Xu, Jiazheng and Yu, Wenmeng and Ji, Junhui and Wang, Yan and Wang, Zihan and Dong, Yuxiao and Ding, Ming and others",
        "title": "Cogagent: A visual language model for gui agents"
      },
      {
        "key": "lai2024autowebglm",
        "author": "Lai, Hanyu and Liu, Xiao and Iong, Iat Long and Yao, Shuntian and Chen, Yuxuan and Shen, Pengbo and Yu, Hao and Zhang, Hanchen and Zhang, Xiaohan and Dong, Yuxiao and others",
        "title": "AutoWebGLM: A Large Language Model-based Web Navigating Agent"
      }
    ]
  },
  {
    "index": 5,
    "papers": [
      {
        "key": "Gou_2021",
        "author": "Gou, Jianping and Yu, Baosheng and Maybank, Stephen J. and Tao, Dacheng",
        "title": "Knowledge Distillation: A Survey"
      },
      {
        "key": "xu2024survey",
        "author": "Xiaohan Xu and Ming Li and Chongyang Tao and Tao Shen and Reynold Cheng and Jinyang Li and Can Xu and Dacheng Tao and Tianyi Zhou",
        "title": "A Survey on Knowledge Distillation of Large Language Models"
      }
    ]
  },
  {
    "index": 6,
    "papers": [
      {
        "key": "anand2023gpt4all",
        "author": "Anand, Yuvanesh and Nussbaum, Zach and Duderstadt, Brandon and Schmidt, Benjamin and Mulyar, Andriy",
        "title": "GPT4All: Training an Assistant-style Chatbot with Large Scale Data\nDistillation from GPT-3.5-Turbo"
      },
      {
        "key": "hsieh2023distilling",
        "author": "Cheng-Yu Hsieh and Chun-Liang Li and Chih-Kuan Yeh and Hootan Nakhost and Yasuhisa Fujii and Alexander Ratner and Ranjay Krishna and Chen-Yu Lee and Tomas Pfister",
        "title": "Distilling Step-by-Step! Outperforming Larger Language Models with Less Training Data and Smaller Model Sizes"
      }
    ]
  },
  {
    "index": 7,
    "papers": [
      {
        "key": "yin2024agent",
        "author": "Yin, Da and Brahman, Faeze and Ravichander, Abhilasha and Chandu, Khyathi and Chang, Kai-Wei and Choi, Yejin and Lin, Bill Yuchen",
        "title": "Agent lumos: Unified and modular training for open-source language agents"
      },
      {
        "key": "hong2024cogagent",
        "author": "Hong, Wenyi and Wang, Weihan and Lv, Qingsong and Xu, Jiazheng and Yu, Wenmeng and Ji, Junhui and Wang, Yan and Wang, Zihan and Dong, Yuxiao and Ding, Ming and others",
        "title": "Cogagent: A visual language model for gui agents"
      },
      {
        "key": "lai2024autowebglm",
        "author": "Lai, Hanyu and Liu, Xiao and Iong, Iat Long and Yao, Shuntian and Chen, Yuxuan and Shen, Pengbo and Yu, Hao and Zhang, Hanchen and Zhang, Xiaohan and Dong, Yuxiao and others",
        "title": "AutoWebGLM: A Large Language Model-based Web Navigating Agent"
      }
    ]
  }
]