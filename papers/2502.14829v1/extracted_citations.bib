@inproceedings{atanasova2023faithfulness,
  author       = {Pepa Atanasova and
                  Oana{-}Maria Camburu and
                  Christina Lioma and
                  Thomas Lukasiewicz and
                  Jakob Grue Simonsen and
                  Isabelle Augenstein},
  editor       = {Anna Rogers and
                  Jordan L. Boyd{-}Graber and
                  Naoaki Okazaki},
  title        = {Faithfulness Tests for Natural Language Explanations},
  booktitle    = {Proceedings of the 61st Annual Meeting of the Association for Computational
                  Linguistics (Volume 2: Short Papers), {ACL} 2023, Toronto, Canada,
                  July 9-14, 2023},
  pages        = {283--294},
  publisher    = {Association for Computational Linguistics},
  year         = {2023},
  url          = {https://doi.org/10.18653/v1/2023.acl-short.25},
  doi          = {10.18653/V1/2023.ACL-SHORT.25},
  timestamp    = {Sun, 19 Jan 2025 13:22:05 +0100},
  biburl       = {https://dblp.org/rec/conf/acl/AtanasovaCLLSA23.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{bao2024llms,
author       = {Guangsheng Bao and
                  Hongbo Zhang and
                  Cunxiang Wang and
                  Linyi Yang and
                  Yue Zhang},
  editor       = {Owen Rambow and
                  Leo Wanner and
                  Marianna Apidianaki and
                  Hend Al{-}Khalifa and
                  Barbara Di Eugenio and
                  Steven Schockaert},
  title        = {How Likely Do LLMs with CoT Mimic Human Reasoning?},
  booktitle    = {Proceedings of the 31st International Conference on Computational
                  Linguistics, {COLING} 2025, Abu Dhabi, UAE, January 19-24, 2025},
  pages        = {7831--7850},
  publisher    = {Association for Computational Linguistics},
  year         = {2025},
  url          = {https://aclanthology.org/2025.coling-main.524/},
  journal = {COLING},
  timestamp    = {Tue, 28 Jan 2025 16:22:21 +0100},
  biburl       = {https://dblp.org/rec/conf/coling/BaoZWY025.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{bentham2024chain,
  title={Chain-of-Thought Unfaithfulness as Disguised Accuracy},
  author={Bentham, Oliver and Stringham, Nathan and Marasovi{\'c}, Ana},
  journal={arXiv preprint arXiv:2402.14897},
  year={2024}
}

@inproceedings{biran2024hopping,
  author       = {Eden Biran and
                  Daniela Gottesman and
                  Sohee Yang and
                  Mor Geva and
                  Amir Globerson},
  editor       = {Yaser Al{-}Onaizan and
                  Mohit Bansal and
                  Yun{-}Nung Chen},
  title        = {Hopping Too Late: Exploring the Limitations of Large Language Models
                  on Multi-Hop Queries},
  booktitle    = {Proceedings of the 2024 Conference on Empirical Methods in Natural
                  Language Processing, {EMNLP} 2024, Miami, FL, USA, November 12-16,
                  2024},
  pages        = {14113--14130},
  publisher    = {Association for Computational Linguistics},
  year         = {2024},
  url          = {https://aclanthology.org/2024.emnlp-main.781},
  timestamp    = {Thu, 14 Nov 2024 17:20:55 +0100},
  biburl       = {https://dblp.org/rec/conf/emnlp/BiranGYGG24.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{camburu2020adversarial,
  author       = {Oana{-}Maria Camburu and
                  Brendan Shillingford and
                  Pasquale Minervini and
                  Thomas Lukasiewicz and
                  Phil Blunsom},
  editor       = {Dan Jurafsky and
                  Joyce Chai and
                  Natalie Schluter and
                  Joel R. Tetreault},
  title        = {Make Up Your Mind! Adversarial Generation of Inconsistent Natural
                  Language Explanations},
  booktitle    = {Proceedings of the 58th Annual Meeting of the Association for Computational
                  Linguistics, {ACL} 2020, Online, July 5-10, 2020},
  pages        = {4157--4165},
  publisher    = {Association for Computational Linguistics},
  year         = {2020},
  url          = {https://doi.org/10.18653/v1/2020.acl-main.382},
  doi          = {10.18653/V1/2020.ACL-MAIN.382},
  timestamp    = {Fri, 06 Aug 2021 00:40:55 +0200},
  biburl       = {https://dblp.org/rec/conf/acl/CamburuSMLB20.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{deng2024explicit,
  title={From explicit cot to implicit cot: Learning to internalize cot step by step},
  author={Deng, Yuntian and Choi, Yejin and Shieber, Stuart},
  journal={arXiv preprint arXiv:2405.14838},
  year={2024}
}

@inproceedings{fu2023complexity,
  author       = {Yao Fu and
                  Hao Peng and
                  Ashish Sabharwal and
                  Peter Clark and
                  Tushar Khot},
  title        = {Complexity-Based Prompting for Multi-step Reasoning},
  booktitle    = {The Eleventh International Conference on Learning Representations,
                  {ICLR} 2023, Kigali, Rwanda, May 1-5, 2023},
  publisher    = {OpenReview.net},
  year         = {2023},
  url          = {https://openreview.net/forum?id=yf1icZHC-l9},
  timestamp    = {Wed, 24 Jul 2024 16:50:33 +0200},
  biburl       = {https://dblp.org/rec/conf/iclr/FuPSCK23.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{fu2023specializing,
  author       = {Yao Fu and
                  Hao Peng and
                  Litu Ou and
                  Ashish Sabharwal and
                  Tushar Khot},
  editor       = {Andreas Krause and
                  Emma Brunskill and
                  Kyunghyun Cho and
                  Barbara Engelhardt and
                  Sivan Sabato and
                  Jonathan Scarlett},
  title        = {Specializing Smaller Language Models towards Multi-Step Reasoning},
  booktitle    = {International Conference on Machine Learning, {ICML} 2023, 23-29 July
                  2023, Honolulu, Hawaii, {USA}},
  series       = {Proceedings of Machine Learning Research},
  volume       = {202},
  pages        = {10421--10430},
  publisher    = {{PMLR}},
  year         = {2023},
  url          = {https://proceedings.mlr.press/v202/fu23d.html},
  timestamp    = {Mon, 26 Feb 2024 10:36:58 +0100},
  biburl       = {https://dblp.org/rec/conf/icml/FuPOSK23.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{jacovi-goldberg-2020-towards,
    title = "Towards Faithfully Interpretable {NLP} Systems: How Should We Define and Evaluate Faithfulness?",
    author = "Jacovi, Alon  and
      Goldberg, Yoav",
    editor = "Jurafsky, Dan  and
      Chai, Joyce  and
      Schluter, Natalie  and
      Tetreault, Joel",
    booktitle = "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics",
    month = jul,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2020.acl-main.386",
    doi = "10.18653/v1/2020.acl-main.386",
    pages = "4198--4205",
    abstract = "With the growing popularity of deep-learning based NLP models, comes a need for interpretable systems. But what is interpretability, and what constitutes a high-quality interpretation? In this opinion piece we reflect on the current state of interpretability evaluation research. We call for more clearly differentiating between different desired criteria an interpretation should satisfy, and focus on the faithfulness criteria. We survey the literature with respect to faithfulness evaluation, and arrange the current approaches around three assumptions, providing an explicit form to how faithfulness is {``}defined{''} by the community. We provide concrete guidelines on how evaluation of interpretation methods should and should not be conducted. Finally, we claim that the current binary definition for faithfulness sets a potentially unrealistic bar for being considered faithful. We call for discarding the binary notion of faithfulness in favor of a more graded one, which we believe will be of greater practical utility.",
}

@inproceedings{joshi2023useful,
  author       = {Brihi Joshi and
                  Ziyi Liu and
                  Sahana Ramnath and
                  Aaron Chan and
                  Zhewei Tong and
                  Shaoliang Nie and
                  Qifan Wang and
                  Yejin Choi and
                  Xiang Ren},
  editor       = {Anna Rogers and
                  Jordan L. Boyd{-}Graber and
                  Naoaki Okazaki},
  title        = {Are Machine Rationales (Not) Useful to Humans? Measuring and Improving
                  Human Utility of Free-text Rationales},
  booktitle    = {Proceedings of the 61st Annual Meeting of the Association for Computational
                  Linguistics (Volume 1: Long Papers), {ACL} 2023, Toronto, Canada,
                  July 9-14, 2023},
  pages        = {7103--7128},
  publisher    = {Association for Computational Linguistics},
  year         = {2023},
  url          = {https://doi.org/10.18653/v1/2023.acl-long.392},
  doi          = {10.18653/V1/2023.ACL-LONG.392},
  timestamp    = {Tue, 29 Oct 2024 08:50:32 +0100},
  biburl       = {https://dblp.org/rec/conf/acl/JoshiLRCTNW0023.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{kim2021presupposition,
  author       = {Najoung Kim and
                  Ellie Pavlick and
                  Burcu Karagol Ayan and
                  Deepak Ramachandran},
  editor       = {Chengqing Zong and
                  Fei Xia and
                  Wenjie Li and
                  Roberto Navigli},
  title        = {Which Linguist Invented the Lightbulb? Presupposition Verification
                  for Question-Answering},
  booktitle    = {Proceedings of the 59th Annual Meeting of the Association for Computational
                  Linguistics and the 11th International Joint Conference on Natural
                  Language Processing, {ACL/IJCNLP} 2021, (Volume 1: Long Papers), Virtual
                  Event, August 1-6, 2021},
  pages        = {3932--3945},
  publisher    = {Association for Computational Linguistics},
  year         = {2021},
  url          = {https://doi.org/10.18653/v1/2021.acl-long.304},
  doi          = {10.18653/V1/2021.ACL-LONG.304},
  timestamp    = {Sun, 19 Jan 2025 13:20:29 +0100},
  biburl       = {https://dblp.org/rec/conf/acl/KimPAR20.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{kim2023questionable,
  author       = {Najoung Kim and
                  Phu Mon Htut and
                  Samuel R. Bowman and
                  Jackson Petty},
  editor       = {Anna Rogers and
                  Jordan L. Boyd{-}Graber and
                  Naoaki Okazaki},
  title        = {(QA){\({^2}\)}: Question Answering with Questionable Assumptions},
  booktitle    = {Proceedings of the 61st Annual Meeting of the Association for Computational
                  Linguistics (Volume 1: Long Papers), {ACL} 2023, Toronto, Canada,
                  July 9-14, 2023},
  pages        = {8466--8487},
  publisher    = {Association for Computational Linguistics},
  year         = {2023},
  url          = {https://doi.org/10.18653/v1/2023.acl-long.472},
  doi          = {10.18653/V1/2023.ACL-LONG.472},
  timestamp    = {Thu, 10 Aug 2023 12:35:53 +0200},
  biburl       = {https://dblp.org/rec/conf/acl/KimHBP23.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{kojima2022large,
 author = {Kojima, Takeshi and Gu, Shixiang (Shane) and Reid, Machel and Matsuo, Yutaka and Iwasawa, Yusuke},
 booktitle = {Advances in Neural Information Processing Systems},
 journal={Advances in neural information processing systems},
 editor = {S. Koyejo and S. Mohamed and A. Agarwal and D. Belgrave and K. Cho and A. Oh},
 pages = {22199--22213},
 publisher = {Curran Associates, Inc.},
 title = {Large Language Models are Zero-Shot Reasoners},
 url = {https://proceedings.neurips.cc/paper_files/paper/2022/file/8bb0d291acd4acf06ef112099c16f326-Paper-Conference.pdf},
 volume = {35},
 year = {2022}
}

@article{lanham2023measuring,
  title={Measuring faithfulness in chain-of-thought reasoning},
  author={Lanham, Tamera and Chen, Anna and Radhakrishnan, Ansh and Steiner, Benoit and Denison, Carson and Hernandez, Danny and Li, Dustin and Durmus, Esin and Hubinger, Evan and Kernion, Jackson and others},
  journal={arXiv preprint arXiv:2307.13702},
  year={2023}
}

@article{madsen2024self,
  title={Are self-explanations from large language models faithful},
  author={Madsen, Andreas and Chandar, Sarath and Reddy, Siva},
  journal={ArXiv, abs/2401.07927},
  pages={19},
  year={2024}
}

@article{minder2024controllable,
  title={Controllable Context Sensitivity and the Knob Behind It},
  author={Minder, Julian and Du, Kevin and Stoehr, Niklas and Monea, Giovanni and Wendler, Chris and West, Robert and Cotterell, Ryan},
  journal={arXiv preprint arXiv:2411.07404},
  year={2024}
}

@inproceedings{neeman-etal-2023-disentqa,
    title = "{D}isent{QA}: Disentangling Parametric and Contextual Knowledge with Counterfactual Question Answering",
    author = "Neeman, Ella  and
      Aharoni, Roee  and
      Honovich, Or  and
      Choshen, Leshem  and
      Szpektor, Idan  and
      Abend, Omri",
    editor = "Rogers, Anna  and
      Boyd-Graber, Jordan  and
      Okazaki, Naoaki",
    booktitle = "Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = jul,
    year = "2023",
    address = "Toronto, Canada",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.acl-long.559",
    doi = "10.18653/v1/2023.acl-long.559",
    pages = "10056--10070",
    abstract = "Question answering models commonly have access to two sources of {``}knowledge{''} during inference time: (1) parametric knowledge - the factual knowledge encoded in the model weights, and (2) contextual knowledge - external knowledge (e.g., a Wikipedia passage) given to the model to generate a grounded answer. Having these two sources of knowledge entangled together is a core issue for generative QA models as it is unclear whether the answer stems from the given non-parametric knowledge or not. This unclarity has implications on issues of trust, interpretability and factuality. In this work, we propose a new paradigm in which QA models are trained to disentangle the two sources of knowledge. Using counterfactual data augmentation, we introduce a model that predicts two answers for a given question: one based on given contextual knowledge and one based on parametric knowledge. Our experiments on the Natural Questions dataset show that this approach improves the performance of QA models by making them more robust to knowledge conflicts between the two knowledge sources, while generating useful disentangled answers.",
}

@article{peng2302check,
  title={Check your facts and try again: Improving large language models with external knowledge and automated feedback. CoRR, abs/2302.12813, 2023. doi: 10.48550},
  author={Peng, Baolin and Galley, Michel and He, Pengcheng and Cheng, Hao and Xie, Yujia and Hu, Yu and Huang, Qiuyuan and Liden, Lars and Yu, Zhou and Chen, Weizhu and others},
  journal={arXiv preprint arXiv.2302.12813},
  year={2023},
  volume={10}
}

@article{pfau2024hidden,
  author       = {Jacob Pfau and
                  William Merrill and
                  Samuel R. Bowman},
  title        = {Let's Think Dot by Dot: Hidden Computation in Transformer Language
                  Models},
  journal      = {CoRR},
  volume       = {abs/2404.15758},
  year         = {2024},
  url          = {https://doi.org/10.48550/arXiv.2404.15758},
  doi          = {10.48550/ARXIV.2404.15758},
  eprinttype    = {arXiv},
  eprint       = {2404.15758},
  timestamp    = {Mon, 03 Jun 2024 20:47:54 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/abs-2404-15758.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{roger2023preventing,
  author       = {Fabien Roger and
                  Ryan Greenblatt},
  title        = {Preventing Language Models From Hiding Their Reasoning},
  journal      = {CoRR},
  volume       = {abs/2310.18512},
  year         = {2023},
  url          = {https://doi.org/10.48550/arXiv.2310.18512},
  doi          = {10.48550/ARXIV.2310.18512},
  eprinttype    = {arXiv},
  eprint       = {2310.18512},
  timestamp    = {Thu, 02 Nov 2023 17:30:29 +0100},
  biburl       = {https://dblp.org/rec/journals/corr/abs-2310-18512.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{sedova2024ambiguity,
  author       = {Anastasiia Sedova and
                  Robert Litschko and
                  Diego Frassinelli and
                  Benjamin Roth and
                  Barbara Plank},
  editor       = {Yaser Al{-}Onaizan and
                  Mohit Bansal and
                  Yun{-}Nung Chen},
  title        = {To Know or Not To Know? Analyzing Self-Consistency of Large Language
                  Models under Ambiguity},
  booktitle    = {Findings of the Association for Computational Linguistics: {EMNLP}
                  2024, Miami, Florida, USA, November 12-16, 2024},
  pages        = {17203--17217},
  publisher    = {Association for Computational Linguistics},
  year         = {2024},
  url          = {https://aclanthology.org/2024.findings-emnlp.1003},
  timestamp    = {Mon, 18 Nov 2024 09:06:00 +0100},
  biburl       = {https://dblp.org/rec/conf/emnlp/SedovaLF0P24.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{siegel2024probabilities,
  author       = {Noah Y. Siegel and
                  Oana{-}Maria Camburu and
                  Nicolas Heess and
                  Mar{\'{\i}}a P{\'{e}}rez{-}Ortiz},
  editor       = {Lun{-}Wei Ku and
                  Andre Martins and
                  Vivek Srikumar},
  title        = {The Probabilities Also Matter: {A} More Faithful Metric for Faithfulness
                  of Free-Text Explanations in Large Language Models},
  booktitle    = {Proceedings of the 62nd Annual Meeting of the Association for Computational
                  Linguistics, {ACL} 2024 - Short Papers, Bangkok, Thailand, August
                  11-16, 2024},
  pages        = {530--546},
  publisher    = {Association for Computational Linguistics},
  year         = {2024},
  url          = {https://aclanthology.org/2024.acl-short.49},
  timestamp    = {Fri, 11 Oct 2024 22:05:02 +0200},
  biburl       = {https://dblp.org/rec/conf/acl/SiegelCHP24.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{simhi2024distinguishing,
  title={Distinguishing Ignorance from Error in LLM Hallucinations},
  author={Simhi, Adi and Herzig, Jonathan and Szpektor, Idan and Belinkov, Yonatan},
  journal={arXiv preprint arXiv:2410.22071},
  year={2024}
}

@article{sprague2024cotmath,
  author       = {Zayne Sprague and
                  Fangcong Yin and
                  Juan Diego Rodriguez and
                  Dongwei Jiang and
                  Manya Wadhwa and
                  Prasann Singhal and
                  Xinyu Zhao and
                  Xi Ye and
                  Kyle Mahowald and
                  Greg Durrett},
  title        = {To CoT or not to CoT? Chain-of-thought helps mainly on math and symbolic
                  reasoning},
  journal      = {CoRR},
  volume       = {abs/2409.12183},
  year         = {2024},
  url          = {https://doi.org/10.48550/arXiv.2409.12183},
  doi          = {10.48550/ARXIV.2409.12183},
  eprinttype    = {arXiv},
  eprint       = {2409.12183},
  timestamp    = {Thu, 17 Oct 2024 12:28:14 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/abs-2409-12183.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{sun2023recitation,
  author       = {Zhiqing Sun and
                  Xuezhi Wang and
                  Yi Tay and
                  Yiming Yang and
                  Denny Zhou},
  title        = {Recitation-Augmented Language Models},
  booktitle    = {The Eleventh International Conference on Learning Representations,
                  {ICLR} 2023, Kigali, Rwanda, May 1-5, 2023},
  publisher    = {OpenReview.net},
  year         = {2023},
  url          = {https://openreview.net/forum?id=-cqvvvb-NkI},
  timestamp    = {Wed, 24 Jul 2024 16:50:34 +0200},
  biburl       = {https://dblp.org/rec/conf/iclr/Sun0TYZ23.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{turpin2023unfaithful,
  author       = {Miles Turpin and
                  Julian Michael and
                  Ethan Perez and
                  Samuel R. Bowman},
  editor       = {Alice Oh and
                  Tristan Naumann and
                  Amir Globerson and
                  Kate Saenko and
                  Moritz Hardt and
                  Sergey Levine},
  title        = {Language Models Don't Always Say What They Think: Unfaithful Explanations
                  in Chain-of-Thought Prompting},
  booktitle    = {Advances in Neural Information Processing Systems 36: Annual Conference
                  on Neural Information Processing Systems 2023, NeurIPS 2023, New Orleans,
                  LA, USA, December 10 - 16, 2023},
  year         = {2023},
  url          = {http://papers.nips.cc/paper\_files/paper/2023/hash/ed3fea9033a80fea1376299fa7863f4a-Abstract-Conference.html},
  timestamp    = {Fri, 01 Mar 2024 16:26:21 +0100},
  biburl       = {https://dblp.org/rec/conf/nips/TurpinMPB23.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{yang2024latently,
  author       = {Sohee Yang and
                  Elena Gribovskaya and
                  Nora Kassner and
                  Mor Geva and
                  Sebastian Riedel},
  editor       = {Lun{-}Wei Ku and
                  Andre Martins and
                  Vivek Srikumar},
  title        = {Do Large Language Models Latently Perform Multi-Hop Reasoning?},
  booktitle    = {Proceedings of the 62nd Annual Meeting of the Association for Computational
                  Linguistics (Volume 1: Long Papers), {ACL} 2024, Bangkok, Thailand,
                  August 11-16, 2024},
  pages        = {10210--10229},
  publisher    = {Association for Computational Linguistics},
  year         = {2024},
  url          = {https://doi.org/10.18653/v1/2024.acl-long.550},
  doi          = {10.18653/V1/2024.ACL-LONG.550},
  timestamp    = {Tue, 24 Sep 2024 10:55:52 +0200},
  biburl       = {https://dblp.org/rec/conf/acl/YangGKG024.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{yao2024patching,
  author       = {Wei Jie Yeo and
                  Ranjan Satapathy and
                  Erik Cambria},
  title        = {Towards Faithful Natural Language Explanations: {A} Study Using Activation
                  Patching in Large Language Models},
  journal      = {CoRR},
  volume       = {abs/2410.14155},
  year         = {2024},
  url          = {https://doi.org/10.48550/arXiv.2410.14155},
  doi          = {10.48550/ARXIV.2410.14155},
  eprinttype    = {arXiv},
  eprint       = {2410.14155},
  timestamp    = {Fri, 29 Nov 2024 13:14:57 +0100},
  biburl       = {https://dblp.org/rec/journals/corr/abs-2410-14155.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{zhang2024snowball,
  author       = {Muru Zhang and
                  Ofir Press and
                  William Merrill and
                  Alisa Liu and
                  Noah A. Smith},
  title        = {How Language Model Hallucinations Can Snowball},
  booktitle    = {Forty-first International Conference on Machine Learning, {ICML} 2024,
                  Vienna, Austria, July 21-27, 2024},
  publisher    = {OpenReview.net},
  year         = {2024},
  url          = {https://openreview.net/forum?id=FPlaQyAGHu},
  timestamp    = {Mon, 02 Sep 2024 16:55:26 +0200},
  biburl       = {https://dblp.org/rec/conf/icml/ZhangPMLS24.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{zheng2023does,
  title={Why Does ChatGPT Fall Short in Providing Truthful Answers?},
  author={Zheng, Shen and Huang, Jie and Chang, Kevin Chen-Chuan},
  journal={arXiv preprint arXiv:2304.10513},
  year={2023}
}

@inproceedings{zhou2023complex,
  author       = {Denny Zhou and
                  Nathanael Sch{\"{a}}rli and
                  Le Hou and
                  Jason Wei and
                  Nathan Scales and
                  Xuezhi Wang and
                  Dale Schuurmans and
                  Claire Cui and
                  Olivier Bousquet and
                  Quoc V. Le and
                  Ed H. Chi},
  title        = {Least-to-Most Prompting Enables Complex Reasoning in Large Language
                  Models},
  booktitle    = {The Eleventh International Conference on Learning Representations,
                  {ICLR} 2023, Kigali, Rwanda, May 1-5, 2023},
  publisher    = {OpenReview.net},
  year         = {2023},
  url          = {https://openreview.net/forum?id=WZH7099tgfM},
  timestamp    = {Wed, 24 Jul 2024 16:50:34 +0200},
  biburl       = {https://dblp.org/rec/conf/iclr/ZhouSHWS0SCBLC23.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

