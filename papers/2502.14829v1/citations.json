[
  {
    "index": 0,
    "papers": [
      {
        "key": "zhou2023complex",
        "author": "Denny Zhou and\nNathanael Sch{\\\"{a}}rli and\nLe Hou and\nJason Wei and\nNathan Scales and\nXuezhi Wang and\nDale Schuurmans and\nClaire Cui and\nOlivier Bousquet and\nQuoc V. Le and\nEd H. Chi",
        "title": "Least-to-Most Prompting Enables Complex Reasoning in Large Language\nModels"
      },
      {
        "key": "fu2023complexity",
        "author": "Yao Fu and\nHao Peng and\nAshish Sabharwal and\nPeter Clark and\nTushar Khot",
        "title": "Complexity-Based Prompting for Multi-step Reasoning"
      },
      {
        "key": "sprague2024cotmath",
        "author": "Zayne Sprague and\nFangcong Yin and\nJuan Diego Rodriguez and\nDongwei Jiang and\nManya Wadhwa and\nPrasann Singhal and\nXinyu Zhao and\nXi Ye and\nKyle Mahowald and\nGreg Durrett",
        "title": "To CoT or not to CoT? Chain-of-thought helps mainly on math and symbolic\nreasoning"
      }
    ]
  },
  {
    "index": 1,
    "papers": [
      {
        "key": "pfau2024hidden",
        "author": "Jacob Pfau and\nWilliam Merrill and\nSamuel R. Bowman",
        "title": "Let's Think Dot by Dot: Hidden Computation in Transformer Language\nModels"
      },
      {
        "key": "biran2024hopping",
        "author": "Eden Biran and\nDaniela Gottesman and\nSohee Yang and\nMor Geva and\nAmir Globerson",
        "title": "Hopping Too Late: Exploring the Limitations of Large Language Models\non Multi-Hop Queries"
      }
    ]
  },
  {
    "index": 2,
    "papers": [
      {
        "key": "kojima2022large",
        "author": "Kojima, Takeshi and Gu, Shixiang (Shane) and Reid, Machel and Matsuo, Yutaka and Iwasawa, Yusuke",
        "title": "Large Language Models are Zero-Shot Reasoners"
      },
      {
        "key": "fu2023specializing",
        "author": "Yao Fu and\nHao Peng and\nLitu Ou and\nAshish Sabharwal and\nTushar Khot",
        "title": "Specializing Smaller Language Models towards Multi-Step Reasoning"
      },
      {
        "key": "sun2023recitation",
        "author": "Zhiqing Sun and\nXuezhi Wang and\nYi Tay and\nYiming Yang and\nDenny Zhou",
        "title": "Recitation-Augmented Language Models"
      }
    ]
  },
  {
    "index": 3,
    "papers": [
      {
        "key": "jacovi-goldberg-2020-towards",
        "author": "Jacovi, Alon  and\nGoldberg, Yoav",
        "title": "Towards Faithfully Interpretable {NLP} Systems: How Should We Define and Evaluate Faithfulness?"
      },
      {
        "key": "bao2024llms",
        "author": "Guangsheng Bao and\nHongbo Zhang and\nCunxiang Wang and\nLinyi Yang and\nYue Zhang",
        "title": "How Likely Do LLMs with CoT Mimic Human Reasoning?"
      }
    ]
  },
  {
    "index": 4,
    "papers": [
      {
        "key": "camburu2020adversarial",
        "author": "Oana{-}Maria Camburu and\nBrendan Shillingford and\nPasquale Minervini and\nThomas Lukasiewicz and\nPhil Blunsom",
        "title": "Make Up Your Mind! Adversarial Generation of Inconsistent Natural\nLanguage Explanations"
      },
      {
        "key": "lanham2023measuring",
        "author": "Lanham, Tamera and Chen, Anna and Radhakrishnan, Ansh and Steiner, Benoit and Denison, Carson and Hernandez, Danny and Li, Dustin and Durmus, Esin and Hubinger, Evan and Kernion, Jackson and others",
        "title": "Measuring faithfulness in chain-of-thought reasoning"
      },
      {
        "key": "madsen2024self",
        "author": "Madsen, Andreas and Chandar, Sarath and Reddy, Siva",
        "title": "Are self-explanations from large language models faithful"
      },
      {
        "key": "sedova2024ambiguity",
        "author": "Anastasiia Sedova and\nRobert Litschko and\nDiego Frassinelli and\nBenjamin Roth and\nBarbara Plank",
        "title": "To Know or Not To Know? Analyzing Self-Consistency of Large Language\nModels under Ambiguity"
      }
    ]
  },
  {
    "index": 5,
    "papers": [
      {
        "key": "bao2024llms",
        "author": "Guangsheng Bao and\nHongbo Zhang and\nCunxiang Wang and\nLinyi Yang and\nYue Zhang",
        "title": "How Likely Do LLMs with CoT Mimic Human Reasoning?"
      }
    ]
  },
  {
    "index": 6,
    "papers": [
      {
        "key": "joshi2023useful",
        "author": "Brihi Joshi and\nZiyi Liu and\nSahana Ramnath and\nAaron Chan and\nZhewei Tong and\nShaoliang Nie and\nQifan Wang and\nYejin Choi and\nXiang Ren",
        "title": "Are Machine Rationales (Not) Useful to Humans? Measuring and Improving\nHuman Utility of Free-text Rationales"
      }
    ]
  },
  {
    "index": 7,
    "papers": [
      {
        "key": "kim2021presupposition",
        "author": "Najoung Kim and\nEllie Pavlick and\nBurcu Karagol Ayan and\nDeepak Ramachandran",
        "title": "Which Linguist Invented the Lightbulb? Presupposition Verification\nfor Question-Answering"
      },
      {
        "key": "kim2023questionable",
        "author": "Najoung Kim and\nPhu Mon Htut and\nSamuel R. Bowman and\nJackson Petty",
        "title": "(QA){\\({^2}\\)}: Question Answering with Questionable Assumptions"
      },
      {
        "key": "zheng2023does",
        "author": "Zheng, Shen and Huang, Jie and Chang, Kevin Chen-Chuan",
        "title": "Why Does ChatGPT Fall Short in Providing Truthful Answers?"
      },
      {
        "key": "peng2302check",
        "author": "Peng, Baolin and Galley, Michel and He, Pengcheng and Cheng, Hao and Xie, Yujia and Hu, Yu and Huang, Qiuyuan and Liden, Lars and Yu, Zhou and Chen, Weizhu and others",
        "title": "Check your facts and try again: Improving large language models with external knowledge and automated feedback. CoRR, abs/2302.12813, 2023. doi: 10.48550"
      },
      {
        "key": "zhang2024snowball",
        "author": "Muru Zhang and\nOfir Press and\nWilliam Merrill and\nAlisa Liu and\nNoah A. Smith",
        "title": "How Language Model Hallucinations Can Snowball"
      }
    ]
  },
  {
    "index": 8,
    "papers": [
      {
        "key": "turpin2023unfaithful",
        "author": "Miles Turpin and\nJulian Michael and\nEthan Perez and\nSamuel R. Bowman",
        "title": "Language Models Don't Always Say What They Think: Unfaithful Explanations\nin Chain-of-Thought Prompting"
      },
      {
        "key": "roger2023preventing",
        "author": "Fabien Roger and\nRyan Greenblatt",
        "title": "Preventing Language Models From Hiding Their Reasoning"
      }
    ]
  },
  {
    "index": 9,
    "papers": [
      {
        "key": "turpin2023unfaithful",
        "author": "Miles Turpin and\nJulian Michael and\nEthan Perez and\nSamuel R. Bowman",
        "title": "Language Models Don't Always Say What They Think: Unfaithful Explanations\nin Chain-of-Thought Prompting"
      }
    ]
  },
  {
    "index": 10,
    "papers": [
      {
        "key": "neeman-etal-2023-disentqa",
        "author": "Neeman, Ella  and\nAharoni, Roee  and\nHonovich, Or  and\nChoshen, Leshem  and\nSzpektor, Idan  and\nAbend, Omri",
        "title": "{D}isent{QA}: Disentangling Parametric and Contextual Knowledge with Counterfactual Question Answering"
      },
      {
        "key": "bao2024llms",
        "author": "Guangsheng Bao and\nHongbo Zhang and\nCunxiang Wang and\nLinyi Yang and\nYue Zhang",
        "title": "How Likely Do LLMs with CoT Mimic Human Reasoning?"
      }
    ]
  },
  {
    "index": 11,
    "papers": [
      {
        "key": "kim2021presupposition",
        "author": "Najoung Kim and\nEllie Pavlick and\nBurcu Karagol Ayan and\nDeepak Ramachandran",
        "title": "Which Linguist Invented the Lightbulb? Presupposition Verification\nfor Question-Answering"
      },
      {
        "key": "kim2023questionable",
        "author": "Najoung Kim and\nPhu Mon Htut and\nSamuel R. Bowman and\nJackson Petty",
        "title": "(QA){\\({^2}\\)}: Question Answering with Questionable Assumptions"
      },
      {
        "key": "simhi2024distinguishing",
        "author": "Simhi, Adi and Herzig, Jonathan and Szpektor, Idan and Belinkov, Yonatan",
        "title": "Distinguishing Ignorance from Error in LLM Hallucinations"
      },
      {
        "key": "minder2024controllable",
        "author": "Minder, Julian and Du, Kevin and Stoehr, Niklas and Monea, Giovanni and Wendler, Chris and West, Robert and Cotterell, Ryan",
        "title": "Controllable Context Sensitivity and the Knob Behind It"
      }
    ]
  },
  {
    "index": 12,
    "papers": [
      {
        "key": "yang2024latently",
        "author": "Sohee Yang and\nElena Gribovskaya and\nNora Kassner and\nMor Geva and\nSebastian Riedel",
        "title": "Do Large Language Models Latently Perform Multi-Hop Reasoning?"
      },
      {
        "key": "deng2024explicit",
        "author": "Deng, Yuntian and Choi, Yejin and Shieber, Stuart",
        "title": "From explicit cot to implicit cot: Learning to internalize cot step by step"
      }
    ]
  },
  {
    "index": 13,
    "papers": [
      {
        "key": "lanham2023measuring",
        "author": "Lanham, Tamera and Chen, Anna and Radhakrishnan, Ansh and Steiner, Benoit and Denison, Carson and Hernandez, Danny and Li, Dustin and Durmus, Esin and Hubinger, Evan and Kernion, Jackson and others",
        "title": "Measuring faithfulness in chain-of-thought reasoning"
      },
      {
        "key": "bentham2024chain",
        "author": "Bentham, Oliver and Stringham, Nathan and Marasovi{\\'c}, Ana",
        "title": "Chain-of-Thought Unfaithfulness as Disguised Accuracy"
      },
      {
        "key": "atanasova2023faithfulness",
        "author": "Pepa Atanasova and\nOana{-}Maria Camburu and\nChristina Lioma and\nThomas Lukasiewicz and\nJakob Grue Simonsen and\nIsabelle Augenstein",
        "title": "Faithfulness Tests for Natural Language Explanations"
      },
      {
        "key": "siegel2024probabilities",
        "author": "Noah Y. Siegel and\nOana{-}Maria Camburu and\nNicolas Heess and\nMar{\\'{\\i}}a P{\\'{e}}rez{-}Ortiz",
        "title": "The Probabilities Also Matter: {A} More Faithful Metric for Faithfulness\nof Free-Text Explanations in Large Language Models"
      }
    ]
  },
  {
    "index": 14,
    "papers": [
      {
        "key": "atanasova2023faithfulness",
        "author": "Pepa Atanasova and\nOana{-}Maria Camburu and\nChristina Lioma and\nThomas Lukasiewicz and\nJakob Grue Simonsen and\nIsabelle Augenstein",
        "title": "Faithfulness Tests for Natural Language Explanations"
      },
      {
        "key": "lanham2023measuring",
        "author": "Lanham, Tamera and Chen, Anna and Radhakrishnan, Ansh and Steiner, Benoit and Denison, Carson and Hernandez, Danny and Li, Dustin and Durmus, Esin and Hubinger, Evan and Kernion, Jackson and others",
        "title": "Measuring faithfulness in chain-of-thought reasoning"
      }
    ]
  },
  {
    "index": 15,
    "papers": [
      {
        "key": "bao2024llms",
        "author": "Guangsheng Bao and\nHongbo Zhang and\nCunxiang Wang and\nLinyi Yang and\nYue Zhang",
        "title": "How Likely Do LLMs with CoT Mimic Human Reasoning?"
      }
    ]
  },
  {
    "index": 16,
    "papers": [
      {
        "key": "yao2024patching",
        "author": "Wei Jie Yeo and\nRanjan Satapathy and\nErik Cambria",
        "title": "Towards Faithful Natural Language Explanations: {A} Study Using Activation\nPatching in Large Language Models"
      }
    ]
  }
]