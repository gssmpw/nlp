\section{Conclusion and perspectives}
\label{sec:conclusion}

We adapted the ``Generalized Iterative Conditional Estimation'' (GICE), originally developed for the identification of \blueC{s}witching \blueC{h}idden Markov \blueC{m}odels to the estimation of Copula-Based Mixture Models (CBMM). GICE iteratively optimizes the forms and parameters of the marginals and copulas of the CBMM component distributions driven by data. The resulting CBMM-GICE method allows us to approach any cohort of samples by an appropriate CBMM, and find the subgroups at the same time. Thanks to the flexibility of CBMM, CBMM-GICE generally outperforms the classic mixture models identified through the EM algorithm e.g. GMM-EM, tested both on synthetic and real medical \blueC{imaging} data, where more flexibility in the distribution fit and cluster estimation is often crucial. Aside from this main contribution, this study also tackled the following tasks that have not been addressed in detail before:
\begin{enumerate}
    \item The impact of the realization time $T$ to the GICE algorithm is neglected and always set to 1 in the pioneer works \cite{zheng2020semi,derrode2016unsupervised}. The experiments on synthetic data show that a larger $T$ value can reduce the oscillation around the target CBMM at convergence, especially when facing small sample numbers. However, the choice of $T$ should balance the performance and the computational burden, since increasing $T$ means also increasing the computational time. $T$ around 10 is suggested for a cohort with clusters of around 1000 samples.
    \item The convergence of GICE is hard to prove theoretically. It has only been demonstrated indirectly via the result error ratio in \cite{zheng2020semi}. Nevertheless, we can monitor the convergence through the fitness score of the statistical distributions, such as the Kolmogorov distance applied in the experiments. \blueCN{This manual monitoring may be improved by adding a convergence control module in the algorithm.}
    %Finally, the convergence of GICE is manually monitored by plotting a fitness measure, which may be improved by adding a convergence control module in the algorithm.
    \item The GMMs are not always a good choice for fitting medical data. 
    In our study, the results of the experiments on cardiac images clustering corroborate that the CBMMs could be the most suitable model, when data subgroups are not elliptically distributed or do not follow the same distribution form (often-met situation). Indeed, GMMs are specific cases of the general CBMMs family when marginals and copulas are all chosen to be Gaussian. 
\end{enumerate}

The \blueC{CBMM-GICE} studied in this article \blueC{has potential}, but still has limits waiting to be improved in the future work. 
As a primary study, the current GICE is developed for \blueC{2D} CBMM only. \blueC{Although the variability of infarct patterns may be contained in slightly more dimensions, %\cite{mom2021fimh}, 
the present work used 2D visualization to easily focus on the clustering output. Latent spaces of more dimensions will be considered in future work focusing on the clinical application.} The challenge of extending the identification ability of GICE to higher dimension lies in the choice and the estimation of multivariate copulas, since much less multivariate copulas with analytical form are available than bivariate ones. 
%The vine-copulas \cite{czado2022vine} %\cite{sun2016c, czado2022vine} and other types of copulas \cite{mazo2015class} which construct multivariate copulas using bivariate copulas are promising as a solution for this problem. 
\greenC{The vine-copulas or neural-copulas are promising to overcome this limit\cite{sahin2022vine, FAN2024105263}.} More flexibility can be still introduced into the current CBMM. For instance by incorporating the parametric rotation of copulas for component distributions \cite{kosmidis2016model}. Also, 
by jointly estimating a simplified representation of the data and performing clustering, as in deep clustering approaches \cite{Ren_Arxiv:2022}, some of these models reach much better performance than our method on the MNIST dataset\footnote{\url{https://paperswithcode.com/sota/image-clustering-on-mnist-full}}, but without the flexible and parametric clustering offered by the copulas which is of interest for risk stratification in e.g. clinical applications. Our paper primarily focuses on the thorough evaluation of the benefits of our more flexible parametric clustering model. The adaptation of our work to the broader framework of deep clustering is not straightforward and left for future work.
