\section{Experiments and results}
\label{sec:Experiments}

\blueC{W}e consider data dimension $D=2$ and the following candidate forms for all the experiments:
\begin{itemize}
    \item[] $\H = \set{\text{Gamma, Fisk, Gaussian, T, Laplace, Beta, BetaPrime}}$,
    \item[] $\G = \set{\text{Gumble, Gaussian, Clayton, FGM, Arch12, Arch14, Product}}$.
\end{itemize}
Their PDF, CDF, and parameter details are listed in Appendix A.

\subsection{Experiments on synthetic data}
\label{sec:Experimentation on synthetic data}

This series of experiments aims to test the efficiency of the GICE for the identification of CBMMs constructed by different marginal and copula forms\blueC{, with component number $K=2$}. Some computational details that impact the performance of GICE are also illustrated and discussed in this section.

\subsubsection{Test on simulated data of Non-Gaussian CBMM}
\label{sec:Test on simulated data of Non-Gaussian CBMM}
This series of tests aims to verify the performance of GICE on non-Gaussian CBMM identification. 2000 samples were simulated from a pre-defined CBMM with non-Gaussian marginal and copulas. The model parameters are listed in the second row of Table \ref{tab:nonGauss True and estimated CBMM parameters}. Figure \ref{fig:nonGauss True PDF and labels} shows the simulated data and the cluster densities. The two clusters 
were designed to partially overlap and imitate a difficult identification situation, since clearly separated clusters are much easier to identify, and even simply using K-Means may well predict the labels.

\begin{figure}[tb]
\centering
\begin{subfigure}[t]{0.49\textwidth}
  \centering
  \includegraphics[width=0.95\textwidth]{Figures/nonGaussCBMM_truePDF.png}
  \captionsetup{width=.9\linewidth}
  \caption{True cluster densities and labels, CBMM parameters as listed in Table \ref{tab:nonGauss True and estimated CBMM parameters}}
  \label{fig:nonGauss True PDF and labels}
\end{subfigure}%
\begin{subfigure}[t]{0.49\textwidth} 
  \centering
  \includegraphics[width=0.95\textwidth]{Figures/nonGaussCBMM_estPDF.png}
  \captionsetup{width=.95\linewidth}
  \caption{Estimated cluster densities and labels (GICE \blueC{with realization time $T$}=10, GMM initialization, \blueC{100 max. iterations}).}
  \label{fig:nonGauss Estimated PDF and labels}
\end{subfigure}
\caption{Synthetic experiment \blueCN{(N=2000 samples)} to evaluate the performance of GICE on non-Gaussian CBMM identification.}
\label{fig:nonGauss CBMM PDF and labels}
\end{figure}



We tested two different initialization methods: the K-Means and the EM for GMM, and considered different realization times $T=1$ and $T=10$. 
We set a maximum of $100$ iterations for GICE to reach its convergence. The evolution of the Kolmogrorov distance between the learnt model and the empirical data distribution  with iterations is reported in 
Appendix B, Figure \ref{fig:nonGauss gof}. 
The evolution of error ratio between the predicted labels and the true ones with iterations is illustrated in 
Appendix B, Figure \ref{fig:nonGauss error ratio}. 
For these synthetic data generated from the defined CBMM as in Figure \ref{fig:nonGauss True PDF and labels}, we see that EM for GMM provides a better-fit initialization than K-Means, by comparing the 
Kolmogorov distance and error ratio of the two GICE settings ``$T=10$, init: K-Means'' and ``$T=10$, init: GMM'' \greenC{at the start of the algorithm}
%at 0 iteration 
in Figure \ref{fig:nonGauss CBMM convergence}. However, after 30 iterations they converged to the same level and give very similar estimated CBMMs in the end, see the estimated marginal and copula distributions in 
the third and fourth rows of Table \ref{tab:nonGauss True and estimated CBMM parameters}. 

\begin{table}[b]
\caption{True and estimated CBMM parameters with different realization times and initializations. \blueC{$T$: realization time, init: initialization method}.}
\label{tab:nonGauss True and estimated CBMM parameters}
\centering
    \resizebox{1\columnwidth}{!}{
        \begin{tabular}{c||c|c|c|c||c|c|c|c|}
            \cline{2-9}
             & $\pi_{k=1}$ & $\theta_{k=1,d=1}$ & $\theta_{k=1,d=2}$ & $\alpha_1$ & $\pi_{k=2}$ & $\theta_{k=2,d=1}$ & $\theta_{k=2,d=2}$ & $\alpha_2$ \\
            \hline
            True $\bsTheta$ & 0.4 & \makecell{T \\(2, 2, 0.7)}  & \makecell{Fisk \\(4, 0, 3)} &  \makecell{FGM \\(1)}& 0.6 & \makecell{Laplace \\(3.5, 0.8)} & \makecell{ Gamma\\(10, -4, 0.5)} & \makecell{Arch14 \\(3)} \\
            \hline
            \makecell{GICE $T$=10 \\ init: K-Means} & 0.38 & \makecell{T \\(1.74, 1.95, 0.64)}  & \makecell{Fisk \\(3.78, 0.29, 2.77)} & \makecell{FGM \\(0.89)} & 0.62 & \makecell{Laplace \\(3.51, 0.79)}  & \makecell{T \\(27.0, 1.00, 1.49)} & \makecell{Arch14 \\(2.95)} \\
            \hline
            \makecell{GICE $T$=10 \\ init: GMM} & 0.38 & \makecell{T \\(1.76, 1.95, 0.65)}  & \makecell{Fisk \\(3.80, 0.28, 2.78)} & \makecell{FGM \\(0.92)} & 0.62 & \makecell{Laplace \\(3.51, 0.79)}  & \makecell{T \\(24.6, 1.00, 1.49)} & \makecell{Arch14 \\(2.95)} \\
            \hline    
            \makecell{GICE $T$=1 \\ init: GMM} & 0.38 & \makecell{T \\(1.73, 1.94, 0.63)}  & \makecell{Fisk \\(3.84, 0.22, 2.84)} & \makecell{FGM \\(0.94)} & 0.62 & \makecell{Laplace \\(3.51, 0.79)}  & \makecell{T \\(37.4, 1.02, 1.51)} & \makecell{Arch14 \\(2.91)} \\
            \hline 
        \end{tabular}
    }
\end{table}

GICE is a stochastic method, thus the curves of the convergence indexes are not smoothly 
decreasing.
The change of the selected distribution forms between iterations may lead to small burrs in these curves. In spite of the stochastic nature of GICE, the realization time $T$ also impacts the smoothness of the convergence. The curves obtained from the settings ``$T=10$, init: GMM'' are smoother than the ones obtained from ``$T=1$, init: GMM'' in both Figure \ref{fig:nonGauss gof} and Figure \ref{fig:nonGauss error ratio}. The estimated parameters with only one realization are not too far from the result of ten realizations as reported in the last row of Table \ref{tab:nonGauss True and estimated CBMM parameters}. 
Although increasing $T$ reduces the oscillation around the target parameters at convergence, it also means to increase the computational time of GICE. In this experiment, GICE took 207 s when $T=1$, and 1548 s when $T=10$, running on a 2.7MHz CPU. In practice, $T$ should be chosen such that it balances the expected convergence smoothness and time cost.

Figure \ref{fig:nonGauss Estimated PDF and labels} shows the identified cluster densities and predicted labels through GICE with $T=10$ realizations and GMM initialization. GICE attempts to find the best-fit CBMM for the data, but it does not ensure to always find the true marginal and copula forms. Many factors have impact on its final form decision. For example, the estimation condition, including the 
number of available samples and the difficulty to separate the clusters. This situation is not something we can improve. But in practice, by carefully examining the GICE convergence, we can try different candidate forms, initialization methods, estimators, and run GICE with different random seeds, to avoid being trapped in local extrema, and increase the chance of finding the best-fit model. 

\begin{figure}[tb]
\centering
\begin{subfigure}[t]{0.49\textwidth}
  \centering
  \includegraphics[width=0.95\textwidth]{Figures/GMM_truePDF.png}
  \captionsetup{width=.8\linewidth}
  \caption{True cluster densities and labels, GMM parameters as listed in Table \ref{tab:Gauss True and estimated CBMM parameters}}
  \label{fig:Gauss True PDF and labels}
\end{subfigure}%
\begin{subfigure}[t]{0.49\textwidth}
  \centering
  \includegraphics[width=0.95\textwidth]{Figures/GMM_estPDF.png}
  \captionsetup{width=.95\linewidth}
  \caption{Estimated cluster densities and labels (GICE \blueC{with realization time $T$}=10, K-Means initialization, \blueC{100 max. iterations}).}
  \label{fig:Gauss Estimated PDF and labels}
\end{subfigure}
\caption{Synthetic experiment \blueCN{(N=2000 samples)} to evaluate the performance of GICE on GMM identification.}
\label{fig:Gauss CBMM PDF and labels}
\end{figure}

\begin{table}[b]
\caption{True Gaussian CBMM (GMM) and estimated parameters with different initializations. \blueC{$T$: realization time, init: initialization method}.}
\label{tab:Gauss True and estimated CBMM parameters}
\centering
    \resizebox{1\columnwidth}{!}{
        \begin{tabular}{c||c|c|c|c||c|c|c|c|}
            \cline{2-9}
             & $\pi_{k=1}$ & $\theta_{k=1,d=1}$ & $\theta_{k=1,d=2}$ & $\alpha_1$ & $\pi_{k=2}$ & $\theta_{k=2,d=1}$ & $\theta_{k=2,d=2}$ & $\alpha_2$ \\
            \hline
            True $\bsTheta$ & 0.4 & \makecell{Gaussian \\(0, 1)}  & \makecell{Gaussian \\(2, 0.5)} & \makecell{Gaussian \\ 0.3} & 0.6 & \makecell{Gaussian \\(3.5, 1.5)} & \makecell{Gaussian \\(2.5, 2)} & \makecell{Gaussian \\0.7} \\
            \hline
            \makecell{GICE $T$=10 \\ init: \blueC{K-Means}} & 0.42 & \makecell{T \\(195, 0.07, 1.01)}  & \makecell{Gaussian \\(2.02, 0.52)} & \makecell{Gaussian \\(0.33)} & 0.58 & \makecell{T \\(28.2, 3.60, 1.42)}  & \makecell{T \\(39.8, 2.57, 1.92)} & \makecell{Gaussian \\(0.69)} \\
            \hline
            \makecell{GICE $T$=10 \\ init: GMM} & 0.42 & \makecell{T \\(29.6, 0.06, 0.98)}  & \makecell{Gaussian \\(2.02, 0.51)} & \makecell{Gaussian \\(0.27)} & 0.58 & \makecell{T \\(28.2, 3.59, 1.42)}  & \makecell{T \\(39.0, 2.57, 1.92)} & \makecell{Gaussian \\(0.69)} \\
            \hline    
        \end{tabular}
    }
\end{table}


\subsubsection{Test on simulated data of GMM}
This series of tests aims to check if GICE also works
for the identification of GMM, which can be considered a special case of CBMM.

2000 samples were simulated from a pre-defined two-component CBMM with Gaussian \blueCN{marginals} and copulas (thus, it is actually a GMM), see Figure \ref{fig:Gauss True PDF and labels} for the simulated data and the true cluster densities. The parameters are reported in the first row of Table \ref{tab:Gauss True and estimated CBMM parameters}. 
$T=10$ was set as realization time for GICE, and similar to the previous series, we 
tested two initialization methods: K-Means and EM for GMM. 
Initializing by EM for GMM means to start with the optimized parameters, and GICE does not drive the estimated model far away from the already optimized one, as we observe stable horizontal lines for both the evolution of the Kolmogorov distance and the error ratio in Figure \ref{fig:GMM convergence}. Meanwhile, GICE converges to the same level with K-Means initialization, and the identified model is quite close to the one initialized by EM for GMM, see the \blueC{second} and \blueC{third} rows in Table \ref{tab:Gauss True and estimated CBMM parameters}. It is reasonable that 
the T distribution is often selected by GICE instead of the Gaussian (the ground truth),
because Gaussian and T distributions with an infinite amount of degrees of freedom
are identical, and the estimated parameters of T distributions are all with relatively large degrees of freedom.
Comparing the two sub-figures in Figure \ref{fig:Gauss CBMM PDF and labels}, differences are hardly noticeable visually between the identified cluster density through GICE and the ground truth.
