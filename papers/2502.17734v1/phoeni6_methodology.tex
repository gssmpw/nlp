
This methodology is designed to streamline the energy evaluation process of neural networks while ensuring adherence to portability, transparency, and the principles of Fair Comparison (FC) and Result Reproducibility (RR). The proposed approach consists of eleven structured steps, outlined in Figure~\ref{fig:graph-steps}. These steps serve as a guide for users aiming to perform evaluations and leverage the provided tools for process automation. Notably, the methodology remains flexible, allowing subsequent steps to proceed seamlessly even if optional steps are omitted.

\begin{figure*}[th!]
\centering
\caption{Steps of the proposed methodology for energy evaluation, covering all phases from setup to energy calculation.}
\includegraphics[width=\textwidth]{graph-steps.pdf}
\label{fig:graph-steps}
\end{figure*}

\begin{enumerate}
    \item \textbf{Device Registration}: this step refers to the registration of devices in a database so they can be included in future evaluations. The Device entity must be registered according to the model described in Subsubsection-\ref{sec:experimental-data-model}. This way, it will be possible to access information about these devices in an organized and standardized way;

    \item \textbf{Application containerization}: 
    this step consists of the activities required to make an application portable across operating systems and transparent for control by an automated orchestration tool. For example, the collector-app and NN-app, in Figure~\ref{fig:ecosystem-design}, need to go through this procedure. The collector-app is a type of program usually developed by the manufacturer to monitor the performance of one or more devices. For example, nvidia-smi~\cite{nvidia-smi:2020} is a program for some NVidia GPUs. On the other hand, the NN-app is developed by the neural network’s creator or a third party. For everything to work as expected, all dependencies, such as drivers and libraries, must be correctly configured in the container or accessible at runtime.
    
    \item \textbf{Application Deployment}: this step deploys the containerized application on the target execution host for energy consumption assessment. For this, a container manager such as Docker~\cite{docker:2020} or Singularity~\cite{singularity:2020} is required. Additionally, the data identified in the application model described in Subsubsection-\ref{sec:experimental-data-model} are stored in a database for future reference;
    
    \item \textbf{Dataset Deployment}: this step corresponds to deploying a dataset for one or more networks. The dataset must be accessible from the host where the network is or will be deployed, which could eventually be the same host. In addition, configuration data must be recorded in a database according to the dataset entity described in Subsubsection-\ref{sec:experimental-data-model}. Other relevant information, such as the size of each file, data type, and, depending on the type of file, additional information, including image size, number of layers, and others, must be stored in the multivalued attribute. More details are presented in the Subsubsection~\ref{sec:three-databases};

    \item \textbf{Recording neural network results}: In this optional stage, the neural network under evaluation is executed on one of the available datasets. The results of this execution are stored in a database to serve different purposes, including calculating accuracy - a metric commonly used to address trade-offs arising from energy consumption reduction techniques.

Running in either training or inference mode, techniques that modify software or hardware parameters, as well as those that compress the network or dataset to reduce energy consumption, can be evaluated based on the newly calculated accuracy. As Phoeni6 is further utilized, this stage will contribute to creating a results history with the potential to assist in resolving more comprehensive questions, such as those related to multiple models and datasets.

    \item \textbf{Setup Evaluation and Investigation}: this step configures the evaluation and investigation entities described in Subsubsection-\ref{sec:experimental-data-model}. It enables automating the process of obtaining energy consumption results. An evaluation of a network consists of investigations on specific datasets and hardware devices where the neural network runs. This configuration makes the analysis process more agile, allowing accurate and reliable results to be obtained more efficiently;
    
    \item \textbf{Network or Dataset Preparation}: 
    This optional step involves preparation tasks for evaluating or executing each investigation. The tasks include:    
        \begin{itemize}
            \item Modifying the trained NN, such as quantization, pruning, or layer compaction;
            \item Modifying the implanted dataset artifact, such as through compression, or by adding or removing features;
            \item Modifying hardware parameters;
            \item Modifying operating system parameters;
            \item Performing NN training steps;
            \item Modifying the NN during training.
        \end{itemize}
        Each parameter should be stored in a database along with its new value for more precise conclusions about energy consumption.
                
    \item \textbf{Execution of the evaluation and investigation setup}: this step refers to the execution of the configuration saved in step 6.
    
    \item \textbf{Data Gathering}: this step is divided into device and network monitoring. Device monitoring is mandatory and should be transparent and portable so that the program responsible for the reading is containerized. This monitoring corresponds to the reading of the device counters during the network execution and is automated by the process described in Subsection G. The other monitoring is optional. It corresponds to the log data generated during the network execution;
        
    \item \textbf{Obtaining results}: this step consists of submitting the log files generated during the data collection step to the backend host, as shown in Figure 1. As exemplified in Subsection C, the results are directed to a specific route according to their type. This procedure makes the format of the data present in the logs transparent. Finally, all the data are stored in a database, according to the model described in Figure 4, so that it is possible to recover information related to the results from the devices and the program's execution;

    \item \textbf{Energy calculation}: 
        this step uses the data provided in the previous step to perform energy calculations—the Evaluation entity stores the total energy, as shown in Figure 4.    

\end{enumerate}

To ensure scalability across diverse hardware configurations, the Phoeni6 framework was designed with a modular and containerized architecture. This allows individual components, such as the collector-app and NN-app, to be easily adapted for different hardware environments by modifying container configurations. The use of database-driven configurations ensures that the addition of new devices or neural networks can be managed systematically, minimizing manual intervention. For instance, the framework can scale from single-GPU systems to multi-GPU clusters by leveraging parallelized container deployments.