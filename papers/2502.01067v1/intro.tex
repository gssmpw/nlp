\renewenvironment{quote}
{\list{}{\rightmargin=0.5cm \leftmargin=0.5cm}%
	\item\relax}
{\endlist}

\section{Introduction}
\label{sec:intro}
%\chen{Make MISC changes according to reviewer 2}
% \chen{Think about how to highlight the differences between our work and the previous ones}
The pure exploration in multi-armed bandits (MABs) is one of the most well-studied problems in theoretical computer science (TCS) and machine learning (ML). The problem is formulated as follows: given $n$ arms with unknown sub-Gaussian reward distributions, find the best arm, defined as the arm with the highest mean reward, with a sufficiently high probability and a small number of arm pulls (sample complexity). Here, and throughout, the parameter $\Delta_{[i]}$ is defined as the mean reward gap between the best and the $i$-th best arms. The problem has been extensively studied in the literature (e.g., \cite{Even-Dar+02,MannorTs04,KalyanakrishnanSt10,KarninKS13,JamiesonMNB14,KCG16,CL16,AgarwalAAK17,ChenLQ17}, see~\cite{Slivkins19} for an excellent monograph), and its application has been found in numerous areas, e.g., experiment design \cite{Robbins52,villar2015multi,aziz2021multi}, recommendation systems \cite{silva2022multi}, search ranking \cite{AgarwalCEMPRRZ08,radlinski2008learning}, robot control \cite{KovalKPS15}, to name a few. 

The optimal sample complexity bound under the classical RAM setting has been established 
%for around a 
through a series of elegant works \cite{Even-Dar+02,MannorTs04,KarninKS13,JamiesonMNB14}. The pioneering work of \cite{Even-Dar+02} shows that if the value of $\Delta_{[2]}$ is known, there exists an algorithm that finds the best arm with high (constant) probability and a \emph{worst-case optimal} $O(n/\Delta^2_{[2]})$ arm pulls. Subsequently, the work of \cite{KarninKS13,JamiesonMNB14} improved the sample complexity to the \emph{nearly instance optimal} bound of $O(\sum_{i=2}^{n}1/\Delta^2_{[i]}\cdot \log\log(1/\Delta_{[i]}))$\footnote{We slightly overload the terminology to call both $O(\sum_{i=2}^{n}1/\Delta^2_{[i]}\cdot \log\log(1/\Delta_{[i]}))$ and $O(\sum_{i=2}^{n}1/\Delta^2_{[i]}\cdot \polylog{(n)})$ nearly instance optimal sample complexity, and denote (any of) them with $\tilde{O}(\sum_{i=2}^{n}1/\Delta^2_{[i]})$ when the context is clear.}, and their algorithms do \emph{not} require a known value of $\Delta_{[2]}$. On the lower bound side, \cite{MannorTs04} showed that a sample complexity of $\Omega(\sum_{i=2}^{n}1/\Delta^2_{[i]})$ is necessary to find the best arm with high constant probability, which completes the picture for classical pure exploration up to the doubly-logarithmic factor.\footnote{The seemingly artificial $\log\log(1/\Delta_{[i]})$ factor embodies some fundamental properties of the problem. See \cite{ChenL16,CLQ17} for more discussions.} % The doubly-logarithmic factor $\log\log(1/\Delta_{[i]})$ was further proved by \cite{JamiesonMNB14} to be necessary for $n=2$ case, but the progress for the general case has since been stalled.  % \chen{classical bounds for the problem -- worst-case optimal vs. (nearly) instance-optimal}

% \chen{The streaming multi-armed bandit setting -- introduced by AW'20, single-pass setting with $O(n/\Delta_{[2]})$ sample complexity}
Virtually all algorithms for pure exploration in the classical setting require all arms available in the memory for repeated visits. Aimed at modern large-scale applications, in which storing everything becomes impossible, an important direction to explore is MABs in the memory-constrained setting. To this end, \cite{AssadiW20} introduced the streaming MABs model, where the arms arrive one by one in a streaming manner, and the algorithm uses a limited memory to store, discard, and replace arms. The target for streaming MABs algorithms is to simultaneously minimize the sample complexity and the \emph{space complexity} -- the maximum number of arms stored at any point. \cite{AssadiW20} showed that if the value of $\Delta_{[2]}$ is provided, there exists a \emph{single-pass} algorithm that finds the best arm with high constant probability, the worst-case optimal $O(n/\Delta^2_{[2]})$ sample complexity, and a \emph{single-arm} memory. The key conceptual message of \cite{AssadiW20} is that in the regime where $\Delta_{[2]}$ is known and the target is the worst-case optimal sample complexity, there is no sample-space trade-off in this setting.


% \chen{The necessity of going beyond single-pass -- without known $\Delta_{[2]}$ value + instance sensitive. Then mention the positive result by Jin et al.}
The results of \cite{AssadiW20} have led to considerable interest in understanding the power and limitations of the streaming MABs model \cite{MaitiPK21,JinH0X21,AWneurips22,AgarwalKP22,Wang23Regret,LZWL23,HYZ25SODA}. In particular, since \cite{AssadiW20} only deals with the setting when $\Delta_{[2]}$ is given and the worst-case optimal bound, a natural question is to ask what happens if $\Delta_{[2]}$ is unknown, or if the target becomes the (nearly) instance optimal bound instead. Unfortunately, in these settings, the optimistic message in \cite{AssadiW20} no longer holds: \cite{AWneurips22} showed that in the single-pass setting, if the value of $\Delta_{[2]}$ is not given a priori, then the sample complexity is unbounded unless the algorithm has $\Omega(n)$-arm memory. Furthermore, even if the value of $\Delta_{[2]}$ is known, there is a sample complexity lower bound of $\Omega(n/\Delta^2_{[2]})$ for any algorithm with $o(n)$-arm memory in the single-pass streaming setting. These results assert that multiple passes over the stream are necessary if we want any streaming algorithms with sublinear memory under the new settings.

It turns out that allowing multiple passes does lead to improved bounds. Concretely, \cite{JinH0X21} shows that in $O(\log(1/\Delta_{[2]}))$ passes, it is possible to find the best arm with a single-arm memory and the near-instance optimal $O(\sum_{i=2}^{n}1/\Delta^2_{[i]}\cdot \log\log(1/\Delta_{[i]}))$ arm pulls. Furthermore, the algorithm does \emph{not} require a known quantity of $\Delta_{[2]}$. Recently, \cite{AW23BestArm} proved that for a streaming algorithm with $o(n)$-arm memory to achieve even the worst-case optimal bound $O(n/\Delta^2_{[2]})$ bound with the stream alone, a number of $\Omega\left(\frac{\log(1/\Delta_{[2]})}{\log\log(1/\Delta_{[2]})}\right)$ passes is necessary. As such, we already established a good understanding of the pass-sample-space trade-off for multi-pass algorithms without $\Delta_{[2]}$ value.

The final missing piece to complete the theoretical picture of multi-pass streaming MABS is to understand the case when $\Delta_{[2]}$ is provided \emph{and} the target is the instance-optimal sample complexity.
We remark this question is not trivial: in the adversarial instance distribution of \cite{AW23BestArm}, if $\Delta_{[2]}$ is provided, we can uniquely determine the realization of instances in their distribution. As such, it is possible that if $\Delta_{[2]}$ is known, there are algorithms with better efficiency. %In particular, although we know that the value $\Delta_{[2]}$ is not sufficient for an algorithm to achieve the nearly instance optimal sample complexity in a single pass (by \cite{AWneurips22}), this piece of information might be helpful in the \emph{multi-pass} setting for the same target sample complexity. 
This open question can be formally presented as follows.

\begin{quote}
	\centering
	\it If the value of $\Delta_{[2]}$ is known \emph{a priori}, what is the optimal number of passes for a streaming algorithm with $o(n)$ arm memory to find the best arm with the (nearly) instance optimal sample complexity?
\end{quote}

We now provide some additional discussions to better motivate the investigation. The importance of the open question could be summarized as follows.
\begin{itemize}
\item The question is important for the theoretical foundations of \emph{online learning}. The streaming MABs model has been widely regarded as an important models for modern large-scale online learning \cite{MaitiPK21,JinH0X21,AWneurips22,AgarwalKP22,Wang23Regret,LZWL23,AW23BestArm}. Since the knowledge of $\Delta_{[2]}$ is frequently assumed in the literature, as evidenced by works such as \cite{Even-Dar+02,AssadiW20}, the motivating question is an important missing piece to be answered for multi-pass pure exploration. As such, the primary motivation for the investigation is to complete the theoretical picture for the streaming MABs model.
\item Algorithms with better sample and pass efficiency could lead to \emph{direct application} in various tasks. For instance, if we want to find the best seller in large-scale online retailers, we could query the data from data centers in a streaming fashion, and run the algorithm using the local RAM. Here, we could \emph{estimate} the value of $\Delta_{[2]}$ from historical data (we only require a lower bound of such estimations for the algorithms to work, see \Cref{obs:delta-lower-bound} for more details). And since the products often have very different scales of transcactions, which implies that $\frac{n}{\Delta^2_{[2]}}\gg \sum_{i=2}^{n}\frac{1}{\Delta^2_{[i]}}$, our algorithm is much more efficient than the algorithm of \cite{AssadiW20,JinH0X21}.
\end{itemize}
% We remark that in addition to being an interesting open problem itself, the question also has strong connections to both the literature and practical applications.  Moreover, this value can often be obtained in practice by 
% \chen{Very recently, the first multi-pass lower bound by... + Pose the open problem -- if the value of $\Delta_{[2]}$ is known, can we get improvement on the number of passes to achieve the (nearly) instance-optimal sample bound?}

\subsection{Our Contributions}
\label{sec:contribution}
% We answer the open question in the quest, and provide almost matching (up to exponentially smaller terms) upper and lower bounds for streaming algorithms with $o(n)$-arm memory to find the best arm with a (nearly) instance optimal sample complexity. We first present our upper bound result as follows.
Our main contribution is the answer to open question: we provide nearly-matching (up to exponentially smaller terms) upper and lower bounds for streaming algorithms with $o(n)$-arm memory to find the best arm with a (nearly) instance optimal sample complexity. We first present our lower bound result as follows.

\begin{result}[Lower bound, informal of \Cref{thm:lb-main}]
	\label{rst:main-lb}
	\vspace{-3pt}
	Any streaming algorithm that given $n$ arms in  a stream and a known value of $\Delta_{[2]}$, finds the best arm with high constant probability, $\tilde{O}(\sum_{i=2}^{n}\frac{1}{\Delta^2_{[i]}})$\footnote{In \Cref{rst:main-lb} and \Cref{rst:main-ub}, we use $\tilde{O}(\cdot)$ to hide $\polylog(n)$ terms.} arm pulls, and $o(\frac{n}{\polylog(n)})$ arm memory has to use $\Omega(\frac{\log(n)}{\log\log(n)})$ passes over the stream.
\end{result}

\Cref{rst:main-lb} shares a similar form of the \cite{AW23BestArm}, albeit we are able to substitute $\log(1/\Delta_{[i]})$ terms with $\log{n}$ terms. Before our results, the only known result for streaming MABs lower bounds with instance-optimal sample complexity is th result of \cite{AWneurips22}, which only works for a \emph{single} pass. Therefore, \Cref{rst:main-lb} marks a significant improvement in the pass complexity of the problem.

A natural question to follow up \Cref{rst:main-lb} is to answer whether the lower is optimal, i.e., is it possible to design an algorithm with a sample and pass complexity that matches the lower bound in \Cref{rst:main-lb}. We answer this question in the affirmative by showing an algorithm as in \Cref{rst:main-ub}.

\begin{result}[Upper bound, informal of \Cref{thm:basic}]
	\label{rst:main-ub}
	\vspace{-3pt}
	There exists a streaming algorithm that given $n$ arms in a stream and the value of $\Delta_{[2]}$, finds the best arm with high constant probability with $\tilde{O}(\sum_{i=2}^{n}\frac{1}{\Delta^2_{[i]}})$ arm pulls, $O(\log(n))$ passes over the stream, and a memory of a single arm.
\end{result}
% In fact, the guarantee of our algorithm is more general than $O(\log(n))$ passes. We can always keep using only a single arm memory, and set $P$ passes to achieve $O(\sum_{i = 2}^n \frac{1}{\Delta^2_{[i]}} \cdot n^{2/P} \cdot \log \left({n P}\right))$ sample complexity. The sample-pass trade-off is optimized by taking $P=O(\log(n))$. 
In fact, the guarantee of our algorithm extends beyond just $O(\log(n))$ passes. We can always keep using only a single arm memory, and set $P$ passes to achieve $O(\sum_{i = 2}^n \frac{1}{\Delta^2_{[i]}} \cdot n^{2/P} \cdot \log \left({n P}\right))$ sample complexity. The sample-pass trade-off is optimized by taking $P=O(\log(n))$. The sample complexity bound of $O(\sum_{i=2}^{n}\frac{1}{\Delta^2_{[i]}}\cdot \log(n))$ we obtain here is slightly different from the classical near-instance optimal bound of $O(\sum_{i=2}^{n}\frac{1}{\Delta^2_{[i]}}\cdot \log\log{(1/\Delta_{[i]})})$. We remark that the $\log(n)$ multiplicative factor does \emph{not} render the bound trivial -- see \Cref{rmk:logn-overhead} for more details.

\Cref{rst:main-ub} suggests that algorithms with known $\Delta_{[2]}$ values could have much better pass efficiency. Note that the lower bound in \cite{AW23BestArm} holds with $\Delta_{[2]}$ values as small as $2^{n^{O(1)}}$, which means we may be forced to take $\poly(n)$ passes if $\Delta_{[2]}$ is unknown. In contrast, in the case when $\Delta_{[2]}$ is known, it becomes possible to find the best arm in $\log(n)$ passes, which is much smaller and reasonable in practice.


To make it easier for the readers to understand the context and contributions of our results, we provide \Cref{tab:results-comparison} that illustrates the comparison between the existing results and ours.

\begin{table}[!h]
	\centering
	\begin{tabular}{@{}c|c|c|c|c@{}}
		\toprule
		Pass & $\Delta_{[2]}$ is given & Target Sample Complexity & Memory & Remark and Reference\\ \midrule
		1 & Yes & $O(\frac{n}{\Delta^2_{[2]}})$  & Single arm & Upper bound, \cite{AssadiW20}  \\
		1 & No & $O(\frac{n}{\Delta^2_{[2]}})$  & $\Omega(n)$ arms & Lower bound, \cite{AWneurips22} \\
		1 & Yes & $\tilde{O}(\sum_{i=2}^{n}\frac{1}{\Delta^2_{[i]}})$  &  $\Omega(n)$ arms & Lower bound, \cite{AWneurips22} \\
		$O(\log(\frac{1}{\Delta_{[2]}}))$ & No & $\tilde{O}(\sum_{i=2}^{n}\frac{1}{\Delta^2_{[i]}})$ & Single arm & Upper bound, \cite{JinH0X21} \\
		$O(\frac{\log(\frac{1}{\Delta_{[2]}})}{\log\log(\frac{1}{\Delta_{[2]}})})$ & No & $O(\frac{n}{\Delta^2_{[2]}})$ & $\Omega(n/\polylog(\frac{1}{\Delta_{[2]}}))$ arms & Lower bound, \cite{AW23BestArm} \\
		$O(\frac{\log(n)}{\log\log(n)})$ & Yes & $\tilde{O}(\sum_{i=2}^{n}\frac{1}{\Delta^2_{[i]}})$ & $\Omega(n/\polylog(n))$ arms & Lower bound, \Cref{rst:main-lb} \\
		$O(\log{n})$ & Yes & $\tilde{O}(\sum_{i=2}^{n}\frac{1}{\Delta^2_{[i]}})$ & Single arm & Upper bound, \Cref{rst:main-ub} \\
		 \bottomrule
	\end{tabular}
	\caption{\label{tab:results-comparison}Summary of the previous results and our new results. To present the sample-memory-pass trade-offs, we set upper bounds on the number of passes and sample complexity, and show the memory with both upper and lower bounds. 
	}
\end{table}

% The algorithm for \Cref{rst:main-ub} can be found in \Cref{sec:basic}. As standard in the literature, we mainly deal with the memory efficiency defined as the number of arms, and the algorithm may store many bits of statistics for free. Nevertheless, in \Cref{sec:ub-stat-efficient}, we give a $P$-streaming algorithm with a memory of a single-arm and $O(P)$ bits of statistics, albeit with slightly worse sample complexity.

% \Cref{rst:main-ub} shows that with the a priori knowledge of $\Delta_{[2]}$, we can increase the pass efficiency for algorithms. 


% \chen{Almost-matching lower bound}

\Cref{rst:main-lb} and \Cref{rst:main-ub} demonstrate a sharp memory-pass trade-off for streaming algorithms to find the best arm with a near instance optimal sample complexity: with $O(\log(n))$ passes, we can obtain an algorithm with a memory of a single arm. However, if we decrease the number of passes slightly to $o(\log(n)/\log\log(n))$, no streaming algorithm will be able to achieve the sample complexity and success probability guarantee unless it uses almost $n$-arm memory. We note that this kind of dichotomy frequently arises in the streaming MABs literature (\cite{AssadiW20,AWneurips22,AgarwalKP22,AW23BestArm}), and we obtain a similar phenomenon in the multi-pass setting with a known $\Delta_{[2]}$ as well (see~\Cref{tab:results-comparison} for some examples).

Finally, we observe that by simply running our streaming algorithm in the offline setting, we obtain an offline algorithm that finds the best arm with high constant probability and $O(\sum_{i=2}^{n}\frac{1}{\Delta^2_{[i]}}\cdot \log(n))$ arm pulls. This observation, while straightforward, has the following implication on the role of $\Delta_{[2]}$ in the pure exploration MABs problem. The classical \emph{nearly} instance optimal sample complexity bound by \cite{KarninKS13,JamiesonMNB14} is $O(\sum_{i=2}^{n}\frac{1}{\Delta^2_{[i]}}\cdot \log\log(\frac{1}{\Delta_{[i]}}))$. In the two-arm scenario, \cite{JamiesonMNB14} also proved that $\Omega(\frac{1}{\Delta^2_{[2]}}\cdot \log\log(\frac{1}{\Delta_{[2]}}))$ arm pulls are \emph{necessary} (when the value of $\Delta_{[2]}$ is unknown). \cite{ChenLi15} further improved the upper bound to $O(\sum_{i=2}^{n}\frac{1}{\Delta^2_{[i]}}\cdot \log\log(\min\{n, \frac{1}{\Delta_{[i]}}\}) + \frac{1}{\Delta^2_{[2]}}\cdot \log\log(\frac{1}{\Delta_{[2]}}))$, and the discussion went deeper with later results by \cite{ChenL16,CLQ17}, in which they proposed the `gap-entropy conjecture' for the optimal sample complexity bound (also for the case of unknown $\Delta_{[2]}$, see \cite{ChenL16} for details). In contrast, our observation shows that if $\Delta_{[2]}$ is provided, we can instead get a multiplicative term that is independent of all $\Delta_{[i]}$ values in the logarithmic term. % This observation might be of independent interests in the broader MABs community. % This observation can be summarized as the following result.
%\begin{result}[Separation of sample complexity]
%	\label{rst:by-prod-ub}
%	\vspace{-3pt}
%	There exists a pure exploration MABs algorithm that given $n$ arms and the value of $\Delta_{[2]}$, finds the best arm with high constant probability and $O(\sum_{i=2}^{n}\frac{1}{\Delta^2_{[i]}}\cdot \log(n))$ arm pulls. This implies the optimal sample complexity with a known $\Delta_{[2]}$ value is \emph{asymptotically strictly smaller} than the $\Omega(\frac{1}{\Delta^2_{[2]}}\cdot \log\log(\frac{1}{\Delta_{[2]}}))$ lower bound for the setting without $\Delta_{[2]}$ value.
%\end{result}
%To the best of our knowledge, our work is the first to show that the knowledge of  $\Delta_{[2]}$ separates sample complexity in the \emph{offline} pure exploration MABs. We believe this neat observation provides further insights into this classical and fundamental problem.

\paragraph{Experiments.} To validate the performance of our algorithm, we conduct experiments on multiple types of streaming MABs instances. We compare our algorithm with two benchmarks: $i).$ the single-pass algorithm by \cite{AssadiW20}, which enjoys the ultimate pass efficiency of a single pass, but only guarantees the worst-case optimal $\Theta(\frac{n}{\Delta^2_{[2]}})$ sample complexity; and $ii).$ the  $O(\log(1/\Delta_{[2]}))$-pass algorithm by \cite{JinH0X21}, which has the advantage of not requiring the knowledge of $\Delta_{[2]}$, but has to use more passes. Our result shows that in multiple setting, our algorithm consistently enjoys the best sample efficiency. Furthermore, comparing ot the algorithm of \cite{JinH0X21}, our algorithm uses significantly less passes over the stream. The results of our experiments are presented in \Cref{sec:experiment}.

\input{tech-overview}

