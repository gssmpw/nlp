\begin{abstract}
	We study algorithms for pure exploration in multi-pass streaming Multi-armed Bandits (MABs) with the \emph{a priori} knowledge of the optimality gap $\Delta_{[2]}$. The problem is formlulated as follows: given $n$ arms with unkonwn sub-Gaussian reward distributions, find the best arm, defined as the arm with the highest mean reward, with a sufficiently high probability. Here, the parameter $\Delta_{[i]}$ is defined as the mean gap between the best and the $i$-th best arms. In the multi-pass streaming model, the arms arrive one after another in a stream, and the target of the algorithm is to simulaneously minimize the sample complexity -- the total number of arm pulls -- and the space complexity -- the maximum number of arms ever stored. 
	
	The (nearly-)instance optimal sample complexity bounds of $\tilde{\Theta}(\sum_{i=2}^{n}(1/\Delta^2_{[i]}))$ are known for almost a decade in the offline setting, i.e., the algorithm is allowed to store all arms. The recent results by JHTX [ICML'21] and AW [Arxiv'23] have shown that if no additional information is provided besides the stream, any algorithm to find the best arm with an $o(n)$ arm memory and the $\tilde{O}(\sum_{i=2}^{n}(1/\Delta^2_{[i]}))$ sample complexity requires $\tilde{\Theta}(\log{\frac{1}{\Delta}})$ passes. This is in sharp contrast with the upper bound in AW [STOC'20], which shows that if the value of $\Delta_{[2]}$ is known \emph{a priori}, there exists an algorithm that finds the best arm with a single-arm memory, a single pass over the stream, and a \emph{worst-case optimal} $O(n/\Delta^2_{[2]})$ sample complexity. As such, a natural question araises: in the multi-pass setting with a known $\Delta_{[2]}$, what are the optimal passes and memory bounds for the $\tilde{O}(\sum_{i=2}^{n}(1/\Delta^2_{[i]}))$ sample complexity?
	
	We answer the question in this paper by providing nearly matching pass bounds for streaming algorithms with $o(n)$ arm memory. Concretely, we first show an algorithm that finds the best arm with a high constant probability with a \emph{single-arm} memory, $O(\log{n})$ passes, and $O(\sum_{i=2}^{n}(1/\Delta^2_{[i]}) \cdot \log{n})$ arm pulls. We then present a lower bound, showing that any algorithm that finds the best arm with slightly sublinear memory -- a memory of $o({n}/{\polylog{n}})$ arms -- and $O(\sum_{i=2}^{n}{1}/{\Deltai^{2}}\cdot \log{n})$ arm pulls has to make $\Omega(\frac{\log{n}}{\log\log{n}})$ passes over the stream. The upper and lower bounds form a sharp dichotomy in terms of the memory, and the pass bounds match up an exponentially smalll factor.
\end{abstract}