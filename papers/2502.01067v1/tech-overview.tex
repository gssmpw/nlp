\subsection{Our Techniques}
\label{sec:tech-overview}

\paragraph{Lower Bound.} Proving lower bounds for multi-pass streaming MABs typically involves intricate techniques to carefully manage memory, samples, and the information revealed over time. To navigate these technical challenges, we draw inspiration from recent work by \cite{AW23BestArm}, which established lower bounds for multi-pass MABs without prior knowledge of $\Delta_{[2]}$. The lower bound construction devised by \cite{AW23BestArm} employs a 'batched' approach to instance distributions. Roughly, it divides the arms into $B+1$ batches for a $P$-pass algorithm, where $P\leq B$. Within each batch $b$, all but one arm consistently yield a mean reward of $\frac{1}{2}$, while the remaining 'special arm' offers stochastic mean rewards --either $\frac{1}{2}$ or $\frac{1}{2}+\alpha_{b}$ for some $\alpha_{b}>0$-- placed uniformly at random among the arms within batch $b$. Importantly, the later-arriving batches \emph{might} have higher mean rewards. This construction allows us to argue that to maintain optimal sample complexity, the algorithm must always check whether a batch contains an arm with a reward exceeding $1/2$ from the \emph{latest} batch that has not been checked, which forms a lower bound.
	
	
	The above sketches the \emph{intuition} of \cite{AW23BestArm}, and the actual proof is considerably more involved. Despite the very technical analysis, we observe that we could actually extract a framework from \cite{AW23BestArm} to capture the memory-sample trade-off for algorithms on batched instances. In particular, to establish such trade-offs, we only need $i).$ a sample complexity lower bound for the streaming algorithm to `trap' the special arm from a batch; $ii).$ a sample lower bound for the streaming algorithm to `learn' the distribution for each batch; and $iii).$ a sufficiently high gap between the sample complexity for different batches. We remark that these aspects are not explicitly written in \cite{AW23BestArm}, and forming the framework from key observations is one of our technical contributions.
	
	With this novel technical framework, a natural idea to prove lower bounds for the instance-sensitive $O(\sum_{i=2}^{n}1/\Delta^2_{[i]} \cdot \log(n))$ sample complexity is to construct a batched instance distribution that $a).$ satisfies the properties as required by the framework, and $b).$ varies the quantity of $O(\sum_{i=2}^{n}1/\Delta^2_{[i]} \cdot \log(n))$ with different realizations.
	To this end, we note that we could \emph{not} directly use the construction of \cite{AW23BestArm} in our setting. 
	An obvious problem here is that since the values of $\alpha_{b}$ change across batches, the information of $\Delta_{[2]}$ alone can help uniquely identify the realization of the distribution, which renders the distribution not hard. The idea to resolve this issue is to have \emph{two} special arms, whose mean rewards are with $\frac{1}{2}+\chi_{b}$ and $\frac{1}{2}+\chi_{b}+\gamma$. Moreover, we make $\chi_{b}$ to be much larger than $\gamma$ for any $b$, but progressively smaller by $1/\poly(B)$ factor across the batches. As such, we always have $\Delta_{[2]}=\gamma$, which means the value of $\Delta_{[2]}$ no longer reveals any information about the instance realization.
	
	The final missing piece is to show how `hard' the new construction is for streaming algorithms. Unfortunately, due to the introduction of an extra special arm, the standard technical tools developed from \cite{AgarwalKP22,AWneurips22,AW23BestArm} no longer work. To overcome the issue, we use the information-theoretic tools to develop several new results for \emph{double-armed bandits}, and apply the `direct-sum' idea in \cite{AWneurips22,AW23BestArm} to obtain new sample complexity bounds for batches with two special arms. To the best of our knowledge, this is the first lower bound that studies the sample complexity in the \emph{double-armed} setting, which could be of independent interest. Finally, by taking $B=\Theta(\log(n)/\log\log(n))$, we can simultaneously ensure the value gap between $\chi_{b}$ and $\gamma$ and the sample complexity gap between batches, which gives the desired result.
	
	\paragraph{Upper Bound.} Our algorithms work with the elimination-based approach extensively studied in the MABs literature~\cite{HKK+13,KZZ20}. % The elimination-based idea has demonstrated its utility in designing algorithms under various settings. For instance, in distributed settings, it aids in crafting algorithms that require only a few communication rounds~\cite{HKK+13,KZZ20}.
The state-of-the-art multi-pass streaming algorithm by \cite{JinH0X21} is a streaming adaptation of the classical elimination algorithm \cite{KarninKS13}. % begin with the technical overview of the algorithm. 
	The algorithm by \cite{JinH0X21} requires \(O\left(\log \left(\frac{1}{\Delta_{[2]}}\right)\right)\) passes, and the main idea is to ``binary search'' the ``correct'' gap parameters.
	% of this approach is as follows. The algorithm maintains a set of active arms (candidates for being the best arm). Initially, it starts with the whole set of arms. 
	Concretely, at the beginning of the $p$-th pass, the algorithm fixes an elimination gap \(\epsilon_p = O(2^{-p})\), the goal of the algorithm at the end of the \(p\)-pass is to eliminate all arms \(i\) such that \(\Delta_i > \epsilon_p\)\footnote{We use the notation $\Delta_{i}$ (without the brackets on $i$) to denote the gap between the best arm and $\arm_{i}$. See \Cref{subsec:notation} for more clarifications.} with roughly \(O({1}/{\epsilon^2_p})\) arm pulls on arm $i$. 
	% ; furthermore, if the empirical mean of $\arm_{i}$ has a gap of at least \(\Omega(\epsilon_p)\) from the best empirical mean, then by a Chernoff bound argument, $\arm_{i}$ can be safely eliminated from the set of active arms. 
	After \(O\left(\log \left(\frac{1}{\Delta_{[2]}}\right)\right)\) passes, the value of the elimination gap becomes smaller than \(\Delta_{[2]}\), and all arms except the best arm can be safely eliminated. % Note that the extra arm pulls the algorithm pays during the geometric guess is the reason for the $\log\log(\frac{1}{\Delta_{[i]}})$ overhead on the sample complexity. % At the moment when the set of active arm contains only one arm, the algorithm ends its work and output the best arm. 
	
	% Unfortunately, since we have to ``binary search'' for the value of $\Delta_{[2]}$, the algorithm of \cite{JinH0X21} inherently requires a number of passes as a function of $\Delta_{[2]}$. As such, in our algorithms, the high-level idea is to actively utilize the information about \(\Delta_{[2]}\) to decrease the number of passes. % We have found an innovative solution. 
	To make the number of passes independent of $\Delta_{[2]}$, our key observation is that the ``binary search'' in the elimination procedure can be made more efficient with geometric series from $n\Delta_{[2]}$ to $\Delta_{[2]}$. Concretely, instead of initiating the elimination process of arms with constant reward gap, we choose the sequence of elimination gaps in the form of \(\epsilon_p = {\Delta_{[2]}}\cdot n^{1-p/P}\) for the $p$-th pass. Here, \(P\) is the total number of passes for the algorithm. On a very high level, it is easy to observe that after \(P\) passes, the elimination gaps become smaller than \(\Delta_{[2]}\), and all arms except the best arm can be safely eliminated (with high probability). % However, such approach requires a new analysis. 
	The observation generalizes to any $\arm_{i}$ with gap parameter \(\Delta_i\): when \(\epsilon_p\) become smaller than \(\Delta_i\), a sup-optimal arm $\arm_{i}$ is eliminated with high probability. The correctness of the algorithm thus follows from the high probability event that only the best arm will remain after \(P\) passes.
	
	% For the correctness analysis we use the following approach. 
	% First, we use the concentration bound to assert that the estimated means are likely to be close to the actual mean. After that conditioning on this event, we prove the correctness of the algorithm that contains two parts. Firstly, the best arm cannot be eliminated in the algorithm. Secondly, any sup-optimal arm with a gap \(\Delta_i\) should be eliminated after a predetermined number of pulls. In other words when \(\epsilon_p\) become smaller than \(\Delta_i\). Afterwards, we need only to bound the sample complexity in terms of \(\sum_{i = 2}^n \frac{1}{\Delta_{[i]}^2}\). 
	
	
	% The analysis of sample complexity requires a new approach since the known techniques from \cite{KarninKS13,JinH0X21} only work for geometrically progressing elimination gaps \emph{without} accounting for the knowledge of $\Delta_{[2]}$. W
	For the analysis of sample complexity,
	we proceed by categorizing the set of arms into two parts with large gaps \(\Delta_i > n \Delta_{[2]}\) and small gaps \(\Delta_i \le n\Delta_{[2]}\). 
	% These two groups require different approaches. 
	The analysis for a small gaps group controls that the number of pulls assigned to each arm is at most \(O(\frac{n^{1/P}}{\Delta_i^2})\). Similar to the analysis of \cite{KarninKS13,JinH0X21}, the key observation here is that after the number of pulls used on $\arm$ $i$ becomes larger than \(\frac{1}{\Delta^2_i}\), we can eliminate such a suboptimal arm, % . Due to our choice of \(\epsilon_p\), we can guarantee that for this moment \(p\) we have \(\frac{n^{-2/P}}{\epsilon^2_{p}} \le \frac{1}{\Delta_i^2} \le \frac{1}{\epsilon^2_{p}}\), 
	which implies that we spend at most \(\frac{n^{2/P}}{\Delta^2_i}\) pulls for arm \(i\) with high probability. 
	On the other hand, for the arms with large gaps, we observe that the sample complexity of \emph{all} arms with gaps more than $n\Delta_{[2]}$ is dominated by a single largest term \(\frac{1}{\Delta^2_{[2]}}\), which leads to the desired sample complexity bound.



