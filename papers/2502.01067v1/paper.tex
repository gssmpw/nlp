\documentclass{article}

% \usepackage{neurips_2024}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc} 

\usepackage{times}
\usepackage{color}
\usepackage{fullpage}
\usepackage{graphicx}
\usepackage{epstopdf}
\usepackage{mathtools}
\usepackage{amsthm, amssymb}
\usepackage[colorlinks,linkcolor=blue,citecolor=blue,urlcolor=DarkBlue]{hyperref}
\usepackage[ruled, vlined, linesnumbered]{algorithm2e}
\usepackage{caption, subcaption}
\usepackage{enumitem}
\usepackage{comment}
\usepackage{placeins}
\usepackage{microtype}
\usepackage{makecell}
\usepackage{multirow}
\usepackage{booktabs}

\newcommand{\abs}[1]{\left| #1 \right|}
\newcommand{\IC}{\mathbf{H}}
\newcommand{\E}{\mathcal{E}}
\newcommand{\N}{\mathbb{N}}

\usepackage{tcolorbox}
\tcbuselibrary{skins,breakable}
\tcbset{enhanced jigsaw}

\definecolor{DarkRed}{rgb}{0.5,0.1,0.1}
\definecolor{DarkBlue}{rgb}{0.1,0.1,0.5}
\definecolor{RURed}{rgb}{0.8,0.1,0.1}
\definecolor{ForestGreen}{rgb}{0.1333,0.5451,0.1333}
%\definecolor{DarkRed}{rgb}{0.8,0,0}
\definecolor{Red}{rgb}{0.9,0,0}

\usepackage{nameref}
\usepackage[noabbrev,nameinlink]{cleveref}
\crefname{property}{property}{Property}
\creflabelformat{property}{(#1)#2#3}
\crefname{equation}{eq}{Eq}
\creflabelformat{equation}{(#1)#2#3}

\newtheorem{theorem}{Theorem}
\newtheorem{lemma}{Lemma}[section]
% \newtheorem{comment}[theorem]{Comment}
\newtheorem{claim}[lemma]{Claim}
\newtheorem{corollary}{Corollary}
\newtheorem{proposition}{Proposition}
\newtheorem{fact}[lemma]{Fact}

\theoremstyle{definition}
\newtheorem{note}{Note}
\newtheorem{observation}[lemma]{Observation}
\newtheorem{problem}[theorem]{Problem}
\newtheorem{conjecture}[theorem]{Conjecture}
\newtheorem{remark}[lemma]{Remark}
\newtheorem{question}[lemma]{Question}
\newtheorem{definition}{Definition}
\newtheorem{property}[lemma]{Property}

\usepackage{mdframed}
\newtheorem{mdresult}{Result}
\newenvironment{result}{\begin{mdframed}[backgroundcolor=lightgray!40,topline=false,rightline=false,leftline=false,bottomline=false,innertopmargin=5pt]\begin{mdresult}}{\end{mdresult}\end{mdframed}}



\definecolor{RURed}{rgb}{0.8,0.1,0.1}
\newcommand{\chen}[1]{\textcolor{RURed}{[\textbf{Chen:} #1]}}

\newcommand{\nicksays}[1]{\textcolor{RURed}{[\textbf{Nick:} #1]}}


\input{macros}
\title{Nearly Tight Bounds for Exploration in Streaming Multi-armed Bandits with Known Optimality Gap}
%\title{Nearly Tight Bounds for Nearly Instance Optimal Exploration in Streaming Multi-armed Bandits with Known Optimality Gap}
%\title{Memory-pass Bounds for Nearly Instance Optimal Exploration in Streaming Multi-armed Bandits with Known Optimality Gap}
%\title{Memory-pass Bounds in Streaming Multi-armed Bandits with Known Optimality Gap and Nearly Instance-Optimal Sample Complexity}
\author{Nikolai Karpov \thanks{Indiana University. \texttt{email:~kimaska@gmail.com}}
\and 
Chen Wang\thanks{Rice University and Texas A\&M University. \texttt{email:~cwangjhw@tamu.edu}}
}
\date{} 

\begin{document}
\maketitle
% \date{} 

%\input{abstract-long}
\input{abstract-short}

% \chen{remember to anonymize for conference submission}
%\chen{Technical roadmap for our lower bound:
%\begin{enumerate}
%	\item We first show that for a $2$-arm instance, either $i).$ both of them are just with mean reward $1/2$ or $ii).$ one arm is with reward $1/2+\alpha$ and the other is with reward $1/2+\alpha+\beta$, there is
%		 \begin{enumerate}
%		 	\item Distinguishing whether the arm is from the yes or no cases takes $\Omega(\eps^2/(\alpha+\beta)^2)$ arm pulls.
%		 	\item To ``learn'' with advantage $\eps$ from the original distribution, it takes $\Omega(\eps^3/(\alpha+\beta)^2)$ arm pulls.
%		 \end{enumerate}
%	\item For a `batch' of $n/(P+1)$ arms with $a).$ all but two special arms chosen uniformly at random are with mean reward $\frac{1}{2}$; and $b).$ the two special arms are either with reward $\frac{1}{2}$ or with rewards $1/2+\alpha$ and $1/2+\alpha+\beta$, there is
%	\begin{enumerate}
%		\item Conditioning on $1/2+\alpha$ and $1/2+\alpha+\beta$ arms exist, storing any arm with reward $>1/2$ takes $\Omega(n \cdot \eps^2/P^3 (\alpha+\beta)^2)$ arm pulls (if the memory is $o(n/(P+1))$).
%		\item To ``learn'' with advantage $\eps$ from the original distribution, it takes $\Omega(n \cdot \eps^3/P^3 (\alpha+\beta)^2)$ arm pulls.
%	\end{enumerate}
%	\item We want to argue that the algorithm should only pay $\frac{n}{\poly(P)\cdot (\alpha_{p}+\beta)^2}$ in pass $p$ to keep the sample complexity at most $O(H_{2}\cdot \polylog{(n)})$. The reason for this is that $\alpha_{p}>>\beta$ for any $p\leq \frac{\log{n}}{\log\log{n}}$ -- by our choice, we have $\alpha_{1}=n^{1/3} \beta$, $\alpha_{i}=\frac{1}{\polylog(n)}\cdot \alpha_{1}$
%\end{enumerate}
%}



%\chen{Sep/5 What remains to be done:
%\begin{enumerate}
%	\item Write the technical overview of the ub + lb.
%	\item Read each other's technical parts and give comments.
%	\item Items 1 and 2 deadline is Sep/5. 
%	\item \textbf{For Chen:} Write a proof skecth for \Cref{prop:multi-pass-lb} in the appendix -- do this by Sep/7.
%	\item Notation for ``defining a notion'': $:=$ vs. $\triangleq$
%\end{enumerate}
%}
%
%\chen{Some MISC stuff:
%\begin{enumerate}
%	\item Appendix A: standard technical tools. Chernoff bounds should go there. Standard bounds to compare arms should also go there -- do this by Sep/6.
%	\item Add a footnote to explain what is $\tilde{O}$ (in particular, we hide both $\log(n)$ abd $\log(1/\Delta_{[i]})$ terms).
%	\item Our algorithms work with a \emph{lower bound} estimation of $\tilde{\Delta}\leq \Delta_{[2]}$ and we only pay the overhead of $1/\tilde{\Delta}^2$.
%	\item Have a saparate paragraph for the additional notation in the lower bound I section.
%\end{enumerate}
%}


\clearpage

%%
\input{intro}

%%
\input{prelim}

%%
\input{tech-lemma}

%% 
\input{lower-bound-main}


%%
\input{ub-main}

%%
\FloatBarrier
\input{experiments}
\FloatBarrier

\bibliographystyle{plain}
\bibliography{paper}

\appendix

%%
\input{standard-tools}

%%
\input{ub-stat-eff}


%%
\input{proof-sketch-lb-prop}

\end{document}