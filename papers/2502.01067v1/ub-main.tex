%\section{Upper bound}
%\label{sec:ub}
% \subsection{Technical Overview}

\section{Upper Bound: A Multi-pass Pure Exploration Streaming MABs Algorithm with Known $\Delta_{[2]}$}\label{sec:basic}
A natural question to follow from our lower bound in \Cref{sec:lb-main} is whether this bound is tight.
In this section, we show our main upper bound result that nearly matches our lower bound in \Cref{sec:lb-main}. In particular, we prove the following theorem.
\begin{theorem}[Formalization of \Cref{rst:main-ub}]
	\label{thm:basic}
	For any $P\geq 1$, there exists a $(P + 1)$-pass streaming algorithm that given a streaming MABs instance and a known value of $\Delta_{[2]}$, finds the best arm with probability at least $1-\delta$ with a single-arm memory and at most \[O\left(\log \left(\frac{n P}{\delta}\right) \sum_{i = 2}^n \frac{n^{2/P}}{\Delta^2_{[i]}}\right)\]
	arm pulls. 
\end{theorem}

Note that by plugging in $P=\Theta(\log(n))$, \Cref{thm:basic} gives an $O(\log(n))$-pass algorithm with $O(\sum_{i = 2}^n \frac{1}{\Delta^2_{[i]}}\cdot \log{n})$ sample complexity, as we have stated in \Cref{rst:main-ub}.

We describe the general algorithm that could `adjust' the sample complexity bound with the number of passes as a parameter, see \Cref{alg:main}. 
Our approach is similar to the elimination algorithm in~\cite{KarninKS13}, and by leveraging the information about \(\Delta_{[2]}\), we can significantly reduce the number of passes. 
The algorithm proceeds in \(P  +1\) passes over the stream, and maintains a set $I_p$ of `active arms' on pass $p$. In pass \(p\), it samples each arm in the current set \(I_p\) for a carefully chosen \(T_p\) times. After sampling, it computes the estimated mean reward \(\hat{\mu}^{p}_i\) for each arm \(i\) in \(I_p\), and find the maximum estimated mean \(\hat{\mu}^{p}_{\max}\) among the arms in $I_p$. The algorithm then constructs a new set \(I_{p + 1}\) by eliminating arms whose estimated means are more than \(\epsilon_p\) below \(\hat{\mu}^{p}_{\max}\). After \(P + 1\) passes, if the set \(I_{P + 1}\) contains a single arm, the algorithm returns that arm as the best arm. 

% \chen{Based on our model, with the existence of $\pi$, we never need to explicitly maintain the set $I$ -- add a remark about it.}\nicksays{I added this these words in \Cref{lem:main-alg-memory}, but probably it is not the best place} 

\begin{algorithm}
    \caption{The Main Multi-pass Streaming Algorithm}\label{alg:main}
    \KwIn{Stream \(I\), parameter \(P\), gap parameter \(\Delta_{[2]}\), and confidence parameter \(\delta\)}
    \KwOut{Best arm}
    Set \(n \gets \abs{I}\) and \(I_0 \gets \{1, \dotsc, n\}\)\;
    Let \(\epsilon_p = n^{1-p/P}\Delta_{[2]} / 4\) for \(p = 0, \dotsc, P\) \;
    \For{\(p = 0, \dotsc, P\)}{
        \ForEach{\(i \in I\) in the arrival order}{
            \If{\(i \not\in I_p\)}{
                Skip arm\;
            }
            Pull arm \(i\) until the number of pulls reach \(T_p \triangleq \frac{8 \log(2n (P + 1) / \delta)}{\epsilon^2_r \log e}\) times\;
            Compute estimated mean \(\hat{\mu}^p_i\) after \(T_p\) pulls\;
        }
        % Pull each arm from \(I_r\) until the number of pulls reach 
        % Compute estimated mean \(\hat{\mu}^r_i\) after \(T_r\) pulls for each arm from \(I_r\)\;
        Pick \(\hat{\mu}^p_{\max} = \max\limits_{i \in I_r}\{\hat{\mu}^p_i\}\)\;
        Create a new set \(I_{p + 1} \gets \{i \in I_p \mid \hat{\mu}^p_i \ge \hat{\mu}^p_{\max} - {\epsilon_p}\}\)\;
    }
    \If{\(I_{P + 1}\) contains one element}{
        \Return{single index of arm from \(I_{P + 1}\)}\;
    }
\end{algorithm}
% In the rest of the section we prove the following theorem \chen{which theorem?}


It is easy to observe that the streaming algorithm (\Cref{alg:main}) maintains only a single arm memory across the passes. Formally:
\begin{lemma}\label{lem:main-alg-memory}
The memory of \Cref{alg:main} contains at most one arm at any point of the stream.
\end{lemma}
\begin{proof}
The algorithm initializes the set \(I_0\) to contain all the arm indices from the stream \(I\). However, this set doesn't actually store the arms themselves, only their indices. The arms are fetched one by one during the execution. 

For each pass number \(p\), from \(0\) to \(P\), the algorithm iterates through each arm \(i\) in the stream \(I\) and loads it to the memory. During this iteration, the algorithm pulls from it a fixed number of times, updates statistics \(\hat\mu^{p}_i\), and then moves on to the next arm. Therefore, at any given time, the memory contains only one arm, which is the arm currently being proceeded. 
We note that the whole information \(\hat\mu^p_i\) and \(I_p\) can be extracted from the transcript \(\Pi\), and we maintain this information explicitly only for the convenience of the presentation.  
\end{proof}


What remains is to prove the correctness and the sample complexity of \Cref{alg:main}. For simplicity and to remove any issues with dependency, in the analysis, we apply the following standard trick. We assume that we first extract \(T_P\) samples from each arm before the algorithm even starts the work. During the work, \Cref{alg:main} only utilize these samples for the computation. In other words, uses a prefix of length \(T_p\) for computation \(\hat\mu^{p}_i\). % One might wonder about the meaning or purpose of this approach. 
This strategy provides a structured and consistent set of samples and values \(\hat\mu^{p}_i\) for the algorithm's decisions, avoiding any dependency from continuously updated statistics.


%Without loss of generality we can assume that we first make \(T_{R}\) samples from each distribution, and the algorithm only reveals these samples \chen{What does this sentence mean?}. 
We first define a `good event' that captures the high-probability bound for the empirical rewards to deviate from the actual rewards with $T_{p}$ number of arm pulls. More formally, we define event $\cE$ as follows.

\begin{align}\label{eq:event-E}
    \E \triangleq \{\forall{i \in I}, p \in \{0, \dotsc, P\} : \abs{\hat\mu^p_i - \mu_i} \le \epsilon_r / 4\}
\end{align}

We show that $\E$ holds probability at least $(1-\delta)$, which is by an application of the Chernoff-Hoeffding bound (\Cref{lem:chernoff}). The formal lemma and proof are as follows.
\begin{lemma}\label{lem:bound-E}
    Let \(\E\) be the event defined in \Cref{eq:event-E}. Then, \[\Pr\left[~\neg \E~\right] \le \delta \,.\]
\end{lemma}
% \chen{The $\mathcal{E}^{\complement}$ notation is not defined. Also, this is an event, I think this notation is for sets only, no?}
% \chen{suggestion: $\Pr\left[~\neg \E~\right] \le \delta$  }
\begin{proof}
    By the union bound, we have:
    \begin{align}\label{eq:event-sum}
        \Pr\left[\neg {\E}\right] \le \sum_{i \in I} \sum_{p = 0}^{P} \Pr\left[\abs{\hat{\mu}^p_i - \mu_i} > \epsilon_p/4\right]\,.
    \end{align}
    % \chen{And suddenly here the notation changes to $\bar{\E}$! :(}
    
    By the Chernoff-Hoeffding inequality (\Cref{lem:chernoff}), we have:
    \begin{align}\label{eq:event-single}
        \Pr\left[\abs{\hat{\mu}^p_i - \mu_i} > \frac{\epsilon_p}{4} \right] \le 2 \exp\left(-\frac{\epsilon_p^2 T_p}{8}\right) \le 2\exp\left(-\ln\left(\frac{n(P + 1)}{\delta}\right)\right) \le \frac{\delta}{n (P + 1)}\,.
    \end{align}
    
    Combining~\Cref{eq:event-sum} and~\Cref{eq:event-single}, we get:
    \begin{equation*}
        \Pr\left[\neg \E\right] \le n (P + 1) \frac{\delta}{n(P + 1)} \le \delta\, ,
    \end{equation*}
    as desired.
 % \chen{Please make sure the notation is unified in this proof.}
\end{proof}

In the rest of the proof, we condition on the high probability event that $\E$ happens. We now establish the correctness of the algorithm by \Cref{lem:best} and \Cref{lem:eliminate-large-gap}. Our target is to demonstrate that the algorithm correctly identifies the best arm in stream \(I\). We prove that if the event \(\E\) holds, then the algorithm outputs the best arm. Combining this result with the bound from \Cref{lem:bound-E}, we get that the probability of the algorithm making an incorrect identification is at most \(\delta\), thus affirming the algorithm's correctness.

We first prove that the best arm cannot be eliminated during the work of the algorithm. 
\begin{lemma}\label{lem:best}
    Conditioning on the event \(\E\) defined in \Cref{eq:event-E} holds, for any \(p \in \{0, \dotsc, P + 1\}\), we have \(\star \in I_p\). 
\end{lemma}

\begin{proof}
    To prove that the best arm \(\star\) cannot be eliminated in the algorithm, we start by assuming the opposite. Assume that the best arm \(\star\) belongs to \(I_p\), but does not belong to \(I_{p + 1}\) for some \(r\). This implies the existence of an arm \(i\) for which the following inequality holds 
    \begin{equation}\label{eq:upper-bound}
        \hat{\mu}^{p}_\star < \hat{\mu}^{p}_i - \epsilon_p \,.
    \end{equation}

    However, from the property of the event \(\E\), we have \(\hat{\mu}^{p}_\star \ge \mu_\star - \epsilon_p / 4 \) and \(\hat{\mu}^p_i \le \mu_i + \epsilon_p / 4\).
    Consequently, we get: 
    \begin{equation}\label{eq:lower-bound}
        \hat{\mu}^p_\star - \hat{\mu}^p_i \ge \mu_\star - \mu_i -\epsilon_p / 2 \ge -\epsilon_p / 2\,.
    \end{equation}

    The~\Cref{eq:upper-bound} and~\Cref{eq:lower-bound} contradict each other, leading to a contradiction. Therefore, it is not possible for \(\star\) to be in \(I_p\) and eliminate the subsequent round, and as a result, \(\star\) remains in \(I_p\) for any \(p\). Thus, the best arm \(\star\) is always present in the set \(I_p\) for any \(p\) and consequently in set \(I_{P + 1}\). 
\end{proof}
% \chen{I'm not sure \Cref{lem:best} is sufficient to prove the algorithm returns the optimal arm -- we need to say that the size of $I_{R}$ is also $1$, for which we need to combine \Cref{lem:best} and \Cref{lem:eliminate-large-gap}. }


Next, we demonstrate that if event \(\cE\) holds, then an arm with a large gap should be eliminated before a specific iteration in Algorithm~\ref{alg:main}. In other words, if the condition \(\cE\) is satisfied, the algorithm will identify and eliminate arms with significant gaps with a specific number of iterations. 
% In what follows, for simplicity of notation, we use the notation $\Delta_i$ as the gap between the best arm and the arm with index $i$ (\emph{not to be confused with $\Delta_{[i]}$}).

\begin{lemma}\label{lem:eliminate-large-gap}
    Conditioning on the event \(\cE\) defined in \Cref{eq:event-E} holds, and suppose for arm \(i\) and an integer $p\in [P+1]$, there is \(\Delta_i > \frac{3}{2}\epsilon_p\), then \(i \notin I_{p + 1}\).
\end{lemma}

\begin{proof}
    Consider any arm \(i\) and a value \(r\) such that \(\Delta_i > \frac{3}{2} \epsilon_p \). We aim to prove that arm \(i\) will not be included in the set \(I_{p  +1}\). We can first assume that \(i\in I_p\) since otherwise, if \(i\) is not in \(I_p\), arm \(i\) cannot be included in \(I_{p + 1}\) simply by set inclusion.

    Assuming \(i\) is in \(I_p\), by using \Cref{lem:best} and the event \(\cE\), we have the following inequality:
    \begin{equation}\label{eq:a1}
        \hat{\mu}^{p}_{\max} \geq \hat{\mu}^{p}_{\star} \geq \mu_\star - \epsilon_p / 4\,.
    \end{equation}

    This inequality indicates that the maximum estimated mean \(\hat{\mu}^{p}_{\max}\) in \(p\)-th iteration is at least as large as the estimated mean \(\hat{\mu}^p_\star\), of the best arm \(\star\), which in turn, is at least \(\mu_\star - \epsilon_p / 4\) according to the event \(\cE\). 

    Furthermore, according to the event \(\cE\), we have:
    \begin{equation}\label{eq:a2}
        \hat{\mu}^p_i \leq \mu_i + \epsilon_p / 4\,.
    \end{equation}
    
    By combining~\Cref{eq:a1} and~\Cref{eq:a2}, we obtain: 
    \begin{align*}
        \hat{\mu}^{p}_i - \hat{\mu}^{p}_{\max} + \epsilon_p \le \mu_{i} - \mu_{\star} + \epsilon_p / 2 + \epsilon_p = \frac{3}{2} \epsilon_p - \Delta_i < 0.
    \end{align*}
    The above inequality shows that \(\hat{\mu}^p_i < \hat{\mu}^p_{\max} -\epsilon_p\) holds due the large gap \(\Delta_i = \mu_{\star} - \mu_i > \frac{3}{2}\epsilon_{p}\). 
    Consequently, if \(i\) fails to meet the condition for inclusion in \(I_{p + 1}\), \(i\) will not present in \(I_{p + 1}\). This concludes the proof of the lemma. 
\end{proof}

As \(\epsilon_P \le \Delta_{[2]}/4\) and for any \(i \in I\) we have \(\Delta_i > \Delta_{[2]} \ge 4\epsilon_P > \frac{3}{2}\epsilon_P\), it follows that \(i\) satisfies the conditions of~\Cref{lem:eliminate-large-gap}. By combining~\Cref{lem:best} and~\Cref{lem:eliminate-large-gap}, we deduce that if event \(\mathcal{E}\) holds true, then \(I_{P + 1} = \{\star\}\), and \Cref{alg:main} outputs the correct arm.

We next bound the number of samples that \Cref{alg:main} makes.

\begin{lemma}\label{lem:bound-pull}
    Conditioning on the event \(\E\) defined in \Cref{eq:event-E} holds, the sample complexity of \Cref{alg:main} is at most 
    \begin{equation*}
        O\left(\log \left(\frac{nP}{\delta} \right) \sum_{i =2}^n \frac{n^{2/P}}{\Delta^2_{[i]}}\right)\,.
    \end{equation*}
\end{lemma}

\begin{proof}
	% \chen{It seems on Line~4 we do not resample -- does that creat a dependency issue? If we resample that number of times we only pay a constant overhead.}\nicksays{I extended sentence, hope it will work better}
    For any suboptimal arm $\arm_{i}$, define the value \(p(i) \triangleq \min\{p \ge 0 \mid \Delta_i > \frac{3}{2}\epsilon_p\}\). For an optimal arm, we define \(p(\star) \triangleq P\). We note that it is correctly defined because \(\frac{3}{2}\epsilon_P = \frac{3}{2} \frac{\Delta_{[2]}}{4} < \Delta_{[2]} \le \min_i \{\Delta_i\}\), which means \(\forall i : p(i) \le P\). We split the set of arms into two parts. The first set is the set of arms with small gaps
    \begin{align*}
        S \triangleq \{i \in I\mid \Delta_i \le 3 n \Delta / 2\},
    \end{align*}
    and the set of arms with big gaps
    \begin{align*}
        B \triangleq \{i \in I\mid \Delta_i > 3 n \Delta / 2\}\,.
    \end{align*}
    \noindent
    We define \(T_{S}\) and \(T_{B}\) as the number of arm pulls used by the sets \(S\) and \(B\), and \(T\triangleq T_{S}+T_{B}\) is the total number of arm pulls. We bound the two terms in what follows. 
    Furthermore, we first look at arms from \(S\) \emph{except} \(\armstar\). For \(\arm_{i}\) with gap parameter \(\Delta_{i}\), due to the definition of \(\epsilon_p\), we have that 
    \begin{align*}
        \frac{3}{2} n^{1/P} \epsilon_{p(i)}\ge \Delta_i > \frac{3}{2} \epsilon_{p(i)},
    \end{align*}
    and consequently,
    \begin{eqnarray}\label{eq:eps-lower}
        \epsilon_{p(i)} \ge \frac{2\Delta_i}{3 n^{1/P}}\,.
    \end{eqnarray}

    By \Cref{lem:eliminate-large-gap}, we have that the number of pulls for \(\arm_{i}\) is bounded by \(T_{p(i)}\). By the definition of \(T_{p}\) and~\Cref{eq:eps-lower}, we have

    \begin{align}\label{eq:basic-small}
        T_{p(i)} = \frac{8 \log(2 n (P + 1) / \delta)}{\epsilon^2_{p(i)} \log e} \le \frac{72 \ln (2 n (P + 1) / \delta) n^{2/P}}{4 \Delta^2_i \log e}\,.
    \end{align} 
    
    For the optimal arm, by \Cref{lem:best} and \Cref{lem:eliminate-large-gap}, the number of pulls assigned to the optimal arm is equal to
    \begin{align}\label{eq:basic-optimal}
        T_{P} = \frac{8 \ln (2 n (P + 1) / \delta)}{\epsilon^2_{P} \log e} = \frac{128 \ln (2 n (P + 1) / \delta)}{\Delta_{[2]}^2 \log e}.
    \end{align}
    % Thus, the total number of pulls  for arms from \(S\) is bounded by 
    % \begin{align}
        % \sum_{i \neq \star} \frac{72 \ln (16 n (P + 1) / \delta) n^{2/P}}{4 \Delta^2_i} + \frac{128 \ln (16 n (P + 1) / \delta)}{\Delta^2} = O\left(\ln (16 n (P + 1) / \delta) \sum_{i \in I} \frac{1}{\Delta^2_i}\right)
    % \end{align}

    All arms from the set \(B\) are eliminated after the first round, the number of pulls assigned in the first round is bounded by \(T_0 \le \frac{128 \ln (2 n (P + 1) / \delta)}{n^2\Delta_{[2]}^2}\). Thus, the total number of pulls assigned for arms from \(B\) is at most 
    \begin{align}\label{eq:basic-large}
        T_B \leq nT_0 \le \frac{128 \ln (2 n (P + 1) / \delta)}{n\Delta_{[2]}^2}.
    \end{align}

    Therefore, we have 
    \begin{align*}
    	T &= T_{S}+T_{B}\\
    	  &\leq T_{P} + \sum_{i\neq \star} T_{r(i)} + T_{B} \tag{by \Cref{lem:eliminate-large-gap}}\\
    	  &\leq \frac{128 \ln (2 n (P + 1) / \delta)}{\Delta_{[2]}^2 \log e} + \sum_{i\neq \star} \frac{72 \ln (2 n (P + 1) / \delta) n^{2/P}}{4 \Delta^2_i \log e} + T_{B} \tag{by \Cref{eq:basic-small} and \Cref{eq:basic-optimal}}\\
    	  &\leq \frac{128 \ln (2 n (P + 1) / \delta)}{\Delta_{[2]}^2 \log e} + \sum_{i\neq \star} \frac{72 \ln (2 n (P + 1) / \delta) n^{2/P}}{4 \Delta^2_i \log e} + \frac{128 \ln (2 n (P + 1) / \delta)}{n\Delta_{[2]}^2} \tag{by \Cref{eq:basic-large}}\\
    	  & = O\left(\log \left(\frac{nP}{\delta} \right) \sum_{i =2}^n \frac{n^{2/P}}{\Delta^2_{[i]}}\right),
    \end{align*}
    as desired.
%     Combining inequalities \Cref{eq:basic-small}, \Cref{eq:basic-optimal}, and \Cref{eq:basic-optimal} we get the desire result. \chen{Not clear to me!}
\end{proof}

\paragraph{Finalizing the proof of \Cref{thm:basic}.} 
% cite all lemmas as blackboxes and use them to prove  \Cref{thm:basic}.
\Cref{lem:bound-E,lem:best,lem:eliminate-large-gap} guarantee that the \Cref{alg:main} outputs the best arm with probability at least \(1 - \delta\). The combination of \Cref{lem:bound-E} and \Cref{lem:bound-pull} gives the bound on the sample complexity. Finally, \Cref{lem:main-alg-memory} bounds the memory usage. 
\begin{observation}
\label{obs:delta-lower-bound}
We observe that \Cref{alg:main} can be extended to situations where the exact value of the optimality gap \(\Delta_{[2]}\) is unknown. Instead, we only have access to a lower bound \(\gamma\) for \(\Delta_{[2]}\) (we should use \(\epsilon_p = \gamma n^{1-\frac{p}{P}}\)). Under these circumstances, the analysis requires slight modifications. Although the correctness analysis remains unchanged, the bound of sample complexity needs modification. Specifically, when categorizing arms into sets \(B\) and \(S\), we should use the value \(\gamma n\) instead of \(\Delta_{[2]}n\). The contribution of arms from set \(S\) remains unchanged. However, the bound on the contributions of arms from set \(B\) to the total number of pulls is now bounded by \(O\left(\log\left(\frac{nP}{\delta}\right)\frac{1}{n\gamma^2}\right)\). Consequently, if we only have access to the lower bound \(\gamma\), the guarantees of \Cref{thm:basic} remain intact, except for a minor additive overhead of \(O\left(\log\left(\frac{nP}{\delta}\right)\frac{1}{n\gamma^2}\right)\) in the sample complexity.
\end{observation}
% \chen{Add a remark here for the lower bound estimation of $\Delta_{[2]}$}

\begin{remark}
\label{rmk:logn-overhead}
Note that the sample complexity bound for \Cref{alg:main} with $P=O(\log(n))$ does \emph{not} have the dependency on the $\log\log(\frac{1}{\Delta_{[i]}})$ factor as in \cite{KarninKS13,JamiesonMNB14}. Instead, we have an extra $O(\log(n))$ multiplicative factor. We remark that the bound is \emph{not} trivial to obtain. For the worst-case optimal bounds, there exists a simple single-pass streaming algorithm that finds the best arm with $O(n\log(n)/\Delta^2_{[2]})$ sample complexity and a memory of a single arm. The algorithm is simply to keep the best arm on the fly with $O(\log(n)/\Delta^2_{[2]})$ samples on each arm. However, for the instance-sensitive sample complexity, it is unclear how to simulate this simple algorithm with only the knowledge of $\Delta_{[2]}$. Furthermore, since the parameters $\Delta_{[i]}$ can be arbitrarily small for any $i$, our multiplicative factor of $O(\log(n))$ can be better for infinitely many instances.
\end{remark}

\begin{remark}
    We observe that our algorithm is very similar to the elimination algorithms of \cite{JinH0X21,KarninKS13}, albeit our ``search'' of the gap parameter starts from $O(\sqrt{n}\Delta_{[2]})$. We rearmark that if we change the algorithm of \cite{JinH0X21,KarninKS13} by choosing the starting value for the gap as \(O(\sqrt{n}\Delta_{[2]})\), it appears that we can get a similar result with the number of passes \(P=\log(n)\) and sample complexity $\tilde{O}(\sum_{i=2}^{n}\frac{1}{\Delta^2_{[2]}})$. However, if we do not make the extra changes as in our algorithm, it is unclear how to obtain the trade-off between the sample complexity and the number of passes.
\end{remark}