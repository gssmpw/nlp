



\section{Summary and Future Work} \label{s_a_fw}

In this paper, we propose a TAPE scheme to investigate the auditing of unlearning effectiveness based on unlearning posterior differences, involving only the unlearning process. TAPE contributes a method to build unlearned shadow models to mimic the posterior difference quickly. Moreover, two strategies are introduced to augment the posterior difference, enabling the audit of unlearning multiple samples. The extensive experimental results validate the significant efficiency improvement compared with backdoor-based methods and the effectiveness of auditing genuine samples in both exact and approximate unlearning manners.


The auditing method proposed in this paper significantly addresses the limitations of existing unlearning verification methods. It effectively audits genuine samples for both exact and approximate unlearning methods in single-sample and multi-sample unlearning scenarios. Additionally, it eliminates the need for involvement in the original model training process. Future work could continue this line of inquiry, developing more efficient unlearning auditing methods to guarantee and support the right to be forgotten in MLaaS environments.

