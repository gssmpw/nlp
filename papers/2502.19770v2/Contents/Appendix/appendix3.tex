

\subsection{The Verifier Training Process}  \label{verifi_train}



\begin{algorithm}[h]
	%\small
	\caption{Verifier Model Training (VMT)} \label{verifier_trianing}
	\begin{small} % small, normalsize
		\BlankLine
		\KwIn{Reconstruction model $\texttt{AE}$, posterior differences $\delta$, local dataset $D_{local}$, unlearned dataset $D_u$ }
		\KwOut{The Verifier Model $\mathcal{V}$}  
		\SetNlSty{}{}{} % This line removes the vertical line before the for-loop
		\SetKwFunction{VMT}{\textbf{VMT}}
		\SetKwProg{Fn}{procedure}{:}{end procedure}
		\SetNlSty{}{}{} % This line removes the vertical line before the for-loop
		\Fn{\VMT{$\texttt{AE}$, $\delta$, $D_{local}$, $D_u$}}{
			Initialize a verification dataset $D_{veri.}$ \\
			\For{$x_u$ in $D_u$, $x_i$ in $D_{local} \backslash D_u$ }{
				$D_{veri.}$ adds the positive sample ($\texttt{AE}(\delta_{\backslash x_u}), x_u; 1$) \\
				$D_{veri.}$ adds the negative sample ($\texttt{AE}(\delta_{\backslash x_u}), x_i; 0$) \\
			}
			Initialize a Verifier model $\mathcal{V}$ \\
			Train $\mathcal{V}$ on the constructed $D_{veri.}$ using a cross entropy loss  \\
			\Return the trained $\mathcal{V}$
		}
	\end{small}
\end{algorithm}


The Verifier Model Training (VMT) algorithm is designed to construct a model that can distinguish between the unlearned and still remaining data instances. We first construct a verification dataset. For each instance in the unlearned dataset, the reconstructor model reconstructs information from the posterior difference that unlearns the instance, and we set the corresponding label equal to 1. For each instance in the local dataset that is not part of the unlearned dataset, we set a negative label for the instance and the reconstructed sample pair. These samples are added to the verification dataset. A verifier model is then initialized and trained on this constructed dataset using a cross-entropy loss. We return the final trained Verifier model.
