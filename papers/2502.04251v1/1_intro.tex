% !TeX root = 0_main

\section{Introduction}
\label{sec:intro}

End-users and developers frequently submit natural language bug descriptions through issue trackers in the form of bug reports.
These reports are essential in helping developers reproduce and understand the bugs, which in turn help in fixing them.
At the very least, a good bug report should describe the observed behavior (OB) of the app (\ie the buggy behavior), the expected behavior (EB) of the app (\ie the correct behavior), and the steps to reproduce the bug (S2Rs)~\cite{Zimmermann2010, Bettenburg2008GoodBR}.
Among these, the S2Rs are arguably the most important in reproducing the reported bug, an essential step in confirming the presence of the bug.

In GUI-based applications, reproducing a bug requires exercising a series of interactions via the Graphical User Interface~(GUI), as described by the S2Rs.
A developer (or a tool) trying to replicate a bug needs to understand and extract from each S2R description the user action (a click, swipe, \etc) and the GUI component the action is applied to (a button, menu, check box, \etc). 
This is often challenging, as end-users often use their own language and understanding of the app when describing the S2Rs, which may differ from that of the developers.
Incorrect or ambiguous S2R descriptions and missing S2Rs hinder developers' ability to understand the bug and lead to non-reproducible bugs \cite{ErfaniJoorabchi2014}, delays in bug fixes \cite{Guo2010, Zimmermann2012}, unresolved bugs \cite{Guo2010}, and even reopening bugs due to incorrect fixes \cite{Zimmermann2012}.
\looseness=-1

To address the problem of low-quality S2R descriptions in bug reports, previous research focused on generating missing S2Rs \cite{Bo2024}, providing quality feedback to bug reporters \cite{Chaparro2019}, automatically reproducing the bug reports  \cite{Fazzini2018}, or facilitating interactive bug reporting~\cite{song2022burt,Moran2015,song2020bee}.
A common issue shared by several of these approaches is related to difficulties in \rev{mapping} low-quality S2R sentences to elements of the GUI, stemming from the limitations of traditional natural language processing techniques.
\looseness=-1

In this paper, we present \tool (\toolTitle), a novel approach for improving bug reports at reporting time, by providing quality feedback on S2Rs to the reporter. To do this, \tool constructs an application execution model comprising the application interactions via dynamic analysis. Then, for each S2R, it identifies the corresponding application interactions via traversal of an app execution model, guided by GPT-4 \cite{chatgpt}. During the traversal, it identifies the best path comprising interactions for the first to last S2R of the bug report. Leveraging the interaction path and the mapped interaction information for each S2R, \tool can assess the quality of the reported S2R as well as generate the potential steps that are not reported in the bug, but required to reproduce the bug (\ie\ missing steps). 
\looseness=-1

\begin{figure*}[t]
		\centering
		\includegraphics[width=\linewidth]{figures/Bug-Report-Example.pdf}
		\caption{Bug Report Quality Annotations}
		\label{fig:bug-report}
		\vspace{-0.3cm}
\end{figure*}

Unlike previous work, \tool uses an LLM (GPT-4) for three different tasks, in three distinct ways. 
\textit{First}, it automatically extracts S2R sentences in a natural language bug report, framing the task as a text classification problem.
For this task, we evaluated three prompt templates, based on three prompting strategies (\ie zero-shot, few-shot, and chain-of-thought),  using a development set of 54 bug reports.
\textit{Second}, it extracts individual user actions and the GUI components interacted with from the S2R sentences, framing the task as a phrase extraction problem.
For this task, we evaluated three additional prompt templates, based on the three prompting strategies.
\textit{Third}, it maps the extracted actions and GUI components to elements of an app execution model, framing the task as a guided graph exploration problem.
For this task, we evaluated six prompt templates, based on the three prompting strategies.
GPT-4 is used to guide the systematic and efficient exploration of the execution model.
During this mapping process, \tool identifies problems with the S2R sentences (\eg ambiguous descriptions, vocabulary mismatches, or missing steps) and generates a quality report with annotations reflecting these issues.
When S2Rs are missing, \tool also generates the missing steps and includes them in a quality report.
\looseness=-1


We compared the performance of \tool with a recent state-of-the-art technique, \EulerC \cite{Chaparro2019}, utilizing a test dataset consisting of 21 bug reports having 73 S2R sentences, from five Android applications. 
\tool achieves better results in generating quality annotations (by 25.2\% F1 score) and identifying missing S2Rs (by 71.4\% F1 score).

In summary, this paper makes the following contributions:
\begin{itemize}
	\item An approach that integrates graph-based dynamic analysis and LLMs (\ie GPT-4) to automatically identify and extract S2Rs from the bug report, assess their quality, and generate missing steps. 
	\item A ground truth dataset containing the identified and extracted S2Rs, quality annotations, and missing steps to evaluate \tool with the existing baselines. This dataset contains 75 annotated bug reports.
	\item A replication package~\cite{package,doi} containing all the dataset and source code to replicate and validate our results.
\end{itemize}
\looseness=-1
