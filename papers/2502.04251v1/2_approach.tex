% !TeX root = 0_main

\section{\tool: Automated S2R Quality Assessment}
\label{sec:approach}
\begin{figure*}[t]
		\vspace{-2em}
		\centering
		\includegraphics[width=1\linewidth]{figures/approach.pdf}
		\caption{{The \tool Approach}}
		\label{fig:approach}
\end{figure*}

This section presents \tool, an automated approach that leverages an LLM and a graph-based app execution model to assess the quality of the steps to reproduce (S2Rs) in textual bug reports.  
\tool identifies, extracts, and processes the S2Rs from a bug report to detect which ones are correct, ambiguous, missing, or phrased using language that does not correspond to a target app, according to the quality model described in \Cref{sec:quality_model}.
 \tool generates a quality report with annotations that provide feedback to the reporter about problematic S2Rs and includes generated missing S2Rs.
\tool has four main components, as illustrated in \Cref{fig:approach}:
\begin{enumerate}
	\item \textbf{S2R sentence identification}: \tool identifies the sentences that describe any S2Rs (\Cref{sec:identification-phase}).
	\item \textbf{Individual S2R extraction}: \tool extracts phrases describing individual S2Rs from S2R sentences (\Cref{sec:indiv-s2rs-approach}).
	\item \textbf{App execution model generation}: \tool builds a graph-based model using automated and manual app execution (\Cref{sec:execution-model}).  
	\item \textbf{S2R quality assessment}: \tool maps individual S2Rs to GUI-level interactions captured in the app execution model, providing feedback about high- and low-quality S2Rs as well as missing steps in a quality report (\Cref{sec:quality-assessment-annotations}).
\end{enumerate}

We leverage the language processing capabilities of LLMs \rev{(\ie\ GPT-4)} across the three phases, integrating these with GUI-level dynamic app analysis to assess S2R quality. \rev{The selection of GPT-4 as the LLM was based on its demonstrated effectiveness in language and bug understanding tasks, including bug reproduction~\cite{Feng2024} and analysis~\cite{Bo2024}.}
In the remainder of this section, we detail \tool's components or phases.



\subsection{S2R Sentence Identification Phase}
\label{sec:identification-phase}

\tool automatically identifies sentences that describe any steps to reproduce (S2R) in the bug report (see the blue sentences in Fig. \ref{fig:bug-report}). 
This is necessary as the bug report typically includes other content, notably the observed (OB) and expected app behaviors (EB). 
We formulate this task as a text classification task, using LLMs. 
\tool decomposes the bug report into a list of sentences and asks the LLM to identify which of these sentences describe any S2Rs. 
Sentence parsing is done using the Stanford CoreNLP toolkit~\cite{manning2014stanford} and heuristics. 
We experimented with three types of prompts, each one providing a different context to facilitate the task for the LLM (\eg the definition of S2Rs and guidelines on how to distinguish them from other content like the OB and EB). 
\Cref{sec:prompt_development} describes the process we followed to develop and evaluate these prompts.
\looseness=-1



\subsection{Individual S2R Extraction Phase}
\label{sec:indiv-s2rs-approach}

After identifying S2R sentences, \tool asks the LLM to extract the individual S2Rs from these sentences in a particular format (described below). 
Individual S2Rs are phrases that describe a single, atomic interaction with the app. 
Individual S2R extraction is needed because S2R sentences may describe multiple interactions with the app together with content such as the OB (\eg ``I opened the app and clicked on the Start button'' or ``The app crashes if the user checks the Angle Box''). 
In addition, different S2R sentences may describe the same interaction (\eg "... the user checks the Angle Box" and "give the Exercise a name and check the Angle Box"). 
\tool resolves this redundancy by asking the LLM to provide only one S2R among all extracted individual S2Rs that describe the same interaction.
\looseness=-1

The output of this phase is a list of individual S2Rs extracted in the order they appear in the sentences from left to right and top to bottom. 
\tool asks the LLM to represent the individual S2Rs in the following format: 
\texttt{\small[action][object][preposition][object2]}. 
The \texttt{\small[action]} is a verb associated with the app interaction (tap, long tap, enter, \etc). 
The \texttt{\small[object]} is the GUI component upon which the action is performed. 
The \texttt{\small[object2]} is additional information related to the object connected by a \texttt{\small[preposition]}. 
For example, the S2R ``Click any button on this page" is formatted as \texttt{\small[Click] [any button] [on] [this page]}.

We designed and evaluated three prompt types to extract individual S2Rs via GPT-4. 
Each prompt implements a different approach, providing different contexts about the task (\eg examples that illustrate how to accomplish the task). 
\Cref{sec:prompt_development} details the prompts and the process we followed to design and evaluate them.
\looseness=-1
 
\subsection{App Execution Model Generation Phase}
\label{sec:execution-model}

\tool's quality assessment relies on mapping individual S2Rs to interactions that can be executed on the app to replicate the reported bug. 
This requires collecting and representing possible user GUI interactions, for which we adapt graph-based representations and dynamic app execution strategies from prior work~\cite{song2022toward,saha2024toward}.

\tool creates an app execution model represented as a directed graph, $G = (V, E)$, where $V$ represents the set of unique GUI screens for an app, and $E$ represents the set of unique interactions that users can perform on the GUI components of the screens. 
A GUI screen (\ie node) is represented as a hierarchy of the GUI components and layouts. 
Two GUI screens with different GUI component hierarchies are considered distinct graph nodes. 
Each interaction (\ie edge) in $E$ is represented by a unique tuple in the form of ($v_x, v_y, e, c)$, where $c$ is a GUI component of screen $v_x$ and  $e$ in an action (tap, type, \etc) performed on $c$, resulting in a transition to another screen $v_y$. 
Each edge contains additional interaction metadata such as the interacted GUI component type, ID, text (\ie label), and description. 

To build the execution model for an app, \tool parses GUI interaction traces collected from automated app exploration and manual app usage.  \tool executes an adapted version of the \CrashScope tool~\cite{Moran2016, Moran2017}, which implements multiple
automated exploration strategies to interact with the UI components of app screens, trying to exercise as many app screens and GUI components as possible.
In the process, \CrashScope collects app screenshots and XML-based GUI hierarchies and metadata for the exercised app UI screens and components. 
As \CrashScope may \rev{fail} to interact with certain GUI screens and components that app users would normally interact with, \tool can also make use of interaction data collected from manual app usage and testing. 
In this paper, for the development set, we used the set of traces collected by Saha \etal~\cite{saha2024toward} which consists of 10-12 manually recorded feature interaction traces for each of the 5 test applications. For the prompt development dataset, two authors collected the same number of traces for each of the 31 apps. These recordings include all the app GUI interactions starting from launching the application to the last step related to carrying out an application feature (more details of this process, used for prompt development and evaluation, are found in \Cref{sec:dev_dataset}). 
In practical applications of \tool, manual executions can be collected in several ways.
For example, developers can enable user monitoring features in the app and perform record-and-replay during in-house or crowd-sourced app testing~\cite{du2022semcluster}. 
\tool parses the interaction traces generated by \CrashScope and the traces collected during app usage/testing to build the graph, according to the graph format we previously described in this section (details found in \Cref{sec:dev_dataset}). 
 
\subsection{S2R Quality Assessment Phase}
\label{sec:quality-assessment-annotations}

The app execution model captures possible interaction sequences that a user could perform when using or testing an app as paths in the graph. 
To assess the quality of the S2Rs, \tool attempts to map each individual S2R to interactions (\ie edges) along these paths. 
To do so, \tool implements an LLM-guided depth-first-search (DFS) graph traversal 
to establish the correspondence between an individual S2R and interactions on a given screen. 

Any S2Rs that cannot be mapped to a graph interaction are labeled as having a Vocabulary Mismatch (\textbf{VM}).  
S2Rs that map to multiple interactions performed on a single screen (\ie a node) are labeled as Ambiguous Steps (\textbf{AS}). 
Those that map to single interactions within a sequence are labeled as Correct Steps (\textbf{CS}). 
Finally, for the mapped S2Rs that correspond to non-consecutive interactions spanning different screens in a path, additional interactions are required to connect them to form a complete path. 
These additional interactions are used to generate individual S2Rs that are labeled as Missing Steps~(\textbf{MS}) and used to fill in the "gaps" between the existing S2Rs.

\subsubsection{Mapping Individual S2Rs to Interactions on a Screen}
\label{sec:qualtiy_phase:mapping_single_screen}
Mapping an individual S2R (S2R, hereon)
to interactions on a given screen is supported by GPT-4. 
For a graph node (\ie a screen), \tool asks GPT-4 to identify which of the outgoing edges (\ie interactions) from that node correspond to the S2R. 
Both the S2R and graph interactions are represented textually: the S2R is extracted from the bug report, while each interaction is represented as a tuple of textual information (\eg the event description and the label of the interacted GUI component).  
We designed and evaluated a set of prompts using different prompting strategies to accomplish this mapping in a 2-step manner: a first prompt asks GPT-4 to return a yes/no answer on whether an individual S2R maps to the interactions of a given screen and if the answer is yes, a second prompt asks GPT-4 to return the list of corresponding interactions. The methodology used to develop and evaluate the prompts is detailed in \Cref{sec:prompt_development_methodology}. 

\subsubsection{Graph Traversal and S2R Mapping to Interaction Paths}
\label{sec:graph-traversal}

To map all the S2Rs from a bug report to app interaction sequences, \tool implements an algorithm that traverses the graph in a depth-first-search (DFS) manner, aiming to \rev{map} the S2Rs to interactions along the DFS paths. 
When S2Rs map to non-consecutive interactions within a path, \tool connects these interactions by selecting the shortest path between the nodes where these interactions occur. 
Since multiple paths may map to the S2Rs, \tool selects the path with the most mapped S2Rs or the shortest path, if multiple paths have the same number of mapped S2Rs.

The DFS traversal of the graph is guided by the LLM-based mapping approach from \Cref{sec:qualtiy_phase:mapping_single_screen}, as only edges that map to S2Rs are traversed, avoiding the need to explore the entire graph. 
While none of the S2Rs can map to any interaction in the graph (in which case \tool would traverse the graph entirely), this scenario is expected to be rare, as we assume reporters would describe at least one S2R using the appâ€™s vocabulary and the graph is as complete as possible, covering a broad range of screens and interactions.

\textbf{\textit{Algorithm Details.}} 
\tool's DFS-based graph traversal algorithm is recursive. 
It receives an S2R $s$ and graph node~$n$ as input, where $s$ is the first item in the S2R list $L$ (the bug report S2Rs). 
The algorithm returns either: the best DFS path $p$ (starting from $n$) that maps to a subset of S2Rs in $L$ (possibly including $s$), or no path if no S2Rs can be mapped. 

The traversal begins with the first S2R from the bug report and the starting node of the graph, which contains "\textit{open app}" interactions that navigate to the screens users usually see upon launching the application. 

The algorithm has two main logic branches:
\begin{enumerate}
	\item If S2R $s$ does not map to any of the outgoing interactions~$I$ from $n$, the algorithm recurses, attempting to map  $s$ on each node connected to $n$ by $I$.  If this traversal results in no DFS paths mapped to $s$ or following S2Rs in $L$, $s$ is labeled as having a Vocabulary Mismatch (\textbf{VM}), and the algorithm recurses with the next S2R in $L$ at the current node $n$. 
	This means that the S2R $s$ cannot be mapped to any node in the (sub)graph starting from $n$, then the algorithm attempts to map the next S2R.
	\item Conversely, if $s$ maps to interactions in $I$, the algorithm checks whether there are one or more mapped interactions. If there is a single interaction, $s$ is labeled as a Correct Step~(\textbf{CS}); if there are multiple, it is labeled as an Ambiguous Step (\textbf{AS}). 
	The algorithm then recurses with the next S2R in $L$ on each node connected to $n$ by only the mapped interactions from $I$. 
	Essentially, if the algorithm succeeds at mapping $s$ to interactions from $n$, then it proceeds with attempting to map the next S2R to the resulting nodes after navigating to the mapped interactions.
\end{enumerate}

It is possible that $s$ maps to interactions in $I$ (second branch above), but there are "gaps" between the previous mapped S2R and $s$: if their mapped interactions are not consecutive in the DFS path. 
If this is the case, the algorithm connects them by determining the shortest path between the involved nodes. 
The interactions used to connect the nodes are then labeled as Missing Steps (\textbf{MS}). 
Note that this shortest path may include interactions outside the DFS path, as we are not limiting the shortest path search to the DFS path alone. A shorter path may exist that bypasses parts of the DFS path.

After traversing a node with a given S2R (in either branch above), it is possible that when calling the algorithm recursively on a set of interactions (\ie when navigating down DFS paths), it returns multiple DFS paths mapped to the S2Rs. 
If this is the case, the algorithm selects the DFS path to return based on the following criteria: prioritizing the path with the most mapped S2Rs in $L$, or, if paths have the same number, choosing the shortest path.
\looseness=-1

The traversal continues until all S2Rs in $L$ have been exhausted or until none of the S2Rs are mapped to any DFS paths. 
If all S2Rs have been mapped, but there are still nodes along a DFS path, the algorithm does not proceed to check additional nodes down the current DFS path.
To prevent re-processing nodes and their interactions, the algorithm marks each (node, S2R) pair as visited before it processes the node and S2R.
\looseness=-1

\subsubsection{Quality Report Generation}

The returned DFS path contains interactions mapped to all or a subset of the S2Rs from the bug report. Each S2R is labeled as either a Correct Step (CS), Ambiguous Step (AS), or Vocabulary Mismatch Step (VM).  
In addition, interactions identified to fill in the "gaps" between S2Rs are labeled as Missing Steps (MS). 
For evaluation purposes, we also mark the corresponding S2Rs with missing steps as MS, so that we can perform a fine-grained analysis of results (more details found in Section \ref{sec:empirical_evaluation}).
