% !TeX root = 0_main

\section{Conclusions and Future Work}
\label{sec:conclusions}

Providing quality feedback to bug reporters at reporting time promises to result in bug reports that are easier to understand and reproduce by developers.  
We found that using LLMs (\ie GPT-4) for automatically extracting and analyzing S2Rs from natural language bug reports, and matching them to GUI interactions, is very effective, resulting in better quality annotations than state-of-the-art approaches.
As with any other applications of LLMs, their performance is highly dependent on the prompting quality.
By investigating 12 prompt templates, using different prompting strategies, we observed that the use of GPT-4 in this context is quite robust with respect to the type of prompt used.
That is, different prompt templates lead to similar performance levels.

Future work will focus on expanding the evaluation to larger data sets and tackle the quality of other elements of bug reports, such as, the observed and expected behavior. \rev{We will also add support for additional types of interactions (\eg\ rotation) and perform a user study to assess \tool's usability by engineers in real-world scenarios. In addition, we will compare multiple LLMs in a follow-up extension of this work.}
