\section{Related Work}
\textbf{Long-Tailed Recognition.} 
Addressing the challenges posed by long-tailed data distributions has been a critical area of research in machine learning, for both classification and regression problems. Traditional methods, such as re-sampling and re-weighting techniques, have been used to mitigate class imbalances by either over-sampling minority classes or assigning higher weights to them during training**Chen et al., "On the Fairness of Deep Learning Models"**. 
Such algorithms fail to measure the distance in continuous label space and fall short in handling high-dimensional data (e.g., images and text). 
Deep imbalanced regression methods**Lei et al., "Class Balancing for Imbalanced Regression"** address this challenge by reweighting the data using the effective label density during representation learning. 
However, all methods above are designed for \emph{recognition} tasks such as classification and regression, and are therefore not applicable to our \emph{generation} task. 

\textbf{Diffusion Models Related to Long-Tailed Data.} 
There are also works that related to both diffusion models and long-tailed data. They aim at improving generation robustness using noisy label**Carmon et al., "Deep Unsupervised Learning with Noisy Labels"**, improving fairness in image generation**Liu et al., "Long-Tailed Image Generation via Adversarial Training"**, and improving classification accuracy using diffusion models**Ho et al., "Diffusion Models for Classification Tasks"**. However, these works have different goals and therefore are not applicable to our setting. 

Most relevant to our work is Class Balancing Diffusion Model (CBDM)**Liu et al., "Class Balancing Diffusion Model"**, which uses a distribution adjustment regularizer that enhances tail-class generation based on the modelâ€™s predictions for the head class. 
It improves the quality of long-tailed generation by assuming one-hot conditional labels (i.e., classification-based settings). 
However, this assumption does not generalize to the modern setting where image generation is usually conditioned on free-form text prompts. As a result, when adapted to the free-form setting, they often fail to model the similarity among different text prompts, leading to suboptimal generation performance in minority data (as verified by empirical results in~\secref{sec:experiments}).