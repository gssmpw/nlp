%%%%%%%% ICML 2025 EXAMPLE LATEX SUBMISSION FILE %%%%%%%%%%%%%%%%%

\documentclass{article}

% Recommended, but optional, packages for figures and better typesetting:
\usepackage{microtype}
\usepackage{graphicx}
\usepackage{subfigure}
\usepackage{booktabs} % for professional tables
\usepackage{wrapfig} % For wrapping text around figures
\usepackage{bbm}

% hyperref makes hyperlinks in the resulting PDF.
% If your build breaks (sometimes temporarily if a hyperlink spans a page)
% please comment out the following usepackage line and replace
% \usepackage{icml2025} with \usepackage[nohyperref]{icml2025} above.
\usepackage{hyperref}


% Attempt to make hyperref and algorithmic work together better:
\newcommand{\theHalgorithm}{\arabic{algorithm}}

% Use the following line for the initial blind version submitted for review:
% \usepackage{icml2025}

% If accepted, instead use the following line for the camera-ready submission:
% \usepackage[accepted]{icml2025}

% preprint
\usepackage[preprint]{icml2025}

% For theorems and such
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{mathtools}
\usepackage{amsthm}

% if you use cleveref..
\usepackage[capitalize,noabbrev]{cleveref}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% THEOREMS
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\theoremstyle{plain}
\newtheorem{theorem}{Theorem}[section]
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{corollary}[theorem]{Corollary}
\theoremstyle{definition}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{assumption}[theorem]{Assumption}
\theoremstyle{remark}
\newtheorem{remark}[theorem]{Remark}

% Todonotes is useful during development; simply uncomment the next line
%    and comment out the line below the next line to turn off comments
%\usepackage[disable,textsize=tiny]{todonotes}
\usepackage[textsize=tiny]{todonotes}


% The \icmltitle you define below is probably too long as a header.
% Therefore, a short form for the running title is supplied here:
\icmltitlerunning{Multifidelity Simulation-based Inference}

% PG: it would be good to have several alternative names for our method
% PG: it will be good to have a latex command for the name of the method, so that if we change the method name, we can easily change it throughout the text
% \newcommand{\method}{MuFiN} % Or MuFiN
% \newcommand{\method}{MF-NPE}
% \newcommand{\method}{MuFi-NPE}
% \newcommand{\seqmethod}{MuFi-TSNPE}
\newcommand{\method}{MF-NPE}
\newcommand{\seqmethod}{MF-TSNPE}
% ntroduce a small spelling shift (like MuFiN, MuFiNE, or MuFiNi) or a format tweak (dash, capital changes). That way, you retain the recognizable “multi-fidelity” + “inference/estimation” spirit, but avoid looking like “muffin.”

\newcommand{\xlf}{$x_\mathrm{L}$}

% Remove URL from citations
\makeatletter
\renewcommand{\url}[1]{}
\makeatother

\begin{document}

\twocolumn[

\icmltitle{Multifidelity Simulation-based Inference \\ for Computationally Expensive Simulators}
% \icmltitle{Multi-fidelity neural posterior estimation for expensive simulators}

% % Suggestion 1: Pedro
% \icmltitle{Multi-fidelity approaches for scalable Simulation-Based Inference}

% Suggestion 2: Nastya
% \icmltitle{\method: Multifidelity Neural Posterior Estimation \\ for Simulation-hungry Inference}

% Suggestion 3
% Multi-fidelity Simulation-Based Inference for Costly Simulators

% Multi-fidelity simulation-based inference for expensive simulators


% Multi-fidelity approaches for scalable simulation-Based inference

% old title: MF-NPE: Scaling Simulation-Based Inference for Costly Simulators
% Simulation-efficient Neural Posterior Estimation
%Neural Posterior Estimation for Computationally Expensive Simulators

% It is OKAY to include author information, even for blind
% submissions: the style file will automatically remove it for you
% unless you've provided the [accepted] option to the icml2025
% package.

% List of affiliations: The first argument should be a (short)
% identifier you will use later to specify author affiliations
% Academic affiliations should list Department, University, City, Region, Country
% Industry affiliations should list Company, City, Region, Country

% You can specify symbols, otherwise they are numbered in order.
% Ideally, you should not use this facility. Affiliations will be numbered
% in order of appearance, which is the preferred way.
% \icmlsetsymbol{equal}{*}

\begin{icmlauthorlist}
\icmlauthor{Anastasia N. Krouglova}{aaa,bbb}
\icmlauthor{Hayden R. Johnson}{aaa,bbb}
\icmlauthor{Basile Confavreux}{eee}
\icmlauthor{Michael Deistler}{ccc,ddd}
\icmlauthor{Pedro J. Gonçalves}{aaa,bbb,fff}
%\icmlauthor{}{sch}
%\icmlauthor{}{sch}
\end{icmlauthorlist}

% \icmlaffiliation{yyy}{Department of XXX, University of YYY, Location, Country}
% \icmlaffiliation{comp}{Company Name, Location, Country}
% \icmlaffiliation{sch}{School of ZZZ, Institute of WWW, Location, Country}


\icmlaffiliation{aaa}{Departments of Computer Science and Electrical Engineering, KU Leuven, Belgium}
\icmlaffiliation{bbb}{VIB-Neuroelectronics Research Flanders (NERF), Belgium}
\icmlaffiliation{ccc}{Machine Learning in Science, University of Tübingen, Germany}
\icmlaffiliation{ddd}{Tübingen AI Center, Tübingen, Germany}
\icmlaffiliation{eee}{Gatsby Computational Neuroscience Unit, UCL, London, UK}
\icmlaffiliation{fff}{VIB Center for AI $\&$ Computational Biology (VIB.AI), Leuven, Belgium}

% \affil[1]{Machine Learning in Science, University of Tübingen}
% \affil[2]{Tübingen AI Center, Tübingen, Germany}

\icmlcorrespondingauthor{Anastasia N. Krouglova}{nastya.krouglova@nerf.be}
\icmlcorrespondingauthor{Pedro J. Gonçalves}{pedro.goncalves@nerf.be}

% You may provide any keywords that you
% find helpful for describing your paper; these are used to populate
% the "keywords" metadata in the PDF but will not be shown in the document
\icmlkeywords{Machine Learning, ICML}

\vskip 0.3in
]

% this must go after the closing bracket ] following \twocolumn[ ...

% This command actually creates the footnote in the first column
% listing the affiliations and the copyright notice.
% The command takes one argument, which is text to display at the start of the footnote.
% The \icmlEqualContribution command is standard text for equal contribution.
% Remove it (just {}) if you do not need this facility.

\printAffiliationsAndNotice{}  % leave blank if no need to mention equal contribution
% \printAffiliationsAndNotice{\icmlEqualContribution} % otherwise use the standard text.
\begin{abstract}

% new version of the abstract 23/01/2025
Across many domains of science, stochastic models are an essential tool to understand the mechanisms underlying empirically observed data. Models can be of different levels of detail and accuracy, with models of high-fidelity (i.e., high accuracy) to the phenomena under study being often preferable. However, inferring parameters of high-fidelity models via simulation-based inference is challenging, especially when the simulator is computationally expensive. We introduce \method, a multifidelity approach to neural posterior estimation that leverages inexpensive low-fidelity simulations to infer parameters of high-fidelity simulators within a limited simulation budget. \method\ performs neural posterior estimation with limited high-fidelity resources by virtue of transfer learning, with the ability to prioritize individual observations using active learning. On one statistical task with analytical ground-truth and two real-world tasks, \method\ shows comparable performance to current approaches while requiring up to two orders of magnitude fewer high-fidelity simulations. Overall, \method\ opens new opportunities to perform efficient Bayesian inference on computationally expensive simulators.
\end{abstract}

% While some rely on deterministic formulations, many others incorporate stochastic processes for simulations (i.e., even for constant inputs, the outputs vary)

\section{Introduction}
Stochastic models are used across science and engineering to capture complex properties of real systems through simulations \cite{barbers_exploring_2024, nelson_foundations_2021, fadikar_calibrating_2018, pillow_fully_2012}. These simulators encode domain-specific knowledge and provide a means to generate high-fidelity synthetic data, enabling accurate forward modeling of experimental outcomes.
However, inferring model parameters from observed data can be challenging, especially when simulators are stochastic, the likelihoods of the simulators are inaccessible, or when simulations are computationally expensive.

Bayesian inference offers a principled framework to address the challenge of estimating parameters from stochastic observations by quantifying uncertainty in parameter estimates while incorporating prior knowledge. However, classical Bayesian methods are not applicable to cases where the likelihood of the simulator is not accessible in closed form \cite{tavare_inferring_1997}. Simulation-based inference (SBI) has emerged as a paradigm to tackle this by leveraging forward simulations to infer the posterior distribution \cite{cranmer_frontier_2020}. 

The challenge of extending sampling-based SBI methods like Approximate Bayesian Computation (ABC) \cite{tavare_inferring_1997, pritchard_population_1999} to problems with large numbers of parameters has driven significant advancements \cite{cranmer_frontier_2020}. Modern SBI approaches aim for the estimation of the posterior through amortized neural posterior estimation (NPE) \cite{greenberg_automatic_2019, lueckmann_flexible_2017, papamakarios_fast_2016}, neural likelihood estimation \cite{papamakarios_sequential_2019}, neural ratio estimation \cite{hermans_likelihood-free_2020} and respective sequential variants. These approaches have leveraged recent progress in neural density estimation to improve the scalability and accuracy of SBI, allowing parameter inference in problems with higher dimensionality than was previously achievable \cite{ramesh_gatsbi_2021, gloeckler_all--one_2024}.

Despite these advancements, SBI methods face computational challenges for scenarios involving expensive simulations or high-dimensional parameter spaces, as state-of-the-art methods often require extensive simulation budgets to achieve reliable posterior estimates \cite{lueckmann_benchmarking_2021}.

% Multifidelity modeling presents a promising solution to this problem: it balances precision and computational efficiency by combining high-fidelity models \cite{hoppe_dream_2021, behrens_new_2015}, 
% %HJ: May be nice to provide examples of high-cost simulation. I think this paper has some: https://arxiv.org/pdf/2410.07930
% which are accurate but resource-intensive, with faster, less accurate low-fidelity models \cite{peherstorfer_survey_2018}. 
Multifidelity modeling offers a solution to this problem by balancing precision and efficiency. It combines accurate but costly high-fidelity models \cite{hoppe_dream_2021, behrens_new_2015} with faster, less accurate low-fidelity models. 
Here, low-fidelity models could be simplifications made possible through domain knowledge about the high-fidelity models, low-dimensional projection of the high-fidelity model, or surrogate modeling \cite{peherstorfer_survey_2018}. 
%are seen as simplifications of high-fidelity models, usually made possible through domain expertise \cite{han_improving_2013}, low-dimensional projection of the high-fidelity model \cite{berkooz_proper_1993}, or interpolation or regression through surrogate models \cite{forrester_recent_2009}.
% These models could be the same 
% they could be the same (e.g. low-fidelity with larger time-steps), nested, or entirely different! Which cases do you tackle (does become clear later
%multifidelity modeling approaches are widely used across scientific domains.
For example, Reynolds-averaged Navier-Stokes (RANS) models simplify turbulent flow simulations in aerodynamics \cite{han_improving_2013}, while climate models often reduce complexity by focusing on specific atmospheric effects \cite{held_gap_2005, majda_quantifying_2010}. 
Similarly, mean-field approximations are used to capture certain features of spiking neural network dynamics \cite{vogels_inhibitory_2011, dayan_theoretical_2001}. 
By exploiting this range of fidelities, recent methods in inference, such as multifidelity Monte Carlo approaches \cite{peherstorfer_optimal_2016, nobile_multi_2015, giles_multilevel_2008, zeng_multifidelity_2023} have shown clear improvements in computational efficiency through the incorporation of coarse approximations as low-fidelity models. In the context of SBI, we hypothesized that by leveraging the complementarity of high- and low-fidelity simulators, it would be possible to reduce the computational cost of inference while retaining inference accuracy.

In this work, we present \method, a multifidelity approach that improves the efficiency of amortized neural posterior estimation for expensive simulators. \method{} reduces the computational burden of posterior estimation by pre-training a neural density estimator on low-fidelity simulations and refining the inference with a smaller set of high-fidelity simulations. Additionally, we extend our method with active learning, facilitating targeted parameter space exploration to effectively enhance high-fidelity posterior estimates given single observations. We focus on multifidelity cases where both models are simulators and where the low-fidelity model is a simplified version of the high-fidelity model, designed based on domain expertise.

%cases do you tackle (does become clear later
% Building on NPE, we introduce a multifidelity framework to extend its applicability to costly simulators. By incorporating multiple levels of fidelity in simulators, our approach enables the efficient and accurate estimation of posterior distributions even for computationally intensive scenarios.
We demonstrate that for one statistical task, with known ground-truth posterior, and two computationally expensive neuroscience simulators, \method\ can identify the posterior distributions more efficiently than NPE.

% TODO
The \textbf{core contributions of our work} are: 
\begin{itemize}
    \item A multifidelity approach for NPE. We propose a transfer learning-based method to integrate low- and high-fidelity simulators for efficient posterior estimation of parameters of high-fidelity simulators. 
    % exploiting the pre-configuration of network weights for training efficacy on low-data modes.
    \item Sequential multifidelity NPE. We propose two active learning schemes that focus computational resources on the most relevant or informative high-fidelity simulations, further improving computational efficiency.
    % \item Empirical validation. We demonstrate that \method{} consistently outperforms baseline NPE methods in terms of accuracy and simulation cost, particularly in the tasks with the complex neuroscience simulators.
\end{itemize}

\section{Related work}

% \subsection{SBI via neural density estimation}

% The challenge of extending sampling-based methods \cite{tavare_inferring_1997, pritchard_population_1999} to high-dimensional problems has driven significant advancements in simulation-based inference, catalysed by developments in probabilistic deep learning \cite{}. Modern SBI approaches aim for the direct estimation of the posterior distribution (e.g., Neural Posterior Estimation (NPE) \cite{papamakarios_fast_2016, lueckmann_flexible_2017, greenberg_automatic_2019}), the likelihood function (e.g., Neural Likelihood Estimation (NLE) \cite{papamakarios_fast_2018}), or likelihood ratios (e.g., Neural Ratio Estimation (NRE) \cite{hermans_likelihood-free_2020}). Each class of these methods has sequential variants, enabling adaptive sampling to improve simulation efficiency given single empirical observations.

% Building on NPE, we introduce a multifidelity framework to extend its applicability to costly simulators. By incorporating multiple levels of fidelity in simulators, our approach enables the efficient and accurate estimation of posterior distributions even for computationally intensive scenarios.


\subsection{Multifidelity methods for inference} % in machine learning

%It is a common practice in science to develop models that vary in terms of accuracy and computational efficiency, in order to handle the complexity and computational cost of high-fidelity models \cite{peherstorfer_survey_2018, fernandez-godino_review_2023}. 


%Low-fidelity models are seen as simplifications of high-fidelity models, usually made possible through domain expertise \cite{han_improving_2013}, low-dimensional projection of the high-fidelity model \cite{berkooz_proper_1993}, or interpolation or regression through surrogate models \cite{forrester_recent_2009}.
Multifidelity has been widely explored in the context of likelihood-based inference \cite{peherstorfer_survey_2018}, from maximum likelihood estimation approaches \cite{maurais_multifidelity_2023} to Bayesian inference methods \cite{vo_bayesian_2019, catanach_bayesian_2020}.

Currently, few studies tackle the scenario where the likelihood is not explicitly available \cite{warne_multifidelity_2022, prescott_efficient_2024, prescott_multifidelity_2021}. For instance, some multifidelity sampling-based methods have been proposed within the framework of ABC \cite{prescott_multifidelity_2020} or sequential Monte Carlo ABC \cite{prescott_multifidelity_2021}. However, despite their potential for multifidelity inference, these methods inherit limitations of ABC approaches, particularly in high-dimensional parameter spaces, where neural density estimators offer more scalable alternatives to complex real-world problems \cite{lueckmann_benchmarking_2021}.

% 1. multifidelity for models where you have a likelihood-based inference (bayesian and non-bayesian: e.g., max likelihood)
% bayesian methods have all likelihood
% and aiming for maximizing likelihood or...
% 2. Likelihood-free methods
% We don't have a likelihood. Only other example:
% The use of multiple models in likelihood-free bayesian inference has been applied only for for ABC : MF-ABC\cite{prescott_multifidelity_2020, prescott_multifidelity_2021}.
% Inherits limitations of ABC approaches, namely scaling with dimensionality of parameter spaces
% How different from ours?

% To accelerate the outputs of computationally expensive (i.e., time-consuming) high-fidelity models, recent studies proposed approaches combining multifidelity and ABC \cite{prescott_multifidelity_2020, prescott_multifidelity_2021, prescott_efficient_2024}. 

% proposed to accelerate the outputs of summary statistics.
%  When the cost of generating individual stochastic samples is high,

% Multifidelity Monte Carlo approaches incorporate typically coarse approximations as low-fidelity models, with controllable discretization parameters \cite{peherstorfer_optimal_2016, nobile_multi_2015, giles_multilevel_2008, zeng_multifidelity_2023}, 
% However, the results do typically not scale well with the dimensionality of the spaces. 

Here, we combine multifidelity approaches with neural density estimation, enabling its application to inference problems with large numbers of model parameters.

\subsection{Transfer learning and simulators} 

% approach here:
% (1) describe transfer learning in general very briefly, with key citations;
% (2) discuss previous approaches to transfer learning in the multifidelity setting (if any exist);
% (3) discuss previous approaches to transfer learning in neural density estimation (if any exist);
% (4) discuss previous approaches to transfer learning in the SBI setting (if any exist)

To facilitate learning in a target domain, transfer learning borrows knowledge from a source domain \cite{panigrahi_survey_2021}. This is often done when the target dataset is smaller than the source dataset \cite{larsen-freeman_transfer_2013} and has successfully been applied to a range of machine learning tasks, e.g., in computer vision \cite{jiang_face_2017, hussain_study_2019}. 

%This approach has been successfully applied to a range of tasks, e.g., in computer vision \cite{jiang_face_2017, hussain_study_2019}.
In the context of numerical simulators, transfer learning approaches have been used to lower the simulation budget, for instance, in CO$_2$ forecasting \cite{falola_rapid_2023}, surrogate modeling \cite{wang_local_2024} and model inversion with physics-informed neural networks \cite{haghighat_physics-informed_2021}. To the best of our knowledge, the potential of transfer learning for computationally-efficient simulation-based inference has not been realized yet.

% We do not use the inverse properties of normalizing flow, removing the need to tune an additional hyperparameter.

% Point out: physics based models don't do inference, only fitting models to data


%(rather than inference), 
% Previous transfer learning approaches in a multifidelity setting include the work of \citet{chakraborty_transfer_2021}, which explores the use of physics-informed deep neural networks \cite{raissi_physics-informed_2019}. 

% Another direction explored by \citet{li_-line_2022} uses an online transfer learning approach that fuses multifidelity data within an ensemble of deep neural networks and incorporates Bayesian Optimization (BO) to lower the cost of sampling points for expensive optimization tasks. 

% In the context of normalizing flows, \citet{gambardella_transflow_2019} developed a method that does not require any additional training in the context of neural style transfer. The variance of the likelihood is tuned by hyperparameter $\lambda$, which is similar to the tolerance error in Approximate Bayesian Computation \cite{marjoram_markov_2003, beaumont_approximate_2002}.

% We do not use the inverse properties of normalizing flow, removing the need to tune an additional hyperparameter.
% explored transfer learning in the context of normalizing flows. Leveraging its inverse properties, they

% This is different from our approach since we do not rely on additional hyperparameter tuning for the likelihood variance.


\subsection{Model misspecification} 

Our work has connections to the issue of model misspecification, a fundamental and widely studied problem in SBI \cite{gao_generalized_2023, ward_robust_2022, huang_learning_2023, frazier_synthetic_2024, adachi_reversal_2010, schmitt_detecting_2024, cannon_investigating_2022}. The issue arises when the probability over the true observation does not fall within the family of estimated probability distributions defined by a model.

A misspecified model can be seen as a form of low-fidelity model of the data-generating process (the high-fidelity model) since this will often rely on several simplifying assumptions.
% \citet{schmitt_detecting_2024} proposed a misspecification measure that precludes the need for true observations, and \citet{cannon_investigating_2022} investigated the impact of misspecification through empirical tests. The problem has been addressed with a regularized loss function to penalize the statistics that increase the mismatch between the data and the model \cite{huang_learning_2023} 
With this perspective in mind, ROPE can be considered a multifidelity approach to SBI \cite{wehenkel_addressing_2024}: model misspecification is addressed by providing a small set of real-world observations that re-calibrate through optimal transport the posterior estimates of the misspecified model. In contrast with our work, this scheme does not allow the active sampling of high-fidelity simulations. 

%It also does not allow posterior predictive checks.
% They rely on calibration set: as high-fdielity model (as if high-feilty simulator). Similar problem, but not simulator, but real empirical observation data. Imprtant is that we have an online method (they don't have). You get what you measure, and don't generate with high fidleit model (so no synthetic data). So no active scheme because we cannot sample for informative samples! active sampling but fixed there set of hf simulations. Also, we have the high-fidelity simulator, can do ppc and so on, they dont

% Here, the low-fidelity model is often seen as the misspecified model while relying on a small calibration set  \cite{}. 




\section{Methods}
\label{section:methods}

\method\ is a multifidelity approach to neural posterior estimation for computationally expensive simulators. We present our approach in Section \ref{section:mf-npe}. In Section \ref{section:mf-evaluation}, we discuss the evaluation metrics used to compare \method\ with NPE \cite{greenberg_automatic_2019}. \method\ is summarized in Algorithm \ref{alg:mf-npe} and Fig.~\ref{fig:method}. % All code to reproduce the results can be found at \textcolor{red}{anonymous}.

\subsection{Multifidelity NPE}
\label{section:mf-npe}


\begin{figure*}[ht]
% \vskip 0.2in
\begin{center}
\centerline{\includegraphics[width=\linewidth]{figures/method.png}}
\caption{\textbf{Multifidelity Neural Posterior Estimation (\method)}. \method{} proceeds by dense sampling from the prior distribution, running the low-fidelity simulator (visualized as a 3D sinusoidal), and training a neural density estimator with a negative log-likelihood loss. \method{} then retrains the pre-trained network on sparse samples from the same prior distribution and respective high-fidelity simulations (visualized as a falling waterdrop simulator with exponential decay). Given empirical observations $\boldsymbol{x_o}$, \method{} estimates the posterior distribution given the high-fidelity model. In the sequential case, the parameters for high-fidelity simulations are drawn from iterative refinements of the prior distribution within the support of the current posterior estimate, at some observation $\boldsymbol{x_o}$.
\label{fig:method}
}
% large amount of parameter values from the prior and simulates a large amount of low-fidelity model simulations. 
% Simulator: visualization of a 3D sinusoidal representing a waterdrop in a pool, and a damped oscillatory high-fidelity model. (2) We pretrain a neural density estimator on pairs of parameters and simulations and transfer the pre-trained weights to a new density estimator. (4-5) we sample a smaller batch of samples from the prior and create a smaller batch of simulations with the high-fidelity model, on which the new pre-trained architecture is trained. Now, (8) given real data, we can infer the posterior over true data points x.
%Visualization of bi-fidelity Bohachevsky function \cite{dong_multi-fidelity_2015}.
\label{MF-NPE}
\end{center}
% \vskip -0.2in
\end{figure*}


% In Multifidelity Neural Posterior Estimation (\method), parameters are sampled from a prior $p(\theta)$ with high-fidelity simulations $x \sim p(x | \theta)$.
% of interest as  $x \sim p_\mathrm{hi}(x | \theta)$. Where 
% a stochastic mapping from a parameter space $\Theta$ to output space $\mathcal{X}$, with
% f^\mathrm{hi}(x | \theta): \Theta \rightarrow \mathcal{X}$. 

% We seek an estimator that exploits a low-fidelity model $p_L(x | \theta)$ with low computational cost $c_L$ to achieve a computationally efficient estimation of the posterior distribution given a high-fidelity model $p(x | \theta)$ with high cost $c \gg c_L$. 
We aim to infer the posterior distribution over the parameters $\boldsymbol{\theta}$ of a computationally expensive high-fidelity simulator $p(\boldsymbol{x} | \boldsymbol{\theta})$, with computational cost $c$. We designate the simulator as high-fidelity if the model accurately captures the empirical phenomenon, but incurs high computational cost when generating simulations. We assume that we have access to a low-fidelity simulator $p_L(\boldsymbol{x}_\mathrm{L} | \boldsymbol{\theta})$, describing a simplification of the phenomenon of interest with cost $c_L \ll c$. We assume that both simulators operate over the same domain of observations $\boldsymbol{x}$, and the parameters of the low-fidelity model form at least a subset (and at most the entirety) of the high-fidelity parameters. Our goal is to develop an estimator that leverages low-fidelity simulations to infer the posterior distribution over parameters of the high-fidelity model with limited high-fidelity simulations, without access to a tractable likelihood for either simulator. 

%where $\Theta' \subseteq \Theta$.
%: \Theta' \rightarrow \mathcal{X'}$.
% We define the simulation cost of the high-fidelity model as $c_\mathrm{hi}$, which is typically higher than the cost of low-fidelity model $c_\mathrm{L}$.



As with NPE \cite{papamakarios_fast_2016, greenberg_automatic_2019}, to estimate the posterior density over model parameters $\boldsymbol{\theta}$ for which the likelihood function is unavailable, we consider a sufficiently expressive neural density estimator $q_\phi(\boldsymbol{\theta} | \boldsymbol{x})$, and train it to minimize the negative log-likelihood loss:
%
\begin{equation}
  \begin{aligned}
    \mathcal{L(\phi)} 
    & = \mathbb{E}_{\theta \sim p(\boldsymbol{\theta})}\mathbb{E}_{x \sim p(\boldsymbol{x}|\boldsymbol{\theta})}\left[-\log q_\phi(\boldsymbol{\theta} | \boldsymbol{x})\right], \\
    %& \approx \frac{1}{N} \sum_{i=1}^N-\log q_\phi\left(\boldsymbol{\theta}_i | \boldsymbol{x}_i\right)\\
  \end{aligned}
\end{equation}
%
where $\boldsymbol{\theta}$ is sampled from the prior distribution and $\boldsymbol{x}$ denotes the respective simulations (i.e., samples from $p(\boldsymbol{x}|\boldsymbol{\theta})$), and $\boldsymbol{\phi}$ are the network parameters. By minimizing $\mathcal{L}$, the neural density estimator approximates the conditional distribution $p(\boldsymbol{\theta} | \boldsymbol{x})$ directly \cite{papamakarios_fast_2016}.
Given a true observation $\boldsymbol{\boldsymbol{x_o}}$, we can then estimate the posterior over parameters $p(\boldsymbol{\theta} | \boldsymbol{x_o})$. To ensure $q_\phi(\boldsymbol{\theta} | \boldsymbol{x_o})$ closely approximates the true posterior $p(\boldsymbol{\theta} | \boldsymbol{x_o})$, the density estimator must be sufficiently expressive. We use neural spline flows (NSF) \cite{durkan_neural_2019}, expressive normalizing flows that have been shown empirically to be competitive for SBI \cite{lueckmann_benchmarking_2021}. 


\subsubsection{Transfer learning}
\method\ leverages representations learned from low-fidelity simulations to reduce the number of high-fidelity simulations required to approximate a high-fidelity posterior. To that end, \method{} performs \textit{transfer learning}: \method{} pre-trains a neural density estimator $q_\psi(\boldsymbol{\theta} | \boldsymbol{x}_\mathrm{L})$ on low-fidelity simulations, and uses the network parameters $\psi$ as initialization for a high-fidelity density estimator $q_\phi(\boldsymbol{\theta} | \boldsymbol{x})$.
We argue that by pre-training on low-fidelity simulations, the density estimator learns useful features up front -- i.e., the feature spaces of the low- and high-fidelity density estimators overlap --, so fewer high-fidelity simulations suffice to refine the posterior estimates. Indeed, \citet{tahir_features_2024} show that once networks learn suitable features for a given predictive task, they drastically reduce the sample complexity for related tasks. Since we do not freeze the weights after transfer, the network retains the flexibility to adapt to high-fidelity simulations without losing the benefits of pre-training.

We apply \method{} to cases where the low-fidelity model has fewer parameters than the high-fidelity model. In this setting, the parameters that are exclusive to the high-fidelity model are treated as dummy variables in the pre-trained density estimator, although it would be possible to further improve this pre-conditioning by adapting the network architecture \cite{papamakarios_normalizing_2021}. We note that the pre-conditioning with the dummy variables leads to the pre-trained neural density estimator to effectively estimate the prior distribution over the respective parameters (see Appendix \ref{appendix:dealing-with-diff-dimensionalities}). As shown below, \method{} shows competitive performance compared to NPE, even when the dimensionality of the low- and high-fidelity model are substantially different (e.g., Section \ref{section:task3}, where the low- and high-fidelity models have 12 and 14 parameters, respectively).

% Expressive conditional density estimators relying on architectures of Normalizing Flows (e.g., MAF; \cite{papamakarios_masked_2017}, NSF \cite{durkan_neural_2019}), do not support transfer learning with different parameter dimensionalities. We transfer the knowledge through the use of dummy values for the non-fitted parameters of the low-fidelity model. Although we argue that there might be improvements in this approach, given the co-dependence and permutation between the layers of normalizing flows in order to have all dimensions interact with each other \cite{papamakarios_normalizing_2021}, our experimental results showcase already substantial improvements with this technique, even when the dimensionality of the low- and high-fidelity model are substantially different (e.g., Task 3, where the low-fidelity model contains only 12 parameters, and the high-fidelity model 24 parameters). The dummy dimensionalities are learned to estimate the prior distribution (Appendix \ref{appendix:dealing-with-diff-dimensionalities}). 


    %\method\ aims to reduce the number of high-fidelity simulations needed to approximate the high-fidelity posterior by applying \textit{transfer learning} to leverage representations learned from low-fidelity simulations. We do this by pre-training a neural density estimator $q_\psi(\boldsymbol{\theta} | \boldsymbol{x}_\mathrm{L})$ on low-fidelity observations, and using the learned weights $\psi$ as initialization for our high-fidelity density estimator $q_\phi(\boldsymbol{\theta} | \boldsymbol{x})$. 
    
    %We did not see significant differences in the initialization with other distributions over the dummy variables (e.g., a gaussian distribution).
    
    


    %Transfer learning, which is shown to tend to perform better when the source model is a base of the feature space for the target model \cite{tahir_features_2024}. In other words, we argue that a form of a subspace can be found in the network weights and biases for exploitation, given a relation between the high and low-fidelity models.The dimensionality of the problem is the same.
    %We pre-train a neural posterior estimator $q_\psi(\theta | x_\mathrm{L})$ on low-fidelity samples, and a density estimator  $q_\phi(\theta | x)$ on high-fidelity samples. We do not freeze the weights or alter the network's hierarchical structure. This decision ensures that the pre-configuration is seen as a better network initialization, and the network hereby has enough flexibility to adjust the network parameters. 

     

\subsubsection{Sequential Training}
In addition to learning amortized posterior estimates with NPE, our approach naturally extends to sequential training schemes when estimating the non-amortized posterior $q_\phi(\boldsymbol{\theta}|\boldsymbol{x_{o}})$. Rather than sampling simulation parameters from the prior, sequential methods introduce an active learning scheme that iteratively refines the posterior estimate for a specific observation $\boldsymbol{x_o}$. 

These methods -- known as Sequential Neural Posterior Estimation \cite{papamakarios_fast_2016, lueckmann_flexible_2017} -- have shown increased simulation efficiency when compared to NPE \cite{lueckmann_benchmarking_2021}. However, applying these methods with flexible neural density estimators requires a modified loss that suffers from instabilities in training and posterior leakage \cite{greenberg_automatic_2019}. Truncated Sequential Neural Posterior Estimation (TSNPE) mitigates these issues by sampling from a truncated prior distribution that covers the support of the posterior. This leads to a simplified loss function and increased training stability, while retaining performance \cite{deistler_truncated_2022}.

We apply our multifidelity approach to TSNPE. First, the high-fidelity density estimator is initialized from the learned network parameters of a low-fidelity density estimator. Then, high-fidelity simulations are generated iteratively from a truncated prior, within the support of the current posterior. We refer to this method as \seqmethod{} (complete description of the algorithm in Appendix \ref{appendix:mf-tsnpe}).

\subsubsection{Acquisition function}
To further enhance the efficiency of our sequential algorithm, we explore the use of an acquisition function to supplement our round-wise samples from the TNSPE proposal. In particular, we generate simulations for round $i$ with a set of parameters $\boldsymbol{\theta}^{(i)} = \ \{\boldsymbol{\theta}^{(i)}_\mathrm{prop} \cup \boldsymbol{\theta}^{(i)}_\mathrm{active} \}$ where $\boldsymbol{\theta}^{(i)}_\mathrm{prop}$ are samples from the the proposal distribution at round $i$, and $\boldsymbol{\theta}^{(i)}_\mathrm{active}$ are the top $\mathcal{B}$ values according to an acquisition function.

Following \citet{jarvenpaa_efficient_2019, lueckmann_likelihood-free_2019}, we select an acquisition function that targets the variance of the posterior estimate with respect to the uncertainty in the learned parameters $\phi|\mathcal{D}$.
%
     \begin{equation}
         \boldsymbol{\theta}^* = \underset{\boldsymbol{\theta}}{\operatorname{argmax}} \space  \mathbb{V}_{\phi|\mathcal{D}}[q_\phi(\boldsymbol{\theta}|\boldsymbol{x_o})]
         \label{eq:acq_func}
     \end{equation}
%
We realize this as the sample variance across an ensemble of neural density estimators trained independently on the same dataset $\mathcal{D}$ --- as done in \citet{lueckmann_likelihood-free_2019}. Alternatively, one could estimate $\phi|\mathcal{D}$ using other methods of uncertainty quantification such as Monte Carlo dropout as demonstrated in \citet{griesemer_active_2024}.

The addition of an acquisition function raises the possibility of biasing the proposal distribution, causing the density estimate to diverge from the true posterior. In principle, this could be addressed by using atomic proposals \cite{greenberg_automatic_2019}, but given that such an approach suffers from posterior leakage, we do not introduce a proposal correction in order to retain the well-behaved loss function in TNSPE. We hypothesized that the benefit of informative samples would outweigh the potential bias, as long as the percentage of samples selected from the acquisition function would be small compared to the proposal samples, and indeed, our empirical results support this. We refer to this algorithm as A-\seqmethod{} (full description in Appendix \ref{appendix:active-mf-tsnpe}).
    
% In our implementation, this is realized as the variance over an ensemble of independent neural density estimators.

%In addition to our low-fidelity pre-training, we consider how active learning can be used to further improve the sample efficiency of our approach. The motivation of active learning is that data acquisition is costly, and we should acquire data that is maximally informative to the learning problem at hand. In the context of SBI, this means selecting the $\theta$ values that will produce simulations $x \sim p(x|\theta)$ that maximally improve our density estimator $q_\phi(\theta_\mathrm{hi} | x_o)$ in its approximation of true posterior $p(\theta|x_o)$.

%To do this, we develop an acquisition function that quantifies the utility of generating simulation for a given $\theta$ --- in our case corresponding to the epistemic uncertainty of the high-fidelity density estimator $q_\phi(\theta_\mathrm{hi} | x_o)$. In particular, we represent our uncertainty over the network parameters $\phi$ as an deep ensemble \cite{lakshminarayanan2017simple} of $\mathcal{B}$ independently trained networks on dataset $\mathcal{D} = \{\theta_i, x_i\}$. Our acquisition function then seeks the $\theta$ values with maximum (expected) variance in posterior evaluations across the ensemble members, where the expectation is taken over some pool of observations $\mathcal{X} = \{x_i\}$ In principle, we would like to compute $\mathbb{E}_{x \sim p(x|\theta)}[.]$, however, in practice...

%    \begin{equation}
%        \theta^* = \underset{\theta}{\operatorname{argmax}} \space \underset{x %\in \mathcal{X}}{\mathbb{E}}[\mathbb{V}_{\phi|\mathcal{D}}[q_\phi(\theta|x)]]
%    \end{equation}

%Intuitively, this acquisition function selects $\theta$ values for which our density estimators disagree, across many $x$'s, and are therefore not well approximated by the current density estimators. This acquisition function can be seen as an extension to the \textit{MaxVar} rule presented in \cite{lueckmann2019likelihood}, where our density estimator is amortized and directly targets the posterior.

%- something about how it computed in practice (samples rather than gradients)
%- something about integrating prior likelihood
%- something about posteriors correction

%... citations for this being used in other papers... something about posterior correction...

%After a first estimate of $q_\phi(\theta_\mathrm{hi} | x_o)$, the density estimation is then gradually refined in a sequential matter by the samples with the largest discrepancy between low-f posterior and high-f posterior. \textcolor{red}{math about active learning.} 
%\begin{itemize}
    % \item Simple idea: run the simulator at parameter points $\theta$ that are expected to increase our knowledge the most.
    % \item Targets critical regions of design spaces for high-fidelity evaluation. Ensures that computational resources are concentrated on where there are most needed, and leads to significant improvements.
    % \item let $\Theta$ be the sample space of the common prior between the high- and low-fidelity simulators.
%    \item Ensemble of posteriors: calculate the variance between the networks with different initialization. Sample 1-ratio // num rounds additional points.
%\end{itemize}

%\method\ is summarized in Algorithm \ref{alg:mf-npe} and Fig.~\ref{fig:method}.

      \begin{algorithm}[ht]
   \caption{\method}
   \label{alg:mf-npe}
\begin{algorithmic}
   \STATE {\bfseries Input:} 
   $N$ pairs of $(\boldsymbol{\theta},\boldsymbol{x}_\text{L})$; 
   $M$ pairs of ($\boldsymbol{\theta}, \boldsymbol{x})$;
   conditional density estimators $q_\psi(\boldsymbol{\theta} | \boldsymbol{x}_\text{L})$ and $q_\phi(\boldsymbol{\theta} | \boldsymbol{x})$ with respectively learnable parameters $\psi$ and $\phi$; early stopping criterion $S$.
   
   \STATE $\mathcal{L}(\psi) = \frac{1}{N} \sum_{i=1}^N-\log q_\psi\left(\boldsymbol{\theta}_i | \boldsymbol{x}^\text{L}_i\right)$ .

   % \STATE $\phi^t = \phi^{t-1}-\alpha(ADAM(\nabla_\phi \mathcal{L}(\phi)))$

   \FOR{epoch in epochs}
   \STATE train $q_\psi$ to minimize $\mathcal{L(\psi)}$ until $S$ is reached.
   \ENDFOR
   \STATE Initialize $q_\phi$ with weights and biases of trained $q_\psi$.
    \STATE $\mathcal{L}(\phi) = \frac{1}{M} \sum_{i=1}^M-\log q_\phi\left(\boldsymbol{\theta}_i | \boldsymbol{x}_i\right)$.
   
    \FOR{epoch in epochs}
    \STATE train $q_\phi$ to minimize $\mathcal{L(\phi)}$ until $S$ is reached.
    \ENDFOR
    
    %\STATE \textcolor{red}{active learning iterations}
    % \FOR{$m = 1..M$}
    %     %\STATE $\text{logit}(\mathbf{\theta_M})$
    %     \STATE sample $\theta_m \sim \pi(\theta)$,
    %     generate $x_m \sim p_\text{hi}(x | \theta_m)$\;
    % \ENDFOR


\end{algorithmic}
\end{algorithm}




\subsection{Evaluation metrics}
\label{section:mf-evaluation}
We evaluate the method on observations $x_o$ from the high-fidelity simulator, with parameter values drawn from the prior distribution. This ensured a fair evaluation of how much the low-fidelity simulator helps to infer the posterior distribution given the high-fidelity model.

% To quantify the performance of our multifidelity approach to standard NPE, we define the \textit{transferability} of the relationship as:
%     \begin{equation}
%         \mathcal{T} = \mathbb{E}_\Theta ( \mathcal{R}_\mathrm{npe} - \mathcal{R}_\mathrm{mfnpe}),
%     \end{equation}
% with $\mathbb{E}_\Theta$ the expectation over i.i.d.~samples from the prior distribution and $\mathcal{R}$ the generalization error over the expectation of the average negative log-likelihood over the true parameters:
% \begin{equation}
% \begin{split}
%         \mathcal{R} & =\mathbb{E}_{\mathbf{x}_o \sim p(\mathbf{x})} D_{\mathrm{KL}}\left(p\left(\boldsymbol{\theta} \mid \mathbf{x}_o\right) \| q\left(\boldsymbol{\theta} \mid \mathbf{x}_o\right)\right) \\
%         & +\mathbb{E}_{\mathbf{x}_o \sim p(\mathbf{x})} \mathbb{H}\left(p\left(\boldsymbol{\theta} \mid \mathbf{x}_o\right)\right)
%         %\mathbb{E}_p(\theta | x) \left[  \right]
% \end{split}
% \end{equation}
  
%   and $\mathbb{E}_\Theta$ the expectation over i.i.d samples from the prior distribution. The entropy $\mathbb{H}$ is constant across all compared methods of a task. The transfer learning is considered successful if $\mathcal{T} > 0$, i.e., when the expected generalization of the transfer learning outperforms training from scratch on the source task.


All methods were evaluated for a range of high-fidelity simulation budgets  ($50, 10^2, 10^3, 10^4, 10^5$), on posteriors given the same data set of observations $x_o$. %We did not perform empirical evaluations for high-fidelity simulation budgets below 50, given the high chance of overfitting of the neural density estimator.
% \subsection{Evaluation metrics}
\paragraph{Known true posterior}
We evaluate the method with the Classifier-2-Sample Test (C2ST) \cite{friedman_multivariate_2004, lopez-paz_revisiting_2017}, which allows evaluating the accuracy of posterior distributions in cases when the ground-truth posterior is known \cite{lueckmann_benchmarking_2021}. Here, a value close to 0.5 means that a classifier does not effectively distinguish the two distributions, and therefore, the posterior estimate is close to the ground-truth posterior. A value close to 1 means that the classifier can distinguish the distributions very well, indicating a poor posterior estimation. This framework is not applicable in most practical SBI settings, since it requires samples from the true posterior and is primarily used in toy examples (e.g., Section \ref{section:task1}).

\paragraph{Unknown true posterior} 
The average Negative Log probability of the True Parameters (NLTP; $-\mathbb{E}[\log q(\boldsymbol{\theta_o} | \boldsymbol{x_o})]$ ) is a commonly reported metric in simulation-based inference for problems where the true posterior is unknown \cite{greenberg_automatic_2019, papamakarios_fast_2016, durkan_contrastive_2020}. In the limit of a large number of pairs $(\boldsymbol{\theta_o}, \boldsymbol{x_o})$, the average over the log probability of each pair $(\boldsymbol{\theta_o}, \boldsymbol{x_o})$ approaches the expected KL divergence between the estimated and the true posterior (up to a term that is independent of the estimated posterior), as shown in \cite{lueckmann_benchmarking_2021}. 
%This metric converges in the limit of infinite true pairs to a $D_\text{KL}$ plus a constant. 








\section{Results}
We evaluate the performance of our multifidelity approach to simulation-based inference on three tasks. 
We start with the Ornstein-Uhlenbeck process, for which the likelihood function is available in closed form, and follow with two challenging neuroscience problems with computationally expensive simulators and for which no likelihood is available: a multicompartmental neuron model, and a neural network model with synaptic plasticity.

% The low/high-fidelity simulation ratio lies inside the range of 1.5-5.5, as has been suggested for multilevel Monte Carlo \cite{taverniers_accelerated_2020}.
    




\subsection{Ornstein-Uhlenbeck process}
\label{section:task1}

Consider a drift-diffusion process of a particle starting at position $X(0)$ and drifting towards an equilibrium state. In this task, the Ornstein-Uhlenbeck (OU) process is the high-fidelity model of this phenomenon and has four parameters: the long-term mean $\mu$, volatility $\sigma$, rate of mean reversion $\gamma$, and $\mu_\mathrm{offset}$, which is the distance between the initial position $X(0)$ and $\mu$. As low-fidelity model, we chose i.i.d.~samples from a Gaussian distribution, parametrized by $\mu_\mathrm{L}$ and $\sigma_\mathrm{L}$ (Fig.~\ref{fig:task1-illustration}; Appendix \ref{appendix:task1} for details).

\begin{figure}[h]
\begin{center}
\centerline{\includegraphics[width=\columnwidth]{figures/OU-GS-illustration.png}}
\caption{\textbf{(A) High-fidelity model:} Time-dependent Ornstein-Uhlenbeck process with four parameters. \textbf{(B) Low-fidelity model:} Time-independent i.i.d.~Gaussian samples with two parameters.}
\label{fig:task1-illustration}
\end{center}
\vskip -0.2in
\end{figure}
The Ornstein-Uhlenbeck (OU) process has a tractable likelihood, which is given by 
\begin{equation}
p_{\text {exact}}(\boldsymbol{X} \mid \mu, \sigma, \gamma, \mu_\mathrm{offset})=p(X(0))\prod_{t=1}^n \frac{1}{\sqrt{\pi g} \sigma} \exp^{K_t},
\end{equation}
where K is defined as
\begin{equation*}
    K_t = -\frac{1}{g \sigma^2}\left(\left(\mu-X_t\right)-\sqrt{1-\gamma g}\left(\mu-X_{t-1}\right)\right)^2,
\end{equation*}
%
$p(X(0)) = \mathcal{N}(\mu+\mu_\text{offset}, 1)$ is the distribution over initial conditions, and $g=(1 - \exp(-2 \gamma \Delta T)) / \gamma$ (details in Appendix \ref{appendix:ornstein-uhlenbeck}) \cite{kou_multiresolution_2012}.



\begin{figure*}[ht]
\begin{center}
\centerline{\includegraphics[width=\linewidth]{figures/task1.png}}
\caption{\textbf{\method{} is sample efficient}. (\textbf{A}) Posterior density estimates for a single observation from the OU process with two free parameters (OU2). The orange contour lines contain 68$\%$ of the probability mass of the true posterior distribution. (\textbf{B}) C2ST averaged over 10 network initializations: means and $95 \%$ confidence intervals. \method 3 is pre-trained on a low-fidelity dataset of size $10^3$, while \method4 and \method5 use datasets of $10^4$ and $10^5$ low-fidelity simulations, respectively. \method\ improves its performance with a larger number of low-fidelity samples, and all variants of our method perform better than NPE.
}
\label{figure:task1}
\end{center}
\vskip -0.3in
\end{figure*}


To evaluate \method, we compared the estimated densities to the respective reference posterior, estimated from the exact likelihood with rejection sampling \cite{martino_acceptreject_2018}. We quantified the performance with the Classifier-2-Sample Test (C2ST) over 30 observations and 10 network initializations per observation. 

First, we evaluated our multifidelity approach in a setting where the low- and high-fidelity models have the same number of parameters (Fig.~\ref{figure:task1}).
% Our goal was to infer $p(\mu,\sigma | x_o)$ by first pre-training a neural density estimator to infer the posterior over the parameters of a low-fidelity model $p_L(\mu_L,\sigma_L | x_L)$. Parameters $\gamma$ and $\mu_\mathrm{offset}$ were set to $\gamma=0.5$ and $\mu_\mathrm{offset}=3$.
Second, we gradually increased the number of parameters of the high-fidelity model by adding the mean reversion $\gamma$ and $\mu_\mathrm{offset}$, resulting in a setup with three and four parameters for the high-fidelity model versus two for the low-fidelity model. We designate the three experiments OU2, OU3 and OU4, respectively.

Across experiments, we observed a consistent increase in performance with \method{} compared to NPE, especially in low simulation budgets from the high-fidelity model (50-1000 simulations) (Fig.~\ref{figure:task1}). In addition, we found that having a higher number of low-fidelity samples improved performance, reinforcing that low-fidelity simulations were indeed advantageous for pre-training the neural density estimator for the downstream task. Note that in this task, we did not observe a substantial increase in \method{} performance between the setting with $10^4$ and $10^5$ low-fidelity samples, suggesting that we might have reached an upper bound regarding pre-training efficacy.

We expected that adding parameters to the high-fidelity model that are not present in the low-fidelity model, increased the complexity of the inference problem for \method, and indeed observed a decrease in \method{} performance, although \method{} still performed better than NPE. 



As described in Section \ref{section:methods}, we enhanced the sequential algorithm TSNPE \cite{deistler_truncated_2022} with a first round of \method, and designated this approach as \seqmethod. We found that \seqmethod{} (with 5 rounds; more details in Appendix \ref{appendix:mf-tsnpe}) performs better than the amortized \method{}, especially in regimes with low budget of high-fidelity simulations, further confirming previous findings that sequential methods have substantially higher performance in non-amortized scenarios \cite{lueckmann_benchmarking_2021}.

Finally, we found that A-\seqmethod{} shows minor improvements compared to \seqmethod{}. Such an approach is substantially more costly to run (given the ensemble of density estimators) and has a larger number of hyperparameters to tune. We cannot exclude the hypothesis that larger performance gains could be obtained from such an approach by a more extensive hyperparameter search.
% , however this remains a question for future investigation.

Overall, the results of the Ornstein-Uhlenbeck task suggest that \method{} and \seqmethod{} have the potential to lead to substantial performance gains compared to NPE.

\subsection{Multicompartmental neuron model}

The voltage response of a morphologically-detailed neuron to an input current is typically modeled with a multicompartment model wherein the voltage dynamics of each compartment are based on the Hodgkin-Huxley equations \cite{hodgkin_quantitative_1952, hay_models_2011, druckmann_novel_2007}. The higher the number of compartments of the model, the more accurate the model is, but the higher the simulation cost.

In this task, we aimed to infer the densities of ion channels $\bar{g}_{Na}$ and $\bar{g}_{K}$ on a morphologically-detailed model of a thick-tufted layer 5 pyramidal cell (L5PC) containing 8 compartments per branch (Fig.~\ref{figure:task2}A) \cite{van_geit_bluepyopt_2016}.
We injected in the first neuron compartment a noisy 100 ms step current with mean $I_m = 0.3 \text{ nA}$: $I_e = I_m + \epsilon, \epsilon \sim \mathcal{N}(0, 0.01)$. The voltage response of the neuron was recorded over 120 ms, with a simulation step size of 0.025 ms and 10 ms margin before and after the current injection. We defined the high-fidelity model to have 8 compartments per branch and the low-fidelity model to have 1 compartment per branch, and both the high and low-fidelity models had the same injected current and ion channel types.

To simulate the neuron models, we used Jaxley, a Python toolbox that makes use of GPU acceleration for efficiently simulating multicompartment single neurons with biophysical detail \cite{deistler_differentiable_2024}. In this setting, the simulation time for the high-fidelity model is approximately 7 times higher than that of the low-fidelity model.
% Note that the low- and high-fidelity models produce different outputs for the same parameter values.

We characterized the neural response with four summary statistics that have been commonly used when fitting biophysical models of single neurons to empirical data: number of spikes, mean resting potential, standard deviation of the resting potential, and the voltage mean \cite{goncalves_training_2020, gao_generalized_2023}.
% When sampling from the prior distribution over parameters, approximately $0.1 \%$ of the respective simulations had clearly unrealistic summary statistics: these simulations were iteratively replaced by random draws from the prior distribution until we collected a desired number of valid simulations.
% In showcased use cases, the embedding net for the summary statistics $x$ is the identity matrix.
 

The performances of \method{} and NPE were evaluated with NLTP on $10^3$ pairs of $\theta_o$ and respective simulation outputs $x_o$ (see Section \ref{section:mf-evaluation}), averaged over 10 different random network initialization and fixed simulation data set.
% During the performance evaluation, we encountered numerical instabilities, particularly with NPE in low-simulation budgets -- a substantial proportion of the estimated probability density was placed outside of the uniform prior bounds, a phenomenon dubbed `leakage' that has been previously documented \cite{greenberg_automatic_2019,deistler_truncated_2022} --, but logit-transforming the parameters resolved the issue.

In line with the results in the OU process task, \method{} showed much better performance than NPE in terms of NLTP, in particular with higher low-fidelity simulation budgets (Fig.~\ref{figure:task2}B,C). Furthermore, posterior predictives of \method{} closely matched the empirical data, in contrast with NPE, even when NPE was trained on a higher number of high-fidelity simulations (Fig.~\ref{figure:task2}D; Appendix \ref{appendix:multicompartmental}). Finally, we ran simulation-based calibration tests and found that both \method{} and NPE estimates are relatively well calibrated (Fig.~\ref{figure:task2}E) \cite{talts_validating_2020}.

% In summary, the \method and \seqmethod{} showed higher performance than NPE. We need exponentially fewer samples (e.g., 100 instead of 10 000 samples, as shown on Figure \ref{figure:task2}), to achieve comparable results to NPE.


\begin{figure}[ht!]
\vskip 0.2in
\begin{center}
\centerline{\includegraphics[width=1\linewidth]{figures/task2.png}}
\caption{\textbf{(A)} A thick-tufted layer 5 pyramidal cell from the neocortex, containing 1 or 8 compartments per branch, respectively for the low- and high-fidelity models. \textbf{(B)} NLTP evaluated on 1000 pairs of observations and respective true parameters. Different colors of \method\ correspond to different numbers of low-fidelity samples used to pre-train the model (respectively $10^3,10^4,10^5$; same naming convention as in Fig.~\ref{figure:task1}). \textbf{(C)} Posterior distributions across 4 methods, trained on $10^3$ high-fidelity samples (dotted box in panel B). \textbf{(D)} Posterior predictives, where NPE and \method{} have been trained on $10^3$ high-fidelity samples. \textbf{(E)} Simulation-based calibration for NPE and \method{} trained on $10^3$ samples.}
\label{figure:task2}
\end{center}
\vskip -0.3in
\end{figure}



\subsection{Recurrent Spiking Network}
\label{section:task3}


Finally, we applied \method{} to a particularly challenging and timely problem in neuroscience: the inference of synaptic plasticity rules that endow large spiking neural networks with dynamics reminiscent of experimental data.
% recurrent spiking networks evolving with synaptic plasticity rules drawn from a parameterized search space.
This problem has been recently tackled with an SBI method (filter simulation-based inference, fSBI) that progressively narrows down the search space of parameters given different sets of summary statistics \cite{confavreux_meta-learning_2023}. fSBI was successful in obtaining manifolds of plasticity rules that ensure plausible network activity, but the compute requirements were reported to be very large. Here, we aim to test whether this problem can be efficiently tackled with \method.
% Lastly, we examine the benefits of \method\ in inferring the parameter space of entire families of complex and co-active plasticity rules in spiking neural networks. 

The high-fidelity simulator consisted of a recurrent network of 4096 excitatory ($E$) and 1024 inhibitory ($I$) leaky integrate-and-fire neurons connected with conductance-based synapses (Fig.~\ref{figure:task3}A, B). Each synapse type in this network ($E$-to-$E$, $E$-to-$I$, $I$-to-$E$ and $I$-to-$I$) was plastic with an unsupervised local learning rule. For each synapse type, six parameters governed how the recent pre- and post-synaptic activity were used to update the synapse, for a total of 24 free parameters across all 4 synapse types, following previous work \cite{confavreux_meta-learning_2023}. The networks were simulated using Auryn, a C++ simulator \cite{zenke_limits_2014} (additional details in Appendix \ref{appendix:spiking-network}). 

\begin{figure}[ht]
\vskip 0.2in
\begin{center}
\centerline{\includegraphics[width=1\linewidth]{figures/task3.png}}
\caption{(\textbf{A}) Example raster plots of the neural activities in a recurrent plastic network over 1s time window. (\textbf{B}) Schematics of the low- and high-fidelity models of a spiking network. \textbf{(C)} Performance of NPE and \method{} evaluated on 1000 true observations with NLTP, and averaged over 10 network initializations, with 95\% confidence intervals.
%All results were obtained over an ensemble of 10 networks with a fixed training dataset (and random train-test split).
}
\label{figure:task3}
\end{center}
\vskip -0.2in
\end{figure}
 
Mean-field theory can be applied to the dynamical system above to obtain the steady-state activities of the excitatory and inhibitory populations as a function of the parameters of the plasticity rules embedded in the network. Though such analysis is widely performed in the field \cite{vogels_inhibitory_2011, confavreux_meta-learning_2023, gerstner_mathematical_2002, gerstner_neuronal_2014}, it has never been used as a low-fidelity model to help with the inference of the high-fidelity model parameters (additional details in Appendix \ref{appendix:spiking-network}). Since there are no dynamics to simulate with the mean-field model, the simulation was almost instantaneous, while the high-fidelity model took approximately 5 minutes to generate a 2-minute long simulation on a single CPU.



% it's just one linear equation, so it's instantaneous (maybe a couple ms in numpy vs say 5 min for the HF simulator)

Summary statistics for both the low- and high-fidelity models were two-dimensional: the average firing rates of the excitatory and inhibitory neurons at steady state (after 2 minutes of simulation in the high-fidelity model). Plastic networks were considered plausible if the measured firing rates were between 1 and 50Hz \cite{dayan_theoretical_2001, confavreux_meta-learning_2023}.



Note that in our task, the low-fidelity model focuses solely on the $E$-to-$E$ and $E$-to-$I$ rules from the high-fidelity model, thereby having 12 out of the 24 parameters of the high-fidelity model. This setup allows us to demonstrate the performance of \method{} on problems with different parameter spaces, highlighting \method{}'s flexibility and advantages.


\begin{table}[ht]
    \centering
    \caption{Comparison between methods. \method4 is pretrained on $10^4$ low-fidelity samples, and \method5 on $10^5$ samples.}
    \label{tab:comparison_methods}
    \begin{tabular}{l l c}
        \toprule
        \textbf{Method} & \textbf{$\#$ simulations} & \textbf{rates 1--50 Hz} \\
        \midrule
        NPE & HF: $10^3$ & 66.4\% \\
        \method4  & HF: $10^3$; LF: $10^4$ & 
        94.2\% \\

        \method5  & HF: $10^3$; LF: $10^5$ & 95.6\% \\
        
        \bottomrule
    \end{tabular}
\end{table}

We found that \method{} has better performance than NPE in terms of NLTP (Fig.~\ref{figure:task3}C). Furthermore, \method{} leads to an increase of almost $30\%$ in the proportion of posterior samples within the target firing rate bounds (Table \ref{tab:comparison_methods}), reinforcing that \method{} is a practical and effective method for simulation-based inference of costly real-world simulators.

% \begin{figure}[ht]
% \vskip 0.2in
% \begin{center}
% \centerline{\includegraphics[width=1\linewidth]{figures/task3-method.pdf}}
% \caption{(Multifidelity) NPE evaluated on 1000 true observations with NLTP, and averaged over 10 network initializations, with 95\% confidence intervals.
% %All results were obtained over an ensemble of 10 networks with a fixed training dataset (and random train-test split).
% }
% \label{figure:task3-methods}
% \end{center}
% \vskip -0.2in
% \end{figure}


% \subsection{Extra}
% \begin{itemize}
%        \item given the co-dependence and permutation between the layers of normalizing flows in order to have all dimensions interact with each other \cite{papamakarios_normalizing_2021}, we should just make sure that the dummy layers are only dependend on the others, and then allow the permutation in the refinement / new hieararchy! TODO As first element after submitting the paper!
%      \item Second element to do: 
%     \item Transformer: Dealing with different dimensionalities: Getting more from less
%     \item collection of multifidelity simulators: \href{https://github.com/sjvrijn/mf2}{link to github}
%     \item Define a 4th benchmarking task, on Navier-Stroke (since they also discuss this in their paper)
%     \item Use physics-informed SBI: so that the partial differential equations can help to reduce the simulation-cost
%     \item Active sampling: Even better predictions: try weighting the sample importance in loss + rebalance with prior trick
%     \item Add NLE as well
%     \item make SBI differentiable: then we don't need LF simulations at all (like differential DNN that are described in related work).
%     \item global and local active learning
%      \item weighted loss, at least a try out (?)
%      \item Explore Transflow learning and how we can use the inverse to transfer from low to high-fidelity model.
% \end{itemize}


\section{Discussion}

We proposed a new method for simulation-based inference that leverages low-fidelity models to efficiently infer the parameters of costly high-fidelity models. By incorporating transfer learning and multifidelity approaches, \method{} substantially reduces the simulation budget required for accurate posterior inference. This addresses a pervasive challenge across scientific domains: the high computational cost of simulating complex high-fidelity models and linking them to empirical data. Our empirical results demonstrate \method{}'s competitive performance in SBI across statistical benchmarks and real-world applications, as compared to a standard method such as NPE.

Despite \method{}'s advantages, the method comes with some challenges. First, the effectiveness of \method{} relies on the similarity between the low-fidelity and high-fidelity models. Fortunately, in many situations, domain experts will know beforehand whether low-fidelity models are poor approximations of high-fidelity models. Second, \method{} and \seqmethod{} inherit the limitations of NPE and TSNPE, respectively, in particular regarding the scalability of simulation-based inference to high-dimensional parameter spaces. How to balance exploration of high-dimensional parameter spaces and computational cost in a simulation-based inference setting remains a topic of active research.

We identify two promising research directions in the realm of multifidelity simulation-based inference. First, we expect that the scalability and expressivity of \method{} can be improved by utilizing the same approaches of multifidelity and transfer learning presented here with neural density estimators other than normalizing flows, such as diffusion models \cite{gloeckler_all--one_2024}. Second, similar to past efforts in developing a benchmark for simulation-based inference, it will be beneficial for the SBI community to develop a benchmark for multifidelity problems, with new tasks, algorithms and evaluation metrics. This will promote rigorous and reproducible research and catalize new developments in multifidelity SBI, and in SBI more generally. Our work and codebase are a step in this direction.



% \begin{table*}[h]
% \caption{Cost-efficiency. 1.0 is seen as standard NPE, $C_{hi} < 1.0$ means the cost is smaller than NPE}
% \label{sample-table}
% \vskip 0.15in
% \begin{center}
% \begin{small}
% \begin{sc}
% \begin{tabular}{llccccr}
% \toprule
% Task & NPE & MF-NPE3 & MF-NPE4 & MF-NPE5 & MF-TSNPE & $\mathcal{T}$  \\
% \midrule
% OU2 & 1.0 & ... & ... & ... & ...\\
% OU3 & 1.0 & ... & ... & ... & ...\\
% OU4 & 1.0 & ... & ... & ... & ...\\
% % OU process & Random walk & 2 & 10 \\
% L5PC  & 1.0 & ... & ... & ... & ...\\
% Spiking network & 1.0 & ... & ... & ...  & ...\\

% \bottomrule
% \end{tabular}
% \end{sc}
% \end{small}
% \end{center}
% \vskip -0.1in
% \end{table*}

% On our machine, we saw $c(100) \approx ... seconds$.

\paragraph{Conclusion}
Overall, \method{} is a method for simulation-based inference that leverages low-fidelity models and transfer learning to infer the parameters of costly high-fidelity models, thus providing an effective balance between computational cost and inference accuracy.


\section*{Acknowledgements}
We thank Karthik Sama, Najlaa Mohamed, Guy Moss, Marcel Nonnenmacher and Pierre Vanvolsem for discussions. Anastasia N. Krouglova was supported by an FWO grant (G097022N). Hayden R.~Johnson was supported by an FWO grant (G053624N). Basile Confavreux was supported by a Schmidt Science Polymath Award to Andrew Saxe, the Sainsbury Wellcome Centre Core Grant from Wellcome (219627/Z/19/Z) and the Gatsby Charitable Foundation (GAT3850). Michael Deistler was supported by the German Research Foundation (DFG) through Germany’s Excellence Strategy (EXC 2064 – Project number 390727645), the German Federal Ministry of Education and Research (Tübingen AI Center, FKZ: 01IS18039A) and the European Union (ERC, ``DeepCoMechTome'', ref. 101089288). Views and opinions expressed are however those of the authors only and do not necessarily reflect those of the European Union or the European Research Council Executive Agency. Neither the European Union nor the granting authority can be held responsible for them. Michael Deistler is a member of the International Max Planck Research School for Intelligent Systems (IMPRS-IS).


\section*{Impact Statement}

%this is the statement suggested at ICML if we feel there is no ethical concern other than the usual ML ones. See instructions here https://icml.cc/Conferences/2025/CallForPapers
This paper presents work whose goal is to advance the field of Machine Learning. There are many potential societal consequences of our work, none which we feel must be specifically highlighted here.

% "As engineering systems become increasingly complex and computational resources remain a limiting factor, methodologies like this will be essential in advancing the field of reliability engineering, ensuring that critical systems perform safely and effectively under a wide range of conditions"


\bibliography{references}
\bibliographystyle{icml2025}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% APPENDIX
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newpage
\appendix
\onecolumn

\section{Further experimental details}
%You can have as much text here as you want. The main body must be at most $8$ pages long.
%For the final version, one more page can be added.
%If you want, you can use an appendix like this one.  
%The $\mathtt{\backslash onecolumn}$ command above can be kept in place if you prefer a one-column appendix, or can be removed if you prefer a two-column appendix.  Apart from this possible change, the style (font size, spacing, margins, page numbering, etc.) should be kept the same as the main body.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Training procedure}
All methods and evaluations were implemented in PyTorch \cite{paszke_pytorch_2019}. We used Zuko package \cite{roset_zuko_2024} implementations of Neural Spline flows (NSF) \cite{durkan_neural_2019} and SBI package \cite{boelts_sbi_2024} for additional functions. The parameters were logit-transformed for numerical stability, and the summary statistics were z-scored to improve the performance of the Normalizing Flows.

The Normalizing Flows had 5 transformations, each parametrized with 50 hidden units and 8 bins, the default settings in the SBI package \cite{boelts_sbi_2024}. All results were obtained over an ensemble of 10 networks with a fixed training dataset and a random train-test split.



\subsection{Data generation and transformations for increased network performance}

During the performance evaluation, we encountered numerical instabilities, particularly with NPE in low-simulation budgets: a substantial proportion of the estimated probability density was placed outside of the uniform prior bounds, a phenomenon dubbed `leakage' that has been previously documented \cite{greenberg_automatic_2019,deistler_truncated_2022}. Logit-transforming the model parameters before training the density estimator resolved the issue.

% In our numerical experiments, the parameters $\theta$ were logit-transformed for numerical stability in the evaluation metrics, since we empirically observed that NPE can have a significant proportion of leakage outside the prior bound with low number of simulations \cite{deistler_truncated_2022}.

This transformation creates a mapping from a bounded to an unbounded space, resulting in a density estimation within the prior bounds after the inverse transformation. In addition, the summary statistics of the simulations were z-scored for improved performance of the density estimator, the default setting in the SBI package \cite{boelts_sbi_2024}. 

% \subsection{Logit-transform}
% \label{appendix:logit-transform}

% % Simulation-based inference typically relies on the rejection-sampling algorithm to evaluate samples that lie within the prior bounds. However, in low-data regimes—particularly with neural posterior estimation (NPE)—the algorithm often encounters challenges, as it tends to get stuck during inference conditional on summary statistics, rejecting a large proportion of samples.
% To address the `leakage' issue, we transformed the sampled model parameters from a bounded space (defined by prior bounds) to an unbounded space during the training process.

% Let $f$ be a logit function that maps $\left[ \pi_{\min}, \pi_{\max}\right]$ into $\left[-\infty, +\infty \right]$. For every random sample $\theta \sim \mathcal{U}(\pi_{min}, \pi_{max})$, we define:
% \begin{equation}
%     % \text{logit } t = \sigma^{-1}(t) = \ln \frac{t}{1-t},
%     y = f(\theta) = \ln \left(\frac{\theta - \pi_\text{min}}{\pi_\text{max}- \theta}\right) \quad\text{for  } \theta \in (\pi_{min}, \pi_{max}).
% \end{equation}
% % where
% % \begin{equation}
% %     t = \frac{\theta-\pi_{\min}}{\pi_{\max}-\pi_{\min}}, \quad\text{for  } \theta \in (\pi_{min}, \pi_{max}).
% % \end{equation}
% To retrieve the original values after the logit transformation after training the density estimator, i.e., the inverse mapping, we define for every continuous probability density function on $\left[ \pi_{\min}, \pi_{\max}\right]$ the following change of variables formula: 

% \begin{equation}
%    \int_{\pi_{\min}}^{\pi_{\max}} p(\theta | x) d\theta = \int_{-\infty}^{+\infty} p(y | x)|J_f(y)|dy.
% \end{equation}

% The logit transformed samples $\theta$ are denoted by $\theta_l$ and the determinant of the Jacobian matrix is $J_{\sigma^{-1}}$. Thus, the change of variables formula allows the retrieval of the probability densities of true samples $\theta$ given the probability density of $\theta_l$ of the estimated probability density function in an unbound space.

% The values of samples from the unbound probability space can be inverted by a bounded sigmoidal function:
% \begin{equation}
%     \theta = f^{-1}(y) = \pi_{\min} + (\pi_{\max} - \pi_{\min})  \frac{1}{1 + e^{-y}}
% \end{equation}


% \section{Convergence of the log-loss function for the high-fidelity model}
% Let $\theta_i \sim p_{\text{hi}}(\theta_i)$ be samples from the prior of a high-fidelity model, and $x_i \sim p_{\text{hi}}(x | \theta_i)$ be simulations with parameters sampled from the prior distribution.
% We define the loss function as the negative log likelihood:
% \begin{equation}
%   \mathcal{L}(\phi) = \min_{\phi} - \frac{1}{N} \sum_i^N \log q_{\phi}(\theta_i | x_i)
% \end{equation}
% With $\phi$, the parameters that are optimized by the neural network.
% Let the number of simulations $N \rightarrow \infty$. Therefore:
% \begin{equation}
%     \begin{split}
%      \min_{\phi} \mathcal{L}(\phi) &=  \min_{\phi}  \mathbb{E}_{p_\text{hi}(x)}\left[D_{\text{KL}}(p_\text{hi}(\theta | x) || q_{\phi}(\theta | x))\right] \\
%       &= \min_{\phi} \left[ - \int_\theta \int_x p_\text{hi}(x)p_\text{hi}(\theta | x) \log {q_{\phi}(\theta | x)}   d\theta dx \right] \\
%      &= \min_{\phi} \left[  \int_\theta \int_x p_\text{hi}(x)p_\text{hi}(\theta | x) \log \frac{1}{q_{\phi}(\theta | x)}   d\theta dx \right] + C \\
%      &= \min_{\phi} \left[  \int_\theta \int_x p_\text{hi}(x)p_\text{hi}(\theta | x) \log \frac{1}{q_{\phi}(\theta | x)}   d\theta dx \right] + \int_\theta \int_x p_\text{hi}(x)p_\text{hi}(\theta | x) \log {p_\text{hi}(\theta | x)} d\theta dx \\
%     &= \min_{\phi} \left[  \int_\theta \int_x p_\text{hi}(x)p_\text{hi}(\theta | x) \log \frac{p_\text{hi}(\theta|x)}{q_{\phi}(\theta | x)}   d\theta dx \right] \\
%     &= \min_{\phi} \left[ \int_x p_\text{hi}(x) D_{\text{KL}}(p_\text{hi}(\theta | x) || q_\phi(\theta | x)) dx\right]\\
%     \end{split}
% \end{equation}
% Where $p(\theta)p(x|\theta)$ is the same as the join probability distribution, i.e., $p(\theta, x)$. Since we are minimizing, adding a constant $C$ to the function that has to be minimized will not make a difference in the minimization. We see that the log-loss function aims to minimize the KL divergence between the theoretical likelihood of the high-fidelity model $p_\text{hi}(\theta | x)$ and estimated likelihood $q_\phi(\theta | x)$. 


% \begin{equation}
%     \mathcal{L}(\phi) = \int p_\text{hi}(x) D_{\text{KL}}(p(\theta | x) || q_{\phi}(\theta | x) ) dx
% \end{equation}


\newpage
\section{Task 1: Ornstein-Uhlenbeck process}
\label{appendix:task1}
% The OU process task was implemented in work on ABC and model misspecification with NPE \cite{chen_neural_2021, huang_learning_2023}.
% We choose to use this toy example rather than standard benchmarking tasks \cite{lueckmann_benchmarking_2021} because this example has a low- and high-fidelity model with a true likelihood, allowing us to verify the sufficiency of the proposed statistics.


\subsection{High-fidelity model: Ornstein-Uhlenbeck Process}
\label{appendix:ornstein-uhlenbeck}

\begin{wrapfigure}{r}{0.3\textwidth}
  %\begin{center}
   %\raisebox{0pt}[\dimexpr\height-0.6\baselineskip\relax]
    %\includegraphics[width=0.4\textwidth]{figures/OU_calibration.pdf}
    \raisebox{0pt}[\dimexpr\height-0.6\baselineskip\relax]{\includegraphics[width=0.3\textwidth]{figures/OU-illustration.png}}%
  %\end{center}
  \caption{The four parameters of the Ornstein-Uhlenbeck process: the mean $\mu$, standard deviation $\sigma$, convergence rate $\gamma$, and $\mu_\mathrm{offset}$, which is the difference between the initial condition $X(0)$ and the mean.}
  \label{figure:OU-illustration}
\end{wrapfigure}

The Ornstein-Uhlenbeck process models a drift-diffusion process of a particle starting at position X(0) and drifting towards an equilibrium state. The model has two main components: a \textit{drift} term and a \textit{diffusion} term:
%
\begin{equation*}
dX_t = \underbrace{\gamma(\mu - X_t)dt}_{\text {drift}} + \underbrace{\sigma  d W_t}_{\text {diffusion}},
\end{equation*}
%
where $\mu$ is the mean of the asymptotic distribution over positions X, $\sigma$ is the magnitude of the stochasticity of the process and $\gamma$ is the convergence speed.
% corresponds to the time constant $\tau$. This means, that a smaller value for $\gamma$ results in a slower convergence to the long-term mean, while a larger $\gamma$ corresponds to a fast-decaying process, as shown in Fig.~\ref{figure:gamma-decay}.
$X(0)$ is the initial position of the process, which we assume to be stochastic: $X(0)\sim \mathcal{N}(\mu+\mu_\text{offset}, 1)$. The parameters of interest that we aim to estimate are $\mu, \sigma, \gamma, \mu_\text{offset}$.


The Ornstein-Uhlenbeck process was approximated with the Euler-Maruyama method:
\begin{equation*} 
X(t+\delta t) = X(t) + f_{\text{drift}}(t,X) \,\delta t + f_{\text{diffusion}}(t,X) \,\sqrt{\delta t} \, \mathcal{N}(0,1).
\end{equation*}
%With brownian motion $W_t = \int_0^t dW/d\tau(\tau)d\tau$ 
% Brownian motion $W_t$ is rewritten as $\sqrt{\delta t}$ to compensate for the time step.
% The initial point $X(0)$ of the Markov process was assumed to be stochastic: $X(0) \sim \mathcal{N}(\mu+\mu_\text{offset}, 1)$.


Starting from the exact likelihood for the Ornstein-Uhlenbeck process given by \citet{kou_multiresolution_2012}:
% The exact likelihood for the OU process (with deterministic $X(0)$) was derived in \citet{kou_multiresolution_2012}:
% The likelihood for the low-fidelity model is described
% described as independent samples 
%
\begin{equation*}
f_{\text {exact hi}}(\boldsymbol{X} \mid \mu, \gamma, \sigma)=\prod_{t=1}^n \frac{1}{\sqrt{\pi g} \sigma} \exp \left\{-\frac{1}{g \sigma^2}\left(\left(\mu-X_t\right)-\sqrt{1-\gamma g}\left(\mu-X_{t-1}\right)\right)^2\right\},
\end{equation*}
where $g=(1 - \exp(-2 \gamma \Delta T)) / \gamma$, we modify it by incorporating an additional parameter $\mu_\mathrm{offset}$ to account for a stochastic $X(0)$.

The full likelihood $f_{\text {exact hi}}(\boldsymbol{X} \mid \mu, \sigma, \gamma, \mu_\text{offset})$ is given by
% . Therefore, we add the log-likelihood of $x(0)$, parametrized by $\mu_\mathrm{offset}$ to the product over timesteps of the summary statistics.
\begin{equation*}
f_{\text {exact hi}}(\boldsymbol{X} \mid \mu, \sigma, \gamma, \mu_\text{offset})=\frac{1}{\sqrt{2\pi} } \exp \left\{-\frac{(x-(\mu+\mu_\text{offset}))^2}{2}\right\}\prod_{t=1}^n \frac{1}{\sqrt{\pi g} \sigma} \exp \left\{-\frac{1}{g \sigma^2}\left(\left(\mu-X_t\right)-\sqrt{1-\gamma g}\left(\mu-X_{t-1}\right)\right)^2\right\}
\end{equation*}
%
% \begin{figure}[ht]
% \vskip 0.2in
% \begin{center}
% \centerline{\includegraphics[width=\columnwidth-90]{figures/appendix_change_gamma.pdf}}
% \caption{Visualisation of the decay of gamma with respect to their values. \textcolor{red}{TODO: remove bar and cleanup title}}
% \label{figure:gamma-decay}
% \end{center}
% \vskip -0.2in
% \end{figure}
\begin{wrapfigure}{r}
{0.3\textwidth}
\vskip 0.1in
  %\begin{center}
   %\raisebox{0pt}[\dimexpr\height-0.6\baselineskip\relax]
    %\includegraphics[width=0.4\textwidth]{figures/OU_calibration.pdf}
    \raisebox{0pt}[\dimexpr\height-0.6\baselineskip\relax]{\includegraphics[width=0.3\textwidth]{figures/GS-illustration.png}}%
  %\end{center}
  \caption{i.i.d. Gaussian samples with mean $\mu_\mathrm{L}$ and standard deviation $\sigma_\mathrm{L}$.}
  \label{figure:GS-illustration}
\end{wrapfigure}
\subsection{Low-fidelity model: i.i.d.~Gaussian Samples}
At convergence, the distribution over $X_t$ approaches a Gaussian distribution with mean $\mu$ and standard deviation $\frac{\sigma}{\sqrt{2\gamma}}$. In our setup, we chose a low-fidelity model that corresponds to time-independent random draws from a Gaussian distribution with mean $\mu_\textrm{lo}$ and standard deviation $\sigma_\textrm{lo}$:
\begin{equation}
    X_t \sim \mathcal{N}(\mu_\text{lo},\sigma_\text{lo}^2)
\end{equation}

The posterior distribution over the parameters of the low-fidelity model has a biased mean influenced by the initial position  $\mu_\mathrm{offset}$ and convergence speed $\gamma$.
   
The \textbf{summary statistics} from both the high-fidelity and low-fidelity models consisted of 10 subsamples drawn from a trace of 100 timesteps. Parameters and summary statistics are described in Fig.~\ref{figure:GS-illustration}.

% \begin{figure}[ht]
% % \vskip 0.2in
% \begin{center}
% \centerline{\includegraphics[width=10cm]{figures/task1A.pdf}}
% \caption{The four parameters of the Ornstein-Uhlenbeck process: the long-term convergence mean $\mu$, standard deviation $\sigma$, convergence rate $\gamma$, offset from the mean $\mu_\mathrm{offset}$ for $X(t_0)$.}
% \label{figure:OU-illustration}
% \end{center}
% \vskip -0.3in
% \end{figure}


% In this example, you clearly see that with the increase of gamma, the decay becomes larger/smaller.



% \subsection{Histograms}
% In Fig.~\ref{figure:histograms-OUprocess}, we show the predictions of the Classifier-2-sample test (C2ST) for 30 observations across 10 network initialization (i.e., 300 predictions). Overall, we see a broader ranges of C2STs in low-data regimes, with \method{} showing many training instances with lower C2ST than NPE.
% \begin{figure}[ht]
% \vskip 0.2in
% \begin{center}
% \centerline{\includegraphics[width=\columnwidth]{figures/histograms_OU.pdf}}
% \caption{C2ST values of OU process with two degrees of freedom show less variation in high-data modes.}
% \label{figure:histograms-OUprocess}
% \end{center}
% \vskip -0.2in
% \end{figure}


\newpage
\subsection{Posterior distribution over different dimensionalities}
\label{appendix:dealing-with-diff-dimensionalities}
When the low-fidelity has lower number of parameters than the high-fidelity model, we pre-train the low-fidelity density estimator with dummy parameter values in the dimensions exclusive to the high-fidelity model. Effectively, the pre-conditioning with the dummy variables leads to the pre-trained neural density estimator to effectively estimate the prior distribution over the respective parameters (Figure \ref{figure:diff-dim-OU}A). Despite the different dimensionalities, the posterior estimates from \method{} are closer to the ground-truth posterior than NPE (Figure \ref{figure:diff-dim-OU}B,C).


\begin{figure}[ht]
\vskip 0.2in
\begin{center}
\centerline{\includegraphics[width=\linewidth]{figures/diff-dimensionalities.png}}
\caption{\textbf{Posterior distributions for the OU process}.  \textbf{(A)} Posterior distribution under the low-fidelity (i.e., pre-trained) model estimated with \method{}. Blue contours contain 68$\%$ of the true posterior mass for the low-fidelity model. Vertical bars and dots correspond to the value of the true parameters. Note the different scale in the x-axis with respect to panels (B) and (C). \textbf{(B)} Density estimation with MF-NPE3, after retraining the low-fidelity model on high-fidelity samples. Blue contours contain 68$\%$ of the true posterior mass for the high-fidelity model.\textbf{(C)} Density estimation with NPE. Blue contours contain 68$\%$ of the true posterior mass for the high-fidelity model.
}
\label{figure:diff-dim-OU}
\end{center}
\vskip -0.2in
\end{figure}

% \subsection{Model similarity \textcolor{red}{todo: rewrite because gamma decay is interpreted a bit different}}


% We evaluated across different sets of $\mu_\mathrm{offset}$ and $\gamma$ (So two extreme cases: mu offset: 5, gamma 0.1 and mu offset: 5, gamma 1.0). \textcolor{red}{Figure...}, a comparison matrix presents a C2ST evaluation between the parameters $(\mu^*_\mathrm{lo}, \sigma^*_\mathrm{lo})$ and $(\mu^*, \sigma^*)$ obtained from the analytical solutions of the low- and high-fidelity posterior distributions with controlled variation in $\gamma$ and $\mu_\mathrm{offset}$ values.



    
% We observe a clear linear relationship between the similarity of the posterior distributions and the increase/decrease of $\gamma$ and $\mu_\mathrm{offset}$ captured by the following equation, after fitting the c2st values, $\gamma$ and $\mu_\mathrm{offset}$ with a linear regression model:
%     % I derived it by fitting a linear regression
%      \begin{equation}
%          f(\gamma, \mu_\mathrm{offset}) = 
%          -0.07 \gamma + 0.06 \mu_\mathrm{offset} + 0.82
%      \end{equation}
%     Showing that $\gamma$ and $\mu_\mathrm{offset}$ have a similar impact on the difference between the low and high-fidelity model. Note that the C2ST value does not converge to 0.5 when the drift term is dropped. This is because the posterior shapes between both model outputs are different.

%     % \begin{figure}[ht]
%     %   \begin{center}
%     % \centerline{\includegraphics[width=6cm]{figures/task1B.pdf}}
%     % \caption{Classification accuracy (C2ST) of the distance between the analytical solution of the low-fidelity and high-fidelity models. Evaluated on 50 observations across different values of $\gamma$ and $\mu_\mathrm{offset}$. Thorough analysis of extremas in \ref{appendix:OU_parameters} }
%     % \label{figure:task1B}
%     % \end{center}
%     % \vskip -0.3in
%     % \end{figure}



% Interestingly, when the models are more similar (mu offset 0 is almost iid Gaussian), NPE is doing a worse job than when they are very different, but the MF seems to help evenly well, especially when pretrained on many samples.

% \begin{figure}[ht]
% \vskip 0.2in
% \begin{center}
% \centerline{\includegraphics[width=\columnwidth]{figures/appendix_change_dims.pdf}}
% \caption{The similarity of the posteriors or traces did not have a large impact on the predictions \textcolor{red}{(see appendix)}. This is coherent with Tahir's publication features and fate \cite{tahir_features_2024}, where he analytically showed that the similarity of the traces/output does not influence transfer learning, but the weights and biases do. }
% \label{icml-historical}
% \end{center}
% \vskip -0.2in
% \end{figure}



% \subsection{Method Calibration}
% \label{appendix:method-calibration}



% % \begin{wrapfigure}{r}{0.3\textwidth}
% %   %\begin{center}
% %    %\raisebox{0pt}[\dimexpr\height-0.6\baselineskip\relax]
% %     %\includegraphics[width=0.4\textwidth]{figures/OU_calibration.pdf}
% %     \raisebox{0pt}[\dimexpr\height-0.6\baselineskip\relax]{\includegraphics[width=0.3\textwidth]{figures/OU_calibration.pdf}}%
% %   %\end{center}
% %   \caption{Calibration method of our NPE implementation and NPE provided by SBI. The evaluation was performed on 50 true summary statistics and averaged over 30 network initializations for the Ornstein-Uhlenbeck task with 2 degrees of freedom.}
% %   \label{figure:OU_calibration}
% % \end{wrapfigure}

% Our custom implementation of NPE (and \method) and NPE provided by the SBI package \cite{boelts_sbi_2024} have been calibrated with the same hyperparameters. Fig.~\ref{figure:calibration} illustrates that the same predictions over the same data averaged over 30 random network initializations. The summary statistics have been z-scored, and the parameters have been z-scored or logit-transformed across tasks.

% \begin{figure}[h!]
%   \begin{center}
%     \raisebox{0pt}[\dimexpr\height-0.6\baselineskip\relax]{\includegraphics[width=0.3\textwidth]{figures/OU_calibration.pdf}}%
%   \end{center}
%   \caption{Method calibration between custom NPE implementation and the SBI package \cite{boelts_sbi_2024}}
%   \label{figure:calibration}
% \end{figure}
% % Here, the prior bounds of $\gamma$, which is 1 over the time constant, define the range of numerically stable solutions of the Ornstein-Uhlenbeck process with a slope that converges to the long-term mean between \textcolor{red}{+- 5-100 timesteps}. We study the OU cases where the $\mu_\mathrm{offset}$ is positive and has a probability distribution overlap between the analytical solutions of the low-fidelity and high-fidelity simulations.




\newpage
\section{Task 2: Multicompartmental single neuron model}
\label{appendix:multicompartmental}
The response of a morphologically detailed neuron to an input current is typically modeled with a multicompartmental neuron model wherein the voltage dynamics of each compartment $\mu$ are based on Hodgkin-Huxley equations \cite{hodgkin_quantitative_1952}:
    \begin{equation}
    \begin{aligned}
        c_{\mathrm{m}} \frac{d V_\mu}{d t} = & -i_{\mathrm{m}}^\mu+\frac{I_{\mathrm{e}}^\mu}{A_\mu} 
        +g_{\mu, \mu+1}\left(V_{\mu+1}-V_\mu\right) \\
       &  +g_{\mu, \mu-1}\left(V_{\mu-1}-V_\mu\right).
        \end{aligned}
    \end{equation}

    The total membrane current $i_\mathrm{m}$ for a specific compartment is the sum over different types of ion channels $i$, such as sodium, potassium and leakage channels: 
    \begin{equation}
        i_\mathrm{m} = \bar{g}_\mathrm{Na}m^3h(V-E_\mathrm{Na}) + \bar{g}_\mathrm{K}n^4(V-E_\mathrm{K}) + \bar{g}_\mathrm{L}(V - E_\mathrm{L}) + \bar{g}_\mathrm{M}p(V - E_\mathrm{M}) 
        %\sum_i g_i(V-E_i).
    \end{equation}

    We are interested in inferring the densities of two prominent ion channels $\bar{g}_\mathrm{Na}$ and $\bar{g}_\mathrm{K}$. 
    % The fixed parameters for the model are $\bar{g}_\mathrm{L}=0.001$, ... and varying radius, length.. Axial resisistivity = 5000.0, capacitance = 1.0
% \textbf{Low-fidelity model} A low-fidelity variation of a multi-compartmental neuron model is a single-compartmental model, a simplification wherein the spatial dimension is neglected. This simplified model is fast to simulate. However, it is often weakly justifiable because 
    % the decrease in the strength of the voltage depends on its frequency, and even passive synaptic inputs can cause significant voltage fluctuations over short spatial distances \cite{brette_what_2015}. The single-compartmental neuron model is described as follows:
    % \begin{equation}
    %     c_\mathrm{m}\frac{d V}{d t} = - i_\mathrm{m} + \frac{I_\mathrm{e}}{A}.
    % \end{equation}
The low- and high-fidelity models differ in the number of compartments per branch: the low-fidelity model has a single compartment per branch, while the high-fidelity model consists of eight compartments per branch.

All simulations were performed using Jaxley \cite{deistler_differentiable_2024} over 120 ms. The injection current is a step current of 0.55mV over 100 ms, with a delay of 10ms. The step size of the simulator is 0.025.

When sampling from the prior distribution over parameters, approximately $0.1 \%$ of the respective simulations had clearly unrealistic summary statistics: these simulations were iteratively replaced by random draws from the prior distribution until we collected a desired number of valid simulations.

\subsection{Posterior distributions}
Posterior distributions over the parameters of the multicompartmental neuron model trained on 10k high-fidelity simulations.
\begin{figure}[ht]
\vskip 0.2in
\begin{center}
\centerline{\includegraphics[width=\columnwidth]{figures/posterior-dist-multicomp.png}}
\caption{Simulation-based calibration and respective posterior distributions for the multicompartmental neuron model trained on 10k high-fidelity simulations.}
\label{figure:multicomp-posteriors}
\end{center}
\vskip -0.2in
\end{figure}

\newpage
\subsection{Posterior Predictive Checks}
MF-NPE gives similar results as NPE with a training set of high-fidelity simulations up to two orders of magnitude smaller than NPE.
\begin{figure}[ht]
\vskip 0.2in
\begin{center}
\centerline{\includegraphics[width=\columnwidth]{figures/ppc-multicomp.png}}
\caption{Posterior predictives for the multicompartmental neuron model.}
\label{figure:ppc-multicomp}
\end{center}
\vskip -0.2in
\end{figure}

% \subsection{Simulator output}
% \label{appendix:simulator-output-multicomp}
% We present two simulations with the a 1- and 100-compartmental neuron model to illustrate that the model output (and summary statistics) are different between the two models (given the same true parameters).

% \begin{figure}[ht]
% \vskip 0.2in
% \begin{center}
% \centerline{\includegraphics[width=\columnwidth]{figures/multicomp-diff-models.pdf}}
% \caption{The low- and high-fidelity models return different model outputs.}
% \label{figure:multicomp-diff-models}
% \end{center}
% \vskip -0.2in
% \end{figure}

%  We showcase that our evaluation on the 1- and 100 compartmental neuron model give very similar results as with the L5PC neuron (where the low-fidelity model contains more compartments):

% \begin{figure}[ht]
% \vskip 0.2in
% \begin{center}
% \centerline{\includegraphics[width=\columnwidth]{figures/100-compartmental.pdf}}
% \caption{The low- and high-fidelity models return different model outputs.}
% \label{figure:multicomp-diff-models}
% \end{center}
% \vskip -0.2in
% \end{figure}


\newpage
\section{Task 3: Spiking network model}
\label{appendix:spiking-network}
\subsection{High-fidelity model}
We considered a recurrent spiking network of 5120 neurons (4096 excitatory, 1024 inhibitory), with parameters taken from \citet{confavreux_meta-learning_2023}.
The membrane potential dynamics of neuron $j$, excitatory ($E$) or inhibitory ($I$), followed
\begin{equation}
    \tau_{m}\frac{\text{d}V_j}{\text{d}t} = -\left(V_j-V_\text{rest}\right) - g^\text{E}_j(t)\left(V_j-E_\text{E}\right) - g^\text{I}_j(t)\left(V_j-E_\text{I}\right),
\end{equation}
A postsynaptic spike was generated whenever the membrane potential $V_j(t)$ crossed a threshold $V^\text{th}_j(t)$, with an instantaneous reset to $V_\text{reset}$. This threshold $V^\text{th}_j(t)$ was incremented by $V^\text{th}_\text{spike}$ every time neuron $j$ spiked and otherwise decayed following
\begin{equation}
    \tau_\text{th}\frac{\text{d}V^\text{th}_j}{\text{d}t} = V^\text{th}_\text{base}-V^\text{th}_j.
\end{equation}
The excitatory and inhibitory conductances, $g^\text{E}$ and $g^\text{I}$ evolved such that
\begin{equation}
    \begin{split}
    g_j^\text{E}(t) = a g^\text{AMPA}_j(t) + (1-a)g^\text{NMDA}_j(t) \quad \text{ and } \quad \frac{\text{d}g_j^\text{I}}{\text{d}t} = -\frac{g_j^\text{I}}{\tau_\text{GABA}} + \sum_{i \in \text{Inh}} w_{ij}(t) \delta_i(t) \\
    \text{with } \quad \frac{\text{d}g_j^\text{AMPA}}{\text{d}t} = -\frac{g_j^\text{AMPA}}{\tau_\text{AMPA}} + \sum_{i \in \text{Exc}} w_{ij}(t) \delta_i(t)  \quad \text{and } \quad \frac{\text{d}g_j^\text{NMDA}}{\text{d}t} = \frac{g_j^\text{AMPA}(t) - g_j^\text{NMDA}}{\tau_\text{NMDA}},
    \end{split}
\end{equation}
with $w_{ij}(t)$ the connection strength between neurons $i$ and $j$ (unitless), $\delta_k(t)=\sum \delta(t-t_k^*)$ the spike train of pre-synaptic neuron $k$, where $t_k^*$ denotes the spike times of neuron $k$, and $\delta$ the Dirac delta. 
All neurons received input from 5k Poisson neurons, with 5\% random connectivity and constant rate $r_\text{ext}=10$Hz in each simulation. The recurrent connectivity was instantiated with random sparse connectivity (10\%).
All recurrent synapses in the network ($E$-to-$E$ and $E$-to-$I$, $I$-to-$E$, $I$-to-$I$) underwent variations of spike-timing dependent plasticity (STDP) \cite{gerstner_mathematical_2002, confavreux_meta-learning_2023}. Given the learning rate $\eta$, the weights between the neurons $i$ and $j$ of connection type $X$-to-$Y$ evolved over time as:
% uses co-active polynomial rules to
%We used plasticity rules that are flexibly parameterized using polynomials. The fixed parameters are inherited from \cite{zenke_diverse_2015, confavreux_meta-learning_2023}
%The four co-active polynomial rules at hand are
\begin{equation}
\begin{aligned}
\frac{d w_{ij}}{d t}= & \eta\left[\delta_{\text{pre}}(t)\left(\alpha+\kappa x_{\text{post}}(t)\right)\right. \\
& \left.+\delta_{\text{post}}(t)\left(\beta+\gamma x_{\text{pre}}(t)\right)\right].
\end{aligned}
\end{equation}
with variables $x_i(t)$ and $x_j(t)$ describing the pre- and postsynaptic spikes over time:
\begin{equation}
    \frac{\mathrm{d} x_i}{\mathrm{~d} t}=-\frac{x_i}{\tau_{\mathrm{XY}}^{\mathrm{pre}}}+\delta_i(t) \quad \text { and } \quad \frac{\mathrm{d} x_j}{\mathrm{~d} t}=-\frac{x_j}{\tau_{\mathrm{XY}}^{\text {post }}}+\delta_j(t)
\end{equation}
with $\tau_\text{XY}^\text{pre}$ and $\tau_\text{XY}^\text{post}$ the time constants of the traces associated with the pre- and postsynaptic neurons, respectively.

The 24 free parameters of interest were $\tau_\text{pre}, \tau_\text{post}, \alpha , \beta, \kappa, \gamma$ multiplied by the number of synapse types (e.g., $\alpha_{EE}, \alpha_{II}, \alpha_{EI}, \alpha_{IE}$), following previous work \cite{confavreux_meta-learning_2023}. 
% \begin{figure}[ht]
% \vskip 0.2in
% \begin{center}
% \centerline{\includegraphics[width=0.3\columnwidth]{figures/mean_field-concept.pdf}}
% \caption{Historical locations and number of accepted papers for International
% Machine Learning Conferences (ICML 1993 -- ICML 2008)}
% \label{icml-historical}
% \end{center}
% \vskip -0.2in
% \end{figure}

\subsection{Low-fidelity model}
Following previous work \cite{confavreux_meta-learning_2023, vogels_inhibitory_2011, dayan_theoretical_2001}, a (partial) mean-field theory applied to the $E$-to-$E$ and $E$-to-$I$ connections in the model described above gave:
\begin{equation}
    r^*_\text{E} = \frac{-\alpha_\text{EE} -\beta_\text{EE}}{\lambda_\text{EE}} \quad \text { and } \quad 
    r^*_\text{I} = \frac{-\alpha_\text{EI} r^*_\text{E} }{\beta_\text{EI} + \lambda_\text{EI} r^*_\text{E}} 
\end{equation}
with $r^*_\text{E}$ and $r^*_\text{I}$ the firing rates of the excitatory (resp. inhibitory) population at steady state, and
\begin{equation}
    \lambda_\text{XY} = \kappa_\text{XY} \tau^\text{post}_\text{XY} + \gamma^\text{pre}_\text{XY}
\end{equation}

With type $(X,Y) \in \{E, I\}$. For all synapse types, we assume $(-\alpha_\text{XY} - \beta_\text{XY}) > 0$ and $\lambda_\text{XY} > 0$, as a second-order stability condition \cite{confavreux_meta-learning_2023}. Note that in this low-fidelity model, we only considered 2 of the 4 plastic conditions, and thus 12 of the 24 free parameters of the high-fidelity model.





% \section{Summary}

% \begin{table}[ht]
% \caption{Gain across models with various fidelities}
% \label{sample-table}
% \vskip 0.15in
% \begin{center}
% \begin{small}
% \begin{sc}
% \begin{tabular}{llccccr}
% \toprule
% High-fidelity & Low-fidelity & MI & $d_\theta$ & $d_x$ & $c_\text{lo}$ & $c_\text{hi}$ \\
% \midrule
% OU process    & gaussian samples & 96.7$\pm$ 0.2& 2-4 & 10 & ... & ... \\
% OU process & Random walk & 80.0$\pm$ 0.6& $\times$\\
% 100-comp neuron & 1-comp neuron & 83.8$\pm$ 0.7& $\surd$ \\
% Spiking network & mean-field & 78.3$\pm$ 0.6&       \\

% OU process & gaussian samples & 2-4 & 10 \\
% % OU process & Random walk & 2 & 10 \\
% 100-comp neuron & 1-comp neuron & 2 & 2 \\
% Spiking network & mean-field & 25 &  4  
% \bottomrule
% \end{tabular}
% \end{sc}
% \end{small}
% \end{center}
% \vskip -0.1in
% \end{table}

\newpage
\section{Prior bounds across tasks}
For the OU process task, we chose a uniform prior with bounds that would lead to a range of different outputs. For the multicompartment neuron model task, we chose a uniform prior with bounds based on the work of \citet{deistler_truncated_2022}. For the spiking network model task, we chose a uniform prior with bounds based on the work of \citet{confavreux_meta-learning_2023}.

\begin{table}[ht]
\caption{Prior bounds for i.i.d.~Gaussian samples and the Ornstein-Uhlenbeck process.}
\label{tab:OU-process}
\vskip 0.15in
\begin{center}
\begin{small}
\begin{sc}
\begin{tabular}{ccc}
\toprule
parameter name & lower bound & upper bound \\
\midrule
        $\mu$ & 0.1 & 3.0 \\
         $\sigma$ & 0.1 & 0.6 \\
         $\gamma$ & 0.1 & 1.0 \\
         $\mu_\mathrm{offset}$ & 0.0 & 4.0 \\
\bottomrule
\end{tabular}
\end{sc}
\end{small}
\end{center}
\vskip -0.1in
\end{table}


\begin{table}[ht]
\caption{Prior bounds for the single- and multicompartmental neuron model.}
\label{tab:multicomp}
\vskip 0.15in
\begin{center}
\begin{small}
\begin{sc}
\begin{tabular}{ccc}
\toprule
parameter name & lower bound & upper bound \\
\midrule
        $\bar{g}_\text{Na}$ & $0.005$ & $0.8$ \\
         $\bar{g}_\text{K}$ & $10^{-6}$ & $0.15$ \\
\bottomrule
\end{tabular}
\end{sc}
\end{small}
\end{center}
\vskip -0.1in
\end{table}


\begin{table}[ht]
\caption{Prior bounds for each synapse type ($E$-to-$E$, $E$-to-$I$, $I$-to-$E$ and $I$-to-$I$) for the spiking neural network and mean-field model.
}
\label{tab:spiking}
\vskip 0.15in
\begin{center}
\begin{small}
\begin{sc}
\begin{tabular}{ccc}
\toprule
parameter name & lower bound & upper bound \\
\midrule
        $\tau_\mathrm{pre}$ & $0.01$ & $0.1$ \\
         $\tau_\mathrm{post}$ & $0.01$ & $0.1$ \\
          $\alpha$ & $-2$ & $2$ \\
          $\beta$ & $-2$ & $2$ \\
          $\gamma$ & $-2$ & $2$ \\
          $\kappa$ & $-2$ & $2$ \\
\bottomrule
\end{tabular}
\end{sc}
\end{small}
\end{center}
\vskip -0.1in
\end{table}


% \section{Overview of model dimensionalities}
% \label{appendix:model-dimensionalities}
% \begin{table}[h!]
% \caption{Number of free parameters for the low- and high-fidelity models.
% }
% \label{tab:overview-dims}
% \vskip 0.15in
% \begin{center}
% \begin{small}
% \begin{sc}
% \begin{tabular}{ccc}
% \toprule
% hf task & lf model & hf model \\
% \midrule
%         OU2 & 2 & 2 
%         \\
%          OU3 & 2 & 3
%          \\
%           OU4 & 2 & 4
%           \\
%           multicompartmental neuron & 2 & 2
%           \\
%           spiking network & 12 & 24 \\
% \bottomrule
% \end{tabular}
% \end{sc}
% \end{small}
% \end{center}
% \vskip -0.1in
% \end{table}

\newpage
\section{Sequential Algorithms}
\subsection{\seqmethod{}}
\label{appendix:mf-tsnpe}
   \begin{algorithm}[ht]
   \caption{\seqmethod{}}
   \label{alg:mf-tnpe}
\begin{algorithmic}
   \STATE {\bfseries Input:} 
   $N$ pairs of $(\boldsymbol{\theta},\boldsymbol{x}_\text{L})$; 
   conditional density estimators $q_\psi(\boldsymbol{\theta} | \boldsymbol{x}_\text{L})$ and $q_\phi(\boldsymbol{\theta} | \boldsymbol{x})$ with learnable parameters $\psi$ and $\phi$; early stopping criterion $S$; simulator $p_\mathrm{H}(\boldsymbol{x}|\boldsymbol{\theta})$; prior $p(\boldsymbol{\theta})$; number of rounds $R$; $\epsilon$ that defines the highest-probability region ($\mathrm{HPR}_\epsilon$); number of high-fidelity simulations per round $M$.
   \STATE {\bfseries Output:} posterior estimate $q_\phi(\boldsymbol{\theta}|\boldsymbol{x})$
   
   \STATE $\mathcal{L}(\psi) = \frac{1}{N} \sum_{i=1}^N-\log q_\psi\left(\boldsymbol{\theta}_i | \boldsymbol{x}^\text{L}_i\right)$ .

   % \STATE $\phi^t = \phi^{t-1}-\alpha(ADAM(\nabla_\phi \mathcal{L}(\phi)))$

   \FOR{epoch in epochs}
   \STATE train $q_\psi$ to minimize $\mathcal{L(\psi)}$ until $S$ is reached.
   \ENDFOR
   \STATE Initialize $\tilde{p}(\boldsymbol{\theta})$ as $p(\boldsymbol{\theta})$
   \STATE Initialize $q_\phi$ with weights and biases of trained $q_\psi$.
    \FOR{r in $R$}
        \STATE $\boldsymbol{\theta}^{(r)} \sim \tilde{p}(\boldsymbol{\theta})$, sample parameters from proposal
        \STATE $\boldsymbol{x}^{(r)} \sim p_\mathrm{H}(\boldsymbol{x}|\boldsymbol{\theta}^{(r)})$, generate high-fidelity simulations 
        \FOR{epoch in epochs}
        \STATE $\mathcal{L}(\phi) = \frac{1}{M} \sum_{i=1}^M-\log q_\phi\left(\boldsymbol{\boldsymbol{\theta}}^{(r)}_i | \boldsymbol{x}^{(r)}_i\right)$.
        \STATE train $q_\phi$ to minimize $\mathcal{L(\phi)}$ until $S$ is reached.
        \ENDFOR
        \STATE Compute expected coverage ($\tilde{p}(\boldsymbol{\theta})$, $q_\phi$)
        \STATE $\tilde{p}(\boldsymbol{\theta}) \propto p(\boldsymbol{\boldsymbol{\theta}}) \cdot \mathbbm{1}_{\theta \in \mathrm{HPR}_\epsilon}$
    \ENDFOR
    

\end{algorithmic}
\end{algorithm}

All experiments were ran with $R = 5$ rounds and $\epsilon = 1e^{-6}$. More details about TSNPE at \citet{deistler_truncated_2022}.


%\hfill
\newpage
\subsection{A-\seqmethod{}}
\label{appendix:active-mf-tsnpe}
   \begin{algorithm}[ht]
   \caption{A-\seqmethod{}}
   \label{alg:a-mf-npe}
\begin{algorithmic}
   \STATE {\bfseries Input:} 
   $N$ pairs of $(\boldsymbol{\theta},\boldsymbol{x}_\text{L})$; 
   conditional density estimator $q_\psi(\boldsymbol{\theta} | \boldsymbol{x}_\text{L})$ with learnable parameters $\psi$ and and ensemble of conditional density estimators $\{q^e_\phi(\boldsymbol{\theta} | \boldsymbol{x})\}^e_E$, each with independent $\phi$; early stopping criterion $S$; simulator $p_\mathrm{H}(\boldsymbol{x}|\boldsymbol{\theta})$; prior $p(\boldsymbol{\theta})$; number of rounds $R$; $\epsilon$ that defines the highest-probability region ($\mathrm{HPR}_\epsilon$); number of high-fidelity simulations per round $M$. 

  \STATE {\bfseries Output:} Ensemble posterior estimate $q_\phi(\boldsymbol{\theta}|\boldsymbol{x}) = \frac{1}{E} \sum^{E}_{e=1} q^e_\phi(\boldsymbol{\theta}|\boldsymbol{x})$
   
   \STATE $\mathcal{L}(\psi) = \frac{1}{N} \sum_{i=1}^N-\log q_\psi\left(\boldsymbol{\theta}_i | \boldsymbol{x}^\text{L}_i\right)$ .

   % \STATE $\phi^t = \phi^{t-1}-\alpha(ADAM(\nabla_\phi \mathcal{L}(\phi)))$

   \FOR{epoch in epochs}
   \STATE train $q_\psi$ to minimize $\mathcal{L(\psi)}$ until $S$ is reached.
   \ENDFOR
   \FOR{e $\in$ Ensemble}
   \STATE Initialize $q_\phi^{e}$ with weights and biases of trained $q_\psi$.
   \ENDFOR
    \STATE $\boldsymbol{\theta}_{\mathrm{pool}} \sim p(\boldsymbol{\theta})$
   \STATE Initialize $\tilde{p}(\boldsymbol{\theta})$ as $p(\boldsymbol{\theta})$
    \FOR{r in $R$}
        \STATE $\boldsymbol{\theta}^{(r)}_{\mathrm{prop}} \sim \tilde{p}(\boldsymbol{\theta})$, generate $M-B$ samples from proposal
        \STATE $\boldsymbol{\theta}^{(r)}_{\mathrm{active}} $ = top $B$ values from $\boldsymbol{\theta}_{\mathrm{pool}}$ using the acquisition function eq.~\eqref{eq:acq_func}
        \STATE $\boldsymbol{\theta}^{(r)} =\{\boldsymbol{\theta}_{\mathrm{prop}}^{(r)} \cup \boldsymbol{\theta}_{\mathrm{active}}^{(r)}\}$
        \STATE $\boldsymbol{x}^{(r)} \sim p_\mathrm{H}(\boldsymbol{x}|\boldsymbol{\theta}^{(r)})$, generate high-fidelity simulations 
        \FOR {e $\in$ Ensemble}
        \FOR{epoch in epochs}
        \STATE $\mathcal{L}(\phi) = \frac{1}{M} \sum_{i=1}^M-\log q^e_\phi\left(\boldsymbol{\boldsymbol{\theta}}^{(r)}_i | \boldsymbol{x}^{(r)}_i\right)$.
        \STATE train $q_\phi$ to minimize $\mathcal{L(\phi)}$ until $S$ is reached.
        \ENDFOR
        \ENDFOR
        \STATE Compute expected coverage ($\tilde{p}(\boldsymbol{\theta})$, $\frac{1}{E}\sum q^e_\phi(\boldsymbol{\theta}|\boldsymbol{x})$)
        \STATE $\tilde{p}(\boldsymbol{\theta}) \propto p(\boldsymbol{\boldsymbol{\theta}}) \cdot \mathbbm{1}_{\theta \in \mathrm{HPR}_\epsilon}$
    \ENDFOR
    

\end{algorithmic}
\end{algorithm}

All experiments were ran with $R = 5$ rounds,  $\epsilon = 1e^{-6}$, and an ensemble of 5 networks. We set $B = .2M$ to mitigate the concern of biasing the posterior with parameters selected with the acquisition function.


\end{document}

