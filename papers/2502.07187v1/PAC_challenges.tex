\section{Challenges in Extending to the PAC Model}\label{Section:PAC-difficulties}

Let us now describe by some of the challenges involved in extending \Cref{Theorem:local-regularization-fails} to the \emph{Probably Approximately Correct} (PAC) learning model of \citet{valiant1984theory}. We begin by recalling the model. 

\begin{definition}
Let $\CH \subseteq \CY^\CX$. A probability measure $\CD$ over $\CX \times \CY$ is \defn{$\CH$-realizable} if there exists an $h \in \CH$ for which
\[ L_\CD(h) := \E_{(x, y) \sim \CD} \big( \ell_{0-1}(h(x), y) \big) = 0. \] 
\end{definition}

\begin{definition}
Let $\CH \subseteq \CY^\CX$ be a hypothesis class and $\CA$ a learner. $\CA$ is said to be a \defn{PAC learner} for $\CH$ if there exists a function $m \colon (0, 1)^2 \to \N$ with the following property: for any $\CH$-realizable distribution $\CD$ and any $\epsilon, \delta \in (0, 1)$, if $S \sim \CD^{n}$ is a sample of size $n \geq m(\epsilon, \delta)$ drawn i.i.d.\ from $\CD$, then 
\[ L_\CD(\CA(S)) \leq \epsilon \] 
with probability at least $1 - \delta$ over the random choice of $S$. 
\end{definition}

In short, the PAC model differs from the transductive model by considering underlying probability distributions $\CD$ and requiring learners to attain favorable performance on $\CD$-i.i.d.\ test points when trained on $\CD$-i.i.d.\ training sets. Notably, the condition of learnability (by an arbitrary learner) is equivalent for both the PAC and transductive models. Furthermore, there are efficient reductions for converting optimal PAC learners into nearly-optimal transductive learners (and vice versa), demonstrating an equivalence between sample complexities in both models, up to only a logarithmic factor in the error parameter \citep{trans_equiv_pac?}. Converting a PAC learner $\CA$ into a transductive learner, however, requires randomly sampling from the training set $S$ and calling $\CA$ on the resulting dataset. This procedure does \emph{not} preserve the algorithmic form of transductive learners (as the resulting learner may even misclassify a point in $S$), and thus \Cref{Theorem:local-regularization-fails} does not imply --- at a black-box level --- the failure of local regularizers in the PAC model. 

We now describe three primary sources of difficulty in porting \Cref{Theorem:local-regularization-fails} to the PAC model. 

\begin{itemize}
    \item \textbf{Favoring non-ground-truth hypotheses.} The proof of \Cref{Theorem:local-regularization-fails}, and in particular of \Cref{Lemma:internal-main-theorem}, makes use of a train/test setting in which there are exactly two hypotheses attaining zero empirical error, only one of which --- the ground truth hypothesis --- is correct for the test point. Using this fact, we are able to deduce precise inequalities relating the various candidate ground truth hypotheses considered, which collectively lead to a contradiction. (I.e., to a cycle in the preferences of the local regularizer.) When learning in the PAC model, one immediately loses such tight control over the train/test setup, as both datasets are drawn i.i.d.\ from the underlying distribution $\CD$. In this setting, there will typically be various hypotheses attaining zero empirical error which are also correct at the test point, offering considerably more freedom to a successful local regularizer and (seemingly) prohibiting the detection of simple cycles. 

    \item \textbf{Incomparable version spaces.} Another approach may be  as follows: Note that a successful local regularizer $\psi$ for $\Hotp$ must, at a minimum, perform well on average when $A \in \{0, 1\}^n$ and $b \in \{0, 1\}$ are selected uniformly at random, the training set $S$ consist of $m < n$ points drawn uniformly at random from $[n]$ whose labels are all $(b, A)$, and the test point $\xtest$ is likewise a uniformly random point in $[n]$. (Whose correct label is $(b, A)$.) To deduce a contradiction from this strong condition imposed on $\psi$ requires considering its behavior on sets of ERM hypotheses $L_{S}^{-1}(0)$ for varying training sets $S$. (These sets are often referred to as the \emph{version spaces} of $S$ \citep{mitchell1977version}.) In almost all cases, distinct version spaces will be incomparable as sets (i.e., neither subsets nor supersets of one another), rendering it difficult to derive contradictions from such conditions. 

    \item \textbf{Error measurement.} One may note that by drawing $m$ points uniformly at random from a set $S = \big((x_i, y_i) \big)_{i \in [n]}$ for carefully chosen $m = \Theta (n \log n)$, it will occur with constant probability that exactly one point in $S$ is \emph{not} drawn. Na\"ively, this would seem to recover transductive learning as a special case of PAC learning. Crucially, however, the transductive model places full weight upon the learner's performance at the (unseen) test point, whereas the PAC model averages a learner's performance across the entire distribution $\CD = \Unif(S)$. In the PAC model, then, simply memorizing the training set suffices to learn $\Unif(S)$ to small error in $\Theta(n \log n)$ samples.  
\end{itemize}
