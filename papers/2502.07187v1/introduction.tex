\section{Introduction}\label{Section:Introduction}

Understanding the power of various algorithmic templates for supervised learning is a core concern of both computational and statistical learning theory. This understanding arguably serves two purposes: a descriptive one by explaining the success of approaches employed in practice, and a prescriptive one which conveniently circumscribes the search space of promising algorithms for the practitioner. Most appealing are algorithmic approaches which are simple, natural, mirror what is seen in practice, and are powerful enough to learn in a rich variety of settings.

The most compelling  success story in this vein is that of \emph{empirical risk minimization (ERM)}. In practice, ERM and its approximations (such as gradient descent) are the work-horses of machine learning. In theory, ERM characterizes learnability for both binary classification~\citep{vapnik1982estimation,BEHW89} and agnostic real-valued regression~\citep{alon1997scale}.\footnote{That said, the sample complexity of ERM is slightly suboptimal for binary classification~\citep{hanneke2016optimal}, and more significantly suboptimal for regression~\citep{vavskevivcius2023suboptimality}.}

In second place is perhaps \emph{Structural Risk Minimization (SRM)}, a template for generalizations of ERM which trade off empirical risk with a user-specified measure $\psi(\arg)$ of model complexity, often referred to as a \emph{regularizer}. In trading off the fit of a model $h$ with its complexity $\psi(h)$, SRM protects against overfitting by encoding a preference for ``simple" models, Ã  la Occam's razor. Approaches such as ridge regression, Lasso, and other instantiations of SRM have seen much success in applied machine learning. On the theoretical front, ridge regression learns successfully for a large class of convex and smooth problems, and SRM in the abstract is known to characterize non-uniform learnability~\citep{shalev2014understanding}.

These natural and instructive algorithmic characterizations have been largely limited to small or low-dimensional label spaces as in regression and binary classification. The next frontier in this regard is the family of multiclass classification problems, where neither ERM, SRM, nor any ``simple" algorithmic approach is known to learn whenever learning is possible. As evidence that any such characterization must employ more sophisticated algorithmic templates than ERM or SRM, \cite{DS14} show that no \emph{proper} learner can succeed in general; i.e., an optimal learner must sometimes ``stitch together'' different hypotheses to form its predictor. 
Improper algorithms which are optimal (or near-optimal) for multiclass classification have been described through orienting \emph{one-inclusion graphs} \citep{rubinstein2006shifting,DS14,aden2023optimal}, and as a combination of \emph{sample compression} and \emph{list learning} \citep{brukhim2022characterization}. While lending remarkable structural insight into multiclass learning, neither approach is ``simple'' in any meaningful sense, nor reminiscent of approaches employed in practice.

Our starting point for this paper, and perhaps the closest thing to the sort of algorithmic characterization we seek for multiclass problems, is the recent work of \cite{asilis2024regularization}. They demonstrate that every multiclass problem can be learned by an \emph{unsupervised local SRM (UL-SRM)} learner, a generalization of SRM on two fronts. First, the complexity of a hypothesis $h$ is described \emph{locally} per test point $x$ via a \emph{local regularizer} $\psi(h,x)$. Second, this local regularizer $\psi(\arg, \arg)$ is derived from the unlabeled data in what resembles an unsupervised pre-training stage.\footnote{We note that both local regularization and unsupervised pre-training have been successfully employed in the theory and practice of machine learning --- see \cite{wolf2008local,prost2021learning,vavskevivcius2023suboptimality,geprovable,azoury2001relative,vovk2001competitive}.} The former generalization, locality, is what makes such a learner improper, and therefore appears indispensible by the impossibility result of \cite{DS14}. Whether the second generalization, which allows learning the regularizer from unlabeled data, can be dispensed with is less clear. This was posed as an open problem by \cite{asilis-open-problem}, where they conjecture that dependence on the unlabeled data is indeed necessary; i.e., that \emph{local structural risk minimization} --- a.k.a.~\emph{local regularization} --- is insufficient for learning all learnable multiclass problems. 

The present paper resolves this conjecture in the affirmative for the transductive model of learning: we construct a hypothesis class which is learnable in both the transductive and PAC models, and yet cannot be transductively learned by a local regularizer. Our hypothesis class can be viewed as a cryptographic generalization of the \emph{first Cantor class} of \cite{DS14}, incorporating ideas from \emph{secret-sharing}. Each of our hypotheses divides a large domain arbitrarily in half, with each half receiving its own label. We ensure that each hypothesis is uniquely identified by its two labels, which by itself suffices to render the class learnable. However, the two halves ``share a secret,'' such that witnessing any one label reveals next to nothing about the hypothesis or the identity of the other label. While this does not obstruct learnability in general, we show that it does obstruct local regularizers: a transductive learner with vanishing error must exhibit a ``cycle'' in the typical test point's preferences over hypotheses, and therefore cannot be a local regularizer.

Although we were unable to extend our result to the PAC model, we suspect that this is a failure of our proof techniques rather than of our construction. We conjecture therefore that our same hypothesis class is in fact not learnable by any local regularizer in the PAC model. This would be in keeping with the tight relationship between the transductive and PAC models: learnability is equivalent in the two models, with sample-efficient reductions in both directions~--- see the discussion in \citep{trans_equiv_pac?,shaddin_position} and references therein. Whereas the reduction from PAC to transductive learning preserves the form of the learner, the converse reduction does not, obstructing black-box extensions of our result to the PAC model. Non-black-box approaches also appear challenging, and we outline the difficulties in \Cref{Section:PAC-difficulties}. Irrespective of the outcome for the PAC model, we argue that our result for the transductive model is interesting in its own right due to the tight relationship to the PAC model in most other respects, the promising hypothesis class we design and employ for our proof, and the intricacies involved in proving our main theorem (which uses a coupling argument at its center). Furthermore, the prospect of separating the transductive and PAC models with respect to learnability by local regularizers --- in the event that our conjecture is misguided --- is even more tantalizing. 
