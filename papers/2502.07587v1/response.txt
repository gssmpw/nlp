\section{Related Works}
\label{sec:rw}

Numerous unlearning approaches are grounded in knowledge distillation. In **Chen, "Distilling a Dataset onto a Very Small Model"**, the authors introduce a teacher-student framework to selectively forget specific data while retaining other instances across various scenarios. Their approach incorporate a rewinding mechanism to obscure the identification of deleted instances. Similarly, in **Furlanello et al., "Unlearning as Kalman Filtering"**, a distillation-based method is proposed for scenarios where no training data is available to the algorithm. In **Denton et al., "Efficient Unlearning through Distillation"**, another distillation-driven technique is tailored for conditional generative models, though its evaluation is primarily focused on text-to-image and text-to-speech applications.

A recent study, **Raghu et al., "Don't Forget, the Original Model is Not Obsolete!"** , introduces the concept of \emph{forget vectors}, which perturb input data without altering the original model weights. However, this method is specifically designed for image classification and is not applicable to generative models. Meanwhile, the authors of **Chen et al., "Towards Efficient Unlearning via Singular Value Decomposition"** propose a singular value decomposition-based approach that diverges from SEMU in its methodology.
By analyzing the activation of samples from the forget and retain classes, they estimate the corresponding feature spaces and quantify the mutual information. Subsequently, they adjust the weights to suppress activations specific to the targeted class. Nevertheless, this method is not designed to handle the unlearning of arbitrary subsets of data.

The authors of **Sankar et al., "Model Pruning for Efficient Unlearning"** utilize model sparsification through weight pruning to minimize the discrepancy between an approximate unlearning model and a model retrained from scratch. Similarly, in **Raghu et al., "Efficient Unlearning via Standard Deviation Loss"**, the authors aim to reduce this discrepancy by introducing a standard deviation loss.
In **Xu et al., "SalUn: Saliency-Aware Unlearning for Efficient Model Pruning"**, the SalUn approach is proposed, which leverages a weight saliency map that can be applied independently or in conjunction with other unlearning methods. SalUn identifies the most influential weights, referred to as salient weights, based on  the forgetting loss  and prioritizes parameter updates on these weights.
It is considered in classification and generation.

Several methods focus on the unlearning of generative models. For instance, **Denton et al., "MAE-Forget: Unlearning for Masked Autoencoders"** is designed for models that reconstruct images from incomplete inputs, such as masked autoencoders (MAEs), vector-quantized GANs, or diffusion models. Similarly,**Raghu et al., "Unlearning for Generative Models with Forget-GAN and Forget-VAE"**,  is tailored for both GANs and VAEs, while**Chen et al., "G-Forget: Unlearning for Generative Adversarial Networks" and **Sankar et al., "V-Forget: Unlearning for Variational Autoencoders"** are specifically dedicated to GANs and VAEs. 

Another approach,**Zhang et al., "Decision Boundary Attack for Efficient Unlearning"**, shifts focus from modifying network parameters, to adjusting the decision boundary of the class targeted for forgetting, similar to adversarial attack strategies. Variants of gradient descent methods have also been proposed for unlearning tasks, as exemplified by**Xu et al., "Noisy Gradient Descent for Efficient Unlearning"**. In **Sankar et al., "Unlearning via Noisy Gradient Descent for Deep Regression and Forecasting Models"**, the authors propose a noisy gradient descent-based solution and argue that indistinguishability from retraining does not guarantee deletion privacy due to residual internal data states. Meanwhile, **Zhang et al., "Counterfactual Unlearning: Efficiently Removing Biases from Models with Counterfactual Samples"** introduces an unlearning method for deep regression and forecasting models, and  addresses the removal of biases from models using counterfactual samples.