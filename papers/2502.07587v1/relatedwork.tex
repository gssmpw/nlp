\section{Related Works}
\label{sec:rw}

Numerous unlearning approaches are grounded in knowledge distillation. In~\cite{kurmanji2023scrub}, the authors introduce a teacher-student framework to selectively forget specific data while retaining other instances across various scenarios. Their approach incorporate a rewinding mechanism to obscure the identification of deleted instances. Similarly, in~\cite{chundawat2023zeroshot}, a distillation-based method is proposed for scenarios where no training data is available to the algorithm. In~\cite{Kong2024satml}, another distillation-driven technique is tailored for conditional generative models, though its evaluation is primarily focused on text-to-image and text-to-speech applications.

A recent study,~\cite{sun2025forgetvectorsplayuniversal}, introduces the concept of \emph{forget vectors}, which perturb input data without altering the original model weights. However, this method is specifically designed for image classification and is not applicable to generative models. Meanwhile, the authors of~\cite{kodge2024deep} propose a 
singular value decomposition-based approach that diverges from SEMU in its methodology.
By analyzing the activation of samples from the forget and retain classes, they estimate the corresponding feature spaces and quantify the mutual information. Subsequently, they adjust the weights to suppress activations specific to the targeted class. Nevertheless, this method is not designed to handle the unlearning of arbitrary subsets of data.

The authors of~\cite{jia2023model} utilize model sparsification through weight pruning to minimize the discrepancy between an approximate unlearning model and a model retrained from scratch. Similarly, in~\cite{thudi2022unrolling}, the authors aim to reduce this discrepancy by introducing a standard deviation loss.
In~\cite{fan2024salun}, the SalUn approach is proposed, which leverages a weight saliency map that can be applied independently or in conjunction with other unlearning methods. SalUn identifies the most influential weights, referred to as salient weights, based on  the forgetting loss  and prioritizes parameter updates on these weights.
It is considered in classification and generation.

Several methods focus on the unlearning of generative models. For instance, ~\cite{li2024machineunlearning} is designed for models that reconstruct images from incomplete inputs, such as masked autoencoders (MAEs), vector-quantized GANs, or diffusion models. Similarly,~\cite{moon2024feature} is tailored for both GANs and VAEs, while~\cite{sun2023generativeadversarialnetworksunlearning} and~\cite{bae2023gradientsurgeryoneshotunlearning} are specifically dedicated to GANs and VAEs. 

Another approach,~\cite{chen2023boundaryshifting}, shifts focus from modifying network parameters, to adjusting the decision boundary of the class targeted for forgetting, similar to adversarial attack strategies. Variants of gradient descent methods have also been proposed for unlearning tasks, as exemplified by~\cite{neel2021descent}. In~\cite{chourasia2023forgetunlearning}, the authors propose a noisy gradient descent-based solution and argue that indistinguishability from retraining does not guarantee deletion privacy due to residual internal data states. Meanwhile,~\cite{tarun2023deepunlearning} introduces an unlearning method for deep regression and forecasting models, and~\cite{chen2023fast} addresses the removal of biases from models using counterfactual samples.