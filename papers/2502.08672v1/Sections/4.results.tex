\section{Results and Discussion}
\subsection{Evaluation}
We implemented an LSTM with Attention Mechanism to detect early signs of Parkinson's Disease using the same dataset as the review paper\cite{10}.

In this study, we employed two primary metrics to evaluate the performance of our model: the Mean Squared Error (MSE)\cite{11} and the coefficient of determination, commonly referred to as \( R^2 \).

MSE is defined as:
\begin{equation}
MSE = \frac{1}{n} \sum_{i=1}^{n} (y_i - \hat{y}_i)^2
\end{equation}
where \( y_i \) represents the actual value, \( \hat{y}_i \) is the predicted value, and \( n \) is the number of observations. A lower MSE indicates a better fit of the model to the data, as it means the predictions are closer to the actual values.

The coefficient of determination, \( R^2 \)\cite{12}, is a statistical measure of how close the data are to the fitted regression line. It is defined as:
\begin{equation}
R^2 = 1 - \frac{\sum_{i=1}^{n} (y_i - \hat{y}_i)^2}{\sum_{i=1}^{n} (y_i - \bar{y})^2}
\end{equation}
where \( \bar{y} \) is the mean value of \( y \). An \( R^2 \) value close to 1 suggests that a large proportion of the variability in the output has been explained by the model.






The results obtained from our model are summarized in Tables \ref{table:MSE_results} and \ref{table:R2_results}.



\newcolumntype{C}{>{\centering\arraybackslash}X}  % for centered "X" column type

\begin{table}[ht]
\centering
\small
\begin{tabularx}{\columnwidth}{C|c|c|c}
Meth. & Train. MSE & Val. MSE & Test MSE \\
\hline
LLS & 10.4735 & 10.0138 & 10.9074 \\
Conjugate Gradient & 10.4762 & 10.5898 & 10.9075 \\
Adam optimization  & 10.4762 & 10.5892 & 10.9072 \\
Ridge Regressions & 10.4798 & 10.5869 & 10.9136 \\
LSTM-Attention & 6.3572 & 6.6108 & 7.0491 \\
\end{tabularx}
\vspace{0.75mm}
\caption{Comparison of MSE results for different methods}
\label{table:MSE_results}
\end{table}



\begin{table}[ht]
\centering
\small
\begin{tabular}{c|c}
Methods & R$^2$ \\
\hline
LLS & 0.904409 \\
Conjugate Gradient & 0.904408 \\
Adam optimization & 0.904410 \\
Ridge Regressions & 0.904354 \\
LSTM-Attention & 0.9591 \\
\end{tabular}
\vspace{0.75mm}
\caption{Comparison of R$^2$ scores for different methods}
\label{table:R2_results}
\end{table}


















\subsection{Discussion}

The presented results indicate that the LSTM with Attention Mechanism offers a substantial improvement over the traditional ML techniques used in the referenced review paper. As seen in Table \ref{table:MSE_results}, the test MSE of our model is significantly lower than those of the other methods, highlighting its superior predictive performance. Similarly, the R$^2$ score from Table \ref{table:R2_results} shows our model's ability to explain a larger proportion of the variance in the dataset.

The drastic reduction in MSE scores, especially in the test set, suggests that the LSTM with Attention Mechanism captures the underlying patterns in the data more effectively than traditional ML techniques. This is likely due to the attention mechanism's ability to give differential importance to various time steps in the sequence, which can be critical for early detection of Parkinsonâ€™s Disease.

While our model has outperformed the methods from the referenced paper, it's essential to emphasize the importance of clinical validation. These results showcase the potential of deep learning, especially with attention mechanisms, in medical diagnostics. However, ensuring its generalizability and efficacy in real-world scenarios is crucial for practical applications.

