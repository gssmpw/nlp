@article{agoritsas2018out,
  title={Out-of-equilibrium dynamical mean-field equations for the perceptron model},
  author={Agoritsas, Elisabeth and Biroli, Giulio and Urbani, Pierfrancesco and Zamponi, Francesco},
  journal={Journal of Physics A: Mathematical and Theoretical},
  volume={51},
  number={8},
  pages={085002},
  year={2018},
  publisher={IOP Publishing}
}

@article{aiudi2025local,
  title={Local kernel renormalization as a mechanism for feature learning in overparametrized convolutional neural networks},
  author={Aiudi, R and Pacelli, R and Baglioni, P and Vezzani, A and Burioni, R and Rotondo, P},
  journal={Nature Communications},
  volume={16},
  number={1},
  pages={568},
  year={2025},
  publisher={Nature Publishing Group UK London}
}

@article{baglioni2024predictive,
  title={Predictive power of a bayesian effective action for fully connected one hidden layer neural networks in the proportional limit},
  author={Baglioni, P and Pacelli, R and Aiudi, R and Di Renzo, F and Vezzani, A and Burioni, R and Rotondo, P},
  journal={Physical Review Letters},
  volume={133},
  number={2},
  pages={027301},
  year={2024},
  publisher={APS}
}

@article{bassetti2024feature,
  title={Feature learning in finite-width Bayesian deep linear networks with multiple outputs and convolutional layers},
  author={Bassetti, Federico and Gherardi, Marco and Ingrosso, Alessandro and Pastore, Mauro and Rotondo, Pietro},
  journal={arXiv preprint arXiv:2406.03260},
  year={2024}
}

@article{bordelon2022self,
  title={Self-consistent dynamical field theory of kernel evolution in wide neural networks},
  author={Bordelon, Blake and Pehlevan, Cengiz},
  journal={arXiv preprint arXiv:2205.09653},
  year={2022}
}

@article{bordelon2023dynamics,
  title={Dynamics of Finite Width Kernel and Prediction Fluctuations in Mean Field Neural Networks},
  author={Bordelon, Blake and Pehlevan, Cengiz},
  journal={arXiv preprint arXiv:2304.03408},
  year={2023}
}

@article{bordelon2024dynamical,
  title={A dynamical model of neural scaling laws},
  author={Bordelon, Blake and Atanasov, Alexander and Pehlevan, Cengiz},
  journal={arXiv preprint arXiv:2402.01092},
  year={2024}
}

@misc{bordelon2024featurelearningimproveneural,
      title={How Feature Learning Can Improve Neural Scaling Laws}, 
      author={Blake Bordelon and Alexander Atanasov and Cengiz Pehlevan},
      year={2024},
      eprint={2409.17858},
      archivePrefix={arXiv},
      primaryClass={stat.ML},
      url={https://arxiv.org/abs/2409.17858}
}

@inproceedings{cui2023bayes,
  title={Bayes-optimal learning of deep random networks of extensive-width},
  author={Cui, Hugo and Krzakala, Florent and Zdeborov{\'a}, Lenka},
  booktitle={International Conference on Machine Learning},
  pages={6468--6521},
  year={2023},
  organization={PMLR}
}

@article{domine2024lazy,
  title={From Lazy to Rich: Exact Learning Dynamics in Deep Linear Networks},
  author={Domin{\'e}, Cl{\'e}mentine CJ and Anguita, Nicolas and Proca, Alexandra M and Braun, Lukas and Kunin, Daniel and Mediano, Pedro AM and Saxe, Andrew M},
  journal={arXiv preprint arXiv:2409.14623},
  year={2024}
}

@inproceedings{dyerasymptotics,
  title={Asymptotics of Wide Networks from Feynman Diagrams},
  author={Dyer, Ethan and Gur-Ari, Guy},
  booktitle={International Conference on Learning Representations},
  year={2020}
}

@article{gerbelot2022rigorous,
  title={Rigorous dynamical mean field theory for stochastic gradient descent methods},
  author={Gerbelot, Cedric and Troiani, Emanuele and Mignacco, Francesca and Krzakala, Florent and Zdeborova, Lenka},
  journal={arXiv preprint arXiv:2210.06591},
  year={2022}
}

@article{hanin2019finite,
  title={Finite depth and width corrections to the neural tangent kernel},
  author={Hanin, Boris and Nica, Mihai},
  journal={arXiv preprint arXiv:1909.05989},
  year={2019}
}

@article{hanin2024bayesian,
  title={Bayesian Inference with Deep Weakly Nonlinear Networks},
  author={Hanin, Boris and Zlokapa, Alexander},
  journal={arXiv preprint arXiv:2405.16630},
  year={2024}
}

@article{hoffmann2022training,
  title={Training compute-optimal large language models},
  author={Hoffmann, Jordan and Borgeaud, Sebastian and Mensch, Arthur and Buchatskaya, Elena and Cai, Trevor and Rutherford, Eliza and Casas, Diego de Las and Hendricks, Lisa Anne and Welbl, Johannes and Clark, Aidan and others},
  journal={arXiv preprint arXiv:2203.15556},
  year={2022}
}

@article{jacot2018neural,
  title={Neural tangent kernel: Convergence and generalization in neural networks},
  author={Jacot, Arthur and Gabriel, Franck and Hongler, Cl{\'e}ment},
  journal={Advances in neural information processing systems},
  volume={31},
  year={2018}
}

@article{kunin2024get,
  title={Get rich quick: exact solutions reveal how unbalanced initializations promote rapid feature learning},
  author={Kunin, Daniel and Ravent{\'o}s, Allan and Domin{\'e}, Cl{\'e}mentine and Chen, Feng and Klindt, David and Saxe, Andrew and Ganguli, Surya},
  journal={arXiv preprint arXiv:2406.06158},
  year={2024}
}

@article{lee2019wide,
  title={Wide neural networks of any depth evolve as linear models under gradient descent},
  author={Lee, Jaehoon and Xiao, Lechao and Schoenholz, Samuel and Bahri, Yasaman and Novak, Roman and Sohl-Dickstein, Jascha and Pennington, Jeffrey},
  journal={Advances in neural information processing systems},
  volume={32},
  year={2019}
}

@article{li2021statistical,
  title={Statistical mechanics of deep linear neural networks: The backpropagating kernel renormalization},
  author={Li, Qianyi and Sompolinsky, Haim},
  journal={Physical Review X},
  volume={11},
  number={3},
  pages={031059},
  year={2021},
  publisher={APS}
}

@inproceedings{mannelli2019passed,
  title={Passed \& spurious: Descent algorithms and local minima in spiked matrix-tensor models},
  author={Mannelli, Stefano Sarao and Krzakala, Florent and Urbani, Pierfrancesco and Zdeborova, Lenka},
  booktitle={international conference on machine learning},
  pages={4333--4342},
  year={2019},
  organization={PMLR}
}

@inproceedings{mei2019mean,
  title={Mean-field theory of two-layers neural networks: dimension-free bounds and kernel limit},
  author={Mei, Song and Misiakiewicz, Theodor and Montanari, Andrea},
  booktitle={Conference on Learning Theory},
  pages={2388--2464},
  year={2019},
  organization={PMLR}
}

@article{mignacco2020dynamical,
  title={Dynamical mean-field theory for stochastic gradient descent in Gaussian mixture classification},
  author={Mignacco, Francesca and Krzakala, Florent and Urbani, Pierfrancesco and Zdeborov{\'a}, Lenka},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={9540--9550},
  year={2020}
}

@article{mignacco2022effective,
  title={The effective noise of stochastic gradient descent},
  author={Mignacco, Francesca and Urbani, Pierfrancesco},
  journal={Journal of Statistical Mechanics: Theory and Experiment},
  volume={2022},
  number={8},
  pages={083405},
  year={2022},
  publisher={IOP Publishing}
}

@article{pacelli2023statistical,
  title={A statistical mechanics framework for Bayesian deep neural networks beyond the infinite-width limit},
  author={Pacelli, R and Ariosto, S and Pastore, Mauro and Ginelli, F and Gherardi, Marco and Rotondo, Pietro},
  journal={Nature Machine Intelligence},
  volume={5},
  number={12},
  pages={1497--1507},
  year={2023},
  publisher={Nature Publishing Group UK London}
}

@article{paquette20244+,
  title={4+ 3 Phases of Compute-Optimal Neural Scaling Laws},
  author={Paquette, Elliot and Paquette, Courtney and Xiao, Lechao and Pennington, Jeffrey},
  journal={arXiv preprint arXiv:2405.15074},
  year={2024}
}

@book{roberts2022principles,
  title={The principles of deep learning theory},
  author={Roberts, Daniel A and Yaida, Sho and Hanin, Boris},
  year={2022},
  publisher={Cambridge University Press Cambridge, MA, USA}
}

@article{rotskoff2022trainability,
  title={Trainability and accuracy of artificial neural networks: An interacting particle system approach},
  author={Rotskoff, Grant and Vanden-Eijnden, Eric},
  journal={Communications on Pure and Applied Mathematics},
  volume={75},
  number={9},
  pages={1889--1935},
  year={2022},
  publisher={Wiley Online Library}
}

@article{saxe2013exact,
  title={Exact solutions to the nonlinear dynamics of learning in deep linear neural networks},
  author={Saxe, Andrew M and McClelland, James L and Ganguli, Surya},
  journal={arXiv preprint arXiv:1312.6120},
  year={2013}
}

@inproceedings{yang2021tensor,
  title={Tensor programs iv: Feature learning in infinite-width neural networks},
  author={Yang, Greg and Hu, Edward J},
  booktitle={International Conference on Machine Learning},
  pages={11727--11737},
  year={2021},
  organization={PMLR}
}

@article{yang2023tensor,
  title={Tensor programs vi: Feature learning in infinite-depth neural networks},
  author={Yang, Greg and Yu, Dingli and Zhu, Chen and Hayou, Soufiane},
  journal={arXiv preprint arXiv:2310.02244},
  year={2023}
}

@article{zavatone2022contrasting,
  title={Contrasting random and learned features in deep Bayesian linear regression},
  author={Zavatone-Veth, Jacob A and Tong, William L and Pehlevan, Cengiz},
  journal={Physical Review E},
  volume={105},
  number={6},
  pages={064118},
  year={2022},
  publisher={APS}
}

@misc{zavatoneveth2023learning,
      title={Learning curves for deep structured Gaussian feature models}, 
      author={Jacob A. Zavatone-Veth and Cengiz Pehlevan},
      year={2023},
      eprint={2303.00564},
      archivePrefix={arXiv},
      primaryClass={stat.ML}
}

