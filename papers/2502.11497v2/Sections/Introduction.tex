\begin{comment}
To-do list
\begin{itemize}
    \item Polish the intro
    \item  Either use whole word or abbreviation (DP and GAP) everywhere to be consistent
    \item  Related work - VST applications and some previous VST works missing, should be more related to the actual work. No mention of GAP (link reprojection part to GAP?).
    \item Trisha and Vrushank - Finalize thematic analysis
    \item Discussion is missing some relation to previous work
    \item Finalize Conclusion
\end{itemize}
\end{comment}

\section{Introduction}

Virtual Reality (VR) head-mounted displays (HMDs) utilize high resolution near-eye displays and multi-sensory input systems to fully immerse the user in a virtual environment. 
The high level of immersion isolates the user from their physical surroundings. To allow seamless integration between the real and virtual worlds, augmented reality (AR) HMDs overlay digital content onto the reprojected physical world surrounding the user. As a result, in recent years, Video See-Through (VST) or passthrough AR devices such as Apple Vision Pro\footnote[1]{\url{https://www.apple.com/apple-vision-pro}} and Meta Quest 3\footnote[2]{\url{https://www.meta.com/quest}} have become increasingly popular. VST HMDs utilize camera-captured imagery offering users the ability to transition between AR and VR modes to deliver immersive experiences across the full reality-virtuality continuum \cite{milgram1995augmented}. In parallel to VST headsets, Optical See-Through (OST) systems, such as the Microsoft HoloLens\footnote[3]{\url{https://www.microsoft.com/hololens}}, have also been developed. These systems enable users to see the real world through a panel with variable transparency that can display virtual content.

With the rise in popularity of VST HMDs, several AR applications have emerged, including education\footnote[4]{\url{https://giantlazer.com}}, interactive real-world gaming \cite{arGaming}, and especially productivity tasks\footnotemark[1] such as typing, attending meetings, media consumption, and interacting with the physical world in indoor scenarios. As the adoption of these devices as \emph{spatial computers} increases, there is a need for research focused on user discomfort and associated cybersickness with VST technology. While motion sickness in VR \cite{laviola2000discussion, blum2010effect, chang2020virtual} has been extensively studied in last few decades, there is limited work dedicated to enhancing comfort and safety with the use of AR devices. Insights from VR research are informative, but the unique nature of VST where users can see and interact with the physical world suggests a need for dedicated investigation to guide the design of VST HMDs that prioritize user comfort. One of our objectives with this work is to quantitatively measure user discomfort with passthrough systems and provide insights into mitigating user experienced cybersickness.

In VST headsets, due to hardware and physical constraints, cameras are generally positioned on the outer surface of the headset, away from the user's eye positions (see Figure \ref{fig:teaser}a). \emph{Direct passthrough}, i.e. delivering the raw camera feed to the display, exaggerates distances and consequently the motion of objects (see Figure \ref{fig:teaser}b). According to the sensory-conflict theory, the most accepted theory of motion sickness, this mismatch between visual and inertial cues can potentially cause discomfort \cite{oman1990motion}. To mitigate this mismatch, past research focuses on utilizing depth information to reproject camera image feeds into the eye views \cite{chaurasia2020passthroughplus, Lei2022Neuralpassthrough}. We introduce the term \emph{\DepthPassthrough Passthrough} (GAP) to describe these depth-based reprojection algorithms. While previous work assumes that \GAP reduces discomfort compared to direct passthrough, to the best of our knowledge, no empirical studies have directly investigated this assumption. In addition, depth discontinuities and disocclusions can lead to warping artifacts in \GAP algorithms, which could further contribute to the overall cybersickness experienced by users. To address these issues, we propose technical metrics (see Figure \ref{fig:teaser}c) that can estimate the geometrical inaccuracies percevied on the VST displays along with the warping artifacts that potentially modify the shape of objects.

% {\textcolor{red}{Talk about key VST applications and usage}}

% \begin{itemize}
%     \item With VST headsets getting more popular, several key applications have emerged such as education, training workforce with spatial 3D models, personal usage such as productivity and entertainment.
%     \item As adoption to these products increases, it becomes very important to understand the impact of passthrough usage on human behviour such as motion sickness, eye strain and cybersickness. 
%     \item There is vast literature on understanding cybersickness with VR headsets, however, AR presents new challenges since the user can interact with the physical environement \cite{chaurasia2020passthroughplus}. In constrast, there has been limited research in formally evaluating the user comfort when performing key tasks in VST headsets. We try to fill this gap by proposing a protocol designed to capture sickness in VST headsets.
    
%     \item To design better passthrough systems, it is important to understand the source of discomfort as well. Considering, a typical passthrough headset,  it uses cameras to display the physical world, however, due to hardware constraints, the viewpoints for the camera deviates from that of user's eyes. 
%     \item Direct passthrough, i.e. delivering the raw camera feed to the display, exaggerates distances and consequently the motion of objects.  According to the sensory-conflict theory, the most accepted theory of motion sickness, this mismatch between visual and inertial cues can potentially cause discomfort \cite{oman1990motion}.  To accurately render the user's surroundings, VST systems generally utilize depth information to reproject camera image feeds into the eye coordinate system \cite{chaurasia2020passthroughplus, Lei2022Neuralpassthrough}. We introduce the term Geometry Aware Passthrough (GAP) to describe these depth-based algorithms. Maintenance and synchronization of a depth pipeline necessitate additional computational resources and contribute to the overall system latency.  Furthermore, depth discontinuities and disocclusions can lead to warping artifacts in \depthpassthrough VST algorithms, which could contribute to the overall user cybersickness. While these depth-based algorithms are expected to improve geometric accuracy of the perceived scene capturing this quantitatively is hard. Therefore, we propose methods for quantifying these errors and design our passthrough system to improve these metrics. 
%     \item To design 
% \end{itemize}

% {\textcolor{red}{Maybe skip to comfort directly as }}

% The latest HMDs offer high-resolution, low-latency video in VST mode, therefore enabling extended use over long periods. 
% This shift in usage patterns necessitates careful consideration of human factors associated with these devices. 
% Existing research in psychology, communication, and human-computer interaction has largely concentrated on virtual content within VST environments while other studies have addressed depth perception and various technological and application issues \cite{bailenson2024seeing,pfeil2021distance}. However, there is a critical need for research that is focused on user discomfort and cybersickness related to using VST technology for everyday tasks and navigation in the real-world. Although motion sickness in VR has been studied for decades, and contemporary systems strive to minimize it, there remains a distinct lack of studies dedicated to enhancing safety and comfort for AR users. 
% Insights from VR research are informative, but the unique nature of VST environments suggests a need for dedicated investigation to guide the design of VST HMDs that prioritize user comfort.

% Due to constraints inherent in the manufacturing process, VST cameras are typically positioned at a non-negligible distance from the user's eye positions. Direct passthrough, i.e. delivering the raw camera feed to the display, exaggerates distances and consequently the motion of objects. 
% According to the sensory-conflict theory, the most accepted theory of motion sickness, this mismatch between visual and inertial cues can potentially cause discomfort \cite{oman1990motion}. 
% To accurately render the user's surroundings, VST systems generally utilize depth information to reproject camera image feeds into the eye coordinate system \cite{chaurasia2020passthroughplus, Lei2022Neuralpassthrough}. We introduce the term Geometry Aware Passthrough (GAP) to describe these depth-based algorithms. While previous work assumes that GAP reduces discomfort compared to direct passthrough, there is currently no evidence that supports these claims. Additionally, the maintenance and synchronization of a depth pipeline necessitate additional computational resources and contribute to the overall system latency. 
% Furthermore, depth discontinuities and disocclusions can lead to warping artifacts in \depthpassthrough VST algorithms, which could contribute to the overall user cybersickness. 
% To the best of our knowledge, the literature currently lacks a comprehensive investigation into the incremental user comfort afforded by depth-corrected VST camera streams.

\textbf{Contributions.} In this paper, we first describe the technical differences between \directpassthrough and \depthpassthrough passthrough systems and propose metrics governing the trade-off between enhanced geometrical accuracy and the mitigation of perceived warping artifacts. We demonstrate how these metrics can be used to unveil impact of geometry estimation on the geometry perceived by the user and quantify the introduced distortions in VST images.
% We first provide a structured approach to designing depth-based passthrough algorithms that account for both geometrical accuracy and perceived distortions. 
% Specifically, we introduce two key metrics for evaluating view synthesis in passthrough: (i) spatial reprojection error and (ii) warping error. We utilize these metrics to refine our depth-based passthrough algorithm.
We then introduce a comprehensive protocol (see Figure \ref{fig:teaser}d) focused on key VST use cases to holistically assess visually-induced discomfort and cybersickness in VST HMDs. We apply this protocol to compare our refined \depthpassthrough algorithm to \directpassthrough passthrough. The study encompasses three activities in VST: (i) typing on physical keyboards, (ii) navigation around obstacles, and (iii) near-field object interaction/assembly. Through the proposed study, we first show that VST systems induce several specific symptoms otherwise not experienced without the headset while performing the same tasks. We further demonstrate that \depthpassthrough passthrough significantly reduces nausea, disorientation, and total scores of cybersickness compared to direct passthrough. \edits{By situating our investigation within the context of user comfort, we emphasize the practical implications of GAP for enhancing the human factors and overall user experience of VST HMDs.} We hope our findings will inspire future research focused on designing VST systems with enhanced user comfort. 

Our main contributions in this work can be summarized as follows:
\newcommand{\SubItem}[1]{
    {\setlength\itemindent{15pt} \item[-] #1}
}
\begin{itemize}
\item We propose metrics for quantifying spatial reprojection errors (percevied position and scale) and warping artifacts (change in object shape) which can be utilized to benchmark and compare different passthrough algorithms.
\item We present a protocol for evaluating and quantifying user comfort in VST HMDs. 
\item We demonstrate that \GAP significantly mitigates cybersickness compared to direct passthrough in a user study with 24 participants.
\end{itemize}

    \begin{figure*}[h!]
%   \includegraphics[width=\textwidth,trim={0 3cm 0 0},clip]{images/PassthroughModes.pdf}
 \includegraphics[width=\textwidth]{images/PassthroughModes.pdf}
\caption{\textbf{Comparison between reprojection in \directpassthrough and \depthpassthrough passthrough}. In this figure, we show a 2D illustration to describe the reprojection step where foreground and background are reprojected using different geometries. For direct passthrough, each point in 3D is assumed to belong to a single plane situated at a certain distance. However, that results in reprojecting objects at incorrect pixel locations and at incorrect scale (left). In comparison, \depthpassthrough passthrough uses a geometry estimate which improves the perceived location and the scale (right).}
  \Description{Comparing direct and geometry aware passthrough from first principles. We show a 2D illustration to describe the reprojection where forground (closer objects) and background (far away objects) are reprojected using different geometries. For direct passthrough, each point in 3D is assumed to belong to a single plane situated at a certain distance. However, that results in reprojecting objects at incorrect pixel locations and at incorrect scale. In comparison, geometry aware passthrough uses a geometry estimate which improves the perceived location and the scale. }
  \label{fig:passthroughmodes}
\end{figure*}