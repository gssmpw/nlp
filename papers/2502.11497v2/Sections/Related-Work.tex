\section{Related Work}
\subsection{Cybersickness and Comfort in VST}
Literature on VST discomfort builds upon the seminal work on simulator sickness, which informs our current understanding of the psycho-physical causes of cybersickness, such as sensory conflict and postural instability \cite{reason1975motion}. As VR HMDs have become more pervasive over the last few decades, research has validated and expanded our understanding of cybersickness by contextualizing the findings in VR applications \cite{li2022mixed}. LaViola et al.  \cite{laviola2000discussion} studied the visual-vestibular mismatch in VR environments associated with nausea and disorientation and identified vection, the perception of self-motion projected by visual stimuli despite the user being stationary. This effect is particularly pronounced with a wide field of view and rapid changes in the virtual scene, and it may be further accentuated in VST due to increased sensitivity to real-world cues \cite{suwa2022reducing}. Blum et al. investigated out-of-focus blur in VR and found it less problematic, noting lower levels of diplopia (double vision) and higher tolerance for blur \cite{blum2010effect}. They acknowledged that individual differences, such as ocular dominance and susceptibility to motion sickness, influence the accommodation of blur in VR. Additionally, hardware factors like display type, field of view, latency, and graphic realism can contribute to VR sickness \cite{chang2020virtual}. 

Compared to the literature on VR sickness, research on VST-specific discomfort is relatively sparse. Studies have explored various approaches to mitigate simulator sickness in VST systems, including the effects of visual displacement conditions \cite{kim2014effects} and the use of fisheye lenses to expand peripheral vision \cite{orlosky2014fisheye}. Freiwald et al. illustrate the complexities in developing VST technologies by using an offline computing method to create a system to reduce latency \cite{freiwald2018camera}. This approach provided better stabilization, reducing the disconnect introduced by the mismatch between camera and HMD refresh rates. More recently, Li et al \cite{li2022mixed} investigated the effects of mixed-reality tunneling methods on simulator sickness. In our work, we propose a comprehensive evaluation framework that includes both machine-readable metrics and user evaluations (subjective ratings) to address hardware and software aspects of VST. We apply this framework to investigate the effects of geometry aware passthrough on cybersickness, an area that has not yet been examined.
% Compared to the literature on VR sickness, research on VST-specific discomfort is relatively sparse. Hardware and real-time runtime limitations have hindered the full exploration of VST research topics. In a recent example, Freiwald et al. illustrates the complexities in developing VST technologies by using an offline computing method to create a system to reduce latency \cite{freiwald2018camera}. The authors intentionally injected delays in the tracking stream to match the camera system latency. This approach provided better stabilization, reducing the disconnect introduced by the mismatch between camera and HMD refresh rates. 

\subsection{ Novel-View Synthesis and Evaluation.}
    Geometry aware passthrough algorithms fall into the class of novel view synthesis techniques. In contrast to synthesizing views based on fixed camera and eye positions, novel view synthesis aims to solve for a more generalized case i.e. \emph{any} new camera viewpoint given images from a few known viewpoints of the same scene. Early work in this space utilized image-based rendering techniques \cite{SilhouetteIBR, li2023dynibar}], where multiple views were used to construct the scene geometry and then blended together to render novel views. Then, Mildenhall et al. \cite{mildenhall2020nerf} proposed learning a volumetric scene function to model the entire scene which could be queried from novel camera viewpoints. Tretschk et al. \cite{tretschk2020nonrigid} extended this approach to non-rigid scenes, allowing novel view reconstruction over time. Recently, Gaussian splatting \cite{kerbl3Dgaussians} was proposed which aims to model the world with 3D Gaussians and learn these Gaussians to minimize the rendering error on images from known viewpoints. Generally, to evaluate novel view synthesis, novel viewpoints are manually collected using cameras or synthetically rendered. These images then serve as a reference and can be directly compared with the estimated image using metrics like PSNR (Peak Signal-to-Noise Ratio), SSIM (Structural Similarity) and Perceptual Similarity \cite{zhang2018perceptual, kerbl3Dgaussians}. However, these metrics rely on the assumption that reference images are available for evaluation.  \edits{While collecting paired input images of the camera and the eye view is possible \cite{IBRreview}, it is hard to scale for VST headsets and doesn't directly allow assessment from a geometrical standpoint. Instead, we propose metrics that solely utilize depth to compute reprojection errors at the eye, focusing on the geometrical correctness of passthrough systems.}
    
    
    \subsection{Reprojection in VST HMDs} For VST HMDs, the passthrough cameras are placed in front of the user's eyes, typically a few centimeters away.
    The scene as viewed by the user's eyes needs to be reconstructed and displayed back to the user through VST displays. This process is generally referred to as \emph{reprojection}, where the camera images are reprojected to the user's eyes. 
    Past work on performing on-device reprojection for passthrough either utilizes classical depth estimation to synthesize eye-views \cite{chaurasia2020passthroughplus} or relies on dedicated GPUs to perform real-time accurate reprojection \cite{novelviewsynthdevice, IBRreview, Lei2022Neuralpassthrough}. In our work, we follow Chaurasia et al. \cite{chaurasia2020passthroughplus}  and implement our geometry aware passthrough pipeline using a low powered, on-device depth estimation algorithm. 
    \edits{While many of these studies discuss several technical aspects that are important for reprojection in headsets, their impact and the significance of reprojection itself on cybersickness remain underinvestigated. With the growing adoption of VST HMDs, we believe that further research into the relationship between reprojection and user comfort is crucial for driving fundamental advancements in VST technology, ultimately enhancing user experience and usability in AR applications.}