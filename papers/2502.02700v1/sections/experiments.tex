%evaluation metrics....

%validating the freeboard

%plan the experiments and plots

\subsection{Experimental Setup and Evaluation Metrics}

%We have applied .....  

We utilize the Google Cloud Dataproc (GCD) service on the Google Cloud Platform for PySpark-based experiments. There, we use a cluster of four nodes with one master node and three worker nodes. Each of the Intel N2 Cascade Lake computers is equipped with four cores.
%

As for the DL models, first, we divide the dataset into 80\% training dataset and 20\% test dataset. Then, we organize the data into batches for the MLP and LSTM models. We use the Adam optimizer, dropouts of 0, 0.2, and 0.3 in different convolutional layers, and epochs of 20, 30, and 40 to observe the changes. Both our LSTM and MLP model has a dropout rate of 0.2, a batch size of 32, and the number of epochs is 20. 
%Similarly, our MLP model has a dropout rate of 0.1, a batch size of 32, and the number of epochs is 30. 
Detailed results are reported in the following parts. 

Since the model training is computationally heavy, we have applied Horovod-based distributed training. We have utilized an NVIDIA DGX A100 machine with dual CPUs, each with four A100 GPUs.

%\subsubsection{Evaluation Metrics}
To validate the results of our algorithm, 
%the following evaluation metrics over the validation dataset are computed:
%\begin{itemize}
    %\item Thin cloud and shadow removal:\\We have 
    %\item 
    %Classification Accuracy, Precision, Recall, and F1 score:
    %The overall accuracy is the ratio of the correctly predicted samples over all the samples in the validation set. 
    %For measuring the overall accuracy of the color-seg model, we measured SSIM (structural similarity index) to find similarity accuracy between model output with the target image. 
    we compute the accuracy, precision, recall, and F1 score to obtain a comprehensive and balanced evaluation of the model's performance.
    For the two models, MLP and LSTM, we evaluate the models using a 20\% validation dataset to find the overall classification accuracy of these two models.  
    
    %\item Confusion Matrix:
    %For our segmentation model evaluation, we also construct a confusion matrix \cite{ting2017confusion}. The number of samples predicted in category A over the number of samples in category B is specified as an element of the matrix in row A and column B. A complete classification would result in a diagonal confusion matrix, with 100\% on the diagonal and 0\% in the rest of the matrix. Each column adds up to a total of 100\%. This helps understand the model accuracy for classifying each sea ice type individually.
    
%\end{itemize}

\subsection{IS2 Auto-labeling} %check

\subsubsection{IS2 Auto-labeling Speedup}
The GCD service is utilized alongside the PySpark framework for thin cloud and shadow-filtered autolabeling of IS2 data. 
This technique was applied for the annotation of S2 data, which was subsequently used for training deep learning models \cite{iqrah2023toward}, \cite{iqrah2024parallel}. Then, based on the overlapped IS2 and S2 Data, IS2 data is auto-labeled. 
%The same projection is used for overlapping, and to handle mismatched overlap due to the temporal difference between S2 and IS2, S2 data was shifted accordingly.
IS2 auto-labeling speedup results for the PySpark-based approach are as follows, in table \ref{tab:auto_label_spark}.
%\textcolor{red}{in sec}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{table}[htb]
\centering
\caption{PySpark-based IS2 auto-labeling scalability over Google Cloud.}
\label{tab:auto_label_spark}
\begin{tabular}{ |>{\centering\arraybackslash}p{0.115\linewidth}||>{\centering\arraybackslash}p{0.06\linewidth}||>{\centering\arraybackslash}p{0.06\linewidth}||>{\centering\arraybackslash}p{0.06\linewidth}||>{\centering\arraybackslash}p{0.08\linewidth}||>{\centering\arraybackslash}p{0.11\linewidth}||>{\centering\arraybackslash}p{0.11\linewidth}|}
%\begin{tabular}{|c|c|c|c|c|c|c|}
\hline
\textbf{Executors} & \textbf{Cores} & \textbf{Load Time (s)} & \textbf{Map Time (s)} & \textbf{Reduce Time (s)} & \textbf{Speed-up Load} & \textbf{Speed-up Reduce} \\ \hline
1                  & 1              & 108                & 0.4               & 390                  & 1                      & 1                        \\ \hline
1                  & 2              & 58                 & 0.4               & 174                  & 1.86                   & 2.24                     \\ \hline
1                  & 4              & 33                 & 0.3               & 72                   & 3.27                   & 5.42                     \\ \hline
2                  & 1              & 56                 & 0.3               & 156                  & 1.93                   & 2.5                      \\ \hline
2                  & 2              & 31                 & 0.3               & 84                   & 3.48                   & 4.64                     \\ \hline
2                  & 4              & 19                 & 0.3               & 41                   & 5.68                   & 9.51                     \\ \hline
4                  & 1              & 31                 & 0.2               & 78                   & 3.48                   & 5                        \\ \hline
4                  & 2              & 17                 & 0.2               & 39                   & 6.35                   & 10                       \\ \hline
4                  & 4              & 12                 & 0.3               & 24                   & \textbf{9}                      & \textbf{16.25}                    \\ \hline
\end{tabular}
\end{table}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
A speedup of up to 16.25 times is attained in the execution of this workflow, as illustrated in Table \ref{tab:auto_label_spark}. Additionally, there is a significant improvement in data loading speed when utilizing numerous machines, with a maximum speedup of up to 9 times. 
The auto-labeling of IS2 data is highly scalable due to independent data point processing, albeit fine-grained. This is easily parallelized using PySpark (map-reduce framework). PySpark is utilized here to parallelize and scale the auto-labeling of the IS2 data on different architectures. Along with a single multi-core machine, it is scaled over multiple heterogeneous machines in a GCD cluster with 9.0x data loading and 16.25x map-reduce processing speedup. Since the PySpark-based approach supports larger clusters for distributing the auto-labeling procedure, it points to a potential for scaling over much larger data in the future.

\subsection{Model Training Results}

\subsubsection{Model Accuracy}

\begin{table}[htb]
\centering
\caption{DL models sea ice classification accuracy over IS2 ATL03 Antarctic summer datasets. }
\label{tab:dl_accuracy}
\begin{tabular}{ |>{\centering\arraybackslash}p{0.18\linewidth}||>{\centering\arraybackslash}p{0.14\linewidth}||>{\centering\arraybackslash}p{0.14\linewidth}||>{\centering\arraybackslash}p{0.12\linewidth}||>{\centering\arraybackslash}p{0.12\linewidth}|}
%\begin{tabular}{|c|c|c|c|c|}
\hline
\textbf{Model} & \textbf{Accuracy} & \textbf{Precision} & \textbf{Recall} & \textbf{F1 score} \\ \hline
\textbf{MLP}   & 91.80             & 91.80              & 91.80           & 91.79             \\ \hline
\textbf{LSTM}  & 96.56             & 97.00              & 96.09           & 96.54             \\ \hline
\end{tabular}
\end{table}

The accuracy comparison of the LSTM and MLP model is presented in Table \ref{tab:dl_accuracy} for IS2 ATL03 data. Basically, the two methods show over 90\% accuracy results. However, the LSTM has a better accuracy of 96.56\% compared to the MLP with 91.80\%. Therefore, the LSTM is used for sea ice classification in the study. Moreover, the figure \ref{fig:confusion_mat} represents a confusion matrix consisting of detailed individual classification accuracy of thick ice, thin ice, and open water with 98.39\%, 73.80\%, and 60.25\%, respectively.

\begin{figure}
    \centering
    \includegraphics[width=0.5\linewidth]{figures/confusion_mat.png}
    \caption{Sea-ice Classification Confusion Matrix}
    \label{fig:confusion_mat}
\end{figure}


\begin{table}[htb]
\caption{Distributed DL model training using Horovod framework on DGX A100 cluster.}
\label{tab:dl_training_horovod}
\begin{tabular}{ |>{\centering\arraybackslash}p{0.10\linewidth}||>{\centering\arraybackslash}p{0.12\linewidth}||>{\centering\arraybackslash}p{0.25\linewidth}||>{\centering\arraybackslash}p{0.12\linewidth}||>{\centering\arraybackslash}p{0.12\linewidth}|}
%\begin{tabular}{|c|c|c|c|}
\hline
\textbf{No. of GPUs} & \textbf{Time (s)} & \textbf{Time (s)/Epoch} & \textbf{Data/s} & \textbf{Speedup}     \\ \hline
1          & 280.72                        & 5.5                                 & 585.88                       & 1.00    \\ \hline
2          & 143.22                        & 2.778                               & 1160.81                      & 1.96    \\ \hline
4          & 73.68                         & 1.45                                & 2229.56                      & 3.81    \\ \hline
6          & 49.42                         & 0.97                                & 3330.03                      & 5.68    \\ \hline
8          & 38.72                         & 0.79                                & 4248.56                      & 7.25   \\ \hline
\end{tabular}
\end{table}

\begin{figure}[htb]
    %\begin{framed}
        \centering
        \begin{subfigure}[b]{0.24\textwidth}
            \centering
            \frame{\includegraphics[width=\textwidth]{figures/Distributed_Training_Speedup.png}}
            \caption{}%{Distributed Training Speedup}
            \label{fig:distributed_training_speedup}
        \end{subfigure}
        %\hfill
        \begin{subfigure}[b]{0.24\textwidth}
            \centering
            \frame{\includegraphics[width=\textwidth]{figures/Total_Training_Time_sec.png}}
            \caption{}%{Total_Training Time(sec)}
            \label{fig:total_train_time}
        \end{subfigure}
        \par\medskip
        %\hfill
        \begin{subfigure}[b]{0.24\textwidth}
            \centering
            \frame{\includegraphics[width=\textwidth]{figures/Data_sec_for_each_Epoch.png}}
            \caption{}%{Data/sec for each Epoch}
            \label{fig:data_sec_per_epoch}
        \end{subfigure}
        %\hfill
        \begin{subfigure}[b]{0.24\textwidth}
            \centering
            \frame{\includegraphics[width=\textwidth]{figures/Time_sec_for_each_Epoch.png}}
            \caption{}%{Time(sec) for each Epoch}
            \label{fig:time_per_epoch}
        \end{subfigure}
        %\hfill
        %\medskip
    %\end{framed}
    \caption{Distributed model training via Horovod framework, 
    (a) distributed training speedup, 
    (b) total training time over multiple GPUs, 
    (c) data processed per second for each epoch and 
    (d) time for each epoch.}
    \label{fig:horovod_training_chart}
\end{figure}


\subsubsection{Distributed Model Training Speedup}
Table \ref{tab:dl_training_horovod} shows the scaled and distributed model training results. We train our LSTM model in the DGX A100 cluster using the Horovod framework. We calculate the time for our Horovod-based model training in 1, 2, 4, 6, and 8 GPU setups and a batch size of 32. The training time is reduced from 280.72s for 1 GPU to 38.72s for 8 GPU, gaining up to 7.25x speedup. We have trained our model for 20 epochs, and for each epoch, we achieve up to 4248.56 image data/s throughput within 0.79s on 8 GPUs compared to 585.88 image data/s throughput with 5.5s on a single GPU. Figure \ref{fig:horovod_training_chart} shows the performance results of distributed model training via Horovod over multiple GPUs. 
Here, we observe that the distributed training speedup and the throughput growth rate are almost close to linear, which is ideal with the increased number of GPUs.
On the other hand, the total training time and the time per epoch decreasing rate are high initially; however, eventually, they slow down with the increased number of GPUs. 
%This happens due to data starvation on the GPU side. 
%We notice that we are not getting ideal linear speedup and throughput or reduced total training time and time per epoch.
During training, the bottleneck arises from data preprocessing and subsequent batch preparation, resulting in GPU starvation. As a result, we are not achieving optimal speedup or throughput performance.

% The distributed training speed-up slows down after 4 GPUs due to the communication overhead across two groups of GPUs, as the DGX cluster is a dual CPU with 4 GPUs each.
% - based on paper,
% single node GPU vs multinode node
% communication
% 4k 8k 12k data GPU utilization 
%we know why its happening
%not scaling linearly at all since it has to copy the weights to all cards after each optimizer step which takes a lot of memory read/write operations.
%

\subsubsection{Sea-ice Classification Comparison}
After the LSTM-based sea ice classification of ATL03 data, different types of sea ice (thick ice, thin ice and open water) classification over IS2 ATL03 product are compared with IS2 ALT07's sea ice classification product. We did the ATL03 classification using the LSTM model, where \cite{koo2023sea} used the MLP model for the ATL07 classification. ATL03 and ATL07 data product's sea ice classification is plotted in figure \ref{fig:classification_atl03_atl07_1} and \ref{fig:classification_atl03_atl07_2}. 
%
%\textcolor{red}{add figure}
\begin{figure}[ht]
    %\begin{framed}
        \centering
        \begin{subfigure}[b]{\linewidth}
            \centering
            %\includegraphics[width=\textwidth]{figures/elev_atl03_1.png}
            \includegraphics[width=\textwidth]{figures/atl03_04_classification_cor_label.png}
            \caption{Sea ice classification on ATL03}%20191104195311\_05940510\_gt2r from ATL03}
            \label{fig:elev04_atl03}
        \end{subfigure}

        \begin{subfigure}[b]{\linewidth}
            \centering
            \includegraphics[width=\textwidth]{figures/atl07_04_classification.png}
            \caption{Sea ice classification on ATL07 Koo\_method \cite{koo2023sea}}%20191104195311\_05940510\_gt2r from ATL07}
            \label{fig:elev_atl07_1}
        \end{subfigure}
    %\end{framed}
    \caption{Sea ice classification comparison of ATL03 and ATL07 (Koo\_method \cite{koo2023sea}) of IS2 track \textit{20191104195311\_05940510\_gt2r}. Here, thick ice is blue, thin ice is green, and open water is orange}
    \label{fig:classification_atl03_atl07_1}
\end{figure}
%
\begin{figure}[ht]
    %\begin{framed}
        \centering
        \begin{subfigure}[b]{\linewidth}
            \centering
            %\includegraphics[width=\textwidth]{figures/elev_atl03.png}
            \includegraphics[width=\textwidth]{figures/atl03_26_classification_cor_label.png}
            \caption{Sea ice classification on ATL03}%20191126182014\_09290510\_gt2r from ATL03}
            \label{fig:elev26_atl03}
        \end{subfigure}

        \begin{subfigure}[b]{\linewidth}
            \centering
            \includegraphics[width=\textwidth]{figures/atl07_26_classification.png}
            \caption{Sea ice classification on ATL07 Koo\_method \cite{koo2023sea}}%20191126182014\_09290510\_gt2r from ATL07}
            \label{fig:elev_atl07}
        \end{subfigure}
    %\end{framed}
    \caption{Sea ice classification comparison of ATL03 and ATL07 (Koo\_method \cite{koo2023sea}) of IS2 track \textit{20191126182014\_09290510\_gt2r}. Here, thick ice is blue, thin ice is green, and open water is orange}
    \label{fig:classification_atl03_atl07_2}
\end{figure}
%
Based on the results in figure \ref{fig:classification_atl03_atl07_1} and \ref{fig:classification_atl03_atl07_2}, we can see that our ATL03 data product's sea ice classification in figure \ref{fig:elev26_atl03} and \ref{fig:elev04_atl03} are more dense than ATL07. It provides a higher resolution sea ice classification product than the ATL07 sea ice classification in figures \ref{fig:elev_atl07} and \ref{fig:elev_atl07_1}.


\subsection{Freeboard Computation}
For freeboard calculation, the first step is to find the local sea surface and then calculate the freeboard based on the height difference of sea ice with the derived local sea surface. 
IS2 ATL03 freeboard computation results, along with the PySpark-based approach, are as follows,

\subsubsection{Local Sea Level Comparison}
We have applied four different techniques for local sea surface detection: i) Minimum Elevation, ii) Average Elevation, iii) Nearest Minimum Elevation, and iv) The sea surface equation formulated by NASA.
%
To compare these different local sea surface detection methods, we plot the four different types of local sea surface products shown in figure \ref{fig:localSS_1} and \ref{fig:localSS_2}.
%
\begin{figure}[ht]
    %\begin{framed}
        \centering

        \begin{subfigure}[b]{\linewidth}
            \centering
            \includegraphics[width=\textwidth]{figures/ss04_1_v2.png}
            \caption{Local sea surface using four different methods from ATL03}
            \label{fig:ss04_1}
        \end{subfigure}

        \begin{subfigure}[b]{\linewidth}
            \centering
            \includegraphics[width=\textwidth]{figures/ss04_2_v2.png}
            \caption{Local sea surface of ATL03 and ATL07 (Koo\_method \cite{koo2023sea}}
            \label{fig:ss04_2}
        \end{subfigure}
    %\end{framed}
    \caption{Local sea surface detection based on four different methods from ATL03 (a) and comparison based on ATL03 (this paper) and ATL07 (Koo\_method \cite{koo2023sea}) (b) over IS2 track \textit{20191104195311\_05940510\_gt2r}.} 
    \label{fig:localSS_1}
\end{figure}
%
\begin{figure}[ht]
    %\begin{framed}
        \centering
        \begin{subfigure}[b]{\linewidth}
            \centering
            \includegraphics[width=\textwidth]{figures/ss26_1_v2.png}
            \caption{Local sea surface using four different methods from ATL03}
            \label{fig:ss26_1}
        \end{subfigure}

        \begin{subfigure}[b]{\linewidth}
            \centering
            \includegraphics[width=\textwidth]{figures/ss26_2_v2.png}
            \caption{Local sea surface of ATL03 and ATL07 (Koo\_method \cite{koo2023sea}}
            \label{fig:ss26_2}
        \end{subfigure}
    %\end{framed}
    \caption{Local sea surface detection based on four different methods from ATL03 (a) and comparison based on ATL03 (this paper) and ATL07 (Koo\_method \cite{koo2023sea}) (b) over IS2 track \textit{20191126182014\_09290510\_gt2r}.} 
    \label{fig:localSS_2}
\end{figure}
%
In Figure \ref{fig:ss04_1} and \ref{fig:ss26_1}, we observe that the sea surface detection using ATL03 data, based on NASA's sea surface detection formula (represented by the blue line), is a better technique compared to other methods, as it provides a smoother local sea surface. As a result, we select this sea surface based on NASA's sea surface detection formula one as our primary local sea surface. We also compare this sea surface with Koo\_method \cite{koo2023sea}, ATL07 product and saw that these two have a similar sea surface, and the difference between them is little over 0.1m. This comparison is illustrated in figure \ref{fig:ss04_2} and \ref{fig:ss26_2}. 

%\textcolor{red}{add figure}
\begin{figure}[!htb]
    %\begin{framed}
        \centering
        \begin{subfigure}[b]{\linewidth}
            \centering
            \includegraphics[width=\textwidth]{figures/freeboard_03_1_v2.png}
            \caption{Freeboard from ATL03}
            \label{fig:freeboard_03_1}
        \end{subfigure}
        \begin{subfigure}[b]{\linewidth}
            \centering
            \includegraphics[width=\textwidth]{figures/freeboard_07_1_v2.png}
            \caption{Freeboard from ATL07 (Koo\_method \cite{koo2023sea})}
            \label{fig:freeboard_07_1}
        \end{subfigure}
        \begin{subfigure}[b]{0.9\linewidth}
            \centering
            \includegraphics[width=\textwidth]{figures/freeboard_hist04_atl_03_07_10_v2.png}
            \caption{Freeboard distributions from ATL03, ATL07 (Koo\_method), and ATL10}
            \label{fig:freeboard_hist04_atl_03_07_10}
        \end{subfigure}
        \begin{subfigure}[b]{\linewidth}
            \centering
            \includegraphics[width=\textwidth]{figures/hist04_atl_03_10_v2.png}
            \caption{Point density difference between ATL03 and ATL07 (Koo\_method)}
            \label{fig:hist04_atl_03_10}
        \end{subfigure}
    %\end{framed}
    \caption{Freeboard from this study (a) and from ATL07 (Koo\_method) (b), freeboard distributions (c) from this study, ATL07 (Koo\_method) and ATL10, 0, and (d) point density between this study and ATL07 (Koo\_method) along the IS2 track \textit{20191104195311\_05940510\_gt2r}}
    \label{fig:freeboard_comp1}
\end{figure}

\begin{figure}[!htb]
    %\begin{framed}
        \centering
        \begin{subfigure}[b]{\linewidth}
            \centering
            \includegraphics[width=\textwidth]{figures/freeboard_03_v2.png}
            \caption{Freeboard from ATL03}
            \label{fig:freeboard_03}
        \end{subfigure}
        \begin{subfigure}[b]{\linewidth}
            \centering
            \includegraphics[width=\textwidth]{figures/freeboard_07_v2.png}
            \caption{Freeboard from ATL07 (Koo\_method \cite{koo2023sea})}
            \label{fig:freeboard_07}
        \end{subfigure}
        \begin{subfigure}[b]{0.9\linewidth}
            \centering
            \includegraphics[width=\textwidth]{figures/freeboard_hist26_atl_03_07_10_v2.png}
            \caption{Freeboard distributions from ATL03, ATL07 (Koo\_method), and ATL10}
            \label{fig:freeboard_hist26_atl_03_07_10_v1}
        \end{subfigure}
        \begin{subfigure}[b]{\linewidth}
            \centering
            \includegraphics[width=\textwidth]{figures/hist26_atl_03_10_v2.png}
            \caption{Point density difference between ATL03 and ATL07 (Koo\_method)}
            \label{fig:hist26_atl_03_10}
        \end{subfigure}
    %\end{framed}
    \caption{Freeboard comparison, (a),(b) represents ATL03 and ATL07/ATL10 freeboard, (c) freeboard value density ATL03 with ATL07/ATL10, and (d) represent point density difference between ATL03 with ATL07/ATL10 freeboard over IS2 track \textit{20191126182014\_09290510\_gt2r}}
    \label{fig:freeboard_comp2}
\end{figure}

\subsubsection{Freeboard Comparison}
The figures \ref{fig:freeboard_comp1} and \ref{fig:freeboard_comp2} show the freeboard comparisons from this study on ATL03 and those from Koo\_method and ATL10. 
%, We derive the IS2 sea ice freeboard from the high-resolution ATL03 data. To validate our freeboard computation, we compared the ATL03 freeboard with the ATL07 freeboard \cite{koo2023sea} and ATL10 freeboard calculations. The results are shown in figure \ref{fig:freeboard_comp},
Clearly, our results directly based on 2m sampled ATL03 data show a more dense and high-resolution freeboard product than those based on the ATL07 and ATL10 products, although the freeboard distributions show similar peak values. 
%, according to figure \ref{fig:freeboard_comp}.

\subsubsection{Freeboard Computation Speedup}
Similar to the auto-labeling process, we utilize a PySpark-based MapReduce framework to scale the freeboard computation. The freeboard calculation for IS2 ATL03 data benefits from high scalability due to the independent processing of data points. PySpark enables the parallelization and scaling of the freeboard calculation across different architectures. 
%
\begin{table}[htb]
\centering
\caption{PySpark-based IS2 freeboard computation over Google Cloud.}
\label{tab:freeboard_spark}
\begin{tabular}{ |>{\centering\arraybackslash}p{0.115\linewidth}||>{\centering\arraybackslash}p{0.06\linewidth}||>{\centering\arraybackslash}p{0.06\linewidth}||>{\centering\arraybackslash}p{0.06\linewidth}||>{\centering\arraybackslash}p{0.08\linewidth}||>{\centering\arraybackslash}p{0.11\linewidth}||>{\centering\arraybackslash}p{0.11\linewidth}|}
%\begin{tabular}{|c|c|c|c|c|c|c|}
\hline
\textbf{Executors} & \textbf{Cores} & \textbf{Load Time (s)} & \textbf{Map Time (s)} & \textbf{Reduce Time (s)} & \textbf{Speed-up Load} & \textbf{Speed-up Reduce} \\ \hline
1                  & 1              & 111                & 0.4               & 392                  & 1                      & 1                        \\ \hline
1                  & 2              & 60                 & 0.4               & 177                  & 1.85                   & 2.21                     \\ \hline
1                  & 4              & 36                 & 0.3               & 74                   & 3.08                   & 5.30                     \\ \hline
2                  & 1              & 58                 & 0.3               & 159                  & 1.91                   & 2.47                      \\ \hline
2                  & 2              & 33                 & 0.3               & 86                   & 3.36                   & 4.56                     \\ \hline
2                  & 4              & 21                 & 0.3               & 44                   & 5.29                   & 8.91                     \\ \hline
4                  & 1              & 34                 & 0.2               & 80                   & 3.26                   & 4.9                        \\ \hline
4                  & 2              & 20                 & 0.2               & 41                   & 5.55                   & 9.56                       \\ \hline
4                  & 4              & 13                 & 0.3               & 25                   & \textbf{8.54}                      & \textbf{15.68}                    \\ \hline
\end{tabular}
\end{table}
%
This includes not only single multi-core machines but also multiple heterogeneous machines within a GCD cluster, achieving an 8.5x improvement in data loading and a 15.7x speedup in map-reduce processing as displayed in Table \ref{tab:freeboard_spark}. The PySpark-based approach's support for larger clusters enhances the potential for scaling the freeboard computation to much larger datasets in the future.