\begin{figure}[!ht]
%\begin{framed}
    \centering
    \frame{\includegraphics[width=1.0\linewidth]{figures/is2_workflow_1.png}}
%\end{framed}
\caption{ATL03 Sea Ice Classification and Freeboard Computation Workflow}
\label{fig:is2_workflow}
\end{figure}

This study focuses on the sea ice classification and freeboard retrieval workflow in the Antarctic Ross Sea region. This workflow comprises four primary stages. In the first stage, data collection, processing, and auto-labeling are conducted to prepare labeled data for training and scaling the auto-labeling process. Following that, we perform a distributed training of deep learning models, encompassing Multi-layer Perceptron (MLP) \cite{riedmiller2014multi} and Long Short-Term Memory (LSTM) \cite{hochreiter1997long} networks. The third stage involves scaled and distributed model inference to obtain sea ice classification data. In the fourth stage, distributed local sea level detection and computation of freeboard are performed. Figure \ref{fig:is2_workflow} demonstrates the ATL03 sea ice classification and Freeboard Computation Workflow.


\subsection{Data Curation}

\subsubsection{Region of Interest}
The Ross Sea, located in a deep embayment of the Southern Ocean, holds the title of the southernmost sea on Earth.% figure ~\ref{fig:ross_sea}.
Strong katabatic winds in the Ross Sea dynamically push sea ice away from the coast and ice shelves on a daily or weekly basis \cite{bromwich1993hemispheric}, \cite{dale2017atmospheric}, creating open polynyas (areas of open water or newly formed thin ice) \cite{bromwich1993hemispheric}, \cite{thompson2020frazil}. Three significant and persistent polynyas identified in the Ross Sea are the Ross Ice Shelf Polynya, the Terra Nova Bay Polynya, and the McMurdo Sound Polynya. The interplay of strong katabatic winds and polynya formation is vital for understanding the behavior of sea ice in the Ross Sea \cite{dai2020ice}, \cite{kwok2007ross}, \cite{tian2020sea}.
Hence, in this study, the Ross Sea region is used as an experimental site to demonstrate the development of the sea ice dynamics algorithms and workflow. 
The spatial extent of the Ross Sea is from longitude -180 to -140 and latitude -78 to -70.
%Figure ~\ref{fig:ross_sea} refers to the Ross sea region of Antarctic.
% \begin{figure}[htbp]
% \centerline{\includegraphics[width=0.7\linewidth]{figures/ross_sea.png}}
% \caption{Map of Ross Sea \cite{koo2021weekly}.}
% \label{fig:ross_sea}
% \end{figure}


\begin{figure}[htb]
\begin{framed}
        \centering
        \begin{subfigure}[b]{0.32\textwidth} 
            \centering
            \includegraphics[width=\textwidth]{figures/autolabeling_ori_elev.png}
            \caption{}%IS2 track elevation over S2 original data} %using continuous colors, towards blue is water, towards green is ice}
            \label{fig:autolabeling_ori_elev}
        \end{subfigure}
        \begin{subfigure}[b]{0.32\textwidth}
            \centering
            \includegraphics[width=\textwidth]{figures/autolabeling_seg.png}
            \caption{}%Auto labeling IS2 track using S2 labeled data}%, red is water, blue is thick ice, green in thin ice}
            \label{fig:autolabeling_seg}
        \end{subfigure}
        \begin{subfigure}[b]{0.32\textwidth}
            \centering
            \includegraphics[width=\textwidth]{figures/autolabeling_ori.png}
            \caption{}%Auto labeled IS2 data over S2 original data}
            \label{fig:autolabeling_ori}
        \end{subfigure}
    \end{framed}
    \caption{Auto-labeling of IS2 (line) elevations into thick sea ice, thin ice, and open water based on S2 (image) classified surface types: (a) IS2 track elevation over S2 image, (b) Auto-labeling IS2 surface types using S2 classified surface types, and (c) Auto-labeled IS2 surface types over S2 image.}
    \label{fig:autolabeling}
\end{figure}

\subsubsection{Data Preprocessing}
This research is based on the ATL03 (release 006) sea ice geolocated photon data over the Ross Sea region. The data are obtained from the NASA Earthdata server. Only the three strong beams of the ATL03 tracks are used for the study. For each of the beams, we collect geolocation elevation along with other parameters based on the signal classification confidence of the high sea ice surface type. We also calculate the background factors, apply a geographical correction based on \cite{neumann2021icesat}, and remove ineffective reference photons. After that, we sample ATL03 data for every 2m to calculate statistical parameters, such as mean, median, and standard deviation for height, elevation, photon count, background photon, etc. Finally, we apply the first-photon bias correction to the data to maintain its correctness.
% \color{red}
% Mention getatl03 function 2m samplinh ....
% \color{black}
\subsubsection{Auto-Label Data}
Since sea ice classification requires labeled ATL03 data, we select correlated Sentinel-2 (S2) imagery for labeling. First, we search for ATL03 track line data from the Ross Sea region in November 2019. Then, we collect correlated S2 images for the same region with up to an 80-minute temporal window difference between these two satellite data. We apply thin cloud and shadow-filtered color-based segmentation \cite{iqrah2023toward} to auto-label the S2 imagery. This technique for labeling can handle thin clouds and thin shadows as satellites are often affected by the atmospheric cloud and shadow cover. Then we use the labeled data and overlay the ATL03 data on it using the same geographical projection code (EPSG 3976) for both datasets. This same projection code is needed to compare the IS2 data points with the S2 data points. After that, we auto-label the IS2 ATL03 data point based on the corresponding S2 image sea ice labels. A sample autolabeling of the IS2 track line using a 10m resolution S2 image is given in the figure \ref{fig:autolabeling}. 
%
%\textcolor{red}{write about shifting}
%
However, there is a temporal difference between IS2 and S2 datasets, as shown in Table 1. Due to this time difference, in some cases, there is a drift in the sea ice, causing the overlapped S2 and IS2 data to be misaligned. To correct this misalignment, we need to calculate the drift and adjust the IS2 and S2 data positions to get better alignment. Therefore, we shift the coincident S2 images to align them with the IS2 track based on the sea ice (thick ice, thin ice, and open water) labels from the S2 images and the elevation value of the IS2 ATL03 data product. The shift of S2 images is accomplished based on the Table \ref{shift_table}. Since these alignments are not perfect, the transition regions of different types of sea ice are affecting the correctness of the data labeling. We also found that due to some thick cloud and shadow cover in the S2 images, the overlapped IS2 track data are mislabeled. To handle these mislabeling issues resulting from the auto-labeling process, we manually correct the cloudy and transition regions to obtain a better labeled training data for IS2 data.
%\textcolor{red}{shift table}

\begin{table}[htb]

\caption{IS2 ATL03 and S2 coincident pairs ($<2$ h of time difference) in the Ross Sea in November 2019. S2 images are shifted to match the IS2 data.}
\label{shift_table}
\begin{tabular}{|c|c|c|c|c|}
\hline
  & \begin{tabular}[c]{@{}c@{}}IS2 \\ acquisition time\\ (UTC)\end{tabular} & \begin{tabular}[c]{@{}c@{}}S2 \\ acquisition time\\ (UTC)\end{tabular} & \begin{tabular}[c]{@{}c@{}}Time \\ difference \\ (minutes)\end{tabular} & \begin{tabular}[c]{@{}c@{}}Shift of \\ S2 images\\ (distance /\\  direction)\end{tabular} \\ \hline
1 & \begin{tabular}[c]{@{}c@{}}2019/11/03\\ 18:44:32\end{tabular}           & \begin{tabular}[c]{@{}c@{}}2019/11/03\\ 18:34:59\end{tabular}          & 9.55                                                                    & 550 m / NW                                                                                \\ \hline
2 & \begin{tabular}[c]{@{}c@{}}2019/11/04\\ 19:53:11\end{tabular}           & \begin{tabular}[c]{@{}c@{}}2019/11/04\\ 19:45:29\end{tabular}          & 7.7                                                                     & 0 m                                                                                       \\ \hline
3 & \begin{tabular}[c]{@{}c@{}}2019/11/13\\ 19:10:53\end{tabular}           & \begin{tabular}[c]{@{}c@{}}2019/11/13\\ 18:34:59\end{tabular}          & 35.9                                                                    & 200 m / W                                                                                 \\ \hline
4 & \begin{tabular}[c]{@{}c@{}}2019/11/16\\ 19:28:13\end{tabular}           & \begin{tabular}[c]{@{}c@{}}2019/11/16\\ 18:44:59\end{tabular}          & 43.23                                                                   & 0 m                                                                                       \\ \hline
5 & \begin{tabular}[c]{@{}c@{}}2019/11/17\\ 19:02:34\end{tabular}           & \begin{tabular}[c]{@{}c@{}}2019/11/17\\ 18:15:09\end{tabular}          & 47.57                                                                   & 530 m / NW                                                                                \\ \hline
6 & \begin{tabular}[c]{@{}c@{}}2019/11/20\\ 19:19:52\end{tabular}           & \begin{tabular}[c]{@{}c@{}}2019/11/20\\ 20:05:29\end{tabular}          & 45.62                                                                   & 400 m / NW                                                                                \\ \hline
7 & \begin{tabular}[c]{@{}c@{}}2019/11/23\\ 18:02:55\end{tabular}           & \begin{tabular}[c]{@{}c@{}}2019/11/23\\ 18:34:59\end{tabular}          & 32.07                                                                   & 150 m / E                                                                                 \\ \hline
8 & \begin{tabular}[c]{@{}c@{}}2019/11/26\\ 18:20:14\end{tabular}           & \begin{tabular}[c]{@{}c@{}}2019/11/26\\ 18:44:59\end{tabular}          & 24.75                                                                   & 350 m / SW                                                                                \\ \hline
\end{tabular}
\end{table}

\subsubsection{Scaled IS2 Auto-labeling}
First, to scale the finding of IS2 and S2 overlapped data and labeling of the IS2 based on corresponding S2 data, we used the pyspark-based map-reduce framework. Our labeling process is highly data-parallel.
Given the substantial volume of IS2 data, partitioning the dataset and distributing the computations across multiple machines is essential for improving scalability and expediting processing. To facilitate this, we leverage the PySpark map-reduce framework. This PySpark framework enables effective partitioning of large datasets and distribution of the workload across multiple worker nodes, thus enabling data parallelism and enhancing the efficiency of our project. 


\subsection{Deep Learning Model Training}
For the sea ice classification problem, we explore two techniques: LSTM and MLP. The MLP model is generally more useful for classification problems. However, the LSTM model performs better in terms of sensor-based data.

For sea ice classification in ATL07 from ATL03, NASA used their own decision tree-based approach. However, this product has the disadvantage of having a lower resolution than the original ATL03. The decision tree is a relatively simple machine-learning technique utilized for both classification and regression purposes. 
%The algorithm operates by a recursive process of partitioning the dataset into subsets, utilizing various feature values as criteria. This results in the formation of a hierarchical structure composed of decision nodes and terminal leaves. 
%Decision trees are highly conducive to visual representation and comprehension, rendering them well-suited for tasks that prioritize interpretability. 
%Decision trees offer valuable insights into the process of decision-making, as they possess the ability to effectively handle both numerical and categorical data. 
%Moreover, they are capable of capturing non-linear correlations to a certain degree. 
Nevertheless, the decision tree algorithm is susceptible to overfitting, particularly when the tree is deep and intricate, rendering it ill-suited for capturing complicated patterns within extensive datasets.
As ICESat-2 data has lots of complex information with complicated patterns, we decided to employ a Deep Neural Network approach for handling this complex spatial dataset.   

% \color{red}
% how decision tree and lstm different from nasa
% \color{black}

\subsubsection{LSTM}
The LSTM \cite{hochreiter1997long} is a special type of recurrent neural network (RNN) that has been developed to effectively process sequential data, such as time series 
and textual information. LSTM models have the ability to capture and model long-range relationships included in sequential data effectively. This characteristic makes LSTMs particularly suitable for tasks that require the analysis of temporal patterns and context. 
%Recurrent neural networks (RNNs) are particularly advantageous in handling sequence data that involves temporal and contextual considerations. 
This is achieved by the utilization of memory cells, which enable the capturing of long-range dependencies. Consequently, RNNs have found extensive application, mostly over the time series data classification and prediction. Since ATL03 is time series sensor data, and since we are doing classification on this big data, the LSTM model can help to achieve better results. 
%We plan to apply LSTM based model for the classification task.
In this study, we aim to classify each data point from high-resolution ATL03 data into three categories, namely i) Thick Ice, ii) Thin Ice, and iii) Open Water. By analyzing our data, we saw that the properties of one point, such as height/elevation, height standard deviation, high-confidence photon, photon rate changes, background photon, and background photon rate changes, are the most effective features. For example, open water is usually at sea level, wherein when the point moves from open water to sea ice or thin ice, the elevation level and height standard deviation, along with the other photon properties, also change. The point moves from along the IS2 track line path. Therefore, classifying a point in $n^{\text{th}}$ position depends on the information of the four surrounding point's $n-2$, $n-1$, $n+1$ and $n+2$ positions. Hence, we propose an LSTM \cite{hochreiter1997long} model for our classification task, which analyzes our data based on the progression data points. LSTM was originally developed to analyze sequential data where the output depends on the previous input. We use this property as the progression of data points, which simulates the change of sea ice cover (thick ice, thin ice, and open water.)
We employ a deep learning model implemented to classify geospatial data for our experiments.
The model begins with an LSTM layer, configured with 16 units and an Exponential Linear Unit (ELU) activation function, to effectively capture temporal dependencies within the input sequences, which are structured with a batch size of 5 and 6 features per time step. We include a dropout rate of 0.2 in the LSTM layer to maintain all information during the training phase. Following the LSTM, 7 Dense layers with 32, 96, 32, 16, 112, 48, and 64 units and ELU activation function are added to transform the learned features. The final layer is a Dense layer with three neurons, using a softmax activation function to output probabilities for the three classification categories. 
%
% The optimal number of units in the LSTM layer units:16
% activation:"elu"
% dropout_rate:0.2
% num_dense_layers:6
% dense_units_0:32
% learning_rate:0.003101886584898133
% dense_units_1:96
% dense_units_2:32
% dense_units_3:16
% dense_units_4:112
% dense_units_5:48
% dense_units_6:64

\subsubsection{MLP}
The MLP \cite{riedmiller2014multi} is a prevalent category of neural networks that are frequently employed in tasks that pertain to image and spatial data. To process this dataset, we need a deep learning model to get better classification results. 
%
We apply a fine-tuned MLP model to classify sea ice cover from the dataset. The model input is the same as the LSTM method. The model dense layer has 32 units, a RELU activation function, and a softmax activation function to output probabilities for the three classification categories in the final layer. 
%

Both the LSTM and MLP models are compiled with the Adam optimizer with a learning rate of 0.003 and focal loss as the loss function due to class imbalance of thick ice, thin ice and open water since we have more thick ice compared to the thin ice and open water regions in the Ross Sea.
Furthermore, we incorporate accuracy, F1 score, precision, and recall as performance metrics to ensure a comprehensive evaluation of the model’s classification capabilities. 

% focal_loss = tf.keras.losses.CategoricalFocalCrossentropy(
%     alpha=sample_weight,
%     gamma=2.0,
%     from_logits=False,
%     label_smoothing=0.0,
%     axis=-1,
%     reduction='sum_over_batch_size',
%     name='categorical_focal_crossentropy'
% )

%\textcolor{red}{We plan to compare both methods for sea ice classification and will choose the better one.}


\subsubsection{Distributed Training using Horovod Framework}
Since the training dataset size is large and the deep learning models are computationally heavy, it takes some time to train the deep learning models. Hence, the application of distributed training techniques would help reduce the training time and scale the model training without losing accuracy. We train our models using the distributed training framework Horovod \cite{sergeev2018horovod}. We have employed \textit{synchronized data parallelism} to enhance the scalability of model training across multiple GPUs. It reduces the model training time and needs only a few number line modifications in the code. 
%\textcolor{red}{talk about forward, backward, what it looks like, how it works, briefly about method for training and how it scales over multi node}
Instead of relying on one or multiple parameter servers, which are part of TensorFlow's built-in distribution strategy, we choose to leverage Horovod to aggregate and average gradients across multiple GPUs. The Horovod framework is a distributed deep-learning training framework that supports TensorFlow, Keras, PyTorch, and Apache MXNet. It allows us to distribute MLP and LSTM model training across multiple GPUs. To facilitate efficient inter-GPU communication, Horovod utilizes a ring-based all-reduce algorithm known for its bandwidth optimization and avoidance of system bottlenecks \cite{patarasuk2009bandwidth}. Coordination between processes in Horovod is achieved through MPI, with the Open-MPI-based wrapper being utilized for executing Horovod scripts.


To integrate our single-GPU implementation with the Horovod-based multiple-GPU distributed training, we follow the subsequent steps:
\begin{enumerate}
    \item Initialize Horovod using \textit{hvd.init()}.
    \item Assign a GPU to each of the TensorFlow processes.
    \item Wrap the TensorFlow optimizer with the Horovod optimizer using \textit{opt=hvd.DistributedOptimizer(opt)}. This Horovod optimizer handles gradient averaging using a ring-based all-reduce mechanism.
    \item Broadcast initial variable states from rank 0 to all other processes using\\ \textit{hvd.callbacks.BroadcastGlobalVariablesCallback(0)}.
\end{enumerate}
With the integration of Horovod, our model training accelerates significantly and becomes more scalable, all while maintaining accuracy.


\subsection{Deep Learning Model Inferencing}
High-precision LSTM and MLP models have been trained for the purpose of classifying sea ice using the IS2 ATL03 dataset.
%Our proposed approach involves the implementation of distributed inferencing for our model over a range of heterogeneous machines, with the aim of improving scalability.
\begin{figure}[htb]
%    \begin{framed}
        \centering
        \frame{\includegraphics[width=\linewidth]{figures/is2_infer.png}}
    %\end{framed}
    \caption{Workflow for IS2 sea ice classification deep learning model inferencing.
    }
    \label{fig:is2_infer}
\end{figure}
In the inferencing workflow of the generic deep learning model, as depicted in Figure \ref{fig:is2_infer}, the initial step involves the acquisition of the original IS2 ATL03 data. Then, preprocess the data and 2m resampling data. Then, these processed and sampled data are utilized as input for the deep learning model during this inferencing phase. Finally, we obtain the sea ice types classified along ATL03 tracks as the output.

%The resolution of the R, G, and B bands in these images is 10 meters. The process involves dividing the huge images into smaller 256*256 images, which will then be utilized as input for the U-net model during the inferencing phase. Prior to providing the U-net model, our thin cloud and shadow filter technique is employed to effectively exclude thin clouds and cloud shadows from the image, hence enhancing the accuracy of the inference results. Subsequently, the filtered image is forwarded to the model in order to obtain the predicted image that classifies sea ice.


\subsection{Freeboard Computation}
The freeboard of sea ice is the distance (height difference) between the local sea level and the top of the sea ice (or snow if snow appears on sea ice). Freeboard is the basis for sea ice thickness calculations. 
After the sea ice classification, we calculate the sea ice freeboard using the classification results. 
First, we need to find the local sea surface height $h_{ref}$ of the region. Then, by subtracting the local sea surface height/elevation from the individual sea ice height/elevation $h_s$, we can find individual freeboard information, $h_f$, along the ATL03 tracks.

    \begin{equation}
        h_f = h_s - h_{ref}
    \end{equation}



\subsubsection{Local Sea Surface Detection}
As for local sea surface/level detection, we have chosen a sliding window-based strategy with a radius of 5km and a whole window size of 10km with a sliding overlap of 5km, which is similar to the way the original IS2 ATL10 retrieving local sea surface \cite{kwok2022icesat}.
We use open water or lead region for a particular window of a 5 km radius (10 km length) to select the local sea level for that window region. 
However, if there is no open water for a particular window, we do a linear interpolation with respect to the nearest local sea surface to derive the local sea surface for that area.

For calculating the local sea surface, we have tested four different approaches,
\begin{enumerate}
    \item Minimum Elevation: Finding the minimum elevation of open water from a given window of a 5 km radius (10 km length).
    \item Average Elevation: Finding the average elevation of open water from a given window of a 5 km radius (10 km length).
    \item Nearest Minimum Elevation: Finding the nearest minimum elevation of open water from a given window within a 5 km radius (10 km length).
    \item The sea surface equation formulated by NASA involves the utilization of standard deviation and various other elements to determine the elevation of the sea surface within a 10km length segment of the data track. 
    For each of these segments, we first calculate the mean lead height $\hat{h_{lead\_w}}$ and estimated error $\hat{\sigma^2_{lead\_w}}$ of a single open water lead from candidate points as follows:

    \begin{equation}
        \hat{h}_{lead\_w} = \sum_{i=1}^{N_s} a_i h_i
        \text{ and }
        \hat{\sigma^2}_{lead\_w} = \sum_{i=1}^{N_s} \alpha_i^2 \sigma_i^2    
    \end{equation}

    where, $\alpha_i = \frac{w_i}{\sum_{i=1}^{N_s} w_i}$ and $w_i = \exp \left( - \frac{h_i - h_{min}}{\sigma_i} \right)^2 $.

    In this equation, $h_i$ is the surface height, and $\sigma_i^2$ is the error variance of each 2m sampled height estimate from open water candidate points, respectively. 
    Here, $h_{min}$ stands for the minimum height of each lead group point, and $N_s$ denotes the number of samples forming the individual open-water lead.
 
    After these open water leads are identified, the sea reference height $\hat{h}_{ref}$ is calculated following NASA's \cite{kwok2022icesat} equations that are done based on all the open water lead segments in the 10km segment: 
    
    \begin{equation}
        \hat{h}_{ref} = \sum_{i=1}^{N_l} a_i \hat{h}_{lead\_w(i)} 
        \text{ and }
        \hat{\sigma^2}_{ref} = \sum_{i=1}^{N_l} \alpha_i^2 \sigma_{lead\_w(i)}^2
    \end{equation}

    where, $\alpha_i = \frac{\frac{1}{\sigma_{lead\_w(i)}^2}}{\sum_{j=1}^{N_l}\frac{1}{\sigma_{lead\_w(i)}^2}}.$ Here, $N_l$ denotes the number of leads in a 10km segment.

\end{enumerate}

We compare our results of local sea level with the ATL07 and ATL10 to decide the best one for this study. 


% \color{red}

% why chose min elev

% two box map reduce aspects......

% \textbf{DGX nodes....}

% 10 times big data

% steps scaling.....

% highly parallelizable

% inferencing GPU level, map reduce

% tensorflows inferencing on gpu scaling/multiple gpus for inferencing...

% \textbf{hadoop hdfs}

% \color{black}


\subsubsection{Scaled Freeboard Computation}
To accelerate the freeboard computation, we use the map-reduce-based PySpark framework similar to our PySpark-based auto-labeling of IS2. 
Since we have a large volume of data, partitioning it and distributing the computation across multiple machines would improve scalability and processing speed. By dividing the data into smaller chunks and handling these chunks in parallel on different machines, we can process the data more efficiently and reduce overall computation time. 
Spark facilitates the partitioning of large datasets and the distribution of workloads across multiple worker nodes. This capability allows us to implement data parallelism, thereby improving the efficiency and scalability of our project.


%inferencing GPU level, map reduce
%tensorflows inferencing on gpu scaling/multiple gpus for inferencing...
%\textbf{hadoop hdfs}