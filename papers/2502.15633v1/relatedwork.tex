\section{RELATED WORK}
\subsection{Differentiable Rendering SLAM.} 
Since NeRF \cite{yen2021inerf} is proposed, many NeRF-based SLAM methods have emerged. iMAP \cite{sucar2021imap} innovatively introduces NeRF as a scene representation in SLAM, utilizing a dual-threaded approach to perform camera pose tracking and scene mapping simultaneously. NICE-SLAM \cite{zhu2022niceslam} incorporates hierarchical scene representation to fuse multi-level local information. Vox-Fusion \cite{yang2022voxfusion} combines traditional volumetric fusion methods with neural implicit representations. ESLAM \cite{johari2023eslam} implements multi-scale axis-aligned feature planes, diverging from traditional voxel grids, significantly improving frame processing speed. Subsequent works, such as GO-SLAM \cite{zhang2023goslam}, HI-SLAM \cite{zhang2023hislam}, and Loopy-SLAM \cite{liso2024loopyslam}, incorporates loop closure and global bundle adjustment (BA) into NeRF-based SLAM.
%, further improving tracking accuracy and mapping performance.

Recently, due to the fast and differentiable rendering capabilities of 3DGS \cite{kerbl20233dgs}, as well as its strong scene representation, some works have begun exploring Gaussian-based SLAM. SplaTAM \cite{keetha2024splatam} integrates Gaussian scene representation into the SLAM process, optimizing camera pose and Gaussian map by minimizing rendering photometric and depth losses. MonoGS \cite{matsuki2024gaussianmonogs} derives the pose Jacobian matrix for tracking optimization and introduced isotropic regularization to ensure geometric consistency. Photo-SLAM \cite{huang2024photo} combines ORB-SLAM3 \cite{campos2021orb-slam3} with Gaussian scene representation. GS-SLAM \cite{yan2024gs-slam} proposes a robust coarse-to-fine camera tracking technique to improve tracking speed and accuracy. Gaussian-SLAM \cite{yugay2023gaussianslam} introduces submap-based Gaussian scene representation, while CG-SLAM \cite{hu2024cg-slam} uses a novel uncertainty-aware 3D Gaussian field for consistent and stable tracking and mapping.

\begin{figure*}
    \centering
    \includegraphics[width=0.9\linewidth]{image/main_5.pdf}
    \caption{\textbf{SLAM System Pipeline:} Each frame inputs an RGB image for tracking. The current and previous frames are input as a pair into the Pointmap Regression network for pose estimation, followed by pose optimization based on the current Gaussian map. At keyframes, mapping is performed and the pointmap is processed by the Adaptive Scale Mapper for new Gaussian mapping. Camera pose and Gaussian map are jointly optimized in the local window.}
    \label{main}
\vspace{-15pt}
\end{figure*}

\subsection{RGB-only Dense Visual SLAM. }

Despite the success of these methods with RGB-D inputs, RGB-only SLAM presents unique challenges, primarily due to the lack of direct depth information which complicates geometric reconstruction. However, the increased difficulty makes RGB-only dense SLAM research more valuable. NeRF-SLAM \cite{rosinol2023nerfslam} and Orbeez-SLAM \cite{chung2023orbeez-slam} utilize DROID-SLAM \cite{teed2021droid-slam} and ORB-SLAM2 \cite{mur2017orb-slam2} as tracking modules, respectively, both leveraging Instant-NGP \cite{muller2022instant-ngp} for volumetric neural radiance field mapping. DIM-SLAM \cite{li2023densedim-slam} and NICER-SLAM \cite{zhu2024nicer} perform tracking and mapping on the same neural implicit map represented by hierarchical feature grids, but do not address global map consistency, such as loop closure. GO-SLAM \cite{zhang2023goslam} and Hi-SLAM \cite{zhang2023hislam} extend DROID-SLAM \cite{teed2021droid-slam} to the full SLAM setting by introducing online loop closure via factor graph optimization. GlORIE-SLAM \cite{zhang2024glorie} employs a flexible neural point cloud representation and introduces a novel DSPO layer for bundle adjustment, optimizing keyframe poses and depth.

Recently, some works have started using 3DGS to address the challenges of RGB-only SLAM. MonoGS \cite{matsuki2024gaussianmonogs} and Photo-SLAM \cite{huang2024photo} both support RGB-only inputs and achieve performance comparable to that of RGB-D inputs. MotionGS \cite{guo2024motiongs} implements tracking through feature extraction and a motion filter on each frame, using compressed 3D Gaussian representation to reduce memory usage. MGS-SLAM \cite{zhu2024mgs-slam} adopts DPVO \cite{teed2023deepdpvo} as tracking module and utilizes a pre-trained MVS network to estimate prior depth, adjusting its scale for Gaussian scene reconstruction. Splat-SLAM \cite{sandstrom2024splat-slam} combines GlORIE-SLAM \cite{zhang2024glorie} with Gaussian scene representation, introducing global BA into Gaussian-based SLAM. 
While substantial progress has been made, particularly in adapting SLAM technologies for indoor environments, the extension to outdoor settings remains limited. The development of robust RGB-only SLAM systems that can handle the unbounded and dynamic nature of outdoor environments is an ongoing area of research, with potential breakthroughs likely to have a significant impact on the field.