% This must be in the first 5 lines to tell arXiv to use pdfLaTeX, which is strongly recommended.
\pdfoutput=1
% In particular, the hyperref package requires pdfLaTeX in order to break URLs across lines.

\documentclass[11pt]{article}

% Change "review" to "final" to generate the final (sometimes called camera-ready) version.
% Change to "preprint" to generate a non-anonymous version with page numbers.
% \usepackage[review]{acl}
\usepackage[preprint]{acl}

% Standard package includes
\usepackage{times}
\usepackage{latexsym}

% For proper rendering and hyphenation of words containing Latin characters (including in bib files)
\usepackage[T1]{fontenc}
% For Vietnamese characters
% \usepackage[T5]{fontenc}
% See https://www.latex-project.org/help/documentation/encguide.pdf for other character sets

% This assumes your files are encoded as UTF8
\usepackage[utf8]{inputenc}

% This is not strictly necessary, and may be commented out,
% but it will improve the layout of the manuscript,
% and will typically save some space.
\usepackage{microtype}

% This is also not strictly necessary, and may be commented out.
% However, it will improve the aesthetics of text in
% the typewriter font.
\usepackage{inconsolata}

%Including images in your LaTeX document requires adding
%additional package(s)
\usepackage{graphicx}


\usepackage{booktabs}
\usepackage{changepage}
\usepackage[breakable]{tcolorbox}
\usepackage{amsmath}

\usepackage{enumitem}
%\setlist[itemize]{topsep=3pt, partopsep=3pt} % Reduces space above and below

\usepackage{hyperref}
\usepackage{xspace}
\usepackage{comment}
\usepackage{multirow}
\usepackage{algorithm}
\usepackage{algpseudocode}
\newcommand{\ours}{\textsl{AutoToM}\xspace}
\algnewcommand{\LineComment}[1]{\State \(\triangleright\) #1}

\DeclareMathOperator*{\argmax}{arg\,max}
\DeclareMathOperator*{\argmin}{arg\,min}

\usepackage[breakable]{tcolorbox}
\usepackage{fix-cm}
\usepackage{fontawesome5}

\newcommand{\jcy}[1]{{\color{red}{[(JCY): #1]}}}





% If the title and author information does not fit in the area allocated, uncomment the following
%
%\setlength\titlebox{<dim>}
%
% and set <dim> to something 5cm or larger.

\title{\ours: Automated Bayesian Inverse Planning and Model Discovery \\ for Open-ended Theory of Mind}

\author{
Zhining Zhang\textsuperscript{$\diamondsuit$}\thanks{~Equal contribution. Zhining Zhang completed this work during an internship at JHU. $^\dagger$ Project lead.} \quad
Chuanyang Jin\textsuperscript{$\heartsuit$}\footnotemark[1]$^\dagger$ \quad
Mung Yao Jia\textsuperscript{$\heartsuit$}\footnotemark[1] \quad 
Tianmin Shu\textsuperscript{$\heartsuit$} \\
\textsuperscript{$\diamondsuit$} Peking University \quad
\textsuperscript{$\heartsuit$} Johns Hopkins University \\
\texttt{zzn\_nzz@stu.pku.edu.cn, \{cjin33, mjia8, tianmin.shu\}@jhu.edu} \\
% Project website: \texttt{https://chuanyangjin.com/AutoToM/}
}


\begin{document}
\maketitle
\begin{abstract}
Theory of Mind (ToM), the ability to understand people's mental variables based on their behavior, is key to developing socially intelligent agents. Current approaches to Theory of Mind reasoning either rely on prompting Large Language Models (LLMs), which are prone to systematic errors, or use rigid, handcrafted Bayesian Theory of Mind (BToM) models, which are more robust but cannot generalize across different domains. In this work, we introduce \ours, an automated Bayesian Theory of Mind method for achieving open-ended machine Theory of Mind. \ours can operate in any domain, infer any mental variable, and conduct robust Theory of Mind reasoning of any order. Given a Theory of Mind inference problem, \ours first proposes an initial BToM model. It then conducts automated Bayesian inverse planning based on the proposed model, leveraging an LLM as the backend. Based on the uncertainty of the inference, it iteratively refines the model, by introducing additional mental variables and/or incorporating more timesteps in the context. Empirical evaluations across multiple Theory of Mind benchmarks demonstrate that \ours consistently achieves state-of-the-art performance, offering a scalable, robust, and interpretable approach to machine Theory of Mind.

\vspace{0.15cm}
\quad \faIcon[regular]{star}\; \href{https://chuanyangjin.com/AutoToM}{chuanyangjin.com/AutoToM}

\quad \faGithub\ \; \href{https://github.com/SCAI-JHU/AutoToM}{github.com/SCAI-JHU/AutoToM}
\vspace{0.15cm}
\end{abstract}

\input{sections/1-intro}
\input{sections/2-related}
\input{sections/3-method}
\input{sections/4-exp}
% \input{sections/5-analysis}
\input{sections/6-conclusion}

%\section*{Acknowledgments}
%...


% Bibliography entries for the entire Anthology, followed by custom entries
%\bibliography{anthology,custom}
% Custom bibliography entries only
\bibliography{paper}

\appendix

% \section{Example Appendix}
\label{sec:appendix}

%\onecolumn
\input{appendices/more-results}
\input{appendices/method-details}
\input{appendices/baseline-details}
\input{appendices/bench-details}
\input{appendices/prompts}

\end{document}
