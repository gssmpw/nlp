\section{Introduction}

To successfully engage in rich and complex social interactions such as cooperation, communication, and social learning, humans must adequately understand one another's mental states (e.g., goals, beliefs, desires). This ability is termed Theory of Mind (ToM) \cite{wimmer1983beliefs}. Prior works have demonstrated that like human interactions, Theory of Mind is also crucial for the success of human-AI interactions  \citep[e.g.,][]{dautenhahn2007socially, hadfield2016cooperative,liu2018goal}. In particular, to safely and productively interact with humans in an open-ended manner, AI systems need to interpret humans' mental states from observed human behavior \citep[e.g.,][]{chandra2020stylepredict,wang2021towards, wan2022handmethat,patel2022proactive,puig2023nopa,zhi2024pragmatic,ying2024goma}. 


\begin{figure*}[ht]
  \centering
  \includegraphics[width=0.95\linewidth]{figures/overview.pdf}
    \vspace{-15pt}
  \caption{An overview of \ours. $X^{t_s:t}$ are observable variables, $V^{t_s:t}$ are latent mental variables, and $q$ is the query (in this case, a mental variable $v_i^t \in V^{t}$). $t_s:t$ denotes timesteps from $t_s$ to $t$ in the context that are considered for inference. Variables $s^t, o^t, b^t, a^t, g^t$ represent state, observation, belief, action, and goal, respectively, with solid arrows indicating dependencies defined in the models. Given a question, we extract the observable variables (information extraction) and propose an initial BToM model. This is followed by automated Bayesian inverse planning and iterative model adjustment. When the model utility is high enough, we will produce the final answer based on the inference result.}
  \label{fig:overview}
  \vspace{-10pt}
\end{figure*}

There are two primary approaches to developing machine Theory of Mind in recent works. First, with the rapid progress of large language models (LLMs), there has been an increasing interest in directly applying LLMs to reason about people's mental states with prompting strategies such as perspective-taking \citep{wilf2023think, sclar2023minding, jung2024perceptions}, change-tracking \citep{huang2024notion}, and temporal-spatial reasoning \citep{hou2024timetom}. However, even with these advanced prompting techniques, state-of-the-art LLMs still make systematic errors in complex scenarios \citep{jin2024mmtom}. Second, cognitive studies have demonstrated that model-based inference, in particular, Bayesian inverse planning (BIP), can reverse engineer human-like theory of Mind reasoning \cite{baker2009action, ullman2009help, baker2017rational, zhi2020online}. BIP relies on Bayesian Theory of Mind (BToM) models \cite{baker2017rational} to approximate rational agent behaviors. Inspired by this, recent works have proposed to combine BIP and LLMs to achieve scalable yet robust model-based ToM inference \citep{jin2024mmtom, shi2024muma}. While these methods significantly outperform LLMs in specific domains, they typically require manual specification of BToM models, including necessary mental variables (e.g., goals, beliefs) for answering a given ToM question. Therefore, they lack the required generalizability for open-ended Theory of Mind.


In this work, we aim to develop a fully \textit{automated} and \textit{open-ended} Theory of Mind reasoning method. That is a unified method that can be applied to robustly infer any given mental variable in any domain. Achieving this aim requires addressing two critical questions: (1) How can we ensure that our approach is flexible enough to adapt across contexts, robust enough to model diverse human behaviors, and scalable enough to tackle increasingly complex scenarios? (2) How can we avoid manually defining model structures and instead autonomously discover the appropriate model for mental inference?


To address these challenges, we introduce \ours, a general framework for open-ended Theory of Mind. It automates every aspect of Bayesian inverse planning, including the proposal and adjustment of model structures, the identification of relevant timesteps, the generation of hypotheses, and the execution of Bayesian inference. It is designed to operate in \textit{any context}, infer \textit{any mental state}, reason about \textit{any number of agents}, and support \textit{any order of recursive reasoning}, which represents our vision of an open-ended and robust machine Theory of Mind.

Figure \ref{fig:overview} provides an overview of \ours, which consists of two main components:


First, \textbf{Automated Bayesian Inverse Planning.} \ours is capable of flexibly modeling various mental variables and their dependencies for any specified BToM model (in the form of a Bayesian network). The construction, information flow, and computations within a given BToM model are entirely automated, leveraging the adaptability of the LLM backend. Specifically, conditioned on observable variables and their values extracted from the context (by an LLM), \ours samples a small set of hypotheses for each latent mental variable using an LLM. Given the hypotheses, \ours then conducts Bayesian inference to produce the posterior distribution of the target mental variable in the question. To achieve this, \ours leverages an LLM to estimate each local conditional in the BToM model. (Section \ref{sec:inverse_planning}) 


Second, \textbf{Automated Model Discovery.} In a given scenario, \ours performs automated model proposals and iteratively adjusts variables and the timesteps of observable variables. We ground the BToM model proposals in cognitive models of human decision-making \citep[e.g.,][]{baker2017rational,ullman2009help}. The goal is to include the relevant mental variables and timesteps necessary for the inference, optimizing based on model utility, which balances the certainty of the inference and the complexity of the model. This approach eliminates the need for manual effort in defining model structures and enhances generalization by enabling automatic adaptation to diverse scenarios. Furthermore, \ours can select a different suitable model for each timestep, enabling it to adapt dynamically to changing circumstances. (Section \ref{sec:model_discovery})


\ours is the first model-based ToM method that extends beyond domain-specific applications and addresses open-ended scenarios. It integrates the flexibility of LLMs with the robustness of Bayesian inverse planning. We evaluate \ours in multiple ToM benchmarks. The results consistently show that \ours achieves state-of-the-art performance, establishing a scalable, robust, and interpretable framework for machine ToM.