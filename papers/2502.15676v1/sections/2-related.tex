\section{Related Works}

\textbf{Enhancing LLMs' Theory of Mind.} There has been systematic evaluation that revealed LLMs' limitations in achieving robust Theory of Mind inference \citep{ullman2023large, shapira2023clever}. To enhance LLMs' Theory of Mind capacity, recent works have proposed various prompting techniques. For instance, SimToM \citep{wilf2023think} encourages LLMs to adopt perspective-taking, PercepToM \citep{jung2024perceptions} improves perception-to-belief inference by extracting relevant contextual details, and \citet{huang2024notion} utilize an LLM as a world model to track environmental changes and refine prompts. Explicit symbolic modules also seem to improve LLM's accuracy through dynamic updates based on inputs. Specifically, TimeToM \citep{hou2024timetom} constructs a temporal reasoning framework to support inference, while SymbolicToM \citep{sclar2023minding} uses graphical representations to track characters' beliefs. Additionally, \citet{wagner2024mind} investigates ToM's necessity and the level of recursion required for specific tasks. However, these approaches continue to exhibit systematic errors in long contexts, complex behaviors, and recursive reasoning due to inherent limitations in inference and modeling \citep{jin2024mmtom,shi2024muma}. Most of them rely on domain-specific designs, lacking open-endedness.


\textbf{Model-based Theory of Mind inference.} Model-based Theory of Mind inference, in particular, Bayesian inverse planning (BIP) \citep{baker2009action,ullman2009help,baker2017rational,zhi2020online}, explicitly constructs representations of agents' mental states and how mental states guide agents' behavior via Bayesian Theory of Mind (BToM) models. These methods can reverse engineer human ToM inference in simple domains \citep[e.g.,][]{baker2017rational,netanyahu2021phase,shu2021agent}. Recent works have proposed to combine BIP with LLMs to achieve robust ToM inference in more realistic settings \citep{ying2023neuro, jin2024mmtom, shi2024muma}. However, these methods require manual specification of the BToM models as well as rigid, domain-specific implementations of Bayesian inference, limiting their adaptability to open-ended scenarios. To overcome this limitation, we propose \ours, a method capable of automatically modeling mental variables across diverse conditions and conducting automated BIP without domain-specific knowledge or implementations.


\begin{figure*}[ht]
  \centering
  \includegraphics[width=\linewidth]{figures/benchmarks_and_models.pdf}
    \vspace{-15pt}
  \caption{Examples questions (top panels) and the necessary Bayesian Theory of Mind (BToM) model for Bayesian inverse planning (bottom panels) in diverse Theory of Mind benchmarks. \ours aims to answer any Theory of Mind question in a variety of benchmarks, encompassing different mental variables, observable contexts, numbers of agents, the presence or absence of utterances, wording styles, and modalities. It proposes and iteratively adjusts an appropriate BToM and conducts automated Bayesian inverse planning based on the model.
  There can be more types of questions/models in each benchmark beyond the examples shown in this figure.}
  \label{fig:benchmarks_and_models}
  %\vspace{-0.75em}
  \vspace{-10pt}
\end{figure*}



\textbf{Automated Modeling with LLMs.} There has been an increasing interest in integrating LLMs with inductive reasoning and probabilistic inference for automated modeling. \citet{piriyakulkij2024doing} combine LLMs with Sequential Monte Carlo to perform probabilistic inference about underlying rules. Iterative hypothesis refinement techniques \citep{qiu2023phenomenal} further enhance LLM-based inductive reasoning by iteratively proposing, selecting, and refining textual hypotheses of rules. Beyond rule-based hypotheses, \citet{wang2023hypothesis} prompt LLMs to generate natural language hypotheses that are then implemented as verifiable programs, while \citet{li2024automated} propose a method in which LLMs construct, critique, and refine statistical models represented as probabilistic programs for data modeling. \citet{cross2024hypothetical} leverage LLMs to propose and evaluate agent strategies for multi-agent planning but do not specifically infer individual mental variables. Our method also aims to achieve automated modeling with LLMs. Unlike prior works, we propose a novel automated model discovery approach for Bayesian inverse planning, where the objective is to confidently infer any mental variable given any context via constructing a suitable Bayesian Theory of Mind model.