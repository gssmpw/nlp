\begin{table}[t]
\centering
\small
\begin{tabular}{l@{\hspace{0.1pt}}c@{\hspace{6pt}}c@{\hspace{6pt}}c@{\hspace{6pt}}c@{\hspace{6pt}}c}
\toprule
\textbf{Model} & \textbf{MATH-500} & \textbf{AIME2024} & \textbf{AIME2025-I} & \textbf{LiveMath} & \textbf{Olympiad} \\ \midrule
\multicolumn{6}{c}{API Models} \\ \midrule
GPT-4o-1120~\cite{gpt4o} & 72.8 & 16.7 & 13.3 & 44.8 & 33.7 \\
Claude-3.5-Sonnet-1022~\cite{claude35sonnet} & 78.3 & 13.3 & 3.3 & 46.7 & 35.4 \\
OpenAI-o1-preview~\cite{openai2024learning} & 85.5 & 44.6 & 40.0 & 71.0 & 43.6 \\
OpenAI-o1-mini~\cite{openai2024learning} & 90.0 & 56.6 & 46.7 & 74.4 & 46.3 \\ \midrule
\multicolumn{6}{c}{7B Models} \\ \midrule
Qwen2.5-Instrust-7B~\cite{yang2024qwen2} & 76.6 & 13.3 & 0.0 & 37.0 & 29.1 \\
Qwen2.5-Math-Instrust-7B~\cite{yang2024qwen2} & 81.8 & 20.0 & 13.3 & 44.1 & 31.1 \\
rStar-Math-7B~\cite{guan2025rstar}  & 78.4* & 26.7* & - & - & 47.1* \\
Qwen2.5-7B-SimpleRL~\cite{zeng2025simplerl}  & 82.4* & 26.7* & - & - & 37.6* \\
Eurus-2-7B-PRIME~\cite{cui2025process} & 79.2* & 26.7* & - & - & 42.1* \\
DeepSeek-R1-Distill-Qwen-7B~\cite{deepseekr1} & \underline{92.8}* & \textbf{55.5}* & \textbf{40.0} & \textbf{65.6} & \underline{64.1} \\
\textbf{\methodname{}-7B} & 91.0 & 33.3 & 33.3 & 62.6 & 59.9 \\ 
\textbf{\methodname{}-DSR1-Distill-Qwen-7B}  & \textbf{94.0} & \underline{50.0} & \textbf{40.0} & \textbf{65.6} & \textbf{66.1} \\  \midrule
\multicolumn{6}{c}{32B Models} \\ \midrule
Qwen2.5-Instrust-32B~\cite{yang2024qwen2} & 80.6 & 20.0 & 13.3 & 50.8 & 40.4 \\
QwQ-32B-Preview~\cite{qwq-32b-preview} & 90.6 & 50.0 & 40.0 & \underline{72.7} & 58.5 \\
DeepSeek-R1-Distill-Qwen-32B~\cite{deepseekr1} & 94.3* & \textbf{72.6}* & \textbf{46.7} & 67.7 & \underline{71.2} \\
\textbf{\methodname{}-32B} & \textbf{95.0} & \underline{60.0} & \textbf{46.7} & \textbf{74.8} & \textbf{72.4} \\ \bottomrule
\end{tabular}
\vspace{1em}
\caption{
Overall evaluation results for \methodname{} and each baseline.
``\methodname{}-DSR1-Distill-Qwen-7B'' denotes the DeepSeek-R1-Distill-Qwen7B trained by \methodname{}.
``AIME2025-I'', ``LiveMath'' and ``Olympiad'' represent ``AIME 2025 Part1'', ``LiveMathBench'', and ``OlympiadBench'', respectively.
For models at the parameter scale of 7B and 32B, we use Bold and Underlined to represent the best and second best performance, respectively.
For part of the baseline, we directly use the results from their report, marked with *.}
\vspace{-1em}
\label{tab: main_res}
\end{table}