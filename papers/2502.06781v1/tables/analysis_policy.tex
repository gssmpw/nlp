\begin{table}[t]
\centering
\small
\begin{tabular}{l@{\hspace{0.1pt}}c@{\hspace{6pt}}c@{\hspace{6pt}}c@{\hspace{6pt}}c@{\hspace{6pt}}c}
\toprule
\textbf{Model} & \textbf{MATH-500} & \textbf{AIME2024} & \textbf{AIME2025-I} & \textbf{LiveMath} & \textbf{Olympiad} \\ \midrule
OREAL-7B-SFT-wo-enhance & 84.8 & 26.7 & 26.7 & 55.0 & 55.1 \\
\methodname{}-7B-wo-enhance & 89.0 & 36.7 & 40.0 & 60.1 & 58.1 \\ 
\midrule
OREAL-7B-SFT & 86.4 & 26.7 & 26.7 & 54.2 & 56.0 \\
\methodname{}-7B & 91.0 & 33.3 & 33.3 & 62.6 & 59.9 \\ 
\midrule
DeepSeek-R1-Distill-Qwen-7B~\cite{deepseekr1} & 92.8* & 55.5* & 40.0 & 65.6 & 64.1 \\
\methodname{}-DSR1-Distill-Qwen-7B  & 94.0 & 50.0 & 40.0 & 65.6 & 66.1 \\ 
\midrule
OREAL-32B-SFT & 92.6 & 43.3 & 46.7 & 71.9 & 68.7 \\
OREAL-32B & 95.0 & 60.0 & 46.7 & 74.8 & 72.4 \\

\bottomrule
\end{tabular}
\vspace{1em}
\caption{Evaluation for the performance of \methodname{} on different initial policy models. Here, ``-SFT'' and ``DeepSeek-R1-Distill-Qwen7B'' denote the initial policy model. ``wo-enhance'' means the model which do not perform the skill-based enhancement during the SFT stage.}
\vspace{-1em}
\label{tab: base_model}
\end{table}