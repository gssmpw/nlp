\section{Related Work}
\label{sec:relate_work} The construction of embodied agents can be categorized into three approaches, including rule-based and traditional planning methods ____, RL methods ____, and LLM-based methods ____. 
\vspace{-1em}
\paragraph{Rule-based and Traditional Planning Methods:} Rule-based and traditional planning methods rely on expert-designed rules or algorithms to solve tasks, making them suitable for simple tasks in static environments. For example, the A* algorithm ____ excels in path planning but suffers from lower efficiency and accuracy in dynamic or unstructured environments ____. Model-based planning ____ and constraint-based planning ____ attempt to improve adaptability to complex environments, but challenges persist when handling uncertainty and dynamic changes.
\vspace{-1em}
\paragraph{RL Methods:} RL enables agents to learn task strategies through interaction with the environment and has achieved notable success in various domains, such as AlphaZero ____ in board games. However, RL often faces issues in slow convergence and policy instability in high-dimensional action spaces and sparse reward scenarios ____. Additionally, RL performs poorly in tasks requiring global planning and long-term memory due to its focus on short-term returns ____. To address these challenges, researchers have proposed model-based RL ____ to improve sample efficiency by constructing environment models, but these methods still struggle with model complexity and generalization. Deep RL ____ utilizes neural networks to enhance state representation but faces computational and data efficiency challenges in multi-task and high-dimensional scenarios ____. Furthermore, hierarchical RL ____ and meta-RL ____ offer new approaches to handle long-term planning and task transfer, demonstrating potential in dynamic and complex environments. Despite these advances, RL still struggles with stability, computational overhead, and sample efficiency, particularly in the context of complex embodied tasks.
\vspace{-1em}
\paragraph{LLM-based Methods:} The introduction of LLMs has significantly enhanced the reasoning and task-handling capabilities of agents ____. LLMs like GPT ____ and Gato ____ leverage self-supervised learning to process multimodal data and excel in natural language understanding and open-world tasks ____. However, existing LLM-driven agents exhibit limitations in long-term planning and dynamic task environments, manifesting two key issues---(1) Memory limitations: LLMs rely on autoregressive generation models and are unable to track task context or effectively store historical information; (2) Spatio-temporal reasoning deficits: LLMs perform reasoning based on pattern matching, lacking the ability to model spatio-temporal relationships in dynamic environments.

Recently, researchers have proposed several approaches to address these issues. 
%____. 
For example, ReAct ____ enhances task planning by introducing reflective and multi-step reasoning. However, ReAct's reasoning process relies on manually set few-shot samples, which limits its generalization. Reflexion ____, building upon ReAct, incorporates a self-reflection mechanism that allows agents to accumulate experience through multi-step trial and error. However, in embodied environments, errors may not be recoverable, limiting the effectiveness of this trial-and-error learning. Swiftsage ____, inspired by human dual-process theory ____ and fast-slow thinking ____, combines these modules to handle complex tasks. However, its open-loop architecture fails to adequately support long-term memory and dynamic planning. AdaPlanner ____ proposes a closed-loop architecture where an initial plan is refined based on environmental feedback. Nevertheless, it lacks a memory system, limiting its adaptability to long-horizon planning tasks. Hippo RAG ____ mimics the human hippocampus ____ and introduces KGs as long-term memory indices ____, significantly enhancing knowledge retrieval. However, these methods are still confined to short-term reasoning and lack support for long-term planning in dynamic environments.