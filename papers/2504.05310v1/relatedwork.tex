\section{Related Work}
IR search systems aim to execute user-provided queries to retrieve documents that are relevant to them.
The process is challenging when the information need expressed by the query is unclear or indirect 
\cite{pmlr-v119-guu20a,10.1145/3394486.3403305,10.1016/j.ipm.2021.102522,wen2024elaborativesubtopicqueryreformulation}. 

\subsection{Lexical and Neural First-stage IR}

To retrieve the most relevant information or candidates, traditional text-based information retrieval systems rely on matching terms between the query and the documents \cite{Croft2009SearchEI}. These methods use an inverted index, which leads to very high efficiency. They were further improved in terms of effectiveness by considering various term weighting schemes. This advancement led to a variety of TF-IDF models exemplified by BM25 \cite{Robertson2009ThePR}. These bag-of-words based approaches like BM25 gave impetus to early efforts focused on efficiency aspects of the retrieval problem. These research initiatives continued with multiple variations of BM25 to tackle different application specific challenges \cite{Robertson2009ThePR}. 

Neural models work on a semantic level, overcoming lexical overlap limitations of traditional methods. With improvement in computational resources while maintaining low-latency requirements of the e-commerce domain, single-representation bi-encoder models have become an alternative for the first-stage retrieval. TAS-B \cite{10.1145/3404835.3462891}, TCT-ColBERT-HNP \cite{lin-etal-2021-batch}, RetroMAE \cite{RetroMAE} and SimLM \cite{wang-etal-2023-simlm} are some of the state-of-the-art single-representation bi-encoder models.
Learned-sparse models exemplified by SPLADE++ \cite{10.1145/3477495.3531857,10.1145/3404835.3463098} use regularization to learn sparse representations of documents and queries. This enables efficiency comparable to lexical methods using inverted index while maintaining high effectiveness of neural methods.
Three types of methods (lexical, bi-encoder neural, and learned-sparse) are popularly used for first-stage retrieval in e-commerce.


\subsection{IR for E-Commerce and Task-oriented Queries}

E-commerce connects customers to different products and services. E-commerce product search deals with finding and ranking relevant products for user queries. The search for e-commerce products needs to be handled differently due to the prevalence of domain-specific vocabulary, seasonality, and the scale of the available user-product interaction data \cite{10.1145/3642979.3643007}. Information retrieval in e-commerce is more challenging due to the multiple heterogeneous sources of information, the wide spectrum of intent of users, and vocabulary gaps \cite{10.1145/3209978.3210185}.  Hence, various kinds of signals, including clicks, and favorites, need to be integrated into the model to derive relevance \cite{10.1145/3209978.3209993}. Furthermore, e-commerce demands high efficiency due to multi-stage pipeline with additional business specific promotional initiative layers \cite{10.1145/3451964.3451966}. Prior research has shown that traditional retrieval systems generally outperform general purpose pretrained embedding models \cite{campos2023overviewtrec2023product}. Attempts are reported where mismatched results were used for contextual retrieval improvements \cite{nguyen-etal-2020-learning}. Furthermore, it is necessary to leverage procedural knowledge which is crucial for responding to task-oriented e-commerce queries \cite{10.1145/2766462.2767744}. 

\begin{figure*}
    \centering
   % \includegraphics[scale=0.95]
\includegraphics[width=0.7\linewidth]{tqe.png}
    \caption{\qs{}: Task-oriented query generation}
    \label{fig:tqe}
\end{figure*}


Task-oriented queries or action driven queries enhance the e-commerce product search process \cite{10.1145/3583780.3615474} and are also important in the web search \cite{6040862}. Hence, it is crucial to assess task-oriented queries \cite{yim2024taskorientedqueriesbenchmarktoqb}. Existing benchmarks in relevant NLP fields focus on task-oriented dialogue systems \cite{raghu-etal-2021-unsupervised,yim2024taskorientedqueriesbenchmarktoqb}. The previous research though underlines some efforts to create task-oriented queries in a generalized setup - there is a need to have a specific task-oriented queries benchmark dataset focused on e-commerce. 
   
\subsection{Neighborhood-based Search}
A variety of systems leverage a document-level nearest-neighbor structure, referred to as a \textit{corpus graph}. For instance, HNSW \cite{8594636} is the most popular Approximate Nearest Neighbor (ANN) search method, which traverses a multi-level graph to retrieve results for vector-based queries. In addition, methods such as GAR \cite{macavaney:cikm2022-adaptive} and LADR \cite{10.1145/3539618.3591715} perform ANN search by leveraging a corpus graph and an inexpensive first stage to identify candidate documents. Unlike HNSW, GAR and LADR can approximate any relevance model, but are ultimately upper-bounded by the model's effectiveness. Meanwhile, methods such as LexBoost \cite{10.1145/3685650.3685658} focus on improving lexical retrieval with graph-based score formulations.
In addition, weighted bipartite query-document graphs have been used to include user query characteristics in graph navigation \cite{frayling:ecir2024-reverted}.

In contrast with these existing methods that use lexical or semantic signals to construct a corpus graph, we propose \sys{}, which uses user click/train annotation data to build a product-product similarity graph. Furthermore, \sys{} is not upper bounded by the recall of first-stage retrieval and works on all types of first-stage retrieval methods. In addition, it does not increase the candidate size, thus having no effect on the latency of consecutive stages.