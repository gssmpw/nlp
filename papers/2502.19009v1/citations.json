[
  {
    "index": 0,
    "papers": [
      {
        "key": "offlineRL",
        "author": "Sergey Levine and Aviral Kumar and G. Tucker and Justin Fu",
        "title": "Offline Reinforcement Learning: Tutorial, Review, and Perspectives on Open Problems"
      }
    ]
  },
  {
    "index": 1,
    "papers": [
      {
        "key": "DT",
        "author": "Lili Chen and\nKevin Lu and\nAravind Rajeswaran and\nKimin Lee and\nAditya Grover and\nMichael Laskin and\nPieter Abbeel and\nAravind Srinivas and\nIgor Mordatch",
        "title": "Decision Transformer: Reinforcement Learning via Sequence Modeling"
      },
      {
        "key": "TTO",
        "author": "Michael Janner and\nQiyang Li and\nSergey Levine",
        "title": "Offline Reinforcement Learning as One Big Sequence Modeling Problem"
      },
      {
        "key": "MGDT",
        "author": "Kuang-Huei Lee and Ofir Nachum and Mengjiao Yang and L. Y. Lee and Daniel Freeman and Winnie Xu and Sergio Guadarrama and Ian S. Fischer and Eric Jang and Henryk Michalewski and Igor Mordatch",
        "title": "Multi-Game Decision Transformers"
      },
      {
        "key": "GATO",
        "author": "Scott Reed and Konrad Zolna and Emilio Parisotto and Sergio Gomez Colmenarejo and Alexander Novikov and Gabriel Barth-Maron and Mai Gimenez and Yury Sulsky and Jackie Kay and Jost Tobias Springenberg and Tom Eccles and Jake Bruce and Ali Razavi and Ashley D. Edwards and Nicolas Manfred Otto Heess and Yutian Chen and Raia Hadsell and Oriol Vinyals and Mahyar Bordbar and Nando de Freitas",
        "title": "A Generalist Agent"
      }
    ]
  },
  {
    "index": 2,
    "papers": [
      {
        "key": "AD",
        "author": "Michael Laskin and Luyu Wang and Junhyuk Oh and Emilio Parisotto and Stephen Spencer and Richie Steigerwald and DJ Strouse and Steven Stenberg Hansen and Angelos Filos and Ethan A. Brooks and Maxime Gazeau and Himanshu Sahni and Satinder Singh and Volodymyr Mnih",
        "title": "In-context Reinforcement Learning with Algorithm Distillation"
      }
    ]
  },
  {
    "index": 3,
    "papers": [
      {
        "key": "AD",
        "author": "Michael Laskin and Luyu Wang and Junhyuk Oh and Emilio Parisotto and Stephen Spencer and Richie Steigerwald and DJ Strouse and Steven Stenberg Hansen and Angelos Filos and Ethan A. Brooks and Maxime Gazeau and Himanshu Sahni and Satinder Singh and Volodymyr Mnih",
        "title": "In-context Reinforcement Learning with Algorithm Distillation"
      }
    ]
  },
  {
    "index": 4,
    "papers": [
      {
        "key": "DPT",
        "author": "Jonathan Lee and Annie Xie and Aldo Pacchiano and Yash Chandak and Chelsea Finn and Ofir Nachum and Emma Brunskill",
        "title": "Supervised Pretraining Can Learn In-Context Reinforcement Learning"
      }
    ]
  },
  {
    "index": 5,
    "papers": [
      {
        "key": "IDT",
        "author": "Sili Huang and Jifeng Hu and Hechang Chen and Lichao Sun and Bo Yang",
        "title": "In-Context Decision Transformer: Reinforcement Learning via Hierarchical Chain-of-Thought"
      }
    ]
  },
  {
    "index": 6,
    "papers": [
      {
        "key": "Headless-AD",
        "author": "Viacheslav Sinii and Alexander Nikulin and Vladislav Kurenkov and Ilya Zisman and Sergey Kolesnikov",
        "title": "In-Context Reinforcement Learning for Variable Action Spaces"
      }
    ]
  },
  {
    "index": 7,
    "papers": [
      {
        "key": "AD-eps",
        "author": "Ilya Zisman and Vladislav Kurenkov and Alexander Nikulin and Viacheslav Sinii and Sergey Kolesnikov",
        "title": "Emergence of In-Context Reinforcement Learning from Noise Distillation"
      }
    ]
  },
  {
    "index": 8,
    "papers": [
      {
        "key": "RL2",
        "author": "Yan Duan and John Schulman and Xi Chen and Peter L. Bartlett and Ilya Sutskever and P. Abbeel",
        "title": "{RL\\textsuperscript{2}: Fast Reinforcement Learning via Slow Reinforcement Learning}"
      },
      {
        "key": "LtoRL",
        "author": "Jane X. Wang and Zeb Kurth-Nelson and Hubert Soyer and Joel Z. Leibo and Dhruva Tirumala and R{\\'e}mi Munos and Charles Blundell and Dharshan Kumaran and Matthew M. Botvinick",
        "title": "Learning to reinforcement learn"
      }
    ]
  },
  {
    "index": 9,
    "papers": [
      {
        "key": "MAML",
        "author": "Chelsea Finn and\nPieter Abbeel and\nSergey Levine",
        "title": "Model-Agnostic Meta-Learning for Fast Adaptation of Deep Networks"
      },
      {
        "key": "Reptile",
        "author": "Alex Nichol and Joshua Achiam and John Schulman",
        "title": "On First-Order Meta-Learning Algorithms"
      }
    ]
  },
  {
    "index": 10,
    "papers": [
      {
        "key": "MACAW",
        "author": "Eric Mitchell and\nRafael Rafailov and\nXue Bin Peng and\nSergey Levine and\nChelsea Finn",
        "title": "Offline Meta-Reinforcement Learning with Advantage Weighting"
      },
      {
        "key": "BOReL",
        "author": "Ron Dorfman and\nIdan Shenfeld and\nAviv Tamar",
        "title": "Offline Meta Reinforcement Learning - Identifiability Challenges and Effective Data Collection Strategies"
      },
      {
        "key": "CORRO",
        "author": "Haoqi Yuan and\nZongqing Lu",
        "title": "Robust Task Representations for Offline Meta-Reinforcement Learning\nvia Contrastive Learning"
      },
      {
        "key": "IDAQ",
        "author": "Jianhao Wang and Jin Zhang and Haozhe Jiang and Junyu Zhang and Liwei Wang and Chongjie Zhang",
        "title": "Offline Meta Reinforcement Learning with In-Distribution Online Adaptation"
      },
      {
        "key": "MoSS",
        "author": "Mingyang Wang and Zhenshan Bing and Xiangtong Yao and Shuai Wang and Hang Su and Chenguang Yang and Kai Huang and Alois Knoll",
        "title": "Meta-Reinforcement Learning Based on Self-Supervised Task Representation Learning"
      }
    ]
  },
  {
    "index": 11,
    "papers": [
      {
        "key": "MACAW",
        "author": "Eric Mitchell and\nRafael Rafailov and\nXue Bin Peng and\nSergey Levine and\nChelsea Finn",
        "title": "Offline Meta-Reinforcement Learning with Advantage Weighting"
      }
    ]
  },
  {
    "index": 12,
    "papers": [
      {
        "key": "BOReL",
        "author": "Ron Dorfman and\nIdan Shenfeld and\nAviv Tamar",
        "title": "Offline Meta Reinforcement Learning - Identifiability Challenges and Effective Data Collection Strategies"
      }
    ]
  },
  {
    "index": 13,
    "papers": [
      {
        "key": "CORRO",
        "author": "Haoqi Yuan and\nZongqing Lu",
        "title": "Robust Task Representations for Offline Meta-Reinforcement Learning\nvia Contrastive Learning"
      }
    ]
  },
  {
    "index": 14,
    "papers": [
      {
        "key": "AD",
        "author": "Michael Laskin and Luyu Wang and Junhyuk Oh and Emilio Parisotto and Stephen Spencer and Richie Steigerwald and DJ Strouse and Steven Stenberg Hansen and Angelos Filos and Ethan A. Brooks and Maxime Gazeau and Himanshu Sahni and Satinder Singh and Volodymyr Mnih",
        "title": "In-context Reinforcement Learning with Algorithm Distillation"
      },
      {
        "key": "DPT",
        "author": "Jonathan Lee and Annie Xie and Aldo Pacchiano and Yash Chandak and Chelsea Finn and Ofir Nachum and Emma Brunskill",
        "title": "Supervised Pretraining Can Learn In-Context Reinforcement Learning"
      },
      {
        "key": "IDT",
        "author": "Sili Huang and Jifeng Hu and Hechang Chen and Lichao Sun and Bo Yang",
        "title": "In-Context Decision Transformer: Reinforcement Learning via Hierarchical Chain-of-Thought"
      },
      {
        "key": "Headless-AD",
        "author": "Viacheslav Sinii and Alexander Nikulin and Vladislav Kurenkov and Ilya Zisman and Sergey Kolesnikov",
        "title": "In-Context Reinforcement Learning for Variable Action Spaces"
      }
    ]
  },
  {
    "index": 15,
    "papers": [
      {
        "key": "VariBAD",
        "author": "Luisa M. Zintgraf and\nKyriacos Shiarlis and\nMaximilian Igl and\nSebastian Schulze and\nYarin Gal and\nKatja Hofmann and\nShimon Whiteson",
        "title": "VariBAD: {A} Very Good Method for Bayes-Adaptive Deep {RL} via Meta-Learning"
      },
      {
        "key": "HyperX",
        "author": "Luisa M. Zintgraf and\nLeo Feng and\nCong Lu and\nMaximilian Igl and\nKristian Hartikainen and\nKatja Hofmann and\nShimon Whiteson",
        "title": "Exploration in Approximate Hyper-State Space for Meta Reinforcement\nLearning"
      },
      {
        "key": "BOReL",
        "author": "Ron Dorfman and\nIdan Shenfeld and\nAviv Tamar",
        "title": "Offline Meta Reinforcement Learning - Identifiability Challenges and Effective Data Collection Strategies"
      }
    ]
  },
  {
    "index": 16,
    "papers": [
      {
        "key": "MoSS",
        "author": "Mingyang Wang and Zhenshan Bing and Xiangtong Yao and Shuai Wang and Hang Su and Chenguang Yang and Kai Huang and Alois Knoll",
        "title": "Meta-Reinforcement Learning Based on Self-Supervised Task Representation Learning"
      }
    ]
  },
  {
    "index": 17,
    "papers": [
      {
        "key": "IDAQ",
        "author": "Jianhao Wang and Jin Zhang and Haozhe Jiang and Junyu Zhang and Liwei Wang and Chongjie Zhang",
        "title": "Offline Meta Reinforcement Learning with In-Distribution Online Adaptation"
      }
    ]
  },
  {
    "index": 18,
    "papers": [
      {
        "key": "ReBAL",
        "author": "Anusha Nagabandi and\nIgnasi Clavera and\nSimin Liu and\nRonald S. Fearing and\nPieter Abbeel and\nSergey Levine and\nChelsea Finn",
        "title": "Learning to Adapt in Dynamic, Real-World Environments through Meta-Reinforcement\nLearning"
      },
      {
        "key": "TFsearch",
        "author": "Brieuc Pinon and Jean-Charles Delvenne and Rapha{\\\"e}l M. Jungers",
        "title": "A model-based approach to meta-Reinforcement Learning: Transformers and tree search"
      },
      {
        "key": "MAMBA",
        "author": "Zohar Rimon and Tom Jurgenson and Orr Krupnik and Gilad Adler and Aviv Tamar",
        "title": "MAMBA: an Effective World Model Approach for Meta-Reinforcement Learning"
      }
    ]
  },
  {
    "index": 19,
    "papers": [
      {
        "key": "ReBAL",
        "author": "Anusha Nagabandi and\nIgnasi Clavera and\nSimin Liu and\nRonald S. Fearing and\nPieter Abbeel and\nSergey Levine and\nChelsea Finn",
        "title": "Learning to Adapt in Dynamic, Real-World Environments through Meta-Reinforcement\nLearning"
      },
      {
        "key": "MAMBA",
        "author": "Zohar Rimon and Tom Jurgenson and Orr Krupnik and Gilad Adler and Aviv Tamar",
        "title": "MAMBA: an Effective World Model Approach for Meta-Reinforcement Learning"
      }
    ]
  },
  {
    "index": 20,
    "papers": [
      {
        "key": "TFsearch",
        "author": "Brieuc Pinon and Jean-Charles Delvenne and Rapha{\\\"e}l M. Jungers",
        "title": "A model-based approach to meta-Reinforcement Learning: Transformers and tree search"
      }
    ]
  }
]