\section{RELATED WORK}
\paragraph{Learning-Based Cardinality Estimators.}Learning-based cardinality estimators are typically divided into query-driven and data-driven models based on the form of inputs required during training. Query-driven methods\cite{kipf2018learned,dutt2019selectivity,zhao2022lightweight} aim to establish a regression model between the data range and the true cardinality, indirectly fitting the data distribution under the schema. Data-driven methods\cite{hilprecht2019deepdb,wang2021face,wu2012bayescard,wu2023factorjoin,yang2019deep,yang2020neurocard,} directly model the data distribution under the schema by combining the principles of probabilistic graphical models in machine learning. The learning objectives of these two types of methods are not contradictory; hence, some research combines these two approaches into hybrid-driven methods. Some hybrid methods \cite{dutt2019selectivity,wu2021unified} use queries and true cardinalities as penalty items for the learning objective to enhance the performance of data-driven methods and introduce several strengths of query-driven methods.

\paragraph{Distributionally Robust Optimization (DRO).}DRO methods are typically used in the deep learning field\cite{oren2019distributionally,sagawa2019distributionally,xie2024doremi} to enhance the generalization ability of models to obtain robust models by defining the uncertainty set. Group DRO\cite{sagawa2019distributionally}, emerging on this basis, reduces training difficulty at the cost of fewer degrees of freedom. Our method follows DoReMi\cite{xie2024doremi}, using a small-scale proxy model to optimize the data for training large language models more efficiently. We use group DRO to calculate the contribution of each training set to the model's performance.