


\section{RELATED WORK}
% In this section, we briefly review the traditional tagging system and LLM-enhanced tagging system.
% Tagging system plays a crucial role for various online applications~\cite{givon2009predicting,gupta2010survey}), which aims to assign appropriate tags toward a certain content. 

In this section, we briefly review traditional tagging systems and LLM-enhanced tagging systems.


\subsection{Traditional Tagging Systems}
Traditional tagging systems~\cite{gupta2010survey,mishne2006autotag,choi2016automatic} generally employ multi-label classification models, which utilize human-annotated tags as ground truth labels and employ content descriptions as input to predict. Qaiser et al.~\cite{qaiser2018text} utilize TF-IDF to categorize the tag while Diaz et al.~\cite{diaz2010lda} employ LDA to automatically tag the resource based on the most likely tags derived from the latent topics identified. The advent of deep learning has led to the proposal of RNN-based~\cite{liu2016recurrent} and CNN-based~\cite{zhang2015sensitivity} methods for achieving multi-label learning, which are directly applied to tagging systems~\cite{wang2015unified, elnagar2019automatic}. Hasegawa et al.~\cite{hasegawa2021bert} further adopt the BERT pre-training technique in their tagging systems. Recently, with the growing popularity of pre-trained Small Language Models (SLMs), numerous pre-training embedding models, such as BGE~\cite{bge}, GTE~\cite{gte}, and CONAN~\cite{conan}, have been proposed and directly employed in tagging systems through domain knowledge fine-tuning.

Nonetheless, the capabilities of these models are constrained by their limited model capacity, particularly in the presence of complex content. Additionally, they depend excessively on annotated training data, resulting in sub-optimal generalization and transferability.



\subsection{LLM-Enhanced Tagging Systems}
With Large Language Models (LLMs) achieving remarkable breakthroughs in natural language processing~\cite{achiam2023gpt,touvron2023llama,guo2025deepseek,brown2020language} and information retrieval systems~\cite{zhu2023large,lin2023can}, LLM-enhanced tagging systems have received much attention and have been actively explored currently~\cite{wang2023large,sun2023text,chae2023large,li2023taggpt,zhu2023icxml}.
Wang et al.~\cite{wang2023large} employ LLMs as a direct tagging classifier, while Sun et al.~\cite{sun2023text} introduce clue and reasoning prompts to further enhance performance. LLM4TC~\cite{chae2023large} undertakes studies on diverse LLMs architectures and leverages annotated samples to fine-tune the LLMs. TagGPT~\cite{li2023taggpt} introduces an early match-based recall mechanism to generate candidate tags from a large-scale tag 
repository with textual clues from multimodal data. ICXML~\cite{zhu2023icxml} proposes a two-stage framework through in-context learning to guide LLMs to align with the tag space.

However, the aforementioned works suffer from three critical limitations (mentioned in Section 1): (1) difficulties in comprehensively retrieving relevant candidate tags, (2) challenges in adapting to emerging domain-specific knowledge, and (3) the lack of reliable tag confidence quantification. %Consequently, the implementation of these methods for tag generation in industrial information retrieval applications is impractical and unreasonable. 
To this end, we propose LLM4Tag, an automatic tagging system, to address the aforementioned limitations.




