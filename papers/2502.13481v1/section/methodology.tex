
\section{Methodology}
In this section, we present our proposed LLM4Tag framework in detail. We start by providing an overview of the proposed framework and then give detailed descriptions of the three modules in LLM4Tag.

\subsection{Overview}
As illustrated in Figure~\ref{fig: overall}, our proposed LLM4Tag framework consists of three major modules: (1) Graph-based Tag Recall, (2) Knowledge-enhanced Tag Generation, and (3) Tag Confidence Calibration, which respectively provides completeness, continual knowledge evolution, and quantifiability.

\textbf{Graph-based Tag Recall} module is responsible for retrieving a small-scale, highly relevant candidate tag set from a massive tag repository. Based on a scalable content-tag graph constructed dynamically, graph-based tag recall is utilized to fetch dozens of relevant tags for each content. 

\textbf{Knowledge-enhanced Tag Generation} module is designed to accurately generate tags for each content via Large Language Models (LLMs). To address the lack of domain-specific and emerging knowledge in general-purpose LLMs, this module implements a scheme integrating the injection of both long-term and short-term domain knowledge, thereby achieving continual knowledge evolution.

\textbf{Tag Confidence Calibration} module is aimed to generate a quantifiable and reliable confidence score for each tag, thus alleviating the issues of hallucination and uncertainty in LLMs. Furthermore, the confidence score can be employed as a relevance metric for downstream information retrieval tasks.


% \cb{use label or tag for the whole paper} 
% \cb{and emerging information} 
% \cb{sft ot ft?}
% \cb{what is self-alignment?}
% \cb{contribution1} 

\subsection{Graph-based Tag Recall}
Given the considerable magnitude of tags (millions) in industrial information retrieval system, the direct integration of the whole tag repository into LLMs is impractical due to the constrained nature of the context window and inference efficiency of LLMs. 
Existing approaches~\cite{li2023taggpt,zhu2023icxml} adopt simple match-based tag recall to filter out a small-scale candidate tag set based on small language models (SLMs), such as BGE~\cite{bge}. However, they are prone to missing relevant tags due to the limited capabilities of SLMs. 
To address this issue and improve the comprehensiveness of the retrieved candidate tags, we construct a semantic graph globally and propose a graph-based tag recall module. 


Firstly, we initial an undirected graph $\mathcal{G}$ with contents and tags as:
\begin{equation}
\begin{aligned}
\mathcal{G}=\{\mathcal{V},\mathcal{E}\}~,
\end{aligned}
\end{equation}
where vertex set $\mathcal{V}=\{\mathcal{C},\mathcal{T}\}$ is the set of existing content vertices $\mathcal{C}$ and all tag vertices $\mathcal{T}$. As for the edge set $\mathcal{E}$, it contains two types of edges, called \textit{Deterministic Edges} and \textit{Similarity Edges}.


\textbf{Deterministic Edges} only connect between content vertex $c$ and tag vertex $t$, formulated as $e_{c-t}^d$, which indicates that content $c$ is labeled with tag $t$ based on historical annotation data.
To ease the high sparsity of the deterministic edges in the graph $\mathcal{G}$, we further introduce semantic similarity-based edges (\textbf{Similarity Edges}) that connect not only between content vertex $c$ and tag vertex $t$, but also between different content vertices, formulated as $e_{c-t}^s$ and $e_{c-c}^s$, respectively. 

Specifically, for the $i$-th vertex $v^i \in \mathcal{V}$ in graph $\mathcal{G}$, we summarize all textual information (\textit{i.e.}, title and category in content, tag description) as $text^{i}$ and vectorize it with an encoder to get a semantic representation $\boldsymbol{r}^i$:
\begin{equation}
\begin{aligned}
    \textit{\textbf{r}}^i &= \operatorname{Encoder}(text^{i})~,
\end{aligned}
\end{equation}
where $\operatorname{Encoder}$ is a small language model, such as BGE~\cite{bge}. Then the similarity distance of two different vertices $v^i, v^j$ can be computed as:
\begin{equation}
\begin{aligned}
    \operatorname{Dis}(v^i, v^j) &= \frac{\textit{\textbf{r}}^i\cdot\boldsymbol{r}^j}{\lVert\boldsymbol{r}^i\rVert \lVert\boldsymbol{r}^j\rVert}~.
\end{aligned}
\end{equation}

After obtaining the similarity estimations, we can use a threshold-based method to determine the similarity edge construction, \textit{i.e.},
\begin{itemize}[leftmargin=12pt]
    \item $e_{c-t}^s$ connects the content $c$ and the tag $t$ if the similarity distance between them exceeds $\delta_{c-t}$.
    \item $e_{c-c}^s$ connects the similar contents when their similar distance exceeds $\delta_{c-c}$.
\end{itemize}

In this way, we can construct a basic content-tag graph with deterministic/similarity edges. Then, when a new content $c$ appears that needs to be tagged, we dynamically insert it into this graph by adding similarity edges.
Next, we define two types of meta-paths (\textit{i.e.}, C2T meta-path and C2C2T meta-path) and adopt the meta-path-based approach to recall candidate tags.

\textbf{C2T Meta-Path}: Based on the given content $c$, we first recall the tags which is connected directly to $c$ as the candidate tags. The meta-path can be defined as:
\begin{equation}
\begin{aligned}
    p^{C2T} = c\overset{s}{\rightarrow} t~, 
\end{aligned}
\end{equation}
where $\overset{s}{\rightarrow}$ is the  similarity edge.

\textbf{C2C2T Meta-Path}: C2C2T contains two sub-procedures: C2C and C2T. C2C is aimed at discovering similar contents while C2T further attempts to recall the deterministic tags from these similar contents. The meta-path can be formulated as:
\begin{equation}
\begin{aligned}
    p^{C2C2T} = c\overset{s}{\rightarrow}c\overset{d}{\rightarrow}t~,
\end{aligned}
\end{equation}
where $\overset{d}{\rightarrow}$ is the deterministic edge and $\overset{s}{\rightarrow}$ is the similarity edge.

With these two types of meta-paths, we can generate a more comprehensive candidate tag set for content $c$ as
\begin{equation}
\begin{aligned}
    \Phi(c) &=  \Phi^{C2T}\left(c\right) \cup \Phi^{C2C2T}\left(c\right)~,
\end{aligned}
\end{equation}
where $\Phi^{C2T}\left(c\right)$ is retrieved by C2T meta-path and $\Phi^{C2C2T}$ is retrieved by C2C2T meta-path.
Notably, the final tagging results of LLM4Tag for the content $c$ will also be added to the graph as deterministic edges, enabling dynamic scalability of the graph.


Compared to simple match-based tag recall, our graph-based tag recall leverages semantic similarity to construct a global content-tag graph and incorporates a meta-path-based multi-hop recall mechanism to enhance candidate tags completeness, which will be demonstrated in Sec~\ref{sec:exp_retrieval}. 
% 多跳random work->利用图的局部性->相关性->召回完整性更全 

% 多路图召回

\subsection{Knowledge-enhanced Tag Generation}
After obtaining the candidate tag set, we can directly use the Large Language Models (LLMs) to select the most appropriate tags. However, due to the diversity and industry-specific nature of the information retrieval system applications, domain-specific knowledge varies significantly across different scenarios. That is, the same content and tags may have distinct definitions and interpretations depending on the specific application context.
Furthermore, the domain-specific knowledge is emerged continually and constantly at an expeditious pace. As a result, the general-purpose LLMs have difficulty in understanding the emerging domain-specific information, such as newly listed products, emerging hot news, or newly added tags, leading to a lower accuracy on challenging cases.

To address the lack of emerging domain-specific information in LLMs, we devise a knowledge-enhanced tag generation scheme that takes into account both long-term and short-term domain-specific knowledge by two key components, namely \textit{Long-term Supervised Knowledge Injection} (LSKI), \textit{Short-term Retrieved Knowledge Injection} (SRKI).

% \begin{figure}[h]
%   \centering
% %   \vspace{-0.8em}
%   \includegraphics[width=0.9\linewidth]{}
% %   \vspace{-1.0em}
%   \caption{\chenxu{given a graph with no RAG/RAG prompt}}
%   \label{fig: prompt}
% \end{figure}

\begin{figure}[h]
    \centering
    \includegraphics[width=0.48\textwidth]{figure/prompt1.pdf}
    \caption{Prompt template for basic tag generation in advertisement creatives tagging scenario.}
    \label{fig:prompt1}
\end{figure}

\subsubsection{Long-term Supervised Knowledge Injection.} For long-term domain-specific knowledge, we first construct a training dataset $\mathcal{D}$ and adopt a basic prompt template as ${Template_b}$ for tag generation (shown in Figure~\ref{fig:prompt1}). 
\begin{equation}
\begin{aligned}
    \mathcal{D} &= \{(x_i, y_i)\}_{i=1}^N~,\\
    x_i &= {Template_b}(c_i, \Phi(c_i))~,
    % \{(c_i, \Phi(c_i), y_i)\}_{i=1}^N~,
\end{aligned}
\end{equation}
where $N$ is the size of training dataset. Notably, to ensure the comprehensiveness of domain-specific knowledge, we employ the principle of diversity for sample selection and obtain correct answers $y_i$ by combining LLMs generation with human expert annotations.


After obtaining the training set, we leverage the causal language modeling objective for LLM Supervised Fine-Tuning (SFT):
% \begin{equation}
%     \max_{\Theta}\sum_{i=1}^N\, \sum_{j=1}^{|y_i|}\log P_{\Theta}\left(y_{i}\left[j\right] \mid x_i,y_{i}\left[1:j-1\right]\right)~,
% \end{equation}
% where $\Theta$ is the parameter of LLM, $y_{i}\left[j\right]$ is the $j$-th token of the textual output $y_{i}$, and $y_{i}\left[1:j-1\right]$ denotes the tokens before $y_{i}\left[j\right]$.
\begin{equation}
    \max_{\Theta}\sum_{i=1}^N\, \sum_{j=1}^{|y_i|}\log P_{\Theta}\left(y_{i,j} \mid x_i,y_{i,<j}\right)~,
    \label{eq:loss}
\end{equation}
where $\Theta$ is the parameter of LLM, $y_{i,j}$ is the $j$-th token of the textual output $y_{i}$, and $y_{i,<j}$ denotes the tokens before $y_{i,j}$ in the $i$-th samples.

By adopting this approach, we can effectively integrate the domain-specific knowledge from information retrieval systems into LLMs, thus improving the tagging performance.


\subsubsection{Short-term Retrieved Knowledge Injection.} Although LSKI effectively provides domain-specific knowledge, continuously incorporating short-term knowledge through LLM fine-tuning is highly resource-intensive, especially given the rapid emergence of new domain knowledge.
Additionally, this approach suffers from poor timeliness, making it more challenging to adapt to rapidly evolving content in information retrieval systems, particularly for emerging hot topics.



Therefore, we further introduce a short-term retrieved knowledge injection (SRKI). 
Specifically, we derive two retrieved knowledge injection methods: \textit{retrieved in-context learning injection} and \textit{retrieved augmented generation injection}.

% \begin{figure}[h]
%   \centering
% %   \vspace{-0.8em}
%   \includegraphics[width=0.9\linewidth]{}
% %   \vspace{-1.0em}
%   \caption{\chenxu{given a graph to show short-term knowledge injection}}
%   \label{fig: f}
% \end{figure}

% \textbf{Retrieved In-Context Learning Injection}.
% Given the content $c$ and the candidate tag set $\Phi(c)$, this composition attempts to retrieve similar contents and their correct/incorrect tagging information. This information is inserted into the prompt as input of LLM to achieve in-context learning, which guides LLM in understanding the domain-specific knowledge in this scenario to assist in tagging, especially for those tags that are on the boundary. Similarly, the tags in $\Phi(c)$ and their correct/incorrect content information can also be employed to further improve the performance.

% \textbf{Retrieved Augmented Generation Injection}. Given the content $c$ and the candidate tag set $\Phi(c)$, this composition tries to retrieve relevant paragraphs from web search and our own database. It can retrieve a lot of information that is beneficial to the tagging, for example, the definition of terminology in the content/tag or some manually defined tagging rules. Then all retrieved information is integrated into the input of LLM, directing LLM to select the appropriate tags.

\textbf{Retrieved In-Context Learning Injection}.
We first construct a retrievable sample knowledge base (including contents and their correct/incorrect annotated tags) and continuously append newly emerging samples. 
Then, given the target content $c$, this composition retrieves $n$ relevant samples from the sample knowledge base. 
This approach not only leverages the few-shot in-context learning capability of LLMs but also enables them to quickly adapt to emerging domain knowledge, enhancing tagging accuracy for challenging cases.

%These information can guide LLM to understand the specification of tagging in this scenario, especially for those tags that are on the boundary.
% Similarly, the tags in $\Phi(c)$ and their correct/incorrect content information can also be employed to further improve the performance.

\textbf{Retrieved Augmented Generation Injection}. 
Given the content $c$ and the candidate tag set $\Phi(c)$, this composition retrieves relevant descriptive corpus from web search and domain knowledge base. It can retrieve extensive information that assists LLMs in understanding unknown domain-specific knowledge or new knowledge, such as the definition of terminology in the content/tag or some manually defined tagging rules.

\begin{figure}[h]
    \centering
    \includegraphics[width=0.48\textwidth]{figure/prompt2.pdf}
    \caption{Prompt template for retrieval enhanced tag generation in advertisement creatives tagging scenario.}
    \label{fig:prompt2}
\end{figure}

After obtaining the retrieved knowledge, we design a prompt template, ${Template_r}$,  (shown in Figure~\ref{fig:prompt2}) to integrate knowledge with the content $c$ and candidate tag set $\Phi(c)$ to provide the in-context guidance for LLMs to predict the most appropriate tags for content $c$ as:
\begin{equation}
\begin{aligned}
      \Gamma(c)  &=\operatorname{LLM}({Template_r}(c, \Phi(c), R(c)))~, \\
      &= \left\{t^c_1, t^c_2, \cdots, t^c_m\right\}~,
\end{aligned}
\end{equation}
where $R(c)$ is the retrieved knowledge above, and $m$ is the number of appropriate tags generated by LLMs.





\subsection{Tag Confidence Calibration}
After tag generation, there still exist two serious problems for real-world applications: (1) the hallucination due to the uncertainty of LLMs, which leads to generating irrelevant or wrong tags; (2) the necessity of assigning a quantifiable relevance score for each tag for the sake of downstream usage in the information retrieval systems (\textit{e.g.}, recall and marketing). 

% \begin{figure}[h]
%   \centering
% %   \vspace{-0.8em}
%   \includegraphics[width=0.9\linewidth]{}
% %   \vspace{-1.0em}
%   \caption{\chenxu{given a tag confidence prompt}}
%   \label{fig: prompt}
% \end{figure}

\begin{figure}[h]
    \centering
    \includegraphics[width=0.48\textwidth]{figure/prompt3.pdf}
    \caption{Prompt template for tag confidence judgment in advertisement creatives tagging scenario.}
    \label{fig:prompt3}
\end{figure}

To handle these two problems, the tag confidence calibration module is adopted. Specifically, given a target content $c$ and a certain tag $t^c \in \Gamma(c)$, we derive a prompt template, ${Template_c}$ (shown in Figure~\ref{fig:prompt3}), to leverage the reasoning ability of LLMs to achieve a tag confidence judgment task, \textit{i.e.}, whether $c$ and $t^c$ is relevant. Then we extract the probability of the token in the LLM result to get a confidence score $\operatorname{Conf}(c, t^c)$:
\begin{equation}
\begin{aligned}
    \boldsymbol{s} &= \operatorname{LLM}({Template_c}(c, t^c))\,\in\mathbb{R}^{V}, \\
    \operatorname{Conf}(c, t^c) &= \frac{\exp\left(\boldsymbol{s}\left[``Yes"\right]\right)}{\exp\left(\boldsymbol{s}\left[``Yes"\right]\right)+\exp\left(\boldsymbol{s}\left[``No"\right])\right)} \,\in(0,1)~,
\end{aligned}
\end{equation} 
where $\boldsymbol{s}$ is the probability score for all tokens, and $V$ is the vocabulary size of LLMs.

After obtaining the confidence score $\operatorname{Conf}(c, t)$, we implement self-calibration for the results by eliminating those tags with low confidence, achieving a better performance by mitigating the hallucination problem. Furthermore, this confidence score can be directly set as a relevance metric for the downstream tasks. 

\textbf{Tag Confidence Training.}
In order to make the confidence score more consistent with the requirements of information retrieval, we construct a confidence training dataset $\mathcal{D}'$ as:
\begin{equation}
\begin{aligned}
    \mathcal{D}' &= \{(x_i', y_i')\}_{i=1}^M,\\
    x_i' &= \operatorname{Prompt_c}(c_i, t_i)~,\\
    y_i' &\in \{``Yes", ``No"\}~,
    % \{(c_i, \Phi(c_i), y_i)\}_{i=1}^N~,
\end{aligned}
\end{equation}
where $y_i$ is annotated by experts and $M$ is the size of training dataset. Then we leverage the causal language modeling objective, which is the same as Equation~(\ref{eq:loss}) to perform supervised fine-tuning. In that case, the confidence score predicted by this module aligns with the requirements of the information retrieval systems, thereby facilitating the calibration of incorrect tags.


% \subsection{Discussion}


% \cb{discussion section?}
% 把introduction中的三个特性加进来  亮点
% 效率,训练

% 	1. Overview
% 	2. 多路召回候选标签
% 		a. Item-tag检索
% 			i. 文本检索+视频检索+图片检索+音频检索；非文本态的先转文本态再检索
% 		b. Item-item-tag检索
% 			i. 相关内容检索（根据内容，去检索相似的内容，将这些内容的标签也作为候选标签）
% 	3. 基于垂域知识的学习模块的LLM打标
% 		a. 更新快：短期RAG，长期sft
% 		b. RAG增强
% 		c. SFT
% 定制化
% 	4. LLM为打出来的标签生成置信度
% 		a. logit方法（问打出来的标签是否相关 ）
% 		b. 剔除低置信度标签
% sft