\section{Related Work}
This section provides an overview of SDP and explores existing techniques for explainable SDP.
\subsection{Software defect prediction}\label{subsec_2}
The primary goal of SDP is to classify code fragments (e.g., method or class) as either clean or buggy. Constructing a typical SDP model involves three steps. \textcolor{blue}{The first step is to transform software metrics, such as cohesion, coupling, complexity, encapsulation, inheritance, and size, into corresponding numerical representations \cite{12}.} \textcolor{blue}{The second step labels code fragments as buggy or clean based on post-release defects.} These defects can be collected from a Bug Tracking System (BTS) by connecting bug reports to their bug-fixing activities. Code fragments associated with these bug-fixing activities are regarded as buggy, while all others are labeled as clean. Finally, the labeled code fragments serve as training data for an ML-based classifier, which is then used to predict whether code fragments in a later version are buggy or clean.

Numerous ML algorithms, including Fuzzy self-organizing maps, K-means, SVM, random forest, logistic regression, etc., have been extensively employed in previous research \cite{20, 21, 22, 23, 24, 25, 26}. However, metrics used in SDP consistently exhibit correlations and redundancies \cite{13}, compromising the effectiveness of traditional ML-based predictors \cite{14}. To address this issue, various DL models have been investigated to improve SDP performance. The initial DL-based defect predictor, Deeper, introduced by Yang et al. \cite{27}, employed a deep belief network to identify discriminative information in the input data. Experimental results showed that Deeper could identify 32.22\% more defects than many traditional ML-based approaches.
Inspired by Yang’s work, many researchers have proposed different DL-based solutions. Specifically, Hoang et al. proposed a convolutional neural network (CNN)-based defect prediction model \cite{28}, which experimental results indicated outperformed Deeper. Qiao et al. proposed another DL-based model called DPNN to predict the number of defects \cite{29}. Experimental results showed a 14\% reduction in mean square error and an 8\% increase in the squared correlation coefficient. Li et al. proposed another CNN-based defect predictor, DP-CNN \cite{30}, which achieved better performance than other methods. As demonstrated, DL has significantly improved the performance of SDP.

To ensure the generalization, we employ the DP-CNN proposed in \cite{30} as the predictor and evaluate the difference in accuracy before and after integrating it into the joint-learning framework.

\subsection{Interpretation of defect prediction}
In many practical application scenarios, practitioners often ask: What is the underlying decision logic of the predictor? What is the reason for predicting a code fragment as buggy? How do different metrics influence the prediction? These questions highlight an urgent requirement for explainable defect prediction. However, highly accurate SDP models (e.g., Random Forest, DL) are often black-box in nature, making them difficult to interpret.

Efforts to improve the interpretability of predictions can be broadly divided into two main categories \cite{murdoch2019definitions}: \textit{global} and \textit{local} approaches. The \textit{global} approaches offer a high-level view of how inputs influence the model’s predictions and reveal patterns that are consistent across the model’s entire operation, rather than focusing on individual predictions. Many ML algorithms (e.g., decision trees, logistic regression techniques) and statistical methods (e.g., ANOVA, variable importance) fall into this category\cite{31,32}. These methods share two common aspects: 1. Simulatability: Every step of the decision-making process is comprehensible. For example, decision trees are simulatable since we can observe the state of every node as well as the feature thresholds used to separate samples. 2. Transparency: The decision-making process can be broken down into interpretable steps. For instance, the interpretability of a decision tree is defined by the computational path from the root node to the leaf nodes.
However, \textit{global} approaches cannot provide detailed interpretations for each code fragment, and their relatively simple structure often fails to guarantee optimal predictive accuracy. Consequently, many practical applications have adopted \textit{local} methods.

In contrast to \textit{global} approaches, \textit{local} methods such as LIME \cite{lime} and BreakDown \cite{34}, usually interpret the prediction of each code fragment as a list of ordered features. Feedback from practitioners indicates that the interpretations produced by \textit{local} methods can offer more actionable guidance \cite{58}.
However, recent studies have reported that \textit{local} techniques lack reliability under various conditions \cite{36,37,58}. Firstly, \textit{\textbf{ the interpretations \textcolor{blue}{of the same code can be inconsistent} when different data sampling techniques are used.}} 
In SDP, sampling is frequently used due to the scarcity of buggy codes. It is an effective way to mitigate the effects of imbalanced data on the ML algorithms \cite{59}. In \cite{58}, Jiho Shin et al., investigated the consistency of \textit{local} methods across five commonly used data sampling techniques. Their analysis revealed that both the features and the ranking of features in the interpretation vary significantly when different data sampling techniques are employed.
Secondly, \textit{\textbf{the interpretations of a code fragment do not exhibit consistency when multiple interpretations are executed.}} The underlying intuition of \textit{local} methods regards the interpreter $g$ and the predictor $f$ as two independent ML algorithms and leverages $g$ to approximate the behavior of $f$ within the local area of an instance $x$, denoted as $\pi_x$. In general, \textit{local} methods cannot guarantee that the $\pi_x$ required for multiple interpretations of the same instance are the same. So different $\pi_x$ can lead to distinct interpretations for the same code fragment \cite{37}. Finally, \textit{\textbf{the predictions produced by the interpreter and the predictor for the same code fragment are not consistent.}} To reduce the difficulty of interpretation, many \textit{local} methods define the interpreter as a simple-structure ML model. Taking the most widely used local interpretation technique LIME as an example, it sets a linear regression model as the interpreter, and the interpretation of SDP is oversimplified as a linear transformation between input metrics and prediction outcomes.
Recently, \cite{37} emphasized that attempting to comprehend an intricate model by employing a simple model might be overly optimistic. The inconsistency between the predictions generated by the interpreter and the predictor indicates that the interpretation fails to capture the underlying decision-making logic of the predictor.

\subsection{Knowledge distillation}
Knowledge distillation (KD) is a typical model compression technique that transfers knowledge from a teacher model (e.g., DL models) to a student model (e.g., a shallow neural network) \cite{38,39}. KD is regarded as a promising framework for improving the reliability of interpretation due to the faithful knowledge transfer channel between the student and teacher models. In the health care domain, \cite{che2016interpretable} leveraged distilled knowledge to discover disease patterns. Similarly, in the business domain, \cite{biggs2021model} distilled dynamical pricing knowledge from a complex black-box DL model, optimizing revenue while maintaining interpretability. In this paper, we designate the predictor as the teacher model and the interpreter as the student model, and transfer the decision-making knowledge of predictor to interpreter based on the KD principle. The main difference between our approach and existing methods lies in the revised loss functions of KD framework, which enable us to train the interpreter and predictor in a collaborative manner.


%-------------------------------3. proposed method ---------------------------------------