[
  {
    "index": 0,
    "papers": [
      {
        "key": "image_reward",
        "author": "Xu, Jiazheng and Liu, Xiao and Wu, Yuchen and others",
        "title": "{ImageReward}: Learning and evaluating human preferences for text-to-image generation"
      },
      {
        "key": "hpsv2",
        "author": "Wu, Xiaoshi and Hao, Yiming and Sun, Keqiang and Chen, Yixiong and Zhu, Feng and Zhao, Rui and Li, Hongsheng",
        "title": "{Human Preference Score v2}: A solid benchmark for evaluating human preferences of text-to-image synthesis"
      },
      {
        "key": "pickscore",
        "author": "Kirstain, Yuval and Polyak, Adam and Singer, Uriel and Matiana, Shahbuland and Penna, Joe and Levy, Omer",
        "title": "{Pick-a-Pic}: An open dataset of user preferences for text-to-image generation"
      },
      {
        "key": "ahf",
        "author": "Lee, Kimin and Liu, Hao and Ryu, Moonkyung and others",
        "title": "Aligning text-to-image models using human feedback"
      }
    ]
  },
  {
    "index": 1,
    "papers": [
      {
        "key": "raft",
        "author": "Hanze Dong and Wei Xiong and Deepanshu Goyal and others",
        "title": "{RAFT}: {Reward rAnked FineTuning} for Generative Foundation Model Alignment"
      },
      {
        "key": "emu",
        "author": "Dai, Xiaoliang and Hou, Ji and Ma, Chih-Yao and others",
        "title": "{Emu}: Enhancing image generation models using photogenic needles in a haystack"
      }
    ]
  },
  {
    "index": 2,
    "papers": [
      {
        "key": "ddpo",
        "author": "Black, Kevin and Janner, Michael and Du, Yilun and Kostrikov, Ilya and Levine, Sergey",
        "title": "Training diffusion models with reinforcement learning"
      },
      {
        "key": "DPOK",
        "author": "Fan, Ying and Watkins, Olivia and Du, Yuqing and others",
        "title": "{DPOK}: Reinforcement learning for fine-tuning text-to-image diffusion models"
      },
      {
        "key": "d3po",
        "author": "Yang, Kai and Tao, Jian and Lyu, Jiafei and others",
        "title": "Using Human Feedback to Fine-tune Diffusion Models without Any Reward Model"
      },
      {
        "key": "diffusion-dpo",
        "author": "Wallace, Bram and Dang, Meihua and Rafailov, Rafael and others",
        "title": "Diffusion Model Alignment Using Direct Preference Optimization"
      }
    ]
  },
  {
    "index": 3,
    "papers": [
      {
        "key": "ddpo",
        "author": "Black, Kevin and Janner, Michael and Du, Yilun and Kostrikov, Ilya and Levine, Sergey",
        "title": "Training diffusion models with reinforcement learning"
      }
    ]
  },
  {
    "index": 4,
    "papers": [
      {
        "key": "DPOK",
        "author": "Fan, Ying and Watkins, Olivia and Du, Yuqing and others",
        "title": "{DPOK}: Reinforcement learning for fine-tuning text-to-image diffusion models"
      }
    ]
  },
  {
    "index": 5,
    "papers": [
      {
        "key": "d3po",
        "author": "Yang, Kai and Tao, Jian and Lyu, Jiafei and others",
        "title": "Using Human Feedback to Fine-tune Diffusion Models without Any Reward Model"
      }
    ]
  },
  {
    "index": 6,
    "papers": [
      {
        "key": "diffusion-dpo",
        "author": "Wallace, Bram and Dang, Meihua and Rafailov, Rafael and others",
        "title": "Diffusion Model Alignment Using Direct Preference Optimization"
      }
    ]
  },
  {
    "index": 7,
    "papers": [
      {
        "key": "llm_dpo",
        "author": "Rafailov, Rafael and Sharma, Archit and Mitchell, Eric and Ermon, Stefano and Manning, Christopher D. and Finn, Chelsea",
        "title": "Direct preference optimization: your language model is secretly a reward model"
      }
    ]
  },
  {
    "index": 8,
    "papers": [
      {
        "key": "cg",
        "author": "Dhariwal, Prafulla and Nichol, Alex",
        "title": "Diffusion models beat {GANs} on image synthesis"
      }
    ]
  },
  {
    "index": 9,
    "papers": [
      {
        "key": "cfg",
        "author": "Ho, Jonathan and Salimans, Tim",
        "title": "Classifier-free diffusion guidance"
      }
    ]
  },
  {
    "index": 10,
    "papers": [
      {
        "key": "sag",
        "author": "Hong, Susung and Lee, Gyuseong and Jang, Wooseok and Kim, Seungryong ",
        "title": "Improving Sample Quality of Diffusion Models Using Self-Attention Guidance"
      },
      {
        "key": "uni_guide",
        "author": "Bansal, Arpit and Chu, Hong-Min and Schwarzschild, Avi and Sengupta, Soumyadip and Goldblum, Micah and Geiping, Jonas and Goldstein, Tom",
        "title": "Universal Guidance for Diffusion Models"
      },
      {
        "key": "readout",
        "author": " Luo, Grace and Darrell, Trevor and Wang, Oliver and Goldman, Dan B and Holynski, Aleksander ",
        "title": "{Readout Guidance}: Learning Control from Diffusion Features"
      },
      {
        "key": "glide",
        "author": "Nichol, Alex and Dhariwal, Prafulla and Ramesh, Aditya and others",
        "title": "{Glide}: Towards photorealistic image generation and editing with text-guided diffusion models"
      }
    ]
  }
]