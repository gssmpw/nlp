\section{Conclusion}
Our proposed framework, \ours, advances humanoid standing-up control by addressing the limitations of existing methods, which either neglect hardware constraints or rely on predefined motion trajectories. By leveraging reinforcement learning from scratch, \ours enables the learning of posture-adaptive standing-up motions across diverse terrains, ensuring effective sim-to-real transfer. The multi-critic architecture, along with smoothness regularization and implicit speed constraints, optimizes the controllers for real-world deployment. Experimental results with the Unitree G1 humanoid robot demonstrate smooth, stable, and robust standing-up motions in a variety of real-world scenarios. Looking forward, this work paves the way for integrating standing-up control into existing humanoid systems, with the potential of expanding their real-world applicability.

\section{Limitations and Future Directions}
While our method demonstrates strong real-world performance, we acknowledge several key limitations that should be addressed in the near future. 

\paragraphbegin{Perception of the environment.} Although proprioception alone is sufficient for many postures, some failures were observed during outdoor tests, such as standing from a seated position and colliding with surroundings. Integrating perceptual capabilities will help address this issue.

\paragraphbegin{More diverse postures.} We observe that training with both supine and prone postures has negatively impacted performance due to interference between sampled rollouts. Addressing this issue could further enhance capabilities like fall recovery and improve overall system generalization.

\paragraphbegin{Integration with existing humanoid systems.} Although integration with existing humanoid systems is not demonstrated in this paper, we envision that standing-up control can be effectively incorporated into current humanoid frameworks to extend real-world applications.
