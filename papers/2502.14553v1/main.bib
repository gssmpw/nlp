@inproceedings{langley00,
 author    = {P. Langley},
 title     = {Crafting Papers on Machine Learning},
 year      = {2000},
 pages     = {1207--1216},
 editor    = {Pat Langley},
 booktitle     = {Proceedings of the 17th International Conference
              on Machine Learning (ICML 2000)},
 address   = {Stanford, CA},
 publisher = {Morgan Kaufmann}
}

@TechReport{mitchell80,
  author = 	 "T. M. Mitchell",
  title = 	 "The Need for Biases in Learning Generalizations",
  institution =  "Computer Science Department, Rutgers University",
  year = 	 "1980",
  address =	 "New Brunswick, MA",
}


@phdthesis{kearns89,
  author = {M. J. Kearns},
  title =  {Computational Complexity of Machine Learning},
  school = {Department of Computer Science, Harvard University},
  year =   {1989}
}

@Book{MachineLearningI,
  editor = 	 "R. S. Michalski and J. G. Carbonell and T.
		  M. Mitchell",
  title = 	 "Machine Learning: An Artificial Intelligence
		  Approach, Vol. I",
  publisher = 	 "Tioga",
  year = 	 "1983",
  address =	 "Palo Alto, CA"
}

@Book{DudaHart2nd,
  author =       "R. O. Duda and P. E. Hart and D. G. Stork",
  title =        "Pattern Classification",
  publisher =    "John Wiley and Sons",
  edition =      "2nd",
  year =         "2000"
}

@misc{anonymous,
  title= {Suppressed for Anonymity},
  author= {Author, N. N.},
  year= {2021}
}

@InCollection{Newell81,
  author =       "A. Newell and P. S. Rosenbloom",
  title =        "Mechanisms of Skill Acquisition and the Law of
                  Practice", 
  booktitle =    "Cognitive Skills and Their Acquisition",
  pages =        "1--51",
  publisher =    "Lawrence Erlbaum Associates, Inc.",
  year =         "1981",
  editor =       "J. R. Anderson",
  chapter =      "1",
  address =      "Hillsdale, NJ"
}


@Article{Samuel59,
  author = 	 "A. L. Samuel",
  title = 	 "Some Studies in Machine Learning Using the Game of
		  Checkers",
  journal =	 "IBM Journal of Research and Development",
  year =	 "1959",
  volume =	 "3",
  number =	 "3",
  pages =	 "211--229"
}

% ------------ OUR SOURCES --------------

@article{mamba,
  title={Mamba: Linear-Time Sequence Modeling with Selective State Spaces},
  author={Gu, Albert and Dao, Tri},
  journal={arXiv preprint arXiv:2312.00752},
  year={2023}
}

@inproceedings{mamba2,
  title={Transformers are {SSM}s: Generalized Models and Efficient Algorithms Through Structured State Space Duality},
  author={Dao, Tri and Gu, Albert},
  booktitle={International Conference on Machine Learning (ICML)},
  year={2024}
}

@misc{dao2024transformersssmsgeneralizedmodels,
      title={Transformers are SSMs: Generalized Models and Efficient Algorithms Through Structured State Space Duality}, 
      author={Tri Dao and Albert Gu},
      year={2024},
      eprint={2405.21060},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2405.21060}, 
}
@inproceedings{
mambabyte,
title={MambaByte: Token-free Selective State Space Model},
author={Junxiong Wang and Tushaar Gangavarapu and Jing Nathan Yan and Alexander M Rush},
booktitle={First Conference on Language Modeling},
year={2024},
url={https://openreview.net/forum?id=X1xNsuKssb}
}
@inproceedings{megabyte,
 author = {Yu, Lili and Simig, Daniel and Flaherty, Colin and Aghajanyan, Armen and Zettlemoyer, Luke and Lewis, Mike},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {A. Oh and T. Naumann and A. Globerson and K. Saenko and M. Hardt and S. Levine},
 pages = {78808--78823},
 title = {MEGABYTE: Predicting Million-byte Sequences with Multiscale Transformers},
 volume = {36},
 year = {2023}
}

@inproceedings{
s4,
title={Efficiently Modeling Long Sequences with Structured State Spaces},
author={Albert Gu and Karan Goel and Christopher Re},
booktitle={International Conference on Learning Representations},
year={2022},
url={https://openreview.net/forum?id=uYLFoz1vlAC}
}
@ARTICLE{markovmodelsog,
  author={Rabiner, L.R.},
  journal={Proceedings of the IEEE}, 
  title={A tutorial on hidden Markov models and selected applications in speech recognition}, 
  year={1989},
  volume={77},
  number={2},
  pages={257-286},
  keywords={Tutorial;Hidden Markov models;Speech recognition},
  doi={10.1109/5.18626}}
@article{
hopfield,
author = {J J Hopfield },
title = {Neural networks and physical systems with emergent collective computational abilities.},
journal = {Proceedings of the National Academy of Sciences},
volume = {79},
number = {8},
pages = {2554-2558},
year = {1982},
doi = {10.1073/pnas.79.8.2554},
URL = {https://www.pnas.org/doi/abs/10.1073/pnas.79.8.2554},
eprint = {https://www.pnas.org/doi/pdf/10.1073/pnas.79.8.2554}}

@article{lstm,
author = {Hochreiter, Sepp and Schmidhuber, Jürgen},
year = {1997},
month = {12},
pages = {1735-80},
title = {Long Short-term Memory},
volume = {9},
journal = {Neural computation},
doi = {10.1162/neco.1997.9.8.1735}
}
@article{rnnreview,
    author = {Yu, Yong and Si, Xiaosheng and Hu, Changhua and Zhang, Jianxun},
    title = "{A Review of Recurrent Neural Networks: LSTM Cells and Network Architectures}",
    journal = {Neural Computation},
    volume = {31},
    number = {7},
    pages = {1235-1270},
    year = {2019},
    month = {07},
    issn = {0899-7667},
    doi = {10.1162/neco_a_01199},
    url = {https://doi.org/10.1162/neco\_a\_01199},
    eprint = {https://direct.mit.edu/neco/article-pdf/31/7/1235/1053200/neco\_a\_01199.pdf},
}
@article{Bengio1994LearningLD,
  title={Learning long-term dependencies with gradient descent is difficult},
  author={Yoshua Bengio and Patrice Y. Simard and Paolo Frasconi},
  journal={IEEE transactions on neural networks},
  year={1994},
  volume={5 2},
  pages={
          157-66
        },
  url={https://api.semanticscholar.org/CorpusID:206457500}
}
@misc{encoderdecoderlearningphase,
      title={Learning Phrase Representations using RNN Encoder-Decoder for Statistical Machine Translation}, 
      author={Kyunghyun Cho and Bart van Merrienboer and Caglar Gulcehre and Dzmitry Bahdanau and Fethi Bougares and Holger Schwenk and Yoshua Bengio},
      year={2014},
      eprint={1406.1078},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/1406.1078}, 
}
@inproceedings{seq2seq,
author = {Sutskever, Ilya and Vinyals, Oriol and Le, Quoc V.},
title = {Sequence to sequence learning with neural networks},
year = {2014},
publisher = {MIT Press},
address = {Cambridge, MA, USA},
booktitle = {Proceedings of the 27th International Conference on Neural Information Processing Systems - Volume 2},
pages = {3104–3112},
numpages = {9},
location = {Montreal, Canada},
series = {NIPS'14}
}

@inproceedings{koehn-etal-2003-statistical,
    title = "Statistical Phrase-Based Translation",
    author = "Koehn, Philipp  and
      Och, Franz J.  and
      Marcu, Daniel",
    booktitle = "Proceedings of the 2003 Human Language Technology Conference of the North {A}merican Chapter of the Association for Computational Linguistics",
    year = "2003",
    url = "https://aclanthology.org/N03-1017",
    pages = "127--133",
}
@inproceedings{attnisallyouneed,
 author = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, \L ukasz and Polosukhin, Illia},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {I. Guyon and U. Von Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {Attention is All you Need},
 url = {https://proceedings.neurips.cc/paper_files/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf},
 volume = {30},
 year = {2017}
}
@proceedings{bytelevellanguages,title	= {Byte-level Machine Reading across Morphologically Varied Languages},editor	= {Tom Kenter and Llion Jones and Daniel Hewlett},year	= {2018},URL	= {https://www.aaai.org/ocs/index.php/AAAI/AAAI18/paper/download/16605/16145},booktitle	= {Proceedings of the Thirty-Second AAAI Conference on Artificial Intelligence (AAAI-18)}}
@article{Bahdanau2014NeuralMT,
  title={Neural Machine Translation by Jointly Learning to Align and Translate},
  author={Dzmitry Bahdanau and Kyunghyun Cho and Yoshua Bengio},
  journal={CoRR},
  year={2014},
  volume={abs/1409.0473},
  url={https://api.semanticscholar.org/CorpusID:11212020}
}
@article{byt5tokenfree,
    title = "{B}y{T}5: Towards a Token-Free Future with Pre-trained Byte-to-Byte Models",
    author = "Xue, Linting  and
      Barua, Aditya  and
      Constant, Noah  and
      Al-Rfou, Rami  and
      Narang, Sharan  and
      Kale, Mihir  and
      Roberts, Adam  and
      Raffel, Colin",
    editor = "Roark, Brian  and
      Nenkova, Ani",
    journal = "Transactions of the Association for Computational Linguistics",
    volume = "10",
    year = "2022",
    address = "Cambridge, MA",
    publisher = "MIT Press",
    url = "https://aclanthology.org/2022.tacl-1.17/",
    doi = "10.1162/tacl_a_00461",
    pages = "291--306",
}

@article{clevr,
  title={CLEVR: A Diagnostic Dataset for Compositional Language and Elementary Visual Reasoning},
  author={Justin Johnson and Bharath Hariharan and Laurens van der Maaten and Li Fei-Fei and C. Lawrence Zitnick and Ross B. Girshick},
  journal={2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2016},
  pages={1988-1997},
  url={https://api.semanticscholar.org/CorpusID:15458100}
}
@article{pg19,
author = {Rae, Jack W and Potapenko, Anna and Jayakumar, Siddhant M and
          Hillier, Chloe and Lillicrap, Timothy P},
title = {Compressive Transformers for Long-Range Sequence Modelling},
journal = {arXiv preprint},
url = {https://arxiv.org/abs/1911.05507},
year = {2019},
}
@article{clark-etal-2022-canine,
    title = "Canine: Pre-training an Efficient Tokenization-Free Encoder for Language Representation",
    author = "Clark, Jonathan H.  and
      Garrette, Dan  and
      Turc, Iulia  and
      Wieting, John",
    editor = "Roark, Brian  and
      Nenkova, Ani",
    journal = "Transactions of the Association for Computational Linguistics",
    volume = "10",
    year = "2022",
    address = "Cambridge, MA",
    publisher = "MIT Press",
    url = "https://aclanthology.org/2022.tacl-1.5",
    doi = "10.1162/tacl_a_00448",
    pages = "73--91",
}
@inproceedings{
tay2022charformer,
title={Charformer: Fast Character Transformers via Gradient-based Subword Tokenization},
author={Yi Tay and Vinh Q. Tran and Sebastian Ruder and Jai Gupta and Hyung Won Chung and Dara Bahri and Zhen Qin and Simon Baumgartner and Cong Yu and Donald Metzler},
booktitle={International Conference on Learning Representations},
year={2022},
url={https://openreview.net/forum?id=JtBRnrlOEFN}
}
@article{baevski2020wav2vec,
  title={wav2vec 2.0: A framework for self-supervised learning of speech representations},
  author={Baevski, Alexei and Zhou, Yuhao and Mohamed, Abdelrahman and Auli, Michael},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={12449--12460},
  year={2020}
}
@article{alphafold,
  title={Highly accurate protein structure prediction with AlphaFold},
  author={Jumper, John and Evans, Richard and Pritzel, Alexander and Green, Tim and Figurnov, Michael and Ronneberger, Olaf and Tunyasuvunakool, Kathryn and Bates, Russ and {\v{Z}}{\'\i}dek, Augustin and Potapenko, Anna and others},
  journal={nature},
  volume={596},
  number={7873},
  pages={583--589},
  year={2021},
  publisher={Nature Publishing Group}
}
@inproceedings{lmsarefewshotlearners,
 author = {Brown, Tom and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared D and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and Agarwal, Sandhini and Herbert-Voss, Ariel and Krueger, Gretchen and Henighan, Tom and Child, Rewon and Ramesh, Aditya and Ziegler, Daniel and Wu, Jeffrey and Winter, Clemens and Hesse, Chris and Chen, Mark and Sigler, Eric and Litwin, Mateusz and Gray, Scott and Chess, Benjamin and Clark, Jack and Berner, Christopher and McCandlish, Sam and Radford, Alec and Sutskever, Ilya and Amodei, Dario},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {H. Larochelle and M. Ranzato and R. Hadsell and M.F. Balcan and H. Lin},
 pages = {1877--1901},
 publisher = {Curran Associates, Inc.},
 title = {Language Models are Few-Shot Learners},
 url = {https://proceedings.neurips.cc/paper_files/paper/2020/file/1457c0d6bfcb4967418bfb8ac142f64a-Paper.pdf},
 volume = {33},
 year = {2020}
}

@inproceedings{charlevellanguagemodeling,
author = {Al-Rfou, Rami and Choe, Dokook and Constant, Noah and Guo, Mandy and Jones, Llion},
title = {Character-level language modeling with deeper self-attention},
year = {2019},
isbn = {978-1-57735-809-1},
publisher = {AAAI Press},
url = {https://doi.org/10.1609/aaai.v33i01.33013159},
doi = {10.1609/aaai.v33i01.33013159},
booktitle = {Proceedings of the Thirty-Third AAAI Conference on Artificial Intelligence and Thirty-First Innovative Applications of Artificial Intelligence Conference and Ninth AAAI Symposium on Educational Advances in Artificial Intelligence},
articleno = {388},
numpages = {8},
location = {Honolulu, Hawaii, USA},
series = {AAAI'19/IAAI'19/EAAI'19}
}
@misc{bridginggaptokenizerfreelanguage,
      title={Bridging the Gap for Tokenizer-Free Language Models}, 
      author={Dokook Choe and Rami Al-Rfou and Mandy Guo and Heeyoung Lee and Noah Constant},
      year={2019},
      eprint={1908.10322},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/1908.10322}, 
}
@misc{tfreellm,
      title={T-FREE: Tokenizer-Free Generative LLMs via Sparse Representations for Memory-Efficient Embeddings}, 
      author={Björn Deiseroth and Manuel Brack and Patrick Schramowski and Kristian Kersting and Samuel Weinbach},
      year={2024},
      eprint={2406.19223},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2406.19223}, 
}
@inproceedings{bpe-sennrich-etal-2016-neural,
    title = "Neural Machine Translation of Rare Words with Subword Units",
    author = "Sennrich, Rico  and
      Haddow, Barry  and
      Birch, Alexandra",
    editor = "Erk, Katrin  and
      Smith, Noah A.",
    booktitle = "Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = aug,
    year = "2016",
    address = "Berlin, Germany",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/P16-1162",
    doi = "10.18653/v1/P16-1162",
    pages = "1715--1725",
}
@misc{tokenizationhistory,
      title={Between words and characters: A Brief History of Open-Vocabulary Modeling and Tokenization in NLP}, 
      author={Sabrina J. Mielke and Zaid Alyafeai and Elizabeth Salesky and Colin Raffel and Manan Dey and Matthias Gallé and Arun Raja and Chenglei Si and Wilson Y. Lee and Benoît Sagot and Samson Tan},
      year={2021},
      eprint={2112.10508},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2112.10508}, 
}
@book{Goodfellow-et-al-2016,
    title={Deep Learning},
    author={Ian Goodfellow and Yoshua Bengio and Aaron Courville},
    publisher={MIT Press},
    note={\url{http://www.deeplearningbook.org}},
    year={2016}
}
@inproceedings{gpt,
 author = {Brown, Tom and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared D and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and Agarwal, Sandhini and Herbert-Voss, Ariel and Krueger, Gretchen and Henighan, Tom and Child, Rewon and Ramesh, Aditya and Ziegler, Daniel and Wu, Jeffrey and Winter, Clemens and Hesse, Chris and Chen, Mark and Sigler, Eric and Litwin, Mateusz and Gray, Scott and Chess, Benjamin and Clark, Jack and Berner, Christopher and McCandlish, Sam and Radford, Alec and Sutskever, Ilya and Amodei, Dario},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {H. Larochelle and M. Ranzato and R. Hadsell and M.F. Balcan and H. Lin},
 pages = {1877--1901},
 publisher = {Curran Associates, Inc.},
 title = {Language Models are Few-Shot Learners},
 url = {https://proceedings.neurips.cc/paper_files/paper/2020/file/1457c0d6bfcb4967418bfb8ac142f64a-Paper.pdf},
 volume = {33},
 year = {2020}
}
@article{gage,
author = {Gage, Philip},
title = {A new algorithm for data compression},
year = {1994},
issue_date = {Feb. 1994},
publisher = {R \& D Publications, Inc.},
address = {USA},
volume = {12},
number = {2},
issn = {0898-9788},
journal = {C Users J.},
month = feb,
pages = {23–38},
numpages = {16}
}
@article{wordpiece,
  title={Japanese and Korean voice search},
  author={Mike Schuster and Kaisuke Nakajima},
  journal={2012 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  year={2012},
  pages={5149-5152},
  url={https://api.semanticscholar.org/CorpusID:22320655}
}
@inproceedings{unigram,
    title = "Subword Regularization: Improving Neural Network Translation Models with Multiple Subword Candidates",
    author = "Kudo, Taku",
    editor = "Gurevych, Iryna  and
      Miyao, Yusuke",
    booktitle = "Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = jul,
    year = "2018",
    address = "Melbourne, Australia",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/P18-1007",
    doi = "10.18653/v1/P18-1007",
    pages = "66--75",
}
@inproceedings{gentextwithrecnn,
author = {Sutskever, Ilya and Martens, James and Hinton, Geoffrey},
year = {2011},
month = {01},
pages = {1017-1024},
title = {Generating Text with Recurrent Neural Networks},
journal = {Proceedings of the 28th International Conference on Machine Learning (ICML-11)}
}
@inproceedings{gao-etal-2020-character-level,
    title = "Character-Level Translation with Self-attention",
    author = "Gao, Yingqiang  and
      Nikolov, Nikola I.  and
      Hu, Yuhuang  and
      Hahnloser, Richard H.R.",
    editor = "Jurafsky, Dan  and
      Chai, Joyce  and
      Schluter, Natalie  and
      Tetreault, Joel",
    booktitle = "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics",
    month = jul,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2020.acl-main.145",
    doi = "10.18653/v1/2020.acl-main.145",
    pages = "1591--1604",
}
@misc{digitalworldsimulators,
        title={Beyond Language Models: Byte Models are Digital World Simulators}, 
        author={Shangda Wu and Xu Tan and Zili Wang and Rui Wang and Xiaobing Li and Maosong Sun},
        year={2024},
        eprint={2402.19155},
        archivePrefix={arXiv},
        primaryClass={cs.LG}
  }
@inproceedings{gaido-genderbias,
    title = "How to Split: the Effect of Word Segmentation on Gender Bias in Speech Translation",
    author = "Gaido, Marco  and
      Savoldi, Beatrice  and
      Bentivogli, Luisa  and
      Negri, Matteo  and
      Turchi, Marco",
    editor = "Zong, Chengqing  and
      Xia, Fei  and
      Li, Wenjie  and
      Navigli, Roberto",
    booktitle = "Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021",
    month = aug,
    year = "2021",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.findings-acl.313",
    doi = "10.18653/v1/2021.findings-acl.313",
    pages = "3576--3589",
}
@article{Graves2013GeneratingSWbytes,
  title={Generating Sequences With Recurrent Neural Networks},
  author={Alex Graves},
  journal={ArXiv},
  year={2013},
  volume={abs/1308.0850},
  url={https://api.semanticscholar.org/CorpusID:1697424}
}
@article{lmsmultitasklearners,
  title={Language Models are Unsupervised Multitask Learners},
  author={Radford, Alec and Wu, Jeff and Child, Rewon and Luan, David and Amodei, Dario and Sutskever, Ilya},
  year={2019}
}
@misc{takase2024largevocabularysizeimproves,
      title={Large Vocabulary Size Improves Large Language Models}, 
      author={Sho Takase and Ryokan Ri and Shun Kiyono and Takuya Kato},
      year={2024},
      eprint={2406.16508},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2406.16508}, 
}
@inproceedings{bygpt5,
author = {Belouadi, Jonas and Eger, Steffen},
year = {2023},
month = {01},
pages = {7364-7381},
title = {ByGPT5: End-to-End Style-conditioned Poetry Generation with Token-free Language Models},
doi = {10.18653/v1/2023.acl-long.406}
}
@misc{bytelevelmultimodal,
      title={Compression via Pre-trained Transformers: A Study on Byte-Level Multimodal Data}, 
      author={David Heurtel-Depeiges and Anian Ruoss and Joel Veness and Tim Genewein},
      year={2024},
      eprint={2410.05078},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2410.05078}, 
}
@misc{tunesformer,
  title = {TunesFormer: Forming Irish Tunes with Control Codes by Bar Patching},
      author={Shangda Wu and Xiaobing Li and Feng Yu and Maosong Sun},
      year={2023},
      eprint={2301.02884},
      archivePrefix={arXiv},
      primaryClass={cs.SD}
}
@inproceedings{
bhirangi2024hierarchicalssm,
title={Hierarchical State Space Models for Continuous Sequence-to-Sequence Modeling},
author={Raunaq Bhirangi and Chenyu Wang and Venkatesh Pattabiraman and Carmel Majidi and Abhinav Gupta and Tess Hellebrekers and Lerrel Pinto},
booktitle={Forty-first International Conference on Machine Learning},
year={2024},
url={https://openreview.net/forum?id=TK7xkOsXDu}
}

@inproceedings{
marvininterleaving,
title={Interleaving Text and Number Embeddings to Solve Mathemathics Problems},
author={Marvin Alberts and Gianmarco Gabrieli and Irina Espejo Morales},
booktitle={The 4th Workshop on Mathematical Reasoning and AI at NeurIPS'24},
year={2024},
url={https://openreview.net/forum?id=8cNJyqs45T}
}
@article{perplexity,
    author = {Jelinek, F. and Mercer, R. L. and Bahl, L. R. and Baker, J. K.},
    title = "{Perplexity—a measure of the difficulty of speech recognition tasks}",
    journal = {The Journal of the Acoustical Society of America},
    volume = {62},
    number = {S1},
    pages = {S63-S63},
    year = {2005},
    month = {08},
    issn = {0001-4966},
    doi = {10.1121/1.2016299},
    url = {https://doi.org/10.1121/1.2016299},
    eprint = {https://pubs.aip.org/asa/jasa/article-pdf/62/S1/S63/11558910/s63\_5\_online.pdf},
}
@ARTICLE{shanonentropy,
  author={Shannon, C. E.},
  journal={The Bell System Technical Journal}, 
  title={A mathematical theory of communication}, 
  year={1948},
  volume={27},
  number={3},
  pages={379-423},
  keywords={},
  doi={10.1002/j.1538-7305.1948.tb01338.x}}

 @book{probmachinelearningbook,
 author = "Kevin P. Murphy",
 title = "Probabilistic Machine Learning: An introduction",
 publisher = "MIT Press",
 year = 2022,
 url = "probml.ai"
}
@article{pile,
  title={The {P}ile: An 800GB Dataset of Diverse Text for Language Modeling},
  author={Gao, Leo and Biderman, Stella and Black, Sid and Golding, Laurence and Hoppe, Travis and Foster, Charles and Phang, Jason and He, Horace and Thite, Anish and Nabeshima, Noa and Presser, Shawn and Leahy, Connor},
  journal={arXiv preprint arXiv:2101.00027},
  year={2020}
}
@article{scalinglanguagemodelsbpb,
  title={Scaling Language Models: Methods, Analysis \& Insights from Training Gopher},
  author={Jack W. Rae and Sebastian Borgeaud and Trevor Cai and Katie Millican and Jordan Hoffmann and Francis Song and John Aslanides and Sarah Henderson and Roman Ring and Susannah Young and Eliza Rutherford and Tom Hennigan and Jacob Menick and Albin Cassirer and Richard Powell and George van den Driessche and Lisa Anne Hendricks and Maribeth Rauh and Po-Sen Huang and others},
  journal={ArXiv},
  year={2021},
  volume={abs/2112.11446},
  url={https://api.semanticscholar.org/CorpusID:245353475}
}
@inproceedings{wang2021interpretable,
  title={Interpretable visual reasoning via induced symbolic space},
  author={Wang, Zhonghao and Wang, Kai and Yu, Mo and Xiong, Jinjun and Hwu, Wen-mei and Hasegawa-Johnson, Mark and Shi, Humphrey},
  booktitle={Proceedings of the IEEE/CVF international conference on computer vision},
  pages={1878--1887},
  year={2021}
}
@book{nlpwithtransformers,
  title={Natural Language Processing with Transformers: Building Language Applications with Hugging Face},
  author={Tunstall, Lewis and von Werra, Leandro and Wolf, Thomas},
  isbn={1098103246},
  url={https://books.google.ch/books?id=7hhyzgEACAAJ},
  year={2022},
  publisher={O'Reilly Media, Incorporated}
}
@article{efficienttransformers,
author={Tay, Yi and Dehghani, Mostafa and Bahri, Dara and Metzler, Donald},
title={Efficient Transformers: A Survey},
year={2022},
issue_date={June 2023},
publisher={Association for Computing Machinery},
address={New York, NY, USA},
volume={55},
number={6},
issn={0360-0300},
url={https://doi.org/10.1145/3530811},
doi={10.1145/3530811},
journal={ACM Comput. Surv.},
month=dec,
articleno={109},
numpages={28},
keywords={Transformers, attention, deep learning, neural networks}
}
@inproceedings{dao2022flashattention,
  title={Flash{A}ttention: Fast and Memory-Efficient Exact Attention with {IO}-Awareness},
  author={Dao, Tri and Fu, Daniel Y. and Ermon, Stefano and Rudra, Atri and R{\'e}, Christopher},
  booktitle={Advances in Neural Information Processing Systems (NeurIPS)},
  year={2022}
}
@inproceedings{dao2023flashattention2,
  title={Flash{A}ttention-2: Faster Attention with Better Parallelism and Work Partitioning},
  author={Dao, Tri},
  booktitle={International Conference on Learning Representations (ICLR)},
  year={2024}
}
@inproceedings{bert,
  title={BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding},
  author={Jacob Devlin and Ming-Wei Chang and Kenton Lee and Kristina Toutanova},
  booktitle={North American Chapter of the Association for Computational Linguistics},
  year={2019},
  url={https://api.semanticscholar.org/CorpusID:52967399}
}
@misc{roberta,
      title={RoBERTa: A Robustly Optimized BERT Pretraining Approach}, 
      author={Yinhan Liu and Myle Ott and Naman Goyal and Jingfei Du and Mandar Joshi and Danqi Chen and Omer Levy and Mike Lewis and Luke Zettlemoyer and Veselin Stoyanov},
      year={2019},
      eprint={1907.11692},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/1907.11692}, 
}
@misc{distilbert,
      title={DistilBERT, a distilled version of BERT: smaller, faster, cheaper and lighter}, 
      author={Victor Sanh and Lysandre Debut and Julien Chaumond and Thomas Wolf},
      year={2020},
      eprint={1910.01108},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/1910.01108}, 
}
@inproceedings{lewis-etal-2020-bart,
    title = "{BART}: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension",
    author = "Lewis, Mike  and
      Liu, Yinhan  and
      Goyal, Naman  and
      Ghazvininejad, Marjan  and
      Mohamed, Abdelrahman  and
      Levy, Omer  and
      Stoyanov, Veselin  and
      Zettlemoyer, Luke",
    booktitle = "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics",
    month = jul,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2020.acl-main.703",
    doi = "10.18653/v1/2020.acl-main.703",
    pages = "7871--7880",
}
@article{t5,
author = {Raffel, Colin and Shazeer, Noam and Roberts, Adam and Lee, Katherine and Narang, Sharan and Matena, Michael and Zhou, Yanqi and Li, Wei and Liu, Peter J.},
title = {Exploring the limits of transfer learning with a unified text-to-text transformer},
year = {2020},
issue_date = {January 2020},
publisher = {JMLR.org},
volume = {21},
number = {1},
issn = {1532-4435},
journal = {J. Mach. Learn. Res.},
month = jan,
articleno = {140},
numpages = {67},
keywords = {deep learning, attention based models, multi-task learning, natural language processing, transfer learning}
}
@article{Beltagy2020Longformer,
  title={Longformer: The Long-Document Transformer},
  author={Iz Beltagy and Matthew E. Peters and Arman Cohan},
  journal={arXiv:2004.05150},
  year={2020},
}
@misc{linformer,
      title={Linformer: Self-Attention with Linear Complexity}, 
      author={Sinong Wang and Belinda Z. Li and Madian Khabsa and Han Fang and Hao Ma},
      year={2020},
      eprint={2006.04768},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2006.04768}, 
}
@inproceedings{performers,
    title={Rethinking Attention with Performers},
    author={Krzysztof Marcin Choromanski and Valerii Likhosherstov and David Dohan and Xingyou Song and Andreea Gane and Tamas Sarlos and Peter Hawkins and Jared Quincy Davis and Afroz Mohiuddin and Lukasz Kaiser and David Benjamin Belanger and Lucy J Colwell and Adrian Weller},
    booktitle={International Conference on Learning Representations},
    year={2021},
    url={https://openreview.net/forum?id=Ua6zuk0WRH}
}
@inproceedings{lineartransformers,
    author = {Katharopoulos, Angelos and Vyas, Apoorv and Pappas, Nikolaos and Fleuret, Fran\c{c}ois},
    title = {Transformers are RNNs: fast autoregressive transformers with linear attention},
    year = {2020},
    publisher = {JMLR.org},
    booktitle = {Proceedings of the 37th International Conference on Machine Learning},
    articleno = {478},
    numpages = {10},
    series = {ICML'20}
}
@inproceedings{
ssmnodiscret,
title={Effectively Modeling Time Series with Simple Discrete State Spaces},
author={Michael Zhang and Khaled Kamal Saab and Michael Poli and Tri Dao and Karan Goel and Christopher Re},
booktitle={The Eleventh International Conference on Learning Representations },
year={2023},
url={https://openreview.net/forum?id=2EpjkjzdCAa}
}
@inproceedings{ssmstructure,
author = {Gu, Albert and Gupta, Ankit and Goel, Karan and R\'{e}, Christopher},
title = {On the parameterization and initialization of diagonal state space models},
year = {2024},
isbn = {9781713871088},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
booktitle = {Proceedings of the 36th International Conference on Neural Information Processing Systems},
articleno = {2607},
numpages = {13},
location = {New Orleans, LA, USA},
series = {NIPS '22}
}
@online{nvidiaparallelscan,
  author = {Mark Harris and Shubhabrata Sengupta and John D. Owens},
title = {Parallel Prefix Sum (Scan) with CUDA},
  year = 2024,
  url = {https://developer.nvidia.com/gpugems/gpugems3/part-vi-gpu-computing/chapter-39-parallel-prefix-sum-scan-cuda},
  urldate = {2024-11-25}
}
@inproceedings{
hungryhippo,
title={Hungry Hungry Hippos: Towards Language Modeling with State Space Models},
author={Daniel Y Fu and Tri Dao and Khaled Kamal Saab and Armin W Thomas and Atri Rudra and Christopher Re},
booktitle={The Eleventh International Conference on Learning Representations },
year={2023},
url={https://openreview.net/forum?id=COZDy0WYGg}
}
@online{ssmblogpt1,
  author = {Albert Gu and Tri Dao},
  title = {State Space Duality (Mamba-2) Part I - The Model},
  year = 2024,
  url = {https://tridao.me/blog/2024/mamba2-part1-model/},
  urldate = {2024-05-31}
}
@misc{megatrontensorparallelism,
      title={Megatron-LM: Training Multi-Billion Parameter Language Models Using Model Parallelism}, 
      author={Mohammad Shoeybi and Mostofa Patwary and Raul Puri and Patrick LeGresley and Jared Casper and Bryan Catanzaro},
      year={2020},
      eprint={1909.08053},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/1909.08053}, 
}
@inproceedings{seqparallelism,
 author = {Korthikanti, Vijay Anand and Casper, Jared and Lym, Sangkug and McAfee, Lawrence and Andersch, Michael and Shoeybi, Mohammad and Catanzaro, Bryan},
 booktitle = {Proceedings of Machine Learning and Systems},
 editor = {D. Song and M. Carbin and T. Chen},
 pages = {341--353},
 publisher = {Curan},
 title = {Reducing Activation Recomputation in Large Transformer Models},
 url = {https://proceedings.mlsys.org/paper_files/paper/2023/file/80083951326cf5b35e5100260d64ed81-Paper-mlsys2023.pdf},
 volume = {5},
 year = {2023}
}
@article{universalcomputeengines, title={Frozen Pretrained Transformers as Universal Computation Engines}, volume={36}, url={https://ojs.aaai.org/index.php/AAAI/article/view/20729}, DOI={10.1609/aaai.v36i7.20729}, number={7}, journal={Proceedings of the AAAI Conference on Artificial Intelligence}, author={Lu, Kevin and Grover, Aditya and Abbeel, Pieter and Mordatch, Igor}, year={2022}, month={Jun.}, pages={7628-7636} }

@article{nvidiaempiricalmambahybrid,
  publtype={informal},
  author={Roger Waleffe and Wonmin Byeon and Duncan Riach and Brandon Norick and Vijay Korthikanti and Tri Dao and Albert Gu and Ali Hatamizadeh and Sudhakar Singh and Deepak Narayanan and Garvit Kulshreshtha and Vartika Singh and Jared Casper and Jan Kautz and Mohammad Shoeybi and Bryan Catanzaro},
  title={An Empirical Study of Mamba-based Language Models},
  year={2024},
  cdate={1704067200000},
  journal={CoRR},
  volume={abs/2406.07887},
  url={https://doi.org/10.48550/arXiv.2406.07887}
}

@misc{ssmjamba,
      title={Jamba: A Hybrid Transformer-Mamba Language Model}, 
      author={Opher Lieber and Barak Lenz and Hofit Bata and Gal Cohen and Jhonathan Osin and Itay Dalmedigos and Erez Safahi and Shaked Meirom and Yonatan Belinkov and Shai Shalev-Shwartz and Omri Abend and Raz Alon and Tomer Asida and Amir Bergman and Roman Glozman and Michael Gokhman and Avashalom Manevich and Nir Ratner and Noam Rozen and Erez Shwartz and Mor Zusman and Yoav Shoham},
      year={2024},
      eprint={2403.19887},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2403.19887}, 
}

@misc{glorioso2024zambassm,
    title={Zamba: A Compact 7B SSM Hybrid Model}, 
    author={Paolo Glorioso and Quentin Anthony and Yury Tokpanov and James Whittington and Jonathan Pilault and Adam Ibrahim and Beren Millidge},
    year={2024},
    eprint={2405.16712},
    archivePrefix={arXiv},
    primaryClass={cs.LG}
}
@inproceedings{
anthony2024blackmamba,
title={BlackMamba: Mixture of Experts for State-Space Models},
author={Quentin Gregory Anthony and Yury Tokpanov and Paolo Glorioso and Beren Millidge},
booktitle={ICLR 2024 Workshop on Mathematical and Empirical Understanding of Foundation Models},
year={2024},
url={https://openreview.net/forum?id=10dsmPgq9L}
}
@inproceedings{
visiontransformer,
title={An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale},
author={Alexey Dosovitskiy and Lucas Beyer and Alexander Kolesnikov and Dirk Weissenborn and Xiaohua Zhai and Thomas Unterthiner and Mostafa Dehghani and Matthias Minderer and Georg Heigold and Sylvain Gelly and Jakob Uszkoreit and Neil Houlsby},
booktitle={International Conference on Learning Representations},
year={2021},
url={https://openreview.net/forum?id=YicbFdNTTy}
}
@inproceedings{li2019bytes,
  title={Bytes are all you need: End-to-end multilingual speech recognition and synthesis with bytes},
  author={Li, Bo and Zhang, Yu and Sainath, Tara and Wu, Yonghui and Chan, William},
  booktitle={ICASSP 2019-2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  pages={5621--5625},
  year={2019},
  organization={IEEE}
}
@article{
hortonbytesareallyouneed,
title={Bytes Are All You Need: Transformers Operating Directly On File Bytes},
author={Maxwell Horton and Sachin Mehta and Ali Farhadi and Mohammad Rastegari},
journal={Transactions on Machine Learning Research},
issn={2835-8856},
year={2024},
url={https://openreview.net/forum?id=RkaqxxAOfN},
note={}
}

@misc{scalinglawsneuralmodels,
      title={Scaling Laws for Neural Language Models}, 
      author={Jared Kaplan and Sam McCandlish and Tom Henighan and Tom B. Brown and Benjamin Chess and Rewon Child and Scott Gray and Alec Radford and Jeffrey Wu and Dario Amodei},
      year={2020},
      eprint={2001.08361},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2001.08361}, 
}
@inproceedings{perceiverar,
author       = {Curtis Hawthorne and
                  Andrew Jaegle and
                  Catalina Cangea and
                  Sebastian Borgeaud and
                  Charlie Nash and
                  Mateusz Malinowski and
                  Sander Dieleman and
                  Oriol Vinyals and
                  Matthew M. Botvinick and
                  Ian Simon and
                  Hannah Sheahan and
                  Neil Zeghidour and
                  Jean{-}Baptiste Alayrac and
                  Jo{\~{a}}o Carreira and
                  Jesse H. Engel},
  editor       = {Kamalika Chaudhuri and
                  Stefanie Jegelka and
                  Le Song and
                  Csaba Szepesv{\'{a}}ri and
                  Gang Niu and
                  Sivan Sabato},
  title        = {General-purpose, long-context autoregressive modeling with Perceiver
                  {AR}},
  booktitle    = {International Conference on Machine Learning, {ICML} 2022, 17-23 July
                  2022, Baltimore, Maryland, {USA}},
  series       = {Proceedings of Machine Learning Research},
  volume       = {162},
  pages        = {8535--8558},
  publisher    = {{PMLR}},
  year         = {2022},
  url          = {https://proceedings.mlr.press/v162/hawthorne22a.html},
  timestamp    = {Mon, 13 May 2024 20:38:12 +0200},
  biburl       = {https://dblp.org/rec/conf/icml/HawthorneJCBNMD22.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}
@misc{pagnoni2024bytelatenttransformerpatches,
      title={Byte Latent Transformer: Patches Scale Better Than Tokens}, 
      author={Artidoro Pagnoni and Ram Pasunuru and Pedro Rodriguez and John Nguyen and Benjamin Muller and Margaret Li and Chunting Zhou and Lili Yu and Jason Weston and Luke Zettlemoyer and Gargi Ghosh and Mike Lewis and Ari Holtzman and Srinivasan Iyer},
      year={2024},
      eprint={2412.09871},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2412.09871}, 
}

@InProceedings{hyenahierarchy,
  title = 	 {Hyena Hierarchy: Towards Larger Convolutional Language Models},
  author =       {Poli, Michael and Massaroli, Stefano and Nguyen, Eric and Fu, Daniel Y and Dao, Tri and Baccus, Stephen and Bengio, Yoshua and Ermon, Stefano and Re, Christopher},
  booktitle = 	 {Proceedings of the 40th International Conference on Machine Learning},
  pages = 	 {28043--28078},
  year = 	 {2023},
  editor = 	 {Krause, Andreas and Brunskill, Emma and Cho, Kyunghyun and Engelhardt, Barbara and Sabato, Sivan and Scarlett, Jonathan},
  volume = 	 {202},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {23--29 Jul},
  publisher =    {PMLR},
  pdf = 	 {https://proceedings.mlr.press/v202/poli23a/poli23a.pdf},
  url = 	 {https://proceedings.mlr.press/v202/poli23a.html},
}


@article{selfattncomplexity,
    title = "On The Computational Complexity of Self-Attention",
    author = "Keles, {Feyza Duman} and Wijewardena, {Pruthuvi Mahesakya} and Chinmay Hegde",
    year = "2023",
    language = "English (US)",
    volume = "201",
    pages = "597--619",
    journal = "Proceedings of Machine Learning Research",
    issn = "2640-3498",
    publisher = "ML Research Press",
}
@inproceedings{yi2018neural,
  title={Neural-symbolic vqa: Disentangling reasoning from vision and language understanding},
  author={Yi, Kexin and Wu, Jiajun and Gan, Chuang and Torralba, Antonio and Kohli, Pushmeet and Tenenbaum, Joshua B.},
  booktitle={Advances in Neural Information Processing Systems},
  pages={1039--1050},
  year={2018}
}

@InProceedings{llmarchitecture,
  title = 	 {What Language Model Architecture and Pretraining Objective Works Best for Zero-Shot Generalization?},
  author =       {Wang, Thomas and Roberts, Adam and Hesslow, Daniel and Scao, Teven Le and Chung, Hyung Won and Beltagy, Iz and Launay, Julien and Raffel, Colin},
  booktitle = 	 {Proceedings of the 39th International Conference on Machine Learning},
  pages = 	 {22964--22984},
  year = 	 {2022},
  editor = 	 {Chaudhuri, Kamalika and Jegelka, Stefanie and Song, Le and Szepesvari, Csaba and Niu, Gang and Sabato, Sivan},
  volume = 	 {162},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {17--23 Jul},
  publisher =    {PMLR},
  pdf = 	 {https://proceedings.mlr.press/v162/wang22u/wang22u.pdf},
  url = 	 {https://proceedings.mlr.press/v162/wang22u.html},
}

@article{autoassociative,
author = {Kramer, Mark A.},
title = {Nonlinear principal component analysis using autoassociative neural networks},
journal = {AIChE Journal},
volume = {37},
number = {2},
pages = {233-243},
doi = {https://doi.org/10.1002/aic.690370209},
url = {https://aiche.onlinelibrary.wiley.com/doi/abs/10.1002/aic.690370209},
eprint = {https://aiche.onlinelibrary.wiley.com/doi/pdf/10.1002/aic.690370209},
year = {1991}
}

@inproceedings{
jaegle2022perceiverio,
title={Perceiver {IO}: A General Architecture for Structured Inputs \& Outputs},
author={Andrew Jaegle and Sebastian Borgeaud and Jean-Baptiste Alayrac and Carl Doersch and Catalin Ionescu and David Ding and Skanda Koppula and Daniel Zoran and Andrew Brock and Evan Shelhamer and Olivier J Henaff and Matthew Botvinick and Andrew Zisserman and Oriol Vinyals and Joao Carreira},
booktitle={International Conference on Learning Representations},
year={2022},
url={https://openreview.net/forum?id=fILj7WpI-g}
}

@InProceedings{perceiver,
  title = 	 {Perceiver: General Perception with Iterative Attention},
  author =       {Jaegle, Andrew and Gimeno, Felix and Brock, Andy and Vinyals, Oriol and Zisserman, Andrew and Carreira, Joao},
  booktitle = 	 {Proceedings of the 38th International Conference on Machine Learning},
  pages = 	 {4651--4664},
  year = 	 {2021},
  editor = 	 {Meila, Marina and Zhang, Tong},
  volume = 	 {139},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {18--24 Jul},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v139/jaegle21a/jaegle21a.pdf},
  url = 	 {https://proceedings.mlr.press/v139/jaegle21a.html},
}

@Techreport{cifar10,
 author = {Krizhevsky, Alex and Hinton, Geoffrey},
 address = {Toronto, Ontario},
 institution = {University of Toronto},
 number = {0},
 publisher = {Technical report, University of Toronto},
 title = {Learning multiple layers of features from tiny images},
 year = {2009},
 title_with_no_special_chars = {Learning multiple layers of features from tiny images},
 url = {https://www.cs.toronto.edu/~kriz/learning-features-2009-TR.pdf}
}
@misc{modernbert,
      title={Smarter, Better, Faster, Longer: A Modern Bidirectional Encoder for Fast, Memory Efficient, and Long Context Finetuning and Inference}, 
      author={Benjamin Warner and Antoine Chaffin and Benjamin Clavié and Orion Weller and Oskar Hallström and Said Taghadouini and Alexis Gallagher and Raja Biswas and Faisal Ladhak and Tom Aarsen and Nathan Cooper and Griffin Adams and Jeremy Howard and Iacopo Poli},
      year={2024},
      eprint={2412.13663},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2412.13663}, 
}
@inbook{unifiedlanguagemodel,
author = {Dong, Li and Yang, Nan and Wang, Wenhui and Wei, Furu and Liu, Xiaodong and Wang, Yu and Gao, Jianfeng and Zhou, Ming and Hon, Hsiao-Wuen},
title = {Unified language model pre-training for natural language understanding and generation},
year = {2019},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
booktitle = {Proceedings of the 33rd International Conference on Neural Information Processing Systems},
articleno = {1170},
numpages = {13}
}
@article{roformer,
author = {Su, Jianlin and Ahmed, Murtadha and Lu, Yu and Pan, Shengfeng and Bo, Wen and Liu, Yunfeng},
title = {RoFormer: Enhanced transformer with Rotary Position Embedding},
year = {2024},
issue_date = {Feb 2024},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {568},
number = {C},
issn = {0925-2312},
url = {https://doi.org/10.1016/j.neucom.2023.127063},
doi = {10.1016/j.neucom.2023.127063},
journal = {Neurocomput.},
month = mar,
numpages = {12},
keywords = {Pre-trained language models, Position information encoding, Pre-training, Natural language processing}
}
@inproceedings{translengthextra,
    title = "Length Extrapolation of Transformers: A Survey from the Perspective of Positional Encoding",
    author = "Zhao, Liang  and
      Feng, Xiachong  and
      Feng, Xiaocheng  and
      Zhong, Weihong  and
      Xu, Dongliang  and
      Yang, Qing  and
      Liu, Hongtao  and
      Qin, Bing  and
      Liu, Ting",
    editor = "Al-Onaizan, Yaser  and
      Bansal, Mohit  and
      Chen, Yun-Nung",
    booktitle = "Findings of the Association for Computational Linguistics: EMNLP 2024",
    month = nov,
    year = "2024",
    address = "Miami, Florida, USA",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2024.findings-emnlp.582/",
    doi = "10.18653/v1/2024.findings-emnlp.582",
    pages = "9959--9977",
}
@misc{mambaextrapolation,
      title={DeciMamba: Exploring the Length Extrapolation Potential of Mamba}, 
      author={Assaf Ben-Kish and Itamar Zimerman and Shady Abu-Hussein and Nadav Cohen and Amir Globerson and Lior Wolf and Raja Giryes},
      year={2024},
      eprint={2406.14528},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      note={under review},
      url={https://arxiv.org/abs/2406.14528}, 
}
@misc{li2024longcontext,
      title={Long-context LLMs Struggle with Long In-context Learning}, 
      author={Tianle Li and Ge Zhang and Quy Duc Do and Xiang Yue and Wenhu Chen},
      year={2024},
      eprint={2404.02060},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}
@inproceedings{bai2024longbench,
    title = "{L}ong{B}ench: A Bilingual, Multitask Benchmark for Long Context Understanding",
    author = "Bai, Yushi and Lv, Xin  and Zhang, Jiajie  and Lyu, Hongchang  and
      Tang, Jiankai  and Huang, Zhidian  and Du, Zhengxiao  and Liu, Xiao  and Zeng, Aohan  and Hou, Lei  and Dong, Yuxiao  and Tang, Jie  and Li, Juanzi",
    booktitle = "Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = aug,
    year = "2024",
    address = "Bangkok, Thailand",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2024.acl-long.172",
    doi = "10.18653/v1/2024.acl-long.172",
    pages = "3119--3137",
}
@inproceedings{tay2021longarena,
title={Long Range Arena : A Benchmark for Efficient Transformers },
author={Yi Tay and Mostafa Dehghani and Samira Abnar and Yikang Shen and Dara Bahri and Philip Pham and Jinfeng Rao and Liu Yang and Sebastian Ruder and Donald Metzler},
booktitle={International Conference on Learning Representations},
year={2021},
url={https://openreview.net/forum?id=qVyeW-grC2k}
}
@inproceedings{lin-2004-rouge,
    title = "{ROUGE}: A Package for Automatic Evaluation of Summaries",
    author = "Lin, Chin-Yew",
    booktitle = "Text Summarization Branches Out",
    month = jul,
    year = "2004",
    address = "Barcelona, Spain",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/W04-1013/",
    pages = "74--81"
}
@inproceedings{multimodalreason,
author = {Lu, Pan and Mishra, Swaroop and Xia, Tony and Qiu, Liang and Chang, Kai-Wei and Zhu, Song-Chun and Tafjord, Oyvind and Clark, Peter and Kalyan, Ashwin},
title = {Learn to explain: multimodal reasoning via thought chains for science question answering},
year = {2024},
isbn = {9781713871088},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
booktitle = {Proceedings of the 36th International Conference on Neural Information Processing Systems},
articleno = {182},
numpages = {15},
location = {New Orleans, LA, USA},
series = {NIPS '22}
}
@inproceedings{kudo-richardson-2018-sentencepiece,
    title = "{S}entence{P}iece: A simple and language independent subword tokenizer and detokenizer for Neural Text Processing",
    author = "Kudo, Taku  and
      Richardson, John",
    editor = "Blanco, Eduardo  and
      Lu, Wei",
    booktitle = "Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing: System Demonstrations",
    month = nov,
    year = "2018",
    address = "Brussels, Belgium",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/D18-2012/",
    doi = "10.18653/v1/D18-2012",
    pages = "66--71",
}
@online{karpathy,
  author = {Karpathy, Andrej},
  title = {Let's build the GPT Tokenizer},
  year = 2024,
  url = {https://www.youtube.com/watch?v=zduSFxRajkE&t=1367s},
  urldate = {2025-01-11}
}
@inproceedings{gettingthemostofyourtokenizer,
author = {Dagan, Gautier and Synnaeve, Gabriel and Rozi\`{e}re, Baptiste},
title = {Getting the most out of your tokenizer for pre-training and domain adaptation},
year = {2025},
publisher = {JMLR.org},
booktitle = {Proceedings of the 41st International Conference on Machine Learning},
articleno = {387},
numpages = {22},
location = {Vienna, Austria},
series = {ICML'24}
}
@inproceedings{
slagle2024spacebyte,
title={SpaceByte: Towards Deleting Tokenization from Large Language Modeling},
author={Kevin Slagle},
booktitle={The Thirty-eighth Annual Conference on Neural Information Processing Systems},
year={2024},
url={https://openreview.net/forum?id=KEe4IUp20I}
}
@misc{touvron2023llama2openfoundation,
      title={Llama 2: Open Foundation and Fine-Tuned Chat Models}, 
      author={Hugo Touvron and Louis Martin and Kevin Stone and Peter Albert and Amjad Almahairi and Yasmine Babaei and Nikolay Bashlykov and Soumya Batra and Prajjwal Bhargava and Shruti Bhosale and Dan Bikel and others},
      year={2023},
      eprint={2307.09288},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2307.09288}, 
}
@misc{chen2023extendingcontextwindowlarge,
      title={Extending Context Window of Large Language Models via Positional Interpolation}, 
      author={Shouyuan Chen and Sherman Wong and Liangjian Chen and Yuandong Tian},
      year={2023},
      eprint={2306.15595},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2306.15595}, 
}
@inproceedings{
liu2024scaling,
title={Scaling Laws of Ro{PE}-based Extrapolation},
author={Xiaoran Liu and Hang Yan and Chenxin An and Xipeng Qiu and Dahua Lin},
booktitle={The Twelfth International Conference on Learning Representations},
year={2024},
url={https://openreview.net/forum?id=JO7k0SJ5V6}
}
@inproceedings{transformersmalldata,
    title = "Optimizing Deeper Transformers on Small Datasets",
    author = "Xu, Peng  and
      Kumar, Dhruv  and
      Yang, Wei  and
      Zi, Wenjie  and
      Tang, Keyi  and
      Huang, Chenyang  and
      Cheung, Jackie Chi Kit  and
      Prince, Simon J.D.  and
      Cao, Yanshuai",
    editor = "Zong, Chengqing  and
      Xia, Fei  and
      Li, Wenjie  and
      Navigli, Roberto",
    booktitle = "Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)",
    month = aug,
    year = "2021",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.acl-long.163/",
    doi = "10.18653/v1/2021.acl-long.163",
    pages = "2089--2102",
}
@misc{grattafiori2024llama3herdmodels,
      title={The Llama 3 Herd of Models}, 
      author={Aaron Grattafiori and Abhimanyu Dubey and Abhinav Jauhri and Abhinav Pandey and Abhishek Kadian and Ahmad Al-Dahle and Aiesha Letman and Akhil Mathur and Alan Schelten and Alex Vaughan and Amy Yang and Angela Fan and Anirudh Goyal and Anthony Hartshorn and Aobo Yang and Archi Mitra and Archie Sravankumar and Artem Korenev and Arthur Hinsvark and Arun Rao and Aston Zhang and Aurelien Rodriguez and others},
      year={2024},
      eprint={2407.21783},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2407.21783}, 
}
@article{bytelevelmachinetrans, title={Neural Machine Translation with Byte-Level Subwords}, volume={34}, url={https://ojs.aaai.org/index.php/AAAI/article/view/6451}, DOI={10.1609/aaai.v34i05.6451}, number={05}, journal={Proceedings of the AAAI Conference on Artificial Intelligence}, author={Wang, Changhan and Cho, Kyunghyun and Gu, Jiatao}, year={2020}, month={Apr.}, pages={9154-9160} }

@inproceedings{ott-etal-2019-fairseq,
    title = "fairseq: A Fast, Extensible Toolkit for Sequence Modeling",
    author = "Ott, Myle  and
      Edunov, Sergey  and
      Baevski, Alexei  and
      Fan, Angela  and
      Gross, Sam  and
      Ng, Nathan  and
      Grangier, David  and
      Auli, Michael",
    editor = "Ammar, Waleed  and
      Louis, Annie  and
      Mostafazadeh, Nasrin",
    booktitle = "Proceedings of the 2019 Conference of the North {A}merican Chapter of the Association for Computational Linguistics (Demonstrations)",
    month = jun,
    year = "2019",
    address = "Minneapolis, Minnesota",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/N19-4009/",
    doi = "10.18653/v1/N19-4009",
    pages = "48--53",
    abstract = "fairseq is an open-source sequence modeling toolkit that allows researchers and developers to train custom models for translation, summarization, language modeling, and other text generation tasks. The toolkit is based on PyTorch and supports distributed training across multiple GPUs and machines. We also support fast mixed-precision training and inference on modern GPUs. A demo video can be found at \url{https://www.youtube.com/watch?v=OtgDdWtHvto}"
}
