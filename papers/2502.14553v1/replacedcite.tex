\section{Related work}
The MBLM builds upon the design principles of MegaByte ____, a causal byte language model featuring a hierarchical architecture of two Transformer decoders, enabling subquadratic self-attention and context windows up to 1.2M bytes. MegaByte processes patch representations of the input sequence with a global decoder, refines these representations, and feeds them into a local model that autoregressively predicts individual bytes. Incorporating the Mamba architecture ____ at the byte level, MambaByte ____ demonstrated superior performance over MegaByte in a FLOP-controlled setting across various datasets. As an alternative to the fixed-size patching used in MegaByte, ____ proposed the Byte Latent Transformer (BLT), which dynamically segments bytes into patches based on the entropy of the next byte. 
BLT demonstrated that byte language models can be efficiently scaled, achieving performance comparable to a subword-based LLama 3 model ____ at the 8B parameter scale.\\
However, none of these approaches have demonstrated the capability to handle multimodal inputs, which is arguably the most inherent strength of byte-level models. As shown by ____ with bGPT, extending pre-training to include binary data from mixed modalities facilitates effective cross-modality knowledge transfer. This reinforces the hypothesis that byte-level models uniquely capture features and patterns in ubiquitous bytestreams, irrespective of the original data format. Nevertheless, limited focus has been placed on architectures capable of translating multimodal inputs into multimodal outputs. Perceiver IO ____ addresses this by mapping inputs of arbitrary size into a latent space using a latent array that encodes the semantics of the input. The latent representation is iteratively refined through a series of attention modules and subsequently decoded into outputs of arbitrary shape via an output query array. Due to the encoder and decoder attention modules scaling linearly with the input and output size, and most of the computation occurring in the latent attention modules, Perceiver IO can efficiently handle extremely large input and output dimensions.
Yet, PerceiverIO explores bytes only to represent text and thus, to date, we still lack applications of BLMs on multimodal tasks like visual Q\&A.