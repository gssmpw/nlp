\begin{table}[h!]
\caption{\textbf{Evaluation on Vision Understanding Benchmarks.} The best two values are shown in \textbf{\textcolor{black}{bold}} and \underline{underlined}. The blue row refers to the main competitors. In MMMU benchmark, * indicates that the measurement is developed over the validation set. We can observe that \model~shows performance comparable to the leading open-source models and advanced closed-source counterparts.}
    \label{fig:image}
\renewcommand\arraystretch{1.2}
\resizebox{\textwidth}{!}{
\begin{tabular}{llcccccccc}
\toprule
\textbf{Model} & \textbf{LLM-size}   & \textbf{Video-MME}  & \textbf{MMMU} & \textbf{MathV}   & \textbf{Hal} & \textbf{AI2D} & \textbf{OCR} & \textbf{MMVet} & \textbf{MME}\\ \hline
\multicolumn{10}{c}{{\cellcolor[rgb]{0.957,0.957,0.957}} \textbf{\textit{Vision-Language Models}}} \\
VILA-1.5 & Vicuna-v1.5-13B &  44.2 & 41.1 & 42.5 & 39.3 & 69.9 & 460.0 & 45.0 & 1718.2\\
LLaVA-Next & Yi-34B  & 51.6 & 48.8 & 40.4 & 34.8 & 78.9 & 574.0 & 50.7 & 2006.5 \\
CogVLM2 & Llama3-Instruct-8B & 50.5 & 42.6 & 38.6 & 41.3 & 73.4 & 757.0 & 57.8 & 1869.5 \\
InternLM-Xcomposer2 & InternLM2-7B  & 56.2 & 41.4 & 59.5 & 41.0 & 81.2 & 532.0 & 46.7 & 2220.4 \\
Cambrian & NousHermes2-Yi-34B  & 54.2 & 50.4 & 50.3 & 41.6 & 79.5 & 591.0 & 53.2 & 2049.9 \\
InternVL-Chat-1.5 & InternLM2-20B  & 57.1 & 46.8 & 54.7 & 47.4 & 80.6 & 720.0 & 55.4 & 2189.6 \\
Ovis1.5 & Gemma2-It-9B  & 58.1 & 49.7 & 65.6 & 48.2 & \textbf{84.5} & 752.0 & 53.8 & 2125.2 \\
InternVL2 & InternLM2.5-7B  & \underline{61.5} & 51.2 & 58.3 & 45.0 & \underline{83.6} & 794.0 & 54.3 & 2215.1 \\
\rowcolor{blue!8}{MiniCPM-V 2.6} & Qwen2-7B  & 57.5 & 49.8 & 60.6 & 48.1 & 82.1 & 852.0 & 60.0 & 2268.7 \\
\rowcolor{blue!8}Qwen2.5-VL & Qwen2.5-7B  & 56.0 & 51.8* & 61.1 & \textbf{71.7} & 80.7 & \underline{877.0} & - & 2299.1 \\
\hline
\multicolumn{10}{c}{{\cellcolor[rgb]{0.957,0.957,0.957}} \textbf{\textit{Omni-modal Models}}} \\
\rowcolor{blue!8}{VITA-1.5-Audio} & Qwen2-7B  & - & 52.1 & \textbf{66.2} & 44.9 & 79.3 & 732.0 & 49.6 & \textbf{2352.0} \\
EMova-8B & LLaMA-3.1-8B & - & - & 61.1 & -& 82.8 & 824.0 & 55.8 & 2205.0 \\
Baichuan-Omni-1.5 & - & 58.2 & 47.3 & 51.9 & 47.8 & - & - & 65.4 & 2186.9 \\
Megrez-3B-Omni & Megrez-3B  & - & 51.8 & 62.0 & 50.1 & 82.0 & - & - & 2315.0 \\
\hline
\multicolumn{10}{c}{{\cellcolor[rgb]{0.957,0.957,0.957}} \textbf{\textit{Proprietary}}} \\
GPT-4V & -  & 50.4 & 59.3 & 48.2 & 39.3 & 71.4 & 678.0 & 49.0 & 1790.3 \\
GPT-4o mini  & - & 54.8 & 60.0 & 52.4 & 46.1 & 77.8 & 785.0 & \textbf{66.9} & 2003.4 \\
Gemini 1.5 Pro & 200B  & 59.1 & 60.6 & 57.7 & 45.6 & 79.1 & 754.0 & 64.0 & 2110.6\\
GPT-4o  & - & 61.6 & \underline{62.8} & 56.5 & 51.7 & 77.4 & 663.0 & \underline{66.5} & \underline{2328.7}\\
Claude3.5 Sonnet & 175B  & \textbf{62.2} & \textbf{65.9} & 61.6 & 49.9 & 80.2 & 788.0 & 66.0 & 1920.0 \\ \hline \rowcolor[gray]{0.9}
\multicolumn{10}{c}{{\cellcolor[rgb]{0.957,0.957,0.957}} \textbf{\textit{Our Model}}} \\
\rowcolor{blue!8}{\model} & Qwen2.5-VL-7B  & 57.0 & 53.2* & \underline{62.1} & \underline{71.1} & 81.2 & \textbf{882.0} & - & 2315.5 \\ \bottomrule
\end{tabular}
}
\end{table}


% \begin{table}
% \caption{\textbf{Evaluation on Vision Understanding Benchmarks.} \model-Instruct shows performance comparable to the leading open-source models and advanced closed-source counterparts. Hal refers to HallusionBench, MathV to MathVista, and OCR to OCRBench.}
%     \label{fig:image}
% \resizebox{\textwidth}{!}{%
% \renewcommand\arraystretch{1.2}
% \begin{tabular}{cccccccccccc}
% \toprule
% \textbf{Method} & \textbf{LLM} & \textbf{DocVQA-val}  & \textbf{Video-MME}  & \textbf{MMMU} & \textbf{MathV}   & \textbf{Hal} & \textbf{AI2D} & \textbf{OCR} & \textbf{MMVet} & \textbf{MME} & \textbf{Avg}\\ \hline
% \multicolumn{12}{c}{{\cellcolor[rgb]{0.957,0.957,0.957}} \textbf{\textit{Vision-Language Models}}} \\
% VILA-1.5 & Vicuna-v1.5-13B & - & 44.2 & 41.1 & 42.5 & 39.3 & 69.9 & 460.0 & 45.0 & 1718.2 & 52.1  \\
% LLaVA-Next & Yi-34b & - & 51.6 & 48.8 & 40.4 & 34.8 & 78.9 & 574.0 & 50.7 & 2006.5 & 58.3 \\
% CogVLM2 & Llama3-8B-Instruct & - & 50.5 & 42.6 & 38.6 & 41.3 & 73.4 & 757.0 & 57.8 & 1869.5 & 58.8 \\
% InternLM-Xcomposer2 & InternLM2-7B & - & 56.2 & 41.4 & 59.5 & 41.0 & 81.2 & 532.0 & 46.7 & 2220.4 & 61.2 \\
% Cambrian & Nous-Hermes-2-Yi-34B & - & 54.2 & 50.4 & 50.3 & 41.6 & 79.5 & 591.0 & 53.2 & 2049.9 & 61.4 \\
% InternVL-Chat-1.5 & InternLM2-20B & - & 57.1 & 46.8 & 54.7 & 47.4 & 80.6 & 720.0 & 55.4 & 2189.6 & 65.1 \\
% Ovis1.5 & Gemma2-9B-It & - & 58.1 & 49.7 & 65.6 & 48.2 & \textbf{84.5} & 752.0 & 53.8 & 2125.2 & 66.9 \\
% InternVL2 & InternLM2.5-7b & - & \underline{61.5} & 51.2 & 58.3 & 45.0 & \underline{83.6} & 794.0 & 54.3 & 2215.1 & 67.3 \\
% MiniCPM-V 2.6 & Qwen2-7B & - & 57.5 & 49.8 & 60.6 & 48.1 & 82.1 & \textbf{852.0} & 60.0 & 2268.7 & 68.5 \\
% Qwen2-VL & Qwen2-7B & - & 55.0 & 54.1 & - & \underline{50.6} & - & 845.0 & - & 2326.8 & - \\
% \hline\Gray
% \multicolumn{12}{c}{{\cellcolor[rgb]{0.957,0.957,0.957}} \textbf{\textit{Omni-modal Models}}} \\
% % \multicolumn{12}{c}{\texttt{Omni}} \\
% VITA-1.5-Audio & Qwen2-7B & - & - & 52.1 & \textbf{66.2} & 44.9 & 79.3 & 732.0 & 49.6 & \textbf{2352.0} & - \\
% EMova-8B & LLaMA-3.1-8B & 90.4 &- & - & 61.1 & -& 82.8 & 824.0 & 55.8 & 2205.0 & - \\
% Baichuan-Omni & - & - & 58.2 & 47.3 & 51.9 & 47.8 & - & - & 65.4 & 2186.9 & - \\
% Megrez-3B-Omni & Megrez-3B & \underline{91.6} & - & 51.8 & \underline{62.0} &50.1 & 82.0 & - & - & 2315.0 & - \\
% \hline
% \multicolumn{12}{c}{{\cellcolor[rgb]{0.957,0.957,0.957}} \textbf{\textit{Proprietary}}} \\
% GPT-4V & - & - & 50.4 & 59.3 & 48.2 & 39.3 & 71.4 & 678.0 & 49.0 & 1790.3 & 58.5 \\
% GPT-4o mini & - & - & 54.8 & 60.0 & 52.4 & 46.1 & 77.8 & 785.0 & \textbf{66.9} & 2003.4 & 66.3 \\
% Gemini 1.5 Pro & - & - & 59.1 & 60.6 & 57.7 & 45.6 & 79.1 & 754.0 & 64.0 & 2110.6 & 67.2 \\
% GPT-4o & - & - & 61.6 & \underline{62.8} & 56.5 & \textbf{51.7} & 77.4 & 663.0 & \underline{66.5} & \underline{2328.7} & 69.3 \\
% Claude3.5 Sonnet & - & - & \textbf{62.2} & \textbf{65.9} & 61.6 & 49.9 & 80.2 & 788.0 & 66.0 & 1920.0 & 69.3 \\ \hline \Gray
% \multicolumn{12}{c}{{\cellcolor[rgb]{0.957,0.957,0.957}} \textbf{\textit{Our Model}}} \\
% \model-Instruct & Qwen2-7B & \textbf{92.7} & 54.0 & 47.8 & \textbf{66.2} & - & - & \underline{847.0} & - & 2219.0 & - \\ \bottomrule
% \end{tabular}%
% }
% \end{table}