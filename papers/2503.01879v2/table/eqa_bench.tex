% \begin{table}[!h]
% \caption{\textbf{Evaluation on Audio English QA Benchmarks.} The accuracy~(\%) of different models in English question answering on three sets. {\model$\dagger$} shows the results of the evaluation using the large language model. The parameter size is derived from the backbone LLMs. Our model achieves top 3 accuracy in the LLaMA Q. benchmark, outperforming the same-period competitor MiniCPM-o2.6-7B.}
% \label{tab:eqa}
% \centering
% \renewcommand{\arraystretch}{1.2}
% % \setlength{\tabcolsep}{10pt}
% \resizebox{14cm}{!}{
% \begin{tabular}{lcc>{\columncolor{blue!8}}cc}
% \toprule
% \textbf{Model}  & \textbf{Modality} & \textbf{Web Q.}$\uparrow$  & \textbf{LLaMA Q.}$\uparrow$  & \textbf{Audio Trivia QA} $\uparrow$ \\ \hline
% % \multicolumn{5}{c}{{\cellcolor[rgb]{0.957,0.957,0.957}} \textit{**Notice: this part refers to the performance upper boundary of  \model~**}}\\
% % % Helium~\citep{defossez2024moshi}           & Text Only         & 32.30            & 75.00                & 56.40                     \\
% % Qwen2-VL-Instruct-7B\citep{wang2024qwen2}           & Text Only         & 32.30            & 75.00                & 56.40                     \\
% % Qwen2-Instruct-7B\citep{yang2024qwen2} & Text Only         & 45.13           & 77.67             & 63.93                    \\ 
% % \hline
% SpeechGPT-7B\citep{zhang2023speechgptempoweringlargelanguage}    & Audio\&Text       & 6.50             & 21.60              & 14.80                     \\
% Spectron-1B\citep{nachmani2023spoken}     & Audio\&Text       & 6.10             & 22.90              & -                         \\
% Moshi-7B\citep{defossez2024moshi}        & Audio\&Text       & 26.60            & 62.30              & 22.80                     \\
% GLM-4-Voice-9B\citep{zeng2024scalingspeechtextpretrainingsynthetic}        & Audio\&Text       & 32.20            & 64.70              & 39.10                     \\
% \rowcolor{blue!8}MiniCPM-o2.6-7B        & Audio\&Text       & 40.00           & 61.00             & 40.20                     \\
% Mini-Omni-0.5B\citep{xie2024mini} & Audio\&Text       & 12.80           & 22.00            & 6.90 \\
% Llama-Omni-8B\citep{fang2024llamaomniseamlessspeechinteraction} & Audio\&Text       & 22.90           & 45.30            & 10.70 \\
% MinMo-7B\citep{chen2025minmomultimodallargelanguage} & Audio\&Text       & \textbf{55.00}          & \textbf{78.90}           & \underline{48.30} \\
% Freeze-Omni-7B\citep{wang2024freeze}  & Audio\&Text       & \underline{44.73}          & \underline{72.00}                & \textbf{53.88}                    \\ 
% \hline
% \multicolumn{5}{c}{{\cellcolor[rgb]{0.957,0.957,0.957}} \textbf{\textit{Our Models}}} \\
% \rowcolor{blue!8}\model  & Audio\&Text       & 22.07           & 67.33               & \underline{48.30}    \\
% \model$\dagger$  & Audio\&Text       & 38.86          & 80.66                & 54.98 \\
% \bottomrule

% \end{tabular}
% }
% \end{table}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% \begin{table}[!h]
% \caption{\textbf{Evaluation on Audio English QA Benchmarks.} The accuracy~(\%) of different models in English question answering on three sets. {\model$\dagger$} shows the results of the evaluation using the large language model. The parameter size is derived from the backbone LLMs. Our model achieves top accuracy in the LLaMA Q. benchmark, outperforming the same-period competitor MiniCPM-o2.6-7B.}
% \label{tab:eqa}
% \centering
% \renewcommand{\arraystretch}{1.2}
% % \setlength{\tabcolsep}{10pt}
% \resizebox{14cm}{!}{
% \begin{tabular}{lcccc}
% \toprule
% \textbf{Model}  & \textbf{Modality} & \textbf{Web Q.}$\uparrow$  & \textbf{LLaMA Q.}$\uparrow$  & \textbf{Audio Trivia QA} $\uparrow$ \\ \hline
% SpeechGPT-7B\citep{zhang2023speechgptempoweringlargelanguage} & Audio\&Text & 6.50 & 21.60 & 14.80                     \\
% Spectron-1B\citep{nachmani2023spoken} & Audio\&Text & 6.10  & 22.90  & -                         \\
% Moshi-7B\citep{defossez2024moshi}     & Audio\&Text & 26.60 & 62.30  & 22.80                     \\
% GLM-4-Voice-9B\citep{zeng2024scalingspeechtextpretrainingsynthetic}        & Audio\&Text       & \underline{32.20}            & \underline{64.70}              & 39.10                     \\
% \rowcolor{blue!8}MiniCPM-o2.6-7B  & Audio\&Text  & \textbf{40.00} & 61.00  & \underline{40.20}                     \\
% Mini-Omni-0.5B\citep{xie2024mini} & Audio\&Text       & 12.80           & 22.00            & 6.90 \\
% Llama-Omni-8B\citep{fang2024llamaomniseamlessspeechinteraction} & Audio\&Text       & 22.90           & 45.30            & 10.70 \\
% \hline
% \multicolumn{5}{c}{{\cellcolor[rgb]{0.957,0.957,0.957}} \textbf{\textit{Our Models}}} \\
% \rowcolor{blue!8}\model  & Audio\&Text       & 22.07           & \textbf{67.33}               & \textbf{48.30}    \\
% \model$\dagger$  & Audio\&Text       & 38.86          & 80.66                & 54.98 \\
% \bottomrule

% \end{tabular}
% }
% \end{table}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{table}[!h]
\caption{\textbf{Evaluation on Audio English QA Benchmarks.} The accuracy~(\%) of different models in English question answering on three sets. The parameter size is derived from the backbone LLMs. Our model achieves top accuracy in the LLaMA Q. benchmark, outperforming the same-period competitor MiniCPM-o2.6-7B.}
\label{tab:eqa}
\centering
\renewcommand{\arraystretch}{1.2}
% \setlength{\tabcolsep}{10pt}
\resizebox{10cm}{!}{
\begin{tabular}{lcc}
\toprule
\textbf{Model}  & \textbf{Modality}  & \textbf{LLaMA Q.}$\uparrow$ \\ \hline
SpeechGPT-7B\citep{zhang2023speechgptempoweringlargelanguage} & Audio\&Text & 21.60 \\
Spectron-1B\citep{nachmani2023spoken} & Audio\&Text & 22.90                         \\
Moshi-7B\citep{defossez2024moshi}     & Audio\&Text & 62.30                         \\
GLM-4-Voice-9B\citep{zeng2024scalingspeechtextpretrainingsynthetic}  & Audio\&Text  & \underline{64.70}  \\
\rowcolor{blue!8}MiniCPM-o2.6-7B  & Audio\&Text & 61.00   \\
Mini-Omni-0.5B\citep{xie2024mini} & Audio\&Text & 22.00   \\
Llama-Omni-8B\citep{fang2024llamaomniseamlessspeechinteraction} & Audio\&Text  & 45.30 \\
\hline
\multicolumn{3}{c}{{\cellcolor[rgb]{0.957,0.957,0.957}} \textbf{\textit{Our Models}}} \\
\rowcolor{blue!8}\model  & Audio\&Text  & \textbf{67.33}  \\
\bottomrule

\end{tabular}
}
\end{table}