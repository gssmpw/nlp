\begin{table}[h!]
\centering
\caption{\textbf{Evaluation on Speech-to-Text Translation Benchmarks.} 
% \model~has demonstrated strong performance in both Mandarin (zh) and English (en) ASR tasks. 
\model~demonstrated superior performance compared to Qwen2-Audio-Instruct-7B in both translation tasks, however, it still falls short of the performance of its contemporary competitor. We conjecture that this performance gap may be due to the relatively modest scale of our pretraining speech dataset.}\label{tab:speech2text}
\resizebox{8.5cm}{!}{
\begin{tabular}{lcc}
\toprule
\multirow{2}{*}{\textbf{Model}} & \multicolumn{1}{c}{\textbf{zh-en (BLEU$\uparrow$)}} & \multicolumn{1}{c}{\textbf{en-zh (BLEU$\uparrow$)}} \\ \cmidrule{2-3}
 & \textbf{CoVoST2}  & \textbf{CoVoST2} \\ \hline
 \multicolumn{3}{c}{{\cellcolor[rgb]{0.957,0.957,0.957}} \textbf{\textit{Speech LLMs}}} \\
% Wav2vec2-base & - & - \\
Qwen2-Audio-7B  & 24.40 & 45.20 \\
Qwen2-Audio-Instruct-7B\textsuperscript{*} & 22.90 & 39.50 \\ 
MinMo-7B \textsuperscript{*} & \underline{25.95} & \underline{46.68} \\ 
\hline
 \multicolumn{3}{c}{{\cellcolor[rgb]{0.957,0.957,0.957}} \textbf{\textit{Omni-modal LLMs}}} \\
% Mini-Omini2-0.5B & - & - \\
% Freeze-Omini-7B & - & - \\ 
% VITA-1.0-8$\times$7B & - & -  \\
% VITA-1.5-7B & - & -  \\
% OpenOmni-7B\citep{luo2025openomnilargelanguagemodels} & - & -  \\
\rowcolor{blue!8}{MiniCPM-o2.6-7B} &  \textbf{27.20} &  \textbf{48.20} \\
\hline
\multicolumn{3}{c}{{\cellcolor[rgb]{0.957,0.957,0.957}} \textbf{\textit{Our Models}}} \\
\rowcolor{blue!8}\model & 23.17 & 40.21  \\ \bottomrule
\end{tabular}%
}
\end{table}