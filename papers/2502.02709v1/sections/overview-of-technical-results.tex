\section{Overview of Technical Results}\label{sec:overview-of-technical-results}

In \Cref{sec:acheivingdc}, we show parameter conversions under which any pure-DP algorithm, and any approx-DP algorithm enforces demographic coherence. 
Here, we present informal statements of these technical results.

We start by presenting a simplified definition of \emph{coherence enforcement} (Definition~\ref{def:coherence},~\ref{def:coherenceEnforcing}). \pj{(This presentation is meant to allow the informal statements of our technical results. For a formal presentation, see \Cref{sec:formaldef}. Additionally, the concept of enforcing demographic coherence emerges from careful consideration of several key principles, which are discussed in detail in \Cref{sec:walkthrough}.)}
Informally, a coherence-enforcing $\alg$ guarantees that predictors trained using its private reports will be demographically coherent.\footnote{In reality, the property of demographic coherence applies to algorithms $\cL$ that use private reports to design predictors.} 
% (The concept of enforcing demographic coherence emerges from careful consideration of several key principles, which are discussed in detail in \Cref{sec:walkthrough}.)
\pjnote{I moved the commented out parenthetical up.}

\begin{definition}[Informal Version of Definitions~\ref{def:coherence}~and~\ref{def:coherenceEnforcing}
]\label{informaldef:coherence}
Consider a data universe $\univ$, and a data-curation algorithm $\alg: \univ^* \to \cY$. We say that $\alg$ enforces $(\alpha, \beta)$-demographic coherence, if for all algorithms $\cL: \cY \to (\univ \to [-1,1])$ that use the report produced by the curator to create a confidence-rated predictor $h: \univ \to [-1,1]$, the following condition is satisfied. For all datasets $X$, 
$$ 
\Pr_{X_a,X_b \setrandomly X, R_a \leftarrow \alg(X_a), h \leftarrow \cL(R_a)}[dist(h(X_a), h(X_b)) \geq \alpha] \leq \beta,$$
where $X_a, X_b$ represent a random split of the dataset $X$ into halves, report $R_a $ is produced by the data-curator using only $X_a$, and $h$ is created by running algorithm $\cL$ on the report, $h(X_a)$ represents the empirical distribution of predictions made on $X_a$, and $\dist(\cdot,\cdot)$ represents a metric distance between distributions. 
Here, $\beta$ is the probability that $h$ is not demographically coherent, and $\alpha$ represents how close the distributions of $h(X_a)$ and $h(X_b)$ are required to be.
\end{definition}

The formal definition of \emph{coherence enforcement} is more intricate than the one above. One key technical distinction is that the restriction on predictor $h$ applies not only to the full sets $X_a$ and $X_b$, but also across different subpopulations in those sets. For the remainder of this section, we specify the distance metric $\dist(\cdot,\cdot)$ as Wasserstein\nobreakdash-1 distance between distributions. In this context, we say that and algorithm $\alg$ \emph{enforces Wasserstein-coherence}.

The following theorem is an informal statement of \Cref{thm:max-info-implies-demographic-coherence}, which argues that any data-curation algorithm with bounded max-information \cite{DworkFHPRR15} (a notion that mathematically captures the dependence of algorithms' outputs to their inputs) also enforces Wasserstein coherence. 
\begin{theorem}[Informal Version of ~\Cref{thm:max-info-implies-demographic-coherence}]\label{introthm:max-info-implies-demographic-coherence}
    Let $n\in\N$,$\zeta>0$, $\beta \in (0,1)$, $\alpha \in (0,2]$.  %Let $\cC$ be a collection of categories $C \in \univ^*$. 
    
   Consider a data curation algorithm ${\alg:\univ^{n/2}\to \cY}$ with bounded max-information 
    $$I^{\beta/2}_{\infty}(\alg,n/2) < \zeta.$$
   Then, $\alg$ enforces $(\alpha,\beta)$-demographic coherence provided that $n \geq k\cdot\frac{\zeta + \ln(1/\beta)}{\alpha^2}$ for some constant $k$.
\end{theorem}

We leverage the connection between differential privacy and max-information to show the exact parameter conversion under which differentially private algorithms enforce demographic coherence.  
Theorem~\ref{introthm:pure-DP-implies-demographic-coherence} is an informal statement of \Cref{thm:pure-dp-implies-coherence-enforcement}, the result for pure-DP. For the approximate-DP result, we point the reader to \Cref{thm:approx-dp-implies-coherence-enforcement} in \Cref{sec:acheivingdc}.

\begin{theorem}[Informal Version of Theorem~\ref{thm:pure-dp-implies-coherence-enforcement}]\label{introthm:pure-DP-implies-demographic-coherence}
    Let $n\in\N$, $\beta, \eps \in (0,1)$, $\alpha \in (0,2]$.
    
   Consider an $\eps$-DP data curation algorithm ${\alg:\univ^{n/2}\to \cY}$.
   Then, $\alg$ enforces $(\alpha,\beta)$-demographic coherence provided that $\eps \leq k \cdot \frac{\alpha}{\ln(1/\beta)}$ for some constant $k$.
\end{theorem}

This theorem should be understood as follows: a data curator identifies (possibly experimentally) regimes for $\alpha$ and $
\beta$ that they find to be ``too risky''
for a data release (with respect to demographic coherence).  That curator can then use this 
theorem to suggest a value of $\eps$ such that, if they were to use differential privacy as their privatization mechanism, the resulting data release would achieve their desired constraints. While the parameter conversion in \Cref{thm:pure-dp-implies-coherence-enforcement} would likely result in a value of $\eps$ that is too small for most use cases, we expect this to be inherent to a black-box conversion of differential privacy to the enforcement of demographic coherence. 
We leave it as an important open question 
to identify other ways of achieving our definition, including non-black-box uses of DP-algorithms for obtaining better coherence enforcement guarantees.