\section{Introduction}
\label{sec01}
The increasing popularity of computationally intensive services, such as machine learning (ML), automated driving, and augmented reality (AR), is increasing demand for computational resources with low latency, high reliability, and strong security \& privacy guarantees. 
This has led to the emergence of edge and fog computing paradigms (e.g., pervasive edge computing) to allow for the delegation of these services to capable machines located at the network's edge. This addresses the applications' needs in a distributed and scalable manner~\cite{edgeCom}, while providing greater availability and reliability and lower latency to users than deployments on the cloud. 
\begin{figure}[t]
\centering
  \includegraphics[width=\columnwidth]{Figures/Introduction.pdf} 
  \vspace{-0.3in}
  \caption{Asynchronous aggregation mechanism, although useful, leads to privacy vulnerability in asynchronous FL.}
  \label{fig:Introduction} 
  \vspace{-0.2in}
\end{figure}

Scalability of large edge ML applications have received a shot-in-the-arm with the adoption of distributed ML techniques, which can collaboratively leverage available resources of varying computational capabilities and operate at dynamic time scales.
However, the democratized and heterogeneous nature of the edge computing environment exacerbates some security flaws in the distributed models.  
Distributed learning models generally make use of either centralized training data or decentralized training data. The decentralized approach is more desirable for the sake of scalability and continuous learning for applications.  
Popular decentralized methods include Gossip Learning~\cite{Gossip} and Federated Learning (FL)~\cite{FederatedOpt}. Of the two, FL tends to be more efficient with an aggregator incorporating training data from various clients. 
FL can be done either synchronously or asynchronously~\cite{Caozhazha2024SRFL,FanLiuGon2022AFLGuard} as illustrated in Figure~\ref{fig:Introduction}. 

In a synchronous model, an aggregator will wait for all its clients to send in their weights before performing the aggregation. 
This method can provide some privacy to individual clients, as each model update reflects the sum of all the clients' weights.  
In a dynamic environment, such as the network edge, where clients may freely join and leave the system, this model is difficult to use. The aggregator may be left hanging on a client that has left or exclude clients that joined later. At the pervasive edge, an asynchronous model is more apt---the clientâ€™s weights will be aggregated as they are received or at regular time periods. While this model provides improved dynamicity, it loses some of the privacy provided by the synchronous model, as the model is updated upon receipt of a subset of clients' feedback instead of when all clients' feedback is received. As shown in Figure~\ref{fig:Introduction}, in this case the updates to the global model directly reflect incorporation of a client's weights. This allows a snooper (including client) that receives the server's iterative updates to reconstruct the updating clients' models by comparing the current and previous server updates. %

There are various works showcasing the vulnerability of both synchronous and asynchronous FL models to membership interference attacks and reconstruction attacks~\cite{nasshohou2019comprehensive,zhuLiGu2024evaluating,shostrmarc2017membership,yanGeXia2023using, BoeDziSchu2023when, ZhaShaElk2024Large-scale}. Several follow-on methods have been proposed to protect against said attacks, but most focus on synchronous FL~\cite{ShoRezShm2015Privacy,weilima2023personalized,Hewancai2024clustered,HuGuoGon2023Federated,xuliliu2020verifynet,NaHyeJun2022Closing,liuligao2023privacy-encoded,Caozhazha2024SRFL}. The differences between asynchronous and synchronous FL mean that these solutions cannot be properly mapped onto asynchronous FL. We  also present novel attack vectors we discovered, which are not addressed by these solutions. 

Some of these attack vectors are also made possible due to the inherent untrustworthiness of the aggregator's host machine. To address this lack of trust Trusted Execution Environment (TEE)~\cite{IEECiteforSGX, TEECite} have emerged. TEEs, with their controlled enclaves, contain a verification mechanism to ensure that only the program designated to handle a data runs inside, thus preserving the privacy of the client's data. An example of a TEE is Intel's SGX~\cite{IEECiteforSGX} which uses specialized hardware to create secure enclaves. 

\noindent
\textbf{Our Framework:}
To address these outstanding concerns, we present a framework for \emph{Learning Asynchronously, Tempered with Trusted Execution and Obfuscation}--referred to as \textit{\textbf{LATTEO}}. The \sysname framework addresses the privacy and scalability challenges in asynchronous federated learning (AsyncFL) through a three-component architecture. 
The first component is a \textit{\textbf{novel gradient obfuscation mechanism}} to safeguard client data privacy by entangling local gradient updates with a private orthogonal distribution in the latent space. Unlike differential privacy, which can degrade model utility, our gradient obfuscation scheme preserves the global model's utility with negligible computational overhead.
The second component is a \textit{\textbf{secure aggregation service mesh}} that employs confidential computing principles to enable the agile deployment of trusted aggregation services at the network edge. This is crucial in the edge-cloud ecosystem, where service providers delegate AsyncFL aggregation tasks to edge servers closer to clients, reducing latency and enhancing efficiency. To avoid constant reliance on cloud-based service providers, \sysname establishes a hierarchical trusted coordinator enclave structure, which is vendor-agnostic, and transfers the credentialing authority for attesting local aggregation enclaves and for provisioning credentials.
The vendor-agnostic design enables devices with different TEEs (e.g., Intel, Nvidia) to operate seamlessly in the ecosystem.    

Finally, \sysname framework features a novel \textit{\textbf{data-centric attestation mechanism}}, which provides a vendor-agnostic solution, enabling clients to implicitly verify aggregation services, using enclaves from multiple vendors in the same ecosystem. At its core, this mechanism leverages Multi-Authority Attribute-Based Encryption (MABE) to support asynchronous communication, aligning with the asynchronous nature of AsyncFL. This approach ensures scalability and eliminates reliance on hardware-specific attestation, outperforming conventional remote attestation methods.

We prototyped \sysname~and evaluated it with multiple neural network architectures and datasets. Results demonstrate that our gradient obfuscation mechanism preserves model utility, within {\em 1\%} of vanilla AsyncFL, while significantly reducing data reconstruction risks--lowering similarity metrics, such as structural similarity index by {\em 85\%} and increasing reconstruction error by {\em 400\%}. The system also scales seamlessly under high client loads, reducing average client latency by up to {\em 15x} compared to conventional RA-TLS.


The novel {\bf contributions} of \sysname are as follows: 

    \noindent {\bf (i)}
    We perform a thorough evaluation of AsyncFed by utilizing adversaries performing reconstruction attack with varying levels of prior knowledge. We do so by extending existing attack methodologies to fit the unique vulnerabilities that exist in AsyncFL, demonstrating privacy risks in AsyncFL systems.
    

    \noindent {\bf (ii)} We propose a gradient obfuscation mechanism to protects client privacy by entangling local gradient updates with an orthogonal distribution in the latent space. This entanglement is performed using a carefully designed loss function, ensuring that the gradients remain indistinguishable while maintaining model performance. 
    
    \noindent {\bf (iii)} We propose a scalable framework for the secure deployment of aggregation services at the network edge. \sysname incorporates a hierarchical enclave structure for trusted aggregation and a data-centric, vendor-agnostic attestation mechanism that provides scalable and implicit client verification, addressing limitations of conventional remote attestation methods. This attestation mechanism is generic and can be used widely in secure distributed systems. 
    

    \noindent {\bf (iv)} We systematically evaluate \sysname using major benchmark datasets of varying complexity across two neural network architectures. We also assess scalability of the proposed hierarchical enclave structure and implicit attestation mechanism, comparing its operation cost to that of the conventional remote attestation-trasport layer security (RA-TLS) attestation scheme.

The rest of this paper is organized as follows. In Section~\ref{sec03} we discuss the threat model and elaborate on our gradient reconstruction attack. We then overview \sysname in Section~\ref{sec04}, and elaborate on its detailed design in Section~\ref{sec05}. Using the Universal Composability Framework, we prove \sysname's security in Section~\ref{formalsec}. Section~\ref{sec08} details the implementation scope, experimental setup, and analysis. Finally, we review the related work in Section~\ref{sec02}, and conclude our work in Section~\ref{sec09}. 






