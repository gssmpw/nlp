\section{Experimental Results and Analysis}
\label{sec08} 
In this section, we first elaborate on the \sysname' implementation scope, and review the experimental setup. We will then share the results and findings, including the proposed attack, mitigation strategy, and the system performance and scalability of the proposed data-centric attestation.



\subsection{System Implementation Scope}
\label{implementation}
To evaluate our approach, we implemented the \sysname~framework, consisting of an aggregation application designed to run on a server and a client application intended for operation on client devices. For comparison, we also implemented an alternative framework employing the same set of applications but utilizing the standard RA-TLS attestation framework~\cite{intel2018ratls}.
Our \sysname~implementation adheres to Protocols~\ref{proto-5} and~\ref{proto-6}. We assumed that the necessary credentials had already been distributed to both the client and the server. Hence, we partially implemented Protocols~\ref{proto1} through~\ref{proto-3}. This does not have an impact on our performance comparison because, in practice, server and client onboarding operations occur at much lower frequencies than client service requests. We also implemented GOOD-based client training (Algorithm~\ref{Algo-1}) and compared it against vanilla and differential privacy-based AsyncFL approaches.

All implementations were written in Python and executed using Gramine~\cite{gramine}, a library OS that allows unmodified applications to run within an SGX enclave. The SGX enclaves were configured with 4 GB of memory and 32 threads. We extended the C++ MABE implementation from~\cite{edgeCom}, generalizing it to accept variables specifying the number of authorities and number of attributes from each authority in the system. Additionally, \sysname leverages the reliable UDP implementation of MsQuic, a C++-based QUIC protocol implementation, to facilitate communication. Both aggregator implementations include federated learning mechanisms capable of integrating client updates.
In both implementations, the aggregator hosts the global weights, which are distributed to clients upon request. The interaction begins when a new user (client) requests the global weights from the aggregator. The aggregator responds by providing an ID and the current global weights. The client then updates the weights using its local data and sends the updated weights along with its ID back to the aggregator. Thereafter, the clients in the system can request the newly updated global weights.


\subsection{Dataset and Architecture}
We evaluate the reconstruction attack and the efficacy of the proposed gradient obfuscation defense using these datasets:

$\bullet$ {FMNIST}~\cite{FMNIST}, a dataset consisting of $70,000$ grayscale images. These images are labeled under ten clothing categories such as sneaker, shirt, pullover, etc.

$\bullet$ {CIFAR-10}~\cite{CIFAR}, a dataset consisting of 60,000 color images labeled under ten classes such as airplane, automobile, bird, etc. There are $50000$ training and $10000$ test images.

$\bullet$ {UTKFace}~\cite{UTKFace}, a multi-task dataset consisting of $20,000$ face images. Each image is labeled based with age, gender, and ethnicity. We train our classifiers to classify the images based on ethnicity.

We utilize two architectures to train our target models, namely, a SimpleCNN architecture (consisting of three convolution layers and two dense layers) and a Resnet18~\cite{resnet18} architecture. Both of these architectures are trained on all of the aforementioned datasets.
{\color{black} For the CIFAR-10 and UTKFace datasets, we set the number of epochs to 700; for the FMNIST dataset, we set EPOCHS to 350. We set the training batch size for all models to 64, used RMSprop and Adam for the optimizers, and used CrossEntropyLoss for the loss function for vanilla training.}
We compare GOOD against differential privacy (DP-SGD). We train the differentially private models on an epsilon value 0.1 with gradient norm of 1.2 and delta of $10^{-5}$. Lower epsilon values improve the level of privacy in a model but also adversely impact the utility of the said model. In the following sections we analyze both the utility performance and privacy performance of GOOD and DP-SGD. 

\begin{figure}[t]
\centering
  \includegraphics[width=\columnwidth]{Figures/deep_prior_reconstruction.pdf} 
  \vspace{-0.24in}
  \caption{Comparison of the GOOD and vanilla approaches against a data reconstruction attack using the strongest prior knowledge. The results highlight GOOD's superiority in effective attack mitigation, even under the strongest prior.}
  \label{fig:Reconstruction_deep_prior} 
  \vspace{-0.15in}
\end{figure}



\begin{figure*}[htb]
    \centering %
\subfloat[ GOOD reconstruction.\label{fig:GOODRecon}]{
  \includegraphics[width=0.48\textwidth]{Figures/Results/BoxPlots_GOOD.png}
}
\hspace{-0.5in}
\hfill
\subfloat[DP-SGD reconstruction. \label{fig:DPRecon}]{
  \includegraphics[width=0.48\textwidth]{Figures/Results/BoxPlots_01.png}
}
\vspace{-0.15in}
\caption{Effectiveness of GOOD in mitigating data reconstruction attacks under varying levels of prior knowledge. On average, GOOD maintains consistently low SSIM values across all scenarios, highlighting its robust privacy-preserving capabilities.}
\label{fig:Reconstruction_different_prior}
\vspace{-0.1in}
\end{figure*}






\subsection{Utility Performance}
We first assess the utility of GOOD when compared to the other schemes. Figure~\ref{fig:detection_correction} illustrates the accuracy and F1-score of GOOD and vanilla asynchronous federated learning across the dataset and architecture combinations. The results are plotted for every ten epochs. 
From the figure, it is evident that the training performance using the GOOD-based approach aligns closely with the vanilla approach in terms of both accuracy and convergence rate. The only exception is observed with the UTKFace dataset, where the overall accuracy and F1-score are slightly lower compared to the vanilla approach, despite a similar convergence rate. We attribute this discrepancy is to the inherent characteristics of the dataset. 
We observed that the GOOD-CNN architecture performs slightly worse than Good-ResNet18, requiring more time to converge to a marginally lower value. This indicates that a more advanced architecture, like ResNet18, may be preferable for achieving optimal results in both approaches. Overall, our findings show that our gradient obfuscation approach maintains model utility without compromise. Next, we discuss the privacy benefits of GOOD in mitigating data reconstruction attacks.
Figure~\ref{fig:detection_correction} also shows the training performance of the DP-SGD approach. We observe significantly lower accuracy and F1 score with DP-SGD compared to both the GOOD and vanilla approaches. We see that FMNIST and UTKFace perform better than Cifar10 when trained using DP-SGD. This is mainly due to the higher complexity of the Cifar10 dataset.



\subsection{Privacy-preserving Performance}
We also evaluated the privacy benefits of our proposed gradient obfuscation method by comparing it to the vanilla asynchronous FL approach using structural similarity index (SSIM) and mean square error (MSE) metrics. Figure~\ref{fig:Reconstruction_deep_prior} illustrates the performance comparison of GOOD and the vanilla approach against an adversary equipped with the strongest prior knowledge~\cite{gradientObfuscation}, \ie access to non-overlapping IID shadow dataset. Specifically, it can be observed that the vanilla approach results in significantly higher SSIM values compared to GOOD--approximately \textbf{800\% higher}--across all dataset and architecture combinations. The MSE scores for GOOD are observed to be \textbf{nearly 300\% higher} than those of the vanilla approach across all datasets, except for UTKFace, where the MSE scores are still \textbf{around 200\% higher}. These results indicate that reconstruction attempts under GOOD produce significantly less perceptible outcomes, effectively safeguarding client privacy even when the attacker possesses strong prior information.
We also observed that while Cifar10 and UTKFace show similar SSIMs and MSE scores for the GOOD update, FMNIST shows a noticeably higher MSE for both CNN and ResNet18, suggesting that simpler datapoints are easier to obfuscate, resulting in a greater reduction in reconstruction effectiveness. However, when left unobfuscated, simpler data is the easiest to reconstruct. These findings demonstrate that our approach effectively protects the privacy of the client regardless of the complexity of the data. 





We also evaluated the effectiveness of data reconstruction attacks leveraging various prior knowledge, as outlined in Section~\ref{subsec03-02}, against the GOOD method and DP-SGD (Figure~\ref{fig:Reconstruction_different_prior}). The results reveal that GOOD provides even stronger protection of client data privacy against weaker adversaries, with the median SSIM consistently remaining \textbf{below 5\%}. 
Overall SSIM performance is very consistent in the CNN architecture, with the most variation coming from the Euclidean distance based attack when run with the FMNIST dataset. Interestingly, the SSIM score tends to lower as the priors become stronger when using the CNN architecture. The performance is also very consistent in the ResNet18 architecture, with variation being highest when run with the UTKface dataset. The MSE scores are also very consistent within both architectures, with the MSE scores being higher and having more variation within the CNN, indicating the reconstruction was less effective there. %
GOOD is effective in privacy protection against diverse adversarial scenarios with various levels of prior knowledge. It maintains consistently strong performance against reconstruction in terms of SSIM across all datasets and architectures. 
 
{\color{black} DP-SGD has strong performance in terms of MSE and SSIM, effectively protecting client privacy. For all attacks, the SSIM score is also under 5\%, with the medians being even lower than those found in the GOOD results. The only exception is the GradInversion ResNet18 results with the FMNIST dataset. The MSE results are generally higher than those seen with GOOD, with a significantly strong performance against Euclid. The other MSE results have higher medians but much more variation than those seen in GOOD. %
Overall, while stronger in some cases, DP-SGD's performance is comparable to our GOOD approach. These results show that GOOD can provide protection nearly on par with DP-SGD without significantly impacting a model's utility.

Note that while we compare GOOD's performance in preventing privacy violations via reconstruction attacks, it does not provide worst-case guarantees like the DP-SGD approach. Although early experiments are encouraging, future work will include a more comprehensive theoretical and empirical assessment and comparison.}












\subsection{System Scalability Analysis}
\label{sec:eval-scalability}
{\bf Deployment Setup:} To evaluate the scalability of our approach, we conducted experiments in two settings: {\it (i)} a one-to-one setup, where a single client connects to a single aggregator, and {\it (ii)} a many-to-one setup, where multiple clients simultaneously connect to a single aggregator. In the one-to-one setup, we tested the client application on multiple devices with varying specifications: a server-grade desktop, a consumer-grade desktop, and a Raspberry Pi 3. The server-grade desktop featured an Intel(R) Xeon(R) W-2245 CPU clocked at 3.90 GHz with 128 GiB of RAM, the consumer-grade desktop was powered by an AMD Ryzen 9 7900X 12-Core Processor running at 4.70 GHz with 64 GiB of RAM, and the Pi 3 runs an ARM Cortex-A53. The aggregator was deployed on a standard DC16s v3 Microsoft Azure Virtual Machine (VM), equipped with 16 virtual CPUs and 128 GiB of memory.
In the second setup, the client and server applications were deployed on Microsoft Azure standard D16s v5 VMs, each equipped with 16 vCPUs and 64 GiB of memory. Using these machines, we experimented with incrementally increasing the number of simultaneous connections to the aggregator and measuring the average latency. The aggregator application was hosted on a VM of similar capability, for consistency.

\begin{figure*}[ht]
\centering
    \begin{minipage}[t]{0.3\textwidth}
        \centering
        \includegraphics[height=4cm,width=\linewidth]{Figures/Results/Comm_BreakDown.pdf}
        \vspace{-0.3in}
        \caption{Comparison of the communication between the client and server in RA-TLS vs \sysname.} 
        \label{fig:LatOnboarding}
    \end{minipage}%
    \hspace{0.02\textwidth}
    \begin{minipage}[t]{0.3\textwidth}
        \centering
        \includegraphics[height=4cm,width=\linewidth]{Figures/Results/ScaleTest.pdf}  
        \vspace{-0.3in}
        \caption{Average time for the initial connection across different number of simultaneous clients.}
        \label{fig:ScaleTest}
    \end{minipage}%
    \hspace{0.02\textwidth}
    \begin{minipage}[t]{0.3\textwidth}
        \centering
        \includegraphics[height=4cm,width=\linewidth]{Figures/Results/First200-200_Log.pdf}  
        \vspace{-0.3in}
         \caption{Communication latency as the number of simultaneous connections increases (log scale).}  
        \label{fig:First1000}
    \end{minipage}
    \vspace{-0.1in}
\end{figure*}

\noindent
{\bf Results Analysis:} For system scalability, we began by evaluating the end-to-end latency of our system. Figure~\ref{fig:LatOnboarding} provides a breakdown of the time between the client and server in a one-to-one setup, detailing the communication latency which encompasses the elapsed time for cryptographic operations. 
In all cases, except for the Pi 3 (ARM Cortex-A53), there is a noticeable reduction in overall latency despite the additional cryptographic operations introduced by \sysname. Notably, the time spent on these operations has minimal impact on the overall communication latency. Table~\ref{table:times} lists the latency breakdown of \sysname operations. {\color{black} MABE's encryption operation totals around 28.01~ms in the worst case, accounting for at most 4.7\% of the total communication time. The symmetric key encryption operation takes less than 3~ms except when on the ARM processor where it takes 14~ms accounting for 1.3\% of the total communication time.} These times are negligible when compared to the total time taken by the communication process, and as seen in Figure~\ref{fig:LatOnboarding} do not affect the overall performance of \sysname.

An interesting trend is that the latency gap between \sysname and RA-TLS decreases as the available RAM of the device decreases. This can be attributed to the use of MsQuic, which spawns background threads that may strain memory-limited devices. These results indicate that on devices with sufficient resources, \sysname significantly reduces user-perceived latency compared to TLS-TCP and, at worst, introduces no additional latency. 

\begin{table}[t]
\small
\centering
\caption{\label{table:times} The breakdown of the client’s perceived latency, averaged across multiple runs.}
\label{results} 
\vspace{-0.1in}
\begin{tabular}{ccccc}
\toprule
\hline
    {\bf Processor}     & {\bf Total} & {\bf Comm}   & {\bf Sym. Key}  & {\bf MABE}     \\ \midrule
    Intel(R) Xeon(R)    & 592.87 ms     & 565.37 ms     & 2.75 ms       & 28.01 ms \\ \hline
    AMD Ryzen 9         & 784.4 ms     & 758.8 ms      & 0.85 ms       & 10.85 ms \\ \hline
    ARM Cortex-A53      & 1089.06 ms     & 1048.48 ms    & 14 ms         & 12.7 ms  \\ 
\hline
\bottomrule
\end{tabular}
\vspace{-0.2in}
\end{table}


\begin{figure*}[h]
\centering
    \begin{minipage}[t]{0.31\textwidth}
        \centering
        \includegraphics[height=4cm, width=\linewidth]{Figures/Results/ServerCPULabeled1.png}   
        \vspace{-0.25in}
        \caption{Server CPU Utilization}   
        \label{fig:CPUServer}
    \end{minipage}%
    \hspace{0.01\textwidth}
    \begin{minipage}[t]{0.31\textwidth}
        \centering
        \includegraphics[height=4cm,width=\linewidth]{Figures/Results/ClientCPULabeled1.png}  
        \vspace{-0.25in}
        \caption{Client CPU Utilization}   
        \label{fig:CPUClient}
    \end{minipage}%
    \hspace{0.01\textwidth}
    \begin{minipage}[t]{0.31\textwidth}
        \centering
        \includegraphics[height=4cm,width=\linewidth]{Figures/Results/MemoryUtil.pdf} 
        \vspace{-0.25in}
        \caption{Memory Utilization}   
        \label{fig:Memory}
    \end{minipage}
    \vspace{-0.1in}
\end{figure*}

We employed the many-to-one setup to evaluate how increasing the number of active connections to the server affects communication for clients. In this series of experiments, we progressively increased the number of active clients attempting to register and retrieve the global weights from the aggregation server. For instance, in our experiments with 200 simultaneous clients, there were always 200 active clients competing to register with the aggregator at any given time. This was achieved by launching a new client instance as soon as another completed its registration. For each experiment, we measured the average time required for a client to complete the registration process.
Figure~\ref{fig:ScaleTest} illustrates the average latency as the number of clients increases from 2 to 200. Initially, with just two simultaneous connections, RA-TLS and \sysname exhibit comparable performance. However, as the number of simultaneous connections grows, RA-TLS shows a significant increase in average latency, whereas \sysname consistently maintains low latency. 
Specifically, with 200 concurrent clients' connections, \textbf{RA-TLS demonstrates an average latency nearly 1500\% higher than that of \sysname}.

To further investigate the root cause of RA-TLS’s behavior, we analyzed per-connection latency as the number of clients increased (Figure~\ref{fig:First1000}). This latency was calculated as the total time a client takes to connect to the server, including the re-establishment of timed-out connections. It is evident that the increased latency in RA-TLS is directly correlated with the growing number of connection timeouts, particularly when the increasing number of concurrent connections, between 100 to 200 connections, overwhelms the RA-TLS server. Note that we did not consider any extra load balancing service for either of the approaches in an attempt to replicate the edge environment.
These results demonstrate that the \sysname framework scales effectively and is better suited to handle many simultaneous users than the RA-TLS framework.



\subsection{System Cost Analysis}











To evaluate the cost incurred by our system, we analyzed the CPU utilization and memory footprint of both \sysname and RA-TLS.
Figure~\ref{fig:CPUServer} shows the CPU utilization of the aggregator application over time for both \sysname and RA-TLS. During the initialization phase, both frameworks exhibit a CPU utilization of approximately 6\%. While their performance during initialization is relatively similar, RA-TLS shows more frequent spikes, whereas \sysname has a startup time about 30 seconds longer. This discrepancy can be attributed to \sysname's use of MsQuic, which initializes a series of threads for communication, all of which must be provisioned within the SGX enclave. During the client aggregation phase, both frameworks exhibit similar CPU utilization.
A comparison of client-side CPU utilization on the server-grade desktop, shown in Figure~\ref{fig:CPUClient}, indicates that both frameworks have nearly identical utilization profiles, although, the CPU usage increases to approximately 50\% for a few seconds while processing the global model and cryptographic operations have minimal impact on CPU usage.

The maximum memory consumption of the aggregator and client applications, as shown in Figure~\ref{fig:Memory}, indicates that both frameworks demonstrate similar performance. However, the RA-TLS implementation shows slightly higher memory usage for the server application. This difference can be attributed to the additional state management required by TLS connections use in the RA-TLS.


