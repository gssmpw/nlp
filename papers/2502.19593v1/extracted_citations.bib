@article{ge_interpretable_2018,
	title = {An {Interpretable} {ICU} {Mortality} {Prediction} {Model} {Based} on {Logistic} {Regression} and {Recurrent} {Neural} {Networks} with {LSTM} units.},
	volume = {2018},
	issn = {1942-597X},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6371274/},
	abstract = {Most existing studies used logistic regression to establish scoring systems to predict intensive care unit (ICU) mortality. Machine learning-based approaches can achieve higher prediction accuracy but, unlike the scoring systems, frequently cannot provide explicit interpretability. We evaluated an interpretable ICU mortality prediction model based on Recurrent Neural Networks (RNN) with long short-term memory(LSTM)units. This model combines both sequential features with multiple values over the patient’s hospitalization (e.g. vital signs or laboratory tests) and non-sequential features (e.g. diagnoses), while identifying features that most strongly contribute to the outcome. Using a set of 4,896 MICU admissions from a large medical center, the model achieved a c-statistic for prediction of ICU mortality of 0.7614 compared to 0.7412 for a logistic regression model that used the same data, and identified clinically valid predictors (e.g. DNR designation or diagnosis of disseminated intravascular coagulation). Further research is needed to improve interpretability of sequential features analysis and generalizability.},
	urldate = {2024-07-31},
	journal = {AMIA Annual Symposium Proceedings},
	author = {Ge, Wendong and Huh, Jin-Won and Park, Yu Rang and Lee, Jae-Ho and Kim, Young-Hak and Turchin, Alexander},
	month = dec,
	year = {2018},
	pmid = {30815086},
	pmcid = {PMC6371274},
	keywords = {notion},
	pages = {460--469},
}

@article{kong_using_2020,
	title = {Using machine learning methods to predict in-hospital mortality of sepsis patients in the {ICU}},
	volume = {20},
	issn = {1472-6947},
	url = {https://doi.org/10.1186/s12911-020-01271-2},
	doi = {10.1186/s12911-020-01271-2},
	abstract = {Early and accurate identification of sepsis patients with high risk of in-hospital death can help physicians in intensive care units (ICUs) make optimal clinical decisions. This study aimed to develop machine learning-based tools to predict the risk of hospital death of patients with sepsis in ICUs.},
	language = {en},
	number = {1},
	urldate = {2024-07-31},
	journal = {BMC Medical Informatics and Decision Making},
	author = {Kong, Guilan and Lin, Ke and Hu, Yonghua},
	month = oct,
	year = {2020},
	keywords = {In-hospital mortality, Intensive care unit, Machine learning, Prediction model, Sepsis, notion},
	pages = {251},
}

@misc{labach_duett_2023,
	title = {{DuETT}: {Dual} {Event} {Time} {Transformer} for {Electronic} {Health} {Records}},
	shorttitle = {{DuETT}},
	url = {http://arxiv.org/abs/2304.13017},
	abstract = {Electronic health records (EHRs) recorded in hospital settings typically contain a wide range of numeric time series data that is characterized by high sparsity and irregular observations. Effective modelling for such data must exploit its time series nature, the semantic relationship between different types of observations, and information in the sparsity structure of the data. Self-supervised Transformers have shown outstanding performance in a variety of structured tasks in NLP and computer vision. But multivariate time series data contains structured relationships over two dimensions: time and recorded event type, and straightforward applications of Transformers to time series data do not leverage this distinct structure. The quadratic scaling of self-attention layers can also significantly limit the input sequence length without appropriate input engineering. We introduce the DuETT architecture, an extension of Transformers designed to attend over both time and event type dimensions, yielding robust representations from EHR data. DuETT uses an aggregated input where sparse time series are transformed into a regular sequence with fixed length; this lowers the computational complexity relative to previous EHR Transformer models and, more importantly, enables the use of larger and deeper neural networks. When trained with self-supervised prediction tasks, that provide rich and informative signals for model pre-training, our model outperforms state-of-the-art deep learning models on multiple downstream tasks from the MIMIC-IV and PhysioNet-2012 EHR datasets.},
	urldate = {2024-04-03},
	publisher = {arXiv},
	author = {Labach, Alex and Pokhrel, Aslesha and Huang, Xiao Shi and Zuberi, Saba and Yi, Seung Eun and Volkovs, Maksims and Poutanen, Tomi and Krishnan, Rahul G.},
	month = aug,
	year = {2023},
	note = {arXiv:2304.13017 [cs]},
	keywords = {Computer Science - Machine Learning, notion},
}

@article{lentzen_exmed-bert_2023,
	title = {{ExMed}-{BERT}: {A} {Transformer}-{Based} {Model} {Trained} on {Large} {Scale} {Claims} {Data} for {Prediction} of {Severe} {COVID}-19 {Disease} {Progression}},
	volume = {27},
	issn = {2168-2194, 2168-2208},
	url = {https://ieeexplore.ieee.org/document/10159467/},
	doi = {10.1109/JBHI.2023.3288768},
	number = {9},
	urldate = {2023-09-14},
	journal = {IEEE Journal of Biomedical and Health Informatics},
	author = {Lentzen, Manuel and Linden, Thomas and Veeranki, Sai and Madan, Sumit and Kramer, Diether and Leodolter, Werner and Fröhlich, Holger},
	month = sep,
	year = {2023},
	keywords = {notion},
	pages = {4548--4558},
}

@article{li_behrt_2020,
	title = {{BEHRT}: {Transformer} for {Electronic} {Health} {Records}},
	volume = {10},
	issn = {2045-2322},
	shorttitle = {{BEHRT}},
	url = {https://www.nature.com/articles/s41598-020-62922-y},
	doi = {10.1038/s41598-020-62922-y},
	abstract = {Abstract
            Today, despite decades of developments in medicine and the growing interest in precision healthcare, vast majority of diagnoses happen once patients begin to show noticeable signs of illness. Early indication and detection of diseases, however, can provide patients and carers with the chance of early intervention, better disease management, and efficient allocation of healthcare resources. The latest developments in machine learning (including deep learning) provides a great opportunity to address this unmet need. In this study, we introduce BEHRT: A deep neural sequence transduction model for electronic health records (EHR), capable of simultaneously predicting the likelihood of 301 conditions in one’s future visits. When trained and evaluated on the data from nearly 1.6 million individuals, BEHRT shows a striking improvement of 8.0–13.2\% (in terms of average precision scores for different tasks), over the existing state-of-the-art deep EHR models. In addition to its scalability and superior accuracy, BEHRT enables personalised interpretation of its predictions; its flexible architecture enables it to incorporate multiple heterogeneous concepts (e.g., diagnosis, medication, measurements, and more) to further improve the accuracy of its predictions; its (pre-)training results in disease and patient representations can be useful for future studies (i.e., transfer learning).},
	language = {en},
	number = {1},
	urldate = {2023-10-09},
	journal = {Scientific Reports},
	author = {Li, Yikuan and Rao, Shishir and Solares, José Roberto Ayala and Hassaine, Abdelaali and Ramakrishnan, Rema and Canoy, Dexter and Zhu, Yajie and Rahimi, Kazem and Salimi-Khorshidi, Gholamreza},
	month = apr,
	year = {2020},
	keywords = {notion},
	pages = {7155},
}

@misc{li_hi-behrt_2021,
	title = {Hi-{BEHRT}: {Hierarchical} {Transformer}-based model for accurate prediction of clinical events using multimodal longitudinal electronic health records},
	shorttitle = {Hi-{BEHRT}},
	url = {http://arxiv.org/abs/2106.11360},
	abstract = {Electronic health records represent a holistic overview of patients' trajectories. Their increasing availability has fueled new hopes to leverage them and develop accurate risk prediction models for a wide range of diseases. Given the complex interrelationships of medical records and patient outcomes, deep learning models have shown clear merits in achieving this goal. However, a key limitation of these models remains their capacity in processing long sequences. Capturing the whole history of medical encounters is expected to lead to more accurate predictions, but the inclusion of records collected for decades and from multiple resources can inevitably exceed the receptive field of the existing deep learning architectures. This can result in missing crucial, long-term dependencies. To address this gap, we present Hi-BEHRT, a hierarchical Transformer-based model that can significantly expand the receptive field of Transformers and extract associations from much longer sequences. Using a multimodal large-scale linked longitudinal electronic health records, the Hi-BEHRT exceeds the state-of-the-art BEHRT 1\% to 5\% for area under the receiver operating characteristic (AUROC) curve and 3\% to 6\% for area under the precision recall (AUPRC) curve on average, and 3\% to 6\% (AUROC) and 3\% to 11\% (AUPRC) for patients with long medical history for 5-year heart failure, diabetes, chronic kidney disease, and stroke risk prediction. Additionally, because pretraining for hierarchical Transformer is not well-established, we provide an effective end-to-end contrastive pre-training strategy for Hi-BEHRT using EHR, improving its transferability on predicting clinical events with relatively small training dataset.},
	urldate = {2023-10-09},
	publisher = {arXiv},
	author = {Li, Yikuan and Mamouei, Mohammad and Salimi-Khorshidi, Gholamreza and Rao, Shishir and Hassaine, Abdelaali and Canoy, Dexter and Lukasiewicz, Thomas and Rahimi, Kazem},
	month = jun,
	year = {2021},
	note = {arXiv:2106.11360 [cs]},
	keywords = {Computer Science - Machine Learning, notion},
}

@article{meng_brltm_2021,
	title = {{BRLTM}: {Bidirectional} {Representation} {Learning} {From} {Transformers} {Using} {Multimodal} {Electronic} {Health} {Record} {Data} to {Predict} {Depression}},
	volume = {25},
	issn = {2168-2194, 2168-2208},
	url = {https://ieeexplore.ieee.org/document/9369833/},
	doi = {10.1109/JBHI.2021.3063721},
	abstract = {Advancements in machine learning algorithms have had a beneficial impact on representation learning, classification, and prediction models built using electronic health record (EHR) data. Effort has been put both on increasing models’ overall performance as well as improving their interpretability, particularly regarding the decision-making process. In this study, we present a temporal deep learning model to perform bidirectional representation learning on EHR sequences with a transformer architecture to predict future diagnosis of depression. This model is able to aggregate five heterogenous and high-dimensional data sources from the EHR and process them in a temporal manner for chronic disease prediction at various prediction windows. We applied the current trend of pretraining and fine-tuning on EHR data to outperform the current state-ofthe-art in chronic disease prediction, and to demonstrate the underlying relation between EHR codes in the sequence. The model generated the highest increases of precision-recall area under the curve (PRAUC) from 0.70 to 0.76 in depression prediction compared to the best baseline model. Furthermore, the self-attention weights in each sequence quantitatively demonstrated the inner relationship between various codes, which improved the model’s interpretability. These results demonstrate the model’s ability to utilize heterogeneous EHR data to predict depression while achieving high accuracy and interpretability, which may facilitate constructing clinical decision support systems in the future for chronic disease screening and early detection.},
	language = {en},
	number = {8},
	urldate = {2023-12-13},
	journal = {IEEE Journal of Biomedical and Health Informatics},
	author = {Meng, Yiwen and Speier, William and Ong, Michael K. and Arnold, Corey W.},
	month = aug,
	year = {2021},
	keywords = {notion},
	pages = {3121--3129},
}

@inproceedings{poulain_gt-behrt_2023,
	title = {{GT}-{BEHRT}: {Graph} {Transformers} on {EHRs}: {Better} {Representation} {Improves} {Downstream} {Performance}},
	shorttitle = {Graph {Transformers} on {EHRs}},
	url = {https://openreview.net/forum?id=pe0Vdv7rsL},
	abstract = {Following the success of transformer-based methods across various machine learning applications, their adoption to healthcare predictive tasks using electronic health records (EHR) has also expanded extensively. Similarly, graph-based methods have been shown to be very effective in capturing inherent graph-type relationships in EHRs, leading to improved downstream performance. Although integrating these two families of approaches seems like a natural next step, in practice, creating such a design is challenging and has not been done. This is partly due to known EHR problems, such as high sparsity, making extracting meaningful temporal representations of medical visits challenging. In this study, we propose GT-BEHRT, a new approach that leverages temporal visit embeddings extracted from a graph transformer and uses a BERT-based model to obtain more robust patient representations, especially on longer EHR sequences. The graph-based approach allows GT-BEHRT to implicitly capture the intrinsic graphical relationships between medical observations, while the BERT model extracts the temporal relationships between visits, loosely mimicking the clinicians' decision-making process. As part of our method, we also present a two-step pre-training strategy for learning better graphical and temporal representations. Our proposed method achieves state-of-the-art performance in a variety of standard medical predictive tasks, demonstrating the versatility of our approach.},
	language = {en},
	urldate = {2024-02-09},
	author = {Poulain, Raphael and Beheshti, Rahmatollah},
	month = oct,
	year = {2023},
	keywords = {notion},
}

@article{prakash_rarebert_2021,
	title = {{RareBERT}: {Transformer} {Architecture} for {Rare} {Disease} {Patient} {Identification} using {Administrative} {Claims}},
	volume = {35},
	copyright = {Copyright (c) 2021 Association for the Advancement of Artificial Intelligence},
	issn = {2374-3468},
	shorttitle = {{RareBERT}},
	url = {https://ojs.aaai.org/index.php/AAAI/article/view/16122},
	doi = {10.1609/aaai.v35i1.16122},
	abstract = {A rare disease is any disease that affects a very small percentage (1 in 1,500) of population. It is estimated that there are nearly 7,000 rare disease affecting 30 million patients in the U. S. alone. Most of the patients suffering from rare diseases experience multiple misdiagnoses and may never be diagnosed correctly. This is largely driven by the low prevalence of the disease that results in a lack of awareness among healthcare providers. There have been efforts from machine learning researchers to develop predictive models to help diagnose patients using healthcare datasets such as electronic health records and administrative claims. Most recently, transformer models have been applied to predict diseases BEHRT, G-BERT and Med-BERT. However, these have been developed specifically for electronic health records (EHR) and have not been designed to address rare disease challenges such as class imbalance, partial longitudinal data capture, and noisy labels. As a result, they deliver poor performance in predicting rare diseases compared with baselines. Besides, EHR datasets are generally confined to the hospital systems using them and do not capture a wider sample of patients thus limiting the availability of sufficient rare dis-ease patients in the dataset. To address these challenges, we introduced an extension of the BERT model tailored for rare disease diagnosis called RareBERT which has been trained on administrative claims datasets. RareBERT extends Med-BERT by including context embedding and temporal reference embedding. Moreover, we introduced a novel adaptive loss function to handle the class imbal-ance. In this paper, we show our experiments on diagnosing X-Linked Hypophosphatemia (XLH), a genetic rare disease. While RareBERT performs significantly better than the baseline models (79.9\% AUPRC versus 30\% AUPRC for Med-BERT), owing to the transformer architecture, it also shows its robustness in partial longitudinal data capture caused by poor capture of claims with a drop in performance of only 1.35\% AUPRC, compared with 12\% for Med-BERT and 33.0\% for LSTM and 67.4\% for boosting trees based baseline.},
	language = {en},
	number = {1},
	urldate = {2024-01-11},
	journal = {Proceedings of the AAAI Conference on Artificial Intelligence},
	author = {Prakash, P. K. S. and Chilukuri, Srinivas and Ranade, Nikhil and Viswanathan, Shankar},
	month = may,
	year = {2021},
	note = {Number: 1},
	keywords = {(Deep) Neural Network Algorithms, notion},
	pages = {453--460},
}

@article{rasmy_med-bert_2021,
	title = {Med-{BERT}: pretrained contextualized embeddings on large-scale structured electronic health records for disease prediction},
	volume = {4},
	issn = {2398-6352},
	shorttitle = {Med-{BERT}},
	url = {https://www.nature.com/articles/s41746-021-00455-y},
	doi = {10.1038/s41746-021-00455-y},
	abstract = {Abstract
            Deep learning (DL)-based predictive models from electronic health records (EHRs) deliver impressive performance in many clinical tasks. Large training cohorts, however, are often required by these models to achieve high accuracy, hindering the adoption of DL-based models in scenarios with limited training data. Recently, bidirectional encoder representations from transformers (BERT) and related models have achieved tremendous successes in the natural language processing domain. The pretraining of BERT on a very large training corpus generates contextualized embeddings that can boost the performance of models trained on smaller datasets. Inspired by BERT, we propose Med-BERT, which adapts the BERT framework originally developed for the text domain to the structured EHR domain. Med-BERT is a contextualized embedding model pretrained on a structured EHR dataset of 28,490,650 patients. Fine-tuning experiments showed that Med-BERT substantially improves the prediction accuracy, boosting the area under the receiver operating characteristics curve (AUC) by 1.21–6.14\% in two disease prediction tasks from two clinical databases. In particular, pretrained Med-BERT obtains promising performances on tasks with small fine-tuning training sets and can boost the AUC by more than 20\% or obtain an AUC as high as a model trained on a training set ten times larger, compared with deep learning models without Med-BERT. We believe that Med-BERT will benefit disease prediction studies with small local training datasets, reduce data collection expenses, and accelerate the pace of artificial intelligence aided healthcare.},
	language = {en},
	number = {1},
	urldate = {2023-10-09},
	journal = {npj Digital Medicine},
	author = {Rasmy, Laila and Xiang, Yang and Xie, Ziqian and Tao, Cui and Zhi, Degui},
	month = may,
	year = {2021},
	keywords = {notion},
	pages = {86},
}

@incollection{rupp_exbehrt_2023,
	title = {{ExBEHRT}: {Extended} {Transformer} for {Electronic} {Health} {Records} to {Predict} {Disease} {Subtypes} \& {Progressions}},
	volume = {13932},
	shorttitle = {{ExBEHRT}},
	url = {http://arxiv.org/abs/2303.12364},
	abstract = {In this study, we introduce ExBEHRT, an extended version of BEHRT (BERT applied to electronic health records), and apply different algorithms to interpret its results. While BEHRT considers only diagnoses and patient age, we extend the feature space to several multimodal records, namely demographics, clinical characteristics, vital signs, smoking status, diagnoses, procedures, medications, and laboratory tests, by applying a novel method to unify the frequencies and temporal dimensions of the different features. We show that additional features significantly improve model performance for various downstream tasks in different diseases. To ensure robustness, we interpret model predictions using an adaptation of expected gradients, which has not been previously applied to transformers with EHR data and provides more granular interpretations than previous approaches such as feature and token importances. Furthermore, by clustering the model representations of oncology patients, we show that the model has an implicit understanding of the disease and is able to classify patients with the same cancer type into different risk groups. Given the additional features and interpretability, ExBEHRT can help make informed decisions about disease trajectories, diagnoses, and risk factors of various diseases.},
	urldate = {2023-12-13},
	author = {Rupp, Maurice and Peter, Oriane and Pattipaka, Thirupathi},
	year = {2023},
	doi = {10.1007/978-3-031-39539-0_7},
	note = {arXiv:2303.12364 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning, notion},
	pages = {73--84},
}

@article{savcisens_life2vec_2023,
	title = {life2vec: {Using} {Sequences} of {Life}-events to {Predict} {Human} {Lives}},
	issn = {2662-8457},
	url = {http://arxiv.org/abs/2306.03009},
	doi = {10.1038/s43588-023-00573-5},
	abstract = {Over the past decade, machine learning has revolutionized computers' ability to analyze text through flexible computational models. Due to their structural similarity to written language, transformer-based architectures have also shown promise as tools to make sense of a range of multi-variate sequences from protein-structures, music, electronic health records to weather-forecasts. We can also represent human lives in a way that shares this structural similarity to language. From one perspective, lives are simply sequences of events: People are born, visit the pediatrician, start school, move to a new location, get married, and so on. Here, we exploit this similarity to adapt innovations from natural language processing to examine the evolution and predictability of human lives based on detailed event sequences. We do this by drawing on arguably the most comprehensive registry data in existence, available for an entire nation of more than six million individuals across decades. Our data include information about life-events related to health, education, occupation, income, address, and working hours, recorded with day-to-day resolution. We create embeddings of life-events in a single vector space showing that this embedding space is robust and highly structured. Our models allow us to predict diverse outcomes ranging from early mortality to personality nuances, outperforming state-of-the-art models by a wide margin. Using methods for interpreting deep learning models, we probe the algorithm to understand the factors that enable our predictions. Our framework allows researchers to identify new potential mechanisms that impact life outcomes and associated possibilities for personalized interventions.},
	urldate = {2024-01-08},
	journal = {Nature Computational Science},
	author = {Savcisens, Germans and Eliassi-Rad, Tina and Hansen, Lars Kai and Mortensen, Laust and Lilleholt, Lau and Rogers, Anna and Zettler, Ingo and Lehmann, Sune},
	month = dec,
	year = {2023},
	note = {arXiv:2306.03009 [cs, stat]},
	keywords = {Computer Science - Machine Learning, Statistics - Applications, Statistics - Machine Learning, notion},
}

@article{tipirneni_strats_2022,
	title = {{STraTS}: {Self}-{Supervised} {Transformer} for {Sparse} and {Irregularly} {Sampled} {Multivariate} {Clinical} {Time}-{Series}},
	volume = {16},
	issn = {1556-4681, 1556-472X},
	url = {https://dl.acm.org/doi/10.1145/3516367},
	doi = {10.1145/3516367},
	abstract = {Multivariate time-series data are frequently observed in critical care settings and are typically characterized by sparsity (missing information) and irregular time intervals. Existing approaches for learning representations in this domain handle these challenges by either aggregation or imputation of values, which in-turn suppresses the fine-grained information and adds undesirable noise/overhead into the machine learning model. To tackle this problem, we propose a
              S
              elf-supervised
              Tra
              nsformer for
              T
              ime-
              S
              eries (STraTS) model, which overcomes these pitfalls by treating time-series as a set of observation triplets instead of using the standard dense matrix representation. It employs a novel Continuous Value Embedding technique to encode continuous time and variable values without the need for discretization. It is composed of a Transformer component with multi-head attention layers, which enable it to learn contextual triplet embeddings while avoiding the problems of recurrence and vanishing gradients that occur in recurrent architectures. In addition, to tackle the problem of limited availability of labeled data (which is typically observed in many healthcare applications), STraTS utilizes self-supervision by leveraging unlabeled data to learn better representations by using time-series forecasting as an auxiliary proxy task. Experiments on real-world multivariate clinical time-series benchmark datasets demonstrate that STraTS has better prediction performance than state-of-the-art methods for mortality prediction, especially when labeled data is limited. Finally, we also present an interpretable version of STraTS, which can identify important measurements in the time-series data. Our data preprocessing and model implementation codes are available at
              https://github.com/sindhura97/STraTS
              .},
	language = {en},
	number = {6},
	urldate = {2023-09-14},
	journal = {ACM Transactions on Knowledge Discovery from Data},
	author = {Tipirneni, Sindhu and Reddy, Chandan K.},
	month = dec,
	year = {2022},
	keywords = {notion},
	pages = {1--17},
}

@misc{van_de_water_yet_2024,
	title = {Yet {Another} {ICU} {Benchmark}: {A} {Flexible} {Multi}-{Center} {Framework} for {Clinical} {ML}},
	shorttitle = {Yet {Another} {ICU} {Benchmark}},
	url = {http://arxiv.org/abs/2306.05109},
	abstract = {Medical applications of machine learning (ML) have experienced a surge in popularity in recent years. The intensive care unit (ICU) is a natural habitat for ML given the abundance of available data from electronic health records. Models have been proposed to address numerous ICU prediction tasks like the early detection of complications. While authors frequently report state-of-the-art performance, it is challenging to verify claims of superiority. Datasets and code are not always published, and cohort definitions, preprocessing pipelines, and training setups are difficult to reproduce. This work introduces Yet Another ICU Benchmark (YAIB), a modular framework that allows researchers to define reproducible and comparable clinical ML experiments; we offer an end-to-end solution from cohort definition to model evaluation. The framework natively supports most open-access ICU datasets (MIMIC III/IV, eICU, HiRID, AUMCdb) and is easily adaptable to future ICU datasets. Combined with a transparent preprocessing pipeline and extensible training code for multiple ML and deep learning models, YAIB enables unified model development. Our benchmark comes with five predefined established prediction tasks (mortality, acute kidney injury, sepsis, kidney function, and length of stay) developed in collaboration with clinicians. Adding further tasks is straightforward by design. Using YAIB, we demonstrate that the choice of dataset, cohort definition, and preprocessing have a major impact on the prediction performance - often more so than model class - indicating an urgent need for YAIB as a holistic benchmarking tool. We provide our work to the clinical ML community to accelerate method development and enable real-world clinical implementations. Software Repository: https://github.com/rvandewater/YAIB.},
	urldate = {2024-02-09},
	publisher = {arXiv},
	author = {van de Water, Robin and Schmidt, Hendrik and Elbers, Paul and Thoral, Patrick and Arnrich, Bert and Rockenschaub, Patrick},
	month = jan,
	year = {2024},
	note = {arXiv:2306.05109 [cs]},
	keywords = {Computer Science - Machine Learning},
}

@article{wiens_machine_2018,
	title = {Machine {Learning} for {Healthcare}: {On} the {Verge} of a {Major} {Shift} in {Healthcare} {Epidemiology}},
	volume = {66},
	issn = {1058-4838, 1537-6591},
	shorttitle = {Machine {Learning} for {Healthcare}},
	url = {https://academic.oup.com/cid/article/66/1/149/4085880},
	doi = {10.1093/cid/cix731},
	language = {en},
	number = {1},
	urldate = {2024-07-31},
	journal = {Clinical Infectious Diseases},
	author = {Wiens, Jenna and Shenoy, Erica S},
	month = jan,
	year = {2018},
	keywords = {notion},
	pages = {149--153},
}

@misc{wornow_ehrshot_2023,
	title = {{EHRSHOT}: {An} {EHR} {Benchmark} for {Few}-{Shot} {Evaluation} of {Foundation} {Models}},
	shorttitle = {{EHRSHOT}},
	url = {http://arxiv.org/abs/2307.02028},
	doi = {10.48550/arXiv.2307.02028},
	abstract = {While the general machine learning (ML) community has benefited from public datasets, tasks, and models, the progress of ML in healthcare has been hampered by a lack of such shared assets. The success of foundation models creates new challenges for healthcare ML by requiring access to shared pretrained models to validate performance benefits. We help address these challenges through three contributions. First, we publish a new dataset, EHRSHOT, which contains deidentified structured data from the electronic health records (EHRs) of 6,739 patients from Stanford Medicine. Unlike MIMIC-III/IV and other popular EHR datasets, EHRSHOT is longitudinal and not restricted to ICU/ED patients. Second, we publish the weights of CLMBR-T-base, a 141M parameter clinical foundation model pretrained on the structured EHR data of 2.57M patients. We are one of the first to fully release such a model for coded EHR data; in contrast, most prior models released for clinical data (e.g. GatorTron, ClinicalBERT) only work with unstructured text and cannot process the rich, structured data within an EHR. We provide an end-to-end pipeline for the community to validate and build upon its performance. Third, we define 15 few-shot clinical prediction tasks, enabling evaluation of foundation models on benefits such as sample efficiency and task adaptation. Our model and dataset are available via a research data use agreement from our website: https://ehrshot.stanford.edu. Code to reproduce our results are available at our Github repo: https://github.com/som-shahlab/ehrshot-benchmark},
	urldate = {2024-01-11},
	publisher = {arXiv},
	author = {Wornow, Michael and Thapa, Rahul and Steinberg, Ethan and Fries, Jason A. and Shah, Nigam H.},
	month = dec,
	year = {2023},
	note = {arXiv:2307.02028 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language, Computer Science - Machine Learning, notion},
}

