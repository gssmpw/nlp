
@misc{akiba_optuna_2019,
	title = {Optuna: {A} {Next}-generation {Hyperparameter} {Optimization} {Framework}},
	shorttitle = {Optuna},
	url = {http://arxiv.org/abs/1907.10902},
	doi = {10.48550/arXiv.1907.10902},
	abstract = {The purpose of this study is to introduce new design-criteria for next-generation hyperparameter optimization software. The criteria we propose include (1) define-by-run API that allows users to construct the parameter search space dynamically, (2) efficient implementation of both searching and pruning strategies, and (3) easy-to-setup, versatile architecture that can be deployed for various purposes, ranging from scalable distributed computing to light-weight experiment conducted via interactive interface. In order to prove our point, we will introduce Optuna, an optimization software which is a culmination of our effort in the development of a next generation optimization software. As an optimization software designed with define-by-run principle, Optuna is particularly the first of its kind. We will present the design-techniques that became necessary in the development of the software that meets the above criteria, and demonstrate the power of our new design through experimental results and real world applications. Our software is available under the MIT license (https://github.com/pfnet/optuna/).},
	urldate = {2024-08-16},
	publisher = {arXiv},
	author = {Akiba, Takuya and Sano, Shotaro and Yanase, Toshihiko and Ohta, Takeru and Koyama, Masanori},
	month = jul,
	year = {2019},
	note = {arXiv:1907.10902 [cs, stat]},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, notion},
}

@misc{gorishniy_embeddings_2023,
	title = {On {Embeddings} for {Numerical} {Features} in {Tabular} {Deep} {Learning}},
	url = {http://arxiv.org/abs/2203.05556},
	abstract = {Recently, Transformer-like deep architectures have shown strong performance on tabular data problems. Unlike traditional models, e.g., MLP, these architectures map scalar values of numerical features to high-dimensional embeddings before mixing them in the main backbone. In this work, we argue that embeddings for numerical features are an underexplored degree of freedom in tabular DL, which allows constructing more powerful DL models and competing with gradient boosted decision trees (GBDT) on some GBDT-friendly benchmarks (that is, where GBDT outperforms conventional DL models). We start by describing two conceptually different approaches to building embedding modules: the first one is based on a piecewise linear encoding of scalar values, and the second one utilizes periodic activations. Then, we empirically demonstrate that these two approaches can lead to significant performance boosts compared to the embeddings based on conventional blocks such as linear layers and ReLU activations. Importantly, we also show that embedding numerical features is beneficial for many backbones, not only for Transformers. Specifically, after proper embeddings, simple MLP-like models can perform on par with the attention-based architectures. Overall, we highlight embeddings for numerical features as an important design aspect with good potential for further improvements in tabular DL. The source code is available at https://github.com/yandex-research/tabular-dl-num-embeddings.},
	language = {en},
	urldate = {2024-08-14},
	publisher = {arXiv},
	author = {Gorishniy, Yury and Rubachev, Ivan and Babenko, Artem},
	month = oct,
	year = {2023},
	note = {arXiv:2203.05556 [cs]},
	keywords = {Computer Science - Machine Learning, notion},
}

@misc{faltys_hirid_2021,
	title = {{HiRID}, a high time-resolution {ICU} dataset (version 1.1.1)},
	url = {https://physionet.org/content/hirid/1.1.1/},
	doi = {10.13026/NKWC-JS72},
	abstract = {HiRID is a freely accessible critical care dataset containing data relating to
almost 34 thousand patient admissions to the Department of Intensive Care
Medicine of the Bern University Hospital, Switzerland (ICU), an
interdisciplinary 60-bed unit admitting {\textgreater}6,500 patients per year. The ICU
offers the full range of modern interdisciplinary intensive care medicine for
adult patients. The dataset was developed in cooperation between the Swiss
Federal Institute of Technology (ETH) Zurich, Switzerland and the ICU.

The dataset contains de-identified demographic information and a total of 681
routinely collected physiological variables, diagnostic test results and
treatment parameters from almost 34 thousand admissions during the period from
January 2008 to June 2016. Data is stored with a uniquely high time resolution
of one entry every two minutes.},
	urldate = {2024-07-30},
	publisher = {PhysioNet},
	author = {Faltys, Martin and Zimmermann, Marc and Lyu, Xinrui and Hüser, Matthias and Hyland, Stephanie and Rätsch, Gunnar and Merz, Tobias},
	year = {2021},
}

@inproceedings{arnrich_medical_2024,
	title = {Medical {Event} {Data} {Standard} ({MEDS}): {Facilitating} {Machine} {Learning} for {Health}},
	shorttitle = {Medical {Event} {Data} {Standard} ({MEDS})},
	url = {https://openreview.net/forum?id=IsHy2ebjIG},
	abstract = {We introduce the Medical Event Data Standard (MEDS), a lightweight schema for enabling machine learning over electronic health record (EHR) data. Unlike common data models and data interoperability formats, MEDS is a minimal standard designed for maximum interoperability across datasets, existing tools, and model architectures. By providing a simple standardization layer between datasets and model-specific code, MEDS will enable more reproducible, robust, computationally performant, and collaborative machine learning research using EHR data. We highlight several existing MEDS integrations with models, datasets, and tools, and invite the community for further development and adoption.},
	language = {en},
	urldate = {2024-08-09},
	author = {Arnrich, Bert and Choi, Edward and Fries, Jason A. and McDermott, Matthew B. A. and Oh, Jungwoo and Pollard, Tom J. and Shah, Nigam and Steinberg, Ethan and Wornow, Michael and Water, Robin van de},
	month = mar,
	year = {2024},
	keywords = {notion},
}

@misc{wolf_huggingfaces_2020,
	title = {{HuggingFace}'s {Transformers}: {State}-of-the-art {Natural} {Language} {Processing}},
	shorttitle = {{HuggingFace}'s {Transformers}},
	url = {http://arxiv.org/abs/1910.03771},
	doi = {10.48550/arXiv.1910.03771},
	abstract = {Recent progress in natural language processing has been driven by advances in both model architecture and model pretraining. Transformer architectures have facilitated building higher-capacity models and pretraining has made it possible to effectively utilize this capacity for a wide variety of tasks. {\textbackslash}textit\{Transformers\} is an open-source library with the goal of opening up these advances to the wider machine learning community. The library consists of carefully engineered state-of-the art Transformer architectures under a unified API. Backing this library is a curated collection of pretrained models made by and available for the community. {\textbackslash}textit\{Transformers\} is designed to be extensible by researchers, simple for practitioners, and fast and robust in industrial deployments. The library is available at {\textbackslash}url\{https://github.com/huggingface/transformers\}.},
	urldate = {2024-08-07},
	publisher = {arXiv},
	author = {Wolf, Thomas and Debut, Lysandre and Sanh, Victor and Chaumond, Julien and Delangue, Clement and Moi, Anthony and Cistac, Pierric and Rault, Tim and Louf, Rémi and Funtowicz, Morgan and Davison, Joe and Shleifer, Sam and von Platen, Patrick and Ma, Clara and Jernite, Yacine and Plu, Julien and Xu, Canwen and Scao, Teven Le and Gugger, Sylvain and Drame, Mariama and Lhoest, Quentin and Rush, Alexander M.},
	month = jul,
	year = {2020},
	note = {arXiv:1910.03771 [cs]},
	keywords = {Computer Science - Computation and Language, notion},
}

@misc{lea_temporal_2016,
	title = {Temporal {Convolutional} {Networks}: {A} {Unified} {Approach} to {Action} {Segmentation}},
	shorttitle = {Temporal {Convolutional} {Networks}},
	url = {http://arxiv.org/abs/1608.08242},
	doi = {10.48550/arXiv.1608.08242},
	abstract = {The dominant paradigm for video-based action segmentation is composed of two steps: first, for each frame, compute low-level features using Dense Trajectories or a Convolutional Neural Network that encode spatiotemporal information locally, and second, input these features into a classifier that captures high-level temporal relationships, such as a Recurrent Neural Network (RNN). While often effective, this decoupling requires specifying two separate models, each with their own complexities, and prevents capturing more nuanced long-range spatiotemporal relationships. We propose a unified approach, as demonstrated by our Temporal Convolutional Network (TCN), that hierarchically captures relationships at low-, intermediate-, and high-level time-scales. Our model achieves superior or competitive performance using video or sensor data on three public action segmentation datasets and can be trained in a fraction of the time it takes to train an RNN.},
	urldate = {2024-08-07},
	publisher = {arXiv},
	author = {Lea, Colin and Vidal, Rene and Reiter, Austin and Hager, Gregory D.},
	month = aug,
	year = {2016},
	note = {arXiv:1608.08242 [cs]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, notion},
}

@inproceedings{ke_lightgbm_2017,
	title = {{LightGBM}: {A} {Highly} {Efficient} {Gradient} {Boosting} {Decision} {Tree}},
	volume = {30},
	shorttitle = {{LightGBM}},
	url = {https://proceedings.neurips.cc/paper_files/paper/2017/hash/6449f44a102fde848669bdd9eb6b76fa-Abstract.html},
	abstract = {Gradient Boosting Decision Tree (GBDT) is a popular machine learning algorithm, and has quite a few effective implementations such as XGBoost and pGBRT. Although many engineering optimizations have been adopted in these implementations, the efficiency and scalability are still unsatisfactory when the feature dimension is high and data size is large. A major reason is that for each feature, they need to scan all the data instances to estimate the information gain of all possible split points, which is very time consuming. To tackle this problem, we propose two novel techniques: {\textbackslash}emph\{Gradient-based One-Side Sampling\} (GOSS) and {\textbackslash}emph\{Exclusive Feature Bundling\} (EFB). With GOSS, we exclude a significant proportion of data instances with small gradients, and only use the rest to estimate the information gain. We prove that, since the data instances with larger gradients play a more important role in the computation of information gain, GOSS can obtain quite accurate estimation of the information gain with a much smaller data size. With EFB, we bundle mutually exclusive features (i.e., they rarely take nonzero values simultaneously), to reduce the number of features. We prove that finding the optimal bundling of exclusive features is NP-hard, but a greedy algorithm can achieve quite good approximation ratio (and thus can effectively reduce the number of features without hurting the accuracy of split point determination by much). We call our new GBDT implementation with GOSS and EFB {\textbackslash}emph\{LightGBM\}. Our experiments on multiple public datasets show that, LightGBM speeds up the training process of conventional GBDT by up to over 20 times while achieving almost the same accuracy.},
	urldate = {2024-08-07},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	publisher = {Curran Associates, Inc.},
	author = {Ke, Guolin and Meng, Qi and Finley, Thomas and Wang, Taifeng and Chen, Wei and Ma, Weidong and Ye, Qiwei and Liu, Tie-Yan},
	year = {2017},
	keywords = {notion},
}

@misc{cho_learning_2014,
	title = {Learning {Phrase} {Representations} using {RNN} {Encoder}-{Decoder} for {Statistical} {Machine} {Translation}},
	url = {http://arxiv.org/abs/1406.1078},
	doi = {10.48550/arXiv.1406.1078},
	abstract = {In this paper, we propose a novel neural network model called RNN Encoder-Decoder that consists of two recurrent neural networks (RNN). One RNN encodes a sequence of symbols into a fixed-length vector representation, and the other decodes the representation into another sequence of symbols. The encoder and decoder of the proposed model are jointly trained to maximize the conditional probability of a target sequence given a source sequence. The performance of a statistical machine translation system is empirically found to improve by using the conditional probabilities of phrase pairs computed by the RNN Encoder-Decoder as an additional feature in the existing log-linear model. Qualitatively, we show that the proposed model learns a semantically and syntactically meaningful representation of linguistic phrases.},
	urldate = {2024-08-07},
	publisher = {arXiv},
	author = {Cho, Kyunghyun and van Merrienboer, Bart and Gulcehre, Caglar and Bahdanau, Dzmitry and Bougares, Fethi and Schwenk, Holger and Bengio, Yoshua},
	month = sep,
	year = {2014},
	note = {arXiv:1406.1078 [cs, stat]},
	keywords = {Computer Science - Computation and Language, Computer Science - Machine Learning, Computer Science - Neural and Evolutionary Computing, Statistics - Machine Learning, notion},
}

@inproceedings{chen_xgboost_2016,
	title = {{XGBoost}: {A} {Scalable} {Tree} {Boosting} {System}},
	shorttitle = {{XGBoost}},
	url = {http://arxiv.org/abs/1603.02754},
	doi = {10.1145/2939672.2939785},
	abstract = {Tree boosting is a highly effective and widely used machine learning method. In this paper, we describe a scalable end-to-end tree boosting system called XGBoost, which is used widely by data scientists to achieve state-of-the-art results on many machine learning challenges. We propose a novel sparsity-aware algorithm for sparse data and weighted quantile sketch for approximate tree learning. More importantly, we provide insights on cache access patterns, data compression and sharding to build a scalable tree boosting system. By combining these insights, XGBoost scales beyond billions of examples using far fewer resources than existing systems.},
	urldate = {2024-08-07},
	booktitle = {Proceedings of the 22nd {ACM} {SIGKDD} {International} {Conference} on {Knowledge} {Discovery} and {Data} {Mining}},
	author = {Chen, Tianqi and Guestrin, Carlos},
	month = aug,
	year = {2016},
	note = {arXiv:1603.02754 [cs]},
	keywords = {Computer Science - Machine Learning, notion},
	pages = {785--794},
}

@article{hochreiter_long_1997,
	title = {Long {Short}-{Term} {Memory}},
	volume = {9},
	issn = {0899-7667, 1530-888X},
	url = {https://direct.mit.edu/neco/article/9/8/1735-1780/6109},
	doi = {10.1162/neco.1997.9.8.1735},
	abstract = {Learning to store information over extended time intervals by recurrent backpropagation takes a very long time, mostly because of insufficient, decaying error backflow. We briefly review Hochreiter's (1991) analysis of this problem, then address it by introducing a novel, efficient, gradient based method called long short-term memory (LSTM). Truncating the gradient where this does not do harm, LSTM can learn to bridge minimal time lags in excess of 1000 discrete-time steps by enforcing constant error flow through constant error carousels within special units. Multiplicative gate units learn to open and close access to the constant error flow. LSTM is local in space and time; its computational complexity per time step and weight is O. 1. Our experiments with artificial data involve local, distributed, real-valued, and noisy pattern representations. In comparisons with real-time recurrent learning, back propagation through time, recurrent cascade correlation, Elman nets, and neural sequence chunking, LSTM leads to many more successful runs, and learns much faster. LSTM also solves complex, artificial long-time-lag tasks that have never been solved by previous recurrent network algorithms.},
	language = {en},
	number = {8},
	urldate = {2024-08-07},
	journal = {Neural Computation},
	author = {Hochreiter, Sepp and Schmidhuber, Jürgen},
	month = nov,
	year = {1997},
	pages = {1735--1780},
}

@misc{shukla_multi-time_2021,
	title = {Multi-{Time} {Attention} {Networks} for {Irregularly} {Sampled} {Time} {Series}},
	url = {http://arxiv.org/abs/2101.10318},
	doi = {10.48550/arXiv.2101.10318},
	abstract = {Irregular sampling occurs in many time series modeling applications where it presents a significant challenge to standard deep learning models. This work is motivated by the analysis of physiological time series data in electronic health records, which are sparse, irregularly sampled, and multivariate. In this paper, we propose a new deep learning framework for this setting that we call Multi-Time Attention Networks. Multi-Time Attention Networks learn an embedding of continuous-time values and use an attention mechanism to produce a fixed-length representation of a time series containing a variable number of observations. We investigate the performance of this framework on interpolation and classification tasks using multiple datasets. Our results show that the proposed approach performs as well or better than a range of baseline and recently proposed models while offering significantly faster training times than current state-of-the-art methods.},
	urldate = {2024-08-07},
	publisher = {arXiv},
	author = {Shukla, Satya Narayan and Marlin, Benjamin M.},
	month = jun,
	year = {2021},
	note = {arXiv:2101.10318 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning, notion},
}

@misc{zhang_graph-guided_2022,
	title = {Graph-{Guided} {Network} for {Irregularly} {Sampled} {Multivariate} {Time} {Series}},
	url = {http://arxiv.org/abs/2110.05357},
	doi = {10.48550/arXiv.2110.05357},
	abstract = {In many domains, including healthcare, biology, and climate science, time series are irregularly sampled with varying time intervals between successive readouts and different subsets of variables (sensors) observed at different time points. Here, we introduce RAINDROP, a graph neural network that embeds irregularly sampled and multivariate time series while also learning the dynamics of sensors purely from observational data. RAINDROP represents every sample as a separate sensor graph and models time-varying dependencies between sensors with a novel message passing operator. It estimates the latent sensor graph structure and leverages the structure together with nearby observations to predict misaligned readouts. This model can be interpreted as a graph neural network that sends messages over graphs that are optimized for capturing time-varying dependencies among sensors. We use RAINDROP to classify time series and interpret temporal dynamics on three healthcare and human activity datasets. RAINDROP outperforms state-of-the-art methods by up to 11.4\% (absolute F1-score points), including techniques that deal with irregular sampling using fixed discretization and set functions. RAINDROP shows superiority in diverse setups, including challenging leave-sensor-out settings.},
	urldate = {2024-08-07},
	publisher = {arXiv},
	author = {Zhang, Xiang and Zeman, Marko and Tsiligkaridis, Theodoros and Zitnik, Marinka},
	month = mar,
	year = {2022},
	note = {arXiv:2110.05357 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning, notion},
}

@article{kdigo_section_2012,
	series = {{KDIGO} {Clinical} {Practice} {Guideline} for {Acute} {Kidney} {Injury}},
	title = {Section 2: {AKI} {Definition}},
	volume = {2},
	issn = {2157-1716},
	shorttitle = {Section 2},
	url = {https://www.sciencedirect.com/science/article/pii/S2157171615310315},
	doi = {10.1038/kisup.2011.32},
	number = {1},
	urldate = {2024-08-07},
	journal = {Kidney International Supplements},
	author = {{KDIGO}},
	month = mar,
	year = {2012},
	keywords = {notion},
	pages = {19--36},
}

@article{harutyunyan_multitask_2019,
	title = {Multitask learning and benchmarking with clinical time series data},
	volume = {6},
	copyright = {2019 The Author(s)},
	issn = {2052-4463},
	url = {https://www.nature.com/articles/s41597-019-0103-9},
	doi = {10.1038/s41597-019-0103-9},
	abstract = {Health care is one of the most exciting frontiers in data mining and machine learning. Successful adoption of electronic health records (EHRs) created an explosion in digital clinical data available for analysis, but progress in machine learning for healthcare research has been difficult to measure because of the absence of publicly available benchmark data sets. To address this problem, we propose four clinical prediction benchmarks using data derived from the publicly available Medical Information Mart for Intensive Care (MIMIC-III) database. These tasks cover a range of clinical problems including modeling risk of mortality, forecasting length of stay, detecting physiologic decline, and phenotype classification. We propose strong linear and neural baselines for all four tasks and evaluate the effect of deep supervision, multitask training and data-specific architectural modifications on the performance of neural models.},
	language = {en},
	number = {1},
	urldate = {2024-08-01},
	journal = {Scientific Data},
	author = {Harutyunyan, Hrayr and Khachatrian, Hrant and Kale, David C. and Ver Steeg, Greg and Galstyan, Aram},
	month = jun,
	year = {2019},
	note = {Publisher: Nature Publishing Group},
	keywords = {Databases, Disease-free survival, Machine learning, notion},
	pages = {96},
}

@article{ge_interpretable_2018,
	title = {An {Interpretable} {ICU} {Mortality} {Prediction} {Model} {Based} on {Logistic} {Regression} and {Recurrent} {Neural} {Networks} with {LSTM} units.},
	volume = {2018},
	issn = {1942-597X},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6371274/},
	abstract = {Most existing studies used logistic regression to establish scoring systems to predict intensive care unit (ICU) mortality. Machine learning-based approaches can achieve higher prediction accuracy but, unlike the scoring systems, frequently cannot provide explicit interpretability. We evaluated an interpretable ICU mortality prediction model based on Recurrent Neural Networks (RNN) with long short-term memory(LSTM)units. This model combines both sequential features with multiple values over the patient’s hospitalization (e.g. vital signs or laboratory tests) and non-sequential features (e.g. diagnoses), while identifying features that most strongly contribute to the outcome. Using a set of 4,896 MICU admissions from a large medical center, the model achieved a c-statistic for prediction of ICU mortality of 0.7614 compared to 0.7412 for a logistic regression model that used the same data, and identified clinically valid predictors (e.g. DNR designation or diagnosis of disseminated intravascular coagulation). Further research is needed to improve interpretability of sequential features analysis and generalizability.},
	urldate = {2024-07-31},
	journal = {AMIA Annual Symposium Proceedings},
	author = {Ge, Wendong and Huh, Jin-Won and Park, Yu Rang and Lee, Jae-Ho and Kim, Young-Hak and Turchin, Alexander},
	month = dec,
	year = {2018},
	pmid = {30815086},
	pmcid = {PMC6371274},
	keywords = {notion},
	pages = {460--469},
}

@article{kong_using_2020,
	title = {Using machine learning methods to predict in-hospital mortality of sepsis patients in the {ICU}},
	volume = {20},
	issn = {1472-6947},
	url = {https://doi.org/10.1186/s12911-020-01271-2},
	doi = {10.1186/s12911-020-01271-2},
	abstract = {Early and accurate identification of sepsis patients with high risk of in-hospital death can help physicians in intensive care units (ICUs) make optimal clinical decisions. This study aimed to develop machine learning-based tools to predict the risk of hospital death of patients with sepsis in ICUs.},
	language = {en},
	number = {1},
	urldate = {2024-07-31},
	journal = {BMC Medical Informatics and Decision Making},
	author = {Kong, Guilan and Lin, Ke and Hu, Yonghua},
	month = oct,
	year = {2020},
	keywords = {In-hospital mortality, Intensive care unit, Machine learning, Prediction model, Sepsis, notion},
	pages = {251},
}

@article{wiens_machine_2018,
	title = {Machine {Learning} for {Healthcare}: {On} the {Verge} of a {Major} {Shift} in {Healthcare} {Epidemiology}},
	volume = {66},
	issn = {1058-4838, 1537-6591},
	shorttitle = {Machine {Learning} for {Healthcare}},
	url = {https://academic.oup.com/cid/article/66/1/149/4085880},
	doi = {10.1093/cid/cix731},
	language = {en},
	number = {1},
	urldate = {2024-07-31},
	journal = {Clinical Infectious Diseases},
	author = {Wiens, Jenna and Shenoy, Erica S},
	month = jan,
	year = {2018},
	keywords = {notion},
	pages = {149--153},
}

@article{hirsch_icd-10_2016,
	title = {{ICD}-10: {History} and {Context}},
	volume = {37},
	issn = {0195-6108, 1936-959X},
	shorttitle = {{ICD}-10},
	url = {http://www.ajnr.org/lookup/doi/10.3174/ajnr.A4696},
	doi = {10.3174/ajnr.A4696},
	language = {en},
	number = {4},
	urldate = {2024-07-30},
	journal = {American Journal of Neuroradiology},
	author = {Hirsch, J.A. and Nicola, G. and McGinty, G. and Liu, R.W. and Barr, R.M. and Chittle, M.D. and Manchikanti, L.},
	month = apr,
	year = {2016},
	pages = {596--599},
}

@article{moazemi_artificial_2023,
	title = {Artificial intelligence for clinical decision support for monitoring patients in cardiovascular {ICUs}: {A} systematic review},
	volume = {10},
	issn = {2296-858X},
	shorttitle = {Artificial intelligence for clinical decision support for monitoring patients in cardiovascular {ICUs}},
	url = {https://www.frontiersin.org/articles/10.3389/fmed.2023.1109411/full},
	doi = {10.3389/fmed.2023.1109411},
	abstract = {Background
              Artificial intelligence (AI) and machine learning (ML) models continue to evolve the clinical decision support systems (CDSS). However, challenges arise when it comes to the integration of AI/ML into clinical scenarios. In this systematic review, we followed the Preferred Reporting Items for Systematic reviews and Meta-Analyses (PRISMA), the population, intervention, comparator, outcome, and study design (PICOS), and the medical AI life cycle guidelines to investigate studies and tools which address AI/ML-based approaches towards clinical decision support (CDS) for monitoring cardiovascular patients in intensive care units (ICUs). We further discuss recent advances, pitfalls, and future perspectives towards effective integration of AI into routine practices as were identified and elaborated over an extensive selection process for state-of-the-art manuscripts.
            
            
              Methods
              Studies with available English full text from PubMed and Google Scholar in the period from January 2018 to August 2022 were considered. The manuscripts were fetched through a combination of the search keywords including AI, ML, reinforcement learning (RL), deep learning, clinical decision support, and cardiovascular critical care and patients monitoring. The manuscripts were analyzed and filtered based on qualitative and quantitative criteria such as target population, proper study design, cross-validation, and risk of bias.
            
            
              Results
              More than 100 queries over two medical search engines and subjective literature research were developed which identified 89 studies. After extensive assessments of the studies both technically and medically, 21 studies were selected for the final qualitative assessment.
            
            
              Discussion
              Clinical time series and electronic health records (EHR) data were the most common input modalities, while methods such as gradient boosting, recurrent neural networks (RNNs) and RL were mostly used for the analysis. Seventy-five percent of the selected papers lacked validation against external datasets highlighting the generalizability issue. Also, interpretability of the AI decisions was identified as a central issue towards effective integration of AI in healthcare.},
	urldate = {2024-07-30},
	journal = {Frontiers in Medicine},
	author = {Moazemi, Sobhan and Vahdati, Sahar and Li, Jason and Kalkhoff, Sebastian and Castano, Luis J. V. and Dewitz, Bastian and Bibo, Roman and Sabouniaghdam, Parisa and Tootooni, Mohammad S. and Bundschuh, Ralph A. and Lichtenberg, Artur and Aubin, Hug and Schmid, Falko},
	month = mar,
	year = {2023},
	pages = {1109411},
}

@incollection{carbonaro_ai-based_2024,
	title = {{AI}-{Based} {Decision} {Support} {Systems} in {Intensive} {Care}},
	isbn = {978-1-64368-460-4 978-1-64368-461-1},
	url = {https://ebooks.iospress.nl/doi/10.3233/SSW230024},
	abstract = {Intensive Care Units (ICUs) serve a critical role in providing specialized care to critically ill patients in modern healthcare. The ICU environment poses numerous challenges, including high workload, complex decision-making, management of large healthcare data, and the consideration of individual patient needs and preferences. Decision support systems (DSS) in healthcare aim to improve care and aid decision-making by providing person-specific information and recommendations. Recent advancements in Artificial Intelligence (AI) have enabled the development of AI-based DSS, which analyze extensive medical data to identify patterns, make predictions, and personalize care. Various AI models and approaches, such as regression models, decision trees, random forest models, support vector machines, and neural networks have been employed to analyze patient data and help with decision making in the ICU. Evaluation of AI tool performance employs metrics such as accuracy, precision, sensitivity, and specificity, with validation against external databases being necessary. Gaining insights into decision-making factors, integrating subjective factors, and addressing ethical concerns are essential for the acceptance and deployment of AI-DSS in clinical practice. Clarification regarding responsibility, accountability, and the ability for clinicians to override AI-DSS recommendations is necessary to ensure appropriate utilization. While efforts have been made to evaluate AI-DSS in the ICU, most applications remain retrospective and lack clear evidence of improved clinician performance or patient outcomes. The majority of AI models rely on supervised learning for detection and identification tasks, but their efficacy is limited by the scarcity of high-quality data and inadequate consideration of human factors.. Furhtermore, the implementation of AI in the ICU still faces limitations and skepticism from healthcare personnel. Transparent explanations of modeling methods and operational procedures are necessary to instill clinician confidence. Addressing challenges such as the lack of standardized ICU databases and regulatory frameworks is pivotal for widespread adoption of AI in the ICU.},
	urldate = {2024-07-30},
	booktitle = {Studies on the {Semantic} {Web}},
	publisher = {IOS Press},
	author = {Theilen, Raphael and Wittenstein, Jakob},
	editor = {Carbonaro, Antonella and Tiwari, Sanju and Ortiz-Rodriguez, Fernando and Janev, Valentina},
	month = jan,
	year = {2024},
	doi = {10.3233/SSW230024},
}

@article{eini-porat_tell_2022,
	title = {Tell me something interesting: {Clinical} utility of machine learning prediction models in the {ICU}},
	volume = {132},
	issn = {15320464},
	shorttitle = {Tell me something interesting},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S153204642200123X},
	doi = {10.1016/j.jbi.2022.104107},
	language = {en},
	urldate = {2024-07-30},
	journal = {Journal of Biomedical Informatics},
	author = {Eini-Porat, Bar and Amir, Ofra and Eytan, Danny and Shalit, Uri},
	month = aug,
	year = {2022},
	pages = {104107},
}

@misc{vaswani_attention_2017,
	title = {Attention {Is} {All} {You} {Need}},
	url = {http://arxiv.org/abs/1706.03762},
	abstract = {The dominant sequence transduction models are based on complex recurrent or convolutional neural networks in an encoder-decoder configuration. The best performing models also connect the encoder and decoder through an attention mechanism. We propose a new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely. Experiments on two machine translation tasks show these models to be superior in quality while being more parallelizable and requiring significantly less time to train. Our model achieves 28.4 BLEU on the WMT 2014 English-to-German translation task, improving over the existing best results, including ensembles by over 2 BLEU. On the WMT 2014 English-to-French translation task, our model establishes a new single-model state-of-the-art BLEU score of 41.8 after training for 3.5 days on eight GPUs, a small fraction of the training costs of the best models from the literature. We show that the Transformer generalizes well to other tasks by applying it successfully to English constituency parsing both with large and limited training data.},
	urldate = {2023-10-13},
	publisher = {arXiv},
	author = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N. and Kaiser, Lukasz and Polosukhin, Illia},
	year = {2017},
	note = {arXiv:1706.03762 [cs]},
	keywords = {Computer Science - Computation and Language, Computer Science - Machine Learning, notion},
}

@article{goldberger_physiobank_2000,
	title = {{PhysioBank}, {PhysioToolkit}, and {PhysioNet}: {Components} of a {New} {Research} {Resource} for {Complex} {Physiologic} {Signals}},
	volume = {101},
	issn = {0009-7322, 1524-4539},
	shorttitle = {{PhysioBank}, {PhysioToolkit}, and {PhysioNet}},
	url = {https://www.ahajournals.org/doi/10.1161/01.CIR.101.23.e215},
	doi = {10.1161/01.CIR.101.23.e215},
	abstract = {Abstract
              —The newly inaugurated Research Resource for Complex Physiologic Signals, which was created under the auspices of the National Center for Research Resources of the National Institutes of Health, is intended to stimulate current research and new investigations in the study of cardiovascular and other complex biomedical signals. The resource has 3 interdependent components. PhysioBank is a large and growing archive of well-characterized digital recordings of physiological signals and related data for use by the biomedical research community. It currently includes databases of multiparameter cardiopulmonary, neural, and other biomedical signals from healthy subjects and from patients with a variety of conditions with major public health implications, including life-threatening arrhythmias, congestive heart failure, sleep apnea, neurological disorders, and aging. PhysioToolkit is a library of open-source software for physiological signal processing and analysis, the detection of physiologically significant events using both classic techniques and novel methods based on statistical physics and nonlinear dynamics, the interactive display and characterization of signals, the creation of new databases, the simulation of physiological and other signals, the quantitative evaluation and comparison of analysis methods, and the analysis of nonstationary processes. PhysioNet is an on-line forum for the dissemination and exchange of recorded biomedical signals and open-source software for analyzing them. It provides facilities for the cooperative analysis of data and the evaluation of proposed new algorithms. In addition to providing free electronic access to PhysioBank data and PhysioToolkit software via the World Wide Web (http://www.physionet.org), PhysioNet offers services and training via on-line tutorials to assist users with varying levels of expertise.},
	language = {en},
	number = {23},
	urldate = {2024-07-30},
	journal = {Circulation},
	author = {Goldberger, Ary L. and Amaral, Luis A. N. and Glass, Leon and Hausdorff, Jeffrey M. and Ivanov, Plamen Ch. and Mark, Roger G. and Mietus, Joseph E. and Moody, George B. and Peng, Chung-Kang and Stanley, H. Eugene},
	month = jun,
	year = {2000},
}

@article{hyland_early_2020,
	title = {Early prediction of circulatory failure in the intensive care unit using machine learning},
	volume = {26},
	issn = {1078-8956, 1546-170X},
	url = {https://www.nature.com/articles/s41591-020-0789-4},
	doi = {10.1038/s41591-020-0789-4},
	language = {en},
	number = {3},
	urldate = {2024-07-30},
	journal = {Nature Medicine},
	author = {Hyland, Stephanie L. and Faltys, Martin and Hüser, Matthias and Lyu, Xinrui and Gumbsch, Thomas and Esteban, Cristóbal and Bock, Christian and Horn, Max and Moor, Michael and Rieck, Bastian and Zimmermann, Marc and Bodenham, Dean and Borgwardt, Karsten and Rätsch, Gunnar and Merz, Tobias M.},
	month = mar,
	year = {2020},
	pages = {364--373},
}

@article{pollard_eicu_2018,
	title = {The {eICU} {Collaborative} {Research} {Database}, a freely available multi-center database for critical care research},
	volume = {5},
	issn = {2052-4463},
	url = {https://www.nature.com/articles/sdata2018178},
	doi = {10.1038/sdata.2018.178},
	abstract = {Abstract
            Critical care patients are monitored closely through the course of their illness. As a result of this monitoring, large amounts of data are routinely collected for these patients. Philips Healthcare has developed a telehealth system, the eICU Program, which leverages these data to support management of critically ill patients. Here we describe the eICU Collaborative Research Database, a multi-center intensive care unit (ICU)database with high granularity data for over 200,000 admissions to ICUs monitored by eICU Programs across the United States. The database is deidentified, and includes vital sign measurements, care plan documentation, severity of illness measures, diagnosis information, treatment information, and more. Data are publicly available after registration, including completion of a training course in research with human subjects and signing of a data use agreement mandating responsible handling of the data and adhering to the principle of collaborative research. The freely available nature of the data will support a number of applications including the development of machine learning algorithms, decision support tools, and clinical research.},
	language = {en},
	number = {1},
	urldate = {2024-07-30},
	journal = {Scientific Data},
	author = {Pollard, Tom J. and Johnson, Alistair E. W. and Raffa, Jesse D. and Celi, Leo A. and Mark, Roger G. and Badawi, Omar},
	month = sep,
	year = {2018},
	pages = {180178},
}

@article{niu_ehr-bert_2024,
	title = {{EHR}-{BERT}: {A} {BERT}-based model for effective anomaly detection in electronic health records},
	volume = {150},
	issn = {1532-0464},
	shorttitle = {{EHR}-{BERT}},
	url = {https://www.sciencedirect.com/science/article/pii/S1532046424000236},
	doi = {10.1016/j.jbi.2024.104605},
	abstract = {Objective:
Physicians and clinicians rely on data contained in electronic health records (EHRs), as recorded by health information technology (HIT), to make informed decisions about their patients. The reliability of HIT systems in this regard is critical to patient safety. Consequently, better tools are needed to monitor the performance of HIT systems for potential hazards that could compromise the collected EHRs, which in turn could affect patient safety. In this paper, we propose a new framework for detecting anomalies in EHRs using sequence of clinical events. This new framework, EHR-Bidirectional Encoder Representations from Transformers (BERT), is motivated by the gaps in the existing deep-learning related methods, including high false negatives, sub-optimal accuracy, higher computational cost, and the risk of information loss. EHR-BERT is an innovative framework rooted in the BERT architecture, meticulously tailored to navigate the hurdles in the contemporary BERT method; thus, enhancing anomaly detection in EHRs for healthcare applications.
Methods:
The EHR-BERT framework was designed using the Sequential Masked Token Prediction (SMTP) method. This approach treats EHRs as natural language sentences and iteratively masks input tokens during both training and prediction stages. This method facilitates the learning of EHR sequence patterns in both directions for each event and identifies anomalies based on deviations from the normal execution models trained on EHR sequences.
Results:
Extensive experiments on large EHR datasets across various medical domains demonstrate that EHR-BERT markedly improves upon existing models. It significantly reduces the number of false positives and enhances the detection rate, thus bolstering the reliability of anomaly detection in electronic health records. This improvement is attributed to the model’s ability to minimize information loss and maximize data utilization effectively.
Conclusion:
EHR-BERT showcases immense potential in decreasing medical errors related to anomalous clinical events, positioning itself as an indispensable asset for enhancing patient safety and the overall standard of healthcare services. The framework effectively overcomes the drawbacks of earlier models, making it a promising solution for healthcare professionals to ensure the reliability and quality of health data.},
	urldate = {2024-07-30},
	journal = {Journal of Biomedical Informatics},
	author = {Niu, Haoran and Omitaomu, Olufemi A. and Langston, Michael A. and Olama, Mohammad and Ozmen, Ozgur and Klasky, Hilda B. and Laurio, Angela and Ward, Merry and Nebeker, Jonathan},
	month = feb,
	year = {2024},
	keywords = {Anomaly detection, BERT, Deep learning, Electronic health records, Event sequence, NLP, notion},
	pages = {104605},
}

@misc{choi_ecgbert_2023,
	title = {{ECGBERT}: {Understanding} {Hidden} {Language} of {ECGs} with {Self}-{Supervised} {Representation} {Learning}},
	shorttitle = {{ECGBERT}},
	url = {http://arxiv.org/abs/2306.06340},
	abstract = {In the medical field, current ECG signal analysis approaches rely on supervised deep neural networks trained for specific tasks that require substantial amounts of labeled data. However, our paper introduces ECGBERT, a self-supervised representation learning approach that unlocks the underlying language of ECGs. By unsupervised pre-training of the model, we mitigate challenges posed by the lack of well-labeled and curated medical data. ECGBERT, inspired by advances in the area of natural language processing and large language models, can be fine-tuned with minimal additional layers for various ECG-based problems. Through four tasks, including Atrial Fibrillation arrhythmia detection, heartbeat classification, sleep apnea detection, and user authentication, we demonstrate ECGBERT’s potential to achieve state-of-the-art results on a wide variety of tasks.},
	language = {en},
	urldate = {2024-07-30},
	publisher = {arXiv},
	author = {Choi, Seokmin and Mousavi, Sajad and Si, Phillip and Yhdego, Haben G. and Khadem, Fatemeh and Afghah, Fatemeh},
	month = jun,
	year = {2023},
	note = {arXiv:2306.06340 [cs, eess, q-bio]},
	keywords = {Computer Science - Machine Learning, Electrical Engineering and Systems Science - Signal Processing, Quantitative Biology - Quantitative Methods, notion},
}

@misc{fallahpour_ehrmamba_2024,
	title = {{EHRMamba}: {Towards} {Generalizable} and {Scalable} {Foundation} {Models} for {Electronic} {Health} {Records}},
	shorttitle = {{EHRMamba}},
	url = {http://arxiv.org/abs/2405.14567},
	doi = {10.48550/arXiv.2405.14567},
	abstract = {Transformers have significantly advanced the modeling of Electronic Health Records (EHR), yet their deployment in real-world healthcare is limited by several key challenges. Firstly, the quadratic computational cost and insufficient context length of these models pose significant obstacles for hospitals in processing the extensive medical histories typical in EHR data. Additionally, existing models employ separate finetuning for each clinical task, complicating maintenance in healthcare environments. Moreover, these models focus exclusively on either clinical prediction or EHR forecasting, lacking the flexibility to perform well across both. To overcome these limitations, we introduce EHRMamba, a robust foundation model built on the Mamba architecture. EHRMamba can process sequences up to four times longer than previous models due to its linear computational cost. We also introduce a novel approach to Multitask Prompted Finetuning (MTF) for EHR data, which enables EHRMamba to simultaneously learn multiple clinical tasks in a single finetuning phase, significantly enhancing deployment and cross-task generalization. Furthermore, our model leverages the HL7 FHIR data standard to simplify integration into existing hospital systems. Alongside EHRMamba, we open-source Odyssey, a toolkit designed to support the development and deployment of EHR foundation models, with an emphasis on data standardization and interpretability. Our evaluations on the MIMIC-IV dataset demonstrate that EHRMamba advances state-of-the-art performance across 6 major clinical tasks and excels in EHR forecasting, marking a significant leap forward in the field.},
	urldate = {2024-07-30},
	publisher = {arXiv},
	author = {Fallahpour, Adibvafa and Alinoori, Mahshid and Afkanpour, Arash and Krishnan, Amrit},
	month = may,
	year = {2024},
	note = {arXiv:2405.14567 [cs]},
	keywords = {Computer Science - Machine Learning, notion},
}

@article{ghosh_class_2024,
	title = {The class imbalance problem in deep learning},
	volume = {113},
	issn = {1573-0565},
	url = {https://doi.org/10.1007/s10994-022-06268-8},
	doi = {10.1007/s10994-022-06268-8},
	abstract = {Deep learning has recently unleashed the ability for Machine learning (ML) to make unparalleled strides. It did so by confronting and successfully addressing, at least to a certain extent, the knowledge bottleneck that paralyzed ML and artificial intelligence for decades. The community is currently basking in deep learning’s success, but a question that comes to mind is: have all of the issues previously affecting machine learning systems been solved by deep learning or do some issues remain for which deep learning is not a bulletproof solution? This question in the context of the class imbalance becomes a motivation for this paper. Imbalance problem was first recognized almost three decades ago and has remained a critical challenge at least for traditional learning approaches. Our goal is to investigate whether the tight dependency between class imbalances, concept complexities, dataset size and classifier performance, known to exist in traditional learning systems, is alleviated in any way in deep learning approaches and to what extent, if any, network depth and regularization can help. To answer these questions we conduct a survey of the recent literature focused on deep learning and the class imbalance problem as well as a series of controlled experiments on both artificial and real-world domains. This allows us to formulate lessons learned about the impact of class imbalance on deep learning models, as well as pose open challenges that should be tackled by researchers in this field.},
	language = {en},
	number = {7},
	urldate = {2024-07-29},
	journal = {Machine Learning},
	author = {Ghosh, Kushankur and Bellinger, Colin and Corizzo, Roberto and Branco, Paula and Krawczyk, Bartosz and Japkowicz, Nathalie},
	month = jul,
	year = {2024},
	keywords = {Class imbalance, Concept complexity, Deep learning, notion},
	pages = {4845--4901},
}

@article{feng_imbalanced_2021,
	title = {Imbalanced classification: {A} paradigm-based review},
	volume = {14},
	copyright = {© 2021 Wiley Periodicals LLC.},
	issn = {1932-1872},
	shorttitle = {Imbalanced classification},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/sam.11538},
	doi = {10.1002/sam.11538},
	abstract = {A common issue for classification in scientific research and industry is the existence of imbalanced classes. When sample sizes of different classes are imbalanced in training data, naively implementing a classification method often leads to unsatisfactory prediction results on test data. Multiple resampling techniques have been proposed to address the class imbalance issues. Yet, there is no general guidance on when to use each technique. In this article, we provide a paradigm-based review of the common resampling techniques for binary classification under imbalanced class sizes. The paradigms we consider include the classical paradigm that minimizes the overall classification error, the cost-sensitive learning paradigm that minimizes a cost-adjusted weighted type I and type II errors, and the Neyman–Pearson paradigm that minimizes the type II error subject to a type I error constraint. Under each paradigm, we investigate the combination of the resampling techniques and a few state-of-the-art classification methods. For each pair of resampling techniques and classification methods, we use simulation studies and a real dataset on credit card fraud to study the performance under different evaluation metrics. From these extensive numerical experiments, we demonstrate under each classification paradigm, the complex dynamics among resampling techniques, base classification methods, evaluation metrics, and imbalance ratios. We also summarize a few takeaway messages regarding the choices of resampling techniques and base classification methods, which could be helpful for practitioners.},
	language = {en},
	number = {5},
	urldate = {2024-07-29},
	journal = {Statistical Analysis and Data Mining: The ASA Data Science Journal},
	author = {Feng, Yang and Zhou, Min and Tong, Xin},
	year = {2021},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/sam.11538},
	keywords = {Neyman–Pearson (NP) paradigm, binary classification, classical classification (CC) paradigm, cost-sensitive (CS) learning paradigm, imbalance ratio, imbalanced data, notion, resampling methods},
	pages = {383--406},
}

@article{farias_remote_2020,
	title = {Remote {Patient} {Monitoring}: {A} {Systematic} {Review}},
	volume = {26},
	copyright = {https://www.liebertpub.com/nv/resources-tools/text-and-data-mining-policy/121/},
	issn = {1530-5627, 1556-3669},
	shorttitle = {Remote {Patient} {Monitoring}},
	url = {https://www.liebertpub.com/doi/10.1089/tmj.2019.0066},
	doi = {10.1089/tmj.2019.0066},
	language = {en},
	number = {5},
	urldate = {2024-07-29},
	journal = {Telemedicine and e-Health},
	author = {Farias, Frederico Arriaga Criscuoli De and Dagostini, Carolina Matté and Bicca, Yan De Assunção and Falavigna, Vincenzo Fin and Falavigna, Asdrubal},
	month = may,
	year = {2020},
	keywords = {notion},
	pages = {576--583},
}

@article{jain_how_2014,
	title = {How {Accurate} {Is} the {Eyeball} {Test}?: {A} {Comparison} of {Physician}’s {Subjective} {Assessment} {Versus} {Statistical} {Methods} in {Estimating} {Mortality} {Risk} {After} {Cardiac} {Surgery}},
	volume = {7},
	issn = {1941-7713, 1941-7705},
	shorttitle = {How {Accurate} {Is} the {Eyeball} {Test}?},
	url = {https://www.ahajournals.org/doi/10.1161/CIRCOUTCOMES.113.000329},
	doi = {10.1161/CIRCOUTCOMES.113.000329},
	abstract = {Background—
              In the era of increasing percutaneous treatment options for heart disease, the estimation of surgical risk has become a key factor in selecting optimal treatment strategies. Surgical risk has historically been estimated by physician’s subjective assessment and more recently by statistical risk estimates.
            
            
              Methods and Results—
              
                We studied 5099 consecutive patients who underwent cardiac surgery at Minneapolis Veterans Affairs Medical Center between 1993 and 2010. Operative mortality risk was estimated statistically by the Veterans Affairs mortality risk estimate and subjectively by cardiac surgeons before surgery. Observed mortality rate was 3.3\% (168 deaths) at 1 month, 7.1\% (360 deaths) at 1 year, and 18.5\% (942 deaths) at 5 years after surgery. Physician’s risk estimate (mean [SD], 5.6\% [4.4]) and statistical risk estimate (4.3\% [5.1]) had modest correlation (c-index, 0.56;
                P
                {\textless}0.001). Both methods modestly overestimated operative mortality risk. Statistical risk estimate was significantly better than physician’s risk estimate in separating patients who died from those who survived at 30 days (c-index, 0.78 versus 0.73;
                P
                =0.003), at 1 year (c-index, 0.72 versus 0.61;
                P
                {\textless}0.001), and at 5 years (c-index, 0.72 versus 0.64;
                P
                {\textless}0.001) after surgery. Physician’s risk estimate was higher than statistical risk estimate in all subgroups except high-risk patients.
              
            
            
              Conclusions—
              In patients undergoing cardiac surgery, statistical risk estimate is a better method to predict operative and long-term mortality compared with physician’s subjective risk estimate. However, both methods modestly overestimate actual operative mortality risk.},
	language = {en},
	number = {1},
	urldate = {2024-07-29},
	journal = {Circulation: Cardiovascular Quality and Outcomes},
	author = {Jain, Renuka and Duval, Sue and Adabag, Selcuk},
	month = jan,
	year = {2014},
	keywords = {notion},
	pages = {151--156},
}

@misc{lundberg_unified_2017,
	title = {A {Unified} {Approach} to {Interpreting} {Model} {Predictions}},
	url = {http://arxiv.org/abs/1705.07874},
	doi = {10.48550/arXiv.1705.07874},
	abstract = {Understanding why a model makes a certain prediction can be as crucial as the prediction's accuracy in many applications. However, the highest accuracy for large modern datasets is often achieved by complex models that even experts struggle to interpret, such as ensemble or deep learning models, creating a tension between accuracy and interpretability. In response, various methods have recently been proposed to help users interpret the predictions of complex models, but it is often unclear how these methods are related and when one method is preferable over another. To address this problem, we present a unified framework for interpreting predictions, SHAP (SHapley Additive exPlanations). SHAP assigns each feature an importance value for a particular prediction. Its novel components include: (1) the identification of a new class of additive feature importance measures, and (2) theoretical results showing there is a unique solution in this class with a set of desirable properties. The new class unifies six existing methods, notable because several recent methods in the class lack the proposed desirable properties. Based on insights from this unification, we present new methods that show improved computational performance and/or better consistency with human intuition than previous approaches.},
	urldate = {2024-07-29},
	publisher = {arXiv},
	author = {Lundberg, Scott and Lee, Su-In},
	month = nov,
	year = {2017},
	note = {arXiv:1705.07874 [cs, stat]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Statistics - Machine Learning, notion},
}

@article{fry_inpatient_2016,
	title = {Inpatient and 90-{Day} {Postdischarge} {Outcomes} in {Cardiac} {Surgery}},
	volume = {4},
	language = {en},
	number = {1},
	journal = {American Journal of Account Care},
	author = {Fry, Donald E and Pine, Michael and Nedza, Susan M and Locke, David G and Reband, Agnes M and Pine, Gregory},
	year = {2016},
	keywords = {notion},
	pages = {10--15},
}

@article{fan_development_2022,
	title = {Development of machine learning models for mortality risk prediction after cardiac surgery},
	volume = {12},
	issn = {2223-3652},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8898685/},
	doi = {10.21037/cdt-21-648},
	abstract = {Background
We developed machine learning models that combine preoperative and intraoperative risk factors to predict mortality after cardiac surgery.

Methods
Machine learning involving random forest, neural network, support vector machine, and gradient boosting machine was developed and compared with the risk scores of EuroSCORE I and II, Society of Thoracic Surgeons (STS), as well as a logistic regression model. Clinical data were collected from patients undergoing adult cardiac surgery at the First Medical Centre of Chinese PLA General Hospital between December 2008 and December 2017. The primary outcome was post-operative mortality. Model performance was estimated using several metrics, including sensitivity, specificity, accuracy, and area under the receiver operating characteristic curve (AUC). The visualization algorithm was implemented using Shapley’s additive explanations.

Results
A total of 5,443 patients were enrolled during the study period. The mean EuroSCORE II score was 3.7\%, and the actual in-hospital mortality rate was 2.7\%. For predicting operative mortality after cardiac surgery, the AUC scores were 0.87, 0.79, 0.81, and 0.82 for random forest, neural network, support vector machine, and gradient boosting machine, compared with 0.70, 0.73, 0.71, and 0.74 for EuroSCORE I and II, STS, and logistic regression model. Shapley’s additive explanations analysis of random forest yielded the top-20 predictors and individual-level explanations for each prediction.

Conclusions
Machine learning models based on available clinical data may be superior to clinical scoring tools in predicting postoperative mortality in patients following cardiac surgery. Explanatory models show the potential to provide personalized risk profiles for individuals by accounting for the contribution of influencing factors. Additional prospective multicenter studies are warranted to confirm the clinical benefit of these machine learning-driven models.},
	number = {1},
	urldate = {2024-07-29},
	journal = {Cardiovascular Diagnosis and Therapy},
	author = {Fan, Yunlong and Dong, Junfeng and Wu, Yuanbin and Shen, Ming and Zhu, Siming and He, Xiaoyi and Jiang, Shengli and Shao, Jiakang and Song, Chao},
	month = feb,
	year = {2022},
	pmid = {35282663},
	pmcid = {PMC8898685},
	keywords = {notion},
	pages = {12--23},
}

@article{benedetto_can_2020,
	title = {Can machine learning improve mortality prediction following cardiac surgery?},
	volume = {58},
	issn = {1873-734X},
	doi = {10.1093/ejcts/ezaa229},
	abstract = {OBJECTIVES: Interest in the clinical usefulness of machine learning for risk prediction has bloomed recently. Cardiac surgery patients are at high risk of complications and therefore presurgical risk assessment is of crucial relevance. We aimed to compare the performance of machine learning algorithms over traditional logistic regression (LR) model to predict in-hospital mortality following cardiac surgery.
METHODS: A single-centre data set of prospectively collected information from patients undergoing adult cardiac surgery from 1996 to 2017 was split into 70\% training set and 30\% testing set. Prediction models were developed using neural network, random forest, naive Bayes and retrained LR based on features included in the EuroSCORE. Discrimination was assessed using area under the receiver operating characteristic curve, and calibration analysis was undertaken using the calibration belt method. Model calibration drift was assessed by comparing Goodness of fit χ2 statistics observed in 2 equal bins from the testing sample ordered by procedure date.
RESULTS: A total of 28 761 cardiac procedures were performed during the study period. The in-hospital mortality rate was 2.7\%. Retrained LR [area under the receiver operating characteristic curve 0.80; 95\% confidence interval (CI) 0.77-0.83] and random forest model (0.80; 95\% CI 0.76-0.83) showed the best discrimination. All models showed significant miscalibration. Retrained LR proved to have the weakest calibration drift.
CONCLUSIONS: Our findings do not support the hypothesis that machine learning methods provide advantage over LR model in predicting operative mortality after cardiac surgery.},
	language = {eng},
	number = {6},
	journal = {European Journal of Cardio-Thoracic Surgery: Official Journal of the European Association for Cardio-Thoracic Surgery},
	author = {Benedetto, Umberto and Sinha, Shubhra and Lyon, Matt and Dimagli, Arnaldo and Gaunt, Tom R. and Angelini, Gianni and Sterne, Jonathan},
	month = dec,
	year = {2020},
	pmid = {32810233},
	keywords = {Adult, Bayes Theorem, Cardiac Surgical Procedures, Hospital Mortality, Humans, Machine Learning, Machine learning, Mortality prediction, Naive Bayes, Neural network, Random forest, Risk Assessment, notion},
	pages = {1130--1136},
}

@article{harrell_evaluating_1982,
	title = {Evaluating the yield of medical tests},
	volume = {247},
	issn = {0098-7484},
	abstract = {A method is presented for evaluating the amount of information a medical test provides about individual patients. Emphasis is placed on the role of a test in the evaluation of patients with a chronic disease. In this context, the yield of a test is best interpreted by analyzing the prognostic information it furnishes. Information from the history, physical examination, and routine procedures should be used in assessing the yield of a new test. As an example, the method is applied to the use of the treadmill exercise test in evaluating the prognosis of patients with suspected coronary artery disease. The treadmill test is shown to provide surprisingly little prognostic information beyond that obtained from basic clinical measurements.},
	language = {eng},
	number = {18},
	journal = {JAMA},
	author = {Harrell, F. E. and Califf, R. M. and Pryor, D. B. and Lee, K. L. and Rosati, R. A.},
	month = may,
	year = {1982},
	pmid = {7069920},
	keywords = {Catheterization, Diagnostic Services, Evaluation Studies as Topic, Exercise Test, Heart Diseases, Hospital Bed Capacity, 500 and over, Humans, Medical History Taking, North Carolina, Physical Examination, notion},
	pages = {2543--2546},
}

@article{harrell_evaluating_1982-1,
	title = {Evaluating the {Yield} of {Medical} {Tests}},
	volume = {247},
	issn = {0098-7484},
	url = {http://jama.jamanetwork.com/article.aspx?doi=10.1001/jama.1982.03320430047030},
	doi = {10.1001/jama.1982.03320430047030},
	language = {en},
	number = {18},
	urldate = {2024-07-26},
	journal = {JAMA: The Journal of the American Medical Association},
	author = {Harrell, Frank E.},
	month = may,
	year = {1982},
	keywords = {notion},
	pages = {2543},
}

@misc{noauthor_evaluating_nodate,
	title = {Evaluating the {Yield} of {Medical} {Tests} {\textbar} {JAMA} {\textbar} {JAMA} {Network}},
	url = {https://jamanetwork.com/journals/jama/article-abstract/372568},
	urldate = {2024-07-26},
	keywords = {notion},
}

@misc{pedregosa_scikit-learn_2018,
	title = {Scikit-learn: {Machine} {Learning} in {Python}},
	shorttitle = {Scikit-learn},
	url = {http://arxiv.org/abs/1201.0490},
	doi = {10.48550/arXiv.1201.0490},
	abstract = {Scikit-learn is a Python module integrating a wide range of state-of-the-art machine learning algorithms for medium-scale supervised and unsupervised problems. This package focuses on bringing machine learning to non-specialists using a general-purpose high-level language. Emphasis is put on ease of use, performance, documentation, and API consistency. It has minimal dependencies and is distributed under the simplified BSD license, encouraging its use in both academic and commercial settings. Source code, binaries, and documentation can be downloaded from http://scikit-learn.org.},
	urldate = {2024-07-26},
	publisher = {arXiv},
	author = {Pedregosa, Fabian and Varoquaux, Gaël and Gramfort, Alexandre and Michel, Vincent and Thirion, Bertrand and Grisel, Olivier and Blondel, Mathieu and Müller, Andreas and Nothman, Joel and Louppe, Gilles and Prettenhofer, Peter and Weiss, Ron and Dubourg, Vincent and Vanderplas, Jake and Passos, Alexandre and Cournapeau, David and Brucher, Matthieu and Perrot, Matthieu and Duchesnay, Édouard},
	month = jun,
	year = {2018},
	note = {arXiv:1201.0490 [cs]},
	keywords = {Computer Science - Machine Learning, Computer Science - Mathematical Software, notion},
}

@article{benedetto_can_2020-1,
	title = {Can machine learning improve mortality prediction following cardiac surgery?},
	volume = {58},
	issn = {1873-734X},
	doi = {10.1093/ejcts/ezaa229},
	abstract = {OBJECTIVES: Interest in the clinical usefulness of machine learning for risk prediction has bloomed recently. Cardiac surgery patients are at high risk of complications and therefore presurgical risk assessment is of crucial relevance. We aimed to compare the performance of machine learning algorithms over traditional logistic regression (LR) model to predict in-hospital mortality following cardiac surgery.
METHODS: A single-centre data set of prospectively collected information from patients undergoing adult cardiac surgery from 1996 to 2017 was split into 70\% training set and 30\% testing set. Prediction models were developed using neural network, random forest, naive Bayes and retrained LR based on features included in the EuroSCORE. Discrimination was assessed using area under the receiver operating characteristic curve, and calibration analysis was undertaken using the calibration belt method. Model calibration drift was assessed by comparing Goodness of fit χ2 statistics observed in 2 equal bins from the testing sample ordered by procedure date.
RESULTS: A total of 28 761 cardiac procedures were performed during the study period. The in-hospital mortality rate was 2.7\%. Retrained LR [area under the receiver operating characteristic curve 0.80; 95\% confidence interval (CI) 0.77-0.83] and random forest model (0.80; 95\% CI 0.76-0.83) showed the best discrimination. All models showed significant miscalibration. Retrained LR proved to have the weakest calibration drift.
CONCLUSIONS: Our findings do not support the hypothesis that machine learning methods provide advantage over LR model in predicting operative mortality after cardiac surgery.},
	language = {eng},
	number = {6},
	journal = {European Journal of Cardio-Thoracic Surgery: Official Journal of the European Association for Cardio-Thoracic Surgery},
	author = {Benedetto, Umberto and Sinha, Shubhra and Lyon, Matt and Dimagli, Arnaldo and Gaunt, Tom R. and Angelini, Gianni and Sterne, Jonathan},
	month = dec,
	year = {2020},
	pmid = {32810233},
	keywords = {Adult, Bayes Theorem, Cardiac Surgical Procedures, Hospital Mortality, Humans, Machine Learning, Machine learning, Mortality prediction, Naive Bayes, Neural network, Random forest, Risk Assessment, notion},
	pages = {1130--1136},
}

@article{fernandez_society_2019,
	title = {The {Society} of {Thoracic} {Surgeons} {National} {Database} 2019 {Annual} {Report}},
	volume = {108},
	issn = {00034975},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0003497519315930},
	doi = {10.1016/j.athoracsur.2019.09.034},
	language = {en},
	number = {6},
	urldate = {2024-07-26},
	journal = {The Annals of Thoracic Surgery},
	author = {Fernandez, Felix G. and Shahian, David M. and Kormos, Robert and Jacobs, Jeffrey P. and D’Agostino, Richard S. and Mayer, John E. and Kozower, Benjamin D. and Higgins, Robert S.D. and Badhwar, Vinay},
	month = dec,
	year = {2019},
	keywords = {notion},
	pages = {1625--1632},
}

@article{obrien_society_2018,
	title = {The {Society} of {Thoracic} {Surgeons} 2018 {Adult} {Cardiac} {Surgery} {Risk} {Models}: {Part} 2—{Statistical} {Methods} and {Results}},
	volume = {105},
	issn = {00034975},
	shorttitle = {The {Society} of {Thoracic} {Surgeons} 2018 {Adult} {Cardiac} {Surgery} {Risk} {Models}},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0003497518303710},
	doi = {10.1016/j.athoracsur.2018.03.003},
	language = {en},
	number = {5},
	urldate = {2024-07-26},
	journal = {The Annals of Thoracic Surgery},
	author = {O’Brien, Sean M. and Feng, Liqi and He, Xia and Xian, Ying and Jacobs, Jeffrey P. and Badhwar, Vinay and Kurlansky, Paul A. and Furnary, Anthony P. and Cleveland, Joseph C. and Lobdell, Kevin W. and Vassileva, Christina and Wyler Von Ballmoos, Moritz C. and Thourani, Vinod H. and Rankin, J. Scott and Edgerton, James R. and D’Agostino, Richard S. and Desai, Nimesh D. and Edwards, Fred H. and Shahian, David M.},
	month = may,
	year = {2018},
	keywords = {notion},
	pages = {1419--1428},
}

@article{weng_can_2017,
	title = {Can machine-learning improve cardiovascular risk prediction using routine clinical data?},
	volume = {12},
	issn = {1932-6203},
	url = {https://dx.plos.org/10.1371/journal.pone.0174944},
	doi = {10.1371/journal.pone.0174944},
	language = {en},
	number = {4},
	urldate = {2024-07-26},
	journal = {PLOS ONE},
	author = {Weng, Stephen F. and Reps, Jenna and Kai, Joe and Garibaldi, Jonathan M. and Qureshi, Nadeem},
	editor = {Liu, Bin},
	month = apr,
	year = {2017},
	keywords = {notion},
	pages = {e0174944},
}

@article{shroyer_society_2003,
	title = {The society of thoracic surgeons: 30-day operative mortality and morbidity risk models},
	volume = {75},
	copyright = {https://www.elsevier.com/tdm/userlicense/1.0/},
	issn = {00034975},
	shorttitle = {The society of thoracic surgeons},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0003497503001796},
	doi = {10.1016/S0003-4975(03)00179-6},
	language = {en},
	number = {6},
	urldate = {2024-07-26},
	journal = {The Annals of Thoracic Surgery},
	author = {Shroyer, A.Laurie W and Coombs, Laura P and Peterson, Eric D and Eiken, Mary C and DeLong, Elizabeth R and Chen, Anita and Ferguson, T.Bruce and Grover, Frederick L and Edwards, Fred H},
	month = jun,
	year = {2003},
	keywords = {notion},
	pages = {1856--1865},
}

@inproceedings{shameer_predictive_2017,
	address = {Kohala Coast, Hawaii, USA},
	title = {{PREDICTIVE} {MODELING} {OF} {HOSPITAL} {READMISSION} {RATES} {USING} {ELECTRONIC} {MEDICAL} {RECORD}-{WIDE} {MACHINE} {LEARNING}: {A} {CASE}-{STUDY} {USING} {MOUNT} {SINAI} {HEART} {FAILURE} {COHORT}},
	isbn = {978-981-320-780-6 978-981-320-781-3},
	shorttitle = {{PREDICTIVE} {MODELING} {OF} {HOSPITAL} {READMISSION} {RATES} {USING} {ELECTRONIC} {MEDICAL} {RECORD}-{WIDE} {MACHINE} {LEARNING}},
	url = {http://www.worldscientific.com/doi/abs/10.1142/9789813207813_0027},
	doi = {10.1142/9789813207813_0027},
	language = {en},
	urldate = {2024-07-26},
	booktitle = {Biocomputing 2017},
	publisher = {WORLD SCIENTIFIC},
	author = {Shameer, Khader and Johnson, Kipp W and Yahi, Alexandre and Miotto, Riccardo and Li, Li and Ricks, Doran and Jebakaran, Jebakumar and Kovatch, Patricia and Sengupta, Partho P. and Gelijns, Sengupta and Moskovitz, Alan and Darrow, Bruce and David, David L and Kasarskis, Andrew and Tatonetti, Nicholas P. and Pinney, Sean and Dudley, Joel T},
	month = jan,
	year = {2017},
	keywords = {notion},
	pages = {276--287},
}

@article{safavi_development_2019,
	title = {Development and {Validation} of a {Machine} {Learning} {Model} to {Aid} {Discharge} {Processes} for {Inpatient} {Surgical} {Care}},
	volume = {2},
	issn = {2574-3805},
	url = {https://jamanetwork.com/journals/jamanetworkopen/fullarticle/2757372},
	doi = {10.1001/jamanetworkopen.2019.17221},
	language = {en},
	number = {12},
	urldate = {2024-07-26},
	journal = {JAMA Network Open},
	author = {Safavi, Kyan C. and Khaniyev, Taghi and Copenhaver, Martin and Seelen, Mark and Zenteno Langle, Ana Cecilia and Zanger, Jonathan and Daily, Bethany and Levi, Retsef and Dunn, Peter},
	month = dec,
	year = {2019},
	keywords = {notion},
	pages = {e1917221},
}

@article{prins_cardiac_2012,
	title = {Cardiac surgery risk-stratification models},
	volume = {23},
	issn = {19951892, 16800745},
	url = {http://www.cvja.co.za/onlinejournal/vol23/vol23_issue3/#/42/},
	doi = {10.5830/CVJA-2011-047},
	number = {3},
	urldate = {2024-07-26},
	journal = {Cardiovascular Journal of Africa},
	author = {Prins, Carla and De Villiers Jonker, I. and Botes, Lizelle and Smit, Francis E.},
	month = apr,
	year = {2012},
	keywords = {notion},
	pages = {160--164},
}

@article{nashef_european_1999,
	title = {European system for cardiac operative risk evaluation ({EuroSCORE})},
	volume = {16},
	issn = {1873-734X, 1010-7940},
	url = {https://academic.oup.com/ejcts/article-lookup/doi/10.1016/S1010-7940(99)00134-7},
	doi = {10.1016/S1010-7940(99)00134-7},
	language = {en},
	number = {1},
	urldate = {2024-07-26},
	journal = {European Journal of Cardio-Thoracic Surgery},
	author = {Nashef, S.A.M. and Roques, F. and Michel, P. and Gauducheau, E. and Lemeshow, S. and Salamon, R.},
	month = jul,
	year = {1999},
	keywords = {notion},
	pages = {9--13},
}

@article{li_analysis_2019,
	title = {Analysis of risk factors and establishment of a risk prediction model for cardiothoracic surgical intensive care unit readmission after heart valve surgery in {China}: {A} single-center study},
	volume = {48},
	issn = {01479563},
	shorttitle = {Analysis of risk factors and establishment of a risk prediction model for cardiothoracic surgical intensive care unit readmission after heart valve surgery in {China}},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0147956318300773},
	doi = {10.1016/j.hrtlng.2018.07.013},
	language = {en},
	number = {1},
	urldate = {2024-07-26},
	journal = {Heart \& Lung},
	author = {Li, Si and Tang, Bai-yun and Zhang, Bao and Wang, Cui-ping and Zhang, Wen-bo and Yang, Song and Chen, Jia-bin},
	month = jan,
	year = {2019},
	keywords = {notion},
	pages = {61--68},
}

@article{kirmani_comparison_2013,
	title = {Comparison of the {EuroSCORE} {II} and {Society} of {Thoracic} {Surgeons} 2008 risk tools},
	volume = {44},
	issn = {1010-7940, 1873-734X},
	url = {https://academic.oup.com/ejcts/article-lookup/doi/10.1093/ejcts/ezt122},
	doi = {10.1093/ejcts/ezt122},
	language = {en},
	number = {6},
	urldate = {2024-07-26},
	journal = {European Journal of Cardio-Thoracic Surgery},
	author = {Kirmani, B. H. and Mazhar, K. and Fabri, B. M. and Pullan, D. M.},
	month = dec,
	year = {2013},
	keywords = {notion},
	pages = {999--1005},
}

@article{kilic_predictive_2020,
	title = {Predictive {Utility} of a {Machine} {Learning} {Algorithm} in {Estimating} {Mortality} {Risk} in {Cardiac} {Surgery}},
	volume = {109},
	issn = {00034975},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0003497519316200},
	doi = {10.1016/j.athoracsur.2019.09.049},
	language = {en},
	number = {6},
	urldate = {2024-07-26},
	journal = {The Annals of Thoracic Surgery},
	author = {Kilic, Arman and Goyal, Anshul and Miller, James K. and Gjekmarkaj, Eva and Tam, Weng Lam and Gleason, Thomas G. and Sultan, Ibrahim and Dubrawksi, Artur},
	month = jun,
	year = {2020},
	keywords = {notion},
	pages = {1811--1819},
}

@article{johnson_artificial_2018,
	title = {Artificial {Intelligence} in {Cardiology}},
	volume = {71},
	issn = {07351097},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0735109718344085},
	doi = {10.1016/j.jacc.2018.03.521},
	language = {en},
	number = {23},
	urldate = {2024-07-26},
	journal = {Journal of the American College of Cardiology},
	author = {Johnson, Kipp W. and Torres Soto, Jessica and Glicksberg, Benjamin S. and Shameer, Khader and Miotto, Riccardo and Ali, Mohsin and Ashley, Euan and Dudley, Joel T.},
	month = jun,
	year = {2018},
	keywords = {notion},
	pages = {2668--2679},
}

@article{hekmat_daily_2005,
	title = {Daily {Assessment} of {Organ} {Dysfunction} and {Survival} in {Intensive} {Care} {Unit} {Cardiac} {Surgical} {Patients}},
	volume = {79},
	copyright = {https://www.elsevier.com/tdm/userlicense/1.0/},
	issn = {00034975},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0003497504021198},
	doi = {10.1016/j.athoracsur.2004.10.017},
	language = {en},
	number = {5},
	urldate = {2024-07-26},
	journal = {The Annals of Thoracic Surgery},
	author = {Hekmat, Khosro and Kroener, Axel and Stuetzer, Hartmut and Schwinger, Robert H.G. and Kampe, Sandra and Bennink, Gerardus B.W.E. and Mehlhorn, Uwe},
	month = may,
	year = {2005},
	keywords = {notion},
	pages = {1555--1562},
}

@article{gao_predictive_2021,
	title = {Predictive {Ability} of {European} {Heart} {Surgery} {Risk} {Assessment} {System} {II} ({EuroSCORE} {II}) and the {Society} of {Thoracic} {Surgeons} ({STS}) {Score} for in-{Hospital} and {Medium}-{Term} {Mortality} of {Patients} {Undergoing} {Coronary} {Artery} {Bypass} {Grafting}},
	volume = {Volume 14},
	copyright = {http://creativecommons.org/licenses/by-nc/3.0/},
	issn = {1178-7074},
	url = {https://www.dovepress.com/predictive-ability-of-european-heart-surgery-risk-assessment-system-ii-peer-reviewed-fulltext-article-IJGM},
	doi = {10.2147/IJGM.S338819},
	language = {en},
	urldate = {2024-07-26},
	journal = {International Journal of General Medicine},
	author = {Gao, Fei and Shan, Lingtong and Wang, Chong and Meng, Xiaoqi and Chen, Jiapeng and Han, Lixiang and Zhang, Yangyang and Li, Zhi},
	month = nov,
	year = {2021},
	keywords = {notion},
	pages = {8509--8519},
}

@article{fernandes_machine_2021,
	title = {Machine {Learning} {Models} with {Preoperative} {Risk} {Factors} and {Intraoperative} {Hypotension} {Parameters} {Predict} {Mortality} {After} {Cardiac} {Surgery}},
	volume = {35},
	issn = {10530770},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S1053077020306595},
	doi = {10.1053/j.jvca.2020.07.029},
	language = {en},
	number = {3},
	urldate = {2024-07-26},
	journal = {Journal of Cardiothoracic and Vascular Anesthesia},
	author = {Fernandes, Marta Priscila Bento and Armengol De La Hoz, Miguel and Rangasamy, Valluvan and Subramaniam, Balachundhar},
	month = mar,
	year = {2021},
	keywords = {notion},
	pages = {857--865},
}

@article{catelli_crosslingual_2020,
	title = {Crosslingual named entity recognition for clinical de-identification applied to a {COVID}-19 {Italian} data set},
	volume = {97},
	issn = {15684946},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S1568494620307171},
	doi = {10.1016/j.asoc.2020.106779},
	language = {en},
	urldate = {2024-07-26},
	journal = {Applied Soft Computing},
	author = {Catelli, Rosario and Gargiulo, Francesco and Casola, Valentina and De Pietro, Giuseppe and Fujita, Hamido and Esposito, Massimo},
	month = dec,
	year = {2020},
	keywords = {notion},
	pages = {106779},
}

@article{badreldin_rapid_2013,
	title = {Rapid clinical evaluation: an early warning cardiac surgical scoring system for hand-held digital devices*},
	volume = {44},
	issn = {1873-734X, 1010-7940},
	shorttitle = {Rapid clinical evaluation},
	url = {https://academic.oup.com/ejcts/article-lookup/doi/10.1093/ejcts/ezt232},
	doi = {10.1093/ejcts/ezt232},
	language = {en},
	number = {6},
	urldate = {2024-07-26},
	journal = {European Journal of Cardio-Thoracic Surgery},
	author = {Badreldin, Akmal M.A. and Doerr, Fabian and Bender, Edward M. and Bayer, Ole and Brehm, Bernhard R. and Wahlers, Thorsten and Hekmat, Khosro},
	month = dec,
	year = {2013},
	keywords = {notion},
	pages = {992--998},
}

@article{ariyaratnam_prediction_2019,
	title = {Prediction of {Postoperative} {Outcomes} and {Long}-{Term} {Survival} in {Cardiac} {Surgical} {Patients} {Using} the {Intensive} {Care} {National} {Audit} \& {Research} {Centre} {Score}},
	volume = {33},
	issn = {10530770},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S1053077019304975},
	doi = {10.1053/j.jvca.2019.05.034},
	language = {en},
	number = {11},
	urldate = {2024-07-26},
	journal = {Journal of Cardiothoracic and Vascular Anesthesia},
	author = {Ariyaratnam, Priyadharshanan and Ananthasayanam, Anantha and Moore, Julie and Vijayan, Ajith and Hong, Vincent and Loubani, Mahmoud},
	month = nov,
	year = {2019},
	keywords = {notion},
	pages = {3022--3027},
}

@article{abdalla_using_2020,
	title = {Using word embeddings to improve the privacy of clinical notes},
	volume = {27},
	copyright = {http://creativecommons.org/licenses/by-nc/4.0/},
	issn = {1527-974X},
	url = {https://academic.oup.com/jamia/article/27/6/901/5835527},
	doi = {10.1093/jamia/ocaa038},
	abstract = {Abstract
            
              Objective
              In this work, we introduce a privacy technique for anonymizing clinical notes that guarantees all private health information is secured (including sensitive data, such as family history, that are not adequately covered by current techniques).
            
            
              Materials and Methods
              We employ a new “random replacement” paradigm (replacing each token in clinical notes with neighboring word vectors from the embedding space) to achieve 100\% recall on the removal of sensitive information, unachievable with current “search-and-secure” paradigms. We demonstrate the utility of this paradigm on multiple corpora in a diverse set of classification tasks.
            
            
              Results
              We empirically evaluate the effect of our anonymization technique both on upstream and downstream natural language processing tasks to show that our perturbations, while increasing security (ie, achieving 100\% recall on any dataset), do not greatly impact the results of end-to-end machine learning approaches.
            
            
              Discussion
              As long as current approaches utilize precision and recall to evaluate deidentification algorithms, there will remain a risk of overlooking sensitive information. Inspired by differential privacy, we sought to make it statistically infeasible to recreate the original data, although at the cost of readability. We hope that the work will serve as a catalyst to further research into alternative deidentification methods that can address current weaknesses.
            
            
              Conclusion
              Our proposed technique can secure clinical texts at a low cost and extremely high recall with a readability trade-off while remaining useful for natural language processing classification tasks. We hope that our work can be used by risk-averse data holders to release clinical texts to researchers.},
	language = {en},
	number = {6},
	urldate = {2024-07-26},
	journal = {Journal of the American Medical Informatics Association},
	author = {Abdalla, Mohamed and Abdalla, Moustafa and Rudzicz, Frank and Hirst, Graeme},
	month = jun,
	year = {2020},
	keywords = {notion},
	pages = {901--907},
}

@article{sullivan_meta-analysis_2016,
	title = {Meta-{Analysis} {Comparing} {Established} {Risk} {Prediction} {Models} ({EuroSCORE} {II}, {STS} {Score}, and {ACEF} {Score}) for {Perioperative} {Mortality} {During} {Cardiac} {Surgery}},
	volume = {118},
	issn = {00029149},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0002914916313844},
	doi = {10.1016/j.amjcard.2016.08.024},
	language = {en},
	number = {10},
	urldate = {2024-07-26},
	journal = {The American Journal of Cardiology},
	author = {Sullivan, Patrick G. and Wallach, Joshua D. and Ioannidis, John P.A.},
	month = nov,
	year = {2016},
	keywords = {notion},
	pages = {1574--1582},
}

@article{speir_additive_2009,
	title = {Additive {Costs} of {Postoperative} {Complications} for {Isolated} {Coronary} {Artery} {Bypass} {Grafting} {Patients} in {Virginia}},
	volume = {88},
	copyright = {https://www.elsevier.com/tdm/userlicense/1.0/},
	issn = {00034975},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0003497509005761},
	doi = {10.1016/j.athoracsur.2009.03.076},
	language = {en},
	number = {1},
	urldate = {2024-07-26},
	journal = {The Annals of Thoracic Surgery},
	author = {Speir, Alan M. and Kasirajan, Vigneshwar and Barnett, Scott D. and Fonner, Edwin},
	month = jul,
	year = {2009},
	keywords = {notion},
	pages = {40--46},
}

@article{shahian_society_2018,
	title = {The {Society} of {Thoracic} {Surgeons} 2018 {Adult} {Cardiac} {Surgery} {Risk} {Models}: {Part} 1—{Background}, {Design} {Considerations}, and {Model} {Development}},
	volume = {105},
	issn = {00034975},
	shorttitle = {The {Society} of {Thoracic} {Surgeons} 2018 {Adult} {Cardiac} {Surgery} {Risk} {Models}},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0003497518303709},
	doi = {10.1016/j.athoracsur.2018.03.002},
	language = {en},
	number = {5},
	urldate = {2024-07-26},
	journal = {The Annals of Thoracic Surgery},
	author = {Shahian, David M. and Jacobs, Jeffrey P. and Badhwar, Vinay and Kurlansky, Paul A. and Furnary, Anthony P. and Cleveland, Joseph C. and Lobdell, Kevin W. and Vassileva, Christina and Wyler Von Ballmoos, Moritz C. and Thourani, Vinod H. and Rankin, J. Scott and Edgerton, James R. and D’Agostino, Richard S. and Desai, Nimesh D. and Feng, Liqi and He, Xia and O’Brien, Sean M.},
	month = may,
	year = {2018},
	keywords = {notion},
	pages = {1411--1418},
}

@article{seese_impact_2020,
	title = {The {Impact} of {Major} {Postoperative} {Complications} on {Long}-{Term} {Survival} {After} {Cardiac} {Surgery}},
	volume = {110},
	issn = {00034975},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0003497519317485},
	doi = {10.1016/j.athoracsur.2019.09.100},
	language = {en},
	number = {1},
	urldate = {2024-07-26},
	journal = {The Annals of Thoracic Surgery},
	author = {Seese, Laura and Sultan, Ibrahim and Gleason, Thomas G. and Navid, Forozan and Wang, Yisi and Thoma, Floyd and Kilic, Arman},
	month = jul,
	year = {2020},
	keywords = {notion},
	pages = {128--135},
}

@article{pudil_floating_1994,
	title = {Floating search methods in feature selection},
	volume = {15},
	copyright = {https://www.elsevier.com/tdm/userlicense/1.0/},
	issn = {01678655},
	url = {https://linkinghub.elsevier.com/retrieve/pii/0167865594901279},
	doi = {10.1016/0167-8655(94)90127-9},
	language = {en},
	number = {11},
	urldate = {2024-07-26},
	journal = {Pattern Recognition Letters},
	author = {Pudil, P. and Novovičová, J. and Kittler, J.},
	month = nov,
	year = {1994},
	keywords = {notion},
	pages = {1119--1125},
}

@article{pittams_scoring_2022,
	title = {Scoring {Systems} for {Risk} {Stratification} in {Patients} {Undergoing} {Cardiac} {Surgery}},
	volume = {36},
	issn = {10530770},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S105307702100207X},
	doi = {10.1053/j.jvca.2021.03.005},
	language = {en},
	number = {4},
	urldate = {2024-07-26},
	journal = {Journal of Cardiothoracic and Vascular Anesthesia},
	author = {Pittams, Ashleigh P. and Iddawela, Sashini and Zaidi, Sara and Tyson, Nathan and Harky, Amer},
	month = apr,
	year = {2022},
	keywords = {notion},
	pages = {1148--1156},
}

@article{park_telecare_2011,
	title = {Telecare {System} for {Cardiac} {Surgery} {Patients}: {Implementation} and {Effectiveness}},
	volume = {17},
	copyright = {http://creativecommons.org/licenses/by-nc/3.0/},
	issn = {2093-3681},
	shorttitle = {Telecare {System} for {Cardiac} {Surgery} {Patients}},
	url = {http://e-hir.org/journal/view.php?id=10.4258/hir.2011.17.2.93},
	doi = {10.4258/hir.2011.17.2.93},
	language = {en},
	number = {2},
	urldate = {2024-07-26},
	journal = {Healthcare Informatics Research},
	author = {Park, Dong Kyun and Jung, Eun-Young and Park, Rae Woong and Lee, Young Ho and Hwang, Hee Jung and Son, In Ah and Hu, Min-Hee},
	year = {2011},
	keywords = {notion},
	pages = {93},
}

@article{mortazavi_prediction_2017,
	title = {Prediction of {Adverse} {Events} in {Patients} {Undergoing} {Major} {Cardiovascular} {Procedures}},
	volume = {21},
	copyright = {https://ieeexplore.ieee.org/Xplorehelp/downloads/license-information/IEEE.html},
	issn = {2168-2194, 2168-2208},
	url = {https://ieeexplore.ieee.org/document/7865946/},
	doi = {10.1109/JBHI.2017.2675340},
	number = {6},
	urldate = {2024-07-26},
	journal = {IEEE Journal of Biomedical and Health Informatics},
	author = {Mortazavi, Bobak J. and Desai, Nihar and Zhang, Jing and Coppi, Andreas and Warner, Fred and Krumholz, Harlan M. and Negahban, Sahand},
	month = nov,
	year = {2017},
	keywords = {notion},
	pages = {1719--1729},
}

@article{king_logistic_2003,
	title = {Logistic {Regression} in {Rare} {Events} {Data}},
	volume = {8},
	issn = {1548-7660},
	url = {http://www.jstatsoft.org/v08/i02/},
	doi = {10.18637/jss.v008.i02},
	language = {en},
	number = {2},
	urldate = {2024-07-26},
	journal = {Journal of Statistical Software},
	author = {King, Gary and Zeng, Langche},
	year = {2003},
	keywords = {notion},
}

@article{jonkers_prevalence_2003,
	title = {Prevalence of 90-days postoperative wound infections after cardiac surgery},
	volume = {23},
	issn = {10107940},
	url = {https://academic.oup.com/ejcts/article-lookup/doi/10.1016/S1010-7940(02)00662-0},
	doi = {10.1016/S1010-7940(02)00662-0},
	language = {en},
	number = {1},
	urldate = {2024-07-26},
	journal = {European Journal of Cardio-Thoracic Surgery},
	author = {Jonkers, D},
	month = jan,
	year = {2003},
	keywords = {notion},
	pages = {97--102},
}

@article{hirji_utility_2020,
	title = {Utility of 90-{Day} {Mortality} vs 30-{Day} {Mortality} as a {Quality} {Metric} for {Transcatheter} and {Surgical} {Aortic} {Valve} {Replacement} {Outcomes}},
	volume = {5},
	issn = {2380-6583},
	url = {https://jamanetwork.com/journals/jamacardiology/fullarticle/2757047},
	doi = {10.1001/jamacardio.2019.4657},
	language = {en},
	number = {2},
	urldate = {2024-07-26},
	journal = {JAMA Cardiology},
	author = {Hirji, Sameer and McGurk, Siobhan and Kiehm, Spencer and Ejiofor, Julius and Ramirez-Del Val, Fernando and Kolkailah, Ahmed A. and Berry, Natalia and Sobieszczyk, Piotr and Pelletier, Marc and Shah, Pinak and O’Gara, Patrick and Kaneko, Tsuyoshi},
	month = feb,
	year = {2020},
	keywords = {notion},
	pages = {156},
}

@article{head_systematic_2013,
	title = {A systematic review of risk prediction in adult cardiac surgery: considerations for future model development},
	volume = {43},
	issn = {1010-7940, 1873-734X},
	shorttitle = {A systematic review of risk prediction in adult cardiac surgery},
	url = {https://academic.oup.com/ejcts/article-lookup/doi/10.1093/ejcts/ezt044},
	doi = {10.1093/ejcts/ezt044},
	language = {en},
	number = {5},
	urldate = {2024-07-26},
	journal = {European Journal of Cardio-Thoracic Surgery},
	author = {Head, S. J. and Osnabrugge, R. L. J. and Howell, N. J. and Freemantle, N. and Bridgewater, B. and Pagano, D. and Kappetein, A. P.},
	month = may,
	year = {2013},
	keywords = {notion},
	pages = {e121--e129},
}

@article{allyn_comparison_2017,
	title = {A {Comparison} of a {Machine} {Learning} {Model} with {EuroSCORE} {II} in {Predicting} {Mortality} after {Elective} {Cardiac} {Surgery}: {A} {Decision} {Curve} {Analysis}},
	volume = {12},
	issn = {1932-6203},
	shorttitle = {A {Comparison} of a {Machine} {Learning} {Model} with {EuroSCORE} {II} in {Predicting} {Mortality} after {Elective} {Cardiac} {Surgery}},
	url = {https://dx.plos.org/10.1371/journal.pone.0169772},
	doi = {10.1371/journal.pone.0169772},
	language = {en},
	number = {1},
	urldate = {2024-07-26},
	journal = {PLOS ONE},
	author = {Allyn, Jérôme and Allou, Nicolas and Augustin, Pascal and Philip, Ivan and Martinet, Olivier and Belghiti, Myriem and Provenchere, Sophie and Montravers, Philippe and Ferdynus, Cyril},
	editor = {Parolari, Alessandro},
	month = jan,
	year = {2017},
	keywords = {notion},
	pages = {e0169772},
}

@article{ad_comparison_2016,
	title = {Comparison of {EuroSCORE} {II}, {Original} {EuroSCORE}, and {The} {Society} of {Thoracic} {Surgeons} {Risk} {Score} in {Cardiac} {Surgery} {Patients}},
	volume = {102},
	issn = {00034975},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S000349751600120X},
	doi = {10.1016/j.athoracsur.2016.01.105},
	language = {en},
	number = {2},
	urldate = {2024-07-26},
	journal = {The Annals of Thoracic Surgery},
	author = {Ad, Niv and Holmes, Sari D. and Patel, Jay and Pritchard, Graciela and Shuman, Deborah J. and Halpin, Linda},
	month = aug,
	year = {2016},
	keywords = {notion},
	pages = {573--579},
}

@article{lopes_smartphone-based_2019,
	title = {Smartphone-{Based} {Remote} {Monitoring} {Solution} for {Heart} {Failure} {Patients}},
	volume = {261},
	issn = {1879-8365},
	abstract = {The hospitalisation of patients with Heart Failure (HF) represents an increasing problem for the healthcare system with more than 26 million worldwide suffering from this disease. Predictions demonstrate that the total health expenditure will increase by 127\% in 2030. In Portugal, demographic changes caused by an ageing population are associated with an increase in HF incidence rate, forecasting 479.921 Heart Failure patients by 2035. In this paper, we present the smartBEAT solution that was developed to monitor Heart Failure patients so that physicians can early detect HF decompensation and prevent HF hospitalisations. SmartBEAT collects data from several sensors: weigh scale, blood pressures, physical activity bracelet - and transmits to the cloud where a decision support algorithm helps to detect acute episodes early. The system was evaluated during a pilot phase for two weeks with nine seniors, and later for 1-3 months with 38 seniors HF patients. Adherence to the evaluation protocol was high, and perceptions on wellbeing and control over the disease were considered positive. Moreover, healthcare professionals were overwhelmed with the patients' high adherence and found the usability of the portal high, and providing interesting information about patients' health status.},
	language = {eng},
	journal = {Studies in Health Technology and Informatics},
	author = {Lopes, Inês and Sousa, Filipe and Moreira, Emilia and Cardoso, José},
	year = {2019},
	pmid = {31156100},
	keywords = {Blood Pressure, Heart Failure, Hospitalization, Humans, Monitoring, Physiologic, Portugal, Remote Monitoring, Smartphone, Weight Scale, notion},
	pages = {109--114},
}

@article{londral_developing_2022,
	title = {Developing and validating high-value patient digital follow-up services: a pilot study in cardiac surgery},
	volume = {22},
	issn = {1472-6963},
	shorttitle = {Developing and validating high-value patient digital follow-up services},
	url = {https://doi.org/10.1186/s12913-022-08073-4},
	doi = {10.1186/s12913-022-08073-4},
	abstract = {The existing digital healthcare solutions demand a service development approach that assesses needs, experience, and outcomes, to develop high-value digital healthcare services. The objective of this study was to develop a digital transformation of the patients’ follow-up service after cardiac surgery, based on a remote patient monitoring service that would respond to the real context challenges.},
	number = {1},
	urldate = {2024-07-25},
	journal = {BMC Health Services Research},
	author = {Londral, A. and Azevedo, S. and Dias, P. and Ramos, C. and Santos, J. and Martins, F. and Silva, R. and Semedo, H. and Vital, C. and Gualdino, A. and Falcão, J. and Lapão, L. V. and Coelho, P. and Fragata, J. G.},
	month = may,
	year = {2022},
	keywords = {Cardiac surgery, Design science research, Digital healthcare, Patient-reported outcomes, Real-world validation, Remote patient monitoring, Service design, notion},
	pages = {680},
}

@article{ware_mos_1992,
	title = {The {MOS} 36-item short-form health survey ({SF}-36). {I}. {Conceptual} framework and item selection},
	volume = {30},
	issn = {0025-7079},
	abstract = {A 36-item short-form (SF-36) was constructed to survey health status in the Medical Outcomes Study. The SF-36 was designed for use in clinical practice and research, health policy evaluations, and general population surveys. The SF-36 includes one multi-item scale that assesses eight health concepts: 1) limitations in physical activities because of health problems; 2) limitations in social activities because of physical or emotional problems; 3) limitations in usual role activities because of physical health problems; 4) bodily pain; 5) general mental health (psychological distress and well-being); 6) limitations in usual role activities because of emotional problems; 7) vitality (energy and fatigue); and 8) general health perceptions. The survey was constructed for self-administration by persons 14 years of age and older, and for administration by a trained interviewer in person or by telephone. The history of the development of the SF-36, the origin of specific items, and the logic underlying their selection are summarized. The content and features of the SF-36 are compared with the 20-item Medical Outcomes Study short-form.},
	language = {eng},
	number = {6},
	journal = {Medical Care},
	author = {Ware, J. E. and Sherbourne, C. D.},
	month = jun,
	year = {1992},
	pmid = {1593914},
	keywords = {Activities of Daily Living, Adolescent, Adult, Aged, Health Policy, Health Services Research, Health Status, Health Surveys, Humans, Mental Health, Middle Aged, Outcome Assessment, Health Care, Role, Self-Assessment, Surveys and Questionnaires, notion},
	pages = {473--483},
}

@article{ferreira_development_2000,
	title = {Development of the {Portuguese} version of {MOS} {SF}-36. {Part} {I}. {Cultural} and linguistic adaptation},
	volume = {13},
	issn = {0870-399X},
	abstract = {No one aims at applying generic measures as substitutes for other more traditional clinical procedures. The whole history of the evolution of these types of measures has been based on comparisons with clinical measures, always seen by researchers as ways to validate health outcome measures and as a process to be recognized by clinicians as a way to detect changes in time not always detected by the usual measures. The measurement instrument presented in this paper is the Portuguese version of the MOS SF-36, originally a result of the Medical Outcomes Study, a study carried out by Rand Corporation researchers in the 80's. One of the objectives of these researchers was precisely to develop instruments to be used in continuous monitoring of outcomes. This paper describes the first time MOS SF-36 was culturally adapted to Portuguese, validated and implemented. The first part mentions some of the foundations and developments of the original instrument as well as some results obtained from some specific applications. The second part introduces operational definitions for each of the eight scales and describes the SF-36 measurement model as well as the factor structure with two dimensions. Next, we present the design used by us to transform the data from the time they are collected from the respondents to the time they are ready to be further used. Finally, the methodology used to culturally adapt the MOS SF-36 and create a Portuguese version which is culturally equivalent are presented.},
	language = {por},
	number = {1-2},
	journal = {Acta Medica Portuguesa},
	author = {Ferreira, P. L.},
	year = {2000},
	pmid = {11059056},
	keywords = {Humans, Outcome Assessment, Health Care, Portugal, Surveys and Questionnaires, notion},
	pages = {55--66},
}

@phdthesis{curioso_delivering_nodate,
	title = {Delivering {Reliable} {AI} to {Clinical} {Contexts}: {Addressing} the {Challenge} of {Missing} {Data}},
	abstract = {Clinical data are essential in the medical domain, ensuring quality of care and improving decision-making. However, their heterogeneous and incomplete nature leads to an ubiquity of data quality problems, particularly missing values. Inevitable challenges arise in delivering reliable Decision Support Systems (DSSs), as missing data yield negative effects on the learning process of Machine Learning models. The interest in developing missing value imputation strategies has been growing, in an endeavour to overcome this issue. This dissertation aimed to study missing data and their relationships with observed values, and to later employ that information in a technique that addresses the predicaments posed by incomplete datasets in real-world scenarios. Moreover, the concept of correlation was explored within the context of missing value imputation, a promising but rather overlooked approach in biomedical research. First, a comprehensive correlational study was performed, which considered key aspects from missing data analysis. Afterwards, the gathered knowledge was leveraged to create three novel correlation-based imputation techniques. These were not only validated on datasets with a controlled and synthetic missingness, but also on real-world medical datasets. Their performance was evaluated against competing imputation methods, both traditional and state-of-the-art. The contributions of this dissertation encompass a systematic view of theoretical concepts regarding the analysis and handling of missing values. Additionally, an extensive literature review concerning missing data imputation was conducted, which comprised a comparative study of ten methods under diverse missingness conditions. The proposed techniques exhibited similar results when compared to their competitors, sometimes even superior in terms of imputation precision and classification performance, evaluated through the Mean Absolute Error and the Area Under the Receiver Operating Characteristic curve, respectively. Therefore, this dissertation corroborates the potential of correlation to improve the robustness of DSSs to missing values, and provides answers to current flaws shared by correlation-based imputation strategies in real-world medical problems.},
	language = {en},
	author = {Curioso, Isabel de Almeida},
}

@article{santos_corki_nodate,
	title = {{CORKI}: {A} {Correlation}-driven {Imputation} {Method} for {Partial} {Annotation} {Scenarios} in {Multi}-{Label} {Clinical} {Problems}},
	abstract = {Multi-label classification tasks are relevant in healthcare, as data samples are commonly associated with multiple interdependent, non-mutually exclusive outcomes. Incomplete label information often arises due to unrecorded outcomes at planned checkpoints, varying disease testing across patients, collection constraints, or human error. Dropping partially annotated samples can reduce data size, introduce bias, and compromise accuracy. To address these issues, this study introduces CORKI (Correlation-Optimised and Robust K Nearest Neighbours Imputation for Multi-label Classification), a data-centric method for partial annotation imputation in multi-label data. This method employs proximity measures and an optional weighting term for outcome prevalence to tackle imbalanced labels. Additionally, it leverages different modalities of correlation that consider not only variable values but also missingness patterns. CORKI’s performance was compared with a domain-knowledge-based rule system and the standard sample-dropping approach on three public and one private cardiothoracic surgery datasets with diverse missing label rates. CORKI yielded performances comparable to those of the domain-knowledge approach, establishing itself as a reliable method, while being highly generalizable. Moreover, it was able to maintain imputation accuracy in demanding partial annotation scenarios, presenting drops of only 5\% for missing rates of 50\%.},
	language = {en},
	author = {Santos, Ricardo and Ribeiro, Bruno and Curioso, Isabel and Carreiro, André V and Gamboa, Hugo and Coelho, Pedro and Fragata, José and Sousa, Inês},
}

@article{head_european_2013,
	title = {The {European} {Association} for {Cardio}-{Thoracic} {Surgery} ({EACTS}) database: an introduction},
	volume = {44},
	issn = {1010-7940, 1873-734X},
	shorttitle = {The {European} {Association} for {Cardio}-{Thoracic} {Surgery} ({EACTS}) database},
	url = {https://academic.oup.com/ejcts/article-lookup/doi/10.1093/ejcts/ezt303},
	doi = {10.1093/ejcts/ezt303},
	language = {en},
	number = {3},
	urldate = {2024-07-17},
	journal = {European Journal of Cardio-Thoracic Surgery},
	author = {Head, S. J. and Howell, N. J. and Osnabrugge, R. L. J. and Bridgewater, B. and Keogh, B. E. and Kinsman, R. and Walton, P. and Gummert, J. F. and Pagano, D. and Kappetein, A. P.},
	month = sep,
	year = {2013},
	keywords = {notion},
	pages = {e175--e180},
}

@article{yun_comparative_2018,
	title = {Comparative {Effectiveness} of {Telemonitoring} {Versus} {Usual} {Care} for {Heart} {Failure}: {A} {Systematic} {Review} and {Meta}-analysis},
	volume = {24},
	copyright = {https://www.elsevier.com/tdm/userlicense/1.0/},
	issn = {10719164},
	shorttitle = {Comparative {Effectiveness} of {Telemonitoring} {Versus} {Usual} {Care} for {Heart} {Failure}},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S1071916417312113},
	doi = {10.1016/j.cardfail.2017.09.006},
	language = {en},
	number = {1},
	urldate = {2024-07-17},
	journal = {Journal of Cardiac Failure},
	author = {Yun, Ji Eun and Park, Jeong-Eun and Park, Hyun-Young and Lee, Hae-Young and Park, Dong-Ah},
	month = jan,
	year = {2018},
	keywords = {notion},
	pages = {19--28},
}

@article{pekmezaris_home_2018,
	title = {Home {Telemonitoring} {In} {Heart} {Failure}: {A} {Systematic} {Review} {And} {Meta}-{Analysis}},
	volume = {37},
	issn = {0278-2715, 1544-5208},
	shorttitle = {Home {Telemonitoring} {In} {Heart} {Failure}},
	url = {http://www.healthaffairs.org/doi/10.1377/hlthaff.2018.05087},
	doi = {10.1377/hlthaff.2018.05087},
	language = {en},
	number = {12},
	urldate = {2024-07-17},
	journal = {Health Affairs},
	author = {Pekmezaris, Renee and Tortez, Leanne and Williams, Myia and Patel, Vidhi and Makaryus, Amgad and Zeltser, Roman and Sinvani, Liron and Wolf-Klein, Gisele and Lester, Janice and Sison, Cristina and Lesser, Martin and Kozikowski, Andrzej},
	month = dec,
	year = {2018},
	keywords = {notion},
	pages = {1983--1989},
}

@article{mastroiacovo_is_2022,
	title = {Is {EuroSCORE} {II} still a reliable predictor for cardiac surgery mortality in 2022? {A} retrospective study study},
	volume = {64},
	copyright = {https://creativecommons.org/licenses/by/4.0/},
	issn = {1873-734X},
	shorttitle = {Is {EuroSCORE} {II} still a reliable predictor for cardiac surgery mortality in 2022?},
	url = {https://academic.oup.com/ejcts/article/doi/10.1093/ejcts/ezad294/7260513},
	doi = {10.1093/ejcts/ezad294},
	abstract = {Abstract
            
            
              OBJECTIVES
              The European System for Cardiac Operation Risk Evaluation II (EuroSCORE II) is the most common tool used to evaluate the perioperative risk of mortality after cardiac surgery in Europe, and its use is currently recommended by the relevant guidelines. However, recently, its role has been questioned: Several papers have suggested that these algorithms may no longer be adequate for risk prediction due to an overestimation of adult cardiac surgical risk. Our goal was to validate the EuroSCORE II in the prediction of 30-day in-hospital mortality in patients undergoing open cardiac surgery in a high-volume hospital.
            
            
              METHODS
              In this retrospective cohort study, we included all patients who underwent cardiac surgery from January 2016 to May 2022 within the departments of cardiac surgery of the Monzino Cardiology Centre in Milan, Italy. We evaluated the discrimination power of the EuroSCORE II by using the receiver operating characteristic curve and the corresponding area under the curve. We performed calibration plots to assess the concordance between the model’s prediction and the observed outcomes.
            
            
              RESULTS
              A total of 4,034 patients were included (mean age = 65.1 years; 68\% males), of which 674 (16.7\%) underwent isolated coronary artery bypass grafting. The EuroSCORE II showed a good discrimination power in predicting 30-day in-hospital mortality (area under the curve = 0.834). However, for interventions performed in an elective setting, very low values of the EuroSCORE II overestimated the observed mortality, whereas for interventions performed in an emergency setting, EuroSCORE II values above 10 extensively underestimated the observed mortality.
            
            
              CONCLUSIONS
              Our study suggests that the EuroSCORE II seems not to be a reliable score in estimating the true risk of death, especially in high-risk patients.},
	language = {en},
	number = {3},
	urldate = {2024-07-17},
	journal = {European Journal of Cardio-Thoracic Surgery},
	author = {Mastroiacovo, Giorgio and Bonomi, Alice and Ludergnani, Monica and Franchi, Matteo and Maragna, Riccardo and Pirola, Sergio and Baggiano, Andrea and Caglio, Alice and Pontone, Gianluca and Polvani, Gianluca and Merlino, Luca},
	month = jan,
	year = {2022},
	keywords = {notion},
	pages = {ezad294},
}

@article{caruso_trade-off_2020,
	title = {The trade-off between costs and outcome after cardiac surgery. {Evidence} from an {Italian} administrative registry},
	volume = {124},
	issn = {01688510},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0168851020302402},
	doi = {10.1016/j.healthpol.2020.09.005},
	language = {en},
	number = {12},
	urldate = {2024-07-17},
	journal = {Health Policy},
	author = {Caruso, Enza and Rossi Zadra, Andrea},
	month = dec,
	year = {2020},
	keywords = {notion},
	pages = {1345--1353},
}

@article{efthymiou_postdischarge_2011,
	title = {Postdischarge complications: what exactly happens when the patient goes home?},
	volume = {12},
	issn = {1569-9285, 1569-9293},
	shorttitle = {Postdischarge complications},
	url = {https://academic.oup.com/icvts/article-lookup/doi/10.1510/icvts.2010.249474},
	doi = {10.1510/icvts.2010.249474},
	language = {en},
	number = {2},
	urldate = {2024-07-17},
	journal = {Interactive CardioVascular and Thoracic Surgery},
	author = {Efthymiou, Christopher Andrew and O'Regan, David John},
	month = feb,
	year = {2011},
	keywords = {notion},
	pages = {130--134},
}

@article{nashef_euroscore_2012,
	title = {{EuroSCORE} {II}},
	volume = {41},
	issn = {1010-7940, 1873-734X},
	url = {https://academic.oup.com/ejcts/article-lookup/doi/10.1093/ejcts/ezs043},
	doi = {10.1093/ejcts/ezs043},
	language = {en},
	number = {4},
	urldate = {2024-07-17},
	journal = {European Journal of Cardio-Thoracic Surgery},
	author = {Nashef, S. A. M. and Roques, F. and Sharples, L. D. and Nilsson, J. and Smith, C. and Goldstone, A. R. and Lockowandt, U.},
	month = apr,
	year = {2012},
	keywords = {notion},
	pages = {734--745},
}

@article{sanchez_predictors_2020,
	title = {Predictors and {Risk} {Calculator} of {Early} {Unplanned} {Hospital} {Readmission} {Following} {Contemporary} {Self}-{Expanding} {Transcatheter} {Aortic} {Valve} {Replacement} from the {STS}/{ACC} {TVT} {Registry}},
	volume = {21},
	issn = {15538389},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S155383891930332X},
	doi = {10.1016/j.carrev.2019.05.032},
	language = {en},
	number = {3},
	urldate = {2024-07-17},
	journal = {Cardiovascular Revascularization Medicine},
	author = {Sanchez, Carlos E. and Hermiller, James B. and Pinto, Duane S. and Chetcuti, Stanley J. and Arshi, Arash and Forrest, John K. and Huang, Jian and Yakubov, Steven J.},
	month = mar,
	year = {2020},
	keywords = {notion},
	pages = {263--270},
}

@misc{noauthor_predictors_nodate,
	title = {Predictors and {Risk} {Calculator} of {Early} {Unplanned} {Hospital} {Readmission} {Following} {Contemporary} {Self}-{Expanding} {Transcatheter} {Aortic} {Valve} {Replacement} from the {STS}/{ACC} {TVT} {Registry} - {ScienceDirect}},
	url = {https://www.sciencedirect.com/science/article/pii/S155383891930332X?via%3Dihub},
	urldate = {2024-07-17},
	keywords = {notion},
}

@article{shawon_patient_2021,
	title = {Patient and hospital factors associated with 30-day readmissions after coronary artery bypass graft ({CABG}) surgery: a systematic review and meta-analysis},
	volume = {16},
	issn = {1749-8090},
	shorttitle = {Patient and hospital factors associated with 30-day readmissions after coronary artery bypass graft ({CABG}) surgery},
	url = {https://cardiothoracicsurgery.biomedcentral.com/articles/10.1186/s13019-021-01556-1},
	doi = {10.1186/s13019-021-01556-1},
	abstract = {Abstract
            
              Background
              Readmission after coronary artery bypass graft (CABG) surgery is associated with adverse outcomes and significant healthcare costs, and 30-day readmission rate is considered as a key indicator of the quality of care. This study aims to: quantify rates of readmission within 30 days of CABG surgery; explore the causes of readmissions; and investigate how patient- and hospital-level factors influence readmission.
            
            
              Methods
              We conducted systematic searches (until June 2020) of PubMed and Embase databases to retrieve observational studies that investigated readmission after CABG. Random effect meta-analysis was used to estimate rates and predictors of 30-day post-CABG readmission.
            
            
              Results
              In total, 53 studies meeting inclusion criteria were identified, including 8,937,457 CABG patients. The pooled 30-day readmission rate was 12.9\% (95\% CI: 11.3–14.4\%). The most frequently reported underlying causes of 30-day readmissions were infection and sepsis (range: 6.9–28.6\%), cardiac arrythmia (4.5–26.7\%), congestive heart failure (5.8–15.7\%), respiratory complications (1–20\%) and pleural effusion (0.4–22.5\%). Individual factors including age (OR per 10-year increase 1.12 [95\% CI: 1.04–1.20]), female sex (OR 1.29 [1.25–1.34]), non-White race (OR 1.15 [1.10–1.21]), not having private insurance (OR 1.39 [1.27–1.51]) and various comorbidities were strongly associated with 30-day readmission rates, whereas associations with hospital factors including hospital CABG volume, surgeon CABG volume, hospital size, hospital quality and teaching status were inconsistent.
            
            
              Conclusions
              Nearly 1 in 8 CABG patients are readmitted within 30 days and the majority of these are readmitted for noncardiac causes. Readmission rates are strongly influenced by patients’ demographic and clinical characteristics, but not by broadly defined hospital characteristics.},
	language = {en},
	number = {1},
	urldate = {2024-07-17},
	journal = {Journal of Cardiothoracic Surgery},
	author = {Shawon, Md Shajedur Rahman and Odutola, Michael and Falster, Michael O. and Jorm, Louisa R.},
	month = dec,
	year = {2021},
	keywords = {notion},
	pages = {172},
}

@misc{noauthor_patient_nodate,
	title = {Patient and hospital factors associated with 30-day readmissions after coronary artery bypass graft ({CABG}) surgery: a systematic review and meta-analysis - {PubMed}},
	url = {https://pubmed.ncbi.nlm.nih.gov/34112216/},
	urldate = {2024-07-17},
	keywords = {notion},
}

@misc{noauthor_predictors_nodate-1,
	title = {Predictors and {Risk} {Calculator} of {Early} {Unplanned} {Hospital} {Readmission} {Following} {Contemporary} {Self}-{Expanding} {Transcatheter} {Aortic} {Valve} {Replacement} from the {STS}/{ACC} {TVT} {Registry} - {PubMed}},
	url = {https://pubmed.ncbi.nlm.nih.gov/31255552/},
	urldate = {2024-07-17},
	keywords = {notion},
}

@article{khoury_readmission_2020,
	title = {Readmission {After} {Surgical} {Aortic} {Valve} {Replacement} in the {United} {States}},
	volume = {110},
	issn = {1552-6259},
	doi = {10.1016/j.athoracsur.2019.11.058},
	abstract = {BACKGROUND: Reducing inpatient readmissions is a national priority for improving healthcare quality and decreasing costs. Previous studies have shown that readmissions after surgical aortic valve replacement are frequent and contribute to increased healthcare costs, yet no studies have analyzed risk factors for readmission.
METHODS: The Nationwide Readmissions Database was used to identify adult patients undergoing surgical aortic valve replacement from 2010 to 2015. Incidence, patient characteristics, causes, resource utilization, and predictors of 30-day readmission were determined. International Classification of Diseases codes were used to capture surgical aortic valve replacement.
RESULTS: Among 136,051 patients, 18,631 (13.7\%) were readmitted within 30 days of discharge. Readmitted patients were more commonly women (47.4\% vs 41.6\%; P {\textless} .001) and were older (70.4 years of age vs 68.3 years of age; P {\textless} .001), with higher Elixhauser comorbidity index (5.4 vs 4.8; P {\textless} .001), rates of postoperative complications (44.0\% vs 37.3\%; P {\textless} .001), and greater length of stay (10.9 days vs 8.5 days; P {\textless} .001). The mean cost of 1 readmission episode was \$13,426. On multivariable analysis, significant predictors of readmission were female sex, age greater than 75 years, atrial fibrillation, chronic kidney and liver disease, and lower surgical aortic valve replacement hospital volume. A total of 49.1\% of readmissions were related to cardiac causes, with heart failure (13.2\%) and arrhythmia (12.5\%) being the most common.
CONCLUSIONS: Using a national inpatient database, we found readmission after surgical aortic valve replacement to be common and resource-intensive. Enhanced management of comorbidities and targeted postdischarge interventions for patients at high risk of readmission may help decrease healthcare utilization.},
	language = {eng},
	number = {3},
	journal = {The Annals of Thoracic Surgery},
	author = {Khoury, Habib and Ragalie, William and Sanaiha, Yas and Boutros, Hannah and Rudasill, Sarah and Shemin, Richard J. and Benharash, Peyman},
	month = sep,
	year = {2020},
	pmid = {31981500},
	keywords = {Aged, Aortic Valve Stenosis, Databases, Factual, Female, Humans, Length of Stay, Male, Patient Readmission, Postoperative Complications, Quality Improvement, Transcatheter Aortic Valve Replacement, notion},
	pages = {849--855},
}

@article{ball_postoperative_2016,
	title = {Postoperative complications of patients undergoing cardiac surgery},
	volume = {22},
	issn = {1070-5295},
	url = {https://journals.lww.com/co-criticalcare/abstract/2016/08000/postoperative_complications_of_patients_undergoing.18.aspx},
	doi = {10.1097/MCC.0000000000000319},
	abstract = {Purpose of review 
          Cardiac surgery is at high risk for the development of postoperative complications involving cardiovascular and respiratory system, as well as kidneys and central nervous system. The aim of this review is to provide an overview on the most recent findings concerning the type and incidence of different complications after cardiac surgery and to summarize the current recommendations.
          Recent findings 
          Despite an improvement of surgical and anaesthesia techniques that resulted in a significant decrease in mortality, postoperative complications play a major role in affecting morbidity, mortality, length of hospital stay and patients’ quality of life. The most recent evidence suggests that fluid and inotropes administration should be targeted to maintain a cardiac index above 3 l/min/m2 throughout the perioperative period. Volatile anaesthesia and mechanical ventilation with low tidal volumes, low driving pressure and moderate-low positive end-expiratory pressure should be preferred. Preoperative steroids could reduce postoperative atrial fibrillation, whereas no drug has shown to effectively prevent kidney injury.
          Summary 
          Cardiac surgery is still at high risk for postoperative complications. The optimal type of anaesthesia, protective mechanical ventilation during and after surgery as well as haemodynamic management with vasoactive and inotropic drugs is still to be determined.},
	language = {en-US},
	number = {4},
	urldate = {2024-07-17},
	journal = {Current Opinion in Critical Care},
	author = {Ball, Lorenzo and Costantino, Federico and Pelosi, Paolo},
	month = aug,
	year = {2016},
	keywords = {notion},
	pages = {386},
}

@misc{noauthor_euroscore_nodate,
	title = {{EuroSCORE} {II}† {\textbar} {European} {Journal} of {Cardio}-{Thoracic} {Surgery} {\textbar} {Oxford} {Academic}},
	url = {https://academic.oup.com/ejcts/article/41/4/734/646622},
	urldate = {2024-07-17},
	keywords = {notion},
}

@article{coelho_quality_2019,
	title = {Quality of life after elective cardiac surgery in elderly patients},
	volume = {28},
	issn = {1569-9285},
	url = {https://doi.org/10.1093/icvts/ivy235},
	doi = {10.1093/icvts/ivy235},
	abstract = {Cardiac surgery has little effect on life expectancy in elderly patients. Thus, improving the quality of life should be the main factor affecting therapeutic decisions. Most studies on quality of life in elderly patients undergoing cardiac surgery report improvement but have limitations. Consequently, we assessed improvements in the quality of life of elderly patients undergoing elective cardiac surgery, identified influencing variables and established patterns of mental and physical health variations in the first year postoperatively.We conducted a prospective study of patients aged 65 or older who underwent elective cardiac surgery between September 2011 and August 2013. The 36-item Short Form (SF-36) surveys were obtained preoperatively and at 3, 6 and 12 months postoperatively.The 430 preoperative patients with a mean age of 74 years (SD 5.5 years) comprised 220 men. Most physical health improvements occurred within 3 months and continued to improve significantly until 12 months. Predictive variables for patients showing less improvement were poor preoperative physical health, female sex, older age and longer length of hospital stay. Mental health improved significantly through the third postoperative month. The negative predictive variables were poor preoperative mental health and longer intensive care unit stay.Most patients improved both physically and mentally after surgery, and most of the improvement occurred within 3 months post-surgery. These improvement patterns should be taken into account when creating rehabilitation programmes, and patients should be counselled on what improvements can be expected during the first 12 months after surgery.},
	number = {2},
	urldate = {2024-07-17},
	journal = {Interactive CardioVascular and Thoracic Surgery},
	author = {Coelho, Pedro N M P and Miranda, Luís M R P C and Barros, Pedro M P and Fragata, José I G},
	month = feb,
	year = {2019},
	keywords = {notion},
	pages = {199--205},
}

@article{vervoort_global_2024,
	title = {Global {Cardiac} {Surgical} {Volume} and {Gaps}: {Trends}, {Targets}, and {Way} {Forward}},
	volume = {2},
	issn = {2772-9931},
	shorttitle = {Global {Cardiac} {Surgical} {Volume} and {Gaps}},
	url = {https://www.annalsthoracicsurgeryshortrep.org/article/S2772-9931(23)00373-X/fulltext},
	doi = {10.1016/j.atssr.2023.11.019},
	language = {English},
	number = {2},
	urldate = {2024-07-16},
	journal = {Annals of Thoracic Surgery Short Reports},
	author = {Vervoort, Dominique and Lee, Grace and Ghandour, Hiba and Guetter, Camila R. and Adreak, Najah and Till, Brian M. and Lin, Yihan},
	month = jun,
	year = {2024},
	note = {Publisher: Elsevier},
	keywords = {notion},
	pages = {320--324},
}

@incollection{moniz_unravelling_2023,
	address = {Cham},
	title = {Unravelling {Heterogeneity}: {A} {Hybrid} {Machine} {Learning} {Approach} to {Predict} {Post}-discharge {Complications} in {Cardiothoracic} {Surgery}},
	volume = {14116},
	isbn = {978-3-031-49010-1 978-3-031-49011-8},
	shorttitle = {Unravelling {Heterogeneity}},
	url = {https://link.springer.com/10.1007/978-3-031-49011-8_24},
	abstract = {Predicting post-discharge complications in cardiothoracic surgery is of utmost importance to improve clinical outcomes. Machine Learning (ML) techniques have been successfully applied in similar tasks, aiming at short time windows and in specific surgical conditions. However, as the target horizon is extended and the impact of unpredictable external factors rises, the complexity of the task increases, and traditional predictive models struggle to reproduce good performances. This study presents a two-step hybrid learning methodology to address this problem. Building up from identifying unique sub-groups of patients with shared characteristics, we then train individual supervised classification models for each sub-group, aiming at improved prediction accuracy and a more granular understanding of each decision. Our results show that specific sub-groups demonstrate substantially better performance when compared to the baseline model without sub-divisions, while others do not benefit from specialised models. Strategies such as the one presented may catalyse the success of applied ML solutions by contributing to a better understanding of their behaviour in different regions of the data space, leading to an informed decision-making process.},
	language = {en},
	urldate = {2024-07-16},
	booktitle = {Progress in {Artificial} {Intelligence}},
	publisher = {Springer Nature Switzerland},
	author = {Ribeiro, Bruno and Curioso, Isabel and Santos, Ricardo and Guede-Fernández, Federico and Coelho, Pedro and Santos, Jorge and Fragata, José and Londral, Ana and Sousa, Inês},
	editor = {Moniz, Nuno and Vale, Zita and Cascalho, José and Silva, Catarina and Sebastião, Raquel},
	year = {2023},
	doi = {10.1007/978-3-031-49011-8_24},
	note = {Series Title: Lecture Notes in Computer Science},
	pages = {298--310},
}

@article{curioso_addressing_2023,
	title = {Addressing the {Curse} of {Missing} {Data} in {Clinical} {Contexts}: {A} {Novel} {Approach} to {Correlation}-based {Imputation}},
	volume = {35},
	issn = {1319-1578},
	shorttitle = {Addressing the {Curse} of {Missing} {Data} in {Clinical} {Contexts}},
	url = {https://www.sciencedirect.com/science/article/pii/S1319157823001088},
	doi = {10.1016/j.jksuci.2023.101562},
	abstract = {Clinical data are essential in the medical domain. However, their heterogeneous nature leads to many data quality problems, notably missing values, which undermine the performance of Machine Learning-based clinical systems. Hence, there has been a growing interest in strategies that address this challenge in order to build trustworthy systems to improve the quality of care and benefit clinical decision-making. In particular, missing value imputation is a common approach. This paper proposes three novel imputation techniques that leverage correlation in an innovative manner by exploring the relationship between values and missingness patterns. Experiments were carried out on three publicly available datasets, under three missingness mechanisms with different missing rates, and on two real-world medical datasets. The imputation precision and the classification performance of the proposed techniques were evaluated in a comprehensive comparative study, which included diverse existing methods. The developed techniques outperformed state-of-the-art methods on several assessments while overcoming current flaws shared by correlation-based imputation strategies in real-world medical problems.},
	number = {6},
	urldate = {2024-07-16},
	journal = {Journal of King Saud University - Computer and Information Sciences},
	author = {Curioso, Isabel and Santos, Ricardo and Ribeiro, Bruno and Carreiro, André and Coelho, Pedro and Fragata, José and Gamboa, Hugo},
	month = jun,
	year = {2023},
	keywords = {Clinical data, Correlation, Machine learning, Missing data, Missing data imputation},
	pages = {101562},
}

@inproceedings{ribeiro_layered_2021,
	title = {Layered {Learning} for {Acute} {Hypotensive} {Episode} {Prediction} in the {ICU}: {An} {Alternative} {Approach}},
	shorttitle = {Layered {Learning} for {Acute} {Hypotensive} {Episode} {Prediction} in the {ICU}},
	url = {https://ieeexplore.ieee.org/document/9657577/?arnumber=9657577},
	doi = {10.1109/EHB52898.2021.9657577},
	abstract = {Precise machine learning models for the early identification of anomalies based on biosignal data retrieved from bedside monitors could improve intensive care, by helping clinicians make decisions in advance and produce on-time responses. However, traditional models show limitations when dealing with the high complexity of this task. Layered Learning (LL) emerges as a solution, as it consists of the hierarchical decomposition of the problem into simpler tasks. This paper explores the uncovered potential of LL in the early detection of Acute Hypotensive Episodes (AHEs). We leverage information from the MIMIC-III Database to test different subdivisions of the main task and study how to combine the outcomes from distinct layers. In addition to this, we also test a novel approach to reduce false positives in AHE predictions.},
	urldate = {2024-07-16},
	booktitle = {2021 {International} {Conference} on e-{Health} and {Bioengineering} ({EHB})},
	author = {Ribeiro, Bruno and Cerqueira, Vitor and Santos, Ricardo and Gamboa, Hugo},
	month = nov,
	year = {2021},
	note = {ISSN: 2575-5145},
	keywords = {Biological system modeling, Biosignal Processing, Complexity theory, Data models, Databases, Intensive Care, Layered Learning, MIMICs, Machine Learning, Machine learning, Predictive models},
	pages = {1--4},
}

@inproceedings{santos_risk_2023,
	address = {Cham},
	title = {A {Risk} {Prediction} {Framework} to {Optimize} {Remote} {Patient} {Monitoring} {Following} {Cardiothoracic} {Surgery}},
	isbn = {978-3-031-43430-3},
	doi = {10.1007/978-3-031-43430-3_32},
	abstract = {Remote Patient Monitoring (RPM) in cardiac surgery can become valuable for clinicians to follow patients post-discharge closely. However, these services require additional and frequently limited human and technical resources. We present the CardioFollow.AI Framework, a decision support system to assist doctors in selecting patients to be monitored remotely. Currently supporting a clinical trial, it leverages a Machine Learning model to predict the risk of post-discharge complications. Interpretable assessments are included so that clinicians can evaluate individual predictions. Additionally, the user-friendly interface of the CardioFollow.AI Framework enhances the follow-up of discharged patients by granting access to centralised information. This paper outlines the design and implementation of the CardioFollow.AI Framework and its potential impact on improving personalised patient careq.},
	language = {en},
	booktitle = {Machine {Learning} and {Knowledge} {Discovery} in {Databases}: {Applied} {Data} {Science} and {Demo} {Track}},
	publisher = {Springer Nature Switzerland},
	author = {Santos, Ricardo and Ribeiro, Bruno and Dias, Pedro and Curioso, Isabel and Madeira, Pedro and Guede-Fernández, Federico and Santos, Jorge and Coelho, Pedro and Sousa, Inês and Londral, Ana},
	editor = {De Francisci Morales, Gianmarco and Perlich, Claudia and Ruchansky, Natali and Kourtellis, Nicolas and Baralis, Elena and Bonchi, Francesco},
	year = {2023},
	pages = {366--371},
}

@article{folgado_explainability_2023,
	title = {Explainability meets uncertainty quantification: {Insights} from feature-based model fusion on multimodal time series},
	volume = {100},
	issn = {1566-2535},
	shorttitle = {Explainability meets uncertainty quantification},
	url = {https://www.sciencedirect.com/science/article/pii/S1566253523002713},
	doi = {10.1016/j.inffus.2023.101955},
	abstract = {Feature importance evaluation is one of the prevalent approaches to interpreting Machine Learning (ML) models. A drawback of using these methods for high-dimensional datasets is that they often lead to high-dimensional explanation output that hinders human analysis. This is especially true for explaining multimodal ML models, where the problem’s complexity is further exacerbated by the inclusion of multiple data modalities and an increase in the overall number of features. This work proposes a novel approach to lower the complexity of feature-based explanations. The proposed approach is based on uncertainty quantification techniques, allowing for a principled way of reducing the number of modalities required to explain the model’s predictions. We evaluated our method in three multimodal datasets comprising physiological time series. Results show that the proposed method can reduce the complexity of the explanations while maintaining a high level of accuracy in the predictions. This study illustrates an innovative example of the intersection between the disciplines of uncertainty quantification and explainable artificial intelligence.},
	urldate = {2024-07-16},
	journal = {Information Fusion},
	author = {Folgado, Duarte and Barandas, Marília and Famiglini, Lorenzo and Santos, Ricardo and Cabitza, Federico and Gamboa, Hugo},
	month = dec,
	year = {2023},
	keywords = {Complexity, Explainable AI, Feature-based explanations, Multimodal, SHAP, Uncertainty quantification},
	pages = {101955},
}

@article{narotamo_deep_2024,
	title = {Deep learning for {ECG} classification: {A} comparative study of {1D} and {2D} representations and multimodal fusion approaches},
	volume = {93},
	issn = {17468094},
	shorttitle = {Deep learning for {ECG} classification},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S174680942400199X},
	doi = {10.1016/j.bspc.2024.106141},
	language = {en},
	urldate = {2024-07-16},
	journal = {Biomedical Signal Processing and Control},
	author = {Narotamo, Hemaxi and Dias, Mariana and Santos, Ricardo and Carreiro, André V. and Gamboa, Hugo and Silveira, Margarida},
	month = jul,
	year = {2024},
	pages = {106141},
}

@article{santos_predicting_2024,
	title = {Predicting post-discharge complications in cardiothoracic surgery: {A} clinical decision support system to optimize remote patient monitoring resources},
	volume = {182},
	issn = {1386-5056},
	shorttitle = {Predicting post-discharge complications in cardiothoracic surgery},
	url = {https://www.sciencedirect.com/science/article/pii/S1386505623003258},
	doi = {10.1016/j.ijmedinf.2023.105307},
	abstract = {Cardiac surgery patients are highly prone to severe complications post-discharge. Close follow-up through remote patient monitoring can help detect adverse outcomes earlier or prevent them, closing the gap between hospital and home care. However, equipment is limited due to economic and human resource constraints. This issue raises the need for efficient risk estimation to provide clinicians with insights into the potential benefit of remote monitoring for each patient. Standard models, such as the EuroSCORE, predict the mortality risk before the surgery. While these are used and validated in real settings, the models lack information collected during or following the surgery, determinant to predict adverse outcomes occurring further in the future. This paper proposes a Clinical Decision Support System based on Machine Learning to estimate the risk of severe complications within 90 days following cardiothoracic surgery discharge, an innovative objective underexplored in the literature. Health records from a cardiothoracic surgery department regarding 5 045 patients (60.8\% male) collected throughout ten years were used to train predictive models. Clinicians' insights contributed to improving data preparation and extending traditional pipeline optimization techniques, addressing medical Artificial Intelligence requirements. Two separate test sets were used to evaluate the generalizability, one derived from a patient-grouped 70/30 split and another including all surgeries from the last available year. The achieved Area Under the Receiver Operating Characteristic curve on these test sets was 69.5\% and 65.3\%, respectively. Also, additional testing was implemented to simulate a real-world use case considering the weekly distribution of remote patient monitoring resources post-discharge. Compared to the random resource allocation, the selection of patients with respect to the outputs of the proposed model was proven beneficial, as it led to a higher number of high-risk patients receiving remote monitoring equipment.},
	urldate = {2024-07-16},
	journal = {International Journal of Medical Informatics},
	author = {Santos, Ricardo and Ribeiro, Bruno and Sousa, Inês and Santos, Jorge and Guede-Fernández, Federico and Dias, Pedro and Carreiro, André V. and Gamboa, Hugo and Coelho, Pedro and Fragata, José and Londral, Ana},
	month = feb,
	year = {2024},
	keywords = {Cardiothoracic surgery, Clinical decision support system, Complications prediction, Machine learning, Remote patient monitoring, Risk estimation},
	pages = {105307},
}

@inproceedings{jun_stochastic_2019,
	title = {Stochastic {Imputation} and {Uncertainty}-{Aware} {Attention} to {EHR} for {Mortality} {Prediction}},
	url = {https://ieeexplore.ieee.org/document/8852132},
	doi = {10.1109/IJCNN.2019.8852132},
	abstract = {Electronic health records (EHR) have become an important source of a patient data but characterized by a variety of missing values. Using the variational inference of Bayesian framework, variational autoencoder (VAE), a deep generative model, has been shown to be efficient and accurate to capture the latent structure of complex high-dimensional data. Recently, it has been used for missing data imputation. In this paper, we propose a general framework that incorporates effective missing data imputation using VAE and multivariate time series prediction. We utilize the uncertainty obtained from the generative network of the VAE and employ uncertainty-aware attention in imputing the missing values. We evaluated the performance of our architecture on real-world clinical dataset (MIMIC-III) for in-hospital mortality prediction task. Our results showed higher performance than other competing methods in mortality prediction task.},
	urldate = {2023-11-14},
	booktitle = {2019 {International} {Joint} {Conference} on {Neural} {Networks} ({IJCNN})},
	author = {Jun, Eunji and Mulyadi, Ahmad Wisnu and Suk, Heung-Il},
	month = jul,
	year = {2019},
	note = {ISSN: 2161-4407},
	keywords = {notion},
	pages = {1--7},
}

@misc{gu_mamba_2023,
	title = {Mamba: {Linear}-{Time} {Sequence} {Modeling} with {Selective} {State} {Spaces}},
	shorttitle = {Mamba},
	url = {http://arxiv.org/abs/2312.00752},
	doi = {10.48550/arXiv.2312.00752},
	abstract = {Foundation models, now powering most of the exciting applications in deep learning, are almost universally based on the Transformer architecture and its core attention module. Many subquadratic-time architectures such as linear attention, gated convolution and recurrent models, and structured state space models (SSMs) have been developed to address Transformers' computational inefficiency on long sequences, but they have not performed as well as attention on important modalities such as language. We identify that a key weakness of such models is their inability to perform content-based reasoning, and make several improvements. First, simply letting the SSM parameters be functions of the input addresses their weakness with discrete modalities, allowing the model to selectively propagate or forget information along the sequence length dimension depending on the current token. Second, even though this change prevents the use of efficient convolutions, we design a hardware-aware parallel algorithm in recurrent mode. We integrate these selective SSMs into a simplified end-to-end neural network architecture without attention or even MLP blocks (Mamba). Mamba enjoys fast inference (5\${\textbackslash}times\$ higher throughput than Transformers) and linear scaling in sequence length, and its performance improves on real data up to million-length sequences. As a general sequence model backbone, Mamba achieves state-of-the-art performance across several modalities such as language, audio, and genomics. On language modeling, our Mamba-3B model outperforms Transformers of the same size and matches Transformers twice its size, both in pretraining and downstream evaluation.},
	urldate = {2024-01-08},
	publisher = {arXiv},
	author = {Gu, Albert and Dao, Tri},
	month = dec,
	year = {2023},
	note = {arXiv:2312.00752 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning, notion},
}

@article{xie_deep_2022,
	title = {Deep learning for temporal data representation in electronic health records: {A} systematic review of challenges and methodologies},
	volume = {126},
	issn = {1532-0464},
	shorttitle = {Deep learning for temporal data representation in electronic health records},
	url = {https://www.sciencedirect.com/science/article/pii/S1532046421003099},
	doi = {10.1016/j.jbi.2021.103980},
	abstract = {Objective
Temporal electronic health records (EHRs) contain a wealth of information for secondary uses, such as clinical events prediction and chronic disease management. However, challenges exist for temporal data representation. We therefore sought to identify these challenges and evaluate novel methodologies for addressing them through a systematic examination of deep learning solutions.
Methods
We searched five databases (PubMed, Embase, the Institute of Electrical and Electronics Engineers [IEEE] Xplore Digital Library, the Association for Computing Machinery [ACM] Digital Library, and Web of Science) complemented with hand-searching in several prestigious computer science conference proceedings. We sought articles that reported deep learning methodologies on temporal data representation in structured EHR data from January 1, 2010, to August 30, 2020. We summarized and analyzed the selected articles from three perspectives: nature of time series, methodology, and model implementation.
Results
We included 98 articles related to temporal data representation using deep learning. Four major challenges were identified, including data irregularity, heterogeneity, sparsity, and model opacity. We then studied how deep learning techniques were applied to address these challenges. Finally, we discuss some open challenges arising from deep learning.
Conclusion
Temporal EHR data present several major challenges for clinical prediction modeling and data utilization. To some extent, current deep learning solutions can address these challenges. Future studies may consider designing comprehensive and integrated solutions. Moreover, researchers should incorporate clinical domain knowledge into study designs and enhance model interpretability to facilitate clinical implementation.},
	urldate = {2023-11-14},
	journal = {Journal of Biomedical Informatics},
	author = {Xie, Feng and Yuan, Han and Ning, Yilin and Ong, Marcus Eng Hock and Feng, Mengling and Hsu, Wynne and Chakraborty, Bibhas and Liu, Nan},
	month = feb,
	year = {2022},
	keywords = {Deep learning, Electronic health records, Representation, Systematic review, Temporal data, notion},
	pages = {103980},
}

@article{liu_armour_2023,
	title = {{ARMOUR}: {Attention}-based multimodal fusion with contrast for robust clinical prediction in the face of missing modalities},
	volume = {145},
	issn = {1532-0464},
	url = {https://www.sciencedirect.com/science/article/pii/S1532046423001879},
	doi = {10.1016/j.jbi.2023.104466},
	abstract = {Objective:
With the increasing amount and growing variety of healthcare data, multimodal machine learning supporting integrated modeling of structured and unstructured data is an increasingly important tool for clinical machine learning tasks. However, it is non-trivial to manage the differences in dimensionality, volume, and temporal characteristics of data modalities in the context of a shared target task. Furthermore, patients can have substantial variations in the availability of data, while existing multimodal modeling methods typically assume data completeness and lack a mechanism to handle missing modalities.
Methods:
We propose a Transformer-based fusion model with modality-specific tokens that summarize the corresponding modalities to achieve effective cross-modal interaction accommodating missing modalities in the clinical context. The model is further refined by inter-modal, inter-sample contrastive learning to improve the representations for better predictive performance. We denote the model as Attention-based cRoss-MOdal fUsion with contRast (ARMOUR). We evaluate ARMOUR using two input modalities (structured measurements and unstructured text), six clinical prediction tasks, and two evaluation regimes, either including or excluding samples with missing modalities.
Results:
Our model shows improved performances over unimodal or multimodal baselines in both evaluation regimes, including or excluding patients with missing modalities in the input. The contrastive learning improves the representation power and is shown to be essential for better results. The simple setup of modality-specific tokens enables ARMOUR to handle patients with missing modalities and allows comparison with existing unimodal benchmark results.
Conclusion:
We propose a multimodal model for robust clinical prediction to achieve improved performance while accommodating patients with missing modalities. This work could inspire future research to study the effective incorporation of multiple, more complex modalities of clinical data into a single model.},
	urldate = {2023-11-14},
	journal = {Journal of Biomedical Informatics},
	author = {Liu, Jinghui and Capurro, Daniel and Nguyen, Anthony and Verspoor, Karin},
	month = sep,
	year = {2023},
	keywords = {Clinical prediction, Machine learning, Missing modality, Multimodal modeling, Natural language processing, notion},
	pages = {104466},
}

@article{suo_multi-task_2017,
	title = {A {Multi}-{Task} {Framework} for {Monitoring} {Health} {Conditions} via {Attention}-based {Recurrent} {Neural} {Networks}},
	volume = {2017},
	issn = {1942-597X},
	abstract = {Monitoring the future health status of patients from the historical Electronic Health Record (EHR) is a core research topic in predictive healthcare. The most important challenges are to model the temporality of sequential EHR data and to interpret the prediction results. In order to reduce the future risk of diseases, we propose a multi-task framework that can monitor the multiple status ofdiagnoses. Patients' historical records are directly fed into a Recurrent Neural Network (RNN) which memorizes all the past visit information, and then a task-specific layer is trained to predict multiple diagnoses. Moreover, three attention mechanisms for RNNs are introduced to measure the relationships between past visits and current status. Experimental results show that the proposed attention-based RNNs can significantly improve the prediction accuracy compared to widely used approaches. With the attention mechanisms, the proposed framework is able to identify the visit information which is important to the final prediction.},
	language = {English},
	journal = {AMIA ... Annual Symposium proceedings. AMIA Symposium},
	author = {Suo, Q. and Ma, F. and Canino, G. and Gao, J. and Zhang, A. and Veltri, P. and Agostino, G.},
	year = {2017},
	keywords = {notion},
	pages = {1665--1674},
}

@article{guo_multi-center_2024,
	title = {A multi-center study on the adaptability of a shared foundation model for electronic health records},
	volume = {7},
	copyright = {2024 The Author(s)},
	issn = {2398-6352},
	url = {https://www.nature.com/articles/s41746-024-01166-w},
	doi = {10.1038/s41746-024-01166-w},
	abstract = {Foundation models are transforming artificial intelligence (AI) in healthcare by providing modular components adaptable for various downstream tasks, making AI development more scalable and cost-effective. Foundation models for structured electronic health records (EHR), trained on coded medical records from millions of patients, demonstrated benefits including increased performance with fewer training labels, and improved robustness to distribution shifts. However, questions remain on the feasibility of sharing these models across hospitals and their performance in local tasks. This multi-center study examined the adaptability of a publicly accessible structured EHR foundation model (FMSM), trained on 2.57 M patient records from Stanford Medicine. Experiments used EHR data from The Hospital for Sick Children (SickKids) and Medical Information Mart for Intensive Care (MIMIC-IV). We assessed both adaptability via continued pretraining on local data, and task adaptability compared to baselines of locally training models from scratch, including a local foundation model. Evaluations on 8 clinical prediction tasks showed that adapting the off-the-shelf FMSM matched the performance of gradient boosting machines (GBM) locally trained on all data while providing a 13\% improvement in settings with few task-specific training labels. Continued pretraining on local data showed FMSM required fewer than 1\% of training examples to match the fully trained GBM’s performance, and was 60 to 90\% more sample-efficient than training local foundation models from scratch. Our findings demonstrate that adapting EHR foundation models across hospitals provides improved prediction performance at less cost, underscoring the utility of base foundation models as modular components to streamline the development of healthcare AI.},
	language = {en},
	number = {1},
	urldate = {2024-07-09},
	journal = {npj Digital Medicine},
	author = {Guo, Lin Lawrence and Fries, Jason and Steinberg, Ethan and Fleming, Scott Lanyon and Morse, Keith and Aftandilian, Catherine and Posada, Jose and Shah, Nigam and Sung, Lillian},
	month = jun,
	year = {2024},
	note = {Publisher: Nature Publishing Group},
	keywords = {Computer science, Machine learning, notion},
	pages = {1--9},
}

@misc{bommasani_opportunities_2022,
	title = {On the {Opportunities} and {Risks} of {Foundation} {Models}},
	url = {http://arxiv.org/abs/2108.07258},
	abstract = {AI is undergoing a paradigm shift with the rise of models (e.g., BERT, DALL-E, GPT-3) that are trained on broad data at scale and are adaptable to a wide range of downstream tasks. We call these models foundation models to underscore their critically central yet incomplete character. This report provides a thorough account of the opportunities and risks of foundation models, ranging from their capabilities (e.g., language, vision, robotics, reasoning, human interaction) and technical principles(e.g., model architectures, training procedures, data, systems, security, evaluation, theory) to their applications (e.g., law, healthcare, education) and societal impact (e.g., inequity, misuse, economic and environmental impact, legal and ethical considerations). Though foundation models are based on standard deep learning and transfer learning, their scale results in new emergent capabilities,and their effectiveness across so many tasks incentivizes homogenization. Homogenization provides powerful leverage but demands caution, as the defects of the foundation model are inherited by all the adapted models downstream. Despite the impending widespread deployment of foundation models, we currently lack a clear understanding of how they work, when they fail, and what they are even capable of due to their emergent properties. To tackle these questions, we believe much of the critical research on foundation models will require deep interdisciplinary collaboration commensurate with their fundamentally sociotechnical nature.},
	language = {en},
	urldate = {2024-07-08},
	publisher = {arXiv},
	author = {Bommasani, Rishi and Hudson, Drew A. and Adeli, Ehsan and Altman, Russ and Arora, Simran and von Arx, Sydney and Bernstein, Michael S. and Bohg, Jeannette and Bosselut, Antoine and Brunskill, Emma and Brynjolfsson, Erik and Buch, Shyamal and Card, Dallas and Castellon, Rodrigo and Chatterji, Niladri and Chen, Annie and Creel, Kathleen and Davis, Jared Quincy and Demszky, Dora and Donahue, Chris and Doumbouya, Moussa and Durmus, Esin and Ermon, Stefano and Etchemendy, John and Ethayarajh, Kawin and Fei-Fei, Li and Finn, Chelsea and Gale, Trevor and Gillespie, Lauren and Goel, Karan and Goodman, Noah and Grossman, Shelby and Guha, Neel and Hashimoto, Tatsunori and Henderson, Peter and Hewitt, John and Ho, Daniel E. and Hong, Jenny and Hsu, Kyle and Huang, Jing and Icard, Thomas and Jain, Saahil and Jurafsky, Dan and Kalluri, Pratyusha and Karamcheti, Siddharth and Keeling, Geoff and Khani, Fereshte and Khattab, Omar and Koh, Pang Wei and Krass, Mark and Krishna, Ranjay and Kuditipudi, Rohith and Kumar, Ananya and Ladhak, Faisal and Lee, Mina and Lee, Tony and Leskovec, Jure and Levent, Isabelle and Li, Xiang Lisa and Li, Xuechen and Ma, Tengyu and Malik, Ali and Manning, Christopher D. and Mirchandani, Suvir and Mitchell, Eric and Munyikwa, Zanele and Nair, Suraj and Narayan, Avanika and Narayanan, Deepak and Newman, Ben and Nie, Allen and Niebles, Juan Carlos and Nilforoshan, Hamed and Nyarko, Julian and Ogut, Giray and Orr, Laurel and Papadimitriou, Isabel and Park, Joon Sung and Piech, Chris and Portelance, Eva and Potts, Christopher and Raghunathan, Aditi and Reich, Rob and Ren, Hongyu and Rong, Frieda and Roohani, Yusuf and Ruiz, Camilo and Ryan, Jack and Ré, Christopher and Sadigh, Dorsa and Sagawa, Shiori and Santhanam, Keshav and Shih, Andy and Srinivasan, Krishnan and Tamkin, Alex and Taori, Rohan and Thomas, Armin W. and Tramèr, Florian and Wang, Rose E. and Wang, William and Wu, Bohan and Wu, Jiajun and Wu, Yuhuai and Xie, Sang Michael and Yasunaga, Michihiro and You, Jiaxuan and Zaharia, Matei and Zhang, Michael and Zhang, Tianyi and Zhang, Xikun and Zhang, Yuhui and Zheng, Lucia and Zhou, Kaitlyn and Liang, Percy},
	month = jul,
	year = {2022},
	note = {arXiv:2108.07258 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computers and Society, Computer Science - Machine Learning, notion},
}

@misc{pan_self-correcting_2019,
	title = {A {Self}-{Correcting} {Deep} {Learning} {Approach} to {Predict} {Acute} {Conditions} in {Critical} {Care}},
	url = {http://arxiv.org/abs/1901.04364},
	abstract = {In critical care, intensivists are required to continuously monitor high dimensional vital signs and lab measurements to detect and diagnose acute patient conditions. This has always been a challenging task. In this study, we propose a novel self-correcting deep learning prediction approach to address this challenge. We focus on an example of the prediction of acute kidney injury (AKI). Compared with the existing models, our method has a number of distinct features: we utilized the accumulative data of patients in ICU; we developed a selfcorrecting mechanism that feeds errors from the previous predictions back into the network; we also proposed a regularization method that takes into account not only the model’s prediction error on the label but also its estimation errors on the input data. This mechanism is applied in both regression and classiﬁcation tasks. We compared the performance of our proposed method with the conventional deep learning models on two real-world clinical datasets and demonstrated that our proposed model constantly outperforms these baseline models. In particular, the proposed model achieved area under ROC curve at 0.893 on the MIMIC III dataset, and 0.871 on the Philips eICU dataset.},
	language = {en},
	urldate = {2024-06-21},
	publisher = {arXiv},
	author = {Pan, Ziyuan and Du, Hao and Ngiam, Kee Yuan and Wang, Fei and Shum, Ping and Feng, Mengling},
	month = jan,
	year = {2019},
	note = {arXiv:1901.04364 [cs, stat]},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@article{rank_deep-learning-based_2020,
	title = {Deep-learning-based real-time prediction of acute kidney injury outperforms human predictive performance},
	volume = {3},
	copyright = {2020 The Author(s)},
	issn = {2398-6352},
	url = {https://www.nature.com/articles/s41746-020-00346-8},
	doi = {10.1038/s41746-020-00346-8},
	abstract = {Acute kidney injury (AKI) is a major complication after cardiothoracic surgery. Early prediction of AKI could prompt preventive measures, but is challenging in the clinical routine. One important reason is that the amount of postoperative data is too massive and too high-dimensional to be effectively processed by the human operator. We therefore sought to develop a deep-learning-based algorithm that is able to predict postoperative AKI prior to the onset of symptoms and complications. Based on 96 routinely collected parameters we built a recurrent neural network (RNN) for real-time prediction of AKI after cardiothoracic surgery. From the data of 15,564 admissions we constructed a balanced training set (2224 admissions) for the development of the RNN. The model was then evaluated on an independent test set (350 admissions) and yielded an area under curve (AUC) (95\% confidence interval) of 0.893 (0.862–0.924). We compared the performance of our model against that of experienced clinicians. The RNN significantly outperformed clinicians (AUC = 0.901 vs. 0.745, p {\textless} 0.001) and was overall well calibrated. This was not the case for the physicians, who systematically underestimated the risk (p {\textless} 0.001). In conclusion, the RNN was superior to physicians in the prediction of AKI after cardiothoracic surgery. It could potentially be integrated into hospitals’ electronic health records for real-time patient monitoring and may help to detect early AKI and hence modify the treatment in perioperative care.},
	language = {en},
	number = {1},
	urldate = {2024-06-21},
	journal = {npj Digital Medicine},
	author = {Rank, Nina and Pfahringer, Boris and Kempfert, Jörg and Stamm, Christof and Kühne, Titus and Schoenrath, Felix and Falk, Volkmar and Eickhoff, Carsten and Meyer, Alexander},
	month = oct,
	year = {2020},
	note = {Publisher: Nature Publishing Group},
	keywords = {Diagnosis, Preventive medicine},
	pages = {1--12},
}

@article{shamout_machine_2021,
	title = {Machine {Learning} for {Clinical} {Outcome} {Prediction}},
	volume = {14},
	issn = {1941-1189},
	url = {https://ieeexplore.ieee.org/document/9134853},
	doi = {10.1109/RBME.2020.3007816},
	abstract = {Clinical decision-making in healthcare is already being influenced by predictions or recommendations made by data-driven machines. Numerous machine learning applications have appeared in the latest clinical literature, especially for outcome prediction models, with outcomes ranging from mortality and cardiac arrest to acute kidney injury and arrhythmia. In this review article, we summarize the state-of-the-art in related works covering data processing, inference, and model evaluation, in the context of outcome prediction models developed using data extracted from electronic health records. We also discuss limitations of prominent modeling assumptions and highlight opportunities for future research.},
	urldate = {2024-06-21},
	journal = {IEEE Reviews in Biomedical Engineering},
	author = {Shamout, Farah and Zhu, Tingting and Clifton, David A.},
	year = {2021},
	note = {Conference Name: IEEE Reviews in Biomedical Engineering},
	keywords = {Big Data applications, Decision support systems, Electronic medical records, Feature extraction, Learning (artificial intelligence), Machine learning, Predictive models, big data applications, decision support systems, electronic medical records, machine learning, notion},
	pages = {116--126},
}

@article{kellum_acute_2021,
	title = {Acute kidney injury},
	volume = {7},
	copyright = {2021 Springer Nature Limited},
	issn = {2056-676X},
	url = {https://www.nature.com/articles/s41572-021-00284-z},
	doi = {10.1038/s41572-021-00284-z},
	abstract = {Acute kidney injury (AKI) is defined by a sudden loss of excretory kidney function. AKI is part of a range of conditions summarized as acute kidney diseases and disorders (AKD), in which slow deterioration of kidney function or persistent kidney dysfunction is associated with an irreversible loss of kidney cells and nephrons, which can lead to chronic kidney disease (CKD). New biomarkers to identify injury before function loss await clinical implementation. AKI and AKD are a global concern. In low-income and middle-income countries, infections and hypovolaemic shock are the predominant causes of AKI. In high-income countries, AKI mostly occurs in elderly patients who are in hospital, and is related to sepsis, drugs or invasive procedures. Infection and trauma-related AKI and AKD are frequent in all regions. The large spectrum of AKI implies diverse pathophysiological mechanisms. AKI management in critical care settings is challenging, including appropriate volume control, nephrotoxic drug management, and the timing and type of kidney support. Fluid and electrolyte management are essential. As AKI can be lethal, kidney replacement therapy is frequently required. AKI has a poor prognosis in critically ill patients. Long-term consequences of AKI and AKD include CKD and cardiovascular morbidity. Thus, prevention and early detection of AKI are essential.},
	language = {en},
	number = {1},
	urldate = {2024-06-21},
	journal = {Nature Reviews Disease Primers},
	author = {Kellum, John A. and Romagnani, Paola and Ashuntantang, Gloria and Ronco, Claudio and Zarbock, Alexander and Anders, Hans-Joachim},
	month = jul,
	year = {2021},
	note = {Publisher: Nature Publishing Group},
	keywords = {Acute kidney injury, Risk factors, notion},
	pages = {1--17},
}

@article{thomas_definition_2015,
	title = {The definition of acute kidney injury and its use in practice},
	volume = {87},
	issn = {0085-2538},
	url = {https://www.sciencedirect.com/science/article/pii/S0085253815300351},
	doi = {10.1038/ki.2014.328},
	abstract = {Acute kidney injury (AKI) is a common syndrome that is independently associated with increased mortality. A standardized definition is important to facilitate clinical care and research. The definition of AKI has evolved rapidly since 2004, with the introduction of the Risk, Injury, Failure, Loss, and End-stage renal disease (RIFLE), AKI Network (AKIN), and Kidney Disease Improving Global Outcomes (KDIGO) classifications. RIFLE was modified for pediatric use (pRIFLE). They were developed using both evidence and consensus. Small rises in serum creatinine are independently associated with increased mortality, and hence are incorporated into the current definition of AKI. The recent definition from the international KDIGO guideline merged RIFLE and AKIN. Systematic review has found that these definitions do not differ significantly in their performance. Health-care staff caring for children or adults should use standard criteria for AKI, such as the pRIFLE or KDIGO definitions, respectively. These efforts to standardize AKI definition are a substantial advance, although areas of uncertainty remain. The new definitions have enabled the use of electronic alerts to warn clinicians of possible AKI. Novel biomarkers may further refine the definition of AKI, but their use will need to produce tangible improvements in outcomes and cost effectiveness. Further developments in AKI definitions should be informed by research into their practical application across health-care providers. This review will discuss the definition of AKI and its use in practice for clinicians and laboratory scientists.},
	number = {1},
	urldate = {2024-06-21},
	journal = {Kidney International},
	author = {Thomas, Mark E. and Blaine, Caroline and Dawnay, Anne and Devonald, Mark A. J. and Ftouh, Saoussen and Laing, Chris and Latchem, Susan and Lewington, Andrew and Milford, David V. and Ostermann, Marlies},
	month = jan,
	year = {2015},
	keywords = {acute kidney injury, chronic kidney disease, creatinine, notion},
	pages = {62--73},
}

@article{noauthor_explainable_nodate,
	title = {Explainable {Artificial} {Intelligence} in {Time} {Series}   {Applied} to {Physiological} {Data}},
	language = {en},
}

@article{johnson_mimic-iii_2016,
	title = {{MIMIC}-{III}, a freely accessible critical care database},
	volume = {3},
	copyright = {2016 The Author(s)},
	issn = {2052-4463},
	url = {https://www.nature.com/articles/sdata201635},
	doi = {10.1038/sdata.2016.35},
	abstract = {MIMIC-III (‘Medical Information Mart for Intensive Care’) is a large, single-center database comprising information relating to patients admitted to critical care units at a large tertiary care hospital. Data includes vital signs, medications, laboratory measurements, observations and notes charted by care providers, fluid balance, procedure codes, diagnostic codes, imaging reports, hospital length of stay, survival data, and more. The database supports applications including academic and industrial research, quality improvement initiatives, and higher education coursework.},
	language = {en},
	number = {1},
	urldate = {2024-05-14},
	journal = {Scientific Data},
	author = {Johnson, Alistair E. W. and Pollard, Tom J. and Shen, Lu and Lehman, Li-wei H. and Feng, Mengling and Ghassemi, Mohammad and Moody, Benjamin and Szolovits, Peter and Anthony Celi, Leo and Mark, Roger G.},
	month = may,
	year = {2016},
	note = {Publisher: Nature Publishing Group},
	keywords = {Diagnosis, Health care, Medical research, Outcomes research, Prognosis, notion},
	pages = {160035},
}

@incollection{goharian_incorporating_2024,
	address = {Cham},
	title = {Incorporating {Query} {Recommendation} for {Improving} {In}-{Car} {Conversational} {Search}},
	volume = {14612},
	isbn = {978-3-031-56068-2 978-3-031-56069-9},
	url = {https://link.springer.com/10.1007/978-3-031-56069-9_36},
	language = {en},
	urldate = {2024-05-13},
	booktitle = {Advances in {Information} {Retrieval}},
	publisher = {Springer Nature Switzerland},
	author = {Rony, Md. Rashad Al Hasan and Sahoo, Soumya Ranjan and Khan, Abbas Goher and Friedl, Ken E. and Sudhi, Viju and Süß, Christian},
	editor = {Goharian, Nazli and Tonellotto, Nicola and He, Yulan and Lipani, Aldo and McDonald, Graham and Macdonald, Craig and Ounis, Iadh},
	year = {2024},
	doi = {10.1007/978-3-031-56069-9_36},
	note = {Series Title: Lecture Notes in Computer Science},
	pages = {304--312},
}

@misc{mirza_illuminer_2024,
	title = {{ILLUMINER}: {Instruction}-tuned {Large} {Language} {Models} as {Few}-shot {Intent} {Classifier} and {Slot} {Filler}},
	shorttitle = {{ILLUMINER}},
	url = {http://arxiv.org/abs/2403.17536},
	abstract = {State-of-the-art intent classification (IC) and slot filling (SF) methods often rely on data-intensive deep learning models, limiting their practicality for industry applications. Large language models on the other hand, particularly instruction-tuned models (Instruct-LLMs), exhibit remarkable zero-shot performance across various natural language tasks. This study evaluates Instruct-LLMs on popular benchmark datasets for IC and SF, emphasizing their capacity to learn from fewer examples. We introduce ILLUMINER, an approach framing IC and SF as language generation tasks for Instruct-LLMs, with a more efficient SF-prompting method compared to prior work. A comprehensive comparison with multiple baselines shows that our approach, using the FLAN-T5 11B model, outperforms the state-of-the-art joint IC+SF method and in-context learning with GPT3.5 (175B), particularly in slot filling by 11.1--32.2 percentage points. Additionally, our in-depth ablation study demonstrates that parameter-efficient fine-tuning requires less than 6\% of training data to yield comparable performance with traditional full-weight fine-tuning.},
	urldate = {2024-05-13},
	publisher = {arXiv},
	author = {Mirza, Paramita and Sudhi, Viju and Sahoo, Soumya Ranjan and Bhat, Sinchana Ramakanth},
	month = mar,
	year = {2024},
	note = {arXiv:2403.17536 [cs]},
	keywords = {Computer Science - Computation and Language},
}

@misc{ali_tokenizer_2024,
	title = {Tokenizer {Choice} {For} {LLM} {Training}: {Negligible} or {Crucial}?},
	shorttitle = {Tokenizer {Choice} {For} {LLM} {Training}},
	url = {http://arxiv.org/abs/2310.08754},
	abstract = {The recent success of Large Language Models (LLMs) has been predominantly driven by curating the training dataset composition, scaling of model architectures and dataset sizes and advancements in pretraining objectives, leaving tokenizer influence as a blind spot. Shedding light on this underexplored area, we conduct a comprehensive study on the influence of tokenizer choice on LLM downstream performance by training 24 mono- and multilingual LLMs at a 2.6B parameter scale, ablating different tokenizer algorithms and parameterizations. Our studies highlight that the tokenizer choice can significantly impact the model's downstream performance and training costs. In particular, we find that the common tokenizer evaluation metrics fertility and parity are not always predictive of model downstream performance, rendering these metrics a questionable proxy for the model's downstream performance. Furthermore, we show that multilingual tokenizers trained on the five most frequent European languages require vocabulary size increases of factor three in comparison to English. While English-centric tokenizers have been applied to the training of multi-lingual LLMs in the past, we find that this approach results in a severe downstream performance degradation and additional training costs of up to 68\%, due to an inefficient tokenization vocabulary.},
	urldate = {2024-05-13},
	publisher = {arXiv},
	author = {Ali, Mehdi and Fromm, Michael and Thellmann, Klaudia and Rutmann, Richard and Lübbering, Max and Leveling, Johannes and Klug, Katrin and Ebert, Jan and Doll, Niclas and Buschhoff, Jasper Schulze and Jain, Charvi and Weber, Alexander Arno and Jurkschat, Lena and Abdelwahab, Hammam and John, Chelsea and Suarez, Pedro Ortiz and Ostendorff, Malte and Weinbach, Samuel and Sifa, Rafet and Kesselheim, Stefan and Flores-Herr, Nicolas},
	month = mar,
	year = {2024},
	note = {arXiv:2310.08754 [cs]},
	keywords = {Computer Science - Machine Learning},
}

@misc{weber_investigating_2024,
	title = {Investigating {Multilingual} {Instruction}-{Tuning}: {Do} {Polyglot} {Models} {Demand} for {Multilingual} {Instructions}?},
	shorttitle = {Investigating {Multilingual} {Instruction}-{Tuning}},
	url = {http://arxiv.org/abs/2402.13703},
	abstract = {The adaption of multilingual pre-trained Large Language Models (LLMs) into eloquent and helpful assistants is essential to facilitate their use across different language regions. In that spirit, we are the first to conduct an extensive study of the performance of multilingual models on parallel, multi-turn instruction-tuning benchmarks across a selection of the most-spoken Indo-European languages. We systematically examine the effects of language and instruction dataset size on a mid-sized, multilingual LLM by instruction-tuning it on parallel instruction-tuning datasets. Our results demonstrate that instruction-tuning on parallel instead of monolingual corpora benefits cross-lingual instruction following capabilities by up to 4.6\%. Furthermore, we show that the Superficial Alignment Hypothesis does not hold in general, as the investigated multilingual 7B parameter model presents a counter-example requiring large-scale instruction-tuning datasets. Finally, we conduct a human annotation study to understand the alignment between human-based and GPT-4-based evaluation within multilingual chat scenarios.},
	urldate = {2024-05-13},
	publisher = {arXiv},
	author = {Weber, Alexander Arno and Thellmann, Klaudia and Ebert, Jan and Flores-Herr, Nicolas and Lehmann, Jens and Fromm, Michael and Ali, Mehdi},
	month = feb,
	year = {2024},
	note = {arXiv:2402.13703 [cs]},
	keywords = {Computer Science - Computation and Language},
}

@misc{noauthor_diffusion_nodate,
	title = {Diffusion {Models} for {Tabular} {Data} {Imputation} and {Synthetic} {Data} {Generation} {\textbar} {OpenReview}},
	url = {https://openreview.net/forum?id=wiYV0KDAE6},
	urldate = {2024-05-10},
}

@misc{liu_towards_2023,
	title = {Towards {Graph} {Foundation} {Models}: {A} {Survey} and {Beyond}},
	shorttitle = {Towards {Graph} {Foundation} {Models}},
	url = {http://arxiv.org/abs/2310.11829},
	abstract = {Foundation models have emerged as critical components in a variety of artificial intelligence applications, and showcase significant success in natural language processing and several other domains. Meanwhile, the field of graph machine learning is witnessing a paradigm transition from shallow methods to more sophisticated deep learning approaches. The capabilities of foundation models to generalize and adapt motivate graph machine learning researchers to discuss the potential of developing a new graph learning paradigm. This paradigm envisions models that are pre-trained on extensive graph data and can be adapted for various graph tasks. Despite this burgeoning interest, there is a noticeable lack of clear definitions and systematic analyses pertaining to this new domain. To this end, this article introduces the concept of Graph Foundation Models (GFMs), and offers an exhaustive explanation of their key characteristics and underlying technologies. We proceed to classify the existing work related to GFMs into three distinct categories, based on their dependence on graph neural networks and large language models. In addition to providing a thorough review of the current state of GFMs, this article also outlooks potential avenues for future research in this rapidly evolving domain.},
	urldate = {2024-05-10},
	publisher = {arXiv},
	author = {Liu, Jiawei and Yang, Cheng and Lu, Zhiyuan and Chen, Junze and Li, Yibo and Zhang, Mengmei and Bai, Ting and Fang, Yuan and Sun, Lichao and Yu, Philip S. and Shi, Chuan},
	month = dec,
	year = {2023},
	note = {arXiv:2310.11829 [cs]},
	keywords = {Computer Science - Machine Learning},
}

@misc{noauthor_data_nodate,
	title = {Data {Science} {Platform} {Market} {Size} \& {Growth}},
	url = {https://www.marketsandmarkets.com/Market-Reports/data-science-platform-market-21532997.html},
	abstract = {The global data science platform market size is projected to grow from \$95.3 billion in 2021 to \$322.9 billion by 2026, at a CAGR of 27.7\%},
	urldate = {2024-05-10},
	journal = {MarketsandMarkets},
}

@article{baptista_federated_2023,
	title = {Federated {Learning} for {Computer}-{Aided} {Diagnosis} of {Glaucoma} {Using} {Retinal} {Fundus} {Images}},
	volume = {13},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	issn = {2076-3417},
	url = {https://www.mdpi.com/2076-3417/13/21/11620},
	doi = {10.3390/app132111620},
	abstract = {Deep learning approaches require a large amount of data to be transferred to centralized entities. However, this is often not a feasible option in healthcare, as it raises privacy concerns over sharing sensitive information. Federated Learning (FL) aims to address this issue by allowing machine learning without transferring the data to a centralized entity. FL has shown great potential to ensure privacy in digital healthcare while maintaining performance. Despite this, there is a lack of research on the impact of different types of data heterogeneity on the results. In this study, we research the robustness of various FL strategies on different data distributions and data quality for glaucoma diagnosis using retinal fundus images. We use RetinaQualEvaluator to generate quality labels for the datasets and then a data distributor to achieve our desired distributions. Finally, we evaluate the performance of the different strategies on local data and an independent test dataset. We observe that federated learning shows the potential to enable high-performance models without compromising sensitive data. Furthermore, we infer that FedProx is more suitable to scenarios where the distributions and quality of the data of the participating clients is diverse with less communication cost.},
	language = {en},
	number = {21},
	urldate = {2024-05-09},
	journal = {Applied Sciences},
	author = {Baptista, Telmo and Soares, Carlos and Oliveira, Tiago and Soares, Filipe},
	month = jan,
	year = {2023},
	note = {Number: 21
Publisher: Multidisciplinary Digital Publishing Institute},
	keywords = {federated learning, fundus images, glaucoma, image processing, retina quality},
	pages = {11620},
}

@misc{noauthor_addressing_nodate,
	title = {Addressing the {Curse} of {Missing} {Data} in {Clinical} {Contexts}: {A} {Novel} {Approach} to {Correlation}-based {Imputation} - {ScienceDirect}},
	url = {https://www.sciencedirect.com/science/article/pii/S1319157823001088},
	urldate = {2024-05-09},
}

@article{barandas_evaluation_2024,
	title = {Evaluation of uncertainty quantification methods in multi-label classification: {A} case study with automatic diagnosis of electrocardiogram},
	volume = {101},
	issn = {1566-2535},
	shorttitle = {Evaluation of uncertainty quantification methods in multi-label classification},
	url = {https://www.sciencedirect.com/science/article/pii/S1566253523002944},
	doi = {10.1016/j.inffus.2023.101978},
	abstract = {Artificial Intelligence (AI) use in automated Electrocardiogram (ECG) classification has continuously attracted the research community’s interest, motivated by their promising results. Despite their great promise, limited attention has been paid to the robustness of their results, which is a key element for their implementation in clinical practice. Uncertainty Quantification (UQ) is a critical for trustworthy and reliable AI, particularly in safety-critical domains such as medicine. Estimating uncertainty in Machine Learning (ML) model predictions has been extensively used for Out-of-Distribution (OOD) detection under single-label tasks. However, the use of UQ methods in multi-label classification remains underexplored. This study goes beyond developing highly accurate models comparing five uncertainty quantification methods using the same Deep Neural Network (DNN) architecture across various validation scenarios, including internal and external validation as well as OOD detection, taking multi-label ECG classification as the example domain. We show the importance of external validation and its impact on classification performance, uncertainty estimates quality, and calibration. Ensemble-based methods yield more robust uncertainty estimations than single network or stochastic methods. Although current methods still have limitations in accurately quantifying uncertainty, particularly in the case of dataset shift, incorporating uncertainty estimates with a classification with a rejection option improves the ability to detect such changes. Moreover, we show that using uncertainty estimates as a criterion for sample selection in active learning setting results in greater improvements in classification performance compared to random sampling.},
	urldate = {2024-05-09},
	journal = {Information Fusion},
	author = {Barandas, Marília and Famiglini, Lorenzo and Campagner, Andrea and Folgado, Duarte and Simão, Raquel and Cabitza, Federico and Gamboa, Hugo},
	month = jan,
	year = {2024},
	keywords = {Artificial Intelligence, Cardiology, Multi-label classification, Uncertainty quantification},
	pages = {101978},
}

@inproceedings{madeira_zebra_2023,
	title = {{ZEBRA}: {Explaining} rare cases through outlying interpretable concepts},
	shorttitle = {{ZEBRA}},
	url = {https://ieeexplore.ieee.org/document/10208711},
	doi = {10.1109/CVPRW59228.2023.00392},
	abstract = {Anomaly detection methods can detect outliers, but what are the properties of an outlierƒ In this paper, we propose ZEBRA, a novel framework for generating explanations of an outlier based on the analysis of feature rarity in an interpretable feature space. The contributions of our work include: (a) a modular model-agnostic framework for explanations of outliers; (b) a statistical explanation method based on a rarity score and weighted aggregation functions; (c) multimodal explanations combining visual, textual, and numeric explanations. ZEBRA simplifies the mapping of low-level features to high-level concepts to generate multimodal and human-readable explanations of outliers.},
	urldate = {2024-05-09},
	booktitle = {2023 {IEEE}/{CVF} {Conference} on {Computer} {Vision} and {Pattern} {Recognition} {Workshops} ({CVPRW})},
	author = {Madeira, Pedro and Carreiro, André and Gaudio, Alex and Rosado, Luís and Soares, Filipe and Smailagic, Asim},
	month = jun,
	year = {2023},
	note = {ISSN: 2160-7516},
	keywords = {Detectors, Geometry, Image color analysis, Limiting, Meters, Time series analysis, Visualization},
	pages = {3782--3788},
}

@inproceedings{ribeiro_incognitus_2023,
	address = {Dubrovnik, Croatia},
	title = {{INCOGNITUS}: {A} {Toolbox} for {Automated} {Clinical} {Notes} {Anonymization}},
	shorttitle = {{INCOGNITUS}},
	url = {https://aclanthology.org/2023.eacl-demo.22},
	doi = {10.18653/v1/2023.eacl-demo.22},
	abstract = {Automated text anonymization is a classical problem in Natural Language Processing (NLP). The topic has evolved immensely throughout the years, with the first list-search and rule-based solutions evolving to statistical modeling approaches and later to advanced systems that rely on powerful state-of-the-art language models. Even so, these solutions fail to be widely implemented in the most privacy-demanding areas of activity, such as healthcare; none of them is perfect, and most can not guarantee rigorous anonymization. This paper presents INCOGNITUS, a flexible platform for the automated anonymization of clinical notes that offers the possibility of applying different techniques. The available tools include an underexplored yet promising method that guarantees 100\% recall by replacing each word with a semantically identical one. In addition, the presented framework incorporates a performance evaluation module to compute a novel metric for information loss assessment in real-time.},
	urldate = {2024-05-09},
	booktitle = {Proceedings of the 17th {Conference} of the {European} {Chapter} of the {Association} for {Computational} {Linguistics}: {System} {Demonstrations}},
	publisher = {Association for Computational Linguistics},
	author = {Ribeiro, Bruno and Rolla, Vitor and Santos, Ricardo},
	editor = {Croce, Danilo and Soldaini, Luca},
	month = may,
	year = {2023},
	pages = {187--194},
}

@misc{engelbach_combining_2022,
	title = {Combining {Deep} {Learning} and {Reasoning} for {Address} {Detection} in {Unstructured} {Text} {Documents}},
	url = {http://arxiv.org/abs/2202.03103},
	abstract = {Extracting information from unstructured text documents is a demanding task, since these documents can have a broad variety of different layouts and a non-trivial reading order, like it is the case for multi-column documents or nested tables. Additionally, many business documents are received in paper form, meaning that the textual contents need to be digitized before further analysis. Nonetheless, automatic detection and capturing of crucial document information like the sender address would boost many companies' processing efficiency. In this work we propose a hybrid approach that combines deep learning with reasoning for finding and extracting addresses from unstructured text documents. We use a visual deep learning model to detect the boundaries of possible address regions on the scanned document images and validate these results by analyzing the containing text using domain knowledge represented as a rule based system.},
	urldate = {2024-05-09},
	publisher = {arXiv},
	author = {Engelbach, Matthias and Klau, Dennis and Drawehn, Jens and Kintz, Maximilien},
	month = feb,
	year = {2022},
	note = {arXiv:2202.03103 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Information Retrieval, Computer Science - Machine Learning},
}

@misc{engelbach_fine-tuning_2023,
	title = {Fine-tuning and aligning question answering models for complex information extraction tasks},
	url = {http://arxiv.org/abs/2309.14805},
	abstract = {The emergence of Large Language Models (LLMs) has boosted performance and possibilities in various NLP tasks. While the usage of generative AI models like ChatGPT opens up new opportunities for several business use cases, their current tendency to hallucinate fake content strongly limits their applicability to document analysis, such as information retrieval from documents. In contrast, extractive language models like question answering (QA) or passage retrieval models guarantee query results to be found within the boundaries of an according context document, which makes them candidates for more reliable information extraction in productive environments of companies. In this work we propose an approach that uses and integrates extractive QA models for improved feature extraction of German business documents such as insurance reports or medical leaflets into a document analysis solution. We further show that fine-tuning existing German QA models boosts performance for tailored extraction tasks of complex linguistic features like damage cause explanations or descriptions of medication appearance, even with using only a small set of annotated data. Finally, we discuss the relevance of scoring metrics for evaluating information extraction tasks and deduce a combined metric from Levenshtein distance, F1-Score, Exact Match and ROUGE-L to mimic the assessment criteria from human experts.},
	urldate = {2024-05-09},
	publisher = {arXiv},
	author = {Engelbach, Matthias and Klau, Dennis and Scheerer, Felix and Drawehn, Jens and Kintz, Maximilien},
	month = sep,
	year = {2023},
	note = {arXiv:2309.14805 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language},
}

@misc{blohm_leveraging_2020,
	title = {Leveraging {Automated} {Machine} {Learning} for {Text} {Classification}: {Evaluation} of {AutoML} {Tools} and {Comparison} with {Human} {Performance}},
	shorttitle = {Leveraging {Automated} {Machine} {Learning} for {Text} {Classification}},
	url = {http://arxiv.org/abs/2012.03575},
	abstract = {Recently, Automated Machine Learning (AutoML) has registered increasing success with respect to tabular data. However, the question arises whether AutoML can also be applied effectively to text classification tasks. This work compares four AutoML tools on 13 different popular datasets, including Kaggle competitions, and opposes human performance. The results show that the AutoML tools perform better than the machine learning community in 4 out of 13 tasks and that two stand out.},
	urldate = {2024-05-09},
	publisher = {arXiv},
	author = {Blohm, Matthias and Hanussek, Marc and Kintz, Maximilien},
	month = dec,
	year = {2020},
	note = {arXiv:2012.03575 [cs]},
	keywords = {Computer Science - Machine Learning},
}

@misc{hanussek_can_2020,
	title = {Can {AutoML} outperform humans? {An} evaluation on popular {OpenML} datasets using {AutoML} {Benchmark}},
	shorttitle = {Can {AutoML} outperform humans?},
	url = {http://arxiv.org/abs/2009.01564},
	abstract = {In the last few years, Automated Machine Learning (AutoML) has gained much attention. With that said, the question arises whether AutoML can outperform results achieved by human data scientists. This paper compares four AutoML frameworks on 12 different popular datasets from OpenML; six of them supervised classification tasks and the other six supervised regression ones. Additionally, we consider a real-life dataset from one of our recent projects. The results show that the automated frameworks perform better or equal than the machine learning community in 7 out of 12 OpenML tasks.},
	urldate = {2024-05-09},
	publisher = {arXiv},
	author = {Hanussek, Marc and Blohm, Matthias and Kintz, Maximilien},
	month = dec,
	year = {2020},
	note = {arXiv:2009.01564 [cs, stat]},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@misc{klau_bringing_2023,
	title = {Bringing {Quantum} {Algorithms} to {Automated} {Machine} {Learning}: {A} {Systematic} {Review} of {AutoML} {Frameworks} {Regarding} {Extensibility} for {QML} {Algorithms}},
	shorttitle = {Bringing {Quantum} {Algorithms} to {Automated} {Machine} {Learning}},
	url = {http://arxiv.org/abs/2310.04238},
	abstract = {This work describes the selection approach and analysis of existing AutoML frameworks regarding their capability of a) incorporating Quantum Machine Learning (QML) algorithms into this automated solving approach of the AutoML framing and b) solving a set of industrial use-cases with different ML problem types by benchmarking their most important characteristics. For that, available open-source tools are condensed into a market overview and suitable frameworks are systematically selected on a multi-phase, multi-criteria approach. This is done by considering software selection approaches, as well as in terms of the technical perspective of AutoML. The requirements for the framework selection are divided into hard and soft criteria regarding their software and ML attributes. Additionally, a classification of AutoML frameworks is made into high- and low-level types, inspired by the findings of. Finally, we select Ray and AutoGluon as the suitable low- and high-level frameworks respectively, as they fulfil all requirements sufficiently and received the best evaluation feedback during the use-case study. Based on those findings, we build an extended Automated Quantum Machine Learning (AutoQML) framework with QC-specific pipeline steps and decision characteristics for hardware and software constraints.},
	urldate = {2024-05-09},
	publisher = {arXiv},
	author = {Klau, Dennis and Zöller, Marc and Tutschku, Christian},
	month = oct,
	year = {2023},
	note = {arXiv:2310.04238 [cs]},
	keywords = {Computer Science - Machine Learning, Computer Science - Software Engineering},
}

@inproceedings{stuhler_benchmarking_2023,
	title = {Benchmarking {Automated} {Machine} {Learning} {Methods} for {Price} {Forecasting} {Applications}},
	url = {http://arxiv.org/abs/2304.14735},
	doi = {10.5220/0012051400003541},
	abstract = {Price forecasting for used construction equipment is a challenging task due to spatial and temporal price fluctuations. It is thus of high interest to automate the forecasting process based on current market data. Even though applying machine learning (ML) to these data represents a promising approach to predict the residual value of certain tools, it is hard to implement for small and medium-sized enterprises due to their insufficient ML expertise. To this end, we demonstrate the possibility of substituting manually created ML pipelines with automated machine learning (AutoML) solutions, which automatically generate the underlying pipelines. We combine AutoML methods with the domain knowledge of the companies. Based on the CRISP-DM process, we split the manual ML pipeline into a machine learning and non-machine learning part. To take all complex industrial requirements into account and to demonstrate the applicability of our new approach, we designed a novel metric named method evaluation score, which incorporates the most important technical and non-technical metrics for quality and usability. Based on this metric, we show in a case study for the industrial use case of price forecasting, that domain knowledge combined with AutoML can weaken the dependence on ML experts for innovative small and medium-sized enterprises which are interested in conducting such solutions.},
	urldate = {2024-05-09},
	booktitle = {Proceedings of the 12th {International} {Conference} on {Data} {Science}, {Technology} and {Applications}},
	author = {Stühler, Horst and Zöller, Marc-André and Klau, Dennis and Beiderwellen-Bedrikow, Alexandre and Tutschku, Christian},
	year = {2023},
	note = {arXiv:2304.14735 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning},
	pages = {30--39},
}

@article{zhang_dissecting_2024,
	title = {{DISSECTING} {LEARNING} {AND} {FORGETTING} {IN} {LAN}- {GUAGE} {MODEL} {FINETUNING}},
	abstract = {Finetuning language models on domain-specific corpus is a common approach to enhance their domain knowledge and capability. While improving performance on domain tasks, it often brings a side-effect of forgetting of the model’s general abilities. In this study, we analyze the effects of finetuning on language models by dissecting its impacts on the modeling of topic, style, and factual knowledge in text. Our method uses instruction-following LLMs such as ChatGPT to autogenerate controlled-variable text examples which we use to probe the model. Our findings reveal that finetuning results in significant shifts in the language model’s topic and style priors, while actual knowledge learning only contributes to a small fraction of the total probability change. Analysis shows that the adaptation of topic and style priors behave akin to learning simple features: they are learned rapidly and require little model capacity. They are also learned independently and primarily at the beginning of a text sequence. In contrast, factual knowledge is learned stably but slowly and requires significant model capacity. The findings offer insights and understanding into the finer dynamics of learning and forgetting in language models, and potentially inform future research on improving domain adaptation and addressing the challenges of continual language learning.},
	language = {en},
	author = {Zhang, Xiao and Wu, Ji},
	year = {2024},
}

@misc{wang_chain--table_2024,
	title = {Chain-of-{Table}: {Evolving} {Tables} in the {Reasoning} {Chain} for {Table} {Understanding}},
	shorttitle = {Chain-of-{Table}},
	url = {http://arxiv.org/abs/2401.04398},
	abstract = {Table-based reasoning with large language models (LLMs) is a promising direction to tackle many table understanding tasks, such as table-based question answering and fact verification. Compared with generic reasoning, table-based reasoning requires the extraction of underlying semantics from both free-form questions and semi-structured tabular data. Chain-of-Thought and its similar approaches incorporate the reasoning chain in the form of textual context, but it is still an open question how to effectively leverage tabular data in the reasoning chain. We propose the Chain-of-Table framework, where tabular data is explicitly used in the reasoning chain as a proxy for intermediate thoughts. Specifically, we guide LLMs using in-context learning to iteratively generate operations and update the table to represent a tabular reasoning chain. LLMs can therefore dynamically plan the next operation based on the results of the previous ones. This continuous evolution of the table forms a chain, showing the reasoning process for a given tabular problem. The chain carries structured information of the intermediate results, enabling more accurate and reliable predictions. Chain-of-Table achieves new state-of-the-art performance on WikiTQ, FeTaQA, and TabFact benchmarks across multiple LLM choices.},
	urldate = {2024-05-09},
	publisher = {arXiv},
	author = {Wang, Zilong and Zhang, Hao and Li, Chun-Liang and Eisenschlos, Julian Martin and Perot, Vincent and Wang, Zifeng and Miculicich, Lesly and Fujii, Yasuhisa and Shang, Jingbo and Lee, Chen-Yu and Pfister, Tomas},
	month = jan,
	year = {2024},
	note = {arXiv:2401.04398 [cs]},
	keywords = {Computer Science - Computation and Language},
}

@misc{narayan_can_2022,
	title = {Can {Foundation} {Models} {Wrangle} {Your} {Data}?},
	url = {http://arxiv.org/abs/2205.09911},
	abstract = {Foundation Models (FMs) are models trained on large corpora of data that, at very large scale, can generalize to new tasks without any task-specific finetuning. As these models continue to grow in size, innovations continue to push the boundaries of what these models can do on language and image tasks. This paper aims to understand an underexplored area of FMs: classical data tasks like cleaning and integration. As a proof-of-concept, we cast five data cleaning and integration tasks as prompting tasks and evaluate the performance of FMs on these tasks. We find that large FMs generalize and achieve SoTA performance on data cleaning and integration tasks, even though they are not trained for these data tasks. We identify specific research challenges and opportunities that these models present, including challenges with private and domain specific data, and opportunities to make data management systems more accessible to non-experts. We make our code and experiments publicly available at: https://github.com/HazyResearch/fm\_data\_tasks.},
	urldate = {2024-05-09},
	publisher = {arXiv},
	author = {Narayan, Avanika and Chami, Ines and Orr, Laurel and Arora, Simran and Ré, Christopher},
	month = dec,
	year = {2022},
	note = {arXiv:2205.09911 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Databases, Computer Science - Machine Learning},
}

@misc{liu_ptab_2022,
	title = {{PTab}: {Using} the {Pre}-trained {Language} {Model} for {Modeling} {Tabular} {Data}},
	shorttitle = {{PTab}},
	url = {http://arxiv.org/abs/2209.08060},
	abstract = {Tabular data is the foundation of the information age and has been extensively studied. Recent studies show that neural-based models are effective in learning contextual representation for tabular data. The learning of an effective contextual representation requires meaningful features and a large amount of data. However, current methods often fail to properly learn a contextual representation from the features without semantic information. In addition, it's intractable to enlarge the training set through mixed tabular datasets due to the difference between datasets. To address these problems, we propose a novel framework PTab, using the Pre-trained language model to model Tabular data. PTab learns a contextual representation of tabular data through a three-stage processing: Modality Transformation(MT), Masked-Language Fine-tuning(MF), and Classification Fine-tuning(CF). We initialize our model with a pre-trained Model (PTM) which contains semantic information learned from the large-scale language data. Consequently, contextual representation can be learned effectively during the fine-tuning stages. In addition, we can naturally mix the textualized tabular data to enlarge the training set to further improve representation learning. We evaluate PTab on eight popular tabular classification datasets. Experimental results show that our method has achieved a better average AUC score in supervised settings compared to the state-of-the-art baselines(e.g. XGBoost), and outperforms counterpart methods under semi-supervised settings. We present visualization results that show PTab has well instance-based interpretability.},
	urldate = {2024-05-09},
	publisher = {arXiv},
	author = {Liu, Guang and Yang, Jie and Wu, Ledell},
	month = sep,
	year = {2022},
	note = {arXiv:2209.08060 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning},
}

@misc{wang_assessing_2023,
	title = {Assessing the {Reliability} of {Large} {Language} {Model} {Knowledge}},
	url = {http://arxiv.org/abs/2310.09820},
	abstract = {Large language models (LLMs) have been treated as knowledge bases due to their strong performance in knowledge probing tasks. LLMs are typically evaluated using accuracy, yet this metric does not capture the vulnerability of LLMs to hallucination-inducing factors like prompt and context variability. How do we evaluate the capabilities of LLMs to consistently produce factually correct answers? In this paper, we propose MOdel kNowledge relIabiliTy scORe (MONITOR), a novel metric designed to directly measure LLMs' factual reliability. MONITOR computes the distance between the probability distributions of a valid output and its counterparts produced by the same LLM probing the same fact using different styles of prompts and contexts.Experiments on a comprehensive range of 12 LLMs demonstrate the effectiveness of MONITOR in evaluating the factual reliability of LLMs while maintaining a low computational overhead. In addition, we release the FKTC (Factual Knowledge Test Corpus) test set, containing 210,158 prompts in total to foster research along this line (https://github.com/Vicky-Wil/MONITOR).},
	urldate = {2024-05-09},
	publisher = {arXiv},
	author = {Wang, Weixuan and Haddow, Barry and Birch, Alexandra and Peng, Wei},
	month = oct,
	year = {2023},
	note = {arXiv:2310.09820 [cs]},
	keywords = {Computer Science - Computation and Language},
}

@inproceedings{bouneffouf_survey_2020,
	address = {Glasgow, United Kingdom},
	title = {Survey on {Automated} {End}-to-{End} {Data} {Science}?},
	copyright = {https://ieeexplore.ieee.org/Xplorehelp/downloads/license-information/IEEE.html},
	isbn = {978-1-72816-926-2},
	url = {https://ieeexplore.ieee.org/document/9207453/},
	doi = {10.1109/IJCNN48605.2020.9207453},
	urldate = {2024-05-09},
	booktitle = {2020 {International} {Joint} {Conference} on {Neural} {Networks} ({IJCNN})},
	publisher = {IEEE},
	author = {Bouneffouf, Djallel and Aggarwal, Charu and Hoang, Thanh and Khurana, Udayan and Samulowitz, Horst and Buesser, Beat and Liu, Sijia and Pedapati, Tejaswini and Ram, Parikshit and Rawat, Ambrish and Wistuba, Martin and Gray, Alexander},
	month = jul,
	year = {2020},
	pages = {1--9},
}

@inproceedings{wang_autods_2021,
	title = {{AutoDS}: {Towards} {Human}-{Centered} {Automation} of {Data} {Science}},
	shorttitle = {{AutoDS}},
	url = {http://arxiv.org/abs/2101.05273},
	doi = {10.1145/3411764.3445526},
	abstract = {Data science (DS) projects often follow a lifecycle that consists of laborious tasks for data scientists and domain experts (e.g., data exploration, model training, etc.). Only till recently, machine learning(ML) researchers have developed promising automation techniques to aid data workers in these tasks. This paper introduces AutoDS, an automated machine learning (AutoML) system that aims to leverage the latest ML automation techniques to support data science projects. Data workers only need to upload their dataset, then the system can automatically suggest ML configurations, preprocess data, select algorithm, and train the model. These suggestions are presented to the user via a web-based graphical user interface and a notebook-based programming user interface. We studied AutoDS with 30 professional data scientists, where one group used AutoDS, and the other did not, to complete a data science project. As expected, AutoDS improves productivity; Yet surprisingly, we find that the models produced by the AutoDS group have higher quality and less errors, but lower human confidence scores. We reflect on the findings by presenting design implications for incorporating automation techniques into human work in the data science lifecycle.},
	urldate = {2024-05-09},
	booktitle = {Proceedings of the 2021 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	author = {Wang, Dakuo and Andres, Josh and Weisz, Justin and Oduor, Erick and Dugan, Casey},
	month = may,
	year = {2021},
	note = {arXiv:2101.05273 [cs]},
	keywords = {Computer Science - Human-Computer Interaction, Computer Science - Machine Learning},
	pages = {1--12},
}

@misc{dettmers_qlora_2023,
	title = {{QLoRA}: {Efficient} {Finetuning} of {Quantized} {LLMs}},
	shorttitle = {{QLoRA}},
	url = {http://arxiv.org/abs/2305.14314},
	abstract = {We present QLoRA, an efficient finetuning approach that reduces memory usage enough to finetune a 65B parameter model on a single 48GB GPU while preserving full 16-bit finetuning task performance. QLoRA backpropagates gradients through a frozen, 4-bit quantized pretrained language model into Low Rank Adapters{\textasciitilde}(LoRA). Our best model family, which we name Guanaco, outperforms all previous openly released models on the Vicuna benchmark, reaching 99.3\% of the performance level of ChatGPT while only requiring 24 hours of finetuning on a single GPU. QLoRA introduces a number of innovations to save memory without sacrificing performance: (a) 4-bit NormalFloat (NF4), a new data type that is information theoretically optimal for normally distributed weights (b) double quantization to reduce the average memory footprint by quantizing the quantization constants, and (c) paged optimziers to manage memory spikes. We use QLoRA to finetune more than 1,000 models, providing a detailed analysis of instruction following and chatbot performance across 8 instruction datasets, multiple model types (LLaMA, T5), and model scales that would be infeasible to run with regular finetuning (e.g. 33B and 65B parameter models). Our results show that QLoRA finetuning on a small high-quality dataset leads to state-of-the-art results, even when using smaller models than the previous SoTA. We provide a detailed analysis of chatbot performance based on both human and GPT-4 evaluations showing that GPT-4 evaluations are a cheap and reasonable alternative to human evaluation. Furthermore, we find that current chatbot benchmarks are not trustworthy to accurately evaluate the performance levels of chatbots. A lemon-picked analysis demonstrates where Guanaco fails compared to ChatGPT. We release all of our models and code, including CUDA kernels for 4-bit training.},
	urldate = {2024-05-09},
	publisher = {arXiv},
	author = {Dettmers, Tim and Pagnoni, Artidoro and Holtzman, Ari and Zettlemoyer, Luke},
	month = may,
	year = {2023},
	note = {arXiv:2305.14314 [cs]},
	keywords = {Computer Science - Machine Learning},
}

@misc{chung_scaling_2022,
	title = {Scaling {Instruction}-{Finetuned} {Language} {Models}},
	url = {http://arxiv.org/abs/2210.11416},
	abstract = {Finetuning language models on a collection of datasets phrased as instructions has been shown to improve model performance and generalization to unseen tasks. In this paper we explore instruction finetuning with a particular focus on (1) scaling the number of tasks, (2) scaling the model size, and (3) finetuning on chain-of-thought data. We find that instruction finetuning with the above aspects dramatically improves performance on a variety of model classes (PaLM, T5, U-PaLM), prompting setups (zero-shot, few-shot, CoT), and evaluation benchmarks (MMLU, BBH, TyDiQA, MGSM, open-ended generation). For instance, Flan-PaLM 540B instruction-finetuned on 1.8K tasks outperforms PALM 540B by a large margin (+9.4\% on average). Flan-PaLM 540B achieves state-of-the-art performance on several benchmarks, such as 75.2\% on five-shot MMLU. We also publicly release Flan-T5 checkpoints, which achieve strong few-shot performance even compared to much larger models, such as PaLM 62B. Overall, instruction finetuning is a general method for improving the performance and usability of pretrained language models.},
	urldate = {2024-05-09},
	publisher = {arXiv},
	author = {Chung, Hyung Won and Hou, Le and Longpre, Shayne and Zoph, Barret and Tay, Yi and Fedus, William and Li, Yunxuan and Wang, Xuezhi and Dehghani, Mostafa and Brahma, Siddhartha and Webson, Albert and Gu, Shixiang Shane and Dai, Zhuyun and Suzgun, Mirac and Chen, Xinyun and Chowdhery, Aakanksha and Castro-Ros, Alex and Pellat, Marie and Robinson, Kevin and Valter, Dasha and Narang, Sharan and Mishra, Gaurav and Yu, Adams and Zhao, Vincent and Huang, Yanping and Dai, Andrew and Yu, Hongkun and Petrov, Slav and Chi, Ed H. and Dean, Jeff and Devlin, Jacob and Roberts, Adam and Zhou, Denny and Le, Quoc V. and Wei, Jason},
	month = dec,
	year = {2022},
	note = {arXiv:2210.11416 [cs]},
	keywords = {Computer Science - Computation and Language, Computer Science - Machine Learning},
}

@misc{yang_unleashing_2024,
	title = {Unleashing the {Potential} of {Large} {Language} {Models} for {Predictive} {Tabular} {Tasks} in {Data} {Science}},
	url = {http://arxiv.org/abs/2403.20208},
	abstract = {In the domain of data science, the predictive tasks of classification, regression, and imputation of missing values are commonly encountered challenges associated with tabular data. This research endeavors to apply Large Language Models (LLMs) towards addressing these predictive tasks. Despite their proficiency in comprehending natural language, LLMs fall short in dealing with structured tabular data. This limitation stems from their lacking exposure to the intricacies of tabular data during their foundational training. Our research aims to mitigate this gap by compiling a comprehensive corpus of tables annotated with instructions and executing large-scale training of Llama-2 on this enriched dataset. Furthermore, we investigate the practical application of applying the trained model to zero-shot prediction, few-shot prediction, and in-context learning scenarios. Through extensive experiments, our methodology has shown significant improvements over existing benchmarks. These advancements highlight the efficacy of tailoring LLM training to solve table-related problems in data science, thereby establishing a new benchmark in the utilization of LLMs for enhancing tabular intelligence.},
	urldate = {2024-05-09},
	publisher = {arXiv},
	author = {Yang, Yazheng and Wang, Yuqi and Sen, Sankalok and Li, Lei and Liu, Qi},
	month = apr,
	year = {2024},
	note = {arXiv:2403.20208 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning},
}

@misc{vacareanu_words_2024,
	title = {From {Words} to {Numbers}: {Your} {Large} {Language} {Model} {Is} {Secretly} {A} {Capable} {Regressor} {When} {Given} {In}-{Context} {Examples}},
	shorttitle = {From {Words} to {Numbers}},
	url = {http://arxiv.org/abs/2404.07544},
	abstract = {We analyze how well pre-trained large language models (e.g., Llama2, GPT-4, Claude 3, etc) can do linear and non-linear regression when given in-context examples, without any additional training or gradient updates. Our findings reveal that several large language models (e.g., GPT-4, Claude 3) are able to perform regression tasks with a performance rivaling (or even outperforming) that of traditional supervised methods such as Random Forest, Bagging, or Gradient Boosting. For example, on the challenging Friedman \#2 regression dataset, Claude 3 outperforms many supervised methods such as AdaBoost, SVM, Random Forest, KNN, or Gradient Boosting. We then investigate how well the performance of large language models scales with the number of in-context exemplars. We borrow from the notion of regret from online learning and empirically show that LLMs are capable of obtaining a sub-linear regret.},
	urldate = {2024-05-09},
	publisher = {arXiv},
	author = {Vacareanu, Robert and Negru, Vlad-Andrei and Suciu, Vasile and Surdeanu, Mihai},
	month = apr,
	year = {2024},
	note = {arXiv:2404.07544 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language},
}

@misc{hollmann_tabpfn_2023,
	title = {{TabPFN}: {A} {Transformer} {That} {Solves} {Small} {Tabular} {Classification} {Problems} in a {Second}},
	shorttitle = {{TabPFN}},
	url = {http://arxiv.org/abs/2207.01848},
	abstract = {We present TabPFN, a trained Transformer that can do supervised classification for small tabular datasets in less than a second, needs no hyperparameter tuning and is competitive with state-of-the-art classification methods. TabPFN performs in-context learning (ICL), it learns to make predictions using sequences of labeled examples (x, f(x)) given in the input, without requiring further parameter updates. TabPFN is fully entailed in the weights of our network, which accepts training and test samples as a set-valued input and yields predictions for the entire test set in a single forward pass. TabPFN is a Prior-Data Fitted Network (PFN) and is trained offline once, to approximate Bayesian inference on synthetic datasets drawn from our prior. This prior incorporates ideas from causal reasoning: It entails a large space of structural causal models with a preference for simple structures. On the 18 datasets in the OpenML-CC18 suite that contain up to 1 000 training data points, up to 100 purely numerical features without missing values, and up to 10 classes, we show that our method clearly outperforms boosted trees and performs on par with complex state-of-the-art AutoML systems with up to 230\${\textbackslash}times\$ speedup. This increases to a 5 700\${\textbackslash}times\$ speedup when using a GPU. We also validate these results on an additional 67 small numerical datasets from OpenML. We provide all our code, the trained TabPFN, an interactive browser demo and a Colab notebook at https://github.com/automl/TabPFN.},
	urldate = {2024-05-09},
	publisher = {arXiv},
	author = {Hollmann, Noah and Müller, Samuel and Eggensperger, Katharina and Hutter, Frank},
	month = sep,
	year = {2023},
	note = {arXiv:2207.01848 [cs, stat]},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@misc{hegselmann_tabllm_2023,
	title = {{TabLLM}: {Few}-shot {Classification} of {Tabular} {Data} with {Large} {Language} {Models}},
	shorttitle = {{TabLLM}},
	url = {http://arxiv.org/abs/2210.10723},
	abstract = {We study the application of large language models to zero-shot and few-shot classification of tabular data. We prompt the large language model with a serialization of the tabular data to a natural-language string, together with a short description of the classification problem. In the few-shot setting, we fine-tune the large language model using some labeled examples. We evaluate several serialization methods including templates, table-to-text models, and large language models. Despite its simplicity, we find that this technique outperforms prior deep-learning-based tabular classification methods on several benchmark datasets. In most cases, even zero-shot classification obtains non-trivial performance, illustrating the method's ability to exploit prior knowledge encoded in large language models. Unlike many deep learning methods for tabular datasets, this approach is also competitive with strong traditional baselines like gradient-boosted trees, especially in the very-few-shot setting.},
	urldate = {2024-05-09},
	publisher = {arXiv},
	author = {Hegselmann, Stefan and Buendia, Alejandro and Lang, Hunter and Agrawal, Monica and Jiang, Xiaoyi and Sontag, David},
	month = mar,
	year = {2023},
	note = {arXiv:2210.10723 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language},
}

@misc{ferrando_primer_2024,
	title = {A {Primer} on the {Inner} {Workings} of {Transformer}-based {Language} {Models}},
	url = {http://arxiv.org/abs/2405.00208},
	abstract = {The rapid progress of research aimed at interpreting the inner workings of advanced language models has highlighted a need for contextualizing the insights gained from years of work in this area. This primer provides a concise technical introduction to the current techniques used to interpret the inner workings of Transformer-based language models, focusing on the generative decoder-only architecture. We conclude by presenting a comprehensive overview of the known internal mechanisms implemented by these models, uncovering connections across popular approaches and active research directions in this area.},
	urldate = {2024-05-09},
	publisher = {arXiv},
	author = {Ferrando, Javier and Sarti, Gabriele and Bisazza, Arianna and Costa-jussà, Marta R.},
	month = may,
	year = {2024},
	note = {arXiv:2405.00208 [cs]},
	keywords = {Computer Science - Computation and Language},
}

@misc{zhao_explainability_2023,
	title = {Explainability for {Large} {Language} {Models}: {A} {Survey}},
	shorttitle = {Explainability for {Large} {Language} {Models}},
	url = {http://arxiv.org/abs/2309.01029},
	abstract = {Large language models (LLMs) have demonstrated impressive capabilities in natural language processing. However, their internal mechanisms are still unclear and this lack of transparency poses unwanted risks for downstream applications. Therefore, understanding and explaining these models is crucial for elucidating their behaviors, limitations, and social impacts. In this paper, we introduce a taxonomy of explainability techniques and provide a structured overview of methods for explaining Transformer-based language models. We categorize techniques based on the training paradigms of LLMs: traditional fine-tuning-based paradigm and prompting-based paradigm. For each paradigm, we summarize the goals and dominant approaches for generating local explanations of individual predictions and global explanations of overall model knowledge. We also discuss metrics for evaluating generated explanations, and discuss how explanations can be leveraged to debug models and improve performance. Lastly, we examine key challenges and emerging opportunities for explanation techniques in the era of LLMs in comparison to conventional machine learning models.},
	urldate = {2024-05-09},
	publisher = {arXiv},
	author = {Zhao, Haiyan and Chen, Hanjie and Yang, Fan and Liu, Ninghao and Deng, Huiqi and Cai, Hengyi and Wang, Shuaiqiang and Yin, Dawei and Du, Mengnan},
	month = nov,
	year = {2023},
	note = {arXiv:2309.01029 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language, Computer Science - Machine Learning},
}

@misc{ahamed_mambatab_2024,
	title = {{MambaTab}: {A} {Simple} {Yet} {Effective} {Approach} for {Handling} {Tabular} {Data}},
	shorttitle = {{MambaTab}},
	url = {http://arxiv.org/abs/2401.08867},
	abstract = {Tabular data remains ubiquitous across domains despite growing use of images and texts for machine learning. While deep learning models like convolutional neural networks and transformers achieve strong performance on tabular data, they require extensive data preprocessing, tuning, and resources, limiting accessibility and scalability. This work develops an innovative approach based on a structured state-space model (SSM), MambaTab, for tabular data. SSMs have strong capabilities for efficiently extracting effective representations from data with long-range dependencies. MambaTab leverages Mamba, an emerging SSM variant, for end-to-end supervised learning on tables. Compared to state-of-the-art baselines, MambaTab delivers superior performance while requiring significantly fewer parameters and minimal preprocessing, as empirically validated on diverse benchmark datasets. MambaTab's efficiency, scalability, generalizability, and predictive gains signify it as a lightweight, "out-of-the-box" solution for diverse tabular data with promise for enabling wider practical applications.},
	urldate = {2024-05-09},
	publisher = {arXiv},
	author = {Ahamed, Md Atik and Cheng, Qiang},
	month = jan,
	year = {2024},
	note = {arXiv:2401.08867 [cs]},
	keywords = {Computer Science - Machine Learning},
}

@misc{hollmann_large_2023,
	title = {Large {Language} {Models} for {Automated} {Data} {Science}: {Introducing} {CAAFE} for {Context}-{Aware} {Automated} {Feature} {Engineering}},
	shorttitle = {Large {Language} {Models} for {Automated} {Data} {Science}},
	url = {http://arxiv.org/abs/2305.03403},
	abstract = {As the field of automated machine learning (AutoML) advances, it becomes increasingly important to incorporate domain knowledge into these systems. We present an approach for doing so by harnessing the power of large language models (LLMs). Specifically, we introduce Context-Aware Automated Feature Engineering (CAAFE), a feature engineering method for tabular datasets that utilizes an LLM to iteratively generate additional semantically meaningful features for tabular datasets based on the description of the dataset. The method produces both Python code for creating new features and explanations for the utility of the generated features. Despite being methodologically simple, CAAFE improves performance on 11 out of 14 datasets -- boosting mean ROC AUC performance from 0.798 to 0.822 across all dataset - similar to the improvement achieved by using a random forest instead of logistic regression on our datasets. Furthermore, CAAFE is interpretable by providing a textual explanation for each generated feature. CAAFE paves the way for more extensive semi-automation in data science tasks and emphasizes the significance of context-aware solutions that can extend the scope of AutoML systems to semantic AutoML. We release our \${\textbackslash}href\{https://github.com/automl/CAAFE\}\{code\}\$, a simple \${\textbackslash}href\{https://colab.research.google.com/drive/1mCA8xOAJZ4MaB\_alZvyARTMjhl6RZf0a\}\{demo\}\$ and a \${\textbackslash}href\{https://pypi.org/project/caafe/\}\{python{\textbackslash} package\}\$.},
	urldate = {2024-05-09},
	publisher = {arXiv},
	author = {Hollmann, Noah and Müller, Samuel and Hutter, Frank},
	month = sep,
	year = {2023},
	note = {arXiv:2305.03403 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning},
}

@misc{zhu_realm_2024,
	title = {{REALM}: {RAG}-{Driven} {Enhancement} of {Multimodal} {Electronic} {Health} {Records} {Analysis} via {Large} {Language} {Models}},
	shorttitle = {{REALM}},
	url = {http://arxiv.org/abs/2402.07016},
	abstract = {The integration of multimodal Electronic Health Records (EHR) data has significantly improved clinical predictive capabilities. Leveraging clinical notes and multivariate time-series EHR, existing models often lack the medical context relevent to clinical tasks, prompting the incorporation of external knowledge, particularly from the knowledge graph (KG). Previous approaches with KG knowledge have primarily focused on structured knowledge extraction, neglecting unstructured data modalities and semantic high dimensional medical knowledge. In response, we propose REALM, a Retrieval-Augmented Generation (RAG) driven framework to enhance multimodal EHR representations that address these limitations. Firstly, we apply Large Language Model (LLM) to encode long context clinical notes and GRU model to encode time-series EHR data. Secondly, we prompt LLM to extract task-relevant medical entities and match entities in professionally labeled external knowledge graph (PrimeKG) with corresponding medical knowledge. By matching and aligning with clinical standards, our framework eliminates hallucinations and ensures consistency. Lastly, we propose an adaptive multimodal fusion network to integrate extracted knowledge with multimodal EHR data. Our extensive experiments on MIMICIII mortality and readmission tasks showcase the superior performance of our REALM framework over baselines, emphasizing the effectiveness of each module. REALM framework contributes to refining the use of multimodal EHR data in healthcare and bridging the gap with nuanced medical context essential for informed clinical predictions.},
	language = {en},
	urldate = {2024-05-07},
	publisher = {arXiv},
	author = {Zhu, Yinghao and Ren, Changyu and Xie, Shiyun and Liu, Shukai and Ji, Hangyuan and Wang, Zixiang and Sun, Tao and He, Long and Li, Zhoujun and Zhu, Xi and Pan, Chengwei},
	month = feb,
	year = {2024},
	note = {arXiv:2402.07016 [cs]},
	keywords = {Computer Science - Artificial Intelligence, notion},
}

@misc{saab_capabilities_2024,
	title = {Capabilities of {Gemini} {Models} in {Medicine}},
	url = {http://arxiv.org/abs/2404.18416},
	doi = {10.48550/arXiv.2404.18416},
	abstract = {Excellence in a wide variety of medical applications poses considerable challenges for AI, requiring advanced reasoning, access to up-to-date medical knowledge and understanding of complex multimodal data. Gemini models, with strong general capabilities in multimodal and long-context reasoning, offer exciting possibilities in medicine. Building on these core strengths of Gemini, we introduce Med-Gemini, a family of highly capable multimodal models that are specialized in medicine with the ability to seamlessly use web search, and that can be efficiently tailored to novel modalities using custom encoders. We evaluate Med-Gemini on 14 medical benchmarks, establishing new state-of-the-art (SoTA) performance on 10 of them, and surpass the GPT-4 model family on every benchmark where a direct comparison is viable, often by a wide margin. On the popular MedQA (USMLE) benchmark, our best-performing Med-Gemini model achieves SoTA performance of 91.1\% accuracy, using a novel uncertainty-guided search strategy. On 7 multimodal benchmarks including NEJM Image Challenges and MMMU (health \& medicine), Med-Gemini improves over GPT-4V by an average relative margin of 44.5\%. We demonstrate the effectiveness of Med-Gemini's long-context capabilities through SoTA performance on a needle-in-a-haystack retrieval task from long de-identified health records and medical video question answering, surpassing prior bespoke methods using only in-context learning. Finally, Med-Gemini's performance suggests real-world utility by surpassing human experts on tasks such as medical text summarization, alongside demonstrations of promising potential for multimodal medical dialogue, medical research and education. Taken together, our results offer compelling evidence for Med-Gemini's potential, although further rigorous evaluation will be crucial before real-world deployment in this safety-critical domain.},
	urldate = {2024-05-04},
	publisher = {arXiv},
	author = {Saab, Khaled and Tu, Tao and Weng, Wei-Hung and Tanno, Ryutaro and Stutz, David and Wulczyn, Ellery and Zhang, Fan and Strother, Tim and Park, Chunjong and Vedadi, Elahe and Chaves, Juanma Zambrano and Hu, Szu-Yeu and Schaekermann, Mike and Kamath, Aishwarya and Cheng, Yong and Barrett, David G. T. and Cheung, Cathy and Mustafa, Basil and Palepu, Anil and McDuff, Daniel and Hou, Le and Golany, Tomer and Liu, Luyang and Alayrac, Jean-baptiste and Houlsby, Neil and Tomasev, Nenad and Freyberg, Jan and Lau, Charles and Kemp, Jonas and Lai, Jeremy and Azizi, Shekoofeh and Kanada, Kimberly and Man, SiWai and Kulkarni, Kavita and Sun, Ruoxi and Shakeri, Siamak and He, Luheng and Caine, Ben and Webson, Albert and Latysheva, Natasha and Johnson, Melvin and Mansfield, Philip and Lu, Jian and Rivlin, Ehud and Anderson, Jesper and Green, Bradley and Wong, Renee and Krause, Jonathan and Shlens, Jonathon and Dominowska, Ewa and Eslami, S. M. Ali and Chou, Katherine and Cui, Claire and Vinyals, Oriol and Kavukcuoglu, Koray and Manyika, James and Dean, Jeff and Hassabis, Demis and Matias, Yossi and Webster, Dale and Barral, Joelle and Corrado, Greg and Semturs, Christopher and Mahdavi, S. Sara and Gottweis, Juraj and Karthikesalingam, Alan and Natarajan, Vivek},
	month = may,
	year = {2024},
	note = {arXiv:2404.18416 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language, Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning, notion},
}

@article{johnson_mimic_2018,
	title = {The {MIMIC} {Code} {Repository}: enabling reproducibility in critical care research},
	volume = {25},
	issn = {1527-974X},
	shorttitle = {The {MIMIC} {Code} {Repository}},
	url = {https://doi.org/10.1093/jamia/ocx084},
	doi = {10.1093/jamia/ocx084},
	abstract = {Lack of reproducibility in medical studies is a barrier to the generation of a robust knowledge base to support clinical decision-making. In this paper we outline the Medical Information Mart for Intensive Care (MIMIC) Code Repository, a centralized code base for generating reproducible studies on an openly available critical care dataset.Code is provided to load the data into a relational structure, create extractions of the data, and reproduce entire analysis plans including research studies.Concepts extracted include severity of illness scores, comorbid status, administrative definitions of sepsis, physiologic criteria for sepsis, organ failure scores, treatment administration, and more. Executable documents are used for tutorials and reproduce published studies end-to-end, providing a template for future researchers to replicate. The repository’s issue tracker enables community discussion about the data and concepts, allowing users to collaboratively improve the resource.The centralized repository provides a platform for users of the data to interact directly with the data generators, facilitating greater understanding of the data. It also provides a location for the community to collaborate on necessary concepts for research progress and share them with a larger audience. Consistent application of the same code for underlying concepts is a key step in ensuring that research studies on the MIMIC database are comparable and reproducible.By providing open source code alongside the freely accessible MIMIC-III database, we enable end-to-end reproducible analysis of electronic health records.},
	number = {1},
	urldate = {2024-04-29},
	journal = {Journal of the American Medical Informatics Association},
	author = {Johnson, Alistair E W and Stone, David J and Celi, Leo A and Pollard, Tom J},
	month = jan,
	year = {2018},
	keywords = {notion},
	pages = {32--39},
}

@misc{noauthor_establishment_nodate,
	title = {Establishment of a {Chinese} critical care database from electronic healthcare records in a tertiary care medical center {\textbar} {Scientific} {Data}},
	url = {https://www.nature.com/articles/s41597-023-01952-3},
	urldate = {2024-04-17},
}

@article{rodemund_salzburg_2023,
	title = {The {Salzburg} {Intensive} {Care} database ({SICdb}): an openly available critical care dataset},
	volume = {49},
	issn = {1432-1238},
	shorttitle = {The {Salzburg} {Intensive} {Care} database ({SICdb})},
	url = {https://doi.org/10.1007/s00134-023-07046-3},
	doi = {10.1007/s00134-023-07046-3},
	language = {en},
	number = {6},
	urldate = {2024-04-17},
	journal = {Intensive Care Medicine},
	author = {Rodemund, Niklas and Wernly, Bernhard and Jung, Christian and Cozowicz, Crispiana and Koköfer, Andreas},
	month = jun,
	year = {2023},
	pages = {700--702},
}

@misc{steinberg_clbmr_2020,
	title = {{CLBMR}: {Language} {Models} {Are} {An} {Effective} {Patient}  {Representation} {Learning} {Technique} {For} {Electronic} {Health} {Record} {Data}},
	url = {http://arxiv.org/abs/2001.05295},
	abstract = {Widespread adoption of electronic health records (EHRs) has fueled the development of using machine learning to build prediction models for various clinical outcomes. This process is often constrained by having a relatively small number of patient records for training the model. We demonstrate that using patient representation schemes inspired from techniques in natural language processing can increase the accuracy of clinical prediction models by transferring information learned from the entire patient population to the task of training a specific model, where only a subset of the population is relevant. Such patient representation schemes enable a 3.5\% mean improvement in AUROC on five prediction tasks compared to standard baselines, with the average improvement rising to 19\% when only a small number of patient records are available for training the clinical prediction model.},
	urldate = {2024-01-15},
	publisher = {arXiv},
	author = {Steinberg, Ethan and Jung, Ken and Fries, Jason A. and Corbin, Conor K. and Pfohl, Stephen R. and Shah, Nigam H.},
	month = may,
	year = {2020},
	note = {arXiv:2001.05295 [cs, stat]},
	keywords = {Computer Science - Computation and Language, Computer Science - Machine Learning, Statistics - Machine Learning, notion},
}

@article{arnrich_draft_nodate,
	title = {{DRAFT} {PROPOSAL} {Medical} {Event} {Data} {Standard}: {An} {ML}-oriented {Interface} for {Medical} {Record} {Datasets}},
	abstract = {We introduce the Medical Event Data Standard (MEDS), a simple dataset schema for machine learning over electronic health record (EHR) data. Unlike existing tools, pipelines, and common data models, MEDS is a minimal standard designed for maximum interoperability across datasets, existing tools, and model architectures. By providing a simple standardization layer between datasets and model-specific code, MEDS will enable more reproducible, robust, computationally performant, and collaborative machine learning research for EHR data. Alongside this report, we highlight several existing MEDS integrations with models, datasets, and tools, and will work actively with the community for further development and adoption.},
	language = {en},
	author = {Arnrich, Bert and Choi, Edward and Fries, Jason A and McDermott, Matthew B A and Oh, Jungwoo and Pollard, Tom J and Shah, Nigam and Steinberg, Ethan and Wornow, Michael},
}

@misc{noauthor_githubmedical_event_data_standardpdf_nodate,
	title = {.github/{Medical}\_Event\_Data\_Standard.pdf at main · {Medical}-{Event}-{Data}-{Standard}/.github},
	url = {https://github.com/Medical-Event-Data-Standard/.github/blob/main/Medical_Event_Data_Standard.pdf},
	abstract = {Contribute to Medical-Event-Data-Standard/.github development by creating an account on GitHub.},
	language = {en},
	urldate = {2024-04-05},
	journal = {GitHub},
}

@misc{labach_duett_2023,
	title = {{DuETT}: {Dual} {Event} {Time} {Transformer} for {Electronic} {Health} {Records}},
	shorttitle = {{DuETT}},
	url = {http://arxiv.org/abs/2304.13017},
	abstract = {Electronic health records (EHRs) recorded in hospital settings typically contain a wide range of numeric time series data that is characterized by high sparsity and irregular observations. Effective modelling for such data must exploit its time series nature, the semantic relationship between different types of observations, and information in the sparsity structure of the data. Self-supervised Transformers have shown outstanding performance in a variety of structured tasks in NLP and computer vision. But multivariate time series data contains structured relationships over two dimensions: time and recorded event type, and straightforward applications of Transformers to time series data do not leverage this distinct structure. The quadratic scaling of self-attention layers can also significantly limit the input sequence length without appropriate input engineering. We introduce the DuETT architecture, an extension of Transformers designed to attend over both time and event type dimensions, yielding robust representations from EHR data. DuETT uses an aggregated input where sparse time series are transformed into a regular sequence with fixed length; this lowers the computational complexity relative to previous EHR Transformer models and, more importantly, enables the use of larger and deeper neural networks. When trained with self-supervised prediction tasks, that provide rich and informative signals for model pre-training, our model outperforms state-of-the-art deep learning models on multiple downstream tasks from the MIMIC-IV and PhysioNet-2012 EHR datasets.},
	urldate = {2024-04-03},
	publisher = {arXiv},
	author = {Labach, Alex and Pokhrel, Aslesha and Huang, Xiao Shi and Zuberi, Saba and Yi, Seung Eun and Volkovs, Maksims and Poutanen, Tomi and Krishnan, Rahul G.},
	month = aug,
	year = {2023},
	note = {arXiv:2304.13017 [cs]},
	keywords = {Computer Science - Machine Learning, notion},
}

@article{bennett_ricu_2022,
	title = {ricu: {R}’s interface to intensive care data},
	volume = {12},
	copyright = {https://creativecommons.org/licenses/by/4.0/},
	issn = {2047-217X},
	shorttitle = {ricu},
	url = {https://academic.oup.com/gigascience/article/doi/10.1093/gigascience/giad041/7198370},
	doi = {10.1093/gigascience/giad041},
	abstract = {Objective: To develop a unified framework for analyzing data from 5 large publicly available intensive care unit (ICU) datasets. Findings: Using 3 American (Medical Information Mart for Intensive Care III, Medical Information Mart for Intensive Care IV, electronic ICU) and 2 European (Amsterdam University Medical Center Database, High Time Resolution ICU Dataset) databases, we constructed a mapping for each database to a set of clinically relevant concepts, which are grounded in the Observational Medical Outcomes Partnership Vocabulary wherever possible. Furthermore, we performed synchronization in the units of measurement and data type representation. On top of this, we built functionality, which allows the user to download, set up, and load data from all of the 5 databases, through a unified Application Programming Interface. The resulting ricu R-package represents the computational infrastructure for handling publicly available ICU datasets, and its latest release allows the user to load 119 existing clinical concepts from the 5 data sources.},
	language = {en},
	urldate = {2024-04-03},
	journal = {GigaScience},
	author = {Bennett, Nicolas and Plečko, Drago and Ukor, Ida-Fong and Meinshausen, Nicolai and Bühlmann, Peter},
	month = dec,
	year = {2022},
	pages = {giad041},
}

@article{syed_application_2021,
	title = {Application of {Machine} {Learning} in {Intensive} {Care} {Unit} ({ICU}) {Settings} {Using} {MIMIC} {Dataset}: {Systematic} {Review}},
	volume = {8},
	issn = {2227-9709},
	shorttitle = {Application of {Machine} {Learning} in {Intensive} {Care} {Unit} ({ICU}) {Settings} {Using} {MIMIC} {Dataset}},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8112729/},
	doi = {10.3390/informatics8010016},
	abstract = {Modern Intensive Care Units (ICUs) provide continuous monitoring of critically ill patients susceptible to many complications affecting morbidity and mortality. ICU settings require a high staff-to-patient ratio and generates a sheer volume of data. For clinicians, the real-time interpretation of data and decision-making is a challenging task. Machine Learning (ML) techniques in ICUs are making headway in the early detection of high-risk events due to increased processing power and freely available datasets such as the Medical Information Mart for Intensive Care (MIMIC). We conducted a systematic literature review to evaluate the effectiveness of applying ML in the ICU settings using the MIMIC dataset. A total of 322 articles were reviewed and a quantitative descriptive analysis was performed on 61 qualified articles that applied ML techniques in ICU settings using MIMIC data. We assembled the qualified articles to provide insights into the areas of application, clinical variables used, and treatment outcomes that can pave the way for further adoption of this promising technology and possible use in routine clinical decision-making. The lessons learned from our review can provide guidance to researchers on application of ML techniques to increase their rate of adoption in healthcare.},
	number = {1},
	urldate = {2024-04-03},
	journal = {Informatics (MDPI)},
	author = {Syed, Mahanazuddin and Syed, Shorabuddin and Sexton, Kevin and Syeda, Hafsa Bareen and Garza, Maryam and Zozus, Meredith and Syed, Farhanuddin and Begum, Salma and Syed, Abdullah Usama and Sanford, Joseph and Prior, Fred},
	month = mar,
	year = {2021},
	pmid = {33981592},
	pmcid = {PMC8112729},
	keywords = {notion},
	pages = {16},
}

@article{jana_predicting_2022,
	title = {Predicting medical events and {ICU} requirements using a multimodal multiobjective transformer network},
	volume = {247},
	issn = {1535-3702},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9791303/},
	doi = {10.1177/15353702221126559},
	abstract = {Effective utilization of premium hospital resources such as intensive care unit (ICU), operating theater (OT), mechanical ventilator, endotracheal tube, and so on plays a significant role in providing high-quality care to critically ill patients within reasonable costs. Non-availability of specialized resources can lead to dire consequences for such patients, and in the worst case, may even turn out to be fatal. However, these resources cannot be kept idle, as they are expensive to maintain. Therefore, one of the core functions of hospital management is targeted at planning and managing these critical resources in order to provide efficient and effective health-care services to the end-users. Predictive technologies play a big role in this. In this article, we present methods for predicting the length of stay in ICU as well as the need for critical interventions for a patient based on the vital signs, laboratory measurements, and the nursing notes of the patient prepared within the first 24 h of ICU stay. The model has been built and cross-validated on the publicly available Medical Information Mart for Intensive Care (MIMIC-III v1.4) data set. We show that the proposed model performs way better than most of the earlier models in the prediction of ICU stay, which had used patient vitals primarily. Experimental results also demonstrate the advantage of using a multiobjective model over independent models for the prediction of ICU stay and critical interventions. The proposed model uses Local Interpretable Model-agnostic Explanations (LIME) that help in identifying the features responsible for predictive decisions. This is very useful in building trust and confidence in the prediction model among clinical practitioners.},
	number = {22},
	urldate = {2024-04-03},
	journal = {Experimental Biology and Medicine},
	author = {Jana, Sudeshna and Dasgupta, Tirthankar and Dey, Lipika},
	month = nov,
	year = {2022},
	pmid = {36250540},
	pmcid = {PMC9791303},
	keywords = {notion},
	pages = {1988--2002},
}

@article{oliver_introducing_2023,
	title = {Introducing the {BlendedICU} dataset, the first harmonized, international intensive care dataset},
	volume = {146},
	issn = {1532-0464},
	url = {https://www.sciencedirect.com/science/article/pii/S153204642300223X},
	doi = {10.1016/j.jbi.2023.104502},
	abstract = {Objective:
This study introduces the BlendedICU dataset, a massive dataset of international intensive care data. This dataset aims to facilitate generalizability studies of machine learning models, as well as statistical studies of clinical practices in the intensive care units.
Methods:
Four publicly available and patient-level intensive care databases were used as source databases. A unique and customizable preprocessing pipeline extracted clinically relevant patient-related variables from each source database. The variables were then harmonized and standardized to the Observational Medical Outcomes Partnership (OMOP) Common Data Format. Finally, a brief comparison was carried out to explore differences in the source databases.
Results:
The BlendedICU dataset features 41 timeseries variables as well as the exposure times to 113 active ingredients extracted from the AmsterdamUMCdb, eICU, HiRID, and MIMIC-IV databases. This resulted in a database of more than 309000 intensive care admissions, spanning over 13 years and three countries. We found that data collection, drug exposure, and patient outcomes varied strongly between source databases.
Conclusion:
The variability in data collection, drug exposure, and patient outcomes between the source databases indicated some dissimilarity in patient phenotypes and clinical practices between different intensive care units. This demonstrated the need for generalizability studies of machine learning models. This study provides the clinical data research community with essential data to build efficient and generalizable machine learning models, as well as to explore clinical practices in intensive care units around the world.},
	urldate = {2024-04-03},
	journal = {Journal of Biomedical Informatics},
	author = {Oliver, Matthieu and Allyn, Jérôme and Carencotte, Rémi and Allou, Nicolas and Ferdynus, Cyril},
	month = oct,
	year = {2023},
	keywords = {Data integration, Intensive care unit database, OMOP common data format},
	pages = {104502},
}

@article{sheikhalishahi_benchmarking_2020,
	title = {Benchmarking machine learning models on multi-centre {eICU} critical care dataset},
	volume = {15},
	issn = {1932-6203},
	url = {https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0235424},
	doi = {10.1371/journal.pone.0235424},
	abstract = {Progress of machine learning in critical care has been difficult to track, in part due to absence of public benchmarks. Other fields of research (such as computer vision and natural language processing) have established various competitions and public benchmarks. Recent availability of large clinical datasets has enabled the possibility of establishing public benchmarks. Taking advantage of this opportunity, we propose a public benchmark suite to address four areas of critical care, namely mortality prediction, estimation of length of stay, patient phenotyping and risk of decompensation. We define each task and compare the performance of both clinical models as well as baseline and deep learning models using eICU critical care dataset of around 73,000 patients. This is the first public benchmark on a multi-centre critical care dataset, comparing the performance of clinical gold standard with our predictive model. We also investigate the impact of numerical variables as well as handling of categorical variables on each of the defined tasks. The source code, detailing our methods and experiments is publicly available such that anyone can replicate our results and build upon our work.},
	language = {en},
	number = {7},
	urldate = {2024-04-02},
	journal = {PLOS ONE},
	author = {Sheikhalishahi, Seyedmostafa and Balaraman, Vevake and Osmani, Venet},
	month = feb,
	year = {2020},
	note = {Publisher: Public Library of Science},
	keywords = {Artificial neural networks, Deep learning, Forecasting, Hospitals, Intensive care units, Machine learning, Medical risk factors, Phenotypes},
	pages = {e0235424},
}

@inproceedings{mandyam_cop-e-cat_2021,
	address = {Gainesville Florida},
	title = {{COP}-{E}-{CAT}: cleaning and organization pipeline for {EHR} computational and analytic tasks},
	isbn = {978-1-4503-8450-6},
	shorttitle = {{COP}-{E}-{CAT}},
	url = {https://dl.acm.org/doi/10.1145/3459930.3469536},
	doi = {10.1145/3459930.3469536},
	language = {en},
	urldate = {2024-04-02},
	booktitle = {Proceedings of the 12th {ACM} {Conference} on {Bioinformatics}, {Computational} {Biology}, and {Health} {Informatics}},
	publisher = {ACM},
	author = {Mandyam, Aishwarya and Yoo, Elizabeth C. and Soules, Jeff and Laudanski, Krzysztof and Engelhardt, Barbara E.},
	month = aug,
	year = {2021},
	keywords = {notion},
	pages = {1--9},
}

@misc{fang_large_2024,
	title = {Large {Language} {Models}({LLMs}) on {Tabular} {Data}: {Prediction}, {Generation}, and {Understanding} -- {A} {Survey}},
	shorttitle = {Large {Language} {Models}({LLMs}) on {Tabular} {Data}},
	url = {http://arxiv.org/abs/2402.17944},
	doi = {10.48550/arXiv.2402.17944},
	abstract = {Recent breakthroughs in large language modeling have facilitated rigorous exploration of their application in diverse tasks related to tabular data modeling, such as prediction, tabular data synthesis, question answering, and table understanding. Each task presents unique challenges and opportunities. However, there is currently a lack of comprehensive review that summarizes and compares the key techniques, metrics, datasets, models, and optimization approaches in this research domain. This survey aims to address this gap by consolidating recent progress in these areas, offering a thorough survey and taxonomy of the datasets, metrics, and methodologies utilized. It identifies strengths, limitations, unexplored territories, and gaps in the existing literature, while providing some insights for future research directions in this vital and rapidly evolving field. It also provides relevant code and datasets references. Through this comprehensive review, we hope to provide interested readers with pertinent references and insightful perspectives, empowering them with the necessary tools and knowledge to effectively navigate and address the prevailing challenges in the field.},
	urldate = {2024-03-20},
	publisher = {arXiv},
	author = {Fang, Xi and Xu, Weijie and Tan, Fiona Anting and Zhang, Jiani and Hu, Ziqing and Qi, Yanjun and Nickleach, Scott and Socolinsky, Diego and Sengamedu, Srinivasan and Faloutsos, Christos},
	month = feb,
	year = {2024},
	note = {arXiv:2402.17944 [cs]
version: 2},
	keywords = {68T50, Computer Science - Computation and Language, I.2.7, notion},
}

@book{noauthor_notitle_nodate,
}

@misc{chen_gradnorm_2018,
	title = {{GradNorm}: {Gradient} {Normalization} for {Adaptive} {Loss} {Balancing} in {Deep} {Multitask} {Networks}},
	shorttitle = {{GradNorm}},
	url = {http://arxiv.org/abs/1711.02257},
	doi = {10.48550/arXiv.1711.02257},
	abstract = {Deep multitask networks, in which one neural network produces multiple predictive outputs, can offer better speed and performance than their single-task counterparts but are challenging to train properly. We present a gradient normalization (GradNorm) algorithm that automatically balances training in deep multitask models by dynamically tuning gradient magnitudes. We show that for various network architectures, for both regression and classification tasks, and on both synthetic and real datasets, GradNorm improves accuracy and reduces overfitting across multiple tasks when compared to single-task networks, static baselines, and other adaptive multitask loss balancing techniques. GradNorm also matches or surpasses the performance of exhaustive grid search methods, despite only involving a single asymmetry hyperparameter \${\textbackslash}alpha\$. Thus, what was once a tedious search process that incurred exponentially more compute for each task added can now be accomplished within a few training runs, irrespective of the number of tasks. Ultimately, we will demonstrate that gradient manipulation affords us great control over the training dynamics of multitask networks and may be one of the keys to unlocking the potential of multitask learning.},
	urldate = {2024-03-14},
	publisher = {arXiv},
	author = {Chen, Zhao and Badrinarayanan, Vijay and Lee, Chen-Yu and Rabinovich, Andrew},
	month = jun,
	year = {2018},
	note = {arXiv:1711.02257 [cs]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, notion},
}

@misc{kendall_multi-task_2018,
	title = {Multi-{Task} {Learning} {Using} {Uncertainty} to {Weigh} {Losses} for {Scene} {Geometry} and {Semantics}},
	url = {http://arxiv.org/abs/1705.07115},
	doi = {10.48550/arXiv.1705.07115},
	abstract = {Numerous deep learning applications benefit from multi-task learning with multiple regression and classification objectives. In this paper we make the observation that the performance of such systems is strongly dependent on the relative weighting between each task's loss. Tuning these weights by hand is a difficult and expensive process, making multi-task learning prohibitive in practice. We propose a principled approach to multi-task deep learning which weighs multiple loss functions by considering the homoscedastic uncertainty of each task. This allows us to simultaneously learn various quantities with different units or scales in both classification and regression settings. We demonstrate our model learning per-pixel depth regression, semantic and instance segmentation from a monocular input image. Perhaps surprisingly, we show our model can learn multi-task weightings and outperform separate models trained individually on each task.},
	urldate = {2024-03-14},
	publisher = {arXiv},
	author = {Kendall, Alex and Gal, Yarin and Cipolla, Roberto},
	month = apr,
	year = {2018},
	note = {arXiv:1705.07115 [cs]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, notion},
}

@article{gupta_obesity_2022,
	title = {Obesity {Prediction} with {EHR} {Data}: {A} deep learning approach with interpretable elements},
	volume = {3},
	issn = {2691-1957, 2637-8051},
	shorttitle = {Obesity {Prediction} with {EHR} {Data}},
	url = {http://arxiv.org/abs/1912.02655},
	doi = {10.1145/3506719},
	abstract = {Childhood obesity is a major public health challenge. Early prediction and identification of the children at a high risk of developing childhood obesity may help in engaging earlier and more effective interventions to prevent and manage obesity. Most existing predictive tools for childhood obesity primarily rely on traditional regression-type methods using only a few hand-picked features and without exploiting longitudinal patterns of children data. Deep learning methods allow the use of high-dimensional longitudinal datasets. In this paper, we present a deep learning model designed for predicting future obesity patterns from generally available items on children medical history. To do this, we use a large unaugmented electronic health records dataset from a large pediatric health system. We adopt a general LSTM network architecture which are known to better represent the longitudinal data. We train our proposed model on both dynamic and static EHR data. Our model is used to predict obesity for ages between 2-20 years. We compared the performance of our LSTM model with other machine learning methods that aggregate over sequential data and ignore temporality. To add interpretability, we have additionally included an attention layer to calculate the attention scores for the timestamps and rank features of each timestamp.},
	number = {3},
	urldate = {2024-03-13},
	journal = {ACM Transactions on Computing for Healthcare},
	author = {Gupta, Mehak and Phan, Thao-Ly T. and Bunnell, Timothy and Beheshti, Rahmatollah},
	month = jul,
	year = {2022},
	note = {arXiv:1912.02655 [cs, q-bio, stat]},
	keywords = {Computer Science - Machine Learning, Quantitative Biology - Quantitative Methods, Statistics - Applications, notion},
	pages = {1--19},
}

@article{yang_large_2022,
	title = {A large language model for electronic health records},
	volume = {5},
	copyright = {2022 The Author(s)},
	issn = {2398-6352},
	url = {https://www.nature.com/articles/s41746-022-00742-2},
	doi = {10.1038/s41746-022-00742-2},
	abstract = {There is an increasing interest in developing artificial intelligence (AI) systems to process and interpret electronic health records (EHRs). Natural language processing (NLP) powered by pretrained language models is the key technology for medical AI systems utilizing clinical narratives. However, there are few clinical language models, the largest of which trained in the clinical domain is comparatively small at 110 million parameters (compared with billions of parameters in the general domain). It is not clear how large clinical language models with billions of parameters can help medical AI systems utilize unstructured EHRs. In this study, we develop from scratch a large clinical language model—GatorTron—using {\textgreater}90 billion words of text (including {\textgreater}82 billion words of de-identified clinical text) and systematically evaluate it on five clinical NLP tasks including clinical concept extraction, medical relation extraction, semantic textual similarity, natural language inference (NLI), and medical question answering (MQA). We examine how (1) scaling up the number of parameters and (2) scaling up the size of the training data could benefit these NLP tasks. GatorTron models scale up the clinical language model from 110 million to 8.9 billion parameters and improve five clinical NLP tasks (e.g., 9.6\% and 9.5\% improvement in accuracy for NLI and MQA), which can be applied to medical AI systems to improve healthcare delivery. The GatorTron models are publicly available at: https://catalog.ngc.nvidia.com/orgs/nvidia/teams/clara/models/gatortron\_og.},
	language = {en},
	number = {1},
	urldate = {2024-03-13},
	journal = {npj Digital Medicine},
	author = {Yang, Xi and Chen, Aokun and PourNejatian, Nima and Shin, Hoo Chang and Smith, Kaleb E. and Parisien, Christopher and Compas, Colin and Martin, Cheryl and Costa, Anthony B. and Flores, Mona G. and Zhang, Ying and Magoc, Tanja and Harle, Christopher A. and Lipori, Gloria and Mitchell, Duane A. and Hogan, William R. and Shenkman, Elizabeth A. and Bian, Jiang and Wu, Yonghui},
	month = dec,
	year = {2022},
	note = {Publisher: Nature Publishing Group},
	keywords = {Health care, Medical research, notion},
	pages = {1--9},
}

@article{moor_foundation_2023,
	title = {Foundation models for generalist medical artificial intelligence},
	volume = {616},
	copyright = {2023 Springer Nature Limited},
	issn = {1476-4687},
	url = {https://www.nature.com/articles/s41586-023-05881-4},
	doi = {10.1038/s41586-023-05881-4},
	abstract = {The exceptionally rapid development of highly flexible, reusable artificial intelligence (AI) models is likely to usher in newfound capabilities in medicine. We propose a new paradigm for medical AI, which we refer to as generalist medical AI (GMAI). GMAI models will be capable of carrying out a diverse set of tasks using very little or no task-specific labelled data. Built through self-supervision on large, diverse datasets, GMAI will flexibly interpret different combinations of medical modalities, including data from imaging, electronic health records, laboratory results, genomics, graphs or medical text. Models will in turn produce expressive outputs such as free-text explanations, spoken recommendations or image annotations that demonstrate advanced medical reasoning abilities. Here we identify a set of high-impact potential applications for GMAI and lay out specific technical capabilities and training datasets necessary to enable them. We expect that GMAI-enabled applications will challenge current strategies for regulating and validating AI devices for medicine and will shift practices associated with the collection of large medical datasets.},
	language = {en},
	number = {7956},
	urldate = {2024-03-13},
	journal = {Nature},
	author = {Moor, Michael and Banerjee, Oishi and Abad, Zahra Shakeri Hossein and Krumholz, Harlan M. and Leskovec, Jure and Topol, Eric J. and Rajpurkar, Pranav},
	month = apr,
	year = {2023},
	note = {Publisher: Nature Publishing Group},
	keywords = {Computational biology and bioinformatics, Health care, notion},
	pages = {259--265},
}

@inproceedings{poulain_gt-behrt_2023,
	title = {{GT}-{BEHRT}: {Graph} {Transformers} on {EHRs}: {Better} {Representation} {Improves} {Downstream} {Performance}},
	shorttitle = {Graph {Transformers} on {EHRs}},
	url = {https://openreview.net/forum?id=pe0Vdv7rsL},
	abstract = {Following the success of transformer-based methods across various machine learning applications, their adoption to healthcare predictive tasks using electronic health records (EHR) has also expanded extensively. Similarly, graph-based methods have been shown to be very effective in capturing inherent graph-type relationships in EHRs, leading to improved downstream performance. Although integrating these two families of approaches seems like a natural next step, in practice, creating such a design is challenging and has not been done. This is partly due to known EHR problems, such as high sparsity, making extracting meaningful temporal representations of medical visits challenging. In this study, we propose GT-BEHRT, a new approach that leverages temporal visit embeddings extracted from a graph transformer and uses a BERT-based model to obtain more robust patient representations, especially on longer EHR sequences. The graph-based approach allows GT-BEHRT to implicitly capture the intrinsic graphical relationships between medical observations, while the BERT model extracts the temporal relationships between visits, loosely mimicking the clinicians' decision-making process. As part of our method, we also present a two-step pre-training strategy for learning better graphical and temporal representations. Our proposed method achieves state-of-the-art performance in a variety of standard medical predictive tasks, demonstrating the versatility of our approach.},
	language = {en},
	urldate = {2024-02-09},
	author = {Poulain, Raphael and Beheshti, Rahmatollah},
	month = oct,
	year = {2023},
	keywords = {notion},
}

@article{hill_chiron_nodate,
	title = {{CHIRon}: {A} {Generative} {Foundation} {Model} for {Structured} {Sequential} {Medical} {Data}},
	abstract = {Recent advances in large language models (LLMs) have shown that foundation models (FMs) can learn highly complex representations of sequences that can be used for downstream generative and discriminative tasks such as text generation and classiﬁcation. While most FMs focus on text, recent work has shown FMs can be learnt for sequential medical data, e.g. ICD-10 diagnosis codes associated with speciﬁc patient visits. These FMs demonstrate improved performance on downstream discriminative disease classiﬁcation tasks, but cannot be used for generative tasks such as synthesizing artiﬁcial patient visits for data augmentation or privacy-preserving data sharing since they utilize BERT-based pre-training. In this paper, we introduce CHIRon, the ﬁrst generative FM for sequential medical data. CHIRon utilizes causal masking during for pre-training, enabling generative applications, and incorporates a number of architectural improvements and support for additional medical data types (diagnoses, procedures, medications, lab results, place of service, demographics). We show empirically that CHIRon can be used to generate realistic sequential medical data and also outperforms state of the art FMs for sequential medical data on disease classiﬁcation tasks.},
	language = {en},
	author = {Hill, Brian L and Cordova-Palomera, Aldo and Emami, Melika and Tillman, Robert and Nori, Vijay S and Halperin, Eran},
	keywords = {notion},
}

@misc{chen_multimodal_2023,
	title = {Multimodal {Clinical} {Benchmark} for {Emergency} {Care} ({MC}-{BEC}): {A} {Comprehensive} {Benchmark} for {Evaluating} {Foundation} {Models} in {Emergency} {Medicine}},
	shorttitle = {Multimodal {Clinical} {Benchmark} for {Emergency} {Care} ({MC}-{BEC})},
	url = {http://arxiv.org/abs/2311.04937},
	abstract = {We propose the Multimodal Clinical Benchmark for Emergency Care (MC-BEC), a comprehensive benchmark for evaluating foundation models in Emergency Medicine using a dataset of 100K+ continuously monitored Emergency Department visits from 2020-2022. MC-BEC focuses on clinically relevant prediction tasks at timescales from minutes to days, including predicting patient decompensation, disposition, and emergency department (ED) revisit, and includes a standardized evaluation framework with train-test splits and evaluation metrics. The multimodal dataset includes a wide range of detailed clinical data, including triage information, prior diagnoses and medications, continuously measured vital signs, electrocardiogram and photoplethysmograph waveforms, orders placed and medications administered throughout the visit, free-text reports of imaging studies, and information on ED diagnosis, disposition, and subsequent revisits. We provide performance baselines for each prediction task to enable the evaluation of multimodal, multitask models. We believe that MC-BEC will encourage researchers to develop more effective, generalizable, and accessible foundation models for multimodal clinical data.},
	language = {en},
	urldate = {2024-03-04},
	publisher = {arXiv},
	author = {Chen, Emma and Kansal, Aman and Chen, Julie and Jin, Boyang Tom and Reisler, Julia Rachel and Kim, David A. and Rajpurkar, Pranav},
	month = nov,
	year = {2023},
	note = {arXiv:2311.04937 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning},
}

@article{xu_mufasa_2021,
	title = {{MUFASA}: {Multimodal} {Fusion} {Architecture} {Search} for {Electronic} {Health} {Records}},
	volume = {35},
	copyright = {Copyright (c) 2021 Association for the Advancement of Artificial Intelligence},
	issn = {2374-3468},
	shorttitle = {{MUFASA}},
	url = {https://ojs.aaai.org/index.php/AAAI/article/view/17260},
	doi = {10.1609/aaai.v35i12.17260},
	abstract = {One important challenge of applying deep learning to electronic health records (EHR) is the complexity of their multimodal structure. EHR usually contains a mixture of structured (codes) and unstructured (free-text) data with sparse and irregular longitudinal features -- all of which doctors utilize when making decisions. In the deep learning regime, determining how different modality representations should be fused together is a difficult problem, which is often addressed by handcrafted modeling and intuition. In this work, we extend state-of-the-art neural architecture search (NAS) methods and propose MUltimodal Fusion Architecture SeArch (MUFASA) to simultaneously search across multimodal fusion strategies and modality-specific architectures for the first time. We demonstrate empirically that our MUFASA method outperforms established unimodal NAS on public EHR data with comparable computation costs. In addition, MUFASA produces architectures that outperform Transformer and Evolved Transformer. Compared with these baselines on CCS diagnosis code prediction, our discovered models improve top-5 recall from 0.88 to 0.91 and demonstrate the ability to generalize to other EHR tasks. Studying our top architecture in depth, we provide empirical evidence that MUFASA's improvements are derived from its ability to both customize modeling for each modality and find effective fusion strategies.},
	language = {en},
	number = {12},
	urldate = {2024-03-04},
	journal = {Proceedings of the AAAI Conference on Artificial Intelligence},
	author = {Xu, Zhen and So, David R. and Dai, Andrew M.},
	month = may,
	year = {2021},
	note = {Number: 12},
	keywords = {Healthcare, Medicine \& Wellness, notion},
	pages = {10532--10540},
}

@article{choi_learning_2020,
	title = {Learning the {Graphical} {Structure} of {Electronic} {Health} {Records} with {Graph} {Convolutional} {Transformer}},
	volume = {34},
	copyright = {Copyright (c) 2020 Association for the Advancement of Artificial Intelligence},
	issn = {2374-3468},
	url = {https://ojs.aaai.org/index.php/AAAI/article/view/5400},
	doi = {10.1609/aaai.v34i01.5400},
	abstract = {Effective modeling of electronic health records (EHR) is rapidly becoming an important topic in both academia and industry. A recent study showed that using the graphical structure underlying EHR data (e.g. relationship between diagnoses and treatments) improves the performance of prediction tasks such as heart failure prediction. However, EHR data do not always contain complete structure information. Moreover, when it comes to claims data, structure information is completely unavailable to begin with. Under such circumstances, can we still do better than just treating EHR data as a flat-structured bag-of-features? In this paper, we study the possibility of jointly learning the hidden structure of EHR while performing supervised prediction tasks on EHR data. Specifically, we discuss that Transformer is a suitable basis model to learn the hidden EHR structure, and propose Graph Convolutional Transformer, which uses data statistics to guide the structure learning process. The proposed model consistently outperformed previous approaches empirically, on both synthetic data and publicly available EHR data, for various prediction tasks such as graph reconstruction and readmission prediction, indicating that it can serve as an effective general-purpose representation learning algorithm for EHR data.},
	language = {en},
	number = {01},
	urldate = {2024-03-04},
	journal = {Proceedings of the AAAI Conference on Artificial Intelligence},
	author = {Choi, Edward and Xu, Zhen and Li, Yujia and Dusenberry, Michael and Flores, Gerardo and Xue, Emily and Dai, Andrew},
	month = apr,
	year = {2020},
	note = {Number: 01},
	keywords = {notion},
	pages = {606--613},
}

@misc{karami_tee4ehr_2024,
	title = {{TEE4EHR}: {Transformer} {Event} {Encoder} for {Better} {Representation} {Learning} in {Electronic} {Health} {Records}},
	shorttitle = {{TEE4EHR}},
	url = {http://arxiv.org/abs/2402.06367},
	abstract = {Irregular sampling of time series in electronic health records (EHRs) is one of the main challenges for developing machine learning models. Additionally, the pattern of missing data in certain clinical variables is not at random but depends on the decisions of clinicians and the state of the patient. Point process is a mathematical framework for analyzing event sequence data that is consistent with irregular sampling patterns. Our model, TEE4EHR, is a transformer event encoder (TEE) with point process loss that encodes the pattern of laboratory tests in EHRs. The utility of our TEE has been investigated in a variety of benchmark event sequence datasets. Additionally, we conduct experiments on two real-world EHR databases to provide a more comprehensive evaluation of our model. Firstly, in a self-supervised learning approach, the TEE is jointly learned with an existing attention-based deep neural network which gives superior performance in negative log-likelihood and future event prediction. Besides, we propose an algorithm for aggregating attention weights that can reveal the interaction between the events. Secondly, we transfer and freeze the learned TEE to the downstream task for the outcome prediction, where it outperforms state-of-the-art models for handling irregularly sampled time series. Furthermore, our results demonstrate that our approach can improve representation learning in EHRs and can be useful for clinical prediction tasks.},
	urldate = {2024-03-04},
	publisher = {arXiv},
	author = {Karami, Hojjat and Atienza, David and Ionescu, Anisoara},
	month = feb,
	year = {2024},
	note = {arXiv:2402.06367 [cs]},
	keywords = {Computer Science - Machine Learning, notion},
}

@article{gupta_flexible-window_2022,
	title = {Flexible-{Window} {Predictions} on {Electronic} {Health} {Records}},
	volume = {36},
	issn = {2159-5399},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9610888/},
	doi = {10.1609/aaai.v36i11.21520},
	abstract = {Various types of machine learning techniques are available for analyzing electronic health records (EHRs). For predictive tasks, most existing methods either explicitly or implicitly divide these time-series datasets into predetermined observation and prediction windows. Patients have different lengths of medical history and the desired predictions (for purposes such as diagnosis or treatment) are required at different times in the future. In this paper, we propose a method that uses a sequence-to-sequence generator model to transfer an input sequence of EHR data to a sequence of user-defined target labels, providing the end-users with “flexible” observation and prediction windows to define. We use adversarial and semi-supervised approaches in our design, where the sequence-to-sequence model acts as a generator and a discriminator distinguishes between the actual (observed) and generated labels. We evaluate our models through an extensive series of experiments using two large EHR datasets from adult and pediatric populations. In an obesity predicting case study, we show that our model can achieve superior results in flexible-window prediction tasks, after being trained once and even with large missing rates on the input EHR data. Moreover, using a number of attention analysis experiments, we show that the proposed model can effectively learn more relevant features in different prediction tasks.},
	number = {11},
	urldate = {2024-03-04},
	journal = {Proceedings of the ... AAAI Conference on Artificial Intelligence. AAAI Conference on Artificial Intelligence},
	author = {Gupta, Mehak and Poulain, Raphael and Phan, Thao-Ly T. and Bunnell, H. Timothy and Beheshti, Rahmatollah},
	year = {2022},
	pmid = {36312212},
	pmcid = {PMC9610888},
	keywords = {notion},
	pages = {12510--12516},
}

@misc{noauthor_flexible-window_nodate,
	title = {Flexible-{Window} {Predictions} on {Electronic} {Health} {Records}},
	url = {https://openreview.net/forum?id=SWQ7pkoahMU&referrer=%5Bthe%20profile%20of%20Raphael%20Poulain%5D(%2Fprofile%3Fid%3D~Raphael_Poulain1)},
	abstract = {Various types of machine learning techniques are available for analyzing electronic health records (EHRs). For predictive tasks, most existing methods either explicitly or implicitly divide these...},
	language = {en},
	urldate = {2024-03-04},
	journal = {OpenReview},
	keywords = {notion},
}

@article{chahkoutahi_influence_2024,
	title = {Influence of cost/loss functions on classification rate: {A} comparative study across diverse classifiers and domains},
	volume = {128},
	issn = {09521976},
	shorttitle = {Influence of cost/loss functions on classification rate},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0952197623015993},
	doi = {10.1016/j.engappai.2023.107415},
	language = {en},
	urldate = {2024-02-26},
	journal = {Engineering Applications of Artificial Intelligence},
	author = {Chahkoutahi, Fatemeh and Khashei, Mehdi},
	month = feb,
	year = {2024},
	keywords = {notion},
	pages = {107415},
}

@article{de_la_torre_weighted_2018,
	series = {Machine {Learning} and {Applications} in {Artificial} {Intelligence}},
	title = {Weighted kappa loss function for multi-class classification of ordinal data in deep learning},
	volume = {105},
	issn = {0167-8655},
	url = {https://www.sciencedirect.com/science/article/pii/S0167865517301666},
	doi = {10.1016/j.patrec.2017.05.018},
	abstract = {Weighted Kappa is an index of reference used in many diagnosis systems to compare the agreement between different raters. This index can be also used to evaluate the performance of automatic classification methods against the gold standard given by an expert (or from a consensus of an expert group). On the other hand, in the last years, deep learning has achieved a great importance as a new machine learning method. The usual loss function used in deep learning for multi-class classification is the logarithmic loss. In this paper we explore the direct use of a weighted kappa loss function for multi-class classification of ordinal data, also known as ordinal regression. Three classification problems are solved in the paper using these two loss functions. Results confirm that better classification is made when the model is constructed with the optimization of kappa instead of logarithmic loss.},
	urldate = {2024-02-26},
	journal = {Pattern Recognition Letters},
	author = {de la Torre, Jordi and Puig, Domenec and Valls, Aida},
	month = apr,
	year = {2018},
	keywords = {Computer vision, Convolutional neural networks, Deep learning, Diabetic retinopathy, Supervised learning, Weighted kappa, notion},
	pages = {144--154},
}

@misc{noauthor_annotated_nodate,
	title = {The {Annotated} {Transformer}},
	url = {https://nlp.seas.harvard.edu/annotated-transformer/},
	urldate = {2024-02-23},
	keywords = {notion},
}

@misc{van_de_water_yet_2024,
	title = {Yet {Another} {ICU} {Benchmark}: {A} {Flexible} {Multi}-{Center} {Framework} for {Clinical} {ML}},
	shorttitle = {Yet {Another} {ICU} {Benchmark}},
	url = {http://arxiv.org/abs/2306.05109},
	abstract = {Medical applications of machine learning (ML) have experienced a surge in popularity in recent years. The intensive care unit (ICU) is a natural habitat for ML given the abundance of available data from electronic health records. Models have been proposed to address numerous ICU prediction tasks like the early detection of complications. While authors frequently report state-of-the-art performance, it is challenging to verify claims of superiority. Datasets and code are not always published, and cohort definitions, preprocessing pipelines, and training setups are difficult to reproduce. This work introduces Yet Another ICU Benchmark (YAIB), a modular framework that allows researchers to define reproducible and comparable clinical ML experiments; we offer an end-to-end solution from cohort definition to model evaluation. The framework natively supports most open-access ICU datasets (MIMIC III/IV, eICU, HiRID, AUMCdb) and is easily adaptable to future ICU datasets. Combined with a transparent preprocessing pipeline and extensible training code for multiple ML and deep learning models, YAIB enables unified model development. Our benchmark comes with five predefined established prediction tasks (mortality, acute kidney injury, sepsis, kidney function, and length of stay) developed in collaboration with clinicians. Adding further tasks is straightforward by design. Using YAIB, we demonstrate that the choice of dataset, cohort definition, and preprocessing have a major impact on the prediction performance - often more so than model class - indicating an urgent need for YAIB as a holistic benchmarking tool. We provide our work to the clinical ML community to accelerate method development and enable real-world clinical implementations. Software Repository: https://github.com/rvandewater/YAIB.},
	urldate = {2024-02-09},
	publisher = {arXiv},
	author = {van de Water, Robin and Schmidt, Hendrik and Elbers, Paul and Thoral, Patrick and Arnrich, Bert and Rockenschaub, Patrick},
	month = jan,
	year = {2024},
	note = {arXiv:2306.05109 [cs]},
	keywords = {Computer Science - Machine Learning},
}

@inproceedings{noauthor_flexible_2023,
	title = {A {Flexible} {Generative} {Model} for {Heterogeneous} {Tabular} {EHR} with {Missing} {Modality}},
	url = {https://openreview.net/forum?id=W2tCmRrj7H},
	abstract = {Realistic synthetic electronic health records (EHRs) can be leveraged to acceler- ate methodological developments for research purposes while mitigating privacy concerns associated with data sharing. However, the training of Generative Ad- versarial Networks remains challenging, often resulting in issues like mode col- lapse. While diffusion models have demonstrated progress in generating qual- ity synthetic samples for tabular EHRs given ample denoising steps, their perfor- mance wanes when confronted with missing modalities in heterogeneous tabular EHRs data. For example, some EHRs contain solely static measurements, and some contain only contain temporal measurements, or a blend of both data types. To bridge this gap, we introduce FLEXGEN-EHR– a versatile diffusion model tai- lored for heterogeneous tabular EHRs, equipped with the capability of handling missing modalities in an integrative learning framework. We define an optimal transport module to align and accentuate the common feature space of hetero- geneity of EHRs. We empirically show that our model consistently outperforms existing state-of-the-art synthetic EHR generation methods both in fidelity by up to 3.10\% and utility by up to 7.16\%. Additionally, we show that our method can be successfully used in privacy-sensitive settings, where the original patient-level data cannot be shared.},
	language = {en},
	urldate = {2024-02-09},
	month = oct,
	year = {2023},
	keywords = {notion},
}

@inproceedings{noauthor_large-scale_2023,
	title = {Large-scale training of foundation models for wearable biosignals},
	url = {https://openreview.net/forum?id=pC3WJHf51j},
	abstract = {Tracking biosignals is crucial for monitoring wellness and preempting the development of severe medical conditions. Today, wearable devices can conveniently record various biosignals, creating the opportunity to monitor health status without disruption to one's daily routine. Despite widespread use of wearable devices and existing digital biomarkers, the absence of curated data with annotated medical labels hinders the development of new biomarkers to measure common health conditions. In fact, medical datasets are usually small in comparison to other domains, which is an obstacle for developing neural network models for biosignals. To address this challenge, we have employed self-supervised learning using the unlabeled sensor data collected under informed consent from the large longitudinal Apple Heart and Movement Study (AHMS) to train foundation models for two common biosignals: photoplethysmography (PPG) and electrocardiogram (ECG) recorded on Apple Watch. We curated PPG and ECG datasets from AHMS that include data from \$\{{\textbackslash}sim\} 141\$K participants spanning \$\{{\textbackslash}sim\} 3\$ years. Our self-supervised learning framework includes participant level positive pair selection, stochastic augmentation module and a regularized contrastive loss optimized with momentum training, and generalizes well to both PPG and ECG modalities. We show that the pre-trained foundation models readily encode information regarding participants' demographics and health conditions. To the best of our knowledge, this is the first study that builds foundation models using large-scale PPG and ECG data collected via wearable consumer devices \${\textbackslash}textendash\$ prior works have commonly used smaller-size datasets collected in clinical and experimental settings. We believe PPG and ECG foundation models can enhance future wearable devices by reducing the reliance on labeled data and hold the potential to help the users improve their health.},
	language = {en},
	urldate = {2024-02-09},
	month = oct,
	year = {2023},
	keywords = {notion},
}

@article{lim_temporal_2021,
	title = {Temporal {Fusion} {Transformers} for interpretable multi-horizon time series forecasting},
	volume = {37},
	issn = {0169-2070},
	url = {https://www.sciencedirect.com/science/article/pii/S0169207021000637},
	doi = {10.1016/j.ijforecast.2021.03.012},
	abstract = {Multi-horizon forecasting often contains a complex mix of inputs – including static (i.e. time-invariant) covariates, known future inputs, and other exogenous time series that are only observed in the past – without any prior information on how they interact with the target. Several deep learning methods have been proposed, but they are typically ‘black-box’ models that do not shed light on how they use the full range of inputs present in practical scenarios. In this paper, we introduce the Temporal Fusion Transformer (TFT) – a novel attention-based architecture that combines high-performance multi-horizon forecasting with interpretable insights into temporal dynamics. To learn temporal relationships at different scales, TFT uses recurrent layers for local processing and interpretable self-attention layers for long-term dependencies. TFT utilizes specialized components to select relevant features and a series of gating layers to suppress unnecessary components, enabling high performance in a wide range of scenarios. On a variety of real-world datasets, we demonstrate significant performance improvements over existing benchmarks, and highlight three practical interpretability use cases of TFT.},
	number = {4},
	urldate = {2024-02-06},
	journal = {International Journal of Forecasting},
	author = {Lim, Bryan and Arık, Sercan Ö. and Loeff, Nicolas and Pfister, Tomas},
	month = oct,
	year = {2021},
	keywords = {Attention mechanisms, Deep learning, Explainable AI, Interpretability, Multi-horizon forecasting, Time series, notion},
	pages = {1748--1764},
}

@misc{baevski_effectiveness_2020,
	title = {Effectiveness of self-supervised pre-training for speech recognition},
	url = {http://arxiv.org/abs/1911.03912},
	doi = {10.48550/arXiv.1911.03912},
	abstract = {We compare self-supervised representation learning algorithms which either explicitly quantize the audio data or learn representations without quantization. We find the former to be more accurate since it builds a good vocabulary of the data through vq-wav2vec [1] to enable learning of effective representations in subsequent BERT training. Different to previous work, we directly fine-tune the pre-trained BERT models on transcribed speech using a Connectionist Temporal Classification (CTC) loss instead of feeding the representations into a task-specific model. We also propose a BERT-style model learning directly from the continuous audio data and compare pre-training on raw audio to spectral features. Fine-tuning a BERT model on 10 hour of labeled Librispeech data with a vq-wav2vec vocabulary is almost as good as the best known reported system trained on 100 hours of labeled data on testclean, while achieving a 25\% WER reduction on test-other. When using only 10 minutes of labeled data, WER is 25.2 on test-other and 16.3 on test-clean. This demonstrates that self-supervision can enable speech recognition systems trained on a near-zero amount of transcribed data.},
	urldate = {2024-02-06},
	publisher = {arXiv},
	author = {Baevski, Alexei and Auli, Michael and Mohamed, Abdelrahman},
	month = may,
	year = {2020},
	note = {arXiv:1911.03912 [cs]},
	keywords = {Computer Science - Computation and Language, Computer Science - Machine Learning, notion},
}

@inproceedings{baevski_effectiveness_2020-1,
	title = {Effectiveness of {Self}-{Supervised} {Pre}-{Training} for {ASR}},
	url = {https://ieeexplore.ieee.org/abstract/document/9054224?casa_token=4iAngZytAp0AAAAA:ynwXNrbABOJ8xdCdYUuneqXXPT3eow6dOy_jKT8Xi9rxjtiIqBTjngz1j_CGNqzXDBtGuND-Cw},
	doi = {10.1109/ICASSP40776.2020.9054224},
	abstract = {We compare self-supervised representation learning algorithms which either explicitly quantize the audio data or learn representations without quantization. We find the former to be more accurate since it builds a good vocabulary of the data through vq-wav2vec [1] self-supervision approach to enable learning of effective representations in subsequent BERT training. Different to previous work, we directly fine-tune the pre-trained BERT models on transcribed speech using a Connectionist Temporal Classification (CTC) loss instead of feeding the representations into a task-specific model. We also propose a BERT-style model learning directly from the continuous audio data and compare pre-training on raw audio to spectral features. Fine-tuning a BERT model on 10 hour of labeled Librispeech data with a vq-wav2vec vocabulary is almost as good as the best known reported system trained on 100 hours of labeled data on test-clean, while achieving a 25\% WER reduction on test-other. When using only 10 minutes of labeled data, WER is 25.2 on test-other and 16.3 on test-clean. This demonstrates that self-supervision can enable speech recognition systems trained on a near-zero amount of transcribed data.},
	urldate = {2024-02-06},
	booktitle = {{ICASSP} 2020 - 2020 {IEEE} {International} {Conference} on {Acoustics}, {Speech} and {Signal} {Processing} ({ICASSP})},
	author = {Baevski, Alexei and Mohamed, Abdelrahman},
	month = may,
	year = {2020},
	note = {ISSN: 2379-190X},
	keywords = {Bit error rate, Data models, Speech processing, Speech recognition, Task analysis, Training, Vocabulary, notion},
	pages = {7694--7698},
}

@article{an_tertian_2022,
	title = {{TERTIAN}: {Clinical} {Endpoint} {Prediction} in {ICU} via {Time}-{Aware} {Transformer}-{Based} {Hierarchical} {Attention} {Network}},
	volume = {2022},
	issn = {1687-5273, 1687-5265},
	shorttitle = {{TERTIAN}},
	url = {https://www.hindawi.com/journals/cin/2022/4207940/},
	doi = {10.1155/2022/4207940},
	abstract = {Accurately predicting the clinical endpoint in ICU based on the patient’s electronic medical records (EMRs) is essential for the timely treatment of critically ill patients and allocation of medical resources. However, the patient’s EMRs usually consist of a large amount of heterogeneous multivariate time series data such as laboratory tests and vital signs, which are produced irregularly. Most existing methods fail to effectively model the time irregularity inherent in longitudinal patient medical records and capture the interrelationships among different types of data. To tackle these limitations, we propose a novel time-aware transformer-based hierarchical attention network (TERTIAN) for clinical endpoint prediction. In this model, a time-aware transformer is introduced to learn the personalized irregular temporal patterns of medical events, and a hierarchical attention mechanism is deployed to get the accurate patient fusion representation by comprehensively mining the interactions and correlations among multiple types of medical data. We evaluate our model on the MIMIC-III dataset and MIMIC-IV dataset for the task of mortality prediction, and the results show that TERTIAN achieves higher performance than state-of-the-art approaches.},
	language = {en},
	urldate = {2024-02-05},
	journal = {Computational Intelligence and Neuroscience},
	author = {An, Ying and Liu, Yang and Chen, Xianlai and Sheng, Yu},
	editor = {Hošovský, Alexander},
	month = dec,
	year = {2022},
	keywords = {notion},
	pages = {1--13},
}

@misc{darabi_taper_2020,
	title = {{TAPER}: {Time}-{Aware} {Patient} {EHR} {Representation}},
	shorttitle = {{TAPER}},
	url = {http://arxiv.org/abs/1908.03971},
	abstract = {Effective representation learning of electronic health records is a challenging task and is becoming more important as the availability of such data is becoming pervasive. The data contained in these records are irregular and contain multiple modalities such as notes, and medical codes. They are preempted by medical conditions the patient may have, and are typically jotted down by medical staff. Accompanying codes are notes containing valuable information about patients beyond the structured information contained in electronic health records. We use transformer networks and the recently proposed BERT language model to embed these data streams into a unified vector representation. The presented approach effectively encodes a patient's visit data into a single distributed representation, which can be used for downstream tasks. Our model demonstrates superior performance and generalization on mortality, readmission and length of stay tasks using the publicly available MIMIC-III ICU dataset. Code avaialble at https://github.com/sajaddarabi/TAPER-EHR},
	urldate = {2024-02-05},
	publisher = {arXiv},
	author = {Darabi, Sajad and Kachuee, Mohammad and Fazeli, Shayan and Sarrafzadeh, Majid},
	month = may,
	year = {2020},
	note = {arXiv:1908.03971 [cs, stat]},
	keywords = {Computer Science - Computation and Language, Computer Science - Machine Learning, Statistics - Machine Learning, notion},
}

@article{ma_predicting_2023,
	title = {Predicting heart failure in-hospital mortality by integrating longitudinal and category data in electronic health records},
	volume = {61},
	issn = {1741-0444},
	url = {https://doi.org/10.1007/s11517-023-02816-z},
	doi = {10.1007/s11517-023-02816-z},
	abstract = {Heart failure is a life-threatening syndrome that is diagnosed in 3.6 million people worldwide each year. We propose a deep fusion learning model (DFL-IMP) that uses time series and category data from electronic health records to predict in-hospital mortality in patients with heart failure. We considered 41 time series features (platelets, white blood cells, urea nitrogen, etc.) and 17 category features (gender, insurance, marital status, etc.) as predictors, all of which were available within the time of the patient’s last hospitalization, and a total of 7696 patients participated in the observational study. Our model was evaluated against different time windows. The best performance was achieved with an AUC of 0.914 when the observation window was 5 days and the prediction window was 30 days. Outperformed other baseline models including LR (0.708), RF (0.717), SVM (0.675), LSTM (0.757), GRU (0.759), GRU-U (0.766) and MTSSP (0.770). This tool allows us to predict the expected pathway of heart failure patients and intervene early in the treatment process, which has significant implications for improving the life expectancy of heart failure patients.},
	language = {en},
	number = {7},
	urldate = {2024-02-05},
	journal = {Medical \& Biological Engineering \& Computing},
	author = {Ma, Meikun and Hao, Xiaoyan and Zhao, Jumin and Luo, Shijie and Liu, Yi and Li, Dengao},
	month = jul,
	year = {2023},
	keywords = {Deep learning, Electronic health records, Fatal outcome, Feature fusion, Heart failure, notion},
	pages = {1857--1873},
}

@misc{liu_multimodal_2022,
	title = {Multimodal data matters: language model pre-training over structured and unstructured electronic health records},
	shorttitle = {Multimodal data matters},
	url = {http://arxiv.org/abs/2201.10113},
	doi = {10.48550/arXiv.2201.10113},
	abstract = {As two important textual modalities in electronic health records (EHR), both structured data (clinical codes) and unstructured data (clinical narratives) have recently been increasingly applied to the healthcare domain. Most existing EHR-oriented studies, however, either focus on a particular modality or integrate data from different modalities in a straightforward manner, which usually treats structured and unstructured data as two independent sources of information about patient admission and ignore the intrinsic interactions between them. In fact, the two modalities are documented during the same encounter where structured data inform the documentation of unstructured data and vice versa. In this paper, we proposed a Medical Multimodal Pre-trained Language Model, named MedM-PLM, to learn enhanced EHR representations over structured and unstructured data and explore the interaction of two modalities. In MedM-PLM, two Transformer-based neural network components are firstly adopted to learn representative characteristics from each modality. A cross-modal module is then introduced to model their interactions. We pre-trained MedM-PLM on the MIMIC-III dataset and verified the effectiveness of the model on three downstream clinical tasks, i.e., medication recommendation, 30-day readmission prediction and ICD coding. Extensive experiments demonstrate the power of MedM-PLM compared with state-of-the-art methods. Further analyses and visualizations show the robustness of our model, which could potentially provide more comprehensive interpretations for clinical decision-making.},
	urldate = {2024-02-05},
	publisher = {arXiv},
	author = {Liu, Sicen and Wang, Xiaolong and Hou, Yongshuai and Li, Ge and Wang, Hui and Xu, Hui and Xiang, Yang and Tang, Buzhou},
	month = oct,
	year = {2022},
	note = {arXiv:2201.10113 [cs]},
	keywords = {Computer Science - Computation and Language, Computer Science - Machine Learning, notion},
}

@article{guo_ehr_2023,
	title = {{EHR} foundation models improve robustness in the presence of temporal distribution shift},
	volume = {13},
	copyright = {2023 The Author(s)},
	issn = {2045-2322},
	url = {https://www.nature.com/articles/s41598-023-30820-8},
	doi = {10.1038/s41598-023-30820-8},
	abstract = {Temporal distribution shift negatively impacts the performance of clinical prediction models over time. Pretraining foundation models using self-supervised learning on electronic health records (EHR) may be effective in acquiring informative global patterns that can improve the robustness of task-specific models. The objective was to evaluate the utility of EHR foundation models in improving the in-distribution (ID) and out-of-distribution (OOD) performance of clinical prediction models. Transformer- and gated recurrent unit-based foundation models were pretrained on EHR of up to 1.8 M patients (382 M coded events) collected within pre-determined year groups (e.g., 2009–2012) and were subsequently used to construct patient representations for patients admitted to inpatient units. These representations were used to train logistic regression models to predict hospital mortality, long length of stay, 30-day readmission, and ICU admission. We compared our EHR foundation models with baseline logistic regression models learned on count-based representations (count-LR) in ID and OOD year groups. Performance was measured using area-under-the-receiver-operating-characteristic curve (AUROC), area-under-the-precision-recall curve, and absolute calibration error. Both transformer and recurrent-based foundation models generally showed better ID and OOD discrimination relative to count-LR and often exhibited less decay in tasks where there is observable degradation of discrimination performance (average AUROC decay of 3\% for transformer-based foundation model vs. 7\% for count-LR after 5–9 years). In addition, the performance and robustness of transformer-based foundation models continued to improve as pretraining set size increased. These results suggest that pretraining EHR foundation models at scale is a useful approach for developing clinical prediction models that perform well in the presence of temporal distribution shift.},
	language = {en},
	number = {1},
	urldate = {2024-01-15},
	journal = {Scientific Reports},
	author = {Guo, Lin Lawrence and Steinberg, Ethan and Fleming, Scott Lanyon and Posada, Jose and Lemmon, Joshua and Pfohl, Stephen R. and Shah, Nigam and Fries, Jason and Sung, Lillian},
	month = mar,
	year = {2023},
	note = {Number: 1
Publisher: Nature Publishing Group},
	keywords = {Health care, Machine learning, notion},
	pages = {3767},
}

@inproceedings{shang_pre-training_2019,
	address = {Macao, China},
	title = {Pre-training of {Graph} {Augmented} {Transformers} for {Medication} {Recommendation}},
	isbn = {978-0-9992411-4-1},
	url = {https://www.ijcai.org/proceedings/2019/825},
	doi = {10.24963/ijcai.2019/825},
	abstract = {Medication recommendation is an important healthcare application. It is commonly formulated as a temporal prediction task. Hence, most existing works only utilize longitudinal electronic health records (EHRs) from a small number of patients with multiple visits ignoring a large number of patients with a single visit (selection bias). Moreover, important hierarchical knowledge such as diagnosis hierarchy is not leveraged in the representation learning process. To address these challenges, we propose G-BERT, a new model to combine the power of Graph Neural Networks (GNNs) and BERT (Bidirectional Encoder Representations from Transformers) for medical code representation and medication recommendation. We use GNNs to represent the internal hierarchical structures of medical codes. Then we integrate the GNN representation into a transformer-based visit encoder and pre-train it on EHR data from patients only with a single visit. The pre-trained visit encoder and representation are then ﬁne-tuned for downstream predictive tasks on longitudinal EHRs from patients with multiple visits. G-BERT is the ﬁrst to bring the language model pre-training schema into the healthcare domain and it achieved state-of-the-art performance on the medication recommendation task.},
	language = {en},
	urldate = {2024-01-12},
	booktitle = {Proceedings of the {Twenty}-{Eighth} {International} {Joint} {Conference} on {Artificial} {Intelligence}},
	publisher = {International Joint Conferences on Artificial Intelligence Organization},
	author = {Shang, Junyuan and Ma, Tengfei and Xiao, Cao and Sun, Jimeng},
	month = aug,
	year = {2019},
	keywords = {notion},
	pages = {5953--5959},
}

@misc{hur_descemb_2022,
	title = {{DescEmb}: {Unifying} {Heterogeneous} {Electronic} {Health} {Records} {Systems} via {Text}-{Based} {Code} {Embedding}},
	url = {http://arxiv.org/abs/2108.03625},
	abstract = {Substantial increase in the use of Electronic Health Records (EHRs) has opened new frontiers for predictive healthcare. However, while EHR systems are nearly ubiquitous, they lack a unified code system for representing medical concepts. Heterogeneous formats of EHR present a substantial barrier for the training and deployment of state-of-the-art deep learning models at scale. To overcome this problem, we introduce Description-based Embedding, DescEmb, a code-agnostic description-based representation learning framework for predictive modeling on EHR. DescEmb takes advantage of the flexibility of neural language understanding models while maintaining a neutral approach that can be combined with prior frameworks for task-specific representation learning or predictive modeling. We tested our model's capacity on various experiments including prediction tasks, transfer learning and pooled learning. DescEmb shows higher performance in overall experiments compared to code-based approach, opening the door to a text-based approach in predictive healthcare research that is not constrained by EHR structure nor special domain knowledge.},
	urldate = {2024-01-11},
	publisher = {arXiv},
	author = {Hur, Kyunghoon and Lee, Jiyoung and Oh, Jungwoo and Price, Wesley and Kim, Young-Hak and Choi, Edward},
	month = mar,
	year = {2022},
	note = {arXiv:2108.03625 [cs]},
	keywords = {Computer Science - Machine Learning, Computer Science - Neural and Evolutionary Computing, notion},
}

@misc{hansen_m-bert_2023,
	title = {M-{BERT}: {Hospitalization} {Length} of {Stay} {Prediction} using {Patient} {Event} {Sequences}},
	url = {http://arxiv.org/abs/2303.11042},
	doi = {10.48550/arXiv.2303.11042},
	abstract = {Predicting patients hospital length of stay (LOS) is essential for improving resource allocation and supporting decision-making in healthcare organizations. This paper proposes a novel approach for predicting LOS by modeling patient information as sequences of events. Specifically, we present a transformer-based model, termed Medic-BERT (M-BERT), for LOS prediction using the unique features describing patients medical event sequences. We performed empirical experiments on a cohort of more than 45k emergency care patients from a large Danish hospital. Experimental results show that M-BERT can achieve high accuracy on a variety of LOS problems and outperforms traditional nonsequence-based machine learning approaches.},
	urldate = {2023-12-13},
	publisher = {arXiv},
	author = {Hansen, Emil Riis and Nielsen, Thomas Dyhre and Mulvad, Thomas and Strausholm, Mads Nibe and Sagi, Tomer and Hose, Katja},
	month = mar,
	year = {2023},
	note = {arXiv:2303.11042 [cs]},
	keywords = {68T07, Computer Science - Artificial Intelligence, Computer Science - Machine Learning, I.2.7, J.3, notion},
}

@misc{wang_medhmp_2023,
	title = {{MEDHMP}: {Hierarchical} {Pretraining} on {Multimodal} {Electronic} {Health} {Records}},
	url = {http://arxiv.org/abs/2310.07871},
	doi = {10.48550/arXiv.2310.07871},
	abstract = {Pretraining has proven to be a powerful technique in natural language processing (NLP), exhibiting remarkable success in various NLP downstream tasks. However, in the medical domain, existing pretrained models on electronic health records (EHR) fail to capture the hierarchical nature of EHR data, limiting their generalization capability across diverse downstream tasks using a single pretrained model. To tackle this challenge, this paper introduces a novel, general, and unified pretraining framework called MEDHMP, specifically designed for hierarchically multimodal EHR data. The effectiveness of the proposed MEDHMP is demonstrated through experimental results on eight downstream tasks spanning three levels. Comparisons against eighteen baselines further highlight the efficacy of our approach.},
	urldate = {2023-12-13},
	publisher = {arXiv},
	author = {Wang, Xiaochen and Luo, Junyu and Wang, Jiaqi and Yin, Ziyi and Cui, Suhan and Zhong, Yuan and Wang, Yaqing and Ma, Fenglong},
	month = oct,
	year = {2023},
	note = {arXiv:2310.07871 [cs]},
	keywords = {Computer Science - Artificial Intelligence, notion},
}

@inproceedings{poulain_cehr-gan-bert_2022,
	title = {{CEHR}-{GAN}-{BERT}: {Few}-{Shot} {Learning} with {Semi}-{Supervised} {Transformers} for {Electronic} {Health} {Records}},
	url = {https://proceedings.mlr.press/v182/poulain22a.html},
	abstract = {With the growing availability of Electronic Health Records (EHRs), many deep learning methods have been developed to leverage such datasets in medical prediction tasks. Notably, transformer-based architectures have proven to be highly effective for EHRs. Transformer-based architectures are generally very effective in “transferring” the acquired knowledge from very large datasets to smaller target datasets through their comprehensive “pre-training” process. However, to work efficiently, they still rely on the target datasets for the downstream tasks, and if the target dataset is (very) small, the performance of downstream models can degrade rapidly. In biomedical applications, it is common to only have access to small datasets, for instance, when studying rare diseases, invasive procedures, or using restrictive cohort selection processes. In this study, we present CEHR-GAN-BERT, a semi-supervised transformer-based architecture that leverages both in and out-of-cohort patients to learn better patient representations in the context of few-shot learning. The proposed method opens new learning opportunities where only a few hundred samples are available. We extensively evaluate our method on four prediction tasks and three public datasets showing the ability of our model to achieve improvements upwards of 5\% on all performance metrics (including AUROC and F1 Score) on the tasks that use less than 200 annotated patients during the training process.},
	language = {en},
	urldate = {2024-01-11},
	booktitle = {Proceedings of the 7th {Machine} {Learning} for {Healthcare} {Conference}},
	publisher = {PMLR},
	author = {Poulain, Raphael and Gupta, Mehak and Beheshti, Rahmatollah},
	month = dec,
	year = {2022},
	note = {ISSN: 2640-3498},
	keywords = {notion},
	pages = {853--873},
}

@article{purushotham_benchmarking_2018,
	title = {Benchmarking deep learning models on large healthcare datasets},
	volume = {83},
	issn = {1532-0480},
	doi = {10.1016/j.jbi.2018.04.007},
	abstract = {Deep learning models (aka Deep Neural Networks) have revolutionized many fields including computer vision, natural language processing, speech recognition, and is being increasingly used in clinical healthcare applications. However, few works exist which have benchmarked the performance of the deep learning models with respect to the state-of-the-art machine learning models and prognostic scoring systems on publicly available healthcare datasets. In this paper, we present the benchmarking results for several clinical prediction tasks such as mortality prediction, length of stay prediction, and ICD-9 code group prediction using Deep Learning models, ensemble of machine learning models (Super Learner algorithm), SAPS II and SOFA scores. We used the Medical Information Mart for Intensive Care III (MIMIC-III) (v1.4) publicly available dataset, which includes all patients admitted to an ICU at the Beth Israel Deaconess Medical Center from 2001 to 2012, for the benchmarking tasks. Our results show that deep learning models consistently outperform all the other approaches especially when the 'raw' clinical time series data is used as input features to the models.},
	language = {eng},
	journal = {Journal of Biomedical Informatics},
	author = {Purushotham, Sanjay and Meng, Chuizheng and Che, Zhengping and Liu, Yan},
	month = jul,
	year = {2018},
	pmid = {29879470},
	keywords = {Aged, Aged, 80 and over, Algorithms, Benchmarking, Databases, Factual, Deep Learning, Deep learning models, Female, Forecasting, Hospital Mortality, Humans, ICD-9 code group prediction, Intensive Care Units, International Classification of Diseases, Length of Stay, Length of stay, Male, Middle Aged, Mortality prediction, Neural Networks, Computer, Super learner algorithm},
	pages = {112--134},
}

@inproceedings{mcdermott_comprehensive_2021,
	address = {Virtual Event USA},
	title = {A comprehensive {EHR} timeseries pre-training benchmark},
	isbn = {978-1-4503-8359-2},
	url = {https://dl.acm.org/doi/10.1145/3450439.3451877},
	doi = {10.1145/3450439.3451877},
	language = {en},
	urldate = {2024-01-11},
	booktitle = {Proceedings of the {Conference} on {Health}, {Inference}, and {Learning}},
	publisher = {ACM},
	author = {McDermott, Matthew and Nestor, Bret and Kim, Evan and Zhang, Wancong and Goldenberg, Anna and Szolovits, Peter and Ghassemi, Marzyeh},
	month = apr,
	year = {2021},
	pages = {257--278},
}

@misc{guo_characterizing_2023,
	title = {Characterizing the limitations of using diagnosis codes in the context of machine learning for healthcare},
	copyright = {© 2023, Posted by Cold Spring Harbor Laboratory. This pre-print is available under a Creative Commons License (Attribution 4.0 International), CC BY 4.0, as described at http://creativecommons.org/licenses/by/4.0/},
	url = {https://www.medrxiv.org/content/10.1101/2023.03.14.23287202v1},
	doi = {10.1101/2023.03.14.23287202},
	abstract = {Importance Diagnostic codes are commonly used as inputs for clinical prediction models, to create labels for prediction tasks, and to identify cohorts for multicenter network studies. However, the coverage rates of diagnostic codes and their variability across institutions are underexplored.
Objective Primary objective was to describe lab- and diagnosis-based labels for 7 selected outcomes at three institutions. Secondary objectives were to describe agreement, sensitivity, and specificity of diagnosis-based labels against lab-based labels.
Methods This study included three cohorts: SickKidsPeds from The Hospital for Sick Children, and StanfordPeds and StanfordAdults from Stanford Medicine. We included seven clinical outcomes with lab-based definitions: acute kidney injury, hyperkalemia, hypoglycemia, hyponatremia, anemia, neutropenia and thrombocytopenia. For each outcome, we created four lab-based labels (abnormal, mild, moderate and severe) based on test result and one diagnosis-based label. Proportion of admissions with a positive label were presented for each outcome stratified by cohort. Using lab-based labels as the gold standard, agreement using Cohen’s Kappa, sensitivity and specificity were calculated for each lab-based severity level.
Results The number of admissions included were: SickKidsPeds (n=59,298), StanfordPeds (n=24,639) and StanfordAdults (n=159,985). The proportion of admissions with a positive diagnosis-based label was significantly higher for StanfordPeds compared to SickKidsPeds across all outcomes, with odds ratio (99.9\% confidence interval) for abnormal diagnosis-based label ranging from 2.2 (1.7-2.7) for neutropenia to 18.4 (10.1-33.4) for hyperkalemia. Lab-based labels were more similar by institution. When using lab-based labels as the gold standard, Cohen’s Kappa and sensitivity were lower at SickKidsPeds for all severity levels compared to StanfordPeds.
Conclusions Across multiple outcomes, diagnosis codes were consistently different between the two pediatric institutions. This difference was not explained by differences in test results. These results may have implications for machine learning model development and deployment.},
	language = {en},
	urldate = {2024-01-11},
	publisher = {medRxiv},
	author = {Guo, Lin Lawrence and Morse, Keith E. and Aftandilian, Catherine and Steinberg, Ethan and Fries, Jason and Posada, Jose and Fleming, Scott Lanyon and Lemmon, Joshua and Jessa, Karim and Shah, Nigam and Sung, Lillian},
	month = mar,
	year = {2023},
	note = {Pages: 2023.03.14.23287202},
	keywords = {notion},
}

@article{li_inferring_2020,
	title = {Inferring multimodal latent topics from electronic health records},
	volume = {11},
	copyright = {2020 The Author(s)},
	issn = {2041-1723},
	url = {https://www.nature.com/articles/s41467-020-16378-3},
	doi = {10.1038/s41467-020-16378-3},
	abstract = {Electronic health records (EHR) are rich heterogeneous collections of patient health information, whose broad adoption provides clinicians and researchers unprecedented opportunities for health informatics, disease-risk prediction, actionable clinical recommendations, and precision medicine. However, EHRs present several modeling challenges, including highly sparse data matrices, noisy irregular clinical notes, arbitrary biases in billing code assignment, diagnosis-driven lab tests, and heterogeneous data types. To address these challenges, we present MixEHR, a multi-view Bayesian topic model. We demonstrate MixEHR on MIMIC-III, Mayo Clinic Bipolar Disorder, and Quebec Congenital Heart Disease EHR datasets. Qualitatively, MixEHR disease topics reveal meaningful combinations of clinical features across heterogeneous data types. Quantitatively, we observe superior prediction accuracy of diagnostic codes and lab test imputations compared to the state-of-art methods. We leverage the inferred patient topic mixtures to classify target diseases and predict mortality of patients in critical conditions. In all comparison, MixEHR confers competitive performance and reveals meaningful disease-related topics.},
	language = {en},
	number = {1},
	urldate = {2024-01-11},
	journal = {Nature Communications},
	author = {Li, Yue and Nair, Pratheeksha and Lu, Xing Han and Wen, Zhi and Wang, Yuening and Dehaghi, Amir Ardalan Kalantari and Miao, Yan and Liu, Weiqi and Ordog, Tamas and Biernacka, Joanna M. and Ryu, Euijung and Olson, Janet E. and Frye, Mark A. and Liu, Aihua and Guo, Liming and Marelli, Ariane and Ahuja, Yuri and Davila-Velderrain, Jose and Kellis, Manolis},
	month = may,
	year = {2020},
	note = {Number: 1
Publisher: Nature Publishing Group},
	keywords = {Computational science, Health care, Machine learning, notion},
	pages = {2536},
}

@misc{hur_unihpf_2022,
	title = {{UniHPF} : {Universal} {Healthcare} {Predictive} {Framework} with {Zero} {Domain} {Knowledge}},
	shorttitle = {{UniHPF}},
	url = {http://arxiv.org/abs/2211.08082},
	abstract = {Despite the abundance of Electronic Healthcare Records (EHR), its heterogeneity restricts the utilization of medical data in building predictive models. To address this challenge, we propose Universal Healthcare Predictive Framework (UniHPF), which requires no medical domain knowledge and minimal pre-processing for multiple prediction tasks. Experimental results demonstrate that UniHPF is capable of building large-scale EHR models that can process any form of medical data from distinct EHR systems. We believe that our findings can provide helpful insights for further research on the multi-source learning of EHRs.},
	urldate = {2024-01-11},
	publisher = {arXiv},
	author = {Hur, Kyunghoon and Oh, Jungwoo and Kim, Junu and Kim, Jiyoun and Lee, Min Jae and Cho, Eunbyeol and Moon, Seong-Eun and Kim, Young-Hak and Choi, Edward},
	month = nov,
	year = {2022},
	note = {arXiv:2211.08082 [cs]},
	keywords = {Computer Science - Machine Learning, Computer Science - Neural and Evolutionary Computing, notion},
}

@article{zhang_adadiag_2022,
	title = {{AdaDiag}: {Adversarial} {Domain} {Adaptation} of {Diagnostic} {Prediction} with {Clinical} {Event} {Sequences}},
	volume = {134},
	issn = {1532-0464},
	shorttitle = {{AdaDiag}},
	url = {https://www.sciencedirect.com/science/article/pii/S1532046422001794},
	doi = {10.1016/j.jbi.2022.104168},
	abstract = {Early detection of heart failure (HF) can provide patients with the opportunity for more timely intervention and better disease management, as well as efficient use of healthcare resources. Recent machine learning (ML) methods have shown promising performance on diagnostic prediction using temporal sequences from electronic health records (EHRs). In practice, however, these models may not generalize to other populations due to dataset shift. Shifts in datasets can be attributed to a range of factors such as variations in demographics, data management methods, and healthcare delivery patterns. In this paper, we use unsupervised adversarial domain adaptation methods to adaptively reduce the impact of dataset shift on cross-institutional transfer performance. The proposed framework is validated on a next-visit HF onset prediction task using a BERT-style Transformer-based language model pre-trained with a masked language modeling (MLM) task. Our model empirically demonstrates superior prediction performance relative to non-adversarial baselines in both transfer directions on two different clinical event sequence data sources.},
	urldate = {2024-01-11},
	journal = {Journal of Biomedical Informatics},
	author = {Zhang, Tianran and Chen, Muhao and Bui, Alex A. T.},
	month = oct,
	year = {2022},
	keywords = {Clinical event sequence modeling, Domain adaptation, Heart failure, Transformers, notion},
	pages = {104168},
}

@misc{pang_cehr-bert_2021,
	title = {{CEHR}-{BERT}: {Incorporating} temporal information from structured {EHR} data to improve prediction tasks},
	shorttitle = {{CEHR}-{BERT}},
	url = {http://arxiv.org/abs/2111.08585},
	doi = {10.48550/arXiv.2111.08585},
	abstract = {Embedding algorithms are increasingly used to represent clinical concepts in healthcare for improving machine learning tasks such as clinical phenotyping and disease prediction. Recent studies have adapted state-of-the-art bidirectional encoder representations from transformers (BERT) architecture to structured electronic health records (EHR) data for the generation of contextualized concept embeddings, yet do not fully incorporate temporal data across multiple clinical domains. Therefore we developed a new BERT adaptation, CEHR-BERT, to incorporate temporal information using a hybrid approach by augmenting the input to BERT using artificial time tokens, incorporating time, age, and concept embeddings, and introducing a new second learning objective for visit type. CEHR-BERT was trained on a subset of Columbia University Irving Medical Center-York Presbyterian Hospital's clinical data, which includes 2.4M patients, spanning over three decades, and tested using 4-fold cross-validation on the following prediction tasks: hospitalization, death, new heart failure (HF) diagnosis, and HF readmission. Our experiments show that CEHR-BERT outperformed existing state-of-the-art clinical BERT adaptations and baseline models across all 4 prediction tasks in both ROC-AUC and PR-AUC. CEHR-BERT also demonstrated strong transfer learning capability, as our model trained on only 5\% of data outperformed comparison models trained on the entire data set. Ablation studies to better understand the contribution of each time component showed incremental gains with every element, suggesting that CEHR-BERT's incorporation of artificial time tokens, time and age embeddings with concept embeddings, and the addition of the second learning objective represents a promising approach for future BERT-based clinical embeddings.},
	urldate = {2024-01-11},
	publisher = {arXiv},
	author = {Pang, Chao and Jiang, Xinzhuo and Kalluri, Krishna S. and Spotnitz, Matthew and Chen, RuiJun and Perotte, Adler and Natarajan, Karthik},
	month = nov,
	year = {2021},
	note = {arXiv:2111.08585 [cs]},
	keywords = {Computer Science - Machine Learning, notion},
}

@article{prakash_rarebert_2021,
	title = {{RareBERT}: {Transformer} {Architecture} for {Rare} {Disease} {Patient} {Identification} using {Administrative} {Claims}},
	volume = {35},
	copyright = {Copyright (c) 2021 Association for the Advancement of Artificial Intelligence},
	issn = {2374-3468},
	shorttitle = {{RareBERT}},
	url = {https://ojs.aaai.org/index.php/AAAI/article/view/16122},
	doi = {10.1609/aaai.v35i1.16122},
	abstract = {A rare disease is any disease that affects a very small percentage (1 in 1,500) of population. It is estimated that there are nearly 7,000 rare disease affecting 30 million patients in the U. S. alone. Most of the patients suffering from rare diseases experience multiple misdiagnoses and may never be diagnosed correctly. This is largely driven by the low prevalence of the disease that results in a lack of awareness among healthcare providers. There have been efforts from machine learning researchers to develop predictive models to help diagnose patients using healthcare datasets such as electronic health records and administrative claims. Most recently, transformer models have been applied to predict diseases BEHRT, G-BERT and Med-BERT. However, these have been developed specifically for electronic health records (EHR) and have not been designed to address rare disease challenges such as class imbalance, partial longitudinal data capture, and noisy labels. As a result, they deliver poor performance in predicting rare diseases compared with baselines. Besides, EHR datasets are generally confined to the hospital systems using them and do not capture a wider sample of patients thus limiting the availability of sufficient rare dis-ease patients in the dataset. To address these challenges, we introduced an extension of the BERT model tailored for rare disease diagnosis called RareBERT which has been trained on administrative claims datasets. RareBERT extends Med-BERT by including context embedding and temporal reference embedding. Moreover, we introduced a novel adaptive loss function to handle the class imbal-ance. In this paper, we show our experiments on diagnosing X-Linked Hypophosphatemia (XLH), a genetic rare disease. While RareBERT performs significantly better than the baseline models (79.9\% AUPRC versus 30\% AUPRC for Med-BERT), owing to the transformer architecture, it also shows its robustness in partial longitudinal data capture caused by poor capture of claims with a drop in performance of only 1.35\% AUPRC, compared with 12\% for Med-BERT and 33.0\% for LSTM and 67.4\% for boosting trees based baseline.},
	language = {en},
	number = {1},
	urldate = {2024-01-11},
	journal = {Proceedings of the AAAI Conference on Artificial Intelligence},
	author = {Prakash, P. K. S. and Chilukuri, Srinivas and Ranade, Nikhil and Viswanathan, Shankar},
	month = may,
	year = {2021},
	note = {Number: 1},
	keywords = {(Deep) Neural Network Algorithms, notion},
	pages = {453--460},
}

@misc{wornow_ehrshot_2023,
	title = {{EHRSHOT}: {An} {EHR} {Benchmark} for {Few}-{Shot} {Evaluation} of {Foundation} {Models}},
	shorttitle = {{EHRSHOT}},
	url = {http://arxiv.org/abs/2307.02028},
	doi = {10.48550/arXiv.2307.02028},
	abstract = {While the general machine learning (ML) community has benefited from public datasets, tasks, and models, the progress of ML in healthcare has been hampered by a lack of such shared assets. The success of foundation models creates new challenges for healthcare ML by requiring access to shared pretrained models to validate performance benefits. We help address these challenges through three contributions. First, we publish a new dataset, EHRSHOT, which contains deidentified structured data from the electronic health records (EHRs) of 6,739 patients from Stanford Medicine. Unlike MIMIC-III/IV and other popular EHR datasets, EHRSHOT is longitudinal and not restricted to ICU/ED patients. Second, we publish the weights of CLMBR-T-base, a 141M parameter clinical foundation model pretrained on the structured EHR data of 2.57M patients. We are one of the first to fully release such a model for coded EHR data; in contrast, most prior models released for clinical data (e.g. GatorTron, ClinicalBERT) only work with unstructured text and cannot process the rich, structured data within an EHR. We provide an end-to-end pipeline for the community to validate and build upon its performance. Third, we define 15 few-shot clinical prediction tasks, enabling evaluation of foundation models on benefits such as sample efficiency and task adaptation. Our model and dataset are available via a research data use agreement from our website: https://ehrshot.stanford.edu. Code to reproduce our results are available at our Github repo: https://github.com/som-shahlab/ehrshot-benchmark},
	urldate = {2024-01-11},
	publisher = {arXiv},
	author = {Wornow, Michael and Thapa, Rahul and Steinberg, Ethan and Fries, Jason A. and Shah, Nigam H.},
	month = dec,
	year = {2023},
	note = {arXiv:2307.02028 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language, Computer Science - Machine Learning, notion},
}

@misc{steinberg_motor_2023,
	title = {{MOTOR}: {A} {Time}-{To}-{Event} {Foundation} {Model} {For} {Structured} {Medical} {Records}},
	shorttitle = {{MOTOR}},
	url = {http://arxiv.org/abs/2301.03150},
	doi = {10.48550/arXiv.2301.03150},
	abstract = {We present a self-supervised, time-to-event (TTE) foundation model called MOTOR (Many Outcome Time Oriented Representations) which is pretrained on timestamped sequences of events in electronic health records (EHR) and health insurance claims. TTE models are used for estimating the probability distribution of the time until a specific event occurs, which is an important task in medical settings. TTE models provide many advantages over classification using fixed time horizons, including naturally handling censored observations, but are challenging to train with limited labeled data. MOTOR addresses this challenge by pretraining on up to 55M patient records (9B clinical events). We evaluate MOTOR's transfer learning performance on 19 tasks, across 3 patient databases (a private EHR system, MIMIC-IV, and Merative claims data). Task-specific models adapted from MOTOR improve time-dependent C statistics by 4.6\% over state-of-the-art, improve label efficiency by up to 95\% ,and are more robust to temporal distributional shifts. We further evaluate cross-site portability by adapting our MOTOR foundation model for six prediction tasks on the MIMIC-IV dataset, where it outperforms all baselines. MOTOR is the first foundation model for medical TTE predictions and we release a 143M parameter pretrained model for research use at [redacted URL].},
	urldate = {2024-01-11},
	publisher = {arXiv},
	author = {Steinberg, Ethan and Fries, Jason and Xu, Yizhe and Shah, Nigam},
	month = dec,
	year = {2023},
	note = {arXiv:2301.03150 [cs]},
	keywords = {Computer Science - Machine Learning, notion},
}

@article{liang_tbna-pr_2023,
	title = {{tBNA}-{PR}: {Heart} failure disease prediction and stratification with temporal electronic health records data using patient representation},
	volume = {43},
	issn = {0208-5216},
	url = {https://www.sciencedirect.com/science/article/pii/S020852162200119X},
	doi = {10.1016/j.bbe.2022.12.008},
	abstract = {Accurate early prediction of heart failure and identification of heart failure sub-phenotypes can enable in-time interventions and treatments, assist with policy decisions, and lead to a better understanding of disease pathophysiology in groups of patients. However, decision making more challenging for clinicians since the available data is complex, heterogeneous, temporal, and different in granularity. Even with much data, it is difficult for a cardiologist to pre-judge a patient’s heart condition at the next visit by relying on data from only one visit. Moreover, complicated and overloaded information bewilders clinicians, bringing obstacles to the stratification of patients and the mining of disease typical patterns in subgroups. To overcome these issues, this study proposes a novel Patient Representation model based on a temporal Bidirectional neural network with an Attention mechanism deep learning model called tBNA-PR. tBNA-PR effectively models heterogeneous and temporal Electronic Health Records (tEHRs) data from past and future directions to obtain informative patient representation to realize accurate heart failure prediction and reasonable patient stratification. Additionally, this study extracts typical diagnosis and prescriptions for disease patterns exploration and identifies significant features of sub-phenotypes for subgroup explanation in the context of complex clinical settings to provide better quality healthcare services and clinical decision support. This study leverages a real-world dataset MIMIC-III database. We carried out experiments on the prediction of heart failure to investigate tBNA-PR, which obtains prediction accuracy of 0.78, F1-Score of 0.7671, and AUC of 0.7198, showing a certain superiority compared with several state-of-the-art benchmarks. Moreover, we identified three distinct sub-phenotypes in all heart failure patients in the dataset with the clustering method and subgroup analysis. Sub-phenotype I has characteristics of more long-term anticoagulants. This sub-group has more patients who have the thrombotic disease. Sub-phenotype II has features of more patients having kidney disease, pneumonia, urinary tract infection, and coronary heart disease surgery history. Sub-phenotype III has characteristics of more patients having acidosis, depressive disorder, esophageal reflux, obstructive sleep apnea, and acquired hypothyroidism. Statistical tests show that the features, including age, creatinine, hemoglobin, urea nitrogen, and blood potassium, are significantly different among the three sub-phenotypes and have particular high importance. The resultant findings from this work have practical implications for clinical decision support.},
	number = {1},
	urldate = {2023-11-14},
	journal = {Biocybernetics and Biomedical Engineering},
	author = {Liang, Ye and Guo, Chonghui},
	month = jan,
	year = {2023},
	keywords = {Deep learning, Disease prediction, Electronic health records, Heart failure, Patient stratification, notion},
	pages = {124--141},
}

@misc{shukla_mtan_2021,
	title = {{mTAN}: {Multi}-{Time} {Attention} {Networks} for {Irregularly} {Sampled} {Time} {Series}},
	url = {http://arxiv.org/abs/2101.10318},
	abstract = {Irregular sampling occurs in many time series modeling applications where it presents a significant challenge to standard deep learning models. This work is motivated by the analysis of physiological time series data in electronic health records, which are sparse, irregularly sampled, and multivariate. In this paper, we propose a new deep learning framework for this setting that we call Multi-Time Attention Networks. Multi-Time Attention Networks learn an embedding of continuous-time values and use an attention mechanism to produce a fixed-length representation of a time series containing a variable number of observations. We investigate the performance of this framework on interpolation and classification tasks using multiple datasets. Our results show that the proposed approach performs as well or better than a range of baseline and recently proposed models while offering significantly faster training times than current state-of-the-art methods.},
	urldate = {2023-09-14},
	publisher = {arXiv},
	author = {Shukla, Satya Narayan and Marlin, Benjamin M.},
	month = jun,
	year = {2021},
	note = {arXiv:2101.10318 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning, notion},
}

@article{tipirneni_strats_2022,
	title = {{STraTS}: {Self}-{Supervised} {Transformer} for {Sparse} and {Irregularly} {Sampled} {Multivariate} {Clinical} {Time}-{Series}},
	volume = {16},
	issn = {1556-4681, 1556-472X},
	url = {https://dl.acm.org/doi/10.1145/3516367},
	doi = {10.1145/3516367},
	abstract = {Multivariate time-series data are frequently observed in critical care settings and are typically characterized by sparsity (missing information) and irregular time intervals. Existing approaches for learning representations in this domain handle these challenges by either aggregation or imputation of values, which in-turn suppresses the fine-grained information and adds undesirable noise/overhead into the machine learning model. To tackle this problem, we propose a
              S
              elf-supervised
              Tra
              nsformer for
              T
              ime-
              S
              eries (STraTS) model, which overcomes these pitfalls by treating time-series as a set of observation triplets instead of using the standard dense matrix representation. It employs a novel Continuous Value Embedding technique to encode continuous time and variable values without the need for discretization. It is composed of a Transformer component with multi-head attention layers, which enable it to learn contextual triplet embeddings while avoiding the problems of recurrence and vanishing gradients that occur in recurrent architectures. In addition, to tackle the problem of limited availability of labeled data (which is typically observed in many healthcare applications), STraTS utilizes self-supervision by leveraging unlabeled data to learn better representations by using time-series forecasting as an auxiliary proxy task. Experiments on real-world multivariate clinical time-series benchmark datasets demonstrate that STraTS has better prediction performance than state-of-the-art methods for mortality prediction, especially when labeled data is limited. Finally, we also present an interpretable version of STraTS, which can identify important measurements in the time-series data. Our data preprocessing and model implementation codes are available at
              https://github.com/sindhura97/STraTS
              .},
	language = {en},
	number = {6},
	urldate = {2023-09-14},
	journal = {ACM Transactions on Knowledge Discovery from Data},
	author = {Tipirneni, Sindhu and Reddy, Chandan K.},
	month = dec,
	year = {2022},
	keywords = {notion},
	pages = {1--17},
}

@article{harutyunyan_multitask_2019,
	title = {Multitask learning and benchmarking with clinical time series data},
	volume = {6},
	copyright = {2019 The Author(s)},
	issn = {2052-4463},
	url = {https://www.nature.com/articles/s41597-019-0103-9},
	doi = {10.1038/s41597-019-0103-9},
	abstract = {Health care is one of the most exciting frontiers in data mining and machine learning. Successful adoption of electronic health records (EHRs) created an explosion in digital clinical data available for analysis, but progress in machine learning for healthcare research has been difficult to measure because of the absence of publicly available benchmark data sets. To address this problem, we propose four clinical prediction benchmarks using data derived from the publicly available Medical Information Mart for Intensive Care (MIMIC-III) database. These tasks cover a range of clinical problems including modeling risk of mortality, forecasting length of stay, detecting physiologic decline, and phenotype classification. We propose strong linear and neural baselines for all four tasks and evaluate the effect of deep supervision, multitask training and data-specific architectural modifications on the performance of neural models.},
	language = {en},
	number = {1},
	urldate = {2024-01-10},
	journal = {Scientific Data},
	author = {Harutyunyan, Hrayr and Khachatrian, Hrant and Kale, David C. and Ver Steeg, Greg and Galstyan, Aram},
	month = jun,
	year = {2019},
	note = {Number: 1
Publisher: Nature Publishing Group},
	keywords = {Databases, Disease-free survival, Machine learning, notion},
	pages = {96},
}

@article{song_sand_2018,
	title = {{SAnD}: {Attend} and {Diagnose}: {Clinical} {Time} {Series} {Analysis} {Using} {Attention} {Models}},
	volume = {32},
	issn = {2374-3468, 2159-5399},
	shorttitle = {Attend and {Diagnose}},
	url = {https://ojs.aaai.org/index.php/AAAI/article/view/11635},
	doi = {10.1609/aaai.v32i1.11635},
	abstract = {With widespread adoption of electronic health records, there is an increased emphasis for predictive models that can effectively deal with clinical time-series data. Powered by Recurrent Neural Network (RNN) architectures with Long Short-Term Memory (LSTM) units, deep neural networks have achieved state-of-the-art results in several clinical prediction tasks. Despite the success of RNN, its sequential nature prohibits parallelized computing, thus making it inefficient particularly when processing long sequences. Recently, architectures which are based solely on attention mechanisms have shown remarkable success in transduction tasks in NLP, while being computationally superior. In this paper, for the first time, we utilize attention models for clinical time-series modeling, thereby dispensing recurrence entirely. We develop the SAnD (Simply Attend and Diagnose) architecture, which employs a masked, self-attention mechanism, and uses positional encoding and dense interpolation strategies for incorporating temporal order. Furthermore, we develop a multi-task variant of SAnD to jointly infer models with multiple diagnosis tasks. Using the recent MIMIC-III benchmark datasets, we demonstrate that the proposed approach achieves state-of-the-art performance in all tasks, outperforming LSTM models and classical baselines with hand-engineered features.},
	number = {1},
	urldate = {2023-09-29},
	journal = {Proceedings of the AAAI Conference on Artificial Intelligence},
	author = {Song, Huan and Rajan, Deepta and Thiagarajan, Jayaraman and Spanias, Andreas},
	month = apr,
	year = {2018},
	keywords = {notion},
}

@article{meng_brltm_2021,
	title = {{BRLTM}: {Bidirectional} {Representation} {Learning} {From} {Transformers} {Using} {Multimodal} {Electronic} {Health} {Record} {Data} to {Predict} {Depression}},
	volume = {25},
	issn = {2168-2194, 2168-2208},
	url = {https://ieeexplore.ieee.org/document/9369833/},
	doi = {10.1109/JBHI.2021.3063721},
	abstract = {Advancements in machine learning algorithms have had a beneficial impact on representation learning, classification, and prediction models built using electronic health record (EHR) data. Effort has been put both on increasing models’ overall performance as well as improving their interpretability, particularly regarding the decision-making process. In this study, we present a temporal deep learning model to perform bidirectional representation learning on EHR sequences with a transformer architecture to predict future diagnosis of depression. This model is able to aggregate five heterogenous and high-dimensional data sources from the EHR and process them in a temporal manner for chronic disease prediction at various prediction windows. We applied the current trend of pretraining and fine-tuning on EHR data to outperform the current state-ofthe-art in chronic disease prediction, and to demonstrate the underlying relation between EHR codes in the sequence. The model generated the highest increases of precision-recall area under the curve (PRAUC) from 0.70 to 0.76 in depression prediction compared to the best baseline model. Furthermore, the self-attention weights in each sequence quantitatively demonstrated the inner relationship between various codes, which improved the model’s interpretability. These results demonstrate the model’s ability to utilize heterogeneous EHR data to predict depression while achieving high accuracy and interpretability, which may facilitate constructing clinical decision support systems in the future for chronic disease screening and early detection.},
	language = {en},
	number = {8},
	urldate = {2023-12-13},
	journal = {IEEE Journal of Biomedical and Health Informatics},
	author = {Meng, Yiwen and Speier, William and Ong, Michael K. and Arnold, Corey W.},
	month = aug,
	year = {2021},
	keywords = {notion},
	pages = {3121--3129},
}

@article{savcisens_life2vec_2023,
	title = {life2vec: {Using} {Sequences} of {Life}-events to {Predict} {Human} {Lives}},
	issn = {2662-8457},
	url = {http://arxiv.org/abs/2306.03009},
	doi = {10.1038/s43588-023-00573-5},
	abstract = {Over the past decade, machine learning has revolutionized computers' ability to analyze text through flexible computational models. Due to their structural similarity to written language, transformer-based architectures have also shown promise as tools to make sense of a range of multi-variate sequences from protein-structures, music, electronic health records to weather-forecasts. We can also represent human lives in a way that shares this structural similarity to language. From one perspective, lives are simply sequences of events: People are born, visit the pediatrician, start school, move to a new location, get married, and so on. Here, we exploit this similarity to adapt innovations from natural language processing to examine the evolution and predictability of human lives based on detailed event sequences. We do this by drawing on arguably the most comprehensive registry data in existence, available for an entire nation of more than six million individuals across decades. Our data include information about life-events related to health, education, occupation, income, address, and working hours, recorded with day-to-day resolution. We create embeddings of life-events in a single vector space showing that this embedding space is robust and highly structured. Our models allow us to predict diverse outcomes ranging from early mortality to personality nuances, outperforming state-of-the-art models by a wide margin. Using methods for interpreting deep learning models, we probe the algorithm to understand the factors that enable our predictions. Our framework allows researchers to identify new potential mechanisms that impact life outcomes and associated possibilities for personalized interventions.},
	urldate = {2024-01-08},
	journal = {Nature Computational Science},
	author = {Savcisens, Germans and Eliassi-Rad, Tina and Hansen, Lars Kai and Mortensen, Laust and Lilleholt, Lau and Rogers, Anna and Zettler, Ingo and Lehmann, Sune},
	month = dec,
	year = {2023},
	note = {arXiv:2306.03009 [cs, stat]},
	keywords = {Computer Science - Machine Learning, Statistics - Applications, Statistics - Machine Learning, notion},
}

@misc{zhou_survey_2023,
	title = {A {Survey} of {Large} {Language} {Models} in {Medicine}: {Principles}, {Applications}, and {Challenges}},
	shorttitle = {A {Survey} of {Large} {Language} {Models} in {Medicine}},
	url = {http://arxiv.org/abs/2311.05112},
	doi = {10.48550/arXiv.2311.05112},
	abstract = {Large language models (LLMs), such as ChatGPT, have received substantial attention due to their impressive human language understanding and generation capabilities. Therefore, the application of LLMs in medicine to assist physicians and patient care emerges as a promising research direction in both artificial intelligence and clinical medicine. To reflect this trend, this survey provides a comprehensive overview of the principles, applications, and challenges faced by LLMs in medicine. Specifically, we aim to address the following questions: 1) How can medical LLMs be built? 2) What are the downstream performances of medical LLMs? 3) How can medical LLMs be utilized in real-world clinical practice? 4) What challenges arise from the use of medical LLMs? and 5) How can we better construct and utilize medical LLMs? As a result, this survey aims to provide insights into the opportunities and challenges of LLMs in medicine and serve as a valuable resource for constructing practical and effective medical LLMs. A regularly updated list of practical guides on medical LLMs can be found at https://github.com/AI-in-Health/MedLLMsPracticalGuide.},
	urldate = {2024-01-08},
	publisher = {arXiv},
	author = {Zhou, Hongjian and Liu, Fenglin and Gu, Boyang and Zou, Xinyu and Huang, Jinfa and Wu, Jinge and Li, Yiru and Chen, Sam S. and Zhou, Peilin and Liu, Junling and Hua, Yining and Mao, Chengfeng and Wu, Xian and Zheng, Yefeng and Clifton, Lei and Li, Zheng and Luo, Jiebo and Clifton, David A.},
	month = dec,
	year = {2023},
	note = {arXiv:2311.05112 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language, notion},
}

@article{lee_biobert_2020,
	title = {{BioBERT}: a pre-trained biomedical language representation model for biomedical text mining},
	volume = {36},
	issn = {1367-4803},
	shorttitle = {{BioBERT}},
	url = {https://doi.org/10.1093/bioinformatics/btz682},
	doi = {10.1093/bioinformatics/btz682},
	abstract = {Biomedical text mining is becoming increasingly important as the number of biomedical documents rapidly grows. With the progress in natural language processing (NLP), extracting valuable information from biomedical literature has gained popularity among researchers, and deep learning has boosted the development of effective biomedical text mining models. However, directly applying the advancements in NLP to biomedical text mining often yields unsatisfactory results due to a word distribution shift from general domain corpora to biomedical corpora. In this article, we investigate how the recently introduced pre-trained language model BERT can be adapted for biomedical corpora.We introduce BioBERT (Bidirectional Encoder Representations from Transformers for Biomedical Text Mining), which is a domain-specific language representation model pre-trained on large-scale biomedical corpora. With almost the same architecture across tasks, BioBERT largely outperforms BERT and previous state-of-the-art models in a variety of biomedical text mining tasks when pre-trained on biomedical corpora. While BERT obtains performance comparable to that of previous state-of-the-art models, BioBERT significantly outperforms them on the following three representative biomedical text mining tasks: biomedical named entity recognition (0.62\% F1 score improvement), biomedical relation extraction (2.80\% F1 score improvement) and biomedical question answering (12.24\% MRR improvement). Our analysis results show that pre-training BERT on biomedical corpora helps it to understand complex biomedical texts.We make the pre-trained weights of BioBERT freely available at https://github.com/naver/biobert-pretrained, and the source code for fine-tuning BioBERT available at https://github.com/dmis-lab/biobert.},
	number = {4},
	urldate = {2024-01-08},
	journal = {Bioinformatics},
	author = {Lee, Jinhyuk and Yoon, Wonjin and Kim, Sungdong and Kim, Donghyeon and Kim, Sunkyu and So, Chan Ho and Kang, Jaewoo},
	month = feb,
	year = {2020},
	keywords = {notion},
	pages = {1234--1240},
}

@misc{he_survey_2023,
	title = {A {Survey} of {Large} {Language} {Models} for {Healthcare}: from {Data}, {Technology}, and {Applications} to {Accountability} and {Ethics}},
	shorttitle = {A {Survey} of {Large} {Language} {Models} for {Healthcare}},
	url = {http://arxiv.org/abs/2310.05694},
	doi = {10.48550/arXiv.2310.05694},
	abstract = {The utilization of large language models (LLMs) in the Healthcare domain has generated both excitement and concern due to their ability to effectively respond to freetext queries with certain professional knowledge. This survey outlines the capabilities of the currently developed LLMs for Healthcare and explicates their development process, with the aim of providing an overview of the development roadmap from traditional Pretrained Language Models (PLMs) to LLMs. Specifically, we first explore the potential of LLMs to enhance the efficiency and effectiveness of various Healthcare applications highlighting both the strengths and limitations. Secondly, we conduct a comparison between the previous PLMs and the latest LLMs, as well as comparing various LLMs with each other. Then we summarize related Healthcare training data, training methods, optimization strategies, and usage. Finally, the unique concerns associated with deploying LLMs in Healthcare settings are investigated, particularly regarding fairness, accountability, transparency and ethics. Our survey provide a comprehensive investigation from perspectives of both computer science and Healthcare specialty. Besides the discussion about Healthcare concerns, we supports the computer science community by compiling a collection of open source resources, such as accessible datasets, the latest methodologies, code implementations, and evaluation benchmarks in the Github. Summarily, we contend that a significant paradigm shift is underway, transitioning from PLMs to LLMs. This shift encompasses a move from discriminative AI approaches to generative AI approaches, as well as a shift from model-centered methodologies to datacentered methodologies.},
	urldate = {2024-01-08},
	publisher = {arXiv},
	author = {He, Kai and Mao, Rui and Lin, Qika and Ruan, Yucheng and Lan, Xiang and Feng, Mengling and Cambria, Erik},
	month = oct,
	year = {2023},
	note = {arXiv:2310.05694 [cs]},
	keywords = {Computer Science - Computation and Language, notion},
}

@article{peng_study_2023,
	title = {A study of generative large language model for medical research and healthcare},
	volume = {6},
	copyright = {2023 The Author(s)},
	issn = {2398-6352},
	url = {https://www.nature.com/articles/s41746-023-00958-w},
	doi = {10.1038/s41746-023-00958-w},
	abstract = {There are enormous enthusiasm and concerns in applying large language models (LLMs) to healthcare. Yet current assumptions are based on general-purpose LLMs such as ChatGPT, which are not developed for medical use. This study develops a generative clinical LLM, GatorTronGPT, using 277 billion words of text including (1) 82 billion words of clinical text from 126 clinical departments and approximately 2 million patients at the University of Florida Health and (2) 195 billion words of diverse general English text. We train GatorTronGPT using a GPT-3 architecture with up to 20 billion parameters and evaluate its utility for biomedical natural language processing (NLP) and healthcare text generation. GatorTronGPT improves biomedical natural language processing. We apply GatorTronGPT to generate 20 billion words of synthetic text. Synthetic NLP models trained using synthetic text generated by GatorTronGPT outperform models trained using real-world clinical text. Physicians’ Turing test using 1 (worst) to 9 (best) scale shows that there are no significant differences in linguistic readability (p = 0.22; 6.57 of GatorTronGPT compared with 6.93 of human) and clinical relevance (p = 0.91; 7.0 of GatorTronGPT compared with 6.97 of human) and that physicians cannot differentiate them (p {\textless} 0.001). This study provides insights into the opportunities and challenges of LLMs for medical research and healthcare.},
	language = {en},
	number = {1},
	urldate = {2024-01-04},
	journal = {npj Digital Medicine},
	author = {Peng, Cheng and Yang, Xi and Chen, Aokun and Smith, Kaleb E. and PourNejatian, Nima and Costa, Anthony B. and Martin, Cheryl and Flores, Mona G. and Zhang, Ying and Magoc, Tanja and Lipori, Gloria and Mitchell, Duane A. and Ospina, Naykky S. and Ahmed, Mustafa M. and Hogan, William R. and Shenkman, Elizabeth A. and Guo, Yi and Bian, Jiang and Wu, Yonghui},
	month = nov,
	year = {2023},
	note = {Number: 1
Publisher: Nature Publishing Group},
	keywords = {Health care, Translational research, notion},
	pages = {1--10},
}

@article{thoral_sharing_2021,
	title = {Sharing {ICU} {Patient} {Data} {Responsibly} {Under} the {Society} of {Critical} {Care} {Medicine}/{European} {Society} of {Intensive} {Care} {Medicine} {Joint} {Data} {Science} {Collaboration}: {The} {Amsterdam} {University} {Medical} {Centers} {Database} ({AmsterdamUMCdb}) {Example}*},
	volume = {49},
	issn = {0090=3493},
	shorttitle = {Sharing {ICU} {Patient} {Data} {Responsibly} {Under} the {Society} of {Critical} {Care} {Medicine}/{European} {Society} of {Intensive} {Care} {Medicine} {Joint} {Data} {Science} {Collaboration}},
	url = {https://journals.lww.com/ccmjournal/fulltext/2021/06000/sharing_icu_patient_data_responsibly_under_the.16.aspx},
	doi = {10.1097/CCM.0000000000004916},
	abstract = {OBJECTIVES: 
          Critical care medicine is a natural environment for machine learning approaches to improve outcomes for critically ill patients as admissions to ICUs generate vast amounts of data. However, technical, legal, ethical, and privacy concerns have so far limited the critical care medicine community from making these data readily available. The Society of Critical Care Medicine and the European Society of Intensive Care Medicine have identified ICU patient data sharing as one of the priorities under their Joint Data Science Collaboration. To encourage ICUs worldwide to share their patient data responsibly, we now describe the development and release of Amsterdam University Medical Centers Database (AmsterdamUMCdb), the first freely available critical care database in full compliance with privacy laws from both the United States and Europe, as an example of the feasibility of sharing complex critical care data.
          SETTING: 
          University hospital ICU.
          SUBJECTS: 
          Data from ICU patients admitted between 2003 and 2016.
          INTERVENTIONS: 
          We used a risk-based deidentification strategy to maintain data utility while preserving privacy. In addition, we implemented contractual and governance processes, and a communication strategy. Patient organizations, supporting hospitals, and experts on ethics and privacy audited these processes and the database.
          MEASUREMENTS AND MAIN RESULTS: 
          AmsterdamUMCdb contains approximately 1 billion clinical data points from 23,106 admissions of 20,109 patients. The privacy audit concluded that reidentification is not reasonably likely, and AmsterdamUMCdb can therefore be considered as anonymous information, both in the context of the U.S. Health Insurance Portability and Accountability Act and the European General Data Protection Regulation. The ethics audit concluded that responsible data sharing imposes minimal burden, whereas the potential benefit is tremendous.
          CONCLUSIONS: 
          Technical, legal, ethical, and privacy challenges related to responsible data sharing can be addressed using a multidisciplinary approach. A risk-based deidentification strategy, that complies with both U.S. and European privacy regulations, should be the preferred approach to releasing ICU patient data. This supports the shared Society of Critical Care Medicine and European Society of Intensive Care Medicine vision to improve critical care outcomes through scientific inquiry of vast and combined ICU datasets.},
	language = {en-US},
	number = {6},
	urldate = {2023-12-21},
	journal = {Critical Care Medicine},
	author = {Thoral, Patrick J. and Peppink, Jan M. and Driessen, Ronald H. and Sijbrands, Eric J. G. and Kompanje, Erwin J. O. and Kaplan, Lewis and Bailey, Heatherlee and Kesecioglu, Jozef and Cecconi, Maurizio and Churpek, Matthew and Clermont, Gilles and van der Schaar, Mihaela and Ercole, Ari and Girbes, Armand R. J. and Elbers, Paul W. G.},
	month = jun,
	year = {2021},
	pages = {e563},
}

@misc{yeche_hirid-icu-benchmark_2022,
	title = {{HiRID}-{ICU}-{Benchmark} -- {A} {Comprehensive} {Machine} {Learning} {Benchmark} on {High}-resolution {ICU} {Data}},
	url = {http://arxiv.org/abs/2111.08536},
	abstract = {The recent success of machine learning methods applied to time series collected from Intensive Care Units (ICU) exposes the lack of standardized machine learning benchmarks for developing and comparing such methods. While raw datasets, such as MIMIC-IV or eICU, can be freely accessed on Physionet, the choice of tasks and pre-processing is often chosen ad-hoc for each publication, limiting comparability across publications. In this work, we aim to improve this situation by providing a benchmark covering a large spectrum of ICU-related tasks. Using the HiRID dataset, we define multiple clinically relevant tasks in collaboration with clinicians. In addition, we provide a reproducible end-to-end pipeline to construct both data and labels. Finally, we provide an in-depth analysis of current state-of-the-art sequence modeling methods, highlighting some limitations of deep learning approaches for this type of data. With this benchmark, we hope to give the research community the possibility of a fair comparison of their work.},
	urldate = {2023-12-21},
	publisher = {arXiv},
	author = {Yèche, Hugo and Kuznetsova, Rita and Zimmermann, Marc and Hüser, Matthias and Lyu, Xinrui and Faltys, Martin and Rätsch, Gunnar},
	month = jan,
	year = {2022},
	note = {arXiv:2111.08536 [cs]},
	keywords = {Computer Science - Machine Learning},
}

@article{lentzen_exmed-bert_2023,
	title = {{ExMed}-{BERT}: {A} {Transformer}-{Based} {Model} {Trained} on {Large} {Scale} {Claims} {Data} for {Prediction} of {Severe} {COVID}-19 {Disease} {Progression}},
	volume = {27},
	issn = {2168-2194, 2168-2208},
	url = {https://ieeexplore.ieee.org/document/10159467/},
	doi = {10.1109/JBHI.2023.3288768},
	number = {9},
	urldate = {2023-09-14},
	journal = {IEEE Journal of Biomedical and Health Informatics},
	author = {Lentzen, Manuel and Linden, Thomas and Veeranki, Sai and Madan, Sumit and Kramer, Diether and Leodolter, Werner and Fröhlich, Holger},
	month = sep,
	year = {2023},
	keywords = {notion},
	pages = {4548--4558},
}

@misc{devlin_bert_2019,
	title = {{BERT}: {Pre}-training of {Deep} {Bidirectional} {Transformers} for {Language} {Understanding}},
	shorttitle = {{BERT}},
	url = {http://arxiv.org/abs/1810.04805},
	abstract = {We introduce a new language representation model called BERT, which stands for Bidirectional Encoder Representations from Transformers. Unlike recent language representation models, BERT is designed to pre-train deep bidirectional representations from unlabeled text by jointly conditioning on both left and right context in all layers. As a result, the pre-trained BERT model can be fine-tuned with just one additional output layer to create state-of-the-art models for a wide range of tasks, such as question answering and language inference, without substantial task-specific architecture modifications. BERT is conceptually simple and empirically powerful. It obtains new state-of-the-art results on eleven natural language processing tasks, including pushing the GLUE score to 80.5\% (7.7\% point absolute improvement), MultiNLI accuracy to 86.7\% (4.6\% absolute improvement), SQuAD v1.1 question answering Test F1 to 93.2 (1.5 point absolute improvement) and SQuAD v2.0 Test F1 to 83.1 (5.1 point absolute improvement).},
	urldate = {2023-12-13},
	publisher = {arXiv},
	author = {Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
	month = may,
	year = {2019},
	note = {arXiv:1810.04805 [cs]},
	keywords = {Computer Science - Computation and Language, notion},
}

@inproceedings{ren_generative_2022,
	address = {Washington DC USA},
	title = {Generative {Adversarial} {Networks} {Enhanced} {Pre}-training for {Insufficient} {Electronic} {Health} {Records} {Modeling}},
	isbn = {978-1-4503-9385-0},
	url = {https://dl.acm.org/doi/10.1145/3534678.3539020},
	doi = {10.1145/3534678.3539020},
	language = {en},
	urldate = {2023-12-13},
	booktitle = {Proceedings of the 28th {ACM} {SIGKDD} {Conference} on {Knowledge} {Discovery} and {Data} {Mining}},
	publisher = {ACM},
	author = {Ren, Houxing and Wang, Jingyuan and Zhao, Wayne Xin},
	month = aug,
	year = {2022},
	keywords = {notion},
	pages = {3810--3818},
}

@misc{shoham_cpllm_2023,
	title = {{CPLLM}: {Clinical} {Prediction} with {Large} {Language} {Models}},
	shorttitle = {{CPLLM}},
	url = {http://arxiv.org/abs/2309.11295},
	doi = {10.48550/arXiv.2309.11295},
	abstract = {We present Clinical Prediction with Large Language Models (CPLLM), a method that involves fine-tuning a pre-trained Large Language Model (LLM) for clinical disease prediction. We utilized quantization and fine-tuned the LLM using prompts, with the task of predicting whether patients will be diagnosed with a target disease during their next visit or in the subsequent diagnosis, leveraging their historical diagnosis records. We compared our results versus various baselines, including Logistic Regression, RETAIN, and Med-BERT, which is the current state-of-the-art model for disease prediction using structured EHR data. Our experiments have shown that CPLLM surpasses all the tested models in terms of both PR-AUC and ROC-AUC metrics, displaying noteworthy enhancements compared to the baseline models.},
	urldate = {2023-12-13},
	publisher = {arXiv},
	author = {Shoham, Ofir Ben and Rappoport, Nadav},
	month = sep,
	year = {2023},
	note = {arXiv:2309.11295 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language, Computer Science - Machine Learning, notion},
}

@article{tang_democratizing_2020,
	title = {Democratizing {EHR} analyses with {FIDDLE}: a flexible data-driven preprocessing pipeline for structured clinical data},
	volume = {27},
	issn = {1527-974X},
	shorttitle = {Democratizing {EHR} analyses with {FIDDLE}},
	url = {https://doi.org/10.1093/jamia/ocaa139},
	doi = {10.1093/jamia/ocaa139},
	abstract = {In applying machine learning (ML) to electronic health record (EHR) data, many decisions must be made before any ML is applied; such preprocessing requires substantial effort and can be labor-intensive. As the role of ML in health care grows, there is an increasing need for systematic and reproducible preprocessing techniques for EHR data. Thus, we developed FIDDLE (Flexible Data-Driven Pipeline), an open-source framework that streamlines the preprocessing of data extracted from the EHR.Largely data-driven, FIDDLE systematically transforms structured EHR data into feature vectors, limiting the number of decisions a user must make while incorporating good practices from the literature. To demonstrate its utility and flexibility, we conducted a proof-of-concept experiment in which we applied FIDDLE to 2 publicly available EHR data sets collected from intensive care units: MIMIC-III and the eICU Collaborative Research Database. We trained different ML models to predict 3 clinically important outcomes: in-hospital mortality, acute respiratory failure, and shock. We evaluated models using the area under the receiver operating characteristics curve (AUROC), and compared it to several baselines.Across tasks, FIDDLE extracted 2,528 to 7,403 features from MIMIC-III and eICU, respectively. On all tasks, FIDDLE-based models achieved good discriminative performance, with AUROCs of 0.757–0.886, comparable to the performance of MIMIC-Extract, a preprocessing pipeline designed specifically for MIMIC-III. Furthermore, our results showed that FIDDLE is generalizable across different prediction times, ML algorithms, and data sets, while being relatively robust to different settings of user-defined arguments.FIDDLE, an open-source preprocessing pipeline, facilitates applying ML to structured EHR data. By accelerating and standardizing labor-intensive preprocessing, FIDDLE can help stimulate progress in building clinically useful ML tools for EHR data.},
	number = {12},
	urldate = {2023-12-13},
	journal = {Journal of the American Medical Informatics Association},
	author = {Tang, Shengpu and Davarmanesh, Parmida and Song, Yanmeng and Koutra, Danai and Sjoding, Michael W and Wiens, Jenna},
	month = dec,
	year = {2020},
	keywords = {notion},
	pages = {1921--1934},
}

@misc{nerella_transformers_2023,
	title = {Transformers in {Healthcare}: {A} {Survey}},
	shorttitle = {Transformers in {Healthcare}},
	url = {http://arxiv.org/abs/2307.00067},
	doi = {10.48550/arXiv.2307.00067},
	abstract = {With Artificial Intelligence (AI) increasingly permeating various aspects of society, including healthcare, the adoption of the Transformers neural network architecture is rapidly changing many applications. Transformer is a type of deep learning architecture initially developed to solve general-purpose Natural Language Processing (NLP) tasks and has subsequently been adapted in many fields, including healthcare. In this survey paper, we provide an overview of how this architecture has been adopted to analyze various forms of data, including medical imaging, structured and unstructured Electronic Health Records (EHR), social media, physiological signals, and biomolecular sequences. Those models could help in clinical diagnosis, report generation, data reconstruction, and drug/protein synthesis. We identified relevant studies using the Preferred Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA) guidelines. We also discuss the benefits and limitations of using transformers in healthcare and examine issues such as computational cost, model interpretability, fairness, alignment with human values, ethical implications, and environmental impact.},
	urldate = {2023-12-13},
	publisher = {arXiv},
	author = {Nerella, Subhash and Bandyopadhyay, Sabyasachi and Zhang, Jiaqing and Contreras, Miguel and Siegel, Scott and Bumin, Aysegul and Silva, Brandon and Sena, Jessica and Shickel, Benjamin and Bihorac, Azra and Khezeli, Kia and Rashidi, Parisa},
	month = jun,
	year = {2023},
	note = {arXiv:2307.00067 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computers and Society, Computer Science - Machine Learning, notion},
}

@misc{beltagy_longformer_2020,
	title = {Longformer: {The} {Long}-{Document} {Transformer}},
	shorttitle = {Longformer},
	url = {http://arxiv.org/abs/2004.05150},
	doi = {10.48550/arXiv.2004.05150},
	abstract = {Transformer-based models are unable to process long sequences due to their self-attention operation, which scales quadratically with the sequence length. To address this limitation, we introduce the Longformer with an attention mechanism that scales linearly with sequence length, making it easy to process documents of thousands of tokens or longer. Longformer's attention mechanism is a drop-in replacement for the standard self-attention and combines a local windowed attention with a task motivated global attention. Following prior work on long-sequence transformers, we evaluate Longformer on character-level language modeling and achieve state-of-the-art results on text8 and enwik8. In contrast to most prior work, we also pretrain Longformer and finetune it on a variety of downstream tasks. Our pretrained Longformer consistently outperforms RoBERTa on long document tasks and sets new state-of-the-art results on WikiHop and TriviaQA. We finally introduce the Longformer-Encoder-Decoder (LED), a Longformer variant for supporting long document generative sequence-to-sequence tasks, and demonstrate its effectiveness on the arXiv summarization dataset.},
	urldate = {2023-12-13},
	publisher = {arXiv},
	author = {Beltagy, Iz and Peters, Matthew E. and Cohan, Arman},
	month = dec,
	year = {2020},
	note = {arXiv:2004.05150 [cs]},
	keywords = {Computer Science - Computation and Language, notion},
}

@inproceedings{pappagari_hierarchical_2019,
	title = {Hierarchical {Transformers} for {Long} {Document} {Classification}},
	url = {https://ieeexplore.ieee.org/document/9003958},
	doi = {10.1109/ASRU46091.2019.9003958},
	abstract = {BERT, which stands for Bidirectional Encoder Representations from Transformers, is a recently introduced language representation model based upon the transfer learning paradigm. We extend its fine-tuning procedure to address one of its major limitations - applicability to inputs longer than a few hundred words, such as transcripts of human call conversations. Our method is conceptually simple. We segment the input into smaller chunks and feed each of them into the base model. Then, we propagate each output through a single recurrent layer, or another transformer, followed by a softmax activation. We obtain the final classification decision after the last segment has been consumed. We show that both BERT extensions are quick to fine-tune and converge after as little as 1 epoch of training on a small, domain-specific data set. We successfully apply them in three different tasks involving customer call satisfaction prediction and topic classification, and obtain a significant improvement over the baseline models in two of them.},
	urldate = {2023-12-13},
	booktitle = {2019 {IEEE} {Automatic} {Speech} {Recognition} and {Understanding} {Workshop} ({ASRU})},
	author = {Pappagari, Raghavendra and Zelasko, Piotr and Villalba, Jesús and Carmiel, Yishay and Dehak, Najim},
	month = dec,
	year = {2019},
	keywords = {notion},
	pages = {838--844},
}

@incollection{rupp_exbehrt_2023,
	title = {{ExBEHRT}: {Extended} {Transformer} for {Electronic} {Health} {Records} to {Predict} {Disease} {Subtypes} \& {Progressions}},
	volume = {13932},
	shorttitle = {{ExBEHRT}},
	url = {http://arxiv.org/abs/2303.12364},
	abstract = {In this study, we introduce ExBEHRT, an extended version of BEHRT (BERT applied to electronic health records), and apply different algorithms to interpret its results. While BEHRT considers only diagnoses and patient age, we extend the feature space to several multimodal records, namely demographics, clinical characteristics, vital signs, smoking status, diagnoses, procedures, medications, and laboratory tests, by applying a novel method to unify the frequencies and temporal dimensions of the different features. We show that additional features significantly improve model performance for various downstream tasks in different diseases. To ensure robustness, we interpret model predictions using an adaptation of expected gradients, which has not been previously applied to transformers with EHR data and provides more granular interpretations than previous approaches such as feature and token importances. Furthermore, by clustering the model representations of oncology patients, we show that the model has an implicit understanding of the disease and is able to classify patients with the same cancer type into different risk groups. Given the additional features and interpretability, ExBEHRT can help make informed decisions about disease trajectories, diagnoses, and risk factors of various diseases.},
	urldate = {2023-12-13},
	author = {Rupp, Maurice and Peter, Oriane and Pattipaka, Thirupathi},
	year = {2023},
	doi = {10.1007/978-3-031-39539-0_7},
	note = {arXiv:2303.12364 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning, notion},
	pages = {73--84},
}

@article{nguyen_deepr_2017,
	title = {Deepr: {A} {Convolutional} {Net} for {Medical} {Records}},
	volume = {21},
	issn = {2168-2208},
	shorttitle = {{\textbackslash}mathtt {Deepr}},
	url = {https://ieeexplore.ieee.org/abstract/document/7762861},
	doi = {10.1109/JBHI.2016.2633963},
	abstract = {Feature engineering remains a major bottleneck when creating predictive systems from electronic medical records. At present, an important missing element is detecting predictive regular clinical motifs from irregular episodic records. We present Deepr (short for Deep record), a new end-to-end deep learning system that learns to extract features from medical records and predicts future risk automatically. Deepr transforms a record into a sequence of discrete elements separated by coded time gaps and hospital transfers. On top of the sequence is a convolutional neural net that detects and combines predictive local clinical motifs to stratify the risk. Deepr permits transparent inspection and visualization of its inner working. We validate Deepr on hospital data to predict unplanned readmission after discharge. Deepr achieves superior accuracy compared to traditional techniques, detects meaningful clinical motifs, and uncovers the underlying structure of the disease and intervention space.},
	number = {1},
	urldate = {2023-11-14},
	journal = {IEEE Journal of Biomedical and Health Informatics},
	author = {Nguyen, Phuoc and Tran, Truyen and Wickramasinghe, Nilmini and Venkatesh, Svetha},
	month = jan,
	year = {2017},
	note = {Conference Name: IEEE Journal of Biomedical and Health Informatics},
	keywords = {notion},
	pages = {22--30},
}

@article{rao_explainable_2022,
	title = {An {Explainable} {Transformer}-{Based} {Deep} {Learning} {Model} for the {Prediction} of {Incident} {Heart} {Failure}},
	volume = {26},
	issn = {2168-2194, 2168-2208},
	url = {https://ieeexplore.ieee.org/document/9706318/},
	doi = {10.1109/JBHI.2022.3148820},
	number = {7},
	urldate = {2023-12-12},
	journal = {IEEE Journal of Biomedical and Health Informatics},
	author = {Rao, Shishir and Li, Yikuan and Ramakrishnan, Rema and Hassaine, Abdelaali and Canoy, Dexter and Cleland, John and Lukasiewicz, Thomas and Salimi-Khorshidi, Gholamreza and Rahimi, Kazem},
	month = jul,
	year = {2022},
	keywords = {notion},
	pages = {3362--3372},
}

@article{li_validation_2022,
	title = {Validation of risk prediction models applied to longitudinal electronic health record data for the prediction of major cardiovascular events in the presence of data shifts},
	volume = {3},
	issn = {2634-3916},
	url = {https://academic.oup.com/ehjdh/article/3/4/535/6765054},
	doi = {10.1093/ehjdh/ztac061},
	abstract = {Abstract
            
              Aims
              Deep learning has dominated predictive modelling across different fields, but in medicine it has been met with mixed reception. In clinical practice, simple, statistical models and risk scores continue to inform cardiovascular disease risk predictions. This is due in part to the knowledge gap about how deep learning models perform in practice when they are subject to dynamic data shifts; a key criterion that common internal validation procedures do not address. We evaluated the performance of a novel deep learning model, BEHRT, under data shifts and compared it with several ML-based and established risk models.
            
            
              Methods and results
              Using linked electronic health records of 1.1 million patients across England aged at least 35 years between 1985 and 2015, we replicated three established statistical models for predicting 5-year risk of incident heart failure, stroke, and coronary heart disease. The results were compared with a widely accepted machine learning model (random forests), and a novel deep learning model (BEHRT). In addition to internal validation, we investigated how data shifts affect model discrimination and calibration. To this end, we tested the models on cohorts from (i) distinct geographical regions; (ii) different periods. Using internal validation, the deep learning models substantially outperformed the best statistical models by 6\%, 8\%, and 11\% in heart failure, stroke, and coronary heart disease, respectively, in terms of the area under the receiver operating characteristic curve.
            
            
              Conclusion
              The performance of all models declined as a result of data shifts; despite this, the deep learning models maintained the best performance in all risk prediction tasks. Updating the model with the latest information can improve discrimination but if the prior distribution changes, the model may remain miscalibrated.},
	language = {en},
	number = {4},
	urldate = {2023-12-12},
	journal = {European Heart Journal - Digital Health},
	author = {Li, Yikuan and Salimi-Khorshidi, Gholamreza and Rao, Shishir and Canoy, Dexter and Hassaine, Abdelaali and Lukasiewicz, Thomas and Rahimi, Kazem and Mamouei, Mohammad},
	month = dec,
	year = {2022},
	keywords = {notion},
	pages = {535--547},
}

@misc{han_medical_2023,
	title = {Medical {Foundation} {Models} are {Susceptible} to {Targeted} {Misinformation} {Attacks}},
	url = {http://arxiv.org/abs/2309.17007},
	abstract = {Large language models (LLMs) have broad medical knowledge and can reason about medical information across many domains, holding promising potential for diverse medical applications in the near future. In this study, we demonstrate a concerning vulnerability of LLMs in medicine. Through targeted manipulation of just 1.1\% of the model's weights, we can deliberately inject an incorrect biomedical fact. The erroneous information is then propagated in the model's output, whilst its performance on other biomedical tasks remains intact. We validate our findings in a set of 1,038 incorrect biomedical facts. This peculiar susceptibility raises serious security and trustworthiness concerns for the application of LLMs in healthcare settings. It accentuates the need for robust protective measures, thorough verification mechanisms, and stringent management of access to these models, ensuring their reliable and safe use in medical practice.},
	urldate = {2023-12-07},
	publisher = {arXiv},
	author = {Han, Tianyu and Nebelung, Sven and Khader, Firas and Wang, Tianci and Mueller-Franzes, Gustav and Kuhl, Christiane and Försch, Sebastian and Kleesiek, Jens and Haarburger, Christoph and Bressem, Keno K. and Kather, Jakob Nikolas and Truhn, Daniel},
	month = sep,
	year = {2023},
	note = {arXiv:2309.17007 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computers and Society, Computer Science - Machine Learning, notion},
}

@article{qiu_large_2023,
	title = {Large {AI} {Models} in {Health} {Informatics}: {Applications}, {Challenges}, and the {Future}},
	volume = {27},
	issn = {2168-2194, 2168-2208},
	shorttitle = {Large {AI} {Models} in {Health} {Informatics}},
	url = {https://ieeexplore.ieee.org/document/10261199/},
	doi = {10.1109/JBHI.2023.3316750},
	number = {12},
	urldate = {2023-12-07},
	journal = {IEEE Journal of Biomedical and Health Informatics},
	author = {Qiu, Jianing and Li, Lin and Sun, Jiankai and Peng, Jiachuan and Shi, Peilun and Zhang, Ruiyang and Dong, Yinzhao and Lam, Kyle and Lo, Frank P.-W. and Xiao, Bo and Yuan, Wu and Wang, Ningli and Xu, Dong and Lo, Benny},
	month = dec,
	year = {2023},
	keywords = {notion},
	pages = {6074--6087},
}

@article{clusmann_future_2023,
	title = {The future landscape of large language models in medicine},
	volume = {3},
	issn = {2730-664X},
	url = {https://www.nature.com/articles/s43856-023-00370-1},
	doi = {10.1038/s43856-023-00370-1},
	abstract = {Abstract
            Large language models (LLMs) are artificial intelligence (AI) tools specifically trained to process and generate text. LLMs attracted substantial public attention after OpenAI’s ChatGPT was made publicly available in November 2022. LLMs can often answer questions, summarize, paraphrase and translate text on a level that is nearly indistinguishable from human capabilities. The possibility to actively interact with models like ChatGPT makes LLMs attractive tools in various fields, including medicine. While these models have the potential to democratize medical knowledge and facilitate access to healthcare, they could equally distribute misinformation and exacerbate scientific misconduct due to a lack of accountability and transparency. In this article, we provide a systematic and comprehensive overview of the potentials and limitations of LLMs in clinical practice, medical research and medical education.},
	language = {en},
	number = {1},
	urldate = {2023-12-07},
	journal = {Communications Medicine},
	author = {Clusmann, Jan and Kolbinger, Fiona R. and Muti, Hannah Sophie and Carrero, Zunamys I. and Eckardt, Jan-Niklas and Laleh, Narmin Ghaffari and Löffler, Chiara Maria Lavinia and Schwarzkopf, Sophie-Caroline and Unger, Michaela and Veldhuizen, Gregory P. and Wagner, Sophia J. and Kather, Jakob Nikolas},
	month = oct,
	year = {2023},
	keywords = {notion},
	pages = {141},
}

@article{wornow_shaky_2023,
	title = {The shaky foundations of large language models and foundation models for electronic health records},
	volume = {6},
	issn = {2398-6352},
	url = {https://www.nature.com/articles/s41746-023-00879-8},
	doi = {10.1038/s41746-023-00879-8},
	abstract = {Abstract
            The success of foundation models such as ChatGPT and AlphaFold has spurred significant interest in building similar models for electronic medical records (EMRs) to improve patient care and hospital operations. However, recent hype has obscured critical gaps in our understanding of these models’ capabilities. In this narrative review, we examine 84 foundation models trained on non-imaging EMR data (i.e., clinical text and/or structured data) and create a taxonomy delineating their architectures, training data, and potential use cases. We find that most models are trained on small, narrowly-scoped clinical datasets (e.g., MIMIC-III) or broad, public biomedical corpora (e.g., PubMed) and are evaluated on tasks that do not provide meaningful insights on their usefulness to health systems. Considering these findings, we propose an improved evaluation framework for measuring the benefits of clinical foundation models that is more closely grounded to metrics that matter in healthcare.},
	language = {en},
	number = {1},
	urldate = {2023-12-07},
	journal = {npj Digital Medicine},
	author = {Wornow, Michael and Xu, Yizhe and Thapa, Rahul and Patel, Birju and Steinberg, Ethan and Fleming, Scott and Pfeffer, Michael A. and Fries, Jason and Shah, Nigam H.},
	month = jul,
	year = {2023},
	keywords = {notion},
	pages = {135},
}

@article{yang_transformehr_2023,
	title = {{TransformEHR}: transformer-based encoder-decoder generative model to enhance prediction of disease outcomes using electronic health records},
	volume = {14},
	issn = {2041-1723},
	shorttitle = {{TransformEHR}},
	url = {https://www.nature.com/articles/s41467-023-43715-z},
	doi = {10.1038/s41467-023-43715-z},
	abstract = {Abstract
            
              Deep learning transformer-based models using longitudinal electronic health records (EHRs) have shown a great success in prediction of clinical diseases or outcomes. Pretraining on a large dataset can help such models map the input space better and boost their performance on relevant tasks through finetuning with limited data. In this study, we present TransformEHR, a generative encoder-decoder model with transformer that is pretrained using a new pretraining objective—predicting all diseases and outcomes of a patient at a future visit from previous visits. TransformEHR’s encoder-decoder framework, paired with the novel pretraining objective, helps it achieve the new state-of-the-art performance on multiple clinical prediction tasks. Comparing with the previous model, TransformEHR improves area under the precision–recall curve by 2\% (
              p
               {\textless} 0.001) for pancreatic cancer onset and by 24\% (
              p
               = 0.007) for intentional self-harm in patients with post-traumatic stress disorder. The high performance in predicting intentional self-harm shows the potential of TransformEHR in building effective clinical intervention systems. TransformEHR is also generalizable and can be easily finetuned for clinical prediction tasks with limited data.},
	language = {en},
	number = {1},
	urldate = {2023-12-07},
	journal = {Nature Communications},
	author = {Yang, Zhichao and Mitra, Avijit and Liu, Weisong and Berlowitz, Dan and Yu, Hong},
	month = nov,
	year = {2023},
	keywords = {notion},
	pages = {7857},
}

@misc{singhal_towards_2023,
	title = {Towards {Expert}-{Level} {Medical} {Question} {Answering} with {Large} {Language} {Models}},
	url = {http://arxiv.org/abs/2305.09617},
	abstract = {Recent artificial intelligence (AI) systems have reached milestones in "grand challenges" ranging from Go to protein-folding. The capability to retrieve medical knowledge, reason over it, and answer medical questions comparably to physicians has long been viewed as one such grand challenge. Large language models (LLMs) have catalyzed significant progress in medical question answering; Med-PaLM was the first model to exceed a "passing" score in US Medical Licensing Examination (USMLE) style questions with a score of 67.2\% on the MedQA dataset. However, this and other prior work suggested significant room for improvement, especially when models' answers were compared to clinicians' answers. Here we present Med-PaLM 2, which bridges these gaps by leveraging a combination of base LLM improvements (PaLM 2), medical domain finetuning, and prompting strategies including a novel ensemble refinement approach. Med-PaLM 2 scored up to 86.5\% on the MedQA dataset, improving upon Med-PaLM by over 19\% and setting a new state-of-the-art. We also observed performance approaching or exceeding state-of-the-art across MedMCQA, PubMedQA, and MMLU clinical topics datasets. We performed detailed human evaluations on long-form questions along multiple axes relevant to clinical applications. In pairwise comparative ranking of 1066 consumer medical questions, physicians preferred Med-PaLM 2 answers to those produced by physicians on eight of nine axes pertaining to clinical utility (p {\textless} 0.001). We also observed significant improvements compared to Med-PaLM on every evaluation axis (p {\textless} 0.001) on newly introduced datasets of 240 long-form "adversarial" questions to probe LLM limitations. While further studies are necessary to validate the efficacy of these models in real-world settings, these results highlight rapid progress towards physician-level performance in medical question answering.},
	urldate = {2023-12-06},
	publisher = {arXiv},
	author = {Singhal, Karan and Tu, Tao and Gottweis, Juraj and Sayres, Rory and Wulczyn, Ellery and Hou, Le and Clark, Kevin and Pfohl, Stephen and Cole-Lewis, Heather and Neal, Darlene and Schaekermann, Mike and Wang, Amy and Amin, Mohamed and Lachgar, Sami and Mansfield, Philip and Prakash, Sushant and Green, Bradley and Dominowska, Ewa and Arcas, Blaise Aguera y and Tomasev, Nenad and Liu, Yun and Wong, Renee and Semturs, Christopher and Mahdavi, S. Sara and Barral, Joelle and Webster, Dale and Corrado, Greg S. and Matias, Yossi and Azizi, Shekoofeh and Karthikesalingam, Alan and Natarajan, Vivek},
	month = may,
	year = {2023},
	note = {arXiv:2305.09617 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language, Computer Science - Machine Learning, notion},
}

@article{singhal_large_2023,
	title = {Large language models encode clinical knowledge},
	volume = {620},
	issn = {0028-0836, 1476-4687},
	url = {https://www.nature.com/articles/s41586-023-06291-2},
	doi = {10.1038/s41586-023-06291-2},
	abstract = {Abstract
            
              Large language models (LLMs) have demonstrated impressive capabilities, but the bar for clinical applications is high. Attempts to assess the clinical knowledge of models typically rely on automated evaluations based on limited benchmarks. Here, to address these limitations, we present MultiMedQA, a benchmark combining six existing medical question answering datasets spanning professional medicine, research and consumer queries and a new dataset of medical questions searched online, HealthSearchQA. We propose a human evaluation framework for model answers along multiple axes including factuality, comprehension, reasoning, possible harm and bias. In addition, we evaluate Pathways Language Model
              1
              (PaLM, a 540-billion parameter LLM) and its instruction-tuned variant, Flan-PaLM
              2
              on MultiMedQA. Using a combination of prompting strategies, Flan-PaLM achieves state-of-the-art accuracy on every MultiMedQA multiple-choice dataset (MedQA
              3
              , MedMCQA
              4
              , PubMedQA
              5
              and Measuring Massive Multitask Language Understanding (MMLU) clinical topics
              6
              ), including 67.6\% accuracy on MedQA (US Medical Licensing Exam-style questions), surpassing the prior state of the art by more than 17\%. However, human evaluation reveals key gaps. To resolve this, we introduce instruction prompt tuning, a parameter-efficient approach for aligning LLMs to new domains using a few exemplars. The resulting model, Med-PaLM, performs encouragingly, but remains inferior to clinicians. We show that comprehension, knowledge recall and reasoning improve with model scale and instruction prompt tuning, suggesting the potential utility of LLMs in medicine. Our human evaluations reveal limitations of today’s models, reinforcing the importance of both evaluation frameworks and method development in creating safe, helpful LLMs for clinical applications.},
	language = {en},
	number = {7972},
	urldate = {2023-12-06},
	journal = {Nature},
	author = {Singhal, Karan and Azizi, Shekoofeh and Tu, Tao and Mahdavi, S. Sara and Wei, Jason and Chung, Hyung Won and Scales, Nathan and Tanwani, Ajay and Cole-Lewis, Heather and Pfohl, Stephen and Payne, Perry and Seneviratne, Martin and Gamble, Paul and Kelly, Chris and Babiker, Abubakr and Schärli, Nathanael and Chowdhery, Aakanksha and Mansfield, Philip and Demner-Fushman, Dina and Agüera Y Arcas, Blaise and Webster, Dale and Corrado, Greg S. and Matias, Yossi and Chou, Katherine and Gottweis, Juraj and Tomasev, Nenad and Liu, Yun and Rajkomar, Alvin and Barral, Joelle and Semturs, Christopher and Karthikesalingam, Alan and Natarajan, Vivek},
	month = aug,
	year = {2023},
	keywords = {notion},
	pages = {172--180},
}

@misc{li_multimodal_2023,
	title = {Multimodal {Foundation} {Models}: {From} {Specialists} to {General}-{Purpose} {Assistants}},
	shorttitle = {Multimodal {Foundation} {Models}},
	url = {http://arxiv.org/abs/2309.10020},
	abstract = {This paper presents a comprehensive survey of the taxonomy and evolution of multimodal foundation models that demonstrate vision and vision-language capabilities, focusing on the transition from specialist models to general-purpose assistants. The research landscape encompasses five core topics, categorized into two classes. (i) We start with a survey of well-established research areas: multimodal foundation models pre-trained for specific purposes, including two topics -- methods of learning vision backbones for visual understanding and text-to-image generation. (ii) Then, we present recent advances in exploratory, open research areas: multimodal foundation models that aim to play the role of general-purpose assistants, including three topics -- unified vision models inspired by large language models (LLMs), end-to-end training of multimodal LLMs, and chaining multimodal tools with LLMs. The target audiences of the paper are researchers, graduate students, and professionals in computer vision and vision-language multimodal communities who are eager to learn the basics and recent advances in multimodal foundation models.},
	urldate = {2023-12-07},
	publisher = {arXiv},
	author = {Li, Chunyuan and Gan, Zhe and Yang, Zhengyuan and Yang, Jianwei and Li, Linjie and Wang, Lijuan and Gao, Jianfeng},
	month = sep,
	year = {2023},
	note = {arXiv:2309.10020 [cs]},
	keywords = {Computer Science - Computation and Language, Computer Science - Computer Vision and Pattern Recognition, notion},
}

@misc{chen_pali_2023,
	title = {{PaLI}: {A} {Jointly}-{Scaled} {Multilingual} {Language}-{Image} {Model}},
	shorttitle = {{PaLI}},
	url = {http://arxiv.org/abs/2209.06794},
	abstract = {Effective scaling and a flexible task interface enable large language models to excel at many tasks. We present PaLI (Pathways Language and Image model), a model that extends this approach to the joint modeling of language and vision. PaLI generates text based on visual and textual inputs, and with this interface performs many vision, language, and multimodal tasks, in many languages. To train PaLI, we make use of large pre-trained encoder-decoder language models and Vision Transformers (ViTs). This allows us to capitalize on their existing capabilities and leverage the substantial cost of training them. We find that joint scaling of the vision and language components is important. Since existing Transformers for language are much larger than their vision counterparts, we train a large, 4-billion parameter ViT (ViT-e) to quantify the benefits from even larger-capacity vision models. To train PaLI, we create a large multilingual mix of pretraining tasks, based on a new image-text training set containing 10B images and texts in over 100 languages. PaLI achieves state-of-the-art in multiple vision and language tasks (such as captioning, visual question-answering, scene-text understanding), while retaining a simple, modular, and scalable design.},
	urldate = {2023-12-07},
	publisher = {arXiv},
	author = {Chen, Xi and Wang, Xiao and Changpinyo, Soravit and Piergiovanni, A. J. and Padlewski, Piotr and Salz, Daniel and Goodman, Sebastian and Grycner, Adam and Mustafa, Basil and Beyer, Lucas and Kolesnikov, Alexander and Puigcerver, Joan and Ding, Nan and Rong, Keran and Akbari, Hassan and Mishra, Gaurav and Xue, Linting and Thapliyal, Ashish and Bradbury, James and Kuo, Weicheng and Seyedhosseini, Mojtaba and Jia, Chao and Ayan, Burcu Karagol and Riquelme, Carlos and Steiner, Andreas and Angelova, Anelia and Zhai, Xiaohua and Houlsby, Neil and Soricut, Radu},
	month = jun,
	year = {2023},
	note = {arXiv:2209.06794 [cs]},
	keywords = {Computer Science - Computation and Language, Computer Science - Computer Vision and Pattern Recognition},
}

@misc{yu_coca_2022,
	title = {{CoCa}: {Contrastive} {Captioners} are {Image}-{Text} {Foundation} {Models}},
	shorttitle = {{CoCa}},
	url = {http://arxiv.org/abs/2205.01917},
	abstract = {Exploring large-scale pretrained foundation models is of significant interest in computer vision because these models can be quickly transferred to many downstream tasks. This paper presents Contrastive Captioner (CoCa), a minimalist design to pretrain an image-text encoder-decoder foundation model jointly with contrastive loss and captioning loss, thereby subsuming model capabilities from contrastive approaches like CLIP and generative methods like SimVLM. In contrast to standard encoder-decoder transformers where all decoder layers attend to encoder outputs, CoCa omits cross-attention in the first half of decoder layers to encode unimodal text representations, and cascades the remaining decoder layers which cross-attend to the image encoder for multimodal image-text representations. We apply a contrastive loss between unimodal image and text embeddings, in addition to a captioning loss on the multimodal decoder outputs which predicts text tokens autoregressively. By sharing the same computational graph, the two training objectives are computed efficiently with minimal overhead. CoCa is pretrained end-to-end and from scratch on both web-scale alt-text data and annotated images by treating all labels simply as text, seamlessly unifying natural language supervision for representation learning. Empirically, CoCa achieves state-of-the-art performance with zero-shot transfer or minimal task-specific adaptation on a broad range of downstream tasks, spanning visual recognition (ImageNet, Kinetics-400/600/700, Moments-in-Time), crossmodal retrieval (MSCOCO, Flickr30K, MSR-VTT), multimodal understanding (VQA, SNLI-VE, NLVR2), and image captioning (MSCOCO, NoCaps). Notably on ImageNet classification, CoCa obtains 86.3\% zero-shot top-1 accuracy, 90.6\% with a frozen encoder and learned classification head, and new state-of-the-art 91.0\% top-1 accuracy on ImageNet with a finetuned encoder.},
	urldate = {2023-12-07},
	publisher = {arXiv},
	author = {Yu, Jiahui and Wang, Zirui and Vasudevan, Vijay and Yeung, Legg and Seyedhosseini, Mojtaba and Wu, Yonghui},
	month = jun,
	year = {2022},
	note = {arXiv:2205.01917 [cs]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning, Computer Science - Multimedia},
}

@inproceedings{alayrac_flamingo_2022,
	title = {Flamingo: a {Visual} {Language} {Model} for {Few}-{Shot} {Learning}},
	volume = {35},
	url = {https://proceedings.neurips.cc/paper_files/paper/2022/file/960a172bc7fbf0177ccccbb411a7d800-Paper-Conference.pdf},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	publisher = {Curran Associates, Inc.},
	author = {Alayrac, Jean-Baptiste and Donahue, Jeff and Luc, Pauline and Miech, Antoine and Barr, Iain and Hasson, Yana and Lenc, Karel and Mensch, Arthur and Millican, Katherine and Reynolds, Malcolm and Ring, Roman and Rutherford, Eliza and Cabi, Serkan and Han, Tengda and Gong, Zhitao and Samangooei, Sina and Monteiro, Marianne and Menick, Jacob L and Borgeaud, Sebastian and Brock, Andy and Nematzadeh, Aida and Sharifzadeh, Sahand and Bińkowski, Mikołaj and Barreira, Ricardo and Vinyals, Oriol and Zisserman, Andrew and Simonyan, Karén},
	editor = {Koyejo, S. and Mohamed, S. and Agarwal, A. and Belgrave, D. and Cho, K. and Oh, A.},
	year = {2022},
	pages = {23716--23736},
}

@misc{shazeer_fast_2019,
	title = {Fast {Transformer} {Decoding}: {One} {Write}-{Head} is {All} {You} {Need}},
	shorttitle = {Fast {Transformer} {Decoding}},
	url = {http://arxiv.org/abs/1911.02150},
	abstract = {Multi-head attention layers, as used in the Transformer neural sequence model, are a powerful alternative to RNNs for moving information across and between sequences. While training these layers is generally fast and simple, due to parallelizability across the length of the sequence, incremental inference (where such paralleization is impossible) is often slow, due to the memory-bandwidth cost of repeatedly loading the large "keys" and "values" tensors. We propose a variant called multi-query attention, where the keys and values are shared across all of the different attention "heads", greatly reducing the size of these tensors and hence the memory bandwidth requirements of incremental decoding. We verify experimentally that the resulting models can indeed be much faster to decode, and incur only minor quality degradation from the baseline.},
	urldate = {2023-12-06},
	publisher = {arXiv},
	author = {Shazeer, Noam},
	month = nov,
	year = {2019},
	note = {arXiv:1911.02150 [cs]},
	keywords = {Computer Science - Computation and Language, Computer Science - Machine Learning, Computer Science - Neural and Evolutionary Computing},
}

@article{vivar_simultaneous_2021,
	title = {Simultaneous imputation and disease classification in incomplete medical datasets using {Multigraph} {Geometric} {Matrix} {Completion} ({MGMC})},
	volume = {117},
	issn = {09333657},
	url = {http://arxiv.org/abs/2005.06935},
	doi = {10.1016/j.artmed.2021.102097},
	abstract = {Large-scale population-based studies in medicine are a key resource towards better diagnosis, monitoring, and treatment of diseases. They also serve as enablers of clinical decision support systems, in particular Computer Aided Diagnosis (CADx) using machine learning (ML). Numerous ML approaches for CADx have been proposed in literature. However, these approaches assume full data availability, which is not always feasible in clinical data. To account for missing data, incomplete data samples are either removed or imputed, which could lead to data bias and may negatively affect classiﬁcation performance. As a solution, we propose an end-to-end learning of imputation and disease prediction of incomplete medical datasets via Multigraph Geometric Matrix Completion (MGMC). MGMC uses multiple recurrent graph convolutional networks, where each graph represents an independent population model based on a key clinical meta-feature like age, sex, or cognitive function. Graph signal aggregation from local patient neighborhoods, combined with multi-graph signal fusion via self-attention, has a regularizing effect on both matrix reconstruction and classiﬁcation performance. Our proposed approach is able to impute class relevant features as well as perform accurate classiﬁcation on two publicly available medical datasets. We empirically show the superiority of our proposed approach in terms of classiﬁcation and imputation performance when compared with state-of-theart approaches. MGMC enables disease prediction in multimodal and incomplete medical datasets. These ﬁndings could serve as baseline for future CADx approaches which utilize incomplete datasets.},
	language = {en},
	urldate = {2023-12-06},
	journal = {Artificial Intelligence in Medicine},
	author = {Vivar, Gerome and Kazi, Anees and Burwinkel, Hendrik and Zwergal, Andreas and Navab, Nassir and Ahmadi, Seyed-Ahmad},
	month = jul,
	year = {2021},
	note = {arXiv:2005.06935 [cs, stat]},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
	pages = {102097},
}

@article{bhagat_nmvi_2022,
	title = {{NMVI}: {A} data-splitting based imputation technique for distinct types of missing data},
	volume = {223},
	issn = {01697439},
	shorttitle = {{NMVI}},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0169743922000296},
	doi = {10.1016/j.chemolab.2022.104518},
	abstract = {In the IoT world, where minute digital devices are acclimated to sense the data, a failure in such devices results in immense information loss and insufﬁcient information regarding datasets results in inappropriate decisions. Missing values within a dataset have an adverse effect on the data analysis. Data Analysts in pre-processing phase perform data imputation before analyzing the dataset. Distinct traditional methods, which are predicated on simple techniques (mean, case deletion, mode or median), show poor performance while estimating the missing values. In this paper, a novel splitting-based Nullify the Missing Values before Imputation (NMVI) is proposed in which the data is ﬁrst split into complete and incomplete subsets and then an upper-limit is set for every class having missing data that assists the model to estimate missing values closer to the exact values. The proposed NMVI technique surmounts the constraint of exiting imputation techniques that are completely dependent on complete variables within a class to estimate the missing values. The proposed NMVI technique has comparatively less computational time because of which it is beneﬁcial for real-time quandaries. The experimental results depict that the proposed NMVI technique estimates the missing values in an efﬁcient manner with respect to RMSEs, Adjusted coefﬁcient of determination, Accuracy and Correlation coefﬁcient irrespective of the dimensionality as well as missing rate within a dataset.},
	language = {en},
	urldate = {2023-12-06},
	journal = {Chemometrics and Intelligent Laboratory Systems},
	author = {Bhagat, Hutashan Vishal and Singh, Manminder},
	month = apr,
	year = {2022},
	pages = {104518},
}

@article{lin_missing_2020,
	title = {Missing value imputation: a review and analysis of the literature (2006–2017)},
	volume = {53},
	issn = {0269-2821, 1573-7462},
	shorttitle = {Missing value imputation},
	url = {http://link.springer.com/10.1007/s10462-019-09709-4},
	doi = {10.1007/s10462-019-09709-4},
	abstract = {Missing value imputation (MVI) has been studied for several decades being the basic solu‑tion method for incomplete dataset problems, specifically those where some data samples contain one or more missing attribute values. This paper aims at reviewing and analyzing related studies carried out in recent decades, from the experimental design perspective. Altogether, 111 journal papers published from 2006 to 2017 are reviewed and analyzed. In addition, several technical issues encountered during the MVI process are addressed, such as the choice of datasets, missing rates and missingness mechanisms, and the MVI techniques and evaluation metrics employed, are discussed. The results of analysis of these issues allow limitations in the existing body of literature to be identified based upon which some directions for future research can be gleaned.},
	language = {en},
	number = {2},
	urldate = {2023-12-06},
	journal = {Artificial Intelligence Review},
	author = {Lin, Wei-Chao and Tsai, Chih-Fong},
	month = feb,
	year = {2020},
	pages = {1487--1509},
}

@article{acosta_multimodal_2022,
	title = {Multimodal biomedical {AI}},
	volume = {28},
	issn = {1078-8956, 1546-170X},
	url = {https://www.nature.com/articles/s41591-022-01981-2},
	doi = {10.1038/s41591-022-01981-2},
	language = {en},
	number = {9},
	urldate = {2023-12-06},
	journal = {Nature Medicine},
	author = {Acosta, Julián N. and Falcone, Guido J. and Rajpurkar, Pranav and Topol, Eric J.},
	month = sep,
	year = {2022},
	pages = {1773--1784},
}

@inproceedings{yin_domain_2019,
	address = {Beijing, China},
	title = {Domain {Knowledge} {Guided} {Deep} {Learning} with {Electronic} {Health} {Records}},
	isbn = {978-1-72814-604-1},
	url = {https://ieeexplore.ieee.org/document/8970777/},
	doi = {10.1109/ICDM.2019.00084},
	abstract = {Due to their promising performance in clinical risk prediction with Electronic Health Records (EHRs), deep learning methods have attracted signiﬁcant interest from healthcare researchers. However, there are 4 challenges: (i) Data insufﬁciency. Many methods require large amounts of training data to achieve satisfactory results. (ii) Interpretability. Results from many methods are hard to explain to clinicians (e.g., why the models make particular predictions and which events cause clinical outcomes). (iii) Domain knowledge integration. No existing method dynamically exploits complicated medical knowledge (e.g., relations such as cause and is-caused-by between clinical events). (iv) Time interval information. Most existing methods only consider the relative order of visits from EHRs, but ignore the irregular time intervals between neighboring visits. In the study, we propose a new model, Domain Knowledge Guided Recurrent Neural Networks (DG-RNN), by directly introducing domain knowledge from the medical knowledge graph into an RNN architecture, as well as taking the irregular time intervals into account. Experimental results on heart failure risk prediction tasks show that our model not only outperforms state-of-the-art deep-learning based risk prediction models, but also associates individual medical events with heart failure onset, thus paving the way for interpretable accurate clinical risk predictions.},
	language = {en},
	urldate = {2023-12-06},
	booktitle = {2019 {IEEE} {International} {Conference} on {Data} {Mining} ({ICDM})},
	publisher = {IEEE},
	author = {Yin, Changchang and Zhao, Rongjian and Qian, Buyue and Lv, Xin and Zhang, Ping},
	month = nov,
	year = {2019},
	pages = {738--747},
}

@book{bishop_pattern_2006,
	address = {New York},
	series = {Information science and statistics},
	title = {Pattern recognition and machine learning},
	isbn = {978-0-387-31073-2},
	language = {en},
	publisher = {Springer},
	author = {Bishop, Christopher M.},
	year = {2006},
}

@article{emmanuel_survey_2021,
	title = {A survey on missing data in machine learning},
	volume = {8},
	issn = {2196-1115},
	url = {https://journalofbigdata.springeropen.com/articles/10.1186/s40537-021-00516-9},
	doi = {10.1186/s40537-021-00516-9},
	abstract = {Machine learning has been the corner stone in analysing and extracting information from data and often a problem of missing values is encountered. Missing values occur because of various factors like missing completely at random, missing at random or missing not at random. All these may result from system malfunction during data collection or human error during data pre-processing. Nevertheless, it is important to deal with missing values before analysing data since ignoring or omitting missing values may result in biased or misinformed analysis. In literature there have been several proposals for handling missing values. In this paper, we aggregate some of the literature on missing data particularly focusing on machine learning techniques. We also give insight on how the machine learning approaches work by highlighting the key features of missing values imputation techniques, how they perform, their limitations and the kind of data they are most suitable for. We propose and evaluate two methods, the k nearest neighbor and an iterative imputation method (missForest) based on the random forest algorithm. Evaluation is performed on the Iris and novel power plant fan data with induced missing values at missingness rate of 5\% to 20\%. We show that both missForest and the k nearest neighbor can successfully handle missing values and offer some possible future research direction.},
	language = {en},
	number = {1},
	urldate = {2023-12-06},
	journal = {Journal of Big Data},
	author = {Emmanuel, Tlamelo and Maupong, Thabiso and Mpoeleng, Dimane and Semong, Thabo and Mphago, Banyatsang and Tabona, Oteng},
	month = oct,
	year = {2021},
	pages = {140},
}

@article{armina_review_2017,
	title = {A {Review} {On} {Missing} {Value} {Estimation} {Using} {Imputation} {Algorithm}},
	volume = {892},
	issn = {1742-6588, 1742-6596},
	url = {https://iopscience.iop.org/article/10.1088/1742-6596/892/1/012004},
	doi = {10.1088/1742-6596/892/1/012004},
	abstract = {The presence of the missing value in the data set has always been a major problem for precise prediction. The method for imputing missing value needs to minimize the effect of incomplete data sets for the prediction model. Many algorithms have been proposed for countermeasure of missing value problem. In this review, we provide a comprehensive analysis of existing imputation algorithm, focusing on the technique used and the implementation of global or local information of data sets for missing value estimation. In addition validation method for imputation result and way to measure the performance of imputation algorithm also described. The objective of this review is to highlight possible improvement on existing method and it is hoped that this review gives reader better understanding of imputation method trend.},
	language = {en},
	urldate = {2023-12-06},
	journal = {Journal of Physics: Conference Series},
	author = {Armina, Roslan and Mohd Zain, Azlan and Ali, Nor Azizah and Sallehuddin, Roselina},
	month = sep,
	year = {2017},
	pages = {012004},
}

@misc{akkus_multimodal_2023,
	title = {Multimodal {Deep} {Learning}},
	url = {http://arxiv.org/abs/2301.04856},
	abstract = {This book is the result of a seminar in which we reviewed multimodal approaches and attempted to create a solid overview of the field, starting with the current state-of-the-art approaches in the two subfields of Deep Learning individually. Further, modeling frameworks are discussed where one modality is transformed into the other, as well as models in which one modality is utilized to enhance representation learning for the other. To conclude the second part, architectures with a focus on handling both modalities simultaneously are introduced. Finally, we also cover other modalities as well as general-purpose multi-modal models, which are able to handle different tasks on different modalities within one unified architecture. One interesting application (Generative Art) eventually caps off this booklet.},
	urldate = {2023-12-06},
	publisher = {arXiv},
	author = {Akkus, Cem and Chu, Luyang and Djakovic, Vladana and Jauch-Walser, Steffen and Koch, Philipp and Loss, Giacomo and Marquardt, Christopher and Moldovan, Marco and Sauter, Nadja and Schneider, Maximilian and Schulte, Rickmer and Urbanczyk, Karol and Goschenhofer, Jann and Heumann, Christian and Hvingelby, Rasmus and Schalk, Daniel and Aßenmacher, Matthias},
	month = jan,
	year = {2023},
	note = {arXiv:2301.04856 [cs, stat]},
	keywords = {Computer Science - Computation and Language, Computer Science - Machine Learning, Statistics - Machine Learning},
}

@misc{girdhar_imagebind_2023,
	title = {{ImageBind}: {One} {Embedding} {Space} {To} {Bind} {Them} {All}},
	shorttitle = {{ImageBind}},
	url = {http://arxiv.org/abs/2305.05665},
	abstract = {We present IMAGEBIND, an approach to learn a joint embedding across six different modalities - images, text, audio, depth, thermal, and IMU data. We show that all combinations of paired data are not necessary to train such a joint embedding, and only image-paired data is sufficient to bind the modalities together. IMAGEBIND can leverage recent large scale vision-language models, and extends their zeroshot capabilities to new modalities just by using their natural pairing with images. It enables novel emergent applications ‘out-of-the-box’ including cross-modal retrieval, composing modalities with arithmetic, cross-modal detection and generation. The emergent capabilities improve with the strength of the image encoder and we set a new state-of-theart on emergent zero-shot recognition tasks across modalities, outperforming specialist supervised models. Finally, we show strong few-shot recognition results outperforming prior work, and that IMAGEBIND serves as a new way to evaluate vision models for visual and non-visual tasks.},
	language = {en},
	urldate = {2023-12-06},
	publisher = {arXiv},
	author = {Girdhar, Rohit and El-Nouby, Alaaeldin and Liu, Zhuang and Singh, Mannat and Alwala, Kalyan Vasudev and Joulin, Armand and Misra, Ishan},
	month = may,
	year = {2023},
	note = {arXiv:2305.05665 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning, Computer Science - Multimedia},
}

@misc{fan_contextual_2021,
	title = {Contextual {Dropout}: {An} {Efficient} {Sample}-{Dependent} {Dropout} {Module}},
	shorttitle = {Contextual {Dropout}},
	url = {http://arxiv.org/abs/2103.04181},
	abstract = {Dropout has been demonstrated as a simple and effective module to not only regularize the training process of deep neural networks, but also provide the uncertainty estimation for prediction. However, the quality of uncertainty estimation is highly dependent on the dropout probabilities. Most current models use the same dropout distributions across all data samples due to its simplicity. Despite the potential gains in the flexibility of modeling uncertainty, sample-dependent dropout, on the other hand, is less explored as it often encounters scalability issues or involves non-trivial model changes. In this paper, we propose contextual dropout with an efficient structural design as a simple and scalable sample-dependent dropout module, which can be applied to a wide range of models at the expense of only slightly increased memory and computational cost. We learn the dropout probabilities with a variational objective, compatible with both Bernoulli dropout and Gaussian dropout. We apply the contextual dropout module to various models with applications to image classification and visual question answering and demonstrate the scalability of the method with large-scale datasets, such as ImageNet and VQA 2.0. Our experimental results show that the proposed method outperforms baseline methods in terms of both accuracy and quality of uncertainty estimation.},
	urldate = {2023-12-06},
	publisher = {arXiv},
	author = {Fan, Xinjie and Zhang, Shujian and Tanwisuth, Korawat and Qian, Xiaoning and Zhou, Mingyuan},
	month = mar,
	year = {2021},
	note = {arXiv:2103.04181 [cs]},
	keywords = {Computer Science - Machine Learning, notion},
}

@misc{bottou_borges_2023,
	title = {Borges and {AI}},
	url = {http://arxiv.org/abs/2310.01425},
	abstract = {Many believe that Large Language Models (LLMs) open the era of Artificial Intelligence (AI). Some see opportunities while others see dangers. Yet both proponents and opponents grasp AI through the imagery popularised by science fiction. Will the machine become sentient and rebel against its creators? Will we experience a paperclip apocalypse? Before answering such questions, we should first ask whether this mental imagery provides a good description of the phenomenon at hand. Understanding weather patterns through the moods of the gods only goes so far. The present paper instead advocates understanding LLMs and their connection to AI through the imagery of Jorge Luis Borges, a master of 20th century literature, forerunner of magical realism, and precursor to postmodern literature. This exercise leads to a new perspective that illuminates the relation between language modelling and artificial intelligence.},
	urldate = {2023-12-06},
	publisher = {arXiv},
	author = {Bottou, Léon and Schölkopf, Bernhard},
	month = oct,
	year = {2023},
	note = {arXiv:2310.01425 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language, Computer Science - Machine Learning},
}

@article{singhal_publisher_2023,
	title = {Publisher {Correction}: {Large} language models encode clinical knowledge},
	volume = {620},
	issn = {0028-0836, 1476-4687},
	shorttitle = {Publisher {Correction}},
	url = {https://www.nature.com/articles/s41586-023-06455-0},
	doi = {10.1038/s41586-023-06455-0},
	language = {en},
	number = {7973},
	urldate = {2023-12-06},
	journal = {Nature},
	author = {Singhal, Karan and Azizi, Shekoofeh and Tu, Tao and Mahdavi, S. Sara and Wei, Jason and Chung, Hyung Won and Scales, Nathan and Tanwani, Ajay and Cole-Lewis, Heather and Pfohl, Stephen and Payne, Perry and Seneviratne, Martin and Gamble, Paul and Kelly, Chris and Babiker, Abubakr and Schärli, Nathanael and Chowdhery, Aakanksha and Mansfield, Philip and Demner-Fushman, Dina and Agüera Y Arcas, Blaise and Webster, Dale and Corrado, Greg S. and Matias, Yossi and Chou, Katherine and Gottweis, Juraj and Tomasev, Nenad and Liu, Yun and Rajkomar, Alvin and Barral, Joelle and Semturs, Christopher and Karthikesalingam, Alan and Natarajan, Vivek},
	month = aug,
	year = {2023},
	pages = {E19--E19},
}

@inproceedings{qiao_learning_2020,
	address = {Seattle, WA, USA},
	title = {Learning to {Learn} {Single} {Domain} {Generalization}},
	isbn = {978-1-72817-168-5},
	url = {https://ieeexplore.ieee.org/document/9157002/},
	doi = {10.1109/CVPR42600.2020.01257},
	urldate = {2023-12-05},
	booktitle = {2020 {IEEE}/{CVF} {Conference} on {Computer} {Vision} and {Pattern} {Recognition} ({CVPR})},
	publisher = {IEEE},
	author = {Qiao, Fengchun and Zhao, Long and Peng, Xi},
	month = jun,
	year = {2020},
	pages = {12553--12562},
}

@article{wu_iterative_nodate,
	title = {An {Iterative} {Self}-{Learning} {Framework} for {Medical} {Domain} {Generalization}},
	abstract = {Deep learning models have been widely used to assist doctors with clinical decisionmaking. However, these models often encounter a significant performance drop when applied to data that differs from the distribution they were trained on. This challenge is known as the domain shift problem. Existing domain generalization algorithms attempt to address this problem by assuming the availability of domain IDs and training a single model to handle all domains. However, in healthcare settings, patients can be classified into numerous latent domains, where the actual domain categorizations are unknown. Furthermore, each patient domain exhibits distinct clinical characteristics, making it sub-optimal to train a single model for all domains. To overcome these limitations, we propose SLDG, a self-learning framework that iteratively discovers decoupled domains and trains personalized classifiers for each decoupled domain. We evaluate the generalizability of SLDG across spatial and temporal data distribution shifts on two real-world public EHR datasets: eICU and MIMIC-IV. Our results show that SLDG achieves up to 11\% improvement in the AUPRC score over the best baseline.},
	language = {en},
	author = {Wu, Zhenbang and Yao, Huaxiu and Liebovitz, David M and Sun, Jimeng},
	keywords = {notion},
}

@article{s_novel_2021,
	title = {A {Novel} {Deep} {Learning} based {Gated} {Recurrent} {Unit} with {Extreme} {Learning} {Machine} for {Electrocardiogram} ({ECG}) {Signal} {Recognition}},
	volume = {68},
	issn = {17468094},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S1746809421003761},
	doi = {10.1016/j.bspc.2021.102779},
	language = {en},
	urldate = {2023-12-01},
	journal = {Biomedical Signal Processing and Control},
	author = {S., Clement Virgeniya and E., Ramaraj},
	month = jul,
	year = {2021},
	pages = {102779},
}

@article{wagner_ptb-xl_2020,
	title = {{PTB}-{XL}, a large publicly available electrocardiography dataset},
	volume = {7},
	issn = {2052-4463},
	url = {https://www.nature.com/articles/s41597-020-0495-6},
	doi = {10.1038/s41597-020-0495-6},
	abstract = {Abstract
            
              Electrocardiography (ECG) is a key non-invasive diagnostic tool for cardiovascular diseases which is increasingly supported by algorithms based on machine learning. Major obstacles for the development of automatic ECG interpretation algorithms are both the lack of public datasets and well-defined benchmarking procedures to allow comparison s of different algorithms. To address these issues, we put forward
              PTB-XL
              , the to-date largest freely accessible clinical 12-lead ECG-waveform dataset comprising 21837 records from 18885 patients of 10 seconds length. The ECG-waveform data was annotated by up to two cardiologists as a multi-label dataset, where diagnostic labels were further aggregated into super and subclasses. The dataset covers a broad range of diagnostic classes including, in particular, a large fraction of healthy records. The combination with additional metadata on demographics, additional diagnostic statements, diagnosis likelihoods, manually annotated signal properties as well as suggested folds for splitting training and test sets turns the dataset into a rich resource for the development and the evaluation of automatic ECG interpretation algorithms.},
	language = {en},
	number = {1},
	urldate = {2023-11-30},
	journal = {Scientific Data},
	author = {Wagner, Patrick and Strodthoff, Nils and Bousseljot, Ralf-Dieter and Kreiseler, Dieter and Lunze, Fatima I. and Samek, Wojciech and Schaeffter, Tobias},
	month = may,
	year = {2020},
	pages = {154},
}

@article{liu_multimodal_2023,
	title = {Multimodal {Sentiment} {Analysis} {Using} {BiGRU} and {Attention}-{Based} {Hybrid} {Fusion} {Strategy}},
	volume = {37},
	issn = {1079-8587},
	url = {https://www.techscience.com/iasc/v37n2/53229},
	doi = {10.32604/iasc.2023.038835},
	language = {en},
	number = {2},
	urldate = {2023-11-28},
	journal = {Intelligent Automation \& Soft Computing},
	author = {Liu, Zhizhong and Zhou, Bin and Meng, Lingqiang and Huang, Guangyu},
	year = {2023},
	pages = {1963--1981},
}

@inproceedings{zhang_feature-level_2019,
	address = {Macao, China},
	title = {Feature-level {Deeper} {Self}-{Attention} {Network} for {Sequential} {Recommendation}},
	isbn = {978-0-9992411-4-1},
	url = {https://www.ijcai.org/proceedings/2019/600},
	doi = {10.24963/ijcai.2019/600},
	abstract = {Sequential recommendation, which aims to recommend next item that the user will likely interact in a near future, has become essential in various Internet applications. Existing methods usually consider the transition patterns between items, but ignore the transition patterns between features of items. We argue that only the item-level sequences cannot reveal the full sequential patterns, while explicit and implicit feature-level sequences can help extract the full sequential patterns. In this paper, we propose a novel method named Feature-level Deeper Self-Attention Network (FDSA) for sequential recommendation. Specifically, FDSA first integrates various heterogeneous features of items into feature sequences with different weights through a vanilla mechanism. After that, FDSA applies separated self-attention blocks on item-level sequences and feature-level sequences, respectively, to model item transition patterns and feature transition patterns. Then, we integrate the outputs of these two blocks to a fully-connected layer for next item recommendation. Finally, comprehensive experimental results demonstrate that considering the transition relationships between features can significantly improve the performance of sequential recommendation.},
	language = {en},
	urldate = {2023-11-27},
	booktitle = {Proceedings of the {Twenty}-{Eighth} {International} {Joint} {Conference} on {Artificial} {Intelligence}},
	publisher = {International Joint Conferences on Artificial Intelligence Organization},
	author = {Zhang, Tingting and Zhao, Pengpeng and Liu, Yanchi and Sheng, Victor S. and Xu, Jiajie and Wang, Deqing and Liu, Guanfeng and Zhou, Xiaofang},
	month = aug,
	year = {2019},
	keywords = {notion},
	pages = {4320--4326},
}

@article{sharma_medfusenet_2021,
	title = {{MedFuseNet}: {An} attention-based multimodal deep learning model for visual question answering in the medical domain},
	volume = {11},
	issn = {2045-2322},
	shorttitle = {{MedFuseNet}},
	url = {https://www.nature.com/articles/s41598-021-98390-1},
	doi = {10.1038/s41598-021-98390-1},
	abstract = {Abstract
            
              Medical images are difficult to comprehend for a person without expertise. The scarcity of medical practitioners across the globe often face the issue of physical and mental fatigue due to the high number of cases, inducing human errors during the diagnosis. In such scenarios, having an additional opinion can be helpful in boosting the confidence of the decision maker. Thus, it becomes crucial to have a reliable visual question answering (VQA) system to provide a ‘second opinion’ on medical cases. However, most of the VQA systems that work today cater to real-world problems and are not specifically tailored for handling medical images. Moreover, the VQA system for medical images needs to consider a limited amount of training data available in this domain. In this paper, we develop
              MedFuseNet
              , an attention-based multimodal deep learning model, for VQA on medical images taking the associated challenges into account. Our
              MedFuseNet
              aims at maximizing the learning with minimal complexity by breaking the problem statement into simpler tasks and predicting the answer. We tackle two types of answer prediction—categorization and generation. We conducted an extensive set of quantitative and qualitative analyses to evaluate the performance of
              MedFuseNet
              . Our experiments demonstrate that
              MedFuseNet
              outperforms the state-of-the-art VQA methods, and that visualization of the captured attentions showcases the intepretability of our model’s predicted results.},
	language = {en},
	number = {1},
	urldate = {2023-11-22},
	journal = {Scientific Reports},
	author = {Sharma, Dhruv and Purushotham, Sanjay and Reddy, Chandan K.},
	month = oct,
	year = {2021},
	pages = {19826},
}

@article{xiao_integrating_2023,
	title = {Integrating multimodal information in machine learning for classifying acute myocardial infarction},
	volume = {44},
	issn = {0967-3334, 1361-6579},
	url = {https://iopscience.iop.org/article/10.1088/1361-6579/acc77f},
	doi = {10.1088/1361-6579/acc77f},
	abstract = {Abstract
            
              Objective
              . Prompt identification and recognization of myocardial ischemia/infarction (MI) is the most important goal in the management of acute coronary syndrome. The 12-lead electrocardiogram (ECG) is widely used as the initial screening tool for patients with chest pain but its diagnostic accuracy remains limited. There is early evidence that machine learning (ML) algorithms applied to ECG waveforms can improve performance. Most studies are designed to classify MI from healthy controls and thus are limited due to the lack of consideration of ECG abnormalities from other cardiac conditions, leading to false positives. Moreover, clinical information beyond ECG has not yet been well leveraged in existing ML models.
              Approach.
              The present study considered downstream clinical implementation scenarios in the initial model design by dichotomizing study recordings from a public large-scale ECG dataset into a MI class and a non-MI class with the inclusion of MI-confounding conditions. Two experiments were conducted to systematically investigate the impact of two important factors entrained in the modeling process, including the duration of ECG, and the value of multimodal information for model training. A novel multimodal deep learning architecture was proposed to learn joint features from both ECG and patient demographics.
              Main results.
              The multimodal model achieved better performance than the ECG-only model, with a mean area under the receiver operating characteristic curve of 92.1\% and a mean accuracy of 87.4\%, which is on par with existing studies despite the increased task difficulty due to the new class definition. By investigation of model explainability, it revealed the contribution of patient information in model performance and clinical concordance of the model’s attention with existing clinical insights.
              Significance.
              The findings in this study help guide the development of ML solutions for prompt MI detection and move the models one step closer to real-world clinical applications.},
	number = {4},
	urldate = {2023-11-22},
	journal = {Physiological Measurement},
	author = {Xiao, Ran and Ding, Cheng and Hu, Xiao and Clifford, Gari D and Wright, David W and Shah, Amit J and Al-Zaiti, Salah and Zègre-Hemsey, Jessica K},
	month = apr,
	year = {2023},
	pages = {044002},
}

@article{han_classification_2020,
	title = {Classification of pilots’ mental states using a multimodal deep learning network},
	volume = {40},
	issn = {02085216},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0208521619304887},
	doi = {10.1016/j.bbe.2019.12.002},
	language = {en},
	number = {1},
	urldate = {2023-11-22},
	journal = {Biocybernetics and Biomedical Engineering},
	author = {Han, Soo-Yeon and Kwak, No-Sang and Oh, Taegeun and Lee, Seong-Whan},
	month = jan,
	year = {2020},
	keywords = {notion},
	pages = {324--336},
}

@inproceedings{bhatti_attentive_2021,
	address = {Nara, Japan},
	title = {Attentive {Cross}-modal {Connections} for {Deep} {Multimodal} {Wearable}-based {Emotion} {Recognition}},
	isbn = {978-1-66540-021-3},
	url = {https://ieeexplore.ieee.org/document/9666360/},
	doi = {10.1109/ACIIW52867.2021.9666360},
	urldate = {2023-11-22},
	booktitle = {2021 9th {International} {Conference} on {Affective} {Computing} and {Intelligent} {Interaction} {Workshops} and {Demos} ({ACIIW})},
	publisher = {IEEE},
	author = {Bhatti, Anubhav and Behinaein, Behnam and Rodenburg, Dirk and Hungler, Paul and Etemad, Ali},
	month = sep,
	year = {2021},
	keywords = {notion},
	pages = {01--05},
}

@inproceedings{suo_metric_2019,
	address = {Macao, China},
	title = {Metric {Learning} on {Healthcare} {Data} with {Incomplete} {Modalities}},
	isbn = {978-0-9992411-4-1},
	url = {https://www.ijcai.org/proceedings/2019/490},
	doi = {10.24963/ijcai.2019/490},
	abstract = {Utilizing multiple modalities to learn a good distance metric is of vital importance for various clinical applications. However, it is common that modalities are incomplete for some patients due to various technical and practical reasons in healthcare datasets. Existing metric learning methods cannot directly learn the distance metric on such data with missing modalities. Nevertheless, the incomplete data contains valuable information to characterize patient similarity and modality relationships, and they should not be ignored during the learning process. To tackle the aforementioned challenges, we propose a metric learning framework to perform missing modality completion and multi-modal metric learning simultaneously. Employing the generative adversarial networks, we incorporate both complete and incomplete data to learn the mapping relationship between modalities. After completing the missing modalities, we use the nonlinear representations extracted by the discriminator to learn the distance metric among patients. Through jointly training the adversarial generation part and metric learning, the similarity among patients can be learned on data with missing modalities. Experimental results show that the proposed framework learns more accurate distance metric on real-world healthcare datasets with incomplete modalities, comparing with the state-of-the-art approaches. Meanwhile, the quality of the generated modalities can be preserved.},
	language = {en},
	urldate = {2023-11-21},
	booktitle = {Proceedings of the {Twenty}-{Eighth} {International} {Joint} {Conference} on {Artificial} {Intelligence}},
	publisher = {International Joint Conferences on Artificial Intelligence Organization},
	author = {Suo, Qiuling and Zhong, Weida and Ma, Fenglong and Yuan, Ye and Gao, Jing and Zhang, Aidong},
	month = aug,
	year = {2019},
	keywords = {notion},
	pages = {3534--3540},
}

@article{golrizkhatami_ecg_2018,
	title = {{ECG} classification using three-level fusion of different feature descriptors},
	volume = {114},
	issn = {09574174},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0957417418304469},
	doi = {10.1016/j.eswa.2018.07.030},
	language = {en},
	urldate = {2023-11-22},
	journal = {Expert Systems with Applications},
	author = {Golrizkhatami, Zahra and Acan, Adnan},
	month = dec,
	year = {2018},
	keywords = {notion},
	pages = {54--64},
}

@article{cui_deep_2023,
	title = {Deep learning-based multidimensional feature fusion for classification of {ECG} arrhythmia},
	volume = {35},
	issn = {0941-0643, 1433-3058},
	url = {https://link.springer.com/10.1007/s00521-021-06487-5},
	doi = {10.1007/s00521-021-06487-5},
	language = {en},
	number = {22},
	urldate = {2023-11-22},
	journal = {Neural Computing and Applications},
	author = {Cui, Jianfeng and Wang, Lixin and He, Xiangmin and De Albuquerque, Victor Hugo C. and AlQahtani, Salman A. and Hassan, Mohammad Mehedi},
	month = aug,
	year = {2023},
	keywords = {notion},
	pages = {16073--16087},
}

@article{ahmad_ecg_2021,
	title = {{ECG} {Heartbeat} {Classification} {Using} {Multimodal} {Fusion}},
	volume = {9},
	issn = {2169-3536},
	url = {https://ieeexplore.ieee.org/document/9486862/},
	doi = {10.1109/ACCESS.2021.3097614},
	urldate = {2023-11-22},
	journal = {IEEE Access},
	author = {Ahmad, Zeeshan and Tabassum, Anika and Guan, Ling and Khan, Naimul Mefraz},
	year = {2021},
	keywords = {notion},
	pages = {100615--100626},
}

@misc{nagrani_attention_2022,
	title = {Attention {Bottlenecks} for {Multimodal} {Fusion}},
	url = {http://arxiv.org/abs/2107.00135},
	abstract = {Humans perceive the world by concurrently processing and fusing high-dimensional inputs from multiple modalities such as vision and audio. Machine perception models, in stark contrast, are typically modality-specific and optimised for unimodal benchmarks, and hence late-stage fusion of final representations or predictions from each modality (`late-fusion') is still a dominant paradigm for multimodal video classification. Instead, we introduce a novel transformer based architecture that uses `fusion bottlenecks' for modality fusion at multiple layers. Compared to traditional pairwise self-attention, our model forces information between different modalities to pass through a small number of bottleneck latents, requiring the model to collate and condense the most relevant information in each modality and only share what is necessary. We find that such a strategy improves fusion performance, at the same time reducing computational cost. We conduct thorough ablation studies, and achieve state-of-the-art results on multiple audio-visual classification benchmarks including Audioset, Epic-Kitchens and VGGSound. All code and models will be released.},
	urldate = {2023-11-21},
	publisher = {arXiv},
	author = {Nagrani, Arsha and Yang, Shan and Arnab, Anurag and Jansen, Aren and Schmid, Cordelia and Sun, Chen},
	month = nov,
	year = {2022},
	note = {arXiv:2107.00135 [cs]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, notion},
}

@article{hendricks_decoupling_2021,
	title = {Decoupling the {Role} of {Data}, {Attention}, and {Losses} in {Multimodal} {Transformers}},
	volume = {9},
	issn = {2307-387X},
	url = {https://direct.mit.edu/tacl/article/doi/10.1162/tacl_a_00385/102847/Decoupling-the-Role-of-Data-Attention-and-Losses},
	doi = {10.1162/tacl_a_00385},
	abstract = {Abstract
            Recently, multimodal transformer models have gained popularity because their performance on downstream tasks suggests they learn rich visual-linguistic representations. Focusing on zero-shot image retrieval tasks, we study three important factors that can impact the quality of learned representations: pretraining data, the attention mechanism, and loss functions. By pretraining models on six datasets, we observe that dataset noise and language similarity to our downstream task are important indicators of model performance. Through architectural analysis, we learn that models with a multimodal attention mechanism can outperform deeper models with modality-specific attention mechanisms. Finally, we show that successful contrastive losses used in the self-supervised learning literature do not yield similar performance gains when used in multimodal transformers.},
	language = {en},
	urldate = {2023-11-21},
	journal = {Transactions of the Association for Computational Linguistics},
	author = {Hendricks, Lisa Anne and Mellor, John and Schneider, Rosalia and Alayrac, Jean-Baptiste and Nematzadeh, Aida},
	month = jul,
	year = {2021},
	pages = {570--585},
}

@misc{qiao_topology-aware_2023,
	title = {Topology-aware {Robust} {Optimization} for {Out}-of-distribution {Generalization}},
	url = {http://arxiv.org/abs/2307.13943},
	abstract = {Out-of-distribution (OOD) generalization is a challenging machine learning problem yet highly desirable in many high-stake applications. Existing methods suffer from overly pessimistic modeling with low generalization confidence. As generalizing to arbitrary test distributions is impossible, we hypothesize that further structure on the topology of distributions is crucial in developing strong OOD resilience. To this end, we propose topology-aware robust optimization (TRO) that seamlessly integrates distributional topology in a principled optimization framework. More specifically, TRO solves two optimization objectives: (1) Topology Learning which explores data manifold to uncover the distributional topology; (2) Learning on Topology which exploits the topology to constrain robust optimization for tightly-bounded generalization risks. We theoretically demonstrate the effectiveness of our approach and empirically show that it significantly outperforms the state of the arts in a wide range of tasks including classification, regression, and semantic segmentation. Moreover, we empirically find the data-driven distributional topology is consistent with domain knowledge, enhancing the explainability of our approach.},
	urldate = {2023-11-20},
	publisher = {arXiv},
	author = {Qiao, Fengchun and Peng, Xi},
	month = jul,
	year = {2023},
	note = {arXiv:2307.13943 [cs]},
	keywords = {Computer Science - Machine Learning, notion},
}

@article{ma_are_nodate,
	title = {Are {Multimodal} {Transformers} {Robust} to {Missing} {Modality}?},
	abstract = {Multimodal data collected from the real world are often imperfect due to missing modalities. Therefore multimodal models that are robust against modal-incomplete data are highly preferred. Recently, Transformer models have shown great success in processing multimodal data. However, existing work has been limited to either architecture designs or pre-training strategies; whether Transformer models are naturally robust against missing-modal data has rarely been investigated. In this paper, we present the firstof-its-kind work to comprehensively investigate the behavior of Transformers in the presence of modal-incomplete data. Unsurprising, we find Transformer models are sensitive to missing modalities while different modal fusion strategies will significantly affect the robustness. What surprised us is that the optimal fusion strategy is dataset dependent even for the same Transformer model; there does not exist a universal strategy that works in general cases. Based on these findings, we propose a principle method to improve the robustness of Transformer models by automatically searching for an optimal fusion strategy regarding input data. Experimental validations on three benchmarks support the superior performance of the proposed method.},
	language = {en},
	author = {Ma, Mengmeng and Ren, Jian and Zhao, Long and Testuggine, Davide and Peng, Xi},
	keywords = {notion},
}

@article{ma_smil_nodate,
	title = {{SMIL}: {Multimodal} {Learning} with {Severely} {Missing} {Modality}},
	abstract = {A common assumption in multimodal learning is the completeness of training data, i.e., full modalities are available in all training examples. Although there exists research endeavor in developing novel methods to tackle the incompleteness of testing data, e.g., modalities are partially missing in testing examples, few of them can handle incomplete training modalities. The problem becomes even more challenging if considering the case of severely missing, e.g., ninety percent of training examples may have incomplete modalities. For the ﬁrst time in the literature, this paper formally studies multimodal learning with missing modality in terms of ﬂexibility (missing modalities in training, testing, or both) and efﬁciency (most training data have incomplete modality). Technically, we propose a new method named SMIL that leverages Bayesian meta-learning in uniformly achieving both objectives. To validate our idea, we conduct a series of experiments on three popular benchmarks: MM-IMDb, CMU-MOSI, and avMNIST. The results prove the state-of-the-art performance of SMIL over existing methods and generative baselines including autoencoders and generative adversarial networks.},
	language = {en},
	author = {Ma, Mengmeng and Ren, Jian and Zhao, Long and Tulyakov, Sergey and Wu, Cathy and Peng, Xi},
	keywords = {notion},
}

@article{zhang_semi-identical_2023,
	title = {Semi-{Identical} {Twins} {Variational} {AutoEncoder} for {Few}-{Shot} {Learning}},
	issn = {2162-237X, 2162-2388},
	url = {https://ieeexplore.ieee.org/document/10012316/},
	doi = {10.1109/TNNLS.2022.3233553},
	abstract = {Data augmentation is a popular way for few-shot learning (FSL). It generates more samples as supplements and then transforms the FSL task into a common supervised learning problem for a solution. However, most data-augmentation-based FSL approaches only consider the prior visual knowledge for feature generation, thereby leading to low diversity and poor quality of generated data. In this study, we attempt to address this issue by incorporating both prior visual and prior semantic knowledge to condition the feature generation process. Inspired by some genetic characteristics of semi-identical twins, a novel multimodal generative FSL approach was developed named semiidentical twins variational autoencoder (STVAE) to better exploit the complementarity of these modality information by considering the multimodal conditional feature generation process as a process that semi-identical twins are born and collaborate to simulate their father. STVAE conducts feature synthesis by pairing two conditional variational autoencoders (CVAEs) with the same seed but different modality conditions. Subsequently, the generated features of two CVAEs are considered as semiidentical twins and adaptively combined to yield the ﬁnal feature, which is considered as their fake father. STVAE requires that the ﬁnal feature can be converted back into its paired conditions while ensuring these conditions remain consistent with the original in both representation and function. Moreover, STVAE is able to work in the partial modality-absence case due to the adaptive linear feature combination strategy. STVAE essentially provides a novel idea to exploit the complementarity of different modality prior information inspired by genetics in FSL. Extensive experimental results demonstrate that our work achieves promising performances in comparison to the recent state-of-the-art approaches, as well as validate its effectiveness on FSL under various modality settings.},
	language = {en},
	urldate = {2023-11-20},
	journal = {IEEE Transactions on Neural Networks and Learning Systems},
	author = {Zhang, Yi and Huang, Sheng and Peng, Xi and Yang, Dan},
	year = {2023},
	keywords = {notion},
	pages = {1--15},
}

@article{peng_out--domain_2022,
	title = {Out-of-{Domain} {Generalization} {From} a {Single} {Source}: {An} {Uncertainty} {Quantification} {Approach}},
	issn = {0162-8828, 2160-9292, 1939-3539},
	shorttitle = {Out-of-{Domain} {Generalization} {From} a {Single} {Source}},
	url = {https://ieeexplore.ieee.org/document/9801711/},
	doi = {10.1109/TPAMI.2022.3184598},
	abstract = {We are concerned with a worst-case scenario in model generalization, in the sense that a model aims to perform well on many unseen domains while there is only one single domain available for training. We propose Meta-Learning based Adversarial Domain Augmentation to solve this Out-of-Domain generalization problem. The key idea is to leverage adversarial training to create “fictitious” yet “challenging” populations, from which a model can learn to generalize with theoretical guarantees. To facilitate fast and desirable domain augmentation, we cast the model training in a meta-learning scheme and use a Wasserstein Auto-Encoder to relax the widely used worst-case constraint. We further improve our method by integrating uncertainty quantification for efficient domain generalization. Extensive experiments on multiple benchmark datasets indicate its superior performance in tackling single domain generalization.},
	language = {en},
	urldate = {2023-11-20},
	journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
	author = {Peng, Xi and Qiao, Fengchun and Zhao, Long},
	year = {2022},
	keywords = {notion},
	pages = {1--13},
}

@misc{li_are_2023,
	title = {Are {Data}-driven {Explanations} {Robust} against {Out}-of-distribution {Data}?},
	url = {http://arxiv.org/abs/2303.16390},
	abstract = {As black-box models increasingly power high-stakes applications, a variety of data-driven explanation methods have been introduced. Meanwhile, machine learning models are constantly challenged by distributional shifts. A question naturally arises: Are data-driven explanations robust against out-of-distribution data? Our empirical results show that even though predict correctly, the model might still yield unreliable explanations under distributional shifts. How to develop robust explanations against out-of-distribution data? To address this problem, we propose an end-to-end model-agnostic learning framework Distributionally Robust Explanations (DRE). The key idea is, inspired by self-supervised learning, to fully utilizes the inter-distribution information to provide supervisory signals for the learning of explanations without human annotation. Can robust explanations benefit the model’s generalization capability? We conduct extensive experiments on a wide range of tasks and data types, including classification and regression on image and scientific tabular data. Our results demonstrate that the proposed method significantly improves the model’s performance in terms of explanation and prediction robustness against distributional shifts.},
	language = {en},
	urldate = {2023-11-20},
	publisher = {arXiv},
	author = {Li, Tang and Qiao, Fengchun and Ma, Mengmeng and Peng, Xi},
	month = mar,
	year = {2023},
	note = {arXiv:2303.16390 [cs]},
	keywords = {Computer Science - Machine Learning, notion},
}

@article{ansari_deep_2023,
	title = {Deep learning for {ECG} {Arrhythmia} detection and classification: an overview of progress for period 2017–2023},
	volume = {14},
	issn = {1664-042X},
	shorttitle = {Deep learning for {ECG} {Arrhythmia} detection and classification},
	url = {https://www.frontiersin.org/articles/10.3389/fphys.2023.1246746/full},
	doi = {10.3389/fphys.2023.1246746},
	abstract = {Cardiovascular diseases are a leading cause of mortality globally. Electrocardiography (ECG) still represents the benchmark approach for identifying cardiac irregularities. Automatic detection of abnormalities from the ECG can aid in the early detection, diagnosis, and prevention of cardiovascular diseases. Deep Learning (DL) architectures have been successfully employed for arrhythmia detection and classification and offered superior performance to traditional shallow Machine Learning (ML) approaches. This survey categorizes and compares the DL architectures used in ECG arrhythmia detection from 2017–2023 that have exhibited superior performance. Different DL models such as Convolutional Neural Networks (CNNs), Multilayer Perceptrons (MLPs), Transformers, and Recurrent Neural Networks (RNNs) are reviewed, and a summary of their effectiveness is provided. This survey provides a comprehensive roadmap to expedite the acclimation process for emerging researchers willing to develop efficient algorithms for detecting ECG anomalies using DL models. Our tailored guidelines bridge the knowledge gap allowing newcomers to align smoothly with the prevailing research trends in ECG arrhythmia detection. We shed light on potential areas for future research and refinement in model development and optimization, intending to stimulate advancement in ECG arrhythmia detection and classification.},
	urldate = {2023-11-17},
	journal = {Frontiers in Physiology},
	author = {Ansari, Yaqoob and Mourad, Omar and Qaraqe, Khalid and Serpedin, Erchin},
	month = sep,
	year = {2023},
	keywords = {notion},
	pages = {1246746},
}

@article{han_multimodal_2023,
	title = {Multimodal multi-instance learning for long-term {ECG} classification},
	volume = {270},
	issn = {09507051},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0950705123003052},
	doi = {10.1016/j.knosys.2023.110555},
	language = {en},
	urldate = {2023-11-17},
	journal = {Knowledge-Based Systems},
	author = {Han, Haozhan and Lian, Cheng and Zeng, Zhigang and Xu, Bingrong and Zang, Junbin and Xue, Chenyang},
	month = jun,
	year = {2023},
	keywords = {notion},
	pages = {110555},
}

@article{yang_multi-view_2023,
	title = {A {Multi}-{View} {Multi}-{Scale} {Neural} {Network} for {Multi}-{Label} {ECG} {Classification}},
	volume = {7},
	issn = {2471-285X},
	url = {https://ieeexplore.ieee.org/document/10021962/},
	doi = {10.1109/TETCI.2023.3235374},
	number = {3},
	urldate = {2023-11-17},
	journal = {IEEE Transactions on Emerging Topics in Computational Intelligence},
	author = {Yang, Shunxiang and Lian, Cheng and Zeng, Zhigang and Xu, Bingrong and Zang, Junbin and Zhang, Zhidong},
	month = jun,
	year = {2023},
	keywords = {notion},
	pages = {648--660},
}

@article{xiao_deep_2023,
	title = {Deep {Learning}-{Based} {ECG} {Arrhythmia} {Classification}: {A} {Systematic} {Review}},
	volume = {13},
	issn = {2076-3417},
	shorttitle = {Deep {Learning}-{Based} {ECG} {Arrhythmia} {Classification}},
	url = {https://www.mdpi.com/2076-3417/13/8/4964},
	doi = {10.3390/app13084964},
	abstract = {Deep learning (DL) has been introduced in automatic heart-abnormality classification using ECG signals, while its application in practical medical procedures is limited. A systematic review is performed from perspectives of the ECG database, preprocessing, DL methodology, evaluation paradigm, performance metric, and code availability to identify research trends, challenges, and opportunities for DL-based ECG arrhythmia classification. Specifically, 368 studies meeting the eligibility criteria are included. A total of 223 (61\%) studies use MIT-BIH Arrhythmia Database to design DL models. A total of 138 (38\%) studies considered removing noise or artifacts in ECG signals, and 102 (28\%) studies performed data augmentation to extend the minority arrhythmia categories. Convolutional neural networks are the dominant models (58.7\%, 216) used in the reviewed studies while growing studies have integrated multiple DL structures in recent years. A total of 319 (86.7\%) and 38 (10.3\%) studies explicitly mention their evaluation paradigms, i.e., intra- and inter-patient paradigms, respectively, where notable performance degradation is observed in the inter-patient paradigm. Compared to the overall accuracy, the average F1 score, sensitivity, and precision are significantly lower in the selected studies. To implement the DL-based ECG classification in real clinical scenarios, leveraging diverse ECG databases, designing advanced denoising and data augmentation techniques, integrating novel DL models, and deeper investigation in the inter-patient paradigm could be future research opportunities.},
	language = {en},
	number = {8},
	urldate = {2023-11-17},
	journal = {Applied Sciences},
	author = {Xiao, Qiao and Lee, Khuan and Mokhtar, Siti Aisah and Ismail, Iskasymar and Pauzi, Ahmad Luqman Bin Md and Zhang, Qiuxia and Lim, Poh Ying},
	month = apr,
	year = {2023},
	keywords = {notion},
	pages = {4964},
}

@article{zhang_patient2vec_2018,
	title = {{Patient2Vec}: {A} {Personalized} {Interpretable} {Deep} {Representation} of the {Longitudinal} {Electronic} {Health} {Record}},
	volume = {6},
	issn = {2169-3536},
	shorttitle = {{Patient2Vec}},
	url = {http://arxiv.org/abs/1810.04793},
	doi = {10.1109/ACCESS.2018.2875677},
	abstract = {The wide implementation of electronic health record (EHR) systems facilitates the collection of large-scale health data from real clinical settings. Despite the significant increase in adoption of EHR systems, this data remains largely unexplored, but presents a rich data source for knowledge discovery from patient health histories in tasks such as understanding disease correlations and predicting health outcomes. However, the heterogeneity, sparsity, noise, and bias in this data present many complex challenges. This complexity makes it difficult to translate potentially relevant information into machine learning algorithms. In this paper, we propose a computational framework, Patient2Vec, to learn an interpretable deep representation of longitudinal EHR data which is personalized for each patient. To evaluate this approach, we apply it to the prediction of future hospitalizations using real EHR data and compare its predictive performance with baseline methods. Patient2Vec produces a vector space with meaningful structure and it achieves an AUC around 0.799 outperforming baseline methods. In the end, the learned feature importance can be visualized and interpreted at both the individual and population levels to bring clinical insights.},
	urldate = {2023-11-14},
	journal = {IEEE Access},
	author = {Zhang, Jinghe and Kowsari, Kamran and Harrison, James H. and Lobo, Jennifer M. and Barnes, Laura E.},
	year = {2018},
	note = {arXiv:1810.04793 [cs, q-bio, stat]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Information Retrieval, Computer Science - Machine Learning, Quantitative Biology - Quantitative Methods, Statistics - Machine Learning, notion},
	pages = {65333--65346},
}

@misc{noauthor_patient2vec_nodate,
	title = {{Patient2Vec}: {A} {Personalized} {Interpretable} {Deep} {Representation} of the {Longitudinal} {Electronic} {Health} {Record} {\textbar} {IEEE} {Journals} \& {Magazine} {\textbar} {IEEE} {Xplore}},
	url = {https://ieeexplore.ieee.org/document/8490816},
	urldate = {2023-11-14},
}

@inproceedings{park_frequency-aware_2018,
	address = {Jeju},
	title = {Frequency-{Aware} {Attention} based {LSTM} {Networks} for {Cardiovascular} {Disease}},
	isbn = {978-1-5386-5041-7},
	url = {https://ieeexplore.ieee.org/document/8539509/},
	doi = {10.1109/ICTC.2018.8539509},
	abstract = {There are various medical features associated with cardiovascular disease in the EMR data, but the frequency of each medical feature is different. Less frequent feature may be considered as non-critical feature, although cardiovascular disease is closely associated in the cardiovascular disease risk prediction model. We propose a frequency-aware based Attentionbased LSTM (FA-Attn-LSTM) that weighs on important medical features using an attention mechanism that considers the frequency of each medical feature. Our model predicts the risk for cardiovascular disease using the ejection fraction as a prediction target and shows RMSE = 3.65 and MAE = 2.49.},
	language = {en},
	urldate = {2023-11-14},
	booktitle = {2018 {International} {Conference} on {Information} and {Communication} {Technology} {Convergence} ({ICTC})},
	publisher = {IEEE},
	author = {Park, Hwin Dol and Han, Youngwoong and Choi, Jae Hun},
	month = oct,
	year = {2018},
	keywords = {notion},
	pages = {1503--1505},
}

@article{guo_interpretable_2019,
	title = {An {Interpretable} {Disease} {Onset} {Predictive} {Model} {Using} {Crossover} {Attention} {Mechanism} {From} {Electronic} {Health} {Records}},
	volume = {7},
	issn = {2169-3536},
	url = {https://ieeexplore.ieee.org/document/8761846},
	doi = {10.1109/ACCESS.2019.2928579},
	abstract = {Analysis of patients' Electronic Health Records (EHRs) can help guide the prevention of diseases and personalization of treatment. Therefore, it is an important task to predict the disease onset information (referred to as medical codes in this paper) within the upcoming visit based on patients' EHR data. In order to achieve this objective, the real-time nature and high dimensionality of EHR data must be addressed. Moreover, the prediction results of the model must be interpretable. Existing methods mainly use Recurrent Neural Networks (RNNs) to model EHR data and adopt attention mechanism to provide interpretability. However, diagnosis and treatment information have usually been regarded as the same kind of information, the difference and relationship between the two parts being ignored. This has led to unclear analysis about the patient's disease development and inaccurate prediction results. To address this limitation, we propose a CrossOver Attention Model (COAM). This model adopts two RNNs to process diagnosis and treatment information, respectively, and then deploys a crossover attention mechanism to improve prediction accuracy by leveraging the correlation between the two parts of information. It can learn effective representations of personal medical diagnosis and treatment, and provide interpretable prediction results. Experiments demonstrate that COAM can significantly improve the accuracy of prediction and provide clinically meaningful explanations.},
	urldate = {2023-11-13},
	journal = {IEEE Access},
	author = {Guo, Wei and Ge, Wei and Cui, Lizhen and Li, Hui and Kong, Lanju},
	year = {2019},
	note = {Conference Name: IEEE Access},
	keywords = {notion},
	pages = {134236--134244},
}

@inproceedings{luo_hitanet_2020,
	address = {Virtual Event CA USA},
	title = {{HiTANet}: {Hierarchical} {Time}-{Aware} {Attention} {Networks} for {Risk} {Prediction} on {Electronic} {Health} {Records}},
	isbn = {978-1-4503-7998-4},
	shorttitle = {{HiTANet}},
	url = {https://dl.acm.org/doi/10.1145/3394486.3403107},
	doi = {10.1145/3394486.3403107},
	language = {en},
	urldate = {2023-11-09},
	booktitle = {Proceedings of the 26th {ACM} {SIGKDD} {International} {Conference} on {Knowledge} {Discovery} \& {Data} {Mining}},
	publisher = {ACM},
	author = {Luo, Junyu and Ye, Muchao and Xiao, Cao and Ma, Fenglong},
	month = aug,
	year = {2020},
	keywords = {notion},
	pages = {647--656},
}

@article{soenksen_integrated_2022,
	title = {Integrated multimodal artificial intelligence framework for healthcare applications},
	volume = {5},
	issn = {2398-6352},
	url = {https://www.nature.com/articles/s41746-022-00689-4},
	doi = {10.1038/s41746-022-00689-4},
	abstract = {Abstract
            
              Artificial intelligence (AI) systems hold great promise to improve healthcare over the next decades. Specifically, AI systems leveraging multiple data sources and input modalities are poised to become a viable method to deliver more accurate results and deployable pipelines across a wide range of applications. In this work, we propose and evaluate a unified Holistic AI in Medicine (HAIM) framework to facilitate the generation and testing of AI systems that leverage multimodal inputs. Our approach uses generalizable data pre-processing and machine learning modeling stages that can be readily adapted for research and deployment in healthcare environments. We evaluate our HAIM framework by training and characterizing 14,324 independent models based on HAIM-MIMIC-MM, a multimodal clinical database (
              N
               = 34,537 samples) containing 7279 unique hospitalizations and 6485 patients, spanning all possible input combinations of 4 data modalities (i.e., tabular, time-series, text, and images), 11 unique data sources and 12 predictive tasks. We show that this framework can consistently and robustly produce models that outperform similar single-source approaches across various healthcare demonstrations (by 6–33\%), including 10 distinct chest pathology diagnoses, along with length-of-stay and 48 h mortality predictions. We also quantify the contribution of each modality and data source using Shapley values, which demonstrates the heterogeneity in data modality importance and the necessity of multimodal inputs across different healthcare-relevant tasks. The generalizable properties and flexibility of our Holistic AI in Medicine (HAIM) framework could offer a promising pathway for future multimodal predictive systems in clinical and operational healthcare settings.},
	language = {en},
	number = {1},
	urldate = {2023-11-09},
	journal = {npj Digital Medicine},
	author = {Soenksen, Luis R. and Ma, Yu and Zeng, Cynthia and Boussioux, Leonard and Villalobos Carballo, Kimberly and Na, Liangyuan and Wiberg, Holly M. and Li, Michael L. and Fuentes, Ignacio and Bertsimas, Dimitris},
	month = sep,
	year = {2022},
	keywords = {notion},
	pages = {149},
}

@inproceedings{macias_toro_novel_2019,
	title = {Novel {Imputing} {Method} and {Deep} {Learning} {Techniques} for {Early} {Prediction} of {Sepsis} in {Intensive} {Care} {Units}},
	url = {http://www.cinc.org/archives/2019/pdf/CinC2019-038.pdf},
	doi = {10.22489/CinC.2019.038},
	urldate = {2023-11-07},
	author = {Macias Toro, Edwar and Boquet, Guillem and Serrano, Javier and Lopez Vicario, Jose and Ibeas, Jose and Morell, Antoni},
	month = dec,
	year = {2019},
	keywords = {notion},
}

@misc{kazemi_time2vec_2019,
	title = {{Time2Vec}: {Learning} a {Vector} {Representation} of {Time}},
	shorttitle = {{Time2Vec}},
	url = {http://arxiv.org/abs/1907.05321},
	abstract = {Time is an important feature in many applications involving events that occur synchronously and/or asynchronously. To effectively consume time information, recent studies have focused on designing new architectures. In this paper, we take an orthogonal but complementary approach by providing a model-agnostic vector representation for time, called Time2Vec, that can be easily imported into many existing and future architectures and improve their performances. We show on a range of models and problems that replacing the notion of time with its Time2Vec representation improves the performance of the final model.},
	urldate = {2023-11-06},
	publisher = {arXiv},
	author = {Kazemi, Seyed Mehran and Goel, Rishab and Eghbali, Sepehr and Ramanan, Janahan and Sahota, Jaspreet and Thakur, Sanjay and Wu, Stella and Smyth, Cathal and Poupart, Pascal and Brubaker, Marcus},
	month = jul,
	year = {2019},
	note = {arXiv:1907.05321 [cs]},
	keywords = {Computer Science - Machine Learning, notion},
}

@article{xie_benchmarking_2022,
	title = {Benchmarking emergency department prediction models with machine learning and public electronic health records},
	volume = {9},
	issn = {2052-4463},
	url = {https://www.nature.com/articles/s41597-022-01782-9},
	doi = {10.1038/s41597-022-01782-9},
	abstract = {Abstract
            The demand for emergency department (ED) services is increasing across the globe, particularly during the current COVID-19 pandemic. Clinical triage and risk assessment have become increasingly challenging due to the shortage of medical resources and the strain on hospital infrastructure caused by the pandemic. As a result of the widespread use of electronic health records (EHRs), we now have access to a vast amount of clinical data, which allows us to develop prediction models and decision support systems to address these challenges. To date, there is no widely accepted clinical prediction benchmark related to the ED based on large-scale public EHRs. An open-source benchmark data platform would streamline research workflows by eliminating cumbersome data preprocessing, and facilitate comparisons among different studies and methodologies. Based on the Medical Information Mart for Intensive Care IV Emergency Department (MIMIC-IV-ED) database, we created a benchmark dataset and proposed three clinical prediction benchmarks. This study provides future researchers with insights, suggestions, and protocols for managing data and developing predictive tools for emergency care.},
	language = {en},
	number = {1},
	urldate = {2023-11-03},
	journal = {Scientific Data},
	author = {Xie, Feng and Zhou, Jun and Lee, Jin Wee and Tan, Mingrui and Li, Siqi and Rajnthern, Logasan S/O and Chee, Marcel Lucas and Chakraborty, Bibhas and Wong, An-Kwok Ian and Dagan, Alon and Ong, Marcus Eng Hock and Gao, Fei and Liu, Nan},
	month = oct,
	year = {2022},
	keywords = {notion},
	pages = {658},
}

@inproceedings{choi_mime_2018,
	title = {{MiME}: {Multilevel} {Medical} {Embedding} of {Electronic} {Health} {Records} for {Predictive} {Healthcare}},
	volume = {31},
	url = {https://proceedings.neurips.cc/paper_files/paper/2018/file/934b535800b1cba8f96a5d72f72f1611-Paper.pdf},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	publisher = {Curran Associates, Inc.},
	author = {Choi, Edward and Xiao, Cao and Stewart, Walter and Sun, Jimeng},
	editor = {Bengio, S. and Wallach, H. and Larochelle, H. and Grauman, K. and Cesa-Bianchi, N. and Garnett, R.},
	year = {2018},
	keywords = {notion},
}

@article{rasmy_representation_2020,
	title = {Representation of {EHR} data for predictive modeling: a comparison between {UMLS} and other terminologies},
	volume = {27},
	issn = {1067-5027, 1527-974X},
	shorttitle = {Representation of {EHR} data for predictive modeling},
	url = {https://academic.oup.com/jamia/article/27/10/1593/5905876},
	doi = {10.1093/jamia/ocaa180},
	abstract = {Abstract
            
              Objective
              Predictive disease modeling using electronic health record data is a growing field. Although clinical data in their raw form can be used directly for predictive modeling, it is a common practice to map data to standard terminologies to facilitate data aggregation and reuse. There is, however, a lack of systematic investigation of how different representations could affect the performance of predictive models, especially in the context of machine learning and deep learning.
            
            
              Materials and Methods
              We projected the input diagnoses data in the Cerner HealthFacts database to Unified Medical Language System (UMLS) and 5 other terminologies, including CCS, CCSR, ICD-9, ICD-10, and PheWAS, and evaluated the prediction performances of these terminologies on 2 different tasks: the risk prediction of heart failure in diabetes patients and the risk prediction of pancreatic cancer. Two popular models were evaluated: logistic regression and a recurrent neural network.
            
            
              Results
              For logistic regression, using UMLS delivered the optimal area under the receiver operating characteristics (AUROC) results in both dengue hemorrhagic fever (81.15\%) and pancreatic cancer (80.53\%) tasks. For recurrent neural network, UMLS worked best for pancreatic cancer prediction (AUROC 82.24\%), second only (AUROC 85.55\%) to PheWAS (AUROC 85.87\%) for dengue hemorrhagic fever prediction.
            
            
              Discussion/Conclusion
              In our experiments, terminologies with larger vocabularies and finer-grained representations were associated with better prediction performances. In particular, UMLS is consistently 1 of the best-performing ones. We believe that our work may help to inform better designs of predictive models, although further investigation is warranted.},
	language = {en},
	number = {10},
	urldate = {2023-10-17},
	journal = {Journal of the American Medical Informatics Association},
	author = {Rasmy, Laila and Tiryaki, Firat and Zhou, Yujia and Xiang, Yang and Tao, Cui and Xu, Hua and Zhi, Degui},
	month = oct,
	year = {2020},
	pages = {1593--1599},
}

@article{johnson_mimic-iv_2023,
	title = {{MIMIC}-{IV}, a freely accessible electronic health record dataset},
	volume = {10},
	issn = {2052-4463},
	url = {https://www.nature.com/articles/s41597-022-01899-x},
	doi = {10.1038/s41597-022-01899-x},
	abstract = {Abstract
            Digital data collection during routine clinical practice is now ubiquitous within hospitals. The data contains valuable information on the care of patients and their response to treatments, offering exciting opportunities for research. Typically, data are stored within archival systems that are not intended to support research. These systems are often inaccessible to researchers and structured for optimal storage, rather than interpretability and analysis. Here we present MIMIC-IV, a publicly available database sourced from the electronic health record of the Beth Israel Deaconess Medical Center. Information available includes patient measurements, orders, diagnoses, procedures, treatments, and deidentified free-text clinical notes. MIMIC-IV is intended to support a wide array of research studies and educational material, helping to reduce barriers to conducting clinical research.},
	language = {en},
	number = {1},
	urldate = {2023-10-17},
	journal = {Scientific Data},
	author = {Johnson, Alistair E. W. and Bulgarelli, Lucas and Shen, Lu and Gayles, Alvin and Shammout, Ayad and Horng, Steven and Pollard, Tom J. and Hao, Sicheng and Moody, Benjamin and Gow, Brian and Lehman, Li-wei H. and Celi, Leo A. and Mark, Roger G.},
	month = jan,
	year = {2023},
	pages = {1},
}

@article{gupta_extensive_2022,
	title = {An {Extensive} {Data} {Processing} {Pipeline} for {MIMIC}-{IV}},
	volume = {193},
	issn = {2640-3498},
	abstract = {An increasing amount of research is being devoted to applying machine learning methods to electronic health record (EHR) data for various clinical purposes. This growing area of research has exposed the challenges of the accessibility of EHRs. MIMIC is a popular, public, and free EHR dataset in a raw format that has been used in numerous studies. The absence of standardized preprocessing steps can be, however, a significant barrier to the wider adoption of this rare resource. Additionally, this absence can reduce the reproducibility of the developed tools and limit the ability to compare the results among similar studies. In this work, we provide a greatly customizable pipeline to extract, clean, and preprocess the data available in the fourth version of the MIMIC dataset (MIMIC-IV). The pipeline also presents an end-to-end wizard-like package supporting predictive model creations and evaluations. The pipeline covers a range of clinical prediction tasks which can be broadly classified into four categories - readmission, length of stay, mortality, and phenotype prediction. The tool is publicly available at https://github.com/healthylaife/MIMIC-IV-Data-Pipeline.},
	language = {eng},
	journal = {Proceedings of Machine Learning Research},
	author = {Gupta, Mehak and Gallamoza, Brennan and Cutrona, Nicolas and Dhakal, Pranjal and Poulain, Raphael and Beheshti, Rahmatollah},
	month = nov,
	year = {2022},
	pmid = {36686986},
	pmcid = {PMC9854277},
	keywords = {Data preprocessing, Electronic Health Records, MIMIC},
	pages = {311--325},
}

@inproceedings{wang_mimic-extract_2020,
	address = {Toronto Ontario Canada},
	title = {{MIMIC}-{Extract}: a data extraction, preprocessing, and representation pipeline for {MIMIC}-{III}},
	isbn = {978-1-4503-7046-2},
	shorttitle = {{MIMIC}-{Extract}},
	url = {https://dl.acm.org/doi/10.1145/3368555.3384469},
	doi = {10.1145/3368555.3384469},
	language = {en},
	urldate = {2023-10-17},
	booktitle = {Proceedings of the {ACM} {Conference} on {Health}, {Inference}, and {Learning}},
	publisher = {ACM},
	author = {Wang, Shirly and McDermott, Matthew B. A. and Chauhan, Geeticka and Ghassemi, Marzyeh and Hughes, Michael C. and Naumann, Tristan},
	month = apr,
	year = {2020},
	pages = {222--235},
}

@misc{lehman_we_2023,
	title = {Do {We} {Still} {Need} {Clinical} {Language} {Models}?},
	url = {http://arxiv.org/abs/2302.08091},
	abstract = {Although recent advances in scaling large language models (LLMs) have resulted in improvements on many NLP tasks, it remains unclear whether these models trained primarily with general web text are the right tool in highly specialized, safety critical domains such as clinical text. Recent results have suggested that LLMs encode a surprising amount of medical knowledge. This raises an important question regarding the utility of smaller domain-specific language models. With the success of general-domain LLMs, is there still a need for specialized clinical models? To investigate this question, we conduct an extensive empirical analysis of 12 language models, ranging from 220M to 175B parameters, measuring their performance on 3 different clinical tasks that test their ability to parse and reason over electronic health records. As part of our experiments, we train T5-Base and T5-Large models from scratch on clinical notes from MIMIC III and IV to directly investigate the efficiency of clinical tokens. We show that relatively small specialized clinical models substantially outperform all in-context learning approaches, even when finetuned on limited annotated data. Further, we find that pretraining on clinical tokens allows for smaller, more parameter-efficient models that either match or outperform much larger language models trained on general text. We release the code and the models used under the PhysioNet Credentialed Health Data license and data use agreement.},
	urldate = {2023-10-17},
	publisher = {arXiv},
	author = {Lehman, Eric and Hernandez, Evan and Mahajan, Diwakar and Wulff, Jonas and Smith, Micah J. and Ziegler, Zachary and Nadler, Daniel and Szolovits, Peter and Johnson, Alistair and Alsentzer, Emily},
	month = feb,
	year = {2023},
	note = {arXiv:2302.08091 [cs]},
	keywords = {Computer Science - Computation and Language, notion},
}

@misc{choi_retain_2017,
	title = {{RETAIN}: {An} {Interpretable} {Predictive} {Model} for {Healthcare} using {Reverse} {Time} {Attention} {Mechanism}},
	shorttitle = {{RETAIN}},
	url = {http://arxiv.org/abs/1608.05745},
	abstract = {Accuracy and interpretability are two dominant features of successful predictive models. Typically, a choice must be made in favor of complex black box models such as recurrent neural networks (RNN) for accuracy versus less accurate but more interpretable traditional models such as logistic regression. This tradeoff poses challenges in medicine where both accuracy and interpretability are important. We addressed this challenge by developing the REverse Time AttentIoN model (RETAIN) for application to Electronic Health Records (EHR) data. RETAIN achieves high accuracy while remaining clinically interpretable and is based on a two-level neural attention model that detects influential past visits and significant clinical variables within those visits (e.g. key diagnoses). RETAIN mimics physician practice by attending the EHR data in a reverse time order so that recent clinical visits are likely to receive higher attention. RETAIN was tested on a large health system EHR dataset with 14 million visits completed by 263K patients over an 8 year period and demonstrated predictive accuracy and computational scalability comparable to state-of-the-art methods such as RNN, and ease of interpretability comparable to traditional models.},
	urldate = {2023-10-09},
	publisher = {arXiv},
	author = {Choi, Edward and Bahadori, Mohammad Taha and Kulas, Joshua A. and Schuetz, Andy and Stewart, Walter F. and Sun, Jimeng},
	month = feb,
	year = {2017},
	note = {arXiv:1608.05745 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Computer Science - Neural and Evolutionary Computing, notion},
}

@article{rasmy_med-bert_2021,
	title = {Med-{BERT}: pretrained contextualized embeddings on large-scale structured electronic health records for disease prediction},
	volume = {4},
	issn = {2398-6352},
	shorttitle = {Med-{BERT}},
	url = {https://www.nature.com/articles/s41746-021-00455-y},
	doi = {10.1038/s41746-021-00455-y},
	abstract = {Abstract
            Deep learning (DL)-based predictive models from electronic health records (EHRs) deliver impressive performance in many clinical tasks. Large training cohorts, however, are often required by these models to achieve high accuracy, hindering the adoption of DL-based models in scenarios with limited training data. Recently, bidirectional encoder representations from transformers (BERT) and related models have achieved tremendous successes in the natural language processing domain. The pretraining of BERT on a very large training corpus generates contextualized embeddings that can boost the performance of models trained on smaller datasets. Inspired by BERT, we propose Med-BERT, which adapts the BERT framework originally developed for the text domain to the structured EHR domain. Med-BERT is a contextualized embedding model pretrained on a structured EHR dataset of 28,490,650 patients. Fine-tuning experiments showed that Med-BERT substantially improves the prediction accuracy, boosting the area under the receiver operating characteristics curve (AUC) by 1.21–6.14\% in two disease prediction tasks from two clinical databases. In particular, pretrained Med-BERT obtains promising performances on tasks with small fine-tuning training sets and can boost the AUC by more than 20\% or obtain an AUC as high as a model trained on a training set ten times larger, compared with deep learning models without Med-BERT. We believe that Med-BERT will benefit disease prediction studies with small local training datasets, reduce data collection expenses, and accelerate the pace of artificial intelligence aided healthcare.},
	language = {en},
	number = {1},
	urldate = {2023-10-09},
	journal = {npj Digital Medicine},
	author = {Rasmy, Laila and Xiang, Yang and Xie, Ziqian and Tao, Cui and Zhi, Degui},
	month = may,
	year = {2021},
	keywords = {notion},
	pages = {86},
}

@misc{li_hi-behrt_2021,
	title = {Hi-{BEHRT}: {Hierarchical} {Transformer}-based model for accurate prediction of clinical events using multimodal longitudinal electronic health records},
	shorttitle = {Hi-{BEHRT}},
	url = {http://arxiv.org/abs/2106.11360},
	abstract = {Electronic health records represent a holistic overview of patients' trajectories. Their increasing availability has fueled new hopes to leverage them and develop accurate risk prediction models for a wide range of diseases. Given the complex interrelationships of medical records and patient outcomes, deep learning models have shown clear merits in achieving this goal. However, a key limitation of these models remains their capacity in processing long sequences. Capturing the whole history of medical encounters is expected to lead to more accurate predictions, but the inclusion of records collected for decades and from multiple resources can inevitably exceed the receptive field of the existing deep learning architectures. This can result in missing crucial, long-term dependencies. To address this gap, we present Hi-BEHRT, a hierarchical Transformer-based model that can significantly expand the receptive field of Transformers and extract associations from much longer sequences. Using a multimodal large-scale linked longitudinal electronic health records, the Hi-BEHRT exceeds the state-of-the-art BEHRT 1\% to 5\% for area under the receiver operating characteristic (AUROC) curve and 3\% to 6\% for area under the precision recall (AUPRC) curve on average, and 3\% to 6\% (AUROC) and 3\% to 11\% (AUPRC) for patients with long medical history for 5-year heart failure, diabetes, chronic kidney disease, and stroke risk prediction. Additionally, because pretraining for hierarchical Transformer is not well-established, we provide an effective end-to-end contrastive pre-training strategy for Hi-BEHRT using EHR, improving its transferability on predicting clinical events with relatively small training dataset.},
	urldate = {2023-10-09},
	publisher = {arXiv},
	author = {Li, Yikuan and Mamouei, Mohammad and Salimi-Khorshidi, Gholamreza and Rao, Shishir and Hassaine, Abdelaali and Canoy, Dexter and Lukasiewicz, Thomas and Rahimi, Kazem},
	month = jun,
	year = {2021},
	note = {arXiv:2106.11360 [cs]},
	keywords = {Computer Science - Machine Learning, notion},
}

@article{li_behrt_2020,
	title = {{BEHRT}: {Transformer} for {Electronic} {Health} {Records}},
	volume = {10},
	issn = {2045-2322},
	shorttitle = {{BEHRT}},
	url = {https://www.nature.com/articles/s41598-020-62922-y},
	doi = {10.1038/s41598-020-62922-y},
	abstract = {Abstract
            Today, despite decades of developments in medicine and the growing interest in precision healthcare, vast majority of diagnoses happen once patients begin to show noticeable signs of illness. Early indication and detection of diseases, however, can provide patients and carers with the chance of early intervention, better disease management, and efficient allocation of healthcare resources. The latest developments in machine learning (including deep learning) provides a great opportunity to address this unmet need. In this study, we introduce BEHRT: A deep neural sequence transduction model for electronic health records (EHR), capable of simultaneously predicting the likelihood of 301 conditions in one’s future visits. When trained and evaluated on the data from nearly 1.6 million individuals, BEHRT shows a striking improvement of 8.0–13.2\% (in terms of average precision scores for different tasks), over the existing state-of-the-art deep EHR models. In addition to its scalability and superior accuracy, BEHRT enables personalised interpretation of its predictions; its flexible architecture enables it to incorporate multiple heterogeneous concepts (e.g., diagnosis, medication, measurements, and more) to further improve the accuracy of its predictions; its (pre-)training results in disease and patient representations can be useful for future studies (i.e., transfer learning).},
	language = {en},
	number = {1},
	urldate = {2023-10-09},
	journal = {Scientific Reports},
	author = {Li, Yikuan and Rao, Shishir and Solares, José Roberto Ayala and Hassaine, Abdelaali and Ramakrishnan, Rema and Canoy, Dexter and Zhu, Yajie and Rahimi, Kazem and Salimi-Khorshidi, Gholamreza},
	month = apr,
	year = {2020},
	keywords = {notion},
	pages = {7155},
}

@misc{sun_retentive_2023,
	title = {Retentive {Network}: {A} {Successor} to {Transformer} for {Large} {Language} {Models}},
	shorttitle = {Retentive {Network}},
	url = {http://arxiv.org/abs/2307.08621},
	abstract = {In this work, we propose Retentive Network (RetNet) as a foundation architecture for large language models, simultaneously achieving training parallelism, low-cost inference, and good performance. We theoretically derive the connection between recurrence and attention. Then we propose the retention mechanism for sequence modeling, which supports three computation paradigms, i.e., parallel, recurrent, and chunkwise recurrent. Specifically, the parallel representation allows for training parallelism. The recurrent representation enables low-cost \$O(1)\$ inference, which improves decoding throughput, latency, and GPU memory without sacrificing performance. The chunkwise recurrent representation facilitates efficient long-sequence modeling with linear complexity, where each chunk is encoded parallelly while recurrently summarizing the chunks. Experimental results on language modeling show that RetNet achieves favorable scaling results, parallel training, low-cost deployment, and efficient inference. The intriguing properties make RetNet a strong successor to Transformer for large language models. Code will be available at https://aka.ms/retnet.},
	urldate = {2023-10-09},
	publisher = {arXiv},
	author = {Sun, Yutao and Dong, Li and Huang, Shaohan and Ma, Shuming and Xia, Yuqing and Xue, Jilong and Wang, Jianyong and Wei, Furu},
	month = aug,
	year = {2023},
	note = {arXiv:2307.08621 [cs]},
	keywords = {Computer Science - Computation and Language, Computer Science - Machine Learning, notion},
}

@article{cabitza_need_2021,
	title = {The need to separate the wheat from the chaff in medical informatics},
	volume = {153},
	issn = {13865056},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S1386505621001362},
	doi = {10.1016/j.ijmedinf.2021.104510},
	language = {en},
	urldate = {2023-09-29},
	journal = {International Journal of Medical Informatics},
	author = {Cabitza, Federico and Campagner, Andrea},
	month = sep,
	year = {2021},
	pages = {104510},
}

@article{noauthor_fairness_2022,
	title = {The {Fairness} {Handbook} - 2022},
	language = {en},
	year = {2022},
}

@incollection{kamp_algorithmic_2021,
	address = {Cham},
	title = {Algorithmic {Factors} {Influencing} {Bias} in {Machine} {Learning}},
	volume = {1524},
	isbn = {978-3-030-93735-5 978-3-030-93736-2},
	url = {https://link.springer.com/10.1007/978-3-030-93736-2_41},
	language = {en},
	urldate = {2023-09-29},
	booktitle = {Machine {Learning} and {Principles} and {Practice} of {Knowledge} {Discovery} in {Databases}},
	publisher = {Springer International Publishing},
	author = {Blanzeisky, William and Cunningham, Pádraig},
	editor = {Kamp, Michael and Koprinska, Irena and Bibal, Adrien and Bouadi, Tassadit and Frénay, Benoît and Galárraga, Luis and Oramas, José and Adilova, Linara and Krishnamurthy, Yamuna and Kang, Bo and Largeron, Christine and Lijffijt, Jefrey and Viard, Tiphaine and Welke, Pascal and Ruocco, Massimiliano and Aune, Erlend and Gallicchio, Claudio and Schiele, Gregor and Pernkopf, Franz and Blott, Michaela and Fröning, Holger and Schindler, Günther and Guidotti, Riccardo and Monreale, Anna and Rinzivillo, Salvatore and Biecek, Przemyslaw and Ntoutsi, Eirini and Pechenizkiy, Mykola and Rosenhahn, Bodo and Buckley, Christopher and Cialfi, Daniela and Lanillos, Pablo and Ramstead, Maxwell and Verbelen, Tim and Ferreira, Pedro M. and Andresini, Giuseppina and Malerba, Donato and Medeiros, Ibéria and Fournier-Viger, Philippe and Nawaz, M. Saqib and Ventura, Sebastian and Sun, Meng and Zhou, Min and Bitetta, Valerio and Bordino, Ilaria and Ferretti, Andrea and Gullo, Francesco and Ponti, Giovanni and Severini, Lorenzo and Ribeiro, Rita and Gama, João and Gavaldà, Ricard and Cooper, Lee and Ghazaleh, Naghmeh and Richiardi, Jonas and Roqueiro, Damian and Saldana Miranda, Diego and Sechidis, Konstantinos and Graça, Guilherme},
	year = {2021},
	doi = {10.1007/978-3-030-93736-2_41},
	note = {Series Title: Communications in Computer and Information Science},
	pages = {559--574},
}

@article{smit_future_2023,
	title = {The future of artificial intelligence in intensive care: moving from predictive to actionable {AI}},
	volume = {49},
	issn = {0342-4642, 1432-1238},
	shorttitle = {The future of artificial intelligence in intensive care},
	url = {https://link.springer.com/10.1007/s00134-023-07102-y},
	doi = {10.1007/s00134-023-07102-y},
	language = {en},
	number = {9},
	urldate = {2023-09-29},
	journal = {Intensive Care Medicine},
	author = {Smit, Jim M. and Krijthe, Jesse H. and Van Bommel, Jasper and {the Causal Inference for ICU Collaborators} and Van Genderen, M.E. and Labrecque, J.A. and Komorowski, M. and Gommers, D.A.M.P.J and Reinders, M. J. T.},
	month = sep,
	year = {2023},
	pages = {1114--1116},
}

@article{luo_minimum_2023,
	title = {Minimum heart rate and mortality after cardiac surgery: retrospective analysis of the {Multi}-parameter {Intelligent} {Monitoring} in {Intensive} {Care} ({MIMIC}-{III}) database},
	volume = {13},
	issn = {2045-2322},
	shorttitle = {Minimum heart rate and mortality after cardiac surgery},
	url = {https://www.nature.com/articles/s41598-023-29703-9},
	doi = {10.1038/s41598-023-29703-9},
	abstract = {Abstract
            Low heart rate is a risk factor of mortality in many cardiovascular diseases. However, the relationship of minimum heart rate (MHR) with outcomes after cardiac surgery is still unclear, and the association between optimum MHR and risk of mortality in patients receiving cardiac surgery remains unknown. In this retrospective study using the Multi-parameter Intelligent Monitoring in Intensive Care (MIMIC-III) database, 8243 adult patients who underwent cardiac surgery were included. The association between MHR and the 30-day, 90-day, 180-day, and 1-year mortality of patients undergoing cardiac surgery was analyzed using multivariate Cox proportional hazard analysis. As a continuous variable, MHR was evaluated using restricted cubic regression splines, and appropriate cut-off points were determined. Kaplan–Meier curve was used to further explore the relationship between MHR and prognosis. Subgroup analyses were performed based on age, sex, hypertension, diabetes, and ethnicity. The rates of the 30-day, 90-day, 180-day, and 1-year mortalities of patients in the low MHR group were higher than those in the high MHR group (4.1\% vs. 2.9\%, P {\textless} 0.05; 6.8\% vs. 5.3\%, P {\textless} 0.05; 8.9\% vs. 7.0\%, P {\textless} 0.05, and 10.9\% vs. 8.8\%, P {\textless} 0.05, respectively). Low MHR significantly correlated with the 30-day, 90-day, 180-day, and 1-year mortality after adjusting for confounders. A U-shaped relationship was observed between the 30-day, 90-day, 180-day, and 1-year mortality and MHR, and the mortality was lowest when the MHR was 69 bpm. Kaplan–Meier curve analysis also indicated that low MHR had poor prognosis in patients undergoing cardiac surgery. According to subgroup analyses, the effect of low MHR on post-cardiac surgery survival was restricted to patients who were {\textless} 75 years old, male, without hypertension and diabetes, and of White ethnicity. MHR (69 bpm) was associated with better 30-day, 90-day, 180-day, and 1-year survival in patients after cardiac surgery. Therefore, effective HR control strategies are required in this high-risk population.},
	language = {en},
	number = {1},
	urldate = {2023-09-29},
	journal = {Scientific Reports},
	author = {Luo, Chaodi and Duan, Zhenzhen and Xia, Ziheng and Li, Qian and Wang, Boxiang and Zheng, Tingting and Wang, Danni and Han, Dan},
	month = feb,
	year = {2023},
	pages = {2597},
}

@inproceedings{baytas_patient_2017,
	address = {Halifax NS Canada},
	title = {Patient {Subtyping} via {Time}-{Aware} {LSTM} {Networks}},
	isbn = {978-1-4503-4887-4},
	url = {https://dl.acm.org/doi/pdf/10.1145/3097983.3097997},
	doi = {10.1145/3097983.3097997},
	language = {en},
	urldate = {2023-09-29},
	booktitle = {Proceedings of the 23rd {ACM} {SIGKDD} {International} {Conference} on {Knowledge} {Discovery} and {Data} {Mining}},
	publisher = {ACM},
	author = {Baytas, Inci M. and Xiao, Cao and Zhang, Xi and Wang, Fei and Jain, Anil K. and Zhou, Jiayu},
	month = aug,
	year = {2017},
	keywords = {notion},
	pages = {65--74},
}

@misc{horn_set_2020,
	title = {Set {Functions} for {Time} {Series}},
	url = {http://arxiv.org/abs/1909.12064},
	abstract = {Despite the eminent successes of deep neural networks, many architectures are often hard to transfer to irregularly-sampled and asynchronous time series that commonly occur in real-world datasets, especially in healthcare applications. This paper proposes a novel approach for classifying irregularly-sampled time series with unaligned measurements, focusing on high scalability and data efficiency. Our method SeFT (Set Functions for Time Series) is based on recent advances in differentiable set function learning, extremely parallelizable with a beneficial memory footprint, thus scaling well to large datasets of long time series and online monitoring scenarios. Furthermore, our approach permits quantifying per-observation contributions to the classification outcome. We extensively compare our method with existing algorithms on multiple healthcare time series datasets and demonstrate that it performs competitively whilst significantly reducing runtime.},
	urldate = {2023-09-29},
	publisher = {arXiv},
	author = {Horn, Max and Moor, Michael and Bock, Christian and Rieck, Bastian and Borgwardt, Karsten},
	month = sep,
	year = {2020},
	note = {arXiv:1909.12064 [cs, stat]},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, notion},
}

@misc{lipton_modeling_2016,
	title = {Modeling {Missing} {Data} in {Clinical} {Time} {Series} with {RNNs}},
	url = {http://arxiv.org/abs/1606.04130},
	abstract = {We demonstrate a simple strategy to cope with missing data in sequential inputs, addressing the task of multilabel classification of diagnoses given clinical time series. Collected from the pediatric intensive care unit (PICU) at Children's Hospital Los Angeles, our data consists of multivariate time series of observations. The measurements are irregularly spaced, leading to missingness patterns in temporally discretized sequences. While these artifacts are typically handled by imputation, we achieve superior predictive performance by treating the artifacts as features. Unlike linear models, recurrent neural networks can realize this improvement using only simple binary indicators of missingness. For linear models, we show an alternative strategy to capture this signal. Training models on missingness patterns only, we show that for some diseases, what tests are run can be as predictive as the results themselves.},
	urldate = {2023-09-29},
	publisher = {arXiv},
	author = {Lipton, Zachary C. and Kale, David C. and Wetzel, Randall},
	month = nov,
	year = {2016},
	note = {arXiv:1606.04130 [cs, stat]},
	keywords = {Computer Science - Information Retrieval, Computer Science - Machine Learning, Computer Science - Neural and Evolutionary Computing, Statistics - Machine Learning, notion},
}

@article{liu_self-supervised_2021,
	title = {Self-supervised {Learning}: {Generative} or {Contrastive}},
	issn = {1041-4347, 1558-2191, 2326-3865},
	shorttitle = {Self-supervised {Learning}},
	url = {https://ieeexplore.ieee.org/document/9462394/},
	doi = {10.1109/TKDE.2021.3090866},
	urldate = {2023-09-29},
	journal = {IEEE Transactions on Knowledge and Data Engineering},
	author = {Liu, Xiao and Zhang, Fanjin and Hou, Zhenyu and Mian, Li and Wang, Zhaoyu and Zhang, Jing and Tang, Jie},
	year = {2021},
	keywords = {notion},
	pages = {1--1},
}

@article{tan_data-gru_2020,
	title = {{DATA}-{GRU}: {Dual}-{Attention} {Time}-{Aware} {Gated} {Recurrent} {Unit} for {Irregular} {Multivariate} {Time} {Series}},
	volume = {34},
	issn = {2374-3468, 2159-5399},
	shorttitle = {{DATA}-{GRU}},
	url = {https://ojs.aaai.org/index.php/AAAI/article/view/5440},
	doi = {10.1609/aaai.v34i01.5440},
	abstract = {Due to the discrepancy of diseases and symptoms, patients usually visit hospitals irregularly and different physiological variables are examined at each visit, producing large amounts of irregular multivariate time series (IMTS) data with missing values and varying intervals. Existing methods process IMTS into regular data so that standard machine learning models can be employed. However, time intervals are usually determined by the status of patients, while missing values are caused by changes in symptoms. Therefore, we propose a novel end-to-end Dual-Attention Time-Aware Gated Recurrent Unit (DATA-GRU) for IMTS to predict the mortality risk of patients. In particular, DATA-GRU is able to: 1) preserve the informative varying intervals by introducing a time-aware structure to directly adjust the influence of the previous status in coordination with the elapsed time, and 2) tackle missing values by proposing a novel dual-attention structure to jointly consider data-quality and medical-knowledge. A novel unreliability-aware attention mechanism is designed to handle the diversity in the reliability of different data, while a new symptom-aware attention mechanism is proposed to extract medical reasons from original clinical records. Extensive experimental results on two real-world datasets demonstrate that DATA-GRU can significantly outperform state-of-the-art methods and provide meaningful clinical interpretation.},
	number = {01},
	urldate = {2023-09-29},
	journal = {Proceedings of the AAAI Conference on Artificial Intelligence},
	author = {Tan, Qingxiong and Ye, Mang and Yang, Baoyao and Liu, Siqi and Ma, Andy Jinhua and Yip, Terry Cheuk-Fung and Wong, Grace Lai-Hung and Yuen, PongChi},
	month = apr,
	year = {2020},
	keywords = {notion},
	pages = {930--937},
}

@misc{liu_learning_2018,
	title = {Learning the {Joint} {Representation} of {Heterogeneous} {Temporal} {Events} for {Clinical} {Endpoint} {Prediction}},
	url = {http://arxiv.org/abs/1803.04837},
	abstract = {The availability of a large amount of electronic health records (EHR) provides huge opportunities to improve health care service by mining these data. One important application is clinical endpoint prediction, which aims to predict whether a disease, a symptom or an abnormal lab test will happen in the future according to patients' history records. This paper develops deep learning techniques for clinical endpoint prediction, which are effective in many practical applications. However, the problem is very challenging since patients' history records contain multiple heterogeneous temporal events such as lab tests, diagnosis, and drug administrations. The visiting patterns of different types of events vary significantly, and there exist complex nonlinear relationships between different events. In this paper, we propose a novel model for learning the joint representation of heterogeneous temporal events. The model adds a new gate to control the visiting rates of different events which effectively models the irregular patterns of different events and their nonlinear correlations. Experiment results with real-world clinical data on the tasks of predicting death and abnormal lab tests prove the effectiveness of our proposed approach over competitive baselines.},
	urldate = {2023-09-29},
	publisher = {arXiv},
	author = {Liu, Luchen and Shen, Jianhao and Zhang, Ming and Wang, Zichang and Tang, Jian},
	month = nov,
	year = {2018},
	note = {arXiv:1803.04837 [cs, stat]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Statistics - Machine Learning, notion},
}

@article{mou_t-lstm_2019,
	title = {T-{LSTM}: {A} {Long} {Short}-{Term} {Memory} {Neural} {Network} {Enhanced} by {Temporal} {Information} for {Traffic} {Flow} {Prediction}},
	volume = {7},
	issn = {2169-3536},
	shorttitle = {T-{LSTM}},
	url = {https://ieeexplore.ieee.org/document/8767922/},
	doi = {10.1109/ACCESS.2019.2929692},
	urldate = {2023-09-29},
	journal = {IEEE Access},
	author = {Mou, Luntian and Zhao, Pengfei and Xie, Haitao and Chen, Yanyan},
	year = {2019},
	keywords = {notion},
	pages = {98053--98060},
}

@misc{schirmer_modeling_2022,
	title = {Modeling {Irregular} {Time} {Series} with {Continuous} {Recurrent} {Units}},
	url = {http://arxiv.org/abs/2111.11344},
	abstract = {Recurrent neural networks (RNNs) are a popular choice for modeling sequential data. Modern RNN architectures assume constant time-intervals between observations. However, in many datasets (e.g. medical records) observation times are irregular and can carry important information. To address this challenge, we propose continuous recurrent units (CRUs) -- a neural architecture that can naturally handle irregular intervals between observations. The CRU assumes a hidden state, which evolves according to a linear stochastic differential equation and is integrated into an encoder-decoder framework. The recursive computations of the CRU can be derived using the continuous-discrete Kalman filter and are in closed form. The resulting recurrent architecture has temporal continuity between hidden states and a gating mechanism that can optimally integrate noisy observations. We derive an efficient parameterization scheme for the CRU that leads to a fast implementation f-CRU. We empirically study the CRU on a number of challenging datasets and find that it can interpolate irregular time series better than methods based on neural ordinary differential equations.},
	urldate = {2023-09-29},
	publisher = {arXiv},
	author = {Schirmer, Mona and Eltayeb, Mazin and Lessmann, Stefan and Rudolph, Maja},
	month = jul,
	year = {2022},
	note = {arXiv:2111.11344 [cs, stat]},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, notion},
}

@article{du_saits_2023,
	title = {{SAITS}: {Self}-{Attention}-based {Imputation} for {Time} {Series}},
	volume = {219},
	issn = {09574174},
	shorttitle = {{SAITS}},
	url = {http://arxiv.org/abs/2202.08516},
	doi = {10.1016/j.eswa.2023.119619},
	abstract = {Missing data in time series is a pervasive problem that puts obstacles in the way of advanced analysis. A popular solution is imputation, where the fundamental challenge is to determine what values should be filled in. This paper proposes SAITS, a novel method based on the self-attention mechanism for missing value imputation in multivariate time series. Trained by a joint-optimization approach, SAITS learns missing values from a weighted combination of two diagonally-masked self-attention (DMSA) blocks. DMSA explicitly captures both the temporal dependencies and feature correlations between time steps, which improves imputation accuracy and training speed. Meanwhile, the weighted-combination design enables SAITS to dynamically assign weights to the learned representations from two DMSA blocks according to the attention map and the missingness information. Extensive experiments quantitatively and qualitatively demonstrate that SAITS outperforms the state-of-the-art methods on the time-series imputation task efficiently and reveal SAITS' potential to improve the learning performance of pattern recognition models on incomplete time-series data from the real world. The code is open source on GitHub at https://github.com/WenjieDu/SAITS.},
	urldate = {2023-09-14},
	journal = {Expert Systems with Applications},
	author = {Du, Wenjie and Cote, David and Liu, Yan},
	month = jun,
	year = {2023},
	note = {arXiv:2202.08516 [cs]},
	keywords = {Computer Science - Machine Learning, notion},
	pages = {119619},
}

@misc{rubanova_latent_2019,
	title = {Latent {ODEs} for {Irregularly}-{Sampled} {Time} {Series}},
	url = {http://arxiv.org/abs/1907.03907},
	abstract = {Time series with non-uniform intervals occur in many applications, and are difficult to model using standard recurrent neural networks (RNNs). We generalize RNNs to have continuous-time hidden dynamics defined by ordinary differential equations (ODEs), a model we call ODE-RNNs. Furthermore, we use ODE-RNNs to replace the recognition network of the recently-proposed Latent ODE model. Both ODE-RNNs and Latent ODEs can naturally handle arbitrary time gaps between observations, and can explicitly model the probability of observation times using Poisson processes. We show experimentally that these ODE-based models outperform their RNN-based counterparts on irregularly-sampled data.},
	urldate = {2023-09-14},
	publisher = {arXiv},
	author = {Rubanova, Yulia and Chen, Ricky T. Q. and Duvenaud, David},
	month = jul,
	year = {2019},
	note = {arXiv:1907.03907 [cs, stat]
version: 1},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, notion},
}

@inproceedings{cao_brits_2018,
	title = {{BRITS}: {Bidirectional} {Recurrent} {Imputation} for {Time} {Series}},
	volume = {31},
	url = {https://proceedings.neurips.cc/paper_files/paper/2018/file/734e6bfcd358e25ac1db0a4241b95651-Paper.pdf},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	publisher = {Curran Associates, Inc.},
	author = {Cao, Wei and Wang, Dong and Li, Jian and Zhou, Hao and Li, Lei and Li, Yitan},
	editor = {Bengio, S. and Wallach, H. and Larochelle, H. and Grauman, K. and Cesa-Bianchi, N. and Garnett, R.},
	year = {2018},
	keywords = {notion},
}

@article{che_recurrent_2018,
	title = {Recurrent {Neural} {Networks} for {Multivariate} {Time} {Series} with {Missing} {Values}},
	volume = {8},
	issn = {2045-2322},
	url = {https://www.nature.com/articles/s41598-018-24271-9},
	doi = {10.1038/s41598-018-24271-9},
	abstract = {Abstract
            
              Multivariate time series data in practical applications, such as health care, geoscience, and biology, are characterized by a variety of missing values. In time series prediction and other related tasks, it has been noted that missing values and their missing patterns are often correlated with the target labels, a.k.a.,
              informative
              missingness. There is very limited work on exploiting the missing patterns for effective imputation and improving prediction performance. In this paper, we develop novel deep learning models, namely
              GRU
              -
              D
              , as one of the early attempts. GRU-D is based on Gated Recurrent Unit (GRU), a state-of-the-art recurrent neural network. It takes two representations of missing patterns, i.e.,
              masking
              and
              time interval
              , and effectively incorporates them into a deep model architecture so that it not only captures the long-term temporal dependencies in time series, but also utilizes the missing patterns to achieve better prediction results. Experiments of time series classification tasks on real-world clinical datasets (MIMIC-III, PhysioNet) and synthetic datasets demonstrate that our models achieve state-of-the-art performance and provide useful insights for better understanding and utilization of missing values in time series analysis.},
	language = {en},
	number = {1},
	urldate = {2023-09-14},
	journal = {Scientific Reports},
	author = {Che, Zhengping and Purushotham, Sanjay and Cho, Kyunghyun and Sontag, David and Liu, Yan},
	month = apr,
	year = {2018},
	keywords = {notion},
	pages = {6085},
}

@article{sood_realistic_2020,
	title = {Realistic simulation of virtual multi-scale, multi-modal patient trajectories using {Bayesian} networks and sparse auto-encoders},
	volume = {10},
	issn = {2045-2322},
	url = {https://www.nature.com/articles/s41598-020-67398-4},
	doi = {10.1038/s41598-020-67398-4},
	abstract = {Abstract
            Translational research of many disease areas requires a longitudinal understanding of disease development and progression across all biologically relevant scales. Several corresponding studies are now available. However, to compile a comprehensive picture of a specific disease, multiple studies need to be analyzed and compared. A large number of clinical studies is nowadays conducted in the context of drug development in pharmaceutical research. However, legal and ethical constraints typically do not allow for sharing sensitive patient data. In consequence there exist data “silos”, which slow down the overall scientific progress in translational research. In this paper, we suggest the idea of a virtual cohort (VC) to address this limitation. Our key idea is to describe a longitudinal patient cohort with the help of a generative statistical model, namely a modular Bayesian Network, in which individual modules are represented as sparse autoencoder networks. We show that with the help of such a model we can simulate subjects that are highly similar to real ones. Our approach allows for incorporating arbitrary multi-scale, multi-modal data without making specific distribution assumptions. Moreover, we demonstrate the possibility to simulate interventions (e.g. via a treatment) in the VC. Overall, our proposed approach opens the possibility to build sufficiently realistic VCs for multiple disease areas in the future.},
	language = {en},
	number = {1},
	urldate = {2023-09-14},
	journal = {Scientific Reports},
	author = {Sood, Meemansa and Sahay, Akrishta and Karki, Reagon and Emon, Mohammad Asif and Vrooman, Henri and Hofmann-Apitius, Martin and Fröhlich, Holger},
	month = jul,
	year = {2020},
	keywords = {notion},
	pages = {10971},
}

@article{dejong_deep_2019,
	title = {Deep learning for clustering of multivariate clinical patient trajectories with missing values},
	volume = {8},
	issn = {2047-217X},
	url = {https://academic.oup.com/gigascience/article/doi/10.1093/gigascience/giz134/5626377},
	doi = {10.1093/gigascience/giz134},
	abstract = {Abstract
            
              Background
              Precision medicine requires a stratification of patients by disease presentation that is sufficiently informative to allow for selecting treatments on a per-patient basis. For many diseases, such as neurological disorders, this stratification problem translates into a complex problem of clustering multivariate and relatively short time series because (i) these diseases are multifactorial and not well described by single clinical outcome variables and (ii) disease progression needs to be monitored over time. Additionally, clinical data often additionally are hindered by the presence of many missing values, further complicating any clustering attempts.
            
            
              Findings
              The problem of clustering multivariate short time series with many missing values is generally not well addressed in the literature. In this work, we propose a deep learning–based method to address this issue, variational deep embedding with recurrence (VaDER). VaDER relies on a Gaussian mixture variational autoencoder framework, which is further extended to (i) model multivariate time series and (ii) directly deal with missing values. We validated VaDER by accurately recovering clusters from simulated and benchmark data with known ground truth clustering, while varying the degree of missingness. We then used VaDER to successfully stratify patients with Alzheimer disease and patients with Parkinson disease into subgroups characterized by clinically divergent disease progression profiles. Additional analyses demonstrated that these clinical differences reflected known underlying aspects of Alzheimer disease and Parkinson disease.
            
            
              Conclusions
              We believe our results show that VaDER can be of great value for future efforts in patient stratification, and multivariate time-series clustering in general.},
	language = {en},
	number = {11},
	urldate = {2023-09-14},
	journal = {GigaScience},
	author = {de Jong, Johann and Emon, Mohammad Asif and Wu, Ping and Karki, Reagon and Sood, Meemansa and Godard, Patrice and Ahmad, Ashar and Vrooman, Henri and Hofmann-Apitius, Martin and Fröhlich, Holger},
	month = nov,
	year = {2019},
	keywords = {notion},
	pages = {giz134},
}
