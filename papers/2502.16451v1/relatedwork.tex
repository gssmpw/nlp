\section{Related Work}
\paragraph{Self-supervised learning for molecules and crystals}

GNNs have significantly impacted material property predictions \cite{xie2018CGCNN, gilmer2017MPNN} by providing an alternative way for complex quantum chemical computations. However, the costly labeling process requiring expensive quantum chemical calculations is the bottleneck in GNN application. To address this challenge, various self-supervised learning (SSL) methods have been proposed. Wang et al. \cite{wang2022MolCLR} reduced the need for expensive quantum chemical labeling by applying contrastive learning to unlabeled 10 million molecules using molecular GNNs. Koker et al. \cite{koker2022CrystalCLR} emphasized the importance of augmentation techniques when applying contrastive learning to encoding periodic crystals as graphs with CGCNNs as encoders. Magar et al. \cite{magar2022CrystalTwins} improved the performance of CGCNNs by applying Barlow twins \cite{zbontar2021barlowtwins}, a self-supervised learning method that does not require negative pairs.

\paragraph{Multimodal learning for molecules}
In the molecular domain, performing multimodal contrastive learning between graphs and text has been demonstrated to improve representation ability by encoding knowledge from an unstructured domain-specific corpus. Zeng et al. \cite{zeng2022KV-PLM} proposed to encode both SMILES \cite{weininger1988smiles, weininger1989smiles} representation and text corpus of molecules simultaneously using a BERT \cite{devlin2018BERT} model as backbone. To train the proposed model, they extracted a corpus from the semantic scholar \cite{lo2019s2orc}, a database of over 136M published scientific literature, to construct 10k molecule-text pairs. Su et al. \cite{su2022MoMu} proposed to apply the contrastive learning paradigm with distinguishing graph and text branches. To overcome limited training data, authors utilized pre-trained models in the biochemical molecular domain for both GNN, GraphCL \cite{you2020GraphCL}, and text encoder, SciBERT \cite{beltagy2019scibert}. Liu et al. \cite{liu2023MoleculeSTM} pre-trained their model on a larger training set of 280k pairs, and both previous studies enabled zero-shot tasks and showed improved performance compared to unimodal models on downstream tasks.

\paragraph{Multimodal learning for crystals}
Multimodal learning in crystalline materials has not been explored extensively. Das et al. \cite{das2023crysmmnet} proposed CrysMMNet, which simultaneously integrates graph inputs and text inputs describing the structure of materials generated by a Robocrystallographer \cite{ganose2019robocrystallographer}. However, this approach focuses on creating joint representations and using them only to predict material properties and does not address issues related to zero-shot tasks and downstream tasks using natural language.