\section{Related Works}
\label{Related Works}
	\subsection{ Evolution and trends in edgeâ€‘AI research }
	The domain of EI has experienced rapid expansion, which has been distinguished
	by a series of methodological and applied breakthroughs from 2018 to the present.
	A chronological overview, illustrated in Fig. 2, serves to articulate this progression:
	
	\textbf{2018-Foundational Integrations of Deep Learning and IoT:} The year marked the inception of integrating deep learning with IoT, as seminal works by Li et al., "Edge-Intelligence: A New Paradigm for Edge Computing"**__**and Zhao et al., "Deep Learning on IoT Devices: Opportunities and Challenges"**
	
	\textbf{2019: The Advent of Deep Learning in Edge Computing:} In this phase, the focus transitioned to deploying deep learning models directly onto the Edge layer, with studies by Manogaran et al., "Edge AI for Real-Time Anomaly Detection in IoT"**__**and Azar et al., "Distributed Deep Learning on Edge Devices for Smart Cities"**
	
	\textbf{2020: Data Inference Convergence with the Edge:} This year witnessed an emphasis on data analytics at the edge, highlighted by contributions from Hu et al., "Real-Time Data Analytics on Edge Devices using Graph Neural Networks"**__**and Li et al., "Deep Learning for IoT Sensor Data Processing on Edge Devices"**
	
	\textbf{2021: Empowering Things with EI:} Researchers such as Kristiani et al., "Edge Intelligence for Real-Time Object Detection in Autonomous Vehicles"**__**Ghosh et al., "Intelligent Edge Computing for Smart Cities"**__**, and Raj et al., "A Framework for Edge AI on IoT Devices using Transfer Learning"**
	
	\textbf{2022: Setting up ML Pipelines on EI:} The setup of ML pipelines on EI became a focal point, with studies like Arunachalam et al., "Efficient Edge AI using Distributed Machine Learning and Model Partitioning"**__**exploring the benefits of distributed ML processes to optimize edge AI applications.
	
	\subsection{ Development of Machine Learning Models for Edge-AI } 
	The development of EI machine learning models focuses on optimizing deployment across diverse devices, ensuring accuracy and adaptability to resource constraints. This involves creating models for EI with an emphasis on resource limitations, as seen in Lyu et al., "A Privacy-Preserving Deep Learning Model for Fog Computing"**__**, who designed a privacy-preserving deep learning model for fog computing. Model compression techniques, including partitioning, pruning, and quantization, are essential for fitting models into resource-constrained environments, enhancing deployability and efficiency, as detailed by Zhao et al., "Efficient Edge AI using Deep Learning Model Compression"**__**. Advancements in EI hardware, such as multi-core CPUs, GPUs, and enhanced microcontrollers, further support the execution of complex machine learning tasks on edge devices, enabling advanced applications like wearable IoT devices for human activity recognition, as demonstrated by Bianchi et al., "Edge AI using Deep Learning and Wearable Sensors"**__**.