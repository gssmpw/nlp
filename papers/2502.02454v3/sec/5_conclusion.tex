\section{Conslusion}
In this paper, we propose a novel image manipulation detection prompt learning method, IMDPrompter, utilizing the SAM foundational model. The primary goal of IMDPrompter is to learn the generation of SAM prompt inputs, thereby automating image manipulation detection and localization tasks. Considering the reliance of image manipulation detection on semantically unrelated information, we constructed an integration and enhancement framework that merges multiple types of view information to achieve optimal prompt selection and mixing. We introduced modules such as SAF, CPC, OPS, and PMM to realize efficient image manipulation detection performance. Our IMDPrompter achieves objective image-level and pixel-level image manipulation detection performance in in-domain (IND) and out-of-domain (OOD) as well as various robustness evaluation settings.





