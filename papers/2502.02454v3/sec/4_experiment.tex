\section{Experiment}
\begin{figure*}[t]
	\centering
	\includegraphics[width=0.95\linewidth]{sec/fig/vis.pdf}
	\caption{ Visualization Comparison of Image Manipulation Detection and Localization Results}
	\label{vis}
\end{figure*}
\input{sec/table/4-1-1}
\input{sec/table/4-1-2}
\input{sec/table/4-1-3}



% \input{sec/table/new-3}
% \input{sec/table/new-4}



% % \input{sec/table/new-5}
% \begin{figure}[t]
% 	\centering
% 	\includegraphics[width=0.80\textwidth, keepaspectratio]{sec/fig/combined_chart.pdf}
% 	\caption{Radar chart comparing experimental performance with mainstream methods.}
 
% 	\label{sensitivity}
% \end{figure}

% \begin{figure}[ht]
%     \centering
    
%     \begin{subfigure}{\columnwidth} 
%         \centering
%         \includegraphics[width=0.80\textwidth]{sec/fig/IMDP-111.pdf}  % Adjust the image width as necessary, here set to 75% of the column width
%         \caption{ Bar chart analysis of ablation experiments on the IND dataset.}
%         \label{fig:sub1}
%     \end{subfigure}
    
%     \vspace{0.3cm} 
%     \begin{subfigure}{\columnwidth}  
%         \centering
%         \includegraphics[width=0.80\textwidth]{sec/fig/IMDP-222.pdf}
%         \caption{ Bar chart analysis of ablation experiments on the OOD dataset.}
%         \label{fig:sub2}
%     \end{subfigure}
    
%     \caption{Bar chart analysis of ablation experiments.}
%     \label{fig:test}
% \end{figure}

% \begin{figure}[t]
%     \centering
%     \begin{minipage}{0.48\textwidth}
%         \centering
%         \includegraphics[width=\textwidth]{sec/fig/IMDP-111.pdf}
%         \caption{ Bar chart analysis of ablation experiments on the IND dataset.}
%         \label{fig:sub1}
%     \end{minipage}\hfill
%     \begin{minipage}{0.48\textwidth}
%         \centering
%         \includegraphics[width=\textwidth]{sec/fig/IMDP-222.pdf}
%         \caption{ Bar chart analysis of ablation experiments on the OOD dataset.}
%         \label{fig:sub2}
%     \end{minipage}
% \end{figure}


% \begin{figure}[ht]
%     \centering
%     \begin{subfigure}[b]{0.49\textwidth}  % 
%         \centering
%         \includegraphics[width=\textwidth]{sec/fig/IMDP-111.pdf}  % 
%         \caption{Bar chart analysis of ablation experiments on the IND dataset.}
%         \label{fig:sub1}
%     \end{subfigure}
%     \hfill  %
%     \begin{subfigure}[b]{0.49\textwidth}  % 
%         \centering
%         \includegraphics[width=\textwidth]{sec/fig/IMDP-222.pdf}
%         \caption{Bar chart analysis of ablation experiments on the OOD dataset.}
%         \label{fig:sub2}
%     \end{subfigure}
%     \caption{Bar chart analysis of ablation experiments.}
%     \label{fig:test}
% \end{figure}


% \begin{figure}[ht]
%     \centering
%     % First row
%     \begin{subfigure}{0.3\columnwidth}
%         \centering
%         \includegraphics[width=\linewidth]{sec/fig/IMDP-rada-1-F1}
%         \caption{ I-F1 radar chart}
%         \label{fig:sub1}
%     \end{subfigure}
%     \hfill  
%     \begin{subfigure}{0.3\columnwidth}
%         \centering
%         \includegraphics[width=\linewidth]{sec/fig/IMDP-rada-1-AUC}
%         \caption{I-AUC radar chart}
%         \label{fig:sub3}
%     \end{subfigure}
%     \hfill
%     \begin{subfigure}{0.3\columnwidth}
%         \centering
%         \includegraphics[width=\linewidth]{sec/fig/IMDP-rada-2}
%         \caption{Com-F1 radar chart}
%         \label{fig:sub4}
%     \end{subfigure}

%     % Third row
%     \begin{subfigure}{0.3\columnwidth}
%         \centering
%         \includegraphics[width=\linewidth]{sec/fig/IMDP-rada-3-1}
%         \caption{Best threshold P-F1 radar chart}
%         \label{fig:sub5}
%     \end{subfigure}
%     \hfill
%     \begin{subfigure}{0.3\columnwidth}
%         \centering
%         \includegraphics[width=\linewidth]{sec/fig/IMDP-rada-3-2}
%         \caption{Fixed threshold P-F1 radar chart}
%         \label{fig:sub6}
%     \end{subfigure}
%     \hfill
%     \begin{subfigure}{0.3\columnwidth}
%         \centering
%         \includegraphics[width=\linewidth]{sec/fig/radar_chart_legend.pdf}
%         \caption{ }
%         \label{fig:sub2}
%     \end{subfigure}
    
%     \caption{Radar chart comparing experimental performance with mainstream methods.}
%     \label{fig:grid}
% \end{figure}





\noindent\textbf{Dataset.} Our method is trained only on the CASIAv2 dataset \cite{dong2013casia}. For in-distribution (IND) evaluation, we use the CASIAv1 dataset \cite{dong2013casia}. For out-of-distribution (OOD) evaluation, we use three datasets: Columbia \cite{hsu2006detecting}, Coverage \cite{wen2016coverage}and IMD2020 \cite{novozamsky2020imd2020}. 

\noindent\textbf{Evaluation Metrics.} For image-level manipulation detection, we report specificity, sensitivity, and their F1-score (I-F1). The area under the receiver operating characteristic curve (AUC) is also reported as a threshold-independent metric for image-level detection. For pixel-level manipulation localization, we follow previous methods\cite{chen2021image,zhou2018learning,zhou2018generate,salloum2018image} to compute pixel accuracy, recall, and their F1-score (P-F1) on manipulated images. The overall performance of image and pixel-level manipulation detection/localization is measured by the harmonic mean of pixel-level and image-level F1-scores \cite{chen2021image}, denoted as composite F1 (Com-F1), and is sensitive to lower values of P-F1 and I-F1. To ensure fair comparison, a default threshold of 0.5 is used for F1 computation unless otherwise specified.

\noindent\textbf{Implementation Details.} In our experiments, unless otherwise specified, we consistently use the VIT-L backbone of SAM and employ FCN as the segmentor for the three prompt views. We maintain image size at 1024×1024, consistent with the original input of the SAM model. To augment training samples, we use data augmentation techniques such as horizontal flipping and random cropping. The image encoder remains frozen during the training phase. All experiments are run on NVIDIA A6000 GPUs. For the optimization process, we train our model using the AdamW optimizer with an initial learning rate of 1e-4. We use a batch size of 4 and train for 100 epochs. We implement a linear warm-up strategy with a cosine annealing scheduler \cite{loshchilov2016sgdr} to decay the learning rate. Our proposed method is developed using PyTorch.

\subsection{
Comparison with State-of-the-Art Method}

\noindent\textbf{Pixel-level Manipulation Detection}
Table \ref{4-1-1} illustrates the pixel-level detection performance of different models. We evaluate the F1-score under two settings: best threshold and fixed threshold (0.5). From Table \ref{4-1-1}, it is evident that IMDPrompter achieves the best performance across nearly all datasets. Under the optimal threshold setting, we achieved an average F1 Score of 81.36\%. Under the fixed threshold setting, IMDPrompter achieved an average F1 Score of 59.78\%, indicating that our proposed IMDPrompter demonstrates better robustness in threshold settings.

\noindent\textbf{Image-level Manipulation Detection.}
Table \ref{4-1-2} presents the image-level performance of different models. For image-level performance, we use a default decision threshold of 0.5. Once again, IMDPrompter emerges as the top performer, leveraging our prompt learning paradigm to achieve higher specificity in most test settings, thereby reducing false positives. Additionally, IMDPrompter achieves the best average AUC and average F1-scores. The average F1-score of IMDPrompter significantly surpasses that of the second-best method, MVSS-Net, with an improvement of 38.4\%.

% \noindent\textbf{Image-level Operation Detection.}
% Table \ref{4-1-3} provides the overall performance of pixel-level and image-level operation detection. We calculate the harmonic mean of image-level detection F1 and pixel-level localization F1, termed Com-F1, as our overall performance evaluation metric. As shown in Table VII, IMDPrompter achieves the best performance across all settings. In terms of average Com-F1-score, we achieve a performance gain of 24.8\% relative to the second-best method, particularly demonstrating a substantial performance gain of 77.6\% in experiments on the COVER dataset.


% \noindent\textbf{Performance of Detection and Localization Overall.} 
% Table VII presents the overall performance of pixel-level and image-level manipulation detection. We evaluate the overall performance by computing the harmonic mean of image-level detection F1 and pixel-level localization F1, denoted as Com-F1. As shown in Table III, IMDPrompter achieves the best performance across all settings, showing a performance gain of 24.8\% relative to the second-best method in terms of average Com-F1-score. Particularly in experiments with the COVER dataset, we achieve a performance gain of 77.6\%.

% \noindent\textbf{Qualitative Results.}

% \noindent\textbf{Robustness Evaluation.} Following\cite{bi2019rru,hu2020span,li2019localization}, we assess the robustness of the model under two common manipulation operations encountered when images are shared on the internet: JPEG compression and Gaussian blur. Comparing these two operations, Gaussian blur has a more significant impact on detection performance, especially when using larger 17×17 scale convolution kernels. Our IMDPrompter exhibits better robustness compared to previous methods under these conditions.

\subsection{Ablation Studies}
% \noindent % 确保内容从页面边缘开始

% \begin{minipage}[t]{0.48\textwidth} % 左侧半页
% \centering
% \captionof{table}{Evaluation of each component of our method in IND dataset.} % 使用 captionof 来为 minipage 中的表格添加标题
% \renewcommand\arraystretch{1.2}
% \resizebox{\columnwidth}{!}{
% \begin{tabular}{c|cccc|ccc}
% \hline
% \multirow{2}{*}{} & \multirow{2}{*}{SAF} & \multirow{2}{*}{CPC} & \multirow{2}{*}{OPS} & \multirow{2}{*}{PMM} & \multicolumn{3}{c}{CASIA} \\ \cline{6-8} 
%                   &                      &                      &                       &                      & I-F1   & P-F1   & Com-F1  \\ \hline
% \Rmnum{1}               &                      &                      &                       &                      & 70.6   & 44.6   & 54.7    \\
% \Rmnum{2}               & $\checkmark$         &                      &                       &                      & 73.2   & 47.2   & 57.4    \\
% \Rmnum{3}               & $\checkmark$         & $\checkmark$         &                       &                      & 74.3   & 48.3   & 58.5    \\
% \Rmnum{4}               & $\checkmark$         & $\checkmark$         & $\checkmark$          &                      & 75.1   & 50.4   & 60.3    \\
% \Rmnum{5}               & $\checkmark$         & $\checkmark$         & $\checkmark$          & $\checkmark$         & 77.3   & 50.6   & 61.2    \\ \hline
% \end{tabular}
% }
% \label{AS1}
% \end{minipage}%
% \hspace{0.3cm}  % 添加空格以隔开两个 minipage
% \begin{minipage}[t]{0.48\textwidth} % 右侧半页
% \centering
% \captionof{table}{Evaluation of each component of our method in OOD dataset.}
% \renewcommand\arraystretch{1.2}
% \resizebox{\columnwidth}{!}{
% \begin{tabular}{c|cccc|ccc}
% \hline
% \multirow{2}{*}{} & \multirow{2}{*}{SAF} & \multirow{2}{*}{CPC} & \multirow{2}{*}{OPS} & \multirow{2}{*}{PMM} & \multicolumn{3}{c}{COVER} \\ \cline{6-8} 
%                   &                      &                      &                       &                      & I-F1   & P-F1   & Com-F1  \\ \hline
% \Rmnum{6}         &                      &                      &                       &                      & 20.4   & 23.1   & 21.7    \\
% \Rmnum{7}         & $\checkmark$         &                      &                       &                      & 49.6   & 37.6   & 42.8    \\
% \Rmnum{8}         & $\checkmark$         & $\checkmark$         &                       &                      & 58.6   & 40.3   & 47.8    \\
% \Rmnum{9}         & $\checkmark$         & $\checkmark$         & $\checkmark$          &                      & 65.2   & 44.7   & 53.0    \\
% \Rmnum{10}        & $\checkmark$         & $\checkmark$         & $\checkmark$          & $\checkmark$         & 70.3   & 46.9   & 56.3    \\ \hline
% \end{tabular}
% }
% \label{AS2}
% \end{minipage}
\begin{minipage}[t]{0.48\textwidth} % 左侧半页
\centering
\captionof{table}{Evaluation of each component of our method in IND dataset.} % 使用 captionof 来为 minipage 中的表格添加标题
\renewcommand\arraystretch{1.2}
\resizebox{\columnwidth}{!}{
\begin{tabular}{c|cccc|ccc}
\hline
\multirow{2}{*}{} & \multirow{2}{*}{SAF} & \multirow{2}{*}{CPC} & \multirow{2}{*}{OPS} & \multirow{2}{*}{PMM} & \multicolumn{3}{c}{CASIA} \\ \cline{6-8} 
                  &                      &                      &                       &                      & I-F1   & P-F1   & Com-F1  \\ \hline
\Rmnum{1}               &                      &                      &                       &                      & 70.6   & 70.3   & 70.4    \\
\Rmnum{2}               & $\checkmark$         &                      &                       &                      & 73.2   & 73.1   & 73.1    \\
\Rmnum{3}               & $\checkmark$         & $\checkmark$         &                       &                      & 74.3   & 74.3   & 74.3    \\
\Rmnum{4}               & $\checkmark$         & $\checkmark$         & $\checkmark$          &                      & 75.1   & 76.1   & 75.6    \\
\Rmnum{5}               & $\checkmark$         & $\checkmark$         & $\checkmark$          & $\checkmark$         & 77.3   & 76.3   & 76.8    \\ \hline
\end{tabular}
}
\label{AS1}
\end{minipage}%
\hspace{0.3cm}  % 添加空格以隔开两个 minipage
\begin{minipage}[t]{0.48\textwidth} % 右侧半页
\centering
\captionof{table}{Evaluation of each component of our method in OOD dataset.}
\renewcommand\arraystretch{1.2}
\resizebox{\columnwidth}{!}{
\begin{tabular}{c|cccc|ccc}
\hline
\multirow{2}{*}{} & \multirow{2}{*}{SAF} & \multirow{2}{*}{CPC} & \multirow{2}{*}{OPS} & \multirow{2}{*}{PMM} & \multicolumn{3}{c}{COVER} \\ \cline{6-8} 
                  &                      &                      &                       &                      & I-F1   & P-F1   & Com-F1  \\ \hline
\Rmnum{6}         &                      &                      &                       &                      & 20.4   & 39.8   & 27.0    \\
\Rmnum{7}         & $\checkmark$         &                      &                       &                      & 49.6   & 54.3   & 51.8    \\
\Rmnum{8}         & $\checkmark$         & $\checkmark$         &                       &                      & 58.6   & 57.0   & 57.8    \\
\Rmnum{9}         & $\checkmark$         & $\checkmark$         & $\checkmark$          &                      & 65.2   & 61.4   & 63.2    \\
\Rmnum{10}        & $\checkmark$         & $\checkmark$         & $\checkmark$          & $\checkmark$         & 70.3   & 63.6   & 66.8    \\ \hline
\end{tabular}
}
\label{AS2}
\end{minipage}

To reveal the impact of different components, we evaluated the proposed model under different settings, incrementally adding components and considering the distinct impacts of each component on in-domain and out-of-domain datasets. Thus, we conducted ablation experiments on two test sets, CASIA and COVER, for in-domain and out-of-domain data, respectively, as shown  in Tables \ref{AS1} and \ref{AS2}.

\noindent\textbf{Baseline.}  From \textit{Experiment \Rmnum{1}}, it is known that our baseline method achieved performance scores of 70.6\%, 70.3\%, and 70.4\% on the I-F1, P-F1, and Com-F1 metrics respectively in the CASIA dataset. In the COVER dataset, it scored 20.4\%, 39.8\%, and 27.0\% on the same metrics. These experiments show that using only RGB visual view information has limited generalization ability in out-of-domain datasets.

\noindent\textbf{Impact of SAF.} From \textit{Experiment \Rmnum{2}}, with the addition of SAF which introduced semantically unrelated view information, there was an increase in performance on the CASIA dataset's I-F1, P-F1, Com-F1 metrics by 2.6\%, 2.8\%, and 2.7\% respectively. Experiment VII showed that on the COVER dataset, there was a performance gain of 29.2\%, 14.5\%, and 24.8\% respectively on the I-F1, P-F1, Com-F1 metrics, indicating that introducing semantically unrelated information can enhance performance in both in-domain and out-of-domain datasets, especially in the in-domain datasets.

\noindent\textbf{Impact of CPC.} From \textit{Experiment \Rmnum{3}}, the inclusion of CPC, which introduced cross-view consistency enhancement, resulted in performance gains of 3.7\%, 4.0\%, and 3.9\% on the I-F1, P-F1, Com-F1 metrics respectively in the CASIA dataset. Experiment VIII showed performance gains of 38.2\%, 17.2\%, and 30.8\% respectively on the COVER dataset, confirming that the prompt information between different views is complementary and integrative enhancement can bring objective performance improvements.

\noindent\textbf{Impact of OPS.} From \textit{Experiment \Rmnum{4}}, the inclusion of CPC adaptive selection of the optimal prompts resulted in performance gains of 4.5\%, 5.8\%, and 5.2\% on the I-F1, P-F1, Com-F1 metrics respectively in the CASIA dataset. Experiment IX showed gains of 44.8\%, 21.6\%, and 36.2\% respectively on the COVER dataset, indicating that simply adding together prompts from different views is not enough to generate the best prompts, and a optimal prompts selection strategy can optimize the prompt selection process.

\noindent\textbf{Impact of PMM.} From \textit{Experiment \Rmnum{5}}, with the inclusion of PMM which fully integrates various types of prompt information, there was an increase in performance of 6.7\%, 6.0\%, and 6.4\% on the I-F1, P-F1, Com-F1 metrics respectively in the CASIA dataset. \textit{Experiment \Rmnum{10}} showed an increase of 49.9\%, 23.8\%, and 39.8\% respectively on the COVER dataset, further demonstrating the effectiveness of PMM.













