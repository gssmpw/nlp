\begin{abstract}
% Using a vast amount of training data from SA-1B, the Segment Anything Model (SAM) has demonstrated outstanding generalization and zero-shot capabilities. However, as an instance segmentation method independent of categories, SAM heavily relies on manual priors, including points, boxes, and coarse-grained masks. Furthermore, its performance on tasks related to image manipulation detection has largely remained unexplored and unconfirmed. This paper aims to develop an image manipulation detection method based on the basic SAM model and incorporating various semantic-agnostic noisy graph information. Drawing inspiration from prompt learning, we propose a method called IMDPrompter, which learns to generate appropriate prompts for SAM, enabling it to generate accurate manipulation region masks for image manipulation detection. Extensive experimental results from five datasets, namely CASIA, Columbia, Coverage, IMD2020, and NIST16, validate the effectiveness of the proposed method.

Using extensive training data from SA-1B, the Segment Anything Model (SAM) has demonstrated exceptional generalization and zero-shot capabilities, attracting widespread attention in areas such as medical image segmentation and remote sensing image segmentation. However, its performance in the image manipulation detection field remains largely unexplored and unconfirmed. There are two main challenges in applying SAM to image manipulation detection: a) SAM heavily relies on prior manual guidance, including points, boxes, and coarse-grained masks; b) Unlike traditional image segmentation tasks, image manipulation detection tasks rely significantly on the guidance of semantic-agnostic information. In response to these challenges, this paper develops an image manipulation detection method, IMDPrompter, based on the foundational SAM model and incorporating various semantic-agnostic noise map information. Inspired by prompt learning, our IMDPrompter no longer depends on manual guidance but can achieve automated prompt learning. Moreover, we introduce components such as Semantic-Agnostic Feature Fusion (SAF), Optimal Prompt Selection (OPS), Cross-View Prompt Consistency (CPC), and Prompt Mixing Module (PMM), which fully integrate various semantic-agnostic information, enabling SAM to generate accurate tampered area masks for image manipulation detection. Extensive experimental results from the five datasets CASIA, Columbia, Coverage, IMD2020, and NIST16 validate the effectiveness of our proposed method.
\end{abstract}