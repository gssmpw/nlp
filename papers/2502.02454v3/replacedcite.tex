\section{Related Work}
\noindent\textbf{Image Manipulation Detection.} Currently, methods for image manipulation detection can be broadly categorized into two types, primarily distinguished by their recognition of manipulated artifacts. Some techniques ____ rely on detecting abnormal features and often use high-pass noise filters ____ to suppress content information. Other methods ____ attempt to detect inconsistencies in compression within tampered images, as they assume different compression Quality Factors (QFs) before and after the operation. Additionally, some researchers focus their attention on camera-based artifacts, such as model fingerprints ____.

\noindent\textbf{Foundational Models.} In recent years, foundational models have sparked a tremendous transformation in the field of artificial intelligence . These models, trained on extensive datasets, have demonstrated impressive generalization capabilities across various scenarios ____. Renowned models such as Chat-GPT ____, GPT-4 ____, and Stable Diffusion ____ have further propelled the development of artificial intelligence, making significant contributions to human civilization and exerting considerable influence across various industries. 
Inspired by the success of foundational models in natural language processing (NLP), researchers have begun exploring their potential applications in computer vision. While most of these models are aimed at extracting accessible knowledge from freely available data ____, the recent SAM model ____ adopts an innovative approach by constructing a data engine where the model co-develops annotations with environmental datasets. SAM uniquely leverages a vast collection of masks, showcasing robust generalization capabilities. However, it was initially designed as a task-agnostic segmentation model, requiring prompts (i.e., inputs of prior points, bounding boxes, or masks), and therefore does not directly facilitate end-to-end automated segmentation perception.
This paper does not delve into the design and training of foundational image manipulation detection models; instead, we explore the potential of utilizing SAM's powerful universal segmentation capabilities for image manipulation detection and localization. Furthermore, the proposed method of learning prompts can be extended to other visual foundational models beyond SAM.

\noindent\textbf{Prompt Learning.} In the past, machine learning tasks were primarily focused on fully supervised learning, where task-specific models were trained only on labeled instances of the target task  ____. However, over time, there has been a significant shift in learning paradigms, transitioning from fully supervised learning towards \textit{pretraining and fine-tuning }approaches for downstream tasks. This shift allows models to leverage general features acquired during pretraining ____.
More recently, with the advent of foundational models, a new paradigm has emerged known as \textit{pretraining and prompting} ____. In this paradigm, researchers no longer train models specifically for downstream tasks but instead redesign inputs using prompts to reformulate the downstream tasks to align with the original pretraining task ____. Prompting helps to reduce semantic gaps, bridge the gap between pretraining and fine-tuning, and prevent overfitting of the heads. Since the advent of GPT-3 ____, prompting has evolved from traditional discrete ____ and continuous prompt constructions ____ to large-scale model-centric contextual learning ____, instruction tuning ____, and chaining approaches ____.
Currently, methods for constructing prompts include manual templates, heuristic-based templates, generation, fine-tuning word embeddings, and pseudo-labeling ____. In this paper, we propose a prompt generator for generating prompts compatible with SAM.
% \label{headings}

% First level headings are in small caps,
% flush left and in point size 12. One line space before the first level
% heading and 1/2~line space after the first level heading.

% \subsection{Headings: second level}

% Second level headings are in small caps,
% flush left and in point size 10. One line space before the second level
% heading and 1/2~line space after the second level heading.

% \subsubsection{Headings: third level}

% Third level headings are in small caps,
% flush left and in point size 10. One line space before the third level
% heading and 1/2~line space after the third level heading.