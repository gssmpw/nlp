\section{Related Work}\label{sec:related_work}

\paragraph{LLM Data Selection}
In the LLM SFT phase, various metrics have been introduced to assess data quality including completion length \citep{zhao2024long}, perplexity \citep{caoinstruction}, reward scores \citep{gou2024mixed}, discrete confidence scores \citep{chen2024automated}, the loss disparities when certain examples are included or excluded \citep{li2023quantity}, gradient matching \citep{zhou2023dataset}  and influence function scores \citep{xia2024less}.
Another line of work uses advanced LLMs directly to filter out low-quality samples according to different metrics, such as quality-based rating scores ~\citep{chen2023alpagasus, liu2023makes, pang2024improving} and fine-grained tags \citep{lu2023instag}. Diversity-aware scoring has also been integrated into the overall quality assessment, highlighting its importance. 
Although extensive data selection methods have shown promise, fine-grained token-level selection remains underexplored. Recent studies \citep{linnot} have highlighted the significant benefits of token selection during the pre-training phase, yet its application in the SFT phase has received limited attention.

\paragraph{Noisy Data Cleaning} 
The learning with noisy labels has been extensively studied \citep{vahdat2017toward, veit2017learning, li2017learning, lessbemore, yuan2024early}. Various approaches have been proposed to mitigate label errors, including developing noise-tolerant loss functions \citep{natarajan2013learning, reed2014training, zhu2021second} and identifying clean samples while re-labeling corrupted ones \citep{northcutt2021confident, northcutt2017rankpruning, cheng2021learningsieve, zhu2022detecting}.
Recently, the issue of noisy labels in LLM alignment has gained increasing attention, driven by the observation that data quality is far more critical than quantity \citep{zhou2024lima}. Recent work \citep{chong-etal-2022-detecting} investigated the effectiveness of leveraging pre-trained models to identify inherent label errors in natural language datasets. Additionally, efforts have been made to mitigate label errors in LLM alignment datasets \citep{zhu2024unmasking}, particularly in the context of binary harmlessness classification. Furthermore, \citet{pang2024improving} systematically analyzed error patterns in LLM-generated quality rating scores to reduce score errors. Another line of research has focused on developing noise-tolerant DPO-based loss functions, including cDPO \citep{mitchellnote}, robust-DPO \citep{chowdhury2024provably}, and PerpCorrect \citep{kongperplexity}.
The above studies primarily focus on noisy labels at the sample level. In contrast, our work explores fine-grained, token-level noisy labels to identify and filter out uninformative tokens, thereby boosting downstream task performance.



