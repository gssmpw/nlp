\section{Related Works}
\label{sec2}
\subsection{Continual Learning}
Continual learning is a scenario that the model learn from a stream of data over time, distinguishing it from traditional methods that train on the stationary dataset.
In continual learning, LLMs commonly encounter the problem of catastrophic forgetting. This occurs because as the model adapts to new tasks, its parameters tend to deviate from the optimal values that were previously established for old tasks. This phenomenon significantly affects the performance and reliability of models in practical applications, especially when dealing with multiple tasks and datasets**Goodfellow et al., "An Empirical Investigation of Catastrophic Forgeting in Gradient-Based Neural Networks"**. To address this issue, various strategies have been proposed in the past. Here, we discuss three widely used methods, which include replay**Shmelkov et al., "Memory-based Task-agnostic Few-shot Learning with a Single-network Architecture"**, parameter regularization**Kemker and Kanan, "Learning to Reason: Leveraging Neural Networks for Question Answering"**, and parameter isolation**Riemer et al., "Learning to Adapt: Constructing an Adaptation System for Continual Learning"** methods.

Replay, also known as rehearsal, is based on the idea of training models by supplementing the training data of current task with representative previous data**Vandenhende et al., "Efficient Lifelong Learning with A-GEM"**. However, these approaches are not without risk, as they may lead to privacy leakage. Further more, as the model scales up, there is a corresponding increase in the required storage and computing resources. 

Parameter regularization restricts the update of model weights through adding a regularization term to the loss function that penalizes large changes to the network's parameters**Kirkpatrick et al., "Overcoming Catastrophic Forgetting in Neural Networks with Online Hard Parameter Sharing"**. Although these methods alleviate the problem of forgetting to some extent, they may also reduce the model's ability to adapt to new tasks**Li and Hoiem, "Transfer Learning Through Selective Integration of Homologous Subnetworks from Multiple Species"**. 

Parameter isolation methods avoid interference between different tasks by assigning certain parts of the model exclusively to specific tasks**Ruden et al., "Continual Learning with Neural Network Pruning"**. However, these methods are only applicable to task-incremental learning scenarios as they often require a task-id to select the correct model when testing.

\subsection{Task Arithmetic}
In our study, we employ Task Arithmetic**Chen et al., "Meta-Learning for Continual Learning: A Survey"**, a groundbreaking approach to combines all parameters corresponding to each individual task after training. Task Arithmetic represents an innovative paradigm to guiding model behavior, focusing on the use of task vectors. The task vector specifies a direction within the weight space of a pre-trained model, and adjusting the model along this direction enhances its performance on the specific task. These vectors are obtained by subtracting the weights of the pre-trained model from those of a fine-tuned model. Subsequently, we can leverage simple arithmetic operations, termed task arithmetic, on task vectors to edit a model. For instance, by adding task vectors, we can combine diverse models to create a more effective multi-task model.