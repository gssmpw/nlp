\section{Related Work}
\label{sec2} 
Resilience in distributed multi-objective optimization plays a critical role across domains such as smart grids, transportation, logistics, and communication networks, where robust and adaptive systems are crucial for ensuring operational efficiency \cite{yazdani2023techno, qiao2023multi}. Convex distributed optimization has received significant attention, with a focus on addressing challenges posed by adversary agents, network structures, and varied application domains \cite{yang2019survey, fanitabasi2018review, patari2021distributed}. Earlier work examines the robustness and vulnerability of consensus-based distributed optimization to address limitations and assumptions related to adversary behavior, network topology, objective functions, and application domains \cite{fanitabasi2018review, fu2021resilient, zhang2023accelerated}. The presence of adversary agents significantly impacts the performance of distributed optimization models. These agents disrupt optimization by slowing convergence, manipulating data, or withholding participation, resulting in suboptimal performance \cite{gupta2020fault, gonzalez2018multi}. Table \ref{t1} provides a comparative analysis of related work in distributed optimization under adversarial conditions, focusing on adversary behavior, attack strategies, and their impact on network and system performance.

\begin{table*}[htbp]
  \caption{Comparison of literature on resilience in distributed optimization}
  \centering
  \footnotesize % Adjust font size here
  \begin{adjustbox}{width=\textwidth}
    \begin{tabular}{cp{1.5cm}p{1.5cm}p{3.5cm}p{2.5cm}p{2.5cm}p{3cm}}
      \toprule
      \textbf{Work} & \textbf{Adversarial behavior}  & \textbf{Adversary target} & \textbf{Knowledge of the system} & \textbf{Network} & \textbf{Performance measure} & \textbf{Algorithms / Techniques for Optimization Recovery} \\
      \midrule
      \cite{sundaram2018distributed} & Malicious \& Byzantine \footnotemark[2] & Consensus protocol & Full knowledge of network structure and cost functions of other agents & Connected undirected network & Distance to optimality minimization & Local filtering \\ 
      \midrule
      \cite{kuwaranancharoen2020byzantine} & Byzantine & Consensus process \& parameter agreement & Full knowledge of network structure and cost functions of other agents & Strongly connected directed network & Convergence to a bounded region containing the global minimizer & Distance-based filtering \\
      \midrule
      \cite{su2020byzantine} & Byzantine & Information exchange among agents & Full knowledge of network structure and cost functions of other agents & Complete directed network & Admissibility (structure of the convex coefficients) & Local filtering \\
      \midrule
      \cite{lin2020robustness} & Adversarial manipulation of observations & Single agent observation & Black-box access to an agent's policy and environment & Limited directed communication & Average reward \& team win rate & Gradient-based methods (Deep Q-learning) \\
      \midrule
      \cite{figura2021adversarial} & Malicious & Consensus-based MARL & Partial knowledge (compromises rewards) & Fully connected network & Average team reward & Consensus-based MARL \\
      \midrule
      \cite{zheng2021vulnerability} & Data perturbations (cyber-attacks) & DRL rewards & Full knowledge of DRL model parameters & DNN (power system topology) & Expected performance decay \& critical attack rate & None \\
      \midrule
      \cite{ishii2022overview} & Injection \& DoS attacks & Consensus in cyber-physical systems & Full knowledge of network structure and cost functions of neighbors & Robust sparse network & Resilient asymptotic consensus & Mean subsequence reduced \\
      \midrule
      \cite{yemini2022resilience} & Malicious data injections & Convergence to the global optimal point & Partial knowledge of network structure and neighbors' states & Undirected connected network & Convergence to optimal point & Probabilistic trust-based weight adjustment \& projection-based update \\
      \midrule
      \cite{du2023distributed} & Malicious \& Byzantine & Information exchange among agents & Full knowledge of network structure and neighbors' states & Directed connected spanning network & Convergence to optimal point & Markov switching communication topology \& Push-DIGing \\
      \midrule
      \cite{zhao2019resilient} & Malicious \& Byzantine & Consensus process and state updates & Full knowledge of network structure and neighbors' states & Undirected connected network & Convergence to optimal point & Resilient distributed optimization with trusted agents \& connected dominating set \\
      \midrule
      \cite{uribe2019resilient, turan2020resilient} & Impersonation Byzantine & Communication channels between agents and coordinator & Local knowledge & Directed network with central coordinator & Distance to optimality minimization & Primal-Dual \\
      \midrule
      \cite{ravi2019case} & Malicious & Consensus value & Local knowledge & Directed \& strongly connected & Distance to optimality minimization & FROST \\
      \midrule
      \cite{gentz2016data} & Malicious & Consensus value & Local knowledge & Undirected network & Distance to optimality minimization & Randomized gossip \\
      \midrule
      \cite{ding2018consensus, ding2021differentially} & Eavesdropping & Information exchange among agents & All transmitted messages & Undirected network & Convergence to a privacy-preserving approximate solution & Differentially private gradient tracking  \\
    \midrule
      \textbf{This work} & Selfish malicious & System-wide optimization& Local knowledge \& black-box access to network structure & Bidirectional hierarchical network & Optimization efficiency & I-EPOS \\    
      \bottomrule
    \end{tabular} 
  \end{adjustbox}
  \label{t1}
\end{table*}

    \footnotetext[2]{A node is considered malicious if it sends the same value to all its out-neighbors at each time-step, while a Byzantine node can send different values to different neighbors at each time-step.}
    
\subsection{Adversary Agents in Distributed Optimization}
Yang et al. \cite{yang2019survey} provide a comprehensive survey on distributed optimization. Notable advancements include extensions of consensus-based protocols by Sundaram et al. \cite{sundaram2018distributed} and Kuwaranancharoen et al. \cite{kuwaranancharoen2020byzantine}, which address adversarial threats in convex optimization. Su et al. \cite{su2020byzantine} enhance these methods with decentralized architectures and explore adversarial influence on global objectives. However, these approaches assume adversary agents have full knowledge of the network topology and the private functions of all agents. This coordination among adversaries compromises the privacy of the agents in the system.

\subsection{Adversarial Attacks in Multi-Agent Systems}
Adversarial attacks significantly impact reinforcement learning (RL) systems across applications such as robotics, video games, and smart grids, undermining system stability and performance \cite{guesmi2023physical, ali2023survey}. Lin et al. \cite{lin2020robustness} demonstrate how adversarial perturbations affect cooperative multi-agent RL (c-MARL), showing its vulnerability compared to single-agent RL. Figura et al. \cite{figura2021adversarial} highlight how a single adversary can influence consensus-based c-MARL systems, disrupting team objectives. Zheng et al. \cite{zheng2021vulnerability} introduce criticality-based perturbations in deep Q-networks, demonstrating substantial performance degradation due to adversarial attacks. These studies highlight that an adversary agent has the ability not only to disrupt system operations but also to manipulate the policy to align with its own adversarial objectives, thereby influencing other agents to adopt a policy of its preference. These insights underscore the critical need for robust defense against adversaries that manipulate policies and system states in RL systems.

\subsection{Cyber-Attacks and Resilient Control}
Cyber-attacks, including data injection and denial-of-service (DoS) attacks, pose significant threats to distributed optimization by disrupting system operations and consensus mechanisms \cite{ishii2022overview}. To address these challenges, Yemini et al. \cite{yemini2022resilience} introduce trust-based frameworks that mitigate malicious input, ensuring convergence to global optima. Similarly, Du et al. \cite{du2023distributed} and Zhao et al. \cite{zhao2019resilient} propose models relying on trusted agents to counteract adversarial influence. However, the effectiveness of these can be limited in scenarios with intermittent communication, such as ad hoc or robotic networks.

\subsection{Resource Allocation Challenges Under Adversaries}
In resource allocation, adversarial disruptions are mitigated using robust optimization algorithms. Uribe et al. \cite{uribe2019resilient} and Turan et al. \cite{turan2020resilient} propose primal-dual methods to tolerate adversaries by identifying and eliminating Byzantine inputs. Similarly, Ravi et al. \cite{ravi2019case} and Gentz et al. \cite{gentz2016data} focus on adversary detection, using statistical analysis and hypothesis testing to isolate malicious agents. These methods achieve resilience for up to 50\% adversary density. However, they assume adversarial influence is evenly distributed and may not generalize to more concentrated or dynamic adversarial settings.
 
Another approach focuses on devising an adversary detection model to identify malicious agents in distributed optimization systems \cite{ravi2019case, gentz2016data}. Ravi et al. \cite{ravi2019case} address the challenge of detecting and mitigating malicious inputs in a distributed optimization system. Their method focuses on utilizing the data values of the agents to identify and isolate potential malicious agents. The researchers impose an upper limit on the number of tolerable malicious agents, specifically setting it at half of the total number of agents in the network topology. On the other hand, Gentz et al. propose a detection method for insider attackers in randomized gossip-based sensor networks. This approach involves utilizing theory and hypothesis testing to analyze the statistical states of the sensors, enabling the detection of malicious agents within the network \cite{gentz2016data}.

\subsection{Privacy-Preserving Distributed Optimization}
Privacy-preserving distributed optimization safeguards sensitive agent information against eavesdropping adversaries using techniques such as differential privacy \cite{ding2018consensus, ding2021differentially}, homomorphic cryptography \cite{zhang2018enabling, lu2018privacy}, and gradient perturbation \cite{mao2020privacy, chen2023differentially}, to ensure secure information exchange. However, these studies focus on privacy protection rather than adversarial behavior in optimization contexts.

\subsection{Combinatorial Optimization Algorithms}
In distributed collective learning and combinatorial optimization, Hinrichs et al. \cite{hinrichs2014cohda, hinrichs2017distributed} propose COHDA, a combinatorial optimization heuristic designed for multi-agent systems. However, COHDA encounters scalability challenges due to increasing communication overhead as the number of agents grows. Pournaras et al. \cite{pournaras2017self} address this with EPOS,
a decentralized framework that enables agents to collaboratively optimize global resource allocation, particularly in participatory sharing economies. EPOS ensures privacy, autonomy, and scalability but encounters computational limitations when applied to wide tree structures with multiple child nodes \cite{pournaras2018decentralized}. I-EPOS extends EPOS by introducing decentralized iterative back-propagation and localized decision-making to enhance scalability \cite{pournaras2020collective, pournaras2018decentralized}. While these works significantly contribute to decentralized combinatorial optimization, none of them study the performance in the presence of adversary agents.

Research on adversarial attacks predominantly focuses on continuous distributed optimization, often analyzing specific attack types or assuming a limited number of adversaries, which may not accurately reflect real-world scenarios. These studies typically rely on complete graph assumptions and address single points of failure rather than system-wide resilience. While several solutions mitigate adversarial attacks in multi-agent optimization, there is a notable lack of comprehensive analyses of inherent system vulnerability, resilience, and how optimization collapses.

This study addresses the critical gap in understanding how adversary agents impact system functionality by introducing a generic adversarial model to analyze resilience and vulnerability in distributed multi-objective optimization. The primary objective is to assess in-depth the influence of adversary agents on system optimality. By filling this gap, this research aims to advance the design of self-healing strategies to enhance fault-tolerance and fault-correction in adversarial distributed optimization, which, to the best of our knowledge, has not been comprehensively explored in prior research.