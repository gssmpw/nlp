\documentclass[journal]{IEEEtran}
\usepackage{url} 
\usepackage{amsmath,amssymb}
\usepackage{booktabs}
\usepackage{adjustbox}
\usepackage{subcaption}
\usepackage{cite}
\renewcommand{\citepunct}{, }
\renewcommand{\citedash}{--}
\newcommand{\Agents}{\ensuremath{A }}
\newcommand{\NumAgents}{\ensuremath{\mathsf{n}}}
\newcommand{\AdversaryAgents}{\ensuremath{A_\mathsf{d}}}
\newcommand{\LegitimateAgents}{\ensuremath{A_\mathsf{l}}}
\newcommand{\PossiblePlans}{\ensuremath{P_\mathsf{a}}}
\newcommand{\Plan}{\ensuremath{p_\mathsf{a,i}}}
\newcommand{\SelectedPlan}{\ensuremath{s_\mathsf{a}}}
\newcommand{\GlobalResponse}{\ensuremath{g}}
\newcommand{\DiscomfortCost}{\ensuremath{D}}
\newcommand{\DiscomfortFunction}{\ensuremath{f_D}}
\newcommand{\InefficiencyCost}{\ensuremath{I}}
\newcommand{\InefficiencyFunction}{\ensuremath{f_I}}
\newcommand{\UnfairnessCost}{\ensuremath{U}}
\newcommand{\UnfairnessFunction}{\ensuremath{f_U}}
\newcommand{\NumPlans}{\ensuremath{k}}
\newcommand{\PlanSize}{\ensuremath{d}}


\begin{document}

\title{Optimization under Attack: Resilience, Vulnerability, and the Path to Collapse}

\author{
    \IEEEauthorblockN{Amal Aldawsari\textsuperscript{1,2,*}, Evangelos Pournaras\textsuperscript{1}} \\
    \IEEEauthorblockA{\textsuperscript{1}School of Computer Science, University of Leeds, Leeds, UK} \\
    \IEEEauthorblockA{\textsuperscript{2}College of Computer Science and Engineering, University of Hail, Hail, KSA}
    \thanks{\textsuperscript{*}Corresponding author: Amal Aldawsari. \\
    E-mail address: ml21aa2a@leeds.ac.uk; aa.aldosery@uoh.edu.sa.}
}
\maketitle

\begin{abstract}
Optimization is instrumental for improving operations of large-scale socio-technical infrastructures of Smart Cities, for instance, energy and traffic systems. In particular, understanding the performance of multi-agent discrete-choice combinatorial optimization under distributed adversary attacks is a compelling and underexplored problem, since multi-agent systems exhibit a large number of remote control variables that can influence in an unprecedented way the cost-effectiveness of distributed optimization heuristics. This paper unravels for the first time the trajectories of distributed optimization from resilience to vulnerability, and finally to collapse under varying adversary influence. Using real-world data to emulate over 28 billion multi-agent optimization scenarios, we exhaustively assess how the number of agents with different adversarial severity and network positioning influences optimization performance, including the influence on Pareto optimal points. With this novel large-scale dataset, made openly available as a benchmark, we disentangle how optimization remains resilient to adversaries and which adversary conditions are required to make optimization vulnerable or collapsed. These new findings can provide new insights for designing self-healing strategies for fault-tolerance and fault-correction in adversarial distributed optimization that have been missing so far. 
\end{abstract}

\begin{IEEEkeywords}
Optimization, Multi-agent systems, Adversary behavior, Resilience, Vulnerability, Distributed systems, Fault-tolerance
\end{IEEEkeywords}

\section{Introduction} \label{sec1}
The rapid development of Internet of Things (IoT) applications has brought about transformative changes in numerous domains, ranging from smart cities to industrial automation and healthcare \cite{perwej2019internet}. These applications involve vast networks of interconnected devices that generate substantial amounts of data, and require efficient and decentralized decision-making for processing \cite{ali2018applications}. Distributed optimization is essential in such scenarios, as it enables multiple agents to collaborate effectively without centralized coordination. This approach ensures scalability, reliability, and robust performance across diverse applications, including energy management, autonomous systems, and federated learning \cite{yang2019survey, nedic2009distributed, boyd2011distributed, zhou2021asynchronous, zhou2021graph}.

While distributed optimization is essential for achieving system-wide objectives, most algorithms rely on assumptions of rational, cooperative, and non-adversarial agents contributing toward the global objective without prioritizing their individual goals over collective outcomes. However, real-world scenarios often deviate from these assumptions, as adversarial agents can disrupt optimization systems by introducing inaccuracies, manipulating decisions, or compromising functionality \cite{gupta2020fault, ravi2019case, sundaram2018distributed, lu2020distributed}. For example, in smart grid systems, where autonomous agents (e.g., households) collaborate to manage energy distribution and prevent power outages, certain households may act adversarially by manipulating consumption data and prioritizing self-interest, i.e. their thermal comfort. Such disruptions distort energy allocation processes, leading to inefficient resource use and blackouts \cite{ravi2019case, sundaram2018distributed,  rajabi2021resilience, fanitabasi2018review, Pournaras2016}.

Several studies have examined multi-agent optimization in continuous-choice frameworks \cite{gupta2020fault,ravi2019case, sundaram2018distributed, lu2020distributed, fanitabasi2018review, gonzalez2018multi}. While stochastic optimization techniques address noise, they lack mechanisms to counteract strategic manipulations by adversarial agents \cite{hodgkinson2021multiplicative, spall2012stochastic}. These manipulations amplify system vulnerability by prioritizing individual goals over collective objectives, which can lead to inefficiencies, instability, and eventual collapse \cite{hancock2022avoiding, zan2023adversarial}. Despite this, adversarial disruptions in discrete-choice settings have received little attention.

This paper addresses this gap by investigating the resilience, vulnerability, and collapse of multi-agent systems in discrete-choice optimization under adversarial conditions, offering a novel framework for understanding system behavior. Resilience refers to the system ability to maintain performance despite adversarial influence. Vulnerability captures the emergence of inefficiencies due to adversarial behaviors, and collapse occurs when the system fails to achieve its objectives. This study evaluates the impact of adversarial agents on optimization performance, analyzing critical parameters such as the number of adversarial agents, their adversarial severity, and their network positions. By systematically examining these dynamics, the paper provides critical insights into the conditions under which systems transition from resilience to collapse, unravelling new insights for the development of strategies \cite{9466159} for self-healing, fault-tolerance, and fault-correction in adversarial environments.

The main contributions of this paper are outlined as follows:
\begin{itemize}
    \item An adversarial model for discrete-choice multi-objective optimization problems. 
    \item A novel evaluation framework for characterizing resilience, vulnerability, and collapse in distributed optimization systems under adversarial conditions.
    \item The applicability of the proposed adversarial model in different application domains.
    \item  Open large-scale benchmark datasets comprising over 13 million experiments on real-world data, for comprehensive evaluation of distributed optimization systems in the presence of adversaries.
    \item A comprehensive evaluation of the adversarial impact on system efficiency and agent discomfort. 
    \item New insights highlighting adversarial influences on optimality in various application scenarios.
    \item An open-source software artifact implementation of the proposed adversarial model for the I-EPOS collective learning algorithm\footnote{Available at \url{https://github.com/epournaras/EPOS}}.
\end{itemize}

The rest of this paper is organized as follows: Section \ref{sec2} reviews related literature on adversarial impacts in distributed optimization. Section \ref{sec3} introduces the proposed adversarial model, along with the problem formulation, detailing the network model and optimization challenge. Section \ref{sec4} outlines the experimental methodology and evaluation metrics. The key findings are presented in Section \ref{sec5}, discussing system behavior under varying adversarial conditions. Finally, Section \ref{sec6} concludes the paper and outlines directions for future research.

\section{Related Work} \label{sec2} 
Resilience in distributed multi-objective optimization plays a critical role across domains such as smart grids, transportation, logistics, and communication networks, where robust and adaptive systems are crucial for ensuring operational efficiency \cite{yazdani2023techno, qiao2023multi}. Convex distributed optimization has received significant attention, with a focus on addressing challenges posed by adversary agents, network structures, and varied application domains \cite{yang2019survey, fanitabasi2018review, patari2021distributed}. Earlier work examines the robustness and vulnerability of consensus-based distributed optimization to address limitations and assumptions related to adversary behavior, network topology, objective functions, and application domains \cite{fanitabasi2018review, fu2021resilient, zhang2023accelerated}. The presence of adversary agents significantly impacts the performance of distributed optimization models. These agents disrupt optimization by slowing convergence, manipulating data, or withholding participation, resulting in suboptimal performance \cite{gupta2020fault, gonzalez2018multi}. Table \ref{t1} provides a comparative analysis of related work in distributed optimization under adversarial conditions, focusing on adversary behavior, attack strategies, and their impact on network and system performance.

\begin{table*}[htbp]
  \caption{Comparison of literature on resilience in distributed optimization}
  \centering
  \footnotesize % Adjust font size here
  \begin{adjustbox}{width=\textwidth}
    \begin{tabular}{cp{1.5cm}p{1.5cm}p{3.5cm}p{2.5cm}p{2.5cm}p{3cm}}
      \toprule
      \textbf{Work} & \textbf{Adversarial behavior}  & \textbf{Adversary target} & \textbf{Knowledge of the system} & \textbf{Network} & \textbf{Performance measure} & \textbf{Algorithms / Techniques for Optimization Recovery} \\
      \midrule
      \cite{sundaram2018distributed} & Malicious \& Byzantine \footnotemark[2] & Consensus protocol & Full knowledge of network structure and cost functions of other agents & Connected undirected network & Distance to optimality minimization & Local filtering \\ 
      \midrule
      \cite{kuwaranancharoen2020byzantine} & Byzantine & Consensus process \& parameter agreement & Full knowledge of network structure and cost functions of other agents & Strongly connected directed network & Convergence to a bounded region containing the global minimizer & Distance-based filtering \\
      \midrule
      \cite{su2020byzantine} & Byzantine & Information exchange among agents & Full knowledge of network structure and cost functions of other agents & Complete directed network & Admissibility (structure of the convex coefficients) & Local filtering \\
      \midrule
      \cite{lin2020robustness} & Adversarial manipulation of observations & Single agent observation & Black-box access to an agent's policy and environment & Limited directed communication & Average reward \& team win rate & Gradient-based methods (Deep Q-learning) \\
      \midrule
      \cite{figura2021adversarial} & Malicious & Consensus-based MARL & Partial knowledge (compromises rewards) & Fully connected network & Average team reward & Consensus-based MARL \\
      \midrule
      \cite{zheng2021vulnerability} & Data perturbations (cyber-attacks) & DRL rewards & Full knowledge of DRL model parameters & DNN (power system topology) & Expected performance decay \& critical attack rate & None \\
      \midrule
      \cite{ishii2022overview} & Injection \& DoS attacks & Consensus in cyber-physical systems & Full knowledge of network structure and cost functions of neighbors & Robust sparse network & Resilient asymptotic consensus & Mean subsequence reduced \\
      \midrule
      \cite{yemini2022resilience} & Malicious data injections & Convergence to the global optimal point & Partial knowledge of network structure and neighbors' states & Undirected connected network & Convergence to optimal point & Probabilistic trust-based weight adjustment \& projection-based update \\
      \midrule
      \cite{du2023distributed} & Malicious \& Byzantine & Information exchange among agents & Full knowledge of network structure and neighbors' states & Directed connected spanning network & Convergence to optimal point & Markov switching communication topology \& Push-DIGing \\
      \midrule
      \cite{zhao2019resilient} & Malicious \& Byzantine & Consensus process and state updates & Full knowledge of network structure and neighbors' states & Undirected connected network & Convergence to optimal point & Resilient distributed optimization with trusted agents \& connected dominating set \\
      \midrule
      \cite{uribe2019resilient, turan2020resilient} & Impersonation Byzantine & Communication channels between agents and coordinator & Local knowledge & Directed network with central coordinator & Distance to optimality minimization & Primal-Dual \\
      \midrule
      \cite{ravi2019case} & Malicious & Consensus value & Local knowledge & Directed \& strongly connected & Distance to optimality minimization & FROST \\
      \midrule
      \cite{gentz2016data} & Malicious & Consensus value & Local knowledge & Undirected network & Distance to optimality minimization & Randomized gossip \\
      \midrule
      \cite{ding2018consensus, ding2021differentially} & Eavesdropping & Information exchange among agents & All transmitted messages & Undirected network & Convergence to a privacy-preserving approximate solution & Differentially private gradient tracking  \\
    \midrule
      \textbf{This work} & Selfish malicious & System-wide optimization& Local knowledge \& black-box access to network structure & Bidirectional hierarchical network & Optimization efficiency & I-EPOS \\    
      \bottomrule
    \end{tabular} 
  \end{adjustbox}
  \label{t1}
\end{table*}

    \footnotetext[2]{A node is considered malicious if it sends the same value to all its out-neighbors at each time-step, while a Byzantine node can send different values to different neighbors at each time-step.}
    
\subsection{Adversary Agents in Distributed Optimization}
Yang et al. \cite{yang2019survey} provide a comprehensive survey on distributed optimization. Notable advancements include extensions of consensus-based protocols by Sundaram et al. \cite{sundaram2018distributed} and Kuwaranancharoen et al. \cite{kuwaranancharoen2020byzantine}, which address adversarial threats in convex optimization. Su et al. \cite{su2020byzantine} enhance these methods with decentralized architectures and explore adversarial influence on global objectives. However, these approaches assume adversary agents have full knowledge of the network topology and the private functions of all agents. This coordination among adversaries compromises the privacy of the agents in the system.

\subsection{Adversarial Attacks in Multi-Agent Systems}
Adversarial attacks significantly impact reinforcement learning (RL) systems across applications such as robotics, video games, and smart grids, undermining system stability and performance \cite{guesmi2023physical, ali2023survey}. Lin et al. \cite{lin2020robustness} demonstrate how adversarial perturbations affect cooperative multi-agent RL (c-MARL), showing its vulnerability compared to single-agent RL. Figura et al. \cite{figura2021adversarial} highlight how a single adversary can influence consensus-based c-MARL systems, disrupting team objectives. Zheng et al. \cite{zheng2021vulnerability} introduce criticality-based perturbations in deep Q-networks, demonstrating substantial performance degradation due to adversarial attacks. These studies highlight that an adversary agent has the ability not only to disrupt system operations but also to manipulate the policy to align with its own adversarial objectives, thereby influencing other agents to adopt a policy of its preference. These insights underscore the critical need for robust defense against adversaries that manipulate policies and system states in RL systems.

\subsection{Cyber-Attacks and Resilient Control}
Cyber-attacks, including data injection and denial-of-service (DoS) attacks, pose significant threats to distributed optimization by disrupting system operations and consensus mechanisms \cite{ishii2022overview}. To address these challenges, Yemini et al. \cite{yemini2022resilience} introduce trust-based frameworks that mitigate malicious input, ensuring convergence to global optima. Similarly, Du et al. \cite{du2023distributed} and Zhao et al. \cite{zhao2019resilient} propose models relying on trusted agents to counteract adversarial influence. However, the effectiveness of these can be limited in scenarios with intermittent communication, such as ad hoc or robotic networks.

\subsection{Resource Allocation Challenges Under Adversaries}
In resource allocation, adversarial disruptions are mitigated using robust optimization algorithms. Uribe et al. \cite{uribe2019resilient} and Turan et al. \cite{turan2020resilient} propose primal-dual methods to tolerate adversaries by identifying and eliminating Byzantine inputs. Similarly, Ravi et al. \cite{ravi2019case} and Gentz et al. \cite{gentz2016data} focus on adversary detection, using statistical analysis and hypothesis testing to isolate malicious agents. These methods achieve resilience for up to 50\% adversary density. However, they assume adversarial influence is evenly distributed and may not generalize to more concentrated or dynamic adversarial settings.
 
Another approach focuses on devising an adversary detection model to identify malicious agents in distributed optimization systems \cite{ravi2019case, gentz2016data}. Ravi et al. \cite{ravi2019case} address the challenge of detecting and mitigating malicious inputs in a distributed optimization system. Their method focuses on utilizing the data values of the agents to identify and isolate potential malicious agents. The researchers impose an upper limit on the number of tolerable malicious agents, specifically setting it at half of the total number of agents in the network topology. On the other hand, Gentz et al. propose a detection method for insider attackers in randomized gossip-based sensor networks. This approach involves utilizing theory and hypothesis testing to analyze the statistical states of the sensors, enabling the detection of malicious agents within the network \cite{gentz2016data}.

\subsection{Privacy-Preserving Distributed Optimization}
Privacy-preserving distributed optimization safeguards sensitive agent information against eavesdropping adversaries using techniques such as differential privacy \cite{ding2018consensus, ding2021differentially}, homomorphic cryptography \cite{zhang2018enabling, lu2018privacy}, and gradient perturbation \cite{mao2020privacy, chen2023differentially}, to ensure secure information exchange. However, these studies focus on privacy protection rather than adversarial behavior in optimization contexts.

\subsection{Combinatorial Optimization Algorithms}
In distributed collective learning and combinatorial optimization, Hinrichs et al. \cite{hinrichs2014cohda, hinrichs2017distributed} propose COHDA, a combinatorial optimization heuristic designed for multi-agent systems. However, COHDA encounters scalability challenges due to increasing communication overhead as the number of agents grows. Pournaras et al. \cite{pournaras2017self} address this with EPOS,
a decentralized framework that enables agents to collaboratively optimize global resource allocation, particularly in participatory sharing economies. EPOS ensures privacy, autonomy, and scalability but encounters computational limitations when applied to wide tree structures with multiple child nodes \cite{pournaras2018decentralized}. I-EPOS extends EPOS by introducing decentralized iterative back-propagation and localized decision-making to enhance scalability \cite{pournaras2020collective, pournaras2018decentralized}. While these works significantly contribute to decentralized combinatorial optimization, none of them study the performance in the presence of adversary agents.

Research on adversarial attacks predominantly focuses on continuous distributed optimization, often analyzing specific attack types or assuming a limited number of adversaries, which may not accurately reflect real-world scenarios. These studies typically rely on complete graph assumptions and address single points of failure rather than system-wide resilience. While several solutions mitigate adversarial attacks in multi-agent optimization, there is a notable lack of comprehensive analyses of inherent system vulnerability, resilience, and how optimization collapses.

This study addresses the critical gap in understanding how adversary agents impact system functionality by introducing a generic adversarial model to analyze resilience and vulnerability in distributed multi-objective optimization. The primary objective is to assess in-depth the influence of adversary agents on system optimality. By filling this gap, this research aims to advance the design of self-healing strategies to enhance fault-tolerance and fault-correction in adversarial distributed optimization, which, to the best of our knowledge, has not been comprehensively explored in prior research.

\section {Adversarial Distributed Optimization} \label{sec3}
\subsection{Problem Formulation}
Resilience in distributed optimization is essential for maintaining system performance under adversarial conditions. Adversary agents disrupt operations, degrade efficiency, and increase system vulnerability. This raises key questions: How do adversary agents influence the efficiency and stability of distributed optimization systems? What thresholds of adversarial behavior lead to transitions from resilience to vulnerability or collapse? How do parameters such as adversary density, adversarial severity, and network positioning influence these transitions?

To address these challenges, we propose a generic adversarial distributed optimization model tailored to discrete-choice scenarios. This model is used to investigate the trade-offs between system-wide and individual agent goals in adversarial settings. It incorporates critical parameters, including adversary density, adversarial severity, and structural positioning, providing a robust framework to evaluate system vulnerability and resilience. This study identifies thresholds for transitions from resilience to collapse, providing an in-depth understanding of system behavior under adversarial influence. These findings inform the development of self-healing strategies that enhance fault-tolerance and mitigate adversarial impacts across diverse distributed optimization applications.

\subsection{Network Model}
Consider a network with \NumAgents{} agents, denoted by \Agents, each identified by a unique ID in the set $\{1,2,3,...,\NumAgents\}$. The network topology is represented as a connected graph $G = (\Agents, E)$, where \Agents{} is the set of agents, and $E$ is the set of edges, such that $(j, i) \in E \neq (i, j) \in E$. Agents interact within a self-organized network through bidirectional communication to exchange information and update their states to align with the system goals.

Table \ref{t2} defines the notations used throughout the paper to formalize the network model and optimization framework.

\begin{table}[htbp]
 \caption{Nomenclature utilized in this research}
    \label{t2}
     \centering
    \begin{tabular}{ll}
    \toprule
    \textbf{Notation} & \textbf{Description} \\
    \midrule
    \Agents  & set of agents in the network \\
    \NumAgents$ = |\Agents|$  & number of agents  \\
    $\AdversaryAgents \subseteq \Agents$ & set of adversary agents  \\
    $\LegitimateAgents \subseteq \Agents$  & set of legitimate agents \\
    \PossiblePlans & set of possible plans of agent $a$  \\
    \Plan$ \in \PossiblePlans$ & plan $i$ of agent $a$ \\
    \NumPlans & number of plans \\
    \PlanSize & size of plan \\ 
    \SelectedPlan & selected plan of agent $a$ \\
    \GlobalResponse & global response \\
    \DiscomfortCost & discomfort cost \\
    \DiscomfortFunction & discomfort cost function \\
    \InefficiencyCost & inefficiency cost \\
    \InefficiencyFunction & inefficiency cost function\\
    \bottomrule
    \end{tabular}
\end{table}

\subsection{Optimization Framework in Discrete-Choice Scenarios}
Each agent \(a \in \Agents\) selects one and only one option from a finite set of \NumPlans{} options referred to as \textit{possible plans} \PossiblePlans \(\subset \mathbb{R}^d\). Each plan \Plan \(\in \PossiblePlans\) is a sequence of size \PlanSize, which has real values that correspond to a resource allocation. The chosen plan, referred to as the \textit{selected plan} \SelectedPlan, determines the agent's future operation. The \textit{global response}, defined as \GlobalResponse = \(\sum_{a \in \Agents} \SelectedPlan\), aggregates all selected plans of all agents to evaluate overall system performance and ensure collective contributions toward shared objectives. For instance, in power grid systems, each household acts as an agent with multiple plans representing low/medium/high appliance energy consumption levels. Each household selects one plan, contributing to the \GlobalResponse, which determines the total energy consumption.

Agents balance their individual preferences with system-wide goals, which often involve conflicting criteria. Each agent has an individual preference for its plans, calculated by the \textit{discomfort cost} (\DiscomfortCost), such that \DiscomfortCost\(_{a,i} = \DiscomfortFunction(\Plan)\), where \DiscomfortFunction{} is the agent's preference associated with a particular plan. Each agent $a$ measures the costs \DiscomfortCost{} for each possible plan \Plan $\in$ \PossiblePlans{} and the plan with the minimum cost is selected. While agents aim to minimize their own discomfort, they may also consider system-wide metrics such as the \textit{inefficiency cost} (\InefficiencyCost). The inefficiency cost (\InefficiencyCost) is the measure used to evaluate the collective system-wide performance based on the aggregated responses of all agents. It represents the system-wide performance inefficiency that agents aim to minimize through coordinated decision-making: $\InefficiencyCost = \InefficiencyFunction\left(\sum_{a=1}^{\NumAgents}(\SelectedPlan)\right)$. 

Agents optimize their decisions by minimizing a weighted combination of these costs, as illustrated in Equation \ref{eq1}. The behavior of agent $a$ is modeled by the corresponding weights $\beta_a, \text{ and } \alpha_a$, prioritizing efficiency and comfort, respectively. A higher weight indicates a higher preference for minimizing the corresponding objective. On the other hand, a weight of 0 means that the corresponding objective is not considered. For example, When $\beta_a = 0, \text{ and } \alpha_a = 1$, the agent prioritizes system-wide efficiency, acting as altruistic. Conversely, when $\beta_a = 1, \text{ and } \alpha_a = 0$, the agent prioritizes its own interest, behaving as selfish.

\begin{align}
    \SelectedPlan &= \arg\min_{i=1}^{\NumPlans} \left( \alpha_a \cdot \InefficiencyCost_{a,i} + \beta_a \cdot \DiscomfortCost_{a,i} \right) \nonumber \\
     &= \arg\min_{i=1}^{\NumPlans}  \alpha_a \cdot \InefficiencyFunction\left(s_1, s_2, \ldots, s_{\NumAgents}\right) \notag \\
    &\quad + \beta_a \cdot \DiscomfortFunction \left(\DiscomfortCost_{1,s}, \DiscomfortCost_{2,s}, \ldots, \DiscomfortCost_{\NumAgents,s}\right) \label{eq1}
\end{align}
 
\begin{align*}
\text{where} \quad  \alpha_a + \beta_a &= 1 \quad \text{\&} \quad \alpha_a, \beta_a \in [0, 1]
\end{align*}

The decision-making process in distributed optimization is influenced not only by each agent's individual objectives but also by the collective impact of their choices on system-wide goals. This interdependence introduces significant complexity, particularly when cost functions are non-linear, as agents' choices depend on one another. Minimizing inefficiency and discomfort costs under such conditions is an NP-hard problem \cite{pournaras2018decentralized}. These challenges are further exacerbated by the lack of complete information about other agents' selections and the need for coordination among agents' choices. Addressing these issues requires a decentralized optimization framework that enables agents to iteratively refine their plan selections based on aggregated contributions and prior iterations (see Section \ref{sec4-1}).

\subsection {Adversarial Distributed Optimization Model} 
To study the resilience of distributed optimization in an adversarial environment, we partition the set of agents, \Agents, into two subsets: adversary agents (\AdversaryAgents{}) and legitimate agents (\LegitimateAgents{}). Adversary agents, $\AdversaryAgents \subseteq \Agents$, prioritize their individual interests over collective system goals by adapting their behavior to maximize personal benefits. This behavior disregards system-wide efficiency and leads to suboptimal outcomes for the overall system. Legitimate agents, $\LegitimateAgents \subseteq \Agents$, align their actions with system-wide objectives to optimize overall performance. The total set of agents is defined as $A = \AdversaryAgents \cup \LegitimateAgents$.

Adversarial behavior amplifies the inefficiency cost \InefficiencyCost{}, reflecting the trade-off between minimizing individual discomfort (\DiscomfortCost{}) and optimizing overall system efficiency (\InefficiencyCost{}). While \DiscomfortCost{} focuses on individual preferences, \InefficiencyCost{} addresses the system-wide inefficiency caused by deviations from optimal resource allocation, underscoring the conflict between personal and collective goals. For instance, in a bike-sharing system, optimization ensures a balanced distribution of bikes across stations to meet user demand. Legitimate users select pick-up and drop-off stations with consideration for system-wide efficiency, aiming to maintain network equilibrium. Conversely, adversary users prioritize their convenience, choosing stations that minimize their discomfort without regard for the network state. This behavior creates imbalances, such as empty or overstocked stations, reducing overall efficiency and user satisfaction.

\section{Experimental Methodology} \label{sec4}
This paper proposes a novel adversarial distributed optimization model to study the performance of multi-agent discrete-choice combinatorial optimization
under distributed adversary attacks.

\subsection{Decentralized Optimization Framework}\label{sec4-1}
The proposed model is implemented within the \textit{Iterative Economic Planning and Optimized Selections} (I-EPOS)\footnote{Available at \url{https://github.com/epournaras/EPOS}}, a collective learning framework. I-EPOS employs a self-organized, multi-level hierarchical network structure that ensures efficient communication and coordinated decision-making while reducing communication overhead \cite{pournaras2013multi}. 

I-EPOS enables the agents to iteratively adjust their plan selections based on the aggregated plans of the agents beneath and previous iteration choices. The proposed model operates iteratively, enabling agents to coordinate their choices in collective decision-making. Each iteration consists of two distinct phases: a bottom-up phase and a top-down phase. During the bottom-up phase, agents select plans based on the aggregated choices of agents in the subtree beneath, as well as the selections made by all agents in the previous iteration. Conversely, the top-down phase addresses incomplete knowledge from higher branches in the hierarchy, enabling agents to revert to previous selections if no cost reduction is achieved. This process continues until a predefined iteration limit is reached or no further improvement in the optimization objective occurs \cite{pournaras2018decentralized, pournaras2020collective}.

The hierarchical network structure is organized as an acyclic graph, where each parent agent aggregates responses from its children without redundancy, explicitly avoiding double counting of contributions from lower nodes in the hierarchy. This design ensures efficient coordination and alignment of individual decisions with system-wide objectives while maintaining overall optimization \cite{pournaras2018decentralized, pournaras2013multi, pournaras2020holarchic}. I-EPOS is well-suited for adversarial scenarios in Smart City applications due to its scalability, adaptability to diverse agent behaviors, and ability to handle adversarial conditions \cite{pournaras2020collective, pournaras2024collective}. 

\subsection{Experimental Setup}
Experiments are conducted using multiple HPC servers with varying configurations that support large-scale simulations and ensure computational efficiency. These include high-memory nodes (up to 768 GB) and multi-core processors (up to 40 cores per node). In addition to these servers, the University of Leeds ARC4 system \footnote{ARC4 is an HPC cluster at Leeds providing a Linux-based HPC service based on CentOS 7. More information: \url{https://arcdocs.leeds.ac.uk/systems/arc4.html}} is utilized. The ARC4 system includes two nodes, each equipped with 40 cores, 768 GB of memory, and 800 GB of storage, providing robust computational capacity for large-scale experiments.


\subsection{Application Scenarios}

\begin{table*}[htbp]
  \centering
  \caption{Description of the datasets and experimental setup in this research}
  \begin{adjustbox}{width=\textwidth}
  \begin{tabular}{p{2cm}p{1cm}p{1cm}p{1cm}p{1.5cm}p{2.5cm}p{3.5cm}p{2.2cm}} 
    \toprule
    \textbf{Dataset Name} & \textbf{No. Agents} & \textbf{No. Plans} &  \textbf{Plan Size} & \textbf{Agents}&\textbf{Discomfort Cost}& \textbf{Inefficiency Cost} & \textbf{Total Experiments} \\
    \midrule
    Energy & 1000 & 10 & 144 & Households &Agent preference based on time shift & Energy demand & 30,018,000 \\ 
     \midrule
     Data-collective & 72  & 3  & 64 & participants  & Privacy loss & Data collective inefficiency (quality of collected data) & 65,433,600 (2 target signals) \\ 
     \midrule
     Voting  & 266  & 31 & 5  & Voters  & Compromise &  Polarization & 97,551,840 (120 target signals) \\ 
    \bottomrule
  \end{tabular}
\end{adjustbox}
\label{t3}
\end{table*}

\subsubsection{Energy-demand dataset}
The energy application scenario uses a dataset derived from simulated zonal power transmission in the Pacific Northwest\footnote{Available upon request at \url{http://www.pnwsmartgrid.org/participants.asp}}. The dataset includes power consumption profiles for 1,000 users, with each user represented by an agent containing 10 possible plans. Each plan comprises a 144-length sequence representing electricity consumption at 5-minute intervals over a 12-hour period. These plans are generated using load-shifting strategies to balance grid load during peak and off-peak hours, reducing strain on the energy system. Plans are ranked by preference scores ranging from 0 to 1, with higher scores reflecting greater alignment with the user's original consumption patterns. 
The inefficiency cost is measured as the deviation in aggregated energy consumption from the desired load-balancing levels, capturing the system ability to maintain stability and efficiency. Adversarial households disrupt the system by selecting plans that counteract load balancing, thereby increasing the risk of grid instability during peak periods.

\subsubsection{Privacy dataset}
The privacy dataset originates from a living-lab experiment at the Decision Science Laboratory\footnote{\url{https://www.descil.ethz.ch}} of ETH Zurich, involving 72 participants evaluating 64 data-sharing scenarios that involve 4 sensor types, data collectors, and contexts \cite{pournaras2024collective}. The data-sharing choices of each participant determine three data-sharing plans, representing their intrinsic motivation to share and two rewarded scenarios. The plans are assessed using privacy valuation schemes assigning normalized costs ranging from 0 to 1, where lower costs indicate less privacy compromise. The dataset facilitates testing under high and low privacy-preservation target signals, reflecting intrinsic preferences for data-sharing behaviors. The inefficiency cost is calculated based on the reduction in the quality of the aggregated data due to adversarial participants prioritizing minimal data sharing over collective goals. Adversarial participants disrupt coordination by focusing solely on minimizing their data sharing, under-mining the quality of service of data collectors.

\subsubsection{Voting dataset}
This new dataset is derived from voting data in a regional election with five candidates and 266 voters\footnote{The UK Labour Party Leadership Vote Available at \url{https://preflib.simonrey.fr/datasets}} \cite{majumdar2024score}. Each voter has 31 alternative voting plans, representing ranked preferences among the five candidates.  The optimization focuses on minimizing polarization in decision outcomes, which refers to the extent of divergence in voters’ preferences from a collectively agreed compromise. Inefficiency cost is measured as the cost of polarized decision outcomes. To ensure fair representation, 120 target signals are generated from all combinations of values 0, 0.25, 0.5, 0.75, and 1. Adversarial behavior occurs when voters prioritize minimizing their personal compromise cost, disregarding collective consensus, which amplifies polarization and disrupts the system ability to achieve shared, balanced outcomes.

Table \ref{t3} provides an overview of each dataset used in this research, including the number of agents, the number and size of plans per agent, agent representation, the corresponding discomfort and inefficiency cost functions, and the total number of experiments conducted.

\subsection{Varying Dimensions and Performed Experiments}
The experiments systematically evaluate the resilience and vulnerability of the system across the following dimensions:
\begin{itemize}
\item \textbf{Scale of adversaries ($|\AdversaryAgents|$):} Incrementally increase the number of adversary agents \AdversaryAgents{} from 1 to \NumAgents{} across all datasets to analyze performance under varying adversary densities; i.e., $\AdversaryAgents=\{ a \mid a \in \Agents\}$.

\item \textbf{Adversarial severity ($\beta$):} The adversarial preference to minimize discomfort cost (\(\beta\)) is varied across 30 levels, with $\beta$ incrementing from 0 to 1 such as $\beta = \frac{b}{30}$ for $b = \{1, 2, 3, ..., 30\}$. This variation captures the impact of varying levels of adversarial intent, where agents prioritize their personal objectives at the expense of system-wide goals, on overall system performance.

\item \textbf{Adversary position:} The influence of adversary positions within the hierarchical network is analyzed using two approaches: layer-wise and cumulative structural analysis. A binary tree structure is employed, with each hierarchical layer containing approximately $\log_2 |A|$ agents, where $|A|$ is the total number of agents. The layer-wise analysis evaluates inefficiency costs across individual hierarchical layers under varying adversary scales (25\%, 50\%, 75\%, 100\%) and behavior levels ($\beta$ = 0.1, 0.4, 0.7, 1.0). The cumulative analysis examines the aggregated impact of adversary agents propagating through the network in top-down (root-to-leaf) and bottom-up (leaf-to-root) configurations.
\end{itemize}

For each dataset, experiments are conducted with 30 adversary behavior levels and 100 simulations per configuration, systematically analyzing the impact of adversary count, placement, and behavior on system performance. Additionally, experiments account for adversary positioning within the hierarchy, evaluated across four scales of adversaries and four levels of adversarial behavior, with the number of layers determined by $\log_2 |A|$ for the binary tree structure. Furthermore, the cumulative structure analysis is performed by adding adversaries sequentially, both top-down and bottom-up, resulting in an additional $2 \times |A|$ experiments. The total number of experiments per dataset is calculated as: $\text{Total experiments (per dataset)} = \text{number of signals} \times \left[(|\AdversaryAgents| \times 30 \times 100) + (100 \times 4 \times 4 \times \log_2 |A|) + (2 \times |A|)\right].$

\subsection{Evaluation Metrics}

\textbf{Optimization objectives:} 
Three metrics evaluate system performance: inefficiency cost \InefficiencyCost{}, discomfort cost \DiscomfortCost{}, and compromise cost of legitimate agents. The inefficiency cost measures the overall cost incurred by the system. The discomfort cost evaluates agents' dissatisfaction with non-preferred choices. The compromise cost quantifies the extent to which legitimate agents adjust their individual preferences to align with collective goals under adversarial influence. This metric is calculated as the deviation between the selected plans of legitimate agents and their most preferred plans. These metrics evaluate the trade-offs between individual agent goals and system-wide objectives, particularly under varying adversarial conditions.

\textbf{Pareto optimality:}
In multi-objective optimization, the Pareto front represents the set of non-dominated solutions where no objective can be improved without compromising another. The knee point on the Pareto front indicates the solution that achieves the best trade-off between competing objectives, making it a key decision-making criterion \cite{sun2024knee, li2020knee}.

This study identifies the knee point using the Minimum Manhattan Distance (MMD) method, which measures the distance between each solution on the Pareto front and an ideal reference point where both objectives are optimized. The solution with the smallest distance to the ideal point is selected as the knee point. This approach ensures a balanced evaluation of discomfort cost (\DiscomfortCost{}) and inefficiency cost (\InefficiencyCost{}) while maintaining alignment with established methodologies in the literature \cite{li2020knee}.

\textbf{Resilience, vulnerability, and collapse framework:}
To define thresholds for resilience, vulnerability, and collapse in distributed optimization, we apply the multi-Otsu thresholding method. The Otsu method is an efficient technique for dividing data into distinct regions by minimizing intra-class variance \cite{otsu1979, merzban2019efficient}. In this study, the method segments data into three regions based on inefficiency levels: resilience (low inefficiency), vulnerability (moderate inefficiency), and collapse (high inefficiency). This framework provides a robust method for segmenting inefficiency data into resilience, vulnerability, and collapse states, enabling a clear assessment of system performance transitions under adversarial conditions.

\section{Results Analysis and Discussion} \label{sec5}
This section presents the results of extensive experiments evaluating the impact of adversarial agents on multi-objective distributed optimization across the Energy, Voting, and Privacy datasets.


\begin{figure*}[htbp]
  \centering
  \begin{subfigure}{\textwidth}
    \centering
    \includegraphics[width=\textwidth]{InefficinecyThreshold-PREF.pdf}
    \caption{Inefficiency costs}
    \label{fig:inefficinecy}
  \end{subfigure}

  \begin{subfigure}{\textwidth}
    \centering
    \includegraphics[width=\textwidth]{Discomfort-threshold-PREF.pdf}
    \caption{Discomfort costs}
    \label{fig:discomfort}
  \end{subfigure}

  \begin{subfigure}{\textwidth}
    \centering
    \includegraphics[width=\textwidth]{compromised-legit-threshold-PREF.pdf}
    \caption{Compromised discomfort costs for non-adversary agents}
    \label{fig:compromised}
  \end{subfigure}
    \caption{Multi-objective optimization performance across different numbers of adversary agents and various levels of adversaries within the Energy, Voting, and Privacy datasets. R, V, and C indicate regions of Resilience, Vulnerability, and Collapse.}
  \label{fig:combined_plots}
\end{figure*}

\subsection{Resilience Analysis}
Figure \ref{fig:combined_plots} illustrates inefficiency costs, discomfort costs, and compromised discomfort costs across varying scale of adversaries and behavior levels. These metrics collectively capture system-wide inefficiency, individual agent dissatisfaction, and the trade-offs faced by legitimate agents under adversarial conditions.

\paragraph{Energy Dataset}
The Energy dataset demonstrates notable stability, maintaining resilience across more than 90\% of the operational space. Inefficiency costs remain low for $\beta < 0.8$ and scale of adversaries below 30\%, reflecting the system ability to withstand moderate adversarial behavior. Vulnerability arises between 30\% and 85\% adversary agents under high adversarial severity($\beta \geq 0.9$), transitioning to collapse when proportions exceed 85\%. Collapse is marked by a sharp rise in inefficiency up to 4000 at $\beta = 1$\footnote{Values for $\beta=1$ are excluded from the visualizations to avoid saturation of the heatmap due to extremely high inefficiency values.}.
Discomfort costs exhibit a slight reduction in resilient regions, declining by 8\% from the highest value, but collapse occurs when $\beta > 0.9$ and scale of adversaries exceed 50\%, with discomfort stabilizing near zero, indicating a system prioritizing agent satisfaction over functionality under extreme conditions.
Compromised discomfort costs for legitimate agents rise steadily as number of adversaries increase. In resilient regions ($\beta < 0.85$ and scale of adversaries below 40\%), these costs remain low and manageable. However, vulnerability emerges for $\beta \geq 0.9$ and scale of adversaries around 30\%, with compromised discomfort costs escalating sharply in collapse regions where proportions exceed 40\% at high levels of adversarial behavior ($\beta > 0.9$) ,where discomfort trade-offs become unsustainable in highly adversarial environments.

\paragraph{Voting Dataset}
The Voting dataset demonstrates significant stability, maintaining resilience across more than 90\% of the operational space. Inefficiency remains low for $\beta < 0.9$ and scale of adversaries below 50\%. Vulnerability emerges between 50\% and 70\% adversary agents, with inefficiency increasing by 111\%. Collapse occurs at $\beta \geq 0.96$ and proportions exceeding 70\%. Discomfort costs decline gradually in resilient regions and are entirely eliminated under collapse conditions, highlighting a clear trade-off between individual comfort and system-wide efficiency. Compromised discomfort costs show resilience for adversary agents below 20\%, remaining low even under high levels of adversarial behavior. However, collapse is observed for proportions exceeding 50\% and adversarial levels $\beta > 0.7$, where compromised discomfort costs rise smoothly. This trend suggests that legitimate agents in the Voting dataset show lower resilience compared to the Energy dataset.

\paragraph{Privacy Dataset}
The Privacy dataset reveals lower resilience thresholds compared to the Energy and Voting datasets, especially for high privacy-preserving signal. For $\beta < 0.2$ and adversary agents below 20\%, inefficiency costs remain low. However, vulnerability emerges as proportions increase to 50\%, and collapse occurs at $\beta \geq 0.3$ for high data-sharing levels and $\beta \geq 0.5$ for low data-sharing levels when adversary agents exceed 50\%.

Discomfort costs follow similar trends, with resilience observed below 30\% adversary agents for high privacy-preserving signal and 20\% for low privacy-preserving signal. Collapse occurs when $\beta > 0.3$ and proportions exceed 60\%. Compromised discomfort costs rise steadily, peaking at values of 9 and 10 for high and low privacy-preserving signal, respectively, at 90\% adversary agents. Unlike the Energy and Voting datasets, where $\beta$ strongly influences compromised discomfort costs, the Privacy dataset shows that scale of adversaries serves as the dominant driver of these costs beyond $\beta > 0.3$. This highlights the Privacy dataset heightened sensitivity to adversarial density, requiring more targeted interventions to preserve legitimate agent objectives.

\begin{figure*}[htbp]
  \centering
  \begin{subfigure}{0.98\textwidth} 
    \includegraphics[width=\textwidth]{Pareto_1.pdf}
    \centering
    \caption{Pareto front and knee points across adversarial severity.}
    \label{fig:pareto_level}
  \end{subfigure}

  \begin{subfigure}{0.98\textwidth}
    \includegraphics[width=\textwidth]{Pareto_2.pdf}
    \centering
    \caption{Pareto front and knee points across scales of adversaries.}
    \label{fig:pareto_adv}
  \end{subfigure}

\caption{The Pareto Optimality of The Energy Voting, and Privacy datasets}
\label{fig:pareto}
\end{figure*}


\begin{figure*}[htbp]
  \centering
  \begin{subfigure}{\textwidth}
    \centering
    \includegraphics[width=\textwidth]{Energy_layers.pdf}
    \caption{Energy dataset.}
    \label{layer_energy}
  \end{subfigure}

  \begin{subfigure}{\textwidth} 
    \centering
    \includegraphics[width=\textwidth]{score_layers.pdf}
    \caption{Voting dataset.}
    \label{layer_score}
  \end{subfigure}

  \begin{subfigure}{\textwidth} 
    \centering
    \includegraphics[width=\textwidth]{Privacy_high_layer.pdf}
    \caption{Privacy dataset (High privacy-preserving).}
    \label{layer_high}
  \end{subfigure}
  
  \begin{subfigure}{\textwidth} 
    \centering
    \includegraphics[width=\textwidth]{Privacy_low_layer.pdf}
    \caption{Privacy dataset (Low privacy-preserving).}
    \label{layer_low}
  \end{subfigure}

\caption{Inefficiency costs across hierarchical structure layers under various adversarial configurations.}
\label{fig:layers}
\end{figure*}

\subsection{Pareto Optimality Analysis}
Pareto optimality analysis identifies Pareto fronts knee points that represent optimal system performance under varying adversarial conditions. Figure \ref{fig:pareto} highlights system resilience to adversarial severity and proportions across the Energy, Voting, and Privacy datasets. Figure \ref{fig:pareto_level} focuses on the impact of adversarial severity ($\beta$) on tolerated scale of adversaries, while Figure \ref{fig:pareto_adv} explores how varying adversary densities affect tolerated behavior levels.

In the Energy dataset, Figure \ref{fig:pareto_level} shows resilience up to 90\% adversary agents for moderate behavior levels ($0.3 \leq \beta \leq 0.8$), declining to 50\% at higher levels of adversarial behavior. A similar trend is observed in Figure \ref{fig:pareto_adv}, where knee points vary between $\beta = 0.03$--$0.3$ for scale of adversaries up to 90\%, rise sharply to $\beta = 0.9$ at scale of adversaries less than 40\%, and drop sharply to $\beta < 0.1$ under full adversarial saturation, reflecting system vulnerability. 

The Voting dataset demonstrates robust stability. Figure \ref{fig:pareto_level} shows consistent knee points tolerating 50--60\% adversary agents across a broad range of behavior levels ($0.1 \leq \beta \leq 0.7$). Even under high adversarial severity ($0.86 \leq \beta \leq 0.9$), as illustrated in Figure \ref{fig:pareto_adv}, the system exhibits exceptional resilience, tolerating densities from 10\% to 100\%. This highlights the dataset high tolerance to adversarial influence.

The Privacy dataset exhibits slightly difference dynamics between high and low privacy-preserving signals. In Figure \ref{fig:pareto_level}, tolerated scale of adversaries for high signal configurations are approximately 70\% at $\beta < 0.5$, but drop to 50\% at higher intensities. The low signal Privacy scenario displays smoother declines, with tolerated densities averaging 68\% Adversary agents across behavior levels. Figure \ref{fig:pareto_adv} shows that high signal configurations begin at knee points of $\beta = 0.03$ for 10\% adversary agents, rising gradually to $\beta = 0.2$ at 50--90\%. Low privacy-preserving signal exhibits a smoother gradient, peaking at $\beta = 0.36$ at 20\% Adversary agents and declining to $\beta = 0.13$ at full adversarial saturation.

\subsection{Structure Analysis}
This section analyzes how hierarchical structures influence inefficiency costs in Energy, Voting, and Privacy datasets. This analysis is divided into two approaches: individual layer-wise and cumulative structure analysis.

\subsubsection{Layer-wise structural analysis}
Figure \ref{fig:layers} highlights inefficiency costs across hierarchical layers for varying scale of adversaries at 25\%, 50\%, 75\%, and 100\% and behavior levels ($\beta$) at 0.1, 0.4, 0.7, and 1.0. In all datasets, deeper layers and layers with higher agent proportions exhibit greater inefficiency escalation under intensified adversarial influence.

In the Energy dataset (Figure \ref{layer_energy}), with 1,000 agents distributed across 10 layers, inefficiency costs remain stable up to Layer 5 at moderate adversarial severity ($\beta=0.1$, 0.4, and 0.7). Beyond Layer 6, costs fluctuate and peak at Layers 7 and 8. Notably, while Layer 9 contains the highest number of agents (256), inefficiency only peaks at $\beta=1.0$ and 100\% Adversary agents, highlighting the compounded vulnerability of deeper layers under extreme adversarial influence. This emphasizes the increasing impact of both adversary density and adversarial severity on deeper layers.

The Voting dataset (Figure \ref{layer_score}), with 266 agents distributed across 9 layers, shows minimal inefficiency in the upper layers (1--5) across all adversarial configurations. However, inefficiency rises sharply beyond Layer 5, with Layer 7 consistently incurring the highest costs, especially at higher adversarial severity ($\beta \geq 0.7$) and scale of adversaries of 75\% and 100\%. At $\beta=1.0$, inefficiency increases steadily from the root (Layer 1) to the leaves (Layer 9), highlighting the compounding impact of adversarial behavior as it propagates deeper into the hierarchy.

The Privacy dataset (Figures \ref{layer_high} and \ref{layer_low}), with 72 agents distributed across 7 layers, exhibits almost similar trends for high and low privacy-preserving signal. At low adversarial behavior ($\beta=0.1$), inefficiency costs remain stable across all layers, demonstrating resilience to mild adversarial influence. At higher levels of adversarial behavior ($\beta \geq 0.7$), inefficiency peaks at Layer 6, which has the highest agent proportion (32 agents). Interestingly, Layer 7, with fewer agents, incurs lower costs even under severe adversarial conditions. Minor deviations, such as Layer 5 occasionally surpassing Layer 6 in the low signal scenario, highlight the nuanced relationship between layer depth, agent density, and adversarial behavior.

These results suggest that inefficiency costs in hierarchical systems are highly sensitive to layer depth, scale of adversaries, and the level of adversarial behavior. Deeper layers and those with higher agent proportion emerge as critical vulnerabilities under intensified adversarial configurations. Reinforcing deeper layers and redistributing agent densities could mitigate inefficiency spikes, especially in applications with high adversarial risks.

\begin{figure*}[htbp]
  \centering
  \begin{subfigure}{0.98\textwidth}
    \centering
      \includegraphics[width=\textwidth]{cumulative-TD.pdf}
      \caption{Top-down cumulative}
      \label{fig:TD cumulative}
      \end{subfigure}
      
    \begin{subfigure}{0.98\textwidth}
    \centering
      \includegraphics[width=\textwidth]{cumulative-BU.pdf}
      \caption{Bottom-up cumulative}
      \label{fig:BU cumulative}
      \end{subfigure}
    \caption{Inefficiency cost across hierarchical structure layers under various adversarial configurations in Energy, voting and Privacy datasets.}
\label{fig:cumulative}
\end{figure*}

\subsubsection{Cumulative structural analysis}
Another approach assesses the cumulative impact of adversary agents on inefficiency costs as they propagate through the hierarchical network structure in two configurations: top-down (root-to-leaf) and bottom-up (leaf-to-root). Figure \ref{fig:cumulative} presents inefficiency trends for scale of adversaries and adversarial severity (0.1, 0.4, 0.7, 1.0) across Energy, Voting, and Privacy datasets.

The cumulative structural analysis of the Energy dataset reveals distinct differences in inefficiency trends between top-down and bottom-up propagation. At $\beta=1$,
top-down propagation results in significantly higher initial inefficiency costs, reaching 272 with a single adversarial agent, compared to just 0.8 in bottom-up propagation. Inefficiency costs in the top-down configuration also rise more rapidly, indicating accelerated system deterioration. In contrast, bottom-up propagation exhibits a slower emergence of inefficiency, with costs remaining low up to 20\% adversarial agent participation, followed by exponential growth. These trends emphasize the critical impact of adversarial agent placement, as costs escalate faster and peak higher when adversaries are positioned in top layers. At lower adversarial severity (0.1, 0.4, 0.7), inefficiency costs remain low and stable, fluctuating between 0.1 and 0.5, even as number of adversaries increases. This highlights the system resilience to moderate adversarial behavior.


The Voting dataset shows distinct trends in inefficiency costs. At $\beta = 1$, inefficiency costs start at approximately 2.8, similar to lower $\beta$ levels, but rise sharply as the proportion of adversary agents increases, peaking at 6.0 when adversary agents saturate the network (100\%). In the top-down propagation, inefficiency costs accelerate rapidly within the top four layers, driven by early adversarial influence. This is followed by a clear decrease between Layers 5 and 6, corresponding to scale of adversaries ranging from 6\% to 17\%, indicating that inefficiencies stabilize as the system progresses deeper into the hierarchy. At lower adversarial severity ($\beta = 0.1, 0.4, 0.7$), inefficiency costs remain low and stable, fluctuating slightly between 2.8 and 2.9, regardless of scale of adversaries. Notably, at $\beta = 0.7$, inefficiency costs increase faster in the top-down propagation compared to the bottom-up propagation, underscoring the impact of adversary agents propagation direction on system performance under moderate adversarial behavior.

The Privacy dataset reveals resilience at low adversarial severity ($\beta = 0.1$), with minimal inefficiency increases (0.01\textendash 0.05) across all layers in both top-down and bottom-up propagations, even under full adversary participation. At higher adversarial levels ($\beta = 0.7, 0.4$ and $\beta = 1$), inefficiency costs rise significantly across layers. For high privacy-preserving signal, inefficiency emerges early with just one adversary agent in top-down propagation at Layer 1 with $\beta = 0.4, 0.7$, and $1$, while in bottom-up propagation, inefficiency begins with low value $< 62.8$. In both propagations Layer 2 shows heightened sensitivity, where even 2-3 adversary agents sharply increase inefficiency. Layer 6 experiences notable surges when the scale of adversaries exceeds 50\% for both propagation directions. In low privacy-preserving signals, inefficiency costs rise more prominently in top-down propagation, particularly at Layer 5, with sharp increases at $\beta = 0.4, 0.7$, and $1$ when scale of adversaries exceeds 25\%. In bottom-up propagation, inefficiency escalates at $\beta = 0.7$ and $1$ when scale of adversaries exceeds 70\%. These patterns emphasize structural vulnerabilities, with Layers 2, 5, and 6 emerging as critical points for inefficiency escalation under intensified adversarial influence.

\subsection{Discussion} 
The results of this study reveal critical insights into adversarial influence on multi-objective distributed optimization systems, uncovering opportunities for designing self-healing strategies that enhance system resilience. By examining the dynamics of resilience, vulnerability, and collapse across diverse datasets, the analysis offers valuable lessons for addressing challenges in adversarial environments.

The Energy and Voting datasets exhibit strong resilience, withstanding a broad range of adversarial configurations and transitioning smoothly from vulnerability to collapse under higher adversarial severity. In contrast, the Privacy dataset demonstrates heightened sensitivity to adversarial scales and severity, particularly under high privacy-preservation constraints. This results underscore the importance of tailoring optimization strategies, particularly for privacy-preserving systems.

Pareto analysis identifies critical resilience thresholds where systems can balance inefficiency and discomfort costs. The Energy dataset sustains resilience up to 90\% adversarial scale, collapsing only under extreme severity, while the Voting dataset maintains consistent performance across configurations, showcasing robustness. The Privacy dataset requires earlier interventions for high privacy-preserving configurations but allows for more gradual adjustments under low privacy-preserving scenarios. These findings reinforce the importance of identifying Pareto knee points to enable dynamic trade-off prioritization and effective system adaptation under real-time adversarial conditions.

Structural analysis reveals vulnerabilities in deeper hierarchical layers with higher number of agents, which are more prone to inefficiency propagation under intensified adversarial influence. Targeted strategies, such as reinforcing critical layers, redistributing agent densities, and employing localized containment mechanisms, can mitigate inefficiencies. Top-down configurations show rapid cascading of adversarial impact from top layers, demanding robust protections at higher levels, whereas bottom-up configurations exhibit slower propagation, suggesting inherent resilience.

Integrating adaptive fault-monitoring mechanisms is essential for maintaining system stability. Dynamically detecting transitions between resilience, vulnerability, and collapse allows for strategic resource allocation. For instance, energy systems can employ load-balancing strategies to address inefficiency, while hierarchical vulnerabilities in distributed optimization algorithms should be addressed through structural reinforcements and proactive monitoring.

This research provides a comprehensive framework for understanding adversarial impacts on distributed optimization systems and offers actionable insights for designing robust, self-healing mechanisms. By combining structural interventions, adaptive monitoring, and informed resource allocation, distributed systems can maintain efficiency and resilience even under significant adversarial configurations.

\section{Conclusion and Future work} \label{sec6}
This study provides a comprehensive analysis of resilience, vulnerability, and collapse dynamics in multi-agent distributed optimization systems under adversarial conditions. By systematically examining the impact of the scale of adversaries, adversarial severity, and hierarchical structure, it identifies critical thresholds where system performance transitions from resilience to collapse. These insights offer practical strategies to enhance system design and resilience against adversarial influences.

The results highlight critical thresholds where systems transition from resilience to collapse, emphasizing the interplay of structural vulnerabilities and adversarial factors. These findings provide a foundation for designing tailored resilience strategies across diverse operational contexts.

A significant contribution of this work is the introduction of a benchmark dataset and software artifact for I-EPOS collective learning. These resources enable researchers to further investigate adversarial dynamics and develop advanced self-healing strategies. Integrating real-time detection and mitigation mechanisms will be critical for dynamically restoring system performance and resilience in the presence of adversarial behaviors.

Future work will focus on embedding real-time adaptive mechanisms within practical systems to monitor and counteract adversarial influences dynamically. Exploring complex network topologies, diverse adversarial scenarios, and broader application domains will deepen understanding and support the development of robust, fault-tolerant distributed optimization systems capable of maintaining efficiency and stability under challenging conditions.


\section*{Acknowledgments}
This project is funded by a UKRI Future Leaders Fellowship (MR-/W009560-/1): `\emph{Digitally Assisted Collective Governance of Smart City Commons--ARTIO}'.
The authors would like to thank Thomas Wellings and Chuhao Qin for their feedback on the paper, Abhinav Sharma for technical support in experimentation and Srijoni Majumdar for support with the voting dataset.

\bibliographystyle{IEEEtran}
\bibliography{references}

\end{document}

