\section{Conclusion}
\label{sec:conclusion}
In this study, we examined how social and linguistic attributes—gender, CEFR proficiency, academic field, and language environment—affect AI text detection in realistic, out-of-domain settings. Our analyses revealed that all tested detectors are highly sensitive to CEFR level and language environment, while biases tied to gender and academic field manifest more inconsistently across models. These findings highlight the pivotal role of author diversity in shaping detection performance and underscore the need for socially aware benchmarks, debiasing strategies, and more inclusive training data. By recognizing the nuanced ways in which “who is writing” influences text characteristics, future research can foster more equitable and reliable AI detection systems that effectively serve diverse linguistic and cultural communities.
