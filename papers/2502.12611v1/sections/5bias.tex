\section{Bias Analysis}
\label{sec:bias}

This section illustrates our approach for identifying and quantifying \emph{bias} in AI text detection with respect to different author attributes (e.g., gender, CEFR level, academic field, and language environment). Our primary goal is to examine whether certain subgroups experience systematically higher or lower detection accuracy, even after controlling for other factors. Below, we introduce the core principles, define bias mathematically, and discuss why our \emph{multi-factor} method is both appropriate and advantageous over simpler alternatives. Detailed algorithmic steps appear in Appendix~\ref{sec:appendix-tests}.

\subsection{Task Definition}
\paragraph{Input-Output Principle.} Our pipeline takes as \emph{input} texts labeled as \emph{human-authored} or \emph{LLM-generated} (aggregating outputs from all LLMs). Each text includes metadata describing the author's (or LLM emulated author's) demographic and linguistic attributes. Each detector provides a binary classification (human or AI). We then group all texts (human and LLM-generated) by these attributes (e.g., CEFR level) to compute and compare detection accuracy across subgroups.




\paragraph{Definition of Bias.} 
We define bias in terms of statistically significant differences in detection accuracy across subgroups. Let \(A\) represent a categorical author attribute (e.g., CEFR level) with values \(\{\mathcal{A}_1, \ldots, \mathcal{A}_k\}\), and let \(\mathrm{Accuracy}(A=a)\) be the detection accuracy for texts where \(A=a\). A detector is considered \emph{biased} with respect to \(A\) if our multi-factor analysis reveals a significant difference in accuracy between any two attribute values \(a_i\) and \(a_j\).

We quantify this bias using a two-stage process:
1) ANOVA \(p\)-values: We first use Type II ANOVA to determine whether attribute \(A\) has a statistically significant overall effect on detection accuracy, while controlling for other attributes. A \(p\)-value below 0.05 indicates that the attribute significantly impacts detector performance.

2) Post-hoc Comparisons using LSMeans: If (and only if) the ANOVA \(p\)-value for attribute \(A\) is significant, we proceed to post-hoc pairwise comparisons.  These comparisons use Least-Squares Means (LSMeans), which are adjusted means for each level of \(A\), holding other factors constant.  We employ pairwise Wald tests with Holm correction on the LSMeans to reveal the magnitude and direction of significant differences between specific subgroups.  This pinpoints which subgroups are disproportionately affected by the detector.





\subsection{Multi-Factor Weighted Least Squares and ANOVA.}
We employ a \textbf{multi-factor regression} framework to isolate each attribute’s effect on detection accuracy, using ordinary least squares (OLS) adapted to unbalanced data through \textbf{weighted least squares (WLS)}. We then perform \textbf{Type~II ANOVA} to determine each factor’s unique contribution once other attributes are held constant \citep{scheffe_analysis_1999}. This approach is well-suited for the uneven subgroup sizes common in sociolinguistic and fairness research \citep{hardt2016equalityopportunitysupervisedlearning}, as WLS estimates how accuracy varies with each factor while Type~II ANOVA tests whether including a particular attribute (e.g., \textit{language environment}) significantly reduces unexplained variance. By including all attributes jointly, we disentangle their individual effects and correct for subgroup size imbalances.

In contrast to single-factor tests—which examine each attribute in isolation—our multi-factor WLS+ANOVA approach accounts for overlapping or correlated attributes. For instance, CEFR level and language environment may be intertwined if certain regions tend to have higher proficiency, and ignoring these dependencies risks spurious conclusions or masking real biases \citep{angwin2016machine}. Although \emph{rule-based} or \emph{single-factor} methods can provide initial insights (e.g., focusing on one attribute at a time), they cannot robustly address the interactions among multiple variables \citep{solon2017fairness}. Our multi-factor framework systematically partitions the variance in detection accuracy explained by each attribute, giving a more reliable measure of bias and enabling fairer AI text detection systems.

\paragraph{High-Level Implementation.}
Algorithm~\ref{alg:wls-anova-main} summarizes our multi-factor WLS and Type II ANOVA procedure.  Broadly, we (1) aggregate accuracy and assign weights for each unique combination of attribute values; (2) fit a WLS model, treating each attribute as a factor; and (3) apply Type II ANOVA by iteratively removing each attribute to assess its unique contribution to the model.



\begin{algorithm}[!h]
\caption{Multi-Factor WLS + Type II ANOVA}
\label{alg:wls-anova-main}
\renewcommand{\algorithmicrequire}{\textbf{Input:}}
\renewcommand{\algorithmicensure}{\textbf{Output:}}
\begin{algorithmic}[1]
    \REQUIRE Dataset of \(n\) texts, each with a binary classification \(y_i\) (0: human, 1: AI) and a set of attribute values (e.g., CEFR=B1, Sex=F, ...).
    \ENSURE ANOVA table (F-statistics, \(p\)-values) and LSMeans.

    \STATE \textbf{Data Preparation:}
        \STATE \quad Group texts by unique combinations of attribute values.
        \STATE \quad Calculate the mean accuracy \(a_j\) and weight \(w_j\) (text count) for each group \(j\).
        \STATE \quad Treat each attribute as a factor.

    \STATE \textbf{Fit WLS Model:} Estimate parameters \(\boldsymbol{\beta}\) using weighted least squares, weighting each group's contribution by \(w_j\).

    \STATE \textbf{Perform Type II ANOVA:} For each attribute:
        \begin{itemize}[leftmargin=1.5em]
        \item Construct a reduced model by removing the attribute.
        \item Refit the WLS model to the reduced model, obtaining \(\text{RSS}_{\text{reduced}}\).
        \item Compute the \(F\)-statistic and \(p\)-value by comparing \(\text{RSS}_{\text{reduced}}\) to the full model's \(\text{RSS}_{\text{full}}\).
        \end{itemize}

    \STATE \textbf{Calculate LSMeans:} Compute LSMeans for each attribute level using the full WLS model.

    \STATE \RETURN ANOVA table and LSMeans.
\end{algorithmic}
\end{algorithm}




\paragraph{Outputs and Usage.}
The WLS and ANOVA procedure yields (i) ANOVA tables with each attribute's \(F\)-statistic, \(p\)-value, and significance, and (ii) LSMeans, providing model-adjusted accuracy for each attribute combination. By accounting for correlated attributes and weighting groups by size, we detect and interpret biases without discarding data or ignoring interactions. Appendix~\ref{appendix:hyp_testing_wls} provides full implementation details, including pseudocode (Algorithm~\ref{alg:wls-anova}) and our Python \texttt{statsmodels} setup.




\paragraph{References to Additional Analyses.}
% \label{sec:additional-analyses}
While our \emph{primary} approach is the \textbf{multi-factor} WLS, we also conduct complementary tests for confirmation or exploratory checks. First, we perform \textbf{single-factor analyses}, such as Welch’s \emph{t}-test or one-way (weighted) ANOVA, when focusing on a single categorical attribute in isolation. Second, we explore \textbf{data subsetting}, in which we match certain attributes or filter the data to reduce confounding (often shrinking the sample size). Finally, we implement \textbf{down-sampling} to balance group sizes, potentially discarding data from larger subgroups (see Appendix~\ref{sec:appendix-tests}). Although these approaches can yield valuable insights, they are \emph{less comprehensive} in controlling for multiple attributes simultaneously, reinforcing the importance of multi-factor methodologies as the central tool in our bias assessment. 

% 



\subsection{Hypothesis Testing Results}
\label{sec:hyp_test_results}

To quantify how each demographic or contextual factor influences detector performance, we conduct a two-stage bias analysis. First, we use multi-factor Weighted Least Squares (WLS) regression and Type II ANOVA to determine which author attributes (factors) significantly influence detector accuracy. Second, for those attributes found to be significant in the ANOVA, we conduct post-hoc pairwise comparisons using Least-Squares Means (LSMeans) to identify which specific levels of the attribute exhibit significant differences in accuracy. 



\paragraph{ANOVA Results.} Table~\ref{tab:bias_table_neat} presents the ANOVA results, with \(p\)-values for each factor (CEFR, Sex, Academic Genre, Language Environment) and detector. A \(p\)-value below 0.05 signifies a statistically significant effect of the factor on accuracy, controlling for other factors.  \textbf{CEFR proficiency level} (\texttt{cefr}) is highly significant for all detectors, indicating a strong, consistent bias related to language proficiency.  \textbf{Language environment} (\texttt{language\_env}) is significant for most detectors, suggesting the context of English learning (EFL, ESL, or NS) matters. \textbf{Sex} (\texttt{Sex}) shows no significant effect, implying no evidence of gender-based bias. \textbf{Academic genre} (\texttt{academic\_genre}) exhibits detector-dependent effects, with about half the detectors showing significant differences across fields.







\begin{table}[ht]
    \centering
    \small
    \begin{tabular}{>{\raggedright\arraybackslash}m{1.7cm}
    >{\raggedright\arraybackslash}m{0.7cm}
    >{\raggedright\arraybackslash}m{0.7cm}
    >{\raggedright\arraybackslash}m{1.2cm}
    >{\raggedright\arraybackslash}m{1.2cm}}
        \toprule
        \textbf{Detector} & 
        \textbf{CEFR} & 
        \textbf{Sex} & 
        \textbf{Academic Genre} & 
        \textbf{Language Env.} \\
        \midrule
        \rowcolors{2}{gray!10}{white}
        binoculars      & \cellcolor{green!20}\textbf{Yes}  &  No  &  No  & \cellcolor{green!20}\textbf{Yes} \\
        chatgpt-roberta & \cellcolor{green!20}\textbf{Yes}  &  No  &  No  &  No  \\
        detectgpt       & \cellcolor{green!20}\textbf{Yes}  &  No  & \cellcolor{green!20}\textbf{Yes}  & \cellcolor{green!20}\textbf{Yes} \\
        fastdetectgpt   & \cellcolor{green!20}\textbf{Yes}  &  No  &  No  & \cellcolor{green!20}\textbf{Yes} \\
        fastdetectllm   & \cellcolor{green!20}\textbf{Yes}  &  No  & \cellcolor{green!20}\textbf{Yes}  & \cellcolor{green!20}\textbf{Yes}  \\
        gltr            & \cellcolor{green!20}\textbf{Yes}  &  No  &  No  & \cellcolor{green!20}\textbf{Yes} \\
        gpt2-base       & \cellcolor{green!20}\textbf{Yes}  &  No  & \cellcolor{green!20}\textbf{Yes}  & \cellcolor{green!20}\textbf{Yes} \\
        gpt2-large      & \cellcolor{green!20}\textbf{Yes}  &  No  & \cellcolor{green!20}\textbf{Yes}  & \cellcolor{green!20}\textbf{Yes} \\
        llmdet          & \cellcolor{green!20}\textbf{Yes}  &  No  & \cellcolor{green!20}\textbf{Yes}  & \cellcolor{green!20}\textbf{Yes} \\
        radar           & \cellcolor{green!20}\textbf{Yes}  &  No  &  No  & \cellcolor{green!20}\textbf{Yes} \\
        \bottomrule
    \end{tabular}
    \caption{ANOVA $p$-values for each factor across detectors.  Columns show significance (Sig.?). ``Yes'' indicates $p<0.05$ (significant), ``No'' otherwise. Green-shaded cells indicate significant results (p < 0.05).}
    \label{tab:bias_table_neat}
\end{table}







\paragraph{Post-Hoc Comparisons and LSMeans.} 


\begin{table*}[h!]
\centering
\resizebox{\textwidth}{!}{
\begin{tabular}{llcccccccccc}
\toprule
\textbf{Factor} & \textbf{Level} & \textbf{binoc.} & \textbf{chatgpt-r} & \textbf{detectgpt} & \textbf{fdgpt} & \textbf{fdllm} & \textbf{gltr} & \textbf{gpt2-base} & \textbf{gpt2-large} & \textbf{llmdet} & \textbf{radar} \\
\midrule
\multirow{5}{*}{CEFR} & A2\_0 & 0.9482 & 0.7480 & 0.7944 & 0.8963 & 0.4873 & 0.8366 & 0.6493 & 0.5402 & 0.5063 & 0.6886 \\
 & B1\_1 & 0.9443 & 0.7408 & 0.8072 & 0.8887 & 0.4842 & 0.8305 & 0.6399 & 0.5676 & 0.4961 & 0.7267 \\
 & B1\_2 & 0.9475 & 0.7377 & 0.8228 & 0.9023 & 0.4786 & 0.8206 & 0.5881 & 0.5410 & 0.4812 & 0.7210 \\
 & B2\_0 & 0.9507 & 0.7045 & 0.8289 & 0.9143 & 0.4828 & 0.7967 & 0.5623 & 0.5462 & 0.4581 & 0.7020 \\
 & XX\_0 & 0.8981 & 0.7410 & 0.7722 & 0.8748 & 0.4975 & 0.7180 & 0.5482 & 0.5162 & 0.5037 & 0.6686 \\
\midrule
\multirow{3}{*}{LangEnv} & EFL & 0.9482 & -- & 0.7944 & 0.8963 & 0.4873 & 0.8366 & 0.6493 & 0.5402 & 0.5063 & 0.6886 \\
 & ESL & 0.9337 & -- & 0.7867 & 0.8941 & 0.4837 & 0.8346 & 0.6504 & 0.5521 & 0.5250 & 0.6671 \\
 & NS & 0.8981 & -- & 0.7722 & 0.8748 & 0.4975 & 0.7180 & 0.5482 & 0.5162 & 0.5037 & 0.6686 \\
\midrule
\multirow{4}{*}{AcadGenre} & Humanities & -- & -- & 0.7944 & -- & 0.4873 & -- & 0.6493 & 0.5402 & 0.5063 & -- \\
 & Social Sciences & -- & -- & 0.7884 & -- & 0.4856 & -- & 0.6409 & 0.5238 & 0.5097 & -- \\
 & Sciences \& Tech & -- & -- & 0.7759 & -- & 0.4813 & -- & 0.6866 & 0.5705 & 0.5109 & -- \\
 & Life Sciences & -- & -- & 0.7547 & -- & 0.4732 & -- & 0.6741 & 0.5484 & 0.5265 & -- \\
\bottomrule
\end{tabular}
}
\caption{LSMeans for CEFR Level, Language Environment (EFL, ESL, NS), and Academic Genre (Humanities, Social Sciences, Sciences \& Technology, Life Sciences), across detectors. A ``--'' indicates that the overall ANOVA for that factor and detector was not statistically significant (see Table~\ref{tab:bias_table_neat}), so LSMeans are not reported.}
\label{tab:lsmeans_combined}
\end{table*}








\begin{table}[ht!]
\centering
\small
\begin{tabular}{llll}
\toprule
\textbf{Factor} & \textbf{Detector} & \textbf{Comparison} & \textbf{Sig.?} \\
\midrule
\multirow{9}{*}{CEFR} & \multirow{4}{*}{binoc.}
 & B2\_0 vs XX\_0 & Yes \\
 &  & A2\_0 vs XX\_0 & Yes \\
 &  & B1\_2 vs XX\_0 & Yes \\
 &  & B1\_1 vs XX\_0 & Yes \\
\cmidrule(lr){2-4}
 & \multirow{2}{*}{chatgpt-r}
 & A2\_0 vs B2\_0 & Yes \\
 &  & B1\_1 vs B2\_0 & Yes \\
\cmidrule(lr){2-4}
 & \multirow{2}{*}{detectgpt}
 & B2\_0 vs A2\_0 & Yes \\
 &  & B2\_0 vs XX\_0 & Yes \\
\midrule
\multirow{4}{*}{Lang. Env.} & \multirow{3}{*}{binoc.}
 & EFL vs ESL & Yes \\
 &  & EFL vs NS  & Yes \\
 &  & ESL vs NS  & Yes \\
\cmidrule(lr){2-4}
 & detectgpt
 & EFL vs NS & Yes \\
\midrule
\multirow{10}{*}{Acad. Genre} & \multirow{3}{*}{detectgpt}
 & Hum. vs S.\&T. & Yes \\
 &  & Hum. vs Life S.  & Yes \\
 &  & Soc. S. vs Life S.  & Yes \\
\cmidrule(lr){2-4}
 & \multirow{2}{*}{gpt2-base}
 & S.\&T. vs Hum. & Yes \\
 &  & S.\&T. vs Soc. S. & Yes \\
\cmidrule(lr){2-4}
 & \multirow{2}{*}{gpt2-large}
 & S.\&T. vs Hum. & Yes \\
 &  & S.\&T. vs Soc. S. & Yes \\
\cmidrule(lr){2-4}
 & \multirow{3}{*}{llmdet}
 & Life S. vs S.\&T. & Yes \\
 &  & Life S. vs Soc. S. & Yes \\
 &  & Life S. vs Hum. & Yes \\
\bottomrule
\end{tabular}
\caption{Post-hoc pairwise comparisons (Wald test, Holm correction) for CEFR Level, Language Environment, and Academic Genre. Only showing significant pairs for detectors where the overall ANOVA for the respective factor was significant (see Table~\ref{tab:bias_table_neat}).}
\label{tab:posthoc_combined}
\end{table}





For factors with significant overall effects in the ANOVA (Table~\ref{tab:bias_table_neat}), we conduct post-hoc pairwise comparisons using the Wald test with Holm correction. These tests, performed on the LSMeans, identify which specific levels of a factor differ significantly in detection accuracy. The LSMeans (Table~\ref{tab:lsmeans_combined}) represent the model-adjusted mean accuracy for each subgroup, controlling for all other factors. In other words, they estimate the average detection accuracy for a particular subgroup (e.g., CEFR level B1), assuming all other attributes (Sex, Academic Genre, Language Environment) are held constant at their average values across the dataset. This allows us to isolate the effect of the factor of interest. A "--" in Table~\ref{tab:lsmeans_combined} indicates a non-significant ANOVA result for that factor and detector, precluding meaningful post-hoc tests. Table~\ref{tab:posthoc_combined} presents the significant comparisons. To interpret the direction of significant differences (i.e., which subgroup has higher accuracy), the LSMeans values in Table~\ref{tab:lsmeans_combined} must be compared. Table~\ref{tab:posthoc_combined} reveals the following key patterns:

\textbf{CEFR Level:} `binoculars` shows the most extensive bias; all non-native CEFR levels differ significantly from native speakers (XX\_0), with higher accuracy for non-native levels (see Table~\ref{tab:lsmeans_combined}). `chatgpt-roberta` distinguishes A2 from B2, and B1.1 from B2. `detectgpt` distinguishes B2 from both A2 and XX\_0.

\textbf{Language Environment:}  For `binoculars`, all pairwise comparisons (EFL vs. ESL, EFL vs. NS, ESL vs. NS) are significant, with EFL and ESL generally showing higher accuracy than NS (see Table~\ref{tab:lsmeans_combined}). `detectgpt` shows a significant difference only between EFL and NS.

\textbf{Academic Genre:} Significant differences are found for `detectgpt`, `gpt2-base`, `gpt2-large`, and `llmdet`, but specific differing pairs vary by detector. For instance, `detectgpt` distinguishes Humanities from both Science \& Technology and Life Sciences, and Social Sciences from Life Sciences.









