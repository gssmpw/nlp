
\section{Detailed Subset Results}

\begin{table*}[ht!]
\centering
\resizebox{\textwidth}{!}{%
\begin{tabular}{lcccccccccc}
\toprule
\textbf{Generator Model} 
& \textbf{binoculars} 
& \textbf{fastdetectgpt} 
& \textbf{detectgpt} 
& \textbf{gltr} 
& \textbf{chatgpt-roberta} 
& \textbf{radar} 
& \textbf{gpt2-base} 
& \textbf{gpt2-large} 
& \textbf{llmdet} 
& \textbf{fastdetectllm} \\
\midrule
\textbf{Qwen2.5-72B-Instruct} & 0.959 & 0.967 & 0.897 & 0.939 & 0.808 & 0.822 & 0.653 & 0.531 & 0.496 & 0.479 \\
\textbf{Qwen2.5-32B-Instruct} & 0.958 & 0.906 & 0.789 & 0.789 & 0.789 & 0.691 & 0.518 & 0.483 & 0.487 & 0.479 \\
\textbf{Qwen2.5-14B-Instruct} & 0.958 & 0.896 & 0.751 & 0.836 & 0.874 & 0.802 & 0.579 & 0.496 & 0.493 & 0.479 \\
\textbf{Qwen2.5-7B-Instruct} & 0.958 & 0.964 & 0.840 & 0.884 & 0.822 & 0.700 & 0.525 & 0.485 & 0.487 & 0.479 \\
\textbf{Qwen2.5-3B-Instruct} & 0.946 & 0.735 & 0.693 & 0.603 & 0.774 & 0.562 & 0.506 & 0.485 & 0.497 & 0.479 \\
\textbf{Qwen2.5-1.5B-Instruct} & 0.925 & 0.876 & 0.786 & 0.661 & 0.733 & 0.647 & 0.571 & 0.534 & 0.500 & 0.480 \\
\textbf{Qwen2.5-0.5B-Instruct} & 0.825 & 0.873 & 0.762 & 0.621 & 0.651 & 0.622 & 0.654 & 0.779 & 0.499 & 0.480 \\
\textbf{llama3.1-70b-instruct} & 0.930 & 0.905 & 0.802 & 0.871 & 0.759 & 0.721 & 0.637 & 0.540 & 0.531 & 0.483 \\
\textbf{llama3.1-8b-instruct} & 0.955 & 0.957 & 0.832 & 0.902 & 0.690 & 0.725 & 0.672 & 0.572 & 0.505 & 0.479 \\
\textbf{llama3.2-3b-instruct} & 0.924 & 0.907 & 0.776 & 0.831 & 0.649 & 0.728 & 0.635 & 0.559 & 0.519 & 0.483 \\
\textbf{llama3.2-1b-instruct} & 0.824 & 0.795 & 0.715 & 0.687 & 0.706 & 0.631 & 0.671 & 0.668 & 0.512 & 0.527 \\
\textbf{Mistral-Small-Instruct-2409} & 0.959 & 0.947 & 0.767 & 0.773 & 0.685 & 0.630 & 0.524 & 0.481 & 0.497 & 0.479 \\
\textbf{Average} & 0.927 & 0.894 & 0.784 & 0.783 & 0.745 & 0.690 & 0.595 & 0.551 & 0.502 & 0.484 \\
\bottomrule
\end{tabular}%
}
\caption{Overall Detector performance across various generator models without subsetting}
\label{tab:all}
\end{table*}


\begin{table*}[ht!]
\centering
\resizebox{\textwidth}{!}{%
\begin{tabular}{lcccccccccc}
\toprule
\textbf{Generator Model} 
& \textbf{binoculars}
& \textbf{fastdetectgpt}
& \textbf{detectgpt}
& \textbf{gltr}
& \textbf{chatgpt-roberta}
& \textbf{radar}
& \textbf{gpt2-base}
& \textbf{gpt2-large}
& \textbf{llmdet}
& \textbf{fastdetectllm} \\
\midrule
\textbf{Qwen2.5-72B-Instruct} & 0.990 & 0.965 & 0.990 & 0.892 & 0.866 & 0.834 & 0.814 & 0.588 & 0.511 & 0.488 \\
\textbf{Qwen2.5-32B-Instruct} & 0.990 & 0.915 & 0.930 & 0.801 & 0.858 & 0.759 & 0.620 & 0.480 & 0.497 & 0.488 \\
\textbf{Qwen2.5-14B-Instruct} & 0.989 & 0.918 & 0.933 & 0.781 & 0.940 & 0.814 & 0.691 & 0.504 & 0.499 & 0.488 \\
\textbf{Qwen2.5-7B-Instruct} & 0.990 & 0.965 & 0.945 & 0.857 & 0.837 & 0.757 & 0.551 & 0.470 & 0.494 & 0.488 \\
\textbf{Qwen2.5-3B-Instruct} & 0.976 & 0.759 & 0.732 & 0.720 & 0.777 & 0.609 & 0.568 & 0.486 & 0.521 & 0.488 \\
\textbf{Qwen2.5-1.5B-Instruct} & 0.959 & 0.894 & 0.750 & 0.836 & 0.794 & 0.677 & 0.594 & 0.524 & 0.511 & 0.489 \\
\textbf{Qwen2.5-0.5B-Instruct} & 0.870 & 0.878 & 0.683 & 0.802 & 0.671 & 0.626 & 0.673 & 0.772 & 0.513 & 0.489 \\
\textbf{llama3.1-70B-instruct} & 0.944 & 0.856 & 0.860 & 0.743 & 0.651 & 0.610 & 0.674 & 0.552 & 0.5757 & 0.491 \\
\textbf{llama3.1-8B-instruct} & 0.985 & 0.955 & 0.954 & 0.836 & 0.674 & 0.716 & 0.784 & 0.665 & 0.526 & 0.489 \\
\textbf{llama3.2-3B-instruct} & 0.944 & 0.889 & 0.870 & 0.753 & 0.644 & 0.692 & 0.679 & 0.572 & 0.583 & 0.492 \\
\textbf{llama3.2-1B-instruct} & 0.839 & 0.765 & 0.720 & 0.707 & 0.692 & 0.660 & 0.702 & 0.696 & 0.532 & 0.543 \\
\textbf{Mistral-Small-Instruct-2409} & 0.990 & 0.935 & 0.780 & 0.739 & 0.682 & 0.577 & 0.621 & 0.471 & 0.519 & 0.488 \\
\textbf{Average} & 0.956 & 0.891 & 0.845 & 0.789 & 0.757 & 0.694 & 0.664 & 0.565 & 0.520 & 0.493 \\
\bottomrule
\end{tabular}%
}
\caption{Detector performance across various generator models under subgroup CEFR = A2-0}
\label{tab:cefr_A2-0}
\end{table*}


\begin{table*}[ht!]
\centering
\resizebox{\textwidth}{!}{%
\begin{tabular}{lcccccccccccc}
\toprule
\textbf{Generator Model} 
& \textbf{binoculars} 
& \textbf{fastdetectgpt} 
& \textbf{gltr} 
& \textbf{detectgpt} 
& \textbf{chatgpt-roberta} 
& \textbf{radar} 
& \textbf{gpt2-base} 
& \textbf{gpt2-large} 
& \textbf{llmdet} 
& \textbf{fastdetectllm} \\
\midrule
\textbf{Qwen2.5-72B-Instruct} & 0.981 & 0.976 & 0.987 & 0.932 & 0.843 & 0.909 & 0.774 & 0.572 & 0.502 & 0.475 \\
\textbf{Qwen2.5-32B-Instruct} & 0.981 & 0.942 & 0.891 & 0.817 & 0.818 & 0.789 & 0.558 & 0.488 & 0.483 & 0.475 \\
\textbf{Qwen2.5-14B-Instruct} & 0.981 & 0.908 & 0.925 & 0.786 & 0.926 & 0.849 & 0.658 & 0.514 & 0.503 & 0.475 \\
\textbf{Qwen2.5-7B-Instruct} & 0.981 & 0.973 & 0.956 & 0.867 & 0.856 & 0.805 & 0.605 & 0.500 & 0.485 & 0.475 \\
\textbf{Qwen2.5-3B-Instruct} & 0.952 & 0.701 & 0.679 & 0.719 & 0.797 & 0.583 & 0.551 & 0.492 & 0.507 & 0.475 \\
\textbf{Qwen2.5-1.5B-Instruct} & 0.952 & 0.879 & 0.737 & 0.803 & 0.782 & 0.682 & 0.619 & 0.558 & 0.505 & 0.476 \\
\textbf{Qwen2.5-0.5B-Instruct} & 0.850 & 0.888 & 0.670 & 0.811 & 0.670 & 0.643 & 0.674 & 0.788 & 0.493 & 0.475 \\
\textbf{llama3.1-70b-Instruct} & 0.922 & 0.862 & 0.872 & 0.751 & 0.682 & 0.668 & 0.692 & 0.585 & 0.560 & 0.482 \\
\textbf{llama3.1-8b-Instruct} & 0.974 & 0.961 & 0.951 & 0.827 & 0.665 & 0.734 & 0.781 & 0.639 & 0.523 & 0.475 \\
\textbf{llama3.2-3b-Instruct} & 0.916 & 0.868 & 0.809 & 0.713 & 0.589 & 0.687 & 0.684 & 0.595 & 0.542 & 0.483 \\
\textbf{llama3.2-1b-Instruct} & 0.832 & 0.781 & 0.710 & 0.722 & 0.682 & 0.661 & 0.692 & 0.697 & 0.524 & 0.513 \\
\textbf{Mistral-Small-Instruct-2409} & 0.981 & 0.957 & 0.851 & 0.825 & 0.704 & 0.678 & 0.567 & 0.484 & 0.505 & 0.475 \\
\textbf{Average} & 0.942 & 0.891 & 0.837 & 0.798 & 0.751 & 0.724 & 0.655 & 0.576 & 0.511 & 0.479 \\
\bottomrule
\end{tabular}%
}
\caption{Detector performance across various generator models under subgroup CEFR = B1-1}
\label{tab:cefr_B1-1}
\end{table*}


\begin{table*}[ht!]
\centering
\resizebox{\textwidth}{!}{%
\begin{tabular}{lcccccccccccc}
\toprule
\textbf{Generator Model} 
& \textbf{binoculars} 
& \textbf{fastdetectgpt} 
& \textbf{gltr} 
& \textbf{detectgpt} 
& \textbf{chatgpt-roberta} 
& \textbf{radar} 
& \textbf{gpt2-base} 
& \textbf{gpt2-large} 
& \textbf{llmdet} 
& \textbf{fastdetectllm} \\
\midrule
\textbf{Qwen2.5-72B-Instruct} & 0.974 & 0.981 & 0.982 & 0.913 & 0.812 & 0.870 & 0.658 & 0.521 & 0.496 & 0.466 \\
\textbf{Qwen2.5-32B-Instruct} & 0.974 & 0.929 & 0.843 & 0.811 & 0.800 & 0.669 & 0.514 & 0.488 & 0.484 & 0.466 \\
\textbf{Qwen2.5-14B-Instruct} & 0.974 & 0.895 & 0.857 & 0.763 & 0.895 & 0.801 & 0.574 & 0.497 & 0.496 & 0.466 \\
\textbf{Qwen2.5-7B-Instruct} & 0.974 & 0.979 & 0.921 & 0.854 & 0.827 & 0.729 & 0.526 & 0.491 & 0.488 & 0.466 \\
\textbf{Qwen2.5-3B-Instruct} & 0.967 & 0.725 & 0.604 & 0.711 & 0.770 & 0.547 & 0.506 & 0.488 & 0.485 & 0.466 \\
\textbf{Qwen2.5-1.5B-Instruct} & 0.943 & 0.886 & 0.690 & 0.787 & 0.717 & 0.643 & 0.574 & 0.526 & 0.495 & 0.466 \\
\textbf{Qwen2.5-0.5B-Instruct} & 0.838 & 0.889 & 0.649 & 0.774 & 0.647 & 0.624 & 0.652 & 0.772 & 0.493 & 0.468 \\
\textbf{Llama3.1-70b-Instruct} & 0.949 & 0.923 & 0.919 & 0.838 & 0.795 & 0.750 & 0.663 & 0.548 & 0.534 & 0.471 \\
\textbf{Llama3.1-8b-Instruct} & 0.971 & 0.972 & 0.954 & 0.852 & 0.697 & 0.761 & 0.679 & 0.563 & 0.506 & 0.466 \\
\textbf{Llama3.2-3b-Instruct} & 0.936 & 0.905 & 0.850 & 0.778 & 0.657 & 0.745 & 0.662 & 0.572 & 0.519 & 0.473 \\
\textbf{Llama3.2-1b-Instruct} & 0.852 & 0.822 & 0.715 & 0.743 & 0.724 & 0.623 & 0.678 & 0.671 & 0.509 & 0.516 \\
\textbf{Mistral-Small-Instruct-2409} & 0.974 & 0.964 & 0.841 & 0.788 & 0.685 & 0.657 & 0.523 & 0.488 & 0.492 & 0.466 \\
\textbf{Average} & 0.944 & 0.906 & 0.819 & 0.801 & 0.752 & 0.702 & 0.601 & 0.552 & 0.500 & 0.471 \\
\bottomrule
\end{tabular}%
}
\caption{Detector performance across various generator models under subgroup CEFR = B1-2}
\label{tab:cefr_B1-2}
\end{table*}


\begin{table*}[ht!]
\centering
\resizebox{\textwidth}{!}{%
\begin{tabular}{lcccccccccccc}
\toprule
\textbf{Generator Model} 
& \textbf{binoculars} 
& \textbf{fastdetectgpt} 
& \textbf{gltr} 
& \textbf{detectgpt} 
& \textbf{chatgpt-roberta} 
& \textbf{radar} 
& \textbf{gpt2-base} 
& \textbf{gpt2-large} 
& \textbf{llmdet} 
& \textbf{fastdetectllm} \\
\midrule
\textbf{Qwen2.5-72B-Instruct} & 0.961 & 0.980 & 0.950 & 0.902 & 0.705 & 0.781 & 0.538 & 0.507 & 0.467 & 0.474 \\
\textbf{Qwen2.5-32B-Instruct} & 0.960 & 0.899 & 0.716 & 0.794 & 0.693 & 0.632 & 0.490 & 0.500 & 0.467 & 0.474 \\
\textbf{Qwen2.5-14B-Instruct} & 0.961 & 0.900 & 0.807 & 0.744 & 0.818 & 0.794 & 0.531 & 0.500 & 0.468 & 0.474 \\
\textbf{Qwen2.5-7B-Instruct} & 0.961 & 0.970 & 0.873 & 0.816 & 0.780 & 0.635 & 0.513 & 0.501 & 0.470 & 0.474 \\
\textbf{Qwen2.5-3B-Instruct} & 0.956 & 0.800 & 0.590 & 0.667 & 0.753 & 0.548 & 0.496 & 0.500 & 0.468 & 0.474 \\
\textbf{Qwen2.5-1.5B-Instruct} & 0.936 & 0.897 & 0.653 & 0.775 & 0.684 & 0.629 & 0.559 & 0.544 & 0.476 & 0.474 \\
\textbf{Qwen2.5-0.5B-Instruct} & 0.854 & 0.889 & 0.647 & 0.752 & 0.642 & 0.623 & 0.682 & 0.806 & 0.481 & 0.474 \\
\textbf{Llama3.1-70b-Instruct} & 0.958 & 0.966 & 0.925 & 0.868 & 0.795 & 0.777 & 0.606 & 0.525 & 0.481 & 0.476 \\
\textbf{Llama3.1-8b-Instruct} & 0.960 & 0.971 & 0.903 & 0.860 & 0.697 & 0.743 & 0.607 & 0.523 & 0.469 & 0.474 \\
\textbf{Llama3.2-3b-Instruct} & 0.952 & 0.960 & 0.895 & 0.849 & 0.649 & 0.762 & 0.634 & 0.553 & 0.481 & 0.474 \\
\textbf{Llama3.2-1b-Instruct} & 0.848 & 0.837 & 0.736 & 0.729 & 0.705 & 0.634 & 0.692 & 0.679 & 0.486 & 0.523 \\
\textbf{Mistral-Small-Instruct-2409} & 0.961 & 0.956 & 0.776 & 0.771 & 0.663 & 0.628 & 0.505 & 0.500 & 0.470 & 0.474 \\
\textbf{Average} & 0.939 & 0.919 & 0.789 & 0.794 & 0.715 & 0.682 & 0.571 & 0.553 & 0.474 & 0.478 \\
\bottomrule
\end{tabular}%
}
\caption{Detector performance across various generator models under subgroup CEFR = B2-0}
\label{tab:cefr_B2-0}
\end{table*}


\begin{table*}[ht!]
\centering
\resizebox{\textwidth}{!}{
\begin{tabular}{lcccccccccccc}
\toprule
\textbf{Generator Model} 
& \textbf{binoculars} 
& \textbf{fastdetectgpt} 
& \textbf{gltr} 
& \textbf{detectgpt} 
& \textbf{chatgpt-roberta} 
& \textbf{radar} 
& \textbf{gpt2-base} 
& \textbf{gpt2-large} 
& \textbf{llmdet} 
& \textbf{fastdetectllm} \\
\midrule
\textbf{Qwen2.5-72B-Instruct} & 0.875 & 0.923 & 0.756 & 0.837 & 0.809 & 0.685 & 0.453 & 0.460 & 0.503 & 0.500 \\
\textbf{Qwen2.5-32B-Instruct} & 0.875 & 0.823 & 0.527 & 0.711 & 0.773 & 0.598 & 0.395 & 0.457 & 0.509 & 0.500 \\
\textbf{Qwen2.5-14B-Instruct} & 0.875 & 0.857 & 0.632 & 0.675 & 0.773 & 0.741 & 0.421 & 0.464 & 0.500 & 0.500 \\
\textbf{Qwen2.5-7B-Instruct} & 0.875 & 0.922 & 0.694 & 0.799 & 0.809 & 0.545 & 0.410 & 0.457 & 0.500 & 0.500 \\
\textbf{Qwen2.5-3B-Instruct} & 0.873 & 0.693 & 0.394 & 0.645 & 0.766 & 0.537 & 0.399 & 0.457 & 0.506 & 0.500 \\
\textbf{Qwen2.5-1.5B-Instruct} & 0.824 & 0.815 & 0.451 & 0.730 & 0.689 & 0.603 & 0.500 & 0.521 & 0.521 & 0.503 \\
\textbf{Qwen2.5-0.5B-Instruct} & 0.699 & 0.806 & 0.436 & 0.664 & 0.625 & 0.594 & 0.587 & 0.761 & 0.522 & 0.500 \\
\textbf{Llama3.1-70b-Instruct} & 0.873 & 0.915 & 0.755 & 0.810 & 0.877 & 0.804 & 0.522 & 0.476 & 0.503 & 0.502 \\
\textbf{Llama3.1-8b-Instruct} & 0.872 & 0.917 & 0.716 & 0.782 & 0.721 & 0.664 & 0.485 & 0.462 & 0.503 & 0.500 \\
\textbf{Llama3.2-3b-Instruct} & 0.870 & 0.913 & 0.726 & 0.797 & 0.716 & 0.759 & 0.488 & 0.491 & 0.509 & 0.500 \\
\textbf{Llama3.2-1b-Instruct} & 0.739 & 0.763 & 0.531 & 0.667 & 0.728 & 0.573 & 0.581 & 0.586 & 0.510 & 0.548 \\
\textbf{Mistral-Small-Instruct-2409} & 0.875 & 0.914 & 0.576 & 0.697 & 0.693 & 0.599 & 0.394 & 0.457 & 0.500 & 0.500 \\
\textbf{Average} & 0.844 & 0.855 & 0.600 & 0.735 & 0.748 & 0.642 & 0.470 & 0.504 & 0.507 & 0.504 \\
\bottomrule
\end{tabular}
}
\caption{Detector performance across various generator models under subgroup CEFR = XX-0}
\label{tab:cefr_XX-o}
\end{table*}



\begin{table*}[ht!]
\centering
\resizebox{\textwidth}{!}{%
\begin{tabular}{lcccccccccccc}
\toprule
\textbf{Generator Model} 
& \textbf{binoculars} 
& \textbf{fastdetectgpt} 
& \textbf{gltr} 
& \textbf{detectgpt} 
& \textbf{chatgpt-roberta} 
& \textbf{radar} 
& \textbf{gpt2-base} 
& \textbf{gpt2-large} 
& \textbf{llmdet} 
& \textbf{fastdetectllm} \\
\midrule
\textbf{Qwen2.5-72B-Instruct} & 0.983 & 0.981 & 0.978 & 0.917 & 0.823 & 0.862 & 0.716 & 0.554 & 0.489 & 0.474 \\
\textbf{Qwen2.5-32B-Instruct} & 0.983 & 0.932 & 0.866 & 0.800 & 0.817 & 0.725 & 0.547 & 0.478 & 0.477 & 0.474 \\
\textbf{Qwen2.5-14B-Instruct} & 0.983 & 0.913 & 0.883 & 0.763 & 0.903 & 0.820 & 0.615 & 0.497 & 0.487 & 0.474 \\
\textbf{Qwen2.5-7B-Instruct} & 0.983 & 0.978 & 0.929 & 0.860 & 0.829 & 0.764 & 0.546 & 0.481 & 0.478 & 0.474 \\
\textbf{Qwen2.5-3B-Instruct} & 0.967 & 0.743 & 0.643 & 0.710 & 0.791 & 0.574 & 0.520 & 0.480 & 0.490 & 0.474 \\
\textbf{Qwen2.5-1.5B-Instruct} & 0.956 & 0.900 & 0.717 & 0.803 & 0.749 & 0.667 & 0.587 & 0.531 & 0.489 & 0.475 \\
\textbf{Qwen2.5-0.5B-Instruct} & 0.861 & 0.895 & 0.670 & 0.803 & 0.670 & 0.649 & 0.669 & 0.773 & 0.484 & 0.474 \\
\textbf{llama3.1-70b-instruct} & 0.943 & 0.897 & 0.885 & 0.787 & 0.716 & 0.696 & 0.664 & 0.547 & 0.540 & 0.480 \\
\textbf{llama3.1-8b-instruct} & 0.979 & 0.969 & 0.941 & 0.845 & 0.682 & 0.737 & 0.726 & 0.603 & 0.503 & 0.474 \\
\textbf{llama3.2-3b-instruct} & 0.936 & 0.899 & 0.842 & 0.761 & 0.627 & 0.714 & 0.660 & 0.573 & 0.521 & 0.481 \\
\textbf{llama3.2-1b-instruct} & 0.846 & 0.796 & 0.705 & 0.724 & 0.695 & 0.658 & 0.678 & 0.681 & 0.506 & 0.516 \\
\textbf{Mistral-Small-Instruct-2409} & 0.983 & 0.957 & 0.816 & 0.794 & 0.675 & 0.644 & 0.552 & 0.477 & 0.491 & 0.474 \\
\textbf{Average} & 0.950 & 0.905 & 0.823 & 0.797 & 0.748 & 0.709 & 0.623 & 0.556 & 0.496 & 0.479 \\
\bottomrule
\end{tabular}%
}
\caption{Detector performance across various generator models under subgroup Language Environment = EFL}
\label{tab:language environment_EFL}
\end{table*}


\begin{table*}[ht!]
\centering
\resizebox{\textwidth}{!}{
\begin{tabular}{lcccccccccccc}
\toprule
\textbf{Generator Model} 
& \textbf{binoculars} 
& \textbf{fastdetectgpt} 
& \textbf{gltr} 
& \textbf{detectgpt} 
& \textbf{chatgpt-roberta} 
& \textbf{radar} 
& \textbf{gpt2-base} 
& \textbf{gpt2-large} 
& \textbf{llmdet} 
& \textbf{fastdetectllm} \\
\midrule
\textbf{Qwen2.5-72B-Instruct} & 0.967 & 0.967 & 0.977 & 0.904 & 0.787 & 0.836 & 0.665 & 0.534 & 0.501 & 0.477 \\
\textbf{Qwen2.5-32B-Instruct} & 0.966 & 0.907 & 0.813 & 0.816 & 0.757 & 0.691 & 0.535 & 0.505 & 0.490 & 0.477 \\
\textbf{Qwen2.5-14B-Instruct} & 0.967 & 0.890 & 0.874 & 0.777 & 0.886 & 0.805 & 0.605 & 0.514 & 0.498 & 0.477 \\
\textbf{Qwen2.5-7B-Instruct} & 0.967 & 0.962 & 0.915 & 0.833 & 0.823 & 0.686 & 0.555 & 0.507 & 0.494 & 0.477 \\
\textbf{Qwen2.5-3B-Instruct} & 0.957 & 0.739 & 0.654 & 0.698 & 0.750 & 0.567 & 0.544 & 0.509 & 0.501 & 0.477 \\
\textbf{Qwen2.5-1.5B-Instruct} & 0.935 & 0.869 & 0.690 & 0.793 & 0.732 & 0.643 & 0.585 & 0.549 & 0.507 & 0.477 \\
\textbf{Qwen2.5-0.5B-Instruct} & 0.839 & 0.873 & 0.648 & 0.758 & 0.640 & 0.600 & 0.670 & 0.804 & 0.510 & 0.478 \\
\textbf{llama3.1-70b-Instruct} & 0.942 & 0.908 & 0.911 & 0.824 & 0.764 & 0.718 & 0.652 & 0.563 & 0.533 & 0.479 \\
\textbf{llama3.1-8b-Instruct} & 0.963 & 0.958 & 0.940 & 0.843 & 0.690 & 0.746 & 0.691 & 0.584 & 0.510 & 0.477 \\
\textbf{llama3.2-3b-Instruct} & 0.936 & 0.911 & 0.871 & 0.788 & 0.648 & 0.737 & 0.673 & 0.576 & 0.517 & 0.479 \\
\textbf{llama3.2-1b-Instruct} & 0.841 & 0.814 & 0.740 & 0.732 & 0.712 & 0.623 & 0.710 & 0.692 & 0.521 & 0.533 \\
\textbf{Mistral-Small-Instruct-2409} & 0.967 & 0.948 & 0.740 & 0.732 & 0.712 & 0.623 & 0.710 & 0.692 & 0.521 & 0.533 \\
\textbf{Average} & 0.937 & 0.896 & 0.821 & 0.795 & 0.741 & 0.690 & 0.620 & 0.570 & 0.507 & 0.482 \\
\bottomrule
\end{tabular}
}\caption{Detector performance across various generator models under subgroup Language Environment = ESL}
\label{tab:language environment_ESL}
\end{table*}


\begin{table*}[ht]
\centering
\resizebox{\textwidth}{!}{%
\begin{tabular}{lcccccccccccc}
\toprule
\textbf{Generator Model} 
& \textbf{binoculars} 
& \textbf{fastdetectgpt} 
& \textbf{chatgpt-roberta} 
& \textbf{detectgpt} 
& \textbf{radar} 
& \textbf{gltr} 
& \textbf{gpt2-large} 
& \textbf{gpt2-base} 
& \textbf{llmdet} 
& \textbf{fastdetectllm} \\
\midrule
\textbf{Qwen2.5-72B-Instruct} & 0.875 & 0.923 & 0.809 & 0.837 & 0.685 & 0.756 & 0.460 & 0.453 & 0.503 & 0.500 \\
\textbf{Qwen2.5-32B-Instruct} & 0.875 & 0.823 & 0.773 & 0.711 & 0.598 & 0.527 & 0.457 & 0.395 & 0.509 & 0.500 \\
\textbf{Qwen2.5-14B-Instruct} & 0.875 & 0.857 & 0.773 & 0.675 & 0.741 & 0.632 & 0.464 & 0.421 & 0.500 & 0.500 \\
\textbf{Qwen2.5-7B-Instruct} & 0.875 & 0.922 & 0.809 & 0.799 & 0.545 & 0.694 & 0.457 & 0.410 & 0.500 & 0.500 \\
\textbf{Qwen2.5-3B-Instruct} & 0.873 & 0.693 & 0.766 & 0.645 & 0.537 & 0.394 & 0.457 & 0.399 & 0.506 & 0.500 \\
\textbf{Qwen2.5-1.5B-Instruct} & 0.824 & 0.815 & 0.689 & 0.730 & 0.603 & 0.451 & 0.521 & 0.500 & 0.521 & 0.503 \\
\textbf{Qwen2.5-0.5B-Instruct} & 0.699 & 0.806 & 0.625 & 0.664 & 0.594 & 0.436 & 0.761 & 0.587 & 0.522 & 0.500 \\
\textbf{Llama3.1-70b-Instruct} & 0.873 & 0.915 & 0.877 & 0.810 & 0.804 & 0.755 & 0.476 & 0.522 & 0.503 & 0.502 \\
\textbf{Llama3.1-8b-Instruct} & 0.872 & 0.917 & 0.721 & 0.782 & 0.664 & 0.716 & 0.462 & 0.485 & 0.503 & 0.500 \\
\textbf{Llama3.2-3b-Instruct} & 0.870 & 0.913 & 0.716 & 0.797 & 0.759 & 0.726 & 0.491 & 0.488 & 0.509 & 0.500 \\
\textbf{Llama3.2-1b-Instruct} & 0.739 & 0.763 & 0.728 & 0.667 & 0.573 & 0.531 & 0.586 & 0.581 & 0.510 & 0.548 \\
\textbf{Mistral-Small-Instruct-2409} & 0.875 & 0.914 & 0.693 & 0.697 & 0.599 & 0.576 & 0.457 & 0.394 & 0.500 & 0.500 \\
\textbf{Average} & 0.844 & 0.855 & 0.748 & 0.735 & 0.642 & 0.600 & 0.504 & 0.470 & 0.507 & 0.504 \\
\bottomrule
\end{tabular}%
}
\caption{Detector performance across various generator models under subgroup Language Environment = NS}
\label{tab:language environment_NS}
\end{table*}


\begin{table*}[ht!]
\centering
\resizebox{\textwidth}{!}{
\begin{tabular}{lcccccccccccc}
\toprule
\textbf{Generator Model} 
& \textbf{binoculars} 
& \textbf{fastdetectgpt} 
& \textbf{gltr} 
& \textbf{detectgpt} 
& \textbf{chatgpt-roberta} 
& \textbf{radar} 
& \textbf{gpt2-base} 
& \textbf{gpt2-large} 
& \textbf{llmdet} 
& \textbf{fastdetectllm} \\
\midrule
\textbf{Qwen2.5-72B-Instruct} & 0.951 & 0.963 & 0.937 & 0.903 & 0.820 & 0.814 & 0.649 & 0.538 & 0.495 & 0.479 \\
\textbf{Qwen2.5-32B-Instruct} & 0.950 & 0.892 & 0.788 & 0.793 & 0.783 & 0.681 & 0.513 & 0.484 & 0.484 & 0.479 \\
\textbf{Qwen2.5-14B-Instruct} & 0.951 & 0.895 & 0.839 & 0.757 & 0.877 & 0.805 & 0.574 & 0.500 & 0.492 & 0.479 \\
\textbf{Qwen2.5-7B-Instruct} & 0.951 & 0.959 & 0.880 & 0.841 & 0.807 & 0.705 & 0.521 & 0.485 & 0.484 & 0.479 \\
\textbf{Qwen2.5-3B-Instruct} & 0.938 & 0.733 & 0.603 & 0.690 & 0.775 & 0.558 & 0.510 & 0.490 & 0.494 & 0.479 \\
\textbf{Qwen2.5-1.5B-Instruct} & 0.919 & 0.871 & 0.676 & 0.785 & 0.736 & 0.645 & 0.579 & 0.544 & 0.498 & 0.480 \\
\textbf{Qwen2.5-0.5B-Instruct} & 0.817 & 0.867 & 0.626 & 0.770 & 0.650 & 0.620 & 0.652 & 0.779 & 0.499 & 0.480 \\
\textbf{Llama3.1-70b-instruct} & 0.926 & 0.903 & 0.882 & 0.813 & 0.764 & 0.722 & 0.639 & 0.547 & 0.523 & 0.483 \\
\textbf{Llama3.1-8b-instruct} & 0.946 & 0.951 & 0.900 & 0.836 & 0.679 & 0.714 & 0.671 & 0.571 & 0.500 & 0.479 \\
\textbf{Llama3.2-3b-instruct} & 0.921 & 0.903 & 0.832 & 0.786 & 0.642 & 0.727 & 0.628 & 0.562 & 0.517 & 0.483 \\
\textbf{Llama3.2-1b-instruct} & 0.834 & 0.805 & 0.699 & 0.716 & 0.708 & 0.630 & 0.670 & 0.671 & 0.510 & 0.521 \\
\textbf{Mistral-Small-Instruct-2409} & 0.951 & 0.941 & 0.776 & 0.787 & 0.675 & 0.619 & 0.518 & 0.482 & 0.494 & 0.479 \\
\textbf{Average} & 0.921 & 0.890 & 0.787 & 0.790 & 0.743 & 0.687 & 0.594 & 0.554 & 0.499 & 0.483 \\
\bottomrule
\end{tabular}
}
\caption{Detector performance across various generator models under subgroup Sex = Female}
\label{tab:sec_female}
\end{table*}


\begin{table*}[ht!]
\centering
\resizebox{\textwidth}{!}{
\begin{tabular}{lcccccccccccccc}
\toprule
\textbf{Generator Model} 
& \textbf{binoculars} 
& \textbf{fastdetectgpt} 
& \textbf{gltr} 
& \textbf{detectgpt} 
& \textbf{chatgpt-roberta} 
& \textbf{radar} 
& \textbf{gpt2-base} 
& \textbf{gpt2-large} 
& \textbf{llmdet} 
& \textbf{fastdetectllm} \\
\midrule
\textbf{Qwen2.5-72B-Instruct} & 0.968 & 0.972 & 0.942 & 0.891 & 0.793 & 0.834 & 0.657 & 0.522 & 0.496 & 0.479 \\
\textbf{Qwen2.5-32B-Instruct} & 0.968 & 0.921 & 0.791 & 0.788 & 0.797 & 0.704 & 0.523 & 0.482 & 0.492 & 0.479 \\
\textbf{Qwen2.5-14B-Instruct} & 0.967 & 0.899 & 0.834 & 0.747 & 0.868 & 0.798 & 0.584 & 0.493 & 0.496 & 0.479 \\
\textbf{Qwen2.5-7B-Instruct} & 0.968 & 0.969 & 0.890 & 0.837 & 0.839 & 0.694 & 0.529 & 0.485 & 0.491 & 0.479 \\
\textbf{Qwen2.5-3B-Instruct} & 0.956 & 0.736 & 0.606 & 0.699 & 0.769 & 0.570 & 0.503& 0.480 & 0.501 & 0.479 \\
\textbf{Qwen2.5-1.5B-Instruct} & 0.933 & 0.881 & 0.644 & 0.788 & 0.729 & 0.651 & 0.560 & 0.524 & 0.504 & 0.480 \\
\textbf{Qwen2.5-0.5B-Instruct} & 0.834 & 0.880 & 0.617 & 0.754 & 0.653 & 0.629 & 0.658 & 0.777 & 0.501 & 0.479 \\
\textbf{Llama3.1-70B-Instruct} & 0.936 & 0.909 & 0.858 & 0.788 & 0.750 & 0.721 & 0.637 & 0.532 & 0.541 & 0.483 \\
\textbf{Llama3.1-8b-Instruct} & 0.965 & 0.964 & 0.906 & 0.828 & 0.703 & 0.741 & 0.674 & 0.575 & 0.512 & 0.479 \\
\textbf{Llama3.2-3b-Instruct} & 0.929 & 0.911 & 0.832 & 0.766 & 0.654 & 0.730 & 0.641 & 0.555 & 0.520 & 0.483 \\
\textbf{Llama3.2-1b-Instruct} & 0.811 & 0.783 & 0.671 & 0.715 & 0.702 & 0.633 & 0.671 & 0.666 & 0.514 & 0.535 \\
\textbf{Mistral-Small-Instruct-2409} & 0.968 & 0.954 & 0.771 & 0.742 & 0.699 & 0.644 & 0.533 & 0.480 & 0.502 & 0.479 \\
\textbf{Average} & 0.934 & 0.898 & 0.780 & 0.779 & 0.746 & 0.696 & 0.597 & 0.548 & 0.506 & 0.485 \\
\bottomrule
\end{tabular}
}
\caption{Detector performance across various generator models under subgroup Sex = Male}
\label{tab:sex_male}
\end{table*}



\begin{table*}[ht!]
\centering
\resizebox{\textwidth}{!}{
\begin{tabular}{lcccccccccccc}
\toprule
\textbf{Generator Model} 
& \textbf{binoculars} 
& \textbf{fastdetectgpt} 
& \textbf{gltr} 
& \textbf{detectgpt} 
& \textbf{chatgpt-roberta} 
& \textbf{radar} 
& \textbf{gpt2-base} 
& \textbf{gpt2-large} 
& \textbf{llmdet} 
& \textbf{fastdetectllm} \\
\midrule
\textbf{Qwen2.5-72B-Instruct} & 0.962 & 0.960 & 0.948 & 0.921 & 0.794 & 0.823 & 0.619 & 0.510 & 0.491 & 0.482 \\
\textbf{Qwen2.5-32B-Instruct} & 0.962 & 0.889 & 0.771 & 0.799 & 0.759 & 0.669 & 0.489 & 0.483 & 0.485 & 0.482 \\
\textbf{Qwen2.5-14B-Instruct} & 0.961 & 0.910 & 0.859 & 0.789 & 0.873 & 0.811 & 0.565 & 0.496 & 0.490 & 0.482 \\
\textbf{Qwen2.5-7B-Instruct} & 0.962 & 0.957 & 0.890 & 0.845 & 0.806 & 0.705 & 0.525 & 0.487 & 0.484 & 0.482 \\
\textbf{Qwen2.5-3B-Instruct} & 0.953 & 0.729 & 0.605 & 0.716 & 0.770 & 0.571 & 0.496 & 0.486 & 0.490 & 0.482 \\
\textbf{Qwen2.5-1.5B-Instruct} & 0.927 & 0.854 & 0.640 & 0.777 & 0.703 & 0.629 & 0.556 & 0.531 & 0.498 & 0.482 \\
\textbf{Qwen2.5-0.5B-Instruct} & 0.811 & 0.851 & 0.627 & 0.770 & 0.637 & 0.612 & 0.660 & 0.796 & 0.503 & 0.482 \\
\textbf{llama3.1-70b-instruct} & 0.934 & 0.890 & 0.885 & 0.799 & 0.755 & 0.723 & 0.613 & 0.528 & 0.528 & 0.487 \\
\textbf{llama3.1-8b-instruct} & 0.957 & 0.946 & 0.894 & 0.852 & 0.679 & 0.732 & 0.643 & 0.546 & 0.498 & 0.482 \\
\textbf{llama3.2-3b-instruct} & 0.938 & 0.906 & 0.841 & 0.810 & 0.651 & 0.743 & 0.624 & 0.552 & 0.508 & 0.486 \\
\textbf{llama3.2-1b-instruct} & 0.838 & 0.790 & 0.694 & 0.732 & 0.695 & 0.638 & 0.659 & 0.665 & 0.511 & 0.529 \\
\textbf{Mistral-Small-Instruct-2409} & 0.962 & 0.935 & 0.757 & 0.791 & 0.677 & 0.626 & 0.497 & 0.484 & 0.499 & 0.482 \\
\textbf{Average} & 0.931 & 0.885 & 0.784 & 0.800 & 0.733 & 0.690 & 0.579 & 0.547 & 0.499 & 0.486 \\
\bottomrule
\end{tabular}
}
\caption{Detector performance across various generator models under subgroup Academic Genre = Humanities}
\label{tab:academic genre_humanities}
\end{table*}


\begin{table*}[ht!]
\centering
\resizebox{\textwidth}{!}{
\begin{tabular}{lcccccccccccc}
\toprule
\textbf{Generator Model} 
& \textbf{binoculars} 
& \textbf{fastdetectgpt} 
& \textbf{gltr} 
& \textbf{detectgpt} 
& \textbf{chatgpt-roberta} 
& \textbf{radar} 
& \textbf{gpt2-base} 
& \textbf{gpt2-large} 
& \textbf{llmdet} 
& \textbf{fastdetectllm} \\
\midrule
\textbf{Qwen2.5-72B-Instruct} & 0.951 & 0.976 & 0.931 & 0.868 & 0.852 & 0.777 & 0.683 & 0.562 & 0.496 & 0.476 \\
\textbf{Qwen2.5-32B-Instruct} & 0.951 & 0.911 & 0.797 & 0.751 & 0.824 & 0.690 & 0.553 & 0.490 & 0.493 & 0.476 \\
\textbf{Qwen2.5-14B-Instruct} & 0.951 & 0.890 & 0.810 & 0.697 & 0.864 & 0.775 & 0.589 & 0.502 & 0.497 & 0.476 \\
\textbf{Qwen2.5-7B-Instruct} & 0.951 & 0.968 & 0.880 & 0.810 & 0.834 & 0.689 & 0.511 & 0.495 & 0.495 & 0.476 \\
\textbf{Qwen2.5-3B-Instruct} & 0.939 & 0.751 & 0.611 & 0.668 & 0.756 & 0.516 & 0.518 & 0.494 & 0.498 & 0.476 \\
\textbf{Qwen2.5-1.5B-Instruct} & 0.921 & 0.908 & 0.648 & 0.784 & 0.744 & 0.665 & 0.561 & 0.519 & 0.496 & 0.476 \\
\textbf{Qwen2.5-0.5B-Instruct} & 0.819 & 0.863 & 0.613 & 0.723 & 0.660 & 0.642 & 0.671 & 0.781 & 0.495 & 0.479 \\
\textbf{Llama3.1-70B-Instruct} & 0.926 & 0.932 & 0.878 & 0.787 & 0.756 & 0.724 & 0.664 & 0.556 & 0.530 & 0.478 \\
\textbf{Llama3.1-8B-Instruct} & 0.948 & 0.972 & 0.909 & 0.816 & 0.703 & 0.694 & 0.683 & 0.593 & 0.504 & 0.476 \\
\textbf{Llama3.2-3B-Instruct} & 0.912 & 0.913 & 0.844 & 0.760 & 0.648 & 0.697 & 0.640 & 0.571 & 0.531 & 0.483 \\
\textbf{Llama3.2-1B-Instruct} & 0.806 & 0.785 & 0.681 & 0.683 & 0.737 & 0.600 & 0.673 & 0.671 & 0.513 & 0.529 \\
\textbf{Mistral-Small-Instruct-2409} & 0.951 & 0.963 & 0.794 & 0.714 & 0.717 & 0.602 & 0.528 & 0.486 & 0.499 & 0.476 \\
\textbf{Average} & 0.919 & 0.903 & 0.783 & 0.755 & 0.758 & 0.673 & 0.606 & 0.560 & 0.504 & 0.481 \\
\bottomrule
\end{tabular}
}
\caption{Detector performance across various generator models under subgroup Academic Genre = Life Science}
\label{tab:academic genre_life science}
\end{table*}


\begin{table*}[ht!]
\centering
\resizebox{\textwidth}{!}{
\begin{tabular}{lcccccccccccc}
\toprule
\textbf{Generator Model} 
& \textbf{binoculars} 
& \textbf{fastdetectgpt} 
& \textbf{gltr} 
& \textbf{detectgpt} 
& \textbf{chatgpt-roberta} 
& \textbf{radar} 
& \textbf{gpt2-base} 
& \textbf{gpt2-large} 
& \textbf{llmdet} 
& \textbf{fastdetectllm} \\
\midrule
\textbf{Qwen2.5-72B-Instruct} & 0.962 & 0.958 & 0.941 & 0.887 & 0.817 & 0.826 & 0.694 & 0.559 & 0.501 & 0.477 \\
\textbf{Qwen2.5-32B-Instruct} & 0.962 & 0.913 & 0.814 & 0.796 & 0.797 & 0.717 & 0.543 & 0.497 & 0.486 & 0.477 \\
\textbf{Qwen2.5-14B-Instruct} & 0.962 & 0.883 & 0.853 & 0.761 & 0.878 & 0.806 & 0.599 & 0.514 & 0.492 & 0.477 \\
\textbf{Qwen2.5-7B-Instruct} & 0.962 & 0.954 & 0.893 & 0.844 & 0.847 & 0.702 & 0.543 & 0.493 & 0.484 & 0.477 \\
\textbf{Qwen2.5-3B-Instruct} & 0.942 & 0.706 & 0.609 & 0.673 & 0.784 & 0.570 & 0.519 & 0.496 & 0.504 & 0.477 \\
\textbf{Qwen2.5-1.5B-Instruct} & 0.935 & 0.868 & 0.674 & 0.797 & 0.752 & 0.647 & 0.574 & 0.544 & 0.496 & 0.479 \\
\textbf{Qwen2.5-0.5B-Instruct} & 0.841 & 0.872 & 0.626 & 0.775 & 0.658 & 0.631 & 0.649 & 0.490 & 0.490 & 0.477 \\
\textbf{llama3.1-70b-Instruct} & 0.931 & 0.894 & 0.868 & 0.802 & 0.756 & 0.708 & 0.668 & 0.568 & 0.537 & 0.480 \\
\textbf{llama3.1-8b-Instruct} & 0.960 & 0.950 & 0.913 & 0.812 & 0.681 & 0.712 & 0.717 & 0.612 & 0.511 & 0.477 \\
\textbf{llama3.2-3b-Instruct} & 0.928 & 0.895 & 0.827 & 0.751 & 0.642 & 0.733 & 0.644 & 0.580 & 0.521 & 0.489 \\
\textbf{llama3.2-1b-Instruct} & 0.816 & 0.776 & 0.674 & 0.698 & 0.702 & 0.634 & 0.680 & 0.653 & 0.518 & 0.529 \\
\textbf{Mistral-Small-Instruct-2409} & 0.962 & 0.937 & 0.784 & 0.766 & 0.683 & 0.649 & 0.547 & 0.489 & 0.494 & 0.477 \\
\textbf{Average} & 0.930 & 0.884 & 0.790 & 0.780 & 0.750 & 0.695 & 0.615 & 0.568 & 0.503 & 0.482 \\
\bottomrule
\end{tabular}
}
\caption{Detector performance across various generator models under subgroup Academic Genre = Science Technology}
\label{tab:academic genre_science technology}
\end{table*}


\begin{table*}[ht!]
\centering
\resizebox{\textwidth}{!}{
\begin{tabular}{lcccccccccccc}
\toprule
\textbf{Generator Model} 
& \textbf{binoculars} 
& \textbf{fastdetectgpt} 
& \textbf{gltr} 
& \textbf{detectgpt} 
& \textbf{chatgpt-roberta} 
& \textbf{radar} 
& \textbf{gpt2-base} 
& \textbf{gpt2-large} 
& \textbf{llmdet} 
& \textbf{fastdetectllm} \\
\midrule
\textbf{Qwen2.5-72B-Instruct} & 0.955 & 0.977 & 0.932 & 0.906 & 0.780 & 0.847 & 0.619 & 0.500 & 0.495 & 0.481 \\
\textbf{Qwen2.5-32B-Instruct} & 0.954 & 0.909 & 0.774 & 0.798 & 0.784 & 0.686 & 0.494 & 0.462 & 0.487 & 0.481 \\
\textbf{Qwen2.5-14B-Instruct} & 0.955 & 0.901 & 0.813 & 0.742 & 0.876 & 0.806 & 0.563 & 0.472 & 0.495 & 0.481 \\
\textbf{Qwen2.5-7B-Instruct} & 0.955 & 0.976 & 0.870 & 0.849 & 0.806 & 0.699 & 0.515 & 0.465 & 0.488 & 0.481 \\
\textbf{Qwen2.5-3B-Instruct} & 0.948 & 0.760 & 0.590 & 0.711 & 0.780 & 0.579 & 0.495 & 0.466 & 0.495 & 0.481 \\
\textbf{Qwen2.5-1.5B-Instruct} & 0.916 & 0.881 & 0.676 & 0.784 & 0.735 & 0.651 & 0.587 & 0.537 & 0.510 & 0.481 \\
\textbf{Qwen2.5-0.5B-Instruct} & 0.823 & 0.901 & 0.616 & 0.768 & 0.652 & 0.607 & 0.645 & 0.762 & 0.509 & 0.481 \\
\textbf{llama3.1-70b-Instruct} & 0.929 & 0.911 & 0.857 & 0.814 & 0.767 & 0.728 & 0.609 & 0.510 & 0.531 & 0.486 \\
\textbf{llama3.1-8b-Instruct} & 0.950 & 0.964 & 0.891 & 0.844 & 0.701 & 0.753 & 0.644 & 0.540 & 0.507 & 0.481 \\
\textbf{llama3.2-3b-Instruct} & 0.916 & 0.913 & 0.817 & 0.780 & 0.656 & 0.730 & 0.632 & 0.535 & 0.518 & 0.484 \\
\textbf{llama3.2-1b-Instruct} & 0.832 & 0.827 & 0.694 & 0.740 & 0.700 & 0.643 & 0.673 & 0.653 & 0.507 & 0.523 \\
\textbf{Mistral-Small-Instruct-2409} & 0.955 & 0.956 & 0.760 & 0.782 & 0.674 & 0.632 & 0.522 & 0.464 & 0.499 & 0.481 \\
\textbf{Average} & 0.924 & 0.906 & 0.774 & 0.793 & 0.743 & 0.697 & 0.583 & 0.531 & 0.504 & 0.485 \\
\bottomrule
\end{tabular}
}
\caption{Detector performance across various generator models under subgroup Academic Genre = Social Science}
\label{tab:academic genre_social science}
\end{table*}

