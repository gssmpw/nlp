%\documentclass[journal]{IEEEtran}
\documentclass[10pt, conference]{IEEEtran}
% \usepackage{cite}
% \usepackage{CJK}
%\usepackage[english]{babel}
%\usepackage{algorithm}
%\usepackage{algorithmic}
\usepackage{algorithmicx}
\usepackage[ruled,vlined,linesnumbered]{algorithm2e}
% \usepackage{hyperref}
\usepackage{hhline}
\usepackage{amsmath,mathtools}
\usepackage{amsfonts,amssymb}
\usepackage{mathrsfs}
\usepackage{gensymb} % for degree
\usepackage{caption}% http://ctan.org/pkg/caption
\usepackage{multirow}
\usepackage{graphicx} 
\usepackage{multirow}
\usepackage{enumitem,color}
\usepackage{algpseudocode}

\usepackage{subfigure}

% for spacing details, see https://tex.stackexchange.com/questions/26521/how-to-change-the-spacing-between-figures-tables-and-text
\setlength{\textfloatsep}{1pt}  % this sets the gap between float obj (table, alg, figure, etc.) and the text
\setlength{\intextsep}{1pt}  % this sets the gap between float obj (table, alg, figure, etc.) and the text
\setlength{\floatsep}{1pt}  % this sets the gap between float obj (table, alg, figure, etc.) and the text
\setlength{\dbltextfloatsep}{1pt}  % this sets the gap between float obj (table, alg, figure, etc.) and the text
\setlength{\dblfloatsep}{1pt}  % this sets the gap between float obj (table, alg, figure, etc.) and the text
\setlength{\abovedisplayskip}{1pt} % this set the gap between equation and text
\setlength{\belowdisplayskip}{1pt} % this set the gap between equation and text


\usepackage{titlesec}
\titlespacing*{\section}{1pt}{0.5ex}{0.5ex}
\titlespacing*{\subsection}{1pt}{0.5ex}{0.5ex}
\titlespacing*{\subsubsection}{1pt}{0.5ex}{0.5ex}

\begin{document}
%
% paper title
% Titles are generally capitalized except for words such as a, an, and, as,
% at, but, by, for, in, nor, of, on, or, the, to and up, which are usually
% not capitalized unless they are the first or last word of the title.
% Linebreaks \\ can be used within to get better formatting as desired.
% Do not put math or special symbols in the title.
\title{\huge \emph{InSlicing}:  Interpretable Learning-Assisted Network Slice Configuration in Open Radio Access Networks}


\author{\IEEEauthorblockN{Ming Zhao, Yuru Zhang, Qiang Liu \vspace{-0.2in}}\\
\IEEEauthorblockA{
University of Nebraska-Lincoln\\
qiang.liu@unl.edu}\vspace{-0.3in}
\and
\IEEEauthorblockN{Ahan Kak, Nakjung Choi \vspace{-0.2in}}\\
\IEEEauthorblockA{
Nokia Bell Labs\\
nakjung.choi@nokia-bell-labs.com}\vspace{-0.3in}
}



\maketitle

\begin{abstract}
Network slicing is a key technology enabling the flexibility and efficiency of 5G networks, offering customized services for diverse applications. However, existing methods face challenges in adapting to dynamic network environments and lack interpretability in performance models. In this paper, we propose a novel interpretable network slice configuration algorithm (\emph{InSlicing}) in open radio access networks, by integrating Kolmogorov-Arnold Networks (KANs) and hybrid optimization process. 
On the one hand, we use KANs to approximate and learn the unknown performance
function of individual slices, which converts the blackbox optimization problem.
On the other hand, we solve the converted problem with a genetic method for global search and incorporate a trust region for gradient-based local refinement.
With the extensive evaluation, we show that our proposed algorithm achieves high interpretability while reducing 25+\% operation cost than existing solutions.
\end{abstract}

\begin{IEEEkeywords}
Network Slicing, Slice Configuration, Solution Interpretability, Open Radio Access Networks 
\end{IEEEkeywords}

\section{Introduction}
\label{sec:introduction}

% network slicing 

% explainability, optimization problem, only model unknown (online learning)

% model learning: KAN

% opt problem solving: convex opt. -  GA and TRM

%

%

%

Network slicing is one of the key technologies driving the development of 5G \cite{foukas2017network}, enabling customized network services for various mobile applications, such as autonomous driving \cite{campolo20175g}, AR/VR \cite{wijethilaka2021survey}, and IoT \cite{qiu2020edge}. 
By virtualizing physical network resources into multiple independent logical networks \cite{afolabi2018network}, multiple network slices can be concurrently supported and operated with tailored network performance and functionality, such as low-latency, high-throughput, and ultra reliability. 
With the advance of open radio access networks (e.g., O-RAN \cite{polese2023understanding}), the disaggregated network architecture, complex network dynamics, and diversified RAN Intelligent Controller (RIC) creates ever-complicating slice configuration in next-generation mobile networks.

For mobile network operators (MNOs), the key challenge is dynamic slice configuration, which aims to minimize the operational cost (e.g., resource usage) while meeting slice usersâ€™ performance requirements to assure their service level agreements (SLAs)~\cite{salvat2018overbooking}. 
With the ever-complicating mobile networks, however, it is impractical (if not impossible) to obtain the accurate representation of the complex relationship between the slice configuration and resulting slice performances~\cite{liu2022atlas, shi2021adapting}.
Hence, recent works~\cite{li2018deep, liu2020deepslicing, liu2021onslicing} focused on leveraging the superior approximation capability of AI/ML techniques, especially deep neural networks (DNNs), to learn the relationship and then optimize the slice configuration accordingly. 
For example, Atlas~\cite{liu2022atlas} used Bayesian optimization to online learn and allocate multi-dimensional resources (e.g., virtual radio bandwidth) to concurrent network slices, by combining Bayesian neural network (BNN) and Thompson sampling.
Some works~\cite{ayala2023edgebol, ayala2021bayesian} targeted the joint orchestration of both radio and computing resources, by designing a new Bayesian learning algorithm, in virtual radio access networks (vRANs).
However, existing works can only obtain the implicit representation (mostly parameterized by blackbox DNNs) of unknown correlations, which lack the explainability and interpretability of their solutions, such as \emph{why this action is taken, not others}.
As a result, although existing works could achieve promising performance, their limited interpretability remains various concerns to MNOs and eventually constrains their practical deployment in real-world networks.



In this paper, we propose a novel interpretable network slice configuration algorithm (\emph{InSlicing}) in open radio access networks.
The fundamental idea is to integrate Kolmogorov-Arnold Networks (KANs \cite{liu2024kan}) with high interpretability into the conventional non-convex optimization process. 
Distinct from traditional DNNs, KANs offer significant advantages (e.g., accuracy and interpretability) and enable intuitive visualization of how different components influence performance metrics through activation functions, providing enhanced model transparency. 
First, we formulate the slice configuration optimization problem to minimize the operation cost while satisfying the performance requirement of network slices.
Second, we design KANs to approximate and learn the unknown performance function of individual network slices.
Third, with the learned KANs, we derive the closed-form representations for individual slices, which converts the original blackbox optimization problem.
Fourth, we solve the converted problem with a population-based genetic method (GA \cite{mitchell1998introduction}) for global exploration, complemented by trust region \cite{conn2000trust} for gradient-information local refinement. 
With the extensive evaluation, we show that our proposed algorithm achieves high interpretability while reducing 25+\% operation cost than existing solutions.
We believe this work provides a new perspective of slice configuration, by considering the solution interpretability beyond the solution performance only.

% where unknown performance functions are represented by KANs. 

% The framework first utilizes KANs to approximate and model the relationship between slice configuration and slice performance. 

% Specifically, we formulate the slice configuration optimization problem where unknown performance functions are represented by KANs. 
% Given the complexity of the problem (often non-convex and high-dimensional), we employ a population-based genetic method (GA \cite{mitchell1998introduction}) for global exploration, complemented by trust region \cite{conn2000trust} for gradient-information local refinement. 
% This work provides a new perspective for managing resources in complex network environments.


\section{System Model}
We consider a generic cellular network, including the core network (CN), the radio access network (RAN) with multiple base stations and network slices. 
To assure the slice SLAs, MNOs optimize diverse configurations (e.g., resources and settings) for concurrent slices. 
Slice tenants deploy various applications within their respective slices, which impose specific performance requirements. 
From the network perspective, the performance of each slice is intrinsically related to the slice configuration decisions, denoted as \( X \). 
Each slice exhibits a unique performance function \( P(X) \). 
However, the performance function \( P(X) \) remains generally unknown, due to the complex network dynamics and unique characteristics. 
Meanwhile, slice configuration decisions incur operation costs for the MNOs.

We define \( I \) as the set of network slices, where \( i \in I \) represents the \( i \)-th slice, and \( R \) as the set of resource types, where \( r \in R \) represents the \( r \)-th resource type. Let \( x_{i,r} \) denote the amount of resource \( r \) allocated to slice \( i \). Subsequently, we can formulate the MNOs' total cost function $C(\cdot)$ as:
\begin{equation}
C(w_r , x_{i,r}) = \sum_{i \in I} \sum_{r \in R} w_r \cdot x_{i,r},
\end{equation}
where $w_r$ denotes the cost coefficient per unit of resource $r$.

The objective of network slice configuration can be formulated as a cost minimization problem, where the MNOs seek to minimize operational expenditure while ensuring that the performance requirements of slice tenants are satisfied. Specifically, the network slice configuration problem can be mathematically formulated as a constrained optimization problem as follows:
\begin{align}
    \mathbb{P}:& \quad \min_{x_{i,r}} \quad C(w_r , x_{i,r}) \\
    \text{s.t.} \quad 
    &C1: \quad  P(X_i) \ge Q_i,\quad \forall i \in I, \\
    &C2: \quad  L_{r} \le x_{i,r} \le H_r, \quad \forall i \in I, \ \forall r \in R,\\
    &C3: \quad  \sum\nolimits_{i\in I} x_{i,r} \le H_r, \quad \forall r \in R.
    \label{opt_p}
\end{align}
In problem $\mathbb{P}$, $C1$ constraints represent that the performance \( P(X_i) \) of the \( i \)-th slice, when the slice configuration action \( X_i \) is applied, should satisfy the threshold requirements \( Q_i \). Here, \( X_i = \{x_{i,1}, \ldots, x_{i,r}\} \) is the action vector allocated to slice \( i \), including all relevant resources. $C2 $ constraints ensure that the control actions \( x_{i,r} \) for each resource type \( r \) remain within the lower bound \( L_r \) and upper bound \( H_r \). $C3$ constraints impose a global restriction on resource utilization. For resource type \( r \), the total amount of resources allocated across all slices must not exceed the maximum resource capacity \( H_r \).  

\textbf{Challenge.} The primary challenge in solving the aforementioned problem $\mathbb{P}$ lies in the performance function \( P(X) \). 
On the one hand, the performance function \( P(X) \) is unknown in advance, i.e., no closed-form representation, which results in blackbox problem.
Although several frameworks (e.g., Bayesian optimization and multi-armed bandit) could solve the problem, they lack interpretability and explainability. 
On the other hand, the complex performance functions are nearly non-convex, the problem is still non-convex even if we obtain these closed-form representations.

% To tackle the above problem effectively, it is imperative to develop an accurate model for the performance function embedded within the  $C1 $ constraint. 
% On the one hand, the performance of each slice depends on multiple factors, including the types and quantities of resources allocated to the slice. 
% Its relationship with configuration actions is often intricate and difficult to represent using a closed-form expression, making traditional analytical approaches inadequate. On the other hand, the performance function is highly slice-specific, as each slice may have distinct requirements for various resources. This slice-dependent variability leads to a significantly large action variable space, resulting in a high-dimensional optimization problem.  The dimensionality, coupled with potential non-convexity, further complicate the searching process. This complexity implies that existing optimization approaches, such as Bayesian optimization, may struggle to identify globally optimal resource orchestration strategies efficiently.




\section{Solution}

% diagram figure, 1) learn, (why not GP, pologny regression (approxim capability,)) -->> KAN ; 2) optim ->> limited online decision, --> GA parallaiablity, + trust region

% subsection) KAN approximation; theorem 

% subsection) optim method: 1) GA ; 2) trust region

% algorithm description: pesudoe code

\begin{figure}[!t]
	\centering
	\includegraphics[width=3.4in]{fig/solution_fig.pdf}
	\vspace{-0.07in} \caption{\small The overview of the \emph{InSlicing} algorithm.}
	\label{fig:solution_fig}
\end{figure}


In this section, we present the proposed solution to effectively solve the above problem (see Fig. \ref{fig:solution_fig}), which optimizes resource usage through a combination of approximation techniques and heuristic search methodologies. 
On the one hand, we leverage KANs to perform online approximation learning of slice-specific performance functions. This approach focuses on the relationship between performance metrics and slice configuration actions for each slice, thereby transforming the previously intractable performance constraints into knowable and solvable components of the optimization problem. 
On the other hand, we solve the converted problem by developing a heuristic search method, based on genetic methods augmented with a local optimization method. 
This hybrid approach minimizes the MNOs' cost by conducting a population-based heuristic exploration of the entire resource space for each slice and evaluating slice performance. 
The proposed method is suitable for tackling complex, discontinuous, and non-convex optimization problems, which are common in slice configuration tasks with intricate constraints. 
Additionally, the parallel processing capabilities of the GA significantly enhance the efficiency of the approach, making it well-suited for large-scale resource optimization scenarios. 
To further accelerate convergence and avoid the resource optimization problem resulting in local optima, we integrate a trust region method (TRM)-based local optimization component. 

% Specifically, the proposed \emph{InSlicing} algorithm (see Alg. \ref{alg:pseudo_code}) consists of two main components, KANs approximation and cost optimization. 
% First, we employ the KANs to perform online learning of the performance functions for individual network slices. 
% For each slice, slice configuration actions are mapped to corresponding performance metrics. 
% Through the KANs model, we establish the relationship between actions and performance, obtaining a mathematical representation of this connection. 
% The powerful approximation capabilities of the KANs enable to derive of highly complex mathematical expressions, though the resulting formulas are often intricate in nature. 
% This transformation converts problem from an unknown form into a fully mathematically tractable problem. 
% To solve this now-defined optimization problem, we implement a hybrid search approach that integrates GA with TRM. 
% The population-based search method enables efficient exploration of slice configuration space with respect to complex constrained optimization problems. 
% Its inherent parallelism significantly accelerates the search process. 
% During the evolution of the population, we incorporate trust regions to perform local searches withing promising area. 
% This integration enhances the ability to identify globally optimal slice configuration strategies while avoiding local optima.

\subsection{KANs Approximation}

In the performance function approximation phase, KANs are used to learn the relationship $P(X)$ between each slice's performance metrics and its control actions. Our goal is to achieve accurate approximation while maintaining the interpretability of the connection between input $X_i$ and system performance output $p_i$. This can be expressed as:
\begin{equation}
    P(X_i) = \text{KANs}(X_i, p_i), \quad i \in I.
\end{equation}
The KANs are founded on the Kolmogorov-Arnold representation theorem \cite{braun2009constructive},\cite{kolmogorov1957representation} as an alternative to traditional MLPs-based solutions to learn the performance function. KANs implement activation functions on edges rather than on nodes, as in MLPs. This unique characteristic enables it to achieve better approximation (e.g., $P(X)$) in terms of accuracy and interpretability.

\textbf{Kolmogorov-Arnold representation theorem.} The theorem~\cite{liu2024kan} asserts that any multivariate continuous function can be expressed as a combination of univariate continuous functions and addition operations. Specifically, for a smooth $f:[0,1]^n \rightarrow \mathbb{R}$,
\begin{equation}
    f(x)=f\left(x_1, \ldots, x_n\right)=\sum_{q=1}^{2 n+1} \Phi_q\left(\sum_{p=1}^n \phi_{q, p}\left(x_p\right)\right),
\end{equation}
where $\phi_{q,p}:[0,1] \rightarrow \mathbb{R}$ and $\Phi_q: \mathbb{R} \rightarrow \mathbb{R}$. Certain univariate functions may be non-smooth or even fractal, rendering them unsuitable for machine learning. KANs extend the aforementioned theorem by generalizing it to arbitrary depths and widths, thereby enhancing their expressive power, which can be represented as follows:
\begin{equation}
\mathrm{KAN}(\mathbf{x})=(\boldsymbol{\Phi}_{L-1} \circ \boldsymbol{\Phi}_{L-2} \circ \cdots \circ \boldsymbol{\Phi}_1 \circ \boldsymbol{\Phi}_0) \circ \mathbf{x}.
\end{equation}
Here, $\boldsymbol{\Phi}_L$ denotes the B-spline function matrix corresponding to the $L$-th KAN layer, and $\mathbf{x}$ is the input vector. The structure of $\boldsymbol{\Phi}$ is given by:
\begin{equation}
\boldsymbol{\Phi}=\left(\begin{array}{ccc}
\phi_{1,1}(\cdot), & \cdots, & \phi_{1, n_{\text {in }}}(\cdot) \\
\vdots & & \vdots \\
\phi_{n_{\text {out }}, 1}(\cdot), & \cdots, & \phi_{n_{\text {out }}, n_{\text {in }}}(\cdot)
\end{array}\right),
\end{equation}
The elements $\phi(x)$  are activation functions, which are defined as the sum of a bias function $b(x)$ and a spline function, weighted by a coefficient $w$:
\begin{equation}
    \phi(x) = w \left(b(x) + \operatorname{spline}(x)\right). 
\end{equation}

KANs are a combination of spline functions and MLPs. This hybrid structure enables KANs to not only learn features but also obtain a high-precision optimization of these features (owing to its internal similarity to spline functions). As a result, the accuracy of our performance function is enhanced. Furthermore, KANs exhibit excellent interpretability. Their inherent visualization and interactivity facilitate human understanding of model behavior and outcomes. This transparency enables better comprehension of the relationships between slice configuration decisions and slice performance during the learning process, providing valuable insights into the underlying system dynamics and decision-making.

\subsection{Problem Optimization}
In the cost minimization phase, the objective is to solve the previously established optimization problem, now mathematically defined by the KAN$-$derived performance functions. This problem involves a large number of variables (e.g., $|R| \times |I|$) and numerous complex constraints (e.g., $|I|+|R|^2+|R|$). Traditional optimization approaches, such as gradient descent (also with unknown convexity) and Bayesian optimization, are often inadequate for solving large-scale optimization problems of this nature. Moreover, some methods are prone to converging to local optima. To overcome these challenges, we employ a genetic method embedded with a trust region approach to navigate the search space and seek a global optimum. 

\textbf{Genetic Method.} The genetic method is inspired by the principles of natural evolution. The evolutionary process maintains diversity among individuals within a population. Individuals that are better adapted to the environment are more likely to survive, reproduce, and pass their traits to the next generation. In the context of evolution, a fitness function is used to evaluate individuals. These individuals undergo selection, crossover, and mutation operators, which simulate the process of biological evolution. In our work, the objective function is mapped to the fitness function $F(\cdot) = C(w_r , x_{i,r}) $. Following the evaluation, the tournament selection \cite{miller1995genetic} is used to choose parents for reproduction and generation of the next population. Next, we apply a crossover operation with a predefined crossover probability. Let $p_1$ and $p_2$ represent two parent individuals, which produce two offspring $c_1$ and $c_2$ through the following crossover formula:
\begin{equation}
\begin{aligned}
& c_1=\alpha \cdot p_1+(1-\alpha) \cdot p_2, \\
& c_2=\alpha \cdot p_2+(1-\alpha) \cdot p_1,
\end{aligned}
\label{eq:crossover}
\end{equation}
where $\alpha$ is a random number, ensuring diversity in the offspring by balancing the traits inherited from both parents. Subsequently, offspring undergo a mutation operation with an adaptive mutation rate $m(g)$ and random number $r$. The mutation is performed as follows:
\begin{equation}
x_i^{\prime}= \begin{cases}x_i+\epsilon & \text { if } r<m(g) \text { and } x_i^{\prime} \text { is feasible, } \\ x_i & \text { otherwise, }\end{cases}
\label{eq:mutation}
\end{equation}
where $x_i^{\prime}$ is the mutated solution after boundary correction and feasibility checks. The $\epsilon$ is the mutation magnitude, following a normal distribution. The adaptive mutation rate is defined as $m(g) = m_0 \cdot \left(1 - {g}/{G}\right)$, where $g$ is the current generation index, $G$ is the total number of generations, and $m_0$ is the initial mutation rate. This strategy ensures a higher mutation rate in the early stages to promote exploration, and a reduced mutation rate in later stages to enhance exploitation and convergence towards the optimal solution.

\textbf{Trust Region Searching.} It defines a localized region around the current iteration $k$. In this region, the objective function $f(x_k)$ is approximated with its second-order Taylor expansion to construct a local quadratic model $m_k(s)$. The TRM then minimizes the quadratic model within the trust region, which can be formulated as follows:
\begin{align}
    &  \min_{s} \quad m_k(s)=f\left(x_k\right)+\nabla f\left(x_k\right)^T s+\frac{1}{2} s^T B_k s \\
    &\text{s.t.} \quad \quad \quad 
     \quad  \|s\| \leq \Delta_k,
     \label{eq:trm}
\end{align}
where $\nabla f(x_k)$ represents the gradient, $B_k$ is the Hessian matrix, and $\Delta_k$ is the radius of the trust region. After each iteration, the algorithm adjusts the region's radius based on the ratio $\rho_k$ between the actual reduction and the predicted reduction in the objective function, defined as:
$\rho_k
 = (f(x_k) - f(x_k + s_k))/(m_k(0) - m_k(s_k))$. If $\rho_k$ approaches 1, it indicates the model closely approximates the objective function, and the current trust region radius is acceptable. Conversely, if $\rho_k$ is close to 0, it suggests a discrepancy between the model and the objective function. In this case, the region radius needs to be reduced in the next iteration.


\begin{algorithm}[!t]
    \caption{The \textit{InSlicing} Algorithm}
    \label{alg:pseudo_code}
    \KwIn{$I, R, Q_i, L_r, H_r, w_r, G,n$}
    \KwOut{$X_{best}, F_{best}$}

    $/**\; KANs \; Approximation \; Process \; **/$\;

    \For{$i = 0, 1, \ldots, |I|$}{
        Initialize KAN models for slice $i$\;
        Train models to learn performance function $P(X_i)$ using online querying\;
    }

    $/**\; Optimization \; Search\; Process \; **/$\;

    Initialize population and parameters for GA\;
    Set best solution $X_{best} \gets \emptyset$, best value $F_{best} \gets \infty$\;

    \For{$g = 0, 1, \ldots, G$}{
        $/**\; Evaluate \; Fitness\; **/$\;
        \ForEach{individual $X$ in population}{
            Calculate fitness function $F(X)$\;
            \If{$F(X) < F_{best}$ and $X$ is feasible}{
                $X_{best} \gets X$, $F_{best} \gets F(X)$\;
            }
        }
        $/**\;Natural \; Evolution\; **/$\;
        Perform selection, crossover and mutation operators with Eq. \ref{eq:crossover} and Eq. \ref{eq:mutation}\;
        
        $/**\; Trust\; Region\; **/$\;
        \If{$g ~\%~ n == 0$ and $X_{best} \neq \emptyset$}{
            Set start point with $X_{best}$\;
            \For{$k = 0, 1, \ldots, K$}{
             $X_{k} \gets$ Solve approximated problem $m_k(s)$\;
             Adjust region radius $\Delta_k$ based on $\rho_{k}$\;
            }
            Update $X_{best} \gets X_{K}, F_{best} \gets F(X_{K})$\;
        }
    }
\end{algorithm}

\subsection{ The \emph{InSlicing} Algorithm}

Based on the preceding analysis, we summarize the \emph{InSlicing} algorithm in Alg. \ref{alg:pseudo_code}. 
In the KANs approximation phase, we use KAN models to learn the mathematical expressions for both control actions and performance metrics for each slice. This transforms the unknown constraints to well-defined formulations. Next, we implement a hybrid optimization framework that combines global exploration with local refinement. we initialize the population with a genetic method, leveraging the cost function as the fitness function to evaluate the individual solutions. Through heuristic search, the GA performs a global exploration to identify a rough optimal solution. Meanwhile, a trust region is defined around the solution. Within this trust region, a quadratic model is constructed, and gradient information is used for local optimization. This dual-phase optimization framework significantly enhances both optimization precision and convergence efficiency.



\section{Evaluation}

% dataset from Atlas (oai+.....), % parameters % slice, threshold

% comparsion algorithms: 1)


% figure 1) insights, justify


In this section, we extensively evaluate the proposed \emph{InSlicing} algorithm in terms of slicing performance, scalability, and regret minimization. 
We use the same end-to-end network testbed from Atlas~\cite{liu2022atlas}, which consists of OpenAirInterface radio access network and core network, and multiple network slices. 
Each slice has one smartphone with a customized Android mobile application, which generally sends different kinds of data to the core and gets feedback accordingly. 
The slice configuration includes \emph{bandwidth\_ul}, \emph{bandwidth\_dl}, \emph{mcs\_offset\_ul}, \emph{mcs\_offset\_dl}, \emph{backhaul\_bw}, and \emph{cpu\_ratio}.
Without loss of generality, the performance metric of all slices is round-trip latency (more details see Atlas~\cite{liu2022atlas}). 
By default, we configure 9 slices with performance thresholds (i.e., $Q_i, \forall i$) [400, 500, 60]ms, and configuration values ranging between [0,1].
The KAN models are learned for 1000 iterations. 
For the optimization process, we set a maximum search time of 400 seconds. 
The genetic method is configured with a population size of 50, a crossover probability of 0.9, and a base mutation probability of 0.2. 
Every 5 evolutions, the best-performing individual is selected as the starting point for trust region optimization, which is configured with a base radius of 0.2 and executes for 25 iterations. 
A clipping operation is applied during the optimization process to ensure that the solutions remain within the resource bounds. 

We compare our proposed algorithm with the following methods:
\begin{itemize}
    \item \textbf{GBO}: The GBO employs a global Bayesian optimization framework (similar to the algorithm in \cite{ayala2023edgebol}) to address the slice configuration problem across all slices. A Gaussian process is used as the surrogate model, and expected improvement is utilized as the acquisition function. To ensure the SLAs of slices, the objective function incorporates penalty terms for performance requirement violations. 
    \item \textbf{GA-only}: The GA-only uses a genetic method based on population evolution principles. It is well-suited for optimization tasks involving a large number of parameters and complex mathematical representations. GA-only focuses solely on global optimization and it cannot perform any local refinement within local regions around promising solutions. 
\end{itemize}


\begin{figure}[!t]
	\centering
	\includegraphics[width=2.7in]{fig/kan_loss_model.pdf}
	\vspace{-0.07in} \caption{\small The learning loss and illustration of KANs.}
	\label{fig:kan_loss_model}
\end{figure}


\begin{figure}[!t]
	\centering
	\includegraphics[width=2.7in]{fig/resource_alloc_ga_trust_slices_9.pdf}
	\vspace{-0.07in} \caption{\small The heatmap of slice configuration in \textit{InSlicing}.}
	\label{fig:resource_allocation_map}
\end{figure}

\begin{figure}[!t]
	\centering
	\includegraphics[width=3.0in]{fig/comparsion_slice_9_with_time_no_variance.pdf}
	\vspace{-0.07in} \caption{\small The cost under comparison algorithms.}
	\label{fig:comparison}
\end{figure}




Fig. \ref{fig:kan_loss_model} illustrates the process of KAN model learning the performance metric for a specific slice. The model begins to converge after approximately 400 steps, achieving low root mean square error (RMSE) values for both training and test losses (0.2867 and 0.3354, respectively). The right side shows the model architecture, which processes two distinct resource inputs through three hidden layers to generate performance predictions. This structure captures the differential impact of the two resources on the performance metric through a series of activation functions. The resulting mathematical expression is formulated as $P(x_1,x_2) = -788.9124x_1 + 11.1672x_2 + 65.9526 \sin(0.6438x_1 - 4.1988) - 154.8258 \sin(0.5912x_2 + 5.1804) + 45.7148 \sin(0.6943x_2 + 5.2315) + 15.8861 \sin(1.9874x_2 + 7.6146) + 836.0928$.

Fig. \ref{fig:resource_allocation_map} illustrates the optimization results of the proposed \textit{InSlicing} to minimize the cost while ensuring that slice users' performance requirements are satisfied. The figure depicts the slice configuration map across 9 slices for 6 resource types. To maintain the operation of  MAR and HVS applications, the minimum resource thresholds for URBG, CCPU, DRBG, and TNBW are set to 0.1.



Fig. \ref{fig:comparison} compares the proposed \textit{InSlicing} with other methods, demonstrating that our approach achieves the lowest MNOs operational cost of 1.90 under the same computational time complexity, outperforming both GBO (2.55) and GA-only (2.28) approaches. This is because GBO struggles with high-dimensional spaces due to the sparsity of sampled points. Moreover, surrogate models like Gaussian processes often fail to accurately approximate complex functions in high-dimensional spaces, particularly those with oscillations or multiple local optima. This leads to insufficient guidance for the optimization search (e.g., the cost is more than twice that of the other algorithm at the beginning of the optimization process), causing it to converge prematurely to local optima. The GA-only utilizes population-based search strategies, which makes it well-suited for problems with multiple local optima and high-dimensional spaces, resulting in better solutions than GBO. However, as the population evolves, diversity can decrease, and individuals also get trapped in local optima. Our proposed \textit{InSlicing} incorporates local refinement using the trust region. While GA provides a rough global solution, TRM leverages gradient information within the trust region to further optimize the solution locally, where the hybrid approach mitigates the degradation of global search capability caused by reduced population diversity.


\begin{figure}[!t]
	\centering
	\includegraphics[width=3.0in]{fig/scalbility_bar_fig.pdf}
	\vspace{-0.07in} \caption{\small The scalability under comparison algorithms.}
	\label{fig:scalability}
\end{figure}

\begin{figure}[!t]
	\centering
	\includegraphics[width=3.0in]{fig/average_regret_fig.pdf}
	\vspace{-0.07in} \caption{\small The regret under comparison algorithms.}
	\label{fig:regret}
\end{figure}

\begin{figure}[!t]
	\centering
	\includegraphics[width=3.0in]{fig/cdf_performance_fig.pdf}
	\vspace{-0.07in} \caption{\small The CDF of normalized performance.}
	\label{fig:performance_cdf}
\end{figure}

Fig. \ref{fig:scalability} compares the scalability of various algorithms under different numbers of slices in the network. It shows all three algorithms are capable of handling resource orchestration under different slice configurations. As the number of slices increases, the optimal cost also rises correspondingly. Our proposed \textit{InSlicing} can achieve the lowest cost among the three methods (at six slices, although our optimization result is not the absolute lowest, it remains highly competitive and approaches the minimum). Interestingly, GBO always obtains higher costs, likely due to its difficulty in handling high-dimensional optimization problems. 

Fig. \ref{fig:regret} compares the regret values under the default settings. The regret value is defined as the ratio between the cumulative gap (the sum of differences between the cost value after each optimization iteration and the final optimal cost value) and the number of iterations. The results show that our proposed \textit{InSlicing} achieves the lowest regret value, indicating its ability to significantly reduce the gap between the objective function value and the optimal value throughout most iterations. In contrast, GBO exhibits the highest regret value, which can be attributed to its premature convergence to a suboptimal solution as shown in Fig. \ref{fig:comparison}.

Fig. \ref{fig:performance_cdf} presents the cumulative distribution function (CDF) of normalized performance under the three algorithms. It can be observed that in most cases (e.g., normalized performance ranges from 1.33 to 1.41), our algorithm obtains lower normalized performance, which indicates that our algorithm precisely meets slice usersâ€™ requirements avoiding unnecessary resource overprovisioning. In comparison, the curve of GBO shows a more dispersed distribution. This suggests that GBO tends to over-allocate resources to meet slice users' requirements and fails to effectively control the MNOs' costs in Fig. \ref{fig:comparison}.



% \begin{algorithm}[!t]
% 	\caption{DNT}\label{alg:proposed}
% 	\KwIn{ $\beta$, $\theta^*$, $\mathbf{s}^s_{t}$, $\mathbf{s}^w_{t}$  }
% 	\KwOut{$x, y$}
% % 	$\theta^*$ $\gets$ Online train in real system\;
	  
% 	    $\mathbf{s}^v_{t}, i \gets$ vehicle, $/*\;accept\; vehicle*/$\;
%     	$\mathbf{s}_{t} \gets [\mathbf{s}^v_{t},\; \mathbf{s}^s_{t},\; \mathbf{s}^w_{t}]$, $/*\;build\; state\; */$\;
%     	\If {time to schedule}
%     	{
% 		    $x_k \gets 1,\; \forall k \in \mathcal{I}$\;
%         	\While{$True$}
%         	{
%         	 $k \gets \arg\max\limits_{k \in \mathcal{I}, x_k \neq 0}O_k$\;
%         	 $x_k \gets 0$;
        	 
%         	 \If {$\bigcup\limits_{i\in \mathcal{I}, x_i \neq 0} C_i^{(t)} \leq \beta \bigcup\limits_{i\in \mathcal{I}} C_i^{(t)}$}
%         	    {
%         	        $x_k \gets 1$\;
%         	        \textbf{break}\;
%         	    }
%         	}
%     	}
%     	\If {$x_i == 1$ (scheduled)}
%     	{
%         	$y$ $\gets$ $\arg\max \limits_{\mathbf{a}_{t}}Q^*(\mathbf{s}_{t}, \mathbf{a}_{t} | \theta^*)$, $/*\;get\; action */$\;
%     	}
%     	\Else
%     	{
%     	    $y \gets -1$,  $/*\;not\; scheduled*/$\;
%     	}
%     % 	vehicle $\gets$ $(x, y)$, $/*\;return\; to\; vehicle */$\;
	
%     \Return{$x, y$}\;
% \end{algorithm}

% \section{System Implementation}
% In this section, we describe the system implementation, including the end-to-end testbed and the proposed DNT.

% \subsection{End-to-End Testbed}
% We implement an end-to-end network testbed in Fig. \ref{fig:DNT-testbed}, including an eNB in RAN, a CN, and a mobile user. 
% We implement CN based on OpenAir-CN with the separation of the control plane and data plane (CUPS), wherer network functions (NFs), e.g., HSS, SPGW-U and SPGW-C, are deployed using Docker containers. 
% We implement the RAN based on OpenAirInterface (OAI) on an Intel i7 desktop with Ubuntu 18.04 low-latency kernel. 
% The RAN host is connected to an USRP B210 serving as the RF front end. 
% The eNB operates on frequency band 7 with a 10MHz radio bandwidth. 
% An Oneplus 9 Android smartphone is connected to eNB as the UE, with 1 meter UE-to-Antenna distance.
% We develop an Android application that continuously sends video frames to edge server co-located with the SPGW-U. 
% These video frames are processed by the server using a feature extraction algorithm (i.e., ORB), and the results are subsequently fed back to the UE. 
% The performance metric for evaluating this application is the end-to-end latency of frames. 
% % To facilitate congestion control and simulate diverse user traffic, we impose a restriction on the number of dynamic frames, which refers to frames awaiting results. 

% The \textbf{state} $\mathcal{S}= \left\{ U, D, C, R, M_{U}, M_{D},F \right\} $ includes 1) $ U\in[0,50]$ is the uplink bandwidth allocation; 2) $D\in[0,50]$ is downlink bandwidth allocation; 3) $C\in[0,1.0]$ is CPU ratio; 4) $R\in [0,1.0]$ is RAM ratio; 5) $M_{u}\in[0,20]$ is average uplink Modulation and Coding Scheme (MCS); 6) $M_{d}\in[0,28]$ is average downlink MCS; 7) $F\in[1,4]$ is user traffic. % We emulate maximum four users by controlling the interval of frame the number of users as 1, 2, 3, and 4, respectively.
% Note that, the state space is discrete due to the intrinsic implementation of the end-to-end testbed, such as physical resource block (PRB) allocation in the MAC layer and the number of user traffic.
% Hence, we exhaustively search the whole state space and generate a database of network performance with nearly 2500 states.

% \begin{figure}[!t]
% 	\centering
% 	\includegraphics[width=3.4in]{fig/DNT-testbed.pdf}
% 	\caption{\small The overview of the end-to-end network testbed. }
% 	\label{fig:DNT-testbed}
% \end{figure}

% \subsection{Digital Network Twin}
% % We develop a simulation environment to simulate the real network by utilizing the state of the real-world network system and develop its digital twin based on this simulator. The simulator is developed with NS3, and shares the same parameters with the real-world system. This means that the simulation accurately recreates the scenario found in the real world system. At the same time, we allow the DNT to be refined in an online learning manner by enabling direct interaction with the actual network during training. DNT can utilize algorithms to rapidly acquire knowledge about the difference between real-world system and network simulator, ultimately bridging these discrepancies.

% The proposed DNT is mainly composed of an offline network simulator and a neural agent.

% \textbf{Simulator.}
% We replicate the end-to-end testbed by using NS-3, where the simulation parameters are matched correspondingly.
% In particular, we adopt the \emph{LogDistancePropagationLossModel} as the pathloss model while omitting any fading models. 
% For the transport network, a p2p link is created to connect RAN and CN, where the bandwidth and delay are configured based on realistic measurements. 
% We also replicate the traffic generation of mobile users and the edge computing processing by developing a FIFO service queue.
% Specifically, the transmission sizes match closely with a mean of 28.8kb and a standard deviation of 9.9kb. 
% Besides, other simulation parameters are calibrated with that of the end-to-end testbed, including the MAC scheduler algorithm, antenna specifications, frequency band, and the distance between the eNB and smartphones. 
% The end-to-end latency of frames is logged and extracted as the output of network simulations.
% % The outcomes of the simulations have been extracted by analyzing the tracer data. This analysis covers not only the end-to-end latency of each frame but also encompasses intricate details concerning transmission and computational processes, e.g., queuing time, computing time, and uplink and downlink transmission time.

% \textbf{Neural Agent.}
% We implement the neural agent with a BNN model with 4-layer fully connected architecture (i.e., 128x256x256x128), in PyTorch.
% We use the \textit{Tanh} activation function in the BNN \cite{Goodfellow-et-al-2016}. 
% We utilize the \textit{Adadelta} optimizer with the initial learning rate of 0.001, where the learning rate is decayed by using the \textit{StepLR} scheduler with gamma 0.95. 
% % Additionally, the input dimension of the BNN model is 7 (states) and 20 (distribution of network performance), respectively.

% \textbf{Learn-to-Bridge Algorithm.}
% We use cost-aware Bayesian optimization in the first stage, where GP is implemented by using \textit{scikit-learn} with the \textit{GaussianProcessRegressor} module. 
% We utilize the \textit{Matern} kernel with $nu = 2.5$, which extends the RBF kernel and the absolute exponential kernel by introducing the parameter $nu$.
% The $nu$ parameter governs the smoothness of the learned function. 
% % Additionally, to enhance regression performance, we normalize the target values by subtracting the mean and scaling to unit variance.

% % In the second stage of the algorithm, we develop BNN model using PyTorch 1.13.1, where neural network employ 4-layer fully connected architectures, specifically 128x256x256x128, with \textit{Tanh} activation functions \cite{Goodfellow-et-al-2016}. We utilize the \textit{Adadelta} optimizer with the initial learning rate of 0.001, where the learning rate is decayed by using the \textit{StepLR} scheduler with gamma 0.95. Additionally, the input and output dimension of each BNN model is 7 (states) and 20 (distribution of network performance), respectively.

% \section{Performance evaluation}


% % comparison algorithms:
% % 1) original simulator
% % 2) grid-search, + mean value only
% % 3) BO + GP

% % figure 1&2: gap reduction, cumulative cost

% % figure 3&4: detailed analytics: heatmap of reduced gap under different states; 4

% % figure 5&6: scabaility, different states, importance of states (state-dependent gap): 
%     % for example, do the experiment under 1 states, 3 states, all states.

% % impact of batch size? yuru: try 8, 16, 32(with 78 iteration)

% % figure 7&8: impact of different cost function: 1) when actions have all the same 1 cost; 2) ours latency; 3) unknown cost??

% % figure 9: individual components, i.e., BO + ours EL, vs. ours CBO + GP, vs. ours CBO + ours EL.

% % impact of different datasets?

% \begin{figure*}[!t] % cannot have space
% \captionsetup{justification=centering}
%   \begin{minipage}[t]{0.33\textwidth}
% 	\centering
% 	\includegraphics[width=2.3in]{fig/gap_reduction.pdf}
% 	\vspace{-0.1in} \caption{\small Performance of discrepancy reduction.}
% 	\label{fig:gap_reduction}
%   \end{minipage}
%   \begin{minipage}[t]{0.33\textwidth}
% 	\centering
% 	\includegraphics[width=2.3in]{fig/cumulative_cost.pdf}
% 	\vspace{-0.1in} \caption{\small Performance of cumulative cost.}
% 	\label{fig:cumulative_cost}
%   \end{minipage}
%   \begin{minipage}[t]{0.33\textwidth}
% 	\centering
% 	\includegraphics[width=2.3in]{fig/cost_efficiency.pdf}
% 	\vspace{-0.1in} \caption{\small Performance of cost efficiency.}
% 	\label{fig:cost_efficiency}
%   \end{minipage}
% \end{figure*}


% \begin{figure*}[!t] % cannot have space
% \captionsetup{justification=centering}
%   \begin{minipage}[t]{0.49\textwidth}
% 	\centering
% 	\includegraphics[width=2.2in]{fig/gap_remaining_gap.pdf}
%     \caption{\small Discrepancy reduction under different user traffic.}
% 	\label{fig:gap_remaining_gap}
%   \end{minipage}
%   \begin{minipage}[t]{0.49\textwidth}
% 	\centering
% 	\includegraphics[width=2.2in]{fig/Discrepancy_reduction.pdf}
%    \caption{\small Discrepancy reduction under different states.}
% 	\label{fig:Discrepancy_reduction}
%   \end{minipage}
% \end{figure*}

% In the performance evaluation, we compare our proposed algorithm with the following methods:
% \begin{itemize}
%     \item \textbf{Baseline}: The \emph{Baseline} randomly selects states to query the real-world network, and use linear regression to bridge the sim-to-real discrepancy.
%     \item \textbf{Grid Search (GS)}: The \emph{GS} relies on grid search to select states to query the real-world network, and use Gaussian process to bridge the sim-to-real discrepancy.
%     \item \textbf{L2B-Lite}: The \emph{L2B-Lite} is the simplified version of our proposed L2B algorithm, while it is unaware of the cost of different states during the system querying stage. 
% \end{itemize}


% Fig.~\ref{fig:gap_reduction} shows the performance of different methods for bridging the sim-to-real discrepancy. 
% Here, we show the original sim-to-real discrepancy, which is calculated by averaging the sim-to-real discrepancy of all states in the database.
% It can be seen that, all methods can gradually reduce the sim-to-real discrepancy as the number of queried states accumulate.
% This is because, more queried states would help to continuously improve the accuracy of approximating the discrepancy.
% In particular, our proposed learn-to-bridge algorithm achieves the fastest reduction of the discrepancy, where the sim-to-real discrepancy is reduced by nearly 90\% with only 500 queried states.
% Note that, the achieved sim-to-real discrepancy between our algorithms and \emph{GS} method are almost the same, when all the states in the database are queried.
% This can be attribute to the limited size of the database, where Gaussian process can achieve similar approximation accuracy of the sim-to-real discrepancy with BNN.
% In large-scale operating network, we expect that the Gaussian process could be insufficient to tackle the high-dim state space.


% Fig.~\ref{fig:cumulative_cost} shows the accumulation of the querying cost versus the number of queried states.
% It can be seen that, our proposed learn-to-bridge algorithm achieves the lowest accumulated querying costs, which is almost 40\% less than all other methods after 500 states are queried.
% Note that, all other methods (including \emph{L2B-Lite}) are unaware of the querying cost when they select the states, hence we observe the accumulated cost grows linearly. 
% In particular, we show the cost efficiency of all methods in Fig.~\ref{fig:cost_efficiency}, which is defined as the ratio between the reduced sim-to-real discrepancy and the accumulated querying cost.
% We can see that, our proposed learn-to-bridge algorithm substantially outperforms all other methods (e.g., more than 10x than the \emph{GS} method) before 1000 queried states, which verifies its cost-efficiency in bridging the sim-to-real discrepancy.
% After 1500 queried states, the cost-efficiency of all methods are similar.
% This is because, the remaining state space keeps shrinking as more states are queried and thus unavailable to be selected at the system querying stage. 
% As a result, the learn-to-bridge algorithm has to select these cost inefficient states from the ever-decreasing state space.
% % alteration in cumulative cost with an increase in the number of querying systems and simulator samples. As evident from the figure, our method exhibits remarkable performance in selecting samples with minimal cost. Conversely, the cumulative cost among the other three methods remains predominantly consistent. Given that all four methods ultimately encompass the entire sample set, the overall cost after querying 2500 samples remains identical.


% % Fig.~\ref{fig:cost_efficiency} shows  the cost efficiency performance of four distinct methods. Cost efficiency pertains to the decrease in unit cost for each method when compared to the initial gap. Our algorithm attains an average cost efficiency of 31.1\%, outshining other algorithms whose efficiencies stand at 12.87\% (GS-GP), 20.0\% (BO-BNN), and 15.6\% (RS-LR). To sum up, our algorithm exhibits the most superior cost efficiency performance.


% Next, we show the achieved performance of the learn-to-bridge algorithm in terms of reducing the sim-to-real discrepancy under different states.
% Fig.~\ref{fig:gap_remaining_gap} shows the discrepancy between sim-to-real and DNT-to-reality under different user traffic. 
% It can be seen that, our proposed DNT has a minimal discrepancy with the real-world network across all different user traffic scenarios.
% Besides, our proposed DNT reduces the discrepancy between simulation and reality by 93.1\%, 95.1\%, 94.0\%, and 91.2\% for 1, 2, 3, and 4 users, respectively.
% Fig.~\ref{fig:Discrepancy_reduction} shows the reduction of the sim-to-real discrepancy under different uplink and downlink bandwidth allocation. 
% We observe that, the sim-to-real discrepancy is reduced on average of 93.3\%, where at least 92.1\% reduction can be achieved.
% From this result, we also justify that the sim-to-real discrepancy is state-dependent, rather than uniform.
% Note that, the sim-to-real discrepancy cannot be completely reduced due to the various abstraction of network simulators and unobservable variabilities in real-world networks.

% % \begin{figure}[!t]
% % 	\centering
% % 	\includegraphics[width=3.0in]{fig/cost_comparison.pdf}
% % 	\vspace{-0.07in} \caption{\small Cost comparison.}
% % 	\label{fig:cost_comparison}
% % \end{figure}

% % Fig.~\ref{fig:cost_comparison} depicts the total cost of the selected state in each iteration under different cost functions. We compare our algorithm with two scenarios: one where all state costs are the same and another where the state cost is unknown. In this paper, we employ cost-aware Bayesian optimization to select 16 states $\mathcal{S}$ that adhere to the constraint function in Equation. \ref{constrain} during each iteration to train our algorithm. The figure clearly demonstrates that the total cost of the state selected by our DNT in the initial eight iterations is the lowest. As the iterations progress, $\mathcal{S}$ with lower cost is favored, leading to a gradual increase in the total cost of the green line.

% % \begin{figure}[!t]
% % 	\centering
% % 	\includegraphics[width=3.0in]{fig/different_batch_remaining_gap.pdf}
% % 	\vspace{-0.07in} \caption{\small Gap reduction.}
% % 	\label{fig:different_batch_remaining_gap}
% % \end{figure}

% % \begin{figure}[!t]
% % 	\centering
% % 	\includegraphics[width=3.0in]{fig/different_batch_Cumulative_Cost.pdf}
% % 	\vspace{-0.07in} \caption{\small Cumulative Cost.}
% % 	\label{fig:different_batch_Cumulative_Cost}
% % \end{figure}



\section{Related work}

\textbf{Resource Management in Network Slicing.} A primary challenge in network slicing is the efficient allocation of resources to support heterogeneous user services. Leconte et. al. \cite{leconte2018resource} proposed a framework for fine-grained slice configuration in terms of network bandwidth and cloud processing. Their approach considers traffic fairness and computational fairness, utilizing an alternating direction method of multipliers (ADMM)-based iterative algorithm, which is proven to converge to optimal resource allocation. Fossati et. al. \cite{fossati2020multi} investigated the fair sharing among slices under insufficient resources scenarios. They proposed an optimization framework based on the ordered weighted average (OWA) operator to ensure fairness in both single-resource and multi-resource allocation problems. The O-RAN \cite{polese2023understanding} advocates for an open network structure and promotes the use of open RAN interfaces to interconnect components with a RAN intelligent controller (RIC) for managing and controlling resources. The OnSlicing \cite{liu2021onslicing} proposed an online end-to-end network slicing system based on the O-RAN. This system aimed to minimize resource usage while avoiding violations of slice SLAs and infrastructure resource capacity. By leveraging domain managers, it achieved subsecond-level control for resource allocation. However, existing work often overlooks the cost of resources. In contrast, our work approaches the problem from the perspective of MNOs, focusing on minimizing operation costs while ensuring SLA compliance for slice users. 

\textbf{AI/ML for Networking.} AI/ML techniques have emerged as powerful tools for network orchestration due to the complex nature of network environments and intricate interactions between multiple network components. It provides adaptive and data-driven solutions that can accommodate these variations. DeepSlicing \cite{liu2020deepslicing} proposed an efficient resource allocation framework that decomposes the optimization problem into multiple sub-problems. Their approaches combine convex optimization for the master problem and deep deterministic policy gradient (DDPG) agents for slave problems, aiming to maximize utility functions. Li et. al. \cite{li2018deep} explored two typical demand-aware slice configuration scenarios, wireless resource slicing and priority-based core network slicing. Compared to demand-prediction-based approaches, their DRL framework could implicitly capture deeper relationships between demand and supply, improving the effectiveness and flexibility of network slicing. Atlas \cite{liu2022atlas} proposed an online network slicing system that leverages Bayesian optimization to reduce the sim-to-real discrepancy. Using Gaussian process regression, the system learns real-world policies online, enhancing the performance of network slicing strategies. 
However, existing solutions are mostly based on DNN-based model representations, which lack transparency and interpretability, and thus constrain their practical deployment in real-world networks.







\section{Conclusion}
In this paper, we presented a new interpretable network slice configuration algorithm in open radio access networks, by integrating Kolmogorov-Arnold Networks (KANs) and hybrid optimization process.
On the one hand, we use KANs to approximate and learn the unknown performance
function of individual slices, which converts the blackbox optimization problem. On the other hand, the genetic method embedded with trust region is used to solve the converted problem.
With the extensive evaluation, we show that our proposed algorithm achieves high interpretability while reducing 25+\% operation cost than existing solutions.
We believe this work provides a new perspective of slice configuration, by considering the solution interpretability beyond the solution performance only.

% \section*{Acknowledgement}
% This work is supported by the US National Science Foundation under Grant No. 2321699.


\bibliographystyle{IEEEtran}
% argument is your BibTeX string definitions and bibliography database(s)
\bibliography{ref/reference}

\end{document}

â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢