\section{Conclusion}
In this work, we represent RLEdit, a hypernetwork-based editing method designed for lifelong editing. RLEdit formulates lifelong editing as an RL task, employing an offline update approach to enhance the model's retention of entire knowledge sequences. Additionally, RLEdit proposes the use of memory backtracking to review previously edited knowledge and applies regularization to mitigate knowledge forgetting over long sequences. Through extensive testing on several LLMs across multiple datasets, our experimental results demonstrate that RLEdit significantly outperforms existing baseline methods in lifelong editing tasks, showing superior performance in editing effectiveness, editing efficiency, and general capability preservation.