\section{Convergence Analysis}

We first present the assumptions under which we prove \celora's convergence properties. 

\begin{assumption}[Lower Boundedness]\label{asp:proper}
    The loss function $f:\mathbb{R}^{d}\rightarrow\mathbb{R}$ satisfies $\inf_{\mathbf{x}\in\mathbb{R}^d}f(\mathbf{x})>-\infty$.
\end{assumption}
\begin{assumption}[$L$-Smoothness]\label{asp:smoothness}
    The loss function $f$ is $L$-smooth, \ie, it holds for any $\mathbf{x},\mathbf{y}\in\mathbb{R}^{d}$ that
    \begin{align*}
        \|\nabla f(\mathbf{x})-\nabla f(\mathbf{y})\|_2\le L\|\mathbf{x}-\mathbf{y}\|_2.
    \end{align*}
\end{assumption}
\begin{assumption}[Stochastic Gradient]\label{asp:stochastic}
    We assume the stochastic gradient oracle satisfies
    \begin{align}
        &\mathbb{E}[\nabla F(\mathbf{x}^t;\xi^t)]=\nabla f(\mathbf{x}^t);\\
        &\mathbb{E}[\|\nabla F(\mathbf{x}^t;\xi^t)-\nabla f(\mathbf{x}^t)\|^2]\le\sigma^2,
    \end{align}
    for some $\sigma>0$.
\end{assumption}

Assumptions \ref{asp:proper}-\ref{asp:stochastic} are standard assumptions commonly used in stochastic optimization. 

\begin{assumption}[Gradient Error]\label{asp:contractive}
    Let $\mathbf{g}^t$ and $\hat{\mathbf{g}}^t$ denote the original stochastic gradient $\nabla F(\mathbf{x}^t,\xi^t)$ and its estimation by \celora, it holds that
    \begin{align}
        \|\hat{\mathbf{g}}^t-\mathbf{g}^t\|^2\le(1-\delta)\|\mathbf{g}^t\|^2,\label{eq:asp-cgk}
    \end{align}
    and 
    \begin{align}
        \|\mathbb{E}_{\xi^t\sim\mathcal{D}}[\hat{\mathbf{g}}^t]-\nabla f(\mathbf{x}^t)\|^2\le(1-\delta)\|\nabla f(\mathbf{x}^t)\|^2,\label{eq:asp-ecgk}
    \end{align}
    for some $\delta\in(0,1].$
\end{assumption}

Assumption \ref{asp:contractive} illustrates the property of stochastic gradients in \celora. Though not standard, this assumption can be empirically justified by our experimental results.

\textbf{Empirical Justification of Assumption \ref{asp:contractive}.} To justify \eqref{eq:asp-cgk}, we conduct experiments on language model fine-tuning tasks on google/gemma-2b~\cite{gemmamodelcard} model using CoLA~\cite{warstadt-etal-2019-neural}, RTE and MRPC~\cite{dolan-brockett-2005-automatically} datasets, three tasks in the GLUE benchmark~\cite{wang2019gluemultitaskbenchmarkanalysis}. In these experiments, we use AdamW with a learning rate of \texttt{1e-5} to train for 1 epoch per task and calculate the relative error $\|\hat{\mathbf{g}}^t-\mathbf{g}^t\|^2/\|\mathbf{g}^t\|^2$ every 10 steps, as illustrated in Figure~\ref{fig:cgk}, where all relative errors are below 0.9. To justify \eqref{eq:asp-ecgk}, we conduct experiments on the same model and datasets, where we alternatively calculate one iteration of full gradient AdamW and one epoch of random gradient AdamW, each with a learning rate of \texttt{1e-5} for a total of 80 cycles. We apply a rank of 64 for both LoRA and double-LoRA in \celora, and apply a structured sparsity of $p_{\mathrm{FFN}}=0.9$ and $p_{\mathrm{MHA}}=0.4$. We calculate the relative error $\|\mathbb{E}_{\xi^t\sim\mathcal{D}}[\hat{\mathbf{g}}^t]-\nabla f(\mathbf{x}^t)\|^2/\|\nabla f(\mathbf{x}^t)\|^2$ for every full-gradient step, as illustrated in Figure~\ref{fig:ecgk}, where all relative errors are below 0.9. 


\begin{figure*}[ht]
    \centering
    % \begin{minipage}{\textwidth}
        \includegraphics[width=\textwidth]{figures/histogram_delta.pdf}
    % \end{minipage}
    \vspace{-4mm}
    \caption{Empirical validation of \eqref{eq:asp-cgk} on MRPC (left), RTE (middle) and CoLA (right).}
    \label{fig:cgk}
\end{figure*}

\begin{figure*}[ht]
    \centering
    % \begin{minipage}{\textwidth}
        \includegraphics[width=\textwidth]{figures/histogram_delta_fullgrad.pdf}
    % \end{minipage}
    \vspace{-4mm}
    \caption{Empirical validation of \eqref{eq:asp-ecgk} on MRPC (left), RTE (middle) and CoLA (right).}
    \label{fig:ecgk}
    % \vspace{-1em}
\end{figure*}

% where all observed $\hat{g}^k$ satisfy \eqref{eq:asp-cgk} and $\mathbb{E}_{\xi^k\sim\mathcal{D}}[\hat{g}^k]$ satisfy \eqref{eq:asp-ecgk}, for some $\delta\in(0,1]$.

We now propose the convergence results of \celora using  the momentum SGD optimizer with the following update:
\begin{align*}
\mathbf{m}^t=&\ (1-\beta_1)\mathbf{m}^{t-1}+\beta_1\hat{\mathbf{g}}^t,\\
\mathbf{x}^{t+1}=&\ \mathbf{x}^t-\eta \mathbf{m}^t,
\end{align*}
\begin{theorem}\label{thm:celora}
    Under Assumptions \ref{asp:proper} - \ref{asp:contractive}, if $\beta_1\in\left(0,\frac{\delta}{24-12\delta}\right)$ and $\eta\le\min\left\{\frac{L}{2}, \frac{\beta_1}{L}\cdot\sqrt{\frac{\delta}{8}}\right\}$, \celora with momentum SGD converges as
    \begin{align*}
        % &\frac{1}{T+1}\sum_{t=0}^T\mathbb{E}[\|\nabla f(\mathbf{x}^t)\|_2^2]\nonumber\\
        % \le&\frac{4[f(\mathbf{x}^0)-\inf_{\mathbf{x}}f(\mathbf{x})]}{\delta\eta(T+1)}+\frac{4\|\mathbf{m}^0-\nabla f(\mathbf{x}^0)\|_2^2]}{\delta\beta_1(T+1)}+\frac{12\beta_1\sigma^2}{\delta}.
        &\frac{1}{T+1}\sum_{t=0}^T\mathbb{E}[\|\nabla f(\mathbf{x}^t)\|_2^2]
        \le\frac{4[f(\mathbf{x}^0)-\inf_{\mathbf{x}}f(\mathbf{x})]}{\delta\eta(T+1)}+\frac{4\|\mathbf{m}^0-\nabla f(\mathbf{x}^0)\|_2^2]}{\delta\beta_1(T+1)}+\frac{12\beta_1\sigma^2}{\delta}. \nonumber
    \end{align*}
\end{theorem}
% \begin{proof}
%     By Assumption \ref{asp:smoothness}, we have
%     \begin{align}
%         &f(x^{k+1})-f(x^k)\nonumber\\
%         \le&\langle\nabla f(x^k),x^{k+1}-x^k\rangle+\frac{L}{2}\|x^{k+1}-x^k\|_2^2\nonumber\\
%         =&\left\langle\frac{m^k}{2},x^{k+1}-x^k\right\rangle+\left\langle\nabla f(x^k)-\frac{m^k}{2},x^{k+1}-x^k\right\rangle\nonumber\\
%         &+\frac{L}{2}\|x^{k+1}-x^k\|_2^2\nonumber\\
%         =&-\left(\frac{1}{2\eta}-\frac{L}{2}\right)\|x^{k+1}-x^k\|_2^2+\frac{\eta}{2}\|\nabla f(x^k)-m^k\|_2^2\nonumber\\
%         &-\frac{\eta}{2}\|\nabla f(x^k)\|_2^2.\label{eq:pfthm-1}
%     \end{align}
%     Taking expectation and summing \eqref{eq:pfthm-1} for $k=0,1,\cdots,K$ yields
%     \begin{align}
%         &\inf_{x}f(x)-f(x^0)\nonumber\\
%         \le&\frac{\eta}{2}\sum_{k=0}^{K}\mathbb{E}[\|\nabla f(x^k)-m^k\|_2^2]\nonumber\\
%         &-\left(\frac{1}{2\eta}-\frac{L}{2}\right)\sum_{k=0}^{K}\mathbb{E}[\|x^{k+1}-x^k\|_2^2]\nonumber\\
%         &-\frac{\eta}{2}\sum_{k=0}^K\mathbb{E}[\|\nabla f(x^k)\|_2^2].\label{eq:pfthm-2}
%     \end{align}
%     Applying Lemma \ref{lm:m} to \eqref{eq:pfthm-2} and noting that $\beta_1\in(0,\delta/(24-12\delta))$ implies $(1-\delta/2)(1+6\beta_1)\le1-\delta/4$, we obtain
%     \begin{align}
%         &\frac{1}{K+1}\sum_{k=0}^K\mathbb{E}[\|\nabla f(x^k)\|_2^2]\nonumber\\
%         \le&\frac{4[f(x^0)-\inf_xf(x)]}{\delta\eta(K+1)}+\frac{4\|m^0-\nabla f(x^0)\|_2^2}{\delta\beta_1(K+1)}+\frac{12\beta_1\sigma^2}{\delta}\nonumber\\
%         &-\frac{4}{\delta\eta}\left(\frac{1}{2\eta}-\frac{L}{2}-\frac{2\eta L^2}{\delta\beta_1^2}\right)\sum_{k=0}^K\|x^{k+1}-x^k\|_2^2.\label{eq:pfthm-3}
%     \end{align}
%    Since $\eta\le\min\{1/2L,\sqrt{(\delta\beta_1^2)/(8L^2)}\}$ implies $1/(4\eta)\ge L/2$ and $1/(4\eta)\ge(2\eta L^2)/(\delta\beta_1^2)$, \eqref{eq:thm} is a direct result of \eqref{eq:pfthm-3}.
% \end{proof}
\begin{corollary}
    Under Assumptions \ref{asp:proper}-\ref{asp:contractive}, if we choose $\beta_1=\left(\frac{24}{\delta}+\sigma\sqrt{\frac{\delta^{1/2}\left(T+1\right)}{L\Delta}}\right)^{-1}$, $\eta=\left(2L+ \frac{2^{3/2}L}{\delta^{1/2}\beta_1}\right)^{-1}$, \celora with momentum SGD converges as
    \begin{align}
        &\frac{1}{T+1}\sum_{t=0}^{T}\mathbb{E}[\|\nabla f(\mathbf{x}^t)\|_2^2]
        =\mathcal{O}\left(\frac{L\Delta}{\delta^{5/2}(T+1)}+\sqrt{\frac{L\Delta\sigma^2}{\delta^{5/2}(T+1)}}\right),\nonumber
    \end{align}
    where $\Delta:=f(\mathbf{x}^0)-\inf_{\mathbf{x}}f(\mathbf{x})+(\delta/L)\cdot\|\mathbf{m}^0-\nabla f(\mathbf{x}^0)\|_2^2$.
\end{corollary}

Detailed proofs are deferred to Appendix \ref{app:proof}.