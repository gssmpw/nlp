\begin{algorithm}[t]
\caption{\celora}\label{alg:CeLoRA}
\footnotesize
\begin{algorithmic}[1]

\Statex{\textbf{Input:} Frozen layer weight $\mathbf{W}_{\ell}\in\mathbb{R}^{m_{\ell}\times n_{\ell}}$, sparsity level $p_\ell$, double-LoRA rank $r_{0,\ell}$, indices recomputing period $\tau$, Top-K indices $\mathcal{I}_\ell=$ empty, optimizer $\rho$.
% learning rate $\eta$, AdamW hyperparameters $\beta_1,\beta_2$, momentum $\mathbf{m}_\ell=\mathbf{0}$, $\mathbf{v}_\ell=\mathbf{0}$, $\ell=1,2,\cdots,L$.
}

% \vspace{1mm}
\Statex\rule{\linewidth}{0.4pt}
\Statex \textbf{Initialize Double-LoRA}
    \State \quad \textbf{for} Layer $\ell=1,2,\cdots,L$ \textbf{do}
    \State \qquad Conducting SVD on frozen weight matrix
    \Statex \qquad $\mathbf{W}_{0,\ell}=\mathbf{U}_\ell\mathbf{\Sigma}_\ell \mathbf{V}_\ell^\top$;
    \State \qquad $\mathbf{A}_{0,\ell},\ \mathbf{B}_{0,\ell} \gets \sqrt{\mathbf{\Sigma}_\ell}{\mathbf{V}_\ell^\top}_{[:r_0,]},\ {\mathbf{U}_{\ell}}_{[,:r_0]}\sqrt{\mathbf{\Sigma}_\ell}$ ;\Comment{Stored in layer's buffer.}
    \State \quad \textbf{end for}
\Statex \rule{\linewidth}{0.4pt}

\State \textbf{for} {\textbf{\celora Training Step $t=0,1,\cdots,T-1$}} \textbf{do}
% \For{$t=0,1,\cdots,T-1$}
\vspace{0.5mm}
    \State \quad \textbf{for} Layer $\ell=1,2,\cdots,L$ \textbf{do}\Comment{\textbf{Forward}}
        \State \quad\quad $\mathbf{z}_\ell\gets\mathbf{A}_\ell\mathbf{x}_\ell$;
        \State \quad\quad $\mathbf{y}_\ell \gets \mathbf{W}_{0,\ell}\mathbf{x}_\ell+\mathbf{B}_\ell\mathbf{z}_\ell$;
        % \State \quad\quad  \textbf{Return} $\mathbf{y}_\ell$
    \State\quad\textbf{end for}
\vspace{0.5mm}
    \State \quad \textbf{for} Layer $\ell=L,L-1,\cdots,1$ \textbf{do}\Comment{\textbf{Backward}}
        \State \quad\quad  $\mathbf{W}_{s,\ell} \gets \mathbf{W}_{0,\ell} - \mathbf{B}_{0,\ell}\mathbf{A}_{0,\ell}$;
        \State \quad\quad \textbf{if} {$\tau\mid t$ \textbf{or} $\mathcal{I}_\ell$ is empty} \textbf{then}
            
            \State \quad\qquad $\alpha_{i,\ell} \gets\left\|{\mathbf{W}_{s,\ell}^\top}_{[:,i]} {\mathbf{G_{y_\ell}}}_{[i,:]}\right\|_F$, \ $\forall i \in \left\{1,\dots,m_\ell\right\}$
            \State \quad\qquad {Select $\left\{i_{1,\ell},\cdots,i_{\text{K}_\ell,\ell}\right\}$ with largest $\alpha_{i,\ell}$'s;}
            
            \State \quad\qquad $\mathcal{I}_\ell = \left\{i_{1,\ell},\cdots,i_{\text{K}_\ell,\ell}\right\}$; \Comment{Here K$_\ell= \lceil m_\ell p_\ell \rceil$}
        \State \quad\quad\textbf{end if}
        \State \quad\quad $\mathbf{G}_{\mathbf{B}_\ell}\gets\mathbf{G}_{\mathbf{y}_\ell}\mathbf{z}_\ell^\top$;
        \State \quad\quad $\mathbf{G}_{\mathbf{z}_\ell}\gets\mathbf{B}_{\ell}^\top\mathbf{G}_{\mathbf{y}_{\ell}}$;
        \State \quad\quad
        $\mathbf{G}_{\mathbf{A}_\ell}\gets\mathbf{G}_{\mathbf{z}_\ell}\mathbf{x}_\ell^\top$;
        \State \quad\quad $\mathbf{G}_{\mathbf{x}_\ell} \gets {\mathbf{W}_{s,\ell}^\top}_{[,\mathcal{I}]} {\mathbf{G}_{\mathbf{y}_\ell}}_{[\mathcal{I},]} + \mathbf{A}_{0,\ell}^\top(\mathbf{B}_{0,\ell}^\top \mathbf{G}_{\mathbf{y}_\ell})+\mathbf{A}_\ell^\top\mathbf{G}_{\mathbf{z}_\ell}$;
        % \State \quad  \textbf{Return} $\mathbf{G_x}$
\State\quad\textbf{end for}
\State Use optimizer $\rho$ to update $\{\mathbf{A}_\ell,\mathbf{B}_\ell\}_{\ell=1}^L$ according to $\{\mathbf{G}_{\mathbf{A}_\ell},\mathbf{G}_{\mathbf{B}_\ell}\}_{\ell=1}^L$;
\State\textbf{end for}
\end{algorithmic}
\end{algorithm}




% \begin{algorithm}[t]
% \caption{\celora}\label{alg:CeLoRA}
% \footnotesize
% \begin{algorithmic}[1]

% \Statex{\textbf{Input:} Frozen layer weight $W\in\mathbb{R}^{m\times n}$, sparsity level $p$, double-LoRA rank $r_0$, indices recomputing period $\tau$, Top-K indices $\mathcal{I}=$ empty.
% }

% \vspace{1mm}
% \Statex \textbf{Initialize Double-LoRA rank}
%     \State \quad Conducting SVD on frozen weight matrix $W_0=U\Sigma V^\top$
%     \State \quad $A_0,\ B_0 \gets \sqrt{\Sigma}V^\top_{[:r_0,]},\ U_{[,:r_0]}\sqrt{\Sigma}$ \Comment{Stored in layer's buffer.}

% \Statex \rule{\linewidth}{0.4pt}

% \Statex \textbf{\celora Training Step $t$}
% % \For{$t=0,1,\cdots,T-1$}
% \vspace{0.5mm}
%     \Statex{\textbf{Forward}$\left(\mathbf{x}\right)$:}
%         \State \quad $\mathbf{y} = \mathbf{W}_0\mathbf{x}$
%         \State \quad  \textbf{Return} $\mathbf{y}$

% \vspace{0.5mm}

%     \Statex{\textbf{Backward} $\left(\mathbf{G}_\mathbf{y}\right)$:}
%         \State \quad  $\mathbf{W}_s = \mathbf{W}_0 - \mathbf{B}_0\mathbf{A}_0$
%         \State \quad \textbf{if} {$\tau\mid t$ \textbf{or} $\mathcal{I}$ is empty} \textbf{then}
            
%             \State \quad\quad $\alpha_i = {\mathbf{W}_s^\top}_{[:,i]} {\mathbf{G_y}}_{[i,:]}$, \ $\forall i \in \left\{1,\dots,m\right\}$
%             \State \quad\quad {Select the K largest indices $\left\{i_1,\cdots,i_\text{K}\right\}$ by $\Vert \alpha_i \Vert_F$}
            
%             \State \quad\quad $\mathcal{I} = \left\{i_1,\cdots,i_\text{K}\right\}$ \Comment{Here K $= \lceil mp \rceil$}


%         \State \quad $\mathbf{G_x} = {\mathbf{W}_s^\top}_{[,\mathcal{I}]} {\mathbf{G_y}}_{[\mathcal{I},]} + \mathbf{A}_0^\top(\mathbf{B}_0^\top \mathbf{G_y})$
%         \State \quad  \textbf{Return} $\mathbf{G_x}$
% % \EndFor
% \end{algorithmic}
% \end{algorithm}
