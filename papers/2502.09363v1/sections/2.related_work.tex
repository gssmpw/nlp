\section{Related Work}

This work introduces a framework for characterizing segmentation label noise in FIX weak labeling, a largely unexplored area. Below, we review studies addressing noisy labels and approaches to mitigate their effects, with a focus on weak labeling in audio and related domains.

\subsection{Understanding Noisy Labels}

Noisy labels are a partial description of the target model, influencing its performance. Early work by \citet{Liang2009} introduced the concept of \textit{measurements} for conditional exponential families, encompassing labels and constraints for model learning with minimal human inputâ€”a goal shared by this work.

In deep learning, the ability of models to overfit noisy labels has prompted studies into the relationship between noise rate and generalization~\citep{Zhang2021, Chen2019}. Research on class label noise often assumes a noise transition matrix~\citep{Li2021} but rarely considers spatially correlated errors like those arising in segmentation tasks~\citep{Yao2023}. For audio, \citet{Hershey2021} demonstrated that training on strongly labeled data yields better results than weakly labeled data, highlighting the need for precise labels, particularly in evaluation.

\subsection{Mitigating Noisy Labels}

Several strategies address noisy labels, including regularization techniques like dropout~\citep{Srivastava2014}, data augmentation~\citep{Shorten2019}, and specialized loss functions~\citep{Fonseca2019_agnostic}. For weakly labeled audio, \citet{Dinkel2022} proposed a pseudo-labeling approach, iteratively refining labels to improve training performance. Despite these advances, most methods focus on training labels and offer limited insights into noisy evaluation labels, underscoring the need for frameworks that quantify label noise, such as the one proposed in this work.

\subsection{Strong vs. Weak Labeling}

Strong labeling, where the annotator provides the event boundaries and the class label, while often precise, is resource-intensive and subject to annotator variability~\citep{Mesaros2017}. In bioacoustics, experts use spectrograms for efficient annotation~\citep{Cartwright2017}, but the reliance on specialists limits scalability. Weak labeling, by contrast, simplifies the annotation task, which is especially important for crowd-sourced annotations, enabling broader data collection~\citep{Martin-Morato2023a}. However, segment label noise, especially at event boundaries, remains a significant challenge.

Large-scale audio datasets employing FIX weak labeling are summarized in Table~\ref{tab:fix_datasets}. Two common annotation tasks are single-pass multi-label and multi-pass binary-label annotation~\citep{Cartwright2019}. Single-pass multi-label annotation asks annotators to recognize the presence of multiple event classes during a single pass through the data. In contrast, multi-pass binary-label annotation asks annotators to detect the presence or absence of a single event class at a time through multiple passes through the data.

\citet{Cartwright2019} studied the trade-offs between these tasks and found that binary labeling is preferable when high recall is required. For example, AudioSet~\citep{Gemmeke2017} employs single-pass multi-label annotation with non-overlapping $10$-second segments, which limits temporal resolution. Conversely, MAESTRO Real~\citep{Martin-Morato2023a} uses overlapping $10$-second segments with a $9$-second overlap, increasing the accuracy of the derived labels.

\begin{table}[t]
    \centering
    \begin{tabular}{l c c}
         Dataset                  & Task                & Fixed Length \\
         \hline
         CHIME~\citep{Foster2015}     & Single-pass multi-label & $4$ seconds \\
         AudioSet~\citep{Gemmeke2017} & Single-pass multi-label & $10$ seconds \\
         MAESTRO Real~\citep{Martin-Morato2023a} & Single-pass multi-label & $10$ seconds \\
         OpenMIC-2018~\citep{Humphrey2018} & Multi-pass binary-label & $10$ seconds \\
    \end{tabular}
    \caption{Large-scale audio datasets using variations of FIX weak labeling.}
    \label{tab:fix_datasets}
\end{table}

The choice of segment length and overlap significantly impacts the utility of weak labeling. For example, while overlapping segments increase label accuracy~\citep{Martin-Morato2023a}, they still fail to distinguish events occurring close in time. Current work aims to better understand the effect of different choices of the segment length for FIX weak labeling.


\subsection{Contributions of This Work}

Existing research focuses predominantly on class label noise or assumes noise independence. This work extends these efforts by characterizing segment label noise specific to FIX weak labeling, providing a foundation for improving both training and evaluation processes in weakly labeled datasets.
