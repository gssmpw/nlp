
\section{Representing Structures with Holoplanes}
\label{sec:holoplane}
The Holoplane representation consists of feature maps that encode both the geometric shape and physical properties of the microstructure within a symmetry-preserving, physics-aware autoencoder.

To obtain the holoplane representation $\holo$, we project $\phi_\Omega(\bx)$ onto a set of planes that correspond to the symmetry group of the microstructure. 
The projection is defined as:
\begin{equation}
    \holo_k=\mathcal{E}(\phi_\Omega;\theta,k), 
\end{equation}
where $\mathcal{E}$ is a neural encoder that maps the SDF onto the $k$-th symmetry plane of microstructure. 
The number of planes used depends on the symmetry of the structure. 

During decoding, the Holoplane representation is used to reconstruct a neural field $\mathcal{D}(\bx)$ at any given point. 
The coordinates $\bx$ are first projected onto the symmetry planes, and the corresponding features are then sampled and processed by a decoder:
\begin{equation}
\label{eq:decode}
    \mathcal{D}(\holo, \bx) = f_{\text{decode}}(\holo_1(\bu_1(\bx)) + ... + \holo_k(\bu_k(\bx)); \theta),
\end{equation}
where $\bu(\bx)$ represents the coordinate projected onto the plane, $\holo(\bu)$ represents the sample from the plane, and $f_\text{decode}$ is a lightweight multilayer perceptron (MLP) that combines the features from all the planes.

\subsection{Hybrid Symmetry-aware Representation}
\label{sec:sym_enc}
A symmetry plane is defined as one where the SDF values of points reflected across the plane are identical. 
Specifically, for a plane defined by the equation $ax+by+cz+d=0$, the SDF satisfies $\phi_\Omega(\bx)=\phi_\Omega(\bx')$, where $\bx'$ is the reflection of $\bx$.
Neural networks are employed to perform encoding along the symmetry plane's normal direction $\bn = (a, b, c)$.
During decoding, $\bu$ in Eq.\ref{eq:decode} is represented as $\bu=\bx-2(\bx\cdot\bn)\bn$.

The SDF is discretized as voxel data and fed into the encoder $\mathcal{E}$.
The decoder generates an SDF $\mathcal{D}\phi$, which is compared against the ground truth through the reconstruction loss:
\begin{equation}
\label{eq:rec}
    \mathcal{L}_{\phi}=\sum_{\bx}{\left|\left|\phi_\Omega(\bx) - \mathcal{D}_\phi(\holo_{\Omega}, \bx)\right|\right|}^2.
\end{equation}
The loss is minimized by sampling random points within the SDF (Sec.~\ref{sec:network_imp}), ensuring accurate reconstruction of the implicit field.

\begin{figure}[tb]
    \includegraphics[width=\linewidth]{figures_new/distribution.jpg}
    \caption{We visualize the latent space with and without physical priors using t-SNE. The color represents Young's moduli.
    Without physical priors, close data points exhibit significant property discrepancies (a).
    This disordered latent space (b) hinders the Diffusion model's ability to condition effectively.
    Incorporating physical priors improves this distribution significantly (c).
    We further conducted ablation experiments to compare the results of using the generative model in space (b) and (c) (Sec.\ref{sec:accuracy}).}
	\label{fig:distribution}
\end{figure}

\subsection{Physics-aware Neural Embedding}
\label{sec:phy_enc}
We enhance the Holoplane's ability to align with physical properties by integrating physical priors. 
Mapping diverse families of microstructure data to their corresponding physical properties poses a significant challenge, as a simple MLP~\cite{Zheng2023} tends to overfit on our dataset.
To address this, we integrate physical equations derived from the homogenization process~\cite{andreassen2014Design, dong2018149}, enabling the construction of a smooth and interpretable latent space.

The latent space is constrained by minimizing a property loss between the ground-truth properties $\bC_\Omega$ and a solver $f_{E}(\holo_\Omega)$, which computes the elasticity tensor from the Holoplane representation. 
However, the homogenization process is computationally expensive, and a single network is incapable of capturing the complex physical relationships involved.
Consequently, neither approach is suitable as $f_{E}$. 

Instead, we leverage the displacement fields $\boldsymbol{\chi}$, introduced during the homogenization process, to bridge geometry (SDF) and physical properties in a more coherent and efficient manner.
The calculation of $\boldsymbol{\chi}$ is formulated as solving the system $\bK \boldsymbol{\chi} = \bF$ (\srefhomo), where $\mathbf{K}$ is the global stiffness matrix and $\mathbf{F}$ represents the applied load.
This step, the most computationally intensive part of the homogenization solver, is approximated using:
\begin{equation}
\label{eq:disp}
    \mathcal{L}_{\boldsymbol{\chi}}=\sum_{\bx}{\left|\left|{\boldsymbol{\chi}_{\Omega}}(\bx) - \mathcal{D}_{\boldsymbol{\chi}}(\holo_{\Omega}, \bx)\right|\right|}^2.
\end{equation}

We further leverage these two fields $\phi$ and $\boldsymbol{\chi}$ to predict the elasticity tensor by minimizing the property loss:
\begin{equation}
    \mathcal{L}_{E}={||\bC_\Omega - \sum_{\bx \in \Omega}f_{E}(\mathcal{D}_{\boldsymbol{\chi}}(\bx), \mathcal{D}_\phi(\bx); \holo_\Omega)||}^2.
\end{equation}


With the physics-aware embedding, we found that the physical properties and geometries are effectively aligned in the latent space (Fig.~\ref{fig:distribution}). 


\section{Generating Structures with Diffusion}
\label{sec:diffusion}

We define a representation of microstructures through Holoplanes, where each Holoplane serves as an encoding of the microstructure, and decoding reconstructs both the structure and its physical properties. 
A conditional diffusion model is trained to generate diverse Holoplanes, enabling the design of microstructures with specific properties.

Each Holoplane instance represents a sample from the distribution $\holo \sim p(\holo)$.
During the training phase, the diffusion process perturbs the original distribution by adding Gaussian noise $\epsilon \sim \mathcal{N}(0, \sigma \mathbf{I})$ to the original data~\cite{Ho2020DDPM}.
A neural network is trained to learn the denoising process.

Following~\cite{song2021scorebased, karras2022edm}, the diffusion process is defined as:
\begin{equation}
\label{eq:dif_sample}
    d\holo=-\dot{\sigma}(t)\sigma(t)\nabla_{\holo}\log{p(\holo;\sigma(t))}dt,
\end{equation}
where $\sigma(t)$ is the noise level at time $t \in (0, 1]$.

A neural denoiser $\Psi(\holo;\sigma, \theta)$ is trained by minimizing:
\begin{equation}
\label{eq:dif_train}
    \mathbb{E}_{\holo\sim p(\holo)}\mathbb{E}_{\mathbf{\epsilon \sim \mathcal{N}(0, \sigma \mathbf{I})}} \left|\left| \Psi(\holo + \epsilon; \sigma) - \holo\right|\right|_2^2.
\end{equation}
This denoising process can be interpreted as learning to reverse the noise perturbation, recovering the original microstructure from noisy samples. 
The gradient of the log-probability in Eq.~\ref{eq:dif_sample} is then expressed as $\nabla_{\holo}\log{p(\holo;\sigma)}=\left(\Psi(\holo; \sigma) - \holo\right) / \sigma^2$.


\subsection{Guided Generation Using Properties}
A conditional denoiser $\Psi_C$ is trained according to Eq.\ref{eq:dif_train} with $p_{data}=p(\holo | C)$, where $C$ represents the elastic tensor of microstructures.
To improve properties-conditioned generation, we incorporate Classifier-free Guidance (CFG ~\cite{ho2022classifierfree}). 
An unconditional denoiser $\Psi_{\mathbf{0}}$ is trained without properties.
During inference, CFG interpolates between the conditional and unconditional outputs to guide the sampling process:
\begin{equation}
    \Psi(\holo;\sigma, C)=\Psi_{\mathbf{0}} + w(\Psi_C - \Psi_{\mathbf{0}}),
\end{equation}
where $w$ controls the strength of the guidance. 


\subsection{Boundary Compatibility Enhancement}
\label{sec:compat}


\paragraph{Compatibility gradient}
In heterogeneous design, ensuring continuous boundaries between adjacent cells is crucial. 
To achieve this, we introduce a compatibility gradient that enforces consistent boundary shapes between two microstructures during diffusion sampling.
The compatibility loss $\mathcal{L}_{\text{compat}}$ is designed to minimize the discrepancy between the boundaries of two microstructures.
By using the Holoplane, we can more effectively compare and align the microstructures within a shared latent space. 
Therefore, the compatibility loss is formulated as:
\begin{equation}
    \mathcal{L}_{\text{compat}} = \int_{\Gamma} \| \holo_A - \holo_B \|^2 \, d\mathbf{x},
\end{equation}
where $\Gamma$ denotes the boundary area.
To maintain consistent boundary shapes throughout the sampling process, we modify the ODE (Eq.~\ref{eq:dif_sample}) as follows:
\begin{equation}
    d\holo=-\dot{\sigma}(t)\sigma(t)(\nabla_{\holo}\log{p(\holo;\sigma(t))} - \nabla_{\holo}\mathcal{L}_{\text{compat}})dt.
\end{equation}


\paragraph{Blending}
Although the compatibility gradient promotes alignment along the boundaries, minor discontinuities may still arise (Fig.~\ref{fig:blending} (b)). 
To further enhance compatibility, we adopt an interpolation-based blending approach.

First, we add noise to the two Holoplanes during the forward diffusion process, resulting in noisy representations $\holo^{\sigma}$.
Next, spherical linear interpolation (slerp) is applied between these two noisy data points using a coefficient $\alpha$:
\begin{equation}
    \holo_\alpha^{\sigma}=\text{slerp}(\holo^{\sigma}_A, \holo^{\sigma}_B; \alpha).
\end{equation}
We then perform reverse diffusion to generate an interpolated Holoplane, $\holo_{\alpha}$.

The interpolated results are then used to reconstruct the boundary region, seamlessly blending the microstructures (Fig.~\ref{fig:blending}(a)):
\begin{equation}
    \phi(\bx) = \mathcal{D}_{\phi}(\holo_{\alpha}, \bx).
\end{equation}
Specifically, for a coordinate $\bx$ located at a distance $x_0$ from the boundary of microstructure $A$ (adjacent to $B$), we compute an interpolation coefficient $\alpha = \frac{l - x_0}{2l}$, where $l$ represents the boundary width.
Interpolation-based blending ensures perfect connectivity (Fig.~\ref{fig:blending} (c)) at the boundaries, enhancing structural stability during heterogeneous design.

\begin{figure}[tb]
    \includegraphics[width=\linewidth]{figures_new/boundary_comp.jpg}
    \caption{We enhance the boundary compatibility through smooth interpolation. (a) The blended microstructure’s SDF is decoded from the corresponding positions in the interpolation sequence.
    We quantify boundary similarity using the intersection-over-union (IoU) of binarized boundary surfaces.
    (b) Using only the boundary compatibility gradient, we achieve 70.1\% boundary similarity.
    (c) Under blending, boundary compatibility reaches 100\%.}
	\label{fig:blending}
\end{figure}

