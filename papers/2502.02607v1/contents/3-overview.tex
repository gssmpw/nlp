\section{Overview}
\label{sec:overview}

\begin{figure*}[ht]
    \centering
    \includegraphics[width=\linewidth]{figures_new/pipeline.jpg}
    \caption{Pipeline of the MIND. 
    (a) We explicitly encode the microstructural symmetry in voxel space, leveraging the inherent symmetry to ensure tilability.
    (b) A combination of distance and displacement fields integrates physical priors into the implicit fields, enabling a hybrid neural representation, Holoplane.
    (c) Holoplane can be conditionally generated using a diffusion model, yielding diverse microstructural demands.
    (d) We apply this process to heterogeneous design, generating seamlessly fitting, 3D-printable structures.}
    \label{fig:pipeline}
\end{figure*}


\subsection{Problem Statement}
We propose a framework for generating tileable microstructures with targeted physical properties.
The geometry of each microstructure $\Omega$ is represented by a signed distance field (SDF) $\phi_{\Omega}(\mathbf{x}): \mathbb{R}^3 \to \mathbb{R}$. 
By generating the structure to be translationally symmetric, we enable tessellation in 3D space, ensuring the structure remains invariant under lattice translations: 
% \pmh{the wording `By enforcing translational symmetry' is somehow confusing, it sounds like you already said that we do enforce it } \tim{revised}
\begin{equation}
    \phi(\mathbf{x})=\phi(\mathbf{x} + n\mathbf{t}),
\end{equation}
where $\mathbf{t}$ is a lattice translation vector and $n$ is the tiling number.

The mechanical properties of the microstructure are described by the macroscopic elasticity tensor $\mathbf{C} \in \mathbb{R}^{6\times6}$. 
$\mathbf{C}$ can be directly converted to Young's modulus $E$, Poisson's ratio $\nu$, and shear modulus $G$.
Our objective is to generate microstructures whose elasticity tensor $\mathbf{C}(\phi_{\Omega}(\mathbf{x}))$ closely matches a target elasticity tensor $\mathbf{C}_{\text{target}}$.

\subsection{MIND: Neural Microstructure Generation}
To achieve this, we introduce a latent representation, termed \textit{Holoplane}, and train an autoencoder to encode microstructures into this latent space (Fig.~\ref{fig:pipeline}). 
Diffusion models are then employed for conditional generation within the latent space.

Tileable microstructures often possess inherent symmetries, which can be explicitly utilized to achieve a more compact and efficient representation.
Voxel-based representations are particularly well-suited for encoding such structural symmetries.
For example, previous work~\cite{Yang2024} has utilized the $\frac{1}{8}$-space of the microstructure to express tetrahedral symmetry. 
However, voxel-based encodings are inherently limited by their resolution.
As illustrated in Fig.~\ref{fig:super_resolution}, even at a relatively high resolution of $128^3$, typical structures cannot be faithfully represented.

\begin{wrapfigure}{l}{0.4\linewidth}
    \centering
    \setlength{\columnsep}{5pt} 
    \setlength{\intextsep}{5pt} 
    \includegraphics[width=1.2\linewidth]{figures_new/super_resolution.jpg}
    \caption{Left: Resolution 128, Right: Super-resolution 196.
    }
	\label{fig:super_resolution}
\end{wrapfigure}
To address this, we utilize a hybrid explicit-implicit representation method for encoding microstructures. 
This combines voxel grids (explicit) with SDFs (implicit), allowing precise symmetry capture and continuous structure representation (Fig.~\ref{fig:pipeline} (a)).
We refer to this representation as \textit{Hybrid Symmetric Representation}~(Sec.~\ref{sec:sym_enc}).

The geometry of a microstructure strongly influences its stiffness, but the relationship is highly 
 nonlinear. 
Minor geometric changes can cause substantial variations in properties.
Solely encoding geometry risks the autoencoder learning spurious correlations, hindering diffusion-based generation in the latent space.
To overcome this, we incorporate physical priors during the training of the autoencoder, enabling the model to jointly capture both geometric and physical details (Fig.~\ref{fig:pipeline} (b)).
This approach is termed \textit{Physics-aware Neural Embedding}~(Sec.~\ref{sec:phy_enc}).

By combining these ideas, we present a novel representation, termed \textit{Holoplane}.
The Holoplane $\mathcal{P} \in \mathbb{R}^{r\times r\times c}$ can be viewed as a symmetric 2D snapshot of the microstructureâ€™s geometry $\phi$ and physical properties $\mathbf{C}$, aligning them within a unified latent space. Here, $r$ represents the resolution of the snapshot, while $c$ denotes the number of channels.


We train a diffusion model to generate Holoplanes conditioned on given properties (Sec.~\ref{sec:diffusion}). 
The generated Holoplanes are then decoded to produce the microstructure SDF $\phi_{\Omega}$.
When performing heterogeneous design, the compatibility between adjacent microstructures significantly impacts the overall physical performance.
To address this, we utilize the gradient of a boundary-compatibility loss to guide the diffusion sampling of Holoplanes, ensuring that the generated microstructures adhere to compatibility constraints.
Additionally, we apply interpolation-based blending to ensure seamless alignment of microstructure boundaries, achieving a tight and consistent fit at their interfaces.
