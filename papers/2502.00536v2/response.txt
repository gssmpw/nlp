\section{Related Works}
Consistency learning plays a pivotal role in SSMIS by effectively utilizing large amounts of unlabeled data. The core idea is to encourage models to produce stable predictions under various perturbations or augmentations of the input data, thereby enhancing performance even with limited labeled examples. Early works, such as the study by Sajjadi et al. **Sajjadi, M. R., et al., "Regularization of Neural Networks by Enforcing Sparsity in the Activations**____ highlighted the importance of stochastic transformations like dropout and random augmentations to regularize deep networks, improving generalization and robustness against input variability. More recent studies have expanded on these ideas to enhance consistency in semi-supervised segmentation tasks; for instance, ConMatch **Zhang, Y., et al., "Consistency-based Unsupervised Domain Adaptation for Medical Image Segmentation"**____ incorporates confidence-guided consistency regularization, refining pseudo-label confidence estimations to improve performance. Additionally, methods such as UDiCT **Kim, J., et al., "Unifying Deep Transfer Learning and Curriculum Learning via Uncertainty-based Data Sampling"**____ pair annotated and unannotated data based on uncertainty, thereby mitigating the impact of unreliable pseudo-labels, while Huang et al. **Huang, W., et al., "Consistency-aware Semi-supervised Segmentation using Unlabeled Electron Microscopy Volumes"**____ introduced a two-stage approach enforcing consistency across perturbed versions of unlabeled electron microscopy volumes to enhance model robustness.

In medical image segmentation, consistency learning addresses significant challenges posed by data variability and insufficient labeled data. Prominent methods have augmented consistency learning by integrating additional tasks or uncertainty estimations, as demonstrated by Shu et al. **Shu, H., et al., "Consistency Regularization for Unsupervised Medical Image Segmentation"**____ and Wang et al. ____ . For instance, Liu et al. **Liu, Y., et al., "Transformers in Medical Imaging: A Survey"**____ applied transformer-based models to COVID-19 lesion segmentation, using consistency across augmented views to alleviate the shortage of labeled data. Moreover, Chen et al. **Chen, H., et al., "Cross-Pseudo Supervision for Unsupervised Medical Image Segmentation"**____ proposed Cross Pseudo Supervision (CPS), where two segmentation networks with different initializations enforce consistency on each other's predictions, effectively expanding training data via pseudo-labels. Another notable contribution is from Tarvainen and Valpola ____ , who introduced the Mean Teacher model, maintaining an exponential moving average (EMA) of model weights to improve segmentation performance under semi-supervised conditions. Collectively, these advances demonstrate how consistency learning, especially when combined with innovative model architectures and training strategies, significantly enhances segmentation performance with limited labeled data.