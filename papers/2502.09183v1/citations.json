[
  {
    "index": 0,
    "papers": [
      {
        "key": "gpt4o-blog",
        "author": "OpenAI",
        "title": "Hello GPT-4o"
      }
    ]
  },
  {
    "index": 1,
    "papers": [
      {
        "key": "gemini-blog",
        "author": "Google",
        "title": "Gemini"
      }
    ]
  },
  {
    "index": 2,
    "papers": [
      {
        "key": "claude3p5-blog",
        "author": "Anthropic",
        "title": "Introducing computer use, a new Claude 3.5 Sonnet, and Claude 3.5 Haiku"
      }
    ]
  },
  {
    "index": 3,
    "papers": [
      {
        "key": "hui2024qwen2",
        "author": "Hui, Binyuan and Yang, Jian and Cui, Zeyu and Yang, Jiaxi and Liu, Dayiheng and Zhang, Lei and Liu, Tianyu and Zhang, Jiajun and Yu, Bowen and Dang, Kai and others",
        "title": "Qwen2.5-Coder Technical Report"
      }
    ]
  },
  {
    "index": 4,
    "papers": [
      {
        "key": "guo2024deepseek",
        "author": "Guo, Daya and Zhu, Qihao and Yang, Dejian and Xie, Zhenda and Dong, Kai and Zhang, Wentao and Chen, Guanting and Bi, Xiao and Wu, Yu and Li, YK and others",
        "title": "DeepSeek-Coder: When the Large Language Model Meets Programming--The Rise of Code Intelligence"
      }
    ]
  },
  {
    "index": 5,
    "papers": [
      {
        "key": "o1-blog",
        "author": "OpenAI",
        "title": "Learning to reason with LLMs"
      }
    ]
  },
  {
    "index": 6,
    "papers": [
      {
        "key": "2025deepseekr1",
        "author": "DeepSeek-AI",
        "title": "DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning"
      }
    ]
  },
  {
    "index": 7,
    "papers": [
      {
        "key": "codealpaca",
        "author": "Sahil Chaudhary",
        "title": "Code Alpaca: An Instruction-following LLaMA model for code generation"
      }
    ]
  },
  {
    "index": 8,
    "papers": [
      {
        "key": "wang-etal-2023-self-instruct",
        "author": "Wang, Yizhong  and\nKordi, Yeganeh  and\nMishra, Swaroop  and\nLiu, Alisa  and\nSmith, Noah A.  and\nKhashabi, Daniel  and\nHajishirzi, Hannaneh",
        "title": "Self-Instruct: Aligning Language Models with Self-Generated Instructions"
      }
    ]
  },
  {
    "index": 9,
    "papers": [
      {
        "key": "luo2024wizardcoder",
        "author": "Ziyang Luo and Can Xu and Pu Zhao and Qingfeng Sun and Xiubo Geng and Wenxiang Hu and Chongyang Tao and Jing Ma and Qingwei Lin and Daxin Jiang",
        "title": "WizardCoder: Empowering Code Large Language Models with Evol-Instruct"
      }
    ]
  },
  {
    "index": 10,
    "papers": [
      {
        "key": "xu2024wizardlm",
        "author": "Can Xu and Qingfeng Sun and Kai Zheng and Xiubo Geng and Pu Zhao and Jiazhan Feng and Chongyang Tao and Qingwei Lin and Daxin Jiang",
        "title": "Wizard{LM}: Empowering Large Pre-Trained Language Models to Follow Complex Instructions"
      }
    ]
  },
  {
    "index": 11,
    "papers": [
      {
        "key": "wei2024magicoder",
        "author": "Yuxiang Wei and Zhe Wang and Jiawei Liu and Yifeng Ding and LINGMING ZHANG",
        "title": "Magicoder: Empowering Code Generation with {OSS}-Instruct"
      }
    ]
  },
  {
    "index": 12,
    "papers": [
      {
        "key": "wu2024inversecoders",
        "author": "Yutong Wu and Di Huang and Wenxuan Shi and Wei Wang and Lingzhe Gao and Shihao Liu and Ziyuan Nan and Kaizhao Yuan and Rui Zhang and Xishan Zhang and Zidong Du and Qi Guo and Yewen Pu and Dawei Yin and Xing Hu and Yunji Chen",
        "title": "InverseCoder: Self-improving Instruction-Tuned Code LLMs with Inverse-Instruct"
      }
    ]
  },
  {
    "index": 13,
    "papers": [
      {
        "key": "yu-etal-2024-wavecoder",
        "author": "Yu, Zhaojian  and\nZhang, Xin  and\nShang, Ning  and\nHuang, Yangyu  and\nXu, Can  and\nZhao, Yishujie  and\nHu, Wenxiang  and\nYin, Qiufeng",
        "title": "{W}ave{C}oder: Widespread And Versatile Enhancement For Code Large Language Models By Instruction Tuning"
      }
    ]
  },
  {
    "index": 14,
    "papers": [
      {
        "key": "zheng-etal-2024-opencodeinterpreter",
        "author": "Zheng, Tianyu  and\nZhang, Ge  and\nShen, Tianhao  and\nLiu, Xueling  and\nLin, Bill Yuchen  and\nFu, Jie  and\nChen, Wenhu  and\nYue, Xiang",
        "title": "{O}pen{C}ode{I}nterpreter: Integrating Code Generation with Execution and Refinement"
      }
    ]
  },
  {
    "index": 15,
    "papers": [
      {
        "key": "huang-etal-2023-large",
        "author": "Huang, Jiaxin  and\nGu, Shixiang  and\nHou, Le  and\nWu, Yuexin  and\nWang, Xuezhi  and\nYu, Hongkun  and\nHan, Jiawei",
        "title": "Large Language Models Can Self-Improve"
      },
      {
        "key": "madaan2023selfrefine",
        "author": "Aman Madaan and Niket Tandon and Prakhar Gupta and Skyler Hallinan and Luyu Gao and Sarah Wiegreffe and Uri Alon and Nouha Dziri and Shrimai Prabhumoye and Yiming Yang and Shashank Gupta and Bodhisattwa Prasad Majumder and Katherine Hermann and Sean Welleck and Amir Yazdanbakhsh and Peter Clark",
        "title": "Self-Refine: Iterative Refinement with Self-Feedback"
      },
      {
        "key": "hu-etal-2024-teaching",
        "author": "Hu, Chi  and\nHu, Yimin  and\nCao, Hang  and\nXiao, Tong  and\nZhu, JingBo",
        "title": "Teaching Language Models to Self-Improve by Learning from Language Feedback"
      }
    ]
  },
  {
    "index": 16,
    "papers": [
      {
        "key": "chen2023codet",
        "author": "Bei Chen and Fengji Zhang and Anh Nguyen and Daoguang Zan and Zeqi Lin and Jian-Guang Lou and Weizhu Chen",
        "title": "CodeT:  Code Generation with Generated Tests"
      }
    ]
  },
  {
    "index": 17,
    "papers": [
      {
        "key": "chen2024teaching",
        "author": "Xinyun Chen and Maxwell Lin and Nathanael Sch{\\\"a}rli and Denny Zhou",
        "title": "Teaching Large Language Models to Self-Debug"
      }
    ]
  },
  {
    "index": 18,
    "papers": [
      {
        "key": "zhong-etal-2024-debug",
        "author": "Zhong, Li  and\nWang, Zilong  and\nShang, Jingbo",
        "title": "Debug like a Human: A Large Language Model Debugger via Verifying Runtime Execution Step by Step"
      }
    ]
  },
  {
    "index": 19,
    "papers": [
      {
        "key": "dong2024self",
        "author": "Qingxiu Dong and Li Dong and Xingxing Zhang and Zhifang Sui and Furu Wei",
        "title": "Self-Boosting Large Language Models with  Synthetic Preference Data"
      },
      {
        "key": "yuan2024selfrewarding",
        "author": "Weizhe Yuan and Richard Yuanzhe Pang and Kyunghyun Cho and Xian Li and Sainbayar Sukhbaatar and Jing Xu and Jason E Weston",
        "title": "Self-Rewarding Language Models"
      },
      {
        "key": "kim2025spread",
        "author": "Dongyoung Kim and Jaehyung Kim and Kimin Lee and Jinwoo Shin",
        "title": "Spread Preference Annotation: Direct Preference Judgment for Efficient {LLM} Alignment"
      }
    ]
  },
  {
    "index": 20,
    "papers": [
      {
        "key": "rafailov2023direct",
        "author": "Rafael Rafailov and Archit Sharma and Eric Mitchell and Christopher D Manning and Stefano Ermon and Chelsea Finn",
        "title": "Direct Preference Optimization: Your Language Model is Secretly a Reward Model"
      }
    ]
  },
  {
    "index": 21,
    "papers": [
      {
        "key": "tao2024codelutra",
        "author": "Tao, Leitian and Chen, Xiang and Yu, Tong and Mai, Tung and Rossi, Ryan and Li, Yixuan and Mitra, Saayan",
        "title": "CodeLutra: Boosting LLM Code Generation via Preference-Guided Refinement"
      }
    ]
  }
]