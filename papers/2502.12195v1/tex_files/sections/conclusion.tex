\section{Conclusion}
\textit{GeneralizeFormer} learns to achieve test-time generalization with target information by adaptively generating model weights for varying target distributions. Under the introduced meta-generalization stage, the method learns to generate the target-specific model parameters by incorporating target information and source-trained weights through a transformer. By bypassing fine-tuning operations, we achieve both data and time-efficient generalization at test time with the target information, which also mitigates the instability and source forgetting caused by cyclical adaptation and prediction in conventional optimization of the source model. By its adaptive nature, the proposed method can handle various distribution shifts effectively and efficiently. 

\noindent Since we utilize meta-learning on multiple source domains to learn the generalization ability with more target information, the generalization of a single source domain is a limitation of the proposed method, which we consider a valuable avenue for future work. Especially, recent generative modeling techniques allow the creation of multiple source domains with varying shifts, which broadens the scope of our proposal.

\section*{Acknowledgments}
\noindent This work is financially supported by Core42, the University of Amsterdam, and the allowance Top consortia for Knowledge and Innovation (TKIs) from the Netherlands Ministry of Economic Affairs and Climate Policy.
