
\section{Methodology}

\noindent
\textbf{Preliminary.} Test-time domain generalization aims to generalize the model $\btheta_{s}$ trained on the source domains $\mathcal{S}$ to the unseen target domain $\mathcal{T}$, where $\mathcal{S}$ usually consists of several source domains $\{ D_s \}_{s=1}^{S}$. Naturally, $\mathcal{T}$ may also consist of several target domains $\{ D_t \}_{t=1}^{T}$. Here, $(\x_s, \y_s)$ and $(\x_t, \y_t)$ denote the data-label pairs on the source domain $D_s$ and target domain $D_t$, respectively. The objective of test-time domain generalization is to maximize the log-likelihood of the target data $p(D_t|\btheta_s)$, i.e., $p(\y_t|\x_t, \btheta_s)$.

Since distribution shifts between the source and target domains are expected, the source-trained model $\btheta_s$ usually struggles on the unseen target domain $D_t$, leading to unreliable predictions \cite{dubey2021adaptive}. In this case, the source model needs to be further generalized to the target domains at test time. One commonly used method for test-time domain generalization is fine-tuning \cite{wang2021tent, jang2022test}, which generalizes the source-trained model $\btheta_s$ to $\btheta_t$ before predicting on target data. The log-likelihood of the target data is then formulated as:
\begin{equation}
\label{tta} %
\begin{aligned}
    p(\y_t|\x_t, \btheta_{s}) & = \int p(\y_t|\x_t, \btheta_{t}) p(\btheta_{t}|\x_t, \btheta_{s}) d \btheta_{t} \\ 
    & \approx p(\y_t|\x_t, \btheta^*_{t}),
\end{aligned}
\end{equation}
where the integration of distribution $p(\btheta_t)$ is usually approximated by the maximum a posteriori (MAP) estimation. The MAP model $\btheta^*_{t}$ is obtained by fine-tuning with an unsupervised learning loss function like entropy minimization \cite{wang2021tent} or pseudo labeling \cite{jang2022test}.
However, by updating the model parameters through backpropagation, fine-tuning methods require expensive time and computational costs for generalization in each test step. 
Moreover, in real-world applications, the target domains are usually unpredictable, which means target samples from any domain will arrive at any test time step during the online inference and generalization \cite{wang2022continual, yuan2023robust, niu2023towards}. In these dynamic scenarios with continually changing distributions, the fine-tuning-based methods would lead to underfitting \blue{adaptation} due to limited target information and distribution forgetting caused by loss of source information.
To deal with these problems, we propose to directly generate the target-specific model $p(\btheta_{t}|\x_t, \btheta_{s})$ with a designed transformer network rather than obtaining it by MAP approximation through fine-tuning. 




\begin{figure*}[t]
\centering
\vspace{-2mm}
\includegraphics[width=0.90\linewidth]{fig/Fig2_1_1.png}
\vspace{-2mm}
\caption{\textbf{Illustration of GeneralizeFormer.} 
We generate the model parameters of the classifiers and the Batch Normalization layers at different levels with GeneralizeFormer. 
The GeneralizeFormer takes the source-trained parameters, target features, and layer-wise gradients as input and outputs the target-specific parameters.
By considering the layer-wise information, the method adaptively generates target parameters for different levels of layers, enabling the model to handle various distribution shifts.}

\label{fig:generalformer}
\vspace{-4mm}
\end{figure*}

\noindent
\textbf{GeneralizeFormer.}
To achieve test-time generalization by directly inferring $p(\btheta_{t}|\x_t, \btheta_{s})$, we generate the target model $p(\btheta_t)$ with a transformer $\bphi$.
The log-likelihood in eq. (\ref{tta}) is:
\begin{equation}
\label{tta_gf} %
\begin{aligned}
    p(\y_t|\x_t, \btheta_{s}) & = \int p(\y_t|\x_t, \btheta_{t}) p_{\bphi}(\btheta_{t}|\x_t, \btheta_{s}) d \btheta_{t},
\end{aligned}
\end{equation}
where the generation of $p_{\bphi}(\btheta_t)$ is conditioned on the source trained model $\btheta_s$ and the target data $\x_t$.
Specifically, the information on the target data is necessary to generate the target data-specific model. 
In test-time generalization, the only available target information is the current batch of test samples $\x_t$ or just a single sample \cite{xiao2022learning}. We use the feature representations of the current target samples to integrate the target information for each test time step. The features are obtained by the source-trained model, i.e. $\z_t {=} f_{\btheta_s}(\x_t)$. 

Since our goal is to achieve good performance on the target data \blue{during generalization}, the generated target model needs to have good ability for feature extraction and classification.
Although the source-trained model parameters suffer from distribution shifts, the basic feature extraction or classification ability is necessary to achieve fast generalization with the limited number of target samples at test time. Therefore, we also utilize the source-trained parameters $\btheta_s$ as inputs for our GeneralizeFormer.

In addition to the target features from $\x_t$ and source-trained model parameters $\btheta_s$, we also include layer-wise gradient information of the model on the target samples. 
The gradients are obtained by $\g_t^l {=} {\partial \mathcal{L} (\x_t)} / {\partial \btheta^l_s}$, where $l$ denotes the model layers. The loss function $\mathcal{L} (\x_t)$ can be any unsupervised loss. Here, we use the common 
entropy minimization \cite{wang2021tent, zhang2021memo}.
By feeding the layer-wise gradient information into the transformer $\bphi$, the generated model $\btheta_t$ further considers the effects of different layers on the target samples. With the gradients $\g_t^l$ that are both data-specific and layer-specific, $\btheta_t$ not only contains more diverse target information but also achieves an adaptive layer-specific adjustment according to the source model and target data.

With the above inputs, the generation of the target-specific model $p_{\bphi} (\btheta_t)$ is achieved by:
\begin{equation}
p_{\bphi} (\btheta_t | \btheta_s, \x_t) = \{ p_{\bphi} (\btheta_t^l | \btheta_s^l, \x_t) \}_{l=1}^L = \{ \bphi (\btheta^l_s, \z_t, \g^l_t) \}_{l=1}^L,
\end{equation}
where $l {=} \{ 1, 2, \cdots, L \} $ denotes the layer of the model. Fig. \ref{fig:generalformer} illustrates the generation process.

\noindent
\textbf{Meta GeneralizeFormer.} To learn the ability of model generation across distributions, we further train the GeneralizeFormer under a meta-learning framework \cite{du2020learning, xiao2022learning}.
Specifically, we simulate distribution shifts during training by splitting the source domains $\mathcal{S}$ into meta-source domains $\mathcal{S}'$ and a meta-target domain $\mathcal{T}'$. The meta-target domain is selected randomly in each iteration to mimic diverse domain shifts. 

Per iteration, we train the meta-source model $\btheta_{s'}$ by minimizing the cross-entropy loss on the meta-source data by:
\begin{equation}
\label{metasource}
   \btheta_{s'} = \mathop{\min}\limits_{\btheta} \mathbb{E}_{(\x_{s'}, \y_{s'}) \in \mathcal{S}'} [\mathcal{L}_{\mathrm{CE}}(\x_{s'}, \y_{s'}; \btheta)]. 
\end{equation}
To mimic the test-time generalization procedure and learn the ability of model generation across distributions, we then train the transformer $\bphi$ by the meta-source model $\btheta_{s'}$ and the meta-target data $\x_{t'}$. Specifically, we obtain the target features $\z_{t'}$ and gradients $\g_{t'}^l{=}{\partial \mathcal{L} (\x_t)} / {\partial \btheta_{s'}^l}$ using the meta-target data. The meta-target model is then generated by $\btheta^l_{t'} {=} \bphi(\btheta^l_{s'}, \z_{t'}, \g_{t'}^l), \forall l=1,2,\cdots, L$. 

Since we have access to the actual meta-target labels $\y_{t'}$ during source training, we train the transformer by supervising the model generation procedure:
\begin{equation}
\label{metatar}
\bphi = \min _{\bphi} \mathbb{E}_{(\x_{t'}, \y_{t'}) \in \mathcal{T}' }[\mathcal{L}_{\mathrm{CE}}(\x_{t'}, \y_{t'}; \btheta_{t'})],
\end{equation}
where $\btheta_{t'} = \{ \btheta^l_{t'} \}_{l=1}^L$ denotes the generated parameters of different layers and $\mathcal{L}_{\mathrm{CE}}$ denotes the supervised cross-entropy loss. Intuitively, after multiple iterations, the cross-entropy on meta-source model $\btheta_{s'}$ in eq.~(\ref{metasource}) trains the basic feature extraction and classification ability of the model. The transformer network $\bphi$ further learns to generate specific model parameters across distributions based on the source-trained model and target data by the supervision in eq.~(\ref{metatar}).

At test time, the method directly generates the target-specific model by $\btheta^l_{t} {=} \bphi(\btheta^l_{s}, \z_{t}, \g_{t}^l), \forall l=1,2,\cdots, L$ for each batch of target data, without any fine-tuning operation and avoiding the unstable \blue{adaptation} or error accumulation in the dynamic scenarios.

\noindent
\textbf{Generating batch norm and classifier.} Due to the relationship between the source and target data, source model parameters of different layers may have different effects on the target samples \cite{lee2022surgical}.
Therefore, it is more effective to implement specific adjustments on various layers of parameters to handle different distribution shifts or different target samples. We achieve layer-specific adaptation by generating the model parameters of different layers and considering the specific gradient information.

To do so, we fix the large amount of parameters from the convolutional layers and generate parameters for the Batch Normalization layers at different levels and the classifiers as shown in Fig. \ref{fig:generalformer}.
In this case, the method is computationally more efficient since the batch norm affine and classifier layers are low dimensional with much fewer parameters than the convolutional layers.
Moreover, the normalization layers and classifiers are known to influence distribution shifts \cite{huang2017arbitrary,xiao2022learning,lim2023ttn,iwasawa2021test}. 
By adaptively generating the affine parameters for required normalization layers, our method adjusts the feature statistics at different levels of the source model, which addresses diverse types of distribution shifts.
The generation of the classifier parameters further handles the domain shifts at the semantic level. 
Overall, by generating BN and classifier parameters, we handle domain shifts across different feature levels efficiently.


Specifically, the Batch Normalization layers \cite{ioffe2015batch} first normalize the feature representations by $\bar{\z}_t {=} {\z_t - \mu} / {\sigma}$, where the statistics $\mu$ and $\sigma^2$ are obtained by the moving average of the training statistics. The normalized features are then scaled and shifted by $\hat{\z}_t {=} \gamma_s \bar{\z}_t + \beta_s$, where the affine parameters $\gamma_s$ and $\beta_s$ are learned during the source training. 
To achieve adaptation on different levels of layers, we generate the target data-specific affine parameters $\gamma_t$ and $\beta_t$ of all Batch Normalization layers by the transformer, with inputs of the source-trained affine parameters, target features, and the corresponding gradients. 
Different from previous methods \cite{wang2021tent} that update both affine parameters and statistics, our method only generates the affine parameters while maintaining the source statistics, which reduces the influence of small batch sizes at test time.

To generate the classifier parameters, we treat the source-trained classifier $ \cc^k_s $ of each category $ k $ as an input vector of the transformer and generate the target classifiers $ \cc^1_t, \cdots, \cc^K_t $ together by considering the target features and gradients information as shown in Fig. \ref{fig:generalformer}.

In summary, the generation of Batch Normalization affine parameters and classifier parameters are formulated as:
\begin{equation}
\begin{aligned}
& \gamma^l_t, \beta^l_t = \bphi (\gamma^l_s, \beta^l_s, \z_t, \g^{\gamma^l}_t, \g^{\beta^l}_t), \\
& \cc^1_t, \cdots, \cc^K_t = \bphi (\cc^1_s, \cdots, \cc^K_s, \z_t, \g^{\cc}_t),
\label{eqn_genbn}
\end{aligned}
\end{equation}
where $\gamma^l, \beta^l$ denote the affine parameters of the $l$\textit{-th} Batch Normalization layers and $\cc^k, k \in \{ 1, \cdots, K, \}$ denote the classifier of $k$\textit{-th} category.  
From now on, to ease notation, we use $\btheta$ to summarize the affine parameters $\gamma$ and $\beta$ of different Batch Normalization layers and classifier parameters $\cc$.

With the trained transformer model $\bphi$, our method adaptively generates the parameters of different Batch Normalization layers and classifiers for different distribution shifts at test time.
Since we fix the convolutional layers and generate other parameters by feedforward calculation of the transformer without online optimization, the model adjustment is more efficient than online fine-tuning methods \cite{wang2021tent, iwasawa2021test}.
Note that we generate Batch Normalization and classifier parameters in this work, but the method can also be extended to any linear layer, which benefits other model architectures.

\noindent \pink{\textbf{Rationale behind utilizing transformer. }} \pink{We introduce a transformer for parameter generation, whose attention mechanism effectively aggregates useful knowledge in source parameters and target features to avoid information loss.
We further consider layer-wise gradients per target batch as input of the transformer, which indicates the relationships between each layer of the source parameters and each target batch. By doing so, the gradients guide model generation for each layer and for different target domains, batches, and even samples.
This reduces error transmission among target samples and layers while enhancing the generalization ability across samples and domain shifts.}




