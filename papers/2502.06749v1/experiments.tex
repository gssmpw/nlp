\section{Numerical Experiments}\label{sec:experiments}


Our experimental study focuses on a setting where the learner is trying to reduce a population's risk of cardiovascular disease. To do so, we identify relevant features and build a causal graph based on the recent medical study of~\cite{causal_cvd}. Their study aims to identify the causal links between features such as smoking, diet, or obesity, and whether a patient may develop a cardiovascular disease (CVD). The study is based on an expert survey where several experts were asked to quantify whether specific links between two features as well as links between features and the outcome variable (CVD) are \emph{causal} or \emph{merely correlated}. 

\subsection{Experimental Setup}
\paragraph{Identifying Relevant Features} We identify a subset of 8 features used in~\cite{causal_cvd} that we focus on in our experimental study. In particular, we did not include features that cannot be changed such as age or ethnicity, and only include the features that can be modified by an individual. The 8 features we identified are: alcohol consumption, diet, physical activity, smoking, diabetes mellitus (DM), hyperlypidia (HPL), hypertension (HPT), and obesity. We normalized features to be between $[0,1]$\footnote{For simplicity and wlog, we assume that $0$ is the least ``healthy'' value of the feature, and $1$ is the ``healthiest'' value of the feature. For example, for smoking, $1$ maps to not smoking; for activity, $1$ maps to high amount of weekly physical activity.}.


Among these features, and as noted in our introduction, a principal (i.e., a doctor) would like to incentivize people to focus on preventative, lifestyle interventions over medical treatment interventions. Hence, we separate them to desirable and undesirable to modify as follows: 
\begin{itemize}
\item \emph{Desirable:} Alcohol, Diet, Activity, Smoking. Note that desirable means here that these features are desirable to \emph{modify}, not that, for example, alcohol consumption is desirable. 
\item \emph{Undesirable:} DM, HPL, HPT, Obesity. Note that these features are not ``undesirable'' per se, but rather less desirable than lifestyle interventions.
\end{itemize}

\paragraph{Building the Causal Graph:} The study of~\cite{causal_cvd} asked the experts to report the likelihood of causation on a Likert scale from $1$ to $7$, which is then transformed into  ``fuzzy score'' via the Fuzzy Delphi Method~\cite{linstone1975delphi}. We denote this score $s$. A fuzzy score of $0.5$ and above indicates that experts at least moderately agree with a relationship being causal, with an increasing score $s$ indicating stronger agreement. A fuzzy score of $0.5$ or below indicates that the experts at best disagree with the feature being causal, with the strength of the disagreement increasing as the score goes down. 

We follow the expert agreement of~\cite{causal_cvd} to build our causal links. Specifically, we identify a link as causal if and only if $s > 0.5$. Further, since a score of $0.5$ denotes that experts are at the boundary of agreeing vs disagreeing on causality, we renormalize our scores to be between $0$ and $1$: to do so, we apply a linear transformation that maps $s = 0.5$ to a causal weight of $0$, and $s = 1$ to a causal weight of $1$. We obtain the following graph (Figure~\ref{fig:causal_graph}): 
\begin{figure}[hbt!]
    \centering
    \includegraphics[width=.5\textwidth]{Figures/causal_graph.png}
    \caption{Causal graph of features which affect the output of interest ``Risk of Cardio-vascular disease (CVD)". There are $8$ features, all of which are \textit{causal}. The features at the bottom form the set of desirable features $\des$ and those on the top form the set of undesirable features $\und$. The causal links are indicated on the graph. This causal graph has a special structure: it is \textit{bipartite}. The edge weights are recorded in Table~\ref{table:weights} in Appendix~\ref{sec:app_addn_exp}.}
    \label{fig:causal_graph}
\end{figure}

\emph{Generating Prior Beliefs} We note that our desirable features are generally harder to observe than our undesirable features. First, DM, HPL, HPT, and Obesity are easy-to-quantify features that are also verifiable by a doctor (e.g., though blood work). On the other hand, lifestyle habits are not only hard to observe, but also often mis-reported to clinicians (i.e., under-reporting alcohol consumption, or lying about smoking to avoid insurance upcharges). Hence, we generate all our priors of $h$ to have both a mean and variance of $0$ for all desirable features (i.e., it is fully known that desirable features are not observed by a clinician, and so not used in the clinician's classifier for high risk of CVD), as they are effectively \emph{unobservable}. We consider four mean beliefs $\mu_h$ on the vector $h$, that we denote as follows: 
\begin{itemize}
\item \emph{DM}: There is a weight of $1$ on the ``DM'' feature, and $0$ on all others.
\item \emph{HPL}: There is a weight of $1$ on the ``HPL'' feature, and $0$ on all others.
\item \emph{HPT}: There is a weight of $1$ on the ``HPT'' feature, and $0$ on all others.
\item \emph{Obesity}: There is a weight of $1$ on the ``Obesity'' feature, and $0$ on all others.
\end{itemize}
We note that all other beliefs that only use undesirable, observable features are a linear combination of the four beliefs above, so our insights extend to general classifiers. Also, we demonstrate later that while the classifier does not put any weight on unobserved/desirable features, agents may still exert effort on them because they affect the observed/undesirable features used in the classifier. 

The variance of each of the desirable features is taken to be $0$ (there is complete information that no weight is put on these features in the principal's classifier). Further, we assume that all undesirable features have the same variance, which is parametrized by $\sigma > 0$ --- thus $\sigma$ is a measure of the level of incomplete information. Finally, the covariance matrix of the classifier ($\Sigma_h$) is taken to be diagonal for simplicity of exposition and interpretation, i.e., individuals' beliefs do not encode correlations between features in the deployed classifier.

\subsection{Experimental Results}
Note that we are operating under the regime where the agent has uncertainty only over the classifier $h$ and not over the causal graph (Model $1$), hence the contribution matrix $\C$ is fully known to agents. Agents are assumed to have unweighted $\ell_2$-norm costs.   

For each of the four classifiers described above, we document the \textit{mean contribution} of each feature, given by $\mu_{\C h} = \C \mu_h$ and the $\ell_2$ norm of the mean contribution over the set of desirable and undesirable features, given by $\ell_2(\des)$ and $\ell_2(\und)$ respectively. All values are recorded in Table~\ref{table:mu}. Also, note that due to our choice of the variance structure on $h$ (given by matrix $\Sigma_h = Diag(0,0,0,0,\sigma^2, \sigma^2, \sigma^2, \sigma^2)$ ), all four classifiers have the same covariance over the contribution vector $\C h$ given by $Cov(\C h) = \C \Sigma_h \C^{\top}$.\\

\begin{table}[t!]
\centering
\begin{tabular}{|c|| c|c|c|c || c|c|c|c||c|c|}
\hline 
Classifier & Alcohol & Diet & Activity & Smoking & DM & HPL & HPT & Obesity & $\ell_2(\des)$ & $\ell_2(\und)$
\\
\hline 
\hline 
DM & 0.1 & 0.84 & 0.82 & 0.52 & 1 & 0 & 0 & 0 & 1.28 & 1 
\\
\hline 
HPL & 0.14 & 0.84 & 0.82 & 0.34 & 0 & 1 & 0 & 0 & 1.23 & 1 
\\
\hline 
HPT & 0.62 & 0.84 & 0.82 & 0.86 & 0 & 0 & 1 & 0 & 1.58 & 1 
\\
\hline 
Obesity & 0.64 & 0.86 & 0.82 & 0 & 0 & 0 & 0 & 1 & 1.35 & 1 
\\
\hline
\end{tabular}
\caption{Mean contribution vector $\mu_{\C h}$ for the 4 classifiers: DM, HPL, HPT, Obesity}\label{table:mu}
\end{table}

\paragraph{Desirable features can be incentivized even if they are never observed.} In our four classifiers of choice, observe that no weight has been put on any of the features in set $\des$ because they represent features which cannot be directly observed. However, Figures~\ref{fig:beta_vs_sigma} and \ref{fig:l2_unknown_classifier}  demonstrate that agents still choose to invest significant effort into desirable features. This is a direct result of the \emph{causal relationship between features}. Observe that in the causal graph, the desirable features influence multiple undesirable features simultaneously. This means that an agent obtains a larger improvement in the undesirable features (which actually affect the agent's classification), not by modifying them directly, but by investing effort into desirable features.
 

\paragraph{Effect of total contribution on desirable vs undesirable features:} From table ~\ref{table:mu}, it is clear that all four classifiers have a higher $\ell_2$-norm on mean contribution over the set of desirable features compared to undesirable features. Naturally, we expect all 4 classifiers to achieve $\beta > 0.5$ under most circumstances (except at high levels of uncertainty), i.e., more than half of the total magnitude of effort should be invested into desirable features (as per Corollary~\ref{cor:prop_effort}). Indeed, this is in line with what we observe in Figure~\ref{fig:beta_vs_sigma}. We also note that, as expected, HPT is better than Obesity, which is better than DM, which is better than HPL for incentivizing desirable features: this is consistent with the ordering over $\ell_2(\des)$ across these four classifiers, again following the insights of Corollary~\ref{cor:prop_effort}.     

\paragraph{Effect of uncertainty level $\sigma$.} In Figure~\ref{fig:beta_vs_sigma}, we plot how $\beta$ varies as a function of the uncertainty parameter $\sigma$ for different classifiers. Higher $\sigma$ indicates a higher degree of uncertainty about the classifier. As $\sigma$ increases, all four classifiers degrade in terms of desirability ($\beta$). This is intuitive: at higher levels of uncertainty, the contribution of desirable features sees higher variance, as they affect not only themselves but also other features. Undesirable features then become safer to modify.

\begin{figure}[!ht]
  \centering
  \raisebox{20pt}{\parbox[b]{.11\textwidth}{}}%
  \subfloat[][$\delta = 0.1$]{\includegraphics[width=.33\textwidth]{Figures/beta_vs_sigma_delta01.png}}\hfill
  \subfloat[][$\delta = 0.3$]{\includegraphics[width=.33\textwidth]{Figures/beta_vs_sigma_delta03.png}}\hfill
  \subfloat[][$\delta = 0.5$]{\includegraphics[width=.33\textwidth]{Figures/beta_vs_sigma_delta05.png}}\par
  \caption{Plot of how $\beta$ varies with $\sigma$ at different levels of $\delta$ and for different classifiers. 
  } 
  \label{fig:beta_vs_sigma}
\end{figure}

\paragraph{Effect of the failure probability $\delta$.} At a fixed level of uncertainty $\sigma$, as the failure probability $\delta$ increases, $\beta$ improves across all four classifiers (Figure~\ref{fig:l2_unknown_classifier}). This is again expected---higher $\delta$ means that the agent is less stringent on the coverage probability requirement and therefore has a much larger space of feasible effort profiles to choose from. Since all features have equal costs, her best response is to invest more in desirable features because they have a higher net contribution which means that she can now ``pass" the classifier while incurring a lower cost.     


\paragraph{Trade-offs between $\sigma$ and $\delta$.} The failure probability $\delta$ is closely related to the level of uncertainty $\sigma$. At a fixed level of uncertainty $\sigma$, there is a limit on how low a failure probability $\delta$ can be achieved (Figure~\ref{fig:l2_unknown_classifier}). Similarly, in order to achieve a given failure rate $\delta$, there is a maximum amount of uncertainty $\sigma$ that can be tolerated (Figure~\ref{fig:beta_vs_sigma}); beyond that the problem becomes infeasible. This closely tracks our theoretical findings in Section~\ref{sec:incomplete} (Lemma~\ref{lem:delta_charac}). As $\delta$ increases (the agent imposes a weaker requirement on the coverage probability), a higher degree of uncertainty can be tolerated. Finally at $\delta = 0.5$, the level of uncertainty becomes irrelevant --- this is because at $\delta = 0.5$, the agent wants to pass the classifier with a probability of $\frac{1}{2}$ and therefore can afford to make decisions just on the basis on the mean belief classifier $\mu_h$. 

\begin{figure}[!ht]
  \centering
  \raisebox{20pt}{\parbox[b]{.11\textwidth}{}}%
  \subfloat[][$(\alpha = 1, \sigma = 3)$]{\includegraphics[width=.3\textwidth]{Figures/beta_vs_delta_alpha1std3.png}}\hfill
  \subfloat[][$(\alpha = 1, \sigma = 1)$]{\includegraphics[width=.3\textwidth]{Figures/beta_vs_delta_alpha1std1.png}}\hfill
  \subfloat[][$(\alpha = 1, \sigma = 0.1)$]{\includegraphics[width=.3\textwidth]{Figures/beta_vs_delta_alpha1std01.png}}\par
  \raisebox{20pt}{\parbox[b]{.11\textwidth}{}}%
  \subfloat[][$(\alpha = 10, \sigma = 3)$]{\includegraphics[width=.3\textwidth]{Figures/beta_vs_delta_alpha10std3.png}}\hfill
  \subfloat[][$(\alpha = 10, \sigma = 1)$]{\includegraphics[width=.3\textwidth]{Figures/beta_vs_delta_alpha10std1.png}}\hfill
  \subfloat[][$(\alpha = 10, \sigma = 0.1)$]{\includegraphics[width=.3\textwidth]{Figures/beta_vs_delta_alpha10std01.png}}\par
  \caption{Plots of how $\beta$ varies with $\delta$ for different parameter combinations.} 
  \label{fig:l2_unknown_classifier}
\end{figure}

\paragraph{Effect of $\alpha$.} $\alpha$ represents the amount by which the agent is shy of a positive classification outcome. In this case, we see that $\beta$ has no dependence on $\alpha$ (Figure~\ref{fig:l2_unknown_classifier}). This is an artifact of the $\ell_2$-norm cost function --- the agent's optimal effort profile is proportional to $\alpha$ in each feature and therefore $\beta$ remains unaffected. However, note that $\alpha$ does affect the cost incurred by the agent, the farther she is from the classification boundary (higher $\alpha$), the higher is the cost incurred.  





