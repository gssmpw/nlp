\documentclass[11pt]{article}
\usepackage{graphicx} % Required for inserting images
\usepackage{fullpage}
\usepackage{amsfonts}
\usepackage{amsmath}
\usepackage{xcolor}
\usepackage[colorlinks=true, citecolor=blue]{hyperref}
\newcommand{\calG}{\mathcal{G}}
\usepackage{float}
\usepackage{tcolorbox}
\usepackage{mathtools}
\usepackage{lipsum}
\usepackage{blindtext}
\usepackage{titlesec}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{rotating}
\usepackage{subcaption}
\usepackage{caption}
\usepackage{svg}
\usepackage{verbatim}
\usepackage{enumerate}
\usepackage{float}
\usepackage{natbib}


\usepackage{ifthen}
\usepackage{color}
\usepackage{color-edits}
\addauthor{cp}{red}
\addauthor{jz}{blue}

\newcommand{\footremember}[2]{%
    \footnote{#2}
    \newcounter{#1}
    \setcounter{#1}{\value{footnote}}%
}
\newcommand{\footrecall}[1]{%
    \footnotemark[\value{#1}]%
} 

\title{Incentivizing Desirable Effort Profiles in Strategic Classification: The Role of Causality and Uncertainty}
\author{Valia Efthymiou\footremember{alley}{Massachussetts Institute of Technology. Email: valia554@mit.edu} 
\and Chara Podimata\footremember{somelse}{Massachussetts Institute of Technology. Email: podimata@mit.edu}
\and Diptangshu Sen\footremember{trailer}{Georgia Institute of Technology. Email: dsen30@gatech.edu}
\and Juba Ziani\footremember{somethingelse}{Georgia Institute of Technology. Email: jziani3@gatech.edu}
}

\begin{document}

\maketitle

\input{macros.tex}

\begin{abstract}
We study strategic classification in binary decision-making settings where agents can modify their features in order to improve their classification outcomes. Importantly, our work considers the causal structure across different features, acknowledging that effort in a given feature may affect other features. The main goal of our work is to understand \emph{when and how much agent effort is invested towards desirable features}, and how this is influenced by the deployed classifier, the causal structure of the agent's features, their ability to modify them,  and the information available to the agent about the classifier and the feature causal graph.

In the complete information case, when agents know the classifier and the causal structure of the problem, we derive conditions ensuring that rational agents focus on features favored by the principal. We show that designing classifiers to induce desirable behavior is generally non-convex, though tractable in special cases. We also extend our analysis to settings where agents have incomplete information about the classifier or the causal graph. While optimal effort selection is again a non-convex problem under general uncertainty, we highlight special cases of partial uncertainty where this selection problem becomes tractable. Our results indicate that uncertainty drives agents to favor features with higher expected importance and lower variance, potentially misaligning with principal preferences. Finally, numerical experiments based on a cardiovascular disease risk study illustrate how to incentivize desirable modifications under uncertainty. 
\end{abstract}

\input{intro.tex}
\input{model.tex}
\input{complete_information.tex}
\input{incomplete_info.tex}
\input{experiments.tex}
\input{discussion.tex}


\bibliographystyle{plainnat}
\bibliography{mybib.bib}

\newpage
\appendix
\input{appendix.tex}

\end{document}
