
% \paragraph{1.\ \texttt{register\_dataset}}
% \begin{itemize}
% \item \textbf{Inputs:} 
%   \begin{itemize}
%   \item \texttt{path} (string): File or directory path to be registered.
%   \item \texttt{name} (string): Name to assign to the dataset.
%   \end{itemize}
% \item \textbf{Output:} 
%   \begin{itemize}
%   \item \texttt{str}: A message indicating the registration status.
%   \end{itemize}
% \item \textbf{Functionality:} 
%   Registers a dataset in the \sys\ system so it can be used in later steps, such as filtering or schema-based transformations.
% \end{itemize}

% \paragraph{2.\ \texttt{unregister\_dataset}}
% \begin{itemize}
% \item \textbf{Inputs:}
%   \begin{itemize}
%   \item \texttt{dataset\_name} (string): Name of the dataset to unregister.
%   \end{itemize}
% \item \textbf{Output:} 
%   \begin{itemize}
%   \item \texttt{str}: A message about the unregistration result.
%   \end{itemize}
% \item \textbf{Functionality:} 
%   Removes a dataset from \sys\ so it is no longer accessible.
% \end{itemize}

% \paragraph{3.\ \texttt{list\_datasets}}
% \begin{itemize}
% \item \textbf{Inputs:} None.
% \item \textbf{Output:} 
%   \begin{itemize}
%   \item \texttt{str}: A formatted list of all registered datasets.
%   \end{itemize}
% \item \textbf{Functionality:} 
%   Provides an overview of all currently tracked datasets in the system.
% \end{itemize}

% \paragraph{4.\ \texttt{retrieve\_dataset}}
% \begin{itemize}
% \item \textbf{Inputs:}
%   \begin{itemize}
%   \item \texttt{dataset\_path} (string): Location of the dataset in \sys.
%   \end{itemize}
% \item \textbf{Output:}
%   \begin{itemize}
%   \item \texttt{list[str]}: A list of item identifiers (filenames, keys, etc.) contained in the dataset.
%   \end{itemize}
% \item \textbf{Functionality:}
%   Shows which records (e.g., individual documents) are available in a particular dataset.
% \end{itemize}

% \paragraph{5.\ \texttt{generate\_extraction\_schema}}
% \begin{itemize}
% \item \textbf{Inputs:}
%   \begin{itemize}
%   \item \texttt{schema\_name} (string): Name for the new schema.
%   \item \texttt{schema\_description} (string): Description for the intended schema.
%   \item \texttt{field\_names} (list): List of attribute names.
%   \item \texttt{field\_descriptions} (list): Descriptions corresponding to each field name.
%   \item \texttt{field\_required} (list): Boolean flags indicating required attributes.
%   \end{itemize}
% \item \textbf{Output:} 
%   \begin{itemize}
%   \item \texttt{str}: The name of the newly created schema.
%   \end{itemize}
% \item \textbf{Functionality:}
%   Defines a new schema that can be subsequently used for extracting named attributes from unstructured data.
% \end{itemize}


% \paragraph{6.\ \texttt{filter\_data}}
% \begin{itemize}
% \item \textbf{Inputs:}
%   \begin{itemize}
%   \item \texttt{input\_dataset} (string): The dataset to filter.
%   \item \texttt{filter\_expression} (string): A natural-language condition describing which records to keep.
%   \end{itemize}
% \item \textbf{Output:}
%   \begin{itemize}
%   \item \texttt{str}: A new dataset containing only the records that match the given condition.
%   \end{itemize}
% \item \textbf{Functionality:}
%   Harnesses LLMs or other methods to parse the user’s filter expression and apply the appropriate subset operation on the dataset.
% \end{itemize}

% \paragraph{7.\ \texttt{convert\_dataset}}
% \begin{itemize}
% \item \textbf{Inputs:}
%   \begin{itemize}
%   \item \texttt{input\_dataset} (string): The source dataset.
%   \item \texttt{schema} (string): The target schema name for conversion.
%   \item \texttt{cardinality} (string): Either \texttt{``one\_to\_one''} or \texttt{``one\_to\_many''}, indicating how many schema objects can be extracted from a single record.
%   \end{itemize}
% \item \textbf{Output:}
%   \begin{itemize}
%   \item \texttt{str}: The newly created dataset under the specified schema.
%   \end{itemize}
% \item \textbf{Functionality:}
%   Transforms the data into a desired form (e.g., extracting specific attributes from documents) by applying the specified schema.  
% \end{itemize}

% \paragraph{8.\ \texttt{override\_dataset}}
% \begin{itemize}
% \item \textbf{Inputs:}
%   \begin{itemize}
%   \item \texttt{input\_dataset} (string): The dataset to become the new working dataset.
%   \end{itemize}
% \item \textbf{Output:}
%   \begin{itemize}
%   \item \texttt{str}: Confirmation of the newly set working dataset.
%   \end{itemize}
% \item \textbf{Functionality:}
%   Resets the current environment’s notion of the ``active'' dataset to the specified dataset, which is useful after an extraction or other transformations.
% \end{itemize}

% \paragraph{9.\ \texttt{set\_input\_dataset}}
% \begin{itemize}
% \item \textbf{Inputs:}
%   \begin{itemize}
%   \item \texttt{dataset} (string): Name of the dataset to set as input.
%   \item \texttt{input\_schema} (string): Name of the schema to apply when loading; if unknown, the tool attempts to find or create a matching schema.
%   \end{itemize}
% \item \textbf{Output:}
%   \begin{itemize}
%   \item \texttt{str}: The dataset now set as the input for subsequent operations.
%   \end{itemize}
% \item \textbf{Functionality:}
%   Establishes or updates the default dataset and schema for a \sys\ pipeline before initiating further actions.
% \end{itemize}

% \paragraph{10.\ \texttt{pick\_schema}}
% \begin{itemize}
% \item \textbf{Inputs:}
%   \begin{itemize}
%   \item \texttt{schema\_name} (string): The name of the desired schema.
%   \end{itemize}
% \item \textbf{Output:}
%   \begin{itemize}
%   \item \texttt{str}: The identified schema object or \texttt{None} if not found.
%   \end{itemize}
% \item \textbf{Functionality:}
%   Retrieves an existing schema by name, or indicates the need to create a new one if none is found.
% \end{itemize}

% \paragraph{11.\ \texttt{list\_schemas}}
% \begin{itemize}
% \item \textbf{Inputs:} None.
% \item \textbf{Output:}
%   \begin{itemize}
%   \item \texttt{str}: A formatted overview of all known schemas in the system.
%   \end{itemize}
% \item \textbf{Functionality:}
%   Displays which schemas are available for tasks such as conversions and extractions.
% \end{itemize}

% \paragraph{12.\ \texttt{execute\_workload}}
% \begin{itemize}
% \item \textbf{Inputs:}
%   \begin{itemize}
%   \item \texttt{output\_dataset} (string): The dataset on which the final extraction or transformation should run.
%   \item \texttt{policy\_method} (string): Specifies whether to prioritize cost (\texttt{min\_cost}) or quality (\texttt{max\_quality}).
%   \item \texttt{allow\_code\_synth} (string): Enables or disables code synthesis (\texttt{``True''} or \texttt{``False''}).
%   \item \texttt{allow\_token\_reduction} (string): Enables or disables token reduction (\texttt{``True''} or \texttt{``False''}).
%   \end{itemize}
% \item \textbf{Output:}
%   \begin{itemize}
%   \item \texttt{str}: A result summary, typically containing a reference to a Pandas DataFrame with extracted data.
%   \end{itemize}
% \item \textbf{Functionality:}
%   Executes an entire workload on the current pipeline, optionally performing transformations or filtering as needed. The system decides how to run each operator (e.g., LLM-based or conventional) for optimal performance and correctness, based on the user’s preferences.
% \end{itemize}