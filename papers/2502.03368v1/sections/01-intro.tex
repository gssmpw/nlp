% \vspace{-10pt}
\section{Introduction} \label{sec:introduction}

\begin{figure}
    \centering
    \includegraphics[width=\linewidth]{figures/PZ_DEMO.png}
    \caption{An overview of data processing using \sys}
    \label{fig:architecture-overview}
\end{figure}

The advent of generative AI has fundamentally changed how we engage with data and computing systems. Large Language Models (LLMs) now enable a wide range of applications—such as question answering, multimodal and unstructured data extraction, and agent-driven workflows like reasoning and code synthesis~\cite{yao2022react,hong2023metagpt}. However, these systems increasingly rely on intricate architecture: they combine traditional data processing components (e.g., vector databases~\cite{lewis2020retrieval} and relational operators~\cite{palimpzestCIDR}) with novel programming concepts like prompt engineering~\cite{dspy} or multi-step chain-of-thought reasoning.

Such complexity entails several drawbacks. First, the runtime, monetary cost, and resource consumption of AI pipelines can grow exorbitantly. Second, from a software engineering perspective, designing, deploying, and testing these systems is becoming ever more challenging. Developers must juggle a variety of software frameworks and rapidly changing runtime environments, making the promise of “natural language interfaces” increasingly hard to fulfill for complex data processing tasks.

The core challenge to build a declarative data management system for compound AI pipelines is to design an optimizer that can take in logical pipelines as defined by the users, and produce physical implementations of them that meet specific goals in terms of cost, runtime, and output quality.  Furthermore, a technical challenge involves the designing of a user interface to bridge the freedom of expressing general-purpose AI pipelines, as well as imposing a certain structure on the compiled programs in order to perform automated optimization.

To bridge this gap and address these challenges, we present \sys.
Our system is based on a declarative programming framework, that expert users can leverage to build optimized data processing pipelines for large collections of unstructured documents.
On top of this framework, we designed a chat-based assistant \chat\ that allows non-expert users to build their pipelines using natural language.

In this demo, we focus on both interfaces: the native programming environment (for expert developers) and a natural language interface (for less technical users). Our running example tackles a real-world scientific discovery scenario: a medical researcher analyzing literature on cancer-related papers to identify genomic and proteomic datasets that validate specific hypotheses. SIGMOD attendees can also explore two other use cases or upload their own data to design and execute custom pipelines.

\sys\ is an early, but promising, prototype, and we welcome suggestions for further optimizations and features. We encourage readers to consult our extended technical description in~\cite{palimpzestCIDR}, experiment with our open-source \sys{} code at \systemurl, and interact with \chat{} demo at \demourl and code at \chatcode.

The remainder of this paper is structured as follows:  
Section~\ref{sec:architecture} describes the core architecture of \sys\ and the reasoning framework driving \chat.  
Section~\ref{sec:demoscenario} demonstrates a concrete usage scenario through the chat-based interface.
