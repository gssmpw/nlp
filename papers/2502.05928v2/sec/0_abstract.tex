\begin{abstract}
Medical Visual Question Answering (Med-VQA) represents a critical and challenging subtask within the general VQA domain. Despite significant advancements in general Visual Question Answering (VQA), multimodal large language models (MLLMs) still exhibit substantial limitations when handling multi-task VQA scenarios. These limitations manifest through erroneous spatial localization and misinterpretation of medical images, which primarily arise from two fundamental issues: inadequate image-text alignment and insufficient medical knowledge in general-purpose MLLMs for specialized medical applications. To address these issues, we introduce the Cross-Modal \textbf{Clin}ical \textbf{K}nowledge \textbf{D}istiller (\textbf{ClinKD}), an innovative framework designed to enhance image-text alignment and establish more effective medical knowledge adaptation mechanisms, which enables MLLMs to adapt to medical knowledge. Our extensive experimental evaluations demonstrate that the ClinKD achieves state-of-the-art performance on the Med-GRIT-270k dataset, a challenging medical benchmark containing fine-grained multi-task QA pairs. The results indicate that our approach not only significantly improves image-text alignment but also effectively enables MLLMs to adapt to the medical knowledge. The source code for ClinKD is available at: https://github.com/overloadedHenry/ClinKD.
\begin{figure}[t]
    \centering
    % \hspace{-12pt}
    \includegraphics[width=3.2in]{figure/compare.pdf}
    % \vspace{0.5cm}
    \caption{The left part shows that the BiRD~\cite{huang2024BiRD} only utilizes traditional supervised fine-tuning (SFT) and 2D-RoPE~\cite{su2023roformerenhancedtransformerrotary} to obtain the capabilities of understanding and grounding medical images. The right part is our method which uses Med-CLIP Guided RoPE for enhancing image-text alignment and Pseudo-Labels Medical Knowledge Distillation for filling the gap of medical knowledge in ClinKD. During the SFT procedure, we will use Reflective Correction Training to enable answers with low semantic similarity or incorrect groundings to be reused.}
    \label{fig:compare}
    \vspace{-1em}
\end{figure}
\end{abstract}
