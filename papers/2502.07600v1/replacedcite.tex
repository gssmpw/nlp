\section{Related Work}
\paragraph{Unsupervised Object-Centric Learning}
%
Object-centric representation methods aim to parse in an unsupervised manner an image or video into a set of $\NumSlots$ latent vectors called slots, where each of them binds to a different object in the scene____.
%
Early slot-based methods aimed to learn object representations from synthetic images____ or videos____ by minimizing a reconstruction objective.
%
To learn meaningful representations from real data, recent slot-based methods leverage weak supervision____, large pretrained transformers____, or diffusion models____
%
These object-centric representations benefit multiple downstream tasks such as reinforcement learning for robotic manipulation____ or visual-question-answering____.




\paragraph{Object-Centric Video Prediction}

Object-centric video prediction aims to model the object dynamics and interactions in a video sequence with the goal of forecasting future object states and video frames.
%
Several methods address this task using different architectural priors, including RNNS____, transformers____ or state-space models____, attaining a remarkable prediction accuracy on synthetic datasets.
%
Recently, some methods improve the controllability of object-centric video prediction models by conditioning the prediction process on actions____ or language captions____.
%
However, forecasting future object states without supervision in complex environments still remains an open challenge.




% main fig
\input{imgs/main_fig.tex}




\paragraph{Learning Latent Actions from Unlabeled Videos:}
%

Videos provide abundant information about dynamics and activities, but often lack the action labels necessary for learning behaviors from video.
%
To address this challenge, some methods train a latent policy directly from observations by learning a discrete latent action space and sampling the actions that minimize a reconstruction error____.
%
Another group of methods, to which \Method{} belongs, learns inverse dynamics from unlabeled videos by predicting latent actions given pairs of observations, and uses them for learning behaviors for video games and robot simulations____, as pretraining for Vision-Language-Action models____ or for learning robot policies____.
%

Latent action models have also been used for conditional video prediction.
%
The most similar method to ours is \emph{CADDY}____, which learns latent actions from a collection of unlabeled videos from a single domain and uses the latent actions as conditioning signal for predicting future frames.
%
At inference time, CADDY maps user inputs to the latent space for playable video generation.
%
Building upon this same principle, \emph{Genie}____ proposes a foundation world model for playable video generation on diverse environments.
%
However, both CADDY and Genie operate on holistic scene representations, which are limited for tasks that require relational reasoning, often struggle to model object relationships and interactions, and require human supervision to generalize to scenes with multiple moving agents.









%%%%%%%%%%%%%%%%%%
%% Method %%
%%%%%%%%%%%%%%%%%%