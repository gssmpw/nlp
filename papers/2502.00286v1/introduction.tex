% \subsubsection*{\textbf{Introduction}}\label{sec:introduction}

\vspace{-5pt}
\section{Introduction}\label{sec:introduction}
\vspace{-3pt}
The rapid growth of machine learning (ML) has driven advances in computing, with specialized hardware accelerators enhancing the efficiency of Deep Neural Networks (DNNs). However, this progress comes with a significant environmental cost, as the embodied carbon footprint from the manufacturing of these accelerators remains largely unexplored. Recent studies~\cite{gupta2021chasing,panteleaki2024carbon} highlight that embodied carbon now surpasses operational emissions as a dominant factor in the environmental impact of ML systems, particularly in edge-based applications.

Designing DNN hardware accelerators is challenging due to the wide range of possible hardware configurations and mappings. Key decisions, such as determining the number of Processing Elements (PEs) and setting up local and global memory configurations, greatly affect the accelerator's performance. However, previous works~\cite{gupta2022act} have shown that such accelerators are often overdesigned, providing more performance than necessary for edge applications, and significantly increasing their embodied carbon footprint at the same time. Relaxing performance requirements offers a promising solution that allows the development of carbon-aware designs, that better balance performance and sustainability.
% By focusing on meeting the minimum performance needs of edge applications, these relaxed constraints enable the exploration of more efficient design options, reducing the embodied carbon footprint while maintaining functionality.

% 1st reviewer comment: -DNNs are inherently resilient to errors: revise that last sentence. Much of the literature argues the opposite. Even single bit-flips can corrupt and produce wrong predictions. DNNs possess a certain robustness level due to the redundancy, but this does not prevent them from being vulnerable to random-hardware errors or security attacks.

%Moreover, DNNs are inherently resilient to errors, making them an ideal candidate for leveraging approximate computing to reduce embodied carbon. 
Moreover, DNNs are inherently resilient to computational errors in arithmetic operations, making them an ideal candidate for leveraging approximate computing to reduce embodied carbon. By introducing approximate arithmetic units, which require fewer transistors and have a smaller hardware footprint, it is possible to significantly lower the embodied carbon of DNN accelerators. These approximate units not only reduce the area required for computation, but also free up design space for optimizing memory configurations. Despite the potential benefits, no prior work has explored the use of approximate computing as a means to address the embodied carbon emissions of DNN accelerators. 

In this work, we investigate how relaxed constraints along with approximate computing can be systematically applied to balance embodied carbon footprint and performance for DNN inference accelerators.