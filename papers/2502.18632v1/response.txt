\section{Related Work}
%\ml{A related word is Work :)} \nsf{lol}

\subsection{Knowledge Component Generation} 

Traditional methods for KC creation and tagging rely on human domain experts to identify the knowledge requirements for solving a problem**Kumar, "A Framework for Knowledge Component Representation"**, a highly time-consuming process.
%This manual process can be aided by tools (e.g., CTAT**Lange, "Automated Task Analysis"**) and frameworks (e.g., EAKT**Burgos, "Evaluating Adaptive Instructional Systems"**) to help identify the problem-solving steps and associated KCs students must master. 
Recent work has proposed automated approaches for KC discovery and tagging, employing data-driven approaches including the Q-matrix method**Rau, "A Quantitative Approach to Modeling Cognitive Skills"**.
In programming, **Burgess, "AST-based Knowledge Component Identification"** uses a rule-based parser to obtain ASTs with KCs identified at their lowest ontological level, **Kumar et al., "Knowledge Components in Programming Education"** define KCs as nodes in an AST followed by a learning curve analysis to identify KCs students struggle with the most in Python programming, **Burgess et al., "AST-based Neural Network for KC Identification"** uses an AST-based neural network to identify student misconceptions, **Rau et al., "Deep Learning Approach for KC Attribution"** presents a deep learning approach for KC attribution, and **Lange et al., "Learning Latent Knowledge Components"** learn latent KCs, lacking textual descriptions, by training deep learning models on KT data enforced with priors from pedagogical theory.
%However, these latent KCs lack textual descriptions making them uninterpretable. 
Recent advances in LLMs have inspired automated approaches for descriptive KC generation for dialogues**Rau, "Descriptive Knowledge Generation for Conversational Systems"**, and problems in math**Kumar et al., "Mathematical Problem-Solving with LLMs"**, and science**Burgos et al., "Science Education with LLM-based KC Generation"**. 
However, we're among the first approaches to present a fully automated, LLM-based pipeline for KC generation and tagging for open-ended programming problems.

\subsection{Knowledge Tracing}
There exists a wide body of work on KT**Rau, "A Survey of Knowledge Tracing Methods"** in the student modeling literature. 
The classic KT task aims to estimate a student's mastery of KCs from their responses to past problems and use these estimates to predict their future performance.
Classic Bayesian knowledge tracing methods**Corbett, "Knowledge Tracing with Bayesian Networks"** use latent binary-valued variables to represent student KC mastery.
With the widespread adoption of neural networks, multiple deep learning-based KT methods were proposed with limited interpretability since student knowledge is modeled as hidden states in these networks.
Most of these methods use long short-term memory networks**Liang et al., "KT with LSTM Networks"**, or variants**Zhang et al., "Variants of LSTM for KT"**, with other variants coupling them with memory augmentation**Rao et al., "Memory-Augmented KT Models"**, graph neural networks**Goyal et al., "Graph-based KT with GNNs"**, or attention networks**Li et al., "Attention-based KT Methods"**.
KT methods have been applied to many different educational domains, including programming**Kumar et al., "Programming Education with KT"**. Recent work has attempted to leverage LLMs to develop generative KT methods predicting exact student responses to programming problems**Rau et al., "Generative KT for Programming Problems"**. However, to the best of our knowledge, we are the first to present an LLM-based KT method for programming problems that leverages the textual content of KC descriptions, modeling interpretable student mastery levels on each KC, for improved KT performance.