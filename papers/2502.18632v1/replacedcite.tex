\section{Related Work}
%\ml{A related word is Work :)} \nsf{lol}



\subsection{Knowledge Component Generation} 

Traditional methods for KC creation and tagging rely on human domain experts to identify the knowledge requirements for solving a problem____, a highly time-consuming process.
%This manual process can be aided by tools (e.g., CTAT____) and frameworks (e.g., EAKT____) to help identify the problem-solving steps and associated KCs students must master. 
Recent work has proposed automated approaches for KC discovery and tagging, employing data-driven approaches including the Q-matrix method____. 
In programming, ____ uses a rule-based parser to obtain ASTs with KCs identified at their lowest ontological level, ____ define KCs as nodes in an AST followed by a learning curve analysis to identify KCs students struggle with the
most in Python programming, ____ uses an AST-based neural network to identify student misconceptions, ____ presents a deep learning approach for KC attribution, and ____ learn latent KCs, lacking textual descriptions, by training deep learning models on KT data enforced with priors from pedagogical theory.
%However, these latent KCs lack textual descriptions making them uninterpretable. 
Recent advances in LLMs have inspired automated approaches for descriptive KC generation for dialogues____, and problems in math____, and science____. 
However, we're among the first approaches to present a fully automated, LLM-based pipeline for KC generation and tagging for open-ended programming problems.

\subsection{Knowledge Tracing}
There exists a wide body of work on KT____ in the student modeling literature. 
The classic KT task aims to estimate a student's mastery of KCs from their responses to past problems and use these estimates to predict their future performance.
Classic Bayesian knowledge tracing methods____ use latent binary-valued variables to represent student KC mastery.
With the widespread adoption of neural networks, multiple deep learning-based KT methods were proposed with limited interpretability since student knowledge is modeled as hidden states in these networks.
Most of these methods use long short-term memory networks____ or variants____, with other variants coupling them with memory augmentation____, graph neural networks____, or attention networks____.
KT methods have been applied to many different educational domains, including programming____. Recent work has attempted to leverage LLMs to develop generative KT methods predicting exact student responses to programming problems____. However, to the best of our knowledge, we are the first to present an LLM-based KT method for programming problems that leverages the textual content of KC descriptions, modeling interpretable student mastery levels on each KC, for improved KT performance.