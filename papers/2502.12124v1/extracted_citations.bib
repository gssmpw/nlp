@inproceedings{10.1145/2983323.2983788,
author = {Tan, Jiwei and Wan, Xiaojun and Xiao, Jianguo},
title = {A Neural Network Approach to Quote Recommendation in Writings},
year = {2016},
isbn = {9781450340731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2983323.2983788},
doi = {10.1145/2983323.2983788},
abstract = {Quote is a language phenomenon of transcribing the saying of someone else. Proper usage of quote can usually make the statement more elegant and convincing. However, the ability of quote usage is usually limited by the amount of quotes one remembers or knows. Quote recommendation is a task of exploiting abundant quote repositories to help people make better use of quotes while writing. The task is different from conventional recommendation tasks due to the characteristic of quote. A pilot study has explored this task by using a learning to rank framework and manually designed features. However, it is still hard to model the meaning of a quote, which is an interesting and challenging problem. In this paper, we propose a neural network approach based on LSTMs to the quote recommendation task. We directly learn the distributed meaning representations for the contexts and the quotes, and then measure the relevance based on the meaning representations. In particular, we try to represent the words in quotes with specific embeddings, according to the contexts, topics and even author preferences of the quotes. Experimental results on a large dataset show that our proposed approach achieves the state-of-the-art performance and it outperforms several strong baselines.},
booktitle = {Proceedings of the 25th ACM International on Conference on Information and Knowledge Management},
pages = {65–74},
numpages = {10},
keywords = {lstm, quote recommendation, document recommendation, deep learning},
location = {Indianapolis, Indiana, USA},
series = {CIKM '16}
}

@inproceedings{10.1145/3269206.3271702,
author = {Nishida, Kyosuke and Saito, Itsumi and Otsuka, Atsushi and Asano, Hisako and Tomita, Junji},
title = {Retrieve-and-Read: Multi-task Learning of Information Retrieval and Reading Comprehension},
year = {2018},
isbn = {9781450360142},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3269206.3271702},
doi = {10.1145/3269206.3271702},
abstract = {This study considers the task of machine reading at scale (MRS) wherein, given a question, a system first performs the information retrieval (IR) task of finding relevant passages in a knowledge source and then carries out the reading comprehension (RC) task of extracting an answer span from the passages. Previous MRS studies, in which the IR component was trained without considering answer spans, struggled to accurately find a small number of relevant passages from a large set of passages. In this paper, we propose a simple and effective approach that incorporates the IR and RC tasks by using supervised multi-task learning in order that the IR component can be trained by considering answer spans. Experimental results on the standard benchmark, answering SQuAD questions using the full Wikipedia as the knowledge source, showed that our model achieved state-of-the-art performance. Moreover, we thoroughly evaluated the individual contributions of our model components with our new Japanese dataset and SQuAD. The results showed significant improvements in the IR task and provided a new perspective on IR for RC: it is effective to teach which part of the passage answers the question rather than to give only a relevance score to the whole passage.},
booktitle = {Proceedings of the 27th ACM International Conference on Information and Knowledge Management},
pages = {647–656},
numpages = {10},
keywords = {reading comprehension, question answering, information retrieval},
location = {Torino, Italy},
series = {CIKM '18}
}

@inproceedings{10.1145/3626772.3657834,
author = {Cuconasu, Florin and Trappolini, Giovanni and Siciliano, Federico and Filice, Simone and Campagnano, Cesare and Maarek, Yoelle and Tonellotto, Nicola and Silvestri, Fabrizio},
title = {The Power of Noise: Redefining Retrieval for RAG Systems},
year = {2024},
isbn = {9798400704314},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626772.3657834},
doi = {10.1145/3626772.3657834},
abstract = {Retrieval-Augmented Generation (RAG) has recently emerged as a method to extend beyond the pre-trained knowledge of Large Language Models by augmenting the original prompt with relevant passages or documents retrieved by an Information Retrieval (IR) system. RAG has become increasingly important for Generative AI solutions, especially in enterprise settings or in any domain in which knowledge is constantly refreshed and cannot be memorized in the LLM. We argue here that the retrieval component of RAG systems, be it dense or sparse, deserves increased attention from the research community, and accordingly, we conduct the first comprehensive and systematic examination of the retrieval strategy of RAG systems. We focus, in particular, on the type of passages IR systems within a RAG solution should retrieve. Our analysis considers multiple factors, such as the relevance of the passages included in the prompt context, their position, and their number. One counter-intuitive finding of this work is that the retriever's highest-scoring documents that are not directly relevant to the query (e.g., do not contain the answer) negatively impact the effectiveness of the LLM. Even more surprising, we discovered that adding random documents in the prompt improves the LLM accuracy by up to 35\%. These results highlight the need to investigate the appropriate strategies when integrating retrieval with LLMs, thereby laying the groundwork for future research in this area.},
booktitle = {Proceedings of the 47th International ACM SIGIR Conference on Research and Development in Information Retrieval},
pages = {719–729},
numpages = {11},
keywords = {information retrieval, llm, rag},
location = {Washington DC, USA},
series = {SIGIR '24}
}

@inproceedings{bendersky-smith-2012-dictionary,
    title = "A Dictionary of Wisdom and Wit: Learning to Extract Quotable Phrases",
    author = "Bendersky, Michael  and
      Smith, David",
    booktitle = "Proceedings of the {NAACL}-{HLT} 2012 Workshop on Computational Linguistics for Literature",
    month = jun,
    year = "2012",
    address = "Montr{\'e}al, Canada",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/W12-2510",
    pages = "69--77",
}

@misc{kim2024reragimprovingopendomainqa,
      title={RE-RAG: Improving Open-Domain QA Performance and Interpretability with Relevance Estimator in Retrieval-Augmented Generation}, 
      author={Kiseung Kim and Jay-Yoon Lee},
      year={2024},
      eprint={2406.05794},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2406.05794}, 
}

@inproceedings{kongyoung-etal-2022-monoqa,
    title = "mono{QA}: Multi-Task Learning of Reranking and Answer Extraction for Open-Retrieval Conversational Question Answering",
    author = "Kongyoung, Sarawoot  and
      Macdonald, Craig  and
      Ounis, Iadh",
    editor = "Goldberg, Yoav  and
      Kozareva, Zornitsa  and
      Zhang, Yue",
    booktitle = "Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing",
    month = dec,
    year = "2022",
    address = "Abu Dhabi, United Arab Emirates",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.emnlp-main.485",
    doi = "10.18653/v1/2022.emnlp-main.485",
    pages = "7207--7218",
    abstract = "To address the Conversational Question Answering (ORConvQA) task, previous work has considered an effective three-stage architecture, consisting of a retriever, a reranker, and a reader to extract the answers. In order to effectively answer the users{'} questions, a number of existing approaches have applied multi-task learning, such that the same model is shared between the reranker and the reader. Such approaches also typically tackle reranking and reading as classification tasks. On the other hand, recent text generation models, such as monoT5 and UnifiedQA, have been shown to respectively yield impressive performances in passage reranking and reading. However, no prior work has combined monoT5 and UnifiedQA to share a single text generation model that directly extracts the answers for the users instead of predicting the start/end positions in a retrieved passage. In this paper, we investigate the use of Multi-Task Learning (MTL) to improve performance on the ORConvQA task by sharing the reranker and reader{'}s learned structure in a generative model. In particular, we propose monoQA, which uses a text generation model with multi-task learning for both the reranker and reader. Our model, which is based on the T5 text generation model, is fine-tuned simultaneously for both reranking (in order to improve the precision of the top retrieved passages) and extracting the answer. Our results on the OR-QuAC and OR-CoQA datasets demonstrate the effectiveness of our proposed model, which significantly outperforms existing strong baselines with improvements ranging from +12.31{\%} to +19.51{\%} in MAP and from +5.70{\%} to +23.34{\%} in F1 on all used test sets.",
}

@inproceedings{lee,
author = {Lee, Hanbit and Ahn, Yeonchan and Lee, Haejun and Ha, Seungdo and Lee, Sang-goo},
title = {Quote Recommendation in Dialogue Using Deep Neural Network},
year = {2016},
isbn = {9781450340694},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2911451.2914734},
doi = {10.1145/2911451.2914734},
abstract = {Quotes, or quotations, are well known phrases or sentences that we use for various purposes such as emphasis, elaboration, and humor. In this paper, we introduce a task of recommending quotes which are suitable for given dialogue context and we present a deep learning recommender system which combines recurrent neural network and convolutional neural network in order to learn semantic representation of each utterance and construct a sequence model for the dialog thread. We collected a large set of twitter dialogues with quote occurrences in order to evaluate proposed recommender system. Experimental results show that our approach outperforms not only the other state-of-the-art algorithms in quote recommendation task, but also other neural network based methods built for similar tasks.},
booktitle = {Proceedings of the 39th International ACM SIGIR Conference on Research and Development in Information Retrieval},
pages = {957–960},
numpages = {4},
keywords = {quote recommendation, deep neural network, dialogue model},
location = {Pisa, Italy},
series = {SIGIR '16}
}

@inproceedings{maclaughlin-smith-2021-content,
    title = "Content-based Models of Quotation",
    author = "MacLaughlin, Ansel  and
      Smith, David",
    booktitle = "Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume",
    month = apr,
    year = "2021",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.eacl-main.195",
    doi = "10.18653/v1/2021.eacl-main.195",
    pages = "2296--2314",
}

@article{maclaughlin2021context, title={Context-Based Quotation Recommendation}, volume={15}, url={https://ojs.aaai.org/index.php/ICWSM/article/view/18070}, DOI={10.1609/icwsm.v15i1.18070}, abstractNote={While composing a new document, anything from a news article to an email or essay, authors often utilize direct quotes from a variety of sources. Although an author may know what point they would like to make, selecting an appropriate quote for the specific context may be time-consuming and difficult. We therefore propose a novel context-aware quote recommendation system which utilizes the content an author has already written to generate a ranked list of quotable paragraphs and spans of tokens from a given source document. We approach quote recommendation as a variant of open-domain question answering and adapt the state-of-the-art BERT-based methods from open-QA to our task. We conduct experiments on a collection of speech transcripts and associated news articles, evaluating models’ paragraph ranking and span prediction performances. Our experiments confirm the strong performance of BERT-based methods on this task, which outperform bag-of-words and neural ranking baselines by more than 30\% relative across all ranking metrics. Qualitative analyses show the difficulty of the paragraph and span recommendation tasks and confirm the quotability of the best BERT model’s predictions, even if they are not the true selected quotes from the original news articles.}, number={1}, journal={Proceedings of the International AAAI Conference on Web and Social Media}, author={MacLaughlin, Ansel and Chen, Tao and Ayan, Burcu Karagol and Roth, Dan}, year={2021}, month={May}, pages={397-408} }

@inproceedings{nandy-etal-2021-question-answering,
    title = "Question Answering over Electronic Devices: A New Benchmark Dataset and a Multi-Task Learning based {QA} Framework",
    author = "Nandy, Abhilash  and
      Sharma, Soumya  and
      Maddhashiya, Shubham  and
      Sachdeva, Kapil  and
      Goyal, Pawan  and
      Ganguly, NIloy",
    editor = "Moens, Marie-Francine  and
      Huang, Xuanjing  and
      Specia, Lucia  and
      Yih, Scott Wen-tau",
    booktitle = "Findings of the Association for Computational Linguistics: EMNLP 2021",
    month = nov,
    year = "2021",
    address = "Punta Cana, Dominican Republic",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.findings-emnlp.392",
    doi = "10.18653/v1/2021.findings-emnlp.392",
    pages = "4600--4609",
    abstract = "Answering questions asked from instructional corpora such as E-manuals, recipe books, etc., has been far less studied than open-domain factoid context-based question answering. This can be primarily attributed to the absence of standard benchmark datasets. In this paper, we meticulously create a large amount of data connected with E-manuals and develop a suitable algorithm to exploit it. We collect E-Manual Corpus, a huge corpus of 307,957 E-manuals, and pretrain RoBERTa on this large corpus. We create various benchmark QA datasets which include question answer pairs curated by experts based upon two E-manuals, real user questions from Community Question Answering Forum pertaining to E-manuals etc. We introduce EMQAP (E-Manual Question Answering Pipeline) that answers questions pertaining to electronics devices. Built upon the pretrained RoBERTa, it harbors a supervised multi-task learning framework which efficiently performs the dual tasks of identifying the section in the E-manual where the answer can be found and the exact answer span within that section. For E-Manual annotated question-answer pairs, we show an improvement of about 40{\%} in ROUGE-L F1 scores over most competitive baseline. We perform a detailed ablation study and establish the versatility of EMQAP across different circumstances. The code and datasets are shared at \url{https://github.com/abhi1nandy2/EMNLP-2021-Findings}, and the corresponding project website is \url{https://sites.google.com/view/emanualqa/home}.",
}

@misc{nian2024wragweaklysuperviseddense,
      title={W-RAG: Weakly Supervised Dense Retrieval in RAG for Open-domain Question Answering}, 
      author={Jinming Nian and Zhiyuan Peng and Qifan Wang and Yi Fang},
      year={2024},
      eprint={2408.08444},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2408.08444}, 
}

@inproceedings{quoteR,
  title={QuoteR: A Benchmark of Quote Recommendation for Writing},
  author={Qi, Fanchao and Yang, Yanhui and Yi, Jing and Cheng, Zhili and Liu, Zhiyuan and Sun, Maosong},
  booktitle={Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
  pages={336--348},
  year={2022}
}

@article{tan2015learning, title={Learning to Recommend Quotes for Writing}, volume={29}, url={https://ojs.aaai.org/index.php/AAAI/article/view/9530}, DOI={10.1609/aaai.v29i1.9530}, abstractNote={ &lt;p&gt; In this paper, we propose and address a novel task of recommending quotes for writing. Quote is short for quotation, which is the repetition of someone else’s statement or thoughts. It is a common case in our writing when we would like to cite someone’s statement, like a proverb or a statement by some famous people, to make our composition more elegant or convincing. However, sometimes we are so eager to make a citation of quote somewhere, but have no idea about the relevant quote to express our idea. Because knowing or remembering so many quotes is not easy, it is exciting to have a system to recommend relevant quotes for us while writing. In this paper we tackle this appealing AI task, and build up a learning framework for quote recommendation. We collect abundant quotes from the Internet, and mine real contexts containing these quotes from large amount of electronic books, to build up a dataset for experiments. We explore the particular features of this task, and propose a few useful features to model the characteristics of quotes and the relevance of quotes to contexts. We apply a supervised learning to rank model to integrate multiple features. Experiment results show that, our proposed approach is appropriate for this task and it outperforms other recommendation methods. &lt;/p&gt; }, number={1}, journal={Proceedings of the AAAI Conference on Artificial Intelligence}, author={Tan, Jiwei and Wan, Xiaojun and Xiao, Jianguo}, year={2015}, month={Feb.} }

@inproceedings{vosk,
  title={News article retrieval in context for event-centric narrative creation},
  author={Voskarides, Nikos and Meij, Edgar and Sauer, Sabrina and de Rijke, Maarten},
  booktitle={Proceedings of the 2021 ACM SIGIR International Conference on Theory of Information Retrieval},
  pages={103--112},
  year={2021}
}

@inproceedings{wang-etal-2021-retrieval,
    title = "Retrieval, Re-ranking and Multi-task Learning for Knowledge-Base Question Answering",
    author = "Wang, Zhiguo  and
      Ng, Patrick  and
      Nallapati, Ramesh  and
      Xiang, Bing",
    editor = "Merlo, Paola  and
      Tiedemann, Jorg  and
      Tsarfaty, Reut",
    booktitle = "Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume",
    month = apr,
    year = "2021",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.eacl-main.26",
    doi = "10.18653/v1/2021.eacl-main.26",
    pages = "347--357",
    abstract = "Question answering over knowledge bases (KBQA) usually involves three sub-tasks, namely topic entity detection, entity linking and relation detection. Due to the large number of entities and relations inside knowledge bases (KB), previous work usually utilized sophisticated rules to narrow down the search space and managed only a subset of KBs in memory. In this work, we leverage a \textit{retrieve-and-rerank} framework to access KBs via traditional information retrieval (IR) method, and re-rank retrieved candidates with more powerful neural networks such as the pre-trained BERT model. Considering the fact that directly assigning a different BERT model for each sub-task may incur prohibitive costs, we propose to share a BERT encoder across all three sub-tasks and define task-specific layers on top of the shared layer. The unified model is then trained under a multi-task learning framework. Experiments show that: (1) Our IR-based retrieval method is able to collect high-quality candidates efficiently, thus enables our method adapt to large-scale KBs easily; (2) the BERT model improves the accuracy across all three sub-tasks; and (3) benefiting from multi-task learning, the unified model obtains further improvements with only 1/3 of the original parameters. Our final model achieves competitive results on the SimpleQuestions dataset and superior performance on the FreebaseQA dataset.",
}

@inproceedings{wang_trans,
  title={Quotation Recommendation and Interpretation Based on Transformation from Queries to Quotations},
  author={Wang, Lingzhi and Zeng, Xingshan and Wong, Kam-Fai},
  booktitle={Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 2: Short Papers)},
  pages={754--758},
  year={2021}
}

