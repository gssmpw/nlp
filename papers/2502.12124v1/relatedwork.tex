\section{Related work}
%Numerous studies that analyze quote identification and recommendation processes utilizing information from well-known books, newspapers, magazines, different websites, etc. can be found in the research literature.\\ %The literature can be divided into four major parts -- a) quote identification, where the aim is to distinguish between quotable and non-quotable phrases based on certain linguistic features, b) given a context, quote recommendation (QR) attempts to recommend quotes from a list of available quotes, c) quotable paragraph identification, where the goal is to rank the most quotable paragraphs in the source document given the context,  and d) quote identification and recommendation, which attempts to simultaneously rank the paragraphs and recommend the most quotable phrase from a source document, given a context. We illustrate the recent works which cover each of those categories of research. \\
\noindent\textbf{Quotability detection}:
\textcolor{black}{\citet{bendersky-smith-2012-dictionary} developed a quotable phrase extraction process that includes a supervised quotable phrase detection using lexical and syntactic features. \citet{wang_trans} introduced a transformation matrix that directly maps the query representations to quotation representations. \citet{maclaughlin-smith-2021-content} utilized BERT-based models for ranking the quotable paragraphs while evaluating on five different datasets. \citet{vosk} discussed challenges of retrieving news articles in the context of developing event-centric narratives.} 

\noindent\textbf{Context based quote recommendation}:
\textcolor{black}{\citet{tan2015learning} proposed a learning-to-rank framework for quote recommendation. %for the quote recommendation task, using 16 hand-crafted features. 
\citet{10.1145/2983323.2983788} proposed a quote recommendation framework by learning the distributed meaning representations for the contexts and the quotes using LSTM. \citet{lee} built a quote recommender system to predict quotes based on Twitter dialogues as context. 
\citet{quoteR} built a large and the first publicly available dataset for quote recommendation. \citet{maclaughlin2021context} attempted to simultaneously rank the most quotable paragraphs and predict the most quotable spans from source transcripts modeling quote recommendation as an openQA problem.}\\ 
% \noindent\textbf{Quotable paragraph retrieval}: \textcolor{black}{Given a context, the task is to identify the most relevant paragraph from a list of paragraphs where the quote can be present.} \citet{maclaughlin-smith-2021-content} utilized BERT-based models for ranking the quotable paragraphs evaluating on five different datasets. \citet{vosk} discussed challenges of retrieving news articles in the context of developing event-centric narratives.\\ 
% \noindent\textbf{Quote identification and recommendation simultaneously}: \textcolor{black}{This is a combination of the above tasks, where the goal is to simultaneously identify the quotable paragraph and recommend a quotable span/phrase given a context.} To the best of our knowledge \citet{maclaughlin2021context} made the first attempt to simultaneously rank the most quotable paragraphs and predict the most quotable spans from source transcripts modeling quote recommendation as an open-QA problem.\\ 
\if{0}\noindent\textbf{RAG and multi-task learning for openQA}: \textcolor{black}{Recently, retrieval augmented generation (RAG) based approach receives huge attention for different knowledge intensive NLP tasks. \citet{10.1145/3626772.3657834} thoroughly examines the importance of retrieval phase in a RAG based system. \citet{kim2024reragimprovingopendomainqa,nian2024wragweaklysuperviseddense} employ RAG based method for openQA tasks.  Multi-task learning has been widely used in the context of reading comprehension tasks, where multiple complementary tasks are simultaneously learnt to improve the main task's performance. Few lines of work \cite{10.1145/3269206.3271702, nandy-etal-2021-question-answering, wang-etal-2021-retrieval} jointly trained retriever and reader using embedding models to predict final answer given a question. \citet{kongyoung-etal-2022-monoqa} used encoder-decoder based model to extract answer spans. However, multi-task learning has not been explored in the domain of quotes extraction.}\\ 
\fi
\noindent\textbf{The present work}: We extend the work of \citet{maclaughlin2021context}, by proposing a novel retriever augmented multi-task reader based quote extraction. The framework employs a \textit{vector-store} based paragraph retriever followed by a decoder-only transformer based re-ranker and a novel multi-task based reader containing a sequence tagging module for identifying quotable phrases along with context aware span prediction. We curate three datasets of different genres and evaluate our approach. Our method outperforms all the previous baselines and generalizes better in a cross-domain few-shot setting.