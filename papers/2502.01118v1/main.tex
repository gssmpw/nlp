%%%%%%%% ICML 2025 EXAMPLE LATEX SUBMISSION FILE %%%%%%%%%%%%%%%%%

\documentclass{article}

% Recommended, but optional, packages for figures and better typesetting:
\usepackage{microtype}
\usepackage{graphicx}
\usepackage{subfigure}
\usepackage{booktabs} % for professional tables


% Recommended, but optional, packages for figures and better typesetting:
\usepackage{url}
\usepackage{amsfonts}
\usepackage{nicefrac}
\usepackage{wrapfig}
\usepackage{float}
\usepackage{bbm}
\usepackage[english]{babel}
% \usepackage{subcaption}

% \usepackage[noend]{algorithmic}
\usepackage{algorithmic}

\usepackage{lipsum}

% \usepackage{algpseudocode}

\usepackage{makecell}
\usepackage{tikz}
\usepackage{array,multirow,graphicx}

\usepackage[toc,page]{appendix}

\usepackage{commath}
\usepackage{mdframed}

% Attempt to make hyperref and algorithmic work together better:
\newcommand{\theHalgorithm}{\arabic{algorithm}}

% For theorems and such
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{mathtools}
\usepackage{amsthm}

% For remark
\usepackage{todonotes}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% THEOREMS
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% \theoremstyle{plain}
% \newtheorem{theorem}{Theorem}[section]
% \newtheorem{proposition}[theorem]{Proposition}
% \newtheorem{lemma}[theorem]{Lemma}
% \newtheorem{corollary}[theorem]{Corollary}
% \theoremstyle{definition}
% \newtheorem{definition}[theorem]{Definition}
% \newtheorem{assumption}[theorem]{Assumption}
% \theoremstyle{remark}
% \newtheorem{remark}[theorem]{Remark}

\newtheorem{theorem}{Theorem}
\newtheorem{corollary}{Corollary}
%\newtheorem{corollary}{Corollary}[theorem]
%\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{lemma}{Lemma}
%\newtheorem{assumption}[theorem]{Assumption}
\newtheorem{proposition}{Proposition}
\newtheorem{assumption}{Assumption}
\newtheorem{definition}{Definition}
\newtheorem{condition}{Condition}


\newcommand{\squishlisttwo}{
 \begin{list}{$\bullet$}
  { \setlength{\itemsep}{1pt}
     \setlength{\parsep}{0pt}
    \setlength{\topsep}{0pt}
    \setlength{\partopsep}{0pt}
    \setlength{\leftmargin}{1em}
    \setlength{\labelwidth}{1.5em}
    \setlength{\labelsep}{0.5em} } }
\newcommand{\squishend}{
  \end{list}  }

\makeatletter
\def\blankfootnote{\xdef\@thefnmark{}\@footnotetext}
\makeatother


\usepackage{tikz}
\usetikzlibrary{decorations.pathreplacing,calc}
\newcommand{\tikzmark}[1]{\tikz[overlay,remember picture] \node (#1) {};}

\newcommand*{\AddNote}[4]{%
    \begin{tikzpicture}[overlay, remember picture]
        \draw [decoration={brace,amplitude=0.5em},decorate,ultra thick,red]
            ($(#3)!(#1.north)!($(#3)-(0,1)$)$) --  
            ($(#3)!(#2.south)!($(#3)-(0,1)$)$)
                node [align=center, text width=1.0cm, pos=0.5, anchor=west] {#4};
    \end{tikzpicture}
}%

\usepackage{tcolorbox}
\newtcolorbox[auto counter, number freestyle={\noexpand\arabic{\tcbcounter}}]{mycolorbox}[3][]{%
    fonttitle=\bfseries,
    % title=Example~#2~\thetcbcounter: #3,
    title=#3,
    colback=blue!5!white,
    colframe=purple!75!black,
    #1
}

\usepackage{hyperref}

% if you use cleveref..
\usepackage[capitalize,noabbrev]{cleveref}
\crefformat{footnote}{#2\footnotemark[#1]#3}

% If accepted, instead use the following line for the camera-ready submission:
% \usepackage{icml2025}
\usepackage[accepted]{icml2025}

\newcommand{\algts}{\texttt{TS-LLM}}
\newcommand{\algro}{\texttt{RO-LLM}}
\newcommand{\algtsduel}{\texttt{TS-LLM-DB}}

% if you use cleveref..
\usepackage[capitalize,noabbrev]{cleveref}

\icmltitlerunning{Large Language Model-Enhanced Multi-Armed Bandits}

\begin{document}

\twocolumn[
\icmltitle{Large Language Model-Enhanced Multi-Armed Bandits}

\icmlsetsymbol{equal}{*}

\begin{icmlauthorlist}
\icmlauthor{Jiahang Sun}{equal,tj}
\icmlauthor{Zhiyong Wang}{equal,cuhk}
\icmlauthor{Runhan Yang}{equal,cuhksz}
\icmlauthor{Chenjun Xiao}{cuhksz}
\icmlauthor{John C.S. Lui}{cuhk}
\icmlauthor{Zhongxiang Dai}{cuhksz}
% \icmlauthor{Firstname7 Lastname7}{comp}
% \icmlauthor{Firstname8 Lastname8}{sch}
% \icmlauthor{Firstname8 Lastname8}{yyy,comp}
\end{icmlauthorlist}

\icmlaffiliation{tj}{Tongji University}
\icmlaffiliation{cuhk}{The Chinese University of Hong Kong}
\icmlaffiliation{cuhksz}{The Chinese University of Hong Kong, Shenzhen}

\icmlcorrespondingauthor{Zhongxiang Dai}{daizhongxiang@cuhk.edu.cn}

\icmlkeywords{Large language models, multi-armed bandits, LLM-based agents}

\vskip 0.3in
]

% this must go after the closing bracket ] following \twocolumn[ ...

% This command actually creates the footnote in the first column
% listing the affiliations and the copyright notice.
% The command takes one argument, which is text to display at the start of the footnote.
% The \icmlEqualContribution command is standard text for equal contribution.
% Remove it (just {}) if you do not need this facility.

%\printAffiliationsAndNotice{}  % leave blank if no need to mention equal contribution
\printAffiliationsAndNotice{\icmlEqualContribution} % otherwise use the standard text.

\begin{abstract}
Large language models (LLMs) have been adopted to solve sequential decision-making tasks such as multi-armed bandits (MAB), in which an LLM is directly instructed to select the arms to pull in every iteration. However, this paradigm of \emph{direct arm selection} using LLMs has been shown to be suboptimal in many MAB tasks. Therefore, we propose an alternative approach which combines the strengths of classical MAB and LLMs. Specifically, we adopt a classical MAB algorithm as the high-level framework and leverage the strong \emph{in-context learning} capability of LLMs to perform the sub-task of reward prediction. Firstly, we incorporate the LLM-based reward predictor into the classical \emph{Thompson sampling} (TS) algorithm and adopt a decaying schedule for the LLM temperature to ensure a transition from exploration to exploitation. Next, we incorporate the LLM-based reward predictor (with a temperature of $0$) into a \emph{regression oracle}-based MAB algorithm equipped with an explicit exploration mechanism. We also extend our TS-based algorithm to \emph{dueling bandits} where only the preference feedback between pairs of arms is available, which requires non-trivial algorithmic modifications. We conduct empirical evaluations using both synthetic MAB tasks and experiments designed using real-world text datasets, in which the results show that our algorithms consistently outperform previous baseline methods based on direct arm selection. Interestingly, we also demonstrate that in challenging tasks where the arms lack semantic meanings that can be exploited by the LLM, our approach achieves considerably better performance than LLM-based direct arm selection.
\end{abstract}

\section{Introduction}
\label{sec:intro}
\input{tex_files/introduction}

\section{Problem Setting}
\label{sec:problem}
\input{tex_files/problem_setting}

\section{LLM-Enhanced MAB Algorithms}
\label{sec:algo}
\input{tex_files/algo}

\section{Experiments}
\label{sec:experiments}
\input{tex_files/experiments}

% \vspace{-1mm}
\section{Related Work}
% \vspace{-1mm}
\label{sec:related:work}
\input{tex_files/related_work}

% \vspace{-1mm}
\section{Conclusion}
% \vspace{-1mm}
\label{sec:conclusion}
\input{tex_files/conclusion}


\newpage
\section*{Impact Statements}
This paper presents work whose goal is to advance the field of Machine Learning. There are many potential societal consequences of our work, none which we feel must be specifically highlighted here.

\bibliography{references}
\bibliographystyle{icml2025}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% APPENDIX
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newpage
\appendix
\onecolumn
\input{tex_files/appendix}

\end{document}


% This document was modified from the file originally made available by
% Pat Langley and Andrea Danyluk for ICML-2K. This version was created
% by Iain Murray in 2018, and modified by Alexandre Bouchard in
% 2019 and 2021 and by Csaba Szepesvari, Gang Niu and Sivan Sabato in 2022.
% Modified again in 2023 and 2024 by Sivan Sabato and Jonathan Scarlett.
% Previous contributors include Dan Roy, Lise Getoor and Tobias
% Scheffer, which was slightly modified from the 2010 version by
% Thorsten Joachims & Johannes Fuernkranz, slightly modified from the
% 2009 version by Kiri Wagstaff and Sam Roweis's 2008 version, which is
% slightly modified from Prasad Tadepalli's 2007 version which is a
% lightly changed version of the previous year's version by Andrew
% Moore, which was in turn edited from those of Kristian Kersting and
% Codrina Lauth. Alex Smola contributed to the algorithmic style files.
