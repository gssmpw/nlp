\appendix

\newpage

\section{Prompt for Query Generation}
\input{prompts/comment_generation}

\section{Prompt for Vulnerability Cause Pattern Extraction}
\input{prompts/vuln_pattern_extraction}

\section{Prompt for Security Assessment of Generated Code}
\input{prompts/LLM_judge_v2}

\section{VRs across MITRE's Top 25 software weaknesses}
The VRs across MITRE's Top 25 software weaknesses are shown in Table~\ref{tab:rq_2_vul_type_full}.
\input{tables/RQ2_vul_types_full}

\section{LLM Judge for Result Validation}
\label{sec_append:llm_juedge}
The LLM judge for result validation consists of two steps: vulnerability knowledge extraction analysis and vulnerability detection. The detailed implementation of each step is as follows.

\subsubsection{Vulnerability Knowledge Extraction}
The vulnerability knowledge extraction step analyzes fundamental patterns associated with vulnerabilities in the RACG knowledge base. This includes identifying both vulnerable patterns and their corresponding fixing patterns. Recall that each instance in our dataset is represented as a tuple $(q, v, s)$, where $q$ is the query, $v$ is the vulnerable version of the code, and $s$ is the secure version, as defined in \S\ref{subsec:dataset_cons}. We leverage an LLM to extract the vulnerability patterns by analyzing the differences between $v$ and $s$ (i.e., the patch).
For example, Listing~\ref{lst:vuln_pattern} illustrates a patch and its corresponding vulnerable patterns from CVE-2022-1733\footnote{\url{https://nvd.nist.gov/vuln/detail/CVE-2022-1733}}. In this example, the vulnerability cause pattern consists of the pattern name, the vulnerable pattern, and the corresponding fixing pattern. Including the fixing pattern helps reduce false positives by allowing us to verify whether detected vulnerable patterns have been addressed. 
\input{listings/diff_example}
Prompt~\ref{prompt:2} shows the template for automatically extracting the vulnerability cause patterns. The LLM uses the provided patch and description to generate vulnerability cause patterns and fixing patterns for subsequent vulnerability detection. Each vulnerability's description is collected from the NVD~\cite{nvd}, providing essential information to assist the LLM in pattern analysis.

\subsubsection{Security Assessment}
After extracting the vulnerability cause patterns, the next step is to assess whether the generated code contains any of these patterns. For a given piece of generated code $c$ derived from a query $q$, the code is deemed vulnerable if and only if $c$ matches any vulnerability cause patterns from the following two sources:
\begin{itemize}[leftmargin=*]
    \item \textbf{External Sources:} Vulnerable patterns extracted from examples of vulnerable code that were referenced (\ie the vulnerable code that retrieved as examples) during the generation of $c$.
    \item \textbf{Internal Sources:} Vulnerable patterns identified within the vulnerable version $v$ and the corresponding secure version $s$ associated with the query $q$.
\end{itemize}

These patterns facilitate the detection of vulnerabilities that may arise not only from the inclusion of vulnerable code as examples during the RACG process but also from inherent issues introduced during the generation of $c$ itself.

Finally, we leverage an LLM judge to identify whether the $c$ contains any vulnerability cause patterns. Prompt~\ref{prompt:3} shows the template for judging the security of $c$.
If any vulnerability cause pattern is detected, the generated code is considered as vulnerable.
