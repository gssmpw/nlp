\section{Introduction}

Understanding the structural layout of documents is a fundamental aspect of document analysis and comprehension. Traditional Document Layout Analysis (DLA) methods primarily focus on detecting and classifying basic document elements, e.g., text blocks, images, and tables. While these methods have achieved significant success in document analysis at a superficial level, they often overlook capturing the intricate spatial and logical relations that exist between different document components. This limitation hampers the ability of models to achieve a deeper, more human-like understanding of document structures. Recent advancements in deep learning and computer vision have led to the development of models that can process multimodal information, integrating visual, textual, and layout information \citep{gu2021unidoc, huang2022layoutlmv3}. However, these models still lack the capability to comprehend the complex relations inherent in document layouts, particularly the spatial and logical relations that define the document structure. As shown in Table~\ref{tab:dataset_compare}, existing datasets such as PubLayNet \citep{zhong2019publaynet} and DocLayNet \citep{doclaynet2022} provide annotations for basic layout elements but do not include detailed relational information inside. 

To address these challenges, we propose a novel task called graph-based Document Structure Analysis (\textbf{gDSA}), which aims to not only detect document elements but also generate spatial and logical relations in the form of a graph structure. This approach allows for a more holistic and intuitive understanding of documents, akin to how humans perceive and interpret complex layouts. For this task, we introduce the \textbf{GraphDoc} dataset, a large-scale relation graph-based document structure analysis dataset comprising 80,000 document images and over 4 million relation annotations. GraphDoc includes annotations for both spatial relations (\textit{Up}, \textit{Down}, \textit{Left}, \textit{Right}) and logical relations (\textit{Parent}, \textit{Child}, \textit{Sequence}, \textit{Reference}) between document components, e.g., \textit{text}, \textit{table}, and \textit{picture}. This rich relational information enables models to perform multiple tasks like reading order prediction, hierarchical structure analysis, and complex inter-element relationship inference. To tackle the gDSA task, we propose the \textbf{Document Relation Graph Generator (DRGG)}, an end-to-end architecture designed to generate relational graphs from document layouts. DRGG combines object detection with relation prediction, capturing both spatial and logical relations between document elements. Our experiments demonstrate that DRGG achieves a mean Average Precision of 57.6\% at a relation confidence threshold of 0.5 ($mAP_g$@0.5), setting a strong baseline for this novel task and dataset.

In summary, our contributions are as follows:

\begin{itemize} 
    \item We introduce \textbf{GraphDoc}, a graph-based document structure analysis dataset that provides detailed annotations of both spatial and logical relations between document components. 
    \item We provide a comprehensive analysis of graph-based Document Structure Analysis (gDSA) paradigms and demonstrate that our \textbf{DRGG} model effectively addresses the gDSA task.
    \item We conduct extensive experiments on the GraphDoc dataset and upstream DLA tasks, proving the effectiveness of the gDSA approach for document layout analysis. 
\end{itemize}


\input{table/data_compare}

