\section{Generating and evaluating \SCEs}


We formally describe the process of generating \SCEs and then list the metrics used to evaluate their quality.

\subsection{Generating counterfactuals}
\label{sec:ce_gen}
We consider datasets of the form $\Dcal = \{(\xb_i, y_i)\}_{i=1}^N$. $\xb$ are input texts, \eg, social media posts or math problems. $y_i \in \Ycal$ are either discrete labels, \eg, sentiment of a social media post, or integers from a predefined finite set, \eg, solution to a math problem. The model prediction and explanation process consists of the following steps.
Precise prompts for each step are shown in~\autoref{app:prompts}.


\xhdr{Step 1: Input and output} Given the input $\xb$, we denote the model output by $\hat{y} = f(\xb) \in \Ycal$. For instruction-tuned LLMs, this step involves encapsulating the input $\xb$ into a natural language prompt before passing it through the model, see for example  the work by \citet{dubey2024llama}. We detail these steps in~\autoref{app:prompts}. The outputs of LLMs are often natural language and one needs to employ some post-processing to convert them to the desired output domain $\Ycal$. For the sake of notational simplicity, we do not explicitly state these post-processing steps here but describe them in~\autoref{app:post}. 

\xhdr{Step 2: Generating \SCEs}
A counterfactual explanation $\xbce$ is a modified version of the original input $\xb$ that would lead the model to change its decision, that is $f(\xb) \neq f(\xbce)$.
A common strategy for generating counterfactuals is to first identify a counterfactual output $\yce \neq y$ and then solve an optimization problem to generate $\xbce$ such that $f(\xbce) = \yce$~\cite{wachter2017counterfactual, mothilal2020explaining, verma2024counterfactual}. $\yce$ is either chosen at random or in a targeted manner.
Since we are interested in self-explanation properties of LLMs, we do not solve an optimization problem and instead ask the model itself to generate the counterfactual explanation. 

A key desiderata for counterfactual explanations is to keep the differences between $\xb$ and $\xbce$ to a minimum~\cite{verma2024counterfactual}. Our preliminary experiments showed that an \textbf{unconstrained prompting} where the model is simply asked to generate a counterfactual already led to relatively small changes from $\xb$ to $\xbce$ for many models. However, to systematically keep changes to a minimum, we use a \textbf{rationale-based prompting} method as well. This method is inspired by rationale-based explanations~\cite{deyoung2019eraser}. We first ask the model to identify the rationales in the original input that caused the model to predict $\hat{y}$. Next, we ask the model to alter only these rationales such that the output changes to $\yce$.

\xhdr{Step 3: Generating model output on $\xbce$}
Finally, we ask the model to make the prediction on the counterfactual it generated, namely, $\hat{\yce} = f(\xbce)$. While one would expect $\hat{\yce}$ to be the same as $\yce$, we find that in practice this is not always true.

One could ask the model to make this final prediction while the model still retains Steps 1 and 2 in its context window or 
without them. We denote the former as prediction \textbf{with context} and latter as predictions \textbf{without context}. 


\subsection{Evaluating CEs}
\label{sec:ce_eval}

We use the following metrics for evaluating \SCEs.

\xhdrnodot{Generation percentage (\Gen)}  measures the percentage of times a model was able to generate a \SCE. In a vast majority of cases, the models generate a \SCE as instructed. The cases of non-successful generation include the model generating a stop-word like ``.'' or ``!'' or generating a $\xbce$ that is much shorter in length than $\xb$. We describe the detailed filtering process in~\autoref{app:post}.


\xhdrnodot{Counterfactual validity (\Val)} measures the percentage of times the \SCE actually produces the intended target label, \ie, $f(\xbce) = \yce$. As described in Step 3 in Section~\ref{sec:ce_gen}, this final prediction can be made either with Steps 1 and 2 in context or without. We denote the validity without context as \Val and with context as \ValH.


\xhdrnodot{Edit distance (\ED)}  measures the edit distance between the original input $\xb$ and the counterfactual $\xbce$.
Closeness to the original input is a key desideratum of a counterfactual explanation~\cite{wachter2017counterfactual}. Our use of edit distance as the closeness metric is inspired by prior studies on evaluating counterfactual generations~\cite{chatzi2025ce}.
We only report the \ED for valid \SCEs. 
Since the validity of \SCEs is impacted by the presence of Steps 1 and 2 in the generation context (Section~\ref{sec:ce_gen}), we report the edit distance for the in-context case separately and denote it by \EDH.
For simplifying comparisons across datasets of various input lengths, we normalize the edit distance to a percentage by first dividing it by the length of the longer string ($\xb$ or $\xbce$) and then multiplying it by $100$.








