[
  {
    "index": 0,
    "papers": [
      {
        "key": "gilpin2018explaining",
        "author": "Gilpin, Leilani H and Bau, David and Yuan, Ben Z and Bajwa, Ayesha and Specter, Michael and Kagal, Lalana",
        "title": "Explaining explanations: An overview of interpretability of machine learning"
      }
    ]
  },
  {
    "index": 1,
    "papers": [
      {
        "key": "10.1145/3236009",
        "author": "Guidotti, Riccardo and Monreale, Anna and Ruggieri, Salvatore and Turini, Franco and Giannotti, Fosca and Pedreschi, Dino",
        "title": "A Survey of Methods for Explaining Black Box Models"
      }
    ]
  },
  {
    "index": 2,
    "papers": [
      {
        "key": "zhao2024explainability",
        "author": "Zhao, Haiyan and Chen, Hanjie and Yang, Fan and Liu, Ninghao and Deng, Huiqi and Cai, Hengyi and Wang, Shuaiqiang and Yin, Dawei and Du, Mengnan",
        "title": "Explainability for large language models: A survey"
      }
    ]
  },
  {
    "index": 3,
    "papers": [
      {
        "key": "verma2024counterfactual",
        "author": "Verma, Sahil and Boonsanong, Varich and Hoang, Minh and Hines, Keegan and Dickerson, John and Shah, Chirag",
        "title": "Counterfactual explanations and algorithmic recourses for machine learning: A review"
      }
    ]
  },
  {
    "index": 4,
    "papers": [
      {
        "key": "delaney2023counterfactual",
        "author": "Delaney, Eoin and Pakrashi, Arjun and Greene, Derek and Keane, Mark T",
        "title": "Counterfactual explanations for misclassified images: How human and machine explanations differ"
      }
    ]
  },
  {
    "index": 5,
    "papers": [
      {
        "key": "tsiourvas2024manifold",
        "author": "Tsiourvas, Asterios and Sun, Wei and Perakis, Georgia",
        "title": "Manifold-Aligned Counterfactual Explanations for Neural Networks"
      },
      {
        "key": "slack2021counterfactual",
        "author": "Slack, Dylan and Hilgard, Anna and Lakkaraju, Himabindu and Singh, Sameer",
        "title": "Counterfactual explanations can be manipulated"
      }
    ]
  },
  {
    "index": 6,
    "papers": [
      {
        "key": "arvanitidis2016locally",
        "author": "Arvanitidis, Georgios and Hansen, Lars K and Hauberg, S{\\o}ren",
        "title": "A locally adaptive normal distribution"
      }
    ]
  },
  {
    "index": 7,
    "papers": [
      {
        "key": "agarwal2024faithfulness",
        "author": "Agarwal, Chirag and Tanneru, Sree Harsha and Lakkaraju, Himabindu",
        "title": "Faithfulness vs. plausibility: On the (un) reliability of explanations from large language models"
      }
    ]
  },
  {
    "index": 8,
    "papers": [
      {
        "key": "tanneru2024quantifying",
        "author": "Tanneru, Sree Harsha and Agarwal, Chirag and Lakkaraju, Himabindu",
        "title": "Quantifying uncertainty in natural language explanations of large language models"
      }
    ]
  },
  {
    "index": 9,
    "papers": [
      {
        "key": "turpin2024language",
        "author": "Turpin, Miles and Michael, Julian and Perez, Ethan and Bowman, Samuel",
        "title": "Language models don't always say what they think: unfaithful explanations in chain-of-thought prompting"
      },
      {
        "key": "lanham2023measuring",
        "author": "Lanham, Tamera and Chen, Anna and Radhakrishnan, Ansh and Steiner, Benoit and Denison, Carson and Hernandez, Danny and Li, Dustin and Durmus, Esin and Hubinger, Evan and Kernion, Jackson and others",
        "title": "Measuring faithfulness in chain-of-thought reasoning"
      },
      {
        "key": "tanneru2024quantifying",
        "author": "Tanneru, Sree Harsha and Agarwal, Chirag and Lakkaraju, Himabindu",
        "title": "Quantifying uncertainty in natural language explanations of large language models"
      }
    ]
  },
  {
    "index": 10,
    "papers": [
      {
        "key": "chen2023models",
        "author": "Chen, Yanda and Zhong, Ruiqi and Ri, Narutatsu and Zhao, Chen and He, He and Steinhardt, Jacob and Yu, Zhou and McKeown, Kathleen",
        "title": "Do models explain themselves? counterfactual simulatability of natural language explanations"
      }
    ]
  },
  {
    "index": 11,
    "papers": [
      {
        "key": "chen2023models",
        "author": "Chen, Yanda and Zhong, Ruiqi and Ri, Narutatsu and Zhao, Chen and He, He and Steinhardt, Jacob and Yu, Zhou and McKeown, Kathleen",
        "title": "Do models explain themselves? counterfactual simulatability of natural language explanations"
      }
    ]
  },
  {
    "index": 12,
    "papers": [
      {
        "key": "bhattacharjee2024towards",
        "author": "Bhattacharjee, Amrita and Moraffah, Raha and Garland, Joshua and Liu, Huan",
        "title": "Towards llm-guided causal explainability for black-box text classifiers"
      },
      {
        "key": "slack2023explaining",
        "author": "Slack, Dylan and Krishna, Satyapriya and Lakkaraju, Himabindu and Singh, Sameer",
        "title": "Explaining machine learning models with interactive natural language conversations using TalkToModel"
      },
      {
        "key": "nguyen2024llms",
        "author": "Nguyen, Van Bach and Youssef, Paul and Schl{\\\"o}tterer, J{\\\"o}rg and Seifert, Christin",
        "title": "LLMs for Generating and Evaluating Counterfactuals: A Comprehensive Study"
      },
      {
        "key": "li2023prompting",
        "author": "Li, Yongqi and Xu, Mayi and Miao, Xin and Zhou, Shen and Qian, Tieyun",
        "title": "Prompting large language models for counterfactual generation: An empirical study"
      },
      {
        "key": "gat2023faithful",
        "author": "Gat, Yair and Calderon, Nitay and Feder, Amir and Chapanin, Alexander and Sharma, Amit and Reichart, Roi",
        "title": "Faithful explanations of black-box nlp models using llm-generated counterfactuals"
      }
    ]
  },
  {
    "index": 13,
    "papers": [
      {
        "key": "nguyen2024llms",
        "author": "Nguyen, Van Bach and Youssef, Paul and Schl{\\\"o}tterer, J{\\\"o}rg and Seifert, Christin",
        "title": "LLMs for Generating and Evaluating Counterfactuals: A Comprehensive Study"
      }
    ]
  },
  {
    "index": 14,
    "papers": [
      {
        "key": "li2023prompting",
        "author": "Li, Yongqi and Xu, Mayi and Miao, Xin and Zhou, Shen and Qian, Tieyun",
        "title": "Prompting large language models for counterfactual generation: An empirical study"
      }
    ]
  },
  {
    "index": 15,
    "papers": [
      {
        "key": "jacovi2020towards",
        "author": "Jacovi, Alon and Goldberg, Yoav",
        "title": "Towards faithfully interpretable NLP systems: How should we define and evaluate faithfulness?"
      }
    ]
  }
]