\begin{table*}[tb!]
\caption{Model configurations for six representative open-source \lmms{} with an example input image of $896 \times 896$ pixels.}
\centering
\setlength{\tabcolsep}{2pt}
\resizebox{0.97\linewidth}{!}{%
\begin{tabular}{l|c|c|c|c|c|c|c|c}
\toprule
\multirow{2}{*}{\textbf{\lmm Model Name}} &
\multirow{2}{*}{\textbf{Abbreviation}} &
\multirow{2}{*}{\textbf{Architecture}} &
\multirow{2}{*}{\textbf{Tile Size}} &
\textbf{Image Encoder} &
\textbf{Total Image Token Size} &
\textbf{LLM Backend} &
\textbf{Tensor} &
\textbf{Avgerage Accuracy}
\\
& & & &
\textbf{(\#Params)} &
\textbf{($\#Tiles\times{}\#TokensPerTile$)} &
\textbf{(\#Params)} &
\textbf{Parallelism} &
\textbf{(HF-VLM~\cite{vlm-leaderboard})}\\
\midrule
Llama 3.2 Vision 11B ~\cite{llama-3.2-11b-instruct} & Llama3.2-11B & Cross-attention & 560$\times$560 & ViT-H/14 (630M)  & 4 $\times$ 1601 $\times$ 1 = 6404 & Llama 3.1 (8B) & TP-4 & 
\begin{tikzpicture}
    % First progress bar (57.8%)
    \fill[mygray] (0,2.5) rectangle (5,3);
    \fill[red!20] (0,2.5) rectangle (2.865,3);
    \node[right] at (2.9,2.75) {57.8\%};
\end{tikzpicture}\\
Llama 3.2 Vision 90B~\cite{llama-3.2-90b-instruct} & Llama3.2-90B & Cross-attention & 560$\times$560 & ViT-H/14 (630M) & 4 $\times$ 1601 $\times$ 1 = 6404 & Llama 3.1 (70B) & TP-8 & 
\begin{tikzpicture}
    % First progress bar (57.8%)
    \fill[mygray] (0,2.5) rectangle (5,3);
    \fill[yellow!20] (0,2.5) rectangle (3.17,3);
    \node[right] at (3.18,2.75) {63.4\%};
\end{tikzpicture} \\
LLaVA-OneVision 7B~\cite{llava-7b} & LLaVA-OV-7B & Decoder-only & 384$\times$384 & SigLIP (400M)  & 10 $\times$ 729 $\times$ 1 = 7290 & Qwen2 (7B) & TP-4 & \begin{tikzpicture}
    % First progress bar (57.8%)
    \fill[mygray] (0,2.5) rectangle (5,3);
    \fill[yellow!20] (0,2.5) rectangle (3.005,3);
    \node[right] at (3.11,2.75) {60.1\%};
\end{tikzpicture} \\
LLaVA-OneVision 72B~\cite{llava-72b} & LLaVA-OV-72B & Decoder-only & 384$\times$384 & SigLIP (400M)  & 10 $\times$ 729 $\times$ 1 = 7290 & Qwen2 (72B) & TP-8 & \begin{tikzpicture}
    % First progress bar (57.8%)
    \fill[mygray] (0,2.5) rectangle (5,3);
    \fill[green!20] (0,2.5) rectangle (3.4,3);
    \node[right] at (3.5,2.75) {68\%};
\end{tikzpicture}\\
InternVL-2.5 26B~\cite{internvl-26b} & InternVL-26B & Decoder-only & 448$\times$448 & InternViT (6B)& $5 \times 256$ = 1280 & InternLM (20B) & TP-8 & \begin{tikzpicture}
    % First progress bar (57.8%)
    \fill[mygray] (0,2.5) rectangle (5,3);
    \fill[green!20] (0,2.5) rectangle (3.58,3);
    \node[right] at (3.7,2.75) {71.6\%};
\end{tikzpicture} \\
NVLM-D 72B~\cite{nvlm-72b} & NVLM-D-72B & Decoder-only & 448$\times$448 & InternViT (6B) & $5 \times 256$ = 1280 & Qwen2-Instruct (72B) & TP-8 & \begin{tikzpicture}
    % First progress bar (57.8%)
    \fill[mygray] (0,2.5) rectangle (5,3);
    \fill[green!20] (0,2.5) rectangle (3.38,3);
    \node[right] at (3.4,2.75) {67.6\%};
\end{tikzpicture}\\
\bottomrule
\end{tabular}}
% \vspace{-8pt}
\label{table:model-config}
\end{table*}

% llama_11b_acc = 57.8
% llama_90b_acc = 63.4
% llava_ov_7b_acc = 60.1
% llava_ov_72b_acc = 68
% internvl_26b_acc = 71.6
% nvlm_d_72b_acc = 67.6