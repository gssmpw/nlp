% background
@inproceedings{chen2022visualgpt,
  title={{VisualGPT}: Data-efficient adaptation of pretrained language models for image captioning},
  author={Chen, Jun and Guo, Han and Yi, Kai and Li, Boyang and Elhoseiny, Mohamed},
  booktitle={Proceedings of the 2022 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR 2022)},
  pages={18030--18040},
  year={2022}
}

@article{mokady2021clipcap,
  title={{ClipCap}: {CLIP} Prefix for Image Captioning},
  author={Mokady, Ron and Hertz, Amir and Bermano, Amit H},
  journal={arXiv preprint arXiv:2111.09734},
  year={2021}
}

@inproceedings{hu2023promptcap,
  title={{PromptCap}: Prompt-guided image captioning for {VQA} with {GPT}-3},
  author={Hu, Yushi and Hua, Hang and Yang, Zhengyuan and Shi, Weijia and Smith, Noah A and Luo, Jiebo},
  booktitle={Proceedings of the 2023 IEEE/CVF International Conference on Computer Vision (ICCV 2023)},
  pages={2963--2975},
  year={2023}
}

@inproceedings{schwenk2022okvqa,
  title={{A-OKVQA: A benchmark for visual question answering using world knowledge}},
  author={Schwenk, Dustin and Khandelwal, Apoorv and Clark, Christopher and Marino, Kenneth and Mottaghi, Roozbeh},
  booktitle={Proceedings of the European Conference on Computer Vision (ECCV)},
  year={2022},
}

@inproceedings{shao2023prompting,
  title={Prompting large language models with answer heuristics for knowledge-based visual question answering},
  author={Shao, Zhenwei and Yu, Zhou and Wang, Meng and Yu, Jun},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR 2023)},
  year={2023}
}

@article{li2024llava,
  title={{LLaVA-OneVision}: Easy Visual Task Transfer},
  author={Li, Bo and Zhang, Yuanhan and Guo, Dong and Zhang, Renrui and Li, Feng and Zhang, Hao and Zhang, Kaichen and Li, Yanwei and Liu, Ziwei and Li, Chunyuan},
  journal={arXiv preprint arXiv:2408.03326},
  year={2024}
}

@inproceedings{chen2024internvl,
  title={{InternVL}: Scaling up vision foundation models and aligning for generic visual-linguistic tasks},
  author={Chen, Zhe and Wu, Jiannan and Wang, Wenhai and Su, Weijie and Chen, Guo and Xing, Sen and Zhong, Muyan and Zhang, Qinglong and Zhu, Xizhou and Lu, Lewei and others},
  booktitle={Proceedings of the 2024 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR 2024)},
  pages={24185--24198},
  year={2024}
}

@article{team2024gemini,
  title={{Gemini 1.5}: Unlocking multimodal understanding across millions of tokens of context},
  author={Team, Gemini and Georgiev, Petko and Lei, Ving Ian and Burnell, Ryan and Bai, Libin and Gulati, Anmol and Tanzer, Garrett and Vincent, Damien and Pan, Zhufeng and Wang, Shibo and others},
  journal={arXiv preprint arXiv:2403.05530},
  year={2024}
}

@article{liu2024sora,
  title={{Sora: A review on background, technology, limitations, and opportunities of large vision models}},
  author={Liu, Yixin and Zhang, Kai and Li, Yuan and Yan, Zhiling and Gao, Chujie and Chen, Ruoxi and Yuan, Zhengqing and Huang, Yue and Sun, Hanchi and Gao, Jianfeng and others},
  journal={arXiv preprint arXiv:2402.17177},
  year={2024}
}

@article{alexey2020image,
  title={{An image is worth 16x16 words: Transformers for image recognition at scale}},
  author={Alexey, Dosovitskiy},
  journal={arXiv preprint arXiv: 2010.11929},
  year={2020}
}

@inproceedings{zhai_sigmoid_2023,
	title = {{Sigmoid Loss for Language Image Pre-Training}},
	urldate = {2025-01-06},
	booktitle = {2023 IEEE/CVF International Conference on Computer Vision (ICCV)},
	author = {Zhai, Xiaohua and Mustafa, Basil and Kolesnikov, Alexander and Beyer, Lucas},
	year = {2023},
}

@misc{cua2025,
  title={{Computer-Using Agent: Introducing a universal interface for AI to interact with the digital world}},
  author={OpenAI},
  year={2025},
  howpublished={\url{https://openai.com/index/computer-using-agent}},
}

@article{niu2024screenagent,
  title={{ScreenAgent: A Vision Language Model-Driven Computer Control Agent}},
  author={Niu, Runliang and Li, Jindong and Wang, Shiqi and Fu, Yali and Hu, Xiyu and Leng, Xueyuan and Kong, He and Chang, Yi and Wang, Qi},
  journal={arXiv preprint arXiv:2402.07945},
  year={2024}
}

% benchmarks and models
@article{chen2024far,
  title={How Far Are We to {GPT-4V}? {Closing} the Gap to Commercial Multimodal Models with Open-Source Suites},
  author={Chen, Zhe and Wang, Weiyun and Tian, Hao and Ye, Shenglong and Gao, Zhangwei and Cui, Erfei and Tong, Wenwen and Hu, Kongzhi and Luo, Jiapeng and Ma, Zheng and others},
  journal={arXiv preprint arXiv:2404.16821},
  year={2024}
}

@misc{tensor-rt,
  author = {{NVIDIA}},
  title = {{NVIDIA TensoRT}},
  year = {2024},
  howpublished={\url{https://github.com/NVIDIA/TensorRT}}
}

@misc{hf-transformers,
  author = {{HuggingFace}},
  title = {{HuggingFace Transformers}},
  year = {2024},
  howpublished={\url{https://huggingface.co/docs/transformers/en/index}}
}

@misc{ittt,
  author = {{HuggingFace}},
  title = {{Image-Text-to-Text Models}},
  year = {2024},
  howpublished={\url{https://huggingface.co/models?pipeline_tag=image-text-to-text}}
}

@misc{vttt,
  author = {{HuggingFace}},
  title = {{Video-Text-to-Text Models}},
  year = {2024},
  howpublished={\url{https://huggingface.co/models?pipeline_tag=video-text-to-text}}
}

@misc{attt,
  author = {{HuggingFace}},
  title = {{Audio-Text-to-Text Models}},
  year = {2024},
  howpublished={\url{https://huggingface.co/models?pipeline_tag=audio-text-to-text}}
}

@misc{llava-ov,
  title={{LLaVA-OneVision: Easy Visual Task Transfer}}, 
  author={Bo Li and Yuanhan Zhang and Dong Guo and Renrui Zhang and Feng Li and Hao Zhang and Kaichen Zhang and Peiyuan Zhang and Yanwei Li and Ziwei Liu and Chunyuan Li},
  year={2024},
  eprint={2408.03326},
  archivePrefix={arXiv},
  primaryClass={cs.CV},
  url={https://arxiv.org/abs/2408.03326}, 
}

@misc{nvlm,
  title={{NVLM: Open Frontier-Class Multimodal LLMs}}, 
  author={Wenliang Dai and Nayeon Lee and Boxin Wang and Zhuolin Yang and Zihan Liu and Jon Barker and Tuomas Rintamaki and Mohammad Shoeybi and Bryan Catanzaro and Wei Ping},
  year={2024},
  eprint={2409.11402},
  archivePrefix={arXiv},
  primaryClass={cs.CL},
  url={https://arxiv.org/abs/2409.11402}, 
}

@article{llama3,
  title={{Llama Guard 3 Vision}: Safeguarding Human-{AI} Image Understanding Conversations},
  author={Chi, Jianfeng and Karn, Ujjwal and Zhan, Hongyuan and Smith, Eric and Rando, Javier and Zhang, Yiming and Plawiak, Kate and Coudert, Zacharie Delpierre and Upasani, Kartikeya and Pasupuleti, Mahesh},
  journal={arXiv preprint arXiv:2411.10414},
  year={2024}
}

@article{alayrac2022flamingo,
  title={{Flamingo: a Visual Language Model for Few-Shot Learning}},
  author={Alayrac, Jean-Baptiste and Donahue, Jeff and Luc, Pauline and Miech, Antoine and Barr, Iain and Hasson, Yana and Lenc, Karel and Mensch, Arthur and Millican, Katherine and Reynolds, Malcolm and others},
  journal={2024 Conference on Neural Information Processing Systems (NeurIPS 2024)},
  volume={35},
  pages={23716--23736},
  year={2022}
}

@misc{janus,
  title={{Janus-Pro}: Unified Multimodal Understanding and Generation with Data and Model Scaling}, 
  author={Xiaokang Chen and Zhiyu Wu and Xingchao Liu and Zizheng Pan and Wen Liu and Zhenda Xie and Xingkai Yu and Chong Ruan},
  year={2025},
}

@misc{llama-3.2-11b-instruct,
  author = {{Meta AI}},
  title = {{HuggingFace Model: meta-llama/Llama-3.2-11B-Vision-Instruct}},
  year = {2024},
  howpublished = {\url{https://huggingface.co/meta-llama/Llama-3.2-11B-Vision-Instruct}}
}

@misc{llama-3.2-90b-instruct,
  author = {{Meta AI}},
  title = {{HuggingFace Model: meta-llama/Llama-3.2-90B-Vision-Instruct}},
  year = {2024},
  howpublished = {\url{https://huggingface.co/meta-llama/Llama-3.2-90B-Vision-Instruct}}
}

@misc{llava-7b,
  author = {{Li, Bo and Zhang, Yuanhan and Guo, Dong and Zhang, Renrui and Li, Feng and Zhang, Hao and Zhang, Kaichen and Li, Yanwei and Liu, Ziwei and Li, Chunyuan}},
  title = {{HuggingFace Model: lmms-lab/llava-onevision-qwen2-7b-ov}},
  year = {2024},
  howpublished = {\url{https://huggingface.co/lmms-lab/llava-onevision-qwen2-7b-ov}}
}

@misc{llava-72b,
  author = {{Li, Bo and Zhang, Yuanhan and Guo, Dong and Zhang, Renrui and Li, Feng and Zhang, Hao and Zhang, Kaichen and Li, Yanwei and Liu, Ziwei and Li, Chunyuan}},
  title = {{HuggingFace Model: lmms-lab/llava-onevision-qwen2-72b-ov-sft}},
  year = {2024},
  howpublished = {\url{https://huggingface.co/lmms-lab/llava-onevision-qwen2-72b-ov-sft}}
}

@misc{internvl-26b,
  author = {{Chen, Zhe and Wu, Jiannan and Wang, Wenhai and Su, Weijie and Chen, Guo and Xing, Sen and Zhong, Muyan and Zhang, Qinglong and Zhu, Xizhou and Lu, Lewei and others}},
  title = {{HuggingFace Model: OpenGVLab/InternVL2\_5-26B}},
  year = {2024},
  howpublished = {\url{https://huggingface.co/OpenGVLab/InternVL2_5-26B}}
}

@misc{nvlm-72b,
  author = {{Dai, Wenliang and Lee, Nayeon and Wang, Boxin and Yang, Zhuolin and Liu, Zihan and Barker, Jon and Rintamaki, Tuomas and Shoeybi, Mohammad and Catanzaro, Bryan and Ping, Wei}},
  title = {{HuggingFace Model: nvidia/NVLM-D-72B}},
  year = {2024},
  howpublished = {\url{https://huggingface.co/nvidia/NVLM-D-72B}}
}

@misc{vllm-tp-pp,
  author = {{vLLM}},
  title = {{Distributed Inference and Serving}},
  year = {2024},
  howpublished = {\url{https://docs.vllm.ai/en/latest/serving/distributed_serving.html}}
}

@misc{dcgm,
  author = {{NVIDIA}},
  title = {{NVIDIA DCGM}: Manage and Monitor {GPUs} in Cluster Environments},
  year = {2024},
  howpublished = {\url{https://developer.nvidia.com/dcgm}}
}

@misc{dali,
  author = {{NVIDIA}},
  title = {{NVIDIA} Data Loading Library ({DALI})},
  year = {2024},
  howpublished = {\url{https://github.com/NVIDIA/DALI}}
}

@misc{mps,
  author = {{NVIDIA}},
  title = {{NVIDIA} Multi-Process Service},
  year = {2024},
  howpublished = {\url{https://docs.nvidia.com/deploy/mps/index.html}}
}

@misc{mig,
  author = {{NVIDIA}},
  title = {{NVIDIA} Multi-Instance {GPU} ({MIG})},
  year = {2024},
  howpublished = {\url{https://www.nvidia.com/en-us/technologies/multi-instance-gpu/}}
}

@inproceedings{vlm-leaderboard,
  title={{VLMEvalKit: An open-source toolkit for evaluating large multi-modality models}},
  author={Duan, Haodong and Yang, Junming and Qiao, Yuxuan and Fang, Xinyu and Chen, Lin and Liu, Yuan and Dong, Xiaoyi and Zang, Yuhang and Zhang, Pan and Wang, Jiaqi and others},
  booktitle={Proceedings of the 32nd ACM International Conference on Multimedia},
  year={2024},
  howpublished = {\url{https://huggingface.co/spaces/opencompass/open_vlm_leaderboard}}
}

% related work
@inproceedings{patel2024splitwise,
  title={{Splitwise: Efficient generative LLM inference using phase splitting}},
  author={Patel, Pratyush and Choukse, Esha and Zhang, Chaojie and Shah, Aashaka and Goiri, {\'I}{\~n}igo and Maleki, Saeed and Bianchini, Ricardo},
  booktitle={Proceedings of the ACM/IEEE 51st Annual International Symposium on Computer Architecture (ISCA)},
  year={2024},
}

@inproceedings{zhong2024distserve,
  title={{DistServe: Disaggregating Prefill and Decoding for Goodput-optimized Large Language Model Serving}},
  author={Zhong, Yinmin and Liu, Shengyu and Chen, Junda and Hu, Jianbo and Zhu, Yibo and Liu, Xuanzhe and Jin, Xin and Zhang, Hao},
  booktitle={Proceedings of the 18th USENIX Symposium on Operating Systems Design and Implementation (OSDI)},
  year={2024}
}

@article{pod-attention,
  title={Pod-attention: Unlocking full prefill-decode overlap for faster {LLM} inference},
  author={Kamath, Aditya K and Prabhu, Ramya and Mohan, Jayashree and Peter, Simon and Ramjee, Ramachandran and Panwar, Ashish},
  journal={arXiv preprint arXiv:2410.18038},
  year={2024}
}

@inproceedings{tvm,
  author = {Chen, Tianqi and Moreau, Thierry and Jiang, Ziheng and Zheng, Lianmin and Yan, Eddie and Cowan, Meghan and Shen, Haichen and Wang, Leyuan and Hu, Yuwei and Ceze, Luis and Guestrin, Carlos and Krishnamurthy, Arvind},
  title = {{TVM: An automated end-to-end optimizing compiler for deep learning}},
  year = {2018},
  booktitle = {Proceedings of the 13th USENIX Conference on Operating Systems Design and Implementation (OSDI)},
}

@inproceedings{hf,
    title = {{Transformers: State-of-the-Art Natural Language Processing}},
    author = "Thomas Wolf and Lysandre Debut and Victor Sanh and Julien Chaumond and Clement Delangue and Anthony Moi and Pierric Cistac and Tim Rault and Rémi Louf and Morgan Funtowicz and Joe Davison and Sam Shleifer and Patrick von Platen and Clara Ma and Yacine Jernite and Julien Plu and Canwen Xu and Teven Le Scao and Sylvain Gugger and Mariama Drame and Quentin Lhoest and Alexander M. Rush",
    booktitle = "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations",
    month = oct,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/2020.emnlp-demos.6",
    pages = "38--45"
}

@inproceedings{transformer,
  title={Attention is all you need},
  author={Waswani, A and Shazeer, N and Parmar, N and Uszkoreit, J and Jones, L and Gomez, A and Kaiser, L and Polosukhin, I},
  booktitle={2017 Conference on Neural Information Processing Systems (NIPS 2017)},
  year={2017}
}

@inproceedings{deepspeed,
  title={{DeepSpeed-Inference}: Enabling efficient inference of transformer models at unprecedented scale},
  author={Aminabadi, Reza Yazdani and Rajbhandari, Samyam and Awan, Ammar Ahmad and Li, Cheng and Li, Du and Zheng, Elton and Ruwase, Olatunji and Smith, Shaden and Zhang, Minjia and Rasley, Jeff and others},
  booktitle={Proceedings of the International Conference for High Performance Computing, Networking, Storage and Analysis (SC)},
  year={2022},
}

% LMM model level optimization
@article{ning2024infmllm,
  title={{Inf-MLLM}: Efficient Streaming Inference of Multimodal Large Language Models on a Single {GPU}}, 
  author={Zhenyu Ning and Jieru Zhao and Qihao Jin and Wenchao Ding and Minyi Guo},
  year={2024},
  journal={arXiv preprint arXiv:2409.09086},
}

@article{huang2024dynamic,
  title={{Dynamic-LLaVA}: Efficient Multimodal Large Language Models via Dynamic Vision-language Context Sparsification},
  author={Huang, Wenxuan and Zhai, Zijie and Shen, Yunhang and Cao, Shaoshen and Zhao, Fei and Xu, Xiangfeng and Ye, Zheyu and Lin, Shaohui},
  journal={arXiv preprint arXiv:2412.00876},
  year={2024}
}

@article{lin2024boosting,
  title={Boosting Multimodal Large Language Models with Visual Tokens Withdrawal for Rapid Inference},
  author={Lin, Zhihang and Lin, Mingbao and Lin, Luxi and Ji, Rongrong},
  journal={arXiv preprint arXiv:2405.05803},
  year={2024}
}

@inproceedings{liu2025efficient,
  title={{Efficient inference of vision instruction-following models with elastic cache}},
  author={Liu, Zuyan and Liu, Benlin and Wang, Jiahui and Dong, Yuhao and Chen, Guangyi and Rao, Yongming and Krishna, Ranjay and Lu, Jiwen},
  booktitle={European Conference on Computer Vision (ECCV)},
  year={2025},
}

@article{li2024inference,
  title={Inference Optimal {VLMs} Need Only One Visual Token but Larger Models},
  author={Li, Kevin Y and Goyal, Sachin and Semedo, Joao D and Kolter, J Zico},
  journal={arXiv preprint arXiv:2411.03312},
  year={2024}
}

% characterization
@article{lee2024characterizing,
  title={Characterizing and Efficiently Accelerating Multimodal Generation Model Inference},
  author={Lee, Yejin and Sun, Anna and Hosmer, Basil and Acun, Bilge and Balioglu, Can and Wang, Changhan and Hernandez, Charles David and Puhrsch, Christian and Haziza, Daniel and Guessous, Driss and others},
  journal={arXiv preprint arXiv:2410.00215},
  year={2024}
}

@article{hou2022characterizing,
  title={{Characterizing and understanding end-to-end multi-modal neural networks on GPUs}},
  author={Hou, Xiaofeng and Xu, Cheng and Liu, Jiacheng and Tang, Xuehan and Sun, Lingyu and Li, Chao and Cheng, Kwang-Ting},
  journal={IEEE Computer Architecture Letters},
  volume={21},
  number={2},
  pages={125--128},
  year={2022},
}

% others
@misc{a100azure,
  author = {{Microsoft Azure}},
  title = {{Azure VM NDm-A100-v4 sizes series}},
  year = {2024},
  howpublished = {\url{https://learn.microsoft.com/en-us/azure/virtual-machines/sizes/gpu-accelerated/ndma100v4-series}}
}

@misc{h100azure,
  author = {{Microsoft Azure}},
  title = {{Azure VM ND-H100-v5 sizes series}},
  year = {2024},
  howpublished = {\url{https://learn.microsoft.com/en-us/azure/virtual-machines/sizes/gpu-accelerated/ndh100v5-series?tabs=sizebasic}}
}

@misc{nvidia-sm-occupancy,
  author = {{NVIDIA}},
  title = {{NVIDIA Nsight Visual Studio Edition:} Achieved {SM} occupancy},
  year = {2024},
  howpublished={\url{https://docs.nvidia.com/gameworks/content/developertools/desktop/analysis/report/cudaexperiments/kernellevel/achievedoccupancy.htm#:~:text=Occupancy%20is%20defined%20as%20the,be%20different%20for%20each%20SM.}}
}

@inproceedings{gupta2001scalable,
  title={{On Scalable and Efficient Distributed Failure Detectors}},
  author={Gupta, Indranil and Chandra, Tushar D and Goldszmidt, Germ{\'a}n S},
  booktitle={Proceedings of the Twentieth Annual ACM Symposium on Principles of Distributed Computing (PODC)},
  year={2001}
}

@inproceedings{raft,
  author = {Ongaro, Diego and Ousterhout, John},
  title = {{In Search of An Understandable Consensus Algorithm}},
  year = {2014},
  booktitle = {Proceedings of the 2014 USENIX Conference on USENIX Annual Technical Conference (ATC)},
}

@inproceedings{pb,
  title={{PLOVER: Fast, Multi-core Scalable Virtual Machine Fault-tolerance}},
  author={Wang, Cheng and Chen, Xusheng and Jia, Weiwei and Li, Boxuan and Qiu, Haoran and Zhao, Shixiong and Cui, Heming},
  booktitle={Proceedings of the 15th USENIX Symposium on Networked Systems Design and Implementation (NSDI)},
  year={2018}
}

@article{optscaler,
  author = {Zou, Ding and Lu, Wei and Zhu, Zhibo and Lu, Xingyu and Zhou, Jun and Wang, Xiaojin and Liu, Kangyu and Wang, Kefan and Sun, Renen and Wang, Haiqing},
  title = {{OptScaler: A Collaborative Framework for Robust Autoscaling in the Cloud}},
  year = {2024},
  issue_date = {August 2024},
  publisher = {VLDB Endowment},
  volume = {17},
  number = {12},
  issn = {2150-8097},
  url = {https://doi.org/10.14778/3685800.3685829},
  doi = {10.14778/3685800.3685829},
  journal = {Proceedings of the VLDB Endowment},
  month = aug,
  pages = {4090–4103},
  numpages = {14}
}

% LLM optimization
@inproceedings{qiu2024muserve,
  title = {{Power-aware Deep Learning Model Serving with $\mu$-Serve}},
  author = {Haoran Qiu and Weichao Mao and Archit Patke and Shengkun Cui and Saurabh Jha and Chen Wang and Hubertus Franke and Zbigniew Kalbarczyk and Tamer Ba{\c s}ar and Ravishankar K. Iyer},
  booktitle = {USENIX Annual Technical Conference (USENIX ATC 2024)},
  year = {2024},
}

@inproceedings{stojkovic2024dynamollm,
  title={{DynamoLLM: Designing LLM Inference Clusters for Performance and Energy Efficiency}},
  author={Stojkovic, Jovan and Zhang, Chaojie and Goiri, {\'I}{\~n}igo and Torrellas, Josep and Choukse, Esha},
  year={2025},
  booktitle={Proceedings of the IEEE International Symposium on High Performance Computer Architecture (HPCA)}, 
}

@inproceedings{polca,
    author = {Patel, Pratyush and Choukse, Esha and Zhang, Chaojie and Goiri, \'{I}\~{n}igo and Warrier, Brijesh and Mahalingam, Nithish and Bianchini, Ricardo},
    title = {{Characterizing Power Management Opportunities for LLMs in the Cloud}},
    booktitle = {Proceedings of the 29th ACM International Conference on Architectural Support for Programming Languages and Operating Systems (ASPLOS)},
    year = {2024},
}

@inproceedings{aiops2024qiu,
  author  = {Qiu, Haoran and Mao, Weichao and Patke, Archit and Cui, Shengkun and Jha, Saurabh and Wang, Chen and Franke, Hubertus and Kalbarczyk, Zbigniew T. and Ba\c{s}ar, Tamer and Iyer, Ravishankar K.},
  title   = {{Efficient Interactive LLM Serving with Proxy Model-based Sequence Length Prediction}},
  year    = {2024},
  booktitle = {The 5th International Workshop on Cloud Intelligence / AIOps at ASPLOS 2024},
}

@inproceedings{sarathi-serve,
  title={{Taming Throughput-Latency Tradeoff in LLM Inference with Sarathi-Serve}},
  author={Agrawal, Amey and Kedia, Nitin and Panwar, Ashish and Mohan, Jayashree and Kwatra, Nipun and Gulavani, Bhargav and Tumanov, Alexey and Ramjee, Ramachandran},
  booktitle={Proceedings of the 18th USENIX Symposium on Operating Systems Design and Implementation (OSDI)},
  year={2024},
}

@inproceedings{orca,
    author = {Gyeong-In Yu and Joo Seong Jeong and Geon-Woo Kim and Soojeong Kim and Byung-Gon Chun},
    title = {{Orca: A Distributed Serving System for Transformer-Based Generative Models}},
    booktitle = {Proceedings of the 16th USENIX Symposium on Operating Systems Design and Implementation (OSDI)},
    year = {2022}
}

@inproceedings{vllm,
  title={{Efficient Memory Management for Large Language Model Serving with PagedAttention}},
  author={Woosuk Kwon and Zhuohan Li and Siyuan Zhuang and Ying Sheng and Lianmin Zheng and Cody Hao Yu and Joseph E. Gonzalez and Hao Zhang and Ion Stoica},
  booktitle={Proceedings of the Symposium on Operating Systems Principles (SOSP)},
  year={2023}
}

@inproceedings{patke2024queue,
  title={{Queue Management for SLO-Oriented Large Language Model Serving}},
  author={Patke, Archit and Reddy, Dhemath and Jha, Saurabh and Qiu, Haoran and Pinto, Christian and Narayanaswami, Chandra and Kalbarczyk, Zbigniew and Iyer, Ravishankar},
  booktitle={Proceedings of the ACM Symposium on Cloud Computing (SoCC)},
  year={2024}
}

@article{sun2024llumnix,
  title={{Llumnix: Dynamic Scheduling for Large Language Model Serving}},
  author={Sun, Biao and Huang, Ziming and Zhao, Hanyu and Xiao, Wencong and Zhang, Xinyi and Li, Yong and Lin, Wei},
  journal={arXiv preprint arXiv:2406.03243},
  year={2024}
}

@article{stojkovic2025tapas,
  title={{TAPAS: Thermal-and Power-Aware Scheduling for LLM Inference in Cloud Platforms}},
  author={Stojkovic, Jovan and Zhang, Chaojie and Goiri, {\'I}{\~n}igo and Choukse, Esha and Qiu, Haoran and Fonseca, Rodrigo and Torrellas, Josep and Bianchini, Ricardo},
  journal={arXiv preprint arXiv:2501.02600},
  year={2025}
}

@article{wang2023openchat,
  title={{OpenChat: Advancing open-source language models with mixed-quality data}},
  author={Wang, Guan and Cheng, Sijie and Zhan, Xianyuan and Li, Xiangang and Song, Sen and Liu, Yang},
  journal={arXiv preprint arXiv:2309.11235},
  year={2023}
}

@article{qin2024mooncake,
  title={{Mooncake: A KVCache-centric Disaggregated Architecture for LLM Serving}},
  author={Qin, Ruoyu and Li, Zheming and He, Weiran and Zhang, Mingxing and Wu, Yongwei and Zheng, Weimin and Xu, Xinran},
  journal={arXiv preprint arXiv:2407.00079},
  year={2024}
}

@article{hu2024memserve,
  title={{MemServe: Context caching for disaggregated LLM serving with elastic memory pool}},
  author={Hu, Cunchen and Huang, Heyang and Hu, Junhao and Xu, Jiang and Chen, Xusheng and Xie, Tao and Wang, Chenxi and Wang, Sa and Bao, Yungang and Sun, Ninghui and others},
  journal={arXiv preprint arXiv:2406.17565},
  year={2024}
}

@article{shazeer2020megatron,
  title={{Megatron-LM: Training Multi-Billion Parameter Language Models Using Pipeline Parallelism}},
  author={Shazeer, Mohammad and others},
  year={2020},
  journal={arXiv preprint arXiv:1909.08053},
  url={https://arxiv.org/abs/1909.08053}
}