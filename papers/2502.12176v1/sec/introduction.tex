
\section{introduction}

\subsection{Motivation}

Foundation Models (FMs) \cite{zhou2024comprehensive} have emerged as a groundbreaking force in the realm of artificial intelligence. Renowned FMs, including GPT-4 and LLaMa, have exhibited an extraordinary ability to understand context and nuances, enabling them to skillfully handle a wide range of tasks across diverse fields such as natural language processing (NLP) and computer vision (CV).
On the other hand, Domain Models (DMs), often deployed  remotely on edge devices, are trained locally using private data that cannot be shared with the FMs. However, DMs also have limitations stemming from their restricted generalization capacities.
The dilemma  raises a question: \textit{How can we effectively harness the power of FMs for domain-specific knowledge while simultaneously ensure that DMs possess adequate generalization capabilities and adhere to privacy protection requirements?}



One promising solution to integrate capabilities of FMs and DMs is through Federated Foundation Models (FedFMs)~\cite{fan2023fate,kang2023grounding,ren2024advances}.  This paper provides a comprehensive summary of definitions and challenges in this new machine learning paradigm. Specifically, as depicted in Fig. \ref{fig:fedfms}, FedFMs is defined as a distributed learning framework which includes at least one pre-trained FM and a multitude of DMs. 
Federated learning (FL) \cite{yang2019federated} methods are adopted in FedFMs to ensure that data privacy are well-respected during the training of FedFMs, especially, for healthcare, finance and IoTs  applications.

\captionsetup[table]{labelformat=simple, labelsep=newline, textfont=sc, justification=centering}


\begin{figure}
    \centering
    % \includegraphics[width=0.9\linewidth]{figures/intro_fedfms.pdf}
    \includegraphics[width=0.9\linewidth]{figures/fedfm.pdf}
    \caption{An illustration of Federated Foundation Models (FedFMs). 
    On one hand, Domain Models (DMs) can augment the domain-specific knowledge of Foundation Models (FMs) through FedFMs. On the other hand, FMs can assist in enhancing the generalization capabilities of DMs on the edges in a distributed setting.}
    \label{fig:fedfms}
    \vspace{-5mm}
\end{figure}

\begin{table*}[ht]
%		 \renewcommand{\arraystretch}{1.3}
		\caption{Ten Challenging Problems in FedFMs} 
		\label{tab:framework}
		\resizebox{\textwidth}{!}{
			\begin{threeparttable}
				\begin{tabular}{|l|l|l|l|}
					\specialrule{0em}{2pt}{2pt} 
					\hline \hline
					\textbf{\qquad \qquad \qquad \qquad Problems}                                                                 & \multicolumn{1}{c|}{ \textbf{Existing Methods}}                                                                  & \multicolumn{1}{c|}{ \textbf{Challenges}} & \multicolumn{1}{c|}{ \textbf{Potential Solutions}}
					      \\ \hline
					\begin{tabular}[l]{@{}c@{}} Problem 1: How to establish a foundational theory for FedFMs?\end{tabular}               
					& \begin{tabular}[c]{@{}l@{}}
						$\bullet$ Multi-objective Trade-off Methods \cite{zhang2024no,dong2023tunable,hou2023privately,kuang2024federatedscope,wu2024fedbiot}\\
						$\bullet$ Open- and Closed-Source FMs Trade-off Methods \cite{zhang2023towards, wang2024flora,guo2023pfedprompt, yang2023efficient}\end{tabular}                                                       & \begin{tabular}[c]{@{}l@{}}
						$\bullet$ Multi-Objective Optimization in FedFMs\\ 
						$\bullet$ Fairness in FedFMs \\ 
						$\bullet$ Black-Box and White-Box \\Aggregation in FedFMs 
					\end{tabular} 

                     & \begin{tabular}[c]{@{}l@{}}
                          $\bullet$ Establishing Theoretical Bounds\\
                          $\bullet$ Balancing Cross-Layer \\~Privacy-Utility-Efficiency \\ 
					   $\bullet$ Adaptive Strategies \\ 
						 $\bullet$ Hybrid Aggregation Techniques
					\end{tabular} 
					
					\\ \hline
					\begin{tabular}[l]{@{}l@{}} Problem 2: How to utilize private data in FedFMs?\end{tabular}             & \begin{tabular}[c]{@{}l@{}}
						$\bullet$ Data-Centric Methods  \cite{6-data-dpsda,qin2023federated,6-data-fedkim,6-data-fedcampus}\\
						$\bullet$ Model-Centric Methods \cite{zhang2024fedpit,ye2024openfedllm,JCST-2308-13639,zhangenhancing}\end{tabular}                        
					& \begin{tabular}[l]{@{}l@{}}
						$\bullet$ Data Quality Impact\\ 
						$\bullet$ Scale and Efficiency Trade-offs  \\ 
						$\bullet$ Computational Resource Constraints \end{tabular}

                    & \begin{tabular}[l]{@{}l@{}}
						$\bullet$ Balancing Data Efficiency \\and Computational Cost \\
						$\bullet$ Enhancing Private Data Processing  \\ 
						$\bullet$ Refining Data Contribution Evaluation 
                        \end{tabular}
					
					\\ \hline
					\begin{tabular}[l]{@{}l@{}}Problem 3: How to design continual learning in FedFMs?\end{tabular}       
					& \begin{tabular}[c]{@{}l@{}}
						$\bullet$ Replay-based Methods \cite{li2024towards,li2024sr,yu2024overcoming,liang2025diffusion}  \\
						$\bullet$ Methods based on Regularization and Decomposition \cite{yoon2021federated,dong2022federated}\\
                        $\bullet$ Distillation-based Methods \cite{ma2022continual,wei2022knowledge}\\
						$\bullet$ Prompted-based Methods \cite{piaofederated,yu2024personalized} 
					\end{tabular}                          
					
					& \begin{tabular}[c]{@{}l@{}}
						$\bullet$ Spatial-Temporal Data Heterogeneity \\ 
                        $\bullet$ Knowledge Transfer and Error Correction \\
                        $\bullet$ Knowledge Conflict \\
                        \end{tabular} 

                    & \begin{tabular}[c]{@{}l@{}}
                        $\bullet$ External Knowledge Base\\
                        $\bullet$ Selective Knowledge Fusion\\
                        \end{tabular} 
					                                           
					\\ \hline
					\begin{tabular}[l]{@{}l@{}} Problem 4: How to design unlearning in FedFMs?\end{tabular}                                                             
					& \begin{tabular}[c]{@{}l@{}}
						$\bullet$ Unlearning Targets \cite{wang2022federated, shah2023unlearning, gu2024few,gu2024ferrari,Gu2024Unlearning}\\
						$\bullet$ Unlearning Executors \cite{liu2022right,su2023asynchronous, fraboni2024sifu,halimi2022federated,wu2022federated,gao2024verifi}\\
                        $\bullet$ Unlearning Verification \cite{cao2023fedrecover,zhang2023fedrecovery}\\
						$\bullet$ Unlearning Principles  \cite{shao2024federated}\end{tabular}                                     
					
					& \begin{tabular}[c]{@{}l@{}}
						$\bullet$ High Model Complexity\\
						$\bullet$ Knowledge Coupling \\
                            $\bullet$ Cross-Client Consistency
                        \end{tabular} 

                    & \begin{tabular}[c]{@{}l@{}}
						$\bullet$ Modular Optimization Unlearning\\
						$\bullet$ Disentangled Knowledge Decoupling \\
                            $\bullet$ Federated Cross-Client Coordination
                        \end{tabular} 
                        
				\\ \hline
					\begin{tabular}[l]{@{}l@{}} Problem 5: How to address NON-IID issues \\ and graph data in FedFMs?\end{tabular}                   
                    & \begin{tabular}[c]{@{}l@{}}
						$\bullet$ Distribution Adaptation \cite{park2024fedbaffederatedlearningaggregation,imteaj2024tripleplayenhancingfederatedlearning,6-data-feddpa}\\ 
						$\bullet$ Federated Graph of Models \cite{li2024fedgtatopologyawareaveragingfederated,ma2024beyond,huang2022accelerating}\\ 
						$\bullet$ Optimization in Graph of Models \cite{chen2024privfusion, chen2024model}\end{tabular}                                          
					
					& \begin{tabular}[c]{@{}l@{}}
						$\bullet$ Convergence Issues from Heterogeneity\\ 
						$\bullet$ Complexity of Network Topology \\
                            $\bullet$ Sustainable Optimization
                        \end{tabular}

                    & \begin{tabular}[c]{@{}l@{}}
						$\bullet$ Adaptive Optimization\\ 
						$\bullet$ Dynamic and Topology-aware \\ Aggregation \\
                            $\bullet$ Multi-objective Optimization
                            \end{tabular}
                        
					                               \\ \hline
					\begin{tabular}[l]{@{}l@{}}  Problem 6: How to achieve the bidirectional knowledge transfer \\ ~between FMs and DMs in FedFMs? \end{tabular}              
					& \begin{tabular}[l]{@{}l@{}}
						$\bullet$ Data-Level Knowledge Transfer \cite{hsieh2023distilling,li2022explanations,jiang2023lion,fan2024pdss,li2024federated}\\ 
						$\bullet$ Representation-Level Knowledge Transfer \cite{shen2023split,he2019model,gu2024minillm,yu2023multimodal,fan-etal-2025-fedmkt}\\
						$\bullet$ Model-Level Knowledge Transfer \cite{zhang2023gpt,xiao2023offsite,fan2024fedcollm,deng2023mutual}
					\end{tabular}                                                        
                    & \begin{tabular}[l]{@{}l@{}}
						$\bullet$  Data Heterogeneity\\ 
						$\bullet$  Representation Heterogeneity\\ 
                            $\bullet$  Model Heterogeneity\\ 
						$\bullet$  Privacy\\
                        \end{tabular} 
                        
					& \begin{tabular}[l]{@{}l@{}}
						$\bullet$ Unified Model Architectures\\ 
						$\bullet$ Adaptive Knowledge Transfer\\ 
                         $\bullet$ Synthetic Data\\
                        $\bullet$ Advanced Privacy Techniques
                        \end{tabular} 
					                                                                     \\ \hline
					\begin{tabular}[l]{@{}l@{}}  Problem 7: How to design incentive mechanisms\\ through contribution evaluation in FedFMs? \end{tabular}             
					& \begin{tabular}[c]{@{}l@{}}
						$\bullet$ Individual based Evaluation Schemes~\cite{Individual}\\
                        $\bullet$ Leave-One-Out based Evaluation Schemes~\cite{LOO1999} \\
						$\bullet$ Interaction based Evaluation Schemes~\cite{RN9, RN33} \\ 
						$\bullet$ Shapley-Value based Contribution Evaluation~\cite{song2019profit, wei2020efficient,RN21} \\
                        $\bullet$ Least Core based Evaluation Schemes~\cite{Yan2021IfYL} 
                        \end{tabular} 
					& \begin{tabular}[c]{@{}l@{}}
						$\bullet$ Scalability and Computational Overhead\\ 
						$\bullet$ Data-Task Contribution Mapping \end{tabular} 

                    & \begin{tabular}[c]{@{}l@{}}
						$\bullet$ Learned Contribution Evaluation\\ 
						$\bullet$ Crowd-sourced Data Contribution Map \end{tabular} 
                        
                        \\ \hline 
					\begin{tabular}[l]{@{}l@{}} Problem 8: How to design game mechanisms in FedFMs? \end{tabular} 
					
					& \begin{tabular}[c]{@{}l@{}}
						$\bullet$ Stackelberg Game-based Methods \cite{sarikaya2019motivating,pandey2020crowdsourcing,khan2020federated,luo2023incentive,hu2020trading,lee2020market}\\ $\bullet$ Yardstick Competition-based Schemes \cite{sarikaya2020regulating}\\
                        $\bullet$ Shapley-Value Based Schemes \cite{qu2020privacy,song2019profit}\\
                        $\bullet$ Other Incentive Mechanisms \cite{tang2023utility,tang2023competitive,tang2024bias,tang2023multi,tang2024cost,tang2024intelligent,tang2024stakeholder}
                        \end{tabular}                      
					& \begin{tabular}[c]{@{}l@{}}
						$\bullet$ Privacy Cost Quantification \\
						$\bullet$ Information Asymmetry \\
						$\bullet$ Multi-objective Tradeoffs \end{tabular}     

                    & \begin{tabular}[c]{@{}l@{}}
						$\bullet$ Adaptive Game-theoretic Models\\
						$\bullet$ Resource-aware Privacy Mechanisms\\
						$\bullet$ Incentive-compatible Mechanisms\\
                            $\bullet$ AI-driven Anomaly Detection\end{tabular} 

                        
					\\  \hline
					\begin{tabular}[l]{@{}l@{}} Problem 9: How to design model watermarking in FedFMs?  \end{tabular}    
					& \begin{tabular}[c]{@{}l@{}}
						$\bullet$ White-Box Watermarking \cite{li2022fedipr,yang2023fedsov,shao2024fedtrackerfurnishingownershipverification,liang2023fedcip}\\ 
						$\bullet$ Black-Box Watermarking \cite{atli2021wafflewatermarkingfederatedlearning, 9658998, yang2023watermarkingsecurefederatedlearning, electronics13214306}\end{tabular}                                                                             & \begin{tabular}[c]{@{}l@{}}
						$\bullet$ Large-Scale Watermarking \\ 
						$\bullet$ Scalability with Massive FMs\\ 
						$\bullet$ Multi-Modalities  \\
                        $\bullet$ Dynamic Model Composition
                        \end{tabular}
                      &
                    \begin{tabular}[c]{@{}l@{}}
						$\bullet$ Lightweight Watermark Embedding\\ and Federated Pruning\\ 
						$\bullet$ Resource-efficient Watermarking\\ 
						$\bullet$ Modality-agnostic Watermarking \\
                        $\bullet$ Adaptive Watermarks \\with Self-reinforcing Signatures
                        \end{tabular}    
                        
					\\  \hline
					\begin{tabular}[l]{@{}c@{}} Problem 10: How to to improve the efficiency in FedFMs? \end{tabular}       
					& \begin{tabular}[c]{@{}l@{}}
                        $\bullet$ Data Selection Strategies and Prompt Compression \cite{ye2024openfedllm,qin2024federated}\\
                        $\bullet$ Model Compression \cite{ren2023two,fan2024data,li2019fedmd}\\
                        $\bullet$ Resource-aware Scheduling and Framework Optimization \cite{hou2020dynabert,niu2024smartmem}\\
                        $\bullet$ Communication Parameter Reduction \cite{wang2021resource, hu2021mhat}\end{tabular}    
                    
                        & \begin{tabular}[c]{@{}l@{}}
						$\bullet$ Communication Bottlenecks\\ 
                        $\bullet$ Efficiency-Performance-Privacy Trade-off\\ 
						$\bullet$ Task Redundancy \end{tabular}

                        & \begin{tabular}[c]{@{}l@{}}
						$\bullet$ Compression\\ 
                        $\bullet$ Hybrid Privacy-Preserving Techniques\\ 
						$\bullet$ Disentangling Tasks\end{tabular}

                        
					\\  \hline 
				\end{tabular} 
				
		\end{threeparttable} }
	\end{table*}


\subsection{Ten Challenging Problems in FedFMs}

Despite their promising applications, FedFMs face significant challenges for widespread adoption. 
In this paper, we delve into the intrinsic challenges of FedFMs from five key aspects: “\textbf{Foundational Theory}”, “\textbf{Data}”, “\textbf{Heterogeneity}”, “\textbf{Security and Privacy}” and “\textbf{Efficiency}”.

\textbf{Foundational Theory} addresses the optimization objectives at the highest level in FedFMs. The theory must address issues such as how to harmonize privacy, utility, and efficiency within the framework of FedFMs \cite{zhang2022no}, guiding algorithm design (\textit{Problem 1}). 

\textbf{Data}, challenges arise from data distribution across organizations or individuals. FedFMs must adapt to unique private data characteristics, balancing data utility and privacy risks \cite{kang2023grounding} (\textit{Problem 2}). Data also varies over time; thus, FedFMs must adapt to new task requirements without forgetting previously learned knowledge \cite{yang2024federatedcl} (\textit{Problem 3}). Additionally, FedFMs need mechanisms for “unlearning” when participants exit \cite{liu2024survey} (\textit{Problem 4}).

\textbf{Heterogeneity} in FedFMs includes data, model, and computational aspects. Non-IID data variations across clients challenge effective generalization and pattern capture, necessitating advanced methodologies \cite{park2024fedbaffederatedlearningaggregation} (\textit{Problem 5}). Additionally, collaboration between large FMs and small domain models introduces bidirectional knowledge transfer challenges \cite{fan-etal-2025-fedmkt} (\textit{Problem 6}). Lastly, evaluating and fairly rewarding participants' contributions remain critical \cite{wei2020efficient} (\textit{Problem 7}).

\textbf{Security and Privacy} are vital for FedFMs' practical application. FedFMs face two primary security threats: privacy attacks and local data/model theft. Addressing these requires both defensive technical measures and game-theoretic mechanisms to deter attackers \cite{zhang2024game} (\textit{Problem 8}). To combat model theft, leveraging model watermarking for full life-cycle tracking, auditing, and detection is crucial  \cite{li2022fedipr} (\textit{Problem 9}).

\textbf{Efficiency} refers to optimized training and inference times and computational resources. There are still significant improvements needed in three key areas to ensure efficiency: training efficiency, communication efficiency, and parameter efficiency 
 \cite{mcmahan2017communication,wang2021resource, hu2021mhat} (\textit{Problem 10}).

This paper critically assesses recent advancements in FedFMs from the aforementioned five aspects and identifies the \textbf{\textit{ten challenging problems}}, summarized in TABLE \ref{tab:framework}.


\subsection{Related Works}

The research field of FedFMs is in its early stages, with only two position papers \cite{chen2023federated,li2024position} and six review papers \cite{zhuang2023foundation,yu2023federated,kang2023grounding,woisetschlager2024survey,li2024synergizing,ren2024advances} available. Table \ref{tab:existingreview} compares these papers to our survey, indicating coverage of key FedFMs aspects (\usym{1F5F8} mentioned, \usym{2717} not discussed). While existing surveys provide some summary of FedFMs, they are often concise and lack comprehensiveness. To our knowledge, this survey presents the most exhaustive treatment of the FedFMs topic to date.

\subsection{Organization of This Paper}

The remainder of this paper is organized as follows.
Sections II-XI address \textit{Problem 1-10}, each dedicated to a single problem. For each problem, we provide a concise definition, review existing methods, and explore key challenges and potential solutions.
Section \ref{sec:summay} summarizes key insights from the 10 challenging problems in FedFMs, providing readers with a clear understanding of practical implications and the broader context of the findings. Notations used in this paper are shown in Table \ref{tab:notation}.



\begin{table*}[htbp]
\setlength\tabcolsep{0.6pt}
\caption{Comparison of Existing Reviews and Position Papers with This Survey Paper}
\label{tab:existingreview}
\centering
\resizebox{\textwidth}{!}{
%\small
\begin{tabular}{c|c|cccccccccc}
\toprule
{\textsc{Years}} & {\textsc{References}} & 
{\makecell[c]{\textsc{Problem} \\ \textsc{1}} }& 
{\makecell[c]{\textsc{Problem} \\ \textsc{2}}}& 
{\makecell[c]{\textsc{Problem} \\ \textsc{3}}}&
{\makecell[c]{\textsc{Problem} \\ \textsc{4}}}& 
{\makecell[c]{\textsc{Problem} \\ \textsc{5}}}&
{\makecell[c]{\textsc{Problem} \\ \textsc{6}}}& 
{\makecell[c]{\textsc{Problem} \\ \textsc{7}}}&
{\makecell[c]{\textsc{Problem} \\ \textsc{8}}}&
{\makecell[c]{\textsc{Problem} \\ \textsc{9}}}&
{\makecell[c]{\textsc{Problem} \\ \textsc{10}}}
\\

\midrule
\multicolumn{1}{c|}{\multirow{4}{*}{\begin{tabular}[c]{@{}l@{}}2023\end{tabular}}} &
Chen \textit{et al}. \cite{chen2023federated} & \usym{2717}   & \usym{1F5F8} & \usym{2717} & \usym{2717}  & \usym{1F5F8} & \usym{2717} & \usym{1F5F8} & \usym{2717} & \usym{1F5F8} & \usym{1F5F8} \\ 
\multicolumn{1}{c|}{} &
Zhuang \textit{et al}. \cite{zhuang2023foundation} & \usym{2717}   & \usym{1F5F8} & \usym{2717} & \usym{2717}  & \usym{1F5F8} & \usym{2717} & \usym{1F5F8} & \usym{2717} & \usym{1F5F8} & \usym{1F5F8} \\ 
\multicolumn{1}{c|}{} &
Yu \textit{et al}. \cite{yu2023federated} & \usym{2717}   & \usym{1F5F8} & \usym{1F5F8} & \usym{2717} & \usym{2717} & \usym{2717} & \usym{2717} & \usym{2717} & \usym{2717} & \usym{1F5F8} \\ 
\multicolumn{1}{c|}{} &
Kang \textit{et al}. \cite{kang2023grounding} & \usym{2717}  & \usym{1F5F8} & \usym{2717}  & \usym{2717}  & \usym{2717} & \usym{1F5F8}   & \usym{2717} & \usym{2717} & \usym{2717} & \usym{1F5F8}   \\ \midrule

\multicolumn{1}{c|}{\multirow{4}{*}{\begin{tabular}[c]{@{}l@{}}2024\end{tabular}}} &
Herbert \textit{et al}. \cite{woisetschlager2024survey} &  \usym{2717}  & \usym{1F5F8}   & \usym{2717}  & \usym{2717}  & \usym{2717}  & \usym{2717}   & \usym{2717}  &  \usym{2717} & \usym{2717} & \usym{1F5F8}   \\ 
\multicolumn{1}{c|}{} &
Li \textit{et al}. \cite{li2024position} & \usym{2717} & \usym{1F5F8} & \usym{2717} & \usym{2717}  & \usym{1F5F8}   & \usym{2717} & \usym{2717}  & \usym{2717} & \usym{2717} & \usym{2717}\\ 
\multicolumn{1}{c|}{} &
Li \textit{et al}. \cite{li2024synergizing} & \usym{2717}  & \usym{1F5F8} & \usym{2717}  & \usym{2717}  & \usym{2717} & \usym{2717}  & \usym{2717}  & \usym{2717}  & \usym{1F5F8} & \usym{1F5F8} \\ 
\multicolumn{1}{c|}{} &
Ren \textit{et al}. \cite{ren2024advances} & \usym{2717}  & \usym{1F5F8} & \usym{2717}  & \usym{2717}  & \usym{1F5F8}  & \usym{2717} & \usym{1F5F8} & \usym{2717} & \usym{1F5F8}  & \usym{1F5F8}  \\ 

\midrule

\multicolumn{2}{c|}{\textbf{This paper}} & 
 \usym{1F5F8}   & \usym{1F5F8} & \usym{1F5F8} & \usym{1F5F8}  & \usym{1F5F8} & \usym{1F5F8} & \usym{1F5F8} & \usym{1F5F8} & \usym{1F5F8} & \usym{1F5F8}\\ 

\bottomrule 
\end{tabular}
}
\end{table*}

