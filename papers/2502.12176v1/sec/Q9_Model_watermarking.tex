\section{Problem 9: How to Design Model Watermarking in FedFMs?}

% Shortform declaration
\newcommand{\et}{\textit{et al.}}
\newcommand{\eg}{\textit{e.g.,}}
\newcommand{\ie}{\textit{i.e.,}}
\newcommand{\eq}{Eq.}
\newcommand{\fig}{Fig.}
\newcommand{\tab}{Tab.}
\newcommand{\s}{Sec.}
\newcommand{\alg}{Alg.}

\subsection{Defining Model Watermarking in FedFMs}




Model watermarking in FedFMs plays a crucial role in safeguarding intellectual property (IP), helping to ensure that FedFMs ownership is protected and preventing unauthorized use by individual clients during local training and model theft by embedding unique watermark for each client.

Watermarking in FedFMs refers to the process by which both clients and the central server collaboratively embed a watermark into a shared model to assert ownership and ensure traceability. Given that FedFMs involve multiple clients contributing to a jointly trained model while a central server orchestrates training, watermarking serves as a mechanism for both clients and the server to embed unique identifiers. This enables clients to verify their contributions and claim ownership in case of disputes, while also allowing the server to track model integrity and detect unauthorized modifications.



\textbf{Problem Formulation}. There are two categories of model watermarking:  \textit{White-Box} and \textit{Black-Box}.



\textbf{White-Box.} A binary watermark \(B \in \{0,1\}^{N_b}\) is embedded directly into the model parameters \(\theta\) (\eg~batch normalization layers) during training by adding specialized regularization terms to the loss function \cite{li2022fedipr}. During verification \(V_w\), an extractor \(E\) retrieves the watermark \(\tilde{B}\) from \(\theta\). The watermark is verified if the Hamming distance \(H(B, \tilde{B})\) is below a predefined threshold \(\epsilon_w\) as illustrated in \fig~\ref{fig: q09 watermark method}.



\textbf{Black-Box.} \(N_t\) trigger-based samples \(T = \{ (x^i_t, y^i_t) \}_{i=1}^{N_t}\) are embedded into the model \(\theta\) using a trigger objective during training \cite{li2022fedipr}. In the verification step (\(V_b\)), trigger inputs \(x_t\) are fed into the model \(\mathcal{M}\), and the outputs are compared to the corresponding labels \(y_t\) to compute the trigger accuracy \(A_t\). The watermark is confirmed if \(A_t\) exceeds a predefined threshold \(\epsilon_b\) as illustrated in \fig~\ref{fig: q09 watermark method}.


The watermark embedding process for client \( k \) minimizes a loss comprising the main task on \( \mathcal{D}_k \) and two regularization terms, \( \ell_{u,T_k}(w_s) \) and \( \ell_{u,B_k}(w_s) \), to embed trigger samples \( T_k \) and feature-based watermarks \( B_k \) in terms of the server's global model $w_s$. Given the global model $w$ at communication round \( t \), the objective formulation is defined as:

\begin{equation}
\begin{split}
      & \min_wF_{k=0,1,\cdots, K}\alpha\ell_{u,k}(w_s)+(1-\alpha)\ell_{m,k}(w_s) \\
       &:=\Big(\alpha\underbrace{\ell_{u,k}(w_s)}_{\text{utility loss}} 
    + \beta\underbrace{\ell_{u,T_k}(w_s)}_{\text{black-box}} 
    + \gamma\underbrace{\ell_{u,B_k}(w_s)}_{\text{white-box}} \Big), \\
    &s.t. \quad \ell_{e,k}(w_s)<\delta_k,
\end{split}
\end{equation}

where $\ell_{u,k}(w_s)$ and $\ell_{m,k}(w_s)$  represent the model utility and watermark loss receptively. Watermark loss aims to make the watermark embedded in the model accurately. $\ell_{u,T_k}(w_s)$ and  $\ell_{u,B_k}(w_s)$ represent black-box watermark and white-box watermark loss respectively. $F_{k=0,1,\cdots, K}$ is the aggregation mechanishm for the server and $K$ clients such as FedAvg \cite{mcmahan2017communication}.  $\alpha,\beta,\gamma$ are the respective weights reflecting the relative importance of each component and meet $\alpha+\beta+\gamma=1$.


\subsection{Existing Methods}

\begin{figure}
    \centering
    \begin{adjustbox}{max width= \linewidth}
        \begin{tabular}{c c}
             \includegraphics[width= 0.5\linewidth]{figures/Q09/white_box_verification.pdf}&  \includegraphics[width= 0.5\linewidth]{figures/Q09/black_box_verification.pdf}\\
             (a) White-Box& (b) Black-Box\\ 
        \end{tabular}
    \end{adjustbox}
    \caption{Illustration of watermarking methods in FedFMs.}
    \label{fig: q09 watermark method}
    \vspace{-5mm}
\end{figure}



In FedFMs, watermarking methods are categorized as \textbf{white-box} or \textbf{black-box}, as shown in \fig~\ref{fig: q09 watermark method}. White-box methods use a \textbf{feature-based} approach to embed binary strings into model parameters via regularization terms \cite{uchida2017embedding,chen2018deepmarks,darvish2019deepsigns} or passport layers \cite{fan2019rethinking, fan2021deepipr}, allowing verification through full model access. In contrast, black-box methods employ \textbf{trigger-based} verification, using adversarial backdoor training samples to verify watermarks via model outputs \cite{adi2018turning,zhang2018protecting}.



\textbf{White-Box.} FedIPR \cite{li2022fedipr} introduced a client-side algorithm embedding unique, detectable watermarks in shared models, ensuring robustness against privacy-preserving techniques while identifying freeriders to promote fairness. DUW \cite{yu2023leakedmodeltrackingip} countered client-side tampering by injecting server-side watermarks, preserving their integrity. FedSOV \cite{yang2023fedsov} enhanced resilience to ambiguity attacks by embedding client public keys as watermarks via a near-collision-resistant hash function, reinforced with digital signatures to prevent forgery. FedTracker \cite{shao2024fedtrackerfurnishingownershipverification} balanced fidelity and traceability using continual learning and a watermark discrimination mechanism, while FedCIP \cite{liang2023fedcip} improved traceability by cross-referencing multiple iterations.

\textbf{Black-Box.} WAFFLE \cite{atli2021wafflewatermarkingfederatedlearning} introduced the first black-box watermarking approach in FedFMs, relying on a trusted aggregator to pre-train the global model with a trigger set before standard FL training. FedTracker \cite{shao2024fedtrackerfurnishingownershipverification} improved WAFFLE by preventing watermarking-induced model updates from interfering with primary task training and freezing batch normalization layers to maintain distribution consistency. Client-side Backdoor \cite{9658998} allowed clients to embed trigger sets in local updates. Yang \et~ \cite{yang2023watermarkingsecurefederatedlearning} refined this by structuring multi-class trigger sets into a grid-based scheme to mitigate overfitting. PWFed \cite{electronics13214306} further enhanced robustness by dynamically generating and embedding watermarks based on varying vectors.

Note that FedTracker involves both white-box and black-box methods.




\subsection{Challenges and Potential Solutions}
\textit{Large-scale watermarking} in FedFMs faces challenges such as computational overhead on resource-limited clients, \textit{scalability issues} with massive models like LLMs and ViTs due to their size and communication costs, and the risk of watermark distortion from compression or quantization. Additionally, the \textit{diverse data modalities} handled by FedFMs (e.g., images, text, audio, video) complicate the creation of universal watermarks due to architectural and sensitivity differences. The \textit{dynamic client participation} in FedFMs further challenges the integrity and persistence of watermarks, making this an underexplored area. %in the field.




To address these challenges, potential solutions include: (1) \textit{Lightweight embedding and federated pruning} techniques \cite{jiang2022modelpruningenablesefficient, lin2022federatedpruningimprovingneural} can minimize computational demands on resource-constrained devices. (2) \textit{Resource-efficient watermarking} methods \cite{jimaging8060152}, including memory-efficient anti-pruning strategies, ensure robustness against compression techniques like quantization, pruning, and distillation. (3) \textit{Modality-agnostic watermarking }
\cite{tang2023watermarkingvisionlanguagepretrainedmodels} can embed watermarks in shared latent representations or parameter distributions, enabling compatibility across diverse data types. (4) \textit{Adaptive watermarks with self-reinforcing signatures} can enhance persistence and integrity in dynamic aggregation scenarios.

