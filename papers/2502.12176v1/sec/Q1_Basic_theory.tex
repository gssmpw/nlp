
\section{Problem 1: How to establish a foundational theory for FedFMs?}

\label{ftheory}

\subsection{Defining A Foundational Theory of FedFMs}

Although FedFMs hold great potential, they currently lack a solid theoretical foundation. 
This section defines the foundational theory of FedFMs as a multi-dimensional trade-off framework, focusing on balancing various goals such as privacy , utility,  efficiency, interpretability, fairness, robustness and aggregation methods. The aim is to emphasize the complex interactions between these dimensions and seek to achieve an optimal equilibrium that accommodates the diverse requirements of FedFMs.

The foundational theory of FedFMs involves three key trade-offs. First, the trade-off between privacy, utility, and efficiency. It provides a multi-objective optimization framework to ensure that improvements in one dimension do not compromise others, enabling the simultaneous optimization of all objectives in practical applications. Second, the trade-off between global and personalized model performance, which explores how to optimize the global model while maintaining flexibility for client-specific customizations. Finally, the trade-off between different types of FedFMs, which examines the differences between open-source (white-box) and closed-source (black-box) models, aiming to optimize the aggregation process for different model types and deployment scenarios.

\textbf{Problem Formulation.}
Consider \(K\) clients, each possessing private data \(D_k\), who participate in the FedFMs training process. Let \(w_s\) represent the model of the server, and \(w_c=\{w_1,\cdots,w_K\}\) denote the set of models of \(K\) clients. We define \(w_g = \{w_s, w_c\}\)\footnote{In this paper, the definition of $w_g,w_s$ and $w_c$ will be used consistently.
}.  We use $w$ as either $w_s, w_c$ or $w_g$. The foundation theory in FedFMs can be regarded as a multi-objective optimization \cite{kang2023optimizing,zhang2022no}, which aims to achieve a balance among privacy loss, utility loss, and efficiency loss as:
\begin{equation}
    \begin{split}
      &\min_{w}\Big( \ell_u(w), \ell_p(w), \ell_e(w) \Big), \\
\text{s.t. } &\ell_u(w) + \ell_p(w) + \ell_e(w) >0   
    \end{split}\label{eq:multi-objective}
\end{equation} 
$\text{where } \ell_i(w) = F\Big(\ell_{i,1}(w,D_1),\cdots, \ell_{i,K}(w,D_K))$ $ \text{for } i\in\{u,p,e\}$, $F$ is the aggregation mechanism such as FedAvg \cite{mcmahan2017communication}.  \(\ell_{u,k}(w,D_k)\), \(\ell_{p,k}(w,D_k)\), and \(\ell_{e,k}(w,D_k)\) denote the loss functions corresponding to the privacy, utility, and efficiency of client \(k\) for the data \(D_k\) respectively. Note that the sum of loss in Eq. \eqref{eq:multi-objective} for privacy, utility and efficiency is larger than zero, denoting the "no free lunch" aspect of the tradeoff \cite{zhang2022no}.


\subsection{Existing Methods}

\subsubsection{Multi-objective Trade-off Methods}

In previous FL research, multi-objective optimization problems are often represented as tasks where the â€œoptimal balance point" lies on the Pareto front or surface, as illustrated in Fig. \ref{fig:Pareto}. This surface effectively identifies solutions that achieve the best balance, ensuring that improving one objective (e.g., privacy) does not come at the expense of others (e.g., utility or efficiency). 

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.6\linewidth]{figures/1-Pareto.png}
    \captionsetup{justification=centering}
    \caption{Pareto Curve of Privacy-Utility Trade-off}
    \label{fig:Pareto}
    % \vspace{-3mm}
\end{figure}

First, we examine the trade-offs between privacy and other dimensions. In  FL, numerous studies have addressed the privacy-utility trade off~\cite{zhang2022no, kang2023optimizing}. For instance, \citet{zhang2022no} proposed the NFL theorem within the FL framework, indicating an inherent trade-off between privacy and utility, expressed as:
\begin{align}
C_1 \leq \ell_p + C_2\cdot\ell_u,
\end{align}
where $\ell_p $ represents the amount of privacy leakage, and $\ell_u$ represents utility loss. \citet{zhang2024no} further applied the NFL framework to LLMs. Unlike the privacy leakage defined by gradients exchanged between clients and servers in \cite{zhang2022no}, this framework focuses more on how much an attacker can infer the original data through protected embeddings. The core expression is:
\begin{align}
\label{eq:tv}
\frac{C_2}{C_1} \cdot \ell_p + \ell_u \geq C_2 \cdot \text{TV}(P \parallel \hat{P}),
\end{align}
where $\text{TV}(P \parallel \hat{P})$ represents the total variation distance between the distribution of the undistorted embedding and the distribution of the embedding independent of the client's prompt embedding. $\text{TV}(P \parallel \hat{P})$ is a constant that has nothing to do with the protection mechanism. Eq. (\ref{eq:tv}) indicates that when interacting with an LLM using protected prompts, it is impossible to minimize both privacy leakage and utility loss simultaneously.

Several studies have explored privacy-utility trade-offs in FedFMs. In FedFMs, privacy protection can be categorized into two scenarios: 1) absolute privacy protection, where no leakage is allowed, and 2) privacy protection with cost, where only specific data (e.g., names) is protected, focusing on key information. Common methods for absolute privacy protection include homomorphic encryption~\cite{zheng2024safely} and differential privacy~\cite{ hou2023privately}. For privacy with cost, techniques like knowledge distillation~\cite{wang2023can} and tunable soft prompts~\cite{dong2023tunable} can be applied. 


Given the large number of parameters in FMs, optimizing efficiency without sacrificing performance is a critical challenge in FedFMs foundational theory. To this end, several methods~\cite{wu2024fedbiot,su2024titanic,yue2023fedjudge} have been proposed to enhance the efficiency of FedFMs systems. For instance, \citet{kuang2024federatedscope} introduced a federated parameter-efficient fine-tuning (PEFT) framework. Additionally, \citet{yue2023fedjudge} and \citet{su2024titanic} focused on selecting key parameters or subsets of clients to minimize communication costs, and \citet{wu2024fedbiot} leverages model compression for FedFMs.


In FedFMs, addressing system heterogeneity is crucial, as variations in data, resources, and personalization needs affect both global model generalization and client fairness. To tackle this, \citet{6-data-feddpa} employed global and local adapters to handle distribution shifts and personalized needs.

\subsubsection{Open- and Closed-Source FMs Trade-off Methods}

FMs can be categorized as closed-source (black-box) and open-source (white-box) based on parameter accessibility and usage rights. Closed-source FMs (e.g., GPT-4~\cite{OpenAI_GPT4_2023}) are proprietary, with their architecture, weights, and training processes kept confidential. These models are typically accessible only via APIs, limiting users' control over internal workings. In contrast, open-source FMs (e.g., LLaMA~\cite{touvron2023llama}) provide full access to architecture, weights, and training methods, enabling free access, modification, and redistribution by the community.

Aggregation plays a crucial role in training and fine-tuning FedFMs, requiring efficient knowledge integration while maintaining data privacy. However, aggregation methods differ between closed-source and open-source FMs, impacting how organizations deploy, train, and share models. These differences involve trade-offs in complexity, resource and feasibility.


In FedFMs, aggregation methods vary between open-source and closed-source models. For white-box FedFMs, where model weights and architectures are accessible~\cite{zhang2023towards, wang2024flora}, traditional parameter-based aggregation methods, such as FedAvg~\cite{mcmahan2017communication}, can be used. These methods allow for customized aggregation at different layers based on specific needs~\cite{zhang2023towards, li2020federated}. However, implementing open-source FedFMs requires significant AI expertise, computational resources, and infrastructure, which may not be feasible for all organizations. In contrast, black-box FedFMs, where model parameters are inaccessible~\cite{guo2023pfedprompt, yang2023efficient, bai2024diprompt}, focus on prompt-level aggregation. This involves aggregating high-level representations or prompt patterns~\cite{guo2023pfedprompt, yang2023efficient, bai2024diprompt}, rather than direct model parameters. This "prompt-centric" approach reduces technical barriers and operational overhead, making it accessible to organizations with limited AI expertise or resources, though it offers less customization than weight-based methods~\cite{yi2023pfedes}.


\subsection{Challenges and Potential Solutions}


\textit{Multi-objective optimization} in FedFMs remains challenging, as balancing privacy, utility, and efficiency across data heterogeneity, varying client resources, and network conditions is difficult. While Pareto optimization provides a theoretical framework, real-world complexities hinder achieving an optimal balance. Addressing \textit{fairness} across heterogeneous clients is also critical, as FedFMs rely on large-scale sensitive data, often highly heterogeneous, impacting system utility.
Furthermore, developing \textit{effective aggregation} methods for both open-source and closed-source models in FedFMs poses another challenge. Open-source models allow traditional parameter-based aggregation but require advanced AI expertise. Closed-source models accessed via APIs limit direct access to parameters and rely on less customizable prompt-level aggregation.

To address these challenges, potential solutions include: (1) Establishing \textit{theoretical bounds} for dimensions such as privacy, utility, and efficiency. (2) Adopting \textit{cross-layer optimization} strategies to balance the data, model, and communication layers. (3) \textit{Adaptive strategies} that dynamically adjust to client capabilities and network conditions, incorporating game theory or reinforcement learning, can optimize resource allocation and minimize communication overhead. (4) Developing \textit{hybrid aggregation} methods is crucial for overcoming the limitations of both open-source and closed-source aggregation approaches.