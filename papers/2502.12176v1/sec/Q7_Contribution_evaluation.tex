% \usepackage{amsmath}
% \newpage 
\section{Problem 7: How to design incentive mechanisms through contribution evaluation in FedFMs?}
\label{con_eva}


\subsection{Defining Incentives through Contribution Evaluation}

    As the scaling law shows, the FMs' performance relies on high-quality data and substantial computational resources, which need appropriate compensation to be contributed in the real-world.
    Thus, it is crucial for FedFMs to attract data providers and incentive them to contribute high-quality data or other resources.
    The contribution evaluation for FedFMs aims to enable the client's participation by measuring the importance of datasets or computational resources.
    The incentive mechanisms for FedFMs aim to ensure the data providers' active and sustained participation by providing them with fair rewards.
    Contribution evaluation in FedFMs refers to measuring the importance or influence of heterogeneous datasets, model quality, or computational resources, which is vital for identifying the free riders and outliers within the FedFMs ecosystem and can serve as a prerequisite for the incentive mechanisms in FedFMs.

        
    
\textbf{Problem Formulation}.
Consider a scenario with \(K\)  clients, where each client \(k\) has a private dataset \(D_{k}\). A contribution evaluation mechanism $\mathcal C$ is designed to compute the contribution \(\mathcal C(w, D_k)\) for client \(k\) by introducing data $D_k$ in FedFMs. Assume an Oracle knows the true contribution $C_k^*$ for each client $k.$
The objective of contribution evaluation is to look for the contribution evaluation mechanishm $\mathcal C$ such that this evaluation is accurate \cite{song2019profit, wei2020efficient}, formulated as:
\begin{equation}
% \begin{split}\
 \min_{\mathcal C}\ell_{c,k}(C,w_s,D_k)
 :=\sum_{k=1}^K\|\mathcal C(w_s, D_k) -C_k^*\|_2^2.
% \end{split}
\end{equation}
Here ${\ell_{c,k}(\cdot)}$ is the loss of contribution estimation for client $k$.

 
\begin{figure}[htb]
        \centering
        \includegraphics[width=0.35\textwidth]{figures/Q7/3-Contribution-example.pdf} %
        \caption{Contribution Evaluation across Medical Institutions.}
        \label{fig:Q3_Contribution_Example}
        \vspace{-15pt}
    \end{figure}
 





\subsection{Existing Methods}
In contribution evaluation for FedFMs, the first step is to select an evaluation scheme and then chose a utility function to assess the FedFM's performance.
Prior work in contribution evaluation for FedFMs mainly focus on two aspects: \textit{(1) contribution evaluation schemes} and \textit{(2) utility functions}.


\subsubsection{Contribution Evaluation Schemes}

Existing work primarily include five schemes, \textit{i.e.,} \textit{individual}, \textit{interaction}, \textit{leave-one-out}, \textit{shapley value}, and \textit{least core}.


\textbf{Individual}.
The individual method~\cite{Individual} determines an individual's contribution in FedFMs by directly using the output of the utility function.
Formally, the individual method is defined as, $\varphi_{i}(v) = v(i)$,  where $v(\cdot)$ can be any utility function and $i$ represents the $i${\small-th} FedFMs client.
The primary limitation of this method is its inability to account for the marginal contribution.
The time complexity of the \textit{Individual} method is $\mathcal{O}(n)$.


\textbf{Leave-One-Out}. 
The leave-one-out (LOO) method~\cite{LOO1999} accounts for the marginal utility, which removes a specific individual and recalculating the evaluation value using.
It is calculated based on the difference between the overall utility of the entire FedFMs system and the utility obtained after the FedFMs client's removal.
Formally, the contribution is defined as $\varphi_{i}(v) = v(N) - v(N/\{i\})$, where $N$ denotes all the clients.


\textbf{Interaction}.
It evaluates clients' contributions in the training process, where we can vary the proportion of training data in each round to estimate the FedFMs client's contribution~\cite{RN9, RN33}.
The time complexity of \textit{Interaction} is $\mathcal{O}(n)$. 
Researchers also design several specific solutions tailored for distinct characteristics and application scenarios using interaction approach.
\citet{RN9} proposes FedCCEA.
It evaluates contributions by various FedFMs through random adjustments to the proportion of training data provided by FedFMs clients.
\citet{RN33} provided a contribution evaluation scheme using gradient-based evaluations, which ensures strong model performance and is well-suited for scenarios where the data distribution among FedFMs clients is typically statistically heterogeneous.


\textbf{Shapley-Value (SV)}. It is a classical concept in the collaborative game theory to fairly measures player's contribution~\cite{Shapley1988AVF}.
The SV provides four essential properties for contribution evaluation in FedFMs and is widely adopted as the standard evaluation scheme, such as \textit{no-free-rider, symmetric-fairness} and \textit{group-rationality}.
Though the Shapley value holds several desirable properties, it suffers from the computational complexity in $\mathcal{O}(2^n)$ and existing studies mainly adopt two kinds of approximation solutions, \textit{i.e.,} the sampling-based~\cite{RN21} and the gradient-based approximations~\cite{song2019profit, wei2020efficient}.


\textbf{Least Core}.
The core method~\cite{Sch1969nucleolus} is a classic concept widely applied in fields such as economics.
It requires contributions for any set of FedFMs clients should be no less than that of its subset.
The time complexity of \textit{Least Core} is also $\mathcal{O}(2^n)$.
% however, it can only be achieved sometimes. 
% As a remedy, the least core method minimizes the maximum loss value across all potential subsets.
Yan et al. \cite{Yan2021IfYL} used the least core and converts it as an optimization problem.
This evaluation scheme seeks to optimize the overall value distribution among all FedFM clients, prioritizing fairness at the coalition level.
   
\subsubsection{Utility Functions for Contribution Evaluation} 

The utility function measures the performance of FedFMs and prior studies can be divided into following two categories.



\textbf{Task-Specific Utility}. 
It quantifies FedFMs client's utility within specific tasks.
We review the three widely-adopted utility functions as follows.
    \textit{(i) Model Performance}~\cite{RN35}.
    It is a straightforward way to evaluate the utility of FedFMs clients by measuring their impact on model performance.
    \textit{(ii) Mutual Cross Entropy}~\cite{RN4}. It is a metric that quantifies the value of the FedFMs client's local dataset by calculating the mutual cross-entropy between the FL model's performance on local datasets and that on the test dataset.
    \textit{(iii) Influence Function}~\cite{RN12, RN13}. It is a classic technique in statistics tracing model predictions to identify the training data with most influence.
    

\textbf{Task-Agnostic Utility}. It provides functionality to measure the FedFMs client's contributions without being bound to specific learning tasks.
We review the commonly-used metrics as follows.
    \textit{(i) Data Size and Diversity}~\cite{RN15}. It quantifies the divergence of data distributions, with its value characterizing data value~\cite{RN16}. 
     \textit{(ii) Model Similarity}~\cite{RN18}. It assumes valuable data produces local models close to the global model and use the global model to evaluate local models.
    \textit{(iii) Mutual Information}. It takes the mutual information between local datasets 
    as the metric to evaluate the  FedFMs client's utility. 




\subsection{Challenges and Potential Solutions}

\textit{Scalability and computational overhead} are significant issues in FedFMs, as existing contribution evaluation methods, such as Shapley value-based approaches, exhibit exponential time complexity. It is crucial to design efficient yet fair contribution evaluation schemes tailored for billion-scale FedFMs. Additionally, \textit{data-task contribution mapping} remains challenging in FedFMs, as traditional approaches fail to account for task-specific data value variations.

To address these challenges, potential solutions include: (1) \textit{Learned contribution evaluation}, where FedFMs are trained for contribution assessment with adjustable loss functions and penalty coefficients. (2) \textit{Crowd-sourced data contribution map} can be established, leveraging results from numerous data providers to create and refine the valuation between data and downstream tasks.


