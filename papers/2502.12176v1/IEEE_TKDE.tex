\documentclass[lettersize,journal]{IEEEtran}
\usepackage{amsmath,amsfonts}
\usepackage{algorithmic}
\usepackage{algorithm}
\usepackage{array}
\usepackage[caption=false,font=normalsize,labelfont=sf,textfont=sf]{subfig}
\usepackage{textcomp}
\usepackage{stfloats}
\usepackage{url}
\usepackage{verbatim}
\usepackage{graphicx}
\usepackage{xcolor} 
\usepackage{colortbl}
\usepackage{utfsym}
\usepackage{adjustbox}
\usepackage{multirow}
\usepackage{makecell}
\usepackage{booktabs}
\usepackage{titlesec}
\usepackage{hyperref}
\usepackage{refcount}
\usepackage{caption}
\usepackage{threeparttable}
\usepackage[utf8]{inputenc}
\usepackage[numbers,square]{natbib} % 使用square选项
\hyphenation{op-tical net-works semi-conduc-tor IEEE-Xplore}
% updated with editorial comments 8/9/2021

\newcommand{\methodname}{{\tt{FedFM}}}
\newtheorem{definition}{Definition}

\DeclareMathOperator*{\argmax}{arg\,max}
\DeclareMathOperator*{\argmin}{arg\,min}
\begin{document}

\title{Ten Challenging Problems in Federated Foundation Models}


 \author{
      Tao Fan,
      Hanlin Gu,
      Xuemei Cao, 
      Chee Seng Chan,~\IEEEmembership{Senior Member,~IEEE,}
      Qian Chen, 
      Yiqiang Chen,~\IEEEmembership{Senior Member,~IEEE,}
      Yihui Feng,
      Yang Gu,~\IEEEmembership{Member,~IEEE,}
      Jiaxiang Geng,
      Bing Luo,~\IEEEmembership{Senior Member,~IEEE,}
      Shuoling Liu,~\IEEEmembership{Member,~IEEE,}
      Win Kent Ong,
      Chao Ren,~\IEEEmembership{Member,~IEEE,} 
      Jiaqi Shao,
      Chuan Sun,~\IEEEmembership{Member,~IEEE,} 
      Xiaoli Tang,
      Hong Xi Tae,
      Yongxin Tong,~\IEEEmembership{Member,~IEEE,}
      Shuyue Wei,
      Fan Wu,~\IEEEmembership{Member,~IEEE,} 
      Wei Xi,
      Mingcong Xu,
      He Yang,
      Xin Yang,~\IEEEmembership{Member,~IEEE,}
      Jiangpeng Yan,
      Hao Yu,
      Han Yu,~\IEEEmembership{Senior Member,~IEEE,}
      Teng Zhang,
      Yifei Zhang,
      Xiaojin Zhang,
      Zhenzhe Zheng,~\IEEEmembership{Member,~IEEE,} 
      Lixin Fan, ~\IEEEmembership{Member,~IEEE,}
      and Qiang Yang,~\IEEEmembership{Fellow,~IEEE}



\thanks{Apart from the first and corresponding authors, the remaining authors are listed in alphabetical order by their last names.}

\thanks{Tan Fan, Hanlin Gu are with the WeBank, Shenzhen, China (\textit{Co-First Author}, e-mail: tfanac@cse.ust.hk, allengu@webank.com).}

\thanks{Chee Seng Chan, Win Kent Ong, Hong Xi Tae are with the Universiti Malaya, Malaysia (e-mail: \{cs.chan, winkent.ong\}@um.edu.my, taehongxi55@gmail.com).}

\thanks{Yiqiang Chen, Yang Gu, Qian Chen, Teng Zhang are with the Institute of Computing Technology, Chinese Academy of Sciences, China (e-mail:  \{yqchen, guyang, chenqian20b, zhangteng19s\}@ict.ac.cn).}

\thanks{Bing Luo, Jiaxiang Geng, Jiaqi Shao are with the Duke Kunshan University, Kunshan, China (e-mail: \{bl291, jg645,  js1139\}@duke.edu).}

\thanks{Shuoling Liu, Jiangpeng Yan are with the Innovation Reseach Center, EFunds, China (e-mail: \{liushuoling, yanjiangpeng\}@efunds.com.cn).}

\thanks{Chao Ren is with the KTH Royal Institute of Technology, Sweden (e-mail: renc0003@e.ntu.edu.sg).}

\thanks{Yongxin Tong, Shuyue Wei are with the Beihang University, China (e-mail: \{yxtong, weishuyue\}@buaa.edu.cn).}

\thanks{Fan Wu, Zhenzhe Zheng are with the Shanghai Jiao Tong University, China (e-mail: fwu@cs.sjtu.edu.cn, zhengzhenzhe@sjtu.edu.cn).}

\thanks{Wei Xi, He Yang are with the Xi'an Jiaotong University, China (e-mail: xiwei@xjtu.edu.cn, sleepingcat@stu.xjtu.edu.cn).}

\thanks{Xin Yang, Xuemei Cao, Yihui Feng, Hao Yu are with the Southwestern University of Finance and Economic, China (e-mail: yangxin@swufe.edu.cn, caoxuemei.qpz@gmail.com, yihuifeng@foxmail.com, yuhao2033@163.com).}

\thanks{Han Yu, Chuan Sun, Xiaoli Tang, Yifei Zhang are with the Nanyang Technological University, Singapore (e-mail: \{han.yu, chuan.sun,  yifei.zhang\}@ntu.edu.sg, xiaoli001@e.ntu.edu.sg).}

\thanks{ Xiaojin Zhang, Mingcong Xu are with the Huazhong University of Science and Technology, China (e-mail: \{xiaojinzhang, xumingcong\}@hust.edu.cn).}


\thanks{Lixin Fan is the Principal Scientist of Artificial Intelligence at
WeBank, Shenzhen, China (\textit{Co-Corresponding Author}, e-mail: lixinfan@webank.com).} 

\thanks{Qiang Yang is Professor Emeritus at the Department of Computer Science and Engineering,
Hong Kong University of Science and Technology, Hong Kong, and the Chief AI Officer of WeBank, Shenzhen, China (\textit{Co-Corresponding Author}, e-mail: qyang@cse.ust.hk).} 
}

% The paper headers
% \markboth{IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING,~Vol.~, No.~, ~2025}%
% {Shell \MakeLowercase{\textit{et al.}}: Ten Challenging Problems in Federated foundation Models}



\maketitle
% As a general rule, do not put math, special symbols or citations
% in the abstract or keywords.
\begin{abstract}
Federated Foundation Models (FedFMs) represent a distributed learning paradigm that fuses general competences of foundation models as well as privacy-preserving capabilities of federated learning. This combination allows the large foundation models and the small local domain models at the remote clients to learn from each other in a teacher-student learning setting. This paper provides a comprehensive summary of the ten challenging problems inherent in FedFMs, encompassing foundational  theory, utilization of private data, continual learning, unlearning, Non-IID and graph data, bidirectional knowledge transfer, incentive mechanism design, game mechanism design, model watermarking, and efficiency.  
The ten  challenging problems manifest in five pivotal aspects: ``Foundational Theory,"  which aims to establish a coherent and unifying theoretical framework for FedFMs. ``Data," addressing the difficulties in leveraging domain-specific knowledge from private data while maintaining privacy; ``Heterogeneity," examining variations in data, model, and computational resources across clients; ``Security and Privacy," focusing on defenses against malicious attacks and model theft; and ``Efficiency," highlighting the need for improvements in training, communication, and parameter efficiency. 
For each problem, we offer a clear mathematical definition on the objective function, analyze existing methods, and discuss the key challenges and potential solutions. This in-depth exploration aims to advance the theoretical foundations of FedFMs, guide practical implementations, and inspire future research to overcome these obstacles, thereby enabling the robust, efficient, and privacy-preserving FedFMs in various real-world applications.
\end{abstract}

% Note that keywords are not normally used for peerreview papers.
\begin{IEEEkeywords}
Federated Foundation Models, Federated learning, Foundation Models.
\end{IEEEkeywords}

\IEEEpeerreviewmaketitle

\input{sec/introduction}
\input{sec/notation_table}
\input{sec/Q1_Basic_theory}
\input{sec/Q2_Private_data_utilization}
\input{sec/Q3_Continual_learning}
\input{sec/Q4_Unlearning}
\input{sec/Q5_non-iid_in_FL}
\input{sec/Q6_Bidirectional_knowledge_transfer}
\input{sec/Q7_Contribution_evaluation}
\input{sec/Q8_Game_mechanism_design}
\input{sec/Q9_Model_watermarking}
\input{sec/Q10_Efficiency}
\input{sec/conclusion}


\appendices



\ifCLASSOPTIONcaptionsoff
  \newpage
\fi

\footnotesize
\bibliographystyle{IEEEtranN}
\bibliography{reference_new1}


\vfill

\end{document}


