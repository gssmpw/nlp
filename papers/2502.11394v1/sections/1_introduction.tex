\section{Introduction}
% what is gnn
Graph neural networks (GNNs) are a powerful framework for processing graph-structured data across a wide range of applications, such as drug discovery, recommender systems and social networks ~\citep{Gori2005GNN, Scarselli2009TheGN,Bruna2014SpectralNA,Duvenaud2015ConvolutionalNO, Defferrard2016ConvolutionalNN, Battaglia2016Interaction, Li2016Gated}. 
% Most GNN models recursively aggregate information from all neighboring nodes along the unsigned edges (unsigned message-passing)
Most GNN models follow the \textit{message-passing} paradigm, where node features are computed by recursively aggregating information from neighboring nodes along the edges~\citep{gcn,sgc,gat,gin}.
% Unrestricted aggregation of all neighbors would eventually cause the oversmoothing issue, where
Despite notable advancements, oversmoothing remains an issue for deploying
GNNs in practice, characterized by the convergence of all node features to a common value 
when stacking a substantial number of GNN layers~\citep{oversmooth_first, Oono2019GraphNN, Cai2020ANO, wu2023demystifying}.

Several strategies~\citep{LRGNN,Peng2024BeyondOU,signremedy,orderedgnn,ACM-GCN,GRP-GNN} have been developed to mitigate oversmoothing in GNNs, 
including normalization layers~\citep{centernorm,layernorm, contranorm, pairnorm}, random edge dropping~\citep{Fang2022DropMessageUR}, and residual connections~\citep{GCNII,wGCN,appap,dagnn,jknet}. 
However, these methods arise from different motivations and lack a unified framework for comparison and analysis, making it unclear why they succeed or fail on specific homophilic or heterophilic graphs and explaining their inefficacy in deep-layer regimes~\citep{platonov2023critical,sbm_xinyi,ma2021homophily}.

In this paper, we introduce a signed graph perspective to theoretically analyze existing anti-oversmoothing methods, categorizing eight empirically effective approaches~\citep{contranorm,pairnorm,batchnorm,dropedge,do2020graph,appap,jknet,dagnn} into three major groups. Our analysis reveals that all these methods can be mathematically interpreted as message-passing over a signed graph with different design choices, where negative edges induce repulsion among neighboring nodes, thereby mitigating oversmoothing.  
% Consequently, they may only mitigate oversmoothing to a limited extent, .
% However, there lacks a unified understanding of these different strategies for dissecting their limitations,  as it seems that these methods can only mitigate oversmoothing to a certain extent, and the model performance still degrades after a large number of propagation steps~\citep{oversmooth_first,sbm_xinyi}.
% The prevalence of unsigned message-passing among GNNs stems from two key aspects in their development. 
% First, unsigned graphs possess conventional Laplacians that enable spectral graph neural networks based on graph signal processing principles~\citep{gcn,sgc,gat,gin}.
% This property allows for a natural representation of graph convolution operations in the Fourier domain. 
% However, in the presence of negative edges, more than one definition of Laplacian is possible. This ambiguity in defining the Laplacian for graphs with negative edges poses significant challenges for analyzing and making use of the spectral properties of such signed graphs~\citep{signed_dynamics_paper_review}.
% Orthogonal Laplacian eigenvectors act as a natural generalization of the Fourier transform and allow to express graph convolution operations in the Fourier domain.
% Secondly, early benchmarks for node classification predominantly feature \textit{homophilic} graphs like Cora, CiteSeer, and PubMed~\citep{cora,pubmed}, where neighboring nodes in the graph often share identical labels. In that case, unrestricted aggregation of all neighbors can help improve node classification accuracy~\citep{sbm_xinyi}. On the contrary, when neighboring nodes exhibit dissimilar labels, which is known as being \textit{heterophilic}, the performance ofthe unsigned message-passing tends to deteriorate, unless the rooted subtree of each node in the graph satisfies certain specific structural property.~\citep{ma2021homophily}
% , resulting in lower performance levels than random guessing. 
% alleviate methods
% 2 problems
% However, despite these empirical advancements, two primary challenges remain unresolved. 
% these empirical advancements are promising, the heuristic nature of these strategies makes it difficult to discern their precise mechanisms for alleviating oversmoothing.
% Furthermore, the absence of a unified framework complicates the direct comparison and hinders the understanding of these methodologies.
% introduce signed graph
% In this paper, we revisit \textit{signed graph}~\citep{signedgraph} as a unified framework to formalize and understand existing oversmoothing countermeasures.
% A signed graph is one in which each edge has a positive or negative sign compared to a standard graph with only positive or unsigned edges.

\begin{figure*} % {0.99\textwidth}
% \vspace{-0.05in}
    \centering
    \captionsetup{font=small}
    \includegraphics[width=0.8\textwidth]{figures/SBP-overview.pdf}
    % {figures/diagram2.pdf}
    \vspace{-2ex}
    \caption{  Illustration of different graph structures, edge types used in this work and our method, \ours.
    Blue and orange circles represent nodes from class 1 and class 2, respectively. Solid lines indicate actual edges, while dashed lines denote constructed edges. Positive and negative edges are represented by black and purple lines, respectively. Let \(x_i\) be the node features for node \(i\).
    (a) Unsigned graph with all positive edges.
    (b) Structurally balanced graph with positive edges within clusters and negative edges between clusters. (c) Label-\ours, which adds negative edges between classes and positive edges within classes.
    (d) Feature-\ours, which adds edges based on node feature similarities. Here, we assume the underlying graph is homophilic, meaning that node features in the same class are similar. This results in adding positive edges within classes and negative edges between classes.
    % Left: comparison of different graphs. (a) is an unsigned graph where all edges are positive, (b) is a signed graph where edges are either positive or negative, and (c) is a structural balance graph where positive edges exist only within clusters, and negative edges only exist between clusters. Right: example of structural balance adjacency matrix $A_s$ composed of a positive adjacency matrix $A^+$ and a negative adjacency matrix $A^-$ where $\alpha$ and $\beta$ are the weights representing the strengths of attraction and repulsion, respectively.
    }
    \label{fig: sb sample}
\vspace{-3ex}
\end{figure*}



This observation not only highlights how these techniques mitigate oversmoothing through a unified signed graph perspective but also motivates a deeper exploration into the asymptotic behavior of signed graph propagation.
Our theoretical analysis suggests that while negative edges can partially disperse nodes and thus help mitigate oversmoothing, message-passing over an arbitrary signed graph would inevitably either converge or diverge over a large number of propagation steps (Theorem~\ref{thm: small nega}). 
To address this, we introduce the \textit{structural balance graph}, characterized by a distinctive distribution of positive and negative edges, serving as an ideal condition for controlling the asymptotic behavior of signed graph propagation.
As illustrated in Figure~\ref{fig: sb sample}(b),
a structurally balanced graph consists of clusters where only positive edges exist within each cluster and only negative edges exist between clusters. 
% Built upon these theoretical findings, we introduce the signed graph propagation based on the structurally balanced graph, termed as \textit{structurally balanced propagation} (\ours)~\citep{structuralbalance}, taking into account the signed edge distribution based on different clusters.
% As illustrated in Figure~\ref{fig: sb sample}, in a structurally balanced graph, nodes can be grouped into clusters where only positive edges exist within each cluster, and only negative edges exist between clusters. 
% We demonstrate that signed propagation over a structurally balanced signed graph 
Under signed graph propagation in such a graph,  nodes within the same cluster converge to a shared value, while different clusters repel each other to have distinct values (Theorem~\ref{thm: repel_struct}. This long-term behavior effectively manages oversmoothing within clusters while simultaneously preserving inter-cluster separation, thereby enhancing node classification accuracy in the long run.



% \xw{discuss how SB graphs are nonetheless an ideal condition, then connect to the next paragraph}
% revisit \textit{signed graphs}~\citep{signedgraph, signed_dynamics_paper_review} where each edge has a positive or negative sign and propose that 
% Thus the signed propagation can serve as a remedy to combat the overmoothing issue. 
% Moreover, we collect eight classic yet empirically efficient oversmoothing countermeasures in the existing literature (Section~\ref{sec: background}). 

% when oversmoothing was supposed to occur when edges are unsigned. 
% and theory
% \yf{Need more background and motivation on signed graph to use this; highlight that why it is more unified}
% Conventionally, a signed graph is one in which each edge has a positive or negative sign compared to a standard graph with only positive or unsigned edges. 
% Signed graph propagation can be divided into attraction and repulsion rules depending on whether the edge is positive or negative, respectively.
% In the signed graph propagation, positive edges form a positive graph that attracts nodes, while negative edges create a negative graph that repels them.
% Through the lens of signed graphs, 
% Specifically, we categorize these methods into three major types: normalization (BatchNorm~\citep{batchnorm}, PairNorm~\citep{Zhao2020PairNorm}, and ContraNorm~\cite{contranorm}), edge dropping  (Edge Drop and Node Drop~\citep{dropedge}) and residual connections (Residual, APPNP~\citep{appap}, JKNET~\citep{jknet}, and DAGNN~\citep{dagnn}).
% for mitigating oversmoothing 

% with the same positive graph (but with different designs of the negative graph), 

% This observation motivated us to review that oversmoothing issue from a novel signed graph perspective. 
% We theoretically prove when the graph of only positive edges are connected, the oversmoothing can be alleviated eventually when the repel ability is sufficiently large.
% This suggests that traditional unsigned graph convolution cannot theoretically mitigate oversmoothing and provides a unified perspective for reviewing and analyzing previous studies from the standpoint of repulsion.
% \yf{distill more concrete messages from the theory}




% but also inspires us to further make use of the signed graph to theoretically address the oversmoothing issue.the explicit design of signed graphs to alleviate the oversmoothing issue.
% balance theory

% This underscores the limitations of previous methods on general graphs, which may fail in settings such as homophilic or heterophilic graphs.
% We find that although negative edges can partially disperse nodes to some extent, arbitrary signed propagation does not definitively resolve oversmoothing with a theoretical guarantee (Theorem~\ref{thm: small nega}), highlighting the ineffectiveness of previous methods on general graphs, such as potentially failing on homophilic or heterophilic graphs.

% This asymptotic behavior of structural balance raises hope for theoretically alleviating oversmoothing~\citep{sbm_xinyi}.  

% our methods
% Based on the 
% Motivated by our structural balance analysis, we propose our method: \oursfull (\ours) to artificially construct a structurally balanced graph to conduct signed propagation.
% , a principled approach to attain a meaningful feature equilibrium to alleviate oversmoothing 
% \xinyic{what do you mean by "meaningful feature equilibrium"? Unclear to me. jq: changed}
% Specifically, we devise two practical variants of \ours, Labels-\ours and Feature-\ours, where we respectively leverage label and feature information to assign positive edges among intra-class nodes and negative edges among inter-class nodes in the training set without any additional learnable parameters. 
% Specifically, we leverage the ground truth in the training set (label) to assign positive edges among intra-class nodes and negative edges among inter-class nodes  without any additional learnable parameters, which we denote as Label-\ours.
Motivated by our structural balance analysis, we introduce \oursfull (\ours), a method for constructing a structurally balanced graph to facilitate signed propagation. Specifically, we propose Label-\ours, which assigns positive edges between nodes of the same class and negative edges between nodes of different classes, without introducing additional learnable parameters (Figure~\ref{fig: sb sample}(c)). 
This is achieved by preserving the original unsigned graph as the positive graph and leveraging the training labels to construct the negative graph. We show that as the training ratio increases, Label-\ours progressively approximates a structurally balanced graph (Proposition~\ref{pro: ours-label}). To handle scenarios with limited ground truth information, we further introduce a feature-induced variant, Feature-\ours (Figure~\ref{fig: sb sample}(d)). Instead of relying on labels, Feature-\ours constructs the negative graph based on node similarities, enabling its applicability in label-scarce settings. 
% under the simplified GNN settings~\citep{sgc}.

\textbf{Our main contributions are summarized as follows:}
\begin{itemize}[leftmargin=1ex]
    \vspace{-2ex}
    \item We present a signed graph perspective to unify three major classes of anti-oversmoothing techniques, demonstrating that they all implicitly involve adding negative edges to the original graph. This perspective offers a unifying framework, shedding light on the underlying mechanisms of these techniques and the role of signed edges in mitigating oversmoothing. 
    % (Section~\ref{sec: signed pers}).
    \item We introduce \oursfull (\ours) to alleviate oversmoothing with theoretical guarantees. To quantify the level of structural balance in a signed graph, we propose a novel metric, structural imbalance degree (\(\mathcal{SID}\)). Leveraging both theoretical insights and \(\mathcal{SID}\), we reveal that existing anti-oversmoothing techniques fail to achieve structural balance due to the improper distribution of signs, which explains their inefficacy in consistently combating oversmoothing over a large number of propagation steps.
    % \item We further analyze message-passing over signed graph and introduce the concept of structural balance from the signed graph theory, proving that it is an ideal state to alleviate oversmoothing while improving node classification accuracy (Section~\ref{subsec: sb theory}).
    % By measuring the Structural Imbalance Degree ($\mathcal{SID}$), we find that due to the lack of class-awareness, existing techniques fail at improving $\mathcal{SID}$, which explains their inefficacy under more propagation steps.
    % theoretically demonstrate that the negative graph introduces repulsion in message-passing. 
    % The structural balance theory further reveals that convergence of node features to the same value can be controlled within positive edge clusters while the repulsion only occurs between clusters connected by negative edges. 
    % Such an asymptotic behavior would be ideal for node classification.
    \item Motivated by the desirable asymptotic behavior of signed graph propagation over structurally balanced graphs, we propose Label-SBP and Feature-SBP, which explicitly design negative edges to enhance the structural balance of the signed graph. Experiments on nine datasets demonstrate that SBP consistently improves node classification accuracy in both homophilic and heterophilic settings, validating the effectiveness of SBP and the value of our signed graph perspective.
    % (Section~\ref{sec: exp_main}).
% verify our signed graph insight and the effectiveness our method \ours in practice.
\end{itemize}
