\section{Related Work}
\textbf{Deep Learning in Survival analysis.} Machine learning and deep learning techniques for survival analysis are not limited to LVSM. ____ introduced the first neural-network-based Cox regression model, allowing nonlinear relationships between covariates. A modern yet similar one is DeepSurv ____. Deep Cox Mixture ____ extends this idea to finite mixture models, but all these Coxian models rely on the proportional hazards (PH) assumption, which results in separated survival functions ____ and may be unrealistic. A famous nonparametric tree ensemble approach, Random Survival Forest ____, builds multiple decision trees to model the cumulative hazard function, leveraging Nelson-Aalen estimator ____. That said, hazard function estimation for discrete time-to-event can also be framed as a series of binary classification problems, which can be solved by black-box methods via various network architectures. DeepHit ____ uses a simple shared network to model competing risks, while RNN- ____ and Transformer-based ____ structures capture sequential relationships in time-specific predictions. These methods often require additional techniques to mitigate overfitting.

\textbf{Inference Optimality in Survival Analysis.} Improving VI of latent variable models has been extensively discussed in general learning tasks. For instance, ____ suggests utilizing a more expressive variational family than the commonly used factorized Gaussians. ____ suggests that an annealed training dynamic for model parameters can enhance the estimated $q_\phi$ and $\theta$. We subjectively summarize the types of strategies to facilitate a better estimate $\theta^*$: (1) maximize the availability of optimal VI for more $\theta$, i.e., increasing the support of $\theta$, where $\min_{\phi} B(\theta,\phi)=0$;  (2) propose a tighter lower bound than ELBO to reduce $\min_{\phi} B(\theta,\phi)$ for general $\theta$; (3) training strategies to avoid some notorious suboptimal inference like posterior collapse. %However, most of them do not apply to LVSM and account for censored data. 
As contributions, our criticism on vanilla VI, the extensions of IS and DVI on CDVI, and the discussion on decoder variance fall under each type, respectively.

\textbf{Variational method for other tasks.} Variational methods in survival analysis are not limited to time-to-event modeling. One unsupervised task is identifying potential sub-populations, providing valuable insights for treatment recommendations and clinical decision-making ____. These clustering models, if used as an intermediate step of time-to-event modeling, can be seen as a restricted LVSM, often in a D-separation latent structure. While a restrictive approach can help prevent overfitting, our criticism remains valid: the objective of VI in unsupervised tasks can be misaligned with M-estimation of the time-to-event distribution, undermining the performance of survival time prediction. 
\vspace{-5pt}