\section{Sample Efficiency Bounds for Controller Synthesis Approaches}

\vspace{-5pt}

\begin{table}[h!]
    \centering
    \begin{tabular}{|c|c|c|c|c|}
    \hline
        Method\! & Leading Term & Burn-in Time & \!Scalable Alg.\! & Source of Bounds \\
    \hline
     CE & $\frac{1}{N}\trace\paren{H(\theta^\star) \mathsf{FI}(\theta^\star)^{-1}}$ & $ {\norm{P(\theta^\star)}^{10}}$ & Yes & \!\citet{wagenmaker2021task}\footnotemark\! \\
     \hline
     RC & $\frac{1}{N} d_{\theta} \norm{H(\theta^\star) \mathsf{FI}(\theta^\star)^{-1}}$ & ${\!\norm{P(\theta^\star)}^4\!\vee\! \frac{1}{r^2}}\!$ & No & This paper \\
     \hline
     DR & $\frac{1}{N}\trace\paren{H(\theta^\star) \mathsf{FI}(\theta^\star)^{-1}}$ & $ \!{\norm{P(\theta^\star)}^{11}} \tau_{B(\theta^\star\!)}^{16}\!$ & Yes & This paper \\
     \hline
    \end{tabular}
    \vspace{-6pt}
    \caption{Comparison of sample efficiency bounds for CE, RC, and DR. The leading term is stated up to universal constants. The burn-in time reports the components which are different between the three approaches. We use the shorthand $\tau_{B(\theta^\star)} = \norm{B(\theta^\star)} \vee 1$. We classify algorithms as scalable if they are possible to implement via first order gradient-based approaches.}
    \vspace{-2pt}
    \label{tab:sample_efficiency}
\end{table}
\footnotetext{Due to slight discrepancies in the setting (e.g. we consider multiple trajectories for identification), the exact version of the certainty equivalent bound considered is presented in \Cref{s: certainty equivalence bound}.}


Our sample efficiency bounds are summarized in \Cref{tab:sample_efficiency}, where they are compared with existing bounds for certainty equivalence. The leading term in the bound characterizes the asymptotic rate of decay. For all three synthesis approaches described in \Cref{s: methods}, the leading term depends on four quantities: the parameter dimension, $d_{\theta}$, the number of experiments, $N$, the Fisher Information matrix $\mathsf{FI}(\theta^\star)$, and a matrix $H(\theta^\star)$, which captures the sensitivity of control synthesis to the estimation error. In particular, $H(\theta^\star)$ is given by
\begin{align*}
    H(\theta^\star) = \nabla_{\theta}^2 C(K(\theta), \theta^\star)\vert_{\theta=\theta^\star}.
\end{align*}
\citet{wagenmaker2021task} show that $\frac{1}{N}\trace\paren{H(\theta^\star) \mathsf{FI}(\theta^\star)^{-1}}$ is the optimal asymptotic rate achievable by any algorithm mapping a dataset \eqref{eq: dataset} to a controller.\footnote{This lower bound is specified to our setting in \Cref{s: lower bound proof}.} Accordingly, both certainty equivalence and domain randomization can be classified as sample-efficient, as they achieve this optimal rate of decay with respect to system-theoretic quantities. The bound on robust control instead has a leading term of $d_{\theta} \norm{H(\theta^\star) \mathsf{FI}(\theta^\star)^{-1}} \geq \trace\paren{H(\theta^\star) \mathsf{FI}(\theta^\star)^{-1}}$, and therefore cannot be classified as efficient.\footnote{While we lack a formal lower bound proving the inefficiency of RC, experiments support this conclusion (see Fig.~\ref{fig:result dr lqr}).} 

\Cref{tab:sample_efficiency} also highlights the burn-in time, the number of samples that suffice for the sample efficiency bounds to hold. The reported values omit terms common to all three methods. Among the differing quantities, the burn-in for CE scales with $\norm{P(\theta^\star)}^{10}$, for DR it scales with $\norm{P(\theta^\star)}^{11}\tau_{B(\theta^\star)}^{12}$, and for RC it scales with the max of $\norm{P(\theta^\star)}^{4}$ and $\frac{1}{r^2}$, a term quantifying the robust stabilizability of $\theta^\star$. Although $\frac{1}{r^2}$ can be as large as $\norm{P(\theta^\star)}^{10}$, it is often much smaller (see \Cref{s: robust control}), suggesting that robust control can achieve a much lower burn-in than the alternative approaches for many system instances.\footnote{We emphasize that these burn-in conditions are sufficient but not necessary; refining them is left to future work.} Experiments further suggest that domain randomization's burn-in can potentially fall between that of certainty equivalence and robust control.

Finally, \Cref{tab:sample_efficiency} highlights that certainty equivalence and domain randomization give rise to scalable gradient-based policy optimization algorithms, which can easily be extended to nonlinear and high dimensional systems. In contrast, the solving the robust control problem requires computationally challenging LMI-based approaches, even for fully observed linear systems. 


\subsection{Sample Efficiency of Domain Randomization}

We now establish the characterization of domain randomization in the final row of \Cref{tab:sample_efficiency}. To this end, we first define a burn-in time which enables a bound on the the least squares  error: 
\begin{align}
    \label{eq: id burn-in}
    N_{\mathsf{ID}} \triangleq \mathsf{poly}\paren{\sum_{t=0}^{T-1} \norm{A(\theta^\star)^t \bmat{I & B(\theta^\star)} }, \norm{\Sigma_u}, \norm{\Sigma_w}, \norm{\mathsf{FI}(\theta^\star)}, \frac{1}{\lambda_{\min}\paren{\mathsf{FI}(\theta^\star)}} }.
\end{align}
A bound on least squares using this quantity is shown in \Cref{s: id bound proof}. Proofs for the remainder of the results in this section may be found in \Cref{s: domain randomization proofs}. 

We first state a bound on the performance of domain randomization that holds for general sampling distributions centered at $\hat \theta$. 
\begin{lemma}
    \label{lem: domain randomization general}
    Suppose the dataset $\curly{(X_t^n, U_t^n, X_{t+1}^n)}_{t=1, n=1}^{T,N}$ is collected from N trajectories of the system \eqref{eq: linear system} via a random control input $U_t \sim \calN(0, \Sigma_u)$. Let $\hat\theta$ be the least square estimate computed by \eqref{eq: least squares}. Let $\calD$ be any distribution with mean $\hat \theta$, and which is supported on a set with diameter bounded by $\frac{1}{256} \norm{P(\theta^\star)}^{-5}$.
    It holds with probability at least $1-\delta$ that 
    \begin{align}
        &C(K_{\mathsf{DR}}(\calD), \theta^\star) - C(K(\theta^\star), \theta^\star) \nonumber \leq \frac{8{\trace\paren{H(\theta^\star}{\mathsf{FI}}(\theta^\star)^{-1})}}{N} + 2\trace\paren{\mathbf{V}(\calD) H(\theta^\star)} \\& + 16\frac{\norm{H(\theta^\star)\mathsf{FI}(\theta^\star)^{-1}}}{N}\log\frac{2}{\delta} + L_{\mathsf{DR}}(\theta^\star)\frac{\norm{\mathsf{FI}(\theta^\star)^{-1}}^{3/2}}{N^{3/2}}, \label{eq:DR upper bound}
    \end{align}
    where $
        L_{\mathsf{DR}}(\theta^\star, \delta) = \mathsf{poly}(d_{\theta}, \max\curly{1, \norm{B(\theta^\star}}, \norm{P(\theta^\star)}, \log\frac{1}{\delta}),$ as long as the number of experiments $N$ satisfies $N \geq \max\curly{N_{\mathsf{ID}}, ~ \frac{c\norm{P(\theta^\star)}^{11} (\norm{B(\theta^\star)} \vee 1)^{16}\paren{d_\theta+\log\frac{2}{\delta}}}{\lambda_{\min}\paren{\mathsf{FI}(\theta^\star)}}}$ for a universal constant $c$.
\end{lemma}

To minimize the above upper bound, choosing a sampling distribution with a variance of zero would be best and would lead to completely canceling the term with $\mathbf{V}(\calD)$. However, this would eliminate any benefits that we hope to see in the low data regime. Instead, to maximize the potential robustness benefits, we should choose the distribution with the most spread, which does not significantly degrade the performance achieved for large $N$ (the regime where the above bound is valid). We therefore propose choosing $\calD$ as a uniform distribution over the confidence ellipsoid constructed for RC \eqref{eq: confidence ellipsoid}. Computing the variance of this quantity demonstrates that the term $\trace\paren{\mathbf{V}(\calD) H(\theta^\star)}$ scales as $\frac{1}{N}\trace\paren{\hat{\mathsf{FI}}^{-1} H(\theta^\star)}\paren{1 + \frac{1}{d_{\theta}}\log\frac{2}{\delta}}$, leading to the following bound. 

\begin{theorem}
    \label{thm: Domain Randomization Upper Bound}
    Under the setting of \Cref{lem: domain randomization general}, let $\calD$ be a uniform distribution over the confidence ellipsoid $G$ defined in \Cref{eq: confidence ellipsoid}. Then it holds with probability at least $1-\delta$ that 
    \begin{align}
        &C(K_{\mathsf{DR}}(\calD), \theta^\star) - C(K(\theta^\star), \theta^\star) \nonumber \leq \frac{40\paren{1+\log\paren{\frac{2}{\delta}}/d_\theta}\trace\paren{H(\theta^\star}{\mathsf{FI}}(\theta^\star)^{-1})}{N} \\
        &+ 16\frac{\norm{H(\theta^\star)\mathsf{FI}(\theta^\star)^{-1}}}{N}\log\frac{2}{\delta} + L_{\mathsf{DR}}(\theta^\star, \delta)\frac{\norm{\mathsf{FI}(\theta^\star)^{-1}}^{3/2}}{N^{3/2}},\label{eq:DR upper bound w/ unif dist}
    \end{align}
    as long as $N$ satisfies the burn-in time of \Cref{lem: domain randomization general}.
\end{theorem}
The burn-in time from \Cref{lem: domain randomization general} provides the powers of $\norm{P(\theta^\star)}$ and $\tau_{B(\theta^\star)}$ listed in the final row of \Cref{tab:sample_efficiency}. The leading term follows from the fact that $L_{\mathsf{DR}}(\theta^\star)$ is multiplied by $N^{-3/2}$, and therefore decays faster. The deviation terms (quantities multiplied by $\log\frac{2}{\delta}$) are not considered leading terms, because they are dominated by the term 
$\frac{1}{N}\trace\paren{H(\theta^\star) \mathsf{FI}(\theta^\star)^{-1}}$ when the bounds are converted from high probability bounds to bounds in expectation.
This leaves a universal constant multiplied by  $\trace\paren{H(\theta^\star) \mathsf{FI}(\theta^\star)^{-1}}$, leading to the characterization of domain randomization with the chosen distribution as sample efficient. 



The bound above fails to demonstrate a clear advantage of domain randomization over certainty equivalence in the low-data regime, despite empirical evidence suggesting such benefits (\Cref{fig:result dr lqr}). By designing the sampling distribution to have support on the confidence ellipsoid \eqref{eq: confidence ellipsoid}, we ensure that the true system $\theta^\star$ has positive density in the sampling distribution with high probability. This design raises the hope that domain randomization could reduce the burn-in time. However, we have not been able to prove this property, as we cannot exclude the possibility that for distributions with large support, the domain-randomized controller \eqref{eq: domain randomization} might incur very high costs  near $\theta^\star$ while performing well elsewhere. In contrast, we show in the sequel that robust control can provide such benefits, albeit at the expense of sacrificing asymptotic efficiency.


\subsection{Sample Efficiency of Robust Control}
\label{s: robust control}

We now establish the second row of \Cref{tab:sample_efficiency} by analyzing the efficiency of robust control. Our goal is to demonstrate how robust control addresses the limitations of certainty equivalence with limited data. To achieve this, we introduce a formal definition of robust stabilizability for the system. In this definition, we denote the state covariance of system $\theta$ under controller $K$ by $\Sigma^K(\theta)$. 

\begin{definition}[Robust Stabilizability]
    Let $M\in\R$ and $G$ be a set. $G$ is $M$-robustly stabilizable by CE if $\exists \theta \in G $ such that for all $\theta' \in G$, $\norm{\Sigma^{K(\theta)}(\theta')} \leq M$. 
    Let also $r\in\R$. $\theta$ is $(M,r)$-robustly stabilizable by CE if $\forall A\subseteq\mathcal{B}(\theta, r)$, $A$ is $M$-robustly stablizable by CE. 
\end{definition}

The above definition captures the idea that a CE controller synthesized for a some parameter in a set can stabilize every member of that set. This is stronger than merely assuming the existence of an arbitrary controller that stabilizes all members, and plays a key role in our analysis of robust control. Relaxing this condition is left for future work. Nevertheless, for any stabilizable system, we can choose $r$ sufficiently small to satisfy the condition. Specifically, by Theorem 3 of \citet{simchowitz2020naive}, if $r \leq \frac{1}{256} \norm{P(\theta)}^{-5}$, then $\theta$ is $(M,r)$-robustly stabilizable by CE with $M = 2 \norm{P(\theta)}$. However, the given condition is system-specific and can often be satisfied with larger $r$.
Consider the following example.

\begin{example}
    Consider a scalar linear dynamical system:
     % \begin{align*}
        $X_{t+1} = a^\star X_t + b^\star U_t + W_t \quad \forall t\geq 0,$
     % \end{align*}
    where $a^\star = 1.05$ and $b^\star = 1$. Suppose that only $a^\star$ is unknown. Consider the LQR problem defined by $Q=1$, and $R=1000$. Computing $\norm{P(\theta^\star)}$, it holds by \citet{simchowitz2020naive} that the instance is $(M, r)$ stabilizable with $M = 225$ and $r = 2\times 10^{-13}$. However, we can achieve a better characterization for this instance by noting that for any subset $G$ of the interval $[0.3, 1.8]$, synthesizing an LQR controller $k$ using the largest value of the parameter in $G$ ensures that $a + b^\star k < 0.97$ for all $a \in G$, thereby ensuring that $\norm{\Sigma^k(a)} \leq \frac{1}{1-.97^2}\leq 20$ for all $a \in G$. Then the instance is $(20, 0.75)$-robustly stabilizable by CE. 

    To illustrate the impact on control performance, suppose we have an estimate $\hat a = 1.01$. The certainty-equivalent controller derived from this estimate is $k=-0.0424$, which fails to stabilize the true system. In contrast, if we apply robust control over any uncertainty set within the interval 
    $[0.3,1.8]$ that includes $a^\star$, we synthesize a controller that stabilizes the system. Therefore, the robust control procedure selects such a controller to avoid infinite cost.
\end{example}

With the definition of robust stabilizability by certainty equivalence in hand, we proceed to state an upper bound on the excess cost incurred by the robust controller. 

\begin{theorem}
    \label{thm: Robust Control upper bound}
    Suppose the dataset $\curly{(X_t^n, U_t^n, X_{t+1}^n)}_{t=1, n=1}^{T,N}$ is collected from N trajectories of the system \eqref{eq: linear system} via a random control input $U_t \sim \calN(0, \Sigma_u)$. Let $\hat\theta$ be the least square estimate computed by \eqref{eq: least squares}, and $G$ be the confidence ellipsoid of \eqref{eq: confidence ellipsoid}.
    Choose $r > 0$. Let $M$ be the smallest real number such that $\theta^\star$ is $(M, r)$-robustly stabilizable.
    It holds that with probability at least $1-\delta$
    \begin{align}
        &C(K_{RC}(G), \theta^\star)\! -\! C(K(\theta^\star), \theta^\star)\nonumber\!\leq\! \frac{64\paren{d_\theta\!+\!\log\frac{2}{\delta}}\norm{H(\theta^\star)\mathsf{FI}(\theta^\star)^{\!-\!1}}}{N} \!+\! L_{\mathsf{RC}}(\theta^\star\!,\! \delta, M\!)\frac{\norm{\mathsf{FI}(\theta^\star)^{-1}\!}^{3/2}}{N^{3/2}}, %\label{eq:RC upper bound}
    \end{align}
    \sloppy where
    %\begin{align*}
        $L_{\mathsf{RC}}(\theta^\star, \delta, M) = \mathsf{poly}(d_{\theta}, \max\curly{1, \norm{B(\theta^\star)}}, \norm{P(\theta^\star)}, \log\frac{1}{\delta}, M),$
    %\end{align*}
    as long as the number of experiments satisfies
    %\begin{align}
    $N \geq \max\curly{N_{\mathsf{ID}}, \frac{c\norm{P(\theta^\star)}^4\paren{d_\theta+\log\frac{2}{\delta}}}{\lambda_{\min}\paren{\mathsf{FI}(\theta^\star)}}, \frac{c \paren{d_\theta+\log\frac{2}{\delta}}}{r^2 \lambda_{\min}\paren{\mathsf{FI}(\theta^\star)}}}$ for a universal constant $c$.  %\label{eq:RC burn-in time}    
    %\end{align}
\end{theorem}
A proof of this result is provided in \Cref{s: robust control proof}. Similar to \Cref{thm: Domain Randomization Upper Bound}, the leading term in \Cref{tab:sample_efficiency} is obtained by omitting the deviation term ($\log\frac{2}{\delta}$) and the lower-order term scaling with $N^{-3/2}$
 . While we lack a lower bound for robust control, we conjecture that the leading term is tight. The reasoning behind this conjecture is that robust control selects the worst-case perturbation of the parameter within the confidence set, which naturally leads to dependence on the operator norm, as opposed to the trace observed in alternative approaches.

The burn-in time from in the above theorem demonstrates how the robust stabilizability condition combined with the robust synthesis approach leads to the value reported in \Cref{tab:sample_efficiency}. 

%\Bruce{Replace this discussion in light of the discussion around Table 1. } Comparing the burn-in times of \Cref{thm: Robust Control upper bound} with that of  \Cref{thm: certainty equivalence bound} and \Cref{thm: Domain Randomization Upper Bound}, we notice that robust control potentially achieves a better burn-in time compared to certainty equivalence or domain randomization, due to the relaxation of the closeness condition on $\norm{\hat\theta-\theta^\star}$ using the definition of $(R,r)$-robust stabilizability by certainty equivalence. While certainty equivalence requires $\hat\theta$ to be close enough to $\theta^\star$ to actually stabilize $\theta^\star$ by $K_{CE}(\theta^\star)$, robust control is able to relax this condition since there only needs to be some $\theta\in G$ such that $\theta^\star$ can be stabilized. However, if we compare the dominant term in the upper bound on the sub-optimality gap, we notice that robust control suffers from the conservativeness asymptotically as $\trace(H(\theta^\star)FI(\theta^\star)^{-1})\leq d_\theta\norm{H(\theta^\star)FI(\theta^\star)^{-1}}$ holds. 

