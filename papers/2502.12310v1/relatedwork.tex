\section{Related Work}
\paragraph{Domain Randomization} 
Domain randomization, introduced by \citet{tobin2017dr}, is widely used for \emph{sim-to-real transfer}. By randomizing simulator parameters during training, it aims to produce policies robust to simulator variations, thereby enabling transfer to the real-world. This approach has been applied in areas like autonomous racing \citep{loquercio2019deep}
and robotic control \citep{peng2018drforcontrol, akkaya2019solving}. However, its success depends heavily on selecting an effective sampling strategy \citep{mehta2020active}, which is often challenging. While previous work has explored generalization of domain randomization in discrete Markov Decision Processes \citep{chen2021understanding, zhong2019pacreinforcementlearningrealworld, jiang2018pac}, formalizing generalization for continuous control remains an open problem, which we address in this work.
\vspace{-3pt}
\paragraph{Identification and Control} The linear quadratic regulator problem has become a key benchmark for evaluating reinforcement learning in continuous control \citep{abbasi2011regret, recht2019tour}. The offline setting has been extensively studied: \citet{dean2020sample} analyzed the sample efficiency of robust control, while \citet{mania2019certainty, wagenmaker2021task, lee2023fundamental} showed that certainty equivalence is asymptotically instance-optimal, achieving the best possible sample efficiency with respect to system-theoretic quantities. Extensions to smooth nonlinear systems were made by \citet{wagenmaker2024optimal, lee2024active}. However, certainty equivalence can perform poorly with limited data. Alternative Bayesian approaches \citep{von2022improving, chiuso2023harnessing} can mitigate such limitations. We therefore show that such uncertainty-aware synthesis methods can match the asymptotic efficiency of certainty equivalence while achieving better performance in low-data regimes.
\vspace{-3pt}
\paragraph{Robust Control:} The control community has traditionally addressed policy synthesis with imperfect models using methods like $\calH_\infty$ control, which focuses on worst-case uncertainty \citep{zhou1996robust, bacsar2008h, doyle1982analysis, fan1991robustness}. Randomized approaches to robust control emphasizing high-probability guarantees have also been explored \citep{calafiore2006scenario, stengel1991technical, ray1993monte}. \citet{vidyasagar2001randomized} proposed an average performance metric similar to domain randomization but focused on a fixed distribution rather than one informed by data. Early data-driven synthesis efforts combined classical system identification \citep{ljung1998system} with worst-case robust control \citep{gevers2005identification}, while recent work has developed robust synthesis methods that bypass explicit models \citep{berberich2020robust}. To the best of our knowledge, existing analyses of statistical efficiency in robust control yield suboptimal rates, with excess control cost decreasing at $1/\sqrt{N}$ \citep{dean2020sample}, compared to the faster $1/N$ rate achieved by certainty equivalence. This work refines robust synthesis analysis, demonstrating the $1/N$ rate and a short burn-in period, highlighting its advantages with limited data.