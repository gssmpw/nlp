\section{Introduction_unused}

\sloppy 
Prior work analyzing the sample complexity of learning the linear quadratic regulator has shown that the principle known as certainty equivalence, in which one uses the dataset $\curly{(X_t^n, U_t^n, X_{t+1}^n)}_{t=1, n=1}^{T,N}$ to estimate the dynamics $\hat\theta = \bmat{\hat A & \hat B}$, and then in turn synthesizes a controller as though these parameters were the ground truth as $\hat K = K(\hat \theta)$, 
is efficient \citep{mania2019certainty}.  The notion of efficiency in prior work refers to the fact that the rate of decay suboptimality gap \eqref{eq: suboptimality gap}, asymptotically matches the lower bound, i.e. it decays at the optimal rate the total number of samples $TN$. Follow up analysis by \citet{wagenmaker2021task, lee2024active} has shown the optimal asymptotic dependence on system theoretic constants. 

What prior analysis studying certainty equivalence fails to adequately address is that certainty equivalence may perform very poorly in the low-data regime. In particular, it may be that the certainty equivalent controller does not even stabilize the system when limited data is available. This motivates alternative design methodologies, in which one quantifies the uncertainty in the estimate of $\hat A$ and $\hat B$, and uses this uncertainty quantification to design a robust controller. Common notions of how to do this would be to use robust synthesis, whereby a controller is either synthesized to minimize an objective value in the face of the worst case dynamics realization in a high probability set or minimize the nominal cost while ensuring stability for all systems in a high probability set \citep{gevers2005identification, dean2020sample}. Alternatively, $\calH_\infty$ or mixed $\calH_2/\calH_\infty$ methods can be used to design systems which are robust to feedback uncertainty, as guaranteed by the small gain theorem \citep{zhou1996robust}. 
There are severe limitations to these approaches. 
\begin{enumerate}
    \item It is challenging to derive computationally feasible extensions of either of these approaches to general classes of nonlinear systems. 
    \item The increasingly adopted approaches of performing approximate dynamic programming to perform optimal control via policy approximation (typically with neural networks) are not easily amenable to these conventional approaches for incorporating robustness. 
    \item Robust synthesis can be overly conservative. Indeed, while some existing finite sample bounds exist for robust synthesis \citep{dean2020sample}, the rate of decay is linear the estimation error rather than quadratic. This limitation is not fundamental (as we show in this work.) However, suptoptimal dependence on the system theoretic constants may be fundamental (as we conjecture in this work). 
    \item Analyzing the sample complexity of certainty equivalence with stability constraints is not straightforward in the regime where the constraints are active. 
\end{enumerate}

\section{Excess cost analysis}
Define the \emph{model-task Hessian} of the LQR problem as 
\begin{align*}
    H(\tilde \theta) = \nabla_{\theta}^2 J(K(\theta), \tilde \theta) \vert_{\theta= \tilde \theta}.
\end{align*}
Additionally, let
\begin{align*}
    \Psi(\theta) &= B(\theta)^\top P(\theta) B(\theta) + R \\
    \Sigma_{\tilde K}(\theta) &= \sum_{t=0}^\infty (A(\theta) + B(\theta) \tilde K)^t \Sigma_W\paren{(A(\theta) + B(\theta) \tilde K)^t }^\top
\end{align*}

\begin{theorem}
    \label{thm: CE bound}
    Let $\hat K = \argmin_K C(K \hat \theta)$. Suppose that 
    \[
        \norm{\hat \theta - \theta^\star} \leq \mathsf{poly}(\norm{P(\theta_\star)}^{-1})
    \]
    Then
    \begin{align*}
        C(\hat K, \theta^\star) - C(K^\star, \theta^\star) \leq (\hat\theta - \theta^\star)^\top H(\theta^\star) (\hat \theta - \theta^\star) + L_{LQR} \norm{\hat \theta - \theta^\star}^3, 
    \end{align*}
    where 
    \begin{align*}
        L_{\mathsf{cost}} \leq \mathsf{poly}(\norm{P(\theta_\star)}, \norm{B}).
    \end{align*}
\end{theorem}
\begin{proof}
    {\color{red} Tesshu will fill in}
\end{proof}

\begin{lemma}
    Let $\hat K = \argmin_K \sup_{\theta\in\calB} C(K,  \theta) - C(K(\theta), \theta)$, where $\calB = \curly{\theta: (\theta - \hat\theta)^\top G (\theta - \hat \theta) \leq 1}$.  Suppose that $\theta_\star \in \calB$. Then
    \begin{align*}
        C(\hat K, \theta^\star) - C(K^\star, \theta^\star) \leq \inf_{\tilde \theta \in \calB} \paren{ 2 \norm{D \VEC K(\theta)\vert_{\theta= \theta_1}^\top (\Psi(\theta_1) \otimes \Sigma_{K(\tilde \theta)}(\theta_1)) D \VEC K(\theta)\vert_{\theta= \theta_1} G} + 2 L_{\mathsf{h.o.t.}}(\tilde \theta) \norm{G}^{3/2}}
    \end{align*}
\end{lemma}
\begin{proof}
    \begin{align*}
        C(\hat K, \theta^\star) - C(K^\star, \theta^\star)  &\leq \sup_{\theta: (\theta - \hat \theta)^\top G (\theta - \hat\theta) \leq 1} C(\hat K, \theta) - C(K(\theta), \theta) \\
        & = \inf_{\tilde K} \sup_{\theta: (\theta - \hat \theta)^\top G (\theta - \hat\theta) \leq 1} C(\tilde K, \theta) - C(K(\theta), \theta) \\
        &= \inf_{\tilde K} \sup_{\theta: (\theta - \hat \theta)^\top G (\theta - \hat\theta) \leq 1} \trace\paren{(\tilde K - K(\theta))^\top \Psi(\theta) \paren{\tilde K - K(\theta)} \Sigma_{\tilde K}(\theta)} \\
        &\leq \inf_{\tilde \theta \in \calB} \sup_{\theta_1, \theta_2\in\calB} \trace\paren{(K(\theta_2) - K(\theta_1))^\top \Psi(\theta_1) \paren{K(\theta_2) - K(\theta_1)} \Sigma_{K(\tilde \theta)}(\theta_1)},
    \end{align*}
    where the inequality follows from the fact that for $S_1 \subseteq S_2$, $\inf_{x \in S_2} f(x,x) \leq \inf_{x \in S_1} f(x,x) \leq \inf_{x \in S_1} \sup_{y\in S_1} f(x,y)$. Taylor expanding $K$ with respect to $\theta$ results in the upper bound of 
    \begin{align*}
        \inf_{\tilde \theta \in \calB} \paren{\sup_{\theta_1, \theta_2\in\calB} (\theta_2 - \theta_1) D \VEC K(\theta)\vert_{\theta= \theta_1}^\top (\Psi(\theta_1) \otimes \Sigma_{K(\tilde \theta)}(\theta_1)) D \VEC K(\theta)\vert_{\theta= \theta_1} (\theta_2 - \theta_1) + \sup_{\theta_1, \theta_2\in\calB}  L_{\mathsf{h.o.t.}} (\tilde \theta) \norm{\theta_2 - \theta_1}^3},
    \end{align*}
    where $L_{\mathsf{h.o.t.}} = ?$ \textcolor{red}{Work out the higher order terms from the derivative}. Taking the supremum over $\theta_1$ and $\theta_2$ thus leads to the upper bound
    \begin{align*}
         \inf_{\tilde \theta \in \calB} \paren{ 2 \norm{D \VEC K(\theta)\vert_{\theta= \theta_1}^\top (\Psi(\theta_1) \otimes \Sigma_{K(\tilde \theta)}(\theta_1)) D \VEC K(\theta)\vert_{\theta= \theta_1} G} + 2 L_{\mathsf{h.o.t.}}(\tilde \theta) \norm{G}^{3/2}}
    \end{align*}
    
    % {\color{red} Use the fact that both $\tilde K$ and $K$ stabilize the system to bound
    % \begin{align*}
    %     \norm{\Sigma_{\tilde K}(\theta)- \Sigma_{K(\theta)}(\theta)} \leq  \norm{\dlyap(A+BK(\theta))} \\ \paren{2 \norm{A+B K(\theta)} \norm{\Sigma_{\tilde K}} \norm{B} \norm{\tilde K - K(\theta)} + \norm{\Sigma_{\tilde K}} \norm{B}^2 \norm{\tilde K - K(\theta)}^2}
    % \end{align*} 
    % $\norm{\Sigma_{\tilde K}}$ can then be bounded by $\norm{\Sigma_{K(\theta)}} + \norm{\Sigma_{\tilde K} - \Sigma_{K(\theta)}}$. Under a closeness condition on $\tilde K$, this in turn can imply a bound on $\norm{\Sigma_{\tilde K} - \Sigma_{K(\theta)}}$ in terms of $\tilde K - K(\theta)$.
    % }
\end{proof}

If $\hat \theta$ is identified from data via least squares, then for any $\delta$, we can construct a matrix $G$ such that $\theta_\star \in \calB$ with probability at least $1-\delta$ as $G = $ empirical covariance divided by confidence scaling. This leads to the following result:
\begin{theorem}
Suppose data is collected ... Then .
\end{theorem}
Notably, the above upper bound may be finite even in situations where the certainty equivalent controller is not stabilizing. In particular, consider the system $A = 0.99$, $B = 1$ with $Q= 1e-3$ and $R=1$ - {\color{red} work out an amount of data where CE is not stabilizing with high probability, whereas DR is.} Nonetheless, a rate of decay of $\frac{1}{N}$ is achieved asymptotically, matching the analysis of \citet{mania2019certainty} for certainty equivalence, and improving upon the $1/\sqrt{N}$ rate of \citet{dean2020sample} for robust synthesis. However, the bound does not achieve the optimal asymptotic dependence on system theoretic parameters. In particular, \Cref{thm: CE bound} shows that certainty equivalence achieves the bound $\trace\paren{H(\theta^\star) \mathsf{FI}(\theta^\star)^{-1}}$.

Motivated by the above limitations, we study an approach to controller synthesis rooted in domain randomization. In particular, using the dataset $\curly{(X_t^n, U_t^n, X_{t+1}^n)}_{t=1, n=1}^{T,N}$, we construct a parameter distribution $\calD$, and select the controller as
\begin{align}
    \label{eq: domain randomization}
    \hat K = \argmin_{K} \E_{\boldsymbol \theta \sim \calD} \brac{C(K, \boldsymbol \theta)}. 
\end{align}

Our main result is a bound on the suboptimality gap incurred by rolling out a controller synthesized with domain randomization. This result is stated informally below.

\begin{theorem}[(Main Result)]
    \label{thm: informal main result}
    Let $\hat K$ be generated according to \eqref{eq: domain randomization}. Then the suboptimality gap satisfies
    \begin{align*}
        &C(\hat K, \theta^\star) - C(K(\theta^\star), \theta^\star) \leq  \trace(\var(\theta) \cdot H(\theta^\star)) + \left(\E[\theta] - \theta^\star\right)^\top H(\theta^\star) \left(\E[\theta] - \theta^\star\right) + \text{h.o.t.},
    \end{align*}
    where $H(\theta^\star)$ is the \textit{model-task Hessian}. The above bound holds whenever $\hat K$ robustly stabilizes the true system parameters $\theta^\star = \bmat{A^\star & B^\star}$.
\end{theorem}

\begin{proof}
    Our result proceeds by the observations that 

\end{proof}

We contrast this result with the analogous bound for certainty equivalence: as long as $K(\hat \theta)$ robustly stabilizes $\theta^\star$,
\begin{equation}
\label{eq: certainty equivalence suboptimality gap}
\begin{aligned}
    &C(K(\hat \theta), \theta^\star) - C(K(\theta^\star), \theta^\star) \leq \trace\left((\hat \theta - \theta^\star)^\top H (\hat \theta - \theta^\star)\right) + \text{h.o.t.}.
\end{aligned}
\end{equation}

At first glance, the upper bound for domain randomization (\Cref{thm: informal main result}) appears to be worse than the one for certainty equivalence. The key reason this is not the case lies in the stability assumptions. Domain randomization ensures that $\hat K$ robustly stabilizes all parameters $\theta = \bmat{A & B}$ with non-zero support in the distribution $\calD$, whereas certainty equivalence requires the parameters $\hat A$ and $\hat B$ to be very close to the true values $A^\star$ and $B^\star$. This discrepancy shows up in the required data collection to achieve the respective performance bounds.

We now briefly return to the robust synthesis problem. 

\begin{theorem}
    Suppose that $\hat K$ is generated by
    \begin{align*}
        \hat K = \argmin_K \sup_{\theta \in \calB} C(K, \theta).
    \end{align*}
    Then the suboptimality gap is bounded by
    \begin{align*}
        &C(\hat K, \theta^\star) - C(K(\theta^\star), \theta^\star) \\
        &\leq \sup_{\theta \in \calB} \VEC(\theta - \theta^\star)^\top H \VEC(\theta - \theta^\star) + \text{h.o.t.}.
    \end{align*}
\end{theorem}

Crucially, even if we shrink the diameter of the uncertainty set $\calB$ based on parameter estimation uncertainty, the suboptimality gap for robust synthesis includes a term scaling with $\norm{H \mathsf{FI}^{-1}}$, whereas domain randomization and certainty equivalence instead involve a term scaling as $\trace(H \mathsf{FI}^{-1})$.

\begin{figure}
    \centering
    \includegraphics[width=1.0\linewidth]{figures/Excess_cost.png}
    \caption{Excess cost comparison between Certainty Equivalence (CE) and Domain Randomization (DR).}
    \label{fig:excess cost}
\end{figure}


% Our main result is a bound on the suboptimality gap incurred by rolling out a controller synthesized with domain randomization. This result is stated informally below. 
% \begin{theorem}[(informal, main result)]
%     \label{thm: informal main result}
%     Let $\hat K$ be generated according to \eqref{eq: domain randomization}. Then the subpotimality gap satisifes
%     \begin{align*}
%         &C(\hat K, \bmat{A_\star & B_\star}) - C(K(\bmat{A_\star & B_\star}), \bmat{A_\star & B_\star})  \\
%         &\leq  \trace(\var(\bmat{\bfA & \bfB})\cdot H^\star) + \left(\mathbf{E}\bmat{\bfA & \bfB} - \bmat{A_\star & B_\star}\right)^T H^\star \left(\mathbf{E}\bmat{\bfA & \bfB} - \bmat{A_\star & B_\star}\right) + h.o.t
%     \end{align*}
%     where $H^\star$ is the \textit{model-task hessian}. The above bound holds whenever $\hat K$ robustly stabilizes $\bmat{A_\star & B_\star}$. 
% \end{theorem}

% We contrast this result with the analog for certainty equivalence: As long as $K(\bmat{\hat A & \hat B})$ robustly stabilizes $\bmat{A_\star & B_\star}$,
% \begin{equation}
% \label{eq: certainty equivalence subtoptimality gap}
% \begin{aligned}
%     &C(K(\bmat{\hat A & \hat B}), \bmat{A_\star & B_\star}) - C(K(\bmat{A_\star & B_\star}), \bmat{A_\star & B_\star}) \\
%     &\leq \trace(\paren{\bmat{\hat A & \hat B} - \bmat{A_\star & B_\star}} H \paren{\bmat{\hat A & \hat B} - \bmat{A_\star & B_\star}}) + h.o.t.
% \end{aligned}
% \end{equation}

% It appears that the upper bound for domain randomization (\Cref{thm: informal main result}) is strictly worse than the one for certainty equivalence. The key to why this is not so is in the stability assumptions. Domain randomization effortlessly ensures that $\hat K$ is stabilizing all parameters $\bmat{A & B}$ with nonzero support in the probability distribution $\calD$, whereas certainty equivalence needs the parameters $\hat A$ and $\hat B$ very close to ground truth. This discrepancy shows up in the burn-in times (amount of sampled data required to achieve the above bounds). 

% It is worth returning briefly to the problem of robust synthesis. 
% \begin{theorem}
%     Suppose that $\hat K$ is given by
%     \begin{align*}
%         \argmin_K \sup_{\bmat{A & B} \in \calB} C(K, \bmat{A & B}).
%     \end{align*}
%     Then the suboptimality gap is bounded by
%     \begin{align*}
%         &C(\hat K, \bmat{A_\star & B_\star}) - C(K(\bmat{A_\star & B_\star}), \bmat{A_\star & B_\star}) \\ 
%         &\leq \sup_{\bmat{A & B} \in \calB} \VEC \bmat{A - A_\star & B - B_\star}^\top H \VEC \bmat{A - A_\star & B - B_\star} + h.o.t.
%     \end{align*}
% \end{theorem}
% Critically, even if we shrink the diameter of the ball $\calB$ in the above robust synthesis according to the uncertainty in the parameter estimates, the suboptimality gap above picks up a quantity scaling as $\norm{H \mathsf{FI}^{-1}}$, whereas domain randomization and certianty equivalence instead pick up a term scaling like $\trace\paren{H \mathsf{FI}^{-1}}$. 

% \begin{figure}
%     \centering
%     \includegraphics[width=1.0\linewidth]{figures/Excess_cost.png}
%     \caption{Excess Cost between CE vs. DR}
%     \label{fig:excess cost}
% \end{figure}

\Bruce{TODO 
- Add preliminary plot for proof of concept experiments
- verify proof sketch of the main result
}