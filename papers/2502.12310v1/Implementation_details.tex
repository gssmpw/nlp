\section{Implementation Details}
\label{s: implementation details}
\subsection{Linear System}
We explain the details about the linear system experiments in \Cref{s: numerical}. The goal is to compare the three controller synthesis methods considered in this work (\Cref{s: methods}) to study show how the suboptimality gap of the LQR cost changes. 
All the code is implemented in JAX \citep{jax2018github}. 
First we identify the least square estimate $\hat\theta$ by solving \eqref{eq: least squares} given collected data by running a variable number of experiments with $U_t\sim\mathcal{N}(0, I)$ and $W_t\sim\mathcal{N}(0, I)$, and followed by the controller design. 
\begin{itemize}
\item 
For the certainty equivalence controller synthesis, we simply synthesize a controller by solving the \textit{Algebraic Ricatti Equation}. 
\item 
For the domain randomization controller synthesis, we implement \Cref{alg: dr lqr} via stochastic gradient descent. 
We choose $\mathcal{D}$ as a uniform distribution over the confidence ellipsoid $G$. We set $M = 10000$ and $\eta=0.0005$ in \Cref{alg: dr lqr}. We use the closed-form expression of the policy gradient as described in Lemma $1$ of \cite{fazel2018global} to implement gradient descent. 
\item 
For the robust controller synthesis, we adopt the scenario-approach \citep{calafiore2006scenario}, where we sample 30 points from the ellipsoid $G$ \eqref{eq: confidence ellipsoid}, by formulating as the semidefinite programming problem with linear matrix inequalities \citep{caverly2019lmi} and solve the convex optimization problem using CVXPY \citep{diamond2016cvxpy} using the SCS solver \citep{ocpb:16}. 
\end{itemize}

Since these randomization procedures result in high variance, we perform $500$ trials and report the median and quartiles over those trials in \Cref{fig:result dr lqr}. 

\subsection{Pendulum}
The pendulum is goverend by the following dynamics
\begin{align*}
    X_{t+1} = f(X_t, U_t+W_t; \theta^\star),
\end{align*}
where the state space $X_t\in\R^2$ consists of angle $\psi_t$(rad) and angular velocity $\dot\psi_t$(rad/s), and the action $U_t\in\R$ is the actuation torque $\tau_t$(N m) applied directly to the free end of the pendulum, which is corrupted by i.i.d Gaussian noise $W_t \sim \mathcal{N}(0, 1)$. The unknown parameter $\theta\in\R^3$ accounts for the mass $m$ and the length $l$ of the pole, and the gravitiy $g$, which take values $1.0$, $1.0$, and $9.81$, respectively.  

As in the linear experiments, first we identify the estimate $\hat\theta$ by solving the following least squares problem:
\begin{align*}
    \hat\theta \triangleq \argmin_\theta \sum_{n=1}^N\sum_{t=1}^T\norm{X_{t+1}^n - f(X_t, U_t; \theta)}^2.
\end{align*}
The data consists of varying numbers of length $10$ trajectories collected from the pendulum starting from the downward position ($\theta = \pi, \dot \theta =0$) with $U_t\sim\mathcal{N}(0, 1)$ and $W_t\sim\mathcal{N}(0, 1)$ 
This estimation procedure is followed by the sampling-based Model Predictive Controller synthesis based on the cross-entropy method \citep{botev2013cross} with the different design methods.
\begin{itemize}
    \item For the certainty equivalence control, actions are selected to  minimize the cost of the rollout in the receding horizon which is simulated with $\hat\theta$ as if it were the ground truth.
    \item For the domain randomization control, we first design a sampling distribution $\calD$ as a uniform distribution over a sphere centered at the estimate $\hat \theta$, with radius given by a hyperparameter $2.0$ divided by the number of trajectories used to identify $\theta$. We then sample $K=15$ instances $\theta_1, \dots, \theta_{K} \in\mathcal{D}$. The controller then plans sequences of actions which minimize the average cost of all the rollouts simulated with $\theta_1, \dots, \theta_{K}$. 
\end{itemize}
We set the stage cost $C(X_t, U_t)$ as
\begin{align*}
    C(X_t, U_t) = \left\{\begin{array}{ll}
        \psi_t^2 + 0.1\dot\psi_t^2 + 2.0\tau_t^2 & -\pi/4 \leq \psi \leq \pi/4 \\
        50.0 & \text{otherwise}
    \end{array}\right.
\end{align*}
This cost design promotes the controller to keep the pendulum upright using the minimal control effort. CE with an inaccurate parameter estimate might underestimate control effort required to avoid letting the pendulum fall.
On the other hand, DR plans such that it keeps the pendulum upright for all sampled systems $\theta_1, \dots, \theta_K$, therefore is able to keep upright position even when the estimates are poor.

For other hyperparameters and detailed implementation, refer to the code \footnote{Codes can be found at \url{https://github.com/Tesshuuuu/domain-randomization-l4dc2025}}.

