\section{Related Literature}

Using Figure~\ref{fig:caraml} as a map, we will provide an overview of the AI literature in relation to climate awareness and resource awareness. 

% \subsection{AI and Awareness Axes}

\subsection{State-Of-The-Art (SOTA) AI} 

The advancements in DL methods in the last few years that have ushered in a new class of generative AI that are particularly resource intensive. Text to image models based on diffusion models have shown mind-boggling potential in generating images based on text prompts~\citep{ho2020denoising,rombach2022high}. The strides made with the class of large language models (LLMs) has revolutionized multiple domains beyond natural language processing with popular applications such as ChatGPT built on GPT-3/GPT-4~\citep{brown2020language,openai2023gpt4} and open-source alternatives built on models such as LLaMA~\citep{touvron2023llama}. Other recent classes of models that fall under the umbrella term of foundational models are also extremely powerful in modelling complex, and diverse, data distributions with versatile capabilities. For instance, the segment anything model has proven to be quite powerful in solving segmentation problems across image types~\citep{kirillov2023segment,ma2023segment}.

While the astonishing capabilities of these SOTA models are one common aspect between them, the other commonality is their extreme reliance on large-scale resources~\cite{sevilla2022compute}. All the aforementioned classes of models require massive amounts of data to train extremely large models (with several billion parameters) for several hundred GPU days. All these resources amount to an increase in their underlying energy consumption and carbon emissions~\citep{luccioni2023counting}. Further, questions on how to address the ethical usage of these models, and measures to mitigate bias are still being explored~\citep{bender2021dangers,ricci2022addressing}. These features are captured in Figure~\ref{fig:caraml} in the bottom-left quadrant wherein the SOTA AI methods are shown to have low climate and resource awareness.


\subsection{Green AI}
% \todo[inline]{Pinar: I have not covered EdgeAI/tinyML here. If you can add a paragraph here, that will be useful.}

The life-cycle of a typical deep learning model consists of several stages: dataset curation, model selection, model training, model development, and model deployment.

Each of these steps can be resource intensive due to the storage, compute, and energy consumption requirements.
Recent works demonstrate the benefit of data, work, and hardware resource sharing when reducing the CPU needs of data loading and preprocessing steps of model training~\citep{xuDeepLearningDataloader2022, audibert2023tf, mohan2021analyzing, robroek2024tensorsocket} and the GPU needs of actual training computations~\citep{10.1145/3642970.3655830, robroek2023analysis, orion, hfta}.
Reducing the reliance of model deployment
%, which is only one of the steps, 
on large-scale resources is also an active area of investigation within the domains of resource-efficient ML~\citep{sze2017efficient}.
Some works in this domain target using existing hardware resources more effectively in data centers~\citep{10.5555/3692070.3693972, orca}, thereby reducing the need for more, 
or building hardware specifically tailored for deep learning
~\citep{DBLP:conf/isca/JouppiK0MNNPSST23}.
Others investigate model deployment on resource-constrained platforms~\citep{ReachingEdgeEdge, 10.1145/3643832.3661856},
enabling TinyML~\citep{dutta2021tinyml} or EdgeML/EdgeAI~\citep{10.1145/3450268.3453520}.
For such cases, the model deployment and inference is performed closer to the data sources (satellites, under-water monitoring, phones, etc.), i.e., at the edge, rather than in the cloud.
This brings several benefits thanks to the reduced data movement: lower dependency on a powerful network connection and cloud hardware, higher privacy and security, and faster and more energy-efficient end-to-end inference. 
Other classes of methods comprising quantization~\citep{dettmers20218}, model compression~\citep{cheng2018model}, efficient model selection~\citep{bakhtiarifard2022energy}, tensor decomposition~\citep{memmel2024position}, knowledge distillation~\citep{sanh2019distilbert}, dataset condensation~\citep{cui2022dc} or a combination of these steps are being studied to address the question of improving resource efficiency in other steps in the DL life-cycle~\citep{greenAI,bartoldson2023compute}. There are no existing theoretical paradigms that can holistically improve the resource efficiency of the entire DL pipeline.

On the other hand, it has been shown in multiple recent works that the techniques that improve the resource efficiency of AI methods can hamper the social sustainability of AI methods by making them more biased or reducing their fairness~\citep{hooker2020characterising,stoychev2022effect,ramesh2023comparative}.
Furthermore, deploying billions of resource-constrained devices for utilizing TinyML/EdgeAI creates both a resource availability challenge and increases the end-to-end environmental footprint of these methods~\citep{istinysustainable}.
Finally, specialized hardware for ML tends to be at the hands of a few big companies rather than a wider variety of institutions. 
As a result we position the class of Green AI methods in the lower right quadrant in Figure~\ref{fig:caraml} with high climate awareness but low resource awareness.

\subsection{Inclusive AI} 

The nebulousness of social sustainability results in a broad and multi-faceted understanding of the social sustainability of AI. In this work, we narrow down to the factors that will positively improve the equitable use of AI. Topics related to the ethical use of AI models~\citep{jobin2019global}, ensuring user privacy~\citep{abadi2016deep}, fairness~\citep{ricci2022addressing}, and bias mitigation strategies~\citep{bender2021dangers} are considered to be under the purview of the social sustainability of AI.

Measuring and optimizing for factors that affect the equitable use of AI methods such as privacy, fairness and bias is not straightforward. Consider fairness, for instance, which is difficult to optimize for when performing standard deep learning~\citep{corbett2018measure}. Existing approaches enforce additional optimization criteria which could be at odds with the task-specific performance measures~\citep{li2023accurate}. Furthermore, the computational overhead due to these can reduce the environmental sustainability of AI methods. This is most clearly captured with differentially private deep learning which is notorious for the additional computational overheads~\citep{bu2023differentially}. Given these factors, we place the Equitable AI in the upper-left quadrant in Figure~\ref{fig:caraml} indicating the trade-off between resource awareness and climate awareness.

Given these, we want Sustainable AI to be in the upper-right quadrant of Figure~\ref{fig:caraml} which has high climate and resource awareness.

% Scare resource allocation requires randomness~\cite{jainposition}

% Open foundation models~\cite{kapoor2024position}

% \subsection{Climate Change Adaptation and Mitigation with AI}
% AI for climate change mitigation~\cite{kaack2022aligning}

% Technological fix cannot fix climate.\cite{klein2014changes}
