
\section{Introduction}

The capabilities of artificial intelligence (AI) methods are demonstrably diverse and multi-faceted with the potential to help us as a global society to reach many of the Sustainable Development Goals (SDGs)~\citep{vinuesa2020role}. Availability of large-scale datasets and computational resources has been essential in the recent accelerated development of deep learning (DL) that is driving most of the AI methods~\citep{lecun2015deep,schmidhuber2015deep}.

\begin{figure}[t]
    \centering
    \includegraphics[width=0.9\linewidth]{img/countries_green500.png}
    \caption{Compute capacity in different countries based on the Top500 listing of supercomputers using data from November, 2024~\cite{top5002024compute}. Vast regions in the world, primarily in LMICs have almost no large-scale compute capacity which have grown to become necessary for developing latest AI research.}
    \label{fig:top500}
\end{figure}
\begin{figure}[t]%{r}{0.8\textwidth}
% %\vspace{-0.8cm}
    \centering
    \hspace{-1ex}\includegraphics[width=0.6\textwidth]{img/research-trends.pdf}
    \vspace{-0.55cm}
    \caption{(left) Proportion of authors based on the geographic location of their affiliations. The plot shows this based on publications at two ML conferences (ICML and NeurIPS) in 2017 and 2022. The countries are classified based on their income groups as defined by World Bank. We notice that HICs dominate these conferences compared to LMICs. Details on the data preparation is provided in~\autoref{app:data}.}
    \label{fig:publications}.
    % \vspace{-.5cm}
\end{figure}

The computational resources required to develop AI methods have doubled every 3.4 months for some salient DL methods~\citep{amodei2019,sevilla2022compute}. This trend has maintained for over a decade starting around 2012. This startling trend of doubling the compute resources required to develop AI models every few months has disparate effects on \emph{holistically} sustainable AI. \\
{\bf Environmental sustainability of AI}: The growing computational demand has led to a proportional increase in the energy consumption of AI. As energy production is still one of the largest green house gas (GHG) emitters in the world~\citep{bruckner2014energy,sevilla2022compute}, the resulting carbon footprint of AI has been of increasing concern~\citep{strubell2019energy,anthony2020carbontracker,selvan2022carbon}. Furthermore, the specialized hardware required to develop AI models such as graphics processing units (GPUs), the e-waste generated due to these electronics~\cite{wang2024waste}, building infrastructure that houses these data-centers, and the water required to cool the data-centers~\cite{li2023making} are adversely impacting the {\em environmental sustainability} of AI methods~\citep{li2023making,wright2023efficiency,ssdcarbon}.
\\
{\bf Social sustainability of AI}: The large-scale resource requirements in terms of compute, energy, and other raw materials, have given rise to a new access barrier to AI methods risking the de-democratization of AI~\citep{ahmed2020democratization}. The resource barrier is reducing the participation of stakeholders from several regions of the world, primarily from low- and middle- income countries (LMICs) compared to high-income countries (HICs). The availability of large-scale compute capacity in different countries is shown in Figure~\ref{fig:top500}, and the distribution of AI research publications in 2022 country-wise is visualized in Figure~\ref{fig:publications} which captures a clear under-representation of LMICs in several regions. Disenfranchisement of communities due to the steep resource costs is also aggravating the already existing biases in AI methods~\citep{ricci2022addressing,farnadiposition}.


Improving the environmental sustainability of AI primarily focuses on {\em climate awareness} as the guiding principle~\cite{bartoldson2023compute,greenAI}, whereas {\em resource awareness} is used to grapple with improving the social sustainability of AI~\cite{ahmed2020democratization}. In this position paper, we argue that the joint consideration of {\bf climate and resource awareness is a prerequisite to achieve sustainable AI}. We present the standpoint that the sole focus on climate awareness or on resource awareness leads to a tension that can negatively affect the ambitions of achieving sustainable AI.


AI methods have demonstrated significant potential in advancing the SDGs, for example, in climate change adaptation and improving healthcare access. However, the accelerated expansion of AI infrastructure (fx: data-centers) by big corporations and HICs, often without serious sustainability considerations, presents a critical challenge. An unregulated {\em global AI arms race} that disregards sustainability is not a strategic or responsible trajectory for the future of AI and the world.

To address these contradictions when pursuing sustainable AI, we present a paradigm of climate and resource aware ML (CARAML). Just as AI models grow in complexity, so too must the actions we need to take. In line with this view, the CARAML framework presents recommendations and actions that evolve across individual, community, industry, government, and global levels.

\subsection{Preliminaries and Definitions}

Before proceeding further, we define the key terms with their intended use in this work.

{\bf Sustainable AI:} The definition of Sustainable AI that we adhere to considers all the three facets of sustainability, i.e., economic, environmental, and social. This definition is from~\citet{van2021sustainable}, where the author explains that Sustainable AI is about {\em ``how to develop AI that is compatible with sustaining environmental resources for current and future generations; economic models for societies; and societal values that are fundamental to a given society."} 

This is to contrast with the looser use of the term Sustainable AI in the literature, which can conflate energy efficiency with carbon efficiency, carbon efficiency with environmental sustainability, and environmentally sustainable AI to Sustainable AI as pointed out by~\citet{wright2023efficiency}.

{\bf Climate awareness:} By this, we will mean the recognition, understanding, and integration of climate impact considerations of AI development and deployment. This awareness enables practitioners to optimize the energy efficiency, carbon footprint, and other broader environmental impacts of AI. The class of methods which result from this can be grouped into the {\em Green AI} quadrant in \autoref{fig:caraml}.

{\bf Resource awareness:} By this, we focus on the effort to bridge the AI divide by making it more accessible~\cite{un2024aidivide}. The recognition here is not only of the resource consumption of AI models, but also of the resource availability of the people who develop and use AI solutions. The class of methods that promote {\em Inclusive AI} either by arguing for more accessibility and democratization in the top-left quadrant in \autoref{fig:caraml} are examples of resource awareness.

An overview of current developments within AI research are mapped using the axes of climate awareness and resource awareness in Figure~\ref{fig:caraml}.



\begin{figure}[t]%{r}{0.8\textwidth}
% %\vspace{-0.8cm}
    \centering
    \includegraphics[width=0.7\textwidth]{img/CARAML.pdf}
    \vspace{-0.35cm}
    \caption{Contextualizing Sustainable AI using the two axes of climate awareness and resource awareness. The position of this paper is that Sustainable AI should be in the top right quadrant where both climate and resource awareness are high. In case of Edge AI, there is some ambiguity in if it actually is climate aware; so we have marked it with a question mark.}
    \label{fig:caraml}.
    \vspace{-0.35cm}
\end{figure}
\subsection{Tension between Climate awareness and Resource Awareness}

Achieving Sustainable AI necessitates a balanced approach that includes both climate awareness and resource awareness. The two are complementary but can sometimes be at odds with each other. We present two concrete examples to highlight this contradiction. 

\subsubsection{Social sustainability of low-carbon data centers}

The push towards powering data-centers with renewable energy, or generally known as green computing~\cite{yang2022}, is a valid approach to reduce {\em some} of the climate impact of developing large AI models by reducing operational carbon emissions.\footnote{Carbon emissions due to the energy consumption of data centers is just one factor of the climate impact of AI. Embodied emissions, water usage for cooling, mining of rare-earth minerals, e-waste disposal, and other broader environmental impact are not accounted for when only talking about green energy~\cite{wright2023efficiency}.} 

However, these green computing solutions, such as low-carbon data centers, rely heavily on renewable energy like solar, wind, or hydroelectric power to operate. Many countries still face significant challenges in energy access, with large portions of the population lacking reliable electricity, or relying on cheaper carbon-intensive sources such as fossil fuels. According to the International Renewable Energy Agency (IRENA), renewable energy capacity in many developing countries is still insufficient to meet growing demand~\cite{irena2024}, as shown in Fig.~\ref{fig:irena}. 


As a result, the demand for clean energy to support greener data-centers for AI not only strains already limited resources~\cite{10.1145/3627703.3650079} but also creates a paradox for LMICs. These countries are being asked to adopt greener technologies while lacking the clean energy infrastructure necessary to power them. This deepens the technological divide and locks out LMICs from participating in the climate aware development of AI. This we argue results in double penalty -- once for not having access to the resources, and again for not having access to cleaner resources.

\subsubsection{Environmental sustainability of Efficient AI Models}

The ML community has acknowledged the growing resource costs of developing recent AI models and has primarily turned towards making them more efficient~\cite{bartoldson2023compute}. While this in itself is a meaningful endeavor, as it improves access to a broader community, the larger implications of this resource awareness on the environment are not immediately apparent.

From a climate awareness standpoint, efficiency in computational resource use, though seemingly beneficial in terms of reducing direct energy consumption, could paradoxically be at odds with long-term environmental sustainability when considering the rebound effect~\cite{alcott2005jevons}. This effect, rooted in economic and ecological theory, suggests that any technological advancement that improves efficiency often leads to an increase in overall demand for the very resource it was designed to conserve~\cite{wright2023efficiency}.

This paradox has come to the foray with the recent success of DeepSeek models~\cite{deepseekai2024deepseekv3technicalreport,deepseekai2025deepseekr1incentivizingreasoningcapability}, where they report using a fraction of resources compared to other existing models in the same class.\footnote{We note that even this ``smaller" resource cost is exorbitant. DeepSeek-V3 used about 2.8M GPU hours on Nvidia-H800s, compared to say 30.8M GPU hours on Nvidia-H100s for a comparable model Llama-3-405B.} This claim of efficiency has drawn many more people to use and build with these models i.e, it has improved access which is a key factor in improving social sustainability. 
For some companies and countries, DeepSeek may be a sign that 
``AI-sovereignty'' (see \autoref{sec:demo}) also in reach for them, which may lead to more investments in data centers and model creation.

So, how do we resolve these contradictions between climate awareness and resource awareness? 

The short answer we adhere to in this position is that this contradiction can be resolved only by integrating both climate and resource awareness. Only then can we create a Sustainable AI ecosystem that is not only efficient and climate-friendly but also just and equitable.

\begin{figure}[t]
    \centering
    \includegraphics[width=0.7\textwidth]{img/renewables.pdf}
    \caption{Proportion of non-renewable and renewable energy sources in different regions of the world. Source:\cite{irena2024}}
    \label{fig:irena}
    \vspace{-0.75cm}
\end{figure}

\input{related}

\section{Democratization of AI}\label{sec:demo}

Democratizing AI -- ensuring widespread access and participation in its development and use -- is a necessary step towards equitable technological advancement. This can improve the social sustainability of AI, as it can improve participation in the development of AI~\cite{berditchevskaia2021participatory} to match the local needs instead of {\em trickle-down AI} solutions.

Jensen Huang, CEO of NVIDIA, captures the essence of {\em AI sovereignty} by emphasizing that AI codifies a society’s culture, intelligence, and history, asserting that nations should ``own their own data."~\cite{nvidia2024sovereign}. We agree with this aspiration, however, are wary of the monopoly held by NVIDIA over global AI infrastructure~\cite{cusumanonvidia}, and would push for AI sovereignty that also includes the hardware capabilities. 

The pursuit of AI sovereignty, wherein nations develop and control their AI capabilities, stands in contrast to what could be termed {\em Factional AI} -- a scenario where AI development is concentrated among a few powerful entities with disproportionate influence~\cite{ahmed2023growing}. While AI sovereignty promises a more democratized and inclusive technological future, it is also a driver of the global competition for computational resources, exacerbating existing inequalities.

This divide between the {\em GPU-rich} and {\em GPU-poor} clearly reflects the contrasting abundance and scarcity mindsets shaping AI development. Countries and corporations with vast computational resources can push the frontiers of AI, while others struggle with limited access to hardware, data, and expertise. Unequal access to AI skews its development, reinforcing biases that cater to specific groups while neglecting or misinterpreting others. As AI research becomes increasingly dominated by industry interests~\cite{ahmed2023growing}, the risks of a widening technological divide grow more pronounced, leading to cascading disparities that further marginalize underrepresented communities~\cite{farnadiposition}.

Despite these concerns, calls for AI democratization remain strong. Joe Biden, in his farewell address as the 46th President of the United States, declared AI to be ``the most consequential technology of our time, perhaps of all time,`` while cautioning against ``the potential rise of a tech-industrial complex that could pose real dangers."~\cite{nyt2025biben}. His assertion that ``in the age of AI, it’s more important than ever that the people must govern`` underscores the necessity of a grassroots approach to AI governance and development, ensuring that AI remains a tool for collective progress rather than corporate or geopolitical dominance.

However, as we have discussed earlier in this position, democratization by emphasizing resource awareness alone is insufficient. The expansion of AI infrastructure -- large-scale data centers, energy-intensive training processes, and resource-intensive hardware manufacturing -- places enormous pressure on the environment. The pursuit of AI sovereignty and universal AI access risks accelerating ecological degradation unless sustainability considerations are embedded within AI policies and practices. Without careful intervention, AI development risks deepening its alienation from nature, individuals, and broader societal well-being~\cite{marx1844philosophic}.

\section{The Material Basis for AI}


Training one of the Llama-3 models with 405B parameters on a dataset consisting $>$15 trillion tokens required 30.84M GPU hours~\cite{llama3modelcard}. The corresponding energy consumption only based on the GPU usage can be estimated to be 21.5 GWh, with a total of 8,930 tons CO2e in emissions. This is the cost for one {\em open-source} model, but exorbitant resources at this or higher scales are being used to develop wide array of recent AI models. While one can argue that open-source models can be used by a broader community\footnote{Meta {reported} that the Llama models have been downloaded more than 350M times between Feb. 2023-Jul. 2024.}, majority of the resources being spent are for proprietary models. This is because the material infrastructure required to develop models at this scale is currently available only with a handful of private actors operating in HICs.

Kate Crawford characterizes AI not as an algorithmic advancement but an embodied infrastructure. Crawford writes, {\em "artificial intelligence is both embodied and material, made from natural resources, fuel, human labor, infrastructures, logistics, histories, and classifications"}~\cite{crawford2021atlas}. The unequal access to this embodied infrastructure shapes not only the types of AI models that are created but also how these models are used. 

The material basis for AI's development forming the embodied infrastructure -- knowledge, labour, investments, and raw materials -- do not merely exist in isolation; they also shape the ethics, policy, cultural narratives, and educational frameworks that govern AI and beyond. The {\em dominant} ethical frameworks, policy decisions, cultural narratives, and educational systems are all shaped to maintain the concentration of control over the material base. This interplay ensures that AI is deployed in ways that maintains existing power imbalances, rather than challenging them~\cite{pasquinelli2023eye}. This framework of viewing a material base that is interacting with a superstructure stems from historical materialism, pioneered by~\citet{marx1844philosophic}, illustrated in Figure~\ref{fig:base}, and is particularly relevant in this era of large-scale AI development and the risks posed by climate change.

\subsubsection*{Illustration of the Base-Superstructure Interplay in AI}

Consider a {\em hypothetical} scenario where an advanced AI hardware producer faces export restrictions due to political and economic tensions. These restrictions, justified under national security and technological leadership narratives, exemplify how the superstructure -- through policy, regulation, and strategic discourse -- can exert control over the material base, shaping the trajectory of AI development. 

In response, the restricted entity must rapidly reconfigure its supply chains, invest in alternative semiconductor manufacturing, and develop domestic expertise to regain technological independence. However, this forced adaptation is constrained by existing dependencies controlled by the dominant actors forming the superstructure. The initial effect is technological deceleration, increased production costs, and fragmentation of global AI development efforts, reinforcing existing asymmetries rather than dismantling them.

Meanwhile, the controlling superstructure uses these constraints to strengthen its own material dominance. By limiting access to critical AI hardware, it dictates the pace and direction of innovation elsewhere, ensuring that alternative ecosystems develop under more challenging conditions. At the same time, narratives around security, ethical AI governance, and responsible innovation are deployed to justify these material restrictions, further legitimizing the existing power structure.  

This feedback loop illustrates how the superstructure does not passively reflect material conditions but actively intervenes to maintain and reshape them. Even as new production centers emerge, they do so within a landscape already defined by the controlling actors, reinforcing a cycle where technological dependencies persist under a different guise~\cite{pappachen2023historical}. Thus, the ability to withhold access to essential AI components becomes not just an economic tool but a structural mechanism for maintaining global technological hierarchies.

The question we pose in this position is, can we steer the base-superstructure interplay towards more Sustainable AI? This, we argue, can happen only if climate and resource awareness start to shape the superstructure to adjust its relationship with the material base. But, it has to start from the material base, as the labour layer in AI -- all of us -- are part of the material base. In the next section we present some action points that can steer the base-superstructure towards Sustainable AI.


\begin{figure}[t]
    \centering
    \includegraphics[width=0.7\textwidth]{img/base.pdf}
    \caption{The material basis for developing AI consists of raw-materials, monetary investments, labour, and knowledge commodities. This base forms the foundation of AI as an infrastructure which also shapes the socio-political identity of AI -- manifested through policy, regulation, cultural narratives, media and education -- which can be considered the superstructure. The material base shapes the superstructure, which in turn maintains and shapes the base. Both the base and superstructure are not static; they influence each other. This base-superstructure view, developed as part of historical materialism~\cite{marx1844philosophic}, when applied to AI offers useful insights into how we can influence the combined entity to become more sustainable.}
    \label{fig:base}
\end{figure}



\section{Climate and Resource Aware Machine Learning (CARAML)} 
\label{sec:caraml}


The process of scaling up AI models typically involves the transition from small, specialized models to large, generalizable ones with progressively increasing effort and resources~\cite{kaplan2020scaling}. Similarly, achieving Sustainable AI requires one to {\em scale up actions} at multiple levels that work together toward a unified goal of building CARAML systems.

We outline some ideas that are already prevalent in literature, and chalk out other new suggestions, within the CARAML framework that evolves across individual, community, industry, government and global levels.


\begin{enumerate}
\item {\bf Individual Researchers} 
\begin{enumerate}
    \item {\em Redefining Metrics of AI Success:} Performance measures of models should account for sustainability, as focusing only on task-specific measures like accuracy obfuscate climate and resource awareness. Performance that is normalised to account for resource costs is more useful in this regard~\cite{evchenko2021frugal,selvan2025pepr}.

    \item {\em Pareto Sustainable AI:} Multi-objective optimization that actively strives to balance performance, climate awareness and resource awareness will be important in pursuing Sustainable AI. Pareto optimization offers tools here to obtain set of solutions with varying trade-offs~\cite{miettinen1999nonlinear}.

    \item {\em Commit to Open-Source and Transparent Reporting:} Publishing trained models and datasets to foster reproducibility can go a long way in improving how we conduct AI sustainably. This can reduce repeated investment of resources to redo experiments and help improve access to expensive models~\cite{eiras2024risks}. Additionally, documenting useful negative results in publications can be important in reducing resources being spent on ideas that have been shown to be unsuccessful~\cite{schein2024i}.
    \end{enumerate}
    \item  {\bf ML Community}
    \begin{enumerate}
        \item {\em Pre-Registering Experiments and Accountability:}  Large-scale AI experiments should be pre-registered as it enhances transparency and accountability. It can also prevent wasted resources on flawed or misleading research, ensuring investments in AI contribute to long-term, ethical progress rather than short-term hype. Finally, it can help prioritize responsible experiments that justify their resource costs, discouraging redundant or wasteful computations~\cite{albanie2021prereg}.

        \item {\em Encourage Transparency and Self-reporting:} Many ML conferences already have a {broader impact} statement. Expanding these statements to include a comprehensive sustainability impact statement can be useful. Providing tools to measure this impact can help standardise reporting resource costs, using interfaces like MLCO2 Impact Calculator~\cite{lacoste2019quantifying}, carbontracking tools~\cite{henderson2020towards,anthony2020carbontracker}, and model cards~\cite{mitchell2019model,strubell2019energy}.

        \item {\em Hybrid Conferences for Sustainable AI:} Transitioning to hybrid conferences can enhance accessibility by allowing researchers from diverse backgrounds, including those with financial, geographic, or mobility constraints, to participate. They reduce travel costs for attendees while broadening the audience. Significantly lower the carbon footprint of conferences by reducing the need for extensive air travel~\cite{epp2023can,hybrid2024}. Some ML conferences are already doing this. To take this forward, in-person participation should be limited and spots should be either randomly allocated\footnote{NeurIPS 2024 had to resort to a lottery-based participation as the number of spots were fewer than the expected number of participants. Source:~\url{https://blog.neurips.cc/2024/10/29/neurips-2024-registration-changes/}}, or allotted to optimize for improving diversity, equity, and inclusion amongst the participants. On the other hand, the hybrid conferences may increase the costs of the conference due to the need to ensure reliably streaming the conference talks to everyone, lead to an unpredictable conference budget due to difficulties of estimating the number of people who will join the conference in-person, and amplify the burden on the conference organizers.
    \end{enumerate}
    \item {\bf AI Industry}
    \begin{enumerate}
        \item {\em Synergy with Academia:} Collaborations between industry and academia can help address AI’s societal challenges -- such as bias, fairness, and inclusivity -- by combining resources from industry (data and other infrastructure). It can also help avoid redundant efforts, enabling efficient and responsible resource allocation~\cite{ahmed2023growing}.

        \item {\em Sustainability Impact Disclosures:} Handful of industrial entities control vast infrastructure in the AI sector. Estimating the embodied emissions is next to impossible due to the opacity in how many industries conduct business~\cite{luccioni2023BLOOM}. Mandating these disclosures in standardized reporting can help assess the actual sustainability impact of AI industry~\cite{luccioni2023counting,wright2023efficiency}.

        \item {\em Carbon Cap for AI:} A regulatory limit on the total carbon emissions due to AI should be endorsed by industry. Given the skyrocketing energy demands of large-scale AI training and deployment~\cite{sevilla2022compute}, this approach would force the industry to prioritize sustainability and accountability.

    \end{enumerate}
    \item {\bf Governments}
    \begin{enumerate}
        \item {\em Redefining Metrics for AI Impact:} Governments could require mandatory AI Impact Assessments (AIAs) similar to Environmental Impact Assessments (EIAs)~\cite{reisman2018algorithmic}. These would evaluate potential AI impacts on employment, social structures, privacy, and environmental sustainability, ensuring projects are aligned with public welfare.

        \item {\em Reverse Innovation from LMICs:} Implement programs that not only transfer AI technologies to LMICs but also create mechanisms for reverse innovation, where solutions developed in LMICs are brought back to HICs. This model ensures that AI development is truly inclusive and reflects diverse challenges, as has been argued for in domains like healthcare~\cite{ahmed2017can}.

        \item {\em Ethics, Policy and Governance:} Each country faces unique challenges based on its socio-political context, economic development, technological infrastructure, and cultural values. This would entail pursuing regional {AI sovereignty}. However, the core challenges surrounding Sustainable AI are shared globally. Governments must recognize both the commonalities and the specifics to create effective frameworks that are adaptable yet robust across contexts~\cite{mugge2024eu}.

    \end{enumerate}

    \item {\bf Global Action}
    \begin{enumerate}
        \item {\em Coordinated Global Standards:} Governments, in collaboration with international organizations (like the UN or OECD), could establish global standards for AI ethics, safety, and performance. These standards would provide guidelines for ensuring Sustainable AI. Efforts like the EU-AI Act~\cite{eu2024aiact} are initial attempts at this which need support from all levels in the CARAML framework to help it evolve in the fast-paced AI sector.

        \item {\em Addressing the Digital Divide Through Global Access:} Governments and international organizations should make AI tools, infrastructure, and knowledge accessible to all. This could involve providing affordable cloud-based AI platforms, open-source models, and training programs to build local AI expertise~\cite{sastry2024computing}. The question of ``Right to Compute" is already being raised~\cite{shearer2024compute} which needs to be adjusted to the ``Right to Sustainable Compute". 

        \item {\em Coordinated Research on Global Challenges:} Establish international consortia that bring together AI stakeholders from across the world to work on solving pressing global challenges, such as climate change, pandemic response, poverty, and sustainable development. By pooling resources, knowledge, and expertise, these collaborative efforts would ensure that AI solutions are developed with global impact in mind, particularly for solving problems that span the planet~\cite{kaack2022aligning}. This would be the antidote to the rhetoric that encourages a global AI arms race.

    \end{enumerate}



\end{enumerate}

To develop Sustainable AI in a way that benefits everyone, we must embrace climate and resource awareness. The recommendations presented here at the different scales in the CARAML framework can be used to sway the dynamics in the AI base-superstructure towards improving the sustainability of AI.


\subsection*{Alternative views}

The key alternative views to the position presented in this paper have been argued against from only climate or on resource aspects. To the best of the authors knowledge, there are no widely held views that dispute our stance of identifying the contradictions between climate awareness and resource awareness and/or the recommendations proposed within the CARAML framework.

The caution we ask the community to have about the growing climate impact of AI has been disputed in some important papers. For example, \citet{patterson2022carbon} claim that the carbon footprint of ML will plateau, and then shrink. All the authors in this work were affiliated with Google, and was seen as a rebuke to some works like~\citet{strubell2019energy} that had estimated the carbon footprint of training AI models. Ironically though, Google had ``a 13\% year-over-year increase and a 48\% increase" in their 2024 carbon emissions compared to their 2019 target base year. This is primarily attribute to increases in data center energy  consumption~\cite{google2024environment} indicating that the carbon footprint is neither plateauing nor shrinking.

Another line of argument that is presented is that the carbon footprint of ICT sector has largely remained constant due to the efficiency improvements of hardware. For example,~\citet{malmodin2024ict} show this to some degree according to their estimations. While efficiency improvements are important, and can certainly reduce the corresponding carbon footprint, it is not enough to achieve Sustainable AI as argued by \citet{wright2023efficiency}.


\section{Conclusion}

We are at the precipice of massive changes in our world. Climate change is at our doorstep and we -- as a global community -- are lagging behind on the effort required to meet any reasonable planetary warming targets. These effects have a disproportionate impact on poorer and disadvantaged communities~\cite{hallegatte2017climate}. 

And concurrently, we are also at the verge of creating one of the most promising technological capability with the recent advancements in AI. The hype and doom around ``general AI" is detrimental to a meaningful discourse~\cite{hanna2024theoretical}. And also viewing AI as a panacea to all problems including climate change adaptation and climate change mitigation is naive~\cite{klein2014changes}. However, when faced with a planetary-scale problem, we should have all the tools at our disposal -- including AI methods, except with a key difference. We have argued in this position that it should be Sustainable AI that we should strive for. The discourse around democratization of AI, AI sovereignty, green AI, and inclusive AI, are all inter-related. We as a community should resist the forces that pit us against each other in a global AI arms race. We have more important problems that are actually threatening our existence, like climate change to address. For the AI solutions we develop to have a net positive impact, we have to be both aware of its climate impact and resource costs.
