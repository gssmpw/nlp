\section{\MR Attacks and Surveys}
\label{sec:relwork}
%While there are significant advances in the field of \MR security, 
Our literature review categorizes unique aspects of \MR security into three distinct areas: User Manipulation and Deception, Privacy and Data Security, and Frameworks and Surveys.

\subsection{User Manipulation and Deception}
%\MR and \VR technologies have the potential to be excellent environments for manipulating users' perceptions. 

Prior work explored techniques to manipulate facets of users' perceptions and decision-making in \MR. 
Casey et al. \cite{Casey_2021} introduced new proof-of-concept attacks that pose a threat to user safety in a \VE. Their work categorized and defined the following attack types: chaperone, disorientation, human joystick, and overlay. The human joystick successfully manipulated users to move to specific physical locations without their awareness. The chaperone attacks manipulated the \VE boundaries, while the disorientation attack elicited a sense of dizziness and confusion from an immersed \VR user. Lastly, in an overlay attack, an adversary overlaid objects such as images and videos onto a user’s \VR view.
Chandio et al.~\cite{chandio2024stealthy} introduced stealthy and practical multi-modal attacks on \MR tracking, showing that \MR systems relying on sensor fusion algorithms for tracking can be compromised through perceptual manipulation by attacking multiple sensing streams simultaneously.

Nilsson et al. \cite{nilsson201815} provided an overview of \RDW techniques in \VR that use subtle manipulations of gains and overt redirection techniques to manipulate user's perception of space and movement. Brinkman \cite{Brinkman} describes attacks that subtly influence user choices without their awareness as decisional interference.
%Through a series of experiments involving card sorting tasks, the study shows that even when \AR systems are intended to deliberately mislead users, the majority fail to notice the deception. 
De Haas \& Lee \cite{deHaas2022audio} provide a comprehensive analysis of the manipulative potential of audio effects design in \AR which systematically categorizes deceptive audio cues into various categories, each of which uniquely influences user perception and behavior.
Wang et al. \cite{wang2023dark} further investigate how these deceptive design techniques, known as dark patterns, can manipulate users in \AR environments and compromise their information and safety.
% Moved Trivers work from the memory section
Building on psychological aspects of manipulation, Trivers \cite{Trivers2011Deceit} describes how deception is a natural part of life, not just for humans but all living beings.
%describes the relationships between deceit and self-deception, emphasizing their cognitive cost and potential benefits in various interactions. 
This analysis provides a foundational understanding of the psychological dynamics at play, illustrating how \MR systems can exploit the natural tendencies of humans to manipulate and be manipulated, influencing user perception and decision-making.

%``\acp{PMA} are a class of potential attacks aiming to manipulate a human’s multi-sensory perceptions of the physical world to influence users' decision-making and even lead to physical harm through the presented \MR output stimuli'' \cite{Tseng_2022, cheng2023exploring}. 
\acp{PMA} attempt to exploit a user's sensory perceptions to influence their decision-making, which can lead to physical harm \cite{Tseng_2022, cheng2023exploring}.
Ali et al.~\cite{Ali_Mahmood_Qadri_2018} investigated visual deception by creating illusions of 3D views using projections onto 2D surfaces.
%as an example of a \PMA, which is investigated  in the work done by 
Cheng et al.~\cite{cheng2023exploring} derived a framework for comprehending and addressing \acp{PMA} within the context of \MR. 
%They addressed three specific scenarios: 
They demonstrated that \acp{PMA} can manipulate user perceptions to affect reaction times. 
%They emphasized the potential of visual and auditory \acp{PMA} to divert users' attention and impair their ability to focus on tasks. Additionally, 
They investigated the effects of \acp{PMA} on situational awareness, revealing how \MR content can divert users' attention away from essential real-world stimuli, undermining their concentration and attentiveness. 
Ledoux et al.~\cite{ledoux2013using} found that visual cues in \VR can evoke food cravings, showing how sensory manipulations influence user perception. % that can be extended to \acp{PMA} in \MR. 
Tseng et al.~\cite{Tseng_2022} investigated the risks of perceptual manipulations in \VR, focusing on the negative impacts that these manipulations may have on users.

\gap{Most recent research on user manipulation and deception has focused on \VR systems, leaving \AR systems underrepresented. Future research should prioritize \AR security.}

% \subsection{Method}
% The related works can be classified into two primary categories: studies that concentrate on security attacks within the domains of Virtual Reality and Augmented Reality, as well as broader Mixed Realities, and studies that concentrate on Perceptual Manipulation Attacks and establish the terminology and attributes of them.

\subsection{Privacy and Security}
% \MR, \VR, and \AR technologies offer immersive experiences but also raise deception, privacy, and data security concerns. Ling et al. \cite{inproceedings1} expose \VR system vulnerabilities to side-channel attacks, revealing how they can be exploited for deception. Yarramreddy et al. \cite{Yarramreddy} explore the forensic implications of deceptive practices in immersive \VR systems, showing how forensically relevant data can be reconstructed from network traffic and system logs. Casey et al. \cite{Casey} contribute to the detection of deceptive activities with an open-source \VR memory forensics plugin for the Volatility Framework. Nair et al. \cite{nair2023exploring} uncover serious privacy risks in \VR environments, detailing various adversaries capable of leveraging deceptive techniques to extract personal data covertly. They caution against adversarially designed \VR games that exploit user trust to gather sensitive information.
%\MR and \VR not only offer immersive experiences that can be used for deception and manipulation but also 
\addition{MR and VR headsets pose significant challenges for privacy and security.
These headsets collect, use, and present personal information, making them vulnerable to information leaks via side-channel attacks.
Further, attackers can use deception attacks to disrupt information channels and cognitive processes causing users to take actions that may expose additional personal information.}


\addition{%Prior work has explored vulnerabilities that expose users' personal information.
Slocum et al.~\cite{slocum2023going} introduced TyPose, which uses machine learning techniques to classify motion signals from \MR headsets by analyzing subtle head movements made by users when interacting with virtual keyboards. 
Al Arafat et al.~\cite{al2021vr} presented the VR-Spy system, which utilizes the channel state information of Wi-Fi signals to detect and recognize keystrokes based on fine-grained hand movements. Su et al.~\cite{su2024remote} present a method for remotely extracting motion data from network packets and correlating them with keystroke entries to obtain user-typed data such as passwords or private conversations.} 
Ling et al. \cite{ling2019know} highlighted the vulnerability of \VR systems to novel side-channel attacks. 
They showed how these attacks exploit computer vision and motion sensor data to infer keystrokes in a \VE. 
\addition{Knowing what information a user is typing or specific personal details could help attackers develop more believable deception attacks.}

Vondráček et al.~\cite{vondravcek2023rise} introduced the Man-in-the-Room attack in \VR, where an attacker gains unauthorized access to a private \VR room and observes all interactions. 
\addition{Through observation, attackers can develop more targeted deception attacks.} 
Nair et al. \cite{nair2023exploring} outlined significant privacy risks in \VR environments, proposing a threat model with four adversaries: Hardware, Client, Server, and User. These adversaries have access to different aspects of the \VR information flow. These risks can covertly reveal personal data, and adversarially designed \VR games may manipulate users into disclosing sensitive information.

%They implemented \VR-specific worms and botnets, showing the malware propagation within \VE.  
\addition{Prior work has also explored the digital forensics of VR headsets.}
Yarramreddy et al.~\cite{Yarramreddy} presented an exploration of the forensics of immersive \VR systems, which demonstrates the feasibility of reconstructing forensically relevant data from both network traffic and the systems themselves. 
Casey et al.~\cite{Casey} introduced the first open-source \VR memory forensics plugin for the Volatility Framework. 
\addition{Using forensic techniques could allow an attacker to uncover personal information about a user's behavior or interest, which could be leveraged for deception attacks.}

% \removal{One significant privacy challenge for VR is the use of side-channel attacks to infer user input. Slocum et al.~\cite{slocum2023going} introduced TyPose, which uses machine learning techniques to classify motion signals from MR headsets by analyzing subtle head movements made by users when interacting with virtual keyboards. In contrast, Al Arafat et al.~\cite{al2021vr} presented the VR-Spy system, which utilizes the channel state information of Wi-Fi signals to detect and recognize keystrokes based on fine-grained hand movements. Su et al.~\cite{su2024remote} propose a method for remotely extracting motion data from network packets and correlating them with keystroke entries to obtain user-typed data such as passwords or private conversations.} 

% Nair et al. in their recent study \cite{nair2023exploring}, highlight serious privacy risks in \VR environments and mention that the \VR privacy threat model includes four potential adversaries, each associated with different aspects of the \VR information flow, which include the Hardware Adversary, with access to raw sensor data; the Client Adversary, representing the \VR application developer with full API access; the Server Adversary, controlling the external server for multiplayer functionalities; and the User Adversary, a second end-user in the same multiplayer application. They suggest that these privacy risks can covertly infer personal data attributes, and adversarially designed \VR games can trick users into revealing personal information.

% Roesner et al. \cite{10.1145/2580723.2580730} provide a comprehensive analysis of security and privacy in augmented reality \AR, revealing unique vulnerabilities in \AR browsers. Another study \cite{10.1145/2736277.2741657} conducts the first system-level assessment of security features in \AR browsers. Lebeck et al. \cite{10.1145/2873587.2873595} introduce Arya, an \AR platform regulating application output to mitigate risks from malicious or faulty applications. This focus is complemented by additional research \cite{inproceedings3} exploring input privacy risks and malicious \AR output.

\addition{
%In addition to privacy concerns, 
Security issues can expose \MR users to physical harm and potential deception attacks.}
Odeleye et al.~\cite{odeleye2021detecting} showed attacks targeting GPU and network vulnerabilities in \VR systems to manipulate frame rates and cause \VR sickness. 
Roesner et al.~\cite{Roesner2011Security} conducted a comprehensive examination of security and privacy concerns in \AR, unveiling new vulnerabilities unique to \AR applications. 
\addition{For example, they suggest displaying the provenance of AR elements so that users know the source of augmentations. Without this, users are susceptible to deception attacks that inject false information.}
McPherson et al.~\cite{10.1145/2736277.2741657} conducted the first system-level assessment of security and privacy features in \AR browsers. 
Lebeck et al.~\cite{10.1145/2873587.2873595} introduced Arya, an \AR platform aimed at regulating application output to mitigate risks from malicious or faulty applications. 
This focus on output security is complemented by research delving into input privacy risks and the largely unexplored area of malicious \AR output \cite{inproceedings3}.
Cheng et al. \cite{cheng2024user} introduced several proof-of-concept attacks targeting \UI security vulnerabilities in \AR systems. %\addition{By compromising UI security, attackers can undermine user trust by directly affecting user interactions.}
Slocum et al. \cite{Slocum2024Shared} investigate the security vulnerabilities in multi-user \AR applications, focusing on the shared state that maintains a consistent virtual environment across users.

% The paper by Roesner et al. \cite{10.1145/2580723.2580730} provides a comprehensive overview of security and privacy issues in augmented reality \AR, identifying new categories of vulnerabilities unique to \AR browsers and another study \cite{10.1145/2736277.2741657} offers the first system-level evaluation of the security and privacy properties of \AR browsers. Addressing the output side of \AR security, the work by Lebeck et al. \cite{10.1145/2873587.2873595} introduces Arya, an \AR platform designed to control application output according to specified policies, thereby mitigating risks from malicious or buggy applications. This focus on output security is further elaborated by research \cite{inproceedings3} that explores both input privacy risks and the largely unexplored domain of malicious \AR output.

\begin{figure*}[t!]
    \centering
    \includegraphics[width=\textwidth]{figures/mindmap.pdf}
    \caption{Mind Map of \MR Deception Attacks Ontology. Channel attacks on the left. Processing attacks on the right.} % Goals are labeled for Degradation, Denial, Subversion, and Corruption Attacks.}
    \label{fig:attacks-mindmap}
    \vspace{-1ex}
\end{figure*}


\subsection{Frameworks and Surveys} %Security Attacks within \MR}

%Regarding security threats in the context of \MR, 
%Rokhsaritalemi et al.~\cite{article1} categorized \MR systems into five layers: \MR concepts, system architecture, design integration issues, and interfaces.
Garrido et al.~\cite{garrido2023sok} systematized knowledge on \VR privacy threats and countermeasures, %, and sensitive personal information within telemetry data.
%They successfully outline privacy opportunities for practitioners. 
focusing on two types of attacks: profiling and identification.
Profiling attacks collect sensitive personal data to create user profiles.
Identification attacks uniquely pinpoint a user within a \VR environment. %, often by collecting and combining several data points.
Happa et al.~\cite{10.3389/fict.2019.00005} developed an abstraction-based reasoning framework to reveal possible attacks in collaborative \MR applications.
%conducted a comprehensive examination in their study,
De Guzman et al. \cite{De_Guzman_2019} provided a survey of various protection mechanisms proposed for \MR. 
Adams et al.~\cite{219386} conducted interviews with \MR users and developers to survey \MR privacy policies and their perceptions. %focused on \MR security and privacy perceptions by 
Stephenson et al. \cite{stephenson2022sok} systematized knowledge on \AR/\VR authentication mechanisms, evaluating research proposals and practical deployments.

\gap{There is a notable lack of frameworks that address diverse aspects of \MR security, including technical exploits, user experience, detection, and defense.}

% oLD
% \gap{There is a lack of integrated frameworks that address different aspects of \MR security.}