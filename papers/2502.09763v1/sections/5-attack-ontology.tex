\section{\MR Deception Attacks Ontology}
\label{sec:decattacks}

We derive a \MR deception attack ontology (Figure~\ref{fig:attacks-mindmap}) from our review of the literature, our expert knowledge, and the Borden-Kopp model~\cite{borden1999information,kopp2000information,brumley:2012}.  
\addition{Their model focuses on how deceptions alter a victim's decision-making by manipulating information channels to inject false information or hide true information.
Additionally, they identify how false information can be used to induce biases that influence how information is processed and interpreted. 
As MR headsets directly transmit information to users, their information-theoretic model provides an appropriate and robust framework for describing, categorizing, and analyzing MR deception attacks.
}
%Figure~\ref{fig:attacks-mindmap} shows a mind map of the ontology. 
The Borden-Kopp model divides deception attacks into \textit{channel attacks} and \textit{processing attacks}. 

%The model's emphasis on both manipulating information channels and altering information processing provides a robust framework for understanding deception within MR systems.

%The Borden-Kopp model specifies four forms of manipulation that can mislead perceptions of news media: \textit{Degradation}, \textit{Denial}, \textit{Subversion}, and \textit{Corruption}. They classify Degradation and Denial as \textit{Channel Attacks} and Subversion and Corruption as \textit{Processing Attacks}. 
%Table~\ref{tab:attacks} categorizes technical attacks from the literature review using our ontology.

\subsection{Channel Attacks}
Channel attacks primarily target information communication channels. 
These attacks exploit the physical or logical paths that data takes as it moves between different components of a system or between different entities. 
The Borden-Kopp model identifies three types of channel attacks: \textit{overt degradation}, \textit{covert degradation}, and \textit{denial}.
%Degradation and Denial models are two forms of these attacks.

\subsubsection{Overt Degradation} 
     % In overt degradation, an attacker introduces recognizable noise, disrupting the signal and causing uncertainty, confusion, or false perceptions.
     % For example, adding a repetitive, annoying sound makes it difficult for a user to process task-related information and may evoke frustration that leads to uncertainty.
     %to introduce uncertainty or to mislead perception in the belief of a user by adding noise or background messages to the \MR environment. 
     %Degradation is either overt (active) or covert (passive). 
     With overt degradation, attackers of \MR systems create confusion by introducing substantial visual, auditory, or tactile noise to prevent victims from accurately perceiving or engaging with virtual objects, the physical world, or associated tasks.
     Due to the blatant nature of overt degradation, victims become aware that they are under attack.
     %the attacker generates significant noise to prevent information processing, but additionally revealing that an attack is taking place. 
     %the objective is to introduce doubt, confusion, or uncertainty. 
     The presence of virtual noise can be disorienting in the context of \MR, as users heavily depend on the seamless integration of real and virtual information in order to maintain focus on a task. 
     \addition{Further, it can disrupt immersive experiences, preventing users from becoming fully engaged in a task.}
     We identify the following forms of overt degradation attacks:
     %This deception tactic can be exploited through various methods which encompass:
     
     \begin{itemize}
     \itemsep0em
     \item 
     \emph{Sensory Overload}: Inundate the user's sensory receptors with excessive amounts of stimuli, leading to disorientation or distraction \cite{Roesner2011Security, odeleye2021detecting}. 
     %According to the \APA Dictionary of Psychology~\cite{10dbfdda-1535-34bd-8b0c-3f342ddcf745}, disorientation is ``a state of confusion or loss of awareness of one's surroundings.'' 
     Disorientation can cause a user to feel lost or confused within a \VE, making them more susceptible to manipulation. 
     %Distraction is ``any stimulus or event that diverts attention away from the task at hand.'' 
     Distraction diverts the user's attention, potentially preventing them from detecting or responding to an attack.
     
     \item \emph{Momentary Misdirection}: Redirect the user's attention using virtual content within a \MR systems. Misdirection distracts the user from their task. For example, an attacker can insert flashing virtual elements that draw the user's visual attention away from seeing important information or activities in the physical world.
     
     \item  \emph{Signal Replacement}: Alter or replace sensory input within \MR systems. This can lead to a user perceiving a different reality from what actually exists, potentially causing confusion, disorientation, or exploitation \cite{Tseng_2022}.
     
     \item  \emph{Quality Erosion}: Reduce the quality of the signal from the \MR headset. This can be achieved through actions such as decreasing the resolution of visual elements, introducing distortions to audio, or reducing the vibration intensity of haptic feedback.
     \end{itemize} 





\subsubsection{Covert Degradation}
      Covert degradation attacks subtly suppress or diminish the clarity of information presented by \MR headsets.
      Attackers can blend deceptions seamlessly with the \MR environment, thereby making it harder for the user to discern.
      %utilize a concealed attack method, leveraging the virtual background elements or ambient noise intrinsic to the \MR setting. The objective is to . 
      \addition{By leveraging immersive MR experiences, deception attacks can mask false information as users' attention and interactions are focused elsewhere.}
      We identify the following forms of covert degradation attacks:
      
     \begin{itemize}
     \itemsep0em
     \item \emph{Physical Movement Manipulation}: Relocate a user without their awareness or consent by discreetly shifting the center of a \VE while they focus on a task%, with users naturally adjusting as they focus on their tasks
     ~\cite{Casey_2021}.
     
     % user's movements or interactions within the virtual environment are taken over by an attacker without authorization. They have the ability to cause confusion and discomfort by altering the user's movements, interactions, or sensory experiences.
     \item \emph{Boundary Manipulation}: Altering boundaries within the \VE, which can lead to unexpected collisions with objects or distortions in spatial perception~\cite{schmidt2019blended}.
     
     \item \emph{Dimension Manipulation}: Modifying the proportions, scale, or spatial relationships of virtual objects~\cite{bozgeyikli2021evaluating}.
     \end{itemize} 

\subsubsection{Denial}

Denial attacks seek to increase uncertainty by obstructing the user's access to information. This is achieved by shutting down virtual overlays, prohibiting interaction with virtual objects, or disrupting the seamless blend of real and virtual elements. % that \MR relies upon effectively denying the user access to their own information. 
This is often an overt method of deception, as users may be cognizant of their deprived or diminished accesses \cite{kopp2003shannon}. A user may find themselves subject to a Denial attack if they lose ingress to existing networks, communication channels, and various other system features. 
%Three types of denial attacks are:
We identify the following forms of denial attacks:
    \begin{itemize}
    \itemsep0em 
    
    \item \emph{Shutdown}: Deliberately terminate or disable a \MR communication channel or service. % of the \MR system. % with the intention of disrupting its availability.
    
    \item \emph{Overlay}: Layer content over a communication channel to disrupt normal operations of the channel \cite{Lee2021AdCube, Roesner2011Security, Tseng_2022}. %. The purpose of this overlay is to 
     
    \item \emph{Removal}: Selectively remove or block information \cite{odeleye2021detecting}.
    \end{itemize} 

\input{tables/attacks}

\subsection{Processing Attacks}
Processing attacks target vulnerabilities in how humans cognitively process information, aiming to deceive humans by altering their perceptions, interpretations, and understandings of information. 
The Borden-Kopp model identifies two types of processing attacks: Corruption and Subversion.
%Corruption and Subversion are two categories of processing attacks that exploit this method to deceive a user.

    \subsubsection{Corruption} 
Corruption attacks deliberately manipulate the \MR system by counterfeiting existing virtual elements and information.
These manipulations result in inconspicuous data and actions that are difficult to discern from standard data and actions within the \MR system.
Their primary objective is to create false belief in a user, often causing compromised decision-making, incorrect conclusions, or virtual misdirection. 
\addition{Due to the immersiveness of MR, users may be more susceptible to corruption attacks as their engagement keeps them preoccupied, preventing critical analysis of false information.}
We identify the following corruption attacks:
     
     \begin{itemize}
     \itemsep0.5em 
     \item \emph{Spoofing}: Create or modify data in a way that deceives the recipient or system into believing that the data is authentic or unaltered. %Spoofing can take many forms. 
     Two forms of spoofed data are:
     %Two common types are software telemetry and hardware telemetry ~\cite{zhang2023s, al2021vr}: 

         \begin{itemize}[leftmargin=3mm]
         \itemsep0em
         \item \emph{Software Telemetry}: Alter or fabricate telemetry data from software. Attackers create or manipulate telemetry messages that convey a normally functioning application. Further, attackers may spoof telemetry messages at the system level, affecting multiple applications or impacting critical systems \cite{chandio2024stealthy}. %These messages provide information about the status of the entire system. By altering them, an attacker can hide the presence of failures or other critical system issues.
         
         \item \emph{Hardware Telemetry}: Alter or fabricate telemetry data from hardware sensors. Attackers can generate false sensor readings. Alternatively, attackers can manipulate input data from \MR headsets or peripherals, such as controllers, enacting undesired actions or preventing users from performing desired tasks \cite{tu2018injected, chandio2024stealthy}. %This can lead to input spoofing attacks, where the attacker sends fake input signals to the system, potentially causing unexpected or malicious behavior.
         \end{itemize}
     
     \item \emph{False-Flag Operations}: Disguise the source of an attack in order to blame another party. %Generate confusion and redirect focus away from an attacker's actions.
     \end{itemize} 

     \subsubsection{Subversion} 
     Subversion attacks covertly manipulate a system or its information streams, resulting in falsified and fabricated interpretations by the user. Subversion often employs covert tactics, such as corruption attacks, which weaken trust or disrupt normal operations. 
     \addition{We suspect that the immersiveness of MR can aid false interpretations as users unknowingly engage with deceptive information through repeated interactions, which can correspondingly build trust in deceptive elements.}
     We identify the following subversion attacks:
     \begin{itemize}
     \itemsep0em

     \item \emph{Bias Attacks}: Deliberate manipulation of data or decision-making processes to systematically introduce bias or prejudice toward a specific concept or outcome.
     %\item \emph{A-Priori Attacks}: The attacker manipulates perceptions and decisions by taking advantage of existing beliefs, prejudices, or preconceptions.
     \item \emph{Disinformation}: Spread false information to deceive and cause harm~\cite{guess2020misinformation}.
     \item  \emph{Lure}: Entice users to engage with (harmful) content.
     \item \emph{Propaganda}: Manipulate perceptions, influence narratives, and garner support for a specific cause or element.
     \item \emph{Gaslighting}: Erode trust and confidence, making it difficult for victims to distinguish truth from deception.
     \end{itemize}

%By applying the Borden-Kopp model of deception to \MR systems, we have successfully categorized deception attacks into five different types: Overt Degradation, Covert Degradation, Denial, Corruption, and Subversion. 
%Based on an extensive literature review, this categorization provides valuable insights for researchers and practitioners. 
%Our systematic approach serves to clarify the \MR systems' potential vulnerabilities, thereby directly addressing the RQ1}.

\subsection{Connecting Technical Attacks to Ontology}

\MR deception attacks in our ontology typically rely on technical attacks to facilitate access to \MR systems.
Table~\ref{tab:attacks} characterizes the modalities and deception attacks supported by each technical attack identified in our literature review.
For each technical attack, we identify deception attacks directly mentioned by the authors (\scaledDing{108}) and deception attacks where the technical attack could be deployed but was not specifically mentioned by the authors (\scaledDing{109}).
We found more Channel Attacks (23) mentioned than Processing Attacks (8). 
This is not surprising considering that technical attacks typically target system-level functions which have more impact on the communication channels of \MR headsets than user's cognitive processes.
Still, we see seven attacks that mention Corruption or Subversion, and another eleven that we consider capable of supporting Processing Attacks.

\gap{State-of-the-art \MR technical attacks predominately enable Channel Attacks. More research is needed on technical attacks that facilitate Processing Attacks and how these attacks affect \MR users. }

% We need investigations of technical attacks that support processing attacks.}

We identify the sensory modalities affected by an attack and the technical modalities it targets. 
Sensory modalities include visual, auditory, and tactile (e.g., vibrotactile feedback from controllers).
Technical modalities include hardware, software, network, data, and side-channel~\cite{attkan2022cyber}.
%While we found attacks for all modalities, it is clear that visual and software modalities are the primary targets of existing technical attacks.
%The least targeted modalities are tactile and hardware.

\finding{Technical attacks primarily target the visual and software modalities. \MR headsets include displays and processors, making visual and software modalities convenient targets. These attacks particularly focus on overlaying content or replacing signals as opposed to overloading, eroding, or removing signals. The least targeted modalities are tactile and hardware.} 