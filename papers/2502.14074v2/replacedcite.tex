\section{Related Work}
\textbf{LLM-as-a-Judge.}
The LLM-as-a-Judge ____ evaluation method leverages frontier models to rank responses to open-ended queries without explicit ground-truths. A common approach involves using a fixed baseline model for pairwise comparisons to assess the performance of the target model, as seen in frameworks such as VicunaEval ____, AlpacaEval ____, and Arena-Hard ____. The target models are then ranked on the basis of their win rates against the baseline. However, an implicit assumption in these frameworks is that transitivity holds in preference judgments, which has not been empirically verified. Transitivity requires that if an LLM judge prefers model $m_A$ over $m_B$ and $m_B$ over $m_C$, it must consequently prefer $m_A$ over $m_C$. Violations of transitivity can result in unstable rankings that undermine the evaluation framework's reliability (\cref{fig:overview}). To address this gap, we examine the robustness of current LLM ranking methodologies by extending the AlpacaEval framework to investigate the existence of non-transitivity, aiming to establish a more rigorous foundation for the LLM evaluation system.

\textbf{Non-Transitivity in Zero-sum Games.} Prior work has explored non-transitivity in two-player zero-sum games within multi-agent reinforcement learning. ____ characterize agent interactions through convex polytopes, using their dimensionality to decompose transitive and cyclic components. ____ demonstrate that real-world strategy spaces exhibit a spinning top distribution, where non-transitivity peaks at middling performance levels but diminishes at either lower or higher levels. Given the presence of non-transitivity, evaluating a strategy based on its performance against a single opponent does not reliably reflect its true capability. Therefore, previous achievements in complex games such as StarCraft ____ and Dota 2 ____ employ population-based self-play training and evaluate agents through tournament-style competitions against diverse opponents. Mirroring the population-based evaluation paradigm that succeeded in non-transitive games, we adopt tournament-based comparisons in LLM-as-a-Judge frameworks to mitigate ranking instability induced by non-transitivity.