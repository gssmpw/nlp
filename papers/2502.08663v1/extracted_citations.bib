@article{arslan2024survey,
  title={A Survey on RAG with LLMs},
  author={Arslan, Muhammad and Ghanem, Hussam and Munawar, Saba and Cruz, Christophe},
  journal={Procedia Computer Science},
  volume={246},
  pages={3781--3790},
  year={2024},
  publisher={Elsevier}
}

@article{chen2024inside,
  title={INSIDE: LLMs' Internal States Retain the Power of Hallucination Detection},
  author={Chen, Chao and Liu, Kai and Chen, Ze and Gu, Yi and Wu, Yue and Tao, Mingyuan and Fu, Zhihang and Ye, Jieping},
  journal={arXiv preprint arXiv:2402.03744},
  year={2024}
}

@article{du2024haloscope,
  title={Haloscope: Harnessing unlabeled llm generations for hallucination detection},
  author={Du, Xuefeng and Xiao, Chaowei and Li, Yixuan},
  journal={arXiv preprint arXiv:2409.17504},
  year={2024}
}

@inproceedings{fan2024survey,
  title={A survey on rag meeting llms: Towards retrieval-augmented large language models},
  author={Fan, Wenqi and Ding, Yujuan and Ning, Liangbo and Wang, Shijie and Li, Hengyun and Yin, Dawei and Chua, Tat-Seng and Li, Qing},
  booktitle={Proceedings of the 30th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
  year={2024}
}

@article{farquhar2024detecting,
  title={Detecting hallucinations in large language models using semantic entropy},
  author={Farquhar, Sebastian and Kossen, Jannik and Kuhn, Lorenz and Gal, Yarin},
  journal={Nature},
  volume={630},
  number={8017},
  pages={625--630},
  year={2024},
  publisher={Nature Publishing Group UK London}
}

@article{feldman2023trapping,
  title={Trapping llm hallucinations using tagged context prompts},
  author={Feldman, Philip and Foulds, James R and Pan, Shimei},
  journal={arXiv preprint arXiv:2306.06085},
  year={2023}
}

@inproceedings{filippova2020controlled,
  title={Controlled Hallucinations: Learning to Generate Faithfully from Noisy Data},
  author={Filippova, Katja},
  booktitle={Findings of the Association for Computational Linguistics: EMNLP 2020},
  pages={864--870},
  year={2020}
}

@article{friel2023chainpoll,
  title={Chainpoll: A high efficacy method for llm hallucination detection},
  author={Friel, Robert and Sanyal, Atindriyo},
  journal={arXiv preprint arXiv:2310.18344},
  year={2023}
}

@article{giorgi2024human,
  title={Human and LLM Biases in Hate Speech Annotations: A Socio-Demographic Analysis of Annotators and Targets},
  author={Giorgi, Tommaso and Cima, Lorenzo and Fagni, Tiziano and Avvenuti, Marco and Cresci, Stefano},
  journal={arXiv preprint arXiv:2410.07991},
  year={2024}
}

@article{guerreiro2022looking,
  title={Looking for a needle in a haystack: A comprehensive study of hallucinations in neural machine translation},
  author={Guerreiro, Nuno M and Voita, Elena and Martins, Andr{\'e} FT},
  journal={arXiv preprint arXiv:2208.05309},
  year={2022}
}

@article{hao2024quantifying,
  title={Quantifying the uncertainty of LLM hallucination spreading in complex adaptive social networks},
  author={Hao, Guozhi and Wu, Jun and Pan, Qianqian and Morello, Rosario},
  journal={Scientific reports},
  volume={14},
  number={1},
  pages={16375},
  year={2024},
  publisher={Nature Publishing Group UK London}
}

@article{huang2023survey,
  title={A survey on hallucination in large language models: Principles, taxonomy, challenges, and open questions},
  author={Huang, Lei and Yu, Weijiang and Ma, Weitao and Zhong, Weihong and Feng, Zhangyin and Wang, Haotian and Chen, Qianglong and Peng, Weihua and Feng, Xiaocheng and Qin, Bing and others},
  journal={ACM Transactions on Information Systems},
  year={2023},
  publisher={ACM New York, NY}
}

@article{huang2025look,
  title={Look Before You Leap: An Exploratory Study of Uncertainty Analysis for Large Language Models},
  author={Huang, Yuheng and Song, Jiayang and Wang, Zhijie and Zhao, Shengming and Chen, Huaming and Juefei-Xu, Felix and Ma, Lei},
  journal={IEEE Transactions on Software Engineering},
  year={2025},
  publisher={IEEE}
}

@inproceedings{ji2023towards,
  title={Towards mitigating LLM hallucination via self reflection},
  author={Ji, Ziwei and Yu, Tiezheng and Xu, Yan and Lee, Nayeon and Ishii, Etsuko and Fung, Pascale},
  booktitle={Findings of the Association for Computational Linguistics: EMNLP 2023},
  pages={1827--1843},
  year={2023}
}

@article{kadavath2022language,
  title={Language models (mostly) know what they know},
  author={Kadavath, Saurav and Conerly, Tom and Askell, Amanda and Henighan, Tom and Drain, Dawn and Perez, Ethan and Schiefer, Nicholas and Hatfield-Dodds, Zac and DasSarma, Nova and Tran-Johnson, Eli and others},
  journal={arXiv preprint arXiv:2207.05221},
  year={2022}
}

@article{kuhn2023semantic,
  title={Semantic uncertainty: Linguistic invariances for uncertainty estimation in natural language generation},
  author={Kuhn, Lorenz and Gal, Yarin and Farquhar, Sebastian},
  journal={arXiv preprint arXiv:2302.09664},
  year={2023}
}

@inproceedings{ladhak2023pre,
  title={When do pre-training biases propagate to downstream tasks? a case study in text summarization},
  author={Ladhak, Faisal and Durmus, Esin and Suzgun, Mirac and Zhang, Tianyi and Jurafsky, Dan and McKeown, Kathleen and Hashimoto, Tatsunori B},
  booktitle={Proceedings of the 17th Conference of the European Chapter of the Association for Computational Linguistics},
  pages={3206--3219},
  year={2023}
}

@article{lin2022teaching,
  title={Teaching models to express their uncertainty in words},
  author={Lin, Stephanie and Hilton, Jacob and Evans, Owain},
  journal={arXiv preprint arXiv:2205.14334},
  year={2022}
}

@inproceedings{lin2022truthfulqa,
  title={TruthfulQA: Measuring How Models Mimic Human Falsehoods},
  author={Lin, Stephanie and Hilton, Jacob and Evans, Owain},
  booktitle={Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
  year={2022}
}

@article{malinin2021uncertainty,
  title={Uncertainty estimation in autoregressive structured prediction},
  author={Malinin, Andrey and Gales, Mark},
  year={2020}
}

@inproceedings{manakul2023selfcheckgpt,
  title={SelfCheckGPT: Zero-Resource Black-Box Hallucination Detection for Generative Large Language Models},
  author={Manakul, Potsawee and Liusie, Adian and Gales, Mark},
  booktitle={Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing},
  pages={9004--9017},
  year={2023}
}

@inproceedings{martino2023knowledge,
  title={Knowledge injection to counter large language model (LLM) hallucination},
  author={Martino, Ariana and Iannelli, Michael and Truong, Coleen},
  booktitle={European Semantic Web Conference},
  pages={182--185},
  year={2023},
  organization={Springer}
}

@inproceedings{maynez2020faithfulness,
  title={On Faithfulness and Factuality in Abstractive Summarization},
  author={Maynez, Joshua and Narayan, Shashi and Bohnet, Bernd and McDonald, Ryan},
  booktitle={Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics},
  pages={1906--1919},
  year={2020}
}

@article{orgad2024llms,
  title={Llms know more than they show: On the intrinsic representation of LLM hallucinations},
  author={Orgad, Hadas and Toker, Michael and Gekhman, Zorik and Reichart, Roi and Szpektor, Idan and Kotek, Hadas and Belinkov, Yonatan},
  journal={arXiv preprint arXiv:2410.02707},
  year={2024}
}

@inproceedings{perkovic2024hallucinations,
  title={Hallucinations in llms: Understanding and addressing challenges},
  author={Perkovi{\'c}, Gabrijela and Drobnjak, Antun and Boti{\v{c}}ki, Ivica},
  booktitle={2024 47th MIPRO ICT and Electronics Convention (MIPRO)},
  pages={2084--2088},
  year={2024},
  organization={IEEE}
}

@inproceedings{ren2022out,
  title={Out-of-distribution detection and selective generation for conditional language models},
  author={Ren, Jie and Luo, Jiaming and Zhao, Yao and Krishna, Kundan and Saleh, Mohammad and Lakshminarayanan, Balaji and Liu, Peter J},
  booktitle={The Eleventh International Conference on Learning Representations},
  year={2022}
}

@article{varshney2023stitch,
  title={A stitch in time saves nine: Detecting and mitigating hallucinations of llms by validating low-confidence generation},
  author={Varshney, Neeraj and Yao, Wenlin and Zhang, Hongming and Chen, Jianshu and Yu, Dong},
  journal={arXiv preprint arXiv:2307.03987},
  year={2023}
}

@inproceedings{venkit2023nationality,
  title={Nationality Bias in Text Generation},
  author={Venkit, Pranav Narayanan and Gautam, Sanjana and Panchanadikar, Ruchi and Huang, Ting-Hao and Wilson, Shomir},
  booktitle={Proceedings of the 17th Conference of the European Chapter of the Association for Computational Linguistics},
  pages={116--122},
  year={2023}
}

@article{verma2023reducing,
  title={Reducing llm hallucinations using epistemic neural networks},
  author={Verma, Shreyas and Tran, Kien and Ali, Yusuf and Min, Guangyu},
  journal={arXiv preprint arXiv:2312.15576},
  year={2023}
}

