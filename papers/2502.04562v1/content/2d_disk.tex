% \subsection{2D MOR-Physics Operator Problem}\label{sec:2d_disk}\.\./

% We generate synthetic 2d data consisting of pairs of functions on the unit disk that vanish on the boundary, as discussed in Section~\ref{sec:2d_data} and train our mixture of experts model to fit the operator, $\mathcal{P}(a)\approx u$. The data have activity in the center but have zero boundary conditions, \(\forall x \in \partial D, a(x)=u(x)=0\). This process generates pairs \( (\mathbf{a}, \mathbf{u}) \) that are suitable for training models and conducting further analysis because they are non-periodic and need different experts to fit different regions.

% \begin{figure}[H]
%     \centering
%         \includegraphics[width=0.4\linewidth]{\path figures/2d_exercise/2d_Input.png}
%         \hspace{.1in} % Adds horizontal space between the figures
%         \includegraphics[width=0.4\linewidth]{\path figures/2d_exercise/2d_Output.png}
%         \caption{(Left) input and (Right) output functions from 2D synthetic data.}
%     \label{fig:input_output2d}
% \end{figure}

\subsection{Recovery of a nonlinear operator on the unit disk}\label{sec:2d_data}

Our first example demonstrates POU-MOR-Physics is capable of learning local operators in nontrivial domains. We consider synthetically generated pairs of functions, ($u_i,v_i$), on the unit disk that vanish on the boundary, $\Omega = \left\{(x,y):x^2+y^2\leq 1\right\}$. We first generate a function $\hat{u}_i$ by sampling a Gaussian process. We construct a regular grid of points over a box in which $\mathcal{X}$ is embedded, and compute the point evaluations of the function $\hat{u}$ on the grid by sampling from a spatial Gaussian process with a fixed kernel $K$; the function $\hat{v}_i$ is then manufactured by a second-order finite difference approximation of the Laplacian of $\hat{u}_i^2$. We retain the function evaluations in the disk as our data, ($u_i,v_i$).
% as,
% \begin{equation}
% \begin{aligned}
%     &z_i \sim \mathcal{GP}(0,K) \\
%     &\hat{u}_i(x',y') = z_i(x',y') | \{z_i(x,y) = 0: (x,y) \not\in \Omega\} \\
%     & (x,y),(x',y') \in G
% \end{aligned}
% \end{equation}
% where $K$ is a symmetric positive definite kernel, $K: \mathcal{B} \times \mathcal{B} \rightarrow \mathbb{R}$. We compute $\hat{v}_i$ by taking the second order finite difference approximation of the Laplacian of $\hat{u}_i^2$.
Our loss function is then the squared error, 
% We obtain a mapping, $u_i \mapsto v_i$, from this synthetic data by solving the least squares problem,
\begin{equation}
    L = \sum_i || \mathcal{R}{\mathcal{P}}(\mathcal{E}{{u}}_i; \theta) - {v}_i||_{\ell_2}^2
\end{equation}
%where ${\mathcal{P}}$ is the model operator and $\theta$ are the parameters of $\hat{\mathcal{P}}$. 
% We discuss the parameterization of $\hat{\mathcal{P}}$ in Section~\ref{sec:model}

%To build our periodic domain (i.e. torus), we note that $\hat{u}_i$ and $\hat{v}_i$ vanish at the boundaries of $\mathcal{B}$. Thus, we glue the opposite sides of the box together and treat them as periodic functions. We arrive at $(u_i,v_i)$ by taking the restriction of $\hat{u}_i$ and $\hat{v}_i$ to the domain, $\Omega$, and we construct $\mathcal{P}(u)$ by extending $u$ to the domain $\mathcal{B}$ where it evaluates to zero outside of $\Omega$
%, so that ultimately our prediction mechanism takes the form $$\mathcal{P}: u \overset{\mathrm{extend}}{\mapsto} \hat{u} \overset{\hat{\mathcal{P}}}{\mapsto} \hat{v} \overset{\mathrm{restrict}}{\mapsto} v. $$
On this synthetic 2D data problem, the model successfully recovers the true solution; the model's outputs are visualized in Figure~\ref{fig:Truth_Pred2d}. We achieve a validation \(R^2>99.999\%\); as seen in Figure~\ref{fig:2d_expert_partitions}, we successfully assign a  ``Zero Expert'' \(Z(a)=0, Z: A \rightarrow U\) to the boundaries as is intended, allowing the recovery of the true boundary conditions for this problem.

\begin{figure}[htpb!]
    \centering
        \includegraphics[width=0.3\linewidth]{\path figures/2d_exercise/2d_Truth1.png}
        \hspace{.1in}  % Adds horizontal space between the figures
        \includegraphics[width=0.3\linewidth]{\path figures/2d_exercise/2d_Pred1.png}
        \hfill \\
        \includegraphics[width=0.3\linewidth]{\path figures/2d_exercise/2d_Truth2.png}
        \hspace{.1in}  % Adds horizontal space between the figures
        \includegraphics[width=0.3\linewidth]{\path figures/2d_exercise/2d_Pred2.png}
    \caption{(Left) Test data and (Right) prediction 2D synthetic exemplar. Top and Bottom are results from different test data samples.}
    \label{fig:Truth_Pred2d}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.7\linewidth]{\path figures/2d_exercise/2d_expert_partitions.png}
    \caption{Learned 2D expert partitions for 2D synthetic data. We clearly see a ``zero expert'' learned to capture boundary behavior.}
    \label{fig:2d_expert_partitions}
\end{figure}
