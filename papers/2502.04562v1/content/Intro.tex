\section{Introduction}\label{intro}

Fully resolved simulations of partial differential equations (PDEs) are prohibitively expensive for most systems, even on the largest supercomputers. Accordingly, under-resolved simulations are supplemented with models for subgrid-scale dynamics. For example, for the Navier-Stokes equations in the turbulent regime, the turbulence dynamics are approximated statistically via large eddy simulation (LES) or Reynolds averaged Navier-Stokes (RANS) models; such models are imperfect as they encode various empirical assumptions and hand-tuned approximations \cite{Pope_2000}.

Neural operators are a class of surrogate models that parameterize unknown operators with neural networks and can learn %resolution-invariant solution 
PDE models from high-fidelity simulation and/or experimental data. %Resolution invariance guarantees the learned operator will behave consistently at any data resolution. 
Originally introduced as a theoretical construction by \cite{Chen1995}, recent numerical implementations of neural operators have seen recent success in learning a variety of PDE's, e.g., \cite{patel2018MOR_Operator,patel2021MOR_Operator2,li2021FNO,Lu2021deeponet,rahman2023uno,Tapas2023wavelet}.

%Modal Operator Learning for Physics (MOR-Physics) have been shown to be effective for learning important PDEs such as Burger's equation and Kuramoto-Sivashinsky equation and obtaining homogenized PDE models from particle simulations.

Neural operators utilizing the Fourier transform, e.g., MOR-Physics \cite{patel2018MOR_Operator} and Fourier Neural Operator (FNO) \cite{li2021FNO} are particularly attractive due to the simplicity of parametrization and computational efficiency. However, the Fourier transform exhibits Gibbs phenomenon when attempting to model discontinuities and cannot handle non-periodic boundary conditions. Fourier Neural Operators (FNOs) \cite{li2021FNO} tries to remedy this by adding ``bias functions'', \(Wv(x)\) that operate along the Fourier convolution layers. However, \cite{lu2022FNOvsDeepONet} has shown that this does not fully alleviate the weakness that FNO has around non-periodic boundary conditions and discontinuities, e.g., shock waves. Another neural operator, NORM \cite{Chen2024riemannian}, generalizes the modal strategy to Riemannian manifolds, but requires precomputation of the eigenfunctions of the Laplace-Beltrami operator and lacks a fast transform. \citep{Li2023deform}, learns in addition to an FNO, a deformation from a nontrivial domain to a periodic domain but is ill-suited for higher dimensional domains \cite{Chen2024riemannian}.

% \begin{figure}[H]
%     \centering
%     \includegraphics[width=0.5\linewidth]{\path figures/Gibbs_Phenomenon.png}
%     \caption{Gibbs Phenomenon Example}
%     \label{fig:gibbs}
% \end{figure}

Instead, we address model discontinuities and boundary conditions by proposing a mixture of experts model, where the weighting of experts is determined locally across space via a partition of unity (POU). This mechanism enables the model to choose different experts on each side of a discontinuity or non-periodic transition, e.g. zero velocity at the walls for channel flow.  We apply a POU-Net \cite{lee2021POU_net, shazeer2017MoE_Sparse}  with a set of MOR-Physics Operators \cite{patel2018MOR_Operator} to better learn boundary conditions, introducing POU-MOR-Physics. In addition to being well suited to nontrivial boundary conditions, our method interpretably divides the domains for the experts. To demonstrate the method, we simultaneously learn the boundary conditions and a LES model for channel flow using the Johns Hopkins Turbulence Database (JHTDB) \cite{li2008JHTDB,graham2016JHTDB_channel,perlman2007JHTDB}.

% Below is the content added from the methods section (seemed better here).

We also take measures to accommodate the limited high-fidelity JHTDB DNS dataset. We embed a forward-Euler PDE solver in our model for training and implement uncertainty quantification (UQ) to provide a range of predictions outside the training data. The integration of the PDE solver with the learned correction serves a purpose similar to data augmentation: enabling higher-quality predictions despite the limited data. The UQ is implemented with Mean-Field Variational Inference (MFVI) \cite{blei2017variational}, which enables (1) the identification of the support of the dataset at prediction time (and hence detection of out-of-distribution (OOD) queries), and (2) the modeling of the notoriously high aleatoric uncertainty that are inherent to turbulence.


We leverage our neural operator to provide the missing physics for the subgrid scale dynamics in turbulent channel flow, i.e., LES closure modeling. To the best of our knowledge, the current state of the art for LES modeling of wall bounded turbulence with operator learning was presented by \citep{wang2024prediction}. The authors used an UNet enhanced FNO to learn a model for flows up to Re=590. In comparison, with the novel methods presented in this paper, our LES model incorporates UQ, \textit{a priori} known physics, models flows up to Re=1000, and is more interpretable due to Mixture-of-Expert style partitioning.
% Our model operates by applying a learned correction after each timestep of the regular forward-Euler solver. This correction is designed to capture the subgrid dynamics that the low-resolution solver fails to resolve, effectively enhancing its accuracy to better match the DNS data. By integrating the learned correction into the forward-Euler method at every timestep, the model adjusts the solver's output, compensating for the missing fine-scale dynamics.  In contrast to papers like \cite{li2024PINO} and \cite{raissi2019PINNs}, we apply our PDE constraints by construction rather than by penalty of the model.

\subsection{Contributions}

In this work we,

\begin{itemize}
    \item Describe a connection between volume penalized numerical methods and POU-Nets
    \item Leverage the connection to develop a novel operator learning strategy capable of learning identifying multi-physics systems with non-trivial boundary conditions.
    \item Demonstrate the method in simple 2D operator learning problems.
    % \item Learn a UQ aware LES model for turbulent channel flow.
    \item Advance the State-of-the-Art relative to \cite{wang2024prediction}, by accurately modeling Re=1000 3d wall bounded turbulence via neural operators and quantifying uncertainties.
\end{itemize}
