\subsection{Complex Values and Reparameterization Trick}\label{Complex_Reparameterization}
The complex-valued weights in the network architecture in Equation \eqref{eq:MOR_layer} are defined as
$ \theta_i = w_i+i\tilde w_i,$
where $\theta_i \in \mathbb{C}$, and the values $w_i \sim N(\mu_i, \sigma_i^2), \tilde w_i \sim N(\tilde \mu_i, \tilde \sigma_i^2)$, with Gaussian values parameterized by the reparameterization trick. This scheme yields twice as many parameters (1/2 real, and 1/2 imaginary) as compared to a comparable network parameterized with real-valued weights.

\section{Filtered DNS and LES fields from deterministic model}\label{sec:deteministic_les}

Although the main text describes a MFVI LES model, we include here a comparison between fields predicted by a deterministic model trained on the least squares loss and the fields from the filtered DNS. We note the close correspondence between the two sets of fields.

\begin{figure}[H]
    \centering
    \begin{minipage}[b]{1.0\linewidth}
        \centering
        \includegraphics[width=1\linewidth]{\path figures/deterministic_model/Learned_3d_Channel_Flow_X_Velocity.png}
        \caption{Learned Simulation: X Velocity}
    \end{minipage}
    \begin{minipage}[b]{1.0\linewidth}
        \centering
        \includegraphics[width=1\linewidth]{\path figures/deterministic_model/DNS_3d_Channel_Flow_X_Velocity.png}
        \caption{DNS: X Velocity}
    \end{minipage}
    \caption{Comparison of X velocity field from learned simulation vs DNS from JHTDB.}
    \label{fig:deterministic_x_velocity}
\end{figure}

\begin{figure}[H]
    \centering
    \begin{minipage}[b]{1.0\linewidth}
        \centering
        \includegraphics[width=1\linewidth]{\path figures/deterministic_model/Learned_3d_Channel_Flow_Y_Velocity.png}
        \caption{Learned Simulation: Y Velocity}
    \end{minipage}
    \begin{minipage}[b]{1.0\linewidth}
        \centering
        \includegraphics[width=1\linewidth]{\path figures/deterministic_model/DNS_3d_Channel_Flow_Y_Velocity.png}
        \caption{DNS: Y Velocity}
    \end{minipage}
    \caption{Comparison of Y velocity field from learned simulation vs DNS from JHTDB.}
    \label{fig:deterministic_y_velocity}
\end{figure}

\begin{figure}[H]
    \centering
    \begin{minipage}[b]{1.0\linewidth}
        \centering
        \includegraphics[width=1\linewidth]{\path figures/deterministic_model/Learned_3d_Channel_Flow_Z_Velocity.png}
        \caption{Learned Simulation: Y Velocity}
    \end{minipage}
    \begin{minipage}[b]{1.0\linewidth}
        \centering
        \includegraphics[width=1\linewidth]{\path figures/deterministic_model/DNS_3d_Channel_Flow_Z_Velocity.png}
        \caption{DNS: Y Velocity}
    \end{minipage}
    \caption{Comparison of Y velocity field from learned simulation vs DNS from JHTDB.}
    \label{fig:deterministic_z_velocity}
\end{figure}


\section{\textit{a priori} known physics for LES model}\label{sec:les_apriori}

Our LES model is an autoregressive model with \textit{a priori} known physics. See Section \ref{sec:autoregressive} for the general formulation of autoregressive models in our framework. In this section, we will start from the standard formulation of LES models and arrive at an LES model that incorporates a learned operator for various unclosed terms. As in Section \ref{sec:autoregressive}, we will separate the known physics from the unknown and expose the unknown physics to operator learning.

 Direct numerical simulation (DNS) solves the Navier-Stokes equations,
\begin{equation}\label{eq:ns}
\begin{aligned}
    &\partial_t v + \nabla {v} \otimes {u} = -\frac{1}{\rho} \nabla p + \nu \nabla^2 v & x \in \Omega\\
    &\nabla \cdot v = 0 & x \in \Omega \\
    &v = 0 & x \in \partial\Omega
\end{aligned}
\end{equation}
Equation \eqref{eq:ns} is typically expensive to integrate because real systems often contain a large range of spatiotemporal scales that must be resolved. The LES equations are obtained by applying a low pass spatiotemporal filter to the Navier-Stokes equations,
\begin{equation}\label{eq:les}
\begin{aligned}
    &\partial_t \tilde{v} + \nabla \tilde{v} \otimes \tilde{v} = -\frac{1}{\rho} \nabla \tilde{p} + \nu \nabla^2 \tilde{v} - \nabla \tau  & x \in \Omega \\
    &\nabla \cdot \tilde{v} = 0  & x \in \Omega \\
    &\tilde{v} = 0 & x \in \partial\Omega
\end{aligned}
\end{equation}
where $\tau = \widetilde{v \otimes v} - \tilde{v} \otimes \tilde{v}$ is the residual stress tensor. Since the small scale features have been filtered out, Equation \eqref{eq:les}, can be much cheaper to numerically integrate than Equation \eqref{eq:ns}. However, $\tau$ is an unclosed term that must be modeled. Traditionally, one uses a combination of intuition and analysis to arrive at a simple model with a few parameters that can be fitted to DNS simulation or experiments. Here, we will use POU-MOR-Physics to provide the closure.

To obtain our model, we will first consider LES in a triply periodic domain.
\begin{equation}\label{eq:les_periodic}
\begin{aligned}
    &\partial_t \tilde{v} + \nabla \tilde{v} \otimes \tilde{v} = -\frac{1}{\rho} \nabla \tilde{p} + \nu \nabla^2 \tilde{v} - \nabla \tau  & x \in \Omega \\
    &\nabla \cdot \tilde{v} = 0  & x \in \Omega 
    \end{aligned}
\end{equation}
We use the Chorin projection method to eliminate the pressure term and the explicit Euler time integrator to obtain an evolution operator,
\begin{equation}
\begin{aligned}
\hat{v}^{n+1} = &\tilde{v}^n  - \mathcal{F}^{-1} \left(i {\kappa} \cdot \mathcal{F}{\tilde{v}^n \otimes \tilde{v}^n} \right. \\
&\left. + \frac{i {\kappa}}{||{\kappa}||_2^2} ({\kappa} \otimes {\kappa}) : \mathcal{F}\tilde{v}^n \otimes \tilde{v}^n  - ||{\kappa}||_2^2 \mathcal{F}\tilde{{v}}^n \right)\\
= &\mathrm{LES}(\tilde{v}^n)
\end{aligned}
\end{equation}
where $\mathcal{F}$ is the Fourier transform and $\kappa$ is the wave vector.
 
This update operator does not include the boundary conditions, the missing sub-grid scale physics, or any forcing. We model these as an operator learned correction to the action above and obtain,
\begin{equation}
\tilde{v}^{n+1} = \mathcal{P} ( \mathrm{LES}(\tilde{v}^n)) = \mathcal{U}(\tilde{v}^n)
\end{equation}
where $\mathcal{P}$ is the POU-MOR-Physics operator discussed in Section~\ref{sec:model}. We can learn the closure $\mathcal{P}$ from low pass filtered DNS data and obtain a model that operates on much lower dimensional features than the original DNS, as we demonstrate in Section \ref{sec:les} and Appendix \ref{sec:deteministic_les}.

\begin{comment}
\subsection{Model Training Metrics}

Figures \ref{fig:deterministic_R2} and \ref{fig:deterministic_wMAPE} show training and validation metrics of our Mixture of Experts MOR-Physics Operator method to the full 3D JHTDB channel flow problem. We compare both $R^2$ values and weighted mean absolute percent error (wMAPE) scores, where
$$\text{wMAPE}(\tilde y, y) = \frac{\sum_{i=1}^{n} | \tilde {y}_i - y_i |}{\sum_{i=1}^{n} | y_i |} \in [0,1].$$
Notably, there seems to be almost no discrepancy between the training and validation performance, indicating good generalization with an $R^2 = 0.988$ and  $wMAPE = 0.01$ after 92K training steps.

\begin{figure}[htpb!]
\centering
\begin{subfigure}[t]{0.45\linewidth}
        \includegraphics[width=\linewidth]{\path figures/best_model_metrics/train_R2.png}
        \caption{Train \(R^2\)}
\end{subfigure}%
\begin{subfigure}[t]{0.45\linewidth}
        \includegraphics[width=\linewidth]{\path figures/best_model_metrics/val_R2.png}
        \caption{Test \(R^2\)}
\end{subfigure}
    \caption{Train and test $R^2$ scores for the JHTDB problem, plotted against epoch.}
    \label{fig:deterministic_R2}
\end{figure}

\begin{figure}[htpb!]
\centering
\begin{subfigure}[t]{0.45\linewidth}
        \includegraphics[width=\linewidth]{\path figures/best_model_metrics/train_wMAPE.png}
        \caption{Train wMAPE)}
\end{subfigure}%
\begin{subfigure}[t]{0.45\linewidth}
        \includegraphics[width=\linewidth]{\path figures/best_model_metrics/val_wMAPE.png}
        \caption{Test wMAPE}
\end{subfigure}
    \caption{Train and test wMAPE scores for the JHTDB problem, plotted against epoch.}
    \label{fig:deterministic_wMAPE}
\end{figure}

\end{comment}
