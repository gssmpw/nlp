\section{Related Work}
\subsection{Cluttered Objects Manipulation}
Interacting with objects in a cluttered environment is of significant importance for real-world applications \cite{6907059, 1087038, 9197318}. Prior research has extensively explored robotic manipulation in these environments, aiming to equip robots with the ability to master diverse and complex skills. For instance, \citet{9197318, 10342335} have focused on improving robust object grasping techniques, while \citet{li2024broadcasting, 10611541} investigate retrieval tasks. Additionally, studies such as \citet{goyal2022ifor, pmlr-v205-tang23a, jia2024cluttergen} address challenges in rearrangement, as well as grasping and throwing \cite{kasaei2024harnessing}. Visual-based approaches have also been widely adopted to enhance manipulation strategies in cluttered environments. For example, \citet{9591286} leverage visual prediction and planning to forecast the future states of objects after pushing actions, thereby optimizing grasping paths. In a related effort, \citet{9341545} propose a continuous pushing strategy driven by real-time visual signals to improve object graspability.

\subsection{Object Retrieval}
Retrieving a target object from complex clutter is a fundamental robotic skill with broad applications, ranging from domestic services to manufacturing. To address this challenge, various studies have proposed solutions from multiple perspectives. For instance, some works focus on planning strategies, such as object search optimization \cite{8793494}, teacher-aided exploration \cite{9341545}, and human-guided planning \cite{9196689}, while others emphasize action-based methods, including push-grasping synergy policies \cite{9465702} and learning pushing and grasping without visual foresight \cite{8794143}. Additionally, approaches like analyzing support relations among cluttered objects have shown promise for improving retrieval efficiency \cite{li2024broadcasting}. In terms of perception, researchers have explored both tactile sensing \cite{xu2024tactile, 10611541} and visual or language-based modalities \cite{lemke2024spotcompose, pmlr-v205-tang23a}. The choice of end-effector has also been a key focus, with methods employing rod-like pushers \cite{10161041}, parallel grippers \cite{9636230, pmlr-v205-tang23a, 10611541, 9812132}, and dexterous hands \cite{pmlr-v229-chen23e} to address the challenges posed by cluttered environments. Moreover, task scenarios vary widely, from granular media \cite{xu2024tactile} to confined spaces \cite{10611541}, requiring tailored approaches to accommodate environmental constraints. Our approach differs fundamentally from most previous methods by actively manipulating occluding objects to expose the target object, enabling efficient retrieval while introducing more challenging control requirements.

\begin{figure*}
    \centering
    \includegraphics[width=0.99\linewidth]{figs/method.pdf}
    % \vspace{-0.3em}
    \caption{\textbf{Illustration of the Retrieval Skill System Design.} (a) Constructs diverse cluttered scenes using a drop-from-above strategy. (b) Utilizes large-scale parallel RL with well-designed rewards to train policies. (c) Generates trajectories from the RL expert policy, selects useful ones based on our principle, and trains the distilled policy for deployment on a real robot.}
    \label{fig:method}
    % \vspace{-5pt}
\end{figure*}

\subsection{Reinforcement Learning for Dexterous Manipulation}
Dexterous manipulation has remained a cornerstone of robotics research due to its critical role in replicating the sophisticated motor skills humans use to interact with diverse objects and achieve intelligent control \cite{6907059,1087038,6907864}. While traditional methods employ analytical dynamic models for trajectory optimization
% ~\cite{chen2024springgrasp, mordatch2012contact, bai2014dexterous, kumar2014real}
, their simplified treatment of contact dynamics limits their effectiveness in complex tasks. Imitation learning (IL) has demonstrated impressive results in dexterous manipulation tasks \cite{9561802, pmlr-v205-chen23b}. However, IL faces significant challenges due to its reliance on human expert demonstrations, making it resource-intensive and difficult to scale for contact-rich tasks \cite{chen2024objectcentric, yang2024anyrotate, lin2024twisting}. In contrast, this work trains a generalizable policy using sim-to-real reinforcement learning without using any expert data. Reinforcement Learning (RL) has been widely adopted for robotic manipulation to master complex skills, particularly in unstructured and contact-rich scenarios. RL-based approaches offer two significant advantages: they simplify the controller design process and enable the acquisition of complex skills. For instance, \citet{pmlr-v164-chen22a} developed an efficient system for in-hand object re-orientation, while \citet{lin2024twisting} proposed a sim-to-real framework for twisting lids of various bottle-like objects using two hands. Similarly, \citet{pmlr-v229-huang23d} designed a system for efficient bimanual handovers, and additional studies have explored tasks such as spinning pen-like objects \cite{wang2024lessons}, sequential block building \cite{pmlr-v229-chen23e}, bimanual manipulation \cite{10343126, lin2024twisting} and diverse skills based on Vision-Language Models~\cite{liu2025vlp, sun2024large} or exploration~\cite{Bai_Zhang_Tao_Wu_Wang_Xu_2023, zhang2025beta}. On the other hand, several works \cite{zhou2022learning, pmlr-v229-agarwal23a, yang2024anyrotate, lin2024twisting} demonstrate that RL-based methods can learn emergent dexterous behaviors without additional reward terms. Our work leverages this capability to discover emergent behaviors, where carefully designed reward functions and environmental setups enable autonomous learning of retrieval skills including pushing and poking.