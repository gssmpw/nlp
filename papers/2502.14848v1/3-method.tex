\vspace{-2pt}
\section{Methodology}
\label{sec:method}
\subsection{\ours\ Framework}
As shown in Figure~\ref{fig:toolgraph}, \ours\ consists of two agents: the Task Solver and the Tool Manager, interacting with a dynamic tool graph. Its action space is defined as $\mathcal{A}_s = \{\text{RequestTool}, \text{Terminate}, \text{Code}\}$, allowing it to request tools, operate tools in code, and conclude the task. The Tool Manager assembles or modifies tools based on the Task Solverâ€™s requests, aiming to create high-quality tools. Its action space is given by $\mathcal{A}_t = \{\text{EditTool}, \text{CreateTool}, \text{ReturnTool}\}$, enabling it to edit, create, and return tools. Both agents use the GraphRank algorithm to retrieve tools from the tool graph, with basic tools provided by default.

\subsection{Tool Graph Architecture}
\label{subsec:arch}
\ours 's tool graph is a hierarchical undirected graph, represented as $\mathcal{G} = (\mathcal{V}, \mathcal{E})$, where $\mathcal{V}$ is the set of tool nodes, and $\mathcal{E}$ represents the edges denoting tool dependencies.

\paragraph{Node($\mathcal{V})$} 
The node set $\mathcal{V}$ consists of two types of tools: basic tools, pre-defined by humans, and composed tools, which are created during training. Each node $v_i \in \mathcal{V}$ stores metadata, including the tool's name, docstring, implementation code, usage frequency, and layer position $L(v_i)$. The layer position of basic tools is set to 1, as they form the foundation of the graph. For composed tools, the layer position is determined by the dependencies between the tool and other nodes, where $\text{Call}(v_j, v_i)$ indicates whether tool $v_j$ invokes tool $v_i$ in its implementation:
\begin{equation}
\text{Call}(v_j, v_i) =
\begin{cases}
1, & \text{if } v_j \text{ calls } v_i, \\
0, & \text{otherwise}.
\end{cases}    
\end{equation}
The dependencies of node $v_j$, denoted as $D(v_j) \subset \mathcal{V}$, are given by $D(v_j) = \{ v \in \mathcal{V} \mid \text{Call}(v_j, v) = 1 \}$. The layer position of $v_j$ is then computed as:
\begin{equation}
   L(v_j) = \max\limits_{v \in D(v_j)} L(v) + 1
\end{equation}
\vspace{-3pt}
\paragraph{Edge ($\mathcal{E}$)}
The edge set $\mathcal{E}$ represents the invocation relationships between tools. For any two nodes $v_i, v_j \in \mathcal{V}$, if an invocation relationship exists between them, an edge is established, which is represented through the adjacency matrix $E$. This construction of edges is crucial for capturing the functional dependencies between tools, reflecting how tools interact and depend on each other within the graph. The adjacency matrix $E = \{e_{ij}\}_{N\times N}$ is used to represent these relationships, where $e_{ij}$ is defined as:
\vskip -0.2in
\begin{equation}
    e_{ij} = e_{ji} = \text{Call}(v_i, v_j) \vee \text{Call}(v_j, v_i)
\end{equation}
% \paragraph{Agents ($\mathcal{B}$)} We employs two agents to interact with graph: Task Solver $B_s \in \mathcal{B}$ and Tool Manager $B_t \in \mathcal{B}$. Task Solver $B_s$ generates tool requests based on the task and observation space, leveraging tools created by the Tool Manager to solve problems. Its action space is defined as $\mathcal{A}_s = \{\text{RequestTool}, \text{Terminate}\} \cup \mathcal{V}$, allowing it to request tools or operate those from $\mathcal{V}$. Meanwhile, the Tool Manager $B_t$ is responsible for creating and modifying tools in response to requests. Its action space is given by $\mathcal{A}_t = \{\text{EditTool}, \text{CreateTool}, \text{ReturnTool}\}$, enabling it to edit, create, and return tools. 

% The behavior of each agent $r \in \mathcal{B}$ is modeled as a Partially Observable Markov Decision Process (POMDP), represented by the tuple $(\mathcal{O}, \mathcal{A}, \mathcal{S}, \mathcal{T}, \mathcal{R})$. Here, $\mathcal{S}$ denotes the state space, $\mathcal{A}$ the action space, and $\mathcal{O}$ the observation space. The state transition function $\mathcal{T}: \mathcal{S} \times \mathcal{A} \rightarrow P(\mathcal{S})$ models the impact of actions on the state, while the observation function $\mathcal{R}: \mathcal{S} \times \mathcal{A} \rightarrow P(\mathcal{O})$ defines how actions yield new observations.


% The behavior of each agent is modeled as a Partially Observable Markov Decision Process (POMDP), represented by the tuple $(\mathcal{O}, \mathcal{A}, \mathcal{S}, \mathcal{T}, \mathcal{R})$. Here, $\mathcal{S}$ denotes the state space, $\mathcal{A}$ the action space, and $\mathcal{O}$ the observation space. The state transition function $\mathcal{T}: \mathcal{S} \times \mathcal{A} \rightarrow P(\mathcal{S})$ models the impact of actions on the state, while the observation function $\mathcal{R}: \mathcal{S} \times \mathcal{A} \rightarrow P(\mathcal{O})$ defines how actions yield new observations.

\subsection{Tool Graph Construction}
As shown in Figure \ref{fig:toolgraph}, \ours involves an iterative collaboration between the Task Solver and the Tool Manager to construct the tool graph. The process begins with the Task Solver extracting \textbf{Tool Requirement}, followed by the Tool Manager entering the Tool Generation phase. This phase consists of three sub-stages: \textbf{Tool Creation}, creating new tools; \textbf{Tool Merging}, which identifies and merges redundant tools; and \textbf{Self-Check}, refining tool effectiveness. The tools are then provided to the Task Solver, and those used in correct solutions are incorporated to \textbf{Update the Tool Graph}.
\vspace{-5pt}
\paragraph{Tool Requirement} Given a task and the current environment, the Task Solver analyzes the situation to extract the required tool requirements and sends them to the Tool Manager. These functionalities are represented as $R = \{r_1, r_2, \dots, r_k\}$. 
% The Tool Manager iteratively processes each requirement $r_i \in R$ to create the corresponding tool $v_i^{\prime}$ to fulfill it. 
For each $r_i$, we use the GraphRank algorithm (see Section \ref{subsec:graphrank}) to retrieve the top-$k$ tools, denoted as $\mathcal{V}_{\text{retrieved}}$, which are then provided to the Tool Manager. 
If any of the $\mathcal{V}_{\text{retrieved}}$ meet the requirement, the Tool Manager directly returns the appropriate tool as $v_i^{\prime}$, minimizing redundant tool creation. Alternatively, if the retrieved tools do not fully satisfy $r_i$, the Tool Manager proceeds to the next stage to create new tools.
\vspace{-5pt}
\paragraph{Tool Creation} The Tool Manager utilizes $\mathcal{V}_{\text{retrieved}}$ to construct new tools, denoted as $\mathcal{V}_{\text{created}}$. Tool creation follows four guiding principles:
 \\
(1) \textbf{Reusability}: Tools should have generalized interfaces and clear names for easy adaptation. \\
(2) \textbf{Leveraging Existing Tools}: Prioritize using retrieved tools for efficiency and modularity. \\
(3) \textbf{Innovation}: New tools should introduce novel functionalities or enhance existing ones. \\
(4) \textbf{Completeness}: Tools must handle edge cases and exceptional inputs to ensure robustness.
\vspace{-5pt}
\paragraph{Tool Merging}
After creating new tools, we assess their potential overlap with existing tools to reduce functional redundancy and enhance the overall tool graph structure. $\mathcal{V}_{\text{created}}$ are compared with the existing tools $\mathcal{V}$ using the Smith-Waterman algorithm~\citep{smith1981identification} to measure structural similarity. The redundant tools of $v_i$ are represented as $\mathcal{R}(v_i)$. If $\mathcal{R}(v_i)$ is not empty, the Tool Manager proceeds to combine the functionalities of $v_i$ and the entire redundant tool set $\mathcal{R}(v_i)$ to generalize a new tool, replacing $v_i$.

\vspace{-5pt}
\paragraph{Self-Check} The Self-Check process evaluates the functionality and quality of created tools in two steps. First, the Tool Manager re-assesses each tool based on the four guiding principles mentioned above. Next, the Tool Manager performs a \textbf{bug-free} verification, generating a few test cases to prevent execution errors. Tools that pass both steps are sent to the Task Solver for integration, while those that fail undergo iterative refinement. The validated tools are represented by $\mathcal{V}_{\text{checked}}$, containing the tools that have passed both checks.
\vspace{-5pt}
\paragraph{Tool Graph Update}
Only correctly solved tasks are considered for updating the tool graph. The tools finally used in these correct solutions are denoted as $\mathcal{V}_{\text{used}} \subset \mathcal{V}_{\text{checked}}$. We then analyze the invocation relationships among the utilized tools, where $v_i \in \mathcal{V}_{\text{used}}$ and $v_j \in \mathcal{V}$, and update the edge set $\mathcal{E}$ and node set $\mathcal{V}$ as follows:
\begin{equation}
{\small
\mathcal{E} \leftarrow \mathcal{E} \cup  
\left\{
(v_i, v_j) \mid \text{Call}(v_i, v_j) = 1
\right\}
}
\end{equation}
\vspace{-2pt}
\begin{equation}
{\small
\mathcal{V} \leftarrow \mathcal{V} \cup \mathcal{V}_{\text{used}}
}
\end{equation}
Finally, we need to remove the corresponding redundant tools $\mathcal{R}(v_i)$ for $v_i \in \mathcal{V}_{\text{used}}$, unless they are used to create a higher-level tool.


\paragraph{Pruning} 
To optimize the tool graph, pruning is performed periodically every $C$ iterations, removing nodes with usage below a threshold $\tau_L$. This threshold is defined as $\tau_l = \lambda \times \log_{10}(C)$. Since higher-level tools tend to be used less frequently, $\lambda$ is adapted based on the tool's level: $\lambda = \frac{1}{1 + 0.8 \times \log_2(L(v_i))}$. To preserve the graph's structural integrity, a rule is enforced: \textit{if a node is non-prunable, all its child nodes are retained}.
% \subsection{Tool Graph Augmented-Agent}
% After the completion of tool graph construction in the training phase using GPT-4o, we proceed to the testing phase. For open-ended tasks, which are conducted in a lifelong learning setting without a distinct testing phase, the original training framework is reused. This allows GPT-4o to iteratively refine and expand the tool graph. In contrast, for closed-ended tasks, the constructed tool graph is tested on both open-source models and proprietary models, such as GPT-3.5-turbo. The foundational tool set $ \mathcal{V}_b $ for each task is implicitly embedded in the prompt. Prior to task initiation, the agent analyzes the task and generates a retrieval query $ q $ to retrieve the appropriate subset $ \mathcal{V}_k \subset \mathcal{V}_r $. This query is processed by the retrieval function $ \phi(q) $. To improve the agentâ€™s comprehension of high-level tools $\mathcal{V}_k$, we leverage task embeddings to retrieve the most relevant training data and tool invocation code, which are incorporated into the prompt as tool usage examples. For open-ended tasks and agent-task scenarios, we adopt a ReAct-style prompt, which facilitates the generation of Thought-Action pairs by the agent while retaining $c$ context memory windows. For single-turn code generation tasks, the agent directly generates the program to solve the problem.
\subsection{GraphRank Retrieval}
\label{subsec:graphrank}
To comprehensively capture both semantic similarity and graph structure between tools, we propose \textit{GraphRank Retrieval}, which combines vector similarity retrieval with a modified PageRank algorithm~\citep{xing2004weighted}.
The retrieval process is framed as a random walk on the tool graph, modeled as a Markov chain $\mathcal{M}$ with two key components: the prior probability distribution $p_0$ and the transition matrix $M$. We select the top-k nodes with the highest probabilities from the steady-state distribution $GR$ as the retrieval results.

Given a query and an integer $k$, we first embed the query using \textit{text-embedding-ada-002}~\citep{openai2022textembeddingada002} and compute the cosine similarity $s_i$ between its embedding and each toolâ€™s docstring embedding. These similarity scores are subsequently normalized to get $p_0$:
\begin{equation}
p_0 = \left[ \frac{s_1}{\sum s_i}, \frac{s_2}{\sum s_i}, \dots, \frac{s_N}{\sum s_i} \right] 
\end{equation}
To model the transition probability distribution from each node to others, we treat the distribution as uniform, with the transition probabilities determined by the weight matrix $E$. These probabilities are derived from the column-normalized weight matrix $M=\{m_{ij}\}_{N\times N}$ as follows: 
\begin{equation}
m_{ij} =
\begin{cases}
e_{ij} / \sum_{k=1}^{N} e_{kj} & \text{if } \sum_{k=1}^{N} e_{kj} > 0, \\
1 /N & \text{otherwise}.
\end{cases}
\end{equation}
For isolated nodes, transition probabilities to all nodes are set to $1 / N$, ensuring full participation in the Markov chain. 
Given the probability distribution $GR_{t-1}$ at time step $t-1$, the probability distribution $GR_t$ can be expressed as:
\begin{equation}
    GR_t = (1 - d)p_0 + d \cdot {M}^T GR_{t-1}
\end{equation}
$GR$ satisfies the equation:
\vskip -0.1in
\begin{equation}
GR = (1 - d)p_0 + d \cdot {M}^T GR.
\end{equation}
Here, $d \in [0, 1]$ is a damping factor that balances the influence of the prior distribution and the graph structure. In our implementation, we set $d=0.4$. We directly solve the steady-state equation as a linear system to obtain the solution $GR = (I - d \cdot M^T)^{-1}(1-d)p_0$. The top-$k$ nodes with the highest probabilities in $GR$ are subsequently selected as the retrieved tools.

