% This must be in the first 5 lines to tell arXiv to use pdfLaTeX, which is strongly recommended.
\pdfoutput=1
% In particular, the hyperref package requires pdfLaTeX in order to break URLs across lines.

\documentclass[11pt]{article}

% Change "review" to "final" to generate the final (sometimes called camera-ready) version.
% Change to "preprint" to generate a non-anonymous version with page numbers.
\usepackage[final]{acl}

% Standard package includes
\usepackage{times}
\usepackage{latexsym}
\usepackage{comment}

% For proper rendering and hyphenation of words containing Latin characters (including in bib files)
\usepackage[T1]{fontenc}
% For Vietnamese characters
% \usepackage[T5]{fontenc}
% See https://www.latex-project.org/help/documentation/encguide.pdf for other character sets

% This assumes your files are encoded as UTF8
\usepackage[utf8]{inputenc}

% This is not strictly necessary, and may be commented out,
% but it will improve the layout of the manuscript,
% and will typically save some space.
\usepackage{microtype}

% This is also not strictly necessary, and may be commented out.
% However, it will improve the aesthetics of text in
% the typewriter font.
\usepackage{inconsolata}

%Including images in your LaTeX document requires adding
%additional package(s)
\usepackage{graphicx}
\usepackage{booktabs}
\usepackage{multirow}
\usepackage{xcolor}
\usepackage{hyperref}
\usepackage{amsmath}
\usepackage{mathtools}
\usepackage{makecell}
\usepackage{ltablex}
\usepackage{longtable}
\usepackage{supertabular,booktabs}
\usepackage{xltabular}
\usepackage{tikz}
\usepackage{pgfplots}
\usetikzlibrary{patterns}
\usepackage{xspace}
%\usepackage{numprint}
%\npdecimalsign{.}
\usepackage{booktabs,siunitx}
\usepackage{pgf-pie}

\sisetup{
  table-auto-round = true, % Round numbers in S-columns
  % detect-weight=true,
  detect-all = true,
  % detect-inline-weight=math
}

% If the title and author information does not fit in the area allocated, uncomment the following
%
%\setlength\titlebox{<dim>}
%
% and set <dim> to something 5cm or larger.

% \title{Faithful, Unfaithful or just Ambiguous? Multi-agent Summary Evaluation through Debate with Initial Stance}
% Faithful or not? Depends! Identifying ambiguity by taking a stance in multi agent debate
% \title{Improved Faithfulness Evaluation by Identifying Ambiguity and Taking a Stance in Multi-Agent Debate }
\title{Faithful, Unfaithful or Ambiguous? Multi-Agent Debate with Initial Stance for Summary Evaluation}
% Multi-agent Summary Evaluation through Debate with Initial Stance
% Multi-agent Debate with Initial Stance for Summary Evaluation
% \title{MADDISSE: Multi-Agent Debate with Initial Stance fro Summary Evaluation}

% Author information can be set in various styles:
% For several authors from the same institution:
% \author{Author 1 \and ... \and Author n \\
%         Address line \\ ... \\ Address line}
% if the names do not fit well on one line use
%         Author 1 \\ {\bf Author 2} \\ ... \\ {\bf Author n} \\
% For authors from different institutions:
% \author{Author 1 \\ Address line \\  ... \\ Address line
%         \And  ... \And
%         Author n \\ Address line \\ ... \\ Address line}
% To start a separate ``row'' of authors use \AND, as in
% \author{Author 1 \\ Address line \\  ... \\ Address line
%         \AND
%         Author 2 \\ Address line \\ ... \\ Address line \And
%         Author 3 \\ Address line \\ ... \\ Address line}

% \author{First Author \\
%   Affiliation / Address line 1 \\
%   Affiliation / Address line 2 \\
%   Affiliation / Address line 3 \\
%   \texttt{email@domain} \\\And
%   Second Author \\
%   Affiliation / Address line 1 \\
%   Affiliation / Address line 2 \\
%   Affiliation / Address line 3 \\
%   \texttt{email@domain} \\}

\author{
 \textbf{Mahnaz Koupaee\textsuperscript{1}\thanks{Work done as an intern at Amazon.}},
 \textbf{Jake W. Vincent\textsuperscript{2}},
 \textbf{Saab Mansour\textsuperscript{2}},
 \textbf{Igor Shalyminov\textsuperscript{2}},
\\
 \textbf{Han He\textsuperscript{2}},
 \textbf{Hwanjun Song\textsuperscript{3}},
 \textbf{Raphael Shu\textsuperscript{2}},
 \textbf{Jianfeng He \textsuperscript{2}},
\\
 \textbf{Yi Nian\textsuperscript{2}},
 \textbf{Amy Wing-mei Wong\textsuperscript{2}},
 \textbf{Kyu J. Han\textsuperscript{2}},
 \textbf{Hang Su\textsuperscript{2}},
\\
%  \textbf{Thirteenth Author\textsuperscript{3}},
%  \textbf{Fourteenth F. Author\textsuperscript{2,4}},
%  \textbf{Fifteenth Author\textsuperscript{1}},
%  \textbf{Sixteenth Author\textsuperscript{1}},
% \\
%  \textbf{Seventeenth S. Author\textsuperscript{4,5}},
%  \textbf{Eighteenth Author\textsuperscript{3,4}},
%  \textbf{Nineteenth N. Author\textsuperscript{2,5}},
%  \textbf{Twentieth Author\textsuperscript{1}}
% \\
\\
 \textsuperscript{1}Stony Brook University,
 \textsuperscript{2}Amazon,
 \textsuperscript{3}Korea Advanced Institute of Science and Technology
 % \textsuperscript{4}Affiliation 4,
 % \textsuperscript{5}Affiliation 5
\\
 \texttt{
   % \textbf{Correspondence:} 
   % \href{mailto:mkoupaee@cs.stonybrook.edu}
   mkoupaee@cs.stonybrook.edu
 }
}

\newcommand{\mk}[1]{\textcolor{violet}{$_{Mahnaz}${[#1]}}}
\newcommand{\hs}[1]{\textcolor{teal}{$_{Hang}${[#1]}}}
\newcommand{\sm}[1]{\textcolor{cyan}{$_{Saab}${[#1]}}}
\newcommand{\is}[1]{\textcolor{magenta}{$_{Igor}${[#1]}}}
\newcommand{\hh}[1]{\textcolor{gray}{$_{Han}${[#1]}}}
\newcommand{\jv}[1]{\textcolor{brown}{$_{Jake}${[#1]}}}
\newcommand{\rs}[1]{\textcolor{purple}{$_{Raphael}${[#1]}}}

\newcommand{\method}[0]{\textsc{Madisse}\xspace}

\begin{document}
\maketitle
\begin{abstract}
Faithfulness evaluators based on large language models (LLMs) are often fooled by the fluency of the text and struggle with identifying errors in the summaries. %, usually leading to high false negative rate.
We propose an approach to summary faithfulness evaluation in which multiple LLM-based agents are assigned initial stances (regardless of what their belief might be) and forced to come up with a reason to justify the imposed belief, thus engaging in a multi-round debate to reach an agreement. The uniformly distributed initial assignments result in a greater diversity of stances leading to more meaningful debates and ultimately more errors identified.
Furthermore, by analyzing the recent faithfulness evaluation datasets, we observe that naturally, it is not always the case for a summary to be either faithful to the source document or not. We therefore introduce a new dimension, \textbf{\textit{ambiguity}}, and a detailed taxonomy to identify such special cases. Experiments demonstrate our approach can help identify ambiguities, and have even a stronger performance on non-ambiguous summaries\footnote{Code and data available at \href{https://github.com/amazon-science/madisse}{github.com/amazon-science/madisse}}.

%({\sc TofuEval}, {\sc LLM-AggreFact})
% LLM-based faithfulness evaluators are often fooled by the fluency of the text and struggle with identifying errors in the summaries, usually leading to high false negative rate.
%\is{We propose an approach to summary faithfulness evaluation in which multiple LLM-based agents are assigned initial stances (regardless of what their belief might be) and forced to come up with a reason to justify the imposed belief, thus engaging in a multi-round debate to reach an agreement. The uniformly distributed initial assignments here result in a greater diversity of stances leading to more meaningful debates and ultimately more errors identified.}
% We propose an approach in which multiple LLM-based agents are assigned initial stances (regardless of what their belief might be) and forced to come up with a reason to justify the imposed belief. 
% Then they engage in a multi-round debate to reach an agreement. 

%\is{Furthermore, by analyzing the recent faithfulness evaluation datasets ({\sc TofuEval}, {\sc LLM-AggreFact}), we observe that naturally, it is not always the case for a summary to be either unambiguously faithful to the source document or not.}
% However, we can only expect full agreement if we assume that the faithfulness of a summary \textsc{always} has a right answer and should be either categorized as faithful or unfaithful which might not be the case.
%A summary is ambiguous if it can be correctly interpreted in different ways and then can be seen as both faithful and unfaithful depending on the interpretation. In the setting of multiple raters, that leads to low inter-annotator agreement (IAA) and potentially erroneous conclusions regarding the system performance and ranking. We therefore introduce a new dimension \textbf{\textit{ambiguity}} and a detailed taxonomy to identify such special cases. 
%Our experiments demonstrate the following: first, how the debate approach can help with identifying more errors compared to the existing approaches; second, how the arguments generated in the debate can help with identifying ambiguous cases; and finally, how the debate approach can have even a stronger performance on non-ambiguous summaries.

% SM abstract:
% \sm{Faithfulness evaluation of abstractive summaries is traditionally constrained to the binary judgement of faithful or not faithful. This binary categorization fails to account for instances where ambiguity arises and the final judgment depends on underlying assumptions. The limited binary approach contributes to low inter-annotator agreement (IAA), leading to potentially erroneous conclusions regarding system performance and ranking. In this paper, we propose a novel approach to faithfulness evaluation by introducing an additional "ambiguous" category, accompanied by a detailed taxonomy of ambiguity types. To identify ambiguous cases, we employ a multi-agent debate framework, where agents are initialized with a stance. Our findings demonstrate that initializing agents with a stance not only improves the detection of ambiguous cases but also enhances the correlation between agents and human judgments. This approach offers a finer grained and more accurate method for evaluating faithfulness, leading to more reliable assessments of summarization systems.}

% \textbf{VERSION 1:}
% With the recent progress of LLMs, automatic summary evaluation using LLMs has gained a lot of attention to replace the costly human labor. However, they are far from perfect, struggling with capturing the subtle nuances of the LLM-generated summaries, often being fooled by the fluency of the text and therefore missing on a large proportion of existing errors.
% We propose a LLM-based multi-agent setup in which agents will engage in a debate based on their randomly assigned initial stance on the faithfulness of the summary, and try to convince each other. The initialization forces the agents to think out-of-box and deeper to identify aspects that would go unnoticed otherwise.  
% By inspecting the arguments from the debate approach, we observed the faithfulness should not be seen as a binary classification task and therefore we introduce a third dimension \textbf{\textit{ambiguity}} with a detailed taxonomy to account for cases where there are sound arguments for both faithfulness and unfaithfulness depending on how one would interpret the summary.
% We show that not only the debate approach can help identify more errors and the judgments to be better aligned with human annotations but also further show how the debate arguments can help identifying ambiguous cases. 

% \textbf{VERSION 2:} 
% Faithfulness evaluation of abstractive summaries is usually done by assessing whether a sentence is faithful or not but ignoring the fact the a summary sentence can be \textit{correctly} interpreted in different ways given the context and therefore can be evaluated as both faithful or unfaithful depending on the underlying assumptions.
% We therefore introduce a new dimension \textbf{\textit{ambiguity}} along with a detailed taxonomy of potential ambiguity types to account for cases which can have contrastive faithfulness labels depending on how one would interpret the summary. 
% We also propose a LLM-based multi-agent debate setup in which evaluator agents with random initial stance on the faithfulness of the summary engage in a multiple rounds of debate, trying to convince each other. 
% Our experiments show that not only can the proposed framework improve the overall performance of LLM-based evaluators, but also the final arguments by the evaluator agents can help identify the ambiguous cases.

\end{abstract}

\input{sec_1_intro}
\input{sec_2_related}
\input{sec_3_method}
\input{sec_4_ambiguity}
\input{sec_5_experiments}
\input{sec_6_evaluation}
\input{sec_7_conclusion}
\input{sec_8_limitations}

\bibliography{custom,anthology}
\clearpage
\newpage
\appendix
\input{sec_appendix}
\end{document}


% Multi-Agent Debate with Initial Stance
% MADIS

% Multi-Agent Debate with initial stance and AMbiguity detection
% MADAM

% Multi-Agent Debate with Initial Stance and Abiguity detectioN
% MADISON