% \section{Faithfulness Evaluation through Multi-agent Debate}
\section{\method}
% One of the key dimensions to assess the quality of the summarization systems is \textit{faithfulness} which measures whether the facts specified in the summary can be attributed to the source document. Faithfulness is highly correlated with the term \textit{hallucination} such that in order to maximize faithfulness, one has to minimize hallucination. 
% There is also a clear distinction between \textit{faithfulness} and \textit{factuality}, in a sense that a summary can be factual but not faithful if its facts can be entailed by world knowledge. However, in this work, we focus on faithfulness as defined above and consider summaries to be faithful if only they can be entailed from the source document.  

\textit{Faithfulness} as a key evaluation dimension of summarization systems, measures whether the facts specified in the summary can be attributed to the source document. 
% and is often used interchangeably with the \textit{factuality}. However, faithfulness differs from factuality in a sense that a summary can be factual but not faithful if its facts can be entailed by world knowledge.
We focus on faithfulness as described above and consider summaries to be faithful if only they can be entailed from the source document\footnote{\textit{faithfulness} is different from \textit{factuality} as for factuality, it is enough for a summary to be attributed to the world knowledge~\cite{maynez-etal-2020-faithfulness}.}.
% 
Formally, we define an evaluation model $M$ to predict whether the summary $s$ can be entailed from the source document $D$.
\[M(D, s) \in \{\text{faithful, unfaithful}\}\]
The overview of \method can be seen in Figure \ref{fig:overview}. Each \method session consists of three main stages: initialization, debate and adjudication.
\begin{figure*}
    \centering
    \includegraphics[width=1\linewidth]{figs/overview_wo_ambiguity.jpg}
    \vspace*{-0.7cm}
    \caption{Overview of \method, our proposed framework for automatic faithfulness evaluation. Each debate session consists of three stages: 1) \textit{stance initialization}, in which agents are assigned a belief of the summary faithfulness (faithful or unfaithful), 2) \textit{debate}, where evaluator agents engage in multiple rounds of debate to persuade each other of whether the summary is faithful or not, and 3) \textit{adjudication}, where based on the arguments from the debate, the final label is assigned to the summary. \method can have simultaneous debate sessions.}
    \label{fig:overview}
    \vspace*{-0.2cm}
\end{figure*}


In the initialization stage, a pool of evaluator agents $\mathcal{A}$ are assigned a random stance on whether they believe the summary is faithful or not. 
In the second stage, the agents engage in a debate for $n$ rounds and each agent $A_i \in \mathcal{A}$ provides arguments $U^j_i$ at each round $j$ which consists of an explanation and a label for the summary: $U^j_i = (e^j_i, l^j_i)$ where $e^j_i$ is the explanation to justify the decision and $l^j_i$ is the faithfulness label assigned to the summary at round $j$ for the $i$-th agent $A_i$. If at any round $j$, {\em all} agents agree on the final label, the debate will be stopped and the final label of the summary is determined.
If agents do not reach an agreement after $n$ rounds, the debate will stop and then the final label is determined by adjudication. Adjudicators $J_1, ..., J_k \in \mathcal{J}$ are judges responsible for checking every agent’s arguments $U_i$ and making the final call. 

In the following sections, we will detail each component of \method, describing their responsibilities and goals and how they achieve them. 

\subsection{Initialization}
A debate would be more engaging if the involved parties have conflicting overviews on the topic as they are encouraged to think deeper to come up with better arguments for their beliefs. 
This is also the case for faithfulness evaluation where arguing for conflicting opinions on faithfulness can lead to deeper understanding of the semantics of the summary and even better judgment of the faithfulness. 

One way to inject the desired diversity is to assign the evaluator agents an initial stance: $A_i \leftarrow{f_0}$. More specifically, $f_0$ will be the first argument $U^0_i$ for each agent $A_i$ which they believe is their assessment of the summary. These initial arguments will be part of the chat history for the debate stage (the initial evaluator agent prompt is shown in Table \ref{tab:debate_prompt_first_round} in Appendix \ref{app:prompts}).

% One major issue with existing summarization evaluators is that in a lot of cases, they fail to identify errors that exist in the summaries. 
% To encourage agents to dig deeper into the summary and think more critically and start a more vibrant debate, 
We assign initial stances such that half of the evaluator agents start the debate by believing the summary is faithful and the other half believing the summary is unfaithful (uniform distribution of stances). Therefore, $U^0_i$ can be one of the two: \{\textit{The summary is faithful, The summary is unfaithful}\}. 
% On one hand, having some agents start with disbelief regarding the faithfulness of the summary would force agents to dig deeper into the summary and identify any inconsistency, leading to identifying more errors. On the other hand, the injected opposition would provide enough diversity and would make the debate more engaging leading to more accurate faithfulness detection.
% By assigning random initial stances to the evaluator agents, we make sure that we have enough initial diversity to start the debate with. 
We later show how effective this initialization is in detecting cases that would go unnoticed otherwise.
It can also help with ambiguity detection later discussed in Section \ref{sec:ambiguity})

\subsection{Multi-Round Debate}
During each debate stage, each LLM-based evaluator agent $A_i \in \mathcal{A}$ would go over the document $D$ and the summary $s$ and look for potential inconsistencies that might be present in the summary. Each agent is also aware of the existence of other agents and they are encouraged to continue the debate with each other, specify why other agents might be right or wrong and also ask some follow-up or clarification questions. 
At each round $j$, each agent $A_i$ has access to the previous chat history and what other agents argued for. Then it generates a new argument $U^j_i$ for the current round providing a faithfulness label and why it believes the label is justified (the evaluator prompt is shown in the Appendix \ref{app:prompts} Table \ref{tab:debate_prompt}~\footnote{Note that the evaluator prompt in Table~\ref{tab:debate_prompt} is similar to the initial evaluator prompt in Table~\ref{tab:debate_prompt_first_round} except for the chat history part which is dynamic and excludes the initial imposed stances.}). This argument will be added to the chat history for the next rounds. 
Also, to remove any ordering biases, we shuffle the arguments from each round before showing the chat history to the agents for subsequent debate rounds. 

The debate stage has two main properties: guidelines and stopping criterion.
The first property borrows ideas from collaborative human workflows in which we design guidelines/rules that agents can use and refer to during the debate and making their arguments, which would help with having a more structured debate for easier reference. The stopping criterion is also required to make sure the debate will conclude and the summary is evaluated. These two properties are described in more detail in the Appendix \ref{app:guidelines} and \ref{app:stop}.
% 
The benefits of the debate stage are two-fold. 
Not only does the debate setup provide an opportunity of collaboration among different evaluator agents towards the correct decision, it also helps with resolving inconsistencies that might occur due to stance initialization stage.

\subsection{Adjudication}

Even after rounds of debate, the evaluator agents might still disagree. However, the debate can only go on for $n$ rounds. Once the debate is over, the adjudicator module consisting of $k$ adjudicator agents $J_1, ..., J_k \in \mathcal{J}$ receives all the final arguments $U^n_i$ from the evaluator agents $\mathcal{A}$, goes over them and makes sure they are well aligned with the provided guidelines. 
Then based on the agents’ responses as well as its own judgment, the adjudicator makes the final call on the summary by providing a label as well as an explanation (the adjudicator prompt is shown in Appendix \ref{app:prompts}, Table~\ref{tab:adjudicator_prompt}). To make sure that the adjudication is not biased towards the agents’ arguments order, we use multiple adjudicators each time with a different random order and then finally do a majority voting to get the final response $U^n_k = (e^n_k, l^n_k)$ (the explanation $e^n_k$ is selected randomly from the majority vote responses).

\subsection{Simultaneous Debate Sessions}\label{app:method}
A debate among agents with adjudicators to help with final decision can result in two major type of errors; adjudicator mistake and wrong answer propagation \cite{wang2024rethinking}. The first one happens when adjudicators select the wrong option as the final response specially in cases where there are conflicting views among evaluator agents. The second error happens when some agents will be influenced by other agents and deviate from their correct initial assessments. 
To alleviate this, \method can start with $m$ separate simultaneous debate sessions ($m$ sessions similar to the session shown in Figure \ref{fig:overview}), each with the same number of agents. The sessions will continue independently to reach a final label. Once all sessions are over, the final label can be generated by aggregation over the responses from different sessions.
Having multiple independent debate sessions can help with the overall performance as any error in assessing the summary in one of the sessions will not be propagated to other sessions.
% 
The aggregation can be done in two ways: \emph{debate vote} -- the majority vote over labels assigned in debates. Each debate session concludes with a label as described in the single debate setting.
The majority vote over these values is the final faithfulness label -- and \emph{agent vote} -- the majority vote over all participating agents in all debates. Regardless of the session to which agents belong, their individual responses are aggregated (with a majority vote) and reported as the final label.

This setup can be seen as having more evaluator agents to perform the same task, except that since sessions are independent, if there is an error propagation in one of the sessions, it will only affect the output of that session which would hopefully not affect the final aggregated response.
Also, having more agents can increase the context size (specially in the final rounds) which might not be feasible given the context size limits of some LLMs.
% 
