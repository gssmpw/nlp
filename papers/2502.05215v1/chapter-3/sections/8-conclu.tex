
\section{Conclusion}\label{chap3/sec:conclusion}

By a quick fine-tuning of the decoder of Latent Diffusion Models, we can embed watermarks in all the images they generate.
This does not alter the diffusion process, making it compatible with most of LDM-based generative models.
These watermarks are robust, invisible to the human eye and can be employed to \emph{detect} generated images and \emph{identify} the user that generated it, with very high performance.
The public release of image generative models has an important societal impact.
With this work, we put to light the usefulness of using watermarking instead of relying on passive detection methods.
We hope it encourages researchers and practitioners to employ similar approaches before making their models publicly available.

The biggest drawback from the method is its intrusive nature.
It requires substantial effort in re-evaluating model image quality and increases implementation cost (because it needs to modify multiple production models instead of maintaining a single encoding model as production use-cases grow).
Embedding the watermark task within the generation process is also not conducive to industry standardization and may limit certain ``data sharing'' opportunities.
Therefore, in cases where the model is not expected to be publicly released, or where the model is expected to be used in a wide range of applications, the watermarking method may not be suitable. 
A post-hoc watermarking method may be preferred, as it is more flexible and can be applied to any model without any modification.
This is the approach we take in Chap.~\ref{chapter:audioseal} for audio watermarking.


