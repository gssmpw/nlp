

\section{Problem statement and background}

\autoref{chap3/fig:fig1} shows a model provider \emph{Alice} who deploys a latent diffusion model to users \emph{Bobs}.
Stable Signature embeds a binary signature into the generated images. 
This section derives how Alice can use this signature for two scenarios:
\begin{itemize}
    \item 
    \emph{Detection: ``Is it generated by my model?''.} 
    Alice detects if an image was generated by her model.
    Generated images should be flagged as reliably as possible, while controlling the probability of flagging a natural image. 
    \item 
    \emph{Identification: ``Who generated this image?''.} 
    Alice monitors who created each image, while avoiding to mistakenly identifying a Bob. %
\end{itemize}

\subsection{Image watermarking for detection}
Alice embeds a $k$-bit binary signature into the generated images.
The watermark extractor then decodes messages from the images it receives and detects when the message is close to Alice's signature.
An example application is to block AI-generated images on a content sharing platform. 


\paragraph{Statistical test.}\label{chap3/subsec:statistical-test}
Let $m\in \{ 0,1 \}^{k}$ be Alice's signature. 
We extract the message $m'$ from an image $x$ and compare it to $m$.
As done in previous works~\citep{lin2022cycleganwm, yu2021artificial},
the detection test relies on the number of matching bits $M(m,m')$: if
\begin{equation} 
M\left(m,m'\right) \geq \tau \,\,\textrm{ where }\,\, \tau\in \{0,\ldots,k\},
\label{chap3/eq:detectiontest}
\end{equation}
then the image is flagged.
This provides a level of robustness to imperfections of the watermarking. 
This is a typical use case of the binomial test presented in Sec.~\ref{chap0/sec:test}.

Formally, we test the statistical hypothesis $\H_1$: ``$x$ was generated by Alice's model'' 
against the null hypothesis $\H_0$: ``$x$ was not generated by Alice's model''.
Under $\H_0$ (\ie, for vanilla images), we assume that bits $m'_1,\ldots, m'_k$ are (i.i.d.) Bernoulli random variables with parameter $0.5$.
Then $M(m, m')$ follows a binomial distribution with parameters ($k$, $0.5$).
We verify this assumption experimentally in Sec.~\ref{chap3/app:assumption}.
The False Positive Rate (FPR) is the probability that $M(m, m')$ takes a value bigger than the threshold $\tau$.
It is obtained from the c.d.f. of the binomial distribution, and a closed-form can be written with the regularized incomplete beta function $I_x(a;b)$ (more in~Sec.~\ref{chap0/sec:test}):
\begin{align}\label{chap3/eq:p-value}
    \text{FPR}(\tau) & = \mathbb{P}\left(M \geq \tau \mid \H_0\right) = I_{1/2}(\tau, k - \tau +1).
\end{align}


\subsection{Image watermarking for identification}
Alice now embeds a signature $m^{(i)}$ drawn randomly from $\{0,1\}^k$ into %
the model distributed to
Bob$^{(i)}$ (for $i=1\cdots N$, with $N$ the number of Bobs).
Alice can trace any misuse of her model: generated images violating her policy (gore content, deepfakes) are linked back to the specific Bob by comparing the extracted message to Bobs' signatures.

\paragraph{Statistical test.}\label{chap3/subsec:statistical-test-identification}
We compare the message $m'$ from the watermark extractor to  $m^{(1)}$, $\dots$, $m^{(N)}$. 
There are now $N$ detection hypotheses to test.
If the $N$ hypotheses are rejected, we conclude that the image was not generated by any of the models.
Otherwise, we attribute the image to $\textrm{argmax}_{i=1..N} M\left(m', m^{(i)}\right)$.
With regards to the detection task, false positives are more likely since there are $N$ tests. 
The global FPR at a given threshold $\tau$ is:
\begin{equation}\label{chap3/eq:globalFPR}
    \text{FPR}(\tau,N) = 1-(1-\text{FPR}(\tau))^N\approx N.\text{FPR}(\tau).
\end{equation}

Equation~\eqref{chap3/eq:globalFPR} (resp.~\eqref{chap3/eq:p-value}), is used reversely: we find threshold $\tau$ to achieve a required FPR for identification (resp.~detection). 
Note that these formulae hold only under the assumption of i.i.d. Bernoulli bits extracted from vanilla images. 
This condition is enforced in the next section. 
