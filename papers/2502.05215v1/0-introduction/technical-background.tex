
\chapter{Technical Background}
\label{chapter:technical-background}

This section first exposes key properties and definitions which will be helpful for the rest of the thesis.
It then presents the most common deep learning based watermarking techniques for images, audio and LLM-generated text.




\section{Properties and definitions}\label{chap0/sec:properties}



\subsection{Watermarking as a communication system}

\begin{figure}[b]
    \centering
    \includegraphics[width=0.9\textwidth]{0-introduction/figs/watermarking-minimal.pdf}
    \caption{
        Schema of a watermarking system. 
        The embedder hides a message in a host content called cover (image, audio, etc.). 
        The host is then transmitted through a noisy channel.
        The extractor retrieves the message from the noised host.
    }\label{intro/fig:schema}
\end{figure}

Watermarking involves embedding a hidden message or signal (called watermark) into a \textit{\gls*{cover}} medium (\eg, image, audio, model's weights) without significantly altering its perceived quality. 
The process can be understood as a communication system~\citep{cover1999elements} where the cover serves as channel (see Fig.~\ref{intro/fig:schema}).
It is divided into two main stages:
The \emph{embedding} takes the original cover medium and the message as inputs and generates a watermarked version of the cover medium. 
The \emph{extraction} receives the host medium and attempts to detect and/or extract the embedded watermark. 
The extractor should be able to recover the original watermark with high accuracy, even if the host has undergone various transformations or attacks.
As a disclaimer, this is a simplified view and many variations exist depending on the application and the desired properties of the watermarking system.



\subsection{Zero-bit, multi-bit}

Watermarking techniques are broadly classified into two categories.
\begin{itemize}
    \item 
    (1) In \emph{\gls*{multi-bit watermarking}},
        the watermark is a binary message (a sequence of bits) that is embedded in the cover medium.
        The goal is to \emph{extract the embedded message} from the host medium.
        Multi-bit watermarking is used in applications where the watermark is intended to carry meaningful information that can be extracted and decoded by authorized parties, such as who owns the content.
    \item
    (2) In \emph{\gls*{zero-bit watermarking}}, 
        the watermark is not a message but a unique identifier or signature that is embedded in the cover medium. 
        The goal is to \emph{detect the presence} of the watermark in the host medium.
        Zero-bit watermarking is often used in applications where the watermark is not intended to convey any additional information but to provide a means of verifying the origin or integrity of the content.
\end{itemize}

A multi-bit watermarking system can be converted into a zero-bit system by embedding a unique binary message in the cover medium. 
The detection is then performed by comparing the extracted message with the expected one and performing a binomial test on the number of correct bits (see \hyperref[chap0/sec:test]{\nameref*{chap0/sec:test}}).



\subsection{Three (plus one) criteria}

\begin{figure}[b]
    \centering
    \includegraphics[width=0.37\linewidth, clip, trim=3cm 0.5cm 4cm 0cm]{0-introduction/figs/axes.pdf}
    \caption{
        Watermarking must meet three criteria: imperceptibility, payload, and robustness.
        We can also add security, which is related to robustness but considers intentional attacks.
    }
    \label{intro/fig:criteria}
\end{figure}

Watermarking methods should meet three intertwined criteria, often represented by a triangle as in Fig.~\ref{intro/fig:criteria}:
\begin{itemize}
    \item \emph{\Gls*{robustness}}: 
    The ability of the watermark to withstand various transformations on the host without being significantly degraded or removed. 
    For example, the watermark on an image should be retrieved even after it has been compressed (JPEG, WebP), cropped, resized, etc.
    \item \emph{\Gls*{payload}}: 
    The amount of information that can be embedded into the cover. 
    For multi-bit watermarking, the payload is typically measured in bits, while for zero-bit watermarking, it is linked to the \pval\ of the detection test.
    \item \emph{Imperceptibility}: 
    The degree to which the embedded watermark remains undetectable to human perception\footnote{
        In the context of deep neural networks (DNN) watermarking, the imperceptibility is sometimes renamed \emph{unobtrusiveness}, \ie, the capacity to embed without affecting the performance of the model.
        For instance, \citet{tondi2024robust} show that unobtrusiveness is weakly linked to the other requirements, unless an additional constraint regarding the secrecy of the watermark is considered.
        }.
    For example, in an audio watermarking system, the watermark should introduce the least amount of distortion to the audio signal so that it is not audible to the human ear.
\end{itemize}
These properties are interdependent, and enhancing one property may impact others. 
Very often, decreasing the imperceptibility of a watermark (increasing its strength) will increase its robustness and payload.
Some researchers would join robustness and payload as one single criterion, and add a fourth one:
\begin{itemize}
    \item \emph{\Gls*{security}}: 
    The level of protection against intentional attacks, such as unauthorized removal, embedding, modification, or detection of the watermark.
    A secure watermarking system might use cryptographic techniques to encode the watermark so that it can only be extracted by parties possessing the correct decryption key. 
    However, it is important to note that cryptographic tools alone are often not sufficient to guarantee the security of the watermark, as shown in media watermarking.
\end{itemize}


\subsection{Other considerations}\label{chap0/sec:other-considerations}
Although the literature often focuses on the above criteria, there are several other considerations that can impact the design and implementation of a watermarking system.

\paragraph*{Speed.}
The computational cost of the watermark embedding and extraction is often left aside while of utmost importance in many applications.
Notably, for content tracing at the scale of social networks, the detection of the watermark should be able to process thousands if not millions pieces of content per second.

\paragraph*{Blindness.}
A blind watermarking system is one in which the extractor only requires access to the host medium in order to extract the watermark.
In contrast, non-blind watermarking also requires access to the original cover medium in order to extract the watermark. 
This can enhance the accuracy of the watermark extraction but at the cost of needing to securely store and retrieve the original content.
Most of the methods presented in this thesis are blind, except for the one presented in \autoref{chapter:invariants}.

\paragraph*{Private vs. public.}
Private watermarking restricts the extraction and detection of the watermark to authorized parties who possess specific tools or keys.
This is useful for ensuring that only intended recipients can embed and retrieve the information. 
Private watermarking is often more secure than public watermarking because it relies on a secret key.
In the context of deep learning based watermarking (see Sec.~\ref{chap0/sec:deep learning-watermarking}), the extractor weights can be seen as the secret key, making it private.

In contrast, a public watermarking system is one in which the watermark can be extracted by anyone who has access to the host medium. 
This would be the ideal scenario for detection of AI-generated content, as it would allow anyone to verify the origin of the content.
However, public watermarking methods that are secure and robust to attacks are very scarce.

\paragraph*{Fragile.}
A fragile watermarking system is one in which the watermark is destroyed as soon as the watermarked content is modified or tampered with.
Fragile watermarking is often used for integrity verification and tamper detection, as it provides a way to detect whether an image or audio has been altered.
Robust watermarks, as previously discussed, are on the contrary intended to withstand various types of processing and attacks without being removed or degraded.
In this thesis, we only consider robust watermarking.

\paragraph*{Reversibility.}
A reversible watermarking system is one in which the original medium can be recovered from the host medium. 
This means that the watermark can be removed from the host medium, leaving the original cover medium intact. 
Reversible watermarking is often used in applications where it is important to preserve the original cover medium, such as in medical imaging or forensic analysis.



\subsection{Detection and statistical hypothesis testing}\label{chap0/sec:test}

The detection of the watermark in a zero-bit setup is often formulated as a statistical hypothesis testing problem.
We hereby provide a brief overview of the key concepts and definitions related to hypothesis testing (FPR, TPR, \pval, etc.).

\paragraph*{Detection test.}
The \emph{null hypothesis} $\H_0$ is that the host medium does not contain the watermark, while the \emph{alternative hypothesis} $\H_1$ is that the watermark is present.
The detection test outputs a \emph{\gls*{test statistic}} (or watermark score), which is then compared to a threshold $\tau$ to decide whether to accept or reject $\H_0$.

\paragraph*{Evaluation metrics.}
The global detection performance of a watermarking system is evaluated based on the \emph{False Positive Rate} (\Gls*{FPR}) -- or type I error -- and the \emph{True Positive Rate} (\Gls*{TPR}) -- inversely proportional to the type II error -- of the detection test.
The FPR is the probability of falsely detecting the watermark when it is not present, while the TPR is the probability of correctly detecting the watermark when it is present.

There is a trade-off between the FPR and TPR, which is controlled by the threshold $\tau$. 
Large-scale applications usually operate at very low FPR to avoid human verification.
For example, at the scale of Facebook, where billions of images are uploaded every day, a FPR of $10^{-3}$ would result in millions of false detections per day, which is unacceptable.
The \emph{Receiver Operating Characteristic (\Gls*{ROC}) curve} is a graphical representation of the trade-off between the FPR and TPR, and is obtained by varying the threshold $\tau$.

\paragraph*{\pval, significance level and FPR.}
Given a test statistic, the \emph{\gls*{p-value}} is the probability of observing under $\H_0$ a test statistic as extreme as the one observed.
The \emph{significance level} $\alpha$ is the threshold for the \pval\ below which $\H_0$ is rejected -- it is therefore also the probability of falsely rejecting $\H_0$, \ie, the FPR.
\begin{itemize}
    \item The \pval\ converts the watermark score associated to a piece of content into an interpretable quantity: the probability of non-watermarked content to have a watermark score as extreme as the one observed.
    It can also be interpreted as the FPR we would need to flag this content as watermarked.
    \item The \pval\ is a local notion and concerns a specific piece of content, while the FPR is a global notion and concerns the detector.
    For instance, if the \pval\ is $10^{-6}$, we would flag this content while wrongly flagging a non-watermarked content only once every million times.
\end{itemize}

\paragraph*{Example: Binomial test.}
Let us consider a scenario where the test statistic under the null hypothesis $\H_0$ follows a binomial distribution. This is a common assumption when the watermark detection mechanism is based on counting a number of mismatches that occur randomly, which happens in many related works and in Chapters \ref{chapter:stable-signature}, \ref{chapter:audioseal}, \ref{chapter:three-bricks}, \ref{chapter:radioactive} and \ref{chapter:invariants}.
Notably, it is used when turning a multi-bit watermarking scheme into a zero-bit one, by hiding a binary message and counting the number of matching bits.

The hypotheses are:
($\H_0$) The test statistic $S$ follows a binomial distribution $B(n, p_0)$, where $n$ is the number of trials and $p_0$ is the probability of success under $\H_0$.
In the case of multi-bit watermarking, $n$ is the number of bits in the binary message and $p_0 = 0.5$ (the probability of a random bit being correct).
($\H_1$) The test statistic $S$ follows a different distribution, typically one with a higher probability of success $p_1$ ($p_1 > p_0$).

The \pval\ of the test is the probability of observing a bigger score than the observed value $s$, under the null hypothesis $\H_0$. 
Mathematically, it is given by:
\begin{align}
    \text{\pval}(s) = P(S \geq s \mid \H_0) = 1 - F_{B(n, p_0)}(s-1) = I_{p_0}(s, n-s+1),
\end{align}
where $F_{B(n, p_0)}$ is the cumulative distribution function (c.d.f.) of the binomial distribution under $\H_0$, and $I_{p_0}$ is the \href{https://en.wikipedia.org/wiki/Beta_function#Incomplete_beta_function}{regularized incomplete beta function} (the last equality is a direct consequence of the definition of the beta function).

This \pval\ helps in deciding whether to reject $\H_0$ in favor of $\H_1$ based on the significance level $\alpha$ (or FPR) chosen for the test. 
If $\text{\pval} \leq \alpha$, we reject $\H_0$; otherwise, we do not.
This is equivalent to comparing the test statistic $s$ to a threshold $\tau$ such that $\text{\pval}(\tau) = \alpha$.
In practice, the threshold $\tau$ is chosen based on the desired FPR, and $\H_0$ is rejected if $s \geq \tau$.
For more information and a practical example, see Chap.~\ref{chapter:stable-signature}, Sec.~\ref{chap3/subsec:statistical-test} and Chap.~\ref{chapter:audioseal}, Sec.~\ref{chap4/app:fpr}.




















\section{Deep learning based image/audio watermarking}\label{chap0/sec:deep learning-watermarking}

\begin{figure}[b!]
    \centering
    \includegraphics[width=\textwidth, clip, trim=0 3cm 0 0]{0-introduction/figs/hidden.pdf}
    \caption{
        Overview of encoder/decoder based image watermarking. 
        The embedder (or encoder) takes an image and a binary message and outputs a new watermarked image that slightly differs from the original.
        The extractor (or decoder) takes an augmented version of the image and outputs a binary message.
        The training is done by minimizing 2 losses: a perceptual loss $\ell_{percep}$ between the watermarked and original, which controls the imperceptibility and a watermark loss $\ell_{watermark}$ which makes the output message similar to the original.
    }
    \label{chap0/fig:hidden}
\end{figure}

State-of-the-art watermarking methods for continuous domains, \eg, image, audio, etc. are predominantly based on \emph{encoder/decoder} deep neural networks~\citep{ahmadi2020redmark, DEAR_Liu0FMZY23, chen2023wavmark}, \Gls*{HiDDeN}~\citep{zhu2018hidden} being one of the most known examples.
Although they appear in different forms, they share a common structure and training procedure illustrated in Fig.~\ref{chap0/fig:hidden}.
These approaches serve as baselines and have inspired the techniques developed in Chapters \ref{chapter:ssl-watermarking}, \ref{chapter:active-indexing}, \ref{chapter:stable-signature}, and \ref{chapter:audioseal}.
We describe it bellow in the context of image watermarking\footnote{
    This chapter does not cover classical media watermarking as they are not used in the thesis, except as baselines.
    We refer the reader to Sec.~\ref{chap0/sec:watermarking} for a description and a discussion on these methods.
}.

\paragraph*{Watermark embedding.}
The \emph{encoder} (or embedder) network $E$ takes as input a cover image $\im_o \in \mathbb{R}^{W\times H\times 3}$ and a binary message $m\in\{0,1\}^\payload$.
The input message is fed into the network through a \emph{message embedding layer} that transforms it into a vector representation that can be processed by the network.
In Chap.~\ref{chapter:stable-signature}, the message is converted to $\pm 1$ values and concatenated pixel-wise to a feature map inside the network, while in Chap.~\ref{chapter:audioseal}, the message is used to select representations from a learned embedding layer, which are then aggregated and concatenated to the intermediate activations of the network.

The embedder outputs either directly the watermarked image $x_w$, or a distortion map $\delta \in \mathbb{R}^{W\times H\times 3}$.
$\delta$ is added to the cover image to produce the watermarked image $\im_w = \im_o + \alpha \cdot \delta$ with a scaling factor $\alpha$ that controls the imperceptibility of the watermark.
There are two common strategies to operate on various resolutions.
The first one is to use architectures that can handle images of any size, such as fully convolutional ones (as long as the distribution of the image is covered by the training set).
The second  one -- more practical because more computationally efficient and generalizable -- is to resize the image to a fixed resolution before feeding it to the network, then resize the output to the original resolution: 
\begin{equation}
    \im_w = \im_o + \alpha \cdot \text{resize}(\delta), \quad \delta = E(\text{resize}(\im_o)).
\end{equation}


\paragraph*{Attack simulation (augmentations).}
During training, the watermarked image is augmented with various transformations to simulate attacks and ensure the robustness of the watermark.
At each optimization step we randomly sample an augmentation $T$ to create a transformed image $\im_t = T(\im_w)$.
Among the most common augmentations are: JPEG compression, rotation, resizing, cropping, brightness or contrast changes, etc.

Many times, the augmentation is not differentiable with respect to the image, which makes the training more challenging since the gradients cannot be back-propagated through the augmentation.
The most common solutions are to either use a differentiable approximation of the augmentation, such as differentiable JPEG compression~\citep{zhu2018hidden}, or to use a straight-through estimator that approximates the gradient of the non-differentiable operation with the identity function~\citep{bengio2013estimating}.
The second option is often preferred as it often gives similar or better results than the differentiable approximation and is extremely simple to implement:
\begin{equation}
    \im_t = \im_w + \mathrm{nograd} \left( T(\im_w) - \im_w \right),
\end{equation}
where $\mathrm{no grad}$ does not propagate gradients, such that $\nabla_\theta\,\im_t = \nabla_\theta\,\im_w$ (where $\theta$ are the parameters of the network).



\paragraph*{Message extraction.}
The \emph{decoder} (or extractor) network $D$ takes as input the transformed image $\im_t$ and outputs a ``soft'' message $m' = D(\im_t) \in \mathbb{R}^\payload$ (soft because continuous).
At inference time, the decoded message is obtained by thresholding the soft message, for instance with $m' > 0$.
In the same way as for the embedding, the extraction can be done at a fixed resolution or with a network that can handle any resolution.

\paragraph*{Perceptual loss.}
The \emph{perceptual loss} $\ell_{\text{percep}}$ ensures that the watermarked image is visually similar to the original.
It is computed between the watermarked image and the original image and varies a lot depending on the papers.
It can be the mean squared error (MSE) between the pixel values, the LPIPS~\citep{zhang2018unreasonable} between the feature maps of a pre-trained network, discriminative losses based on GANs~\citep{goodfellow2014generative}, etc. or weighted combinations of these losses.

\paragraph*{Extraction loss.}
The \emph{message loss} $\ell_{\text{watermark}}$ ensures that the extracted message is close to the original message.
Most of the time it is the MSE or the Binary Cross Entropy (BCE) between $m$ and the sigmoid $\sigma (m')$:
\begin{align}
    \ell_{\text{watermark}} &= \frac{1}{\payload} \sum_{i=1}^\payload \left( m_i - \sigma (m'_i) \right)^2 
    \quad \text{or} \nonumber\\
    & =- \sum_{i=1}^\payload m_i \cdot \log \sigma (m'_i) + (1-m_i) \cdot \log ( 1 - \sigma (m'_i)).
\end{align}










\section{Watermarking for large language models}\label{chap0/sec:llm_wm}


We hereby provide a detailed overview of two watermarking techniques for large language models (\Glspl*{LLM}) that are used in Chapters \ref{chapter:three-bricks} and \ref{chapter:radioactive}.
They have been developed concurrently and are based on approximately the same principles~\citep{aaronson2023watermarking,kirchenbauer2023watermark}.
The watermarking process is illustrated in Fig.~\ref{chap0/fig:llm-watermarking}.

\paragraph*{Text generation with LLMs.} 
LLMs generate text by computing the likelihood of generating a sequence of tokens given a context.
The thesis focuses on decoder-only models, \aka, auto-regressive LLMs.
The \glspl*{token} are pieces of words or characters from a vocabulary $\V$, that are represented as integers between 0 and $|\V|-1$.
From a context $x^{(-C)}, ..., x^{(-1)}$, the model estimates the probability of each token of $\V$ being the next.
It computes a vector $\vec{\boldsymbol\ell}\in \R^{|\V|}$ of logits, transformed into:
\begin{equation}
    \vec{p} = \text{softmax}(\vec{\boldsymbol\ell};\temperature) \approx \left(\Prob \left( X^{(0)}= v \mid x^{(-C)},\dots, x^{(-1)} \right)\right)_{v\in\V},
    \label{chap0/eq:Distrib}
\end{equation}
where $\temperature$ is a temperature and $X^{(0)}$ is the random variable representing the next token.
The generation of a sequence from the context samples a token from this distribution, then appends it to the context and iterates the process. 
Various sampling schemes exist: 
greedy search selects the token with the highest probability, 
nucleus-sampling (top-p)~\citep{holtzman2019curious} randomly select a token in the smallest subset whose cumulative probability exceeds $p$,
top-k sampling~\citep{fan2018hierarchical}, beam search, etc.


\begin{figure}[b!]
    \centering
    \includegraphics[width=1.0\textwidth]{0-introduction/figs/llm-watermarking.pdf}
    \caption{
        Text generation with and without watermarking.
        (Top) The LLM generates logits based on the context, then samples the next token according to a distribution $\vec{p}$.
        The watermarking process alters the generation of the next token by 
        (Middle) partitioning the vocabulary into green and red tokens and adding a bias to green tokens~\citep{kirchenbauer2023watermark},
        (Bottom) sampling an uniform vector $\vec{r}$ and choosing the token as $\arg \max \vec{r}^{1/\vec{p}}$~\citep{aaronson2023watermarking}.
        The partitioning $\G \cup \bar{\G} = \V$ or the vector $\vec{r}$ are determined by a hash value computed from the watermark window consisting of the $k$ previous tokens.
    }
    \label{chap0/fig:llm-watermarking}
\end{figure}

\paragraph*{Hashing.}
Both methods alter the generation of the next token $x^{(0)}$ in a way that is influenced by the window formed by the $k$ previous tokens in the context: $x^{(-k)}, ..., x^{(-1)}$. 
We call it the \emph{watermark window} in all the thesis.

A hash function, which also depends on a secret key $\sk$, maps these $k$ integers to a hash value.
It varies according to implementations. 
In our work, the hash function operates according to the equation: 
$$h_{n+1} = (h_{n} \cdot \sk + x^{(n)}) \mod (2^{64} - 1),$$ 
for $n \in -k, .., -1$, and $h_{-k} = 1$.
Here, $h_{n+1}$ is the updated hash value, $h_{n}$ is the current hash value, $\sk$ is a constant, $x^{(n)}$ is the current input token, $\mod$ is the modulus operator, and $2^{64} - 1$ is the modulus value. 
The hash value is the final one ($h_0$).

\paragraph*{Watermark embedding.} 
The hash value is used as a seed that initializes a random number generator (RNG).
RNG is then used to influence the choice of the next token $x^{(0)}$.
\begin{itemize}
    \item \citet{kirchenbauer2023watermark} use the RNG to partition the vocabulary $\V$ into a greenlist $\G$ and a redlist $\bar{\G}$, where $\G$ contains a proportion $\gamma \in [0,1]$ of the vocabulary.
    The logit of each token in the greenlist is incremented by a value $\delta>0$, and the sampling proceeds as usual.
    Intuitively, this encourages the generation of greenlist tokens by increasing their probability.

    The imperceptibility of the watermark is mainly controlled by the parameter $\delta$.
    When it is high, the sampling only selects greenlist tokens, which  degrades the text quality but increases the robustness of the watermark, and vice versa (if $\delta=0$, the generation is not altered).

    \item \citet{aaronson2023watermarking} use the RNG to sample a vector $\vec{r}\in[0,1]^{|\V|}$.
    The next token is chosen as:
    \begin{equation}
        x^{(0)} = \arg \max_{v \in \V } \vec{r}_v^{1/\vec{p}_v}
    \end{equation}
    This encourages the generation of tokens that have a high $\vec{r}$ value.
    It also presents the interesting property that $\forall v\in \V$, $\Prob_{\vec{R}\,\sim\,\mathcal{U}([0,1]^{|\V|})} (X^{(0)}=v) = \vec{p}_v$ (proof is available in App.~\ref{chap5/app:aaronson_prob}).
    In other words, the probability of generating a token is not altered on expectation over the secret hash.

    The imperceptibility of the watermark is controlled by the temperature $\theta$ of the softmax.
    For very high values of $\theta$, the softmax outputs an almost uniform probability vector $\vec{p}$, so the choice of the next token is determined entirely by $\vec{r}$ (the token with highest $\vec{r}$ value is chosen) -- whereas for very low $\theta$, distribution $\vec{p}$ is very peaky so $\vec{r}$ has little influence.
\end{itemize}



\paragraph*{Watermark scoring.} 
We first tokenize a text into a sequence of tokens $x^{(1)}, \ldots, x^{(T)}$.
We go through every token $x^{(t)}$, replay the hashing process with the secret key $\sk$ and the $k$ previous tokens $x^{(t-k)}, \ldots, x^{(t-1)}$ and seed the RNG with the hash value.
We then re-create either the greenlist or the key vector, and score the token $x^{(t)}$ based on this information.
The score function on a current token $x^{(0)}$ may therefore be summed up as $W_{\textrm{score}}$ that also takes as input the watermark window $(x^{(-k)},\dots, x^{(-1)} )$, and implicitly depends on the secret-key $\sk$:
\begin{figure}[h!]
   \vspace*{1em}
   \begin{equation}
   \label{chap6/eq:watermark_score}
   \eqnmarkbox[Plum]{token}{x^{(0)}} ;\, 
   \eqnmarkbox[Emerald]{window}{\big(x^{(-k)},\dots, x^{(-1)} \big)} 
   \mapsto 
   \eqnmarkbox[BurntOrange]{Wscore}{W_{\textrm{score}}} 
   \left(  
      \eqnmarkbox[Plum]{token2}{x^{(0)}}  ;\,  
      \eqnmarkbox[Emerald]{window2}{\big(x^{(-k)},\dots, x^{(-1)} \big)} 
   \right) \in \R.
   \end{equation}
   \annotate[yshift=-0.4em]{below,right}{token}{Current token being scored}
   \annotate[yshift=0.4em]{above,right}{window}{Watermark window ($k$ previous tokens)}
   \annotate[yshift=-0.4em]{below,right}{Wscore}{Scoring function (\eg $1$ if green token, $0$ otherwise)}
\end{figure}\\
The total score $s_T$ is finally the sum of the scores of all tokens:
\begin{equation}
    s_T = 
        \sum_{t=1}^T W_{\textrm{score}} \left( 
                x^{(t)} ;\, 
                \big(x^{(t-k)},\dots, x^{(t-1)} \big)
            \right).
\end{equation}\\
The score functions are defined as follows:
\begin{itemize}
    \item For \citet{kirchenbauer2023watermark}:
    \begin{equation}
        W_{\textrm{score}} \left( x^{(t)} ;\, \G^{(t)} \right) = \mathds{1} \left(x^{(t)}\in\G^{(t)}\right),
    \end{equation}        
    where $x^{(t)}$ and $\G^{(t)}$ are the $t^{\textrm{th}}$ token and its associated partition, \ie, $1$ if the token is in the greenlist and $0$ otherwise.
    The total score is therefore the number of greenlist tokens in the text.
    Intuitively, if the text is not watermarked, the score should be approximately $\gamma$ since a token has a probability $\gamma$ of being in the greenlist.
    If the text is watermarked, the score should be strictly higher than $\gamma$.
    
    \item For \citet{aaronson2023watermarking}:
    \begin{equation}
        W_{\textrm{score}} \left( x^{(t)} ;\, \vec{r}^{(t)} \right) = - \ln \left(1- \vec{r}^{(t)}_{x^{(t)}} \right),
    \end{equation}
    where $x^{(t)}$ and $\vec{r}^{(t)}$ are the $t^{\textrm{th}}$ token and its associated key vector.
    The total score presents the property that for non-watermarked text the expected score $\mathbb{E}(S_T) = T$, while otherwise $\displaystyle \mathbb{E}(S_T) \geq T +  \left( \frac{\pi^2}{6} -1 \right) H_T > T $, where $H_T = - \sum_{t=1}^T p_t\ln(p_t)$ is the entropy of the watermarked completion ($p_t = \vec{p}^{(t)}_{x^{(t)}}$).
    See proofs in App.~\ref{chap5/app:aaronson_score}.
\end{itemize}
Note that $\G^{(t)}$ and $\vec{r}^{(t)}$ only depend on the $k$ tokens that precede $x^{(t)}$ and the secret-key $\sk$.
A corollary is that the score computation does not require the model to be re-run, which is a significant advantage in terms of computational cost.

Moreover, the robustness of the watermark is better for small $k$, since changing a token in the watermark window will change the hash value and increment the score as if there was no watermark.
At the same time, the hash values are more likely to collide during generation when $k$ is low, which creates a bias in the distribution of generated tokens.
Therefore, the choice of $k$ is a trade-off between robustness and imperceptibility.
For instance, if $k=0$ the hash only takes one value, so the generation of some tokens is always favored, but the watermark is robust except if most of the tokens are modified.


\paragraph*{Statistical test for watermark detection.} 
The statistical hypothesis test distinguishes between the hypothesis $\H_0$: ``the text is natural'' and $\H_1$: ``the text has been generated with watermark''.
Originally, both approaches approximate the underlying distribution of the score $S_T$ by using a $Z$-test (\autoref{chapter:three-bricks} introduces statistical tests based on the true distribution of the score $S_T$).

The $Z$-test compares the observed score $S_T$ against its expected value under the hypothesis $\H_0$ (no watermark).
It is typically used for large sample sizes assuming a normal distribution under the null hypothesis thanks to the central limit theorem.  
The $Z$ statistic is computed as:
\begin{equation}
    Z = \frac{{S_T/T - \mu_0}}{{\sigma_0 / \sqrt{T}}},
\end{equation}
where $\mu_0$ and $\sigma_0$ are the expected mean and standard deviation of the score per token under $\H_0$.
A \pval\ is then calculated to determine the likelihood of observing a score as extreme as $S_T$ under $\H_0$:
\begin{equation}
    \text{p-value}(z) = \Prob(Z \geq z \mid \H_0) = 1 - \Phi(z),
\end{equation}
where $\Phi$ is the cumulative distribution function of the normal distribution. 
Texts are flagged as watermarked if the \pval\ is less than a fixed false positive rate (FPR).
