
\chapter{Introduction}\label{chapter:introduction}






\section{A brief history of watermarking}

\Gls*{watermarking}, \ie, the process of hiding information about an object within the object itself, is a technique that has been used for centuries if not millenia.

\paragraph*{Origins.}

\begin{figure}[b]
    \centering
    \begin{minipage}{0.59\textwidth}
        \centering
        \includegraphics[width=1.0\textwidth]{0-introduction/figs/history-1.jpg}
        \caption{
            Pieces of paper with imprinted watermarks that appear when light is shining from behind because the paper is thinner in the places where a wire was. Now used by historians to date the paper~\citep{endersby2023patterns}.
        }\label{intro/fig:history}
    \end{minipage}
    \hfill
    \begin{minipage}{0.37\textwidth}
        \centering
        \includegraphics[width=0.93\textwidth]{0-introduction/figs/dandy_roll.jpg}
        \caption{
            A dandy roll machine with a watermark used to create paper. \href{https://commons.wikimedia.org/wiki/File:Dandy_roll_2.jpg}{Wikimedia Commons}.
        }\label{intro/fig:dandy_roll}
    \end{minipage}
\end{figure}

The term ``watermark'' has its roots in the 13\textsuperscript{th} century in Italy, and comes from the papermaking process.
Until the 19\textsuperscript{th} century, paper was produced by shredding linen rags and other fibers and mashing them up in water to create a liquid paste of fiber.
A wire mesh mould was lowered into this paper pulp, creating a thin layer of fibers on the mould.
The mesh would create distinctive marks by altering the thickness of the paper during its production, while it was still damp, hence the term ``water-mark''.
These marks were visible when the paper was held up to the light, as shown in Fig.~\ref{intro/fig:history}.

Papermakers quickly began using watermarks as a form of logo or trademark to distinguish their products from others. 
This was a simple yet effective way to ensure the authenticity of the paper and to protect the reputation of the papermaker.
By the 14\textsuperscript{th} to 16\textsuperscript{th} centuries, watermarking had become a common practice across Europe. 
The watermarks later evolved to include symbols, logos, and dates, providing more specific information about the origin of the paper.
The invention of the dandy roll -- a wire-covered cylinder that removes excess water from the wet paper pulp -- in the early 19\textsuperscript{th} century allowed for more complex and intricate watermarks to be created (see Fig.~\ref{intro/fig:dandy_roll}).



\paragraph*{Birth of digital watermarking.}

\begin{figure}[b!]
    \centering
    \includegraphics[width=1.0\textwidth]{0-introduction/figs/papers_per_year.pdf}
    \caption{
        Annual number of papers on watermarking, from IEEE Xplore and arXiv (number for 2024 is extrapolated). 
        We can identify the rise of watermarking in the 1990s -- with the popularization of DVDs -- its stabilization and slight decrease in the 2010s, and its resurgence in the 2020s -- which can be attributed to the popularization of generative models, \eg, image models~\citep{karras2020analyzing,ho2020denoising} and LLMs like GPT-3~\citep{brown2020language}.
    }
    \label{intro/fig:num_papers}
\end{figure}

Watermarking evolved from a physical process in papermaking to a digital process as new types of media became available, making the original etymology somewhat obsolete. 
The arrival of digital watermarking in the early 1990s was primarily driven by the need to protect digital media from unauthorized copying and distribution in the rapidly expanding internet. 
This new challenge sparked significant interest in the research community for at least two decades (see Fig.~\ref{intro/fig:num_papers}).

Watermarking techniques were developed for numerous types of content, including audio, images, video, 3D, text, etc.
There is even an intriguing application in DNA sequences~\citep{shimanovsky2002hiding, heider2007dna}, used to protect the intellectual property of genetically modified organisms or to trace infectious agents!
More known applications of digital watermarking are exposed in \textit{Digital Watermarking and Steganograph}y, by~\cite{cox2007digital}.
A notable one is in Digital Rights Management (DRM) systems~\citep{barni2004data}, which protect digital content from unauthorized access and distribution. 
For instance, Hollywood studios use video watermarking for DVD copy protection.
It enables them to trace leaked content back to the specific distributed copy, identifying the person or entity responsible for unauthorized distribution.
Watermarking has become ubiquitous in our everyday lives, even though it often goes unnoticed because its first goal is to be imperceptible.
For example, photos in the news industry are watermarked to identify the source photo agency, and audio and video content in Video On Demand portals are watermarked to combat piracy. 
Other applications include audio or video watermarks that are used for TV broadcasts monitoring~\citep{depovere1999viva}, or in movie theaters to prevent illegal recordings and retrace the specific theater where the recording was made~\citep{nakashima2009watermarked} -- and even the seat and time of the recording!
The decline in watermarking research around the 2010s can be attributed to several factors. 
As the field matured, focus shifted towards industry applications and evolved alongside media distribution methods, particularly with the rise of streaming services. 
Additionally, funding priorities and research interests shifted due to technological advancements in areas like cloud computing and AI.

\paragraph*{Artificial Intelligence.}

Watermarking has started to become popular again since the start of the decade.
This is driven by the renewed interest in deep learning~\citep{lecun2015deep}, or more broadly, Artificial Intelligence (AI).
One possible reason is that researchers are exploring deep learning based methods to improve over traditional ones, with better accessibility, adaptability and robustness. 
However, this alone cannot fully explain the increasing interest in the field.
The factors are more likely (1) the development and popularization of image generative models such as StyleGAN2~\citep{karras2020analyzing}, DDPM~\citep{ho2020denoising} and of Large Language Models (LLM) like GPT-3~\citep{brown2020language} and (2) the productization of deep learning models and the need to protect these million-dollars assets.
This has contributed to bringing new funding and research opportunities to the watermarking community, which is now more attractive than ever.

At the moment of writing this manuscript, watermarking is therefore in the middle of the GenAI revolution given the role it could play for \emph{content authenticity}.
AI-generated content is used for swaying public opinion~\citep{shen2019fake, goldstein2023generative}, fraud, or impersonation at a higher scale and more convincingly than even authentic content~\citep{spitale2023ai}.
Governments are getting hold of the issue through new regulations that impose watermarking as a technical means for transparency and traceability~\citep{USAIAnnouncement, ChineseAIGovernance, EuropeanAIAct, ca_ab3211_2024}.
Several key players, like
\href{https://deepmind.google/discover/blog/watermarking-ai-generated-text-and-video-with-synthid/}{Google}, 
\href{https://about.fb.com/news/2024/04/metas-approach-to-labeling-ai-generated-content-and-manipulated-media/}{Meta},
and
\href{https://openai.com/index/understanding-the-source-of-what-we-see-and-hear-online/}{OpenAI},
are now paving the way for the re-birth of watermarking.















\section{New applications in the era of massive data}

The beginning of the decade, from a digital point of view, is characterized by the rapid growth of the internet (social media, search engines, cloud) and of hardware (processors, mobile devices, compute clusters).
This has led to a significant increase in the amount of data being generated and shared online, as well as new opportunities for using this data to training Machine Learning (ML) models.
In this section, we will explore new applications of watermarking that have emerged in this massive data era.


\subsection*{Content moderation}

\begin{quote}
    \textit{``The internet is the first thing that humanity has built that humanity doesn't understand, the largest experiment in anarchy that we have ever had.''}
    \begin{flushright} -- Eric Schmidt, CEO of Google, 2010 \end{flushright}
\end{quote}


Mankind now relies on internet platforms for a variety of needs: getting news, information from close circles, learning new materials, communicating with professional communities, etc.
In 2020 alone, 3.2 billion images and 720,000 hours of video were shared online daily\footnote{\scriptsize\url{https://www.qut.edu.au/insights/business/3.2-billion-images-and-720000-hours-of-video-are-shared-online-daily.-can-you-sort-real-from-fake}}, often copied and altered as they spread among users.
This explosion of digitization and data sharing presents new significant challenges: complying with intellectual property laws and moderating social platforms have all become untractable. 
Unlike TV or radio, where content is produced by a few controlled sources, everyone can create and share content online. 

The internet, much like other shared spaces, arguably needs governance to ensure it remains safe for users and content creators. 
Content moderation plays a crucial role in this governance by applying a set of rules to user-generated content, preventing the spread of harmful material (hate speech, misinformation, etc.), and ensuring it complies with ethical standards.
This moderation is required by regulations like the European Union's Digital Services Act (DSA) and the United States' Section 230 of the Communications Decency Act (CDA), which hold platforms accountable for the content they host.

Content moderation has evolved from manual verification to ML-based automated systems given the volume of images shared daily.
A key component of these systems is copy detection, which automatically identifies near-duplicate content. 
For instance, during the COVID-19 pandemic, Meta platforms used it to detect misinformation and exploitative content~\citep{sumbaly2020using, pizzi2022self}. 
By identifying and flagging near-exact copies of known misinformation, it allowed to flag millions of pieces of content and enabled human fact-checkers to focus on catching new instances of misinformation rather than near-identical variations of content they had already seen.
Similar approaches, called  NeuralHash~\citep{apple2021csamdetection} and PhotoDNA~\citep{photodna} are used to detect child sexual abuse material respectively in iCloud and on the internet, as well as other harmful content like violent terrorist imagery for the latter.

In this context, where content is transmitted on platforms, watermarking may actively trace its origin by embedding a unique identifier -- specific markers that can be used to verify the source -- in each piece of content as soon as it enters the platform.
It has the potential to increase accuracy and catch instances of misinformation or harmful content that may not be flagged by existing copy detection systems, thereby providing a more robust solution for content protection compared to traditional copy detection methods.





\subsection*{Tracing AI-generated content}

\begin{figure}[b!]
    \centering
    \begin{minipage}[b]{0.25\textwidth}
        \includegraphics[width=\textwidth]{0-introduction/figs/pope.jpeg}
    \end{minipage}
    \hfill
    \begin{minipage}[b]{0.72\textwidth}
        \centering
        \includegraphics[width=0.32\textwidth]{0-introduction/figs/sora1.jpg}\hfill
        \includegraphics[width=0.32\textwidth]{0-introduction/figs/sora2.jpg}\hfill
        \includegraphics[width=0.32\textwidth]{0-introduction/figs/sora3.jpg} \\[10pt]
        \includegraphics[width=0.32\textwidth]{0-introduction/figs/sora2_1.jpg}\hfill
        \includegraphics[width=0.32\textwidth]{0-introduction/figs/sora2_2.jpg}\hfill
        \includegraphics[width=0.32\textwidth]{0-introduction/figs/sora2_3.jpg}
    \end{minipage}
    \caption{
        (Left) A viral image of Pope Francis generated from text by Midjourney, which became famous as deepfake example.
        (Right) Frames from video clips generated by OpenAI's Sora.
        The fact that AI-generated content is visually indistinguishable from human-generated content highlights the need for more robust detection schemes like watermarking.
    }\label{intro/fig:pope}
\end{figure}



The above quote by Eric Schmidt is even more relevant today as the internet has become the playground of generative AI models.
These models are developed and adopted at an unprecedented pace.
In text generation, \href{https://chatgpt.com/}{ChatGPT} reached 100 million users in just two months, and has had a significant impact on the way people interact with AI since then.
It has counterparts in image generation with DALL$\cdot$E~\citep{ramesh2021zero} and \href{https://www.midjourney.com/}{Midjourney}; video with \href{https://openai.com/index/sora/}{Sora} and \href{https://kling.kuaishou.com/en}{Kling}; and audio with \href{https://suno.com/}{Suno} and \href{https://www.udio.com/}{Udio}.
Closed models are generally followed by open-weights alternative of the same quality in less than a year (\eg, Llama or Stable Diffusion).
Furthermore, they create content that is often indistinguishable from human-generated content (see in Fig.~\ref{intro/fig:pope}).
A study by \cite{nightingale2022ai} notably found that human participants exhibited a relatively low accuracy rate in distinguishing between authentic and artificially generated facial images, with an average accuracy of 48.2\% (so AI-generated faces were deemed most trustworthy).
The same finding applies to text~\citep{spitale2023ai}.

Generative models are used to create content at scale and are beginning to replace traditional content creation methods. 
By late 2023, they had already produced as many images as photographers had taken in 150 years of photography\footnote{\scriptsize\url{https://journal.everypixel.com/ai-image-statistics}}.
It raises concerns from Hollywood and the creative industry~\citep{coyle2023chatgpt} and from governments given the risks for misinformation, fraud, and impersonation.
It would be too long to cite all malicious uses of generative AI: they range from scam books sold on Amazon~\citep{knibbs2024scammy} to influence campaigns~\citep{goldstein2023generative} or the creation of deepfakes and impersonation of public figures~\citep{harris2018deepfakes, shen2019fake}.
Ironically, GPT-4o made it possible to build dynamic AI-generated websites self-sufficient by ads\footnote{\scriptsize\url{https://batchmon.com/blog/ai-cheaper-than-ads/}}.

These risks linked to AI-generated content are heightened because it is difficult to detect and attribute such content to models that generated them.
This makes it hard to hold anyone accountable and does not encourage companies to implement effective safety measures. 
Watermarking is an ideal technique for tracing content from generative models since providers have control over the model's outputs.
In this context, it is put forward by most of the regulations on AI~\citep{USAIAnnouncement, ChineseAIGovernance, EuropeanAIAct} to allow for a better transparency.
The idea is to watermark the content during or after the generation to embed a proof that it is AI-generated, or an identifier of the specific model that generated it.
Notably, traditional watermarking methods could also be employed for post-hoc watermarking of AI-generated content. However, as we will discuss later, it presents specific challenges that we address in this thesis.
For instance, in open-weights scenarios, where copy detection or post-hoc watermarking would be impossible, the model provider could even watermark the generative model prior to distribution.



\subsection*{Monitoring AI models}

Tracing AI-generated outputs serves not only regulatory purposes but more broadly economical ones with intellectual property protection and monitoring of the model usage.
Data is said to be the ``fuel of AI,''\footnote{\scriptsize Ilya Sutskever, at NeurIPS 2024.} but in contrast with motors that consume the fuel, ML models memorize and extract value from it.
Models and their training data have therefore become extremely valuable, often representing significant investments. 
How can the data being used to train models be traced and the data providers be properly credited?
How can the models themselves be traced and their use be ensured according to the licensing agreements?
The complexity and lack of transparency in AI models make it challenging to answer these questions, even more when these models can be fine-tuned, distilled or used as black-boxes in other APIs.

Watermarking may help at several levels:
\begin{itemize}
    \item \emph{Watermarking models} allows organizations to trace the origin of models and detect leaks or unauthorized use, protecting intellectual property rights. 
    It also prevents the spread of potentially harmful or insecure AI applications.
    \item \emph{Watermarking training data} enables providers to detect and track the usage of their data, to ensure that it is being used in compliance with licensing agreements.
    It should offer a proof that the said data was used and in which proportion, so that it can be attributed to its owner.
\end{itemize}





















\section{Outline and contributions}

This thesis introduces watermarking techniques for each of the aforementioned applications.
\autoref{chapter:related-work} first presents related works.
\autoref{chapter:technical-background} then presents the detailed technical background on watermarking, necessary to understand the following chapters.
The contributions are structured around their applications:

\noindent
\fullref{part:content-moderation} 

\newcommand{\basedon}{$>$ Based on: }
\newcommand{\codeat}{$>$ Code at: }
\begin{itemize}
    \item \fullref{chapter:ssl-watermarking}.
    This chapter explores how to leverage the intrinsic robustness of self-supervised neural networks, often used for copy-detection, for image watermarking instead.
    It does so by hiding information in their latent representations through an iterative image optimization.
    It enables watermarking images with varying resolutions, adjustable payload, and a customizable tradeoff between robustness and quality.
    \\ \basedon
    \textit{Fernandez et al., Watermarking images in self-supervised latent spaces, ICASSP 2022}.
    \\ \codeat
    \url{github.com/facebookresearch/ssl_watermarking}
    \item \fullref{chapter:active-indexing}.
    This chapter introduces a technique that combines copy detection and watermarking.
    The goal is to greatly improve the robustness of copy detection systems by imperceptibly modifying images before their release, with similar optimization schemes as in the previous chapter.
    \\ \basedon
    \textit{Fernandez et al., Active image indexing, ICLR 2023}.
    \\ \codeat
    \url{github.com/facebookresearch/active_indexing}
\end{itemize}

\noindent
\fullref{part:genai-tracing} 

\begin{itemize}
    \item \fullref{chapter:stable-signature}.
        This chapter presents a technique that fine-tunes latent generative models such that all images they produce hide an invisible signature. 
        These signatures can be used to detect and track the origin of images generated by latent diffusion models.
        Stable Signature offers protection in open-weights scenarios, contrary to methods that would apply the watermark post-generation, like the ones of the previous part.
        \\ \basedon
        \textit{Fernandez et al., The stable signature: Rooting watermarks in latent diffusion models, ICCV 2023}.
        \\ \codeat
        \url{github.com/facebookresearch/stable_signature}
    \item \fullref{chapter:audioseal}.
        This chapter introduces a watermarking solution for the detection of AI-generated speech.
        We proactively watermark the speech signal, which can later be detected to verify the authenticity of the content. 
        Contrary to traditional methods, the watermark detection is localized and predicts for each time step (1/16k of a second) if the watermark is present or not, which makes it fast and able to pinpoint small segments of watermarked audio in longer ones.
        \\ \basedon
        \textit{San Roman et al., Proactive detection of voice cloning with localized watermarking, ICML 2024}.
        \\ \codeat
        \url{github.com/facebookresearch/audioseal}
    \item \fullref{chapter:three-bricks}.
        This chapter brings three improvements to state-of-the-art watermarking methods for large language models (LLM):
        (1) theoretically grounded and empirically validated statistical tests that guarantee false positive rates,
        (2) evaluation on classical LLM benchmarks,
        (3) extension to scalable multi-bit watermarking.
        \\ \basedon
        \textit{Fernandez et al., Three bricks to consolidate watermarks for large language models, WIFS 2023}.
        \\ \codeat
        \url{github.com/facebookresearch/three_bricks}
\end{itemize}

\noindent
\fullref{part:model-monitoring} 

\begin{itemize}
    \item \fullref{chapter:radioactive}.
        This chapter examines whether a watermark can be detected in a language model fine-tuned on watermarked text. 
        We explore scenarios based on model and data access, showing that the watermark can in some cases be identified with high significance ($p<10^{-6}$) even when only 5\% of the fine-tuning data is watermarked. 
        Thus, LLM watermarking, originally designed to detect AI-generated text, can also indicate if an LLM's outputs were used to fine-tune another model. 
        This is a pressing question for model providers concerned about the theft or misuse of their models.
        \\ \basedon
        \textit{Sander et al., Watermarking makes language models radioactive, NeurIPS 2024}.
        \\ \codeat
        \url{github.com/facebookresearch/radioactive-watermark}
    \item \fullref{chapter:invariants}.
        This chapter introduces a training-free watermark for the weights of large transformers.
        It leverages the model's invariance through operations like dimension permutations or scaling/unscaling to generate different functionally equivalent copies with different weights. 
        The use case is to distribute different weights of the exact same model to different clients, and to detect leaks or unauthorized use.
        \\ \basedon
        \textit{Fernandez et al., Functional invariants to watermark large transformers, ICASSP 2024}.
\end{itemize}

\autoref{chapter:conclusion} ends the thesis with a summary of the contributions, a discussion on the perspectives and open questions for watermarking.
