\newcommand{\valtab}[1]{{\color{gray}\footnotesize ({#1})}}

\section{Experiments}\label{chap7/sec:experiments}

The purpose of the experiments is to evaluate the effectiveness and the robustness of the watermarks to transformations on large language models.

\subsection{Setup}

\paragraph*{Model.}
We use Llama~\citep{touvron2023llama} models as main benchmark. 
The architectural differences with regards to the original transformer architecture are pre-normali\-zation~\citep{radford2019language} with RMSnorm~\citep{zhang2019root}, SwiGLU activation~\citep{shazeer2020glu} and rotary embeddings~\citep{su2021roformer}.
To evaluate that the utility of the model is not degraded, we show results on a next-token prediction task.
This is done on random sequences of text taken from Wikipedia, then tokenized using the default tokenizer of Llama.
Unless stated otherwise, we use the $7$B-parameter model.

\paragraph*{Attacks.}
We consider the following attacks.
\emph{Fine-tuning.} 
We fine-tune the model in a supervised manner with the same settings as~\citep{alpaca}, on 3 epochs with learning-rate of $2\times 10^{-5}$.
\emph{Noise.} 
We add zero-mean Gaussian noise with standard deviation $\sigma$ to the model weights.
\emph{Quantization.}
We quantize the model weights into $b$ bits. 
To allow flexible rates and ease the experiments, this is done by uniformly quantizing the weights between their minimum and maximum values.
\emph{Pruning.}
We prune the model weights by zeroing the ones with smallest L1 norms, with sparsity given in percentage of zero weights.

\paragraph*{Watermark settings.}
We apply the encoding process of Sect.~\ref{chap7/sec:invariantsaswatermarks}.
For permutation invariance, we permute attention heads and FFN layers.
For scaling, we alter the layers' RMSnorms and following matrices.
The scaling vector $\alpha$ is such that $\log_{10}(\alpha) \sim \mathcal{U}(-1, 1)$.
For QK products, as mentioned in Sect.~\ref{chap7/sec:invertible}, the invertible matrix has to be block diagonal of $2$ by $2$ rotation matrices, so we randomly sample $d/2$ rotation angles.
We fix the number of possible choices at $k$=$8$, \ie, each choice is encoded with a byte.
Therefore, we encode $2$ bytes at every layer, except in QK products where we encode $1$.
When combining all invariants together, we proceed the same way for all blocks: we start with permutation, then apply invertible matrices in QK products, then scale/unscale the layer norms and matrices.

For instance, the $7$B model has $L$=$32$ layers so the watermark is $64$ bytes long except for the QK products invariant where it is $32$.
In the case of combined invariants, the total number of bytes is $160$.


\subsection{Results.}\label{chap7/sec:results}

\begin{table}
    \centering
    \caption{
    Distortion induced on generation 
    and robustness of watermark extraction under various processes. 
    Each line stands for a different invariant.
    We present results of the sped-up extraction, the ones for no speed-up are given as \valtab{acc}.
    }
    \label{chap7/tab:robustness}
    \footnotesize
        \begin{tabular}{lc *{4}{l}}  
            \toprule
            \multirow{2}{*}{Method} & \multirow{2}{*}{Distortion} & \multicolumn{4}{c}{Byte accuracy ($\%$) on:} \\
            \cmidrule(lr){3-6}
                        &           & Noise $1.0$    & Quantization $3$b & Pruning $50\%$ & Fine-tune  \\
            \midrule
            Perm. & 0.20$\%$ & 51.4  \valtab{99.6} & 72.0 \valtab{100.0}   & 100.0     & 100.0 \\
            QK          & 0.18$\%$ & 100.0          & 100.0         & 100.0     & 100.0 \\
            Scaling     & 0.24$\%$ & 100.0          & 98.1 \valtab{100.0}       & 100.0     & 100.0 \\
            All        & 1.77$\%$ & 60.8  \valtab{99.8} & 70.0   \valtab{99.4} & 100.0 & 100.0 \\
            \bottomrule
        \end{tabular}
\end{table}



\paragraph*{Robustness.}
We evaluate the robustness of the watermark using the \emph{byte accuracy}, \ie, the percentage of bytes correctly recovered.
Results are averaged over $N$=$100$ watermarked models except for fine-tuning where we only fine-tune one model.
We speed-up the extraction by selecting a subset of $100$ rows of the matrices (see Sect.~\ref{chap7/sec:invariantsaswatermarks}); 
time needed for extraction is around 20 minutes when using the full matrix instead.

\autoref{chap7/tab:robustness} reports the byte accuracy for different processing applied before extraction.
We observe that the watermark is robust to all attacks with byte accuracy >$50\%$.
Errors mainly come from the speed-up of the extraction process.
We also consider the \emph{\pval} of the associated statistical test~\eqref{chap7/eq:pvalue}.
A byte accuracy of 50\% on 64-bytes messages is more than enough to reliably identify a model: 
the \pval s are always bellow $10^{-60}$, due to the very low probability of simultaneously observing a match between tens of pairs of random bytes.
As an illustration, 8 matching bytes on 64-bytes messages already gives a \pval\ of $10^{-8}$.

\paragraph*{Model's utility.}
In fact, previous invariants are not perfect because of quantization (weights are stored as 16bits floating point numbers).
Thus, we quantitatively compare watermarked and original models.
We feed to both of them $1$k sequences of $256$ tokens.
Predicted next tokens are greedily chosen as the argmax of the $256$k observed logits.

\autoref{chap7/tab:robustness} reports the distortion as the proportion of predicted tokens that differ between watermarked and original models.
As expected this proportion is very low (<$1.8\%$) and higher for the scaling invariant since it further affects quantization.

Besides, the distortion increases when the token is far in the sequence \eg, for sequences of length 1024 tokens, the average distortion at the last token rises to $2.5\%$ for the scaling invariant.
This is still very low and does not affect the utility of the model since predicted tokens are still very likely.


\paragraph*{Computational efficiency.}
Larger models have more layers and parameters, which increases the computational cost of insertion and extraction.
In \autoref{chap7/tab:modelsize}, we report results for different model sizes.
Insertion and extraction times are averaged over $100$ runs and measured on 2 Intel(R) Xeon(R) 6230 @ 2.10GHz cores and a total of 480GB of RAM.
The low computational costs and requirements (no GPU needed) makes it possible to scale to very large models.



\begin{table}
    \centering
    \caption{
        Computational cost of watermark insertion and extraction for different model sizes and the different invariants. 
    }
    \label{chap7/tab:modelsize}
    \footnotesize
        \begin{tabular}{rcc *{3}{r} *{3}{r}}
            \toprule
            \multirow{2}{*}{Model} & \multirow{2}{*}{$L$} & \multirow{2}{*}{$d$} &  \multicolumn{3}{c}{Insertion (s)} & \multicolumn{3}{c}{Extraction (s)} \\
            & & & Perm. & Scaling & QK   & Perm. & Scaling & QK  \\
             \cmidrule(rr{2pt}){4-6} \cmidrule(rr){7-9}
            7-B & 32 &  4096  & 3.5  & 2.7 &    7.4    &  9.2 &  31.7 &  6.0    \\
            13-B & 40 & 5120  & 7.0  & 4.9 &    15.8   & 14.1 &  30.3 &  7.7    \\
            30-B & 60 & 6656  & 19.3 & 8.7 &    47.3   & 31.7 &  54.7 & 13.5    \\
            70-B & 80 & 8192  & 37.1 & 17.5 &   106.0 &   56.3 & 110.0 & 21.5   \\
            \bottomrule
        \end{tabular}
\end{table}

