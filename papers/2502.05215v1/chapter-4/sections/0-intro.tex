
\section{Introduction}

Generative speech models are now capable of synthesizing voices that are indistinguishable from real ones~\citep{arik2018neural, kim2021conditional, casanova2022yourtts, wang2023neural}.
Though speech generation and voice cloning are not novel concepts, their recent advancements in quality and accessibility have raised new security concerns. 
A notable incident occurred where a deepfake audio misleadingly urged US voters to abstain, showcasing the potential for misusing these technologies to spread false information~\citep{murphy2024biden}.
Regulators and governments are implementing measures for AI content transparency and traceability, including forensics and watermarking -- see \citet{ChineseAIGovernance, EuropeanAIAct, USAIAnnouncement}, and Chap.~\ref{chapter:introduction} for a broader overview.

\begin{figure}[t]
    \centering
    \includegraphics[width=0.99\linewidth, clip, trim={0in 0in 0.5in 0in}]{chapter-4/figs/fig1.pdf}
    \caption{
        Overview of the proactive detection of AI-generated speech.
        We embed an imperceptible watermark in the audio, which can be used to detect if a speech is AI-generated and identify the model that generated it.
        It can also precisely pinpoint AI-generated segments in a longer audio with a sample level resolution (1/16k seconds).
        }
    \label{chap4/fig:fig1}
\end{figure}

The main forensics approach to detect synthesized audio is to train binary classifiers to discriminate between natural and synthesized audios, a technique highlighted in studies by~\citet{Borsos2022AudioLMAL, Kharitonov2023SpeakRA, le2023voicebox}.
We refer to this technique as \textit{passive detection} since it does not alter of the audio source. 
Albeit being a straightforward mitigation, 
it is prone to fail as generative models advance and the difference between synthesized and authentic content diminishes. 

Watermarking emerges as a strong alternative.
It embeds a signal in the generated audio, imperceptible to the ear but robustly detectable by specific algorithms.
As explained in the conclusion of Chap.~\ref{chapter:stable-signature}, post-hoc watermarking methods are more flexible and can be applied to any model without any modification, which makes them the go-to solution for most applications.
However, current post-hoc audio watermarking methods have strong limitations.
First, \emph{they are not adapted for detection}.
Most deep learning based audio watermarking methods~\citep{pavlovic2022robust, DEAR_Liu0FMZY23, chen2023wavmark} are multi-bit.
They train a generator to output the watermarked audio from a sample and a message, and an extractor retrieving the hidden message.
Our method aligns more closely with the concurrent work by \citet{juvela2023collaborative}, which trains a detector, rather than a decoder.
Moreover, the initial applications assumed any sound sample under scrutiny was watermarked (\eg, IP protection).
As a result, the decoders were never trained on non-watermarked samples.
This discrepancy between the training of the models and their practical use leads to poor or overestimated detection rates, depending on the embedded message (see Sec.~\ref{chap4/app:fpr}).

Second, they \emph{are not localized} and consider the entire audio, making it difficult to identify small segments of AI-generated speech within longer audio clips. 
This is particularly important for speech, where editing a single word can be enough to mislead the listener.
The concurrent WavMark's approach~\citep{chen2023wavmark} addresses this by repeating at 1-second intervals a synchronization pattern followed by the actual binary payload. 
This has several drawbacks. 
It cannot be used on spans less than 1 second and is susceptible to temporal edits. 
The synchronization bits also reduce the payload for the encoded message, accounting for 31\% of the total payload. 
Most importantly, the brute force detection algorithm for decoding the synchronization bits is prohibitively slow especially on non-watermarked content, as we show in Sec.~\ref{chap4/sec:speed}.
This makes it unsuitable for real-time and large-scale traceability of AI-generated content on social media platforms, where most content is not watermarked.

To address these limitations, we introduce a method for localized speech watermarking, \emph{AudioSeal}, that can detect AI-generated speech at the time-step level.
It jointly trains two networks: a \emph{generator} that predicts an additive watermark waveform from an audio input, and a \emph{detector} that outputs the probability of the presence of a watermark at each sample of the input audio. 
The detector is trained to precisely and robustly detect synthesized speech embedded in longer audio clips by masking the watermark in random sections of the signal.
The training objective is to maximize the detector's accuracy while minimizing the perceptual difference between the original and watermarked audio. 
We also extend AudioSeal to multi-bit watermarking, so that an audio can be attributed to a specific model or version without affecting the detection signal.

We evaluate the performance of AudioSeal to detect and localize AI-generated speech.
AudioSeal achieves state-of-the-art results on robustness of the detection, far surpassing passive detection with near perfect detection rates over a wide range of audio edits.
It also performs sample-level detection (at resolution of 1/16k second), outperforming WavMark in both speed and performance.
In terms of efficiency, our detector is run once and yields detection logits at every time-step, allowing for real-time detection of watermarks in audio streams. 
This represents a major improvement compared to earlier watermarking methods, which require synchronizing the watermark within the detector, thereby substantially increasing computation time.
Finally, in conjunction with binary messages, AudioSeal almost perfectly attributes an audio to one model among $1000$, even in the presence of strong audio edits.

Our overall contributions are:
\begin{itemize}
    \item We introduce AudioSeal, the first audio watermarking technique designed for localized detection of AI-generated speech up to the sample-level;
    \item A novel perceptual loss inspired by auditory masking, that enables AudioSeal to achieve better imperceptibility of the watermark signal;  
    \item AudioSeal achieves the state-of-the-art robustness to a wide range of real life audio manipulations (Sec.~\ref{chap4/sec:exps});
    \item AudioSeal significantly outperforms the state-of-the-art models in computation speed, achieving up to two orders of magnitude faster detection (Sec.~\ref{chap4/sec:speed});
    \item Insights on the security and integrity of audio watermarking techniques when open-sourcing (Sec.~\ref{chap4/sec:attacks}).
\end{itemize}
