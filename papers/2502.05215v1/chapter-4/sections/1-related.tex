
\section{Related work}

In this section we give an overview of the detection and watermarking methods for audio data. 
A complementary description of prior works can be found in Chap.~\ref{chapter:related-work}.

\paragraph{Synthetic speech detection.}
The approach of most audio generation and text-to-speech (\Gls*{TTS}) papers~\citep{Borsos2022AudioLMAL, Kharitonov2023SpeakRA, borsos2023soundstorm, le2023voicebox} is to train end-to-end deep learning classifiers on what their models generate, similarly as \citet{zhang2017investigation}.
Most of the time, these approaches rely on faint artifacts left by the vocoder that generate the final audio. 
Therefore, accuracy when comparing synthetic to real is usually good, although not performing well on out of distribution audios (compressed, noised, slowed, etc.).
For the same reason, the detection can be fooled by using a different vocoder (to generate synthetic audio that are not flagged) or by using the same vocoder on non-synthetic audios (to generate audios that spoof the detection).
This is highlighted in Sec.~\ref{chap4/sec:active-passive}, where we show that the detection fails on re-synthesized audio.

\paragraph{Invisible watermarking.} 
Traditional audio watermarking methods embed watermarks in the time or frequency domains, often using domain-specific features. 
Deep learning methods focus on multi-bit watermarking and follow a generator/decoder framework, as explained in Sec.~\ref{chap0/sec:watermarking}.
Few works have explored zero-bit watermarking~\citep{wu2023adversarial, juvela2023collaborative}, which is better adapted for detection of AI-generated content.
Our rationale is that robustness increases as the message payload is reduced to the bare minimum~\citep{furon2007constructive}.

In this study, we compare our work with the state-of-the-art watermarking method, WavMark~\citep{chen2023wavmark}, which outperforms previous ones. 
It uses invertible networks to hide 32 bits in 1-second audio segments.
Detection is done by sliding along the audio in 0.05s steps and decoding the message for each window.
If the 10 first decoded bits match a synchronization pattern the rest of the payload is saved (22 bits), and the window can directly slide 1s (instead of the 0.05).
This brute force detection algorithm is prohibitively slow especially when the watermark is absent, since the algorithm will have to attempt and fail to decode a watermark for each sliding window in the input audio (due to the absence of watermark).
