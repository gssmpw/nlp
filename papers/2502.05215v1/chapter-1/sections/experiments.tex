\newcommand{\rot}[1]{\rotatebox{60}{#1}}%

\section{Experiments and results}
\label{chap1/sec:experiments}

\subsection{Experimental setup and implementation details}\label{chap1/sec:exp_setup}

\paragraph*{Data.}
We evaluate our method on: 
1000 images of YFCC100M dataset~\citep{thomee2016yfcc100m} which is selected for the variety of its content, CLIC~\citep{2018clic} composed of 118 professional high-resolution images when comparing to~\citep{vukotic2020classification}, and 1000 images of MS-COCO~\citep{lin2014coco} composed of smaller images for comparison with~\citep{zhu2018hidden,luo2020distortion}.

\paragraph*{Backbone pre-training.}\label{chap1/par:backbone_pretraining} 
We use the ResNet-50 \citep{he2016deep} architecture as backbone model to extract features from its last convolutional layer ($d=2048$).
It is trained on ILSVRC2012~\citep{deng2009imagenet} without labels, using 200 epochs of DINO self-supervised learning with the default parameters~\citep{caron2021dino} and with rotation augmentation.
Models trained for classification come from the torchvision library~\citep{marcel2010torchvision}. 
The PCA-whitening is learned on 100k distinct images from YFCC (resp. COCO) when evaluating on YFCC and CLIC (resp. COCO).

\paragraph*{Embedding.}
We first set a desired FPR (which defines the hypercone angle $\theta$) and a target PSNR.
Watermarking~\eqref{chap1/eq:Watermarking} then uses the Adam optimizer~\citep{kingma2015adam} with learning rate $0.01$ over $100$ gradient descent iterations.
The weight in~\eqref{chap1/eq:global_loss} is set to $\lambda=1$ (zero-bit) or $\lambda=5\cdot 10^4$ (multi-bit). 
The margin of (\ref{chap1/eq:loss_multibit}) is set to $\mu=5$.

At each iteration, the preprocessing step performs the SSIM attenuation and clips the PSNR to the target. 
SSIM heatmaps are computed with $C_1=0.01^2$, $C_2=0.03^2$ and over $17\times 17$ tiles of the image's channels, then summed-up and clamped to be non negative, which generates a single heatmap per image. 
Then, a transformation $t$ is chosen randomly in $\mathcal T$ (identity, rotation, blur, crop or resize). 
The rotation angle $\alpha$ is sampled from a Von Mises distribution with $\mu=0$, $\kappa=1$ and divided by $2$. 
This generates angles in $\pi/2\times[-1,1]$ with a higher probability for small rotations, that are more frequent in practice. 
The crop and resize scales are chosen uniformly in $[0.2, 1.0]$. 
The crop aspect ratio is also randomly chosen between $3/4$ and $4/3$.
The blurring kernel size $b$ is randomly drawn from the odd numbers between $1$ and $15$ and $\sigma$ is set to $0.15 b+0.35$.
Finally, the image is flipped horizontally with probability $0.5$.

\paragraph*{Transformations.} 
\autoref{chap1/tab:transformations} presents the transformations used at pre-training, marking or evaluation stages. 
$p$ represents the cropping ratio in terms of area, $Q$ is the quality factor of the compression and $B$, $C$, $H$ are defined in~\citep{marcel2010torchvision}. 
``Meme format'' and ``Phone screenshot'' come from Augly~\citep{bitton2021augly}. 

\begin{table}[t]
    \centering
    \caption{Transformations used at pre-training, marking or evaluation stages.}\label{chap1/tab:transformations}
    \begin{tabular}{ l c|cc|cc }
        \toprule
                         &                  & \multicolumn{2}{c|}{Type} & \multicolumn{2}{c}{Used for}\\
        Transformations  & Parameter        & Geom. & Value   & Train & Mark\\ 
        \midrule
        Rotation         & angle $\alpha$    & \cmark & \xmark      & \cmark & \cmark \\
        Crop             & ratio $p$         & \cmark & \xmark      & \cmark & \cmark \\
        Resize           & scale $p$         & \cmark & \xmark      & \cmark & \cmark \\
        Gaussian Blur    & width $\sigma$    & \xmark & \cmark      & \cmark & \cmark \\
        Brightness       & $B$               & \xmark & \cmark      & \cmark & \xmark \\
        Contrast         & $C$               & \xmark & \cmark      & \cmark & \xmark \\
        Hue              & $H$               & \xmark & \cmark      & \cmark & \xmark \\
        JPEG             & quality $Q$       & \xmark & \cmark      & \xmark & \xmark \\
        Meme format      & -                 & \cmark & \cmark      & \xmark & \xmark \\
        Phone screenshot & -                 & \cmark & \cmark      & \xmark & \xmark \\
        \bottomrule
    \end{tabular}
\end{table}








\subsection{Qualitative results}\label{chap1/par:0bit_qualitative_results}

\autoref{chap1/fig:watermarked_imgs} presents an image watermarked at PSNR=40~dB and some detected alterations, as well as its pixel-wise difference w.r.t. the original image. 
The watermark is almost invisible even to the trained eye because it is added in the textured regions due to the perceptual SSIM normalization applied during watermarking.
We provide more examples of watermarked images in Fig.~\ref{chap1/fig:holidays_resized_multibit} and Fig.~\ref{chap1/fig:holidays}.

\begin{figure}[b!]
    \centering
    \includegraphics[width=0.8\linewidth]{chapter-1/figs/qual.pdf}
    \caption{Example of an image ($800\times 600$) watermarked at PSNR 40~dB and FPR=$10^{-6}$, and some detected alterations. The black and white picture on the bottom left corner shows the scaled amplitude of the watermark signal.
    \label{chap1/fig:watermarked_imgs}}
\end{figure}


\begin{figure}[H]
    \centering
    \begin{subfigure}[b]{0.9\textwidth}
        \includegraphics[width=\textwidth]{chapter-1/figs/holidays_0bit.png}
        \caption{The watermark is added with our zero-bit watermarking method with an FPR of $10^{-6}$ and with different values for the PSNR: $52$dB (top row), $40$dB (middle row), $32$dB (bottom row)}
        \label{chap1/fig:holidays_0bit}
    \end{subfigure} \\[1em]
    \begin{subfigure}[b]{0.9\textwidth}
        \includegraphics[width=\textwidth]{chapter-1/figs/holidays_multibit.png}
        \caption{The watermark is added with our multi-bit watermarking method with a payload of $30$ bits with the PSNR at $32$dB.}
        \label{chap1/fig:holidays_multibit}
    \end{subfigure}
       \caption{Watermarked images from the Holidays dataset (resolution $\approx 2048 \times 1536$).}
       \label{chap1/fig:holidays}
\end{figure}






\subsection{Zero-bit watermarking}

\paragraph*{Comparison with the state of the art.} 
\autoref{chap1/tab:0bit} compares our method with~\citep{vukotic2020classification} on CLIC. 
In their setup, the FPR=$10^{-3}$ and PSNR must be $\geq 42$dB.
Overall, our method gives better results on CLIC than on YFCC because images have higher resolutions (hence more pixels can be used to convey the mark). We observe a strong improvement over \citep{vukotic2020classification}, especially for large rotations, crops and Gaussian blur where our method yields almost perfect detection over the 118 images. 

\begin{table}[t!]
    \centering
    \caption{TPR over various attacks, at FPR$=10^{-3}$ and PSNR$\geq 42$~dB.
    1\textsuperscript{st} setup: performance with SSL vs supervised ResNet-50 networks on YFCC. 
    2\textsuperscript{nd} setup: evaluation over CLIC.
    ($\star$) best results in~\citep{vukotic2020classification} (VGG-19 trained on hard attacks and RMAC aggregation), ($\star \star$) our implementation of \citep{vukotic2020classification} (with default pre-trained VGG-19).
    $\dagger$ denotes augmentations used at pre-training. 
    }
    \label{chap1/tab:0bit}
    \resizebox{1.0\linewidth}{!}{
    \begin{tabular}{ l | >{\columncolor{gray!10}}cc|>{\columncolor{gray!10}}ccc}
        \toprule
        \multicolumn{1}{c}{}&  \multicolumn{2}{c}{Setup 1: YFCC}    &  \multicolumn{3}{c}{Setup 2: CLIC} \\
        \cmidrule(lr){2-3} \cmidrule(lr){4-6}
        Transformations     & SSL              & Sup.               & Ours                        & \citep{vukotic2020classification} ($\star$) & \citep{vukotic2020classification} ($\star\star$) \\ \hline
        Identity            & 1.00$^\dagger$   & 1.00$^\dagger$     &   1.00$^\dagger$            & 1.0$^\dagger$            & 1.00$^\dagger$  \\
        Rotation (25)       & 0.97$^\dagger$   & 0.54$^\dagger$     &   \textbf{1.00}$^\dagger$   & $\approx 0.3$$^\dagger$ & 0.27$^\dagger$  \\
        Crop (0.5)          & 0.95$^\dagger$   & 0.79$^\dagger$     &   1.00$^\dagger$            & $\approx 0.1$$^\dagger$ & 1.00$^\dagger$  \\
        Crop (0.1)          & 0.39$^\dagger$   & 0.06$^\dagger$     &   \textbf{0.98}$^\dagger$   & $\approx 0.0$$^\dagger$ & 0.02$^\dagger$  \\
        Resize (0.7)        & 0.99$^\dagger$   & 0.85$^\dagger$     &   1.00$^\dagger$            & -                        & 1.00$^\dagger$  \\
        Blur (2.0)          & 0.99$^\dagger$   & 0.04               &   \textbf{1.00}$^\dagger$   & -                        & 0.25  \\
        JPEG (50)           & 0.81             & 0.20               &   0.97                      & $\approx 1.0$            & 0.96  \\
        Brightness (2.0)    & 0.94$^\dagger$   & 0.71               &   0.96$^\dagger$            & -                        & 0.99  \\
        Contrast (2.0)      & 0.96$^\dagger$   & 0.65               &   1.00$^\dagger$            & -                        & 1.00  \\
        Hue (0.25)          & 1.00$^\dagger$   & 0.46               &   1.00$^\dagger$            & -                        & 1.00  \\
        Meme                & 0.99             & 0.94               &   1.00                      & -                        & 0.98  \\
        Screenshot          & 0.76             & 0.18               &   \textbf{0.97}             & -                        & 0.86  \\
        \bottomrule
    \end{tabular}
    }
\end{table}



\paragraph*{Trade-offs.}
The hypercone angle $\theta$ in~\eqref{chap1/eq:FPR} is given by the target FPR. %
A higher FPR implies a wider angle, making the method robust against more severe attacks, at the cost of detecting more false positives. 
The FPR is set to $10^{-6}$ in further experiments.
Large-scale applications usually operate at low FPR to avoid human verification.
As a sanity check we run detection on 100k natural images from YFCC, none of which are found to be marked. 
Similarly, there is only one false positive out of the 1,281,167 images of ImageNet.
Another trade-off lies in the imperceptibility, since allowing greater distortions (lower PSNR) improves the robustness.
It is illustrated in Fig.~\ref{chap1/fig:0bit_trade_offs}.


\begin{figure}[b!]
    \centering
    \begin{subfigure}[b]{0.95\linewidth}
        \includegraphics[width=\linewidth, trim={0 1.8em 0 0em},clip]{chapter-1/figs/0bit_fprs_arxiv.pdf}
    \end{subfigure}
    \begin{subfigure}[b]{0.95\linewidth}
        \includegraphics[width=\linewidth, trim={0 0em 0 2.em},clip]{chapter-1/figs/0bit_psnrs_arxiv.pdf}
    \end{subfigure}
    \caption{Robustness of the detection in the zero-bit setup against image transformations. \emph{Top:} PSNR set at 40~dB and FPR decreasing from \textcolor{BrickRed}{$10^{-2}$} (\textcolor{BrickRed}{red}) to \textcolor{Violet}{$10^{-12}$} (\textcolor{Violet}{blue}). \emph{Bottom:} FPR set at $10^{-6}$ and PSNR ranging from \textcolor{BrickRed}{52\,dB} to \textcolor{Violet}{32\,dB}.
    }
    \label{chap1/fig:0bit_trade_offs}
\end{figure}


\paragraph*{Ablation studies.}\label{chap1/par:0bit_quantitative_results}
We showcase the influence of self supervision at pre-training and of augmentation at marking time.
The performance measure is the True Positive Rate (TPR), at a target PSNR=40\,dB, and FPR=$10^{-6}$.
Fig.~\ref{chap1/fig:0bit_rotations} evaluates the robustness for the specific case of the rotation. 
Rotation augmentation is needed both at pre-training and marking stages to achieve high robustness against it.
Comparison on a wider range of transformations is given in Tab. \ref{chap1/tab:0bit}.

\begin{figure}[b!]
    \centering
    \includegraphics[width=0.9\linewidth,clip,trim={0 0em 15pt 0em}]{chapter-1/figs/0bit_rotations.pdf}
    \caption{Robustness against rotation. Each row (column) represents different $\pm$amplitude of the rotation at training (resp. marking~\eqref{chap1/fig:0bit_rotations}). 
    }
    \label{chap1/fig:0bit_rotations}
\end{figure}



\subsection{Multi-bit data hiding}\label{chap1/sec:multibit_exp}


\begin{figure}[b!]
    \includegraphics[width=\textwidth]{chapter-1/figs/holidays_resized_multibit_v2.png}
    \caption{Watermarked images from the Inria Holidays dataset resized to $128 \times 128$. The watermark is added with our multi-bit watermarking method with a payload of $30$ bits and with different values for the target PSNR: $52$dB (top row), $40$dB (middle row), $32$dB (bottom row). 
    We use a 5-bits character encoding to encode and decode one message per image, and show the decoded messages for each image (without any transformation applied to the image). The higher the PSNR, the higher the decoding errors, and the less robust the decoding is to transformations.}
    \label{chap1/fig:holidays_resized_multibit}
\end{figure}



\paragraph*{Quantitative results.}\label{chap1/par:multibit_quantitative_results}
We evaluate the method on YFCC, with  a target PSNR of 40~dB and a payload $k$ of $30$ random bits as in~\citep{zhu2018hidden,luo2020distortion}.
\autoref{chap1/tab:multibit_30} presents the Bit and Word Error Rate (BER and WER) over various attacks. The decoding achieves low rates over a wide range of geometric (rotation, crops, resize, etc.) and valuemetric (brightness, hue, contrast, etc.) attacks.
Rotation and Gaussian blur are particularly harmless since they are seen both at pre-training and at marking time.
Some images are harder to mark, which can be observed statistically on the empirical WER reported in Tab.~\ref{chap1/tab:multibit_30}. 
If all images were as difficult to mark, then BER would be equal for all images, and $\mathrm{WER} =1- (1-\mathrm{BER})^{k}$. 
Yet, the reported WER are significantly lower: \eg, for Brightness, $\mathrm{WER} = 0.607 < 1-(1-0.087)^{30} = 0.935$. 
Empirically, we see that images with little texture are harder to watermark than others, due to the SSIM normalization.
In practice, ECC can be used to achieve lower WERs.

\begin{table}[t]
    \centering
    \caption{\makebox{BER and WER (\%) for $30$-bits encoding at PSNR~40dB.}}
    \label{chap1/tab:multibit_30}
    \resizebox{1.0\linewidth}{!}{
    \begingroup
        \setlength{\tabcolsep}{3pt}
            \begin{tabular}{ c| *{12}{c}}
            \multicolumn{1}{c}{\rot{Transform.}} & \rot{Identity} & \rot{Rot. (25)} & \rot{Crop (0.5)} & \rot{Crop (0.1)} & \rot{Res. (0.7)} & \rot{Blur (2.0)} & \rot{JPEG (50)} & \rot{Bright. (2.0)} & \rot{Contr. (2.0)} & \rot{Hue (0.25)} & \rot{Meme} & \rot{Screenshot} \\ \midrule
            BER  & 0.1   & 3.3    & 4.8    & 28.9   & 2.1    & 0.5  & 20.8   & 8.7   & 8.4   & 2.5   & 6.4    & 23.9  \\
            WER  & 0.7   & 43.4   & 58.3   & 100    & 29.1   & 4.6  & 98.9   & 60.7  & 62.6  & 31.6  & 75.9   & 100   \\
            \bottomrule
    \end{tabular}
    \endgroup
    }
\end{table}




\soutx{\begin{figure}[b!]
    \centering
    \includegraphics[width=\textwidth]{chapter-1/figs/multibit_numbits.pdf}
    \caption{Illustration of the Capacity/Robustness trade-off. The length of the message increases from $10$ (purple) to $100$ (red): short messages are more robust to transformations than long ones.
    The target PSNR is set to $40$.}
    \label{chap1/fig:multibit_numbits}
\end{figure}}

\soutx{\begin{figure}[b!]
    \centering
    \includegraphics[width=\textwidth]{chapter-1/figs/multibit_psnrs.pdf}
    \caption{Illustration of the Quality/Robustness trade-off. The PSNR of the watermarked images increases from $32$ (purple) to $52$ (red): better robustness is achieved for lower quality images. The length of the message is set to $30$.}
    \label{chap1/fig:multibit_psnrs}
\end{figure}}

\paragraph*{Qualitative results.}
We notice that the watermark is perceptually less visible for multi-bit than for zero-bit watermarking at a fixed PSNR. 
Our explanation is that the energy put into the image feature is more spread-out across carriers in the multi-bit setup than on the zero-bit one where the feature is pushed as much as possible towards a single carrier.



\begin{table}[t!]
    \centering
    \caption{Comparison of BER. The first row uses original resolutions of COCO, while the others use a resized version (to $128 \times 128$). Results for \citep{zhu2018hidden, luo2020distortion} come from \citep{luo2020distortion}. $\dagger$ denotes transformations used in the watermarking process.
    }
    \vspace{-0.3cm}
    \label{chap1/tab:multibit_coco}
    \resizebox{1.0\linewidth}{!}{
    \begin{tabular}{ c|llllll}
        \multicolumn{1}{c}{Transformation} & \rotatebox{45}{Identity} & \rotatebox{45}{JPEG (50)} & \rotatebox{45}{Blur (1.0)} & \rotatebox{45}{Crop (0.1)}  & \rotatebox{45}{Resize (0.7)} & \rotatebox{45}{Hue (0.2)} \\ \midrule
        \rowcolor{Orchid!20} Ours                      & 0.00$^\dagger$ & 0.04           & 0.00$^\dagger$          & 0.18$^\dagger$            & 0.00$^\dagger$ & 0.03          \\ \midrule
        \rowcolor{gray!10} Ours, $128 \times 128$                          & 0.00$^\dagger$ & 0.16  & 0.01$^\dagger$ & 0.45$^\dagger$            & 0.18$^\dagger$ & 0.06 \\
        HiDDeN~\citep{zhu2018hidden}                     & 0.00$^\dagger$ & 0.23$^\dagger$ & 0.01$^\dagger$ & 0.00$^\dagger$   & 0.15           & 0.29          \\
        Dist. Agnostic~\citep{luo2020distortion}         & 0.00$^\dagger$ & 0.18$^\dagger$ & 0.07$^\dagger$          & 0.02$^\dagger$            & 0.12  & 0.06 \\
        \bottomrule
    \end{tabular}
    }
\end{table}

\paragraph*{Comparison with the state of the art.}
\autoref{chap1/tab:multibit_coco} compares against two deep data hiding methods~\citep{zhu2018hidden,luo2020distortion} using their setting: a payload of $30$ bits, a target PSNR of 33dB, over $1000$ images from COCO resized to $128 \times 128$. 
Overall, our method gives comparable results to the state of the art, except for the center crop transform where it fails to achieve high bit accuracies. 
Note also that the resize operation is not used as noise layer in neither of~\citep{zhu2018hidden,luo2020distortion}, which means that our method should have the advantage.
In contrast, while these methods are trained to be robust to JPEG compression with a differentiable approximation, our method achieves similar performance without specific training.

Furthermore, our method easily scales to higher resolution images, where it achieves lower BER for a fixed payload. 
We assume that \citep{zhu2018hidden,luo2020distortion} also scales but at the cost of a specific training, or at least a fine-tuning, for a given resolution. 
This training is more computationally expensive since the message is repeated at each pixel~\citep{zhu2018hidden}. 
It also needs a smaller batch-size to operate larger images, and new hyperparameters values.






