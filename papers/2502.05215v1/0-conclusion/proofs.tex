

\section{Demonstration of the hypercone volume}
\label{app/ssl-watermarking}

\paragraph*{Proposition.}
Let a secret key $a\in \mathbb R ^d$ s.t. $\|a\|=1$, $\theta \in (0, \pi/2)$ and the dual hypercone:
\begin{equation*}
     \mathcal{D} := \left\{  x \in \R^d :  \abs{ x\T  a} > \norm{ x} \cos (\theta) \right\}.
\end{equation*}
We have:
\begin{equation*}
   \mathbb{P}\left(\phi(I)\in \mathcal D \mid \text{``key } a \text{ uniformly distributed''}\right)
    = 1-I_{\cos^2(\theta)} \left(\frac{1}{2}, \frac{d-1}{2} \right)
\end{equation*}
where $I_\tau (\alpha, \beta)$ is the regularized Beta incomplete function.

\paragraph*{Proof.}
Let $ U $ be a random vector uniformly distributed on the unit sphere of $ \mathbb{R}^d $ ($\|U\| = 1$) and $ v $ a fixed vector of the same hypersphere. 
We are interested in the distribution of the cosine similarity, which is in this case $U^\top v$.

One way to sample $U$ is the following: First sample a white Gaussian vector $G \sim \mathcal{N}(0,I)$ in $\mathbb R ^d$ and then normalize: $U=G/\norm{G}$.
Without loss of generality, we can assume that $v = (1,0,...,0)$ (up to a change of axes). Therefore, $$U^T v = \frac{G_1}{\sqrt{\sum_{i=1}^d G_i^2}}$$
Let $\tau \in [0,1]$. We have 
\begin{align*}
    \mathbb{P}\left((U^T v)^{2} \geq \tau^{2}\right) &=\mathbb{P}\left(\frac{G_{1}^{2}}{\sum_{i=1}^{d} G_{i}^{2}} > \tau^{2}\right)
    =\mathbb{P}\left(\frac{G_{1}^{2}}{\sum_{i=2}^{d} G_{i}^{2}} > \frac{\tau^{2}}{1-\tau^{2}}\right)\\
    &=\mathbb{P}\left((d-1)\frac{G_{1}^{2}}{\sum_{i=2}^{d} G_{i}^{2}} > (d-1)\frac{\tau^{2}}{1-\tau^{2}}\right)
\end{align*}
Note that $Y := (d-1)\frac{G_{1}^{2}}{\sum_{i=2}^{d} G_{i}^{2}}$ is the ratio of two independent chi-squares random variables of degree 1 and $d-1$. By definition, $Y$ follows a Fisher distribution $F(1,d-1)$. Its cumulative density function is: $F(x; 1, d-1) = I_{x/(x+d-1)}(1/2, (d-1)/2)$. 

It follows, using $x=(d-1)\frac{\tau^2}{1-\tau^2} = -(d-1) + (d-1)\frac{1}{1-\tau^2}$ and setting $\tau = \cos\theta$, that:
$$\mathbb P (\abs{U^T v} > \cos \theta) = \mathbb P (Y> \cos^2 \theta) = 1 - I_{\cos^2 \theta}(1/2, (d-1)/2),$$
where $I_x(a,b)$ is the regularized incomplete beta function.
(It also equals $ I_{\sin^2 \theta}( (d-1)/2,1/2)) $ by symmetry of the beta function.)

Finally, since 
$$\mathbb{P}\left(\phi(I)\in \mathcal D \mid \text{``key } a \text{ uniformly distributed''}\right) = \mathbb{P}\left(\abs{U^T \phi(I)} > \cos \theta\right),$$
we have the result.





\section{Demonstrations for \texorpdfstring{\cite*{aaronson2023watermarking}}{}}\label{app/three-bricks}

We here provide the proofs of the LLM watermarking results presented by~\cite{aaronson2023watermarking}, which are absent from the literature.

\subsection{Sampling probability}
\label{chap5/app:aaronson_prob}

\paragraph*{Proposition.}
Consider a discrete distribution $\vec{p}=(p_1,\ldots,p_V)$
and $V=|\V |$ random variables $\vec{R} = (R_1,\ldots,R_V)$ s.t. $R_v\overset{iid}{\sim}\mathcal{U}_{[0,1]}$. 
Let $V^\star = \arg \max_v R_v^{1/p_v}$.
Then: $$\Prob(V^\star=v) = p_v.$$

\paragraph*{Proof.}
For any $v \in \V$, $R_v\overset{iid}{\sim}\mathcal{U}_{[0,1]}$ so, $- \ln(R_v)$ follows an exponential distribution $\mathcal{E}(1)$.
Let $Z_v := -\frac{1}{p_v} \ln(R_v)$. By construction, $Z_v\sim\mathcal{E}(p_v)$, with density $f_{Z_v}(z) = p_v e^{-p_v.z}$.
We now have:
\begin{equation}
V^\star = \arg \max_v R_v^{\frac{1}{p_v}} = \arg \min_v Z_v.
\end{equation}
A well known result about exponential laws is that (see \href{https://francisbach.com/the-gumbel-trick/}{the-gumbel-trick} for following lines):
\begin{eqnarray}
\underline{Z}  &=& \min_v Z_v \sim \mathcal{E}\left(\sum_v p_v\right)=\mathcal{E}\left(1\right),\\ \label{chap5/eq:sampling}
\Prob(V^\star=v) &=& \frac{p_v}{\sum_j p_j}  = p_v.
\end{eqnarray}

This shows that for a given secret vector $\vec{r}$, the watermarking chooses a word which may be unlikely (low probability $p_{V^\star}$). 
Yet, on expectation over the secret keys, \ie, over r.v. $\vec{R} = (R_1, \ldots, R_V)$, the distribution of the chosen token follows the distribution given by the LLM.

\paragraph*{Corollary.} $R_{V^\star} \sim Beta(1/p_{V^\star}, 1)$.

\paragraph*{Proof.}
\begin{equation}
\underline{Z}  = Z_{V^\star} = -\frac{1}{p_{V^\star}} \ln(R_{V^\star}) \sim \mathcal{E}(1),
\label{chap5/eq:Coro}
\end{equation}
which translates to $R_{V^\star} = e^{-p_{V^\star} E}$ with $E\sim\mathcal{E}(1)$, with p.d.f. $f_{R_{V^\star}}(r) = \frac{r^{\frac{1}{p_{V^\star}}-1}}{p_{V^\star}}$. 
Therefore, $R_{V^\star} \sim Beta(1/p_{V^\star}, 1)$.

\subsection{Detection}
\label{chap5/app:aaronson_score}

We denote by $x^{(1)}, \ldots, x^{(T)}$ the sequence of tokens in the text, 
by $\vec{p}^{(t)}$ the probability vector output by the LLM and by $\vec{R}^{(t)} \in [0,1]^{|\mathcal{V}|}$ the key random vector at time-step $t$.
We define $R_t := R^{(t)}_{x^{(t)}}$ and $p_t := p^{(t)}_{x^{(t)}}$ at time-step $t$.
The score is $S_T=-\sum_{t=1}^{T} \ln (1-R_t)$.

\paragraph*{Proposition ($p$-value under $\H_0$).}
The $p$-value associated to a score $s$ is defined as:
\begin{equation}
\text{$p$-value}(s) = \Prob(S_T>s \mid \H_0) = \frac{\Gamma(T,s)}{\Gamma(T)},
\end{equation}
where $\Gamma(T,s)$ is the \emph{upper} incomplete gamma function.

\paragraph*{Proof.}
Under $\H_0$, the assumption is s.t. $R_t\overset{iid}{\sim}\mathcal{U}_{[0,1]}$. 
Then, $- \ln(1-R_t)$ follows an exponential distribution $\mathcal{E}(1)$.
Therefore $S\sim\Gamma(T,1)$ (see \href{https://en.wikipedia.org/wiki/Gamma_distribution#Summation}{sum of Gamma distributions}). Therefore the $p$-value associated to a score $s$ is 
\begin{equation}
    \text{$p$-value}(s) = 1 - \frac{\gamma(T,s)}{\Gamma(T)} = \frac{\Gamma(T, s)}{\Gamma(T)} ,
\end{equation}
where $\Gamma(T,s)$ is the \emph{upper} incomplete gamma function, $\gamma(T,s)$ is the \emph{lower} \href{https://en.wikipedia.org/wiki/Incomplete_gamma_function}{incomplete gamma function}. 

\paragraph*{Corollary.} Per token, 
\begin{equation}
\mu_0 = \E(S_T/T|\H_0) = 1,\quad \sigma_0^2 = \mathbb{V}(S_T/T|\H_0) = 1/T.
\end{equation}

\paragraph*{Proposition (Bound on expected score under $\H_1$).}
Under $\H_1$, 
$\displaystyle \mathbb{E}(S_T) \geq T +  \left( \frac{\pi^2}{6} -1 \right) H_T $, 
where $H_T = - \sum_{t=1}^T p_t\ln(p_t)$ is the entropy of the completion.

\paragraph*{Proof.}
From~\eqref{chap5/eq:Coro}, $R_t=\exp(-p_t E)$ with $E\sim \mathcal{E}(1)$, so:
\begin{align*}
    \mathbb{E}(S) &= - \mathbb{E} \left[ \sum_{t=1}^T \ln (1-\exp(-p_t E)) \right] \\
    &= - \sum_{t=1}^T \int_0^\infty \ln (1-e^{-p_t x}) e^{-x} dx \\
    &= - \sum_{t=1}^T \int_0^1 \frac{1}{p_t} r^{1/p_t-1} (-\ln ( 1 - r)) dr  \\ 
    & \text{ \qquad (by change of variable $x = -1/p_t \ln (r) $ )} 
\end{align*}
Then, using integration by parts with $u = 1 - r^{1/p_t}$ and $v = \ln(1-r)$, the integral becomes:
\begin{align*}
    -\int_0^1 \frac{1}{p_t} r^{1/p_t-1} \ln ( 1 - r) dr &= \int_0^1 \frac{1-r^{1/p_t}}{1-r} dr = \H_{1/p_t}
\end{align*}
where $\H_{z}$ is the $z$-th \href{https://en.wikipedia.org/wiki/Harmonic_number}{harmonic number}
also defined as $\H_{z} = \sum_{n=1}^\infty \frac{1}{n} - \frac{1}{n+z}$.
Therefore, we have:
\begin{align*}
    -\int_0^1 \frac{1}{p_t} r^{1/p_t-1} \ln ( 1 - r) dr &= 
        \sum_{n=1}^\infty \frac{1}{n} - \frac{1}{n+1/p_t} \\
    &= 1 + \sum_{n=1}^\infty \frac{1}{n+1} - \frac{1}{n+1/p_t}.
\end{align*}
Now, $\forall n\in \mathbb{N^\star}$, we have:
\begin{align*}
   (n+1)^2 \left(\frac{1}{n+1} - \frac{1}{n+1/p_t}\right) &= \frac{(n+1)(n+1/p_t) - (n+1)^2}{n + 1/p_t} \\
    &=  \frac{1+n}{1/p_t + n} \left( 1/p_t -1\right) \\
    &\geq -  \frac{1+n}{1/p_t + n} \ln(p_t) \\
    &\geq -  \, p_t \ln(p_t).
\end{align*}
Therefore, by summing over all $t\in [1,T]$,
\begin{align*}
    \mathbb{E}(S) &\geq T +  \left(\sum_{n=1}^\infty \frac{1}{(n+1)^2}\right)\left(\sum_{t=1}^T- p_t\ln(p_t) \right) \\
    &=T +  \left( \frac{\pi^2}{6} -1 \right) H_T.
\end{align*}

\paragraph*{Proposition (Variance of score under $\H_1$).}
$\displaystyle\mathbb{V}(S_T)\leq T\frac{\pi^2}{6}$.

\paragraph*{Proof.}
For $R_{t}\sim Beta(1/p_t, 1)$:
\begin{equation}
\mathbb{V}(\ln(1-R_t)) = \psi_1(1) - \psi_1(1+1/p_t)
\end{equation}
where $\psi_1$ is the trigamma function, which can be expressed as the following serie $\psi_1(z) = \sum_{n=0}^{\infty} 1/(n+z)^2$. 
Then $\psi_1(1) = \pi^2/6$ and $\psi_1(1+1/p_t)>0$, so that $\mathbb{V}(\ln(1-R_t)) \leq \pi^2/6$.
The results comes because the sampled tokens are independent. 

