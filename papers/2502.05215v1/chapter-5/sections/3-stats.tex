



\begin{figure}[b!]
    \centering
    \begin{subfigure}{0.8\textwidth}
        \includegraphics[width=\textwidth, trim=0 0 0 0, clip]{chapter-5/figs/pval-emp.pdf}
        \vspace{-0.6cm}
        \caption{Empirical \pval\ distribution without any correction.}
        \label{chap5/fig:pvalue}
    \end{subfigure}
    \\[0.5cm]
    \centering
    \begin{subfigure}{1.0\textwidth}
        \includegraphics[height=1.8in, trim=0.2cm 0 0.3cm 0, clip]{chapter-5/figs/fpr_zscore.pdf}
        \includegraphics[height=1.8in, trim=0.6cm 0 0.3cm 0, clip]{chapter-5/figs/fpr.pdf}
        \includegraphics[height=1.8in, trim=0.6cm 0 0.3cm 0, clip]{chapter-5/figs/fpr_rect.pdf}
        \caption{
            Empirical FPRs against theoretical ones.
            (\emph{Left}) using $Z$-tests;
            (\emph{Middle}) using new statistical tests presented in~\ref{chap5/sec:new-stats};
            (\emph{Right}) using the new statistical tests with the rectified scoring strategy of~\ref{chap5/sec:rect}.
        }\label{chap5/fig:fpr}
    \end{subfigure} \\
    \caption{
        Empirical checks of \pval\ and false positive rates for different watermarks and values of the context width $k$.
        Results are computed over $10$ secret keys $\times$ 100k sequences of $256$ tokens sampled from Wikipedia.
        Theoretical values do not hold in practice for $Z$-tests even for high values of $k$: \pval s are not uniformly distributed and empirical FPRs do not match theoretical ones.
        This is solved by basing detection on grounded statistical tests and analytic \pval, as well as by revising the scoring strategy with deduplication.
    }
\end{figure}


\section{Ensuring reliable \pval\ and FPR}\label{chap5/sec:stats}

In this section, large-scale evaluations of the FPR show a gap between theory and practice. 
It is closed with new statistical tests and by rectifying the scoring method.


\subsection{Empirical validation of FPR with Z-scores}\label{chap5/sec:zscore}

So far, the FPR has been checked on only around $500$ negative samples~\citep{kirchenbauer2023watermark,kirchenbauer2023reliability, zhao2023provable}.
We scale this further and select $100$k texts from multilingual Wikipedia to cover the distribution of natural text.
We tokenize with Llama's tokenizer, and take $T=256$ tokens/text.
We run detection tests with varying window length $k$ when seeding the RNG. 
We repeat this with $10$ different secret keys, which makes $1$M detection results under $\H_0$ for each method and $k$ value.
For the detection of the greenlist watermark, we use $\gamma=0.25$.

\autoref{chap5/fig:pvalue} first shows that the distribution of \pval s is not uniform.
his should be the case for a $Z$-test under $\H_0$, which calls into question whether this type of test can be used here.
To further emphasize this point, \autoref{chap5/fig:fpr} compares empirical and theoretical FPRs.
Theoretical guarantees do not hold in practice and empirical FPRs are much higher than the theoretical ones.
Besides, the larger the watermarking context window $k$, the closer we get to theoretical guarantees. 
In pratice, one would need $k>>8$ to get reliable \pval, but this makes the watermarking method less robust to attacks on generated text because it hurts synchronization.


\subsection{New non-asymptotical statistical tests}\label{chap5/sec:new-stats}

The Gaussian assumption of $Z$-tests breaks down for short or repetitive texts.
Here are non-asymptotical tests for both methods that reduce the gap between empirical and theoretical FPR, especially at low FPR values as shown in Fig.~\ref{chap5/fig:fpr}.

\paragraph*{\texorpdfstring{\citep{kirchenbauer2023watermark}}{}} 
Under $\H_0$, we assume that the event $x^{(t)}\in\G^{(t)}$ occurs with probability $\gamma$, and that these events are i.i.d.
Therefore, $S_T$~\eqref{chap5/eq:score-kirchenbauer} is distributed as a binomial of parameters $T$ and $\gamma$. Consider a text under scrutiny whose score equals $s$.
The \pval\ is defined as the probability of obtaining a score higher than $s$ under $\H_0$: %
\begin{equation}
    \text{p-value}(s) = \Prob(S_T \geq s \mid \H_0) = I_{\gamma}(s,T-s+1).
\end{equation}
This comes from the fact that $S\sim\mathcal{B}(T,\gamma)$ whose c.d.f. is expressed by $I_x(a,b)$ the regularized incomplete Beta function.

\paragraph*{\texorpdfstring{\citep{aaronson2023watermarking}}{}} 
Under $\H_0$, we assume that the text under scrutiny and the secret vector are independent, so that $\vec{r}_{x^{(t)}} \overset{i.i.d.}{\sim} \mathcal{U}(0,1)$. 
Therefore, $S_T$~\eqref{chap5/eq:score-aaronson} follows a $\Gamma(T,1)$ distribution.
The \pval\ associated to a score $s$ reads:
\begin{equation}
    \text{p-value}(s) = \Prob(S_T \geq s \mid \H_0) = \frac{\Gamma(T,s)}{\Gamma(T)},
\end{equation}
where $\Gamma$ is the upper incomplete gamma function.
Under $\H_1$, the score is expected to be higher as proven in App.~\ref{chap5/app:aaronson_score}, so the \pval\ is likely to be small.




    
    


\subsection{Rectifying the detection scores}\label{chap5/sec:rect}


\begin{figure}[b!]
    \centering
    \begin{tcolorbox}[width=0.7\linewidth, colframe=metablue, colback=white]
        \includegraphics[width=0.99\linewidth, trim=0 110 0 18, clip]{chapter-5/figs/low-pval-text.pdf}
    \end{tcolorbox}
    \centering
    \caption{
    Typical example of a non-watermarked text with low \pval\ because of repeated tokens (we only show half of the text).
    Here \pval$=10^{-21}$ on $256$ tokens.
    }
    \label{chap5/fig:low-pval-text}
\end{figure}

Even with grounded statistical tests, empirical FPRs are still higher than theoretical ones.
In fact, \citet{kirchenbauer2023watermark} mention that random variables are only pseudo-random since repeated windows generate the same secret. 
This can happen even in a short text and especially in formatted data.
For instance in a bullet list, the sequence of tokens \texttt{$\backslash$n$\backslash$n*\_} repeats a lot as shown in Fig.~\ref{chap5/fig:low-pval-text}.
In this text of $256$ tokens, the \pval\ is $10^{-21}$ for the scheme of~\citet{kirchenbauer2023watermark} and with $\gamma=0.25$ and $k=2$.
Repetition pulls down the assumption of independence necessary for computing the \pval.

We experiment with two simple heuristics mitigating this issue.
The first one takes into account a token only if the watermark context window has not already been seen during the detection.
The second scores the tokens for which the $k+1$-tuple formed by \{watermark context + current token\} has not already been seen.
Note, that the latter is present in~\citep{kirchenbauer2023watermark}, although without ablation and without being used in further experiments.
Of the two, the second one is better since it counts more ngrams, and thus has better TPR. 
It can also deal with the specific case of $k=0$.
\autoref{chap5/fig:fpr} reports empirical and theoretical FPRs when choosing not to score already seen $k+1$-tuples.
They now match perfectly, except for $k=0$ where the FPR is still slightly underestimated.
\emph{In short, we guarantee FPR thanks to new statistical tests and by scoring only tokens for which \{watermark context + current token\} has not been scored.}
