\section{Introduction}\label{chap2/sec:intro}

\begin{figure}[t]
    \centering
    \includegraphics[width=1.0\textwidth]{chapter-2/figs/fig1.pdf}
    \caption{ 
    Overview of the method and 
        latent space representation. 
        We start from an original image $I_o$ that can be edited $t(\cdot)$ in various ways: its feature extraction $f(t(I_o))$ spawns the shaded region in the embedding space.
        The edited versions should be recoverable by nearest neighbor search on quantized representations.
        In the regular (non-active) case, $f(I_o)$ is quantized by the index as \includegraphics[width=0.5em]{chapter-2/figs/assets/c1.pdf}. 
        When the image is edited, $t(I_o)$ switches cells and the closest neighbor returned by the index is the wrong one \includegraphics[width=0.5em]{chapter-2/figs/assets/c2.pdf}.
        In active indexing: $I_o$ is modified in an imperceptible way to generate $I^\acti$ such that $f(I^\acti)$ is further away from the boundary. 
        When edited copies $f(t(I^\acti))$ are queried, retrieval errors are significantly reduced.
    \label{chap2/fig:fig1}}
\end{figure}

The traceability of images on a media sharing platform is a challenge: 
they are widely used, easily edited and disseminated both inside and outside the platform.
In this chapter, we tackle the corresponding task of image \gls*{copy detection} (ICD), \ie, finding whether an image already exists in the database; and if so, give back its identifier.
ICD methods power reverse search engines, photography service providers checking copyrights, or media platforms moderating and tracking down malicious content (\eg, PhotoDNA~\citep{photodna} or NeuralHash~\citep{apple2021csamdetection}).
Image identification systems have to be robust to identify images that are edited (cropping, colorimetric change, JPEG compression \ldots) after their release~\citep{douze2021disc, wang2022benchmark}. 

The common approach for content-based image retrieval reduces images to high dimensional vectors, referred to as \emph{representations}. 
Early representations used for retrieval were hand-crafted features such as color histograms~\citep{swain1991color}, GIST~\citep{oliva2001modeling}, or Fisher Vectors~\citep{perronnin2010large}.
As of now, a large body of work on self-supervised learning focuses on producing discriminative representations with deep neural networks, which has inspired recent ICD systems. 
In fact, \emph{all} submissions to the NeurIPS2021 Image Similarity challenge~\citep{papakipos2022results} exploit neural networks.
They are trained to provide invariance to potential image transformations, akin to data augmentation in self-supervised learning.  

Scalability is another key requirement of image similarity search: searching must be fast on large-scale databases, which exhaustive vector comparisons cannot do.
In practice, ICD engines like \Gls*{FAISS} leverage approximate neighbor search algorithms, that trade search accuracy against scalability.
They speed up the search by \emph{not} computing the exact distance between all representations in the dataset~\citep{johnson2019faiss, guo2020scann}.
First they lower the number of scored items by partitioning the representation space, and evaluate the distances of only a few subsets. 
Second, they reduce the computational cost of similarity evaluation with quantization or binarization.
These mechanisms make indexing methods subject to the curse of dimensionality.
In particular, in high-dimensional spaces, vector representations lie close to boundaries of the partition~\citep{bohm2001searching}.
Since edited versions of an original image have noisy vector representations, they sometimes fall into different subsets or are not quantized the same way by the index. 
All in all, it makes approximate similarity search very sensitive to perturbations of the edited image representations, which causes images to evade detection.

In this chapter, we introduce a method that improves similarity search on large databases, provided that the platform or photo provider can modify the images before their release, as in watermarking (see Fig.~\ref{chap2/fig:fig1}). 
We put the popular saying ``attack is the best form of defense'' into practice by applying image perturbations and drawing inspiration from adversarial attacks. 
Indeed, representations produced with neural networks are subject to \emph{adversarial examples}~\citep{szegedy2013intriguing}:
small perturbations of the input image can lead to very different vector representations, making it possible to 
create adversarial queries that fool image retrieval systems~\citep{liu2019whos, tolias2019targeted,dolhansky2020adversarial}.
In contrast, we modify an image to make it \emph{more} indexing friendly.  
With minimal changes in the image domain, the image representation is pushed towards the center of the indexing partition, rising the odds that edited versions will remain in the same subset. 
This property is obtained by minimizing an indexation loss by gradient descent back to the image pixels, like for adversarial examples.
For indexing structures based on product quantization~\citep{jegou2010pq}, this strategy amounts to pushing the representation closer to its quantized codeword, in which case the indexation loss is simply measured by the reconstruction error.
Since the image quality is an important constraint here, the perturbation is shaped by perceptual filters to remain invisible to the human eye. 

Our contributions are:
\begin{itemize}[leftmargin=1cm,itemsep=0cm,topsep=-0.1cm]
    \item a new approach to improve ICD and retrieval, when images can be changed before release;
    \item an adversarial image optimization scheme that adds minimal perceptual perturbations to images in order to reduce reconstruction errors, and improve vector representation for indexing;
    \item experimental evidence that the method significantly improves index performance.
\end{itemize}
