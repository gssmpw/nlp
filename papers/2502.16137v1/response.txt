\section{Related Work}
We outline some related work and explain how our approach differs from these efforts.

Chain-of-Thought **Haines et al., "Improving Reasoning in Text-based Dialogue Systems"** primarily aims to enhance the reasoning capabilities of text LLMs by breaking down problems into step-by-step solutions. Our method is inspired by CoT, but our CoD is not a variant of CoT; it is a new strategy specifically designed for multi-modal inputs. In theory, CoD and CoT could be combined to bolster the performance of MLLMs.

**Li et al., "Improving Language Models with Contrastive Learning"** focuses only on LVLMs and also mentions descriptions. However, their descriptions are related directly to the questions. In contrast, we do focus not on specific questions but explore a more general scenario and verify its effectiveness.
**Bao et al., "Fooling Neural Networks with Adversarial Examples"** also concentrates on LVLMs, but their study emphasizes enhancing reasoning tasks, proposing rationale generation before answer inference. Our work is not limited to reasoning tasks but targets more general scenarios. 
**Rae et al., "Composable Vision-and-Language Pre-training for Code Generation"** introduced a method with the same name as ours, but their research direction is about improving the performance of Code LLM.