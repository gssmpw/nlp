@article{vc-survey-taslp,
  author       = {Berrak Sisman and
                  Junichi Yamagishi and
                  Simon King and
                  Haizhou Li},
  title        = {An Overview of Voice Conversion and Its Challenges: From Statistical
                  Modeling to Deep Learning},
  journal      = {{IEEE} {ACM} Trans. Audio Speech Lang. Process.},
  volume       = {29},
  pages        = {132--157},
  year         = {2021}
}

@article{accent-conversion-2009,
  author       = {Daniel Felps and
                  Heather Bortfeld and
                  Ricardo Gutierrez{-}Osuna},
  title        = {Foreign accent conversion in computer assisted pronunciation training},
  journal      = {Speech Commun.},
  volume       = {51},
  number       = {10},
  pages        = {920--932},
  year         = {2009}
}

@article{esd,
  author       = {Kun Zhou and
                  Berrak Sisman and
                  Rui Liu and
                  Haizhou Li},
  title        = {Emotional voice conversion: Theory, databases and {ESD}},
  journal      = {Speech Commun.},
  volume       = {137},
  pages        = {1--18},
  year         = {2022}
}

@book{tts-book-tanxu,
  author       = {Xu Tan},
  title        = {Neural Text-to-Speech Synthesis},
  publisher    = {Springer},
  year         = {2023}
}

@inproceedings{speechsplit,
  author       = {Kaizhi Qian and
                  Yang Zhang and
                  Shiyu Chang and
                  Mark Hasegawa{-}Johnson and
                  David D. Cox},
  title        = {Unsupervised Speech Decomposition via Triple Information Bottleneck},
  booktitle    = {{ICML}},
  series       = {Proceedings of Machine Learning Research},
  volume       = {119},
  pages        = {7836--7846},
  publisher    = {{PMLR}},
  year         = {2020}
}

@inproceedings{speech-resynthesis-interspeech21,
  author       = {Adam Polyak and
                  Yossi Adi and
                  Jade Copet and
                  Eugene Kharitonov and
                  Kushal Lakhotia and
                  Wei{-}Ning Hsu and
                  Abdelrahman Mohamed and
                  Emmanuel Dupoux},
  title        = {Speech Resynthesis from Discrete Disentangled Self-Supervised Representations},
  booktitle    = {{INTERSPEECH}},
  pages        = {3615--3619},
  publisher    = {{ISCA}},
  year         = {2021}
}

@inproceedings{ns3,
  author       = {Zeqian Ju and
                  Yuancheng Wang and
                  Kai Shen and
                  Xu Tan and
                  Detai Xin and
                  Dongchao Yang and
                  Eric Liu and
                  Yichong Leng and
                  Kaitao Song and
                  Siliang Tang and
                  Zhizheng Wu and
                  Tao Qin and
                  Xiangyang Li and
                  Wei Ye and
                  Shikun Zhang and
                  Jiang Bian and
                  Lei He and
                  Jinyu Li and
                  Sheng Zhao},
  title        = {NaturalSpeech 3: Zero-Shot Speech Synthesis with Factorized Codec
                  and Diffusion Models},
  booktitle    = {{ICML}},
  publisher    = {OpenReview.net},
  year         = {2024}
}

@article{megatts,
  author       = {Ziyue Jiang and
                  Yi Ren and
                  Zhenhui Ye and
                  Jinglin Liu and
                  Chen Zhang and
                  Qian Yang and
                  Shengpeng Ji and
                  Rongjie Huang and
                  Chunfeng Wang and
                  Xiang Yin and
                  Zejun Ma and
                  Zhou Zhao},
  title        = {Mega-TTS: Zero-Shot Text-to-Speech at Scale with Intrinsic Inductive
                  Bias},
  journal      = {arXiv preprint},
  volume       = {abs/2306.03509},
  year         = {2023}
}

@article{voiceshop,
  author       = {Philip Anastassiou and
                  Zhenyu Tang and
                  Kainan Peng and
                  Dongya Jia and
                  Jiaxin Li and
                  Ming Tu and
                  Yuping Wang and
                  Yuxuan Wang and
                  Mingbo Ma},
  title        = {VoiceShop: {A} Unified Speech-to-Speech Framework for Identity-Preserving
                  Zero-Shot Voice Editing},
  journal      = {arXiv preprint},
  volume       = {abs/2404.06674},
  year         = {2024}
}

@article{HuBERT,
  author       = {Wei{-}Ning Hsu and
                  Benjamin Bolte and
                  Yao{-}Hung Hubert Tsai and
                  Kushal Lakhotia and
                  Ruslan Salakhutdinov and
                  Abdelrahman Mohamed},
  title        = {HuBERT: Self-Supervised Speech Representation Learning by Masked Prediction
                  of Hidden Units},
  journal      = {{IEEE} {ACM} Trans. Audio Speech Lang. Process.},
  volume       = {29},
  pages        = {3451--3460},
  year         = {2021}
}

@inproceedings{maskgct,
  author={Wang, Yuancheng and Zhan, Haoyue and Liu, Liwei and Zeng, Ruihong and Guo, Haotian and Zheng, Jiachen and Zhang, Qiang and Zhang, Xueyao and Zhang, Shunsi and Wu, Zhizheng},
  title={MaskGCT: Zero-Shot Text-to-Speech with Masked Generative Codec Transformer},
  booktitle    = {{ICLR}},
  publisher    = {OpenReview.net},
  year         = {2025}
}

@inproceedings{voicebox,
  author       = {Matthew Le and
                  Apoorv Vyas and
                  Bowen Shi and
                  Brian Karrer and
                  Leda Sari and
                  Rashel Moritz and
                  Mary Williamson and
                  Vimal Manohar and
                  Yossi Adi and
                  Jay Mahadeokar and
                  Wei{-}Ning Hsu},
  title        = {Voicebox: Text-Guided Multilingual Universal Speech Generation at
                  Scale},
  booktitle    = {NeurIPS},
  year         = {2023}
}

@article{seedtts,
  author       = {Philip Anastassiou and
                  Jiawei Chen and
                  Jitong Chen and
                  Yuanzhe Chen and
                  Zhuo Chen and
                  Ziyi Chen and
                  Jian Cong and
                  Lelai Deng and
                  Chuang Ding and
                  Lu Gao and
                  Mingqing Gong and
                  Peisong Huang and
                  Qingqing Huang and
                  Zhiying Huang and
                  Yuanyuan Huo and
                  Dongya Jia and
                  Chumin Li and
                  Feiya Li and
                  Hui Li and
                  Jiaxin Li and
                  Xiaoyang Li and
                  Xingxing Li and
                  Lin Liu and
                  Shouda Liu and
                  Sichao Liu and
                  Xudong Liu and
                  Yuchen Liu and
                  Zhengxi Liu and
                  Lu Lu and
                  Junjie Pan and
                  Xin Wang and
                  Yuping Wang and
                  Yuxuan Wang and
                  Zhen Wei and
                  Jian Wu and
                  Chao Yao and
                  Yifeng Yang and
                  Yuanhao Yi and
                  Junteng Zhang and
                  Qidi Zhang and
                  Shuo Zhang and
                  Wenjie Zhang and
                  Yang Zhang and
                  Zilin Zhao and
                  Dejian Zhong and
                  Xiaobin Zhuang},
  title        = {Seed-TTS: {A} Family of High-Quality Versatile Speech Generation Models},
  journal      = {arXiv preprint},
  volume       = {abs/2406.02430},
  year         = {2024}
}

@article{valle,
      title={Neural Codec Language Models are Zero-Shot Text to Speech Synthesizers}, 
      author={Chengyi Wang and Sanyuan Chen and Yu Wu and Ziqiang Zhang and Long Zhou and Shujie Liu and Zhuo Chen and Yanqing Liu and Huaming Wang and Jinyu Li and Lei He and Sheng Zhao and Furu Wei},
      journal      = {arXiv preprint},
      year={2023},
      volume={abs/2301.02111},
}

@article{basetts,
  author       = {Mateusz Lajszczak and
                  Guillermo C{\'{a}}mbara and
                  Yang Li and
                  Fatih Beyhan and
                  Arent van Korlaar and
                  Fan Yang and
                  Arnaud Joly and
                  {\'{A}}lvaro Mart{\'{\i}}n{-}Cortinas and
                  Ammar Abbas and
                  Adam Michalski and
                  Alexis Moinet and
                  Sri Karlapati and
                  Ewa Muszynska and
                  Haohan Guo and
                  Bartosz Putrycz and
                  Soledad L{\'{o}}pez Gambino and
                  Kayeon Yoo and
                  Elena Sokolova and
                  Thomas Drugman},
  title        = {{BASE} {TTS:} Lessons from building a billion-parameter Text-to-Speech
                  model on 100K hours of data},
  journal      = {arXiv preprint},
  volume       = {abs/2402.08093},
  year         = {2024}
}

@article{tortoise-tts,
  author       = {James Betker},
  title        = {Better speech synthesis through scaling},
  journal      = {arXiv preprint},
  volume       = {abs/2305.07243},
  year         = {2023}
}

@inproceedings{autovc,
  author       = {Kaizhi Qian and
                  Yang Zhang and
                  Shiyu Chang and
                  Xuesong Yang and
                  Mark Hasegawa{-}Johnson},
  title        = {AutoVC: Zero-Shot Voice Style Transfer with Only Autoencoder Loss},
  booktitle    = {{ICML}},
  series       = {Proceedings of Machine Learning Research},
  volume       = {97},
  pages        = {5210--5219},
  publisher    = {{PMLR}},
  year         = {2019}
}

@inproceedings{vqvc,
  author       = {Da{-}Yi Wu and
                  Hung{-}Yi Lee},
  title        = {One-Shot Voice Conversion by Vector Quantization},
  booktitle    = {{ICASSP}},
  pages        = {7734--7738},
  publisher    = {{IEEE}},
  year         = {2020}
}

@article{cosyvoice,
  author       = {Zhihao Du and
                  Qian Chen and
                  Shiliang Zhang and
                  Kai Hu and
                  Heng Lu and
                  Yexin Yang and
                  Hangrui Hu and
                  Siqi Zheng and
                  Yue Gu and
                  Ziyang Ma and
                  Zhifu Gao and
                  Zhijie Yan},
  title        = {CosyVoice: {A} Scalable Multilingual Zero-shot Text-to-speech Synthesizer
                  based on Supervised Semantic Tokens},
  journal      = {arXiv preprint},
  volume       = {abs/2407.05407},
  year         = {2024}
}

@inproceedings{convertandspeak,
  title={Convert and Speak: Zero-shot Accent Conversion with Minimum Supervision},
  author={Xue, Huaying and Peng, Xiulian and Lu, Yan and others},
booktitle    = {{ACM} Multimedia},
  publisher    = {{ACM}},
  year         = {2024}
}

@article{parallel-vc-1998,
  author       = {Yannis Stylianou and
                  Olivier Capp{\'{e}} and
                  Eric Moulines},
  title        = {Continuous probabilistic transform for voice conversion},
  journal      = {{IEEE} Trans. Speech Audio Process.},
  volume       = {6},
  number       = {2},
  pages        = {131--142},
  year         = {1998}
}

@inproceedings{parallel-vc-2015,
  author       = {Lifa Sun and
                  Shiyin Kang and
                  Kun Li and
                  Helen M. Meng},
  title        = {Voice conversion using deep Bidirectional Long Short-Term Memory based
                  Recurrent Neural Networks},
  booktitle    = {{ICASSP}},
  pages        = {4869--4873},
  publisher    = {{IEEE}},
  year         = {2015}
}

@article{fireredtts,
  title={FireRedTTS: A Foundation Text-To-Speech Framework for Industry-Level Generative Speech Applications},
  author={Guo, Hao-Han and Liu, Kun and Shen, Fei-Yu and Wu, Yi-Chen and Xie, Feng-Long and Xie, Kun and Xu, Kai-Tuo},
  journal={arXiv preprint},
  volume={abs/2409.03283},
  year={2024}
}

@inproceedings{vc-as-anonymization,
  author       = {Brij Mohan Lal Srivastava and
                  Nathalie Vauquier and
                  Md. Sahidullah and
                  Aur{\'{e}}lien Bellet and
                  Marc Tommasi and
                  Emmanuel Vincent},
  title        = {Evaluating Voice Conversion-Based Privacy Protection against Informed
                  Attackers},
  booktitle    = {{ICASSP}},
  pages        = {2802--2806},
  publisher    = {{IEEE}},
  year         = {2020}
}

@inproceedings{l2arctic,
  author       = {Guanlong Zhao and
                  Sinem Sonsaat and
                  Alif Silpachai and
                  Ivana Lucic and
                  Evgeny Chukharev{-}Hudilainen and
                  John Levis and
                  Ricardo Gutierrez{-}Osuna},
  title        = {{L2-ARCTIC:} {A} Non-native English Speech Corpus},
  booktitle    = {{INTERSPEECH}},
  pages        = {2783--2787},
  publisher    = {{ISCA}},
  year         = {2018}
}

@article{parallel-ac-zhaoguanlong21,
  author       = {Guanlong Zhao and
                  Shaojin Ding and
                  Ricardo Gutierrez{-}Osuna},
  title        = {Converting Foreign Accent Speech Without a Reference},
  journal      = {{IEEE} {ACM} Trans. Audio Speech Lang. Process.},
  volume       = {29},
  pages        = {2367--2381},
  year         = {2021}
}

@inproceedings{parallel-ec-2016,
  author       = {Huaiping Ming and
                  Dong{-}Yan Huang and
                  Lei Xie and
                  Jie Wu and
                  Minghui Dong and
                  Haizhou Li},
  title        = {Deep Bidirectional {LSTM} Modeling of Timbre and Prosody for Emotional
                  Voice Conversion},
  booktitle    = {{INTERSPEECH}},
  pages        = {2453--2457},
  publisher    = {{ISCA}},
  year         = {2016}
}

@inproceedings{vq-vae,
  author       = {A{\"{a}}ron van den Oord and
                  Oriol Vinyals and
                  Koray Kavukcuoglu},
  title        = {Neural Discrete Representation Learning},
  booktitle    = {{NIPS}},
  pages        = {6306--6315},
  year         = {2017}
}

@article{emovox,
  author       = {Kun Zhou and
                  Berrak Sisman and
                  Rajib Rana and
                  Bj{\"{o}}rn W. Schuller and
                  Haizhou Li},
  title        = {Emotion Intensity and its Control for Emotional Voice Conversion},
  journal      = {{IEEE} Trans. Affect. Comput.},
  volume       = {14},
  number       = {1},
  pages        = {31--48},
  year         = {2023}
}

@inproceedings{diff-hiervc,
  author       = {Ha{-}Yeong Choi and
                  Sang{-}Hoon Lee and
                  Seong{-}Whan Lee},
  title        = {Diff-HierVC: Diffusion-based Hierarchical Voice Conversion with Robust
                  Pitch Generation and Masked Prior for Zero-shot Speaker Adaptation},
  booktitle    = {{INTERSPEECH}},
  pages        = {2283--2287},
  publisher    = {{ISCA}},
  year         = {2023}
}

@article{parallel-vc-survey-2017,
  author       = {Seyed Hamidreza Mohammadi and
                  Alexander Kain},
  title        = {An overview of voice conversion systems},
  journal      = {Speech Commun.},
  volume       = {88},
  pages        = {65--82},
  year         = {2017}
}

@inproceedings{asr-ac,
  author       = {Mumin Jin and
                  Prashant Serai and
                  Jilong Wu and
                  Andros Tjandra and
                  Vimal Manohar and
                  Qing He},
  title        = {Voice-Preserving Zero-Shot Multiple Accent Conversion},
  booktitle    = {{ICASSP}},
  pages        = {1--5},
  publisher    = {{IEEE}},
  year         = {2023}
}

@inproceedings{chenxi-tts-ac,
  author       = {Xi Chen and
                  Jiakun Pei and
                  Liumeng Xue and
                  Mingyang Zhang},
  title        = {Transfer the Linguistic Representations from {TTS} to Accent Conversion
                  with Non-Parallel Data},
  booktitle    = {{ICASSP}},
  pages        = {12501--12505},
  publisher    = {{IEEE}},
  year         = {2024}
}

@inproceedings{pavits,
  author       = {Tianhua Qi and
                  Wenming Zheng and
                  Cheng Lu and
                  Yuan Zong and
                  Hailun Lian},
  title        = {{PAVITS:} Exploring Prosody-Aware {VITS} for End-to-End Emotional
                  Voice Conversion},
  booktitle    = {{ICASSP}},
  pages        = {12697--12701},
  publisher    = {{IEEE}},
  year         = {2024}
}

@inproceedings{uniaudio,
  author       = {Dongchao Yang and
                  Jinchuan Tian and
                  Xu Tan and
                  Rongjie Huang and
                  Songxiang Liu and
                  Haohan Guo and
                  Xuankai Chang and
                  Jiatong Shi and
                  Sheng Zhao and
                  Jiang Bian and
                  Zhou Zhao and
                  Xixin Wu and
                  Helen M. Meng},
  title        = {UniAudio: Towards Universal Audio Generation with Large Language Models},
  booktitle    = {{ICML}},
  publisher    = {OpenReview.net},
  year         = {2024}
}

@inproceedings{repcodec,
  author       = {Zhichao Huang and
                  Chutong Meng and
                  Tom Ko},
  title        = {RepCodec: {A} Speech Representation Codec for Speech Tokenization},
  booktitle    = {{ACL} {(1)}},
  pages        = {5777--5790},
  publisher    = {Association for Computational Linguistics},
  year         = {2024}
}

@inproceedings{mhubert-duration-reduction,
  author       = {Ann Lee and
                  Hongyu Gong and
                  Paul{-}Ambroise Duquenne and
                  Holger Schwenk and
                  Peng{-}Jen Chen and
                  Changhan Wang and
                  Sravya Popuri and
                  Yossi Adi and
                  Juan Miguel Pino and
                  Jiatao Gu and
                  Wei{-}Ning Hsu},
  title        = {Textless Speech-to-Speech Translation on Real Data},
  booktitle    = {{NAACL-HLT}},
  pages        = {860--872},
  publisher    = {Association for Computational Linguistics},
  year         = {2022}
}

@inproceedings{nclm,
  title={Neural Codec Language Models for Disentangled and Textless Voice Conversion},
  author={Baade, Alan and Peng, Puyuan and Harwath, David},
  booktitle    = {{INTERSPEECH}},
  publisher    = {{ISCA}},
  year         = {2024}
}

@inproceedings{transformer,
  author       = {Ashish Vaswani and
                  Noam Shazeer and
                  Niki Parmar and
                  Jakob Uszkoreit and
                  Llion Jones and
                  Aidan N. Gomez and
                  Lukasz Kaiser and
                  Illia Polosukhin},
  title        = {Attention is All you Need},
  booktitle    = {{NIPS}},
  pages        = {5998--6008},
  year         = {2017}
}

@inproceedings{flow-matching,
  author       = {Yaron Lipman and
                  Ricky T. Q. Chen and
                  Heli Ben{-}Hamu and
                  Maximilian Nickel and
                  Matthew Le},
  title        = {Flow Matching for Generative Modeling},
  booktitle    = {{ICLR}},
  publisher    = {OpenReview.net},
  year         = {2023}
}

@inproceedings{libriheavy,
  author       = {Wei Kang and
                  Xiaoyu Yang and
                  Zengwei Yao and
                  Fangjun Kuang and
                  Yifan Yang and
                  Liyong Guo and
                  Long Lin and
                  Daniel Povey},
  title        = {Libriheavy: {A} 50, 000 Hours {ASR} Corpus with Punctuation Casing
                  and Context},
  booktitle    = {{ICASSP}},
  pages        = {10991--10995},
  publisher    = {{IEEE}},
  year         = {2024}
}

@inproceedings{libri-light,
  author       = {Jacob Kahn and
                  Morgane Rivi{\`{e}}re and
                  Weiyi Zheng and
                  Evgeny Kharitonov and
                  Qiantong Xu and
                  Pierre{-}Emmanuel Mazar{\'{e}} and
                  Julien Karadayi and
                  Vitaliy Liptchinsky and
                  Ronan Collobert and
                  Christian Fuegen and
                  Tatiana Likhomanenko and
                  Gabriel Synnaeve and
                  Armand Joulin and
                  Abdelrahman Mohamed and
                  Emmanuel Dupoux},
  title        = {Libri-Light: {A} Benchmark for {ASR} with Limited or No Supervision},
  booktitle    = {{ICASSP}},
  pages        = {7669--7673},
  publisher    = {{IEEE}},
  year         = {2020}
}

@inproceedings{dit,
  author       = {William Peebles and
                  Saining Xie},
  title        = {Scalable Diffusion Models with Transformers},
  booktitle    = {{ICCV}},
  pages        = {4172--4182},
  publisher    = {{IEEE}},
  year         = {2023}
}

@article{lmvc,
  author       = {Zhichao Wang and
                  Yuanzhe Chen and
                  Lei Xie and
                  Qiao Tian and
                  Yuping Wang},
  title        = {{LM-VC:} Zero-Shot Voice Conversion via Speech Generation Based on
                  Language Models},
  journal      = {{IEEE} Signal Process. Lett.},
  volume       = {30},
  pages        = {1157--1161},
  year         = {2023}
}

@article{hierspeech++,
  author       = {Sang{-}Hoon Lee and
                  Ha{-}Yeong Choi and
                  Seung{-}Bin Kim and
                  Seong{-}Whan Lee},
  title        = {HierSpeech++: Bridging the Gap between Semantic and Acoustic Representation
                  of Speech by Hierarchical Variational Inference for Zero-shot Speech
                  Synthesis},
  journal      = {arXiv preprint},
  volume       = {abs/2311.12454},
  year         = {2023}
}

@inproceedings{voicecraft,
  author       = {Puyuan Peng and
                  Po{-}Yao Huang and
                  Shang{-}Wen Li and
                  Abdelrahman Mohamed and
                  David Harwath},
  title        = {VoiceCraft: Zero-Shot Speech Editing and Text-to-Speech in the Wild},
  booktitle    = {{ACL} {(1)}},
  pages        = {12442--12462},
  publisher    = {Association for Computational Linguistics},
  year         = {2024}
}

@inproceedings{librispeech,
  author       = {Vassil Panayotov and
                  Guoguo Chen and
                  Daniel Povey and
                  Sanjeev Khudanpur},
  title        = {Librispeech: An {ASR} corpus based on public domain audio books},
  booktitle    = {{ICASSP}},
  pages        = {5206--5210},
  publisher    = {{IEEE}},
  year         = {2015}
}

@article{audiolm,
  author       = {Zal{\'{a}}n Borsos and
                  Rapha{\"{e}}l Marinier and
                  Damien Vincent and
                  Eugene Kharitonov and
                  Olivier Pietquin and
                  Matthew Sharifi and
                  Dominik Roblek and
                  Olivier Teboul and
                  David Grangier and
                  Marco Tagliasacchi and
                  Neil Zeghidour},
  title        = {AudioLM: {A} Language Modeling Approach to Audio Generation},
  journal      = {{IEEE} {ACM} Trans. Audio Speech Lang. Process.},
  volume       = {31},
  pages        = {2523--2533},
  year         = {2023}
}

@article{vctk,
  title={{CSTR VCTK Corpus}: English multi-speaker corpus for CSTR voice cloning toolkit (version 0.92)},
  author={Yamagishi, Junichi and Veaux, Christophe and MacDonald, Kirsten and others},
  journal={University of Edinburgh. The Centre for Speech Technology Research (CSTR)},
  year={2019}
}

@inproceedings{common-voice,
  author       = {Rosana Ardila and
                  Megan Branson and
                  Kelly Davis and
                  Michael Kohler and
                  Josh Meyer and
                  Michael Henretty and
                  Reuben Morais and
                  Lindsay Saunders and
                  Francis M. Tyers and
                  Gregor Weber},
  title        = {Common Voice: {A} Massively-Multilingual Speech Corpus},
  booktitle    = {{LREC}},
  pages        = {4218--4222},
  publisher    = {European Language Resources Association},
  year         = {2020}
}

@inproceedings{libritts,
  author       = {Heiga Zen and
                  Viet Dang and
                  Rob Clark and
                  Yu Zhang and
                  Ron J. Weiss and
                  Ye Jia and
                  Zhifeng Chen and
                  Yonghui Wu},
  title        = {{LibriTTS}: {A} Corpus Derived from LibriSpeech for Text-to-Speech},
  booktitle    = {{INTERSPEECH}},
  pages        = {1526--1530},
  year         = {2019}
}

@inproceedings{amphion-svc,
  title={Leveraging Diverse Semantic-based Audio Pretrained Models for Singing Voice Conversion},
  author={Zhang, Xueyao and Fang, Zihao and Gu, Yicheng and Chen, Haopeng and Zou, Lexiao and Zhang, Junan and Xue, Liumeng and Wu, Zhizheng},
  booktitle    = {{SLT}},
  publisher    = {{IEEE}},
  year         = {2024}
}

@inproceedings{amphion,
    author={Zhang, Xueyao and Xue, Liumeng and Gu, Yicheng and Wang, Yuancheng and Li, Jiaqi and He, Haorui and Wang, Chaoren and Song, Ting and Chen, Xi and Fang, Zihao and Chen, Haopeng and Zhang, Junan and Tang, Tze Ying and Zou, Lexiao and Wang, Mingxuan and Han, Jun and Chen, Kai and Li, Haizhou and Wu, Zhizheng},
    title={Amphion: An Open-Source Audio, Music and Speech Generation Toolkit},
    booktitle    = {{SLT}},
    publisher    = {{IEEE}},
    year={2024}
}

@inproceedings{svcc-2023,
  author       = {Wen{-}Chin Huang and
                  Lester Phillip Violeta and
                  Songxiang Liu and
                  Jiatong Shi and
                  Tomoki Toda},
  title        = {The Singing Voice Conversion Challenge 2023},
  booktitle    = {{ASRU}},
  pages        = {1--8},
  publisher    = {{IEEE}},
  year         = {2023}
}

@article{wavlm,
  author       = {Sanyuan Chen and
                  Chengyi Wang and
                  Zhengyang Chen and
                  Yu Wu and
                  Shujie Liu and
                  Zhuo Chen and
                  Jinyu Li and
                  Naoyuki Kanda and
                  Takuya Yoshioka and
                  Xiong Xiao and
                  Jian Wu and
                  Long Zhou and
                  Shuo Ren and
                  Yanmin Qian and
                  Yao Qian and
                  Jian Wu and
                  Michael Zeng and
                  Xiangzhan Yu and
                  Furu Wei},
  title        = {WavLM: Large-Scale Self-Supervised Pre-Training for Full Stack Speech
                  Processing},
  journal      = {{IEEE} J. Sel. Top. Signal Process.},
  volume       = {16},
  number       = {6},
  pages        = {1505--1518},
  year         = {2022}
}

@inproceedings{whisper,
  author       = {Alec Radford and
                  Jong Wook Kim and
                  Tao Xu and
                  Greg Brockman and
                  Christine McLeavey and
                  Ilya Sutskever},
  title        = {Robust Speech Recognition via Large-Scale Weak Supervision},
  booktitle    = {{ICML}},
  volume       = {202},
  pages        = {28492--28518},
  year         = {2023}
}

@article{visqol,
  author       = {Andrew Hines and
                  Jan Skoglund and
                  Anil C. Kokaram and
                  Naomi Harte},
  title        = {ViSQOL: an objective speech quality model},
  journal      = {{EURASIP} J. Audio Speech Music. Process.},
  volume       = {2015},
  pages        = {13},
  year         = {2015}
}

@inproceedings{visqol-v3,
  author       = {Michael Chinen and
                  Felicia S. C. Lim and
                  Jan Skoglund and
                  Nikita Gureev and
                  Feargus O'Gorman and
                  Andrew Hines},
  title        = {ViSQOL v3: An Open Source Production Ready Objective Speech and Audio
                  Metric},
  booktitle    = {QoMEX},
  pages        = {1--6},
  publisher    = {{IEEE}},
  year         = {2020}
}

@inproceedings{common-accent,
  author       = {Juan Zuluaga{-}Gomez and
                  Sara Ahmed and
                  Danielius Visockas and
                  Cem Subakan},
  title        = {CommonAccent: Exploring Large Acoustic Pretrained Models for Accent
                  Classification Based on Common Voice},
  booktitle    = {{INTERSPEECH}},
  pages        = {5291--5295},
  publisher    = {{ISCA}},
  year         = {2023}
}

@inproceedings{emotion2vec,
  author       = {Ziyang Ma and
                  Zhisheng Zheng and
                  Jiaxin Ye and
                  Jinchao Li and
                  Zhifu Gao and
                  Shiliang Zhang and
                  Xie Chen},
  title        = {emotion2vec: Self-Supervised Pre-Training for Speech Emotion Representation},
  booktitle    = {{ACL} (Findings)},
  pages        = {15747--15760},
  publisher    = {Association for Computational Linguistics},
  year         = {2024}
}

@article{non-parallel-seq2seq-vc,
  author       = {Jing{-}Xuan Zhang and
                  Zhen{-}Hua Ling and
                  Li{-}Rong Dai},
  title        = {Non-Parallel Sequence-to-Sequence Voice Conversion With Disentangled
                  Linguistic and Speaker Representations},
  journal      = {{IEEE} {ACM} Trans. Audio Speech Lang. Process.},
  volume       = {28},
  pages        = {540--552},
  year         = {2020}
}

@article{llama,
  author       = {Hugo Touvron and
                  Thibaut Lavril and
                  Gautier Izacard and
                  Xavier Martinet and
                  Marie{-}Anne Lachaux and
                  Timoth{\'{e}}e Lacroix and
                  Baptiste Rozi{\`{e}}re and
                  Naman Goyal and
                  Eric Hambro and
                  Faisal Azhar and
                  Aur{\'{e}}lien Rodriguez and
                  Armand Joulin and
                  Edouard Grave and
                  Guillaume Lample},
  title        = {LLaMA: Open and Efficient Foundation Language Models},
  journal      = {arXiv preprint},
  volume       = {abs/2302.13971},
  year         = {2023}
}

@article{cfg-diffusion,
  author       = {Jonathan Ho and
                  Tim Salimans},
  title        = {Classifier-Free Diffusion Guidance},
  journal      = {arXiv preprint},
  volume       = {abs/2207.12598},
  year         = {2022}
}

@inproceedings{nancy,
  author       = {Hyeong{-}Seok Choi and
                  Juheon Lee and
                  Wansoo Kim and
                  Jie Lee and
                  Hoon Heo and
                  Kyogu Lee},
  title        = {Neural Analysis and Synthesis: Reconstructing Speech from Self-Supervised
                  Representations},
  booktitle    = {NeurIPS},
  pages        = {16251--16265},
  year         = {2021}
}

@inproceedings{contentvec,
  author       = {Kaizhi Qian and
                  Yang Zhang and
                  Heting Gao and
                  Junrui Ni and
                  Cheng{-}I Lai and
                  David D. Cox and
                  Mark Hasegawa{-}Johnson and
                  Shiyu Chang},
  title        = {ContentVec: An Improved Self-Supervised Speech Representation by Disentangling
                  Speakers},
  booktitle    = {{ICML}},
  series       = {Proceedings of Machine Learning Research},
  volume       = {162},
  pages        = {18003--18017},
  publisher    = {{PMLR}},
  year         = {2022}
}

@inproceedings{nancypp,
  author       = {Hyeong{-}Seok Choi and
                  Jinhyeok Yang and
                  Juheon Lee and
                  Hyeongju Kim},
  title        = {{NANSY++:} Unified Voice Synthesis with Neural Analysis and Synthesis},
  booktitle    = {{ICLR}},
  publisher    = {OpenReview.net},
  year         = {2023}
}

@article{u-style,
  title={U-Style: Cascading U-nets with Multi-level Speaker and Style Modeling for Zero-Shot Voice Cloning},
  author={Li, Tao and Wang, Zhichao and Zhu, Xinfa and Cong, Jian and Tian, Qiao and Wang, Yuping and Xie, Lei},
  journal={{IEEE} {ACM} Trans. Audio Speech Lang. Process.},
  year={2024}
}

@inproceedings{speechsplit2,
  author       = {Chak Ho Chan and
                  Kaizhi Qian and
                  Yang Zhang and
                  Mark Hasegawa{-}Johnson},
  title        = {SpeechSplit2.0: Unsupervised Speech Disentanglement for Voice Conversion
                  without Tuning Autoencoder Bottlenecks},
  booktitle    = {{ICASSP}},
  pages        = {6332--6336},
  publisher    = {{IEEE}},
  year         = {2022}
}

@article{vq-vqe-index-collapse,
  author       = {Haohan Guo and
                  Fenglong Xie and
                  Dongchao Yang and
                  Hui Lu and
                  Xixin Wu and
                  Helen Meng},
  title        = {Addressing Index Collapse of Large-Codebook Speech Tokenizer with
                  Dual-Decoding Product-Quantized Variational Auto-Encoder},
  journal      = {arXiv preprint},
  volume       = {abs/2406.02940},
  year         = {2024}
}

@inproceedings{vq-wav2vec,
  author       = {Alexei Baevski and
                  Steffen Schneider and
                  Michael Auli},
  title        = {vq-wav2vec: Self-Supervised Learning of Discrete Speech Representations},
  booktitle    = {{ICLR}},
  publisher    = {OpenReview.net},
  year         = {2020}
}

@inproceedings{wav2vec2,
  author       = {Alexei Baevski and
                  Yuhao Zhou and
                  Abdelrahman Mohamed and
                  Michael Auli},
  title        = {wav2vec 2.0: {A} Framework for Self-Supervised Learning of Speech
                  Representations},
  booktitle    = {NeurIPS},
  year         = {2020}
}

@article{soundstream,
  author       = {Neil Zeghidour and
                  Alejandro Luebs and
                  Ahmed Omran and
                  Jan Skoglund and
                  Marco Tagliasacchi},
  title        = {SoundStream: An End-to-End Neural Audio Codec},
  journal      = {{IEEE} {ACM} Trans. Audio Speech Lang. Process.},
  volume       = {30},
  pages        = {495--507},
  year         = {2022}
}

@inproceedings{speechtokenzier,
  author       = {Xin Zhang and
                  Dong Zhang and
                  Shimin Li and
                  Yaqian Zhou and
                  Xipeng Qiu},
  title        = {SpeechTokenizer: Unified Speech Tokenizer for Speech Language Models},
  booktitle    = {{ICLR}},
  publisher    = {OpenReview.net},
  year         = {2024}
}

@inproceedings{mls,
  author       = {Vineel Pratap and
                  Qiantong Xu and
                  Anuroop Sriram and
                  Gabriel Synnaeve and
                  Ronan Collobert},
  title        = {{MLS:} {A} Large-Scale Multilingual Dataset for Speech Research},
  booktitle    = {{INTERSPEECH}},
  pages        = {2757--2761},
  publisher    = {{ISCA}},
  year         = {2020}
}

@inproceedings{gigaspeech,
  author       = {Guoguo Chen and
                  Shuzhou Chai and
                  Guan{-}Bo Wang and
                  Jiayu Du and
                  Wei{-}Qiang Zhang and
                  Chao Weng and
                  Dan Su and
                  Daniel Povey and
                  Jan Trmal and
                  Junbo Zhang and
                  Mingjie Jin and
                  Sanjeev Khudanpur and
                  Shinji Watanabe and
                  Shuaijiang Zhao and
                  Wei Zou and
                  Xiangang Li and
                  Xuchen Yao and
                  Yongqing Wang and
                  Zhao You and
                  Zhiyong Yan},
  title        = {GigaSpeech: An Evolving, Multi-Domain {ASR} Corpus with 10, 000 Hours
                  of Transcribed Audio},
  booktitle    = {{INTERSPEECH}},
  pages        = {3670--3674},
  publisher    = {{ISCA}},
  year         = {2021}
}

@inproceedings{emilia,
  author       = {Haorui He and
                  Zengqiang Shang and
                  Chaoren Wang and
                  Xuyuan Li and
                  Yicheng Gu and
                  Hua Hua and
                  Liwei Liu and
                  Chen Yang and
                  Jiaqi Li and
                  Peiyang Shi and
                  Yuancheng Wang and
                  Kai Chen and
                  Pengyuan Zhang and
                  Zhizheng Wu},
  title        = {Emilia: An Extensive, Multilingual, and Diverse Speech Dataset for
                  Large-Scale Speech Generation},
  booktitle    = {{SLT}},
  publisher    = {{IEEE}},
  year         = {2024}
}

@inproceedings{bert,
  author       = {Jacob Devlin and
                  Ming{-}Wei Chang and
                  Kenton Lee and
                  Kristina Toutanova},
  title        = {{BERT:} Pre-training of Deep Bidirectional Transformers for Language
                  Understanding},
  booktitle    = {{NAACL-HLT} {(1)}},
  pages        = {4171--4186},
  publisher    = {Association for Computational Linguistics},
  year         = {2019}
}

@inproceedings{ecapa-tdnn,
  author       = {Brecht Desplanques and
                  Jenthe Thienpondt and
                  Kris Demuynck},
  title        = {{ECAPA-TDNN:} Emphasized Channel Attention, Propagation and Aggregation
                  in {TDNN} Based Speaker Verification},
  booktitle    = {{INTERSPEECH}},
  pages        = {3830--3834},
  publisher    = {{ISCA}},
  year         = {2020}
}

@inproceedings{bigvgan,
  author       = {Sang{-}gil Lee and
                  Wei Ping and
                  Boris Ginsburg and
                  Bryan Catanzaro and
                  Sungroh Yoon},
  title        = {BigVGAN: {A} Universal Neural Vocoder with Large-Scale Training},
  booktitle    = {{ICLR}},
  publisher    = {OpenReview.net},
  year         = {2023}
}

@inproceedings{tts-frontend,
  author       = {Qing He and
                  Zhiping Xiu and
                  Thilo K{\"{o}}hler and
                  Jilong Wu},
  title        = {Multi-Rate Attention Architecture for Fast Streamable Text-to-Speech
                  Spectrum Modeling},
  booktitle    = {{ICASSP}},
  pages        = {5689--5693},
  publisher    = {{IEEE}},
  year         = {2021}
}

@inproceedings{expresso,
  author       = {Tu Anh Nguyen and
                  Wei{-}Ning Hsu and
                  Antony D'Avirro and
                  Bowen Shi and
                  Itai Gat and
                  Maryam Fazel{-}Zarandi and
                  Tal Remez and
                  Jade Copet and
                  Gabriel Synnaeve and
                  Michael Hassid and
                  Felix Kreuk and
                  Yossi Adi and
                  Emmanuel Dupoux},
  title        = {Expresso: {A} Benchmark and Analysis of Discrete Expressive Speech
                  Resynthesis},
  booktitle    = {{INTERSPEECH}},
  pages        = {4823--4827},
  publisher    = {{ISCA}},
  year         = {2023}
}

@article{audiobox,
  author       = {Apoorv Vyas and
                  Bowen Shi and
                  Matthew Le and
                  Andros Tjandra and
                  Yi{-}Chiao Wu and
                  Baishan Guo and
                  Jiemin Zhang and
                  Xinyue Zhang and
                  Robert Adkins and
                  William Ngan and
                  Jeff Wang and
                  Ivan Cruz and
                  Bapi Akula and
                  Akinniyi Akinyemi and
                  Brian Ellis and
                  Rashel Moritz and
                  Yael Yungster and
                  Alice Rakotoarison and
                  Liang Tan and
                  Chris Summers and
                  Carleigh Wood and
                  Joshua Lane and
                  Mary Williamson and
                  Wei{-}Ning Hsu},
  title        = {Audiobox: Unified Audio Generation with Natural Language Prompts},
  journal      = {arXiv preprint},
  volume       = {abs/2312.15821},
  year         = {2023}
}

@article{kmeans,
  author       = {Stuart P. Lloyd},
  title        = {Least squares quantization in {PCM}},
  journal      = {{IEEE} Trans. Inf. Theory},
  volume       = {28},
  number       = {2},
  pages        = {129--136},
  year         = {1982}
}

@inproceedings{softvc,
  author       = {Benjamin van Niekerk and
                  Marc{-}Andr{\'{e}} Carbonneau and
                  Julian Za{\"{\i}}di and
                  Matthew Baas and
                  Hugo Seut{\'{e}} and
                  Herman Kamper},
  title        = {A Comparison of Discrete and Soft Speech Units for Improved Voice
                  Conversion},
  booktitle    = {{ICASSP}},
  pages        = {6562--6566},
  publisher    = {{IEEE}},
  year         = {2022}
}

@article{mms,
  author       = {Vineel Pratap and
                  Andros Tjandra and
                  Bowen Shi and
                  Paden Tomasello and
                  Arun Babu and
                  Sayani Kundu and
                  Ali Elkahky and
                  Zhaoheng Ni and
                  Apoorv Vyas and
                  Maryam Fazel{-}Zarandi and
                  Alexei Baevski and
                  Yossi Adi and
                  Xiaohui Zhang and
                  Wei{-}Ning Hsu and
                  Alexis Conneau and
                  Michael Auli},
  title        = {Scaling Speech Technology to 1, 000+ Languages},
  journal      = {J. Mach. Learn. Res.},
  volume       = {25},
  pages        = {97:1--97:52},
  year         = {2024}
}

@inproceedings{vits,
  author       = {Jaehyeon Kim and
                  Jungil Kong and
                  Juhee Son},
  title        = {Conditional Variational Autoencoder with Adversarial Learning for
                  End-to-End Text-to-Speech},
  booktitle    = {{ICML}},
  series       = {Proceedings of Machine Learning Research},
  volume       = {139},
  pages        = {5530--5540},
  publisher    = {{PMLR}},
  year         = {2021}
}

@inproceedings{mutual-information-zhuxinfa,
  author       = {Xinfa Zhu and
                  Yi Lei and
                  Kun Song and
                  Yongmao Zhang and
                  Tao Li and
                  Lei Xie},
  title        = {Multi-Speaker Expressive Speech Synthesis via Multiple Factors Decoupling},
  booktitle    = {{ICASSP}},
  pages        = {1--5},
  publisher    = {{IEEE}},
  year         = {2023}
}

@inproceedings{mutual-information,
  author       = {Pengyu Cheng and
                  Weituo Hao and
                  Shuyang Dai and
                  Jiachang Liu and
                  Zhe Gan and
                  Lawrence Carin},
  title        = {{CLUB:} {A} Contrastive Log-ratio Upper Bound of Mutual Information},
  booktitle    = {{ICML}},
  series       = {Proceedings of Machine Learning Research},
  volume       = {119},
  pages        = {1779--1788},
  publisher    = {{PMLR}},
  year         = {2020}
}

@inproceedings{stargan-vc,
  author={Kameoka, Hirokazu and Kaneko, Takuhiro and Tanaka, Kou and Hojo, Nobukatsu},
  title={StarGAN-VC: non-parallel many-to-many Voice Conversion Using Star Generative Adversarial Networks}, 
  year={2018},
  booktitle    = {{SLT}},
  publisher    = {{IEEE}},
}


@inproceedings{diffvc,
  author       = {Vadim Popov and
                  Ivan Vovk and
                  Vladimir Gogoryan and
                  Tasnima Sadekova and
                  Mikhail Sergeevich Kudinov and
                  Jiansheng Wei},
  title        = {Diffusion-Based Voice Conversion with Fast Maximum Likelihood Sampling
                  Scheme},
  booktitle    = {{ICLR}},
  publisher    = {OpenReview.net},
  year         = {2022}
}

@inproceedings{cyclegan-vc,
  author       = {Takuhiro Kaneko and
                  Hirokazu Kameoka},
  title        = {CycleGAN-VC: Non-parallel Voice Conversion Using Cycle-Consistent
                  Adversarial Networks},
  booktitle    = {{EUSIPCO}},
  pages        = {2100--2104},
  publisher    = {{IEEE}},
  year         = {2018}
}

@inproceedings{liusongxiang-ac,
  author       = {Songxiang Liu and
                  Disong Wang and
                  Yuewen Cao and
                  Lifa Sun and
                  Xixin Wu and
                  Shiyin Kang and
                  Zhiyong Wu and
                  Xunying Liu and
                  Dan Su and
                  Dong Yu and
                  Helen Meng},
  title        = {End-To-End Accent Conversion Without Using Native Utterances},
  booktitle    = {{ICASSP}},
  pages        = {6289--6293},
  publisher    = {{IEEE}},
  year         = {2020}
}

@article{zhouyi-ac,
  author       = {Yi Zhou and
                  Zhizheng Wu and
                  Mingyang Zhang and
                  Xiaohai Tian and
                  Haizhou Li},
  title        = {TTS-Guided Training for Accent Conversion Without Parallel Data},
  journal      = {{IEEE} Signal Process. Lett.},
  volume       = {30},
  pages        = {533--537},
  year         = {2023}
}

@inproceedings{ppg-vc,
  author       = {Lifa Sun and
                  Kun Li and
                  Hao Wang and
                  Shiyin Kang and
                  Helen M. Meng},
  title        = {Phonetic posteriorgrams for many-to-one voice conversion without parallel
                  data training},
  booktitle    = {{ICME}},
  pages        = {1--6},
  publisher    = {{IEEE} Computer Society},
  year         = {2016}
}

@article{self-supervised-vc,
  author       = {Wen{-}Chin Huang and
                  Shu{-}Wen Yang and
                  Tomoki Hayashi and
                  Tomoki Toda},
  title        = {A Comparative Study of Self-Supervised Speech Representation Based
                  Voice Conversion},
  journal      = {{IEEE} J. Sel. Top. Signal Process.},
  volume       = {16},
  number       = {6},
  pages        = {1308--1318},
  year         = {2022}
}

@inproceedings{sef-vc-kmeans,
  author       = {Junjie Li and
                  Yiwei Guo and
                  Xie Chen and
                  Kai Yu},
  title        = {{SEF-VC:} Speaker Embedding Free Zero-Shot Voice Conversion with Cross
                  Attention},
  booktitle    = {{ICASSP}},
  pages        = {12296--12300},
  publisher    = {{IEEE}},
  year         = {2024}
}

@inproceedings{adam,
  author       = {Diederik P. Kingma and
                  Jimmy Ba},
  title        = {Adam: {A} Method for Stochastic Optimization},
  booktitle    = {{ICLR} (Poster)},
  year         = {2015}
}

@inproceedings{adamw,
  author       = {Ilya Loshchilov and
                  Frank Hutter},
  title        = {Decoupled Weight Decay Regularization},
  booktitle    = {{ICLR} (Poster)},
  publisher    = {OpenReview.net},
  year         = {2019}
}

@article{encodec,
  title={High fidelity neural audio compression},
  author={D{\'e}fossez, Alexandre and Copet, Jade and Synnaeve, Gabriel and Adi, Yossi},
  journal={arXiv preprint},
  volume       = {abs/2210.13438},
  year={2022}
}

@inproceedings{w2v-bert,
  author       = {Yu{-}An Chung and
                  Yu Zhang and
                  Wei Han and
                  Chung{-}Cheng Chiu and
                  James Qin and
                  Ruoming Pang and
                  Yonghui Wu},
  title        = {w2v-BERT: Combining Contrastive Learning and Masked Language Modeling
                  for Self-Supervised Speech Pre-Training},
  booktitle    = {{ASRU}},
  pages        = {244--250},
  publisher    = {{IEEE}},
  year         = {2021}
}

@inproceedings{bart,
  author       = {Mike Lewis and
                  Yinhan Liu and
                  Naman Goyal and
                  Marjan Ghazvininejad and
                  Abdelrahman Mohamed and
                  Omer Levy and
                  Veselin Stoyanov and
                  Luke Zettlemoyer},
  title        = {{BART:} Denoising Sequence-to-Sequence Pre-training for Natural Language
                  Generation, Translation, and Comprehension},
  booktitle    = {{ACL}},
  pages        = {7871--7880},
  publisher    = {Association for Computational Linguistics},
  year         = {2020}
}

@inproceedings{vq-content-style,
  title={Unsupervised Learning of Disentangled Speech Content and Style Representation},
  author={Andros Tjandra and Ruoming Pang and Yu Zhang and Shigeki Karita},
  booktitle={{INTERSPEECH}},
  year={2020},
  pages        = {4089--4093},
  publisher    = {{ISCA}},
}

@article{amphion_v0.2,
  title        = {Overview of the Amphion Toolkit (v0.2)},
  author       = {Jiaqi Li and Xueyao Zhang and Yuancheng Wang and Haorui He and Chaoren Wang and Li Wang and Huan Liao and Junyi Ao and Zeyu Xie and Yiqiao Huang and Junan Zhang and Zhizheng Wu},
  year         = {2025},
journal      = {arXiv preprint},
  volume       = {abs/2501.15442},
}