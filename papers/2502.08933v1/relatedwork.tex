\section{Related Work}
\label{sec:background-related-work}

Algorithmic auditing is an active research area and is essential to understand how algorithms impact users, ranging from whether they serve trustworthy and fair content (\eg{} election information)~\cite{PerreaultGoogleSearch,BandyFacebook,MustafarajVoterFair,RobertsonGoogleSearch}, data usage (\eg{} voice recordings) and biases (\eg{} racial discrimination) of ad personalization ~\cite{iqbal-imc-alexa,BaumannAdFair}, to how social media algorithms can deliver problematic content (\eg{} radicalized and harmful content)~\cite{HaroonYoutubePNA,RibeiroYoutubePathways,Pruccoli2022Dec,NigatuYoutube}.
The latter is most relevant to this work: those that audit social media platforms and capture (or simulate) how users interact with the platforms and the outputted content. 

Researchers typically build various ``personas'' that simulate users and their interests by training ``sock puppets'', \ie{} automating interactions (\eg{} liking, watching, searching for relevant content) with the platform and then observing the results. %
Muhammad~\etal{}~\cite{HaroonYoutubePNA} trained thousands of sock puppets to measure whether YouTube's algorithm recommended extreme and problematic ideological content. Similarly, Ribeiro~\etal{}~\cite{RibeiroYoutubePathways} investigated whether YouTube led users to more radicalized content (\eg{} Alt-right content such as white ethnostate) through a sock puppet process that starts with a few known radical channels and then recursively collect related channels using keyword search and YouTube recommendations. Similarly, Boeker~\etal{}~\cite{BoekerTikTokPersonalization} created personas based on location, language, and interests and utilized sock puppets to apply specific interactions with the TikTok FYP (on the web), \eg{} liking the content if it contains a hashtag relevant to the persona. Kaplan~\etal{}~\cite{KaplanTikTok} applied the same methodology as ~\cite{BoekerTikTokPersonalization} but on the TikTok mobile app to examine both the personalization of content and ads based on age and gender.

Another approach is to conduct user studies or leverage existing real-world datasets.
Pruccoli~\etal{}~\cite{Pruccoli2022Dec} surveyed 78 TikTok users from an Italian eating disorder center for children and adolescents; 43\% of participants reported being served unsolicited content that promoted eating disorder as a lifestyle choice while 59\% reported that TikTok content reduced their self-esteem.
Bandy~\etal{}~\cite{BandyFacebook} studied how Facebook's newsfeed algorithm amplified low-quality publishers (\eg{} fake news, untrustworthy news) during the 2020 U.S. election by analyzing a commercial panel dataset containing the Internet browsing history of a million households. 
Similarly, Zannettou~\etal{}~\cite{zannettou2023datadonations} relied on data donations from 347 TikTok users to study how they engage with the platform \eg{} how often users press ``like'' on the content and the percentage of each video that they watch. 
Nigatu~\etal{}~\cite{NigatuYoutube} utilized semi-structured interviews and sock puppets to study how YouTube in Ethiopia can recommend sexual content to users, even when users search for benign topics (\eg{} TV shows). 

Other works developed frameworks to measure personalization. Vombatkere~\etal{}~\cite{VombatkereTikTokFramework} created a framework to identify whether a piece of content was delivered due to personalization (or not), based on features such as shared hashtags and creators, and specific user interactions (\eg{} liking, favoriting). They applied their framework to the real-world TikTok dataset~\cite{zannettou2023datadonations} and found that TikTok delivered personalized content 30\% to 50\% of the time, with the user interaction of liking and following causing the most personalized content. 

\descr{\autolike{} \vs{} Prior Work.}
\autolike{} is a RL-based framework that learns which actions (\eg{} liking, watching) to take to efficiently drive a \rs{} towards delivering content based on a given topic of interest (\eg{} mental health) and sentiment (\eg{} negative/sad). It differs from works that utilize sock puppets~\cite{HaroonYoutubePNA,RibeiroYoutubePathways,BoekerTikTokPersonalization,KaplanTikTok,iqbal-imc-alexa}, which are often hardcoded and static scripts to take specific actions on specific content (\eg{} liking the content if it contains a specific hashtag). On the other hand, \autolike{} takes a list of potential actions and learns through experience (\ie{} interacting with the \fyp{}) which actions to take. It is guided by a reward function and the goal of maximizing its cumulative rewards over time, \eg{} high rewards for the content of interest. 
\autolike{} can learn from scratch (\fyp{} is fresh for a new user) and can still drive the \rs{}. This is a departure from prior work that often relies on searching and watching specific content first, then going to the \fyp{} and seeing the personalization there.
In terms of implementation, \autolike{} is deployed on the TikTok mobile app similar to Kaplan~\etal{}~\cite{KaplanTikTok}. However, our implementation simulates a user trying to share the shown TikTok video to extract the video ID instead of decrypting the network traffic of the app. This is a more practical approach as it enables \autolike{} to run on non-rooted devices and non-modified TikTok apps. In addition, we evaluate \autolike{} on a real Android mobile device instead of an emulator.