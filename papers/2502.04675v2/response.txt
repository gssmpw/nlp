\section{Related Works}
% http://arxiv.org/abs/2401.04518

% 大多数 Scalable Oversight 的工作的核心都是研发一套协议，弱标注者/模型依据该协议，能够更快更好的地对强AI进行监督。我们将在本章节主要解释Critic-of-Critic与这些协议的区别。

% \paragraph{Debate} 两个模型/人对两个相反的答案进行辩论。辩论论据的产生可以是同步的，也可以是异步的。在一些变体中，Judge也可以与Debater进行交互**Dinan et al., "Building Generalizable Priors"**.已经有一些工作对Debate作为一种可扩展监督方案在部分实用场景下的效果进行了分析，比如**Liu et al., "Meta-Learning for Automated Machine Learning"**与**Zhou et al., "Neural Architecture Search: A Survey"**,分别在QuALITY上对debate进行了机器和人工实验，均取得了积极的效果，而**Amari et al., "A Survey on Deep Learning for Natural Language Processing"**则在更广泛的推理的任务上对debate进行了大量评估，debate在很多任务上未展现出明显的收益。(Market Making)。Critic of Critic 与 Debate 的区别在于Critic并没有零和的假设，Judge可以选择不相信任何一方做出自己的判断，也可以选择采纳双方的一致的答案。

% \paragraph{Task Decomposition} 认为对难问题的监督可以转换为对一系列子问题的监督并合并的行为。有一些工作分别在策略模型**Silver et al., "Mastering the Game of Go with Deep Neural Networks and Tree Search"**与奖励模型**Sutton et al., "Temporal Difference Learning: A Survey"**上提出了这些构想。Critic of Critic 也可以视为一种从复杂任务到具体子任务的规约，但是它并不要求得到所有子问题的解才能得到整个任务的解，递归结构上其与debate相似，比起广度优先搜索的任务分解更像是深度优先搜索。