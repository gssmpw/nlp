%%%%%%%% ICML 2025 EXAMPLE LATEX SUBMISSION FILE %%%%%%%%%%%%%%%%%

\documentclass{article}
\usepackage{CJKutf8}
% Recommended, but optional, packages for figures and better typesetting:
\usepackage{microtype}
\usepackage{graphicx}
\usepackage{subfigure}
\usepackage{booktabs} % for professional tables
\usepackage{multirow}
\usepackage{makecell}
\usepackage{array}
\usepackage{bbm}
\usepackage{ragged2e}
\usepackage{vcell}

% hyperref makes hyperlinks in the resulting PDF.
% If your build breaks (sometimes temporarily if a hyperlink spans a page)
% please comment out the following usepackage line and replace
% \usepackage{icml2025} with \usepackage[nohyperref]{icml2025} above.
\usepackage{hyperref}


% Attempt to make hyperref and algorithmic work together better:
\newcommand{\theHalgorithm}{\arabic{algorithm}}

% Use the following line for the initial blind version submitted for review:
% \usepackage{icml2025}

% If accepted, instead use the following line for the camera-ready submission:
\usepackage[accepted]{icml2025}
%\usepackage{icml2025}

% For theorems and such
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{mathtools}
\usepackage{amsthm}

% if you use cleveref..
\usepackage[capitalize,noabbrev]{cleveref}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% THEOREMS
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\theoremstyle{plain}
\newtheorem{theorem}{Theorem}[section]
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{corollary}[theorem]{Corollary}
\theoremstyle{definition}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{assumption}[theorem]{Assumption}
\theoremstyle{remark}
\newtheorem{remark}[theorem]{Remark}

% Todonotes is useful during development; simply uncomment the next line
%    and comment out the line below the next line to turn off comments
%\usepackage[disable,textsize=tiny]{todonotes}
\usepackage[textsize=tiny]{todonotes}
\usepackage{tcolorbox}
\usepackage{multirow}
\usepackage{tabularx}


% The \icmltitle you define below is probably too long as a header.
% Therefore, a short form for the running title is supplied here:
\icmltitlerunning{Scalable Oversight for Superhuman AI via Recursive Self-Critiquing}

\begin{document}

\twocolumn[
\icmltitle{Scalable Oversight for Superhuman AI via Recursive Self-Critiquing
}
% \icmltitle{Scalably Supervise Superhuman AI with Self Recursive Critique}

% It is OKAY to include author information, even for blind
% submissions: the style file will automatically remove it for you
% unless you've provided the [accepted] option to the icml2025
% package.

% List of affiliations: The first argument should be a (short)
% identifier you will use later to specify author affiliations
% Academic affiliations should list Department, University, City, Region, Country
% Industry affiliations should list Company, City, Region, Country

% You can specify symbols, otherwise they are numbered in order.
% Ideally, you should not use this facility. Affiliations will be numbered
% in order of appearance and this is the preferred way.
\icmlsetsymbol{equal}{*}

\begin{icmlauthorlist}
\icmlauthor{Xueru Wen}{iscas,ucas,equal}
\icmlauthor{Jie Lou}{xiaohongshu,equal}
\icmlauthor{Xinyu Lu}{iscas,ucas,equal}
\icmlauthor{Junjie Yang}{xiaohongshu,equal}
\icmlauthor{Yanjiang Liu}{iscas,ucas}
\icmlauthor{Yaojie Lu}{iscas}
\icmlauthor{Debing Zhang}{xiaohongshu}
\icmlauthor{XingYu}{xiaohongshu}
\end{icmlauthorlist}

\icmlaffiliation{iscas}{Chinese Information Processing Laboratory, Institute of Software, Chinese Academy of Sciences}
\icmlaffiliation{ucas}{University of Chinese Academy of Sciences}
\icmlaffiliation{xiaohongshu}{Xiaohongshu Inc}

\icmlcorrespondingauthor{wenxueru2022,luxinyu2021,liuyanjiang2021,luyaojie}{@iscas.ac.cn}
\icmlcorrespondingauthor{loujie0822}{@gmail.com}
\icmlcorrespondingauthor{dengyang}{@xiaohongshu.com}

% You may provide any keywords that you
% find helpful for describing your paper; these are used to populate
% the "keywords" metadata in the PDF but will not be shown in the document
\icmlkeywords{Machine Learning, ICML}

\vskip 0.3in
]

% this must go after the closing bracket ] following \twocolumn[ ...

% This command actually creates the footnote in the first column
% listing the affiliations and the copyright notice.
% The command takes one argument, which is text to display at the start of the footnote.
% The \icmlEqualContribution command is standard text for equal contribution.
% Remove it (just {}) if you do not need this facility.

\renewcommand{\thefootnote}{} % 临时移除脚注编号
\footnotetext{The main idea for this work came from a late-night, insightful discussion between Jie Lou and Xing Yu , which was part of some truly wonderful days.}
\renewcommand{\thefootnote}{\arabic{footnote}} % 恢复正常的脚注编号

\renewcommand{\thefootnote}{} % 临时移除脚注编号
\footnotetext{This work was conducted during Xueru Wen and Xingyu Lu's internship at Xiaohongshu.}
\renewcommand{\thefootnote}{\arabic{footnote}} % 恢复正常的脚注编号

% \printAffiliationsAndNotice{}  % leave blank if no need to mention equal contribution
\printAffiliationsAndNotice{\icmlEqualContribution} % otherwise use the standard text.

\begin{abstract} 
As AI capabilities increasingly surpass human proficiency in complex tasks, current alignment techniques including SFT and RLHF face fundamental challenges in ensuring reliable oversight. 
These methods rely on direct human assessment and become untenable when AI outputs exceed human cognitive thresholds.
In response to this challenge, we explore two hypotheses: (1) \textit{critique of critique can be easier than critique itself}, extending the widely-accepted observation that verification is easier than generation to the critique domain, as critique itself is a specialized form of generation; (2) \textit{this difficulty relationship is recursively held}, suggesting that when direct evaluation is infeasible, performing high-order critiques (e.g., critique of critique of critique) offers a more tractable supervision pathway.
To examine these hypotheses, we perform Human-Human, Human-AI, and AI-AI experiments across multiple tasks.
Our results demonstrate encouraging evidence supporting these hypotheses and suggest that \textbf{\textit{recursive self-critiquing}} is a promising direction for scalable oversight.
\end{abstract}

\section{Introduction}
The provision of supervision signals is fundamental to AI alignment \citep{bowman2022measuringprogressscalableoversight}.
From the supervision signal acquisition perspective, tasks can be categorized as:
(1) tasks with well-defined criteria, where ground truth can be deterministically obtained with low computational overhead, e.g., Go games and mathematical problems~\citep{silver2017masteringchessshogiselfplay,lightman2023letsverifystepstep};
(2) tasks with subjectivity or complex evaluation frameworks, such as business strategy and product design jobs~\citep{ouyang2022traininglanguagemodelsfollow}. 
The second type task is more prevalent in real-world applications and predominantly rely on human assessment, presenting a fundamental challenge for obtaining supervision signals.

Large language models achieve empirical success in alignment~\citep{grattafiori2024llama3herdmodels,yang2024qwen2technicalreport,deepseekai2024deepseekllmscalingopensource} with Supervised Fine-tuning (SFT) and Reinforcement Learning from Human Feedback (RLHF) techniques. Specifically, SFT~\citep{chung2022scalinginstructionfinetunedlanguagemodels,wei2022finetunedlanguagemodelszeroshot} finetunes models with human-annotated demonstrations, showing particular efficacy in tasks where humans can effectively showcase desired behaviors.
RLHF~\citep{christiano2023deepreinforcementlearninghuman,ouyang2022traininglanguagemodelsfollow} leverages reinforcement learning with human preference reward models, extending supervision capability to more complex tasks where direct solution generation proves challenging.

However, both approaches rely on human feedback, making them unsustainable for tasks where direct human evaluation becomes infeasible.
For example, humans can struggle with the time-consuming tasks, e.g., reviewing extensive content in long-form text~\citep{stiennon2022learningsummarizehumanfeedback} or the expertise required tasks, e.g., to verify solutions in complex mathematical formulations~\citep{li2024surveydeeplearningtheorem}.
Furthermore, as AI capabilities advance beyond human abilities, obtaining reliable supervision signals becomes increasingly challenging, representing the core point of scalable oversight \citep{casper2023openproblemsfundamentallimitations,ji2024aialignmentcomprehensivesurvey,kenton2024scalableoversightweakllms}.

The principle behind RLHF is that verification is easier than generation \citep{leike2018scalableagentalignmentreward,irving2018aisafetydebate}.
By recognizing critique as a specialized form of generation, we further hypothesize that \textit{critique of critique is easier than critique itself}.
Taking a complex mathematical proof as an example: direct review can be challenging, but assessing its critique is more manageable, as the key steps have already been identified.
Moreover, we hypothesize that \textit{above difficulty relationship generalizes recursively}, where each successive level of meta-evaluation becomes increasingly tractable.
This is similar to organizational decision-making procedure, where managers evaluate their subordinates' assessments rather than directly reviewing complex details.
Both above hypotheses, if validated, offer a promising pathway for scalable oversight: while directly evaluating sophisticated AI output may exceed human capabilities, performing higher-order critiques could remain feasible.

To systematically explore and verify these hypotheses, we first conduct Human-Human experiments, where human evaluate human outputs, examining the progression from response to critique and critique-of-critique ($C^2$). 
By comparing accuracy with similar effort, completion time, and confidence levels, we find that higher-order critique contributes to more effective evaluation than direct assessment. 
Furthermore, we demonstrate the recursive hypothesis by extending experimental settings to deeper critique chains, i.e., critique of critique of critique ($C^3$).
Inspired by above human-human findings, we further investigate its applicability for supervising AI: when AI generate self-recursive critique, could humans provide effective oversight by evaluating these critique chains? 
To answer this question, we conduct Human-AI experiments, where human evaluate AI outputs, on tasks where AI outperforms average human. The result is promising and exhibited with models of varying capabilities.
Finally, we examine whether AI could achieve effective oversight through self-recursive critiques, i.e., AI evaluate AI ouputs. 
Our results reveal that while contemporary AI systems demonstrate strong generation capabilities, they show notable limitations in higher-order criticism tasks.

In general, our contributions can be summarized as follows:
\begin{enumerate}
    \item We investigate and validate the hypothesis that \textit{critique of critique is easier than critique}, extending the principle that verification is easier than generation.
    \item We demonstrate that \textit{above difficulty relationship can hold recursively}, showing how complex evaluation tasks can be simplified by recursive meta evaluations.
    \item Through comprehensive Human-Human, Human-AI, and AI-AI experiments, our findings provide valuable scalable oversight insights for surpervising advanced AI systems beyond human capabilities.
\end{enumerate}

\begin{figure*}[t]
\centering
\includegraphics[width=\linewidth]{figures/coc_fig1.pdf}
\vspace{-0.5cm}
\caption{Overview of the recursive critique framework. Starting from response generation for a given question, each subsequent level performs pair-wise evaluation of outputs from the previous level, forming a recursive criticism chain. $C^1$ denotes Critique, $C^2$ denotes Critique of Critique, $C^3$ denotes Critique of Critique of Critique.}
\label{fig:coc_method}
\end{figure*}


\section{Recursive Self-Critiquing}
In this section, we introduce the interaction protocols that define how recursive self-critiquing progresses through multiple levels, from initial response to higher-order critiques.
We then present two baselines, majority voting and naive voting, for fair comparison of the recursive critique's effectiveness.

\subsection{Protocols}
As shown in the Figure \ref{fig:coc_method}, the hierarchical criticism architecture progresses through multiple levels: from initial response, through first-order critique, to second-order critique of critique ($C^2$) and higher-order critiques.

\paragraph{Response}
Response represents the initial attempt to answer the question, serving as the foundation of the criticism chain. 
Each response comprises a complete solution process and its corresponding answer, which is formally defined as:

\vspace{-4mm}
\begin{equation}
    R(Q) \rightarrow (T^0, A^0),
\end{equation}
\vspace{-6mm}

where $Q$ denotes the input question, $T$ represents the solution process, and $A$ is the final answer. The inclusion of the full solution process enables critiques to evaluate the complete reasoning path rather than merely the result.

\paragraph{Critique}
The critique evaluates pairs of candidate responses for a given input question, conducting comparative analysis and providing reasoning judgment as follows:

\vspace{-4mm}
\begin{equation}
    C^1(Q, R_1, R_2) \rightarrow (T^1, A^1),
\end{equation}
\vspace{-6mm}

where $R_1$ and $R_2$ denote candidate responses, $T^1$ represents the critique rationale, and $A^1$ is the answer to the question based on the responses and critique rationale.

\paragraph{Critique of critique}
The second-order critique evaluates pairs of critiques, extending the evaluation to a higher level of abstraction, which is defined as:
\begin{equation}
    C^2(Q, R_1, R_2, C_1, C_2) \rightarrow (T^2, A^2),
\end{equation}
where $C_1$ and $C_2$ are two critiques of the original responses. $T^2$ represents the second-order critique's analysis of the critiques' reasoning, and $A^2$ denotes the final judgment.

\paragraph{Higher-order critiques}
The $n$-th order critique extends this evaluation pattern to higher levels of abstraction, analyzing the assessments from all previous levels, and it is defined as:
\begin{equation}
    C^n(Q, R_1, R_2,..., C^{n-1}_1,  C^{n-1}_2) \rightarrow (T^n, A^n),
\end{equation}
where $C^{n-1}_1$ and $C^{n-1}_2$ are evaluations from the $(n-1)$-th order critiques, $T^n$ represents the $n$-th order critic's analysis of the previous critiques, and $A^n$ denotes the final judgment.

\subsection{Baselines}
We introduce two baseline strategies for the rigorous comparison for the recursive critique: majority voting that ensures fair comparison under equivalent computational effort, and naive voting that simply aggregates all available judgments to verify whether recursive critique generates meaningful new insights beyond naive consensus.

\paragraph{Majority voting}
Since higher-order critiques is based on all previous evaluation results, we need to consider computational cost for fair comparison.
To validate that improvements stem from the recursive structure rather than increased computation, we compare higher-order critiques with majority voting of lower-order evaluations under similar effort.
Specifically, let $\epsilon(\cdot)$ denote the computational overhead for each single evaluation. 
As presented in Figure \ref{fig:coc_method}, the total efforts $E(\cdot)$ for different order recursive critique $C^1$, $C^2$ and $C^3$ are defined as:

\vspace{-6mm}
\begin{equation}
\begin{aligned} 
E(C^1) &= \epsilon(R_1) + \epsilon(R_2) + \epsilon(C^1) \approx 3\epsilon(R), \\[0.5em]
E(C^2) &= \epsilon(R_1) + \epsilon(R_2) + \epsilon(C^1_1) + \epsilon(C^1_2) + \epsilon(C^2) \\ &\approx 5\epsilon(R), \\
E(C^3) &= \epsilon(R_1) + \epsilon(R_2) + \epsilon(C^1_1) + \epsilon(C^1_2) + \epsilon(C^2_1) \\ &+ \epsilon(C^2_2) + \epsilon(C^3) \approx 7\epsilon(R).
\end{aligned}    
\end{equation}
\vspace{-4mm}

Then, we define majority voting at each level. For level $l$, given a set of $n$ evaluations, the majority voting result is:

\vspace{-4mm}
\begin{equation}
    \text{Major}_n^l(\mathcal{A}) = \underset{a}{\operatorname{argmax}} \sum_{i=1}^n \mathbbm{1}(A^l_i = a),
\end{equation}
\vspace{-4mm}

where $A^l_i$ represents the judgment from the $i$-th evaluation at level $l$, and $\mathbbm{1}(\cdot)$ is the indicator function.
Intuitively, this formula counts the occurrences of each possible answer among the $n$ evaluations and selects the most frequent one as the final result.
In case of ties where multiple answers have the same highest frequency, one is randomly selected.
To ensure effort equivalence when comparing with recursive critique at level $l$, we calculate $\text{Major}_n^k$ where $k < l$ and $n = E(C^l)/E(C^k)$.  
As an example, for a fair comparison, $C^3$ should be compared with $\text{Major}_3^2$ (majority voting among three $C^2$ critiques) and $\text{Major}_5^1$ (majority voting among five $C^1$ critiques).

\paragraph{Naive voting baseline}
A natural strategy for higher-order critique is to simply aggregate all judgments from previous stages through voting, adding no new analysis but merely following the consensus. The naive voting is defined:

% \vspace{-9mm}

\begin{equation}
\begin{aligned}
    C^1_\text{naive}(R_1, R_2) &\rightarrow \text{Major}(\{A^0_1, A^0_2\}), \\
    C^2_\text{naive}(C^1_1, C^1_2) &\rightarrow \text{Major}(\{A^0_1, A^0_2, A^1_1, A^1_2\}), \\
    C^3_\text{naive}(C^2_1, C^2_2) &\rightarrow \text{Major}(\{A^0_1, A^0_2, A^1_1, A^1_2, A^2_1, A^2_2\}).
\end{aligned}
\end{equation}

% \vspace{-4mm}

We introduce this as a baseline to verify that proposed recursive critique outputs new insights rather than just follow simple vote aggregation results.

\section{Is Recursive Critique Increasingly Easier?}
In this section, we validate the hypothesis that \textit{critique of critique is easier than direct critique} and examine whether \textit{this difficulty relationship holds recursively}.
We conduct experiments across diverse tasks with human annotators of similar abilities, and record their accuracy, completion time, and annotator confidence for analysis.

\subsection{Tasks}

We select five representative tasks, which calls for diverse cognitive capabilities, and remain in moderate difficulty. All tasks include 64 multiple-choice questions.

\paragraph{CET-6} 
College English Test Band 6 (CET-6) is a standardized English proficiency assessment for Chinese university students.
We select one question per passage from its \textit{Careful Reading} section; each passage is 400-450 words and includes multiple-choice questions testing main idea comprehension, vocabulary understanding, or inference abilities.
Given that few annotators have passed CET-6, these questions present a substantial challenge for them.

\paragraph{GAOKAO Chinese}
The chinese reading comprehension questions are drawn from China's National College Entrance Examination (Gaokao).
These questions evaluate comprehensive reading abilities through textual analysis, logical inference, and meaning interpretation.
As our annotators are college graduates who have taken Gaokao before, these questions present moderate difficulty for them.

\paragraph{GAOKAO Math}
The mathematics questions are sourced from standardized high school tests in~\citep{Zhang2023EvaluatingTP}. 
We select first ten multiple-choice problems with moderate difficulty\footnote{Question difficulty increases with problem number.}, as our annotators left campus for a few years and some have non-science backgrounds.

\paragraph{KAOGONG}
The questions are from China's National Civil Service Examination (KAOGONG), the annual government recruitment assessment.
These questions include logical reasoning, verbal comprehension, and quantitative analysis.
We exclude general knowledge questions to focus on cognitive processing rather than factual recall.

\paragraph{Figure Reasoning}
The questions are from the Civil Service Examination as well.
These visual task assesses logical abilities through non-verbal reasoning without requiring extra domain knowledge or cultural context.

\subsection{Setup}
\paragraph{Participants}
We recruit 32 participants with bachelor's degrees, including 22 with STEM backgrounds and 10 with liberal arts backgrounds. Most participants passed CET-4 level English and achieved approximately 100 scores (out of 150) in high school math exam.
Meawhile, most participants have full-time data annotation experience.
% During the study, 7 annotators replaced some original participants while maintaining the total at 32.
% The new participants have similar capabilities and backgrounds to the original group.
% These backgrounds collectively ensure comparable cognitive capabilities among our annotators, providing a consistent evaluation basis.

\input{table/table_1}
\input{table/table_2}

\paragraph{Execution}
We write standardized annotation guidelines for all tasks through descriptive instructions and examples, detailed in Appendix \ref{sec:human_guide}.
Tasks are distributed in data packages with specified submission deadlines, with random assignments across different critique levels to ensure all annotators participate in various stages.
To maintain efficiency, we set a 20-minute time limit for each question at every critique stage.
While time constraint exists, it is managed through package-level deadlines to allow flexible time allocation.
Annotators complete a set number of tasks daily within their scheduled working hours.
Feedback sessions are held to collect comments and suggestions for procedure or guideline improvement.
We assign personnel for process management and annotation quality assurance.

\paragraph{Metrics}
We assess the effectiveness of recursive criticism through three metrics: (i) accuracy measures the consistency with the standard answers; (ii) completion time records the duration of the entire process, including analysis and answer provision; (iii) confidence reflects self-assessed certainty in the final answer on a five-point scale.

\subsection{Critique of Critique can be Easier than Critique}

\input{table/table_3}

We validate the hypothesis that \textit{critique of critique is easier than critique} across five tasks.
The results in Table \ref{tab:human_coc} present consistent improvements from response to critique to $C^2$ stages.
Take GAOKAO Math as an example, the average accuracy improves from 66.29\% (response) to 82.50\% (critique) and further to 90.62\% ($C^2$), while completion time remains stable or slightly decreases (e.g., from 18.36 to 15.82 minutes for CET 6).
Under comparable effort, majority voting shows similar trends.
For example, accuracy improves from 81.81\% (response) through 86.61\% (critique) to 90.62\% ($C^2$) in GAOKAO Math, demonstrating the advantage of higher-order criticism.
Compared to naive voting, average accuracy consistently performs better.
Take GAOKAO Math as an example, naive voting achieves only 66.41\% at critique stage and 81.25\% at $C^2$, significantly lower than average accuracy 90.62\%.
These results validate that recursive critique generates new insights rather than merely aggregating previous judgments.
Moreover, annotator confidence shows steady improvement across stages, suggesting that higher-order criticism becomes more tractable.

\subsection{Recursive Critique Remains Consistently Easier}

We extend the recursive criticism to the third-order critique ($C^3$) on two representative tasks.
As shown in Table \ref{tab:human_c3}, accuracy improves continuously at the $C^3$ level in both tasks, with CET-6 increasing from 60.94\% at $C^2$ to 67.19\%, and GAOKAO Math from 90.62\% to 93.75\%.
More importantly, under comparable computational effort, majority voting shows similar improvements, reaching 67.19\% for CET-6 and 93.75\% for GAOKAO Math at $C^3$ level.
Furthermore, naive voting achieves substantially lower performance than regular accuracy.
These comparisons demonstrate that the effectiveness of recursive critique extends beyond mere computational scaling or consensus aggregation.
Improving confidence scores and decreasing completion time further validate that \textit{recursive critique remains consistently easier}.

\section{Can Recursive Self-Critiquing Enable Human Oversight of AI?}

In this section, we examine whether recursive critique enables effective human oversight when capabilities exceed human performance by asking human to evaluate AI-generated outputs and AI self-criticisms.

\subsection{Tasks}
We select tasks that AI demonstrates superior performance than our human annotators' performance.
The GAOKAO Math comprises the last two multiple-choice questions from high school mathematics examination \citep{Zhang2023EvaluatingTP}, while the TEM4 (Test for English Majors Grade Four) include reading comprehension questions.
Mathematics questions demand advanced problem-solving skills, and TEM-4 questions require professional-level English proficiency. Both tasks are beyond most annotators' abilities.

\subsection{Setup}
\label{sec:human_ai_setup}
We employ the same annotators and evaluation metrics (accuracy, completion time, and confidence scores) as in Human-Human experiments.
To generate AI responses, we utilize both Qwen-7B and Qwen-72B models \citep{qwen2025qwen25technicalreport} to examine recursive criticism across different AI capability levels.
We filter out questions on which models achieve either 0\% or 100\% accuracy, as these extremely easy or difficult tasks lead to uniform model outputs, making them unsuitable for validating recursive criticism.
For each question, the AI model first outputs initial responses, then performs self-criticism recursively to certain orders ($C^1$, $C^2$). 
Human annotators only evaluate the final AI outputs.
% rather than participating in the intermediate critique process.
The annotation process follows the Human-Human procedure, except outputs are AI-generated.

\subsection{Experimental Results}

\paragraph{Recursive critique enables effective human oversight of AI.}
Table \ref{tab:human_ai} indicates that humans' response accuracy is lower than that of AI, showing that AI surpasses human in these tasks.
However, for the following critique, humans consistently achieve higher accuracy than AI's previous outputs.
For example, with Qwen2.5-7B on GAOKAO Math, human accuracy reach 53.12\% at the critique stage (7.03\% higher than AI's initial 46.09\%), and further increases to 56.25\% at $C^2$ (8.59\% above AI's critique stage).
This finding suggests that recursive criticism enables human supervision even when AI outperforms human for generation.
% \vspace{-0.5em} % 根据需要调整负值

\paragraph{Recursive critique improves evaluation efficiency and confidence.}
Despite processing more information at higher levels, completion time generally decreases or remains stable. 
For TEM4 with Qwen-72B, time decreases from 22.44 minutes at response level to 15.47 minutes at $C^2$. 
Meanwhile, annotator confidence shows consistent improvement across levels and model scales, particularly in the mathematics task with Qwen-72B where confidence increases from 2.19 to 3.63. 
These results suggest that recursive criticism makes evaluation more tractable.

\section{Can AI Perform Recursive Self-Critiquing?}

To investigate the effectiveness of the Recursive Self-Critiquing protocol on existing AI models, we conduct experiments on a wide range of LLMs.
% representative
\subsection{Setup}
 We utilize multiple reasoning, knowledge, and alignment-related datasets, including MATH~\citep{hendrycks2021measuring}, GPQA~\citep{rein2023gpqa}, TruthfulQA~\citep{lin-etal-2022-truthfulqa}, MMLU-Pro~\citep{wang2024mmlu}, and BoolQ~\citep{clark-etal-2019-boolq}, as detailed in Appendix~\ref{sec:task_info}. We adopt consistent metrics (Accuracy) and baselines (Majority Voting and Naive Voting) as in human experiments. Each score in the experiments is averaged over 10 different runs. Main results is listed in this section and additional results are included in Appendix~\ref{sec:additional_res}.

% 为了进一步研究图2中低准确率区域（这意味着它们对模型来说可能更具挑战性）的表现，在Table 4, 5, 6, 12, 13中，为了更清晰地比较各阶段Critic和Voting方法对困难样本的处理能力，我们选取了10次采样中单样本点response准确率在[0, 0.7]之间的数据点，并计算了这部分数据点在低阶与更高阶Critic上的准确率以及Voting准确率。

To further investigate the performance in low-accuracy regions shown in Figure \ref{fig:machine_all_avg} (which suggests these samples may be more challenging for the model), in Tables \ref{tab:gemma}, \ref{tab:qwen}, \ref{tab:sub_items}, \ref{tab:add_gemma}, and \ref{tab:add_qwen}, we selected data points where the response accuracy fell within the (0, 0.7) range across 10 sampling iterations. We calculated the accuracy rates of these challenging data points across both lower-order and higher-order critics, as well as the voting accuracy.

\subsection{Experimental Results}

\paragraph{Current AI Models struggle to perform recursive critique tasks.}

% 每一句话需要更完整一些。

\begin{figure*}
    \centering
    \includegraphics[width=\linewidth]{figures/machine_qwen25_ave_all.pdf}
    % \caption{The average accuracy improvement of critic and recursive critic stage compared to direct response from various models in BoolQ dataset. The improvement is defined as the exponential of the difference between the accuracy of the remaining stages and the direct response accuracy, and the samples are binned based on their accuracy (i.e., $Q' = \{q \mid \mu_1 < \text{Acc}(q) < \mu_2, q \in Q\}$)}
    \vspace{-0.5cm}
    \caption{The relative accuracy improvement of critique and recursive critique stages compared to the response stage. Scores are averaged across all datasets. The improvement is calculated as exp(Acc\_stage - Acc\_response), where samples are grouped according to their response accuracy levels.}
    \label{fig:machine_all_avg}
    \vskip -7mm
\end{figure*}

We plot the average imporvement of critique and recursive cirtics over response stage in Figure~\ref{fig:machine_all_avg}, where we find that the performance of critiques and higher-order critiques remains constrained in most scenarios. In detail, critique, critique of critique ($C^2$) and third-order critiques ($C^3$) struggle to surpass the accuracy levels achieved at the Response stages. This phenomenon suggests that current models may have limited capacity for self-critiquing, which is also partially validated in the work of~\citet{huang2023large}, ~\citet{tang2025enabling} and summarized by~\citet{kamoi2024can}. This finding further highlight the importance of post-training models to perform better critique tasks as in~\citet{mcaleese2024llm}.

\input{table/gemma}
\input{table/qwen14}
\input{table/compare}

\paragraph{Potential effectiveness in specific models.} 
We further compare the performance of Qwen and Gemma model across different datasets, following the setting in Section \ref{sec:human_ai_setup}. The results are shown in Table \ref{tab:gemma} and Table \ref{tab:qwen}. From these results, we can observe that the disparity of higher-order critiquing ability exists in specific models. Although performance is limited, Qwen-2.5-14B-Instruct exhibits more effective in high-order critiquing, as we can observe progressive improvements between response and recursive critiques across stages.
Further performance gap analysis reveals that the main discrepancies may arise from those gap in distinguishing the true statements from mixed true and false inputs (Table \ref{tab:sub_items}).

\begin{figure*}[t]
    \centering
    \includegraphics[width=\linewidth]{figures/hack_illu.pdf}
    \vspace{-0.3cm}
    \caption{Illustration of challenges in RLHF: (1) Golden RM has fixed capability ceiling; (2) Proxy RM suffers from degrading supervision as policies improve; (3) Iterative annotation provides temporary improvements through human intervention; (4) Tool-augmentation achieves higher but still limited performance. (5) The ideal scenario requires RM capabilities to scale alongside policy model improvements.}
    \label{fig:hack}
    \vskip -4mm
\end{figure*}

\section{Related Works}
% http://arxiv.org/abs/2401.04518

% 大多数 Scalable Oversight 的工作的核心都是研发一套协议，弱标注者/模型依据该协议，能够更快更好的地对强AI进行监督。我们将在本章节主要解释Critic-of-Critic与这些协议的区别。

% \paragraph{Debate} 两个模型/人对两个相反的答案进行辩论。辩论论据的产生可以是同步的，也可以是异步的。在一些变体中，Judge也可以与Debater进行交互~\citep{,,,}。已经有一些工作对Debate作为一种可扩展监督方案在部分实用场景下的效果进行了分析，比如\citet{}与\citet{}分别在QuALITY上对debate进行了机器和人工实验，均取得了积极的效果，而\citet{}则在更广泛的推理的任务上对debate进行了大量评估，debate在很多任务上未展现出明显的收益。(Market Making)。Critic of Critic 与 Debate 的区别在于Critic并没有零和的假设，Judge可以选择不相信任何一方做出自己的判断，也可以选择采纳双方的一致的答案。

% \paragraph{Task Decomposition} 认为对难问题的监督可以转换为对一系列子问题的监督并合并的行为。有一些工作分别在策略模型~\citep{}与奖励模型~\citep{}上提出了这些构想。Critic of Critic 也可以视为一种从复杂任务到具体子任务的规约，但是它并不要求得到所有子问题的解才能得到整个任务的解，递归结构上其与debate相似，比起广度优先搜索的任务分解更像是深度优先搜索。

Many works have been dedicated to developing protocols that enable weak annotators to supervise strong AI systems.

\paragraph{Debate} This protocol~\citep{irving2018ai} involves two models/humans debating opposing answers. Arguments can be generated synchronously or asynchronously. In certain variants like iteractivate debate, the Judge can interact with the Debaters~\citep{khan2024debating}. Several studies have analyzed debate as a scalable oversight approach in practical settings. For example, \citet{khan2024debating} and \citet{michael2023debate} conducted machine and human experiments respectively on QuALITY dataset with promising results, while~\citet{kenton2024scalable} evaluated debate extensively on broader reasoning tasks but found limited benefits. The key difference between critique of critique and Debate is that critique does not assume a zero-sum game - the Judge can reject both sides and make independent judgments, or accept consensus answers from both response or critiques.

\vspace{-3mm}

\paragraph{Task Decomposition} This approach posits that oversight of difficult problems can be reduced to supervising and combining solutions to sub-problems. Previous works ~\citep{christiano2018supervising,wu2021recursivelysummarizingbookshuman} have explored this concept for both policy models and reward models (i.e., Recursive Reward Modeling). While critique of critique can be viewed as reducing complex tasks to specific sub-tasks, it does not require solving all sub-problems to resolve the overall task. Its recursive structure resembles debate more than task decomposition - it employs depth-first rather than breadth-first search in breaking down problems.

\section{Discusssion}
\paragraph{Limitations in Current AI Alignment Methods.}
RLHF has emerged as the dominant approach in AI alignment, building upon the fundamental principle that “verification is easier than generation” \citep{irving2018aisafetydebate}.
As illustrated in Figure \ref{fig:hack}, the optimal RLHF setup requires direct human preferences (Golden RM) for policy optimization. 
However, the acquisition of real-time human feedback during training presents significant operational challenges.
This limitation necessitates the deployment of static reward models as proxies for human judgment. 
Such reliance on static proxies introduces a fundamental challenge: reward hacking \citep{gao2022scalinglawsrewardmodel,karwowski2023goodhartslawreinforcementlearning}, optimizing against proxy reward models rather than ideal human preferences can lead to policies that diverge from intended objectives due to Goodhart's Law \citep{manheim2019categorizingvariantsgoodhartslaw,karwowski2023goodhartslawreinforcementlearning,wen2024rethinkingrewardmodelevaluation}.
While approaches such as iterative annotation and tool augmentation \citep{li2024toolaugmentedrewardmodeling,gou2024criticlargelanguagemodels} provide intermediate solutions, they ultimately encounter the supervision capability limitations.
Addressing reward hacking requires reward model capabilities to scale alongside policy model improvements. 
The recursive criticism framework, while not eliminating reward hacking entirely, offers a promising approach by enabling sustained human oversight even as direct evaluation becomes intractable.

\paragraph{The Possible Mechanism of Recursive Self-Critiquing.}

% 首先，高阶批评会逐步将关注点从特定领域的细节转移到更抽象的评估原则上，这使得即使在底层内容复杂性增加的情况下，任务也变得更容易处理。

% 其次，每个批评层级都增加了较为结构化的上下文，有助于后续评估的评论者能够在前期分析的基础上进行深入，而不是重新开始。

% 第三，递归结构将绝对评估任务转化为一系列比较性判断，充分利用了人类在相对评估方面相比绝对评估的认知优势。这与认知科学的发现相一致，即当提供清晰的评估标准和结构化信息时，人类在比较性判断方面往往表现得比绝对评估更好。

The effectiveness of recursive self-critiquing in Human-Human and Human-AI experiments likely stems from several key mechanisms. First, higher-order criticism progressively shifts human's attanetion from specific details to more abstract evaluation principles, making the task more tractable even as context length increases. Second, each critique level provides structured context that helps frame subsequent evaluation, allowing critiques to build on previous analyses rather than starting fresh. Third, the recursive structure transforms absolute evaluation tasks into a series of pairwise judgments, leveraging humans' cognitive advantage in relative assessment over absolute evaluation. This aligns with cognitive science findings~\citep{jones2015problem,kelly2022critiquing} that humans often perform better at comparative judgment than absolute evaluation, particularly when provided with structured information.

\vspace{-2mm}

\paragraph{Improving AI Critique Capabilities.}

% 我们的研究结果为训练具有递归批评能力的人工智能系统提出了几个有前途的方向：

% 第一，我们在人工智能实验中观察到的生成能力和批评能力之间的不对称性表明，可能需要专门的架构或训练方法来完成更高层次的批评任务。模型可以被明确训练以在更高层次的批评中生成越来越抽象的评估标准，而不是仅仅汇总低层次的判断。此外，我们建议未来的工作应该探索如何保持人工智能生成的批评的充分多样性，可能通过集成方法或明确的促进多样性的训练目标，以更好地反映人类递归批评中所见到的有效性。

From AI-AI experiments, our findings suggest several promising directions for training AI systems with recursive critique capabilities. Firstly, models could be explicitly trained to more accurately identify critical errors~\citep{xi2024enhancing}, rather than merely aggregating lower-level judgments. Additionally, future work can explore ways to maintain sufficient diversity in AI-generated critiques, perhaps through ensemble methods or explicit diversity-oriented training objectives, to better mirror the effectiveness seen in human recursive self-critiquing experiments. Finally, research into the optimal number of recursive levels and the diminishing returns of additional critique iterations could help establish practical guidelines for implementing recursive critique systems effectively.

\section{Conclusion}
This work investigates how to obtain reliable supervision signals when AI capabilities surpass human abilities.
Through comprehensive experiments in human-human, human-AI, and AI-AI contexts, we examine the hypotheses that \textit{critique of critique is easier than critique} and demonstrate that \textit{this difficulty relation holds recursively}.
These insights of recursive self-critiquing mechanisms could be crucial for maintaining effective oversight in scenarios where direct human evaluation becomes infeasible, and suggest a promising pathway for scalable oversight.

% Acknowledgements should only appear in the accepted version.
% \section*{Acknowledgements}

\section*{Impact Statement}

This recursive self-critiquing framework aims to address challenges in scalable AI oversight, enabling more effective human supervision as AI systems become increasingly capable. Beyond technical contributions, this research promotes responsible AI development by involving more people from different backgrounds in AI supervision. While acknowledging potential limitations, we believe this work helps promote social welfare via contributing scalable oversight mechanisms.

% In the unusual situation where you want a paper to appear in the
% references without citing it in the main text, use \nocite
\nocite{langley00}

\bibliography{custom}
\bibliographystyle{icml2025}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% APPENDIX
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newpage
\appendix
\onecolumn
\section{Human Experiments Guidelines}
\label{sec:human_guide}
This section details the guidelines and quality assurance of involved in the Human-Human and Human-AI experiments. 
We establish consistent and comprehensive guidelines for annotation tasks at different stages across different tasks.

Our guidelines emphasize the quality of reasoning process over accuracy rates, requiring annotators to clearly articulate their thinking process \textbf{without accessing external references}.
While accuracy is encouraged, the primary focus is on providing clear, well-reasoned justifications for their decisions.
Annotators are instructed to invest their time primarily in analytical thinking, expressing their reasoning in clear, concise, and logically coherent natural language.
The guidelines provide suggested formats but maintain flexibility, prioritizing the clear documentation of thought processes over rigid adherence to specific forms\footnote{Fixed templates were initially tested but abandoned as annotators reported them inflexible and including unnecessary burden.}.
We provide detailed instruction at each stage in following sections.

\subsection{Response Stage}
In the response stage, annotators are presented with a source text, a question, and multiple choice options. The primary task is to select the correct answer and provide comprehensive reasoning for their choice.

\paragraph{Recommmanded Annotation Template} 
The response should clearly indicate the selected answer and provide a complete reasoning process. 
This process should include specific citations from the source text as evidence, logical analysis that connects the evidence to the conclusion, and step-by-step reasoning where applicable. 
For example, responses can follow two primary patterns:
\begin{itemize}
    \item Option B is correct because [evidence + reasoning].
    \item Options A/C/D are incorrect because [evidence + reasoning], therefore B is selected.
\end{itemize}
Other patterns are also acceptable as long as they maintain clear reasoning and sufficient evidence support.
The examples of high-quality and low-quality responses are provided in Table \ref{tab:response} for illustration.

\begin{CJK*}{UTF8}{gkai}
\begin{table*}[t]
\centering
\caption{High quality and low quality response examples.}
\label{tab:response}
\begin{tabular}{m{1.6cm}|m{2.9cm}|m{1cm}|m{5cm}|m{5cm}}
\toprule
\textbf{Quality} & \textbf{Definition} & \textbf{Type} & \textbf{Example} & \textbf{English Translation} \\
\midrule
\multirow{3}{*}{High quality} & \multirow{3}{=}{Contains three elements: textual evidence, reasoning, and conclusion. Clear and coherent expression with logical flow.} & English & 根据题中的"before the end of the century"可定位到原文"Scientists have already pointed out that unless something ... before this century is out"。从中可以得知如果不采取措施限制人口快速增长或开发新的食物来源，数百万人将在本世纪结束前死于饥饿。因此可推断作者认为世界最大的问题是如何养活日益增长的人口，选B。 & Based on the phrase "before the end of the century", we can locate "Scientists have already pointed out that unless something ... before this century is out". This indicates that without measures to limit population growth or develop new food sources, millions will face starvation. Therefore, feeding the growing population appears to be the major challenge, supporting option B. \\ 
\cline{3-5}
 & & Chinese & 文章第三段说："由于杂交水稻不同熟期组合的出现，全国各地涌现出各种与杂交水稻种植相配套的新型种植模式。"杂交水稻和新型种植模式的出现是因果关系，而不是正好与新型种植模式相配，所以选D。 & The third paragraph states: "Due to the emergence of hybrid rice varieties with different maturity periods, new planting patterns have emerged nationwide to match hybrid rice cultivation." The relationship between hybrid rice and new planting patterns is causal, not just coincidental matching, therefore D is correct. \\
\cline{3-5}
 & & Math & 首先化简$f(x)=2\cos^2x-\sin^2x+2$，根据二倍角公式$\cos2x=2\cos^2x-1$，得到$2\cos^2x=\cos2x+1$。因为$\sin^2x+\cos^2x=1$，所以$\sin^2x=(1-\cos2x)/2$。最终得到$f(x)=\frac{3}{2}\cos2x+\frac{5}{2}$。通过周期计算和最值分析，得到答案B。 & First simplify $f(x)=2\cos^2x-\sin^2x+2$. Using double angle formula $\cos2x=2\cos^2x-1$, we get $2\cos^2x=\cos2x+1$. Since $\sin^2x+\cos^2x=1$, we derive $\sin^2x=(1-\cos2x)/2$. Finally $f(x)=\frac{3}{2}\cos2x+\frac{5}{2}$. Through period calculation and maximum analysis, we arrive at answer B. \\
\hline
\multirow{3}{*}{Low quality} & \multirow{3}{=}{Missing key elements, unclear reasoning, or lack of evidence support.} & English & 文章第一句"The gift of being able to describe a face accurately is a rare one"就点明文章主要内容为A。 & The first sentence "The gift of being able to describe a face accurately is a rare one" directly points to option A. \\
\cline{3-5}
 & & Chinese & 答案C错在：那些已经被认定，应...，原文说的是这种代代相传的非物质文化遗产得到创新（过程中），同时使他们自己具有一种认同感和历史感。 & Option C is wrong because: those already recognized should..., the text actually discusses how this inherited intangible cultural heritage achieves innovation while maintaining a sense of identity and history. \\
\cline{3-5}
 & & Math & 因为$\sin^2x + \cos^2x = 1$，所以$f(x)=\frac{3}{2}\cos2x+\frac{5}{2}$，$T=\pi$，$\max f(x)=4$。 & Since $\sin^2x + \cos^2x = 1$, we have $f(x)=\frac{3}{2}\cos2x+\frac{5}{2}$, $T=\pi$, $\max f(x)=4$. \\
\bottomrule
\end{tabular}
\end{table*}
\end{CJK*}

\paragraph{Quality Requirements}
Response annotations must satisfy four fundamental criteria:
\begin{itemize}
    \item Relevance: Direct connection to the question and source text
    \item Organization: Clear logical structure and information flow
    \item Clarity: Concise expression without unnecessary complexity
    \item Coherence: Smooth transitions between reasoning steps
\end{itemize}

\subsection{Critique Stage Annotation}
In the critique stage, annotators evaluate two responses from the previous stage based on the source text and question. 
The evaluation should focus on the correctness of responses, examining their logical coherence and evidence support. 

\paragraph{Recommended Annotation Template}
The critiques should clearly present the final judgment and supporting rationale with referenced evidence cited in the responses or the question.
For example, common annotation patterns include:
\begin{itemize}
    \item Agreement with Response 1 with specific justification, noting uncertainties or disagreements with Response 2.
    \item Agreement with Response 1 with justification, identifying specific errors in Response 2.
    \item Agreement with both responses, providing supporting evidence for the shared conclusion.
    \item Disagreement with both responses, detailing specific errors and providing justification for an alternative answer.
\end{itemize}
Critiques should prioritize identifying key errors that affect the final judgment, while minor issues that do not impact the conclusion are optional.
The high quality and low quality examples is presented in Table \ref{tab:critic} and Table \ref{tab:critic_english}.

\begin{CJK*}{UTF8}{gkai}
\begin{table}[t]
\small
\centering
\caption{High quality and low quality critique annotation examples.}
\label{tab:critic}
\begin{tabular}{p{4cm}|p{5cm}|p{5cm}}
\toprule
\multicolumn{1}{c|}{\textbf{Question}} & \multicolumn{1}{c|}{\textbf{Response1}} & \multicolumn{1}{c}{\textbf{Response2}} \\
\hline
根据原文提供的信息，下列选项中，没有体现传统技艺传承价值的一项是

A．农业生产的犁、耙、锄等工具的利用
B．日常生活中医药的陶罐、竹器等物品的制作
C．社会行业中的造纸、印刷、染织等手工艺
D．民俗文化中的剪纸、皮影、年画等艺术的创作 & 作者主要介绍了传统技艺作为非物质文化遗产有着丰富的文化内涵和艺术价值，传统技艺中具有的民生价值、艺术价值、历史文化价值均是其传承价值所在。

选项A提到的内容没有体现传统技艺传承价值，原因是文章提虽然到了犁、耙、锄等工具的制作是传统手工艺的印记，体现了传统技艺传承价值，但选项重点在于对工具的利用，这并未体现。相关的内容是[农业耕作所需要的犁、耙、锄，饮食起居所需要的陶罐、簸箕、箩筐，交通运输所需要的担、船、轿，以及织锦、染布、造纸等日常生活所需要的各种物品，都留下了手工艺的印记]。因此，我认为答案是「A」。 & 文章主要探讨了传统技艺的定义，价值和重要性

选项A可能正确的原因：文章中提到「农业耕作所需要的犁、耙、锄」，「具有民生价值」相关的内容说明这些农业生产的相关工具可以体现传统技艺传承价值。此外，选项C可以由原文中「以及织锦、染布、造纸等日常生活所需要的各种物品」，「具有民生价值、艺术价值」的相关内容得作证，而选项D可以由「木雕、石雕、玉雕、泥塑、面塑给人以美的愉悦，剪纸、刻纸、皮影、年画有丰富的文化内涵和艺术价值」，「具有艺术价值、历史文化价值」得到佐证。

而选项B是错误的原因可参考原文「饮食起居所需要的陶罐、簸箕、箩筐」，可以看到原文是饮食起居的陶罐，而不是医药的陶罐。

综合上述分析，答案是「B」。 \\
\hline
\multicolumn{3}{c}{\textbf{High Quality Examples}} \\
\hline
\multicolumn{3}{p{15cm}}{不同意Response1的答案（A）。Response1引用了相关的段落，但认为相关内容「重点在于对工具的利用」，而不是体现传统技艺传承价值。但他引用的内容里提到了「留下了手工艺的印记」，我认为这个内容正体现了农业生产的犁、耙、锄是体现传统技艺传承价值的。认可Response 2的答案（B）。

Response2分析了选项B，并指出「原文提到的是饮食起居的陶罐，而不是医药的陶罐」，他引用了文章中对应内容确实和选项是不符合的。此外，他还分析了选项ACD，并找到了对应的参考内容佐证。但他对于选项A的分析需要纠正，他引用的文章内容「农业生产的犁、耙、锄等工具的利用」和「具有的民生价值」并不在一个段落内，不能论证他的分析。但第四段的开头「手工艺始于对自然物质的利用和各种工具的制造和使用」之后出现的相关描述确实说明了选择A体现了传统技艺传承价值。因此答案应该是（B）。} \\
\hline
\multicolumn{3}{p{15cm}}{认可Response 2的答案（B），他引用的文章内容「饮食起居所需要的陶罐、簸箕、箩筐」和选项B「医药的陶罐、竹器等物品」确实是不一致的。而Response1的选择（A），他引用[农业耕作所需要的犁、耙、锄，饮食起居所需要的陶罐、簸箕、箩筐，...都留下了手工艺的印记]里的"手工艺"我认为是传统技艺的一部分，因此不应该选答案A。因此答案应该是（B）。} \\
\hline
\multicolumn{3}{p{15cm}}{认可Response 2的答案（B），他引用了文章内容「饮食起居所需要的陶罐、簸箕、箩筐」，而选项B「医药的陶罐、竹器」明显是不一致的，这很可能是题目设下的陷阱，因此Response的2答案应该是对的。而Response1虽然对选项（A）可能是错误的原因做了分析，但基于前面对答案B的分析，它明显是对，因此不该选选项A。因此答案应该是（B）。} \\
\hline
\multicolumn{3}{c}{\textbf{Low Quality Examples}} \\
\hline
\multicolumn{3}{p{14cm}}{认可response 1的答案，不同意Response2的答案，答案应该是（B）。} \\
\bottomrule
\end{tabular}
\end{table}
\end{CJK*}

\begin{table}[t]
\small
\centering
\caption{English translations of high quality and low quality critique annotation examples in Table \ref{tab:critic}.}
\label{tab:critic_english}
\begin{tabular}{p{4cm}|p{5cm}|p{5cm}}
\toprule
\multicolumn{1}{c|}{\textbf{Question}} & \multicolumn{1}{c|}{\textbf{Response1}} & \multicolumn{1}{c}{\textbf{Response2}} \\
\hline
According to the text, which of the following does NOT reflect the inheritance value of traditional craftsmanship?

A. The use of agricultural tools like plows, harrows, and hoes
B. The making of medical pottery and bamboo utensils in daily life
C. The handicrafts in social industries such as papermaking, printing, and dyeing
D. The folk art creations such as paper-cutting, shadow puppets, and New Year paintings & The author mainly introduces traditional crafts as intangible cultural heritage with rich cultural connotations and artistic value. Traditional crafts possess livelihood value, artistic value, and historical-cultural value as their inheritance value.

Option A does not reflect traditional craft inheritance value. While the text mentions the tools like plows, harrows, and hoes as traditional handicraft marks, reflecting craft inheritance value, the option focuses on tool usage, which is not demonstrated. The relevant content states [Agricultural tools like plows, harrows, and hoes, kitchenware like pottery, baskets, and hampers, transportation tools like carriers, boats, and sedan chairs, and daily necessities like brocade, dyed cloth, and paper, all bear handicraft marks]. Therefore, I believe the answer is "A". & The article mainly discusses the definition, value, and importance of traditional crafts.

For Option A: The text mentions "agricultural tools like plows, harrows, and hoes" and their "livelihood value", suggesting these tools reflect traditional craft inheritance value. Additionally, Option C is supported by "daily necessities like brocade, dyed cloth, and paper" showing "livelihood and artistic value", while Option D is evidenced by "wood carving, stone carving, jade carving, clay sculpture, and dough modeling bring aesthetic pleasure, while paper-cutting, paper carving, shadow puppets, and New Year paintings have rich cultural connotations and artistic value".

Option B is incorrect as the text mentions "kitchenware pottery" rather than medical pottery.

Based on this analysis, the answer is "B". \\
\hline
\multicolumn{3}{c}{\textbf{High Quality Examples}} \\
\hline
\multicolumn{3}{p{15cm}}{Disagree with Response 1's answer (A). While Response 1 cites relevant passages, its interpretation that "focus is on tool usage" misses the point about traditional craft inheritance value. The cited phrase "left craftmanship marks" actually demonstrates that agricultural tools reflect traditional craft value. Agree with Response 2's answer (B).

Response 2 correctly analyzes Option B, noting that the text mentions "kitchenware pottery" rather than "medical pottery", with accurate textual evidence. They also provide well-supported analysis for Options A, C, and D. However, their reasoning for Option A needs correction - the connection between "agricultural tools" and "livelihood value" isn't supported by being in different paragraphs. Nevertheless, the fourth paragraph's opening about "handicrafts beginning with the use of natural materials and tool manufacturing" supports that Option A reflects traditional craft value. Therefore, the answer should be (B).} \\
\hline
\multicolumn{3}{p{15cm}}{Agree with Response 2's answer (B). Their citation of "kitchenware pottery" from the text clearly contradicts Option B's "medical pottery". Regarding Response 1's choice of (A), the reference to "handicraft marks" in the passage about agricultural tools suggests this is part of traditional craftsmanship, so A should not be the answer. Therefore, the answer is (B).} \\
\hline
\multicolumn{3}{p{15cm}}{Support Response 2's answer (B). They correctly identified the discrepancy between "kitchenware pottery" in the text and "medical pottery" in Option B, which appears to be an intentional distinction. While Response 1 analyzes why Option A might be incorrect, based on the analysis of Option B being clearly wrong, Option A cannot be the answer. Therefore, the answer should be (B).} \\
\hline
\multicolumn{3}{c}{\textbf{Low Quality Examples}} \\
\hline
\multicolumn{3}{p{14cm}}{Agree with Response 1, disagree with Response 2, the answer should be (B).} \\
\bottomrule
\end{tabular}
\end{table}

\paragraph{Quality Requirements}
critique annotations must satisfy five fundamental criteria:
\begin{itemize}
    \item Relevance: Direct connection to the question and source text
    \item Organization: Clear logical structure and information flow
    \item Clarity: Concise expression without unnecessary complexity
    \item Coherence: Smooth transitions between reasoning steps
    \item Objectivity: Fair analysis of responses' strengths and weaknesses
\end{itemize}

\subsection{Higher-Order Critique Stage}

In the higher-order critique stage, annotators evaluate two critique annotations based on the source text, question, and responses. The evaluation should focus on assessing the critiques' reasoning process, examining the validity of their evidence analysis, and identifying any logical gaps or oversights.

\paragraph{Recommended Annotation Template}
The higher-order critiques should clearly present their evaluation of both critiques' analyses and provide a final judgment with supporting rationale. For example, common annotation patterns include:

\begin{itemize}
    \item Agreement with Critic 1 with specific justification, noting uncertainties or disagreements with Critic 2.
    \item Agreement with Critic 1 with justification, identifying specific errors in Critic 2's analysis.
    \item Agreement with both critics, acknowledging their shared valid points while noting potential weaknesses.
    \item Disagreement with both critics, detailing specific logical flaws and providing independent justification.
\end{itemize}

Critics should prioritize identifying key errors in the critics' reasoning while noting potential improvements even when agreeing with their conclusions.

\paragraph{Quality Requirements}

Higher-order critique annotations must satisfy six fundamental criteria:

\begin{itemize}
    \item Relevance: Direct connection to the question and critics' analyses.
    \item Organization: Clear logical structure and information flow.
    \item Clarity: Concise expression without unnecessary complexity.
    \item Coherence: Smooth transitions between reasoning steps.
    \item Objectivity: Fair analysis of critics' strengths and weaknesses.
    \item \textbf{Improvement: Identification of gaps or potential enhancements in critics' reasoning.}
\end{itemize}

Examples of high-quality and low-quality higher-order critiques are presented in Tables \ref{tab:coc} and \ref{tab:coc_english}.

\begin{CJK*}{UTF8}{gkai}
\begin{table}[t]
\small
\centering
\caption{High quality and low quality higher-order critic annotation examples.}
\label{tab:coc}
\begin{tabular}{p{4cm}|p{5.5cm}|p{5.5cm}}
\toprule
\multicolumn{1}{c|}{\textbf{Question}} & \multicolumn{1}{c|}{\textbf{Response 1}} & \multicolumn{1}{c}{\textbf{Response 2}} \\
\hline
\begin{minipage}[t]{4cm}
根据原文提供的信息，下列选项中，没有体现传统技艺传承价值的一项是
A．农业生产的犁、耙、锄等工具的利用
B．日常生活中医药的陶罐、竹器等物品的制作
C．社会行业中的造纸、印刷、染织等手工艺
D．民俗文化中的剪纸、皮影、年画等艺术的创作
\end{minipage} &  作者主要介绍了传统技艺作为非物质文化遗产有着丰富的文化内涵和艺术价值，传统技艺中具有的民生价值、艺术价值、历史文化价值均是其传承价值所在。

选项A提到的内容没有体现传统技艺传承价值，原因是文章提虽然到了犁、耙、锄等工具的制作是传统手工艺的印记，体现了传统技艺传承价值，但选项重点在于对工具的利用，这并未体现。相关的内容是[农业耕作所需要的犁、耙、锄，饮食起居所需要的陶罐、簸箕、箩筐，交通运输所需要的担、船、轿，以及织锦、染布、造纸等日常生活所需要的各种物品，都留下了手工艺的印记]。因此，我认为答案是「A」。 & 文章主要探讨了传统技艺的定义，价值和重要性

选项A可能正确的原因：文章中提到「农业耕作所需要的犁、耙、锄」，「具有民生价值」相关的内容说明这些农业生产的相关工具可以体现传统技艺传承价值。此外，选项C可以由原文中「以及织锦、染布、造纸等日常生活所需要的各种物品」，「具有民生价值、艺术价值」的相关内容得作证，而选项D可以由「木雕、石雕、玉雕、泥塑、面塑给人以美的愉悦，剪纸、刻纸、皮影、年画有丰富的文化内涵和艺术价值」，「具有艺术价值、历史文化价值」得到佐证。

而选项B是错误的原因可参考原文「饮食起居所需要的陶罐、簸箕、箩筐」，可以看到原文是饮食起居的陶罐，而不是医药的陶罐。

综合上述分析，答案是「B」。 \\
\cline{2-3}
 & \multicolumn{1}{c|}{\textbf{Critic 1}} & \multicolumn{1}{c}{\textbf{Critic 2}} \\
\cline{2-3}
 & 不同意Response1的答案（A）。Response1引用了相关的段落，但认为相关内容「重点在于对工具的利用」，而不是体现传统技艺传承价值。但他引用的内容里提到了「留下了手工艺的印记」，我认为这个内容正体现了农业生产的犁、耙、锄是体现传统技艺传承价值的。

Response2分析了选项B，并指出「原文提到的是饮食起居的陶罐，而不是医药的陶罐」，他引用了文章中对应内容确实和选项是不符合的。此外，他还分析了选项ACD，并找到了对应的参考内容佐证。因此答案应该是（B）。 & 认可Response 2的答案（B），他引用的文章内容「饮食起居所需要的陶罐、簸箕、箩筐」和选项B「医药的陶罐、竹器等物品」确实是不一致的。而Response1的选择（A），他引用[农业耕作所需要的犁、耙、锄，饮食起居所需要的陶罐、簸箕、箩筐，...都留下了手工艺的印记]里的"手工艺"我认为是传统技艺的一部分，因此不应该选答案A。因此答案应该是（B）。 \\
\hline
\multicolumn{3}{c}{\textbf{High Quality Examples}} \\
\hline
\multicolumn{3}{p{15cm}}{认可Critic 1和2的答案（B），两个Critc都指出答案是B的原因是：文章内容「饮食起居所需要的陶罐、簸箕、箩筐」和选项B「医药的陶罐、竹器等物品」的不一致，因此没有体现传统技艺传承价值。} \\
\hline
\multicolumn{3}{p{15cm}}{认可Critic 1和2关于答案（B）的分析，文章内容「饮食起居所需要的陶罐、簸箕、箩筐」和选项B「医药的陶罐、竹器等物品」不一致。但Critic2对于Response1对于选项A错误之处的分析，我觉得理由不充分，「手工艺的印记]不一定直接和「传统技艺」关联，但主要下判断的原因是选项B明显是正确答案。} \\
\hline
\multicolumn{3}{c}{\textbf{Low Quality Examples}} \\
\hline
\multicolumn{3}{p{15cm}}{Critc 1/2的答案是对，应该是（B）。} \\
\bottomrule
\end{tabular}
\end{table}
\end{CJK*}

\begin{table}[t]
\small
\centering
\caption{English translations of high quality and low quality higher-order critic annotation examples in Table \ref{tab:coc}.}
\label{tab:coc_english}
\begin{tabular}{p{4cm}|p{5.5cm}|p{5.5cm}}
\toprule
\multicolumn{1}{c|}{\textbf{Question}} & \multicolumn{1}{c|}{\textbf{Response 1}} & \multicolumn{1}{c}{\textbf{Response 2}} \\
\hline
\begin{minipage}[t]{4cm}
According to the text, which of the following does NOT reflect the inheritance value of traditional craftsmanship?

A. The use of agricultural tools like plows, harrows, and hoes

B. The making of medical pottery and bamboo utensils in daily life

C. The handicrafts in social industries such as papermaking, printing, and dyeing

D. The folk art creations such as paper-cutting, shadow puppets, and New Year paintings
\end{minipage} & The author mainly introduces traditional crafts as intangible cultural heritage with rich cultural connotations and artistic value. Traditional crafts possess livelihood value, artistic value, and historical-cultural value as their inheritance value.

Option A does not reflect traditional craft inheritance value. While the text mentions tools like plows, harrows, and hoes as traditional handicraft marks, reflecting craft inheritance value, the option focuses on tool usage, which is not demonstrated. The relevant content states [Agricultural tools like plows, harrows, and hoes, kitchenware like pottery, baskets, and hampers, transportation tools like carriers, boats, and sedan chairs, and daily necessities like brocade, dyed cloth, and paper, all bear handicraft marks]. Therefore, I believe the answer is "A". & The article mainly discusses the definition, value, and importance of traditional crafts.

For Option A: The text mentions "agricultural tools like plows, harrows, and hoes" and their "livelihood value", suggesting these tools reflect traditional craft inheritance value. Additionally, Option C is supported by "daily necessities like brocade, dyed cloth, and paper" showing "livelihood and artistic value", while Option D is evidenced by "wood carving, stone carving, jade carving, clay sculpture, and dough modeling bring aesthetic pleasure, while paper-cutting, paper carving, shadow puppets, and New Year paintings have rich cultural connotations and artistic value".

Option B is incorrect as the text mentions "kitchenware pottery" rather than medical pottery.

Based on this analysis, the answer is "B". \\
\cline{2-3}
 & \multicolumn{1}{c|}{\textbf{Critic 1}} & \multicolumn{1}{c}{\textbf{Critic 2}} \\
\cline{2-3}
 & Disagree with Response 1's answer (A). While Response 1 cites relevant passages, its interpretation that "focus is on tool usage" misses the point about traditional craft inheritance value. The cited phrase "left craftmanship marks" actually demonstrates that agricultural tools reflect traditional craft value.

Response 2 correctly analyzes Option B, noting that the text mentions "kitchenware pottery" rather than "medical pottery", with accurate textual evidence. They also provide well-supported analysis for Options A, C, and D. Therefore, the answer should be (B). & Agree with Response 2's answer (B). Their citation of "kitchenware pottery" from the text clearly contradicts Option B's "medical pottery". Regarding Response 1's choice of (A), the reference to "handicraft marks" in the passage about agricultural tools suggests this is part of traditional craftsmanship, so A should not be the answer. Therefore, the answer is (B). \\
\hline
\multicolumn{3}{c}{\textbf{High Quality Examples}} \\
\hline
\multicolumn{3}{p{15cm}}{Agree with both Critics' answer (B). Both critics point out that the discrepancy between "kitchenware pottery" in the text and "medical pottery" in Option B shows it does not reflect traditional craft inheritance value.} \\
\hline
\multicolumn{3}{p{15cm}}{Agree with both Critics' analysis of option B, noting the clear difference between "kitchenware pottery" in the text and "medical pottery" in the option. However, Critic 2's reasoning about Response 1's option A analysis is insufficient - "handicraft marks" doesn't necessarily equate to "traditional crafts", though this doesn't affect the final judgment as option B is clearly correct.} \\
\hline
\multicolumn{3}{c}{\textbf{Low Quality Examples}} \\
\hline
\multicolumn{3}{p{15cm}}{Critics 1/2 are correct, the answer should be (B).} \\
\bottomrule
\end{tabular}
\end{table}

\section{AI-AI Experiment Details}
This section introduces the specific setup of our AI-AI experiments. We employ a unified sampling strategy to evaluate multiple models across different tasks. Detailed explanations are provided in the following sections.
\subsection{Tasks Info}
\label{sec:task_info}
Our experiments are conducted across five types of tasks. Below is a detailed introduction to each task category.
\begin{itemize}
    \item \textbf{MATH\citep{hendrycksmath2021}} is a mathematical problem-solving dataset consisting of 12,500 challenging competition-level math problems, designed to assess machine learning models’ mathematical reasoning abilities. Each problem is accompanied by a fully worked-out step-by-step solution, enabling models to learn how to generate answer derivations and explanations.

    \item \textbf{GPQA\citep{rein2023gpqa} }  is a highly challenging multiple-choice question dataset consisting of 448 questions crafted by domain experts in biology, physics, and chemistry. The dataset is designed to assess the reasoning capabilities of both human experts and state-of-the-art AI models on complex scientific topics. To ensure its difficulty and quality, questions were validated by experts with PhD-level knowledge, achieving an accuracy of only 65\% (or 74\% after correcting clear retrospective mistakes). In contrast, highly skilled non-expert validators, even with unrestricted web access for over 30 minutes per question, achieved only 34\% accuracy.
    \item \textbf{TruthfulQA\citep{lin2022truthfulqameasuringmodelsmimic}} evaluates the truthfulness of language models in answering questions, comprising 817 questions across 38 categories, including health, law, finance, and politics. The questions were carefully designed to reflect common human misconceptions or false beliefs, making them particularly challenging. To perform well, models must avoid generating false answers learned from imitating human-written text, which often contains misinformation.
    \item \textbf{BoolQ\citep{clark-etal-2019-boolq}} is a reading comprehension dataset designed to study naturally occurring yes/no questions, meaning questions that arise spontaneously in unprompted and unconstrained settings. The dataset presents unexpected challenges, as its questions often involve complex, non-factoid information and require entailment-like inference rather than simple fact retrieval.
    \item \textbf{MMLU-Pro\citep{wang2024mmluprorobustchallengingmultitask}} is an enhanced version of MMLU designed to go beyond MMLU’s primarily knowledge-driven evaluation. MMLU-Pro incorporates more challenging reasoning-focused questions, expands the answer choice set from 4 to 10 options, and removes trivial and noisy questions from MMLU. Experimental results show that MMLU-Pro significantly increases difficulty, leading to an accuracy drop of 16\% to 33\% compared to MMLU. 
\end{itemize}
\subsection{Sampling Strategy}
In the AI-to-AI experiment, to ensure fairness across different stages of effort, we followed the sampling strategy illustrated in Figure \ref{fig:sam} to sample the responses of the model to a question and critics of various orders. Each sampling begins by obtaining 7 \textit{responses} to the same question. From the first two responses, we further derive 5 \textit{critics}. Similarly, we generate 3 \textit{critics of critics} and 1 \textit{critics of critics of critics}. To ensure the reliability of the results, we repeat the entire process 10 times for the same question and report the average outcomes of these ten iterations. To enhance the diversity of the sampling process, we set the sampling temperature to 1 and top-p to 0.95. The prompts used at different sampling stages are listed in the Appendix \ref{sec:prompt}.
\begin{figure*}[h]
    \centering
    \includegraphics[width=0.3\linewidth]{figures/sam.pdf}
    \caption{The Sampling Strategy of AI Self Recursive Critiquing.
}
    \label{fig:sam}
\end{figure*}

\subsection{Additional Results}

\label{sec:additional_res}

In this section, we provide additional results from AI-AI experiments.
Tables \ref{tab:add_gemma} and \ref{tab:add_qwen} include the results from Gemma2 9B Instruct and Qwen-2.5 14B Instruct on MMLU-Pro and BoolQ.

\input{appendix/additional_results}


\subsection{Generation Prompts}\label{sec:prompt}
In this study, we explore whether AI can engage in Self Recursive Critiquing in an inference-only scenario. We employ the structured prompt illustrated in Figure \ref{prompt:resp}, \ref{prompt:critic}, \ref{prompt:coc}, \ref{prompt:c3_part1}, \ref{prompt:c3_part2} to obtain consistent forms of response, critique, and higher-order critique across different models and datasets. Given the variations in how different models adhere to and comprehend instructions, the prompt structure is slightly adjusted for each model. These adjustments primarily focus on constraints related to output length and the format of the decision-making answers.
\input{appendix/prompt_resp}
\input{appendix/prompt_critic}
\input{appendix/prompt_coc}
\input{appendix/prompt_c3_part1}
\input{appendix/prompt_c3_part2}




%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\end{document}


% This document was modified from the file originally made available by
% Pat Langley and Andrea Danyluk for ICML-2K. This version was created
% by Iain Murray in 2018, and modified by Alexandre Bouchard in
% 2019 and 2021 and by Csaba Szepesvari, Gang Niu and Sivan Sabato in 2022.
% Modified again in 2023 and 2024 by Sivan Sabato and Jonathan Scarlett.
% Previous contributors include Dan Roy, Lise Getoor and Tobias
% Scheffer, which was slightly modified from the 2010 version by
% Thorsten Joachims & Johannes Fuernkranz, slightly modified from the
% 2009 version by Kiri Wagstaff and Sam Roweis's 2008 version, which is
% slightly modified from Prasad Tadepalli's 2007 version which is a
% lightly changed version of the previous year's version by Andrew
% Moore, which was in turn edited from those of Kristian Kersting and
% Codrina Lauth. Alex Smola contributed to the algorithmic style files.
