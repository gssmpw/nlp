\section{Accelerating Dual Phase}\label{sec:parallel-dual}

\input{dual-phase-table}

In this section, we describe how to accelerate the dual phase using parallel \pus.
The key insight is that certain operations in Parity Blossom~\cite{wu2023qce} can be parallelized using the \emph{Covers} of the nodes.
We can use parallel \pus to (1) maintain the \emph{Covers} when performing a dual-phase operation, and (2) implement these operations using the local state.

We first provide background on Parity Blossom in \S\ref{sec:background-parity}, describe a new algorithm design that parallelizes dual-phase operations at the vertex level in \S\ref{ssec:vertex-level-parallel-algorithm}, and present a more resource-efficient version of the algorithm in \S\ref{ssec:resource-efficient-algorithm}.

\input{background-parity}

\subsection{Algorithm of Parallel Dual-phase Operation}\label{ssec:vertex-level-parallel-algorithm}

The key idea of \arch toward achieving vertex-level parallelism is to maintain per-vertex information that is updated locally so that manipulations of a \cov will only require information associated with the vertices and edges within the \cov.
We use vertices to store the information of \covs in a distributed manner while only storing the edge weights on the edges.
The algorithm is formally described in Column 4 of \autoref{tab:dual-phase-operations}.

\smallskip\noindent \textbf{Algorithm: Parallel Dual Operations}~~
Dual-phase operations can be implemented in parallel using information local to \pus, according to \autoref{tab:dual-phase-operations} (Column 4).

We next succinctly present the mathematical notions and theorems behind this algorithm.

\smallskip
\textbf{Definition: Residual Distance}. Given a vertex $v \in V$ and a defect vertex $u \in D$ from a decoding graph, we define the \emph{Residual Distance} as
\begin{align*}
    d_r(v, u) = \sum\nolimits_{A \in \mathcal{A}(u)} y_A - \text{Dist}(u, v)
\end{align*}

\textbf{Definition: Residue, Touches and Nodes}.
Given a vertex $v \in V$, we define the following states: \emph{Residue} $r_v$, \emph{Touches} $T_v \subseteq D$, and \emph{Nodes} $N_v \subseteq \mathcal{O}^*$.
\begin{gather*}
    r_v = \max(0, \max_{u \in D}~d_r(v, u)) \\
    T_v = \argmax_{u \in D | d_r(v, u) \ge 0} d_r(v, u) \\
    N_v = \{\ \text{Root}(u)\ |\ u \in T_v\ \}\\
\end{gather*}

In \arch, each \puv maintains the Residue, Touches and Nodes of the corresponding vertex.
In addition, it also records all the directions $\Delta y_S, \forall S \in N_v$.
The complete \pu state is shown in \autoref{tab:states}.

Together, the per-vertex states maintained by all \puvs constitute a distributed description of the \emph{Covers}.
Each \puv knows whether its vertex belongs to the \emph{Cover} of a node $S$ ($S \in N_v$), and if so, how far it is from the nearest boundary ($r_v$).
An example is shown in \autoref{fig:vertex-state}, where the vertex's state provides information on \emph{Covers} that includes it.

\begin{table}[t]
    \centering
    \caption{The \pu states of both the original algorithm \S\ref{ssec:vertex-level-parallel-algorithm} and a more resource efficient algorithm \S\ref{ssec:resource-efficient-algorithm}.}
    \label{tab:states}
    {
        % \small % 9pt
        \footnotesize
\begin{tabular}{@{}cc|cc@{}}
\toprule
\pu &
  Full State (\S\ref{ssec:vertex-level-parallel-algorithm}) &
  Compact State (\S\ref{ssec:resource-efficient-algorithm}) &
  Compact Values \\ \midrule
Vertex ($v$)&
  Touches ($T_v$) &
  \emph{unique}-Touch ($t_v$) &
  $[0, |V|)$ or $\varnothing$ \\ 
 &
  Nodes ($N_v$) &
  \emph{unique}-Node ($n_v$) &
   $[0, 2|V|)$ or $\varnothing$ \\ 
 &
  \multicolumn{2}{c}{Residue ($r_v$)} &
  $[0, \max \sum w_e]$ \\
 &
  \begin{tabular}{@{}c@{}} Directions \\ ($\Delta y_S, \forall S \in N_v$) \end{tabular} &
  Direction ($s_v = \Delta y_{n_v}$) &
   $\{$+1, -1, 0$\}$ \\ 
 &
  \multicolumn{2}{c}{Is Defect ($d_v = (v \in D)$)} &
  $\{\text{true}, \text{false}\}$ \\ 
 &
  \multicolumn{2}{c}{Is Boundary ($b_v$)} &
  $\{\text{true}, \text{false}\}$  \\
 &
  \multicolumn{2}{c}{Index ($i_v$)} &
  $[0, |V|)$  \\ \midrule
Edge ($e$) &
  \multicolumn{2}{c}{Weight ($w_e$)} &
  $[0, \max w_e]$ \\ \bottomrule
\end{tabular}
        \vspace{1ex}
    }
\end{table}

We prove the following theorems. The first implies that all \emph{Conflicts} can be detected locally on each \pue of $e \in E$ only using information local to $e$ and its incident vertices.
The second implies that the length of growth can be found locally for each \puv and \pue.

\vspace{1ex}
\theoremconflictdetectiondisklet{theorem:conflict-detection-disklet}
\vspace{1ex}

The accelerator computes 
the right side of $\Longleftrightarrow$ in the above theorem in two steps: (\textit{i}) each \pue computes $(r_{v_1} + r_{v_2} \ge w_e) \land \Delta y_{S_1} + \Delta y_{S_2} > 0$ for every $S_1 \in N_{v_1}, S_2 \in N_{v_2}$ in parallel and reports the result; (\textit{ii}) the convergecast tree aggregates results from all \pues. 
We note that $w_e$ is local to the \pue associated with $e$; $r_{v_i}$, $N_{v_i}$, and $\Delta y_{S_i}$ are local to the vPU associated with $v_i$, which is incident to $e$.

When an \pue detects a \emph{Conflict} in Step (\textit{i}), it reports $(v_1$, $v_2$, $S_1$, $S_2$, $t_1$, $t_2)$ where $t_1 \in T_{v_1}, \text{Root}(t_1) = S_1$ and $t_2 \in T_{v_2}, \text{Root}(t_2) = S_2$. $t_1$ and $t_2$ exist due to the definition of $N_v$.
The convergecast tree picks an arbitrary \emph{Conflict} (and its report) out of all reported.
The convergecast tree consists of $|E|-1$ multiplexers and incurs an $O(\log |E|)$ latency.
In this way, when there exists any \emph{Conflict}, the accelerator reports at least one of them and thus implements the dual phase~\cite{wu2023qce}.

\vspace{1ex}
\theoremlocallengthtogrowdisklet{theorem:local-length-to-grow-disklet}
 
In the accelerator, \puvs compute the left of $\bigcup$  in the above theorem while \pues compute the right, both using local information.
The \pus report their results via the convergecast tree to compute the minimum $l$, which consists of $|V|+|E|-1$ comparators and incurs an $O(\log|E|)$ latency.

Together, the above two theorems indicate that per-vertex states can replace \emph{Covers} to detect \emph{Conflicts} in the implementation of the blossom algorithm.
Concretely, they lead to the algorithm for the six dual-phase operations with local information described in \autoref{tab:dual-phase-operations}.

\subsection{A More Resource-Efficient Algorithm}\label{ssec:resource-efficient-algorithm}

Although the local algorithm in \autoref{tab:dual-phase-operations} implements all dual-phase operations with vertex and edge-level parallelism and using only local information, it requires a large per-vertex state for hardware implementation: both $T_v$ and $N_v$ require $O(|V|)$ memory.
In order to reduce resource usage for each \puv, we further simplify the algorithm so that a \puv only stores a unique \emph{Touch} and \emph{Node} for its vertex.

\textbf{Definition: unique Touch and Node}.
The \emph{unique-Touch} $t_v \in D \cup \{ \varnothing \}$ is a touch vertex $u \in T_v$ whose node has the maximum $\Delta y_{\text{Root}(u)}$, and the \emph{unique-Node} $n_v = \text{Root}(t_v) \in \mathcal{O}^* \cup \{ \varnothing \}$ is the node of $t_v$.
\begin{align*}
t_v = \begin{cases}
    v, & \text{if $v \in D$},\\
    \argmax_{u \in T_v} \Delta y_{~\text{Root}(u)}, & \text{else if $T_v \neq \varnothing$},\\
    \varnothing, & \text{otherwise}.
\end{cases}
\end{align*}

By maintaining a single touch $t_v$ and node $n_v$, we reduce the state of \puv as summarized in \autoref{tab:states} and the instruction set that operates on it in \autoref{tab:instruction-set}.

\begin{figure}[t]
    \centering
    \includegraphics[width=\linewidth,trim={0 3.5cm 0 0},clip]{figures/code/vertex-state.pdf}
    \caption{Example of per-vertex states: $r_v$, $T_v$ and $N_v$. These local vertex states allow individual vertex to know its position relative to the \emph{Covers}. A vertex $v$ is outside of any \text{Cover} if and only if $N_v = T_v = \varnothing$. When $T_v \neq \varnothing$, then $r_v \ge 0$ is the distance from the vertex to the nearest \emph{Cover} boundary.}
    \label{fig:vertex-state}
\end{figure}

\paragraph{Instruction set}
As shown in \autoref{tab:instruction-set}, we design a compact instruction set that represents each dual-phase operation in \autoref{tab:dual-phase-operations}.
Another inefficiency in \S\ref{ssec:vertex-level-parallel-algorithm} is that the ``\code{split Cover}'' operation requires each \puv to maintain the hierarchical structure of the blossom.
We mitigate this problem by storing the blossom structure in the CPU and using a single \code{setCover}($C$, $S$) instruction to implement both ``\code{merge Cover}'' and ``\code{split Cover}'' operations.
Each \puv simply set $n_v \coloneq S$ if $\{t_v\} = C$ or $n_v = C$ upon receiving ``\code{set Cover}''.


\paragraph{Compact PUs}
We implement this resource-efficient algorithm using a compact state per vertex and edge as shown in \autoref{tab:states} and combinational logic with a fixed CPI (clock per instruction) of 1.
This combinational logic takes the \emph{current} state from the registers of its neighboring vertices and edges.
Then it outputs the \emph{next} state that is captured by the registers and fed as input in the next clock cycle.
All \pus share the same clock and run synchronously.
In surface code, the number of registers or gates scales with $O(|V|\ \text{polylog}|V|)$, as detailed in \S\ref{ssec:eva-resource}.

\input{instruction-set}
