\section{Micro Blossom Architecture}\label{sec:overview}

As shown in \autoref{fig:architecture}, \arch is a heterogeneous architecture to solve MWPM decoding for QEC with sub-microsecond decoding latency. 
It builds on ideas from recent fast decoders: (\textit{i}) using the decoding graph, instead of the syndrome graph~\cite{wu2023qce,higgott2025sparse} and (\textit{ii}) using fusion operations to support stream decoding~\cite{wu2023qce}.
Like these decoders, \arch also implements the blossom algorithm~\cite{edmonds1969blossom} and therefore is logically equivalent to them.
\arch, however, advances the state of the art in implementation by realizing vertex and edge level parallelism, while Fusion Blossom~\cite{wu2023qce} is effective to coarse-grained parallelism and Parity Blossom~\cite{wu2023qce} and Sparse Blossom~\cite{higgott2025sparse} do not exploit parallelism at all (See \S\ref{sec:related}). 

\begin{figure}[t]
    \centering
    \includegraphics[width=\linewidth]{figures/slides/architecture2.pdf}
    \caption{Heterogeneous Architecture of Micro Blossom. The blue blocks and green cylinders represent \puvs and \pues, respectively.
    An instruction is first broadcast to all \pus, then each \pu updates its local state and generates a response which is convergecasted into a single response. Each \pu only talks to its immediate neighbors on the decoding graph.
    The syndrome data from the quantum hardware is directly loaded to the \puvs in a stream manner.
    }
    \label{fig:architecture}
\end{figure}

\subsection{Overview}

\arch carefully partitions the blossom algorithm between software and hardware.
The software handles dynamically sized data structures while the hardware (accelerator) employs a large number of processing units (\pus) with local connectivity.
There are two types of stateful \pus: \PUV (\puv) and \PUE (\pue).
The accelerator associates a \emph{\puv} for each vertex and an \emph{\pue} for each edge in the decoding graph, achieving the finest possible parallelism for graph algorithms. 
Because decoding graphs vary depending on how physical qubits are grouped into logical qubits and the logical operation, our implementation takes a decoding graph as input and outputs synthesizable Verilog code for the accelerator (\S\ref{sec:implementation}).

The accelerator in \arch is programmable with a small instruction set. 
It carefully decouples the data and control planes. 
The data plane includes the \pus, which only exchanges data locally, with their immediate neighbors.
The syndrome data are loaded to the \puvs, which can be fed with shift registers to minimize routing congestion.
Once all syndromes have been loaded and the MWPM solution is determined, the controller outputs the logical correction bits.
The control plane consists of a controller, a broadcast network that sends control signals to all \pus, and a convergecast network that collects responses from them. 
The controller interfaces with the software via memory-mapped registers.

\subsection{Key Ideas}

\paragraph{Accelerating Dual Phase (\S\ref{sec:parallel-dual})}
Given that the dual phase is the current speed bottleneck of a software implementation, as shown in \autoref{fig:amdahls-law}, we accelerate it using parallel \pus, organized according to the decoding graph.
The key algorithmic innovation behind this is a parallel variant of Parity Blossom~\cite{wu2023qce} with which the dual phase is implemented by parallel \pus, each of which only uses its local state and that of its immediate neighbors.
The key is to distribute the information of \emph{Covers} down to per-vertex data structures (implemented as per-\puv state).
This key idea improves the worst-case time complexity from $O(|V|^4)$ of the fastest sequential algorithm~\cite{higgott2025sparse} to $O(|V|^3)$ using $O(|V|\ \text{polylog}|V|)$ parallel resources.

\paragraph{Accelerating Primal Phase (\S\ref{sec:pre-matching})}
Although the most time-consuming dual-phase operations are offloaded to the hardware, the CPU still has to do at least one read and write for every defect vertex in the primal phase.
The interaction between the CPU and the hardware becomes the bottleneck, leading to an average time complexity of $O(|D|) = O(p|V|)$ with a large constant factor of hundreds of nanoseconds per interaction.
Our key idea is to find a simple component of the primal phase that can be efficiently parallelized in the hardware accelerator.
We prove that if any error occurs alone, it is offloaded to the hardware accelerator in $O(1)$ time.
Given the independence of the errors, the average decoding time is reduced from $O(p|V|+1)$ to $O(p^2|V|+1)$, eliminating the interaction for all first-order errors and thus reducing the interaction between the CPU and the hardware.

\paragraph{Round-wise Fusion for Streaming (\S\ref{sec:fusion})}

Multiple rounds of stabilizer measurements constitute a stream as one round becomes available every $\qty{1}{\mu s}$.
To reduce decoding latency, instead of waiting for all rounds of a syndrome, the decoder can process a round as soon as it arrives and \emph{fuse} their results progressively, as demonstrated in~\cite{wu2023qce}.
Micro Blossom leverages vertex-level parallelism in such fusion operations to further accelerate them for fine-grained stream decoding \emph{within} measurement round.
This round-wise fusion complements the coarse-grained fusion of prior work~\cite{wu2023qce}.
Importantly, we combine round-wise fusion with the parallel primal phase acceleration.
When decoding is faster than the measurement rate, round-wise fusion further reduces the average decoding latency from $O(p^2 d^3 + 1)$ to $O(p^2 d^2 + 1)$.

\smallskip

We elaborate how Micro Blossom leverages these ideas in \S\ref{sec:parallel-dual} to \S\ref{sec:fusion}, respectively.
