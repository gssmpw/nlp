\section{Related Work}\label{sec:related_works}
\gls{bp} estimation from \gls{ecg} and \gls{ppg} waveforms has received significant attention due to its potential for continuous, unobtrusive monitoring. Earlier work relied on classical machine learning with handcrafted features, but deep learning methods have since emerged as more robust alternatives. Convolutional or recurrent architectures designed for \gls{ecg}/\gls{ppg} have shown strong performance, including ResUNet with self-attention~\cite{Jamil}, U-Net variants~\cite{Mahmud_2022}, and hybrid \gls{cnn}--\gls{rnn} models~\cite{Paviglianiti2021ACO}. These architectures often outperform traditional feature-engineering approaches, particularly when both \gls{ecg} and \gls{ppg} signals are used~\cite{Paviglianiti2021ACO}.

Nevertheless, many existing methods train solely on \gls{ecg}/\gls{ppg} data, which, while plentiful~\cite{mimiciii,vitaldb,ptb-xl}, often exhibit significant variability in signal quality and patient-specific characteristics. This variability poses challenges for achieving robust generalization across populations. Recent work has explored transfer learning to overcome these issues; for example, Yang \emph{et~al.}~\cite{yang2023cross} studied the transfer of \gls{eeg} knowledge to \gls{ecg} classification tasks, achieving improved performance and reduced training costs. Joshi \emph{et~al.}~\cite{joshi2021deep} also explored the transfer of \gls{eeg} knowledge using a deep knowledge distillation framework to enhance single-lead \gls{ecg}-based sleep staging. However, these studies have largely focused on within-modality or narrow domain adaptations, leaving open the broader question of whether an \gls{eeg}-based foundation model can serve as a versatile starting point for generalized biosignal analysis.

\gls{eeg} has become an attractive candidate for pre-training large models not only because of the availability of large-scale \gls{eeg} repositories~\cite{TUEG} but also due to its rich multi-channel, temporal, and spectral dynamics~\cite{jiang2024large}. While many time-series modalities (for example, voice) also exhibit rich temporal structure, \gls{eeg}, \gls{ecg}, and \gls{ppg} share common physiological origins and similar noise characteristics, which facilitate the transfer of temporal pattern recognition capabilities. In other words, our hypothesis is that the underlying statistical properties and multi-dimensional dynamics in \gls{eeg} make it particularly well-suited for learning robust representations that can be effectively adapted to \gls{ecg}/\gls{ppg} tasks. Our work is the first to validate the feasibility of fine-tuning a transformer-based model initially trained on EEG (CEReBrO~\cite{CEReBrO}) for arterial \gls{bp} estimation using \gls{ecg} and \gls{ppg} data.

Beyond accuracy, real-world deployment of \gls{bp} estimation models calls for efficient inference. Traditional deep networks can be computationally expensive, motivating recent interest in quantization and other compression techniques~\cite{nagel2021whitepaperneuralnetwork}. Few studies have combined large-scale pre-training with post-training quantization for \gls{bp} monitoring. Hence, our method integrates these two aspects: leveraging a potent \gls{eeg}-based foundation model and applying quantization for a compact, high-accuracy cuffless \gls{bp} solution.