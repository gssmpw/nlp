\section{Discussion}
\label{sec:dis}
% 信号分类及依据，时域，空域，频域，小波域，拉普拉斯域


%为什么需要frequency domain

%结论和发现
% 与高频频道（索引较大的框）相比，低频频道（索引较小的框）的选择频率更高。 这表明对于视觉推理任务而言，低频通道通常比高频通道更具信息性
% 
% F-principle（Frequency Principle，频率原则）是指在训练深度神经网络的过程中，网络倾向于优先学习低频信息，然后逐渐学习高频信息的现象。



The fundamental reason for transforming data into the frequency or other related domains is to gain a different perspective, often simplifying operations or revealing features that are less apparent in the original representation, which is otherwise obscured in the original domain. For instance, by using the Fourier transform, we can make it much easier to filter out noise, compress data, or analyze repeating patterns.
Besides, the frequency domain can be leveraged to speed up convolutions by converting spatial operations to pointwise multiplications in the frequency domain. This is an example of how transformations can reduce computational complexity and make seemingly intractable problems solvable. The frequency domain also enables new ways of feature extraction, making it possible to better encode relevant information and discard less useful components.
Last but not least, the frequency domain lies in its power to simplify complex relationships. Many real-world phenomena exhibit simpler structures in the frequency domain compared to the time or spatial domains. For example, natural images often have their information content concentrated in low-frequency components, meaning that high-frequency details can be selectively pruned to achieve effective compression without significantly impacting the perceptual quality.

Despite these advantages, there are several bottlenecks in the use of frequency domains. One major challenge is the computational cost associated with certain transformations, especially in high-dimensional data scenarios. For example, the computation of complex transforms on 3D volumes or high-resolution images can be prohibitive, often requiring specialized hardware or efficient approximations that may compromise accuracy.
Another significant bottleneck lies in the difficulty of effectively integrating frequency domain features with modern deep learning architectures. While transforms like Fourier or wavelet offer powerful insights, they do not always naturally fit into current end-to-end learning frameworks. Transform-based representations often need careful engineering and can complicate gradient-based optimization.
Finally, selecting the appropriate transform is often non-trivial, as it depends heavily on the data and the specific application. In many cases, no single transform is optimal, and it may be necessary to explore combinations or adaptive transforms. This introduces additional complexity into model design and requires a nuanced understanding of both domain knowledge and transform properties.