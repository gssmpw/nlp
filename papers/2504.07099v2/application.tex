\section{Applications}
\label{sec:appli}
This section explores frequency transform applications in time series analysis, involving conversion from time domain to frequency domain, and spatio-temporal dynamics, involving conversion from time and space domains to frequency domain. 


\begin{table*}[!ht]
    \centering
    \caption{Representative methods using Fourier, wavelet, and Laplace transforms in the frequency domain.}
    \label{tab:representative_mdthod}
    \vspace{-0.3cm}
    \setlength{\tabcolsep}{8pt}
    \resizebox{\textwidth}{!}{
        \fontsize{14}{1.65\baselineskip}\selectfont % 设置字体大小为14pt, 1.75倍行距
        \begin{tabular}{c|c|c|c|c}
        \toprule[1.5pt]
        \textbf{Method}   & \textbf{Task}   & \textbf{Dataset}     & \textbf{Venue} &  \textbf{Code Link}  \\
        \midrule[1.2pt]
        \rowcolor{black!10} \multicolumn{5}{c}{\textbf{Fourier Transform Methods}}   \\
        \midrule
        % \makecell[c]{ATFN~\upcite{yang2020adaptive}}& Time-Series Forecasting  &    \makecell[c]{ S\&P500 Stocks, Parking Birmingham }    &  TKDE 2020 & -    \\
        % \midrule
        % \makecell[c]{StemGNN~\upcite{cao2020spectral}} & Time-Series Forecasting & \makecell[c]{METR-LA, PEMS-BAY, PEMS07, \\ PEMS03, PEMS04, PEMS08, Solar, \\ Electricity, ECG5000, COVID-19}  & NeurIPS 2020 & \url{https://shorturl.at/Rh97F} \\
        % \midrule
        % \makecell[c]{Fourier flows~\upcite{alaa2021generative}} & Time-Series Data Augmentation & - & ICLR 2021 & \url{https://shorturl.at/lqzXm} \\
        % \midrule
        % \makecell[c]{TFAD~\upcite{zhang2022tfad}} & \makecell[c]{ Time-Series Data Augmen-\\tation and Anomaly Detection} & \makecell[c]{KPI, Yahoo, SMAP,  MSL} &  CIKM 2022 & \url{https://shorturl.at/6ZD05}  \\
        % \midrule
        % \makecell[c]{CoST~\upcite{woo2022cost}} & \makecell[c]{Time-Series Feature Enginee-\\ring and Forecasting} & ETT, Electricity, Weather, M5 & ICLR 2022 & \url{https://shorturl.at/9wRBY} \\
        % \midrule
        % \makecell[c]{FEDformer~\upcite{zhou2022fedformer}} & Time-Series Forecasting & \makecell[c]{ETT,  Electricity, Exchange, \\ Traffic, Weather, Illness}         &  ICML 2022  & \url{https://shorturl.at/X3jFt}  \\
        % \midrule
        % \makecell[c]{FiLM~\upcite{zhou2022film}} & Time-Series Forecasting &  \makecell[c]{ETT,Traffic, Electricity, \\ Exchange, ILI, Weather}  &  NeurIPS 2022  &  \url{https://shorturl.at/MveIF}  \\
        % \midrule
        TimesNet~\upcite{wu2023timesnet}  & \makecell[c]{General Time Series Analysis} & \makecell[c]{ETT, Electricity, Exchange~\textit{et al.}} & ICLR 2023 & \url{https://shorturl.at/GBGN4} \\
        \midrule
        \makecell[c]{GAFNO~\upcite{li2023gafno}} & \makecell[c]{General Time Series Analysis} & \makecell[c]{ETT, Electricity, Exchange~\textit{et al.}} & ICDM 2023 & -   \\
        \midrule
        \makecell[c]{FourierGNN~\upcite{yi2023fouriergnn}} & Time-Series Forecasting &     \makecell[c]{Solar, Wiki, Traffic, Electricity, \\ ECG, COVID-19, METR-LA}  & NeurIPS 2023 &  \url{https://shorturl.at/ajT0F}   \\
        \midrule
        \makecell[c]{BFNO~\upcite{cho2024operator}} & Time Series Classifcation & \makecell[c]{HumanActivity and Physionet} & AAAI 2024 & \url{https://shorturl.at/F6ACg}\\
        \midrule
        \makecell[c]{TSLANet~\upcite{eldele2024tslanet}} & \makecell[c]{General Time Series Analysis} & UCR, UEA, Sleep-EDF \textit{et al.} & ICML 2024 & \url{https://shorturl.at/PK4pn} \\
        \midrule
        \makecell[c]{FITS~\upcite{xu2024fits}} & \makecell[c]{Time-Series Forecasting\\ and Reconstruction} & Traffic, Electricity, Weather and ETT & ICLR 2024 & \url{https://shorturl.at/WKtsg} \\
        \midrule
        \makecell[c]{NFT~\upcite{koren2024interpretable}} & Time-Series Forecasting &  \makecell[c]{Electricity, ILI, Exchange, Traffic, \\ Chorales, Weather \textit{et al.}}  &  Arxiv 2024  & \url{https://shorturl.at/hbmlU}   \\
        \midrule
        \makecell[c]{Time-SSM~\upcite{hu2024time}} & Time-Series Forecasting &  \makecell[c]{ETT, Crypots, Exchange, Traffic, Weather}  &  Arxiv 2024  & \url{https://shorturl.at/fMWoe}   \\
        \midrule
      \makecell[c]{Pastnet~\upcite{wu2024pastnet}} & Spatio-Temporal Forecasting &  \makecell[c]{TrafficBJ, EDPS, Weather \textit{et al.}}  &  ACM MM 2024  & \url{https://shorturl.at/Xc3Bd}   \\
        \midrule
        \makecell[c]{FreqMoE~\upcite{liu2025freqmoe}} & Time Series Forecasting & ETT, Weather, ECL and Exchange & AISTATS 2025 & - \\
        \midrule
        \makecell[c]{TimeKAN~\upcite{huang2025timekan}} & Spatio-Temporal Forecasting &  \makecell[c]{Weather,ETTh1,ETTh2, \\ ETTm1,ETTm2}  &  ICLR 2025  & \url{https://shorturl.at/ndD1f}\\
        \midrule
        \makecell[c]{CATCH~\upcite{wu2025catch}} & Time-Series Anomaly Detection &  \makecell[c]{MSL,PSM,SMD,CICIDS,CalIt2,\\ NYC, Creditcard, GECCO, \\Genesis, ASD, SWAT}  &  ICLR 2025  & \url{https://shorturl.at/np732}\\
        \midrule
        
        
        \rowcolor{black!10} \multicolumn{5}{c}{\textbf{Wavelet Transform Methods}}   \\
        \midrule
        % \makecell[c]{LGTTS~\upcite{cosentino2020learnable}} &          &          &          & \url{https://shorturl.at/lLwCG} \\
        % \midrule
        % \makecell[c]{RobustPeriod~\upcite{wen2021robustperiod}} & Time-Series Periodicity Detection &          &          &          \\
        % \midrule
        % \makecell[c]{FEDformer~\upcite{zhou2022fedformer}} & Time-Series Forecasting & \makecell[c]{ETT,  Electricity, Exchange, \\ Traffic, Weather, Illness}     &  ICML 2022  & \url{https://shorturl.at/X3jFt}  \\
        % \midrule
        \makecell[c]{WaveForM~\upcite{yang2023waveform}}& Time-Series Forecasting &   \makecell[c]{Electricity, Traffic, Weather,\\  Solar-Energy}   &  AAAI 2023   &  \url{https://shorturl.at/JCMhh}   \\
        \midrule
        \makecell[c]{WFTNet~\upcite{liu2024wftnet}} & Time-Series Forecasting  &  \makecell[c]{ETT, Traffic, ECL, Weather}  & ICASSP 2024 & \url{https://shorturl.at/9VPlq} \\
        \midrule
        \makecell[c]{MODWT-LSTM~\upcite{tamilselvi2024novel}} & Time-Series Forecasting  &  \makecell[c]{Monthly Rainfall of India}  & \makecell[c]{Neural Computing and\\ Applications 2024} & - \\
        \midrule
        % \makecell[c]{WaveRoRA~\upcite{liang2024waverora}}& Time-Series Forecasting &  \makecell[c]{ETT, Weather, Electricity, \\ Traffic, Solar}  &  Arxiv 2024  &  \url{https://shorturl.at/buJVF}  \\
        % \midrule
        % \makecell[c]{EO-ML~\upcite{kakooei2024analyzing}}& Time-Series Analysis &  \makecell[c]{simulated and DHS dataset}  &  Arxiv 2024  &  \url{https://shorturl.at/ELxLF}  \\
        % \midrule
        \makecell[c]{Wave-Mask/Mix~\upcite{arabi2024wave}}& Time-Series Forecasting &  \makecell[c]{ETTh1, ETTh2, Weather and ILI}  &  Arxiv 2024  &  \url{https://shorturl.at/DUKg5}  \\
        \midrule
        \makecell[c]{SWIFT~\upcite{xie2025swift}}& Time-Series Forecasting &  \makecell[c]{Traffic, Electricity, Weather, ETT}  &  Arxiv 2025  &  \url{https://shorturl.at/u9KjA}  \\
        \midrule
        \makecell[c]{WDNO~\upcite{hu2025wavelet}}& Spatio-Temporal Forecasting &  \makecell[c]{PDE Simulation and ERA5}  &  ICLR 2025  &  \url{https://shorturl.at/Tp23t}  \\
        
        
        \midrule
        \rowcolor{black!10} \multicolumn{5}{c}{\textbf{Laplace Transform Methods}}  \\
        \midrule
        \makecell[c]{LCR~\upcite{chen2024laplacian}} & Time-Series Imputation &  \makecell[c]{Traffic Speed, Traffic Volume, \\ HighD, CitySim}  & TKDE 2024 &  \url{https://shorturl.at/7qL64}   \\
        \midrule
        % \makecell[c]{DRNN-LSTM~\upcite{ambhika2024time}} & Time-Series Forecasting &  \makecell[c]{Energy, Weather, Traffic \\ PM2.5 Air Quality and NASDA-100}  & Researchsquare 2024 & - \\
        % \midrule
        \makecell[c]{LRTC-3DST~\upcite{shu2024low}} &   Traffic Data Imputation   &  \makecell[c]{GuangZhou, Seattle, PeMSD8, \\ PeMSD7(M), PeMSD7(L)}  & TITS 2024 & \url{https://shorturl.at/YycIu} \\
        \bottomrule[1.5pt]
        \end{tabular}}
        \vspace{-0.5cm}
\end{table*}


% Two Parts: Major advantages 


% Major Advances in Frequency-Based Learning (Instead of just listing papers, highlight major themes.)
% 	•	�� Frequency-Aware Neural Networks (Fourier Neural Operators, Wavelet-based CNNs)
% 	•	�� Hybrid Architectures (Combining frequency and time-domain features)
% 	•	�� Scalability Issues & Recent Optimizations (Handling long sequences, computational improvements)
% 	•	�� Interpretability: What do frequency-based features reveal that time-domain models miss?

% 	5.	Challenges and Open Problems
% 	•	What frequency-domain models still struggle with? (e.g., adaptivity, interpretability)
% 	•	When should time-domain methods be preferred over frequency-domain ones?
% 	•	How do we integrate these techniques with deep learning models efficiently?


\subsection{Major Advances in Frequency-Based Learning}
% Frequency-Aware Neural Networks (Fourier Neural Operators, Wavelet-based CNNs)
% Hybrid Architectures (Combining frequency and time-domain features)
% Scalability Issues & Recent Optimizations (Handling long sequences, computational improvements)
% Interpretability: What do frequency-based features reveal that time-domain models miss?
Recent advancements in frequency-aware neural networks, such as Fourier Neural Operators and wavelet-based CNNs, have significantly enhanced performance in various domains including computer vision and time series analysis~\cite{fang2024spiking,wang2024fourier}. For instance, ~\citep{wang2024fourier} proposed a method that replaces traditional SSA with spike-form Fourier Transform and Wavelet Transform, using fixed triangular or wavelet bases. This innovative approach demonstrates the effectiveness of the Fourier-or-Wavelet-based spikformer in visual classification tasks. Similarly, the Spiking Wavelet Transformer (SWformer), introduced by ~\cite{fang2024spiking}, captures intricate spatial-frequency characteristics through a spike-driven approach that leverages the wavelet transform.

In addition to frequency-aware methods, hybrid architectures that combine frequency and time-domain features are gaining traction. ~\citep{chen2024joint} presented a model that merges time and frequency domain representations to improve prediction accuracy. By utilizing a limited number of learnable frequencies, it captures multi-scale dependencies while maintaining sparsity. Concurrently, ~\citep{pang2024time} focused on the physical consistency between time-domain and frequency-domain information in bearing signals, employing supervised contrastive learning to extract universal features applicable across varying speed conditions. Their approach also includes a K-nearest neighbor algorithm based on cosine distance to assign pseudo-labels to unlabeled data in the target domain, facilitating effective cross-domain supervised contrastive pre-training.

Recent work has also addressed scalability issues and optimizations in handling long sequences~\cite{alsulaimawi2024enhanced,grushail2024adaptive}, leading to computational improvements. As models become more complex and data-intensive, the ability to efficiently process extended sequences is critical. New techniques focus on reducing computational overhead while maintaining performance, ensuring that models can scale effectively without sacrificing accuracy~\cite{zhao2024cross,wang2024robust}. These advancements are essential for deploying models in real-world applications where data can be vast and continuous.

Interpretability is another crucial aspect, particularly in understanding what frequency-based features reveal that time-domain models may overlook~\cite{anderson2024interpretable,yan2024relation}. Frequency-domain representations can expose hidden patterns and relationships in the data that are not readily apparent in time-domain analysis. Recent studies highlight how these features can provide insights into underlying processes, making frequency-aware models not only more effective but also more interpretable~\cite{zhao2024cross,wang2024physically}. By enhancing the interpretability of models, researchers can better understand the significance of frequency components and their impact on predictions, leading to more informed decisions in various applications.


\subsection{Applications Across Domains}

This section explores the application of frequency transform techniques across industries, including Financial Time Series, Healthcare, Aerodynamics, and Manufacturing, highlighting their potential, advancements, and challenges.

% 	•	Financial Time Series (Stock prediction, volatility modeling)
% 	•	(Extracting periodic patterns)
% 	•	 (EEG, ECG, anomaly detection)
% 	•	Industrial & Anomaly Detection (Machine monitoring, predictive maintenance)
% 	•	Bridging Gaps with Spatio-Temporal Learning (Traffic, remote sensing)

\paragraph{Financial Time Series.} Financial time series are challenging due to their volatility, noise, and non-stationarity, which motivates the use of Fourier transform techniques to extract periodic patterns and filter out noise for more robust modeling. NFT~\cite{koren2024interpretable} demonstrates how integrating multi-dimensional Fourier transforms with deep learning frameworks can enhance both predictive accuracy and interpretability in financial forecasts. Similarly, approaches like FourNet~\cite{du2023fourier} employ Fourier-based neural networks to approximate transition densities in complex financial models, providing rigorous error bounds and robust performance on diverse stochastic processes. These works highlight the potential of frequency-domain representations to extract periodic and spectral features, reducing noise and improving computational efficiency. However, challenges remain in selecting the optimal number of Fourier components and ensuring generalization across varying market conditions.

\paragraph{Aerodynamics \& Molecular Dynamics.} Simulation of dynamics is challenging due to their multi-scale complexity and turbulent, non-linear phenomena, motivating the use of Fourier transform techniques to decompose signals into frequency components for efficient analysis and simulation. Specifically, ComFNO~\cite{li2024component} and LP-FNO~\cite{kashi2024learning} are advanced architectures that enhance aerodynamic flow predictions by capturing multi-scale dynamics. They improve the Fourier neural operator (FNO) approach, demonstrating the importance of Fourier transform-based representations in solving complex partial differential equations (PDEs) and handling challenging boundary conditions. \citep{sun2024graph} addressed challenges in aerodynamics and molecular dynamics by combining graph Fourier transformation with neural ordinary differential equations (ODEs). Inspired by FTIR spectroscopy, \citep{sun2024graph} decomposed molecular interactions into spatial scales, capturing both high-frequency and low-frequency components. Neural ODEs model the temporal evolution of each scale using adaptive stepping, and an inverse transform reconstructs the molecular state, capturing the interplay between spatial structures and temporal dynamics.

\paragraph{Weather \& Traffic.} Climate and traffic time series prediction are challenging due to their high-dimensional, nonlinear, and multi-variate dynamics, which makes Fourier transform techniques invaluable for isolating dominant spectral features and mitigating noise. Pastnet~\cite{wu2024pastnet} addresses these challenges by employing spectral methods that integrate trainable neural networks with Fourier-based a priori spectral filters, transforming raw data into frequency-domain representations where the Fourier coefficients capture the intrinsic periodic features of the system, thereby enabling the model to achieve state-of-the-art performance in both weather forecasting and traffic prediction. Besides, LPR~\cite{chen2024laplacian} synergistically combines the circulant matrix nuclear norm with Laplacian kernelized temporal regularization to yield a unified framework via FFT in log-linear time complexity, accurately imputing diverse traffic time series behaviors and reconstructing sparse vehicular speed fields.
Nonetheless, challenges remain in enhancing model generalization and real-time adaptability under highly variable conditions and extreme events.

\paragraph{Healthcare \& Biosignals.} Physiological and pathological time series often exhibit transient, non-stationary patterns and are contaminated by artifacts, obscuring underlying physiological rhythms. Fourier transform techniques are crucial for decomposing these complex signals into frequency components that reveal critical diagnostic features. \cite{moon2024frequency} transforms raw time-domain signals, such as EEG, ECG, and EMG, into the frequency domain using FFT or related spectral methods. This transformation reveals inherent periodicities, noise characteristics, and spectral power distributions, which are closely correlated with physiological and pathological states. This work demonstrates that frequency-based analysis offers a promising pathway for non-invasive biosignal analysis and provides clinicians with a novel perspective for predicting intraoperative hypotension.

\paragraph{Energy \& Manufacturing.} The methods in Table \ref{tab:representative_mdthod} involving ETT and Electricity highlight the significance of time series forecasting in industry. In the industrial sector, time series exhibit volatile dynamics, sudden load spikes, and complex seasonal patterns, requiring sophisticated frequency decomposition. Fourier transform techniques are crucial for isolating transient events and long-term cycles, distinguishing this industry from others. CATCH~\cite{wu2025catch} employs Fourier transformation to generate time-frequency representations that detect both point anomalies and extended subsequence anomalies. It also adaptively discovers and fuses channel correlations in different frequency bands using a patch-wise mask generator and masked attention guided by bi-level multi-objective optimization. Future challenges include enhancing adaptability to evolving industrial processes, scaling to handle complex multivariate datasets, and ensuring robust real-time performance with interpretable outputs for operational decision-making.


\section{Challenges and Open Problems}
\label{sec:chall}

Challenges in frequency-domain learning continue to shape research, focusing on persistent issues and field advancement. We divide them into the following three parts.

\paragraph{Adaptivity and Interpretability in Frequency-Domain Models.}  Frequency-domain models have demonstrated remarkable capabilities in capturing intricate data patterns, yet they continue to face significant challenges in adaptivity and interpretability. While these models excel in extracting complex features and reducing noise, their ability to adapt to dynamic and evolving environments remains limited. This limitation hinders their effectiveness in real-world applications where data distributions and patterns may change over time. Recent research by~\citep{zhang2024heterophilic} and~\citep{shadfar2024frequency} has explored these adaptivity challenges, highlighting the need for more flexible and responsive frequency-domain frameworks. Additionally, interpretability remains a persistent issue, as frequency-based methods often produce outputs that are difficult to translate into actionable insights or understandable representations of underlying processes. Studies by~\citep{bouazizi2024enhancing} and~\citep{rezk2023interpretable} have made strides in addressing these interpretability barriers, proposing innovative techniques to make frequency-domain models more transparent and accessible. Overcoming these challenges is essential for unlocking the full potential of frequency-based methodologies, ensuring they can be effectively applied in diverse and dynamic contexts. By improving adaptivity and interpretability, researchers can enhance the practical utility of these models, paving the way for broader adoption and more impactful applications in fields ranging in time series analysis.

% Frequency-domain models face ongoing challenges in adaptivity and interpretability. They excel in capturing complex data patterns but often struggle to adapt to dynamic environments and lack the interpretability necessary for understanding underlying processes effectively. Notable studies by ~\cite{zhang2024heterophilic,shadfar2024frequency} have delved into the adaptivity challenges faced by frequency-domain models in dynamic settings. Additionally, work by~\cite{bouazizi2024enhancing,rezk2023interpretable,tran2024use} sheds light on interpretability issues within frequency-based approaches. Understanding and resolving these challenges are crucial for enhancing the practical utility of frequency-based methodologies. 

\paragraph{Preference for Time-Domain Methods over Frequency-Domain Techniques.} Determining the optimal use cases for time-domain methods over frequency-domain approaches continues to be a central and unresolved research question in the field of data analysis. Time-domain techniques are particularly advantageous in scenarios that demand real-time processing, where the ability to analyze and respond to data instantaneously is critical. These methods are also highly effective in applications that emphasize temporal dependencies, as they directly model the sequential nature of the data, providing insights into how events unfold over time. Furthermore, in contexts where interpretability and the generation of human-readable insights are of utmost importance, time-domain methods often deliver more transparent and intuitive results, making them easier to understand and act upon. Recent studies by~\citep{koch2023terahertz},~\citep{yan2024multi} and~\citep{yan2024comprehensive} have delved into the specific circumstances under which time-domain methods outperform frequency-based approaches, offering valuable insights into their relative strengths and limitations. These investigations highlight the importance of context in determining the most appropriate methodological choice, as the effectiveness of each approach can vary significantly depending on the nature of the data and the objectives of the analysis. Understanding the nuanced differences between time-domain and frequency-domain methods is essential for researchers and practitioners aiming to make informed decisions when selecting techniques for specific applications. By carefully considering the unique requirements of each scenario, it becomes possible to leverage the strengths of both domains, ultimately enhancing the accuracy, efficiency, and interpretability of data analysis outcomes. This ongoing exploration not only advances theoretical knowledge but also drives practical innovations, ensuring that the most suitable methods are employed to address the diverse challenges encountered in real-world applications.

\paragraph{Efficient Integration of Frequency-Domain Techniques with Deep Learning Models.} Efficiently integrating frequency-domain techniques with deep learning architectures represents a formidable yet highly promising challenge that demands innovative and interdisciplinary solutions. The seamless fusion of frequency-based features with deep learning models holds the potential to significantly enhance the ability to extract meaningful and robust representations from complex and high-dimensional data. By leveraging the strengths of frequency-domain methods—such as their ability to capture periodic patterns, reduce noise, and facilitate dimensionality reduction—alongside the powerful learning capabilities of deep neural networks, researchers can develop models that are both more accurate and interpretable. Recent research by~\citep{li2021frequency},~\citep{sun2021artificial}, and ~\citep{kim2023time} has made notable strides in this area, proposing novel methodologies for effectively combining these domains. Their work explores techniques such as incorporating Fourier transforms, wavelet analysis, and other frequency-based representations into neural network frameworks, enabling models to better capture structural nuances and temporal dynamics. These contributions not only advance the performance of deep learning models in tasks like time series forecasting, anomaly detection, and signal processing but also improve their interpretability, allowing for a clearer understanding of the underlying processes. The interdisciplinary nature of this research highlights the potential for cross-pollination between signal processing and machine learning, fostering innovations that can address long-standing challenges in data analysis. By continuing to explore and refine these integration strategies, researchers can unlock new possibilities for enhancing model efficacy, scalability, and applicability across a wide range of domains. This ongoing effort underscores the importance of bridging the gap between theoretical advancements and practical implementations, ultimately driving the development of more powerful tools for analyzing complex datasets.


% \subsection{Time Series Analysis}\label{sec:time-series}
% Predicting long-term trends in time series data (e.g., energy consumption, weather patterns, traffic flow) continues to be a difficult problem. Because the frequency domain is helpful for capturing long-term patterns in time series, frequency domain transformations have been widely used in time series prediction recently, as shown in Figure~\ref{figure-time-series}. 

% % One category of methods combines frequency domain with Convolutional models~\cite{krizhevsky2012imagenet}, while another uses Transformer-based models~\cite{vaswani2017attention} as a basis for combination.

% \begin{figure}[ht]
%     \centering
%     \setlength{\belowcaptionskip}{-0.3cm}  % Adjust this to reduce spacing
%     \includegraphics[width=0.45\textwidth]{figures/time-series.pdf}
%     \caption{Time Series in the Frequency Domain}
%     \label{figure-time-series}
% \end{figure}

% % \subsubsection{Convolution-based}
% Convolution-based methods~\cite{zhou2024fourier} for time series prediction have been a hot topic in recent years. 
% A recent work~\cite{eldele2024tslanet} proposes a method Tslanet, incorporating an adaptive spectral block via \emph{Fourier transform}, employing Fourier analysis for improved feature representation and the detection of both short-term and long-term dependencies. 
% Transformer-based methods~\cite{zhou2024fourier,ni2024time}
% for time series prediction aim to provide better performance in long-term prediction. To capture global-view dependencies of time series, Zhou \textit{et al.}~\cite{zhou2022fedformer} propose a method, namely FEDformer, to decompose Transformer with \emph{Fourier Transform} to compact representations of long-term time series patterns into frequency domain. Another work~\cite{sasal2022w} introduces an innovative approach to learning representations of univariate time series, named W-Transformer, which is built upon a transformer encoder structure utilizing wavelets. 



% To capture temporal-spectral correlations effectively~\cite{yang2024graformer,zhang2023self,wang2024card}, to be specific, Zhang \textit{at al.}~\cite{zhang2023self} propose Cross Reconstruction Transformer (CRT). CRT facilitates time series representation learning by employing a cross-domain dropping-reconstruction task via extracting the frequency domain of the time series using the fast \emph{Fourier Transform} and randomly eliminating specific patches in both the time and frequency domains. Woo \textit{et al.}~\cite{woo2022etsformer} proposed ETSFormer, a fresh Transformer architecture tailored for time-series data. 


% \subsection{Spatio-Temporal Dynamics}\label{sec:spatio-temporal-dynamics}
% Spatio-temporal dynamics involves changes across spatial and temporal dimensions, and processing it in the frequency domain offers advantages such as enhanced recognition of periodic, diffusion, and mobility patterns, as well as anomaly detection. Combining this approach with convolutional or Transformer methods provides further improvement, as shown in Figure~\ref{figure-spatio-temporal-dynamic}.

% \begin{figure}[ht]
%     \centering
%     \setlength{\belowcaptionskip}{-0.3cm}  % Adjust this to reduce spacing
%     \includegraphics[width=0.475\textwidth]{figures/spatio-temporal-dynamic.pdf}
%     \caption{Spatio-Temporal Dynamics in the Frequency Domain}
%     \label{figure-spatio-temporal-dynamic}
% \end{figure}


% % \subsubsection{Convolution-based}
% % Fourier Neural Operator
% Pioneer studies for capturing spatio-temporal dynamics~\cite{kabri2023resolution,guan2023fourier,sun2024graph} combine convolution networks with frequent ways like \emph{Fourier Transform}. For example, due to the flat geometry assumption, DFTs in spherical coordinates create artifacts. To address this limitation, a recent work~\cite{bonev2023spherical} extended FNOs to the sphere by introducing Spherical FNOs for learning operators on spheres. Guan \textit{et al.}~\cite{guan2023fourier} use \emph{Fourier Neural Operator} networks as a rapid data-centric deep learning technique to address the 2D photoacoustic wave equation within a uniform medium. Another research line is based on Transformer. Guibas~\cite{guibas2021adaptive} introduces Adaptive Fourier Neural Operator (AFNO) as a proficient token blending mechanism that assimilates information within the Fourier domain. AFNO is grounded in a systematic approach to operator learning. 

