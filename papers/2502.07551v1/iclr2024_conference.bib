
@article{zhang2021understanding,
  title={Understanding deep learning (still) requires rethinking generalization},
  author={Zhang, Chiyuan and Bengio, Samy and Hardt, Moritz and Recht, Benjamin and Vinyals, Oriol},
  journal={Communications of the ACM},
  year={2021}
}

@inproceedings{arpit2017closer,
  title={A closer look at memorization in deep networks},
  author={Arpit, Devansh and Jastrz{\k{e}}bski, Stanis{\l}aw and Ballas, Nicolas and Krueger, David and Bengio, Emmanuel and Kanwal, Maxinder S and Maharaj, Tegan and Fischer, Asja and Courville, Aaron and Bengio, Yoshua and others},
  booktitle={ICML},
  year={2017}
}

@inproceedings{patrini2017making,
  title={Making deep neural networks robust to label noise: A loss correction approach},
  author={Patrini, Giorgio and Rozza, Alessandro and Krishna Menon, Aditya and Nock, Richard and Qu, Lizhen},
  booktitle={CVPR},
  year={2017}
}

@article{hendrycks2018using,
  title={Using trusted data to train deep networks on labels corrupted by severe noise},
  author={Hendrycks, Dan and Mazeika, Mantas and Wilson, Duncan and Gimpel, Kevin},
  journal={NeurIPS},
  year={2018}
}

@inproceedings{jiang2018mentornet,
  title={Mentornet: Learning data-driven curriculum for very deep neural networks on corrupted labels},
  author={Jiang, Lu and Zhou, Zhengyuan and Leung, Thomas and Li, Li-Jia and Fei-Fei, Li},
  booktitle={ICML},
  year={2018}
}


@article{han2018co,
  title={Co-teaching: Robust training of deep neural networks with extremely noisy labels},
  author={Han, Bo and Yao, Quanming and Yu, Xingrui and Niu, Gang and Xu, Miao and Hu, Weihua and Tsang, Ivor and Sugiyama, Masashi},
  journal={NeurIPS},
  year={2018}
}

@inproceedings{wei2020combating,
  title={Combating noisy labels by agreement: A joint training method with co-regularization},
  author={Wei, Hongxin and Feng, Lei and Chen, Xiangyu and An, Bo},
  booktitle={CVPR},
  year={2020}
}

@article{nguyen2019self,
  title={Self: Learning to filter noisy labels with self-ensembling},
  author={Nguyen, Duc Tam and Mummadi, Chaithanya Kumar and Ngo, Thi Phuong Nhung and Nguyen, Thi Hoai Phuong and Beggel, Laura and Brox, Thomas},
  journal={arXiv preprint arXiv:1910.01842},
  year={2019}
}

@inproceedings{tanaka2018joint,
  title={Joint optimization framework for learning with noisy labels},
  author={Tanaka, Daiki and Ikami, Daiki and Yamasaki, Toshihiko and Aizawa, Kiyoharu},
  booktitle={CVPR},
  year={2018}
}

@article{bai2021understanding,
  title={Understanding and improving early stopping for learning with noisy labels},
  author={Bai, Yingbin and Yang, Erkun and Han, Bo and Yang, Yanhua and Li, Jiatong and Mao, Yinian and Niu, Gang and Liu, Tongliang},
  journal={NeurIPS},
  year={2021}
}


@article{feldman2020neural,
  title={What neural networks memorize and why: Discovering the long tail via influence estimation},
  author={Feldman, Vitaly and Zhang, Chiyuan},
  journal={NeurIPS},
  year={2020}
}

@inproceedings{feldman2020does,
  title={Does learning require memorization? a short tale about a long tail},
  author={Feldman, Vitaly},
  booktitle={STOC},
  year={2020}
}

@article{xia2021sample,
  title={Sample selection with uncertainty of losses for learning with noisy labels},
  author={Xia, Xiaobo and Liu, Tongliang and Han, Bo and Gong, Mingming and Yu, Jun and Niu, Gang and Sugiyama, Masashi},
  journal={arXiv preprint arXiv:2106.00445},
  year={2021}
}

@inproceedings{bai2021me,
  title={Me-momentum: Extracting hard confident examples from noisily labeled data},
  author={Bai, Yingbin and Liu, Tongliang},
  booktitle={ICCV},
  year={2021}
}

@inproceedings{bengio2009curriculum,
  title={Curriculum learning},
  author={Bengio, Yoshua and Louradour, J{\'e}r{\^o}me and Collobert, Ronan and Weston, Jason},
  booktitle={ICML},
  year={2009}
}


@inproceedings{maini2022characterizing,
  title={Characterizing Datapoints via Second-Split Forgetting},
  author={Maini, Pratyush and Garg, Saurabh and Lipton, Zachary Chase and Kolter, J Zico},
  booktitle={ICML 2022: Workshop on Spurious Correlations, Invariance and Stability}
}

@inproceedings{toneva2018empirical,
  title={An Empirical Study of Example Forgetting during Deep Neural Network Learning},
  author={Toneva, Mariya and Sordoni, Alessandro and des Combes, Remi Tachet and Trischler, Adam and Bengio, Yoshua and Gordon, Geoffrey J},
  booktitle={ICLR},
  year={2018}
}

@article{menon2020long,
  title={Long-tail learning via logit adjustment},
  author={Menon, Aditya Krishna and Jayasumana, Sadeep and Rawat, Ankit Singh and Jain, Himanshu and Veit, Andreas and Kumar, Sanjiv},
  journal={arXiv preprint arXiv:2007.07314},
  year={2020}
}

@article{krizhevsky2009learning,
  title={Learning multiple layers of features from tiny images},
  author={Krizhevsky, Alex and Hinton, Geoffrey and others},
  year={2009}
}

@inproceedings{xia2020robust,
  title={Robust early-learning: Hindering the memorization of noisy labels},
  author={Xia, Xiaobo and Liu, Tongliang and Han, Bo and Gong, Chen and Wang, Nannan and Ge, Zongyuan and Chang, Yi},
  booktitle={ICLR},
  year={2021}
}

@article{xu2019l_dmi,
  title={L\_dmi: A novel information-theoretic loss function for training deep nets robust to label noise},
  author={Xu, Yilun and Cao, Peng and Kong, Yuqing and Wang, Yizhou},
  journal={NeurIPS},
  year={2019}
}

@inproceedings{patrini2017making,
  title={Making deep neural networks robust to label noise: A loss correction approach},
  author={Patrini, Giorgio and Rozza, Alessandro and Krishna Menon, Aditya and Nock, Richard and Qu, Lizhen},
  booktitle={CVPR},
  year={2017}
}

@article{rubinstein1999cross,
  title={The cross-entropy method for combinatorial and continuous optimization},
  author={Rubinstein, Reuven},
  journal={Methodology and computing in applied probability},
  year={1999}
}

@article{nguyen2019self,
  title={Self: Learning to filter noisy labels with self-ensembling},
  author={Nguyen, Duc Tam and Mummadi, Chaithanya Kumar and Ngo, Thi Phuong Nhung and Nguyen, Thi Hoai Phuong and Beggel, Laura and Brox, Thomas},
  journal={arXiv preprint arXiv:1910.01842},
  year={2019}
}

@article{li2020dividemix,
  title={Dividemix: Learning with noisy labels as semi-supervised learning},
  author={Li, Junnan and Socher, Richard and Hoi, Steven CH},
  journal={arXiv preprint arXiv:2002.07394},
  year={2020}
}

@article{liu2020early,
  title={Early-learning regularization prevents memorization of noisy labels},
  author={Liu, Sheng and Niles-Weed, Jonathan and Razavian, Narges and Fernandez-Granda, Carlos},
  journal={NeurIPS},
  year={2020}
}

@inproceedings{wei2022self,
  title={Self-Filtering: A Noise-Aware Sample Selection for Label Noise with Confidence Penalization},
  author={Wei, Qi and Sun, Haoliang and Lu, Xiankai and Yin, Yilong},
  booktitle={ECCV},
  year={2022}
}

@inproceedings{hacohen2019power,
  title={On the power of curriculum learning in training deep networks},
  author={Hacohen, Guy and Weinshall, Daphna},
  booktitle={ICML},
  year={2019}
}

@article{cao2020heteroskedastic,
  title={Heteroskedastic and imbalanced deep learning with adaptive regularization},
  author={Cao, Kaidi and Chen, Yining and Lu, Junwei and Arechiga, Nikos and Gaidon, Adrien and Ma, Tengyu},
  journal={arXiv preprint arXiv:2006.15766},
  year={2020}
}

@article{rolnick2017deep,
  title={Deep learning is robust to massive label noise},
  author={Rolnick, David and Veit, Andreas and Belongie, Serge and Shavit, Nir},
  journal={arXiv preprint arXiv:1705.10694},
  year={2017}
}

@article{han2020survey,
  title={A survey of label-noise representation learning: Past, present and future},
  author={Han, Bo and Yao, Quanming and Liu, Tongliang and Niu, Gang and Tsang, Ivor W and Kwok, James T and Sugiyama, Masashi},
  journal={arXiv preprint arXiv:2011.04406},
  year={2020}
}

@inproceedings{wei2020combating,
  title={Combating noisy labels by agreement: A joint training method with co-regularization},
  author={Wei, Hongxin and Feng, Lei and Chen, Xiangyu and An, Bo},
  booktitle={CVPR},
  year={2020}
}

@inproceedings{song2019selfie,
  title={Selfie: Refurbishing unclean samples for robust deep learning},
  author={Song, Hwanjun and Kim, Minseok and Lee, Jae-Gil},
  booktitle={ICML},
  year={2019}
}

@inproceedings{zhou2021robust,
  title={Robust curriculum learning: from clean label detection to noisy label self-correction},
  author={Zhou, Tianyi and Wang, Shengjie and Bilmes, Jeff},
  booktitle={ICLR},
  year={2021}
}

@article{liu2015classification,
  title={Classification with noisy labels by importance reweighting},
  author={Liu, Tongliang and Tao, Dacheng},
  journal={IEEE Transactions on pattern analysis and machine intelligence},
  year={2015}
}

@inproceedings{jiang2021characterizing,
  title={Characterizing Structural Regularities of Labeled Data in Overparameterized Models},
  author={Jiang, Ziheng and Zhang, Chiyuan and Talwar, Kunal and Mozer, Michael C},
  booktitle={ICML},
  year={2021}
}

@inproceedings{mangalam2019deep,
  title={Do deep neural networks learn shallow learnable examples first?},
  author={Mangalam, Karttikeya and Prabhu, Vinay Uday},
  booktitle={ICML 2019 Workshop on Identifying and Understanding Deep Learning Phenomena},
  year={2019}
}

@article{hooker2019compressed,
  title={What do compressed deep neural networks forget?},
  author={Hooker, Sara and Courville, Aaron and Clark, Gregory and Dauphin, Yann and Frome, Andrea},
  journal={arXiv preprint arXiv:1911.05248},
  year={2019}
}

@article{baldock2021deep,
  title={Deep learning through the lens of example difficulty},
  author={Baldock, Robert and Maennel, Hartmut and Neyshabur, Behnam},
  journal={NeurIPS},
  year={2021}
}

@article{carlini2019distribution,
  title={Distribution density, tails, and outliers in machine learning: Metrics and applications},
  author={Carlini, Nicholas and Erlingsson, Ulfar and Papernot, Nicolas},
  journal={arXiv preprint arXiv:1910.13427},
  year={2019}
}


@article{pleiss2020identifying,
  title={Identifying mislabeled data using the area under the margin ranking},
  author={Pleiss, Geoff and Zhang, Tianyi and Elenberg, Ethan and Weinberger, Kilian Q},
  journal={NeurIPS},
  year={2020}
}

@inproceedings{huang2019o2u,
  title={O2u-net: A simple noisy label detection approach for deep neural networks},
  author={Huang, Jinchi and Qu, Lie and Jia, Rongfei and Zhao, Binqiang},
  booktitle={ICCV},
  year={2019}
}

@inproceedings{chen2019understanding,
  title={Understanding and utilizing deep neural networks trained with noisy labels},
  author={Chen, Pengfei and Liao, Ben Ben and Chen, Guangyong and Zhang, Shengyu},
  booktitle={ICML},
  year={2019}
}

@article{song2022learning,
  title={Learning from noisy labels with deep neural networks: A survey},
  author={Song, Hwanjun and Kim, Minseok and Park, Dongmin and Shin, Yooju and Lee, Jae-Gil},
  journal={IEEE Transactions on Neural Networks and Learning Systems},
  year={2022},
  publisher={IEEE}
}

@inproceedings{liu2020peer,
  title={Peer loss functions: Learning from noisy labels without knowing noise rates},
  author={Liu, Yang and Guo, Hongyi},
  booktitle={ICML},
  year={2020}
}

@article{hu2019simple,
  title={Simple and effective regularization methods for training on noisily labeled data with generalization guarantee},
  author={Hu, Wei and Li, Zhiyuan and Yu, Dingli},
  journal={arXiv preprint arXiv:1905.11368},
  year={2019}
}

@inproceedings{li2020gradient,
  title={Gradient descent with early stopping is provably robust to label noise for overparameterized neural networks},
  author={Li, Mingchen and Soltanolkotabi, Mahdi and Oymak, Samet},
  booktitle={International conference on artificial intelligence and statistics},
  year={2020}
}

@inproceedings{han2020sigua,
  title={Sigua: Forgetting may make learning with noisy labels more robust},
  author={Han, Bo and Niu, Gang and Yu, Xingrui and Yao, Quanming and Xu, Miao and Tsang, Ivor and Sugiyama, Masashi},
  booktitle={ICML},
  year={2020}
}

@ARTICLE{9941371,
  author={Yang, Xiangli and Song, Zixing and King, Irwin and Xu, Zenglin},
  journal={IEEE Transactions on Knowledge and Data Engineering}, 
  title={A Survey on Deep Semi-Supervised Learning}, 
  year={2022},
  doi={10.1109/TKDE.2022.3220219}}

  @inproceedings{wu2021ngc,
  title={NGC: A unified framework for learning with open-world noisy data},
  author={Wu, Zhi-Fan and Wei, Tong and Jiang, Jianwen and Mao, Chaojie and Tang, Mingqian and Li, Yu-Feng},
  booktitle={ICCV},
  year={2021}
}

@article{luo2017learning,
  title={Learning with noise: Enhance distantly supervised relation extraction with dynamic transition matrix},
  author={Luo, Bingfeng and Feng, Yansong and Wang, Zheng and Zhu, Zhanxing and Huang, Songfang and Yan, Rui and Zhao, Dongyan},
  journal={arXiv preprint arXiv:1705.03995},
  year={2017}
}

@inproceedings{wang2018iterative,
  title={Iterative learning with open-set noisy labels},
  author={Wang, Yisen and Liu, Weiyang and Ma, Xingjun and Bailey, James and Zha, Hongyuan and Song, Le and Xia, Shu-Tao},
  booktitle={CVPR},
  year={2018}
}

@inproceedings{shen2019learning,
  title={Learning with bad training data via iterative trimmed loss minimization},
  author={Shen, Yanyao and Sanghavi, Sujay},
  booktitle={ICML},
  year={2019}
}

@article{wu2020topological,
  title={A topological filter for learning with label noise},
  author={Wu, Pengxiang and Zheng, Songzhu and Goswami, Mayank and Metaxas, Dimitris and Chen, Chao},
  journal={NeurIPS},
  pages={21382--21393},
  year={2020}
}

@article{lyu2019curriculum,
  title={Curriculum loss: Robust learning and generalization against label corruption},
  author={Lyu, Yueming and Tsang, Ivor W},
  journal={arXiv preprint arXiv:1905.10045},
  year={2019}
}

@article{wei2021learning,
  title={Learning with noisy labels revisited: A study using real-world human annotations},
  author={Wei, Jiaheng and Zhu, Zhaowei and Cheng, Hao and Liu, Tongliang and Niu, Gang and Liu, Yang},
  journal={arXiv preprint arXiv:2110.12088},
  year={2021}
}

@inproceedings{he2016deep,
  title={Deep residual learning for image recognition},
  author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  booktitle={CVPR},
  year={2016}
}

@article{lecun2015deep,
  title={Deep learning},
  author={LeCun, Yann and Bengio, Yoshua and Hinton, Geoffrey},
  journal={Nature},
  year={2015}
}

@article{montufar2014number,
  title={On the number of linear regions of deep neural networks},
  author={Montufar, Guido F and Pascanu, Razvan and Cho, Kyunghyun and Bengio, Yoshua},
  journal={NeurIPS},
  year={2014}
}

@article{bengio2009learning,
  title={Learning deep architectures for AI},
  author={Bengio, Yoshua and others},
  journal={Foundations and trends{\textregistered} in Machine Learning},
  year={2009}
}

@article{bishop1995regularization,
  title={Regularization and complexity control in feed-forward networks},
  author={Bishop, Christopher M},
  year={1995},
  publisher={EC2 et Cie}
}

@article{sjoberg1995overtraining,
  title={Overtraining, regularization and searching for a minimum, with application to neural networks},
  author={Sj{\"o}berg, Jonas and Ljung, Lennart},
  journal={International Journal of Control},
  publisher={Taylor \& Francis}
}

@book{goodfellow2016deep,
  title={Deep learning},
  author={Goodfellow, Ian and Bengio, Yoshua and Courville, Aaron},
  year={2016},
  publisher={MIT press}
}

@inproceedings{
forouzesh2023leveraging,
title={Leveraging Unlabeled Data to Track Memorization},
author={Mahsa Forouzesh and Hanie Sedghi and Patrick Thiran},
booktitle={ICLR },
year={2023}
}

@inproceedings{
zhang2017understanding,
title={Understanding deep learning requires rethinking generalization},
author={Chiyuan Zhang and Samy Bengio and Moritz Hardt and Benjamin Recht and Oriol Vinyals},
booktitle={ICLR},
year={2017}
}

@article{nagarajan2019uniform,
  title={Uniform convergence may be unable to explain generalization in deep learning},
  author={Nagarajan, Vaishnavh and Kolter, J Zico},
  journal={NeurIPS},
  year={2019}
}

@inproceedings{garg2021ratt,
  title={Ratt: Leveraging unlabeled data to guarantee generalization},
  author={Garg, Saurabh and Balakrishnan, Sivaraman and Kolter, Zico and Lipton, Zachary},
  booktitle={ICML},
  year={2021}
}

@inproceedings{dwork2015preserving,
  title={Preserving statistical validity in adaptive data analysis},
  author={Dwork, Cynthia and Feldman, Vitaly and Hardt, Moritz and Pitassi, Toniann and Reingold, Omer and Roth, Aaron Leon},
  booktitle={STOC},
  year={2015}
}

@inproceedings{chen2021robustness,
  title={Robustness of accuracy metric and its inspirations in learning with noisy labels},
  author={Chen, Pengfei and Ye, Junjie and Chen, Guangyong and Zhao, Jingwei and Heng, Pheng-Ann},
  booktitle={AAAI},
  year={2021}
}

@article{xu2018splitting,
  title={On splitting training and validation set: a comparative study of cross-validation, bootstrap and systematic sampling for estimating the generalization performance of supervised learning},
  author={Xu, Yun and Goodacre, Royston},
  journal={Journal of analysis and testing},
  year={2018}
}

@book{mohri2018foundations,
  title={Foundations of machine learning},
  author={Mohri, Mehryar and Rostamizadeh, Afshin and Talwalkar, Ameet},
  year={2018},
  publisher={MIT press}
}

@article{xia2019anchor,
  title={Are anchor points really indispensable in label-noise learning?},
  author={Xia, Xiaobo and Liu, Tongliang and Wang, Nannan and Han, Bo and Gong, Chen and Niu, Gang and Sugiyama, Masashi},
  journal={NeurIPS},
  year={2019}
}

@article{zhang2019perturbed,
  title={Perturbed model validation: A new framework to validate model relevance},
  author={Zhang, Jie and Barr, Earl T and Guedj, Benjamin and Harman, Mark and Shawe-Taylor, John},
  year={2019}
}

@article{forouzesh2022leveraging,
  title={Leveraging Unlabeled Data to Track Memorization},
  author={Forouzesh, Mahsa and Sedghi, Hanie and Thiran, Patrick},
  journal={arXiv preprint arXiv:2212.04461},
  year={2022}
}

@inproceedings{deng2021labels,
  title={Are labels always necessary for classifier accuracy evaluation?},
  author={Deng, Weijian and Zheng, Liang},
  booktitle={CVPR},
  year={2021}
}

@article{jiang2018predicting,
  title={Predicting the generalization gap in deep networks with margin distributions},
  author={Jiang, Yiding and Krishnan, Dilip and Mobahi, Hossein and Bengio, Samy},
  journal={arXiv preprint arXiv:1810.00113},
  year={2018}
}

@inproceedings{corneanu2020computing,
  title={Computing the testing error without a testing set},
  author={Corneanu, Ciprian A and Escalera, Sergio and Martinez, Aleix M},
  booktitle={CVPR},
  year={2020}
}

@inproceedings{arora2018stronger,
  title={Stronger generalization bounds for deep nets via a compression approach},
  author={Arora, Sanjeev and Ge, Rong and Neyshabur, Behnam and Zhang, Yi},
  booktitle={ICML},
  year={2018}
}

@article{morcos2018importance,
  title={On the importance of single directions for generalization},
  author={Morcos, Ari S and Barrett, David GT and Rabinowitz, Neil C and Botvinick, Matthew},
  journal={arXiv preprint arXiv:1803.06959},
  year={2018}
}

@article{hedges2002origin,
  title={The origin and evolution of model organisms},
  author={Hedges, S Blair},
  journal={Nature Reviews Genetics},
  year={2002}
}

@inproceedings{yuan2023latestopping,
  title={Late stopping: Avoiding confidently learning from mislabeled examples},
  author={Yuan, Suqin and Feng, Lei and Liu, Tongliang},
  booktitle={ICCV},
  year={2023}
}

@article{lu2022selc,
  title={SELC: self-ensemble label correction improves learning with noisy labels},
  author={Lu, Yangdi and He, Wenbo},
  journal={arXiv preprint arXiv:2205.01156},
  year={2022}
}

@inproceedings{37648,
title	= {Reading Digits in Natural Images with Unsupervised Feature Learning},
author	= {Yuval Netzer and Tao Wang and Adam Coates and Alessandro Bissacco and Bo Wu and Andrew Y. Ng},
year	= {2011},
booktitle	= {NIPS Workshop on Deep Learning and Unsupervised Feature Learning 2011}
}

@article{le2015tiny,
  title={Tiny imagenet visual recognition challenge},
  author={Le, Ya and Yang, Xuan},
  journal={CS 231N},
  year={2015}
}

@inproceedings{huang2017densely,
  title={Densely connected convolutional networks},
  author={Huang, Gao and Liu, Zhuang and Van Der Maaten, Laurens and Weinberger, Kilian Q},
  booktitle={CVPR},
  year={2017}
}

@article{simonyan2014very,
  title={Very deep convolutional networks for large-scale image recognition},
  author={Simonyan, Karen and Zisserman, Andrew},
  journal={arXiv preprint arXiv:1409.1556},
  year={2014}
}

@article{xia2020part,
  title={Part-dependent label noise: Towards instance-dependent label noise},
  author={Xia, Xiaobo and Liu, Tongliang and Han, Bo and Wang, Nannan and Gong, Mingming and Liu, Haifeng and Niu, Gang and Tao, Dacheng and Sugiyama, Masashi},
  journal={NeurIPS},
  year={2020}
}

@article{van2015learning,
  title={Learning with symmetric label noise: The importance of being unhinged},
  author={Van Rooyen, Brendan and Menon, Aditya and Williamson, Robert C},
  journal={NeurIPS},
  year={2015}
}

@inproceedings{wei2023logitclip,
      title={Mitigating Memorization of Noisy Labels by Clipping the Model Prediction},
      author={Wei, Hongxin and Zhuang, Huiping and Xie, Renchunzi and Feng, Lei and Niu, Gang and An, Bo and Li, Yixuan},
      booktitle={ICML},
      year={2023}
    }

@inproceedings{ijcai2020p305,
  title     = {Can Cross Entropy Loss Be Robust to Label Noise?},
  author    = {Feng, Lei and Shu, Senlin and Lin, Zhuoyi and Lv, Fengmao and Li, Li and An, Bo},
  booktitle = {IJCAI},
  year      = {2020},
}

@article{nakkiran2021deep,
  title={Deep double descent: Where bigger models and more data hurt},
  author={Nakkiran, Preetum and Kaplun, Gal and Bansal, Yamini and Yang, Tristan and Barak, Boaz and Sutskever, Ilya},
  journal={Journal of Statistical Mechanics: Theory and Experiment},
  year={2021}
}

@article{power2022grokking,
  title={Grokking: Generalization beyond overfitting on small algorithmic datasets},
  author={Power, Alethea and Burda, Yuri and Edwards, Harri and Babuschkin, Igor and Misra, Vedant},
  journal={arXiv preprint arXiv:2201.02177},
  year={2022}
}

@article{nanda2023progress,
  title={Progress measures for grokking via mechanistic interpretability},
  author={Nanda, Neel and Chan, Lawrence and Liberum, Tom and Smith, Jess and Steinhardt, Jacob},
  journal={arXiv preprint arXiv:2301.05217},
  year={2023}
}

@article{liu2022towards,
  title={Towards understanding grokking: An effective theory of representation learning},
  author={Liu, Ziming and Kitouni, Ouail and Nolte, Niklas S and Michaud, Eric and Tegmark, Max and Williams, Mike},
  journal={NeurIPS},
  year={2022}
}

@article{belkin2019reconciling,
  title={Reconciling modern machine-learning practice and the classical bias--variance trade-off},
  author={Belkin, Mikhail and Hsu, Daniel and Ma, Siyuan and Mandal, Soumik},
  journal={Proceedings of the National Academy of Sciences},
  year={2019},
  publisher={National Acad Sciences}
}

@article{lyle2020bayesian,
  title={A bayesian perspective on training speed and model selection},
  author={Lyle, Clare and Schut, Lisa and Ru, Robin and Gal, Yarin and van der Wilk, Mark},
  journal={NeurIPS},
  year={2020}
}

@article{ru2021speedy,
  title={Speedy performance estimation for neural architecture search},
  author={Ru, Robin and Lyle, Clare and Schut, Lisa and Fil, Miroslav and van der Wilk, Mark and Gal, Yarin},
  journal={NeurIPS},
  year={2021}
}

@article{algan2021image,
  title={Image classification with deep learning in the presence of noisy labels: A survey},
  author={Algan, G{\"o}rkem and Ulusoy, Ilkay},
  journal={Knowledge-Based Systems},
  year={2021}
}

 @article{robbins1951stochastic,
  title={A stochastic approximation method},
  author={Robbins, Herbert and Monro, Sutton},
  journal={The annals of mathematical statistics},
  year={1951}
}

@article{kingma2014adam,
  title={Adam: A method for stochastic optimization},
  author={Kingma, Diederik P and Ba, Jimmy},
  journal={arXiv preprint arXiv:1412.6980},
  year={2014}
}

@inproceedings{chen2021noise,
title={Noise against noise: stochastic label noise helps combat inherent label noise},
author={Pengfei Chen and Guangyong Chen and Junjie Ye and jingwei zhao and Pheng-Ann Heng},
booktitle={ICLR},
year={2021}
}

@article{kiryo2017positive,
  title={Positive-unlabeled learning with non-negative risk estimator},
  author={Kiryo, Ryuichi and Niu, Gang and Du Plessis, Marthinus C and Sugiyama, Masashi},
  journal={NeurIPS},
  year={2017}
}

@incollection{lang1995newsweeder,
  title={Newsweeder: Learning to filter netnews},
  author={Lang, Ken},
  booktitle={Machine learning proceedings 1995},
  year={1995}
}

@inproceedings{yu2019does,
  title={How does disagreement help generalization against label corruption?},
  author={Yu, Xingrui and Han, Bo and Yao, Jiangchao and Niu, Gang and Tsang, Ivor and Sugiyama, Masashi},
  booktitle={ICML},
  year={2019}
}

@article{zhou2023asymmetric,
  title={Asymmetric loss functions for noise-tolerant learning: Theory and applications},
  author={Zhou, Xiong and Liu, Xianming and Zhai, Deming and Jiang, Junjun and Ji, Xiangyang},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},
  year={2023}
}

@article{advani2020high,
  title={High-dimensional dynamics of generalization error in neural networks},
  author={Advani, Madhu S and Saxe, Andrew M and Sompolinsky, Haim},
  journal={Neural Networks},
  year={2020}
}

@article{chaudhari2019entropy,
  title={Entropy-sgd: Biasing gradient descent into wide valleys},
  author={Chaudhari, Pratik and Choromanska, Anna and Soatto, Stefano and LeCun, Yann and Baldassi, Carlo and Borgs, Christian and Chayes, Jennifer and Sagun, Levent and Zecchina, Riccardo},
  journal={Journal of Statistical Mechanics: Theory and Experiment},
  year={2019}
}

@inproceedings{
toneva2018an,
title={An Empirical Study of Example Forgetting during Deep Neural Network Learning},
author={Mariya Toneva and Alessandro Sordoni and Remi Tachet des Combes and Adam Trischler and Yoshua Bengio and Geoffrey J. Gordon},
booktitle={ICLR},
year={2019}
}

@article{kendall1938new,
  title={A new measure of rank correlation},
  author={Kendall, Maurice G},
  journal={Biometrika},
  year={1938}
}

@inproceedings{
Jiang*2020Fantastic,
title={Fantastic Generalization Measures and Where to Find Them},
author={Yiding Jiang and Behnam Neyshabur and Hossein Mobahi and Dilip Krishnan and Samy Bengio},
booktitle={ICLR},
year={2020}
}

@article{chatterjee2022generalization,
  title={On the generalization mystery in deep learning},
  author={Chatterjee, Satrajit and Zielinski, Piotr},
  journal={arXiv preprint arXiv:2203.10036},
  year={2022}
}

@inproceedings{szegedy2016rethinking,
  title={Rethinking the inception architecture for computer vision},
  author={Szegedy, Christian and Vanhoucke, Vincent and Ioffe, Sergey and Shlens, Jon and Wojna, Zbigniew},
  booktitle={CVPR},
  year={2016}
}

@inproceedings{liu2022robust,
  title={Robust training under label noise by over-parameterization},
  author={Liu, Sheng and Zhu, Zhihui and Qu, Qing and You, Chong},
  booktitle={ICML},
  pages={14153--14172},
  year={2022}
}

@misc{yao2021dual,
      title={Dual T: Reducing Estimation Error for Transition Matrix in Label-noise Learning}, 
      author={Yu Yao and Tongliang Liu and Bo Han and Mingming Gong and Jiankang Deng and Gang Niu and Masashi Sugiyama},
      year={2021},
      archivePrefix={arXiv},
}

@inproceedings{
cheng2021learning,
title={Learning with Instance-Dependent Label Noise: A Sample Sieve Approach},
author={Hao Cheng and Zhaowei Zhu and Xingyu Li and Yifei Gong and Xing Sun and Yang Liu},
booktitle={ICLR},
year={2021}
}

@article{tieleman2012lecture,
  title={Lecture 6.5-rmsprop: Divide the gradient by a running average of its recent magnitude},
  author={Tieleman, Tijmen and Hinton, Geoffrey and others},
  journal={COURSERA: Neural networks for machine learning},
  year={2012}
}


@inproceedings{wei2022smooth,
  title={To Smooth or Not? When Label Smoothing Meets Noisy Labels},
  author={Wei, Jiaheng and Liu, Hangyu and Liu, Tongliang and Niu, Gang and Sugiyama, Masashi and Liu, Yang},
  booktitle={ICML},
  year={2022}
}

@article{polyak1964some,
  title={Some methods of speeding up the convergence of iteration methods},
  author={Polyak, Boris T},
  journal={Ussr computational mathematics and mathematical physics},
  year={1964}
}

@inproceedings{pennington2014glove,
  title={Glove: Global vectors for word representation},
  author={Pennington, Jeffrey and Socher, Richard and Manning, Christopher D},
  booktitle={EMNLP},
  year={2014}
}

@article{song2019does,
  title={How does early stopping help generalization against label noise?},
  author={Song, Hwanjun and Kim, Minseok and Park, Dongmin and Lee, Jae-Gil},
  journal={arXiv preprint arXiv:1911.08059},
  year={2019}
}

@inproceedings{song2021robust,
  title={Robust learning by self-transition for handling noisy labels},
  author={Song, Hwanjun and Kim, Minseok and Park, Dongmin and Shin, Yooju and Lee, Jae-Gil},
  booktitle={KDD},
  year={2021}
}

@inproceedings{xiao2015learning,
  title={Learning from massive noisy labeled data for image classification},
  author={Xiao, Tong and Xia, Tian and Yang, Yi and Huang, Chang and Wang, Xiaogang},
  booktitle={CVPR},
  year={2015}
}

@article{li2017webvision,
  title={Webvision database: Visual learning and understanding from web data},
  author={Li, Wen and Wang, Limin and Li, Wei and Agustsson, Eirikur and Van Gool, Luc},
  journal={arXiv preprint arXiv:1708.02862},
  year={2017}
}

@inproceedings{bossard14,
  title = {Food-101 -- Mining Discriminative Components with Random Forests},
  author = {Bossard, Lukas and Guillaumin, Matthieu and Van Gool, Luc},
  booktitle = {ECCV},
  year = {2014}
}

@article{cao2019learning,
  title={Learning imbalanced datasets with label-distribution-aware margin loss},
  author={Cao, Kaidi and Wei, Colin and Gaidon, Adrien and Arechiga, Nikos and Ma, Tengyu},
  journal={NeurIPS},
  year={2019}
}

@article{lin2023over,
  title={On the Over-Memorization During Natural, Robust and Catastrophic Overfitting},
  author={Lin, Runqi and Yu, Chaojian and Han, Bo and Liu, Tongliang},
  journal={arXiv preprint arXiv:2310.08847},
  year={2023}
}

@article{bartlett2020benign,
  title={Benign overfitting in linear regression},
  author={Bartlett, Peter L and Long, Philip M and Lugosi, G{\'a}bor and Tsigler, Alexander},
  journal={Proceedings of the National Academy of Sciences},
  year={2020}
}

@inproceedings{zhang2018mixup,
  title={mixup: Beyond Empirical Risk Minimization},
  author={Zhang, Hongyi and Cisse, Moustapha and Dauphin, Yann N and Lopez-Paz, David},
  booktitle={ICLR},
  year={2018}
}

@inproceedings{ioffe2015batch,
  title={Batch normalization: Accelerating deep network training by reducing internal covariate shift},
  author={Ioffe, Sergey and Szegedy, Christian},
  booktitle={ICML},
  year={2015}
}

@article{srivastava2014dropout,
  title={Dropout: a simple way to prevent neural networks from overfitting},
  author={Srivastava, Nitish and Hinton, Geoffrey and Krizhevsky, Alex and Sutskever, Ilya and Salakhutdinov, Ruslan},
  journal={The journal of machine learning research},
  year={2014},
}


@inproceedings{xia2022moderate,
  title={Moderate coreset: A universal method of data selection for real-world data-efficient deep learning},
  author={Xia, Xiaobo and Liu, Jiale and Yu, Jun and Shen, Xu and Han, Bo and Liu, Tongliang},
  booktitle={ICLR},
  year={2022}
}


@inproceedings{bai2021me,
  title={Me-momentum: Extracting hard confident examples from noisily labeled data},
  author={Bai, Yingbin and Liu, Tongliang},
  booktitle={ICCV},
  year={2021}
}


@InProceedings{pmlr-v51-duvenaud16,
  title = 	 {Early Stopping as Nonparametric Variational Inference},
  author = 	 {Duvenaud, David and Maclaurin, Dougal and Adams, Ryan},
  booktitle = 	 {Proceedings of the 19th International Conference on Artificial Intelligence and Statistics},
  year = 	 {2016},
}


@article{mahsereci2017early,
  title={Early stopping without a validation set},
  author={Mahsereci, Maren and Balles, Lukas and Lassner, Christoph and Hennig, Philipp},
  journal={arXiv preprint arXiv:1703.09580},
  year={2017}
}

@article{liu2015classification,
  title={Classification with noisy labels by importance reweighting},
  author={Liu, Tongliang and Tao, Dacheng},
  journal={IEEE Transactions on pattern analysis and machine intelligence},
  year={2015}
}

@article{xia2023regularly,
  title={Regularly Truncated M-Estimators for Learning With Noisy Labels},
  author={Xia, Xiaobo and Lu, Pengqian and Gong, Chen and Han, Bo and Yu, Jun and Liu, Tongliang},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},
  year={2023}
}

@article{huang2023machine,
  title={Machine Vision Therapy: Multimodal Large Language Models Can Enhance Visual Robustness via Denoising In-Context Learning},
  author={Huang, Zhuo and Liu, Chang and Dong, Yinpeng and Su, Hang and Zheng, Shibao and Liu, Tongliang},
  journal={arXiv preprint arXiv:2312.02546},
  year={2023}
}