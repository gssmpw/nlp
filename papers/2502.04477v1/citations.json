[
  {
    "index": 0,
    "papers": [
      {
        "key": "howard1960dynamic",
        "author": "Howard, Ronald A",
        "title": "Dynamic Programming and {M}arkov Processes."
      }
    ]
  },
  {
    "index": 1,
    "papers": [
      {
        "key": "blackwell1962discrete",
        "author": "Blackwell, David",
        "title": "Discrete dynamic programming"
      }
    ]
  },
  {
    "index": 2,
    "papers": [
      {
        "key": "mahadevan1996average",
        "author": "Mahadevan, Sridhar",
        "title": "Average reward reinforcement learning: Foundations, algorithms, and empirical results"
      },
      {
        "key": "dewanto2020average",
        "author": "Dewanto, Vektor and Dunn, George and Eshragh, Ali and Gallagher, Marcus and Roosta, Fred",
        "title": "Average-reward model-free reinforcement learning: a systematic review and literature mapping"
      }
    ]
  },
  {
    "index": 3,
    "papers": [
      {
        "key": "jin2021towards",
        "author": "Jin, Yujia and Sidford, Aaron",
        "title": "Towards tight bounds on the sample complexity of average-reward {MDP}s"
      },
      {
        "key": "zurek2024span",
        "author": "Zurek, Matthew and Chen, Yudong",
        "title": "Span-Based Optimal Sample Complexity for Weakly Communicating and General Average Reward {MDP}s"
      }
    ]
  },
  {
    "index": 4,
    "papers": [
      {
        "key": "wei2020model",
        "author": "Wei, Chen-Yu and Jahromi, Mehdi Jafarnia and Luo, Haipeng and Sharma, Hiteshi and Jain, Rahul",
        "title": "Model-free reinforcement learning in infinite-horizon average-reward {M}arkov decision processes"
      },
      {
        "key": "wan2021learning",
        "author": "Wan, Yi and Naik, Abhishek and Sutton, Richard S",
        "title": "Learning and planning in average-reward {M}arkov decision processes"
      }
    ]
  },
  {
    "index": 5,
    "papers": [
      {
        "key": "bai2024regret",
        "author": "Bai, Qinbo and Mondal, Washim Uddin and Aggarwal, Vaneet",
        "title": "Regret analysis of policy gradient algorithm for infinite horizon average reward markov decision processes"
      },
      {
        "key": "kumar2024global",
        "author": "Kumar, Navdeep and Murthy, Yashaswini and Shufaro, Itai and Levy, Kfir Y and Srikant, R and Mannor, Shie",
        "title": "On the global convergence of policy gradient in average reward {M}arkov decision processes"
      }
    ]
  },
  {
    "index": 6,
    "papers": [
      {
        "key": "murthy2023convergence",
        "author": "Murthy, Yashaswini and Srikant, R",
        "title": "On the Convergence of Natural Policy Gradient and Mirror Descent-Like Policy Methods for Average-Reward {MDP}s"
      }
    ]
  },
  {
    "index": 7,
    "papers": [
      {
        "key": "agarwal2020model",
        "author": "Agarwal, Alekh and Kakade, Sham and Yang, Lin F",
        "title": "Model-based reinforcement learning with a generative model is minimax optimal"
      },
      {
        "key": "li2020breaking",
        "author": "Li, Gen and Wei, Yuting and Chi, Yuejie and Gu, Yuantao and Chen, Yuxin",
        "title": "Breaking the sample size barrier in model-based reinforcement learning with a generative model"
      }
    ]
  },
  {
    "index": 8,
    "papers": [
      {
        "key": "gheshlaghi2013minimax",
        "author": "Azar, Mohammad Gheshlaghi and Munos, R{\\'e}mi and Kappen, Hilbert J",
        "title": "Minimax {PAC} bounds on the sample complexity of reinforcement learning with a generative model"
      }
    ]
  },
  {
    "index": 9,
    "papers": [
      {
        "key": "wang2023optimal",
        "author": "Wang, Shengbo and Blanchet, Jose and Glynn, Peter",
        "title": "Optimal sample complexity for average reward {M}arkov decision processes"
      }
    ]
  },
  {
    "index": 10,
    "papers": [
      {
        "key": "zurek2024span",
        "author": "Zurek, Matthew and Chen, Yudong",
        "title": "Span-Based Optimal Sample Complexity for Weakly Communicating and General Average Reward {MDP}s"
      }
    ]
  },
  {
    "index": 11,
    "papers": [
      {
        "key": "tuynman2024finding",
        "author": "Tuynman, Adrienne and Degenne, R{\\'e}my and Kaufmann, Emilie",
        "title": "Finding good policies in average-reward {M}arkov Decision Processes without prior knowledge"
      }
    ]
  },
  {
    "index": 12,
    "papers": [
      {
        "key": "kearns1998finite",
        "author": "Kearns, Michael and Singh, Satinder",
        "title": "Finite-sample convergence rates for {Q}-learning and indirect algorithms"
      }
    ]
  },
  {
    "index": 13,
    "papers": [
      {
        "key": "sidford2018near",
        "author": "Sidford, Aaron and Wang, Mengdi and Wu, Xian and Yang, Lin and Ye, Yinyu",
        "title": "Near-optimal time and sample complexities for solving {M}arkov decision processes with a generative model"
      },
      {
        "key": "wainwright2019variance",
        "author": "Wainwright, Martin J",
        "title": "Variance-reduced {Q}-learning is minimax optimal"
      },
      {
        "key": "jin2024truncated",
        "author": "Jin, Yujia and Karmarkar, Ishani and Sidford, Aaron and Wang, Jiayi",
        "title": "Truncated Variance Reduced Value Iteration"
      }
    ]
  },
  {
    "index": 14,
    "papers": [
      {
        "key": "wang2017primal",
        "author": "Wang, Mengdi",
        "title": "Primal-Dual $\\pi$ Learning: Sample Complexity and Sublinear Run Time for Ergodic {M}arkov Decision Problems"
      }
    ]
  },
  {
    "index": 15,
    "papers": [
      {
        "key": "jin2020efficiently",
        "author": "Jin, Yujia and Sidford, Aaron",
        "title": "Efficiently solving {MDP}s with stochastic mirror descent"
      }
    ]
  },
  {
    "index": 16,
    "papers": [
      {
        "key": "li2024stochastic",
        "author": "Li, Tianjiao and Wu, Feiyang and Lan, Guanghui",
        "title": "Stochastic first-order methods for average-reward {M}arkov decision processes"
      }
    ]
  },
  {
    "index": 17,
    "papers": [
      {
        "key": "zhang2023sharper",
        "author": "Zhang, Zihan and Xie, Qiaomin",
        "title": "Sharper model-free reinforcement learning for average-reward {M}arkov decision processes"
      }
    ]
  },
  {
    "index": 18,
    "papers": [
      {
        "key": "jin2021towards",
        "author": "Jin, Yujia and Sidford, Aaron",
        "title": "Towards tight bounds on the sample complexity of average-reward {MDP}s"
      }
    ]
  },
  {
    "index": 19,
    "papers": [
      {
        "key": "wang2022near",
        "author": "Wang, Jinghan and Wang, Mengdi and Yang, Lin F",
        "title": "Near sample-optimal reduction-based policy learning for average reward {MDP}"
      }
    ]
  },
  {
    "index": 20,
    "papers": [
      {
        "key": "jin2024feasible",
        "author": "Jin, Ying and Gummadi, Ramki and Zhou, Zhengyuan and Blanchet, Jose",
        "title": "Feasible {Q}-Learning for Average Reward Reinforcement Learning"
      }
    ]
  },
  {
    "index": 21,
    "papers": [
      {
        "key": "neu2024dealing",
        "author": "Neu, Gergely and Okolo, Nneka",
        "title": "Dealing with unbounded gradients in stochastic saddle-point optimization"
      }
    ]
  },
  {
    "index": 22,
    "papers": [
      {
        "key": "bellman1957markovian",
        "author": "Bellman, Richard",
        "title": "A {M}arkovian decision process"
      }
    ]
  },
  {
    "index": 23,
    "papers": [
      {
        "key": "Sutton1988",
        "author": "Sutton, Richard S",
        "title": "Learning to predict by the methods of temporal differences"
      }
    ]
  },
  {
    "index": 24,
    "papers": [
      {
        "key": "Ernst05",
        "author": "Ernst, D. and Geurts, P. and Wehenkel, L.",
        "title": "Tree-based batch mode reinforcement learning"
      },
      {
        "key": "Munos08JMLR",
        "author": "Munos, R. and Szepesv{\\'a}ri, C.",
        "title": "Finite-Time Bounds for Fitted Value Iteration"
      }
    ]
  },
  {
    "index": 25,
    "papers": [
      {
        "key": "MnihKavukcuogluSilveretal2015",
        "author": "Mnih, V. and Kavukcuoglu, K. and Silver, D. and Rusu, A. A. and et al.",
        "title": "Human-level control through deep reinforcement learning"
      }
    ]
  },
  {
    "index": 26,
    "papers": [
      {
        "key": "Bertsekas96",
        "author": "Bertsekas, D. P. and Tsitsiklis, J. N.",
        "title": "Neuro-Dynamic Programming"
      },
      {
        "key": "sutton2018reinforcement",
        "author": "Sutton, Richard S and Barto, Andrew G",
        "title": "Reinforcement Learning: An introduction"
      },
      {
        "key": "SzepesvariBook10",
        "author": "Szepesv\\'ari, {\\relax C}.",
        "title": "Algorithms for Reinforcement Learning"
      }
    ]
  },
  {
    "index": 27,
    "papers": [
      {
        "key": "rosenberg2021oracle",
        "author": "Rosenberg, Aviv and Mansour, Yishay",
        "title": "Oracle-efficient regret minimization in factored {MDP}s with unknown structure"
      }
    ]
  },
  {
    "index": 28,
    "papers": [
      {
        "key": "kumarefficient",
        "author": "Kumar, Navdeep and Wang, Kaixin and Levy, Kfir Yehuda and Mannor, Shie",
        "title": "Efficient Value Iteration for s-rectangular Robust {M}arkov Decision Processes"
      }
    ]
  },
  {
    "index": 29,
    "papers": [
      {
        "key": "bourel2023exploration",
        "author": "Bourel, Hippolyte and Jonsson, Anders and Maillard, Odalric-Ambrym and Talebi, Mohammad Sadegh",
        "title": "Exploration in reward machines with low regret"
      }
    ]
  },
  {
    "index": 30,
    "papers": [
      {
        "key": "fruit2017regret",
        "author": "Fruit, Ronan and Pirotta, Matteo and Lazaric, Alessandro and Brunskill, Emma",
        "title": "Regret minimization in {MDP}s with options without prior knowledge"
      }
    ]
  },
  {
    "index": 31,
    "papers": [
      {
        "key": "sidford2023variance",
        "author": "Sidford, Aaron and Wang, Mengdi and Wu, Xian and Ye, Yinyu",
        "title": "Variance reduced value iteration and faster algorithms for solving {M}arkov decision processes"
      },
      {
        "key": "sidford2018near",
        "author": "Sidford, Aaron and Wang, Mengdi and Wu, Xian and Yang, Lin and Ye, Yinyu",
        "title": "Near-optimal time and sample complexities for solving {M}arkov decision processes with a generative model"
      }
    ]
  },
  {
    "index": 32,
    "papers": [
      {
        "key": "wainwright2019variance",
        "author": "Wainwright, Martin J",
        "title": "Variance-reduced {Q}-learning is minimax optimal"
      }
    ]
  },
  {
    "index": 33,
    "papers": [
      {
        "key": "johnson2013accelerating",
        "author": "Johnson, Rie and Zhang, Tong",
        "title": "Accelerating stochastic gradient descent using predictive variance reduction"
      }
    ]
  },
  {
    "index": 34,
    "papers": [
      {
        "key": "jin2024truncated",
        "author": "Jin, Yujia and Karmarkar, Ishani and Sidford, Aaron and Wang, Jiayi",
        "title": "Truncated Variance Reduced Value Iteration"
      }
    ]
  },
  {
    "index": 35,
    "papers": [
      {
        "key": "nguyen2017sarah",
        "author": "Nguyen, Lam M and Liu, Jie and Scheinberg, Katya and Tak{\\'a}{\\v{c}}, Martin",
        "title": "SARAH: A novel method for machine learning problems using stochastic recursive gradient"
      }
    ]
  },
  {
    "index": 36,
    "papers": [
      {
        "key": "halpern1967fixed",
        "author": "Halpern, Benjamin",
        "title": "Fixed points of nonexpanding maps"
      }
    ]
  },
  {
    "index": 37,
    "papers": [
      {
        "key": "halpern1967fixed",
        "author": "Halpern, Benjamin",
        "title": "Fixed points of nonexpanding maps"
      },
      {
        "key": "sabach2017first",
        "author": "Sabach, Shoham and Shtern, Shimrit",
        "title": "A first order method for solving convex bilevel optimization problems"
      },
      {
        "key": "Lieder2021halpern",
        "author": "Felix Lieder",
        "title": "On the convergence rate of the {H}alpern-iteration"
      },
      {
        "key": "park2022exact",
        "author": "Park, Jisun and Ryu, Ernest K",
        "title": "Exact optimal accelerated complexity for fixed-point iterations"
      },
      {
        "key": "contreras2022optimal",
        "author": "Contreras, Juan Pablo and Cominetti, Roberto",
        "title": "Optimal error bounds for non-expansive fixed-point iterations in normed spaces"
      },
      {
        "key": "yoon2021accelerated",
        "author": "Yoon, TaeHo and Ryu, Ernest K",
        "title": "Accelerated algorithms for smooth convex-concave minimax problems with $\\mathcal{O}(1/k^2)$ rate on squared gradient norm"
      },
      {
        "key": "cai2022stochastic",
        "author": "Cai, Xufeng and Song, Chaobing and Guzm{\\'a}n, Crist{\\'o}bal and Diakonikolas, Jelena",
        "title": "Stochastic {H}alpern iteration with variance reduction for stochastic monotone inclusions"
      }
    ]
  },
  {
    "index": 38,
    "papers": [
      {
        "key": "lee2024accelerating",
        "author": "Lee, Jongmin and Ryu, Ernest",
        "title": "Accelerating value iteration with anchoring"
      },
      {
        "key": "lee2025multi",
        "author": "Lee, Jongmin and Ryu, Ernest",
        "title": "Optimal non-asymptotic rates of value iteration for average-reward {MDP}s"
      }
    ]
  },
  {
    "index": 39,
    "papers": [
      {
        "key": "bravostochastic",
        "author": "Bravo, Mario and Contreras, Juan Pablo",
        "title": "Stochastic {H}alpern iteration in normed spaces and applications to reinforcement learning"
      }
    ]
  },
  {
    "index": 40,
    "papers": [
      {
        "key": "wittmann1992approximation",
        "author": "Wittmann, Rainer",
        "title": "Approximation of fixed points of nonexpansive mappings"
      }
    ]
  },
  {
    "index": 41,
    "papers": [
      {
        "key": "reich1980strong",
        "author": "Reich, Simeon",
        "title": "Strong convergence theorems for resolvents of accretive operators in {B}anach spaces"
      },
      {
        "key": "xu2002iterative",
        "author": "Xu, Hong-Kun",
        "title": "Iterative algorithms for nonlinear operators"
      }
    ]
  },
  {
    "index": 42,
    "papers": [
      {
        "key": "sabach2017first",
        "author": "Sabach, Shoham and Shtern, Shimrit",
        "title": "A first order method for solving convex bilevel optimization problems"
      }
    ]
  },
  {
    "index": 43,
    "papers": [
      {
        "key": "Lieder2021halpern",
        "author": "Felix Lieder",
        "title": "On the convergence rate of the {H}alpern-iteration"
      },
      {
        "key": "kim2021accelerated",
        "author": "Kim, Donghwan",
        "title": "Accelerated proximal point method for maximally monotone operators"
      }
    ]
  },
  {
    "index": 44,
    "papers": [
      {
        "key": "contreras2022optimal",
        "author": "Contreras, Juan Pablo and Cominetti, Roberto",
        "title": "Optimal error bounds for non-expansive fixed-point iterations in normed spaces"
      }
    ]
  }
]