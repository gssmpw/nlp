\clearpage
\setcounter{page}{1}
\maketitlesupplementary
 
 
 

 
\noindent This supplementary document is organized as follows:


--\ Section~\ref{sec:RD_noise} provides the rate-distortion (RD) performance of the Gaussian noise degradation setting, where the results are evaluated with MS-SSIM versus BPP. 

--\ Section~\ref{supp_sec:ab} includes the ablation studies that investigate the number of groups in C-GA, and the effectiveness of the adopted training scheme.
 
--\ Section~\ref{supp_sec:figs} provides more qualitative comparisons on the weather degradation setting and Gaussian noise setting, including synthetic realistic weather-degraded images (Section~\ref{supp:syn}), realistic weather-degraded images (Section~\ref{supp:real}), Gaussian noise-degraded images (Section~\ref{supp:noise}) and clean images (Section~\ref{supp:clean}).  
 

--\ Section~\ref{supp_sec:ablation} investigates the performance of cascaded solutions regarding the sequence of image restoration and image compression.
  
 

  --\ Section~\ref{supp_sec:real_apply} provides results of multiple downstream tasks to demonstrate the potential of the proposed method in real-world applications.


--\ Section~\ref{supp_sec:exp} provides details of the experimental settings, including the detailed configurations of network architecture (Section~\ref{supp_sec:network}), an overview of the adopted datasets (Section~\ref{supp_sec:dataset}) and the training details (Section~\ref{supp:train_detail}). 
 

 



\section{Rate-Distortion Performance}\label{sec:RD_noise} 
\noindent \textbf{Gaussian noise degradation setting.} The RD performance on the noisy Kodak dataset~\cite{kodak1993kodak} is reported in Figure~\ref{supp_fig:RD}, where the inputs are degraded by both seen (\ie, $\sigma=15,25,50$) and unseen  (\ie, $\sigma=35,45,55$) Gaussian noise.  We evaluate the RD performance with MS-SSIM versus BPP. As shown in Figure~\ref{supp_fig:RD}, Ours-L shows superiority over all compared methods at all noise levels, while containing much lower model complexity and higher inference speed than the cascaded solutions (as outlined in Sec.~\ref{sec:speed}\footnote{To differentiate from this supplementary material, we use abbreviations to denote sections, tables, and figures in the paper (\ie, ``Sec." for sections, ``Tab." for tables, and ``Fig." for figures).}). Moreover, despite the joint EVC*  showing competitive performance at lower noise levels, its performance drops significantly with the increase in noise levels. Ours-S surpasses the joint EVC* by a large margin and achieves comparable performance with the well-preformed AirNet+EVC, while providing a 7.15$\times$ speedup and requiring only 10.91\% of the FLOPs. These results highlight the superior performance and generalization ability of the proposed method.


\begin{figure}[t]
\centering
\includegraphics[width=1\linewidth, clip=true, trim=4pt 20pt 0 10pt]{fig_evc/ablation_ng_pro.pdf}\vspace{-2pt}
\caption{(a) Ablation study on the number of groups $N_g$ in C-GA. (b) Ablation study on the effectiveness of progressive training strategy.} 
\label{supp_fig:ablation}
\end{figure}


\begin{figure*}[t]
 \centering
\includegraphics[width=0.96\linewidth]{fig_evc/RD_noise_tr_evc_ssim.pdf}\vspace{-4pt}
\caption{RD performance evaluation on the Kodak dataset~\cite{kodak1993kodak}, where inputs are corrupted by known levels (\ie, 15, 25 and 50) and unknown levels (\ie, 35, 45 and 55) of Gaussian noise. We evaluate the results with MS-SSIM. }   
\label{supp_fig:RD}
\end{figure*}



\section{Ablation Studies}\label{supp_sec:ab}
We construct a baseline model with the number of groups $N_g=4$ in Sec.~\ref{ablation}. In this section, we investigate the rationality of such a configuration, and further demonstrate the effectiveness of the adopted progressive training strategy. All ablation studies are conducted with Ours-S on the weather degradation setting, and evaluated on the RESIDE dataset~\cite{reside}.


\noindent \textbf{Number of groups in C-GA.}   To identify the optimal configuration regarding the number of groups $N_g$, we assign various values (\ie, 1, 2, 4, 8, 16 and 32) to $N_g$, then apply the specified $N_g$ to all C-GA layers in the encoder and decoder across 4 stages. The RD performance comparison is reported in Figure~\ref{supp_fig:ablation}(a). As can be seen, the configuration of $N_g=4$ (depicted as the green curve) achieves the best RD performance. Therefore, we adopt the configuration of $N_g=4$ in the proposed method.
 
  \noindent  \textbf{Effectiveness of progressive training strategy. } 
 To evaluate the effectiveness of the progressive training strategy, we remove it and train the network for the same number of iterations (denoted as w/o Progressive). As shown by the blue curve in Figure~\ref{supp_fig:ablation}(b),  discarding the progressive training strategy results in a noticeable performance drop compared with the original design (green curve). 



\section{Qualitative Comparisons}\label{supp_sec:figs} 
\subsection{Synthetic Weather-degraded Images}\label{supp:syn}
We provide qualitative comparisons on \textit{synthetic} hazy, snowy and rainy images in Figure~\ref{fig:haze}, Figure~\ref{fig:snow} and Figure~\ref{fig:rain}, respectively. For each image, we provide the quantitative metrics of BPP, PSNR and MS-SSIM. As shown in Figure~\ref{fig:haze}, cascaded solutions and the joint EVC* cannot fully rectify degradations and are likely to introduce color bias for the hazy inputs, such as the buildings in the 1st row. For the snowy results shown in Figure~\ref{fig:snow}, cascaded solutions and joint EVC* fail to effectively eliminate the degradations and may introduce artifacts for degraded regions (\eg, the ground region occluded by snow in the 1st row), while the joint EVC* additionally introduces noise. For rainy results depicted in Figure~\ref{fig:rain}, cascaded methods struggle to distinguish the image content from rain streaks, which results in the loss of valid textures and blur, such as the roof in the 2nd row. The joint EVC* fails in removing the rain streaks and further introduces visually unpleasant noise (\eg, the box in the 4th row). In contrast, our method effectively removes degradation and keeps accurate details with lower bit rates.





 \subsection{Realistic Weather-degraded Images}\label{supp:real}
We provide more qualitative comparisons on \textit{realistic} hazy, snowy and rainy images in Figure~\ref{fig:real_haze}, Figure~\ref{fig:real_snow} and Figure~\ref{fig:real_rain}, respectively. As can be seen from Figure~\ref{fig:real_haze}, the joint EVC* and most cascaded methods struggle in generalizing to realistic hazy images, and may even introduce artifacts (\eg, the results of SwinIR+EVC). Although the cascaded Restormer+EVC successfully eliminates the haze degradation, the results exhibit unnatural contrast and brightness (\eg, the door in the 2nd row). In the snowy scenario depicted in Figure~\ref{fig:real_snow}, the joint EVC* introduces additional noise and spends extra bits to preserve the degradations. In contrast, our method improves the contrast and effectively eliminates visible snow (\eg, the building in the 1st row), thus outperforming the compared solutions. For the rainy images in Figure~\ref{fig:real_rain}, the joint EVC* introduces texture distortion, while most cascaded methods fail to remove rain streaks (\eg, the rainy case in the 1st row), and may amplify artifacts in the process of cascaded image restoration and compression (\eg, the wall in the 2nd row). Despite SwinIR+EVC performing well in eliminating rain streaks, it removes valid image structures, such as the corner in the 1st case. In contrast, our method effectively removes rain streaks and preserves the background with lower bit rates.

 


 

 

\begin{figure*}[t]
% \centering
\hspace*{-4pt}\includegraphics[width=1.02\linewidth]{fig_evc/hazy_0003_evc.pdf}\vspace{-2pt}
\hspace*{-4pt}\includegraphics[width=1.02\linewidth]{fig_evc/hazy_1949_evc.pdf}\vspace{-2pt}
\hspace*{-4pt}\includegraphics[width=1.02\linewidth]{fig_evc/hazy_126_evc.pdf}\vspace{-2pt}
\hspace*{-4pt}\includegraphics[width=1.02\linewidth]{fig_evc/hazy_1947_evc.pdf}\vspace{-0.15in}
\caption{Qualitative comparisons on \textit{synthetic} hazy images, where cascaded solutions are denoted referred to as \textit{restoration + compression}, and Ours denotes the results of Ours-L. For each image, we include metrics of \orange{BPP}/\blue{PSNR}/\purple{MS-SSIM}. }   \vspace{-4pt}
\label{fig:haze}
\end{figure*}
 
 
\begin{figure*}[t]
\hspace*{-4pt}\includegraphics[width=1.02\linewidth]{fig_evc/snow_138_evc.pdf}\vspace{-2pt}
\hspace*{-4pt}\includegraphics[width=1.02\linewidth]{fig_evc/snow_175_evc.pdf}\vspace{-2pt}
\hspace*{-4pt}\includegraphics[width=1.02\linewidth]{fig_evc/snow_1972_evc.pdf} \vspace{-2pt}
\hspace*{-4pt}\includegraphics[width=1.02\linewidth]{fig_evc/snow_70_evc.pdf}\vspace{-0.12in}
\caption{Qualitative comparisons on \textit{synthetic} snowy images, where cascaded solutions are referred to as \textit{restoration + compression}, and Ours denotes the results of Ours-L. For each image, we include metrics of \orange{BPP}/\blue{PSNR}/\purple{MS-SSIM}. } \vspace{-0.11in}
\label{fig:snow}  
\end{figure*}

\begin{figure*}[t]
% \centering
\hspace*{-4pt}\includegraphics[width=1.02\linewidth]{fig_evc/rain_969_5_evc.pdf}\vspace{-2pt}
\hspace*{-4pt}\includegraphics[width=1.02\linewidth]{fig_evc/rain_918_9_evc.pdf}\vspace{-2pt}
\hspace*{-4pt}\includegraphics[width=1.02\linewidth]{fig_evc/rain_921_10_evc.pdf}\vspace{-2pt}
\hspace*{-4pt}\includegraphics[width=1.02\linewidth]{fig_evc/rain_940_14_evc.pdf}\vspace{-0.15in}
\caption{Qualitative comparisons on \textit{synthetic} rainy images, where cascaded solutions are referred to as \textit{restoration + compression}, and Ours denotes the results of Ours-L. For each image, we include metrics of \orange{BPP}/\blue{PSNR}/\purple{MS-SSIM}. }  \vspace{-0.1in}
\label{fig:rain}
\end{figure*}



 

 \begin{figure}[t]
\centering
\includegraphics[width=0.75\linewidth, clip=true, trim=10pt 2pt 50pt 40pt]{fig_evc/sequence_psnr.pdf}\vspace{-4pt}
\caption{Discussion regarding the sequence of image restoration and compression, where Restor. and Compres. denote restoration and compression, respectively. We evaluate the RD performance with PSNR.}  \vspace{-0.1in}
\label{fig:order}
\end{figure}

\subsection{Gaussian Noisy Images}\label{supp:noise}
Qualitative results of the Gaussian noise degradation setting are shown in Figure~\ref{supp_fig:visual_noise_sgm15}, where the noise level is set to $\sigma=15$. As can be seen, although the cascaded methods seem to keep plausible textures, these textures are unreal and distorted (\eg, the hair in the 1st row).  Meanwhile, the joint EVC* and cascaded solutions tend to introduce over-smoothness (\eg, the window in the 2nd row), leading to the loss of textures and details. The proposed method effectively eliminates noise degradation and preserves details, demonstrating its ability to handle various levels of noise and finer details with a unified framework.


 \begin{figure}[t]
 \centering
\includegraphics[width=0.9\linewidth]{fig_evc/clean_kodak02.pdf}\vspace{-4pt}
\includegraphics[width=0.9\linewidth]{fig_evc/clean_kodak07.pdf}\vspace{-4pt}
\includegraphics[width=0.9\linewidth]{fig_evc/clean_kodak04.pdf}\vspace{-4pt}
\includegraphics[width=0.9\linewidth]{fig_evc/clean_kodak21.pdf}\vspace{-4pt}
\includegraphics[width=0.9\linewidth]{fig_evc/clean_kodak06.pdf}\vspace{-0.15in} 
\caption{Qualitative comparisons on clean images, where metrics of \orange{BPP}/\blue{PSNR}/\purple{MS-SSIM} are reported for each image.}  \vspace{-0.05in}
\label{supp_fig:visual_clean}
\end{figure}

\subsection{Clean Images} \label{supp:clean}
We provide qualitative comparisons on clean images in Figure~\ref{supp_fig:visual_clean}.  As can be seen, despite the proposed method showing a slight drop in quantitative performance compared to the clean-image-specific EVC (Fig.~\ref{fig:clean}), the visual differences are negligible (\eg, the door and flower). When dealing with intricate details, the proposed method even provides more visually pleasing results (\eg, the hair in the 3rd row). However, in challenging scenarios, such as the water ripples in the 4th row, both EVC and our method struggle to deliver high-fidelity results, which occasionally leads to a loss of texture in other regions (\eg, the sky in the last row), since most of the bits are spent to preserve the details of water surface.  









 

\begin{figure*}[t]
\centering
\includegraphics[width=1\linewidth]{fig_evc/real_hazy_23_evc.pdf}\vspace{-3pt}
\includegraphics[width=1\linewidth]{fig_evc/real_hazy_35_evc.pdf}\vspace{-3pt}
\includegraphics[width=1\linewidth]{fig_evc/real_hazy_52_evc.pdf}\vspace{-0.15in}
% \includegraphics[width=1\linewidth]{fig_evc/real_hazy_52v2_crop.pdf}
\caption{Qualitative comparisons on \textit{realistic} hazy images, where cascaded solutions are denoted referred to as \textit{restoration + compression}, and Ours denotes the results of Ours-L. We include BPP for each image.
}\vspace{-0.1in}
\label{fig:real_haze}
\end{figure*}

\begin{figure*}[t]
\centering
\includegraphics[width=1\linewidth]{fig_evc/real_snow_winter_street_09064_evc.pdf}\vspace{-3pt}
\includegraphics[width=1\linewidth]{fig_evc/real_snow_snow_walk_00111_evc.pdf}\vspace{-3pt}
\includegraphics[width=1\linewidth]{fig_evc/real_snow_snow_nature_1_103668_evc.pdf}\vspace{-0.15in}
\caption{Qualitative comparisons on \textit{realistic} snowy images, where cascaded solutions are denoted referred to as \textit{restoration + compression}, and Ours denotes the results of Ours-L. We include BPP for each image.}\vspace{-0.14in}
\label{fig:real_snow}
\end{figure*}


\begin{figure*}[t]
\centering
\includegraphics[width=1\linewidth]{fig_evc/real_rain_328_evc.pdf}\vspace{-2pt}
\includegraphics[width=1\linewidth]{fig_evc/real_rain_126_evc.pdf}\vspace{-2pt}
\includegraphics[width=1\linewidth]{fig_evc/real_rain_292_evc.pdf}\vspace{-0.16in}
\caption{Qualitative comparisons on \textit{realistic} rainy images, where cascaded solutions are denoted referred to as \textit{restoration + compression}, and Ours denotes the results of Ours-L. We include BPP for each image. } \vspace{-0.05in}  
\label{fig:real_rain}
\end{figure*}
 
 
 \begin{figure*}[t]
 \centering
\includegraphics[width=1\linewidth]{fig_evc/noise_sgm15_k04_evc.pdf}\vspace{-2pt}
\includegraphics[width=1\linewidth]{fig_evc/noise_sgm15_k07_evc.pdf}\vspace{-2pt}
\includegraphics[width=1\linewidth]{fig_evc/noise_sgm15_k14_evc.pdf}\vspace{-0.15in} 
\caption{Qualitative comparisons on Gaussian noise-degraded images, where the noise level of input is set to $\sigma=15$. Results of cascaded solutions are denoted as \textit{restoration+compression}. We report metrics of \orange{BPP}/\blue{PSNR}/\purple{MS-SSIM} for each image.}  \vspace{-0.05in}
\label{supp_fig:visual_noise_sgm15}
\end{figure*}





\vspace{-10pt}\section{Sequence of Cascaded Solutions}\label{supp_sec:ablation} \vspace{-8pt}
 For the cascaded solutions, we further discuss the sequence of image restoration and image compression, denoted as \textit{restoration+compression} and \textit{compression+restoration}, respectively. We adopt Restormer~\cite{restormer} and EVC~\cite{evc} for image restoration and image compression, respectively.   The performance of EVC~\cite{evc} on degraded images (denoted as \textit{compression only}) is provided for reference. As illustrated in Figure~\ref{fig:order}, \textit{compression only} underperforms on degraded images due to its tendency to faithfully preserve degraded inputs. Compared with the \textit{restoration+compression},  \textit{compression+restoration} yields inferior rate-distortion performance, which may result from the degradation mismatch between the compressed results and the subsequent image restoration model. The sequence of \textit{restoration+compression} shows an overall promising performance in improving the quality of inputs and reducing the size of images. Therefore, we compare our models with the \textit{restoration+compression} solution in Sec.~\ref{sec:rd_per}.

 


 

 
  
\begin{table}[t]
% \begin{wraptable}{l}{0.58\linewidth}
\resizebox{1\linewidth}{!}{
\Large
\begin{tabular}{c|c|c|c|c|c}
\toprule
Method  & EVC & Restormer+EVC & AirNet+EVC & Ours-S & Ours-L    \\
\midrule
\rowcolor{pink} mAP $\uparrow$ & 43.21 &	52.15 &	\uline{54.02} & 53.93  & \textbf{54.93}   \\
\rowcolor{pink} Recall $\uparrow$& 0.44	& 0.51&	0.51 & \uline{0.52} &  \textbf{0.54}  	\\
\midrule
\rowcolor{yellow} $\delta_1$ $\uparrow$ & 0.859 & 0.880 & 0.879 & \uline{0.936} & \textbf{0.939} \\
\rowcolor{yellow}AbsRel $\downarrow$ & 0.132 &	0.131 & 0.125 & \uline{0.087} & \textbf{0.083}\\
\rowcolor{yellow}RMSE $\downarrow$ & 0.540 & 0.371 & 0.383 & \uline{0.302} & \textbf{0.292} \\
\bottomrule
\end{tabular} 
}\vspace{-4pt}
  \caption{Results on the task of \sethlcolor{pink}\hl{OD} and \sethlcolor{yellow}\hl{MDE}, where the best and second best results are highlighted with \textbf{bold} and \uline{underline}. }\vspace{-0.13in}
\label{tab:dection}
% \end{minipage}
% \end{wraptable}
\end{table}


  
\section{Real-world Applications} \label{supp_sec:real_apply} 
In this section, we devote the compressed results to multiple downstream tasks, \ie, Object Detection (OD) and Monocular Depth Estimation (MDE), to evaluate the potential of the proposed method in real applications (\eg, autonomous driving). We adopt the pre-trained Swin Transformer~\cite{swin} for \sethlcolor{pink}\hl{Object Detection (OD)}  and Depth Anything~\cite{yang2024depth} for \sethlcolor{yellow}\hl{Monocular Depth Estimation (MDE)} on the compressed results of RESIDE dataset~\cite{reside}.  To demonstrate the improvement introduced by compared methods and the proposed method, we provide the results of EVC~\cite{evc} (tailored for clean images) as a reference. We compare with the well-performing cascaded solutions Restormer+EVC and AirNet+EVC. As shown in Table~\ref{tab:dection}, the proposed Ours-L introduces superior improvement over other methods, while Ours-S also achieves competitive performance and surpasses almost all the cascaded methods. The significant improvement over EVC and cascaded methods shows the effectiveness of our method in improving the performance of OD and MDE on degraded images, demonstrating its potential for practical scenarios. 



\section{Experimental Settings}\label{supp_sec:exp}  
\subsection{Network Architecture}\label{supp_sec:network} 
Each stage in the encoder and decoder consists of 4 hybrid-attention transformer blocks.  The number of groups $N_g$ in channel-wise group attention (C-GA) is set to 4. For the spatially decoupled attention (S-DA), we set the kernel sizes $K_v$ and $K_h$ of depth-wise convolution to 5.   For the entropy model, we adopt the dual spatial prior configuration\cite{mm}. In the comparison of attention variants, to keep similar computational complexity, we set the number of MDTA and SWTA to 2-3-3-4 and 1-1-1-1 across the four stages, respectively. 


\subsection{Dataset}\label{supp_sec:dataset}  
\noindent \textbf{Weather degradation setting.}
This setting includes weather-related degradations, \ie, haze, snow and rain.  For the synthetic images,  the Rain1400 dataset~\cite{rain1400}  contains 12,600 pairs of rainy-clean images for training and 1,400 for testing, with rain streaks of different levels included. The RESIDE dataset~\cite{reside}  comprises the ITS dataset (72,135 images) for training and the OTS dataset (500 images) for testing. The CSD dataset~\cite{csd}  includes 8,000 snowy images for training and 2,000 images for testing.  By convention~\cite{chen2022learning,park2023all}, we randomly select 5,000 images from each dataset, and merge them for training.  Testing splits of these datasets are adopted for quantitative and qualitative evaluation.   For the realistic images, six indoor scenes from the REVIDE dataset~\cite{REVIDE} (with four different styles) are used for evaluation.  Snow100K~\cite{snow100k} offers 1,329 realistic snowy images for evaluation, which differs a lot from the synthetic snowy scenario.  Based on SPA~\cite{wang2019spatial}, SPA+~\cite{wgwsnet} removes images with repetitive backgrounds and further densifies the rain streaks.


 
\noindent \textbf{Gaussian noise degradation setting.}
We adopt the testing split of Open  Images~\cite{krasin2017openimages} for training, which consists of 125,436 high-quality images. The Kodak~\cite{kodak1993kodak} dataset provides 24 high-quality images for evaluation.

 

  \subsection{Training Details.}\label{supp:train_detail} 
During training,  to guarantee the versatility of the proposed method for both clean and degraded images, we randomly select clean images as input with a probability of 0.2.  For each input image, it is randomly augmented with cropping, horizontal flip, and vertical flip.  We adopt the Adam optimizer~\cite{kingma2014adam} with $\beta1=0.9$, $\beta2=0.999$. The initial learning rate is set to $1\times10^{-4}$ and adjusted with the Cosine Annealing scheme~\cite{sgdr}.  For the progressive training strategy, we train the network with the patch size of 256, 320 and 384 for 250K, 100K and 50K iterations, respectively. To conduct a fast evaluation in the ablation studies, the baseline model that investigates the number of channels $N_g$, the experiment that verifies the effectiveness of S-DA, the model disposing of spatial decoupling design, and the models composed by different attention variants are trained for 300K iterations.  To investigate the effectiveness of the progressive training strategy, we train the complete model for 400K iterations under the conditions of with and without the progressive training strategy.


 
  

