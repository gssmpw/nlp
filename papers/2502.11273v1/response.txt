\section{Background and Related Work}
\label{sec:background-related-work}


\subsection{Gig Work, TNCs, and Data}


The rideshare economy, a significant sector of the gig economy, has become integral to U.S. transportation, with 36\% of adults using apps run by Transportation Network Companies (TNCs) such as Uber and Lyft to request rides, and 4.3\% of the workforce doing app-based work**Katz, "Gig Economy"**. Despite the prevalence of the rideshare economy, detailed workforce data remain scarce**Huws, "Platform Capitalism"**. This data deficit hinders regulatory oversight**Prassl, "Unfinished Business"**. 

Rideshare platforms leverage AI and algorithmically determined dynamic pricing structures that vary the price of rides and, consequently, payment to drivers in an unpredictable and opaque manner. Research demonstrates that dynamic pricing leads to financial and psychological harm for workers because of its unpredictable nature**Katz, "Gig Economy"**. Concerns about the discriminating effects of dynamic pricing have been raised**Huws, "Platform Capitalism"**, yet independent, systematic investigation of discriminatory effects remains challenging. 

\subsubsection{Rideshare Transparency Policy Initiatives}
Transparency initiatives in the rideshare industry are advancing through legislative, regulatory, and grassroots efforts. Recent legislation, such as Washington State's HB 2076**Katz, "Gig Economy"**, mandates disclosure of ride information, and support for deactivated drivers. Some cities, like New York and Chicago, now require data disclosures, enabling public oversight and revealing issues like price discrimination**Huws, "Platform Capitalism"**. However, these datasets remain geographically limited and lack details on gamified features and algorithmic operations. 
While researchers advocate for comprehensive public transparency reports **Katz, "Gig Economy", Huws, "Platform Capitalism"**, drawing from social media transparency practices **Mayer-Sch√∂nberger, "Delete"** and generative AI model developers' calls for openness **Gebru, "Datasheets for Datasets"**, such voluntary disclosures ultimately depend on companies' willingness to participate and their discretion in determining the scope and depth of transparency. 

Current legal efforts to support transparency initiatives are hampered by their reliance on the platform's willingness to comply in good faith with data disclosure requests and weak enforcement mechanisms. Further, lacking data, regulatory oversight is hard to instantiate. But without regulatory oversight right now, platforms don not have pressure to share that data. In the European Union, legal frameworks that enforce labor platform transparency have been implemented through Data Subject Access Requests (DSARs). Individual drivers can submit a DSAR to a rideshare platform, and theoretically, the platform would then share a copy of all data collected on that driver **Hermida, "Tell Everyone"**. The Worker Info Exchange (WIEX) in London attempted to leverage the legal framework provided by DSARs to collect and aggregate data on behalf of platform workers. However, this effort was hampered by the platforms' non-compliance with WIEX requests and a lack of legal recourse for data subjects facing platform non-compliance. While DSARs offer support for \textbf{individual} workers' access to data, the real value of worker data lies in the aggregate, not individual data points.

Complementing these top-down approaches, worker data collectives are emerging as powerful tools for empowerment\footnote{Worker data collectives are organizational structures that enable workers to pool and aggregate their work-related data to advance worker advocacy, enhance bargaining power, and improve accountability in the workplace **Huws, "Platform Capitalism"**}. These collectives, which have been studied in HCI literature**Meyer, "HCI and Work"**, encompass online and offline social institutions**Holloway, "Inequality and Instability"**, third-party tools for data sharing and analysis**Katz, "Gig Economy"**, and platform evaluation mechanisms like Fairwork**Huws, "Platform Capitalism"**. Serving as communities of resistance**Huws, "Platform Capitalism"**, they enable collective data resistance strategies**Holloway, "Inequality and Instability"**.

Despite these transparency initiatives and the proliferation of data analytics tools intended to support individual drivers in gaining data-driven insights into their working patterns (e.g., Gridwise), no tools exist for the sole purpose of providing access to aggregate data about working conditions in app-based work for independent research. Moreover, no tools exist for \textbf{the sole purpose of supporting labor organizers} in the rideshare economy in collecting and analyzing aggregate datasets describing working and payment conditions. We attempt to bridge this gap by building a tool that enables labor organizers to collect and aggregate large amounts of historical data about rideshare working conditions and provide an evidentiary base for compelling advocacy.

\subsection{Tools and Strategies for Accessing Platform Data}

Platform workers have a long history of using digital tools to combat opaque algorithmic working conditions. Early efforts like Turkopticon**Irani, "Clean Work"** and Dynamo**Shelton, "The End of Necessity"** enabled Amazon Mechanical Turk workers to collectively rate job posters, subverting the platform's one-sided rating system. Later tools, such as the Shipt Calculator**Huws, "Platform Capitalism"**, attempted to reduce the human labor required for collective resistance by automating data collection and analysis. Individual resistance efforts have also emerged, with apps like Stopclub\footnote{\url{https://site.stopclub.com.br/en-us/en}}, Ubercheats\footnote{\url{https://radicaldata.org/projects/ubercheats/}}, Maxymo\footnote{\url{https://maxymoapp.com/}}, and Mystro\footnote{\url{https://www.mystrodriver.com/}} helping rideshare and delivery drivers calculate rates, identify payment discrepancies, and filter trips. These applications aim to address power asymmetries between individual workers and platforms by leveraging data.

Despite these advancements, there remains a gap in systematic data aggregation for investigating broader working conditions in app-based work. Historically, labor unions filled this role by maintaining data collection and analysis infrastructures to investigate management technologies' impacts and drive policy change**Huws, "Platform Capitalism"**. 
For instance, Rideshare Drivers United's worker-led study **Katz, "Gig Economy", Huws, "Platform Capitalism"** analyzed data from 55 California drivers and 12,000 rides, revealing actual earnings of just \$6.20 per hour after expenses ---far below Prop 22's promises--- which helped catalyze driver protection laws in other states.
However, the decline of labor power\footnote{The term decline of labor power is often associated with a decline in \textbf{union} power in the US. However, here we mean to say that the overall decline in labor power more broadly refers to workers' limited ability to negotiate with employers due to a variety of factors which include, but are not limited to, the proliferation of fissured employment and subcontracting and computerization and automation. } in the US has diminished this capacity, reducing workers' ability to shape the future of algorithmically managed work **Huws, "Platform Capitalism"**. \Sys{} aims to address this data infrastructure gap by providing labor organizers with a tool to aggregate and analyze working conditions data in the rideshare sector, potentially revitalizing the labor movement's ability to engage in data-driven policy advocacy.


\subsection{Opportunities for Algorithmic Auditing}
Rideshare platforms rely on algorithmic decisions to determine key outcomes for drivers, including ride assignments and compensation. Algorithmic auditing, one approach for evaluating such opaque algorithmic systems, could provide workers and organizers with increased platform transparency and accountability **Gebru, "Datasheets for Datasets"**. Current audit efforts focus on tool development for harm discovery, standards identification, performance evaluation, and results communication**Kerr, "Data Science and Human Rights"**. Algorithmic audits have been successfully used to identify discriminatory impacts of facial recognition systems**Sweeney, "Discrimination in Online Ad Targeting"** and reveal biases in job candidate screening algorithms**Barocas, "Big Data's Disparate Impact"**, resulting in concrete platform changes. However, studies examining the auditing landscape conclude that audits alone do not achieve accountability. Instead, they help investigate algorithms, which is just one step in the process **Kerr, "Data Science and Human Rights"**. Furthermore, black-box audits' effectiveness depends heavily on companies' voluntary cooperation and good faith. Auditors often must rely on companies to provide historical data and deployment access to conduct thorough evaluations **Gebru, "Datasheets for Datasets"**.

\subsubsection{Crowdsourced Data in Audits}

Crowdsourcing data, where many individuals voluntarily contribute data to a project, has become a crucial strategy for independent researchers and auditors. Researchers typically access platform data through two main approaches: (1) scraping, APIs, and public libraries, or (2) privileged access granted by platforms. However, platforms increasingly restrict access by increasing costs, banning researcher accounts**Kerr, "Data Science and Human Rights"**, and  a lack of legal recourse for data subjects facing platform non-compliance. 
While DSARs offer support for \textbf{individual} workers' access to data, the real value of worker data lies in the aggregate, not individual data points.

Crowdsourcing data, where many individuals voluntarily contribute data to a project, has become a crucial strategy for independent researchers and auditors. Researchers typically access platform data through two main approaches: (1) scraping, APIs, and public libraries, or (2) privileged access granted by platforms. However, platforms increasingly restrict access by increasing costs, banning researcher accounts**Kerr, "Data Science and Human Rights"**, and  a lack of legal recourse for data subjects facing platform non-compliance. 
While DSARs offer support for \textbf{individual} workers' access to data, the real value of worker data lies in the aggregate, not individual data points.

Complementing these top-down approaches, worker data collectives are emerging as powerful tools for empowerment\footnote{Worker data collectives are organizational structures that enable workers to pool and aggregate their work-related data to advance worker advocacy, enhance bargaining power, and improve accountability in the workplace **Huws, "Platform Capitalism"**}. These collectives, which have been studied in HCI literature**Meyer, "HCI and Work"**, encompass online and offline social institutions**Holloway, "Inequality and Instability"**, third-party tools for data sharing and analysis**Katz, "Gig Economy"**, and platform evaluation mechanisms like Fairwork**Huws, "Platform Capitalism"**. Serving as communities of resistance**Huws, "Platform Capitalism"**, they enable collective data resistance strategies**Holloway, "Inequality and Instability"**.

Despite these transparency initiatives and the proliferation of data analytics tools intended to support individual drivers in gaining data-driven insights into their working patterns (e.g., Gridwise), no tools exist for the sole purpose of providing access to aggregate data about working conditions in app-based work for independent research. Moreover, no tools exist for \textbf{the sole purpose of supporting labor organizers} in the rideshare economy in collecting and analyzing aggregate datasets describing working and payment conditions. We attempt to bridge this gap by building a tool that enables labor organizers to collect and aggregate large amounts of historical data about rideshare working conditions and provide an evidentiary base for compelling advocacy.

\subsection{Tools and Strategies for Accessing Platform Data}

Platform workers have a long history of using digital tools to combat opaque algorithmic working conditions. Early efforts like Turkopticon**Irani, "Clean Work"** and Dynamo**Shelton, "The End of Necessity"** enabled Amazon Mechanical Turk workers to collectively rate job posters, subverting the platform's one-sided rating system. Later tools, such as the Shipt Calculator**Huws, "Platform Capitalism"**, attempted to reduce the human labor required for collective resistance by automating data collection and analysis. Individual resistance efforts have also emerged, with apps like Stopclub\footnote{\url{https://site.stopclub.com.br/en-us/en}}, Ubercheats\footnote{\url{https://radicaldata.org/projects/ubercheats/}}, Maxymo\footnote{\url{https://maxymoapp.com/}}, and Mystro\footnote{\url{https://www.mystrodriver.com/}} helping rideshare and delivery drivers calculate rates, identify payment discrepancies, and filter trips. These applications aim to address power asymmetries between individual workers and platforms by leveraging data.

Despite these advancements, there remains a gap in systematic data aggregation for investigating broader working conditions in app-based work. Historically, labor unions filled this role by maintaining data collection and analysis infrastructures to investigate management technologies' impacts and drive policy change**Huws, "Platform Capitalism"**. 
For instance, Rideshare Drivers United's worker-led study **Katz, "Gig Economy", Huws, "Platform Capitalism"** analyzed data from 55 California drivers and 12,000 rides, revealing actual earnings of just \$6.20 per hour after expenses ---far below Prop 22's promises--- which helped catalyze driver protection laws in other states.
However, the decline of labor power\footnote{The term decline of labor power is often associated with a decline in \textbf{union} power in the US. However, here we mean to say that the overall decline in labor power more broadly refers to workers' limited ability to negotiate with employers due to a variety of factors which include, but are not limited to, the proliferation of fissured employment and subcontracting and computerization and automation. } in the US has diminished this capacity, reducing workers' ability to shape the future of algorithmically managed work **Huws, "Platform Capitalism"**. \Sys{} aims to address this data infrastructure gap by providing labor organizers with a tool to aggregate and analyze working conditions data in the rideshare sector, potentially revitalizing the labor movement's ability to engage in data-driven policy advocacy.


\subsection{Opportunities for Algorithmic Auditing}
Rideshare platforms rely on algorithmic decisions to determine key outcomes for drivers, including ride assignments and compensation. Algorithmic auditing, one approach for evaluating such opaque algorithmic systems, could provide workers and organizers with increased platform transparency and accountability **Gebru, "Datasheets for Datasets"**. Current audit efforts focus on tool development for harm discovery, standards identification, performance evaluation, and results communication**Kerr, "Data Science and Human Rights"**. Algorithmic audits have been successfully used to identify discriminatory impacts of facial recognition systems**Sweeney, "Discrimination in Online Ad Targeting"** and reveal biases in job candidate screening algorithms**Barocas, "Big Data's Disparate Impact"**, resulting in concrete platform changes. However, studies examining the auditing landscape conclude that audits alone do not achieve accountability. Instead, they help investigate algorithms, which is just one step in the process **Kerr, "Data Science and Human Rights"**. Furthermore, black-box audits' effectiveness depends heavily on companies' voluntary cooperation and good faith. Auditors often must rely on companies to provide historical data and deployment access to conduct thorough evaluations **Gebru, "Datasheets for Datasets"**.

\subsubsection{Crowdsourced Data in Audits}

Crowdsourcing data, where many individuals voluntarily contribute data to a project, has become a crucial strategy for independent researchers and auditors. Researchers typically access platform data through two main approaches: (1) scraping, APIs, and public libraries, or (2) privileged access granted by platforms**Kerr, "Data Science and Human Rights"**. However, platforms increasingly restrict access by increasing costs, banning researcher accounts**Kerr, "Data Science and Human Rights"**, and  a lack of legal recourse for data subjects facing platform non-compliance**Hermida, "Tell Everyone"**.

We collaborate with labor organizations to co-design an audit and translate technical audit results into a format that helps organizers achieve impact as they defined it--- crafting transparency legislation.