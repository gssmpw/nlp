\section{Related Work}
Various machine unlearning methods have been proposed for removing knowledge from LLMs~\cite{zhang2024negativepreferenceoptimizationcatastrophic,pawelczyk2023context,chen-yang-2023-unlearn}. However, most of them report results on small sets such as ~\cite{eldan2023whosharrypotterapproximate}. Recently, \cite{maini2024tofu} and \cite{shi2024musemachineunlearningsixway} proposed unlearning benchmarks (with various evaluation metrics), but they carry key limitations we address here. We provide more detailed discussions comparing \textsc{Lume} with these works in Appendix \ref{sec:relatedexpanded}.