@misc{clark2018thinksolvedquestionanswering,
      title={Think you have Solved Question Answering? Try ARC, the AI2 Reasoning Challenge}, 
      author={Peter Clark and Isaac Cowhey and Oren Etzioni and Tushar Khot and Ashish Sabharwal and Carissa Schoenick and Oyvind Tafjord},
      year={2018},
      eprint={1803.05457},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/1803.05457}, 
}

@inproceedings{haddadan-etal-2019-yes,
    title = "Yes, we can! Mining Arguments in 50 Years of {US} Presidential Campaign Debates",
    author = "Haddadan, Shohreh  and
      Cabrio, Elena  and
      Villata, Serena",
    editor = "Korhonen, Anna  and
      Traum, David  and
      M{\`a}rquez, Llu{\'i}s",
    booktitle = "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics",
    month = jul,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/P19-1463/",
    doi = "10.18653/v1/P19-1463",
    pages = "4684--4690",
    abstract = "Political debates offer a rare opportunity for citizens to compare the candidates' positions on the most controversial topics of the campaign. Thus they represent a natural application scenario for Argument Mining. As existing research lacks solid empirical investigation of the typology of argument components in political debates, we fill this gap by proposing an Argument Mining approach to political debates. We address this task in an empirical manner by annotating 39 political debates from the last 50 years of US presidential campaigns, creating a new corpus of 29k argument components, labeled as premises and claims. We then propose two tasks: (1) identifying the argumentative components in such debates, and (2) classifying them as premises and claims. We show that feature-rich SVM learners and Neural Network architectures outperform standard baselines in Argument Mining over such complex data. We release the new corpus USElecDeb60To16 and the accompanying software under free licenses to the research community."
}

@misc{hendrycks2021measuringmassivemultitasklanguage,
      title={Measuring Massive Multitask Language Understanding}, 
      author={Dan Hendrycks and Collin Burns and Steven Basart and Andy Zou and Mantas Mazeika and Dawn Song and Jacob Steinhardt},
      year={2021},
      eprint={2009.03300},
      archivePrefix={arXiv},
      primaryClass={cs.CY},
      url={https://arxiv.org/abs/2009.03300}, 
}

@misc{lee2024ethicevaluatinglargelanguage,
      title={ETHIC: Evaluating Large Language Models on Long-Context Tasks with High Information Coverage}, 
      author={Taewhoo Lee and Chanwoong Yoon and Kyochul Jang and Donghyeon Lee and Minju Song and Hyunjae Kim and Jaewoo Kang},
      year={2024},
      eprint={2410.16848},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2410.16848}, 
}

@misc{lin2022truthfulqameasuringmodelsmimic,
      title={TruthfulQA: Measuring How Models Mimic Human Falsehoods}, 
      author={Stephanie Lin and Jacob Hilton and Owain Evans},
      year={2022},
      eprint={2109.07958},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2109.07958}, 
}

@inproceedings{roush-balaji-2020-debatesum,
    title = "{D}ebate{S}um: A large-scale argument mining and summarization dataset",
    author = "Roush, Allen  and
      Balaji, Arvind",
    editor = "Cabrio, Elena  and
      Villata, Serena",
    booktitle = "Proceedings of the 7th Workshop on Argument Mining",
    month = dec,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2020.argmining-1.1/",
    pages = "1--7",
    abstract = "Prior work in Argument Mining frequently alludes to its potential applications in automatic debating systems. Despite this focus, almost no datasets or models exist which apply natural language processing techniques to problems found within competitive formal debate. To remedy this, we present the DebateSum dataset. DebateSum consists of 187,386 unique pieces of evidence with corresponding argument and extractive summaries. DebateSum was made using data compiled by competitors within the National Speech and Debate Association over a 7year period. We train several transformer summarization models to benchmark summarization performance on DebateSum. We also introduce a set of fasttext word-vectors trained on DebateSum called debate2vec. Finally, we present a search engine for this dataset which is utilized extensively by members of the National Speech and Debate Association today. The DebateSum search engine is available to the public here: \url{http://www.debate.cards}"
}

@misc{ruizdolz2024vivesdebatespeechcorpusspokenargumentation,
      title={VivesDebate-Speech: A Corpus of Spoken Argumentation to Leverage Audio Features for Argument Mining}, 
      author={Ramon Ruiz-Dolz and Javier Iranzo-SÃ¡nchez},
      year={2024},
      eprint={2302.12584},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2302.12584}, 
}

@misc{sakaguchi2019winograndeadversarialwinogradschema,
      title={WinoGrande: An Adversarial Winograd Schema Challenge at Scale}, 
      author={Keisuke Sakaguchi and Ronan Le Bras and Chandra Bhagavatula and Yejin Choi},
      year={2019},
      eprint={1907.10641},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/1907.10641}, 
}

@misc{wang2020supergluestickierbenchmarkgeneralpurpose,
      title={SuperGLUE: A Stickier Benchmark for General-Purpose Language Understanding Systems}, 
      author={Alex Wang and Yada Pruksachatkun and Nikita Nangia and Amanpreet Singh and Julian Michael and Felix Hill and Omer Levy and Samuel R. Bowman},
      year={2020},
      eprint={1905.00537},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/1905.00537}, 
}

@misc{zellers2019hellaswagmachinereallyfinish,
      title={HellaSwag: Can a Machine Really Finish Your Sentence?}, 
      author={Rowan Zellers and Ari Holtzman and Yonatan Bisk and Ali Farhadi and Yejin Choi},
      year={2019},
      eprint={1905.07830},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/1905.07830}, 
}

