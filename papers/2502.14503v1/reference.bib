@inproceedings{BEVDepth,
  title={{BEVDepth: Acquisition of reliable depth for multi-view 3D object detection}},
  author={Li, Yinhao and Ge, Zheng and Yu, Guanyi and Yang, Jinrong and Wang, Zengran and Shi, Yukang and Sun, Jianjian and Li, Zeming},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={37},
  number={2},
  pages={1477--1485},
  year={2023}
}

@ARTICLE{LXL,
  author={Xiong, Weiyi and Liu, Jianan and Huang, Tao and Han, Qing-Long and Xia, Yuxuan and Zhu, Bing},
  journal={IEEE Transactions on Intelligent Vehicles}, 
  title={{LXL: LiDAR excluded lean 3D object detection with 4D imaging radar and camera fusion}}, 
  year={2024},
  volume={9},
  number={1},
  pages={79-92},
  doi={10.1109/TIV.2023.3321240}}

@inproceedings{CBAM,
  title={{CBAM: Convolutional block attention module}},
  author={Woo, Sanghyun and Park, Jongchan and Lee, Joon-Young and Kweon, In So},
  booktitle={Proceedings of the European Conference on Computer Vision},
  pages={3--19},
  year={2018}
}

@inproceedings{RCBEVDet,
  title={{RCBEVDet: Radar-camera fusion in bird's eye view for 3D object detection}},
  author={Lin, Zhiwei and Liu, Zhe and Xia, Zhongyu and Wang, Xinhao and Wang, Yongtao and Qi, Shengxiang and Dong, Yang and Dong, Nan and Zhang, Le and Zhu, Ce},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={14928--14937},
  year={2024}
}

@article{VoD,
  title={{Multi-class road user detection with 3+ 1D radar in the View-of-Delft dataset}},
  author={Palffy, Andras and Pool, Ewoud and Baratam, Srimannarayana and Kooij, Julian FP and Gavrila, Dariu M},
  journal={IEEE Robotics and Automation Letters},
  volume={7},
  number={2},
  pages={4961--4968},
  year={2022},
  publisher={IEEE}
}

@inproceedings{TJ4DRadSet,
  title={{TJ4DRadSet: A 4D radar dataset for autonomous driving}},
  author={Zheng, Lianqing and Ma, Zhixiong and Zhu, Xichan and Tan, Bin and Li, Sen and Long, Kai and Sun, Weiqi and Chen, Sihan and Zhang, Lu and Wan, Mengyue and others},
  booktitle={IEEE International Conference on Intelligent Transportation Systems},
  pages={493--498},
  year={2022},
  organization={IEEE}
}

@inproceedings{CenterPoint,
  title={{Center-based 3D object detection and tracking}},
  author={Yin, Tianwei and Zhou, Xingyi and Krahenbuhl, Philipp},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={11784--11793},
  year={2021}
}

@ARTICLE{SMURF,
  author={Liu, Jianan and Zhao, Qiuchi and Xiong, Weiyi and Huang, Tao and Han, Qing-Long and Zhu, Bing},
  journal={IEEE Transactions on Intelligent Vehicles}, 
  title={{SMURF: Spatial multi-representation fusion for 3D object detection with 4D imaging radar}}, 
  year={2024},
  volume={9},
  number={1},
  pages={799-812},
  doi={10.1109/TIV.2023.3322729}}

@article{RCFusion,
  title={{RCFusion: Fusing 4-D radar and camera with birdâ€™s-eye view features for 3-D object detection}},
  author={Zheng, Lianqing and Li, Sen and Tan, Bin and Yang, Long and Chen, Sihan and Huang, Libo and Bai, Jie and Zhu, Xichan and Ma, Zhixiong},
  journal={IEEE Transactions on Instrumentation and Measurement},
  volume={72},
  pages={1--14},
  year={2023},
  publisher={IEEE}
}

@inproceedings{BEVFusion,
  title={{BEVFusion: Multi-task multi-sensor fusion with unified bird's-eye view representation}},
  author={Liu, Zhijian and Tang, Haotian and Amini, Alexander and Yang, Xinyu and Mao, Huizi and Rus, Daniela L and Han, Song},
  booktitle={IEEE International Conference on Robotics and Automation},
  pages={2774--2781},
  year={2023},
  organization={IEEE}
}

@inproceedings{FUTR3D,
  title={{FUTR3D: A unified sensor fusion framework for 3D detection}},
  author={Chen, Xuanyao and Zhang, Tianyuan and Wang, Yue and Wang, Yilun and Zhao, Hang},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={172--181},
  year={2023}
}

@article{BEVFusion2,
  title={{BEVFusion: A simple and robust LiDAR-camera fusion framework}},
  author={Liang, Tingting and Xie, Hongwei and Yu, Kaicheng and Xia, Zhongyu and Lin, Zhiwei and Wang, Yongtao and Tang, Tao and Wang, Bing and Tang, Zhi},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={10421--10434},
  year={2022}
}

@article{BiCo-Fusion,
  title={{BiCo-Fusion: Bidirectional complementary LiDAR-camera fusion for semantic-and spatial-aware 3D object detection}},
  author={Song, Yang and Wang, Lin},
  journal={arXiv preprint arXiv:2406.19048},
  year={2024}
}

@inproceedings{Simple-BEV,
  title={{Simple-BEV: What really matters for multi-sensor BEV perception?}},
  author={Harley, Adam W and Fang, Zhaoyuan and Li, Jie and Ambrus, Rares and Fragkiadaki, Katerina},
  booktitle={IEEE International Conference on Robotics and Automation},
  pages={2759--2765},
  year={2023},
  organization={IEEE}
}

@inproceedings{Dual-BEV,
  title={{DualBEV: CNN is all you need in view transformation}},
  author={Li, Peidong and Shen, Wancheng and Huang, Qihao and Cui, Dixiao},
  booktitle={Proceedings of the European Conference on Computer Vision},
  year={2024}
}

@article{EA-LSS,
  title={{EA-LSS: Edge-aware Lift-Splat-Shot framework for 3D BEV object detection}},
  author={Hu, Haotian and Wang, Fanyi and Su, Jingwen and Wang, Yaonong and Hu, Laifeng and Fang, Weiye and Xu, Jingwei and Zhang, Zhiwang},
  journal={arXiv preprint arXiv:2303.17895},
  year={2023}
}

@article{BEVDet,
  title={{BEVDet: High-performance multi-camera 3D object detection in bird-eye-view}},
  author={Huang, Junjie and Huang, Guan and Zhu, Zheng and Ye, Yun and Du, Dalong},
  journal={arXiv preprint arXiv:2112.11790},
  year={2021}
}

@article{M2BEV,
  title={{M$^2$BEV: Multi-camera joint 3D detection and segmentation with unified birds-eye view representation}},
  author={Xie, Enze and Yu, Zhiding and Zhou, Daquan and Philion, Jonah and Anandkumar, Anima and Fidler, Sanja and Luo, Ping and Alvarez, Jose M},
  journal={arXiv preprint arXiv:2204.05088},
  year={2022}
}

@inproceedings{LSS,
  title={{Lift, Splat, Shoot: Encoding images from arbitrary camera rigs by implicitly unprojecting to 3D}},
  author={Philion, Jonah and Fidler, Sanja},
  booktitle={Proceedings of the European Conference on Computer Vision},
  pages={194--210},
  year={2020},
  organization={Springer}
}

@inproceedings{BEVSpread,
  title={{BEVSpread: Spread voxel pooling for bird's-eye-view representation in vision-based roadside 3D object detection}},
  author={Wang, Wenjie and Lu, Yehao and Zheng, Guangcong and Zhan, Shuigen and Ye, Xiaoqing and Tan, Zichang and Wang, Jingdong and Wang, Gaoang and Li, Xi},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={14718--14727},
  year={2024}
}


@inproceedings{DeformableDETR,
  title={{Deformable DETR: Deformable Transformers for End-to-End Object Detection}},
  author={Zhu, Xizhou and Su, Weijie and Lu, Lewei and Li, Bin and Wang, Xiaogang and Dai, Jifeng},
  booktitle={International Conference on Learning Representations},
  year={2021}
}

@inproceedings{PETRv2,
  title={{PETRv2: A unified framework for 3D perception from multi-camera images}},
  author={Liu, Yingfei and Yan, Junjie and Jia, Fan and Li, Shuailin and Gao, Aqi and Wang, Tiancai and Zhang, Xiangyu},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={3262--3272},
  year={2023}
}

@inproceedings{MonoDETR,
  title={{MonoDETR: Depth-guided transformer for monocular 3D object detection}},
  author={Zhang, Renrui and Qiu, Han and Wang, Tai and Guo, Ziyu and Cui, Ziteng and Qiao, Yu and Li, Hongsheng and Gao, Peng},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={9155--9166},
  year={2023}
}

@article{MonoDETRNext,
  title={{MonoDETRNext: Next-generation accurate and efficient monocular 3D object detection method}},
  author={Liao, Pan and Yang, Feng and Wu, Di and Bo, Liu},
  journal={arXiv preprint arXiv:2405.15176},
  year={2024}
}


@article{K-radar,
  title={{K-radar: 4D radar object detection for autonomous driving in various weather conditions}},
  author={Paek, Dong-Hee and Kong, Seung-Hyun and Wijaya, Kevin Tirta},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={3819--3829},
  year={2022}
}

@inproceedings{RPFA-Net,
  title={{RPFA-Net: A 4D radar pillar feature attention network for 3D object detection}},
  author={Xu, Baowei and Zhang, Xinyu and Wang, Li and Hu, Xiaomei and Li, Zhiwei and Pan, Shuyue and Li, Jun and Deng, Yongqiang},
  booktitle={IEEE International Conference on Intelligent Transportation Systems},
  pages={3061--3066},
  year={2021},
  organization={IEEE}
}

@inproceedings{PointPillars,
  title={{PointPillars: Fast encoders for object detection from point clouds}},
  author={Lang, Alex H and Vora, Sourabh and Caesar, Holger and Zhou, Lubing and Yang, Jiong and Beijbom, Oscar},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={12697--12705},
  year={2019}
}

@inproceedings{PointNet,
  title={{PointNet: Deep learning on point sets for 3D classification and segmentation}},
  author={Qi, Charles R and Su, Hao and Mo, Kaichun and Guibas, Leonidas J},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={652--660},
  year={2017}
}

@article{RadarMFNet,
  title={{3-D object detection for multiframe 4-D automotive millimeter-wave radar point cloud}},
  author={Tan, Bin and Ma, Zhixiong and Zhu, Xichan and Li, Sen and Zheng, Lianqing and Chen, Sihan and Huang, Libo and Bai, Jie},
  journal={IEEE Sensors Journal},
  volume={23},
  number={11},
  pages={11125--11138},
  year={2022},
  publisher={IEEE}
}

@article{RTNH+,
  title={{RTNH+: Enhanced 4D radar object detection network using combined cfar-based two-level preprocessing and vertical encoding}},
  author={Kong, Seung-Hyun and Paek, Dong-Hee and Cho, Sangjae},
  journal={arXiv preprint arXiv:2310.17659},
  year={2023}
}

@article{DPFT,
  title={{DPFT: Dual perspective fusion transformer for camera-radar-based object detection}},
  author={Fent, Felix and Palffy, Andras and Caesar, Holger},
  journal={arXiv preprint arXiv:2404.03015},
  year={2024}
}

@article{OFT,
  title={{Orthographic feature transform for monocular 3D object detection}},
  author={Roddick, Thomas and Kendall, Alex and Cipolla, Roberto},
  journal={arXiv preprint arXiv:1811.08188},
  year={2018}
}

@ARTICLE{rad_ins_seg,
  author={Liu, Jianan and Xiong, Weiyi and Bai, Liping and Xia, Yuxuan and Huang, Tao and Ouyang, Wanli and Zhu, Bing},
  journal={IEEE Transactions on Intelligent Vehicles}, 
  title={Deep instance segmentation with automotive radar detection points}, 
  year={2023},
  volume={8},
  number={1},
  pages={84-94},
  doi={10.1109/TIV.2022.3168899}}

@inproceedings{CenterFusion,
  title={{CenterFusion: Center-based radar and camera fusion for 3D object detection}},
  author={Nabati, Ramin and Qi, Hairong},
  booktitle={Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision},
  pages={1527--1536},
  year={2021}
}

@inproceedings{CRN,
  title={{CRN: Camera radar net for accurate, robust, efficient 3D perception}},
  author={Kim, Youngseok and Shin, Juyeb and Kim, Sanmin and Lee, In-Jae and Choi, Jun Won and Kum, Dongsuk},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={17615--17626},
  year={2023}
}

@article{RCBEV,
  title={{Bridging the view disparity between radar and camera features for multi-modal fusion 3D object detection}},
  author={Zhou, Taohua and Chen, Junjie and Shi, Yining and Jiang, Kun and Yang, Mengmeng and Yang, Diange},
  journal={IEEE Transactions on Intelligent Vehicles},
  volume={8},
  number={2},
  pages={1523--1535},
  year={2023},
  publisher={IEEE}
}

@inproceedings{SE,
  title={{Squeeze-and-excitation networks}},
  author={Hu, Jie and Shen, Li and Sun, Gang},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={7132--7141},
  year={2018}
}

@InProceedings{UniAD,
    author    = {Hu, Yihan and Yang, Jiazhi and Chen, Li and Li, Keyu and Sima, Chonghao and Zhu, Xizhou and Chai, Siqi and Du, Senyao and Lin, Tianwei and Wang, Wenhai and Lu, Lewei and Jia, Xiaosong and Liu, Qiang and Dai, Jifeng and Qiao, Yu and Li, Hongyang},
    title     = {Planning-Oriented Autonomous Driving},
    booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
    year      = {2023},
    pages     = {17853-17862}
}

@InProceedings{BEVFormer,
    author="Li, Zhiqi and Wang, Wenhai and Li, Hongyang and Xie, Enze and Sima, Chonghao and Lu, Tong and Qiao, Yu and Dai, Jifeng",
    title="{BEVFormer: Learning bird's-eye-view representation from multi-camera images via spatio-temporal transformers}",
    booktitle="Proceedings of the European Conference on Computer Vision",
    year="2022",
    pages="1--18",
}

@InProceedings{DETR3D,
  title={{DETR3D: 3D object detection from multi-view images via 3D-to-2D queries}},
  author={Wang, Yue and Guizilini, Vitor Campagnolo and Zhang, Tianyuan and Wang, Yilun and Zhao, Hang and Solomon, Justin},
  booktitle={Proceedings of the 5th Conference on Robot Learning},
  pages={180--191},
  year={2022},
}

@inproceedings{LiRaFusion,
    author = {Song, Jingyu and Zhao, Lingjun and Skinner, K. A.},
    title = {{LiRaFusion: Deep adaptive LiDAR-radar fusion for 3D object detection}},
    booktitle = {IEEE International Conference on Robotics and Automation},
    year = 2024
}