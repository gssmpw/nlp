Using the definitions \ref{def:lineartasks}, \ref{def:loraset}, \ref{def:newtask}, \ref{def:principalsubspace} and \ref{def:subspace} we state the following theorem; 
% with detailed proof in appendix section \ref{appendix:proof} .
\begin{theorem}
\label{thm:2}
    % Given a set of stacked (along the axis of its rank) weight matrices $\hat{W} = \{W_t \mid W_t \in \mathbb{R}^{m \times n}\}$ each with rank $r\leq\min(m,n)$ learned for a set of tasks $\{t \mid t \in \mathcal{T}_d\}$ and a training set $\mathcal{S}_t=\{\{x_i,y_i\} \mid x_i\in\mathcal{X}_t, y_i\in\mathcal{Y}_t\}^{s_t}_{i=1}$ where $s_t = |\mathcal{S}_t|$ and $\mathcal{X}_t \times \mathcal{Y}_t$ are distributed according to some unknown Gaussian distribution with mean $\Bar{\mathcal{X}_t}$. Each weight matrix can have different ranks and the following theorem will still hold however for brevity we restrict our analysis to same rank for all weight matrices of stacked in $\hat{W}$. Intuitively, we can think each of these stacked weights as belonging to some LoRA for task $t$ where $W_t = BA$. 
    % Using SVD, we can obtain $\hat{W}=\mathcal{U}\Sigma \mathcal{V}$. We then represent top $K$ right singular vectors of $\hat{W}$ (or top $K$ principal components if $\hat{W}$ is zero-centered) as $\mathcal{V}_K \in\mathbb{R}^{K\times n}=\{V_k\in\mathbb{R}^{1\times n}\}^K_{k=1}$. 
    % For a new related linear task $\tnew$ with true minimizer $W^*_{\tnew} = \arg\min_{W}$ such that it is spanned by the basis of $\hat{W}$ i.e. $\Wtrue = C\hat{W}$ and it holds that $\lVert \Wtrue - \alphatrue\Vk\lVert^2_F \leq \Vert\Wtrue - \alphalearnt\Vk\lVert_F$ for all rank $K$ linear transformation matrices $\alphalearnt$ and $\lVert \Wtrue - \alphatrue\Vk\lVert^2_F \leq \singularsum$ where $\sigma_i$'s are singular values of $\hat{W}$. For such a task, we learn coefficients of $K$ principal components $\alpha_{\tnew} \in \mathbb{R}^{m\times K}$ resulting in EigenLoRAx weights $\Wegn = \alphalearnt\Vk$. \\
    % Let $\ell_\tnew: \mathbb{R} \times \mathcal{Y} \rightarrow \mathbb{R}^+$ represent a Lipschitz loss function of interest for task $t$ with Lipschitz constant $L_{\ell}$. We denote the expected loss of $w$ for a task $t$ as $\mathcal{L}_t(w) = \mathbb{E}[\ell(w,x,y)] \forall (x,y)\in(\mathcal{X},\mathcal{Y})$ Similarly, we denote the empirical loss for task $t$ as $\hat{\mathcal{L}}(w)=\frac{1}{m_t}\sum^{m_t}_{i=1}\ell(w,x_i,y_i)$. Then we can say with at least probability $1-4\delta$ that
    For a task $\tnew$, we assume a hypothesis $h\in\mathcal{H}_{\Wnew}$ expressed as $h(\Wnew,X)=\Wnew \Xnew+W_0\Xnew+b$ where $\Wnew$ has rank $m$, $b$ is some constant and $W_0$ represents weights of a pretrained foundation model that is frozen during finetuning respectively. We have $\hegn\in\mathcal{H}_{\Wegn}, \htrue\in\mathcal{H}_{\Wtrue}$ such that $\hegn(\Wegn,\Xnew) = \alphalearnt\Vk \Xnew+W_0\Xnew+b$ where $\Wegn$ has rank $K$ and $\htrue(\Wtrue,\Xnew) = C\hat{W} \Xnew + W_0\Xnew+b$ where $\htrue(\Wtrue,\Xnew)=\Ynew$ is the true solution for task $\tnew$. For a Lipschitz continuous loss ($\loss(h)$) that is strong convex within the shared principal subspace spanned by principal components $\Vk$  with some Lipschitz constant ($L$), the risk can be written as $\Frisk(h_W) = E_{\mathcal{S}_t}[\loss(h) ]$ , and using Rademacher complexity bounds we can say with probability at least $1-4\delta$ for some $\delta>0$,
    % \begin{equation}
    %     \lVert W_t - W_t' \rVert_F < 
    %     \delta \lVert W_t \rVert_F = 
    %     % \sqrt{r}\cdot
    %     \tan(\sin^{-1}\delta)
    %     \lVert W_t' \rVert_F
    % \end{equation}
    \begin{equation}
    \label{equation:eq2}
        \Vert \Wtrue - \Wnew\lVert^2_F \leq C_1\cdot\Bigg(\frac{\sqrt{m}}{\sqrt{s_t}} \Bigg) + C_2
    \end{equation}
    \begin{equation}
    \label{equation:eq1}
        \Vert \alphatrue\Vk - \Wegn\lVert^2_F \leq C_1\cdot\Bigg(\frac{\sqrt{K}}{\sqrt{s_t}} \Bigg) + \singularsum + C_2
    \end{equation}
    where $\sigma_i$ are singular values of $\hat{W}$, $C$ is some constant such that $\Wtrue=C\hat{W}$ and $C_1$, $C_2$ are some constants.

\begin{proof}
    The derivation is straightforward, we can write the difference in risks for $\hegn$ and $\htrue$ as 
    \begin{align*}
        \Frisk(\hegn) - \Frisk(\htrue) = \mathbb{E}_{\mathcal{S}_t}\big[\loss(\hegn) - \loss(h^*)\big]
    \end{align*}
    By definition of strong convex loss function for some constant $\mu\geq0$, 
    \begin{align*}
        \mathbb{E}_{\mathcal{S}_t}\big[\loss(\hegn) - \loss(h^*)\big] \geq \frac{\mu}{2}\lVert \Wegn - \Wtrue\Vert^2_F
    \end{align*}
    We also know from generalization error bounds using Rademacher Complexity from \cite{bartlett2003rademacher} that with probability at least $1-2\delta$, 
    \begin{align*}
        |\Frisk(\hegn) - \emprisk(\hegn)| \leq \frac{\Rademacher(\mathcal{H}_{\Wegn})}{2} + \sqrt{\frac{\ln(1/\delta)}{2s_t}}  
    \end{align*}
    We can rewrite risk as
    \begin{align*}
        \Frisk(\htrue) - \Frisk(\hegn) =& \Frisk(\htrue) - \emprisk(\htrue)\\ 
        &- \Frisk(\hegn) + \emprisk(\hegn)\\
        &+ \emprisk(\htrue) - \emprisk(\hegn)
    \end{align*}
    Since we know by definition of $\htrue$ that $\emprisk(\htrue) \leq \emprisk(\hegn)$, we can say
    \begin{align*}
        \Frisk(\htrue) - \Frisk(\hegn) \leq \Frisk(\htrue) - \emprisk(\htrue)\\ 
        - \Frisk(\hegn) + \emprisk(\hegn)
    \end{align*}
    
    Then we take a union bound to conclude that with probability at least $1-4\delta$,
    \begin{align*}
        \Frisk(\htrue) - \Frisk(\hegn) \leq \frac{\Rademacher(\mathcal{H}_{\Wegn})}{2} + \sqrt{\frac{2\ln(1/\delta)}{s_{d+1}}}\\ 
        + \frac{\Rademacher(\mathcal{H}_{\Wtrue})}{2}
    \end{align*}
    Hence, we can also say that with probability at least $1-4\delta$,
    \begin{equation}
    \label{eq:totalerror1}
        \frac{\mu}{2}\lVert\Wtrue - \Wegn\lVert^2_F
        \leq \frac{\Rademacher(\mathcal{H}_{\Wegn})}{2} + \sqrt{\frac{2\ln(1/\delta)}{s_t}} + \frac{\Rademacher(\mathcal{H}_{\Wtrue})}{2}
    \end{equation}
    The Rademacher complexity of a low-rank weight matrix class $\mathcal{H}_{\Wegn}$ with rank $K$ can be directly bounded using results from \cite{bartlett2003rademacher} as
    \begin{align*}
        \Rademacher(\mathcal{H}_{\Wegn}) &= \mathcal{O}(\frac{\sqrt{K}\lVert \Wegn \lVert_F}{\sqrt{s_t}})\\ 
        % &= C_1\cdot \Bigg(\frac{\sqrt{K}\lVert \Wegn \lVert_F}{\sqrt{s_t}}\Bigg) + C_2
    \end{align*}
    We can separate the constants including $\Rademacher(\mathcal{H}_{\Wtrue})$ from \ref{eq:totalerror1} and assume that, for a normalised $\lVert\Wegn\lVert$, it is usually bounded, then we can write:
    \begin{equation}
    \label{eq:totalerror2}
         \lVert\Wtrue - \Wegn\lVert^2_F
        \leq C_1\cdot \Bigg(\frac{\sqrt{K}}{\sqrt{s_t}} \Bigg) + C_2
    \end{equation}
    Similarly, we can also say for $\Wnew$ that
    \begin{equation}
    \label{eq:totalerror}
        \lVert\Wtrue - \Wnew\lVert^2_F
        \leq C_1\cdot\Bigg(\frac{\sqrt{m}}{\sqrt{s_t}}\Bigg) + C_2
    \end{equation}
    This proves \ref{equation:eq2}. Now to further prove \ref{equation:eq1}, we use  properties of Frobenius norm,
    \begin{align*}
        \lVert \Wegn - \alphatrue\Vk \lVert^2_F - \lVert \Wtrue - \alphatrue\Vk \lVert^2_F \leq \Vert \Wegn - \Wtrue\lVert^2_F
    \end{align*}
    Then following from the definition of $\Wtrue$, we can say that,
    \begin{align*}
        \lVert \Wegn - \alphatrue\Vk \lVert^2_F - \singularsum \leq \Vert \Wegn - \Wtrue\lVert^2_F
    \end{align*}
    Finally, using the Rademacher complexity bound we provided earlier, 
    we can say that with probability at least $1-4\delta$
    \begin{align*}
        \lVert \alphatrue\Vk &- \Wegn \lVert^2_F \leq  \lVert\Wtrue - \Wegn\lVert^2_F\\
        &\leq C_1\cdot\Bigg(\frac{\sqrt{K}}{\sqrt{s_t}} \Bigg) + \singularsum + C_2
    \end{align*}
    We can just rewrite $\Wegn = \alphatrue\Vk$ and get the same bound as above for $\lVert \alphatrue - \alphalearnt\lVert^2_F$.
    We can similarly obtain the upper bound for \ref{equation:eq1}
    
    This concludes the proof. 
\end{proof}
\end{theorem}
% \begin{proof}
%     The derivation is straightforward, we can write the difference in risks for $\hegn$ and $\htrue$ as 
%     \begin{align*}
%         \Frisk(\hegn) - \Frisk(\htrue) = \mathbb{E}_{\mathcal{S}_t}\big[\loss(\hegn) - \loss(h_\Wtrue)\big]
%     \end{align*}
%     By definition of strong convex loss function for some constant $\mu\geq0$, 
%     \begin{align*}
%         \mathbb{E}_{\mathcal{S}_t}\big[\loss(\hegn) - \loss(h_\Wtrue)\big] \geq \frac{\mu}{2}\lVert \Wegn - \Wtrue\Vert^2_F\lVert X \lVert_F
%     \end{align*}
%     We also know from generalization error bounds using Rademacher Complexity from \cite{bartlett2003rademacher} that with probability at least $1-2\delta$, 
%     \begin{align*}
%         |\Frisk(\hegn) - \emprisk(\hegn)| \leq \frac{\Rademacher(\mathcal{H}_{\Wegn})}{2} + \sqrt{\frac{\ln(1/\delta)}{2s_t}}  
%     \end{align*}
%     We can rewrite risk as
%     \begin{align*}
%         \Frisk(\htrue) - \Frisk(\hegn) = \Frisk(\htrue) - \emprisk(\htrue) \\ - \Frisk(\hegn) + \emprisk(\hegn) \\
%         + \emprisk(\htrue) - \emprisk(\hegn)
%     \end{align*}
%     Since we know by definition of $\htrue$ that $\emprisk(\htrue) \leq \emprisk(\hegn)$, we can say
%     \begin{align*}
%         \Frisk(\htrue) - \Frisk(\hegn) \leq \Frisk(\htrue) - \emprisk(\htrue) \\ - \Frisk(\hegn) + \emprisk(\hegn) \\
%     \end{align*}
    
%     Then we take a union bound to conclude that with probability at least $1-4\delta$,
%     \begin{align*}
%         \Frisk(\htrue) - \Frisk(\hegn) \leq \Rademacher(\mathcal{H}_{\Wegn}) + \sqrt{\frac{2\ln(1/\delta)}{s_t}}
%     \end{align*}
%     Hence, we can also say that with probability at least $1-4\delta$,
%     \begin{equation}
%     \label{eq:totalerror}
%         \frac{\mu}{2}\lVert\Wtrue - \Wegn\lVert^2_F
%         \leq \Rademacher(\mathcal{H}_{\Wegn}) + \sqrt{\frac{2\ln(1/\delta)}{s_t}}
%     \end{equation}
%     Similarly, we can also say for $\Wnew$ that
%     \begin{equation}
%     \label{eq:totalerror}
%         \lVert\Wtrue - \Wnew\lVert^2_F
%         \leq \mathcal{O}(\Rademacher(\mathcal{H}_{\Wnew}))
%     \end{equation}
%     This proves \ref{equation:eq2}. Now to further prove \ref{equation:eq1}, we use  properties of Frobenius norm,
%     \begin{align*}
%         \lVert \Wegn - \alphatrue\Vk \lVert^2_F - \lVert \Wtrue - \alphatrue\Vk \lVert^2_F \leq \Vert \Wegn - \Wtrue\lVert^2_F
%     \end{align*}
%     Then following from the definition of $\Wtrue$, we can say that,
%     \begin{align*}
%         \lVert \Wegn - \alphatrue\Vk \lVert^2_F - \singularsum \leq \Vert \Wegn - \Wtrue\lVert^2_F
%     \end{align*}
%     Finally, using the Rademacher complexity bound we provided earlier, 
%     we can say that with probability at least $1-4\delta$
%     \begin{align*}
%         \lVert \alphatrue\Vk - \Wegn \lVert^2_F \leq  \mathcal{O}(\Rademacher(\mathcal{H}_{\Wegn})) + \\ \singularsum
%     \end{align*}
%     We can just rewrite $\Wegn = \alphatrue\Vk$ and get the same bound as above for $\lVert \alphatrue - \alphalearnt\lVert^2_F$.
%     We can similarly obtain the upper bound for \ref{equation:eq1}
    
%     This concludes the proof. 
% \end{proof}

Theorem \ref{thm:2} provides an upper bound on the Frobenius norm of the difference between $\Wnew$ or $\Wegn$ and the optimal solution $\Wtrue$. \ref{equation:eq1} provides a tighter upper bound on the norm of the difference when task $\tnew$ majorly lies in the shared principal subspace. The extent to which task $\tnew$ lies in the shared principle subspace is captured by the second term involving the sum of squared truncated singular values $\hat{W}$. Hence, if the task completely or majorly lie in the shared principal subspace, then the first term (sqrt(rank)) will dominate the upper bound.  Hence, if rank($\Wnew\geq K$), then we can see that the upper bound in eq. \ref{equation:eq1} will be tighter than in eq. \ref{equation:eq2} where the task lies majorly in the shared principal subspace. Similarly, when $m\leq K$, the upper bound on the difference norm will be tighter for $\Wnew$ than $\Wegn$.  When $\Wtrue$ has a significant alignment or projection along the singular vectors orthogonal to the ones with top $K$ singular values, then the second term in \ref{equation:eq2} comes into picture and it becomes difficult to directly compare the bounds in \ref{equation:eq2} and \ref{equation:eq1}. However, if majority of the variance of $\Wtrue$ is along the singular vectors orthogonal to the top $K$ components, it follows that $\Wegn$ will never be able to achieve convergence while $\Wnew$. In contrast, $\Wnew$ could perform significantly better, as it is not restricted to learning only along the top $K$ principal components of $\hat{W}$. While the assumption that $\Wtrue$ is spanned by the principal components of the shared principal subspace might appear to be very strong, we empirically observe in table \ref{tab:lola} that such an assumption is not impractically far from reality. Particularly, we observe in table \ref{tab:glue_benchmark_results} that for GLUE benchmark, LoRA adapters trained on 5 diverse tasks shared a principal subspace. We see that EigenLoRAx was able to leverage the principal components of this shared subspace with just 12K training parameters learned for a new 6th task and achieve competitive performance compared to fine-tuning full rank weights with 125M parameters or individual LoRA adaptors with 1.2M parameters, even outperforming them in certain tasks. Similarly, table \ref{tab:lola} demonstrates zeroshot performance using only top $K$ principal components of the shared subspace obtained through 500 LoRA adaptors trained on diverse tasks. This further suggests that increasing the number of LoRA adapters enables a richer set of top principal components, effectively spanning the shared subspace and providing broader coverage for new tasks.
    
    
    % Using Eckart-Young-Mirsky theorem we can say that 
    % \begin{align*} 
    % \lVert \hat{W} - \alpha_t^{*T}\mathcal{E}_d^{K,n}\lVert^2_F = \sum_{i=K+1}^{rd}\sigma_i^2
    % \end{align*}
    % where $\sigma_i$ is a singular value of $\hat{W}$ and $\alpha_t^{*T}$ is the optimal value of $\alpha_t$ that minimizes $\lVert W_t - \alpha_t^{T} \mathcal{E}^{K,n}_{d}\lVert$. As described in section \ref{method:learningnewelora}, for known LoRA weights $\alpha_t$ can be analytically computed. However, we are focusing on the scenario when we do not have access to the weights learnt for a given task $t$.
    % Hence, we can say for any task $t\in\mathcal{T}_d$,
    % \begin{align*} 
    %     \lVert W_t - \alpha_t^{T}\mathcal{E}_d^{K,n} \lVert^2_F \leq \Vert W_t(\mathcal{E}^{K,n}_d)^T\mathcal{E}^{K,n}_d-\alpha_t^T\mathcal{E}^{K,n}_d\lVert^2_F + \sum_{i=K+1}^{rd}\sigma_i^2
    % \end{align*}
    % We represent the Rademacher Complexity of hypothesis class parameterized by $W_t$ and $W_{eigen}$ as $\mathcal{R}_{\mathcal{S}_t}(W_t)$ and $\mathcal{R}_{\mathcal{S}_t}(W_{eigen})$, respectively, for a training set $\mathcal{S}_t$ of task $t$. \\
    % Now from \cite{bartlett2003rademacher}, we can write for a Lipschitz loss $\ell$ bounded by $c$, for any $\delta\geq0$ with probability at least $1-\delta$ simultaneously for all possible values of $W_t$ that
    % \begin{align*} 
    %     \mid\mathcal{L}_t(W_t) - \hat{\mathcal{L}}_t(W_t)\mid \leq 2L_\ell\mathcal{R}_{S_t}(W_t) + c\sqrt{\frac{\textnormal{log}(1/\delta)}{2m_t}}
    % \end{align*}
    % Similarly, we can say for all the possible values of $\alpha_t$ with probability $1-\delta$ for any $\delta\geq 0$ that
    % \begin{align*} 
    % \mid\mathcal{L}_t(W_{eigen}) - \hat{\mathcal{L}}_t(W_{eigen})\mid \leq 2L_\ell\mathcal{R}_{S_t}(W_{eigen}) + c\sqrt{\frac{\textnormal{log}(1/\delta)}{2m_t}}
    % \end{align*}
    % \begin{align*}
    %     \mathcal{L}_t(W_{eigen}) - \mathcal{L}_t(W_t) =  (\mathcal{L}_t(W_{eigen}) - \hat{\mathcal{L}_t}(W_{eigen})) - \\
    %     (\mathcal{L}_t(W_t) - \hat{\mathcal{L}}_t(W_t)) + \\
    %     \hat{\mathcal{L}_t}(W_{eigen})- \hat{\mathcal{L}}_t(W_t)
    % \end{align*}
    % Then we take a union bound to say thath with probability at least $1-4\delta$
    % \begin{align*}
    %     \mathcal{L}_t(W_{eigen}) - \mathcal{L}_t(W_t) \leq 2L_\ell\mathcal{R}_{S_t}(W_{eigen}) + \\
    %     2L_\ell\mathcal{R}_{S_t}(W_t)) + c\sqrt{\frac{2\textnormal{log}(1/\delta)}{m_t}}\\
    %     + \mathbb{E}_{\{X,Y\}\in\mathcal{S}_t}[\ell(W_{eigen},X,Y)-\ell(W_t,X,Y)]
    % \end{align*}
    % Assuming $W_t$ optimally solves the task such that its empirical error is $0$ and $y_i = W_tx_i + W_0x$ with Mean absolute error loss we can rewrite the right side of the inequality as,
    % \begin{align*}
    %     \leq 2L_\ell\mathcal{R}_{S_t}(W_{eigen}) + \\
    %     2L_\ell\mathcal{R}_{S_t}(W_t)) + c\sqrt{\frac{2\textnormal{log}(1/\delta)}{m_t}}\\
    %     + \mathbb{E}_{X\in\mathcal{S}_t}[\lVert W_t - W_{eigen}\lVert_F\lVert X\lVert_F]
    % \end{align*}
    % Now we can bound $\mathbb{E}_{X\in\mathcal{S}_t}[\lVert W_t - W_{eigen}\lVert_F\lVert X\lVert_F]$ as ,
    % \begin{align*}
    %     \leq \mathbb{E}_{X\in\mathcal{S}_t}\bigg[\Vert W_t(\mathcal{E}^{K,n}_d)^T\mathcal{E}^{K,n}_d-\alpha_t^T\mathcal{E}^{K,n}_d\lVert^2_F + \\ \sum_{i=K+1}^{rd}\sigma_i^2\bigg]\mathbb{E}_{X\in\mathcal{S}_t}[\lVert X\lVert_F]
    % \end{align*}
    
    
    
    

% \begin{wrapfigure}{r}{0.30\textwidth}
\begin{figure}
  \begin{center}
    \includegraphics[width=0.35\textwidth]{images/eigen_plot.png}
  \end{center}
  % \vspace{-15pt}
  \caption{\small{The top 16 components contain the most information from a total of 4000+ components for $~500$ LoRAs. ($A$ matrices from layer 1 of Mistral-7b model, Lots of LoRAs, see Section~\ref{sec:lotsofloras}).}}
  % \vspace{-10pt}
  \label{fig:singular}
% \end{wrapfigure}
\end{figure}
\paragraph{How to choose optimal number of PCs $K$} The hyperparameter $K$, which determines the number of top PC, can be viewed as a function of task domain complexityâ€”simpler domains require a smaller $K$, while more complex domains benefit from a larger $K$.
In practice, we determine $K$ based on empirical observations (\cref{sec:ablation}), evaluating performance across different values. Additionally, we can leverage established techniques from literature, such as explained variance and singular value thresholds \cite{gavish2014optimalhardthresholdsingular}. As illustrated in \cref{fig:singular}, most of the relevant information is often concentrated in a few top EigenLoRAx PCs, providing a practical criterion for selecting $K$.

\paragraph{Memory Efficiency and Complexity} Our method demonstrates significant memory efficiency across experiments. A single set of EigenLoRAx PCs, combined with lightweight task-specific coefficients, can effectively replace both past and future LoRAs within a task domain. This is particularly advantageous when serving a large number of adapters, where frequent loading and unloading in VRAM incurs high latency, or keeping all adapters in memory demands excessive VRAM.
For $d$ LoRAs of rank $r$ and $l$ layers, the memory footprint is $O(2drln)$. For EigenLoRAxs, it is $O(2Kl (d + n) )$. As $r, K \ll n$, EigenLoRAx becomes more memory efficient in terms of memory required to save the models as $d$ increases. This becomes significantly useful for edge devices and large scale user serving AI systems. 