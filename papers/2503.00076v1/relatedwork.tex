\section{Related Work}
\label{sec:related_work}

\subsection{Data for crisis management}

While crisis management relies on information about the crisis, its impact and development, the processing of the data plays an important role.
The used data should provide an overview of the situation and enable the crisis managers to draw the right conclusions.
With the availability of data from multiple sources nowadays the challenge is not only to gather data about the crisis but also to interpret it in the right way.
We have found multiple approaches in the literature to this challenge.

In publications \cite{Conges2023} and \cite{Essendorfer2020} approaches to present data in comprehensible way through visualization techniques are discussed.
The focus of \cite{Conges2023} is the usage of virtual reality to create a crisis management cell.
In this cell the data is presented in an immersive way to the crisis managers and domain experts can join the cell from remote places to support the decision making with their expertise.
An alternative approach using visual analytics in crisis management as well as a multidisciplinary approach combining visualization and data analysis, is discussed in \cite{Essendorfer2020}.
The approach aims to provide a deeper insight into heterogeneous data used in crisis management and thus enhance the decision making process.
Additionally the paper elaborates on the benefits of Coalition Shared Data (CSD), but only mentions the potential data analysis techniques marginally.

A recent research contribution \cite{Zheng2023} has adopted incoming DT data analysis to deal with real-time detection of cybertheats using anomaly detection operation by applying a multidimensional deconvolutional network equipped with an attention mechanism.
An ontology-based approach has been recently published in \cite{Bai2024}, where an information framework for tracking provenance and managing information has been embedded in knowledge graphs.
In \cite{Borges2023} a taxonomy has been built to better understanding topics, interrelations, challenges, gaps related to crisis information managment systems.

A broad overview about the potential of the analysis of spatio-temporal data with deep learning techniques is presented in \cite{Wang2022}.
The survey covers multiple domains where deep learning approaches demonstrated their potential.
These domains include relevant domains for crisis management like human mobility and crime analysis.
Even though the analysis of big data benefits from deep learning approaches there are open research questions which hinder the usage in crisis management.
Deep learning models are often considered as black boxes and thus make it hard to interpret and explain the results.
While the analysis of large data sets is a common application for deep learning models, the fusion of heterogeneous spatio-temporal data sets is still an active area of research.
The potential of spatial-temporal selection criteria are shown in \cite{Zoppi2018}, where information collected by a crisis management system from different sensors including human sensors are labelled by reference using the spatial and temporal information of the data sources.
%
The benefits of using an established standard for the data collection is discussed in \cite{Lopez2019}.
The usage of connectors and data converters enable the storage of data from sources with differing standards in common database and the provision of the information to varying systems used in crisis management.

The handling of big data during crisis management is being discussed in \cite{Shah2019}. The authors give a thorough overview of the overall architectural deployment of big data analytics- and Internet of Things-based disaster management environments through a reference model having dedicated layers, such as data generation, harvesting, communication, management and analytics, and applications.
In a similar approach \cite{Li2022} applies big data analysis on the massive data generated in the smart city. Deep learning algorithms are being used to analyse electricity performance. The authors claim increased efficiency and reduced data usage. However, deep learning requires prior availability of data sets. As each disaster event is different the approach fails in crisis management.
The authors in \cite{Nayak2023} apply deep learning to enhance IoT analytics and teaching. It is advertised to integrated deep learning into the IoT sensors.

Together with \cite{Palen2016} the above mentioned publications \cite{Zoppi2018} and \cite{Lopez2019} describe the additional challenges to gather information from social media or integrate it as additional source.
In \cite{Palen2016} it is shown that social media provides new insights in crisis scenarios.
As information is often distributed over multiple short messages and the context can only be understood by analyzing all related messages, even simple questions require mature analysis approaches to extract the relevant information.
Also the management of misinformation, noise and bias in social media requieres advanced forms of filtering and verification techniques \cite{Zoppi2018} to select only valid and trusted data.

The existing research contributions address numerous aspects of the data processing chain in crisis management, spanning from data acquisition to data analysis and decision support.  However, none of the contributions addressed the full data life cycle, including the issue of data source interruptions.


\subsection{Digital Twin Application in Crisis Management}
\label{sec:related_work:Framework}

The concept of digital twins has been adopted for the monitoring, analysis, control and optimization of systems throughout their life cycle with a focus on real-time interaction.
Virtual replication and twinning form the core concept for synchronizing the \DT with the real world section, which is highly dependent on availability of reliable data.
Implementation details include considerations for data acquisition, modeling, value creation, human-computer interfaces and platform implementation. As Figure \ref{fig:digital_twin_basic} depicts added value is created by tools that offer smart functionality as part of the \DT, predict future conditions and initiate smart measures.
This makes \DTs a technology suitable for use in crisis management and promises to improve the resilience of critical infrastructure services, highlighting its responsiveness, intelligent features and adaptability.
The following literature research displays a variety of proposed implementation approaches.

The term "Digital Twin" was first introduced in 2002 by Grieves \cite{Grieves2014}. Over the years, the concept has undergone intense research and development efforts as surveyed by Fuller \cite{Fuller2020}, Liu \cite{Liu2021}, and Jones \cite{Jones2020}. This sets the historical context and underscores the increasing significance of \DTs in various domains.

In \cite{Galera-Zarco2023}, the authors explored the  role of DT beyond enhancing internal processes, recognizing their potential to shape new service offerings. They highlighted the need to investigate DT's role in enabling services, prompting the creation of a taxonomy classifying these digital services. Through literature review and use cases, four key dimensions -- service recipient, target operand resource, service content, and pricing model -- were identified to structure the taxonomy. This taxonomy aided in understanding existing DT-based services and design principles as well as served as a  tool for service providers venturing into developing new DT-enabled services.
In \cite{Pronost2021} classification is exploited to characterize, categorize and distinguish different DTs and related applications.
Whereas in \cite{VanDerValk2020}  the relationship between DTs and simulations, aiming to bridge the gap between their conceptual definitions and real-world applications, were investigated. A taxonomy based on simulation characteristics, analyzing 69 DT applications predominantly in manufacturing has been proposed. The findings reveal a disparity: while simulations are vital to DTs, the two concepts remain distinct, lacking alignment in crucial areas like data connectivity and distribution aspects. This underscores the need to refine definitions for better synergy in analyzing and optimizing systems.

\DT concept named \textit{Universal Digital Twin} is presented in \cite{Akroyd2021}, based on a knowledge graph and ontologies. Data is stored and connected semantically by Uniform Resource Identifiers (URI). Agents are being defined that fulfill tasks on the knowledge graph including data preparation or simulation.
\cite{lyan2021} propose a framework called DATATIME. Models capture at runtime  the state of a socio-technical system according to the dimensions of
both time and space. Space is modeled as a slowly evolving
directed graph with states associated to nodes and edges.

Benaben et. al. present in \cite{Benaben2016} a metaconcept which is defined as a model of the crisis situation itself including partners, objectives, behaviour and context. The technical level includes simulations based on data gatherd from the observed situation and how actors react to it.

The concept of \DTs encompasses a wide range of systems, from small, well-defined machines to large, complex systems of systems. This diversity of scope adds to the complexity of defining what a \DT \cite{Kritzinger2018} is.
Each area, with its own scope and application, has developed its own approach.
While digital twins in production have a strong focus on storing the manufacturing and usage history of products, other applications focus on the lifecycle of products with a strong 3D/CAD aspect from the design phase to production.
For infrastructures and smart cities, the focus is on modeling the functionality and capturing all types of city data. It is an open research task how to design a digital twin for these different areas and first steps towards implementation have already been taken. Crisis management with its big data requirements raises additional areas of research.


\subsection{Previous related work}

\begin{figure}[ht]
\centering
\begin{minipage}{.48\textwidth}
  \centering
  	\includegraphics[width=\columnwidth]{Figure1_dt_full_v5.png}
	\caption{General architecture of a Digital Twin to provide added value \cite{Brucherseifer2021}. The twinning is an essential function of the DT, connecting physical and real space in real-time. The virtual replica consists of models and data.}
    \label{fig:digital_twin_basic}
\end{minipage}
\hfill
\begin{minipage}{.48\textwidth}
   \centering
	\includegraphics[height=0.65\columnwidth]{Figure2_dt_framework_v3.png}
	\caption{\DT Conceptual Model for the operation of infrastructures to improve resilience in crisis situations, as introduced in \cite{Brucherseifer2021}}
	\label{fig:dt_framework_previous}
\end{minipage}
\end{figure}

In \cite{Brucherseifer2021} we proposed a specific conceptual framework for implementing a \DT to increase the resilience of critical infrastructures in crisis situations, depicted in Figure \ref{fig:dt_framework_previous}. The building blocks and data handling presented in Section \ref{sec:building_blocks} directly inherits from this framework.
The framework is supplied with a study, where we derived implementation requirements from methods of critical infrastructure, crisis management and resilience, compared them with the concept of the digital twin and supplemented them with guiding principles.
The proposed model is suitable for daily use and for crisis situations, with user machine interfaces for situation control and tool interaction. In addition, scenario recording enables retrospective analysis, and simulators based on virtual clones serve as valuable tools for experimentation and optimization and help prepare for rare events and crises. Overall, the application of the digital twin concept to critical infrastructures has been shown to support learning, address challenges in networked systems and systematically improve resilience.
The Digital Twin concept, with its main components meeting the outlined requirements, is presented as a valuable approach to significantly increase the resilience of critical infrastructures. The proposed framework aims to optimize and manage the performance of infrastructures to enhance their resilience.