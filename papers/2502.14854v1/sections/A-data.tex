\newpage
\appendix
\section{Data Collection}

\subsection{Books used in manual analysis}
Table \ref{tab:six-books} lists six books used in our manual analysis. These books are chosen due to the annotator's familiarity with the content, which eases the manual verification process. 
\begin{table*}[htbp]
    \small
    \centering
    \begin{tabular}{llccc}
        \toprule
        Title & Author & Publication Year & Number of Tokens & Number of Chapters \\
        \midrule
        Anne of the Island & L. M. Montgomery & 1915 & 111,337& 41 \\
        Alice in Wonderland & Lewis Carroll & 1865 & 36,691 & 12 \\
        The Murder of Roger Ackroyd & Agatha Christie & 1926 & 98,602 & 27 \\
        The Picture of Dorian Gray & Oscar Wilde & 1890 & 105368 & 20\\
        Frankenstein & Mary Shelley & 1818 & 97,574 & 24\\
        The Adventures of Tom Sawyer & Mark Twain & 1876 & 97,968 & 35 \\
        \bottomrule
    \end{tabular}
    \caption{Six books used in our manual analysis. Books are chosen due to familiarity with the content.}
    \label{tab:six-books}
\end{table*}

\subsection{Does memorization have an effect on claim verification performance?}
\label{appendix:memorization}
We measure the performance of the models used for finetuning on our test set, with and without book text. We provide the book title and author name where the book text is not provided. Our hypothesis is that if the model does better than the random chance baseline (25\% accuracy) without the book text, then the claims are either too easy or can be verified without even reasoning over the texts. 
% \begin{table}[htbp]
% \small
%     \centering
%     \begin{tabular}{lcc}
%         \toprule
%         Models & No Text & With Text\\
%         \midrule
%         Prolong-8B-Instruct &   0.00\%& 35.60\%\\
%         Llama-3-8B-Instruct & 0.00\%& 32.75\%\\
%         Qwen-2.5-7B-Instruct & 0.00\%& 51.40\%\\
%         \bottomrule
%     \end{tabular}
%     \caption{Accuracy on \pipeline's test set (with and without book texts).}
%     \label{tab:memorization}
% \end{table}
\begin{table}[htbp]
\small
    \centering
    \begin{tabular}{lcc}
        \toprule
        Models & No Text & With Text\\
        \midrule
        \prolonginst\ & 0.0\%& 35.6\%\\
        \llamainst\ & 0.0\%& 32.8\%\\
        \qweninst\ & 0.0\%& 51.4\%\\
        \bottomrule
    \end{tabular}
    \caption{Accuracy on \pipeline's test set (with and without book texts).}
    \label{tab:memorization}
\end{table}

Table \ref{tab:memorization} shows that all baseline models perform below random chance, significantly trailing behind the performance achieved when the book text is included in the claim verification prompt. These results indicate that even if a model has memorized the book texts or generated claims, such memorization does not affect its performance on the task itself.

\subsection{Are the True/False claims distinguishable without the book texts?}
We ask the question of whether distinguishing between True and False claims is inherently too easy. If so, then the high performance of the fine-tuned models may be attributed merely to their ability to detect formatting cues rather than actually reasoning. To investigate this, we prompt both baseline and fine-tuned models to verify claims without providing any book texts or metadata. Our hypothesis is that if a model performs better than random chance under these conditions, then the claims are likely too easily distinguishable based on their formatting alone. 

% \begin{table}[ht!]
%     \small
%     \centering
%     \begin{tabular}{lcc}
%         \toprule
%         Models & Before SFT & After SFT\\
%         \midrule
%         Prolong-8B-Instruct &  0.00\%& 25.20\%\\
%         Llama-3-8B-Instruct & 20.20\%& 13.80\%\\
%         Qwen2.5-7B-Instruct & 21.65\%& TODO\%\\
%         \bottomrule
%     \end{tabular}
%     \caption{Accuracy on \pipeline's test set (no book text or metadata provided).}
%     \label{tab:claim-formatting}
% \end{table}
\begin{table}[htbp]
    \small
    \centering
    \begin{tabular}{lcc}
        \toprule
        Models & Before SFT & After SFT\\
        \midrule
        \prolonginst\ &  0.0\%& 25.2\%\\
        \llamainst\ & 20.2\%& 13.8\%\\
        \qweninst\ & 21.7\%& 22.9\%\\
        \bottomrule
    \end{tabular}
    \caption{Accuracy on \pipeline's test set (no book text or metadata provided).}
    \label{tab:claim-formatting}
\end{table}

As shown in Table \ref{tab:claim-formatting}, even after fine-tuning, the models perform only marginally above random guessing. We conclude that, without the contextual information from the book text, True/False claims are not easily distinguishable.

\subsection{Cost Analysis}
\label{appendix:data-cost}
Table \ref{tab:cost_analysis} shows the cost incurred by running each stage of our data synthesis pipeline. With the exception of deduplication, which is done by GPT-4o, each stage of the pipeline is performed by Claude.  Table \ref{tab:cost-naive-main} shows the estimated per claim cost for the \texttt{na\"ive} versus \texttt{main} approach based on estimated cost for 6 books. For human annotation, NoCha \cite{karpinska_one_2024} reports that their total cost of annotating 1,001 claim pairs is \$3,327 USD, so each claim costs around \$1.7.

% \begin{table}[htbp]
%     \centering
%     \small
%     \begin{tabular}{lc}
%         \toprule
%         Stage & Cost (per book)\\
%         \midrule 
%         Book summmary generation &  \$0.12\\
%         Chapter outline generation & \$0.52 \\
%         Book-level claim synthesis & \$0.59 \\
%         Chapter-level claim synthesis & \$0.76\\
%         Deduplication & \$0.05\\
%         Verification & \$ 0.28 \\
%         \bottomrule
%     \end{tabular}
%     \caption{Cost to run pipeline per book (in US dollars, rounded to the nearest hundredth).}
%     \label{tab:cost_analysis}
% \end{table}
\begin{table}[htbp]
    \centering
    \small
    \begin{tabular}{lc}
        \toprule
        Stage & Cost\\
        \midrule 
        Book summary generation & \$0.0021 \\
        Chapter outline generation & \$0.0107 \\
        Book-level claim synthesis & \$0.0129 \\
        Chapter-level claim synthesis & \$0.0172 \\
        Deduplication & \$0.0021 \\
        Verification & \$0.0064 \\
        \midrule
        Total&\$0.0514\\
        \bottomrule\\
    \end{tabular}
    \caption{Cost to run pipeline per claim (in US dollars, rounded to four decimal places).}
    \label{tab:cost_analysis}
\end{table}


\begin{table}[htbp]
\centering
\small
\begin{tabular}{@{}lcc@{}}
\toprule
                            & \naive & \pipeline \\ \midrule
Cost per claim (book-level) & \$0.09         & \$0.07        \\
Cost per claim (chap-level) & \$0.04         & \$0.02        \\
\bottomrule
\end{tabular}
\caption{Estimated cost for our \naive\ vs \pipeline\ approach (rounded to two decimal places)}
\label{tab:cost-naive-main}
\end{table}



\subsection{Prompts}
\label{appendix:data-construction}
Table \ref{tab:prompt-mapping} shows stages to construct \pipeline, mapped to their corrresponding prompts.
\begin{table}[htbp]
    \small
    \centering
    \begin{tabular}{ll}
        \toprule
         Prompt & Figure\\
         \midrule
         Chapter outline generation & \ref{fig:chapter-outline-prompt}\\
         Book summary generation & \ref{fig:summary-prompt} \\
         Chapter-level claim extraction & \ref{fig:chapter-level} \\
         Book-level claim extraction & \ref{fig:book-level} \\
         Claim deduplication & \ref{fig:dedup-prompt} \\
         Claim verification & \ref{fig:verification-prompt-1}, \ref{fig:verification-prompt-2}, \ref{fig:verification-prompt-3}, \ref{fig:verification-prompt-4}, \ref{fig:verification-prompt-5}\\
         \midrule
         Chapter-level claim extraction (\naive) & \ref{fig:chapter-alt}\\
         Book-level claim extraction (\naive) & \ref{fig:book-alt}\\
         \bottomrule
    \end{tabular} 
    \caption{Figure references for each prompt.}
    \label{tab:prompt-mapping}
\end{table}

% Begin new figure -----
\begin{figure*}[htbp]
\centering
\begin{tcolorbox}[colback=gray!5!white, colframe=black, title=Prompt for Chapter Outline Generation]
\lstset{
    basicstyle=\ttfamily\footnotesize,
    breaklines=true,
    frame=none,
    xleftmargin=0pt,
    framexleftmargin=0pt,
    columns=fullflexible,
    tabsize=1,
    breakindent=0pt,
    breakautoindent=false,
    postbreak=\space,
    showstringspaces=false,
}
\lstinputlisting[language=Markdown]{assets/markdowns/outline.md}
\end{tcolorbox}
\caption{Prompt for generating chapter outlines in our dataset.}
\label{fig:chapter-outline-prompt}
\end{figure*}


% Begin new figure -----
\begin{figure*}[htbp]
\centering
\begin{tcolorbox}[colback=gray!5!white, colframe=black, title=Prompt for Generating Book Summaries]
\lstset{
    basicstyle=\ttfamily\footnotesize,
    breaklines=true,
    frame=none,
    xleftmargin=0pt,
    framexleftmargin=0pt,
    columns=fullflexible,
    tabsize=1,
    breakindent=0pt,
    breakautoindent=false,
    postbreak=\space,
    showstringspaces=false,
}
\lstinputlisting[language=Markdown]{assets/markdowns/summary.md}
\end{tcolorbox}
\caption{Prompt for generating book summaries.}
\label{fig:summary-prompt}
\end{figure*}

% Begin new figure -----
\begin{figure*}[htbp]
\centering
\begin{tcolorbox}[colback=gray!5!white, colframe=black, title=Prompt for Extracting Chapter-level Claims]
\lstset{
    basicstyle=\ttfamily\footnotesize,
    breaklines=true,
    frame=none,
    xleftmargin=0pt,
    framexleftmargin=0pt,
    columns=fullflexible,
    tabsize=1,
    breakindent=0pt,
    breakautoindent=false,
    postbreak=\space,
    showstringspaces=false,
}
\lstinputlisting[language=Markdown]{assets/markdowns/extraction_single.md}
\end{tcolorbox}
\caption{Prompt for extracting chapter-level claims}
\label{fig:chapter-level}
\end{figure*}


% Begin new figure -----
\begin{figure*}[htbp]
\centering
\begin{tcolorbox}[colback=gray!5!white, colframe=black, title=Prompt for Extracting Book-level Claims]
\lstset{
    basicstyle=\ttfamily\footnotesize,
    breaklines=true,
    frame=none,
    xleftmargin=0pt,
    framexleftmargin=0pt,
    columns=fullflexible,
    tabsize=1,
    breakindent=0pt,
    breakautoindent=false,
    postbreak=\space,
    showstringspaces=false,
}
\lstinputlisting[language=Markdown]{assets/markdowns/extraction_multiple.md}
\end{tcolorbox}
\caption{Prompt for extracting book-level claims}
\label{fig:book-level}
\end{figure*}


% Begin new figure -----
\begin{figure*}[htbp]
\centering
\begin{tcolorbox}[colback=gray!5!white, colframe=black, title=Prompt for Deduplicating Claims]
\lstset{
    basicstyle=\ttfamily\footnotesize,
    breaklines=true,
    frame=none,
    xleftmargin=0pt,
    framexleftmargin=0pt,
    columns=fullflexible,
    tabsize=1,
    breakindent=0pt,
    breakautoindent=false,
    postbreak=\space,
    showstringspaces=false,
}
\lstinputlisting[language=Markdown]{assets/markdowns/duplication.md}
\end{tcolorbox}
\caption{Prompt for de-duplicating claims}
\label{fig:dedup-prompt}
\end{figure*}


% Begin new figure -----
\begin{figure*}[htbp]
\centering
\begin{tcolorbox}[colback=gray!5!white, colframe=black, title=Prompt for Verifying Claims with GPT-4o (Part 1)]
\lstset{
    basicstyle=\ttfamily\footnotesize,
    breaklines=true,
    frame=none,
    xleftmargin=0pt,
    framexleftmargin=0pt,
    columns=fullflexible,
    tabsize=1,
    breakindent=0pt,
    breakautoindent=false,
    postbreak=\space,
    showstringspaces=false,
}
\lstinputlisting[firstline=1, lastline=30, language=Markdown]{assets/markdowns/verification.md} % Adjust line numbers
\end{tcolorbox}
\caption{Prompt for verifying claims with GPT-4o (Part 1)}
\label{fig:verification-prompt-1}
\end{figure*}

\begin{figure*}[htbp]
\centering
\begin{tcolorbox}[colback=gray!5!white, colframe=black, title=Prompt for Verifying Claims with GPT-4o (Part 2)]
\lstset{
    basicstyle=\ttfamily\footnotesize,
    breaklines=true,
    frame=none,
    xleftmargin=0pt,
    framexleftmargin=0pt,
    columns=fullflexible,
    tabsize=1,
    breakindent=0pt,
    breakautoindent=false,
    postbreak=\space,
    showstringspaces=false,
}
\lstinputlisting[firstline=31, lastline=60, language=Markdown]{assets/markdowns/verification.md} % Adjust line numbers
\end{tcolorbox}
\caption{Prompt for verifying claims with GPT-4o (Part 2)}
\label{fig:verification-prompt-2}
\end{figure*}

\begin{figure*}[htbp]
\centering
\begin{tcolorbox}[colback=gray!5!white, colframe=black, title=Prompt for Verifying Claims with GPT-4o (Part 3)]
\lstset{
    basicstyle=\ttfamily\footnotesize,
    breaklines=true,
    frame=none,
    xleftmargin=0pt,
    framexleftmargin=0pt,
    columns=fullflexible,
    tabsize=1,
    breakindent=0pt,
    breakautoindent=false,
    postbreak=\space,
    showstringspaces=false,
}
\lstinputlisting[firstline=61, lastline=90, language=Markdown]{assets/markdowns/verification.md} % Adjust line numbers
\end{tcolorbox}
\caption{Prompt for verifying claims with GPT-4o (Part 3)}
\label{fig:verification-prompt-3}
\end{figure*}


\begin{figure*}[htbp]
\centering
\begin{tcolorbox}[colback=gray!5!white, colframe=black, title=Prompt for Verifying Claims with GPT-4o (Part 4)]
\lstset{
    basicstyle=\ttfamily\footnotesize,
    breaklines=true,
    frame=none,
    xleftmargin=0pt,
    framexleftmargin=0pt,
    columns=fullflexible,
    tabsize=1,
    breakindent=0pt,
    breakautoindent=false,
    postbreak=\space,
    showstringspaces=false,
}
\lstinputlisting[firstline=91, lastline=120, language=Markdown]{assets/markdowns/verification.md} % Adjust line numbers
\end{tcolorbox}
\caption{Prompt for verifying claims with GPT-4o (Part 4)}
\label{fig:verification-prompt-4}
\end{figure*}


\begin{figure*}[htbp]
\centering
\begin{tcolorbox}[colback=gray!5!white, colframe=black, title=Prompt for Verifying Claims with GPT-4o (Part 5)]
\lstset{
    basicstyle=\ttfamily\footnotesize,
    breaklines=true,
    frame=none,
    xleftmargin=0pt,
    framexleftmargin=0pt,
    columns=fullflexible,
    tabsize=1,
    breakindent=0pt,
    breakautoindent=false,
    postbreak=\space,
    showstringspaces=false,
}
\lstinputlisting[firstline=121, lastline=160, language=Markdown]{assets/markdowns/verification.md} % Adjust line numbers
\end{tcolorbox}
\caption{Prompt for verifying claims with GPT-4o (Part 5)}
\label{fig:verification-prompt-5}
\end{figure*}

\begin{figure*}[htbp]
\centering
\begin{tcolorbox}[colback=gray!5!white, colframe=black, title=Prompt for Verifying Claims with GPT-4o (Part 6)]
\lstset{
    basicstyle=\ttfamily\footnotesize,
    breaklines=true,
    frame=none,
    xleftmargin=0pt,
    framexleftmargin=0pt,
    columns=fullflexible,
    tabsize=1,
    breakindent=0pt,
    breakautoindent=false,
    postbreak=\space,
    showstringspaces=false,
}
\lstinputlisting[firstline=161, lastline=200, language=Markdown]{assets/markdowns/verification.md} % Adjust line numbers
\end{tcolorbox}
\caption{Prompt for verifying claims with GPT-4o (Part 6)}
\label{fig:verification-prompt-6}
\end{figure*}


% Begin new figure -----
\begin{figure*}[htbp]
\centering
\begin{tcolorbox}[colback=gray!5!white, colframe=black, title=Prompt for Generating Book-level Claims in \naive]
\lstset{
    basicstyle=\ttfamily\footnotesize,
    breaklines=true,
    frame=none,
    xleftmargin=0pt,
    framexleftmargin=0pt,
    columns=fullflexible,
    tabsize=1,
    breakindent=0pt,
    breakautoindent=false,
    postbreak=\space,
    showstringspaces=false,
}
\lstinputlisting[language=Markdown]{assets/markdowns/extraction_alt_multiple.md}
\end{tcolorbox}
\caption{Prompt for generating book-level claims in \naive.}
\label{fig:book-alt}
\end{figure*}


% Begin new figure -----
\begin{figure*}[htbp]
\centering
\begin{tcolorbox}[colback=gray!5!white, colframe=black, title=Prompt for Generating Chapter-level Claims in \naive]
\lstset{
    basicstyle=\ttfamily\footnotesize,
    breaklines=true,
    frame=none,
    xleftmargin=0pt,
    framexleftmargin=0pt,
    columns=fullflexible,
    tabsize=1,
    breakindent=0pt,
    breakautoindent=false,
    postbreak=\space,
    showstringspaces=false,
}
\lstinputlisting[language=Markdown]{assets/markdowns/extraction_alt_single.md}
\end{tcolorbox}
\caption{Prompt for generating chapter-level claims in \naive.}
\label{fig:chapter-alt}
\end{figure*}


\subsection{Using DeepSeek-Distill to measure CoT groundedness} 
\label{appendix:deepseek-cot}
We evaluate the model on 66 annotated claims from \S\ref{data:claim_validation} and measure its agreement with human annotations (Table \ref{tab:judge_agreement}). Among the models tested, DeepSeek-Distill aligns most closely with human judgments, with only one instance of disagreement, outperforming other models like GPT-4o (10 disagreements) and LLaMA-3.1-70B-Instruct (3 disagreements). Although Llama-70B performs comparably, it fails to provide clear explanations for its decisions and instead generating generic reasoning messages that lack specificity to samples. Therefore, we use DeepSeek-Distill to measure CoT groundedness in our dataset.

\begin{table}[htbp]
    \small
    \centering
    \begin{tabular}{lc}
        \toprule
        Judge Models & \% Agreement \\
        \midrule
        GPT-4o & 84.8\% \\
        Llama-3.1-70b-Instruct & 95.5\% \\
        DeepSeek-Distill-Llama-70B & 98.5\%\\
         \bottomrule
    \end{tabular}
    \caption{Percentage of times LLM judges for chain of thought groundedness agree with our manual annotation over 66 samples in Section \ref{data:claim_validation}.}
    \label{tab:judge_agreement}
\end{table}