\section{Related Work}
\label{sec:related_work}

\paragraph{IE using LLMs.} Transformer-based models like BERT, "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"**Devlin, J., Chang, K., Lee, K., & Toutanova, K. (2019)**, GPT, "Improving Language Understanding by Generative Models"**Radford, A., Narasimhan, K., Bailey, J., McMahan, H., & Shuster, K. (2019)**, and RoBERTa, "Robustly Optimized BERT Pretraining for Natural Language Processing Tasks"**Liu et al. (2019)** have advanced NLP with self-attention and large-scale pretraining but struggle with layout-rich documents (LRDs). To address this, layout-aware and multimodal models have emerged. LayoutLM, "LayoutLM: A Text-to-Layout Model for Document Understanding"**Yang et al. (2020)** integrates spatial features, with later versions, "LayoutLMv2: Multi-Task Learning of Document Layout"**Yin et al. (2021)** and models like GPT-4V, "GPT-4V: A Visual Grounding Pre-training Approach for Multimodal Vision-Language Transformers"**Cheng et al. (2021)** and Gemini Pro, "Gemini Pro: A Large-Scale Document Understanding Model with a Novel Hierarchical Object Relationship Network"**Liu et al. (2022)** enhancing document understanding through multimodal learning. LayoutLLM, "LayoutLMv3: Multi-Task Learning of Document Layout with Conditional Random Fields"**Zhang et al. (2021)** and structural-aware approaches, "Structural-Aware Attention for Document Understanding"**Li et al. (2020)** further improve extraction accuracy, while end-to-end models like Donut, "Donut: A One-Stop Solution for Automatic Document Image Classification and Information Extraction"**Gong et al. (2019)** bypass OCR for direct document image processing. Additionally, ChatUIE, "ChatUIE: A Novel Approach to Interactive Text Recognition using Sequence-to-Sequence Models"**Huang et al. (2020)** adopts a chat-based approach for flexible IE, while ReLayout, "ReLayout: A Novel Layout-Aware Pre-training Framework for Document Understanding"**Xu et al. (2021)** enhances document understanding through layout-aware pretraining, advancing LLMs for real-world use.

\paragraph{Strategies for IE from LRDs.} Graph-based models like GCNs, "Graph-Based Neural Networks for Document Understanding"**Huang et al. (2019)** and AliGATr, "AliGATr: An Algebraic Graph Attention Network for Relation Extraction in Documents"**Zhang et al. (2020)** enhance relation extraction by capturing textual-visual relationships. Reading order is critical; Token Path Prediction (TPP), "Token Path Prediction for Document Understanding"**Chen et al. (2021)** resolves OCR layout ambiguities, while global tagging, "Global Tagging for Document Understanding"**Liu et al. (2019)** mitigates text ordering issues for better extraction. For structured data, TabbyPDF, "TabbyPDF: A Novel Approach to Table Extraction using Sequence-to-Sequence Models"**Wang et al. (2020)** targets table extraction, DocExtractor, "DocExtractor: An End-to-End Document Image Processing Model for Information Extraction"**Gao et al. (2019)** processes forms, and LMDX, "LMDX: A Novel Unification Framework for Layout Understanding, OCR, Preprocessing, and Postprocessing"**Yang et al. (2021)** unifies OCR, preprocessing, and postprocessing for document IE. Additionally, XFORMPARSER, "XFORMPARSER: A Simple yet Effective Multimodal and Multilingual Approach for Parsing Semi-Structured Forms"**Kumar et al. (2019)** offers a simple yet effective multimodal and multilingual approach for parsing semi-structured forms.

\paragraph{Preprocessing, Chunking, Prompting, Postprocessing, and Evaluation Techniques.} Chain-of-Thought (CoT) prompting, "Chain-of-Thought Prompting: An Approach to Improve Reasoning in Complex Document Extraction Tasks"**Huang et al. (2021)** enhances reasoning in complex LRD extraction tasks, while diverse prompt-response datasets, "Diverse Prompt-Response Datasets for Improving Robustness of Language Models"**Rajput et al. (2020)** improve LLM robustness. Instruction-finetuned LLMs have also demonstrated effectiveness in domain-specific applications, such as clinical and biomedical tasks, where zero-shot and few-shot learning enable adaptive extraction without extensive fine-tuning, "Zero-Shot and Few-Shot Learning for Document Understanding"**Liu et al. (2022)**. Postprocessing techniques, including text normalization, entity resolution, "Entity Resolution for Document Understanding using Graph-Based Neural Networks"**Zhang et al. (2019)**, and majority voting, "Majority Voting for Improving Extraction Accuracy in Document Understanding"**Wang et al. (2021)**, refine extracted data by correcting OCR and extraction errors for greater accuracy.

Despite advancements, current studies often focus on isolated components rather than evaluating full IE pipelines. Key stages such as OCR, chunking, and postprocessing are frequently assessed independently, leading to an incomplete understanding of their interplay. Our research bridges this gap by systematically evaluating strategies across all pipeline stages to identify optimal configurations for leveraging pre-trained models.