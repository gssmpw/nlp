@inproceedings{papineni2002bleu,
  title={Bleu: a method for automatic evaluation of machine translation},
  author={Papineni, Kishore and Roukos, Salim and Ward, Todd and Zhu, Wei-Jing},
  booktitle={Proceedings of the 40th annual meeting of the Association for Computational Linguistics},
  pages={311--318},
  year={2002}
}
@inproceedings{lin2004rouge,
  title={Rouge: A package for automatic evaluation of summaries},
  author={Lin, Chin-Yew},
  booktitle={Text summarization branches out},
  pages={74--81},
  year={2004}
}
@article{yang2018adaptations,
  title={Adaptations of ROUGE and BLEU to better evaluate machine reading comprehension task},
  author={Yang, An and Liu, Kai and Liu, Jing and Lyu, Yajuan and Li, Sujian},
  journal={arXiv preprint arXiv:1806.03578},
  year={2018}
}

@inproceedings{park2019cord,
  title={CORD: a consolidated receipt dataset for post-OCR parsing},
  author={Park, Seunghyun and Shin, Seung and Lee, Bado and Lee, Junyeop and Surh, Jaeheung and Seo, Minjoon and Lee, Hwalsuk},
  booktitle={Workshop on Document Intelligence at NeurIPS 2019},
  year={2019}
}

@article{xu2024hallucination,
  title={Hallucination is inevitable: An innate limitation of large language models},
  author={Xu, Ziwei and Jain, Sanjay and Kankanhalli, Mohan},
  journal={arXiv preprint arXiv:2401.11817},
  year={2024}
}

@inproceedings{furst2023versamatch,
  title={Versamatch: ontology matching with weak supervision},
  author={F{\"u}rst, Jonathan and Fadel Argerich, Mauricio and Cheng, Bin},
  booktitle={49th Conference on Very Large Data Bases (VLDB), Vancouver, Canada, 28 August-1 September 2023},
  volume={16},
  number={6},
  pages={1305--1318},
  year={2023},
  organization={Association for Computing Machinery}
}


@article{ji2023survey,
  title={Survey of hallucination in natural language generation},
  author={Ji, Ziwei and Lee, Nayeon and Frieske, Rita and Yu, Tiezheng and Su, Dan and Xu, Yan and Ishii, Etsuko and Bang, Ye Jin and Madotto, Andrea and Fung, Pascale},
  journal={ACM Computing Surveys},
  volume={55},
  number={12},
  pages={1--38},
  year={2023},
  publisher={ACM New York, NY}}

@article{huang2023survey,
  title={A survey on hallucination in large language models: Principles, taxonomy, challenges, and open questions},
  author={Huang, Lei and Yu, Weijiang and Ma, Weitao and Zhong, Weihong and Feng, Zhangyin and Wang, Haotian and Chen, Qianglong and Peng, Weihua and Feng, Xiaocheng and Qin, Bing and others},
  journal={arXiv preprint arXiv:2311.05232},
  year={2023}
}



@inproceedings{dong2013big,
  title={Big data integration},
  author={Dong, Xin Luna and Srivastava, Divesh},
  booktitle={2013 IEEE 29th international conference on data engineering (ICDE)},
  pages={1245--1248},
  year={2013},
  organization={IEEE}
}


@inproceedings{Wang_2023, series={KDD ’23},
   title={VRDU: A Benchmark for Visually-rich Document Understanding},
   url={http://dx.doi.org/10.1145/3580305.3599929},
   DOI={10.1145/3580305.3599929},
   booktitle={Proceedings of the 29th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
   publisher={ACM},
   author={Wang, Zilong and Zhou, Yichao and Wei, Wei and Lee, Chen-Yu and Tata, Sandeep},
   year={2023},
   month=aug, collection={KDD ’23} }

@article{liu2024lost,
  title={Lost in the middle: How language models use long contexts},
  author={Liu, Nelson F and Lin, Kevin and Hewitt, John and Paranjape, Ashwin and Bevilacqua, Michele and Petroni, Fabio and Liang, Percy},
  journal={Transactions of the Association for Computational Linguistics},
  volume={12},
  pages={157--173},
  year={2024},
  publisher={MIT Press One Broadway, 12th Floor, Cambridge, Massachusetts 02142, USA~…}
}


@misc{zmigrod2024buddiebusinessdocumentdataset,
      title={BuDDIE: A Business Document Dataset for Multi-task Information Extraction}, 
      author={Ran Zmigrod and Dongsheng Wang and Mathieu Sibue and Yulong Pei and Petr Babkin and Ivan Brugere and Xiaomo Liu and Nacho Navarro and Antony Papadimitriou and William Watson and Zhiqiang Ma and Armineh Nourbakhsh and Sameena Shah},
      year={2024},
      eprint={2404.04003},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2404.04003}, 
}

@article{cui2021document,
  title={Document ai: Benchmarks, models and applications},
  author={Cui, Lei and Xu, Yiheng and Lv, Tengchao and Wei, Furu},
  journal={arXiv preprint arXiv:2111.08609},
  year={2021}
}

@inproceedings{tang2023unifying,
  title={Unifying vision, text, and layout for universal document processing},
  author={Tang, Zineng and Yang, Ziyi and Wang, Guoxin and Fang, Yuwei and Liu, Yang and Zhu, Chenguang and Zeng, Michael and Zhang, Cha and Bansal, Mohit},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={19254--19264},
  year={2023}
}

@inproceedings{arif-etal-2024-generalists,
    title = "Generalists vs. Specialists: Evaluating Large Language Models for {U}rdu",
    author = "Arif, Samee  and
      Azeemi, Abdul Hameed  and
      Raza, Agha Ali  and
      Athar, Awais",
    editor = "Al-Onaizan, Yaser  and
      Bansal, Mohit  and
      Chen, Yun-Nung",
    booktitle = "Findings of the Association for Computational Linguistics: EMNLP 2024",
    month = nov,
    year = "2024",
    address = "Miami, Florida, USA",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2024.findings-emnlp.426/",
    doi = "10.18653/v1/2024.findings-emnlp.426",
    pages = "7263--7280"
}

@inproceedings{shi-etal-2023-specialist,
    title = "Specialist or Generalist? Instruction Tuning for Specific {NLP} Tasks",
    author = "Shi, Chufan  and
      Su, Yixuan  and
      Yang, Cheng  and
      Yang, Yujiu  and
      Cai, Deng",
    editor = "Bouamor, Houda  and
      Pino, Juan  and
      Bali, Kalika",
    booktitle = "Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing",
    month = dec,
    year = "2023",
    address = "Singapore",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.emnlp-main.947/",
    doi = "10.18653/v1/2023.emnlp-main.947",
    pages = "15336--15348",
    abstract = "The potential of large language models (LLMs) to simultaneously perform a wide range of natural language processing (NLP) tasks has been the subject of extensive research. Although instruction tuning has proven to be a data-efficient method for transforming LLMs into such generalist models, their performance still lags behind specialist models trained exclusively for specific tasks. In this paper, we investigate whether incorporating broadcoverage generalist instruction tuning can contribute to building a specialist model. We hypothesize that its efficacy depends on task specificity and skill requirements. Our experiments assess four target tasks with distinct coverage levels, revealing that integrating generalist instruction tuning consistently enhances model performance when the task coverage is broad. The effect is particularly pronounced when the amount of task-specific training data is limited. Further investigation into three target tasks focusing on different capabilities demonstrates that generalist instruction tuning improves understanding and reasoning abilities. However, for tasks requiring factual knowledge, generalist data containing hallucinatory information may negatively affect the model`s performance. Overall, our work provides a systematic guide for developing specialist models with general instruction tuning."
}

@book{jm3,
  author    = {Daniel Jurafsky and James H. Martin},
  title     = {Speech and Language Processing: An Introduction to Natural Language Processing, Computational Linguistics, and Speech Recognition with Language Models},
  year      = {2025},
  url       = {https://web.stanford.edu/~jurafsky/slp3/},
  note      = {Online manuscript released January 12, 2025},
  edition   = {3rd}
}

@book{manning1999foundations,
  title={Foundations of statistical natural language processing},
  author={Manning, Christopher and Schutze, Hinrich},
  year={1999},
  publisher={MIT press}
}

@inproceedings{grishman1997information,
  title={Information extraction: Techniques and challenges},
  author={Grishman, Ralph},
  booktitle={Information Extraction A Multidisciplinary Approach to an Emerging Information Technology: International Summer School, SCIE-97 Frascati, Italy, July 14--18, 1997},
  pages={10--27},
  year={1997},
  organization={Springer}
}

@article{sarawagi2008information,
  title={Information extraction},
  author={Sarawagi, Sunita and others},
  journal={Foundations and Trends{\textregistered} in Databases},
  volume={1},
  number={3},
  pages={261--377},
  year={2008},
  publisher={Now Publishers, Inc.}
}



@inproceedings{xu2020layoutlm,
  title={Layoutlm: Pre-training of text and layout for document image understanding},
  author={Xu, Yiheng and Li, Minghao and Cui, Lei and Huang, Shaohan and Wei, Furu and Zhou, Ming},
  booktitle={Proceedings of the 26th ACM SIGKDD international conference on knowledge discovery \& data mining},
  pages={1192--1200},
  year={2020}
}

@article{xu2020layoutlmv2,
  title={Layoutlmv2: Multi-modal pre-training for visually-rich document understanding},
  author={Xu, Yang and Xu, Yiheng and Lv, Tengchao and Cui, Lei and Wei, Furu and Wang, Guoxin and Lu, Yijuan and Florencio, Dinei and Zhang, Cha and Che, Wanxiang and others},
  journal={arXiv preprint arXiv:2012.14740},
  year={2020}
}







@inproceedings{tian2016detecting,
  title={Detecting text in natural image with connectionist text proposal network},
  author={Tian, Zhi and Huang, Weilin and He, Tong and He, Pan and Qiao, Yu},
  booktitle={Computer Vision--ECCV 2016: 14th European Conference, Amsterdam, The Netherlands, October 11-14, 2016, Proceedings, Part VIII 14},
  pages={56--72},
  year={2016},
  organization={Springer}
}

@article{liao2018textboxes++,
  title={Textboxes++: A single-shot oriented scene text detector},
  author={Liao, Minghui and Shi, Baoguang and Bai, Xiang},
  journal={IEEE transactions on image processing},
  volume={27},
  number={8},
  pages={3676--3690},
  year={2018},
  publisher={IEEE}
}

@inproceedings{zhou2017east,
  title={East: an efficient and accurate scene text detector},
  author={Zhou, Xinyu and Yao, Cong and Wen, He and Wang, Yuzhi and Zhou, Shuchang and He, Weiran and Liang, Jiajun},
  booktitle={Proceedings of the IEEE conference on Computer Vision and Pattern Recognition},
  pages={5551--5560},
  year={2017}
}

@inproceedings{bhadauria-etal-2024-effects,
    title = "The Effects of Data Quality on Named Entity Recognition",
    author = "Bhadauria, Divya  and
      Sierra M{\'u}nera, Alejandro  and
      Krestel, Ralf",
    editor = {van der Goot, Rob  and
      Bak, JinYeong  and
      M{\"u}ller-Eberstein, Max  and
      Xu, Wei  and
      Ritter, Alan  and
      Baldwin, Tim},
    booktitle = "Proceedings of the Ninth Workshop on Noisy and User-generated Text (W-NUT 2024)",
    month = mar,
    year = "2024",
    address = "San {\.{G}}iljan, Malta",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2024.wnut-1.8/",
    pages = "79--88",
    abstract = "The extraction of valuable information from the vast amount of digital data available today has become increasingly important, making Named Entity Recognition models an essential component of information extraction tasks. This emphasizes the importance of understanding the factors that can compromise the performance of these models. Many studies have examined the impact of data annotation errors on NER models, leaving the broader implication of overall data quality on these models unexplored. In this work, we evaluate the robustness of three prominent NER models on datasets with varying amounts of textual noise types. The results show that as the noise in the dataset increases, model performance declines, with a minor impact for some noise types and a significant drop in performance for others. The findings of this research can be used as a foundation for building robust NER systems by enhancing dataset quality beforehand."
}

@misc{lee2022formnetstructuralencodingsequential,
      title={FormNet: Structural Encoding beyond Sequential Modeling in Form Document Information Extraction}, 
      author={Chen-Yu Lee and Chun-Liang Li and Timothy Dozat and Vincent Perot and Guolong Su and Nan Hua and Joshua Ainslie and Renshen Wang and Yasuhisa Fujii and Tomas Pfister},
      year={2022},
      eprint={2203.08411},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2203.08411}, 
}

@article{li2020docbank,
  title={DocBank: A benchmark dataset for document layout analysis},
  author={Li, Minghao and Xu, Yiheng and Cui, Lei and Huang, Shaohan and Wei, Furu and Li, Zhoujun and Zhou, Ming},
  journal={arXiv preprint arXiv:2006.01038},
  year={2020}
}

@inproceedings{zhong2019publaynet,
  title={Publaynet: largest dataset ever for document layout analysis},
  author={Zhong, Xu and Tang, Jianbin and Yepes, Antonio Jimeno},
  booktitle={2019 International conference on document analysis and recognition (ICDAR)},
  pages={1015--1022},
  year={2019},
  organization={IEEE}
}

@article{verga2020facts,
  title={Facts as experts: Adaptable and interpretable neural memory over symbolic knowledge},
  author={Verga, Pat and Sun, Haitian and Soares, Livio Baldini and Cohen, William W},
  journal={arXiv preprint arXiv:2007.00849},
  year={2020}
}

@article{yao2019docred,
  title={DocRED: A large-scale document-level relation extraction dataset},
  author={Yao, Yuan and Ye, Deming and Li, Peng and Han, Xu and Lin, Yankai and Liu, Zhenghao and Liu, Zhiyuan and Huang, Lixin and Zhou, Jie and Sun, Maosong},
  journal={arXiv preprint arXiv:1906.06127},
  year={2019}
}

@inproceedings{powalski2021going,
  title={Going full-tilt boogie on document understanding with text-image-layout transformer},
  author={Powalski, Rafa{\l} and Borchmann, {\L}ukasz and Jurkiewicz, Dawid and Dwojak, Tomasz and Pietruszka, Micha{\l} and Pa{\l}ka, Gabriela},
  booktitle={Document Analysis and Recognition--ICDAR 2021: 16th International Conference, Lausanne, Switzerland, September 5--10, 2021, Proceedings, Part II 16},
  pages={732--747},
  year={2021},
  organization={Springer}
}

@article{beltagy2020longformer,
  title={Longformer: The long-document transformer},
  author={Beltagy, Iz and Peters, Matthew E and Cohan, Arman},
  journal={arXiv preprint arXiv:2004.05150},
  year={2020}
}

@article{zaheer2020big,
  title={Big bird: Transformers for longer sequences},
  author={Zaheer, Manzil and Guruganesh, Guru and Dubey, Kumar Avinava and Ainslie, Joshua and Alberti, Chris and Ontanon, Santiago and Pham, Philip and Ravula, Anirudh and Wang, Qifan and Yang, Li and others},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={17283--17297},
  year={2020}
}

@inproceedings{li2020oscar,
  title={Oscar: Object-semantics aligned pre-training for vision-language tasks},
  author={Li, Xiujun and Yin, Xi and Li, Chunyuan and Zhang, Pengchuan and Hu, Xiaowei and Zhang, Lei and Wang, Lijuan and Hu, Houdong and Dong, Li and Wei, Furu and others},
  booktitle={Computer Vision--ECCV 2020: 16th European Conference, Glasgow, UK, August 23--28, 2020, Proceedings, Part XXX 16},
  pages={121--137},
  year={2020},
  organization={Springer}
}

@article{zhang2022multimodal,
  title={Multimodal pre-training based on graph attention network for document understanding},
  author={Zhang, Zhenrong and Ma, Jiefeng and Du, Jun and Wang, Licheng and Zhang, Jianshu},
  journal={IEEE Transactions on Multimedia},
  volume={25},
  pages={6743--6755},
  year={2022},
  publisher={IEEE}
}

@article{velickovic2017graph,
  title={Graph attention networks},
  author={Velickovic, Petar and Cucurull, Guillem and Casanova, Arantxa and Romero, Adriana and Lio, Pietro and Bengio, Yoshua and others},
  journal={stat},
  volume={1050},
  number={20},
  pages={10--48550},
  year={2017}
}

@article{kipf2016semi,
  title={Semi-supervised classification with graph convolutional networks},
  author={Kipf, Thomas N and Welling, Max},
  journal={arXiv preprint arXiv:1609.02907},
  year={2016}
}

@article{devlin2018bert,
  title={Bert: Pre-training of deep bidirectional transformers for language understanding},
  author={Devlin, Jacob},
  journal={arXiv preprint arXiv:1810.04805},
  year={2018}
}

@article{radford2019language,
  title={Language models are unsupervised multitask learners},
  author={Radford, Alec and Wu, Jeffrey and Child, Rewon and Luan, David and Amodei, Dario and Sutskever, Ilya and others},
  journal={OpenAI blog},
  volume={1},
  number={8},
  pages={9},
  year={2019}
}

@article{brown2020language,
  title={Language models are few-shot learners},
  author={Brown, Tom and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared D and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and others},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={1877--1901},
  year={2020}
}

@article{gao2020making,
  title={Making pre-trained language models better few-shot learners},
  author={Gao, Tianyu and Fisch, Adam and Chen, Danqi},
  journal={arXiv preprint arXiv:2012.15723},
  year={2020}
}

@article{wei2022chain,
  title={Chain-of-thought prompting elicits reasoning in large language models},
  author={Wei, Jason and Wang, Xuezhi and Schuurmans, Dale and Bosma, Maarten and Xia, Fei and Chi, Ed and Le, Quoc V and Zhou, Denny and others},
  journal={Advances in neural information processing systems},
  volume={35},
  pages={24824--24837},
  year={2022}
}

@article{raffel2020exploring,
  title={Exploring the limits of transfer learning with a unified text-to-text transformer},
  author={Raffel, Colin and Shazeer, Noam and Roberts, Adam and Lee, Katherine and Narang, Sharan and Matena, Michael and Zhou, Yanqi and Li, Wei and Liu, Peter J},
  journal={Journal of machine learning research},
  volume={21},
  number={140},
  pages={1--67},
  year={2020}
}

@article{ouyang2022training,
  title={Training language models to follow instructions with human feedback},
  author={Ouyang, Long and Wu, Jeffrey and Jiang, Xu and Almeida, Diogo and Wainwright, Carroll and Mishkin, Pamela and Zhang, Chong and Agarwal, Sandhini and Slama, Katarina and Ray, Alex and others},
  journal={Advances in neural information processing systems},
  volume={35},
  pages={27730--27744},
  year={2022}
}

@article{kasneci2023chatgpt,
  title={ChatGPT for good? On opportunities and challenges of large language models for education},
  author={Kasneci, Enkelejda and Se{\ss}ler, Kathrin and K{\"u}chemann, Stefan and Bannert, Maria and Dementieva, Daryna and Fischer, Frank and Gasser, Urs and Groh, Georg and G{\"u}nnemann, Stephan and H{\"u}llermeier, Eyke and others},
  journal={Learning and individual differences},
  volume={103},
  pages={102274},
  year={2023},
  publisher={Elsevier}
}

@article{chung2024scaling,
  title={Scaling instruction-finetuned language models},
  author={Chung, Hyung Won and Hou, Le and Longpre, Shayne and Zoph, Barret and Tay, Yi and Fedus, William and Li, Yunxuan and Wang, Xuezhi and Dehghani, Mostafa and Brahma, Siddhartha and others},
  journal={Journal of Machine Learning Research},
  volume={25},
  number={70},
  pages={1--53},
  year={2024}
}

@article{touvron2023llama,
  title={Llama: Open and efficient foundation language models},
  author={Touvron, Hugo and Lavril, Thibaut and Izacard, Gautier and Martinet, Xavier and Lachaux, Marie-Anne and Lacroix, Timoth{\'e}e and Rozi{\`e}re, Baptiste and Goyal, Naman and Hambro, Eric and Azhar, Faisal and others},
  journal={arXiv preprint arXiv:2302.13971},
  year={2023}
}

@misc{openai2024gpt4technicalreport,
      title={GPT-4 Technical Report}, 
      author={OpenAI and Achiam, Josh and Adler, Steven and Agarwal, Sandhini and Ahmad, Lama and Akkaya, Ilge and Aleman, Florencia Leoni and Almeida, Diogo and Altenschmidt, Janko and Altman, Sam and Anadkat, Shyamal and others},
      year={2024},
      eprint={2303.08774},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2303.08774}, 
}

@inproceedings{huang2022layoutlmv3,
  title={Layoutlmv3: Pre-training for document ai with unified text and image masking},
  author={Huang, Yupan and Lv, Tengchao and Cui, Lei and Lu, Yutong and Wei, Furu},
  booktitle={Proceedings of the 30th ACM International Conference on Multimedia},
  pages={4083--4091},
  year={2022}
}

@inproceedings{hong2022bros,
  title={Bros: A pre-trained language model focusing on text and layout for better key information extraction from documents},
  author={Hong, Teakgyu and Kim, Donghyun and Ji, Mingi and Hwang, Wonseok and Nam, Daehyun and Park, Sungrae},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={36},
  pages={10767--10775},
  year={2022}
}

@inproceedings{radford2021learning,
  title={Learning transferable visual models from natural language supervision},
  author={Radford, Alec and Kim, Jong Wook and Hallacy, Chris and Ramesh, Aditya and Goh, Gabriel and Agarwal, Sandhini and Sastry, Girish and Askell, Amanda and Mishkin, Pamela and Clark, Jack and others},
  booktitle={International conference on machine learning},
  pages={8748--8763},
  year={2021},
  organization={PMLR}
}

@article{zhou2022least,
  title={Least-to-most prompting enables complex reasoning in large language models},
  author={Zhou, Denny and Sch{\"a}rli, Nathanael and Hou, Le and Wei, Jason and Scales, Nathan and Wang, Xuezhi and Schuurmans, Dale and Cui, Claire and Bousquet, Olivier and Le, Quoc and others},
  journal={arXiv preprint arXiv:2205.10625},
  year={2022}
}

@misc{luo2024asgeaexploitinglogicrules,
      title={ASGEA: Exploiting Logic Rules from Align-Subgraphs for Entity Alignment}, 
      author={Yangyifei Luo and Zhuo Chen and Lingbing Guo and Qian Li and Wenxuan Zeng and Zhixin Cai and Jianxin Li},
      year={2024},
      eprint={2402.11000},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2402.11000}, 
}

@inproceedings{smith2007overview,
  title={An overview of the Tesseract OCR engine},
  author={Smith, Ray},
  booktitle={Ninth international conference on document analysis and recognition (ICDAR 2007)},
  volume={2},
  pages={629--633},
  year={2007},
  organization={IEEE}
}

@inproceedings{mieskes-schmunk-2019-ocr,
    title = "{OCR} Quality and {NLP} Preprocessing",
    author = "Mieskes, Margot  and
      Schmunk, Stefan",
    editor = "Axelrod, Amittai  and
      Yang, Diyi  and
      Cunha, Rossana  and
      Shaikh, Samira  and
      Waseem, Zeerak",
    booktitle = "Proceedings of the 2019 Workshop on Widening NLP",
    month = aug,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/W19-3633/",
    pages = "102--105",
    abstract = "We present initial experiments to evaluate the performance of tasks such as Part of Speech Tagging on data corrupted by Optical Character Recognition (OCR). Our results, based on English and German data, using artificial experiments as well as initial real OCRed data indicate that already a small drop in OCR quality considerably increases the error rates, which would have a significant impact on subsequent processing steps."
}

@inproceedings{cheng-etal-2025-xformparser,
    title = "{XF}orm{P}arser: A Simple and Effective Multimodal Multilingual Semi-structured Form Parser",
    author = "Cheng, Xianfu  and
      Zhang, Hang  and
      Yang, Jian  and
      Li, Xiang  and
      Zhou, Weixiao  and
      Liu, Fei  and
      Wu, Kui  and
      Guan, Xiangyuan  and
      Sun, Tao  and
      Wu, Xianjie  and
      Li, Tongliang  and
      Li, Zhoujun",
    editor = "Rambow, Owen  and
      Wanner, Leo  and
      Apidianaki, Marianna  and
      Al-Khalifa, Hend  and
      Eugenio, Barbara Di  and
      Schockaert, Steven",
    booktitle = "Proceedings of the 31st International Conference on Computational Linguistics",
    month = jan,
    year = "2025",
    address = "Abu Dhabi, UAE",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2025.coling-main.41/",
    pages = "606--620",
    abstract = "In the domain of Document AI, parsing semi-structured image form is a crucial Key Information Extraction (KIE) task. The advent of pre-trained multimodal models significantly empowers Document AI frameworks to extract key information from form documents in different formats such as PDF, Word, and images. Nonetheless, form parsing is still encumbered by notable challenges like subpar capabilities in multilingual parsing and diminished recall in industrial contexts in rich text and rich visuals. In this work, we introduce a simple but effective Multimodal and Multilingual semi-structured FORM PARSER (XFormParser), which is anchored on a comprehensive Transformer-based pre-trained language model and innovatively amalgamates semantic entity recognition (SER) and relation extraction (RE) into a unified framework. Combined with Bi-LSTM, the performance of multilingual parsing is significantly improved. Furthermore, we develop InDFormSFT, a pioneering supervised fine-tuning (SFT) industrial dataset that specifically addresses the parsing needs of forms in a variety of industrial contexts. Through rigorous testing on established benchmarks, XFormParser has demonstrated its unparalleled effectiveness and robustness. Compared to existing state-of-the-art (SOTA) models, XFormParser notably achieves up to 1.79{\%} F1 score improvement on RE tasks in language-specific settings. It also exhibits exceptional improvements in cross-task performance in both multilingual and zero-shot settings."
}

@inproceedings{xu-etal-2024-chatuie,
    title = "{C}hat{UIE}: Exploring Chat-based Unified Information Extraction Using Large Language Models",
    author = "Xu, Jun  and
      Sun, Mengshu  and
      Zhang, Zhiqiang  and
      Zhou, Jun",
    editor = "Calzolari, Nicoletta  and
      Kan, Min-Yen  and
      Hoste, Veronique  and
      Lenci, Alessandro  and
      Sakti, Sakriani  and
      Xue, Nianwen",
    booktitle = "Proceedings of the 2024 Joint International Conference on Computational Linguistics, Language Resources and Evaluation (LREC-COLING 2024)",
    month = may,
    year = "2024",
    address = "Torino, Italia",
    publisher = "ELRA and ICCL",
    url = "https://aclanthology.org/2024.lrec-main.279/",
    pages = "3146--3152",
    abstract = "Recent advancements in large language models have shown impressive performance in general chat. However, their domain-specific capabilities, particularly in information extraction, have certain limitations. Extracting structured information from natural language that deviates from known schemas or instructions has proven challenging for previous prompt-based methods. This motivated us to explore domain-specific modeling in chat-based language models as a solution for extracting structured information from natural language. In this paper, we present ChatUIE, an innovative unified information extraction framework built upon ChatGLM. Simultaneously, reinforcement learning is employed to improve and align various tasks that involve confusing and limited samples. Furthermore, we integrate generation constraints to address the issue of generating elements that are not present in the input. Our experimental results demonstrate that ChatUIE can significantly improve the performance of information extraction with a slight decrease in chatting ability."
}

@inproceedings{jiang-etal-2025-relayout,
    title = "{R}e{L}ayout: Towards Real-World Document Understanding via Layout-enhanced Pre-training",
    author = "Jiang, Zhouqiang  and
      Wang, Bowen  and
      Chen, Junhao  and
      Nakashima, Yuta",
    editor = "Rambow, Owen  and
      Wanner, Leo  and
      Apidianaki, Marianna  and
      Al-Khalifa, Hend  and
      Eugenio, Barbara Di  and
      Schockaert, Steven",
    booktitle = "Proceedings of the 31st International Conference on Computational Linguistics",
    month = jan,
    year = "2025",
    address = "Abu Dhabi, UAE",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2025.coling-main.255/",
    pages = "3778--3793",
    abstract = "Recent approaches for visually-rich document understanding (VrDU) uses manually annotated semantic groups, where a semantic group encompasses all semantically relevant but not obviously grouped words. As OCR tools are unable to automatically identify such grouping, we argue that current VrDU approaches are unrealistic. We thus introduce a new variant of the VrDU task, real-world visually-rich document understanding (ReVrDU), that does not allow for using manually annotated semantic groups. We also propose a new method, ReLayout, compliant with the ReVrDU scenario, which learns to capture semantic grouping through arranging words and bringing the representations of words that belong to the potential same semantic group closer together. Our experimental results demonstrate the performance of existing methods is deteriorated with the ReVrDU task, while ReLayout shows superiour performance."
}

@inproceedings{labrak-etal-2024-zero,
    title = "A Zero-shot and Few-shot Study of Instruction-Finetuned Large Language Models Applied to Clinical and Biomedical Tasks",
    author = "Labrak, Yanis  and
      Rouvier, Mickael  and
      Dufour, Richard",
    editor = "Calzolari, Nicoletta  and
      Kan, Min-Yen  and
      Hoste, Veronique  and
      Lenci, Alessandro  and
      Sakti, Sakriani  and
      Xue, Nianwen",
    booktitle = "Proceedings of the 2024 Joint International Conference on Computational Linguistics, Language Resources and Evaluation (LREC-COLING 2024)",
    month = may,
    year = "2024",
    address = "Torino, Italia",
    publisher = "ELRA and ICCL",
    url = "https://aclanthology.org/2024.lrec-main.185/",
    pages = "2049--2066",
    abstract = "The recent emergence of Large Language Models (LLMs) has enabled significant advances in the field of Natural Language Processing (NLP). While these new models have demonstrated superior performance on various tasks, their application and potential are still underexplored, both in terms of the diversity of tasks they can handle and their domain of application. In this context, we evaluate four state-of-the-art instruction-tuned LLMs (ChatGPT, Flan-T5 UL2, Tk-Instruct, and Alpaca) on a set of 13 real-world clinical and biomedical NLP tasks in English, including named-entity recognition (NER), question-answering (QA), relation extraction (RE), and more. Our overall results show that these evaluated LLMs approach the performance of state-of-the-art models in zero- and few-shot scenarios for most tasks, particularly excelling in the QA task, even though they have never encountered examples from these tasks before. However, we also observe that the classification and RE tasks fall short of the performance achievable with specifically trained models designed for the medical field, such as PubMedBERT. Finally, we note that no single LLM outperforms all others across all studied tasks, with some models proving more suitable for certain tasks than others."
}

@inproceedings{bai-etal-2024-schema,
    title = "Schema-Driven Information Extraction from Heterogeneous Tables",
    author = "Bai, Fan  and
      Kang, Junmo  and
      Stanovsky, Gabriel  and
      Freitag, Dayne  and
      Dredze, Mark  and
      Ritter, Alan",
    editor = "Al-Onaizan, Yaser  and
      Bansal, Mohit  and
      Chen, Yun-Nung",
    booktitle = "Findings of the Association for Computational Linguistics: EMNLP 2024",
    month = nov,
    year = "2024",
    address = "Miami, Florida, USA",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2024.findings-emnlp.600/",
    doi = "10.18653/v1/2024.findings-emnlp.600",
    pages = "10252--10273",
    abstract = "In this paper, we explore the question of whether large language models can support cost-efficient information extraction from tables. We introduce schema-driven information extraction, a new task that transforms tabular data into structured records following a human-authored schema. To assess various LLM`s capabilities on this task, we present a benchmark comprised of tables from four diverse domains: machine learning papers, chemistry literature, material science journals, and webpages. We use this collection of annotated tables to evaluate the ability of open-source and API-based language models to extract information from tables covering diverse domains and data formats. Our experiments demonstrate that surprisingly competitive performance can be achieved without requiring task-specific pipelines or labels, achieving F1 scores ranging from 74.2 to 96.1, while maintaining cost efficiency. Moreover, through detailed ablation studies and analyses, we investigate the factors contributing to model success and validate the practicality of distilling compact models to reduce API reliance."
}

@article{kojima2022large,
  title={Large language models are zero-shot reasoners},
  author={Kojima, Takeshi and Gu, Shixiang Shane and Reid, Machel and Matsuo, Yutaka and Iwasawa, Yusuke},
  journal={Advances in neural information processing systems},
  volume={35},
  pages={22199--22213},
  year={2022}
}

@article{nye2021show,
  title={Show your work: Scratchpads for intermediate computation with language models},
  author={Nye, Maxwell and Andreassen, Anders Johan and Gur-Ari, Guy and Michalewski, Henryk and Austin, Jacob and Bieber, David and Dohan, David and Lewkowycz, Aitor and Bosma, Maarten and Luan, David and others},
  journal={arXiv preprint arXiv:2112.00114},
  year={2021}
}

@article{liu2021makes,
  title={What Makes Good In-Context Examples for GPT-$3 $?},
  author={Liu, Jiachang and Shen, Dinghan and Zhang, Yizhe and Dolan, Bill and Carin, Lawrence and Chen, Weizhu},
  journal={arXiv preprint arXiv:2101.06804},
  year={2021}
}

@article{chowdhery2023palm,
  title={Palm: Scaling language modeling with pathways},
  author={Chowdhery, Aakanksha and Narang, Sharan and Devlin, Jacob and Bosma, Maarten and Mishra, Gaurav and Roberts, Adam and Barham, Paul and Chung, Hyung Won and Sutton, Charles and Gehrmann, Sebastian and others},
  journal={Journal of Machine Learning Research},
  volume={24},
  number={240},
  pages={1--113},
  year={2023}
}

@article{zhang2022opt,
  title={Opt: Open pre-trained transformer language models},
  author={Zhang, Susan and Roller, Stephen and Goyal, Naman and Artetxe, Mikel and Chen, Moya and Chen, Shuohui and Dewan, Christopher and Diab, Mona and Li, Xian and Lin, Xi Victoria and others},
  journal={arXiv preprint arXiv:2205.01068},
  year={2022}
}

@inproceedings{j-wang-etal-2022-globalpointer,
    title = "A {G}lobal{P}ointer based Robust Approach for Information Extraction from Dialog Transcripts",
    author = "Wang, Yanbo J.  and
      Chen, Sheng  and
      Cai, Hengxing  and
      Wei, Wei  and
      Yan, Kuo  and
      Sun, Zhe  and
      Qin, Hui  and
      Li, Yuming  and
      Cai, Xiaochen",
    editor = "Ou, Zhijian  and
      Feng, Junlan  and
      Li, Juanzi",
    booktitle = "Proceedings of the Towards Semi-Supervised and Reinforced Task-Oriented Dialog Systems (SereTOD)",
    month = dec,
    year = "2022",
    address = "Abu Dhabi, Beijing (Hybrid)",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.seretod-1.2/",
    doi = "10.18653/v1/2022.seretod-1.2",
    pages = "13--18",
    abstract = "With the widespread popularisation of intelligent technology, task-based dialogue systems (TOD) are increasingly being applied to a wide variety of practical scenarios. As the key tasks in dialogue systems, named entity recognition and slot filling play a crucial role in the completeness and accuracy of information extraction. This paper is an evaluation paper for Sere-TOD 2022 Workshop challenge (Track 1 Information extraction from dialog transcripts). We proposed a multi-model fusion approach based on GlobalPointer, combined with some optimisation tricks, finally achieved an entity F1 of 60.73, an entity-slot-value triple F1 of 56, and an average F1 of 58.37, and got the highest score in SereTOD 2022 Workshop challenge"
}

@inproceedings{tamayo-etal-2022-nlp,
    title = "{NLP}-{CIC}-{WFU} at {S}ocial{D}is{NER}: Disease Mention Extraction in {S}panish Tweets Using Transfer Learning and Search by Propagation",
    author = "Tamayo, Antonio  and
      Gelbukh, Alexander  and
      Burgos, Diego",
    editor = "Gonzalez-Hernandez, Graciela  and
      Weissenbacher, Davy",
    booktitle = "Proceedings of The Seventh Workshop on Social Media Mining for Health Applications, Workshop {\&} Shared Task",
    month = oct,
    year = "2022",
    address = "Gyeongju, Republic of Korea",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.smm4h-1.6/",
    pages = "19--22",
    abstract = "Named entity recognition (e.g., disease mention extraction) is one of the most relevant tasks for data mining in the medical field. Although it is a well-known challenge, the bulk of the efforts to tackle this task have been made using clinical texts commonly written in English. In this work, we present our contribution to the SocialDisNER competition, which consists of a transfer learning approach to extracting disease mentions in a corpus from Twitter written in Spanish. We fine-tuned a model based on mBERT and applied post-processing using regular expressions to propagate the entities identified by the model and enhance disease mention extraction. Our system achieved a competitive strict F1 of 0.851 on the testing data set."
}

@inproceedings{makhoul1999performance,
  title={Performance measures for information extraction},
  author={Makhoul, John and Kubala, Francis and Schwartz, Richard and Weischedel, Ralph and others},
  booktitle={Proceedings of DARPA broadcast news workshop},
  pages={249--252},
  year={1999},
  organization={Herndon, VA}
}

@inproceedings{cohen2003comparison,
  title={A Comparison of String Distance Metrics for Name-Matching Tasks.},
  author={Cohen, William W and Ravikumar, Pradeep and Fienberg, Stephen E and others},
  booktitle={IIWeb},
  volume={3},
  pages={73--78},
  year={2003}
}

@article{gallegos2024bias,
  title={Bias and fairness in large language models: A survey},
  author={Gallegos, Isabel O and Rossi, Ryan A and Barrow, Joe and Tanjim, Md Mehrab and Kim, Sungchul and Dernoncourt, Franck and Yu, Tong and Zhang, Ruiyi and Ahmed, Nesreen K},
  journal={Computational Linguistics},
  pages={1--79},
  year={2024},
  publisher={MIT Press 255 Main Street, 9th Floor, Cambridge, Massachusetts 02142, USA~…}
}


@inproceedings{perot-etal-2024-lmdx,
    title = "{LMDX}: Language Model-based Document Information Extraction and Localization",
    author = "Perot, Vincent  and
      Kang, Kai  and
      Luisier, Florian  and
      Su, Guolong  and
      Sun, Xiaoyu  and
      Boppana, Ramya Sree  and
      Wang, Zilong  and
      Wang, Zifeng  and
      Mu, Jiaqi  and
      Zhang, Hao  and
      Lee, Chen-Yu  and
      Hua, Nan",
    editor = "Ku, Lun-Wei  and
      Martins, Andre  and
      Srikumar, Vivek",
    booktitle = "Findings of the Association for Computational Linguistics: ACL 2024",
    month = aug,
    year = "2024",
    address = "Bangkok, Thailand",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2024.findings-acl.899/",
    doi = "10.18653/v1/2024.findings-acl.899",
    pages = "15140--15168",
    abstract = "Large Language Models (LLM) have revolutionized Natural Language Processing (NLP), improving state-of-the-art and exhibiting emergent capabilities across various tasks. However, their application in extracting information from visually rich documents, which is at the core of many document processing workflows and involving the extraction of key entities from semi-structured documents, has not yet been successful. The main obstacles to adopting LLMs for this task include the absence of layout encoding within LLMs, which is critical for high quality extraction, and the lack of a grounding mechanism to localize the predicted entities within the document. In this paper, we introduce Language Model-based Document Information EXtraction and Localization (LMDX), a methodology to reframe the document information extraction task for a LLM. LMDX enables extraction of singular, repeated, and hierarchical entities, both with and without training data, while providing grounding guarantees and localizing the entities within the document. Finally, we apply LMDX to the PaLM 2-S and Gemini Pro LLMs and evaluate it on VRDU and CORD benchmarks, setting a new state-of-the-art and showing how LMDX enables the creation of high quality, data-efficient parsers."
}

@article{devlin2019bert,
  title={BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding},
  author={Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
  journal={arXiv preprint arXiv:1810.04805},
  year={2019}
}

@article{liu2019roberta,
  title={RoBERTa: A Robustly Optimized BERT Pretraining Approach},
  author={Liu, Yinhan and Ott, Myle and Goyal, Naman and Du, Jingfei and Joshi, Mandar and Chen, Danqi and Levy, Omer and Lewis, Mike and Zettlemoyer, Luke and Stoyanov, Veselin},
  journal={arXiv preprint arXiv:1907.11692},
  year={2019}
}

@article{xu2021layoutlmv2,
  title={LayoutLMv2: Multi-modal pre-training for visually-rich document understanding},
  author={Xu, Yiheng and Xu, Jingjing and Li, Minghao and Cui, Lei and Huang, Shaohan and Wei, Furu and Zhou, Ming},
  journal={arXiv preprint arXiv:2012.14740},
  year={2021}
}

@article{xu2022layoutlmv3,
  title={LayoutLMv3: Pre-training for Document AI with Unified Text and Image Masking},
  author={Xu, Yiheng and Li, Minghao and Cui, Lei and Huang, Shaohan and Wei, Furu and Zhou, Ming},
  journal={arXiv preprint arXiv:2204.08387},
  year={2022}
}

@article{liu2023llava,
  title={LLaVA: Large Language and Vision Assistant},
  author={Liu, Xiang and others},
  journal={arXiv preprint arXiv:2305.11410},
  year={2023}
}

@article{anil2023gemini,
  title={Gemini Pro: Integrating Multimodal Capabilities for Enhanced Information Extraction},
  author={Anil, Rohan and others},
  journal={Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing (EMNLP)},
  year={2023}
}

@article{openai2023gpt4,
  title={GPT-4 Technical Report},
  author={OpenAI},
  journal={OpenAI},
  year={2023},
  url={https://www.openai.com/research/gpt-4}
}

@article{jain2020tabbypdf,
  title={TabbyPDF: Table Structure Recognition in PDF Documents},
  author={Jain, Priya and others},
  journal={arXiv preprint arXiv:2007.12308},
  year={2020}
}

@article{zhong2020docextractor,
  title={DocExtractor: An End-to-End System for Information Extraction from Forms and Receipts},
  author={Zhong, Jian and others},
  journal={arXiv preprint arXiv:2012.04573},
  year={2020}
}

@article{wei2022cot,
  title={Chain of Thought Prompting Elicits Reasoning in Large Language Models},
  author={Wei, Jason and others},
  journal={arXiv preprint arXiv:2201.11903},
  year={2022}
}

@article{wang2022majority,
  title={Majority Voting for Improved Consistency in Information Extraction Tasks},
  author={Wang, Lin and others},
  journal={arXiv preprint arXiv:2207.05214},
  year={2022}
}

@article{hwang2021entityresolution,
  title={Entity Resolution in Heterogeneous Data Sources: A Survey},
  author={Hwang, Sunghwan and others},
  journal={IEEE Transactions on Knowledge and Data Engineering},
  year={2021}
}

@inproceedings{hearst1999untangling,
  title={Untangling text data mining},
  author={Hearst, Marti A},
  booktitle={Proceedings of the 37th Annual meeting of the Association for Computational Linguistics},
  pages={3--10},
  year={1999}
}

@article{kernighan1979unix,
  title={The UNIX™ programming environment},
  author={Kernighan, Brian W and Mashey, John R},
  journal={Software: Practice and Experience},
  volume={9},
  number={1},
  pages={1--15},
  year={1979},
  publisher={Wiley Online Library}
}

@book{grishman1986computational,
  title={Computational linguistics: an introduction},
  author={Grishman, Ralph},
  year={1986},
  publisher={Cambridge University Press}
}

@article{gaizauskas1998information,
  title={Information extraction: Beyond document retrieval},
  author={Gaizauskas, Robert and Wilks, Yorick},
  journal={Journal of documentation},
  volume={54},
  number={1},
  pages={70--105},
  year={1998},
  publisher={MCB UP Ltd}
}

@book{frakes1992information,
  title={Information retrieval: data structures and algorithms},
  author={Frakes, William B and Baeza-Yates, Ricardo},
  year={1992},
  publisher={Prentice-Hall, Inc.}
}

@misc{christopher2008introduction,
  title={Introduction to information retrieval},
  author={Christopher, D Manning and Prabhakar, Raghavan and Hinrich, Schutze},
  year={2008},
  publisher={Cambridge University Press}
}

@inproceedings{mccallum1998comparison,
  title={A comparison of event models for naive bayes text classification},
  author={McCallum, Andrew and Nigam, Kamal and others},
  booktitle={AAAI-98 workshop on learning for text categorization},
  volume={752},
  pages={41--48},
  year={1998},
  organization={Madison, WI}
}

@inproceedings{joachims1998text,
  title={Text categorization with support vector machines: Learning with many relevant features},
  author={Joachims, Thorsten},
  booktitle={European conference on machine learning},
  pages={137--142},
  year={1998},
  organization={Springer}
}

@inproceedings{lafferty2001conditional,
  title={Conditional random fields: Probabilistic models for segmenting and labeling sequence data},
  author={Lafferty, John and McCallum, Andrew and Pereira, Fernando and others},
  booktitle={Icml},
  volume={1},
  pages={3},
  year={2001},
  organization={Williamstown, MA}
}

@inproceedings{roth2004linear,
  title={A linear programming formulation for global inference in natural language tasks},
  author={Roth, Dan and Yih, Wen-tau},
  booktitle={Proceedings of the eighth conference on computational natural language learning (CoNLL-2004) at HLT-NAACL 2004},
  pages={1--8},
  year={2004}
}

@article{elman1990finding,
  title={Finding structure in time},
  author={Elman, Jeffrey L},
  journal={Cognitive science},
  volume={14},
  number={2},
  pages={179--211},
  year={1990},
  publisher={Wiley Online Library}
}

@article{hochreiter1997long,
  title={Long Short-term Memory},
  author={Hochreiter, S},
  journal={Neural Computation MIT-Press},
  year={1997}
}

@misc{bengio2009learning,
  title={Learning Deep Architectures for AI},
  author={Bengio, Y},
  year={2009},
  publisher={Now Publishers Inc}
}

@article{lecun2015deep,
  title={Deep learning},
  author={LeCun, Yann and Bengio, Yoshua and Hinton, Geoffrey},
  journal={nature},
  volume={521},
  number={7553},
  pages={436--444},
  year={2015},
  publisher={Nature Publishing Group UK London}
}

@article{le2023bloom,
  title={Bloom: A 176b-parameter open-access multilingual language model},
  author={Le Scao, Teven and Fan, Angela and Akiki, Christopher and Pavlick, Ellie and Ili{\'c}, Suzana and Hesslow, Daniel and Castagn{\'e}, Roman and Luccioni, Alexandra Sasha and Yvon, Fran{\c{c}}ois and Gall{\'e}, Matthias and others},
  year={2023}
}

@misc{google_document_ai_docs,
  author       = {Google Cloud},
  title        = {Document AI Documentation},
  year         = {2025},
  howpublished = {\url{https://cloud.google.com/document-ai/docs}},
  note         = {Accessed: 2025-01-14}
}

@inproceedings{kim2022ocr,
  title={Ocr-free document understanding transformer},
  author={Kim, Geewook and Hong, Teakgyu and Yim, Moonbin and Nam, JeongYeon and Park, Jinyoung and Yim, Jinyeong and Hwang, Wonseok and Yun, Sangdoo and Han, Dongyoon and Park, Seunghyun},
  booktitle={European Conference on Computer Vision},
  pages={498--517},
  year={2022},
  organization={Springer}
}

@inproceedings{zhang-etal-2023-reading,
    title = "Reading Order Matters: Information Extraction from Visually-rich Documents by Token Path Prediction",
    author = "Zhang, Chong  and
      Guo, Ya  and
      Tu, Yi  and
      Chen, Huan  and
      Tang, Jinyang  and
      Zhu, Huijia  and
      Zhang, Qi  and
      Gui, Tao",
    editor = "Bouamor, Houda  and
      Pino, Juan  and
      Bali, Kalika",
    booktitle = "Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing",
    month = dec,
    year = "2023",
    address = "Singapore",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.emnlp-main.846/",
    doi = "10.18653/v1/2023.emnlp-main.846",
    pages = "13716--13730",
    abstract = "Recent advances in multimodal pre-trained models have significantly improved information extraction from visually-rich documents (VrDs), in which named entity recognition (NER) is treated as a sequence-labeling task of predicting the BIO entity tags for tokens, following the typical setting of NLP. However, BIO-tagging scheme relies on the correct order of model inputs, which is not guaranteed in real-world NER on scanned VrDs where text are recognized and arranged by OCR systems. Such reading order issue hinders the accurate marking of entities by BIO-tagging scheme, making it impossible for sequence-labeling methods to predict correct named entities. To address the reading order issue, we introduce Token Path Prediction (TPP), a simple prediction head to predict entity mentions as token sequences within documents. Alternative to token classification, TPP models the document layout as a complete directed graph of tokens, and predicts token paths within the graph as entities. For better evaluation of VrD-NER systems, we also propose two revised benchmark datasets of NER on scanned documents which can reflect real-world scenarios. Experiment results demonstrate the effectiveness of our method, and suggest its potential to be a universal solution to various information extraction tasks on documents."
}

@inproceedings{nourbakhsh-etal-2024-aligatr,
    title = "{A}li{GAT}r: Graph-based layout generation for form understanding",
    author = "Nourbakhsh, Armineh  and
      Jin, Zhao  and
      Parekh, Siddharth  and
      Shah, Sameena  and
      Rose, Carolyn",
    editor = "Al-Onaizan, Yaser  and
      Bansal, Mohit  and
      Chen, Yun-Nung",
    booktitle = "Findings of the Association for Computational Linguistics: EMNLP 2024",
    month = nov,
    year = "2024",
    address = "Miami, Florida, USA",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2024.findings-emnlp.778/",
    doi = "10.18653/v1/2024.findings-emnlp.778",
    pages = "13309--13328",
    abstract = "Forms constitute a large portion of layout-rich documents that convey information through key-value pairs. Form understanding involves two main tasks, namely, the identification of keys and values (a.k.a Key Information Extraction or KIE) and the association of keys to corresponding values (a.k.a. Relation Extraction or RE). State of the art models for form understanding often rely on training paradigms that yield poorly calibrated output probabilities and low performance on RE. In this paper, we present AliGATr, a graph-based model that uses a generative objective to represent complex grid-like layouts that are often found in forms. Using a grid-based graph topology, our model learns to generate the layout of each page token by token in a data efficient manner. Despite using 30{\%} fewer parameters than the smallest SotA, AliGATr performs on par with or better than SotA models on the KIE and RE tasks against four datasets. We also show that AliGATr`s output probabilities are better calibrated and do not exhibit the over-confident distributions of other SotA models."
}

@inproceedings{shaojie-etal-2023-document,
    title = "Document Information Extraction via Global Tagging",
    author = "Shaojie, He  and
      Tianshu, Wang  and
      Yaojie, Lu  and
      Hongyu, Lin  and
      Xianpei, Han  and
      Yingfei, Sun  and
      Le, Sun",
    editor = "Sun, Maosong  and
      Qin, Bing  and
      Qiu, Xipeng  and
      Jiang, Jing  and
      Han, Xianpei",
    booktitle = "Proceedings of the 22nd Chinese National Conference on Computational Linguistics",
    month = aug,
    year = "2023",
    address = "Harbin, China",
    publisher = "Chinese Information Processing Society of China",
    url = "https://aclanthology.org/2023.ccl-1.62/",
    pages = "726--735",
    language = "eng"
}

@inproceedings{liu-etal-2019-graph,
    title = "Graph Convolution for Multimodal Information Extraction from Visually Rich Documents",
    author = "Liu, Xiaojing  and
      Gao, Feiyu  and
      Zhang, Qiong  and
      Zhao, Huasha",
    editor = "Loukina, Anastassia  and
      Morales, Michelle  and
      Kumar, Rohit",
    booktitle = "Proceedings of the 2019 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 2 (Industry Papers)",
    month = jun,
    year = "2019",
    address = "Minneapolis, Minnesota",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/N19-2005/",
    doi = "10.18653/v1/N19-2005",
    pages = "32--39"
}

@inproceedings{zheng-etal-2024-comprehensive,
    title = "A Comprehensive Survey on Document-Level Information Extraction",
    author = "Zheng, Hanwen  and
      Wang, Sijia  and
      Huang, Lifu",
    editor = "Tetreault, Joel  and
      Nguyen, Thien Huu  and
      Lamba, Hemank  and
      Hughes, Amanda",
    booktitle = "Proceedings of the Workshop on the Future of Event Detection (FuturED)",
    month = nov,
    year = "2024",
    address = "Miami, Florida, USA",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2024.futured-1.6/",
    doi = "10.18653/v1/2024.futured-1.6",
    pages = "58--72"
}

@inproceedings{fujitake-2024-layoutllm,
    title = "{L}ayout{LLM}: Large Language Model Instruction Tuning for Visually Rich Document Understanding",
    author = "Fujitake, Masato",
    editor = "Calzolari, Nicoletta  and
      Kan, Min-Yen  and
      Hoste, Veronique  and
      Lenci, Alessandro  and
      Sakti, Sakriani  and
      Xue, Nianwen",
    booktitle = "Proceedings of the 2024 Joint International Conference on Computational Linguistics, Language Resources and Evaluation (LREC-COLING 2024)",
    month = may,
    year = "2024",
    address = "Torino, Italia",
    publisher = "ELRA and ICCL",
    url = "https://aclanthology.org/2024.lrec-main.892/",
    pages = "10219--10224",
    abstract = "This paper proposes LayoutLLM, a more flexible document analysis method for understanding imaged documents. Visually Rich Document Understanding tasks, such as document image classification and information extraction, have gained significant attention due to their importance. Existing methods have been developed to enhance document comprehension by incorporating pre-training awareness of images, text, and layout structure. However, these methods require fine-tuning for each task and dataset, and the models are expensive to train and operate. To overcome this limitation, we propose a new LayoutLLM that integrates these with large-scale language models (LLMs). By leveraging the strengths of existing research in document image understanding and LLMs' superior language understanding capabilities, the proposed model, fine-tuned with multimodal instruction datasets, performs an understanding of document images in a single model. Our experiments demonstrate improvement over the baseline model in various document analysis tasks."
}

@inproceedings{zmigrod-etal-2024-value,
    title = "{\textquotedblleft}What is the value of {templates}?{\textquotedblright} Rethinking Document Information Extraction Datasets for {LLM}s",
    author = "Zmigrod, Ran  and
      Shetty, Pranav  and
      Sibue, Mathieu  and
      Ma, Zhiqiang  and
      Nourbakhsh, Armineh  and
      Liu, Xiaomo  and
      Veloso, Manuela",
    editor = "Al-Onaizan, Yaser  and
      Bansal, Mohit  and
      Chen, Yun-Nung",
    booktitle = "Findings of the Association for Computational Linguistics: EMNLP 2024",
    month = nov,
    year = "2024",
    address = "Miami, Florida, USA",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2024.findings-emnlp.770/",
    doi = "10.18653/v1/2024.findings-emnlp.770",
    pages = "13162--13185",
    abstract = "The rise of large language models (LLMs) for visually rich document understanding (VRDU) has kindled a need for prompt-response, document-based datasets. As annotating new datasets from scratch is labor-intensive, the existing literature has generated prompt-response datasets from available resources using simple templates. For the case of key information extraction (KIE), one of the most common VRDU tasks, past work has typically employed the template {\textquotedblleft}What is the value for the key?{\textquotedblright}. However, given the variety of questions encountered in the wild, simple and uniform templates are insufficient for creating robust models in research and industrial contexts. In this work, we present K2Q, a diverse collection of five datasets converted from KIE to a prompt-response format using a plethora of bespoke templates. The questions in K2Q can span multiple entities and be extractive or boolean. We empirically compare the performance of seven baseline generative models on K2Q with zero-shot prompting. We further compare three of these models when training on K2Q versus training on simpler templates to motivate the need of our work. We find that creating diverse and intricate KIE questions enhances the performance and robustness of VRDU models. We hope this work encourages future studies on data quality for generative model training."
}

@misc{google2023geminiapi,
  author       = {Google},
  title        = {Google Gemini API documentation},
  year         = {2023},
  howpublished = {\url{https://ai.google.dev/gemini-api/docs}},
  note         = {Accessed: 2025-01-22}
}

@article{vaswani2017attention,
  title={Attention is all you need},
  author={Vaswani, A},
  journal={Advances in Neural Information Processing Systems},
  year={2017}
}

@article{rajpurkar2016squad,
  title={Squad: 100,000+ questions for machine comprehension of text},
  author={Rajpurkar, P},
  journal={arXiv preprint arXiv:1606.05250},
  year={2016}
}

@article{bommasani2021opportunities,
  title={On the opportunities and risks of foundation models},
  author={Bommasani, Rishi and Hudson, Drew A and Adeli, Ehsan and Altman, Russ and Arora, Simran and von Arx, Sydney and Bernstein, Michael S and Bohg, Jeannette and Bosselut, Antoine and Brunskill, Emma and others},
  journal={arXiv preprint arXiv:2108.07258},
  year={2021}
}

@inproceedings{narayan-etal-2018-ranking,
    title = "Ranking Sentences for Extractive Summarization with Reinforcement Learning",
    author = "Narayan, Shashi  and
      Cohen, Shay B.  and
      Lapata, Mirella",
    editor = "Walker, Marilyn  and
      Ji, Heng  and
      Stent, Amanda",
    booktitle = "Proceedings of the 2018 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long Papers)",
    month = jun,
    year = "2018",
    address = "New Orleans, Louisiana",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/N18-1158/",
    doi = "10.18653/v1/N18-1158",
    pages = "1747--1759",
    abstract = "Single document summarization is the task of producing a shorter version of a document while preserving its principal information content. In this paper we conceptualize extractive summarization as a sentence ranking task and propose a novel training algorithm which globally optimizes the ROUGE evaluation metric through a reinforcement learning objective. We use our algorithm to train a neural summarization model on the CNN and DailyMail datasets and demonstrate experimentally that it outperforms state-of-the-art extractive and abstractive systems when evaluated automatically and by humans."
}

@inproceedings{wang-etal-2025-llms,
    title = "{LLM}s Know What They Need: Leveraging a Missing Information Guided Framework to Empower Retrieval-Augmented Generation",
    author = "Wang, Keheng  and
      Duan, Feiyu  and
      Li, Peiguang  and
      Wang, Sirui  and
      Cai, Xunliang",
    editor = "Rambow, Owen  and
      Wanner, Leo  and
      Apidianaki, Marianna  and
      Al-Khalifa, Hend  and
      Eugenio, Barbara Di  and
      Schockaert, Steven",
    booktitle = "Proceedings of the 31st International Conference on Computational Linguistics",
    month = jan,
    year = "2025",
    address = "Abu Dhabi, UAE",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2025.coling-main.163/",
    pages = "2379--2400",
    abstract = "Retrieval-Augmented Generation (RAG) demonstrates great value in alleviating outdated knowledge or hallucination by supplying LLMs with updated and relevant knowledge. However, RAG still faces several challenges in tackling complex multi-hop queries, which require LLMs to perform accurate reasoning and retrieval at each step. Inspired by the human reasoning process, where we progressively search for missing information after acquiring useful clues, it is natural to question whether LLMs have similar capabilities. In this work, we first experimentally verified the ability of LLMs to extract information from the retrieved knowledge as well as to know what is still missing. Based on the above discovery, we propose a Missing Information Guided Retrieve-Extraction-Solving paradigm (MIGRES), where we leverage the identification of missing information to generate a targeted query that steers the subsequent knowledge retrieval. Besides, we design a sentence-level re-ranking filtering approach to filter the irrelevant content from the document, along with the information extraction capability of LLMs to extract useful information from denoised documents. Extensive experiments conducted on multiple public datasets reveal the superiority of the proposed MIGRES method, and analytical experiments demonstrate the effectiveness of our proposed modules. Code and data are released in https://github.com/AdelWang/MIGRES."
}

@inproceedings{liao-etal-2025-ruie,
    title = "{RUIE}: Retrieval-based Unified Information Extraction using Large Language Model",
    author = "Liao, Xincheng  and
      Duan, Junwen  and
      Huang, Yixi  and
      Wang, Jianxin",
    editor = "Rambow, Owen  and
      Wanner, Leo  and
      Apidianaki, Marianna  and
      Al-Khalifa, Hend  and
      Eugenio, Barbara Di  and
      Schockaert, Steven",
    booktitle = "Proceedings of the 31st International Conference on Computational Linguistics",
    month = jan,
    year = "2025",
    address = "Abu Dhabi, UAE",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2025.coling-main.645/",
    pages = "9640--9655",
    abstract = "Unified information extraction (UIE) aims to extract diverse structured information from unstructured text. While large language models (LLMs) have shown promise for UIE, they require significant computational resources and often struggle to generalize to unseen tasks. We propose RUIE (Retrieval-based Unified Information Extraction), a framework that leverages in-context learning for efficient task generalization. RUIE introduces a novel demonstration selection mechanism combining LLM preferences with a keyword-enhanced reward model, and employs a bi-encoder retriever trained through contrastive learning and knowledge distillation. As the first trainable retrieval framework for UIE, RUIE serves as a universal plugin for various LLMs. Experimental results on eight held-out datasets demonstrate RUIE`s effectiveness, with average F1-score improvements of 19.22 and 3.22 compared to instruction-tuning methods and other retrievers, respectively."
}

@inproceedings{zhang-etal-2025-survey,
    title = "A Survey of Generative Information Extraction",
    author = "Zhang, Zikang  and
      You, Wangjie  and
      Wu, Tianci  and
      Wang, Xinrui  and
      Li, Juntao  and
      Zhang, Min",
    editor = "Rambow, Owen  and
      Wanner, Leo  and
      Apidianaki, Marianna  and
      Al-Khalifa, Hend  and
      Eugenio, Barbara Di  and
      Schockaert, Steven",
    booktitle = "Proceedings of the 31st International Conference on Computational Linguistics",
    month = jan,
    year = "2025",
    address = "Abu Dhabi, UAE",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2025.coling-main.324/",
    pages = "4840--4870",
    abstract = "Generative information extraction (Generative IE) aims to generate structured text sequences from unstructured text using a generative framework. Scaling in model size yields variations in adaptation and generalization, and also drives fundamental shifts in the techniques and approaches used within this domain. In this survey, we first review generative information extraction (IE) methods based on pre-trained language models (PLMs) and large language models (LLMs), focusing on their adaptation and generalization capabilities. We also discuss the connection between these methods and these two aspects. Furthermore, to balance task performance with the substantial computational demands associated with LLMs, we emphasize the importance of model collaboration. Finally, given the advanced capabilities of LLMs, we explore methods for integrating diverse IE tasks into unified models."
}

@inproceedings{appalaraju2021docformer,
  title={Docformer: End-to-end transformer for document understanding},
  author={Appalaraju, Srikar and Jasani, Bhavan and Kota, Bhargava Urala and Xie, Yusheng and Manmatha, R},
  booktitle={Proceedings of the IEEE/CVF international conference on computer vision},
  pages={993--1003},
  year={2021}
}

@misc{openai2024gpt4o,
  title = {Hello GPT-4o},
  author = {{OpenAI}},
  year = {2024},
  url = {https://openai.com/index/hello-gpt-4o/}
}

@misc{openai2023gpt4v,
  title = {GPT-4V(ision) Technical Work and Authors},
  author = {{OpenAI}},
  year = {2023},
  url = {https://openai.com/contributions/gpt-4v/}
}

@article{zhang2023sentiment,
  title={Sentiment analysis in the era of large language models: A reality check},
  author={Zhang, Wenxuan and Deng, Yue and Liu, Bing and Pan, Sinno Jialin and Bing, Lidong},
  journal={arXiv preprint arXiv:2305.15005},
  year={2023}
}

@article{xu2023paradigm,
  title={A paradigm shift in machine translation: Boosting translation performance of large language models},
  author={Xu, Haoran and Kim, Young Jin and Sharaf, Amr and Awadalla, Hany Hassan},
  journal={arXiv preprint arXiv:2309.11674},
  year={2023}
}

@article{singhal2025toward,
  title={Toward expert-level medical question answering with large language models},
  author={Singhal, Karan and Tu, Tao and Gottweis, Juraj and Sayres, Rory and Wulczyn, Ellery and Amin, Mohamed and Hou, Le and Clark, Kevin and Pfohl, Stephen R and Cole-Lewis, Heather and others},
  journal={Nature Medicine},
  pages={1--8},
  year={2025},
  publisher={Nature Publishing Group US New York}
}

@article{pu2023summarization,
  title={Summarization is (almost) dead},
  author={Pu, Xiao and Gao, Mingqi and Wan, Xiaojun},
  journal={arXiv preprint arXiv:2309.09558},
  year={2023}
}

@article{liang2022holistic,
  title={Holistic evaluation of language models},
  author={Liang, Percy and Bommasani, Rishi and Lee, Tony and Tsipras, Dimitris and Soylu, Dilara and Yasunaga, Michihiro and Zhang, Yian and Narayanan, Deepak and Wu, Yuhuai and Kumar, Ananya and others},
  journal={arXiv preprint arXiv:2211.09110},
  year={2022}
}

@article{patterson2021carbon,
  title={Carbon emissions and large neural network training},
  author={Patterson, David and Gonzalez, Joseph and Le, Quoc and Liang, Chen and Munguia, Lluis-Miquel and Rothchild, Daniel and So, David and Texier, Maud and Dean, Jeff},
  journal={arXiv preprint arXiv:2104.10350},
  year={2021}
}

@inproceedings{wang2023vrdu,
  title={Vrdu: A benchmark for visually-rich document understanding},
  author={Wang, Zilong and Zhou, Yichao and Wei, Wei and Lee, Chen-Yu and Tata, Sandeep},
  booktitle={Proceedings of the 29th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
  pages={5184--5193},
  year={2023}
}