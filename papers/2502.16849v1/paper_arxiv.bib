

@article{ren2024learning,
  title={Learning orthogonal multi-index models: A fine-grained information exponent analysis},
  author={Ren, Yunwei and Lee, Jason D},
  journal={arXiv preprint arXiv:2410.09678},
  year={2024}
}



@article{bietti2023learning,
  title={On learning gaussian multi-index models with gradient flow},
  author={Bietti, Alberto and Bruna, Joan and Pillaud-Vivien, Loucas},
  journal={arXiv preprint arXiv:2310.19793},
  year={2023}
}


@inproceedings{zhao2019learning,
  title={On learning invariant representations for domain adaptation},
  author={Zhao, Han and Des Combes, Remi Tachet and Zhang, Kun and Gordon, Geoffrey},
  booktitle={International conference on machine learning},
  pages={7523--7532},
  year={2019},
  organization={PMLR}
}



@article{tachet2020domain,
  title={Domain adaptation with conditional distribution matching and generalized label shift},
  author={Tachet des Combes, Remi and Zhao, Han and Wang, Yu-Xiang and Gordon, Geoffrey J},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={19276--19289},
  year={2020}
}



@article{hanneke2019value,
  title={On the value of target data in transfer learning},
  author={Hanneke, Steve and Kpotufe, Samory},
  journal={Advances in Neural Information Processing Systems},
  volume={32},
  year={2019}
}



@inproceedings{david2010impossibility,
  title={Impossibility theorems for domain adaptation},
  author={David, Shai Ben and Lu, Tyler and Luu, Teresa and P{\'a}l, D{\'a}vid},
  booktitle={Proceedings of the Thirteenth International Conference on Artificial Intelligence and Statistics},
  pages={129--136},
  year={2010},
  organization={JMLR Workshop and Conference Proceedings}
}


@article{ben2010theory,
  title={A theory of learning from different domains},
  author={Ben-David, Shai and Blitzer, John and Crammer, Koby and Kulesza, Alex and Pereira, Fernando and Vaughan, Jennifer Wortman},
  journal={Machine learning},
  volume={79},
  pages={151--175},
  year={2010},
  publisher={Springer}
}


@article{albuquerque2019generalizing,
  title={Generalizing to unseen domains via distribution matching},
  author={Albuquerque, Isabela and Monteiro, Jo{\~a}o and Darvishi, Mohammad and Falk, Tiago H and Mitliagkas, Ioannis},
  journal={arXiv preprint arXiv:1911.00804},
  year={2019}
}



@inproceedings{long2017deep,
  title={Deep transfer learning with joint adaptation networks},
  author={Long, Mingsheng and Zhu, Han and Wang, Jianmin and Jordan, Michael I},
  booktitle={International conference on machine learning},
  pages={2208--2217},
  year={2017},
  organization={PMLR}
}


@article{ganin2016domain,
  title={Domain-adversarial training of neural networks},
  author={Ganin, Yaroslav and Ustinova, Evgeniya and Ajakan, Hana and Germain, Pascal and Larochelle, Hugo and Laviolette, Fran{\c{c}}ois and March, Mario and Lempitsky, Victor},
  journal={Journal of machine learning research},
  volume={17},
  number={59},
  pages={1--35},
  year={2016}
}


@article{sagawa2019distributionally,
  title={Distributionally robust neural networks for group shifts: On the importance of regularization for worst-case generalization},
  author={Sagawa, Shiori and Koh, Pang Wei and Hashimoto, Tatsunori B and Liang, Percy},
  journal={arXiv preprint arXiv:1911.08731},
  year={2019}
}


@inproceedings{wu2019domain,
  title={Domain adaptation with asymmetrically-relaxed distribution alignment},
  author={Wu, Yifan and Winston, Ezra and Kaushik, Divyansh and Lipton, Zachary},
  booktitle={International conference on machine learning},
  pages={6872--6881},
  year={2019},
  organization={PMLR}
}


@article{maity2022minimax,
  title={Minimax optimal approaches to the label shift problem in non-parametric settings},
  author={Maity, Subha and Sun, Yuekai and Banerjee, Moulinath},
  journal={Journal of Machine Learning Research},
  volume={23},
  number={346},
  pages={1--45},
  year={2022}
}



@article{storkey2008training,
  title={When training and test sets are different: characterizing learning transfer},
  author={Storkey, Amos},
  year={2008}
}



@book{quinonero2022dataset,
  title={Dataset shift in machine learning},
  author={Qui{\~n}onero-Candela, Joaquin and Sugiyama, Masashi and Schwaighofer, Anton and Lawrence, Neil D},
  year={2022},
  publisher={Mit Press}
}


@inproceedings{wang2014active,
  title={Active transfer learning under model shift},
  author={Wang, Xuezhi and Huang, Tzu-Kuo and Schneider, Jeff},
  booktitle={International Conference on Machine Learning},
  pages={1305--1313},
  year={2014},
  organization={PMLR}
}


@inproceedings{wang2015generalization,
  title={Generalization Bounds for Transfer Learning under Model Shift.},
  author={Wang, Xuezhi and Schneider, Jeff G},
  booktitle={UAI},
  pages={922--931},
  year={2015}
}


@article{shimodaira2000improving,
  title={Improving predictive inference under covariate shift by weighting the log-likelihood function},
  author={Shimodaira, Hidetoshi},
  journal={Journal of statistical planning and inference},
  volume={90},
  number={2},
  pages={227--244},
  year={2000},
  publisher={Elsevier}
}



@article{huang2006correcting,
  title={Correcting sample selection bias by unlabeled data},
  author={Huang, Jiayuan and Gretton, Arthur and Borgwardt, Karsten and Sch{\"o}lkopf, Bernhard and Smola, Alex},
  journal={Advances in neural information processing systems},
  volume={19},
  year={2006}
}


@article{heckman1979sample,
  title={Sample selection bias as a specification error},
  author={Heckman, James J},
  journal={Econometrica: Journal of the econometric society},
  pages={153--161},
  year={1979},
  publisher={JSTOR}
}


@article{baldi1989neural,
  title={Neural networks and principal component analysis: Learning from examples without local minima},
  author={Baldi, Pierre and Hornik, Kurt},
  journal={Neural networks},
  volume={2},
  number={1},
  pages={53--58},
  year={1989},
  publisher={Elsevier}
}

@inproceedings{damian2022neural,
  title={Neural networks can learn representations with gradient descent},
  author={Damian, Alexandru and Lee, Jason and Soltanolkotabi, Mahdi},
  booktitle={Conference on Learning Theory},
  pages={5413--5452},
  year={2022},
  organization={PMLR}
}



@article{bourlard1988auto,
  title={Auto-association by multilayer perceptrons and singular value decomposition},
  author={Bourlard, Herv{\'e} and Kamp, Yves},
  journal={Biological cybernetics},
  volume={59},
  number={4},
  pages={291--294},
  year={1988},
  publisher={Springer}
}



@article{nguyen2021analysis,
  title={Analysis of feature learning in weight-tied autoencoders via the mean field lens},
  author={Nguyen, Phan-Minh},
  journal={arXiv preprint arXiv:2102.08373},
  year={2021}
}

@book{bai2010spectral,
  title={Spectral analysis of large dimensional random matrices},
  author={Bai, Zhidong and Silverstein, Jack W},
  volume={20},
  year={2010},
  publisher={Springer}
}






@article{arous2021online,
  title={Online stochastic gradient descent on non-convex losses from high-dimensional inference},
  author={Ben Arous, Gerard  and Gheissari, Reza and Jagannath, Aukosh},
  journal={Journal of Machine Learning Research},
  volume={22},
  number={106},
  pages={1--51},
  year={2021}
}

@article{vaswani2017attention,
  title={Attention is all you need},
  author={Vaswani, A},
  journal={Advances in Neural Information Processing Systems},
  year={2017}
}

@article{brown2020language,
  title={Language models are few-shot learners},
  author={Brown, Tom B},
  journal={arXiv preprint arXiv:2005.14165},
  year={2020}
}

@inproceedings{rombach2022high,
  title={High-resolution image synthesis with latent diffusion models},
  author={Rombach, Robin and Blattmann, Andreas and Lorenz, Dominik and Esser, Patrick and Ommer, Bj{\"o}rn},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={10684--10695},
  year={2022}
}

@article{arous2020algorithmic,
  title={Algorithmic thresholds for tensor PCA},
  author={Ben Arous, Gerard and Gheissari, Reza and Jagannath, Aukosh},
  journal={The Annals of Probability},
  volume={48},
  number={4},
  pages={2052--2087},
  year={2020},
  publisher={JSTOR}
}

@inproceedings{wang2025yolov9,
  title={Yolov9: Learning what you want to learn using programmable gradient information},
  author={Wang, Chien-Yao and Yeh, I-Hau and Mark Liao, Hong-Yuan},
  booktitle={European Conference on Computer Vision},
  pages={1--21},
  year={2025},
  organization={Springer}
}

@inproceedings{maas-etal-2011-learning,
    title = "Learning Word Vectors for Sentiment Analysis",
    author = "Maas, Andrew L.  and
      Daly, Raymond E.  and
      Pham, Peter T.  and
      Huang, Dan  and
      Ng, Andrew Y.  and
      Potts, Christopher",
    editor = "Lin, Dekang  and
      Matsumoto, Yuji  and
      Mihalcea, Rada",
    booktitle = "Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies",
    month = jun,
    year = "2011",
    address = "Portland, Oregon, USA",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/P11-1015",
    pages = "142--150",
}

@inproceedings{wang2023yolov7,
  title={YOLOv7: Trainable bag-of-freebies sets new state-of-the-art for real-time object detectors},
  author={Wang, Chien-Yao and Bochkovskiy, Alexey and Liao, Hong-Yuan Mark},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={7464--7475},
  year={2023}
}

@inproceedings{varghese2024yolov8,
  title={YOLOv8: A Novel Object Detection Algorithm with Enhanced Performance and Robustness},
  author={Varghese, Rejin and Sambath, M},
  booktitle={2024 International Conference on Advances in Data Engineering and Intelligent Computing Systems (ADICS)},
  pages={1--6},
  year={2024},
  organization={IEEE}
}

@inproceedings{vincent2008extracting,
  title={Extracting and composing robust features with denoising autoencoders},
  author={Vincent, Pascal and Larochelle, Hugo and Bengio, Yoshua and Manzagol, Pierre-Antoine},
  booktitle={Proceedings of the 25th international conference on Machine learning},
  pages={1096--1103},
  year={2008}
}

@article{devlin2018bert,
  title={Bert: Pre-training of deep bidirectional transformers for language understanding},
  author={Devlin, Jacob},
  journal={arXiv preprint arXiv:1810.04805},
  year={2018}
}

@article{robbins1951stochastic,
  title={A stochastic approximation method},
  author={Robbins, Herbert and Monro, Sutton},
  journal={The annals of mathematical statistics},
  pages={400--407},
  year={1951},
  publisher={JSTOR}
}

@article{kingma2014adam,
  title={Adam: A method for stochastic optimization},
  author={Kingma, Diederik P},
  journal={arXiv preprint arXiv:1412.6980},
  year={2014}
}


@article{radford2019language,
  title={Language models are unsupervised multitask learners},
  author={Radford, Alec and Wu, Jeffrey and Child, Rewon and Luan, David and Amodei, Dario and Sutskever, Ilya and others},
  journal={OpenAI blog},
  volume={1},
  number={8},
  pages={9},
  year={2019}
}

@article{hagos2019transfer,
  title={Transfer learning based detection of diabetic retinopathy from small dataset},
  author={Hagos, Misgina Tsighe and Kant, Shri},
  journal={arXiv preprint arXiv:1905.07203},
  year={2019}
}

@article{wang2016learning,
  title={Learning to reinforcement learn},
  author={Wang, Jane X and Kurth-Nelson, Zeb and Tirumala, Dhruva and Soyer, Hubert and Leibo, Joel Z and Munos, Remi and Blundell, Charles and Kumaran, Dharshan and Botvinick, Matt},
  journal={arXiv preprint arXiv:1611.05763},
  year={2016}
}
@inproceedings{he2017mask,
  title={Mask r-cnn},
  author={He, Kaiming and Gkioxari, Georgia and Doll{\'a}r, Piotr and Girshick, Ross},
  booktitle={Proceedings of the IEEE international conference on computer vision},
  pages={2961--2969},
  year={2017}
}

@article{schneider2019wav2vec,
  title={wav2vec: Unsupervised pre-training for speech recognition},
  author={Schneider, Steffen and Baevski, Alexei and Collobert, Ronan and Auli, Michael},
  journal={arXiv preprint arXiv:1904.05862},
  year={2019}
}

@article{lee2024neural,
  title={Neural network learns low-dimensional polynomials with SGD near the information-theoretic limit},
  author={Lee, Jason D and Oko, Kazusato and Suzuki, Taiji and Wu, Denny},
  journal={arXiv preprint arXiv:2406.01581},
  year={2024}
}

@article{achiam2023gpt,
  title={Gpt-4 technical report},
  author={Achiam, Josh and Adler, Steven and Agarwal, Sandhini and Ahmad, Lama and Akkaya, Ilge and Aleman, Florencia Leoni and Almeida, Diogo and Altenschmidt, Janko and Altman, Sam and Anadkat, Shyamal and others},
  journal={arXiv preprint arXiv:2303.08774},
  year={2023}
}

@article{yosinski2014transferable,
  title={How transferable are features in deep neural networks?},
  author={Yosinski, Jason and Clune, Jeff and Bengio, Yoshua and Lipson, Hod},
  journal={Advances in neural information processing systems},
  volume={27},
  year={2014}
}

@article{wang2017scaling,
  title={Scaling limit: Exact and tractable analysis of online learning algorithms with applications to regularized regression and PCA},
  author={Wang, Chuang and Mattingly, Jonathan and Lu, Yue M},
  journal={arXiv preprint arXiv:1712.04332},
  year={2017}
}

@book{williams1991probability,
    title={Probability with Martingales},
    author={Williams, David},
    year={1991},
    publisher={Cambridge University Press}
}

@article{gross1967gronwall,
    title={Gronwall's Inequality and Its Applications},
    author={Gross, Leonard},
    journal={The Journal of Mathematical Analysis and Applications},
    volume={20},
    number={3},
    pages={359-370},
    year={1967}
}
@article{ljung1977analysis,
  title={Analysis of recursive stochastic algorithms},
  author={Ljung, Lennart},
  journal={IEEE transactions on automatic control},
  volume={22},
  number={4},
  pages={551--575},
  year={1977},
  publisher={IEEE}
}

@book{MDS,
  added-at = {2020-06-17T18:39:03.000+0200},
  author = {Bandeira, Alfonso S. and Singer, Amit and Strohmer, Thomas},
  biburl = {https://www.bibsonomy.org/bibtex/2c938436eaf49f4fc3e4a37d9e0184a83/kirk86},
  description = {BandeiraSingerStrohmer-MDS-draft.pdf},
  interhash = {d7446f64b564e488a2f3c89424fea6f3},
  intrahash = {c938436eaf49f4fc3e4a37d9e0184a83},
  keywords = {book machine-learning mathematics readings},
  timestamp = {2020-06-17T18:44:25.000+0200},
  title = {Mathematics of Data Science},
  url = {https://people.math.ethz.ch/~abandeira/BandeiraSingerStrohmer-MDS-draft.pdf},
  year = 2020
}

@article{lee2021predicting,
  title={Predicting what you already know helps: Provable self-supervised learning},
  author={Lee, Jason D and Lei, Qi and Saunshi, Nikunj and Zhuo, Jiacheng},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={309--323},
  year={2021}
}

@inproceedings{lei2021near,
  title={Near-optimal linear regression under distribution shift},
  author={Lei, Qi and Hu, Wei and Lee, Jason},
  booktitle={International Conference on Machine Learning},
  pages={6164--6174},
  year={2021},
  organization={PMLR}
}

@article{wei2021pretrained,
  title={Why do pretrained language models help in downstream tasks? an analysis of head and prompt tuning},
  author={Wei, Colin and Xie, Sang Michael and Ma, Tengyu},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={16158--16170},
  year={2021}
}

@article{zhai2023understanding,
  title={Understanding augmentation-based self-supervised representation learning via rkhs approximation and regression},
  author={Zhai, Runtian and Liu, Bingbin and Risteski, Andrej and Kolter, Zico and Ravikumar, Pradeep},
  journal={arXiv preprint arXiv:2306.00788},
  year={2023}
}

@article{zhang2021inductive,
  title={On the inductive bias of masked language modeling: From statistical to syntactic dependencies},
  author={Zhang, Tianyi and Hashimoto, Tatsunori},
  journal={arXiv preprint arXiv:2104.05694},
  year={2021}
}

@article{arora2019theoretical,
  title={A theoretical analysis of contrastive unsupervised representation learning},
  author={Arora, Sanjeev and Khandeparkar, Hrishikesh and Khodak, Mikhail and Plevrakis, Orestis and Saunshi, Nikunj},
  journal={arXiv preprint arXiv:1902.09229},
  year={2019}
}

@article{tosh2021contrastive,
  title={Contrastive estimation reveals topic posterior information to linear models},
  author={Tosh, Christopher and Krishnamurthy, Akshay and Hsu, Daniel},
  journal={Journal of Machine Learning Research},
  volume={22},
  number={281},
  pages={1--31},
  year={2021}
}

@inproceedings{tosh2021contrastive2,
  title={Contrastive learning, multi-view redundancy, and linear models},
  author={Tosh, Christopher and Krishnamurthy, Akshay and Hsu, Daniel},
  booktitle={Algorithmic Learning Theory},
  pages={1179--1206},
  year={2021},
  organization={PMLR}
}

@article{ba2024learning,
  title={Learning in the presence of low-dimensional structure: a spiked random matrix perspective},
  author={Ba, Jimmy and Erdogdu, Murat A and Suzuki, Taiji and Wang, Zhichao and Wu, Denny},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@article{patarroyo2019digression,
  title={A digression on Hermite polynomials},
  author={Patarroyo, Keith Y},
  journal={arXiv preprint arXiv:1901.01648},
  year={2019}
}

@article{damian2024smoothing,
  title={Smoothing the landscape boosts the signal for sgd: Optimal sample complexity for learning single index models},
  author={Damian, Alex and Nichani, Eshaan and Ge, Rong and Lee, Jason D},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@article{barbier2019optimal,
  title={Optimal errors and phase transitions in high-dimensional generalized linear models},
  author={Barbier, Jean and Krzakala, Florent and Macris, Nicolas and Miolane, L{\'e}o and Zdeborov{\'a}, Lenka},
  journal={Proceedings of the National Academy of Sciences},
  volume={116},
  number={12},
  pages={5451--5460},
  year={2019},
  publisher={National Acad Sciences}
}

@inproceedings{mondelli2018fundamental,
  title={Fundamental limits of weak recovery with applications to phase retrieval},
  author={Mondelli, Marco and Montanari, Andrea},
  booktitle={Conference On Learning Theory},
  pages={1445--1450},
  year={2018},
  organization={PMLR}
}

@article{maillard2019landscape,
  title={Landscape complexity for the empirical risk of generalized linear models},
  author={Maillard, Antoine and Ben Arous, G{\'e}rard  and Biroli, Giulio},
  journal={arXiv preprint arXiv:1912.02143},
  year={2019}
}

@inproceedings{abbe2023sgd,
  title={Sgd learning on neural networks: leap complexity and saddle-to-saddle dynamics},
  author={Abbe, Emmanuel and Adsera, Enric Boix and Misiakiewicz, Theodor},
  booktitle={The Thirty Sixth Annual Conference on Learning Theory},
  pages={2552--2623},
  year={2023},
  organization={PMLR}
}

@article{lu2020phase,
  title={Phase transitions of spectral initialization for high-dimensional non-convex estimation},
  author={Lu, Yue M and Li, Gen},
  journal={Information and Inference: A Journal of the IMA},
  volume={9},
  number={3},
  pages={507--541},
  year={2020},
  publisher={Oxford University Press}
}

@article{sun2018geometric,
  title={A geometric analysis of phase retrieval},
  author={Sun, Ju and Qu, Qing and Wright, John},
  journal={Foundations of Computational Mathematics},
  volume={18},
  pages={1131--1198},
  year={2018},
  publisher={Springer}
}

@article{pan2009survey,
  title={A survey on transfer learning},
  author={Pan, Sinno Jialin and Yang, Qiang},
  journal={IEEE Transactions on knowledge and data engineering},
  volume={22},
  number={10},
  pages={1345--1359},
  year={2009},
  publisher={IEEE}
}


@article{azar2024semi,
  title={Semi-Supervised Sparse Gaussian Classification: Provable Benefits of Unlabeled Data},
  author={Azar, Eyar and Nadler, Boaz},
  journal={arXiv preprint arXiv:2409.03335},
  year={2024}
}


@article{ben2020bounding,
  title={Bounding flows for spherical spin glass dynamics},
  author={Ben Arous, G{\'e}rard and Gheissari, Reza and Jagannath, Aukosh},
  journal={Communications in Mathematical Physics},
  volume={373},
  pages={1011--1048},
  year={2020},
  publisher={Springer}
}

@article{lasalle1949uniqueness,
  title={Uniqueness theorems and successive approximations},
  author={LaSalle, J},
  journal={Annals of Mathematics},
  volume={50},
  number={3},
  pages={722--730},
  year={1949},
  publisher={JSTOR}
}

@article{baik2005phase,
  title={Phase transition of the largest eigenvalue for nonnull complex sample covariance matrices},
  author={Baik, Jinho and Ben Arous, G{\'e}rard and P{\'e}ch{\'e}, Sandrine},
  year={2005}
}

@book{Vershynin_2018, place={Cambridge}, series={Cambridge Series in Statistical and Probabilistic Mathematics}, title={High-Dimensional Probability: An Introduction with Applications in Data Science}, publisher={Cambridge University Press}, author={Vershynin, Roman}, year={2018}, collection={Cambridge Series in Statistical and Probabilistic Mathematics}} <div></div>

@inproceedings{dudeja2018learning,
  title={Learning single-index models in gaussian space},
  author={Dudeja, Rishabh and Hsu, Daniel},
  booktitle={Conference On Learning Theory},
  pages={1887--1930},
  year={2018},
  organization={PMLR}
}

@article{candes2015phase,
  title={Phase retrieval via Wirtinger flow: Theory and algorithms},
  author={Candes, Emmanuel J and Li, Xiaodong and Soltanolkotabi, Mahdi},
  journal={IEEE Transactions on Information Theory},
  volume={61},
  number={4},
  pages={1985--2007},
  year={2015},
  publisher={IEEE}
}


@inproceedings{damian2024computational,
  title={Computational-statistical gaps in gaussian single-index models},
  author={Damian, Alex and Pillaud-Vivien, Loucas and Lee, Jason and Bruna, Joan},
  booktitle={The Thirty Seventh Annual Conference on Learning Theory},
  pages={1262--1262},
  year={2024},
  organization={PMLR}
}

@article{maillard2020phase,
  title={Phase retrieval in high dimensions: Statistical and computational phase transitions},
  author={Maillard, Antoine and Loureiro, Bruno and Krzakala, Florent and Zdeborov{\'a}, Lenka},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={11071--11082},
  year={2020}
}

@article{dandi2024benefits,
  title={The benefits of reusing batches for gradient descent in two-layer networks: Breaking the curse of information and leap exponents},
  author={Dandi, Yatin and Troiani, Emanuele and Arnaboldi, Luca and Pesce, Luca and Zdeborov{\'a}, Lenka and Krzakala, Florent},
  journal={arXiv preprint arXiv:2402.03220},
  year={2024}
}



@article{zweig2024single,
  title={On Single-Index Models beyond Gaussian Data},
  author={Zweig, Aaron and Pillaud-Vivien, Loucas and Bruna, Joan},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@article{mousavi2023gradient,
  title={Gradient-based feature learning under structured data},
  author={Mousavi-Hosseini, Alireza and Wu, Denny and Suzuki, Taiji and Erdogdu, Murat A},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  pages={71449--71485},
  year={2023}
}

@article{tan2023online,
  title={Online stochastic gradient descent with arbitrary initialization solves non-smooth, non-convex phase retrieval},
  author={Tan, Yan Shuo and Vershynin, Roman},
  journal={Journal of Machine Learning Research},
  volume={24},
  number={58},
  pages={1--47},
  year={2023}
}