\documentclass[10pt,twocolumn,letterpaper]{article}
\usepackage[rebuttal]{cvpr}

% Include other packages here, before hyperref.
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{booktabs}

% Import additional packages in the preamble file, before hyperref
\input{preamble}

% If you comment hyperref and then uncomment it, you should delete
% egpaper.aux before re-running latex.  (Or just hit 'q' on the first latex
% run, let it finish, and you should be clear).
\definecolor{cvprblue}{rgb}{0.21,0.49,0.74}
\usepackage[pagebackref,breaklinks,colorlinks,citecolor=cvprblue]{hyperref}

% Support for easy cross-referencing
\usepackage[capitalize]{cleveref}
\crefname{section}{Sec.}{Secs.}
\Crefname{section}{Section}{Sections}
\Crefname{table}{Table}{Tables}
\crefname{table}{Tab.}{Tabs.}

% If you wish to avoid re-using figure, table, and equation numbers from
% the main paper, please uncomment the following and change the numbers
% appropriately.
%\setcounter{figure}{2}
%\setcounter{table}{1}
%\setcounter{equation}{2}

% If you wish to avoid re-using reference numbers from the main paper,
% please uncomment the following and change the counter for `enumiv' to
% the number of references you have in the main paper (here, 6).
%\let\oldthebibliography=\thebibliography
%\let\oldendthebibliography=\endthebibliography
%\renewenvironment{thebibliography}[1]{%
%     \oldthebibliography{#1}%
%     \setcounter{enumiv}{6}%
%}{\oldendthebibliography}


%%%%%%%%% PAPER ID  - PLEASE UPDATE
\def\paperID{*****} % *** Enter the Paper ID here
\def\confName{CVPR}
\def\confYear{2023}
\newcommand{\Ours}{\textsc{GraphGPT-o}\xspace}
\begin{document}

%%%%%%%%% TITLE - PLEASE UPDATE
\title{\Ours: Synergistic Multimodal Comprehension and Generation on Graphs}

\maketitle
\thispagestyle{empty}
\appendix

%%%%%%%%% BODY TEXT - ENTER YOUR RESPONSE BELOW
\section{To Reviewer 66KC}
\textbf{\textit{Question 1:}} PageRank is a classic algorithm for graphs, but the paper could explore more modern techniques, such as graph neural networks, for graph token extraction.

\noindent
\textbf{\textit{Answer 1:}} In \Ours, the PageRank method is used for neighbor selection. Surely it can be refined by introducing some more advanced methods, such as sampling based on textual or visual similarity. We leave this part for future work to make the process more accurate and more controllable. As for graph neural networks, we did some experiments replacing our hierarchical q-former with it, and the result is shown below. \\



\noindent
\textbf{\textit{Question 2:}} In Table 1, several image-only results outperform other methods. This outcome needs further explanation.

\noindent
\textbf{\textit{Answer 2:}} Thank you for pointing this out—it’s indeed a fascinating result. There are two main reasons for this observation: \textbf{First,} it occurs in the Beauty dataset, where the textual information often appears in forms like \textbf{\textit{"Victoria's Secret Dream Angels Heavenly Body Mist 8.4 Oz (250 ML)"}}, which may confuse the MLLM. \textbf{Secondly,} the original MLLM backbone may have limitations in effectively processing long sequences. 
\noindent
\newline
This raises an interesting research question for future work: for each node, how can we adaptively sample or select the most suitable modality for the task at hand? \\

\noindent
\textbf{\textit{Question 3\&4:}} The paper ID is missing. The paper’s overall formatting could be improved for better readability, such as the placement of Figure 4 and Figure 5, which are too far from their corresponding text.

\noindent
\textbf{\textit{Answer 3\&4:}} We are sorry to miss the ID part the formatting. We will refine these in the later version. \\

\section{To Reviewer CKyo}
\noindent
\textbf{\textit{Question 1:}} Intrinsically, it is still an visual conditional MLLM. A key difference is that this work sample visual conditions from graph data and via a certain sampling method. Would the sampling method significantly effect the generation performance?

\noindent
\textbf{\textit{Answer 1:}} Yes, the sampling method is rather important. We compared the results of different sampling strategies in Figure 3. Moreover, the sampling method could be important to make graph for generation more controllable.\\

\noindent
\textbf{\textit{Question 2:}} Beside of sampling method, any novelty in MLLM? Would be the MLLM part replaced by any SOTA MLLMs? 

\noindent
\textbf{\textit{Answer 2:}} Our goal is to introduce a plug-and-play component that seamlessly integrates with all SOTA MLLMs. The novelty lies in the hierarchical tokenization approach, which aligns semantic information across text, image, and graph modalities, enabling richer and more cohesive representations. This component is designed to be both easy to implement and train, making it a versatile addition to existing MLLMs.\\

\noindent
\textbf{\textit{Question 3:}} A node will carry multiple images/captions? The token length for a node will vary a lot?

\noindent
\textbf{\textit{Answer 3:}} A node is associated with only one image and one textual description. The token length within one dataset will not vary a lot. \\

\noindent
\textbf{\textit{Question 4:}} For neighbors, are you only using first nearest neighbors? What if including second or ever further neightbors?

\noindent
\textbf{\textit{Answer 4:}} For neighbors sampling, we used PageRank to sample neighbors. Some 2-hop or multi-hop neighbors might be sampled.

\section{To Reviewer X3yz}
\noindent
\textbf{\textit{Question 1:}} The ablation study includes only the hierarchical aligner module and the Personalized PageRank sampling method. The ablation studies for different approaches to graph linearization and inference strategies are missing.

\noindent
\textbf{\textit{Answer 1:}} We demonstrate the results of graph linearization in Table 1. And based on the results, we choose to input both text and image modalities in the order of text-first and also text-first during inference. \\

\noindent
\textbf{\textit{Question 2:}} It appears that there are too few methods compared in the study.

\noindent
\textbf{\textit{Answer 2:}} We had added two more baselines and the results are shown below.\\

\noindent
\textbf{\textit{Question 3:}} The qualitative results are insufficient.


\noindent
\textbf{\textit{Answer 3:}}


\end{document}
