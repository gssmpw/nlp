\section{Related Work}\label{se:related}
The related work of our research includes DSLs defined for metadata usage checking, detection of metadata-related bugs, and configuration debugging.

  \vspace{-.5em}
\subsection{Domain-Specific Languages (DSLs) Defined for Metadata-Usage Checking}

People invented DSLs to check and/or fix the usage of metadata (i.e., XML and annotations)~\cite{
benzaken2003cduce,chamberlin2002xquery,hosoya2003xduce,darwin2009annabot,eichberg2005using,Song12,noguera2008annotation}. For instance, XQuery is a widely used query and functional programming language that queries and transforms collections of structured or unstructured data in XML documents~\cite{chamberlin2002xquery}. Similarly, CDuce~\cite{benzaken2003cduce} and XDuce~\cite{hosoya2003xduce} are independently developed DSLs for XML processing. 
%To validate and transform XML files, users have to learn one of these DSLs and uses the DSL to prescribe matching logic and change operations, which procedure can be tedious and error-prone. 
To validate Java annotation usage, 
Eichberg et al.~created a DSL for users to define constraints~\cite{eichberg2005using}. To check user-specified constraints, the researchers automatically converted Java bytecode to XML documents, and converted constraints to XQuery path expressions.  Darwin~\cite{darwin2009annabot} and Noguera et al.~\cite{noguera2008annotation} also  defined distinct DSLs for users to specify and  validate the constraints on annotation usage. 
All DSLs mentioned above only focus on one type of metadata (i.e., either XML or annotations), but not on both types or on the relations between them. 


%However, general developers may not have sufficient domain knowledge to properly utilize these languages. 

Song and Tilevich created (1) MIL to express metadata invariants, and (2) the language implementation/engine to 
examine code-annotation relations (i.e., relations between Java code and annotations) and code-XML relations (i.e., relations between code and XML)~\cite{Song12}. We tried to run MIL engine in our experiments, albeit without success. RSL is different from MIL in three ways. First, it is an imperative instead of declarative language, so users have more flexibility in controlling how items are extracted, enumerated, filtered, and checked. 
Second, RSL has stronger expressiveness. It can express rules to examine 
XML-annotation-code constraints and XML-annotation constraints, but we did not find MIL capable of doing that. Third, RSL can  have better performance, because we applied specialized optimizations in \tool to eliminate repetitive computation but MIL engine was unoptimized.
%while the implementation of MIL was not optimized.

  \vspace{-.5em}
\subsection{Detection of Metadata-Related Bugs}

Researchers created tools to automatically detect metadata-related bugs~\cite{Noguera2012,Wen20,Nuryyev2022,Zhang2024}.
For instance, Wen et al.~created XEDITOR to automatically infer and apply def-use like configuration couplings in XML files~\cite{Wen20}. Specifically, XEDITOR extracts XML entity pairs that (i) frequently coexist in the same files and (ii) hold the same data at least once; it then applies customized association rule mining to infer def-use like couplings ``A$\rightarrow$B'' between entities. For bug detection, given a new XML file, XEDITOR checks whether the file violates any couplings; if so, XEDITOR reports the violation(s). 
Noguera et al.~created an extension of the Eclipse IDE's refactoring engine, to check whether any Java code refactoring violates the
correspondence constraints between existing code and annotations~\cite{Noguera2012}. 
Nuryyev et al.~devised a frequent-itemset based pattern mining approach to mine annotation-usage rules for MicroProfile, an open-source Java microservice framework~\cite{Nuryyev2022}. 
By scanning 533 MicroProfile projects for violations of 12 of the mined rules, the researchers found 100 violations of 5 mined rules in 16 projects. 
Zhang et al.~noticed that existing static program analyzers are unaware of the semantic changes introduced by annotations, and consequently can produce imprecise analysis results~\cite{Zhang2024}. Thus, they conducted a study of annotation-induced faults (AIF) by analyzing 246 issues in 6 open-source and popular static analysis (i.e., PMD, SpotBugs, CheckStyle, Infer, SonarQube, and Soot). Based on their findings in the study, the researchers created a tool to generate new tests for static analyzers, and revealed 43 new faults, 20 of which have been fixed.

Our research complements prior work in two ways. First, it examines correspondence constraints in a wider scope, by querying and checking on the content correspondence in XML files, Java code, and annotations; nevertheless, existing tools only examine correspondence in one type of metadata. 
No existing tool examines the content constraints between XML and annotations,  but \tool does so.
Second, RSL enables people (e.g., library developers) to freely express domain-specific constraints for XML-based and annotation-based configurations. This feature is especially important when some domain-specific constraints are not detectable for any mining tool.
%Therefore, when a domain-specific rule is not discovered by any mining tool, people can still leverage RSL to integrate that rule into automatic metadata analysis. 
Furthermore, when a constraint is mined by existing tools, people can easily extend \tool by defining an RSL specification for it, to embed the mined knowledge into automatic metadata analysis.

%quickly strengthen automatic metadata analysis with the mined knowledge. 

%Based on their manual analysis of existing annotation usage rules described for MicroProfile, they devised a frequent-itemset based pattern mining approach for mining annotation usage rules, and found 12 of the 23 mined rules are at least partially valid. By scanning 533 MicroProfile projects for violations of the 12 rules, they found 100 violations of 5 mined rules in 16 projects, which indicates that the 12 rules are useful in detecting annotation-based API misuse.

  \vspace{-.5em}
\subsection{Configuration Debugging}
Some tools were built to diagnose or fix software configuration errors~\cite{Attariyan:2008:UCD,Attariyan:2010:ACT,Rabkin:2011:PPC,Zhang:2013:ADS,Weiss:2017:TIS,Oh2021}. 
%These approaches execute buggy software, gather execution profiles, compare the profiles, and/or conduct dynamic analysis to locate errors. 
For instance, Attariyan et al.~\cite{Attariyan:2008:UCD} and Zhang et al.~\cite{Zhang:2013:ADS} separately created tools to record predicates that may be affected by configuration options, collect the execution profiles of a program's correct and undesired runs, and compare the behavioral differences between the two types of runes to diagnose configuration errors. 
%Attariyan and Flinn also created another tool---ConfAid~\cite{Attariyan:2010:ACT}. The tool instruments application binaries to monitor the causal dependencies introduced through control and data flow as the program executes; it uses these dependencies to link the erroneous behavior to specific tokens in configuration files. 
Rabkin and Katz created a static analysis-based tool to help users debug configuration errors in software~\cite{Rabkin:2011:PPC}. 
The tool tracks the flow of configuration labels through a program: labels are introduced via configuration reads, and propagate via assignment and library calls. %Unlike taint tracking, the tool does not try to find all possible dependencies, but only the most relevant ones for troubleshoot. To avoid the well-known problem of taint explosion, it applies a number of heuristics. 
%It computes a forward thin slice from each configuration option read point, and records the set of slices that each program point belongs to. 
\tool produces a table mapping each line in the program's source code to the set of relevant configuration dependencies. This procedure is done by developers at release time. When a user encounters an error, they can use the error message to query this table. 
 
Weiss et al.~built an approach to generalize system configuration repairs for certain types of machines, from the shell commands developers entered to update one machine~\cite{Weiss:2017:TIS}. 
Oh et al.~introduce a model checking framework for building Kconfig static analysis tools~\cite{Oh2021}. The configuration specification language, Kconfig, is defined to prevent invalid configurations of the Linux kernel from being built. %However, Kconfig specifications can have bugs that are hard to detect. 
To detect bugs in Kconfig specifications, Oh et al.~created a symbolic evaluator \codefont{kclause} to model Kconfig specifications, and a tool to find bugs in \codefont{kclause} models. 
%and leverage theorem proving to find bugs.

The configuration files examined by these tools are irrelevant to XML documents or Java annotations, so they cannot detect the bugs we  focus on. 
