\subsection{Detection of Metadata-Related Bugs in Real-World Settings}\label{ss:eval-real-world}

To assess how well \tool reveals real bugs, we also created a dataset of \totalRealProject real-world open-source software repositories (Section~\ref{sec:dataset}), and applied \tool to that dataset (Section~\ref{sec:real-setting}). 

\subsubsection{A Dataset of Real-World Software Repositories}\label{sec:dataset}
To create this dataset, we started with the \totalProject projects initially mined from GitHub (see Section~\ref{sss:data}). From those projects, we removed 85 projects that are irrelevant to any of the \totalRule rules implemented in \tool. Namely, if a project does not contain any code/XML/annotation item involved in those rules, we consider it irrelevant. Afterwards, we 
removed the \totalInjection projects used for creating buggy EAs (see Section~\ref{sss:data}), to avoid doing multiple experiments on the same projects.  
%Due to the time limit, we were unable to experiment with all versions of the remaining 701 projects,  
{Na\"ively, we could experiment with all program versions{,} for each of the remaining 701 projects, to check whether any version has metadata-related bugs and violates our predefined rules. However, it  would take too much time to analyze all versions of each project,} 
%This is because when a project is very large and has thousands of versions kept in its repository, it can be very time-consuming to run \tool with all program versions. 
so we decided to only experiment with a subset of the pool.  
%experiment with a sample set of projects from that pool. 
To ensure the representatives of our experiment and results, we decided to include projects of distinct scales (i.e., small, medium, and large projects). Thus, we ranked the 701 projects in ascending order of Java file counts, as file counts roughly reflect project sizes. We randomly sampled 10 projects for every 100-project interval, and got \totalRealProject projects. 
%Then we located program commits in those projects, which modify file(s) that have items to be checked by \tool. In this way, we did not need to apply \tool to all version of the \totalRealProject projects, but only needed to experiment with the versions where any of the rule-related files are edited.

In our resulting dataset, each project has 1--987 Java files and 5--1068 total files; the mean value of Java files in each project is 68; the median value of Java files is 24.


\subsubsection{Experiment and Results}\label{sec:real-setting}

We applied \tool to different versions of each selected project, to thoroughly explore whether developers committed any mistakes when maintaining metadata and related Java code. Because many projects have long version histories, it can be very time-consuming to apply \tool to all versions of each project. 
Therefore, to accelerate the bug detection procedure, we developed scripts to filter versions, and focus our experiments on versions that edit any Java or XML file containing code/annotation/XML items relevant to the \totalRule rules. 

Our results show that among the selected \totalRealProject software repositories, \tool reported in total \totalReportedInReal bugs in 21 projects. After manually inspecting the bug reports, we found \totalInteresting reports to be true positives, as they violate either $r_1$ (i.e., xml-path-check) or $r_2$ (i.e., bean-class-exists).   
%so we calculated the detection precision as 78\% (121/156). 
{In particular, 18 bugs were detected in the first commits of software repositories; % 102
{99} bugs were found in later commits, meaning that developers accidentally introduced the bugs when they revised software for maintenance.}
{115 of the \totalInteresting bugs were reported together with bugs of the same kind. The existence of multiple bugs in the same program version does not affect our evaluation results, as bugs are analyzed and reported independently. }
% Furthermore, we noticed that \totalRealBugs of the \totalInteresting true positives were already fixed by developers, because we checked later versions of the same projects and those programs got revised  for bug fixing. 

{Furthermore, we noticed that \totalRealBugs of the \totalInteresting true positives were already fixed by developers. We found that out by checking later versions of the same projects and by observing revision of those buggy programs.} The remaining 68 bugs had not been fixed yet, so we filed bug reports to contact developers and seek for their feedback. So far, we have not heard from developers for those bug reports.
There are \totalFalsePositives false positives in the \totalReportedInReal bug reports, because the RegEx patterns we used to identify library classes do not cover all the libraries used by EAs.
%Namely, when an EA references a library class $C$ without defining it and \tool fails to recognize $C$ as a library class, \tool incorrectly reports a mismatch between metadata and code items. Although we tried our best to define RegEx patterns to cover frequently used libraries, there are always libraries that we overlooked but get used by EAs. Thus, such false positives are not fully avoidable for RegEx-based approaches. In the future, people may try to overcome the limitation 

\begin{table}
\footnotesize
    \centering
        \caption{The \totalRealBugs real bugs later fixed by developers}
    \label{tab:real-bug-fix}\vspace{-1.5em}
    \begin{tabular}{r l r R{2cm} r R{3cm}}
\toprule 
    \textbf{Idx}& \textbf{Project Name}&\textbf{\# of Bugs}&\textbf{Ddiff(bug, fix) {(days)}}&\textbf{Vdiff(bug, fix)} &\textbf{Time cost per version ({seconds})}\\ \toprule
    1 & aioweb~\cite{aioweb} & 9 & 1--2 & 1--2&4--6\\ \hline
    2 & angular-js-spring-mybatis~\cite{angular} & 1 & 0 & 1 & 0\\ \hline
    3 & biyam\_repository~\cite{biyam} & 2 &194 & 4&2 \\ \hline
    4 & cv-web~\cite{cv-web} & 2 & 44--47& 1--2&0 \\ \hline
    5 & enterprise-routing-system~\cite{enterprise-routing-system} &2 & 0& 1&5--6 \\ \hline
    6 & FileExplorer~\cite{fe} &1 &0 & 1&3 \\ \hline
    7 & generica~\cite{generica} &2 & 0 &1&2\\ \hline
    8 & I377-esk~\cite{I377} & 1 & 0 &1&7 \\ \hline
    9 & jarvis~\cite{jarvis} & % 3
    {4}& 9--10 &4--5&2--6\\ \hline
    10 & johnsully83\_groovy~\cite{johnsully} &10 &23&2 &17\\ \hline
    11 & Kognitywistyka~\cite{kognity} & 8 & 0 &1--3 &3--4\\ \hline
    12 & LIBRARY~\cite{library} & 2 & 0 & 1&2\\ \hline
    13 & rop~\cite{rop} & % 7 
    {3} &5--% 597
    {556} & 2--% 59
    {27} &7--9\\ \hline
    14 & ShcUtils~\cite{shcutils} & 1 & 1 & 1&0\\ \hline
    15 & spring-vaadin~\cite{vaadin} & 1 & 10 &1&0\\ \bottomrule
    \end{tabular}
\vspace{-2.em}
\end{table}
%, \tool incorrectly interprets the class to be 
%As a result, when a referenced library class is not recognized by \tool to be defined in a library, and it

%With more details, as shown in Table~\ref{tab:real-bug-fix}, 
Table~\ref{tab:real-bug-fix} presents 
the % 53 
\totalRealBugs bugs that developers later fixed.
All these bugs violate $r_2$---the bean-class-exists rule. Namely, each of the bugs references a nonexistent class when declaring a bean.
In Table~\ref{tab:real-bug-fix}, 
 column \textbf{Idx} shows the index we assigned to each buggy project. \textbf{Project Name} lists the projects where the bugs occurred. \textbf{\# of Bugs} counts the total number of bugs we found in different versions of each project. \textbf{Ddiff(bug, fix)} describes the day difference between committing dates of a bug-fixing version and the related bug-introducing version. Similarly, \textbf{Vdiff(bug, fix)} describes the version difference between the bug-fixing version and buggy version. Let us take the second project angular-js-spring-mybatis~\cite{angular} as an example. In one commit $C_i$ checked in on % 01/29/2014
 {Jan 29, 2014}, {developers declared a bean by wrongly referencing a nonexistent class.} In a later commit $C_{i+1}$ checked in on the same day, developers fixed the bug by {correcting the class reference}. Therefore, Vdiff(bug, fix) = (i+1) - i = 1, and Ddiff(bug, fix) = 0. 

For only % 16
{17} of the \totalRealBugs bugs, developers applied fixes on the same day. However, for the remaining % 37
{32} bugs, developers applied fixes either on the following day or after quite a long time. 
{15 of the bugs we detected were fixed 1-10 days after the bug-introducing commits; 17 of the bugs were fixed more than 10 days after the bug-introducing commits. 
The largest time difference we observed between a bug-fixing commit and a buggy version is 556 days. 
The phenomena imply the difficulty of revealing those bugs, and the necessity of our approach.}
Additionally, 
{for 24 of the \totalRealBugs bugs, developers applied fixes in the immediately next commit. However, they fixed the remaining bugs after at least two commits. Most interestingly, developers fixed a bug in rop~\cite{rop} after 
% 59
{27} commits. 
These observations indicate the great benefits developers can potentially get out of the \tool usage.  
Namely, if developers had used \tool to examine their software before committing program changes, they should have avoided checking in the erroneous program changes, or even have fixed the introduced bugs earlier. 

%\color{red} Additionally, based on our experiments for \ref{ss:eval-effect-mecheck}, all the rule violations are severe bugs that trigger runtime errors instead of compilation errors. It means that without any tool support, developers have to wait till the testing phase, to reveal those rule violations, making the bugs critical. \color{black} 

Finally, \tool has very low runtime cost. We experimented with a laptop that has (1) an Intel i7-8565U CPU with four cores and eight logical processors, and (2) 15.9 GB memory. 
As shown in Table~\ref{tab:real-bug-fix}, when \tool was applied to detect bugs based on the \totalRule rules, it spent no more than 6 seconds on each program version. 

\vspace{0.5em}
\noindent\begin{tabular}{|p{13.6cm}|}
	\hline
	\textbf{Finding 3 (Response to RQ3):} \emph{\tool demonstrated great effectiveness and high performance when being applied to different versions of 70 real-world open-source EAs. It reported in total \totalReportedInReal bugs; \totalInteresting of the bugs are true positives, \totalRealBugs of which have been already fixed by developers
 %It managed to detect bugs with \precision precision, \recall recall, and \fscore F-score. 
 }
	\\
	\hline
\end{tabular}