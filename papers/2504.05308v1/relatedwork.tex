\section{Related works}
Typically, revenue maximization is solved using standalone reranking models. 
For example, studies~\cite{kompan2021exploring, de2024model,pei2019value} propose models based on individual-based metrics that improve revenue but ignore the influence of neighboring items. 
The latter feature can lead to a reduction in user engagement if high-value items are placed together at the top of the page with search results.
Therefore, standalone reranking models may permute search results in a way that increases revenue but decreases user engagement.
To prevent this negative effect, an auxiliary click model should be used to evaluate the relevance of the perturbed search results generated by the re-ranking model~\cite{2021context}.
The standard quantity for relevance estimation is click-through rate (CTR).
The industry standard for CTR prediction~\cite{chen2024branches, gao2024gbdt4ctrvis} is
Gradient Boosting Decision Trees (GBDT) ~\cite{friedman2001greedy,chen2016xgboost,prokhorenkova2018catboost,ke2017lightgbm}.
At the same time, factorization machines, like DeepFM~\cite{guo2017deepfm} and FFM~\cite{juan2016field}, improve CTR prediction accuracy by explicitly capturing the dependence between items' features.
In contrast, deep learning models like Wide \& Deep~\cite{cheng2016wide} and FiBiNET~\cite{huang2019fibinet} 
% \cite{covington2016deep}
rely on neural networks to implicitly capture dependence between items' features through non-linear transformations.
Although Transformer models~\cite{stec, hou, rat, chen2022extr} could fit the CTR prediction task, they still track only dependencies within item features. 
Thus, the approaches mentioned above do not consider the user's features like previous clicks, timestamp, location, etc.

To address this limitation, models for processing sequential users' actions are developed.
In particular, Recurrent Neural Networks (RNN)~\cite{lstm_with_attn_CTR} and attention mechanism~\cite{vaswani2017attention,min2022neighbour} improve CTR prediction in this setup. 
Other RNN-based models like DIN~\cite{din} and DIEN~\cite{dien} predict user actions based on the available history logs.
While the mentioned studies include user features and the corresponding sequential data in the models for CTR prediction, they do not consider how the neighbor items affect the CTR of the selected item. 
This effect is important for users' behavior, see~\cite{effects,banner}.

A combination of the clicker and reranking models is proposed in~\cite{monster}, where the Bi-GRU clicker model captures the search context and the RL-based reranking model with GRU and MLP adjusts the search results order. 
However, this model training is too costly due to the architecture's complexity, and the authors do not share their implementation. 
A similar idea is developed in~\cite{2021context}, where Position-aware Graph Embedding with Bi-LSTM is used for modeling item interactions while contextual loss is used for pairwise revenue maximization. 
This approach effectively captures context over the search results items but suffers from processing long sequences of items in search results.