\section{Derivation of the gradient of Eq.~\eqref{eq:look_ahead_policy}} \label{app:gradient}

We derive the gradient of the look-ahead policy using the chain-rule as follows:
\begin{align*}
    \nabla_{\bpi} (R(\bar{\bpi}_t^{1}(\bpi); \bar{\blambda}_t(\bpi))) 
    &= \nabla_{\bpi} \left( \sum_{k=1}^{K} \bar{\lambda}_{k}(\bpi) \sum_{l=1}^L \bar{\pi}_{k,l}^{1}(\bpi) (b_{k,l} + f_{k,l}(\bar{\lambda}_l(\bpi))) \right) \\
    &= \sum_{k=1}^{K} \sum_{l=1}^L \nabla_{\bpi} (\bar{\pi}_{k,l}^{1}) \, \bar{\lambda}_k(\bpi) (b_{k,l} + f_{k,l}(\bar{\lambda}_l(\bpi))) \\
    & \quad + \sum_{k=1}^K \nabla_{\bpi} (\bar{\lambda}_k) \sum_{l=1}^L \bar{\pi}_{k,l}^{1}(\bpi) (b_{k,l} + f_{k,l}(\bar{\lambda}_l(\bpi))) \\
    & \quad + \sum_{k=1}^K \bar{\blambda}_k(\bpi) \sum_{l=1}^L \nabla_{\bar{\lambda}_l} (f_{k,l}) \nabla_{\bpi} (\bar{\lambda}_l) \, \bar{\pi}_{k,l}^{1}(\bpi),
\end{align*}
where the $(k', l')$-th element of the gradient matrix is defined as follows:
\begin{align*}
    \nabla_{\bpi} (\bar{\lambda}_k)_{k',l'} 
    &= \nabla_{s_k} (\bar{\lambda}_k) \nabla_{\bpi} (s_k)_{k',l'} 
    = \nabla_{s_k} (\bar{\lambda}_k) \cdot \mathbb{I} \{ k' = k \} \, q_{k',l'}, \\
    \nabla_{\bpi} (\bar{\lambda}_l)_{k',l'} 
    &= \nabla_{e_l} (\bar{\lambda}_l) \nabla_{\bpi} (e_l)_{k',l'} 
    = \nabla_{e_l} (\bar{\lambda}_l) \cdot \mathbb{I} \{ l' = l \} \lambda_{k'}.
\end{align*}
Note that $\nabla_{\bar{\lambda}_l} (f_{k,l})$, $\nabla_{s_k} (\bar{\lambda}_k)$, and $\nabla_{e_l} (\bar{\lambda}_l)$ can be the gradient of the estimated dynamics and population effect functions, when the true dynamics are not accessible (i.e., we can use the estimation process described in Section~\ref{sec:dyanmics_estimation}).

When implementing the algorithm, one can also use \texttt{autograd} implemented in PyTorch~\citep{paszke2019pytorch} to calculate the gradient directly from the look-ahead objective.

\section{Omitted Proofs} \label{app:proofs}

This section provides proofs for the Theorems and Propositions presented in the main text. Note that we define the fixed point and Nash equilibrium as follows.

\begin{definition}[Fixed point] \label{def:fixed_point} $\blambda_{eq}$ is the fixed point under the policy $\bpi$ when $\blambda_{eq}$ satisfies,
\begin{align*}
    \exists T_0 > 0, \, \forall t > T_{0}, \quad \lVert \blambda_{t+1} - \blambda_{eq} \rVert \, \leq \, \lVert \blambda_{t} - \blambda_{eq} \rVert.
\end{align*}
\end{definition}

\begin{definition}[Nash equilibrium] \label{def:nash_eq} $\blambda^*$ is a Nash equilibrium of game $\G(\bpi,B,f,\bar{\lambda})$ under the policy $\bpi$ when $\blambda^*$ satisfies,
\begin{align*}
    & \lambda_k^* = \arg\max_{\lambda_k} \; u_k(\lambda_k,\blambda_{-k}=\blambda_{-k}^*), \\
    & \lambda_l^* = \arg\max_{\lambda_l} \; v_l(\lambda_l, \blambda_{-l}=\blambda_{-l}^*),
\end{align*}
where $\blambda_{-k},\blambda_{-l}$ denotes the vectors that contain all elements of $\blambda^*$ except $\lambda_k$ and $\lambda_l$, and $u_k,v_l$ are determined by Eqs. \eqref{eq:util_user} and \eqref{eq:util_creator}.
\end{definition}

Based on the definition of fixed point, we prove the properties of the policy and the corresponding fixed point below.

\subsection{Proof of Proposition~\ref{coro:sufficient_eq}} \label{proof:condition_eq}
To prove Proposition~\ref{coro:sufficient_eq}, we first introduce the following Theorem~\ref{thrm:condition_eq}. We also use the fixed point described in the following in the proof of Theorem~\ref{thm:ne_exist}.

\begin{theorem}[Conditions for a fixed point] \label{thrm:condition_eq}
    $\blambda_{eq}$ is a stable equilibrium when the following is satisfied for all $l \in [L]$. 
    \begin{align*}
        \eta_l (1 - \eta_l) (\nabla_{e_l} \bar{\lambda}_l) (\nabla_{\lambda_l} f_l) \sum_{k=1}^{K} \eta_{k} (\nabla_{s_k} \bar{\lambda}_k) \pi_{k,l} < 1
    \end{align*}
    where $(\nabla \cdot)$ is the first-order derivative at $\blambda_{eq}$.
\end{theorem}

\begin{proof}
We prove the condition for the stable equilibrium. Let $S(\cdot)$ be the dynamics function that maps the population from the previous timestep to the next timestep, i.e., $\lambda_{t+1} = S(\lambda_{t})$. Then we have
\begin{align*}
    \lambda_{t+1} - \lambda_{eq} = (\nabla_{\lambda} S) (\lambda_{t} - \lambda_{eq}).
\end{align*}
This matrix is decomposed into four sub-matrices as 
\begin{align*}
    (\nabla_{\lambda} S) = \begin{bmatrix}
    A_{1,1} & A_{1,2} \\
    A_{2,1} & A_{2,2}
\end{bmatrix}
\end{align*}
where $A_{1,1}$ is a ($K, K$)-dimensional matrix, $A_{1,2}$ is a ($K, L$)-dimensional matrix, $A_{2,1}$ is a ($L, K$)-dimensional matrix, and $A_{2,2}$ is a ($L, L$)-dimensional matrix. From the dynamics equations~\ref{eq:user_dynamics} and \ref{eq:content_dynamics}, the element of each matrix is derived as
\begin{align*}
    \{A_{1,1}\}_{k,k'} 
    &= (\nabla_{\lambda_{k'}} \lambda_k) 
    = (1 - \eta_k) \mathbb{I} \{ k = k' \} \\
    \{A_{2,2}\}_{l,l'} 
    &= (\nabla_{\lambda_{l'}} \lambda_l) 
    = (1 - \eta_l) \mathbb{I} \{ l = l' \} \\
    \{A_{1,2}\}_{k,l} 
    &= (\nabla_{\lambda_{l}} \lambda_k) 
    = \eta_k (\nabla_{q_k} \bar{\lambda}_k) \pi_{k,l} (\nabla_{\lambda_l} f_l) \\
    \{A_{2,1}\}_{l,k} 
    &= (\nabla_{\lambda_{k}} \lambda_l) 
    = \eta_l (\nabla_{e_l} \bar{\lambda}_l) \pi_{k,l}
\end{align*}.
When the spectrum radius (i.e., the maximum eigenvalues) of $(\nabla_{\lambda} S)$ is less than $1$, $\lambda_{eq}$ is a stable equilibrium of the dynamics. Here, because $A_{1,1}$ and $A_{2,2}$ are invertible matrices, we can use the Schur complement as
\begin{align*}
    \mathrm{det}(\nabla_{\lambda}S) = \mathrm{det}(A_{1,1}) \, \mathrm{det}(\underbrace{A_{2,2} - A_{2,1} A_{1,1}^{-1} A_{1,2}}_{:=A'}).
\end{align*}
Therefore, when the eigenvalues of $A_{1,1}$ is $\mu_1$ and that of $A'$ is $\mu_2$, 
the eigenvalues of $(\nabla_{\lambda} S)$ is $\mu = [\mu_1, \mu_2$]. Thus, the eigenvalues of $(\nabla_{\lambda} S)$ are
\begin{align*}
    \{\mu_{1}\}_k &= (1 - \eta_k) \\
    \{\mu_{2}\}_l &= \eta_l (1 - \eta_l) (\nabla_{e_l} \bar{\lambda}_l) (\nabla_{\lambda_l} f_l) \sum_{k=1}^{K} \eta_{k} (\nabla_{q_k} \bar{\lambda}_k) \pi_{k,l}
\end{align*}
\end{proof}

When $\eta_k \leq \eta, \forall k \in [K]$ hold and the gradient norm is bounded as $(\nabla_{e_l} \bar{\lambda}_l)(\nabla_{\lambda_l} f_l) \leq C_1$ and $(\nabla_{q_k} \bar{\lambda}_k) \leq C_2$ at $\lambda_{eq}$, we have Proposition~\ref{coro:sufficient_eq}:
\begin{align*}
    \sum_{k=1}^{K} \pi_{k,l} \leq \frac{4 \eta^{-1}}{C_1 C_2},
\end{align*}
where we use $\forall \eta_l \in [0, 1), \eta_l(1- \eta_l) \leq 0.25$.

\vspace{3mm}

\subsection{Proof of Theorem~\ref{thm:ne_exist}}\label{app:exist_eq}

\begin{proof}
\textbf{Existence of NE:} First we show the Nash equilibrium must exist. Note that $u_k, v_l$ take negative values as $\lambda_k,\lambda_l$ become sufficiently large, we can without loss of generality assume each player's strategy is upper bounded by a finite constant. As a result, for each player in the game, its strategy set is a convex, closed, and bounded region, and its utility function is clearly concave in its own strategies. According to Theorem 1 in \cite{rosen1965existence}, such a game is a concave $n$-person game and its Nash equilibrium must exist.

\textbf{Non-uniqueness of NE:}
Next, we give an example showing that the Nash equilibrium is not necessarily unique, if we do not impose any assumption on $\bar{\lambda}_k,\bar{\lambda}_l,q$. Consider the case when $K=L=1$ and the following configurations
    \begin{align*} \bar{\lambda}_k(\lambda^{(c)})=\sigma(4(2\lambda^{(c)}-1)), \quad \bar{\lambda}_l(\lambda^{(u)})=\sigma(3(2\lambda^{(u)}-1)),
    \end{align*}
    where $\sigma(x)=1/(1+\exp(-x))$ is the sigmoid function. In this case, the two players have the following utility functions
    \begin{align}\notag
        & u_1(\lambda^{(u)},\lambda^{(c)})=\lambda^{(u)}\cdot \sigma(4(2\lambda^{(c)}-1)) - \frac{1}{2} (\lambda^{(u)})^2,\\\label{eq:nega_example}
        & u_2(\lambda^{(c)},\lambda^{(u)})=\lambda^{(c)}\cdot \sigma(3(2\lambda^{(u)}-1)) - \frac{1}{2} (\lambda^{(c)})^2.
    \end{align}
    Any fixed point of system \eqref{eq:nega_example} should satisfy the following first-order condition
    \begin{equation}\label{eq:20}
    \lambda^{(u)}=\sigma(4(2\lambda^{(c)}-1)),\quad \lambda^{(c)}=\sigma(3(2\lambda^{(u)}-1)),
    \end{equation}
    and we can easily verify that Eq. \eqref{eq:20} has three solutions
    \begin{equation}\label{eq:24}
        [\lambda^{(u)}, \lambda^{(c)}]=[0.0278, 0.0555], \quad [0.5, 0.5], \quad [0.9722, 0.9445].
    \end{equation}
    On the other hand, since each player's utility function is strictly concave in its own strategy, any fixed point of system \eqref{eq:nega_example} must correspond to a Nash equilibrium of the game. Hence, the game has three distinct Nash equilibria, which are given by Eq. \eqref{eq:24}.
    
 \textbf{Convergence of two-sided dynamics:} According to Theorem \ref{thrm:condition_eq}, we know that two-sided dynamics converge to some stable fixed point $\blambda_{eq}$, as long as for each reactiveness hyperparam $\eta$, it holds that
 \begin{align}\label{eq:hyper_param_eta_condition}
    \sum_{k=1}^{K} \pi_{k,l} \leq \frac{4 \eta^{-1}}{C_1 C_2},
\end{align}
where $C_1$ and $C_2$ are upper bounds of $(\nabla_{e_l} \bar{\lambda}_l)(\nabla_{\lambda_l} f_l)$ and $(\nabla_{q_k} \bar{\lambda}_k)$ at $\blambda_{eq}$. A sufficient condition for Eq. \eqref{eq:hyper_param_eta_condition} to hold is $\eta\leq \frac{4}{KC_1C_2}$. 

Next we argue that $\blambda_{eq}$ must also correspond to the Nash equilibrium of $\G$ if $\eta\leq \frac{4}{KC_1C_2}$. This is because $\blambda_{eq}$ being a stable point means that for each viewer $k$ and provider $l$ under $\blambda_{eq}$, they cannot alter their strategies unilaterally to improve their payoffs $u_k$ or $v_l$ in a small region around $\blambda_{eq}$. That is, $\lambda_k,\lambda_l$ given by $\blambda_{eq}$ are the local maximum points of $u_k$ and $v_l$ under $\blambda_{eq}$. Since both $u_k$ and $v_l$ are strictly concave quadratic functions in $\lambda_k$ and $\lambda_l$, their local maximum points must also be the global maximum points. Hence, they also cannot unilaterally improve their payoffs in their entire strategy sets. This demonstrates that $\blambda_{eq}$ satisfies the definition of Nash equilibrium.

\end{proof}

\subsection{Proof of Theorem~\ref{prop:regret}} \label{proof:regret}

\begin{proof}
Here, we provide a proof of the regret decomposition. First of all, we have
\begin{align*}
    &R(\bpi^{\ast}; \blambda_t^{\ast}) - R(\bpi_t; \blambda_t) \\
    &= R(\bpi^{\ast}; \blambda_t^{\ast}) \textcolor{blue}{- R(\bpi_t^{1, \ast}; \blambda_t^{\ast}) + R(\bpi_t^{1, \ast}; \blambda_t^{\ast})} \textcolor{dkred}{- R(\bpi_t^{1}; \blambda_t) + R(\bpi_t^{1}; \blambda_t)} - R(\bpi_t; \blambda_t) \\
    &= \Delta R (\blambda_t^{\ast},  \blambda_t) + \Delta R (\bpi_t^{1}, \bpi_t) + \text{const.}
\end{align*}
where 
\begin{itemize}
    \item $\Delta R (\blambda_t^{\ast},  \blambda_t) := R(\bpi_t^{1,\ast}; \blambda_t^{\ast}) - R(\bpi_t^{1}; \blambda_t)$ is the regret arises from the population difference of stationary optimal policy ($\bpi^{\ast}$) and the policy of interest ($\bpi_t$). 
    \item $\Delta R (\bpi_t^{1}, \bpi_t) := R(\bpi_t^{1}; \blambda_t) - R(\bpi_t; \blambda_t)$ is the one-step regret of the policy.
    \item $\text{const.} = R(\bpi_t^{1, \ast}; \blambda_t^{\ast}) - R(\bpi_t^{\ast}; \blambda_t^{\ast})$ is the one-step regret of the stationally optimal policy. This term does not depend on $\bpi$ and only depends on $\bpi^{\ast}$.
\end{itemize}
Then, let $\blambda_t^{\pi}$ to be the population dynamics of a stationary policy $\bpi$. From the assumption about the policy convergence, 
\begin{align*}
    \forall \delta, \delta' > 0, \; \exists T_0 \in \mathbb{Z}, \; 
    \text{s.t.}, \; \forall t > T_0, \; D(\bpi, \bpi_t) < \delta' \; \text{and} \; D(\blambda_t^{\bpi}, \blambda_t) < \delta
\end{align*}
holds true.
Thus, we have $\frac{1}{T} \sum_{t=1}^T \Delta R (\blambda_t^{\pi}, \blambda_t) \leq \mathcal{O}(\delta / T)$. Therefore, 
\begin{align*}
    \text{Regret}(\bpi)
    &= \frac{1}{T} \sum_{t=1}^T \left( R(\bpi^{\ast}; \blambda_t^{\ast}) - R(\bpi_t; \blambda_t) \right) \\
    &= \frac{1}{T} \sum_{t=1}^T \left( \Delta R (\blambda_t^{\ast},  \blambda_t) + \Delta R (\bpi_t^{1}, \bpi_t) + \text{const.} \right) \\
    &= \frac{1}{T} \sum_{t=1}^T \left( \Delta R (\blambda_t^{\ast},  \blambda_t^{\pi}) + \Delta R (\blambda_t^{\pi},  \blambda_t) + \Delta R (\bpi_t^{1}, \bpi_t) \right) + \text{const.} \\
    &= \underbrace{\frac{1}{T} \sum_{t=1}^T \Delta R (\blambda_t^{\ast},  \blambda_t^{\bpi})}_{(1)} + \underbrace{\frac{1}{T} \sum_{t=1}^T \Delta R (\bpi_t^{1}, \bpi_t)}_{(2)} + \mathcal{O} \left( \frac{\delta}{T} \right) + \text{const.}
\end{align*}

\vspace{3mm}

\end{proof}

\subsection{Proof of Theorem~\ref{thrm:optimal_greedy}} \label{app:optimal_greedy}
\begin{proof}

When $f,\bar{\lambda}$ are linear functions, from Theorem \ref{thm:ne_exist} we know that the NE of $\G(\bpi, B, f, \bar{\lambda})$ exists and is unique. For any fixed $\bpi$, let $\blambda_{\infty}=(\blambda_u^*,\blambda_c^*)$ denote the NE obtained under $\bpi$. By Proposition \ref{prop:dynamics_equivalence}, $(\blambda_u^*,\blambda_c^*)$ is also the unique stable fixed point of system \eqref{eq:user_dynamics},\eqref{eq:content_dynamics} and therefore satisfies
\begin{equation}\label{eq:ne_first_order}
    \lambda_{k}^{(u)*} = \bar{\lambda}_k\left(\sum_{l=1}^L \pi_{l,k}\left(b_{l,k}+f(\lambda_l^{(c)*})\right)\right),  \quad \text{and}\quad\lambda_l^{(c)*}=\bar{\lambda}_l\left(\sum_{k=1}^K \pi_{l,k}\lambda_k^{(u)*}\right), \quad\forall 1\leq l\leq L, 1\leq k\leq K.
\end{equation}

Next, we derive the closed-form of $(\blambda_u^*,\blambda_c^*)$. Suppose 
$$f(x)=a_0 x+b_0, \quad\bar{\lambda}_k(x)=a_1 x+b_1, \quad\bar{\lambda}_l(x)=a_2 x+b_2, \quad a_0,a_1,a_2>0.$$ From Eq. \eqref{eq:ne_first_order} we know $(\blambda_u^*,\blambda_c^*)$ is the unique solution to the following linear system
\begin{equation}\label{eq:linear_eq_lambda_mu}
    \begin{bmatrix}
        I_K & -a_0a_1\bpi^{\top} \\
        -a_2\bpi & I_L
    \end{bmatrix}
    \begin{bmatrix}
        \blambda_u^*  \\
        \blambda_c^*
\end{bmatrix}=\left[a_1\sum_{l=1}^L\pi_{l,1}(b_{l,1}+b_0)+b_1,\cdots,a_1\sum_{l=1}^L\pi_{l,K}(b_{l,K}+b_0)+b_1,b_2,\cdots,b_2\right]^{\top},
\end{equation}
where $I_K,I_L$ denote the identity matrices of sizes $K,L$. Since $\sum_{l=1}^L \pi_{l,k}=1$, we have 
$$a_1\sum_{l=1}^L\pi_{l,k}(b_{l,k}+b_0)+b_1=a_1\sum_{l=1}^L\pi_{l,k}\left(b_{l,k}+b_0+\frac{b_1}{a_1}\right), \forall 1\leq k\leq K.$$
Without loss of generality, we let $b_0,b_1=0$ hereafter, since we can always absorb the term $b_0+\frac{b_1}{a_1}$ into $B$ by letting $\tilde{b}_{l,k}=b_{l,k}+b_0+\frac{b_1}{a_1}$. As a result, from Eq. \eqref{eq:linear_eq_lambda_mu} we can obtain the closed-form solution for $(\blambda_u^*,\blambda_c^*)$ as follows:

\begin{align}\notag
   \begin{bmatrix}
        \blambda_u^*  \\
        \blambda_c^*
\end{bmatrix}&=\begin{bmatrix}
        (I_K-a_0a_1a_2\bpi^{\top}\bpi)^{-1} & (I_K-a_0a_1a_2\bpi^{\top}\bpi)^{-1}a_0a_1\bpi^{\top}\\
        a_2\bpi(I_K-a_0a_1a_2\bpi^{\top}\bpi)^{-1} & I_L+a_0a_1a_2\bpi(I_K-a_0a_1a_2\bpi^{\top}\bpi)^{-1}\bpi^{\top}
\end{bmatrix} \\ \label{eq:solution_lambda_mu}
&\cdot\left[a_1\sum_{l=1}^L\pi_{l,1}b_{l,1},\cdots,a_1\sum_{l=1}^L\pi_{l,u}b_{l,u},b_2,\cdots,b_2\right]^{\top},
\end{align}
where $I_K-a_0a_1a_2\bpi^{\top}\bpi$ is a positive definite matrix. 

On the other hand, the user-side social welfare can be rewritten into 
\begin{align}\notag
     R(\bpi; (\blambda_u^*,\blambda_c^*))=&\sum_{k=1}^{K} \lambda_{k}^{(u)*} \sum_{l=1}^{L} \pi_{l,k} (b_{l,k} + f(\lambda_l^{(c)*})) \\ \notag
    = & \blambda_u^{*\top}\cdot\left[\sum_{l=1}^L\pi_{l,1}b_{l,1},\cdots,\sum_{l=1}^L\pi_{l,K}b_{l,K}\right]^{\top}+a_0\blambda_u^{*\top}\bpi^{\top}\blambda_c^* \\ \notag
    = &  \frac{1}{a_1}\blambda_u^{*\top}(\blambda_u^*-a_0a_1\bpi^{\top}\blambda_c^*) + a_0\blambda_u^{*\top}\bpi^{\top}\blambda_c^* & \mbox{by Eq. \eqref{eq:linear_eq_lambda_mu} } \\ \label{eq:obj_lambda}
    =&\frac{\blambda_u^{*\top}\blambda_u^*}{a_1}.
\end{align}

From Eq. \eqref{eq:solution_lambda_mu} we also have 
\begin{align}\notag
    \blambda_u^{*}&=(I_K-a_0a_1a_2\bpi^{\top}\bpi)^{-1} 
\cdot a_1 \cdot \left[\sum_{l=1}^L \pi_{l,1}b_{l,1}, \cdots, \sum_{l=1}^L \pi_{l,K}b_{l,K}\right]^{\top}  \\ \notag
    &\quad + (I_K-a_0a_1a_2\bpi^{\top}\bpi)^{-1} a_0 a_1 \bpi^{\top} \cdot b_2 \bm{1}_L \\\label{eq:lambda_eq}
    &= a_1(I_K - a_0 a_1 a_2 \bpi^{\top} \bpi)^{-1} \left[\text{diag}(\bpi^{\top}B) + a_0 b_2 \bm{1}_K\right], & \text{by } \bpi^{\top} \bm{1}_L = \bm{1}_K.
\end{align}
Plug Eq. \eqref{eq:lambda_eq} into Eq. \eqref{eq:obj_lambda}, we obtain the following explicit expression of $R$ for any $\bpi$ and $B$:

\begin{equation}\label{eq:user_welfare_linear_closed}
   R(\bpi;\blambda_{\infty})=R(\bpi; (\blambda_u^*,\blambda_c^*))= a_1\left\|(I_K - a_0 a_1 a_2 \bpi^{\top} \bpi)^{-1} \left[\text{diag}(\bpi^{\top}B) + a_0 b_2 \bm{1}_K\right]\right\|_2^2,
\end{equation}
where $\bm{1}_K=(1,\cdots,1)^{\top}$ is a column vector of length $K$. Let $\sigma_{\max}(\cdot)$ and $\sigma_{\min}(\cdot)$ denotes the largest and the smallest eigenvalue of a matrix. Then Eq. \eqref{eq:user_welfare_linear_closed} implies

\begin{equation}
   R_{-}(\bpi; \blambda_{\infty})\triangleq\frac{a_1\left\|\text{diag}(\bpi^{\top}B) + a_0 b_2 \bm{1}_K\right\|_2^2}{\sigma^2_{\max}(I_K - a_0 a_1 a_2 \bpi^{\top} \bpi)}\leq R(\bpi; \blambda_{\infty})\leq \frac{a_1\left\|\text{diag}(\bpi^{\top}B) + a_0 b_2 \bm{1}_K\right\|_2^2}{\sigma^2_{\min}(I_K - a_0 a_1 a_2 \bpi^{\top} \bpi)}\triangleq R_{+}(\bpi; \blambda_{\infty}).
\end{equation}

Next, we consider any $\epsilon$-greedy policy $\bpi^{(\epsilon)}$ w.r.t. $B$ and show that both $R_{-}(\bpi^{(\epsilon)}; \blambda_{\infty}^{(\epsilon)})$ and $R_{+}(\bpi^{(\epsilon)}; \blambda_{\infty}^{(\epsilon)})$ as functions of $\epsilon$ are monotonically decreasing in $\epsilon\in[0,1]$. Without loss of generality, we may assume the greedy recommendation policy $\bpi_0$ has the following form:
\[\bpi_0=
\II\{b_{l,k}=\arg\max_{1\leq i\leq L}b_{i,k}\}]_{L\times K} =
\begin{bmatrix}\label{eq:pi_0}
\bm{1}_{K_1} & \bm{0} & \cdots & \bm{0} & \bm{0}\\
\bm{0} & \bm{1}_{K_2} & \cdots & \bm{0} & \bm{0}\\
\vdots & \vdots & & \vdots & \vdots\\
\bm{0} & \bm{0} & \cdots & \bm{0} & \bm{1}_{K_m} \\
\bm{0} & \bm{0} & \cdots & \bm{0} & \bm{0}
\end{bmatrix},
\]
i.e., all user groups are clustered into $m$ sub-groups and each has size $K_m$. Each user within a sub-group prefers the same content group and users from different sub-groups prefer different content groups. The total number of user sub-groups $m$ satisfies $1\leq m \leq L$, $K=K_1+\cdots+K_m$, and $K_1\geq\cdots\geq K_m$.

Denote $\bm{b}_0=\text{diag}(\bpi_0^{\top}B)=[\max_{1\leq l\leq L}\{b_{l,k}\}]_{k=1}^k$, and $\bm{b}_1=[ \frac{1}{L}\sum_{l=1}^L b_{l,k}]_{k=1}^K$. By plugging $\bpi_{\epsilon}=(1-\epsilon)\bpi_0 +\frac{\epsilon}{L} \1_{L\times K}$ into Eq. \eqref{eq:user_welfare_linear_closed}, we obtain 
\begin{align*}
    \text{diag}(\bpi_{\epsilon}^{\top}B) + a_0 b_2 \bm{1}_K = (1-\epsilon)\bm{b}_0 + \epsilon \bm{b}_1+ a_0 b_2 \bm{1}_K.
\end{align*}
Since $\bm{b}_0\geq \bm{b}_1$ elementary-wise, we conclude that $\|\text{diag}(\bpi_{\epsilon}^{\top}B) + a_0 b_2 \bm{1}_K\|_2$ as a function of $\epsilon$ is decreasing in $[0,1]$.

On the other hand, direct calculation shows 
\begin{align*}
    I_K - a_0 a_1 a_2 \bpi_{\epsilon}^{\top} \bpi_{\epsilon} = &I_k - a_0a_1a_2 \left[(1-\epsilon)\bpi^{\top}_0 +\frac{\epsilon}{L} \1_{K\times L}\right] \cdot \left[(1-\epsilon)\bpi_0 +\frac{\epsilon}{L} \1_{L\times K}\right] \\ 
    =& I_K - a_0a_1a_2(1-\epsilon)^2\bpi^{\top}_0\bpi_0 - \frac{a_0a_1a_2\epsilon(2-\epsilon)}{L}\1_{K\times K}.
\end{align*}

Given the explicit form of the block matrix $\pi_0$, we can directly compute the smallest and the largest eigenvalues of matrix $I_K - a_0 a_1 a_2(1-\epsilon)^2 \bpi_0^{\top} \bpi_0$ as followings: 
\begin{align}\notag
    & \sigma_{\max}(I_K - a_0 a_1 a_2(1-\epsilon)^2 \bpi_0^{\top} \bpi_0)=1, \\ \notag
    & \sigma_{\min}(I_K - a_0 a_1 a_2(1-\epsilon)^2 \bpi_0^{\top} \bpi_0)= 1-a_0a_1a_2(1-\epsilon)^2K_1.
\end{align}

In addition, from Weyl's inequality \cite{fan1949theorem,bunch1978rank}, we conclude that 
\begin{align}\notag
     \sigma_{\max}(I_K - a_0 a_1 a_2 \bpi_{\epsilon}^{\top} \bpi_{\epsilon})&=1, \\ \notag
     \sigma_{\min}(I_K - a_0 a_1 a_2 \bpi_{\epsilon}^{\top} \bpi_{\epsilon}) &\geq \sigma_{\min}(I_K - a_0 a_1 a_2(1-\epsilon)^2 \bpi_0^{\top} \bpi_0) - \sigma_{\max}\left(\frac{a_0a_1a_2\epsilon(2-\epsilon)}{L}\1_{K\times K}\right) \\ \notag 
     & = 1-a_0a_1a_2(1-\epsilon)^2K_1 - \frac{a_0a_1a_2\epsilon(2-\epsilon)K}{L} \\
     \label{eq:sigma_min_lower}
     &= 1-a_0a_1a_2K_1+ a_0a_1a_2\epsilon(2-\epsilon)\left(K_1-\frac{K}{L}\right).
\end{align}
Note that by the definition of $K_1$, it holds that $K_1\geq \frac{K}{m} \geq \frac{K}{L}$. Hence, the lower bound of $\sigma_{\min}$ in Eq. \eqref{eq:sigma_min_lower} is an increasing function in $\epsilon\in[0,1]$.

Hence, we have 
\begin{align}\label{eq:W_lower}
   & R_{-}(\bpi^{(\epsilon)}; \blambda_{\infty}^{(\epsilon)})=a_1\|(1-\epsilon)\bm{b}_0 + \epsilon \bm{b}_1+ a_0 b_2 \bm{1}_K\|_2^2, \\\label{eq:W_upper}
   & R_{+}(\bpi^{(\epsilon)}; \blambda_{\infty}^{(\epsilon)})\leq \frac{a_1\|(1-\epsilon)\bm{b}_0 + \epsilon \bm{b}_1+ a_0 b_2 \bm{1}_K\|_2^2}{\left(1-a_0a_1a_2K_1- a_0a_1a_2\epsilon(2-\epsilon)\left(K_1-\frac{K}{L}\right)\right)^2},
\end{align}
and the RHS of both Eqs. \eqref{eq:W_lower} and \eqref{eq:W_upper} are decreasing functions of $\epsilon$ in $[0,1]$.

Take $g(\epsilon)=a_1\|(1-\epsilon)\bm{b}_0 + \epsilon \bm{b}_1+ a_0 b_2 \bm{1}_K\|_2^2$, and $h(\epsilon)=\left(1-a_0a_1a_2K_1- a_0a_1a_2\epsilon(2-\epsilon)\left(K_1-\frac{K}{L}\right)\right)^{-2}$, we conclude that  
$$g(\epsilon)\leq R(\bpi^{(\epsilon)}; \blambda_{\infty}^{(\epsilon)})\leq g(\epsilon)h(\epsilon),$$
and $h(\epsilon)=\left(1-a_0a_1a_2K_1- a_0a_1a_2\epsilon(2-\epsilon)\left(K_1-\frac{K}{L}\right)\right)^{-2}<(1-2a_0a_1a_2K)^{-2}$. Since by definition $(\nabla_{\lambda_l} f_{k,l})(\nabla_{e_l} \bar{\lambda}_l) (\nabla_{s_k} \bar{\lambda}_k)=a_0a_1a_2$, our claim holds.
\end{proof}

\subsection{Proof of Proposition~\ref{prop:heterogeneous_f}} \label{proof:heterogeneous_f}
\begin{proof}
Consider a two-sided system with $K=1, L=2, B=[1, 0.9]^{\top}$ and $$\bar{\lambda}^{{u}}_1(x)=a_0x,\bar{\lambda}^{{c}}_1(x)=a_1x,\bar{\lambda}^{{c}}_2(x)=a_2x, f_1(x)=b_1x,f_2(x)=b_2x.$$ According to Theorem \ref{thm:ne_exist}, the NE of the system exists and is unique when $a_0, a_1, a_2>0$ are sufficiently small. Moreover, $(\lambda^{(u)}_1,\lambda^{(c)}_1,\lambda^{(c)}_2)$ at the NE satisfies

\begin{align*}
    & \lambda^{(u)}_1=\bar{\lambda}^{{(u)}}_1(\pi_{11}f_1(\lambda^{(c)}_1)+\pi_{21}f_2(\lambda^{(c)}_2)+\pi_{11}+0.9\pi_{21}), \\ 
    & \lambda^{(c)}_1=\bar{\lambda}^{(c)}_1(\pi_{11}\lambda^{(u)}_1), \\
    & \lambda^{(c)}_2=\bar{\lambda}^{(c)}_2(\pi_{21}\lambda^{(u)}_1),
\end{align*}
which is equivalent to
\begin{equation}\label{eq:151}
\begin{cases} 
& \lambda^{(u)}_1=a_0(b_1\pi_{11}\lambda^{(c)}_1+b_2\pi_{21}\lambda^{(c)}_2+\pi_{11}+0.9\pi_{21}), \\
& \lambda^{(c)}_1=a_1 \pi_{11}\lambda^{(u)}_1, \\ 
& \lambda^{(c)}_2=a_2 \pi_{21}\lambda^{(u)}_1.\\ 
\end{cases}
\end{equation}

Plugin the last two equations into the first one in Eq. \eqref{eq:151}, we obtain that 

$$\lambda^{(u)}_1=a_0(a_1b_1\pi^2_{11}\lambda^{(u)}_1+a_2b_2\pi^2_{21}\lambda^{(u)}_1+\pi_{11}+0.9\pi_{21}),$$

and therefore 
\begin{align*}
\lambda^{(u)}_1&=\frac{a_0(\pi_{11}+0.9\pi_{21})}{1-a_0a_1b_1\pi^2_{11}-a_0a_2b_2\pi^2_{21}}   \\ 
&=\frac{a_0(0.9+0.1\pi_{11})}{1-a_0a_1b_1\pi^2_{11}-a_0a_2b_2(1-\pi_{11})^2}.
\end{align*}

Now we can write $R(\bpi;\blambda^*)$ as a function of $\pi_{11}$ as the following:
\begin{align*}
R(\bpi;\blambda^*)&=\lambda^{(u)}_1(\pi_{11}f_1(\lambda^{(c)}_1)+\pi_{21}f_2(\lambda^{(c)}_2)+\pi_{11}+0.9\pi_{21})=\frac{1}{a_0}(\lambda_1^{(u)})^2 \\ 
&= \frac{a_0(0.9+0.1\pi_{11})^2}{[1-a_0a_1b_1\pi^2_{11}-a_0a_2b_2(1-\pi_{11})^2]^2}.
\end{align*}

Take $b_1=0, a_0a_2b_2=0.4$, we have 
\begin{equation}\label{eq:176}
    \sqrt{\frac{R(\bpi,\blambda^*)}{a_0}}=\frac{0.9+0.1\pi_{11}}{1-0.4(1-\pi_{11})^2}\triangleq\tilde{R}(\pi_{11}),
\end{equation}
and it is easy to verify that the RHS of Eq. \eqref{eq:176} is not achieved at $\pi_{11}=1$. In fact, for any $\pi'_{11}<0.7$, it holds that $\tilde{R}(\pi'_{11})>\tilde{R}(1)=1$. This means the greedy policy $[\pi_{11}, \pi_{21}]=[1, 0]$ is not optimal in this example.

\end{proof}

\section{Additional experiment settings and observations} \label{app:experiment_details}

Here, we report additional details of the experiment settings and results.

\textbf{Difference of population effects in the synthetic and real-world experiments.} \; Figure~\ref{fig:synthetic_population_effect} shows the population effect used in the synthetic experiment, defined by Eq.~\eqref{eq:synthetic_population_effect}. The biggest difference between the synthetic and real-world experiment setting is that we observe saturation of the population effects as an early stage of the provider population growth, i.e., around $\lambda_l = 100$, which is also a reasonable phenomenon in real-world situations. Therefore, in the synthetic experiment, it is important to distribute the content exposure among multiple subgroups to receive high population effects in many different provider groups. Thus, even the uniform policy outperforms the myopic-policy in this setting. In contrast, when using KuaiRec dataset~\citep{gao2022kuairec}, the situation is milder than the synthetic experiment, and therefore the myopic policy works well in the real-world experiment. Together, our synthetic and real-world experiments show that the proposed look-ahead policy performs reasonably well in two different configurations. This is because seeking for both (immediate) viewer utility ($s_k$) and provider exposure ($e_l$) is important to maximize the look-ahead objective, which depends on reference populations $\bar{\lambda}(s_k)$ and $\bar{\lambda}(e_l)$.

\textbf{Estimation results of the dynamics and population effect functions.} \;
We also report how the dynamics estimation works in the real-world experiment in Figures~\ref{fig:estimation_population_effect} and \ref{fig:estimation_population_dynamics}. While we initialize the population effect and dynamics estimation with a homogeneous function across viewer-provider pairs, the results demonstrate that our estimation scheme provides an accurate estimation of heterogeneous functions by using the dynamics logs in the rollout process. We also observe that the policy optimization results in the main text (w/ population effect and dynamics estimation) are quite similar to those without dynamics estimation (i.e., using the true dynamics) in the experiment.

\begin{figure*}[t]
\centering
\includegraphics[clip, width=0.95\linewidth]{figs/synthetic/concave_increase_population_effect.png}
    \caption{\textbf{Visualization of the population effects in the synthetic experiment.} We randomly sample the scaler and temperature parameter of the sigmoid function from a normal distribution for each content-quality feature pair as described in Section~\ref{sec:synthetic_experiment}. The resulting quality vector is provider-dependent, and the population effects are heterogeneous across viewer-provider pairs.
  } 
  \label{fig:synthetic_population_effect}
\end{figure*}

\begin{figure*}
\begin{minipage}{0.99\hsize}
  \centering
  \includegraphics[clip, width=0.98\linewidth]{figs/real/kuairec_main_population_effect.png} 
  \vspace{1mm}
\end{minipage}
\begin{minipage}{0.99\hsize}
  \centering
  \includegraphics[clip, width=0.98\linewidth]{figs/real/kuairec_main_estimated_population_effect.png} 
  \caption{\textbf{Comparing the true and estimated population effect in the real-world experiment.} (Top) True population effect used in the real-world experiment (the same figure as Figure~\ref{fig:real_population_effect} in the main text). (Bottom) Population effect learned by the long-term optimal policy at the final timestep.} \label{fig:estimation_population_effect}
  \vspace{3mm}
\end{minipage}
\end{figure*}

\begin{figure*}
\begin{minipage}{0.99\hsize}
  \centering
  \includegraphics[clip, width=0.98\linewidth]{figs/real/kuairec_main_dynamics.png} 
  \vspace{1mm}
\end{minipage}
\begin{minipage}{0.99\hsize}
  \centering
  \includegraphics[clip, width=0.98\linewidth]{figs/real/kuairec_main_estimated_dynamics.png} 
  \caption{\textbf{Comparing the true and estimated population dynamics in the real-world experiment.} (Top) True population dynamics simulated in the real-world experiment. (Bottom) Population dynamics learned by the long-term optimal policy at the final timestep.} \label{fig:estimation_population_dynamics}
  \vspace{3mm}
\end{minipage}
\end{figure*}