\section{Empirical Evaluation}
\input{Chapters/tabs/tab_en_inter}

\subsection{Experimental Setup}
We empirically evaluate various defense methods and their ensemble strategies on LLaVA-1.5-7B and LLaVA-1.5-13B~\cite{liu2024visual} to validate their effectiveness in standard settings. Using MM-SafetyBench and MOSSBench datasets, we assess safety and helpfulness by measuring defense success rate (DSR) on harmful queries and response rate (RR) on benign queries. We evaluate 28 defense methods, including system reminders, optimization techniques, query refactoring, and noise injection, as well as inter- and intra-mechanism ensembles. Detailed descriptions of defense methods and experimental setups are provided in Appendix~\ref{sec:defense strategies} and~\ref{sec:experiment_detail}. 
For a broader evaluation, we add more experiments in Appendix~\ref{sec:utility}, ~\ref{sec:diverse_attacks} and~\ref{sec:time}, including evaluation with the MM-Vet dataset for testing the quality of model's response on general queries, tests on JailbreakV-28K for more diverse and complex attack scenarios, and a comparison of inference time for different defense methods.

\subsection{Individual Defense Results}

Table~\ref{tab:indi_results} shows results of individual defense methods across four categories. Most methods, except for noise injection, effectively improve model safety across different models and datasets, as evidenced by increased defense success rates. This aligns with our analysis in Figure~\ref{fig:analysis results} where system reminder, model optimization and query refactoring lead to an overall increase in refusal probabilities. 

\paragraph{Safety shift defenses compromise helpfulness.} System reminder and model optimization methods generally reduce response rates on the benign subset while increasing defense success rates on the harmful subset. This confirms that safety shift tend to compromise helpfulness. This is more pronounced in MOSSBench than MM-SafetyBench due to the more apparent harmfulness and concealed harmlessness in MOSSBench queries.

\paragraph{Harmfulness discrimination defenses mitigate over-defense.} Query refactoring methods, except for Caption (w/o image), generally achieve the highest response rates on the benign subset, particularly for MOSSBench with misleadingly benign queries. This validates that harmfulness discrimination improves the model's ability to distinguish between truly harmful and benign queries. Notably, the removal of images in the Caption (w/o image) significantly reduces response rates for both harmful and benign queries, highlighting the crucial role images play in jailbreaking LVLMs.
% \paragraph{Image matters.} The removal of images in the Caption (w/o image) and Intention (w/o image) defenses leads to significant improvements in DSR compared to their image-included counterparts, underscoring the crucial role that images play in jailbreaking LVLMs.

\paragraph{Multimodal defense is challenging.}
However, all individual defense methods still exhibit limited defense success rates. While larger-scale LVLMs (i.e., LLaVA-1.5-13B) tend to achieve slightly higher success rates, they are also more susceptible to over-defense. This underscores the inherent challenges of jailbreak defense for LVLMs, especially when relying on individual defense methods. 

\subsection{Ensemble Defense Results}
Table~\ref{tab:en_inter_results} provides the empirical evaluation of both inter-mechanism and intra-mechanism ensemble strategies, leading to the following insights:

\paragraph{Ensembles improve safety.} Compared to individual methods, most ensemble strategies effectively enhance safety across both datasets and model sizes, showing increased defense success rates, especially in \textit{SR+MO} and \textit{QR\textbar{}SR} methods.

\paragraph{Inter-mechanism ensembles amplify.} Our evaluation shows most \textit{SR++} and \textit{SR+MO} ensembles improve defense success rates while reducing responses rates, whereas the \textit{QR++} ensemble better maintain responses rates. This confirms that inter-mechanism ensembles can amplify a single defense mechanism. Specifically, safety shift ensembles would further enhance model safety at the expense of helpfulness, while harmfulness discrimination ensemble better preserves helpfulness. Among inter-mechanism ensembles, those combining different types of specific methods (e.g., SR+MO) show a more pronounced amplification effect than those combining the same type (e.g., SR++). 
Notably, the Demonstration-SFT method excels in defense strength, utility, and response rate. Its success comes from combining two strong safety shift defenses, Demonstration and SFT, which complement each other and boost overall performance.

\paragraph{Intra-mechanism ensembles complement.} Compared to inter-mechanism ensembles, most \textit{QR\textbar{}SR} and \textit{QR\textbar{}MO} methods—except those without input images—can simultaneously maintain decent defense success rates and stable response rates,
compared to the undefended model and individual defense methods. This demonstrates that intra-mechanism ensemble can complement each other to achieve a more balanced trade-off. Additionally, the removal of input images offering a most conservative ensemble for multimodal defense while still maintaining certain helpfulness.
% In contrast, the defenses in intra-mechanism ensemble complement each other, strengthening safety while maintaining a stable level of helpfulness.
% In contrast, intra-mechanism ensembles combine the strengths of both mechanisms to achieve a more balanced trade-off. Specifically, \textit{QR\textbar{}SR} and \textit{QR\textbar{}MO} increase the refusal probability for harmful queries, while maintaining or even decreasing the refusal probability for benign queries, thereby improving the model's ability to distinguish between benign and harmful queries. This makes them a better choice for general scenarios where balancing safety and helpfulness is essential. 


\subsection{How Do Fine-tuning Affect Model Safety?}
We examine how different fine-tuning methods impact the safety of LVLMs by training LLaVA-1.5-7B using DPO and SFT with two datasets: SPA-VL~\cite{zhang2024spa} and VLGuard~\cite{zong2024safety}. SPA-VL focuses on safety discussions, while VLGuard emphasizes query rejection. We also test the effect of adding 5000 general instruction-following data from LLaVA.  

Table~\ref{tab:training_dataset_results} shows that DPO with SPA-VL and LLaVA provides a slight safety boost without significantly changing response behavior. In contrast, SFT has a stronger impact, but its effectiveness depends on the dataset. SPA-VL improves safety while maintaining helpfulness, though it may miss some harmful cases. VLGuard, however, makes the model overly defensive, rejecting too many queries. Adding LLaVA data helps balance safety and helpfulness, reducing excessive refusals.  


\begin{table}[ht]
    \centering
    \resizebox{0.49\textwidth}{!}{
    \begin{tabular}{r|cccccc}
        \toprule 
        & \multicolumn{3}{c}{\textbf{MM-SafetyBench}} & \multicolumn{3}{c}{\textbf{MOSSBench}} \\
        \textbf{Method} & \textbf{DSR}$\uparrow$ & \textbf{RR}$\uparrow$ & \textbf{Avg}$\uparrow$ & \textbf{DSR}$\uparrow$ & \textbf{RR}$\uparrow$ & \textbf{Avg}$\uparrow$ \\
        \midrule
        w/o Defense          & 0.06  & 0.98  & 0.52  & 0.14  & 0.97  & 0.55 \\
        \midrule
        \multicolumn{7}{c}{DPO} \\
        \midrule
        \multicolumn{1}{l|}{SPA-VL + LLaVA}          & 0.06  & 0.97  & 0.52  & 0.28  & 0.97  & 0.63  \\
        \midrule
        \multicolumn{7}{c}{SFT} \\
        \midrule
        \multicolumn{1}{l|}{SPA-VL}          & 0.24  & 0.96  & 0.60  & 0.58  & 0.78  & 0.68  \\
        + LLaVA     & 0.20  & 0.95  & 0.58  & 0.50  & 0.88  & 0.69  \\
        \midrule
        \multicolumn{1}{l|}{VLGuard}          & 1.00  & 0.09  & 0.55  & 0.90  & 0.21  & 0.55  \\
        + LLaVA     & 0.97  & 0.43  & 0.70  & 0.76  & 0.58  & 0.67  \\
        \bottomrule
    \end{tabular}}
    \caption{Comparison of varying fine-tuning settings.} % and the full score is 100\%
    \label{tab:training_dataset_results}
\end{table}
