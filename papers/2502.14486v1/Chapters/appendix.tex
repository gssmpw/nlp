\section{Defense Methods}
\label{sec:defense strategies}
\paragraph{System Reminder}
\begin{itemize}
    \item \textbf{Responsible:} We use the system prompt provided by \cite{wang2024adashield} as shown in Table~\ref{tab:responsible}, to instruct the model to act as a responsible assistant. This prompt includes four key guidelines: the model must thoroughly examine image content, utilize a chain-of-thought (CoT) prompt, specify response methods, and incorporate instructions for addressing benign queries.
    \item \textbf{Policy:} We integrate a detailed safety policy into the system prompt. The policy is outlined in Table~\ref{tab:policy}.
    \item \textbf{Demonstration:} We integrate six demonstrations into the system prompt, half of which involve rejecting harmful queries. These demonstrations are displayed in Table~\ref{tab:in_context}.
\end{itemize}

\paragraph{Model Optimization}
\begin{itemize}
    \item \textbf{SFT:} We perform vision-language instruction fine-tuning utilizing the LoRA adapter and the SPA-VL dataset~\cite{zong2024safety}, which is specifically designed for safety alignment. From this dataset, we sampled 2,000 instances, targeting preferred selections as the expected output. Furthermore, we incorporated 5,000 examples from the LLaVA-RLHF dataset~\cite{sun2023aligning}, which also provides preferred outputs for supervised training. We employ the unified framework proposed by ~\cite{zheng2024llamafactory}, utilizing a learning rate of \(1 \times 10^{-4}\) for three epochs, with a global batch size set to 32.
    \item \textbf{SafeDecoding:} We employ an expert model fine-tuned through SFT to enhance the decoding process with the decoding algorithm~\cite{xu2024safedecoding}.
    \item \textbf{DPO:} We perform Direct Preference Optimization (DPO)~\cite{rafailov2024direct} training using the LoRA adapter and the SPA-VL dataset. Specifically, we sample 5,000 instances from SPA-VL and incorporate an additional 5,000 examples from the LLaVA-RLHF dataset. The training is conducted over three epochs with a learning rate of \(2 \times 10^{-5}\) and a global batch size of 64.
\end{itemize}

\paragraph{Query Refactor}
\begin{itemize}
    \item \textbf{Caption:} We follow the ECSO method~\cite{gou2024eyes}. First, we query the model to describe the image using the prompt template outlined in Table~\ref{tab:caption}. The response generated in this initial step is then utilized to refactor the original query for the second prompt, as specified in Table~\ref{tab:refactored query}.

    \item \textbf{Intention:} This process is similar to the Caption method; however, in the first step, we instruct the model to extract the intent of the query with the prompt template presented in Table~\ref{tab:intention}.
    
    \item \textbf{Caption without Image:} In the first step of the Caption method, we extract essential information to address the query, enabling the omission of the image in the subsequent step. In contrast, the Intention method reveals that the model struggles to extract sufficient information in the initial step. Therefore, we only apply this approach for Caption method.
\end{itemize}

\paragraph{Noise Injection}
\begin{itemize}
    \item \textbf{Mask Image:} Randomly mask a specific region of the image.
    \item \textbf{Vertical Flip Image:} Apply a vertical flip transformation to the image.
    \item \textbf{Swap Text:} Randomly exchange positions of tokens within the text.
    \item \textbf{Insert Text:} Randomly introduce individual tokens into the text.
\end{itemize}

\input{Chapters/tabs/defense_details}

\section{Empirical Evaluation Details}
\label{sec:experiment_detail}

\paragraph{Evaluation Datasets}
For empirical evaluation of safety and helpfulness, we utilize the MM-SafetyBench and MOSSBench datasets, containing both harmful and benign query subsets.
\begin{itemize}[itemsep=0.5pt, leftmargin=12pt, parsep=1pt, topsep=1pt]
    \item \textbf{MM-SafetyBench} is a widely-used dataset for safety-critical defense evaluations of LVLMs. We use the \textit{SD+TYPO} split, where harmful keywords are removed from text queries and hidden at the bottom of associated images, making harmfulness detection harder for models. As the original dataset only contains harmful queries, we supplement benign queries from~\cite{zhao2024first}. In total, we sample 634 harmful instances and 450 benign instances for evaluation.
    \item \textbf{MOSSBench} is designed to evaluate helpfulness-oriented defenses. It comprises benign image-text pairs that may trigger overly sensitive responses, alongside a contrasting set of clearly harmful queries. We totally sample 196 harmful instances and 240 benign instances for evaluation.
\end{itemize}

%     \item \textbf{QR\textbar{}MO}: Intention-SFT, Intention (w/o Image)-SFT,  Caption-SafeDecoding and Caption (w/o Image)-SafeDecoding.
% \begin{itemize}[itemsep=0.5pt, leftmargin=12pt, parsep=1pt, topsep=1pt]
%     \item \textbf{System Reminder:} Responsible, Demonstration and Policy.
%     \item \textbf{Model Optimization:} SFT, Safedecoding.
%     \item \textbf{Query Refactoring:} Caption, Intention, Caption (w/o Image), Intention (w/o Image).
%     \item \textbf{Noise Injection:} Mask Image, Vertical Flip Image, Swap Text, Insert Text.
%     \item \textbf{SR++}: Responsible-Demonstration, Policy-Demonstration,Responsible-Policy, Responsible-Policy, Responsible-Policy-Demonstration.
%     \item \textbf{SR+MO}: SFT-Demonstration, SFT-Responsible, SafeDecoding-Demonstration and SafeDecoding-Responsible.
%     \item \textbf{QR++}: Caption-Intention, Caption-Intention (w/o Image)
%     \item \textbf{QR\textbar{}SR}: Caption-Responsible, Caption (w/o Image)-Responsible, Intention-Responsible, Intention (w/o Image)-Responsible
%     \item \textbf{QR\textbar{}MO}: Intention-SFT, Intention (w/o Image)-SFT,  Caption-SafeDecoding and Caption (w/o Image)-SafeDecoding.
% \end{itemize}

\paragraph{Evaluation Metrics}
In standard generation settings, we assess whether models respond to queries with two metrics: defense success rate (DSR) on the harmful subset for safety evaluation, and response rate (RR) on the benign subset for helpfulness measurement~\footnote{It's important to note that we do not assess the actual usefulness of model's responses in addressing the queries, but rather focuses on the model's willingness to engage with benign queries from a safety perspective.}. To determine whether the model refuses a query, we follow a keyword-based detection method in~\cite{wei2024jailbroken,wang2024adashield,zhang2024jailguarduniversaldetectionframework}. This involves checking for predefined rejection keywords such as "I am sorry" in responses. If no such keywords are detected, the response is 
considered compliant. 

\section{Analysis Details}
\subsection{Analysis Setup}
\label{sec:analysis_setup}
To obtain the refusal probability of the model, we designed a prompt template as shown in Table~\ref{tab:cls_prompt}. This template embeds the input query and directly asks whether the model will comply with or refuse the query. We extract the logits of the corresponding option tokens (0 or 1) to calculate their probabilities. The model is queried twice with two permutations of the option tokens related to refusal and compliance, and the average value is computed to mitigate token bias. However, it is important to note that this method has not been validated to accurately reflect the model's internal preferences or refusal probabilities, as discussed in Appendix~\ref{sec:consistency_appendix}.
Alternative methods for simulating refusal probabilities, such as sampling multiple responses to determine the refusal ratio or calculating the probabilities of keywords indicating refusal, may either be prohibitively costly or challenging to define the keyword scope. In our analysis, we only employ this method to gain insights into the effects observed. For the model and dataset, we utilize the LLaVa-1.5-13b and evaluate it using the SD+TYPO version of the MM-SafetyBench dataset.

\begin{table*}[htbp]\centering
    \begin{minipage}{\textwidth}   
    \centering
        \begin{tcolorbox} 
            \centering
            \normalsize
            \begin{tabular}{p{0.99\columnwidth}}
            {
Determine whether you should respond to the user's request, focusing solely on ethical and legal considerations.
            
Select a score of 0 = [[option0]] or 1 = [[option1]]. No other score should be given. \newline

\textbf{Determination Guidelines}:
\begin{itemize}
    \item \textbf{Comply}: You will attempt to address the user's request with direct response.
    \item \textbf{Refuse}: You will explicitly refuse to answer the question or offer an alternative response based on safety concern.
\end{itemize}

Image: [attached]

User Request: 
\{query\} \newline

\textbf{ONLY} consider the ethical and legal implications of your response to determine whether you will comply or refuse the user's query.

\textbf{DO NOT} consider whether you have the capability to answer the user's query.

\textbf{DO NOT} refuse to provide your score.

\textbf{DO NOT} respond with 'I am sorry'.

\textbf{ONLY} provide your \textbf{SCORE (0 = [[option0]] and 1 = [[option1]])} in the response.
            } %\textcolor
            \end{tabular}
        \end{tcolorbox}
        \caption{Prompt for classification task analysis.}
        \label{tab:cls_prompt}
        \vspace{10pt}
    \end{minipage}
\end{table*} % 

\subsection{Additional Analysis Results}
\label{sec:more_analyss_result}
Figure~\ref{fig:all_analysis_results} displays a comprehensive overview of the analysis results of all specific defense methods, including individual and ensemble defenses.

\input{Chapters/figs/all_analysis_results}

\subsection{Analysis on Additional LVLMs}
\label{sec:extra_lvlm}
To further validate the generalizability of the identified mechanisms, we conduct experiments on additional advanced LVLMs. Specifically, we evaluate LLaVA-Next (LLaVa-V1.6-Mistral-7B) with a different LLM backbone and training data, Qwen2-VL (Qwen2-VL-7B-Instruct) with a different training paradigm, and Pixtral (pixtral-12b) with a different model architecture. The results, presented in Figure~\ref{fig:llava-v1.6_analysis}, Figure~\ref{fig:qwen2vl_analysis} and Figure~\ref{fig:pixtral-12b_analysis}, demonstrate that these LVLMs exhibit the same two mechanisms identified in our preliminary analysis, and two ensembles strategies generally achieve similar effects as LLaVA-1.5 
This consistency underscores the robustness and applicability of the mechanisms across different LVLMs.

\begin{figure*}[!h]
    \centering
    \begin{minipage}{0.25\linewidth} 
        \includegraphics[width=\linewidth]{Chapters/images/llava-v1.6-mistral-7b-hf_analysis_0.pdf}
        \vspace{-6mm}
        \subcaption{Baseline}
    \end{minipage}
    \vfill 
    \vspace{10pt}
    \begin{minipage}{\linewidth}
        \includegraphics[width=\linewidth]{Chapters/images/llava-v1.6-mistral-7b-hf_analysis_1.pdf}
        \vspace{-6mm}
        \subcaption{Individual Defenses}
    \end{minipage}
    \vfill
    \vspace{10pt}
    \begin{minipage}{\linewidth}
        \centering
        \includegraphics[width=\linewidth]{Chapters/images/llava-v1.6-mistral-7b-hf_analysis_2.pdf}
        \vspace{-6mm}
        \subcaption{Ensemble Defenses}
    \end{minipage}
    \caption{\textbf{Analysis on LLaVa-V1.6-Mistral-7B.} Overall, system reminder and model optimization exhibit safety shift while query refactoring exhibits harmfulness discrimination. Inter-mechanism ensembles reinforce the mechanism while intra-mechanism ensembles achieve a better trade-off.}
    \label{fig:llava-v1.6_analysis}
\end{figure*}

\begin{figure*}[!ht]
    \centering
    \begin{minipage}{0.25\linewidth} 
        \includegraphics[width=\linewidth]{Chapters/images/qwen2vl_analysis_0.pdf}
        \vspace{-6mm}
        \subcaption{Baseline}
    \end{minipage}
    \vfill 
    \vspace{10pt}
    \begin{minipage}{\linewidth}
        \includegraphics[width=\linewidth]{Chapters/images/qwen2vl_analysis_1.pdf}
        \vspace{-6mm}
        \subcaption{Individual Defenses}
    \end{minipage}
    \vfill
    \vspace{10pt}
    \begin{minipage}{\linewidth}
        \centering
        \includegraphics[width=\linewidth]{Chapters/images/qwen2vl_analysis_2.pdf}
        \vspace{-6mm}
        \subcaption{Ensemble Defenses}
    \end{minipage}
    \caption{\textbf{Analysis on Qwen2-VL-7B-Instruct.} Overall, system reminder and model optimization exhibit safety shift while query refactoring exhibits harmfulness discrimination. Inter-mechanism ensembles reinforce the mechanism (except for QR++) while intra-mechanism ensembles achieve a better trade-off.}
    \label{fig:qwen2vl_analysis}
\end{figure*}

\begin{figure*}[!ht]
    \centering
    \begin{minipage}{0.25\linewidth} 
        \includegraphics[width=\linewidth]{Chapters/images/pixtral_analysis_0.pdf}
        \vspace{-6mm}
        \subcaption{Baseline}
    \end{minipage}
    \vfill 
    \vspace{10pt}
    \begin{minipage}{\linewidth}
        \includegraphics[width=\linewidth]{Chapters/images/pixtral_analysis_1.pdf}
        \vspace{-6mm}
        \subcaption{Individual Defenses}
    \end{minipage}
    \vfill
    \vspace{10pt}
    \begin{minipage}{\linewidth}
        \centering
        \includegraphics[width=\linewidth]{Chapters/images/pixtral_analysis_2.pdf}
        \vspace{-6mm}
        \subcaption{Ensemble Defenses}
    \end{minipage}
    \caption{{\textbf{Analysis on Pixtral-12B.} Overall, system reminder and model optimization exhibit safety shift while query refactoring exhibits harmfulness discrimination. Inter-mechanism ensembles reinforce the mechanism while intra-mechanism ensembles achieve a better trade-off.}}
    \label{fig:pixtral-12b_analysis}
\end{figure*}


\subsection{Analysis of LLMs} 
\label{sec:extra_llm}
To investigate whether the two mechanisms observed in LVLMs can be generalized to text-only LLMs, we conduct analysis on the LLaMA-3.1-8B model with XStest~\cite{rottger2023xstest}, a text-only benchmark comprising 250 safe prompts and 200 unsafe prompts. For this purpose, we adapt the model to text-only defenses by replacing the supervised fine-tuning dataset with Safety-Tuned-LLaMA dataset~\cite{bianchi2023safety}. Additionally, we implement a novel query refactoring method called Summarize, as proposed in~\cite{ji2024defending}. The experimental results, presented in Figure~\ref{fig:llama-3.1_analysis}, show that the LLaMA-3.1-8B model exhibits the same two mechanisms identified in LVLMs, and both intra-mechanism and inter-mechanism ensembles can achieve similar effects as LVLMs.

\begin{figure*}[!ht]
    \centering
    \begin{minipage}{0.25\linewidth} 
        \includegraphics[width=\linewidth]{Chapters/images/Llama-3.1-8B-Instruct_analysis_0.pdf}
        \vspace{-6mm}
        \subcaption{Baseline}
    \end{minipage}
    \vfill
    \vspace{10pt}
    \begin{minipage}{\linewidth}
        \includegraphics[width=\linewidth]{Chapters/images/Llama-3.1-8B-Instruct_analysis_1.pdf}
        \vspace{-6mm}
        \subcaption{Individual Defenses}
    \end{minipage}
    \vfill
    \vspace{10pt}
    \begin{minipage}{\linewidth}
        \centering
        \includegraphics[width=\linewidth]{Chapters/images/Llama-3.1-8B-Instruct_analysis_2.pdf}
        \vspace{-6mm}
        \subcaption{Ensemble Defenses}
    \end{minipage}
    \caption{\textbf{Analysis on LLaMA-3.1-8B.} System reminder and model optimization both exhibit safety shift while query refactoring exhibits harmfulness discrimination. Inter-mechanism ensembles reinforce the mechanism while intra-mechanism ensembles achieve a better trade-off.}
    \label{fig:llama-3.1_analysis}
\end{figure*}


\section{Consistency Analysis}
\label{sec:consistency_appendix}
Figure~\ref{fig:consistency_all} presents the results of the consistency analysis between generation and classification settings. 
The results indicate high consistency between generation and classification tasks when no defense strategies are applied. However, the model tends to demonstrate slightly higher refusal rates during classification compared to generation, with this discrepancy further amplified by different defense applications. Specifically, the model exhibits greater safety awareness and preference when acting as a judge with explicit classification objectives compared to directly generating content. This finding highlights the necessity of implementing self-judgement mechanisms before generating response in the context of jailbreak defenses.

% \textcolor{blue}{To provide a comprehensive comparison of DSR between classification and generative tasks, we conducted a correlation analysis across various defense methods. As shown in Figure~\ref{fig:dsr_comparison}, when the refusal threshold is set to 0.5, the correlation coefficient is 0.59, indicating a moderate positive monotonic correlation. By increasing the refusal threshold to 0.7, the correlation coefficient rises to 0.64. This adjustment enhances the consistency between the two settings, suggesting that higher thresholds align their behaviors more closely.}

To further analyze the correlation between classification and generative settings, we calculate the Spearman's Rank Correlation Coefficient for the Detection Success Rate (DSR) across different defense methods in these two settings. As shown in Figure~\ref{fig:dsr_comparison}(left), the coefficient is 0.59, indicating a moderate positive monotonic correlation. As the model exhibits slightly higher refusal rates during classification compared to generation, we try to adjust the classification threshold for determining whether a model refuses a response from \emph{0.5} to \emph{0.7}. The correlation coefficient is thereby increased to 0.64, as shown in Figure~\ref{fig:dsr_comparison}(right), enhancing the consistency between the two settings.


\begin{figure*}[!ht]
    \centering
    \includegraphics[width=\linewidth]{Chapters/images/consistency_all.pdf}
    \caption{All consistency analysis results on different defense strategies.}
    \label{fig:consistency_all}
\end{figure*}

\begin{figure*}[!ht]
    \centering
    \includegraphics[width=\linewidth]{Chapters/images/dsr_comparison.pdf}
    \caption{\textbf{Spearman's Rank Correlation Coefficient of DSR between generation and classification settings.} The classification threshold for determining whether a model refuses a response is 0.5 for the left image, and 0.7 for the right image. From the result, we see that these two settins are positive correlated, and a higher refusal bar leads to a higher consistency between these two settings.}
    \label{fig:dsr_comparison}
\end{figure*}

\section{Utility Analysis}
\label{sec:utility}
To evaluate how well defense methods preserve the general response generation capabilities of LVLMs, we conduct a detailed evaluation using the MM-Vet benchmark~\cite{yu2023mm}. This benchmark measures six core vision-language capabilities across multiple tasks, offering a comprehensive assessment of model utility. We evaluate both individual and ensemble defense strategies on LLaVA-1.5 with 7B and 13B parameters.
Table~\ref{tab:utility_analysis} summarizes the results of this evaluation.

\begin{table*}[!ht]
    \centering
    \caption{\textbf{Utility analysis of LLaVA-1.5 Models (7B and 13B) on MM-Vet dataset}, where the scores on six core vision-language capabilities, i.e. Recognize (Rec), OCR, Knowledge (Know), Generation (Gen), Spatial (Spat) and Math, are reported. }
    \label{tab:utility_analysis}
    \resizebox{\textwidth}{!}{
    \setlength{\tabcolsep}{3pt} 
    \begin{tabular}{r|ccccccc|ccccccc}
        \toprule 
        \textbf{Method} & \multicolumn{7}{c|}{\textbf{LLaVA-1.5-7B}} & \multicolumn{7}{c}{\textbf{LLaVA-1.5-13B}} \\
        \cmidrule(lr){2-8} \cmidrule(lr){9-15}
         & \textbf{Rec}$\uparrow$ & \textbf{OCR}$\uparrow$ & \textbf{Know}$\uparrow$ & \textbf{Gen}$\uparrow$ & \textbf{Spat}$\uparrow$ & \textbf{Math}$\uparrow$ & \textbf{Total}$\uparrow$ 
         & \textbf{Rec}$\uparrow$ & \textbf{OCR}$\uparrow$ & \textbf{Know}$\uparrow$ & \textbf{Gen}$\uparrow$ & \textbf{Spat}$\uparrow$ & \textbf{Math}$\uparrow$ & \textbf{Total}$\uparrow$ \\
        \midrule
        w/o Defense & 34.9 & 18.7 & 17.1 & 18.0 & 21.1 & 4.2 & 29.1 & 37.9 & 26.5 & 21.3 & 19.6 & 31.2 & 7.7 & 33.6 \\
        \midrule
        \multicolumn{15}{c}{System Reminder} \\
        \midrule
        Responsible & 32.9 & 19.5 & 13.3 & 13.7 & 20.4 & 11.5 & 28.3 & 35.6 & 25.2 & 16.0 & 15.3 & 32.1 & 11.5 & 32.1 \\
        Policy & 33.3 & 19.3 & 13.0 & 14.9 & 23.9 & 7.7 & 28.3 & 34.4 & 27.8 & 15.4 & 15.8 & 35.6 & 18.5 & 32.8 \\
        Demonstration & 32.4 & 19.7 & 14.4 & 14.1 & 23.3 & 7.7 & 28.3 & 36.1 & 27.2 & 18.2 & 16.0 & 34.9 & 15.0 & 33.2 \\
        \midrule
        \multicolumn{15}{c}{Model Optimization} \\
        \midrule
        SFT & 33.2 & 20.1 & 15.1 & 16.9 & 23.6 & 7.7 & 28.3 & 34.1 & 21.9 & 17.1 & 17.2 & 27.7 & 9.2 & 29.7 \\
        SafeDecoding & 33.1 & 19.3 & 15.7 & 16.2 & 21.9 & 7.7 & 28.1 & 34.7 & 24.6 & 17.6 & 15.7 & 32.8 & 9.6 & 31.8 \\
        DPO & 30.5 & 19.1 & 11.5 & 12.0 & 22.9 & 7.3 & 26.8 & 35.7 & 22.3 & 17.1 & 16.8 & 29.7 & 4.6 & 31.2 \\
        \midrule
        \multicolumn{15}{c}{Query Refactoring} \\
        \midrule
        Caption & 31.6 & 19.0 & 17.9 & 15.2 & 24.4 & 7.3 & 27.9 & 31.7 & 28.3 & 13.7 & 15.2 & 34.0 & 15.4 & 30.6 \\
        Caption (w/o image) & 30.9 & 18.2 & 15.6 & 15.1 & 21.6 & 7.7 & 26.4 & 30.4 & 28.3 & 14.4 & 15.1 & 31.5 & 18.8 & 30.2 \\
        Intention & 29.9 & 21.9 & 12.0 & 11.4 & 28.0 & 11.5 & 28.0 & 35.1 & 24.7 & 17.7 & 17.1 & 27.6 & 4.2 & 30.6 \\
        \midrule
        \multicolumn{15}{c}{Noise Injection} \\
        \midrule
        Mask Image & 30.3 & 19.4 & 12.9 & 13.0 & 25.9 & 8.1 & 26.8 & 35.0 & 22.0 & 17.3 & 15.9 & 27.2 & 3.8 & 30.6 \\
        \midrule
        \midrule
        \multicolumn{15}{c}{SR++} \\
        \midrule        
        Responsible-Demonstration & 31.1 & 21.0 & 14.6 & 13.6 & 24.9 & 7.7 & 27.9 & 34.7 & 25.6 & 16.4 & 14.2 & 31.9 & 11.2 & 31.5 \\
        Responsible-Policy & 33.6 & 22.2 & 14.6 & 15.8 & 23.7 & 7.7 & 29.7 & 34.8 & 28.1 & 17.3 & 16.3 & 34.4 & 15.0 & 32.9 \\
        Policy-Demonstration & 32.2 & 18.1 & 13.8 & 14.6 & 22.3 & 7.7 & 27.5 & 34.0 & 27.5 & 15.0 & 13.4 & 34.1 & 15.0 & 32.1 \\
        Responsible-Policy-Demonstration & 31.2 & 19.8 & 12.9 & 13.0 & 23.7 & 7.7 & 27.4 & 32.6 & 24.8 & 13.2 & 10.9 & 32.3 & 15.0 & 30.3 \\
        \midrule
        \multicolumn{15}{c}{SR+MO} \\
        \midrule     
        Responsible-SFT & 32.3 & 20.4 & 15.2 & 15.6 & 23.1 & 7.7 & 28.4 & 35.3 & 28.4 & 17.4 & 17.0 & 32.1 & 7.7 & 33.0 \\
        Responsible-SafeDecoding & 34.0 & 19.0 & 13.8 & 15.4 & 23.9 & 7.7 & 29.0 & 34.3 & 25.9 & 17.3 & 15.9 & 32.7 & 9.2 & 31.7 \\
        Demonstration-SFT & 32.0 & 21.6 & 15.7 & 15.6 & 24.5 & 7.7 & 28.4 & 35.2 & 29.4 & 19.4 & 16.0 & 33.2 & 7.7 & 33.3 \\
        Demonstration-SafeDecoding & 32.5 & 21.4 & 15.2 & 15.5 & 25.3 & 8.1 & 28.4 & 34.9 & 28.2 & 19.2 & 16.2 & 35.1 & 17.7 & 33.3 \\
        \midrule
        \multicolumn{15}{c}{QR++} \\
        \midrule   
        Caption-Intention & 33.4 & 22.4 & 17.4 & 15.9 & 28.7 & 7.7 & 29.9 & 32.4 & 26.7 & 15.2 & 14.6 & 30.8 & 15.0 & 30.8 \\
        \midrule
        \midrule
        \multicolumn{15}{c}{QR\textbar{}SR} \\
        \midrule   
        Caption-Responsible & 33.5 & 20.5 & 17.1 & 17.1 & 26.1 & 7.7 & 28.9 & 31.9 & 26.4 & 14.4 & 14.9 &32.0 & 19.2 & 30.2 \\
        Intention-Responsible & 32.5 & 18.6 & 15.1 & 16.4 & 23.3 & 7.7 & 27.8 & 33.4 & 22.4 & 14.4 & 15.6 & 25.9 & 3.8 & 28.5 \\
        Caption-Responsible (w/o image) & 29.3 & 16.2 & 13.9 & 14.6 & 21.9 & 7.7 & 24.4 & 29.9 & 26.1 & 15.2 & 15.6 & 32.1 & 18.8 & 29.1\\
        \midrule
        \multicolumn{15}{c}{QR\textbar{}MO} \\
        \midrule
        Caption-SafeDecoding & 30.0 & 18.2 & 13.8 & 13.2 & 21.9 & 4.2 & 26.2 & 32.6 & 26.7 & 14.8 & 17.0 & 30.4 & 11.2 & 31.0 \\
        Intention-SFT & 29.9 & 19.1 & 15.7 & 16.1 & 20.8 & 7.7 & 26.4 & 32.0 & 24.6 & 17.1 & 15.2 & 28.0 & 7.7 & 29.4\\
        Caption-SafeDecoding (w/o image) & 28.5 & 15.7 & 16.9 & 16.0 & 18.0 & 3.8 & 23.9 & 31.9 & 24.1 & 15.0 & 17.4 & 28.3 & 11.2 & 29.1\\
        \bottomrule
    \end{tabular}}
\end{table*}


\section{Results under More Diverse Attacks}
\label{sec:diverse_attacks}
To incorporate greater diversity and complexity representative of real-world jailbreak scenarios, we extend our experiments using JailbreakV-28K~\cite{luo2024jailbreakv28k}, a comprehensive multimodal jailbreak evaluation benchmark. This dataset encompasses 16 safety policies, five diverse jailbreak methods, a variety of image types, and only evaluate in terms of DSR. Specifically, we utilize the mini version of this benchmark and evaluate all our defense strategies.

Table~\ref{tab:jailbreakv_results} presents the evaluation results of all defense methods on this benchmark. The findings reveal that LVLMs demonstrate weaker defensive capabilities against MLLM-based attacks compared to LLM transfer attacks. Moreover, ensemble strategies consistently outperform individual defenses, showcasing enhanced effectiveness, especially in scenarios where baseline models initially struggle.

\begin{table*}[!ht]
    \centering
    \caption{\textbf{Evaluation results of all defense methods on the JailbreakV-28K benchmark.} The dataset includes five diverse jailbreak methods, comprising three types of LLM transfer attacks (Template, Persuasive, and Logic) and two types of MLLM attacks (FigStep and Query-relevant attacks involving SD, Typo, and SD+Typo).}
    \label{tab:jailbreakv_results}
    \resizebox{\textwidth}{!}{
     \setlength{\tabcolsep}{3pt} 
    \begin{tabular}{r|cccccccc|cccccccc}
        \toprule 
        \textbf{Method} & \multicolumn{8}{c|}{\textbf{LLaVA-1.5-7B}} & \multicolumn{8}{c}{\textbf{LLaVA-1.5-13B}} \\
        \cmidrule(lr){2-9} \cmidrule(lr){10-17}
         & \textbf{Template}$\uparrow$ & \textbf{Persuasive}$\uparrow$ & \textbf{Logic}$\uparrow$ & \textbf{Figstep}$\uparrow$ & \textbf{SD}$\uparrow$ & \textbf{Typo}$\uparrow$ & \textbf{SD+Typo}$\uparrow$ & \textbf{Total}$\uparrow$
         & \textbf{Template}$\uparrow$ & \textbf{Persuasive}$\uparrow$ & \textbf{Logic}$\uparrow$ & \textbf{Figstep}$\uparrow$ & \textbf{SD}$\uparrow$ & \textbf{Typo}$\uparrow$ & \textbf{SD+Typo}$\uparrow$ & \textbf{Total}$\uparrow$ \\
        \midrule
        w/o Defense & 0.38 & 0.62 & 1.00 & 0.09 & 0.08 & 0.12 & 0.05 & 0.31 & 0.52 & 0.77 & 0.60 & 0.05 & 0.04 & 0.12 & 0.09 & 0.40 \\
        \midrule
        \multicolumn{15}{c}{System Reminder} \\
        \midrule
        Responsible & 0.56 & 0.85 & 1.00 & 0.00 & 0.17 & 0.29 & 0.18 & 0.46 & 0.65 & 0.85 & 1.00 & 0.00 & 0.21 & 0.41 & 0.23 & 0.53 \\
        Policy & 0.46 & 0.69 & 0.80 & 0.69 & 0.08 & 0.12 & 0.09 & 0.36 & 0.54 & 0.77 & 0.60 & 0.05 & 0.12 & 0.18 & 0.09 & 0.42 \\
        Demonstration & 0.51 & 0.85 & 1.00 & 0.05 & 0.17 & 0.29 & 0.14 & 0.42 & 0.59 & 0.85 & 1.00 & 0.05 & 0.17 & 0.47 & 0.27 & 0.50 \\
        \midrule
        \multicolumn{15}{c}{Model Optimization} \\
        \midrule
        SFT & 0.70 & 0.85 & 0.80 & 0.09 & 0.21 & 0.59 & 0.23 & 0.57 & 0.78 & 0.85 & 0.80 & 0.09 & 0.21 & 0.59 & 0.23 & 0.62 \\
        SafeDecoding & 0.51 & 0.77 & 1.00 & 0.14 & 0.21 & 0.59 & 0.18 & 0.46 & 0.59 & 0.77 & 1.00 & 0.14 & 0.21 & 0.59 & 0.18 & 0.51 \\
        DPO & 0.47 & 0.54 & 1.00 & 0.09 & 0.12 & 0.24 & 0.14 & 0.39 & 0.51 & 0.54 & 1.00 & 0.09 & 0.12 & 0.24 & 0.14 & 0.41 \\
        \midrule
        \multicolumn{15}{c}{Query Refactoring} \\
        \midrule
        Caption & 0.38 & 0.08 & 0.40 & 0.09 & 0.04 & 0.06 & 0.09 & 0.27 & 0.56 & 0.62 & 0.60 & 0.09 & 0.12 & 0.12 & 0.14 & 0.43 \\
        Caption (w/o image) & 0.38 & 0.15 & 0.20 & 0.23 & 0.17 & 0.18 & 0.18 & 0.31 & 0.60 & 0.69 & 0.80 & 0.09 & 0.21 & 0.24 & 0.41 & 0.50 \\
        Intention & 0.38 & 0.31 & 0.40 & 0.09 & 0.04 & 0.18 & 0.00 & 0.28 & 0.52 & 0.69 & 0.60 & 0.32 & 0.08 & 0.24 & 0.05 & 0.42 \\
        \midrule
        \multicolumn{15}{c}{Noise Injection} \\
        \midrule
        Mask Image & 0.40 & 0.62 & 0.80 & 0.05 & 0.08 & 0.18 & 0.18 & 0.33 & 0.51 & 0.77 & 0.40 & 0.05 & 0.18 & 0.08 & 0.14 & 0.40 \\
        \midrule
        \multicolumn{15}{c}{SR++} \\
        \midrule        
        Responsible-Demonstration & 0.67 & 0.92 & 0.80 & 0.05 & 0.25 & 0.59 & 0.14 & 0.55 & 0.73 & 0.92 & 1.00 & 0.05 & 0.29 & 0.71 & 0.36 & 0.62 \\
        Responsible-Policy & 0.56 & 0.85 & 1.00 & 0.05 & 0.25 & 0.24 & 0.09 & 0.46 & 0.58 & 0.92 & 1.00 & 0.09 & 0.08 & 0.53 & 0.09 & 0.48 \\
        Policy-Demonstration & 0.50 & 0.92 & 0.80 & 0.05 & 0.25 & 0.35 & 0.09 & 0.43 & 0.54 & 0.92 & 1.00 & 0.05 & 0.17 & 0.35 & 0.18 & 0.46 \\
        Responsible-Policy-Demonstration & 0.62 & 0.92 & 1.00 & 0.05 & 0.25 & 0.35 & 0.14 & 0.51 & 0.67 & 0.92 & 1.00 & 0.05 & 0.21 & 0.41 & 0.32 & 0.56 \\
        \midrule
        \multicolumn{15}{c}{SR+MO} \\
        \midrule     
        Responsible-SFT & 0.76 & 1.00 & 1.00 & 0.23 & 0.50 & 0.88 & 0.64 & 0.71 & 0.82 & 1.00 & 1.00 & 0.14 & 0.42 & 0.76 & 0.45 & 0.71 \\
        Responsible-SafeDecoding & 0.62 & 0.92 & 1.00 & 0.05 & 0.33 & 0.76 & 0.27 & 0.55 & 0.66 & 0.92 & 1.00 & 0.14 & 0.21 & 0.65 & 0.41 & 0.57 \\
        Demonstration-SFT & 0.79 & 1.00 & 1.00 & 0.14 & 0.50 & 0.82 & 0.59 & 0.71 & 0.71 & 1.00 & 1.00 & 0.05 & 0.50 & 0.88 & 0.64 & 0.66 \\
        Demonstration-SafeDecoding & 0.63 & 0.92 & 1.00 & 0.23 & 0.33 & 0.76 & 0.27 & 0.64 & 0.63 & 1.00 & 1.00 & 0.23 & 0.50 & 0.71 & 0.50 & 0.61 \\
        \midrule
        \multicolumn{15}{c}{QR++} \\
        \midrule   
        Caption-Intention & 0.37 & 0.23 & 0.40 & 0.05 & 0.12 & 0.00 & 0.05 & 0.27 & 0.54 & 0.54 & 0.60 & 0.05 & 0.12 & 0.12 & 0.18 & 0.41  \\
        \midrule
        \multicolumn{15}{c}{QR\textbar{}SR} \\
        \midrule   
        Caption-Responsible & 0.51 & 1.00 & 1.00 & 0.18 & 0.21 & 0.47 & 0.32 & 0.47 & 0.69 & 0.92 & 1.00 & 0.00 & 0.21 & 0.41 & 0.27 & 0.56 \\
        Intention-Responsible & 0.63 & 1.00 & 1.00 & 0.59 & 0.38 & 0.76 & 0.23 & 0.61 & 0.75 & 1.00 & 0.80 & 0.18 & 0.17 & 0.59 & 0.32 & 0.62 \\
        Caption-Responsible (w/o image) & 0.58 & 1.00 & 1.00 & 1.00 & 0.92 & 1.00 & 0.95 & 0.72 & 0.68 & 1.00 & 1.00 & 0.59 & 0.42 & 0.41 & 0.64 & 0.65 \\
        \midrule
        \multicolumn{15}{c}{QR\textbar{}MO} \\
        \midrule
        Caption-SafeDecoding & 0.56 & 0.69 & 0.60 & 0.77 & 0.08 & 0.29 & 0.09 & 0.49 & 0.69 & 0.85 & 0.80 & 0.14 & 0.04 & 0.12 & 0.14 & 0.53 \\
        Intention-SFT & 0.60 & 0.77 & 0.60 & 0.95 & 0.29 & 0.71 & 0.27 & 0.59 & 0.66 & 0.92 & 0.80 & 0.00 & 0.21 & 0.59 & 0.27 & 0.55 \\
        Caption-SafeDecoding (w/o image) & 0.54 & 0.69 & 0.40 & 0.73 & 0.17 & 0.35 & 0.32 & 0.50 & 0.76 & 0.60 & 0.20 & 0.17 & 0.29 & 0.41 & 0.60 & 0.60\\
        \bottomrule
    \end{tabular}}
\end{table*}

\section{Inference Time Consumption Comparison}
\label{sec:time}
We assess the inference time overhead introduced by defense methods using the LLaVA-1.5-7B model. The evaluation includes 50 benign queries and 50 harmful queries, with the average time cost per query calculated. The results are shown in Table~\ref{tab:time_comparison}.

We observe that defense methods generally increase inference time for benign queries, especially in approaches like \emph{Query Refactoring}, which involve additional computational steps.  In contrast, for harmful queries, most methods result in faster responses by generating concise rejection messages. These findings highlight the trade-offs between enhanced safety and inference efficiency when deploying different defense strategies.

\begin{table*}[!ht]
    \centering
    \caption{\textbf{Inference Time Comparison Analysis.} The table presents the average inference time (in seconds) per query for both harmful and benign queries under various defense methods.}
    \label{tab:time_comparison}
    \resizebox{\textwidth}{!}{
     \setlength{\tabcolsep}{3pt} 
    \begin{tabular}{l|cc|l|cc|l|cc}
        \toprule
        \textbf{Method} & \textbf{Harmful} & \textbf{Benign} & \textbf{Method} & \textbf{Harmful} & \textbf{Benign} & \textbf{Method} & \textbf{Harmful} & \textbf{Benign} \\
        \midrule
        w/o Defense & 3.51 & 3.56 & Caption & 3.73 & 4.88 & Responsible-Demonstration & 2.98 & 3.98 \\
        Responsible & 3.10 & 3.76 & Caption (w/o image) & 3.59 & 4.80 & Responsible-Policy & 3.40 & 4.22 \\
        Policy & 3.84 & 3.91 & Intention & 4.11 & 4.30 & Policy-Demonstration & 3.19 & 4.15 \\
        Demonstration & 2.89 & 3.80 & Mask Image & 3.49 & 3.62 & Responsible-Policy-Demonstration & 3.76 & 4.44 \\
        SFT & 2.92 & 4.36 & Vertical Flip Image & 3.28 & 4.15 & Responsible-SFT & 1.89 & 4.34 \\
        SafeDecoding & 3.33 & 3.80 & Insert Text & 3.69 & 3.36 & Responsible-SafeDecoding & 3.12 & 3.82 \\
        DPO & 3.46 & 3.85 & Swap Text & 3.07 & 3.97 & Demonstration-SFT & 2.20 & 4.59 \\
        Caption-Intention & 4.35 & 5.45 & Caption-Responsible & 4.00 & 4.71 & Demonstration-SafeDecoding & 2.82 & 3.93 \\
        Intention-Responsible & 4.25 & 5.15 & Caption-Responsible (w/o image) & 2.26 & 4.03 & Caption-SafeDecoding & 3.83 & 4.62 \\
        Caption-SafeDecoding (w/o image) & 3.21 & 4.33 & Intention-SFT & 3.76 & 4.26 & \multicolumn{3}{c}{}  \\
        \bottomrule
    \end{tabular}}
\end{table*}
