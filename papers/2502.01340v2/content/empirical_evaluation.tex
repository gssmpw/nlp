\section{User Study}

Having verified the basic ability of our model to produce polarizing debates in the previous section, we now present an exploratory investigation into how discussion polarization and algorithmic content curation in social media environments affect human perception of debates and their engagement behavior. Rather than testing specific hypotheses, this study aims to examine whether our framework can capture and reproduce fundamental mechanisms of online polarization identified in previous social science research. Through a controlled experiment using a simulated social media platform, we examine how different levels of discussion polarization (polarized vs. moderate) and recommendation bias (pro, balanced, contra) shape opinion formation and interaction patterns. This exploratory approach allows us to assess the framework's potential as a research tool for investigating human behavior in polarized online spaces, while providing initial insights into the complex interplay between platform design, user perception, and engagement patterns. The key findings of our user study are summarized in Table~\ref{tab:user-study-findings}.

\subsection{Experimental Design}

We employed a $2 \times 3$ between-subjects factorial design to investigate the dynamics of opinion formation and perception of polarization in online discussions. The experimental design manipulated two key dimensions: the \emph{Polarization Degree} in the artificial agent population and a systematic \emph{Recommendation Bias} while maintaining Universal Basic Income (UBI) (cf. Section \ref{sec:offline-evaluation}) as the consistent discussion topic.

The first experimental dimension contrasted highly polarized discussions with moderate ones through the manipulation of artificial agent behavior. In the polarized condition, artificial agents expressed extreme viewpoints and employed confrontational discourse patterns, characterized by emotional language, strong assertions, and minimal acknowledgment of opposing viewpoints. The moderate condition featured more nuanced discussions and cooperative interaction styles, with agents expressing uncertainty, acknowledging limitations in their knowledge, and engaging constructively with opposing views.

\input{tables/key_findings_user_study}


\input{figures/prototype_screenshot}

The second dimension introduced systematic bias in the recommendation system, implemented across three levels: neutral ($50\%$ pro-UBI, $50\%$ contra-UBI content), pro-bias ($70\%$ pro-UBI, $30\%$ contra-UBI content), and contra-bias ($30\%$ pro-UBI, $70\%$ contra-UBI content). This manipulation aimed to investigate how algorithmic content curation influences opinion formation and perception of debate polarization.

\subsection{System Prototype}

The prototype implementation consists of a web application that simulates a social media platform, reminiscent of X (formerly Twitter), to study social polarization dynamics. The interface, as depicted in Figure~\ref{fig:prototype-screenshot}, adheres to a familiar social media layout, facilitating user engagement and interaction.

\subsubsection{User Interface}

The application's main interface is divided into three primary sections: a navigation sidebar on the left, a central Newsfeed, and a recommendation panel on the right. The navigation sidebar provides quick access to essential functionalities such as the user's profile, a general user overview, and a logout option. The central Newsfeed serves as the primary interaction space, where users can view and engage with posts from other users. At the top of the Newsfeed, a text input area invites users to share their thoughts, mimicking the spontaneous nature of social media communication.

The Newsfeed displays a series of posts, each accompanied by user avatars, usernames, timestamps, and interaction metrics such as \emph{likes}, \emph{comments}, and \emph{reposts}. This design encourages user engagement and provides visual cues about the popularity and impact of each post. The recommendation panel on the right side of the interface suggests other users to follow, potentially influencing the user's network expansion and exposure to diverse viewpoints.

User profiles are dynamically generated, displaying the user's posts, follower relationships, and other relevant metadata like a user's handle and biography (see Section~\ref{subsec:agent-model} and Section~\ref{subsec:social-network-model} for details). It is also possible to follow and unfollow artificial users.

\subsubsection{Newsfeed Recommendations}

The web application implements an adaptive recommendation system for content presentation that evolves with user engagement. This system employs two distinct algorithmic approaches: a default variant for initial users and a collaborative variant that activates once users establish an interaction history.

The default variant implements a popularity-based scoring mechanism that considers multiple forms of engagement to determine content visibility. For a given message $m$, the system calculates a composite popularity score:

\begin{align}
    S_p(m) = l_m + 2c_m + 2r_m
\end{align}

where $l_m$, $c_m$, and $r_m$ represent the number of the message's \emph{likes}, \emph{comments}, and \emph{reposts} respectively. The weighted coefficients reflect the relative importance assigned to different forms of engagement, with more active forms of interaction carrying greater weight.

As users begin to interact with the platform, the system transitions to a collaborative variant that incorporates popularity metrics, ideological proximity, and a stochastic element to ensure recommendation diversity. The enhanced scoring function combines these elements into a composite score:

\begin{align}
    S_c(m) = \omega_p \cdot \frac{S_p(m)}{S_{max}} + \omega_i \cdot \frac{2 - |o_u - o_a|}{2} + \omega_r \cdot \epsilon
\end{align}

where $S_p(m)$ represents the popularity score normalized by the maximum observed score $S_{max}$, $o_u$ and $o_a$ denote the opinion scores of the active user (determined as the average of the opinion scores of the artificial users interacted with) and the (artificial) message author respectively, $\epsilon$ represents a uniform random variable in the interval $[0,1]$, and $\omega_p$, $\omega_i$, and $\omega_r$ are weighting parameters that sum to unity ($\omega_p + \omega_i + \omega_r = 1$). In the current implementation, these weights are set to $\omega_p = 0.6$, $\omega_i = 0.2$, and $\omega_r = 0.2$, balancing the influence of popularity, ideological similarity, and randomization.

Both variants maintain temporal relevance by presenting the user's most recent content contributions at the beginning of their feed when accessing the first page. This approach ensures users maintain awareness of their own contributions while experiencing the broader content landscape through the scoring-based recommendations.

This dual-variant approach enables the system to provide meaningful content recommendations even in the absence of user interaction data while transitioning smoothly to more personalized recommendations as users engage with the platform. The incorporation of popularity metrics, (mild) ideological factors, and controlled randomization creates diverse recommendations that is designed to give the impression of a dynamic network environment, while still falling under the conditional \emph{Recommendation Bias} regime. The stochastic element particularly aids in preventing recommendation stagnation and ensures dynamic content delivery.

\subsection{Procedure}

The experiment consisted of three phases: pre-interaction, interaction, and post-interaction.

\paragraph{Pre-interaction Phase} Participants first completed a comprehensive questionnaire assessing various baseline measures. These included demographic information, social media usage patterns, and initial attitudes towards UBI. 

\paragraph{Interaction Phase} Afterwards, participants were introduced to our simulated social media platform. They were instructed to engage with the platform naturally, as they would in their regular social media use. Unbeknownst to the participants, all other users on the platform were artificial agents programmed to behave according to the assigned experimental conditions. Participants were given the following instructions:

\begin{quote}
"You will now interact with a social media platform discussing \emph{Universal Basic Income}. Please use the platform as you normally would use social media. You can read posts, like them, comment on them, or create your own posts. Your goal is to form an opinion on the topic. You will have 10 minutes for this task."
\end{quote}

During this phase, participants' interactions, including likes, comments, reposts, and follows were recorded for later analysis.

\paragraph{Post-interaction Phase} After the interaction period, participants completed a post-test questionnaire. This included measures of their perception of the key constructs listed below. Additionally, participants evaluated the realism and effectiveness of the simulated platform.

\subsection{Measures}

Key constructs measured in this study included:

\begin{itemize}
    \item \emph{Attitude Change}: Measured shifts in participants' opinions about UBI between pre- and post-interaction phases using a seven-item scale (1 = Strongly Disagree to 5 = Strongly Agree), capturing changes in both the direction and magnitude of support.
    
    \item \emph{Perceived Polarization}: Assessed participants' perception of opinion extremity and ideological division within the observed discussions using a four-item scale (1 = Strongly Disagree to 5 = Strongly Agree), focusing on the perceived distance between opposing viewpoints.
    
    \item \emph{Perceived Group Salience}: Evaluated the extent to which participants perceived the discussion as being driven by group identities rather than individual perspectives, using a four-item scale (1 = Strongly Disagree to 5 = Strongly Agree).
    
    \item \emph{Perceived Emotionality}: Measured participants' assessment of the emotional intensity and affective tone in discussions using a four-item scale (1 = Strongly Agree to 5 = Strongly Disagree), capturing the perceived level of emotional versus rational discourse.
    
    \item \emph{Perceived Uncertainty}: Captured the degree to which participants observed expressions of doubt and acknowledgment of knowledge limitations in the discussions using a four-item scale (1 = Strongly Disagree to 5 = Strongly Agree).
    
    \item \emph{Perceived Bias}: Evaluated participants' assessment of viewpoint balance and fair representation of different perspectives in the discussion using a four-item scale (1 = Strongly Agree to 5 = Strongly Disagree).
\end{itemize}

\subsection{Participants}

We recruited $122$ participants through the Prolific platform. The sample exhibited a gender distribution favoring male participants ($63.6\%$) over female participants ($35.7\%$), with a single participant preferring not to disclose their gender. The age distribution revealed a predominantly young to middle-aged sample, with approximately $61.5\%$ of participants falling between $20$ and $39$ years old. The modal age group was $25$-$29$ years (18.6\%), followed by $35$-$39$ years ($15.0\%$).

Regarding educational background, nearly half of the participants ($49.3\%$) held university degrees, indicating a relatively high level of formal education in the sample. The remaining participants were distributed across various educational qualifications, with A-levels/IB, GCSE, and vocational certifications each representing approximately $11\%$ of the sample.

The majority of participants were professionally active, with $58.6\%$ being employees and $10.7\%$ self-employed. The sample also included a notable proportion of students ($15.7\%$ combined university and school students), reflecting diverse occupational backgrounds.

\input{tables/construct_factors}

Participants demonstrated high engagement with social media platforms, with $80\%$ reporting daily or near-constant usage. The majority ($75\%$) spent between one and four hours daily on social media platforms. YouTube ($25.0\%$) and Facebook ($24.3\%$) emerged as the most frequently used platforms, followed by Instagram ($17.9\%$) and X, formerly Twitter ($10.7\%$). This usage pattern suggests participants were well-acquainted with social media interfaces and interaction patterns, making them suitable subjects for the study's simulated social media environment.

\subsection{Preliminary Analysis}

We evaluated the ecological validity of our experimental platform. Participants rated various aspects on $7$-point scales ($1$ = Not at all, $7$ = Extremely), with higher scores indicating more positive evaluations. The platform received favorable ratings across multiple dimensions, consistently scoring above the scale midpoint of $4$. Particularly noteworthy was the interface usability ($M = 5.52$, $SD = 1.15$), which participants rated as highly satisfactory. The platform's similarity to real social media platforms ($M = 4.69$, $SD = 1.65$) and its ability to facilitate meaningful discussions ($M = 4.59$, $SD = 1.41$) were also rated positively. The overall platform realism received satisfactory ratings ($M = 4.47$, $SD = 1.61$), suggesting that participants found the experimental environment sufficiently realistic and engaging for the purposes of this study. The attitudes of participants toward Universal Basic Income exhibited a slight decline from the pre-interaction phase ($M = 3.12$, $SD = 0.90$) to the post-interaction phase ($M = 2.99$, $SD = 0.99$). However, these attitudes remained relatively close to the scale midpoint, indicating that participants held moderate views on the subject matter under discussion.

\input{tables/study_anova}


Furthermore, we examined the psychometric properties of our key measures (see Table~\ref{tab:factor-loadings}). Principal component analyses were conducted for each scale, with items loading on their intended factors. Most scales showed good reliability ($\alpha$ ranging from $.715$ to $.893$) and satisfactory factor loadings ($|.40|$ or greater). The \emph{Perceived Group Salience} scale required modification from its original four-item structure. Two items (\emph{"The debate focused on ideas rather than group affiliations"} and \emph{"Individual perspectives were more prominent than group identities in the discussions"}) were dropped due to poor factor loadings ($.049$ and $.051$ respectively). The remaining two items showed modest to acceptable loadings ($.585$ and $.806$), though below optimal thresholds. Given the theoretical importance of group salience in our research design, we retained this measure for further analyses while acknowledging its psychometric limitations.


\subsection{Analysis of Debate Perception}
\label{subsec:debate-perception}

Our first analysis examines how users perceive and process discussions under varying conditions of \emph{Polarization Degree} and \emph{Recommendation Bias}. We specifically investigate whether participants recognize polarized discourse patterns, how they process emotional and group-based content, and how \emph{Recommendation Bias} might moderate these perceptions. Through this analysis, we aim to understand the psychological mechanisms through which discussion climate and content curation shape users' experience of online debates.

\subsubsection{Variance Analysis}

\input{figures/interaction_plots_perception}


The effects of discussion \emph{Polarization Degree} and \emph{Recommendation Bias} were analyzed using a series of $2 \times 3$ analyses of variance. As shown in Table~\ref{tab:perception-anova}, the results revealed consistent main effects of \emph{Polarization Degree} across multiple dependent variables, while \emph{Recommendation Bias} showed more limited impact. Figure~\ref{fig:perception-interaction-plots} visualizes the interaction effects for our key constructs.


Regarding \emph{Opinion Change}, although the effects did not reach statistical significance, the data suggested some noteworthy patterns. Neither \emph{Polarization Degree} ($F(1, 117) = 3.48$, $p = .065$, $\eta_p^2 = 0.029$) nor \emph{Recommendation Bias} ($F(2, 117) = 1.74$, $p = .180$, $\eta_p^2 = 0.029$) significantly influenced opinion change. The descriptive statistics revealed a tendency toward stronger opinion changes in the polarized condition with contra-\emph{Recommendation Bias} ($M = -0.408$, $SD = 0.598$) compared to other conditions, where changes were minimal (means ranging from $-0.087$ to $-0.015$).

Given that directional opinion change might mask important dynamics by allowing positive and negative changes to cancel each other out, we conducted an additional analysis focusing on the magnitude of opinion change (i.e., absolute values). This analysis revealed significant main effects for both \emph{Polarization Degree} ($F(1, 117) = 5.21$, $p = .024$, $\eta_p^2 = 0.043$) and \emph{Recommendation Bias} ($F(2, 117) = 3.61$, $p = .030$, $\eta_p^2 = 0.058$). Participants in the polarized condition showed stronger opinion changes ($M = 0.378$, $SD = 0.378$) compared to the unpolarized condition ($M = 0.248$, $SD = 0.254$, Hedges' $g = 0.390$). Post-hoc analyses for \emph{Recommendation Bias} revealed that participants in the contra-bias condition showed significantly stronger opinion changes compared to the pro-bias condition (Hedges' $g = 0.566$, $p = .009$). The neutral condition showed significantly stronger opinion changes compared to the pro-bias condition (Hedges' $g = 0.456$, $p = .039$), but did not significantly differ from the contra-bias condition (Hedges' $g = 0.147$, $p = .493$)

The \emph{Polarization Degree} manipulation strongly influenced participants' perception of the discussion climate. \emph{Perceived Polarization} showed a substantial main effect ($F(1, 116) = 56.48$, $p < .001$, $\eta_p^2 = 0.327$), with participants in the polarized condition reporting significantly higher levels ($M = 4.46$, $SD = 0.85$) compared to the unpolarized condition ($M = 3.35$, $SD = 0.79$). Post-hoc tests confirmed this significant difference ($t(116.44) = 7.52$, $p < .001$, Hedges' $g = 1.36$).

\emph{Perceived Emotionality} emerged as the strongest effect in the study ($F(1, 116) = 73.54$, $p < .001$, $\eta_p^2 = 0.388$). Participants in the polarized condition perceived substantially higher emotional content ($M = 3.58$, $SD = 0.76$) than those in the unpolarized condition ($M = 2.44$, $SD = 0.72$). Post-hoc analysis revealed a large effect size (Hedges' $g = 1.53$, $t(116.99) = 8.44$, $p < .001$). While \emph{Recommendation Bias} did not show a significant main effect ($F(2, 116) = 1.42$, $p = .245$, $\eta_p^2 = 0.024$), there was a marginal interaction effect ($F(2, 116) = 2.44$, $p = .092$, $\eta_p^2 = 0.040$).

The analysis of \emph{Perceived Uncertainty} revealed another strong main effect of \emph{Polarization Degree} ($F(1, 116) = 48.86$, $p < .001$, $\eta_p^2 = 0.296$). Participants exposed to polarized discussions reported significantly lower levels of expressed uncertainty ($M = 2.07$, $SD = 0.65$) compared to those in the unpolarized condition ($M = 2.90$, $SD = 0.63$). Post-hoc tests indicated a strong effect (Hedges' $g = -1.26$, $t(117.89) = -6.97$, $p < .001$).

\emph{Perceived Group Salience} showed significant main effects for both \emph{Polarization Degree} ($F(1, 116) = 17.18$, $p < .001$, $\eta_p^2 = 0.129$) and \emph{Recommendation Bias} ($F(2, 116) = 5.63$, $p = .005$, $\eta_p^2 = 0.089$). The polarized condition elicited higher reports of group-based discourse ($M = 3.00$, $SD = 0.51$) compared to the unpolarized condition ($M = 2.59$, $SD = 0.55$). Post-hoc analysis revealed a medium to large effect size (Hedges' $g = 0.73$, $t(120.00) = 4.10$, $p < .001$). Post-hoc tests for \emph{Recommendation Bias} showed significant differences between pro-bias and both contra-bias (Hedges' $g = -0.56$, $t(76.97) = -2.61$, $p = .011$) and neutral conditions (Hedges' $g = -0.74$, $t(72.39) = -3.34$, $p = .001$).

\emph{Perceived Bias} demonstrated both a significant main effect of \emph{Polarization Degree} ($F(1, 116) = 15.08$, $p < .001$, $\eta_p^2 = 0.115$) and a significant interaction effect with \emph{Recommendation Bias} ($F(2, 116) = 3.73$, $p = .027$, $\eta_p^2 = 0.060$). In the polarized condition, participants reported higher \emph{Perveived Bias} ($M = 3.51$, $SD = 0.74$) compared to the unpolarized condition ($M = 2.92$, $SD = 0.85$). Post-hoc tests confirmed this difference with a medium to large effect size (Hedges' $g = 0.69$, $t(119.97) = 3.85$, $p < .001$). The significant interaction suggests that the effect of \emph{Polarization Degree} on bias perception varied across \emph{Recommendation Bias} conditions, with particularly pronounced differences in the pro-bias condition (polarized: $M = 3.83$, $SD = 0.59$; unpolarized: $M = 2.68$, $SD = 0.87$).

To examine whether these effects might vary based on participants' prior attitudes toward Universal Basic Income, we conducted additional analyses grouping participants according to their initial position (strongly pro/contra, moderately pro/contra). However, these analyses did not yield any significant results, suggesting that the observed effects of \emph{Polarization Degree} and \emph{Recommendation Bias} on opinion change magnitude operate similarly across different initial attitude positions.

\subsubsection{Path Analysis}

To understand the mechanisms through which our experimental conditions influence both perceptual dimensions and opinion change, we employed structural equation modeling (SEM). This approach allows us to simultaneously estimate multiple interdependent relationships while accounting for measurement error and covariation between constructs.

\input{figures/sem}

We developed a theoretical model examining how \emph{Polarization Degree} and \emph{Recommendation Bias} affect \emph{Opinion Change Magnitude} and \emph{Perceived Polarization} both directly and through various perceptual pathways (see Figure~\ref{fig:path-model}). The model was estimated using maximum likelihood estimation with standardized variables. The results demonstrated excellent fit to the data ($\chi^2(6) = 2.335$, $p = .886$, CFI $= 1.000$, TLI $= 1.109$, RMSEA $= .000$ [90\% CI: .000, .068], SRMR $= .023$), explaining substantial variance in key outcome variables (e.g., \emph{Perceived Emotionality}: 53.3\%, \emph{Perceived Polarization}: 38.0\%, \emph{Perceived Uncertainty}: 30.5\%).

The SEM analysis revealed several significant pathways. First, both experimental conditions showed significant direct effects on \emph{Opinion Change Magnitude}. Higher \emph{Polarization Degree} led to increased \emph{Opinion Change Magnitude} ($\beta = .275$, $p = .007$), while pro-UBI \emph{Recommendation Bias} decreased \emph{Opinion Change Magnitude} ($\beta = -.280$, $p = .006$). Notably, these effects emerged despite none of the perceptual variables showing significant direct effects on \emph{Opinion Change Magnitude}.

Regarding the perceptual pathways, \emph{Polarization Degree} showed strong direct effects on multiple dimensions: \emph{Perceived Emotionality} ($\beta = .472$, $p < .001$), \emph{Perceived Uncertainty} ($\beta = -.541$, $p < .001$), \emph{Perceived Bias} ($\beta = .433$, $p < .001$), and \emph{Perceived Group Salience} ($\beta = .251$, $p = .019$). The analysis further revealed how \emph{Polarization Degree} shapes \emph{Perceived Polarization} through multiple pathways. Beyond its direct effect ($\beta = .247$, $p = .022$), \emph{Polarization Degree} also operated through two indirect paths: via \emph{Perceived Group Salience} ($IE = .105$, $p = .044$) and via \emph{Perceived Emotionality} ($IE = .050$, $p = .406$). The combination of these direct and indirect effects resulted in a substantial total effect of \emph{Polarization Degree} on \emph{Perceived Polarization} ($\beta = .402$, $p < .001$).

The model also captured interesting relationships between mediating variables. \emph{Perceived Group Salience} showed significant positive effects on both \emph{Perceived Emotionality} ($\beta = .447$, $p < .001$) and \emph{Perceived Polarization} ($\beta = .417$, $p < .001$). Additionally, we found a significant negative covariance between \emph{Perceived Uncertainty} and \emph{Perceived Bias} ($\beta = -.291$, $p = .012$), suggesting these perceptions tend to operate in opposition to each other.

These findings reveal a complex pattern where experimental conditions shape both behavioral outcomes (\emph{Opinion Change Magnitude}) and perceptual experiences, though these paths appear to operate independently rather than sequentially. The substantial total effect of \emph{Polarization Degree} on \emph{Perceived Polarization}, decomposed into direct and indirect pathways, highlights how environmental features can influence user perceptions through multiple complementary mechanisms.

\subsubsection{Discussion}

Our findings reveal significant insights into how users perceive, process, and respond to polarized discussions in social media environments. Through complementary analytical approaches, we demonstrate that the manipulation of \emph{Polarization Degree} had profound effects across multiple perceptual dimensions and behavioral outcomes, while \emph{Recommendation Bias} played a more nuanced role in shaping user experiences.

A key finding emerged in our analysis of opinion change. While directional opinion change showed no significant effects, the magnitude of opinion change revealed significant impacts of both experimental conditions. This discrepancy suggests that focusing solely on directional change may mask important dynamics by allowing opposing changes to cancel each other out. The significant effects on magnitude indicate that polarized environments and recommendation patterns do influence opinion formation, but not in a uniformly directional way. This aligns with theoretical perspectives suggesting that polarized environments might increase opinion volatility without necessarily pushing opinions in a consistent direction.

Particularly intriguing is our finding that while experimental conditions significantly predicted \emph{Opinion Change Magnitude}, none of the measured perceptual variables showed significant effects. This creates an interesting puzzle: why would objective environmental conditions affect opinion change while subjective perceptions of these conditions do not? Several theoretical explanations merit consideration. First, this could reflect unconscious processing mechanisms, where participants respond to structural features of the environment without consciously processing them, aligning with dual-process theories of attitude change \citep{petty_elaboration_1986, chaiken_the_2014}. Second, our post-hoc perception measures might not capture the dynamic nature of how perceptions evolved during the interaction period. Third, unmeasured mediating variables like information processing depth or emotional arousal might better explain the mechanism of influence. This pattern aligns with Kurt Lewin's concept of "environmental press," suggesting that behavior might be influenced by objective environmental properties independent of their subjective interpretation \citep{lewin_principles_2013}.

The strong effect of \emph{Polarization Degree} on \emph{Perceived Emotionality} ($\eta_p^2 = 0.388$) suggests that participants were highly attuned to the emotional tenor of discussions. However, our structural equation model revealed an unexpected pattern: the direct effect of \emph{Perceived Emotionality} on \emph{Perceived Polarization} became non-significant when controlling for \emph{Perceived Group Salience}. This finding has profound theoretical implications. It suggests that the relationship between emotional content and polarization perception is primarily mediated through group-based processing, aligning with theories of affective polarization and social identity. Drawing on Carl Schmitt's friend-enemy distinction \citep{schmitt_concept_2008} and its extensions by Laclau and Mouffe \citep{laclau_hegemony_2014}, this might indicate that emotional content primarily influences polarization perception by activating group-based antagonisms rather than through direct affective pathways. The strong mediating role of \emph{Perceived Group Salience} ($\beta = .417$) supports this interpretation, suggesting that emotional content primarily serves to highlight group boundaries and distinctions.

The absence of significant effects from \emph{Perceived Uncertainty} and \emph{Perceived Bias} on polarization perception, despite strong condition effects on these variables, suggests that the path to \emph{Perceived Polarization} is more specific than previously theorized. While polarized environments clearly influence these perceptual dimensions (uncertainty: $\beta = -.541$; bias: $\beta = .433$), their lack of predictive power for polarization perception suggests they might operate through different psychological mechanisms or serve different functions in processing polarized discourse.

Nevertheless, the inverse relationship between \emph{Polarization Degree} and \emph{Perceived Uncertainty} ($\eta_p^2 = 0.296$) aligns with theoretical frameworks suggesting that polarized discourse often manifests through increased assertiveness and reduced acknowledgment of epistemic limitations. This pattern may help explain the self-reinforcing nature of polarized discussions: as uncertainty expressions diminish, the space for nuanced dialogue potentially contracts.

These results carry important implications for platform design and intervention strategies. The clear user sensitivity to emotional content and its indirect effect through group salience suggests that interventions might need to target both emotional expression and group dynamics simultaneously. Moreover, the finding that conscious perceptions do not mediate opinion change suggests that traditional perception-focused interventions might have limited effectiveness. Instead, interventions might need to address structural features of the environment that influence behavior more directly.

Our findings particularly highlight the central role of group processes in polarization dynamics. The strong mediating role of \emph{Perceived Group Salience} in translating emotional content into polarization perceptions suggests that effective interventions might need to focus on reducing the salience of group boundaries rather than just moderating emotional content. This insight, supported by both our variance and path analyses, suggests a more nuanced approach to platform design that considers how features might inadvertently enhance group distinctions even when attempting to reduce emotional intensity.

\subsection{Analysis of User Engagement}

Our second analysis examines how polarization and recommendation bias shape user engagement behaviors on the platform. We investigate both the quantity and quality of interactions, analyzing how different experimental conditions affect users' preferences for specific types of engagement (\emph{likes}, \emph{comments}, \emph{reposts}, and \emph{follows}). This analysis aims to understand whether polarized environments and algorithmic bias influence not just how much users engage, but also how they choose to participate in discussions.

\subsubsection{Descriptive and Variance Analysis}

\input{tables/interactions_anova}


Our analysis revealed distinct patterns of user engagement across the experimental conditions. Of the total sample, participants generated $946$ interactions throughout the study period, with individual engagement levels varying substantially ($M = 6.91$, $SD = 8.50$, $Mdn = 5.00$, Range: $0-56$). The majority of participants ($81.02\%$) engaged at least once with the content. Among active users, engagement levels were distributed across three categories: low engagement ($1$-$5$ interactions; $36.5\%$ of participants), moderate engagement ($6$-$10$ interactions; $24.82\%$), and high engagement ($>10$ interactions; $19.71\%$).


Figure~\ref{fig:stacked-interaction-distribution} illustrates the distribution of interaction types across conditions. The visualization reveals a clear hierarchy in users' preferred forms of engagement, with \emph{likes} consistently representing the dominant form of interaction, accounting for $54.02\%$ of all engagements ($M = 3.73$, $SD = 5.63$). This was followed by \emph{follows} ($26.53\%$; $M = 1.83$, $SD = 2.98$), \emph{reposts} ($9.41\%$; $M = 0.65$, $SD = 1.36$), and \emph{comments} ($7.61\%$; $M = 0.53$, $SD = 1.11$). This pattern suggests a preference for low-effort engagement forms over more demanding interactions like commenting or reposting.

Correlation analysis revealed strong associations between certain interaction types. \emph{Total interactions} showed strong positive correlations with \emph{likes} ($r = .93$, $p < .001$) and \emph{follows} ($r = .73$, $p < .001$), moderate correlations with \emph{comments} ($r = .45$, $p < .001$), and weaker correlations with \emph{reposts} ($r = .37$, $p < .001$). Notably, \emph{comments} and \emph{reposts} showed minimal correlation with each other ($r = .01$, $p = .899$), suggesting these forms of engagement might serve distinct purposes for users.

\input{figures/interaction_distribution_stacked}

\input{figures/interaction_plots_activity}

Analysis of variance (see Table~\ref{tab:interactions-anova} and Figure~\ref{fig:interaction-plot-recommendation-bias}) revealed several significant effects of our experimental manipulations. For \emph{total interactions}, we found a significant main effect of \emph{Recommendation Bias} ($F(2,134) = 3.25$, $p = .042$, $\eta^2_p  = .046$). Post-hoc analyses indicated in the contra conditions ($M = 9.11$, $SD = 10.02$) significantly more interactions were generated than in the balanced ($M = 4.77$, $SD = 3.88$, $p = .008$, Hedges' $g = 0.56$). The comparison between contra and and pro-bias ($M = 7.03$, $SD = 9.07$) did not reach significance ($p = .345$), nor did the comparison between balanced and pro-bias ($p = .180$).

The analysis of specific interaction types revealed distinct patterns. Most notably, we found a significant main effect of \emph{Polarization Degree} on \emph{commenting} behavior ($F(1,135) = 6.51$, $p = .012$, $\eta^2_p = .046$). Participants in unpolarized conditions exhibited higher commenting rates ($M = 0.77$, $SD = 1.41$) compared to those in polarized conditions ($M = 0.28$, $SD = 0.52$), suggesting that a less polarized environment might facilitate more substantive engagement through \emph{comments}.

While other interaction types did not show significant main effects, several trending patterns emerged. The analysis of following behavior revealed a marginal effect of \emph{Recommendation Bias} ($F(2,134) = 2.60$, $p = .078$, $\eta^2_p  = .037$), with participants showing a tendency to follow more users when exposed to opposing views ($M = 2.59$, $SD = 3.75$) compared to balanced content ($M = 1.25$, $SD = 1.71$). Similarly, \emph{likes} showed a pattern consistent with \emph{total interactions}, though the effect did not reach statistical significance ($F(2,134) = 2.25$, $p = .110$, $\eta^2_p  = .032$).

Examining the combined effects of \emph{Polarization Degree} and \emph{Recommendation Bias} revealed interesting patterns in user behavior. In polarized conditions, participants showed the highest level of engagement in the contra condition ($M = 10.30$, $SD = 12.43$), while engagement with neutral ($M = 4.82$, $SD = 4.49$) and pro ($M = 4.80$, $SD = 5.29$) was notably lower. In unpolarized conditions, engagement was more evenly distributed across recommendation types, though still elevated for contra ($M = 7.92$, $SD = 7.62$) and pro-bias ($M = 9.25$, $SD = 12.85$) compared to balanced ($M = 4.71$, $SD = 3.26$).

\subsubsection{Discussion}

The patterns of user activity reveal nuanced insights into how \emph{Polarization Degree} and \emph{Recommendation Bias} shape engagement in online discussions. Our analyses demonstrate that these factors influence not merely the quantity of interactions but also alter how users choose to participate in debates.

The clear hierarchy in engagement forms---with \emph{likes} ($54.02\%$) dominating over \emph{follows} ($26.53\%$), \emph{reposts} ($9.41\%$), and \emph{comments} ($7.61\%$)---reflects fundamental patterns in social media behavior. Notably, the minimal correlation between \emph{comments} and \emph{reposts} ($r = .01$) challenges the intuition that all forms of active engagement serve similar functions. Instead, these behaviors may represent distinct modes of participation, with commenting indicating dialectical engagement while reposting signals content amplification.

The relationship between \emph{Polarization Degree} and commenting behavior ($\eta^2_p = .046$) warrants careful interpretation. While higher commenting rates in unpolarized conditions appear to suggest that moderate discourse environments foster more substantive engagement \citep{koudenburg_polarized_2022, yousafzai_political_2022}, this interpretation requires qualification. Our sample exhibited predominantly moderate attitudes toward UBI, making them potentially unrepresentative of users who actively engage in polarized discussions \citep{simchon_troll_2022}. The reduced commenting in polarized conditions might thus reflect a mismatch between discussion climate and user predispositions rather than an inherent effect of polarization.

The significant effect of \emph{Recommendation Bias} on \emph{total interactions} ($\eta^2_p = .046$) is particularly noteworthy in the context of opinion formation. The higher engagement in the polarized contra-bias condition ($M = 10.30$) coincided with the strongest observed opinion shifts ($M = -0.408$). Given that UBI represents a proposal for systemic economic change, arguments against it may have resonated more strongly with users' status quo bias and loss aversion. In a polarized environment, these contra-UBI arguments might have appeared particularly salient and consequential, leading to both increased engagement and stronger opinion shifts. This suggests that the combination of topic-specific factors---namely the potentially threatening nature of economic system changes---with polarized discourse might amplify user engagement, particularly when arguments align with psychological tendencies toward preserving existing systems.

While these findings provide initial insights into the relationship between platform design, user engagement, and opinion dynamics, several limitations suggest the need for more extensive research. The short-term nature of our study and its focus on a single topic limit generalizability. Future research should pursue longitudinal studies comparing topics with varying degrees of polarization and personal involvement to distinguish between topic-specific effects and general patterns of online discourse dynamics. Our findings thus represent a starting point for understanding the complex interplay between platform design, user behavior, and opinion dynamics in online discussions.
