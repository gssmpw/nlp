\section{Related Work}

Research on social polarization in online networks spans multiple disciplines and methodological approaches. The existing literature can be categorized into three main streams: (1) observational studies analyzing empirical data, (2) theoretical models simulating opinion dynamics, (3) and experimental user studies. While the first two approaches have been extensively developed and increasingly integrated, experimental studies with human participants remain relatively scarce despite their potential for understanding individual-level effects of polarization.

\subsection{Observational Studies}
Large-scale analyses of social media data have revealed fundamental patterns of online polarization. Early work by \citep{conover_political_2011} and \citep{bakshy_exposure_2015} established the presence of ideologically segregated communication networks on Twitter and Facebook, demonstrating how both user choice and algorithmic curation contribute to echo chamber formation. Recent studies have expanded this approach across platforms and contexts, with \citep{xing_research_2022} examining polarization patterns on Weibo and \citep{yarchi_political_2021} cross-platform comparisons across Facebook, Twitter, and WhatsApp. Further contributions by \citep{jiang_political_2020} and \citep{recuero_using_2019} have enhanced our understanding of user roles and information flow patterns in polarized networks, particularly focusing on how specific users shape the dissemination of information and reinforce ideological divides through selective engagement.

\subsection{Opinion Dynamics Models}
The theoretical understanding of polarization has evolved through increasingly sophisticated mathematical frameworks that attempt to capture the mechanisms of social influence and opinion formation. Beginning with simple consensus models and evolving toward complex multi-agent systems, these approaches have provided crucial insights into how individual interactions can lead to collective opinion patterns. While classical models focused on basic mechanisms like weighted averaging and confidence bounds, contemporary approaches have expanded to incorporate psychological factors, network effects, and, most recently, natural language interactions through large language models. This theoretical landscape can be organized into three main traditions: classical consensus models and bounded confidence frameworks, modern psychological extensions, and language-based approaches.

\subsubsection{Classical Models}
The theoretical understanding of polarization has evolved through several distinct families of mathematical models. The DeGroot model \citep{degroot_reaching_1974} introduced a weighted averaging approach where agents update beliefs by averaging their neighbors' opinions, inevitably leading to consensus under connected networks. The Friedkin-Johnson model \citep{friedkin_social_1990} extended this framework by introducing the concept of "stubborn" agents who maintain partial commitment to their initial beliefs, accounting for opinion persistence and explaining why consensus might not occur.

Another influential approach emerged with bounded confidence models, where agents only interact with others whose opinions fall within a certain threshold. The Deffuant model \citep{deffuant_mixing_2000} implemented this mechanism through pairwise interactions, while the Hegselmann-Krause model \citep{hegselmann_opinion_2002} applied a similar principle but with simultaneous updates where agents consider the average opinion of all neighbors within their confidence bound. Both models can produce opinion clustering and polarization under certain parameter regimes.

The voter model \citep{holley_ergodic_1975} represents a fundamentally different approach based on random imitation, where agents adopt the opinion of a randomly selected neighbor. This stochastic mechanism has connections to statistical physics and has been particularly useful for understanding consensus formation in binary opinion spaces. Meanwhile, the Sznajd model \citep{sznajd-weron_opinion_2000} proposed a unique social validation mechanism where neighboring agent pairs with the same opinion can jointly influence their neighbors, modeling conformity pressures through the principle that "united we stand."

Moving beyond one-dimensional opinions, the Axelrod model \citep{axelrod_agent-based_2006} addressed cultural dissemination through multiple discrete traits, showing how local convergence can coexist with global diversity. This multidimensional approach helped explain how distinct cultural groups might persist despite social influence.

\subsubsection{Modern Extensions}
Building on these foundations, modern models incorporate more realistic features of human behavior and social interaction. These advancements account for cognitive biases such as confirmation bias \citep{del_vicario_modeling_2017, allahverdyan_opinion_2014} and reactance effects \citep{flache_models_2017, cornacchia_polarization_2020}, providing explanations for the persistence of segregation in online environments. Research by \citep{baumann_modeling_2020} has advanced our understanding of how social ties evolve with shared beliefs, contributing to community polarization. \citep{sasahara_social_2021} proposed an agent-based model exploring how information diffusion, social influence, and network rewiring can lead to the emergence of echo chambers on social media. Further advancements include other nuanced models of cognitive processes and information environments, such as varying degrees of individual susceptibility to social influence \citep{amelkin_polar_2017} or the incorporation of opinion leaders and their impact on group polarization \citep{chen_characteristics_2016}. Moreover, studies by \citep{donkers_-sounding_2023, donkers_dual_2021, geschke_triple-filter_2019} have incorporated the crucial role of algorithmic amplification and media effects in reinforcing ideological divisions.

\subsubsection{LLM-based Approaches}
Recent advances in large language models (LLMs) have enabled a new generation of opinion dynamics simulations that incorporate natural language-based interactions. These LLM-based approaches can be categorized into several interrelated strands of research:

At the foundational level, \citep{ghaffarzadegan_generative_2024} introduced the concept of "generative agent-based modeling" (GABM), which couples mechanistic agent-based models with LLMs to enable language-based reasoning processes rather than fixed rules. Similarly, \citep{gurcan_llm_2024} explored architectural considerations for LLM-augmented agent-based simulations, emphasizing the importance of organizational structures in multi-agent systems. \citep{junprung_exploring_2024} demonstrated concrete implementations through small scenarios like two-agent bargaining and multi-agent role-playing, highlighting emergent properties such as strategic anchoring and the impact of memory constraints on simulations.

Several studies have focused specifically on how language-based agents form and sustain polarized communities. \citep{ohagi_polarization_2024} showed that LLM-driven agents can become polarized in echo-chamber conditions despite having only language-based updates, particularly when confirmation bias is explicitly induced. By contrast, \citep{chuang_simulating_2024} found that without such bias, LLM agents tend to converge toward scientifically correct views—suggesting these models may have an inherent preference for factually accurate content absent explicit biases. \citep{gao_social_2024} demonstrated that network phenomena like information diffusion and emotional contagion can be replicated through authentic text exchanges between LLM agents.

Understanding the mechanisms of opinion influence between LLM agents has been another active research direction. \citep{breum_persuasive_2024} proposed a "convincer–skeptic" paradigm revealing how human-like rhetorical strategies—emphasizing trust, facts, or emotional support—can shift another LLM agent's stance on topics like climate change. \citep{velarde_principles_2024} systematically investigated how LLM agents allocate "funding" across competing items, finding biases toward compromise or "safety" that lead to non-trivial final group outcomes.

Finally, \citep{gao_large_2024} offered an early survey of LLM-empowered agent-based methods, highlighting both new capabilities (richer language-based interactions) and key challenges (scaling, interpretability, alignment).

\subsection{Experimental Studies}

Despite substantial advances in observational and theoretical research on polarization, experimental studies with human participants remain comparatively scarce. This methodological imbalance is significant because experiments offer unique insights into causal mechanisms of opinion formation and polarization that neither observational data nor pure simulations can fully capture. While foundational social psychology experiments established core principles of social influence and group dynamics, contemporary research on digital polarization broadly falls into two distinct experimental traditions: (1) targeted intervention studies and (2) model calibration studies.

\subsubsection{Foundations in Social Psychology}
The experimental study of social influence and opinion formation has deep roots in social psychology. Foundational work by \citep{sherif_psychology_1936} on the autokinetic effect and \citep{asch_effects_1951} on conformity demonstrated how social pressure shapes individual judgment, even in simple perceptual tasks. These studies were complemented by theoretical frameworks such as cognitive dissonance theory \citep{festinger_theory_1957} and social identity theory \citep{tajfel_social_1971}, which respectively explained why exposure to contradictory information might lead to belief entrenchment and how even minimal group categorizations can trigger intergroup bias. Later work on groupthink \citep{janis_groupthink_1982} and motivated reasoning \citep{kunda_case_1990} further illuminated how group dynamics and cognitive biases affect information processing and opinion formation. While these classic studies were conducted in face-to-face settings, their insights into conformity pressure, social identity, cognitive consistency, and motivated reasoning remain crucial for understanding how digital environments—with their unique affordances for anonymous interaction and algorithmic curation—can amplify polarization tendencies.

\subsubsection{Targeted Intervention Studies}
Building on these foundational insights into social influence and group dynamics, a first strand of contemporary experimental research investigates specific causal drivers of online polarization. These studies examine targeted mechanisms of opinion change without necessarily embedding participants in comprehensive social media environments or incorporating formal opinion-update models.

Several studies focus on content exposure and its effects on perceived polarization. \citep{banks_polarizedfeeds_2021} experimentally demonstrate that exposure to negative tweets increases perceived ideological distance between political candidates, while \citep{wuestenenk_influence_2023} reveal how perceived platform affordances (e.g., anonymity, privacy) connect to uncivil political discourse and perceptions of polarization. Similarly, \citep{schieferdecker_affective_2024} trace the emergence and stability of affective polarization around COVID-19 policies using panel surveys with embedded experiments.

Other research examines how social identity and group dynamics shape polarization. \citep{wuestenenk_influence_2023} show that minority and majority ethnic group members respond differently to disagreement, revealing how social identity cues shape willingness to express dissent. \citep{groser_candidate_2019} confirm that extreme participants more frequently enter elections in a "citizen–candidate" game, thereby producing polarized outcomes. \citep{herne_influence_2019} explore how participants' political knowledge affects polarization under different mini-public deliberation formats, finding that knowledge effects vary depending on deliberative context.

A notable advancement in this category is the "information gerrymandering" study by \citep{stewart_information_2019}, in which participants repeatedly update their votes based on polling information from neighbors in a synthetic influence network. By manipulating network structure (including strategic placement of partisan "zealots"), the authors demonstrate how otherwise balanced groups can produce skewed outcomes. However, even this innovative approach relies on numeric voting signals rather than free-form communication.

While these targeted studies provide valuable insights into specific polarization mechanisms, they typically isolate one or two variables in controlled settings that abstract away much of the complexity of real social media environments. Participants are rarely embedded in a comprehensive, networked social platform where opinions, content, and interactions evolve organically over time.

\subsubsection{Model Calibration Studies}
A second experimental tradition seeks to bridge classical social psychological insights with formal mathematical models of opinion dynamics. These studies explicitly parameterize and validate opinion-update rules using controlled experimental data, measuring how participants revise their beliefs or judgments when exposed to information from others.

In these experiments, participants typically provide numeric judgments (e.g., estimating quantities or probabilities) and then revise their estimates after seeing reference points or "neighbor" guesses. \citep{chacoma_opinion_2015} measure how confidence levels affect the extent of opinion change under new information, extracting parameters for continuous-update dynamics. \citep{vande_kerckhove_modelling_2016} introduce repeated "judgment revision" tasks so participants iteratively see each other's estimates, permitting the estimation of "influenceability" weights for linear consensus models. Similarly, \citep{das_modeling_2014} investigate whether standard models (Voter, DeGroot) capture how participants update factual or taste-based responses when exposed to group opinions, ultimately proposing a "Biased Voter Model" that better accounts for certain conformity behaviors.

Adjacent to these user-focused calibration studies, recent research has validated and refined polarization models using large-scale empirical data from actual social platforms. \citep{phillips_high-dimensional_2023} propose multi-dimensional network approaches that capture real-world polarization patterns, while \citep{valensise_drivers_2023} and \citep{peralta_multidimensional_2024} develop methods to fit opinion dynamics models using social media interaction data.

While calibration studies explicitly link experimental data to formal opinion-update rules, the interactions they simulate are heavily constrained: subjects typically provide numeric inputs, see numeric references from others, and update accordingly, often in brief "rounds" that do not mimic real-time discussions. These designs effectively generate empirical parameters but rarely capture the unstructured language, emotional cues, or discursive styles that characterize real online exchanges.

\subsection{Bridging the Gaps: Our Integrative Approach}
Current approaches to studying online polarization face several key limitations. Opinion dynamics models, while mathematically precise, often reduce complex social interactions to simplified numeric updates. Recent LLM-based simulations, though capable of generating realistic language, typically rely on emergent conversation alone to drive opinion dynamics, lacking the theoretical grounding of classical models. Meanwhile, experimental studies either focus on targeted interventions without embedding participants in realistic social environments, or constrain interactions to numeric inputs that fail to capture the richness of natural discourse.

Our framework addresses these limitations through a novel integration of formal modeling and authentic human-agent interaction. At the modeling level, we preserve the mathematical precision of classical opinion dynamics while incorporating the linguistic complexity of LLM-based interactions. Rather than substituting traditional update rules with purely text-driven emergence, we maintain explicit mathematical equations for opinion updates and network evolution, ensuring theoretical interpretability. Simultaneously, our LLM agents generate and interpret messages in an organic, context-aware manner, allowing us to study how rhetorical strategies and emotional content influence opinion formation.

At the experimental level, we place human participants within a fully synthetic social platform that combines controlled mathematical models with genuine social media-style interactions. Unlike previous experiments that used simplified numeric signals or isolated interventions, our system creates a comprehensive social environment where participants encounter LLM-generated content through personalized feeds, engage in threaded discussions, and interact with artificial agents that mirror real users' ideological and stylistic traits. This design allows us to systematically control network structures and opinion dynamics while preserving the ecological validity of social media discourse.

This integration enables several novel research directions. First, we can examine how formal opinion-update rules interact with natural language persuasion, bridging mathematical and psychological theories of social influence. Second, we can study how network topology and content curation algorithms shape opinion dynamics in environments with realistic social discourse. Third, we can investigate how different rhetorical strategies and interaction patterns contribute to or mitigate polarization, while maintaining precise mathematical control over underlying opinion distributions.


