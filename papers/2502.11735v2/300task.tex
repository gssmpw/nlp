We introduce the \task task, which are two-step pipeline, 1) table retrieval and insight generation.
First, for the given question $q$ and the table corpus $C=\{t_i\}_{i=1}^N$, we retrieve top-$K$ most relevant tables for $q$ with a retriever $\mathcal{R}$ from $C$.
Denote top-$K$ most relevant tables for $q$ as $T=\{t_i\}_{i=1}^K$, and size of the table corpus as $N$.
This task can be formulated as $\mathcal{R}(q,C)=T$

Upon retrieving top-$K$ tables $T$, LLM-based reader $\mathcal{G}$ generate question-focused insight, utilizing the generative nature and the flexibility of the LLM.
The insight generation task can be modeled as $\sum_1^L\mathcal{G}(w_l|w_{0:l-1};q,T)$.

\task task is designed to extract deep insights in real-world scenarios involving tables.
There have been no prior attempts to address this problem, our \bench and \eval serve as a settle point for this effort.