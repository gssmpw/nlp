The output of text generation from LLMs may sometimes contain harmful, biased, or offensive content.
However, in our research, we assert that this risk is largely minimized.
The source tables and source natural language facts used in the construction of our \bench are derived from SPIDER~\citep{Yu2018SpiderAL} and Open-WikiTable~\citep{Kweon2023OpenWikiTableDF}, both of which are publicly available datasets licensed under the CC BY-SA 4.0, and these datasets have been annotated by human experts.
Additionally, we manually reviewed the generated texts and eliminate any toxic, offensive, or biased language to ensure the quality and fairness of the auto-generated contents. 
For human evaluation, two graduate students participated as annotators, receiving a pre-guide before taking part in evaluation and validation.
We advise the annotators to complete no more than 20 unit tasks per day, and the entire annotation process spanned approximately 30 days.