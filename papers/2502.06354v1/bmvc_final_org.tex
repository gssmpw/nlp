\documentclass{bmvc2k}

\usepackage[dvipdfmx]{graphicx}
\usepackage{amsfonts}
\usepackage{multirow}
\usepackage{bm} 
\makeatletter
\newcommand{\figcaption}[1]{\def\@captype{figure}\caption{#1}}
\newcommand{\tblcaption}[1]{\def\@captype{table}\caption{#1}}
\makeatother

%% Enter your paper number here for the review copy
% \bmvcreviewcopy{??}

\title{Diffusion Models with Guidance Based on Imaging Condition Information for Improvement of Photoacoustic Image Quality.}

% Enter the paper's authors in order
% \addauthor{Name}{email/homepage}{INSTITUTION_CODE}
\addauthor{Tatsuhiro Eguchi}{}{1}
\addauthor{Shunpei Takezaki}{}{1}
\addauthor{takayuki yagi}{yagi.takayuki@luxonus.jp}{2}
\addauthor{Ryoma Bise}{}{1}

% Enter the institutions
% \addinstitution{Name\\Address}
\addinstitution{
 Kyushu University\\
 Fukuoka, Japan
}
\addinstitution{
 luxonus, Inc.\\
}

\runninghead{Student, Prof, Collaborator}{}

% Any macro definitions you would like to include
% These are not defined in the style file, because they don't begin
% with \bmva, so they might conflict with the user's own macros.
% The \bmvaOneDot macro adds a full stop unless there is one in the
% text already.
\def\eg{\emph{e.g}\bmvaOneDot}
\def\Eg{\emph{E.g}\bmvaOneDot}
\def\etal{\emph{et al}\bmvaOneDot}

%-------------------------------------------------------------------------
% Document starts here
\begin{document}

\maketitle

\begin{abstract}
Photoacoustic(PA) imaging is a nondestructive and noninvasive technology for visualizing minute blood vessel structures in the body using ultrasonic sensors. In PA imaging, the image quality of a single shot image is poor, and it is necessary to improve the image quality by averaging many one-shot images. Therefore, imaging the entire subject requires high imaging costs.

In our study, we propose a method to improve the quality of PA images using a diffusion model in order to reduce the imaging cost. In our method, we improve the reverse diffusion process using sensor information of PA imaging and introduce a guidance method using imaging condition information to generate high-quality images.
\end{abstract}

%-------------------------------------------------------------------------
\section{Introduction}
\label{sec:intro}
Photoacoustic(PA) imaging is a technique that visualizes the fine vascular structures within the body. Ultrasonic signals generated from vessels are acquired by sensors and then converted into images. By illuminating blood vessels with laser light, which the blood absorbs, ultrasound is generated, and the resulting signals are captured by sensors and visualized. This technology is non-destructive and non-invasive and is used to understand vascular structures before surgery.

 The one of challenges with PA imaging is the time required to capture images. The range of signal acquisition by the sensor is very narrow, and each captured image (one shot image) only covers a local area (see Figure~\ref{fig:pa} left). Furthermore, one shot images often contain a lot of noise, and the foreground parts (blood vessels) are frequently partially missing (see Figure~\ref{fig:pa} center). Therefore, to create high-quality images, one shot images taken while moving the light source and sensor positions are averaged over overlapping imaging areas (see Figure~\ref{fig:pa} right).However, imaging the entire subject can be time-consuming, leading to higher imaging costs. This study aims to reduce the imaging costs of PA images by enhancing the quality of images from a small number of one shot images. To achieve this goal, we propose a method using a diffusion models guided by imaging condition information. The diffusion model, a recently popular image generation model, enables the creation of diverse, high-quality images and is used in various image processing tasks. In Image to Image tasks, diffusion models have been widely used and achieved high accuracy \cite{rahman2023ambiguous},\cite{saharia2022palette},\cite{saharia2022image}.

\begin{figure}[t]
    \centering
    \vspace{3mm}
    % \includegraphics[scale=0.3]{image/pa_image.pdf}
    % \vspace{2mm}
    \includegraphics[scale=0.65]{image/intro3.pdf}
    \caption{}
    \vspace{-4mm}
    \label{fig:pa}
\end{figure}

In this study, we use this diffusion model to generate high-quality PA images from one shot images that include noise and missing foreground elements. Specifically, we utilize the guidance that using multiple one shot images (multi-shots) rather than a single one shot image (single-shot) results in higher quality images. By using the vector from the noise estimated from the low-quality single-shot images to the noise estimated from the multi-shot images, we guide the reverse diffusion model towards higher quality.

Moreover, this method introduces the unique property of image averaging in PA imaging into the noise estimation of the diffusion model. Specifically, as shown in Figure~\ref{fig:sensor}, the laser light scatters inside the body and spreads in a circle around the irradiation position, weakening the signal strength as it moves away from this position. As shown in Figure~\ref{fig:sensor}, the relative positions of light irradiation in one shot images vary, leading to areas with clear blood vessels and areas with missing details (i.e., regions of differing quality).

Therefore, we propose a method that combines the estimated noise from each one shot image, considering the reliability of the signals based on the light irradiation positions. This allows for the estimation of high-quality images. We conducted experiments using actual PA images and confirmed the effectiveness of our method compared to traditional techniques.

\section{Related Work}
\label{sec:relatedwork}
\subsection{Supervised Denoising Methods}
Numerous methods for image noise reduction have been developed to date. Research by Zhang, Zamir, and others has proposed methods using CNNs and Vision Transformers. Furthermore, Luo and colleagues have achieved noise removal using diffusion models. All these methods focus on general images containing synthetic Gaussian noise, and to our knowledge, no studies have specifically targeted the quality improvement of photoacoustic images. Therefore, our approach, which effectively utilizes imaging condition information, is considered superior in improving the quality of photoacoustic images.

\subsection{Guidance Methods}

As a method for conditional image generation based on specific classes using diffusion models, Classifier Guidance\cite{dhariwal2021diffusion} can be mentioned. This technique mixes the classifier's gradients with the estimates of the diffusion model, enabling more stable image generation that reflects class information. In Classifier-free Guidance\cite{ho2021classifierfree}, instead of using classifier gradients, the estimates of the conditional and unconditional diffusion models are mixed based on the following equation:
\begin{equation}
    \tilde{\bm{\epsilon}}_\theta(\bm{x}_t,t,c) = (1+w)\bm{\epsilon}_\theta(\bm{x}_t,t,c) - w\bm{\epsilon}_\theta(\bm{x}_t,t,\phi),
    \label{eq:cfg}
\end{equation}
where $w$ represents the strength of guidance, and $\phi$ signifies the unconditional token used for unconditional generation. Adjusting $w$ achieves a trade-off between diversity in image generation and fidelity to class information. This method is not limited to class-conditional generation and has also been used in Text to Image tasks, based on textual information \cite{rombach2022high}. However, there are few studies applying such guidance in Image to Image tasks.

\begin{figure*}[t]
    \centering
    \includegraphics[scale=0.2, width=\linewidth]{image/proposed4.pdf}
    % \vspace{1mm}
    \caption{}
    % \vspace{1mm}
    \label{fig:proposed}
\end{figure*}


\section{Guidance-based diffusion model for improving photoacoustic image quality}
\subsection{Prepare a paired dataset (low and high-quality images)}

The objective of our method is to train an diffusion model-based image transfer from a low quality to high

In PA, 

Photoacoustic (PA) imaging harnesses the thermoacoustic effect, wherein objects such as blood vessels absorb short-pulsed near-infrared irradiation and subsequently emit ultrasonic waves. By detecting these thermoacoustic waves, it is possible to reconstruct the 3D structures of objects. This imaging technique offers non-invasive visualization of blood vessels in vivo with remarkable spatial resolution, eliminating the need for contrast media. To extend PA imaging to cover larger areas of the human body, multi-scan and registration systems have been developed. These systems scan local areas of the sample separately and then merge them. However, single-shot volume reconstruction by PA technology often suffers from significant noise due to sound and light scattering, as well as limitations in sensor layout (see Fig. 1). This study aims to enhance the quality of 3D volumes generated from these noisy shot volumes, making vessels clearly discernible.

The data acquisition speed of photoacoustic imaging is limited by the laser repetition rate
and the number of ultrasound sensors; the number of sampling is usually limited for the sake of real-time imaging and reducing the system cost. This insufficient
sampling usually causes streaking artifacts.


PA takes advantage of the thermoacoustic effect; that is, objects (i.e., blood vessels) absorb short-pulsed near-infrared irradiation and emit ultrasonic waves thereafter. 3D structures of objects can be reconstructed by sensing the thermoacoustic waves [2]. This technique can non-invasively visualize blood vessels in vivo with high spatial resolution without any contrast media. In order for PA imaging to capture entire portions of the human body, multi-scan and registration systems [3] have been developed that separately scan local areas of the sample and merge them. A single-shot volume reconstructed by PA technology usually suffers from severe noise caused by sound and light scattering and sensor layout limitations (Fig. 1). The goal of this study is to generate high-quality 3D volumes from these noisy shot volumes, in which vessels become clearly visible.


\subsection{Denoising Diffusion Probabilistic Models}
In this method, we utilize a model based on the framework of Denoising Diffusion Probabilistic Models (DDPM)~\cite{ho2020denoising}. In the diffusion process of DDPM, noise is progressively added to the original image $x_0$ from timestep $t=1$ to $T$ according to the following equation:
\begin{equation}
    \bm{x}_t = \sqrt{1-\beta_t}\bm{x}_{t-1} + \sqrt{\beta_t}\bm{\epsilon} ,
    \label{eq:q_ddpm}
\end{equation}
where $\beta_t$ indicates the intensity of the noise, and $\bm{\epsilon} \sim N(0,I)$ represents random noise. The reverse diffusion process is defined from $t=T$ to $1$ based on the following equation, utilizing a model $\bm{\epsilon_{\theta}}$ with parameters $\theta$:
\begin{equation}
    \bm{x}_{t-1} = \frac{1}{\sqrt{1-\beta_t}}(\bm{x}_t - \frac{\beta_t}{\sqrt{1-\alpha_t}}\bm{\epsilon}_\theta(\bm{x}_t,t)) + \sigma_t{\bm{z}},
    \label{eq:p_ddpm}
\end{equation}
where $\alpha_t=\prod^{t}{s=1}(1-\beta_s)$, $\sigma_t=\sqrt{\beta_t}$, and $\bm{z}$ is random noise following $N(0,I)$. For image transformation with DDPM, a conditional model $\bm{\epsilon}{\theta}(x_t,t,c)$, where the input image $c$ serves as the condition, is used. DDPM achieves image generation by estimating noise with the model $\bm{\epsilon}_\theta$. Therefore, the model is trained to minimize the following loss function:
\begin{equation}
    L = \mathbb{E}_{t,x_0,\bm{\epsilon}}[\parallel{\bm{\epsilon} - \bm{\epsilon}_\theta(\bm{x_t},t,c)}\parallel].
    \label{eq:loss_ddpm}
\end{equation}
Based on this DDPM framework, our method inputs one-shot PA images as the condition and generates corresponding high-quality images. The condition is attached and provided at the input layer of the network.

\subsection{Guidance}
In the generative process of diffusion models, guiding from lower to higher quality can potentially result in higher quality outputs. In our method, generation based solely on a single-shot is considered low quality, while generation based on multi-shots is regarded as high quality. We provide guidance to generate higher quality PA images.

The overview of our guidance method is shown in Figure~\ref{fig:proposed} left. First, we prepare two models $\bm{\epsilon}_{\theta}^{\mathrm{single}}$ and $\bm{\epsilon}_{\theta}^{\mathrm{multi}}$, each trained with single-shot and multi-shots as conditions, respectively. Both models generate corresponding high-quality images based on the one-shot images provided as conditions. However, given that the number of one-shot images as conditions differs, the model $\bm{\epsilon}_{\theta}^{\mathrm{multi}}$, which has more conditions, is considered capable of higher quality generation. This is because, due to the nature of PA imaging, even one-shot images captured at the same location hold different structural information; thus, inputting more one-shot images results in higher accuracy. Using the difference in outputs from models trained with single-shot and multi-shots, we guide towards further quality improvement.Specifically, in each timestep of the reverse diffusion process, instead of $\bm{\epsilon}_\theta(\bm{x}t,t,c)$, we use $\tilde{\epsilon}_{\theta}(\bm{x}_t,t,c)$ calculated based on the following:
\begin{equation}
    \tilde{\bm{\epsilon}}_\theta(\bm{x}_t,t,c) = (1+w)\bm{\epsilon}_{\theta}(\bm{x}_t,t,c) - w\bar{\bm{\epsilon}}_\theta(\bm{x}_t,t,c) ,
    \label{eq:cond_guidace}
\end{equation}

where $\bm{\epsilon}_{\theta}(\bm{x}t,t,c)$ is the output from $\bm{\epsilon}_{\theta}^{\mathrm{multi}}$, and $\bar{\bm{\epsilon}}_\theta(\bm{x}t,t,c)$ is the output obtained through the Noise Mix Process using $\bm{\epsilon}_{\theta}^{\mathrm{single}}$, described later. Additionally, $w$ is a hyperparameter indicating the strength of guidance. Through Equation~(\ref{eq:cond_guidace}), we can expand the difference between the consistent outputs of $\bm{\epsilon}_{\theta}^{\mathrm{single}}$ and $\bm{\epsilon}_{\theta}^{\mathrm{multi}}$ by $w$ and guide towards generating higher quality photoacoustic images.


\subsection{Noise Mix Process with imaging condition}
In the Noise Mix Process, to effectively utilize the structural information from multiple one-shot images, the outputs of $\bm{\epsilon}_{\theta}^{\mathrm{single}}$ based on each one-shot image are mixed. During this process, a confidence map based on the light irradiation position of each one-shot image is used to more accurately integrate the structural information of each one-shot image.

As mentioned above, in PA imaging, the reliability of the acquired signal changes depending on the distance from the position of light irradiation, and the light irradiation positions differ in each one-shot image. Therefore, a confidence map is created for each one-shot image based on the position of light irradiation. First, a heatmap based on a Gaussian distribution centered around the position of light irradiation is created (with values ranging from 0.2 to 1.0). From this heatmap, the overlapping parts of one-shot images during image averaging are used as the confidence map for each one-shot image.

In the Noise Mix Process, $\bm{\epsilon}{\theta}^{\mathrm{single}}$ is provided with each one-shot image individually, and $\bar{\bm{\epsilon}}\theta$ is calculated based on the following equation from the outputs corresponding to each one-shot image and the aforementioned confidence maps:
\begin{equation}
   \bar{\bm{\epsilon}}_\theta(\bm{x}_t,t,c) = \frac{1}{n}\sum^n_{i=0}{\bm{h_i} \odot \bm{\epsilon}_{\theta}^{\mathrm{single}}(\bm{x}_t,t,c_i)}.
    \label{eq:noise mix}
\end{equation}
where $\bm{\epsilon}_{\theta}(\bm{x}t,t,c_i)$ represents the output of $\bm{\epsilon}{\theta}^{\mathrm{single}}$ corresponding to each one-shot image $c_i$. Additionally, $h_i$ is the confidence map for the one-shot image $c_i$. By Equation~(\ref{eq:noise mix}), mixing the noise estimated with each one-shot image as a condition allows for the integration of their respective structural information. Furthermore, considering the confidence maps based on the light irradiation positions of each one-shot image enables more accurate completion of the foreground parts.

\begin{figure*}[t]
    \centering
    \includegraphics[scale=0.35]{image/pre_exp1.pdf}
    % \vspace{1mm}
    \caption{}
    \label{fig:proposed}
    \vspace{-5mm}
\end{figure*}

\section{Experiments}
\noindent\textbf{Dataset.} In our experiments, real PA images captured from one-shot images. We created a dataset where the input images are one-shot images, and the corresponding high-quality images enhanced by image averaging served as the teacher images. Since the goal of this study is to achieve high-quality results from a few one-shot images, we set the number of one-shot images used as inputs to three. The training data consisted of 3988 pairs, and the test data consisted of 907 pairs, both derived from PA images of different subjects.

\noindent\textbf{Implimentation Details.} we used a U-Net by Ho et al. \cite{ho2020denoising} as the diffusion model $\bm{\epsilon}_{\theta}$. The U-Net has the residual layer and self-attention to improve the representation performance of the model. The training was conducted over 300,000 iterations with a batch size of 16. The optimization algorithm used was Adam, with a learning rate of $1.0\times10^{-4}$. The total number of timesteps $T$ in sampling and the noise scheduler were the same as those in \cite{ho2020denoising}, with $T=1000$, $\beta_t = 10^{-4}$, and $\beta_T = 0.02$.

There is a known issue that excessively large guidance scales $w$ can degrade the precision of image generation \cite{ho2021denoising}, \cite{saharia2022photorealistic}. In the generative process of diffusion models, semantic information is formed in the early stages, while finer image details are developed towards the end \cite{choi2022perception}. Thus, especially towards the end, using a large guidance scale $w$ can lead to deviations from the training data distribution of the diffusion model, resulting in degraded generation quality. Therefore, our method sets an interval $[T,t_{guide}]$ where guidance is used with a predefined $w$, and $[t_{guide},0]$ where $w=0$. This $t_{guide}$ was tuned using validation data.

\noindent\textbf{Comparison Methods.} As the most naive approach, we used image averaging of three input images as the Baseline. For comparison, we employed a CNN-based method with U-Net \cite{Ronneberger2015} and DnCNN \cite{zhang2017beyond}, a Transformer-based method with Restormer \cite{zamir2022restormer}, and a standard diffusion model, DDPM \cite{ho2020denoising}. Here, DDPM refers to $\bm{\epsilon}_{\theta}^{\mathrm{multi}}$, given three one-shot images as conditions and performing conditional generation based solely on Equation~(\ref{eq:p_ddpm}).

\noindent\textbf{Evaluation Metrics.} To compare the accuracy of the outputs from each method, widely used image similarity metrics, PSNR and SSIM, were used.


\begin{table}[t]
    % \def\@captype{table}
    %   \makeatother
        \begin{minipage}[t]{0.5\textwidth}
          % \vspace{-3mm}
          \centering
          \caption{}
          \vspace{4mm}
          \label{table:t1}
          % \scalebox{1}{
          \begin{tabular}{llcc}
            \hline
            \multicolumn{2}{c}{Method}  & PSNR  &  SSIM   \\
            \hline \hline
            \multicolumn{2}{l}{Baseline}  & 20.63  & 0.3396 \\
            \multicolumn{2}{l}{U-Net\cite{Ronneberger2015}}  & 30.10  & 0.5055 \\
            \multicolumn{2}{l}{DnCNN\cite{zhang2017beyond}} & 30.14  & 0.5210 \\
            \multicolumn{2}{l}{Restormer\cite{zamir2022restormer}}  & 30.48  & 0.5247 \\
            \multicolumn{2}{l}{\bf{Ours}} & \bf{30.63}  & \bf{0.5468} \\
        
            
            \hline
          \end{tabular}
          % }
        \end{minipage}
        \begin{minipage}[t]{0.45\textwidth}
          % \vspace{-3mm}
          \centering
          \caption{}
          \vspace{4mm}
          \label{table:t1}
          \scalebox{1}{
          \begin{tabular}{llcc}
            \hline
            \multicolumn{2}{c}{Method}  & PSNR  &  SSIM   \\
            \hline \hline
            \multirow{2}{*}{$w=5$} & \bf{Ours}  &  30.25   & 0.5132 \\
                                   & \bf{w/o $h$}  &  30.27   & 0.5144 \\
            % \quad \quad \,\,\, w/o $h$  & 30.06   & 0.4883 \\
            \hline
            \multirow{2}{*}{$w=10$} & \bf{Ours}  & \bf{30.63}   & \bf{0.5468} \\
                                   & \bf{w/o $h$}  & 30.61   & 0.5456 \\
            % \quad \quad \,\,\, $w=10$  & \bf{30.60}   & \bf{0.5396} \\
            % \quad \quad \,\,\, w/o $h$  & 30.59   & 0.5381 \\
            \hline
            \multirow{2}{*}{$w=20$} & \bf{Ours}  & 30.29   & 0.5313 \\
                                   & \bf{w/o $h$}  & 30.25   & 0.5301 \\
            % \quad \quad \,\,\, $w=20$  & 30.11   & 0.5338 \\
            % \quad \quad \,\,\, w/o $h$  & 29.88   & 0.5347 \\
            \hline
            \multirow{2}{*}{$w=30$} & \bf{Ours}  & 27.94   & 0.4611 \\
                                   & \bf{w/o $h$}  & 27.70   & 0.4573 \\
            % \quad \quad \,\,\, $w=30$  & 26.83   & 0.4476 \\
            % \quad \quad \,\,\, w/o $h$  & 26.69   & 0.4440 \\
        
            
            \hline
          \end{tabular}
          }
        \end{minipage}
\end{table}

\begin{figure}[h]
  \def\@captype{table}
  \begin{minipage}[c]{0.4\textwidth}
      \centering
      \vspace{-10mm}
      \tblcaption{}
      \vspace{4mm}
      \begin{tabular}{llcc}
            \hline
            \multicolumn{2}{c}{Method}  & PSNR  &  SSIM   \\
            \hline \hline 		
            \multicolumn{2}{l}{DDPM(one-shot×1)}  & 28.88  & 0.3889 \\
            \multicolumn{2}{l}{DDPM(one-shot×3)}  & 29.39  & 0.4159 \\
            \multicolumn{2}{l}{classifier-free-guidance}  & 29.38  & 0.5315 \\
            \multicolumn{2}{l}{Ours w/o Noise Mix Process}  & 30.48  & 0.5247 \\
            \multicolumn{2}{l}{\bf{Ours}} & \bf{30.63}  & \bf{0.5468} \\
        
            
            \hline
        \end{tabular}
    \label{左側の表へのラベル}
  \end{minipage}
  % \hfill
  \begin{minipage}[c]{0.75\textwidth}
    \centering
    \vspace{3mm}
    \includegraphics[scale=0.35]{image/cfg-ours1.pdf}
    % \vspace{1mm}
    \vspace{-5mm}
    \caption{}
    \label{fig:proposed}
  \end{minipage}
\end{figure}


\subsection{Correlation with Confidence Maps}
First, we conducted preliminary experiments to quantitatively verify the characteristic that the clarity of the foreground parts (blood vessels) changes depending on the distance from the light irradiation position in each shot image. 

The figure shows the relationship between the SSIM values in a local area (window size 50×50) of the output results of DDPM with a single one-shot image as the condition and the ground truth in the test data, and the values of the corresponding confidence map in the same area.Initially, we created a scatter plot by plotting the average values of SSIM and the confidence map within each randomly set window across all test data. Subsequently, this scatter plot's horizontal axis was divided into 20 bins, and the average values of each point within those intervals were calculated and plotted in the figure.

From the figure, it can be seen that as the values in the confidence map within the window increase, so does the SSIM. This indicates that higher values in the confidence map allow for more accurate predictions, whereas lower values indicate areas where predictions are challenging.Therefore, when using multiple one-shot images as inputs, considering the corresponding confidence maps for each can be expected to enable more accurate predictions.

\subsection{Quantitative evaluation}
Table~\ref{table:t1} shows the average performance based on evaluation metrics for output results on test data for each method. From Table~\ref{table:t1}, it is observed that the proposed method with $w=10$ demonstrates the best results in both PSNR and SSIM. Among the comparison methods, the results from DDPM are notably low. This could be because, unlike other methods that learn to transform one-shot images into high-quality images, DDPM generates high-quality images from random noise based on the given one-shot images as conditions, thereby not effectively utilizing the structural information of the one-shot images. However, it can be said that a significant improvement in accuracy was achieved by introducing guidance based on imaging condition information in our method.

As an ablation study of our method, experiments were conducted by varying the guidance scale $w$ and in cases without using the confidence map for each $w$. First, comparing the results with varying $w$ in our method, a decline in accuracy is observed at $w=30$. It is confirmed that significantly increasing the guidance scale can deteriorate the generative results. Next, "w/o $h$" in Table~\ref{table:t1} means that in the Noise Mix Process of our method, the outputs based on each one-shot image are averaged without utilizing the corresponding confidence maps $h$. From Table~\ref{table:t1}, it is evident that using the confidence map $h$ results in higher PSNR values for each $w$, and although SSIM values are higher without the confidence map at $w=5,20$, using the confidence map at $w=10$ consistently shows the best results. This suggests that considering the confidence of each one-shot image contributes to improved accuracy.
\begin{figure*}[t]
    \begin{minipage}[t]{0.5\textwidth}
        \centering
        \vspace{-30mm}
        \includegraphics[scale=0.35]{image/wide-local-view.pdf}
        % \vspace{2mm}
        \caption{}
        \label{fig:proposed}
        \vspace{-5mm}
    \end{minipage}
    \begin{minipage}[t]{0.7\textwidth}
        \centering
        \includegraphics[scale=0.18]{image/local-view1.pdf}
        % \vspace{1mm}
        \caption{}
        \label{fig:proposed}
        \vspace{-5mm}
    \end{minipage}
\end{figure*}

\subsection{Qualitative evaluation}
Figure~\ref{fig:outputs} displays examples of Ground Truth, input one-shot images, and output results from each method. Initially, comparing the one-shot images and outputs from each method, it is evident that noise in the background parts contained in the one-shot images has been removed by all methods. Focusing on the parts enclosed in red frames, the comparison methods do not sufficiently complete the missing foreground parts, which are the blood vessels, whereas our method successfully completes these missing parts, resulting in clearer blood vessels compared to the comparison methods.

A qualitative assessment was conducted for different guidance scales $w$. Regarding the output results at $w=30$ in our method, as indicated by the blue curve, blood vessels are complemented in areas where, according to the Ground Truth, they should not exist. This suggests that excessively increasing the guidance scale can lead to over-detection of blood vessels, adversely affecting the generation results.

\section{Discussion and Conclusion}

Please number all of your sections and displayed equations.  It is
important for readers to be able to refer to any particular equation.  Just
because you didn't refer to it in the text doesn't mean some future reader
might not need to refer to it.  It is cumbersome to have to use
circumlocutions like ``the equation second from the top of page 3 column
1''.  (Note that the ruler will not be present in the final copy, so is not
an alternative to equation numbers).  All authors will benefit from reading
Mermin's description~\cite{Mermin89} of how to write mathematics.


\bibliography{egbib}
\end{document}
