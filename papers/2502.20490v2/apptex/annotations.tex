\section{Human Validation Process}
\label{sec:HumanValidationProcess}

We recruit human annotators from Prolific\footnote{\url{https://www.prolific.co/}} to validate the instances in our dataset. 
The annotators are first screened (i.e. a qualification task) to ensure that they can provide high-quality annotations 
and then are invited to the main annotation task. 

\subsection{Screening Process}
\label{appendix:screening}
To ensure the quality of the annotations, 
we set up a screening process to select high-quality annotators.
The screening process aims to ensure that the annotators:
\begin{enumerate}
    \item Follow the instructions carefully,
    \item Understand the terminology used in the dataset,
    \item Can identify best actions and justifications, and
    \item Can write normative actions and justifications that fall within the context of the scene.
\end{enumerate}
We provide detailed instructions and examples to help the annotators understand the task.
Figure~\ref{fig:screening} shows the interface of the screening process.
We pay the annotators \$1.0 for screening. 
Out of 350 annotators who participated in the screening process, 
33\% passed the screening process and were invited to the main annotation task.

\subsection{Main Annotation Task}
\label{appendix:annotation}
In the main annotation task, 
the annotators are required to watch a video clip.
When the video clip ends, 
the annotators are presented with a set of AJTs and are asked to select the best AJT.
If they believe the best AJT is not present in the set,
they can write their own AJT.
The annotators are also asked to mark the AJTs as sensible or non-sensible.

To prevent any biases in the annotations,
the annotators can't change their selection of best AJT after watching the next scene.
Figures~\ref{fig:maintask-1} and~\ref{fig:maintask-2} show the interface of the main annotation task.

The annotators were paid \$0.40 for each completed annotation which translates to an hourly wage of \$18.95 
(median time to complete an annotation was 1:16 minutes).
In total, we collected 3095 annotations from 90 annotators.
The annotators were all based in the United States from diverse backgrounds.
Figure~\ref{fig:annotator_demographics} shows the demographics of the annotators.
Each annotator was allowed to complete up to 200 annotations. 
On average, each annotator completed 34 tasks.
Figure~\ref{fig:tasks_completed} shows the number of tasks completed by annotators.
The annotations were randomly reviewed by the authors to ensure the quality of the annotations.

\begin{figure}
    \centering
    \includegraphics[width=0.5\textwidth]{figures/eth_pie.pdf}
    \caption{Demographics of the annotators. More than half (58\%) of the annotators are White.
    \label{fig:annotator_demographics}}
\end{figure}

\begin{figure}
    \centering
    \includegraphics[width=0.5\textwidth]{figures/tasks_completed.pdf}
    \caption{Number of tasks completed by annotators. 
    Most annotators completed fewer than 25 tasks.
    \label{fig:tasks_completed}}
\end{figure}







\begin{figure*}
    \centering
    \includegraphics[width=0.6\textwidth]{figures/screen1.png}
    \includegraphics[width=0.6\textwidth]{figures/screen2.png}
    \includegraphics[width=0.6\textwidth]{figures/screen3.png}
    \includegraphics[width=0.6\textwidth]{figures/screen4.png}
    \caption{The screening interface.\label{fig:screening}}
\end{figure*}

\begin{figure*}
    \centering
    \includegraphics[width=0.6\textwidth]{figures/main1.png}
    \includegraphics[width=0.6\textwidth]{figures/main2.png}
    \includegraphics[width=0.6\textwidth]{figures/main3.png}
    \caption{Part 1 of the screening interface: instructions and video clip.
    \label{fig:maintask-1}}
\end{figure*}
\begin{figure*}
    \centering
    \includegraphics[width=0.6\textwidth]{figures/main4.png}
    \includegraphics[width=0.6\textwidth]{figures/main5.png}
    \includegraphics[width=0.6\textwidth]{figures/main6.png}
    \caption{Part 2 of the screening interface: AJTs and the next scene.
    \label{fig:maintask-2}}
\end{figure*}
