
\begin{figure}
    \centering
    \includegraphics[width=\linewidth]{figures/normthinker.pdf}
    \caption{Retrieval-augmented generation pipeline.}
    \label{fig:normthinker}
    \vspace{-10pt}
\end{figure}
\section{Augmenting Normative Reasoning with Retrieval over \dataset{}}
In this section, we answer RQ3, and evaluate whether \dataset{} can be directly applied to augment normative reasoning in VLMs. 
% As incorrect norm sensibility understanding and norm prioritization are the primary causes for norm reasoning failures (Figure \ref{fig:fail}), we propose performing retrieval over the context present in \dataset{}, a strategy we call \normthinker{}, to guide VLMs in making contextually-grounded normative decisions.
Recall that incorrect norm sensibility understanding and norm prioritization are the primary causes of norm reasoning failures (Figure \ref{fig:fail}). Therefore, we propose performing retrieval over the context present in \dataset{}, a strategy we call \normthinker{}, to guide VLMs in making contextually-grounded normative decisions.
% As incorrect norm sensibility understanding and norm prioritization are the primary causes for norm reasoning failures (Figure \ref{fig:fail}), we propose performing retrieval over the context present in \dataset{}, a strategy we call \normthinker{}, to guide the VLMs to make contextually-grounded normative decisions.


% To validate this approach, we study the performance improvement of \normthinker{} using GPT-4o as a base model.

\subsection{\dataset{} RAG Approach}
Existing VLMs parse context robustly, but fail to retrieve and apply correct norms from the context. Thus, intuitively, given the strong context-sensitivity of norms, a tractable approach would be to guide VLMs towards the correct norms for a given context, once the context is extracted by that VLM. Retrieval-Augmented Generation (RAG) \cite{lewis2020retrieval} enables us to do this---by leveraging the VLMs where they are most performant (i.e., as a visual context parser),
% ,\footnote{i.e. as a visual context parser} 
this simplifies the task of deeper normative reasoning by providing contextually-grounded norm examples that the VLM can use as a many-shot example. 
The retrieval pipeline is shown in Figure \ref{fig:normthinker}; further details on the pipeline are provided in Appendix~\ref{appendix:indexing}.

%\dataset{} is well-suited as a source in this method, as its diversity of context and basis in human consensus means th 

\subsection{\dataset{}-Enhanced Results}
To fairly test the utility of \dataset{} on new data, we curate an out-of-domain test dataset based on egocentric robotic assistant footage \cite{zhu2024siat}, selected as its context and embodiment are orthogonal to those seen in Ego4D. Actions and justifications are manually generated to be highly challenging, with baseline GPT-4o scoring 18.2\%.\footnote{11 samples were selected from 100 candidate samples, from which 11 datapoints were generated to maximize the diversity of actions and contexts represented. While this is a sufficient number for the purposes of this example, future work should target a wider range of embodiments.} Using retrieval across \dataset{}, we demonstrate improvement relative to the best non-RAG model and base GPT-4o on unseen in-domain tasks, obtaining an \dataset{} bench 9.4\% better than base GPT-4o, and 7.9\% better than randomized retrieval across \dataset{}, as shown in Table~\ref{tab:normthinker1}.

%By contrast, \normthinker{} exhibits a notable improvement in normative reasoning, as shown in Table \ref{tab:normthinker}. % , resulting in enhanced performance. 

%However, it still demonstrates a significant performance gap compared to human reasoning.
\begin{table}
\centering
\input{tables/normthinker.tex}
\caption{Results with \normthinker{} on ego-centric robotics videos, n=11. }
\label{tab:normthinker}
\end{table}

\begin{table}
\centering
\input{tables/normthinker_id.tex}
\caption{Results with \normthinker{} on held-out instances in \dataset{}.} 
\label{tab:normthinker1}
\end{table}

% One example \normthinker{} in action is illustrated in Figure~\ref{fig:normthinker_example}. In the case of unenriched inference on the example \dataset{} task, GPT-4o correctly selects the action but arrives at incorrect reasoning, concluding that one should play games with friends after finishing a meal. In contrast, with \normthinker{}, the top retrieved datapoint, which depicts a similar cleanup process following a game, provides an in-context example that contextualizes tidying up as a sign of respect as the most normative action in this class of context, enabling GPT-4o to rethink and select the correct justification: "help with cleanup."

% \begin{figure*}
%     \centering
%     \includegraphics[width=\linewidth]{img/normthinker_example.jpg}
%     \caption{An example from \normthinker{} illustrating how retrieved data points aid normative reasoning. The correct answers are underlined. Without the reference video and justification, GPT 4o selects the correct action but provides incorrect reasoning. With the retrieved data pointâ€”depicting a similar cleanup process, GPT 4o selects the correct justification: "help with cleanup."}

%     \label{fig:normthinker_example}
% \end{figure*}
