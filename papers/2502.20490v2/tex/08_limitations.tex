\section*{Limitations}
While multiple rounds of filtering are applied to ensure diversity in ~\dataset{} video clips, all video clips in ~\dataset{} are exclusively from Ego4D, which may reflect inherent distribution biases within Ego4D. Expanding the benchmark to include a broader range of video sources, including exocentric videos, would improve the generalization of the benchmark.

Another limitation is that the current evaluation scheme treats videos as sequences of frames without incorporating audio information, which limits model performance on tasks that rely heavily on auditory cues. Integrating the audio modality in future work would provide a more comprehensive assessment of the normative reasoning abilities of vision-language models.

% , as well as more comprehensively represent the ranges of embodiments that agents might take.

% Another limitation is that the current evaluation treats videos as sequences of frames without incorporating audio information---this is a fundamental limitation of the current vision-language models; it was determined that testing on a wider, more representative range of models without access to audio was a worthwhile compromise to capture SOTA model performance. Integrating the audio modality, either natively or through an audio-to-text encoder, would provide a more comprehensive assessment of vision-language models, particularly for tasks and norms that rely on auditory cues.

% \yicheng{ego vs exo centric videos are discussed in paragraph 1 I think}
% \hao{Looks good, just add some backlink references to the section where we did the filtering}
Finally, though the generation and filtering pipeline (\S\ref{sec:benchmark_generation_pipeline}) is robust in generating high-difficulty and high-quality \dataset{} tasks, we find that Ego4D contains many action annotation errors that could lead to the generation of ambiguous or incorrect MCQs. We thus carefully conduct additional manual multi-stage filtering processes and human validation to remove or rectify low-quality samples from ~\dataset{} to mitigate the impact of this issue.