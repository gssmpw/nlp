\section{Introduction}
\label{sec:introduction}
Humans have a long history of expecting AI to adhere to human-defined \emph{norms} \citep{asimov1985caves,john2006android,chiang2010lifecycle,chambers2016closed}. This is because norms are fundamental to human \emph{interactions and cooperation} \citep{fehr2004social,chudek2011culture}, with even children being able to operate within a norm-regulated environment \citep{schmidt2016young,koster2024preverbal}. Given the importance of norms to behavior moderation, and the popularity of model-driven embodied agents, we ask whether \textbf{Vision-Language Models (VLMs) can understand norms grounded in the physical world and make normative decisions similar to those of humans}? The answer to this question is critical if VLM-based agents are expected to collaborate and coordinate with humans \citep{chang2024partnr,zhou2024sotopia}, safely \citep{zhou2024multimodal} and responsibly \citep{he2024emerged}.

Current VLMs are neither optimized for, nor evaluated on, physical-normative reasoning. While they excel at mathematical, scientific, and abstract reasoning \citep{jaech2024openai, guo2025deepseek, chollet2024arc}, they are unlikely to have the same strong understanding of human normative dynamics in the physical world. This is because, unlike humans, who learn norms through active feedback in real-world and trial-and-error exploration \citep{zhou2024sotopia}, vision-language models obtain knowledge mainly by learning from web-crawled data \citep{li2024multimodal}, where physically-grounded normative reasoning is sparse \citep{ziems-etal-2023-normbank}. 
%In contrast to the human acquisition of norms, vision-language models \citep{li2024multimodal} obtain knowledge mainly by learning from web-crawled data.
%However, normative reasoning is often sparse in web data \citep{ziems-etal-2023-normbank},
%and this learning objective lacks trial-and-error experience in realistic scenarios with active feedback on norm violations \citep{zhou2024sotopia}.
%Reasoning models often focus on divergent targets from normative reasoning, such as mathematical, scientific, and abstract reasoning \citep{jaech2024openai, guo2025deepseek, chollet2024arc}.
%The lack of normative reasoning results in safety \citep{zhou2024multimodal} and privacy risks \citep{he2024emerged}, and collaboration and coordination failures \citep{chang2024partnr,zhou2024sotopia} of agents.

To comprehensively measure VLM normative reasoning ability,
we introduce \dataset{},\footnote{\textbf{Ego}-centric \textbf{Norm} \textbf{i}n \textbf{a}ction} a challenging QA benchmark that is physically grounded in 1k egocentric social interaction clips from Ego4D~\cite{grauman2022ego4dworld3000hours}. \dataset{} spans 100 distinct settings across a wide range of activities, cultures, and interactions. 

Unlike similarly visually-grounded spatiotemporal, predictive, or causal reasoning benchmarks \citep{chandrasegaran2024hourvideo1hourvideolanguageunderstanding,zellers2019recognition}, \dataset{} evaluates models' ability to reason about what \textit{should} be done under social norms. \dataset{} highlights cases where these norm-related objectives conflict---the richest arena for evaluating normative decision-making. 

%For example, Figure~\ref{fig:teaser} demonstrates the tension between three objectives: safety, politeness, and cooperative utility.

%Most existing visual-language benchmarks focus on the detection of objects \citep{athar2023burst}, activities \citep{caba2015activitynet, xiao2021nextqanextphasequestionansweringexplaining}, and events \citep{oh2011large, fu2024ui}. VCR ~\cite{zellers2019recognition} and HourVideo~\cite{chandrasegaran2024hourvideo1hourvideolanguageunderstanding} contain questions similar to ours, but they focus on why an event happens or what will happen in the future. However, \dataset{} focuses on what \emph{should} be done and why it should be done. This setup emphasizes the decision-making aspect of normative reasoning, which underpins the real-world application of embodied agents. 

As shown in Figure~\ref{fig:teaser}, every egocentric video clip in \dataset{} is associated with a set of five candidate actions that the agent could take next. Only one of these actions is marked by humans as the \textit{most appropriate}, but the other actions may also be plausible, and each will reflect a different combination of normative objectives (for more details, see \S\ref{sec:benchmark_generation_pipeline}). The candidate actions are associated with three related reasoning tasks: (1) classify the most appropriate action (2) classify the most fitting justification for that action, and (3) identify which of the candidate actions are contextually plausible.
%Each instance in \dataset{} consists of an input video and three multiple choice question (MCQ)-based reasoning tasks (\S\ref{sec:task_definition}). The first tests the normative action prediction by the models by providing four challenging choices, each of which is normative under certain norm categories, and a none-of-the-above choice; the second tests whether the model can select the correct reasoning for its choice, and the third evaluates whether the model can identify all sensible actions. 

%Two main challenges exist when it comes to creating a benchmark for normative reasoning. First, normative behavior is context-dependent---what is appropriate in one setting may not be in another, and subtle actions require precise annotation \cite{ziems-etal-2023-normbank}. Second, manually annotating thousands of diverse egocentric videos is time-consuming and inconsistent. To fill these gaps, we construct a challenging and widely-scoped question-answering benchmark (\S\ref{sec:benchmark_generation_pipeline}) which consists of egocentric videos with diverse activities and norm distribution (\S\ref{sec:stats}), by introducing a pipeline that jointly leverages proposals from vision-language models and verification through human effort.

\dataset{} allows us to thoroughly investigate three research questions:
\vspace{-2pt}
\begin{itemize}
    \itemsep-0.3em 
    \item \textbf{RQ1} Can VLMs make normative decisions that agree with human consensus?
    \item \textbf{RQ2} If VLMs do not agree, is this due to failures in perception (e.g., object recognition) or gaps in normative reasoning?
    \item \textbf{RQ3} Can we use \dataset{} to improve the normative reasoning of VLMs?
\end{itemize}

% \noindent\textbf{RQ1} Can state-of-the-art (SOTA) vision-language models make normative decisions similar to human consensus? 

% \noindent\textbf{RQ2} Are errors mostly due to perception failures (objects or action understanding), or normative reasoning on top of perception? 

% \noindent\textbf{RQ3} Can we leverage human-annotated normative reasoning data for normative decision-making in novel scenarios? 

\begin{figure*}[!h]
  \centering
  \includegraphics[width=\linewidth]{figures/egonormia_taxonomy.pdf}
  \caption{Examples of videos and corresponding norms under each taxonomy category in \dataset{}.}
  \label{fig:taxonomy}
\end{figure*}


First, we find that VLMs that retain near-human performance on other reasoning datasets like EgoSchema \citep{mangalam2023egoschemadiagnosticbenchmarklongform} fall far behind human performance on \dataset{} ($45.3\%$ vs $92.4\%$). Second, we determine that this failure is primarily due to gaps in normative reasoning ($>70\%$ of errors), rather than perception ($<25\%$ of errors). Third, we find that a naive retrieval-based generation approach can improve performance by 10\% on held-out \dataset{} examples, and by nearly double on out-of-domain robotics videos, demonstrating the direct advantages of the application of \dataset{}.
%A deeper dive into the results shows that (1) Generating a detailed description of the video first and then doing text-only reasoning can achieve a similar performance (41.5\%), and (2) most errors (>70\%) come from normative reasoning and prioritization, while perception errors only take up 20-25\%. With this insight, we design a new method, \textbf{NormThinker}, which retrieves relevant videos and corresponding norms from the \dataset{} dataset by indexing with generated description and uses retrieved data as examples in context. We found that this method results in a 10\% improvement on held-out examples and nearly doubles the performance on out-of-domain robotics videos.

% Grounded reasoning is a canonical challenge in embodied AI
% As the capabil  rove,  . Much work has been done on parsing and planning around mechanical constraints and the physical environment (insert work on RL task planning, understanding of object properties, or RL obstacle avoidance), 

% Embodied AI systems need to understand the constraints of their environment to bound the space of their actions and perform tasks safely. Many of these constraints are purely mechanical , but the class of constraints derived from human expectation and preference, or \emph{Physical-social norms (PSNs)}, present equally important rules for embodied agents.

% PSN-derived reasoning is present in every human action and interaction in the physical world - the manner in which a person lifts a child, opens a door, or hands over an object is just as much governed by norms of behavior as it is by mechanical affordances. This reasoning can be unconscious or automatic, done because one particular way is "right", and in other cases training and instruction is needed before a person learns the rules of a given situation.

% Humans often follow PSNs and sometimes violate them in a certain context. Recently, foundation models have been widely adopted in embodied agents and robots that have the potential to interact with humans in daily life~\cite{song2024vlm, gao2024physically}. However, despite their impressive capabilities, little attention has been paid to whether foundation models can truly comprehend PSN. The lack of benchmarking for PSN understanding presents a critical challenge in assessing the potential risks and capabilities when interacting with humans in the physical world. 

% In this work, we address this gap by proposing a new dataset PSN through an efficient data annotation process that leverages both proposals from foundation models and verification through human effort. We then use this dataset to create a challenge question-answering benchmark: \textbf{PSN-Bench}, including 2,000 ego-centric videos annotated with the primary and all relevant PSNs, as well as the normative behaviors for each PSN. Together, we acquired ~2000 norms in seven categories. Figure~\ref{fig:teaser} shows the norm categories and the videos in which the behavior follows or violates the norms. 

% \begin{figure*}[ht]
%     \begin{tcolorbox}[colframe=black, colback=gray!10, title=Norm Example, width=\textwidth]
%         \centering
%         \includegraphics[width=\textwidth]{img/example.png}
%         \captionof{figure}{Video snippet}
%         \label{fig:test}
        
%         \raggedright
%         \textbf{\textcolor{green!50!black}{Behavior Following Norm:}} 
%         \textcolor{green!50!black}{Walk briskly, maintaining a consistent pace and spacing with the group as they depart, to efficiently reach the next destination.}
        
%         [\textcolor{green!50!black}{\ding{51}}] \textbf{safety} \hspace{2em}
%         [\textcolor{green!50!black}{\ding{51}}] \textbf{proxemics} \hspace{2em}
%         [\,\,\,\,\,] \textbf{politeness} \hspace{2em}
%         [\,\,\,\,\,] \textbf{privacy} \hspace{2em}
        
%         [\,\,\,\,\,] \textbf{cooperation} \hspace{2em}
%         [\,\,\,\,\,] \textbf{coordination} \hspace{2em}
%         [\,\,\,\,\,] \textbf{communication}
        

%         \vspace{1em}

%         \textbf{\textcolor{red!80!black}{Behavior not Following Norm:}} 
%         \textcolor{red!80!black}{Turn slightly towards and acknowledge each person in the group with a nod or brief eye contact as the group walks away, to show respect and maintain social harmony.}

%         [\textcolor{green!50!black}{\ding{51}}] \textbf{safety} \hspace{2em}
%         [\textcolor{red}{\ding{55}}] \textbf{proxemics} \hspace{2em}
%         [\,\,\,\,\,] \textbf{politeness} \hspace{2em}
%         [\,\,\,\,\,] \textbf{privacy} \hspace{2em}
        
%         [\,\,\,\,\,] \textbf{cooperation} \hspace{2em}
%         [\,\,\,\,\,] \textbf{coordination} \hspace{2em}
%         [\,\,\,\,\,] \textbf{communication}
        
%     \end{tcolorbox}
% \end{figure*}

% \begin{figure*}
%     \includegraphics[width=\linewidth]{figures/teaser.pdf}
%     \caption{Video samples and the relevant norm categories. Will update to high resolution version once finalized.}
%     \vspace{-20pt}
% \end{figure*}




%These benchmarks test advanced inference abilities effectively. However, as VLMs are increasingly integrated into daily life, pure cognitive reasoning alone is insufficient. Social awareness is becoming a critical requirement. In response, PSN-Bench is designed to extend beyond perception and cognition, and evaluate a model's capacity to reason about the social norms underlying human actions.


% Social norm is a very broad topic and scholars from a
% variety of disciplines have explored the central idea behind norms in different perspectives~\cite{chung2016social}. In health education, for instance, social norms have been used to address issues such as heavy alcohol consumption ~\cite{perkins1986perceiving}, while economists focus on how social norms shape market behavior and rational decision-making ~\cite{akerlof1976economics}. A clear definition and taxonomy are essential for the study of physical social norms (PSN). To advance the understanding of PSN, we introduce a novel taxonomy that captures the multiple roles PSN play in everyday social interactions. These roles are categorized into two main dimensions: utility-based and non-utility-based. Utility-based dimensions focus on functional aspects of norms that facilitate goal-oriented behaviors, such as collaboration, coordination, and communication. Non-utility-based dimensions, on the other hand, regulate behavior beyond functionality, emphasizing safety, proxemics, politeness, and privacy to ensure respectful and smooth social conduct. Detailed examples and further explanations of these dimensions will be provided in section~\ref{sec:PSN}.


% We meticulously curated this dataset by first leveraging the Gemini-2 model to generate diverse hypotheses of potential social norms in each video. Subsequently, human experts validated these norms to select the most relevant and significant ones for each scenario. This dataset serves as the first large-scale resource dedicated to studying physical social norms in video-based interactions. We also introduce a video question answering benchmark, which evaluates VLMs' ability to recognize and navigate PSN. Our benchmark includes multiple-choice questions (MCQ) that assess whether VLMs can correctly identify and understand social dynamics in given scenarios.

% The primary research questions we seek to address with this dataset and benchmark include: (1) How well do current VLMs understand and interpret physical social norms in video-based scenarios? (2) What are the strengths and limitations of current VLMs in the realm of PSN recognition and application? (3) Is the limitation because VLMs can not parse objects and recognize actions correctly?

% Our experimental findings reveal a stark reality: state-of-the-art models frequently fail at recognizing PSNs, even in cases that are trivial for humans. This gap underscores the urgent need to rethink AI development with social awareness at its core. Without proper PSN understanding, foundation models risk becoming not just ineffective but actively disruptive when deployed in human environments.

% Through PSN-Bench, we aim to catalyze research into norm-aware AI systems that can seamlessly integrate into social spaces—ensuring that the next generation of embodied agents not only see and act but also understand the unspoken rules that govern human life.

% Our experimental results reveal that VLMs exhibit a significantly weaker ability to recognize physical social norms compared to humans. While VLMs are generally proficient at object detection and action classification, their capacity to adhere to physical social norms in social interactions is limited. This highlights the need for further research to enhance VLMs' understanding and integration of these norms in real-world scenarios.
