


% \noindent {\textbf{Neural Fields.}} 
% 3d shape (\cite{chen2019learning}, \cite{park2019deepsdf}, \cite{mescheder2019occupancy})
% 3D scene reconstruction (NeRF\cite{mildenhall2021nerf}, ; \cite{niemeyer2021giraffe}),

% Neural Fields (NeFs) map coordinates to signals, providing a compact and flexible continuous data representation~\citep{sitzmann2020implicit, tancik2020fourier}. They are widely used for 3D object and scene modeling~\citep{chen2019learning, park2019deepsdf, mescheder2019occupancy, genova2020local, niemeyer2021giraffe}. NeRF~\citep{mildenhall2021nerf} learns neural radiance fields for view synthesis, mapping spatial coordinates to colors and densities via differentiable volumetric rendering. Extensions include Mip-NeRF~\citep{barron2021mip} for multiscale representations, TensoRF~\citep{chen2022tensorf} for low-rank tensor factorization, and NeuRBF~\citep{chen2023neurbf} for radial basis function aggregation. Unlike these methods, which rely on pre-defined structured information, we infer geometric bases to encode spatial structure.



%RBF-based works (\cite{ramasinghe2021learning}, \cite{ramasinghe2022beyond}, NeuRBF~\cite{chen2023neurbf}, 


\noindent {\textbf{Neural Fields (NeFs) and Generalization.}} Neural Fields (NeFs) map coordinates to signals, providing a compact and flexible continuous data representation~\citep{sitzmann2020implicit, tancik2020fourier}. They are widely used for 3D object and scene modeling~\citep{chen2019learning, park2019deepsdf, mescheder2019occupancy, genova2020local, niemeyer2021giraffe}. However, how to generalize to new scenes without retraining remains a problem. 
Many previous methods attempt to use meta-learning to achieve NeF generalization. Specifically, gradient-based meta-learning algorithms such as Model-Agnostic Meta Learning (MAML)~\citep{finn2017model} and Reptile~\citep{nichol2018first} have been used to adapt NeFs to unseen data samples in a few gradient steps~\citep{lee2021meta, sitzmann2020metasdf, tancik2021learned}. Another line of work uses HyperNet~\citep{Ha2016HyperNetworks} to predict modulation vectors for each data instance, scaling and shifting the activations in all layers of the shared MLP~\citep{mehta2021modulated, dupont2022data, dupont2022coin++}. Some methods use HyperNet to predict the weight matrix of NeF functions~\citep{dupont2021generative, zhang20233dshape2vecset}. Transformers~\citep{vaswani2017attention} have also been used as hypernetworks to predict column vectors in the weight matrix of MLP layers~\citep{chen2022transformers, dupont2022coin++}. In addition, \cite{reizenstein2021common,wang2022attention} use transformers specifically for NeRF. Such methods are deterministic and do not consider the uncertainty of a scene when only partially observed. Other approaches model NeRF from a probabilistic perspective~\citep{kosiorek2021nerf, hoffman2023probnerf, dupont2021generative, moreno2023laser,erkocc2023hyperdiffusion}. For instance, NeRF-VAE~\citep{kosiorek2021nerf} learns a distribution over radiance fields using latent scene representations based on VAE~\citep{kingma2013auto} with amortized inference. Normalizing flow~\citep{winkler2019learning} has also been used with variational inference to quantify uncertainty in NeRF representations~\citep{shen2022conditional, wei2023fg}. However, these methods do not consider potential structural information, such as the geometric characteristics of signals, which our approach explicitly models.



\noindent {\textbf{Neural Processes.}} Neural Processes (NPs)~\citep{garnelo2018neural} is a meta-learning framework that characterizes distributions over functions, enabling probabilistic inference, rapid adaptation to novel observations, and the capability to estimate uncertainties. This framework is divided into two classes of research. The first one concentrates on the marginal distribution of latent variables~\citep{garnelo2018neural}, whereas the second targets the conditional distributions of functions given a set of observations~\citep{garnelo2018conditional, gordon2019convolutional}. Typically, MLP is employed in Neural Processes methods. To improve this, Attentive Neural Processes (ANP)~\citep{kim2019attentive} integrate the attention mechanism to improve the representation of individual context points. Similarly, Transformer Neural Processes (TNP)~\citep{nguyen2022transformer} view each context point as a token and utilize transformer architecture to effectively approximate functions.
Additionally, the Versatile Neural Process (VNP)~\citep{guo2023versatile} employs attentive neural processes for neural field generalization but does not consider the information misalignment between the 2D context set and the 3D target points. The hierarchical structure in VNP is more sequential than global-to-local. Conversely, PONP~\citep{gu2023generalizable} is agnostic to neural-field specifics and concentrates on the neural process perspective. In this work, we consider a hierarchical neural process to model the structure information of the scene. 


