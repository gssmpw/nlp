% In conclusion, we propose Geometric Neural Processes (GeomNPs), a probabilistic neural fields generalization formulation, which is based on a set of posterior geometric bases. 

% which incorporates structure information into the inference of the INR function distribution and achieve generalized INR functions in different spatial levels. 


\label{sec:conclusion}
In this paper, we addressed the challenge of Neural Field (NeF) generalization, enabling models to rapidly adapt to new signals with limited observations. To achieve this, we proposed Geometric Neural Processes (\name{}), a probabilistic neural radiance field that explicitly captures uncertainty.  
By formulating neural field generalization in a probabilistic framework, \name{} incorporates uncertainty and infers NeF function distributions directly from sparse context images. To embed structural priors, we introduce geometric bases, which learn to provide structured spatial information. Additionally, our hierarchical neural process modeling leverages both global and local latent variables to parameterize NeFs effectively.  
In practice, \name{} extends to 1D, 2D, and 3D signal generalization, demonstrating its versatility across different modalities.

%\noindent{\textbf{Limitation \& Broader Impacts.}} The proposed method may become computationally intensive with more context images due to the increased number of Gaussian bases. We do not find potential obvious negative social impact.
