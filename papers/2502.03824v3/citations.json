[
  {
    "index": 0,
    "papers": [
      {
        "key": "lewis2020retrieval",
        "author": "Lewis, Patrick and Perez, Ethan and Piktus, Aleksandra and Petroni, Fabio and Karpukhin, Vladimir and Goyal, Naman and K{\\\"u}ttler, Heinrich and Lewis, Mike and Yih, Wen-tau and Rockt{\\\"a}schel, Tim and others",
        "title": "Retrieval-augmented generation for knowledge-intensive nlp tasks"
      }
    ]
  },
  {
    "index": 1,
    "papers": [
      {
        "key": "chen2017reading",
        "author": "Chen, Danqi and Fisch, Adam and Weston, Jason and Bordes, Antoine",
        "title": "Reading Wikipedia to Answer Open-Domain Questions"
      }
    ]
  },
  {
    "index": 2,
    "papers": [
      {
        "key": "robertson2009probabilistic",
        "author": "Robertson, Stephen and Zaragoza, Hugo and others",
        "title": "The probabilistic relevance framework: BM25 and beyond"
      }
    ]
  },
  {
    "index": 3,
    "papers": [
      {
        "key": "devlin2018bert",
        "author": "Devlin, Jacob",
        "title": "Bert: Pre-training of deep bidirectional transformers for language understanding"
      }
    ]
  },
  {
    "index": 4,
    "papers": [
      {
        "key": "karpukhin2020dense",
        "author": "Karpukhin, Vladimir and Oguz, Barlas and Min, Sewon and Lewis, Patrick and Wu, Ledell and Edunov, Sergey and Chen, Danqi and Yih, Wen-tau",
        "title": "Dense Passage Retrieval for Open-Domain Question Answering"
      },
      {
        "key": "gao2022unsupervised",
        "author": "Gao, Luyu and Callan, Jamie",
        "title": "Unsupervised Corpus Aware Language Model Pre-training for Dense Passage Retrieval"
      },
      {
        "key": "xiong2021approximate",
        "author": "Lee Xiong and Chenyan Xiong and Ye Li and Kwok-Fung Tang and Jialin Liu and Paul N. Bennett and Junaid Ahmed and Arnold Overwijk",
        "title": "Approximate Nearest Neighbor Negative Contrastive Learning for Dense Text Retrieval"
      }
    ]
  },
  {
    "index": 5,
    "papers": [
      {
        "key": "qu2021rocketqa",
        "author": "Qu, Yingqi and Ding, Yuchen and Liu, Jing and Liu, Kai and Ren, Ruiyang and Zhao, Wayne Xin and Dong, Daxiang and Wu, Hua and Wang, Haifeng",
        "title": "RocketQA: An Optimized Training Approach to Dense Passage Retrieval for Open-Domain Question Answering"
      }
    ]
  },
  {
    "index": 6,
    "papers": [
      {
        "key": "izacard2021unsupervised",
        "author": "Izacard, Gautier and Caron, Mathilde and Hosseini, Lucas and Riedel, Sebastian and Bojanowski, Piotr and Joulin, Armand and Grave, Edouard",
        "title": "Unsupervised dense information retrieval with contrastive learning"
      },
      {
        "key": "wang2022text",
        "author": "Wang, Liang and Yang, Nan and Huang, Xiaolong and Jiao, Binxing and Yang, Linjun and Jiang, Daxin and Majumder, Rangan and Wei, Furu",
        "title": "Text embeddings by weakly-supervised contrastive pre-training"
      }
    ]
  },
  {
    "index": 7,
    "papers": [
      {
        "key": "chen2024bge",
        "author": "Chen, Jianlv and Xiao, Shitao and Zhang, Peitian and Luo, Kun and Lian, Defu and Liu, Zheng",
        "title": "Bge m3-embedding: Multi-lingual, multi-functionality, multi-granularity text embeddings through self-knowledge distillation"
      }
    ]
  },
  {
    "index": 8,
    "papers": [
      {
        "key": "shi2024replug",
        "author": "Shi, Weijia and Min, Sewon and Yasunaga, Michihiro and Seo, Minjoon and James, Richard and Lewis, Mike and Zettlemoyer, Luke and Yih, Wen-tau",
        "title": "REPLUG: Retrieval-Augmented Black-Box Language Models"
      }
    ]
  },
  {
    "index": 9,
    "papers": [
      {
        "key": "eldan2023tinystories",
        "author": "Eldan, Ronen and Li, Yuanzhi",
        "title": "Tinystories: How small can language models be and still speak coherent english?"
      }
    ]
  },
  {
    "index": 10,
    "papers": [
      {
        "key": "achiam2023gpt",
        "author": "Achiam, Josh and Adler, Steven and Agarwal, Sandhini and Ahmad, Lama and Akkaya, Ilge and Aleman, Florencia Leoni and Almeida, Diogo and Altenschmidt, Janko and Altman, Sam and Anadkat, Shyamal and others",
        "title": "Gpt-4 technical report"
      }
    ]
  },
  {
    "index": 11,
    "papers": [
      {
        "key": "eldan2023tinystories",
        "author": "Eldan, Ronen and Li, Yuanzhi",
        "title": "Tinystories: How small can language models be and still speak coherent english?"
      }
    ]
  },
  {
    "index": 12,
    "papers": [
      {
        "key": "gunasekar2023textbooks",
        "author": "Gunasekar, Suriya and Zhang, Yi and Aneja, Jyoti and Mendes, Caio C{\\'e}sar Teodoro and Del Giorno, Allie and Gopi, Sivakanth and Javaheripi, Mojan and Kauffmann, Piero and de Rosa, Gustavo and Saarikivi, Olli and others",
        "title": "Textbooks are all you need"
      }
    ]
  },
  {
    "index": 13,
    "papers": [
      {
        "key": "li2023textbooks",
        "author": "Li, Yuanzhi and Bubeck, S{\\'e}bastien and Eldan, Ronen and Del Giorno, Allie and Gunasekar, Suriya and Lee, Yin Tat",
        "title": "Textbooks are all you need ii: phi-1.5 technical report"
      },
      {
        "key": "abdin2024phi",
        "author": "Abdin, Marah and Jacobs, Sam Ade and Awan, Ammar Ahmad and Aneja, Jyoti and Awadallah, Ahmed and Awadalla, Hany and Bach, Nguyen and Bahree, Amit and Bakhtiari, Arash and Behl, Harkirat and others",
        "title": "Phi-3 technical report: A highly capable language model locally on your phone"
      }
    ]
  },
  {
    "index": 14,
    "papers": [
      {
        "key": "wang2023improving",
        "author": "Wang, Liang and Yang, Nan and Huang, Xiaolong and Yang, Linjun and Majumder, Rangan and Wei, Furu",
        "title": "Improving text embeddings with large language models"
      }
    ]
  },
  {
    "index": 15,
    "papers": [
      {
        "key": "jiang2023mistral",
        "author": "Jiang, Albert Q and Sablayrolles, Alexandre and Mensch, Arthur and Bamford, Chris and Chaplot, Devendra Singh and Casas, Diego de las and Bressand, Florian and Lengyel, Gianna and Lample, Guillaume and Saulnier, Lucile and others",
        "title": "Mistral 7B"
      }
    ]
  },
  {
    "index": 16,
    "papers": [
      {
        "key": "yu2024distilling",
        "author": "Yu, Ping and Xu, Jing and Weston, Jason and Kulikov, Ilia",
        "title": "Distilling system 2 into system 1"
      }
    ]
  },
  {
    "index": 17,
    "papers": [
      {
        "key": "wei2022chain",
        "author": "Wei, Jason and Wang, Xuezhi and Schuurmans, Dale and Bosma, Maarten and Xia, Fei and Chi, Ed and Le, Quoc V and Zhou, Denny and others",
        "title": "Chain-of-thought prompting elicits reasoning in large language models"
      },
      {
        "key": "deng2023rephrase",
        "author": "Deng, Yihe and Zhang, Weitong and Chen, Zixiang and Gu, Quanquan",
        "title": "Rephrase and respond: Let large language models ask better questions for themselves"
      }
    ]
  }
]