
\section{challenges and Future Trends}\label{sec_future}
Despite the advanced methodologies and techniques developed, training DNNs for CD with very few samples remains challenging. This section presents an analysis of the remaining challenges and bottleneck problems in applying sample-efficient CD algorithms, along with a prospective overview of future developments in the field.

\subsection{Challenges}

Sample-efficient CD still encounters considerable challenges in mitigating the data dependency and in generalizing insights across diverse datasets without necessitating extensive fine-tuning. In the followings we analyse several principal obstacles.

\subsubsection{Domain adaptability}

RSIs collected by different sensors and platforms exhibit considerable variability in spatial resolution, imaging scale, and spectral patterns. Conventional machine learning methods derive different levels of analysis on pixel spectrals, local textures, and object contexts \cite{wen2021change, lv2022land}. Despite the capability of DL to facilitate end-to-end modeling of multilevel change patterns, these approaches still suffer from severe accuracy degradation when dealing with data from other domains. Although there are heterogeneous CD methods, they are constrained by trained domain transitions and face challenges in obtaining domain-invariant change representations.

The major reasons are two-fold:
i) domain-specific network architectures. DL-based CD methods employ diversified DL techniques to perform intricate analysis on the informative attributes in different RS data. For instance, some methods employ spectral attention \cite{hu2022hypernet} and superpixel GNNs \cite{qu2023feature} for hyperspectral CD, while some other methods introduce low-level supervision \cite{peng2019end, lu2020weakly} and geometric perturbations \cite{wang2024stcrnet} for CD in VHR RSIs. Although these designs yield significant accuracy enhancements within the training domains, they present substantial challenges when it comes to generalizing to novel domains.
ii) Domain-coupled change learning. Typical CD approaches learn mappings of difference patterns specific to training domains. Although there exist domain-invariant change representation methods \cite{sublime2019automatic}, they also neglect the intrinsic semantic transition mechanism in CD. Consequently, the resultant models struggle to differentiate between specific semantic changes and unknown domain variations.

\subsubsection{Spatial and Temporal Complexity}

Recent advancements in Earth Observation technologies enable dense time-series monitoring through the deployment of surveillance satellites and small satellite constellations. The improvement in temporal resolution benefits applications that require frequent observations, including environmental monitoring, urban management, and disaster alarm. However, DL-based analysis on time series CD is still in an early exploration phase, especially for the analysis of long-time series of HR images. Conventional methods address TSCD as a multidate LCLU classification task or analyze the trajectory of multi-temporal images \cite{stahl2023automated}. This neglects the spatio-temporal context in HR data and may result in false alarms due to temporal variations (such as temporary occlusions and seasonal changes). 

Additionally, few studies address the spatial misalignment that often occurs in multi-source RSIs. Observation platforms such as UAVs and surveillance satellites offer quick access to regions of interest due to shorter revisiting. However, these platforms differ greatly in imaging angles and geometric distortions \cite{shen2021s2looking}. Most CD studies require costly and time-consuming preprocessing operations to ensure strict spatial consistency, thereby constraining their applicability. To expand the applicability of CD techniques, there is a research gap in developing sample-efficient methodologies to address the spatial and temporal complexity in CD.

\subsubsection{Unseen changes} Sample-efficient CD requires identification of changes that are absent from the training data. Unseen changes can be classified into two distinct types: (i) change instances that exhibit novel appearances yet remain within the established categories, a frequent occurrence in SMCD due to constrained usage of training data; and (ii) novel categories of changes that remain undefined, a common situation in SSCD and UCD while transferring domain knowledge into new datasets.

In BCD, the major challenge lies in distinguishing semantic changes amid temporal variations; whereas in MCD/SCD, the difficulties additionally encompass the identification of novel change categories. These challenges can be further amplified while encountering the previously mentioned obstacles including domain gap and spatio-temporal complexity. Generalization of CD insights into wider RS applications requires a profound understanding of the semantic transitions, as well as comprehension of the specific application contexts.

\begin{comment}
    
\subsubsection{Interactivity and Accessibility of CD Insights}

Making change detection results accessible and interpretable to non-experts and enabling efficient interaction with CD systems are ongoing challenges \cite{li2023lrr,Li2024Learning}. Traditional methods often produce outputs that require specialized knowledge for comprehension and do not support intuitive querying. Further analysis or post-processing is necessary to transform CD results into detailed, contextual insights. For example, in the common CD paradigm, the categories of detected changes are predefined and do not support interactive selection by users. Summarizing the change statistics and ongoing trends also requires specialized expertise.

\end{comment}

\subsection{Future trends}


\subsubsection{Multi-temporal foundation models}

Recent breakthroughs in generative image synthesis, self-supervision techniques, and VFMs are setting the stage for the next generation of CD algorithms \cite{ding2024samcd, zheng2024segment}. Although variable VFMs \cite{Kirillov2023Segment} and spectral foundation models \cite{hong2024spectralgpt, guo2024skysense} have been established within the domains of computer vision and RS, the development of multi-temporal foundation models (TFMs) is crucial to achieve sample-efficient, sensor-agnostic, and eventually training-free CD within a unimodal framework.

TFMs are designed to capture temporal patterns and dynamic changes across multiple observations and subsequently utilizing the learned temporal knowledge to identify evolving trends. These models are designed to manage complex spatio-temporal dependencies within time-series RSIs, address data heterogeneity, and adapt to varying temporal intervals. They ensure scalability for extensive volumes of RS big data and create universal change representations by seamlessly integrating diverse sensor data across a range of resolutions and scales.



\begin{comment}
\subsubsection{Multi-modal, multi-resolution, and multi-scale CD}

Recent breakthroughs in generative image synthesis, self-supervision techniques, and VFMs are setting the stage for the next generation of change detection algorithms \cite{ding2024samcd, zheng2024segment}. These advances promise the development of multi-modal, multiresolution, and multiscale CD algorithms. Such future technologies aim to achieve universal change representations that seamlessly incorporate data from a wide variety of sensors, spanning various resolutions, and importantly, capturing and analyzing changes that manifest at different scales.

\subsubsection{CD in unregistered/cross-view images}

Most CD methodologies are developed for strictly registered RSIs. This necessitates pre-processing operations to align the resolution and spatial regions in multi-temporal RSIs, a process that can be costly and time-consuming. Furthermore, images collected via aerial platforms such as drones frequently exhibit different imaging angles beyond overhead perspectives \cite{shen2021s2looking}. Conducting CD in unregistered or cross-view contexts can substantially improve the efficacy and promptness of CD techniques in monitoring applications that demand swift responses.
    

\subsubsection{Multi-temporal foundation models}

Although variable VFMs \cite{Kirillov2023Segment} and spectral foundation models \cite{hong2024spectralgpt} have been established within the domains of computer vision and RS, the development of multi-temporal foundation models (TFMs) is of significant importance. TFMs are designed to capture temporal patterns and dynamic changes across multiple observations. These models are expected to handle complex spatio-temporal dependencies in time-series RSIs, address data heterogeneity, adapt to varying temporal intervals, and ensure scalability to accommodate extensive volumes of RS big data.

  
\subsubsection{From CD to map updating}

The improved accuracy and reliability of CD results have opened opportunities for the continuous updating of LCLU maps. Literature investigations in this domain predominantly employ pixel-level analysis, making them vulnerable to salt-and-pepper noise, and are limited to medium resolution RSIs such as Landsat data \cite{paris2019novel}. Recent advances in CD methodologies allow for direct comparison between LCLU maps and new observations \cite{chen2023land, hong2023cross,chen2024change}, and obtaining high-quality and geometrically regularized CD results at the object level \cite{wu2020geo}. By incorporating these recent advances into LCLU mapping systems in a geometrically consistent manner, we can generate up-to-date maps that accurately capture the dynamic nature of the environment.
  
\end{comment}

\subsubsection{Few-shot and Zero-shot CD}

As detailed in Sec.\ref{sc3-e}, most literature studies on SMCD still require a considerable number of training samples to achieve accurate results. In real-world applications, collecting change samples is costly, especially when data is scarce or quick responses are necessary. Thus, developing few-shot and zero-shot CD algorithms is critical for deploying CD systems with minimal change samples.

Few-shot learning (FSL) aims to acquire generalized knowledge applicable across various tasks using only a few examples. Most of the literature methods on FSL follow the meta-learning framework proposed in \cite{vinyals2016matching}. This framework mimics the few-shot applicational scenarios, where the network learns to identify novel classes in the unlabeled data (query set) by utilizing the knowledge obtained from a few number of examples in the labeled data (support set). FSL allows DNNs to generalize to novel classes from a minimum of just one example, and has been investigated in the task of semantic segmentation \cite{lang2022learning}. 

Zero-shot learning (ZSL) uses data from known classes to train DNNs, enabling inference on unseen classes. Typical FSL methods map visual and semantic features to a common space for data-independent semantic alignment. Several problem settings have been further derived from ZSL to address various distinct application contexts \cite{rahman2022polarity}. These include: i) transductive ZSL, which uses unlabeled unseen data in training; ii) generalized ZSL, which involves classifying both seen and unseen classes; iii) domain adaptation, which adapts unseen targets to seen source domains; and iv) class-attribute association, which links unsupervised semantics to human-recognizable attributes. 

Integrating FSL and ZSL into CD methods could remove the need for fine-tuning algorithms on target domains. However, the context of CD presents more severe challenges, such as data heterogeneity and reduced density of semantic contexts. Few-shot and zero-shot CD remain to be rarerly explored and requires further research investigations.

\subsubsection{Interactive CD}

In many practical cases, CD is closely associated with the specific application context, such as urban building changes or agricultural monitoring. Conventional DL-based CD implicitly learn these applicational contexts through training samples, which is challenging with scarce change samples. An alternative is to incorporate explicit human interactions to guide the active exploitation of the relevant change information. Two key interaction types are spatial and language interactions.

a. Spatial interactions. In various VFMs, user-generated input, such as points, scribbles, and rectangles, is encoded as spatial prompts to indicate the interesting objects to be extracted/segmented \cite{Kirillov2023Segment}. This approach can be expanded to CD tasks by incorporating bi-temporal annotations to specify the change objects of interest. This depends on the application of WSCD methodologies, which entails parsing weak spatial annotations into dense change predictions. Moreover, to minimize human effort and achieve the capability of 'clicking few and detecting many', the incorporation of SMCD and continual learning techniques \cite{douillard2021plop} is essential. The former facilitate the efficient use of sparse and scarce change annotations, while the latter allows for interactive refining and updating of annotations to specify the desired changes.

b. Language interactions. Recent developments in the fusion of language models with RS data analysis represent a new frontier in CD, offering innovative ways to interact with and interpret CD results. This approach includes: i) change captioning: describing the major changes in multi-temporal RSIs, ii) prompt-driven CD: selectively segment the changes of interested LCLU categories given user prompt such as keywords \cite{dong2024changeclip}, and iii) visual question answering for CD: given questions concerning changes on RSIs, providing detailed and informative language answers. Language-driven CD offers a more intuitive interface between users and CD systems.

\section{Conclusions}

Leveraging limited data to train DNNs with dense parameters has consistently been a bottleneck challenge in the deployment of DL algorithms. Recently, with the ongoing progress in DL methodologies such as image generation, self-supervised learning, and VFMs, there has been a growing increase in research attention towards sample-efficient CD.

CD has consistently been an important visual recognition task in RS applications. It can be classified into BCD, MCD/SCD, and TSCD, based on the granularity of the results and the number of observation dates. Sample-efficient change detection can be categorized into distinct learning paradigms based on the diversity in label forms and quantities. These paradigms encompass four principal types, including SMCD, WSCD, SSCD, and UCD. Each learning setting further derives diverse strategies and technologies specifically designed to overcome the unique challenges presented, which have been systematically reviewed and summarized in Table \ref{Table.Strategy}. Moreover, to facilitate an intuitive comprehension of the SOTA performance in sample-efficient CD, a comparative analysis is performed across various learning settings with regard to change samples and the achieved accuracy. Finally, a critical analysis of the challenges encountered is provided, along with recommendations for potential future research directions.

In conclusion, the exploration of sample-efficient CD is still in an early stage of exploration. Although notable progress has been made in decreasing the dependence on extensive training samples, the challenge of performing CD with very scarce samples persists. There exists a substantial research gap in the development of CD methodologies to tackle more challenging CD scenarios, such as few-shot CD, image label-supervised WSCD, unsupervised CD (UCD), non-fine-tuned SSCD, and ultimately zero-shot CD.

\section*{Acknowledgement}
This work was supported by the National Natural Science Foundation of China under Grant 42201443, Grant 42271350, and also supported by the International Partnership Program of the Chinese Academy of Sciences under Grant No.313GJHZ2023066FN. Danfeng Hong is the corresponding author.