\section{Related Works}
\paragraph{Verbal Reinforcement Learning for Self-Reflection}
VRL has emerged as a promising approach for enhancing LLM reasoning at inference time____. Early methods relied on self-reflection mechanisms where LLMs refined outputs using contextual cues____. However, studies show that LLMs struggle to self-correct reliably____. To address this, trained critic models have been used to generate verbal feedback for LLM correction____, though they primarily focus on single-step feedback. More complex reasoning tasks typically rely on Oracle labels for correction____. Our work introduces a dual-model framework where a Critic independently provides more detailed, trace-level reflections, eliminating the need for Oracle labels in verification.

\paragraph{Explainable Automated Student Answer Scoring}
ASAS is traditionally treated as a text classification problem____, with efforts to improve transparency via feature analysis____ and attention visualization____. Recent approaches incorporate rationale generation for enhanced explainability and transparency____ but often underperform compared to classification-based methods. ____ proposed a thought tree framework to model human assessment processes, leveraging LLMs for structured scoring rationales. Our work builds upon this by not only explaining decisions but also improving the transparency of assessment refinement process, through iterative LLM reasoning improvements.