\section{Related Work}

\subsection{GNN-based methods for HAR}
GNNs have been widely adopted in IoT scenarios, in applications including  multi-agent interaction, Human State-dynamic, sensor interconnection, and autonomous vehicles~\cite{10.1145/3565973}.
Considering sensor-based human activity recognition, GNNs have been mainly proposed to recognize activities from mobile/wearable devices~\cite{10174597}.

The differences between existing work lies in how the graph is constructed from sensor data.
For instance, a common solution is to consider each time window as a node with the goal of performing node classification~\cite{9680185,9767342,9874212}.
%In \cite{9680185} and in \cite{9767342} a graph is built using nodes in the temporal windows and the classification of the activity is reduced as the node classification task.
%Similarly in \cite{9874212} HAR is reduced to a node classification task, but the model is built upon spectral convolutions. This system is tested on a dataset containing data from inertial sensors. 
Other works consider a node for each sensor, considering a graph classification task~\cite{9995660}. 

Only a few works applied GNNs to ADLs recognition in smart home environments. For example, \cite{s24123944} uses graphs to model sensor dependencies. In that work, a graph is built such that each node represents an environmental sensor, while a directed arc represents the influence of the behavior of one sensor to another one. The arcs of the graph structure and their weights are learned using an attention mechanism. The graph classification task is then considered to perform ADLs classification.
The work in~\cite{ye2023graph} is closely related to \acronym{} since it dynamically constructs each graph from the time window of sensor data, where each node is a sensor event. Differently from our work, the arcs are automatically learned from the network considering spatial and temporal properties at the same time.  

While it may be possible to apply XAI techniques on such methods, it would be challenging to obtain meaningful explanations. For instance, considering the work in~\cite{s24123944}, it may be possible to obtain explanations only about the sensors triggered consecutively, without considering longer temporal relationships. On the other hand, since in~\cite{ye2023graph} the arcs are automatically learned, they are not associated with a specific semantic and hence it would be challenging to explain them.


\subsection{XAI methods for Human Activity Recognition}

The first attempts for explainable sensor-based activity recognition considered simple inherently interpretable models~\cite{bettini2021explainable,atzmueller2018explicative,guesgen2020using,khodabandehloo2021healthxai}. However, such models usually underperform deep learning models that, on the contrary, are more complex to explain.

A few works proposed XAI methods for deep learning for sensor-based activity recognition~\cite{jeyakumar2023x,meena2023explainable}. However, only a few of them focused on ADLs recognition in smart homes.
For instance, DeXAR~\cite{arrotta2022dexar} leverages CNN models and explores the use of various XAI methods for computer vision by converting sensor data into semantic images.
Similarly, the work in~\cite{das2023explainable} applies several XAI methods to LSTM-based neural networks. Both works generate explanations in natural language for non-expert users.

While eXplainable Graph Neural Networks have been studied in the general machine learning community~\cite{agarwal2023evaluating}, this is the first work exploring this combination for sensor-based ADLs recognition in smart homes.