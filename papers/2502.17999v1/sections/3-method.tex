\section{\acronym{} under the hood}

In this work, we consider a smart home environment equipped with binary environmental sensors (e.g., motion sensors, magnetic sensors, pressure sensors). We assume that the smart-home is inhabited only by a single resident, and that sensor events are the result of the interaction of the subject with the environment. We also assume that the same timestamp will never be assigned to two distinct sensor events, hence we consider a total order in the sensor event sequence \footnote{Note that this is a realistic assumption, since typically events are queued by a single process on the gateway that assigns different timestamps even if the events occurred at the same time, without any impact on our results.}. The goal of \acronym{} is to provide the most likely activity from time windows of sensor events and, at the same time, to provide an explanation in natural language about the aspects of the input that mostly contributed to the prediction.


\subsection{Overall Architecture}
Figure~\ref{fig:architecture} depicts the architecture of \acronym{}.

   \begin{figure}[h!]
        \centering
        \includegraphics[width=\textwidth]{figures/XTT.png}
        \caption{Overall architecture of \acronym{}.}
        \label{fig:architecture}
    \end{figure}


First, the stream of environmental sensor data is segmented into fixed size overlapping time windows. Each time window is then processed by the \textsc{Graph Construction} module to obtain a graph representation of the window, encoding both spatial and temporal properties with an heuristic-based approach. Each graph is processed by the \textsc{GNN} module for ADLs classification. Then, the \textsc{Explainer} module leverages posthoc XAI methods to obtain the nodes and arcs that were the most important in the input to obtain the classified activity. Posthoc XAI approaches consider the model as a black box and generate explanations by analyzing the relationships between inputs and outputs. Finally, the \textsc{Explanation Generation} module uses this information to generate an explanation in natural language for non-expert users. 



\subsection{Graph Construction}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%The \textsc{Graph Construction} module dynamically constructs a graph $G_w$ starting from a temporal window $w$ of sensor events.
%In our framework, we consider two types of sensors. The first type are the sensors for which we are interested only in the activation and deactivation events. An example of this type of sensors includes magnetic sensors, whose deactivation requires an explicit action by the user (e.g. closing a cabinet). The second type are sensors for which we are interested in the state and the duration of the activation. An example of this type of sensors includes motion sensors, which are automatically deactivated after a fixed amount of time.

%\acronym{} leverages a heuristic-based strategy for graph construction, taking into account spatial and temporal properties (that will be leveraged to generate meaningful explanations).

%Let $w=\langle E_1, E_2, \dots, E_n \rangle$ be a temporal window including $n$ sequential sensor events.
%Let $G_w = (V,A)$ the corresponding graph, where $V$ is the set of nodes and $A$ the set of edges. In \acronym{}, the set $V = \{E_1,E_2,\dots,E_n\}$ corresponds to the set of sensor events in $w$.

%For each pair of sensor events $E_i,E_j \in V$ such that $i \neq j$, there is an oriented edge $(E_i,E_j)\in A$ in the following two cases:
%\begin{enumerate}
%    \item $E_i$ and $E_j$ are sensor events generated by the same sensor $S$, and there are no other events generated by $S$ happening between them. This is shown in Figure~\ref{fig:XT1}.
%    \begin{figure}
%        \centering
%        \includegraphics[width=0.7\textwidth]{figures/XT1.png}
%        \caption{Edges between events generated by the same sensor.}
%        \label{fig:XT1}
%    \end{figure}
%    \item $E_i$ and $E_j$ are sensor events generated by different sensors $S_a$ and $S_b$ and there are no other events generated by $S_a$ or $S_b$ that happen between them. 
%    %These edges often represent the transition between two different areas in the smart home.
%    This is shown in Figure~\ref{fig:XT2}.

%        \begin{figure}
%        \centering
%        \includegraphics[width=0.7\textwidth]{figures/XT2.png}
%        \caption{Edges between events generated by different sensors.}
%        \label{fig:XT2}
%    \end{figure}
%\end{enumerate}

%Both nodes and edges are also associated with features. Each edge is associated with the time difference between the timestamps of the two events.
%Regarding the node feature, it is composed by: a) the duration of the corresponding event, and b) the sensor type (e.g., magnetic, motion) mapped in the latent space by a (trainable) embedding layer.
%However, in the activation and deactivation events (e.g., the ones of magnetic sensors), the duration of the event is set to $0$.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%



The \textsc{Graph Construction} module dynamically constructs a graph $G_w$ starting from a temporal window $w$ of sensor events. \acronym{} leverages a heuristic-based strategy for graph construction, taking into account spatial and temporal properties (that will be leveraged to generate meaningful explanations).

Let $w=\langle E_1, E_2, \dots, E_n \rangle$ be a temporal window including $n$ sequential sensor events. An event $E_i$ is associated with the following information:
\begin{itemize}
    \item An identifier of the sensor that produced it ($E_i^{id}$), that encodes the sensor type (magnetic, motion ...) and the position (fridge, sofa...).
    \item The event type ON or OFF ($E_i^{type}$).
    \item The timestamp of the event ($E_i^{ts}$).
\end{itemize}

In our framework, we consider the events differently based on the type of sensor that generated them:
\begin{itemize}
    \item The first type of sensor includes sensors whose both activation and deactivation require explicit actions by the user (e.g. opening or closing a cabinet). In this case, we are interested in both the activation and deactivation (i.e. ON and OFF) events.
    \item The second type includes sensors that are automatically deactivated after some time, for instance, motion sensors. In this case, we are interested in the ON event and in the duration of the \textit{active state} of the sensor, computed as the time from the ON event to the OFF event.\footnote{In the case of motion sensors if there are multiple subsequent detections of movements, a single active state is considered. This is also how the events are reported in the public datasets we considered.}
    %So, a sensor of this type is considered in \textit{active state} from an ON event until the next OFF event. Note that when using temporal information related to \textit{active states} (e.g., defining a temporal ordering), we refer to the beginning of the state (marked by the ON event).
\end{itemize}

Given a window $w$, we denote the corresponding graph with $G_w = (V,A)$, where $V$ is the set of nodes and $A$ is the set of arcs. In \acronym{}, the set $V$ is created as follows:

\begin{itemize}
    \item We add a node $v$ for each event in $w$ (activation or deactivation) generated by the first type of sensor. These are \textbf{event nodes}.
    \item We add a node $v$ for every \textit{active} state of a sensor of the second type. These are \textbf{state nodes}.
\end{itemize}
%Each node has as an associated feature the sensor identifier mapped in the latent space by a (trainable) embedding layer. State nodes have as second feature the duration of the corresponding \textit{active state}.
In our system, each node has the sensor identifier as a feature. As common in deep learning, a (trainable) embedding layer computes an embedding vector representing this feature. State nodes have the duration of the corresponding \textit{active state} as an additional feature.

The set of arcs $A$ is created as follows:
For each pair of node $v_i,v_j \in V$ such that $i \neq j$, there is an oriented arc $(v_i,v_j)\in A$ in the following two cases:
\begin{enumerate}
    \item $v_i$ and $v_j$ are event nodes derived from consecutive events generated by the same sensor $S$ (i.e., there are no other events from $S$ between them). This is shown in Figure~\ref{fig:XT1}.
    \begin{figure}
        \centering
        \includegraphics[width=0.7\textwidth]{figures/XT1.png}
        \caption{Arcs between event nodes generated by the same sensor.}
        \label{fig:XT1}
    \end{figure}
    \item $v_i$ and $v_j$ are state nodes derived from consecutive active states of the same sensor $S$. 
    
    \item $v_i$ and $v_j$ are derived from events/states generated by different sensors $S_a$ and $S_b$ and there are no other events/states generated by $S_a$ or $S_b$ between them. This temporal relationship is computed considering as timestamp of an active state the timestamp of the activation (ON) event. 
    %These edges often represent the transition between two different areas in the smart home.
    This is shown in Figure~\ref{fig:XT2}.

        \begin{figure}
        \centering
        \includegraphics[width=0.7\textwidth]{figures/XT2.png}
        \caption{Arcs between event or state nodes generated by different sensors.}
        \label{fig:XT2}
    \end{figure}
\end{enumerate}

Each arc $(v_i,v_j)\in A$ has as associated feature the time difference between the timestamp of the event/state corresponding to $v_j$ and the timestamp of the event/state corresponding to $v_i$, considering as timestamp of an active state the timestamp of the activation (ON) event.










This method for building the graph has also the advantage of maintaining a sparse structure, avoiding the graph degeneration into a fully connected graph.

Our graph construction strategy makes it possible to consider spatiotemporal relationships between sensor events. Considering temporal aspects, a directed arc from a node $v_i$ to a node $v_j$ models the fact that the event/state corresponding to $v_i$ occurred before the event/state corresponding to $v_j$. This temporal relationship is also quantitative since the arc feature encodes the time distance between them. Moreover, when $v_i$ and $v_j$ are generated by different sensors $S_a$ and $S_b$, the directed arc also implicitly encodes spatial relationships about the resident interacting with sensors in different home positions.



A challenge with graphs with a variable number of nodes is that it complicates the graph pooling process (i.e., creating an embedding for the whole graph).
For instance, pooling by concatenation would lead to graph embeddings of different shapes. 
%
\acronym{} solves this problem by augmenting $V$ with a fixed number of \textit{super-nodes}: fictitious nodes not corresponding to real sensor events or states. 
Specifically, we add a super node $SN_S$ to $V$ for each sensor $S$. We also add an arc $(v_i, SN_S)\in \mathbf{A}$ if $v_i$ corresponds to an event/state generated by the sensor $S$. Note that, if a window $w$ does not contain events/states generated by a sensor $S_a$, $V$ would include the super node $SN_{S_a}$ without associated arcs.
Hence, all the nodes corresponding to an event/state generated by a sensor are connected to its super-node. 
Super-nodes have the role of summarizing all the graph information into a fixed number of nodes. Thanks to this approach, it is possible to concatenate the information of the whole graph only by performing pooling on super-nodes.

In the following, we show a simple example of how to build a graph $G_w$ starting from a window $w$ including active states from three sensors.
The window $w$ and its states are depicted in Figure~\ref{fig:EX1}.

\begin{figure}
    \centering
    \includegraphics[width=1\textwidth]{figures/NI0.png}
    \caption[Graph construction example 1]{Example of a time window. For the magnetic sensor, the black lines represent the events. For the movement sensors, the black regions represent the active states}
    \label{fig:EX1}
\end{figure}

Figure~\ref{fig:EX2} shows the resulting graph $G_w$, that is constructed with the following steps:
\begin{itemize}
    \item For each sensor $S$, a super-node is created (represented as squares in the figure).
    \item For each event/state a node $v_i$ is generated (represented as circles in the figure).
    \item Each event/state generated by $S$ is connected to the respective super-node associated with $S$ (the dashed arrows).
    \item We include arcs based on the rules defined above (the solid arrows).
   % \begin{itemize}
   %     \item Considering events generated by the same sensors, in Figure~\ref{fig:EX2} we see that the edges $E_2$-$E_4$, $E_4$-$E_5$ and $E_1$-$E_6$ have been created, but there is no edge between $E_2$ and $E_6$.
   %     \item As an example for events from different sensors, consider Sensors 1 and 2. The resident at the beginning was near sensor 2, but in the middle of the window he was close to sensor 1, for this reason, the edge E1-E2 must be created, later the resident goes back to the proximity of sensor 2 and thus there is another edge going from E5 to E6
   % \end{itemize}
    
\end{itemize}

\begin{figure}
    \centering
    \includegraphics[width=1\textwidth]{figures/NI1.png}
    \caption[Graph construction example 2]{The directed graph computed from the sensor window in Figure~\ref{fig:EX1}. } 

    \label{fig:EX2}
\end{figure}

\subsection{Graph Neural Network}

In the following, we describe the steps for graph classification.

\subsubsection{Message Passing}

Message passing is a crucial step in GNNs for transmitting information between nodes in a graph. This technique allows nodes to share and update their features based on the features of their neighbors, facilitating the extraction of meaningful patterns and relationships in graph-structured data. 
%In \acronym{}, each node is associated with a feature vector created by concatenating the event duration with an embedding obtained by passing the type of sensor that generated the event through an embedding layer. 

Information propagates through the graph in two distinct steps. The first step aggregates and processes all the known information, including event duration and distances between events, to compute the new node features, while the second step has the goal of further spreading this information into the graph. The second step is particularly useful for spreading information to the super nodes.

More specifically, in the first iteration, for each node, a message is computed by applying a linear layer to the concatenation of the node embeddings and the arc features. This linear layer reduces the message's dimension to match the original node feature dimension. Subsequently, the aggregate message for each node is computed using a sum aggregation function, and the new node feature is obtained by summing the previous embedding with the aggregated message.

The second phase involves a simplified propagation in which only the new node embeddings are considered. Given that less information is processed in this phase, no linear layer is applied. Instead, a sum aggregation function is used directly. The same update function from the first phase is then applied, summing the previous node feature with the aggregated messages to compute the new node feature.

Although this propagation process can be iterated multiple times, the high connectivity of the graphs generated by \acronym{} makes it possible to leverage a small number of iterations to allow information to travel throughout the entire graph.

%To perform the message passing algorithm each node must be associated with a vector, this vector consists of the concatenation of the sensor activation time with a 50-dimensional vector representing an embedding obtained passing the event type (the id of the sensors that generated the event) through an embedding layer.
%The information is propagated through the graph in two different ways, at first a single propagation step is performed by computing the message by applying a linear layer to the concatenate of the node features vectors and edge features. The linear layer reduces the dimension of the message to be equal to the original node feature. Then for each node, the aggregate of the messages is computed using a mean aggregation function. For each node, the previous embedding is summed with the aggregate of the messages to compute the new node feature.
%In the second propagation phase, which is much simpler than the previous one, we are considering only the new node embedding without considering event durations and distance. Since we have less information to process, no linear layer has been used, and a sum aggregation function is applied directly, followed by the same update function described in the previous step without further operations. This propagation can be iterated multiple times, but since the graphs we are working with have high connectivity, even a small number of iterations is enough to let the information travel through the whole graph.



\subsubsection{Graph Pooling and Classification}

Figure~\ref{fig:GNN} shows the GNN model architecture of \acronym{}.
Graph Pooling consists in generating an embedding that is representative of the whole graph. As we previously mentioned, since the number of nodes is different for each instance, we leverage super-nodes. Thus, the pooling strategy proposed for this model consists of considering only the embeddings of super nodes and concatenating them to obtain a vector of length equal to the embedding dimension multiplied by the number of sensors.

The classification is carried out using linear layers: the flattened embedding encoding the graph is passed through two linear layers, each one followed by a LeakyReLU function. Finally, the output of the network is the probability distribution over the possible ADLs, obtained thanks to a softmax layer.
%\acronym{} only considers the most likely ADL from the network's output.

   \begin{figure}[h!]
        \centering
        \includegraphics[width=\textwidth]{figures/CG1.pdf}
        \caption{The model architecture of \acronym{}.}
        \label{fig:GNN}
    \end{figure}

\subsection{Explainer}

XAI methods applied on GNNs aim to find the subset of nodes and arc that mostly contributed to a specific prediction. In \acronym{}, a node is selected for the explanation if the corresponding sensor event/state was important for classifying the activity; an arc is selected if the specific order of sensor events/states was important for classifying the activity.

\acronym{} leverages the GNNexplainer~\cite{ying2019gnnexplainer} method for explanations. Through an optimization method, GNNexplainer derives a subgraph maximizing the mutual information between the GNN's prediction and the prediction that would have been obtained by the GNN based only on this subgraph. This is achieved by perturbing the graph and its features, and observing the effect of these perturbations on the GNN's predictions. Given the most likely ADL predicted by the GNN, the input graph and the GNN model, GNNexplainer computes importance values for nodes and arcs. The algorithm leverages gradient descent to derive node and arc masks that modulate the information spread in the graph during the message-passing procedure. 


%In its original version, the GNNexplainer algorithm creates a mask by multiplying the node features by a value in the range $[0,1]$, and similarly a second mask by multiplying the features of the arcs.
In its original version, the GNNexplainer algorithm includes the multiplication of each node feature by a value in the range $[0,1]$ to generate the node mask.
However, this approach cannot be adopted in GNN-XAR since the sensor id node feature represents a categorical value, %and even if they are mapped to numerical values within the network, 
the perturbation of that value would not convey the intended meaning. For this reason, we apply the original GNNExplainer but extract only the arc mask. We then compute the importance of each node as the importance of the arc connecting it to its corresponding super node. 
%The importance of that edge, is a good indicator of the importance of the node because it is the only edge from which information from the node itself passes to the super node.}
The intuition behind this strategy is that there is only one arc through which the information from the node is propagated to the super node. Since it is the super node that is used for the classification, the importance of this arc is a good indicator of the importance of the information conveyed by the node.
%\st{Figure}~\ref{fig:MSK-1} \st{shows an example of the output of GNNExplainer highlighting the obtained edge importance.}

\begin{figure}
    \centering
    \includegraphics[width=0.8\textwidth]{figures/MSK-1.png}
    \caption[How explainer algorithm works]{Output of the original GNNExplainer limited to arcs importance. The thickness of each arrow represents the importance values on the arcs.}
    \label{fig:MSK-1}
\end{figure}

Figure ~\ref{fig:MSK-1} represents the arcs importance as computed by the original GNNExplainer on an example in our domain. Note that the dashed lines, connecting nodes with super nodes, also have different thicknesses representing different importance.


%As stated above, those arcs will be later used to compute the importance of the respective node and removed from the final explanation mask.}
%In the original algorithm, GNNexplainer creates a mask by multiplying the node feature by a value in the range $[0,1]$ and then evaluating the model against the masked input. However, this approach works with numerical features and it can not be adopted in \acronym{} where node features are categorical. To overcome this issue, we adapted GNNexplainer to compute the importance of each node as the importance of the edge connecting it to the corresponding super node.

As stated above, our adapted version of GNNexplainer assigns as importance of each node the importance of the arc connecting it with its super node.
Figure ~\ref{fig:EX4} shows the output of our adapted version of GNNexplainer on the same example of Figure \ref{fig:MSK-1}. Note that super nodes are not part of the output and that an importance value is associated with each node, denoted in the figure by the thickness.
%Here it can be seen that the link between the nodes and the respective supernode is no longer there, and that the importance of that link was used to calculate the importance of the respective node.}


\begin{figure}
    \centering
    \includegraphics[width=0.65\textwidth]{figures/MSK-2.png}
    \caption[How to obtain a node mask]{Output of our adapted version of GNNExplainer on the same input example of Figure \ref{fig:MSK-1}.}
    \label{fig:EX4}
\end{figure}

GNNexplainer is a non-deterministic algorithm. For this reason, it requires multiple executions, and only the average of the masks obtained at each execution is considered for the explanations.
A major challenge of using GNNexplainer is that the importance values obtained for nodes and arcs are not directly comparable, since they range in different intervals. 
%and nodes always get higher scores than arcs, 
Since we observed that arcs scorers are usually associated with lower importance values, we rescale them by a multiplicative factor such that the importance values of the nodes and the ones for the arcs have the same mean.

Finally, \acronym{} aims at extracting a supgraph $G_w^\star = (V^\star,A^\star)$ where $V^\star$ is the set of the most important nodes, while $A^\star$ is the set of the most important arcs. A straightforward approach to achieve this task would be using a threshold on the importance value.
However, we observed that different predictions are usually associated with importance values in completely different ranges. Hence, defining a robust threshold is challenging. We mitigated this problem by adopting a clustering approach. Indeed, we cluster arcs and nodes based on their importance values.
We consider as the most important arcs and nodes the ones in the cluster associated with the highest importance values.

%and for certain input all nodes/edges are above the fixed threshold while for other graph no element get a score higher than a threshold. 



%Then, from the continuous mask, a finite number of elements must be extracted and added to the pool of important nodes or edges that will build the final explanation, an easy way to do that is to use a threshold unfortunately using a fixed threshold is not feasible since for each graphs the mask have different ranges and for certain input all nodes/edges are above the fixed threshold while for other graph no element get a score higher than a threshold. Thus another option may consists in using an adaptive threshold, various experiments have been done this way but at the end a clustering approach have been observed to provide superior explanation.

%The clustering approach proposed has been developed within the scope of this work and it consists in dividing nodes and edges using k-mean clustering algorithm on the value of the node and edge mask dividing this way the set of total elements in multiple clusters, where the number of clusters depends on the number of sensor events appearing in the window. Then only the cluster corresponding to the elements with higher score is taken in consideration.



\subsection{Generating explanations in natural language}

As a final step, \acronym{} converts $G^\star$ into a natural language explanation for non-expert users.

Given the set of most important arcs $A^\star$, we compute the longest path.
We then use a heuristic-based approach similar to the one proposed in~\cite{arrotta2022dexar} to generate from this path a natural language explanation.
For instance, the continuous activation of certain sensors implies that the resident has moved toward the sensor multiple times: in this case, in the path explanation, the expression ``\textit{multiple times}'' is added:\\

  \textit{``I predicted preparing a meal mainly due to the following observations: Bob was near the fridge, then he opened the fridge multiple times''}\\

%However, in certain situations multiple activations of the same sensor simply imply that the user has been staying in the same place for some time (e.g., motion sensors on the sofa area); in these cases, ``\textit{multiple times}'' is not added. 

%Also, some sensors represent a position in a room, so if there is movement near a specific place in the room, it will be redundant to add to the explanation that the user is inside the room even if the wider range sensor has been activated.