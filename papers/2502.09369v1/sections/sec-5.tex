%ÃŸ\newpage
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Discussion}\label{sec:5}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
We fine-tune language agents to act as digital representatives in the context of collective decision-making, offering practical implications for scenario studies and mechanism design. In the sequel, we provide an overview of related work and conclude with a discussion on limitations and future work.

\dayum{
%==============================================================================
\textbf{Related Work}~
%==============================================================================
Our work in ``simulation for representation'' straddles two domains of research: in (1) how human behavior is simulated with models, and (2) how human behavior is represented by models.
}

\muline{\textit{Simulation}}:~ First, \textit{imitation learning} deals with training an artificial agent to mimic a demonstrator \cite{le2016smooth,yue2018imitation,osa2018imitation,huyuk2021explaining},
to match some notion of performance
\cite{syed2010reduction,abbeel2004apprenticeship,neu2007apprenticeship,babes2011apprenticeship}, or
to recover some underlying motive for their behavior
\cite{ziebart2008maximum,finn2016guided,ho2016generative,jarrett2021inverse}.
Multiple artificial agents have also been cloned \cite{zhan2018generative,codevilla2019exploring}, such as for
simple control tasks \cite{song2018multi},
bandit environments \cite{shih2022conditional}, and
driving simulation \cite{bhattacharyya2018multi}.
This contrasts with our high-dimensional language domain, and with our focus on ``representativity'' in collective decision-making.
Second, \textit{synthetic data generation} deals with sampling from learned distributions to approximate real phenomena, such as in sequential data
\cite{lin2019generating,xu2020cot,jarrett2021time},
medical environments
\cite{chan2021medkit,rcgan},
driving simulation
\cite{dosovitskiy2017carla},
as well as in language space
for social science
\cite{veselovsky2023generating},
privacy preservation,
\cite{kurakin2023harnessing},
and to augment
text mining
\cite{tang2023does}.
However, this contrasts with our emphasis on learning models to act in an interactive context.
Third, recent work has explored creating plausible simulacra of \textit{social agents} using language models, such as
in creating populated prototypes for social computing
\cite{park2022social},
in prompting models to simulate human sub-populations
\cite{argyle2023out}
and replicate human subject studies
\cite{aher2023using,harding2023ai},
in simulating economic agents
\cite{horton2023large},
and in creating believable social behavior in sandbox environments
\cite{park2023generative}.
In contrast, we fine-tune models on a personalized level to represent specific individuals within a group.

\dayum{
%--------------------------------------
\muline{\textit{Representation}}:~
%--------------------------------------
Since large language models are often pre-trained on human data with diverse perspectives,
a recent line of work has seeks to measure the preferences that pre-trained models \textit{inherently reflect} with prompting, such as
the representation of broad-based global demographic groups
\cite{durmus2023towards},
the alignment of their views with demographic categories in the United States
\cite{santurkar2023whose},
as well as to uncover the intrinsic ideological biases that pre-trained models exhibit
\cite{hartmann2023political}.
Secondly, a related strand of research systematically probes pre-trained models to \textit{actively simulate} biased perspectives, such as
by prompting with socio-demographic profiles
\cite{beck2023not}, as well as
by prompting with liberal or conservative profiles to sample text with corresponding moral biases
\cite{simmons2022moral}.
Some models have also been \textit{explicitly fine-tuned} to query the opinions and worldviews of demographic categories of people \cite{jiang2022communitylm,haller2023opiniongpt}.
In contrast, however, in this work we seek to simulate behavior at the granularity of individual representativity, specifically in the context of collective interaction.
Finally,
while we draw an analogy with value-aware
\cite{farahmand2017value,farahmand2018iterative}
and value equivalent learning
\cite{grimm2020value,grimm2021proper,grimm2022approximate,arumugam2022deciding},
our work has close connections with broader notions of representation \cite{dovi2006political}
in collective interaction
\cite{narahari2014game},
consensus-based decision-making
\cite{leach2016freedom},
and has potential implications for real and simulated deliberative democracy
\cite{dryzek2011toward,engelstad1989assignment,bessette1994mild,leike2023proposal}.
}

\dayum{
%==============================================================================
\textbf{Future Work}~
%==============================================================================
We began with the question: ``\textit{What makes a good representative?}''. Our argument contends that a representative should not only capture the conditional dynamics of behavior but also ensure that its interaction through a mechanism preserves the trajectory-wise dynamics of outcomes.
%
Several caveats are in order:
%
First, there is no escaping the fact that the fidelity of any notion of ``representative'' is most solidly grounded in human endorsement. While we use a black-box payoff model as proxy, future work would greatly benefit from human validation of digital representatives.
%
Second, in this work we focused on learning representatives for the critique-writing step only. Future work would benefit from naturally extending this to the opinion-writing step as well, yielding fully-simulated representatives.
% (multi-step).
%
Thirdly, although we defined and evaluated representatives based on an equivalence objective, in our experiments the models were trained on a standard likelihood-based fine-tuning objective. Future work could explore directly training for the equivalence objective.
}

%==============================================================================
\textbf{Broader Impact}~
%==============================================================================
It is important to emphasize that our  training of digital representatives is geared toward \textit{simulation}, not advocating for their deployment as substitutes for human accountability in decision-making. For instance, suppose we were interested in using digital representatives for the purpose of simulating outcomes to improve some downstream tasks. Then evaluation of \textit{those} tasks must be performed with real humans. This is crucial, since we do not train representatives on any notion of factuality or transparency. In fact, representatives are specifically trained to mimic their human inputs per se, thereby carrying over any biases from those corresponding humans. That said, this research was conducted with a focus on societal benefit. The ultimate goal is to facilitate granular simulations of collective interactions for policy design, allowing decision mechanisms to benefit from scalable and cost-effective iterative refinement before real-world deployment.