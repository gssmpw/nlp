%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{abstract}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\dayum{
Consider the process of collective decision-making, in which a group of individuals interactively select a preferred outcome from among a universe of alternatives.
%
In this context, ``representation'' is the activity of making an individual's preferences present in the process via participation by a proxy agent---i.e. their ``representative''.
%
To this end, learned models of human behavior have the potential to fill this role, with practical implications for multi-agent scenario studies and mechanism design.
%
In this work, we investigate the possibility of training \textit{language agents} to behave in the capacity of representatives of human agents, appropriately expressing the preferences of those individuals whom they stand for.
%
First, we formalize the setting of \textit{collective decision-making}---as the episodic process of interaction between a group of agents and a decision mechanism.
%
On this basis, we then formalize the problem of \textit{digital representation}---as the simulation of an agent's behavior to yield equivalent outcomes from the mechanism.
%
Finally, we conduct an empirical case study in the setting of \textit{consensus-finding} among diverse humans, and demonstrate the feasibility of fine-tuning large language models to act as digital representatives.
}
\end{abstract}