% We introduce Koel-TTS, a suite of encoder-decoder Transformer models that efficiently map text and context audio to acoustic speech tokens. Our work advances LLM-based TTS synthesis by integrating preference alignment techniques and CFG to improve intelligibility, speaker similarity, and naturalness, while mitigating hallucinations in generated speech. By leveraging automatic metrics such as transcription accuracy and speaker similarity, we develop a robust reward system that enables effective preference alignment, leading to SOTA zero-shot TTS performance without extensive retraining. 
% We demonstrate the effectiveness of our models in multilingual TTS, showcasing their ability to produce high-quality, low-latency speech while maintaining a simplified model design. 
% Finally, through audio examples on our webpage, we demonstrate that Koel-TTS can be effectively finetuned for long-form multi-turn dialogue generation, by adapting the model for contextually aware podcast synthesis.
We introduce Koel-TTS, a suite of encoder-decoder transformer models that map text and context audio to acoustic speech tokens. 
By incorporating preference alignment driven by transcription accuracy and speaker similarity, and Classifier Free Guidance,
we improve intelligibility, speaker similarity, and naturalness of generated speech,  achieving state-of-the-art zero-shot TTS performance. 
Koel-TTS excels in multilingual TTS, delivering high-quality, low-latency speech with a simplified model design. Finally, through audio examples on our webpage, we demonstrate that Koel-TTS can be effectively fine-tuned for long-form multi-turn dialogue generation, by adapting the model for contextually aware podcast synthesis.