% Classifier free guidance (CFG) has emerged as a powerful technique to enhance the quality and controllability of generative models, particularly in the domain of diffusion models. CFG was originally introduced to trade-off sample fidelity and diversity without relying on a separate classifier~\cite{ho2021classifier}.
% For text-to-speech synthesis, CFG has been extended to improve non-autoregressive conditional flow-matching models (CFM)~\cite{le2024voicebox,chen2024f5}. It has also been adapted to improve autoregressive models based on next-token prediction~\cite{darefsky2024parakeet}. 
To adapt CFG for autoregressive token prediction models, we train both a conditional and an unconditional model simultaneously by randomly dropping out the text and context/speaker conditioning during training. At inference time, conditional and unconditional outputs are combined to guide the speech generation process. This approach allows for more precise control over the generated speech, which can lead to improved pronunciation, prosody, robustness, and overall audio quality. 

Distinct from the previous work that only deals with text-independent conditionals~\cite{darefsky2024parakeet}, in our approach, we randomly dropout both audio and text conditioning inputs (with a probability of $10\%$) during training and interpolate conditional logits ($\ell_{c}$) with the unconditional logits ($\ell_{u}$) during inference\footnote{Note that CFG inference doubles the effective batch size to obtain conditional and unconditional logits.}, 
\begin{equation*}
    \ell_\textit{cfg} = \gamma * \ell_{c} + (1 - \gamma) * \ell_{u}
\end{equation*}
where $\gamma\ge1$ is the CFG interpolation scale controlling the strength of guidance. Higher scale values steer the generation to follow the text/audio inputs, while lower scale values allow more variations. In practice, we sweep around a range of values to find the optimal scale $\gamma$. 
Figure~\ref{figs:cfg} demonstrates the CFG inference process. 

\begin{figure}[!ht]
    \centering
    \includegraphics[width=1.0\columnwidth]{diagrams/CFG_paper_diag.pdf}
    \vspace{-8mm} 
    \caption{\footnotesize{CFG Inference: Logits from conditional and unconditional inputs are combined using a CFG scale $\gamma$\texttt{>1}, steering model predictions towards better alignment with conditional inputs.}}
    \label{figs:cfg}
     \vspace{-4mm} 
\end{figure}

