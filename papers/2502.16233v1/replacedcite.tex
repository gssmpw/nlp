\section{Related Work}
\label{sec:background}
GNNs are designed to effectively process and represent graph-structured data, and they come in various flavors, including GCN ____, GAT ____, GraphSAGE ____, GIN ____, DFNets ____, linear SSGC ____, GReLU ____, \etc. Such models distinguish representations of graphs based on their data labels. However, annotating graph data, such as identifying categories of biochemical molecules, often requires specialized expertise, making it challenging to obtain large-scale labeled graph datasets ____. This challenge highlights a key limitation of supervised graph representation learning.

Contrastive Learning (CL) stands out as a highly effective self-supervised technique embedding unlabeled data ____. By bringing similar examples closer together and pushing dissimilar ones apart, CL methods including SimCLR ____, MoCo ____, BYOL ____, MetAug ____, Barlow Twins ____ and their multi-head variants ____ have demonstrated remarkable success in  computer vision ____.

\vspace{0.1cm}
\noindent
\textbf{Graph Self-Supervised Learning (GSSL)} %Graph Self-Supervised Learning (GSSL) has emerged as a 
is a promising technique for learning representations of graph-structured data without requiring labeled examples, making it especially effective for graph classification tasks. To date, many GSSLs with unique strategies have been proposed to enhance  graph classification. These methods build on the strengths of GNNs and CL techniques ____.

A key focus of GSSL is the development of effective graph augmentation strategies. For instance, GraphCL ____ introduces perturbation invariance and proposes various graph augmentations, such as node dropping, edge perturbation, attribute masking, and subgraph extraction. Recognizing the limitations of using complete graphs, Subg-Con ____ advocates for subgraph sampling as a more effective method for capturing structural information. To improve the semantic depth of sampled subgraphs, MICRO-Graph ____ proposes generating informative subgraphs by learning graph motifs. Furthermore, the process of selecting suitable graph augmentations can be time-consuming and labor-intensive; JOAO ____ addresses this by introducing a bi-level optimization framework that automates the selection of data augmentations tailored to specific graph data. RGCL ____ argues that random destruction of graph properties during augmentation can lead to a loss of critical semantic information and proposes a rationale-aware approach for graph augmentation. Additionally, SPAN ____ introduces a spectral perspective for guiding topology augmentation,
while SFA ____ is a spectral embedding augmentation. 
%
%noting that previous work has largely concentrated on spatial domain augmentation. 
%
To capture the hierarchical structures by GSSL, HGCL ____ proposes Hierarchical GSSL, which integrates node-level CL, graph-level CL, and mutual CL components. HDC ____ studies hierarchical dimensional collapse in hyperbolic spaces. Another important aspect of GSSL is the process of negative sampling; BGRL ____ simplifies this process by eliminating the need for constructing negative samples, allowing it to scale efficiently to large graphs. To mitigate sampling bias, PGCL ____ introduces a negative sampling strategy based on semantic clustering. 
COLES ____ reformulate Laplacian eigenmaps into CL while GLEN ____ formulates COLES as the rank difference optimization. COSTA ____ uses sketching to create embedding perturbations.
%
In contrast, we emphasize both global and local structural understanding. Global graph representations  capture complex topological similarities and differences, while local node embeddings are refined to preserve detailed structural and positional nuances. By incorporating structural and positional awareness through invariance, variance, and covariance across node features, our method improves the ability to distinguish between isomorphic and non-isomorphic graphs. %This ensures that both global graph structure and local node characteristics are robustly represented and aligned.



\vspace{0.1cm}
\noindent
\textbf{Enhancing GNN Expressiveness. } A substantial amount of effort has been devoted to enhancing the expressive power of GNNs beyond the 1-WL\footnote{WL stands for the Weisfeiler Leman graph isomorphism test.}. This pursuit arises from the need to capture more intricate graph structures and relationships to address complex real-world problems effectively. Broadly, there are four primary directions which GNNs can extend beyond the 1-WL level: (1) A number of studies have introduced higher-order variants of GNNs, demonstrating comparable expressiveness to k-WL with $k\geq3$ ____. As an example, k-order graph networks, introduced by ____, offer expressiveness that is similar to a set-based variation of k-WL. ____ introduced a 2-order graph network that maintains expressive power similar to 3-WL. Furthermore, ____ introduced a localized variant of k-WL, focusing solely on a subset of vertices within a neighborhood. Nevertheless, using these expressive GNNs presents challenges due to their intrinsic computational demands and intricate architecture. In addition, some studies aimed to integrate inductive biases on isomorphism counting w.r.t predefined topological attributes such as triangles, cliques, and cycles ____. These efforts similar to the traditional graph kernels, as outlined by ____. However, the task of predefining topological characteristics needs specialised knowledge in the respective domain, a resource that is frequently not easily accessible. (3) In a different vein, there has been a recent surge in studies exploring into the notion of enhancing GNNs through the augmenting of node identifiers or stochastic features. For example, ____ introduced an approach that preserves a node's local context through the manipulation of node identifiers in a permutation-equivariant fashion. ____ developed ID-GNNs, incorporating vertex identity information in their design. ____ and ____ assigned one-hot identifiers to nodes, drawing inspiration from the principles of relational pooling. In a similar vein, ____ enriched the representational capability of GNNs by incorporating a random feature for each node. There are some other approaches modify the MPNN framework or incorporate additional heuristics to enhance their expressiveness ____. (4) Some works inject positional encoding (PE) as initial node features because nodes in a graph lack inherent positional information. Canonical index PE can be assigned to the nodes in a graph. However, the model must be trained on all possible index permutations, or sampling must be employed ____. Another direction for PE in graphs is using Laplacian Eigenvectors ____, as they establish a meaningful local coordinate system while maintaining the global structure of the graph. ____ proposed a PE scheme (RWPE) based on random-walk diffusion to initialize the positional representations of nodes. These positional encoding methods such as Laplacian positional encoding ____ or RWPE ____ have a significant limitation in that they usually fail to quantify the structural similarity between nodes and their surrounding neighborhoods. Nonetheless, while these techniques have demonstrated their expressivity to go beyond 1-WL. However, it remains uncertain what further attributes they can encompass beyond the scope of 1-WL. 

Despite these limitations, our method offers notable advantages. \emph{GenHopNet} enjoys greater expressive power than the 1-WL test, providing improved node and graph-level distinction by accounting for both local and global graph structures through closed walk counts and positional information. Additionally, by incorporating edge centrality measures to enrich message-passing, \emph{StructPosGSSL} enhances the model's ability to differentiate various types of connections, making it strictly more expressive than Subgraph MPNNs ____ in distinguishing certain non-isomorphic graphs.

% \vspace{-0.3cm}