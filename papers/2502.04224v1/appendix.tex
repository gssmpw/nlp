\appendix

\section{Proofs}

\subsection{Proof of Theorem~\ref{thm:bounddiff}}
\label{app:thm:bounddiff}

When an edge $e$ is added to or deleted from $G$, only the subgraph $G^{i_e} = (\mathcal{V}, \mathcal{E}_{i_{e}})$ is corrupted after hash mapping, and all the other subgraphs $\{G^{j}\}_{j\neq i_e}$ are unaffected. Note that the complete graph $G_C$ is fixed and all subgraphs built from it are never affected. 
Then, with Equation (\ref{eq:hybrid}), only the hybrid subgraph $G_H^{i_{e}}$ would be corrupted. 
Further, when $M$ edges from $G$ are perturbed to form $\hat{G}$, only hybrid subgraphs containing these edges would be corrupted. As some edges may be mapped to the same group index, the different subgraphs between $\{ G_H^i\}$ and $\{ \hat{G}_H^i\}$ is at most $M$.


\subsection{Proof of Theorem~\ref{thm:VerifyExp}}
\label{app:thm:VerifyExp}

After the graph perturbation, we want to satisfy two requirements:   
(1) the voting classifier still predicts 
the class $y$ in the perturbed graph $\hat{G}$  with more votes than predicting any other class $\forall b\in \mathcal{C}\setminus\{y\}$; (2)
the voting explainer ensures at least $\lambda$ edges in $\mathcal{E}_k$ are still in $\hat{\mathcal{E}}_k$, or at most $(k-\lambda)$ edges in ${\mathcal{E}}_C \setminus\mathcal{E}_k$ 
have higher votes than the minimum votes of the edges in ${\mathcal{E}}_k$. 


We first achieve (1):  Based on Theorem~\ref{thm:bounddiff}, with any $M$ perturbations on a graph $G$, at most $M$ hybrid subgraphs from $\{G_H^i\}$ can be corrupted. 
Hence, it decreases the largest votes $n_y$ at most $M$, while increasing the second-largest votes $n_{b}$ at most $M$ based on Eqn (\ref{eqn:labelcount}). 
Let $\hat{n}_y$ and $\hat{n}_b$ denote the votes of predicting the label $y$ and $b$ on the perturbed graph $\hat{G}$. We have 
$\hat{n}_y \geq n_y - M$ and $\hat{n}_b \leq n_b + M$. 
To ensure the voting classifier $\bar{f}$ still predicts $y$ for the perturbed graph $\hat{G}$, we require $\hat{n}_y > \hat{n}_b - \mathbb{I}(y<b)$ or $\hat{n}_y \geq \hat{n}_b - \mathbb{I}(y<b) + 1$, where $\mathbb{I}(y<b)$ is due to the tie breaking mechanism (i.e., we  choose a label with a smaller number when ties exist). Combining these inequalities, 
we require $n_y-M \geq n_b+M - \mathbb{I}(y<b) + 1$, yielding
\begin{align}
\label{eqn:reqclassifier}
M \leq \lfloor \frac{n_y-n_{b} + \mathbb{I}(y<b)-1}{2} \rfloor.
\end{align}

We now achieve (2): Recall $\bar{\mathcal{E}}_M $ the edges  in $\bar{\mathcal{E}}$ with top-$M$ scores in $\textbf{n}^{\gamma}$, which $\bar{\mathcal{E}}$ are edges in the complement of graph $G$. 
Similarly, with $M$ perturbed edges, the votes of every explanatory edge $e \in \mathcal{E}_k$ is decreased at most $M$, while the votes of every other edge $e \in \mathcal{E}_C \setminus \mathcal{E}_k$ is increased at most $M$ based on Eqn (\ref{eqn:votes}). 
Note that the edge $l \in \mathcal{E}_k$ has the $\lambda$-th highest votes $n_{l}^{\gamma}$, and the edge $h_M \in \bar{\mathcal{E}}_M \cup (\mathcal{E} \setminus \mathcal{E}_k)$ has the $(k-\lambda+1)$-th highest votes $n_{h_M}^{\gamma}$. 
Let $\hat{n}_{l}^{\gamma}$ and $\hat{n}_{h_M}^{\gamma}$ denote the votes of the edge $l$ and $h_M$ on $\hat{G}$ for each $M$. 
Likewise, we have $\hat{n}_{l}^{\gamma} \geq n_{l}^{\gamma} - M$ and $\hat{n}_{h_M}^{\gamma}  \leq {n}_{h_M}^{\gamma} + M$ for every $h_M$ (note $h_M$ depends on $M$). 
If the smallest votes $\hat{n}_{l}^{\gamma}$ of edge $l$ after the perturbation is still larger than the largest votes $\hat{n}_{h_M}^{\gamma}$ of the edge $h_M$, then at least $\lambda$ edges in $\mathcal{E}_k$ are still in $\hat{\mathcal{E}}_k$. 
This requires: $\hat{n}_{l}^{\gamma} > \hat{n}_{h_M}^{\gamma} - \mathbb{I}(l<h_M))$ for all $h_M$, where $\mathbb{I}(l<h_M)$ is due to the tie breaking. 
Combining these inequalities together, we require ${n}_{l}^\gamma -M > {n}_{h_M}^\gamma +M - \mathbb{I}(l<h_M), \forall M$, yielding
\begin{align}
\label{eqn:reqxGNN}
{n}_{l}^\gamma- {n}_{h_M}^\gamma + \mathbb{I}(l<h_M) > 2M
\end{align}

By satisfying both requirements, we force 
$$M \leq \min \big( \lfloor \frac{n_y-n_{b} + \mathbb{I}(y<b)-1}{2} \rfloor, M_h\big),$$
where $M_h = \max \, M,  \quad {s.t.} \quad {n}_{l}^\gamma- {n}_{h_M}^\gamma + \mathbb{I}(l<h_M) > 2M.$

\begin{algorithm}[!t] 
\small
\caption{XGNNCert: Classification, Explanation, and Certified Perturbation Size}
\label{alg:algorithm1}
\textbf{Input}: Graph $G={(\mathcal{V},\mathcal{E})}$ with $k$  explanation edges,  base classifier $f$, base explainer $g$, 
hyperparameters: ratio $p$, ratio $\gamma$, number of subgraphs $T$, hash function $h$.

\textbf{Output}: Prediction $y$, explanation $\mathcal{E}_{k}$, certified perturbation size $\{{  M_\lambda},\lambda\in[1,k]\}$ for $G$


\begin{algorithmic}[1] %[1] enables line numbers
\STATE Initialize $T$ subgraphs with empty edges $\{G^{i}=(\mathcal{V},\mathcal{E}^{i}=\emptyset),i=1,\cdots,T\}$.
\STATE Initialize $T$ complete subgraphs with empty edges $\{G^{i}_{C}=(\mathcal{V},\mathcal{E}^{i}_{C}=\emptyset),i=1,\cdots,T\}$.
\STATE Initialize $T$ hybrid subgraphs with empty edges $\{G^{i}_{H}=(\mathcal{V},\mathcal{E}^{i}_{H}=\emptyset),i=1,\cdots,T\}$.
\STATE Initialize a complete edge set $\mathcal{E}_{C} = \{(u,v),\forall u,v\in\mathcal{V}:u<v\}$
\STATE Initialize votes for all classes ${\bf n}= \{0\}^{|\mathcal{C}|}$, and all edges: ${\bf n}^{\gamma}= \{0\}^{|\mathcal{E}_{C}|}$

\FOR{Edge $e \in \mathcal{E}_{C}$}  
\STATE Assign index $i_e = h[\mathrm{str}(u) + \mathrm{str}(v)] \, \, \mathrm{mod} \, \, T+1.$
\IF{$e \in G$}
\STATE Add $e$ into subgraph 
$G^{i_{e}}$ by $\mathcal{E}^{i_{e}}\cup= \{e\}$
\ENDIF
\STATE Add $e$ into complete subgraph  $G^{i_{e}}_{C}$ by $\mathcal{E}^{i_{e}}_{C}\cup=\{e\}$
\ENDFOR

\FOR{$i \in [1,T]$}
\STATE Add the $i$-th subgraph $G^i$ into $i$-th hybrid subgraph by $\mathcal{E}_{H}^{i}\cup = \mathcal{E}^{i}$
\FOR{$j\in [1,i-1]\cup[i+1,T]$}
\STATE Randomlize a value $\Tilde{p}\in[0,1)$
\IF{$\Tilde{p}\leq p$}
\STATE Add the $j$-th complete subgraph into $i$-th hybrid subgraph by $\mathcal{E}_{H}^{i}\cup = \mathcal{E}^{i}_{C}$
\ENDIF
\ENDFOR
\ENDFOR
\FOR{$G^{i}_{C},i\in [1,T]$}
\STATE Predict $G^{i}_{C}$'s label via the base classifier: $c=f(G^{i}_{C})$
\STATE Add to the classification vote by 1: $n_c+=1$
\ENDFOR
\STATE Find the class with the most votes: $y = \underset{c \in \mathcal{C}}{{\arg\max}} \, n_c$
\STATE Find the class with the second most votes: $b = \underset{c \in \mathcal{C}\setminus\{y\}}{{\arg\max}} \, n_c$
\STATE Calculate the certified bound w.r.t. the classifier: $M_{f} = \lfloor \frac{n_y-n_{b} + \mathbb{I}(y<b)-1}{2} \rfloor$.
\FOR{$G^{i}_{C},i\in [1,T]$}
\STATE Explain $G^{i}_{C}$'s output via the base explainer: $\textbf{m}^{i}=g(G_H^{i},y)$
\FOR{$e\in G^i_{H}$}
\IF{${\bf m}_{e}^{i} \geq {\bf m}_{(\gamma)}^{i}$}
\STATE $n_{e}^{\gamma}+=1$
\ENDIF
\ENDFOR
\ENDFOR
\STATE Find the edges with top-k votes in $G$: $\mathcal{E}_{k}=\mathcal{E}.top_{k}(\textbf{n}^{\gamma})$
\STATE Initialize $M=0$, $\{{  M_\lambda}=0, \lambda=1,\cdots,k\}$ 
\WHILE{$M_{1}=M$}
\STATE $M+=1$
\STATE Find the edges with top-$M$ votes in $\mathcal{E}_{C}\setminus\mathcal{E}$: $\overline{\mathcal{E}}_{M}=(\mathcal{E}_{C}\setminus\mathcal{E}).top_{M}(\textbf{n}^{\gamma})$
\FOR{$\lambda \in [1,k]$}
\STATE Find the edge $l \in \mathcal{E}_k$ is with the $\lambda$-th highest votes $n_{l}^{\gamma}$, 
 \STATE Find the edge 
  $h \in \bar{\mathcal{E}}_{M} \cup (\mathcal{E} \setminus \mathcal{E}_k)$ 
 with the $(k-\lambda+1)$-th highest votes ${n}_{h}^{\gamma}$ in ${\textbf{n}}^{\gamma}$ 
\IF{${n}_{l}^\gamma- {n}_{h}^\gamma + \mathbb{I}(l<h) > 2M$}
\STATE ${  M_\lambda}=M$
\ENDIF
\ENDFOR
\ENDWHILE
\FOR{$\lambda\in [1,k]$}
\STATE ${  M_\lambda}=\text{min}({  M_\lambda},M_{f})$
\ENDFOR
\STATE {\bf Return $y, \mathcal{E}_K, \{{  M_\lambda}, \lambda \in [1,k]\}$} 
\end{algorithmic}
\end{algorithm}



\section{Pseudo Code on XGNNCert}


{Here we provide the pseudo code of our XGNNCert, shown in Algorithm~\ref{alg:algorithm1}}.




\section{Experimental Setup and More Results}
\label{app:evaluation}


{
\subsection{Detailed Experimental Setup}
\label{app:setup}

{\bf Dataset statistics:} Table~\ref{tab:Datasets} shows the statistics of the used datasets. 


{\bf Hyperparameter and network architecture details in training GNN classifiers and explainers:}  We have tested the base GNN classifiers with 2 and 3 layers, the hidden neurons $\{32, 64, 128, 192\}$, learning rates $\{0.001, 0.002, 0.005, 0.01\}$ and training epochs $\{600, 800, 1000, 1200\}$ with the Adam optimizer (no weight decay in the training). Finally, our base GNN classifiers are all 3-layer architectures with 128 hidden neurons, the learning rate as 0.001, and the epochs as 1000. 

For base GNN explainers, we simply use the configured hyperparameters in their source code. We set their hidden sizes as 64, coefficient sizes as 0.0001, coefficient entropy weights as 0.001, learning rates as 0.01, and epochs as 20. For PG Explainer, we set its first temperature as 5 and last temperature as 2. For GSAT, we set its final rate as 0.7, decay interval as 10 and decay rate as 0.1. For Refine, we set its gamma parameter as 1, beta parameter as 1 and tau parameter as 0.1.

}

 {{\bf Training the GNN classifier and GNN explainer}: Traditionally, we only use the training graphs (with their labels) to train a GNN classifier, which is used to predict the testing graphs. In {\name}, however, the voting classifier uses the hybrid subgraphs (the combination of subgraphs from the testing graphs and from the corresponding complete graphs) 
for evaluation. To enhance the testing performance of our voting classifier, we propose to train  the GNN classifier using not only the original training graphs but also the hybrid subgraphs, whose labels are same as the training graphs'\footnote{We observe the wrong prediction rate on our test hybrid subgraphs is relatively high, if we use the GNN classifier trained only on the raw training graphs. For instance, when $T=30$, the wrong prediction rate could be range from 35\% to 65\% on the five datasets. This is because the training graphs used to train the GNN classifier and test hybrid subgraphs have drastically different distributions. 
}.

Instead, the GNN  explainer is directly trained on raw clean graphs due to two reasons. First, the cost of training the explainer on subgraphs is high; Second, some subgraphs do not contain groundtruth explanatory edges, making it unable to explain these subgraphs during training.    
}


\begin{table}[!t]
    \centering
    \scriptsize
    \begin{tabular}{ccccccccc}
		\toprule
         Dataset& Graphs&$|\mathcal{V}|_{\text{avg}}$&$|\mathcal{E}|_{\text{avg}}$&Features&GT Graphs&GT Explanation&$|\mathcal{E}_{\text{GT}}|_{\text{avg}}$&k\\
         \midrule
         
         SG+House&1,000&13.69&15.56& 10&693&House Shape&6&6\\
         SG+Diamond& 1,000&10.46&14.03&10&486&Diamond Shape&5&5\\
         SG+Wheel&1,000& 12.76&14.07 & 10&589&Wheel Shape&8&8\\
         \midrule
         Benzene& 12,000&20.58&43.65&14&6,001 &Benzene Ring&6&6\\
         Fluoride-Carbonyl (FC) & 8,6716&21.36&45.37&14& 3,254 &F- and C=O& 5 & 5 \\
         \bottomrule
    \end{tabular}
    \vspace{-2mm}
    \caption{Datasets and their statistics.}
    \vspace{-4mm}
    \label{tab:Datasets}
\end{table}




{\subsection{More Results}}
\label{app:moreresults}


{ 
Figure~\ref{fig:CEA_T_pge_2}---Figure~\ref{fig:CEA_T_gsat_2} show the certified perturbation size vs. $\lambda$ on the three GNN explainers. 

Figure~\ref{fig:CEA_p_PG-2}---Figure~\ref{fig:CEA_h_PG} show the certified perturbation size of {\name} vs. $p, \gamma, h$ on PGExplainer, respectively. Additionally, Table \ref{tab:frac_performance}  and Table \ref{tab:hash_performance}  show the prediction accuracy of {\name}  vs. $p$ and $h$, respectively. We see the results are close, implying {\name}  is insensitive to $p$ and $h$. 
}


Figure~\ref{fig:deceive} shows the explanation results when the GNN model is deceived. We see that explaining wrong predictions yields explanation results that are not meaningful. 


\begin{table}[!t]
\centering
\begin{tabular}{lccccc}
\toprule
\textbf{Ratio $p$}   & \textbf{SG+House} & \textbf{SG+Diamond} & \textbf{SG+Wheel} & \textbf{Benzene} & \textbf{FC} \\ \midrule
0.0              & 0.900             & 0.925               & 0.905             & 0.723           & 0.674       \\
0.02             & 0.895             & 0.920               & 0.900             & 0.723           & 0.692       \\
0.03             & 0.905             & 0.935               & 0.900             & 0.723           & 0.692       \\
0.04             & 0.895             & 0.925               & 0.900             & 0.725           & 0.662       \\ \bottomrule
\end{tabular}
\caption{Prediction accuracy of XGNNCert 
 with different $\rho$ (default $p=0.3$).}
\label{tab:frac_performance}
\end{table}


\begin{table}[!t]
\centering
\begin{tabular}{lccccc}
\toprule
\textbf{Hash function $h$}   & \textbf{SG+House} & \textbf{SG+Diamond} & \textbf{SG+Wheel} & \textbf{Benzene} & \textbf{FC} \\ \midrule
\textbf{MD5}    & 0.905             & 0.935               & 0.900             & 0.723           & 0.692       \\

\textbf{SHA1}     & 0.905             & 0.935               & 0.895             & 0.718           & 0.692       \\
\textbf{SHA256}  & 0.900             & 0.935               & 0.905             & 0.725           & 0.674       \\ \bottomrule
\end{tabular}
\caption{Prediction accuracy of XGNNCert 
 with different hash functions. Default is "MDS".}
 \vspace{-5mm}
\label{tab:hash_performance}
\end{table}


\begin{figure*}[!t]
	\centering
 \subfloat[{SG+Wheel}]
	{\centering\includegraphics[scale=0.22]{png/PG-Wheel.png}}
 \,
 \subfloat[{FC}]
	{\centering \includegraphics[scale=0.22]{png/PG-FC.png}} 
	\caption{Certified perturbation size over all testing graphs  vs. $\lambda$ on PGExplainer.} 
	\label{fig:CEA_T_pge_2}
	 \vspace{-2mm}
\end{figure*}



\begin{figure*}[!t]
	\centering
 \subfloat[{SG+House}]
	{\centering\includegraphics[scale=0.22]{png/Ref-House.png}}
 \,
	\subfloat[{SG+Diamond}]
	{\centering \includegraphics[scale=0.22]{png/Ref-Diamond.png}}
\,
 \subfloat[{SG+Wheel}]
	{\centering\includegraphics[scale=0.22]{png/Ref-Wheel.png}}
 \,
 \vspace{-4mm}
\\
 \subfloat[{Beneze}]
	{\centering\includegraphics[scale=0.22]{png/Ref-Benz.png}}
\,	
 \subfloat[{FC}]
	{\centering \includegraphics[scale=0.22]{png/Ref-FC.png}} 
	\caption{Certified perturbation size over all testing graphs vs. $\lambda$ on ReFine.} 
	\label{fig:CEA_T_refine-2}
	 \vspace{-2mm}
\end{figure*}





  \begin{figure*}[!t]
	\centering
 \subfloat[{SG+House}]
	{\centering\includegraphics[scale=0.22]{png/GSAT-House.png}}
 \,
	\subfloat[{SG+Diamond}]
	{\centering \includegraphics[scale=0.22]{png/GSAT-Diamond.png}}
\,
 \subfloat[{SG+Wheel}]
	{\centering\includegraphics[scale=0.22]{png/GSAT-Wheel.png}}
 \,
  \vspace{-4mm}
\\
 \subfloat[{Beneze}]
	{\centering\includegraphics[scale=0.22]{png/GSAT-Benz.png}}
\,	
 \subfloat[{FC}]
	{\centering \includegraphics[scale=0.22]{png/GSAT-FC.png}} 
	\caption{{  Maximal}
 certified perturbation size over all testing graphs vs. $\lambda$ on GSAT.} 
	\label{fig:CEA_T_gsat_2}
	 \vspace{-2mm}
\end{figure*}

\begin{figure*}[!t]
	\centering
 \subfloat[{SG+Wheel}]
	{\centering\includegraphics[scale=0.22]{png/Wheel-p.png}}
 \,
\subfloat[{FC}]
	{\centering \includegraphics[scale=0.22]{png/FC-p.png}} 
	\caption{Certified perturbation size over all testing graphs  vs. $p$ on PGExplainer.} 
	\label{fig:CEA_p_PG-2}
	 \vspace{-6mm}
\end{figure*}


\begin{figure*}[!t]
	\centering
 \subfloat[{SG+Wheel}]
	{\centering\includegraphics[scale=0.22]{png/Wheel-g.png}}
\,	
 \subfloat[{FC}]
	{\centering \includegraphics[scale=0.22]{png/FC-g.png}} 
	\caption{Certified perturbation size over all testing graphs vs. $\gamma$ on PGExplainer.} 
	\label{fig:CEA_gamma_PG-2}
	 \vspace{-6mm}
\end{figure*}


\begin{figure*}[!t]
	\centering
 \subfloat[{SG+House}]
	{\centering\includegraphics[scale=0.22]{png/House-h.png}}
 \,
	\subfloat[{SG+Diamond}]
	{\centering \includegraphics[scale=0.22]{png/Diamond-h.png}}
\,
 \subfloat[{SG+Wheel}]
	{\centering\includegraphics[scale=0.22]{png/Wheel-h.png}}
 \,
 \vspace{-4mm}
\\
 \subfloat[{Beneze}]
	{\centering\includegraphics[scale=0.22]{png/Benzene-h.png}}
\,	
 \subfloat[{FC}]
	{\centering \includegraphics[scale=0.22]{png/FC-h.png}} 
	\caption{Certified perturbation size over all testing graphs vs. $h$ on PGExplainer.} 
	\label{fig:CEA_h_PG}
	 \vspace{-2mm}
\end{figure*}

\begin{figure*}[t]
	\centering
    \captionsetup[subfloat]{labelsep=none,format=plain,labelformat=empty,farskip=0pt}
\subfloat[{Ground-Truth}]{
 \subfloat[{House}]{
	{\centering\includegraphics[scale=0.16]{prechange/House-GT.png}}}
 \,
 \subfloat[{Diamond}]{
	{\centering\includegraphics[scale=0.16]{prechange/Diamond-GT.png}}}
 \,
 \subfloat[{Wheel}]{
	{\centering\includegraphics[scale=0.16]{prechange/Wheel-GT.png}}}
 
 \,
 \subfloat[{Benzene}]{
	{\centering\includegraphics[scale=0.16]{prechange/GT.png}}}
 
 \,
 \subfloat[{FC}]{
	{\centering\includegraphics[scale=0.16]{prechange/FC-GT.png}}}
 }
 \\
\subfloat[{Original Explanation}]{
 \subfloat[{House}]{
	{\centering\includegraphics[scale=0.16]{prechange/House-EX.png}}}
 \,
 \subfloat[{Diamond}]{
	{\centering\includegraphics[scale=0.16]{prechange/Diamond-EX.png}}}
 \,
 \subfloat[{Wheel}]{
	{\centering\includegraphics[scale=0.16]{prechange/Wheel-EX.png}}}
 
 \,
 \subfloat[{Benzene}]{
	{\centering\includegraphics[scale=0.16]{prechange/EX.png}}}
 
 \,
 \subfloat[{FC}]{
	{\centering\includegraphics[scale=0.16]{prechange/FC-EX.png}}}
 }
 \\
\subfloat[{GNN Deceived Explanation}]{
 \subfloat[{House}]{
	{\centering\includegraphics[scale=0.16]{prechange/House-AT.png}}}
 \,
 \subfloat[{Diamond}]{
	{\centering\includegraphics[scale=0.16]{prechange/Diamond-AT.png}}}
 \,
 \subfloat[{Wheel}]{
	{\centering\includegraphics[scale=0.16]{prechange/Wheel-AT.png}}}
 
 \,
 \subfloat[{Benzene}]{
	{\centering\includegraphics[scale=0.16]{prechange/AT.png}}}
 
 \,
 \subfloat[{FC}]{
	{\centering\includegraphics[scale=0.16]{prechange/FC-AT.png}}}
 }
	\caption{Examples of how an explanatory subgraph outputted by PGExplainer changes when GNN is deceived. Top Row: Groundtruth Explanation; Middle Row: Explanation under correct predictions; Bottom Row: Explanation when GNN is deceived by a graph perturbation (2 edges are perturbed). 
 } 
	\vspace{-4mm}
  \label{fig:deceive}
\end{figure*}


\section{Discussion}
\label{app:discussion}

{\bf Instability of GNN explainers:}
We conduct experiments on the well-known GNNExplainer~\citep{GNNEx19} to show its unstable explanation results. Particularly, we run it 5 times and show the explanation results in Table~\ref{tab:instable}, where “Std” is the Standard Deviation of the explanation accuracy on test data across the 5 runs, and “Change Rate” is the average fraction of different explanation edges among every pair of the 5 runs. 
We can see both the variance and change rate are  large, meaning it is unreliable and difficult to pick any run of the result to design the robust explainer. 

\begin{table}[!h]
    \centering
    \begin{tabular}{c|c|c|c|c|c}
    \toprule
    Dataset&SG+House&SG+Diamond&SG+Wheel&Benzene&FC\\
    
    \Xhline{0.8pt} 
    Exp. Accuracy&0.624&0.368&0.475&0.276&0.226 \\
    \cline{1-6}
    Std& 9.3\%&9.7\%&8.1\%&10.9\%&12.4\%\\
    \cline{1-6}
    Change Rate&36.8\%&64.0\%&51.6\%&72.6\%&76.9\%\\
    \bottomrule
    \end{tabular}
    \caption{Instability of GNNExplainer}
    \label{tab:instable}
\end{table}


\begin{table}[!ht]
    \centering
    \renewcommand{\arraystretch}{1.2}
    \begin{tabular}{c|c|c|c|c}
        \hline
        \textbf{Dataset} & \textbf{Pred. Acc. (Avg)} & \textbf{Pred. Acc. (Std)} & \textbf{Exp. Acc. (Avg)} & \textbf{Exp. Acc. (Std)} \\ \hline
        Benzene & 0.722 & 0.002 & 0.466 & 0.007 \\ \hline
        FC      & 0.682 & 0.012 & 0.358 & 0.037 \\ \hline
    \end{tabular}
    \caption{Averaged prediction and explanation accuracy of XGNNCert on the two real-world datasets with 5 random node orderings.}
    \label{tab:gnncert_runs}
\end{table}


{\bf Node-order invariant vs. variant GNNs:} There exist both node-order invariant GNNs  (whose outputs are insensitive to the node ordering) and node-order variant GNNs  (whose outputs depend on the node ordering). Node-order invariant GNNs typically use, e.g., the mean and convolution aggregator such as  GCN~\citep{kipf2017semi}, SGC~\citep{wu2019simplifying}, GIN~\citep{xu2018powerful}, GAT~\citep{velivckovic2018graph}, GSAGE-mean~\citep{hamilton2017inductive}). 
Node-order variant GNNs are based on, e.g., random neighbor sampling~\citep{papp2021dropgnn,Rong2020DropEdge,Zeng2020GraphSAINT}, LSTM aggregator~\citep{hamilton2017inductive}, relational pooling~\citep{murphy2019relational}, positional embedding ~\citep{dwivedi2022graph,kreuzer2021rethinking,zhu2023hierarchical}. 

While node-order invariant GNNs are desirable in certain cases, recent works ~\citep{Loukas2020What,papp2021dropgnn,huang2022going} show node-order variant GNNs can produce better expressivity. This ranges from the classic GSAGE with LSTM to modern graph transformers~\citep{kreuzer2021rethinking,zhu2023hierarchical}. Our GNN voting classifier is node-order variant due to the property of hash function.  

{To further explore the impact of node permutations on {\name}, we randomly permute the input graphs 5 times and report {\name}'s average prediction and explanation accuracies on the two real-world datasets under the default setting in Table~\ref{tab:gnncert_runs}.  
We observe that {\name} exhibits stable prediction and explanation accuracies across the 5 runs. This demonstrates that, though {\name} is not inherently permutation invariant, its classification and explanation performance remain relatively stable to node permutations. 
We hypothesize that one possible reason for this stability is that {\name} augments the training graphs with a set of subgraphs to train the GNN classifier. This augmentation may mitigate the effect of node ordering, as the subgraphs are much smaller in size.}


{\bf Can this framework be extended to node-level or edge-level tasks?} Theoretically, it is possible, but needs technique adaptation. For example, in the node-level task, we are given a target node and its prediction by a GNN model, then GNN explainers aim to find the subgraph (usually from the target node’s neighboring graph) that is most important for the target node’s prediction. When applying the proposed framework for certifying node-level explainers, it becomes designing a graph division and voting strategy such that: with an arbitrary graph perturbation under a perturbation budget, 1) the voting classifier guarantees the correct prediction for \emph{the target node} on the perturbed graph, and 2) the voting explainer guarantees the explanation results on the perturbed graph and clean graph are close. The current graph division strategy is not applicable as all subgraphs have disjoint nodes, while the target node should be contained in all subgraphs for the node-level task. Hence, a key challenge is how to adapt the graph division and voting strategy to satisfy 1) and 2), particularly guaranteeing only a bounded number of subgraphs is affected when predicting the target node, while the explanations of these subgraphs' predictions are also retained. We acknowledge it is interesting future work to extend the proposed framework specially for node/edge-level explanation tasks. 


\clearpage
\newpage 
