@inproceedings{DBLP:journals/corr/abs-2011-04573/PGExplainer,
author = {Luo, Dongsheng and Cheng, Wei and Xu, Dongkuan and Yu, Wenchao and Zong, Bo and Chen, Haifeng and Zhang, Xiang},
title = {Parameterized Explainer for Graph Neural Network},
year = {2020},
booktitle = {NeurIPS}
}

@InProceedings{GEM,
  title = 	 {Generative Causal Explanations for Graph Neural Networks},
  author =       {Lin, Wanyu and Lan, Hao and Li, Baochun},
  booktitle = 	 {ICML},
  year = 	 {2021}
}

@incollection{GNNEx19,
title = {{GNNE}xplainer: Generating Explanations for Graph Neural Networks},
author = {Ying, Zhitao and Bourgeois, Dylan and You, Jiaxuan and Zitnik, Marinka and Leskovec, Jure},
booktitle = {NeurIPS},
year = {2019}
}

@article{Wang_2023/RCExplainer,
	year = 2023,
	pages = {2297--2309},
  
	author = {Xiang Wang and Yingxin Wu and An Zhang and Fuli Feng and Xiangnan He and Tat-Seng Chua},
  
	title = {Reinforced Causal Explainer for Graph Neural Networks},
  
	journal = {{IEEE} TPAMI}
}

@article{baldassarre2019explainability,
  title={Explainability techniques for graph convolutional networks},
  author={Baldassarre, Federico and Azizpour, Hossein},
  journal={ICML Workshop},
  year={2019}
}

@inproceedings{behnam2024graph,
  title={Graph Neural Network Causal Explanation via Neural Causal Models},
  author={Behnam, Arman and Wang, Binghui},
  booktitle={ECCV},
  year={2024}
}

@inproceedings{bojchevski2020efficient,
  title={Efficient robustness certificates for discrete data: Sparsity-aware randomized smoothing for graphs, images and more},
  author={Bojchevski, Aleksandar and Gasteiger, Johannes and G{\"u}nnemann, Stephan},
  booktitle={ICML},
  year={2020}
}

@article{cohen2019certified,
  title={Certified adversarial robustness via randomized smoothing},
  author={Cohen, Jeremy M and Rosenfeld, Elan and Kolter, J Zico},
  journal={arXiv preprint arXiv:1902.02918},
  year={2019}
}

@inproceedings{dai2018adversarial,
  title={Adversarial attack on graph structured data},
  author={Dai, Hanjun and Li, Hui and Tian, Tian and Huang, Xin and Wang, Lin and Zhu, Jun and Song, Le},
  booktitle={ICML},
  year={2018}
}

@inproceedings{feng2023degree,
  title={Degree: Decomposition based explanation for graph neural networks},
  author={Feng, Qizhang and Liu, Ninghao and Yang, Fan and Tang, Ruixiang and Du, Mengnan and Hu, Xia},
  booktitle={ICLR},
  year={2022}
}

@article{funke2022zorro,
  title={Zorro: Valid, sparse, and stable explanations in graph neural networks},
  author={Funke, Thorben and Khosla, Megha and Rathee, Mandeep and Anand, Avishek},
  journal={IEEE TKDE},
  year={2022}
}

@inproceedings{hammoudeh2023feature,
  title={Feature Partition Aggregation: A Fast Certified Defense Against a Union of L\_0 Attacks},
  author={Hammoudeh, Zayd and Lowd, Daniel},
  booktitle={The Second Workshop on New Frontiers in Adversarial ML},
  year={2023}
}

@inproceedings{hong2022unicr,
  title={Unicr: Universally approximated certified robustness via randomized smoothing},
  author={Hong, Hanbin and Wang, Binghui and Hong, Yuan},
  booktitle={ECCV},
  year={2022}
}

@inproceedings{jia2021intrinsic,
  title={Intrinsic certified robustness of bagging against data poisoning attacks},
  author={Jia, Jinyuan and Cao, Xiaoyu and Gong, Neil Zhenqiang},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  year={2021}
}

@inproceedings{jia2022certified,
  title={Certified robustness of nearest neighbors against data poisoning and backdoor attacks},
  author={Jia, Jinyuan and Liu, Yupei and Cao, Xiaoyu and Gong, Neil Zhenqiang},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  year={2022}
}

@inproceedings{lecuyer2019certified,
  title={Certified robustness to adversarial examples with differential privacy},
  author={Lecuyer, Mathias and Atlidakis, Vaggelis and Geambasu, Roxana and Hsu, Daniel and Jana, Suman},
  booktitle={2019 IEEE Symposium on Security and Privacy (SP)},
  pages={656--672},
  year={2019},
  organization={IEEE}
}

@article{levine2019certifiably,
  title={Certifiably robust interpretation in deep learning},
  author={Levine, Alexander and Singla, Sahil and Feizi, Soheil},
  journal={arXiv preprint arXiv:1905.12105},
  year={2019}
}

@inproceedings{levine2020deep,
  title={Deep Partition Aggregation: Provable Defenses against General Poisoning Attacks},
  author={Levine, Alexander and Feizi, Soheil},
  booktitle={ICLR},
  year={2020}
}

@inproceedings{levine2020randomized,
  title={(De) Randomized smoothing for certifiable defense against patch attacks},
  author={Levine, Alexander and Feizi, Soheil},
  booktitle={NeurIPS},
  year={2020}
}

@inproceedings{levine2020robustness,
  title={Robustness certificates for sparse adversarial attacks by randomized ablation},
  author={Levine, Alexander and Feizi, Soheil},
  booktitle={AAAI},
  year={2020}
}

@inproceedings{li2025agnncert,
  title={AGNNCert: Defending Graph Neural Networks against Arbitrary Perturbations with Deterministic Certification},
  author={Li, Jiate and Wang, Binghui},
  booktitle={USENIX Security},
  year={2025}
}

@article{liu2022certifiably,
  title={Certifiably robust interpretation via R{\'e}nyi differential privacy},
  author={Liu, Ao and Chen, Xiaoyu and Liu, Sijia and Xia, Lirong and Gan, Chuang},
  journal={Artificial Intelligence},
  volume={313},
  pages={103787},
  year={2022},
  publisher={Elsevier}
}

@inproceedings{ma2020towards,
  title={Towards More Practical Adversarial Attacks on Graph Neural Networks},
  author={Ma, Jiaqi and Ding, Shuangrui and Mei, Qiaozhu},
  booktitle={NeurIPS},
  year={2020}
}

@inproceedings{mu2021hard,
  title={A Hard Label Black-box Adversarial Attack Against Graph Neural Networks},
  author={Mu, Jiaming and Wang, Binghui and Li, Qi and Sun, Kun and Xu, Mingwei and Liu, Zhuotao},
  booktitle={CCS},
  year={2021}
}

@inproceedings{pereira2023distill,
  title={Distill nâ€™Explain: explaining graph neural networks using simple surrogates},
  author={Pereira, Tamara and Nascimento, Erik and Resck, Lucas E and Mesquita, Diego and Souza, Amauri},
  booktitle={AISTATS},
  year={2023}
}

@inproceedings{pope2019explainability,
  title={Explainability methods for graph convolutional neural networks},
  author={Pope, Phillip E and Kolouri, Soheil and Rostami, Mohammad and Martin, Charles E and Hoffmann, Heiko},
  booktitle={CVPR},
  year={2019}
}

@article{schnake2021higher,
  title={Higher-order explanations of graph neural networks via relevant walks},
  author={Schnake, Thomas and Eberle, Oliver and Lederer, Jonas and Nakajima, Shinichi and Sch{\"u}tt, Kristof T and M{\"u}ller, Klaus-Robert and Montavon, Gr{\'e}goire},
  journal={IEEE TPAMI},
  year={2021}
}

@inproceedings{shan2021reinforcement/RGExplainer,
author = {Shan, Caihua and Shen, Yifei and Zhang, Yao and Li, Xiang and Li, Dongsheng},
title = {Reinforcement Learning Enhanced Explainer for Graph Neural Networks},
booktitle = {NeurIPS 2021},
year = {2021},
month = {December},
abstract = {Graph neural networks (GNNs) have recently emerged as revolutionary technologies for machine learning tasks on graphs. In GNNs, the graph structure is generally incorporated with node representation via the message passing scheme, making the explanation much more challenging. Given a trained GNN model, a GNN explainer aims to identify a most influential subgraph to interpret the prediction of an instance (e.g., a node or a graph), which is essentially a combinatorial optimization problem over graph. The existing works solve this problem by continuous relaxation or search-based heuristics. But they suffer from key issues such as violation of message passing and hand-crafted heuristics, leading to inferior interpretability. To address these issues, we propose a RL-enhanced GNN explainer, RG-Explainer, which consists of three main components: starting point selection, iterative graph generation and stopping criteria learning. RG-Explainer could construct a connected explanatory subgraph by sequentially adding nodes from the boundary of the current generated graph, which is consistent with the message passing scheme. Further, we design an effective seed locator to select the starting point, and learn stopping criteria to generate superior explanations. Extensive experiments on both synthetic and real datasets show that RG-Explainer outperforms state-of-the-art GNN explainers. Moreover, RG-Explainer can be applied in the inductive setting, demonstrating its better generalization ability.},
}

@inproceedings{sui2022causal,
  title={Causal attention for interpretable and generalizable graph classification},
  author={Sui, Yongduo and Wang, Xiang and Wu, Jiancan and Lin, Min and He, Xiangnan and Chua, Tat-Seng},
  booktitle={KDD},
  year={2022}
}

@inproceedings{tan2023robust,
  title={Robust explanation for free or at the cost of faithfulness},
  author={Tan, Zeren and Tian, Yang},
  booktitle={ICML},
  year={2023}
}

@inproceedings{vu2020pgm,
  title={Pgm-explainer: Probabilistic graphical model explanations for graph neural networks},
  author={Vu, Minh and Thai, My T},
  booktitle={NeurIPS},
  year={2020}
}

@inproceedings{wang2019attacking,
  title={Attacking Graph-based Classification via Manipulating the Graph Structure},
  author={Wang, Binghui and Gong, Neil Zhenqiang},
  booktitle={CCS},
  year={2019}
}

@inproceedings{wang2021certified,
  title={Certified robustness of graph neural networks against adversarial structural perturbation},
  author={Wang, Binghui and Jia, Jinyuan and Cao, Xiaoyu and Gong, Neil Zhenqiang},
  booktitle={KDD},
  year={2021}
}

@inproceedings{wang2021towards,
  title={Towards multi-grained explainability for graph neural networks},
  author={Wang, Xiang and Wu, Yingxin and Zhang, An and He, Xiangnan and Chua, Tat-Seng},
  booktitle={NeurIPS},
  volume={34},
  pages={18446--18458},
  year={2021}
}

@inproceedings{wang2022bandits,
  title={Bandits for structure perturbation-based black-box attacks to graph neural networks with theoretical guarantees},
  author={Wang, Binghui and Li, Youqi and Zhou, Pan},
  booktitle={CVPR},
  year={2022}
}

@inproceedings{wang2022improved,
  title={Improved certified defenses against data poisoning with (deterministic) finite aggregation},
  author={Wang, Wenxiao and Levine, Alexander J and Feizi, Soheil},
  booktitle={ICML},
  pages={22769--22783},
  year={2022},
  organization={PMLR}
}

@inproceedings{wang2023turning,
  title={Turning Strengths into Weaknesses: A Certified Robustness Inspired Attack Framework against Graph Neural Networks},
  author={Wang, Binghui and Pang, Meng and Dong, Yun},
  booktitle={CVPR},
  year={2023}
}

@inproceedings{wang2024efficient,
  title={Efficient, Direct, and Restricted Black-Box Graph Evasion Attacks to Any-Layer Graph Neural Networks via Influence Function},
  author={Wang, Binghui and Lin, Minhua and Zhou, Tianxiang and Zhou, Pan and Li, Ang and Pang, Meng and Li, Hai and Chen, Yiran},
  booktitle={WSDM},
  year={2024}
}

@inproceedings{xia2021causal,
  title={The causal-neural connection: Expressiveness, learnability, and inference},
  author={Xia, Kevin and Lee, Kai-Zhan and Bengio, Yoshua and Bareinboim, Elias},
  booktitle={NeurIPS},
  year={2021}
}

@inproceedings{xia2024gnncert,
  title={GNNCERT: DETERMINISTIC CERTIFICATION OF
GRAPH NEURAL NETWORKS AGAINST ADVERSARIAL
PERTURBATIONS},
  author={Xia, Zaishuo and Yang, Han and Wang, Binghui and Jia, Jinyuan},
  booktitle={ICLR},
  year={2024}
}

@inproceedings{xiang2021patchguard,
  title={$\{$PatchGuard$\}$: A provably robust defense against adversarial patches via small receptive fields and masking},
  author={Xiang, Chong and Bhagoji, Arjun Nitin and Sehwag, Vikash and Mittal, Prateek},
  booktitle={USENIX Security},
  year={2021}
}

@inproceedings{xu2019topology,
  title={Topology attack and defense for graph neural networks: An optimization perspective},
  author={Xu, Kaidi and Chen, Hongge and Liu, Sijia and Chen, Pin-Yu and Weng, Tsui-Wei and Hong, Mingyi and Lin, Xue},
  booktitle={IJCAI},
  year={2019}
}

@inproceedings{zhang2021backdoor,
  title={Backdoor attacks to graph neural networks},
  author={Zhang, Zaixi and Jia, Jinyuan and Wang, Binghui and Gong, Neil Zhenqiang},
  booktitle={SACMAT},
  year={2021}
}

@inproceedings{zhang2023pointcert,
  title={PointCert: Point Cloud Classification with Deterministic Certified Robustness Guarantees},
  author={Zhang, Jinghuai and Jia, Jinyuan and Liu, Hongbin and Gong, Neil Zhenqiang},
  booktitle={CVPR},
  year={2023}
}

@inproceedings{zugner2018adversarial,
  title={Adversarial Attacks on Neural Networks for Graph Data},
  author={Z{\"u}gner, Daniel and Akbarnejad, Amir and G{\"u}nnemann, Stephan},
  booktitle={SIGKDD},
  pages={2847--2856},
  year={2018},
}

@inproceedings{zugner2019adversarial,
  title={Adversarial attacks on graph neural networks via meta learning},
  author={Z{\"u}gner, Daniel and G{\"u}nnemann, Stephan},
  booktitle={ICLR},
  year={2019}
}

