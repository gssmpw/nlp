\section{{\name}: Our Certifiably Robust XGNN}
\label{sec:xgnncert}

\vspace{-2mm}
In this section, we propose  {\name}, our certifiably robust XGNN against graph perturbation attacks.   
Given a testing graph, a GNN classifier, and a GNN explainer, {\name} consists of three major steps. 
\emph{1) Hybrid subgraphs generation:} it aims to generate a set of subgraphs that leverage  the edges from both the testing graph and its  complete graph. 
\emph{2) Majority-voting based classification and explanation:} it builds a majority-vote based classifier (called voting classifier) on GNN predictions for the hybrid subgraphs,
as well as a majority-vote based explainer (called voting explainer) on GNN explanations for interpreting the predicted label of the hybrid subgraphs. 
\emph{3) Deriving the certified robustness guarantee:} based on the generated subgraphs, our voting classifier and voting explainer, it derives the maximum perturbed edges, such that our voting classifier guarantees the same prediction on the perturbed graph and testing graph, and our voting explainer guarantees the explanation results on the perturbed graph and the clean graph are close.
 Figure~\ref{fig:overview} shows an overview of our {\name}. 

\begin{figure}[t]
\vspace{-4mm}
    \centering
    \captionsetup[subfloat]{labelsep=none, format=plain, labelformat=empty}

    \includegraphics[width=\linewidth]{overview-new.jpg}
    \vspace{-4mm}
    \caption{Overview of the proposed three-step certifiably robust XGNN.
    }
    \label{fig:overview}
   \vspace{-2mm}
\end{figure}

\subsection{Hybrid Subgraphs Generation}
\label{sec:Hybrid}
A straightforward idea is to adapt the existing defense strategy for  classification~\citep{levine2020randomized,xiang2021patchguard, jia2021intrinsic,jia2022certified,xia2024gnncert} that divides an input into multiple \emph{non-overlapping} parts. 
Particularly, one can divide a graph into multiple non-overlapping subgraphs, such that only a bounded number of  subgraphs are affected when the graph is adversarially perturbed under a bounded perturbation. 
However, this strategy does not work well to robustify GNN explanation (Our results in Section~\ref{sec:eval} also validate this) due to two reasons: 
(1) Every edge in a graph appears only once in all subgraphs. This  makes it hard for the GNN explainer to ensure the groundtruth explanatory edges to have higher scores than non-explanatory edges. 
(2) All subgraphs only contain existent edges in the graph, while nonexistent edges can be inserted into the graph during the attack and their importance for explanation needs to be also considered. 
To address the challenge, we develop a hybrid subgraph generation method, that consists of two steps shown below.  

{\bf Generating Subgraph Indexes via Hash Mapping:} 
We use the hash function (e.g., MD5) to generate the subgraph indexes {as done in \citet{xia2024gnncert,yang2024distributed}}\footnote{Our theoretical results require the graph division function has two important properties: 1) It is deterministic, such that each edge and node in a graph is deterministically mapped into only one subgraph. This property is the core to derive our theoretical results.  2) It is independent of the graph structure, as otherwise an attacker may reverse-engineer the function to find the relation between the output and input, and possibly break the defense. The used hash function can achieve both properties.}. A hash function takes input as a bit string and outputs an integer (e.g., within a range $[0,2^{128}-1]$). Here, we propose to use the string of edge index as the input to the hash function. For instance, for an edge $e=(u,v)$, we denote its string as $\textrm{str}(u)+\textrm{str}(v)$, where {the $\textrm{str}(\cdot)$ function  transfers the index number into a string in a fixed length (filled with prefix "0"s)}, and``+" means the string concatenation\footnote{For instance, with a 4-bit length, an edge 12-21 is represented as the string "0012" and "0021", respectively. Then the concatenated string between the edge 12-21 is "00120021".}. 
Then we can map each edge using the hash function to a unique index.
Specifically, we denote the hash function as $h$ and assume $T$ groups 
in total. Then for every edge $e=(u,v)$, we compute its subgraph index $i_e$ as\footnote{We put the node with a smaller index (say  $u$) first and let 
$h[\mathrm{str}(v) + \mathrm{str}(u)]=h[\mathrm{str}(u) + \mathrm{str}(v)]$.}. 
\begin{align}
\label{eqn:hashidx}
i_e = h[\mathrm{str}(u) + \mathrm{str}(v)] \, \, \mathrm{mod} \, \, T+1. 
\end{align}


{\bf Generating Hybrid Subgraphs:} Based on the hash function, we can construct a set of $T$ subgraphs for any graph. However, instead of only using existent edges in the given graph to construct subgraphs, we propose to also use \emph{nonexistent edges} to promote the robustness performance for GNN explainers. \emph{A key requirement is: how to guarantee only a bounded number of subgraphs are affected when the original graph is adversarially perturbed.} To address it, we innovatively propose to use the \emph{complete graph},
and our theoretical results in Theorem~\ref{thm:bounddiff} show the requirement can be satisfied.

\emph{Dividing the input graph into subgraphs:} 
For an input graph $G=(\mathcal{V},\mathcal{E})$, we use 
$\mathcal{E}^i$ to denote the set of edges whose subgraph index is $i$, i.e., 
$\mathcal{E}^i = \{\forall e \in \mathcal{E}: i_e= i \}.$ 
Then, we can construct $T$ subgraphs for $G$ as $\{ {G}^i = (\mathcal{V}, \mathcal{E}^i): i=1,2,\cdots, T\}$. 

\emph{Dividing the complete graph into subgraphs:} 
We denote the complete graph of $G$ as $G_C = (\mathcal{V}, \mathcal{E}_C), \mathcal{E}_{C}=\{(u,v), \forall u,v\in \mathcal{V}: u<v\}$. Similarly,  we can divide  $G_C$ into $T$ subgraphs using the same hash function. 
First, the edges having a subgraph index $i$ is denoted as $\mathcal{E}^{i}_{C} = \{\forall e \in \mathcal{E}_{C}: i_{e}=i\}$. Then, we create the $T$ subgraphs for $G_C$ as: $\{{G}_C^i = (\mathcal{V}, \mathcal{E}_C^i): i=1,2,\cdots, T\}$. 

\emph{Hybrid subgraphs:} Now we combine subgraphs $\{G^i\}$ with $\{G_C^i\}$ to construct the hybrid subgraphs. 
For each subgraph $G^i$, we propose to combine it with a fraction (say $p$) of the subgraphs in $\{G_C^i\}$ to generate a hybrid subgraph, denoted as $G_H^i$. There are many ways for the combination, and the only constraint is that the subgraph $G_C^i$ with the same subgraph index $i$ as $G^i$ is not chosen in  $G_H^i$, in order to maintain the information from the original subgraph $G^i$ (otherwise it is overlaid by $G_C^i$). 
Let $\mathcal{T}_{-i} = \mathcal{T}\setminus{i}$ be the index set not including $i$. For instance, we can choose $\lfloor pT\rfloor$ indexes, denoted as $\mathcal{T}_{-i}^p$, from $\mathcal{T}_{-i}$ uniformly at random. 
Then a constructed hybrid subgraph is  $G_H^i = (\mathcal{V}, {\mathcal{E}}_H^{i})$, where 
\begin{align}\label{eq:hybrid}
{\mathcal{E}}_H^{i} =   (\cup_{j \in \mathcal{T}_{-i}^p} \mathcal{E}^{j}_{C})\cup \mathcal{E}^{i}.  
\end{align}
Note that a too small or too large $p$ would degrade the explanation performance. This is because a too large $p$ would make excessive nonexistent edges be added in each $G_H^i$, and a too small $p$ would make explanatory edges be difficult to have higher important scores than non-explanatory edges. Our results show the best performance is often achieved with a modest $p$, e.g., $p \in [0.2,0.4]$.

With the built hybrid subgraphs, we prove in Theorem~\ref{thm:bounddiff} that for any two graphs with $M$ different edges (but same nodes), there are at most $M$ different ones between their respective hybrid subgraphs. 
\emph{We emphasize this is the key property to derive our certified robustness guarantee in Section~\ref{sec:Certify}.}   

\begin{theorem}
[Bounded number of different subgraphs]
\label{thm:bounddiff}
For any two graphs $G=(\mathcal{V},\mathcal{E})$, $\hat{G}=(\mathcal{V}, \hat{\mathcal{E}})$ satisfying $|\mathcal{E}\setminus \hat{\mathcal{E}}| = M$. 
The corresponding hybrid subgraphs generated using the above strategy are denoted as  $\{ G_H^i\}$ and $\{ \hat{G}_H^i\}$, respectively. 
Then $\{ G_H^i\}$ and $\{ \hat{G}_H^i\}$ have at most $M$ different graphs. 
\vspace{-2mm}
\end{theorem}
\begin{proof}
See Appendix~\ref{app:thm:bounddiff}.
\end{proof}


\subsection{Majority Voting-based Classification and Explanation}
\label{sec:Voting}

Inspired by existing works~\citep{levine2020randomized,jia2022certified,xia2024gnncert,yang2024distributed}, we propose to use the majority vote to aggregate the results on the hybrid subgraphs. 
We then design a voting classifier and voting explainer that can respectively act as the robust GNN classifier and robust GNN explainer, as expected. 
Assume we have a testing graph $G$ with label $y$, a set of $T$ hybrid subgraphs $\{G_H^{i}\}$ built from $G$, a GNN classifier $f$, and a GNN explainer $g$.  

{\bf Voting Classifier:} 
We denote by $n_c$ the votes of hybrid subgraphs classified as the label $c$ by $f$, i.e., 
{\begin{align}
\small
\label{eqn:labelcount}
n_c = \sum_{i=1}^{T}\mathbb{I}(f(G_H^{i})=c), \forall c \in \mathcal{C},
\end{align}}
where $\mathbb{I}(\cdot)$ is an indicator function.  Then, we define 
our voting classifier $\bar{f}$\footnote{$\bar{f}$ returns a smaller label index when ties exist.} as: 
\begin{align}
\bar{f}(G) = \underset{c \in \mathcal{C}}{{\arg\max}} \, n_c.
\vspace{-2mm}
\end{align}

{\bf Voting Explainer:} 
Recall that when a GNN explainer interprets the predicted label for a graph, it first learns the importance scores for all edges in this graph and then selects the edges with the highest scores as the explanatory edges. 
Motivated by this, we apply $g$ on the hybrid subgraphs  having the same predicted label as the majority-voted label to obtain the explanatory edges,
and then vote the explanatory edges from these hybrid subgraphs. 
Edges with top-$k$ scores are the final explanatory edges. 
Specifically, for each $G_H^{i}$, we apply $g$ to obtain its edges' importance scores $\textbf{m}^{i}=g(G_H^{i},\bar{f}(G))$.  
We define the votes ${n}_{e}^\gamma$ of each edge $e \in \mathcal{E}_{C}$ as the times that its importance score ${m}_{e}^{i}$ is no less than $\gamma$ fraction of the largest scores in every hybrid subgraph $G_H^{i}$ with the prediction $f(G_H^{i})= \bar{f}(G)$: 
{
\begin{align}
\label{eqn:votes}
{n}_{e}^\gamma = \sum_{i=1}^{T} \mathbb{I}({m}_{e}^{i} \geq {\bf m}_{(\gamma)}^{i}) \cdot \mathbb{I}(f(G_H^{i})= \bar{f}(G)), \forall e \in \mathcal{E}_{C},   
\end{align}
}
where ${\bf x}_{(\gamma)}$ means the $\gamma \cdot \texttt{size}({\bf x})$ largest element in ${\bf x}$ and $\gamma$ is a tuning hyperparameter (we will study its impact in our experiments). We denote  $\textbf{n}^{\gamma}$ as the set of votes for all edges in $\mathcal{E}_C$.  Then we define our voting explainer $\bar{g}^{\gamma}$ as outputting the edges from $G$ with the top-$k$ scores in $\textbf{n}^{\gamma}$\footnote{When two edges have the same $\textbf{n}^{\gamma}$, the edge with a smaller index is selected by $\bar{g}^{\gamma}$.}:
\begin{align}
\bar{g}^{\gamma}(G,\bar{f}(G)) = \mathcal{E}.top_{k}(\textbf{n}^{\gamma}).   
\end{align}

{ 
\emph{Remark:}
Traditional GNN classifiers are designed to be node permutation invariant \citep{kipf2017semi,velivckovic2018graph,xu2018powerful}, meaning that the model’s predictions remain consistent regardless of how the nodes in the graph are permuted.
In contrast, our voting classifier is node permutation variant due to the properties of the hash function. This implies that both the classification and explanation performances of {\name} may vary depending on the node ordering. However, we empirically observed that {\name}'s performance remains relatively stable across different node permutations (see Table \ref{tab:gnncert_runs} in Appendix \ref{app:discussion}). 
Moreover, recent studies \citep{Loukas2020What,papp2021dropgnn,huang2022going} suggest that node-order sensitivity can actually enhance the expressivity and generalization capabilities of GNNs. Additional discussions are provided in Appendix \ref{app:discussion}.
}


\subsection{Certified Robustness Guarantee}
\label{sec:Certify}
%\vspace{-2mm}
In this section, we derive the certified robustness guarantee against graph perturbation attacks using our graph division strategy and introduced robust voting classifier and voting explainer. 

We first define some notations. We let $y = \bar{f}(G)$ by assuming the voting classifier $\bar{f}$ has an accurate label prediction, and $\mathcal{E}_k = \bar{g}^{\gamma}(G,y)$ by assuming the voting explainer $\bar{g}$  has an accurate explanation.  
We denote $\bar{G} = (\mathcal{V}, \bar{\mathcal{E}})$ as the complement of $G$, and $\bar{\mathcal{E}}_M$ the edges  in $\bar{\mathcal{E}}$ with top-$M$ scores in $\textbf{n}^{\gamma}$. 
{We introduce the non-existent edges $\bar{\mathcal{E}}_M$ with top scores by considering that, in the worst-case attack with $M$ edge perturbations, $\bar{\mathcal{E}}_{M}$ would be chosen to compete with the true explanatory edges.} 


\begin{theorem}
[Certified Perturbation Size $M_\lambda$ for a given $\lambda$] 
\label{thm:VerifyExp} 
Assume $y \in \mathcal{C}$ and ${b} \in \mathcal{C} \setminus \{y\}$ be the class with the highest votes $n_y$ and second highest votes by Eqn (\ref{eqn:labelcount}), respectively. 
 Assume further the edge $l \in \mathcal{E}_k$ is with the $\lambda$-th highest votes $n_{l}^{\gamma}$, and edge $h_M \in \bar{\mathcal{E}}_M \cup (\mathcal{E} \setminus \mathcal{E}_k)$ with the $(k-\lambda+1)$-th highest votes ${n}_{h_M}^{\gamma}$ in ${\textbf{n}}^{\gamma}$ by Eqn (\ref{eqn:votes}) ($h_M$ hence depends on $M$). Then $M_{\lambda}$ satisfies: 
\begin{align}
\label{eqn:CPS}
& M_\lambda \leq M^*= \min \big( \lfloor \frac{n_y-n_{b} + \mathbb{I}(y<b)-1}{2} \rfloor, M_h), \textrm{ where } \\ 
& M_h = \max \, M,  \quad {s.t.} \quad {n}_{l}^\gamma- {n}_{h_M}^\gamma + \mathbb{I}(l<h_M) > 2M. \label{Eq:ExpCondition}
\end{align}

\vspace{-4mm}
\end{theorem}
\begin{proof}
See Appendix \ref{app:thm:VerifyExp}. 
\vspace{-2mm}
\end{proof}

\emph{Remark:} We have the following remarks from Theorem~\ref{thm:VerifyExp}:
\begin{itemize}[leftmargin=*]
\vspace{-2mm}
\item Our voting classifier and voting explainer can tolerate  $M^*$\footnote{{In general, $M^* \leq M^*_\lambda$ in Def.~\ref{def:certxgnn}. 
We will leave it as future work to prove whether the derived $M^*$ is tight. 
}} perturbed edges. 

\item Our voting classifier can be applied for \emph{any} GNN classifier and our voting explainer for any GNN explainer that outputs edge importance score.

\item Our certified robustness guarantee is deterministic, i.e., it is true with a probability of 1.  

\end{itemize}

