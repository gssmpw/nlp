\section{Identification of Truncation Region}
\label{app:truncation}
In general, it is difficult to identify the truncation region $\mathcal{Z}$ in~(\ref{truncatedarea}) directly 
because conditioning only on the result of the CP candidate selection, i.e., $\mathcal{A}(\bm{a} + \bm{b}z) = \mathcal{A}(\bm{x})$, is intractable.
In this case, we have to enumerate all patterns where $\mathcal{A}(\bm{x})$ appears as a result of simulated annealing algorithm, 
which is computationally impractical.
To address this issue, we first compute the region conditioned on the process of the algorithm $\mathcal{A}$. %for computational tractability.
That is to say, it is guaranteed that the process remains identical within the region. 
This additional conditioning is often denoted as ``over-conditioning'' 
because it is redundant for valid inference. 
In the case of SI with over-conditioning, 
the type I error rate can still be controlled at the significance level, 
while the power tends to be low~\citep{lee2016exact, liu2018more, le2022more}. 
Therefore, we apply an efficient line search method based on parametric programming to compute $\mathcal{Z}$ where the redundant conditioning is removed for the purpose of improving the power~\citep{le2022more}.
In the following, we first compute the over-conditioned region in Appendix~\ref{subsec:over-conditioning}, 
and then identify the truncation region $\mathcal{Z}$ using parametric programming in Appendix~\ref{subsec:parametricprogramming}.

\subsection{Characterizing using Over-conditioning}
\label{subsec:over-conditioning}
Since we only need to consider one-dimensional data space in $\mathbb{R}^N$ as indicated in~(\ref{one-D}), 
we define the over-conditioned region $\mathcal{Z}^{\text{oc}}$ where the process of the algorithm $\mathcal{A}$ remains unchanged as
\begin{equation}
  \mathcal{Z}^{\text{oc}} (\bm{a} + \bm{b}z) = \{r \in \mathbb{R} \, | \, \mathcal{S}_{\text{DP}}(r) = \mathcal{S}_{\text{DP}}(z), \mathcal{S}_{\text{pre-SA}}(r) = \mathcal{S}_{\text{pre-SA}}(z), \mathcal{S}_{\text{SA}}(r) = \mathcal{S}_{\text{SA}}(z) \}, \label{oc_interval}
\end{equation}
where $\mathcal{S}_{\text{DP}}$, $\mathcal{S}_{\text{pre-SA}}$ and $\mathcal{S}_{\text{SA}}$ are the events characterized by the process of dynamic programming for generating an initial solution, 
the preliminary experiment to determine the initial temperature, 
and simulated annealing for making the solution more sophisticated, respectively. 
This conditioning is redundant because $\mathcal{Z}^{\text{oc}} (\bm{a} + \bm{b}z)$ is a subset of the minimum conditioned region $\mathcal{Z}$. 

\textbf{Over-conditioning on dynamic programming.}
We compute $\{r \in \mathbb{R} \, | \, \mathcal{S}_{\text{DP}}(r) = \mathcal{S}_{\text{DP}}(z)\}$ % by conditioning on the determination of the solution based on the Bellman equation which is used in the dynamic programming algorithm.
by conditioning on all the operations based on the Bellman equation 
which is used in the dynamic programming algorithm to obtain the optimal solution in~(\ref{PO}).
Since the Bellman equation consists of the cost $\mathcal{C}(\cdot)$ and the penalty $\bm{\beta}$, the condition is finally represented by a quadratic inequality, as in the following discussion of simulated annealing.
The detail derivation is presented in~\citet{duy2020computing}.
% (Duy論文) These subsets are constructed by considering all the operations when DP algorithm is used for detecting the optimal CPs. 

\textbf{Over-conditioning on simulated annealing containing the preliminary experiment.}
Considering the algorithm of simulated annealing, we find that the procedure depends on $\bm{X} = \bm{a} + \bm{b}z$ at only one specific point, that is, the Metropolis algorithm, %in the first line of Algorithm~\ref{alg_sa}.
which is given by
% \begin{equation}
%   \text{status} =
%   \begin{cases}
%     \text{accept} & (\exp(-\Delta E(\bm{\mathcal{T}}_{i,l}, \bm{\mathcal{T}}_{i,l-1}, \bm{a} + \bm{b}r) /c_i) > \theta_{i,l}) \\
%     \text{reject} & (\exp(-\Delta E(\bm{\mathcal{T}}_{i,l}, \bm{\mathcal{T}}_{i,l-1}, \bm{a} + \bm{b}r) /c_i) \leq \theta_{i,l})
%   \end{cases}, \notag
% \end{equation}
\begin{equation}
  \text{status is}
  \begin{cases}
    \text{Acceptance} & \left(\exp\left(\frac{-\Delta E(\bm{\mathcal{T}}_{i,l}, \bm{\mathcal{T}}_{i,l-1}, \bm{a} + \bm{b}r)}{c_i}\right) > \theta_{i,l}\right) \\
    \vspace{-1mm}\\
    \text{Rejection} & \left(\exp\left(\frac{-\Delta E(\bm{\mathcal{T}}_{i,l}, \bm{\mathcal{T}}_{i,l-1}, \bm{a} + \bm{b}r)}{c_i}\right) \leq \theta_{i,l}\right)
  \end{cases}, \notag
\end{equation}
where $\Delta E(\bm{\mathcal{T}}_{i,l}, \bm{\mathcal{T}}_{i,l-1}, \bm{a} + \bm{b}r) = E(\bm{\mathcal{T}}_{i,l}, \bm{a} + \bm{b}r) - E(\bm{\mathcal{T}}_{i,l-1}, \bm{a} + \bm{b}r)$, 
and $\bm{\mathcal{T}}_{i,l-1}$, $\bm{\mathcal{T}}_{i,l}$ respectively represent CP candidates before and after a transition to the neighborhood 
in the $l$-th iteration with a parameter $\theta_{i,l}$ for the $i$-th temperature $c_i$. 
Note that while the transitions are accepted when either $\Delta E(\bm{\mathcal{T}}_{i,l}, \bm{\mathcal{T}}_{i,l-1}, \bm{a} + \bm{b}r) \leq 0$ or $\exp(-\Delta E(\bm{\mathcal{T}}_{i,l}, \bm{\mathcal{T}}_{i,l-1}, \bm{a} + \bm{b}r) /c_i) > \theta_{i,l}$, 
the latter case includes the former. 
Thus, to compute the region $\{r \in \mathbb{R} \, | \, \mathcal{S}_{\text{SA}}(r) = \mathcal{S}_{\text{SA}}(z)\}$ where the process of simulated annealing is identical, 
we need to condition on all results of the Metropolis algorithm at each temperature.
This condition consists of multiple inequalities as~follows
\begin{align}
  &\{r \in \mathbb{R} \, | \, \mathcal{S}_{\text{SA}}(r) = \mathcal{S}_{\text{SA}}(z)\} \notag \\
  &= \bigcap_{i=0}^{I_z} \bigcap_{l=1}^{L_z} \left\{r \in \mathbb{R} \, \Bigg| \,
  \begin{cases}
    \Delta E(\bm{\mathcal{T}}_{i,l}, \bm{\mathcal{T}}_{i,l-1}, \bm{a} + \bm{b}r) + c_i \ln (\theta_{i,l}) < 0 & \text{(status is Acceptance)} \\
    \Delta E(\bm{\mathcal{T}}_{i,l}, \bm{\mathcal{T}}_{i,l-1}, \bm{a} + \bm{b}r) + c_i \ln (\theta_{i,l}) \geq 0 & \text{(status is Rejection)}
  \end{cases}
  \right\}, \label{sa_condition}
\end{align}
where $I_z$ and $L_z$ denote the number of temperature updates and operations at each temperature for $z$, respectively.

We subsequently consider solving this inequality for $r$. 
The cost $\mathcal{C} \left(\bm{F}_{s+1:e}^{(d)}\right)$ used in the objective function $E$ can be expressed as a quadratic form of $\bm{X}$ such that 
\begin{align}
  \mathcal{C} \left(\bm{F}_{s+1:e}^{(d)}\right)
  &= c_{\text{sym}}^{(d)} \sum_{t=s+1}^e \left|F_t^{(d)} - \bar{F}_{s+1:e}^{(d)}\right|^2 \notag \\
  &= c_{\text{sym}}^{(d)} \sum_{t=s+1}^e \left|\left(\bm{1}_{t:t} \otimes \bm{w}_M^{(d)}\right)^\top \bm{X} - \frac{1}{e - s} \left(\bm{1}_{s+1:e} \otimes \bm{w}_M^{(d)}\right)^\top \bm{X} \right|^2 \notag \\
  &= \bm{X}^\top C^{(d)}_{s+1:e} \bm{X}, \notag 
\end{align}
where 
\begin{equation}
  C^{(d)}_{s+1:e} = c_{\text{sym}}^{(d)} \sum_{t=s+1}^e \bm{u}^{(d)}_{s+1:e, t} {\bm{u}_{s+1:e, t}^{{\ast^{(d)}}^\top}} \in \mathbb{R}^{N \times N}, \notag 
\end{equation}
\begin{equation}
\bm{u}^{(d)}_{s+1:e, t} = \bm{1}_{t:t} \otimes \bm{w}_M^{(d)} - \frac{1}{e - s} \left(\bm{1}_{s+1:e} \otimes \bm{w}_M^{(d)}\right) \in \mathbb{C}^N, \notag
\end{equation}
and $\bm{u}_{s+1:e, t}^{\ast^{(d)}}$ is the complex conjugate of $\bm{u}^{(d)}_{s+1:e, t}$. 
Therefore, the objective function $E(\bm{\mathcal{T}}, \bm{a} + \bm{b}r)$ in~(\ref{objective_func}) can be rewritten as follows 
\begin{align}
  E(\bm{\mathcal{T}}, \bm{a} + \bm{b}r) 
  &= (\bm{a} + \bm{b}r)^{\top} \left(\sum_{d=0}^{D-1} \sum_{k=1}^{K^{(d)}+1} C^{(d)}_{\tau_{k - 1}^{(d)}+1 : \tau_k^{(d)}}\right) (\bm{a} + \bm{b}r) + \sum_{d=0}^{D-1} \beta^{(d)} K^{(d)} + \gamma K \notag \\
  &= e_2 r^2 + e_1 r + e_0, \label{objective_func_quadratic}
\end{align}
where 
\begin{align}
  e_2 &= \bm{b}^{\top} \sum_{d=0}^{D-1} \sum_{k=1}^{K^{(d)}+1} C^{(d)}_{\tau_{k - 1}^{(d)}+1 : \tau_k^{(d)}} \bm{b}, \notag \\
  e_1 &= 2 \bm{a}^{\top} \sum_{d=0}^{D-1} \sum_{k=1}^{K^{(d)}+1} C^{(d)}_{\tau_{k - 1}^{(d)}+1 : \tau_k^{(d)}} \bm{b}, \notag \\
  e_0 &= \bm{a}^{\top} \sum_{d=0}^{D-1} \sum_{k=1}^{K^{(d)}+1} C^{(d)}_{\tau_{k - 1}^{(d)}+1 : \tau_k^{(d)}} \bm{a} + \sum_{d=0}^{D-1} \beta^{(d)} K^{(d)} + \gamma K. \notag
\end{align}
Thus, the multiple inequalities in~(\ref{sa_condition}) can be easily solved after computing the coefficients in~(\ref{objective_func_quadratic}).

Note that the region $\{r \in \mathbb{R} \, | \, \mathcal{S}_{\text{pre-SA}}(r) = \mathcal{S}_{\text{pre-SA}}(z)\}$ can be computed similarly to~(\ref{sa_condition}) 
because the preliminary experiment is also based on the Metropolis algorithm. 
Therefore, this condition is formulated~as
\begin{align}
  &\left\{r \in \mathbb{R} \, | \, \mathcal{S}_{\text{pre-SA}}(r) = \mathcal{S}_{\text{pre-SA}}(z)\right\} \notag \\ 
  &= \bigcap_{i=0}^{I_z^+} \bigcap_{l=1}^{L_z^+} \left\{r \in \mathbb{R} \, \Bigg| \, 
  \begin{cases}
    \Delta E(\bm{\mathcal{T}}_{i,l}^{+}, \bm{\mathcal{T}}_{i,l-1}^{+}, \bm{a} + \bm{b}r) + c_i^{+} \ln (\theta_{i,l}^{+}) < 0 & \text{(status is Acceptance)} \\
    \Delta E(\bm{\mathcal{T}}_{i,l}^{+}, \bm{\mathcal{T}}_{i,l-1}^{+}, \bm{a} + \bm{b}r) + c_i^{+} \ln (\theta_{i,l}^{+}) \geq 0 & \text{(status is Rejection)}
  \end{cases} \right\}, \notag
\end{align}
where $\bm{\mathcal{T}}_{i,l}^{+}, c_i^{+}, \theta_{i,l}^{+}, I_z^+$ and $L_z^+$ in the preliminary experiment correspond to the respective parameters in~(\ref{sa_condition}), 
and $\bm{\mathcal{T}}_{i,0}^{+} = \bm{\mathcal{T}}^{\text{init}}$. 

Based on the above discussion, since the conditioning in~(\ref{oc_interval}) is represented as the intersection of multiple quadratic inequalities, 
the region $\mathcal{Z}^{\text{oc}} (\bm{a} + \bm{b}z)$ can be computed by solving them as 
\begin{equation}
  \mathcal{Z}^{\text{oc}} (\bm{a} + \bm{b}z) = \bigcup_{r=1}^{R_z} \, [L_{z {(r)}}^{\text{oc}}, U_{z {(r)}}^{\text{oc}}], \notag
\end{equation}
where, for $z$, $L_{z {(r)}}^{\text{oc}}$ and $U_{z {(r)}}^{\text{oc}}$ denote the lower and upper bounds of the $r$-th over-conditioned region, respectively, 
and $R_z$ represents the number of the intervals.

\subsection{Parametric Programming}
\label{subsec:parametricprogramming}
Having derived $\mathcal{Z}^{\text{oc}} (\bm{a} + \bm{b}z)$ in the previous analysis, 
the region $\mathcal{Z}$ in~(\ref{truncatedarea}) conditioned on the result of the algorithm $\mathcal{A}$ can be obtained using 
a computational method called parametric programming as follows
\begin{equation}
  \mathcal{Z} = \bigcup_{z \in \mathbb{R} |  \mathcal{A}( \bm{a} + \bm{b} z) = \mathcal{A}(\bm{x})} \mathcal{Z}^{\text{oc}} (\bm{a} + \bm{b}z). \label{parametricprogramming}
\end{equation}
The overall procedure for computing selective $p$-values of the detected CP candidate locations is presented in Algorithm~\ref{SI_alg}.
Furthermore, the line search method based on~(\ref{parametricprogramming}) for obtaining the region $\mathcal{Z}$ required for the computation of $p_k^{\text{selective}}$ is detailed in Algorithm~\ref{SI_path_alg}. 
An overview of the proposed search method is shown in Figure~\ref{fig6}. 

\begin{algorithm}[t] 
  \caption{SI for detected CP candidate locations}
  \label{SI_alg}
  \begin{algorithmic}[1]
    \REQUIRE $\bm{x}$
    \STATE $\bm{\mathcal{T}}^{\text{det}} \leftarrow \mathcal{A}(\bm{x})$ in~(\ref{eq:detected_obs})
    \STATE Obtain $\bm{\tau}^{\text{det}}$ by~(\ref{changetimepoint}) 
    \FOR{$\tau_k^{\text{det}} \in \bm{\tau}^{\text{det}}$}
      \STATE $\mathcal{Z} \leftarrow$ \texttt{compute\_solution\_path}$\left(\bm{x}, \bm{\mathcal{T}}^{\text{det}}, \tau_k^{\text{det}}\right)$ 
      \STATE Compute $p_k^{\text{selective}}$ by~(\ref{psel_z}) 
    \ENDFOR
    \ENSURE $\left\{\left(\tau_k^{\text{det}}, p_k^{\text{selective}}\right)\right\}_{k=1}^{K}$
  \end{algorithmic}
\end{algorithm}

\begin{algorithm}[t] 
  \caption{\texttt{compute\_solution\_path}}
  \label{SI_path_alg}
  \begin{algorithmic}[1]
    \REQUIRE $\bm{x}, \bm{\mathcal{T}}^{\text{det}}$ and $\tau_k^{\text{det}}$
    \STATE $z^{\text{obs}} \leftarrow T_k(\bm{x})$ in~(\ref{eq:teststatistic2})
    \STATE Compute $\bm{a}$ and $\bm{b}$ by~(\ref{ab})
    \STATE Obtain $\mathcal{Z}^{\text{oc}}(\bm{a}+\bm{b}z^{\text{obs}})$ by~(\ref{oc_interval})
    \STATE $S \leftarrow \mathcal{Z} \leftarrow \mathcal{Z}^{\text{oc}}(\bm{a}+\bm{b}z^{\text{obs}})$
    \WHILE{$S^c \neq \emptyset$}
      \STATE Obtain $\mathcal{Z}^{\text{oc}}(\bm{a}+\bm{b}z)$ for $z \in S^c$ by~(\ref{oc_interval})
      \STATE $S \leftarrow S \cup \mathcal{Z}^{\text{oc}}(\bm{a}+\bm{b}z)$
      \IF{$\mathcal{A}(\bm{a}+\bm{b}z) = \mathcal{A}(\bm{a}+\bm{b}z^{\text{obs}})$}
        \STATE $\mathcal{Z} \leftarrow \mathcal{Z} \cup \mathcal{Z}^{\text{oc}}(\bm{a}+\bm{b}z)$
      \ENDIF 
    \ENDWHILE
    \ENSURE $\mathcal{Z}$
  \end{algorithmic}
\end{algorithm}

\begin{figure}[H]
  \centering
  \includegraphics[width=0.9\hsize]{figure/fig6.pdf}
  \caption{
            Schematic illustration of the proposed line search method for the identification of the truncation region.
            We first compute the over-conditioned region where the process of the algorithm $\mathcal{A}$ remains unchanged. 
            Then, we identify the truncation region $\mathcal{Z}$ by removing the redundant conditioning using parametric programming.
           }
  \label{fig6}
\end{figure}

\citet{watanabe2021selective} proposed a selective inference method for model selection using simulated annealing in latent block models; 
however, this approach was limited to the specific algorithm and computed an approximated truncation region. 
In contrast, our proposed method can be applied to not only CP detection in the frequency domain which is the subject of this paper, 
but also a wide range of optimization problems solved using simulated annealing.
Even in such a general case, we consider the over-conditioning based on the process of algorithm as in~(\ref{oc_interval}) 
and can obtain the ``exact'' truncation region using the parametric programming approach in~(\ref{parametricprogramming}).
% 初期解生成の部分はBSやランダム生成など他の手法を用いることもできる