\section{Related Work}
\subsection{Hand-crafted prior-based methods.}
Due to the ill-posed nature of image deblurring, many conventional approaches **Fu et al., "A Novel Image Deblurring Method Using Hand-Crafted Priors"** address this challenge by incorporating hand-crafted priors to constrain the set of possible solutions. While these priors can aid in blur removal, the image degradation process is often uncertain. Consequently, these methods not only face difficulties in accurately modeling the degradation process but also often lack generalization ability.

\begin{figure*}
    \centering
    \includegraphics[width=0.9\linewidth]{network.jpg}
    \caption{(a) Overall architecture of the proposed SFAFNet. (b) Simplified channel attention block (SCABlock) extracts shallow features.   (c) Gated spatial-frequency domain feature fusion block (GSFFBlock), which consists of N **Huang et al., "NAFBlock: A Novel Attention-Based Block for Image Deblurring"** __**Zhou et al., "FDGM: Frequency Domain Information Dynamic Generation Module"**, and a gated fusion module (GFM). (d) NAFBlock used to extract spatial domain features. (e) FDGM dynamically decompose features into separate frequency subbands.}
    \label{fig:network}
\end{figure*}
\subsection{Spatial-based methods.}
With the rapid advancement of deep learning, instead of manually designing image priors, many methods have turned to developing various deep CNN architectures. **Li et al., "MPRNet: A Multi-Path Residual Network for Image Deblurring"** decomposes the image restoration process into manageable steps to maintain spatial details and contextual informations.
**Zhang et al., "MIRNet-V2: A Multi-Scale Architecture for Image Deblurring"** introduces a multi-scale architecture that ensures spatially-precise representations are maintained , while also gathering complementary contextual information.
**Wang et al., "NAFNet: Non-Autoregressive Frequency Domain Image Deblurring"** analyzes baseline modules and demonstrates that non-linear activation functions may be dispensable.
**Chen et al., "CGNet: A Context-Guided Network for Image Deblurring"** employs a global context extractor to effectively capture global context information.
**Xu et al., "MR-VNet: A Multi-Resolution Volterra Network for Image Deblurring"** utilizes the Volterra layers to optimally introduce non-linearities in the restoration process. 
Nonetheless,  the inherent limitations of convolutional operations restrict the models' ability to effectively remove long-range degradation artifacts.

To address these challenges, **Vaswani et al., "Transformers: Attention is All You Need"** have been applied to image deblurring. However, traditional Transformer architectures face significant computational overhead.
To improve efficiency, **Liu et al., "SwinIR: A SwinB-Style Network for Real Image Denoising and Deraining"** and **Chen et al., "U$^2$former: Unified Unfolded Transformer for Visual Recognition Tasks"** adopt window-based self-attention mechanisms in Transformer architectures. Additionally, **Alayande et al., "Restormer: A New Vision Transformers for Image Restoration Tasks"** and **Li et al., "PromptIR: Prompt-Based Vision Transformers for Image Deblurring"** compute self-attention across channels rather than spatial dimensions, resulting in linear complexity and enhancing computational efficiency.
While these methods achieve better performance than  hand-crafted approaches, they predominantly emphasize the spatial domain and often neglect the frequency differences between sharp and degraded image pairs. 


\subsection{Frequency-based methods.}
Based on the spectral convolution theorem and the frequency disparities between sharp and degraded image pairs, it is feasible to process different frequency subbands individually in the frequency domain, effectively capturing global information.  Considering these advantages, several frequency-based methods have been proposed for image deblurring.
**Li et al., "SDWNet: A Wavelet-Based Network for Image Deblurring"** proposes a wavelet reconstruction module to recover more high-frequency details. **Chen et al., "FFTformer: Fourier Feature Fusion Transformer for Image Deblurring"** leverages the convolution theorem to explore the properties of Transformers. **Wang et al., "DeepRFT: Deep Residual Fourier Transform Network for Image Deblurring"** integrates Fourier transform to incorporate kernel-level information into image deblurring networks. **Xu et al., "AdaRevD: Adaptive Reverberation and Detail Enhancement Network for Image Deblurring"** introduces a FourierBlock to decode blur patterns. However, these methods typically require Fourier inverse or wavelet transforms, leading to additional computational overhead and limited flexibility.


To effectively choose the most informative frequency components for reconstruction, **Fu et al., "FocalNet: A Focal Attention-Based Network for Image Deblurring"** and **Li et al., "IRNeXt: Invertible Residual Network for Image Deblurring"** design conventional filters to generate different frequency signals. **Chen et al., "DDANet: Dynamic Decomposition and Attention Network for Image Deblurring"** devises a frequency attention module that performs controlled frequency transformation. **Wang et al., "AirFormer: An Air-Wavelet Prior-Based Network for Image Deblurring"** proposes a supplementary prior module to selectively filter. **Xu et al., "MRLPFNet: A Multi-Resolution Low-Pass Filter Network for Image Deblurring"** exploits a learnable low-pass filter module to adaptively explore the global contexts.
**Huang et al., "SFNet: A Spatial-Frequency Domain Network for Image Deblurring"** and **Li et al., "FSNet: Frequency-Spatial Domain Network for Image Deblurring"** utilize multi-branch and content-aware modules to dynamically and locally decompose features into separate frequency subbands.

Nonetheless, these frequency domain-based methods often neglect to effectively capture the spatial variation property.  In this paper, we propose the spatial-frequency domain adaptive fusion network to  facilitate the learning of complementary representations between local spatial information and global frequency information.