\section{Related Work}
\subsection{Hand-crafted prior-based methods.}
Due to the ill-posed nature of image deblurring, many conventional approaches~\cite{2011Image,karaali2017edge} address this challenge by incorporating hand-crafted priors to constrain the set of possible solutions. While these priors can aid in blur removal, the image degradation process is often uncertain. Consequently, these methods not only face difficulties in accurately modeling the degradation process but also often lack generalization ability.

\begin{figure*}
    \centering
    \includegraphics[width=0.9\linewidth]{network.jpg}
    \caption{(a) Overall architecture of the proposed SFAFNet. (b) Simplified channel attention block (SCABlock) extracts shallow features.   (c) Gated spatial-frequency domain feature fusion block (GSFFBlock), which consists of N NAFBlocks~\cite{chen2022simple}, a frequency domain information dynamic generation module (FDGM), and a gated fusion module (GFM). (d) NAFBlock used to extract spatial domain features. (e) FDGM dynamically decompose features into separate frequency subbands.}
    \label{fig:network}
\end{figure*}
\subsection{Spatial-based methods.}
With the rapid advancement of deep learning, instead of manually designing image priors, many methods have turned to developing various deep CNN architectures. MPRNet~\cite{Zamir2021MPRNet} decomposes the image restoration process into manageable steps to maintain spatial details and contextual informations.
MIRNet-V2~\cite{Zamir2022MIRNetv2} introduces a multi-scale architecture that ensures spatially-precise representations are maintained , while also gathering complementary contextual information.
NAFNet~\cite{chen2022simple} analyzes baseline modules and demonstrates that non-linear activation functions may be dispensable.
CGNet~\cite{CascadedGaze} employs a global context extractor to effectively capture global context information.
MR-VNet~\cite{MR-VNet} utilizes the Volterra layers to optimally introduce non-linearities in the restoration process. 
Nonetheless,  the inherent limitations of convolutional operations restrict the models' ability to effectively remove long-range degradation artifacts.

To address these challenges, Transformers~\cite{2017Attention} have been applied to image deblurring. However, traditional Transformer architectures face significant computational overhead.
To improve efficiency, SwinIR~\cite{liang2021swinir} and U$^2$former~\cite{u2former} adopt window-based self-attention mechanisms in Transformer architectures. Additionally, Restormer~\cite{Zamir2021Restormer} and PromptIR~\cite{potlapalli2023promptir} compute self-attention across channels rather than spatial dimensions, resulting in linear complexity and enhancing computational efficiency.
While these methods achieve better performance than  hand-crafted approaches, they predominantly emphasize the spatial domain and often neglect the frequency differences between sharp and degraded image pairs. 


\subsection{Frequency-based methods.}
Based on the spectral convolution theorem and the frequency disparities between sharp and degraded image pairs, it is feasible to process different frequency subbands individually in the frequency domain, effectively capturing global information.  Considering these advantages, several frequency-based methods have been proposed for image deblurring.
SDWNet~\cite{SDWNet} proposes a wavelet reconstruction module to recover more high-frequency details. FFTformer~\cite{kong2023efficient} leverages the convolution theorem to explore the properties of Transformers. DeepRFT~\cite{fxint2023freqsel} integrates Fourier transform to incorporate kernel-level information into image deblurring networks. AdaRevD~\cite{AdaRevD} introduces a FourierBlock to decode blur patterns. However, these methods typically require Fourier inverse or wavelet transforms, leading to additional computational overhead and limited flexibility.


To effectively choose the most informative frequency components for reconstruction, FocalNet~\cite{focalnetcui2023focal} and IRNeXt~\cite{IRNeXt} design conventional filters to generate different frequency signals. DDANet~\cite{DDAnet} devises a frequency attention module that performs controlled frequency transformation. AirFormer~\cite{10196308} proposes a supplementary prior module to selectively filter. MRLPFNet~\cite{MRLPFNet} exploits a learnable low-pass filter module to adaptively explore the global contexts.
SFNet~\cite{SFNet} and FSNet~\cite{FSNet} utilize multi-branch and content-aware modules to dynamically and locally decompose features into separate frequency subbands.

Nonetheless, these frequency domain-based methods often neglect to effectively capture the spatial variation property.  In this paper, we propose the spatial-frequency domain adaptive fusion network to  facilitate the learning of complementary representations between local spatial information and global frequency information.