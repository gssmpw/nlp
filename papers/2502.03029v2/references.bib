%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Nonparametric Bayes/ mixture models references
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
@book{pardo2018statistical,
  title={Statistical Inference Based on Divergence Measures},
  author={Pardo, L.},
  isbn={9781420034813},
  lccn={2005049685},
  series={Statistics: A Series of Textbooks and Monographs},
  url={https://books.google.com/books?id=ziDGGIkhqlMC},
  year={2018},
  publisher={CRC Press}
}

@misc{OpenAI2025a,
  author       = {OpenAI},
  title        = {ChatGPT},
  year         = {2025},
  howpublished = {\url{https://chat.openai.com}},
  note         = {Accessed: 2025}
}

@article{ho2022convergence,
  title={Convergence rates for Gaussian mixtures of experts},
  author={Ho, Nhat and Yang, Chiao-Yu and Jordan, Michael I},
  journal={Journal of Machine Learning Research},
  volume={23},
  number={323},
  pages={1--81},
  year={2022}
}

@article{li2024continuallearning,
  title={Theory on Mixture-of-Experts in Continual Learning},
  author={Hongbo Li and Sen Lin and Lingjie Duan and Yingbin Liang and Ness B. Shroff},
  journal={arXiv preprint arXiv:2406.16437},
  year={2024}
}

@inproceedings{han2024fusemoe,
  title={FuseMoE: Mixture-of-Experts Transformers for Fleximodal Fusion},
  author={Han, Xing and Nguyen, Huy and Harris, Carl and Ho, Nhat and Saria, Suchi},
  booktitle = "Advances in Neural Information Processing Systems",
  year={2024}
}

@article{pham2024competesmoe,
      title={CompeteSMoE -- Effective Training of Sparse Mixture of Experts via Competition}, 
      author={Quang Pham and Giang Do and Huy Nguyen and TrungTin Nguyen and Chenghao Liu and Mina Sartipi and Binh T. Nguyen and Savitha Ramasamy and Xiaoli Li and Steven Hoi and Nhat Ho},
      journal={arXiv preprint arXiv:2402.02526},
      year={2024}
}

@inproceedings{chen2022theory,
 author = {Chen, Zixiang and Deng, Yihe and Wu, Yue and Gu, Quanquan and Li, Yuanzhi},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {S. Koyejo and S. Mohamed and A. Agarwal and D. Belgrave and K. Cho and A. Oh},
 pages = {23049--23062},
 publisher = {Curran Associates, Inc.},
 title = {Towards Understanding the Mixture-of-Experts Layer in Deep Learning},
 volume = {35},
 year = {2022}
}

@inproceedings{nguyen2024general,
      title={A General Theory for Softmax Gating Multinomial Logistic Mixture of Experts}, 
      author={Huy Nguyen and Pedram Akbarian and TrungTin Nguyen and Nhat Ho},
      booktitle ="Proceedings of the ICML",
      year={2024}
}

@inproceedings{nguyen2025cosine,
    author = {Huy Nguyen and Pedram Akbarian and Trang Pham and Trang Nguyen and Shujian Zhang and Nhat Ho},
    title = {Statistical Advantages of Perturbing Cosine Router in Mixture of Experts},
    booktitle = {International Conference on Learning Representations},
    year = 2025
}

@inproceedings{yan2025contaminated,
    title = {Understanding Expert Structures on Minimax Parameter Estimation in Contaminated Mixture of Experts},
    author = {Fanqi Yan and Huy Nguyen and Dung Le and Pedram Akbarian and Nhat Ho},
    booktitle = {Proceedings of The 28th International Conference on Artificial Intelligence and Statistics},
    year = 2025
}

@article{nguyen2024least,
  title={On least squares estimation in softmax gating mixture of experts},
  author={Nguyen, Huy and Ho, Nhat and Rinaldo, Alessandro},
  journal={arXiv preprint arXiv:2402.02952},
  year={2024}
}

@article{nguyen2024sigmoid,
  title={Sigmoid Gating is More Sample Efficient than Softmax Gating in Mixture of Experts},
  author={Nguyen, Huy and Ho, Nhat and Rinaldo, Alessandro},
  journal={arXiv preprint arXiv:2405.13997},
  year={2024}
}

@article{nguyen2023demystifying,
  title={Demystifying softmax gating function in Gaussian mixture of experts},
  author={Nguyen, Huy and Nguyen, TrungTin and Ho, Nhat},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  pages={4624--4652},
  year={2023}
}

@article{peng2023instruction,
  title={Instruction tuning with gpt-4},
  author={Peng, Baolin and Li, Chunyuan and He, Pengcheng and Galley, Michel and Gao, Jianfeng},
  journal={arXiv preprint arXiv:2304.03277},
  year={2023}
}

@article{minaee2024large,
  title={Large language models: A survey},
  author={Minaee, Shervin and Mikolov, Tomas and Nikzad, Narjes and Chenaghlu, Meysam and Socher, Richard and Amatriain, Xavier and Gao, Jianfeng},
  journal={arXiv preprint arXiv:2402.06196},
  year={2024}
}

@article{openai2024gpt,
  title={Gpt-4 technical report, 2024},
  author={OpenAI, Josh Achiam and Adler, Steven and Agarwal, Sandhini and Ahmad, Lama and Akkaya, Ilge and Aleman, Florencia Leoni and Almeida, Diogo and Altenschmidt, Janko and Altman, Sam and Anadkat, Shyamal and others},
  journal={URL https://arxiv. org/abs/2303.08774},
  volume={2},
  pages={6},
  year={2024}
}

@article{anil2023palm,
  title={Palm 2 technical report},
  author={Anil, Rohan and Dai, Andrew M and Firat, Orhan and Johnson, Melvin and Lepikhin, Dmitry and Passos, Alexandre and Shakeri, Siamak and Taropa, Emanuel and Bailey, Paige and Chen, Zhifeng and others},
  journal={arXiv preprint arXiv:2305.10403},
  year={2023}
}

@article{raffel2020exploring,
  title={Exploring the limits of transfer learning with a unified text-to-text transformer},
  author={Raffel, Colin and Shazeer, Noam and Roberts, Adam and Lee, Katherine and Narang, Sharan and Matena, Michael and Zhou, Yanqi and Li, Wei and Liu, Peter J},
  journal={Journal of machine learning research},
  volume={21},
  number={140},
  pages={1--67},
  year={2020}
}

@article{radford2019language,
  title={Language models are unsupervised multitask learners},
  author={Radford, Alec and Wu, Jeffrey and Child, Rewon and Luan, David and Amodei, Dario and Sutskever, Ilya and others},
  journal={OpenAI blog},
  volume={1},
  number={8},
  pages={9},
  year={2019}
}

@article{nguyen_approximations_2021,
	title = {Approximations of conditional probability density functions in {Lebesgue} spaces via mixture of experts models},
	volume = {8},
	copyright = {All rights reserved},
	issn = {2195-5832},
	url = {https://doi.org/10.1186/s40488-021-00125-0},
	doi = {10.1186/s40488-021-00125-0},
	abstract = {Mixture of experts (MoE) models are widely applied for conditional probability density estimation problems. We demonstrate the richness of the class of MoE models by proving denseness results in Lebesgue spaces, when inputs and outputs variables are both compactly supported. We further prove an almost uniform convergence result when the input is univariate. Auxiliary lemmas are proved regarding the richness of the soft-max gating function class, and their relationships to the class of Gaussian gating functions.},
	number = {1},
	urldate = {2022-01-21},
	journal = {Journal of Statistical Distributions and Applications},
	author = {Nguyen, Hien Duy and Nguyen, TrungTin and Chamroukhi, Faicel and McLachlan, Geoffrey John},
	month = aug,
	year = {2021},
	keywords = {Mixture models, Mixture of experts, Approximation theory, Conditional probability density functions, Lebesgue spaces},
	pages = {13},
}


@article{nguyen2023statistical,
      title={Statistical Perspective of Top-K Sparse Softmax Gating Mixture of Experts}, 
      author={H. Nguyen and P. Akbarian and F. Yan and N. Ho},
      Journal={arxiv preprint arxiv 2309.13850},
      year={2023}
}

@inproceedings{do_hyperrouter_2023,
	address = {Singapore},
	title = {{HyperRouter}: {Towards} {Efficient} {Training} and {Inference} of {Sparse} {Mixture} of {Experts}},
	booktitle = {Proceedings of the 2023 {Conference} on {Empirical} {Methods} in {Natural} {Language} {Processing}},
	publisher = {Association for Computational Linguistics},
	author = {Do, Truong Giang and Le, Huy Khiem and Nguyen, TrungTin and Pham, Quang and Nguyen, Binh T. and Doan, Thanh-Nam and Liu, Chenghao and Ramasamy, Savitha and Li, Xiaoli and HOI, Steven},
	month = dec,
	year = {2023},
}

@inproceedings{kwon_global_2019,
	series = {Proceedings of {Machine} {Learning} {Research}},
	title = {Global {Convergence} of the {EM} {Algorithm} for {Mixtures} of {Two} {Component} {Linear} {Regression}},
	volume = {99},
	url = {https://proceedings.mlr.press/v99/kwon19a.html},
	abstract = {The Expectation-Maximization algorithm is perhaps the most broadly used algorithm for inference of latent variable problems. A theoretical understanding of its performance, however, largely remains lacking. Recent results established that EM enjoys global convergence for Gaussian Mixture Models. For Mixed Linear Regression, however, only local convergence results have been established, and those only for the high SNR regime. We show here that EM converges for mixed linear regression with two components (it is known that it may fail to converge for three or more), and moreover that this convergence holds for random initialization. Our analysis reveals that EM exhibits very different behavior in Mixed Linear Regression from its behavior in Gaussian Mixture Models, and hence our proofs require the development of several new ideas.},
	booktitle = {Proceedings of the {Thirty}-{Second} {Conference} on {Learning} {Theory}},
	publisher = {PMLR},
	author = {Kwon, Jeongyeol and Qian, Wei and Caramanis, Constantine and Chen, Yudong and Davis, Damek},
	editor = {Beygelzimer, Alina and Hsu, Daniel},
	month = jun,
	year = {2019},
	pages = {2055--2110},
}


@inproceedings{kwon_em_2020,
	series = {Proceedings of {Machine} {Learning} {Research}},
	title = {{EM} {Converges} for a {Mixture} of {Many} {Linear} {Regressions}},
	volume = {108},
	url = {https://proceedings.mlr.press/v108/kwon20a.html},
	booktitle = {Proceedings of the {Twenty} {Third} {International} {Conference} on {Artificial} {Intelligence} and {Statistics}},
	publisher = {PMLR},
	author = {Kwon, Jeongyeol and Caramanis, Constantine},
	editor = {Chiappa, Silvia and Calandra, Roberto},
	month = aug,
	year = {2020},
	pages = {1727--1736},
}


@article{chen_improved_1999,
	title = {Improved learning algorithms for mixture of experts in multiclass classification},
	volume = {12},
	issn = {0893-6080},
	url = {https://www.sciencedirect.com/science/article/pii/S089360809900043X},
	doi = {https://doi.org/10.1016/S0893-6080(99)00043-X},
	abstract = {Mixture of experts (ME) is a modular neural network architecture for supervised learning. A double-loop Expectation-Maximization (EM) algorithm has been introduced to the ME architecture for adjusting the parameters and the iteratively reweighted least squares (IRLS) algorithm is used to perform maximization in the inner loop [Jordan, M.I., Jacobs, R.A. (1994). Hierarchical mixture of experts and the EM algorithm, Neural Computation, 6(2), 181–214]. However, it is reported in literature that the IRLS algorithm is of instability and the ME architecture trained by the EM algorithm, where IRLS algorithm is used in the inner loop, often produces the poor performance in multiclass classification. In this paper, the reason of this instability is explored. We find out that due to an implicitly imposed incorrect assumption on parameter independence in multiclass classification, an incomplete Hessian matrix is used in that IRLS algorithm. Based on this finding, we apply the Newton–Raphson method to the inner loop of the EM algorithm in the case of multiclass classification, where the exact Hessian matrix is adopted. To tackle the expensive computation of the Hessian matrix and its inverse, we propose an approximation to the Newton–Raphson algorithm based on a so-called generalized Bernoulli density. The Newton–Raphson algorithm and its approximation have been applied to synthetic data, benchmark, and real-world multiclass classification tasks. For comparison, the IRLS algorithm and a quasi-Newton algorithm called BFGS have also been applied to the same tasks. Simulation results have shown that the use of the proposed learning algorithms avoids the instability problem and makes the ME architecture produce good performance in multiclass classification. In particular, our approximation algorithm leads to fast learning. In addition, the limitation of our approximation algorithm is also empirically investigated in this paper.},
	number = {9},
	journal = {Neural Networks},
	author = {Chen, K. and Xu, L. and Chi, H.},
	year = {1999},
	keywords = {Mixture of experts, BFGS algorithm, Expectation-Maximization (EM) algorithm, Generalized Bernoulli density, Iterative reweighted least squares (IRLS) algorithm, Multiclass classification, Multinomial density, Newton–Raphson method},
	pages = {1229--1252},
}


@article{green_iteratively_1984,
	title = {Iteratively {Reweighted} {Least} {Squares} for {Maximum} {Likelihood} {Estimation}, and some {Robust} and {Resistant} {Alternatives}},
	volume = {46},
	issn = {00359246},
	url = {http://www.jstor.org/stable/2345503},
	abstract = {The scope of application of iteratively reweighted least squares to statistical estimation problems is considerably wider than is generally appreciated. It extends beyond the exponential-family-type generalized linear models to other distributions, to non-linear parameterizations, and to dependent observations. Various criteria for estimation other than maximum likelihood, including resistant alternatives, may be used. The algorithms are generally numerically stable, easily programmed without the aid of packages, and highly suited to interactive computation.},
	number = {2},
	urldate = {2023-05-20},
	journal = {Journal of the Royal Statistical Society. Series B (Methodological)},
	author = {Green, P. J.},
	year = {1984},
	note = {Publisher: [Royal Statistical Society, Wiley]},
	pages = {149--192},
}


@article{krishnapuram_sparse_2005,
	title = {Sparse multinomial logistic regression: fast algorithms and generalization bounds},
	volume = {27},
	doi = {10.1109/TPAMI.2005.127},
	number = {6},
	journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
	author = {Krishnapuram, B. and Carin, L. and Figueiredo, M.A.T. and Hartemink, A.J.},
	year = {2005},
	pages = {957--968},
}


@inproceedings{chamroukhi_regression_2009,
	title = {A regression model with a hidden logistic process for feature extraction from time series},
	doi = {10.1109/IJCNN.2009.5178921},
	booktitle = {2009 {International} {Joint} {Conference} on {Neural} {Networks}},
	author = {Chamroukhi, Faicel and Same, Allou and Govaert, Gerard and Aknin, Patrice},
	year = {2009},
	pages = {489--496},
}


@article{chamroukhi_time_2009,
	title = {Time series modeling by a regression approach based on a latent process},
	volume = {22},
	number = {5-6},
	journal = {Neural Networks},
	author = {Chamroukhi, Faicel and Samé, Allou and Govaert, Gérard and Aknin, Patrice},
	year = {2009},
	note = {Publisher: Elsevier},
	pages = {593--602},
}


@article{huynh_estimation_2019,
	title = {Estimation and feature selection in mixtures of generalized linear experts models},
	journal = {arXiv preprint arXiv:1907.06994},
	author = {Huynh, Bao Tuyen and Chamroukhi, Faicel},
	year = {2019},
}


@article{gormley_mixture_2008,
	title = {A mixture of experts model for rank data with applications in election studies},
	volume = {2},
	url = {https://doi.org/10.1214/08-AOAS178},
	doi = {10.1214/08-AOAS178},
	number = {4},
	journal = {The Annals of Applied Statistics},
	author = {Gormley, Isobel Claire and Murphy, Thomas Brendan},
	year = {2008},
	note = {Publisher: Institute of Mathematical Statistics},
	keywords = {Mixture models, EM algorithm, generalized linear models, MM algorithm, rank data},
	pages = {1452 -- 1477},
}


@inproceedings{jiang_hierarchical_1999,
	series = {Proceedings of {Machine} {Learning} {Research}},
	title = {Hierarchical {Mixtures}-of-{Experts} for {Generalized} {Linear} {Models}: {Some} {Results} on {Denseness} and {Consistency}},
	volume = {R2},
	url = {https://proceedings.mlr.press/r2/jiang99a.html},
	booktitle = {Proceedings of the {Seventh} {International} {Workshop} on {Artificial} {Intelligence} and {Statistics}},
	publisher = {PMLR},
	author = {Jiang, Wenxin and Tanner, Martin A.},
	editor = {Heckerman, David and Whittaker, Joe},
	month = jan,
	year = {1999},
	annote = {Reissued by PMLR on 20 August 2020.},
}


@article{jiang_approximation_1999,
	title = {On the {Approximation} {Rate} of {Hierarchical} {Mixtures}-of-{Experts} for {Generalized} {Linear} {Models}},
	volume = {11},
	issn = {0899-7667},
	url = {https://doi.org/10.1162/089976699300016403},
	doi = {10.1162/089976699300016403},
	abstract = {We investigate a class of hierarchical mixtures-of-experts (HME) models where generalized linear models with nonlinear mean functions of the form ψ(α + xTβ) are mixed. Here ψ(·) is the inverse link function. It is shown that mixtures of such mean functions can approximate a class of smooth functions of the form ψ(h(x)), where h(·) ϵ W∞2;k (a Sobolev class over [0, 1]s, as the number of experts m in the network increases. An upper bound of the approximation rate is given as O(m−2/s) in Lp norm. This rate can be achieved within the family of HME structures with no more than s-layers, where s is the dimension of the predictor x.},
	number = {5},
	journal = {Neural Computation},
	author = {Jiang, Wenxin and Tanner, Martin A},
	month = jul,
	year = {1999},
	pages = {1183--1198},
}


@article{ruiz_hierarchical_2002,
	title = {Hierarchical {Text} {Categorization} {Using} {Neural} {Networks}},
	volume = {5},
	issn = {1573-7659},
	url = {https://doi.org/10.1023/A:1012782908347},
	doi = {10.1023/A:1012782908347},
	abstract = {This paper presents the design and evaluation of a text categorization method based on the Hierarchical Mixture of Experts model. This model uses a divide and conquer principle to define smaller categorization problems based on a predefined hierarchical structure. The final classifier is a hierarchical array of neural networks. The method is evaluated using the UMLS Metathesaurus as the underlying hierarchical structure, and the OHSUMED test set of MEDLINE records. Comparisons with an optimized version of the traditional Rocchio's algorithm adapted for text categorization, as well as flat neural network classifiers are provided. The results show that the use of the hierarchical structure improves text categorization performance with respect to an equivalent flat model. The optimized Rocchio algorithm achieves a performance comparable with that of the hierarchical neural networks.},
	number = {1},
	journal = {Information Retrieval},
	author = {Ruiz, Miguel E. and Srinivasan, Padmini},
	month = jan,
	year = {2002},
	pages = {87--118},
}


@article{peng_bayesian_1996,
	title = {Bayesian {Inference} in {Mixtures}-of-{Experts} and {Hierarchical} {Mixtures}-of-{Experts} {Models} {With} an {Application} to {Speech} {Recognition}},
	volume = {91},
	issn = {01621459},
	number = {435},
	urldate = {2023-05-16},
	journal = {Journal of the American Statistical Association},
	author = {Peng, Fengchun and Jacobs, Robert A. and Tanner, Martin A.},
	year = {1996},
	pages = {953--960},
}


@article{jacobs_bayesian_1997,
	title = {A {Bayesian} {Approach} to {Model} {Selection} in {Hierarchical} {Mixtures}-of-{Experts} {Architectures}},
	volume = {10},
	issn = {0893-6080},
	number = {2},
	journal = {Neural Networks},
	author = {Jacobs, Robert A. and Peng, Fengchun and Tanner, Martin A.},
	year = {1997},
	keywords = {Model selection, Bayesian analysis, Gibbs sampling, Hierarchical architecture, Modular architecture},
	pages = {231--241},
}


@inproceedings{zhao_hierarchical_1994,
	title = {Hierarchical mixtures of experts methodology applied to continuous speech recognition},
	volume = {7},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Zhao, Ying and Schwartz, Richard and Sroka, Jason and Makhoul, John},
	year = {1994},
}


@inproceedings{liang_m3vit_2022,
	title = {M$^3${ViT}: {Mixture}-of-{Experts} {Vision} {Transformer} for {Efficient} {Multi}-task {Learning} with {Model}-{Accelerator} {Co}-design},
	url = {http://papers.nips.cc/paper\_files/paper/2022/hash/b653f34d576d1790481e3797cb740214-Abstract-Conference.html},
	booktitle = {{NeurIPS}},
	author = {Liang, Hanxue and Fan, Zhiwen and Sarkar, Rishov and Jiang, Ziyu and Chen, Tianlong and Zou, Kai and Cheng, Yu and Hao, Cong and Wang, Zhangyang},
	year = {2022},
}


@inproceedings{hazimeh_dselect_k_2021,
	title = {{DSelect}-k: {Differentiable} {Selection} in the {Mixture} of {Experts} with {Applications} to {Multi}-{Task} {Learning}},
	volume = {34},
	url = {https://proceedings.neurips.cc/paper_files/paper/2021/file/f5ac21cd0ef1b88e9848571aeb53551a-Paper.pdf},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	publisher = {Curran Associates, Inc.},
	author = {Hazimeh, Hussein and Zhao, Zhe and Chowdhery, Aakanksha and Sathiamoorthy, Maheswaran and Chen, Yihua and Mazumder, Rahul and Hong, Lichan and Chi, Ed},
	editor = {Ranzato, M. and Beygelzimer, A. and Dauphin, Y. and Liang, P. S. and Vaughan, J. Wortman},
	year = {2021},
	pages = {29335--29347},
}


@inproceedings{ma_modeling_2018,
	address = {New York, NY, USA},
	series = {{KDD} '18},
	title = {Modeling {Task} {Relationships} in {Multi}-{Task} {Learning} with {Multi}-{Gate} {Mixture}-of-{Experts}},
	isbn = {978-1-4503-5552-0},
	url = {https://doi.org/10.1145/3219819.3220007},
	doi = {10.1145/3219819.3220007},
	abstract = {Neural-based multi-task learning has been successfully used in many real-world large-scale applications such as recommendation systems. For example, in movie recommendations, beyond providing users movies which they tend to purchase and watch, the system might also optimize for users liking the movies afterwards. With multi-task learning, we aim to build a single model that learns these multiple goals and tasks simultaneously. However, the prediction quality of commonly used multi-task models is often sensitive to the relationships between tasks. It is therefore important to study the modeling tradeoffs between task-specific objectives and inter-task relationships. In this work, we propose a novel multi-task learning approach, Multi-gate Mixture-of-Experts (MMoE), which explicitly learns to model task relationships from data. We adapt the Mixture-of-Experts (MoE) structure to multi-task learning by sharing the expert submodels across all tasks, while also having a gating network trained to optimize each task. To validate our approach on data with different levels of task relatedness, we first apply it to a synthetic dataset where we control the task relatedness. We show that the proposed approach performs better than baseline methods when the tasks are less related. We also show that the MMoE structure results in an additional trainability benefit, depending on different levels of randomness in the training data and model initialization. Furthermore, we demonstrate the performance improvements by MMoE on real tasks including a binary classification benchmark, and a large-scale content recommendation system at Google.},
	booktitle = {Proceedings of the 24th {ACM} {SIGKDD} {International} {Conference} on {Knowledge} {Discovery} \& {Data} {Mining}},
	publisher = {Association for Computing Machinery},
	author = {Ma, Jiaqi and Zhao, Zhe and Yi, Xinyang and Chen, Jilin and Hong, Lichan and Chi, Ed H.},
	year = {2018},
	note = {event-place: London, United Kingdom},
	keywords = {mixture of experts, neural network, multi-task learning, recommendation system},
	pages = {1930--1939},
}


@inproceedings{waterhouse_classification_1994,
	title = {Classification using hierarchical mixtures of experts},
	doi = {10.1109/NNSP.1994.366050},
	booktitle = {Proceedings of {IEEE} {Workshop} on {Neural} {Networks} for {Signal} {Processing}},
	author = {Waterhouse, S.R. and Robinson, A.J.},
	year = {1994},
	pages = {177--186},
}


@inproceedings{zhou_mixture_experts_2022,
	title = {Mixture-of-{Experts} with {Expert} {Choice} {Routing}},
	url = {https://openreview.net/forum?id=jdJo1HIVinI},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Zhou, Yanqi and Lei, Tao and Liu, Hanxiao and Du, Nan and Huang, Yanping and Zhao, Vincent Y. and Dai, Andrew M. and Chen, Zhifeng and Le, Quoc V. and Laudon, James},
	editor = {Oh, Alice H. and Agarwal, Alekh and Belgrave, Danielle and Cho, Kyunghyun},
	year = {2022},
}


@inproceedings{karakoulas_semi_supervised_2004,
	title = {Semi-supervised mixture-of-experts classification},
	doi = {10.1109/ICDM.2004.10103},
	booktitle = {Fourth {IEEE} {International} {Conference} on {Data} {Mining} ({ICDM}'04)},
	author = {Karakoulas, G. and Salakhutdinov, R.},
	year = {2004},
	pages = {138--145},
}


@article{doss_optimal_2023,
	title = {Optimal estimation of high-dimensional {Gaussian} location mixtures},
	volume = {51},
	url = {https://doi.org/10.1214/22-AOS2207},
	doi = {10.1214/22-AOS2207},
	number = {1},
	journal = {The Annals of Statistics},
	author = {Doss, Natalie and Wu, Yihong and Yang, Pengkun and Zhou, Harrison H.},
	year = {2023},
	note = {Publisher: Institute of Mathematical Statistics},
	keywords = {method of moments, Finite mixture model, Gaussian mixture, Minimax optimality, high-dimensional density estimation, low-rank tensor, Metric entropy},
	pages = {62 -- 95},
}

@article{manole_selection_2023,
	title = {Optimal estimation of high-dimensional {Gaussian} location mixtures},
	volume = {51},
	url = {https://doi.org/10.1214/22-AOS2207},
	doi = {10.1214/22-AOS2207},
	number = {1},
	journal = {The Annals of Statistics},
	author = {Doss, Natalie and Wu, Yihong and Yang, Pengkun and Zhou, Harrison H.},
	year = {2023},
	note = {Publisher: Institute of Mathematical Statistics},
	keywords = {method of moments, Finite mixture model, Gaussian mixture, Minimax optimality, high-dimensional density estimation, low-rank tensor, Metric entropy},
	pages = {62 -- 95},
}


@inproceedings{chamroukhi_regularized_2018,
	title = {Regularized {Maximum}-{Likelihood} {Estimation} of {Mixture}-of-{Experts} for {Regression} and {Clustering}},
	doi = {10.1109/IJCNN.2018.8489670},
	booktitle = {2018 {International} {Joint} {Conference} on {Neural} {Networks} ({IJCNN})},
	author = {Chamroukhi, Faicel and Huynh, Bao Tuyen},
	year = {2018},
	pages = {1--8},
}

@article{chamroukhi_regularized_2019,
	title = {Regularized {Maximum} {Likelihood} {Estimation} and {Feature} {Selection} in {Mixtures}-of-{Experts} {Models}},
	volume = {160},
	number = {1},
	journal = {Journal de la Société Française de Statistique},
	author = {Chamroukhi, Faicel and Huynh, Bao-Tuyen},
	year = {2019},
	pages = {57--85},
}


@article{chamroukhi_hidden_2010,
	title = {A hidden process regression model for functional data description. {Application} to curve discrimination},
	volume = {73},
	number = {7-9},
	journal = {Neurocomputing},
	author = {Chamroukhi, Faicel and Samé, Allou and Govaert, Gérard and Aknin, Patrice},
	year = {2010},
	pages = {1210--1221},
}


@article{dempster_maximum_1977,
	title = {Maximum {Likelihood} from {Incomplete} {Data} {Via} the {EM} {Algorithm}},
	volume = {39},
	issn = {0035-9246},
	url = {https://doi.org/10.1111/j.2517-6161.1977.tb01600.x},
	doi = {10.1111/j.2517-6161.1977.tb01600.x},
	abstract = {Summary A broadly applicable algorithm for computing maximum likelihood estimates from incomplete data is presented at various levels of generality. Theory showing the monotone behaviour of the likelihood and convergence of the algorithm is derived. Many examples are sketched, including missing value situations, applications to grouped, censored or truncated data, finite mixture models, variance component estimation, hyperparameter estimation, iteratively reweighted least squares and factor analysis.},
	number = {1},
	urldate = {2022-02-06},
	journal = {Journal of the Royal Statistical Society: Series B (Methodological)},
	author = {Dempster, A. P. and Laird, N. M. and Rubin, D. B.},
	month = sep,
	year = {1977},
	keywords = {em algorithm, incomplete data, maximum likelihood, posterior mode},
	pages = {1--22},
	annote = {https://doi.org/10.1111/j.2517-6161.1977.tb01600.x},
}


@article{montuelle_mixture_2014,
	title = {Mixture of {Gaussian} regressions model with logistic weights, a penalized maximum likelihood approach},
	volume = {8},
	number = {1},
	journal = {Electronic Journal of Statistics},
	author = {Montuelle, Lucie and Le Pennec, Erwan},
	year = {2014},
	pages = {1661--1695},
}


@article{Chen-2003,
        author="H. Chen and J. Chen",
        title="Tests for homogeneity in normal mixtures in the presence of a structural parameter",
        journal="Statistica Sinica",
        volume="13",
        pages="351-365",
        year="2003"
}

@article{Shimotsu-2014,
        author="H. Kasahara and K. Shimotsu",
        title="Testing the number of components in normal mixture regression models",
        journal="Journal of the American Statistical Association",
        volume="",
        pages="",
        year="2014"
}

@book{Vandegeer-2000,
author= "S. van de Geer",
title="Empirical Processes in M-estimation",
publisher= "Cambridge University Press",
year="2000"
}

@book{Polak-book,
author = "E. Polak",
title = "Optimization: Algorithms and Consistent Approximations",
publisher = "Springer",
year = "1997"
}

@book{Dudley-76,
author = "R. M. Dudley",
title = "Probabilities and metrics: Convergence of laws on metric spaces, with a view to statistical testing",
publisher = "Aarhus Universitet",
year = "1976"
}

@book{Villani-03,
author = "C\'edric Villani",
title = "Topics in Optimal Transportation",
publisher = "American Mathematical Society", 
year = "2003"}

@book{Villani-09,
author = "C\'edric Villani",
title = "Optimal transport: Old and New",
publisher = "Springer",
year = "2008"
}

@book{Rachev-Ruschendorf,
author = "S. T. Rachev and L. Ruschendorf",
title = "Mass transportation problems. Vol I: Theory, Vol II: Probability and its Applications", 
publisher = "Springer-Verlag",
year = "1998"
}

@book{Rachev-91,
author = "S. T. Rachev",
title = "Probability metrics and the stability of stochastic systems",
publisher = "John Wiley and Sons Ltd.",
year = "1991"
}

@article{Zhang-90,
author = "C. Zhang",
year = "1990",
title = "Fourier methods for estimating mixing densities and distributions",
journal = "Annals of Statistics",
volume = "18",
number = "2",
pages = "806--831"
}

@article{Fan-91,
author = "J. Fan",
year = "1991",
title = "On the optimal rates of convergence for nonparametric deconvolution problems",
journal = "Annals of Statistics",
volume = "19",
number = "3",
pages = "1257--1272"
}

@article{Carroll-Hall-88,
author = "R. J. Carroll and P. Hall",
year = "1988",
title = "Optimal rates of convergence for deconvolving a density",
journal = "Journal of American Statistical Association",
volume = "83",
pages = "1184--1186"
}


@article{Caillerie-etal-11,
author = "C. Caillerie and F. Chazal and J. Dedecker and B. Michel",
title = "Deconvolution for the {W}asserstein metric and geometric inference",
journal = "Electronic Journal of Statistics",
volume = "5",
pages = "1394--1423",
year = "2011"
}

@article{Dedecker-Michel-13,
author = "J. Dedecker and B. Michel",
title = "Minimax rates of convergence for {W}asserstein deconvolution with supersmooth errors in any dimension",
journal = "Arxiv manuscript",
year = "2013"
}


@article{Bickel-Freedman-81,
author = "P. Bickel and D. Freedman",
year = "1981",
title = "Some asymptotic theory for the bootstrap",
journal = "Annals of Statistics",
volume = "9",
number = "6",
pages = "1196--1217"
}

@article{delBarrio-etal-99,
author = "E. del Barrio and J. Cuesta-Albertos and C. Matr\'an and J. Rodr\'iguez-Rodr\'iguez",
year = "1999",
title = "Tests of goodness of fit based on the $L_2$-Wasserstein distance",
journal = "Annals of Statistics",
volume = "27",
number = "4",
pages = "1230--1239"
}


@article{Mallows-72,
author = "C. Mallows",
year = "1972",
title = "A note on asymptotic joint normality",
journal = "Annals of Mathematical Statistics",
volume = "43",
pages = "508--515"
}


@article{Dobrushin-70,
author = "R. Dobrushin",
year = "1970",
title = "Describing a system of random variables by conditional distributions",
journal = "Theory Probab. Appl.",
volume = "15",
pages = "458--486"
}


@article{Gibbs-Su-02,
author = "A. L. Gibbs and F. E. Su",
year = "2002",
title = "On choosing and bounding probability metrics",
journal = "International Statistical Review",
volume = "70",
number = "3",
pages = "419--435"
}


@book{Ferraty-Vieu-06,
author = "F. Ferraty and P. Vieu",
title = "Nonparametric Functional Data Analysis: {T}heory and {P}ractice",
publisher = "Springer",
year = "2006"
}

@book{Ramsay-Silverman-02,
author = "J. O. Ramsay and B. W. Silverman",
title = "Applied functional data analysis: {M}ethods and case studies",
publisher = "Springer-Verlag", 
address = "New York",
year = "2002"
}

@book{Ramsay-Silverman-05,
author = "J. O. Ramsay and B.W. Silverman",
title = "Functional Data Analysis",
edition = "2",
publisher = "Springer",
year = "2006"
}

@article{Abraham-etal-03,
author = "C. Abraham and P.A. Cornillon and E. Matzner-Lober and N. Molinari",
year = "2003",
title = "Unsupervised curve clustering using B-splines",
journal = "Scand. J. Statist.",
volume = "30", 
pages = "581--595"
}

@article{Biau-etal-08,
author = "G. Biau and L. Devroye and G. Lugosi",
year = "2008",
title = "On the Performance of Clustering in Hilbert Spaces",
journal = "IEEE Trans. Inform. Theory",
volume = "54", 
pages = "781--790" 
} 

@article{Chiou-Li-07,
author = "J.-M. Chiou and P.-L. Li",
year = "2007",
title = "Functional clustering and identifying substructures of longitudinal data",
journal = "J. Roy. Statist. Soc. Ser. B",
volume = "69", 
pages = "679--699",
}

@article{Cuesta-Albertos-Fraiman-07,
author = "J. A. Cuesta-Albertos and R. Fraiman",
year = "2007", 
title = "Impartial trimmed k-means for functional data",
journal = "Comput. Statist. Data Anal.",
volume = "51", 
pages = "4864--4877"
}

@article{Dabo-Niang-etal-06,
author = "S. Dabo-Niang and F. Ferraty and P. Vieu",
year = "2006",
title = "Mode estimation for functional random variable and its application for curves classication",
journal = "Far East J.  Theor. Stat.",
volume = "18", 
pages = "93--119"
}

@article{Fraiman-etal-08,
author = "R. Fraiman and A. Justel and M. Svarc",
year = "2008", 
title = "Selection of variables for cluster analysis and classication rules",
journal = "J. Amer. Stat. Assoc.",
volume = "103", 
pages = "1294--1303"
}

@article{Fraiman-Muniz-01,
author = "R. Fraiman and G. Muniz",
year = "2001",
title = "Trimmed means for functional data",
journal = "Test",
volume = "10", 
pages = "419--440"
}

@article{James-Sugar-03,
author = "G. M. James and C.A. Sugar",
year = "2003",
title = "Clustering for sparsely sampled functional data",
journal = "J. Amer. Stat. Assoc.",
volume = "98", 
pages = "397--408"
}

@article{Ma-Zhong-08,
author = "P. Ma and W. Zhong",
year = "2008",
title = "Penalized clustering of large-scale functional data with multiple covariates",
journal = "J. Amer. Statist. Assoc.",
volume = "103", 
pages = "625--636"
}

@article{Tokushige-etal-07,
author = "S. Tokushige and H. Yadohisa and K. Inada",
year = "2007",
title = "Crisp and fuzzy k-means clustering algorithms for multivariate functional data",
journal = "Comput. Statist.",  
volume = "22", 
pages = "1--16"
}


@ARTICLE{ishwaran-zarepour,
  author = "H. Ishwaran and M. Zarepour",
  title = "Dirichlet prior sieves in finite normal mixtures",
  journal = "Statistica Sinica", 
  year = "2002",
  volume = "12",
  pages = "941--963"
}

@article{Teicher-63,
author = "H. Teicher",
title = "Identifiability of finite mixtures",
journal = "Ann. Math. Statist.",
volume = "32",
year = "1963",
pages = "1265--1269"
}

@article{Ghosal-09,
author = "S. Ghosal",
title = "Dirichlet process, related priors and posterior asymptotics",
journal = "Manuscript",
year = "2007"
}

@article{Ghosal-Ghosh-Ramamoorthi-99,
author = "S. Ghosal and J. K. Ghosh and R. V. Ramamoorthi",
title = "Posterior consistency of Dirichlet mixtures in density estimation",
journal = "Annals of Statistics",
volume = "27",
pages = "143--158",
year = "1999"
}

@article{Barron-Shervish-Wasserman-99,
author = "A. Barron and M. Schervish and L. Wasserman",
title = "The consistency of posterior distributions in nonparametric problems",
journal = "Ann. Statist",
volume = "27",
pages = "536--561",
year = "1999"
}



@article{Wu-Ghosal,
author = "Y. Wu and S. Ghosal",
title = "L1-Consistency of Dirichlet mixtures in multivariate Bayesian density estimation",
year = "2009",
pages = "submitted"
}


@book{Stein99,
author = "M.L. Stein",
title = "Interpolation of Spatial Data",
publisher = "Springer-Verlag",
address = "New York",
year = "1999"
}

@inproceedings{MS-images,
author = "J. Winn and A. Criminisi and T. Minka",
title = "Object Categorization by Learned Universal Visual Dictionary",
booktitle =  "Proc. IEEE Intl. Conf. on Computer Vision (ICCV)",
year = "2005"
}


@ARTICLE{Brumback-Rice98,
  author = "B.A. Brumback and J. Rice",
  title = "Smoothing spline models for the analysis of nested and
crossed samples of curves",
  journal = "J. Amer. Statist. Assoc.",
  year = "1998",
  volume = "93",
  number = "443",
  pages = "961--980"
}


@ARTICLE{Sudderth-et-al08,
  author = "E. Sudderth and A. Torralba and W. Freeman and A. Willsky",
  title = "Describing Visual Scenes Using Transformed Objects and Parts",
  journal = "International Journal of Computer Vision",
  year = "2008",
  volume = "77"
}



@ARTICLE{Pritchard-et-al00,
  author = "J. Pritchard and M. Stephens and P. Donnelly",
  title = "Inference of populaton structure using multilocus genotype data",
  journal = "Genetics",
  year = "2000",
  volume = "155",
  pages = "945--959"
}


@ARTICLE{DeIorio-et-al,
  author = "M. DeIorio and P. Muller and G.L. Rosner and S.N. MacEachern",
  title = "An {ANOVA} model for dependent random measures",
  journal = "J. Amer. Statist. Assoc.",
  year = "2004",
  volume = "99",
  pages = "205-215"
}


@ARTICLE{Duan-et-al07,
  author = "J. Duan and M. Guindani and A. Gelfand",
  title = "Generalized spatial {D}irichlet processes",
  journal = "Biometrika",
  volume = "94",
  number = "4",
  pages = "809--825",
  year = "2007"
}


@ARTICLE{Dunson-Park,
  author = "D.B. Dunson and J.-H. Park",
  title = "Kernel stick-breaking processes",
  journal = "Biometrika",
  volume = "95",
  number = "2",
  pages = "307--323",
  year = "2008"
}

@techreport{Dunson-kernellabel,
  author = "D.B. Dunson",
  title = "Kernel local partition processes for functional data",
  institution = "Department of Statistical Science, Duke University",
  number = "26", 
  year = "2008"
}

@ARTICLE{Dunson-partition,
  author = "D.B. Dunson",
  title = "Nonparametric Bayes local partition models for random effects",
  journal = "Biometrika",
  pages = "to appear",
  year = "2008"
}

@article{McLehose-Dunson,
author = "R. F. MacLehose and D.B. Dunson",
title = "Nonparametric Bayes kernel-based priors for functional data analysis", 
journal = "Statistica Sinica",
pages = "to appear",
year = "2008"
}

@techreport{Pillai-et-al,
author = "N. Pillai and F. Liang and S. Mukerjee and R. Wolpert and Q. Wu",
title = "Characterizing the function space for Bayesian kernel models",
institution = "Departmet of Statistical Science, Duke University",
year = "2006"
}


@inproceedings{ksbp-images,
author = "Q. An and C. Wang and I. Shterev and E. Wang and L. Carin and 
D. Dunson",
title = "Hierachicial kernel stick-breaking process for multi-task image
analysis",
booktitle = "Proc. ICML",
year = "2008"
}

@ARTICLE{Ferguson,
  author = "T.S. Ferguson",
  title = "A {B}ayesian analysis of some nonparametric problems",
  journal = "Ann. Statist.",
  year = "1973",
  volume = "1",
  pages = "209--230"
}



@ARTICLE{Gelfand-et-al05,
  author = "A.E. Gelfand and A. Kottas and S.N. MacEachern",
  title = "Bayesian nonparametric spatial modeling with {D}irichlet process mixing",
  journal = "J. Amer. Statist. Assoc.",
  year = "2005",
  volume = "100",
  pages = "1021--1035"
}

@techreport{Griffin-Steel-tech06,
  author = "J.E. Griffin and M.F. Steel",
  title = "Bayesian nonparametric spatial modeling with {D}irichlet process mixing",
  institution = "Dept. of Statistics, University of Warwick",
  year = "2005",
}

@ARTICLE{Griffin-Steel06,
  author = "J.E. Griffin and M.F. Steel",
  title = "Order-based dependent {D}irichlet processes",
  journal = "J. Amer. Statist. Assoc.",
  year = "2006",
  volume = "101",
  pages = "179--194"
}


@ARTICLE{Ishwaran-James,
  author = "H. Ishwaran and L.F. James",
  title = "Gibbs sampling methods for stick-breaking priors",
  journal = "J. Amer. Statist. Assoc.",
  year = "2001",
  volume = "96",
  pages = "161--173"
}

@techreport{MacEachern00,
  author = "S.N. MacEachern",
  title = "Dependent {D}irichlet processes",
  institution = "Ohio State University",
  year = "2000"
}

@article{PGG07,
    author = "S. Petrone and M. Guidani and A.E. Gelfand",
    title = "Hybrid {D}irichlet processes for functional data",
    journal = "J. Royal Stat. Soc. Series B",
    year = "2009",
    volume = "to appear"
}


@ARTICLE{Rodriguez-et-al07,
  author = "A. Rodriguez and D. Dunson and A.E. Gelfand",
  title = "The nested {D}irichlet process",
  journal = "J. Amer. Statist. Assoc.",
  year = "to appear"
}


@ARTICLE{Sethuraman,
  author = "J. Sethuraman",
  title = "A constructive definition of {D}irichlet priors",
  journal = "Statistica Sinica",
  year = "1994",
  volume = "4",
  pages = "639--650"
}


@ARTICLE{Teh-et-al06,
  author = "Y.W. Teh and M.I. Jordan and M.J. Beal and D.M. Blei",
  title = "Hierarchical {D}irichlet processes",
  journal = "J. Amer. Statist. Assoc.",
  year = "2006",
  volume = "101",
  pages = "1566--1581"
}


@ARTICLE{Blei-et-al,
  author = "D.M. Blei and A.Y. Ng and M.I. Jordan",
  title = "Latent {D}irichlet allocation",
  journal = "J. Mach. Learn. Res", 
  year = "2003",
  volume = "3",
  pages = "993--1022"
}

@inproceedings{Wang-Grimson,
  title = "Spatial latent {D}irichlet allocation",
  author = "X. Wang and E. Grimson",
  booktitle = "NIPS 20",
  year = "2008"
}

@inproceedings{Figueiredo-et-al07,
  title = "Clustering under prior knowledge with application to image segmentation",
  author = "M.A. Figueiredo and D.S. Cheng and V. Murino",
  booktitle = "NIPS 19",
  year = "2007",
}


@ARTICLE{Fernandez-Green,
  author = "C. Fernandez and P. Green",
  title = "Modelling spatially correlated data via mixtures: A {B}ayesian approach",
  journal = "J. Roy. Statist. Soc, Series B",
  year = "2002",
  volume = "64",
  pages = "805--826"
}

@ARTICLE{Green-Richardson,
  author = "P. Green and S. Richardson",
  title = "Hidden {M}arkov models and desease mapping",
  journal = "J. Amer. Statist. Assoc.",
  year = "2001",
  volume = "97",
  pages = "1055--1070"
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%  analysis/optimization references
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

@book{Phelps93,
title = "Convex functions, monotone operators and
differentiability", 
author = "R. R. Phelps",
volume = "1364 of Lecture Notes in Math",
publisher = "Springer",
year = "1993"
}

@TECHREPORT{Wainwright03, 
  TITLE = "Graphical models, exponential families, and variational inference",
  AUTHOR = "M. J. Wainwright and M. I. Jordan",
  INSTITUTION = "Dept of Statistics, UC Berkeley", 
  NUMBER = 649,
  MONTH = "Sept",
  YEAR = 2003
}


@BOOK{Bertsekas_nonlin,
AUTHOR = "D.P. Bertsekas", 
TITLE = "Nonlinear Programming",
PUBLISHER = "Athena Scientific", 
ADDRESS = "Belmont, MA", 
YEAR = "1995",
}

@BOOK{Berg84,
EDITOR = "C. Berg and J. P. R. Christensen and P. Ressel",
TITLE = "Harmonic analysis on semigroups",
PUBLISHER = "Springer-Verglag",
ADDRESS = "New York",
YEAR = 1984
}


@ARTICLE{Aronszajn50,
  author = "N. Aronszajn",
  title = "Theory of reproducing kernels",
  journal = "Transactions of the American Mathematical Society",
  year = 1950,
  volume = "68",
  pages = "337--404"
}

@BOOK{Luenberger69,
   AUTHOR = "D. G. Luenberger",
   TITLE = "Optimization by Vector Space Methods",
   YEAR = 1969,
   PUBLISHER = "Wiley",
   ADDRESS = "New York"
}

% Authoritative text on convex analysis
@BOOK{Rockafellar,
AUTHOR = "G. Rockafellar",
TITLE = "Convex Analysis",
PUBLISHER = "Princeton University Press",
ADDRESS = "Princeton", 
YEAR = "1970"
}

@book{Urruty01,
title = "Fundamentals of Convex Analysis",
author = "J. Hiriart-Urruty and C. Lemar\'echal",
publisher = "Springer",
year = "2001"
}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%5
% Statistical learning theory references
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

@ARTICLE{Koltchinskii02,
  author = "V. Koltchinskii and D. Panchenko",
  title = "Empirical margin distributions and bounding the generalization error
of combined classifiers",
  journal = "Annals of Statistics",
  year = 2002,
  volume = "30",
  pages = "1-50"
}


@ARTICLE{Bousquet02,
  author = "O. Bousquet and A. Elisseeff",
  title = "Stability and generalization",
  journal = "Journal of Machine Learning Research",
  year = 2002,
  volume = "2",
  pages = "499--526"
}


@ARTICLE{Freund97,
  author = "Y. Freund and R. Schapire",
  title = "A decision-theoretic generalization of on-line learning and an application to boosting",
  journal = "Journal of Computer and System Sciences",
  year = "1997",
  volume = "55(1)",
  pages = "119--139"
}


@ARTICLE{Bartlett02,
  author = "P. Bartlett and S. Mendelson",
  title = "{G}aussian and {R}ademacher complexities: {R}isk bounds and structural results",
  journal = "Journal of Machine Learning Research",
  year = 2002,
  volume = "3",
  pages = "463--482"
}


@INPROCEEDINGS{Predd04,
   AUTHOR = "J. Predd and S. Kulkarni and H. V. Poor",
   title = "Consistency in Models
for Communication Constrained Distributed Learning", 
   BOOKTITLE = 	 "Proceedings of the COLT", 
   YEAR = 	 2004,
   PAGES = "442--456"
}


@book{Weinert82,
EDITOR = "H. L. Weinert",
title = "Reproducing Kernel Hilbert Spaces : 
Applications in Statistical Signal Processing",
publisher = "Hutchinson Ross Publishing Co.", 
address = "Stroudsburg, PA",
year = "1982"
}

@book{Saitoh88,
author = "S. Saitoh",
title = "Theory of Reproducing Kernels and its Applications",
publisher = "Longman Scientific \& Technical",
address = "Harlow, UK",
year = "1988"
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%	Theoretical statistics references
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

@article{Blackwell51,
author = "D. Blackwell",
title = "Comparison of experiments",
journal = "Proceeding of 2nd Berkeley Symposium on Probability and Statistics",
volume = "1",
pages = "93--102",
year = "1951"
}

@article{Blackwell53,
author = "D. Blackwell",
title = "Equivalent comparisons of experiments",
journal = "Annals of Statistics",
volume = "24(2)",
pages = "265--272",
year = "1953"
}

@article{Bradt56,
author = "R. Bradt and S. Karlin",
title = "On the design and comparison of certain dichotomous experiments",
journal = "Annals of Statistics",
volume = "27(2)",
pages = "390-409",
year = "1956"
}

@article{Goel79,
author = "P. Goel and M. DeGroot",
title = "Comparisons of experiments and information measures",
journal = "Annals of Statistics",
volume = "7(2)",
pages = "1066--1077",
year = "1979"
}

@article{Chernoff52,
author = "H. Chernoff",
title = "A measure of asymptotic efficiency for tests of a hypothesis
based on a sum of observations",
journal = "Annals of Statistics",
volume = "23",
pages = "493--507",
year = "1952"
}

@article{Massart00,
author = "P. Massart",
title = "Some applications of concentration inequalities to statistics",
journal = "Annales de la Facult\'e des Sciences de Toulouse",
volume = "IX",
pages = "245--303",
year = "2000"
}

@inproceedings{McDiarmid89,
author = "C. McDiarmid",
title = "On the method of bounded differences",
booktitle = "Surveys in Combinatorics",
publisher = "(J. Simons, ed.) Cambridge University Press",
year = "1989"
}

@BOOK{vanderVaart-Wellner-96,
AUTHOR = "A. W. van der Vaart and J. Wellner",
TITLE = "Weak Convergence and Empirical Processes",
PUBLISHER = "Springer-Verlag", 
ADDRESS = "New York, NY", 
YEAR = "1996"
}

@BOOK{vanderVaart-98,
AUTHOR = "A. W. van der Vaart",
TITLE = "Asymptotic Statistics",
PUBLISHER = "Cambridge University Press",
YEAR = "1998"
}

@BOOK{LeCam-86,
author = "L. Le \ Cam",
title = "Asymptotic methods in statistical decision theory",
publisher = "Springer-Verlag",
year = "1986"
}


@BOOK{vandeGeer-00,
AUTHOR = "S. van de Geer",
TITLE = "Empirical processes in M-estimation",
PUBLISHER = "Cambridge University Press",
YEAR = "2000"
}

@ARTICLE{Zhang04,
  author = "T. Zhang",
  title = "Statistical behavior and consistency of classification methods based on convex risk minimization",
  journal = "Annal of Statistics",
  year = 2004,
  volume = "53",
  pages = "56--134"
  }


@ARTICLE{Zhang06-AoS,
  author = "T. Zhang",
  title = "From $\epsilon$-entropy to {KL}-entropy: 
Analysis of Minimum Complexity Density Estimation",
  journal = "Ann. Statist.",
  volume = "34",
  pages = "2180--2210",
  year = "2006"
  }


@article{Zhang06-IT,
author = "T. Zhang",
title = "Information Theoretical Upper and Lower 
Bounds for Statistical Estimation",
journal = "IEEE Trans.Info.", 
year = "2006",
volume = "51",
pages = "1307--1321"
}

@article{Steinwart05,
author = "I. Steinwart",
title = "Consistency of support vector machines and other regularized
kernel machines",
journal = "IEEE Trans. Info. Theory",
year = "2005",
volume = "51",
pages = "128-142"
}


@ARTICLE{Friedman00,
  author = "J. Friedman and T. Hastie and R. Tibshirani",
  title = "Additive logistic regression: A statistical view of boosting",
  journal = "Annals of Statistics",
  year = "2000",
  volume = "28",
  pages = "337--374"
}

@ARTICLE{Bartlett05,
  TITLE = "Convexity, classification and risk bounds",
  AUTHOR = "P. Bartlett and M. I. Jordan and J. D. McAuliffe",
  JOURNAL = "Journal of the American Statistical Association",
  YEAR = "2006",
  volume = "101",
  pages = "138--156"
}

@ARTICLE{Breiman98,
  TITLE = "Arcing classifiers",
  AUTHOR = "L. Breiman",
  journal = "Annals of Statistics",
  year = "1998",
  volume = "26",
  pages = "801--824"
}


@article{Jiang04,
title = "Process consistency for Adaboost",
author = "W. Jiang",
journal = "Annals of Statistics",
year = "2004",
volume = "32",
pages = "13--29"
}

@article{Lugosi04,
title = "On the Bayes-risk consistency of regularized boosting methods",
author = "G. Lugosi and N. Vayatis",
journal = "Annals of Statistics",
year = "2004",
volume = "32",
pages = "30--55"
}

@article{Mannor03,
title = "Greedy algorithms for classification - consistency, convergence rates and adaptivity",
author = "S. Mannor and R. Meir and T. Zhang",
journal = "Journal of Machine Learning Research",
year = "2003",
volume = "4",
pages = "713--741"
}

@ARTICLE{Yang99,
  TITLE = "Information theoretic determination of minimax rates of convergence",
  AUTHOR = "Y. Yang and A. Barron",
  journal = "Annals of Statistics",
  year = "1999",
  volume = "27",
  pages = "1564--1599"
}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%	Information theory and signal processing papers
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

@article{Guo05,
author = "D. Guo and S. Shamai and S. Verdú",
title =  "Mutual Information and Minimum Mean-Square Error in Gaussian Channels",
journal = "IEEE Trans. Information Theory",
volume =  "51",
number = "4",
pages = "1261--1283",
year = "2005"
}

@book{Cover91,
title = "Elements of information theory",
author = "T. Cover and J. Thomas",
publisher = "Wiley",
year = "1991"
}


@ARTICLE{Csiszar-67,
  author = "I. Csisz\'ar",
  title = "Information-type measures of difference of probability distributions and indirect observation",
  journal = "Studia Sci. Math. Hungar",
  year = 1967,
  volume = "2",
  pages = "299--318"
}


@ARTICLE{Ali-Silvey-66,
  author = "S. M. Ali and S. D. Silvey",
  title = "A general class of coefficients of divergence of one distribution from another",
  journal = "J. Royal Stat. Soc. Series B",
  year = 1966,
  volume = "28",
  pages = "131--142"
}

@ARTICLE{Kailath1,
  author = "T. Kailath",
  title = "{RKHS} approach to detection and estimation problems---{P}art {I}: {D}eterministic signals in {G}aussian noise", 
  journal = "{IEEE} {T}rans. {I}nfo. {T}heory.",
  year = 1971,
  volume = "17",
  pages = "530--549"
}

@ARTICLE{Kailath98,
  author = "T. Kailath and H. V. Poor",
  title = "Detection of stochastic processes",
  journal = "{IEEE} {T}rans. {I}nfo. {T}heory.",
  year = 1998,
  volume = "44",
  pages = "2230--2259"
}

@ARTICLE{Kailath67,
  author = "T. Kailath",
  title = "The Divergence and {B}hattacharyya Distance Measures in Signal Selection",
  journal = "IEEE Trans. on Communication Technology",
  year = 1967,
  volume = "15(1)",
  pages = "52--60"
}

@ARTICLE{Longo90,
  author = "M. Longo and T. Lookabaugh and R. Gray",
  title = "Quantization for Decentralized Hypothesis Testing under Communication Contraints",
  journal = "IEEE Trans. on Information Theory",
  year = 1990,
  volume = "36(2)",
  pages = "241--255"
}

@ARTICLE{Poor77,
  author = "H. V. Poor and J. B. Thomas",
  title = "Applications of {A}li-{S}ilvey distance measures in the design
of generalized quantizers for binary decision systems",
  journal = "IEEE Trans. on Communications",
  year = 1977,
  volume = "25",
  pages = "893--900"
}


% Original Tenney article
@ARTICLE{Tenney81,
  author = "R. R. Tenney and Sandell, N. R. Jr.",
  title = "Detection with Distributed Sensors",
  journal = "IEEE Trans. Aero. Electron. Sys.",
  year = 1981,
  volume = "17",
  pages = "501--510"
}



% 
@BOOK{vanTrees,
AUTHOR = "H. L. van Trees",
TITLE = "Detection, Estimation and Modulation Theory",
PUBLISHER = "Krieger Publishing Co.",
ADDRESS = "Melbourne, FL", 
YEAR = "1990"
}





@UNPUBLISHED{Luo03,
 AUTHOR = "Z. Luo",
 TITLE = "Universal decentralized estimation in a bandwidth constrained sensor network",
 YEAR = "2003",
 MONTH = "September"
  }      

@INCOLLECTION{Tsitsiklis93,
  author =   {J. N. Tsitsiklis},
  BOOKTITLE =    "Advances in Statistical Signal Processing",
  EDITORS = "H. V. Poor and J. B. Thomas",
  TITLE = "Decentralized Detection",
  publisher =    {JAI Press},
  pages = {297--344},
  year =     1993
}

@article{Tsitsiklis93-extremal,
author = "J. Tsitsiklis",
title = "Extremal properties of likelihood-ratio quantizers",
journal = "IEEE Trans. on Communication",
volume = "41(4)",
pages = "550--558",
year= "1993"
}

@INCOLLECTION{Kassam93,
  author =   {S. A. Kassam},
  BOOKTITLE =    "Advances in Statistical Signal Processing",
  EDITORS = "H. V. Poor and J. B. Thomas",
  TITLE = "Nonparametric signal detection",
  publisher =    {JAI Press},
  year =     1993
}

@book{Poor94,
author = "H. V. Poor",
title = "An introduction to signal detection and estimation",
publisher = "New York: Springer-Verlag",
year = "1994",
edition = "2"
}

%% wilcoxon test
@article{Viswanathan89,
author = "R. Viswanathan and A. Ansari",
title = "Distributed detection of a signal in generalized {G}aussian noise",
journal = "IEEE Trans. Acoust., Speech, and Signal Process.",
volume = "37",
pages = "775--778",
year= "1989"
}

@article{Topsoe,
author = "F. Topsoe",
title = "Some inequalities for information divergence and
related measures of discrimination",
journal = "IEEE Transactions on Information Theory",
volume = "46",
pages = "1602--1609",
year= "2000"
}

@article{Nasipuri97,
author = "A. Nasipuri and S. Tantaratana",
title = "Nonparametric distributed detection using {W}ilcoxon statistics",
journal = "Signal Processing", 
Volume = "57", 
number = "2",
pages = "139-146", 
publisher = "Elsevier Press", 
year= "1997"
}
@ARTICLE{Blum97,
  author = "R. S. Blum and S. A. Kassam and H. V. Poor",
  title = "Distributed detection with multiple sensors: {P}art {II}
  --- Advanced Topics",
  journal = "Proceedings of the IEEE",
  year = 1997,
  volume = "85",
  pages = "64--79"
}

@inproceedings{Han90,
author = "J. Han and P. K. Varshney and V. C. Vannicola",
title = "Some results on distributed nonparametric detection",
booktitle = "Proc. 29th Conf. on Decision and Control",
pages = "2698--2703",
year = "1990"
}

@inproceedings{Al-Ibrahim89,
author = "M. M. Al-Ibrahim and P. K. Varshney",
title = "Nonparametric sequential detection based on multisensor data",
booktitle = "Proc. 23rd Annu. Conf. on Inform. Sci. and Syst.",
pages = "157--162",
year = "1989"
}

@article{Hussaini89,
author = "E. K. Hussaini and A. A. M. Al-Bassiouni and Y. A. El-Far",
title = "Decentralized {CFAR} signal detection",
journal = "Signal Processing",
volume = "44",
pages = "299-307",
year = "1995"
}


@article{Veeravalli93,
author = "V. V. Veeravalli and T. Basar and H. V. Poor",
title = "Decentralized sequential detection with a fusion center performing the
sequential test",
journal = "IEEE Trans. Info. Theory",
volume = "39",
number = "2",
pages = "433--442",
year= "1993"
}

@article{Chamberland03,
author = "J. F. Chamberland and V. V. Veeravalli",
title = "Decentralized detection in sensor networks",
journal = "IEEE Transactions on Signal Processing",
volume = "51",
number = "2",
pages = "407--416",
year= "2003"
}

@article{Nguyen04,
author = "X. Nguyen and M. J. Wainwright and M. I. Jordan",
title = "Nonparametric decentralized detection using kernel methods",
journal = "IEEE Transactions on Signal Processing",
year= "2005",
volume = "53",
number = "11",
pages = "4053--4066"
}

@INPROCEEDINGS{Nguyen-nips05,
   AUTHOR = "X. Nguyen and M. J. Wainwright and M. I. Jordan",
   TITLE = "Divergence measures, surrogate loss functions and experiment design", 
   BOOKTITLE =   "Advances in Neural Information Processing Systems 11",
   PUBLISHER = "MIT Press",
   ADDRESS = "Cambridge, MA",
   YEAR =    2005 
}

@TECHREPORT{Nguyen05, 
  TITLE = "On divergences, surrogate loss functions and decentralized detection",
  AUTHOR = "X. Nguyen and M. J. Wainwright and M. I. Jordan",
  INSTITUTION = "Department of Statistics, University of California at Berkeley",
  NUMBER = 695,
  MONTH = "September",
  YEAR = 2005
}

@article{Nguyen-aos-09,
author = "X. Nguyen and M. J. Wainwright and M. I. Jordan",
title = "On surrogate loss functions and $f$-divergences",
journal = "Annals of Statistics", 
volume = "37",
number = "2", 
pages = "876--904", 
year = "2009"
}

@article{Nguyen-ieee-10,
author = "X. Nguyen and M. J. Wainwright and M. I. Jordan",
title = "Estimating divergence functionals and the likelihood ratio by convex risk minimization",
journal = "IEEE Transactions on Information Theory",
volume = "56",
number = "11", 
pages = "5847--5861", 
year = "2010"
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% MACHINE LEARNING REFERENCES
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


@INPROCEEDINGS{Jaakkola99,
   AUTHOR = "T. Jaakkola and D. Haussler",
   TITLE = "Exploiting generative models in discriminative classifiers",
   BOOKTITLE = 	 "Advances in Neural Information Processing Systems 11", 
PUBLISHER = "MIT Press", 
ADDRESS = "Cambridge, MA", 
   YEAR = 	 1999
}


@INPROCEEDINGS{Taskar03,
   AUTHOR = "B. Taskar and C. Guestrin and D. Koller",
   TITLE = "Max-{M}argin {M}arkov {N}etworks",
   BOOKTITLE = 	 "NIPS 15", 
   YEAR = 	 2003,
   PAGES = "To appear"
}

@INPROCEEDINGS{Dougherty,
   AUTHOR = "J. Dougherty and R. Kohavi and M. Sahami",
   TITLE = "Supervised and unsupervised discretization of continuous features",
   BOOKTITLE = 	 "Proceedings of the ICML",
   YEAR = 	 1995
}


@article{Cortes95,
    author = "C. Cortes and V. Vapnik",
    title = "Support-Vector Networks",
    journal = "Machine Learning",
    volume = "20",
    number = "3",
    pages = "273-297",
    year = "1995"
}


@misc{UCI,
author = "C.L. Blake and C.J. Merz",
year = "1998",
title = "{UCI} Repository of machine learning databases",
url = "http://www.ics.uci.edu/$\sim$mlearn/MLRepository.html",
institution = "University of California, Irvine, Dept. of Information and Computer Sciences"
} 

@ARTICLE{Tsuda02,
  author = "K. Tsuda and T. Kin and K. Asai",
  title = "Marginalized Kernels for Biological Sequences",
  journal = "Bioinformatics",
  year = 2002,
  volume = "18",
  pages = "268--275"
}

@BOOK{Scholkopf02,
AUTHOR = {B. Sch\"olkopf and A. Smola},
TITLE = "Learning with Kernels",
PUBLISHER = "MIT Press", 
ADDRESS = "Cambridge, MA", 
YEAR = "2002"
}

@book{Cristianini00,
author =  "N. Cristianini and J. Shawe-Taylor",
title = "An Introduction to Support Vector Machines (and other kernel based learning methods)",
publisher = "Cambridge University Press", 
year = "2000"
}

% Non-technical invited overview paper on sensor networks 
@ARTICLE{Chong03, 
  author = "C. Chong and S. P. Kumar", 
  title = "Sensor Networks:  Evolution, Opportunities, and Challenges", 
  journal = "Proceedings of the IEEE", 
  year = 2003, 
  volume = "91", 
  pages = "1247--1256" 
} 

@inproceedings{Bodik05,
  title = "Combining Visualization and Statistical Analysis to Improve Operator Confidence and Efficiency for Failure Detection and Localization",
  author ="P. Bodik and G. Friedman and L. Biewald and H. Levine and G. Candea and K. Patel and G. Tolle and J. Hui and A. Fox and M. I. Jordan and D. Patterson",
 booktitle = "Proceedings of the 2nd IEEE Int'l Conf. on Auto. Computing (ICAC)", 
 address = "Seattle",
 year = "2005"
}

@article{ CortesVapnik,
    author = "Corinna Cortes and Vladimir Vapnik",
    title = "Support-vector networks",
    journal = "Machine Learning",
    volume = "20",
    number = "3",
    pages = "273-297",
    year = "1995"
}

@article{Chen1992,
	author="J. H. Chen",
	title="Optimal rate of convergence for finite mixture models",
	journal="Annals of Statistics",
	volume="23",
	number="1",
	pages="221-233",
	year="1995"
}

@article{Yakowitzspragins-1968,
	author="S. J. Yakowitz and J. D. Spragins",
	title="On the identifiability of finite mixtures",
	journal="Annals of Statistics",
	volume="39",
	number="1",
	pages="209-214",
	year="1968"
}

@article{Nguyen-13,
	author="X. Nguyen",
	title="Convergence of latent mixing measures in finite and infinite mixture models",
	journal="Annals of Statistics",
	volume="4",
	number="1",
	pages="370-400",
	year="2013"
}

@article{Ghosal-2001,
	author="S. Ghosal and A. van der Vaart",
	title="Entropies and rates of convergence for maximum likelihood and bayes estimation for mixtures of normal densities",
	journal="Annals of Statistics",
	volume="29",
	pages="1233-1263",
	year="2001",
}

@book{Lindsay-1995,
	author="B. Lindsay",
	title="Mixture models: Theory, geometry and applications",
	publisher="In NSF-CBMS Regional Conference Series in Probability and Statistics. IMS, Hayward, CA.",
	year="1995"
}

@book{Mclachlan-1988,
	author="G. J. McLachlan and K. E. Basford",
	title="Mixture models: Inference and Applications to Clustering. Statistics: Textbooks and Monographs.",
	publisher="New York",
	year="1988"
}

@article{Vandegeer-1996,
	author="S. van de Geer",
	title="Rates of convergence for the maximum likelihood estimator in mixture models.",
	journal="Journal of Nonparametric Statistics",
	volume="6",
	pages="293-310",
	year="1996"
}

@article{Shen-1994,
	author="X. Shen and W. H. Wong",
	title="Convergence rate of sieves estimates.",
	journal="Annals of Statistics",
	volume="22",
	pages="580-615",
	year="1994"
}

@article{Shen-2001,
	author="X. Shen and L. Wasserman",
	title="Rates of convergence of posterior distributions.",
	journal="Annals of Statistics",
	volume="29",
	pages="687-714",
	year="2001"
}

@article{Ghosal-2000,
	author="S. Ghosal and J. K. Ghosh and A. van der Vaart",
	title="Convergence rates of posterior distributions",
	journal="Annals of Statistics",
	volume="28",
	pages="500-531",
	year="2000"
}

@article{Walker-2007,
	author="S. G. Walker, A. Lijoi and I. Prunster",
	title="On rates of convergence for posterior distributions in infinite-dimensional models",
	journal="Annals of Statistics",
	volume="35",
	pages="738-746",
	year="2007"
}

@article{Ghosal-2007,
	author="S. Ghosal and A. van der Vaart",
	title="Posterior convergence rates of Dirichlet mixtures at smooth densities",
	journal="Annals of Statistics",
	volume="35",
	pages="697-723",
	year="2007"
}

@article{Ghosal-1999,
	author="S. Ghosa and J. K. Ghosh and R. V. Ramamoorthi",
	title="Posterior consistency of Dirichlet mixtures in density estimation",
	journal="Annals of Statistics",
	volume="27",
	pages="143-158",
	year="1999"
}

@article{Wasserman-2000,
	author="C. R. Genovese. and L. Wasserman",
	title="Rates of convergence for the Gaussian mixture sieve",
	journal="Annals of Statistics",
	volume="28",
	pages="1105-1127",
	year="2000"
}

@book{Villani-2003,
	author="C. Villani",
	title="Topics in Optimal Transportation.Graduate Studies in Mathematics",
	publisher="58. Amer.Math.Soc.,Providence,RI.",
	year="2003"
}

@book{Villani-2009,
	author="C. Villani",
	title="Optimal Transport: Old and New. Grundlehren der Mathematischen Wissenschaften [Fundamental Principles of Mathemtical Sciences]",
	publisher="Springer, Berlin",
	year="2009"
}

@article{Teicher-1961,
	author="H. Teicher",
	title="Identifiability of Mixtures",
	journal="Annals of Statistics",
	volume="32",
	pages="244-248",
	year="1961",
}

@article{Teicher-1960,
	author="H. Teicher",
	title="On the mixture of distributions",
	journal="Annals of Statistics",
	volume="31",
	pages="55-73",
	year="1960",
}

@article{Teicher-1963,
	author="H. Teicher",
	title="Identifiability of finite mixtures",
	journal="Annals of Statistics",
	volume="34",
	pages="1265-1269",
	year="1963",
}

@article{Teicher-1967,
	author="H. Teicher",
	title="Identifiability of mixtures of product measures",
	journal="Annals of Statistics",
	volume="38",
	pages="1300-1302",
	year="1967"
}

@article{Osiewalski-1993,
	author="J. Osiewalski and M. F. J. Steel",
	title="Robust Bayesian Inference in $l_{q}$-spherical models",
	journal="Biometrika",
	volume="80",
	pages="456-460",
	year="1993"
} 
	
@article{Kent-1983,
	author="J. T. Kent",
	title="Identifiability of finite mixtures for directional data",
	journal="Annals of Statistics",
	volume="11",
	pages="984-988",
	year="1983"
}

@article{Fraser-1981,
	author="Y. S. Hsu and M. D. Fraser and J. J. Walker",
	title="Identifiability of finite mixtures of von Mises distributions",
	journal="Annals of Statistics",
	volume="9",
	pages="1130-1131",
	year="1981"
}

@article{Mardia-1975,
	author="K. V. Mardia",
	title="Statistics of directional data",
	journal="Journal of the Royal Statistical Society. Series B(Methodological)",
	volume="37",
	pages="349-393",
	year="1975"
}

@article{Ali-1966,
	author="S. M. Ali and S. D. Silvey",
	title="A general class of coefficients of divergence of one distribution from another",
	journal="Journal of the Royal Statistical Society. Series B(Methodological)",
	volume="28",
	pages="131-142",
	year="1966"
}

@article{Peel-2000,
	author="D. Peel and G. J. McLachlan",
	title="Robust mixture modelling using the t distribution",
	journal="Statistics and Computing",
	volume="10",
	pages="339-348",
	year="2000"
}

@article{Azzalini-1996,
	author="A. Azzalini and A. D. Valle",
	title="The multivariate skew-normal distribution",
	journal="Biometrika",
	volume="83",
	pages="715-726",
	year="1996"
}

@article{Azzalini-1999,
	author="A. Azzalini and A. Capitanio",
	title="Statistical applications of the multivariate skew-normal distribution",
	journal="Journal of the Royal Statistical Society, Series B(Methodological)",
	volume="61",
	pages="579-602",
	year="1999"
}

@article{Allman-2009,
	author="E. S. Allman and C. Matias and J. A. Rhodes",
	title="Identifiability of parameters in latent structure models with many observed variables",
	journal="Annals of Statistics",
	volume="37",
	pages="3099-3132",
	year="2009"
}

@article{PeterHall-2003,
	author="P. Hall and X. -H. Zhou",
	title="Nonparametric estimation of component distributions in a multivariate mixture",
	journal="Annals of Statistics",
	volume="31",
	pages="201-224",
	year="2003"
}

@article{PeterHall-2005,
	author="P. Hall and A. Neeman and R. Pakyari and R. Elmore",
	title="Nonparametric inference in multivariate mixtures",
	journal="Biometrika",
	volume="92",
	pages="667-678",
	year="2005"
}

@article{HallNeeman-2005,
	author="R. Elmore and P. Hall and A. Neeman",
	title="An application of classical invariant theory to identifiability in nonparametric mixtures",
	journal="Ann. Inst. Fourier (Grenoble)",
	volume="55",
	pages="1-28",
	year="2005"
}

@article{LeCam-73,
	author="L. Le \ Cam",
	title="Convergence of estimates under dimensionality reductions",
	journal="Annals of Statistics",
	volume="1",
	pages="38-53",
	year="1973"
}

@PHDTHESIS{Bruno-Thesis,
	author= {B. Buchberger},
		title= {An algorithm for finding the basis elements of the residue class ring of a zero dimensional polynomial ideal },
			school= {Johannes Kepler University of Linz},
				year = {1965},
}

@book{Sturmfels,
author = "B. Sturmfels",
title = "Solving system of polynomial equations",
year = "2002",
publisher = "Providence R.I"
}

@article{Wiper-01,
	author="M. Wiper and D. R. Insua and F. Ruggeri",
	title="Mixtures of Gamma distributions with applications",
	journal="Journal of Computational and Graphical Statistics",
	volume="10",
	pages="440-454",
	year="2001"
}

@article{Lee-13,
	author="S. X. Lee and G. J. McLachlan",
	title="On mixtures of skew normal and skew t -distributions",
	journal="Advances in Data Analysis and Classification",
	volume="7",
	pages="241-266",
	year="2013"
}

@article{Ghosal-13,
	author="S. Ghosal and A. Roy",
	title="Predicting false discovery proportion under dependence",
	journal="Journal of the American Statistical Association",
	volume="106",
	pages="1208-1217",
	year="2011"
}

@article{Weisel-13,
	author="T. Zhang and A. Weisel and M. S. Greco",
	title="Multivariate generalized Gaussian distribution: Convexity and graphical models",
	journal="IEEE Transactions on Signal Processing",
	volume="61",
	pages="4141-4148",
	year="2013"
}

@article{Teicher-67,
	author="H. Teicher",
	title="Identifiability of mixtures of product measures",
	journal="Annals of Statistics",
	volume="38",
	pages="1300-1302",
	year="1967"
}

@article{Ho-Nguyen-EJS-16,
	author="N. Ho and X. Nguyen",
	title="On strong identifiability and convergence rates of parameter estimation in finite mixtures",
	journal="Electronic Journal of Statistics",
	volume="10",
	pages="271-307",
	year="2016"
}

@article{Ho-Nguyen-Ann-16,
	author="N. Ho and X. Nguyen",
	title="Convergence rates of parameter estimation for some weakly identifiable finite mixtures",
	journal="Annals of Statistics",
	volume = "44",
	pages = "2726-2755",
	year="2016"
}

@article{Kulis-2012,
	author="B. Kulis and M. I. Jordan",
	title="Revisiting k-means: new algorithm via Bayesian nonparametrics",
	journal="Proceedings of the $29^{\text{th}}$ International Conference on Machine Learning",
	year="2012"
}

@article{Hallin-2012,
	author="M. Hallin and C. Ley",
	title="Skew-symmetric distributions and Fisher information - a tale of two densities",
	journal="Bernoulli",
	volume="18",
	pages="747-763",
	year="2012"
}

@article{Hallin-2014,
	author="M. Hallin and C. Ley",
	title="Skew-symmetric distributions and Fisher information: the double sin of skew-normal",
	journal="Bernoulli",
	volume="20",
	pages="1432-1453",
	year="2014"
}

@article{Chiogna-2005,
	author="M. Chiogna",
	title="A note on the asymptotic distribution of the maximum likelihood estimator for the scalar skew-normal distribution",
	journal="Statistical Methods and Applications",
	volume="14",
	pages="331-341",
	year="2005"
}

@article{Azzalini-2003,
	author="A. Azzalini and A. Capitanio",
	title=" Distributions generated by perturbation of symmetry with emphasis on a multivariate skew t-distribution",
	journal=" Journal of Royal Statistical Society: Series B (Statistical Methodology)",
	volume="65",
	pages="367-389",
	year="2003"
}

@article{Azzalini-1986,
	author="A. Azzalini",
	title="Further results on a class of distributions which includes the normal ones",
	journal="Statistica (Bologna)",
	volume="46",
	pages="199-208",
	year="1986"
}

@article{Diciccio-2004,
	author="T. J. DiCiccio and A. C. Monti",
	title="Inferential aspects of the skew-exponential power distribution",
	journal="Journal of the American Statistical Association",
	volume="99",
	pages="439-450",
	year="2004"
}

@article{Azzalini-1999,
	author="A. Azzalini and A. Capitanio",
	title="Statistical applications of the multivariate skew normal distribution",
	journal=" Journal of Royal Statistical Society: Series B (Statistical Methodology)",
	volume="61",
	pages="579-602",
	year="1999"
}

@article{Tsung-2007,
	author="T. I. Lin and J. C. Lee and S. Y. Yen",
	title="Finite mixture modelling using the skew normal distribution",
	journal="Statistica Sinica",
	volume="17",
	pages="909-927",
	year="2007"
}

@article{Ley-2010,
	author="C. Ley and D. Paindaveine",
	title="On the singularity of multivariate skew-symmetric models",
	journal="Journal of Multivariate Analysis",
	volume="101",
	pages="1434-1444",
	year="2010"
}

@article{Nguyen-2015,
	author="X. Nguyen",
	title="Borrowing strength in hierarchical Bayes: convergence of the Dirichlet base measure",
	journal="Bernoulli",
	year="2015+"
}

@article{Azzalini-2003,
	author="A. Azzalini and A. Capitanio",
	title="Distributions generated by perturbation of symmetry with emphasis on a multivariate skew t distribution",
	journal="Journal of Royal Statistical Society: Series B (Statistical Methodology)",
	volume="65",
	pages="367-389",
	year="2003"
}

@article{Lin-2009,
	author="T. I. Lin",
	title="Maximum likelihood estimation for multivariate skew normal mixture
models",
	journal="Journal of Multivariate Analysis",
	volume="100",
	pages="257-265",
	year="2009"
}

@article{Lin-2010,
	author="T. I. Lin",
	title="Robust mixture modeling using multivariate skew t-distributions",
	journal="Statistics and Computing",
	volume="20",
	pages="343-356",
	year="2010"
}

@article{Lin-2007,
	author="T. I. Lin and J. C. Lee and W. J. Hsieh",
	title="Robust mixture modelling using the skew t-distribution",
	journal="Statistics and Computing",
	volume="17",
	pages="81-92",
	year="2007"
}

@article{Lee-2014,
	author="S. Lee and G. J. McLachlan",
	title="Finite mixtures of multivariate skew t-distributions: some
recent and new results",
	journal="Statistics and Computing",
	volume="24",
	pages="181-202",
	year="2014"
}

@article{Lin-2012,
	author="H. J. Ho and S. Pyne and T. I. Line",
	title="Maximum likelihood inference for mixtures of skew student-
t-Normal distributions through practical EM-type algorithms",
	journal="Statistics and Computing",
	volume="22",
	pages="287-299",
	year="2012"
}

@article{Prates-2013,
	author="M. O. Prates and C. R. B. Cabral and V. H. Lachos",
	title="mixsmsn: fitting finite mixture of scale mixture of skew-normal distributions",
	journal="Journal of Statistical Software",
	volume="54",
	year="2013"
}

@article{Sylvia-2009,
	author="S. W. Schnatter and S. Pyne",
	title="Bayesian inference for finite mixtures of univariate and multivariate skew-normal and skew-t distributions",
	journal="Biostatistics",
	volume="11",
	pages="317-336",
	year="2009"
}

@article{Genton-2008,
	author="R. B. Arellano-Valle and L. M. Castro and M. C. Genton and H. W. Gómez",
	title="Bayesian inference for shape mixtures of skewed distributions, with application to regression analysis",
	journal="Bayesian Analysis",
	volume="3",
	pages="513-540",
	year="2008"
}

@article{Genton-2009,
	author="R. B. Arellano-Valle and M. C. Genton and R. H. Loschi",
	title="Shape mixtures of multivariate skew-normal distributions",
	journal="Journal of Multivariate Analysis",
	volume="100",
	pages="91-101",
	year="2009"
}

@article{Zeller-2015,
	author="C. B. Zeller and C. R. B. Cabral and V. H. Lachos",
	title="Robust mixture regression modeling based on scale mixtures of skew-normal distributions",
	journal="TEST",
	pages="1-22",
	year="2015"
}
	
@article{Azzallini-1985,
	author="A. Azzallini",
	title="A class of distributions which includes the normal ones",
	journal="Scadinavian Journal of Statistics",
	volume="12",
	pages="171-178",
	year="1985"
}

@article{Azzallini-2008,
	author="R. B. Arellano-Valle and A. Azzallini",
	title="The centred parametrization for the multivariate skew-normal distribution.",
	journal="Journal of Multivariate Analysis",
	volume="99",
	pages="1362-1382",
	year="2008"
}

@book{Genton-2004,
author= "M. G. Genton",
title="Skew-elliptical distributions and their applications: a journey beyond normality",
publisher= "Boca Raton, FL: Chapman and Hall/ CRC",
year="2004"
}

@article{Wang-Genton-2004,
	author="J. Wang and J. Boyer and M. C. Genton",
	title="A skew-symmetric representation of multivariate distribution",
	journal="Statistica Sinica",
	volume="14",
	pages="1259-1270",
	year="2004"
}

@article{Canale-2015,
	author="A. Canale and B. Scarpa",
	title=" Bayesian nonparametric location-scale-shape mixtures",
	journal="TEST",
	pages="1-18",
	year="2015"
}

@article{Ishwaran-2001,
	author="H. Ishwaran and L. F. James and J. Sun",
	title="Bayesian model selection in finite mixtures by marginal density decompositions",
	journal="Journal of the American Statistical Association",
	volume="96",
	pages="1316-1332",
	year="2001"
}

@article{Rousseau-2011,
	author="J. Rousseau and K. Mengersen",
	title="Asymptotic behaviour of the posterior distribution in overfitted mixture models",
	journal="Journal of the Royal Statistical Society: Series B (Statistical Methodology)",
	volume="73",
	pages="689-710",
	year="2011"
}

@article{Dunson-2012,
	author="F. Petralia and V. Rao and D. B. Dunson",
	title="Repulsive mixtures",
	journal="Advances in Neural Information Processing Systems (NIPS)",
	year="2012"
}
	
@article{Rotnitzky-2000,
	author="A. Rotnitzky and D. R. Cox and M. Bottai and J. Robins",
	title="Likelihood-based inference with singular information matrix",
	journal="Bernoulli",
	volume="6",
	pages="243-284",
	year="2000"
}
	
@article{Jonas-2016,
	author="P. Heinrich and J. Kahn",
	title="Optimal rates for finite mixture estimation",
	journal="Under review",
	year="2016+"
}
	
@article{Chesher-Lee-86,
	author="L. F. Lee and A. Chesher",
	title="Specification testing when score test statistics are identically zero",
	journal="Journal of Econometrics",
	volume="31",
	pages="33-61",
	year="1986"
}

@article{Chen-2016,
	author="J. Chen",
	title="Consistency of the MLE under mixture models",
	journal="arXiv preprint arXiv:1607.01251",
	year="2016"
}

@article{Chen-2008,
	author="J. Chen and X. Tan and R. Zhang",
	title="Inference for normal mixtures in mean and variance",
	journal="Statistica Sinica",
	volume="18",
	pages="443-465",
	year="2008"
}

@book{Vandegeer,
author= "S. van de Geer",
title="Empirical Processes in M-estimation",
publisher= "Cambridge University Press",
year="2000"
}

@book{Cox-etal,
	author="D. Cox and J. Little and D. O'Shea",
	title="Ideals, Varieties, and Algorithms: An Introduction to Computational Algebraic Geometry and Commutative Algebra",
	publisher="Springer",
	year="2007"
}

@book{Stumfel-2002,
	author="B. Stumfel",
	title="Solving systems of polynomial equations",
	publisher="Providence, RI: American Mathematical Soc",
	year="2002"
}
	
@article{Xiao-14,
	author="S. Xiao and G. Zeng",
	title="Determination of the limits for multivariate rational functions",
	journal="Science China Mathematics",
	volume="57",
	pages="397-416",
	year="2014"
}

@article{Kiefer-82,
	author="N. M. Kiefer",
	title="A remark on the parameterization of a model for heterogeneity.", 
	volume="Working paper no 278. Department of Economics, Cornell University, Ithaca, NY.",
	year="1982"
}

@techreport{Ho-Nguyen-skewnormalTR,
  author = "N. Ho and X. Nguyen",
  title = "Singularity structures and impacts on parameter estimation in finite mixtures of distributions",
  institution = "Department of Statistics, University of Michigan",
  number = "540", 
  year = "2016"
}

@article{Gassiat-2009,
	author="W. Toussile and E. Gassiat",
	title="Variable selection in model-based clustering using multilocus genotype data",
	journal="Advances in Data Analysis and Classification",
	volume="3",
	pages="109-134",
	year="2009"
}

@article{Handel-2014,
	author="E. Gassiat and R. V. Handel",
	title="The local geometry of finite mixtures",
	journal="Transaction of the American Mathematical Society",
	volume="366",
	pages="1047-1072",
	year="2014"	
}

@book{Basu-2006,
	author="S. Basu and R. Pollack and M. Roy",
	title="Algorithms in real algebraic geometry",
	publisher="Springer-Verlag Berlin Heidelberg",
	year="2006"
}

@article{Jacob_Jordan-1991,
	author="R. A. Jacobs and M. I. Jordan and S. J. Nowlan and G. E. Hinton",
	title="Adaptive mixtures of local experts",
	journal="Neural Computation",
	volume="3",
	page="79-87",
	year="1991"
}

@article{Xu_Jordan-1995,
	author="M. I. Jordan and L. Xu",
	title="Convergence results for the {EM} approach to mixtures of experts architectures",
	journal="Neural Networks",
	volume="8",
	page="1409-1431",
	year="1995"
}

@article{Jonas-2017,
	author="P. Heinrich and J. Kahn",
	title="Strong identifiability and optimal minimax rates for finite mixture estimation",
	journal="Annals of Statistics",
	volume="To appear",
	year = "2017+"
}

@article{Siva_2017,
	Author = {S. Balakrishnan and M. J. Wainwright and B. Yu},
	Journal = {Annals of Statistics},
	Pages = {77-120},
	Title = {Statistical guarantees for the {EM} algorithm: From population to sample-based analysis},
	Volume = {45},
	Year = {2017}}

@article{Raaz_Ho_Koulik_2020,
	Author = {R. Dwivedi and N. Ho and K. Khamaru and M. J. Wainwright and M. I. Jordan and B. Yu},
	Journal = {Annals of Statistics},
	Title = {Singularity, misspecification, and the convergence rate of {EM}},
	Pages = {2726-2755},
	Volume = {44},
	Year = {2020}
}

@article{Raaz_Ho_Koulik_2018_second,
	Author = {R. Dwivedi and N. Ho and K. Khamaru and M. J. Wainwright and M. I. Jordan and B. Yu},
	Date-Modified = {2019-02-01 15:45:28 -0700},
	Journal = {AISTATS},
	Title = {Sharp analysis of Expectation-Maximization for weakly identifiable models},
	Year = {2020}}

@article{wu2020a,
  title = {Optimal Estimation of {{Gaussian}} Mixtures via Denoised Method of Moments},
  author = {Wu, Yihong and Yang, Pengkun},
  year = {2020},
  journal = {The Annals of Statistics},
  volume = {48},
  eprinttype = {arxiv},
  pages = {1987--2007}
}

@article{heinrich2018,
  title={Strong identifiability and optimal minimax rates for finite mixture estimation},
  author={Heinrich, P. and Kahn, J.},
  journal={The Annals of Statistics},
  volume={46},
  number={6},
  pages={2844-2870},
  year={2018}
}

@article{ho2022gaussian,
  author  = {Nhat Ho and Chiao-Yu Yang and Michael I. Jordan},
  title   = {Convergence Rates for {G}aussian Mixtures of Experts},
  journal = {Journal of Machine Learning Research},
  year    = {2022},
  volume  = {23},
  number  = {323},
  pages   = {1--81},
}

@article{do_strong_2022,
	title = {Strong identifiability and parameter learning in regression with heterogeneous response},
	journal = {arXiv preprint arXiv:2212.04091},
	author = {Do, Dat and Do, Linh and Nguyen, XuanLong},
	year = {2022},
}

@article{guha2021Bernoulli,
  title={On posterior contraction of parameters and interpretability in {{Bayesian}} mixture modeling},
  author={Guha, Aritra and Ho, Nhat and Nguyen, XuanLong},
  journal={Bernoulli},
  volume={27},
  number={4},
  pages={2159--2188},
  year={2021},
  publisher={Bernoulli Society for Mathematical Statistics and Probability}
}

@article{Jiang-1999,
	author="W. Jiang and M. A. Tanner",
	title="On the identifiability of mixtures-of-experts",
	journal="Neural Networks",
	volume="9",
	pages="1253-1258",
	year="1999"
}

@article{Jordan-1994,
	author="M. I. Jordan and R. A. Jacobs",
	title="Hierarchical mixtures of experts and the {EM} algorithm",
	journal="Neural Computation",
	volume="6",
	pages="181-214",
	year="1994"
}

@book{Boyd_optimization,
title = "Convex Optimization", 
author = "S. Boyd and L. Vandenberghe",
publisher = "Cambridge University Press",
year = "2004"
}


@INPROCEEDINGS{Quoc-conf-2017,
   AUTHOR = "N. Shazeer and A. Mirhoseini and K. Maziarz and A. Davis and Q. Le and G. Hinton and J. Dean",
   TITLE = "Outrageously Large Neural Networks: The Sparsely-Gated Mixture-of-Experts Layer",
   BOOKTITLE = 	 "International Conference on Learning Representations (ICLR)", 
   YEAR = 	 2017
}

@inproceedings{Eigen_learning_2014,
  title = "Learning Factored Representations in a Deep Mixture of Experts",
  author = "D. Eigen and M. Ranzato and I. Sutskever",
  booktitle = "ICLR Workshops",
  year = "2014"
}

@article{Shazeer_JMLR,
	author="W. Fedus and B. Zoph and N. Shazeer",
	title="Switch Transformers: Scaling to Trillion Parameter Models with Simple and Efficient Sparsity",
	journal="Journal of Machine Learning Research",
        volume = "23",
        pages = "1-39",
	year="2022"
}

@inproceedings{Ruiz_Vision_MoE,
  title = "Scaling Vision with Sparse Mixture of Experts",
  author = "C. Ruiz and J. Puigcerver and B. Mustafa and M. Neumann and R. Jenatton and A. Pinto and D. Keysers and N. Houlsby",
  booktitle = "NeurIPS",
  year = "2021"
}

@inproceedings{You_Speech_MoE,
  title = "SpeechMoE: Scaling to Large Acoustic Models with Dynamic Routing Mixture of Experts",
  author = "Z. You and S. Feng and D. Su and D. Yu",
  booktitle = "Interspeech",
  year = "2021"
}


@inproceedings{You_Speech_MoE_2,
	title = {Speechmoe2: Mixture-of-experts model with improved routing},
	doi = {10.1109/ICASSP43922.2022.9747065},
	booktitle = {{ICASSP} 2022 - 2022 {IEEE} {International} {Conference} on {Acoustics}, {Speech} and {Signal} {Processing} ({ICASSP})},
	author = {You, Zhao and Feng, Shulin and Su, Dan and Yu, Dong},
	year = {2022},
	pages = {7217--7221},
}

@inproceedings{Mustafa_multimodal_MoE,
  title = "Multimodal Contrastive Learning with LIMoE: the Language-Image Mixture of Experts",
  author = "B. Mustafa and C. Ruiz and J. Puigcerver and R. Jenatton and N. Houlsby",
  booktitle = "NeurIPS",
  year = "2022"
}


@inproceedings{Du_Glam_MoE,
  title = "GLaM: Efficient Scaling of Language Models with Mixture-of-Experts",
  author = "N. Du and Y. Huang and A. M. Dai and S. Tong and D. Lepikhin and Y. Xu and M. Krikun and Y. Zhou and A. Yu and O. Firat and B. Zoph and L. Fedus and M. Bosma and Z. Zhou and T. Wang and E. Wang and K. Webster and M. Pellat and K. Robinson and K. Meier-Hellstern and T. Duke and L. Dixon and K. Zhang and Q. Le and Y. Wu and Z. Chen and C. Cui",
  booktitle = "ICML",
  year = "2022"
}

@article{Manole_2020,
	author="T. Manole and N. Ho",
	title="Uniform Convergence Rates for Maximum Likelihood Estimation under Two-Component Gaussian Mixture Models",
	journal="arXiv preprint arXiv:2006.00704",
	year="2020"
}

@inproceedings{Kwon_minimax_EM,
  title = "On the minimax optimality of the {EM} algorithm for learning two-component mixed linear regression",
  author = "J. Kwon and N. Ho and C. Caramanis",
  booktitle = "AISTATS",
  year = "2021"
}

@inproceedings{Chen_mixed_regression,
  title = "A Convex Formulation for Mixed Regression with Two Components: Minimax Optimal Rates",
  author = "Y. Chen and X. Yi and C. Caramanis",
  booktitle = "COLT",
  year = "2014"
}

@inproceedings{Yi_mixed_regression,
  title = "Alternating Minimization for Mixed Linear Regression",
  author = "X. Yi and C. Caramanis and S. Sanghavi",
  booktitle = "ICML",
  year = "2014"
}

@inproceedings{Zhong_mixed_regression,
  title = "Mixed Linear Regression with Multiple Components",
  author = "K. Zhong and P. Jain and I. S. Dhillon",
  booktitle = "NeurIPS",
  year = "2016"
}

@article{Wu_minimax_EM,
	author="Y. Wu and H. H. Zhou",
	title="Randomly initialized {EM} algorithm for two-component {G}aussian mixture achieves near optimality in $O(\sqrt{n})$ iterations",
	journal="Mathematical Statistics and Learning",
        volume = "4",
        pages = "143–220",
	year="2021"
}

@inproceedings{Anandkumar_moment_method,
  title = "A Method of Moments for Mixture Models and Hidden Markov Models",
  author = "A. Anandkumar and D. Hsu and S. M. Kakade",
  booktitle = "COLT",
  year = "2012"
}

@inproceedings{Hardt_mixture,
  title = "Tight bounds for learning a mixture of two gaussians",
  author = "M. Hardt and E. Price",
  booktitle = "STOC",
  year = "2015"
}

@book{Sturmfels_System,
title = "Solving Systems of Polynomial Equations", 
author = "B. Sturmfels",
publisher = "Providence, R.I",
year = "2002"
}

@inproceedings{bao_vlmo_2022,
	title = {{VLMo}: Unified Vision-Language Pre-Training with Mixture-of-Modality-Experts},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {H. Bao and W. Wang and L. Dong and Q. Liu and O-K. Mohammed and K. Aggarwal and S. Som and S. Piao and F. Wei},
	year = {2022},
}

@inproceedings{dosovitskiy_image_2021,
	title = {An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale},
	url = {https://openreview.net/forum?id=YicbFdNTTy},
	booktitle = {International {Conference} on {Learning} {Representations}},
	author = {A. Dosovitskiy and L. Beyer and A. Kolesnikov and D. Weissenborn and X. Zhai and T. Unterthiner and M. Dehghani and M. Minderer and G. Heigold and S. Gelly and J. Uszkoreit and N. Houlsby},
	year = {2021},
}

@InProceedings{manole22refined,
  title = 	 {Refined Convergence Rates for Maximum Likelihood Estimation under Finite Mixture Models},
  author =       {T. Manole and N. Ho},
  booktitle = 	 {Proceedings of the 39th International Conference on Machine Learning},
  pages = 	 {14979--15006},
  year = 	 {2022},
  volume = 	 {162},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {17--23 Jul},
  publisher =    {PMLR}
}

@article{li2019drug,
  author  = {Q. Li and R. Shi and and F. Liang},
  title   = {Drug sensitivity prediction with high-dimensional mixture regression},
  journal = {{PL}o{S} {ONE} },
  year    = {2019}
}

@article{Kuusela2011SemisupervisedAD,
  title={Semi-supervised anomaly detection – towards model-independent searches of new physics},
  author={Mikael Kuusela and Tommi Vatanen and Eric Malmi and Tapani Raiko and Timo Aaltonen and Yoshikazu Nagai},
  journal={Journal of Physics: Conference Series},
  year={2011},
  volume={368},
  pages={012032}
}


@inproceedings{zhang2024llama,
  title={LLaMA-adapter: Efficient fine-tuning of large language models with zero-initialized attention},
  author={Zhang, Renrui and Han, Jiaming and Liu, Chris and Zhou, Aojun and Lu, Pan and Qiao, Yu and Li, Hongsheng and Gao, Peng},
  booktitle={The Twelfth International Conference on Learning Representations},
  year={2024}
}


@article{le2024mixture,
  title={Mixture of Experts Meets Prompt-Based Continual Learning},
  author={Le, Minh and Nguyen, An and Nguyen, Huy and Nguyen, Trang and Pham, Trang and Van Ngo, Linh and Ho, Nhat},
  journal={Advances in Neural Information Processing Systems},
  volume={38},
    year={2024},
}


@inproceedings{le2024revisiting,
    title={Revisiting Prefix-tuning: Statistical Benefits of Reparameterization among Prompts},
    author={Le, Minh and Nguyen, Chau and Nguyen, Huy and Tran, Quyen and Le, Trung and Ho, Nhat},
    booktitle={The Thirteenth International Conference on Learning Representations},
    year={2025}
}


@article{zhou2022learning,
  title={Learning to prompt for vision-language models},
  author={Zhou, Kaiyang and Yang, Jingkang and Loy, Chen Change and Liu, Ziwei},
  journal={International Journal of Computer Vision},
  volume={130},
  number={9},
  pages={2337--2348},
  year={2022},
  publisher={Springer}
}

@article{zhang2023adalora,
  title={AdaLoRA: Adaptive budget allocation for parameter-efficient fine-tuning},
  author={Zhang, Qingru and Chen, Minshuo and Bukharin, Alexander and Karampatziakis, Nikos and He, Pengcheng and Cheng, Yu and Chen, Weizhu and Zhao, Tuo},
  journal={arXiv preprint arXiv:2303.10512},
  year={2023}
}

@article{jordan1994hierarchical,
  title={Hierarchical mixtures of experts and the EM algorithm},
  author={Jordan, Michael I and Jacobs, Robert A},
  journal={Neural computation},
  volume={6},
  number={2},
  pages={181--214},
  year={1994},
  publisher={MIT Press}
}

@article{clark2018think,
  title={Think you have solved question answering? try arc, the ai2 reasoning challenge},
  author={Clark, Peter and Cowhey, Isaac and Etzioni, Oren and Khot, Tushar and Sabharwal, Ashish and Schoenick, Carissa and Tafjord, Oyvind},
  journal={arXiv preprint arXiv:1803.05457},
  year={2018}
}

@article{zellers2019hellaswag,
  title={Hellaswag: Can a machine really finish your sentence?},
  author={Zellers, Rowan and Holtzman, Ari and Bisk, Yonatan and Farhadi, Ali and Choi, Yejin},
  journal={arXiv preprint arXiv:1905.07830},
  year={2019}
}

@article{hendrycks2020measuring,
  title={Measuring massive multitask language understanding},
  author={Hendrycks, Dan and Burns, Collin and Basart, Steven and Zou, Andy and Mazeika, Mantas and Song, Dawn and Steinhardt, Jacob},
  journal={arXiv preprint arXiv:2009.03300},
  year={2020}
}

@inproceedings{houlsby2019parameter,
  title={Parameter-efficient transfer learning for NLP},
  author={Houlsby, Neil and Giurgiu, Andrei and Jastrzebski, Stanislaw and Morrone, Bruna and De Laroussilhe, Quentin and Gesmundo, Andrea and Attariyan, Mona and Gelly, Sylvain},
  booktitle={International conference on machine learning},
  pages={2790--2799},
  year={2019},
  organization={PMLR}
}

@article{li2024graphadapter,
  title={Graphadapter: Tuning vision-language models with dual knowledge graph},
  author={Li, Xin and Lian, Dongze and Lu, Zhihe and Bai, Jiawang and Chen, Zhibo and Wang, Xinchao},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@article{gao2024clip,
  title={Clip-adapter: Better vision-language models with feature adapters},
  author={Gao, Peng and Geng, Shijie and Zhang, Renrui and Ma, Teli and Fang, Rongyao and Zhang, Yongfeng and Li, Hongsheng and Qiao, Yu},
  journal={International Journal of Computer Vision},
  volume={132},
  number={2},
  pages={581--595},
  year={2024},
  publisher={Springer}
}

@article{lin2021truthfulqa,
  title={Truthfulqa: Measuring how models mimic human falsehoods},
  author={Lin, Stephanie and Hilton, Jacob and Evans, Owain},
  journal={arXiv preprint arXiv:2109.07958},
  year={2021}
}

@article{karimi2021compacter,
  title={Compacter: Efficient low-rank hypercomplex adapter layers},
  author={Karimi Mahabadi, Rabeeh and Henderson, James and Ruder, Sebastian},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={1022--1035},
  year={2021}
}

@misc{taori2023stanford,
  title={Stanford alpaca: An instruction-following llama model},
  author={Taori, Rohan and Gulrajani, Ishaan and Zhang, Tianyi and Dubois, Yann and Li, Xuechen and Guestrin, Carlos and Liang, Percy and Hashimoto, Tatsunori B},
  year={2023}
}

@article{touvron2023llama,
  title={Llama: Open and efficient foundation language models},
  author={Touvron, Hugo and Lavril, Thibaut and Izacard, Gautier and Martinet, Xavier and Lachaux, Marie-Anne and Lacroix, Timoth{\'e}e and Rozi{\`e}re, Baptiste and Goyal, Naman and Hambro, Eric and Azhar, Faisal and others},
  journal={arXiv preprint arXiv:2302.13971},
  year={2023}
}

@article{touvron2023llama1,
  title={Llama: Open and efficient foundation language models},
  author={Touvron, Hugo and Lavril, Thibaut and Izacard, Gautier and Martinet, Xavier and Lachaux, Marie-Anne and Lacroix, Timoth{\'e}e and Rozi{\`e}re, Baptiste and Goyal, Naman and Hambro, Eric and Azhar, Faisal and others},
  journal={arXiv preprint arXiv:2302.13971},
  year={2023}
}

@article{touvron2023llama2,
  title={Llama 2: Open foundation and fine-tuned chat models},
  author={Touvron, Hugo and Martin, Louis and Stone, Kevin and Albert, Peter and Almahairi, Amjad and Babaei, Yasmine and Bashlykov, Nikolay and Batra, Soumya and Bhargava, Prajjwal and Bhosale, Shruti and others},
  journal={arXiv preprint arXiv:2307.09288},
  year={2023}
}

@article{brown2020language,
  title={Language models are few-shot learners},
  author={Brown, Tom and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared D and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and others},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={1877--1901},
  year={2020}
}


@article{devlin2018bert,
  title={Bert: Pre-training of deep bidirectional transformers for language understanding},
  author={Devlin, Jacob},
  journal={arXiv preprint arXiv:1810.04805},
  year={2018}
}

@article{mangrulkar2022peft,
  title={Peft: State-of-the-art parameter-efficient fine-tuning methods},
  author={Mangrulkar, Sourab and Gugger, Sylvain and Debut, Lysandre and Belkada, Younes and Paul, Sayak and Bossan, B},
  journal={URL: https://github. com/huggingface/peft},
  year={2022}
}


@article{han2024parameter,
  title={Parameter-efficient fine-tuning for large models: A comprehensive survey},
  author={Han, Zeyu and Gao, Chao and Liu, Jinyang and Zhang, Jeff and Zhang, Sai Qian},
  journal={arXiv preprint arXiv:2403.14608},
  year={2024}
}

@article{liu2021p,
  title={P-tuning v2: Prompt tuning can be comparable to fine-tuning universally across scales and tasks},
  author={Liu, Xiao and Ji, Kaixuan and Fu, Yicheng and Tam, Weng Lam and Du, Zhengxiao and Yang, Zhilin and Tang, Jie},
  journal={arXiv preprint arXiv:2110.07602},
  year={2021}
}

@article{lester2021power,
  title={The power of scale for parameter-efficient prompt tuning},
  author={Lester, Brian and Al-Rfou, Rami and Constant, Noah},
  journal={arXiv preprint arXiv:2104.08691},
  year={2021}
}


@article{li2021prefix,
  title={Prefix-tuning: Optimizing continuous prompts for generation},
  author={Li, Xiang Lisa and Liang, Percy},
  journal={arXiv preprint arXiv:2101.00190},
  year={2021}
}


@article{hu2021lora,
  title={Lora: Low-rank adaptation of large language models},
  author={Hu, Edward J and Shen, Yelong and Wallis, Phillip and Allen-Zhu, Zeyuan and Li, Yuanzhi and Wang, Shean and Wang, Lu and Chen, Weizhu},
  journal={arXiv preprint arXiv:2106.09685},
  year={2021}
}


@article{vaswani2017attention,
  title={Attention is all you need},
  author={Vaswani, A},
  journal={Advances in Neural Information Processing Systems},
  year={2017}
}

@article{shazeer2017outrageously,
  title={Outrageously large neural networks: The sparsely-gated mixture-of-experts layer},
  author={Shazeer, Noam and Mirhoseini, Azalia and Maziarz, Krzysztof and Davis, Andy and Le, Quoc and Hinton, Geoffrey and Dean, Jeff},
  journal={arXiv preprint arXiv:1701.06538},
  year={2017}
}

@article{chen2024llava,
  title={Llava-mole: Sparse mixture of lora experts for mitigating data conflicts in instruction finetuning mllms},
  author={Chen, Shaoxiang and Jie, Zequn and Ma, Lin},
  journal={arXiv preprint arXiv:2401.16160},
  year={2024}
}

@inproceedings{chen2023adamv,
  title={Adamv-moe: Adaptive multi-task vision mixture-of-experts},
  author={Chen, Tianlong and Chen, Xuxi and Du, Xianzhi and Rashwan, Abdullah and Yang, Fan and Chen, Huizhong and Wang, Zhangyang and Li, Yeqing},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={17346--17357},
  year={2023}
}

@article{li2024mixlora,
  title={Mixlora: Enhancing large language models fine-tuning with lora based mixture of experts},
  author={Li, Dengchun and Ma, Yingzi and Wang, Naizheng and Cheng, Zhiyuan and Duan, Lei and Zuo, Jie and Yang, Cal and Tang, Mingjie},
  journal={arXiv preprint arXiv:2404.15159},
  year={2024}
}

@article{ruckle2020adapterdrop,
  title={Adapterdrop: On the efficiency of adapters in transformers},
  author={R{\"u}ckl{\'e}, Andreas and Geigle, Gregor and Glockner, Max and Beck, Tilman and Pfeiffer, Jonas and Reimers, Nils and Gurevych, Iryna},
  journal={arXiv preprint arXiv:2010.11918},
  year={2020}
}

@article{fedus2022switch,
  title={Switch transformers: Scaling to trillion parameter models with simple and efficient sparsity},
  author={Fedus, William and Zoph, Barret and Shazeer, Noam},
  journal={Journal of Machine Learning Research},
  volume={23},
  number={120},
  pages={1--39},
  year={2022}
}

@article{shi2023dept,
  title={Dept: Decomposed prompt tuning for parameter-efficient fine-tuning},
  author={Shi, Zhengxiang and Lipani, Aldo},
  journal={arXiv preprint arXiv:2309.05173},
  year={2023}
}

@misc{beeching2023openllm,
  author    = {Edward Beeching and Clementine Fourrier and Nathan Habib and Sheon Han and Nathan Lambert and Nazneen Rajani and Omar Sanseviero and Lewis Tunstall and Thomas Wolf},
  title     = {Open LLM Leaderboard},
  year      = {2024},
  howpublished = {\url{https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard}},
  note      = {Accessed:2024}
}