
\documentclass[10pt]{article} % For LaTeX2e
\usepackage[accepted]{tmlr}
% If accepted, instead use the following line for the camera-ready submission:
% \usepackage[accepted]{tmlr}
% To de-anonymize and remove mentions to TMLR (for example for posting to preprint servers), instead use the following:
%\usepackage[preprint]{tmlr}


\usepackage{hyperref}
\usepackage{url}
\usepackage{graphicx}
\usepackage{dsfont}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{amssymb}
\usepackage{amsfonts}
\usepackage{booktabs}

%\usepackage{algorithm}
%\usepackage{algorithmic}
\usepackage{multirow}


%\usepackage{algorithm}
\usepackage{comment}
\usepackage{amsmath}
\usepackage{bm}
\usepackage{amsfonts}
\usepackage{amsthm}
\usepackage{graphicx}
\usepackage{enumitem}
\usepackage{booktabs}
\usepackage{array}
\usepackage{siunitx}  % For aligning numbers at the decimal point
\usepackage{algpseudocode}
% \usepackage{sub}
% \usepackage{algorithmic}
\usepackage{multirow}
\usepackage{subcaption}
\usepackage{bm}
%\usepackage{bbm}
%\usepackage[switch]{lineno}
\newtheorem{theorem}{Theorem}[section]
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{prop}[theorem]{Proposition}
\newtheorem{property}[theorem]{Property}
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{remark}{Remark}
\newtheorem{definition}{Definition}
\newtheorem{assumption}{Assumption}
\usepackage{pifont}
\usepackage{wrapfig}

\usepackage{comment}
\usepackage{tikz}
%\usepackage{pgfplots}
\usepackage{xcolor}
%\usepackage{wrapfig}
\usepackage{url}
\usepackage{inconsolata}
\usepackage{eurosym}
\usepackage{todonotes} 
\usepackage{subcaption}
\usepackage{amssymb}
\usepackage{lipsum}
\usepackage{amsmath}
\usepackage{enumitem}
\usepackage{array}
\usepackage{longtable}
\usepackage{makecell}
\usepackage{xspace}
\usepackage{tikz}
\usepackage{xcolor,colortbl}
\usepackage[most]{tcolorbox}
\usepackage{arydshln}
\usepackage{adjustbox}
\newcommand{\dline}{\hdashline[0.5pt/1pt]}
\usepackage{tikz}
\usepackage[tikz]{bclogo}
\usepackage{pgfplots}
\pgfplotsset{width=1.0\columnwidth}
\usepackage{multirow}
% \usepackage{fontawesome}
%\usepackage[fixed]{fontawesome5}
\usepackage{makecell}
\usepackage{pifont}
%\usepackage{bbm}
\usepackage{rotating}
\usepackage{tablefootnote}
\usepackage{soul}
\usepackage{booktabs}
\usepackage{tikz}
\usepackage[tikz]{bclogo}
\usepackage{pgfplotstable}
\usepackage{mdframed}
\usepackage{graphicx}
\usepackage{verbatim}
\usepackage{tokcycle}
\usepackage{fancyvrb,fvextra}
% \usepackage{subfigure}
\usepackage{filecontents}
\usepackage{subcaption}
\usepackage{tablefootnote}
\usepackage{amsmath}
\usepackage{graphicx}
\usepackage{url}
%\usepackage{hyperref}
%\usepackage{subfig}
\usepackage{comment}
% \usepackage{amsfonts,amssymb}
\usepackage{amsfonts}
\usepackage{color, soul}
\usepackage{mathrsfs}
\usepackage{cleveref}
\usepackage{multirow}
\usepackage{float}
%\usepackage{wrapfig}
\usepackage{amsthm}
\usepackage{bm}
% \usepackage[title]{appendix}
%\usepackage{bbm}
%\usepackage{algorithm}
%\usepackage{algorithmicx}
\usepackage{algpseudocode}
\usepackage{colortbl}
\usepackage{enumitem}
\usepackage{color}
% \usepackage{flushend}
%\usepackage{balance}
%\usepackage{stfloats}
\usepackage{makecell}
%\usepackage{bbold}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{amssymb}
\usepackage{amsfonts}
\usepackage{fontawesome}
% \newcommand{\yd}[1]{\stepcounter{todocounter}
%   {\color{blue} YD: #1}}
\newcommand{\yd}[1]{\textcolor{blue}{\textbf{yd: #1}}}
\newcommand{\sw}[1]{\textcolor{red}{\textbf{#1}}}
\newcommand{\yj}[1]{\textcolor{purple}{[yj: #1]}}

\usepackage{xcolor}         % colors

\newcommand{\cmark}{\ding{51}}%
\newcommand{\xmark}{\ding{55}}%
\def \mL{\mathcal L}
\def \T{\mathbb T}
\def \R{\mathbb R}



\def \st{\;\text{s.t.}\;}
\def\etal{et al.\;}
\newcommand{\bX}{\mathbf{X}}
\newcommand{\bU}{\mathbf{U}}
\newcommand{\bV}{\mathbf{V}}
\newcommand{\bu}{\mathbf{u}}
\newcommand{\bv}{\mathbf{v}}
\newcommand{\bL}{\mathbf{L}}
\newcommand{\bD}{\mathbf{D}}
\newcommand{\bA}{\mathbf{A}}
\newcommand{\bY}{\mathbf{Y}}
\newcommand{\bZ}{\mathbf{Z}}
\newcommand{\bb}{\mathbf{b}}
\newcommand{\bs}{\mathbf{s}}
\newcommand{\bB}{\mathbf{B}}
\newcommand{\bS}{\mathbf{S}}
\newcommand{\bW}{\mathbf{W}}
\newcommand{\bH}{\mathbf{H}}
\newcommand{\bh}{\mathbf{h}}
\newcommand{\bO}{\mathbf{O}}

\newcommand{\bx}{\mathbf{x}}
\newcommand{\by}{\mathbf{y}}
\newcommand{\bz}{\mathbf{z}}


%\newcommand{\p}{\mathbf{p}}
\newcommand{\bsig}{\mathbf{\sigma}}
\newcommand{\bSig}{\mathbf{\Sigma}}
% norms
\newcommand{\NM}[2]{\| #1 \|_{#2} }  
\newcommand{\SO}[1]{\mathcal{P}_{\mathbf{\Omega}}(#1)}
\newcommand{\Tr}[1]{\text{tr}( #1 ) }

\newcommand{\Diag}[1]{\text{Diag}(#1)}
\newcommand{\mypara}[1]{{\smallskip \noindent \bf #1}\hspace{0.1in}}
\usepackage{array}
\newcolumntype{L}[1]{>{\raggedright\let\newline\\\arraybackslash\hspace{0pt}}m{#1}}
\newcolumntype{C}[1]{>{\centering\let\newline  \\\arraybackslash\hspace{0pt}}m{#1}}
\newcolumntype{R}[1]{>{\raggedleft\let\newline \\\arraybackslash\hspace{0pt}}m{#1}}
\newcommand\norm[1]{\left\lVert#1\right\rVert}
% Replace "require" and "ensure" with "input" and "output" in algorithmic package of LaTeX
\renewcommand{\algorithmicrequire}{\textbf{Input:}}
\renewcommand{\algorithmicensure}{\textbf{Output:}}
\newcommand{\colorann}[3]{\textcolor{#1}{${}^{#2}[$#3$]$}}
\newcommand{\JL}[1]{\colorann{red}{JL}{#1}}
\newcommand{\red}{\color{red}}
\newcommand{\zt}[1]{\colorann{blue}{zt}{#1}}
\newcommand{\rc}[1]{\colorann{brown}{rc}{#1}}
%\newcommand{\sw}[1]{\colorann{red}{sw}{#1}}
\newcommand{\zy}[1]{\colorann{cyan}{zy}{#1}}

\renewcommand{\algorithmicrequire}{\textbf{Input:}}
\renewcommand{\algorithmicensure}{\textbf{Output:}}

%\usepackage{ bbold }
\DeclareMathOperator*{\argmax}{argmax}
\DeclareMathOperator*{\argmin}{argmin}

\newtheorem{innercustomthm}{Theorem}
\newenvironment{customthm}[1]
  {\renewcommand\theinnercustomthm{#1}\innercustomthm}
  {\endinnercustomthm}

%
% These are are recommended to typeset listings but not required. See the subsubsection on listing. Remove this block if you don't have listings in your paper.
\usepackage{newfloat}
\usepackage{listings}

\title{Generative Risk Minimization for Out-of-Distribution \\ Generalization on Graphs}

% Authors must not appear in the submitted version. They should be hidden
% as long as the tmlr package is used without the [accepted] or [preprint] options.
% Non-anonymous submissions will be rejected without review.

\author{\name Song Wang \email sw3wv@virginia.edu \\
        \addr Department of Electrical and Computer Engineering \\
        University of Virginia
        \AND
        \name Zhen Tan \email ztan36@asu.edu \\
        \addr Department of Electrical and Computer Engineering \\
        University of Virginia
        \AND
        \name Yaochen Zhu \email uqp4qh@virginia.edu \\
        \addr Department of Electrical and Computer Engineering \\
        University of Virginia
        \AND
        \name Chuxu Zhang \email chuxu.zhang@uconn.edu  \\
        \addr School of Computing \\
        University of Connecticut
        \AND
        \name Jundong Li \email jundong@virginia.edu\\
        \addr Department of Electrical and Computer Engineering \\
        University of Virginia
      }

% The \author macro works with any number of authors. Use \AND 
% to separate the names and addresses of multiple authors.

\newcommand{\fix}{\marginpar{FIX}}
\newcommand{\new}{\marginpar{NEW}}

\def\month{02}  % Insert correct month for camera-ready version
\def\year{2025} % Insert correct year for camera-ready version
\def\openreview{\url{https://openreview.net/forum?id=EcMVskXo1n}} % Insert correct link to OpenReview for camera-ready version


\begin{document}


\maketitle

\begin{abstract}
Out-of-distribution (OOD) generalization on graphs aims at dealing with scenarios where 
the test graph distribution differs from the training graph distributions. Compared to i.i.d. data like images, the OOD generalization problem on graph-structured data remains challenging due to the non-i.i.d. property and complex structural information on graphs. Recently, several works on graph OOD generalization have explored extracting invariant subgraphs that share crucial classification information across different distributions. Nevertheless, such a strategy could be suboptimal for entirely capturing the invariant information, as the extraction of discrete structures could potentially lead to the loss of invariant information or the involvement of spurious information. In this paper, we propose an innovative framework, named Generative Risk Minimization (GRM), designed to \textit{generate} an invariant subgraph for each input graph to be classified, instead of extraction. To address the challenge of optimization in the absence of optimal invariant subgraphs (i.e., ground truths), we derive a tractable form of the proposed GRM objective by introducing a latent causal variable, and its effectiveness is validated by our theoretical analysis. We further conduct extensive experiments across a variety of real-world graph datasets for both node-level and graph-level OOD generalization, and the results demonstrate the superiority of our framework GRM. Our code is provided at \href{https://github.com/SongW-SW/GRM}{https://github.com/SongW-SW/GRM}.
\end{abstract}

\input{intro}


\begin{comment}
    

\section{Problem Formulation}
In this section, we provide the formulation for our studied graph OOD generalization problem. Notably, our framework is capable of both node and graph classification tasks.
We start by representing a graph (or a local subgraph of a node) as $G=(\mathcal{V},\mathcal{E},\bX)$, where $\mathcal{V}$ and $\mathcal{E}$ are the node set and the edge set, respectively. Moreover, $\mathbf{X}\in\mathbb{R}^{|\mathcal{V}|\times d_x}$ is a feature matrix, where the $j$-th row vector ($d_x$-dimensional) represents the attribute of the $j$-th node. Notice that in graph OOD generalization, each domain typically refers to a single graph~\citep{wuhandling,gui2022good}. %%%%%with a potentially massive number of nodes. 
We can define the distribution of a node and its label from domain $D_i$ as $(v,y)\sim P(v,y|D_i)$, where $v\in\mathcal{V}$ and $y\in\mathcal{Y}$ is its corresponding label. Here $\mathcal{Y}$ is the label space shared across domains. We further denote the training and test domains (i.e., graphs) as $\mathcal{D}_{tr}=\{D_1,D_2, \dotsc, D_{|\mathcal{D}_{tr}|}\}$ and $\mathcal{D}_{te}=\{D_1,D_2, \dotsc, D_{|\mathcal{D}_{te}|}\}$, respectively. 
%
Let $f(\cdot)$ denote the classifier that takes $v$ as input and aims to predict its label $y$. Since most classification models on graphs will involve information from other nodes, we additionally consider the computation graph $G_v$ of node $v$, which contains neighboring nodes of $v$, as the input of $f(\cdot)$. In this way, by introducing a loss function $\ell$, we can represent the risk for the classifier $f(\cdot)$ as follows:
\begin{equation}
    \mathcal{R}=\mathbb{E}_{D\in \mathcal{D}_{tr}}\mathbb{E}_{(v, y)\sim P(v,y|D_i)}[\ell(f(v, G_v),y)].
\end{equation}
However, the distribution shifts between $\mathcal{D}_{tr}$ and $\mathcal{D}_{te}$ will severely impact the performance of a trained classification model $f(\cdot)$ on graphs in $\mathcal{D}_{te}$. Therefore, to handle distribution shifts via adaptation to test domains, we propose to introduce a generator that outputs an adaptive subgraph for the classification of each node. Note that the adaptive subgraph will be used as the input of $f(\cdot)$, instead of the original computation graph $G_v$. Denoting the generator as $g(\cdot)$, which takes the target node $v$ and the domain $D$ as input, we can formulate the optimization problem for both $f(\cdot)$ and $g(\cdot)$ as follows:
\begin{equation}
        \mathcal{R}=\mathbb{E}_{D\in \mathcal{D}_{tr}}\mathbb{E}_{(v, y)\sim P(v,y|D_i)}[\ell\left(f(v, g(v, G_v, D)),y\right)].
\end{equation}
By optimizing the above risk, we can train a classifier $f(\cdot)$ and a generator $g(\cdot)$ that can output adaptive subgraphs for nodes in test domains for classification. We further denote the obtained adaptive subgraph as $G^*_v=g(v, G_v, D)$.
%, and its component as $(\mathcal{V}^*_v, \mathcal{E}^*_v, \bX^*_v)$.


\end{comment}




			\begin{figure*}[!t]
	    \centering
	    \includegraphics[width=0.95\textwidth]{framework.png}
	    %\vspace{-0.05in}
\caption{The overall framework of GRM. Each input graph $G$ is processed by the encoder of our generator to learn the latent variable $Z$. Then we extract the most influential nodes from the domain and learn a domain-specific representation for each node in $G$. These domain-specific representations will be used in the invariance loss. We further classify the output invariant subgraph with a classifier to obtain the predictions. The regularization loss is calculated for $Z$ and the invariant subgraph.
}
\label{fig:illustration}
%\vspace{-0.12in}
	\end{figure*}


 
\section{Methodology}
In this section, we elaborate on our proposed Generative Risk Minimization (GRM) framework, which aims to tackle the graph OOD generalization problem by generating invariant subgraphs instead of extraction. In the following, we first derive our proposed GRM objective and then introduce specific designs to optimize the objective in a generative manner.
%As illustrated in Fig.~\ref{fig:illustration}, GRM consists of three objectives for different purposes. 
The overall process of our GRM framework is illustrated in Fig.~\ref{fig:illustration}.


\subsection{GRM Objective}

In our GRM framework, we propose to learn a classifier $f(\cdot)$ and a generator $g(\cdot)$, such that the generator $g(\cdot)$ will output an invariant subgraph 
%%%%%%for any target node, which will be used as the input of classifier $f$\tz{
for each input graph.
%%%
Considering a graph input $G=(\mathcal{V}, \mathcal{E}, \bX)$, the generator aims to outputs the invariant subgraph $\widehat{G}_c =(\widehat{\mathcal{V}}, \widehat{\mathcal{E}}, \widehat{\bX})$ for classification. 
%Note that $G_v$ is generally obtained from the $L$-hop neighbors of $v$, where $L$ is a predefined integer to indicate the neighborhood size. In other words, 
%Here $\mathcal{V}$ is the node set of $G$, $\mathcal{E}=\{(v_a, v_b)|v_a,v_b\in\mathcal{V}\}$, and $\bX\in\mathbb{R}^{|\mathcal{V}|\times d_x}$ denotes the attributes of nodes in $G$. 
%Here $d(u,v)$ is the shortest path distance between $u$ and $v$. 
%For brevity, we omit $v$ in the expression of $G_v$ and $G^*_v$ and denote them as $G_v$ and $G^*_v$, respectively. 
%We further denote $m$ as the number of nodes in $G_v$, i.e., $m=|\mathcal{V}'|$.


To ensure that the obtained subgraph is maximally invariant across domains while preserving the causal information, we consider the following learning objective for $f$ and $g$, which is adopted in existing works~\citep{chen2022learning, chen2023does}:
\begin{equation}
    \max\ I(\widehat{G}_c ; Y),\ \  \st\ \  \widehat{G}_c \perp D,\ \widehat{G}_c=g(G).
    \label{eq:objective}
\end{equation}
However, it is difficult to directly optimize this objective. Generally, the optimization objective of the generator is to maximize the log-likelihood term $\log P(\widehat{G}_c|G)$. Combining this term, we propose a more feasible objective for Eq.~(\ref{eq:objective}):
\begin{equation}
    \max\ \mathbb{E}\left[\log P(\widehat{G}_c|G)\right] - I(\widehat{G}_c; D),
        \label{eq:GRM_objective}
\end{equation}
which is referred to as our proposed GRM objective. 
%Here $\alpha$ is a scalar to control the degree of invariance to distribution shifts. 
Although the GRM objective is straightforward, it is intractable due to the lack of ground truth, i.e., ${G}_c$, for the generated invariant subgraph $\widehat{G}_c$. Alternatively, based on the SCMs on distribution shifts as illustrated in Fig.~\ref{fig:SCM}, we propose to model the causal variable $Z$ as a latent variable for graph generation.  By introducing the latent causal variable $Z$, we are able to derive the following theorem that allows for an end-to-end optimization for our objective in Eq.~(\ref{eq:GRM_objective}).

\begin{theorem} \label{theorem:ELBO}
An evidence lower bound (ELBO) for optimization of the GRM objective, by introducing a latent causal variable $Z$ and variational approximations $Q(Z)$ and $Q(\widehat{G}_c)$, is as follows:
\begin{equation}
\begin{aligned}
\max\ \mathbb{E} \left[\log P(\widehat{G}_c|G, Z)\right]-\text{KL}(Q(Z)\|P(Z|G))-\mathbb{E}[\text{KL}(P(\widehat{G}_c|D,Z)\|Q(\widehat{G}_c))]+
\mathbb{E}\left[\log P(Z|D,\widehat{G}_c)\right].
\end{aligned}
\end{equation}
\end{theorem}
The proof is provided in Appendix~\ref{appendix:proof}. $KL(\cdot\|\cdot)$ denotes the Kullback-Leibler (KL) divergence. %Moreover, $\log P(\widehat{G}_c)|D, Z)$ represents the probability of the generated invariant subgraph conditioned on the latent variable $Z$ and domain $D$. Differently, $\log P(\widehat{G}_c)|G,Z)$ is conditioned on the latent variable $Z$ and input $G$. 
Based on the above objective, we could devise specific losses for optimization of the classifier and generator. 


\subsection{Generator Implementation}
Before we derive the detailed optimization losses based on Theorem~\ref{theorem:ELBO}, we first introduce the implementation of our generator. {In particular, we aim to model $Q(Z)$ using the generator $g$, which uses any graph $G$ as input.} However, it remains challenging to model $Z$ with a suitable architecture of the generator $g$ in the absence of the ground truth $\widehat{G}_c$. In particular, we propose to leverage the Variational Graph Auto-Encoder (VGAE)~\citep{kipf2016variational,simonovsky2018graphvae} for the generation of invariant subgraphs. This is because the optimization objective of VGAE involves a latent variable $Z$ and aligns with the first term of the GRM objective. As such, we propose to implement the generator $g(\cdot)$ as a VGAE. 

Following the VGAE architecture, our generator consists of an encoder and a decoder.
Given a graph input $G$, the encoder maps it into a latent space and outputs the latent variable $Z\in\mathbb{R}^{|\mathcal{V}|\times d_z}$. Here $d_z$ is the dimension size of $Z$. Moreover, $Z$ involves $|\mathcal{V}|$ latent representations, i.e., $Z=\{\bz_1, \bz_2, \dotsc, \bz_{|\mathcal{V}|}\}$, which means we learn a latent representation for each node in $G$, and thus the number of nodes in $\widehat{G}_c$ equals that in $G$. 
For each node $v_i$, where $i\in\{1,2,\dotsc, |\mathcal{V}|\}$, we learn its representation as follows:
\begin{equation}
    \begin{aligned}
    \bz_i\sim \mathcal{N}({\bz}|\mu_i, \text{diag}(\sigma^2_i)),\ \ \text{where} \ \mu_i=\text{GNN}_\mu (\mathcal{V}, \mathcal{E}, X)_i\ \text{and}\    
        \log {\sigma_i}= \text{GNN}_\sigma (\mathcal{V}, \mathcal{E}, X)_i.
    \end{aligned}
    \label{eq:generation}
\end{equation}
To generate node features of the invariant subgraph, i.e., $\widehat{\bX}\in\mathbb{R}^{|\mathcal{V}|\times d_x}$, 
we leverage the obtained latent variable $Z$ along with a linear projection layer $f_x(\cdot)$:
\begin{equation}
\begin{aligned}
 \widehat{\bX}=\{f_x(\bz_1), f_x(\bz_2), \dotsc, f_x(\bz_{|\mathcal{V}|})\},\ \ 
 \text{where}\ f_x(\bz_i)=\mathbf{W_x}\bz_i+\mathbf{b_x}.
\end{aligned}
  \label{eq:feature}
\end{equation}
Here $\mathbf{W_x}\in\mathbb{R}^{d_x\times d_z}$ is the weight of the projection layer, and $\mathbf{b_x}\in\mathbb{R}^{d_x}$ is the bias. 
 Then we further generate edges from the latent variables $\bz_i$ as follows:
\begin{equation}
\begin{aligned}
    \widehat{\mathcal{E}}=\{\widehat{e}_{ij}|i,j=1,2,\dotsc,|\mathcal{V}|\}, \ \text{where}\ \ \widehat{e}_{ij}=\sigma(f_e^\top(\bz_i)\cdot f_e(\bz_j))\ \text{and}\ f_e(\bz_i)=\mathbf{W_e}\bz_i+\mathbf{b_e}.
\end{aligned}
%\widehat{\mathcal{E}}=\prod\limits_{i=1}^{|\mathcal{V}|}\prod\limits_{j=1}^{|\mathcal{V}|} p(\widehat{e}_{ij}|\bz_i,\bz_j), \ \text{where}\  \widehat{e}_{ij}=\sigma(f_e^\top(\bz_i)\cdot f_e(\bz_j))\ \text{and}\ f_e(\bz_i)=\mathbf{W_e}\bz_i+\mathbf{b_e}.
\label{eq:edge_sample}
\end{equation}
Here $\mathbf{W_e}\in\mathbb{R}^{d_e\times d_z}$ is the weight of the projection layer, and $\mathbf{b_e}\in\mathbb{R}^{d_e}$ is the bias. $d_e$ is the dimension size of $f_e(\bz_i)$. $\sigma(x)=1/(1+\exp(-x))$ is the sigmoid function. Notably, unlike traditional graph generation tasks~\citep{de2018molgan,
jin2018junction}, here we keep the continuous values of $\widehat{e}_{ij}$ as the edge weight and do not sample discrete edges. This is because we aim to generate precise subgraphs that maximally preserve the invariant information, and sampling discrete edges could potentially incorporate spurious information or cause the loss of invariant information. Through the above steps, we could generate an invariant subgraph $\widehat{G}_c =(\widehat{\mathcal{V}}, \widehat{\mathcal{E}}, \widehat{\bX})$, given an input graph $G$.

\subsection{Optimization based on GRM}
In this subsection, we introduce the detailed process to optimize our framework based on the GRM objective derived in Theorem~\ref{theorem:ELBO}. In particular, we design three different losses for the terms in the derivation result.

\noindent\textbf{\underline{Supervision Loss}.} For the supervision loss, we first consider the term $\mathbb{E}[\log(P(\widehat{G}_c|G,Z))]$. As the ground truth $G_c$ is unobserved, the common choice of reconstruction loss in VGAE is unavailable. 
Therefore, we propose to adopt the label $Y$ of $G$ as a proxy for $G_c$, based on the intuition that the optimal $G_c$ should maximally reflect the information of the label $Y$. In this manner, we could formalize the supervision loss as follows:
\begin{equation}
\begin{aligned}
       \mathcal{L}_s=-\sum\limits_{y\in\mathcal{Y}} p(y|G)\log p(y|\widehat{G}_c),\ 
       \text{where}\ p(y|\widehat{G}_c)=f_y(\widehat{G}_c) \ \text{and}\ \widehat{G}_c=g(G).
\end{aligned}
    \label{eq:loss:sup}
\end{equation}
In the above loss, $p(y|\widehat{G}_c)$ is obtained by taking $\widehat{G}_c$ as input to the classifier $f(\cdot)$, and $f_y(\cdot)$ denotes the output class probability regarding class $y$. Moreover, we set $p(y|G)=1$ if $y$ is the label of $G$, and $p(y|G)=0$, otherwise. The above supervision loss could be interpreted as a cross-entropy classification loss for $\widehat{G}_c$.


\noindent\textbf{\underline{Regularization Loss}.} Generally, KL-divergence terms act as regularization in variational generation~\citep{kipf2016variational,kingma2019introduction,simonovsky2018graphvae}. 
In our derivation of the GRM objective in Theorem~\ref{theorem:ELBO}, the two KL-divergence terms \(-\text{KL}(Q(Z)\|P(Z|G))\) and \(-\text{KL}(P(\widehat{G}_c|D,Z)\|Q(\widehat{G}_c))\) represent the differences between the distributions of \(Z\) (given \(D\)) and \(Q(Z)\), as well as between the distributions of \(\widehat{G}_c\) (given \(D\) and \(Z\)) and \(Q(\widehat{G}_c)\). Notably, the derived result is applicable for any $Q(Z)$ and \(Q(\widehat{G}_c)\). Specifically, we first define $Q(Z)$ as a Gaussian distribution  \(\mathcal{N}(0, \mathbf{I})\), where \(\mathbf{I} \in \mathbb{R}^{d^z \times d^z}\) is the identity matrix. In this way, we could directly regularize the learned $\mu$ and $\log$ of $Z$, as $P(Z|G)$ is also a Gaussian distribution, and thus we could explicitly derive the KL-divergence between it and \(\mathcal{N}(0, \mathbf{I})\).
For the second KL-divergence term, i.e., \(-\text{KL}(P(\widehat{G}_c|D,Z)\|Q(\widehat{G}_c))\), we first formulate \(Q(\widehat{G}_c)\) as \(Q(\widehat{G}_c)=Q(\widehat{\bX}) \cdot Q(\widehat{\mathcal{E}})\). In this manner, we could obtain:
\begin{equation}
\begin{aligned}
        -\text{KL}(P(\widehat{G}_c|D,Z)\|Q(\widehat{G}_c))
        =-\text{KL}(P(\widehat{\bX}|D,Z)\|Q(\widehat{\bX}))- \text{KL}(P(\widehat{\mathcal{E}}|D,Z)\|Q(\widehat{\mathcal{E}})).
\end{aligned}
\end{equation}
Notably, as $\widehat{\bX}$ is the linear projection of $Z$, the term $-\text{KL}(P(\widehat{\bX}|D,Z)\|Q(\widehat{\bX}))$ could also use $Z$ for calculating the regularization loss in a similar way to \(-\text{KL}(Q(Z)\|P(Z|G))\). For another term $- \text{KL}(P(\widehat{\mathcal{E}}|D,Z)\|Q(\widehat{\mathcal{E}}))$, we could decompose $Q(\widehat{\mathcal{E}})$ into multiple 
independent Bernoulli distributions as \(\widehat{e}_{ij} \sim \text{Bernoulli}(\theta)\), where \(\theta \in [0,1]\) is a controllable hyper-parameter. In this manner, we could consider the learned edge weight $\widehat{e}_{ij}$ as the parameter in a Bernoulli distribution and compute its KL-divergence with \(Q(\widehat{\mathcal{E}})\). In concrete, we formulate the regularization loss as follows:
\begin{equation}
\begin{aligned}
    \mathcal{L}_r = \sum\limits_{i=1}^{d_z} \left(\frac{1}{2}(\sigma_i^2 + {\mu_i^2}) - \log \sigma_i\right)
    + \sum\limits_{i=1}^{|\mathcal{V}|}\sum\limits_{j=1}^{|\mathcal{V}|}
    \left(r(\alpha_{ij}, \theta)+r(1-\alpha_{ij}, 1-\theta)\right),
    %\sum\limits_{j=i}^{|\mathcal{V}|} \alpha_{ij} \log \frac{\alpha_{ij}}{\theta}  + (1 - \alpha_{ij}) \log \frac{1 - \alpha_{ij}}{1 - \theta}.
\end{aligned}
\end{equation}
where $r(\alpha, \theta)=\alpha \log (\alpha/\theta)$. {The first term is calculated from the KL-divergence of the two Gaussian distributions, which is $\text{KL}(P(\widehat{\bX}|D,Z)\|Q(\widehat{\bX}))$. The second term is calculated from KL-divergence between the two Bernoulli distributions, which is $\text{KL}(P(\widehat{\mathcal{E}}|D,Z)\|Q(\widehat{\mathcal{E}}))$.} Particularly, this loss regularizes the learning process of latent variable $Z$ and the generation process of invariant subgraph $\widehat{G}_c$, such that the obtained $\widehat{G}_c$ is more generalizable to various domains.



\noindent\textbf{\underline{Invariance Loss}.} Finally, we consider the thrid term derived in Theorem~\ref{theorem:ELBO}, i.e., $\mathbb{E}[\log P(Z|D,\widehat{G}_c)]$. Intuitively, this term aims to derive the correct latent variable $Z$ given the generated invariant subgraph $\widehat{G}_c$ and domain $D$. However, the ground truth of $Z$ is unavailable during. Thus, we propose to use the latent variable $Z$ generated from $\widehat{G}_c$ in Eq.~(\ref{eq:generation}) as the proxy and minimize the discrepancy between $Z$ and another set of latent variable $H=\{\bh_1,\bh_2,\dotsc, \bh_{|\mathcal{V}|}\}$ learned from the domain $D$. We refer to $H$ as the domain-specific latent variable. In this manner, optimizing this term could make the learned latent variable $Z$ less vulnerable to the effect of domain-specific information, thereby enhancing the invariance of $Z$.
Specifically, we aim to 
%That being said, the generation of $\widehat{G}_c$ should utilize the domain information $D$. However, it could be difficult to capture the information from the entire domain, especially in node-level tasks where the graph size could be extremely large~\citep{wuhandling}. 
precisely capture the domain information that is maximally related to nodes in $\mathcal{V}$. Due to the diversity of nodes within each domain, the useful domain information can be different for various nodes in $G$ and also distributed across the entire graph~\citep{gui2022good}. Therefore, we propose to learn $\bh_i$ by considering nodes that are influential on $v_i$. Specifically, we construct a subgraph from these influential nodes for $v_i$ and learn $\bh_i$ from this subgraph. 
%Particularly, we introduce the concept of node influence to select the most influential nodes to learn domain-specific representations. 
To effectively select influential nodes, we consider both the shortest path distance and the number of shortest paths. In practice, we choose the one-hop neighboring node set $\mathcal{N}_i$ of $v_i$ and select nodes that are most influential to $\mathcal{N}_i$ to maximally capture domain information. {Notably, we select the one-hop neighboring node set because according to Theorem 1 in \citep{huang2020graph},  the influence of one node on another decreases exponentially as the distance between the two nodes increases. As a result, to determine the nodes from the domain that are most influential for a specific node, it is logical to prioritize nodes with the smallest distances.}
%%%%%%Since we focus on the domain influence, \tz{As we aim to focus on domain influence,}
%As we aim to select influential nodes from the entire domain, we filter out the nodes that already exist in $G$. 
To summarize,  we can represent the selected nodes for learning the domain-specific representation $\bh_i$ of node $v_i$ (the $i$-th node in $\mathcal{V}$) as follows:
%%%%%%In summary, the selected nodes for learning the domain-adaptive representation for node $v_i$ can be represented as follows:
\begin{equation}
\begin{aligned}
    \mathcal{V}^D_i=\{u|\overline{L}_S(u, \mathcal{N}_{i})\leq L^*, \widetilde{P_S}(u,  \mathcal{N}_{i} )\geq P^*,\},\ 
\text{where}\  i=1,2,\dotsc, |\mathcal{V}|.
\end{aligned}
\end{equation}
Here
%$d(v,v_i)$ denotes the shortest path distance between node $v$ and node $v_i$.
$L^*\in\mathbb{R}$ and $P^*\in\mathbb{R}$ are hyper-parameters
%%%%%%\rc{did we do parameter study on them? And what is the computational cost to obtain the set $\mathcal{V}^D_i$?} 
that control the number of selected nodes for learning domain representations based on $\overline{L}_S$ and $\widetilde{P_S}$, respectively. $\mathcal{N}_i$ is the set of one-hop neighboring nodes of $v_i$, and $\mathcal{V}$ is the node set of $G$. In this way, we can learn the domain-specific representation $\bh_i$ of node $v_i$ as follows:
\begin{equation}
\begin{aligned}
        \bh_i = \ \text{Mean}\left(\text{GNN}_\mu(\bX^D_i,\mathcal{V}_i^D, \mathcal{E}_i^D)\right), \ &\text{where}\ \  \mathcal{E}_i^D=\{(v_a, v_b)|v_a,v_b \in\mathcal{V}_i^D\}. 
\end{aligned}
\end{equation}
Here, $\bX^D_i$ and $\mathcal{E}_i^D$ are the corresponding node features and edge set of $\mathcal{V}_i^D$, respectively.
$\bh_i$ is achieved by mean-pooling over learned representations of nodes in $\mathcal{V}_i^D$, learned by the same GNN enocder in Eq.~(\ref{eq:generation}). Then we could achieve the invariance loss for optimizing the term  $\mathbb{E}[\log P(Z|D,\widehat{G}_c)]$ in Theorem~\ref{theorem:ELBO} as follows:
%\begin{equation}
%    \mathcal{L}_s=-\sum\limits_{y\in\mathcal{Y}} p(y|G)\log p(y|\widehat{G}_c),\ \text{where}\ p(y|\widehat{G}_c)=f_y(\widehat{G}_c)\ \text{and}\ \widehat{G}_c=g(G,D).
\begin{equation}
\mathcal{L}_d = \frac{1}{|\mathcal{V}|}\sum\limits_{i=1}^{|\mathcal{V}|} \|\bh_i-\bz_i\|_2, \ \text{where}\ \bz_i\sim \mathcal{N}({\bz}|\mu_i, \text{diag}(\sigma^2_i)).
    \label{eq:loss:domain}
\end{equation}
Here $\bz_i$ is obtained in the same way as in Eq.~(\ref{eq:generation}). As such, the invariance loss could be used to alleviate the domain influence on learned $Z$, which may involve spurious information.

\noindent\textbf{\underline{Optimization}.} With our derived losses, the overall GRM objective for optimization is formulated as follows:
\begin{equation}
\begin{aligned}
    \mathcal{L}=\mathbb{E}_{(G,Y)\sim \mathbb{P}(G,Y|D)} \mathbb{E}_{D\in\mathcal{D}_{tr}} \left[\mathcal{L}_s(G,Y)+\right.
    \left.\alpha\mathcal{L}_r(G)+\beta\mathcal{L}_d(G,D)\right],
\end{aligned}
\end{equation}
where $\alpha$ and $\beta$ are two hyper-parameters to control the weight of $\mathcal{L}_r$ and $\mathcal{L}_d$, respectively. In this way, we can effectively optimize our proposed GRM objective to tackle the OOD generalization on graph data. 

\begin{comment}
\subsection{Optimization of GRM}
In this subsection, we introduce the detailed optimization steps of GRM. Further implementation details are provided in Appendix~\ref{appendix:F}. Based on Theorem~\ref{theorem:objective}, we can optimize our GRM objective regarding any $j\in[1,n]$. In practice, to ensure generalizability and avoid overfitting, we randomly sample a single $j$ from $[1,n]$ and optimize our framework accordingly in each training step. 
%In consequence, we can train our framework with less difficulty. 
Particularly, our loss consists of two parts: (1) the cross-entropy classification loss of our generated adaptive subgraphs; (2) the KL divergence loss between the log-likelihood $p$ and the approximate posterior distribution $q$. Our final loss is formulated as follows:
%\begin{equation}
%    \mathcal{L}=\mathbb{E}_{G\in \mathcal{G}_{tr}}\mathbb{E}_{(v, y)\sim p_{vy|G}}\mathbb{E}_{j\sim[1,|\mathcal{V}|]}\left[\mathbb{E}_{Q}\left[L\left(\text{GNN}(\mathcal{V}^*, \mathcal{E}^*, \bX^*_j, \bz_{-j})\right), y\right]+\text{KL}(q_j(\bz_j|G,D)\|p(\bz_j,G,D))\right].
%\end{equation}
\begin{equation}
\begin{aligned}
        \mathcal{L}=\mathbb{E}_{D\in \mathcal{D}_{tr}}\mathbb{E}_{(v, y)\sim P(v,y|D)}\mathbb{E}_{j\sim[1,n]}\left[\mathbb{E}_{Q}\left[\mathcal{L}_{CE}\left(G^*_v, y\right)\right]\right.\left.+\text{KL}(q_j(\bz_j|G_v,D)\|p(\bz_j|G_v,D))\right].
\end{aligned}
\end{equation}
Specifically, $\mathcal{L}_{CE}$ denotes the cross-entropy loss. $y$ is the label of node $v$. 
%%%%%%%$\mathcal{V}^*$ and $\mathcal{E}^*$ denote the node set and edge set of the generated adaptive subgraph $G^*_v$, respectively. $\bX^*_j$ denote the generated node features of the $j$-th node in $\mathcal{V}^*$.
%%%%%%, and $\bz_{-j}$ represents the latent representations of all nodes in $\mathcal{V}^*$. 
The adaptive subgraph $G^*_v$ of node $v$ is generated by our generator $g(\cdot)$.
The classifier $f(\cdot)$ (implemented as a GNN model) in our framework will utilize $G^*_v$ to output predictions for its label $y$. For the KL divergence term, we use a Gaussian prior $P(\bZ|G_v,D)=\mathcal{N}(\mu_z (G_v,D), \text{diag}(\sigma^2_z(G_v,D))$, where the mean and diagonal covariance are learned by a neural network. In this manner, we can force the approximate posterior distribution $Q(\bZ|G_v,D)$ to approach the prior via minimizing the KL divergence term. 
\end{comment}

%Here $\int_{\bz_j}$ can be interpreted as enumerating over a standard Gaussian distribution
%derived from the evidence lower bound (ELBO)~\citep{simonovsky2018graphvae, kingma2013auto}, which 

%Considering a given node $v$, we aim to generate an adaptive subgraph $G^*_v$ for it, using information from the domain $D$ and its computation graph $G_v$.






\subsection{Complexity Analysis}

In this subsection, we analyze the time complexity of our framework. Particularly, the time complexity of our framework is primarily determined by the GNN encoder and the VGAE generator module, along with the three losses. Therefore, we first break down the complexity by considering the GNN and VGAE separately, then combining their contributions. Note that the time complexity of the GNN encoder is  \( O(|\mathcal{V}|d^2 + |\mathcal{E}|d) \).  For the VGAE complexity, the module (1) encodes each node’s representation and (2) reconstructs the node’s representation.
    For each node, the VAE in VGAE performs operations involving encoding and decoding, which typically, and thus the time complexity for each node’s VAE operation is proportional to \( d^2 \). Thus, for all nodes, the VAE complexity is $O(|\mathcal{V}|d^2)$. Note that this process already involves the time complexity of the regularization loss. For the remaining two losses, the supervision loss and the invariance loss, we compute the time complexity as follows. First, since we are using the cross-entropy loss as the supervision loss, the time complexity is $O(|\mathcal{V}|d)$. The invariance loss involves computing the Euclidean distance between two embeddings of each node, averaging across the graph. Therefore, the time complexity is $O(|\mathcal{V}|^2d)$. In conclusion, the overall time complexity is calculated as 
    \begin{equation}
        O(|\mathcal{V}|d^2 + |\mathcal{E}|d+|\mathcal{V}|d^2+|\mathcal{V}|d+|\mathcal{V}|^2d).
    \end{equation}
By simplifying the above time complexity, we can obtain the final time complexity as
\begin{equation}
    O(|\mathcal{V}|d^2 + |\mathcal{E}|d+|\mathcal{V}|^2d).
\end{equation}





\section{Experiments}
%%%%%%In this section, we evaluate the effectiveness of our framework GRM in a wide variety of tasks on real-world datasets. 
%%%%Particularly, we aim to answer the following research questions through experimental evaluation: \textbf{RQ1:} How does GRM perform on out-of-distribution node classification tasks compared to other state-of-the-art baselines? \textbf{RQ2:} How do different components and strategies in GRM contribute to the final performance? \textbf{RQ3:} How does GRM perform when different degrees of domain shifts are presented? 
%\textbf{RQ4:} How does GRM perform under different settings of hyper-parameters?

%We evaluate our framework primarily on node-level OOD generalization tasks, as the domain information is generally richer and more influential to the target nodes for classification. We also provide results on graph-level OOD generalization tasks in Sec.~\ref{sec:graph_classification}.




	\begin{table*}[!t]
		\setlength\tabcolsep{5.5pt}%调列距
		\centering
  		\caption{Statistics of six out-of-distribution node classification datasets.}
		\renewcommand{\arraystretch}{1.2}
        %\vspace{-0.05in}
\scalebox{0.99}{
\setlength{\aboverulesep}{0pt}
\setlength{\belowrulesep}{0pt}
		\begin{tabular}{c|c|ccccc}
\toprule[1pt]
        \textbf{Shift Type}&\textbf{Dataset} & \# Nodes & \# Edges & \# Classes&\# Domains &Metric
\\
        \hline\hline
        Artificial&\text{Cora} &2,703 &5,278 &10&1/1/8 & Accuracy\\\cline{2-7}
        Transformation&\text{Photo}&7,650& 119,081 &10&1/1/8 & Accuracy \\\hline
        Cross-Domain&\text{Twitch}&1,912 - 9,498 &31,299 - 153,138 &2  &1/1/5&ROC-AUC\\\cline{2-7}
        Transfers&\text{FB-100}&769 - 41,536 &16,656 - 1,590,655 &2&3/2/3 &Accuracy\\\hline
        Temporal&\text{Elliptic}&203,769& 234,355& 2&5/5/9 & F1 Score\\\cline{2-7}
        Evolution&\text{Arxiv}&169,343& 1,166,243 &40&1/1/3& Accuracy\\
        

        \bottomrule[1pt]
		\end{tabular}
  }

%\vspace{-0.08in}
		\label{tab:stat}
	\end{table*}




	\begin{table*}[t]
			\setlength\tabcolsep{7pt}%调列距
		\centering
  \caption{The graph OOD generalization results (test accuracy in \% for {Cora}, {Photo}, {FB-100}, and ROC-AUC in \% for {Twitch}). The best results are in \textbf{bold}.}
		\renewcommand{\arraystretch}{1.15}
  \setlength{\aboverulesep}{0pt}
\setlength{\belowrulesep}{0pt}
		%\caption{The graph OOD generalization results on four datasets (test accuracy in \% for {Cora}, {Photo}, and {FB-100}, and ROC-AUC in \% for {Twitch}). The best results are in \textbf{bold}. The detailed results on each test domain are provided in Appendix~\ref{appendix:G}.}

%\caption{The graph OOD generalization results (test accuracy in \% for {Cora}, {Photo}, {FB-100}, and ROC-AUC in \% for {Twitch}). The best results are in \textbf{bold}.}
		\begin{tabular}{ccccccccc}
\toprule[1pt]
			%\multirow{2}{*}{Model}
			%Dataset&\multicolumn{3}{c||}{{Elliptic}}&\multicolumn{3}{c}{{Arxiv}}
   			Dataset&\multicolumn{2}{c}{{Cora}}&\multicolumn{2}{c}{{Photo}}&\multicolumn{2}{c}{{FB-100}}&\multicolumn{2}{c}{{Twitch}}
			\\
 \cmidrule(lr){1-1}  \cmidrule(lr){2-3} \cmidrule(lr){4-5} \cmidrule(lr){6-7}\cmidrule(lr){8-9}
%Test Task& T1&T2& T3& 2014-2016&2016-2018& 2018-2020 \\\hline\hline
Method& Min.&Avg.& Min.&Avg.&Min.&Avg.&Min.&Avg.\\\hline
ERM & 65.0\scriptsize{$\pm1.5$} & 68.2\scriptsize{$\pm0.4$} & 84.4\scriptsize{$\pm1.5$} & 88.6\scriptsize{$\pm1.3$} & 50.5\scriptsize{$\pm0.4$} & 52.8\scriptsize{$\pm0.6$} & 49.7\scriptsize{$\pm1.1$} & 52.2\scriptsize{$\pm0.9$} \\
DRNN & 56.4\scriptsize{$\pm1.4$} & 74.8\scriptsize{$\pm1.2$} & 76.7\scriptsize{$\pm1.5$} & 77.1\scriptsize{$\pm1.2$} & 48.0\scriptsize{$\pm1.0$} & 51.4\scriptsize{$\pm0.7$} & 44.0\scriptsize{$\pm0.5$} & 48.1\scriptsize{$\pm1.4$} \\
MMD & 52.4\scriptsize{$\pm1.5$} & 75.8\scriptsize{$\pm0.6$} & 82.1\scriptsize{$\pm1.1$} & 84.8\scriptsize{$\pm0.6$} & 51.4\scriptsize{$\pm0.9$} & 53.3\scriptsize{$\pm0.7$} & 42.8\scriptsize{$\pm0.6$} & 49.1\scriptsize{$\pm0.9$} \\
ARM & 60.6\scriptsize{$\pm1.1$} & 62.9\scriptsize{$\pm1.4$} & 58.3\scriptsize{$\pm1.1$} & 74.6\scriptsize{$\pm0.7$} & 50.7\scriptsize{$\pm1.3$} & 54.5\scriptsize{$\pm0.9$} & 43.2\scriptsize{$\pm1.5$} & 48.5\scriptsize{$\pm1.3$} \\\hline
EERM & 68.0\scriptsize{$\pm0.6$} & 70.5\scriptsize{$\pm1.0$} & 90.8\scriptsize{$\pm0.5$} & 91.8\scriptsize{$\pm0.9$} & 50.9\scriptsize{$\pm0.4$} & 54.3\scriptsize{$\pm1.4$} & 51.6\scriptsize{$\pm0.8$} & 54.1\scriptsize{$\pm0.9$} \\
LiSA & 71.1\scriptsize{$\pm1.5$} & 76.7\scriptsize{$\pm0.8$} & 90.3\scriptsize{$\pm1.2$} & 91.5\scriptsize{$\pm1.5$} & 48.8\scriptsize{$\pm1.2$} & 54.2\scriptsize{$\pm1.0$} & 48.6\scriptsize{$\pm1.2$} & 55.8\scriptsize{$\pm2.2$} \\
IS-GIB & 71.3\scriptsize{$\pm1.9$} & 78.6\scriptsize{$\pm1.5$} & 87.2\scriptsize{$\pm0.6$} & 90.2\scriptsize{$\pm0.9$} & 49.6\scriptsize{$\pm1.6$} & 54.6\scriptsize{$\pm1.2$} & 51.2\scriptsize{$\pm1.9$} & 56.0\scriptsize{$\pm1.2$} \\
MARIO & 70.8\scriptsize{$\pm1.3$} & 76.1\scriptsize{$\pm1.0$} & 88.6\scriptsize{$\pm0.8$} & 89.4\scriptsize{$\pm1.4$} & 50.3\scriptsize{$\pm1.9$} & 53.9\scriptsize{$\pm1.4$} & 50.7\scriptsize{$\pm2.0$} & 55.1\scriptsize{$\pm1.9$} \\
\rowcolor{gray!20} GRM & \textbf{74.2}\scriptsize{$\pm1.2$} & \textbf{81.2}\scriptsize{$\pm1.5$} & \textbf{91.3}\scriptsize{$\pm0.9$} & \textbf{92.7}\scriptsize{$\pm1.6$} & \textbf{52.0}\scriptsize{$\pm1.3$} & \textbf{55.1}\scriptsize{$\pm1.1$} & \textbf{52.5}\scriptsize{$\pm1.7$} & \textbf{56.7}\scriptsize{$\pm1.0$} \\
        \bottomrule[1pt]
		\end{tabular}  
        \label{tab:results1}
\end{table*}


\subsection{Experimental Setup}




\noindent\textbf{Datasets.}
In our node-level OOD generalization experiments, we evaluate GRM and other state-of-the-art baselines on six real-world datasets that cover different topics and tasks, following EERM~\citep{wuhandling}. We summarize the statistics of these datasets in Table~\ref{tab:stat}. Specifically, we use datasets that involve three different types of distribution shifts: (1) ``\textit{Artificial Transformation}'' denotes that synthetic spurious features are added to these datasets; (2) ``\textit{Cross-Domain Transfers}'' means that each domain in the datasets corresponds to a graph distinct from each other; (3) ``\textit{Temporal Evolution}'' means that the datasets are dynamic with evolving nature. Each type includes two datasets.
%%%Due to task differences in these datasets, we adopt different evaluation metrics for them. 
More details about these datasets can be found in Appendix~\ref{appendix:E}.






\noindent\textbf{Baselines.}
We evaluate our GRM framework in comparison to two sets of baselines. The general OOD generalization methods include ERM, DRNN~\citep{koh2021wilds}, {MMD}~\citep{li2018domain}, and ARM~\citep{zhang2021adaptive}. The state-of-the-art graph OOD generalization methods include EERM~\citep{wuhandling},  IS-GIB~\citep{yang2023individual}, MARIO~\citep{zhu2023mario}, and LiSA~\citep{yu2023mind}. We provide more details and the parameter settings of these baselines in Appendix~\ref{appendix:F}.



\noindent\textbf{GRM Settings.}
In this subsection, we introduce the detailed parameter settings in our framework GRM. Specifically, we use the Adam optimizer~\citep{kingma2014adam} for training. The dropout rate is set as 0.3, and the weight decay rate is 0.001. The learning rate is set as 0.01. Given an input graph, we utilize two 2-layer GCNs~\citep{kipf2017semi}, with a hidden dimension size of 128, to learn domain-specific representations and node representations. Then we concatenate these two representations as the input of our VAE-based generator. The encoder of the generator is also implemented as a 2-layer GCN. The dimension of latent variables (i.e., $d_z$) is set as 128. For the specific values of $L^*$ and $P^*$ in selecting nodes for learning domain-specific representations, we set them as 3 and 1.5, respectively. For the neighborhood size of the computation graph $G$ of node $v$, i.e., $L$, we set it as 2. In other words, two-hop neighbors will be included in the computation graph $G$. 
%Notably, to accommodate for graph classification tasks introduced in Sec.~\ref{sec:graph_classification}, we randomly select a node in any given graph as the target (central) node for classification and then apply our framework. 
We run 5 times for this process and aggregate the classification results. We provide our code in the supplementary materials. During training, we conduct all experiments on one NVIDIA A6000 GPU with 48GB of memory. We adopt the same GNN encoder for all baselines, i.e., a 2-layer GCN~\citep{kipf2017semi}. Notably, since DRNN and MMD are not designed for scenarios with only one training domain, we use the interpolated domains generated by EERM as training domains for these two methods.





	\begin{table*}[t]
			\setlength\tabcolsep{7pt}%调列距
		\centering

  \caption{The graph OOD generalization results (test accuracy in \% for {Arxiv} and F1 score in \% for {Elliptic}). The best results are in \textbf{bold}.}
		\renewcommand{\arraystretch}{1.15}
  \setlength{\aboverulesep}{0pt}
\setlength{\belowrulesep}{0pt}

		\begin{tabular}{ccccccccc}
\toprule[1pt]
			%\multirow{2}{*}{Model}
			%Dataset&\multicolumn{3}{c||}{{Elliptic}}&\multicolumn{3}{c}{{Arxiv}}
   			Dataset&\multicolumn{4}{c}{{Elliptic}}&\multicolumn{4}{c}{{Arxiv}}
			\\ \cmidrule(lr){1-1} \cmidrule(lr){2-5} \cmidrule(lr){6-9}
Method& T1&T2& T3&Avg.&T1&T2& T3&Avg.\\\hline
ERM & 59.6\scriptsize{$\pm1.4$} & 63.5\scriptsize{$\pm1.3$} & 61.7\scriptsize{$\pm0.6$} & 61.6\scriptsize{$\pm1.1$} & 47.6\scriptsize{$\pm0.9$} & 45.5\scriptsize{$\pm1.4$} & 41.4\scriptsize{$\pm1.0$} & 44.8\scriptsize{$\pm1.4$} \\
DRNN & 73.2\scriptsize{$\pm1.4$} & 71.4\scriptsize{$\pm0.7$} & 70.6\scriptsize{$\pm0.3$} & 71.8\scriptsize{$\pm0.8$} & 46.8\scriptsize{$\pm0.5$} & 44.7\scriptsize{$\pm1.1$} & 40.5\scriptsize{$\pm1.3$} & 44.0\scriptsize{$\pm1.0$} \\
MMD & 71.9\scriptsize{$\pm0.7$} & 70.1\scriptsize{$\pm0.4$} & 69.9\scriptsize{$\pm0.8$} & 70.6\scriptsize{$\pm0.8$} & 44.6\scriptsize{$\pm1.3$} & 42.4\scriptsize{$\pm0.7$} & 38.9\scriptsize{$\pm1.0$} & 42.0\scriptsize{$\pm0.5$} \\
ARM & 72.1\scriptsize{$\pm1.5$} & 69.7\scriptsize{$\pm0.7$} & 67.9\scriptsize{$\pm1.4$} & 69.9\scriptsize{$\pm1.3$} & 44.9\scriptsize{$\pm0.7$} & 42.3\scriptsize{$\pm0.6$} & 39.7\scriptsize{$\pm0.8$} & 42.3\scriptsize{$\pm1.0$} \\\hline
EERM & 66.3\scriptsize{$\pm0.4$} & 63.8\scriptsize{$\pm0.6$} & 55.5\scriptsize{$\pm0.6$} & 61.9\scriptsize{$\pm1.1$} & 50.3\scriptsize{$\pm1.4$} & 48.3\scriptsize{$\pm0.4$} & 44.7\scriptsize{$\pm1.4$} & 47.8\scriptsize{$\pm1.4$} \\
LiSA & 68.8\scriptsize{$\pm0.9$} & 65.6\scriptsize{$\pm0.7$} & 69.3\scriptsize{$\pm1.0$} & 67.9\scriptsize{$\pm0.8$} & 45.9\scriptsize{$\pm0.6$} & 42.3\scriptsize{$\pm0.5$} & 46.1\scriptsize{$\pm0.8$} & 44.7\scriptsize{$\pm0.6$} \\
IS-GIB & 71.2\scriptsize{$\pm1.1$} & 70.0\scriptsize{$\pm1.0$} & 70.4\scriptsize{$\pm1.2$} & 70.5\scriptsize{$\pm1.1$} & 49.3\scriptsize{$\pm0.8$} & 46.6\scriptsize{$\pm0.9$} & 50.5\scriptsize{$\pm1.3$} & 48.8\scriptsize{$\pm0.7$} \\
MARIO & 69.8\scriptsize{$\pm1.9$} & 72.8\scriptsize{$\pm2.4$} & 71.1\scriptsize{$\pm1.4$} & 71.2\scriptsize{$\pm2.0$} & 48.8\scriptsize{$\pm2.3$} & 50.1\scriptsize{$\pm2.4$} & 49.2\scriptsize{$\pm2.4$} & 49.4\scriptsize{$\pm2.8$} \\
\rowcolor{gray!20} GRM & \textbf{89.4}\scriptsize{$\pm1.5$} & \textbf{85.5}\scriptsize{$\pm1.1$} & \textbf{89.1}\scriptsize{$\pm1.5$} & \textbf{88.0}\scriptsize{$\pm1.4$} & \textbf{52.2}\scriptsize{$\pm0.9$} & \textbf{52.6}\scriptsize{$\pm1.4$} & \textbf{56.1}\scriptsize{$\pm1.4$} & \textbf{53.6}\scriptsize{$\pm1.2$} \\

        \bottomrule[1pt]
		\end{tabular}
  %\vspace{-0.15in}

        \label{tab:results2}
 % \vspace{.0in}
	\end{table*}


\subsection{Comparative Results on Node-Level Tasks} 
% \tz{add bold fonts and underlines in tables}
\label{sec:main_results}
To comprehensively demonstrate the effectiveness of GRM, we evaluate its performance on six node-level datasets with different types of distribution shifts and provide results in Table~\ref{tab:results1} and Table~\ref{tab:results2}. We report the worst case result (Min.) and average result (Avg.) for the first four datasets since they consist of multiple (larger than three) test domains. The detailed results on each test domain are provided in Appendix~\ref{appendix:G}. 
From the results, we summarize the observations as follows: 
\begin{itemize}[leftmargin=0.5cm]


    \item  Across all datasets with various types of distribution shifts, GRM consistently outperforms all other baselines on both the worst case (Min.) and average (Avg.) results, which validates the superiority of GRM on graph OOD generalization of node classification tasks. 
 %\item All three ARM variants perform competitively on {Photo} and {FB-100} while becoming less satisfactory on larger datasets {Elliptic} and {Arxiv}. This indicates that existing adaptive methods can hardly extract useful information from an excessively large domain, while our framework can overcome this by learning domain-specific representations from selected influential nodes. 
    \item The performance improvement of GRM over other baselines is substantially larger on {Elliptic}. This is because it contains a large number of test domains, leading to difficulties in generalizing to various test domains. Nevertheless,  our GRM framework optimized with the invariance loss will provide better performance in this situation.
%without explicitly learning from multiple training domains.
    \item  The performance variances of GRM across test domains are lower on {Photo} and {Arxiv} compared to other baselines. These datasets preserve greater node degrees (i.e., more complex structures) and a larger class set. Our generative framework can learn more precise invariant subgraphs with the designed regularization loss.
\end{itemize}






\subsection{Effect under Distribution Shifts}\label{sec:distribution}

\begin{wrapfigure}{r}{0.5\textwidth}
    \vspace{-0.25in}
\centering
        \includegraphics[width=0.99\linewidth]{domain_shifts.pdf}
                                       \vspace{-0.35in}
            \caption{The results of various methods on dataset {Cora-Mix} with different degrees of distribution shifts.}%
            \label{fig:domain_shifts}
            \vspace{-0.05in}
\end{wrapfigure}
In this subsection, we evaluate the effectiveness of GRM under various degrees of distribution shift on the {Cora} dataset. We introduce artificial distribution shifts on {Cora} by mixing node features generated from labels and domain IDs (details are provided in Appendix~\ref{appendix:H}), and we refer to the modified dataset as {Cora-Mix}. 
We systematically evaluate our framework and other baselines on {Cora-Mix} under different spurious feature ratios and present the results in Fig.~\ref{fig:domain_shifts}. The results show that the performance of all methods drops significantly when the bias ratio increases. The performance drop is particularly sharp when the bias ratio increases from 0 to 0.1, indicating that spurious features can adversely affect all models even with a small ratio. Moreover, our proposed framework GRM consistently outperforms other baselines, especially when the bias ratio is relatively large (e.g., 0.5 $\sim$ 0.9). This demonstrates that GRM can effectively alleviate the adverse impact of spurious information by generating invariant subgraphs for classification.
%in the same way as in Sec.~\ref{sec:main_results}, except that we adjust the dimensions of generated spurious features to indicate different degrees of domain shifts.
%We can use line plot with x axis: spurious ratio, y axis: acc






\subsection{Ablation Study}



\begin{wrapfigure}{r}{0.5\textwidth}
    %\vspace{-0.2in}
\centering
        \includegraphics[width=0.99\linewidth]{ablation.pdf}
                            %\vspace{-0.25in}
        \caption{Ablation study of our framework GRM with different variants evaluated on six real-world datasets.}            \label{fig:ablation}
                   % \vspace{-0.1in}
\end{wrapfigure}
In this subsection, we perform a series of ablations studies to evaluate the efficacy of different components in our framework GRM. Specifically, we compare our proposed framework GRM with three degenerate versions: (1) GRM without the regularization loss, denoted as GRM\textbackslash R; (2) GRM without the invariance loss. We denote this variant as GRM\textbackslash I; (3) GRM without the VGAE-based generator, which means we remove the stochastic sampling of $Z$ during generation, denoted as GRM\textbackslash V. From the results presented in Fig.~\ref{fig:ablation}, we obtain following insights. 
(1) GRM consistently outperforms its variants with different components removed, indicating that each module in GRM plays a vital role in handling distribution shifts. 
%\textcolor{red}{deprecating the one-node sampling strategy deteriorates the performance on datasets with multiple training domains (i.e., {FB-100} and {Elliptic}). This is because our proposed strategy can mitigate the difficulty in training our framework with various training domains.} 
(2) Deprecating the invariance loss greatly reduces the performance on Twitch and FB-100 with a limited number of domains. This result implies that the invariance loss is crucial for datasets with few domains for existing works to learn invariant representations.
(3) The performance decreases differently by removing the VGAE module or the regularization loss. Specifically, removing the regularization loss typically leads to a more significant performance drop, as it is more challenging to generate precise invariant subgraphs without regularization. Namely, the potential risk of overfitting is detrimental to performance. {(4) From a broader perspective, the invariance loss generally plays a more critical role than the other two components, as its removal causes a larger performance drop. This is because learning invariant subgraphs is essential for addressing distribution shifts, as it directly impacts the effectiveness of a classifier trained on a domain different from the test domain.
(5) Moreover, the regularization loss and the VGAE module contribute in complementary ways. The regularization loss prevents the generated graphs from deviating from a specific distribution, while the VGAE module introduces randomness during generation. Both are crucial for maintaining the diversity and robustness of the generated subgraphs.
In summary, these components work together to enable GRM to achieve robust generalization across diverse datasets and distribution shifts. }


%\subsection{Case Study}\label{sec:case}
%\begin{figure}
%		\centering
%    \includegraphics[width=0.3\textwidth]{case.pdf}
%        %\vspace{-0.15in}
%    \caption{Original subgraphs and the adaptive subgraph of a node and the statistics of each entire domain.}
%    \label{fig:visualization}\par\vfill
%    %\vspace{-0.12in}
%\end{figure}

%\vspace{-0.05in}

	\begin{wraptable}{r}{0.5\textwidth}
\vspace{-.1in}
			\setlength\tabcolsep{4pt}%调列距
  		\caption{The OOD graph classification results (ROC-AUC for Molhiv and accuracy in \% for other datasets) of various methods on four datasets, with the best results in \textbf{bold}.}
		\centering
		\renewcommand{\arraystretch}{1.2}
    \setlength{\aboverulesep}{0pt}
\setlength{\belowrulesep}{0pt}
%\vspace{-0.05in}
		\begin{tabular}{c|cccc}
\toprule[1pt]
			%\multirow{2}{*}{Model}
			%Dataset&\multicolumn{3}{c\|}{\texttt{Elliptic}}&\multicolumn{3}{c}{\texttt{Arxiv}}
   			{Method}
      &{SP-Motif}&{MNIST}& {G-SST2}&{Molhiv}
\\
\cmidrule(lr){1-1} \cmidrule(lr){2-2} \cmidrule(lr){3-3}\cmidrule(lr){4-4}\cmidrule(lr){5-5}
DIR & 39.87 & 20.36 & 83.29 & 77.05 \\
GIL & 46.04 & 21.94 & 83.44 & 79.08 \\
CIGA & 64.01 & 25.29 & 81.02 & 79.75 \\
GALA& 64.54& 26.09& 83.79& 80.53\\
\rowcolor{gray!20}  GRM & \textbf{65.05} & \textbf{26.53} & \textbf{83.86} & \textbf{81.02} \\
        \bottomrule[1pt]
		\end{tabular}
 % \vspace{-.05in}

\label{tab:result_graph}
%\vspace{-0.1in}
\end{wraptable}

    \subsection{Comparative Results on Graph-Level Tasks}
\label{sec:graph_classification}
Although we focus on the node classification task, our method is also applicable to graph classification, i.e., graph-level out-of-distribution generalization. In the setting for graph-level tasks, the domain information exists in other graphs and thus could not directly calculate the node influence. Thus, we still use the nodes in the input graph $G$ to learn domain-specific representations $H$. Notably, as these nodes will not cover the entire graph $G$, the learned $H$ will not be trivial, i.e., the same for all nodes in $G$. For graph-level experiments, 
%We provide details about adopting our framework for graph classification in Appendix~\ref{appendix:F}. 
We consider four prevalent datasets, namely \textbf{SP-Motif}~\citep{ying2019gnnexplainer}, \textbf{MNIST-75sp}~\citep{knyazev2019understanding}, \textbf{G-SST2} (Graph-SST2)~\citep{socher2013recursive}, and \textbf{Molhiv} (OGBG-Molhiv)~\citep{hu2020open}, with detailed provided in Appendix~\ref{app:graph_data}. For baselines, we consider four state-of-the-art methods: DIR~\citep{wudiscovering}, GIL~\citep{li2022learning}, CIGA~\citep{chen2022learning}, and GALA~\citep{chen2023does}.
From the results presented in Table~\ref{tab:result_graph}, we observe that GRM still exhibits competitive performance on OOD graph classification. Specifically, it achieves the best results over other baselines on all four datasets. The performance improvement is better on the dataset Molhiv with a larger graph size, thereby providing richer domain knowledge for our GRM to learn invariant information.


\section{Related Works}


\subsection{Out-of-Distribution (OOD) Generalization} OOD Generalization aims to learn a model that can generalize to an unseen test domain, given several different but related training domain(s). Prior invariant methods~\citep{ganin2015unsupervised,li2018domain,arjovsky2019invariant} genreally focus on learning invariant features~\citep{sun2016return,peng2019moment} or optimizing for the worst-case group performance~\citep{hu2018does,sagawa2020distributionally}. 
%In contrast, adaptive methods for OOD generalization adapt learned models to unseen domains~\citep{kumagai2018zero}. For example, ARM~\citep{zhang2021adaptive} extracts information from random data points in the test domain for adaptation. %In another work~\citep{kumagai2018zero}, contexts from the test domain are treated as probabilistic latent variables for adaptation. 
  Recent works for OOD generalization on graphs~\citep{chen2022learning,li2022learning,wang2024safety} could be typically categorized into two classes: invariant learning and graph augmentation~\citep{li2022out}. Among invariant learning methods, CIGA~\citep{chen2022learning} proposes to extract subgraphs that maximally preserve the invariant intra-class information based on causality. 
  DIR~\citep{wudiscovering} uses a set of graph representations as the invariant rationales 
  %and conducts interventional augmentations
  to create additional distributions. GIL~\citep{li2022learning} identifies invariant subgraphs via a GNN-based generator.
  More recently, 
  %IS-GIB~\citep{yang2023individual} explores invariant information based on Graph Information Bottleneck (GIB). 
  MARIO~\citep{zhu2023mario} utilizes the Information Bottleneck (IB) principle to learn invariant information. 
  %It maximizes the mutual information between graph representations and labels and minimizes the mutual information between the inputs and the learned representations. In this way, the learned representation could be more robust to distribution shifts.
 Among augmentation methods, LiSA~\citep{yu2023mind} proposes to leverage graph augmentation to obtain more diverse training data for learning invariant information. 
 %The authors notice the potential risk of changing the labels of the augmented graphs and thus employ a variational subgraph generator to output label-invariant subgraphs.  
 EERM~\citep{wuhandling} generates domains by maximizing the loss variance between domains in an adversarial manner, such that the obtained domains could aid in learning invariant representations. 
%Note that DIR, GIL, and CIGA are proposed for graph classification and thus are not suitable for comparisons. EERM, proposed for node classification, is based on the invariant principle. In contrast to EERM, our framework GRM adopts the concept of adaptation to effectively leverage unlabeled data in test domains.

%SRGNN~\citep{zhu2021shift} proposes to convert the biased training data to the unbiased distribution via a central moment discrepancy regularizer and a kernel mean matching technique. 

%GIL~\citep{li2022learning} proposes to identify invariant subgraphs via a GNN-based subgraph generator for inferring latent domain labels. 
%CIGA~\citep{chen2022learning} characterize potential distribution shifts on graphs with causal
%models, concluding that OOD generalization on graphs is achievable when models focus only on subgraphs containing the most information about the causes of labels. Accordingly, we propose an information-theoretic objective to extract the desired subgraphs that maximally preserve the invariant intra-class information







\subsection{Graph Generative Models}
In recent years, numerous works have been proposed for graph generation~\citep{you2018graphrnn,grover2019graphite}. Specifically, GraphVAE~\citep{simonovsky2018graphvae} proposes a framework based on VAE~\citep{kingma2013auto} to generate graphs by encoding existing graphs. GraphRNN~\citep{you2018graphrnn} generates graphs through a sequence of node and edge formations. Moreover, several methods~\citep{jin2018junction,preuer2018frechet} focus on generating graphs based on specific knowledge. For example, MolGAN~\citep{de2018molgan} adapts the framework of Generative Adversarial Networks
(GANs)~\citep{goodfellow2014generative} to operate directly on graph-structured data with a reinforcement learning objective. Note that although these methods leverage different information for generating graphs, they are not explicitly proposed for handling the distribution shift problem on graphs. In contrast, our framework GRM aims to utilize domain information to generate graphs that are suitable for a trained classifier. 
%Moreover, due to flexibility in our design, GRM can be compatible with different graph generative techniques.

% \vspace{0.03in}
\section{Conclusion}
    In this paper, we propose a novel framework, namely Generative Risk Minimization (GRM), to generate invariant subgraphs for each input graph to tackle the OOD generalization problem on graphs. Instead of extracting structures that may cause the loss of invariant information, we propose our GRM objective that incorporates a generation term and a mutual information term. We derive three types of losses to enable the optimization of our GRM objective in the absence of ground truths for the invariant subgraphs. The effectiveness of GRM is validated by our theoretical analysis and also the extensive experiments across both node-level and graph-level OOD generalization tasks. The results indicate the superiority of GRM over other state-of-the-art baselines. 
    
    %As a result, GRM can generate adaptive subgraphs to promote classification performance under the OOD scenario. We conduct extensive experiments on six real-world graph datasets, and the results demonstrate the superiority of GRM over other state-of-the-art baselines. 

\section*{Acknowledgments}
This work is supported in part by the National Science Foundation under grants (IIS-2006844, IIS-2144209,
IIS-2223769, CNS-2154962, BCS-2228534, and CMMI2411248), the Commonwealth Cyber Initiative Awards under
grants (VV-1Q24-011, VV-1Q25-004), and the research gift
funding from Netflix and Snap.


\bibliography{aaai24}
\bibliographystyle{tmlr}



\newpage
\appendix
\onecolumn


\section{Theoretical Analysis}
\subsection{Theorem 3.1 and Proof}
\label{appendix:proof}
In this section, we provide proof for Theorem~\ref{theorem:ELBO}.

\begin{customthm}{3.1}
An evidence lower bound (ELBO) for optimization of the GRM objective, by introducing a latent causal variable $Z$ and a variational approximation $Q(\widehat{G}_c)$, is as follows:
\begin{equation}
\begin{aligned}
\max\ \mathbb{E} &\left[\log P(\widehat{G}_c|G, Z)\right]-\text{KL}(Q(Z|G)\|P(Z|G))\\
&-\mathbb{E}[\text{KL}(P(\widehat{G}_c|D,Z)\|Q(\widehat{G}_c))]+
\mathbb{E}\left[\log P(Z|D,\widehat{G}_c)\right],
\end{aligned}
\end{equation}
\end{customthm}

\begin{proof}
We first present the GRM objective:
\begin{equation}
        \max\ \mathbb{E}\left[\log P(\widehat{G}_c|G)\right] - I(\widehat{G}_c; D).
\end{equation}

We first derive the ELBO for the generation objective, which is a standard derivation for the variational auto-enocder (VAE):
\begin{equation}
\begin{aligned}
    &\ \ \ \ \log P(\widehat{G}_c|G)\\
    &=\log \int_Z P(\widehat{G}_c, Z|G)dZ\\
    &=\log \int_Z Q(Z|G) \frac{P(\widehat{G}_c, Z|G)}{Q(Z|G)}dZ\\
       & \ \ \ \ \ \ (\textcolor{blue}{\textit{using Jensen's Inequality}})\\
    &\geq \int_Z Q(Z|G) \log\frac{P(\widehat{G}_c, Z|G)}{Q(Z|G)}dZ\\
    &=\mathbb{E}_Q[\log \frac{P(\widehat{G}_c, Z|G)}{Q(Z|G)}]\\
           & \ \ \ \ \ \ (\textcolor{blue}{\textit{using the property of conditional probabilities}})\\
    &=\mathbb{E}_Q[\log \frac{P(\widehat{G}_c|Z, G)\cdot P(Z|G)}{Q(Z|G)}]\\
    &=\mathbb{E}_Q[\log P(\widehat{G}_c|Z,G)]- \mathbb{E}_Q[\log \frac{Q(Z|G)}{P(Z|G)}]\\
               & \ \ \ \ \ \ (\textcolor{blue}{\textit{using the definition of KL-divergence}})\\
    &=\mathbb{E}_{Q}[\log P(\widehat{G}_c|G, Z)]-\text{KL}(Q(Z|G)\|P(Z|G)).
\end{aligned}
\end{equation}

Then we decompose the second term $- I(\widehat{G}_c; D)$ of our GRM objective as follows, based on the definition of mutual information:
\begin{equation}
  - I(\widehat{G}_c ; D)= I(\widehat{G}_c;Z|D)-I(\widehat{G}_c;D,Z)
\end{equation}
We first decompose the first term:
\begin{equation}
\begin{aligned}
    I(\widehat{G}_c;Z|D)
    &=\mathbb{E}\left[\log \frac{P(\widehat{G}_c|D,Z)}{P(\widehat{G}_c|D)}\right]\\
    &=\mathbb{E}\left[\log \frac{P(Z|D,\widehat{G}_c)}{P(Z|D)}\right]\\
    &=\mathbb{E}\left[\log P(Z|D,\widehat{G}_c)\right]+H(Z|D)
\end{aligned}
\end{equation}
We consider $P(Z|D)$ as a deterministic distribution for each $D$, and thus it could be ignored for optimization.

Then we dereive the lower bound for the second term:

\begin{equation}
\begin{aligned}
       -I(\widehat{G}_c;D,Z)&=-\mathbb{E}_{\widehat{G}_c,D}  \left[\log\left(\frac{P(\widehat{G}_c|D,Z)}{P(\widehat{G}_c)}\right)\right] \\
       &=   -\mathbb{E}_{\widehat{G}_c,D}  \left[\log\left(\frac{P(\widehat{G}_c|D,Z)}{Q(\widehat{G}_c)}\right)\right]  +\text{KL}(P(\widehat{G}_c)\|Q(\widehat{G}_c))\\
&\geq  -\mathbb{E}_{\widehat{G}_c,D}  \left[\log\left(\frac{P(\widehat{G}_c|D,Z)}{Q(\widehat{G}_c)}\right)\right]\\
&=-\mathbb{E}_G[\text{KL}(P(\widehat{G}_c|D,Z)\|Q(\widehat{G}_c))]
\end{aligned}
\end{equation}

Finally, we could combine the above three derivation results to achieve the final evident lower bound for optimization of the GRM objective:
\begin{equation}
\begin{aligned}
\max\ \mathbb{E} &\left[\log P(\widehat{G}_c|G, Z)\right]-\text{KL}(Q(Z|G)\|P(Z|G))\\
&-\mathbb{E}[\text{KL}(P(\widehat{G}_c|D,Z)\|Q(\widehat{G}_c))]+
\mathbb{E}\left[\log P(Z|D,\widehat{G}_c)\right],
\end{aligned}
\end{equation}



\end{proof}









\section{Datasets in Experiments}
\label{appendix:E}

In this section, we provide further details on the six datasets used in our experiments: \texttt{Cora}, \texttt{Photo}, \texttt{Twitch}, \texttt{FB-100}, \texttt{Elliptic}, and \texttt{Arxiv}. Note that the datasets are originally processed by EERM~\citep{wuhandling}. We follow the same dataset setting and splitting to keep consistency. Additionally, in Sec.~\ref{sec:main_results}, we report the Min. and Avg. performance on four datasets, and further detailed results of these datasets are presented in Appendix~\ref{appendix:G}.

\subsection{Artificial Distribution Shifts on \texttt{Cora} and \texttt{Photo}}

\texttt{Cora} and \texttt{Photo} are two popular benchmark datasets used for node classification tasks and are also widely adopted to assess the effectiveness of GNN models. Specifically, these datasets are of moderate size, containing thousands of nodes (2,703 and 7,650, respectively). The data statistics are provided in Table~\ref{tab:stat}. In particular, \texttt{Cora} is a citation network, where nodes represent papers and edges indicate the citation relationship between them. On the other hand, \texttt{Photo} is a co-purchasing network, with nodes representing specific goods and edges denoting frequent co-purchases of two goods. In the original dataset, the provided node features exhibit a strong correlation with node labels. Following EERM~\citep{hamilton2017inductive}, in order to assess the model performance for graph OOD generalization under various distributions, we manually introduce distribution shifts into the training and testing data.

More specifically, we construct node labels and spurious domain-sensitive attributes from node features. Given the node features as $X_1$, we start by randomly initializing a Graph Neural Network (GNN) with $X_1$ as input and an adjacency matrix to generate node labels $Y$. To obtain the one-hot label vectors, we perform an argmax operation in the output layer. Then, we randomly initialize another GNN with the concatenation of $Y$ and a domain ID as input to generate spurious node features $X_2$. The next step is to concatenate these two sets of node features, i.e., $X = [X1, X2]$, to create new node features for training and test data. This process is performed ten times for each dataset, resulting in ten graphs with different domain IDs. For training and validation, we utilize one graph each, while the classification accuracy is reported on the remaining graphs. 


\subsection{Cross-Domain Transfers on \texttt{Twitch} and \texttt{FB-100}}


Cross-domain transfers are a common occurrence in scenarios involving distribution shifts on graphs. In various real-world situations, multiple observed graphs are available, each belonging to a specific domain. For instance, in social networks, domains can be defined based on where or when the networks are collected. Similarly, in protein networks, distinct species may have their own observed graph data, such as protein-protein interactions, representing separate domains. The key point is that graph data typically captures relational structures among specific entities, which often exhibit unique characteristics for different entity groups. As a result, the data-generating distributions can vary across these groups, leading to domain shifts.

However, in order to facilitate transfer learning across graphs, it is necessary for the graphs within a dataset to share the same input feature space and output space. To achieve this requirement, we utilize two publicly available datasets, \texttt{Twitch} and \texttt{FB-100}, which satisfy these conditions.

Specifically, the \texttt{Twitch} dataset consists of seven networks, where nodes and edges represent Twitch users and their mutual friendships, respectively. These networks are collected from different regions, namely DE, ENGB, ES, FR, PTBR, RU, and TW. Although these networks have similar sizes, they exhibit variations in terms of density and maximum node degrees, as presented in Table~\ref{tab:TW_stat}. 


The \texttt{FB-100} dataset comprises 100 snapshots of Facebook friendship networks from 2005. Here each network contains nodes that represent Facebook users from a specific American university. In our experiments, we utilize fourteen networks: John Hopkins, Caltech, Amherst, Bingham, Duke, Princeton, WashU, Brandeis, Carnegie, Cornell, Yale, Penn, Brown, and Texas. These graphs exhibit significant variations in terms of sizes, densities, and degree distributions, indicating that the model capability in handling different graph structures becomes crucial for this dataset.

\subsection{Temporal Evolution on Dynamic Graph Data: \texttt{Elliptic} and \texttt{Arxiv}}
The distribution shift problem can also occur in temporal graphs that dynamically change over time. The evolution of these graphs can be generally categorized into two types. In the first type, there exist multiple snapshots of the graph, with each snapshot captured at a specific time. As time progresses, a sequence of graph snapshots is generated, which may exhibit variations in terms of node sets and data distributions. For example, financial networks capture the payment flows among transactions within different time intervals and thus result in different domains.     In the second type, there exists only one single graph that evolves through the addition or deletion of nodes and edges. This type is commonly seen in large-scale real-world graphs, such as social networks and citation networks. In these graphs, the distribution of node features, edges, and labels often exhibit a strong correlation with time at different scales.
For our graph OOD generalization experiments, we utilize two public real-world datasets, namely \texttt{Elliptic} and \texttt{Arxiv}. These datasets are suitable for exploring node classification tasks within the context of evolving temporal graphs.

The \texttt{Elliptic} dataset consists of a series of 49 graph snapshots, where each snapshot represents a network of Bitcoin transactions. Specifically, each node corresponds to a transaction and each edge represents a payment flow. Within these transactions, approximately 20\% are labeled as either licit or illicit, with the objective being to identify illicit transactions within future networks. In the original dataset, the first six graph snapshots contain highly imbalanced classes, with the number of illicit transactions being less than 10 among thousands of nodes. Consequently, we exclude these snapshots and focus on the 7th to 11th, 12th to 17th, and 17th to 49th snapshots for training, validation, and testing, respectively.
Furthermore, due to the low positive label rate observed in each graph snapshot, we organize the 33 testing graph snapshots into 9 distinct test sets based on their chronological order. The dataset also requires the framework to effectively handle diverse label distributions encountered during the transition from training to testing data.

The \texttt{Arxiv} dataset comprises 169,343 Arxiv CS papers covering 40 subject areas, along with their citation relationships. The objective is to predict the subject area of a given paper. In~\citep{hu2020open}, the papers published before 2017, in 2018, and since 2019 were utilized for training, validation, and testing, respectively. They employed a transductive learning setting~\citep{tan2022transductive,dolztransductive,mathavan2023inductive}, wherein the nodes in the validation and test sets were also present in the training graph.
Instead, \texttt{Arxiv} adopts an inductive learning setting, which better reflects real-world scenarios. Here, the nodes in the validation and test sets are unseen during training, introducing a greater level of novelty. Specifically, the dataset consists of papers published before 2011 for training, papers from 2011 to 2014 for validation, and papers after 2014 for testing. Such a splitting strategy introduces a distribution shift between the training and testing data, as specific latent influential factors (such as research topic popularity) in data generation would change over time.
	\begin{table*}[htbp]
		\setlength\tabcolsep{7pt}%调列距

		\centering
        		\caption{Statistics of \texttt{Twitch} dataset.}
		\renewcommand{\arraystretch}{1.3}
        %\vspace{-0.05in}
		\begin{tabular}{c|ccccc}
		\hline
        \textbf{Domain} & \# Nodes & \# Edges & Density&Avg. Degree&Max. Degree\\
        \hline
DE&9,498& 153,138 &0.0033 &16 &3,475\\
ENGB &7,126 &35,324&0.0013 &4 &465\\
ES& 4,648 &59,382 &0.0054&12 &809\\
FR &6,549 &112,666& 0.0052 &17 &1,517 \\
PTBR& 1,912& 31,299 &0.0171 &16 &455 \\
RU& 4,385 &37,304 &0.0038 &8& 575 \\
TW &2,772 &63,462& 0.0165& 22 &1,171\\
        
        \hline
		\end{tabular}
		\label{tab:TW_stat}
	\end{table*}


\subsection{Graph Classification Datasets for Out-of-Distirbution Generalization}\label{app:graph_data}
Here we introduce the four datasets used in our experiments in Sec.~\ref{sec:graph_classification}, focusing on graph classification tasks. In particular, we leverage the following datasets:
\begin{itemize}[leftmargin=0.5cm]

\item \textbf{SP-Motif}~\citep{ying2019gnnexplainer}: The SP-Motif dataset, comprising 18,000 synthetic graphs, is constructed by combining a base graph (denoted by Tree, Ladder, or Wheel, represented as $S = 0, 1, 2$ respectively) with a motif (Cycle, House, or Crane, denoted as $C=0, 1, 2$ respectively). The label $Y$ of each graph is exclusively determined by its motif $C$. In the construction of the training set, deliberate spurious correlations between the base $S$ and the label $Y$ are introduced. These correlations are quantified by the formula $P(S) = b \times \mathbb{I}(S = C) + (1 - b)/2 \times \mathbb{I}(S \neq C)$, where the motif follows a uniform distribution, and the base's distribution is contingent on the motif. The parameter $b$ is varied to produce different levels of bias within the Spurious-Motif datasets. The testing set features randomly combined motifs and bases, including graphs with larger bases, to accentuate the distributional disparities. In our experiments, we set the value of $b$ as 0.9.

\item \textbf{MNIST-75sp}~\citep{knyazev2019understanding}: This dataset transforms MNIST images into 70,000 graphs, each comprising up to 75 superpixels. These superpixels, which serve as graph nodes, are interconnected based on their spatial proximity, forming the graph edges. Each graph is categorized into one of 10 classes. Notably, the testing set is augmented with random noise in the node features to introduce variability.

\item \textbf{Graph-SST2}~\citep{socher2013recursive,yuan2022explainability}: This dataset includes graphs labeled according to sentence sentiment, with nodes representing tokens and edges reflecting the syntactic relationships between them. The graphs in this dataset are partitioned into different subsets based on their average node degree, thereby creating dataset shifts.

\item \textbf{Molhiv} (OGBG-Molhiv)~\citep{wu2018moleculenet,hu2020open}: Designed for the task of molecular property prediction, the Molhiv dataset encompasses graphs that represent molecules, where nodes correspond to atoms and edges denote chemical bonds. Each graph is labeled based on its efficacy in inhibiting HIV replication.
\end{itemize}


\section{Implementation Details}\label{appendix:implement}


\subsection{Baseline Settings}
%(1) ERM:  (2) EERM~\citep{wuhandling}: .
%%%%%%%that are simulated by adversarial context generators. 
%(3) ARM~\citep{zhang2021adaptive}: 
%%, where the first two variants leverage data points in the same domain as domain information, and the third variant utilizes the meta-learning paradigm~\citep{finn2017model} for adaptation. 
%(4) DRNN~\citep{koh2021wilds}: DRNN tackles the distribution shift problem by ensuring that the distribution minority receives sufficient training. (5) MMD~\citep{li2018domain} denotes maximum mean discrepancy. 
%
%(6) 
%(7) 
%(8) LiSA~\citep{yu2023mind}. 




In this subsection, we introduce the detailed settings for baseline methods used in our experiments.
\begin{itemize}[leftmargin=0.5cm]
    \item \underline{ERM}: ERM denotes Empirical Risk Minimization, which conducts learning across domains without designs for distribution shifts. This baseline acts as a vanilla comparison where no specific techniques are employed for OOD generalization. We use the same GNN encoder as our framework and set the learning rate as 0.001.
    \item \underline{EERM}~\citep{wuhandling}: EERM denotes Explore-to-Extrapolate Risk Minimization, which minimizes the mean and variance of risks from multiple domains that are simulated by adversarial context generators. For the parameter setting, we follow the choice in the original paper and search the hyper-parameters with grid search on the validation dataset. Specifically, the learning rate for GNN is chosen from $\{0.0001, 0.0002, 0.001, 0.005, 0.01\}$, the learning rate for graph editers is from $\{0.0001, 0.001, 0.005, 0.01\}$, and the weight for combination is chosen from $\{0.2, 0.5, 1.0, 2.0, 3.0\}$. 
\item\underline{ARM}~\citep{zhang2021adaptive}: ARM denotes Adaptive Risk Minimization, which adapts the model parameters to various domains based on a small batch of data from the domain. The ARM framework consists of three variants: ARM-CML, ARM-BN, and ARM-LL. In our experiments, we compare the variant of ARM-CML, which significantly outperforms all variants. Since ARM is not explicitly designed for graph data, we employ the identical GNN architecture to our framework as the encoder and randomly select nodes from each domain for adaptation. Following the original setting in the paper, we set the learning rate as 0.0001, the weight decay rate as 0.0001, and the support size as 50. Furthermore, for ARM-CML, the number of context channels is set as three.
\item\underline{DRNN}~\citep{koh2021wilds}: DRNN aims to tackle the distribution shift problem by ensuring that the distribution minority receives sufficient training. Following the setting in ARM, we set the learning rate as 0.0001 and the robust step size as 0.01.
\item\underline{MMD}~\citep{li2018domain}: MMD aims to maximize the mean discrepancy across domains. For the parameter setting, we set the learning rate as 0.0001 and the gamma value as 1. The support size is set the same as ARM as 50.
\item\underline{IS-GIB}~\citep{yang2023individual}: IS-GIB aims to discard spurious features while learning invariant features from a high-order perspective via preserving 
class relationships under various distribution shifts. We follow the parameter setting in their code and set the learning rate as 0.01.
\item\underline{MARIO}~\citep{zhu2023mario}: MARIO proposes to simultaneously achieve generalizable representations while obtaining invariant representations via adversarial data augmentations, based on graph contrastive learning strategies~\citep{oord2018representation,khosla2020supervised,tan2022supervised,wang2023contrast}. The learning rate is set as 0.001.
\item\underline{LiSA}~\citep{yu2023mind}: LiSA proposes to leverage variational subgraph
generators to extract locally predictive patterns that could be used for constructing label-invariant subgraphs. These subgraphs are then used to create augmented environments with enhanced diversity. 
\end{itemize}
We adopt the same GNN encoder for all baselines, i.e., a 2-layer GCN~\citep{kipf2017semi}. Since DRNN and MMD are not designed for scenarios with only one training domain, we use the interpolated domains generated by EERM as training domains for these two methods.

	\subsection{Training Details}
During training, we conduct all experiments on one NVIDIA
A6000 GPU with 48GB of memory. The package requirements of our experiments are listed below.
	\begin{itemize}
	    \item Python == 3.7.10
	    \item torch == 1.8.1
	    \item numpy == 1.18.5
        \item scipy == 1.5.3
    \item networkx == 2.5.1
    \item scikit-learn == 0.24.1
    \item pandas == 1.2.3
	\end{itemize}
	
\subsection{Training Time and Memory Usage}
In this subsection, we provide the time/memory of all experiments conducted on one NVIDIA A6000 GPU with 48GB of memory in Table~\ref{tab:training_stats}.

\begin{table}[h]
		\setlength\tabcolsep{5pt}%调列距

		\centering
        \caption{Training time and memory usage for different datasets.}
		\renewcommand{\arraystretch}{1.3}

\begin{tabular}{c|c|c|c}
\hline
\textbf{Dataset} & \textbf{Total Training Time (s)} & \textbf{Time Per Epoch (s)} & \textbf{Memory Usage (MB)} \\ \hline
Cora            & 1,782.96                         & 3.91                        & 1,329                      \\ 
Photo           & 3,504.65                         & 24.50                       & 6,255                      \\ 
Twitch          & 1,156.37                         & 7.93                        & 3,011                      \\ 
FB-100          & 5,902.70                         & 44.05                       & 30,387                     \\ 
Elliptic        & 539.43                           & 16.19                       & 4,103                      \\ 
Arxiv           & 4,355.21                         & 4.50                        & 5,505                      \\ \hline
\end{tabular}
\label{tab:training_stats}
\end{table}

From the results, we observe that all training times and memory usages are within a controllable range, demonstrating that our method is applicable to a wide variety of scenarios with different types of distribution shifts. Moreover, the training time per epoch is particularly higher for Elliptic, as graphs in this dataset contain significantly larger numbers of nodes and edges. Nevertheless, the total training time remains reasonable, indicating that our method is scalable to large datasets.


\label{appendix:F}

\section{Detailed Results}
\label{appendix:G}

In this section, we provide detailed results for the specific test domains on \texttt{Cora} (8 test domains), \texttt{Photo} (8 test domains), \texttt{FB-100} (3 test domains), and \texttt{Twitch} (5 test domains). The results are provided in Table~\ref{tab:4}, Table~\ref{tab:5}, and Table~\ref{tab:6}. 
%Note that in Sec.~\ref{sec:main_results}, for dataset \texttt{Elliptic}, we report the results of three integrated test domains based on their chronological order. We also provide detailed results of it in this section.



	\begin{table*}[t]
			\setlength\tabcolsep{8pt}%调列距

		\centering
            		\caption{The graph OOD generalization results on \texttt{Cora}.}
		\renewcommand{\arraystretch}{1.2}
		\begin{tabular}{c|cccccccc}
			\hline

Method&T1&T2&T3&T4&T5&T6&T7&T8\\\hline\hline
ERM & 67.86 & 65.03 & 71.25 & 66.28 & 70.34 & 66.72 & 70.53 & 67.58 \\
DRNN & \textbf{76.62} & 73.63 & 83.09 & 56.35 & 78.18 & 78.47 & 79.84 & 72.49 \\
MMD & 75.30 & \textbf{86.23} & 82.87 & 52.44 & \textbf{82.02 }& 77.70 & 80.61 & 69.05 \\
ARM & 62.22 & 64.25 & 62.74 & 62.27 & 64.11 & 62.92 & 60.64 & 64.40 \\
EERM & 70.09 & 70.99 & 72.55 & 71.13 & 71.03 & 68.04 & 71.29 & 68.88 \\
LiSA &76.05&74.39&81.26&71.08&78.56&79.98&81.27&71.15\\
IS-GIB&75.67&76.41&84.61&74.07&82.90&80.79&82.74&71.32\\
MARIO&73.50&71.01&80.59&70.84&78.68&80.90&78.94&\textbf{74.42}\\
GRM & 74.92&84.95&\textbf{89.15}&\textbf{76.83}&79.74&\textbf{85.04}&\textbf{84.63}&74.23 \\


\hline
		\end{tabular}

      \label{tab:4}
  \end{table*}

	\begin{table*}[t]
			\setlength\tabcolsep{8pt}%调列距

		\centering
          		\caption{The graph OOD generalization results on \texttt{Photo}.}
		\renewcommand{\arraystretch}{1.2}
		\begin{tabular}{c|cccccccc}
			\hline
Method&T1&T2&T3&T4&T5&T6&T7&T8\\\hline\hline
ERM & 84.35 & 89.57 & 89.39 & 90.14 & 87.63 & 90.08 & 87.34 & 90.04 \\
DRNN & 77.08 & 77.28 & 76.71 & 76.86 & 77.33 & 77.33 & 77.01 & 77.18 \\
MMD & 83.83 & 82.09 & 86.26 & 85.50 & 83.90 & 84.98 & 86.78 & 84.80 \\
ARM& 82.05 & 69.62 & 74.03 & 77.23 & 86.18 & 58.33 & 69.49 & 79.59 \\
%ARM-BN & 91.44 & 91.88 & 91.49 & 90.11 & 90.15 & 90.59 & 91.07 & 91.35 \\
%ARM-LL & 73.23 & 91.71 & 81.90 & \textbf{93.90} & \textbf{93.71} & \textbf{93.49} & \textbf{93.53} & 67.88 \\
EERM & {92.70} & 92.18 & \textbf{92.20} & 90.78 & 92.14 & {91.46} & 91.11 & {91.80} \\
LiSA&92.01&92.14&90.88&90.26&91.62&91.09&\textbf{92.24}&91.71\\
IS-GIB&89.92&92.47&90.38&90.08&{93.21}&90.24&87.15&88.33\\
MARIO&91.18&89.24&89.37&88.34&89.81&88.87&88.57&90.10\\
GRM & \textbf{93.37}&\textbf{92.53}&91.91&\textbf{93.86}&\textbf{94.33}&\textbf{91.56}&91.30&\textbf{92.42}\\
\hline
		\end{tabular}

    \label{tab:5}
  \end{table*}

  	\begin{table*}[t]
			\setlength\tabcolsep{8pt}%调列距

		\centering
          		\caption{The graph OOD generalization results on \texttt{FB-100} and \texttt{Twitch}.}
		\renewcommand{\arraystretch}{1.2}
		\begin{tabular}{c|ccc|cccccc}
			\hline
      			Dataset&\multicolumn{3}{c|}{\texttt{FB-100}}&\multicolumn{5}{c}{\texttt{Twitch}}\\\hline
Method&T1&T2&T3&T1&T2&T3&T4&T5\\\hline\hline
ERM & 50.48 & 54.53 & 53.23 & 54.20 & 55.20 & 50.41 & 51.58 & 49.73 \\
DRNN & 49.56 & 56.76 & 47.98 & 50.92 & 53.33 & 43.98 & 45.87 & 46.47 \\
MMD & 51.35 & 57.00 & 51.58 & 53.94 & 54.13 & 42.81 & 48.30 & 46.30 \\
ARM& 50.73 & 56.64 & 56.11 & 52.18 & 49.49 & 43.24 & 50.21 & 47.13 \\
%ARM-BN & 50.82 & 56.97 & \textbf{56.32} & 47.81 & 46.78 & 49.08 & 47.74 & 47.04 \\
%ARM-LL & 50.82 & 56.95 & 56.30 & 46.56 & 49.11 & 44.59 & 49.86 & 49.20 \\
EERM & 50.85 & \textbf{56.73} & 55.39 & 57.19 & 55.17 & 51.61 & 52.54 & 53.79 \\
LiSA&\textbf{59.13}&48.83&54.73&\textbf{63.04}&\textbf{57.94}&48.58&54.45&55.13\\
IS-GIB&49.55&53.25&\textbf{60.87}&61.23&57.08&51.69&\textbf{54.50}&\textbf{55.36}\\
MARIO&50.33&55.73&55.57&59.45&56.81&53.57&50.67&54.98\\
GRM &51.95&56.11&57.33 & 61.45&56.82&\textbf{60.25}&52.52&52.64 \\

\hline
		\end{tabular}

  \label{tab:6}
  \end{table*}

\begin{comment}
    

  	\begin{table*}[t]
			\setlength\tabcolsep{8pt}%调列距
		\small
		\centering
		\renewcommand{\arraystretch}{1.2}
		\caption{The graph OOD generalization results on \texttt{Elliptic}.}
		\begin{tabular}{c|ccccccccc}
			\hline
Method&T1&T2&T3&T4&T5&T6&T7&T8&T9\\\hline\hline
ERM & 59.57 & 61.29 & 57.81 & 64.41 & 67.76 & 58.38 & 71.85 & 59.48 & 53.85 \\
DRNN & 72.36 & 74.90 & 72.41 & 70.58 & 69.89 & 73.82 & 68.09 & 65.99 & 77.74 \\
MMD & 72.27 & 75.03 & 68.31 & 69.87 & 68.48 & 71.87 & 68.16 & 63.53 & 77.90 \\
ARM & 71.51 & 73.90 & 70.81 & 69.13 & 68.52 & 71.53 & 66.26 & 61.11 & 76.34 \\
%ARM-BN & 66.23 & 71.25 & 62.39 & 67.64 & 67.39 & 68.05 & 61.72 & 61.43 & 74.78 \\
%ARM-LL & 71.91 & 74.12 & 71.48 & 69.46 & 68.17 & 70.19 & 61.80 & 61.20 & 76.09 \\
EERM & 65.35 & 67.06 & 66.37 & 65.63 & 62.36 & 63.39 & 64.43 & 54.09 & 48.05 \\
LiSA&71.39&68.98&66.02&64.99&64.66&66.99&69.37&66.05&72.40\\
IS-GIB&71.42&72.28&69.94&68.85&72.02&69.08&71.16&60.97&79.04\\
MARIO&69.29&72.18&67.87&73.48&68.59&76.36&70.90&65.36&76.97\\
GRM & \textbf{88.39} &\textbf{85.21} &\textbf{90.60} & \textbf{79.24} & \textbf{84.05}&\textbf{90.86} & \textbf{88.61} & \textbf{90.03} & \textbf{89.89} \\

\hline
		\end{tabular}
  \vspace{0.1in}\label{tab:7}
  \end{table*}
\end{comment}

\section{Created Datasets with Different Degrees of Distribution Shifts}
\label{appendix:H}
In this section, we introduce the details of the dataset $\texttt{Cora-Mix}$ used in Sec.~\ref{sec:distribution}. Specifically, we aim to manually control the degree of distribution shifts across different domains. However, the original dataset \texttt{Cora} provided in EERM~\citep{wuhandling} creates distribution shifts via the concatenation of domain-sensitive features and label-related features, which means the degree of distribution shifts cannot be easily quantified. Therefore, we propose to mix up these two types of features with a weight to control the distribution shift degree. In particular, we follow the same strategy of generating these features, except that we changed their dimensions to be equal. In this manner, we can perform mix-up on them with a specific weight, i.e., the bias ratio. We also keep the domain split setting of 1/1/8 for training, validation, and test, respectively.


\section{Limitations}\label{sec:limit}
Despite its superior performance, our framework still possesses several limitations. For example, our GRM framework involves the learning of domain information from other nodes or graphs in the domain. However, in practice, the available graphs in each domain may not be sufficient. As a result, the performance of our framework may be impacted. In addition, although our GRM framework is validated in both node-level and graph-level tasks, its performance on edge-level tasks is not evaluated.

\end{document}
