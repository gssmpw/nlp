\section{Related Works}
\subsection{Out-of-Distribution (OOD) Generalization} OOD Generalization aims to learn a model that can generalize to an unseen test domain, given several different but related training domain(s). Prior invariant methods____ genreally focus on learning invariant features____ or optimizing for the worst-case group performance____. 
%In contrast, adaptive methods for OOD generalization adapt learned models to unseen domains____. For example, ARM____ extracts information from random data points in the test domain for adaptation. %In another work____, contexts from the test domain are treated as probabilistic latent variables for adaptation. 
  Recent works for OOD generalization on graphs____ could be typically categorized into two classes: invariant learning and graph augmentation____. Among invariant learning methods, CIGA____ proposes to extract subgraphs that maximally preserve the invariant intra-class information based on causality. 
  DIR____ uses a set of graph representations as the invariant rationales 
  %and conducts interventional augmentations
  to create additional distributions. GIL____ identifies invariant subgraphs via a GNN-based generator.
  More recently, 
  %IS-GIB____ explores invariant information based on Graph Information Bottleneck (GIB). 
  MARIO____ utilizes the Information Bottleneck (IB) principle to learn invariant information. 
  %It maximizes the mutual information between graph representations and labels and minimizes the mutual information between the inputs and the learned representations. In this way, the learned representation could be more robust to distribution shifts.
 Among augmentation methods, LiSA____ proposes to leverage graph augmentation to obtain more diverse training data for learning invariant information. 
 %The authors notice the potential risk of changing the labels of the augmented graphs and thus employ a variational subgraph generator to output label-invariant subgraphs.  
 EERM____ generates domains by maximizing the loss variance between domains in an adversarial manner, such that the obtained domains could aid in learning invariant representations. 
%Note that DIR, GIL, and CIGA are proposed for graph classification and thus are not suitable for comparisons. EERM, proposed for node classification, is based on the invariant principle. In contrast to EERM, our framework GRM adopts the concept of adaptation to effectively leverage unlabeled data in test domains.

%SRGNN____ proposes to convert the biased training data to the unbiased distribution via a central moment discrepancy regularizer and a kernel mean matching technique. 

%GIL____ proposes to identify invariant subgraphs via a GNN-based subgraph generator for inferring latent domain labels. 
%CIGA____ characterize potential distribution shifts on graphs with causal
%models, concluding that OOD generalization on graphs is achievable when models focus only on subgraphs containing the most information about the causes of labels. Accordingly, we propose an information-theoretic objective to extract the desired subgraphs that maximally preserve the invariant intra-class information







\subsection{Graph Generative Models}
In recent years, numerous works have been proposed for graph generation____. Specifically, GraphVAE____ proposes a framework based on VAE____ to generate graphs by encoding existing graphs. GraphRNN____ generates graphs through a sequence of node and edge formations. Moreover, several methods____ focus on generating graphs based on specific knowledge. For example, MolGAN____ adapts the framework of Generative Adversarial Networks
(GANs)____ to operate directly on graph-structured data with a reinforcement learning objective. Note that although these methods leverage different information for generating graphs, they are not explicitly proposed for handling the distribution shift problem on graphs. In contrast, our framework GRM aims to utilize domain information to generate graphs that are suitable for a trained classifier. 
%Moreover, due to flexibility in our design, GRM can be compatible with different graph generative techniques.

% \vspace{0.03in}