\section{Related Works}
\subsection{Out-of-Distribution (OOD) Generalization} OOD Generalization aims to learn a model that can generalize to an unseen test domain, given several different but related training domain(s). Prior invariant methods~\citep{ganin2015unsupervised,li2018domain,arjovsky2019invariant} genreally focus on learning invariant features~\citep{sun2016return,peng2019moment} or optimizing for the worst-case group performance~\citep{hu2018does,sagawa2020distributionally}. 
%In contrast, adaptive methods for OOD generalization adapt learned models to unseen domains~\citep{kumagai2018zero}. For example, ARM~\citep{zhang2021adaptive} extracts information from random data points in the test domain for adaptation. %In another work~\citep{kumagai2018zero}, contexts from the test domain are treated as probabilistic latent variables for adaptation. 
  Recent works for OOD generalization on graphs~\citep{chen2022learning,li2022learning,wang2024safety} could be typically categorized into two classes: invariant learning and graph augmentation~\citep{li2022out}. Among invariant learning methods, CIGA~\citep{chen2022learning} proposes to extract subgraphs that maximally preserve the invariant intra-class information based on causality. 
  DIR~\citep{wudiscovering} uses a set of graph representations as the invariant rationales 
  %and conducts interventional augmentations
  to create additional distributions. GIL~\citep{li2022learning} identifies invariant subgraphs via a GNN-based generator.
  More recently, 
  %IS-GIB~\citep{yang2023individual} explores invariant information based on Graph Information Bottleneck (GIB). 
  MARIO~\citep{zhu2023mario} utilizes the Information Bottleneck (IB) principle to learn invariant information. 
  %It maximizes the mutual information between graph representations and labels and minimizes the mutual information between the inputs and the learned representations. In this way, the learned representation could be more robust to distribution shifts.
 Among augmentation methods, LiSA~\citep{yu2023mind} proposes to leverage graph augmentation to obtain more diverse training data for learning invariant information. 
 %The authors notice the potential risk of changing the labels of the augmented graphs and thus employ a variational subgraph generator to output label-invariant subgraphs.  
 EERM~\citep{wuhandling} generates domains by maximizing the loss variance between domains in an adversarial manner, such that the obtained domains could aid in learning invariant representations. 
%Note that DIR, GIL, and CIGA are proposed for graph classification and thus are not suitable for comparisons. EERM, proposed for node classification, is based on the invariant principle. In contrast to EERM, our framework GRM adopts the concept of adaptation to effectively leverage unlabeled data in test domains.

%SRGNN~\citep{zhu2021shift} proposes to convert the biased training data to the unbiased distribution via a central moment discrepancy regularizer and a kernel mean matching technique. 

%GIL~\citep{li2022learning} proposes to identify invariant subgraphs via a GNN-based subgraph generator for inferring latent domain labels. 
%CIGA~\citep{chen2022learning} characterize potential distribution shifts on graphs with causal
%models, concluding that OOD generalization on graphs is achievable when models focus only on subgraphs containing the most information about the causes of labels. Accordingly, we propose an information-theoretic objective to extract the desired subgraphs that maximally preserve the invariant intra-class information







\subsection{Graph Generative Models}
In recent years, numerous works have been proposed for graph generation~\citep{you2018graphrnn,grover2019graphite}. Specifically, GraphVAE~\citep{simonovsky2018graphvae} proposes a framework based on VAE~\citep{kingma2013auto} to generate graphs by encoding existing graphs. GraphRNN~\citep{you2018graphrnn} generates graphs through a sequence of node and edge formations. Moreover, several methods~\citep{jin2018junction,preuer2018frechet} focus on generating graphs based on specific knowledge. For example, MolGAN~\citep{de2018molgan} adapts the framework of Generative Adversarial Networks
(GANs)~\citep{goodfellow2014generative} to operate directly on graph-structured data with a reinforcement learning objective. Note that although these methods leverage different information for generating graphs, they are not explicitly proposed for handling the distribution shift problem on graphs. In contrast, our framework GRM aims to utilize domain information to generate graphs that are suitable for a trained classifier. 
%Moreover, due to flexibility in our design, GRM can be compatible with different graph generative techniques.

% \vspace{0.03in}