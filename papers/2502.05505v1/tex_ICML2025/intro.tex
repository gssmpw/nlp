\section{Introduction}
Leaking sensitive user information is a significant concern in data-driven applications. A common solution is to generate differentially private (DP) \cite{dwork2006calibrating} synthetic data that closely resembles the original while ensuring strict privacy guarantees. This DP synthetic data can serve as a substitute for the original in various applications, such as model fine-tuning, statistical analysis, and data sharing, while preserving user privacy.

\privateevolution{} (\pe{}) \cite{lin2023differentially,xie2024differentially} has recently emerged as a promising method for generating DP synthetic data. 
\pe{} starts by probing a foundation model to generate random samples, then iteratively selects those most similar to the private data and uses the model to generate more samples that resemble them.
Unlike previous state-of-the-art approaches that require fine-tuning open-source models, \pe{} relies solely on model inference.
Therefore, \pe{} can be up to 66$\times$ faster than training-based methods \cite{xie2024differentially}.
More importantly, this enables \pe{} to easily harness the cutting-edge foundation models like GPT-4 \cite{openai2023gpt4} and Stable Diffusion \cite{rombach2022high}, achieving state-of-the-art performance across multiple image and text benchmarks \cite{lin2023differentially,xie2024differentially,hou2024pre,zou2025contrastive}.

However, \pe{} relies on foundation models suited to the private data domain, which may not always be available. When the model's distribution significantly differs from the private data, \pe{}'s performance lags far behind training-based methods \cite{dpimagebench}.

To address this question, we note that in the traditional synthetic data field—where private data is \emph{not} involved—domain-specific, non-neural-network \emph{simulators} remain widely used, especially in domains where foundation models struggle. Examples include computer graphics-based simulators for images, videos, and 3D data (e.g., Blender \cite{blender} and Unreal \cite{unreal}), physics-based simulators for robotics data (e.g., Genesis \cite{Genesis}), and network simulators for networking data (e.g., ns-2 \cite{issariyakul2009introduction}). While these simulators have been successful, their applications in \emph{DP} data synthesis remain underexplored. This is understandable, as adapting these simulators to fit private data in a DP fashion requires non-trivial, case-by-case modifications.
Our key insight is that \pe{} only requires two APIs: \randomsampleapiname{} that generates random samples and \samplevariationapiname{} that generates samples similar to the given one. These APIs do not have to come from foundation models! Thus, we ask: 
\emph{Can \pe{} use simulators in place of foundation models?}
If viable, this approach could greatly expand \pe{}'s capabilities and unlock the potential of a wide range of domain-specific simulators for DP data synthesis.

In this paper, we explore this potential in the context of \emph{images}. 
We consider two types of simulator access:
\textbf{(1) The simulator is accessible.} In this case, we define \randomsampleapiname{} as using random simulator parameters to render an image, and \samplevariationapiname{} as slightly perturbing the simulator parameters of the given image.
\textbf{(2) The simulator is \emph{not} accessible—only its generated dataset is released.} This scenario is quite common \cite{wood2021fake,bae2023digiface}, especially when simulator assets are proprietary \cite{kar2019meta,devaranjan2020meta}. In this case, we define \randomsampleapiname{} as randomly selecting an image from the dataset, and \samplevariationapiname{} as randomly selecting a nearest neighbor of the given image.
We demonstrate that the resulting algorithm, \simpe{}, outperforms \pe{} with foundation models.
Our key contributions are:
\begin{packeditemize} 
\item \textbf{Insight:} We identify that \pe{} is not limited to foundation models, making it the first framework capable of utilizing both state-of-the-art foundation models and simulators for DP data synthesis. 
\item \textbf{Algorithm:} We propose \simpe{}, an extension of \pe{} using simulators, applicable in both scenarios where the simulator or the generated dataset is available. Additionally, we introduce the use of \emph{both foundation models and simulators interchangeably during the data synthesis process}, allowing for the benefits of both to be leveraged through \pe{}'s easy and standardized interface. 
\item \textbf{Results:} We demonstrate promising results with \simpe{}. For instance, on the \mnist{} dataset with $\epsilon=1$, downstream classification accuracy increases to 89.1\%, compared to 27.9\% with the original \pe{}. 
Furthermore, combining foundation models with weak simulators results in improved performance compared to using either one alone.
\end{packeditemize}

 



