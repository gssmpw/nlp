\section{\simpe{}: \privateevolution{} (\pe{}) with Simulators}

\subsection{Overview}

In this paper, we focus on DP \emph{image} generation.
The beauty of the \privateevolution{} framework is that it isolates \emph{DP mechanism} from \emph{data generation backend}. In particular, any data generation backend that supports \randomsampleapiname{} and \samplevariationapiname{} can be plugged into the framework and transformed into a DP data synthesis algorithm. Therefore, \textbf{our goal is to design \randomsampleapiname{} and \samplevariationapiname{} for image simulators.}


We notice that existing popular image simulators provide different levels of access.
\textbf{Some simulators are open-sourced.} Examples include \kubric{} \cite{greff2021kubric}, a Blender-based renderer for multi-object images/videos; \teapot{} \cite{lin2020infogan,eastwood2018framework}, an OpenDR-based renderer for teapot images; and \pythonavatar{} \cite{pythonavatar}, a rule-based generator for avatars. However, the assets (e.g., 3D models) used in these renderers are often proprietary.
Therefore, \textbf{many simulator works choose to release only the generated datasets without the simulator code.} Examples include the \facesynthetics{} \cite{wood2021fake} and the \digiface{} \cite{bae2023digiface} datasets, both generated using Blender-based renderers for human faces.
In \cref{sec:method_simulator,sec:method_data}, we discuss the design for simulators with code access and data access, respectively.

Moreover, since simulators and foundation models provide the same \randomsampleapiname{} and \samplevariationapiname{} interfaces to \pe{}, we can easily utilize both together in the data generation process. \cref{sec:method_simulator_and_model} discusses the methedology. 

\myparatightestn{Privacy analysis.} Since we only modify \randomsampleapiname{} and \samplevariationapiname{}, the privacy guarantee is exactly the same as \citet{lin2023differentially}, and we skip it here.



\subsection{\simpe{} with Simulator Access}
\label{sec:method_simulator}
While different simulators have very different programming interfaces, most of them can be abstracted in the same way. Given a set of $\numcate$ \emph{categorical} parameters $\cate_1,\ldots,\cate_\numcate$ and $\numnume$ \emph{numerical} parameters $\nume_1,\ldots,\nume_\numnume$ where $\cate_i\in \cateset_i$ and $\nume_i\in \numeset_i$, the simulator $\simulator$ generates an image $\simulatorfun{\cate_1,\ldots,\cate_\numcate,\nume_1,\ldots,\nume_\numnume}$. For example, for face image renders \cite{wood2021fake,bae2023digiface}, $\cate_i$s could be the ID of the 3D human face model and the ID of the hair style, and $\nume_i$s could be the angle of the face and the strength of lighting.

For \randomsampleapiname{}, we simply draw each parameter randomly from its corresponding feasible set. Specifically, we define
\begin{align}
    &\randomsampleapiname{} = \simulatorfun{\cate_1,\ldots,\cate_\numcate,\nume_1,\ldots,\nume_\numnume},\label{eq:simulator_random_api}\\
    &\text{where } \cate_i \sim \uniform{\cateset_i} \text{ and } \nume_i \sim \uniform{\numeset_i}.\nonumber
\end{align}
Here, $\uniform{S}$ denotes drawing a sample uniformly at random from the set $S$.

For \samplevariationapiname{}, we generate variations by perturbing the input image parameters. For numerical parameters $\nume_i$, we simply add noise. However, for categorical parameters $\cate_i$, where no natural ordering exists among feasible values in $\cateset_i$, adding noise is not applicable. Instead, we re-draw the parameter from the entire feasible set $\cateset_i$ with a certain probability. Formally, it is defined as 
\begin{align}
    & \quad\quad\samplevariationapi{\simulatorfun{\cate_1,\ldots,\cate_\numcate,\nume_1,\ldots,\nume_\numnume}} \nonumber\\&\quad\quad=\simulatorfun{\cate_1',\ldots,\cate_\numcate',\nume_1',\ldots,\nume_\numnume'},\label{eq:simulator_variation_api}\\
    &\text{where } \nume_i'\sim \uniform{\brb{\nume_i-\numevariationdegree,\nume_i+\numevariationdegree} \cap \numeset_i}
    \text{ and }\nonumber\\
    &\quad \cate_i'=\begin{cases}
      \uniform{\cateset_i}, & \text{with probability } \catevariationdegree \nonumber\\
      \cate_i, & \text{with probability } 1-\catevariationdegree
    \end{cases}\nonumber.
\end{align}
Here, $\numevariationdegree$ and $\catevariationdegree$ control the degree of variation. At one extreme, when $\numevariationdegree=\infty$ and $\catevariationdegree=1$, \samplevariationapiname{} completely discards the information of the input sample and reduces to \randomsampleapiname{}. Conversely, when $\numevariationdegree=\catevariationdegree=0$, \samplevariationapiname{} outputs the input sample unchanged.


\subsection{\simpe{} with Simulator-generated Data}
\label{sec:method_data}

Here, we assume that a dataset of $\numsimdata$ samples $\simdataset=\brc{\simdata_1,\ldots,\simdata_\numsimdata}$ generated from the simulator is already given. The goal is to pick $\numgensamples$ samples from them to construct the DP synthetic dataset $\generatedsampleset$. Before discussing our final solutions, we first discuss why two straightforward approaches do not work well.

\myparatightestn{Baseline 1: Applying \dpvotingfunctionname{} on $\generatedsampleset$.} One immediate solution is to apply \dpvotingfunctionname{} in \pe{} (\cref{alg:voting}) by treating $\simdataset$ as the generated set $S$. In other words, each private sample votes for its nearest neighbor in $\simdataset$, and the final histogram, aggregating all votes, is privatized with Gaussian noise. We then draw samples from $\simdataset$ according to the privatized histogram (i.e., \cref{line:draw} in \cref{alg:main_full}) to obtain $\generatedsampleset$.

However, the size of the simulator-generated dataset (i.e., $\numsimdata$) is typically very large (e.g., 1.2 million in \citet{bae2023digiface}), and the total amount of added Gaussian noise grows with $\numsimdata$. This means that the resulting histogram suffers from a low signal-to-noise ratio, leading to poor fidelity in $\generatedsampleset$.

\myparatightestn{Baseline 2: Applying \dpvotingfunctionname{} on cluster centers of $\generatedsampleset$.} 
To improve the signal-to-noise ratio of the histogram, one solution is to have private samples vote on the cluster centers of $\simdataset$ instead of the raw samples. Specifically, we first cluster the samples in $\simdataset$ into $\numclusters$ clusters with centers $\brc{\clustercenter_1,\ldots,\clustercenter_{\numclusters}}$ and have private samples vote on these centers rather than individual samples in $\simdataset$.\footnote{Note that voting in \citet{lin2023differentially} is conducted in the image embedding space. Here, $\clustercenter_i$s represent cluster centers in the embedding space, and each private sample uses its image embedding to find the nearest cluster center.}
Since the number of bins in the histogram decreases from $\numsimdata$ to $\numclusters$, the signal-to-noise ratio improves. Following the approach of the previous baseline, we then draw $\numgensamples$ cluster centers (with replacement) based on the histogram and randomly select a sample from each chosen cluster to construct the final $\generatedsampleset$.

However, when the total number of samples $\numsimdata$ is large, each cluster may contain a diverse set of samples, including those both close to and far from the private dataset. While DP voting on clusters improves the accuracy of the DP histogram and helps select better clusters, there remains a risk of drawing unsuitable samples from the chosen clusters.

\myparatightestn{Our approach.} Our key insight is that the unavoidable trade-off between the accuracy of the DP histogram and the precision of selection (clusters vs. individual samples) arises because private samples are forced to consider all samples in $\simdataset$â€”either directly in baseline 1 or indirectly through cluster centers in baseline 2. However, this is not necessary. If we already know that a sample $\simdata_i$ is far from the private dataset, then its nearest neighbors in $\simdataset$ are also likely to be far from the private dataset. Therefore, we can avoid wasting the privacy budget on evaluating such samples. 

The iterative selection and refinement process in \pe{} naturally aligns with this idea. For each sample $\simdata_i$, we define its nearest neighbors in $\simdataset$ as $\nnsample^i_1,\ldots,\nnsample^i_\numsimdata$, sorted by closeness, where $\nnsample^i_1 = \simdata_i$ is the closest.
We define \randomsampleapiname{} as drawing a random sample from $\simdataset$:
\begin{align*}
\randomsampleapiname{} \sim \uniform{\simdataset}.
\end{align*}
Since we only draw $\numgensamples$ samples (instead of $\numsimdata$) from \randomsampleapiname{}, the DP histogram on this subset has a higher signal-to-noise ratio.
In the following steps (\cref{line:voting,line:normalization,line:draw} in \cref{alg:main_full}), samples far from the private dataset are removed, and we perform variations only on the remaining samples according to:
\begin{align*}
\samplevariationapi{\simdata_i} = \uniform{\brc{\nnsample^i_1,\ldots,\nnsample^i_\nnvariationdegree}},
\end{align*}
thus avoiding consideration of nearest neighbors of the removed samples (unless they are also nearest neighbors of retained samples).
Similar to $\numevariationdegree$ and $\catevariationdegree$ and in \cref{sec:method_simulator}, the parameter $\nnvariationdegree$ controls the degree of variation. At one extreme, when $\nnvariationdegree = \numsimdata$, \samplevariationapiname{} disregards the input sample and reduces to \randomsampleapiname{}. At the other extreme, when $\nnvariationdegree = 1$, \samplevariationapiname{} returns the input sample unchanged.

\myparatightestn{Broader applications.}
The proposed algorithm can be applied to any public dataset beyond simulator-generated data. In our experiments (\cref{sec:exp}), we focus on simulator-generated data, and we leave the exploration of broader applications for future work.

\subsection{\simpe{} with both Simulators and Foundation Models}
\label{sec:method_simulator_and_model}

As discussed in \cref{sec:preliminaries}, simulators and foundation models complement each other across different data domains. Moreover, even within a single domain, they excel in different aspects. For example, computer graphics-based face image generation frameworks \cite{bae2023digiface,wood2021fake} allow controlled diversity in race, lighting, and makeup while mitigating potential biases in foundation models. However, the generated faces may appear less realistic than those produced by state-of-the-art foundation models. Thus, combining the strengths of both methods for DP data synthesis is highly appealing. 

Fortunately, \pe{} naturally supports this integration, as it only requires \randomsampleapiname{} and \samplevariationapiname{}, which work the same for both foundation models and simulators. While there are many ways to combine them, we explore a simple strategy: using simulators in the early \pe{} iterations to generate diverse seed samples, then switching to foundation models in later iterations to refine details and enhance realism. As shown in \cref{sec:exp}, this approach outperforms using either simulators or foundation models alone.

