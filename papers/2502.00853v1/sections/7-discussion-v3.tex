\section{Discussions}
\label{sec:discussion}




\para{Hybrid PC+VR interface was preferred.}
After improving the usability of the simulated PC, we observed a significant preference towards hybrid systems overall, particularly interaction. \textit{H\textsubscript{pre}} is supported.
\re{Most participants preferred the PC+VR hybrid interface, as it effectively combined the strengths of both devices, especially
when completing a complicated sensemaking task that requires both an overview and a detailed view of the information for navigation, foraging, insight generation, or synthesizing. 
VR provides participants with an overview of documents so they can quickly scan and move in space to read the documents and graphs with preferred locations and angles.
At the same time, PC offers a detailed view by supporting precise interactions and a compact view for digging deep into specific documents for graph construction.}{}

\re{\para{Hybrid PC+VR help relieving physical demand.}
While the PC+VR setup did not yield a marked improvement in the overall user experience---as evidenced by ratings on mental load and effort are similar for all conditions, 
except for physical demand (thus, \textit{H\textsubscript{exp}} is not supported)---it is noteworthy that the hybrid interface exhibited lower physical demand than a purely VR setup. Ratings on mental load and effort are similar for all conditions, indicating that the hybrid systems do not introduce new mental loads and efforts.}{}
This is worth noting, given that participants in both scenarios operated within a VR environment requiring spatial movement for navigation. 
\re{A possible explanation is that the predominant physical demands in VR stem from interactions, and the smooth transition between hand gestures and mouse and keyboard promotes streamlined interactions, particularly for those that require high precision. Moreover, the wheeled table surface could reduce arm movement, which increases comfort and reduces physical strain~\cite{cheng2022comfortable}. Future designs could consider involving a wheeled desk to support spatial navigation while reducing physical demands for hybrid systems, as well as VR systems.}{}



\para{Hybrid PC+VR interface with spatial features did not hinder performance.}
The study found no significant differences in time, accuracy, and concentration across conditions. Compared with the previous similar result~\cite{pavanatto2021we}, we further found that the involvement of spatial navigation \retvcg{with the movable simulated PC}{} in VR did not hinder performance when using the hybrid interface.
In particular, the task accuracy remains the same as we expected since the functionalities in all conditions were the same (\textit{H\textsubscript{acc}} is supported).
Initially, we had anticipated that PC would outperform VR and PC+VR in terms of speed, but the results suggest that both PC+VR and VR-only performed the same as PC-only. \textit{H\textsubscript{tim}} is largely inconclusive. 
This could be attributed to its intuitive embodied interactions, which enabled participants to physically navigate and leverage their spatial memory to improve their performance. 
Furthermore, the VR interface's ability to display all documents in a layout that allows physical navigation may have contributed to its better-than-expected performance.
More specifically, participants could just rotate their heads to scan, read, and search documents.
Such benefits of physical navigation have been verified in the context of large display walls~\cite{ball2007move}.
Moreover, user concentration did not significantly differ from hybrid PC+VR to single PC or VR conditions. We found no evidence for \textit{H\textsubscript{con}}. Combining the result that PC+VR was observed to have similar time performance, it indirectly demonstrates the success of our efforts to minimize context-switching costs between PC and VR.
\re{Future hybrid systems for data visualization could consider involving more spatial ability since we found evidence that it increased user preferences while not hindering performance.}{}

\para{PC+VR and VR-only required fewer number of \re{nodes and links}{interactions} to complete the study task than PC-only.}
Though we did not find a significant difference in the total number of interactions between conditions, we found a significant difference for the two main interactions, \ie{}, adding nodes and links, between VR-only and PC-only, and between PC+VR and PC-only.. (\textit{H\textsubscript{int}} is partially supported).
Two reasons could explain this finding. 
First, participants tended to add more nodes and links to store information from documents to reduce navigation in PC-only.
\re{As previous studies suggested, the unlimited display space in VR helps reduce navigation, while the limited display space in PC could require more navigation. Since only one document can be viewed at a time with limited display space on a PC, participants need to create more nodes and links to store the information using the graph to reduce the number of navigation between documents.}{} In contrast, documents were displayed with details and spatially distributed in VR, seamlessly blending into the room-sized visualization. This allowed participants to create fewer visualization elements to externalize document information. It could potentially indicate that PC+VR and VR-only facilitate a more precise graph for a more complex task.
Second, authoring the graph in VR is more difficult than it is on PCs and is unfamiliar to users. Although we provided an alternative text selection technique using close interaction, it is still difficult for users to select text precisely with mid-air gesturing due to hand shaking. Therefore, participants might try to create a more precise graph with fewer interactions in the VR environment.
More studies could investigate larger graphs or more complex problems to evaluate these possible reasons.


\para{Temporal strategies.} Most participants (11/18) used both environments in a complementary way. We observed this in two levels of granularity: interaction and task levels.
\textit{Interaction levels}: 
For a given low-level interaction, participants (7/11) would choose the most suitable environment. For example, some participants found VR helpful for exploring the node-link diagram and walking around to find insights but switched to PC to create the link because text selection and input were easier on PC. 
Participants who adopted this strategy switched between environments more frequently, as demonstrated in \Cref{fig:time}(d). \textit{Task levels}: Task-level complementation is more strategic, which might be the best fit for previous transitional approaches~\cite{jansen2023autovis,hubenschmid2022relive}. Participants (4/11) planned ahead and chose the best environment for different sensemaking stages.
For instance, participants first read documents in VR to get a general overview of the story, and then they extract keywords to validate their thoughts using the PC. 
These participants only switched between environments a few numbers of times, as demonstrated in \Cref{fig:time}(c).
Adopting such a strategy might seem counter-intuitive, given that smaller displays are typically associated with overviews, while larger ones are often linked to detailed views. 
However, participants seem to harness the spatial awareness and memory offered by VR to maintain a superior mental model of spatial information, leading to enhanced wayfinding performance---essential attributes of an overview. Concurrently, the precision and inspection capabilities of the PC make it well-suited as a detailed view.
The findings resonate with Schneiderman's mantra of information seeking ``\textit{Overview First, Zoom and Filter, Then Details-on-Demand}''~\cite{shneiderman1996eyes} and the design goals of the hybrid interface to combine immersive display and high-resolution input capabilities~\cite{feiner1991hybrid}.
\retvcg{While some participants transitioned only a few times at the task level or even remained in a single environment (11/18), a substantial portion of participants (7/18) frequently switched between devices at the interaction level. This highlights the need to reduce the transitional costs between devices. Future designs should consider non-transitional approaches~\cite{immersed2023, wang2020towards, pavanatto2021we, wang2022understanding} to lower these costs.}{}

\para{Spatial strategies.} With equipment of a lighter and smaller table, it opens more possibilities for spatial movement for a hybrid user interface. Interestingly, the spatial patterns reflect the current usage of computing devices. \textit{Stationary User and PC} mimicking the stationary working environment of sitting and watching multiple monitors, when \textit{stationary PC} is the representation of the current workflow of the hybrid system, such as ReLive~\cite{hubenschmid2022relive}. Users work in the space in VR and go to a specific location to work on the PC. Besides, two additional patterns, \textit{self-rotation} and \textit{carrying}, were observed compared to the preliminary study. \textit{Self-rotation} captures participants who rotate the desk and the PC screen while using the spatial distribution of documents in VR, while \textit{carrying} describes participants who fully unleash the potential of the VR space and simulated PC in space. \re{These two patterns might help users reduce head rotations, possibly relieving the fatigue for using HMDs~\cite{pavanatto2021we}, though it requires users to put effort into moving the wheeled table. 
}{} 






\para{Generalizability}. Considering the fundamental characteristics of our study task, we believe our findings can be generalized to other data-driven sensemaking tasks, especially tasks related to document and network analysis, such as affinity diagramming, social network analysis, and literature review. \re{Moreover, spatial hybrid interfaces can be used for a more general context beyond visual analysis and users, such as note-taking and building knowledge graphs with Large Language Model~\cite{suh2023sensecape} for the general public.}{}

Our findings might work with well-justified 3D visualizations like 3D scatterplots~\cite{yang2020embodied}, 3D heatmaps~\cite{kraus2020assessing}, and space-time cubes~\cite{wagner2019evaluating}. 
Furthermore, similar to separating documents in space, our result suggests using small multiple in VR while complementing an overview in the PC might be effective.


\para{Limitation and Future Work.} Although our results showed positive outcomes and encouraging feedback, there is still room for improvement. While we can estimate usage time for each device using explicit head gaze interaction logs, detailed interactions across devices—such as peeking at another interface—cannot be retrieved.
In future work, eye-tracking data could be collected to understand a more fine-grained usage of different visualizations from different devices.
We did not observe any significant results in performance in these studies, most likely due to the unfamiliarity of our conditions and limited sample size.
In the future, we could recruit more participants with extensive experience in data visualization and conduct a longitudinal study by providing additional usage and training time for each condition, such as text selection in VR and the use of PC and VR devices in PC+VR
We could also recruit more participants to reduce the effect of confounding factors, such as sensemaking skills, reading speed, and limited VR usage experience.
Given its lower physical demand and comparable mental load, we believe the hybrid condition could provide a more sustainable user experience than VR alone. 
Yet, future work still needs to consider how to reduce the physical demand further to the level of PC-only. 
Lastly, future studies could explore the impact of spatial hybrid PC+VR systems with various spatial and temporal settings to enhance visual sensemaking.
Nevertheless, our study provided valuable preliminary results for future research on spatial hybrid interfaces.

