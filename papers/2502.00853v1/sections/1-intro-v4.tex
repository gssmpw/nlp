\section{Introduction}
\label{sec:intro}

\IEEEPARstart{S}{ensemaking} \retvcg{is the process of interpreting and understanding complex information or situations to create insights and inform decision-making~\cite{pirolli2005sensemaking}}{}.
With increasingly available data, data-driven sensemaking becomes ubiquitous.
Visual user interfaces and data visualization have been shown to be helpful and effective for data-driven sensemaking,
as they augment people's ability to recognize patterns and distill insights from a large and complex dataset~\cite{card1999readings,andrews2010space,endert2012semantic}.
\retvcg{We refer to this process of making sense of data through visual user interfaces and data visualization as \textbf{visual sensemaking}.}{}
To support visual sensemaking, displays are essential to represent the data visually, and interactions are crucial to manipulate the data and visualizations to match the user's mental model.

\retvcg{While many visual sensemaking applications are currently tailored for the desktop environment (or PC), such an environment may be limited in addressing the increasing complexities of real-world problems, constrained by their limited display size, mobility, and interaction modalities. Therefore, a range of computing environments beyond the traditional desktop environment~\cite{munzner2014visualization} have been studied. For example, such as display walls~\cite{ball2007move,belkacem2022interactive} and tabletops~\cite{ens2020uplift} for the larger display size, smartphones for situated analysis~\cite{lee2021mobile}, and smartwatches~\cite{horak2018david} for on-body input capability.}{}
The recent emergence of affordable virtual and augmented reality (VR/AR) head-mounted displays (HMDs) has sparked a growing interest in using VR/AR for interactive data visualization and visual sensemaking.
This has given rise to a new research field known as \textit{Immersive Analytics}~\cite{ens2021grand,marriott2018immersive}.
Immersive analytics offers a range of potential benefits over the traditional desktop environment, such as the ability to use large display spaces~\cite{satriadi2020maps,lisle2020evaluating,yang2020embodied}, embodied and tangible interaction~\cite{yang2020tilt,cordeil2017imaxes,tong2022exploring,in2023table,hurter2018fiberclay}, 3D rendering~\cite{bach2017hologram,yang2018maps,kraus2019impact,kwon2016study,brath20143d}\re{, and spatial navigation~\cite{lisle2020evaluating,in2024evaluating,yang2020embodied,ball2007move,hayatpur2020datahop,li2023gestureexplorer}}{}.

However, immersive analytics has limitations. For example, users have reported experiencing fatigue when using VR/AR systems~\cite{mcmahan2012evaluating}. Additionally, performing precise interactions in VR/AR can be challenging, such as inputting specific values or adjusting a range on a slider~\cite{cordeil2020embodied}. 
While efforts have been made to improve the input experience in VR/AR, it remains time-consuming and frustrating in some scenarios.
Conversely, PC, as the most widely used computing environment, excels in tasks where VR/AR falls short, such as text input~\cite{mcgill2015dose}.

\begin{figure}
\centering
\includegraphics[width=\columnwidth]{figs/rv_v2.png}
\caption{The figure shows the PC, our proposed PC+VR hybrid system, and VR in realityâ€“virtuality continuum~\cite{milgram1995augmented}. As the resulting environment is mainly virtual, it leans towards VR and falls under Augmented Virtuality.}
\label{fig:rv}
\end{figure}

\IEEEpubidadjcol %

While both PC and VR platforms offer distinct advantages and present specific challenges, we wanted to explore the concept of a hybrid user interface~\cite{feiner1991hybrid}, aiming to capitalize on their strengths and mitigate their inherent limitations. 
\re{Current hybrid approaches often adopt a transitive approach, which requires users to frequently switch between devices~\cite{hubenschmid2022relive,jansen2023autovis}.
Other hybrid methods~\cite{immersed2023, wang2020towards, pavanatto2021we, wang2022understanding, seraji2024analyzing} utilize non-transitional approaches, which favor a seated posture suited to the desktop environment but restrict spatial navigation within immersive spaces. 
Spatial ability has been shown to be beneficial in sensemaking and data exploration~\cite{lisle2020evaluating,in2024evaluating}.}{}
Therefore, we aim to explore \textbf{how people would utilize a \textit{spatial hybrid PC+VR system} for visual sensemaking}.

To answer this question, we adopted an iterative design methodology, given the limited existing guidelines on designing spatial hybrid AR/VR systems~\cite{krauss2021current}, particularly in the context of visual sensemaking.
First, based on existing literature (\eg{},~\cite{lisle2020evaluating,hubenschmid2021towards,davidson2022exploring,tong2023towards}), we derived five design requirements: supporting a movable spatial hybrid system, designing optimized interfaces for both PC and VR, providing the same context in both interfaces, allowing non-transitional usage of PC and VR interfaces, and allowing easy-to-switch input modality and cross-device interaction.
\retvcg{Second, we designed a prototype to blend PC and VR interfaces using Augmented Virtuality~\cite{milgram1995augmented} (\Cref{fig:rv}).
As shown in \Cref{fig:teaser}, users can use a simulated PC rendered in a 3D room-sized space in VR. The simulated PC screen's position and rotation are controlled by a tracker placed on a wheeled table so that users can move the virtual screen by physically moving the table. Users can interact with the virtual screen using a mouse and keyboard, creating a similar experience to using a physical ``PC.''}{}
Moreover, the state of the graphs is shared between devices to support cross-device linking and brushing. Lastly, we used hand gestures as the major control for VR because it is easier for users to switch from mouse and keyboard to hand gestures than controllers. Third, we conducted a pilot study with 12 participants to iteratively improve the design and implementation of the spatial hybrid PC+VR system.


\retvcg{In this project, we aim to explore how our proposed spatial hybrid PC+VR system changes user analytics behavior and experience compared to using a single environment, thereby enriching the empirical understanding of spatial hybrid PC+VR systems, particularly in the context of visual sensemaking. 
To achieve this, we conducted a controlled user study with 18 participants, comparing the PC+VR system to two baseline conditions: PC-only and VR-only.}{}
Participants were asked to complete a sensemaking task derived from the literature~\cite{mahyar2014supporting,balakrishnan2008visualizations,tong2023towards,yang2024putting}, requiring them to build a node-link diagram from text documents to answer analytical questions.
We found that the spatial hybrid PC+VR system did not negatively impact task performance, even with the addition of an extra wheeled table compared to previous work~\cite{pavanatto2021we}. Furthermore, it was preferred and reduced physical demand compared to the VR-only system.
We further found four different patterns in both spatial and temporal analysis of users' usage patterns. These findings could provide insight into designing future spatial hybrid PC+VR systems for visual sensemaking.

In summary, our contributions are three-fold.
\textbf{First}, we compiled design requirements for spatial hybrid PC+VR systems for visual sensemaking. 
\textbf{Second}, we iteratively developed a spatial hybrid PC+VR prototype based on these design considerations. 
\textbf{Finally}, we conducted a \retvcg{}{controlled} user study to investigate our system's user experience and performance, which provides insight into future designs.




\begin{figure}
\centering
\includegraphics[width=\columnwidth]{figs/teaser_CHI24_2to1.png}
\caption{A demonstration of spatial hybrid systems for visual problem-solving: users can read documents and build a node-link diagram in VR. They interact with a digitally rendered flat screen on a physically movable table, using a mouse and keyboard to input text annotations. Notably, users do not need to put on and off the VR headset to switch between environments.}
\label{fig:teaser}
\end{figure}
