\section{User Study}
\label{sec:study}

\begin{figure}
\centering
\includegraphics[width=0.6\columnwidth]{figs/users.pdf}
\caption{The figure shows participants working in PC-only (a), VR-only (b), and PC+VR (hybrid) (c) conditions.}
\label{fig:setup}
\end{figure}

\begin{figure*}
\centering
\includegraphics[width=\linewidth]{figs/pattern2.pdf}
\caption{This figure shows two representative spatial patterns with an example of corresponding user trajectories (a-d). The black arc represents the position of the documents in VR. The black line indicates the final position and orientation of the PC when they complete the task. 1. Participants did not move the position of the PC and mainly used VR (a) or PC (b) and transitioned to the other when needed. 2. Others moved the position of the PC to the side and used both devices simultaneously with the simulated PC screen perpendicular (c) or parallel (d) to the documents (the black arc).}
\label{fig:patterns_prelimiary}
\end{figure*}

We conducted a\retvcg{}{controlled} user study to 1) \retvcg{investigate}{evaluate} the potential benefits in using a spatial hybrid system (PC+VR), comparing with a single device (PC-only and VR-only), and 2) explore different strategies and device usage patterns in hybrid setups for visual sensemaking. 
The study was approved by the Institutional Review Board \retvcg{(HREP-2024-0111)}{}.

\subsection{Task, Dataset, and Apparatus}
As introduced in \Cref{secc:task}, we tasked our participants with a visual sensemaking puzzle, where the participant needed to create a node-link diagram by extracting entities and relationships from documents to answer a set of questions.  
We used the Blue Iguanodon dataset~\cite{grinstein2007vast} from the VAST 2007 contest, with its difficulty at the graduate level~\cite{whiting2009vast}. 
We used the three subplots with different illegal activities (\ie{}, drug trafficking, wildlife smuggling, and bioterrorism) from previous work~\cite{tong2023towards}. 
To ensure the task was manageable, challenging, and similar to real scenarios, we provided six key documents and added two irrelevant or background documents for each subplot. Finally, we ensured each subplot contained the same amount of documents (\ie{}, eight) with similar total word counts (\ie{}, 1207, 1229, and 1180, respectively).

We used a Meta Quest Pro as the VR HMD and a Dell Alienware x15 R2 Gaming laptop equipped with an Intel i9-12900H CPU, 32GB RAM, an Nvidia GeForce RTX 3070 Ti graphic card, and a 15.6-inch 2560x1440 LCD monitor as the device for both the PC and the backend server.
The study took place in the space of approximately 3$\times$3~meters.

\subsection{Procedure}
The study consisted of four phases and lasted about 120 minutes. The sessions were audio recorded. After completing the whole study, a \$20 Amazon gift card was given as compensation.

\para{Introduction (avg. 5 minutes).} The introduction provided participants with the study's purpose, duration, and setup. We have asked for participants' consent with a consent form before proceeding further.

\para{Main Study and Training (avg. 105 minutes).} The main study phase involved each participant trying three conditions, as shown in \Cref{fig:setup}. 
We controlled the dataset's sequence, and the sequence of the conditions was counterbalanced using the balanced Latin Square method~\cite{bradley1958complete}. Before each condition, we presented a tutorial to participants to help them get familiar with the current condition's interface. Participants were asked to perform all features one by one, including the fact that the table could be moved during the PC+VR condition, and practice altogether to complete a training task.
The training task was designed to help participants understand the study procedure. It was the same as the main study but with a more straightforward dataset of only six documents (439 words in total).
A short interview was conducted to gather feedback on the system's pros and cons for each condition.

\para{Debriefing (avg. 10 minutes).} The debriefing phase involved presenting participants with a questionnaire to rank the conditions in different aspects. Participants' preferences, reasons, usage patterns, and strategies were then discussed in a follow-up semi-structured interview.


\subsection{Pilot Study}
To comprehend the intricacies of our initial design and identify areas that need improvement, we conducted a pilot study before the formal study to explore the initial user experience of our PC+VR system. 
We recruited 12 participants from the local university, including 9 majoring in computer science, 1 in mechanical engineering, 1 in environmental psychology, and 1 in civil engineering. All participants had experience using VR and had previously authored data visualizations before the pilot study.

\para{Key Findings.}
Though we received positive feedback about the PC+VR interface, three key points need improvement.

\vspace{1mm}\noindent\textit{Simulated PC is rarely moved.} With the spatial position logs of the participants and the simulated PC, we identified two patterns: either put the table on the side or stand stationary horizontally and vertically as shown in \Cref{fig:patterns_prelimiary}. The participants did not fully utilize the movement of the table to explore freely in VR. Though participants did not explain it during interviews, we expected that it was due to the heavy weight and large size of the movable table (see \Cref{fig:setup}).

\vspace{1mm}\noindent\textit{Text selection in VR is challenging.} 10/12 participants pointed out that using a long-range ray pointer to select text in VR was not accurate and precise enough. It largely affected the graph creation process during the study. 

\vspace{1mm}\noindent\textit{Readability of text in VR is poor, affecting the usage of simulated PC.} 5/12 participants were not satisfied with the simulated PC in PC+VR due to low resolution for text as well as its interaction latency. 

\begin{figure}
\centering
\includegraphics[width=\columnwidth]{figs/close_interaction.png}
\caption{This figure demonstrates two techniques for text selection implemented in the VR-only and PC+VR systems: (a) standard text selection with ray pointer and (b-c) two-handed direct touch. (d) demonstrate two-handed direct touch text selection in VR.}
\label{fig:close_interaction}
\end{figure}

\begin{figure}
\centering
\includegraphics[width=0.6\columnwidth]{figs/desk.pdf}
\caption{Tables used in the pilot (left) and formal (right) studies.}
\label{fig:setup_new}
\end{figure}

\para{Improvements on PC+VR and VR.}
Based on these key findings, we made three corresponding improvements.

\vspace{1mm}\noindent\textit{Using a lighter and smaller movable table.}
To address the transportability issue due to the use of the heavy and large movable table, we decided to use a smaller and lighter wheeled height-adjustable table instead, as illustrated in~\Cref{fig:setup_new}. 
By using a more lighter and smaller table, participants could easily move the table with them in the space, enabling them to switch between environments anytime and anywhere.

\vspace{1mm}\noindent\textit{Introducing close interaction for text selection in VR.}
Performing long-range pointer interactions in VR (\Cref{fig:close_interaction}(a)) can be physically exhausting and suffer from precision, as reflected in our pilot study.
To provide users with an alternative method of selecting the text, we have adapted the two-handed and close-hand interaction approach of Voodoo Dolls~\cite{pierce1999voodoo}. With this approach, users can pinch to select a document using their left hand (\Cref{fig:close_interaction}(b)). 
A smaller version of the document view will then be duplicated and mirrored onto their hand, simulating the experience of picking up a piece of paper. Users can then use their right-hand index fingertips to touch and drag over the text they want to select on the duplicated document (\Cref{fig:close_interaction}(c)). 
We also added a light source to the index fingertip to provide a visual cue for enhanced depth perception (\Cref{fig:close_interaction}(d)).

\vspace{1mm}\noindent\textit{Improving the rendering of text and simulated PC display in VR.} 
To ensure sharper text and a clearer simulated PC screen display, we applied WebXR layers\footnote{\url{https://www.w3.org/TR/webxrlayers-1/}} to render the text and the real-time display of the simulated PC for both the VR and PC+VR prototypes.
Using WebXR layers can improve performance by significantly reducing the rendering rate of static text, as well as increasing the image quality by direct rendering to the final buffer without double sampling and distortions. 
The original simulated PC was sized around 85'' with 4K resolution to accommodate text legibility in the pilot study, and participants complained that it was bulky and created unnecessary occlusions. Thanks to the enhanced graphic rendering, we were able to provide a smaller simulated PC screen, now at 32'' with 1440p resolution \retvcg{(0.045 visual angle per pixel\footnote{\retvcg{Calculated with 1m eye-to-screen distance. The visual angle per pixel of the actual 32'' 1440p monitor is 0.015. The lower the better. The detailed calculations can be found in the supplementary material.}{}})}{}. This enhancement reduces the overlap between the simulated PC and the VR content and minimizes interaction latency while ensuring text clarity.

\subsection{Participants}

\re{In terms of the participants in the main user study, we tried to strike a balance between the participants' diversity and the required expertise. We recruited users with different backgrounds and excluded those who had no experience in data visualization or VR to reduce the learning effect.}{} Finally, we recruited 18 participants
 who had not joined the pilot user study.
There were ten males and eight females, with a mean age of 25.6 (SD = 3.73). All participants were graduate students from different majors: computer science (12), linguistics (1), material (1), art (1), bioinformatics (1), construction management (1), and physics (1). 
\re{The distribution of experience in using VR was within one year (12), 1-2 years (2), and more than two years (4). 
The distribution of experience in using data visualization was within one year (8), 1-2 years (5), and more than two years (5).}{}


\subsection{\retvcg{Exploratory Hypotheses}{Hypotheses}}
\retvcg{Our overarching goal is to explore the differences in user behaviors and experiences between using a hybrid system and a single environment. To systematically guide our exploration, we developed several representative hypotheses based on previous empirical results, our pilot study, and the design of our conditions (see \Cref{sec:pc_vr_design}). These exploratory hypotheses serve as a structured starting point for focused observation and discussion, rather than for performance comparisons.}{}


\para{Accuracy (\textit{H\textsubscript{acc}}).} \label{hypo:acc} We did not expect any difference in accuracy as the same functionalities were consistently provided in all testing conditions.

\para{Time (\textit{H\textsubscript{tim}}).} \label{hypo:tim} We expected PC-only to outperform VR-only and PC+VR based on previous studies, which found desktop interactions faster than VR interactions due to less required movement~\cite{bach2017hologram,chen2012effects,wagner2018immersive,arms1999benefits}. Compared to VR-only, PC+VR can partially benefit from faster desktop interactions, especially for precise interactions like selecting the text, but the extra context-switching may introduce more time costs.

\para{User Experience (\textit{H\textsubscript{exp}}).} \label{hypo:exp} We believed PC+VR could have less task load than PC-only and VR-only, as participants had the choice to choose the optimal device for the given task components.
However, PC+VR may introduce distraction when switching between devices, influencing concentration.

\para{Number of Interactions (\textit{H\textsubscript{int}}).} \label{hypo:int} Our task is interaction-intensive, which requires foraging and structuring information. We anticipated VR-only and PC+VR would require fewer interactions than PC-only, based on previous investigations~\cite{lisle2020evaluating,in2023table}, possibly due to the unlimited display space in VR requiring fewer navigations. 
Between VR-only and PC+VR, the advantage of performing precise interactions using the PC in PC+VR can lower the required number of interactions.
 

\para{User Preference (\textit{H\textsubscript{pre}}).} \label{hypo:pre} We considered that participants would mostly prefer PC+VR over PC-only and VR-only due to the existing limitations of a single computing environment.

\subsection{Measures}
We collected data from the formal study with the enhanced version of the spatial hybrid system.
We recorded the \textit{time} taken to complete each task, task \textit{accuracy}, and the \textit{number of interactions} performed to complete the task.
In terms of interactions, we considered all graph-related interactions, including adding, removing, and updating nodes/links, as well as merging nodes.
We used the \textit{NASA TLX task load}~\cite{sandra2006nasatlx} and adapted \textit{concentration}~\cite{novak2000measuring} questionnaires to collect subjective ratings of participants' user experience.
We also asked participants to \textit{rank} the three conditions based on their preference for four different task components: \textit{authoring}, \textit{exploring}, \textit{discovering}, and \textit{interaction}, as well as their \textit{overall} preference at the end of the study. 
Qualitative feedback from the debriefing interviews was used as evidence to explain task efficiency, ratings on user experience, and preference.
We logged users' spatial movements in the space to contribute insights and empirical understanding about how people use PC+VR hybrid interfaces.
Moreover, we also tracked the HMDâ€™s head gaze data to detect the objects users are currently looking at in VR.
