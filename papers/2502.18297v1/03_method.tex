\section{Dataset} \label{Sec:Dataset}
\subsection{Data Preparation}

To maximize the utility of our dataset and enable training and evaluation for LLMs, it is essential to clearly distinguish between chip-level, IP-level, and module-level RTL designs. The repositories of different levels differ in abstraction, scope, and their roles in hardware design automation. 
In detail, chip-level design encompasses the entire System-on-Chip (SoC) and processors, focusing on system-wide integration, interconnects, and global constraints like power, timing, and area. 
IP-level design addresses modular and reusable components, such as cores or memory controllers , with a focus on standalone functionality and scalability. 
Module-level design targets subcomponents within IPs, such as arithmetic units or fundamental operators, emphasizing detailed functionality and local optimization. These levels differ in scope, with chip-level representing the holistic system, IP-level the building blocks, and module-level the internal details, enabling hierarchical abstraction and efficient hardware design.


Our dataset distinguishes itself by focusing on chip-level, IP-level, module-level RTL designs. We collect a list of 222 keywords representing these levels from sources like Alldatasheet~\cite{alldatasheet} and other relevant websites. Examples include chip-level designs such as voice processors, audio processors, and video processors; IP-level designs like DMA, PCI, and true random number generators; and module-level designs including 4-bit binary full adders, arithmetic logic units, and multiplier-accumulators. We collect over 4,000 repository-level RTL projects, which encompass 140,000 RTL files across 77 functional categories, as shown in Table \ref{tab:dataset_levels}. Moreover, the detailed data cases are illustrated in Figure \ref{fig:overview_data}. 

To construct the RTL-language dataset, we organize the data into four distinct levels: repository, file, module, and block. We employ a Chain of Thought (CoT) approach for RTL code annotation, leveraging GPT-4~\cite{achiam2023gpt} and Claude~\cite{claude} to generate detailed comments, descriptions, and question-answer pairs. This methodology enhances the training data for large language models (LLMs) in RTL code understanding and generation, with further details provided in Section \ref{sec:RTL_annotation}. Additionally, to develop the multimodal dataset, we synthesize the RTL projects to obtain netlists, power, performance, and area (PPA) metrics, as well as layout designs. Further details will be discussed in Section \ref{sec:RTL_Repo_synthesize}.




\begin{table}[ht]
\centering
\caption{Summary of data across different levels in DeepCircuitX. The table presents the number of function categories, repositories, and RTL files at the Chip, IP, Module designs.}
\vspace{1em}
\resizebox{\linewidth}{!}{
\begin{tabular}{l|ccc}
\toprule

\textbf{Level} & \textbf{Function Categories} & \textbf{Repo Number} & \textbf{RTL File Number} \\ \midrule
Chip Level     & 17   & 1002   & 54650  \\
IP Level       & 3    & 1410  & 92467 \\ 
Module Level   & 57   & 2383  & 38692  \\  \bottomrule
\end{tabular}}
% \caption{Summary of data across different levels}

\label{tab:dataset_levels}
\end{table}



\subsection{Language-RTL Code Dataset Construction}
\label{sec:RTL_annotation}
\subsubsection{Chain of Thought (CoT) for RTL Code Annotation}
The Chain of Thought (CoT) reasoning method, commonly used in deep learning and natural language processing, simulates human reasoning by guiding models through structured steps. We adopt this approach to create detailed annotations for Verilog code, ensuring a comprehensive understanding at different levels of the RTL design. The annotation process is carried out at three distinct levels: \textbf{\textit{module-level}}, \textbf{\textit{block-level}}, and \textbf{\textit{repository-level}}. 
% The detailed pipeline is shown in Figure \ref{fig:cot} in the Appendix.


% Chain of Thought (CoT) is a reasoning method that has been widely applied in deep learning and natural language processing in recent years, aiming to simulate the process of human thought by gradually guiding the reasoning steps. To generate accurate descriptions for Verilog code, we apply the CoT approach to create annotations. The detailed pipeline is illustrated in Figure \ref{fig:cot}.
\paragraph{Module-Level Annotations} To annotate RTL modules, we utilize a multi-round question-answering approach to extract key information from the Verilog code, focusing on aspects such as the module's name, input/output ports, and internal signals. This process begins with structured questions designed to clarify both what the module does (What) and how it achieves this functionality (How). The responses provide the foundational details about the module's components and behavior. Using this information, a detailed specification is created that summarizes the module’s name, its purpose, the roles of the input and output ports, and an explanation of the internal signals. Additionally, the specification includes a breakdown of the functional blocks within the module. Finally, with this specification and the original code, ChatGPT generates a concise yet comprehensive module-level annotation, encapsulating both the functionality and the implementation details.


% \textbf{Module-Level Annotations}

% For module-level annotations, we implement a multi-round question-answering approach to extract detailed information from the original Verilog code. The final output includes both module-level and block-level annotations, describing what the module does (What) and how it is implemented (How). 
%Each round focuses on different aspects of the code:

% \textbf{Round 1:}
% \begin{itemize}
%     \item What is the name of the module in the code?
%     \item Provide a brief explanation of the module’s functionality.
% \end{itemize}

% \textbf{Round 2:}
% \begin{itemize}
%     \item What are the input and output ports of the module?
%     \item Provide a simple explanation of each input and output port, and their respective roles within the module.
% \end{itemize}

% \textbf{Round 3:}
% \begin{itemize}
%     \item What are the internal signals used in the module?
%     \item Provide a brief explanation of each internal signal and its role in the module.
% \end{itemize}

% Based on the responses from these rounds, we gather details about the module name, input and output ports, and internal signals. Next, we combine this information with the original code and further queried ChatGPT to generate a detailed specification of the module.

%which includes:
% \begin{enumerate}
%     \item The name of the module.
%     \item A concise explanation of the module's functionality.
%     \item The input and output ports, along with explanations of their roles.
%     \item The internal signals used within the module, with descriptions of their purposes.
%     \item An overview of the various blocks or sections in the code and their functions.
% \end{enumerate}

% Finally, using this detailed specification and the original code, ChatGPT is prompted again to generate a concise yet detailed module-level annotation.
\paragraph{Block-Level Annotations} Block-level annotations offer detailed insights into the functionality of specific sections within an RTL module. Given the complexity of Verilog code, which often includes nested structures, segmenting it using regular expressions alone can be challenging. To address this, we leverage GPT-4 for handling these intricacies. The code is divided into distinct functional blocks, including constructs such as \texttt{always}, \texttt{initial}, \texttt{task}, \texttt{function}, \texttt{generate}, \texttt{assign}, and \texttt{final} blocks. While regular expressions are employed to improve segmentation accuracy for straightforward patterns, GPT-4 is crucial for managing more complex structures. Once the blocks are identified, each is annotated to describe both its purpose and how it functions, ensuring that the role of each block within the module is clearly defined, thereby enhancing the overall understanding of the module's functionality.

% \textbf{Block-Level Annotations}

% For block-level annotations, since regular expressions are only suitable for simple pattern matching and not well-suited for handling complex nested structures such as parentheses and begin-end pairs within blocks, as well as distinguishing syntactic structures in Verilog code based on tabs or indentation (e.g., missing begin-end pairs signaling the start and end of an always block), we opt to use GPT-4 to segment the code into multiple functional blocks. However, we found that providing simple regular expression input to ChatGPT can improve its segmentation accuracy. % The types of blocks identified are as follows:
% \begin{itemize}
%     \item \textbf{always block}: Starts with "always @", usually matched by the expression \verb|^\s*always\s*@\s*\(.*?\)\s*begin[\s\S]*?end\s*$|
%     \item \textbf{initial block}: Starts with "initial", typically extracted using \verb|^\s*initial\s+begin\b.*?end\s*;$|
%     \item \textbf{task block}: Starts with "task", often captured through \verb|^\s*task\s+\w+\b.*?endtask\s*;$|
%     \item \textbf{function block}: Starts with "function", extracted via \verb|^\s*function\s+\w+\b.*?endfunction\s*;$|
%     \item \textbf{generate block}: Starts with "generate", matched with \verb|^\s*generate\b.*?endgenerate\s*;$|
%     \item \textbf{final block}: Starts with "final", extracted using \verb|^\s*final\s+begin\b.*?end\s*;$|
%     \item \textbf{assign block}: Starts with "assign", typically matched by \verb|^\s*assign\b.*?;$|
% \end{itemize}

% After segmenting the code into these blocks, we generate annotations for each block. These annotations describe both what the block does (What) and how it achieves its functionality (How), forming the block-level annotations.


% \textbf{Repo-Level Annotations} 

% We gather the file structure information within both the repository-level and the corresponding module-level annotations to form a holistic view of the project. Repo-level annotations provide an overarching description of the entire repository, capturing the purpose and structure of the design as a whole. These annotations help in understanding how individual files and modules fit together within the context of the larger design.
% We utilize GPT-4 to summarize the repo-level information by analyzing the contents of all files within the repository. 
% By leveraging GPT-4's ability to comprehend and summarize large amounts of information, we create a comprehensive repo-level annotation that provides a top-down understanding of the repository. This annotation serves as a bridge between the detailed file and module-level descriptions and the broader goals of the RTL project. Furthermore, this method ensures that the annotations reflect not only the functional details of individual modules but also the strategic design choices made at the system level.
\paragraph{Repo-Level Annotations} At the repository level, we aim to provide an overarching understanding of the entire RTL project. This includes information about the structure, purpose, and interconnections of various modules and files within the repository. To achieve this, we gather the file structure information and combine it with module-level annotations to form a complete picture of the project. GPT-4 is then used to summarize the contents of the repository, producing a top-down view of how individual files and modules work together. This approach allows the repo-level annotation to reflect both functional and design-level details, capturing the broader goals of the RTL project.

% \begin{figure}[!tb]
%     \centering
%     \includegraphics[width=\linewidth]{fig/iclr_Dataset_cot.pdf}
%     \caption{Detailed procedures in our proposed method: CoT code-annotation.}
%     \label{fig:cot}
% \end{figure}


\begin{table}[ht]
\centering
\caption{Summary of annotated RTL categories at the module, block, and repository levels in DeepCircuitX. The table highlights the number of annotated modules, blocks, and repositories for each RTL category, including Chip, IP, and Module.}
\vspace{1em}
\begin{tabular}{l|ccc}
\toprule
\textbf{RTL categories} & \textbf{Module-Level} & \textbf{Block-Level } & \textbf{Repo-Level }  \\ \midrule
Chip  & 7587    & 36955    & 684       \\
IP  & 12863    & 20101    & 183       \\ 
Module  & 28901    & -    & 1389       \\ \bottomrule
\end{tabular}
% \caption{Summary of annotations across different levels}


\label{tab:dataset_repo_levels}
\end{table}

\subsubsection{Dataset for RTL Code Understanding, Completion and Generation}


In addition to annotations, we constructed a dataset that supports three distinct tasks related to RTL code: \textbf{\textit{understanding}}, \textbf{\textit{completion}}, and \textbf{\textit{generation}}. Table \ref{tab:tasks_categories} shows the data counts across RTL categories (IP, Module, and Chip) for each task.


\begin{table}[htbp]
    \centering
    \caption{Data counts for code generation, code completion, and comment generation tasks across different categories.}
    \vspace{1em}
    \begin{tabular}{l|rrrrr}
        \toprule
        \textbf{Tasks Dataset} & \textbf{IP} & \textbf{Module}  & \textbf{Chip} & \textbf{All} \\
        \midrule
        RTL Understanding & 6386 & 14499 & 5270 & 26155 \\
        RTL Completion & 6178 & 14131 & 5134 & 25443 \\
        RTL Generation & 6479 & 16511 &  5343 & 28333 \\
        \bottomrule
    \end{tabular}

    \label{tab:tasks_categories}
\end{table}

\begin{figure}[ht]
    \centering
    \includegraphics[width=\linewidth]{fig/overview_data.pdf}
    \caption{Illustration of the dataset repository structure with multi-level annotations}
    \label{fig:overview_data}
\end{figure}


% \textbf{RTL Code Understanding} 

% In the RTL code understanding task, the goal is to evaluate the model's ability to comprehend and generate a meaningful description of a given RTL code. In this task, we provide the RTL code as input, and the target output is a detailed, concise description of the functionality and structure of the code. The description includes information about the module’s purpose, its input/output signals, internal logic, and the overall behavior. This task helps assess how well models can interpret RTL code and produce human-readable explanations, which is critical for documentation and code analysis purposes.
\paragraph{RTL Code Understanding} This task evaluates the model’s ability to interpret and describe RTL code. Given a module’s RTL code as input, the model generates a detailed, concise description, covering key aspects such as the module’s purpose, input/output signals, internal logic, and overall behavior. This task is crucial for assessing the model’s ability to generate human-readable explanations for code analysis and documentation.


% \textbf{RTL Code Completion} 

% The RTL code completion task focuses on the model’s ability to generate the missing parts of RTL code based on a partial input. We provide a description of the code, along with the module header, which includes the input/output ports or some parameters. The target is for the model to complete the rest of the code, implementing the internal logic, control structures, and signal definitions. This task evaluates the model’s capability to infer and generate the missing code based on context, similar to autocompletion in text editors, and is useful for enhancing productivity in RTL design.
\paragraph{RTL Code Completion} In this task, the model is provided with a partial RTL code (typically the module header with input/output ports and parameters). The goal is for the model to complete the code by generating the missing internal logic, control structures, and signal definitions. This task mirrors autocompletion functionality found in modern code editors and evaluates the model’s ability to infer and generate code from context.


% \textbf{RTL Code Generation} 

% In the RTL code generation task, the model is tasked with generating a complete implementation of RTL code based on a given description and specific details about the I/O and parameters. The description provides a high-level overview of the module’s intended functionality, while additional information, such as the input/output ports and their configurations, guides the code generation process. The goal is to produce a fully functional Verilog module that adheres to the provided specifications. This task evaluates the model’s ability to transform high-level design requirements into a precise RTL implementation, which is essential for automating the hardware design process.
\paragraph{RTL Code Generation} 
In the RTL code generation task, the model is tasked with producing a full implementation of RTL code based on a high-level description and specified input and output parameters. The goal is to generate a fully functional Verilog module that adheres to the provided specifications. This task assesses the model’s ability to translate design requirements into precise RTL implementations, which is critical for automating the hardware design process.




\subsection{Multimodal Transformation of RTL Code}
\subsubsection{Graph-based Code Representation}
Abstract Syntax Tree (AST) serves as a tree-based representation to model the structure of programming code, extensively used in syntax analysis and compilation. In the context of Verilog code, each node within the AST denotes a variable or operator, and the edges formulate the relations between these nodes. Additionally, Control/Data Flow Graph (CDFG)~\cite{orailoglu1986flow} is a another graph-based code representation to visualize how data moves between registers and how control signals dictate the operation of the design. CDFG proves advantages for modeling and verifying the functionality of RTL designs~\cite{coussy2009introduction, vasudevan2021learning}. We generate the AST and CDFG of RTL designs with open-source tools Yosys~\cite{wolf2016yosys} and customized Pyverilog~\cite{takamaeda2015pyverilog}. 


\subsubsection{Circuit Netlist Synthesis}
\label{sec:RTL_Repo_synthesize}
Our dataset contains RTL repositories with module invocations and complete Verilog files, enabling us to derive the circuit netlists via logic synthesis process. For each RTL repository, we employ the commerical tool Synopsys Design Compiler 2019.12 to transform HDL code into netlists. The RTL designs are mapped into several open-source technology libraries, including GlobalFoundries 180nm, skywater 130nm, ihp-sg 130nm, nangate 45nm and asap 7nm. Each RTL file is synthesized using both the compile and \textit{compile\_ultra} commands. By toggling the set max area 0 option, we obtain both the default netlist and a netlist optimized for maximum area constraints. We assess the internal, transition, and leakage power of each mapped netlist using PrimeTime (Synopsys, 2023.12). The critical path delay is reported by the Design Compiler. 

Finally, we store the post-mapping netlist into both verilog format (.v files) and Standard Delay Format (SDF)~\cite{sagdeo1998standard} (.sdf files). Moreover, we record the logic synthesis reports (.rpt files) with maximum path delay, area and dynamic power for the following experiments. We also convert the post-mapping netlist into And-Inverter Graph (AIG) format, a prevalent and widely-adopted  common format for netlist learning~\cite{li2022deepgate, shi2023deepgate2, shi2024deepgate3, deng2024less}, using abc~\cite{brayton2010abc} tool for further investigation. The multi-modal data cases are illustrated in Figure \ref{fig:multimodal}.

\begin{figure}
    \centering
    \includegraphics[width=\linewidth]{fig/syn_dataset.pdf}
    \caption{Illustration of the dataset repository structure with Circuit Transformation}
    \label{fig:multimodal}
\end{figure}



% In integrated circuit design, post mapping netlist is a crucial component of the design process. It serves as a guideline for subsequent stages such as placement and routing, simulation, and verification. Post mapping netlist is derived from the RTL code through the process of logic synthesis. In this netlist, the high-level HDL code is transformed into a gate-level netlist. We leverage Design Compiler (Synopsys, 2019.12) for synthesis flow. ASIC mapping process requires a technology library to determine the information in the post mapping netlist, inculding minimum cell information, wire load models, operating conditions and design constraints. We use five open-source technology libraries: GlobalFoundries 180nm, skywater 130nm, ihp-sg 130nm, nangate 45nm and asap 7nm.  Each RTL file issynthesized using both the compile and \textit{compile\_ultra} commands. By toggling the set max area 0 option, we obtain both the default netlist and a netlist optimized for maximum area constraints. We assess the internal, transition, and leakage power of each mapped netlist using PrimeTime (Synopsys, 2023.12). The critical path delay is reported by the Design Compiler. Additionally, our dataset incorporates SDF files and topological relationships to derive the maximum delay from each node to the primary inputs.



%
%\begin{figure}[!t]
%\centering
%\includegraphics[width=2.5in]{myfigure}
% where an .eps filename suffix will be assumed under latex, 
% and a .pdf suffix will be assumed for pdflatex; or what has been declared
% via \DeclareGraphicsExtensions.
%\caption{Simulation results for the network.}
%\label{fig_sim}
%\end{figure}

% Note that the IEEE typically puts floats only at the top, even when this
% results in a large percentage of a column being occupied by floats.


% An example of a double column floating figure using two subfigures.
% (The subfig.sty package must be loaded for this to work.)
% The subfigure \label commands are set within each subfloat command,
% and the \label for the overall figure must come after \caption.
% \hfil is used as a separator to get equal spacing.
% Watch out that the combined width of all the subfigures on a 
% line do not exceed the text width or a line break will occur.
%
%\begin{figure*}[!t]
%\centering
%\subfloat[Case I]{\includegraphics[width=2.5in]{box}%
%\label{fig_first_case}}
%\hfil
%\subfloat[Case II]{\includegraphics[width=2.5in]{box}%
%\label{fig_second_case}}
%\caption{Simulation results for the network.}
%\label{fig_sim}
%\end{figure*}
%
% Note that often IEEE papers with subfigures do not employ subfigure
% captions (using the optional argument to \subfloat[]), but instead will
% reference/describe all of them (a), (b), etc., within the main caption.
% Be aware that for subfig.sty to generate the (a), (b), etc., subfigure
% labels, the optional argument to \subfloat must be present. If a
% subcaption is not desired, just leave its contents blank,
% e.g., \subfloat[].


% An example of a floating table. Note that, for IEEE style tables, the
% \caption command should come BEFORE the table and, given that table
% captions serve much like titles, are usually capitalized except for words
% such as a, an, and, as, at, but, by, for, in, nor, of, on, or, the, to
% and up, which are usually not capitalized unless they are the first or
% last word of the caption. Table text will default to \footnotesize as
% the IEEE normally uses this smaller font for tables.
% The \label must come after \caption as always.
%
%\begin{table}[!t]
%% increase table row spacing, adjust to taste
%\renewcommand{\arraystretch}{1.3}
% if using array.sty, it might be a good idea to tweak the value of
% \extrarowheight as needed to properly center the text within the cells
%\caption{An Example of a Table}
%\label{table_example}
%\centering
%% Some packages, such as MDW tools, offer better commands for making tables
%% than the plain LaTeX2e tabular which is used here.
%\begin{tabular}{|c||c|}
%\hline
%One & Two\\
%\hline
%Three & Four\\
%\hline
%\end{tabular}
%\end{table}


% Note that the IEEE does not put floats in the very first column
% - or typically anywhere on the first page for that matter. Also,
% in-text middle ("here") positioning is typically not used, but it
% is allowed and encouraged for Computer Society conferences (but
% not Computer Society journals). Most IEEE journals/conferences use
% top floats exclusively. 
% Note that, LaTeX2e, unlike IEEE journals/conferences, places
% footnotes above bottom floats. This can be corrected via the
% \fnbelowfloat command of the stfloats package.
