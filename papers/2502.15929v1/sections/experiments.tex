\section{Experiments}
\label{sec:experiments}
This section discusses experiments evaluating the tightness of our privacy analysis (\Cref{subsec:experiments_privacy}) as well as the $\ell_2$  mechanism's error (\Cref{subsec:experiments_error}) and speed (\Cref{subsec:experiments_speed}). All experiments use the $\ell_2$ mechanism with $n_r = n_R =1000$. Experiment code may be found \narxiv{in the Supplement}\arxiv{on Github~\cite{G25}}.

\subsection{Privacy}
\label{subsec:experiments_privacy}
Our first experiments attempt to measure the tightness of our privacy analysis. To do so, we compare two methods for estimating $\P{}{\ell_{M,X,X'} \geq \eps} - e^\eps \P{}{\ell_{M,X',X}  \leq -\eps}$, the quantity that must be upper bounded by $\delta$ for $M$ to satisfy $(\eps, \delta)$-DP (\Cref{lem:approx_dp}).

We fix $\eps = 1$, $\delta = 0.01$, and vary $d = 1, 2, \ldots, 100$. At each $d$, the first method empirically estimates the smallest $\sigma$ such that  \begin{equation}
\label{eq:empirical_privacy}
    \P{}{\ell_{M,X,X'} \geq 1} - e \cdot \P{}{\ell_{M,X',X}  \leq -1} \leq \delta,
\end{equation}
where $M$ is the $\ell_2$ mechanism with parameter $\sigma$, and $M(X)$ is centered at 0 while $M(X')$ is centered at 1. By the analysis of \Cref{sec:l2}, \Cref{eq:empirical_privacy} is equivalent to
\arxiv{\begin{equation*}
    \P{y \sim M(0)}{\frac{1}{\sigma}(\|e_1-y\|_2 - \|y\|_2) \geq \eps} - e \cdot \P{y \sim M(1)}{\frac{1}{\sigma}(\|e_1-y\|_2 - \|y\|_2) \geq \eps} \leq \delta.
\end{equation*}}
\narxiv{\begin{align*}
    &\P{y \sim M(0)}{\frac{1}{\sigma}(\|e_1-y\|_2 - \|y\|_2) \geq \eps} \\
    -&\ e \cdot \P{y \sim M(1)}{\frac{1}{\sigma}(\|e_1-y\|_2 - \|y\|_2) \geq \eps} \leq \delta.
\end{align*}}
We can estimate the value of this expression by drawing $n$ samples from $M(0)$ and $n$ samples from $M(1)$, counting the fraction $c_1$ satisfying the first inequality and the fraction $c_2$ satisfying the second inequality, and then computing $c_1 - e \cdot c_2$. Binary searching over $\sigma$ to find the smallest value where this computation is upper bounded by $\delta$ leads to an empirical estimate of the minimum $\sigma$ yielding a $(1, 0.01)$-DP $\ell_2$ mechanism.

The second method computes its $\sigma$ using the analysis of \Cref{sec:l2}. As shown in \Cref{fig:empirical_privacy}, our algorithm closely tracks the empirical values. This provides empirical evidence that the resulting privacy analysis is both sound and (with the chosen $n_r = n_R = 1000$ and range for $d$) tight.

\begin{figure}[H]
        \centering
        \includegraphics[scale=0.55]{images/empirical_privacy.pdf}
        \caption{A comparison of empirical (dotted) and algorithmic (solid) estimates of privacy loss. At each $d$,  the empirical method uses $n = 1000 / \delta = 10^5$ samples.}
        \label{fig:empirical_privacy}
\end{figure}

\subsection{Error}
\label{subsec:experiments_error}
We first derive some basic results about the mean squared $\ell_2$ error of the Laplace, $\ell_2$, and Gaussian mechanisms used in our experiments. The Laplace and $\ell_2$ results are corollaries of the following lemma. The lemma is an extension of a previous result about the mean squared $\ell_2$ norm of a sample from an $\ell_p$ ball~\cite{JRY25} and is proved in \Cref{subsec:appendix_experiments}.

\begin{restatable}{lemma}{expectedKNorm}
\label{lem:expected_k_norm}
    The mean squared $\ell_2$ error of the $d$-dimensional $\ell_p$ mechanism with parameter $\sigma$ is
    \begin{equation*}
        (d\sigma)^2(d+1)\left(\frac{\Gamma(\frac{d}{p}) \Gamma(\frac{3}{p})}{\Gamma(\frac{1}{p}) \Gamma(\frac{d+2}{p})}\right).
    \end{equation*}
\end{restatable}

Since a $d$-dimensional statistic with $\ell_2$ sensitivity 1 has $\ell_1$ sensitivity $\sqrt{d}$, substituting $p=1$ and parameter $\sigma\sqrt{d}$ into \Cref{lem:expected_k_norm} yields the following result for the Laplace mechanism.

\begin{corollary}
    The Laplace mechanism with parameter $\sigma\sqrt{d}$ has mean squared $\ell_2$ error $2d^2\sigma^2$.
\end{corollary}

The $\ell_2$ mechanism uses $p=2$ and parameter $\sigma$.

\begin{corollary}
    The $\ell_2$ mechanism with parameter $\sigma$ has mean squared $\ell_2$ error $d(d+1)\sigma^2$.
\end{corollary}

A similar result for the Gaussian mechanism is easy to prove directly (see \Cref{subsec:appendix_experiments} for proof).

\begin{restatable}{lemma}{gaussianExpectedSquaredNorm}
    The Gaussian mechanism with parameter $\sigma$ has mean squared $\ell_2$ error $d\sigma^2$.
\end{restatable}

For a range of $d$, we solve for the smallest possible $\sigma$ for each mechanism to achieve $(\eps, \delta)$-DP and plot the mean squared $\ell_2$ error according to the preceding results. The Laplace mechanism uses $\sigma = \sqrt{d}/(\eps+\delta)$\footnote{Note that the smallest possible $\sigma$ for which the Laplace mechanism is $(\eps, \delta)$-DP is provably negligibly smaller than the one used here. See \Cref{subsec:appendix_experiments} for details.}, the Gaussian mechanism binary searches over $\sigma$ as described by~\citet{BW18}, and the $\ell_2$ mechanism binary searches over $\sigma$ using the algorithms from \Cref{sec:l2}. Throughout, binary searches use tolerance $0.001$ and we use $(1,10^{-5})$-DP.

This produces the left plot in \Cref{fig:intro} in the introduction. The Laplace mechanism obtains lower error than the analytic Gaussian mechanism for small $d$, the analytic Gaussian mechanism obtains lower error than the Laplace mechanism for larger $d$, and the $\ell_2$ mechanism dominates both. The gap between the $\ell_2$ mechanism and the better of the Laplace mechanism and analytic Gaussian mechanism is 0 at $d=1$ (when the Laplace and $\ell_2$ mechanism are identical) and peaks at $50\%$ at $d=7$ before gradually shrinking, to $5\%$ at $d=100$ and $<1\%$ at $d = 500$ (not pictured).

Analogous plots for a high-privacy regime of $(0.1, 10^{-7})$-DP and a low-privacy regime of $(10, 10^{-3})$-DP are essentially the same.

\subsection{Speed}
\label{subsec:experiments_speed}
The last set of experiments evaluates the speed of the $\ell_2$ mechanism, as executed on a typical personal computer. This runtime is split into two operations: the time to compute $\sigma$ and the time to sample the mechanism.\arxiv{ Results for both experiments appear in \Cref{fig:time}.}

The largest gap appears in the time to compute $\sigma$ \narxiv{(\Cref{fig:sigma_time})}\arxiv{(left plot)}. The Laplace computation is $\approx 100$x faster than the Gaussian computation, which is $\approx 100$x faster than the $\ell_2$ computation. This may be expected, as the Laplace computation is a single arithmetic expression, the Gaussian computation is a binary search over the standard normal CDF, and the $\ell_2$ computation is a binary search where each evaluation iterates over $n_r + n_R = 2000$ radii. Nonetheless, we note that the $\ell_2$ computation still runs in $\approx 0.1$ seconds, this time does not increase with $d$, and the calculation only needs to be performed once for each setting of $(\eps, \delta, d)$.

\narxiv{\begin{figure}[h]
        \centering
        \includegraphics[scale=0.5]{images/sigma_times.pdf}
        \caption{A plot of time in seconds to compute the minimum $\sigma$ to achieve $(1, 10^{-5})$-DP. The $\ell_2$ mechanism line jumps after $d=1$ because that case uses \Cref{lem:one_dim} instead of approximating the spherical cap region.}
        \label{fig:sigma_time}
\end{figure}}

The time to draw 1000 mechanism samples is less varied \narxiv{(\Cref{fig:sample_time})}\arxiv{(right plot)}. The $\ell_2$ mechanism is again slowest, but it is within a factor of two of the other mechanisms, and no mechanism takes more than $\approx 0.01$ seconds.

\narxiv{\begin{figure}[h]
        \centering
        \includegraphics[scale=0.5]{images/sample_times.pdf}
        \caption{This plot uses the same setup as \Cref{fig:sigma_time} but records sampling time.}
        \label{fig:sample_time}
\end{figure}}

\arxiv{\begin{figure*}[h]
        \centering
        \includegraphics[scale=0.55]{images/sigma_times.pdf}
        \includegraphics[scale=0.55]{images/sample_times.pdf}
        \caption{\textbf{Left}: a plot of mean time to compute the minimum $\sigma$ to achieve $(1, 10^{-5})$-DP for the $\ell_2$ (solid purple) and analytic Gaussian mechanism (dotted black) mechanisms. Time is measured in seconds, across 100 trials for each $d$. Note that the analytic Gaussian mechanism computation is dimension-independent, so the time is constant; the $\ell_2$ mechanism jumps after $d=1$ because that case uses \Cref{lem:large_sigma} instead of approximating the spherical cap region. \textbf{Right}: a similar plot for drawing 1000 samples from the mechanism.}
        \label{fig:time}
\end{figure*}}