% \section{Conclusion and Future Work}\label{sec:UQ_BENCH_conclusion}

% We develop \textsf{UQBench}, a comprehensive benchmarking framework that
% evaluates the performance of SOTA UQ agents under a carefully designed    framework considering distribution shifts and dynamic acquisition of data, advancing SOTA benchmarks for UQ evaluation.
%  Unlike prior works, our benchmark surfaces the  tradeoff between in-distribution and out-of-distribution performance of these UQ agents.
%  By evaluating UQ performance in dynamic settings, we also assess the ability of UQ agents to balance sharper posterior updates on the observed data while maintaining calibrated uncertainty on out-of-distribution data. 
% These trade-offs, as discussed in Section~\ref{sec:experiment}, indicates the necessity of a  UQ agent to have   flexible priors while maintaining reliable   posterior  updates. We demonstrate that SOTA UQ agents do not demonstrate this desirable behavior.  
% In many settings, though available data is limited,  we may leverage the meta learning framework   to inform   strong priors.  Recent development of Bayesian transformers~\citep{NguyenGr22, MullerHoPiGrHu22} might be an interesting future direction.

 % Updating UQ modules is a severe bottleneck and shorting the stopping time adversely effects the model performance therefore it is not reliable. 
 %  Taking the benefits of the meta-data might be a potential solution.

 % should be quick or not affected by the  stopping times