\subsection{Evaluation metrics}
\label{sec:UQ_eval_metrics}

%Typical approaches in uncertainty quantification (UQ) posit latent factor models that determines the prior and the likelihood. These latent factors, being unobserved, present a challenge in justifying the relative validity of one model over another. Instead, we view UQ models as outputting a probability distribution over a number of data points given contexts, which allows us to evaluate UQ models based on their ability to explain held-out observed sequences. This view is well-founded in  prequential statistics~\citep{Roberts65,Dawid84}, sequence modeling view of Bayesian models~\citep{FortiniPe23}, and information theory~\citep{BarronRiYu98}. Most recently,~\citet{OsbandWeAsSeDwLuVa22} propose this approach to evaluating UQ models.
 Recall we denoted by $ \mc{D}^{0} = (\mc{X}^{0}, \datay^{0}) := (X_{1:m-1},Y_{1:m-1})$ the initial training data and let $X_i \simiid Q_X$. Further, let $P_X$ be the distribution we expect to see during deployment and  $\mc{X}^{0} $ only represents a part of this distribution (with having selection bias). 
 Also recall, given a true data generating function  $f\opt$, outcomes $Y$ are generated as following:
\begin{equation*}
    Y = f\opt(X) + \varepsilon.
\end{equation*}
for some random noise $\varepsilon$,
We view UQ models as outputting a probability distribution over a number of data points given contexts, which allows us to evaluate UQ models based on their ability to explain held-out observed sequences. 
This view is well-founded in  prequential statistics~\citep{Roberts65,Dawid84}, sequence modeling view of Bayesian models~\citep{FortiniPe23}, and information theory~\citep{BarronRiYu98}.
Most recently,~\citet{OsbandWeAsSeDwLuVa22} propose this approach to evaluating UQ models.
Suppose we wish to predict $\tau$ outcomes 
$\ypred \defeq \ypredsetl$ for features $\xpred \defeq \xpredsetl$ where $\xpredsetl \simiid P_X$. The corresponding true outcomes are $y_{m+1:m+\tau}$.  Further, let $\mu(f|\mc{D}^0)$ be the posterior from some UQ module after seeing data $\mc{D}^0$. We  set our evaluation metric to be

\begin{align}
- \log {\left[\int \left(\prod_{i=m}^{m+\tau} p_\epsilon (y_i -f(X_i))\right) d\mu(f|\mc{D}^0) \right]}.
\label{joint_log_loss}
\end{align}




%Let $\dtrain \defeq \dtrainsetl$ be the training data, where $X_i \simiid P_X$ is a feature vector in $\R^d$ and $Y_i \in \R$ is the label/ outcome.  where $\varepsilon$ is a mean zero noise independent of everything else. $Y_i$'s are i.i.d. conditional on $U$ and $X_i$, but linked through the latent factor $U$. If the class of regression functions $\{ f\opt(\cdot, u): u \in \mbox{supp}(U)\}$ was well-specified, then any uncertainty due to $U$ is fully resolvable in the limit of infinite observations. For this reason, we refer to stochasticity due to $U$  epistemic / actionable uncertainty and that due to $\varepsilon$ aleatoric / irreducible uncertainty.

% We wish to predict $\tau$ outcomes 
% $\ypred \defeq \ypredsetl$ for features $\xpred \defeq \xpredsetl$. Based on prior knowledge and data $\dtrain$ generated by a particular realization of $U$,
% we view UQ modules as estimating the 
% $\tau$-sequence probability $p(\ypredsetl \in \cdot ~ |U,\xpredsetl)$ with $\what{p}(\ypredsetl \in \cdot ~ |\xpredsetl)$.

% Recall we denoted  $\mu_0(\cdot) = \mu(f\mid \mc{D}^0)$, the posterior state after observing data $\mc{D}^0$.




% The KL divergence between the oracle and predicted sequence probabilities provides a natural performance measure
% \begin{align}
% & \E_{X_i \simiid P_X, U \sim \pi}
% \left[\dkl{p(\ypredsetl \in \cdot ~ |U,\xpredsetl)}{\what{p}(\ypredsetl \in \cdot ~ |\xpredsetl)}
% \right] \nonumber \\
% & \qquad \qquad \propto
% - \E_{X_i \simiid P_X, U \sim \pi, Y_i = f\opt(X_i, U) + \varepsilon}
% \left[\log  \what{p}(\ypredsetl |\xpredsetl) \right].
% \label{eqn:joint-log-loss}
% \end{align}

% Since the $Y_i$'s in the preceding display are coupled via the latent factor $U$,
\citet{OsbandWeAsSeDwLuVa22}~referred to the above metric as ``\emph{marginal} log-loss'' when 
$\tau=1$ and as ``\emph{joint} log-loss'' when $\tau > 1$. Marginal log-loss represents the expected negative log-likelihood of predicting a single test example, based on the UQ module’s predictive distribution for that specific input. On the other hand, joint log-loss is defined as the expected negative log-likelihood for a batch of test examples, calculated under the model’s joint predictive distribution across various label combinations for the entire batch of inputs. This effectively provides a unified measure to compare the performance of UQ methods. 
%The significance of joint log-loss was also emphasized by~\citep{OsbandWeAsDwLuIbLaHaDoRo22}. 


 
% For example, an idealized Bayesian approach posits a class of models $\{\what{f}(\cdot, u): u \in \mc{U}\}$ that approximates the model class $\{ f\opt(\cdot, u): u \in \mbox{supp}(U)\}$ and generate ``posterior predictives'' $\what{p}(\ypredsetl = \ypredset ~ |\xpredsetl)$ via
% \begin{align}
% \label{eqn:ppd}
% \int \what{p}(\ypredsetl = \ypredset \mid \xpredsetl, u) \what{\pi}(u) du := \int \prod_{i=1}^\tau 
%  \what{p}_{\varepsilon}\left(y_i - \what{f}(X_i, u)\right)
%  \what{\pi}(u) du,
% \end{align}
% where $\what{p}_{\varepsilon}$ is an estimator of
% the likelihood (pdf of $\varepsilon$) and $\what{\pi}(\cdot) := \what{\pi}(\cdot; \mc{D}^0)$ is the prior estimated based on the initial data $\mc{D}^0$.



% Variational inference-based Bayesian neural networks (BNNs)~\citep{JospinLaBoBuBe22},  %. 
% %This category encompasses techniques such as 
%  dropout~\citep{GalGh16}, Bayes by Backprop~\citep{BlundellCoKaWi15}, and Ensembles/ Ensemble $+$~\citep{LakshminarayananPrBl17,OsbandAsCa18}
%  can be represented with the above abstraction.
% BNNs model $\what{f}(X, U)$ a neural network with weights $U \sim \what{\pi}$ and input $X$.
% Ensembles typically consider discretely supported $U \sim \what{\pi}$, where $\what{f}(X, u)$ is 
% a predictive model trained on a (bootstrapped) subset of the training data for $u = \{1, ..., K\}$.
% %\hntodo{I don't know how to write ENNs in my abstraction. @Daksh, please rewrite the below paragraph in the new notation.}
% ~\citet{OsbandWenAsDwIbLuRo23} propose Epistemic Neural Networks (ENNs) and showed that they outperform traditional BNNs at a much lower computational cost. ENNs also fall under the above Bayesian framework and consider a set of functions $\set{g_\eta(\cdot,u): u}$, where $\eta$ is a fixed  parameter  
% and $u$ is called epistemic index with an associated  distribution.

\paragraph{Joint log-loss with dyadic sampling} 
To evaluate the quality of joint predictions as discussed, batches of inputs $(X_1, \cdots, X_\tau)$ need to be sampled multiple times, and their log-loss is assessed against corresponding labels $(y_1, \cdots, y_\tau)$. 
Typically, batch size $\tau$ required to effectively distinguish joint predictions that reflect label interdependencies becomes large as dimensionality of data increases, and it becomes impractical as dimension increases. 
Dyadic sampling~\citep{OsbandWeAsDwLuIbLaHaDoRo22} offers a practical heuristic to estimate joint likelihood.
The basic dyadic sampling method starts by independently sampling two anchor points, $X_1$ and $X_2$, from the input distribution. Then, $\tau$ points are sampled independently and with equal probability from these two anchor points $\set{X_1, X_2}$ that leads to a random sample $X_{(1)}, \cdots, X_{(\tau)}$.
An agent's joint prediction of labels is evaluated on this batch of size $\tau$.  In our experiments, we use $\tau = 10$ and it seems to be an effective estimator of the joint log-loss.



\paragraph{In-distribution and out-of-distribution evaluations} If training distribution and prediction distribution are same, that is $Q_X =P_X$, then we call it in-distribution performance. If $Q_X \neq P_X$  then it is the case of distribution shifts (potentially out-of-support).

