\section*{Limitations}
\label{sec-limitations}

Our work in this paper has the following major limitations. 

\textbf{Limited applicability of \algo.} \algo\ is specifically designed for traditional reasoning tasks where a question is short (e.g., a mathematical query) but its answer is lengthy (e.g., a chain of reasoning followed by a final answer). The waterfall attention pattern primarily occurs during the decode stage, and phoenix tokens are frequently found in the question (prefill tokens). Thus, \algo\ may lose crucial information when applied in other scenarios where the number of prefill tokens exceeds a certain threshold. In this case, we recommend using the combination of Quest (on prefill tokens) and RaaS (on decode tokens). 

\textbf{Evaluation on a limited set of models.} Our evaluation is based on only four models. The presented results may be specific to these models and may not generalize to others. Although there are models with larger context lengths, such as Qwen2.5-Max and DeepSeek-r1, conducting a comprehensive evaluation across all such models is time- and resource-intensive. As noted by previous work~\cite{zhong2024distserve}, if decoding a single token takes around 30 ms,  decoding 16k tokens (a relatively small request) requires approximately 8 minutes on a single A100-80GB GPU. Evaluating 200 data points would take more than one day, being infeasible with only one available A100 GPU. Nonetheless, we believe that the core idea---the waterfall pattern and its underlying rationale--- remains broadly applicable, and we plan to conduct additional experiments in the future.

\textbf{Evaluation on limited inference lengths.} Due to resource and time constraints, we are unable to conduct experiments with extremely long inference lengths, as this experimental setup would require months to complete end-to-end evaluations. However, through small-scale experiments, we observe that the waterfall attention pattern is universal across varying inference lengths.

\textbf{Lack of exploration of representative selection for pages.} For a fair comparison with Quest, we adopt the same representative selection algorithm used in Quest. However, given the distinct objectives of \algo, there may be opportunities to design a more tailored representative selection algorithm that better handles false positives and negatives, potentially improving \algoâ€™s accuracy. Nonetheless, more sophisticated representative selection algorithms may introduce additional computational overhead. Therefore, we have not explored this aspect in our work described in this paper but plan to investigate the impact of different representative selection algorithms in future work.