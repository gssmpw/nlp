%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%% LaTeX Template for AAMAS-2025 (based on sample-sigconf.tex)
%%% Prepared by the AAMAS-2025 Program Chairs based on the version from AAMAS-2025.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%% Start your document with the \documentclass command.


%%% == IMPORTANT ==
%%% Use the first variant below for the final paper (including auithor information).
%%% Use the second variant below to anonymize your submission (no authoir information shown).
%%% For further information on anonymity and double-blind reviewing,
%%% please consult the call for paper information
%%% https://aamas2025.org/index.php/conference/calls/submission-instructions-main-technical-track/

%%%% For anonymized submission, use this
% \documentclass[sigconf,anonymous]{aamas}
\documentclass[sigconf]{aamas}

%%%% For camera-ready, use this
%\documentclass[sigconf]{aamas}


%%% Load required packages here (note that many are included already).

\usepackage{balance} % for balancing columns on the final page

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%% AAMAS-2025 copyright block (do not change!)

\setcopyright{ifaamas}
\acmConference[AAMAS '25]{Proc.\@ of the 24th International Conference
on Autonomous Agents and Multiagent Systems (AAMAS 2025)}{May 19 -- 23, 2025}
{Detroit, Michigan, USA}{A.~El~Fallah~Seghrouchni, Y.~Vorobeychik, S.~Das, A.~Nowe (eds.)}
\copyrightyear{2025}
\acmYear{2025}
\acmDOI{}
\acmPrice{}
\acmISBN{}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%% == IMPORTANT ==
%%% Use this command to specify your submission number.
%%% In anonymous mode, it will be printed on the first page.

\acmSubmissionID{<<submission id>>}

%%% Use this command to specify the title of your paper.

\title[Dynamic Coalition Structure Detection]{Dynamic Coalition Structure Detection in Natural Language-based Interactions}

%%% Provide names, affiliations, and email addresses for all authors.

\author{Abhishek N. Kulkarni*}
\affiliation{
  \institution{University of Texas at Austin}\thanks{* Equal contribution.}
  \city{Austin}
  \country{USA}}
\email{abhishek.kulkarni@austin.utexas.edu}

\author{Andy Liu*}
\affiliation{
  \institution{Carnegie Mellon University}
  \city{Pittsburgh}
  \country{USA}}
\email{andyliu@cs.cmu.edu}

\author{Jean-Rapha\"el Gaglione}
\affiliation{
   \institution{University of Texas at Austin}
  \city{Austin}
  \country{USA}}
\email{jr.gaglione@utexas.edu}

\author{Daniel Fried}
\affiliation{
  \institution{Carnegie Mellon University}
  \city{Pittsburgh}
  \country{USA}}
\email{dfried@cs.cmu.edu}

\author{Ufuk Topcu}
\affiliation{
   \institution{University of Texas at Austin}
  \city{Austin}
  \country{USA}}
\email{utopcu@utexas.edu}



%%% Use this environment to specify a short abstract for your paper.


\usepackage{todonotes}
\usepackage{acronym}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{mathtools}
\usepackage{graphicx}
\usepackage{cite}
\usepackage{bbm}
% \usepackage{changes}
\usepackage[commandnameprefix=always]{changes}
\usepackage{booktabs} 
\usepackage{placeins}
%\usepackage{lineno}
%\linenumbers

\input{include/acronyms}
\input{include/shortcuts}
\input{include/environments}

\begin{abstract}
	
In strategic multi-agent sequential interactions, detecting dynamic coalition structures is crucial for understanding how self-interested agents coordinate to influence outcomes. However, natural-language-based interactions introduce unique challenges to coalition detection due to ambiguity over intents and difficulty in modeling players' subjective perspectives. We propose a new method that leverages recent advancements in large language models and game theory to predict dynamic multilateral coalition formation in Diplomacy, a strategic multi-agent game where agents negotiate coalitions using natural language. The method consists of two stages. The first stage extracts the set of agreements discussed by two agents in their private dialogue, by combining a parsing-based filtering function with a fine-tuned language model trained to predict player intents. In the second stage, we define a new metric using the concept of subjective rationalizability from hypergame theory to evaluate the expected value of an agreement for each player. We then compute this metric for each agreement identified in the first stage by assessing the strategic value of the agreement for both players and taking into account the subjective belief of one player that the second player would honor the agreement. We demonstrate that our method effectively detects potential coalition structures in online Diplomacy gameplay by assigning high values to agreements likely to be honored and low values to those likely to be violated. The proposed method provides foundational insights into coalition formation in multi-agent environments with language-based negotiation and offers key directions for future research on the analysis of complex natural language-based interactions between agents.
\end{abstract}

%%% The code below was generated by the tool at http://dl.acm.org/ccs.cfm.
%%% Please replace this example with code appropriate for your own paper.


%%% Use this command to specify a few keywords describing your work.
%%% Keywords should be separated by commas.

\keywords{Coalition Structures, Game Theory, Multi-Agent Cooperation, Large Language Models}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%% Include any author-defined commands here.

\newcommand{\BibTeX}{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em\TeX}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{document}

%%% The following commands remove the headers in your paper. For final
%%% papers, these will be inserted during the pagination process.

\pagestyle{fancy}
\fancyhead{}

%%% The next command prints the information defined in the preamble.

\maketitle

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%



\section{Introduction}
\label{sec:introduction}
\input{sections/introduction}



\section{Problem Formulation}
\label{sec:problem}
\input{sections/problem}



\section{Background: Hypergame Theory}
\label{sec:background}
\input{sections/background}


\section{Coalition Structure Prediction Methodology}
\label{sec:methodology}
\input{sections/methodology}

% \textbf{Framework picture} 
% \begin{figure}
	%     \centering
	%     \includegraphics[width=0.9\linewidth]{figures/framework.png}
	%     \caption{Caption}
	%     \label{fig:enter-label}
	% \end{figure}

%\textbf{General explanation. }
%At a high-level, our framework combines a dialogue-based intent model that identifies and ranks the set of agreements being discussed in the conversation between two players with a non-dialogue based value function to determine how  rationalizable a given agreement is for a given player. 
%
%
%\subsection{Generating set of agreements}
%
%\textbf{Problem.} Given a state $s$ in the game, determine the set of agreement $\calA_s$ in the diplomacy game. 
%
%
%\ak{
%	For each node in game graph, check if neighboring territory is occupied by a unit of another player. 
%	If yes, add all possible legitimate action pairs to set of agreements. 
%}
%
%
%
%\subsection{Preferences over Intent}
%
%\textbf{Problem.} Given the history of dialogues $\vec{d}$, states $\vec{s}$, actions $\vec{a}$, and the set of agreements $\calA_s$, determine a probability distribution over $\calA_s$. 
%
%
%The distribution implicitly encodes an \emph{incomplete} preference structure. 
%The incompleteness arises from the absence of conversation about certain potential agreements.
%
%
%Note that intents incorrect since the conversations can contain lies. 
%
%
%\ak{How to learn an incomplete preference from dialogue?}
%
%
%\ak{Explore. https://aclanthology.org/W19-5941.pdf}
%
%
%
%\subsection{Value of Coalitions}
%
%\paragraph{Problem.} Given a value model $V_p: S \rightarrow \mathbb{R}$ that maps every state to a real number for each player separately, determine a value function for a coalition ${\mathcal V}: S \times 2^N \rightarrow \mathbb{R}$ and the value a player gains by participating in a coalition, $V: S \times 2^N \times N \rightarrow \mathbb{R}$. 
%
%
%There are two types of models to compute this: transferable vs. non-transferable utility models. 
%We still need to determine which is best for our case. 
%
%
%\subsection{Rationalizability of Coalition Change}
%
%An agreement may be highly preferred for a player, say P1, in the subset of $\calA_s$ in which P1 is involved, but other players may not be interested to participate in this agreement.   
%The solution concept of rationalizability in game theory determines rational actions for a player accounting for their incomplete information.
%To determine whether an agreement is rationalizable, we must evaluate how preferable it is among the set of likely intents.
%
%\ak{Need for formalize rationalizability. I desire it to be a quantitative definition. 
%	This is tricky because most existing work studies rationalizability in games with single objectives. More investigation is needed to find/define the concept for multi-objective games or games with preferences.}
%
%
%\paragraph{Problem.} Given an incomplete preference over intents and a preference over coalitions, determine the rationalizability of an agreement for a player.  


\section{Experiments}

We evaluate the two stages of our proposed method separately. 
First, we outline the dataset employed for evaluation, and then  present the results for each of the two stages.

\subsection{Dataset}\label{sec:data}
We source previous Diplomacy games from WebDiplomacy\footnote{\url{https://webdiplomacy.net/}}, a multiplayer online implementation of Diplomacy. We consider a dataset of $140$ full-press games played over the standard Diplomacy map.  In order to calibrate our agreement detection classifier, we manually annotate five games from this dataset, randomly sampling from games with at least 250 total messages sent. This gives us a total of 16962 $(S, P_1, P_2, u)$ tuples over 1603 combinations of a state $S$ and players $P_1, P_2$. This dataset is highly imbalanced, with 444 (2.6\%) of all $(S, P_1, P_2, u)$ tuples having a coalition formed.

After we validate our usage of the agreement detection classifier, we then use it to label the remainder of the games with detected agreements. This resulting dataset consists of $415001$ total $(S, p_1, p_2, u)$ tuples. Of these tuples, $11008$ have agreements detected by our automatic method, $8344$ of which are upheld (i.e. the player played the agreed-upon move).

\subsection{Validating Agreement Detection Method}\label{sec:valid}

We use the manually-annotated data sample described in Section~\ref{sec:data} to test our agreement detection method, with an 80-20 train-test split. While this dataset is strongly imbalanced, we mitigate the impact of the dataset imbalance by only training on instances that pass our language model-based filter, which reduces our classifier training data to 1768 tuples, and by tuning a classification threshold to optimize F1-score on our training dataset. We benchmark three methods on this dataset: 
\begin{itemize}
    \item \textbf{GPT-4o}, which prompts a strong language model to directly identify units over which an agreement has been reached,
    \item \textbf{Classifier}, which trains a classifier on intent model distributions before and after dialogue over all $(S, P_1, P_2, u)$ tuples in the dataset, and
    \item \textbf{Hybrid}, our approach, which first filters using GPT-4o-parsed locations and player adjacency before training a classifier on the filtered data.
\end{itemize}

The results of our evaluation are in Table~\ref{tab:eval}. Our hybrid method outperforms both training a classifier on unfiltered intent data and prompting a strong language model on identifying units over which agreements have been reached. Extraction of coalition agreements from Diplomacy dialogue is a challenging task, due to the length of many dialogues in Diplomacy as well as the implicitness and fluctuating nature of negotiation over a multi-party dialogue. Fine-tuning more generally capable language models following the intent model formula in CICERO, in combination with more sophisticated parsers such as the one trained in \citep{wongkamjan2024more}, could yield even stronger performance improvements, which we leave to future work in this direction.

\begin{table}
    \centering
    \begin{tabular}{c|c|c|c}
    \toprule
    Method & F1 Score & Precision & Recall \\\midrule
    GPT-4o & 0.34 & 0.26 & 0.47 \\
    Classifier & 0.44 & 0.43 & 0.45 \\
    \textbf{Hybrid} & \textbf{0.55} & \textbf{0.63} & \textbf{0.48} \\\bottomrule
    \end{tabular}
    \caption{Classification metrics over the test dataset for our three methods. Hybrid methods outperform both purely language model-based and intent model distribution-based approaches at detecting whether an agreement has been reached over a specific unit.}
    \label{tab:eval}
\end{table}

\subsection{Evaluating Rationalizability Score}

The rationalizability score establishes a ranking of potential agreements for a unit within a specific game state. To evaluate the effectiveness of the score in predicting coalition structures, we analyze the rankings induced by the score on honored agreements in comparison to those of violated agreements.


We utilize both hand-labeled data and data labeled through the hybrid approach for the evaluation. 
We consider a total of $7434$ agreements labeled using the hybrid approach for evaluation.
For each agreement identified in the agreement detection stage, we generate a set of alternative agreements by sampling different orders for the units involved in the agreement.
The results of this evaluation for honored and violated agreements are presented in Table~\ref{tab:agreement}.
Given that the output of our model is a ranked list based on the rationalizability score, we employ two information retrieval metrics: mean reciprocal rank (MRR) \citep{craswell2009mean} and Brier score \citep{brier1950verification}.
The MRR is calculated using both the top-$1$ and top-$5$ ranked elements.

The ranking generated by the rationalizability score effectively differentiates between honored and violated agreements.
Our findings indicate that honored agreements typically receive lower ranks, while violated agreements tend to rank higher. 
This is observed through both the MRR and Brier scores.
When calculating the Brier score, we normalize the rationalizability scores, such that a score close to $1$ reflects that honored agreements usually have low ranks and violated agreements have higher ranks.
Notably, MRR scores that are close to $1$ in the top-$1$ case suggest that honored agreements are frequently assigned a rank of $0$, suggesting that this metric can very precisely recognize upheld coalitions.

We also compare our rationalizability score to a more conventional coalition formation prediction method, approximate Nash equilibrium (as estimated by the CICERO value model). We find that even when such approximate equilibrium-based methods are adapted for games with large state and action spaces, they remain inadequate for predicting coalition formation in such dynamic environments. Our R-Score yields a significantly higher MRR and a lower Brier score than the value model score in all cases.  This suggests that our rationalizability framework is significantly better at distinguishing between coalitions that are upheld and coalitions that are not upheld than Nash approximation-based predictions.



\begin{table}
\begin{centering}
\resizebox{0.5\textwidth}{!}{
\begin{tabular}{cc|ccc|ccc}
\toprule 
\multicolumn{2}{c}{} & \multicolumn{3}{c}{\textbf{Hand-Labelled}} & \multicolumn{3}{c}{\textbf{Hybrid}} \\
\multicolumn{1}{c}{Honored?} & \multicolumn{1}{c}{Metric} & \multicolumn{1}{c}{Value} & \multicolumn{1}{c}{R-Score@1} & \multicolumn{1}{c}{R-Score@5} & \multicolumn{1}{c}{Value} & \multicolumn{1}{c}{R-Score@1} & \multicolumn{1}{c}{R-Score@5} \\
\midrule
Yes & MRR ($\uparrow$) & 0.2842 & 0.9444 & \textbf{0.9722} & 0.3602 & 0.7416 & \textbf{0.8294} \\
No & MRR ($\downarrow$) & 0.2583 & \textbf{0.0} & 0.125 & 0.3682 & \textbf{0.2628} & 0.3354 \\
Yes & Brier ($\downarrow$) & 0.0802 & \textbf{0.0422} & \textbf{0.0422} & 0.0739 & \textbf{0.0311} & \textbf{0.0311} \\
No & Brier ($\uparrow$) & 0.7303 & \textbf{0.7494} & \textbf{0.7494} & 0.5706 & \textbf{0.6145} & \textbf{0.6145} \\
\bottomrule
\end{tabular}}
\end{centering}
\caption{Evaluation metrics for honored and violated agreements based on hand-labeled and hybrid datasets. The ranking induced by rationalizability score (RScore) on the set of agreements assigns lower ranks to honored agreements and higher ranks to violated agreements when compared to the ranking induced by Nash approximation-based predictions.}
\label{tab:agreement}
\end{table}

\section{Conclusion}

The detection of dynamic coalition structures is a key problem in understanding sequential interactions in strategic multi-agent environments. While many such environments use language, the study of coalition structure detection over natural language-based coordination is relatively understudied. This is compounded in settings like the board game Diplomacy, where players make decisions with incomplete information using dialogue-informed mental models of their opponents' future actions, and where relationships between players can shift drastically between turns as information is revealed.

Drawing from hypergame theory and the concept of subjective rationalizability, we propose a general method to dynamically predict coalition structures over sequential multi-agent interactions. In our method, we first extract detected agreements using the combination of a large language model-based parser and a specialized language model to predict player intents before and after the negotiation phase. We then compute the value of the agreement using a deep reinforcement-learning based value function, which we use in combination with player intents to compute the likelihood that each player will honor the agreement.

We validate the success of our method over sampled interactions between human Diplomacy players, using components of Meta's CICERO agent to compute player intents and action values. When compared to approximate Nash Equilibrium-based methods, our rationalizability score is significantly better at predicting the coalition structure at a given timestep. Our method can also generalize to other multi-agent, dialogue-based games, as long as sufficient human data exists upon which similar, game-specific models can be trained.

Extending coalition structure detection to natural language-based negotiation environments such as Diplomacy presents unique challenges in a setting where agents have incomplete information, negotiations are both multi-issue and multi-party, and where agents must reason over mental models of their opponents. However, for artificial agents to handle such complex environments properly, they must be capable of understanding the coalition dynamics of the environment at a given state. Our method and experiments serve as an important first step in this direction. We hope that future work will be able to extend our framework to new settings, including those with more complex negotiations and less existing domain-specific models, paving the way for agents that can reason over such information in deployment settings.

\FloatBarrier

\begin{acks}
This material is based upon work supported by the Defense Advanced Research Projects Agency (DARPA) under Agreement No. HR00112490410, the Army Research Lab under Agreement ARO W911NF-23-1-0317 and the Office of Naval Research under Agreement N00014-24-1-2097. We thank WebDiplomacy for supporting this research by providing access to online gameplay data.
\end{acks}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%% The acknowledgments section is defined using the "acks" environment
%%% (rather than an unnumbered section). The use of this environment
%%% ensures the proper identification of the section in the article
%%% metadata as well as the consistent spelling of the heading.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%% The next two lines define, first, the bibliography style to be
%%% applied, and, second, the bibliography file to be used.

\bibliographystyle{ACM-Reference-Format}
\bibliography{main}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\end{document}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

