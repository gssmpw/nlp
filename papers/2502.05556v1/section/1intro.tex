  \section{Introduction}




Cognitive diagnosis evaluates a student's learning proficiency through his responses to a series of exercises, as shown in Figure~\ref{fig: intro} (a), which plays a fundamental role in intelligent education systems. 
The outcomes of cognitive diagnosis are crucial for various educational applications, such as educational recommendation~\cite{huang2019exploring}
%替换另一个应用的任务 对于学生建模和预测都有着重要的作用
and computerized adaptive testing~\cite{bi2020quality,zhuang2022robust}.
Consequently, the accuracy and reliability of cognitive diagnosis are essential for enhancing the effectiveness of these educational technologies.
%获得准确诊断是重要的

%Diagnosing a student's learning status is not a complex task for an experienced human teacher, but how to efficiently simulate this process and automatically generate diagnostic results remains challenging.
%

\begin{figure}
    \vspace{-0.5em}
  \centering
  \includegraphics[width=\linewidth]{figs/intro.png}
  \caption{(a) An illustration of cognitive diagnosis.
  (b) Performance of warm and cold scenarios of NCD on PTADisc, exhibiting the limitations in cold scenario.}
    \vspace{-2em}
\label{fig: intro}

\end{figure}
%Although diagnosing a student's learning status is not a complex task for an experienced human teacher, it is still challenging for models and algorithms to diagnose the student's learning status automatically.
%转折 什么在转折
%the development of online intelligent education systems has increasingly emphasized the importance of algorithms and models for automatic cognitive diagnosis.
Traditional cognitive diagnosis models (CDMs) are primarily grounded in psychometric theories, employing manually designed interaction functions inspired by principles from both psychometrics and educational theory. Examples include DINA~\cite{de2009dina} and MIRT~\cite{reckase200618} models. 
%For example, MIRT~\cite{reckase200618}, a representative CDM, originates from item response theory and utilizes multidimensional vectors to expand expressive ability. 
Recent advancements in deep learning have enabled the development of innovative CDMs that leverage neural networks to model complex collaborative information (\textit{i.e.}, student-exercise interactions), thereby improving diagnostic accuracy and adaptability~\cite{wang2020neural, gao2021rcd}. 
%These models leverage deep neural networks and graph neural networks to construct sophisticated interaction functions. Currently, the leading CDMs integrate classic psychometric theory, such as item response theory, with neural network methodologies, thereby significantly enhancing their performance~\cite{wang2024boosting,bi2023beta,li2024towards,wang2023self}.
However, these existing CDMs face significant challenges in diagnosing infrequent students and exercises, commonly referred to as the cold-start problem. This limitation arises primarily from the lack of prior knowledge within these models, which impairs their adaptability to unfamiliar students and exercises. As depicted in Figure~\ref{fig: intro}(b), experiments conducted on the PTADisc dataset~\cite{hu2023ptadisc} indicate that existing CDMs exhibit poor performance in cold scenarios, thereby undermining overall diagnostic accuracy.
%In contrast, experienced human teachers, through the accumulation of domain-specific knowledge from extensive teaching experience, are adept at swiftly adapting to unfamiliar students and exercises. This capability enables them to make more accurate diagnoses of student knowledge states.
%For example, for exercises that only a few students have attempted, the difficulty and discrimination parameters estimated by experienced human teachers tend to be more reliable than those estimated by CDMs, resulting in more precise evaluations of students' capabilities.



Large language models (LLMs) have seen rapid advancements, showcasing remarkable capabilities in logical reasoning and text comprehension. Their success across various domains highlights the feasibility of this approach~\cite{wang2024user,xu2024eduagent,abbasiantaeb2024let,zhu2024reliable,zhang2024agentcf}. 
The extensive prior knowledge embedded in LLMs presents a promising solution for addressing the limitations of existing CDMs. Specifically, LLMs can leverage their understanding of concepts and relationships between different knowledge domains to provide insights into student learning behaviors and exercise characteristics. By incorporating this extensive prior knowledge, LLMs can simulate the reasoning of experienced human teachers, offering more accurate diagnoses in cold scenarios. Therefore, our objective is to effectively integrate LLMs with CDMs to enhance diagnostic performance. 
%Leveraging LLMs for cognitive diagnosis can better simulate experienced human teachers, enabling more accurate diagnoses, especially for cold students and exercises. 

%1.LLM由于input token限制，对于关系描述不够细致 2.虽然LLM具有强大的推理能力，可以进行举一反三，但可能会导致幻觉 3.对LLM的微调成本较高，且适用性差，而使用现有的LLM进行小样本推理效果可能不如CDM
%To this end, our goal is to effectively integrate LLMs with CDMs to achieve better performance.
However, this integration is non-trivial due to several key factors.
Firstly, LLMs are limited in their ability to model the fine-grained collaborative information crucial for understanding student-exercise interactions, as their input length constraints limit the inclusion of detailed textual information about relationships between exercises, knowledge concepts, and students.
Furthermore, LLMs and CDMs operate in distinct representation spaces: LLMs process text-based data within a semantic space, whereas CDMs analyze student behavior within a behavioral space derived from interactions. 
Successful integration necessitates bridging the gap between these semantic and behavioral spaces.

% However, the effectiveness of leveraging LLMs to enhance CDMs is constrained by several challenges.
% Primarily, LLMs and CDMs diagnose students in different representation spaces. How to bridge the gap between the semantic space of LLMs and the behavioral space of CDMs is critical for achieving better performance.
% Moreover, LLMs are susceptible to generating hallucinations, which can negatively affect the accuracy of diagnostic results when integrated with CDMs. 
% Additionally, the input length limitations of LLMs restrict the inclusion of detailed textual information on relationships between exercises, knowledge concepts, and students, which is important for a comprehensive understanding of students' response logs.
% However, the effectiveness of LLMs in cognitive diagnosis is constrained by several challenges.
% Primarily, the input length limitations of LLMs restrict the inclusion of detailed textual information on relationships between exercises, knowledge concepts, and students, which is crucial for a comprehensive understanding of students' response logs.
% Additionally, fine-tuning LLMs to specific educational contexts incurs significant costs, making it impractical to handle the continually increasing dataset of new students and exercises. While employing fixed LLMs could mitigate these costs, their performance in few-shot or zero-shot diagnostic scenarios generally falls short of CDMs.
% Moreover, the strong reasoning capabilities of LLMs may lead to serious hallucinations, which undermine their robustness, particularly in scenarios involving knowledge concepts that students have not previously encountered.

% due to the input length limitation of LLMs, they cannot input all the detailed textual information of exercises, knowledge concepts, and students' relationships, which poses a significant challenge to understanding students' response logs.
% At the same time, fine-tuning LLMs requires a significant cost, making it unsustainable to handle the continuously increasing number of students and exercises during application. Although using fixed-parameter LLMs can reduce costs, performing few-shot or zero-shot diagnostics cannot surpass the full-parameter CDMs.
% Additionally, the strong reasoning capabilities of LLMs may lead to serious hallucinations, resulting in poor robustness when judging knowledge concepts that students have not been exposed to.
% However, the input of LLMs is usually composed of natural language, \textit{e.g.} problem contents, knowledge concepts, and students' responses. Structured data, \textit{e.g.} relationships of different exercises, knowledge concepts, and students, is hard for LLMs to fully grasp and understand~\cite{wei2021knowledge}.
% Besides, a clear description of the student's response logs, such as the responses of other students to the same problems, required additional context of input.
% This may be affected by the context length limitations of LLMs.
% Conversely, the interaction function employed by existing CDMs can efficiently model these complex relationships.

% Therefore, the principal challenge lies in effectively harnessing the extensive prior knowledge of LLMs to enhance conventional CDMs.
% % Therefore, how to effectively integrate the strengths of LLMs and CDMs remains a challenge for bridging the gap between CDMs and human teachers. 
% On the one hand, rich prior knowledge of LLMs makes it possible to swiftly adapt to infrequent students and problems and comprehend the contents of the exercises, knowledge concepts, and students' responses.
% On the other hand, conventional CDMs excel in managing complex relational information and generally incur lower training costs.

To address these challenges, we propose a novel Knowledge-enhanced Cognitive Diagnosis (KCD) framework that seamlessly integrates LLMs to enhance existing CDMs, aligning the semantic space of LLMs with the behavioral space of CDMs. 
The proposed KCD comprises two primary modules: \textbf{LLM diagnosis} and \textbf{cognitive level alignment}. The LLM diagnosis module leverages the capabilities of LLMs to simulate experienced human educators in diagnosing students' learning status and the attributes of exercises, thereby enriching the prior knowledge of conventional CDMs. Specifically, during LLM diagnosis, collaborative information regarding students and exercises is gathered via LLMs, followed by an analysis of students' response logs from both educational and psychological perspectives to generate textual diagnoses of students and exercises, revealing their cognitive status and attributes. 
%Specifically, during LLM diagnosis, we first collect collaborative information of students and exercises through LLM, then we instruct the LLM to analyze students' response logs from educational and psychological perspectives to generate textual diagnoses of students and exercises revealing their cognitive status and attributes. 
Subsequently, the cognitive level alignment module aligns these textual diagnoses from the semantic space of LLMs with the behavioral representations of CDMs, resulting in more accurate cognitive representations of students.
%Subsequently, during cognitive level alignment, we align the modeling of diagnoses from the semantic space of LLMs and the behavioral space of CDMs, formulating more accurate cognition representations of students.
%Moreover, this framework is model-agnostic, it can be conveniently integrated with various CDMs.
%Since this framework is model-agnostic, it can be conveniently integrated with various CDMs and allows for the selection of appropriate CDMs based on different educational scenarios.


The contributions of this work are summarized as:

\begin{itemize}
   \item We propose the KCD framework, which is model-agnostic and leverages the combined strengths of LLMs and CDMs to achieve optimal diagnostic results.
   %the model-agnostic framework KCD that leverages the capabilities of LLMs and CDMs to achieve optimal diagnostic results.
   \item We introduce the LLM diagnosis module that combines collaborative information and response logs to generate textual diagnoses of students and exercises.%, namely the learning status of students and attributes of exercises.
    \item We introduce the cognitive level alignment module, aligning the textual diagnoses from LLMs with behavioral representations from CDMs.
    \item Experiments on several public datasets with different CDMs demonstrate the effectiveness of our framework. Our code and datasets are available at \url{https://github.com/PlayerDza/KCD}.
\end{itemize}

