Motivated by our findings from the mesoscale carbon analysis, we introduce a carbon-aware framework for edge computing, named \proposedsystem, which employs the variations of carbon intensity across edge data centers to intelligently distribute edge applications while satisfying the low-latency demands. We formalize our carbon-aware edge placement problem with latency constraints and present an optimization approach to minimize carbon emissions at the edge. Lastly, we present our incremental placement algorithm to our edge placement optimization in a real-world edge system. 

% to allocate latency-sensitive edge applications across geographically dispersed edge data centers. Within the system, we introduce a new carbon-aware placement policy aimed at minimizing the carbon footprint of complex edge networks that are composed of \emph{diverse} edge applications and \emph{heterogeneous} edge devices. Lastly, we present the implementation of our system. 

% This section first presents an architectural overview of our \proposedsystem system for carbon-aware edge placement. We then formalize our carbon-aware edge placement problem with latency constraints and present an optimization approach to leverage mesoscale spatial carbon intensity variations to implement carbon-aware placement while considering their applications' tight latency requirements. Lastly, we present our \proposedsystem incremental placement algorithm to our edge placement optimization in a real-world edge system. 

\subsection{\proposedsystem Overview}

\proposedsystem is a carbon-aware framework designed to reduce carbon footprint at the edge by spatially distributing workloads across edge data centers. It manages edge data centers dispersed at mesoscales, which have shown prevalently significant variations in carbon intensity (\autoref{sec:carbon_analysis}), and assumes that edge workloads can shift across edge data centers at this scale. 
Edge servers are not only diverse in geolocations but also diverse in architecture and capacity, exhibiting significant differences in energy efficiency. As carbon emission is a function of energy consumption and carbon intensity of the grid, we further combine intensity variations across edge data center locations and energy efficiency differences across diverse edge servers to save carbon emissions at the edge. As a result,  \proposedsystem reduces edge carbon emissions by placing edge applications on energy-efficient edge servers with sustainable energy supply, respecting the low-latency and resource demands. Moreover, \proposedsystem manages the power states of edge servers to reduce emissions from idle servers. 

\autoref{fig:system_design} shows an overview of our system. The telemetry and carbon intensity services continuously collect system metrics, energy consumption, and the electricity carbon intensity of edge data centers. In addition, the carbon intensity service periodically predicts the carbon intensity of all data centers (step \Circled[inner color=black]{\textbf{0}}). When edge workloads arrive, which can be applications offloaded from resource-limited IoT or mobile devices or applications to be redeployed when an edge server fails (step \Circled[inner color=black]{\textbf{1}}), the placement service instantly decides where to allocate the workloads using a carbon-aware placement policy (step \Circled[inner color=black]{\textbf{2}}). Once the placement decisions are made, the edge orchestrator deploys the applications accordingly (step \Circled[inner color=black]{\textbf{3}}) and establishes the connections to end users (step \Circled[inner color=black]{\textbf{4}}). 

%Next, we introduce the four key components of \proposedsystem. 


% \noindent \textbf{Telemetry.} This component collects static (e.g., location and IP address) and real-time metrics from edge data centers.  The static metrics are used to measure the latency, and the real-time metrics are used to present the system states (e.g., uptime and resource utilization), energy consumption, and hosting applications. 
% % In particular, it gathers the base power consumption when an edge server is idle. 

% % collects the metadata (e.g., location) and real-time resource states, including computing, storage, and network utilization and energy consumption, of edge data centers. The locations can be used to compute latency between edge data centers


% \noindent \textbf{Carbon Intensity Service.} It collects real-time carbon intensity data of all edge data centers based on their locations. Since carbon intensity varies over time, the future carbon intensity would affect the emissions of deployed applications. Therefore, this component provides the forecast carbon intensity of edge data centers using predictive models such as Carboncast~\cite{carboncast}. 


% \noindent \textbf{Placement Service.} This component determines workload placements at runtime. When one or multiple placement requests arrive, it leverages the system's real-time metrics, uptime, and energy consumption profiles and forecasts carbon intensity values to make the placement decisions. We assume each edge workload includes its source location or IP address used for latency measurement, latency SLOs, and application profiles, which indicate the application's resource demands and energy consumption. The application profiles can be obtained by profiling the applications on edge servers or by existing estimation methods~\cite{xxx}. With the above inputs from application and edge data centers, the placement service applies a carbon-aware placement optimization to determine the optimal placements and server activation. 


% \noindent \textbf{Edge Orchestrator.} This component implements the placement decision by deploying applications and activating edge servers accordingly. After deployment, it manages the power states of edge servers and the performance of the active applications. For instance, the edge orchestrator automatically powers off the idle servers to reduce emissions. If an edge server fails, it triggers the replacement of affected applications; if an application becomes overloaded, it scales the replicas and initiates the placement of those replicas. 


% Overall,  \proposedsystem consists of four key components, as illustrated in \autoref{fig:system_design}. 1) \emph{Carbon Intensity Service} provides real-time and forecast carbon intensity values for edge data centers. Edge data centers powered by different energy sources typically exhibit varying carbon intensity values, and forecasted carbon intensity can be obtained using prediction models like Carboncast~\cite{carboncast}; 2) \emph{Telemetry Service} collects the metadata (e.g., location) and real-time resource states, including computing, storage, and network utilization and energy consumption, of edge data centers. The locations can be used to compute latency between edge data centers; 3) \emph{Placement Service} acts as the entry point for application placement. It retrieves the configuration of applications and edge data centers and utilizes the carbon-aware placement policy (described in~\autoref{sec:design_problem}) to determine where to allocate the applications; 4) \emph{Edge Orchestrator} implements the placement decisions and deploys applications on edge data centers. 


% Here, we take edge offloading, where resource-limited IoT devices offload computing-intensive and latency-sensitive applications to edge data centers, as an example to illustrate the carbon-aware edge placement with \proposedsystem. 

% \noindent \textbf{Exemplar Workflow (~\autoref{fig:system_design}).}
% When \proposedsystem is deployed to manage a set of edge data centers, it creates metadata, continuously collects real-time carbon intensity data and system metrics, and predicts the carbon intensity for all edge data centers, shown as step \Circled[inner color=black]{\textbf{0}}. In step \Circled[inner color=black]{\textbf{1}}, IoT devices issue edge application offloading requests to \proposedsystem.  These requests include latency limits, originating locations, and application profiles. In step \Circled[inner color=black]{\textbf{2}}, the Placement Service incorporates configurations of applications and edge data centers and determines the placements using the carbon-aware policy. Among the three edge data centers in~\autoref{fig:system_design}, Edge DC II, which is powered by the most sustainable energy sources (such as solar and wind), is selected to deploy the applications. Once the placements are decided, in step \Circled[inner color=black]{\textbf{3}}, the Edge Orchestrator deploys the applications on Edge DC II and informs the IoT devices of the destinated edge data center, where in step \Circled[inner color=black]{\textbf{4}}, the IoT devices connect and send requests to the offloading applications. 



% We design \proposedsystem by following principles:  

% 1) Geographically dispersed and ephemeral edge resources

% 2) Limited computing, storage, and networking resources

% 3) Heterogeneous edge resources / size and resource types

% 4) Diverse edge applications exhibit different resource requirements

% 5) Latency-critical application. Data residency/sovereignty
 
% Edge data centers are decentralized and near end users. They have limited resources like computing and storage, ranging from a single server rack to a micro data center, exhibiting varied capacity and resource types. Additionally, they often feature transient nodes, with devices frequently joining and leaving the network. Meanwhile, edge applications can exhibit diverse behaviors and resource requirements that defy simple characteristics. 




% ~\autoref{fig:system_design} illustrates our realistic workflow of an edge application and how \proposedsystem augments the placement decisions with carbon-awareness. The workflow starts when a new application placement request arrives 
% in the system \Circled[inner color=black]{\textbf{1}}. The request includes latency limits and the originating location. 
% %Application placement requests can be triggered when a new application arrives or clients increase their latency requirements or request rate.
% In step \Circled[inner color=black]{\textbf{2}}, \proposedsystem utilizes the \autoref{alg:algorithm}, where \proposedsystem will map the edge application to the edge data center with the greenest energy source.
% Lastly, once the placements are decided, in step \Circled[inner color=black]{\textbf{3}}, the Edge Orchestrator implements the placement decisions and informs the client of the destination edge data center, where in step \Circled[inner color=black]{\textbf{4}}, the client connects and send its offloading requests.




% \autoref{fig:system_design} depicts the four key components of \proposedsystem for carbon-aware edge placement between a set of edge data centers.
% \proposedsystem utilizes a \emph{Carbon Intensity Service} that provides real-time and forecast across the edge data center, a \emph{ Telemetry Service}, which collects real-time performance and computes applications' profiles. Moreover, \proposedsystem implements a \emph{Placement Service} that encompasses the carbon-aware placement and power management decisions across different edge data centers while ensuring that resource and performance constraints are strictly met. Lastly, \proposedsystem requires an \emph{Orchestrator Service} (e.g., Kubernetes~\cite{kubernetes}) that implements its placement and power management decisions and establishes the connection between the client and servers. In ~\autoref{sec:implementation}, we discuss these components in more detail. 

\begin{figure}[t]
    \centering
    %\includegraphics[width=0.6\linewidth]{figures/Design.pdf}
    %\includegraphics[width=0.8\linewidth]{figures/carbonedge_design.pdf}
    % \vspace{-6mm}
    \includegraphics[width=1.0\linewidth]{figures/carbonedge_design_walid.drawio.pdf}
    \caption{\proposedsystem design and exemplar workflow of placing offloading applications from IoT devices.}
    \label{fig:system_design}
\end{figure}


\subsection{Carbon-aware Edge Placement}
\label{sec:design_problem}

The section presents the carbon-aware placement with latency constraints problem.  and our proposed policy used in \proposedsystem. Our carbon-aware policy minimizes the carbon footprint of edge data centers using an incremental optimization-driven approach. Our approach holistically integrates three factors: 1) carbon intensity variations of mesoscale edge data centers, 2) workload and diversity in energy efficiency across heterogeneous edge servers, and 3) base power usage and power proportionality of servers.
%of resource  1) energy proportionality of edge applications on heterogeneous edge servers, 2) carbon intensity variations of mesoscale edge data centers, and 3) base load emissions from diverse edge servers to jointly optimize placements at the edge. 

% employs carbon intensity variations across mesoscale edge data centers. This policy solves an integer linear programming (ILP) problem to identify application placements that minimize the carbon footprint of edge data centers, accounting for application diversity and hardware heterogeneity. 



\noindent \textbf{Incremental carbon-aware placement.} Our carbon-aware placement problem aims to minimize carbon emissions from incrementally placing arriving edge applications across edge data centers while meeting strict latency requirements. Given the current power state of the servers $y_j^{curr}: j\in \mathcal{S}$ and available resource capacity $C_j^k$, our objective is to place a batch of applications $\mathcal{A}$ on $\mathcal{S}$.
First, we define two decision variables that represent the placement and power management decisions and then define the carbon emissions associated with the placements based on these two variables. Finally, we present the carbon-aware placement problem formulation. ~\autoref{tab:notations} summarizes the notations. 

\textit{Decision variables:} Let $x_{ij} \in \{0, 1\}$ the placement of application $i \in \mathcal{A}$ on server $j \in \mathcal{S}$, and $y_j \in \{0, 1\}$ indicate whether server $j$ is powered on. These variables are subject to the following four constraint classes.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%% Table of notations
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Please add the following required packages to your document preamble:
% \usepackage{graphicx}
\begin{table}[tb]
\caption{Notations used in \proposedsystem.}
\label{tab:notations}
\resizebox{.95\linewidth}{!}{%
\begin{tabular}{cl}
% \toprule
\toprule
% \textbf{Decision Variables} &  \\ %\midrule
\multicolumn{2}{l}{\textbf{Decision variables:}} \\ 
$x_{ij} $ & True if application $i$ is placed on server $j$; False otherwise. \\ %\midrule
$y_j $ & True if server $j$ is {\em powered-on}; False otherwise. \\ %\bottomrule %\toprule

\multicolumn{2}{l}{\textbf{Inputs:}}\\ %\midrule
% $M, N$ &  number of servers in the region and number of applications to place \\ \midrule
$C_j^{k}$ &  Available capacity in server $j$ of type $k$ \\ %\midrule
$\bar{I_j}$ &  Average carbon intensity of server $j$ \\ %\midrule
% $T_j^t$ &  Time span of application's execution\\ \midrule
$B_j$ & Base power usage of server $j$ when it is {\em powered-on} \\ %\midrule
$y_j^{curr}$ & Power state (on or off) of server $j$ before placement optimization \\ %\midrule
$R_{ij}^k$ &  Resource demand of type $k$ of application $i$ when running on server $j$ \\ %\midrule
$E_{ij}$ &  Energy usage of application $i$ when running on server $j$ \\ %\midrule
$L_{ij}$ & Latency between application $i$ and server $j$ \\ %\midrule
$\ell_i$ &  Latency requirement of application $i$ \\ %\bottomrule %\toprule

\multicolumn{2}{l}{\textbf{Optimization goal:}}  \\ %\midrule
$f$ & Total carbon footprint of edge placement \\ \bottomrule %\toprule

% \textbf{Intermediate variables} & \textbf{Definition}  \\ \midrule
% $\mathcal{C}_j^{base}$ & Base power carbon emission of server $s_j$ \\ \midrule 
% $\mathcal{C}_{ij}^{app}$ & Carbon emission of running application $a_i$ on server $s_j$ \\ \bottomrule \bottomrule
\end{tabular}%
}
\end{table}


\noindent 1) \textit{Multi-dimensional resource constraint}:  Edge servers are typically computing, storage, and networking resource-limited and are diverse in capacity and resource types. We define $C_j^k$ represents the available capacity of type $k$ on server $j$. When application $i$ runs the server $j$, its resource demands are $R_{ij}^k$. To ensure the application performance, the aggregated resource demands of applications allocated to a server must not exceed its available resources. 
{\small 
\begin{align}
    \label{eq:comp_cap}
    & \sum_i x_{ij} \cdot R_{ij}^k \leq y_j \cdot C_j^{k}, \quad \quad \quad \quad  \forall j, k 
\end{align}
}

\noindent 2) \textit{Latency constraint}: Each application $i$ comes from a certain geolocation and has a specific latency limit $L_i$. The latency from the application's source to the hosting server $L_{ij}$ must remain below this limit. 
{\small 
\begin{align}
    \label{eq:latency}
    & x_{ij} \cdot L_{ij} \leq \ell_i, \quad \quad \quad \quad \quad \quad \quad \quad \forall i, j 
\end{align}
}

\noindent 3) \textit{Placement constraint}: Each application $i$ is assigned to exactly one server. 
{\small 
\begin{align}
    \label{eq:placement}
    & \sum_j x_{ij} = 1, \quad \quad \quad \quad \quad  \quad \quad \quad \quad \quad \forall i 
\end{align}
}

\noindent 4) \textit{Power state consistency}: An active server cannot be powered off during placement (e.g., to avoid service disruption):
{\small 
\begin{align}
    \label{eq:server_keep_on}
    & y_j^{curr} \leq y_j, \quad \quad \quad \quad  \quad \quad \quad \quad \quad \forall j 
\end{align}
}
where $y_j^{curr}$ is the current power state. Additionally, assignments require active servers:  
{\small 
\begin{align}
    \label{eq:server_on}
    & x_{ij} \leq y_j, \quad \quad \quad \quad \quad  \quad \quad \quad \quad \quad \forall i, j 
\end{align}
}
\textit{Carbon emissions:} Carbon emissions from edge placement are from two main sources: application operation and server activation. Application operational emissions depend on the energy consumption of applications and the carbon intensity of hosting servers, given by $\sum_i \sum_j x_{ij} \cdot E_{ij} \cdot \bar{I_j}$, where $E_{ij}$ is the energy consumption of application $i$ on server $j$, and $\bar{I_j}$ is the average carbon intensity of the hosting server $j$. Note that carbon intensity varies over time depending on the mix of energy sources available in that area. $\bar{I_j}$ represents the average of the forecast carbon intensity values of server $j$. Server activation emissions depend on the base power $B_j$ and the carbon intensity $\bar{I_j}$, represented as $\sum_j (y_j - y_j^{curr}) \cdot B_{j} \cdot \bar{I_j}$, where $(y_j - y_j^{curr})$ represents the newly activated server. The total carbon emissions for placing applications are: 
{\small 
\begin{align}
    %\tag{2.1}
    \label{eq:emission}
    & f =  \underbrace{\sum_i \sum_j x_{ij} \cdot E_{ij} \cdot \bar{I_j}}_{\text{Application operation}} + \underbrace{\sum_j (y_j - y_j^{curr}) \cdot B_j \cdot \bar{I_j}}_{\text{Server activation}}
\end{align}
}

\noindent \textit{Problem formulation:} The carbon-aware placement policy identifies the optimal placement $x_{ij}^*$ and power management $y_j^*$ solutions to minimize carbon emissions at the edge while meeting the latency and resource constraints. The problem is formulated as follows: 

{\small 
\begin{align}
    %\tag{2.1}
    \label{eq:objective}
    & \min_{\substack{x_{ij}^*, y_j^*}}  \quad f  \quad \quad \quad \quad \text{s.t. Constraints 1-5 hold. }
\end{align}
}

% \noindent{\bf Dimensionality reduction.} Edge servers $\mathcal{S}$ are grouped by edge data center locations $\mathcal{L}$, with $S_l$ servers at location $l$. A na\"{\i}ve 3D formulation (application-location-server) requires  $|A| \times |L| \times max(S_l)$ variables. However, server distributions are often skewed (e.g., urban areas have denser deployments), making $\sum_{l \in \mathcal{L}} S_l\ll |L| \times max(S_l)$. By flatting to a 2D model (application-server), we reduce the variable count to $|A| \times S_{total}$, where $S_{totoal} = \sum_{l \in \mathcal{L}} S_l$. For $|A|=100$, $|L|=5$, $max(S_l)=20$, and $|S_{total}|=50$, this cuts variables from 10,000 to 5,000--a 50\% reduction.  Importantly, our model preserves locality: servers retain location-specific attributes (e.g., $I_j$ and $L_{ij}$), so constraints remain semantically unchanged. 

 
\noindent{\bf Extensions.} The above formulation focuses on reducing carbon emissions as a primary goal while considering edge latency as a constraint. Alternatively, a multi-objective optimization can be employed to minimize both carbon emissions and latency. Additionally, other objectives like energy usage can also be optimized alongside carbon in a similar fashion. In ~\autoref{sec:eval_carbon_energy}, we  demonstrate the benefits of such a multi-objective optimization strategy, which navigates the trade-offs between carbon emissions and energy usage in edge computing.

% As discussed in ~\autoref{sec:eval_carbon_energy}, this multi-objective optimization strategy is advantageous for navigating the trade-offs between carbon emissions and energy usage in edge computing.



\begin{algorithm}[t]
\scriptsize
\caption{\proposedsystem Incremental Placement Algorithm}
\label{alg:algorithm}
\raggedright
\textbf{Input:} Arriving applications $\mathcal{A}$,  Servers $\mathcal{S}$, Latency requirements $\boldmath{\ell}$, Resource demands $\mathbf{R}$, and Energy consumption $\mathbf{E}$ \\
\textbf{Output:} Placement ($\mathbf{x}$) and Power ($\mathbf{y}$) decisions.
\begin{algorithmic}[1]
\State Initialize latency matrix $\mathbf{L} \gets \emptyset$
\For{each application $a_i \in \mathcal{A}$}
\For {each server $s_j \in \mathcal{S}$}
\State $\mathbf{L}_{ij} \gets \textsc{CalculateLatency}(a_i, s_j)$ \label{ln:latency_calc} \Comment{Get application-server latency\quad }
% \State $\mathbf{L} \gets \mathbf{L} \cup L_{ij}$
\EndFor
\EndFor

\State $\mathcal{S}', \mathbf{L}' \gets \textsc{FilterFeasibleServers}(\mathcal{A}, \mathcal{S}, \mathbf{L}, \boldmath{\ell})$ \label{ln:preprocess} \Comment{Select servers satisfying latency limits}

\State $\mathbf{C}, B, \bar{I}, \mathbf{y}^{curr} \gets \textsc{GetServerStates}(\mathcal{S}')$ 
\Comment{Available capacities $\mathbf{C}$, base power $B$, mean carbon intensity $\bar{I}$, current power states $\mathbf{y}^{curr}$ }

\State $\mathbf{x}, \mathbf{y} \gets \textsc{SolveOptimization}(\mathcal{A}, \mathcal{S}', \boldmath{\ell}, \mathbf{R}, \mathbf{E}, \mathbf{C}, B, \bar{I} , \mathbf{y}^{curr}, \mathbf{L}')$ \label{ln:solve}
\Comment{Solve \autoref{eq:objective}}

\State $\mathbf{C}' \gets \textsc{UpdateServerStates}(\mathbf{x}, \mathbf{y}, \mathcal{C})$ \label{ln:update}
\Comment{Update servers capacity}  \\

\Return $\mathbf{x}, \mathbf{y}$
\end{algorithmic}
\end{algorithm}


\subsection{\proposedsystem Placement Algorithm}\label{sec:design_algorithm}
Our placement algorithm assumes that latency-sensitive edge applications may arrive unpredictably and need to be placed onto edge data centers in a carbon-aware manner. To achieve this, \proposedsystem employs an incremental placement strategy, executing the algorithm periodically to process newly arriving applications as a batch, to ensure carbon-efficient placement without global recomputation, as shown in \autoref{alg:algorithm}.

The algorithm places a set of arriving applications $\mathcal{A}$ (with latency requirements $\boldmath\ell$, resource demands $\mathbf{R}$, and energy profiles $\mathbf{E}$) across edge servers $\mathcal{S}$ in mesoscale data centers. First, it computes application-server latency $\mathbf{L}$ and prunes (i.e., filters out) servers exceeding latency constraints, retaining only feasible candidates $\mathcal{S}' \in \mathcal{S}$ (line 1-8). Next, it retrieves server telemetry (available capacity $\mathbf{C}$, base power $B$, current power state $y^{curr}$) and  mean carbon intensity $\bar{I}$ (line 9). Then, it solves the optimization in ~\autoref{eq:objective} using the latency-compliant server set $\mathcal{S}'$ to ensure traceability. 
Placing incoming applications in small batches in real-time can be done efficiently---our  result in ~\autoref{sec:eval_overhead} shows that  incremental placement of a batch of 50 newly arriving applications across 400 servers completes in 3 seconds (line 10). Finally, \proposedsystem commits the resource allocation and power state transition, updating server states for the next iteration (line 11).


% periodically and incrementally places all newly arriving applications as a batch as shown in  \autoref{alg:algorithm}. 
%The problem formulation above relies on detailed knowledge of all applications' resource requirements and carbon intensity and assumes all applications are ready upfront. In practice, however, carbon intensity forecasts are only available for a few days, and applications arrive \emph{incrementally}, stay for arbitrary time, and request rates may change with time.
%\autoref{alg:algorithm} illustrates the steps to place a new application or a batch of applications in a carbon-aware manner. 



% The first step is to estimate the resource requirements of each new application by profiling it for $t$ seconds or utilizing a performance model~\cite{paleo,justus2018,cai2017neuralpower, performance_modeling}. After estimating the applications' resource requirements, the placement service utilizes ILP formulation in equations ~\ref{eq:objective}-\ref{eq:binary} while only considering the new applications and the idle resources. Note that, we utilize $\hat{I}_j$ instead of the time-varying carbon intensity $I_j^t$ and to ensure consistency with the current status, we add a constraint $y_j^{curr} \leq y_j \forall j$, which ensures that {\em powered-on} servers remains on. The resource utilization of servers at all edge locations is updated using the computed placement for the next iteration.


% Edge applications exhibit different duration requirements depending on the use cases, such as long-term and short-lived applications. To address these variations, \proposedsystem implements two optimization strategies.

% \noindent{\bf Long-term applications.}
% Applications such as smart city infrastructure monitoring or industrial automation systems demand uninterrupted long-term execution and tolerate gradual deployment optimizations and periodic re-optimization. The Placement Service solves the ILP problem exactly to identify the optimal placement and power management plan. 

% % Note that the computational overhead to solve the ILP does not interfere with application latency requirements, as \proposedsystem operates on a dedicated orchestration server isolated from edge work execution. 

% \noindent{\bf Short-lived applications.} Conversely, short-lived applications (e.g., augmented reality (AR) rendering) require sub-second placement with stringent latency constraints. We use a greedy heuristic to address the time-sensitive placement needs of short-lived applications. The algorithm first filters candidate edge servers that satisfy the application's latency (\autoref{eq:comp_cap}) and resource requirements (\autoref{eq:latency}). Next, for each candidate, it estimates the carbon emissions using the objective function defined in~\autoref{eq:objective} and selects the server yielding the minimum emissions. 
% Additionally, idle servers are automatically powered off post-execution to minimize carbon emissions. 


% \noindent{\bf Applications profiles.} Application profiles, such as resource demands $R_{ij}^k$ and energy consumption $E_{ij}$, are essential for making the placement decisions. These profiles can be obtained by profiling applications on servers or estimating using existing methods~\cite{XXX}. 

% \noindent{\bf Dynamic workloads.} The workloads of edge applications fluctuate over time. To maximize carbon emission reductions without compromising service continuity, \proposedsystem can integrate with the auto-scaler of the Edge Orchestrator, optimizing replica placement and managing workload distribution via the load balancer. 

% \noindent{\bf Temporal carbon intensity.} 
% \noindent{\bf Workload Fluctuation.} 



% \subsection{\proposedsystem Implementation}
% Lastly, we present the implementation of \proposedsystem, built on top of Sinfonia~\cite{satyanarayanan2022sinfonia}, an open-source orchestrator for edge-native applications. Our implementation realizes the \proposedsystem components as follows:

% \noindent\textbf{Carbon Intensity Service}: We built our carbon intensity service by integrating historical traces from Electricity Maps~\cite{electricity-map} and using the traces to provide real-time and forecast carbon intensity.

% \noindent\textbf{Telemetry Service}: \proposedsystem collects real-time performance, resource, and energy consumption telemetry from edge data centers. These telemetries are based on Prometheus monitoring stacks. We augmented Prometheus with power monitoring capabilities. To measure the power consumption of CPU servers using RAPL~\cite{david2010rapl}, while for GPU servers, we leveraged Prometheus's DGCM exporter~\cite{nvidia_dcgm_exporter_github}. 
% Our telemetries are integrated into Sinfoniaâ€™s dynamic attributes and updated periodically. Additionally, we include latency data based on round-trip time (RTT) measurements from WonderNetwork. Finally, alongside the telemetries, we implement an application profiling service that gathers application performance metrics, such as latency, power consumption, resource demands, and other crucial information for accurate placement decisions across available resources. 


% \noindent\textbf{Placement Service}: We implement the placement service with Python, and the carbon-aware placement optimization is solved using the Google OR-Tools~\cite{ortools}, an interface to the branch and cut solver. It gets the configuration of applications and edge data centers and outputs the placement and power management decisions to the edge orchestrator. 

% % The \proposedsystem placement service encompasses the carbon-aware placement and power management decisions across different edge data centers. As we detailed in ~\autoref{sec:design_algorithm}, 
% % the placement service integrates its knowledge of the carbon intensity, resource requirements, and load to compute the decisions that optimize the total carbon emissions while ensuring that resource and performance constraints are strictly met. 
% % We implement \autoref{alg:algorithm} using Python and Google OR-Tools~\cite{ortools}. 


% \noindent\textbf{Edge Orchestrator}: We leverage Sinfonia, which is built on top of Kubernetes~\cite{kubernetes}, to deploy and manage server states. After getting the placement decisions, Sinfonia initiates the deployment sequence (Sinfonia RECIPE) to the destination servers or activates servers if necessary and informs the client(s) of the destination's address.  Note that although Sinfonia is packed with fault-tolerance and reconfiguration capabilities, evaluating them is beyond the scope of this paper.

% In addition to the prototype of \proposedsystem, we developed a simulator for large-scale placement evaluations, in which we simulate diverse edge settings with dynamic workloads and heterogeneous servers. This simulator implements the carbon-aware placement policy and other baseline policies using Google OR-Tools~\cite{ortools}. The simulator and the \proposedsystem policies were implemented in Python with approximately 1,000 lines of code.


% The placement policy is to minimize the carbon emissions of edge data centers, including emissions from applications and powered-on servers. The carbon emission of applications are $\sum_{i=1}^N \sum_{j=1}^M x_{ij} \cdot E_{ij} \cdot I_j$, and the emissions from active servers are $\sum_{j=1}^M y_{j} \cdot B_{j} \cdot I_j$, and the total carbon emissions is:

% {\small 
% \begin{align}
%     %\tag{2.1}
%     \label{eq:objective}
%     & C(t) =  \sum_{i=1}^N \sum_{j=1}^M x_{ij} \cdot E_{ij} \cdot I_j^t + \sum_{j=1}^M y_{j} \cdot B_{j} \cdot I_j^t
% \end{align}
% }

% {\small 
% \begin{align}
%     %\tag{2.1}
%     \label{eq:objective}
%     & \text{min} \quad \mathcal{C}^{total} \\
%     &\mathcal{C}^{total} =  \sum_{j=1}^M y_j \cdot  \mathcal{C}_{j}^{base} + \sum_{i=1}^N \sum_{j=1}^M x_{ij} \cdot \mathcal{C}_{ij}^{app} \quad & \nonumber \\
%     &\mathcal{C}_{ij}^{app} = \sum_{t\in T_i} E_{ij} \cdot I_j^t \quad , \quad \mathcal{C}_{j}^{base} = \sum_{t\in T_i} P_j^{base} \cdot I_j^t & \nonumber \\
%     \textbf{s.t.} \quad &  \nonumber \\
%     %\tag{2.2}
%     \label{eq:comp_cap}
%     & \sum_{i=1}^N x_{ij} \cdot R_{ij}^k \leq y_j \cdot \mathcal{R}_j^{k}, \quad \forall j, k \\
%     %\tag{2.3}
%     % \label{eq:band_cap}
%     % & \sum_{i=1}^N x_{ij} \cdot B_{ij} \leq y_j \cdot B_j^{max}, \quad \forall j \\
%     %\tag{2.4}
%     \label{eq:latency}
%     & x_{ij} \cdot L_{ij} \leq L_i, \quad \forall i, \forall j \\
%     %\tag{2.5}
%     \label{eq:placement}
%     & \sum_{j=1}^M x_{ij} = 1, \quad \forall i \\
%     %\tag{2.6}
%     \label{eq:server_on}
%     & x_{ij} \leq y_j, \quad \forall i, \forall j\\
%     %\tag{2.7}
%     \label{eq:binary}
%     & x_{ij}, y_j \in \{0,1\}, \quad \forall i, \forall j
% \end{align}
% }




% We define the carbon-aware placement problem as a minimization problem of the total carbon emissions from active applications and base power from {\em powered-on} servers while satisfying the application's resource and latency requirements.  Further, \proposedsystem formulates this as an integer linear programming (ILP) problem. The variables used in the problem are summarized in Table~\ref{tab:notations}. 

% Two binary decision variables are used: \todo{We just repeated what is in the table.}

% \begin{enumerate}
%     \item $x_{ij} \in \{0, 1\}$, where $x_{ij} = 1$  indicates that application $a_i$ is placed on server $s_j$, and $x_{ij}=0$ otherwise;
%     \item $y_j \in \{0, 1\}$, where $y_j = 1$ indicates that server $s_j$ is {\em powered-on}, and $y_j = 0$ indicates the server is {\em powered-off}.   
% \end{enumerate}

% We formulate the problem as a minimization problem as follows: 

% As shown, \autoref{eq:objective} aims to minimize the total carbon emissions of application execution and base power, where emissions  
% of running application, $a_i$ on server $s_j$ is defined as ${C}_{ij}^{app}$, which considers the energy consumption and the time-varying carbon intensity across different servers, and the carbon emission from base power from {\em powered-on} servers, denotes as $\mathcal{C}_{j}^{base}$.
% \autoref{eq:comp_cap} ensures that the server's various resource capacities are not exceeded, accounting for heterogeneity in server resources. In particular, we utilize three types of resources: utilization, memory, and bandwidth, where we estimate the utilization based on the application's processing time and request rate~\cite{Clockwork}.% following the method described in~\cite{weee21, Clockwork}.
% ~\autoref{eq:latency} enforces that the end-to-end latency from application $a_i$ to server $s_j$ does not exceed the application's allowable latency. \autoref{eq:placement} ensures each application is placed on exactly one server, while \autoref{eq:server_on} guarantees that an application can only be placed on {\em powered-on} servers. Finally, \autoref{eq:binary} ensures that the decision variables are binary.



%Note that although the above only considers carbon emissions in its objectives and considers latency as energy consumption as part of the constraints and by-product of the carbon savings. Augmenting \autoref{eq:objective} with energy or latency objectives and formulating the problem as a multi-objective optimization is beneficial in navigating the carbon-latency and carbon-energy trade-offs, as we will show in ~\autoref{sec:hetero}.

% \begin{algorithm}[t]
% \footnotesize
% \caption{\proposedsystem Algorithm}
% \label{alg:algorithm}
% \raggedright
% \textbf{Input:} New Applications $N$, Latency Requirements $L$, Servers $M$, Power status $y^{curr}$, Available Resources $\mathcal{R}^{idle}$, and Mean Carbon Intensity $\mathcal{\bar{I}}$. \\
% \textbf{Output:} Placement ($x$) and Power ($y$) decisions.
% \begin{algorithmic}[1]
% \State $\hat{R} \gets []$
% \For{$a_i \in N$}
% \For {$s_i \in M$}
% \State $R_{ij}^k \gets$ \text{Profile}$(a_i, s_j)$ \Comment{Profile or estimate resource requirements.\quad \quad \quad \quad \quad \quad \quad \quad \quad \quad \quad }
% \State $\hat{R}.\text{append}(R_{ij})$\
% \EndFor
% \EndFor
% \State $x,y \gets$ Solve Optimization($N, L, M, y^{curr}, \hat{R}, \mathcal{R}^{idle} , \mathcal{\hat{I}}$)\\
% \Return $x,y$
% \end{algorithmic}
% \end{algorithm}


% \begin{algorithm}[t]
% \footnotesize
% \caption{\proposedsystem Algorithm}
% \label{alg:algorithm}
% \raggedright
% \textbf{Input:} New Applications $N$, Latency Requirements $L$, Servers $M$, Power status $y^{curr}$, Available Resources $\mathcal{R}^{idle}$, and Mean Carbon Intensity $\mathcal{\bar{I}}$. \\
% \textbf{Output:} Placement ($x$) and Power ($y$) decisions.
% \begin{algorithmic}[1]
% \State $\hat{R} \gets []$
% \For{$a_i \in N$}
% \For {$s_i \in M$}
% \State $R_{ij}^k \gets$ \text{Profile}$(a_i, s_j)$ \Comment{Profile or estimate resource requirements.\quad \quad \quad \quad \quad \quad \quad \quad \quad \quad \quad }
% \State $\hat{R}.\text{append}(R_{ij})$\
% \EndFor
% \EndFor
% \State $x,y \gets$ Solve Optimization($N, L, M, y^{curr}, \hat{R}, \mathcal{R}^{idle} , \mathcal{\hat{I}}$)\\
% \Return $x,y$
% \end{algorithmic}
% \end{algorithm}





% \subsection{Online Placement Algorithms}\label{sec:design_algorithm}
% Our edge placement algorithm assumes that new applications can arrive into the system at any time and need to be placed onto edge data centers in a carbon-aware manner while meeting their latency constraints. To do so, we assume that the algorithm runs periodically and incrementally places all newly arriving applications as a batch as shown in  \autoref{alg:algorithm}. 
% %The problem formulation above relies on detailed knowledge of all applications' resource requirements and carbon intensity and assumes all applications are ready upfront. In practice, however, carbon intensity forecasts are only available for a few days, and applications arrive \emph{incrementally}, stay for arbitrary time, and request rates may change with time.
% %\autoref{alg:algorithm} illustrates the steps to place a new application or a batch of applications in a carbon-aware manner. 
% As shown, the algorithm takes the set of new applications $N$, their latency requirements, the set of servers $M$, their power status $y^{curr}$, available resource $\mathcal{R}^{idle}$, and a per-location forecast of mean carbon intensity $\bar{I}$. The first step is to estimate the resource requirements of each new application by profiling it for $t$ seconds or utilizing a performance model~\cite{paleo,justus2018,cai2017neuralpower, performance_modeling}. After estimating the applications' resource requirements, the placement service utilizes ILP formulation in equations ~\ref{eq:objective}-\ref{eq:binary} while only considering the new applications and the idle resources. Note that, we utilize $\hat{I}_j$ instead of the time-varying carbon intensity $I_j^t$ and to ensure consistency with the current status, we add a constraint $y_j^{curr} \leq y_j \forall j$, which ensures that {\em powered-on} servers remains on. The resource utilization of servers at all edge locations is updated using the computed placement for the next iteration.

% \begin{align}
%     %\tag{2.1}
%     \label{eq:objective_alg}
%     & \text{min} \quad \mathcal{C}^{total} =  \sum_{j=1}^M y_j \cdot  \mathcal{C}_{j}^{base} + \sum_{i=1}^N \sum_{j=1}^M x_{ij} \cdot \mathcal{C}_{ij}^{app} \quad & \\
%     &\mathcal{C}_{ij}^{app} = E_{ij} \cdot \bar{I_j} \quad , \quad \mathcal{C}_{j}^{base} =  P_j^{base} \cdot \bar{I_j} & \nonumber \\
%     \textbf{s.t.} \quad &  \nonumber \\
%     %\tag{2.2}
%     \label{eq:comp_cap_alg}
%     & \sum_{i=1}^N x_{ij} \cdot R_{ij}^k \leq y_j \cdot \mathcal{R}_j^{k}, \quad \forall j, k \\
%     %\tag{2.3}
%     % \label{eq:band_cap}
%     % & \sum_{i=1}^N x_{ij} \cdot B_{ij} \leq y_j \cdot B_j^{max}, \quad \forall j \\
%     %\tag{2.4}
%     \label{eq:latency_alg}
%     & x_{ij} \cdot L_{ij} \leq L_i, \quad \forall i, \forall j \\
%     %\tag{2.5}
%     \label{eq:placement_alg}
%     & \sum_{j=1}^M x_{ij} = 1, \quad \forall i \\
%     %\tag{2.6}
%     \label{eq:server_on_alg}
%     & x_{ij} \leq y_j, \quad \forall i, \forall j\\
%     %\tag{2.7}
%     \label{eq:binary_alg}
%     & x_{ij}, y_j \in \{0,1\}, \quad \forall i, \forall j
% \end{align}



% Given an edge network, it includes geographically dispersed edge data centers containing a total of $M$ servers, represented as $S = \{s_1, s_2, ..., s_M\}$. Each server $s_j$ is equipped with various resources--such as CPU, Memory, and Bandwidth--where $C_j^k$ indicates the maximum available resources of type $k$ on server $j$. Furthermore, each {
% \em powered-on} server has a base power consumption denoted by $B_j$. Every server $s_j$ resides in an edge data center and is powered by an energy source that has a carbon intensity value, $I_j$, which is time-varying according to the mix of energy sources available in that area.

% Let us consider, at time $t$,  $N$ application placement requests arrive,  represented as $A = \{a_1, a_2, ..., a_N\}$. These placement requests can be from various locations, and each application $a_i$ comes with specific latency requirements $L_i$, alongside energy consumption and resource needs. These energy consumption rates and resource requirements differ depending on the edge servers hosting them (refer to ~\autoref{fig:models_profile}). When an application $a_i$ is executed on the server $s_j$, its resource demand is indicated as $R_{ij}^k$, while the energy consumption is represented as $E_{ij}$. Additionally, the end-to-end latency connecting the workload of application $a_i$ to server $s_j$ is denoted by $L_{ij}$.

% We define two decision variables. Let $x_{ij} \in \{0, 1\}$ indicate the application placement decision, where $x_{ij} = 1$ means that application $a_i$ is placed on server $s_j$, and $x_{ij} = 0$ otherwise. Let $y_j \in \{0, 1\}$ indicate the server power status, where $y_j = 1$ indicates that server $s_j$ is turned on, and $y_j = 0$ indicates that the server is off. 

% These variants need to meet four constraints. First, the request demands cannot exceed the resource capacity of powered-on servers (\autoref{eq:comp_cap}). Second, the placements need to meet latency limits (\autoref{eq:latency}). Third, all applications need to be placed on a server (\autoref{eq:placement}). Fourth, applications can only be placed on powered-on servers (\autoref{eq:server_on}). Fifth, a powered-on server cannot be powered off. We formulate the four constraints as follows.

% {\small 
% \begin{align}
%     \label{eq:comp_cap}
%     & \sum_{i=1}^N x_{ij} \cdot R_{ij}^k \leq y_j \cdot C_j^{k}, \quad \quad \quad \quad  \forall j, k \\
%     %\tag{2.4}
%     \label{eq:latency}
%     & x_{ij} \cdot L_{ij} \leq L_i, \quad \quad \quad \quad \quad \quad \quad \quad \forall i, j \\
%     %\tag{2.5}
%     \label{eq:placement}
%     & \sum_{j=1}^M x_{ij} = 1, \quad \quad \quad \quad \quad  \quad \quad \quad \quad \quad \forall i \\
%     %\tag{2.6}
%     \label{eq:server_on}
%     & x_{ij} \leq y_j, \quad \quad \quad \quad \quad  \quad \quad \quad \quad \quad \forall i, j \\
%     \label{eq:server_keep_on}
%     & y_j^{curr} \leq y_j, \quad \quad \quad \quad \quad  \quad \quad \quad \quad \quad \forall j
% \end{align}
% }