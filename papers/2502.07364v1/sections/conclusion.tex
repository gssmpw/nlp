\section{Conclusion}

Our analysis points out a key assumption in algorithms designed for training deep GNNs: the idea that if a deep GNN is trainable, it must be able to model LRIs. % In other words, that alleviating the problem of over-smoothing is sufficient to ensure that deep GNNs can be effective at long-range tasks.
Our results suggest that this, in fact, need not be true -- we theoretically and empirically show that DropEdge-like algorithms exacerbate the over-squashing problem in deep GNNs, and degrade their performance on long-range tasks. Our results highlight a need for a thorough evaluation of methods employed when training deep GNNs, with regards to their capacity to capture LRIs. This will allow us to reliably deploy them in real-life, since we can be assured that the models did not simply overfit to short-range signals.

\textbf{Limitations}. While our theoretical analysis successfully predicts how DropEdge-variants affect test performance on short-range and long-range tasks, it is based on several simplifying assumptions. These assumptions, although standard in the literature, limit the generalizability of our conclusions to other architectures. Specifically, our analysis focuses on certain classes of MPNNs, excluding several GNN architectures specifically designed to enhance long-distance information propagation (see \citet{akansha2024oversquashinggraphneuralnetworks} for a review). % (\autoref{sec:related}). % To our knowledge, DropEdge-variants has not been evaluated with such architectures; it can be interesting to study their compatibility in the context of long-range tasks.

\textbf{Practical Considerations}. Previous studies have shown that random edge-dropping algorithms can effectively enhance generalization performance in short-range tasks, and our findings support this conclusion. However, we have also demonstrated that such algorithms can negatively impact over-squashing in MPNNs and harm test-time performance in long-range tasks. Therefore, we recommend exercising caution when using such methods, as careless application can result in models that generalize poorly, which can be detrimental in critical applications.

\textbf{Future Directions}. This work focuses on node-classification tasks, but it is also important to understand the effect of random edge-dropping in other practical settings, \eg link prediction, and even graph-level tasks. In general, there is a need for a broader investigation into methods designed for training deep \inline{GNNs}. % (\autoref{sec:related}).
Specifically, analyzing various strategies designed for mitigating over-smoothing (see \citet{rusch2023surveyoversmoothinggraphneural} for a review), particularly in the context of over-squashing, could be invaluable for designing deep \inline{GNNs} for long-range tasks.