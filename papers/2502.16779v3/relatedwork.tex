\section{Related Work}
% \xd{squeeze to half}

\paragraph{Layout estimation.}
Most room layout estimation research focuses on single-perspective image inputs. \cite{stekovic2020general} formulates layout estimation as a constrained discrete optimization problem to identify 3D polygons. \cite{yang2022learning} introduces line-plane constraints and connectivity relations between planes for layout estimation, while \cite{sun2019horizonnet} formulates the task as predicting 1D layouts.  
Other studies, such as \cite{zou2018layoutnet}, propose to utilize monocular 360-degree panoramic images for more information.
% For example, \citep{zou2018layoutnet} propose a layout estimation algorithm that is suitable for both perspective and panoramic images. 
Several works extend the input setting from single panoramic to multi-view panoramic images, \textit{e.g.} \cite{wang2022psmnet} and \cite{hu2022mvlayoutnet}.
However, there is limited research addressing layout estimation from multi-view RGB perspective images. \cite{howard2019thinking} detects and regresses 3D piece-wise planar surfaces from a series of images and clusters them to obtain the final layout, but this method requires posed images. The most related work is \cite{jin2021planar}, which focuses on a different task: reconstructing indoor scenes with planar surfaces from wide-baseline, unposed images. It is limited to two views and requires an incremental stitching process to incorporate additional views.

\paragraph{Holistic scene understanding.}
Traditional 3D indoor reconstruction methods are widely applicable but often lack explicit semantic information. To address this limitation, recent research has increasingly focused on incorporating holistic scene structure information, enhancing scene understanding by improving reasoning about physical properties, mostly centered on single-perspective images. Several studies have explored the detection of 2D line segments using learning-based detectors~\citep{zhou2019end, pautrat2021sold2, dai2022fully}. However, these approaches often struggle to differentiate between texture-based lines and structural lines formed by intersecting planes. Some research has focused on planar reconstruction to capture higher-level information \citep{liu2018planenet,yu2019single,liu2019planercnn}. Certain studies \citep{huang2018holistic,nie2020total3dunderstanding,sun2021hohonet} have tackled multiple tasks alongside layout reconstruction, such as depth estimation, object detection, and semantic segmentation.
% For instance, \cite{huang2018holistic} introduces a parsed graph representation to capture the contextual relations between objects
% and room layout. \cite{nie2020total3dunderstanding} reconstructs room layouts alongside object bounding boxes and meshes.
% % , providing a more comprehensive understanding of indoor scenes.
% \cite{sun2021hohonet}  simultaneously addresses layout reconstruction, depth estimation, and semantic segmentation. 
Other works operate on constructed point maps; for instance, \cite{yue2023connecting}  reconstructs floor plans from density maps by predicting sequences of room corners to form polygons. SceneScript \citep{avetisyan2024scenescript} employs large language models to represent indoor scenes as structured language commands.

% However, few works focus on multi-view RGB perspective image structural reconstruction. \citep{jin2021planar}  presents the most relevant work, reconstructing indoor scenes with planar surfaces from sparse, unposed views. Nevertheless, it is limited to two views and requires incremental stitching for additional views. Their method often results in independent and incomplete planar segments due to occlusions. Our approach addresses these challenges by jointly processing multiple images to produce more complete layout planes with relational constraints.

\paragraph{Multi-view pose estimation and reconstruction.}
 The most widely applied pipeline for pose estimation and reconstruction on a series of images involves SfM \citep{schoenberger2016sfm} and MVS \citep{schoenberger2016mvs}, which typically includes steps such as feature mapping, finding correspondences, solving triangulations and optimizing camera parameters. Most mainstream methods build upon this paradigm with improvements on various aspects of the pipeline. However, recent works such as DUSt3R \citep{wang2024dust3r} and MASt3R \citep{leroy2024grounding} propose a reconstruction pipeline capable of producing globally-aligned pointmaps from unconstrained images. This is achieved by casting the reconstruction problem as a regression of pointmaps, significantly relaxing input requirements and establishing a simpler end-to-end paradigm for 3D reconstruction.