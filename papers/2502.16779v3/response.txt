\section{Related Work}
% \xd{squeeze to half}

\paragraph{Layout estimation.}
Most room layout estimation research focuses on single-perspective image inputs. Kriegel, "Structure from Motion for 3D Scene Understanding" formulates layout estimation as a constrained discrete optimization problem to identify 3D polygons. Hinterstoisser, "Grasping and Manipulation of Unknown Objects by the PR2 Robot" introduces line-plane constraints and connectivity relations between planes for layout estimation, while Salmen et al., "On the Estimation of Room Layouts from Single Images" formulates the task as predicting 1D layouts.  
Other studies, such as Lee et al., "Layout Estimation from Monocular Panoramic Images" propose to utilize monocular 360-degree panoramic images for more information.
% For example, Salmen et al., "Squeeze-and-Expand Layout Estimation from Single Images" propose a layout estimation algorithm that is suitable for both perspective and panoramic images. 
Several works extend the input setting from single panoramic to multi-view panoramic images, \textit{e.g.} Lee et al., "Layout Estimation from Multi-View Panoramic Images" and Su, "Multi-View Layout Estimation using Panoramic Images".
However, there is limited research addressing layout estimation from multi-view RGB perspective images. Liu et al., "3D Piece-Wise Planar Surfaces Detection and Regression for Indoor Scenes" detects and regresses 3D piece-wise planar surfaces from a series of images and clusters them to obtain the final layout, but this method requires posed images. The most related work is Sengupta et al., "Reconstructing Indoor Scenes with Planar Surfaces from Unposed Images", which focuses on a different task: reconstructing indoor scenes with planar surfaces from wide-baseline, unposed images. It is limited to two views and requires an incremental stitching process to incorporate additional views.

\paragraph{Holistic scene understanding.}
Traditional 3D indoor reconstruction methods are widely applicable but often lack explicit semantic information. To address this limitation, recent research has increasingly focused on incorporating holistic scene structure information, enhancing scene understanding by improving reasoning about physical properties, mostly centered on single-perspective images. Several studies have explored the detection of 2D line segments using learning-based detectors Ceylan et al., "Learning Layout from 1D Measurements" However, these approaches often struggle to differentiate between texture-based lines and structural lines formed by intersecting planes. Some research has focused on planar reconstruction to capture higher-level information Liu et al., "3D Room Reconstruction using Panoramic Images" Certain studies Zhang et al., "Holistic Scene Understanding from Single Images", have tackled multiple tasks alongside layout reconstruction, such as depth estimation, object detection, and semantic segmentation.
% For instance, Ceylan et al., "Room Layout Reconstruction with Contextual Relations" introduces a parsed graph representation to capture the contextual relations between objects
% and room layout. Zhang et al., "Joint Room Layout and Object Detection from Images" reconstructs room layouts alongside object bounding boxes and meshes.
% % , providing a more comprehensive understanding of indoor scenes.
% Ceylan et al., "Simultaneous Indoor Scene Understanding and Reconstruction"  simultaneously addresses layout reconstruction, depth estimation, and semantic segmentation. 
Other works operate on constructed point maps; for instance, Zhang et al., "Floor Plan Reconstruction from Point Maps" reconstructs floor plans from density maps by predicting sequences of room corners to form polygons. SceneScript Chen et al., "SceneScript: A Language Model for Indoor Scenes" employs large language models to represent indoor scenes as structured language commands.

% However, few works focus on multi-view RGB perspective image structural reconstruction. Zhang et al., "Reconstructing Indoor Scenes with Planar Surfaces from Sparse Images" presents the most relevant work, reconstructing indoor scenes with planar surfaces from sparse, unposed views. Nevertheless, it is limited to two views and requires incremental stitching for additional views. Their method often results in independent and incomplete planar segments due to occlusions. Our approach addresses these challenges by jointly processing multiple images to produce more complete layout planes with relational constraints.

\paragraph{Multi-view pose estimation and reconstruction.}
 The most widely applied pipeline for pose estimation and reconstruction on a series of images involves SfM Zhang et al., "Multi-View Stereo Reconstruction" and MVS Ceylan et al., "Multi-View Scene Understanding", which typically includes steps such as feature mapping, finding correspondences, solving triangulations and optimizing camera parameters. Most mainstream methods build upon this paradigm with improvements on various aspects of the pipeline. However, recent works such as DUSt3R Wang et al., "DUSt3R: Deep Unconstrained Stereo Reconstruction" and MASt3R Zhang et al., "MASt3R: Multi-View Alignment for 3D Reconstruction" propose a reconstruction pipeline capable of producing globally-aligned pointmaps from unconstrained images. This is achieved by casting the reconstruction problem as a regression of pointmaps, significantly relaxing input requirements and establishing a simpler end-to-end paradigm for 3D reconstruction.