\section{Related Work}
\subsection{Unsupervised Anomaly Detection Methods}

Unsupervised anomaly detection methods are widely applied in industrial quality inspection, medical image analysis, and other related fields. Unlike supervised approaches, these methods do not rely on labeled anomalous samples, but instead use only normal samples for training. These methods can be classified into three main categories: distribution modeling-based \cite{salehi2021multiresolution}, \cite{bergmann2020uninformed}, \cite{cao2022informative}, reconstruction-based \cite{gong2019memorizing}, \cite{zavrtanik2021reconstruction}, \cite{yang2020dfr}, \cite{zavrtanik2021draem}, \cite{tao2022unsupervised}, \cite{bergmann2018improving}, and self-supervised or knowledge extraction-based \cite{he2020momentum}, \cite{zhang2024realnet}, \cite{li2021cutpaste}, \cite{schluter2022natural}, \cite{zhang2023prototypical}, \cite{zhang2023destseg}, \cite{yuan2023causality} approaches. Our research extends unsupervised anomaly detection by integrating generative and discriminative tasks into a unified framework, where we leverage diffusion models to generate diverse anomaly samples and employ probability distributions for discrimination, thereby enhancing both detection accuracy and robustness.

\subsection{Generative-Based Unsupervised Anomaly Detection Methods}

Generative models have been widely used in unsupervised anomaly detection, particularly Generative Adversarial Networks (GANs) \cite{goodfellow2014generative}, Variational Autoencoders (VAEs) \cite{kingma2013auto}, \cite{vincent2008extracting}, Flow-based models \cite{dinh2016density}, and diffusion models. AnoGAN \cite{schlegl2017unsupervised} was an early attempt to apply GANs to anomaly detection by generating anomaly samples and using a discriminator for detection. However, it faced challenges such as mode collapse, limiting the diversity of generated samples. Ganomaly \cite{akcay2019ganomaly} improved this approach by using conditional GANs for anomaly detection, but adversarial training instability still hindered performance. VAE-based methods \cite{kingma2013auto} generate anomaly samples via reconstruction, but often produce blurry reconstructions, struggling to capture complex anomalies. Flow-based models like CFLOW \cite{gudovskiy2022cflow} and FastFlow \cite{yu2021fastflow} model data distributions explicitly to estimate anomaly probabilities, but they remain computationally expensive.

Recently, diffusion models have demonstrated remarkable progress in image generation. AnoDDPM \cite{wyatt2022anoddpm} introduced Denoising Diffusion Probabilistic Models (DDPMs) \cite{ho2020denoising}, \cite{rombach2022high} for anomaly detection, highlighting their potential for both generation and detection. However, high computational complexity remains a challenge. In this work, we integrate the generative capabilities of Stable Diffusion (SD) \cite{rombach2022high} models with discriminative tasks, enabling the generation of diverse anomaly samples while optimizing probability distributions for anomaly detection. This approach effectively addresses the shortcomings of existing methods in terms of both generation quality and detection performance.

\subsection{Discriminative-Based Unsupervised Anomaly Detection Methods}

Early discriminative methods, such as Ganomaly \cite{akcay2019ganomaly}, relied on GAN-based discriminators to distinguish between normal and anomalous samples, but suffered from adversarial training instability. Later, reconstruction-based methods like MemAE \cite{gong2019memorizing}, \cite{kang2024anomaly}, and DFR \cite{yang2020dfr} improved anomaly detection but often faced issues with inaccurate or overly smooth reconstructions, limiting adaptability to diverse anomaly patterns.
Diffusion models have been explored for discriminative tasks by combining generative capabilities with classification \cite{li2023your}, \cite{mukhopadhyay2023diffusion}. However, these methods are computationally expensive and still rely on prior information, limiting their efficiency in fully unsupervised tasks.

In contrast, our method directly leverages features from the denoising process of diffusion models without relying on prompts or labels. By modeling feature probability distributions and evaluating normal-anomaly differences through log-likelihood estimation, we efficiently determine the detection threshold, reducing computational costs and improving robustness in unsupervised anomaly detection.


\subsection{Innovations in Collaborative Optimization and Dual-Branch Architecture}

Collaborative optimization has been widely used in CNN-based anomaly detection \cite{akccay2019skip}, \cite{defard2021padim}, \cite{roth2022towards}, but CNNs often struggle with performance degradation when normal and anomalous sample distributions overlap. Knowledge distillation, which transfers knowledge from a teacher network to a student network, has proven effective in addressing this issue. By learning only normal feature distributions, the student network can detect anomalies through feature discrepancies. For example, ST \cite{lin2017feature} and IKD \cite{hinton2015distilling} improve anomaly localization and reduce overfitting. RD4AD \cite{deng2022anomaly} and SKD \cite{li2021cutpaste} further enhance performance by mitigating overfitting and incorporating real anomaly samples, while CDO \cite{cao2023collaborative} optimizes the distributional differences between normal and anomalous features.

Building on these advancements, we propose a dual-branch network architecture. The main branch uses a frozen Stable Diffusion model to extract features from normal samples, while the sub-branch generates anomaly samples and extracts features. By optimizing the probability distributions of these features, we enhance the distinction between normal and anomalous distributions, improving detection accuracy and robustness.