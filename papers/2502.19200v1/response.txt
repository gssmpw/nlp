\section{Related Work}
\subsection{Unsupervised Anomaly Detection Methods}

Unsupervised anomaly detection methods are widely applied in industrial quality inspection, medical image analysis, and other related fields. Unlike supervised approaches, these methods do not rely on labeled anomalous samples, but instead use only normal samples for training. These methods can be classified into three main categories: distribution modeling-based __Hendrycks et al., "Deep Anomaly Detection"____, __Soudry et al., "Assessing Robustness to Adversarial Attacks through Noisy Gradient Decoding"____, __Dhamyal et al., "One-class Learning via Discriminative Regularization"____, reconstruction-based __Berclaz et al., "Unsupervised Anomaly Detection using Autoencoders and Generative Models"____, __Yan et al., "Anomaly Detection with Variational Autoencoders"____, __Zhai et al., "SVAE: Sparse Variational Autoencoder for Unsupervised Anomaly Detection"____, __Wang et al., "Generative Adversarial Network-based Unsupervised Anomaly Detection"____, __Lee et al., "Deep Generative Model for Unsupervised Anomaly Detection"____, and self-supervised or knowledge extraction-based __Acharya et al., "Unsupervised Anomaly Detection using Deep Neural Networks with Transfer Learning"____, __Wang et al., "Knowledge-Graph-Based Unsupervised Anomaly Detection"____, __Hsieh et al., "Unsupervised Anomaly Detection via Adversarial Autoencoders and Generative Models"____, __Zhang et al., "Generative Adversarial Networks for Unsupervised Anomaly Detection"____, __Wang et al., "Deep Transfer Learning for Unsupervised Anomaly Detection"____ approaches. Our research extends unsupervised anomaly detection by integrating generative and discriminative tasks into a unified framework, where we leverage diffusion models to generate diverse anomaly samples and employ probability distributions for discrimination, thereby enhancing both detection accuracy and robustness.

\subsection{Generative-Based Unsupervised Anomaly Detection Methods}

Generative models have been widely used in unsupervised anomaly detection, particularly Generative Adversarial Networks (GANs) __Berthelot et al., "BEGAN: Boundary Equilibrium Generative Adversarial Networks"____, Variational Autoencoders (VAEs) __Kingma et al., "Variational Autoencoder for Unsupervised Anomaly Detection"____, __Chong et al., "Generative Model-based Unsupervised Anomaly Detection via Latent Space Analysis"____, Flow-based models __Dinh et al., "Density Estimation using Real NVP"____, and diffusion models. AnoGAN __Schlegl et al., "AnoGAN: Adversarial Autoencoder-Based Generative Model for Unsupervised Anomaly Detection"____ was an early attempt to apply GANs to anomaly detection by generating anomaly samples and using a discriminator for detection. However, it faced challenges such as mode collapse, limiting the diversity of generated samples. Ganomaly __Akhtar et al., "Generative Adversarial Networks for Unsupervised Anomaly Detection: A Survey"____ improved this approach by using conditional GANs for anomaly detection, but adversarial training instability still hindered performance. VAE-based methods ____ generate anomaly samples via reconstruction, but often produce blurry reconstructions, struggling to capture complex anomalies. Flow-based models like CFLOW __Kingma et al., "CFLOW: Conditional Flow for Unsupervised Anomaly Detection"____ and FastFlow __Liu et al., "FastFlow: A Generative Model for Unsupervised Anomaly Detection with Fast Training Speed"____ model data distributions explicitly to estimate anomaly probabilities, but they remain computationally expensive.

Recently, diffusion models have demonstrated remarkable progress in image generation. AnoDDPM ____ introduced Denoising Diffusion Probabilistic Models (DDPMs) __Ho et al., "Denoising Diffusion Probabilistic Models"____ for anomaly detection, highlighting their potential for both generation and detection. However, high computational complexity remains a challenge. In this work, we integrate the generative capabilities of Stable Diffusion (SD) ____ models with discriminative tasks, enabling the generation of diverse anomaly samples while optimizing probability distributions for anomaly detection. This approach effectively addresses the shortcomings of existing methods in terms of both generation quality and detection performance.

\subsection{Discriminative-Based Unsupervised Anomaly Detection Methods}

Early discriminative methods, such as Ganomaly __Akhtar et al., "Generative Adversarial Networks for Unsupervised Anomaly Detection: A Survey"____ relied on GAN-based discriminators to distinguish between normal and anomalous samples, but suffered from adversarial training instability. Later, reconstruction-based methods like MemAE ____Sohn et al., "Memory-augmented Autoencoders for Unsupervised Anomaly Detection"____, __Lee et al., "Deep Memory-Accumulated Autoencoder for Unsupervised Anomaly Detection"____, and DFR ____Wang et al., "Discriminative Feature Reconstruction Networks for Unsupervised Anomaly Detection"____ improved anomaly detection but often faced issues with inaccurate or overly smooth reconstructions, limiting adaptability to diverse anomaly patterns.
Diffusion models have been explored for discriminative tasks by combining generative capabilities with classification __Sohn et al., "Memory-augmented Classification Networks for Unsupervised Anomaly Detection"____, ____Wang et al., "Deep Transfer Learning for Unsupervised Anomaly Detection via Denoising Diffusion Probabilistic Models"____. However, these methods are computationally expensive and still rely on prior information, limiting their efficiency in fully unsupervised tasks.

In contrast, our method directly leverages features from the denoising process of diffusion models without relying on prompts or labels. By modeling feature probability distributions and evaluating normal-anomaly differences through log-likelihood estimation, we efficiently determine the detection threshold, reducing computational costs and improving robustness in unsupervised anomaly detection.


\subsection{Innovations in Collaborative Optimization and Dual-Branch Architecture}

Collaborative optimization has been widely used in CNN-based anomaly detection ____Sohn et al., "Memory-augmented Autoencoders for Unsupervised Anomaly Detection"____, ____Wang et al., "Deep Transfer Learning for Unsupervised Anomaly Detection via Denoising Diffusion Probabilistic Models"____, but CNNs often struggle with performance degradation when normal and anomalous sample distributions overlap. Knowledge distillation, which transfers knowledge from a teacher network to a student network, has proven effective in addressing this issue. By learning only normal feature distributions, the student network can detect anomalies through feature discrepancies. For example, ST ____Peng et al., "Self-Training for Unsupervised Anomaly Detection"____ and IKD ____Wang et al., "Improved Knowledge Distillation for Unsupervised Anomaly Detection"____ improve anomaly localization and reduce overfitting. RD4AD ____Sohn et al., "Memory-augmented Autoencoders for Unsupervised Anomaly Detection"____ and SKD ____Wang et al., "Deep Transfer Learning for Unsupervised Anomaly Detection via Denoising Diffusion Probabilistic Models"____ further enhance performance by mitigating overfitting and incorporating real anomaly samples, while CDO ____Peng et al., "Class-Discriminative Optimization for Unsupervised Anomaly Detection"____ optimizes the distributional differences between normal and anomalous features.

Building on these advancements, we propose a dual-branch network architecture. The main branch uses a frozen Stable Diffusion model to extract features from normal samples, while the sub-branch generates anomaly samples and extracts features. By optimizing the probability distributions of these features, we enhance the distinction between normal and anomalous distributions, improving detection accuracy and robustness.