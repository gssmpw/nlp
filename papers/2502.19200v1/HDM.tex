\documentclass[lettersize,journal]{IEEEtran}
\usepackage{amsmath,amsfonts}
\usepackage{algorithmic}
\usepackage{algorithm}
\usepackage{array}
\usepackage[caption=false,font=normalsize,labelfont=sf,textfont=sf]{subfig}
\usepackage{textcomp}
\usepackage{stfloats}
\usepackage{url}
\usepackage{verbatim}
\usepackage{graphicx}
\usepackage{cite}
\usepackage{subfig}    %% 子图包
\usepackage{float}  
\usepackage{tabularx}   % 自适应宽度
\usepackage{booktabs}   % 美化表格线
\usepackage{array}      % 增强表格格式
\usepackage{multirow}   % 多行合并
\usepackage{float}  
\usepackage{bbding}
\usepackage{utfsym}
% \usepackage{biblatex}  
% \addbibresource{ref.bib}
% \bibliography{ref}
\usepackage{color}
\usepackage{tabularx}
\usepackage{tabularray}
\usepackage{array}
\usepackage{tablefootnote}
\usepackage{booktabs}
\usepackage[flushleft]{threeparttable}
% \usepackage[backend=biber]{biblatex}




\usepackage{hyperref}
\usepackage{cleveref}
\hyphenation{op-tical net-works semi-conduc-tor IEEE-Xplore}
% updated with editorial comments 8/9/2021
\crefformat{figure}{#2Fig.~#1#3}

\begin{document}

\title{HDM: Hybrid Diffusion Model for Unified Image Anomaly Detection}

\author{ Zekang Weng\textsuperscript{1} \hspace{0.8cm} Jinjin Shi\textsuperscript{2}\thanks{Corresponding author.} \hspace{0.8cm} Jinwei Wang\textsuperscript{3}\ \hspace{0.8cm} Zeming Han\textsuperscript{4}\\
{\tt\small \{2231801015,\:2221801008\}@mail.fjut.edu.cn\textsuperscript{1,4}, shijinjinhit@sina.com\textsuperscript{2},
wangjinweige@163.com\textsuperscript{3}}}




\maketitle

\begin{abstract}
Image anomaly detection plays a vital role in applications such as industrial quality inspection and medical imaging, where it directly contributes to improving product quality and system reliability. However, existing methods often struggle with complex and diverse anomaly patterns. In particular, the separation between generation and discrimination tasks limits the effective coordination between anomaly sample generation and anomaly region detection. To address these challenges, we propose a novel hybrid diffusion model (HDM) that integrates generation and discrimination into a unified framework. The model consists of three key modules: the Diffusion Anomaly Generation Module (DAGM), the Diffusion Discriminative Module (DDM), and the Probability Optimization Module (POM). DAGM generates realistic and diverse anomaly samples, improving their representativeness. DDM then applies a reverse diffusion process to capture the differences between generated and normal samples, enabling precise anomaly region detection and localization based on probability distributions. POM refines the probability distributions during both the generation and discrimination phases, ensuring high-quality samples are used for training. Extensive experiments on multiple industrial image datasets demonstrate that our method outperforms state-of-the-art approaches, significantly improving both image-level and pixel-level anomaly detection performance, as measured by AUROC.
\end{abstract}

\begin{IEEEkeywords}
Anomaly Detection, Unsupervised, Diffusion Models, Generative and Discriminative.
\end{IEEEkeywords}



\section{Introduction}

\IEEEPARstart{I}{n} the realm of the Internet of Things (IoT), image anomaly detection plays a critical role in ensuring the reliability and security of connected systems \cite{yin2024masked}, \cite{yin2024anomaly}, \cite{wu2024novel}, \cite{wu20236g}, \cite{yue2024patch}, \cite{chu2021hybrid}. This technology is pivotal in a variety of IoT applications, such as quality control, security monitoring, intelligent manufacturing, medical image analysis, and industrial product inspection, where detecting irregularities ensures system stability and safety.

Current unsupervised approaches primarily rely on Generative Adversarial Networks (GANs) \cite{goodfellow2014generative}, Autoencoders (AEs) \cite{kingma2013auto}, and Flow models \cite{dinh2016density} to generate anomalous images and distinguish normal from anomalous samples using discriminators. Although these methods have made notable progress, they face three critical challenges: (1) GANs, AEs, and Flow-based models often suffer from mode collapse during anomaly generation, resulting in noisy, low-quality samples that lack diversity and representativeness; (2) AEs and Flow-based models separate generative and discriminative tasks, with generators reconstructing samples or estimating probability densities, while discriminators make decisions based on these outputs. Despite GANs integrating both a generator and a discriminator, the instability of adversarial training negatively impacts detection accuracy; (3) In complex scenarios, the significant overlap between normal and anomalous features hinders the generator’s ability to effectively reconstruct anomalous features and impairs the discriminator’s capacity to differentiate between them.

\begin{figure}[t] 
    \centering
    \includegraphics[width=\linewidth]{p1.pdf}  % 插入图片
    \caption{Overview of four anomaly detection methods. Existing methods based on GANs, autoencoders, and flow models separate the generative and discriminative modules. In contrast, our diffusion model-based method can simultaneously perform generative and discriminative tasks.}  % 图片标题
    \label{fig:sample}  % 用于引用的标签
\end{figure}


Previous studies have attempted to enhance the performance of GAN-based anomaly detection methods, such as MemAE \cite{deng2022anomaly}, \cite{gong2019memorizing} and AnoGAN \cite{schlegl2017unsupervised}, by incorporating memory modules and reconstruction mechanisms to improve robustness. However, these approaches still struggle with generating sufficient anomaly samples and achieving high detection accuracy. Due to the inherent limitations of GANs, they often fail to generate representative anomaly images in complex industrial settings.
Recently, Denoising Diffusion Probabilistic Models (DDPM) \cite{ho2020denoising,rombach2022high}, and related approaches have garnered significant attention for their powerful generative capabilities and exceptional performance across various tasks. Unlike GANs and AEs, diffusion models~\cite{shen2023advancing, shen2024imagpose} add Gaussian noise to training data and learn to recover samples from this noisy data. Their strength lies in their ability to make iterative, minor corrections during the generation process, resulting in more realistic and stable samples. As a result, DDPM-based methods have outperformed GAN- and AE-based methods in many generative tasks, as seen in recent works such as \cite{shen2025long}, \cite{shen2024imagdressing}, \cite{shen2024boosting}, and \cite{gao2024exploring}.


Building on the generative capabilities of diffusion models, this study introduces a hybrid diffusion-based anomaly detection method that achieves collaborative optimization of generation and discrimination through a dual-branch architecture. The main branch extracts high-quality features from normal samples, while the sub-branch generates anomaly samples and extracts features for discrimination. This design enables the training of an optimized discriminator that ensures the generation of diverse, high-quality anomaly samples while effectively distinguishing between normal and anomalous features.

Furthermore, we propose an innovative generative-discriminative loss mechanism that combines Mean Squared Error (MSE) \cite{ren2022balanced} to optimize anomaly sample generation with cross-entropy loss to enhance classification accuracy. This approach balances the diversity of generated samples with the precision of discrimination. To further improve robustness, we introduce a probability distribution optimization module that minimizes the overlap between normal and anomalous features by refining their probability distributions. This reduces the risk of misclassification, especially in complex industrial datasets. The integration of generation and discrimination makes the proposed method both efficient and accurate for anomaly detection.

Our contributions are summarized as follows:
\begin{itemize}
    \item[\textcolor{black}{$\bullet$}] We propose a hybrid diffusion model, the first to apply diffusion models to the combination of generative and discriminative tasks for anomaly detection.
    \item[\textcolor{black}{$\bullet$}] We design a novel generative-discriminative loss mechanism that not only generates high-quality anomaly images but also enhances the model's ability to distinguish between normal and anomalous samples, resolving the trade-off between sample diversity and detection task compatibility.
    \item[\textcolor{black}{$\bullet$}] We introduce a probability distribution optimization module that dynamically adjusts the weights to reduce the overlap between normal and anomalous features, improving the handling of difficult-to-classify samples, especially in complex industrial datasets.
\end{itemize}



\section{Related Work}

\subsection{Unsupervised Anomaly Detection Methods}

Unsupervised anomaly detection methods are widely applied in industrial quality inspection, medical image analysis, and other related fields. Unlike supervised approaches, these methods do not rely on labeled anomalous samples, but instead use only normal samples for training. These methods can be classified into three main categories: distribution modeling-based \cite{salehi2021multiresolution}, \cite{bergmann2020uninformed}, \cite{cao2022informative}, reconstruction-based \cite{gong2019memorizing}, \cite{zavrtanik2021reconstruction}, \cite{yang2020dfr}, \cite{zavrtanik2021draem}, \cite{tao2022unsupervised}, \cite{bergmann2018improving}, and self-supervised or knowledge extraction-based \cite{he2020momentum}, \cite{zhang2024realnet}, \cite{li2021cutpaste}, \cite{schluter2022natural}, \cite{zhang2023prototypical}, \cite{zhang2023destseg}, \cite{yuan2023causality} approaches. Our research extends unsupervised anomaly detection by integrating generative and discriminative tasks into a unified framework, where we leverage diffusion models to generate diverse anomaly samples and employ probability distributions for discrimination, thereby enhancing both detection accuracy and robustness.

\subsection{Generative-Based Unsupervised Anomaly Detection Methods}

Generative models have been widely used in unsupervised anomaly detection, particularly Generative Adversarial Networks (GANs) \cite{goodfellow2014generative}, Variational Autoencoders (VAEs) \cite{kingma2013auto}, \cite{vincent2008extracting}, Flow-based models \cite{dinh2016density}, and diffusion models. AnoGAN \cite{schlegl2017unsupervised} was an early attempt to apply GANs to anomaly detection by generating anomaly samples and using a discriminator for detection. However, it faced challenges such as mode collapse, limiting the diversity of generated samples. Ganomaly \cite{akcay2019ganomaly} improved this approach by using conditional GANs for anomaly detection, but adversarial training instability still hindered performance. VAE-based methods \cite{kingma2013auto} generate anomaly samples via reconstruction, but often produce blurry reconstructions, struggling to capture complex anomalies. Flow-based models like CFLOW \cite{gudovskiy2022cflow} and FastFlow \cite{yu2021fastflow} model data distributions explicitly to estimate anomaly probabilities, but they remain computationally expensive.

Recently, diffusion models have demonstrated remarkable progress in image generation. AnoDDPM \cite{wyatt2022anoddpm} introduced Denoising Diffusion Probabilistic Models (DDPMs) \cite{ho2020denoising}, \cite{rombach2022high} for anomaly detection, highlighting their potential for both generation and detection. However, high computational complexity remains a challenge. In this work, we integrate the generative capabilities of Stable Diffusion (SD) \cite{rombach2022high} models with discriminative tasks, enabling the generation of diverse anomaly samples while optimizing probability distributions for anomaly detection. This approach effectively addresses the shortcomings of existing methods in terms of both generation quality and detection performance.

\subsection{Discriminative-Based Unsupervised Anomaly Detection Methods}

Early discriminative methods, such as Ganomaly \cite{akcay2019ganomaly}, relied on GAN-based discriminators to distinguish between normal and anomalous samples, but suffered from adversarial training instability. Later, reconstruction-based methods like MemAE \cite{gong2019memorizing}, \cite{kang2024anomaly}, and DFR \cite{yang2020dfr} improved anomaly detection but often faced issues with inaccurate or overly smooth reconstructions, limiting adaptability to diverse anomaly patterns.
Diffusion models have been explored for discriminative tasks by combining generative capabilities with classification \cite{li2023your}, \cite{mukhopadhyay2023diffusion}. However, these methods are computationally expensive and still rely on prior information, limiting their efficiency in fully unsupervised tasks.

In contrast, our method directly leverages features from the denoising process of diffusion models without relying on prompts or labels. By modeling feature probability distributions and evaluating normal-anomaly differences through log-likelihood estimation, we efficiently determine the detection threshold, reducing computational costs and improving robustness in unsupervised anomaly detection.


\subsection{Innovations in Collaborative Optimization and Dual-Branch Architecture}

Collaborative optimization has been widely used in CNN-based anomaly detection \cite{akccay2019skip}, \cite{defard2021padim}, \cite{roth2022towards}, but CNNs often struggle with performance degradation when normal and anomalous sample distributions overlap. Knowledge distillation, which transfers knowledge from a teacher network to a student network, has proven effective in addressing this issue. By learning only normal feature distributions, the student network can detect anomalies through feature discrepancies. For example, ST \cite{lin2017feature} and IKD \cite{hinton2015distilling} improve anomaly localization and reduce overfitting. RD4AD \cite{deng2022anomaly} and SKD \cite{li2021cutpaste} further enhance performance by mitigating overfitting and incorporating real anomaly samples, while CDO \cite{cao2023collaborative} optimizes the distributional differences between normal and anomalous features.

Building on these advancements, we propose a dual-branch network architecture. The main branch uses a frozen Stable Diffusion model to extract features from normal samples, while the sub-branch generates anomaly samples and extracts features. By optimizing the probability distributions of these features, we enhance the distinction between normal and anomalous distributions, improving detection accuracy and robustness.



\section{ Methodology}
This research proposes an anomaly detection method based on a diffusion model (Stable Diffusion 1.5), combining the generative and discriminative capabilities of the diffusion model to perform efficient anomaly sample detection. The method includes three core modules: the diffusion anomaly generation module, the diffusion detection module, and the probability optimization module. Additionally, a comprehensive loss function is designed to ensure effective learning of the model. Each module will be described in detail, including their working principles and respective formulas.

\begin{figure*}[t]
    \centering
    \includegraphics[width=\textwidth, height=0.45\textheight, keepaspectratio]{p2.pdf}  % 插入图片
    \caption{Our method consists of three core modules: the Diffusion Anomaly Generation Module, the Diffusion Discriminative Module, and the Probability Optimization Module. The Diffusion Anomaly Generation Module is used to generate realistic anomaly samples, the Probability Optimization Module is used to extract features and optimize the extracted probability density, and the Diffusion Discriminative Module is used for classification and discrimination of feature anomalies.}  % 图片标题
    \label{fig:sample}  % 用于引用的标签
\end{figure*}







\subsection{Diffusion Anomaly Generation Module (DAGM)}
In traditional anomaly detection methods, the generation of anomalous samples typically relies on directly adding simple random noise (such as Gaussian noise or uniform noise) to normal samples. Although this method can simulate certain basic anomalous features, the generated anomalous samples often lack diversity and complexity and are difficult to reflect the irregular or local structural anomaly patterns existing in real - world scenarios. To address this issue, this study employs an anomaly sample generation mechanism based on a diffusion model and introduces hierarchical perturbations during the denoising process, thereby significantly enhancing the diversity and authenticity of the generated samples.

Specifically, the anomaly generation process begins with a normal sample \( z_0 \), and noise is progressively added through the forward diffusion process, evolving it into random noise \( z_t \). Each step of the forward diffusion process can be represented as: \( q(z_t | z_{t-1}) = \mathcal{N}(z_t; \sqrt{1 - \beta_t} z_{t-1}, \beta_t I) \)where \( \beta_t \) is typically set to gradually decrease from \( t = 0 \) to \( t = T \). The reverse denoising process removes the noise step-by-step, optimizing the features of the generated samples by introducing disturbance terms.

To optimize the generation process, we combine the variational lower bound (VLB)\cite{kingma2021variational} to maximize the log-likelihood of the samples. By learning the conditional distribution at each time step, the model is able to finely recover the sample distribution. Furthermore, during the denoising process, normal and anomalous samples exhibit distinct feature distributions at different time steps and network layers, providing effective information for anomaly detection.

For the initial sample \( z_0 \), a noisy sample sequence \( z_{1:T} \) is obtained through the forward diffusion process. The goal of the diffusion model is to learn the log-likelihood of the target sample \( z_0 \): \( \log \int p_{\theta}(z_{0:T}) \, dz_{1:T} \)By introducing an auxiliary distribution \( q(z_{1:T} | z_0) \) and applying Jensen's inequality:\( \log \mathbb{E}[x] \geq \mathbb{E}[\log x] \)the VLB\cite{kingma2021variational} is defined to optimize the log-likelihood, as follows:
\begin{equation}\label{1}
\log {{p}_{\theta }}({{z}_{0}})\ge \mathbb{E}\left[ \log p({{z}_{T}})+\sum\limits_{t=1}^{T}{\log \frac{{{p}_{\theta }}({{z}_{t-1}}|{{z}_{t}})}{q({{z}_{t}}|{{z}_{t-1}})}} \right]
\end{equation}

During the reverse denoising process, the model restores the sample distribution by optimizing the log-likelihood and captures multi-scale latent feature patterns. This paper employs a multi-level feature extraction method, using intermediate features from the denoising process to capture anomaly patterns. To enhance the diversity and authenticity of the generated samples, this study introduces a hierarchical disturbance mechanism. At each denoising step, disturbances of varying intensity and frequency are added, embedding local anomaly features while preserving the overall structure of the normal samples.

In the denoising phase, starting from the random noise \( z_t \), the model gradually denoises and adds a disturbance term \( \tau \) through the diffusion model. The final output, \( \hat{z}_0 \), is the anomalous sample. The model performs reverse sampling according to the following formula:
\begin{equation}\label{2}
{{p}_{\theta }}({{z}_{t-1}}|{{\text{z}}_{\text{t}}})=\mathcal{N}({{z}_{t-1}};{{\mu }_{\theta }}({{z}_{t}},t),(1+\tau )\sum\nolimits_{\theta }{({{z}_{t}},t)})
\end{equation}
\begin{equation}\label{3}
{{\mu }_{\theta }}({{z}_{t}},t)=\frac{1}{\sqrt{{{\alpha }_{t}}}}({{z}_{t}}-\frac{{{\beta }_{t}}}{\sqrt{1-\overline{{{\alpha }_{t}}}}}{{\epsilon }_{\theta }}({{z}_{t}},t))
\end{equation}
\begin{equation}\label{4}
{{\alpha }_{t}}=1-{{\beta }_{t}},\overline{{{\alpha }_{t}}}=\prod\limits_{i=1}^{t}{{{\alpha }_{i}}}
\end{equation}

\(\mu_{\theta}(z_t, t) \)is the predicted noise using the network, \( \alpha_t \) is the coefficient in the forward diffusion process, which is a scaling term related to the noise intensity, and \( \tau \) is the adjustment parameter for the anomaly strength. When \( \tau = 0 \), the generated samples tend to follow a normal distribution, while when \( \tau > 0 \), the generated samples exhibit distinct anomaly characteristics. Finally, the model performs the complete reverse sampling process according to the following formula:
\begin{equation}\label{5}
{{p}_{\theta }}({{z}_{0:T}})=p({{z}_{T}})\underset{t=1}{\overset{T}{\mathop{\prod }}}\,{{p}_{\theta }}({{z}_{t-1}}|{{z}_{t}})
\end{equation}

Here, \( p(z_T) \) represents the initial distribution of pure noise, which is typically assumed to be a standard Gaussian distribution. \( p_{\theta}(z_{t-1} | z_t) \) denotes the conditional probability distribution of generating the previous state \( z_{t-1} \) given the current state \( z_t \). The objective of model training is to minimize the noise prediction error:
\begin{equation}\label{6}
{{\mathcal{L}}_{\text{MSE}}}={{\mathbb{E}}_{{{z}_{0}},\epsilon ,t}}\left[ {{\left\| \epsilon -{{\epsilon }_{\theta }}({{z}_{t}},t) \right\|}^{2}} \right]
\end{equation}

\( z_t \) is the latent variable at time step \( t \), generated from \( z_0 \) by adding noise: \( z_t = \sqrt{\alpha_t} z_0 + \sqrt{1 - \alpha_t} \epsilon \)
where \( \epsilon \) is the true Gaussian noise and \( \epsilon_{\theta} \) is the noise predicted by the model. The goal is to minimize the error between the model-predicted noise \( \epsilon_{\theta} \) and the true noise \( \epsilon \). The KL\cite{kim2021comparing} divergence loss function can be written as:
\begin{equation}\label{7}
{{\mathcal{L}}_{KL}}={{\mathbb{E}}_{{{z}_{0}},{{z}_{t}}}}\left[ {{D}_{KL}}\left( q({{z}_{t-1}}|{{z}_{t}},{{z}_{0}})\parallel {{p}_{\theta }}({{z}_{t-1}}|{{z}_{t}}) \right) \right]
\end{equation}

The final optimization objective combines the noise prediction error and the KL divergence loss. The overall loss function can be written as:
\begin{equation}\label{8}
{{\mathcal{L}}_{DAGM}}=\sum\limits_{t=1}^{T}{{{\lambda }_{t}}}{{\mathcal{L}}_{KL}}+{{\mathcal{L}}_{MSE}}
\end{equation}

\(\lambda_t  \) is the balancing coefficient, used to adjust the contribution of the loss at each time step. This diffusion model-based approach not only generates samples similar to the structure of normal samples, but also introduces a hierarchical disturbance strategy to generate complex anomaly features by precisely controlling noise. Unlike traditional methods, it is able to reflect irregular or local structural anomaly patterns in real-world scenarios, significantly improving the performance of anomaly detection tasks.







\subsection{Diffusion Discrimination Module (DDM)}
We design a dual-branch architecture for the DDM. The teacher network ${{\phi }_{E}}$ extracts features from normal samples using a frozen SD1.5 diffusion model (main branch), while the student network ${{\phi }_{A}}$ learns from trainable SD1.5 diffusion models for anomaly samples (sub-branch). For each time step $t$ in the reverse denoising process and each layer  , the extracted features are:
\begin{equation}\label{9}
\mathop{f}_{E}^{k}=\mathop{\phi }_{E}^{k}({{z}_{t}}),\mathop{f}_{A}^{k}=\mathop{\phi }_{A}^{k}({{z}_{t}}),k=1,2,...,K
\end{equation}

Here, \( \mathop{f}_{E}^{k} \) and \( \mathop{f}_{A}^{k} \) denote features of normal and anomalous samples at layer kk. Multi-scale features are concatenated to enhance expressiveness:
\begin{equation}\label{10}
{{F}_{E}}=Concat(\mathop{f}_{E}^{1},\mathop{f}_{E}^{2},...,\mathop{f}_{E}^{K}),{{F}_{A}}=Concat(\mathop{f}_{A}^{1},\mathop{f}_{A}^{2},...,\mathop{f}_{A}^{K})
\end{equation}

The discrepancy between normal and anomalous feature distributions is defined as:
\begin{equation}\label{11}
d(z)={{\left\| {{F}_{E}}-{{F}_{A}} \right\|}_{2}}
\end{equation}

This metric quantifies similarity for subsequent classification tasks. The reverse process approximates \( {{p}_{\theta }}({{z}_{t-1}}|{{\text{z}}_{\text{t}}}) \) , yielding mean \( {{\mu }_{\theta }}({{z}_{t}},t) \) and variance $\sum{_{\theta }({{z}_{t}},t)}$. For conditional generation, equation \ref{5} reverse process becomes:
\begin{equation}\label{12}
{{p}_{\theta }}({{z}_{t-1}}|{{z}_{t}},y)\propto {{p}_{\theta }}({{z}_{t-1}}|{{z}_{t}}){{p}_{\phi }}(y|{{z}_{t}})
\end{equation}

Here, \( {{p}_{\phi }}(y|{{z}_{t}}) \) is the conditional probability of ${{z}_{t}}$ belonging to class $y$, estimated by a classifier. Using the gradient ${{\nabla }_{{{x}_{t}}}}\log {{p}_{\phi }}(y|{{z}_{t}})$, equation \ref{3} is adjusted as:
\begin{equation}\label{13}
{{{\mu }'}_{\theta }}({{z}_{t}},t,y)={{\mu }_{\theta }}({{z}_{t}},t)+s\sum{_{\theta }}{{\nabla }_{{{x}_{t}}}}\log {{p}_{\phi }}(y|{{z}_{t}})
\end{equation}

where $s$ is a hyperparameter controlling the influence of the classifier gradient. This enables conditional sampling with controlled anomaly generation.
\begin{equation}\label{14}
{{p}_{\theta }}({{z}_{t-1}}|{{\text{z}}_{\text{t}}},y)=\mathcal{N}({{z}_{t-1}};{{{\mu }'}_{\theta }}({{z}_{t}},t,y),\sum\nolimits_{\theta }{({{z}_{t}},t)})
\end{equation}

By leveraging the gradient information from the classifier, conditional guidance can be applied to generated samples during the reverse diffusion process. In discriminative tasks, our goal is to estimate the conditional probability $p(y|{{z}_{0}})$ that the input data ${{z}_{0}}$ belongs to category $y$. According to Bayes' theorem, this probability can be written as:
\begin{equation}\label{15}
p(y|{{z}_{0}})\propto p({{z}_{0}}|y)p(y)
\end{equation}

Here, \( p({{z}_{0}}|y) \) is the probability of the input data under the condition of category $y$, and \( p(y) \) is the prior probability of the category. To compute \( p({{z}_{0}}|y) \), we utilize the conditional probability distribution of the diffusion model. By modeling the diffusion process across time steps t=1,2,…,T, the target distribution \( p({{x}_{0}}|y) \) can be decomposed into the joint probability distribution over all time steps:
\begin{equation}\label{16}
p({{z}_{0}}|y)=\int{{{p}_{\theta }}({{z}_{1:T}}|y)d{{z}_{1:T}}}=\prod\limits_{t=1}^{T}{{{p}_{\theta }}({{z}_{t-1}}|{{z}_{t}},y)}
\end{equation}

Combined with the conditional sampling formula, we can compute the log-likelihood:
\begin{equation}\label{17}
\log p({{z}_{0}}|y)=\sum\limits_{t=1}^{T}{\log {{p}_{\theta }}({{z}_{t-1}}|{{z}_{t}},y)}
\end{equation}

Using the properties of the conditional Gaussian distribution, the expression for \( \log {{p}_{\theta }}({{z}_{t-1}},{{z}_{t}},y) \) is:
\begin{equation}\label{18}
\log {{p}_{\theta }}({{z}_{t-1}},{{z}_{t}},y)=-\frac{1}{2}{{({{z}_{t-1}}-{{{\mu }'}_{\theta }})}^{\top }}\sum\nolimits_{\theta }^{-1}{({{z}_{t-1}}-{{{{\mu }'}}_{\theta }})}+C
\end{equation}

Here, \( {{{\mu }'}_{\theta }}={{\mu }_{\theta }}({{z}_{t}},t)+s\sum\nolimits_{\theta }{{{\nabla }_{{{z}_{t}}}}\log {{p}_{\phi }}(y|{{z}_{t}})} \), and $C$ is a normalization constant. By combining the distributions of these conditional samples with the formulas above, we can compute the corresponding log-likelihood values to further optimize the quality of generated samples. Through the use of conditional distribution information, we can generate anomaly samples conforming to the target category   via the diffusion process. This reverse diffusion process, which integrates generation and discrimination, allows us to compute anomaly scores using a classifier. We employ Pixel Classifiers\cite{cheng2021per} (including Linear\cite{li2019learning}, ReLU\cite{agarap2018deep}, BatchNorm\cite{ioffe2015batch}, etc.) to calculate anomaly scores for each pixel. By estimating the anomaly scores of input samples, the model can precisely localize anomalous regions.

Ultimately, the goal of the DDM module is to extract features and perform classification during the reverse denoising process, estimating the probability that an input sample belongs to a specific category by computing anomaly scores. By combining the denoising and generation processes, the model optimizes the detection of anomalous regions. For an input sample ${{z}_{0}}$, the log-likelihood values for categories $y\in \{{{y}_{normal}},{{y}_{abnormal}}\}$ are computed as:
\begin{equation}\label{19}
{{\mathcal{L}}_{DDM}}=\sum\limits_{t=1}^{T}{-\log }{{p}_{\theta }}({{z}_{t-1}}|{{z}_{t}},y)
\end{equation}

This loss function optimizes the discrepancy between generated anomaly samples and real anomaly samples, maximizing the log-likelihood of generated images to enhance anomaly detection accuracy.





\subsection{Probability Optimization Module (POM)}
Within the anomaly detection framework of the diffusion model, the POM module (Probability Optimization Module) is responsible for modeling and optimizing the probability distributions of normal and anomaly samples. By maximizing the margin between the distributions of normal and anomaly samples while minimizing their overlap, the POM module effectively improves the model’s discriminative power. Specifically, at the pixel level, the DDM module first extracts pixel-level feature representations (Pixel Representations) from input samples. These features include the distributions of normal and anomaly samples across different layers (e.g., $C_{E}^{K}$ and $C_{A}^{K}$ in the figure). By mapping these features into higher-resolution multi-scale feature maps, the module captures fine-grained differences between normal and anomaly samples. In the POM module, these pixel-level feature distributions are further modeled as probability distributions to capture the probabilistic differences between normal and anomaly samples at specific pixels. By optimizing the distribution margin and overlap regions, the POM module enhances the pixel-level discriminability between normal and anomaly samples. In the classification task, through the Pixel Classifiers in the DDM module, the features of each pixel are mapped to a classification space, generating corresponding anomaly scores. This pixel-level processing ensures the model accurately captures local anomalous features while achieving comprehensive sample-level discrimination through global probability optimization.

Building on multi-level feature distribution differences, the POM module further optimizes the distributions of normal and anomaly samples by enlarging their margin and reducing overlap. The module employs a dynamic weighting mechanism to balance the contributions of normal and anomaly samples in the optimization objective, achieving more precise optimization. The dynamic weights for normal and anomaly samples are defined as:
\begin{equation}\label{20}
\omega ({{z}_{n}})={{\left( \frac{d({{z}_{n}})}{{{\mu }_{n}}} \right)}^{\gamma }},\omega ({{z}_{a}})={{\left( \frac{d({{z}_{a}})}{{{\mu }_{a}}} \right)}^{-\gamma }}
\end{equation}

Here, $d({{z}_{n}})$ and $d({{z}_{a}})$represent the feature distribution discrepancies for normal and anomaly samples, respectively; ${{\mu }_{n}}$  and ${{\mu }_{a}}$  are the mean discrepancies for normal and anomaly samples; $\gamma >0$ is a tuning parameter controlling the nonlinearity of the weights. This mechanism strengthens normal samples with large discrepancies and enhances the weights of anomaly samples with small discrepancies, thereby optimizing the distributions of normal and anomaly samples to improve detection performance. The optimization objective of the POM module combines distribution margin and overlap, defined as:
\begin{equation}\label{21}
{{\mathcal{L}}_{POM}}=\sum\limits_{i=1}^{{{N}_{n}}}{\omega ({{z}_{{{n}_{i}}}})}d({{z}_{{{n}_{i}}}})\cdot \left( 1-\frac{d({{z}_{{{a}_{j}}}})}{\max (d({{z}_{{{n}_{i}}}}),d({{z}_{{{a}_{j}}}}))} \right)
\end{equation}

In this formula, the first term increases the margin between normal and anomaly samples through weighting, while the second term dynamically reduces distribution overlap, achieving a unified optimization objective. Algorithm \ref{alg:HDM} summarizes the framework of HDM.




\subsection{Comprehensive Loss Design}
To jointly optimize the objectives of these three modules, this paper designs a comprehensive loss function that combines equation \ref{8}, equation \ref{19}, and equation \ref{21} to balance their contributions.
\begin{equation}\label{22}
{{\mathcal{L}}_{total}}={{\lambda }_{1}}{{\mathcal{L}}_{DAGM}}+{{\lambda }_{2}}{{\mathcal{L}}_{DDM}}+{{\lambda }_{3}}{{\mathcal{L}}_{POM}}
\end{equation}




\begin{algorithm}[t]
\caption{Framework of HDM}
\label{alg:HDM}
\renewcommand{\algorithmicrequire}{\textbf{Input:}}
\renewcommand{\algorithmicensure}{\textbf{Output:}}
\begin{algorithmic}[1]
\REQUIRE $D_{\text{train}}$, $D_{\text{test}}$, $\mathcal{N}(0,1)$, $T_{\text{dist}}$, $\tau$, Modules: SD$_{\text{DAGM}}$, SD$_{\text{DDM}}$, PixelCls, POM
\ENSURE Anomaly maps $\{M_X\}_{X \in D_{\text{test}}}$
\FOR{each $X \in D_{\text{train}}$} 
    \STATE $X_{\text{gen}} \gets \text{SD}_\text{DAGM}(X, \mathcal{N}, T_{\text{dist}}(X), \tau)$
    \STATE Update $\text{SD}_\text{DAGM}$ via $\nabla\|X_{\text{gen}} - X\|^2$
\ENDFOR \COMMENT{End of DAGM Training Loop}

\FOR{each $X \in D_{\text{train}}$} 
    \STATE $(C_E, C_A) \gets \oplus(\text{SD}_\text{DDM}(X))$  \COMMENT{$C_*=\oplus(F_*)$: feature concat}
    \STATE $(p_E, p_A) \gets \text{POM}(\log P(C_E), \log P(C_A))$ \COMMENT{Log-likelihood→POM}
    \STATE $\mathcal{L} \gets \lambda_2\|\text{PixelCls}(C_E,C_A) - (p_E \oplus p_A)\| + \lambda_3\text{KL}(p_E\|p_A)$
    \STATE Update $\{\text{SD}_\text{DDM}, \text{PixelCls}, \text{POM}\}$ via $\nabla\mathcal{L}$
\ENDFOR \COMMENT{End of DDM and POM Training Loop}

\FOR{each $X \in D_{\text{test}}$}
    \STATE $(C_E, C_A) \gets \oplus(\text{SD}_\text{DDM}(X))$
    \STATE $M_X \gets \sigma\big(p_E \odot \text{PixelCls}(C_E,C_A) \big)$  \COMMENT{$\odot$: element-wise product}
    \RETURN $M_X$
\ENDFOR \COMMENT{End of Inference Loop}

\end{algorithmic}
\end{algorithm}










\section{Experiments}
\subsection{Experimental Setup}
To evaluate the proposed hybrid diffusion-based anomaly detection method, we conducted experiments on four challenging industrial anomaly detection datasets: MVTec-AD\cite{bergmann2019mvtec} and MPDD\cite{jezek2021deep} datasets.

MVTec-AD Dataset\cite{bergmann2019mvtec}: The MVTec-AD\cite{bergmann2019mvtec} dataset  simulates real industrial production scenarios and is specifically designed for unsupervised anomaly detection tasks. The dataset includes 5,354 high-resolution images across 15 object categories, comprising 5 texture types and 10 different object types. The training set consists of 3,629 normal images, and the test set contains 1,725 images with both normal and anomalous samples. To better evaluate the performance of anomaly detection models, the dataset provides pixel-level annotations for anomaly locations.

MPDD\cite{jezek2021deep} Dataset: The MPDD\cite{jezek2021deep} dataset is specifically designed for detecting defects on metal product surfaces, mainly for magnetic particle defect detection (MPDD). The dataset simulates the metal processing environment in industrial applications, containing high-resolution images of metal surfaces to identify anomalies like cracks, wear, and pores. The MPDD\cite{jezek2021deep} dataset is particularly useful for developing unsupervised detection models for surface defect detection in metal materials.


\begin{table*}[ht]
\centering
\caption{Comparison of our method with other anomaly synthesis methods on the MVTec-AD\cite{bergmann2019mvtec} dataset, using Image-level AUROC (\%), Pixel-level AUROC (\%), and PRO (\%) as evaluation metrics.}
\label{tab:table1}
% \setlength{\tabcolsep}{2.5mm}
% \renewcommand\arraystretch{1.6}
\begin{tabular}{l|c|c|c|c|c|c}
\toprule
\multicolumn{2}{c|}{Category} & CutPaste{\cite{li2021cutpaste}}    & NSA{\cite{schluter2022natural}}         & DTD{\cite{cimpoi2014describing}}         & SIA{\cite{zhang2024realnet}}         & Ours                 \\ 
\midrule
\multirow{6}{*}{Texture} & Carpet     & (99.24,98.42,93.85) & (99.80,98.60,88.77) & (\textbf{100.0},\textbf{99.27},\textbf{96.96}) & (99.84,99.19,96.41) & (99.31,98.79,96.91)  \\ 
                          & Grid       & (\textbf{100.0},99.18,92.53) & (\textbf{100.0},99.32,91.31) & (\textbf{100.0},\textbf{99.57},97.14) & (\textbf{100.0},99.51,97.28) & (\textbf{100.00},99.14,\textbf{97.78}) \\ 
                          & Leather    & (\textbf{100.0},99.41,92.12) & (\textbf{100.0},99.24,\textbf{96.85}) & (\textbf{100.0},\textbf{99.77},96.41) & (\textbf{100.0},99.76,96.22) & (\textbf{100.00},99.25,96.72) \\  
                          & Tile       & (99.86,97.63,84.39) & (\textbf{100.0},97.40,86.45) & (\textbf{100.0},99.35,95.27) & (99.96,99.44,97.70) & (\textbf{100.00},\textbf{99.94},\textbf{98.20}) \\  
                          & Wood       & (98.95,95.29,81.47) & (97.63,93.30,87.20) & (\textbf{99.65},\textbf{98.28},\textbf{91.23}) & (99.21,98.22,90.54) & (99.41,98.22,91.04)  \\ 
                          & AVG        & (99.61,97.99,88.87) & (99.49,97.57,90.11) & (\textbf{99.93},\textbf{99.25},95.40) & (99.80,99.22,95.63) & (99.74,99.07,\textbf{96.13})  \\ 
\midrule
\multirow{11}{*}{Object} & Bottle     & (\textbf{100.0},99.14,91.41) & (\textbf{100.0},99.37,93.49) & (\textbf{100.0},99.35,95.57) & (\textbf{100.0},99.30,95.62) & (\textbf{100.00},\textbf{99.80},\textbf{96.12}) \\  
                         & Cable      & (96.35,96.23,86.05) & (\textbf{99.33},97.62,93.26) & (98.95,97.84,90.36) & (99.19,98.10,93.38) & (99.09,\textbf{98.60},\textbf{93.88})  \\  
                         & Capsule    & (98.48,99.10,79.55) & (99.04,99.27,\textbf{85.77}) & (99.32,99.19,82.28) & (\textbf{99.56},\textbf{99.32},84.48) & (\textbf{99.56},99.22,85.34)  \\  
                         & hazelnut   & (\textbf{100.0},99.03,91.51) & (\textbf{100.0},99.25,\textbf{94.41}) & (\textbf{100.0},99.46,93.46) & (\textbf{100.0},99.68,93.14) & (\textbf{100.00},\textbf{99.75},93.64) \\  
                         & Metal Nut  & (99.90,98.03,89.69) & (\textbf{100.0},\textbf{99.11},93.27) & (99.90,98.58,\textbf{96.49}) & (99.76,98.58,94.39) & (99.69,99.08,94.89)  \\  
                         & Pill       & (97.22,98.96,86.48) & (97.19,98.28,\textbf{95.15}) & (98.36,98.88,84.44) & (99.13,99.02,91.04) & (\textbf{99.63},\textbf{99.42},92.51)  \\  
                         & Screw      & (92.74,98.53,79.63) & (98.79,\textbf{99.62},\textbf{93.74}) & (97.72,99.36,85.22) & (\textbf{98.83},99.45,87.90) & (98.33,99.45,87.57)  \\ 
                         & Toothbrush & (99.17,98.85,78.48) & (\textbf{100.0},\textbf{99.18},89.20) & (99.44,98.69,90.87) & (99.44,98.71,91.57) & (98.81,98.36,\textbf{92.07})  \\ 
                         & Transistor & (99.38,96.32,76.52) & (98.54,95.67,79.09) & (99.71,97.15,86.56) & (\textbf{100.0},98.00,92.92) & (99.47,\textbf{98.47},\textbf{93.42})  \\  
                         & zipper     & (99.61,98.03,92.26) & (\textbf{99.90},98.91,93.05) & (99.68,99.02,88.77) & (99.82,99.17,\textbf{93.43}) & (99.64,\textbf{99.23},91.93)  \\ 
                         & AVG        & (98.29,98.22,85.16) & (99.28,98.63,91.04) & (99.31,98.75,89.40) & (\textbf{99.57},98.93,91.79) & (99.42,\textbf{99.14},\textbf{92.14})  \\ 
\midrule
\multicolumn{2}{c|}{AVG} & (98.73,98.14,86.40) & (99.35,98.28,90.73) & (99.52,98.92,91.40) & (\textbf{99.65},99.03,93.07) & (99.52,\textbf{99.11},\textbf{93.47})  \\ 
\bottomrule
\end{tabular}
\end{table*}


In the experiments, we adopted a unified experimental setup to ensure the fairness and comparability of the results. DAGM is based on the Stable Diffusion 1.5 model, which introduces noise through forward diffusion and adds perturbations during the reverse denoising process to generate anomalies with varying intensities and diversity. The classification and DDM employs a dual-branch architecture, where the frozen Stable Diffusion model extracts features from normal samples, and the trainable model extracts features from anomaly samples. These extracted probability densities are optimized through an improved POM. The learning rate is set to 1 × ${{10}^{-5}}$, with a batch size of 32; the training steps are set to 50,000 for the MVTec-AD\cite{bergmann2019mvtec} dataset and 20,000 for the MPDD\cite{jezek2021deep} dataset. All data is resized to a resolution of 256×256 and undergoes data augmentation operations such as random cropping, horizontal flipping, and Gaussian blurring. The experiments were conducted on two NVIDIA Tesla V100 32GB GPUs, ensuring efficient training and inference speed.

\subsection{Evaluation Metrics}
To comprehensively evaluate the performance of the proposed anomaly detection framework in both classification and localization tasks, we employed three commonly used evaluation metrics: Image-level AUROC\cite{bergmann2019mvtec}, Pixel-level AUROC, and Per-Region Overlap (PRO)\cite{bergmann2020uninformed}. Image-level AUROC measures the classification accuracy at the sample level, reflecting the model's ability to distinguish between normal and anomalous samples. Pixel-level AUROC further assesses the model's performance in pixel-level anomaly localization, indicating the model's accuracy in detecting anomalous regions. The PRO metric evaluates the accuracy of the model in region-level localization tasks by calculating the overlap between the predicted regions and the true anomalous regions. By using these three metrics together, we can comprehensively measure the overall performance of the model in anomaly detection tasks and make fair comparisons with existing methods.









\begin{table*}[ht]
\begin{center}
% \setlength{\tabcolsep}{2.1mm}
% \renewcommand\arraystretch{1.5}
\caption{Comparison of our method with other anomaly detection methods on the MVTec-AD[46] dataset.}
\label{tab:table2}
\begin{tabular}{c|ccc|cccc|c}
\toprule
Metric      & PatchCore{\cite{roth2022towards}} & SimpleNet{\cite{liu2023simplenet}} & FastFlow{\cite{yu2021fastflow}}& UniAD{\cite{you2022unified}} & RD++{\cite{tien2023revisiting}} & DeSTSeg{\cite{zhang2023destseg}} & DiffAD{\cite{zhang2023unsupervised}} & Ours \\ \midrule
Image AUROC & 99.1              & 99.6              & 99.3                                   & 96.6          & 99.4         & 98.6            & 98.7           & 99.5 \\
Pixel AUROC & 98.1              & 98.1              & 98.1                                        & 96.6          & 98.3         & 97.9            & 98.3           & 99.1 \\ \bottomrule
\end{tabular}
\end{center}
\end{table*}





On the MVTec-AD\cite{bergmann2019mvtec} dataset, our method performs exceptionally well, achieving an Image-level AUROC of 99.5\%, a Pixel-level AUROC of 99.11\%, and a Per-Region Overlap (PRO) of 93.47\% in \Cref{tab:table1}. The performance comparison with existing methods is summarized in \Cref{tab:table2}. Our model effectively overcomes the issue of overfitting by generating diverse anomalous samples and optimizing discrimination, achieving very high detection accuracy across multiple categories, especially in detecting small defects such as cracks, where it shows a clear advantage.


\begin{figure*}[t]
    \centering
    \includegraphics[width=\textwidth, height=0.45\textheight, keepaspectratio]{p3.pdf}  % 插入图片
    \caption{Qualitative results of our proposed method on MVTec-AD\cite{bergmann2019mvtec} dataset. The original images (a), ground truth masks (b), and anomaly maps (c) are listed from top to bottom.}  % 图片标题
    \label{fig:fig3} 
\end{figure*}


\begin{table*}[h]
\begin{center}
% \setlength{\tabcolsep}{20pt}%
% \renewcommand{\arraystretch}{1.6}
\caption{Comparison of our method with other anomaly synthesis methods on the MPDD\cite{jezek2021deep} dataset, using Image-level AUROC (\%), Pixel-level AUROC (\%), and PRO (\%) as evaluation metrics.}
\label{tab:table3}
% \resizebox{1.0\linewidth}{!}{
\begin{tabular}{l|c|c|c|c}
\toprule
\textbf{Category} & \textbf{CutPaste\cite{li2021cutpaste}} & \textbf{DTD\cite{cimpoi2014describing}} & \textbf{SIA\cite{zhang2024realnet}} & \textbf{Ours} \\
\midrule
Bracket Black & (66.42,96.67,56.53)  & (89.49,98.90,88.57)  & (94.95,99.27,87.10)  & (\textbf{95.45},\textbf{99.57},\textbf{87.6})   \\
Bracket Brown   & (95.48,97.54,55.17)  & (92.99,97.35,92.64)  & (96.83,97.81,94.36)  & (\textbf{97.33},\textbf{98.31},\textbf{94.86})  \\
Bracket White   & (88.44,96.51,64.32)  & (86.67,\textbf{98.59},77.08)  & (88.78,97.44,84.00)  & (\textbf{89.28},97.94,\textbf{84.5})   \\
Connector       & (99.05,\textbf{98.47},74.05)  & (99.05,97.76,65.91)  & (\textbf{100.0},97.46,84.79)  & (\textbf{100.0},97.96,\textbf{85.29})  \\
Metal Plate     & (99.95,98.83,92.69)  & (\textbf{100.0},\textbf{99.35},93.78)  & (\textbf{100.0},99.28,94.44)  & (\textbf{100.0},\textbf{99.48},\textbf{94.94})  \\
Tubes           & (91.49,98.09,92.99)  & (92.62,\textbf{99.01},\textbf{96.49})  & (\textbf{97.51},97.94,93.29)  & (97.01,98.44,93.79)  \\
\midrule
AVG             & (90.14,97.69,72.63)  & (93.47,98.49,85.75)  & (96.35,98.20,89.66)  & (\textbf{96.51},\textbf{98.61},\textbf{90.16})  \\
\bottomrule
\end{tabular}
% }
\end{center}
\end{table*}




\cref{fig:fig3} Comparison of original images and heatmaps: We present heatmaps showing the anomalous regions detected by our model. The left side shows the original image, while the right side shows the heatmap, with red areas indicating detected anomalous regions. The heatmap clearly illustrates that the model successfully localized small defects like cracks and stains.





\begin{table*}[h]
\begin{center}
\caption{Comparison of our method with other anomaly detection methods on the MPDD\cite{jezek2021deep} dataset.}
\label{tab:table4}
% \renewcommand{\arraystretch}{1.4}
\begin{tabular}{c|cccc|cc|c}
\toprule
Metric      & PatchCore{\cite{roth2022towards}} & CFlow{\cite{gudovskiy2022cflow}} & PaDiM{\cite{defard2021padim}} & SPADE{\cite{cohen2020sub}} & DAGAN{\cite{tang2020anomaly}} & \multicolumn{1}{l|}{\begin{tabular}[c]{@{}l@{}}Skip-GANomaly{\cite{akccay2019skip}}\end{tabular}} & Ours \\ \midrule
Image AUROC & 82.1              & 86.1          & 74.8          & 77.1          & 72.5          & 64.8                                                                                  & 96.5 \\
Pixel AUROC & 95.7              & 97.7          & 96.7          & 95.9          & 83.3          & 82.2                                                                                  & 98.6 \\ \bottomrule
\end{tabular}
\end{center}
\end{table*}



On the MPDD\cite{jezek2021deep} dataset, our method performs excellently, achieving an Image-level AUROC of 96.51\%, a Pixel-level AUROC of 98.61\%, and a Per-Region Overlap (PRO) of 90.16\% in \Cref{tab:table3}. The performance comparison with existing methods is summarized in \Cref{tab:table4}.





\subsection{Ablation Studies}
To systematically analyze the contributions of each module and their associated hyperparameters to the performance of anomaly detection, a series of ablation experiments were conducted. The proposed model comprises three key components: DAGM (Diffusion-based Anomaly Generation Module), DDM (Discriminative Diffusion Module), and POM (Probability Optimization Module). Initially, the effects of the coefficient $\tau $ in the DAGM module, which regulates the intensity of generated images, and the coefficient s in the DDM module, which determines the richness of generated images, were evaluated. Subsequently, ablation experiments were performed by individually removing each module to investigate their specific contributions to the overall anomaly detection performance.

\begin{figure*}[t]
    \centering
    \includegraphics[width=\textwidth, height=0.45\textheight, keepaspectratio]{p4.pdf}  % 插入图片
    \caption{Examples of anomaly images generated using different synthesis methods. (a) Examples generated using DAGM with different anomaly strengths. (b) Examples showcasing local anomaly regions generated by various anomaly synthesis methods.}  % 图片标题
    \label{fig:fig4} 
\end{figure*}

The DAGM  controls the intensity of generated images by introducing the anomaly generation strength coefficient $\tau $. When the DAGM module is removed, the model no longer performs the generation and diffusion processes for anomaly samples. We conducted experiments on the MVTec-AD\cite{bergmann2019mvtec} dataset to compare the performance before and after removing the DAGM module. Without the DAGM module, the model is trained solely on normal images, and the generated anomaly samples lose diversity and distinctiveness. Experimental results show that removing the DAGM module led to a decrease in image-level AU-ROC by 0.08\% and pixel-level AU-ROC by 0.42\%. These findings highlight the significant role of the DAGM module in generating diverse anomaly samples and improving detection accuracy.

The DDM  captures the difference between the generated images and normal images through the reverse diffusion process, and accurately localizes anomalous regions based on probability distribution. We adjust the coefficient s in the DDM module to control the richness of the generated images in \cref{fig:fig4}. After removing the DDM module, the model could not effectively distinguish between anomalous and normal samples, which directly affected the accuracy of anomalous region localization.

After removing the DDM module, the model's AUROC decreased by 2.64\%, and the Pixel-level AUROC decreased by 2.71\% in \Cref{tab:table5}. This suggests that the DDM module plays a critical role in accurately capturing anomalous regions and improving anomaly localization accuracy.

\begin{table}[h]
\begin{center}
\caption{Ablation studies of DAGM and DDM on the MVTec-AD\cite{bergmann2019mvtec} dataset.}
\label{tab:table5}
% \renewcommand{\arraystretch}{1.5}
\newcommand{\xmark}{\textcolor{gray}{\usym{2717}}} 
\begin{tabular}{l|c c|cc}
\hline
 & {DAGM-SD} & {DDM-SD} & {Image AUROC} & {Pixel AUROC} \\
\hline
1 & \xmark & \xmark  & 94.47  & 93.39   \\
2 & \usym{1F5F8} & \xmark  & 96.86  & 96.39  \\
3 & \xmark  & \usym{1F5F8}  & 99.42  & 98.68   \\
4 & \usym{1F5F8}  & \usym{1F5F8}  & \textbf{99.50}  & \textbf{99.10}  \\
\hline
\end{tabular}
\end{center}
\end{table}

\begin{figure}[t]
    \centering
    \includegraphics[width=0.5\textwidth, height=0.45\textheight, keepaspectratio]{p5.pdf}  
    \caption{Comparison of the effects for different anomaly generation richness coefficients   on the MPDD\cite{jezek2021deep} dataset.}  % 图片标题
    \label{fig:fig5} 
\end{figure}


\begin{figure}[t]
    \centering
    \includegraphics[width=0.5\textwidth, height=0.45\textheight, keepaspectratio]{p6.pdf} 
    \caption{(a) Comparison before and after the POM module optimization on the MVTec-AD[46] dataset. The red areas represent before optimization, and the green areas represent after optimization. (b) Results on the MPDD\cite{jezek2021deep} dataset.}  % 图片标题
    \label{fig:fig6} 
\end{figure}

The POM  optimizes the probability distribution of the samples during both generation and discrimination processes, ensuring high-quality anomalous samples are used for training. After removing the POM module, the model no longer performs distribution optimization in the generation and discrimination processes, resulting in significant fluctuations in the quality of the generated anomalous images. The model's AUROC decreased by 1.0\%, and the Pixel-level AUROC decreased by 1.13\%. These results indicate that the POM module plays a crucial role in optimizing the quality of generated anomalous samples, thereby improving the overall performance of the model.The comparison of the POM module before and after optimization is shown in \cref{fig:fig5}.

Through the aforementioned ablation experiments, we have demonstrated the importance of the DAGM, DDM, and POM modules within the model. Removing any one of these modules significantly reduces the model's performance, especially in terms of the accuracy of anomaly image generation and localization. Further experiments show that appropriately adjusting the coefficients and coefficients s can balance the strength and complexity of anomaly image generation, thus achieving optimal performance in anomaly detection tasks.


\section{Conclusion}
This paper introduces a novel anomaly detection approach based on a diffusion model, which effectively integrates both generative and discriminative tasks to enhance the quality of anomaly sample generation and detection accuracy. By incorporating a probability distribution optimization module, we mitigate the inherent trade-off between sample diversity and detection precision that traditional methods often encounter. Extensive experiments on multiple industrial image datasets demonstrate the superior performance of the proposed method in both image-level and pixel-level anomaly detection tasks. Despite its promising results across diverse datasets, the proposed model exhibits certain limitations, particularly in handling highly complex and dynamic anomaly patterns, where balancing generation and detection remains challenging. Future work could focus on enhancing the model’s efficiency and exploring cross-modal data integration, thereby broadening its applicability in real-world industrial and medical domains.

\bibliographystyle{IEEEtran}
\bibliography{ref}        






\vfill


























\end{document}


