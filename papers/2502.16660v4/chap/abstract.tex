
% Large language models (LLMs) have demonstrated remarkable performance across various domains of biology, but their ability to reason about biological pathways remains underexplored. This includes reasoning about how perturbations in biological systems lead to various downstream effects through complex intermediate processes. Such reasoning is crucial for explaining and predicting biological phenomena, as well as for formulating hypotheses and designing experiments.

% In this study, we investigate whether LLMs can effectively understand and reason about biological pathways by introducing \benchname, a comprehensive benchmark focusing on reasoning about the effects and mechanisms of natural and synthetic interventions—such as mutations, infections, or treatments—on various downstream targets under different conditions through complex intermediate pathway processes. \benchname spans multiple biological domains and is categorized along three reasoning dimensions, capturing various aspects of pathway reasoning.

% We evaluate LLMs using the \benchname benchmark with reasoning methods like Chain-of-Thought (CoT) and pathway graph-augmented approaches. Results show that while LLMs can understand mechanisms in natural organisms, they struggle with predicting phenomena after perturbations, highlighting their limitations in reasoning about biological pathways. To address these challenges, we propose \modelname, a novel LLM agent that interactively reasons through subgraph-based navigation within pathway graph. This approach enhances LLMs' reasoning in biological pathways by leveraging pathway graph augmentation, particularly in cases involving perturbations, potentially bridging the gap between LLMs' current capabilities and the complexities of biological systems.

% The applications of large language models (LLMs) in various domains of biology have been explored recently, but their reasoning ability in complex biological systems, formulated as pathways, remains underexplored. Such reasoning is crucial for explaining and predicting biological phenomena, formulating hypotheses, and designing experiments.

% In this work, we explore the potential of large language models in core pathway research questions, such as functional understanding, dynamic changes, regulation, and intervention. We first introduce \benchname, which includes 5.1K high-quality, complex biological pathway problems derived from real scientific research scenarios. These encompass various biological pathway research contexts, including natural dynamic changes, disturbances and interventions, additional intervention conditions, and multi-scale research targets such as single factors, interaction processes, and macro functions.

% Our evaluation of reasoning methods such as CoT and graph-augmented reasoning shows that LLMs struggle with pathway reasoning, especially in perturbed systems. To address these challenges, we propose \modelname, a novel LLM agent that interactively reasons through subgraph-based navigation. This approach enhances LLMs' pathway reasoning by leveraging pathway graph augmentation, particularly in cases involving perturbations, potentially bridging the gap between LLMs' current capabilities and the complexities of biological systems.



% In this work, we explore the potential of LLMs in addressing core pathway research questions, such as functional understanding, dynamic changes, regulation, and intervention. We first introduce \benchname, which includes 5.1K high-quality, complex biological pathway problems derived from real scientific research scenarios. These problems cover various biological pathway research contexts, including natural dynamic changes, disturbances and interventions, additional intervention conditions, and multi-scale research targets such as single factors, interaction processes, and macro functions.

% Our evaluation of reasoning methods, such as CoT and graph-augmented reasoning, shows that LLMs struggle with pathway reasoning, especially in perturbed systems. To address these challenges, we propose \modelname, a novel LLM agent that interactively reasons through subgraph-based navigation. This approach enhances LLMs' pathway reasoning by leveraging pathway graph augmentation, particularly in cases involving perturbations, bridging the gap between LLMs' current capabilities and the complexities of biological systems.
The applications of large language models (LLMs) in various biological domains have been explored recently, but their reasoning ability in complex biological systems, such as pathways, remains underexplored, which is crucial for predicting biological phenomena, formulating hypotheses, and designing experiments. This work explores the potential of LLMs in pathway reasoning. We introduce \benchname, a dataset with 5.1K complex pathway problems derived from real research, covering various biological contexts including natural dynamic changes, disturbances, additional intervention conditions, and multi-scale research targets. Our evaluation of methods such as CoT and graph-augmented reasoning, shows that LLMs struggle with pathway reasoning, especially in perturbed systems. To address this, we propose \modelname, an LLM agent that enhances reasoning through interactive subgraph-based navigation, enabling a more effective approach to handling the complexities of biological systems in a scientifically aligned manner. The dataset and code are available at \url{https://github.com/zhao-ht/BioMaze}.


% This includes reasoning about how perturbations in biological systems lead to various downstream effects through complex intermediate processes. 

% In this study, we investigate whether LLMs can effectively understand and reason about biological pathways by introducing \benchname, a comprehensive benchmark focusing on reasoning about the effects and mechanisms of natural and synthetic interventions—such as mutations, infections, or treatments—on various downstream targets under different conditions through complex intermediate pathway processes. \benchname spans multiple biological domains and is categorized along three reasoning dimensions, capturing various aspects of pathway reasoning.

% We evaluate LLMs using the \benchname benchmark with reasoning methods like Chain-of-Thought (CoT) and pathway graph-augmented approaches. Results show that while LLMs can understand mechanisms in natural organisms, they struggle with predicting phenomena after perturbations, highlighting their limitations in reasoning about biological pathways. To address these challenges, we propose \modelname, a novel LLM agent that interactively reasons through subgraph-based navigation within pathway graph. This approach enhances LLMs' reasoning in biological pathways by leveraging pathway graph augmentation, particularly in cases involving perturbations, potentially bridging the gap between LLMs' current capabilities and the complexities of biological systems.


% Biological systems are inherently complex, consisting of interconnected pathway networks where individual molecules interact through multi-step processes, influencing each other and the overall system. 

% In biological research, generating hypotheses, designing experiments, and predicting or interpreting outcomes heavily depend on the ability to reason within these pathway networks.

% \chang{Scientific research represents the pinnacle of intelligence, characterized by a rigorous methodology that includes the meticulous identification of relevant literature, the formulation of hypotheses, the design of experiments, and the prediction of outcomes. Among the most formidable aspects of this process is the capacity for abductive reasoning, which facilitates the derivation of novel conclusions and the resolution of complex questions. Large language models (LLMs) have recently demonstrated remarkable reasoning ability in STEM domains, and thus we aim to assess their ability on such tasks. We mainly focus on a specific type of research in biological domain, solving problems about biological pathways.}

% \chang{\benchname, a comprehensive benchmark focusing on answering de novo questions curated from pathway-related literature. We augment the original questions with perturbations such as intervening causes and negating conditions and require LLM to solve the enhanced problem. This process imitates the research process in biology. We find that simple reasoning methods like Chain-of-Thought could achieve on average xxx\% on \benchname, but the performances could be further improved when using knowledge-based agents. However, we find that most baselines struggle with complex perturbations and we propose \modelname as a solution. Our enhanced agent could navigate biopathway knowledge bases and draw novel conclusions grounded on knowledge, highlighting the potential of leveraging LLMs to think like a biologist.}
