\section{Experiment}

\subsection{Baseline and Metric}

We evaluate the reasoning performance of LLMs on \benchname in both the unaugmented step-by-step reasoning and the pathway graph-augmented methods. We adopt reasoning method without graph augmentation Chain-of-Thought (CoT) \citep{wei2022chain,kojima2022large}, and methods with pathway graph augmentation: {Chain-of-Knowledge (CoK)} \citep{li2023chain}, {Think-of-Graph (ToG)} \citep{sun2023think}, and {G-Retriever} \citep{he2024g}. Details of baselines are in Appendix \ref{appendix baseline}.

For True/False tasks, we compute accuracy averaged across the True and False labels to account for label imbalance in the dataset. For open-ended tasks, the LLM is used to evaluate the accuracy of generated answers by comparing them to the ground truth and determining whether they are correct or incorrect. In this study, we use the LLaMA3.1-405B model as the evaluator, with five in-context examples. The performance of the evaluator is further analyzed in Appendix \ref{subsection evaluator quality}.


\subsection{Main Result}

% \chang{Main problem is that not enough insights are shown in the tables and is overly focused on comparison with your method. Could improve in 1) separate methods using graph / not, with a separate column detailing graph usage. 2) Provide a difficulty score for each task, use weighted average. 3) Use discriminative instead of judging, it's confusing. 4) The name for tasks are not informative, especially like false/true.  }



% \begin{table}[!h]
% \resizebox{\linewidth}{!}{
% \begin{tabular}{cc|cc|cc|ccc}
% \toprule
%   \multicolumn{1}{l}{} &  & \multicolumn{2}{c}{Source} &  \multicolumn{2}{c}{Condition} & \multicolumn{3}{c}{Target}\\

%  &  w.t. Pathway    & Natural & Unnatural & FALSE & TRUE  & Single & Interaction & Function               \\
% \midrule

% GPT-3.5             &      &                           &                           &                           &                           &                           &                           &                           \\
% Viliana (0 Shot)           & \ding{55}    & 76.80   & \underline{67.42}     & 74.30 & \underline{66.23} & 68.90  & 78.97       & 71.44    \\
% Viliana (2 Shot)           & \ding{55}    & 72.09   & 70.22     & 71.28 & 70.28 & 70.48  & 81.24       & 67.15    \\
% CoT (0 Shot)               & \ding{55}    & 78.02   & 65.45     & 75.08 & 64.35 & 68.45  & 69.75       & 75.23    \\
% CoT (2 Shot)               & \ding{55}    & 77.03   & 67.13     & 73.65 & 68.92 & 68.92  & 79.26       & 71.85    \\
% ToG                        & \ding{51}    & 74.57   & 69.66     & 74.17 & 68.04 & 70.03  & 73.67       & 73.80    \\
% CoK                        & \ding{51}    & 77.47   & 68.54     & 73.09 & 72.95 & 67.92  & 80.56       & 73.86    \\
% G-Retriever                & \ding{51}    & 76.26   & 70.20     & 75.72 & 70.81 & 73.04  & 76.21       & 73.59    \\
% \modelname                 & \ding{51}    & 78.85   & 74.44     & 77.63 & 74.36 & 78.01  & 81.66       & 73.78  \\
% \midrule

% LLaMA3 8B                   &                           &                           &                           &                           &                           &                           &                           \\
% Viliana (0 Shot)  & \ding{55}    & 80.49   & 67.70     & 76.78 & 67.17 & 75.27  & 73.88       & 73.27    \\
% Viliana (2 Shot)  & \ding{55}    & 80.19   & 72.75     & 78.42 & 70.69 & 79.72  & 83.18       & 70.85    \\
% CoT (0 Shot)      & \ding{55}    & 75.07   & 67.13     & 72.04 & 68.66 & 73.15  & 80.15       & 66.33    \\
% CoT (2 Shot)      & \ding{55}    & 81.77   & 71.63     & 79.04 & 70.67 & 79.73  & 84.35       & 71.52    \\
% ToG               & \ding{51}    & 79.37   & 69.31     & 76.96 & 67.60 & 76.57  & 83.17       & 69.16    \\
% CoK               & \ding{51}    & 80.20   & 67.70     & 75.87 & 69.00 & 77.27  & 81.11       & 68.93    \\
% G-Retriever       & \ding{51}    & 80.59   & 72.29     & 81.17 & 70.06 & 80.97  & 82.29       & 73.53    \\
% \modelname    & \ding{51}    & 83.08   & 75.84     & 82.14 & 72.27 & 81.07  & 86.62       & 75.01    \\

% \bottomrule
% \end{tabular}
% }
% \caption{Performance on \benchname True/False tasks.}
% \label{table judge performance}
% \end{table}



% \begin{table}[!h]
% \resizebox{\linewidth}{!}{
% \begin{tabular}{cc|cc|cc|ccc}
% \toprule
%   \multicolumn{1}{l}{} &  & \multicolumn{2}{c}{Source} &  \multicolumn{2}{c}{Condition} & \multicolumn{3}{c}{Target}\\

%  &  w.t. Pathway    & Natural & Unnatural & FALSE & TRUE  & Single & Interaction & Function               \\
% \midrule
% GPT-3.5                   &                           &                           &                           &                           &                           &                           &                           \\

% CoT (0 Shot)                   & \ding{55} & 76.60   & 67.67     & 72.93 & 68.28 & 73.20  & 64.86       & 71.50    \\
% CoT (2 Shot)                   & \ding{55} & 82.67   & 73.66     & 79.66 & 72.69 & 83.28  & 63.51       & 75.73    \\
% ToG                  & \ding{51} & 74.77   & 65.27     & 70.81 & 66.08 & 72.13  & 62.16       & 68.60    \\
% CoK                & \ding{51} & 82.98   & 73.43     & 80.41 & 70.93 & 82.30  & 67.57       & 75.73    \\
% G-Retriever                    & \ding{51} & 84.38   & 72.84     & 80.78 & 74.37 & 82.55  & 70.40       & 76.92    \\
% \modelname                   & \ding{51} & 87.84   & 77.91     & 83.65 & 78.85 & 85.29  & 77.03       & 80.74    \\
% \midrule

% LLaMA3 8B                   &                           &                           &                           &                           &                           &                           &                           \\
% CoT (0 Shot)    & \ding{55} & 82.37   & 69.53     & 77.63 & 69.16 & 76.14  & 62.16       & 76.78    \\
% CoT (2 Shot)    & \ding{55} & 80.55   & 67.91     & 75.94 & 67.40 & 77.78  & 55.41       & 73.35    \\
% ToG             & \ding{51} & 84.80   & 73.49     & 80.64 & 73.13 & 82.68  & 74.32       & 75.73    \\
% CoK             & \ding{51} & 80.55   & 70.70     & 77.82 & 68.28 & 78.43  & 64.86       & 74.14    \\
% G-Retriever     & \ding{51} & 82.62   & 72.10     & 77.21 & 75.92 & 80.71  & 72.53       & 75.65    \\
% \modelname      & \ding{51} & 84.50   & 76.51     & 80.64 & 78.41 & 83.01  & 78.38       & 77.84   \\
% \bottomrule
% \end{tabular}
% }
% \caption{Performance on \benchname open-ended tasks.}
% \label{table generative performance}
% \end{table}


\begin{table*}[!h]
\centering
\resizebox{1.0\linewidth}{!}{
\begin{tabular}{lc|cc|cc|ccc}
\toprule
  \multirow{2}{*}{\textbf{Method}} & \multirow{2}{*}{\textbf{w. Pathway Graph}} & \multicolumn{2}{c|}{\textbf{Inquiry Type}} &  \multicolumn{2}{c|}{\textbf{Extra Condition}} & \multicolumn{3}{c}{\textbf{Investigation Target}}\\

 &    & Normal & Perturbed & Natural & Intervened  & Single & Interaction & Function               \\
\midrule

\textcolor{brown}{\underline{\emph{GPT-3.5 }} }          &      &                           &                           &                           &                           &                           &                           &                           \\

% Viliana (0 Shot) & \multirow{4}{*}{\ding{55}}  & 57.92 & 54.60 & 56.99 & 54.88 & 59.91 & 55.63 & 56.68 \\
% Viliana (2 Shot) &  & 60.73 & 55.59 & 57.40 & 59.39 & 60.30 & 46.43 & 58.26 \\
% CoT (0 Shot)     &  & 59.92 & 61.48 & 62.74 & 51.00 & 57.69 & 56.75 & 66.25 \\
% CoT (2 Shot)     &  & 64.92 & 56.39 & 61.46 & 57.12 & 60.86 & 61.01 & 59.92 \\
% \midrule
% ToG              & \multirow{4}{*}{\ding{51}} & 59.60 & 50.83 & 53.92 & 62.50 & 53.40 & 60.00 & 55.21 \\
% CoK              &  & 60.70 & 54.07 & 57.29 & 56.49 & 60.19 & 50.00 & 58.04 \\
% G-Retriever      &  & 64.14 & 59.32 & 61.55 & 61.88 & 61.53 & 59.00 & 62.60 \\
% \modelname       &  & 63.55 & 63.93 & 57.48 & 62.74 & 62.85 & 64.73 & 68.13 \\

Vanilla (0 Shot) & \multirow{4}{*}{\ding{55}}  & 57.92 & 54.60 & 56.99 & 54.88 & 59.91 & 55.63 & 56.68 \\
Vanilla (2 Shot) &  & 60.73 & 55.59 & 57.40 & 59.39 & 60.30 & 46.43 & 58.26 \\
CoT (0 Shot)     &  & 59.92 & \underline{61.48} & \textbf{62.74} & 51.00 & 57.69 & 56.75 & \underline{66.25} \\
CoT (2 Shot)     &  & \textbf{64.92} & 56.39 & 61.46 & 57.12 & 60.86 & \underline{61.01} & 59.92 \\
\midrule
ToG              & \multirow{4}{*}{\ding{51}} & 59.60 & 50.83 & 53.92 & \underline{62.50} & 53.40 & 60.00 & 55.21 \\
CoK              &  & 60.70 & 54.07 & 57.29 & 56.49 & 60.19 & 50.00 & 58.04 \\
G-Retriever      &  & \underline{64.14} & 59.32 & \underline{61.55} & 61.88 & \underline{61.53} & 59.00 & 62.60 \\
\modelname      &  & 63.55 & \textbf{63.93} & 57.48 & \textbf{62.74} & \textbf{62.85} & \textbf{64.73} & \textbf{68.13} \\

\midrule
\midrule
\textcolor{brown}{\underline{\emph{LLaMA3.1 8B }} }                   &                           &                           &                           &                           &                           &                           &                           \\


Vanilla (0 Shot) & \multirow{4}{*}{\ding{55}}  & 55.82 & 56.64 & 57.21 & 53.37 & 57.87 & 58.31 & 55.66 \\
Vanilla (2 Shot) &  & 55.92 & 58.88 & 60.04 & \underline{59.20} & \textbf{61.88} & 60.75 & 54.14 \\
CoT (0 Shot)     &  & 63.01 & 54.35 & 59.50 & 53.90 & 59.22 & 62.27 & 55.68 \\
CoT (2 Shot)     &  & 62.47 & \underline{57.73} & \underline{60.45} & 58.15 & 60.28 & 59.97 & \underline{59.47} \\
\midrule
ToG              & \multirow{4}{*}{\ding{51}}  & 58.99 & 55.31 & 56.67 & 58.35 & 56.79 & 57.85 & 57.10 \\
CoK              &  & 62.01 & 52.89 & 59.41 & 50.23 & 57.46 & \underline{62.57} & 55.43 \\
G-Retriever      &  & \underline{63.43} & 57.71 & 56.88 & 53.90 & \underline{61.54} & 60.01 & 59.10 \\
\modelname       &  & \textbf{63.69} & \textbf{60.25} & \textbf{62.30} & \textbf{62.91} & 61.27 & \textbf{63.19} & \textbf{63.99} \\
\bottomrule
\end{tabular}
}
\caption{Accuracy (\%) on \benchname True/False tasks (50\% corresponds to the random guessing baseline). The optimal results are in bold and the suboptimal ones are underlined.}
\label{table judge performance}
\vspace{-2mm}
\end{table*}



\begin{table*}[!h]
\centering
\resizebox{1.0\linewidth}{!}{
\begin{tabular}{lc|cc|cc|ccc}
\toprule
\multirow{2}{*}{\textbf{Method}} & \multirow{2}{*}{\textbf{w. Pathway Graph}} & \multicolumn{2}{c|}{\textbf{Inquiry Type}} &  \multicolumn{2}{c|}{\textbf{Extra Condition}} & \multicolumn{3}{c}{\textbf{Investigation Target}}\\

 &      & Normal & Perturbed & Natural & Intervened  & Single & Interaction & Function               \\
\midrule
\textcolor{brown}{\underline{\emph{GPT-3.5 }} }                 &                           &                           &                           &                           &                           &                           &                           \\

% CoT (0 Shot) & \multirow{2}{*}{\ding{55}} & 65.96                         & 61.49                        & 67.15                        & 43.24                        & 61.57                        & 61.90                        & 66.67                        \\
% CoT (2 Shot) &  & 65.43                        & 59.08                        & 63.29                        & 56.25                        & 67.76                        & 66.29                        & 53.26                        \\
% \midrule
% ToG          & \multirow{4}{*}{\ding{51}} & 65.52                        & 59.86                        & 64.71                        & 48.65                        & 66.39                        & 64.00                        & 56.17                        \\
% CoK          &  & 70.27                        & 54.00                        & 63.87                        & 50.00                        & 62.93                        & 67.00                        & 58.18                        \\
% G-Retriever  &  & {\color[HTML]{FF0000} 65.19} & {\color[HTML]{FF0000} 61.54} & {\color[HTML]{FF0000} 64.18} & {\color[HTML]{FF0000} 53.70} & {\color[HTML]{FF0000} 68.72} & {\color[HTML]{FF0000} 66.01} & {\color[HTML]{FF0000} 55.11} \\
% \modelname   &  & 67.51                        & 64.33                        & 66.87                        & 57.59                        & 65.16                        & 67.76                        & 65.79        \\

CoT (0 Shot) & \multirow{2}{*}{\ding{55}}  & 65.96 & 61.49 & \textbf{67.15} & 43.24 & 61.57 & 61.90 & \textbf{66.67} \\
CoT (2 Shot) &  & 65.43 & 59.08 & 63.29 & \underline{56.25} & \underline{67.76} & 66.29 & 53.26 \\
\midrule
ToG & \multirow{4}{*}{\ding{51}} & 65.52 & 59.86 & 64.71 & 48.65 & 66.39 & 64.00 & 56.17 \\
CoK &  & \textbf{70.27} & 54.00 & 63.87 & 50.00 & 62.93 & \underline{67.00} & 58.18 \\
G-Retriever &  & 65.19 & \underline{61.54} & 64.18 & 53.70 & \textbf{68.72} & 66.01 & 55.11 \\
\modelname  &  & \underline{67.51} & \textbf{64.33} & \underline{66.87} & \textbf{57.59} & 65.16 & \textbf{67.76} & \underline{65.79} \\

\midrule
\midrule

\textcolor{brown}{\underline{\emph{LLaMA3.1 8B }} }                    &                           &                           &                           &                           &                           &                           &                           \\

% CoT (0 Shot) & \multirow{2}{*}{\ding{55}}  & 62.79                        & 57.19                        & 61.50                        & 51.16                        & 62.77                        & 62.50                        & 55.31                        \\
% CoT (2 Shot) &  & 58.09                        & 49.52                        & 55.31                        & 45.11                        & 60.06                        & 60.32                        & 42.61                        \\
% \midrule
% ToG          & \multirow{4}{*}{\ding{51}}  & 52.14                        & 49.48                        & 52.05                        & 43.60                        & 53.33                        & 55.24                        & 45.68                        \\
% CoK          &  & 60.55                        & 55.23                        & 59.12                        & 50.63                        & 61.12                        & 62.50                        & 52.15                        \\
% G-Retriever  &  & {\color[HTML]{FF0000} 53.83} & {\color[HTML]{FF0000} 51.19} & {\color[HTML]{FF0000} 53.27} & {\color[HTML]{FF0000} 48.10} & {\color[HTML]{FF0000} 57.79} & {\color[HTML]{FF0000} 55.44} & {\color[HTML]{FF0000} 46.52} \\
% \modelname   &  & 61.65                        & 60.78                        & 61.30                        & 60.60                        & 64.14                        & 64.43                        & 55.07     \\

CoT (0 Shot) & \multirow{2}{*}{\ding{55}}  & \textbf{62.79} & \underline{57.19} & \textbf{61.50} & \underline{51.16} & \underline{62.77} & 62.50 & \textbf{55.31} \\
CoT (2 Shot) &  & 58.09 & 49.52 & 55.31 & 45.11 & 60.06 & 60.32 & 42.61 \\
\midrule
ToG &  \multirow{4}{*}{\ding{51}} & 52.14 & 49.48 & 52.05 & 43.60 & 53.33 & 55.24 & 45.68 \\
CoK &  & 60.55 & 55.23 & 59.12 & 50.63 & 61.12 & \underline{62.50} & 52.15 \\
G-Retriever &  & 53.83 & 51.19 & 53.27 & 48.10 & 57.79 & 55.44 & 46.52 \\
\modelname  &  & \underline{61.65} & \textbf{60.78} & \underline{61.30} & \textbf{60.60} & \textbf{64.14} & \textbf{64.43} & \underline{55.07} \\

\bottomrule
\end{tabular}
}
\caption{Accuracy (\%, evaluated by LLM) on \benchname open-ended tasks.  The optimal results are in bold and the suboptimal ones are underlined.}
\label{table generative performance}
\vspace{-2mm}
\end{table*}


We evaluate \modelname and baseline methods on \benchname, presenting results in Tables \ref{table judge performance} and \ref{table generative performance}. The comparison covers task dimensions including signal source, additional conditions, and target. The results lead to the following conclusions:

\textbf{LLMs struggle with biological pathway reasoning.} Pathway reasoning tasks in \benchname are tough for LLMs, with True/False accuracy slightly above random. Both CoT and graph-augmented reasoning reveal the gap between LLM capabilities and the complexity of biological systems.

\textbf{Perturbation query in \benchname presents significant challenges.} LLMs perform worse with perturbed inquiry settings than normal ones, especially in True/False and open-ended formats. This suggests that reasoning about biological pathways is harder in intervention scenarios, where the events are less aligned with common biological knowledge. answerable using established biological knowledge about how typical pathways work.

\textbf{Intervened conditions present greater reasoning challenges.} Like perturbations, intervention condition complicate reasoning by disrupting the biological system. These scenarios require more deductive reasoning, as they rely less on typical biological knowledge.

\textbf{Reasoning target brings diverse challenges for reasoning.} The Investigation target creates varied difficulties, causing inconsistent performance across models and reasoning methods. "Function as target" is the most difficult category.


\textbf{Pathway augmentation can enhance reasoning in biological systems, especially for intervention cases.} As shown in Tables \ref{table judge performance} and \ref{table generative performance}, reasoning methods with pathway augmentation, especially \modelname, outperform non-augmented approaches. \modelname consistently exceeds CoT across most question types and categories, regardless of the backbone model, highlighting the value of integrating biological pathways to enhance reasoning in biological systems. Additionally, \modelname outperforms other graph augmentation methods, demonstrating the effectiveness of its subgraph-based navigation approach. Notably, it reduces the performance gap between natural and intervened/perturbed groups, helping bridge the gap in pathway causal reasoning.





% \begin{table}[!h]
% \begin{tabular}{ccccccccc}
% \hline
% \hline

%  & CF                   & CI                   & C2F                  & C2C                  & I2F                  & I2C                  & I2I                  & Category Avg.     \\

%  \hline

%  GPT-3.5 \\

% Viliana (0 Shot)             & 100.00               & 91.67                & 67.86                & 68.61                & 75.79                & 68.04                & 66.67                & 76.95                \\
% Viliana (2 Shot)             & 100.00               & 95.83                & 63.99                & 72.02                & 67.06                & 65.06                & 66.67                & 75.80                \\
% CoT (0 Shot)                 & 77.78                & 86.00                & 74.12                & 75.41                & 76.54                & 67.67                & 37.50                & 70.72                \\
% CoT (2 Shot)                 & 83.33                & 75.50                & 76.86                & 79.93                & 74.69                & 69.64                & 37.50                & 71.07                \\
% ToG (2 shot)                 & 94.44                & 73.50                & 71.18                & 80.26                & 78.40                & 68.32                & 50.00                & 73.73                \\
% CoK (2 shot)    & 77.78                & 71.50                & 73.53                & 77.67                & 75.93                & 68.98                & 50.00                & 70.77                \\
% \modelname             & 94.44                & 85.50                & 81.96                & 83.67                & 76.54                & 77.95                & 87.50                & 83.94           \\    

% \hline 
% LLaMa3-8B \\

% Viliana (0 Shot)           & 83.33                & 81.50                & 79.22                & 78.48                & 70.37                & 71.37                & 37.50                & 71.68                \\
% Viliana (2 Shot)           & 44.44                & 87.50                & 72.16                & 80.94                & 71.60                & 75.56                & 37.50                & 67.10                \\
% CoT (0 Shot)               & 44.44                & 81.50                & 72.94                & 76.37                & 71.60                & 71.91                & 87.50                & 72.32                \\
% CoT (2 Shot)               & 94.44                & 81.50                & 81.37                & 83.82                & 73.46                & 77.17                & 87.50                & 82.75                \\
% ToG (2 shot)               & 94.44                & 83.15                & 76.65                & 80.28                & 70.51                & 70.23                & 87.50                & 80.40                \\
% CoK (2 shot)      & 94.44                & 83.50                & 81.37                & 80.74                & 74.69                & 70.18                & 37.50                & 74.63                \\
% \modelname       & 94.44                & 96.00                & 80.98                & 83.51                & 82.10                & 84.94                & 87.50                & 87.07      \\

% \hline
% \hline

% \end{tabular}
% \caption{Performance of \modelname and baselines on \benchname judging tasks.}
% \label{main result judging}
% \end{table}



% \begin{table}[!h]
% \begin{tabular}{cccccccccc}
% \hline
% \hline

%     & CF                   & CI                   & C2F                  & C2C                  & I2F                  & I2C                  & I2I                  & Category Avg.     & Avg.              \\

% \hline


% LLaMa3-8B              \\
% CoT (0 Shot)               & 11.76                & 8.33                 & 34.15                & 23.68                & 30.43                & 20.78                & 0.00                 & 18.45                & 24.03                \\
% CoT (2 Shot)               & 5.88                 & 8.33                 & 26.83                & 18.42                & 19.57                & 22.08                & 0.00                 & 14.44                & 19.48                \\
% ToG (2 shot)               & 5.88                 & 0.00                 & 36.59                & 25.66                & 23.91                & 25.00                & 0.00                 & 16.72                & 24.51                \\
% CoK (2 shot)               & 5.88                 & 8.33                 & 36.59                & 21.93                & 30.43                & 23.38                & 0.00                 & 18.08                & 24.03                \\
% \modelname                 & 5.88                 & 8.33                 & 21.95                & 24.56                & 26.09                & 24.68                & 0.00                 & 15.93                & 22.73           \\    
% % \end{tabular}
% % \end{table}
% \hline

% % \begin{table}[]
% % \begin{tabular}{cccccccccc}
%         & CF                   & CI                   & C2F                  & C2C                  & I2F                  & I2C                  & I2I                  & Category Avg.     & Avg.              \\
% GPT-3.5  \\
% CoT (0 Shot)               & 0.00                 & 16.67                & 17.07                & 16.67                & 26.09                & 16.88                & 0.00                 & 13.34                & 17.21                \\
% CoT (2 Shot)               & 0.00                 & 0.00                 & 21.95                & 24.56                & 13.04                & 18.18                & 0.00                 & 11.11                & 18.51                \\
% ToG (2 shot)               & 0.00                 & 0.00                 & 4.88                 & 21.05                & 19.57                & 16.88                & 0.00                 & 8.91                 & 15.58                \\
% CoK (2 shot)       & 5.88                 & 8.33                 & 17.07                & 18.42                & 21.74                & 12.99                & 0.00                 & 12.06                & 16.23                \\
% \modelname         & 5.88                 & 25.00                & 24.39                & 23.68                & 28.26                & 24.68                & 0.00                 & 18.84                & 23.70          \\     
% \hline
% \hline

% \end{tabular}
% \caption{Performance of \modelname and baselines on \benchname generative tasks.}
% \label{main result judging}
% \end{table}


% \subsection{De novo and Missing Knowledge Experiment}

% To see whether \modelname can reason on known biological knowledge and infer potential new pathway relationships, 

% \subsection{Knowledge Probing: Correlation between Toy and Practical Task}

\subsection{Analysis}

% \chang{Figure 2, 3 would be better if include more methods. It would be insightful to know like including graph / stronger reasoner designs make it easier to reason on more difficult tasks；what is the strength or weakness of different designs }

% In this subsection, we analyze the backbone model ability and reasoning patterns for biological pathways.

\begin{figure*}[!t]
    \centering    
    \renewcommand{\thesubfigure}{} % Hide subfigure labels
    \subfigure[]{\includegraphics[width=0.90\linewidth]{fig/plot_model_comp_judge.pdf}} \\
    \vspace{-10mm}
    \subfigure[]{\includegraphics[width=0.90\linewidth]{fig/plot_model_comp_reasoning.pdf}} 
    \vspace{-2mm}
    \caption{Comparison of the reasoning abilities of different LLMs for biological pathways. While overall performance improves with larger and more powerful models, a consistent gap exists between normal/perturbed and natural/intervened settings. This highlights the inherent limitations of LLMs in reasoning about the causal relationships within biological pathways.}
    \label{fig model comp}
    \vspace{-2mm}
\end{figure*}

\textbf{Backbone Ability for Pathway Reasoning} We compare the performance of different backbones in Figure \ref{fig model comp}. As the model size and capacity increase, overall performance improves, indicating a strong correlation between an LLM’s general reasoning ability and its performance in pathway reasoning. However, a consistent gap remains between the normal/perturbed and natural/intervened settings across different backbones. This underscores the inherent limitations of LLMs in reasoning about causal relationships within biological pathways.





\textbf{Reasoning Difficulty with Steps} To explore the relationship between task difficulty and reasoning steps in \benchname, we prompted LLaMA3.1-405B to explain its reasoning process based on the correct answer and pathway to get the step numbers.

Figure \ref{fig reasoning step} shows that Chain-of-Thought (CoT) performance declines as reasoning steps increase, suggesting that more steps lead to higher reasoning difficulty. This supports our hypothesis that the complexity of the pathways is one factor of challenges in biological pathway reasoning.

Notably, \modelname's performance remains more consistent across different reasoning step counts. This suggests that augmenting LLMs with biological pathway information can mitigate the challenges of pathway reasoning, particularly when dealing with intricate intermediate processes.


\begin{figure}[!h]
    \centering    
    \renewcommand{\thesubfigure}{} % Hide subfigure labels
    \subfigure[]
    {\includegraphics[width=0.45\linewidth]{fig/plot_judge_score_step_fit_std.pdf}}{\includegraphics[width=0.45\linewidth]{fig/plot_reasoning_score_step_fit_std.pdf}}

    \vspace{-2mm}
    \caption{Performance versus reasoning steps. LLMs face increasing difficulty in reasoning about biological systems as task complexity rises and requires more reasoning steps. In contrast, pathway augmentation significantly mitigates the drop of performance for tasks that involve more steps.}
    \label{fig reasoning step}
    \vspace{-2mm} 
\end{figure}

\textbf{Failure Reasons Statistics} We analyze failed cases in biological pathway reasoning, covering CoT and \modelname, and classify the failures into: (1) \textbf{Unresolved Conclusion (UC)} For cases where the model fails to provide a definitive answer, indicating uncertainty or belief that the answer is unknown.
(2) \textbf{Incomplete Answer (IA)}  When the response lacks essential details, such as missing the requested effects or other key elements.
(3) \textbf{Omission in Reasoning (OR)}  For errors where critical pathway steps in the question's biological process are left out, causing the final answer to be incorrect.
(4) \textbf{Faulty in Reasoning (FR)} When the reasoning path is correct, but there are significant errors in deducing the events within that pathway. We manually classify 200 random samples from these error cases to approximate the overall error cases, with a professional biology Ph.D. student.

The results in Figure \ref{fig error analysis} show that in both True/False and open-ended tasks, the main error in CoT reasoning is faulty reasoning, where LLMs correctly identify the biological pathway but misinterpret the events within it. Another key error is omission, where critical steps or branches of the pathway are overlooked. This highlights the challenges LLMs face in reasoning about biological pathways, due to both knowledge gaps and difficulties in deductive reasoning.

\modelname reduces faulty reasoning by providing pathway graphs, improving accuracy. However, omissions remain a challenge, often due to limitations in the pathway database and browsing issues. With pathways available, LLMs are more confident and less fail in drawing conclusions.


\begin{figure}[!t]
    \centering    
    \renewcommand{\thesubfigure}{} % Hide subfigure labels
    \subfigure[]{\includegraphics[width=0.45\linewidth]{fig/reasoning_error_ratio_GPT3.5_y.pdf}}
    % {\includegraphics[width=0.24\linewidth] {fig/reasoning_error_ratio_LLaMA3 8B_y.pdf}} 
    % \subfigure[]
    {\includegraphics[width=0.45\linewidth]{fig/judge_error_ratio_GPT3.5_y.pdf}}
    % {\includegraphics[width=0.24\linewidth]{fig/judge_error_ratio_LLaMA3 8B_y.pdf}}
    \vspace{-2mm}
    \caption{Error analysis for CoT reasoning and reasoning with pathway augmentation (our method \modelname). The primary cause of errors in (CoT) reasoning for biological systems is due to both faulty reasoning and omissions in reasoning. When pathway augmentation is applied, omissions in reasoning become the predominant issue, but the rate of faulty reasoning is significantly reduced, thereby improving the overall reasoning accuracy of LLMs in biological systems.}
    \label{fig error analysis}
    \vspace{-2mm} 
\end{figure}


% \textbf{Performance with Biological Domain} Figure \ref{fig bio radar} presents a comparison of the performance of various reasoning methods across different biological domains in \benchname. The results demonstrate that the difficulty of each domain varies depending on the reasoning method used. Overall, \modelname, when augmented with pathway information, consistently outperforms direct reasoning across nearly all biological domains. The results of more backbones are in Appendix \ref{appendix bio radar full}.

% \begin{figure*}[!t]
%     \centering    
%     \renewcommand{\thesubfigure}{} % Hide subfigure labels
%     \subfigure[]{\includegraphics[width=0.36\linewidth]{fig/plot_radar_map_judge_GPT3.5.pdf}} 
%     \subfigure[]{\includegraphics[width=0.36\linewidth]
%     {fig/plot_radar_map_reasoning_GPT3.5.pdf}} 
%     \vspace{-7mm}
%     \caption{GPT-3.5's performance across different biological domains in \benchname.}
%     \label{fig bio radar}
%     \vspace{-3mm}
% \end{figure*}

% \begin{table*}[!h]
%     \centering
%         \caption{Performance of \modelname and baselines on \benchname True or False question's domains. \todo{plot this part in figure.}}
%     % \vspace{-3mm}
% \begin{tabular}{lcccccccc}
% \hline
% \hline
%  % & Signal transduction & Protein and protein interaction & Regulation of gene expression & Protein and compound interaction & Cell growth and death & Disease and others & Category Average \\
% & Avg. & ST & PPI & RGE & PCI & CGD & DO & Category Avg. \\
% \hline
% % GPT-3.5 t=0.0 & & & & & & & \\
% Viliana (0 Shot) & 66.53 & 74.45 & 60.81 & 67.42 & 63.11 & 72.22 & 43.18 & 63.53 \\
% Viliana (2 Shot) & 64.82 & 71.05 & 63.00 & 60.61 & 56.99 & 69.44 & 47.73 & 61.47 \\
% CoT (0 Shot) & 68.81 & 70.71 & 65.51 & 79.55 & 72.55 & 66.67 & 49.24 & 67.37 \\
% CoT (2 Shot) & 70.60 & 76.91 & 65.32 & 78.03 & 70.98 & 66.67 & 55.30 & 68.87 \\
% ToG (2 shot) & 69.91 & 73.37 & 67.31 & 79.17 & 65.16 & 63.89 & 67.50 & 69.40 \\
% CoK(2 shot) & 72.24	& 78.36 &	65.08 &	82.73 &	72.94 &	72.55 &	62.07 &	72.29 \\
% \modelname & 78.75 & 81.16 & 77.78 & 84.09 & 77.10 & 80.56 & 65.91 & 77.76 \\
% \hline
% \hline
% \end{tabular}
% \end{table*}

% \begin{table*}[!h]
%     \centering
%         \caption{Performance of \modelname and baselines on \benchname generative question's domains. \todo{plot this part in figure.}}
% \begin{tabular}{lcccccccc}
% \hline
% \hline
%  % & Signal transduction & Protein and protein interaction & Protein and compound interaction & Regulation of gene expression & Cell growth and death & Disease and others & Category Average \\
%  & Avg. & ST & PPI & PCI & RGE  & CGD & DO & Category Avg. \\
%  \hline
% % Viliana (0 Shot) & & & & & & & \\
% % Viliana (2 Shot) & & & & & & & \\
% CoT (0 Shot) & 43.63 & 41.82 & 43.14 & 38.89 & 47.83 & 30.77 & 57.69 & 43.39 \\
% CoT (2 Shot) & 33.82 & 47.27 & 43.14 & 19.44 & 34.78 & 23.08 & 11.54 & 30.44 \\
% ToG (2 shot) & 30.39 & 43.64 & 31.37 & 13.89 & 43.48 & 23.08 & 15.38 & 28.75 \\
% CoK(2 shot) & 44.35 &	47.24 &	44.02 &	29.43 &	44.94 &	29.03 &	36.73 &	39.39 \\
% % \modelname  & & & & & & & \\
% \modelname & 50.00 & 61.82 & 58.82 & 30.56 & 52.17 & 38.46 & 38.46 & 47.18 \\
% \hline
% \hline
% \end{tabular}
% \end{table*}





% \textbf{Dependency Judging or Effect Judging}

% \textbf{With Controlled Experiment or Not}



% \begin{table}[!h]
% \centering
% \resizebox{0.8\linewidth}{!}
% {
% \begin{tabular}{lccccc}
% \toprule
% Agent \#Steps          & 1-4   & 4-6   & 6-8   & 8-10 & $\ge$10  \\
% \midrule
% True / False     & 0.91 &	50.14	& 26.58 &	12.66 &	9.70 \\
% Open-Ended & 1.45 &	52.44 &	25.69 &	13.97 &	6.46\\
% \bottomrule
% \end{tabular}
% }
% \vspace{-2mm}
% \caption{Agent steps distribution (\%) of \modelname during task completion.}
% \label{table agent steps}
% \vspace{-4mm}
% \end{table}

% \begin{table}[!h]
% \centering
% \resizebox{0.5\linewidth}{!}{
% \begin{tabular}{lcc}
% \toprule
%    Task Type       & Global & Local \\
% \midrule
% True / False     & 1.47 &	3.62  \\
% Open-Ended & 1.57 &	3.43  \\
% \bottomrule
% \end{tabular}
% }
% \vspace{-2mm}
% \caption{Average API usage times of \modelname during task completion.}
% \label{table API usage}
% \vspace{-5mm}
% \end{table}



\begin{minipage}{\textwidth}
\begin{minipage}[b]{0.48\textwidth}
\makeatletter\def\@captype{table}
\centering
\resizebox{0.84\linewidth}{!}
{
\begin{tabular}{lccccc}
\toprule
Agent \#Steps          & 1-4   & 4-6   & 6-8   & 8-10 & $\ge$10  \\
\midrule
True / False     & 0.91 &	50.14	& 26.58 &	12.66 &	9.70 \\
Open-Ended & 1.45 &	52.44 &	25.69 &	13.97 &	6.46\\
\bottomrule
\end{tabular}
}
\vspace{-2mm}
\caption{Agent steps distribution (\%) of \modelname during task completion.}
\label{table agent steps}
\vspace{-2mm}

\end{minipage}
\hspace{0.3cm}
\begin{minipage}[b]{0.48\textwidth}
\makeatletter\def\@captype{table}
\centering
\resizebox{0.5\linewidth}{!}{
\begin{tabular}{lcc}
\toprule
   Task Type       & Global & Local \\
\midrule
True / False     & 1.47 &	3.62  \\
Open-Ended & 1.57 &	3.43  \\
\bottomrule
\end{tabular}
}
\vspace{-2mm}
\caption{Average API usage times of \modelname during task completion.}
\label{table API usage}
\vspace{-2mm}
\end{minipage}
\end{minipage}




\subsection{Method Analysis and Ablation Study}

% \subsubsection{Agent Retriever Analysis}


\textbf{API Usage and Step Distribution} We analyze \modelname's agent behavior by reviewing task steps and API usage. Tables \ref{table agent steps} and \ref{table API usage} show that most tasks are completed in six or fewer steps, though some require over ten due to missing pathway data. On average, the agent performs 1.5 global searches and over three local navigations per task, indicating frequent subgraph exploration.



% \begin{minipage}{\textwidth}
% \begin{minipage}[b]{0.48\textwidth}
% \makeatletter\def\@captype{table}
% \centering
% \caption{Agent steps distribution (\%) of \modelname during task completion.}
% \label{table agent steps}
% \resizebox{0.99\linewidth}{!}
% {
% \begin{tabular}{cccccc}
% \toprule
% Agent Steps          & 1-4   & 4-6   & 6-8   & 8-10 & $\ge$10  \\
% \midrule
% True/False     & 14.35 & 42.26 & 20.97 & 9.68 & 12.74 \\
% Open-Ended & 19.50 & 41.77 & 15.94 & 8.43 & 14.36\\
% \bottomrule
% \end{tabular}
% }

% \end{minipage}
% \hspace{0.3cm}
% \begin{minipage}[b]{0.48\textwidth}
% \makeatletter\def\@captype{table}
% \centering
% \caption{Average API usage times of \modelname during task completion.}
% \label{table API usage}
% \resizebox{0.62\linewidth}{!}{
% \begin{tabular}{ccc}
% \toprule
%           & Global & Local \\
% \midrule
% True/False     & 1.51   & 3.40  \\
% Open-Ended & 1.62   & 3.26  \\
% \bottomrule
% \end{tabular}
% }
% \end{minipage}
% \end{minipage}




% \begin{table}[!h]
% \centering
% \begin{tabular}{cccccc}
% \toprule
% Agent Steps          & 1-4   & 4-6   & 6-8   & 8-10 & $\ge$10  \\
% \midrule
% Judge     & 14.35 & 42.26 & 20.97 & 9.68 & 12.74 \\
% Reasoning & 19.50 & 41.77 & 15.94 & 8.43 & 14.36\\
% \bottomrule
% \end{tabular}
% \caption{Agent steps of \modelname during task completion.}
% \label{table agent steps}
% \end{table}

% \begin{table}[!h]
% \centering
% \begin{tabular}{ccc}
% \toprule
%           & Global & Local \\
% \midrule
% Judge     & 1.51   & 3.40  \\
% Reasoning & 1.62   & 3.26  \\
% \bottomrule
% \end{tabular}
% \caption{Average API usage times of \modelname during task completion.}
% \label{table API usage}
% \end{table}


\textbf{Ablation Study} To evaluate \modelname's components, we perform ablation studies, with results for LLaMA3-8B in Table \ref{table ablation}. The most important component is FinalReaser; without it, the agent's answers degrade due to long task history. The local search API is also crucial for efficient graph navigation, and the graph encoding method improves performance, highlighting the value of encoding graph data for sequential models.

\begin{table*}[!h]
\centering
\resizebox{0.98\linewidth}{!}{
\begin{tabular}{lcccccc}
\toprule
  Task Type        & \modelname & w.o. RemoveSeen & w.o. DFSOrder & w.o. TripleToText  & w.o. Local search & w.o. FinalReasoner \\
\midrule
True / False     & \textbf{61.87} &	57.48 &	58.60 &	58.32 &	57.78 &	56.97             \\
Open-Ended & \textbf{61.21} &	58.96 &	55.82 &	57.06 &	57.46 &	58.25         \\
\bottomrule
\end{tabular}
}
\caption{Ablation Study of \modelname.}
\label{table ablation}
\vspace{-2mm}
\end{table*}


% \begin{table}[!h]
% \centering
% \begin{tabular}{ccc}
% \toprule
%                    & Judge & Reasoning \\
% \midrule
% \modelname         & 80.82 & 79.97     \\
% w.o. RemoveSeen    & 77.57 & 77.52     \\
% w.o. DFSOrder      & 78.4  & 77.02     \\
% w.o. TripleToText  & 78.68 & 78.31     \\
% w.o. Local search  & 78.29 & 76.27     \\
% w.o. FinalReasoner & 75.33 & 71.86    \\
% \bottomrule
% \end{tabular}
% \caption{Ablation Study of \modelname.}
% \label{table ablation}
% \end{table}



% \subsubsection{Computation Cost Comparisons}

% \subsection{SFT Comparison}