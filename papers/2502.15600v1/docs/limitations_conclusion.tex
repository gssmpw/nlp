\section{Conclusions}

\noindent 
We demonstrate the strength of our proposed mixed model bias detection approach in two  
replication studies: bias scores match, but our conclusions are stronger.
%
Using our method to assess MLMs for gender bias in trait ratings, we find that larger MLMs tend to show greater bias for binary gender (RoBERTa-large is the most biased), while the opposite for non-binary \textit{neo} (ALBERT-base is the most biased).
%
But almost always any bias detected is small. While choice of target words has little influence choice of template is important. Congruence with observations from psychology in Big 5 traits depends on model and trait.
Since MLMs differ in bias it is important to assess them carefully before deploying them in applications critical to society. Within the limits of our research, ALBERT is unbiased for binary gender. However, when considering non-binary gender, no model can be deemed entirely safe.

\section{Limitations}

\noindent Our bias analysis with  3 gender categories, including neo-pronouns (Section \ref{non-binary-result}), is limited because of challenges faced in the field.  
In particular, MLM training sets may not adequately represent neo-pronouns. We leave the exploration of bias in other non-binary gender identities for future work.
%
Another limitation is that we do not account for variables such as age and profession, which could influence character/personality ratings, as we focus on a single attribute-target pair. This is left for future work.
%

Our main study is limited to positive human traits, such as \textit{calm}, and \textit{confident}.
%
As an additional analysis, we include in Section \ref{negative-traits-analysis} experiments to show that our approach can handle negative traits. 

Template design can be quite subjective.
We strengthen template quality and representativeness by generating these from a large dataset of sentences.
We safeguard quality by favoring popular sentences and sentences of limited size and we constrain these to the present tense.  
The intent is to favor sentences that are commonly acceptable expressions of human traits with references to the present.
%
As an additional safeguard, we incorporate templates as a random effect in our model. 
In contrast, the field generally treats all templates as equal for detecting bias.
Ensuring template quality has not been emphasized in prior bias studies in MLMs.
%

Additionally, we focus on template-based bias detection.  However, to demonstrate that our method is not limited to this, we present proof-of-concept experiments with crowdsourced CrowS-Pair \cite{nangia-etal-2020-crows} dataset (appendix \ref{crows-pair-eval}). We show that our analysis methods can be applied to such approaches.

In order to fully understand gender bias in human traits exhibited by computational models, it is necessary to explore both types of large language modelsâ€”MLMs and ALMs (e.g., GPT-4 \cite{achiam2023gpt} and Llama3 \cite{dubey2024llama}). While our main experiments focus on MLMs, in appendix \ref{bias-detection-llama3}, as a proof-of-concept, we demonstrate the application of our method to  Llama3.1-8B ALM. 

Finally, our goal is limited to proposing a robust approach for identifying biases in MLMs. We do not mitigate these biases - many papers in the field have this focus. For the reader interested in the complete pipeline we include in Appendix \ref{bias-mitigation} experiments showing successful mitigation of bias using a standard approach in  \citet{bartl-etal-2020-unmasking}.