\section{Introduction}

\noindent Pre-trained Masked Language Models (MLMs) (e.g., BERT \cite{devlin-etal-2019-bert}) are valuable but show systematic biases favoring certain demographics.
%
E.g., these indicate men as more likely to be engineers, and women as being more emotional \citep{gallegos2023bias,lee2018detecting, parikh2019addressing, booth2021integrating}.
%
These biases amplify societal marginalization and discrimination in automated decision-making and diminish trust in AI systems \cite{solaiman2023evaluating}.
%
Our research contributes to the active stream on bias detection in MLMs.  
%
Our \textbf{first goal} is to propose methods correcting  limitations commonly exhibited by MLM  bias detection approaches that hinder robust inferences.
%
Our \textbf{second goal} is to use our methods to gauge if MLMs are biased across gender in the novel domain of perceptions of character and personality.
%
Such bias would undoubtedly make it risky to use MLMs in socially critical contexts such as hiring and promotion decisions.

\subsection{Methodological limitations}

MLM bias detection typically begins with sentence templates from which parallel sets of sentences are derived, one for each demographic group considered. 
%
In essence, templates specify a universe of sentences used to `probe' an MLM to gauge how it associates a demographic group and a concept representing a domain such as \emph{employment}; this assessment yields a score.
Templates are essential since it is infeasible to consider all possible relevant sentences related to a target concept.  

With few exceptions, template selection and the derivation of probe sentences are done manually. 
Template sets also tend to be inherited from one paper to the next.
%
A key problem is that it is typical to treat all templates used as equal.
%
However, there could be variations across templates that cloud the detection of MLM bias.
%
We handle this problem using a \emph{mixed effects model} where template variations are handled as random effects.  
%
Using parallel logic, we also handle variations across different domain words as random effects (e.g., variations across words for different jobs).
%
Again, such variations should not confound bias assessment.

A second problem is that probe sentences derived from the same template can vary greatly.
%
For example, both \textit{She is a considerate person} and \textit{She is a concerned person} derive from the template \textit{[gendered-word] is a/an [trait-word] person}.
%
They have pseudo-perplexity scores of 1.8 and 13.8, respectively, when evaluated using BERT-large (uncased version).
%
Given this difference treating these as equivalent for bias detection is also risky. 
%
It makes sense to weigh sentence bias estimate by commonality (estimated as pseudo-perplexity).


The next problem is one of making statistically robust inferences. The minimal approach is to see if the association score difference across demographic groups is statistically significant or not. 
%
However, in some cases, even this is absent, relying only on the raw difference in association scores to assess bias \cite{limisiewicz-marecek-2022-dont,guo2022auto,kaneko-bollegala-2021-debiasing}.
%
We consider it important to go beyond significance and consider \emph{effect size}.
%
Effect size tells us how much of an observed difference in association scores is explained by the demographic variable of interest.
%
There may be a sizable and significant difference, but if the effect size is small, then the bias is also small.  
%
This can happen if other factors unaccounted for in the study are responsible for score differences.
%
Our first goal is to advocate for a bias detection methodology that does not have these limitations.


\subsection{Character and personality perceptions}

\noindent MLMs have become deeply entrenched in different societal contexts.  In psychology, MLMs are being used to estimate human attributes like personality and character from social media texts \cite{park2015automatic, liou2023online, pang2020language}. 
%
In organizational settings, they are used in hiring to infer individual attributes from language in job applications \cite{thompson2023deep}, interviews \cite{hickman2022automated}, surveys \cite{speer2023turning}, video interviews and resumes \cite{booth2021bias, gagandeep2023evaluating}.
%
Clearly, biases in these MLM applications would jeopardize the integrity of outcomes and perpetuate stereotypes.
%
While several studies in psychology study bias (or at least differences) when humans rate males and females at least on personality traits, MLMs have not been assessed in the same context.
%
Thus, our second goal is to assess MLMs for gender biases in character and personality ratings. 

We draw on two major psychological frameworks specifying key human traits. One known as \textit{human virtue} or \textit{character traits}
% character strengths or 
\cite{peterson2004character} specifies key positive traits of individuals. Another specifies \textit{personality traits}, which are enduring descriptive characteristics of individuals. 
%
We use lexical approaches based on adjectives describing people as outlined by \citet{john1988lexical}.
%
From lexical studies, there are four key character dimensions (\textit{empathy}, \textit{order}, \textit{resourceful}, \textit{serenity}) \cite{cawley2000virtues} and five personality dimensions (\textit{extroversion}, \textit{agreeableness}, \textit{conscientiousness}, \textit{emotional stability}, \textit{openness}) \cite{goldberg1992development}.
%
Our second goal is to assess MLMs for gender biases along these nine trait dimensions.

\noindent In summary:
\begin{enumerate}[noitemsep, nolistsep]
    \item We propose a better bias detection methodology for MLMs achieved with a mixed effect model accommodating fixed and random effects.  We also weigh probe sentences and estimate effect size.

    \item We assess seven MLMs for gender bias in the novel domain of character and personality traits. Gender bias detection is critical for the societal contexts in which MLMs are used.

\end{enumerate}

We first describe our bias detection method. Then we present results from two replication studies followed by our main results on MLM bias in human trait perception with additional analysis. We then present related works and conclusions ending with limitations and an ethics statement.