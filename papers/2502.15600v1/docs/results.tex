\section{Results}

\subsection{Prior work replication results}\label{prior-work-replication}

\noindent First, we replicate our methods on two prior studies \cite{bartl-etal-2020-unmasking,limisiewicz-marecek-2022-dont}, 
that share key methodological features, namely the use of templates, the same association scores to measure bias (Section \ref{measuring-association}), and focus on gender bias. 
%
We explore their targets:  \textit{profession} in \citet{bartl-etal-2020-unmasking} and \textit{profession/non-profession} indicated by \textit{Nouns} in \citet{limisiewicz-marecek-2022-dont}\footnote{A third work by \citet{kurita-etal-2019-measuring}, 
also shares the same methodological features.
However, we do not replicate it given its significantly small dataset size.}.
%
We aim to see if we obtain comparable results despite using our analytic methods. 

\subsubsection{\texorpdfstring{\citet{bartl-etal-2020-unmasking}}{}}

\noindent \textbf{Overview:} The authors study gender bias w.r.t. profession for both English and German. 
%
We focus on their results for English.
%
Consistent with their work, we use bert-base-uncased MLM and their templates (their Table 1 \textit{English}).  
%
They consider 3 categories with 20 professions in each: \textit{Balanced}, \textit{Female} and \textit{Male}. 
%
\textit{Female} (\textit{Male}) refers to professions where females (males) dominate in the real world while in \textit{Balanced} professions both have roughly equal participation, decided using \citet{us2020employed}.
%
Consistent with their work, we compute averages of association scores (Section \ref{measuring-association}) for each gender across all templates (they call this \textit{Pre}) and then take bias score as male minus female average (Table 4 in their paper), i.e., \textit{m-f}.
%
In our mixed model approach (Section \ref{model-configuration}), professional words from their paper substitute for trait words.
%
While they consider 
the significance of bias scores and effect size, it is unclear whether the reported effect size relates to Pre-association or Post-association (after fine-tuning). So, we exclude their effect size in our comparison.


\begingroup
% \setlength{\tabcolsep}{1pt}
\begin{table}[htbp]
    \scriptsize
  \centering
    \begin{tabular}{@{}llcc@{}}
    \toprule
          &  \textbf{Method}     & \multicolumn{1}{p{5.5em}}{\textbf{Bias score}} & \multicolumn{1}{l}{\textbf{Effect Size ($R^2$)}} \\
    \midrule
    \multirow{2}[0]{*}{Balanced} & Prior work & 0.40  &   \\
            
       
         & $\text{model}_{\text{lme}}$ & 0.41  & 0.13\4 \\
    \cmidrule{2-4}
    \multirow{2}[0]{*}{Female} & Prior work & -1.18 &   \\
        
         
          & $\text{model}_{\text{lme}}$ & -0.83 & 0.24\4 \\
    \cmidrule{2-4}
    \multirow{2}[0]{*}{Male} & Prior work & 0.99  &   \\
        
          
          & $\text{model}_{\text{lme}}$ & 1.00  & 0.50\4 \\
    \midrule
    \multirow{2}[0]{*}{\begin{tabular}[l]{@{}l@{}}104\\\textit{Nouns}\end{tabular}}& Prior work & 0.35  &   \\
          
          & $\text{model}_{\text{lme}}$ & 0.40  & 0.06\3 \\
    \bottomrule
    \end{tabular}%
\caption{{
\footnotesize
Prior work replication results. 
%
The first six rows refer to \citet{bartl-etal-2020-unmasking}. Last two rows refer to \citet{limisiewicz-marecek-2022-dont}. All bias scores and effect sizes ($R^2$) are significant at 95\% confidence level. Please see Table \ref{tab:model2-results} legend for notation. }
}
\label{tab:replication_results}%
\vspace{-5mm}
\end{table}%
\raggedbottom
\endgroup

\vspace{0.5em}
\noindent \textbf{Results and Analysis:}Replication results are in the first 6 rows of Table \ref{tab:replication_results}.
Our bias scores are significant throughout. 
% 
Our model, $\text{model}_{\text{lme}}$, scores are close to prior results in magnitude and the same in direction.
%
As before for \textit{Female} (\textit{Male}) professions bias is high and against males (females) while for the \textit{Balanced} professions bias scores of around 0.41 are lowest but still favoring males.

While our bias scores and direction match those of \citet{bartl-etal-2020-unmasking}, we provide additional meaningful analysis based on effect sizes.
%
Our model yields larger effect sizes -- medium to large 
: 0.13 (\textit{Balanced}), 0.24 (\textit{Female}) and 0.5 (\textit{Male}). 
%
E.g., a sizable 13\% of score variations in \textit{Balanced} are explained by gender differences.

\subsubsection{\texorpdfstring{\citet{limisiewicz-marecek-2022-dont}}{}}
%

\noindent \textbf{Overview:}
%
We focus on their investigation of gender bias in the context of 104 gender neutral professional and non-professional \textit{Nouns} (e.g., professional: `chef', `programmer', `painter'; non professional: `victim', `customer', `patient').
%
We use their templates (their Table 1), bert-base-cased MLM, and 
their masking strategy involving determiners, pronouns and the nouns of interest and compute bias score as in their paper.
%
We replace trait words with their \textit{Noun} words in our models. 
%
Notably, the authors do not consider bias score significance, effect size, or control for random effects.

\vspace{0.5em} 
\noindent \textbf{Results and Analysis:} As seen in the last two rows of Table \ref{tab:replication_results} 
%
our bias score is close to theirs (0.352, see column MEAN, row 1 in their Table 3) in magnitude and matches direction favoring males.
%
However, while it is statistically significant (95\% confidence), our effect size is small, 0.06. Thus, we conclude that the bias found in
\citet{limisiewicz-marecek-2022-dont}
is small.
%
This underlines the importance of considering random effects and of incorporating sentence weights.


\begin{table*}[htbp]
    \scriptsize
  \centering
  \setlength{\tabcolsep}{1.5pt} % adjust spacing between columns
    \begin{tabular}{p{1.5cm}p{2.6cm}ccccccc}
    \toprule
    \multicolumn{1}{l}{} & \textbf{Traits} & \multicolumn{7}{c}{\textbf{Language Models}} \\
    \midrule
          & \multicolumn{1}{r}{} & \multicolumn{4}{c}{\textbf{Base}} & \multicolumn{3}{c}{\textbf{Large}} \\
    \cmidrule{3-9}
          & \multicolumn{1}{r}{} & \textbf{BERT} & \textbf{RoBERTa} & \textbf{ALBERT} & \textbf{DistilBERT} & \textbf{BERT} & \textbf{RoBERTa} & \textbf{ALBERT} \\
    \midrule
    \multirow{4}[0]{*}{\begin{tabular}[l]{@{}l@{}}\textbf{Character}\\\textbf{traits}\end{tabular}} & \textit{empathy} &-0.36\1 & -0.19 & -0.19 & -0.37\2 & 0.99\2  & -0.70\3 & -0.30 \\
          & \textit{order} & \textcolor{blue}{-0.08}  & 0.12  & \textcolor{red}{-0.06} & -0.07 & 0.69\1  & -0.30\1 & -0.41 \\
          & \textit{resourceful} & -0.30 & -0.20 & \textcolor{blue}{-0.15}  & -0.22\1 & 0.86\2  & -0.74\2 & -0.24 \\
          & \textit{serenity} & -0.33 & -0.43\1 & -0.47 & -0.36\2 & 0.47\1  & -1.08\4 & -0.35 \\
        \cmidrule{2-9}
          
          & Effect Size ($R^2$) & [1E-3, 1.03E-2] & [1E-3, 1E-2] & [0, 2E-3] & [1E-3, 3.7E-2] & [1E-2, 3.5E-2] & [1E-2, 0.127] & [1E-3, 3E-3]  \\
    \midrule
    \multirow{5}[0]{*}{\begin{tabular}[l]{@{}l@{}}\textbf{Personality}\\\textbf{traits}\end{tabular}} & \textit{extroversion} & -0.28 & -0.39\1 & -0.26 & -0.25\1 & 0.71\1  & -0.86\4 & -0.38 \\
          & \textit{agreeableness} & -0.16 & -0.21 & \textcolor{red}{-0.16} & \textcolor{red}{-0.05} & 0.61\1  & -0.77\3 & -0.36 \\
          & \textit{conscientiousness} & -0.20 & 0.54\1  & \textcolor{red}{0.05}  & -0.23\1 & 0.64\1  & -0.77\3 & -0.23 \\
          & \textit{emotional stability} & -0.18 & \textcolor{red}{-0.08} & -0.21 & -0.21\1 & 1.01\2  & -0.26 & -0.56 \\
          & \textit{openness} & -0.27 & 0.15  & -0.20 & -0.16 & 0.35  & -0.61\2 & \textcolor{red}{0.12} \\
          \cmidrule{2-9}      
    & Effect Size ($R^2$) & [2E-3, 4E-3] & [0, 2E-2] & [0, 1E-3]
    & [1E-3, 2E-2] & [9E-3, 4.1E-2] & [5E-3, 0.104] & [1E-3, 4E-3] \\
    \bottomrule
    \end{tabular}    
     \caption{
     \footnotesize
     Results for Seven MLMs using $\text{model}_{\text{lme}}$. 
    Values presented in each cell (e.g., -0.36 for \textit{empathy}) represent bias scores. Rows labeled `Effect Size ($R^2$)' presents a range of effect sizes across traits for each model. Notably, symbols next to bias scores indicated where each trait falls within effect size range.
    %
    Notation: 
        Black font: significant (\textit{p-value} $< 0.05$), 
        \textcolor{blue}{blue}: marginally significant (\textit{p-value} $\in [0.05,0.10]$), 
        \textcolor{red}{red}: not significant (\textit{p-value} $> 0.10$).
        %
        Positive (negative) score: bias against females (males). 
        %
        Effect size ($R^2$). 
        %
            *: Medium [0.09, 0.25) to very large [0.64, 1]; Small: 
            $\triangledown$:$R^2\in$[0.01, 0.03)
            $\vartriangle$: $R^2\in$[0.03, 0.06), 
            $\blacktriangle$: $R^2\in$[0.06, 0.09).
     }
  \label{tab:model2-results}%
  \vspace{-4mm}
\end{table*}
\raggedbottom


\vspace{0.5em} 
\noindent \textbf{Summary:} 
In both replications, our bias scores match the original findings in magnitude and direction. 
%
But while we find a medium to large effect bias for all three professions in \citet{bartl-etal-2020-unmasking}, the effect size is relatively small (0.13) for the balanced category -- likely the most important group in their study.
%
Our \citet{limisiewicz-marecek-2022-dont} replication indicates small bias, an inference possible because of effect size analysis.
%
By accounting for random effects and sentence pseudo-perplexity and examining effect size, we offer more robust and quantitative estimates of bias than in prior work.

\begingroup

 \newcolumntype{D}{>{\setbox0=\hbox\bgroup}c<{\egroup}@{}}
 % \setlength{\cmidrulewidth}{0.4pt}
\renewcommand{\arraystretch}{1.2}

\begin{table*}[htbp]
  \scriptsize
  \centering
  \setlength{\tabcolsep}{1.6pt}
    \begin{tabular}{@{}Dp{0.6cm}ccc|ccc|ccc|ccc|ccc|ccc|ccc@{}}
    \hline
    {} & \textbf{Traits} & \multicolumn{21}{c}{\textbf{Language Models}} \\
    
    \hline
    & \multicolumn{1}{r}{} & \multicolumn{12}{c}{\textbf{Base}} & \multicolumn{9}{c}{\textbf{Large}} \\
    \cline{3-23}
        
    {} & {} & \multicolumn{3}{c}{\textbf{BERT}} & \multicolumn{3}{c}{\textbf{RoBERTa}} & \multicolumn{3}{c}{\textbf{ALBERT}} & \multicolumn{3}{c}{\textbf{DistilBERT}} & \multicolumn{3}{c}{\textbf{BERT}} & \multicolumn{3}{c}{\textbf{RoBERTa}} & \multicolumn{3}{c}{\textbf{ALBERT}} \\

      \hline
          
    {} & {}
    %
    & \multicolumn{1}{c}{\textbf{M-F}} & \multicolumn{1}{c}{\textbf{M-N}} & \multicolumn{1}{c|}{\textbf{F-N}} 
    %
    & \multicolumn{1}{c}{\textbf{M-F}} & \multicolumn{1}{c}{\textbf{M-N}} & \multicolumn{1}{c|}{\textbf{F-N}} 
    
    & \multicolumn{1}{c}{\textbf{M-F}} & \multicolumn{1}{c}{\textbf{M-N}} & \multicolumn{1}{c|}{\textbf{F-N}} 
    
    & \multicolumn{1}{c}{\textbf{M-F}} & \multicolumn{1}{c}{\textbf{M-N}} & \multicolumn{1}{c|}{\textbf{F-N}} 
    
    & \multicolumn{1}{c}{\textbf{M-F}} & \multicolumn{1}{c}{\textbf{M-N}} & \multicolumn{1}{c|}{\textbf{F-N}} 
    
    & \multicolumn{1}{c}{\textbf{M-F}} & \multicolumn{1}{c}{\textbf{M-N}} & \multicolumn{1}{c|}{\textbf{F-N}} 
    
    & \multicolumn{1}{c}{\textbf{M-F}} & \multicolumn{1}{c}{\textbf{M-N}} & \multicolumn{1}{c}{\textbf{F-N}} \\

    \hline

    \multirow{4}[0]{*}{\begin{tabular}[l]{@{}l@{}}\textbf{Character}\\\textbf{traits}\end{tabular}} 
        & \textit{EMP} & 0.36\1 & 0.71\1 & 0.86 & -0.19 & 1.55\1 & 1.76\1 & -0.19 & 8.11* & 8.36 * & -0.37\2 & 0.46\1 & 0.81\1 & 0.99\2 & 1.46\1& 0.51 & -0.70\3 & 0.63\1 & 1.21\1 & -0.30 & 3.75\2 & 3.90 \2 \\
    
        & \textit{ORD} & \textcolor{blue}{-0.08} & 0.89\1  & 0.79  & 0.12  & 1.00\1  & 0.94\1  & \textcolor{red}{-0.06} & 8.18*  & 8.31*  & -0.07 & 0.71\2  & 0.74\1  & 0.69\1  & 0.80\1  & \textcolor{red}{0.15}  & -0.30\1 & \textcolor{red}{0.38}  & \textcolor{blue}{0.61}  & -0.41 & 4.12\2  & 4.34\2 \\
        
        & \textit{RES} & -0.30 & 0.76\1  & 0.82  & -0.20 & 0.78  & \textcolor{blue}{0.84}  & \textcolor{blue}{-0.15} & 7.80*  & 7.99\3  & -0.22\1 & 0.47\1 & 0.62\1  & 0.86\2  & \textcolor{red}{0.38}  & \textcolor{red}{-0.50} & -0.74\2 & \textcolor{red}{0.44}  & 1.00\1  & -0.24 & 4.00\2  & 4.09\2 \\
        
        & \textit{SRN} & -0.33 & 1.31\1  & 1.51\1  & -0.43\1 & 1.70\2  & 2.00\2 & -0.47 & 8.03* & 8.70*  & -0.36\2 & \textcolor{red}{0.14}  & \textcolor{red}{0.43}  &  0.47\1  & 1.38\1  & \textcolor{red}{0.88}  & -1.08* & 1.51\3  & 2.53*  & -0.35 & 3.49\2  & 3.71\2 \\

    \hline

    \multirow{5}[0]{*}{\begin{tabular}[l]{@{}l@{}}\textbf{Personality}\\\textbf{traits}\end{tabular}} 

        & \textit{EXT} & -0.28 & \textcolor{red}{0.26}  & \textcolor{red}{0.40} & -0.39\1 & \textcolor{blue}{0.65}  & 1.04\1  & -0.26 & 8.26*  & 8.64*  & -0.25\1 & 0.45\1  & 0.68\1 & 0.71\1 & \textcolor{red}{0.13}  & \textcolor{red}{-0.38} & -0.86* & \textcolor{red}{-0.02} & 0.81\1  & -0.38 & 3.86\2 & 4.05\2 \\
        
        & \textit{AGRE} & -0.16 & 1.44*  & 1.35\2  & -0.21 & \textcolor{red}{0.58}  & \textcolor{red}{0.66}  & \textcolor{red}{-0.16} & 7.40\3 & 7.64\3  & \textcolor{red}{-0.05} & 0.57\1  & 0.57\1  & 0.61\1  & 0.95\1 & \textcolor{red}{0.35}  & -0.77\3 & 1.09\2  & 1.69\2  & -0.36 & 3.11\2 & 3.40\1 \\
        
         & \textit{CON} & -0.20 & 0.74\1  & \textcolor{red}{0.67}  & 0.54\1 & 1.33\1  & \textcolor{red}{0.63}  & \textcolor{red}{0.05}  & 8.52*  & 8.43*  & -0.23\1 & 0.81\2  & 1.00\2  & 0.64\1 & 0.82 \1 & \textcolor{red}{0.20}  & -0.77\3 & \textcolor{blue}{0.77}  & 1.42\1  & -0.23 & 3.91\2  & 4.18\2 \\
        
         & \textit{EMS} &-0.18 & 0.61  & \textcolor{red}{0.61}  & \textcolor{red}{-0.08} & \textcolor{blue}{0.75}  & \textcolor{red}{0.69}  & -0.21 & 7.59*  & 7.93* & -0.21\1 & \textcolor{red}{0.21}  & \textcolor{red}{0.36}  & 1.01\2  & \textcolor{red}{0.29}  & \textcolor{red}{-0.57} & -0.26 & \textcolor{red}{0.56}  & \textcolor{red}{0.63}  & -0.56 & 2.50\1  & 2.98\1 \\
        
         & \textit{OPN} &-0.27 & 0.63  & \textcolor{red}{0.69}  & 0.15  & \textcolor{red}{0.41}  & \textcolor{red}{0.25}  & -0.20 & 7.42\3  & 7.73\3 & -0.16 & \textcolor{red}{0.21}  & \textcolor{red}{0.35}  & 0.35  & \textcolor{red}{0.38}  & \textcolor{red}{-0.14} & -0.61\2 & \textcolor{red}{-0.19} & \textcolor{red}{0.38}  & \textcolor{red}{0.12}  & 3.94*  & 3.56* \\
    \hline
    \end{tabular}
    \caption{
    \footnotesize
    Results for Seven MLMs using $\text{model}_{\text{lme}}$ 
    (\textbf{including non-binary \textit{neo} pronoun}). See Table \ref{tab:model2-results} for reported values descriptions and the notation used. 
    M: Males, F: Females, N: Neo-pronouns. M-F result is identical to Table \ref{tab:model2-results}.
    \textit{EMP}: \textit{empathy}, \textit{ORD}: \textit{order}, \textit{RES}: \textit{resourceful}, \textit{SRN}: \textit{serenity}, \textit{EXT}: \textit{extroversion}, \textit{AGR}: \textit{agreeableness}, \textit{CON}: \textit{conscientiousness}, \textit{EMS}: \textit{emotional stability}, \textit{OPN}: \textit{openness}
    }
  \label{tab:non-binary-results-model2}
  \vspace{-4mm}
\end{table*}
\endgroup


\subsection{MLMs and human traits: bias results} 

\subsubsection{Bias across MLMs (binary gender)} \label{bias-across-mlms}

\noindent Table \ref{tab:model2-results} presents our $\text{model}_{\text{lme}}$  results.

\vspace{0.5em} 
\noindent \textbf{(1) Base MLMs:}
%
\noindent Most scores (29/36) are significant, with 2 more being marginally significant.
%
The range of significant scores (ignoring direction) is [0.07, 0.47] for character and [0.15, 0.54] for personality.
%
To the best of our knowledge, bias scores in the literature are in [0.16, 5.6] 
% dhamala2021bold
\cite{limisiewicz-marecek-2022-dont,ahn-oh-2021-mitigating,bartl-etal-2020-unmasking}
thus ours are at the lower end.


Effect sizes are `at most small' for all base models.
%
DistilBERT exhibits these for 6/9 dimensions; the largest ranging in [0.030, 0.037] are for \textit{empathy} and \textit{serenity}. 
%
RoBERTa does the same for 3/9 dimensions.
%
Interestingly, 
ALBERT stands out as unbiased across all dimensions followed by BERT (its one small effect size, for \textit{empathy}, is actually close to negligible (0.01)).
%
Overall, effect sizes indicate close to no gender bias for both trait sets; those observed almost exclusively favor females.

\vspace{0.3em} 
\noindent \textbf{(2) Large MLMs:} \label{results-discussion-large-mlms}
%
\noindent Scores [0.23, 1.08] are higher in magnitude compared to base models.  
%
Interestingly, RoBERTa favors females, while BERT favors males, perhaps due to differences in training goal and corpus and requires further exploration beyond the scope of this paper.

ALBERT-large is unbiased. 
RoBERTa is the most biased with two medium effect sizes (\textit{serenity} and \textit{extroversion}).
%
BERT's bias is intermediate; but effect sizes are at best small.
%
Ranking models by parameters (least to most):
    ALBERT-base (12M) $\rightarrow$ ALBERT-large (18M) $\rightarrow$ DistilBERT (66M) $\rightarrow$ BERT-base (110M) $\rightarrow$ RoBERTa-base (125M) $\rightarrow$ BERT-large (340M) $\rightarrow$ RoBERTa-large (355M)
    %
    matches model ranking from least to most biased except for a flip between  
     BERT-base and DistilBERT (but the former is almost completely unbiased, the latter only slightly biased).
     % 
     Possibly the larger architectures capture more complex patterns in training data.
     %
     We cannot postulate a causal relation between model size and bias. This requires evidence from nuanced, controlled and focused experiments, also beyond this paper's scope.


Same family MLMs also differ in bias. Thus, each model considered for applications should be examined for bias.
%
Across architectures ALBERT is the only one unbiased.
%
Each trait dimension is vulnerable in at least one large MLM;  \textit{order}, \textit{emotional stability} and \textit{openness} are least impacted.

\subsubsection{Bias: Human vs MLM perspective} \label{human-perspective}

\noindent Although character traits were proposed in early 2000, there has been little follow-up work in psychology focusing on gender differences using the same lexical framework.
Thus, we limit our analysis to personality, where psychology studies on gender differences\footnote{Note that in computer science inequality in ratings is viewed as bias whereas in psychology differences are observed but not necessarily viewed as bias.} are available
using self-reported 
questionnaires and Big Five traits. 

\citet{hartmann2023big,ock2020practical,russo2020gender,weisberg2011gender,lippa2010gender,chapman2007gender} find that females rate higher on \textit{agreeableness} and the negative trait of \textit{neuroticism}.
(Note that \textit{neuroticism} is the opposite of \textit{emotional stability} included in our study.)
Our MLM results for RoBERTa-large align on \textit{agreeableness}.
However, with BERT-large, the bias direction for this dimension is opposite, favoring males.
On \textit{emotional stability} MLMs are largely neutral excepting BERT-large which also favors males as in psychology.
But the MLM bias is only small while it is medium sized in psychology.
%
In the three remaining dimensions, several MLMs exhibit small gender bias.
%
This is in general agreement with psychology, which also finds small to little difference. %\cite{hartmann2023big,weisberg2011gender,lippa2010gender}.
%
Overall, MLMs vary considerably in bias score, significance and direction, whereas differences in psychological studies are small.


\subsubsection{Bias across MLMs (non-binary gender)}\label{non-binary-result}

\noindent While most bias studies in the literature focus on binary genders, there is growing interest in non-binary gender bias \cite{urchs-etal-2024-detecting,ovalle2023m,nozza-etal-2022-measuring,dev-etal-2021-harms}. In line with this, we extend our analysis with the mixed effect model to non-binary gender bias by including neo-pronouns as attribute words.  These are from \citet{hossain-etal-2023-misgendered} and include \textit{co}, \textit{vi}, \textit{xe}, \textit{cy}, 
and \textit{ze}. We analyze pairwise gender bias (Table \ref{tab:non-binary-results-model2}).

Bias considering male and female genders alone remains consistent across models compared to our previous Table \ref{tab:model2-results} results.
%
For neo-pronouns, we consistently find mostly small or no bias across MLMs when comparing neo-pronouns to male and and to female genders.
%
We observe a notable exception with ALBERT models: while we do not find gender bias between males and females, we observe small to medium bias against \textit{neo} compared with males/females. 
%
Specifically in ALBERT-large, with the exception of \textit{openness} where we find medium bias, there are only small biases against \textit{neo}. In ALBERT-base, we find small to medium-sized biases against \textit{neo}.
While larger MLMs exhibit more bias for binary gender (Section \ref{results-discussion-large-mlms}), the opposite is the case for non-binary \textit{neo}.

The MLMs assessed are trained on datasets up to 2019 from sources like Common Crawl, BookCorpus, and Wikipedia. These likely lack adequate representation of non-binary gender patterns \cite{nozza-etal-2022-measuring}. \citet{mille-etal-2024-filling-gaps} also highlight the underrepresentation of the non-binary groups in Wikipedia. This likely contributes to the bias against \textit{neo}. We recommend carefully controlled experiments for more thorough understanding of the issue.

\subsubsection{Additional analyses}\label{additional-analysis}

\noindent We limit analysis to RoBERTa-large (our most biased model for binary gender), except for the analysis of the influence of selected gendered words and the influence of templates, where we analyzed BERT-large (intermediate bias amongst large models).

\subsubsubsection{Effect of negative traits}\label{negative-traits-analysis}

\noindent The main experiments are limited to positive trait words.
Here, we explore the effect of adding negative traits. We identify a suitable antonym (Appendix Table \ref{tab:negative_traits_character}) for each positive character trait 
(Appendix Table \ref{tab:targets_virtue}) 
using WordHippo or Merriam-Webster, followed by manual verification. For personality traits, the antonyms (Table \ref{tab:negative_traits_big_five}) are adapted from \citet{goldberg1992development}.

\begingroup
\setlength{\tabcolsep}{3pt}
\begin{table}[htbp]
  \centering
  \scriptsize
  
    \begin{tabular}{@{}llcccccc@{}}
    \hline
        {} 
        & \textbf{Traits} 
        & \textbf{Positive traits}
        & \begin{tabular}[l]{@{}l@{}}\textbf{Positive and}\\\textbf{Negative traits}\end{tabular} 
        \\
    \hline

    \multirow{4}[0]{*}{\begin{tabular}[l]{@{}l@{}}\textbf{Character}\\\textbf{traits}\end{tabular}}
    
    &  \textit{empathy} & -0.52 \1 & \textcolor{red}{-0.08}    \\
    
    & \textit{order} & -0.23 & 0.10  \\
    
    &  \textit{resourceful} & -0.75 \1 & -0.40 \1   \\
    
    &  \textit{serenity} & -1.00 \4 & \textcolor{red}{-0.08}  \\
    \hline

    \multirow{5}[0]{*}{\begin{tabular}[l]{@{}l@{}}\textbf{Personality}\\\textbf{traits}\end{tabular}}

    & \textit{extroversion} & -0.76 \3 & \textcolor{red}{-0.07} \\
    
    & \textit{agreeableness} & -0.70 \2 & \textcolor{red}{-0.01} \\
    
    & \textit{conscientiousness} & -0.70 \2 & -0.24 \\
    
    & \textit{emotional stability} & \textcolor{blue}{-0.17} & 0.19 \\
    
    & \textit{openness} & -0.54 \1 & \textcolor{red}{-0.07}  \\     
    \hline
    \end{tabular}
    \caption{\footnotesize Results for RoBERTa-large using $\text{t}_1$ to $\text{t}_4$  templates using $\text{model}_{\text{lme}}$. See Table \ref{tab:model2-results} for reported values descriptions and the notation used.}
  \label{tab:roberta-large-negative-traits-results}
  \vspace{-3mm}
\end{table}
\endgroup

We exclude templates $\text{t}_5$ and $\text{t}_6$ (Table \ref{tab:templates}) as they are specific to positive traits.
%
To have a consistent interpretation between positive and negative traits in our combined model, we reverse the association for negative traits by multiplying the MLM-derived $\text{association}_{\text{score}}$ by -1. 
Table \ref{tab:roberta-large-negative-traits-results} presents results.

We find small to medium bias favoring females for positive traits, except in \textit{order} and \textit{emotional stability}. 
When negative traits are included, bias practically disappears except for the \textit{resourceful} trait.
%
This is likely due to the greater prevalence of negative trait sentences (43\% to 91\% lower perplexity than positive trait sentences in our data) for the bias free dimensions.
%
Consistent with our hypothesis we find that in \textit{resourceful} dimension, where positive trait sentences are more common (53\% lower perplexity than negative trait sentences), bias persists albeit with a reduced score. 
%
Key to note is that RoBERTa's training corpus is 50\% news data from Common Crawl (CC-News), where negative content is more prevalent \cite{hamborg2021towards},
which may explain the generally lower perplexity of negative trait sentences compared to positive ones. 

\begingroup
\setlength{\tabcolsep}{1.2pt}
\begin{table}[htbp]
  \centering
  \scriptsize
        \begin{tabular}{@{}llHHll@{}}
        \toprule
       
              &  \textbf{Traits}     & \textbf{Fullset} & \textbf{Subset} & \textbf{Fullset} & \textbf{Subset} \\
        
        \midrule
           {\multirow{5}[0]{*}{\begin{tabular}[l]{@{}l@{}}\textbf{Character}\\\textbf{traits}\end{tabular}}} 
                & \textit{empathy} & -0.36\1 & 0.11 & 0.99\2 & 0.39\2 \\
                & \textit{order} & \textcolor{blue}{-0.08} & 0.20\2 & 0.69\1 & 0.42\3 \\
                & \textit{resourceful} & -0.30 & 0.16\1 & 0.86\2 & 0.39\3 \\
                & \textit{serenity} & -0.33 & \textcolor{blue}{0.13} & 0.47\1 & \textcolor{red}{0.10} \\
    
              \cmidrule{2-6}
              & Effect Size ($R^2$)    & [1E-3,1E-2] & [5E-2,3E-2] & [1E-2,4E-2] & [3E-3,7E-2] \\
    
        \midrule
        {\multirow{5}[0]{*}{\begin{tabular}[l]{@{}l@{}}\textbf{Personality}\\\textbf{traits}\end{tabular}}} 
                & \textit{extroversion} & -0.28 & \textcolor{red}{0.05} & 0.71\1 & \textcolor{red}{0.11} \\
                & \textit{agreeableness} & -0.16 & \textcolor{blue}{0.14\1} & 0.61\1 & 0.21\1 \\
                & \textit{conscientiousness} & -0.20 & 0.21\1 & 0.64\1 & 0.35\2 \\
                & \textit{emotional stability} & -0.18 & \textcolor{red}{0.11} & 1.01\2 & 0.28\2 \\
                & \textit{openness} & -0.27 & 0.11 & 0.35 & 0.31\2 \\
                
              \cmidrule{2-6}
              & Effect Size ($R^2$)    & [2E-3,4E-3] & [1E-3,2.6E-2] & [9E-3,4.1E-2] & [5E-3,4.9E-2] \\
        \bottomrule
        \end{tabular}%
        \caption{
        \footnotesize 
        Full set versus subset of gendered pairs (BERT-large $\text{model}_{\text{lme}}$). See Table \ref{tab:model2-results} legend for notation.}
      \label{tab:all_vs_sub_atrributes_bert_large_model2}
      \vspace{-4mm}
    \end{table}
\endgroup
\raggedbottom

\subsubsubsection{Influence of selected gendered words}

\noindent Table \ref{tab:all_vs_sub_atrributes_bert_large_model2} compares results using the original \textit{full set} of 94 gendered pairs (used in Table \ref{tab:model2-results}) with a \textit{subset} of 7 common gendered words (e.g., daughter-son, girl-boy)
\cite{limisiewicz-marecek-2022-dont,steed2022upstream,kurita-etal-2019-measuring}.
% 
Scores fall with the reduced set; a couple cells are no longer significant. Effect sizes stay the same or increase slightly, but all are still at most small. Overall, bias detection is slightly sensitive to gendered words used. 


\subsubsubsection{Influence of templates}

\noindent 
Except for  \citet{liu2021mitigating}, prior research has largely ignored the impact of templates on bias estimation.
% 
Table \ref{tab:templates_sensitivity_bert_large} compares our \textit{direct} and \textit{indirect} templates with BERT-large and also lists their combination  (`ALL', same as Table \ref{tab:model2-results} column BERT).


\begingroup
\setlength{\tabcolsep}{1.2pt}
% \begin{table}[htbp]
\begin{table}[htbp]
  \centering
  \scriptsize
            % \begin{tabular}{lp{6em}lllll}
            \begin{tabular}{lllHHll}
                
                \toprule
                
              & \textbf{Traits} & \multicolumn{5}{c}{\textbf{Templates}} \\
    
              \cmidrule{2-7}
              
              & \multicolumn{1}{r}{} & \textbf{Indirect} & \textbf{Direct} & \textbf{Mixed} & \textbf{Direct} & \textbf{ALL} \\
    
              
        \midrule
        

             \multirow{5}[0]{*}{\begin{tabular}[l]{@{}l@{}}\textbf{Character}\\\textbf{traits}\end{tabular}} & \textit{empathy} & 2.49\3 & 0.42 & 1.50\2 & \textcolor{red}{0.07} & 0.99\2 \\
              & \textit{order} & 1.58\2 & 0.59\1 & 1.12\2 & 0.14 & 0.69\1 \\
              & \textit{resourceful} & 2.06\3 & 0.61\1 & 1.36\2 & 0.17 & 0.86\2 \\
              & \textit{serenity} & 1.95\2 & \textcolor{red}{0.05} & 0.98\2 & -0.32 & 0.47\1 \\
    
              \cmidrule{2-7}
              
              & Effect Size ($R^2$) & [5E-2,7E-2] & [1E-4,3E-2] & [3E-2,6E-2] & [4E-4,8E-3] & [1E-2,4E-2] \\
    
        \midrule

            \multirow{7}[0]{*}{\begin{tabular}[l]{@{}l@{}}\textbf{Personality}\\\textbf{traits}\end{tabular}} & \textit{extroversion} & 1.60\2 & 0.82\2 & 1.17\2 & 0.33 & 0.71\1 \\
        
              & \textit{agreeableness} & 1.74\2 & 0.41\1 & 1.06\2 & \textcolor{red}{0.01} & 0.61\1 \\
              
              & \textit{conscientiousness} & 1.05\1 & 0.75\2 & 0.93\1 & 0.32 & 0.64\1 \\
              
              & \textit{emotional stability}& 2.50\4 & 0.69\1 & 1.55\4 & 0.28 & 1.01\2 \\
              
              & \textit{openness} & 1.69\2 & -0.24 & 0.63\1 & -0.22 & 0.35 \\
              
              \cmidrule{2-7}
              
              & Effect Size ($R^2$)    & [2E-2,1E-1] & [4E-3,4E-2] & [2E-2,9E-2] & [2E-5,1E-2] & [1E-2,5E-2] \\
              
        \bottomrule
        \end{tabular}
       
         \caption{
         \footnotesize
         Comparing templates (BERT-large $\text{model}_{\text{lme}}$): see Table \ref{tab:templates} for template types and Table \ref{tab:model2-results} for reported values descriptions and the notation used.}
      \label{tab:templates_sensitivity_bert_large}
      \vspace{-2mm}
    \end{table}
\raggedbottom

Direct templates do not detect bias. Indirect and ALL detect bias, but indirect scores are 1.6-4.8 times higher, suggesting that Direct reduces the capacity of ALL to detect bias.
%
Indirect effect sizes are also larger, with even a medium size effect. Template choice strongly affects bias detection.


\subsubsubsection{Influence of pseudo-perplexity}

\noindent We focus on the \textit{conscientiousness} dimension for RoBERTa-large - the most biased MLM.
%
Pseudo-perplexity of 83\% of our 9,066 probe sentences are in [0, 100].
Partitioning these into 20 bins: [0, 5), [5, 10), ...,
%
we find that lower pseudo-perplexity bins have higher sentence density (Figure \ref{fig:influence_of_ppl_on_bias} in Appendix \ref{influence-of-perplexity}).
%
Bin specific analysis shows significant bias for the first four bins, while 
this is rare for bins with pseudo-perplexity $>$ 20. Thus, gender bias is visible mainly when MLMs are probed with the most common sentence expressions of traits.



\subsubsubsection{Proof-of-concept experiments}

\noindent We present several proof-of-concept experiments exploring the broader applicability of our methods. Where MLMs are involved, we analyze RoBERTa-large, our most biased model (for binary genders).

\vspace{0.5em}

\noindent \textbf{Extending our approach to Llama3, an autoregressive generative model:} 
%
While we focus on MLMs, we present proof-of-concepts for extension of our approach to auto-regressive generative model. We evaluate gender bias, including non-binary gender (\textit{neo} pronouns from Section \ref{non-binary-result}) in LLama3.1-8B. 
%
Method and discussion of results are in Appendix Section \ref{bias-detection-llama3}.
%
We find no significant bias between males and females. However, for all traits, we find medium to large bias against \textit{neo}. 



\vspace{0.5em}

\noindent \textbf{Applying our mixed model to non template bias detection datasets:} We present a proof-of-concept for the application of our mixed model to crowdsourced datasets (non template based). Method and results are detailed in Appendix Section \ref{crows-pair-eval}.
%
Running our mixed model with the crowd sourced CrowS-Pair sentence set \cite{nangia-etal-2020-crows}, we find  --- in contrast to their results --- no bias in RoBERTa for their 9 bias categories.
%
Unlike us, they do not assess significance or effect size.

\vspace{0.5em}
\noindent \textbf{Bias mitigation in MLMs:} 
%
Our focus is on bias detection. For completeness of bias detection and mitigation pipeline, we present a proof-of-concept experiment for bias mitigation in RoBERTa-large, our most biased model. Method and discussion of results are in Appendix Section \ref{bias-mitigation}.
%
A standard approach \citet{bartl-etal-2020-unmasking} successfully mitigates our detected bias. 

In future work, we will run more complete tests of our methods in line with these proof-of-concept experiments.