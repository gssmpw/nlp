\section{Related work}
\label{ch:relworks} 

%active vision
Active vision enables intelligent systems to interact dynamically with their environment through mechanisms like selective visual attention, focusing on relevant details to achieve efficient and adaptive perception____. The human visual system is specifically structured to manage the continuous influx of stimuli from the environment. In the retina, receptive fields decrease non-linearly in size from the peripheral retina toward the fovea____. Consequently, in many mammalian visual systems, the fovea captures a small, highly detailed portion of the scene, while the peripheral retina gathers the remainder at a lower resolution____. Peripheral vision identifies points of interest and directs the fovea to focus on them sequentially; a process known as \textit{foveation}. This mechanism balances wide-area scanning with a detailed inspection, enhancing efficiency and enabling the recognition of items within the scene____.

%non-uniform retina for foveation
Foveation is based on the principle that different regions of the visual field are processed at varying resolutions. Numerous systems have been proposed to emulate the log-polar mapping and spatially variant sampling distribution characteristic of the visual field____. This subsampling of visual input offers several advantages, including data reduction____, motion direction detection____, enhanced attention mechanisms, improved object tracking and segmentation, and egomotion segmentation____.
The properties of foveated vision have been studied through both software-based simulation and hardware implementations. For instance, as first demonstrated by Geisler \emph{et al.}____ in 1998 and later confirmed by De Figueiredo \emph{et al.}____, foveal vision systems are beneficial for reducing computational demand while maintaining effective performance in complex tasks, thereby providing foundational insight into space-variant, non-uniform vision mechanisms. In this regard, Dauce \emph{et al.}____ have demonstrated that highly accurate active inference can be achieved by applying saccadic movements using only a fraction of the raw visual input by applying a deep neural network as a predictive system. Deep learning model can also achieve both high throughput and high accuracy for saccadic attention with a log-polar foveated sampling of the input____. An active system with a foveated sensor with log-polar pixel mapping for tracking objects in the visual field____ was found to closely replicate the fixation behaviour of humans scanning objects in the visual field. In____, an FPGA-driven hardware platform for egomotion estimation is implemented on a mobile robotic system, demonstrating that log-polar sampling of the visual input can be harnessed to extract the optical flow and the heading direction of the robot. Comprehensive reviews of foveated systems for robotics can be found in____.

%digital foveation
Selective attention in computer vision can also be approximated by representing the majority of a scene at a low resolution while maintaining high detail in specific key regions, ROIs. This approach selectively discards less relevant information, preserving essential details to enhance task-specific performance without implementing any log-polar mapping.
To that end, a common approach involves using pairs of sensors to emulate the effects of convergence and disparity estimation____. For instance, a foveated stereo-matching algorithm____ can significantly improve the efficiency of robotic cloth manipulation tasks, such as grasping and flattening, by achieving comparable accuracy at two to three times the speed of traditional methods. In____, a binocular foveated system is implemented on a robotic head that can simulate saccadic motion and smooth pursuit, albeit with a significant cumulative pixel error. Additionally, Medeiros \emph{et al.}____ introduced a dynamic multifoveated structure that allows robots to track and focus attention on multiple objects simultaneously without redundancy in processing, thereby optimizing real-time image analysis. This technique enhances visual attention capabilities in robotic systems by enabling rapid focus shifts across different regions of interest. Nevertheless, despite the advantages of visual processing with coupled sensors, such as superior object segmentation, considerable effort has been invested in achieving similar results with a single sensor due to the additional complexity necessary for synchronisation and parallel processing when using multiple sensors.

%SOTA neuromorphic foveation
Recent advancements in selective attention systems for neuromorphic vision have highlighted their potential to enhance visual processing efficiency in robotics due to their low power consumption and low latency. 
A pivotal work____ introduces neuromorphic foveation, using event cameras to selectively process visual information, reducing data load while maintaining high accuracy in tasks like semantic segmentation and classification. This approach achieves a superior balance between data quantity and quality compared to traditional high or low-resolution event data.
While foveated vision enhances certain aspects of perception, it introduces an inherent challenge in event processing: distinguishing between independent object motion (\emph{i.e.}, object motion) and camera-induced motion (\emph{i.e.}, egomotion) while executing fixational eye movements and identifying the next salient point for foveation.
Neuromorphic cameras detect intensity changes, making them sensitive to both objects and egomotion-induced events, which can create ambiguity. Disambiguating visual stimuli and perceptually grouping the information to focus the attention requires mechanisms to enhance object motion cues akin to biological vision systems, to ensure reliable object detection and tracking.

%Event-based attention models
Risi \emph{et al.}____ introduced an event-based FPGA implementation of a saliency-driven selective attention model that efficiently processes visual information from event cameras. This implementation outperforms classic bottom-up models, such as those by Itti \emph{et al.}____, in predicting eye fixations, achieving high performance with minimal computational resources. It captures significant aspects of visual perception by focusing on localised temporal changes and provides microsecond-precise saliency updates without relying on traditional image frames.
Event-based visual attention for robotic applications has already been proposed____, harnessing its responsiveness and robustness under varying lighting conditions while mimicking human-like attentional processes. 

% proto-objects
The turning point in advancing selective attention for object detection was marked by the integration of `Gestalt laws' into bottom-up saliency mechanisms____, ensuring the perceptual grouping of closed contours as potential objects within the scene.
The frame-based proto-object implementation____ has been further adapted for event-based cameras____ for the humanoid robot iCub reducing computational load by eliminating the initial processing stage of edge extraction achieved by utilising the inherent capabilities of the event-based cameras, which interpret the scene with leading and trailing edges, along with polarity, and therefore can be assumed to represent an edge map of the scene. The system ignores clutter and non-proto-object shapes while providing an online saliency map approximately every $\sim$100 ms.
A sparse event-based depth implementation of the model____ has shown a more localised response over frame-based implementation____ ensuring a task-dependent response prioritising proto-objects closer to the observer generating the event-based disparity map and the saliency map approximately every $\sim$170 ms. The final spiking-based implementation of the model____, directly deployed on the neuromorphic SpiNNaker platform, achieves a significant reduction in latency (approximately $\sim$16 ms), although it requires an unmanageable number of platforms (6 SpiNNaker boards) to run the full implementation across different orientations and scales of the von Mises filters.

%the problem 
The current challenge is to demonstrate, test, and validate, what is, to the best of the authors' knowledge, the first end-to-end bioinspired attention system leveraging selective attention mechanisms through object motion sensitivity for neuromorphic architectures. The proposed event-based architecture enables an agent to visually explore the scene, using saliency-based proto-object mechanisms to detect and saccade toward potential objects while enhancing relative object motion during fixational eye movements. 
It not only incorporates two fundamental mechanisms occurring in vision during selective attention but also demonstrates the capability of bioinspired software implementation on a robotic PTU.
To avoid introducing an additional layer of complexity, we do not incorporate the spatially non-uniform architecture of the retina in this approach. Instead, we focus on saccadic movements that place the salient points at the center of the visual field.
The entire pipeline operates without requiring any form of training, further demonstrating the power of hierarchical architectures and their robustness across different scenarios. This approach leaves room for the integration of more complex learning algorithms to address advanced tasks in the future.