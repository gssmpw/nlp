[
  {
    "index": 0,
    "papers": [
      {
        "key": "ben-zaken-etal-2022-bitfit",
        "author": "Ben Zaken, Elad  and\nGoldberg, Yoav  and\nRavfogel, Shauli",
        "title": "{B}it{F}it: Simple Parameter-efficient Fine-tuning for Transformer-based Masked Language-models"
      }
    ]
  },
  {
    "index": 1,
    "papers": [
      {
        "key": "zhao2024tuning",
        "author": "Bingchen Zhao and Haoqin Tu and Chen Wei and Jieru Mei and Cihang Xie",
        "title": "Tuning LayerNorm in Attention: Towards Efficient Multi-Modal {LLM} Finetuning"
      }
    ]
  },
  {
    "index": 2,
    "papers": [
      {
        "key": "pmlr-v97-houlsby19a",
        "author": "Houlsby, Neil and Giurgiu, Andrei and Jastrzebski, Stanislaw and Morrone, Bruna and De Laroussilhe, Quentin and Gesmundo, Andrea and Attariyan, Mona and Gelly, Sylvain",
        "title": "Parameter-Efficient Transfer Learning for {NLP}"
      }
    ]
  },
  {
    "index": 3,
    "papers": [
      {
        "key": "ruckle-etal-2021-adapterdrop",
        "author": "R{\\\"u}ckl{\\'e}, Andreas  and\nGeigle, Gregor  and\nGlockner, Max  and\nBeck, Tilman  and\nPfeiffer, Jonas  and\nReimers, Nils  and\nGurevych, Iryna",
        "title": "{AdapterDrop}: {O}n the Efficiency of Adapters in Transformers"
      }
    ]
  },
  {
    "index": 4,
    "papers": [
      {
        "key": "wu2024reft",
        "author": "Zhengxuan Wu and Aryaman Arora and Zheng Wang and Atticus Geiger and Dan Jurafsky and Christopher D Manning and Christopher Potts",
        "title": "Re{FT}: Representation Finetuning for Language Models"
      },
      {
        "key": "yin2024lofit",
        "author": "Fangcong Yin and Xi Ye and Greg Durrett",
        "title": "Lo{F}i{T}: Localized Fine-tuning on {LLM} Representations"
      }
    ]
  },
  {
    "index": 5,
    "papers": [
      {
        "key": "hu2022lora",
        "author": "Edward J Hu and yelong shen and Phillip Wallis and Zeyuan Allen-Zhu and Yuanzhi Li and Shean Wang and Lu Wang and Weizhu Chen",
        "title": "Lo{RA}: Low-Rank Adaptation of Large Language Models"
      }
    ]
  },
  {
    "index": 6,
    "papers": [
      {
        "key": "hu2022lora",
        "author": "Edward J Hu and yelong shen and Phillip Wallis and Zeyuan Allen-Zhu and Yuanzhi Li and Shean Wang and Lu Wang and Weizhu Chen",
        "title": "Lo{RA}: Low-Rank Adaptation of Large Language Models"
      }
    ]
  },
  {
    "index": 7,
    "papers": [
      {
        "key": "lester-etal-2021-power",
        "author": "Lester, Brian  and\nAl-Rfou, Rami  and\nConstant, Noah",
        "title": "The Power of Scale for Parameter-Efficient Prompt Tuning"
      }
    ]
  },
  {
    "index": 8,
    "papers": [
      {
        "key": "hu2022lora",
        "author": "Edward J Hu and yelong shen and Phillip Wallis and Zeyuan Allen-Zhu and Yuanzhi Li and Shean Wang and Lu Wang and Weizhu Chen",
        "title": "Lo{RA}: Low-Rank Adaptation of Large Language Models"
      }
    ]
  },
  {
    "index": 9,
    "papers": [
      {
        "key": "lialin2024relora",
        "author": "Vladislav Lialin and Sherin Muckatira and Namrata Shivagunde and Anna Rumshisky",
        "title": "ReLo{RA}: High-Rank Training Through Low-Rank Updates"
      }
    ]
  },
  {
    "index": 10,
    "papers": [
      {
        "key": "hayou2024lora",
        "author": "Soufiane Hayou and Nikhil Ghosh and Bin Yu",
        "title": "Lo{RA}+: Efficient Low Rank Adaptation of Large Models"
      }
    ]
  },
  {
    "index": 11,
    "papers": [
      {
        "key": "wu2024mixture",
        "author": "Xun Wu and Shaohan Huang and Furu Wei",
        "title": "Mixture of {L}o{RA} Experts"
      }
    ]
  },
  {
    "index": 12,
    "papers": [
      {
        "key": "10.1145/502512.502546",
        "author": "Bingham, Ella and Mannila, Heikki",
        "title": "Random projection in dimensionality reduction: applications to image and text data"
      }
    ]
  },
  {
    "index": 13,
    "papers": [
      {
        "key": "hao2024flora",
        "author": "Yongchang Hao and Yanshuai Cao and Lili Mou",
        "title": "Flora: Low-Rank Adapters Are Secretly Gradient Compressors"
      }
    ]
  },
  {
    "index": 14,
    "papers": [
      {
        "key": "kopiczko2024vera",
        "author": "Dawid Jan Kopiczko and Tijmen Blankevoort and Yuki M Asano",
        "title": "Ve{RA}: Vector-based Random Matrix Adaptation"
      }
    ]
  },
  {
    "index": 15,
    "papers": [
      {
        "key": "shin-etal-2020-autoprompt",
        "author": "Shin, Taylor  and\nRazeghi, Yasaman  and\nLogan IV, Robert L.  and\nWallace, Eric  and\nSingh, Sameer",
        "title": "{A}uto{P}rompt: {E}liciting {K}nowledge from {L}anguage {M}odels with {A}utomatically {G}enerated {P}rompts"
      }
    ]
  },
  {
    "index": 16,
    "papers": [
      {
        "key": "lester-etal-2021-power",
        "author": "Lester, Brian  and\nAl-Rfou, Rami  and\nConstant, Noah",
        "title": "The Power of Scale for Parameter-Efficient Prompt Tuning"
      }
    ]
  },
  {
    "index": 17,
    "papers": [
      {
        "key": "li-liang-2021-prefix",
        "author": "Li, Xiang Lisa  and\nLiang, Percy",
        "title": "Prefix-{T}uning: Optimizing Continuous Prompts for Generation"
      }
    ]
  },
  {
    "index": 18,
    "papers": [
      {
        "key": "razdaibiedina-etal-2023-residual",
        "author": "Razdaibiedina, Anastasiia  and\nMao, Yuning  and\nKhabsa, Madian  and\nLewis, Mike  and\nHou, Rui  and\nBa, Jimmy  and\nAlmahairi, Amjad",
        "title": "Residual {P}rompt {T}uning: improving prompt tuning with residual reparameterization"
      }
    ]
  },
  {
    "index": 19,
    "papers": [
      {
        "key": "shi2024dept",
        "author": "Zhengxiang Shi and Aldo Lipani",
        "title": "De{PT}: Decomposed Prompt Tuning for Parameter-Efficient Fine-tuning"
      }
    ]
  },
  {
    "index": 20,
    "papers": [
      {
        "key": "wang2023multitask",
        "author": "Zhen Wang and Rameswar Panda and Leonid Karlinsky and Rogerio Feris and Huan Sun and Yoon Kim",
        "title": "Multitask Prompt Tuning Enables Parameter-Efficient Transfer Learning"
      }
    ]
  },
  {
    "index": 21,
    "papers": [
      {
        "key": "xiao-etal-2023-decomposed",
        "author": "Xiao, Yao  and\nXu, Lu  and\nLi, Jiaxi  and\nLu, Wei  and\nLi, Xiaoli",
        "title": "Decomposed Prompt Tuning via Low-Rank Reparameterization"
      }
    ]
  },
  {
    "index": 22,
    "papers": [
      {
        "key": "10.1145/502512.502546",
        "author": "Bingham, Ella and Mannila, Heikki",
        "title": "Random projection in dimensionality reduction: applications to image and text data"
      }
    ]
  }
]