%%%%%%%% ICML 2024 EXAMPLE LATEX SUBMISSION FILE %%%%%%%%%%%%%%%%%

\documentclass{article}

% Recommended, but optional, packages for figures and better typesetting:
\usepackage{microtype}
\usepackage{graphicx}
\usepackage{subfigure}
\usepackage{booktabs} % for professional tables

% hyperref makes hyperlinks in the resulting PDF.
% If your build breaks (sometimes temporarily if a hyperlink spans a page)
% please comment out the following usepackage line and replace
% \usepackage{icml2024} with \usepackage[nohyperref]{icml2024} above.
\usepackage{hyperref}


% Attempt to make hyperref and algorithmic work together better:
\newcommand{\theHalgorithm}{\arabic{algorithm}}

% Use the following line for the initial blind version submitted for review:
\usepackage{icml2024}

% If accepted, instead use the following line for the camera-ready submission:
% \usepackage[accepted]{icml2024}

% For theorems and such
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{mathtools}
\usepackage{amsthm}

% if you use cleveref..
\usepackage[capitalize,noabbrev]{cleveref}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% THEOREMS
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\theoremstyle{plain}
\newtheorem{theorem}{Theorem}[section]
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{corollary}[theorem]{Corollary}
\theoremstyle{definition}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{assumption}[theorem]{Assumption}
\theoremstyle{remark}
\newtheorem{remark}[theorem]{Remark}

% Todonotes is useful during development; simply uncomment the next line
%    and comment out the line below the next line to turn off comments
%\usepackage[disable,textsize=tiny]{todonotes}
\usepackage[textsize=tiny]{todonotes}



%jam packages
\input{header}
\newcommand{\jam}[1]{\textcolor{orange}{[#1]}}
\newcommand{\yan}[1]{\textcolor{blue}{[#1]}}














% The \icmltitle you define below is probably too long as a header.
% Therefore, a short form for the running title is supplied here:
\icmltitlerunning{Shapley Values in Constant Time with Interpretable Models}

\begin{document}

\twocolumn[
\icmltitle{InstaSHAP: Shapley Values in Constant Time with Interpretable Models}

% It is OKAY to include author information, even for blind
% submissions: the style file will automatically remove it for you
% unless you've provided the [accepted] option to the icml2024
% package.

% List of affiliations: The first argument should be a (short)
% identifier you will use later to specify author affiliations
% Academic affiliations should list Department, University, City, Region, Country
% Industry affiliations should list Company, City, Region, Country

% You can specify symbols, otherwise they are numbered in order.
% Ideally, you should not use this facility. Affiliations will be numbered
% in order of appearance and this is the preferred way.
\icmlsetsymbol{equal}{*}

\begin{icmlauthorlist}
\icmlauthor{Firstname1 Lastname1}{equal,yyy}
\icmlauthor{Firstname2 Lastname2}{yyy}
%\icmlauthor{}{sch}
%\icmlauthor{}{sch}
\end{icmlauthorlist}

\icmlaffiliation{yyy}{Department of XXX, University of YYY, Location, Country}
\icmlaffiliation{comp}{Company Name, Location, Country}
\icmlaffiliation{sch}{School of ZZZ, Institute of WWW, Location, Country}

\icmlcorrespondingauthor{Firstname1 Lastname1}{first1.last1@xxx.edu}
\icmlcorrespondingauthor{Firstname2 Lastname2}{first2.last2@www.uk}

% You may provide any keywords that you
% find helpful for describing your paper; these are used to populate
% the "keywords" metadata in the PDF but will not be shown in the document
\icmlkeywords{Machine Learning, ICML}

\vskip 0.3in
]

% this must go after the closing bracket ] following \twocolumn[ ...

% This command actually creates the footnote in the first column
% listing the affiliations and the copyright notice.
% The command takes one argument, which is text to display at the start of the footnote.
% The \icmlEqualContribution command is standard text for equal contribution.
% Remove it (just {}) if you do not need this facility.

%\printAffiliationsAndNotice{}  % leave blank if no need to mention equal contribution
\printAffiliationsAndNotice{\icmlEqualContribution} % otherwise use the standard text.

\begin{abstract}
In recent years,
the Shapley value and SHAP explanations have emerged as one of the most dominant paradigms for providing post-hoc explanations of black-box machine learning models.
Despite their well-founded theoretical properties,
they greatly suffer from the exponential complexity required to compute them exactly.
Accordingly, a large amount of recent work on SHAP has focused on speeding up computational methods related to the Shapley value.
%
Their connection with additive models, however, is left critically under-emphasized in current literature.
In this work,
we leverage the intimate connection between additive models and Shapley values to train additive models which automatically compute the Shapley value in a single forward pass, even for correlated input features.
\end{abstract}




\section{Introduction}
As deep learning and other black-box approaches continue to dominate the fields of machine learning and artificial intelligence with state-of-the-art results across nearly all domains,
the desire to be able to explain the decisions made by black-box systems continues to grow.
This appetite is made increasingly pertinent as the number of stakeholders, both inside the technology sector as well as within the general populace, influenced by AI decisions grows steadily day after day.
Since its major introduction to explanation of black-box models in \cite{lundberg2017shapleySHAP},
the Shapley value has become a staple for providing explainability of trained AI models, 
built upon the long-standing foundations of Lloyd Shapley's seminal work in game theory \cite{shapley1953shapley}.
In light of the strong theoretical support of Shapley or SHAP explanations,
one of their main drawbacks is their computational feasibility.
Their time complexity scales poorly not only with the amount of data but also with the number of features collected, often becoming insurmountable for computing the Shapley value at industry scales.


Accordingly,
a large amount of recent work on the Shapley value and other removal-based explanations has largely focused on theoretical or practical speedups to computing the Shapley value in ever-larger settings \cite{jethani2022fastSHAP,covert2023shapleyForVIT,kolpaczki2024approximatingShapleyWOmarginalContributions,zhang2023efficientSamplingForShapley}.
Despite a significant amount of progress in speeding up explanations across a variety of domains, usage of the Shapley value remains limited in some applications due to its time complexity.


In parallel to the growing popularity of SHAP explanations, there has been a rise in popularity of the interpretable models called generalized additive models (GAMs), also rooted in historical work and gaining recent popularity \cite{hastie1990originalGAM,lou2013accurate,agarwal2020nam,chang2022nodegam}.
Whereas explainability comes from the top-down (distilling a complex model into a simpler explanation), interpretability builds from the bottom-up (always allowing for glass-box understanding of its mechanisms) \cite{rudin2019stopExplaining}.
This duality is paralleled with the case of SHAP explanations and GAM interpretable models.
Despite the intimate connection between these two approaches, seemingly little work has investigated their relationship, with only \cite{bordt2023shapleyToGAMandBack} looking at how to compute Shapley functions and GAM shape functions from one another.
\jam{nothing handling feature correlations}
%surely I can find more papers doing this
In particular, when accounting for how feature interactions affect Shapley values, one can find a direct correspondence between the Shapley functions and GAM functions.

\jam{horrible transition}
Recent work in both SHAP and GAM literature have been further addressing feature interactions which are partially overlooked by the original Shapley value
% Other recent work has also been addressing the feature interactions which are partially overlooked by the original Shapley value
\cite{fumagalli2023shapIQ,tsai2023faithSHAP}.
%%%\jam{I don't know if this is the best work critiquing Shapley}
%%%Recent work has even critiqued SHAP \cite{huang2023inadequacyOfSHAP} because of its native failings in identifying feature interactions, causing the Shapley value to be zero even when a feature is important.
%%% possibly the line of text that pissed off reviewer #1, lol....
%
Recent work has even critiqued SHAP
\cite{huang2023inadequacyOfSHAP,beenKim_one} because of its failings to handle certain use cases.
This is partially due to SHAP's native failings in identifying feature interactions, causing the Shapley value to be zero even when a feature is important.
\jam{It could be critiqued that such works are not `expecting' the right thing out of the SHAP value. It is hoped that by enhancing the connection between GAM and SHAP can help further calibrate what should be expected from SHAP scores.}
%
%
Despite the abundance of existing work addressing SHAP and adressing feature interactions, the study of their interplay in the setting where input features are not completely independent from another seems to be completely missing from the current literature.
\jam{put this earlier}
We hope that in this work, we can not only provide greater intuition on what Shapley explanations provide and hence when they should or should not be adequate, but also that we can make significant progress towards a longstanding challenge in the additive modeling community with 
the automatic purification of additive models.
We provide several contributions in way of training additive models and computing Shapley values in the correlated variables case, providing insight into the interplay between feature interactions and feature correlations in machine learning:

\begin{itemize}
    \item Provide novel theoretical insights on generalized additive models and further connect these results with recent developments in the theory of Shapley values.
    \item Develop a frontier selection algorithm which is able to solve the meta-optimization problem of selecting feature interactions for additive models to match deep learning performance, inspired by difference in functional ANOVA theory for the correlated variables case.
    \item Introduce a purified loss function for training additive models which attains the \jam{elusive} purification of additive models automatically during the training procedure.
\end{itemize}


\section{Related Work}
The Shapley value was first introduced more than half a century ago, originally in its application to equally distributing the wealth earned by a coalition amongst its constituent members.
The SHAP value has repurposed the original Shapley value to distribute the prediction made by a blackbox algorithm amongst its contributing input features.
With some original studies in \cite{lipovetsky2001regressionViaShapleyApproach,strumbelj2014explainingWithFeatureContributions,datta2016transparencyViaQuantInpInfluence}, most work picked up after the algorithm introduced in 
\cite{lundberg2017shapleySHAP}.
% In this way, SHAP allows to explain any black-box model which can be converted into a masked prediction model,
% obeying some very pleasant theoretical properties it inherits from the Shapley value.


Its immediately obvious disadvantage is that of its computational complexity.
Exact computation requires an exponential number of function evaluations and even approximations can take hundreds or thousands of repeated function calls.
Consequently, an abundance of follow-up work has improved the computational complexity via
better algorithms, architecture specific algorithms, or efficient sampling estimators \cite{lundberg2018treeShapInteractions,lundberg2020treeSHAP,chen2018_LandC_shapley,zhang2023efficientSamplingForShapley,kolpaczki2024approximatingShapleyWOmarginalContributions}.
%better alg
%arch specific algs
%general good 

\jam{terrible writing..., terrible structure}
Another major consideration of SHAP which has come under scrutiny besides its computational complexity is its inability to adequately handle feature interactions.
A groups of variables can be jointly important to a prediction, many works have tried to focus on extending Shapley values to additionally handle the study of feature interactions \cite{grabisch1999originalShapleyInteractionIndex,sundararajan2020shapleyTaylorInteractionIndex,tsai2023faithSHAP}.
In many cases, the extension of variable importance to variable group importance is believed to cover the shortcomings in existing applications of the Shapley value. 
%%% In many cases, it is believed that such extensions can cover the shortcomings which may exist in certain applications of the Shapley value \cite{huang2023inadequacyOfSHAP}



The generalized additive model (GAM) \cite{hastie1990originalGAM,wahba1994ssanova} has also existed for decades as a more expressive alternative to linear regression.
Although some interest has remained over the years 
\cite{hooker2007functionalANOVA,lou2013accurate,caruana2015intelligible,kandasamy16salsa},
machine learning is often dominated by kernel machines, boosted models, and deep learning.
% a lot of focus shifted towards other machine learning approaches.
In recent years, however,
there has been an explosion of additive models trained with neural network approaches
as the appetite for interpretable models continues to grow in the deep learning era
\cite{yang2020gamiNet,chang2022nodegam,agarwal2020nam,enouen2022sian,xu2022snam}.

Alongside the revived attention to additive models, some methods have shifted away from the classical approach of truncating after all 1D and 2D functions \cite{wahba1994ssanova,lou2012intelligible}, instead opting for high-dimensional sparsity and/or higher-order functions \cite{kandasamy16salsa,xu2022snam,yang2020gamiNet,enouen2022sian} to provide competitive performance across a wide variety of datasets and tasks.
Additional interest in feature interactions has also existed here trying to measure the importance of feature interactions within additive models \cite{hao2014interaction,tsang2020archipelago,chen2023deepROCK}

Despite the parallel interest in focusing on feature interactions in both SHAP and GAM, much of these works have remain isolated from one another.
A key exception of this rule is \cite{bordt2023shapleyToGAMandBack} which harps on the same connection between SHAP and GAM which we leverage herein.
Their work, however, is limited to the case of independent features and does not enhance the training of additive models, especially in the case of correlated features. \jam{phrasing}
Our work is also closely related to the work of Faith-SHAP \cite{tsai2023faithSHAP}, which recently made great strides in developing the study of Shapley interaction indices, and Fast-SHAP \cite{jethani2022fastSHAP}, which recently introduced a novel amortization approach to computing the Shapley value with auxiliary models.
In comparison with Faith-SHAP, we extend their pointwise definitions of the Shapley indices to a functional which corresponds to the training of an additive model.
In comparison with FastSHAP, we train explanatory models which are themselves the model of interest, as well as automatically handle interaction indices which the original work is unable to do.
Moreover, while their auxiliary model is only an approximation of the original model's Shapley value, we train interpretable models which match or exceed the performance of deep neural networks, and hence give an exact Shapley value of the interpretable model.

% \jam{despite this parallel interest in focusing on feature interactions in both SHAP and GAM, much of these works remain separate and isolated}


% This connection to additive models has been briefly explored in the (vastly simpler) settings where input features are independent \cite{}.
% However, these works overlook many of the important hurdles in applying additive models into more typical machine learning pipelines with correlated input features and the associated challenges of learning Shapley values in these settings.

% The most closely related work is FastSHAP \cite{jethani2022fastSHAP}
% which also learns some type of additive model to accelerate explanations via the Shapley value.
% The biggest key differences are (a) FastSHAP does not learn an interpretable model like InstaSHAP and hence provides only an approximation of the Shapley value; and (b) FastSHAP does not extend their results to feature interactions and the resulting Shapley interaction indices.
%One could imagine that such an endeavor could be difficult





\section{Technical Background}
\paragraph{Notation.}
Let $\cX\subseteq\bbR^d$ and $\cY\subseteq\bbR^c$ be the input and output space, and consider some function space $\cH$ containing functions $F : \cX \to \cY$.

Let $[d] := \{1,\dots,d\}$.
Let $S\subseteq[d]$ and let $S^C$ denote its complement. 
For $x\in\cX$, let $x_S$ denote $\{x_i\}_{i\in S}$.
We will abbreviate set notations throughout: $S+T = S\cup T$, $S+i = S\cup\{i\}$, $S-T=S\setminus T$, and $S-i = S\setminus \{i\}$.

We will then let $\cS:=\cP([d]) \cong \{0,1\}^d$ be the power set of $[d]$, and consider masked functions or surrogate functions of the form $f : \cX\times\cS \to \cY$.
% with functional space $\cG$.






\subsection{Functional ANOVA and Additive Models}
The generalized additive model (GAM) is the additive approximation of a function via:
\begin{align}
    F(x) = f_\emptyset + \sum_{i} f_i(x_i) + \sum_{i,j} f_{i,j}(x_i,x_j) + \dots
    \label{eqn:gam_via_ellipses}
\end{align}
often truncated to some `order' $\ell \leq d$.
Most commonly $\ell$ is taken to be either 1 or 2 \cite{hastie1990originalGAM,agarwal2020nam,chang2022nodegam}.
This choice is both one of historical limitation on computation power, but also for interpretability reasons.
In particular, 1D and 2D functions may be visualized by partial dependence plot and heatmap respectively.
This has led additive models to become one of the largest class of interpretable models used for machine learning.

Recent works have pushed towards investigating `higher-order feature interactions', corresponding to features sets of size 3D and larger \cite{yang2020gamiNet,abhimanyu2022scalableInterpPolynomials,enouen2022sian}.
We can consider these more general additive models by first choosing a candidate set of interactions $\cI\subseteq\cP([d])$ and then writing the similar equation:
\begin{align}
    F(x) = \sum_{S\in\cI} f_S(x_S)
    \label{eqn:gam_via_subsets}
\end{align}

Once again, the order will be the size of the largest subset $\ell = \max\{ |S| : S\in\cI \}$.
This formulation of an additive model as a sum over candidate interactions immediately begs the question of how to select the correct set of feature interactions to include into the additive model.
In the case of independent input variables, \cite{sobol2001globalSensitivity} provides a precise answer to this question via what is called the `Sobol-Hoeffding' or `functional-ANOVA' decomposition.

First, consider the conditional expectation:
\[
[\cM_p \circ F](x,S) := \Big{\bbE}_{X_{S^C}\hspace{0.2em}\sim\hspace{0.2em} p(X_{S^C} | X_S = x_S)}\bigg[ F(x_S,X_{S^C}) \bigg]
\]
We may define the purified functions 
\[
\Tilde{f}(x,S) := \sum_{T\subseteq S} (-1)^{|S|-|T|} f(x,T)
\]
which we also write $f_S(x)=$$f(x,S)$ and $\Tilde{f}_S(x)=$$\Tilde{f}(x,S)$.

In the space of independent input distributions,
these functions are paraded for having the wonderful `decomposition of variance' property which implies independent contributions from the variances of each purified function.
\[
\label{eqn:sobel_decomp_of_var}
\bbV_X[F(X)] = \sum_{S\subseteq[d]} \bbV_{X_S}[\Tilde{f}(X,S)]
\]
% \[
% \bbE_X[f(X)^2] = \sum_{S\subseteq[d]} \bbE_{X_S}[\Tilde{f}(X,S)^2]
% \]
These independent contributions $V_S := \bbV_{X_S}[\Tilde{f}(X,S)]$, called the Sobol indices, laid the foundation for the field of global sensitivity analysis by describing the importance of each feature interaction $S\subseteq[d]$ \cite{sobol2001globalSensitivity}.

Unfortunately, this equation breaks down for the case of correlated input variables, and there is no perfect alternative which describes the marginal benefit of a feature interaction across all possibilities.
In Section \ref{sec:methods_frontier_selection}, we discuss how we instead approach estimating feature interaction importance instead of the typical Sobol indices.
% \jam{add sobol covariances here?}


\subsection{Shapley Functional}

We will define the (conditional) Shapley value as a functional on the space $\cH$, rather than a function prescribed when given a fixed input value.

For a fixed distribution $p(x)$,
we first define the surrogate function $f$ associated with any typical function $F$ as the conditional expectation:
\[
[\cM_p \circ F](x,S) := \bbE_{X_{S^C} \sim p(X_{S^C} | x_S)}\bigg[ F(x_S,X_{S^C}) \bigg]
% = f(x,S) 
\]

The Shapley functional can then be evaluated as a d-vector of functions via:
\[
[\circphi\circ f]_i (x) := \frac{1}{|\cS_d|} \mathlarger{\sum}_{\pi \in \cS_d} \bigg[  f(x; S_{\pi,i}+i) - f(x; S_{\pi,i}) \bigg]  
\]
where $\cS_d$ denotes the set of all permutations of $d$ with $|\cS_d| =d!$ and
$S_{\pi,i}$ is the set of all predecessors of $i$ in $\pi$, $\{j\in[d] : \pi(j) < \pi(i)\}$.

% \[
% \phi_i (X) = \frac{1}{|\cS_d|} \mathlarger{\sum}_{\pi \in \cS_d} \bigg[  f(X; S_{\pi,i}+i) - f(X; S_{\pi,i}) \bigg]  
% = \mathlarger{\mathlarger{\mathop{\bbE}}}_{\pi \sim \cS_d} \bigg[  f(X; S_{\pi,i}+i) - f(X; S_{\pi,i}) \bigg]
% \] 

Hence, $(\circphi\circ f)\in \cH^d$ and we may define the composite mapping $\Phi := \circphi\circ\cM_p$, with $\Phi : \cH \to \cH^d$ taking any function and returning its $d$ Shapley functions.

% We may also define the interventional Shapley value with:
We may also define the marginal Shapley value with:
%by defining it on the orthogonalized probability pdf
\[
[\cN_p \circ F](x,S) := \Big{\bbE}_{X_{S^C}\hspace{0.2em}\sim\hspace{0.2em} p(X_{S^C}) }\bigg[ F(x_S,X_{S^C}) \bigg]
\]
as $\Phi^{\text{int}} := \circphi\circ\cN_p$.
It should be remarked that under the assumption that independent input variables, these two notions of projection $\cM$ and $\cN$ actually align with one another, resulting in the same Shapley value definition.
For heavily correlated datasets which are commonly encountered in practice,
it is increasingly clear that the conditional or observational Shapley
\cite{frye2021shapleyOnTheManifold,covert2021explainingByRemoving} is of greater practical value.
Although some applications still exist for the `interventional' Shapley,
we will focus on the `observational' Shapley throughout.
Moreover, many of the challenges we overcome are unique to the case of correlated variables for the observational or conditional Shapley.



%xxx the references are broken for some URLs
\jam{citation for this sentence}
\jam{remove the bracketed notation}
The Shapley value is well-known to have the alternative formulation in terms of `unanimity games' as follows:
\begin{align}
[\circphi\circ f]_i (x) = \sum_{S\supseteq \{i\}} \frac{\Tilde{f}_S(x_S)}{|S|}
    \label{eqn:shapley_unanimity}
\end{align}

In particular, we can see that from the perspective of the purified functions, 
the Shapley value simply divides the purified contributions of each feature interaction evenly amongst the features which are its constituents.

It is exactly this formulation which we will leverage to generate the Shapley value directly from an additive model in a single forward propagation.
Further, this lays connection to the corresponding Shapley interaction indices of \citet{tsai2023faithSHAP} and we further discuss this connection in Section \ref{sec:methods_fast_shap_and_faith_shap}.


\subsection{Feature Interactions}
We introduce here further notation to help simplify the discussion in the case of feature interactions.
Although the previous sections could additionally be translated into these notations, we opt instead to first provide the 1D definitions in a form most closely resembling their typical introduction.

Let us first introduce the discrete derivative operator for a given interaction $S\subseteq[d]$:
\[
[\delta_S \circ f](x,T) := \sum_{W\subseteq S} (-1)^{|S|-|W|} f(x,(T-S)+W)
\]
In particular, we see that the purified functions are:
\[
\Tilde{f}(x,S) = [\delta_S \circ f](x,\emptyset)
\]
And Shapley is a weighted average of 1D derivatives:
\[
[\circphi\circ f]_i(x) =  \mathlarger{\sum}_{\pi \in \cS_d} \bigg[ \frac{1}{|\cS_d|} \cdot \Big[\delta_{\{i\}} f \Big](x,S_{\pi,i}) \bigg]  
\]

Let us now define some possible interaction indices, which prescribe a value to each interaction subset $S$ and not just each feature individually.
We will delay a discussion of Faith-SHAP to Section \ref{sec:methods_fast_shap_and_faith_shap}, but one can consider the Shapley value as a 1D interaction index in this section as well.
The inclusion and removal values are defined as 
\begin{align}
    [\circphi^{\text{inc}}_S\circ f](x) &:= [\delta_S \circ f](x,\emptyset) \\
    [\circphi^{\text{rem}}_S\circ f](x) &:= [\delta_S \circ f](x,[d])
\end{align}
The Archipelago value \cite{tsang2020archipelago} is defined to be the average of these two $\circphi^{\text{arch}}_S := \frac{1}{2}\circphi^{\text{inc}}_S + \frac{1}{2}\circphi^{\text{rem}}_S$.
\footnote{Archipelago is not originally defined in the masked regime, but rather with respect to a baseline sample.  Nevertheless, we feel this is a natural extension to the original definition.}
In our experiments as in Algorithm \ref{alg:frontier_selection_algorithm},
we primarily use the Archipelago value over the Shapley value because it is vastly quicker to compute.
Moreover, we find that the Archipelago value does a good job of balancing the feature interactions and feature correlations, better than both the inclusion value (which overemphasizes feature correlations) and the removal value (which overemphasizes feature interactions).
% \jam{do i have that backwards}




\section{Methods}

\subsection{GAM Frontier Selection}
\label{sec:methods_frontier_selection}
In training GAM models,
we must additionally solve the meta-optimization of selecting the subset of feature interactions we would like to include in our additive model.
We will refer to the set of feature interactions $\cI := \{ S_1, \dots, S_L \} \subseteq \cP([d])$ as the `frontier' of the additive model.


\begin{algorithm}[H]%[tb]
\caption{Frontier Selection Algorithm}
\label{alg:frontier_selection_algorithm}
\begin{algorithmic}%[1] %[1] enables line numbers
\STATE {\bfseries Input:} Trained model $f(x)$, validation dataset $X\in\bbR^{n\times d}$, $Y\in\bbR^{n\times c}$ for some number of samples $n\in\bbN$
\STATE {\bfseries Hyperparameters:} $R\in\bbN$, number of rounds \\
$k\in\bbN$, number of interactions per rounds \\
$\tau\in[0,1]$, hierarchy threshold \\
$\circphi$, feature interaction index (e.g. the Inlcusion value, Archipelago value, Shapley value)
% \textbf{Output}: $\cI$, a family of feature interactions with index at most $K$ and strength above $\theta$
\STATE {}
\STATE Set $\cI \gets \{\emptyset\}$
%\COMMENT{~detected interactions so far}
\FOR{$r$ in $1,\dots,R$}
\STATE Set $\cJ \gets$ $\textbf{CANDIDATES}(\cI,\tau)$
\COMMENT{Alg. \ref{alg:build_frontier}}
\FOR{$J$ in $\cJ$}
\STATE $\hat{Y}_J = [\circphi\circ f]_J(X)$
% \STATE $\hat{C}_J = \hat{\bbE}[ Y \cdot \hat{Y}_J ]$
\STATE $\hat{C}_J = \frac{1}{n}[ Y^T \cdot \hat{Y}_J ]$
% \COMMENT Empirical approximation of Sobol Covariance
\ENDFOR
\STATE $\cJ' \gets \text{argsort}(\hat{C}_J)$ 
\STATE $\cJ' \gets \text{top-k}(\cJ',k)$ 
\STATE $\cI \gets \cI \cup \cJ'$
\ENDFOR
\STATE \textbf{return} $\cI$
\end{algorithmic}
\end{algorithm}


In the simpler case of independent input variables, we can see from the decomposition of variance in Equation \ref{eqn:sobel_decomp_of_var},
that the inclusion of a feature interaction $S\subseteq[d]$ reduces the mean-squared error by exactly the Sobol index $V_S$ (assuming no statistical error).
It follows that, given an estimate of the Sobol indices $V_S$, we may sequentially add feature subsets $S$ until a particular error tolerance or cross-validation performance is achieved.

In the case of correlated input variables, however, it is no longer the case that Sobol indices are an appropriate measurement of the marginal contribution of a feature interaction's inclusion into the additive model.
The typical extension of the Sobol indices to this case is via the Sobol covariances which may be defined $C_S := \bbE[ F(X) \cdot \Tilde{f}_S(X_S) ]$.
These covariances still obey the desired decomposition equation; however, they no longer perfectly correspond to the marginal value of including a particular subset $S$.
In fact, the marginal value of a subset $S$ now depends on the current frontier set $\cI$ which is being considered, unlike in the independent case.
In Algorithm \ref{alg:frontier_selection_algorithm}, we utilize a partial approximation of the Sobol covariances to estimate the usefulness of including a particular subset $S$ in the additive model's frontier.
A detailed discussion on the learned additive models coming from arbitrary frontiers with correlated features can be found in Appendix \ref{app_sec:novel_GAM_frontier_and_correlated}.

% \jam{that we can measure these Sobol indices or even their correlated counterparts (to get the correct frontier value)}




\begin{algorithm}[tb]
   \caption{Build Frontier Candidates}
   \label{alg:build_frontier}
\begin{algorithmic}
\STATE {\bfseries Input:} Current frontier set $\cI\subseteq\cP([d])$, \\
hierarchy threshold $\tau\in[0,1]$
\STATE {}
   \STATE \COMMENT{\textit{One element fattening of all current feature subsets}}
   \STATE $\cJ' \gets \{S + i : S\in\cI, i\in[d]\}$\quad
   \STATE $\cJ \gets \emptyset$
   \FOR{$J\in\cJ'$}
   % \STATE $p_J = \frac{\cP(J) \cap \cI}{\cP(J)}$
   \STATE \COMMENT{\textit{Ratio of $J$'s subsets which are already included out of the total possible $2^{|J|}$}}
   \STATE $p_J = |\cP(J) \cap \cI| / |{\cP(J)}| $\quad
\STATE {}
   \IF{$p_J \geq \tau$}
  \STATE $\cJ \gets \cJ \cup \{J\}$
   \ENDIF
   \ENDFOR
\STATE \textbf{return} $\cJ$
\end{algorithmic}
\end{algorithm}

\subsection{Fast SHAP and Faith-SHAP}
\label{sec:methods_fast_shap_and_faith_shap}
An alternative formulation of the Shapley value is through the solution to a mean-squared error optimization:
\[
\argmin_{\circphi_0\in\bbR, \circphi\in\bbR^d} \bigg\{
% \big\bbE_{S\sim p(S)}\bigg[
\big\bbE_{S}\bigg[
\bigg| f(S) - \circphi_0 - \sum_{i=1}^d 1_{i\in S}\cdot \circphi_i \bigg|^2
\bigg]
\bigg\}
\]
So long as the expectation is taken with respect to the `Shapley kernel' distribution.
This pointwise optimization has been translated into a functional optimization via the work of FastSHAP \cite{jethani2022fastSHAP}:
\[
\argmin_{\circphi_0, \circphi(x)} \bigg\{
\big\bbE_{x,S}\bigg[
\bigg| f(x,S) - \circphi_0 - \sum_{i=1}^d 1_{i\in S}\cdot \circphi_i(x) \bigg|^2
\bigg]
\bigg\}
\]
This solution to a minimization problem is used to approximately solve for the Shapley functions associated with a given function $f$.
It is in this way that FastSHAP yields an approximation to the Shapley value for any particular input by amortizing the cost of learning the Shapley value through the training of an additive model.
After the training of an additive model, the approximate Shapley value can be returned in constant time.

In the study of feature interactions,
the Faith-SHAP work \cite{tsai2023faithSHAP} extends the mean-square error formulation of the Shapley value to `interaction indices' which not only measure the individual power of features, but also their cooperative strengths in feature interactions.
Their formulation can be written as:
\[
\argmin_{\{\circphi_T\}\in\bbR^\cI} \bigg\{
% \big\bbE_{S\sim p(S)}\bigg[
\big\bbE_{S}\bigg[
\bigg| f(S) - \sum_{T\in\cI} 1_{T \supseteq S}\cdot \circphi_T \bigg|^2
\bigg]
\bigg\}
\]
Where they consider frontiers $\cI$ of the form $\cI_{\leq\ell} := \{ S\subseteq[d] : |S|\leq\ell \}$ for some interaction order $\ell=1,\dots,d$.
It is relatively straightforward to show that $\ell=1$ corresponds to the traditional Shapley value, and the interaction indices obey many of the same axioms as the original Shapley value.
% \jam{when we take p(S) = shapley kernel}
Additional details and an explicit description of the indices can be found within \cite{tsai2023faithSHAP}.





\begin{figure*}[t]
    \centering
    % \includegraphics[width=0.9\textwidth]{icml2024/figures/baby_synthetic_full_11_rhos.pdf}
    \includegraphics[width=1.0\textwidth]{icml2024/figures/baby_synthetic_full_11_rhos.pdf}
    \caption{Simple Synthetic Dataset using various $\rho\in\{0.0,0.1,0.2,\dots,1.0\}$.  First three rows corresponds to the learned $\Tilde{f}_x$, $\Tilde{f}_{y}$, and $\Tilde{f}_{xy}$.  Last two rows correspond to the corresponding Shapley functions $\circphi_x$ and $\circphi_y$ depicted as partial dependence plots (instead of the typical beeswarm plot).  
    Visually constrained to $x,y\in[-2,2]^2$ with colors in $[-3,3]$.  
    A single point is highlighted to emphasize how the Shapley value in the bottom two rows is constructed from the top three rows. }
    \label{fig:baby_synthetic_learned_GAM}
\end{figure*}




\subsection{Purified Additive Models}
Now consider the same pointwise extension of the \cite{tsai2023faithSHAP} definition to the learning of an additive model and compare with the traditional loss function for additive models.
\begin{align}
\argmin_{\{\circphi_T(x)\}} \bigg\{
\big\bbE_{x,S}\bigg[
\bigg| f(x,S) - \sum_{T\in\cI} 1_{T \supseteq S}\cdot \circphi_T(x) \bigg|^2
\bigg]
\bigg\}
\label{eqn:fast_SHAP_but_interactions}
\end{align}
\begin{align}
\argmin_{\{\circphi_T(x)\}} \bigg\{
\big\bbE_{x}\bigg[
\bigg| F(x) - \sum_{T\in\cI} \circphi_T(x) \bigg|^2
\bigg]
\bigg\}
\nonumber
\label{eqn:classical_GAM_loss}
\end{align}


% Arbitrary masked GAM formulation
% \[
% \argmin_{\{\circphi_T(x,S)\}} \bigg\{
% \big\bbE_{x,S}\bigg[
% \bigg| f(x,S) - \sum_{T\in\cI} \circphi_T(x,S) \bigg|^2
% \bigg]
% \bigg\}
% \]

\jam{can use parameters $\theta$ to make more clear.  also this section is still garbage 'sequence of observations' and not actually a methods section}
One immediately notices the serious similarities between the two optimization equations.
In accordance with these similarities, we define the `purified' MSE loss function as 
\begin{align}
\argmin_{\{\circphi_T(x)\}} \bigg\{
\big\bbE_{x,S}\bigg[
\bigg| F(x) - \sum_{T\in\cI} 1_{T \supseteq S}\cdot \circphi_T(x) \bigg|^2
\bigg]
\bigg\}
\label{eqn:purified_loss}
% \label{eqn:purified_loss_insta_SHAP}
\end{align}
In the appendix, we demonstrate that this loss function indeed has a solution which generates a `purified' additive model and 
indeed follows the same solution as the generalization of Faith-SHAP's interaction index.
Importantly, this allows for the training of an additive model which then automatically has its purified terms delineated from one another, allowing for instant computation of the Shapley value function via the previously mentioned Equation \ref{eqn:shapley_unanimity}.
A lengthy discussion on the connections between these different approaches and associated theorems are left to the appendix.
The authors believe that this is the first set of results in the case of correlated features and arbitrary frontier sets.


It should be noted that even without using the distribution $p(S)$ to be the Shapley kernel,
it is still true that we can exactly compute the Shapley value from the learned additive model.
That is to say,
it is sufficient to consider the subset masking as part of the purified loss for any possible distribution $p(S)$ which is strictly positive, since we may treat the learned additive model as the model we are trying to explain with the Shapley value.
Although possibly confusing at first, it is probably most helpful to think of Equation \ref{eqn:fast_SHAP_but_interactions} as the interaction extension to Fast-SHAP, but to think of Equation \ref{eqn:purified_loss} as the InstaSHAP method.

% \jam{say more here: even though additive blah blah, its a perfect shapley value for the additive model (no approx)}

% \jam{Purified Loss function in the uncorrelated case}
% \jam{more complicated frontiers in the correlated case}
% \jam{a lengthy dicsusion on the connections and novel theorems left in the appendix}












\section{Experiments}


\subsection{Synthetic}
First, we look at a particularly simple example of synthetic data to highlight the two important aspects which the Shapley value alone is unable to capture:
feature interaction and feature correlation.
Hopefully this example will help develop intuition for the Shapley value and highlight its unique challenges in the setting where input variables are correlated.
% of the Shapley value, and hopefully help further develop intuition for when it should and should not be utilized in application.


We consider the data generated by 
\[
% f(x,y) = x + y + (xy-\rho) 
f(x,y) = x + xy
\quad\quad
X,Y \sim \cN\Big(\Vec{0}, 
{\scriptsize \setlength\arraycolsep{2pt} \begin{pmatrix}
1&\rho\\ \rho&1 \end{pmatrix}}
\Big)
\]
for some $\rho\in[-1,1]$.  A detailed solution can be found in Appendix \ref{app_sec:synthetic_data_calcs}, but the Sobol covariances can be calculated to be: $C_\emptyset = \rho^2$, $C_x = 1+2\rho^2$, $C_y = 3\rho^2$, and $C_{xy} = 1-4\rho^2$.
Suprisingly, the term $C_{xy}$ can be negative whenever we choose $|\rho|>\frac{1}{2}$.

A further discussion is provided in the appendix, but in short, this surprising case is a consequence of the redundant information from the feature correlation becoming stronger than the synergistic information from the feature interaction.
Such cases can introduce significant challenges to existing approaches using Shapley values or additive models, 
which often implicitly or explicitly assume that input features are independent from one another.




In Figure \ref{fig:baby_synthetic_learned_GAM}, we can see the learned set of functions across various $\rho\in\{0.0,0.1,\dots,1.0\}$ when learning a GAM with the purified loss function.
The Shapley functions can also be calculated to be $\circphi_x = \Tilde{f}_{x} + \frac{1}{2}\Tilde{f}_{xy}$ and $\circphi_y = \Tilde{f}_{y} + \frac{1}{2}\Tilde{f}_{xy}$ which can be seen in the fourth and fifth rows from the Figure.
We can furthermore see that the additive models using the purified loss align with the true purified ANOVA decomposition and that hence the Shapley value functions can be computed in constant time given the purified GAM model.

Further, going left to right, we see how the strength of the 1D effects (first and second rows) increase, whereas the strength of the 2D effects (third row) decreases as the amount of correlation increases.
This corresponds to the deterioration of the feature interaction due to the increase in feature correlation.
At the halfway mark, the 2D function is no longer positively correlated with the true outcome.
This is most obvious in the far right ($\rho=1.0$) plots where $\Tilde{f}_{x} = \Tilde{f}_{x} = -\Tilde{f}_{xy}$, meaning $\circphi_x = \frac{1}{2}\Tilde{f}_{x}$ and $\circphi_y = \frac{1}{2}\Tilde{f}_{y}$.





\begin{figure}
    \centering
    \includegraphics[width=0.96\columnwidth]{icml2024/figures/bikeshare_gam_shape.pdf} \\
    \includegraphics[width=0.96\columnwidth]{icml2024/figures/bikeshare_SHAP_fn.pdf} 
    \includegraphics[width=0.96\columnwidth]{icml2024/figures/bikeshare_full_fn.pdf} 
    \caption{Shape Function Plots for the BikeShare Dataset. \\
    (a) The shape function learned for the interpretable GAM for its dependence on hour of the day and weekday type.
    (b) The SHAP function for hour calculated automatically from the learned GAM. \\
    (c) The true function for the entire dataset, plotted in the same fashion as the shape function and Shapley function. \\
    Note the decreasing levels of precision as one goes from the shape function learned by the interpretable additive model, to the black-box explanations of the same model in terms of the Shapley function, and finally to the predictions themselves made by the additive model. (Note that the categorical variable `Hour' is splayed for visualization purposes.)
    }\label{fig:bikeshare_PDP}
\end{figure}


\subsection{Bike Share}
This dataset predicts the expected bike demand each hour given some relevant features like the day of the week, time of day, and current weather.
There is a total of thirteen different input features predicting a single continuous output variable.

In the case of a multi-layer perceptron trained to predict the bike demand, the normalized mean-squared error ($R^2$) results as $6.59\%$.
After training a GAM model on the first 20 selected indices, the additive model can achieve a normalized MSE of $6.23\%$.
This demonstrates that our frontier selection algorithm can easily allow GAM models to match the performance of state-of-the art approaches, even with as few shapes as 20 selected indices.

In Figure \ref{fig:bikeshare_PDP},
we can see the learned shape functions from the additive model and how it compares with both the Shapley value at each point, but also the full prediction at each point.
This helps not only provide a visualization of the connection between GAM and SHAP through \ref{fig:bikeshare_PDP}a and \ref{fig:bikeshare_PDP}b, but also the spectrum of interpretability to explainability to complete black box.



\subsection{Tree Cover}
The dataset consists of predicting the types of trees covering a specific forest area from a selection of 7 tree species (Spruce, Lodgepole Pine, Ponderosa Pine, Willow, Aspen, Douglas-Fir, or Krummholz) in a Colorado national park based on 10 numerical features and 1 categorical feature of the area.
Simple investigation with feature importance methods or the methods described herein can determine that two features which are the most critical for determining the species:
altitude of the land and soil category of the land.
Accordingly, we provide their partial dependence plots in Figure \ref{fig:elev_or_soil_PDP}.


\begin{figure}
    \centering
    \includegraphics[width=0.76\columnwidth]{icml2024/figures/ELEV_five_averaged_pdp.pdf} \\
    \includegraphics[width=0.76\columnwidth]{icml2024/figures/SOIL_five_averaged_pdp.pdf} 
    % \includegraphics[width=0.49\columnwidth]{icml2024/figures/tree_legend_resized.pdf} 
    \caption{1D Dependence of Tree Species on Altitude \textbf{or} Soil}
    \label{fig:elev_or_soil_PDP}
\end{figure}


However, this misses the fact that both the elevation and soil type are additionally correlated with one another.
Indeed, the soils are grouped according to climatic zone which generally correspond to different altitude climates.
For convenience, we keep these soil classes in the same orders as their expected elevation, named: `lower montane', `upper montane', `subalpine', and `alpine'.
One notes that the Krummholz tree can be found at high altitudes but also in alpine (often rocky) soil.
Without an understanding that these two features are correlated with one another, it might a priori seem like these are two independent contributions to the prediction.
Similarly, Willows, Douglas-firs, and Ponderosas are expected to be found at lower altitudes, but also to be found in montane soils.
Yet again, it turns out that these two facts are indeed correlated with one another and hence the purified projection functions alone may not be sufficient to yield a good explanation.

In this case, a lot can be gleaned by viewing the 2D shape function which depends on both the soil and the elevation.
In Figure \ref{fig:elev_and_soil_PDP}, we visualize this 2D shape function as a scatterplot with colored heatmap.
Through the density of points, we can see there is indeed a strong positive correlation between the soil type and the elevation.
Furthermore, using the colors for each tree species, we can see that there is a lot of redundant information carried by both the soil and the elevation, but also that there is some non redundant information.

\begin{figure}
    \centering
    \includegraphics[width=0.85\columnwidth]{icml2024/figures/ELEV_SOIL_five_averaged_pdp.pdf}
    \includegraphics[width=0.44\columnwidth]{icml2024/figures/tree_legend_resized.pdf} 
    \caption{2D Dependence of Tree Species on Altitude \textbf{and} Soil}
    \label{fig:elev_and_soil_PDP}
\end{figure}


% \begin{figure}
%     \centering
%     \includegraphics[width=0.89\columnwidth]{icml2024/figures/ELEV_SOIL_but_ONLY_ELEV_five_averaged_pdp.pdf}
%     \includegraphics[width=0.89\columnwidth]{icml2024/figures/ELEV_SOIL_but_ONLY_SOIL_five_averaged_pdp.pdf}
%     \caption{2D Partial Dependence of Tree Species on Altitude \textbf{or} Soil}
%     \label{fig:elev_and_soil_PDP}
% \end{figure}


Training a multilayer perceptron on this dataset is able to achieve validation accuracy of $80.4\%$.
After applying our frontier selection algrorithm to choose a set of $50$ interaction subsets, 
a GAM is able to achieve $82.2\%$ accuracy.
This demonstrates that using these techniques to train a GAM can result in models which are matching state-of-the-art performance to blackbox models while simultaneously allowing for instantaneous Shapley value explanations as part of the model.




\section{Conclusion}
% \jam{reconclude and reintroduce}
In conclusion,
using efficient frontier selection algorithms for generalized additive models can match state-of-the-art performance for typical machine learning approaches.
As a consequence of training additive models with our new purified loss function, we enable the automatic computation of Shapley values without the need for further computation.
The issue of fast computation of Shapley values is translated into the objective of training performant additive models.
We provide additional theoretical results which further explain the performance achieved by additive models with an arbitrary frontier set, and empirical results on synthetic and real-world datasets to demonstrate the effectiveness of our approach.



\section{Broader Impact}
This work focuses on enhancing the interpretability of deep learning models.
Although, broadly, the work of interpretability can help inform all related stakeholders to the reasonings behind decisions made by AI systems to the benefit of everyone involved,
all interpretations are done by humans and can be hence used for unfavorable outcomes both intentionally and unintentionally.
Interpretability is only one piece of the larger puzzle which is transparency and trustworthiness in AI systems.



\bibliography{refs,refs_sian,refs_textgenshap}
\bibliographystyle{icml2024}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% APPENDIX
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newpage
\appendix
\onecolumn







\section{Synthetic Data Calculations}
\label{app_sec:synthetic_data_calcs}
We consider the data generated by 
\[
% f(x,y) = x + y + (xy-\rho) 
f(x,y) = x + xy
\quad\quad
X,Y \sim \cN\Big(\Vec{0}, 
{\scriptsize \setlength\arraycolsep{2pt} \begin{pmatrix}
1&\rho\\ \rho&1 \end{pmatrix}}
\Big)
\]
for some $\rho\in[-1,1]$. \\
It is relatively straightforward to calculate that:
% $f_\emptyset = 0$,
% $f_x = x + \rho x + \rho x^2 - \rho$,
% $f_y = \rho y + y + \rho y^2 - \rho$,
% $f_{xy} = x + y + xy - \rho$.
% This means that $\Tilde{f}_\emptyset = 0$,
% $\Tilde{f}_x = x + \rho x + \rho x^2 - \rho$,
% $\Tilde{f}_y = \rho y + y + \rho y^2 - \rho$,
% $\Tilde{f}_{xy} = -\rho y - \rho y + xy - \rho$.

% \begin{align}    
% f_x = x + \rho x + \rho x^2 - \rho \\
% f_y = \rho y + y + \rho y^2 - \rho \\
% f_{xy} = x + y + xy - \rho \\
% \end{align}
\begin{align}
f_\emptyset &= \rho \nonumber \\
f_x &= x + \rho x^2 \nonumber \\
f_y &= \rho y + \rho y^2  \nonumber \\
f_{xy} &= x + xy \nonumber 
\end{align}
\begin{align}   
\Tilde{f}_\emptyset &= \rho \nonumber \\
\Tilde{f}_x &= x + \rho x^2 - \rho \nonumber \\
\Tilde{f}_y &= \rho y + \rho y^2 - \rho  \nonumber \\
\Tilde{f}_{xy} &= -\rho y + xy - \rho x^2 - \rho y^2 + \rho \nonumber
\end{align}

The Sobol covariances are hence
\begin{align}
    \bbE[f \cdot \Tilde{f}_\emptyset] = \rho^2 \nonumber\\
    \bbE[f \cdot \Tilde{f}_{x}] = \bbE[x^2 + \rho x^3 + x^2y + \rho x^3y -\rho x -\rho xy] = 1 + 0 + 0 + 3\rho^2 +0 -\rho^2 \nonumber\\
    \bbE[f \cdot \Tilde{f}_y] = \bbE[\rho xy + \rho xy^2 + \rho xy^2+ \rho xy^3 -\rho x -\rho xy] = \rho^2 + 0 + 0 + \rho(3\rho)+0 -\rho^2 \nonumber \\
    \bbE[f \cdot \Tilde{f}_{xy}] = \bbE[f^2] - (\rho^2) - (1+2\rho^2) - (3\rho^2) = 1 + (1+2\rho^2) - (1+6\rho^2) \nonumber
\end{align}

Hence $C_\emptyset = \rho^2$, $C_x = 1+2\rho^2$, $C_y = 3\rho^2$, $C_{xy} = 1-4\rho^2$.
% $-\rho^2+0+0+0+0   \quad+0+(1+2\rho^2)-\rho(3\rho)-\rho(3\rho)+\rho^2$
% = $1-4\rho^2$

Interestingly, we can see that for $|\rho|> \frac{1}{2}$, we actually have that $C_{xy} < 0$.
That is to say, the interaction term alone is not actually positively correlated with the function we are trying to learn.
This further implies that the purified interaction is actually negatively correlated with our target, and adding it to the model somehow reduces the performance as measured with MSE.
This must be juxtaposed with the fact that our function $f(x,y) = x+xy$ clearly demonstrates a feature interaction in the term $xy$.

This can however be resolved by not thinking of the purified interaction alone but in conjunction with other features when it is added to the model.
For example, if we started with $y$ and added $x$, then we could consider $C_x+C_{xy}=2-2\rho^2 \geq 0$ as the improvement to the model.
Conversely, if we started with $x$ and added $y$, we could consider $C_y+C_{xy}=1-\rho^2 \geq 0$ as the improvement to the model.
Intuitively, it is not the fact that the interaction is detrimental to the model performance, as clearly it is necessary for $|\rho|<1$, but rather that it is overshadowed by the information which is gained from either $x$ or $y$ alone.
``The redundant information from knowing $x$ or $y$ outweighs the synergistic information from knowing $x$ and $y$.''

The Shapley functions can be easily calculated from the purified form as $\circphi_x(x,y) = \Tilde{f}_{x} + \frac{1}{2}\Tilde{f}_{xy}$ and $\circphi_y(x,y) = \Tilde{f}_{y} + \frac{1}{2}\Tilde{f}_{xy}$: 
\begin{align}
    \circphi_x(x,y) &= (x+\rho x^2 - \rho) + \frac{1}{2}( -\rho y + xy - \rho x^2 - \rho y^2 + \rho) &= \Big[x-\frac{\rho}{2}y\Big] + \Big[\frac{xy}{2}+\frac{\rho}{2} (x^2 - y^2 - 1) \Big]\nonumber\\
    \circphi_y(x,y) &= (\rho y+\rho y^2 - \rho) + \frac{1}{2}( -\rho y + xy - \rho x^2 - \rho y^2 + \rho) &= \Big[\frac{\rho}{2}y\Big] + \Big[\frac{xy}{2}+\frac{\rho}{2} (y^2 - x^2 - 1) \Big]\nonumber
\end{align}

\jam{order of sobol covariance introduction before calculation}

\section{Theory of Functional ANOVA for Correlated Inputs}
\label{app_sec:novel_GAM_frontier_and_correlated}
It is well-known that the famous `decomposition of variance' formula critically depends on the fact that each of the input variables is completely independent from one another:
\[
\bbE_X[f(X)^2] = \sum_{S\subseteq[d]} \bbE_{X_S}[\Tilde{f}(X,S)^2]
\]
However, there is a popular alternative for sensitivity analysis in the correlated variables case, namely \cite{rabitz2010correlatedSobolIndices}:
\[
\bbE_X[f(X)^2] = \sum_{S\subseteq[d]} \bbE_{X}[f(X) \cdot \Tilde{f}(X,S)]
\]
In words, instead of the decomposition of the variance completely into the variances of each of the independent feature interactions, one cannot assume that $\Tilde{f}_S$ and $\Tilde{f}_T$ are decorrelated for $S\neq T$ and so our summation formula must account for this.
It follows that the covariance between the original function $f$ and each of the purified functions $\Tilde{f}_S$ is a more appropriate measure to decompose a function on correlated inputs.
It follows that the so-defined measures $C_S := \bbE_{X}[f(X) \cdot \Tilde{f}(X,S)]$ may indeed be negative.
Intuitively, this corresponds to the case where the `constructive' information provided by allowing a feature interaction is overshadowed by the `destructive' information created by the redundancies of a feature correlation. 


\subsection{Additive Model Solution for Arbitrary Frontiers}
As mentioned in the main text, one of the critical issues for using additive models to learn a particular target function, is solving the meta-optimization to find an optimal frontier for the additive model.
As of yet, there is seemingly no known measurements for the correlated input case paralleling the Sobol indices in the indepdendent input case.
In particular,
for a given frontier $\cI\subseteq\cP([d])$ and a candidate interaction $S\subseteq[d]$ not yet in the frontier,
there is seemingly no work trying to estimate the differences in errors between these two learned additive models.
Moreover, it is noted in the main body that the measurements $C_S$ are in general insufficient to measure these differences in all cases, and must only be used as an approximation.

Herein, we describe the solution to the additive model training procedure as the solution the Euler-Lagrange equation from calculus of variations.
Thereafter, we simplify our solution into a single matrix-operator functional equation defined by the projection operators $\cN_S$ in the function space $\cH$.
We then provide a formal solution to the matrix-operator equation and show how it can be approximated through repeated projections.

\begin{theorem}
Fix an input distribution $X\sim p(X)$ and a function $y=F(x)$.
Consider a frontier $\cI = \{S_1,\dots,S_L\}$ and consider the solution to the additive model training equation:
\[
\{g_T^*\}_T := \argmin_{\{g_T\}_T}\bigg\{ \bbE_X\bigg[
\bigg| F(X) - \sum_{T\in\cI} g_T(X) \bigg|^2
\bigg]\bigg\}
\]

Recall the conditional expectation projection operators
\[
[\cM_S \circ F](x) := \Big{\bbE}_{X_{S^C}\hspace{0.2em}\sim\hspace{0.2em} p(X_{S^C} | X_S = x_S)}\bigg[ F(x_S,X_{S^C}) \bigg]
\]
where we drop the subscript denoting the distribution $p(x)$.
The solution obeys the equation:
\begin{align}
\begin{pmatrix}
        e     & \cM_{S_1} & \dots & \cM_{S_1} \\
    \cM_{S_2} &     e     & \dots & \cM_{S_2} \\
    \vdots &   \vdots  & \ddots & \vdots \\
    \cM_{S_L} & \cM_{S_L} & \dots & e \\
\end{pmatrix}
\begin{pmatrix}
g^*_{S_1} \\ g^*_{S_2} \\ \vdots \\ g^*_{S_L}
\end{pmatrix}
=
\begin{pmatrix}
f_{S_1} \\ f_{S_2} \\ \vdots \\ f_{S_L}
\end{pmatrix}
\label{app_eqn:matrix_operator_eqn}
\end{align}

    
\end{theorem}
\begin{proof}
Let the objective functional be defined
\[
J(\{g_T\}_T) := \bbE_X\bigg[
\bigg| F(X) - \sum_{T\in\cI} g_T(X) \bigg|^2
\bigg]
\]
    Recall from calculus of variations the Euler-Lagrange equation:
    \begin{align}
        \frac{\delta J}{\delta g_{S_i}} \equiv 0 \nonumber
    \end{align}
    for each possible $S_i\in\cI$, which then implies 
    \begin{align}
        \bbE_{X_{S_i}}\bigg[ \delta_{S_i}(X_{S_i}) \cdot \bbE_{X_{{S_i}^C} | X_{S_i}}\bigg[ F(X) -  \sum_{{S_i}\in\cI} g_{S_i}(X) \bigg]\bigg]  \equiv 0 \nonumber \\ 
        \bbE_{X_{{S_i}^C} | X_{S_i}}\bigg[ F(X) -  \sum_{{S_i}\in\cI} g_{S_i}(X) \bigg] \equiv 0 \nonumber 
    \end{align}

    This can simply be rewritten as:
    \begin{align}
        f_{S_i}(X) \equiv \cM_{{S_i}} \circ \sum_{T\in\cI} g_T(X) \nonumber \\ 
        f_{S_i}(X) \equiv \cM_{{S_i}} \circ g_{S_i}(X) + \sum_{T\in\cI-{S_i}} \cM_{{S_i}} \circ g_T(X) \nonumber \\ 
        f_{S_i}(x) \equiv g_{S_i}(x) + \sum_{T\in\cI-{S_i}} [{S_i}\circ g_T](x) \nonumber \\
        f_{S_i} =  g_{S_i} + \sum_{T\in\cI-{S_i}} [{S_i}\circ g_T] \nonumber 
    \end{align}
    Hence, it can be seen that each row of the matrix equation corresponds to a partial gradient from the Euler-Lagrange equation as desired.
    Thus, any possible solution to minimization of the quadratic functional $J$ must obey the above matrix equation.
\end{proof}

It is moreover the case that we can reduce a frontier to its solution only on the largest subsets which have no supersets included.
From the perspective of the poset $\cP([d])$, this corresponds to the set of maximal elements.
It can be seen in the above proof that any solution on a projection $S_1 \subseteq S_2$ must automatically be obeyed by the operator equation for the larger set $S_2$.

Accordingly, identify a frontier $\cI$ with its set of maximal elements $T_1, \dots, T_{L'}$.
Following from Equation \ref{app_eqn:matrix_operator_eqn}, we can ensure that it is enough to solve the matrix equation:
\begin{align}
\begin{pmatrix}
        e     & \dots & \cM_{T_1} \\
    \vdots & \ddots & \vdots \\
    \cM_{T_{L'}} & \dots & e \\
\end{pmatrix}
\begin{pmatrix}
g^*_{T_1} \\ \vdots \\ g^*_{T_{L'}}
\end{pmatrix}
=
\begin{pmatrix}
f_{T_1} \\ \vdots \\ f_{T_{L'}}
\end{pmatrix}
\nonumber
\label{app_eqn:matrix_operator_eqn_mountainTops}
\end{align}
Which we can then take the formal inverse of the operator matrix to yield a solution
\begin{align}
\begin{pmatrix}
g^*_{T_1} \\ \vdots \\ g^*_{T_{L'}}
\end{pmatrix}
\text{``}=\text{''}
\begin{pmatrix}
        e     & \dots & \cM_{T_1} \\
    \vdots & \ddots & \vdots \\
    \cM_{T_{L'}} & \dots & e \\
\end{pmatrix}^{-1}
\begin{pmatrix}
f_{T_1} \\ \vdots \\ f_{T_{L'}}
\end{pmatrix}
\nonumber
\label{app_eqn:matrix_operator_eqn_mountainTops_inverted}
\end{align}
so long as we take care with the determinant in realizing that a matrix of non-commutative elements does not have a well-defined matrix determinant as it does in the commutative case.

Nonetheless, let us now illustrate the usefulness of such a formal inverse in a simple case with our synthetic example from earlier.
\begin{align}
\begin{pmatrix}
        e     & \cM_{x} \\
    \cM_{y}  & e \\
\end{pmatrix}
\begin{pmatrix}
g^*_{x} \\ g^*_{y}
\end{pmatrix}
=
\begin{pmatrix}
f_{x} \\  f_{y}
\end{pmatrix}
\nonumber 
\end{align}
\begin{align}
\begin{pmatrix}
        e     & -\cM_{x} \\
    -\cM_{y}  & e \\
\end{pmatrix}
\begin{pmatrix}
        e     & \cM_{x} \\
    \cM_{y}  & e \\
\end{pmatrix}
\begin{pmatrix}
g^*_{x} \\ g^*_{y}
\end{pmatrix}
=
\begin{pmatrix}
        e     & -\cM_{x} \\
    -\cM_{y}  & e \\
\end{pmatrix}
\begin{pmatrix}
f_{x} \\  f_{y}
\end{pmatrix}
\nonumber 
\end{align}
\begin{align}
\begin{pmatrix}
        e-\cM_{x}\cM_{y}     & 0 \\
    0  & e-\cM_{y}\cM_{x} \\
\end{pmatrix}
\begin{pmatrix}
g^*_{x} \\ g^*_{y}
\end{pmatrix}
=
\begin{pmatrix}
f_{x} - \cM_{x}\circ f_{y} \\  f_{y}-\cM_{y}\circ f_{x}
\end{pmatrix}
\nonumber
\end{align}
\begin{align}
\begin{pmatrix}
e -\cM_{x}\cM_{y}\\ e -\cM_{x}\cM_{y}
\end{pmatrix}
\odot
\begin{pmatrix}
g^*_{x} \\ g^*_{y}
\end{pmatrix}
=
\begin{pmatrix}
f_{x} - \cM_{x}\circ f_{y} \\  f_{y}-\cM_{y}\circ f_{x}
\end{pmatrix}
\nonumber
\end{align}
We can then use the formal Taylor series expansion of the operator inverse 
\begin{align}
g^*_{x} = \sum_{n=0}^\infty (\cM_{x}\cM_{y})^n \circ \Big[f_{x} - \cM_{x}\circ f_{y}\Big] \nonumber \\
g^*_{y} = \sum_{n=0}^\infty (\cM_{y}\cM_{x})^n \circ \Big[f_{y} - \cM_{y}\circ f_{x} \Big] \nonumber 
\end{align}
If we choose to denote repeated projections with semicolons, we can then write our solutions as 
\begin{align}
g^*_{x} = f_x - f_{y;x} + f_{x;y;x} - f_{y;x;y;x} + f_{x;y;x;y;x} - f_{y;x;y;x;y;x} + \dots  \nonumber \\
g^*_{y} = f_y - f_{x;y} + f_{y;x;y} - f_{x;y;x;y} + f_{y;x;y;x;y} - f_{x;y;x;y;x;y} + \dots  \nonumber 
\end{align}
So then we can caclulate this to be
\begin{align}
g^*_{x} &= (x + \rho x^2 - \rho \nonumber) - (\rho^2 x + \rho^3 x^2 + \rho(1-\rho^2) - \rho) + (\rho^2 x + \rho^5 x^2 + \rho^3(1-\rho^2) + \rho(1-\rho^2) - \rho \nonumber) - \dots \\
 &= [x] + [-\rho + \rho^3 - \rho^5 + \dots] + [\rho - \rho^3 + \rho^5 - \dots] x^2 \nonumber\\
 &= x + \frac{\rho}{1+\rho^2}[x^2-1]\nonumber\\
g^*_{y} &= (\rho y + \rho y^2 - \rho ) - (\rho y + \rho^3 y^2 + \rho(1-\rho^2) - \rho) + (\rho^3 y + \rho^5 y^2 + \rho^3(1-\rho^2) + \rho(1-\rho^2) - \rho \nonumber) - \dots \\
 &= 0 + [-\rho + \rho^3 - \rho^5 + \dots] + [\rho - \rho^3 + \rho^5 - \dots] y^2 \nonumber\\
 &= 0 + \frac{\rho}{1+\rho^2}[y^2-1]\nonumber
\end{align}

It may be checked that this solution agrees with that of directly solving Equation \ref{app_eqn:matrix_operator_eqn}:
\begin{align}
g^*_{x} = x + \frac{\rho}{1+\rho^2}[x^2-1]\nonumber
\quad
g^*_{y} = \frac{\rho}{1+\rho^2}[y^2-1]\nonumber
\end{align}

It should at the very least be cautioned that these operator manipulations, especially that of the inverse are done only in the formal sense.
For instance, considerations of $\rho=1$ are not able to demonstrate local convergence in the inversion; however, the formula still remains true in this case.
It is considered very likely that these matrix equations are, in most cases, easily able to be solved by the suggested formal manipulations but at least some caution should be exercised.
Nevertheless, these manipulations should hold true for a wide variety of distributions so long as the functions involved have finite variances in all dimensions.
It is at least seemingly sufficient to consider all possible distributions with finite moments and distribution defined by their moments, since this would enable an iterative approximation via Taylor series, and
it is conjectured this inversion will hold for an even wider set of distributions.



\section{Fast-SHAP and Faith-SHAP Details}

\subsection{Faith-SHAP Key Results}
\cite{tsai2023faithSHAP}'s equation (9) defines learning Shapley-inter-indices through the MSE formulation:
\[
\cE(f,\ell) =  \argmin_{ \{\cE_S\}_{|S|\leq \ell} }  \sum_{S\subseteq[d]} p(S) 
\bigg|f(S) - \sum_{T\subseteq S, |T|\leq\ell} \cE_T\bigg|^2
\]


\cite{tsai2023faithSHAP}'s equation (16) solves for the Shap-inter-indices from the perspective of the Mobius/purified functions:
\begin{align}
\cE(f,\ell)(S) = \Tilde{f}_S + (-1)^{\ell-|S|} \frac{|S|}{\ell + |S|} {\ell \choose |S|} \sum_{T\supset S, |T|\leq\ell} \frac{ {|T|-1 \choose \ell} }{ {|T|+\ell-1 \choose \ell+|S|} } \Tilde{f}_T
\label{app_eqn:faith_SHAP_mobius_form}
\end{align}
% \[
% \cE(f,\ell)(S) = (-1)^{0} \cdot \Tilde{f}_S +  \sum_{T\supset S, |T|\leq\ell} (-1)^{\ell-|S|} \frac{|S|}{\ell + |S|} {\ell \choose |S|} \frac{ {|T|-1 \choose \ell} }{ {|T|+\ell-1 \choose \ell+|S|} } \Tilde{f}_T
% \]
% Try working with these for a little bit, but nothing glaringly different or glaringly better

% \[
% \cE(f,\ell)(S) = (-1)^{0} \cdot \Tilde{f}_S +  \sum_{T\supset S, |T|\leq\ell} (-1)^{\ell-|S|} \frac{|S|}{\ell + |S|}\cdot\frac{T-\ell}{T}\cdot\frac{T+\ell}{T_S} {\ell \choose S} \frac{ {T \choose \ell} }{ {T+\ell \choose S+\ell} } \Tilde{f}_T
% \]
% \[
% \cE(f,\ell)(S) = (-1)^{0} \cdot \Tilde{f}_S +  \sum_{T\supset S, |T|\leq\ell} (-1)^{\ell-s} \frac{ {(t-1)\choose(t-s)}\cdot{(t-1-s)\choose(\ell-s)} }{ {(t-1+\ell)\choose(t-s)} } \Tilde{f}_T
% \]
% \[
% \cE(f,\ell)(S) = (-1)^{0} \cdot \Tilde{f}_S +  \sum_{T\supset S, |T|\leq\ell} (-1)^{\ell-s}\cdot{ t-1-s \choose \ell-s} \cdot \frac{ { t-1 \choose t-s } }{ { t-1+\ell \choose t-s} } \Tilde{f}_T
% \]
% \[
% \cE(f,\ell)(S) = (-1)^{0} \cdot \Tilde{f}_S +  \sum_{T\supset S, |T|\leq\ell} (-1)^{\ell-s}{ t-1-s \choose \ell-s} \cdot \frac{ { s-1 + \ell \choose \ell } }{ { t-1 + \ell \choose \ell} } \cdot\Tilde{f}_T
% \]


\subsection{Fast-SHAP Key Results}

The alternative formulation of the Shapley value used by \cite{jethani2022fastSHAP} is through the solution to a mean-squared error optimization:
\[
\argmin_{\circphi_0\in\bbR, \circphi\in\bbR^d} \bigg\{
% \big\bbE_{S\sim p(S)}\bigg[
\big\bbE_{S}\bigg[
\bigg| f(S) - \circphi_0 - \sum_{i=1}^d 1_{i\in S}\cdot \circphi_i \bigg|^2
\bigg]
\bigg\}
\]
So long as the expectation is taken with respect to the `Shapley kernel' distribution.
$p(S) \sim \frac{d-1}{{d \choose |S|}\cdot |S| \cdot (d-|S|)}$

This pointwise optimization has been translated into a functional optimization via the work of FastSHAP's Equation 4 \cite{jethani2022fastSHAP}:
\[
\argmin_{\circphi_0, \circphi(x)} \bigg\{
\big\bbE_{x,S}\bigg[
\bigg| f(x,S) - \circphi_0 - \sum_{i=1}^d 1_{i\in S}\cdot \circphi_i(x) \bigg|^2
\bigg]
\bigg\}
\]



\subsection{Purified Loss Equation}
% Connection to Additive Models and Further Discussion}

Within this work, we introduce the purfied loss equation
\begin{align}
\argmin_{\{\circphi_T(x)\}} \bigg\{
\big\bbE_{x,S}\bigg[
\bigg| F(x) - \sum_{T\in\cI} 1_{T \supseteq S}\cdot \circphi_T(x) \bigg|^2
\bigg]
\bigg\}
\end{align}
to define the InstaSHAP learned additive model.


It follows from our Section \ref{app_sec:novel_GAM_frontier_and_correlated} that we may face cases where the Sobol indices are Sobol covariances are insufficient to measure the marginal contributions of a particular feature interaction.

Regardless of this
it is relatively straightforward to see that if we identify our GAM model with the masked model as part of the purified loss training, then the Shapley values and indices can be automatically computed from the equations in \ref{app_eqn:faith_SHAP_mobius_form}.
It is moreover the case that this does not explicitly depend on the training distribution which is utilized in the purified loss training, which is unlike the FastSHAP training which uses arbitrarily complex auxiliaries, requiring the training only be done under the Shapley kernel.


% \jam{reproduce this here}

\subsection{Connection to Additive Models and Further Discussion}


Note that although Faith-SHAP define the frontier solution for any $\cS_{\leq\ell} = \{S : |S|\leq\ell\}$, 
given our notation of any $\cI\subseteq \cP([d])$, 
we can consider the alternative resolution to the problem through the MSE approach:
\[
\cE(f,\ell) =  \argmin_{ \{\cE_S\}_{S\in\cI} }  \sum_{S\subseteq[d]} p(S) 
\bigg|f(S) - \sum_{T\subseteq S, T\in\cI} \cE_T\bigg|^2
\]



































\end{document}


% This document was modified from the file originally made available by
% Pat Langley and Andrea Danyluk for ICML-2K. This version was created
% by Iain Murray in 2018, and modified by Alexandre Bouchard in
% 2019 and 2021 and by Csaba Szepesvari, Gang Niu and Sivan Sabato in 2022.
% Modified again in 2023 and 2024 by Sivan Sabato and Jonathan Scarlett.
% Previous contributors include Dan Roy, Lise Getoor and Tobias
% Scheffer, which was slightly modified from the 2010 version by
% Thorsten Joachims & Johannes Fuernkranz, slightly modified from the
% 2009 version by Kiri Wagstaff and Sam Roweis's 2008 version, which is
% slightly modified from Prasad Tadepalli's 2007 version which is a
% lightly changed version of the previous year's version by Andrew
% Moore, which was in turn edited from those of Kristian Kersting and
% Codrina Lauth. Alex Smola contributed to the algorithmic style files.
