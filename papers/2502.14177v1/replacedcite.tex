\section{Related Work}
% The Shapley value was first introduced more than half a century ago, originally in its application to equally distributing the wealth earned by a coalition amongst its constituent members.
% The SHAP value has repurposed the original Shapley value to distribute the prediction made by a blackbox algorithm amongst its contributing input features.
% With some original studies in ____, most work picked up after the algorithm introduced in 
% ____.
% % In this way, SHAP allows to explain any black-box model which can be converted into a masked prediction model,
% % obeying some very pleasant theoretical properties it inherits from the Shapley value.


% Its immediately obvious disadvantage is that of its computational complexity.
% Exact computation requires an exponential number of function evaluations and even approximations can take hundreds or thousands of repeated function calls.
% Consequently, an abundance of follow-up work has improved the computational complexity via
% better algorithms, architecture specific algorithms, or efficient sampling estimators ____.
% %better alg
% %arch specific algs
% %general good 

% \jam{terrible writing..., terrible structure}
% Another major consideration of SHAP which has come under scrutiny besides its computational complexity is its inability to adequately handle feature interactions.
% A groups of variables can be jointly important to a prediction, many works have tried to focus on extending Shapley values to additionally handle the study of feature interactions ____.
% In many cases, the extension of variable importance to variable group importance is believed to cover the shortcomings in existing applications of the Shapley value. 
% %%% In many cases, it is believed that such extensions can cover the shortcomings which may exist in certain applications of the Shapley value ____



% The generalized additive model (GAM) ____ has also existed for decades as a more expressive alternative to linear regression.
% Although some interest has remained over the years 
% ____,
% machine learning is often dominated by kernel machines, boosted models, and deep learning.
% % a lot of focus shifted towards other machine learning approaches.
% In recent years, however,
% there has been an explosion of additive models trained with neural network approaches
% as the appetite for interpretable models continues to grow in the deep learning era
% ____.

% Alongside the revived attention to additive models, some methods have shifted away from the classical approach of truncating after all 1D and 2D functions ____, instead opting for high-dimensional sparsity and/or higher-order functions ____ to provide competitive performance across a wide variety of datasets and tasks.
% Additional interest in feature interactions has also existed here trying to measure the importance of feature interactions within additive models ____

% Despite the parallel interest in focusing on feature interactions in both SHAP and GAM, much of these works have remain isolated from one another.
% A key exception of this rule is ____ which harps on the same connection between SHAP and GAM which we leverage herein.
% Their work, however, is limited to the case of independent features and does not enhance the training of additive models, especially in the case of correlated features. \jam{phrasing}
% Our work is also closely related to the work of Faith-SHAP ____, which recently made great strides in developing the study of Shapley interaction indices, and Fast-SHAP ____, which recently introduced a novel amortization approach to computing the Shapley value with auxiliary models.
% In comparison with Faith-SHAP, we extend their pointwise definitions of the Shapley indices to a functional which corresponds to the training of an additive model.
% In comparison with FastSHAP, we train explanatory models which are themselves the model of interest, as well as automatically handle interaction indices which the original work is unable to do.
% Moreover, while their auxiliary model is only an approximation of the original model's Shapley value, we train interpretable models which match or exceed the performance of deep neural networks, and hence give an exact Shapley value of the interpretable model.

% % \jam{despite this parallel interest in focusing on feature interactions in both SHAP and GAM, much of these works remain separate and isolated}


% % This connection to additive models has been briefly explored in the (vastly simpler) settings where input features are independent ____.
% % However, these works overlook many of the important hurdles in applying additive models into more typical machine learning pipelines with correlated input features and the associated challenges of learning Shapley values in these settings.

% % The most closely related work is FastSHAP ____
% % which also learns some type of additive model to accelerate explanations via the Shapley value.
% % The biggest key differences are (a) FastSHAP does not learn an interpretable model like InstaSHAP and hence provides only an approximation of the Shapley value; and (b) FastSHAP does not extend their results to feature interactions and the resulting Shapley interaction indices.
% %One could imagine that such an endeavor could be difficult



%