
\section{Findings}
\label{sec:findings}
\subsection{Self-awareness: Check-ins and MyTrends}
The MiWaves app was designed to encourage self-awareness among participants by providing tools for daily self-monitoring and visualizing trends. 
% These features were central to fostering a deeper understanding of individual cannabis use patterns, and the participant feedback affirmed their effectiveness. 
Overall, participants had a 77\% engagement rate with check-ins during the study.
A total of $N=34$ participants \emph{explicitly} mentioned that the app encouraged greater awareness of their behaviors, reflecting its impact as a behavior-change tool. It is important to note that \emph{participants were neither prompted nor asked explicitly} whether their self-awareness improved during the course of the study, or during the post-test survey after the study.

% For instance, P110 remarked, \emph{``i liked how it kept me accountable with cannabis use}'', while P35 shared \emph{``daily check-ins actually forced me to confront how much weed I was smoking, since I had to ``report'' it in the morning if I did. It definitely prompted me to cut down use''}. These responses emphasize the role of various MiWaves app features in promoting self-awareness.

\subsubsection{Self-monitoring check-ins}~\ A recurring theme in the feedback was the positive impact of the app's self-monitoring check-ins. Participants noted that these regular check-ins created a structured opportunity to think about their cannabis use and its broader implications. Specifically, $N=23$ participants highlighted the value of these check-ins in fostering self-awareness. Participant P35 expressed, \emph{``daily check-ins actually forced me to confront how much weed I was smoking, since I had to ``report'' it in the morning if I did. It definitely prompted me to cut down use.''} Similarly, P51 remarked,  \emph{``doing the check in’s made me more aware of my cannabis use, i had to recognize that i really do smoke every day and maybe it has an impact on me''}. These structured prompts served as a consistent mechanism to prompt participants to evaluate their behavior. Other participants emphasized how the check-ins fostered awareness and intentionality. For example, P72 shared, \emph{``I feel like the check-ins brought a lot of awareness to my daily habits,''} while P98 noted, \emph{``It was a daily reminder to be more intentional about my actions.''} These responses affirm that self-monitoring effectively encouraged some participants to be self-aware on their behaviors and make conscious decisions about their cannabis use.
% Several participants also appreciated the ease and accessibility of the surveys. For example, P125 shared, \emph{``I liked the phrasing and choices for the questions''}, while P116 noted, \emph{``how quick the surveys were.''} These responses indicate that the app made the process of reflection accessible and manageable for participants, to help with sustained engagement.

% Several participants appreciated how the surveys helped them explore the reasons behind their cannabis use. For example, P125 shared, \emph{``I liked the phrasing and choices for the questions,''} while P116 noted the convenience of the surveys, saying, \emph{``How quick the surveys were.''} These responses indicate that the app made the process of reflection accessible and manageable for participants, ensuring sustained engagement.

\subsubsection{My Trends}~\ The trends visualization feature was another key tool for fostering self-awareness, with $N=27$ participants specifically mentioning its impact. By providing a longitudinal view of cannabis use, sleep, and stress levels, this feature may have enabled participants to recognize patterns and associations. P127 remarked that the visualization provided them \emph{``the ability to track trends over an extended period''}. Meanwhile, P130 shared \emph{``I like that we are able to track the trends of how long we used substances throughout the weeks''.} Other participants highlighted how the trends were especially impactful,
% when combined with a clear sense of personal accountability, 
and helped them reflect on their progress. For example, P72 noted, \emph{``seeing the graphs was super cool \ldots seeing my bars for sleep lower than my bars for cannabis use definitely was eye opening''} while P8 explained, \emph{``the graphs were the most helpful thing to me because it showed the patterns in my usage.''} 
% P69 shared, \emph{``Reflecting on my substance use trends helped me see where I needed to improve,''} while P82 explained, \emph{``Tracking progress via graphs made me see where I was improving and where I needed to focus more.''} 
These responses highlight how trends visualization served as a powerful tool for fostering self-awareness, helping some participants better understand their behaviors and track progress over time.

% \sg{Talk about people finding trends + regular checkins to help with self-awareness}

\subsection{Burden}
User burden is a critical factor in the success of digital health interventions. High levels of burden, whether due to time-consuming tasks, rigid structures, or discomfort with sensitive questions, can lead to participant disengagement and negatively impact the effectiveness of an intervention. 
% Therefore, it is essential for interventions like MiWaves to strike a balance between collecting meaningful data and maintaining a user-friendly, low-burden experience.
% Figure \ref{fig:checkin} illustrates how 
MiWaves sought to achieve a balance between collecting meaningful data and maintaining a user-friendly, low-burden experience by designing check-ins and messages that participants would find both manageable and comfortable. 
% \begin{figure}[t]
%     \centering
%     \includegraphics[width=\linewidth]{figures/checkin.png}
%     \caption{Responses to checkin related questions, which asked the participant about how easy and time-consuming the self-monitoring questions (or checkins) were, and how comfortable were participants answering personal questions (eg: about their cannabis use, sleep patterns etc.)}
%     \label{fig:checkin}
%     \Description{Responses to checkin related questions, which asked the participant about how easy and time-consuming the self-monitoring questions (or checkins) were, and how comfortable were participants answering personal questions (eg: about their cannabis use, sleep patterns etc.)}
% \end{figure}
\subsubsection{Self-monitoring check-ins}~\ A significant majority of participants ($N=102$) reported that completing the check-ins twice daily was doable, underscoring the app’s accessibility. Similarly, the majority ($N=103$) agreed that the check-ins could be completed in a reasonable amount of time, reflecting the efficiency and quickness of the check-ins. Furthermore, participants ($N=102$) agreed that they felt comfortable answering personal questions, highlighting the development team’s thoughtful approach to handling sensitive topics like substance use.

The open-ended feedback aligned closely with the quantitative findings. For example, P116 shared, \emph{``how quick the surveys were,''} emphasizing the efficiency of the check-ins. P135 echoed this, stating, \emph{``quick check-ins \ldots made it easy to continually use the app''}, while P86 also noting \emph{``I appreciated how quickly I was able to answer\ldots''}.
Some participants also appreciated the flexibility built into the app’s design. For instance, P91 noted \emph{``I appreciate being given the grace of being able to do a check in a little late.''}, which referenced the 1-hour grace period the app provided participants when they initially missed a self-monitoring check-in. 
These features may have helped reduce the cognitive and time burden on users, facilitating fairly seamless integration of the app into daily routines.

% \sg{Talk about user burden, how easy the surveys were, how little time they took. For the CHI submission, add the time taken actually using their app use}
% \sg{Then support with qualitative responses on checkin}

% \subsection{Context features and privacy}
% \begin{figure}[t]
%     \centering
%     \includegraphics[width=\linewidth]{figures/comfort.png}
%     \caption{Responses to participant's privacy outlook - i.e. questions asking how comfortable they were with an app collecting data about their location, social media messages, text messages, moving speed, physical activity and sleep.}
%     \label{fig:privacy}
%     \Description{Responses to participant's privacy outlook - i.e. questions asking how comfortable they were with an app collecting data about their location, social media messages, text messages, moving speed, physical activity and sleep. Participants were relatively more comfortable with an app tracking their physical activity and sleep, as compared to their location, text messages, social media messages and their moving speed.}
% \end{figure}

% Digital interventions often leverage contextual data, such as location, physical activity, and sleep patterns, to enhance personalization through adaptive algorithms \cite{thomas2021systematic}. These algorithms rely on real-time data to deliver interventions tailored to users' behaviors, routines, and environments, making the experience more relevant and effective. However, integrating such data collection in apps like MiWaves must also address participants' privacy concerns and comfort levels to maintain trust and engagement. To inform future iterations of MiWaves, participants were asked about their comfort with an app collecting data across various contextual variables.

% Figure \ref{fig:privacy} presents participants' responses to questions about their comfort levels with the collection of six specific types of data - namely location tracking, text messages, social media messages, movement speed (which could include traveling in vehicles), physical activity (e.g. step count, heart rate etc.) and sleep. Participants were asked to rate their comfort level (1 to 10) with 1 being not comfortable at all, and 10 being very comfortable. The findings reveal a nuanced outlook -- the majority of participants expressed discomfort with the collection of location data (mean = 3.46, SD = 1.05), text messages (mean = 2.81, SD = 1.16), and social media messages (mean = 2.49, SD = 1.24). This highlights a significant privacy concern around these sensitive forms of contextual data, indicating their use may not align with participants’ preferences in future iterations of MiWaves. Conversely, participants reported higher comfort levels with the collection of physical activity data (mean = 6.70, SD = 0.93) and sleep data (mean = 6.33, SD = 0.89). These findings suggest that participants were more open to sharing physiological or behavioral data compared to communication or location data.

% Interestingly, comfort levels for collecting data about speed of movement were more evenly distributed, with participants showing mixed reactions.

% \sg{Talk about future trials using a more complex context for personalization. Hence we asked participants about their outlook on which features they'd be more comfortable with }

% \subsection{Expiring notifications and user experience}
% The MiWaves intervention was designed with the intention that self-monitoring check-ins and MiWaves message notifications would expire after a set period. This decision was primarily made to clearly delineate time boundaries for post-study effect analysis, allowing researchers to more accurately understand the impact of each intervention. However, this design choice led to dissatisfaction among some participants who felt constrained by the expiration feature, especially when they missed opportunities to self-monitor or engage with messages.

% $N=8$ participants explicitly remarked on the frustrations caused by expired check-ins or limited response windows. For instance, P102 stated, \emph{``that check ins expired too fast so i didn’t get to fill them out even though i could’ve and i wanted to''}, emphasizing the rigidity of the design. Similarly, P40 noted, \emph{``Missing the time slot to do the checkin resulted in no data for that half of a day\ldots wish there was a way to still go in and enter the data''}. Another participant, P62, expressed, \emph{``if u missed a checkin you couldn't correct your data''} reflecting broader dissatisfaction with the inability to make amendments. Suggestions for addressing this issue were also provided by participants. P102 proposed, \emph{``Longer check-in periods that don’t expire,''} while P71 suggested, \emph{``A longer gap in time to answer, 3 or 4 hours.''} Additional participants, such as P78 and P79, echoed similar sentiments, requesting \emph{``longer check-in windows''} and \emph{``longer periods that you could check in for.''} These responses indicate a clear preference for increased flexibility in response times, which could help reduce participant frustration and improve overall satisfaction.

% While the expiration feature served an essential purpose for study analysis, participant feedback underscores the importance of balancing research goals with user experience. For future iterations of MiWaves, one could consider allowing participants to complete expired check-ins. To maintain the rigor of effect analysis, such retroactive entries could be excluded from decision-making algorithms and flagged separately during data analysis.

% Design criterias which are in contention with each other
% Didn’t give them correct feedback (given people feedback)

% \subsection{MiWaves Messages}
% \begin{figure}[t]
%     \centering
%     \includegraphics[width=\linewidth]{figures/effort.png}
%     \caption{Responses to participant's perception of MiWaves (intervention) message burden -- specifically with respect to the different types of interaction level in messages, including reading messages, visiting links and typing in responses.}
%     \label{fig:message_effort}
%     \Description{Responses to participant's perception of MiWaves (intervention) message burden -- specifically with respect to the different types of interaction level in messages, including reading messages, visiting links and typing in responses. The graph highlights the varying levels of effort participants associated with each (interaction) type of message, with reading messages perceived as the least effortful by the majority and exploring links or typing in responses requiring slightly more effort.}
% \end{figure}
% \sg{Talk about effort put into different types of messages}
% \subsubsection{Burden}~\ 

\subsubsection{MiWaves Messages}
The MiWaves app included various types of intervention messages that required participants to engage through reading, exploring links, or typing in responses
% as described in Section \ref{sec:miwaves_app}
% and 
(refer Table \ref{tab:intervention_prompts}). 
% Figure \ref{fig:message_effort} highlights participants' perceptions of the effort required for these tasks. 
Participants were asked about their perceived effort in completing such tasks on a scale of 1 (least effort) to 10 (most effort). Their response suggests that while tasks like reading and acknowledging messages were perceived as manageable (mean=3.79, SD=1.00), tasks such as typing-in responses (mean=4.69, SD=0.89) or exploring links (mean=5.17, SD=0.86), posed more of a burden. Going forward, carefully balancing these effortful messages with low-effort messages of encouragement may reduce barriers to consistent participant message engagement.
% \sg{Compliment with app views for messages}.

\subsection{Personalization: MiWaves Message}
\subsubsection{Frequency and Timing}: MiWaves utilized reBandit, a reinforcement learning (RL) algorithm, to personalize the likelihood of intervention message delivery (as described in Section \ref{sec:miwaves_app}). By learning from participant behaviors and preferences, reBandit optimized message timing to maximize engagement.
% The system contributed to a 77\% engagement rate with the check-ins during the study. 

Participants' perceptions of message timing and frequency were largely positive. When asked to evaluate the number of messages received on a scale of 1 (fewer messages) to 3 (too many messages), the mean response was 1.95 (SD = 0.13), indicating that on average participants felt the frequency was appropriate and balanced. Similarly, when evaluating the convenience of message timing on a scale of 1 (not convenient) to 3 (convenient), the mean response was 2.24 (SD = 0.14). 
% This finding suggests that participants generally perceived the messages as arriving at convenient times.
% , though with some variability.

Overall, 72\% of participants ($N=81$) reported no instances where they wanted a message but did not receive one, and 73\% ($N=82$) indicated they did not experience messages arriving at inconvenient times. When the remaining participants were asked to describe such instances, 
% some expressed frustration when messages were not sent. For instance, 
P44 noted, \emph{``I usually expected to receive a message after completing a survey, especially if it had been a while since my last message''} and P8 shared, \emph{``Sometimes, even when the day is going great, it's nice to have a small little note of encouragement to keep my mood up''}. These comments highlight that some participants would have preferred more consistency in the frequency of messages. However, research has often shown that frequent interventions and prompts (like the suggestions made by some participants) are detrimental to the success of digital interventions, as participants become at-risk of habituation and disengagement \cite{alkhaldi2016effectiveness}. Other participants described that the messages could arrive at inconvenient times. For example, P11 stated, \emph{``Depending on work schedule, they would come during times when I was busy and could not look at the notifications in a timely manner''} and P42 mentioned, \emph{``Sometimes I would be in a meeting or in class and could not fully focus on the message!''} These responses suggest opportunities to refine the algorithm to account for individual schedules and availability.

\subsubsection{Message Content}
While MiWaves leveraged an RL algorithm to personalize the timing of intervention messages, the content of these messages was not personalized -- reflecting the pilot nature of the study. Participant feedback revealed varied opinions about the message content. Some participants praised the messages for being helpful and encouraging. For example, \emph{``I liked the messages that encouraged thoughtfulness,''} noted P105, while 
% P117 shared, \emph{``They were positive and tried to be helpful''}. 
% Similarly, P122 mentioned, \emph{``I liked the positive nature of them,''} and 
P13 appreciated specific advice, stating, \emph{``I liked some of the advice. The one about stress management really helped me when I was extremely stressed at work''}. Others liked the overall approach, with P48 stating, \emph{``I really liked the messages and links provided\ldots''} and P65 remarking, \emph{``The messages \ldots gave me helpful reminders when I wasn’t expecting it so it felt more real''}.

Conversely, some participants also expressed limitations in the relevance of messages.
% and message length. 
P105 stated, \emph{``Sometimes messages seemed random and not particularly helpful.''} 
% and P100 remarked, \emph{``the messages \ldots seemed unrelated''}. 
and P11 shared, \emph{``some of the messages would be unrelated to my use (ex. I don’t drink often)''}. 
% Additionally P45 stated, \emph{``The messages were tacky to be honest\ldots didn't get much at all out of them. Felt like you googled motivational phrases and just stuck em in your project''}. 
% Additionally, P118 noted, \emph{``I wish that the messages were longer and more in depth at times''}. 
Some participants also had additional negative opinions. For instance, P111 stated, \emph{``Some made me feel guilty for my habits and I really did not enjoy that''}, while 
% P101 shared that \emph{``I also thought the focus on reducing cannabis use in the messages rather than just promoting awareness of one's usage often came across as condescending''}.
P101 shared that \emph{``promoting awareness of one's usage often came across as condescending''}.

The feedback underscores the importance of tailoring message content to individual needs and contexts in future iterations of MiWaves. Personalizing content within the framework of Just-In-Time Adaptive Interventions (JITAIs) is critical to delivering messages that are not only well-timed but also meaningful and actionable for participants. Importantly, content personalization in JITAIs remains an active area of research, with ongoing efforts focused on integrating behavioral data, emotional states, and preferences to optimize intervention impact. By leveraging these advancements, future iterations of MiWaves can enhance user engagement and support long-term behavior change.

% By adopting advancements in this area, future iterations of MiWaves can enhance engagement and intervention effectiveness, by ensuring messages resonate deeply with users while supporting long-term behavior change.
