\section{Limitations}
%We evaluate the rewriting effect of each method along two dimensions: translatability and meaning preservation. Scores for each dimension are computed using a neural machine translation metric, \textsc{xCOMET}. To provide additional insights, we could diversify the evaluation metrics by including measures such as Levenshtein edit distance \citep{Levenshtein1965BinaryCC} or semantic similarity between the original source and rewrites.

%Our fine-tuning dataset ($\mathcal{D}_{pos}$) is automatically constructed based on the translatability scores. Although this is a cost-effective approach for building datasets, it remains to be seen how our findings generalize when using human preferences \citep{ouyang2022training} or a combination of multiple preferences (e.g., fluency, detail and meaning preservation) as a form of multi-objective optimization. Despite these limitations, our datasets can still align LLMs to generate rewrites that are easier to translate than the original source sentences.

%Lastly,
We focus our investigation on \textsc{Tower-Instruct 7B} as our MT system, as it is an open-weight model. We exclude closed and larger models such as \textsc{GPT-4}\footnote{\url{https://openai.com/index/gpt-4/}} in the current experiments.

The scope of our study is also limited to out-of-English language pairs, as rewriting with LLMs has been more extensively studied in English \citep{ma-etal-2023-query, ye-etal-2023-enhancing, shu2023rewritelm, mao2024rafe}, and using English as the source language benefits performance from its prevalence in LLM training data. One critical area of future research lies in developing rewriting tools that support a wider range of languages beyond English. 

%  Existing tools are often biased toward high-resource languages, making it difficult to generalize translation improvements to other language pairs, especially those involving low-resource languages. By expanding the availability of rewriting tools and methodologies that cater to broader languages, researchers can ensure that the benefits of MT advancements are distributed more equitably.

% Even within current tools, there are inherent biases that tend to favor expressions and conventions common in the United States, particularly for English-centric language models. For example, when rewriting the sentence ``\textit{Resuming her patrols, Constitution managed to recapture the American sloop Neutrality on 27 March and, a few days later, the French ship Carteret.}'' using the easy translate rewriting method, \textsc{LLaMA-2} rewrites ``\textit{on 27 March}'' to ``\textit{on March 27th},'' following the American date format. Further, \textsc{LLaMA-3} adds unnecessary explication by changing ``\textit{Constitution}'' to ``\textit{USS Constitution},'' which is a name of an American ship. While these rewrites may improve the overall MT quality, they also introduce a subtle standardization toward American expressions and cultural references. Such biases not only risk distorting the linguistic characteristics of the target language but also potentially erase its cultural nuances, making the translated content less relatable to non-American audiences. This emphasizes the importance of developing translation and rewriting systems that can preserve the linguistic and cultural identity of the source language.