\section{Introduction}

\input{figures/main_figure}

Machine translation (MT) users and developers have long exploited the idea that some texts are easier to translate than others. For instance, guiding people to edit their inputs so that they are well formed is a cornerstone of MT literacy courses \citep{bowker-2021-promoting,steigerwald-etal-2022-overcoming}, and adopting plain language has been shown to improve the readability of translated health content \citep{Rossetti2019}. In MT research, a wealth of studies have considered pre-processing strategies to rewrite inputs, particularly for statistical MT \citep{XiaMcCord2004,callison-burch-etal-2006-improved,stajner-popovic-2016-text}.%TODO: expand cites at camera-ready or in related work section

%In MT research, a wealth of studies have considered pre-processing strategies to rewrite inputs, particularly to improve statistical MT via input paraphrasing \citep{callison-burch-etal-2006-improved, mirkin-etal-2009-source, marton-etal-2009-improved, aziz-etal-2010-learning}, reordering \citep{XiaMcCord2004,WangCollinsKoehn2007}, or simplification \citep{stajner-popovic-2016-text,stajner-popovic-2019-automated} or to design systems that help users pre-edit their inputs \citep{mirkin-etal-2013-sort,Miyata2017DissectingHP}. 

The growing use of Large Language Models (LLMs) for translation leads us to revisit the impact of rewriting inputs on MT. On the one hand, rewriting inputs for LLM translation aligns with the re-framing of MT as a multi-step process \citep{Briakou}. LLMs have shown promise in rewriting MT outputs \citep{ki2024guiding, zeng2024improving, xu2024llmrefine}, and can rewrite text according to various style specifications \citep{raheja-etal-2023-coedit, hallinan2023steer, shu2023rewritelm, dipper}. On the other hand, current models might already be robust to input variability, since they are trained on vast amounts of heterogeneous data \citep{touvron2023llama}, fine-tuned on diverse tasks \citep{raffel-etal-2020-exploring,alves2024tower} and operate at a much higher quality level compared to the statistical MT systems used in previous pre-processing studies.%todo later: add cite for this.

How should inputs be rewritten for MT? The assumption that well-written texts are easier to translate drives recommendations for MT literacy, as well as the use of paraphrasing \citep{callison-burch-etal-2006-improved, mirkin-etal-2009-source, marton-etal-2009-improved, aziz-etal-2010-learning} and simplification  \citep{stajner-popovic-2016-text,stajner-popovic-2019-automated}. However, can we more directly rewrite inputs so that they are easier to translate? Generic translatability has been defined as “a measurement of the time and effort
it takes to translate a text” \citep{kumhyr-etal-1994-internationalization}. \citet{uchimoto-etal-2005-automatic} introduced a metric to quantify MT translatability based on back-translation of MT hypotheses in the source language. Given recent progress in quality estimation \citep{fernandes-etal-2023-devil, naskar-etal-2023-quality, tomani2024qualityaware}, we propose instead to use reference-free quality estimation scores as a measure of translatability.

We thus ask the following research questions:
\begin{enumerate}[label=(\arabic*),topsep=0pt,itemsep=-1ex,partopsep=-1ex,parsep=1ex]
    \item Can we improve MT quality from LLMs by rewriting inputs for style?
    \item Do quality estimation metrics provide useful translatability signals for input rewriting?
\end{enumerate}

% We conduct an empirical study of the \textsc{Tower-Instruct} LLM \citep{alves2024tower} for a total of 21 input rewriting methods with varying levels of MT-awareness on translation from English into German, Russian and Chinese, and we further evaluate the generalizability of our best performing approach on translation from English into Czech, Hebrew and Japanese. 
We conduct an empirical study with 3 open-weight LLMs for a total of 21 input rewriting methods with varying levels of MT-awareness on translation from English into German, Russian and Chinese, and we further evaluate the generalizability of our best performing approach on translation from English into Czech, Hebrew and Japanese (\S \ref{sec:newlanguages}). 
Our results show that simple \textbf{MT-Agnostic rewrites} obtained by prompting LLMs to simplify, paraphrase, or change the style of the input, improve translatability, and that simplification most reliably improves translation quality. Interestingly, these MT-agnostic rewrites are more effective than \textbf{Task-Aware rewrites}, where LLMs are prompted to rewrite inputs for the purpose of MT (\S \ref{simplification best}). Finally, using quality estimation signals to assess \textbf{translatability} at the segment level and select when to use rewrites further improves MT quality, outperforming more expensive fine-tuning strategies (\S \ref{input selection}). Human evaluation further confirms that simplified rewrites and their MT largely preserve the original meaning of the source and MT (\S \ref{human evaluation}).

% \mc{X New Tasks}

%We conduct an empirical study of the Tower LLM \citep{alves2024tower} for a total of 21 input rewriting methods with varying levels of MT-awareness on translation from English into German, Russian and Chinese. We further show that the benefits of our best performing approach generalize to new test sets from the WMT23 general translation task for X language pairs.

%To address these questions, we first generate \textbf{MT-Agnostic rewrites} by prompting LLMs to simplify, paraphrase or change the style of the original input (\S \ref{3.1 mt-agnostic}). 

%Next, we design three strategies to obtain \textbf{MT-Aware rewrites}: using Chain-of-Thought \citep{wei2023chainofthought} prompting, selecting generic rewrites with reference-free quality estimation metrics \citep{guerreiro2023xcomet}, and fine-tuning LLMs to rewrite for translation (\S \ref{3.2 task-aware}).
%
%We conduct an empirical study of the Tower LLM \citep{alves2024tower} for a total of 21 input rewriting methods with varying levels of MT-awareness on translation from English into German, Russian and Chinese. Our findings suggest that rewriting inputs can improve translation quality (\S \ref{res:mt agnostic}) and that quality estimation feedback helps generate inputs that are better translated (\S \ref{res:mt aware}), even outperforming post-editing translation outputs (\S \ref{res:post-editing}).
