The scalability problem has been widely investigated in current literatures. Ref. **Singh, "Multi-Faceted Reinforcement Learning"** propose the framework of MFRL that increases scalability by reducing the action-state space. Several works in a related area named mean-field game also proves that using a compact representation to characterize population information helps solve scalability problem **Laraki, "Mean Field Games and Application to Economic Modeling"**.


Several works were proposed to improve MFQ. Ref. **Busoniu, "TD Learning in MFRL"** proposed a weighted mean-field assigning different weights to neighbor actions according to the correlations of the hand-craft agent attribute set, which is difficult to generalize to different environments. Ref. **Deisenroth, "Weighted Mean Field MfQ"** calculate the weights with attention score. The observations of other agents are needed to calculate the attention scores, making its practicality not satisfactory.


Our work is also closely related to recent development in causal inference. Researches indicate that once the SCM, which implicitly contains the causal relationships between variables, is constructed, we can obtain the causal effect by intervening. The causal inference has already been exploited for communication pruning **Zhang, "Causal Inference and Communication Pruning"**, solving credit assignment problem **Sankararaman, "Credit Assignment with Causal Inference"**, demonstrating the potential of causal inference in reinforcement learning **Mansinghka, "Causal Inference for Reinforcement Learning"**. Ref. **Pearl, "Causal Models and Interventions"** and **Shpitser, "Direct and Indirect Causation"** further proved that SCM could be equally replaced with NCM under certain constraints, enabling us to ask ``what if" by directly intervening on neural network.



\begin{figure}
\setlength{\abovedisplayskip}{1.5pt}
\setlength{\belowdisplayskip}{3pt}
    \centering
    \subfigure[]{
        \label{fig:frame}
        \includegraphics[width=0.4\textwidth]{imgs/framework.pdf}}
    \hspace{0.15in}
    \subfigure[]{
        \label{fig:}
        \includegraphics[width=0.3\textwidth]{imgs/causal_module.pdf}}
    \caption{(a) is CMFQ's architecture. Each neighborhood agent is assigned a weight according to its causal effect to the policy of the central agent. (b) is the causal module. It calculate the $KL$ divergence between the two policies that the merged agent is represented by the average action and the $k^{th}$ neighborhood agent action respectively. A large $KL$ divergence means the $k^{th}$ neighborhood agent might be ignored in the merged agent represented by the average action, hence it should be assigned a higher weight to form a better merged agent.}
    \label{fig:frame&causal_module}
\end{figure}