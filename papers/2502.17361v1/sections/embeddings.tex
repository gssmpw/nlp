\section{\ours as a Feature Encoder}
To better understand \ours, we examine whether its in-context learning capability also produces separable and meaningful feature representations.

\subsection{Challenges in Embedding Extraction}
As described in~\autoref{sec:relimiary}, the output tokens from the multiple transformer layers in \ours correspond one-to-one with the input tokens, forming a tensor of size $(N+1) \times (d+1) \times k$. The final token, corresponding to the (dummy) label embedding $\tilde{\vy}^*$ of the test instance, is passed through an MLP block to produce the output. An intuitive idea is to treat the output tokens associated with the training label embeddings $\{\vy_i\}_{i=1}^N$—prior to the MLP block—as the extracted embeddings for the training data.

However, this straightforward method has one fundamental limitation due to the distinct roles of labeled training and unlabeled test data in \ours's in-context learning process. Specifically, the label embeddings for the training instances are derived from their true labels, while those for the test instances rely on dummy labels. This discrepancy results in output embeddings that are inherently {\em non-comparable} between the training and test instances. 

\subsection{Leave-one-fold-out Feature Extraction}
To address this challenge, we propose a leave-one-fold-out strategy that enables the extraction of comparable embeddings for training and test data. Within the \ours framework, we define the support set $\gS$ as the examples with true labels and the query set $\gQ$ as the examples with dummy labels. Under the standard configuration, $\gS$ corresponds to the labeled training set, while $\gQ$ corresponds to the unlabeled test instances.

A key trade-off arises: $\gS$ needs to include as much labeled data as possible to propagate knowledge from $\gS$ to $\gQ$ effectively in the in-context learning process. However, to ensure that embeddings for training and test instances are comparable, training instances must also be included in $\gQ$ and paired with dummy label embeddings.

To reconcile these requirements, we split the training set into multiple folds (\eg, 10 folds). One fold is used as $\gQ$ for embedding extraction, while the remaining folds constitute $\gS$ with true training labels. This ensures that $\gS$ retains sufficient label information while allowing embeddings to be extracted for the training data in $\gQ$. An extreme version of this strategy operates in a leave-one-out fashion, with only one training instance placed in $\gQ$ at a time.

Results in~\autoref{fig:our_extraction}~(c)-(f) demonstrate that embeddings extracted using this strategy (with 10 folds) more effectively reveal dataset properties. We observe that \ours simplifies tabular data distributions and transforms datasets into nearly separable embedding spaces, particularly in the embeddings after intermediate transformer layers.
\begin{table}[t]
\vspace{-3mm}
\caption{Average rank (lower is better) of \ours and a linear classifier trained on the extracted embeddings across 29 classification datasets.  ``Combined'' refers to an approach where embeddings from up to three layers (from the 12 available layers) are selected based on the validation set performance and concatenated.
}
\small
\label{tab:linear_probing}
\tabcolsep 1.5pt
\begin{tabular}{ccccccc}
\addlinespace
\toprule
$\downarrow$ & \ours &Vanilla & Layer 6 & Layer 9 & Layer 12 & Combined \\     
\midrule
Rank & 3.12 & 3.43& 5.03 & 4.72 & 2.45 & \textbf{2.24} \\
\bottomrule
\end{tabular}
\vspace{-3mm}
\end{table}

\subsection{Validation of Embedding Quality}
To validate the quality of the extracted embeddings, we train a logistic regression on top of the extracted embeddings. Specifically, the classifier is trained on embeddings derived from the training set and evaluated on test set embeddings. The average rank across 29 classification datasets from the tiny benchmark2 in~\citet{Ye2024Closer} is reported in~\autoref{tab:linear_probing}.

Remarkably, training a linear classifier on these extracted embeddings yields performance comparable to \ours's in-context learner. Embeddings from intermediate layers (or their selected concatenations) sometimes achieve even better results. These findings highlight \ours's potential as a robust feature encoder, offering valuable insights into its architecture and paving the way for broader applications in tabular data analysis and representation learning.