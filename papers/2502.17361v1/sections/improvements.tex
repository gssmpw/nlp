\section{Extensions of \ours}\label{sec:extension}
We aim to expand \ours's applicability beyond the boundaries outlined in~\citet{hollmann2025TabPFNv2}, which restricts its use to datasets with no more than 10,000 samples, 500 dimensions, and 10 classes. To address these limitations without requiring extensive retraining, we propose post-hoc divide-and-conquer strategies inspired by Chain-of-Thought (CoT) prompting in large-language models~\cite{Wei2022CoT}. We reformulate challenging tasks into multiple simpler subtasks that \ours can effectively handle.

\begin{figure}[t]
    \centering
       %  \vspace{-2mm}
    \includegraphics[width=\linewidth]{files/high-dimensional/mean_acc.pdf}
        \vspace{-8mm}
    \caption{Mean accuracy on 18 high-dimensional datasets. ``$*$'' denote our extension of \ours, and ``-PCA'' is another variant using PCA to reduce dimensions.}
    \vspace{-5mm}
    \label{fig:high_dimension}
\end{figure}

\subsection{High Dimension Datasets}
High-dimensional datasets~\cite{Jiang2024ProtoGate} present a unique challenge due to the quadratic complexity of \ours with respect to the number of dimensions. To mitigate this, we propose subsampling the feature space into smaller subsets, processing each subset independently, and combining the predictions in an ensemble (bagging) fashion, similar to random forests~\cite{Breiman01RandomForest}.

In detail, we iteratively sample $m$ subsets (we set $m=4$ in experiments), each containing $d' < d$ randomly selected attributes. For each subset, we leverage the \ours's ability to handle lower-dimensional data to obtain predictions. The final result aggregates these outputs using averaging (for regression) or majority voting (for classification).


\autoref{fig:high_dimension} summarizes the results 18 high-dimensional \emph{classification} datasets.  TabPFN v2$^*$ with the proposed divide-and-conquer and then ensemble strategy significantly increases the mean accuracy (the second-highest)
against the vanilla \ours, effectively  extending \ours's scalability to datasets with $d \ge 2000$. 
Another variant that utilizes PCA to reduce the dimensionality together with bagging also resolves the dimensionality issue to some extent.


\begin{figure}[t]
    \centering
    \includegraphics[width=\linewidth]{files/multi-class/mean_acc_multi.pdf}
        \vspace{-8mm}
    \caption{Mean accuracy on 12 datasets with more than 10 classes. ``PFNv2$^*$'' denotes our extension, while ``PFNv2-ECOC'' denotes the multi-class ECOC strategy implemented by~\citet{hollmann2025TabPFNv2} in their February 2025 code update. 
    }
    \vspace{-2mm}
    \label{fig:many-classes}
\end{figure}
\subsection{Multi-Class Problems with More Than 10 Classes}
To extend \ours to tasks with more than 10 categories, we propose a decimal encoding approach that decomposes multi-class problems into multiple 10-class subproblems, ensuring compatibility with \ours's constraints.

For a task with $C > 10$ classes, we encode each label $y \in [C]$ as a $t$-digit decimal representation, where $t = \lceil \log_{10} C \rceil$. For each digit position $j \in \{1, \ldots, t\}$, we train a separate \ours model $f_j$ to predict the $j$-th digit.
For example, in a 15-class problem, we decompose it into two subtasks: the first predicts the tens digit (with classes ${0,1}$), while the second predicts the ones digit (with classes ${0, \dots, 9}$). During inference, the predicted digits are reconstructed to obtain the final class label. To improve robustness, we permute the class order $\sqrt{C}$ times, leveraging the efficiency of \ours to predict across all permutations. The final prediction is obtained by ensembling these results.
As shown in~\autoref{fig:many-classes}, this approach achieves the second-best mean accuracy on 12 datasets with more than 10 classes while preserving computational efficiency.

\begin{figure}
    \centering
    % \vspace{-2mm}
    \includegraphics[width=\linewidth]{files/large_scale/average_rank_large1.pdf}
        \vspace{-8mm}
    \caption{Average rank on 18 large-scale datasets. ``*'' indicates our extension. ``-B'' refers to the variant that randomly subsamples 10,000 training examples four times and aggregates their predictions. ``-K'' denotes the variant that selects a representative subset of 10,000 training examples based on proximity to prototypes obtained via KMeans.
    All variants improve \ours.}
    % \vspace{-7.5mm}
    \label{fig:large_scale}
\end{figure}
\subsection{Large-Scale Datasets}
For large-scale datasets, we randomly sample 10,000 training examples from the full training set as the support set and treat the remaining training examples and test instances as the query set. We extract their embeddings to form a new tabular dataset, on which a logistic regression classifier is trained to make predictions on the test set embeddings. This process is repeated four times, and the final predictions are aggregated, denoted as TabPFN v2$^*$-SQ.

We also investigate integrating \ours with decision trees to handle large-scale tasks. Specifically, we first train a shallow decision tree, setting its maximum depth to 5 layers for datasets with fewer than 100,000 samples, and to 10 layers for larger datasets. The decision tree partitions the training set into smaller, more manageable subsets. Then, we apply \ours to each leaf node, treating the examples in each node as a separate training set for \ours. During inference, a test instance is first passed through the shallow decision tree to a leaf node and then predicted by the corresponding \ours model. We denote this extension as TabPFN v2$^*$-DT. 
We note that a similar strategy was mentioned in~\citet{hollmann2025TabPFNv2} but for a drastically difference purpose. Specifically, \citet{hollmann2025TabPFNv2} use decision trees to handle within-dataset heterogeneous for some highly challenging tabular datasets, while we use decision trees for scalability.

\autoref{fig:large_scale} shows the average rank results, including TabPFN v2$^*$-SQ and TabPFN v2$^*$-DT alongside variants using bagging and KMeans-based sampling. We observe that all variants improve upon the vanilla \ours on large-scale datasets, with TabPFN v2$^*$-DT and TabPFN v2$^*$-SQ achieving the most significant improvement.