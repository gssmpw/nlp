\section{Related Works}

\subsection{Data Analysis and Visualisation Tools}

Data analysis and visualization tools have seen significant advancements in recent years. Earlier tools like Excel and R required substantial manual effort and expertise, but there has been a notable shift towards automation. This transformation is driven by research efforts that have progressively automated various aspects of the data analysis process~\cite{wu2021ai4vis}. Initial research focused on providing visualization recommendations from datasets~\cite{cui2019datasite,kim2020gemini,wongsuphasawat2015voyager}, aiding users in the visualization process. Other work improved existing visualizations by focusing on aspects such as visual style searching~\cite{hoque2019searching}, assessing visualizations~\cite{fu2019visualization}, and annotation placement~\cite{bryan2016temporal}. Industrial tools like Tableau and Power BI have begun integrating AI to streamline data management for business applications~\cite{itsnotaboutthecell,nichols_wang_2024}. Although these systems have proven useful for data workers, novice users still face challenges in creating visualizations due to a lack of expertise.

Recent research has shifted towards automatically generating charts from datasets. Data2Vis~\cite{dibia2018data2vis} and VizSmith~\cite{vizsmith} demonstrated the feasibility of generating structured code in Vega-Lite and Python to produce appropriate graphs. Despite these advancements, a common limitation has been the inadequate integration of the human perspective in the outputs. The generated visualizations may not fully align with user intentions, limiting the usability of these systems. NL4DV~\cite{narechania2020nl4dv} addressed this by enabling chart generation based on natural language requests, aligning outputs more closely with user preferences. This capability was further enhanced by NL2Viz~\cite{wu2022nl2viz}, which incorporated program context to better capture user intentions. However, heuristic-based semantic matching in these tools still struggled with linguistic challenges, such as synonyms. For instance, terms like \emph{``yearly''} and \emph{``annual''} were not recognized as equivalent. Recently, LLMs have been applied to data visualization tasks, solving the problem of natural language semantic understanding and accommodating greater flexibility in user input~\cite{chat2vis}. While this research has shown positive results with various prompt techniques, we aim to explore how specialized AI worker definitions can further improve the quality of generated charts.


\subsection{Automatic Story-Telling and Fact Sheet Generations}

In scenarios where isolated visualizations fail to convey complex datasets effectively, narrative visualizations play a crucial role in presenting data with an intuitive and coherent flow, thereby enhancing accessibility for general audiences~\cite{ren2023re}. Narrative visualizations encompass a range of representations, including data videos~\cite{wang2021animated}, data comics, storylines~\cite{liu2013storyflow}, and infographics~\cite{cui2019text}. Early technologies provided platforms for users to manually design story flows. For example, Infonice~\cite{wang2018infonice} assisted users in creating infographics, bridging the gap between data exploration and presentation. Similarly, DataSelfie~\cite{kim2019dataselfie} enabled users to create personalized data visuals. However, these tools required a deep understanding of data and experience in composing data storytelling artifacts, limiting their accessibility to general users.

Recent technological advancements have led to the development of automated storytelling approaches~\cite{chen2023does}, offering a more accessible method for composing storytelling artifacts. These tools capture information from datasets and craft narratives around them. AutoClip~\cite{shi2021autoclips}, for example, automatically generates data videos to showcase fact findings. NewsViews~\cite{gao2014newsviews} provides an automated pipeline that extracts topics and creates corresponding geographic visualizations using contextual information from articles. Focusing on a more concise and data-driven format, recent advancements have also targeted the automated generation of fact sheets. DataShot~\cite{wang2019datashot} was the first tool to automatically generate fact sheets from tabular datasets, focusing on deriving quality facts from the data. However, this approach overlooked the overall story flow due to a lack of semantic relationship identification between different visualizations. Calliope~\cite{shi2020calliope}, an improvement upon DataShot, applied a logic-oriented Monte Carlo tree search algorithm to construct the story from facts. Despite this enhancement, Calliope still faces challenges in creating a seamless narrative across different visualizations due to limited understanding of data semantics. Additionally, previous fact sheet generation approaches did not consider user input and struggled with generating engaging textual components, such as chart titles and descriptions, due to their reliance on template-based methods~\cite{shi2020calliope, wang2019datashot}. Building on this evolving research trajectory, \tool aims to enhance the integration and natural flow of charts with more precise and natural captions.


\begin{figure*}[h]%[tb]% specify a combination of t, b, p, or h for top, bottom, on its own page, or here
  \centering % avoid the use of \begin{center}...\end{center} and use \centering instead (more compact)
  \includegraphics[width=\textwidth]{figs/overview.pdf}
  \caption{%
Workflow of \tool for generating a fact sheet using a global population dataset with columns for Country, Population, and Continent. \tool first prepares the dataset representation, which is then processed by the AI Chain. Each worker in the chain is profiled for specific tasks to generate the fact sheet.
}
  \label{fig:overview}
  \vspace{-4mm}
\end{figure*}

\subsection{Large Language Models for Data Tools}
Recent advancements in generative AI have driven the development of Large Language Models (LLMs), designed to understand natural language and generate human-like responses. Through prompt engineering techniques~\cite{min2022rethinking}, LLMs have improved the accuracy of heuristic-based solutions while reducing the need for extensive data and complex model training. Research on the applicability of LLMs spans various fields, from healthcare~\cite{cascella2023evaluating} and finance~\cite{wu2023bloomberggpt} to IT sectors like testing~\cite{deng2023pentestgpt}, automation~\cite{schwartz2023enhancing}, and smart devices~\cite{king2023get}. However, LLMs struggle with complex multi-step tasks, necessitating further research to enhance their usability. To address this, Wu et al. introduced AI chains~\cite{wu2022ai}, which break down complex tasks into manageable subtasks, each handled by a specific prompt. PromptSapper builds on this concept by defining the roles and collaboration of workers within the chain~\cite{cheng2024prompt}.

In the domain of data tools, pioneering research has explored the capabilities of LLMs in generating visualizations and aiding other visualization-related tasks. LLM4Vis, for instance, conducted experiments using a ChatGPT-based approach for visualization recommendations~\cite{wang2023llm4vis}, demonstrating the model's applicability for data tasks. Additionally, Chat2VIS~\cite{chat2vis} conducted a comparative study on the abilities of ChatGPT, Codex, and GPT-3 in rendering single visualizations from language queries. Other studies have also explored enhancing user interaction with visualizations by integrating LLMs to develop chatbot assistants for datasets~\cite{kavaz2023chatbot}. Recently, ChartGPT~\cite{tian2024chartgpt} performed fine-tuning of LLMs on a specialized dataset of visualizations to generate accurate and expressive charts from abstract natural language inputs. Additionally, DataTales~\cite{sultanum2023datatales} utilized LLMs' natural language capabilities to generate textual narratives accompanying charts in data-driven articles. This research has paved the way for advanced LLM applications in creating robust, user-centric data tools. Building on this, \tool adopts a holistic approach, leveraging LLMs to generate complete fact sheets from tabular datasets. Our goal is to apply AI chain techniques to tackle complex data tasks and validate their feasibility.
