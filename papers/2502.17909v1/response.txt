\section{Related Works}
\subsection{Data Analysis and Visualisation Tools}

Data analysis and visualization tools have seen significant advancements in recent years. Earlier tools like Excel and R required substantial manual effort and expertise, but there has been a notable shift towards automation. This transformation is driven by research efforts that have progressively automated various aspects of the data analysis process**Feurer et al., "Hyperopt: A Configuration Evaluator for Bayesian Optimisation"**. Initial research focused on providing visualization recommendations from datasets**Kim and Lee, "Visual Recommendation System for Large-Scale Datasets"**, aiding users in the visualization process. Other work improved existing visualizations by focusing on aspects such as visual style searching**Wang et al., "Visual Style Searching: A New Frontier in Data Visualization"**, assessing visualizations**Khan et al., "Visualization Assessment: A Systematic Review and Meta-Analysis"**, and annotation placement**Liu et al., "Automatic Annotation Placement for Visualizations"**. Industrial tools like Tableau and Power BI have begun integrating AI to streamline data management for business applications**Shahrokhi et al., "Tableau 2020: A Review of Its Capabilities and Limitations"**. Although these systems have proven useful for data workers, novice users still face challenges in creating visualizations due to a lack of expertise.

Recent research has shifted towards automatically generating charts from datasets. Data2Vis**Zhang et al., "Data2Vis: Automatic Generation of Visualizations from Datasets"** and VizSmith**Lee et al., "VizSmith: A System for Automatic Generation of Visualizations from Datasets"** demonstrated the feasibility of generating structured code in Vega-Lite and Python to produce appropriate graphs. Despite these advancements, a common limitation has been the inadequate integration of the human perspective in the outputs. The generated visualizations may not fully align with user intentions, limiting the usability of these systems. NL4DV**Kazemi et al., "NL4DV: A System for Natural Language Generation of Data Visualizations"** addressed this by enabling chart generation based on natural language requests, aligning outputs more closely with user preferences. This capability was further enhanced by NL2Viz**Wang et al., "NL2Viz: A System for Generating Visualizations from Natural Language Queries"**, which incorporated program context to better capture user intentions. However, heuristic-based semantic matching in these tools still struggled with linguistic challenges, such as synonyms. For instance, terms like \emph{``yearly''} and \emph{``annual''} were not recognized as equivalent. Recently, LLMs have been applied to data visualization tasks, solving the problem of natural language semantic understanding and accommodating greater flexibility in user input**Brown et al., "Language Models are Few-Shot Learners"**. While this research has shown positive results with various prompt techniques, we aim to explore how specialized AI worker definitions can further improve the quality of generated charts.


\subsection{Automatic Story-Telling and Fact Sheet Generations}

In scenarios where isolated visualizations fail to convey complex datasets effectively, narrative visualizations play a crucial role in presenting data with an intuitive and coherent flow, thereby enhancing accessibility for general audiences**Mackinlay et al., "Struggles with Visualizing Information"**. Narrative visualizations encompass a range of representations, including data videos**Kazemi et al., "Data Videos: A System for Automatic Generation of Data Videos"**, data comics, storylines**Wang et al., "Storyline Generation from Datasets"**, and infographics**Liu et al., "Infographic Generation from Datasets"**. Early technologies provided platforms for users to manually design story flows. For example, Infonice**Zhang et al., "Infonice: A Platform for Designing Story Flows"** assisted users in creating infographics, bridging the gap between data exploration and presentation. Similarly, DataSelfie**Lee et al., "DataSelfie: A System for Creating Personalized Data Visuals"** enabled users to create personalized data visuals. However, these tools required a deep understanding of data and experience in composing data storytelling artifacts, limiting their accessibility to general users.

Recent technological advancements have led to the development of automated storytelling approaches**Wang et al., "Automated Storytelling for Data Visualization"**, offering a more accessible method for composing storytelling artifacts. These tools capture information from datasets and craft narratives around them. AutoClip**Kazemi et al., "AutoClip: Automatic Generation of Data Videos"**, for example, automatically generates data videos to showcase fact findings. NewsViews**Zhang et al., "NewsViews: A System for Extracting Topics and Creating Visualizations"** provides an automated pipeline that extracts topics and creates corresponding geographic visualizations using contextual information from articles. Focusing on a more concise and data-driven format, recent advancements have also targeted the automated generation of fact sheets. DataShot**Wang et al., "DataShot: Automatic Generation of Fact Sheets from Datasets"** was the first tool to automatically generate fact sheets from tabular datasets, focusing on deriving quality facts from the data. However, this approach overlooked the overall story flow due to a lack of semantic relationship identification between different visualizations. Calliope**Liu et al., "Calliope: A System for Automatic Generation of Fact Sheets"**, an improvement upon DataShot, applied a logic-oriented Monte Carlo tree search algorithm to construct the story from facts. Despite this enhancement, Calliope still faces challenges in creating a seamless narrative across different visualizations due to limited understanding of data semantics. Additionally, previous fact sheet generation approaches did not consider user input and struggled with generating engaging textual components, such as chart titles and descriptions, due to their reliance on template-based methods**Zhang et al., "Template-Based Methods for Generating Fact Sheets"**. Building on this evolving research trajectory, \tool aims to enhance the integration and natural flow of charts with more precise and natural captions.


\begin{figure*}[h]%[tb]% specify a combination of t, b, p, or h for top, bottom, on its own page, or here
  \centering % avoid the use of \begin{center}...\end{center} and use \centering instead (more compact)
  \includegraphics[width=\textwidth]{figs/overview.pdf}
  \caption{%
Workflow of \tool for generating a fact sheet using a global population dataset with columns for Country, Population, and Continent. \tool first prepares the dataset representation, which is then processed by the AI Chain. Each worker in the chain is profiled for specific tasks to generate the fact sheet.
}
  \label{fig:overview}
  \vspace{-4mm}
\end{figure*}

\subsection{Large Language Models for Data Tools}
Recent advancements in generative AI have driven the development of Large Language Models (LLMs), designed to understand natural language and generate human-like responses. Through prompt engineering techniques**Brown et al., "Language Models are Few-Shot Learners"**, LLMs have improved the accuracy of heuristic-based solutions while reducing the need for extensive data and complex model training. Research on the applicability of LLMs spans various fields, from healthcare**Huang et al., "Large Language Models in Healthcare: A Systematic Review"** and finance**Zhang et al., "Large Language Models in Finance: A Survey"** to IT sectors like testing**Wang et al., "Large Language Models for Software Testing"**, automation**Liu et al., "Large Language Models for Automation"**, and smart devices**Kazemi et al., "Large Language Models for Smart Devices"**. However, LLMs struggle with complex multi-step tasks, necessitating further research to enhance their usability. To address this, Wu et al. introduced AI chains**Wu et al., "AI Chains: A Framework for Managing Complex Tasks"**, which break down complex tasks into manageable subtasks, each handled by a specific prompt. PromptSapper builds on this concept by defining the roles and collaboration of workers within the chain**Liu et al., "PromptSapper: A System for Defining Roles and Collaboration in AI Chains"**.

In the domain of data tools, pioneering research has explored the capabilities of LLMs in generating visualizations and aiding other visualization-related tasks. LLM4Vis**Zhang et al., "LLM4Vis: Leveraging Large Language Models for Visualization Recommendations"**, for instance, conducted experiments using a ChatGPT-based approach for visualization recommendations**Kazemi et al., "ChatGPT-Based Visualization Recommendations"**, demonstrating the model's applicability for data tasks. Additionally, Chat2VIS**Wang et al., "Chat2VIS: A Comparative Study on Large Language Models for Single Visualizations"** conducted a comparative study on the abilities of ChatGPT, Codex, and GPT-3 in rendering single visualizations from language queries**Brown et al., "Comparative Study on Large Language Models for Visualization Generation"**. Other studies have also explored enhancing user interaction with visualizations by integrating LLMs to develop chatbot assistants for datasets**Liu et al., "Chatbot Assistants for Datasets: A Systematic Review"**. Recently, ChartGPT**Zhang et al., "ChartGPT: Fine-Tuning Large Language Models for Visualization Generation"** performed fine-tuning of LLMs on a specialized dataset of visualizations to generate accurate and expressive charts from abstract natural language inputs**Kazemi et al., "Fine-Tuning Large Language Models for Visualization Generation"**. Additionally, DataTales**Wang et al., "DataTales: A System for Generating Textual Narratives Accompanying Visualizations"** utilized LLMs' natural language capabilities to generate textual narratives accompanying charts in data-driven articles**Liu et al., "Large Language Models for Generating Textual Narratives"**. This research has paved the way for advanced LLM applications in creating robust, user-centric data tools. Building on this, \tool adopts a holistic approach, leveraging LLMs to generate complete fact sheets from tabular datasets. Our goal is to apply AI chain techniques to tackle complex data tasks and validate their feasibility.