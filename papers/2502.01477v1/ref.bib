@article{moor2023foundation,
  title={Foundation models for generalist medical artificial intelligence},
  author={Moor, Michael and Banerjee, Oishi and Abad, Zahra Shakeri Hossein and Krumholz, Harlan M and Leskovec, Jure and Topol, Eric J and Rajpurkar, Pranav},
  journal={Nature},
  volume={616},
  number={7956},
  pages={259--265},
  year={2023},
  publisher={Nature Publishing Group UK London}
}

@article{hollmann2025accurate,
  title={Accurate predictions on small data with a tabular foundation model},
  author={Hollmann, Noah and M{\"u}ller, Samuel and Purucker, Lennart and Krishnakumar, Arjun and K{\"o}rfer, Max and Hoo, Shi Bin and Schirrmeister, Robin Tibor and Hutter, Frank},
  journal={Nature},
  volume={637},
  number={8045},
  pages={319--326},
  year={2025},
  publisher={Nature Publishing Group UK London}
}

@article{jin2023time,
  title={Time-llm: Time series forecasting by reprogramming large language models},
  author={Jin, Ming and Wang, Shiyu and Ma, Lintao and Chu, Zhixuan and Zhang, James Y and Shi, Xiaoming and Chen, Pin-Yu and Liang, Yuxuan and Li, Yuan-Fang and Pan, Shirui and others},
  journal={arXiv preprint arXiv:2310.01728},
  year={2023}
}

@inproceedings{liutime,
  title={Time-MMD: Multi-Domain Multimodal Dataset for Time Series Analysis},
  author={Liu, Haoxin and Xu, Shangqing and Zhao, Zhiyuan and Kong, Lingkai and Kamarthi, Harshavardhan and Sasanur, Aditya B and Sharma, Megha and Cui, Jiaming and Wen, Qingsong and Zhang, Chao and others},
  booktitle={The Thirty-eight Conference on Neural Information Processing Systems Datasets and Benchmarks Track},
  year={2024}

}

@article{yang2024survey,
  title={A survey on diffusion models for time series and spatio-temporal data},
  author={Yang, Yiyuan and Jin, Ming and Wen, Haomin and Zhang, Chaoli and Liang, Yuxuan and Ma, Lintao and Wang, Yi and Liu, Chenghao and Yang, Bin and Xu, Zenglin and others},
  journal={arXiv preprint arXiv:2404.18886},
  year={2024}
}

@inproceedings{wu2023multimodal,
  title={Multimodal large language models: A survey},
  author={Wu, Jiayang and Gan, Wensheng and Chen, Zefeng and Wan, Shicheng and Philip, S Yu},
  booktitle={2023 IEEE International Conference on Big Data (BigData)},
  pages={2247--2256},
  year={2023},
  organization={IEEE}
}

@article{wen2022transformers,
  title={Transformers in time series: A survey},
  author={Wen, Qingsong and Zhou, Tian and Zhang, Chaoli and Chen, Weiqi and Ma, Ziqing and Yan, Junchi and Sun, Liang},
  journal={arXiv preprint arXiv:2202.07125},
  year={2022}
}

@article{zamanzadeh2024deep,
  title={Deep learning for time series anomaly detection: A survey},
  author={Zamanzadeh Darban, Zahra and Webb, Geoffrey I and Pan, Shirui and Aggarwal, Charu and Salehi, Mahsa},
  journal={ACM Computing Surveys},
  volume={57},
  number={1},
  pages={1--42},
  year={2024},
  publisher={ACM New York, NY}
}

@article{yin2023survey,
  title={A survey on multimodal large language models},
  author={Yin, Shukang and Fu, Chaoyou and Zhao, Sirui and Li, Ke and Sun, Xing and Xu, Tong and Chen, Enhong},
  journal={arXiv preprint arXiv:2306.13549},
  year={2023}
}

@article{zhang2024mm,
  title={Mm-llms: Recent advances in multimodal large language models},
  author={Zhang, Duzhen and Yu, Yahan and Dong, Jiahua and Li, Chenxing and Su, Dan and Chu, Chenhui and Yu, Dong},
  journal={arXiv preprint arXiv:2401.13601},
  year={2024}
}

@inproceedings{cui2024survey,
  title={A survey on multimodal large language models for autonomous driving},
  author={Cui, Can and Ma, Yunsheng and Cao, Xu and Ye, Wenqian and Zhou, Yang and Liang, Kaizhao and Chen, Jintai and Lu, Juanwu and Yang, Zichong and Liao, Kuei-Da and others},
  booktitle={Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision},
  pages={958--979},
  year={2024}
}

@article{du2024tsi,
  title={Tsi-bench: Benchmarking time series imputation},
  author={Du, Wenjie and Wang, Jun and Qian, Linglong and Yang, Yiyuan and Ibrahim, Zina and Liu, Fanxing and Wang, Zepu and Liu, Haoxin and Zhao, Zhiyuan and Zhou, Yingjie and others},
  journal={arXiv preprint arXiv:2406.12747},
  year={2024}
}

@article{zhou2024survey,
  title={A survey on generative ai and llm for video generation, understanding, and streaming},
  author={Zhou, Pengyuan and Wang, Lin and Liu, Zhi and Hao, Yanbin and Hui, Pan and Tarkoma, Sasu and Kangasharju, Jussi},
  journal={arXiv preprint arXiv:2404.16038},
  year={2024}
}

@article{mohammadi2024deep,
  title={Deep learning for time series classification and extrinsic regression: A current survey},
  author={Mohammadi Foumani, Navid and Miller, Lynn and Tan, Chang Wei and Webb, Geoffrey I and Forestier, Germain and Salehi, Mahsa},
  journal={ACM Computing Surveys},
  volume={56},
  number={9},
  pages={1--45},
  year={2024},
  publisher={ACM New York, NY}
}

@article{yu2024natural,
  title={Natural language reasoning, a survey},
  author={Yu, Fei and Zhang, Hongbo and Tiwari, Prayag and Wang, Benyou},
  journal={ACM Computing Surveys},
  volume={56},
  number={12},
  pages={1--39},
  year={2024},
  publisher={ACM New York, NY}
}

@article{chow2024towards,
  title={Towards time series reasoning with llms},
  author={Chow, Winnie and Gardiner, Lauren and Hallgr{\'\i}msson, Haraldur T and Xu, Maxwell A and Ren, Shirley You},
  journal={arXiv preprint arXiv:2409.11376},
  year={2024}
}

@article{chang2024survey,
  title={A survey on evaluation of large language models},
  author={Chang, Yupeng and Wang, Xu and Wang, Jindong and Wu, Yuan and Yang, Linyi and Zhu, Kaijie and Chen, Hao and Yi, Xiaoyuan and Wang, Cunxiang and Wang, Yidong and others},
  journal={ACM Transactions on Intelligent Systems and Technology},
  volume={15},
  number={3},
  pages={1--45},
  year={2024},
  publisher={ACM New York, NY}
}



@article{ye2024beyond,
  title={Beyond Forecasting: Compositional Time Series Reasoning for End-to-End Task Execution},
  author={Ye, Wen and Zhang, Yizhou and Yang, Wei and Tang, Lumingyuan and Cao, Defu and Cai, Jie and Liu, Yan},
  journal={arXiv preprint arXiv:2410.04047},
  year={2024}
}

@article{xie2024chatts,
  title={ChatTS: Aligning Time Series with LLMs via Synthetic Data for Enhanced Understanding and Reasoning},
  author={Xie, Zhe and Li, Zeyan and He, Xiao and Xu, Longlong and Wen, Xidao and Zhang, Tieying and Chen, Jianjun and Shi, Rui and Pei, Dan},
  journal={arXiv preprint arXiv:2412.03104},
  year={2024}
}

@article{xia2024beyond,
  title={Beyond chain-of-thought: A survey of chain-of-x paradigms for llms},
  author={Xia, Yu and Wang, Rui and Liu, Xu and Li, Mingyan and Yu, Tong and Chen, Xiang and McAuley, Julian and Li, Shuai},
  journal={arXiv preprint arXiv:2404.15676},
  year={2024}
}

@article{shi2024language,
  title={Language models can improve event prediction by few-shot abductive reasoning},
  author={Shi, Xiaoming and Xue, Siqiao and Wang, Kangrui and Zhou, Fan and Zhang, James and Zhou, Jun and Tan, Chenhao and Mei, Hongyuan},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@article{lewis2024using,
  title={Using counterfactual tasks to evaluate the generality of analogical reasoning in large language models},
  author={Lewis, Martha and Mitchell, Melanie},
  journal={arXiv preprint arXiv:2402.08955},
  year={2024}
}

@inproceedings{yang2023dcdetector,
  title={Dcdetector: Dual attention contrastive representation learning for time series anomaly detection},
  author={Yang, Yiyuan and Zhang, Chaoli and Zhou, Tian and Wen, Qingsong and Sun, Liang},
  booktitle={Proceedings of the 29th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
  pages={3033--3045},
  year={2023}
}

@article{nie2022time,
  title={A time series is worth 64 words: Long-term forecasting with transformers},
  author={Nie, Yuqi and Nguyen, Nam H and Sinthong, Phanwadee and Kalagnanam, Jayant},
  journal={arXiv preprint arXiv:2211.14730},
  year={2022}
}

@inproceedings{jin2024position,
  title={Position: What Can Large Language Models Tell Us about Time Series Analysis},
  author={Jin, Ming and Zhang, Yifan and Chen, Wei and Zhang, Kexin and Liang, Yuxuan and Yang, Bin and Wang, Jindong and Pan, Shirui and Wen, Qingsong},
  booktitle={Forty-first International Conference on Machine Learning},
  year={2024}
}

@book{hamilton2020time,
  title={Time series analysis},
  author={Hamilton, James D},
  year={2020},
  publisher={Princeton university press}
}

@article{su2024large,
  title={Large language models for forecasting and anomaly detection: A systematic literature review},
  author={Su, Jing and Jiang, Chufeng and Jin, Xin and Qiao, Yuxin and Xiao, Tingsong and Ma, Hongda and Wei, Rong and Jing, Zhi and Xu, Jiajun and Lin, Junhong},
  journal={arXiv preprint arXiv:2402.10350},
  year={2024}
}

@book{kirchgassner2012introduction,
  title={Introduction to modern time series analysis},
  author={Kirchg{\"a}ssner, Gebhard and Wolters, J{\"u}rgen and Hassler, Uwe},
  year={2012},
  publisher={Springer Science \& Business Media}
}

@book{shumway2000time,
  title={Time series analysis and its applications},
  author={Shumway, Robert H and Stoffer, David S and Stoffer, David S},
  volume={3},
  year={2000},
  publisher={Springer}
}

@article{jin2023large,
  title={Large models for time series and spatio-temporal data: A survey and outlook},
  author={Jin, Ming and Wen, Qingsong and Liang, Yuxuan and Zhang, Chaoli and Xue, Siqiao and Wang, Xue and Zhang, James and Wang, Yi and Chen, Haifeng and Li, Xiaoli and others},
  journal={arXiv preprint arXiv:2310.10196},
  year={2023}
}

@article{wang2024chattime,
  title={ChatTime: A Unified Multimodal Time Series Foundation Model Bridging Numerical and Textual Data},
  author={Wang, Chengsen and Qi, Qi and Wang, Jingyu and Sun, Haifeng and Zhuang, Zirui and Wu, Jinming and Zhang, Lei and Liao, Jianxin},
  journal={arXiv preprint arXiv:2412.11376},
  year={2024}
}

@article{besta2025reasoning,
  title={Reasoning Language Models: A Blueprint},
  author={Besta, Maciej and Barth, Julia and Schreiber, Eric and Kubicek, Ales and Catarino, Afonso and Gerstenberger, Robert and Nyczyk, Piotr and Iff, Patrick and Li, Yueling and Houliston, Sam and others},
  journal={arXiv preprint arXiv:2501.11223},
  year={2025}
}

@article{wei2022chain,
  title={Chain-of-thought prompting elicits reasoning in large language models},
  author={Wei, Jason and Wang, Xuezhi and Schuurmans, Dale and Bosma, Maarten and Xia, Fei and Chi, Ed and Le, Quoc V and Zhou, Denny and others},
  journal={Advances in neural information processing systems},
  volume={35},
  pages={24824--24837},
  year={2022}
}

@article{chu2023survey,
  title={A survey of chain of thought reasoning: Advances, frontiers and future},
  author={Chu, Zheng and Chen, Jingchang and Chen, Qianglong and Yu, Weijiang and He, Tao and Wang, Haotian and Peng, Weihua and Liu, Ming and Qin, Bing and Liu, Ting},
  journal={arXiv preprint arXiv:2309.15402},
  year={2023}
}

@article{zhou2023one,
  title={One fits all: Power general time series analysis by pretrained lm},
  author={Zhou, Tian and Niu, Peisong and Sun, Liang and Jin, Rong and others},
  journal={Advances in neural information processing systems},
  volume={36},
  pages={43322--43355},
  year={2023}
}

@article{kong2024large,
  title={Large Language Models for Financial and Investment Management: Models, Opportunities, and Challenges.},
  author={Kong, Yaxuan and Nie, Yuqi and Dong, Xiaowen and Mulvey, John M and Poor, H Vincent and Wen, Qingsong and Zohren, Stefan},
  journal={Journal of Portfolio Management},
  volume={51},
  number={2},
  year={2024}
}

@article{nie2024survey,
  title={A Survey of Large Language Models for Financial Applications: Progress, Prospects and Challenges},
  author={Nie, Yuqi and Kong, Yaxuan and Dong, Xiaowen and Mulvey, John M and Poor, H Vincent and Wen, Qingsong and Zohren, Stefan},
  journal={arXiv preprint arXiv:2406.11903},
  year={2024}
}

@article{kong2024large2,
  title={Large Language Models for Financial and Investment Management: Applications and Benchmarks.},
  author={Kong, Yaxuan and Nie, Yuqi and Dong, Xiaowen and Mulvey, John M and Poor, H Vincent and Wen, Qingsong and Zohren, Stefan},
  journal={Journal of Portfolio Management},
  volume={51},
  number={2},
  year={2024}
}

@inproceedings{yang2023sgdp,
  title={SGDP: A stream-graph neural network based data prefetcher},
  author={Yang, Yiyuan and Li, Rongshang and Shi, Qiquan and Li, Xijun and Hu, Gang and Li, Xing and Yuan, Mingxuan},
  booktitle={2023 International Joint Conference on Neural Networks (IJCNN)},
  pages={1--8},
  year={2023},
  organization={IEEE}
}

@article{yang2021long,
  title={Long-distance pipeline safety early warning: a distributed optical fiber sensing semi-supervised learning method},
  author={Yang, Yiyuan and Zhang, Haifeng and Li, Yi},
  journal={IEEE sensors journal},
  volume={21},
  number={17},
  pages={19453--19461},
  year={2021},
  publisher={IEEE}
}

@inproceedings{yang2021early,
  title={Early safety warnings for long-distance pipelines: A distributed optical fiber sensor machine learning approach},
  author={Yang, Yiyuan and Li, Yi and Zhang, Taojia and Zhou, Yan and Zhang, Haifeng},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={35},
  pages={14991--14999},
  year={2021}
}

@article{gruver2024large,
  title={Large language models are zero-shot time series forecasters},
  author={Gruver, Nate and Finzi, Marc and Qiu, Shikai and Wilson, Andrew G},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@inproceedings{liang2024foundation,
  title={Foundation models for time series analysis: A tutorial and survey},
  author={Liang, Yuxuan and Wen, Haomin and Nie, Yuqi and Jiang, Yushan and Jin, Ming and Song, Dongjin and Pan, Shirui and Wen, Qingsong},
  booktitle={Proceedings of the 30th ACM SIGKDD conference on knowledge discovery and data mining},
  pages={6555--6565},
  year={2024}
}

@article{chang2023llm4ts,
  title={Llm4ts: Two-stage fine-tuning for time-series forecasting with pre-trained llms},
  author={Chang, Ching and Peng, Wen-Chih and Chen, Tien-Fu},
  journal={arXiv preprint arXiv:2308.08469},
  year={2023}
}

@article{cao2023tempo,
  title={Tempo: Prompt-based generative pre-trained transformer for time series forecasting},
  author={Cao, Defu and Jia, Furong and Arik, Sercan O and Pfister, Tomas and Zheng, Yixiang and Ye, Wen and Liu, Yan},
  journal={arXiv preprint arXiv:2310.04948},
  year={2023}
}

@inproceedings{jingtowards,
  title={Towards Editing Time Series},
  author={Jing, Baoyu and Gu, Shuqi and Chen, Tianyu and Yang, Zhiyu and Li, Dongsheng and He, Jingrui and Ren, Kan},
  booktitle={The Thirty-eighth Annual Conference on Neural Information Processing Systems},
  year={2024}
}

@article{cai2024timeseriesexam,
  title={TimeSeriesExam: A time series understanding exam},
  author={Cai, Yifu and Choudhry, Arjun and Goswami, Mononito and Dubrawski, Artur},
  journal={arXiv preprint arXiv:2410.14752},
  year={2024}
}

@article{potosnak2024implicit,
  title={Implicit Reasoning in Deep Time Series Forecasting},
  author={Potosnak, Willa and Challu, Cristian and Goswami, Mononito and Wili{\'n}ski, Micha{\l} and {\.Z}ukowska, Nina and Dubrawski, Artur},
  journal={arXiv preprint arXiv:2409.10840},
  year={2024}
}

@article{merrill2024language,
  title={Language Models Still Struggle to Zero-shot Reason about Time Series},
  author={Merrill, Mike A and Tan, Mingtian and Gupta, Vinayak and Hartvigsen, Tom and Althoff, Tim},
  journal={arXiv preprint arXiv:2404.11757},
  year={2024}
}

@article{williams2024context,
  title={Context is key: A benchmark for forecasting with essential textual information},
  author={Williams, Andrew Robert and Ashok, Arjun and Marcotte, {\'E}tienne and Zantedeschi, Valentina and Subramanian, Jithendaraa and Riachi, Roland and Requeima, James and Lacoste, Alexandre and Rish, Irina and Chapados, Nicolas and others},
  journal={arXiv preprint arXiv:2410.18959},
  year={2024}
}


@article{zhang2025tempogpt,
  title={TempoGPT: Enhancing Temporal Reasoning via Quantizing Embedding},
  author={Zhang, Haochuan and Yang, Chunhua and Han, Jie and Qin, Liyang and Wang, Xiaoli},
  journal={arXiv preprint arXiv:2501.07335},
  year={2025}
}

@article{zhou2024can,
  title={Can LLMs Understand Time Series Anomalies?},
  author={Zhou, Zihao and Yu, Rose},
  journal={arXiv preprint arXiv:2410.05440},
  year={2024}
}

@inproceedings{dong2024fnspid,
  title={Fnspid: A comprehensive financial news dataset in time series},
  author={Dong, Zihan and Fan, Xinyu and Peng, Zhiyuan},
  booktitle={Proceedings of the 30th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
  pages={4918--4927},
  year={2024}
}

@article{wang2024tabletime,
  title={TableTime: Reformulating Time Series Classification as Zero-Shot Table Understanding via Large Language Models},
  author={Wang, Jiahao and Cheng, Mingyue and Mao, Qingyang and Liu, Qi and Xu, Feiyang and Li, Xin and Chen, Enhong},
  journal={arXiv preprint arXiv:2411.15737},
  year={2024}
}

@article{niu2024multimodal,
  title={Multimodal Clinical Reasoning through Knowledge-augmented Rationale Generation},
  author={Niu, Shuai and Ma, Jing and Bai, Liang and Wang, Zhihua and Xu, Yida and Song, Yunya and Yang, Xian},
  journal={arXiv preprint arXiv:2411.07611},
  year={2024}
}

@article{liu2024picture,
  title={A Picture is Worth A Thousand Numbers: Enabling LLMs Reason about Time Series via Visualization},
  author={Liu, Haoxin and Liu, Chenghao and Prakash, B Aditya},
  journal={arXiv preprint arXiv:2411.06018},
  year={2024}
}

@article{aksu2024xforecast,
  title={XForecast: Evaluating Natural Language Explanations for Time Series Forecasting},
  author={Aksu, Taha and Liu, Chenghao and Saha, Amrita and Tan, Sarah and Xiong, Caiming and Sahoo, Doyen},
  journal={arXiv preprint arXiv:2410.14180},
  year={2024}
}

@article{wang2024news,
  title={From news to forecast: Integrating event analysis in llm-based time series forecasting with reflection},
  author={Wang, Xinlei and Feng, Maike and Qiu, Jing and Gu, Jinjin and Zhao, Junhua},
  journal={arXiv preprint arXiv:2409.17515},
  year={2024}
}

@article{zhou2025unveiling,
  title={Unveiling the Potential of Text in High-Dimensional Time Series Forecasting},
  author={Zhou, Xin and Wang, Weiqing and Qu, Shilin and Zhang, Zhiqiang and Bergmeir, Christoph},
  journal={arXiv preprint arXiv:2501.07048},
  year={2025}
}

@article{fatemi2024dynamical,
  title={A Dynamical View of the Question of Why},
  author={Fatemi, Mehdi and Gowda, Sindhu},
  journal={arXiv preprint arXiv:2402.10240},
  year={2024}
}

@article{hu2024rankprompt,
  title={RankPrompt: Step-by-Step Comparisons Make Language Models Better Reasoners},
  author={Hu, Chi and Ge, Yuan and Ma, Xiangnan and Cao, Hang and Li, Qiang and Yang, Yonghua and Xiao, Tong and Zhu, Jingbo},
  journal={arXiv preprint arXiv:2403.12373},
  year={2024}
}

@article{wang2024exploring,
  title={Exploring the reasoning abilities of multimodal large language models (mllms): A comprehensive survey on emerging trends in multimodal reasoning},
  author={Wang, Yiqi and Chen, Wentao and Han, Xiaotian and Lin, Xudong and Zhao, Haiteng and Liu, Yongfei and Zhai, Bohan and Yuan, Jianbo and You, Quanzeng and Yang, Hongxia},
  journal={arXiv preprint arXiv:2401.06805},
  year={2024}
}

@inproceedings{zhang2023insight,
  title={Insight miner: A time series analysis dataset for cross-domain alignment with natural language},
  author={Zhang, Yunkai and Zhang, Yawen and Zheng, Ming and Chen, Kezhen and Gao, Chongyang and Ge, Ruian and Teng, Siyuan and Jelloul, Amine and Rao, Jinmeng and Guo, Xiaoyuan and others},
  booktitle={NeurIPS 2023 AI for Science Workshop},
  year={2023}
}


@inproceedings{cai2023jolt,
  title={Jolt: Jointly learned representations of language and time-series},
  author={Cai, Yifu and Goswami, Mononito and Choudhry, Arjun and Srinivasan, Arvind and Dubrawski, Artur},
  booktitle={Deep Generative Models for Health Workshop NeurIPS 2023},
  year={2023}
}

@article{zhang2024llmforecaster,
  title={LLMForecaster: Improving seasonal event forecasts with unstructured textual data},
  author={Zhang, Hanyu and Arvin, Chuck and Efimov, Dmitry and Mahoney, Michael W and Perrault-Joncas, Dominique and Ramasubramanian, Shankar and Wilson, Andrew Gordon and Wolff, Malcolm},
  journal={arXiv preprint arXiv:2412.02525},
  year={2024}
}

@article{narasimhan2024time,
  title={Time weaver: A conditional time series generation model},
  author={Narasimhan, Sai Shankar and Agarwal, Shubhankar and Akcin, Oguzhan and Sanghavi, Sujay and Chinchali, Sandeep},
  journal={arXiv preprint arXiv:2403.02682},
  year={2024}
}

@article{moraffah2021causal,
  title={Causal inference for time series analysis: Problems, methods and evaluation},
  author={Moraffah, Raha and Sheth, Paras and Karami, Mansooreh and Bhattacharya, Anchit and Wang, Qianru and Tahir, Anique and Raglin, Adrienne and Liu, Huan},
  journal={Knowledge and Information Systems},
  volume={63},
  pages={3041--3085},
  year={2021},
  publisher={Springer}
}

@article{rosin2022temporal,
  title={Temporal attention for language models},
  author={Rosin, Guy D and Radinsky, Kira},
  journal={arXiv preprint arXiv:2202.02093},
  year={2022}
}

@article{rossi2020temporal,
  title={Temporal graph networks for deep learning on dynamic graphs},
  author={Rossi, Emanuele and Chamberlain, Ben and Frasca, Fabrizio and Eynard, Davide and Monti, Federico and Bronstein, Michael},
  journal={arXiv preprint arXiv:2006.10637},
  year={2020}
}

@inproceedings{radford2021learning,
  title={Learning transferable visual models from natural language supervision},
  author={Radford, Alec and Kim, Jong Wook and Hallacy, Chris and Ramesh, Aditya and Goh, Gabriel and Agarwal, Sandhini and Sastry, Girish and Askell, Amanda and Mishkin, Pamela and Clark, Jack and others},
  booktitle={International conference on machine learning},
  pages={8748--8763},
  year={2021},
  organization={PMLR}
}

@article{es2023ragas,
  title={Ragas: Automated evaluation of retrieval augmented generation},
  author={Es, Shahul and James, Jithin and Espinosa-Anke, Luis and Schockaert, Steven},
  journal={arXiv preprint arXiv:2309.15217},
  year={2023}
}

@article{requeima2024llm,
  title={LLM Processes: Numerical Predictive Distributions Conditioned on Natural Language},
  author={Requeima, James and Bronskill, John and Choi, Dami and Turner, Richard E and Duvenaud, David},
  journal={arXiv preprint arXiv:2405.12856},
  year={2024}
}
