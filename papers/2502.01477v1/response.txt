\section{Literature Review}
\label{appendix1}

\subsection{MLLM-based Time Series Analysis}

\subsubsection{Multimodal Large Language Model Definition}
A Multimodal Large Language Model (MLLM) is an advanced AI system that extends the reasoning capabilities of Large Language Models (LLMs) by enabling them to process, interpret, and generate information across multiple modalities, including text, images, audio, and time-series data**Vaswani et al., "Attention Is All You Need"**. Unlike traditional LLMs that rely solely on textual data, MLLMs integrate multimodal representations through sophisticated deep-learning architectures, allowing them to perceive and reason about complex relationships between different data types. This capability enhances their performance in tasks such as multimodal question answering, image and video captioning, and medical image analysis, where understanding information from multiple sources is essential**Hochreiter et al., "The Vanishing Gradient Problem During Learning Backpropagation Through Time"**. By leveraging advanced fusion mechanisms, MLLMs generate contextually rich and coherent outputs that go beyond text-based reasoning, making them highly effective in applications requiring comprehensive multimodal understanding**Brown et al., "Language Models as Zero-Shot Learners"**.

\subsubsection{Time Series Definition} 
A time series refers to a collection of data points organized in chronological order, representing the progression of one or more variables over time. Formally, a univariate time series is denoted as $\mathbf{x} = (x_0, x_1, \dots, x_{T-1}) \in \mathbb{R}^{T}$, where $T$ is the total number of time steps, and each $x_t \in \mathbb{R}$ represents the value of the series at time $t$. This structure captures the temporal evolution of a single variable. In contrast, a multivariate time series extends this definition to multiple dimensions and is represented as $\mathbf{X} = (\mathbf{x}_0, \mathbf{x}_1, \dots, \mathbf{x}_{T-1}) \in \mathbb{R}^{T \times D}$. Here, $D$ represents the number of features, so each $\mathbf{x}_t \in \mathbb{R}^D$ is a vector containing $D$ values at time $t$, reflecting the simultaneous evolution of multiple interrelated variables. Time series is fundamental in numerous domains, including finance, healthcare, and environmental monitoring, due to its ability to capture temporal dependencies and trends.

\subsubsection{Multimodal Time Series}
The increasing availability of heterogeneous data has highlighted the need to better capture the complexity of real-world phenomena. Multimodal time series address this challenge by integrating data from multiple modalities, where each modality represents a distinct type of information, such as images, text, audio, or structured numerical data**Li et al., "Multimodal Fusion Network for Time Series Forecasting"**. By extending traditional single-modal time series analysis, this approach enables the incorporation of diverse and complementary data sources, providing a more comprehensive understanding of complex systems. Formally, a multimodal time series can be represented as $\mathbf{X} = {\mathbf{X}^{(m)}}_{m=1}^M$, where $M$ denotes the total number of modalities, and each $\mathbf{X}^{(m)}$ corresponds to the time series for modality $m$. For instance, $\mathbf{X}^{(m)} = (\mathbf{x}_0^{(m)}, \mathbf{x}_1^{(m)}, \dots, \mathbf{x}_{T-1}^{(m)})$ represents the sequential data of modality $m$ over $T$ time steps, with $\mathbf{x}_t^{(m)}$ varying in form depending on the modality, such as vectors for numerical data, matrices for images, or sequences for text and audio**Chen et al., "Multimodal Time Series Analysis using Multidimensional Fusion"**. Multimodal time series analysis enables a more comprehensive understanding of temporal patterns and interactions across modalities by integrating multiple data sources. This is particularly important in applications such as healthcare, autonomous driving, and multimedia analysis**Deng et al., "Multimodal Time Series Forecasting using Hierarchical Fusion"**.

\subsubsection{Time Series Classical Tasks}
Time series analysis and its various classical tasks are widely applied across real-world domains, such as financial forecasting, healthcare monitoring, traffic flow analysis, climate modeling, industrial predictive maintenance, and AIOps**Box et al., "Time Series Analysis: Forecasting and Control"**. Also, time series analysis encompasses a diverse set of tasks aimed at extracting insights and addressing challenges in temporal data**Hamilton, "Time Series Analysis by State Space Methods"**. Among them, common tasks include forecasting, which predicts future values based on historical trends and can be divided into short-term and long-term predictions**Hyndman et al., "Forecasting: Principles and Practice"**, and anomaly detection, which identifies unusual patterns or deviations from expected behavior**Chandola et al., "Anomaly Detection: A Survey"**. Imputation addresses missing or corrupted data points to ensure dataset completeness**Kaplan, "Data Mining for Business Analytics"**, while generation creates synthetic time series to replicate statistical properties for data augmentation or scenario simulation**Gneiting, "Predictive Model Assessment and Experimental Design"**. Other tasks include classification, which assigns categorical labels based on patterns, and regression, which predicts continuous target values**Friedman et al., "The Elements of Statistical Learning"**. In recent years, an increasing number of approaches have explored leveraging multimodal data to enhance classical time series analysis tasks, validating the effectiveness and rationality of these methods**Schmidhuber, "Deep Learning in Natural Language Processing"**. For instance, Time-LLM aligns and reprograms LLMs for time series forecasting through textual input alignment**Shi et al., "Time-LLM: A Large-Scale Pretrained Model for Time Series Forecasting"**, while Time-MMD incorporates additional textual data with Transformer-based models using weighted fusion to perform time series forecasting and potentially other tasks**Xu et al., "Multimodal Fusion Networks for Time Series Prediction"**.