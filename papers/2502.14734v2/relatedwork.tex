\section{Related Work and Background}
\label{sec:rw}

\paragraph{Method: Semantic graph as an intermediate representation.} The value of using semantic graphs as an intermediate representation, particularly AMR, has been highlighted in two recent surveys \citep{sadeddine-etal-2024-survey, wein-opitz-2024-survey}. This approach allows the fusion of neural network power with the expressivity and explicitness of meaning representations, which is especially useful when \textit{interpretability} and \textit{control} are required in an application. Related work applies this principle to style transfer \citep{jangra-etal-2022-star}, translationese reduction\footnote{Translationese reduction aims at attempting to reduce ``language weirdness'' that can arise when translating texts, the authors show that post-processing with parsing and generation can mitigate these artifacts.} \citep{wein-schneider-2024-lost}, and data augmentation \citep{shou-etal-2022-amr, shou-lin-2023-evaluate, ghosh-etal-2024-abex}. Our work generalizes this principle further and imposes an additional check for validating the faithfulness of the generation. Notably, the idea of planning and controlling sentence generation through meaning representation dates decades back \citep[i.a.,][]{sondheimer-nebel-1986-logical, mann1986systemic, kasper-1989-flexible, wijnen1990development, bateman1990interfacing}, but was limited by inaccuracies parsing and generation systems. With stronger parsing and generation systems now at hand, we showcase the usefulness of this way of controllable text generation.

\paragraph{Application: Embedding models and benchmarking.} Text embedding models are crucial for a wide range of NLP tasks, including semantic search, information retrieval, and NLG evaluation \citep{clark2019sentence, muennighoff2022sgpt, gao2023retrieval}. Since \citet{reimers-gurevych-2019-sentence}'s foundational "SBERT" work, multiple branches of embedding model research have emerged. These include enhancing model performance through scaling parameters \citep{wang2023improving} or training data \citep{wang2022text}, as well as exploring unsupervised embeddings \citep{gao-etal-2021-simcse} and interpretable embeddings \citep{opitz-frank-2022-sbert}. However, key questions remain: \textit{What is the accuracy of such embeddings? What level of linguistic understanding resides in those vectors?} Towards being better able to answer such questions, we employ \model and demonstrate its capacity to generate fine evaluation data that test embedding models' ability to assess different linguistic phenomena. In posing such questions towards better understanding model's similariy decisions through assessing behavior on tailored datasets, our goal is related to a recent/concurrent line of work from Nastase et al. \citep{nastase-merlo-2024-tracking, nastase2024exploring, nastase2024exploringsy}.

Then, we would also like to learn more about different notions of similarity: Even for long-established datasets like SICK \citep{marelli-etal-2014-sick} or STS \citep{agirre-etal-2016-semeval}, it remains unclear what specific aspects human annotations elicit. For instance, \citet{budanitsky-hirst-2006-evaluating} point out that while relatedness (SICK) and similarity (STS) are somewhat related notions, similarity is ``not an adequate proxy (for relatedness).'' Recent empirical research investigates sentence meaning through descriptions, assessing the similarity of texts through these descriptions \citep{hoyle-etal-2023-natural, ravfogel2024descriptionbased}. Likewise, paraphrases vary widely and are often difficult to formally distinguish \citep{michail-etal-2025-paraphrasus}. In our work, we formalize relatedness as a confounder of similarity by inducing pairs with varying degree of \textit{structural surface similarity}, while their potential \textit{meaning differences are formally distinguishable}. Furthermore, the stasis of most benchmarks has also drawn upon criticism \citep{fan-etal-2024-nphardeval}, and limits evaluation to the available data, with potential ramifications for the trustworthiness of results. By demonstrating how \model can generate challenging, trustworthy, and interpretable test sets, we pave the way for more customizable, dynamic and interpretable testing of models.