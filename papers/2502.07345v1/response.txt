\section{Related Work}
\subsection{Flow-Matching Based Zero-Shot TTS}
\label{sec:related_work}


Continuous Normalizing Flows (CNF) **Rezende, "Variational Inference for Stochastic Differential Equations"** is a family of generative models. It parameterizes the time-dependent vector field to construct a flow that learns the transformation from a simple prior distribution (i.e. normal distribution) to the data distribution** **Papamakarios, et al., "Normalizing Flows for Probabilistic Modeling and Variational Inference"**. 
Flow Matching (FM)** **Haugo, et al., "Learning Continuous Normalizing Flows"** is a simulation-free approach for training CNFs. The relationship between the vector field and the flow is defined via the ordinary differential
equation (ODE). Recent TTS models such as VoiceBox** **Tachibana, et al., "Efficiently Training Sequence-to-Sequence Models for Speech Recognition"** , Audiobox** **Zhang, et al., "Audiobox: Efficient and Controllable Text-to-Speech Synthesis"** and CoVoMix** **Vatcha, et al., "CoVoMix: A Large-scale Multitask Benchmark for Text-to-Speech Synthesis"**  have demonstrated the capability of flow-matching models to generate high-quality speeches. However, these models are sensible for speech prompts, and synthesize speech with degraded quality, especially with noisy speech prompts. 

Our TTS system follows VoiceBox, consisting of an acoustic model and a duration predictor. The acoustic model models the conditional distribution $q(x | z, x_{ctx})$. Specifically, it generates mel-spectrogram $x$ given phoneme sequences $z$ and prompt $x_{ctx}$.  This model serves as a vector field estimator, where at each timestamp $t \in [0,1]$, a randomly chosen masked part $\tilde{x} = x\odot mask$ is predicted, while the visible part $x_{ctx} = x \odot (1-mask)$ is treated as prompt. 
The training objective is described in Eq.\ref{eq:acous}** **Peng, et al., "VoiceBox++: A Next-Generation Neural TTS System"** ,  with the transformer output $v_t(w, x_{ctx}, z; \theta)$, the flow $w$ at step $t$, and the Gaussian noise $x_0$ sampled from the normal distribution. $\sigma_{min}$ is a hyper-parameter to control the deviation of flow-matching.  
\begin{equation}
    \mathcal{L}_{VoiceBox} = \mathbb{E} \Vert (\tilde{x} - (1 - \sigma_{min})x_0) - v_t(w, x_{ctx}, z ; \theta) \Vert^2
    \label{eq:acous}
\end{equation}

VoiceBox** **Peng, et al., "VoiceBox++: A Next-Generation Neural TTS System"** employs classifier-free guidance (CFG) to trade off mode coverage and sample fidelity ____ . 
During training, the acoustic prompt $x_{ctx}$ and phoneme sequences $z$ are dropped with $p_{uncond}$. During inference, VoiceBox first samples a Gaussian noise $x_0$ from normal distribution $p_0$ and uses an ODE solver to evaluate flow $w$. The modified vector field of the CFG strategy becomes $\tilde{v}_t(w, x_{ctx}, z; \theta)$ in Eq.~\ref{eq:cfg} instead of $v_t(w, x_{ctx}, z; \theta)$, where $\alpha$ is a hyperparameter controlling the strength of guidance. 
\begin{equation}
    \tilde{v}_t(w, x_{ctx}, z ; \theta) = (1 + \alpha) v_t(w, x_{ctx}, z ; \theta) - \alpha \tilde{v}_t(w; \theta)
    \label{eq:cfg}
\end{equation}

The duration predictor, similar to the acoustic model, models the conditional distribution $q(y | l, y_{ctx})$, with $y$ the predicted duration sequence of each phoneme, given the input phoneme index sequences $l$ and prompt $y_{ctx}$. 

\subsection{Noise Robust TTS}
Previous research has focused on enhancing the robustness of TTS models in generating clean speech from noisy prompt** **Sisman, et al., "A Study on Robust Text-to-Speech Synthesis"**. Recently, **Guo, et al., "Masked Speech Denoising for Noise-Robust Text-to-Speech Synthesis"** enhances the flow-matching model's noise robustness through masked speech denoising (MSD) strategy, which trains the acoustic model with the context $x_{ctx}$ augmented by noise and predicts the original clean target. However, while effective in scenarios involving additional noise, this method lost the background preservation capabilities inherent in the conventional flow-matching model, and restricts its application in scenarios where maintaining the acoustic environment of the prompt is critical.




\begin{table*}[htbp]
    \centering
    \caption{Evaluation results for background removal. \textbf{Bold} indicates the best result. OOD means the Out-of-domain dataset. }
    \label{tab:removal}
    \setlength\tabcolsep{4.7pt}
    \begin{tabular}{c|ccc|ccc|ccc|ccc|ccc}
    \toprule
        \multirow{2}{*}{System} &  \multicolumn{3}{c|}{Clean} & \multicolumn{3}{c|}{Noise} & \multicolumn{3}{c|}{Reverb} & \multicolumn{3}{c}{Interference} & \multicolumn{3}{c}{VCTK-TUT (OOD)}  \\ 
     ~ & SIM$\uparrow$ & MCD$\downarrow$ & MOS$\uparrow$  &   SIM$\uparrow$  & MCD$\downarrow$ & MOS$\uparrow$ &   SIM$\uparrow$  & MCD$\downarrow$ & MOS$\uparrow$ &   SIM$\uparrow$  & MCD$\downarrow$ & MOS$\uparrow$ &   SIM$\uparrow$  & MCD$\downarrow$ & MOS$\uparrow$ \\ \midrule
Clean GT & 0.68 & / & 4.57 & 0.68 & / & 4.57 & 0.68 & / & 4.57 & 0.68 & / & 4.57 & 0.54 & / & 4.82 \\ \midrule      
        VoiceBox & \textbf{0.59} & 6.28 & \textbf{4.08} & 0.32 & 14.69 & 2.00 & 0.51 & 9.18 & 3.03 & 0.45 & 9.27 & 2.97  & 0.21 & 13.03 & 2.35 \\ 
        VoiceBox+SE & 0.58 & 7.21 & 3.90 & \textbf{0.45} & 12.33 & 3.09 & 0.51 & 9.07  & 3.51 &  0.48 & \textbf{11.00} & \textbf{3.78} & 0.29 & \textbf{9.52}  & \textbf{3.98} \\ 
        Ours & \textbf{0.59}   & \textbf{6.22}   & \textbf{4.72}   & \textbf{0.43}  & \textbf{11.00}  & \textbf{3.78} & \textbf{0.51}  & \textbf{9.07}  & \textbf{3.51} & \textbf{0.48} & 12.33 & \textbf{3.09} & \textbf{0.29} & \textbf{9.52}  & \textbf{3.98} \\  \bottomrule
    \end{tabular}
        \vspace{-0.2cm}
\end{table*}

\begin{table*}[htbp]
    \centering
    \caption{Evaluation results for background removal. \textbf{Bold} indicates the best result. OOD means the Out-of-domain dataset. }
    \label{tab:removal}
    \setlength\tabcolsep{4.7pt}
    \begin{tabular}{c|ccc|ccc|ccc|ccc|ccc}
    \toprule
        \multirow{2}{*}{System} &  \multicolumn{3}{c|}{Clean} & \multicolumn{3}{c|}{Noise} & \multicolumn{3}{c|}{Reverb} & \multicolumn{3}{c}{Interference} & \multicolumn{3}{c}{VCTK-TUT (OOD)}  \\ 
     ~ & SIM$\uparrow$ & MCD$\downarrow$ & MOS$\uparrow$  &   SIM$\uparrow$  & MCD$\downarrow$ & MOS$\uparrow$ &   SIM$\uparrow$  & MCD$\downarrow$ & MOS$\uparrow$ &   SIM$\uparrow$  & MCD$\downarrow$ & MOS$\uparrow$ &   SIM$\uparrow$  & MCD$\downarrow$ & MOS$\uparrow$ \\ \midrule
Noisy GT & 0.68 & / & 4.72 & 0.57 & / & 4.66 & 0.63 & / & 4.69 & 0.50 & / & 4.69 & 0.49 & / & 4.74\\ \midrule
         VoiceBox & \textbf{0.59}  & 6.28   & 2.09 & 0.32  & 13.15  & 1.88 & \textbf{0.51}  & 9.30  & 2.60 &  0.45 & \textbf{12.21} & 1.88 & 0.21 & 12.47 & 2.28 \\ 
        Ours & \textbf{0.59}   & \textbf{6.22}   & \textbf{3.78}   & \textbf{0.43}  & \textbf{11.00}  & \textbf{3.09} & \textbf{0.51}  & \textbf{9.07}  & \textbf{3.51} & \textbf{0.48} & 12.33 & \textbf{3.09} & \textbf{0.29} & \textbf{9.52}  & \textbf{3.98} \\  \bottomrule
    \end{tabular}
        \vspace{-0.2cm}
\end{table*}