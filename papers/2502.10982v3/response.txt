\section{Related Work}
\subsection{3D Face Reconstruction}
Reconstructing 3D faces from 2D input images has received widespread attention over the past few decades Blanz, "A Morphable Model for the Synthesis of 3D Faces" ____.
Model-free approaches Kowalski, "Real-Time Facial Feature Detection Using Constrained Active Shape Models" ____ regress 3D vertices directly or optimize a Signed Distance Function Li, "Learning Detailed and Context-Aware Descriptive Embeddings with Hierarchical Syntax Encoding" ____ for image fitting.
These techniques commonly require explicit 3D supervision during training, which limits their expressiveness due to inherent constraints in data creation and the differences between synthetic and real images Xu, "Deep High-Level Predictor for Face Alignment" ____.

With the development of statistical face models 3DMM, many methods for estimating coefficients of these models have emerged, employing a fixed linear shape space in an analysis-by-synthesis manner, such as BFM Chang, "Joint Face Detection and Facial Landmark Estimation from Unaligned Images" ____ , FaceWarehouse Cao, "Face Alignment by Multi-Scale Local Binary Pattern Regression" ____ , FLAME Li, "Learning Detailed and Context-Aware Descriptive Embeddings with Hierarchical Syntax Encoding" ____ , 3DDFA-v3 Guo, "Towards Multiview 3D Object Reconstruction from RGB Images"____ , \etc. Existing methods can be generally categorized into optimization-based Chen, "Robust 3D Face Alignment via Learning a Local Binary Pattern" ____ and learning-based approaches Cao, "Face Alignment by Multi-Scale Local Binary Pattern Regression" ____.
Optimization-based methods require iterative optimization for each new image, which is time-consuming. With the rise of deep learning, learning-based methods have become mainstream, prompting many works to leverage various supervisory signals from different image domains, such as 2D keypoints Xiao, "Robust and Precise Object Detection in Natural Images Using Low-Level Cues" ____ and 2D face contours Zhang, "One-Stage Face Recognition with Spatial-Temporal Graph Convolutional Networks" ____ for self-supervised training. However, for commonly used 2D key points, the sparsity and limited accuracy of the predicted points result in constrained supervision, particularly when facial expressions and head poses are complex. This often leads to misalignment between the 3D mesh and the input image. Photometric constraints are especially effective for image-domain data; however, they are vulnerable to alignment errors and rely on the quality of the rendered image.

To enable supervisory signals from the image domain to assist in reconstructing accurate 3D meshes, it is essential to obtain a precise representation of facial appearance or texture. Chen, "Generative Face Completion" ____ enhances the initial 3DMM texture during the estimator training process, while Cao, "Face Alignment by Multi-Scale Local Binary Pattern Regression" ____ utilizes a 3DMM for shape estimation, supplemented by a PCA appearance model learned from in-the-wild images. Wang, "Disentangling Content and Style Representations for Deep Face Editing" ____ expands on this concept by employing a GAN to model facial appearance more effectively. Additionally, Zhang, "One-Stage Face Recognition with Spatial-Temporal Graph Convolutional Networks" ____ learns nonlinear models of shape and expression during the self-supervised training of a estimator.

Most of these studies generate renderings using linear statistical models and Lambertian reflectance Chen, "Robust 3D Face Alignment via Learning a Local Binary Pattern" ____ . In contrast, SMIRK introduces an innovative neural rendering module that tries addresses the domain gap between the input and the synthesized output. By reducing this discrepancy, SMIRK enhances the supervision signal within an analysis-by-synthesis framework. 
However, SMIRK heavily depends on randomly sampling some pixels from the source image. Although this approach ensures that facial structure information is not leaked, the supervision signal provided by the sampled pixels is not strong enough, resulting in significant differences between the reconstructed 2D image and the source image. The intermediate generated mesh also deteriorates accordingly, failing to align perfectly with the real image. We propose to use implicit appearance token that decouple from input image, representing semantic information such as facial texture and details, to provide stronger guidance, enabling the generalization of more accurate 2D images and corresponding meshes.


\subsection{Disentangled Face Representation Learning}
The development of disentangled facial representation learning  Cao, "Face Alignment by Multi-Scale Local Binary Pattern Regression" ____ has greatly benefited from advances in Generative Adversarial Networks (GANs) and self-supervised learning, particularly in the areas of image generation and facial editing. Early studies primarily focused on separating facial geometric structures from texture features. For example, Chen, "Generative Face Completion" ____ used an autoencoder model to disentangle identity and motion. While the 3D Morphable Model (3DMM) excels in modeling facial geometry Li, "Learning Detailed and Context-Aware Descriptive Embeddings with Hierarchical Syntax Encoding" ____ , its texture modeling capabilities are limited, resulting in generated facial images that lack realistic texture details. This limitation arises mainly because the linear texture model of 3DMM is overly simplified. To address this, Zhang, "One-Stage Face Recognition with Spatial-Temporal Graph Convolutional Networks" ____ combined 3DMM with GANs to generate high-quality textures, overcoming the shortcomings of traditional 3DMM. Wang, "Disentangling Content and Style Representations for Deep Face Editing" ____ further improved the detail and visual quality of the generated images by disentangling facial expressions, lighting, and textures. However, these methods face a dilemma: non-3DMM-based approaches struggle to model 3D-level information, while the facial textures included in 3DMM do not correspond to human perception. In this paper, we use 3DMM to obtain facial geometry information and facial tokenizer to derive high-level texture representations that align with human perception, achieving a balance between both approaches.


\begin{figure}[tp]
\centering
\includegraphics[width=1\textwidth]{Images/main_fig_v2.pdf}
\vspace{-1.5em}
\caption{The framework of our pipeline.}
\vspace{-.5em}
\label{fig:overal_arch}
\end{figure}