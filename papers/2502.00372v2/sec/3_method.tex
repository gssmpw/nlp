% \begin{table*}[t]
% \centering
% \scalebox{1}{
% \begin{tabular}{c|lcc}
% \toprule[0.4mm]
% \rowcolor{mygray} \textbf{\#} & \textbf{Current State} & \textbf{Condition} & \textbf{Next State} \\ \hline \hline
% 1 & $S_P$ (Perception) & Number of entities categories $|C|=0$. & $S_P$ (Perception) \\
% 2 & $S_P$ (Perception) & Number of entities $|E|<2$. & $S_A$ (Answering) \\
% 3 & $S_P$ (Perception) & Number of entities $|E|\geq 2$. & $S_L$ (Logic Generation) \\ \hline
% 4 & $S_L$ (Logic Generation) & ProbLog code generation error & $S_L$ (Logic Generation) \\
% 5 & $S_L$ (Logic Generation) & ProbLog code generation success & $S_R$ (Logic Reasoning) \\ \hline
% 6 & $S_R$ (Logic Reasoning) & Number of result $|Y_L|=0$ & $S_L$ (Logic Generation) \\
% 7 & $S_R$ (Logic Reasoning) & Number of result $|Y_L|>0$ & $S_A$ (Answering) \\ \hline
% 8 & $S_A$ (Answering) & Answer ``Yes'' & Output $Y_{L1}$ \\
% 9 & $S_A$ (Answering) & ``No'' and number of alternative results $|Y_L'|>0$ & $S_A$ (Answering) \\
% 10 & $S_A$ (Answering) & ``No'' and number of alternative results $|Y_L'|=0$ & $S_P$ (Perception) \\
% \bottomrule[0.4mm]
% \end{tabular}}
% \caption{\textbf{State Transition Table for \methodname{} Finite-State Automaton.} Please refer to the \autoref{sec:perception} to
% % \autoref{sec:logic_generation}, \autoref{sec:logic_reasoning}, and 
% \autoref{sec:answering} for the details of transitions.}
% \label{tab:transitions}
% \end{table*}
\section{\methodname{}}
\label{sec:method}
% Our approach, \methodname{}, aims to complex visual grounding tasks that require complex reasoning, addressing limitations found in previous works~\cite{gupta2023visual, suris2023vipergpt, lu2023chameleon, wu2023visual}. The method leverages an automaton system for defining a flexible pipeline, and an explicit logic reasoning component using ProbLog generated by a LLM code generation. At a high-level, the automaton controls the process switching between the four states: Perception, Logic Generation, Logic Reasoning and Answering. To improve the robustness of the system, we design the validation mechanism in the full-chain of the pipeline. An overview of the framework is shown in \autoref{fig:pipeline}. 
% \subsection{Task Preliminary}
% Visual Grounding (VG) is a foundational task in computer vision, requiring systems to localize the specific objects within images according to textual queries. In this work, we focus on referring expression detection and segmentation as the VG tasks that require reasoning with object attributes and spatial relations among multiple elements within an image. Given the image $I$ and a textual query $Q$, the objective of \methodname{} is to produce reliable and interpretable grounding result $Y$ by reasoning explicitly in the automaton system with explicit logic, based on the input $X = \{Q, I\}$.

\methodname{} addresses complex visual grounding tasks that require complex reasoning, building on the limitations of previous works~\cite{gupta_visual_2023, suris_vipergpt_2023, lu_chameleon_2023, ke_hydra_2024}. In this work, we focus on referring expression detection and segmentation as the VG tasks that require reasoning with object attributes and relations among two or multiple entities within an image. Given the input $X=\{I, Q\}$ including image $I$ and a textual query $Q$, the objective of \methodname{} is to produce reliable and interpretable grounding result $Y$ satisfying the query $Q$. The proposed method is formulated as a \emph{deterministic finite-state automaton} for a flexible pipeline, and an explicit logic reasoning ability using ProbLog~\cite{de_raedt_problog_2007} code generated by an LLM. To improve the robustness of the system, the full-chain of the pipeline is validated in the automaton. With this design, the system maintains a similar computational complexity to that of previous compositional methods~\cite{ke_hydra_2024}, but achieves better performance (See \autoref{sec:quantitative}). An overview of the framework is shown in \autoref{fig:pipeline}.

\subsection{Deterministic Finite-State Automaton}
\label{sec:automaton}

A \emph{Deterministic Finite-State Automaton} (\dfa) is a mathematical model used to describe a system that moves deterministically between a finite number of defined states in response to specific inputs. Formally, a \dfa\ is a 5-tuple $\langle S, \Sigma, \delta, s_o, F \rangle$, where $S$ is a finite set of states, $\Sigma$ is a finite set of symbols, $\delta: S \times \Sigma \mapsto S$ a transition function between states based on the input symbol, $s_0 \in S$ an initial state, and $F\subseteq S$ a set of final states. Alternatively, a \dfa\ can be represented by a directed graph (or state diagram) whose vertices represent the states in $S$; its edges are labeled with elements from $\Sigma$ representing the transitions from $\delta$; $s_0$ is the only vertex with a single, empty incoming edge; and the final states in $F$ are indicated by double circles.

%A \dfa\  operates by existing in one state at any given time and transitioning from one state to another based on inputs or conditions; this transition mechanism defines how the system progresses. The \dfa\ has a predefined set of states, a designated initial state, and rules or conditions that determine when and how transitions occur. 
The design of \methodname{} is based on the \dfa\ shown in~\autoref{fig:pipeline}, which has five states: \emph{Perception} ($S_P$) which is the initial state, \emph{Logic Generation} ($S_L$), \emph{Logic Reasoning} ($S_R$),  \emph{Answering} ($S_A$), and \emph{Return Target} ($S_F$) which is the final state. The \dfa\ starts in the initial state $S_P$ and moves across states deterministically based on the transition function represented in \autoref{tab:transitions}, where the result of each condition maps to an element of alphabet $\Sigma$. Note that the \dfa\ can return to a previously visited state based on self-correction, thus improving the robustness of the pipeline. To prevent infinite loops within the \dfa, the system is programmed to terminate (i.e., to reach the final state \emph{Return Target}) after a defined number of retries during self-correction transitions (red arrow in \autoref{fig:pipeline}). Upon termination, the system returns the grounding target based on the currently collected information. 

Importantly, and unlike the conventional sequential pipelines used in previous compositional methods~\cite{ke_hydra_2024, shen_hugginggpt_2023, suris_vipergpt_2023, you_idealgpt_2023} where each step strictly follows the previous one, a \dfa{} allows for dynamic transitions between states based on intermediate results and specific conditions. This flexibility is critical not only for the self-correction mechanism mentioned above, but also for handling complex reasoning tasks, where the requirements for accurately visual grounding may vary depending on the context. %Besides, the self-correction mechanism can be naturally implemented in the \dfa, improving the robustness of the system.
The next subsections discuss the conditions and transitions of the \dfa{}.

%In \methodname{}, the flow of processing across four main states is managed by the \dfa, as shown in \autoref{tab:transitions}. The four states are \emph{Perception} ($S_P$), \emph{Logic Generation} ($S_L$), \emph{Logic Reasoning} ($S_R$), and \emph{Answering} ($S_A$). The automaton starts in the initial state \emph{Perception} ($S_P$) and proceeds sequentially, but it can also return to a previous state based on self-correction, improving the robustness of the pipeline. To prevent infinite looping within the \dfa, the system is programmed to terminate after a defined number of retries during self-correction transitions (red arrow in \autoref{fig:pipeline}). Upon termination, the system provides the grounding target based on the currently collected information. The next subsections discuss the conditions and transitions of the automaton.
%will be covered in the next subsections.


\begin{table}[t]
\centering
\scalebox{0.75}{
\begin{tabular}{c|ccc}
\toprule[0.4mm]
\rowcolor{mygray} \textbf{\#} & \textbf{Current} & \textbf{Condition} & \textbf{Next} \\ \hline \hline
1 & $S_P$ & Number of entities categories $|C|=0$. & $S_P$ \\
2 & $S_P$ & Number of entities $|E|<2$. & $S_A$ \\
3 & $S_P$ & Number of entities $|E|\geq 2$. & $S_L$ \\ \hline
4 & $S_L$ & ProbLog code generation error & $S_L$ \\
5 & $S_L$ & ProbLog code generation success & $S_R$ \\ \hline
6 & $S_R$ & Number of result $|Y_L|=0$ & $S_L$ \\
7 & $S_R$ & Number of result $|Y_L|>0$ & $S_A$ \\ \hline
8 & $S_A$ & Answer ``Yes'' & $S_F$ \\
9 & $S_A$ & ``No'' and number of alternative results $|Y_L'|>0$ & $S_A$ \\
10 & $S_A$ & ``No'' and number of alternative results $|Y_L'|=0$ & $S_P$ \\
\bottomrule[0.4mm]
\end{tabular}}
\vspace{-2.5mm}
\caption{\textbf{State transition table for \methodname{} finite-state automaton.} Please refer to the \autoref{sec:perception} to
% \autoref{sec:logic_generation}, \autoref{sec:logic_reasoning}, and 
\autoref{sec:answering} for the details of transitions.}
\label{tab:transitions}
\vspace{-4.5mm}
\end{table}


\subsection{Perception (\texorpdfstring{$\boldsymbol{S_P}$}{S\_P})}
\label{sec:perception}

% The \emph{Perception} state serves as the foundation for building explicit ProbLog~\cite{de_raedt_problog_2007} logic expressions that represent the query-related visual content of the image. To do so, it extracts relevant entities and their locations, transforming them into explicit probabilistic logic expressions. By extracting these elements, $S_P$ creates a filtered representation of the image, focusing only on entities related to the query. The motivation for designing dedicated \emph{Perception} state is to prepare the clean and formulated entities information for the following \emph{Logic Generation} state, making the system more interpretable and reducing computational complexity for later states.

The \emph{Perception} state is responsible for establishing an initial understanding of the image content in relation to the query, serving as the basis for explicit reasoning in subsequent states. This state is designed to extract and encode relevant visual entities. By extracting these elements, $S_P$ creates a filtered representation of the image, focusing only on entities relevant to the query. The motivation for designing a dedicated \emph{Perception} state is to prepare the clean and formulated entities information for the following \emph{Logic Generation} state, making the system more interpretable and reducing computational complexity for later states.

For establishing a semantic understanding between the query and the image, and helping later states focus on the most relevant entities, the \emph{Perception} state begins by using a Vision-Language Model (VLM) as captioner to generate a caption $I_c$ for the image $I$. Given the textual query $Q$, an LLM identifies and extracts entity categories of interest $C = \{C_1, C_2, ...\}$ by analyzing both the caption $I_c$ and the query $Q$. The $I_c$ will be shown to the LLM when using only the query $Q$ is not enough for finding the target $Y$. This step filters out irrelevant objects, highlighting only those that are likely to contribute to the reasoning and localize the target.

Once the relevant entity categories $C$ are extracted, a foundation grounding model is applied as an Entity Detector to localize entities $E=\{E_1, E_2, ...\}$ belonging to the categories $C$ within the image, obtaining precise bounding boxes or segmentation masks $Y_E$. Entity IDs are auto-generated to the entities for building the mapping between the location information $Y_E$ and logic symbols. The probability $P(E)$ is assigned by the confidences of the grounding model detection.

\textbf{State Transition:} If no entity categories of interest are detected ($|C| = 0$), the automaton remains in $S_P$ to retry perception with feedback prompting to LLM (Transition 1 in \autoref{tab:transitions}). If no entity is detected ($|E| = 0$), the fallback result detected by the entity detector with query $Q$ is used as the sub-optimal solution. If only one entity is detected ($|E| = 1$), no logic reasoning is needed as the entity can be the final output result, and the automaton directly transitions to Answering $S_A$ (Transition 2) for final verification. If two or more entities are detected ($|E| \geq 2$), the automaton moves to Logic Generation ($S_L$) to proceed with logic reasoning (Transition 3).

\subsection{Logic Generation (\texorpdfstring{$\boldsymbol{S_L}$}{S\_L})}
\label{sec:logic_generation}

To translates the extracted visual information and the text query into explicit logic representations for reasoning, the \emph{Logic Generation} state is designed to generate the ProbLog~\cite{de_raedt_problog_2007} logic code for reasoning. ProbLog is selected as the logic representation because it supports probabilistic logic, allowing the system to reason about the uncertainties that naturally arise in visual tasks (e.g., overlapping entities or ambiguous attributes). 

To model and reason about the visual content and query in logic, the process in the \emph{Logic Generation} state begins by taking the outputs from the \emph{Perception} state, which include the identified entities $E$ with their spatial locations $Y_E$,  grounding confidences $P(E)$ and associated categories $C$. Leveraging predefined ProbLog code templates, each entity is converted into a ProbLog \emph{fact} that declares its ID, category, bounding box coordinates, and probability. %Similarly, each detected relation between two entities (e.g., ``left of'', ``right of'') is represented as a ProbLog fact connecting the two entities to the type of relation they have. %; and each detected category of each entity is also represented as a ProbLog fact connecting the two. 
Code \hyperref[code:problog]{3.1} gives an example.

To translate the natural language query $Q$ into a ProbLog \emph{rule}, an LLM is used to interpret $Q$ in the context of the already encoded entities and relations. In addition, the relations and attributes of entities are involved to model the query for better abstraction and generalization abilities. The LLM receives as input the encoded ProbLog facts, along with the original query $Q$, and generates the corresponding ProbLog rule for querying the existence of target $Y$. For example, if the query is ``Find the person on the left wearing a blue shirt'', the LLM produces a ProbLog rule that matches any entity fulfilling these conditions from the query $Q$. 

However, while the relations and attributes may be included in the target ProbLog rule, they have not yet been perceived. To handle this, we parse the ProbLog query generated by the LLM and extract any relation symbols $\Gamma_R=\{\Gamma_{R1}, \Gamma_{R2}, ...\}$ and attribute symbols $\Gamma_A = \{\Gamma_{A1}, \Gamma_{A2}, ...\}$. Given the location of entity $Y_E$ and the potential attributes $\Gamma_A$, an attribute recognizer VLM is prompted to produce the probability of each attribute $P(A)$ being present in each entity of interest $E$. For example, if the query requires identifying ``Find the person on the left wearing blue shirt,'' the VLM will assess each entity's likelihood of having the attribute ``wearing blue shirt''. The attribute probabilities are then converted into ProbLog facts as before. Similarly, a relation recognizer including a VLM, a symbolic geometry analyzer and a depth estimator, is employed to produce the single-directional relations $R = \{R_{1,2}, R_{1,3}, ...\}$ with the probabilities $P(R)$. See Code \hyperref[code:problog]{3.1} for an example of ProbLog generated code.%\pjs{is this meant to say ''wearing a blue shirt''?}

\textbf{State Transition:} If an error is encountered during ProbLog code generation, the automaton stays in $S_L$ and retries the generation process with LLM (Transition 4 in \autoref{tab:transitions}). Upon successful generation of ProbLog code, the automaton transitions to the \emph{Logic Reasoning} state $S_R$ to proceed probabilistic inference (Transition 5).

\subsection{Logic Reasoning (\texorpdfstring{$\boldsymbol{S_R}$}{S\_R})}
\label{sec:logic_reasoning}

The \emph{Logic Reasoning} state performs probabilistic inference to identify the entities $E$ that best satisfies the query conditions. Probabilistic reasoning is essential here because it allows the system to weigh potential matches based on confidence levels when handling visual ambiguity. Using the logic programming language interpreter, the logic code representing entities, relations, attributes and query is executed to produce the target candidates $Y_L = \{Y_{L1}, Y_{L2}, ...\}$, with each result ranked according to its probability $P(Y_L)$. 
% \pjs{Since we are not training Scallop based model, we could try using a faster provenance like: minmaxprob, or addmultprob. My feeling is topproofs is really important when we are training the neural part of a neuro-symbolic system defined using Scallop}
The candidates produced in this step is the input for final confirmation in the \emph{Answering} state, providing a robust filtered list that can be verified with high confidence.

\textbf{State Transition:} If no results are produced ($|Y_L| = 0$), the automaton returns to the \emph{Logic Generation} state ($S_L$) to refine the logic expressions generated for the query (Transition 6 in \autoref{tab:transitions}). If one or more results are identified ($|Y_L| > 0$), the automaton proceeds to the \emph{Answering} state ($S_A$) for final verification (Transition 7).

\begin{prompt}[title={Code \thetcbcounter: ProbLog Code for Explicit Logic}] \label{code:problog}
\% entity(ID: str, category: str, x1: int, y1: int, x2: int, y2: int).\\
0.7435::entity(``person\_0'', ``person'', 360, 171, 480, 386).\\
0.4134::entity(``person\_1'', ``person'', 0, 142, 159, 478).\\
...\\
\% relation(entity\_a: str, entity\_b: str, value: str).\\
0.0001::relation(``person\_0'', ``person\_1'', ``is'').\\
0.9986::relation(``person\_0'', ``person\_1'', ``left of'').\\
\% attribute(entity: str, value: str).\\
0.8711::attribute(``person\_0'', ``wearing\_blue\_shirt'').\\
0.1468::attribute(``person\_1'', ``wearing\_blue\_shirt'').\\
...\\
\% find person on the left wearing blue shirt\\
target(ID) :- entity(ID, ``person'', \_, \_, \_, \_), relation(ID, \_, ``left of''), attribute(ID, ``wearing\_blue\_shirt'').\\
query(target(ID)).
\end{prompt}

% \subsection{Answering (${S_A}$)}
\subsection{Answering (\texorpdfstring{$\boldsymbol{S_A}$}{S\_A})}
\label{sec:answering}

The \emph{Answering} state serves as a final verification step to ensure that the top-ranked candidate from the \emph{Logic Reasoning} state aligns with the query’s requirements. The reasoning output is prompted to an answerer VLM to confirm if the predicted target entity meets the query. This validation step ensures the output aligns with the query’s intent before returning it as the final result.

To help the answerer VLM better access the top-ranked result $V_{L1}$ from the \emph{Logic Reasoning} state in the image $I$, the image is annotated with $V_{L1}$ to highlight the identified entity within the visual context~\cite{yang_set--mark_2023}. This annotated image is given as input to the answerer VLM, with a prompt asking whether the annotated object satisfies the query $Q$. To ensure a controlled response, we use the next-token prediction of VLM to calculate the probability of receiving a ``Yes'' or ``No'' answer, and the response with the higher probability is selected.


\textbf{State Transition:} If the answerer responds with ``Yes”, the automaton proceeds to the final state $S_F$ and returns the $Y_{L1}$ as the \textbf{final output} (Transition 8 in \autoref{tab:transitions}). If the response is ``No” and there are alternative results ($|Y_L'| > 0$) where $Y_L' = Y_L \setminus \{Y_{L1}\}$, the automaton stays in $S_A$ to evaluate the top-ranked candidate of the remaining candidate results $Y_L := Y_L'$ (Transition 9). If the response is “No” and there are no other candidates ($|Y_L'| = 0$), the automaton returns to Perception $S_P$ to gather new visual information (Transition 10). %pjs{Unclear to me how the automaton chooses which state should be refined when the top-ranked result is not confirmed?}
