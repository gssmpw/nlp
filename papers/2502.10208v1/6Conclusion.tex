\section{Conclusion}
%In work proposes a novel supervised graph sparsification method that performs. 
% The batch partitions of edges for large graphs keeping locality are left for future work.

% \Sid To do concluding remarks with limitation, future work.

We proposed \sgs, a supervised graph sparsifier that produces a sparse subgraph with user-prescribed sparsity facilitating GNNs on large-scale graphs. We provided a theoretical analysis of \sgs in terms of the quality of embedding it produces compared to an idealized, oracle sparsifier. Finally, we empirically validated the effectiveness, efficiency, and convergence of \sgs over several baselines across homophilic and heterophilic graphs of various sizes. In the future, we plan to explore 
% more general problems e.g., task-specific hypergraph sparsification and 
robustness aspect of our sparsifier in defense against adversarial noise.
% regularizers and conditional update of probability distribution learner with prior can improve performance in heterophilic and homophilic graphs with sparse subgraphs. 

% For large graphs, we use METIS for partition to have edges in the same locality; we will explore other options in the future. 