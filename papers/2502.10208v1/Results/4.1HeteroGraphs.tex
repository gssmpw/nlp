% Please add the following required packages to your document preamble:
% \usepackage{booktabs}
\begin{comment}
\begin{table}[!htbp]
\centering
\resizebox{1.0\linewidth}{!}
{
\def\arraystretch{1.0}
\begin{tabular}{@{}l|c|ccc@{}}
\toprule
\textbf{Dataset} & \textbf{Whole Graph}     & \textbf{Random}   & \textbf{Edge}              & \textbf{SGS-GNN}           \\\midrule
Cornell          & 43.78 $\pm$ 4.32 & 49.19 $\pm$ 4.65  & 46.49 $\pm$ 2.65          & \textbf{74.59 $\pm$ 1.32} \\
Texas            & 61.62 $\pm$ 1.08 & 55.14 $\pm$ 5.01  & 69.19 $\pm$ 2.76          & \textbf{76.22 $\pm$ 2.02} \\
Wisconsin        & 51.76 $\pm$ 5.49 & 61.96 $\pm$ 4.40  & 66.27 $\pm$ 2.29          & \textbf{76.08 $\pm$ 3.14} \\
reed98           & 61.35 $\pm$ 0.84 & 54.92 $\pm$ 2.64  & 54.51 $\pm$ 1.98          & \textbf{64.15 $\pm$ 2.28} \\
amherst41        & 61.83 $\pm$ 0.30 & 57.49 $\pm$ 0.81  & 57.40 $\pm$ 0.58          & \textbf{72.75 $\pm$ 0.59} \\
penn94           & 73.23 $\pm$ 0.05 & 68.52 $\pm$ 0.34  & 68.35 $\pm$ 0.36          & \textbf{75.65 $\pm$ 0.41} \\
Roman-empire     & 44.25 $\pm$ 0.16 & 43.08 $\pm$ 0.61  & 42.91 $\pm$ 0.63          & \textbf{64.69 $\pm$ 0.12} \\
cornell5         & 65.13 $\pm$ 0.31 & 63.36 $\pm$ 0.50  & 63.47 $\pm$ 0.46          & \textbf{69.15 $\pm$ 0.33} \\
Squirrel         & 48.38 $\pm$ 0.65 & 42.40 $\pm$ 0.96  & 42.44 $\pm$ 1.10          & \textbf{52.35 $\pm$ 0.35} \\
johnshopkins55   & 68.71 $\pm$ 0.28 & 63.40 $\pm$ 0.53  & 62.80 $\pm$ 0.74          & \textbf{71.64 $\pm$ 0.33} \\
Actor            & 28.42 $\pm$ 0.23 & 32.37 $\pm$ 0.78  & 30.53 $\pm$ 0.59          & \textbf{33.88 $\pm$ 0.42} \\
Minesweeper      & 79.56 $\pm$ 0.03 & 79.73 $\pm$ 0.12  & 79.84 $\pm$ 0.06          & \textbf{80.00 $\pm$ 0.00} \\
Questions        & 97.05 $\pm$ 0.01 & 97.07 $\pm$ 0.03  & \textbf{97.08 $\pm$ 0.01} & 97.05 $\pm$ 0.01          \\
Chameleon        & \textbf{64.43 $\pm$ 0.43} & 57.98 $\pm$ 1.39  & 57.11 $\pm$ 1.22          & 62.37 $\pm$ 0.98 \\
Tolokers         & 79.03 $\pm$ 0.15 & 78.59 $\pm$ 0.16  & 78.59 $\pm$ 0.21          & \textbf{79.46 $\pm$ 0.17} \\
Amazon-ratings   & 46.72 $\pm$ 0.20 & 45.70 $\pm$ 0.21  & 45.75 $\pm$ 0.35          & \textbf{50.15 $\pm$ 0.34} \\
genius           & 80.80 $\pm$ 0.02 & 81.99 $\pm$ 0.09  & 81.60 $\pm$ 0.03          & \textbf{82.59 $\pm$ 0.00} \\
pokec            & 62.05 $\pm$ 0.37 & 60.30 $\pm$ 0.27  & 60.17 $\pm$ 0.17          & \textbf{60.49 $\pm$ 0.10} \\
arxiv-year       & 39.05 $\pm$ 0.08 & 36.96 $\pm$ 0.01  & 37.06 $\pm$ 0.04          & \textbf{38.42 $\pm$ 0.10} \\
snap-patents     & 35.38 $\pm$ 0.15 & 34.57 $\pm$ 0.08  & 34.48 $\pm$ 0.16          & \textbf{35.41 $\pm$ 0.10} \\
ogbn-proteins & 93.15 $\pm$ 0.00 & \textbf{93.15 $\pm$ 0.00} & \textbf{93.15 $\pm$ 0.00} & \textbf{93.15 $\pm$ 0.00} \\\bottomrule
\textbf{Geom. Mean}	 & 58.42 $\pm$ 0.04 &	57.25 $\pm$ 0.08 &	57.63 $\pm$ 0.07	&64.67 $\pm$ 0.00
\end{tabular}
}
\caption{Average F1 score (in \%) $\pm$ standard deviation of various samplers on heterophilic graphs, using $20\%$ edges for training sparsifiers. Bold results show the best-performing sparsifier. The baseline \textit{Whole Graph} refers to ClusterGCN, indicating GNN performance with the full graph.}
\label{tab:hetero_graphs}
\end{table}
\end{comment}

\begin{table}[t]
\caption{Mean F1-scores (in \%) $\pm$ std. dev. of various fixed distribution samplers using $20\%$ edges. \textbf{Bold} indicates best-performing sampler excluding \textit{Org. graph}.}
\label{tab:hetero_homo_graphs}
\centering
\begin{sc}
\resizebox{1.0\linewidth}{!}
{
\def\arraystretch{1.0}
\begin{tabular}{@{}l|c|cccc@{}}
\toprule
\textbf{Dataset} & \textbf{Org. Graph}     & \textbf{Random}   & \textbf{Edge}              & 
\textbf{ER} & \textbf{SGS-GNN}           \\\midrule
Cornell & 43.78 $\pm$ 4.32 & 49.19 $\pm$ 4.65 & 46.49 $\pm$ 2.65 & 43.78 $\pm$ 3.97 & \textbf{74.59 $\pm$ 1.32} \\
Texas & 61.62 $\pm$ 1.08 & 55.14 $\pm$ 5.01 & 69.19 $\pm$ 2.76 & 61.08 $\pm$ 2.76 & \textbf{76.22 $\pm$ 2.02} \\
Wisconsin & 51.76 $\pm$ 5.49 & 61.96 $\pm$ 4.40 & 66.27 $\pm$ 2.29 & 58.82 $\pm$ 2.15 & \textbf{76.08 $\pm$ 3.14} \\
reed98 & 61.35 $\pm$ 0.84 & 54.92 $\pm$ 2.64 & 54.51 $\pm$ 1.98 & 59.69 $\pm$ 2.03 & \textbf{64.15 $\pm$ 2.28} \\
amherst41 & 61.83 $\pm$ 0.30 & 57.49 $\pm$ 0.81 & 57.40 $\pm$ 0.58 & 50.60 $\pm$ 1.14 & \textbf{72.75 $\pm$ 0.59} \\
penn94 & 73.23 $\pm$ 0.05 & 68.52 $\pm$ 0.34 & 68.35 $\pm$ 0.36 & 70.74 $\pm$ 0.39 & \textbf{75.65 $\pm$ 0.41} \\
Roman-empire & 44.25 $\pm$ 0.16 & 43.08 $\pm$ 0.61 & 42.91 $\pm$ 0.63 & 58.18 $\pm$ 1.25 & \textbf{64.69 $\pm$ 0.12} \\
cornell5 & 65.13 $\pm$ 0.31 & 63.36 $\pm$ 0.50 & 63.47 $\pm$ 0.46 & 63.89 $\pm$ 0.35 & \textbf{69.15 $\pm$ 0.33} \\
Squirrel & 48.38 $\pm$ 0.65 & 42.40 $\pm$ 0.96 & 42.44 $\pm$ 1.10 & 43.86 $\pm$ 0.42 & \textbf{52.35 $\pm$ 0.35} \\
johnshopkins55 & 68.71 $\pm$ 0.28 & 63.40 $\pm$ 0.53 & 62.80 $\pm$ 0.74 & 62.14 $\pm$ 2.51 & \textbf{73.80 $\pm$ 0.33} \\
Actor & 28.42 $\pm$ 0.23 & 32.37 $\pm$ 0.78 & 30.53 $\pm$ 0.59 & 32.03 $\pm$ 0.27 & \textbf{33.88 $\pm$ 0.42} \\
Minesweeper & 79.56 $\pm$ 0.03 & 79.73 $\pm$ 0.12 & 79.84 $\pm$ 0.06 & 80.02 $\pm$ 0.03 & \textbf{80.00 $\pm$ 0.00} \\
Questions & 97.05 $\pm$ 0.01 & 97.07 $\pm$ 0.03 & \textbf{97.08 $\pm$ 0.01} & 97.02 $\pm$ 0.00 & 97.05 $\pm$ 0.01 \\
Chameleon & 64.43 $\pm$ 0.43 & 57.98 $\pm$ 1.39 & 57.11 $\pm$ 1.22 & 59.78 $\pm$ 0.85 & \textbf{62.37 $\pm$ 0.98} \\
Tolokers & 79.03 $\pm$ 0.15 & 78.59 $\pm$ 0.16 & 78.59 $\pm$ 0.21 & 78.10 $\pm$ 0.06 & \textbf{79.98 $\pm$ 0.17} \\
Amazon-ratings & 46.72 $\pm$ 0.20 & 45.70 $\pm$ 0.21 & 45.75 $\pm$ 0.35 & 44.39 $\pm$ 0.12 & \textbf{50.15 $\pm$ 0.34} \\
genius & 80.80 $\pm$ 0.02 & 81.99 $\pm$ 0.09 & 81.60 $\pm$ 0.03 & 82.25 $\pm$ 0.86 & \textbf{82.59 $\pm$ 0.00} \\
pokec & 62.05 $\pm$ 0.37 & 60.30 $\pm$ 0.27 & 60.17 $\pm$ 0.17 & 58.76 $\pm$ 0.59 & \textbf{60.49 $\pm$ 0.10} \\
arxiv-year & 39.05 $\pm$ 0.08 & 36.96 $\pm$ 0.01 & 37.06 $\pm$ 0.04 & 36.62 $\pm$ 0.33 & \textbf{38.42 $\pm$ 0.10} \\
snap-patents & 35.38 $\pm$ 0.15 & 34.57 $\pm$ 0.08 & 34.48 $\pm$ 0.16 & 33.13 $\pm$ 0.37 & \textbf{35.41 $\pm$ 0.10} \\
ogbn-proteins & 93.15 $\pm$ 0.00 & 93.15 $\pm$ 0.00 & 93.15 $\pm$ 0.00 & 93.15 $\pm$ 0.00 & 93.15 $\pm$ 0.00 \\\midrule \midrule
Cora & 67.29 $\pm$ 0.51 & 61.20 $\pm$ 7.76 & 57.63 $\pm$ 14.73 & \textbf{66.90 $\pm$ 0.17} & 65.58 $\pm$ 0.69 \\
DBLP & 83.92 $\pm$ 0.04 & 81.00 $\pm$ 0.27 & 81.19 $\pm$ 0.33 & \textbf{81.81 $\pm$ 0.10} & 80.37 $\pm$ 0.16 \\
Computers & 90.19 $\pm$ 0.18 & 90.34 $\pm$ 0.29 & 90.37 $\pm$ 0.25 & 89.87 $\pm$ 0.96 & \textbf{90.97 $\pm$ 0.31} \\
PubMed & 86.73 $\pm$ 0.07 & 87.58 $\pm$ 0.22 & 87.62 $\pm$ 0.14 & \textbf{87.70 $\pm$ 0.11} & 87.52 $\pm$ 0.15 \\
Cora\_ML & 86.29 $\pm$ 0.51 & 85.39 $\pm$ 0.35 & 85.29 $\pm$ 0.60 & \textbf{85.63 $\pm$ 0.51} & 83.99 $\pm$ 0.53 \\
SmallCora & 80.28 $\pm$ 0.37 & 75.82 $\pm$ 0.54 & 76.44 $\pm$ 1.21 & 75.90 $\pm$ 1.25 & \textbf{76.94 $\pm$ 0.76} \\
CS & 92.79 $\pm$ 0.10 & 94.07 $\pm$ 0.14 & 94.09 $\pm$ 0.09 & 93.77 $\pm$ 0.17 & \textbf{94.25 $\pm$ 0.15} \\
Photo & 92.41 $\pm$ 2.01 & 93.54 $\pm$ 0.14 & 93.63 $\pm$ 0.25 & 93.42 $\pm$ 0.10 & \textbf{93.99 $\pm$ 0.25} \\
Physics & 96.08 $\pm$ 0.03 & 96.20 $\pm$ 0.07 & 96.23 $\pm$ 0.12 & 96.22 $\pm$ 0.07 & \textbf{96.27 $\pm$ 0.09} \\
CiteSeer & 91.44 $\pm$ 0.29 & 86.38 $\pm$ 0.26 & 86.75 $\pm$ 0.22 & 86.24 $\pm$ 0.26 & \textbf{86.78 $\pm$ 0.28} \\
wiki & 80.07 $\pm$ 0.21 & 80.10 $\pm$ 0.13 & 80.19 $\pm$ 0.16 & 80.32 $\pm$ 0.13 & \textbf{81.49 $\pm$ 0.31} \\
Reddit & 91.43 $\pm$ 0.07 & 91.39 $\pm$ 0.06 & 91.35 $\pm$ 0.08 & 91.00 $\pm$ 0.06 & \textbf{91.45 $\pm$ 0.06} \\\bottomrule
\rowcolor[HTML]{EFEFEF} 
\textbf{Geom. Mean}	 & 67.30	& 66.01	& 66.20	& 66.51 & 71.55
\end{tabular}
}
\end{sc}
\end{table}
% \end{wrapfigure}

