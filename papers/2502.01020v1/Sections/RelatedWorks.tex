Prior researchers~\cite{meli2019bad,rahman2019share,rahman2019seven, igibeksecret, rahman2021different, krause2023pushed} studied the root causes of secret exposure and found that keeping hard-coded secrets in software artifacts as the most prevalent insecure practices among developers, leading to secret leaks. Meli et al.~\cite{meli2019bad} found over 100K hard-coded secrets by studying a 13\% snapshot of GitHub repositories in 2019. Within Infrastructure as Code (IaC) scripts, Rahman et al.~\cite{rahman2019seven}  found 7 ``Security Smells'' by studying 5,232 IaC scripts from 293 repositories. They found that hard-coded secrets are the most prevalent among the security smells, with 1,326 occurrences. Rayhanur et al.~\cite{rahman2019share} studied 5,822 Python Gists in GitHub and found 689 hard-coded secrets, thus indicating that hard-coded secrets have been leaked in various forms of software artifacts.

To prevent secret leaks in software artifacts, researchers~\cite{krause2023pushed,basaksecretpractice, basakchallenges} recommended developers follow secure practices for secret management. Basak et al.~\cite{basaksecretpractice} conducted a grey literature review of Internet artifacts in 2022 and found 24 developer and organization practices for secure secret management. They suggested using VCS scan tools to prevent accidental secret commits. They also studied the developer's challenges for checked-in secrets by analyzing 779 questions from Stack Exchange (SE) and the solutions suggested to mitigate the challenges by SE users~\cite{basakchallenges}. The SE users also suggested using VCS scan tools to prevent accidental secret commits. However, Basak et al.~\cite{basak2023compare} found VCS scan tools outputting 25-99\% false positives and missing 14-99\% of secrets of a repository by comparing 5 open-source and 4 proprietary tools against SecretBench~\cite{secretbench}. Though Machine Learning (ML) algorithms~\cite{fengsecret, secrethunter, konygin2023using} have been used to reduce false positives, Basak et al.~\cite{basak2023compare} found 2 tools (Commercial X and SpectralOps~\cite{spectralops}) employing ML among the 9 tools showed lower precision of 25\% and 1\%, respectively. Additionally, Rayhanur et al.~\cite{rahman2022secret} found developers ignoring secret alerts due to high false positives and time pressure through a developer survey in a company (anonymized). Basak et al.~\cite{assetharvester} developed AssetHarvester, a static analysis tool to detect asset identifiers protected by secrets. Since each secret-asset pair poses a different security risk, we built upon their work and studied to provide security risk scores for secret-asset pairs to aid developers in prioritizing secret removal. 