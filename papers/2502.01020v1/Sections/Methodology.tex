In this section, we explain the process of RiskBench curation, identifying the value of asset and ease of attack patterns for calculating security risk score, and the developer survey.

\subsection{RiskBench Curation} \label{RiskBench}

To select a dataset of secret-asset pairs for calculating security risk score, we started with AssetBench~\cite{assetharvester}, a publicly-available dataset of secret-asset pairs. We accessed the dataset through Google Cloud (ID: \seqsplit{dev-range-332204.assetbench}). The authors of AssetBench curated 818 repositories from the September 2022 snapshot of GitHub's Google BigQuery Dataset (ID: bigquery-public-data.github\_repos)~\cite{google-big-query}. The dataset contains 97,479 manually labeled secrets (as true or false), extracted using two open-source secret detection tools, TruffleHog~\cite{trufflehog} and Gitleaks~\cite{gitleaks}. In addition, two authors of AssetBench manually inspected candidate asset-containing files to identify the assets protected by the corresponding secrets. The dataset also provides metadata such as repository name, commit ID, file path, and the line number where the secret-asset pairs have been identified. However, the dataset does not contain the database keywords (database, table, and column names) and corresponding sensitive data categories for each secret-asset pair. Additionally, the dataset lacks information on whether the asset identifier is a placeholder. In our study, we have utilized the database keywords, data categories, and asset identifiers for calculating the value of asset and ease of attack (Section~\ref{RiskHarvester}). Thus, to evaluate the performance of RiskHarvester in identifying the value of asset and ease of attack for each secret-asset pair (RQ1), we extended the dataset as \textit{RiskBench} by including the additional information.

\textbf{Filtering Dataset}: Before identifying the value of asset and ease of attack information for each secret-asset pair, we applied the following selection criteria to filter AssetBench. 

\textit{\uline{Criteria 1 (Programming Language):}} According to the 2023 GitGuardian report~\cite{gitguardian-secret-sprawl-2023}, developers most frequently exposed secrets in source code written in Python in GitHub. Thus, we selected repositories containing Python source code in our study. We selected 188 repositories from 818 repositories and 34,569 secrets from 97,479 secrets of AssetBench.     


\textit{\uline{Criteria 2 (Secret Type):}} The 2024 GitGuardian report~\cite{gitguardian-secret-sprawl} reveals that out of 12.8 million exposed secrets in public GitHub repositories, the top secret type is database secrets. Thus, we selected database secret-asset pairs to calculate the security risk score in our study. However, we need to narrow the scope to maintain our study's feasibility since multiple database providers are present. We observed that according to the Stack Overflow Developer Survey 2024~\cite{SOdevelopersurvey2024}, the top five databases used by developers are PostgreSQL~\cite{postgresql}, MySQL~\cite{mysql}, SQLite~\cite{sqlite}, SQL Server~\cite{sqlserver}, and MongoDB~\cite{mongodb}. However, we excluded SQLite since SQLite is a file-based database requiring no authentication. Finally, we filtered the secret-asset pairs of the four databases and selected 1,791 secret-asset pairs from 34,569 secrets.

Table~\ref{asset-types} shows the number of secret-asset pairs of the four database types with the percentage of each type. We observed that only 25 secret-asset pairs (1.4\% of the total) are present for SQL Server. The lower percentage may be due to SQL Server's proprietary nature, limiting the adoption in open-source projects compared to open-source databases.

\input{Tables/AssetBenchStat}

\textbf{Identifying Database Keywords, Sensitive Data Categories, and Asset Identifier Information}: To identify the database keywords, the first and second authors of the paper manually inspected each secret-asset pair using the repository name, commit ID, file path, and line number provided by the dataset. Since the keywords, such as table and column names, may not be present in the same file where the asset is located, both authors inspected the candidate database keywords containing files in the repository. Finally, the database name, corresponding table, and column names are collected.

Next, to assign a sensitive data category for each database keyword, we utilized the data categories provided by Google Cloud Data Loss Prevention (DLP)~\cite{google-dlp}. The Google Cloud DLP is a service that helps organizations discover and classify sensitive data to comply with GDPR, HIPAA, and PCI-DSS regulations~\cite{google-dlp}. The Google Cloud DLP provides 192 sensitive data categories grouped into 7 domains. These 7 domains include Personally Identifiable Information (PII), such as a name, and Sensitive Personally Identifiable Information (SPII), such as a passport number. In addition, each data category is assigned a sensitivity level (``HIGH'', ``MODERATE'' and ``LOW''). Table~\ref{sensitive-data-types} presents an example of a data category and the corresponding sensitivity level in each domain. However, we observed that data categories contain similar information. For example, data categories such as ``CANADA\_PASSPORT'' and ``US\_PASSPORT'' contain passport information, and these data categories have the same sensitivity level. Since we will compute the similarity score of a database keyword with the data category (Step 2.2, Section~\ref{RiskHarvester}) to assign the correct data category, reducing the number of comparisons will improve the mapping performance. Thus, we manually inspected each data category and merged similar categories into a generic data category such as ``PASSPORT''. Finally, we identified 113 data categories. Both authors independently assigned a data category to each database keyword.   

\input{Tables/SensitiveDataType}

Next, both authors inspected the asset identifier for a secret and labeled whether the database host is a placeholder considering the asset source code context. The agreement of finding the database keywords, corresponding data categories, and if the host is a placeholder with a Cohen's Kappa~\cite{cohen-kappa} score of 0.88, 0.93, and 0.85, respectively, between the two authors. These scores indicate a ``near perfect agreement'' according to Landis and Koch's interpretation~\cite{landis-koch}. The disagreements were resolved after a discussion between the two authors.


\subsection{Value of Asset and Ease of Attack Patterns} \label{Patterns}

For each secret-asset pair, we calculated the security risk score as the product of the value of asset and ease of attack, as defined in Equation~\ref{eqriskscore}. This security risk computation is based upon the hypothesis that attackers are more likely to succeed in attacking assets of high value and that are easier to attack.

% \setlength{\abovedisplayskip}{0pt}
% \setlength{\belowdisplayskip}{4pt}
\begin{gather} \label{eqriskscore}
    \begin{aligned}[b]
        \textnormal{Security Risk = (Value of Asset) x (Ease of Attack)}
   \end{aligned}  
\end{gather}

The first and second authors independently inspected a random sample of 50 secret-asset pairs from RiskBench and developed patterns for programmatically calculating the value of asset and ease of attack for each secret-asset pair. Now, we describe the observed patterns, which form the basis of RiskHarvester construction in calculating security risk score (Section~\ref{RiskHarvester}). The source code snippets of Figure~\ref{fig:value-of-asset-infer} and~\ref{fig:value-of-asset-patterns} are taken from RiskBench repositories of the 50 secret-asset pairs.

\textbf{Value of Asset Patterns}: A database asset identifier has three parts (host, port, and database name)~\cite{asset-identifier}. We observed that the asset's value can be inferred from the database name since the name reveals the type of data the database contains. Figure~\ref{fig:only-db-name} shows that a patient (\texttt{"db\_patient"}) and a test log (\texttt{"log\_test"}) database is passed in the \texttt{"db"} arguments where the value of patient database will be relatively higher than that of a test log database. However, we may not always be able to infer the database's data from the database name. Figure~\ref{fig:table-column-name} shows that the database name is \texttt{"my-db"} (line 5), posing difficulty in inferring the value of the asset. However, we observed that the database asset has been configured in line 7, and a SQL query is executed to access the user table containing the email column. Thus, we can retrieve the type of data of the database from the table and column names which we used to calculate the value of asset (Step 2.2, Section~\ref{RiskHarvester}). 

We now describe the three mutually exclusive patterns observed in the database, table, and column name locations for an asset identifier. The numbers in parentheses denote occurrences of each pattern in 50 secret-asset pairs.

\begin{figure}[!t]
    \centering
    \begin{subfigure}[b]{\columnwidth}
        \centering
        \includegraphics[width=\columnwidth, frame]{Figures/value_of_asset_types.pdf}
        \caption[]{{The value of asset can be inferred from the database name}}
        \label{fig:only-db-name}
    \end{subfigure}
\vskip\baselineskip
    \begin{subfigure}[b]{\columnwidth}
        \centering
        \includegraphics[width=\columnwidth, frame]{Figures/value_of_asset_in_tables.pdf}
        \caption[]{{The value of asset can be inferred from table and column names}}
        \label{fig:table-column-name}
    \end{subfigure}
\caption{Asset's value can be inferred from the database name, table names, and column names from the source code.}
\label{fig:value-of-asset-infer}
\end{figure}



\textit{\uline{V-Pattern 1 (SQL Database Driver Calls) (25)}}: We observed that the database name and the corresponding table and column names of relational databases can be found in the SQL database drivers, such as MySQL drivers~\cite{pymysql}. These SQL database drivers provide functions to connect to databases, execute queries, manage transactions, and fetch results. We observed that the database name is passed in the same function where the database secret and server address information is also passed to set up the connection. For example, Figure~\ref{fig:vpattern1} shows that the database name (\texttt{"db\_patient"}) is passed in \texttt{pymysql.connect} function (line 4). Additionally, the corresponding database table and column names are present in raw SQL queries passed in query functions of SQL database drivers such as the ``execute'' function (line 7, Figure~\ref{fig:vpattern1}). 

\textit{\uline{V-Pattern 2 (NoSQL Database Driver Calls) (16)}}: The database, table, and column names of non-relational databases can be found in the NoSQL database drivers, such as MongoDB drivers~\cite{mongodb-driver}. Unlike relational databases, non-relational databases are document or key-value pair databases without a structured schema. The table and column names are referred to as collection and field names, respectively. Figure~\ref{fig:vpattern2} shows that the database name and collection name are passed as a dictionary key to the NoSQL driver client and db instance in lines 2 and 3, respectively. However, the field names are passed as key-value pairs in a dictionary object instead of as a raw SQL string to the driver query function (lines 7-8), where each key is the field name of the corresponding collection.

\textit{\uline{V-Pattern 3 (ORM Framework Calls) (9)}}: We observed that the database name and the corresponding table and column names of relation databases can be found in Object Relational Mapper (ORM) framework calls~\cite{ORM}, such as SQLAlchemy~\cite{sqlalchemy}. Unlike other drivers, ORM abstracts database access through objects rather than directly managing the access with raw SQL queries. Figure~\ref{fig:vpattern3} shows that the database name (\texttt{"portfolio"}) is defined in a connection string along with secret and server address and passed to ORM configuration (line 4). Since ORM maps tables in a relational database to classes and rows to instances of those classes, the table name and column names can be found in these classes. The \texttt{"\_\_tablename\_\_"} attribute defines the table name (line 11), and the other attributes define the column names, such as username and password (lines 14-15), as shown in Figure~\ref{fig:vpattern3}.


\begin{figure*}[!ht]
    \centering
    % Left column with two images stacked vertically
    \begin{minipage}{0.49\textwidth} % Top alignment
        \centering
        % Image (a)
        \begin{subfigure}[b]{\textwidth}
            \centering
            \includegraphics[width=\textwidth, frame]{Figures/value-of-asset-pattern1.pdf}
            \caption[]{{V-Pattern 1 (SQL Database Driver Calls)}}
            \label{fig:vpattern1}
        \end{subfigure}
        \vskip\baselineskip % Adds space between (a) and (b)
        % Image (b)
        \begin{subfigure}[b]{\textwidth}
            \centering
            \includegraphics[width=\textwidth, frame]{Figures/value-of-asset-pattern2.pdf}
            \caption[]{{V-Pattern 2 (NoSQL Database Driver Calls)}}
            \label{fig:vpattern2}
        \end{subfigure}
    \end{minipage}
    \hfill
    % Right column with one image
    \begin{minipage}{0.49\textwidth} % Top alignment
        \centering
        % Image (c)
        \begin{subfigure}[b]{\textwidth}
            \centering
            \includegraphics[width=\textwidth, frame]{Figures/value-of-asset-pattern3.pdf}
            \caption[]{{V-Pattern 3 (ORM Framework Calls)}}
            \label{fig:vpattern3}
        \end{subfigure}
    \end{minipage}
\caption{We identified three patterns to locate database, table, and column names for each secret-asset pair in the source code.}
\label{fig:value-of-asset-patterns}
\end{figure*}

\textbf{Ease of Attack Patterns}: Similar to the value of an asset, ease of accessing the asset can vary based on multiple factors. For example, attackers can more easily access an asset with a public IP address, whereas attackers can not directly access an asset on a localhost. Since the server address is defined as a combination of host and port, we can infer the ease of accessing the asset from these parts of the asset identifier. 

Now, we describe the observed four patterns in the asset identifiers in the source code. The numbers in parentheses denote occurrences of each pattern in 50 secret-asset pairs.

\textit{\uline{E-Pattern 1 (DNS Name) (27)}}: We observed that developers put a DNS name, such as (\texttt{"sh1.cirray.cn"}), in the host part of the asset identifier as a database server address in the source code. However, not all the DNS names are resolved to IP addresses due to non-existent domains, misconfigured DNS records, or expired domains. In addition, we observed invalid DNS names that are not valid according to DNS name format or a placeholder/dummy such as \texttt{"your-project-name.com"}. Thus, the ease of attack of a secret-asset pair differs if DNS is resolvable (Steps 3.1.1 and 3.1.2, Section~\ref{RiskHarvester}).

\textit{\uline{E-Pattern 2 (IP Address) (23)}}: Developers put IP addresses such as (\texttt{\seqsplit{"185.60.21.35"}}) instead of DNS name as database server addresses in the host part of the asset identifier. However, not all the IP addresses are routable addresses. For example, localhost address (\texttt{"127.0.0.1"}) or private IP addresses (\texttt{"192.168.1.1"}) pose more difficulty to external attackers to access the asset than public IP addresses. We also observed invalid or placeholder IP addresses such as \texttt{"x.x.x.x"} or \texttt{"0.0.0.0"} that attackers can not leverage to access the asset. Thus, the ease of attack of a secret-asset pair differs if the IP address is routable (Steps 3.1.3 and 3.1.4, Section~\ref{RiskHarvester}).

\textit{\uline{E-Pattern 3 (Scannable) (7)}}: Not all the public IP addresses that are either present directly in the host or resolved from the DNS names are scannable since IP addresses can be present behind firewalls or other security measures. Scannable means the discovery of active services through network scans. The IP addresses that are scannable are easier to attack than those of non-scannable IP addresses (Step 3.1.5, Section~\ref{RiskHarvester}).

\textit{\uline{E-Pattern 4 (Port Open) (4)}}: Developers include the database server's port number in the asset identifier, such as port 3306 for MySQL database. If the IP address is publicly accessible and the database port is open, the attackers can more easily access the database. In contrast, access is relatively difficult if the database port is closed or restricted (Step 3.1.6, Section~\ref{RiskHarvester}). We observed four ports open in the 50 secret-asset pairs that we inspected using Censys~\cite{censys}, an online service that provides the port information of a host.



\input{Tables/SurveyQuestions}


\subsection{Developer Survey} To answer RQ2, we conducted a survey to understand whether developers prioritize the removal of secrets consistent with our hypothesis (based on the descending security risk scores).

\textbf{Participant Selection}: To find survey participants, we selected the developers who committed the secret-asset pairs in RiskBench. We selected these developers since they have experience with software secrets. We observed that the same developer committed multiple secret-asset pairs in a repository. Thus, we identified unique 1,478 committers from the 1,791 secret-asset pairs of RiskBench. In addition, we filtered out committers having a noreply (\seqsplit{xxx@noreply.github.com}) or GitHub Actions bot email address~\cite{github-no-reply} and selected 1,282 committers. Finally, we randomly selected 500 committers to avoid selection bias~\cite{selection-bias} to participate in the online survey.

\textbf{Survey Design}: Table~\ref{survey-ques} presents the four questions of the developer survey. We provided three alerts of database secrets of GitHub repositories detected by TruffleHog~\cite{trufflehog}. For each alert, we provided the secret, the ``Severity'' level, and the repository and file location provided by TruffleHog. Based on the alert information, we asked developers in which order they would prioritize secret removal and why. We hypothesize that developers will choose Secret A first without considering the asset information since Secret A looks like an actual password. Next, we provided the asset identifier (IP address) protected by the database secret with file location in each alert. Then, we asked if developers would change the priority of secrets removal based on the asset identifier and why. We hypothesize that developers will change their priority and choose B and C since these secrets point to public IP addresses. Next, we provided the security risk score, value of asset, and ease of attack information, such as the sensitive data categories and passive network information from RiskHarvester (Section~\ref{RiskHarvester}). Then, we asked if developers would change the priority of secret removal based on the security risk score and why. We hypothesize that developers will change their order to Secret C, A, and B. We also asked an optional question on developers' suggestions for improving the security risk score calculation. In the survey, all the questions are kept open-ended to avoid bias from predefined options and explore diverse perspectives.

\textbf{Conducting Survey}: For conducting the survey, we leveraged the Qualtrics~\cite{qualtrics}, a popular online survey host. However, before conducting the main survey, we conducted a pilot survey with five security researchers from the anonymized lab. In the pilot survey, we provided an additional question for suggestions on survey improvement, including any unclear, irrelevant, or overly detailed aspects. We conducted the main survey in November and December 2024. We offered a \$20 Amazon gift card to five randomly selected participants if they wished to participate in the lottery. We discussed the IRB approval and other ethical considerations in Section~\ref{Ethics}.