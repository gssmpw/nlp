In this section, we discuss the limitations of our study. 

\textbf{Manual Analysis}: We identified database keywords and the data categories for each secret-asset pair of RiskBench by manually inspecting the source code (Section~\ref{RiskBench}). However, manual analysis is prone to bias due to differing interpretations and oversights. Two authors cross-checked the identified database keywords and data categories to mitigate the bias. 

\textbf{Benchmark Dataset}: Our benchmark dataset selection is susceptible to bias. Basak et al.~\cite{assetharvester} identified the secret-asset pairs of AssetBench using two open-source tools, TruffleHog and Gitleaks, from GitHub repositories. However, these two tools may miss secrets from the repositories. Additionally, AssetBench does not contain repositories from other VCSs, such as BitBucket~\cite{bitbucket}. We could not mitigate the potential bias since AssetBench is the only publicly available dataset.

\textbf{Developer Survey}: Our survey findings are susceptible to external validity, as the participant pool might not accurately represent the broader developer population. To mitigate the limitation, we randomly sampled developers with prior experience in software secrets. The survey results may be influenced by how we presented the problem to the developers. To ensure clarity in the survey questions, we conducted a pilot survey with security researchers and refined the questions based on their feedback. Additionally, we provided open-ended questions to mitigate the bias from predefined options~\cite{tourangeau2000psychology}.

% \textbf{Data Flow Analysis}: We used CodeQL for data flow analysis on the latest repository snapshot. However, CodeQL only models data flow for the current snapshot, and secret-asset pairs may still exist in previous commits. While we could analyze each snapshot from Git history to identify these pairs, the approach would be impractical and time-consuming.