
\documentclass{article}

\usepackage{microtype}
\usepackage{graphicx}
\usepackage{subfigure}
\usepackage{booktabs} %
\usepackage{tcolorbox}
\usepackage{diagbox} %
\usepackage{threeparttable}

\usepackage{hyperref}


\newcommand{\theHalgorithm}{\arabic{algorithm}}


\usepackage[accepted]{icml2024}

\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{mathtools}
\usepackage{amsthm}
\usepackage{booktabs}
\usepackage{multirow}
\usepackage[normalem]{ulem}
\useunder{\uline}{\ul}{}

\usepackage[capitalize,noabbrev]{cleveref}

\theoremstyle{plain}
\newtheorem{theorem}{Theorem}[section]
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{corollary}[theorem]{Corollary}
\theoremstyle{definition}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{assumption}[theorem]{Assumption}
\theoremstyle{remark}
\newtheorem{remark}[theorem]{Remark}

\usepackage[textsize=tiny]{todonotes}


\icmltitlerunning{Large Language Models Are Universal Recommendation Learners}

\begin{document}

\twocolumn[
\icmltitle{Large Language Models Are Universal Recommendation Learners}



\icmlsetsymbol{equal}{*}

\begin{icmlauthorlist}
\icmlauthor{Junguang Jiang}{comp,equal}
\icmlauthor{Yanwen Huang}{comp,equal}
\icmlauthor{Bin Liu}{comp}
\icmlauthor{Xiaoyu Kong}{comp}
\icmlauthor{Ziru Xu}{comp}
\icmlauthor{Han Zhu}{comp}
\icmlauthor{Jian Xu}{comp}
\icmlauthor{Bo Zheng}{comp}
\end{icmlauthorlist}

\icmlaffiliation{comp}{Taobao \& Tmall Group of Alibaba, China}

\icmlcorrespondingauthor{Bo Zheng}{bozheng@alibaba-inc.com}


\icmlkeywords{Machine Learning, ICML}

\vskip 0.3in
]

\printAffiliationsAndNotice{\icmlEqualContribution} %

\begin{abstract}
In real-world recommender systems, different tasks are typically addressed using supervised learning on task-specific datasets with carefully designed model architectures. We demonstrate that large language models (LLMs) can function as universal recommendation learners, capable of handling multiple tasks within a unified input-output framework, eliminating the need for specialized model designs. To improve the recommendation performance of LLMs, we introduce a multimodal fusion module for item representation and a sequence-in-set-out approach for efficient candidate generation. When applied to industrial-scale data, our LLM achieves competitive results with expert models elaborately designed for different recommendation tasks. Furthermore, our analysis reveals that recommendation outcomes are highly sensitive to text input, highlighting the potential of prompt engineering in optimizing industrial-scale recommender systems.


\end{abstract}

\section{Introduction}
Recommender systems have become an integral part of people's daily lives, revolutionizing the way users interact with content and services.
To meet the diverse needs of users, recommender systems are evolving to become more sophisticated and multifaceted, leading to the emergence of a wide variety of recommendation tasks, each tailored to different aspects of user interaction and preference.
For instance,
due to the distribution shift of user behaviors in different contexts, such as in different apps or on different interaction interfaces within the same app,  multi-scenario tasks are introduced for internal relationship modeling \cite{MMOE}. 
To precisely capture the user intention,
multi-objective tasks, such as click prediction, purchase prediction, and like prediction, are formulated \cite{cite:multi_objective_recommendation}. 
To prevent the phenomenon of information cocoons and offer novel candidates to users, specific tasks, such as serendipity recommendation \cite{cite:discovery_recommendation, Serendipity} and long-tail item recommendation \cite{cite:longtail_recommendation} are established. 
Additionally, there are occasions when it is necessary to model changes in user behavior over time, such as during seasonal changes, festival celebrations, or shopping events.

In traditional recommender systems,  for each of the above tasks, a large amount of training data is collected, and specialized models are then designed, trained, evaluated, and deployed separately.
This approach has served well to make progress on narrow tasks, but when the tasks change, it requires collecting new data and training a new model carefully, which is time-consuming, lacks scalability, and sometimes faces challenges due to insufficient task-specific data.

Multi-task learning \cite{Caruana1997MultitaskL} is a promising framework for improving the versatility of recommender systems.
However, learning multiple tasks simultaneously often leads to performance degradation compared to learning tasks individually, a phenomenon known as \textit{negative transfer} \cite{survey_negative_transfer}.
In practice, it is necessary to design models according to the data size of each task. Tasks with less data should share more parameters to prevent insufficient training, while tasks with more data should have more independent parameters to avoid conflicts between tasks. Some studies have also proposed adaptive parameter sharing mechanisms \cite{MMOE, PLE}.
However, the aforementioned methods rely heavily on human expertise, and as the number of tasks continues to increase,
model design becomes increasingly challenging.
\begin{figure}[!t]
    \centering
    \includegraphics[width=1\linewidth]{figs/comparison.pdf}
    \vspace{-25pt}
    \caption{Comparison between different paradigms. Traditional  ID-based recommendation models demonstrate high performance but are data-inefficient and labor-intensive when scaling to more tasks. Using LLMs directly for recommendation provides great task scalability, but the performance is often unsatisfactory and the efficiency is concerning. 
    Our approach URM offers both high recommendation performance and task versatility.
    }
    \label{fig:compare}
    \vspace{-15pt}
\end{figure}


The previous challenges in multi-task learning arise because task conditioning has traditionally been implemented at the architectural level, requiring the model architecture of each task to be specifically adapted to its corresponding data. 
However, LLMs offer a new approach in which tasks can be defined through different prompts~\cite{cite:GPT,cite:GPT2,GPT3}, rather than through specialized architectural modifications.
In this paradigm, the inputs and outputs for different recommendation tasks follow a unified format, with the model architecture and parameters fully shared.
Moreover, previous works~\cite{kaplan2020scaling, hernandez2021scaling} have shown that the issue of negative transfer can be efficiently mitigated by scaling up both the model and the data.


 
Despite the excellent versatility of LLMs, a key challenge to use them in recommendation is how to improve performance and efficiency while retaining versatility.
Recent methods try converting user behaviors to text~\cite{cite:P5, cite:Uncovering_ChatGPT} or text embeddings \cite{HLLM,Jia2024KnowledgeAF}, which, however, lack discriminability and may lead to poor performance in real systems.
Furthermore, the token-by-token generation manner of LLMs
involves multiple-time feedforward computing, which is intolerable in terms of latency and computational efficiency.


 
In this paper, we propose \textbf{Universal Recommendation Model (URM)}, which formulates multiple recommendation tasks that were previously studied in isolation into a unified input-output format using task prompts.
By leveraging LLMs, URM enhances the versatility of recommendation models, enabling zero-shot task transfer and prompt tuning in industrial recommender systems.

To improve the effectiveness of LLM-based recommendation, we explore a new multimodal fusion module for item representation to leverage both the strong discriminability of ID embeddings and the rich semantics of text and image embeddings, which greatly improves the performance. Meanwhile, we design a sequence-in-set-out generation method, which allows the LLMs to generate a high-quality recommendation set in a single forward pass, enhancing the practicality of URM in industrial recommender systems. We conduct comprehensive experiments across public and industrial-scale datasets. Both quantitative and qualitative experimental results demonstrate the excellent performance and versatility of our proposed URM. 

 

 
 
 
 
 
 



\section{Related Work}
\paragraph{Multi-Task Learning.}
To effectively boost information sharing and alleviate task conflict, significant efforts have been invested in multi-task architecture designs. Existing techniques can be categorized into different parameter sharing methods \cite{CrossSwitch, UberNet, MTAN, ASTMT,Multi_centernet} and optimization strategies \cite{UW, GradNorm, PCGrad}.
Multi-task learning has also
been widely applied to recommender systems and achieved substantial improvement \cite{MMOE, ESMM, PLE}.
However, in practice, it is difficult to ensure that the performance of each task improves after multi-task learning, especially when the number of tasks continues to increase \cite{taskonomy, forkmerge}. 
Thus, it's often necessary to carefully design the model structure based on the data proportions and the task relationships.
This has also led to the isolated states among different recommendation problems, such as multi-scenario modeling \cite{jiang2022adaptive}, multi-objective modeling \cite{ESMM, cite:multi_objective_recommendation}, long-tail recommendation \cite{cite:longtail_recommendation}, etc. 
In addition, search tasks can be viewed as a specialized type of recommendation with explicit query constraints. 
Due to significant distribution discrepancies and limited model capacity, traditional recommendation models cannot easily simultaneously handle scenarios both including and excluding explicit inputs \cite{liu2024unified}.
In this paper, we propose to treat all the above problems as multi-task learning problems and address them simultaneously by LLMs, in an end-to-end and fully parameter-sharing manner.

\vspace{-10pt}
\paragraph{LLMs for Recommendation.}
Large Language Models (LLMs)  have demonstrated significant capabilities in natural language processing \cite{cite:GPT,cite:GPT2, GPT3, gpt4}, encouraging researchers to explore their application in recommender systems.
Recent approaches  treat  recommendation tasks as natural language tasks, generating recommendations directly through prompting and in-context learning \cite{P5, cite:Uncovering_ChatGPT,IsGPTGood,InstructionFollowing,ilora}. 
However, in real systems, users typically have hundreds or even millions of behaviors, leading to at least tens of thousands of text tokens, which increases inference costs and decreases LLM performance.
Thus some methods introduce a hierarchical structure that encodes each item's text or image information into item representations and feeds them into LLMs to generate a high-level user representation \cite{HLLM,Jia2024KnowledgeAF,ye2024harnessing}. Yet these representations still suffer from poor discriminability and lead to low performance in industrial applications. 
Another approach employs traditional ID embeddings to represent items \cite{CoLLM,E4SRec,LlaRA}, yet LLMs often struggle to interpret the intrinsic meaning of these embeddings. 
This limitation hinders the ability of LLMs to effectively adapt recommendations based on input prompts, thus degenerating their versatility. 
In this paper,  we integrate the ID embeddings and text embedding 
within a single LLM to balance performance and versatility.



\section{Approach}
In URM, we propose to formulate recommendation tasks through LLM prompt templates to handle the multi-task learning problem. In this section, we first demonstrate the inputs and outputs of the LLM used in URM. Then, we illustrate the overall model architecture of URM, including the proposed multimodal fusion module and the sequence-in-set-out candidate generation pattern. Subsequently, we provide a detailed introduction on how to train URM.


\begin{table}[!b]
\vspace{-10pt}
\footnotesize
\begin{tabular}{p{8cm}}
\toprule
\textbf{Multi-scenario Recommendation}: The items the user has recently clicked on are as follows: \{USER BEHAVIOR SEQUENCE\}.\colorbox{gray!20}{In scenario \{SCENE\}, please recommend items.}
 \\
\textbf{Multi-objective Recommendation}: The items the user has recently clicked on are as follows: \{USER BEHAVIOR SEQUENCE\}. \colorbox{gray!20} {Please find items that the user will \{ACTION\}. } \\
\textbf{Long-tail Item Recommendation}: The items the user has recently clicked on are as follows: \{USER BEHAVIOR SEQUENCE\}.
\colorbox{gray!20}{Please recommend long-tail items.} \\
\textbf{Serendipity  Recommendation}: The items the user has recently clicked on are as follows: \{USER BEHAVIOR SEQUENCE\}. \colorbox{gray!20}{Please recommend some new item categories. }\\
\textbf{Long-term Recommendation}: The items the user has recently clicked on are as follows: \{USER BEHAVIOR SEQUENCE\}. \colorbox{gray!20}{Please find items that match the user's long-term interests. }\\
\textbf{Search Problem}: The items the user has recently clicked on are as follows: \{USER BEHAVIOR SEQUENCE\}. \colorbox{gray!20}{Please recommend items that match  \{QUERY\}.} 
 \\
\bottomrule
\end{tabular}
\vspace{-10pt}
\caption{Examples of recommendation prompt templates. The different parts of each task are highlighted in \colorbox{gray!20}{gray}. The computation of the shared parts can be accelerated using key-value caching, thus improving inference efficiency \cite{zheng2024sglangefficientexecutionstructured}.}
\label{table:prompt_examples}
\vspace{-5pt}
\end{table}

\subsection{Data Construction}
\label{sec:dataset}
 Following the multi-task learning approach in the field of NLP \cite{cite:GPT2}, we utilize language to define recommendation tasks and represent inputs as sequences of symbols.
Based on the characteristics of different tasks, we design multiple templates and then convert the industrial-scale user behavior data into sequence forms.
Table \ref{table:prompt_examples} gives some examples of the prompt templates.















\textbf{Input Format.} 
 To improve efficiency when handling long user behavior sequences and maintain the discriminability of items, 
 URM treats item as a kind of special token.
  The typical inputs are sentences composed of common text tokens and item IDs (such as [7502]) as follows:
 \begin{tcolorbox}[colback=blue!2!white,leftrule=2.5mm,size=title]
\label{obs1}
 \textbf{Inputs:} The items the user has recently clicked on are as follows: [7502][8308][8274][8380].  Please recommend items that match \textit{Clothes}. 
\end{tcolorbox}

\textbf{Output Format.} 
Considering inference efficiency, URM is designed to generate items directly. Additionally, optimizing URM with target text is recommended to align with the semantic space and incorporate external textual knowledge.  Typical targets are as follows:
 \begin{tcolorbox}[colback=blue!2!white,leftrule=2.5mm,size=title]
\label{obs1}
 \textbf{Target Text:} Swimwear \& Beachwear for the Summer; Casual Dresses for Every Occasion.
 
 \textbf{Target Items:} [3632][1334]
\end{tcolorbox}


\begin{figure*}[!t]
    \centering
    \includegraphics[width=0.8\linewidth]{figs/architecture.pdf}
    \vspace{-10pt}
    \caption{URM architecture. 
    The input sequence consists of item IDs from user behavior, text tokens from task prompt, and several fixed query tokens, such as [UM] and [LM]. Item IDs are mapped to item embeddings by a distributed item embedding module and other tokens are mapped to token embeddings.
    The item embeddings or token embeddings are summed up with position embeddings, and fed into the LLM backbone. The outputs corresponding to the [UM] tokens are then mapped to the user representation space via the UM Head $h_\text{UM}$. The outputs corresponding to the [LM] token and its following tokens are mapped to the text space via the LM Head $h_\text{LM}$.
}
    \label{fig:arch}
        \vspace{-10pt}
\end{figure*}


\subsection{Model Architecture}
 URM is based on pre-trained LLMs due to their general capabilities across various tasks \cite{gpt4}.
 In Section \ref{sec:dataset},  recommendation tasks have been converted into sequences consisting of text tokens and item IDs. Text tokens can be mapped to token embeddings by the vocabulary embedding table from the LLM. The number of item IDs in the industry can reach the billion range,  thus we introduce a distributed item embedding module to convert each item ID into a unique item embedding. As shown in Figure \ref{fig:arch}, 
the embedding at each position in the sequence is then the sum of the position embedding and either the token embedding or the item embedding.
The sequence's embeddings are then processed through the LLM backbone, resulting in several hidden features that are used to compute the final output.
To preserve the pre-training knowledge in the LLM, we retain the multi-layer transformer structure and only modify the structure of its input and output layers. We will elaborate on these aspects separately next.


\begin{figure}[!b]
    \centering
    \vspace{-15pt}
    \includegraphics[width=1\linewidth]{figs/INPUT.pdf}
    \vspace{-20pt}
        \caption{Multimodal Fusion Module. The parameters of the Text Encoder and the Image Encoder are frozen and linear projection layers are introduced to transform feature dimensions. Distributed HashTable is introduced for item IDs, which allows for industrial-scale IDs in the billion range. In practice, the item text embeddings and the corresponding image embeddings are precomputed and stored in a separate Distributed HashTable. 
    }
    \label{fig:id_embedding}
\end{figure}

\textbf{Multimodal Fusion Module.}  
There are currently two main methods to obtain item embeddings.
The most common practice in the industry is to use real user behavior as a supervisory signal to learn a unique ID embedding for each item. 
However, the significant discrepancy between the embedding space of ID and that of text makes it challenging for LLMs to align the ID embeddings with their true meanings.  
As a result, LLMs reduce to functioning as similarity measures, losing versatility across different tasks.
Another approach is to input the title \cite{Jia2024KnowledgeAF}, image \cite{ye2024harnessing}, and other information into LLMs or content encoders to obtain the embedding for each item. Understanding the meaning of each item through text embedding is straightforward for LLMs. However, such item embeddings have poor discriminability, resulting in extremely bad performance in practical industrial recommender systems.

To address the limitations of using ID or text embeddings alone, we design a multimodal fusion module to combine different types of item embeddings.
As shown in Figure \ref{fig:id_embedding},  
the text and ID embeddings are all first transformed to the same dimensionality using an MLP layer. These embeddings are then combined by addition, followed by normalization using RMSNorm \cite{zhang2019rootmeansquarelayer}, and processed through another MLP layer to produce the final multimodal item embedding.
After supervised fine-tuning (SFT), the multimodal item  fusion embeddings can effectively
align with the textual semantic space while preserving each item's specific information,  striking a good balance between the generalization of text embeddings and the discriminability of ID embeddings. 
Note that this fusion approach is not limited to text embeddings. Semantic embeddings from other modalities, such as image embeddings~\cite{sheng2024enhancing}, can also be incorporated. 







\textbf{Sequence-In-Set-Out.} 
Although the autoregressive generation manner \cite{cite:GPT, P5, cite:Uncovering_ChatGPT} is more versatile, it cannot ensure that the generated recommendation results are within a continuously updating candidate set. Furthermore, autoregressive generation of the sequence involves multiple forward inference costs of LLM,  which is intolerable in terms of both latency and computational efficiency.

Therefore, we adopt special query tokens to generate target text and target item sets simultaneously.
In our practice, sharing the \textit{last\_hidden\_state} leads to poor results due to the conflicts between text and user's representation spaces. Thus, we add special tokens [$\text{UM}$] and [$\text{LM}$] to the end of the input to indicate whether to output user representation or start generating text at a certain position, respectively.
As for the output, we introduce two linear projections on the top layer features of the LLM, as shown in Figure \ref{fig:arch}. 
One head is the user modeling head $h_{\text{UM}}$ to transform the LLM's hidden features into the user embeddings $U$, which is then used to retrieve relevant item sets during inference. The other one is the original language modeling head $h_\text{LM}$ in the LLM, allowing URM to use text data for training. 

 \begin{tcolorbox}[colback=blue!2!white,leftrule=2.5mm,size=title]
\label{obs1}
 \textbf{Inputs:} The items the user has recently clicked on are as follows: [7502][8308][8274][8380]. Please recommend items that match \textit{Clothes}. \textbf{[$\text{UM}$][$\text{LM}$]}
\end{tcolorbox}
By calculating the similarity between the generated user embeddings $U$  and the multimodal item embeddings $E$, we can obtain the scores between the user and each item. The final objective during inference is to  generate the top $k$ item set from  a large-scale corpus $\mathcal{C}$ with the largest scores,
\begin{equation}
    \arg\text{Topk}_{Z\in \mathcal{C}} 
    \mathcal{D}(U, E_Z) ,
\end{equation}
where $\mathcal{D}$ is a similarity measure.
Instead of measuring similarity with a single high-dimensional user embedding, we find that it is more effective to use multiple low-dimensional user embeddings, which is similar to the multi-head attention~\cite{cite:NIPS17Transformer} architecture.
Specifically, by increasing the number of [UM] tokens and reducing the output dimension of the UM head, URM can express different aspects of the target item set without increasing the total output dimensions.
Without loss of generality, we take the inner product as the similarity measure for example.
Denote the output user embeddings from LLM  as $\mathbf{U} = (U_1, ..., U_H)$,  the  multimodal embedding for item $Z$ as  $E_{Z}$, then the  score between user and item $Z$ is $\mathcal{D}(\mathbf{U}, E_Z) = \max(U_1 E_{Z}, ..., U_H E_{Z})$.
In contrast to the sequential relationship among the auto-regressive generated tokens,
the multiple [UM] tokens are fixed in the input sequence, thus a single LLM forward pass is sufficient to obtain the output for all [UM] tokens.




In industry, the size of the candidate set $\mathcal{C}$ can reach tens of millions or even hundreds of millions. Calculating the inner product for all candidates remains prohibitively expensive. Therefore, we construct an HNSW index \cite{HNSW,chen2022approximate} based on the target multimodal embeddings and use hierarchical retrieval to output the final top $k$ results. Our final inference cost for a single user primarily consists of once LLM feedforward inference plus the following $H \cdot \log(|\mathcal{C}|)$ times of inner product calculation in retrieval.










\subsection{Training  }
Denote the input sequence as $\mathbf{X}=(X_1, ..., X_M)$, the target text as $\mathbf{Y}=(Y_1, ..., Y_N)$, and the target items as $\mathbf{Z}=(Z_1, ..., Z_L)$. 
The text generation tasks can be optimized by the negative log-likelihood of the target text sequence:
 \begin{equation}
    \label{eq:AutoRegressive}
     \mathcal{L}_{\text{LM}} (\mathbf{X}, \mathbf{Y}) = -\sum_{n=1}^{N} \log P (Y_n|\mathbf{X}, \mathbf{Y}_{\textless n}),
 \end{equation}
where $P=\text{softmax}(h_{\text{LM}}(\psi(\cdot))$ is the probabilities output by  transformer $\psi$ and the LM head $h_{\text{LM}}$.
The item recommendation tasks are optimized by Noise Contrastive Estimation (NCE)  Loss \cite{gutmann2010noise}:
\begin{equation}
 \mathcal{L}_{\text{UM}} (\mathbf{X}, \mathbf{Z}) = \sum_{l=1}^L - \log \dfrac{\exp (\mathcal{D}(\mathbf{U}(\mathbf{X}), E_{Z_l}) )}{ \sum_{Z\in \{Z_l\} \cup \mathcal{N}} \exp (\mathcal{D}(\mathbf{U}(\mathbf{X}), E_Z) )} 
\end{equation}
where $\mathbf{U}=h_{\text{UM}}(\psi(\cdot))$ is the output by the transformer $\psi$ and user modeling head $h_{\text{UM}}$.
In each batch, negative examples  
$\mathcal{N}$ are sampled from the item candidates based on
their occurrence frequency.
The final training objective is 
\begin{equation}
    \min \mathcal{L} (\mathbf{X}, \mathbf{Y}, \mathbf{Z}) =  \mathcal{L}_{\text{LM}} (\mathbf{X}, \mathbf{Y}) + \eta \mathcal{L}_{\text{UM}} (\mathbf{X}, \mathbf{Z}), 
\end{equation}
where $\eta$ is the trade-off hyper-parameter.
Considering the fact that URM has made significant modifications to both the input and output layers of the LLM, we adopt the full parameter SFT, with only the original embeddings of items, i.e., item ID embeddings, item text embeddings and item image embeddings being frozen.


\begin{table*}[!t]
\addtolength{\tabcolsep}{-3pt}
\centering
\footnotesize
\caption{Performance on Amazon dataset. RI: Relative Improvement.}
\resizebox{\textwidth}{!}{
\begin{tabular}{@{}l|cccc|cccc|cccc@{}}
\toprule
\multicolumn{1}{c|}{\multirow{2}{*}{\textbf{Methods}}} &
  \multicolumn{4}{c|}{\textbf{Sports}} &
  \multicolumn{4}{c|}{\textbf{Beauty}} &
  \multicolumn{4}{c}{\textbf{Toys}} \\ \cmidrule(l){2-13} 
\multicolumn{1}{c|}{} & HR@5    & NDCG@5  & HR@10    & NDCG@10 & HR@5    & NDCG@5  & HR@10   & NDCG@10 & HR@5    & NDCG@5 & HR@10   & NDCG@10 \\ \midrule
HGN                   & 0.0189  & 0.0120  & 0.0313   & 0.0159  & 0.0325  & 0.0206  & 0.0512  & 0.0266  & 0.0321  & 0.0221 & 0.0497  & 0.0277  \\
GRU4Rec               & 0.0129  & 0.0086  & 0.0204   & 0.0110  & 0.0164  & 0.0099  & 0.0283  & 0.0137  & 0.0097  & 0.0059 & 0.0176  & 0.0084  \\
Caser                 & 0.0116  & 0.0072  & 0.0194   & 0.0097  & 0.0205  & 0.0131  & 0.0347  & 0.0176  & 0.0166  & 0.0107 & 0.0270  & 0.0141  \\
BERT4Rec              & 0.0115  & 0.0075  & 0.0191   & 0.0099  & 0.0203  & 0.0124  & 0.0347  & 0.0170  & 0.0116  & 0.0071 & 0.0203  & 0.0099  \\
FDSA                  & 0.0182  & 0.0122  & 0.0288   & 0.0156  & 0.0267  & 0.0163  & 0.0407  & 0.0208  & 0.0228  & 0.0140 & 0.0381  & 0.0189  \\
SASRec                & 0.0233  & 0.0154  & 0.0350   & 0.0192  & 0.0387  & 0.0249  & 0.0605  & 0.0318  & 0.0445  & 0.0236 & 0.0698  & 0.0318  \\
S3-Rec                & 0.0251  & 0.0161  & 0.0385   & 0.0204  & 0.0387  & 0.0244  & 0.0647  & 0.0327  & 0.0443  & 0.0294 & 0.0700  & 0.0376  \\
E4SRec &
  0.0281 &
  0.0196 &
  0.0410 &
  0.0237 &
  {\ul 0.0525} &
  0.0360 &
  {\ul 0.0758} &
  {\ul 0.0435} &
  0.0566 &
  0.0405 &
  {\ul 0.0798} &
  0.0479 \\
P5 &
  {\ul 0.0387} &
  {\ul 0.0312} &
  {\ul 0.0460} &
  {\ul 0.0336} &
  0.0508 &
  {\ul 0.0379} &
  0.0664 &
  0.0429 &
  {\ul 0.0648} &
  {\ul 0.0567} &
  0.0709 &
  {\ul 0.0587} \\
URM &
  \textbf{0.0733} &
  \textbf{0.0488} &
  \textbf{0.1049} &
  \textbf{0.0590} &
  \textbf{0.0929} &
  \textbf{0.0671} &
  \textbf{0.1225} &
  \textbf{0.0766} &
  \textbf{0.0888} &
  \textbf{0.0619} &
  \textbf{0.1221} &
  \textbf{0.0726} \\ \midrule
RI                    & +89.4\% & +56.4\% & +128.0\% & +75.6\% & +77.0\% & +77.0\% & +61.6\% & +76.1\% & +37.0\% & +9.2\% & +53.0\% & +23.7\% \\ \bottomrule
\end{tabular}
}
\label{table:amazon}
\vspace{-10pt}
\end{table*}


\section{Experiments}
\subsection{Public Dataset Experiments}
\label{sec:open_dataset_experiment}
\textbf{Dataset.} We first evaluate the performance of URM on Sports \& Outdoors, Beauty and Toys \& Games from Amazon Reviews \cite{amazon}.
We follow the preprocessing methods used in recent works \cite{P5, E4SRec} to construct the training and test datasets.


\textbf{Models.}
For baseline, we use both traditional ID-based and LLM-based methods:
(1) HGN \cite{cite:HGN} leverages a hierarchical structure to model user-item interactions.
(2)  GRU4Rec \cite{cite:GRU4Rec} 
    employs Gated Recurrent Units (GRUs) to model sequential user behavior.
(3)  Caser \cite{cite:Caser}
    leverages convolutional neural networks (CNNs) to capture sequential patterns in user behavior. 
(4)    BERT4Rec \cite{cite:Bert4Rec} adapts the BERT architecture for sequential recommendation.
(5) FDSA \cite{FDSA}
applies a self-attention module to model the relationships between features.
 (6)   SASRec \cite{cite:SasRec} employs self-attention mechanisms to model user behavior sequences.
 (7)   S3-Rec \cite{cite:S3Rec}
    enhances sequential recommendation by incorporating self-supervised learning.
 (8)   E4SRec \cite{E4SRec}  integrates ID embedding within  LLaMA2-13B \cite{Llama}.
 (9)   P5 \cite{cite:P5}  employs the T5 \cite{T5} model and takes recommendation tasks as purely natural language tasks.
 
 For URM, we use Qwen-7B \cite{qwen} as the LLM backbone. We use SASRec to generate  $64$-dimensional ID embeddings and use LLM to generate $4096$-dimensional text embeddings (by feeding the item title into LLM, then averaging and normalizing the last hidden features along the sequence dimension).
 The output user embedding dimension is set to $128$ and the number of [UM] tokens is $H=128$. 
The user behavior sequence length is $100$ and trade-off hyper-parameter $\eta=0.3$.



We evaluate the model performance using two widely adopted metrics, namely Hit Rate (HR@$K$) and Normalized Discounted Cumulative Gain (NDCG@$K$), computed at different ranking positions ($K= \{5, 10\}$) across the entire dataset.
As presented in Table \ref{table:amazon}, 
URM outperforms the strongest baseline by an average of $\textbf{74\%}$ and $\textbf{53\%}$ in terms of HR@$K$ and nDCG@$K$, respectively.


\begin{table*}[htbp]
\addtolength{\tabcolsep}{1.5pt}
\centering
\footnotesize
\caption{Performance on the industrial dataset (metric: R@1000).}
\begin{tabular}{@{}llllllllllll@{}}
\toprule
\textbf{Model} &
  \textbf{Learning Method} &
  \textbf{CR} &
  \textbf{RSA} &
  \textbf{RSB} &
  \textbf{RSC} &
  \textbf{SR} &
  \textbf{LR} &
  \textbf{LIR} &
  \textbf{PP} &
  \textbf{SP} &
  \textbf{AVG} \\ \midrule
\multirow{2}{*}{\begin{tabular}[c]{@{}l@{}}Two-tower \\ Model\end{tabular}} &
  STL &
  0.129 &
  0.271 &
  0.166 &
  0.129 &
  0.069 &
  0.066 &
  0.117 &
  0.146 &
  0.355 &
  0.161 \\
 & MTL          & 0.120       & 0.205 & 0.166       & 0.135       & 0.064 & 0.115          & 0.103          & 0.173       & 0.257       & 0.149       \\ \midrule
\multirow{2}{*}{\begin{tabular}[c]{@{}l@{}}Transformer-\\ based Model\end{tabular}} &
  STL &
  0.198 &
  0.409 &
  0.293 &
  0.208 &
  {\ul 0.104} &
  0.115 &
  0.213 &
  0.143 &
  0.593 &
  0.253 \\
 & MTL          & 0.192       & 0.390 & 0.319       & 0.221       & 0.076 & 0.218          & 0.207          & 0.401       & 0.744       & 0.308       \\ \midrule
\multirow{5}{*}{\begin{tabular}[c]{@{}l@{}}Attention-\\ DNN\end{tabular}} &
  STL &
  0.253 &
  {\ul 0.477} &
  0.338 &
  0.260 &
  \textbf{0.106} &
  0.213 &
  {\ul 0.251} &
  0.353 &
  0.651 &
  0.323 \\
 & MTL          & 0.238       & 0.456 & 0.375       & {\ul 0.277} & 0.062 & {\ul 0.336}    & \textbf{0.265} & 0.478       & 0.671       & 0.351       \\
 & MTL-SharedBottom & 0.243       & 0.442 & 0.376       & 0.270       & 0.072 & \textbf{0.337} & 0.224          & {\ul 0.505} & 0.745       & 0.357       \\
 & MTL-MMoE         & 0.233       & 0.439 & 0.375       & 0.257       & 0.070 & 0.325          & 0.218          & 0.491       & 0.736       & 0.349       \\
 & MTL-PLE          & {\ul 0.256} & 0.451 & {\ul 0.397} & 0.274       & 0.062 & 0.327          & 0.224          & 0.512       & {\ul 0.761} & {\ul 0.363} \\ \midrule
URM &
  MTL &
  \textbf{0.263} &
  \textbf{0.530} &
  \textbf{0.439} &
  \textbf{0.362} &
  0.093 &
  0.285 &
  0.240 &
  \textbf{0.581} &
  \textbf{0.835} &
  \textbf{0.403} \\ \bottomrule
\end{tabular}
\label{table:taobao}
\vspace{-5pt}
\end{table*}


\subsection{Industrial-scale Experiments}
\textbf{Dataset.}   Next, we verify the effectiveness of URM in an industrial-scale dataset, which is sampled from real traffic logs of the online system. 
The typical scenarios and objectives include \textbf{C}ontext-free \textbf{R}ecommendation (\textbf{CR}), \textbf{R}ecommendation for \textbf{S}cene \textbf{A} (\textbf{RSA}), \textbf{S}cene \textbf{B} (\textbf{RSB}), \textbf{S}cene \textbf{C} (\textbf{RSC}), \textbf{S}erendipity  \textbf{R}ecommendation (\textbf{SR}), \textbf{L}ong-term \textbf{R}ecommendation (\textbf{LR}), \textbf{L}ong-tail \textbf{I}tem \textbf{R}ecommendation (\textbf{LIR}),  \textbf{P}urchase \textbf{P}rediction (\textbf{PP}), and \textbf{S}earch \textbf{P}roblem (\textbf{SP}). 
This dataset contains hundreds of millions of samples and more than one billion distinct items in user behavior sequences. 
The candidate set contains tens of millions of items.
A more detailed definition of the dataset is in Appendix \ref{appendix:dataset_details}.
We use samples from day $1$ to day $T$ for training and the samples of day $T+1$ for testing.
To improve training efficiency, we aggregate each user's daily behaviors as the target set, which makes these recommendation tasks more challenging.
All methods are compared in this setting to facilitate a more effective result.

\textbf{Models.} For baseline, we use the most commonly used and feasible methods in practice.  (1) Two-tower Model, which uses two multi-layer MLPs to convert user-side and item-side features into embeddings, and use the inner product to obtain the final score. It's the most widely used method in industry.
(2) Transformer-based Model,  which uses a multi-layer transformer to convert user behavior sequence features into user embeddings \cite{cite:HSTU,liu2024kuaiformertransformerbasedretrievalkuaishou}.
(3) Attention-DNN, which calculates cross-attention between the user behavior sequence and the target, and then uses multiple layers to calculate the score between the user and each item. It is typically used in the ranking stage \cite{zhou2018deep} and is a very strong baseline for candidate generation tasks~\cite{zhu2019joint, zhuo2020learning, chen2022approximate}.  
For each method, we implement a single-task learning version (STL) with only task-specific data and a multi-task learning version (MTL) with data from all tasks. For the Attention-DNN model, which has the best performance among them, we further provide the Shared Bottom version \cite{ESMM}, the MMoE version \cite{MMOE}, and the PLE version \cite{PLE}. More details can be found in Appendix \ref{sec:Implementation}.

We tuned the hyperparameters of each method including the embedding size and number of layers using the validation set. For URM, we only list the hyper-parameters that differ from those in Section \ref{sec:open_dataset_experiment}.
The ID Embeddings are generated by the Two-Tower Model optimized with only CR task. 
Considering that the dimension of LLM text embeddings is too high to store for a billion-scale item set, we use $128$-dimensional semantic embeddings trained with CLIP contrastive learning \cite{cite:Arxiv21CLIP} considering the image and text description of items as a substitute.
The user behavior sequence length is $300$ and the total length of text tokens, [UM] tokens, and item IDs is truncated to $1024$.

We use recall to evaluate the effectiveness of our proposed method. Denote the output item set as $\mathcal{P}$  and the ground truth as $\mathcal{G}$,  then recall R@K is 
\begin{equation}
    \text{R@}K=\dfrac{|\mathcal{P} \cap \mathcal{G} |}{|\mathcal{G}|} , \text{where} 
 |\mathcal{P}|=K
\end{equation}
We show results in Table \ref{table:taobao}.  
Due to the complex task relationships, it is difficult for a single approach to perform well on all tasks, which leads to multi-task training being sometimes effective and sometimes causing negative transfer.
In contrast, our proposed URM achieves the best performance in $6$ out of $9$ tasks and achieves a relative improvement of $\textbf{11.0\%}$ in average across all tasks.
Besides, for the search problem, there is a specifically designed three-tower model, which adds an independent tower for queries and reaches 0.822 on SP R@1000. In contrast, our model achieves comparable results without any complex design.
Experimental analysis of the inference efficiency and the results for other LLM backbones can be found in Appendix \ref{appendix:inference_efficiency}  and \ref{appendix:more_backbone}.



\subsection{Ablation Study}
\textbf{The Effectiveness of Multi-Task Learning.}
Table \ref{table:taobao} also gives the performance degradation of single-task learning compared to multi-task learning.
Compared to other methods, URM performs better in multi-task settings,
indicating that URM is less prone to negative transfer issues. Further, Figure \ref{fig:ablation_MTL} compares the performance of single-task and multi-task learning with different amounts of labeled data.
The performance of URM  on the single CR task can also continuously approach that of multi-task learning as the amount of task-specific data increases. 
However, URM with multi-task learning can converge faster to better performance using much less task-specific data, which has significant value for recommendation scenarios where a large amount of task-specific data is not available.
\begin{figure}[!h]
    \centering
    \vspace{-10pt}
    \includegraphics[width=0.75\linewidth]{figs/mtl_comparison.pdf}
    \vspace{-15pt}
    \caption{The effectiveness of multi-task learning.}
    \label{fig:ablation_MTL}
\vspace{-15pt}
\end{figure}


\textbf{The Effectiveness of Multimodal Item Representation.}
As shown in Table \ref{table:item_embedding}, when using fixed ID embedding only, the optimization potential of LLM is limited, resulting in unremarkable performance on both the CR and SP tasks.
On the other hand, when using only semantic embedding, it's difficult to capture collaborative information, thus the model performs even worse.
After using the multimodal fusion representation, LLM can balance semantic alignment and collaborative information, achieving improvements in both tasks. In Appendix \ref{appedix:visualize_item}, we provide a visualization comparison of different item representations. 
\begin{table}[!h]
\addtolength{\tabcolsep}{18pt}
\centering
\footnotesize
\vspace{-15pt}
\caption{The effect of item representation (metric: R@1000).}
\begin{tabular}{@{}lll@{}}
\toprule
\textbf{Methods} & \begin{tabular}[c]{@{}l@{}}\textbf{CR}\end{tabular} & \begin{tabular}[c]{@{}l@{}}\textbf{SP} \end{tabular} \\ \midrule
ID Embedding Only   & 0.170                                                    & 0.663                                                     \\
Semantic Embedding Only & 0.077                                                     & 0.420                                                    \\
URM                 & \textbf{0.263}                                                    & \textbf{0.835}                                                    \\ \bottomrule
\end{tabular}
\label{table:item_embedding}
\vspace{-10pt}
\end{table}

\textbf{The Effectiveness of Special Token.}
After removing the LM loss, as training progresses, the risk of an LLM forgetting the pre-trained parameters may increase. In Table \ref{table:multi_head_output}, we can see that the item generation task is also negatively affected (URM w/o LM Loss).
However, when the LM Loss is retained, if the [UM] token and [LM] token are not introduced for separate generations (URM w/o separated tokens in Table \ref{table:multi_head_output}), the hidden features in the final layer may conflict with each other, leading to worse performance.

\begin{table}[!h]
\addtolength{\tabcolsep}{17pt}
\centering
\footnotesize
\vspace{-15pt}
\caption{The effectiveness of special token (metric: R@1000).}
\begin{tabular}{@{}lll@{}}
\toprule
 \textbf{Methods} & \textbf{CR} & \textbf{SP} \\ \midrule
URM                    & \textbf{0.263}                                                    & \textbf{0.835}                                                    \\
URM w/o LM Loss        & 0.256                                                    & 0.824                                                    \\
URM w/o Separated Tokens & 0.072                                                       & 0.528                                                       \\ \bottomrule
\end{tabular}
\label{table:multi_head_output}
\vspace{-10pt}
\end{table}


We also verify the impact of the number of [UM] tokens. As shown in Figure \ref{fig:MTP}, as the number of [UM] tokens increases, URM's ability to represent the target item set becomes stronger, resulting in better performance.


\begin{figure}[!h]
    \centering
    \includegraphics[width=0.8\linewidth]{figs/multitoken.pdf}
    \vspace{-15pt}
    \caption{The impact of  [UM] token number.}
    \label{fig:MTP}
    \vspace{-5pt}
\end{figure}


\subsection{Prompt Engineering}
In this section, we explore the impact of different prompt templates during inference.
Although we change the generation method to a sequence-in-set-out approach during inference for better performance and efficiency, we observe that  LLM remains sensitive to the text input. This makes it possible to tune the distribution of the generated set through prompt engineering. Only two examples are provided here and more examples can be found in Appendix \ref{appendix:more_prompt_engineering}.

\textbf{Multi-Scene Recommendation.} As shown in Table \ref{table:multi_scenario_prompt}, with prompt templates for specific scenarios, URM aligns more closely with the data distribution and achieves higher performance,
with a relative improvement (RI) of over 20\%.
\begin{table}[!h]
\addtolength{\tabcolsep}{4pt}
\centering
\footnotesize
\vspace{-20pt}
\caption{The effect of prompts on multi-scenario recommendation.}
\begin{tabular}{llll}
\toprule
\textbf{Template} & \textbf{\begin{tabular}[c]{@{}l@{}}RSA\\ R@1000\end{tabular}}   & \textbf{\begin{tabular}[c]{@{}l@{}}RSB\\ R@1000\end{tabular}}    & \textbf{\begin{tabular}[c]{@{}l@{}}RSC\\ R@1000\end{tabular}}    \\ \midrule
CR Template                          & 0.440          & 0.335          & 0.278          \\
RSA Template                          & \textbf{0.530} & 0.409          & 0.240          \\
RSB Template                          & 0.522          & \textbf{0.439} & 0.257          \\
RSC Template                          & 0.444          & 0.327          & \textbf{0.362} \\ 
\midrule
\textbf{RI}                          & \textbf{+20.5\%}          & \textbf{+31.0\%}          & \textbf{+30.2\%} \\ 
\bottomrule
\end{tabular}
\label{table:multi_scenario_prompt}
\vspace{-10pt}
\end{table}


\textbf{Serendipity  Recommendation.} This task requires finding items that users are interested in but the categories have not appeared in their behaviors.
As illustrated in Table \ref{table:serendipity_prompt}, 
after using the SR Template, the percent of the new category increased from 18.8\% to 46.2\%, leading to a relative increase of 82.3\% in the SR R@1000.

\begin{table}[!h]
\addtolength{\tabcolsep}{5pt}
\centering
\footnotesize
\vspace{-10pt}
\caption{The effect of prompts on Serendipity Recommendation.}
\begin{tabular}{@{}llll@{}}
\toprule
\textbf{Template} &
  \textbf{\begin{tabular}[c]{@{}l@{}}CR\\ R@1000\end{tabular}} &
  \textbf{\begin{tabular}[c]{@{}l@{}}SR\\ R@1000\end{tabular}} &
  \textbf{\begin{tabular}[c]{@{}l@{}}Percent of \\ New Category\end{tabular}} \\ \midrule
CR Template                   & \textbf{0.263} & 0.051            & 18.8\%            \\
SR Template                   & 0.213          & \textbf{0.093}   & \textbf{46.2\%}   \\
\midrule
\textbf{RI} &          -       & \textbf{+82.3\%} & \textbf{+145.7\%} \\ \bottomrule
\end{tabular}
\label{table:serendipity_prompt}
\vspace{-10pt}
\end{table}



\subsection{Zero-shot Task Transfer}
In this section, we further explore the performance of URM when encountering new text and even new tasks.

\textbf{New Query.} We analyze the performance of URM on seen and unseen queries. Note that the distributions of these two types of queries are different and unseen queries often tend to be long-tail queries. To make a more reasonable comparison, we plot the model's performance on seen and unseen queries as the query frequency increases. Figure \ref{fig:query_frequency_comparison} shows that URM demonstrates strong robustness to query input,
indicating that URM can generalize well even after SFT on a small dataset.
Meanwhile, tasks that are closely related to user needs, can be expressed by modifying the query in the SP Template and can be directly transferred. Some specific cases are provided in the Appendix \ref{appendix:zero_shot_prompt}.
\begin{figure}[!h]
    \centering
    \vspace{-10pt}
    \includegraphics[width=0.9\linewidth]{figs/query_frequency_comparison.pdf}
    \vspace{-10pt}
    \caption{Comparison of performance on seen and unseen queries.}
    \label{fig:query_frequency_comparison}
\vspace{-10pt}
\end{figure}




\textbf{New Prompt Template.} 
We find that the URM can transfer to tasks with hybrid prompt templates, such as long-tail item recommendations for search. 
 \begin{tcolorbox}[colback=blue!2!white,leftrule=2.5mm,size=title]
\label{obs1}
 \textbf{Inputs:} The items the user has recently clicked on are as follows: \{USER BEHAVIOR SEQUENCE\}. Please recommend long-tail items that match \{QUERY\}. 
\end{tcolorbox}

As shown in Table \ref{table:mix_SR_LIR}, when the SP template and LIR template are combined, the set produced by the URM aligns better with the query, thereby improving search performance compared to using the LIR template. At the same time, the proportion of long-tail items in the output set also increases compared to that of the SP template.
More cases can be found in Appendix \ref{appendix:zero_shot_prompt}. 
Such task versatility is actually difficult for traditional ID-based recommendation models to achieve. To further improve the transferability of URM to any prompt template, it is necessary to construct a richer set of training prompt templates, thereby enabling URM to build a comprehensive mapping relationship between a given sequence and a target set.
\begin{table}[!h]
\addtolength{\tabcolsep}{10pt}
\centering
\footnotesize
\vspace{-10pt}
\caption{The result of hybridizing the SP and LIR templates.}
\begin{tabular}{@{}lll@{}}
\toprule
\textbf{Template} & \textbf{\begin{tabular}[c]{@{}l@{}}SP\\ R@1000\end{tabular}} & \textbf{\begin{tabular}[c]{@{}l@{}}Percent of \\ Long-tail Items\end{tabular}} \\ \midrule
SP Template       & 0.835          & 79.6\%          \\
LIR Template      & 0.630          & 81.6\%          \\
SP $\times$ LIR Template & \textbf{0.836} & \textbf{82.4\%} \\ \bottomrule
\end{tabular}
\label{table:mix_SR_LIR}
\vspace{-10pt}
\end{table}













\section{Conclusion}
Our proposed URM  effectively integrates multiple recommendation tasks into a unified framework, leveraging LLMs for enhanced versatility and performance across various datasets. Furthermore, the incorporation of multimodal fusion representation and sequence-in-set-out generation method significantly improves the practicality and efficacy of URM in industrial recommender systems.



\section*{Impact Statement}
This paper presents work whose goal is to advance the field of 
Machine Learning. There are many potential societal consequences 
of our work, none of which we feel must be specifically highlighted here.

\section*{Acknowledgements}
We sincerely appreciate 
Zhengxiong Zhou, Zhengyu Liu, Qingzhang Shi, Zexin Yan, Jianqi Xie, Zequn Wu, Jinjing Li, Qian Wang, Yunlong Xu
for implementing the key components of the training and serving infrastructure.


\nocite{langley00}

\bibliography{example_paper}
\bibliographystyle{icml2024}


\newpage
\appendix
\onecolumn
\section{Implementation Details}
\subsection{Dataset Details}
\label{appendix:dataset_details}
We  construct datasets from typical scenarios and objectives, listed as follows:
\begin{itemize}
\setlength{\itemsep}{0pt}
  \item   \textbf{C}ontext-free \textbf{R}ecommendation (\textbf{CR}): Recommend items to users without  constraints. Positive samples are click behaviors across all scenarios or contexts.
  \item    \textbf{R}ecommendation for \textbf{S}cene \textbf{A} (\textbf{RSA}), \textbf{S}cene \textbf{B} (\textbf{RSB}), \textbf{S}cene \textbf{C} (\textbf{RSC}): Positive samples are the items exposed to users in $3$ scenarios with distribution shift.
  \item   \textbf{S}erendipity  \textbf{R}ecommendation (\textbf{SR}): Recommend new items to users to mitigate the information cocoon effect. Positive samples are real click behaviors, whose categories have not appeared in user behaviors.
  \item    \textbf{L}ong-term \textbf{R}ecommendation (\textbf{LR}): Recommend items based on long-term behaviors of users. Positive samples are the users' real click behaviors, whose categories only appear in the long-term user behavior sequence.
  \item    \textbf{L}ong-tail \textbf{I}tem \textbf{R}ecommendation (\textbf{LIR}): 
    Recommend long-tail items to mitigate the bias of the recommender system. 
    Positive samples are the items that users have clicked, and the popularity of which is below a certain threshold.
  \item     \textbf{P}urchase \textbf{P}rediction (\textbf{PP}): Positive samples are the items that the users have purchased.
  \item   \textbf{S}earch \textbf{P}roblem (\textbf{SP}): Given a query, recommend the most relevant items that the user is most likely to be interested in. Positive samples are the user's click behaviors under a certain query.
\end{itemize}



This dataset contains billions of training samples in total. 
For URM, it is quite difficult to consume a vast amount of recommendation data in a short time. Therefore, we sample $12.7$ million training examples from the whole dataset. The amount of sampled training data for each task is shown in Table \ref{table:dataset_sample}.

\begin{table}[!h]
\addtolength{\tabcolsep}{30pt}
\centering
\footnotesize
\caption{Statistics of the sampled training dataset.}
\begin{tabular}{@{}cc@{}}
\toprule
\textbf{Task} & \textbf{\#Behaviors}   \\ \midrule
\textbf{C}ontext-free \textbf{R}ecommendation (\textbf{CR})   &  3,146,887        \\
\textbf{R}ecommendation for \textbf{S}cene \textbf{A} (\textbf{RSA})                & 559,449     \\
\textbf{R}ecommendation for \textbf{S}cene \textbf{B} (\textbf{RSB})                & 557,237 \\
\textbf{R}ecommendation for \textbf{S}cene \textbf{C} (\textbf{RSC})               & 1,331,326 \\
\textbf{S}erendipity   in \textbf{R}ecommendation (\textbf{SR})               &  1,097,952     \\
\textbf{L}ong-term \textbf{R}ecommendation (\textbf{LR})               & 1,169,954     \\
\textbf{L}ong-tail \textbf{I}tem \textbf{R}ecommendation (\textbf{LIR})              & 867,462   \\
\textbf{P}urchase \textbf{P}rediction (\textbf{PP})              & 103,205   \\
\textbf{S}earch \textbf{P}roblem (\textbf{SP})               &  3,909,578     \\
\bottomrule
\end{tabular}
\label{table:dataset_sample}
\end{table}

\subsection{Model Implementation Details}
\label{sec:Implementation}

\textbf{Two-tower Model.} 
Both the user-side features and the item-side features are flattened to $2$-dimensional,  and then fed into $3$-layer MLP networks with layers $[256, 128, 64]$ to obtain the final $64$-dimensional user embeddings and item embeddings. The user embeddings will not be normalized, while the item embeddings will be normalized.

\textbf{Transformer-based Model.}  After adding the position embedding, the user behavior sequence embedding, task embedding, and query embedding are concatenated and fed into a $5$-layer Transformer network, where each Transformer layer has $4$ heads and the dimension of the FFN layer is $4$ times larger than the input dimension. The embedding at the last position is taken as the user embedding. The item side follows the same as the two-tower model: features are flattened and then processed through a three-layer MLP network with dimensions $[256, 128, 64]$ to obtain the final $64$-dimensional embedding, which is then normalized.

\textbf{Attention-DNN.} The user side includes multiple aggregated features and $3$ sequence features of different lengths. The sequence features are used to compute cross attention with the item features \cite{zhou2018deep}. The item side also includes multiple features. After flattening all features, they are collectively fed into a fully connected network with layers $[256, 128, 64, 1]$ to obtain the final score.
Due to the increase in computation cost for each item, we build HNSW index \cite{HNSW} on the item embeddings for faster inference following \cite{zhu2018learning, chen2022approximate}. 


\textbf{Attention-DNN + Shared Bottom.} Retain the attention module and all features in Attention-DNN, and use different MLPs for modeling each task separately.

\textbf{Attention-DNN + MMoE.} Retain the attention module and all features in Attention-DNN, and introduce $4$ MLPs to generate the middle representations. The task embedding is fed into the gate network to obtain combination weights, which are then used to adaptively combine the outputs from the MLP.

\textbf{Attention-DNN + PLE.} Retain the attention module and all features in Attention-DNN and adopt $4$ MLPs for shared module and task-specific module separately to generate the middle representations with the dim of $64$. These middle representations of the $4$ shared modules and each task-specific module are then merged using a gate network and fed into each task's $2$-layered MLPs to obtain the final score.

\textbf{URM.} As illustrated in Figure \ref{fig:id_embedding}, URM first employs $2$ linear layers to project item semantic embeddings and item ID embeddings into $128$-dimensional embeddings. These embeddings are then summed and passed through an RMSNorm layer, a linear layer, and a normalization layer to obtain the final $128$-dimensional multimodal item embeddings. 
An additional linear layer will map the multimodal item embeddings into a $4096$-dimensional tensor. Simultaneously, the prompt text is also transformed into this dimension by the token embedding table. As depicted in Figure \ref{fig:arch}, once merged with positional embeddings, the input embeddings are fed into the LLM backbone. The hidden state from the final transformer layer will subsequently pass through an MLP layer and yield the final, non-normalized user embedding of size $H \times 128$.

\subsection{Training Details}
\label{sec:Hyperparameters}

For URM, we use AdamW with an initial learning rate of $2e^{-5}$, weight decay of $0.05$, batch size of $4096$, and cosine learning rate decay.
Each batch consists of $10,000$ negative examples, which are sampled from the item candidates according to the $3/4$ power of their occurrence frequency. The sampled training dataset is trained for a single epoch.
To preserve the pre-trained knowledge in LLM, we follow transfer learning \cite{DAN}
and set the learning rate of the pre-trained layers to be $1/10$  of the learning rate of the other layers.
Using Qwen-7B as the LLM backbone on $64$ NVIDIA H20 GPUs, it takes $33$ hours to process $12.7$ million training examples.


\section{More Experimental Results}

\subsection{Analysis of Inference Efficiency}
\label{appendix:inference_efficiency}
In the inference stage, our model architecture differs from conventional LLMs in two aspects: (1) the multimodal item embedding module and (2) the item retrieval module. Both modules are well-established within ID-based recommendation models and leverage mature, high-performance technologies. Specifically, for the multimodal item embedding module, we utilize distributed hashtable lookup technology to reduce the embedding retrieval latency to within a few milliseconds. For the item retrieval module, we employ HNSW retrieval, enabling efficient searches within a ten-million-item database in under 10 milliseconds.
Consequently, the negative impact of these two additional modules on performance is negligible, making our model nearly equivalent to an LLM inference with an output token length of $1$. This enables seamless utilization of existing inference frameworks (e.g., vLLM \cite{vllm}) and acceleration techniques (including batching, key-value caching, FlashAttention \cite{dao2022flashattention, dao2023flashattention2}, etc.).

We evaluated inference speed on NVIDIA H20 GPUs using Qwen-7B as the base model. With batch size=$4$ and input token length about $1024$, our system achieves batch latency of $~220$ms, single-GPU QPS of $20$, and daily throughput of $1.7$ million requests per GPU. In contrast, traditional LLM-based recommendation methods, which require auto-regressively generating multiple tokens, result in online latencies on the order of seconds and QPS less than $1$, significantly underperforming compared to our approach.


\subsection{Experiments on More LLM Backbones}
\label{appendix:more_backbone}
We also conduct experiments on Qwen-1.8B.
As shown in Table \ref{table:taobao-LLM-backbone}, Qwen-1.8B performs worse than Qwen-7B on most tasks, which indicates that larger-scale parameters also lead to better generalizability in recommendation tasks.


\begin{table*}[htbp]
\addtolength{\tabcolsep}{5pt}
\centering
\footnotesize
\caption{Comparison between Qwen-7B and 1.8B (metric: R@1000).}
\begin{tabular}{@{}llllllllllll@{}}
\toprule
\textbf{Methods}       & \textbf{CR} & \textbf{RSA} & \textbf{RSB} & \textbf{RSC} & \textbf{SR} & \textbf{LR} & \textbf{LIR}  & \textbf{PP} & \textbf{SP} & \textbf{AVG} \\ \midrule
Qwen-7B  &  \textbf{0.263} &
  \textbf{0.530} &
  \textbf{0.439} &
  \textbf{0.362} &
  \textbf{0.093} &
 \textbf{0.285} &
  \textbf{0.240 }&
  \textbf{0.581} &
  \textbf{0.835} &
  \textbf{0.403}   \\
Qwen-1.8B & 0.255 & 0.529 & 0.434 & 0.351 & 0.081 & 0.243  & 0.230  & 0.572 & \textbf{0.835}  & 0.392 \\
\bottomrule
\end{tabular}
\label{table:taobao-LLM-backbone}
\end{table*}


\subsection{More Experiments on Prompt Engineering}
\label{appendix:more_prompt_engineering}
\textbf{Long-tail Item Recommendation.} As shown in Table \ref{table:longtail_prompt}, after using the LIR Template, the proportion of long-tail items in the recommendation set increases by 49.5\% relatively.

\begin{table}[!h]
\vspace{-5pt}
\addtolength{\tabcolsep}{5pt}
\centering
\footnotesize
\caption{Effect of prompts on Long-tail Item Recommendation.}
\begin{tabular}{@{}llll@{}}
\toprule
\textbf{Template} &
  \textbf{\begin{tabular}[c]{@{}l@{}}CR\\ R@1000\end{tabular}} &
  \textbf{\begin{tabular}[c]{@{}l@{}}LIR\\ R@1000\end{tabular}} &
  \textbf{\begin{tabular}[c]{@{}l@{}}Percent of \\ Long-tail Items\end{tabular}} \\ \midrule
CR Template                   & \textbf{0.263} & \textbf{0.240}          & 54.6\%            \\
LIR Template                   & 0.202          & \textbf{0.240}   & \textbf{81.6\%}   \\
\midrule
\textbf{RI} &          -       & +0\% & \textbf{+49.5\%} \\ \bottomrule
\end{tabular}
\label{table:longtail_prompt}
\end{table}


\textbf{Long-term Recommendation.} As shown in Table \ref{table:longterm_prompt}, employing the LR Template results in a relative increase of 96.6\% in the proportion of items within the recommendation set that align with the user's long-term interests 
and a relative increase of  $36.4\% $ in LR R@1000.

\begin{table}[!h]
\addtolength{\tabcolsep}{5pt}
\centering
\footnotesize
\caption{Effect of prompts on Long-term Recommendation.}
\begin{tabular}{@{}llll@{}}
\toprule
\textbf{Template} &
  \textbf{\begin{tabular}[c]{@{}l@{}}CR\\ R@1000\end{tabular}} &
  \textbf{\begin{tabular}[c]{@{}l@{}}LR\\ R@1000\end{tabular}} &
  \textbf{\begin{tabular}[c]{@{}l@{}}Percent of Long-\\term Interest\end{tabular}} \\ \midrule
CR Template                   & \textbf{0.263} & 0.209          & 32.6\%           \\
LR Template                   & 0.149          & \textbf{0.285}  & \textbf{64.1\%}  \\
\midrule
\textbf{RI} & -               & \textbf{+36.4\%} & \textbf{+96.6\%} \\ \bottomrule
\end{tabular}
\label{table:longterm_prompt}
\end{table}

\textbf{Diversity of Recommendation Result.} In some of the training data, we inject the number of categories in the target set into the prompt as shown below. 
 \begin{tcolorbox}[colback=blue!2!white,leftrule=2.5mm,size=title]
\label{obs1}
 Inputs: The items the user has recently clicked on are as follows: \{USER BEHAVIOR SEQUENCE\}. Please recommend the top $\{K\}$  categories that users are most likely to be interested in. \textbf{[$\text{UM}$][$\text{LM}$]}
\end{tcolorbox}
Then, during the test stage, we observe that by adjusting the size of $K$ in the prompt, we could modify the category diversity in the recommendation set as shown in Table \ref{table:diversity_prompt}.



\begin{table}[!h]
\addtolength{\tabcolsep}{5pt}
\centering
\footnotesize
\caption{Effect of prompts on recommendation diversity.}
\begin{tabular}{@{}ccc@{}}
\toprule
\textbf{K} & \textbf{Category Recall@1000} & \textbf{\#Category} \\ \midrule
4          & 0.767               & 74.7                   \\
8          & 0.772               & 80.8                   \\
16         & 0.775               & 94.1                   \\
32         & 0.777               & 104.2                  \\
64         & 0.778               & 113.7                  \\
128        & \textbf{0.780}               & \textbf{117.1}                  \\
\midrule
\textbf{RI  }       & \textbf{+1.7\%}      & \textbf{+56.8\%}       \\ \bottomrule
\end{tabular}
\label{table:diversity_prompt}
\end{table}


\subsection{More Experiments on Zero-shot Task Transfer}
\label{appendix:zero_shot_prompt}

\textbf{New Prompt: Serendipity \& Purchase Prediction.}
As shown in Table \ref{table:mix_ER_PP}, when the SR template and PP template are combined, the set produced by the URM aligns better with the purchase objective, thereby improving PP R@1000 compared to using the SR template. At the same time, the percentage of new categories in the output set also increases compared to that of the PP template. 
This makes the recommended set close to the distribution of items that the user has not clicked on before but is highly likely to purchase next.



\begin{table}[!h]
\addtolength{\tabcolsep}{5pt}
\centering
\footnotesize
\caption{The result of hybridizing the SR and PP templates.}
\begin{tabular}{@{}lll@{}}
\toprule
\textbf{Metric} & \textbf{\begin{tabular}[c]{@{}l@{}}PP\\ R@1000\end{tabular}} & \textbf{\begin{tabular}[c]{@{}l@{}}Percent of \\ New Category\end{tabular}} \\ \midrule
PP Template      & \textbf{0.581} & 25.6\%          \\
SR Template      & 0.411          & \textbf{46.2\%} \\
PP $\times$ SR Template & 0.510          & 45.1\%          \\ \bottomrule
\end{tabular}
\label{table:mix_ER_PP}
\end{table}

\textbf{New Prompt: Long-tail Item Recommendation for Scene A.}
As shown in Table \ref{table:mix_RSA_LIR}, when the RSA template and LIR template are combined, the output set is closer to the distribution of scenario A, thereby improving RSA R@1000 compared to using the LIR template. 
Additionally, there is an increase in the proportion of long-tail items within the output set compared to the RSA template alone. Consequently, the recommended set becomes more representative of the long-tail items that are most likely to occur in scenario A.

\begin{table}[!h]
\addtolength{\tabcolsep}{5pt}
\centering
\footnotesize
\caption{The result of hybridizing the RSA and LIR templates.}
\begin{tabular}{@{}lll@{}}
\toprule
\textbf{Metric} & \textbf{\begin{tabular}[c]{@{}l@{}}RSA\\ R@1000\end{tabular}} & \textbf{\begin{tabular}[c]{@{}l@{}}Percent of \\ Long-tail Items\end{tabular}} \\ \midrule
RSA Template       & \textbf{0.530} & 72.6\%          \\
LIR Template       & 0.410          & \textbf{81.6\%} \\
RSA $\times$ LIR Template & 0.483          & 81.5\%          \\ \bottomrule
\end{tabular}
\label{table:mix_RSA_LIR}
\end{table}

\textbf{New Prompt.}
Further, we validate the zero-shot task transfer performance from the CR task to the SP task.
As shown in Figure \ref{fig:compare_sp}, as the number of training samples increases, URM trained only on the CR task can still learn the mapping between the query and target sets and reach $0.698$ on SP R@1000! The reason is that our training loss includes the language modeling loss, which allows the URM to align item embeddings with the semantic space, even when no query-related tasks exist in the  training samples. 
Of course,  the performance of zero-shot task transfer still has a significant gap with supervised training on the corresponding task (MTL vs STL on CR). 
However, this fully demonstrates that URM inherits the powerful task transfer capabilities of LLM and also underscores the importance of retaining LM loss.

\begin{figure}[!h]
    \centering
    \includegraphics[width=0.5\linewidth]{figs/comparison_sp.pdf}
    \caption{Zero-shot task transfer performance from the CR task to the SP task.}
    \label{fig:compare_sp}
\end{figure}


\textbf{New Context.}
By modifying the query in the SP prompt to a specific context,  we can model the changes in user behavior over periods, such as during seasonal changes, festival celebrations, or shopping events.
Figure \ref{fig:zero_shot_query} gives two examples.
The fundamental reason why URM can achieve this is that the training data for the SP (search problem) has established a broad mapping relationship between user behaviors, text constraints, and the target item set.
This has two potential advantages. 
\begin{enumerate}
    \item By changing the query to a certain context, we can inject external world knowledge into URM, allowing the recommendation results to get ready for potential upcoming events.
    \item This also supports the combination of URM and Chain-of-Thought (CoT) technologies \cite{wei2023chainofthoughtpromptingelicitsreasoning}. Specifically, the LLM generates intermediate results in the form of text through reasoning, and then injects this text as context into URM, thereby producing the final set.
\end{enumerate}

\begin{figure}[!h]
    \centering
    \begin{subfigure}
        \centering
        \includegraphics[width=0.8\linewidth]{figs/QueryCase1.pdf}
        \label{fig:query_case1}
    \end{subfigure}
    
    \hfill
    
    \begin{subfigure}
        \centering
        \includegraphics[width=0.8\linewidth]{figs/QueryCase2.pdf}
        \label{fig:query_case2}
    \end{subfigure}
    
    \hfill

    \caption{Zero task transfer to a new context. Christmas is a festive celebration, and heating is a common need in winter. When these two contexts are injected as queries into the prompt, the model can provide recommendations based on the user's historical behavior and the given context simultaneously.
}
    \label{fig:zero_shot_query}
\end{figure}


\clearpage

\subsection{Visualization Comparison of Different Item Representation}
\label{appedix:visualize_item}
To visualize different item representations, we use the nearest neighbor retrieval approach to find similar items of a given item under a specific representation.
As shown in Figure \ref{fig:emb_case},\ref{fig:emb_case3}, 
semantic embeddings mainly capture similarity relationships, whereas ID embeddings are more centered on co-occurrence relationships. The multimodal fusion representations fall somewhere in between these two.






\begin{figure}[!h]
    \centering
    \begin{subfigure}
        \centering
        \includegraphics[width=0.8\linewidth]{figs/EmbCase1.pdf}
        \label{fig:emb_case1}
    \end{subfigure}
    
    \hfill
    
    \begin{subfigure}
        \centering
        \includegraphics[width=0.8\linewidth]{figs/EmbCase2.pdf}
        \label{fig:emb_case2}
    \end{subfigure}
    
    \hfill
    
    \caption{Visualization of different item representations}
    \label{fig:emb_case}
\end{figure}

\newpage

\begin{figure}[!h]
    \centering
        \includegraphics[width=0.8\linewidth]{figs/EmbCase3.pdf}
    \caption{Visualization of different item representations}
        \label{fig:emb_case3}
\end{figure}





\subsection{More Experiments on the Effect of [UM] Token}
\textbf{Visualization of User Embeddings from Different [UM] Tokens.} To further validate the role of the [UM] token, we categorize the output $1000$ items from URM into the user embeddings that have the largest inner product with it. The items under the $3$ user embeddings are shown in Figure \ref{fig:head_case}. It can be observed that different low-dimensional user embeddings have captured different user interests, which enhances the representation ability of URM for the target item set.

\begin{figure}[!h]
    \centering
    \includegraphics[width=0.7\linewidth]{figs/HeadCase.pdf}
    \caption{Visualization of user embeddings from different [UM] tokens. Each token captures distinct facets of user interest, enabling LLM to jointly express different aspects of the target item set.}
    \label{fig:head_case}
\end{figure}

\textbf{Activation of [UM] Tokens on Different Tasks.} 
Figure \ref{fig:head_proportion} shows the activation proportion for $8$ different [UM] tokens in the CR and SP tasks. A token is activated when the dot product of the user embedding corresponding to that [UM] token and the target multimodal embedding is used for the final output.
We find that different [UM] tokens exhibit variation across different tasks. 

\begin{figure}[!h]
    \centering
    \includegraphics[width=0.5\linewidth]{figs/head_proportion.pdf}
    \caption{Activation proportion of different [UM] tokens in CR and SP tasks.}
    \label{fig:head_proportion}
\end{figure}

\textbf{The Necessity of Multi-[UM]-Token Format.}
URM employs multiple [UM] tokens to generate several 128-dimensional output user embeddings, which are subsequently computed alongside the 128-dimensional multimodal item embedding. To explore the effect of the multi-token format, we conducted experiments using higher embedding dimensions and a single token, with the results presented in Table \ref{table:multi_token}. On one hand, when a single token is used to derive a 4096-dimensional user embedding, which is then split into 32 separate 128-dimensional embeddings, the CR recall drops significantly from 0.248 to 0.163. This highlights the advantage of generating multiple user embeddings with different tokens, even when the formal dimension remains constant. On the other hand, increasing the multimodal item embedding dimension from 128 to 4096 (resulting in logits computed in a higher-dimensional space) does not enhance performance compared to the logits derived from multiple tokens, yielding a mere CR recall of 0.203. These findings confirm that the Multi-[UM]-Token design doesn't solely benefit from its higher dimensionality; rather, it demonstrates superior effectiveness in capturing the diverse interests of users within this specific format.

\begin{table}[!h]
\addtolength{\tabcolsep}{10pt}
\centering
\footnotesize
\caption{The effect of multi-token (metric: R@1000).}
\begin{tabular}{@{}lll@{}}
\toprule
\textbf{Methods} & \begin{tabular}[c]{@{}l@{}}\textbf{CR}\end{tabular} & \begin{tabular}[c]{@{}l@{}}\textbf{SP} \end{tabular} \\ \midrule
32 Tokens with 128-d Embeddings   & \textbf{0.248}                                                    & \textbf{0.835}                                                     \\
1 Token with 4096-d Output User Embedding               & 0.163                                                    & 0.774       \\
1 Token with 4096-d Multimodal Item Embedding & 0.203 & 0.781
\\ \bottomrule
\end{tabular}
\label{table:multi_token}
\end{table}

\newpage



\end{document}
