[
  {
    "index": 0,
    "papers": [
      {
        "key": "chen2024internvl",
        "author": "Chen, Zhe and Wu, Jiannan and Wang, Wenhai and Su, Weijie and Chen, Guo and Xing, Sen and Zhong, Muyan and Zhang, Qinglong and Zhu, Xizhou and Lu, Lewei and others",
        "title": "Internvl: Scaling up vision foundation models and aligning for generic visual-linguistic tasks"
      },
      {
        "key": "li2024llava",
        "author": "Li, Feng and Zhang, Renrui and Zhang, Hao and Zhang, Yuanhan and Li, Bo and Li, Wei and Ma, Zejun and Li, Chunyuan",
        "title": "LLaVA-NeXT-Interleave: Tackling Multi-image, Video, and 3D in Large Multimodal Models"
      }
    ]
  },
  {
    "index": 1,
    "papers": [
      {
        "key": "siglip",
        "author": "Xiaohua Zhai and Basil Mustafa and Alexander Kolesnikov and Lucas Beyer",
        "title": "Sigmoid Loss for Language Image Pre-Training"
      }
    ]
  },
  {
    "index": 2,
    "papers": [
      {
        "key": "zong2024movaadaptingmixturevision",
        "author": "Zhuofan Zong and Bingqi Ma and Dazhong Shen and Guanglu Song and Hao Shao and Dongzhi Jiang and Hongsheng Li and Yu Liu",
        "title": "MoVA: Adapting Mixture of Vision Experts to Multimodal Context"
      }
    ]
  },
  {
    "index": 3,
    "papers": [
      {
        "key": "shi2024eagleexploringdesignspace",
        "author": "Min Shi and Fuxiao Liu and Shihao Wang and Shijia Liao and Subhashree Radhakrishnan and De-An Huang and Hongxu Yin and Karan Sapra and Yaser Yacoob and Humphrey Shi and Bryan Catanzaro and Andrew Tao and Jan Kautz and Zhiding Yu and Guilin Liu",
        "title": "Eagle: Exploring The Design Space for Multimodal LLMs with Mixture of Encoders"
      }
    ]
  },
  {
    "index": 4,
    "papers": [
      {
        "key": "azadani2025leo",
        "author": "Azadani, Mozhgan Nasr and Riddell, James and Sedwards, Sean and Czarnecki, Krzysztof",
        "title": "LEO: Boosting Mixture of Vision Encoders for Multimodal Large Language Models"
      }
    ]
  }
]