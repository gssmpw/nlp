@article{blasi_label-free_2016,
	title = {Label-free cell cycle analysis for high-throughput imaging flow cytometry},
	volume = {7},
	rights = {2016 The Author(s)},
	issn = {2041-1723},
	abstract = {Imaging flow cytometry combines the high-throughput capabilities of conventional flow cytometry with single-cell imaging. Here we demonstrate label-free prediction of {DNA} content and quantification of the mitotic cell cycle phases by applying supervised machine learning to morphological features extracted from brightfield and the typically ignored darkfield images of cells from an imaging flow cytometer. This method facilitates non-destructive monitoring of cells avoiding potentially confounding effects of fluorescent stains while maximizing available fluorescence channels. The method is effective in cell cycle analysis for mammalian cells, both fixed and live, and accurately assesses the impact of a cell cycle mitotic phase blocking agent. As the same method is effective in predicting the {DNA} content of fission yeast, it is likely to have a broad application to other cell types.},
	pages = {10256},
	number = {1},
	journal = {Nature Communications},
	shortjournal = {Nat Commun},
	author = {Blasi, Thomas and Hennig, Holger and Summers, Huw D. and Theis, Fabian J. and Cerveira, Joana and Patterson, James O. and Davies, Derek and Filby, Andrew and Carpenter, Anne E. and Rees, Paul},
	urldate = {2025-01-06},
	date = {2016-01-07},
	langid = {english},
	note = {Publisher: Nature Publishing Group},
	keywords = {Bioinformatics, Cell division, Flow cytometry},
}

@INPROCEEDINGS{chu_prediction_2020,
  author={Chu, Slo-Li and Abe, Kuniya and Yokota, Hideo and Sudo, Kazuhiro and Nakamura, Yukio and Chang, Yuan-Hsiang and Fang, Liang-Che and Tsai, Ming-Dar},
  booktitle={2020 42nd Annual International Conference of the IEEE Engineering in Medicine \& Biology Society (EMBC)}, 
  title={Prediction for Morphology and States of Stem Cell Colonies using a LSTM Network with Progressive Training Microscopy Images}, 
  year={2020},
  volume={},
  number={},
  pages={1820-1823},
  keywords={Training;Microscopy;Computer architecture;Morphology;Corporate acquisitions;Hip;Microprocessors},
  doi={10.1109/EMBC44109.2020.9175759}

@article{eulenberg_reconstructing_2017,
	title = {Reconstructing cell cycle and disease progression using deep learning},
	volume = {8},
	rights = {2017 The Author(s)},
	issn = {2041-1723},
	abstract = {We show that deep convolutional neural networks combined with nonlinear dimension reduction enable reconstructing biological processes based on raw image data. We demonstrate this by reconstructing the cell cycle of Jurkat cells and disease progression in diabetic retinopathy. In further analysis of Jurkat cells, we detect and separate a subpopulation of dead cells in an unsupervised manner and, in classifying discrete cell cycle stages, we reach a sixfold reduction in error rate compared to a recent approach based on boosting on image features. In contrast to previous methods, deep learning based predictions are fast enough for on-the-fly analysis in an imaging flow cytometer.},
	pages = {463},
	number = {1},
	journal = {Nature Communications},
	shortjournal = {Nat Commun},
	author = {Eulenberg, Philipp and Köhler, Niklas and Blasi, Thomas and Filby, Andrew and Carpenter, Anne E. and Rees, Paul and Theis, Fabian J. and Wolf, F. Alexander},
	urldate = {2025-01-06},
	date = {2017-09-06},
	langid = {english},
	note = {Publisher: Nature Publishing Group},
	keywords = {Cell division, Image processing, Machine learning},
}

@article{gu_efficiently_2022,
	title = {Efficiently Modeling Long Sequences with Structured State Spaces},
	abstract = {A central goal of sequence modeling is designing a single principled model that can address sequence data across a range of modalities and tasks, particularly on long-range dependencies. Although conventional models including {RNNs}, {CNNs}, and Transformers have specialized variants for capturing long dependencies, they still struggle to scale to very long sequences of \$10000\$ or more steps. A promising recent approach proposed modeling sequences by simulating the fundamental state space model ({SSM}) {\textbackslash}( x'(t) = Ax(t) + Bu(t), y(t) = Cx(t) + Du(t) {\textbackslash}), and showed that for appropriate choices of the state matrix {\textbackslash}( A {\textbackslash}), this system could handle long-range dependencies mathematically and empirically. However, this method has prohibitive computation and memory requirements, rendering it infeasible as a general sequence modeling solution. We propose the Structured State Space sequence model (S4) based on a new parameterization for the {SSM}, and show that it can be computed much more efficiently than prior approaches while preserving their theoretical strengths. Our technique involves conditioning {\textbackslash}( A {\textbackslash}) with a low-rank correction, allowing it to be diagonalized stably and reducing the {SSM} to the well-studied computation of a Cauchy kernel. S4 achieves strong empirical results across a diverse range of established benchmarks, including (i) 91{\textbackslash}\% accuracy on sequential {CIFAR}-10 with no data augmentation or auxiliary losses, on par with a larger 2-D {ResNet}, (ii) substantially closing the gap to Transformers on image and language modeling tasks, while performing generation \$60{\textbackslash}times\$ faster (iii) {SoTA} on every task from the Long Range Arena benchmark, including solving the challenging Path-X task of length 16k that all prior work fails on, while being as efficient as all competitors.},
	number = {{arXiv}:2111.00396},
	publisher = {{arXiv}},
	author = {Gu, Albert and Goel, Karan and Ré, Christopher},
	urldate = {2025-01-07},
	date = {2022-08-05},
    year={2022},
	journal = {arXiv},
	eprint = {2111.00396 [cs]},
	keywords = {Computer Science - Machine Learning},
}

@article{gu_mamba_2024,
  title={Mamba: Linear-Time Sequence Modeling with Selective State Spaces},
  author={Gu, Albert and Dao, Tri},
  journal={arXiv preprint arXiv:2312.00752},
  year={2023}
}

@article{he_cell_2022,
	title = {Cell Cycle Stage Classification Using Phase Imaging with Computational Specificity},
	volume = {9},
	abstract = {Traditional methods for cell cycle stage classification rely heavily on fluorescence microscopy to monitor nuclear dynamics. These methods inevitably face the typical phototoxicity and photobleaching limitations of fluorescence imaging. Here, we present a cell cycle detection workflow using the principle of phase imaging with computational specificity ({PICS}). The proposed method uses neural networks to extract cell cycle-dependent features from quantitative phase imaging ({QPI}) measurements directly. Our results indicate that this approach attains very good accuracy in classifying live cells into G1, S, and G2/M stages, respectively. We also demonstrate that the proposed method can be applied to study single-cell dynamics within the cell cycle as well as cell population distribution across different stages of the cell cycle. We envision that the proposed method can become a nondestructive tool to analyze cell cycle progression in fields ranging from cell biology to biopharma applications.},
	pages = {1264--1273},
	number = {4},
	journal = {{ACS} Photonics},
	shortjournal = {{ACS} Photonics},
	author = {He, Yuchen R. and He, Shenghua and Kandel, Mikhail E. and Lee, Young Jae and Hu, Chenfei and Sobh, Nahil and Anastasio, Mark A. and Popescu, Gabriel},
	urldate = {2023-11-14},
	date = {2022-04-20},
	note = {Publisher: American Chemical Society},
}

@article{held_cellcognition_2010,
	title = {{CellCognition}: time-resolved phenotype annotation in high-throughput live cell imaging},
	volume = {7},
	rights = {2010 Springer Nature America, Inc.},
	issn = {1548-7105},
	shorttitle = {{CellCognition}},
	abstract = {Incorporation of time information into the annotation of distinct biological states in automated fluorescence time-lapse live-cell imaging of complex cellular dynamics reduces both classification noise and confusion between cell states with similar morphology. A computational framework for achieving this is implemented in the open-source software package {CellCognition}.},
	pages = {747--754},
	number = {9},
	journal = {Nature Methods},
	shortjournal = {Nat Methods},
	author = {Held, Michael and Schmitz, Michael H. A. and Fischer, Bernd and Walter, Thomas and Neumann, Beate and Olma, Michael H. and Peter, Matthias and Ellenberg, Jan and Gerlich, Daniel W.},
	urldate = {2025-01-23},
	date = {2010-09},
	langid = {english},
	note = {Publisher: Nature Publishing Group},
	keywords = {Machine learning, Software, Time-lapse imaging},
}

@article{hewamalage2021recurrent,
title = {Recurrent Neural Networks for Time Series Forecasting: Current status and future directions},
journal = {International Journal of Forecasting},
volume = {37},
number = {1},
pages = {388-427},
year = {2021},
issn = {0169-2070},
author = {Hansika Hewamalage and Christoph Bergmeir and Kasun Bandara},
keywords = {Big data, Forecasting, Best practices, Framework},
abstract = {Recurrent Neural Networks (RNNs) have become competitive forecasting methods, as most notably shown in the winning method of the recent M4 competition. However, established statistical models such as exponential smoothing (ETS) and the autoregressive integrated moving average (ARIMA) gain their popularity not only from their high accuracy, but also because they are suitable for non-expert users in that they are robust, efficient, and automatic. In these areas, RNNs have still a long way to go. We present an extensive empirical study and an open-source software framework of existing RNN architectures for forecasting, and we develop guidelines and best practices for their use. For example, we conclude that RNNs are capable of modelling seasonality directly if the series in the dataset possess homogeneous seasonal patterns; otherwise, we recommend a deseasonalisation step. Comparisons against ETS and ARIMA demonstrate that (semi-) automatic RNN models are not silver bullets, but they are nevertheless competitive alternatives in many situations.}
}

@article{jin_imbalanced_2021,
	title = {An Imbalanced Image Classification Method for the Cell Cycle Phase},
	volume = {12},
	rights = {http://creativecommons.org/licenses/by/3.0/},
	issn = {2078-2489},
	abstract = {The cell cycle is an important process in cellular life. In recent years, some image processing methods have been developed to determine the cell cycle stages of individual cells. However, in most of these methods, cells have to be segmented, and their features need to be extracted. During feature extraction, some important information may be lost, resulting in lower classification accuracy. Thus, we used a deep learning method to retain all cell features. In order to solve the problems surrounding insufficient numbers of original images and the imbalanced distribution of original images, we used the Wasserstein generative adversarial network-gradient penalty ({WGAN}-{GP}) for data augmentation. At the same time, a residual network ({ResNet}) was used for image classification. {ResNet} is one of the most used deep learning classification networks. The classification accuracy of cell cycle images was achieved more effectively with our method, reaching 83.88\%. Compared with an accuracy of 79.40\% in previous experiments, our accuracy increased by 4.48\%. Another dataset was used to verify the effect of our model and, compared with the accuracy from previous results, our accuracy increased by 12.52\%. The results showed that our new cell cycle image classification system based on {WGAN}-{GP} and {ResNet} is useful for the classification of imbalanced images. Moreover, our method could potentially solve the low classification accuracy in biomedical images caused by insufficient numbers of original images and the imbalanced distribution of original images.},
	pages = {249},
	number = {6},
	journal = {Information},
	author = {Jin, Xin and Zou, Yuanwen and Huang, Zhongbing},
	urldate = {2025-01-06},
	date = {2021-06},
	langid = {english},
	note = {Number: 6
Publisher: Multidisciplinary Digital Publishing Institute},
	keywords = {Wasserstein generative adversarial network-gradient penalty, cell cycle, deep learning, image classification, imbalanced image datasets, residual network},
}

@article{jose_automatic_2024,
	title = {Automatic detection of cell-cycle stages using recurrent neural networks.},
	volume = {19},
	copyright = {Copyright: © 2024 Jose et al. This is an open access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted  use, distribution, and reproduction in any medium, provided the original author  and source are credited.},
	issn = {1932-6203},
	abstract = {Mitosis is the process by which eukaryotic cells divide to produce two similar daughter cells with identical genetic material. Research into the process of  mitosis is therefore of critical importance both for the basic understanding of  cell biology and for the clinical approach to manifold pathologies resulting from  its malfunctioning, including cancer. In this paper, we propose an approach to  study mitotic progression automatically using deep learning. We used neural  networks to predict different mitosis stages. We extracted video sequences of  cells undergoing division and trained a Recurrent Neural Network (RNN) to extract  image features. The use of RNN enabled better extraction of features. The  RNN-based approach gave better performance compared to classifier based feature  extraction methods which do not use time information. Evaluation of precision,  recall, and F-score indicates the superiority of the proposed model compared to  the baseline. To study the loss in performance due to confusion between adjacent  classes, we plotted the confusion matrix as well. In addition, we visualized the  feature space to understand why RNNs are better at classifying the mitosis stages  than other classifier models, which indicated the formation of strong clusters  for the different classes, clearly confirming the advantage of the proposed  RNN-based approach.},
	language = {eng},
	number = {3},
	journal = {PloS one},
	author = {Jose, Abin and Roy, Rijo and Moreno-Andrés, Daniel and Stegmaier, Johannes},
	year = {2024},
	pmid = {38466708},
	pmcid = {PMC10927108},
	keywords = {*Mitosis, *Neural Networks, Computer},
	pages = {e0297356},
}

@article{li_predicting_2024,
	title = {Predicting cell cycle stage from 3D single-cell nuclear-stained images},
	rights = {© 2024, Posted by Cold Spring Harbor Laboratory. This pre-print is available under a Creative Commons License (Attribution-{NonCommercial} 4.0 International), {CC} {BY}-{NC} 4.0, as described at http://creativecommons.org/licenses/by-nc/4.0/},
	abstract = {The cell cycle governs the proliferation, differentiation, and regeneration of all eukaryotic cells. Profiling cell cycle dynamics is therefore central to basic and biomedical research spanning development, health, aging, and disease. However, current approaches to cell cycle profiling involve complex interventions that may confound experimental interpretation. To facilitate more efficient cell cycle annotation of microscopy data, we developed {CellCycleNet}, a machine learning ({ML}) workflow designed to simplify cell cycle staging with minimal experimenter intervention and cost. {CellCycleNet} accurately predicts cell cycle phase using only a fluorescent nuclear stain ({DAPI}) in fixed interphase cells. Using the Fucci2a cell cycle reporter system as ground truth, we collected two benchmarking image datasets and trained two {ML} models—a support vector machine ({SVM}) and a deep neural network—to classify nuclei as being in either the G1 or S/G2 phases of the cell cycle. Our results suggest that {CellCycleNet} outperforms state-of-the-art {SVM} models on each dataset individually. When trained on two image datasets simultaneously, {CellCycleNet} achieves the highest classification accuracy, with an improvement in {AUROC} of 0.08–0.09. The model also demonstrates excellent generalization across different microscopes, achieving an {AUROC} of 0.95. Overall, using features derived from 3D images, rather than 2D projections of those same images, significantly improves classification performance. We have released our image data, trained models, and software as a community resource.},
	publisher = {{bioRxiv}},
	author = {Li, Gang and Nichols, Eva K. and Browning, Valentino E. and Longhi, Nicolas J. and Camplisson, Conor and Beliveau, Brian J. and Noble, William Stafford},
	urldate = {2024-12-12},
	date = {2024-09-01},
    journal={bioRxiv},
	langid = {english},
}

@article{moreno-andres_livecellminer_2022,
	title = {{LiveCellMiner}: A new tool to analyze mitotic progression},
	volume = {17},
	issn = {1932-6203},
	shorttitle = {{LiveCellMiner}},
	abstract = {Live-cell imaging has become state of the art to accurately identify the nature of mitotic and cell cycle defects. Low- and high-throughput microscopy setups have yield huge data amounts of cells recorded in different experimental and pathological conditions. Tailored semi-automated and automated image analysis approaches allow the analysis of high-content screening data sets, saving time and avoiding bias. However, they were mostly designed for very specific experimental setups, which restricts their flexibility and usability. The general need for dedicated experiment-specific user-annotated training sets and experiment-specific user-defined segmentation parameters remains a major bottleneck for fully automating the analysis process. In this work we present {LiveCellMiner}, a highly flexible open-source software tool to automatically extract, analyze and visualize both aggregated and time-resolved image features with potential biological relevance. The software tool allows analysis across high-content data sets obtained in different platforms, in a quantitative and unbiased manner. As proof of principle application, we analyze here the dynamic chromatin and tubulin cytoskeleton features in human cells passing through mitosis highlighting the versatile and flexible potential of this tool set.},
	pages = {e0270923},
	number = {7},
	journal = {{PLOS} {ONE}},
	shortjournal = {{PLOS} {ONE}},
	author = {Moreno-Andrés, Daniel and Bhattacharyya, Anuk and Scheufen, Anja and Stegmaier, Johannes},
	urldate = {2025-01-23},
	date = {2022-07-07},
	langid = {english},
	note = {Publisher: Public Library of Science},
	keywords = {Anaphase, Cell cycle and cell division, Chromatin, Data visualization, Metaphase, Mitosis, Morphogenic segmentation, Prophase},
}

@article{narotamo_machine_2021,
	title = {A machine learning approach for single cell interphase cell cycle staging},
	volume = {11},
	rights = {2021 The Author(s)},
	issn = {2045-2322},
	abstract = {The cell nucleus is a tightly regulated organelle and its architectural structure is dynamically orchestrated to maintain normal cell function. Indeed, fluctuations in nuclear size and shape are known to occur during the cell cycle and alterations in nuclear morphology are also hallmarks of many diseases including cancer. Regrettably, automated reliable tools for cell cycle staging at single cell level using in situ images are still limited. It is therefore urgent to establish accurate strategies combining bioimaging with high-content image analysis for a bona fide classification. In this study we developed a supervised machine learning method for interphase cell cycle staging of individual adherent cells using in situ fluorescence images of nuclei stained with {DAPI}. A Support Vector Machine ({SVM}) classifier operated over normalized nuclear features using more than 3500 {DAPI} stained nuclei. Molecular ground truth labels were obtained by automatic image processing using fluorescent ubiquitination-based cell cycle indicator (Fucci) technology. An average F1-Score of 87.7\% was achieved with this framework. Furthermore, the method was validated on distinct cell types reaching recall values higher than 89\%. Our method is a robust approach to identify cells in G1 or S/G2 at the individual level, with implications in research and clinical applications.},
	pages = {19278},
	number = {1},
	journal = {Scientific Reports},
	shortjournal = {Sci Rep},
	author = {Narotamo, Hemaxi and Fernandes, Maria Sofia and Moreira, Ana Margarida and Melo, Soraia and Seruca, Raquel and Silveira, Margarida and Sanches, João Miguel},
	urldate = {2025-01-17},
	date = {2021-09-29},
	langid = {english},
	note = {Publisher: Nature Publishing Group},
	keywords = {Cellular imaging, Genomics, Image processing},
}

@article{rappez_deepcycle_2020,
	title = {{DeepCycle} reconstructs a cyclic cell cycle trajectory from unsegmented cell images using convolutional neural networks},
	volume = {16},
	issn = {1744-4292, 1744-4292},
	number = {10},
	journal = {Molecular Systems Biology},
	shortjournal = {Mol Syst Biol},
	author = {Rappez, Luca and Rakhlin, Alexander and Rigopoulos, Angelos and Nikolenko, Sergey and Alexandrov, Theodore},
	urldate = {2020-10-30},
	date = {2020-10},
	langid = {english},
	note = {{ZSCC}: 0000000},
}

@article{su_spatiotemporal_2017,
  author={Su, Yu-Ting and Lu, Yao and Chen, Mei and Liu, An-An},
  journal={IEEE Access}, 
  title={Spatiotemporal Joint Mitosis Detection Using CNN-LSTM Network in Time-Lapse Phase Contrast Microscopy Images}, 
  year={2017},
  volume={5},
  number={},
  pages={18033-18041},
  keywords={Feature extraction;Microscopy;Machine learning;Hidden Markov models;Computer architecture;Spatiotemporal phenomena;Visualization;Biomedical imaging;computer vision;mitosis detection;machine learning;stem cell},
}

@inproceedings{ulicna_learning_2023,
	title = {Learning dynamic image representations for self-supervised cell cycle annotation},
	abstract = {Time-based comparisons of single-cell trajectories are challenging due to their intrinsic heterogeneity, autonomous decisions, dynamic transitions and unequal lengths. In this paper, we present a self-supervised framework combining an image autoencoder with dynamic time series analysis of latent feature space to represent, compare and annotate cell cycle phases across singlecell trajectories. In our fully data-driven approach, we map similarities between heterogeneous cell tracks and generate statistical representations of single-cell trajectory phase durations, onset and transitions. This work is a first effort to transform a sequence of learned image representations from cell cycle-specific reporters into an unsupervised sequence annotation.},
	institution = {Cell Biology},
  maintitle = {ICML},
  booktitle = {Workshop on Computational Biology},    
	type = {preprint},
	author = {Ulicna, Kristina and Kelkar, Manasi and Soelistyo, Christopher J and Charras, Guillaume T and Lowe, Alan R},
	urldate = {2023-06-09},
	date = {2023-05-31},
	langid = {english},
}

@inproceedings{vaswani_attention_nodate,
 author = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, \L ukasz and Polosukhin, Illia},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {I. Guyon and U. Von Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {Attention is All you Need},
 volume = {30},
 year = {2017}
}

@article{wang_live-cell_2020,
	title = {Live-cell imaging and analysis reveal cell phenotypic transition dynamics inherently missing in snapshot data},
	volume = {6},
	abstract = {Recent advances in single-cell techniques catalyze an emerging field of studying how cells convert from one phenotype to another, in a step-by-step process. Two grand technical challenges, however, impede further development of the field. Fixed cell–based approaches can provide snapshots of high-dimensional expression profiles but have fundamental limits on revealing temporal information, and fluorescence-based live-cell imaging approaches provide temporal information but are technically challenging for multiplex long-term imaging. We first developed a live-cell imaging platform that tracks cellular status change through combining endogenous fluorescent labeling that minimizes perturbation to cell physiology and/or live-cell imaging of high-dimensional cell morphological and texture features. With our platform and an A549 {VIM}-{RFP} epithelial-to-mesenchymal transition ({EMT}) reporter cell line, live-cell trajectories reveal parallel paths of {EMT} missing from snapshot data due to cell-cell dynamic heterogeneity. Our results emphasize the necessity of extracting dynamical information of phenotypic transitions from multiplex live-cell imaging.},
	pages = {eaba9319},
	number = {36},
	journal = {Science Advances},
	author = {Wang, Weikang and Douglas, Diana and Zhang, Jingyu and Kumari, Sangeeta and Enuameh, Metewo Selase and Dai, Yan and Wallace, Callen T. and Watkins, Simon C. and Shu, Weiguo and Xing, Jianhua},
	urldate = {2025-01-23},
	date = {2020-09-04},
    year = {2020},
	note = {Publisher: American Association for the Advancement of Science},
}

@inproceedings{wen2022transformers,
  title     = {Transformers in Time Series: A Survey},
  author    = {Wen, Qingsong and Zhou, Tian and Zhang, Chaoli and Chen, Weiqi and Ma, Ziqing and Yan, Junchi and Sun, Liang},
  booktitle = {Proceedings of the Thirty-Second International Joint Conference on
               Artificial Intelligence, {IJCAI-23}},
  publisher = {International Joint Conferences on Artificial Intelligence Organization},
  editor    = {Edith Elkind},
  pages     = {6778--6786},
  year      = {2023},
  month     = {8},
  note      = {Survey Track},
}

@article{zhao_insights_2024,
	title = {Insights into Cellular Evolution: Temporal Deep Learning Models and Analysis for Cell Image Classification},
	shorttitle = {Insights into Cellular Evolution},
	abstract = {I.
          
            A
            bstract
          
          Understanding the temporal evolution of cells poses a significant challenge in developmental biology. This study embarks on a comparative analysis of various machine-learning techniques to classify sequences of cell colony images, thereby aiming to capture dynamic transitions of cellular states. Utilizing transfer learning with advanced classification networks, we achieved high accuracy in single-timestamp image categorization. We introduce temporal models—{LSTM}, R-Transformer, and {ViViT}—to explore the effectiveness of integrating temporal features in classification, comparing their performance against non-temporal models. This research benchmarks various machine learning approaches in understanding cellular dynamics, setting a foundation for future studies to enhance our understanding of cellular developments with computational methods, contributing significantly to biological research advancements.},
	author = {Zhao, Xinran and De Perez, Alexander Ruys and Dimitrova, Elena S. and Kemp, Melissa and Anderson, Paul E.},
	urldate = {2025-01-24},
	date = {2024-03-12},
	langid = {english},
    journal={bioRxiv},
}

