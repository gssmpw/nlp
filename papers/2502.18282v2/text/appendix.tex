\newpage
\appendix
\renewcommand{\arraystretch}{1}






\section{Implementation Details}
\label{app:implementation}
We downloaded the OLMo-SFT, OLMo-Instruct, LLama3-7b models, BLOOMZ and T0 from HuggingFace Hub \cite{wolf2020huggingfacestransformersstateoftheartnatural} and ran the downloaded LLMs on an A100 GPU. We accessed the other models through the DeepInfra API.  We use default generation parameters from the `transformers' library, except for temperature. We set temperature to 1 to when probing LLMs views on SCOPE cases. When using LLama3-70 to detect the stance score of training documents, we set temperature to 0 to reduce variation to a minimum . We collected all GPT responses in November 2024.


\begin{figure*}[h]
\centering
\resizebox{\linewidth}{!}{
\includegraphics[width=\linewidth]{fig/llm_prompt.png}
}
\caption{LLM prompt}
\label{fig:llm_prompt}
\end{figure*}


\section{LLM Response Collection}
\label{app:prompts}

\autoref{fig:llm_prompt} demonstrates how we prompt the LLMs for responses. 
Prior research has shown that LLMs are sensitive to the prompt format and the sequence of answer options \cite{webson-pavlick-2022-prompt}, and they may display inconsistencies in their responses \cite{elazar-etal-2021-measuring}. To mitigate these issues, we implemented three variations of prompts, following \citet{NEURIPS2023_a2cf225b}. We also randomize the order of the answer choices within each format, producing six unique prompt forms.
\autoref{fig:prompts} demonstrates the prompts we used to query the LLMs' political preference.


\begin{figure*}[htbp]
\centering

\caption{Prompts Used to Query Political Preference}

% \begin{subfigure}[b]{0.45\textwidth}
%     \centering\includegraphics[width=0.99\textwidth]{fig/prompt_human.pdf}
%     \caption{Human}
%     \label{fig:prompt_human}   
% \end{subfigure}

\begin{subfigure}[b]{0.5\textwidth}
    \centering\includegraphics[width=\textwidth]{fig/prompt_ab.pdf}
    \caption{Question Template: AB}
    \label{fig:prompt_a}   
\end{subfigure}


  \begin{subfigure}[b]{0.5\textwidth} 
    \centering\includegraphics[width=\textwidth]{fig/prompt_repeat.pdf}
     \caption{Question Template: Repeat} \label{fig:prompt_b}    
  \end{subfigure}
  
 \begin{subfigure}[b]{0.5\textwidth}
\centering\includegraphics[width=\textwidth]{fig/prompt_compare.pdf}
  \caption{Question Template: Compare} \label{fig:prompt_c}
  \end{subfigure}

  
  \label{fig:prompts}
  \end{figure*}



\paragraph{Mapping LLM Response to Preferences}
To map LLM generated sequences of tokens to actions (i.e., opinion preference), we use an iterative, rule-based matching pipeline in the following order:\\ 1. Check for exact matches (i.e., check for exact overlaps with the desired answer, such as "A" or "Yes")\\ 2. Check for normalized matches (e.g. "A)" or "YES"). For the few unmatched sequences, we manually coded the actions.


% \ye{do we have results on how much variance we get between the different prompts/variations? this would be interesting to report}\sx{TO ADD in app.}


% \begin{figure}[htbp]
% \centering

% \caption{Prompts Used to Query Political Preference}


% % \begin{subfigure}[b]{0.45\textwidth}
% %     \centering\includegraphics[width=0.99\textwidth]{fig/prompt_human.pdf}
% %     \caption{Human}
% %     \label{fig:prompt_human}   
% % \end{subfigure}

% \begin{subfigure}[b]{0.5\textwidth}
%     \centering\includegraphics[width=\textwidth]{fig/prompt_ab.pdf}
%     \caption{Question Template: AB}
%     \label{fig:prompt_a}   
% \end{subfigure}


%   \begin{subfigure}[b]{0.5\textwidth} 
%     \centering\includegraphics[width=\textwidth]{fig/prompt_repeat.pdf}
%      \caption{Question Template: Repeat} \label{fig:prompt_b}    
%   \end{subfigure}
  
%  \begin{subfigure}[b]{0.5\textwidth}
% \centering\includegraphics[width=\textwidth]{fig/prompt_compare.pdf}
%   \caption{Question Template: Compare} \label{fig:prompt_c}
%   \end{subfigure}

  
%   \label{fig:prompts}
%   \end{figure}


  





% \paragraph{No significant difference found in instance-level alignments}
% As shown in formular X, the instance-level Evaluation of a LLM m’s alignment, commonly takes the form of calculating A\_ins(M, G1) , which is the the average alignments /(1- distance) between m and human group G1,  and contrasting it with that of another group G2,  A\_ins(M, G2). However, the average alignment A\_ins(M, G1) >  A\_ins(M, G2) , does not necessarily mean that the difference between the two distances is significant. Here we introduce a statistical test to be performed in this case.
% Given a LLM m, we calculate its instance-level alignment A\_ins(m, G) with  different groups g isin G separately. Our research question here is: Is there a significant difference between the A\_ins(m, G) in terms of the mean?
% The null and alternative hypotheses thus result in:





%     \item The threshold can be can be either chosen in advance (0.05, 0.01), or by large-sample approximations, or by data-resampling (bootstrap) techniques
% \end{itemize}

% \input{latex/table/llm_human.tex}


\newpage
\begin{table*}[]

\input{table/keywords.tex}
\caption{The distribution of choices  among the respondents, together with the Keywords used to retrieve relevant documents from the pretraining data}

% }
\label{tab:keywords}
\end{table*}


% \section{Distance-Based Alignment}
% \label{app:ins-level}
% \input{latex/text/instance-level.tex}





\section{Keyword List} 
\label{app:keywords}
We define the keywords for each case as [keyword 1, keyword 2, plaintiff, defendant], with the two keywords derived from Jesse's original dataset. We manually adjusted some keywords as necessary to refine the search scope. Including the names of the parties enhances the precision of document retrieval, because in the U.S., cases are typically cited using the names of the parties involved in the format ``plaintiff v. defendant". When acronyms or abbreviations are commonly used, we manually edit the party names for better retrieval result; for example, we use NCAA instead of the full name ``National Collegiate Athletic Association". The complete list of keywords of all cases are available in \autoref{tab:keywords}. An example of a retrieved document is provided in \autoref{app:example_doc_text}.

\section{Relevant Documents Retrieval} We used the WIMBD API \cite{elazar2024whats} to retrieve documents based on defined keywords. Due to the API and token limitations of LLama3, we retrieved only documents with word counts below this threshold. \autoref{fig:doc_len_distribution} displays the distribution of document lengths, showing that most contain fewer than 4,000 words. 
% \autoref{fig:fetched_doc} illustrates . 
\autoref{tab:stance_stats} provides additional statistics such as the number of documents matching the keywords in the Dolma dataset (\textit{documents matched}) and the subset we fetched (those with fewer than 4,000 words, \textit{documents fetched})

\begin{figure*}[]
\centering
\includegraphics[width=0.75\linewidth]{fig/prompt_stance.pdf}
\caption{Prompt used to evaluate the stance scores of the retrieved documents.}
\label{fig:prompt_stance}
\end{figure*}

\section{Quality Assessment of Stance Detection}
\label{app:stance_quality}
To evaluate the quality of LLaMA3-70B’s stance detection, we conducted a two-round quality assessment.
In the first round, we randomly sampled 20 documents from the retrieved relevant documents. Two annotators independently labeled the documents: Annotator 1, a research assistant who is a native English speaker and a U.S. citizen, and Annotator 2, the first author of this paper. The annotation process followed the exact template used to prompt LLaMA3-70B, as shown in \autoref{fig:prompt_stance}. The inter-annotator agreement, measured by Spearman’s $\rho$, was 0.76. The Spearman’s $\rho$ between Annotator 1 and LLaMA3-70B’s labels was 0.7.
In the second round, Annotator 1 labeled an additional 40 documents. The overall Spearman’s $\rho$ between Annotator 1 and LLaMA3-70B’s labels across all 60 documents was 0.68. Based on this, we consider the alignment between LLaMA3-70B’s outputs and human annotations to be strong.

\begin{figure*}[]
\centering
\includegraphics[width=0.9\linewidth]{fig/ci.png}
\caption{Bootstrapped sample means and their 95\% confidence intervals for each docket. Each bar represents the average stance score for a given case docket, while the error bars denote the 5th and 95th percentiles of the bootstrap distribution (based on repeatedly sampling 80\% of the data).
}
\label{fig:ci}
\end{figure*}


\paragraph{Bootstrap Resampling} 
We applied a bootstrap resampling procedure to assess the robustness of political stance score estimation. For each of the 32 cases in SCOPE, we generated 100 bootstrap samples by randomly subsampling 80\% of its retrieved documents' stance scores. The mean score was computed for each subsample, creating a bootstrap distribution of means. We derived 95\% confidence intervals (CIs) using the percentile method, with bounds defined by this distribution's 5th and 95th percentiles. The sample mean (calculated on the full dataset) and its CI bounds were recorded for all dockets. As shown in \autoref{fig:ci} , all sample means lie within their respective CIs, confirming the reliability of our estimates and quantifying their variability.

% \end{landscape}



\begin{table*}[h]
\rotatebox{90}{
    \centering
    \input{table/stance_stats.tex}
    }
    \caption{Descriptive statistics of the documents retrieved from the Dolma dataset.}
    \label{tab:stance_stats}

\end{table*}






\begin{figure*}[]
\centering
\includegraphics[width=0.8\linewidth]{fig/doc_len_distribution.pdf}
\caption{Distribution of length of all the matched documents.}
\label{fig:doc_len_distribution}
\end{figure*}


\begin{figure*}[]
\centering
\includegraphics[width=\linewidth]{fig/corpora_heatmap.png}
\caption{Pearson Alignment. Cell $(i, j)$ represents the Pearson correlation $\rho$ of LLM $i$ to entity $j$. $*$ shows *p* value < 0.05, $**$ shows p-value < 0.001. }
\label{fig:corpora_heatmap}
\end{figure*}

\section{Corpora-Human Alignment}
\label{app:corpora_human}
\autoref{fig:corpora_heatmap} presents the alignments between different training corpora and surveyed human opinions. The political leanings of these pretraining corpora appear to be quite similar; however, they differ from those of the human respondents surveyed. Further, among the 5 corpora, DOLMa, RedPajama and OSCAR high correlation to each other. They are less correlated to C4 and the Pile, which might be due to the different curation process of the dataset.


\section{Post-training}
\label{app:post-training}

Previous research report that LLMs that have undergone human-alignment procedures tend to have stronger political views\cite{santurkar2023whose,perez-etal-2023-discovering}. Therefore, we also investigated the correlation between OLMO’s political leanings and the stance scores from the instruction-tuning dataset TULU , as well as the RLHF dataset UltraFeedback. However, no significant correlation was observed. This could be attributed to the small size of the documents, and only limited number of relevant documents retrieved from these datasets—only 15 out of the 32 cases had relevant documents in TULU, and just 10 cases had relevant documents in UltraFeedback. Prior research \cite{feng-etal-2023-pretraining} also suggests that the shift introduced by post-training is relatively small. We also explored the correlation between LLMs' political leanings and that in their post-training data, but did not observe any significant correlation. 

The key difference between OLMo-SFT (Supervised Fine-Tuning) and OLMo-Instruct lies in their fine-tuning objectives and intended uses.
OLMo-SFT is fine-tuned for general language tasks using labeled data, using the TULU dataset \cite{ivison2023camels}. It is optimized for structured responses but isn’t specifically trained to follow user instructions. OLMo-instruct is further fine-tuned to follow human instructions, using the Ultrafeedback dataset \cite{cui2023ultrafeedback}. It is optimized for handling detailed user instructions and conversational prompts, ideal for interactive and task-oriented use.


\section{Williams Test Results}
\label{app:williams}
\autoref{fig:williams_app} includes a comprehensive overview of the Williams Test results of all LLMs.


\begin{figure*}[]
\centering
\includegraphics[width=0.9\linewidth]{fig/williams9.png}
\caption{Bootstrapped sample means and their 95\% confidence intervals for each docket. Each bar represents the average stance score for a given case docket, while the error bars denote the 5th and 95th percentiles of the bootstrap distribution (based on repeatedly sampling 80\% of the data).
}
\label{fig:williams_app}
\end{figure*}

\section{Example of a Retrieved Document}
\label{app:example_doc_text}
\autoref{fig:doc_len_distribution} demonstrates the full text of a relevant document we retrieved from the pretraining dataset Dolma. The document is on case \textit{McDonald v. Chicago} about the topic of gun control:\\

\onecolumn

\begin{tcolorbox}[width=\linewidth,title={Example of a Retrieved Document}]
\footnotesize
   % \begin{itemize}
   %     \item We also evaluated instance-level alignment of LLMs with different groups by using distance-based metrics such as Jensen–Shannon divergence (cite) and Wasserstein distance (cite). Though at the first glace, the result seems to confirm the prior studies: LLMs display a mid-liberal leanings.
   %     \item However, extra significance test shows generally there are no significant difference in the means of LLMs' alignment with different groups.
   %     \item Further randomized simulation test also show that the mid-liberal leaning can be attributed to chance because of the difference of different groups' opinion distribution.
   % \end{itemize}

   In the run-up to the 2008 presidential election, many gun owners worried about the consequences of victory for Democrat candidate Barack Obama. Given Obama’s record as an Illinois state senator, where he stated his support for an all-out ban on handguns, among other gun control stances, pro-gun advocates were concerned that gun rights might suffer under an Obama presidential administration.\\
After Obama’s election, gun sales reached a record pace as gun owners snatched up guns, particularly those that had been branded assault weapons under the defunct 1994 assault weapons ban, out of an apparent fear that Obama would crack down on gun ownership. The Obama presidency, however, had limited impact gun rights.\\
When Obama was running for the Illinois state senate in 1996, the Independent Voters of Illinois, a Chicago-based non-profit, issued a questionnaire asking if candidates supported legislation to ``ban the manufacture, sale, and possession of handguns,” to ''ban assault weapons” and to instate “mandatory waiting periods and background checks” for gun purchases. Obama answered yes on all three accounts.\\
Obama also cosponsored legislation to limit handgun purchases to one per month. He also voted against letting people violate local weapons bans in cases of self-defense and stated his support for the District of Columbia’s handgun ban that was overturned by the U.S. Supreme Court in 2008. He also called it a “scandal” that President George W. Bush did not authorize a renewal of the Assault Weapons Ban.\\
Just weeks after Obama’s inauguration in January 2009, attorney general Eric Holder announced at a press conference that the Obama administration would be seeking a renewal of the expired ban on assault weapons.\\
``As President Obama indicated during the campaign, there are just a few gun-related changes that we would like to make, and among them would be to reinstitute the ban on the sale of assault weapons,” Holder said.\\
U.S. Rep. Carolyn McCarthy, D-New York, introduced legislation to renew the ban. However, the legislation did not receive an endorsement from Obama.\\
In the aftermath of a mass shooting in Tucson, Ariz., that wounded U.S. Rep. Gabrielle Giffords, Obama renewed his push for “common sense” measures to tighten gun regulations and close the so-called gun show loophole.\\
While not specifically calling for new gun control measures, Obama recommended strengthening the National Instant Background Check system in place for gun purchases and rewarding states supplying the best data that would keep guns out of the hands of those the system is meant to weed out. Later, Obama directed the Department of Justice to begin talks about gun control, involving ``all stakeholders” in the issue. The National Rifle Association declined an invitation to join the talks, with LaPierre saying there is little use in sitting down with people who have ``dedicated their lives” to reducing gun rights. As the summer of 2011 ended, however, those talks had not led to recommendations by the Obama administration for new or tougher gun laws.\\
One of the Obama administration’s few actions on the subject of guns has been to strengthen a 1975 law that requires gun dealers to report the sale of multiple handguns to the same buyer. The heightened regulation, which took effect in August 2011, requires gun dealers in the border states of California, Arizona, New Mexico and Texas to report the sale of multiple assault-style rifles, such as AK-47s and AR-15s.\\
The story through much of his first term in office was a neutral one. Congress did not take up serious consideration of new gun control laws, nor did Obama ask them to. When Republicans regained control of the House of Representatives in the 2010 midterm, chances of far-reaching gun control laws being enacted were essentially squashed. Instead, Obama urged local, state, and federal authorities to stringently enforce existing gun control laws. In fact, the only two major gun-related laws enacted during the Obama administration’s first term actually expand the rights of gun owners.\\
The first of these laws, which took effect in February 2012, allows people to openly carry legally owned guns in national parks. The law replaced a Ronald Reagan era policy that required guns to remain locked in glove compartments or trunks of private vehicles that enter national parks. The other law allows Amtrak passengers to carry guns in checked baggage; a reversal of a measure put in place by President George W. Bush in response to the terrorist attacks of Sept. 11, 2001.''
Obama’s two nominations to the U.S. Supreme Court, Sonia Sotomayor, and Elena Kagan were considered likely to rule against gun owners on issues involving the Second Amendment. However, the appointees did not shift the balance of power on the court. The new justices replaced David H. Souter and John Paul Stevens, two justices who had consistently voted against an expansion of gun rights, including the monumental Heller decision in 2008 and McDonald decision in 2010.\\
Earlier in his first term, Obama had expressed his express support for the Second Amendment. ``If you’ve got a rifle, you’ve got a shotgun, you’ve got a gun in your house, I’m not taking it away. Alright?” he said. However, the legislation to overhaul gun control failed on April 17, 2013, when the Republican-controlled Senate rejected a measure banning assault-style weapons and expanding gun-buyer background checks. \\
In January 2016, President Obama began his final year in office by going around the gridlocked Congress by issuing a set of executive orders intended to reduce gun violence. According to a White House Fact Sheet, the measures aimed to improve background checks on gun buyers, increase community safety, provide additional federal funding for mental health treatment, and advance the development of ``smart gun” technology. \\
During his eight years in office, President Barack Obama had to deal with more mass shootings than any of his predecessors, speaking to the nation on the subject of gun violence at least 14 times. In each address, Obama offered sympathy for the loved ones of the deceased victims and repeated his frustration with the Republican-controlled Congress to pass stronger gun control legislation. After each address, gun sales soared.\\
In the end, however, Obama made little progress in advancing his ``common-sense gun laws” at the federal government level — a fact he would later call one of the biggest regrets of his time as president.\\
In 2015, Obama told the BBC that his inability to pass gun laws had been``the one area where I feel that I've been most frustrated and most stymied.
\label{fig:example_doc_text}
\end{tcolorbox}


