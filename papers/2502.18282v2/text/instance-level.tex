% \subsection{Instance-level Alignment}



\input{table/jsd.tex}
\label{app:instance_level}


\input{table/ins_sig.tex}
% \input{table/random_test.tex}

\paragraph{Alignment Metrics}
Many previous work employ distance-based metrics \cite{santurkar2023whose} such as Jensen--Shannon divergence (JSD), Wasserstein distance (WD); see e.g. \cite{manning1999foundations}), which define the (mis)alignment as the distance between the opinion distributions of two groups on each individual instance. The aggregated score is then used to evaluate the alignment of two groups’ opinion distributions on the questions of a certain collection. Given a LLM $D_{1}$ and a human group $D_{2}$, following \cite{santurkar2023whose}, we define the instance alignment as:
\begin{equation}\label{egAINS}
A_\mathrm{dis}\left(D_1, D_2\right)= 1- \frac{1}{|Q|} \sum_{q \in Q}\delta\left(G_1, G_2;q\right)\, ,
\end{equation}
where
\begin{equation}
  \delta\left(D_1, D_2;q\right) = \operatorname{JSD}\left(D_1(q), D_2(q)\right)\, ,
\end{equation}
is the Jensen--Shannon divergence (i.e. the symmetrised Kullback–Leibler divergence).




\paragraph{Better aligned significantly or by chance?}

The upper part of \autoref{tab:jsd} (grey background) displays the Human-LLM alignment in the SCOPE dataset. The results show that LLMs are more aligned with the general survey respondents and the self-identified democratic respondents, which confirms the midliberal leaning in previous research. 


However, observing the inequality in the average distance $A_\mathrm{dis}(M, D_1)>A_\mathrm{dis}(M, D_2)$, does not necessarily mean that the difference between the two distances is significant, as it could be due to chance.
% However, we notice that significance tests are generally not used when comparing the LLM-opinion alignment.  Thus it is possible that the greater similarity to a certain demographic group (such libertarian) over another group (such as conservative) is attributable to chance rather than a systematic improvement. 
\paragraph{Significance Test with ANOVA}
One method for hypothesis testing the significance of differences between the means of multiple entities is the ANOVA (Analysis of Variance) test. We choose to use repeated measures ANOVA in this work because the preference distributions of varaious entities are derived from the same data set, which means that they are statistically \textit{dependent}. First, we conduct repeated measures ANOVA to test if there is a significance of differences between the means of multiple entities. Should there be a significant difference between entities ( ANOVA p-value < 0.05), we perform a post hoc pairwise one-tailed T-test to test which pairs of $A_\mathrm{dis}$ have means that are significantly different from each other. 
% Our simulation shows that without significance test, it is possible that the greater similarity to a certain demographic group (such liberal) over another group (such as conservative) are attributable to chance rather than a systematic significantly better alignment: First, we generate a randomized preference distribution \footnote{populate it with random samples from a uniform distribution over $[0, 1)$}, denoted as $D_r$, to simulate a 'pseudo LLM.' Next, we evaluate the instance-level alignment of $D_r$ with various human groups using the (JSD) metric. We then identify the human group to which the pseudo LLM is most aligned. This process is repeated across 10,000 random trials, each using a different random seed. Finally, we count the number of times each human group is identified as the most aligned with the pseudo LLM. The results in \autoref{tab:simulation} show that around $70\%$ of the time the randomized preference distribution is most aligned with the overall human respondents and $20\%$ with the democrats. We have also tried bootstrapping test and found similar results. 
% See Appendix for the details. \qv{This is appendix, maybe de}



% Given a LLM m, we calculate its instance-level alignment A\_ins(m, G) with  different groups g \isin G separately. In order to determine whether there is a significant difference between the A\_ins(m, G) in terms of the mean, a statistics test is needed:


% \begin{itemize}
%     \item Null hypothesis H\_0: there are no significant differences between the alignments of M and different human groups.
%     \item Alternative hypothesis H\_1: there is a significant difference between the alignments of M and different human groups.
% \end{itemize}


% if p < threshold, corr(Y1, X) shows how a certain LLM Y1 is correlated with a certain human group (X) (T2)
% But, a corr(Y1, X) > corr(Y2, X) can’t prove Y1 is more strongly related to Y2.
% As Y1, Y2 are dependent, measured on the same set of questions. So we use Repeated Measures ANOVA The ANOVA (Analysis of Variance) test is used to determine whether there are statistically significant differences between the means of three or more groups. 
% To control for Type I errors (false positives), Once the ANOVA shows a significant effect, we perform multiple pairwise post hoc comparisons by running  one-tail Paired t-tests with Bonferroni Correction. 

% \paragraph{Significance Test Results}
Table \ref{tab:instance_sig} shows the p-values of the ANOVA test. In general, most LLMs show no significant differences in alignment with different entities, except LLaMA 3-70B, LLaMA 3-B, and Gemma. A paired t-test conducted on these three models revealed significant differences in only two specific cases: (1) the alignment of Gemma with DOLMA compared to its alignment with the Court and (2) the alignment of Gemma with OSCAR compared to the Court. These findings suggest that, in general, LLMs do not show substantial variation alignment between different entities when evaluated in a distance-based measure. 






% \subsection{System-level Alignment}