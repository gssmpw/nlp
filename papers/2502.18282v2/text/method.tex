We employ a three-stage process to examine LLMs' political leanings and further compare their alignment with surveyed human opinions and their pretraining corpora, when available. First, we introduce how we assess the political leanings of different entities\footnote{We use \textit{entity} to refer to either a group of surveyed respondents, Supreme Court justices, LLM-generated responses, or content within the training data.}. Next, we measure the political leanings alignment among them in \autoref{sec:stage2}. Finally, we conduct significance tests to determine whether the observed differences in LLM alignment with different entities are statistically significant in \autoref{sec:stage3}.


\paragraph{Preference Distributions} In our study, we assess the political leanings of various entities by analyzing their preference distributions on SCOPE. We define preference distributions on a survey as follows: consider a survey consisting of a series of questions denoted as $\mathcal{Q}=\left\{q_i\right\}_{i=1}^m$
, where each question $q_i$ offers $n$ possible choices $\left\{a_j\right\}_{j=1}^n$. For our binary questionnaire $n=2$, and the generalization to more choices are straight-forward.
% $c \in \{\mathrm{\textit{pro}},\mathrm{\textit{opo}}\}$\qv{discuss}.
% We denote the set of all entities (such as LLMs, humans, training corpora \ye{"entities" or whatever other term we use for it, was already introduced earlier, so you don't need to specify again what's considered as part of such group, and you definitelly don't need to specify all of them if you use "such as", as it implies you only provide a subset}) responding to questions by $G$ \ye{what is G? it wasn't defined}. 
For an entity $k$, we define its political preference distribution $D_k\in\mathbb{R}^{m\times n}$  as:
$$
D_k^{ij} =p_k(a_i|q_j)\in [0,1],
$$

% \ye{if $D_k=p_k$ and $p_k$ is a probability, $D$ is also a probability, and it cannot be a distribution, and it certainly can't have a dimension of $R^{m \times n}$}

% We evaluate political leaning of various entities by calculating their preference distributions on SCOPE. Specifically, we define preference distributions as follows:
% consider a survey with a set of binary-choice questions  $\mathcal{Q}=\left\{q_i\right\}_{i=1}^n$, where a question $q_i$ has a set of possible choices a $\mathcal{C}=\left\{c_j\right\}_{j=1}^m$ \ye{i should be part of the choice marking, to associate the choice with a particular question}.  Given a group of respondents $g \in G$, we define its political preference $G$ as  
% $$
% G_{k} = p_k(c|q),   G_{k} \in \mathbb{R}^{m \cdot n}
% $$
% \qv{maybe
% $$
% G=(G_{i,j})\in\mathbb{R}^{m\times n}\quad\textnormal{with}\quad G_{i,j}=p_g(c_j|q_i)\in [0,1]
% $$
% or: for $k\in G$ (or $g_k\in G$), define $G_k$ its political preference distirbution as
% $$
% G_k\in\mathbb{R}^{m\times n}\quad\textnormal{with}\quad G(c,q)=p_g(c|q)\in [0,1]
% $$
% or you write $G=\{g_k\}_{k}$ and hence write $p_k\equiv p_{g_k}$, this should be more clear.
% }
% \ye{is G the group of respondents or their preference?}\sx{the distribution of their perference}\qv{Give here what $G$ is, i.e., we will consider $G=\{G_o,G_{\mathrm{dem}},G_{\mathrm{rep}}\}$. Also, discuss next week}
where $D_k^{ij}$ denotes the element in the $i^\text{th}$ row and $j^\text{th}$ column of $D_k$ and  $p_k(a_i|q_j)$  is the probability that entity $k$ selects the choice $a_i$ on  question $q_j$. For example, if $k$ stands for the group of self-identified democrats, then $p_k(a|q)$ is the percentage of the individuals in that group which select choice $a$ for question $q$.
% We also define $G_{k}(q)$ and $G_{k}(a)$ to denote the associated marginal opinion distributions respectively\qv{Maybe here some reference or definition? I have no clue what you mean here}\ye{agreed}. 
In our case, \textsc{SCOPE} has 32 questions with binary choice of $\{\mathrm{\textit{pro}},\mathrm{\textit{opo}}\}$, therefore $D_{k} \in \mathbb{R}^{32 \times 2}$.


% To answer our central question \ye{i don't this it's really clear by this point what is our central question. is it the leaning of llms? the alignment to the training data? this point should be made in a much clearer way}: Whose political views do LLMs mostly align with on Supreme Court Issues,
% % we prompted the LLMs's political preference on the Jesse's dataset, and subsequently to
% we measure the alignment of political preference distributions among LLMs, pretraining corpora, the US public and the Court \ye{you talk here about models, but you haven't introduced them yet. perhaps it's worth having a setup section which includes the data and models. also, i see that later you have subsections about llms and data. perhaps merge them together with the survey data, and make it its own section.}. Specifically, we define preference distributions as follows:
% consider a survey with a set of questions  $\mathcal{Q}=\left\{q_i\right\}_{i=1}^n$, where a question $1_i$ \ye{$q_i$?} has a set of possible choices a $\mathcal{C}=\left\{c_j\right\}_{j=1}^m$ \ye{i should be part of the choice marking, to associate the choice with a particular question}.  Given a group of respondents $g \in G$, we define its political preference $G$ as  
% $$
% G_{k} = p_k(c|q),   G_{k} \in \mathbb{R}^{m \cdot n}
% $$
% \qv{maybe
% $$
% G=(G_{i,j})\in\mathbb{R}^{m\times n}\quad\textnormal{with}\quad G_{i,j}=p_g(c_j|q_i)\in [0,1]
% $$
% or: for $k\in G$ (or $g_k\in G$), define $G_k$ its political preference distirbution as
% $$
% G_k\in\mathbb{R}^{m\times n}\quad\textnormal{with}\quad G(c,q)=p_g(c|q)\in [0,1]
% $$
% or you write $G=\{g_k\}_{k}$ and hence write $p_k\equiv p_{g_k}$, this should be more clear.
% }
% \ye{is G the group of respondents or their preference?}\qv{Give here what $G$ is, i.e., we will consider $G=\{G_o,G_{\mathrm{dem}},G_{\mathrm{rep}}\}$. Also, discuss next week}
% where $p_k(c|q)$  is the probability of the individuals in group k select the choice $c$ on  question $q$ \ye{don't you want to indicate the political leaning of choice c? like c=democrats?}; We also  define $G_{k}(q)$ and $G_{k}(c)$ to denote the associated marginal opinion distributions respectively\qv{Maybe here some reference or definition? I have no clue what you mean here}. In our case, Jesse 2022 has 32 questions with binary choice - supporting/against court decision, therefore  $G_{k} \in \mathbb{R}^{2 \cdot 32}$\qv{Comment here on the role of $k$, also, $\times$ is more standard than $\cdot$ imo}.
% In the rest of the section, we present the framework of how we extract the preference distributions of different groups.


\subsection{Extracting the Preference Distributions} \label{sec:stage1}
In this section, we outline the methodology used to extract the preference distribution of various entities. We divide the entities to three categories - the humans $D_H$,  the LLMs $D_M$, and the pretraining corpora $D_C$.


\subsubsection{The Humans} 
Under the category of \textit{the humans}, we consider the preference distribution of four entities: $D_{H}=\{D_{\mathrm{pub}},D_{\mathrm{dem}},D_{\mathrm{rep}},D_{\mathrm{court}} \}$. Here, $D_\mathrm{pub}$ represents the preference distribution of the overall surveyed respondents, while \( D_{\mathrm{dem}} \) and \( D_{\mathrm{rep}} \) correspond to surveyed self-identified Democrat and Republican respondents, respectively; $D_\mathrm{court}$ represents the preference distribution of the Court. All preference distributions are Bernoulli, with the respective parameter estimated from the data. For the $D_\mathrm{court}$, we fetch the judges' votes from the Supreme Court Database \cite{spaeth2024supreme}\footnote{http://scdb.wustl.edu/} 
% \ye{what is this dataset? it wasn't mentioned before. also, not that the citation's bib title is 2013, but it appears as a 2024 paper}
, and then calculate $D_\mathrm{court}$ as the ratio of justices who agree (\textit{pro}) / dissent (\textit{opo}) with the majority decision. For $D_{pub},D_\mathrm{dem}$ and $D_\mathrm{rep}$ we calculate them as the ratios of \{\textit{pro}\} versus \{\textit{opo}\} to the court's decisions among the respondents based on data retrieved from \textsc{SCOPE}. 
% Table X (++TODO++) in App X also contains detailed statistics on the human votes. 

% We consider the enti
% We obtain the preference distribution of \textbf{the public} as the ratio of supporting/against the court's decision across all surveyed respondents from \textsc{SCOPE}. 
% Regarding to the preference distribution of \textbf{the Court}, we fetched the Court's decisions from the SCDB dataset\cite{spaeth2013supreme}. 
% The U.S. Supreme Court consists of nine justices. After hearing arguments, they cast vote , and a majority (at least 5 votes) decides the case outcome. We use the ratio of the justices agreeing/dissenting the majority decisions as their preference distribution $G_{jus}$. Table X (++TODO++) in App X also contains the detailed statistics of the court's preference distribution.

\begin{figure*}[h]
\centering
\resizebox{\linewidth}{!}{
\includegraphics[width=0.9\linewidth]{fig/stance_ppl.pdf}
}

\caption{Extracting the Preference Distributions of the Pretraining Corpora.}
\label{fig:stance_score_ppl}
\end{figure*}
\vspace{-0.2cm}



\subsubsection{The LLMs}
\label{sec:llm_response_collection}
% we evaluate eight distinct LLMs, represented as $ M= \{GPT, LLama3-80, LLama3-7b, Olmo-sft, Olmo-instr, BLOOMZ, T0\}$. The set of all preference distributions of these models is denoted as $D_M = \{D_m\text{ where }m\in M\}$.
Under the category of the LLMs $D_M$, we probe the political preferences of eight LLMs as listed in \autoref{tab:model_card}. Following \citealt{NEURIPS2023_a2cf225b}, for each survey case in \textsc{SCOPE}, we created six different prompt templates, and we then sample five responses from each of the six prompt variations from the LLMs at a temperature setting of 1, yielding in a total of 30 responses per case per model.  Example prompt templates and detailed prompt creation process can be found in \autoref{fig:llm_prompt} in \autoref{app:prompts}. 

To map the LLM-generated answers to one of the given choice options, we employed an iterative, rule-based matching pipeline, as explained in \autoref{app:prompts}.
% \ye{it says sec, but should be appendix}\ye{also, this is a core part of the method, you should at least give the gist here}
The preference distribution, denoted as $D_m = p_{m}(a_j \mid q_i)$, reflects the ratio of support versus opposition to the court's decision across the 30 generated responses for model $m$ on case $q_i$, illustrated in \autoref{fig:llm_prompt} in \autoref{app:prompts}.
% \ye{i think this fig should be in the main paper}.

% To investigate the models' political preferences, we prompt LLMs to elicit responses in a binary-choice format described below. 
% Each model received background information regarding the case and the central political issue, thereby mirroring the context provided in the human survey \cite{doi:10.1073/pnas.2120284119}.


\subsubsection{The Training Data}
\label{sec:pd_corpora}
\label{sec:pd_corpora}
Under the category of the pretraining corpora $D_C$,  we  investigate the preference distributions of five corpora: $\{\text{Dolma}, \text{RedPajama}, \text{OSCAR}, \text{C4}, \text{Pile}\}$. To quantitatively assess the political preferences embedded within these corpora, we employ a three-stage pipeline, illustrated in \autoref{fig:stance_score_ppl}, which consists of:
(i) \textbf{Relevant Document Retrieval}:  Extracting the set of relevant documents \(  T_i \) from the corpora for case $q_i$ (ii) \textbf{Stance Score Evaluation}: Assigning a political stance score \( s_{i}^j \) to each retrieved document  \( t_i^j \in T_i \) using a Likert scale (1–5).
(iii) \textbf{Preference Distribution Estimation}: We use the average stance scores \( S_i \) as a proxy for the preference distribution $D_c$ for choice \( a \) in question \( q_i \) as a proxy for the corpus-specific preference distribution, denoted as \( D_c(a, q) = p_c(a \mid q) \in [0,1] \). We detail each of the component below.\\
 
\paragraph{(i) Relevant Document Retrieval} For each of the 32 cases \( q_i \) in the \textsc{SCOPE} survey, we compile a set of keywords \( K_i \) to retrieve relevant documents \(  T_i \) from the pretraining corpora using the WIMDB API \cite{elazar2024whats}- a tool designed to facilitate analysis of large-scale pretraining corpora. For example, in the case \textit{Baze v. Rees}\footnote{\textit{Baze v. Rees}, 553 U.S. 35 (2008), addresses whether lethal injection for executions was constitutional or not.}, we use keywords such as [\textit{lethal injection; capital punishment; Baze; Rees}], retrieving 206 documents from the Dolma corpus. Further details on keyword selection and retrieval statistics for each case are provided in \autoref{app:keywords}. Additionally, an example of a retrieved document is included in \autoref{app:example_doc_text}.
\paragraph{(ii) Stance Score Evaluation}
We use Llama3-70B to assess the political stance \( s_{i}^j \) of each retrieved document \( t_i^j \in T_i \). The model is prompted to evaluate the document's level of support for the court's decision on a Likert scale from 1 (strongly against) to 5 (strongly supportive). If a document is unrelated to the case’s political issue, the model is instructed to return ‘Not related.’\\ 
% We define \( S_{i} \) as the average stance score of case \( q_{i} \).
\paragraph{(iii) Preference Distribution Estimation}
To quantify the political leaning of each case \( q_{i} \), we first compute the average stance score 
$S_{i} = \frac{1}{m} \sum_{j=1}^{m} s_{i}^j$
where $s_{i}^j$ denotes the stance score of a retrieved document assigned by Llama3-70B on a Likert scale ranging from 1 (strong opposition) to 5 (strong support).
To facilitate probabilistic interpretation, we transform $S_{i}$ from its original Likert scale to a probability measure $P_{i}$, which represents the likelihood that the document supports the court’s decision.\\
\textbf{Quality Assessment of Stance Detection} To evaluate the reliability of Llama3\-70B’s stance detection, we manually annotated a randomly selected sample of 80 retrieved documents. We measure the agreement between human and model labels using Spearman's rank correlation\cite{spearman1904proof}. The overall Spearman's $\rho$ is 0.68, indicating good alignment between Llama3\-70B and human annotators. \autoref{app:keywords} offers details on the quality assessment process. To evaluate the robustness of our document retrieval method, we performed a bootstrapping analysis by iteratively excluding 20\% of retrieved documents. This procedure revealed no significant shifts in measured political leanings (see \autoref{app:keywords} for methodological details). Although differences in keyword selection may affect document retrieval and thereby influence corpus-level political stance estimates, our findings demonstrate that results are resilient to changes in the retrieved documents.

% In this work, we tested five different pretraining corpora $C \in \{Dolma, RedPajama, OSCAR, C4, Pile\}$. We denoted the preference distribution of the LLMs $D_C=\{D_\mathrm{Dolma}, D_\mathrm{RedPajama}\}$. To quantatively investigate the political preference embedded in the pretraining corpora, as shown in \autoref{fig:stance_score_ppl}, we use a three-staged pipeline focusing (i) first on retrieving relevant documents $T_i = \{t_{ij}\}_{i=1}^m$ from the corpora, (m is the number of retried  relevant documents ), and (ii) then detecting the political stance $S_i$ of the retrieved documents, and finally (iii) we use the average political stance scores $S_i$ for the choice $\mathrm{a}$ on question $q_{i}$ as a proxy for the political preference of the corpora $\mathrm{c}$.\\
% \noindent{\textbf{i) Relevant Document Retrieval:}} 
% % we first retrieved documents from the Dolma pretraining dataset.
% For each of the 32 cases $q_i$ in the \textsc{SCOPE} survey, we compile a list of keywords $K_i$ to retrieve the corresponding documents $T_i $ from the pretraining corpora using the API WIMDB\cite{elazar2024whats}. For instance, in the case \textit{Baze v. Rees}, we used keywords such as [\textit{Lethal injection; capital punishment; Baze; Rees}] and retrieved $m = 206$ documents back from the Dolma corpora. (see \autoref{app:keywords} for how we defined the keywords and descriptive statistics for retrieved documents for each case. An example of a retrieved document is provided in \autoref{app:example_doc_text}.) \\
% \noindent{\textbf{ii) Stance Score Evaluation}} To explore the political leanings are embedded in the pretraining data,  we use Llama3-70B to evaluate each retrieved document’s stance score $s_{ij}$. Specifically, we prompt Llama3-70B to rate the support for the court's decision expressed in the retrieved relevant document $t_{ij}$ on a Likert scale from 1 (strongly against) to 5 (strongly supportive); If the retrieved document does not address the political issue in the case, Llama3-70B is instructed to respond with `Not related'. Then we use the average stance score of all the relevant retrieved documents $S_{i} = \frac{1}{n} \sum_{j=1}^{n} s_{ij}$ as the stance score for the case $q_i$. To ensure the quality of the LLama3-70b’s stance detection, we manually graded the stance scores of 80 retrieved documents. We calculated the Correlation Coefficient between the human and llama’s label using Cohen's $\kappa$. The overall Cohen's $\kappa$ is approximately 0.68, indicating a substantial agreement of the scoring between our human annotator and LLama3-70b. It is also possible that using different keywords will result in different documents retrieved from the corpora, and yield different estimates of the political leanings of the corpora. As shown App XX (++TODO++), however, Bootstrapping by randomly dropping 20\% of the retrieved cases does not meaningfully affect these political leaning estimates. Although not dispositive, this suggests that our results are robust to changes in documents retrieved. (++TO DO++ length limit). We provide the exact prompt used for stance scoring and the descriptive statistics of the documents retrieved in Appendix \autoref{app:stance_score}. The stance scores $S_i$ is Likert-scale based, ranging from 1 to 5, which expresses the extend to which the document supports the court's decision. We transfer $S_i$ into a probability $p_i = (S_i - 1) / 5 $, which is a proxy for how likely this document is to support the court’s decision. By doing so, we can evaluate the uncertainty of stance scores as the entropy of document's preference distribution. 






\subsection{Measuring the LLMs Alignments} \label{sec:stage2}
We use Pearson correlation
% \footnote{Additionally, we assessed distance-based alignment using Jensen–Shannon divergence. Our findings are consistent with prior research indicating a moderate liberal leaning among LLMs. However, our significance tests reveal no statistically significant differences in how closely the LLM aligns with distinct demographic groups, which could be due to several factors such as error in the estimation of the empirical distribution. Additional details on our distance-based alignment evaluations can be found in \autoref{app:ins-level}.}
% Further randomized simulation experiments suggest that the observed "mid-liberal" leanings may be attributed to the variations in the opinion distributions of different groups. Additional details on our distance-based alignment evaluations can be found in \autoref{app:ins-level}.} 
to measure the alignment over distribution pairs of different respondents/entities. We define alignment between two preference distribution $D_1$ and $D_2$ on a set of questions $\mathcal{Q}$ as:

$$
\rho\left(D_1, D_2\right) = \operatorname{CoRR}\left(D_{1},  D_{2}\right)\, ,
$$
% \ye{why the use of `r' if you use it to denote alignment? }
% \begin{equation}
% A_\mathrm{INS}\left(G_1, G_2\right)= 1- \frac{1}{|Q|} \sum_{q \in Q}\delta\left(G_1, G_2;q\right)
% \end{equation}
% where
% \begin{equation}
%   \delta\left(G_1, G_2;q\right) = \operatorname{JSD}\left(D_1(q), D_2(q)\right)
% \end{equation}
% $$
% \operatorname{JSD}\left(D_1(q), D_2(q)\right)
% $$
% $\mathcal{D}=\left\{x_i\right\}_{i=1}^n$
% \paragraph{The system-level alignment} metrics involve correlation and statistical analysis (pearson correlation, tau, etc cite XXX). These metrics evaluates how aligned are the opinion distributions of two groups across a collection of questions. 
% The system-level alignment is calculated as:
% \begin{equation}
% A_{\mathrm{SYS}}\left(D_1, D_2\right) = \operatorname{CoRR}\left(\left\{\left(D_{1}(c),  D_{2}(c)\right)\right\}_{i=1}^m\right)
% \end{equation}
where $\operatorname{CoRR}$ calculates the Pearson correlation coefficients when averaged across questions. The $p$-value associated to the Pearson coefficient quantifies statistical significance \cite{kowalski1972effects}.
% \qv{Can cite C. J. Kowalski, “On the Effects of Non-Normality on the Distribution of the Sample Product-Moment Correlation Coefficient” Journal of the Royal Statistical Society. Series C (Applied Statistics), Vol. 21, No. 1 (1972), pp. 1-12.}
% When evaluating the alignment $\rho(M,G1)$ of an LLM M with a respondent group $G_1$, if the p-value of the \textbf{Pearson correlation} is less than a Significance Level (e.g. alpha = 0.05), then we can conclude that there is \textbf{a statistically significant correlation} between the M and $G_1$ \ye{that's standard, you can remove/shorten this sentence.}. 

% Most previous work employ instance-level metrics (cite XXX), typically compare the LLMs’ (mis) alignment by the average distance of the  opinion distributions over all survey questions between two groups - a LLM and a certain human demographic group. However, we notice that significance tests are generally not used when comparing the llm-opinion alignment.  Thus it is possible that the greater similarity to a certain demographic group (such libertarian) over another group (such as conservative) is attributable to chance rather than a systematic improvement. 



\subsection{Testing for Significance of Stronger Alignments } \label{sec:stage3}

% However, we notice that these studies rarely use statistical significance tests when comparing LLM–human opinion alignments. Consequently, an observed stronger similarity to a particular demographic group (e.g., libertarian) over another (e.g., conservative) might be due to random chance rather than a meaningful difference.
% In this work, we use the Pearson correlation coefficient to measure alignment across different respondent groups. We further propose applying the Williams test to assess whether differences in LLM alignment with various groups are statistically significant \footnote{Additionally, we assess distance-based alignment using Jensen–Shannon divergence and Wasserstein distance. Our findings are consistent with prior research indicating a moderate liberal leaning among LLMs.  However, our significance tests reveal no statistically significant differences in how closely the LLM aligns with distinct demographic groups. Further randomized simulation experiments suggest that the observed "mid-liberal" leanings may be attributed to the variations in the opinion distributions of different groups. Additional details on our distance-based alignment evaluations can be found in \autoref{app:ins-level}.}. Furthermore, diverging from the two-stage process identified in previous studies, we propose an additional stage (3): conducting significance tests to determine whether the differences in LLM alignment with various groups are statistically significant.

Given an LLM \(D_m\) and two human groups \(D_{\mathrm{dem}}\) and \(D_{\mathrm{rep}}\), we compute the alignments \(\rho(D_m, D_{\mathrm{dem}})\) and \(\rho(D_m, D_{\mathrm{rep}})\).
% \qv{Maybe consider using numbers for LLMs and $\{o,\mathrm{dem},\mathrm{rep}\}$ for humans, to make it easier to read}. 
% To determine whether \(D_m\) is more strongly aligned with \(D_{\mathrm{dem}}\) than with \(D_{\mathrm{rep}}\), simply observing that \(\rho(D_m, D_{\mathrm{dem}}) > \rho(D_m, D_{\mathrm{rep}})\) does not suffice to conclude that \(D_m\) aligns better with \(D_{\mathrm{dem}}\) than with \(D_{\mathrm{rep}}\) , because these preference distributions are derived from the same dataset and therefore are not independent. \ye{so?}
To determine whether \(D_m\) aligns more strongly with \(D_{\mathrm{dem}}\) than \(D_{\mathrm{rep}}\), a direct comparison of \(\rho(D_m, D_{\mathrm{dem}})\) and \(\rho(D_m, D_{\mathrm{rep}})\) is insufficient. This is because both correlations are derived from the same dataset, meaning they are statistically \textit{dependent}. Consequently, standard significance tests for independent correlations fail to account for the covariance between \(\rho(D_m, D_{\mathrm{dem}})\) and \(\rho(D_m, D_{\mathrm{rep}})\), potentially overestimating or underestimating the significance of their difference. To address this, 
% a statistical significance test is needed to ascertain whether \(D_m\) is significantly better aligned with \(D_{\mathrm{dem}}\) than with \(D_{\mathrm{rep}}\). 
we use a variation of Williams test \citep{williams_regression_1959}, which evaluates the significance of differences in dependent correlations \cite{steiger1980tests}.
% \qv{This is not quite correct, I think. Originally, the Williams test is to compare means. We are using a variant by Steiger 1980}. 
This test has been widely adopted for comparing the performance of machine translation and text summarization metrics \citep{mathur-etal-2020-tangled, deutsch-etal-2021-statistical,graham-baldwin-2014-testing}.
% \qv{Here, you should cite Steiger 1980, some of the reference are not related} 
In essence, it tests whether the population correlation between \(D_1\) and \(D_3\) equals the population correlation between \(D_2\) and \(D_3\), where the test-statistic is given by:
% Given an LLM M and two respondent groups G1 and G2, and we calculate the alignments of the two pairs A(M,G1) and A(M,G2). Our question is whether the alignment between M and G1 A(M,G1) is stronger than the alignment between M and G2. However, A(M,G1) > A(M,G2) do not directly express that LLM m aligns better to G1 than to G2. That's because the preference distributions of different groups are not independent, as they are computed on the same dataset. An additional \textbf{statistical significance test} is necessary to compare whether \textbf{M is }\textit{significantly better} aligned to G1 than \textbf{to G2.} Williams test (Williams, 1959) evaluates the significance of a difference in dependent correlations (Steiger, 1980), which is frequently used to compare machine translation and text summarization metrics’ performances at the system-level (Mathur et al., 2020, Graham 2014,Deutsch 2021). It is formulated as follows as a test of whether the population correlation between D_1 and D_2 equals the population correlation between D_1 and D_3:
\begin{equation*}\label{eqSteiger}
t_{n-3}=\frac{\left(\rho_{12}-\rho_{13}\right) \sqrt{(n-1)\left(1+\rho_{12}\right)}}{\sqrt{2 K \frac{(n-1)}{(n-3)}+\frac{\left(\rho_{12}+\rho_{13}\right)^2}{4}\left(1-\rho_{23}\right)^3}},
\end{equation*}
where $\rho_{i j}$ is the correlation between $D_i$ and $D_j, n$ (i.e., $\rho_{i j}=\operatorname{CoRR}(D_i,D_j)$) is the size of the population, and $K$ can be computed as:
$$
K=1-\rho_{12}^2-\rho_{13}^2-\rho_{23}^2+2 \rho_{12} \rho_{13} \rho_{23}\, .
$$

% \ye{these formulae are very confusing. many of these variables were not defined. is it even needed to be described here? it's a common test, we could just provide a citation and explain what it tests}\qv{I think all variables are explained}



