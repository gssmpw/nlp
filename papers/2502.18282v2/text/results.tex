% This section presents a comprehensive analysis of the LLMs’ alignment with different respondent groups at both the instance level (ref Section XX) and the systematic level (ref Sec. XX). We begin by introducing the eight LLMs included in this study and describing the pretraining corpora used for each (ref Section XX). For each level of alignment, we first detail the alignment metrics and the significance tests employed. We then report the corresponding results and offer an in-depth discussion of their implications.

This section presents the results and analysis of our experiments. Our investigation on the alignment of LLMs can be formed into two key questions: 
(1) Is there a statistically significant correlation  between the preference distribution of LLM \(m\) and the entity \(E_1\)? (2) Given \(m\), \(E_1\), and \(E_2\), is the correlation between \((m, E_1)\) significantly stronger than that between \((m, E_2)\)?
To address the first question, we applied Pearson correlation to quantify the alignment between LLMs and different entities. \autoref{fig:pearson} presents a heatmap depicting the Pearson correlation coefficients (\(\rho\)-values) between LLMs, surveyed human opinions (\( D_H \)), and pretraining corpora (\( D_C \)). For the second question, we employed the Williams test to assess whether the observed differences between correlation pairs are statistically significant, as shown in \autoref{fig:williams}.
Due to space constraints, our discussion highlights the Williams test results for six selected LLMs. A full overview of all LLMs' results is provided in \autoref{fig:williams_app} in \autoref{app:williams}.
\noindent We make the following observations:
% \subsection{System-level}
% \begin{tcolorbox}[width=\linewidth,title={Takeaway 1}]





\paragraph{Takeaway 1: LLMs are primarily aligned with their pretraining data, but \textit{not} with surveyed human opinions.
}
% \end{tcolorbox}
\autoref{fig:pearson} illustrates the alignment of various LLMs with surveyed human opinions alongside their pretraining corpora, when applicable. Notably, both versions of OLMo-instruct (\(\rho = 0.63\)) and OLMo-sft (\(\rho = 0.57\)) demonstrate a significant correlation with Dolma (highly significant $p < 0.001$), which is precisely the pretraining corpus utilized for their training. Similarly, although the correlation is not as statistically significant, the T0 model exhibits the strongest correlation with its pretraining corpus, C4, compared to the other five training corpora. 

In contrast to the observed trends in monolingual LLMs, the multilingual BLOOMZ exhibits no statistically significant correlation with the aforementioned three pretraining corpora. We hypothesize that its political preference patterns may stem from exposure to non-English languages in training data, which includes different distribution of political views from the English-only corpora we evaluated. This aligns with prior research showing that multilingual models trained on diverse language data can develop unpredictable moral and political biases \cite{haemmerl-etal-2023-speaking}. 

Furthermore, all LLMs, with the exception of Bloomz and T0, display a significant positive correlation with the three training corpora: Dolma, RedPajama, and Oscar. This alignment may stem from the similar political leanings in these corpora and the models trained on them\footnote{\autoref{fig:corpora_heatmap} in \autoref{app:corpora_human} presents the alignments between different training corpora and surveyed human opinions.
% The political leanings of these pretraining corpora appear to be quite similar; however, they differ from those of the human respondents surveyed.
}. In contrast, our findings indicate that there are generally no significant alignments between the LLMs' outputs and surveyed human opinions. The only LLMs that do not follow this trend are LLama3-70b and T0, which we will discuss further in Takeaway 3.
% \autoref{sec:result_3}.







\paragraph{Takeaway 2: Significance testing confirms LLM's alignment to their pretraining data is stronger than to humans.}
% \begin{tcolorbox}[width=\linewidth,title={Takeaway 2}]
% Significance Test Confirms Stronger Alignment of LLMs with Pretraining Data Compared to Human Opinions
% \end{tcolorbox}
\autoref{fig:williams} illustrates the results of the Williams tests conducted on various pairs of alignments. As demonstrated in subfigures \autoref{fig:williams} a), b), and c),  GPT4-o, OLMo-sft, and OLMo-instruct consistently exhibit a significantly stronger alignment with the training corpora (Dolma, RedPajama, Oscar) than with human groups, \( p < 0.05 \). This finding corresponds to the orange cluster in Fig \ref{fig:pearson}, confirming that these LLMs have a stronger alignment to the pretraining data than to the surveyed human opinions.
% (++TODO++ add discussion about llama-70b, llama-8b and bloomz)
% (++TODO ++ add discussion on mid-liberal leaning)
% \ye{I don't understand why we need an entire paragraph for this content. Just add to the previous results that we run a significance test and state what results are significant.}

% \begin{tcolorbox}[width=\linewidth,title={Takeaway 3}]

\vspace{-0.3cm}
\paragraph{Takeaway 3: Correlation numbers alone are not enough.}
% \end{tcolorbox}
\label{sec:result_3}
To address the question, ``With which entity $E_k$ is model \( M \) most aligned?'', it is crucial to not only compare the strength (correlation coefficient \(\rho\)) and significance (p-value) of each correlation \((m, E)\); but also to determine whether the correlation between \((m, E_1)\) (statistically) significantly differs from that between \((m, E_2)\). As discussed in \autoref{sec:stage3}, the dependencies of these distributions imply that a higher correlation coefficient, \(\rho(m,E_1) > \rho(m,E_2)\), does not necessarily indicate that model \( M \) is more aligned with \( E_1 \) than with \( E_2 \), even for small $p$-values. Therefore, a significance test is needed to ascertain whether model \( M \) is \textit{significantly more} aligned with \( E_1 \) compared to \( E_2 \), or if the observed differences in \(\rho\) values are attributable to random variation. For example, as illustrated in \autoref{fig:pearson}, the preference distribution of LLama3-70B exhibits significant correlations (\(p < 0.05\)) with both its pretraining corpus, RedPajama (\(\rho = 0.53\)), and the \(E_{dem} \) (surveyed democratic respondents, (\(\rho = 0.48\)). However, according to the Williams test results in \autoref{fig:williams}(d), the correlation between LLaMA3-70B and RedPajama is not significantly different from its correlation with  \(E_{dem} \) the Democratic respondents, indicating that the observed difference in the correlation pearson coefficient $\rho$ could be due to statistical noise. 

% (e.g., when varying prompts).

Similarly, the Pearson correlation results in \autoref{fig:pearson} indicate that T0 exhibits a significant correlation only with \( E_{\text{pub}} \) (surveyed human opinions), while no significant correlations are observed with other entities. At first glance, this might suggest that T0 is most aligned with human opinions among \textit{all} entities.  
However, the significance test results in \autoref{fig:williams}(e) reveal inconsistencies. While correlation between \( (T0, E_{\text{pub}})  \) is significantly stronger than the correlation between \( (T0, E_{\text{court}}) \), no such significant differences are found with other entities, such as with $E_{\text{dem}}$ or any of the training corpora. This means that we can \textit{only} conclude that T0 aligns more closely with surveyed human opinions $E_{\text{pub}}$ than with the court $E_{\text{court}}$ , but we \textit{cannot} determine whether its alignment with \( E_{\text{pub}} \) is significantly stronger than its alignment with \textit{other} entities, even though there are great differences in \( \rho \)-values observed in \autoref{fig:pearson}.

% Similarly, the Pearson correlation results in \autoref{fig:williams}(e) indicate that T0 exhibits a significant correlation only with \( E_{\text{pub}} \) (surveyed human opinions), while no significant correlations are observed with other entities.
% This might suggest that T0 is most aligned with human opinions among all entities. However, the results of the significance tests in \autoref{fig:williams}(e) reveal inconsistencies. T0's correlation with \( E_{\text{pub}} \) is significantly different only when compared to its correlation with \( E_{\text{court}} \), but not with other entities. Consequently, we can conclude that T0 aligns more closely with surveyed human opinions \( E_{\text{pub}} \) than with the court \( E_{\text{court}} \). However, we cannot conclude whether T0 aligns significantly more with \( E_{\text{pub}} \) than with the other entity. 

These two examples from LLaMA3-70B and T0 underscore the limitations of evaluating LLM alignment based solely on correlation values and highlight the importance of significance testing.
% To address the question of "With which entity $E_k$ is model \( M \) most aligned?", it is essential to not only identify the strength (\(\rho\) value) and significance (p-value) of each correlation \((m, E)\) but also to compare whether the correlation between \((m, E_1)\) significantly differs from that between \((m, E_2)\). As discussed in \autoref{sec:stage3}, the dependency of these distributions implies that a higher correlation value, \(\rho(m,E_1) > \rho(m,E_2)\), does not necessarily indicate that model \( M \) is more aligned with \( E_1 \) than with \( E_2 \). Therefore, a supplementary significance test is essential to determine whether model \( M \) is \textit{significantly better} aligned with \( E_1 \) compared to \( E_2\), or if the observed differences in \(\rho\) values are due to chance.

% For example, as illustrated in \autoref{fig:pearson}, the preference distribution of LLama3-70b exhibits significant correlations (\(p < 0.05\)) with both its pretraining corpus, RedPajama (\(\rho = 0.53\)), and the Democratic respondents (\(\rho = 0.48\)). However, we cannot assert that the correlation between (LLama3-70b, RedPajama) is significantly stronger than that of (LLama3-70b, Democratic respondents). Because according to the Williams tests in Subfigure (d), LLama3-70b's correlation with RedPajama does not exhibit a significant difference when compared to its correlation with the Democratic respondents. 

% Noteworthy is, in \autoref{fig:williams}(e), T0 shows a significantly stronger correlation with C4 than with the other corpora.  This is in contrast to what we observe in \autoref{fig:pearson}, where T0 achieves the strongest correlation with group of the overall public (pub), the correlation is significant at $p$ < 0.05. However, \autoref{fig:williams} (e) reveals the difference between T0’s correlation with pub only statistically significant outperforms the republican respondents, but not outperforms the other human groups or training corpora. The contradicts is because the power of Williams test increases when the third correlation, $\rho(\mathrm{row}_i, \mathrm{col}_j)$, between metric scores is stronger (Graham, 2015)
% That’s why, counter-intuitively, in \autoref{fig:pearson},  T0 shows a much bigger difference in the r value of the correlation to pub and to court distribution ($0.49 - (-0.01) = 0.5$) than the difference of to pub and to rep ($0.49 - 0.44 = 0.05$). However, the williams test results in \autoref{fig:williams}(e) shows T0 aligns  significant stronger to pub than to rep, but T0 does not significantly correlates to pub better than the court distribution. “This underlines the dangers of assessing metrics based solely on correlation numbers, and emphasizes the importance of statistical testing”.(++paraphrase and cite Graham et Baldwin++)



% \ye{this paragraph is very confusing. i'd rewrite it from scratch}



