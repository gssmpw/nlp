

\section{Method}\label{Sec.3}

\subsection{Problem Definition}
This study focuses on detecting anatomical landmarks around teeth and surrounding structures in head 3D-CT scans. Given a 3D medical image volume \( I \in \mathbb{R}^{D \times H \times W} \), the goal is to predict the 3D coordinates of \( N \) landmarks, denoted as \( L = \{l_1, l_2, \ldots, l_N\} \), where each landmark is represented as \( l_i = (x_i, y_i, z_i) \).



We formulate the detection task as a heatmap regression problem to localize landmarks. For each landmark \( l_i \), its location in 3D space is represented by a Gaussian distribution. The corresponding heatmap is defined as:
\begin{equation}
H_i(x, y, z) = \exp\left(-\frac{(x - x_i)^2 + (y - y_i)^2 + (z - z_i)^2}{2\sigma^2}\right),
\end{equation}
where \( (x_i, y_i, z_i) \) is the ground-truth coordinate of the \( i \)-th landmark, and \( \sigma \) controls the spread of the Gaussian distribution. The final heatmap \( H \) is the summation of all individual landmark heatmaps: \( H = \sum_{i=1}^{N} H_i. \)

During inference, the predicted coordinate of each landmark \( \hat{l}_i \) is obtained by finding the peak value in the predicted heatmap:
\begin{equation}
\hat{l}_i = (\hat{x}_i, \hat{y}_i, \hat{z}_i) = \arg\max_{(x, y, z)} H(x, y, z),
\end{equation}



\begin{figure}[htbp]
\centering
\includegraphics[width=0.8\linewidth,trim={0cm 0cm 0cm 0cm},clip]{biformer.png}
\caption{(a) Architecture of the proposed Biformer Block. (b) Illustration of region-to-region routing and token-to-token attention. Our method uses sparsity by selecting key-value pairs from the top-$k$ most relevant windows, avoiding unnecessary calculations.}
\label{fig:biformer}
\end{figure}



\subsection{3D BiFormer Design}

\begin{figure}[htbp]
\centering
\includegraphics[width=\linewidth,trim={0cm 0cm 0cm 0cm},clip]{method11.png}
\caption{The overview of proposed Hybrid-3D Detection Network(H3DE-Net): Anchor-Free Architectures. BiFormer is a module based on bilevel routing attention, and DoubleConv stands for two Cascading convolution layers. Further details will be discussed later. $N$ denotes the number of landmarks.}
\label{fig:network1}
\end{figure}

The 3D BiFormer Module is the core component of H3DE-Net, designed to efficiently extract global and local features from 3D data. By extending the BiFormer module~\cite{biformer} from 2D to 3D, the module introduces a bi-level routing attention mechanism, significantly reducing computational complexity while maintaining the ability to model long-range dependencies and local details. The module's structure, shown in Figure~\ref{fig:biformer}(a), consists of the following key components:

\begin{itemize}
    \item Depthwise Convolution (DWConv): Captures local spatial features.
    \item Bi-Level Routing Attention: Dynamically models global and local dependencies, consisting of Region-to-Region Routing and Token-to-Token Attention.
    \item Layer Normalization (LN) and Multi-Layer Perceptron (MLP): Optimize feature distributions and enhance feature representations.
\end{itemize}



\subsubsection{Bi-Level Routing Attention Mechanism}

The Bi-level routing attention mechanism, illustrated in Figure~\ref{fig:biformer}(b), operates in two stages:

\paragraph{Region-to-Region Routing}

In this stage, the input feature \( F \in \mathbb{R}^{H \times W \times D \times C} \) is divided into multiple regions. For each region, coarse-grained attention is computed using the query \( Q^p \) and key \( K^p \). The coarse-grained attention is defined as:
\begin{equation}
\text{Attention}_{\text{coarse}}(Q^p, K^p) = \text{Softmax}\left( \frac{Q^p (K^p)^\top}{\sqrt{d_k}} \right),
\end{equation}
where \( Q^p, K^p\in \mathbb{R}^{(h \times w \times d) \times C} \) are extracted from \( F \), \( h, w, d \) represent the local region dimensions, and \( d_k \) is the attention head dimension.

The results of coarse-grained routing are used to select high-relevance regions via a Top-k selection mechanism \textbf{\( \text{topkIndex} \)}, producing a set of region indices, which reduces the computational burden of the subsequent steps.

\paragraph{Token-to-Token Attention}

Within the selected regions, fine-grained attention is computed to capture detailed features. The computation is defined as:
\begin{equation}
\text{Attention}_{\text{fine}}(Q^*, K^*, V^*) = \text{Concat}(\text{head}_1, \ldots, \text{head}_h) W_O,
\end{equation}
where \( Q^*, K^*, V^* \in \mathbb{R}^{k \times d_k} \) are the features of the selected tokens, \( k \) is the number of selected tokens, \( W_O \) is a linear projection matrix, and \( \text{head}_i \) represents each independent attention head.

Finally, the aggregated attention within the regions produces the output features \( O \in \mathbb{R}^{H \times W \times D \times C} \).

% \subsubsection{Mathematical Formulation and Efficiency Analysis}

% For an input feature \( F \), the bi-level routing attention mechanism models dependencies in two stages. The overall computational complexity is reduced from \( \mathcal{O}(n^2) \) to \( \mathcal{O}(n \cdot \sqrt{n}) \), where \( n = H \cdot W \cdot D \). This hierarchical mechanism ensures efficient processing of high-resolution 3D data while preserving the ability to model global and local dependencies.

% Through this dual-level modeling, the \textbf{3D BiFormer Module} efficiently processes high-dimensional 3D data, capturing both global context and local details, and serves as a critical component of 3D BiFormer-Net.

\subsection{Designed Architectures}
To accommodate different task requirements(We cover this in detail in Sec.~\ref{sec4}), we design two architectures: \textbf{Anchor-Free Architecture} and \textbf{Anchor-Based Architecture}. Both architectures follow a unified encoder-decoder framework, employ the 3D BiFormer module for multi-scale feature extraction, and integrate additional components such as the \textbf{Feature Fusion Module (FFM)}. These components further enhance the model's capability to aggregate multi-scale information and recover spatial details, which is critical for accurate landmark localization.


\subsubsection{Anchor-Free Architecture}
% TODO 替换为 Basline-> Anchor-Free  帮我再检索一下全文
As shown in Fig.~\ref{fig:network1}, the Baseline architecture directly generates a 3D heatmap \( H_{\text{out}} \in \mathbb{R}^{H \times W \times D \times L} \), where \( H, W, D \) represent the spatial dimensions of the input image, and \( L \) is the total number of landmarks. The network achieves global modeling of landmarks through progressive encoding, decoding, and feature fusion.

Given a 3D input image \( I \in \mathbb{R}^{H \times W \times D} \), an initial convolution layer first extracts embedded features:
\begin{equation}
E_0 = \text{Conv}_{3\times3}(I), \quad E_0 \in \mathbb{R}^{H \times W \times D \times C_0}.
\end{equation}

The encoder then extracts multi-scale features \( E_i \in \mathbb{R}^{\frac{H}{2^i} \times \frac{W}{2^i} \times \frac{D}{2^i} \times C_i} \) (\( i = 1, 2, \ldots, 5 \)) through successive 3D BiFormer modules:
\begin{equation}
E_i = \text{BiFormer}(E_{i-1}), \quad i = 1, 2, \ldots, 5.
\end{equation}




As the feature maps progress through the encoder, their spatial resolution decreases while the number of channels increases, facilitating the extraction of higher-level abstract features. The decoder gradually restores the spatial resolution through upsampling layers \( U_j \) (\( j = 1, 2, \ldots, 4 \)), which are combined with skip connections from the encoder to enhance the information flow:
\begin{equation}
U_j = \text{Fusion}(U_{j+1}, E_{5-j}), \quad j = 1, 2, \ldots, 4.
\end{equation}

The fusion process is implemented through the Feature Fusion Module (FFM), which concatenates the upsampled features from the previous stage with the corresponding encoded features:
\begin{equation}
U_{j} = \text{Concat}(\text{Deconv3D}(U_{j+1}), E_{5-j}).
\end{equation}

Finally, the decoder produces a heatmap \( H_{\text{out}} \) through a \( 1 \times 1 \times 1 \) convolution:
\begin{equation}
H_{\text{out}} = \text{Conv}_{1\times1\times1}(U_1), \quad H_{\text{out}} \in \mathbb{R}^{H \times W \times D \times L}.
\end{equation}

% To recover high-resolution details lost during downsampling, the Baseline architecture incorporates the \textbf{Super-Resolution Block (SRB)} in the decoder. The SRB refines the low-resolution features \( F_{\text{low}} \) by applying 3D convolution, pixel-shuffle upsampling, and another 3D convolution:
% \begin{equation}
% \begin{aligned}
% F_{\text{conv}} &= \text{Conv3D}(F_{\text{low}}), \\
% F_{\text{upsampled}} &= \text{PixelShuffle}(F_{\text{conv}}), \\
% F_{\text{refined}} &= \text{Conv3D}(F_{\text{upsampled}}).
% \end{aligned}
% \end{equation}

This architecture is characterized by its simplicity and direct modeling of global landmark distributions through heatmaps. It is well-suited for tasks where landmarks are regularly distributed and data is complete. By leveraging global modeling, the Baseline architecture effectively utilizes full-image information, avoiding local deviations that might affect predictions.

\subsubsection{Anchor-Based Architecture}
Figure~\ref{fig:anchor} illustrates the anchor design, which addresses the issue of missing landmarks in the dataset. Anchors are uniformly distributed in a grid layout across the 3D feature space, with fixed intervals and radii \( r \). Each anchor serves as a candidate for predicting landmark positions through offset regression and existence probability estimation. The offset regression is parameterized as:
\begin{equation}
t_x = \frac{g_x - f_x}{r}, \quad t_y = \frac{g_y - f_y}{r}, \quad t_z = \frac{g_z - f_z}{r},
\end{equation}
where \( (g_x, g_y, g_z) \) are the ground-truth coordinates of the landmark, \( (f_x, f_y, f_z) \) are the anchor center coordinates, and \( r \) is the anchor radius. The two subfigures in Figure~\ref{fig:anchor} demonstrate different anchor configurations. 
\begin{figure}[htbp]
\centering
\includegraphics[width=0.8\linewidth,trim={0cm 0cm 0cm 0cm},clip]{anchor.png}
\caption{(a) shows a single-scale anchor design where \( r = 0.5u \) and the number of anchors \( n_a = 1 \), while (b) shows a multi-scale anchor design where \( r = 1u \) and \( n_a = 3 \). The multi-scale design enhances the coverage of regions surrounding partially missing landmarks, making the model more robust in handling irregular landmark distributions and incomplete data.}
\label{fig:anchor}
\end{figure}


\begin{figure*}[htbp]
\centering
\begin{minipage}{\textwidth}
  \centering
  \includegraphics[width=\linewidth,trim={0cm 0cm 0cm 0cm},clip]{method22.png}
  \caption{The overview of proposed Hybrid-3D Network(H3DE-Net): Anchor-Based Architectures.}
  \label{fig: network2}
\end{minipage}
\end{figure*}


The Anchor-Based architecture introduces an anchor proposal mechanism that divides the 3D space into candidate regions and predicts the offsets and probabilities for each anchor. As shown in Figure~\ref{fig: network2}, the architecture consists of an encoder and a decoder. The encoder extracts multi-scale features from the input 3D image \( H \times W \times D \) using the 3D BiFormer module. Each encoder stage generates feature maps \( E_i \) with progressively reduced spatial dimensions:
\begin{equation}
E_i = \text{BiFormer}(E_{i-1}), \quad i = 1, 2, \ldots, 5,
\end{equation}
where \( E_i \in \mathbb{R}^{\frac{H}{2^i} \times \frac{W}{2^i} \times \frac{D}{2^i} \times C_i} \). 

The decoder reconstructs spatial resolution through upsampling layers and skip connections. The final decoder stage outputs \( U_1 \), which is used to generate two prediction branches:
1) An offset regression branch that predicts the offsets \( \Delta l \) of each anchor relative to the ground-truth landmark positions:
\begin{equation}
\Delta l = f_{\text{offset}}(U_1), \quad \Delta l \in \mathbb{R}^{\frac{H}{4} \times \frac{W}{4} \times \frac{D}{4} \times (3 \cdot L)},
\end{equation}
where \( L \) is the number of landmarks, and the factor of 3 corresponds to the x, y, and z coordinates in 3D space.
2) A probability prediction branch that estimates the existence probability \( p \) of a landmark for each anchor. The probabilities are normalized using the sigmoid activation function \( \sigma \):
\begin{equation}
p = \sigma(f_{\text{prob}}(U_1)), \quad p \in \mathbb{R}^{\frac{H}{4} \times \frac{W}{4} \times \frac{D}{4} \times L}.
\end{equation}




% The FFM and SRB used in the Anchor-Based architecture are similar to those in Architecture 1, ensuring multi-scale information aggregation and high-resolution detail recovery. However, their application is adjusted to accommodate the anchor-based outputs. For instance, the fused features \( U_j \) are refined to improve anchor-specific predictions.

By focusing on candidate regions, the Anchor-Based architecture captures landmark-specific local features more accurately, making it particularly effective for scenarios with irregularly distributed or missing landmarks. 
% The adaptive anchor proposal mechanism significantly enhances the model's robustness and generalization capability compared to the heatmap-based direct regression in Architecture 1.

% \subsubsection{\textbf{Discussion on Design Differences}}

% While the two architectures share the same backbone for feature extraction, the output layers and optimization objectives are tailored to their respective tasks:
% \begin{itemize}
%     \item In the baseline design, the output is a dense heatmap \( H \), enabling direct localization of landmarks.
%     \item In the anchor-based design, the output includes offsets \( \Delta l \) and probabilities \( p \), allowing the model to localize landmarks relative to predefined anchor regions.
% \end{itemize}

% This dual design ensures that the network is adaptable to various scenarios, including cases with missing landmarks or irregular distributions. The flexibility of the 3D BiFormer module makes it a powerful backbone for both cases.

% \subsubsection{Feature Fusion Module (FFM)}

% The \textbf{Feature Fusion Module (FFM)} is designed to aggregate multi-scale features from different stages, enabling the network to combine high-level semantic information with low-level spatial details. We take the non-anchor-based architecture as an example to illustrate the fusion process.

% Let the encoded features from stage \( l \) be \( D_l \), and the upsampled features from the previous stage be \( U_l \). The fusion at stage \( l \) is defined as:
% \begin{equation}
% U_{l+1} = \text{Fusion}(U_l, D_l) = \text{Concat}(\text{Deconv3D}(U_l), D_l),
% \end{equation}
% where \(\text{Deconv3D}\) performs 3D deconvolution to upsample the features, and \(\text{Concat}\) concatenates the upsampled features \( U_l \) with the encoded features \( D_l \).

% To balance the contributions of features from different stages, a weighted sum operation is applied to fuse the predictions at multiple resolutions:
% \begin{equation}
% H = \sum_{l=1}^L w_l \cdot H_l,
% \end{equation}
% where \( H_l \) is the heatmap predicted at stage \( l \), and \( w_l \) are learnable weights.

% In the anchor-based architecture, the FFM operates similarly but with adaptations to accommodate the dual output (offset \( \Delta l \) and existence probability \( p \)). Specifically, after fusion, the features \( U_{l+1} \) are passed to separate prediction heads for offsets and probabilities:
% \begin{equation}
% \Delta l = f_{\text{offset}}(U_{L}),
% \end{equation}
% \begin{equation}
% p = \sigma(f_{\text{prob}}(U_{L})),
% \end{equation}
% where \( f_{\text{offset}} \) and \( f_{\text{prob}} \) are network branches for offset regression and probability prediction, respectively.

% \subsubsection{Super-Resolution Block (SRB)}

% The \textbf{Super-Resolution Block (SRB)} is designed to recover high-resolution spatial details lost during downsampling, which is critical for accurate landmark localization. The SRB combines pixel-shuffle upsampling with 3D convolutional refinement.

% Given a low-resolution feature map \( F_{\text{low}} \in \mathbb{R}^{D \times H \times W \times C} \), the SRB first applies 3D convolution to enhance feature representation:
% \begin{equation}
% F_{\text{conv}} = \text{Conv3D}(F_{\text{low}}).
% \end{equation}
% The resulting feature map is then upsampled using a pixel-shuffle operation:
% \begin{equation}
% F_{\text{upsampled}} = \text{PixelShuffle}(F_{\text{conv}}),
% \end{equation}
% where pixel-shuffle rearranges feature dimensions to increase spatial resolution. Finally, the upsampled features are refined using another 3D convolution:
% \begin{equation}
% F_{\text{refined}} = \text{Conv3D}(F_{\text{upsampled}}).
% \end{equation}

% The SRB is shared between both architectures (anchor-based and non-anchor-based) and ensures that the final high-resolution features provide sufficient detail for precise heatmap regression or offset and probability prediction.

\subsection{Loss Function}

The network is optimized using a hybrid loss function tailored to the architecture. For the Anchor-free architecture, the loss is based solely on the heatmap regression, while for the Anchor-based architecture, additional anchor-related terms are included.

The heatmap regression loss, applicable to both architectures, is defined as:
\begin{equation}
\mathcal{L}_{\text{heatmap}} = \frac{1}{HWDN} \sum_{n=1}^N \sum_{h=1}^H \sum_{w=1}^W \sum_{d=1}^D (H(h, w, d, n) - G(h, w, d, n))^2,
\end{equation}
where \( H(h, w, d, n) \) and \( G(h, w, d, n) \) are the predicted and ground truth heatmap values for the \( n \)-th landmark at voxel \( (h, w, d) \). \( H, W, D, \) and \( N \) represent the spatial dimensions and number of landmarks.

The anchor regression loss is:
\begin{equation}
\mathcal{L}_{\text{reg}} = \frac{1}{N} \sum_{i=1}^N \| (\Delta x_i, \Delta y_i, \Delta z_i) - (\hat{\Delta x}_i, \hat{\Delta y}_i, \hat{\Delta z}_i) \|^2,
\end{equation}
where \( (\Delta x_i, \Delta y_i, \Delta z_i) \) and \( (\hat{\Delta x}_i, \hat{\Delta y}_i, \hat{\Delta z}_i) \) are the ground truth and predicted offsets for the \( i \)-th anchor.

The classification loss is:
\begin{equation}
\mathcal{L}_{\text{cls}} = - \frac{1}{N} \sum_{i=1}^N \left[ p_i \log \hat{p}_i + (1 - p_i) \log (1 - \hat{p}_i) \right],
\end{equation}
where \( p_i \) and \( \hat{p}_i \) are the ground truth and predicted existence probabilities for the \( i \)-th anchor.

For the Anchor-free architecture, the total loss is:
\begin{equation}
\mathcal{L}_{\text{total}} = \mathcal{L}_{\text{heatmap}}.
\end{equation}

For the Anchor-based architecture, the total loss combines anchor regression, classification, and heatmap regression terms:
\begin{equation}
\mathcal{L}_{\text{total}} = \lambda_{\text{reg}} \mathcal{L}_{\text{reg}} + \lambda_{\text{cls}} \mathcal{L}_{\text{cls}} + \lambda_{\text{heatmap}} \mathcal{L}_{\text{heatmap}}.
\end{equation}

Here, \( \lambda_{\text{reg}} \) and \( \lambda_{\text{cls}} \) are hyperparameters that control the contributions of the anchor-related loss terms.
