\section{Introduction}
3D landmark detection is a critical task in medical image analysis, with wide applications~\cite{landmarkdetection1,king-landmark1, king-landmark2, treatment, huang2024retigan, shao2023diffuseexpand, king-medical1, MP-seg5} in surgical navigation~\cite{king1-naviga}, disease diagnosis~\cite{MP-diag1, MP-diag2, MP-diag3}, and treatment planning~\cite{MP-plan1}. Compared to 2D landmark detection, 3D landmark detection is more challenging due to the increased complexity of volumetric data~\cite{3dlandmark1, 3dlandmark2, 3dlandmark3}. For example, 3D medical imaging modalities such as CT scans contain rich anatomical structures but exhibit larger data volumes, more intricate spatial geometries, and significant patient-specific variability. Furthermore, landmarks in 3D images are often sparsely distributed and subject to low signal-to-noise ratio (SNR) and resolution differences. These factors make 3D landmark detection particularly difficult, especially in scenarios involving complex anatomical structures or missing landmarks.

Traditional marking methods mainly depend on manual annotations and rule-based algorithms. Although these approaches were significant in the early stages of medical image processing, they also present clear limitations. Firstly, rule-based algorithms often depend on specific image features, making it challenging to adapt to diverse medical images or complex lesions~\cite{handcrafted1,handcrafted2,handcrafted3}. Secondly, the manual annotation process is time-consuming and susceptible to subjective influences, resulting in inconsistencies and inaccuracies in the annotations.

Convolutional neural networks (CNNs) have become the mainstream approach for 3D landmark detection, driven by rapid advances in deep learning~\cite{CNN1, CNN2, oNeil, SCN, FARNet, 3D-CNN1-anchor, 3D-CNN2-sr, 3D-CNN3}. CNNs excel at extracting hierarchical and multi-scale features, making them practical for analyzing complex medical images. In particular, their ability to capture local spatial patterns is advantageous in tasks requiring detailed anatomical information. However, CNNs have limited receptive fields and struggle to model long-range dependencies, which are crucial for accurately detecting sparsely distributed landmarks in 3D. This lack of global context modeling represents a significant bottleneck for further performance improvement.

Transformer architectures~\cite{vaswani2017attention}, such as Vision Transformers (ViT)~\cite{VIT} and Swin Transformers, have gained traction in 3D medical imaging due to their ability to capture long-range dependencies through self-attention mechanisms~\cite{MP-atten-seg1, mp-CNN+ATTEn1, MP-hybrid4, MP-hybrid5, MP-hybrid-2}. This feature addresses the limitations of CNNs, which struggle with global context representation. Consequently, hybrid architectures that integrate CNNs for local feature extraction and lightweight Transformers for global context are emerging as effective solutions. This approach can better meet the dual demands of fine-grained spatial representation and holistic understanding in 3D landmark detection. However, the high computational cost and storage requirements of these hybrid models, along with the larger data volume and complexity of 3D data compared to 2D, hinder the performance of existing models, preventing them from achieving optimal results. 

To tackle these challenges, we propose a hybrid framework, \textbf{H}ybrid \textbf{3}D \textbf{DE}tection \textbf{Net}work(H3DE-Net), which integrates CNNs and lightweight Transformer modules for robust and accurate 3D landmark detection. Specifically, CNNs are utilized for efficient local feature extraction and multi-scale representation, while a Transformer module equipped with a bi-level routing attention mechanism enhances global context modeling. We also introduce a Feature Fusion Module (FFM) that integrates multi-scale features, effectively capturing global and local dependencies. This synergistic design enables H3DE-Net to overcome the limitations of standalone architectures and achieve precise and reliable landmark detection even in challenging scenarios.

Our main contributions are summarized as follows:  
\begin{itemize}
    \item We propose a hybrid CNN-Transformer model, \textbf{H3DE-Net}, for 3D landmark detection. By combining CNNs for local feature extraction with a lightweight attention mechanism for global context modeling, the model achieves state-of-the-art(SOTA) performance in challenging scenarios.
    \item We design a feature fusion module (FFM) for multiscale feature integration to restore fine-grained spatial details, significantly enhancing the precision and robustness of landmark detection.
    \item Extensive experiments on the public CT dataset demonstrate that our method outperforms existing baselines across multiple metrics, particularly in scenarios involving complex anatomical structures and missing landmarks.
\end{itemize}


%\end{introduction}