% \section{Discussion}
% \subsection{Impact of Different Backbone and Number of Stages}
% Table~\ref{tab:discuss} provides a detailed comparison of the performance of Transformer-based architectures on the ISBI2015 and Hand datasets, evaluated using MRE and SDR metrics. The results demonstrate that using the Swin Transformer as the backbone in the CAST module significantly outperforms ViT. This superiority arises from the strong coupling between the Swin Transformer and the spatial attention module: the Swin Transformer's hierarchical structure and sliding window mechanism effectively capture multi-scale features. In contrast, the spatial attention module enhances feature representation by focusing on critical regions in local and global spatial details. When the Swin Transformer block in the CAST module is combined with the ESAM module, it strengthens multi-scale feature fusion and semantic bridging, improving robustness and accuracy.

% The “stages” in the four-stage and five-stage architectures refer to the number of down-sampling (Encoder, E1-E5) and up-sampling (Decoder, D1-D5) operations. Compared to the four-stage architecture, the five-stage architecture adds a layer of down-sampling and up-sampling, enabling the extraction of deeper global semantic features while retaining high-resolution details through skip connections, thereby enhancing feature representation capabilities.

% Specifically, on the ISBI2015 dataset, the CAST module with a five-stage Swin Transformer achieves the lowest MRE of \(1.162 \pm 1.10 \, \text{mm}\), outperforming the ViT (four-stage and five-stage) and the four-stage Swin Transformer. Similarly, on the Hand dataset, the five-stage Swin Transformer achieves the best MRE of \(0.544 \pm 0.55 \, \text{mm}\), demonstrating its high precision in landmark detection tasks.

% Regarding SDR, the five-stage Swin Transformer consistently achieves the highest accuracy across various threshold distances. On the ISBI2015 dataset, it achieves an SDR of 84.76\% at the 2 mm threshold, outperforming the ViT (83.24\% and 84.27\% for four-stage and five-stage, respectively) and the four-stage Swin Transformer (84.32\%). The performance gains become more significant at larger thresholds, with the five-stage Swin Transformer achieving SDR values of 89.87\% (2.5 mm), 93.43\% (3 mm), and 97.20\% (4 mm). On the Hand dataset, the five-stage Swin Transformer also excels, achieving an SDR of 97.24\% at the 2 mm threshold and an almost perfect 99.72\% at the 4 mm threshold, significantly surpassing other configurations.

% These results highlight that using the Swin Transformer as the backbone in the CAST module, coupled with the spatial attention module, greatly enhances the network’s ability to capture global and local features. Furthermore, incorporating the ESAM module for multi-scale feature fusion and increasing the number of stages (i.e., down-sampling and up-sampling operations) further improves the network’s performance. This architecture consistently improves MRE and SDR metrics, validating its robustness and generalizability. These advancements represent a significant step forward in medical landmark detection, laying a solid foundation for enhancing the precision of clinical diagnosis and treatment planning.


% \subsection{Contributions to Medical Image Analysis}
% Anatomical landmark detection is a critical task in medical image analysis, widely used in applications such as diagnostic assistance, surgical planning, image registration, segmentation, and 3D reconstruction. Accurate localization of key anatomical structures is essential for improving diagnostic precision and treatment outcomes. However, existing methods often struggle to simultaneously capture global contextual information and fine-grained local features, particularly in complex anatomical structures and noisy medical images, resulting in reduced stability and accuracy.

% CASEMark addresses these challenges through several innovative components. The Convolutional Attention Swin Transformer (CAST) module integrates the strengths of both Swin Transformer and convolutional operations, enabling the model to capture both global context and detailed local features. The Enhanced Skip Attention Module (ESAM) further refines landmark localization through multi-scale feature fusion between the encoder and decoder. Additionally, a multi-resolution heatmap learning strategy improves detection accuracy and robustness across different anatomical regions and imaging modalities.

% These innovations make CASEMark valuable in medical physics. By providing precise landmark localization, CASEMark can effectively support tasks like diagnosis, surgical planning, and image registration, especially in scenarios with significant anatomical variations or poor image quality. Experimental results demonstrate that CASEMark outperforms existing methods, achieving SOTA performance on datasets like ISBI2015 and ISBI2023. Overall, CASEMark offers an efficient and generalizable solution to anatomical landmark detection, with broad application potential in clinical medical image analysis.