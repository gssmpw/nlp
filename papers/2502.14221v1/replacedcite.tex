\section{Related Work}
\label{sec.2}
\subsection{Landmark Detection in Medical Imaging}
Landmark detection is a fundamental task in medical image analysis, aimed at identifying anatomically significant feature points essential for ensuring the reliability and interpretability of automated systems ____. 

Early landmark detection methods relied on hand-crafted features ____ and model-based approaches. Cootes et al. ____ introduced Active Shape Models (ASM), which employed statistical shape constraints to guide landmark localization, requiring significant manual intervention but achieving moderate success in capturing anatomical variations. Active Appearance Models (AAM) ____ extended ASM by incorporating texture characteristics, improving accuracy in anatomical structure detection. These traditional approaches heavily relied on feature engineering, with methods such as SIFT ____ for extracting transformation-invariant features and rule-based techniques ____ for detecting edges and contours using geometric features and prior knowledge. However, these methods often struggled with anatomical variability, image quality degradation, and noise, limiting their robustness in clinical applications.


Deep learning, particularly CNNs and U-Net variants____, revolutionized landmark detection through hierarchical feature learning. These architectures excel at capturing multi-scale features and have demonstrated remarkable success in various medical imaging tasks. Payer et al.____ developed a stacked hourglass network for iterative refinement and deep regression networks that combined heatmap prediction with coordinate regression. Extended 3D heatmap-based approaches____ have further advanced the field by effectively processing volumetric data and providing robust spatial predictions. While these methods show promising results in 3D landmark detection, they face inherent limitations in capturing long-range dependencies and global context, mainly when modeling complex volumetric anatomical relationships across different planes.


\subsection{Hybrid CNN-Transformer Model}
Recent advances in Transformer architectures have shown promising potential in addressing CNNs' limitations in capturing long-range dependencies. Vision Transformers____ excel at modeling global context through self-attention mechanisms, complementing CNNs' local feature extraction capabilities. This complementary nature has led to the development of hybrid CNN-Transformer architectures, particularly in medical image analysis. Models such as TransUNet____ and nnFormer____ and others____ integrate Transformer modules into U-Net frameworks to enhance feature representation, demonstrating significant improvements in capturing spatial dependencies across different anatomical regions. Landmark detection has particularly benefited from this architectural advancement, with approaches like SpineHRFormer ____ and DATR ____ leveraging the combined strengths of both architectures. These hybrid models have demonstrated superior performance by capturing fine-grained anatomical details through CNN features and modeling long-range structural relationships via self-attention mechanisms, effectively addressing the limitations of traditional CNN-based approaches.

However, extending these hybrid approaches to 3D landmark detection faces significant challenges. The quadratic computational complexity of self-attention mechanisms concerning input size makes direct application to volumetric data prohibitive. At the same time, the increased dimensionality of 3D data demands substantial computational resources and training data. These limitations highlight the need for more efficient architectural designs tailored for 3D landmark detection tasks.