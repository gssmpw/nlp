%%%% ijcai25.tex

\typeout{IJCAI--25 Instructions for Authors}

% These are the instructions for authors for IJCAI-25.
\pdfoutput=1
\documentclass{article}
\pdfpagewidth=8.5in
\pdfpageheight=11in

% The file ijcai25.sty is a copy from ijcai22.sty
% The file ijcai22.sty is NOT the same as previous years'
\usepackage{ijcai25}

% Use the postscript times font!
\usepackage{times}
\usepackage{soul}
\usepackage{url}
\usepackage[hidelinks]{hyperref}
\usepackage[utf8]{inputenc}
\usepackage[small]{caption}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{booktabs}
\usepackage{algorithm}
\usepackage{algorithmic}
% \usepackage[switch]{lineno}
% \usepackage[switch]{lineno}

\usepackage{color}
\usepackage{amssymb} 
\usepackage{pifont}  
\usepackage{amssymb} 
\usepackage[dvipsnames, table]{xcolor}
% \newcommand{\cmark}{\textcolor{black}{\ding{51}}} % 红色 ✔
% \newcommand{\xmark}{\textcolor{black}{\ding{55}}} % 绿色 ✘
\newcommand{\xgy}[1]{{\color{black} #1}}
\newcommand{\wys}[1]{{\color{black} #1}}
\newcommand{\xxc}[1]{{\color{black} #1}}
\newcommand{\ljq}[1]{{\color{black} #1}}

\newcommand{\cmark}{\textcolor{red}{\ding{51}}} % 红色 ✔
\newcommand{\xmark}{\textcolor{green}{\ding{55}}} % 绿色 ✘
% \newcommand{\xgy}[1]{{\color{purple} #1}}
% \newcommand{\wys}[1]{{\color{brown} #1}}
% \newcommand{\xxc}[1]{{\color{blue} #1}}
% \newcommand{\ljq}[1]{{\color{red} #1}}
% Comment out this line in the camera-ready submission
% \linenumbers

\urlstyle{same}

% the following package is optional:
%\usepackage{latexsym}

% See https://www.overleaf.com/learn/latex/theorems_and_proofs
% for a nice explanation of how to define new theorems, but keep
% in mind that the amsthm package is already included in this
% template and that you must *not* alter the styling.
\newtheorem{example}{Example}
\newtheorem{theorem}{Theorem}

% Following comment is from ijcai97-submit.tex:
% The preparation of these files was supported by Schlumberger Palo Alto
% Research, AT\&T Bell Laboratories, and Morgan Kaufmann Publishers.
% Shirley Jowell, of Morgan Kaufmann Publishers, and Peter F.
% Patel-Schneider, of AT\&T Bell Laboratories collaborated on their
% preparation.

% These instructions can be modified and used in other conferences as long
% as credit to the authors and supporting agencies is retained, this notice
% is not changed, and further modification or reuse is not restricted.
% Neither Shirley Jowell nor Peter F. Patel-Schneider can be listed as
% contacts for providing assistance without their prior permission.

% To use for other conferences, change references to files and the
% conference appropriate and use other authors, contacts, publishers, and
% organizations.
% Also change the deadline and address for returning papers and the length and
% page charge instructions.
% Put where the files are available in the appropriate places.


% PDF Info Is REQUIRED.

% Please leave this \pdfinfo block untouched both for the submission and
% Camera Ready Copy. Do not include Title and Author information in the pdfinfo section
\pdfinfo{
/TemplateVersion (IJCAI.2025.0)
}

\title{A Survey on Industrial Anomalies Synthesis}


% Single author syntax
\author{
    Author Name
    \affiliations
    Affiliation
    \emails
    email@example.com
}

% Multiple author syntax (remove the single-author syntax above and the \iffalse ... \fi here)
% \iffalse
\author{
Xichen Xu$^{1}$\footnote{Contributed Equally}
\and
Yanshu Wang$^{1*}$\and
Yawen Huang$^{2*}$\and
Jiaqi Liu$^{3}$\and
Xiaoning Lei$^{4}$\\
Guoyang Xie$^{3,4}$\footnote{Corresponding Author}\and
Guannan Jiang$^{4,\dag}$\and
Zhichao Lu$^3$
\affiliations
$^1$Shanghai Jiao Tong University\\
$^2$Jarvis Research Center, Tencent Youtu Lab\\
$^3$City University of Hong Kong\\
$^4$Department of Intelligent Manufacturing, CATL\\
% \emails
% xichen.personal@gmail.com,
% isaac\_wang@sjtu.edu.cn,
% bear\_huang@126.com,
% leixn01@outlook.com,
% guoyang.xie@ieee.org,
% jianggn@catl.com
}
% \fi

\begin{document}

\maketitle

\begin{abstract}
%Rapid advancements in generative models and vision systems have significantly advanced industrial image anomaly synthesis (IAS), addressing the persistent challenge of the scarcity of labeled abnormal data in manufacturing. Therefore, we present a comprehensive review of IAS methodologies in this paper, categorizing existing approaches into four distinct paradigms: Hand-crafted Augmentation Models, Distribution Hypothesis-based Models, Generative Models (GMs), and Vision Language models (VLMs). We rigorously analyze their technical foundations and performance trade-offs in synthesizing high-fidelity and contextually consistent anomalies for downstream industrial applications.
\begin{figure*}[hbt]
\centering
    \includegraphics[width=0.97\textwidth]{trend3.pdf}
    \vskip -0.1in % 使标题与图像更紧凑
   \caption{ (a) Trend of papers related to anomaly detection and anomaly synthesis from 2019 to 2024. Anomaly detection has shown steady growth in publications, while anomaly synthesis has gained increasing attention in recent years, particularly experiencing a significant surge in 2024. (b) Comparison of survey papers on anomaly detection and anomaly synthesis. While numerous surveys exist on anomaly detection, anomaly synthesis remains an emerging field with no dedicated surveys to date. Our work is the \textbf{first} to fill this gap. Data sources are from \href{https://github.com/M-3LAB/awesome-industrial-anomaly-detection} {https://github.com/M-3LAB/awesome-industrial-anomaly-detection}}
    \label{trend}
\vskip -0.1in
\end{figure*}
%Furthermore, we propose a systematic taxonomy incorporating insights from real-world manufacturing challenges, emphasizing various strategies such as multimodal interaction in IAS development. We also discuss the advantages and limitations of each category, with particular attention to their adaptability to different requirements of industrial production. Finally, we summarize key findings and outline future directions for advancing IAS research, including achieving pixel-level fidelity, leveraging multimodal information, and boosting the performance of downstream models. More resources are available at \href{https://github.com/M-3LAB/awesome-anomaly-synthesis}{https://github.com/M-3LAB/awesome-anomaly-synthesis}.

\xgy{This paper comprehensively reviews anomaly synthesis methodologies. Existing surveys focus on limited techniques, missing an overall field view and understanding method interconnections. In contrast, our study offers a unified review, covering about 40 representative methods across Hand-crafted, Distribution-hypothesis-based, Generative models (GM)-based, and Vision-language models (VLM)-based synthesis. We introduce the first industrial anomaly synthesis (IAS) taxonomy. Prior works lack formal classification or use simplistic taxonomies, hampering structured comparisons and trend identification. Our taxonomy provides a fine-grained framework reflecting methodological progress and practical implications, grounding future research. Furthermore, we explore cross-modality synthesis and large-scale VLM. Previous surveys overlooked multimodal data and VLM in anomaly synthesis, limiting insights into their advantages. Our survey analyzes their integration, benefits, challenges, and prospects, offering a roadmap to boost IAS with multimodal learning. More resources are available at \href{https://github.com/M-3LAB/awesome-anomaly-synthesis}{https://github.com/M-3LAB/awesome-anomaly-synthesis}.}

% The rapid advancements in generative modeling and large-scale vision systems have revolutionized industrial image anomaly synthesis (IAS), addressing the scarcity of labeled abnormal data in manufacturing. In this paper, we provide a comprehensive review of IAS techniques, categorizing them into hand-engineered models, distribution hypothesis-based models, generative models (GMs)-based approaches, and \ljq{Vision Language Models?} large vision models (LVMs)-based frameworks. From these perspectives, we analyze their mechanisms \xgy{What is the meaning of mechanisms?}, strengths, and limitations in generating high-fidelity, diverse, and contextually relevant anomalies for industrial applications. 

% In addition, we propose a systematic taxonomy to integrate insights from real-world manufacturing challenges, highlighting emerging techniques such as multimodal synthesis, mask-guided generation, and progressive defect refinement.\xgy{What's the meaning of Integrate?} The merits and limitations of each paradigm are discussed, with a focus on their adaptability to diverse defect scenarios.\xgy{What? diverse defect scenarios} Finally, we summarize our findings and outline future research directions for advancing IAS methodologies, including enhancing anomaly diversity, achieving pixel-level alignment, and leveraging multimodal information. More resources are available at \href{https://github.com/M-3LAB/awesome-anomaly-synthesis}{https://github.com/M-3LAB/awesome-anomaly-synthesis}.
\end{abstract}

% ##################################
% (缺陷合格率低的原因要不要缩减，我不确定....，还有defect和anomaly用一个词就行，)
% 首先，缺陷发生率低是一个显著的挑战。在大规模生产环境中，合格品的比例通常远高于不合格品。其次，专业设备和人工审核的需求进一步抬高了获取异常样本的成本。许多工业缺陷，如微小的裂痕、细微的划痕或隐蔽的污物，往往需要借助高精度的检测设备（如高倍显微镜、X射线检测仪等）才能被发现。同时，检测结果还需要由经验丰富的专业人员进行人工审核和确认，这不仅需要高水平的技术支持，还涉及大量的人力资源投入。此外，数据标注的困难也是一大障碍。异常样本的标注通常需要专业知识和经验，标注过程复杂且耗时。由于异常样本数量有限，标注团队可能需要花费大量时间在每一个样本的详细分析和标记上，这不仅延长了数据准备的周期，也增加了标注工作的成本。
% 为了应对这些问题，人们发明了多种多样的异常合成算法来合成工业异常样本，试图通过合成数据去生成或者扩充异常数据集，以来缓解真实异常样本获取困难的挑战，旨在著提升下游检测算法的性能。然而，工业异常合成算法的进一步发展仍然面临以下挑战：

% 一个产品的某一缺陷种类的样本数量是有限的，即所获取的是对异常样本分布的有限次采样，因此无法涵盖所有可能的情况。这迫使算法必须提高复杂性以满足多样性需求；

% 实际缺陷类型繁多（如裂痕、划痕、污物、破洞、印刷问题等），整体缺陷分布通常呈现混合分布特征，并且与背景分布之间存在复杂的偏移，不同的缺陷在full sample的占比也不一致。导致在建模时面临困难，进而导致合成样本中缺失异常或者异常不真实；
% ##################################



% 在制造业及其他工业领域中，工业异常检测扮演着至关重要的角色。其主要任务是通过监测生产过程中的各种参数和特征，及时发现和识别潜在的缺陷或异常，从而保障产品质量和生产效率。然而，实际应用中，异常检测往往需要大量的异常样本作为训练和验证数据，以确保检测算法的准确性和鲁棒性。与此同时，获取这些实际异常样本与其对应标注的代价却是高昂的，这种高昂代价具体体现在以下几个方面：
% 首先，缺陷发生率低是一个显著的挑战。在大规模生产环境中，合格品的比例通常远高于不合格品。其次，专业设备和人工审核的需求进一步抬高了获取异常样本的成本。许多工业缺陷，如微小的裂痕、细微的划痕或隐蔽的污物，往往需要借助高精度的检测设备（如高倍显微镜、X射线检测仪等）才能被发现。同时，检测结果还需要由经验丰富的专业人员进行人工审核和确认，这不仅需要高水平的技术支持，还涉及大量的人力资源投入。此外，数据标注的困难也是一大障碍。异常样本的标注通常需要专业知识和经验，标注过程复杂且耗时。由于异常样本数量有限，标注团队可能需要花费大量时间在每一个样本的详细分析和标记上，这不仅延长了数据准备的周期，也增加了标注工作的成本。
% 为了应对这些问题，人们发明了多种多样的异常合成算法来合成工业异常样本，试图通过合成数据去生成或者扩充异常数据集，以来缓解真实异常样本获取困难的挑战，旨在著提升下游检测算法的性能。然而，工业异常合成算法的进一步发展仍然面临以下挑战：
% 一个产品的某一缺陷种类的样本数量是有限的，即所获取的是对异常样本分布的有限次采样，因此无法涵盖所有可能的情况。这迫使算法必须提高复杂性以满足多样性需求；
% 实际缺陷类型繁多（如裂痕、划痕、污物、破洞、印刷问题等），整体缺陷分布通常呈现混合分布特征，并且与背景分布之间存在复杂的偏移，不同的缺陷在full sample的占比也不一致。导致在建模时面临困难，进而导致合成样本中缺失异常或者异常不真实；
% 多模态信息的应用日益增多（例如根据文本提示生成异常样本），但如何更有效地利用这些多模态信息来合成缺陷样本仍然是一个亟待解决的挑战。
% 因此，在深入探索现有合成方法具体实现的同时，对工业异常合成算法的现状和挑战进行系统性的梳理和分析显得尤为必要。通过总结不同研究者对上述问题的处理方式，不仅能够明确当前研究的优势和不足，还能为未来算法的发展提供有力的指引。

\section{Introduction}


\xgy{Image anomaly detection plays a pivotal role in manufacturing, primarily focused on identifying the anomalies of products, thereby ensuring product quality. In practical usage, an image anomaly detection system typically requires substantial quantities of high-quality annotated abnormal samples for training. However, the acquisition of high-quality annotated abnormal samples incurs prohibitively high costs. The difficulties are summarized as follows: }
\xgy{\ding{182} The low defective rate presents a fundamental challenge. In large-scale manufacturing scenarios, the proportion of qualified products far exceeds that of abnormal ones. \ding{183} The necessity for specialized equipment substantially escalates costs. Many industrial anomalies, such as microscopic cracks, fine scratches, or concealed contaminants, require detection via high-precision instruments (\textit{e.g.} high-magnification microscopes, and X-ray inspection systems). These high-precision machines advance technical infrastructure investment. \ding{184} \xgy{Abnormal sample labeling requires domain expertise and meticulous analysis, resulting in time-consuming procedures.} \wys{Accurate annotation requires skilled professionals, whose limited availability increases labor expenses. Additionally, certain anomalies demand multi-modal validation using advanced imaging techniques, further amplifying the time and resource burden.} } 

%准确的注释需要熟练的专业人员，他们的有限可用性增加了劳动力成本。此外，某些缺陷需要使用先进的成像技术进行多模态验证，这进一步加重了时间和资源负担。

\xgy{\noindent To address these limitations,  various image anomalies synthesis algorithms have been developed to generate abnormal samples, aiming to mitigate the scarcity of real abnormal samples and enhance downstream detection performances. Nevertheless, the existing anomalies synthesis algorithm cannot fulfill the requirements of industrial manufacturing. The challenges are listed as follows: }
\begin{itemize}

    \xgy{\item[1.] \textbf{Limited Sampling of Anomalies Distribution} The finite number of abnormal samples for specific anomaly types constitutes sparse sampling from the underlying anomaly distribution, failing to capture full variability. This constraint forces the algorithm to adopt increased complexity to satisfy diversity requirements.}
    % Near-In-Distribution/
    \xgy{\item[2.] \textbf{Realistic Anomalies Synthesis}} \xxc{Practical anomalies are highly complex  (\textit{e.g.,} cracks, scratches, contaminants, punctures) and exhibit large distribution shifts compared to background textures. The diverse occurrence rates of different anomaly types add significant complexity to the modeling process. It can lead to synthetic anomalies that fail to accurately capture the realism of real-world anomalies, resulting in missing or unrealistic features.}

    \xgy{\item[3.] \textbf{Underutilization of Multimodal Information} While multimodal cues (\textit{e.g.} text prompts for anomalies synthesis) are increasingly available, effectively integrating such information to synthesize realistic anomalies patterns remains an open challenge. }
\end{itemize}



\noindent \xgy{Consequently, systematic analysis and comprehensive review of current industrial anomaly synthesis (IAS) have become imperative. As shown in Figure \ref{trend}, the number of published papers on anomaly detection has surged significantly in recent years, highlighting the growing industrial and academic focus on this field. Correspondingly, research on anomaly synthesis has also seen a noticeable increase, reflecting the rising recognition of its importance in mitigating the scarcity of real abnormal samples. Despite this upward trend, existing anomaly synthesis methods still face fundamental challenges that hinder their practical adoption in industrial manufacturing. By critically examining these challenges, we can not only identify the strengths and limitations of current research but also establish clear guidelines for future algorithm development. Such an analysis will provide foundational insights for advancing anomaly synthesis techniques and optimizing their applicability in real-world scenarios.}



%to be checked 2.11

% 为了解决工业异常生成中的挑战，我们提出了一项综合性综述，不仅弥补了现有工作的不足，还在系统性分析这一领域方面设立了新的基准。尽管已有若干综述探讨了工业异常生成，但它们仍然存在需要进一步研究和整合的具体局限性，这些局限性可以归纳为以下几个方面：

% 1. 对特定技术的关注过于分散：
% 现有综述通常将研究范围局限于某些特定的生成方法，未能全面审视整个领域。例如，Chen等人 ~\citeauthor{chen2021surface} 强调了数据增强策略，但忽视了更高级的生成方法在生成具有更强判别力的缺陷表示方面的潜力。同样，Xia等人 ~\citeauthor{xia2022gan} 专注于GAN-based models在异常合成的表现，却未探讨其他新兴生成范式的潜能。这种分散的视角限制了对多种方法在解决实际挑战中如何协同发挥作用的理解。

% 2. 分类框架过于简单化：
% 一些研究采用了过于简单的分类方案，未能反映异常生成方法的多样性和发展。例如，Liu等人 ~\citeauthor{liu2024deep} 将方法仅简单地划分为有监督和无监督两类，这种分类方式不足以代表当前领域内涌现的复杂方法学。这种分类的局限性阻碍了对新研究方向和混合方法的发现。

% 3. 对多模态及高级应用的关注不足：
% 尽管已有研究认识到利用多模态输入的重要性，但许多综述未能深入探讨新技术（例如大规模视觉模型，LVMs）如何变革异常生成领域。Cao等人 ~\citeauthor{cao2024survey} 提出将LVMs用于跨模态异常数据生成的想法，但缺乏对其适用性和当前局限性的系统性分析。这种不足使得高级方法与实际工业需求之间的关系未得到充分探讨。

% 与上述局限性相比，我们的综述具有以下独特的贡献：

% 我们建立了一套清晰的异常生成方法分类体系，将其划分为四个综合组：基于手工设计的模型、基于分布假设的模型、生成模型（GMs）和大规模视觉模型（LVMs）。每个类别进一步细化，以反映具体的建模技术。
% 我们对每类方法的优点、缺点以及实际应用场景进行了批判性评估，为研究人员和实践者提供了可操作的见解。
% 我们结合历史发展和新兴趋势，提出了前瞻性的洞察，旨在解决现有差距并引导未来的研究方向。相比现有综述，我们的方法特点在于其系统性分类、方法的批判性评估和面向未来的洞察力，确保其能够成为学术研究和工业应用的重要参考。




\noindent \textbf{Comparison to Existing Surveys:} \wys{Therefore, we propose a comprehensive survey that not only bridges the gaps in existing work but also establishes a novel framework for systematic analysis in IAS. Although several surveys have briefly discussed IAS, they exhibit specific limitations shown in Table.~\ref{comparison},  which can also be categorized as follows:}

% 这里少2篇类我找到的survey！！！！！！！！！！！！！！！！
%\textbf{1. Fragmented Focus on Specific Techniques:} Existing surveys often limit their scope to specific synthesis methods, failing to provide a holistic perspective on the field. For instance, Chen et al. ~\citeauthor{chen2021surface} emphasize data augmentation strategies but overlook the potential of more advanced synthesis methods in generating more discriminative defect representations. Similarly, Xia et al. ~\citeauthor{xia2022gan} focus on the performance of GAN-based models in anomaly synthesis but fail to explore the potential of other emerging generative paradigms. This fragmented perspective restricts the understanding of how diverse methods can complement each other in addressing practical challenges.


% 缺少的两篇加在这里
\xgy{\textbf{(\romannumeral1) Limited Scope on Synthesis Methods.}}  Existing surveys often limit their scope to specific synthesis methods, failing to provide a holistic perspective on the field. For instance, ~\citeauthor{chen2021surface} emphasize data augmentation strategies but overlook the potential of more advanced synthesis methods in generating more discriminative defect representations. Similarly, ~\citeauthor{xia2022gan} focus on the performance of generative adversarial networks (GAN)-based models in anomaly detction and synthesis, but fail to explore the potential of other emerging generative paradigms. This fragmented perspective restricts the understanding of how diverse methods can complement each other in addressing practical challenges.


%\textbf{(\romannumeral2) Oversimplified Categorization Frameworks:} Several studies employ overly simplistic classification schemes, which do not capture the diversity and evolution of anomaly synthesis methods. For example, Liu et al. ~\citeauthor{liu2024deep} divides methods into only supervised and unsupervised categories, which is insufficient to represent the nuanced methodologies emerging in the field. Such a lack of granularity hinders the identification of novel research directions and hybrid approaches.

\wys{\textbf{(\romannumeral2) Lack of a Dedicated Taxonomy:}  Existing anomaly-related surveys primarily focus on anomaly detection, often treating anomaly synthesis as a minor aspect without a structured classification. For instance, ~\citeauthor{liu2024deep} broadly classify anomaly detection methods into supervised and unsupervised categories, which fails to capture the methodological diversity of anomaly synthesis. To the best of our knowledge, our survey is the \textbf{first} dedicated work that systematically categorizes IAS methods. By addressing this gap, we introduce a structured taxonomy tailored specifically for anomaly synthesis, providing a more comprehensive foundation for understanding and comparing different synthesis approaches.}

%\textbf{3. Insufficient Emphasis on Cross-Modality and Advanced Applications:} Despite recognizing the importance of leveraging multi-modal inputs, many surveys fail to explore how emerging techniques, such as Large Vision Models (LVMs), can transform anomaly synthesis. Cao et al. ~\citeauthor{cao2024survey} suggests integrating LVMs for cross-modal abnormal data generation but lacks a systematic analysis of their applicability and current limitations. This oversight leaves the relationship between advanced methodologies and practical industrial challenges underexplored.

\xgy{\textbf{(\romannumeral3) Insufficient Emphasis on Cross-Modality Synthesis.} Although existing research acknowledges the importance of leveraging multiple modalities, many review papers have not thoroughly explored how emerging technologies, such as large-scale vision-language models (VLM), are transforming the field of anomaly synthesis. ~\citeauthor{cao2024survey} proposed the use of VLM for cross-modal anomaly synthesis. However, a systematic analysis of their applicability and current limitations remains urgently needed, the lack of which has hindered the exploration of how advanced methods align with the practical demands of industry.}

\begin{table}[htbp]
\centering
\vskip -0.1in
\caption{Comparison of previous survies and our survey.}
\rowcolors{2}{lightgray!20}{white} 
\renewcommand{\arraystretch}{1.7} 
\Large 
\resizebox{0.5\textwidth}{!}{
    \begin{tabular}{>{\bfseries}lccccc}
        \rowcolor{blue!30} 
        \textcolor{white}{} & 
        \textcolor{white}{~\citeauthor{liu2024deep}} & 
        \textcolor{white}{~\citeauthor{chen2021surface}} & 
        \textcolor{white}{~\citeauthor{xia2022gan}} & 
        \textcolor{white}{~\citeauthor{cao2024survey}} & 
        \textcolor{white}{Our} \\
        \toprule
        Perspective & Detection & Detection & Detection & Detection & Synthesis \\
        % Synthesis Methods & \xmark & \xmark & \xmark & \xmark & \cmark \\
        Number of IAS Categories & 2 & 0 & 4 & 4 & \textbf{10} \\
        Multimodal Interaction & \xmark & \xmark & \xmark & \xmark & \cmark \\
        \bottomrule
    \end{tabular}
}
    \label{comparison}
\end{table}




\begin{figure*}[htb]
    \centering
\includegraphics[width=0.97\textwidth]{Industrial_Anomalies_Synthesis.pdf}
    \caption{A Taxonomy of Image Anomalies Synthesis(IAS)}
    \label{taxonomy}
\end{figure*}


\noindent \textbf{Contributions:} The main contributions of this survey paper can be summarized as follows:

\wys{
\begin{itemize}
   \item[1.] Our survey provides a unified and systematic review of anomaly synthesis, covering nearly \textbf{40} representative methods across different paradigms. By exploring Hand-crafted synthesis, Distribution hypothesis-based synthesis, Generative models (GM)-based synthesis, and Vision language models (VLM)-based synthesis, we provide a comprehensive overview that captures the full scope of techniques available in the field.
 
    \item[2.] We present the \textbf{first} dedicated taxonomy for IAS, offering a structured and fine-grained classification framework that reflects methodological advancements and practical implications, thus serving as a foundation for future research and innovation in IAS.

    \item[3.]This work delves into the integration of multimodal cues and large-scale VLM in anomaly synthesis, addressing their potential benefits, challenges, and future opportunities. Our exploration provides a comprehensive framework for leveraging multimodal learning, enhancing the effectiveness of anomaly synthesis in industrial applications.
\end{itemize}
}

% 贡献：本综述论文的主要贡献可以概括如下：
% 据我们所知，这是第一篇对工业缺陷样本合成算法进行全面回顾和系统分类的工作，涵盖了该领域随着时间的推移而开发的近 40 种代表性方法。
% 它对现有的工业缺陷样本合成方法进行了彻底的研究，根据其底层方法将它们独特地分为四种不同的类型，并讨论了每种方法的优点和局限性。
% 它强调了工业缺陷样本合成未来发展的潜在方向，鼓励研究人员和从业者进一步探索这一领域，以推动持续的技术创新和进步。

\noindent \textbf{Organization:} \wys{The remainder of this paper is structured as follows:  
Section~\ref{sec:taxonomy} presents a systematic taxonomy of IAS4, introducing key paradigms and their methodological distinctions.  
Sections~\ref{sec:handcrafted} to \ref{sec:vlms} provide an in-depth analysis of the four primary categories of IAS, examining their theoretical foundations, implementation strategies, and practical applications. Specifically, these sections cover \hyperref[sec:handcrafted]{Hand-crafted synthesis}, \hyperref[sec:distribution]{Distribution hypothesis-based synthesis}, \hyperref[sec:generation]{Generative models (GM)-based synthesis}, and recently emerging \hyperref[sec:vlms]{Vision language models (VLM)-based synthesis}.  
Finally, Sections~\ref{sec:future} and \ref{sec:conclusion} consolidate key insights from the survey, critically assess the limitations of current methodologies, and outline promising future research directions to advance the field of IAS. 
}


% 本文的其余部分组织如下：第 2 节初步介绍了工业异常生成对于下游检测任务的必要性，以及介绍了IAS survey的taxonomy。第 3 - 6节首先讨论工业异常生成中主流的hand-engineered的异常合成，基于分布假设的异常合成，基于深度生成模型的缺陷合成已经最近兴起的基于大模型的缺陷合成，在每一类进行进一步的细化，并分析了彼此之间的区别与联系，最后，在第六节总结了本次调查并提出了未来工作的途径。

\section{Taxonomy of IAS}
\label{sec:taxonomy}
% 工业图像异常检测是现代制造业的核心环节，通过识别裂纹、划痕以及材料不一致等缺陷，维持产品质量与运营效率。然而，异常标注数据的稀缺性给开发鲁棒的检测系统带来了重大挑战。这种稀缺性源于生产中缺陷发生率低、获取高级成像设备和专家标注的成本高昂，以及准确标注复杂多样异常的难度。
% 因此，合成异常生成成为克服这些挑战的关键策略，能够为训练异常检测模型提供多样化、高质量的缺陷样本。

% \noindent \textbf{Industrial anomaly detection:} As a critical component of modern manufacturing, industrial image anomaly detection ensures product quality by identifying defects such as cracks, scratches, and material inconsistencies. However, the scarcity of anomalous data remains a fundamental challenge in developing robust detection systems. This scarcity arises primarily due to the low occurrence rate of defects, the high cost of acquiring high-quality annotations, and the complexity of labeling diverse anomalies. Consequently, synthetic anomaly synthesis has emerged as a key strategy to provide diverse and high-quality defective samples for model training, thereby enhancing detection capabilities. \xgy{[Yanshu TODO] You should introduce the taxonomy with Fig1 and Fig2 }

% %作为现代制造业的重要环节，工业图像异常检测通过识别裂纹、划痕和材料不一致等缺陷来保障产品质量。然而，异常数据的稀缺性依然是制约检测系统鲁棒性的核心挑战。这种稀缺性主要来源于缺陷发生率低、获取高质量标注成本高，以及复杂异常的标注难度。因此，合成异常数据已成为关键策略，可为模型训练提供多样化、高质量的缺陷样本，以提高检测能力。

% % \noindent \textbf{Categories of Industrial Anomaly Generation:} The methodologies for industrial anomaly generation can be categorized into four distinct paradigms: Hand-Engineered Models, Distribution Hypothesis-Based Models, Generative Models-Based (GMs-Based) Models, and Large Vision Models-Based (LVMs-Based) Models. Below, we define each paradigm and discuss its key characteristics.

\wys{\noindent \textbf{Taxonomy of Industrial Anomaly \xgy{Synthesis:}} In Figure~\ref{taxonomy}, we present a detailed taxonomy of \xgy{IAS}. We categorize \xgy{IAS} into four main paradigms: \xgy{Hand-crafted synthesis, Distribution hypothesis-based synthesis, Generative models (GM)-based synthesis, and Vision language models (VLM)-based synthesis.} Each paradigm has distinct characteristics in terms of the anomaly synthesis approach and applicable scenarios. Additionally, \xgy{Figure~\ref{fig:dif} illustrates the internal structures and implementation details of these four paradigms, providing a comprehensive view of the anomaly synthesis process within the different approaches.} }
% 异常生成方法分类： 我们将工业异常生成的方法划分为四大范式，即手工设计模型（Hand-crafted Model）、基于分布假设的模型（Distribution Hypothesis-Based Models）、基于生成模型的方法（GM-Based Models）以及基于大视觉模型的方法（VM-Based Models）。每种范式在异常生成的方式、适用场景及局限性上各具特点。此外，图 2 展示了这四种范式的内部结构与实现细节，进一步揭示了每种方法在异常合成过程中的具体实现方式。

% \noindent \textbf{Definition of Hand-Craft Models:} Hand-engineered models represent one of the earliest and most straightforward approaches to anomaly generation, relying on manually designed rules and transformations to simulate defects. These models are typically training-free and are characterized by their simplicity, computational efficiency, and reliance on domain knowledge. They are particularly effective in controlled environments where the requirements for defect realism and diversity are limited.

% Typical methods in this category include Data Augmentation and Texture Replacement. The former primarily applies predefined transformations such as cropping and rotation to existing images, while the latter generates anomalies through texture substitution. However, the inherent limitations of these approaches lie in their inability to replicate the complex and diverse characteristics of real-world industrial anomalies.

% \wys{\noindent \textbf{Definition of hand-crafted synthesis:} \xgy{Hand-crafted synthesis rely on manually designed rules to simulate anomalies}, typically without requiring training (training-free), making them suitable for controlled environments where high realism and diversity of defects are not essential. Among them, \textbf{Self-contained} model directly manipulates the original image through operations such as cropping, rearrangement, or local perturbations, relying solely on the image itself to simulate texture misalignment or color variation, thus generating anomalous regions. \xgy{\textbf{External-dependent} model introduces additional data sources (\textit{e.g.}, texture libraries or predefined templates) and synthesizes \xgy{anomalies} independent of the original image by overlaying textures or templates, ensuring that the anomalous features are not constrained by the image content. [Too Long and Break It]} \textbf{Inpainting-based} model artificially removes local image information using masking techniques to create defective regions. Its core principle is to directly disrupt structural continuity, typically by filling in black regions, adding noise, or applying specific patterns, thereby generating anomalies through information removal. }

\wys{\noindent \textbf{Definition of Hand-Crafted Synthesis:} \xgy{Hand-crafted synthesis relies on manually designed rules to simulate anomalies}, typically training-free and suitable for controlled environments where high realism and defect diversity are not critical. \textbf{Self-contained} synthesis manipulates the original image through operations like cropping or rearrangement to simulate texture misalignment or color variation, synthesizing abnormal regions.  \xgy{\textbf{External-dependent} synthesis employs external data (\textit{e.g.}, texture libraries) to synthesize anomalies independently of the original image, ensuring abnormal parts are not confined by its content.} \textbf{Inpainting-based} syhthesis remove local areas through masking techniques, disrupting structural continuity by adding noise or black patches to generate anomalies.}

%手工设计模型依赖人工设定的规则或图像变换策略进行异常模拟，通常无需训练（training-free），适用于对缺陷真实性和多样性要求较低的受控环境。其中，自足式生成方法通过直接操作原始图像，如剪切、重组或局部扰动，仅依赖图像自身内容来模拟纹理错位或颜色变化，以生成异常区域。外部依赖式生成方法则通过引入额外数据源（如纹理库或预定义模板），利用贴图或模板叠加的方式合成独立于原始图像内容的缺陷，确保异常特征不受图像本身限制。遮盖式生成方法通过掩码技术人为移除图像局部信息，从而生成缺陷区域，其核心在于直接破坏图像结构的连续性，通常通过填充黑色、噪声或特定图案实现，从完整图像构造出具有缺失信息的异常样本。

\wys{\noindent \textbf{Definition of Distribution Hypothesis-based Synthesis: }Distribution hypothesis-based synthesis relies on statistical modeling of normal data distributions and synthesize anomalies through controlled perturbations, typically by adjusting the feature space of normal samples. \textbf{Prior-dependent} synthesis uses the pre-defined geometric assumptions (e.g., manifold or hypersphere structures) to define normal data distributions in feature space, 
applying controlled deviations to ensure the synthesized feature-level anomalies lie at the boundary or outside the normal distribution. In contrast, \textbf{Data-driven} synthesis leverages intrinsic statistical properties of data by extracting features in the latent space and synthesizing anomalies through perturbations or adaptive strategies, enhancing the diversity and realism of the generated samples.}

%基于分布假设的模型依赖对正常数据分布的统计建模，并通过受控扰动生成异常样本，通常基于对正常样本特征空间的调整来实现异常模式的模拟。其中，先验依赖生成方法基于假设的几何结构（如流形或超球），首先明确正常数据在特征空间中的分布范围，并在此基础上施加受控偏离，使生成样本位于数据分布边界或外部，从而形成特征级异常。相比之下，数据驱动生成方法直接利用数据的内在统计特性，通过提取潜在空间的特征，并结合噪声扰动或自适应策略合成异常，进一步提升了生成样本的多样性和逼真度。此外，数据驱动生成方法能够结合监督与无监督策略（如双解码器结构或局部自适应扩散）以优化异常样本质量，使其更贴近真实缺陷的分布特性。

\wys{\noindent \textbf{Definition of GM-based Synthesis:} Recent advancements in deep GM, such as GANs and diffusion methods, enable realistic anomaly synthesis. GM-based synthesis is categorized into \textbf{Full-image synthesis}, \textbf{Full-image translation}, and \textbf{Local anomalies synthesis}. \textbf{Full-image synthesis} learns abnormal data distributions and constructs the mapping from random noise to abnormal samples. \textbf{Full-image translation} uses domain translation techniques to map normal images to abnormal ones, injecting anomalies while preserving the global structure. \textbf{Local anomalies synthesis} replaces specific regions of normal images with learned local anomalies and ensures smooth transitions between abnormal areas and the background.}
%近年来，深度生成模型（如 GANs 和扩散模型）的发展使得数据驱动的异常合成成为可能，为异常检测提供了更具多样性和真实感的训练数据。基于此范式的方法可以进一步划分为全图合成、全图翻译和局部修复三类。其中，全图合成方法直接从随机噪声中生成完整的异常样本，通过训练生成式模型学习异常数据分布，以独立于正常图像的方式合成全新的异常数据。全图翻译方法依赖于域转换技术，通过学习正常图像与异常图像之间的映射关系，将正常图像转换为异常版本，仅在局部区域注入缺陷特征，同时保持原始图像的全局结构不变。局部修复方法则侧重于对正常图像的局部区域进行异常修改，利用局部 inpainting 或局部生成技术，在特定区域引入缺陷，同时维持异常区域与背景的自然过渡，以保证合成样本的视觉一致性和合理性。

% \wys{\noindent \textbf{Definition of VLM-based synthesis:} With the advancement of large-scale pretrained vision methods\xgy{[Pretrain Vison Methods? I think it is unsuitable for pre-trained vision]}, this approach has demonstrated significant advantages in anomaly synthesis by leveraging pretrained knowledge for high-quality synthetic abnormal samples. \textbf{Single-stage synthesis} model directly employs pretrained methods for anomaly synthesis without requiring additional training, utilizing prompt engineering or lightweight fine-tuning for computationally efficient anomaly synthesis, making it suitable for resource-constrained scenarios. \textbf{Multi-stage synthesis} model adopts a multi-step optimization strategy to enhance synthesis quality, such as first generating global structures followed by refining local details, or integrating anomaly synthesis with mask synthesis and other multi-process optimization techniques to improve the authenticity and contextual consistency of synthetic anomalies.}
  
\wys{\noindent \textbf{Definition of VLM-based Synthesis:} Leveraging large-scale pre-trained VLMs with billions of parameters,  VLM-based synthesis exploits extensive pre-trained knowledge and integrated multimodal cues to synthesize high-quality anomalies. Single-stage synthesis directly produces realistic, context-aware, and \xgy{detailed abnormal samples}.  It applies prompt engineering or lightweight fine-tuning for computationally efficient anomaly synthesis. In contrast, multi-stage synthesis employs a complete pipeline that refines both global and local features—integrating synthetic abnormal data with mask synthesis or other multi-process optimization techniques—to enhance realism, diversity, and downstream task alignment.}

%随着大规模预训练视觉模型的应用发展，该类方法在异常生成领域展现出显著优势，能够利用预训练知识实现高质量的异常样本合成。单阶段生成方法通过直接调用预训练大模型，在无需额外训练的情况下利用提示工程（Prompt Engineering）或轻量微调，实现计算高效的异常生成，适用于计算资源受限的场景。多阶段生成方法则通过多步优化策略提升生成质量，例如，先生成全局结构，再细化局部细节，或结合异常生成与掩码生成等多流程优化策略，以增强异常样本的真实性和上下文一致性。

% \wys{\noindent \textbf{Distinctions:}The four industrial anomaly generation methods share the common goal of alleviating data scarcity and improving detection performance but differ significantly in generation mechanisms, applicability, and computational requirements.

% First, these methods vary in their fundamental anomaly generation principles. Hand-crafted methods rely on manually designed transformations such as cropping, rearrangement, or masking to simulate defects. Distribution hypothesis-based methods model the distribution of normal data and generate anomalies by controlled perturbations. GM-based methods employ GANs or diffusion methods to learn anomaly patterns and generate realistic abnormal samples. VM-based methods leverage pretrained large-scale vision methods, often incorporating multimodal inputs for context-aware anomaly generation.

% Second, they exhibit different trade-offs in applicability and generative quality. Hand-crafted methods are simple and computationally efficient but lack diversity. Distribution hypothesis-based methods require only normal samples, making them well-suited for scenarios with limited labeled data, but their generated anomalies are less visually intuitive. GM-based methods excel at producing highly realistic and diverse anomalies but suffer from training instability and high computational costs. VM-based methods offer superior generalization and the ability to synthesize highly realistic anomalies but require extensive computational resources and large-scale datasets.

% Third, these methods differ in their dependency on data and computational resources. Hand-crafted methods require the least computational power and no training. Distribution hypothesis-based methods rely heavily on high-quality normal samples for statistical modeling. GM-based methods require large amounts of abnormal data and significant computational resources. VM-based methods demand the most substantial hardware resources, typically requiring high-performance GPU clusters for inference and fine-tuning.}
% %区别（Distinctions）：
% % 四种工业异常生成方法旨在缓解数据稀缺问题并提升检测性能，但在生成机制、适用性和计算需求上存在显著差异。
% % 第一点： 手工设计模型依赖人工设定的变换，如裁剪、重组或掩码遮挡，以直接模拟缺陷；基于分布假设的方法对正常数据分布建模，并通过受控扰动生成异常；基于生成模型的方法利用 GANs 或扩散模型学习异常模式，合成逼真的异常样本；基于大视觉模型的方法则依赖预训练的视觉大模型，通常结合多模态输入进行上下文感知的异常生成。
% % 第二点： 手工设计模型简单高效但缺乏多样性，基于分布假设的方法仅需正常样本，适用于标注稀缺场景，但生成异常的直观性较差；基于生成模型的方法能够生成高度真实的异常，但训练不稳定，计算成本较高；基于大视觉模型的方法具备更强的泛化能力，可生成高度逼真的异常样本，但对计算资源和数据规模要求更高。
% % 第三点： 手工设计模型计算需求最低，无需训练；基于分布假设的方法对高质量正常样本依赖较强；基于生成模型的方法需要大量异常数据和较高计算资源；基于大视觉模型的方法对硬件要求最高，通常需要强大的 GPU 计算能力以支持推理和微调。


\section{\ljq{Hand-crafted Synthesis}}
\label{sec:handcrafted}
% \subsection{Data Augmentation}

\begin{figure*}[h]
    \centering
    \includegraphics[width=0.97\textwidth]{difference.pdf}
    \caption{\textbf{Illustration of different IAS methods}. It categorizes IAS methods into four main approaches: (a) Hand-crafted synthesis, which relies on pre-defined textures such as external-dependent synthesis, self-contained synthesis, and inpainting-based synthesis. (b) Distribution hypothesis-based synthesis, which synthesizes anomalies by perturbing learned feature distributions of normal data through prior-dependent or data-driven synthesis. (c) Generative models (GM)-based synthesis, which employs generative models to perform full-image generation, full-image translation, or local anomaly synthesis. (d) Vision-language models (VLM)-based synthesis, which integrates textual features into a single-stage or multi-stage synthesis process.
}
    \label{fig:dif}

\end{figure*}
% \noindent \xxc{\textbf{Self-contained methods}} are a widely utilized subcategory of Hand-Engineered Models, designed to increase the diversity of training datasets through simple yet effective transformations. Traditional techniques such as rotation, scaling, flipping, cropping, and noise addition expand the dataset by introducing global variations in imaging conditions, thereby improving the robustness of anomaly detection methods. However, these approaches primarily focus on global transformations, often lacking the capacity to simulate localized or complex defect patterns, which limits their applicability to scenarios requiring high-fidelity anomaly generation. Consequently, Data Augmentation is most effective in tasks where the primary goal is to enhance model generalization without emphasizing the realism or diversity of defect representations.
\xxc{
\noindent  \textbf{Self-contained synthesis} is a vital subset of hand-crafted synthesis. It operates by directly manipulating image regions, such as cropping, rearranging, or perturbing portions of the image, to synthesize new anomalies derived entirely from the original image. For instance, ~\citeauthor{li2021cutpaste} and ~\citeauthor{schluter2022natural} propose randomly cropping rectangular patches and pasting them back into normal images. Additionally, ~\citeauthor{lyu2024reb} use Bézier curves to define the shape of anomalies, and CutPaste-based augmentation is employed to synthesize abnormal regions with the guidance of a saliency model. Moreover, ~\citeauthor{pei2023self} extract patches from the same object, apply diverse augmentations (\textit{e.g.}, geometric transformations, color distortions), and paste them back onto the object using a mask-guided strategy, enhancing downstream anomaly detection performance.


\noindent  \textbf{Strengths and Weaknesses.} Self-contained synthesis offers a straightforward and cost-efficient approach by generating anomalies solely from the content of the original images. By directly manipulating regions within an image—such as cropping or rearranging—it maintains the original structural and textural context, thereby enhancing the model’s sensitivity to nuanced anomalies. However, since the anomalies derive exclusively from existing image features, the range and complexity of anomalies that it can simulate are inherently limited, which can result in a reduced ability to capture the full spectrum of real-world anomaly variations, potentially affecting the performance of downstream models when faced with more complex or diverse anomalies.


% \noindent \xxc{\textbf{Self-contained synthesis} constitutes a widely utilized subset of hand-crafted augmentation that produces anomalies exclusively from the content of the source images, without requiring external data or learned-based algorithms. It typically involves direct manipulations, such as cropping, rearranging, or perturbing portions of the image, to synthesize new anomalies (e.g. texture misalignment or color distortion) derived entirely from the source image. While this straightforward approach can effectively increase the number of training datasets and enhance the robustness of downstream models, its capacity to simulate highly localized or complex defect patterns is limited. Therefore, self-contained methods are most suitable for scenarios where the primary objective is to improve the model's generalization with little data. Recent advances in Self-contained synthesis for IAS have been considered universal and proven solutions. ~\citeauthor{yoa2021self} introduced dynamic local augmentation, such as modifications in color or rotation for specific regions. This approach effectively simulates potential industrial defects while preserving much of the original image structure, thereby enhancing the model’s sensitivity to subtle anomalies. Meanwhile, ~\citeauthor{li2021cutpaste} proposed a method in which rectangular patches are randomly cropped and pasted into normal samples. It preserves much of the original image structure, thus improving the model's sensitivity to subtle anomalies, ~\citeauthor{fan2024fegan} designs the multiscale self-enhancement, allowing the variations in the dimensions of the copying region, including both length and width
% Other works [~\citeauthor{lyu2024reb}, and ~\citeauthor{pei2023self}] have also further explored how strategic manipulations of image content can simulate diverse anomaly patterns. And ~\citeauthor{leyendecker2023study} subdivides the impact of different self-contained methods on downstream tasks. Collectively, these studies illustrate how to synthesize anomalies at a lower cost and reduce reliance on large-scale labeled abnormal data [~\citeauthor{zhang2022anomaly}, ~\citeauthor{schluter2022natural}].}

% Recent advancements in Data Augmentation have extended its utility in industrial anomaly generation by incorporating more targeted strategies. Yoa et al. (2021) ~\citeauthor{yoa2021self} introduced dynamic local augmentation, where localized perturbations, such as changes in color, contrast, or rotation in specific image regions, are applied to simulate potential industrial defects. This approach not only strengthens the model’s ability to learn normal features but also enhances its sensitivity to detecting subtle anomalies. Similarly, Jin et al. (2024) ~\citeauthor{jin2024cutout} employed Cutout augmentation to detect burn marks in plastic granules. By randomly masking rectangular regions of the image, this method mimics defect distributions and encourages models to learn robust, discriminative features. These studies demonstrate the adaptability of Data Augmentation in addressing specific industrial challenges, particularly in resource-constrained environments requiring synthetic abnormal data to improve model performance.

% 数据增强： 数据增强是手工设计模型中的一个广泛应用的子类别，旨在通过简单但有效的变换增加训练数据集的多样性。传统技术如旋转、缩放、翻转、裁剪和添加噪声等，通过引入成像条件的全局变化来扩展数据集，从而提高异常检测模型的鲁棒性。然而，这些方法主要关注全局变换，往往缺乏模拟局部或复杂缺陷模式的能力，这限制了其在需要高保真异常生成的场景中的适用性。因此，数据增强在主要目标是提升模型泛化能力而非强调缺陷表示的真实感或多样性的任务中最为有效。

% 近年来，数据增强技术在工业异常生成中的应用被进一步拓展，加入了更具针对性的策略。Yoa等人（2021）提出了动态局部增强技术，通过在特定图像区域内施加局部扰动（如颜色、对比度或旋转的变化）来模拟潜在工业缺陷。这种方法不仅加强了模型学习正常特征的能力，还提高了其检测微小异常的敏感性。同样，Jin等人（2024）采用了Cutout增强技术，用于检测塑料颗粒中的烧痕。通过随机遮挡图像的矩形区域，这种方法模拟了缺陷分布，并促使模型学习鲁棒的判别特征。这些研究表明，数据增强在应对特定工业挑战方面的适应性，尤其是在资源受限的环境中需要合成异常数据以提升模型性能时。

% \subsection{Texture Replacement}
% \noindent \textbf{Texture Replacement} is a widely used approach within Hand-Engineered Models, aimed at simulating industrial defects by replacing parts of an image with artificial patterns. This method generates anomalies by substituting specific regions with synthetic textures such as scratches, stains, or noise, creating defect-like features that align with real-world scenarios. While effective in producing targeted anomalies without the need for real defective samples, traditional Texture Replacement methods often face challenges in achieving seamless blending and replicating the structural complexity of actual defects, limiting their applicability in tasks that require high realism.


\noindent \textbf{External-dependent synthesis} is an approach that synthesizes anomalies by incorporating textures from external data, such as texture libraries. Unlike self-contained methods, it overlays or blends external areas onto an otherwise anomaly-free image. For example, ~\citeauthor{zavrtanik2021draem} and ~\citeauthor{zhang2023destseg} use Perlin noise to generate binary anomaly masks, enabling the combination of clean backgrounds with external textures to produce abnormal samples. Similarly, ~\citeauthor{yang2023memseg} refine the process by restricting the location of anomalies to the foreground, which further bridges the gap between synthetic and real anomalies.

\noindent \textbf{Strengths and Weaknesses.} External-dependent synthesis can produce a wider variety of anomaly patterns by leveraging external data. It allows the generation of anomalies with distinct distributions that may be challenging to replicate using only intrinsic image content, thus potentially improving the robustness of detection models. However, integrating external textures seamlessly with the original content can be difficult, often resulting in inconsistencies or visual artifacts, particularly when high-fidelity anomaly synthesis is crucial.


% \xxc{\noindent \textbf{External-dependent synthesis} usually synthesizes anomalies by incorporating additional textures from other data sources, such as texture libraries or predefined templates. These methods introduce anomaly-like features into an image by overlaying or blending externally provided patterns and textures that bear no direct relation to the source image content. While external-dependent methods enable more diverse anomalies with distinct distributions compared to self-contained methods, they often face challenges in seamless integration, particularly in applications requiring high-fidelity anomaly synthesis. 
% ~\citeauthor{zavrtanik2021draem} and ~\citeauthor{zhang2023destseg} leveraged thresholded Perlin noise to generate binary anomaly masks, facilitating the synthesis of abnormal samples by combining an anomaly-free background with external textures. ~\citeauthor{yang2023memseg} further refined this approach by constraining the abnormal regions to the foreground, reducing the gap between synthesic and real anomalies. These advancements highlight the evolution of external-dependent methods towards enhanced realism and adaptability in IAS.}

% \xxc{\noindent \textbf{Inpainting-based synthesis} is a distinct category within hand-crafted augmentation that synthesize anomalies by purely selectively masking regions of the source image, disrupting the visual continuity of the image [~\citeauthor{jin2024cutout}, ~\citeauthor{li2020superpixel},~\citeauthor{pirnay2022inpainting}. They do not rely on internal content manipulation or external data sources. Common techniques include blacking out regions, filling masked areas with noise, and effectively simulating missing or occluded content.  Inpainting-based approaches usually transition an image from a complete state to an incomplete one, making them particularly suited for the reconstruction-based anomaly detection task. ~\citeauthor{nakanishi2021iterative} and ~\citeauthor{zavrtanik2021reconstruction} both generate abnormal samples by masking random regions of the source image and reconstructing the masked areas using background information. In contrast, ~\citeauthor{luo2024ami} introduces a specialized adaptive mask generator, which adaptively conceals defect regions while preserving the normal background, ensuring a more structured and context-aware IAS.}

\noindent \textbf{Inpainting-based synthesis} is a specialized category within hand-crafted synthesis that synthesizes anomalies by selectively masking regions of the original image, disrupting its visual continuity [\citeauthor{pirnay2022inpainting}]. Unlike methods that paste self-contained content or incorporate external textures, inpainting-based synthesis focuses on introducing missing or occluded areas, often by blacking out regions or filling them with noise. This transformation from a complete to an incomplete image is particularly effective in downstream reconstruction-based anomaly detection. For instance, ~\citeauthor{nakanishi2021iterative}, ~\citeauthor{zavrtanik2021reconstruction}, and \citeauthor{li2020superpixel} synthesize abnormal samples by masking random regions and then reconstructing them using background information. In contrast, ~\citeauthor{luo2024ami} develop an adaptive mask generator that selectively conceals abnormal regions while preserving the surrounding normal background, resulting in a more structured and context-aware synthesis. Additionally, \citeauthor{cao2023collaborative} and \citeauthor{tien2023revisiting} introduce random noise within the masked regions.

\noindent \textbf{Strengths and Weaknesses.} Inpainting-based synthesis is a straightforward approach that involves replacing some areas of an image with black patches or noise to simulate anomalies. It effectively evaluates the performance of reconstruction-based detection models. However, the generated anomalies tend to be overly simplistic and may lack the complexity and subtle nuances characteristic of real-world anomalies.
}



% Recent advancements have significantly enhanced the scope and capability of Texture Replacement. Zavrtanik et al. (2021) ~\citeauthor{zavrtanik2021draem} utilized open-source texture datasets like the Describable Textures Dataset to generate patches with randomized shapes, colors, and brightness, followed by blending strategies to ensure smooth integration into the image background. Meanwhile, Li et al. (2021) ~\citeauthor{li2021cutpaste} introduced the CutPaste method, which involves extracting random patches from normal images and placing them in different positions. This approach effectively creates anomalies with distinct edges and texture inconsistencies, offering a simple yet powerful way to simulate unexpected industrial defects. Zhang et al. (2022) ~\citeauthor{zhang2022anomaly} expanded on these ideas by combining random cropping and repositioning of rectangular image regions with transformations such as scaling, rotation, and color jittering. This method introduced additional irregularities to the image content, making it particularly effective for coarse approximations of real industrial defects.

% Yang et al. (2023) ~\citeauthor{yang2023memseg} and Zhang et al. (2023) ~\citeauthor{zhang2023destseg} explored techniques that leverage Perlin noise to enhance anomaly generation. Yang’s method combined noise-based masks with inpainting to produce highly realistic textures, whereas Zhang extended this by using thresholded Perlin noise to create binary anomaly masks, blending normal and external textures with adjustable transparency to control the intensity of the anomalies. These approaches highlight how procedural noise and advanced blending techniques can elevate the realism and flexibility of Texture Replacement methods.

% Lyu et al. (2024) ~\citeauthor{lyu2024reb} and Pei et al. (2023) ~\citeauthor{pei2023self} pushed the boundaries of Texture Replacement by introducing more structured and adaptive workflows. Lyu’s method incorporated Bézier curve-based defect shapes and explored both direct pasting and weighted blending to simulate anomalies ranging from sharp-edged defects to seamlessly integrated textures. Pei developed a patch-based pipeline that preprocesses images to extract object patches, which are then transformed and integrated with enhanced blending techniques to ensure compatibility with complex industrial backgrounds.

% These advancements collectively underscore the evolution of Texture Replacement from simple patch substitution to sophisticated workflows involving procedural noise, blending techniques, and structured patch integration. By combining external texture datasets, noise generation, and adaptive blending, modern methods have broadened the applicability of Texture Replacement, allowing it to address diverse industrial anomaly generation needs, from simulating minor surface defects to creating highly realistic and complex anomalies.

% 纹理替换： 纹理替换是手工设计模型中的一种常用方法，旨在通过用人工图案替换图像的一部分来模拟工业缺陷。此方法通过将图像的特定区域替换为合成纹理（如划痕、污渍或噪声）来生成异常，从而创建与实际场景相符的缺陷特征。虽然在无需真实缺陷样本的情况下能有效生成有针对性的异常，但传统的纹理替换方法在实现无缝融合和复制实际缺陷的结构复杂性方面往往面临挑战，限制了其在需要高真实感任务中的适用性。

% 近年来，纹理替换技术的范围和能力得到了显著提升。Zavrtanik等人（2021）利用可描述纹理数据集（Describable Textures Dataset），生成具有随机形状、颜色和亮度的纹理块，并通过融合策略确保与图像背景的平滑集成。Li等人（2021）提出了CutPaste方法，该方法从正常图像中提取随机区域并将其放置到不同位置。这种方法通过生成具有明显边缘和纹理不一致的异常，提供了一种简单但强大的方式来模拟意料之外的工业缺陷。Zhang等人（2022）在此基础上结合了随机裁剪和重新定位矩形图像区域，同时使用缩放、旋转和颜色抖动等变换，使图像内容引入额外的不规则性，对实际工业缺陷的粗略模拟特别有效。

% Yang等人（2023）和Zhang等人（2023）探索了利用Perlin噪声增强异常生成的技术。Yang的方法将基于噪声的遮罩与图像修复结合，以生成高度逼真的纹理；Zhang则通过使用阈值化的Perlin噪声生成二值异常遮罩，并结合正常纹理和外部纹理，通过调整透明度来控制异常的强度。这些方法展示了程序化噪声和高级融合技术如何提高纹理替换方法的真实感和灵活性。

% Lyu等人（2024）和Pei等人（2023）在纹理替换的边界上进行了更为结构化和自适应的改进。Lyu的方法结合了基于贝塞尔曲线的缺陷形状，探索了直接粘贴与加权融合，以模拟从锐边缺陷到无缝集成纹理的多种异常。Pei开发了一种基于区域的流程，通过提取图像中的目标区域，并对其进行变换和增强融合，确保与复杂工业背景的兼容性。

% 这些进展共同表明了纹理替换从简单区域替换到复杂流程的演化，包括程序化噪声、融合技术和结构化区域整合。通过结合外部纹理数据集、噪声生成和自适应融合，现代方法拓宽了纹理替换的适用性，能够满足从模拟轻微表面缺陷到创建高度逼真复杂异常的多样化工业需求。
\section{Distribution hypothesis-based Synthesis}
\label{sec:distribution}
\noindent \xxc{\textbf{Prior-dependent synthesis} is a core approach in Distribution hypothesis-based syhthesis that leverages a geometric prior. It assumes that the latent space of normal data maps within a defined region, typically a manifold or hypersphere, while anomalies fall outside this boundary. By modeling the normal feature distribution and applying controlled perturbations, synthesized anomalies are at or beyond these borders, effectively simulating real anomaly features and improving the preformance of downstream task. For instance, \citeauthor{chen2025unified} constrain normal features within a compact space and guide synthesis via gradient ascent and truncated projection for enhanced diversity. Similarly, \citeauthor{chen2024progressive} generate anomalies radially to refine decision boundaries, while \citeauthor{shin2023anomaly} utilize the manifold hypothesis and Gaussian annulus to perturb features and compute restoration errors for localization. In addition, \citeauthor{naud2020manifolds} embed normal data in non-Euclidean spaces and perturb along geodesic paths to synthesize anomalies.}

\noindent \xxc{\textbf{Strengths and Weaknesses.} Prior-dependent synthesis leverages latent assumptions from normal samples to enable controlled perturbations, enhancing downstream tasks like classification or detection. Modeling normal data within a defined latent space (e.g., a manifold or hypersphere) facilitates these perturbations. However, as most methods synthesize anomalies at the feature level, they lack spatial details for precise anomaly segmentation. Moreover, reliance on a predefined latent distribution can limit the ability to capture complex spatial anomalies, reducing broader applicability.}


% \xxc{\textbf{Prior-dependent synthesis} is a core approach within Distribution Hypothesis-Based Models that relies on a geometric prior. This method posits that the features of normal data is confined within a specific region of the feature space—typically modeled as a manifold or hypersphere—while features of anomalies are found outside these strict boundaries. Leveraging this prior assumption, the method explicitly delineates the distribution of normal samples and employs controlled perturbations to generate synthetic anomalies located at or beyond the defined borders. This strategy not only simulates edge-case scenarios but also enhances the model's ability to effectively distinguish between normal and abnormal patterns.~\citeauthor{chen2025unified} model the normal features and constrain them within a compact space (manifold or hypersphere), guiding the direction of feature-level synthesis via gradient ascent and truncated projection for better diversity. ~\citeauthor{chen2024progressive} leverages the hypersphere assumption to model normal features compactly in the feature space and synthesizes anomalies along the radial direction, progressively refining the decision boundary to enhance separability and generalization of anomalies. ~\citeauthor{shin2023anomaly} exploits the manifold hypothesis and Gaussian annulus phenomenon to implicitly model anomalies by applying perturbations and utilizing score-based restoration error, providing a prior-driven approach to ASs for detection and localization. ~\citeauthor{naud2020manifolds} embeds normal data in a non-Euclidean space and synthesizes anomalies by perturbing samples along geodesic paths or extrapolating beyond the manifold boundary while preserving data structure.
% }

% \noindent \textbf{Prior-dependent} method is a core method within Distribution Hypothesis-Based Models, which assumes that normal data resides within a specific manifold or hypersphere in the feature space, while anomalies exist outside this boundary. By introducing controlled perturbations to normal data points, this method generates synthetic anomalies that lie near or beyond the edges of the manifold. These synthetic samples are designed to simulate edge cases, enhancing the detection model’s ability to distinguish normal and abnormal patterns.

% Despite its data-driven nature and geometric grounding, this method faces challenges in complex industrial scenarios where defect distributions often overlap or exhibit mixed characteristics. The strict assumptions about the manifold’s shape and structure can limit its applicability in cases where the normal data distribution is highly irregular. Consequently, the Manifold/Hypersphere Hypothesis is best suited for scenarios with well-defined normal data distributions and tasks focusing on boundary-case anomaly detection.
% 流形/超球体假设
% 流形/超球体假设： 流形/超球体假设是基于分布假设的模型中的核心方法之一，该方法假设正常数据位于特征空间中的某个特定流形或超球体内，而异常数据存在于此边界之外。通过对正常数据点进行有控制的扰动，该方法生成位于流形边缘或之外的合成异常样本。这些合成样本旨在模拟边界情况，从而增强检测模型区分正常和异常模式的能力。

% 尽管该方法具有数据驱动的特点并基于几何理论，但在复杂的工业场景中仍面临挑战，因为缺陷分布通常具有重叠或混合特性。对于流形形状和结构的严格假设会限制其在正常数据分布高度不规则的场景中的适用性。因此，流形/超球体假设最适合于正常数据分布明确的场景以及聚焦于边界异常检测的任务。

\noindent \xxc{\textbf{Data-driven synthesis} is an effective approach within Distribution Hypothesis-Based Models that synthesizes anomalies by directly manipulating latent representations of normal data. Instead of relying on explicit prior assumptions, this method extracts latent features using models like autoencoders and then introduces controlled perturbations, such as Gaussian noise or other data-adaptive constraints, to synthesize anomalies. This flexible strategy leverages the intrinsic statistical properties of the data, producing anomalies that closely mirror distributions of abnormal features. Recent advancements explore diverse approaches to enhance the flexibility and realism of data-driven synthesis. ~\citeauthor{liu2023simplenet} and ~\citeauthor{you2022unified} introduce SimpleNet and UniAD, which synthesize anomalies directly at the feature level by adding noise to extracted features to simulate abnormal features. The perturbed and original features in SimpleNet are then evaluated by a discriminator to ensure that the synthetic anomalies are distinct yet plausible. Building upon this, ~\citeauthor{rolih2025supersimplenet} propose SuperSimpleNet, which confines the noise to specific regions and employs a new segmentation head, offering a more targeted anomaly synthesis strategy. Additionally, ~\citeauthor{zavrtanik2022dsr} develop DSR, a dual subspace re-projection network that trains a codebook and replaces the contents of masked regions in normal features by sampling from this codebook to synthesize abnormal features.}

\noindent \xxc{\textbf{Strengths and Weaknesses.} Data-driven synthesis methods avoid explicit distribution assumptions by directly learning latent representations of normal samples. By mapping normal data in latent space via neural networks and applying perturbations, it synthesizes diverse anomaly features resembling those in the real world. However, its effectiveness relies on the quality of the latent space, since poorly trained models may produce unrealistic anomalies. Additionally, without accurately estimating the normal distribution, the generated anomalies may lead to suboptimal decision boundaries.}

% \noindent \textbf{Data-driven} method is a prominent method within Distribution Hypothesis-Based Models, focusing on altering the latent representations of normal data to generate synthetic anomalies. This method leverages feature spaces learned by models such as autoencoders or variational autoencoders (VAEs) to identify normal data clusters and introduce controlled deviations. By perturbing specific latent dimensions, it produces anomalies that deviate from the normal data distribution while maintaining coherence with the overall structure of the dataset.

% Recent advancements have explored diverse approaches to enhance the flexibility and realism of Latent Feature Manipulation. \ljq{SimpleNet} Liu et al. (2023) ~\citeauthor{liu2023simplenet} proposed a pipeline where anomalies are generated directly in the latent feature space by applying simple noise perturbations to features extracted from normal samples. The perturbed features undergo domain transformations and are evaluated by a discriminator, ensuring the generated anomalies are distinct yet plausible. Similarly, Rolih et al. (2024) ~\citeauthor{rolih2025supersimplenet} introduced a unified framework combining unsupervised and supervised strategies. By introducing latent perturbations and coupling segmentation and classification heads in the loss function, their method achieves improved adaptability and performance across tasks, allowing upstream feature adjustments based on downstream objectives.

% \ljq{DSR} Zavrtanik et al. (2022) ~\citeauthor{zavrtanik2022dsr} extended latent space manipulation by proposing a dual subspace re-projection network with a single encoder and multiple decoders. Each decoder is tailored to emphasize different aspects of object appearance, such as object-specific or general characteristics. This approach enables the selective replacement of masked regions at the feature level, offering a more targeted anomaly synthesis strategy. In another study, Yao et al. (2025) ~\citeauthor{yao2025glad} addressed the limitations of Gaussian assumptions in latent anomaly modeling. They identified that anomalies often deviate from Gaussian priors, proposing a global and local adaptive diffusion framework to constrain these deviations and better align generated anomalies with real-world distributions.

% The strength of Latent Feature Manipulation lies in its ability to generate diverse and realistic anomalies without requiring explicit assumptions about the input data. Techniques such as dual-decoder architectures and adaptive priors further enhance its precision and applicability. However, the success of these methods heavily relies on the quality of learned latent representations. Poorly trained feature spaces can lead to unrealistic or uninformative anomalies, limiting the method’s effectiveness. Consequently, Latent Feature Manipulation is particularly suited for tasks that require tailored and complex defect patterns, provided high-quality training data and careful model tuning are available.
% 潜特征操作： 潜特征操作是基于分布假设的模型中的一个重要方法，重点在于通过改变正常数据的潜在表示来生成合成异常样本。该方法利用自动编码器（autoencoders）或变分自动编码器（VAEs）等模型学习的特征空间来识别正常数据的聚类，并引入控制偏差。在特定潜在维度上进行扰动，生成偏离正常数据分布但仍保持数据集整体结构一致性的异常。

% 近年来，多种方法被提出以提高潜特征操作的灵活性和真实性。Liu等人（2023）提出了一种管道，在潜特征空间直接生成异常，通过对从正常样本提取的特征进行简单噪声扰动。这些扰动的特征经过域转换，并由判别器进行评估，以确保生成的异常既独特又具有合理性。同样，Rolih等人（2024）提出了一种结合无监督和有监督策略的统一框架，通过潜在扰动和将分割与分类头结合在损失函数中，实现了任务间的适应性和性能提升。

% Zavrtanik等人（2022）扩展了潜空间操作，提出了一种双子空间重新投影网络，包含单一编码器和多个解码器。每个解码器专注于对象外观的不同方面，例如对象特定特征或一般特征。该方法使得在特征级别选择性地替换被遮挡区域成为可能，提供了一种更具针对性的异常生成策略。另一项研究中，Yao等人（2025）解决了高斯假设在潜异常建模中的局限性，提出了一种全局和局部自适应扩散框架，用于约束这些偏差，更好地将生成的异常与真实分布对齐。

% 潜特征操作的优势在于无需对输入数据进行显式假设即可生成多样化和真实的异常样本。双解码器架构和自适应先验等技术进一步增强了其精度和适用性。然而，这些方法的成功在很大程度上依赖于学习到的潜在表示的质量。如果特征空间训练不足，可能会生成不真实或无信息的异常，限制方法的有效性。因此，潜特征操作尤其适合需要定制和复杂缺陷模式的任务，前提是具有高质量的训练数据和精心调整的模型。
\section{GM-based Synthesis}
\label{sec:generation}
% \subsection{Generation} 
% \noindent \textbf{Generation} is a foundational method within Generative Models-Based (GMs-Based) Models, widely utilized for directly synthesizing industrial anomalies. By leveraging frameworks such as Generative Adversarial Networks (GANs), these methods train a generator to approximate the distribution of real defects, enabling the creation of high-quality abnormal samples that closely resemble actual defects. These generated samples can be tailored to specific defect types, providing a valuable resource for training anomaly detection systems.
\xxc{
\noindent \textbf{Full-image synthesis} is a fundamental approach within GMs-Based Models, extensively employed for directly synthesizing industrial anomalies. It utilizes GM such as GAN and diffusion models to construct a unique mapping that transforms Gaussian noise into abnormal samples, effectively approximating the distribution of real anomalies. By training distinct models for different types of anomalies, it becomes possible to generate a wide variety of high-quality data that closely to actual anomalies. ~\citeauthor{liu2019multistage} establish multistage GANs that decouple texture generation and background-anomaly fusion, effectively modeling both abnormal areas and contextual coherence. To address data scarcity, ~\citeauthor{du2022new} develop Con-GAN, featuring shared data augmentation and hypersphere-based loss, it simultaneously prevent overfitting and enhance anomaly diversity. ~\citeauthor{duan2023few} also propose a two-stage GAN, namely DFMGAN, which consists of two processes: initial learning on normal samples and subsequent fine-tuning using abnormal samples. For complex anomaly synthesis, ~\citeauthor{yang2025defect} innovatively combine large receptive fields for global structural modeling with patch-level refinement mechanisms, achieving synergistic integration of macro-context and micro-details.}

\noindent \xxc{\textbf{Strengths and Weaknesses.} While full-image synthesis effectively enhances abnormal sample quality, its performance is highly dependent on the availability and diversity of training data. Limited abnormal samples often lead to artifacts or unrealistic defects, restricting practical applicability. Additionally, as these models generate entire images rather than directly modifying normal samples, they struggle to preserve fine-grained structural details and contextual consistency. }


% ~\citeauthor{duan2023few} developed DFMGAN, a two-stage GAN framework that first learns the distribution of normal samples and then fine-tunes the model using a few annotated abnormal samples. By introducing Defect-Aware Residual Blocks and a dual discriminator, DFMGAN achieves better control over defect generation while maintaining diversity, though alignment between masks and generated anomalies remains a challenge.

% Yang et al. (2025) ~\citeauthor{yang2025defect} introduced a two-stage diffusion approach to tackle the generation of complex defects. This method combines masks and images as inputs to the generator, utilizing large receptive fields to model global structures and patches to refine local details, achieving a balance between global context and fine-grained accuracy. Du et al. (2022) ~\citeauthor{du2022new} proposed a contrastive GAN with data augmentation to address the limitations of limited data scenarios. Their framework integrates a shared data augmentation (SDA) module to prevent overfitting, a feature attention matching (FAM) module to align features, and a hypersphere-based contrastive loss to encourage diversity in generated defects.

% Earlier works such as Liu et al. (2019) ~\citeauthor{liu2019multistage} explored multistage GAN architectures, where separate networks were used to model defect textures and background fusion. This approach enables the generation of synthetic samples that can seamlessly blend with the background, enhancing their utility for downstream segmentation tasks. The multistage process ensures that both defect texture distributions and contextual integration are accurately modeled, making it particularly effective for complex defect types.

% While these advancements have significantly improved the robustness and adaptability of GAN-based generation, challenges remain. The effectiveness of these methods heavily relies on the quality and diversity of the training data, as well as the stability of the adversarial training process. Poorly trained models may produce artifacts or unrealistic anomalies, limiting their practical utility. However, techniques like fine-tuning, feature alignment, and diffusion-based refinement offer promising solutions, enabling the application of Generation methods in scenarios with both abundant and scarce real defect datasets.

% 生成： 生成是基于生成模型（GMs-Based）中的基础方法，广泛用于直接合成工业异常。通过利用生成对抗网络（GANs）等框架，这些方法训练生成器逼近真实缺陷的分布，从而生成高度逼真的异常样本，这些样本可以根据具体的缺陷类型进行定制，为训练异常检测系统提供了宝贵的资源。

% 最近的研究引入了新颖的架构和策略，以提高基于GAN的异常生成的质量、多样性和适用性。例如，Fan等人（2024）提出了FEGAN，通过结合深度特征空间和二维图像空间增强缺陷生成和定位。利用欧几里得距离在这些空间中标识异常，同时使用基于VGG19的损失确保生成的缺陷与真实特性一致。同样，Duan等人（2023）开发了DFMGAN，这是一个两阶段GAN框架，首先学习正常样本的分布，然后通过少量标注的异常样本对模型进行微调。通过引入缺陷感知残差块和双判别器，DFMGAN在保持多样性的同时实现了更好的缺陷生成控制，尽管在遮罩与生成异常对齐方面仍存在挑战。

% Yang等人（2025）提出了一种两阶段扩散方法，用于处理复杂缺陷的生成。该方法将遮罩和图像作为生成器的输入，利用大感受野建模全局结构，同时使用图像块细化局部细节，在全局上下文与精细准确性之间实现平衡。Du等人（2022）提出了一种结合对比学习的GAN，通过数据增强解决有限数据场景的限制。其框架整合了共享数据增强（SDA）模块、防止过拟合的特征注意力匹配（FAM）模块，以及基于超球体的对比损失，以促进生成缺陷的多样性。

% 尽管这些进展显著提升了基于GAN生成方法的鲁棒性和适应性，但仍然面临挑战。这些方法的有效性在很大程度上取决于训练数据的质量和多样性，以及对抗训练过程的稳定性。如果模型训练不足，可能会产生伪影或不真实的异常，从而限制其实用性。然而，微调、特征对齐和基于扩散的改进等技术提供了有希望的解决方案，使得生成方法可以应用于真实缺陷数据充足或稀缺的场景。
% \noindent \textbf{Full image Translation} is a prominent method within Generative Models-Based (GMs-Based) Models, focusing on transforming normal images into defective counterparts using domain translation frameworks such as CycleGANs. By learning a mapping between the normal and defect domains, these methods introduce targeted changes to normal images, such as scratches, stains, or other defect-like features, seamlessly integrating them into the image to simulate realistic defects. This approach preserves the contextual integrity of the original image while generating anomalies that are highly representative of real-world defects.

\xxc{\noindent \textbf{Full-image translation} is a key approach within GM-Based Models, it synthesizes anomalies by transforming normal images via domain translation techniques like CycleGAN [\citeauthor{CycleGAN2017}] and Pix2PixGAN [\citeauthor{pix2pix}]. Full-image translation learns mappings between normal and anomaly domains, introducing targeted modifications (\textit{e.g.} scratches, stains) while preserving structural integrity. Nowadays, it is a highly effective strategy for IAS. Recent advancements significantly improve full-image translation by enhancing the fidelity and controllability of synthesized anomalies. ~\citeauthor{wen2022new} extend CycleGAN within their anomaly detection pipeline, achieving superior performance. ~\citeauthor{niu2020defect} propose SDGAN, a CycleGAN-based framework incorporating additional discriminators to refine the translation process. By focusing on modeling the distribution of abnormal samples, SDGAN enhances the realism of synthesized anomalies. Furthermore, ~\citeauthor{zhang2021defect} introduce Defect-GAN, which explicitly models both the defacement and restoration processes rather than synthesizing anomalies arbitrarily. Additionally, it leverages spatial distribution maps to preserve the appearance of normal backgrounds, ensuring structural consistency in generated images.}

\xxc{\noindent \textbf{Strengths and Weaknesses.} Full-image translation excels at generating realistic, context-aware anomalies with minimal abnormal samples and numerous normal samples. Its strength lies in seamlessly integrating anomaly into normal contexts. However, its control over anomaly types and spatial distribution is limited. The inherent property of Full-image translation makes it challenging to precisely dictate where and how anomalies appear, potentially reducing their applicability in scenarios requiring fine-grained anomaly localization.}




% Recent advancements have enhanced the Full image Translation paradigm by improving the fidelity, diversity, and controllability of generated anomalies. Niu et al. (2020) ~\citeauthor{niu2020defect} proposed SDGAN, a CycleGAN-based framework with additional discriminators to ensure higher translation quality. By leveraging a combination of a small set of defect images and a large number of normal samples, the method utilizes cycle-consistency loss to generate defect samples from normal images. This approach enhances defect realism by focusing on translating the texture and appearance of normal samples without requiring extensive defect datasets.

% Zhang et al. (2021) ~\citeauthor{zhang2021defect} introduced Defect-GAN, a framework inspired by the natural processes of damage creation and restoration. Instead of generating defects arbitrarily, this method explicitly models a damage process that creates defects on normal samples and a restoration process that reverses the damage. Defect-GAN incorporates Gaussian noise injection into feature maps at each convolutional block, with scalar weights learned to control the noise intensity. Additionally, the generator leverages an attribute-controlling map to add specific defect types at desired locations, enabling precise and diverse defect generation.

% Wen et al. (2022) ~\citeauthor{wen2022new} extended the CycleGAN framework with an attention mechanism in their model, AttenGAN, targeting scenarios with small defect datasets. The attention mechanism facilitates better localization of defect regions during the translation process, improving the quality and relevance of generated anomalies for downstream tasks such as defect classification and detection.

% These advancements underline the versatility of the Translation approach in producing highly realistic and context-aware anomalies, particularly when the generated defects must align with industrial requirements. However, these methods rely heavily on the accurate mapping between normal and defect domains, requiring sufficient training data and careful tuning of domain translation parameters. When these requirements are met, Translation serves as a powerful tool for generating high-fidelity defects while maintaining contextual consistency, making it invaluable for industrial anomaly detection systems.
% 转换： 转换是基于生成模型（GMs-Based）中的一种重要方法，旨在通过域转换框架（如CycleGANs）将正常图像转化为具有缺陷的对应图像。通过学习正常域和缺陷域之间的映射，这些方法对正常图像进行有针对性的改变，例如添加划痕、污渍或其他缺陷特征，并将其无缝集成到图像中，从而模拟出真实的缺陷。此方法在生成高度代表真实世界缺陷的异常的同时，保留了原始图像的上下文完整性。

%% 近年来，转换方法通过提高生成异常的逼真度、多样性和可控性得到了进一步发展。Niu等人（2020）提出了SDGAN，这是一种基于CycleGAN的框架，附加了额外的判别器以确保更高的转换质量。通过结合少量缺陷图像和大量正常样本，该方法利用循环一致性损失（cycle-consistency loss）从正常图像生成缺陷样本。该方法通过专注于正常样本纹理和外观的转换，在无需大量缺陷数据集的情况下提升了缺陷的真实感。

% Zhang等人（2021）提出了Defect-GAN，这一框架受到损伤生成和修复自然过程的启发。与任意生成缺陷不同，该方法显式建模了一个生成缺陷的损伤过程以及一个逆转损伤的修复过程。Defect-GAN在每个卷积块中向特征图中注入高斯噪声，并学习标量权重以控制噪声强度。此外，生成器利用属性控制图（attribute-controlling map）在指定位置添加特定类型的缺陷，从而实现精确和多样化的缺陷生成。

% Wen等人（2022）扩展了CycleGAN框架，提出了一种结合注意力机制的模型AttenGAN，专注于小型缺陷数据集的场景。注意力机制在转换过程中有助于更好地定位缺陷区域，从而提高生成异常在缺陷分类和检测等下游任务中的质量和相关性。

% 这些进展表明，转换方法在生成高度逼真且具备上下文感知的异常方面具有很强的适应性，尤其是在生成缺陷需要符合工业要求时。然而，这些方法高度依赖正常域和缺陷域之间的精确映射，需要充分的训练数据和精心调整的参数设置。如果这些要求得到满足，转换方法能够作为生成高保真缺陷的强大工具，对于工业异常检测系统具有重要价值。


% \subsection{Local anomaly synthesis}

\xxc{\noindent \textbf{Local anomaly synthesis} is a targeted approach within GMs-Based Models, designed to generate localized anomalies by selectively modifying specific regions of an image. Local anomaly synthesis typically involves removing parts of the image through annotations and employing generative models to synthesize anomaly-like textures within the masked regions. By focusing on localized transformations, it enables the creation of controlled and diverse anomaly patterns, such as scratches, holes, or surface irregularities, which closely resemble real-world anomalies. Recent advancements enhance local anomaly synthesis by aligning the mask with synthesized abnormal regions and improving spatial consistency between synthetic defects and their surrounding contexts. ~\citeauthor{zhang2024realnet} enhance the synthesis of realistic anomalies by amplifying their divergence from normal patterns. Their proposed RealNet perturbs the variance of denoising diffusion during reverse diffusion to synthesize a global anomaly map. ~\citeauthor{wei2022mask} construct pseudo-normal backgrounds in abnormal regions to emphasize the distribution of anomalies. ~\citeauthor{wei2023diversified} develop DCDGAN, which trains a model on anomaly-only textures and blends them with different backgrounds, achieving multi-class and diversified anomaly synthesis.}

\xxc{\noindent \textbf{Strengths and Weaknesses.} Local anomaly synthesis excels at synthesizing controlled abnormal samples, making it suitable for targeted anomaly synthesis. Restricting anomalies to specific regions addresses the impact of synthetic backgrounds on downstream tasks, which is a common issue in GM-based approaches. However, it struggles to maintain texture-background coherence.  Additionally, it depends on mask annotations to define abnormal regions, which makes acquiring high-quality annotations costly and labor-intensive, limiting scalability in large-scale industrial applications.}

% Local AS excels at producing controlled and localized abnormal samples, making it a versatile method for applications requiring targeted anomaly simulation


% Recent research has introduced innovative approaches to refine inpainting for industrial anomaly synthesis. Lugmayr et al. (2022) ~\citeauthor{Lugmayr2022} pioneered the use of denoising diffusion probabilistic models (DDPMs) for inpainting, leveraging forward and reverse processes to iteratively generate noise and reconstruct masked regions. This approach allows for a high degree of control over the inpainting process, though it was not specifically designed for industrial applications. Building on the concept of reverse diffusion, Zhang et al. (2024) ~\citeauthor{Zhang2024} introduced RealNet, which perturbs variance during reverse diffusion to ensure that anomalies are sampled from low-density regions of the normal image distribution. This method enhances the synthesis of realistic anomalies by amplifying their divergence from normal patterns while preserving the overall image structure.

% Wei et al. (2022) ~\citeauthor{wei2022mask} proposed a mask-guided synthesis framework for industrial defect images, incorporating a Background Replacement Module (BRM) to retain normal background content while selectively replacing defect regions. This approach allows precise control over the shape and texture of defects and incorporates a Dual Discriminator Module (DDM) to extract defect features and construct pseudo-normal backgrounds for training. In a subsequent work, Wei et al. (2023) ~\citeauthor{Wei2023} developed DCDGAN, which first trains a generative model on defect textures before blending these textures with backgrounds. By extracting defect-only textures using masks and combining them with either the same or different background types, DCDGAN achieves multi-class and diversified defect synthesis. However, challenges remain in achieving a strong association between generated textures and background contexts.

% Inpainting excels at producing controlled and localized defect samples, making it a versatile method for applications requiring targeted anomaly simulation. Techniques like mask-guided generation and diffusion-based synthesis significantly improve the realism and adaptability of inpainting for industrial scenarios. Nonetheless, limitations persist, including the difficulty of achieving the randomness and seamless blending typical of real-world defects, especially when inpainting models are inadequately trained. Despite these challenges, inpainting remains a popular and computationally efficient choice for generating specific defect patterns, with its advancements offering new avenues for enhancing industrial anomaly detection systems.
% 修复填充： 修复填充是基于生成模型（GMs-Based）的一种技术，专注于通过选择性修改图像的特定区域来生成局部化缺陷。这一过程通常包括去除或遮挡图像的部分区域，并使用生成模型填充这些被移除的区域，使其具备模拟的缺陷纹理或模式。例如，可将光滑表面局部改造成划痕、洞或其他不规则形状，生成用于训练异常检测系统的有针对性的异常。

% 近年来，修复填充技术在工业异常合成方面取得了创新进展。Lugmayr等人（2022）首次将去噪扩散概率模型（DDPMs）应用于修复填充，通过前向和逆向过程迭代生成噪声并重建被遮挡的区域。尽管这一方法并非专为工业应用设计，但其高控制能力为修复填充提供了新的可能性。在此基础上，Zhang等人（2024）提出了RealNet，通过在逆向扩散过程中扰动方差，确保异常样本从正常图像分布的低密度区域中采样。这种方法通过增强异常与正常模式的偏离，同时保持整体图像结构，提升了生成异常的真实性。

% Wei等人（2022）提出了一种面向工业缺陷图像的遮罩引导生成框架，集成了背景替换模块（Background Replacement Module, BRM），以保留正常背景内容，同时选择性地替换缺陷区域。该方法能够精确控制缺陷的形状和纹理，并通过双判别器模块（Dual Discriminator Module, DDM）提取缺陷特征，同时构建伪正常背景进行训练。在后续研究中，Wei等人（2023）开发了DCDGAN，通过首先在缺陷纹理上训练生成模型，然后将这些纹理与背景融合来生成多类别、多样化的缺陷。尽管这种方法在生成纹理与背景的强关联性方面仍面临挑战，但它显著提高了修复填充的多样性和适用性。

% 修复填充在生成控制性强、局部化的缺陷样本方面表现优异，使其成为需要针对性异常模拟应用中的一种多功能方法。遮罩引导生成和基于扩散的生成技术显著提高了修复填充在工业场景中的真实感和适应性。然而，其局限性包括难以实现类似于真实缺陷的随机性和无缝融合，尤其是在填充模型训练不足时。尽管如此，修复填充仍然是生成特定缺陷模式的流行且计算效率高的方法，其相关技术进展为增强工业异常检测系统提供了新途径。




\section{VLM-based Synthesis}
\label{sec:vlms}
\xxc{\noindent \textbf{Single-stage synthesis} leverages pre-trained VLMs with billions of parameters, leveraging their abundant feature representations and multimodal information. It synthesizes realistic anomalies and produces context-aware, highly detailed abnormal samples with minimal or no adjustments. By capitalizing on abundant cues from various modalities, single-stage synthesis balances computational efficiency and domain specificity, making it an attractive solution for industrial applications. ~\citeauthor{sun2024cut} introduce a training-free anomaly synthesis method based on stable diffusion that maximizes alignment between abnormal regions and anomaly descriptions. ~\citeauthor{hu2024anomalyxfusion} generate embeddings from diverse modalities and adjust them dynamically during the diffusion process. This strategy enables the creation of anomalies enriched with multimodal information, resulting in higher fidelity and diversity. Additionally, ~\citeauthor{jiang2024cagen} propose CAGEN, which employs mask annotations and text prompts to fine-tune ControlNet for precise control over the location and type of synthesized anomalies. Furthermore, ~\citeauthor{he2024anomalycontrol} model cross-modal semantic features to allow fine-grained control over the characteristics of generated anomalies.}

\xxc{\noindent \textbf{Strengths and Weaknesses.} Single-stage synthesis harnesses diverse multimodal cues to synthesize realistic abnormal textures. By leveraging both visual and textual modalities, it effectively captures detailed information, enabling more precise anomaly synthesis while allowing fine-grained control through prompt modifications. However, a significant limitation is that the synthesized anomaly regions often do not precisely align with mask annotations, which can adversely impact the accuracy of downstream anomaly segmentation tasks. This misalignment also leads to inconsistencies between the abnormal data and annotations, reducing reliability in industrial applications.}



% \noindent \textbf{Training-Free Generation} is a subcategory of Large Vision Models (LVMs) that leverages pre-trained large-scale vision systems to generate synthetic anomalies directly, without requiring additional training. This approach utilizes the extensive feature representations learned by LVMs on diverse datasets to synthesize anomalies through operations such as prompt-based generation, feature perturbation, or latent manipulation. By bypassing the training phase, Training-Free Generation offers a method that is both rapid and computationally efficient for anomaly generation.

% Recent advancements have highlighted the potential and limitations of this approach. Sun et al. (2024) ~\citeauthor{sun2024cut} introduced CUT, a controllable, universal, and training-free anomaly generation framework based on stable diffusion (SD). CUT maximizes the alignment between anomaly regions and model attention tokens, guided by semantic information and a novel loss function tailored for SD frameworks. While it achieves high flexibility and anomaly relevance, the method requires numerous iterations during the synthesis process, limiting its efficiency in applications demanding real-time or large-scale generation. Additionally, the reliance on precise semantic guidance can impact the approach’s usability in scenarios with vague or incomplete anomaly definitions.

% While Training-Free Generation excels in scenarios requiring rapid anomaly synthesis or exploratory applications, its effectiveness depends on the generalization capacity of the pre-trained model. If the model’s learned features do not closely align with the domain-specific characteristics of the target application, the generated anomalies may lack contextual relevance or realism. CUT demonstrates how advancements in this area are addressing these challenges by integrating semantic guidance and optimizing attention mechanisms to enhance anomaly quality. Nonetheless, the trade-off between efficiency and precision remains a key consideration for further development in this domain.

% 无训练生成： 无训练生成是基于大视觉模型（LVMs）的一种子类别，利用预训练的大规模视觉系统直接生成合成异常样本，而无需额外训练。这种方法通过使用LVMs在多样化数据集上学习的广泛特征表示，通过提示生成（prompt-based generation）、特征扰动（feature perturbation）或潜在特征操作（latent manipulation）来生成异常样本。由于省去了训练阶段，无训练生成在异常生成任务中既快速又计算效率高。

% 近年来的研究突出了这种方法的潜力及其局限性。Sun等人（2024）提出了CUT，这是一种基于稳定扩散（Stable Diffusion, SD）的可控、通用、无训练异常生成框架。CUT通过对异常区域和模型注意力令牌（attention tokens）进行最大化对齐，以语义信息为指导，并结合适用于SD框架的新型损失函数。尽管CUT在灵活性和异常相关性方面表现出色，但其在生成过程中需要多次迭代，这限制了其在需要实时或大规模生成的应用中的效率。此外，该方法对精确语义指导的依赖在定义模糊或信息不完整的异常场景中可能会受到影响。

% 无训练生成在需要快速异常生成或探索性应用的场景中表现出色，但其有效性依赖于预训练模型的泛化能力。如果模型学习的特征不能与目标应用的领域特征紧密对齐，生成的异常可能会缺乏上下文相关性或真实性。CUT表明，通过语义指导和优化注意力机制，可以在此领域克服一些挑战，但效率与精度之间的权衡仍然是进一步发展的关键考虑因素。


% \subsection{Fine-Tuned Model}
% \noindent \textbf{Fine-Tuned Model} extend the capabilities of pre-trained Large Vision Models (LVMs) by adapting them to specific industrial or application contexts. This process involves retraining a pre-trained LVM on domain-specific data, enabling the generation of synthetic anomalies that align closely with the unique characteristics of the target dataset. Techniques such as supervised fine-tuning, reinforcement learning, and multimodal data integration are commonly employed to enhance the relevance and realism of the generated anomalies.

% Recent advancements have expanded the potential of Fine-Tuned Models by incorporating innovative methods for anomaly synthesis. Hu et al. (2024) ~\citeauthor{hu2024anomalyxfusion} introduced AnomalyX Fusion, a framework designed to leverage multimodal data for anomaly generation. The system employs a Multimodal Integration Fusion (MIF) module to combine embeddings from diverse data modalities, followed by a Dynamic Diffusion Fusion (DDF) module that adjusts embeddings dynamically during the diffusion process. This approach allows the generation of anomalies enriched by multimodal information, offering higher fidelity and diversity. Jiang et al. (2024) ~\citeauthor{jiang2024cagen} proposed CAGEN, which uses binary masks and text prompts to fine-tune the ControlNet model for precise control over the spatial location and style of generated anomalies. Their method further integrates anomaly features with normal sample features at the latent level, creating highly realistic synthetic anomalies that maintain strong similarities to real-world defects. This dual-stage framework enhances both the contextual relevance and diversity of anomalies.

% Li et al. (2024) ~\citeauthor{li2024novel} introduced a Blended Latent Diffusion Model with Online Adaptation, featuring a three-stage inference process: free diffusion, edit diffusion, and online decoder adaptation. This multi-stage strategy generates high-quality synthetic anomalies with extensive mode variability, ensuring the versatility of generated samples for diverse industrial defect scenarios. He et al. (2024) ~\citeauthor{he2024anomalycontrol} developed AnomalyControl, which incorporates a Cross-modal Semantic Modeling (CSM) module and a Semantic Guided Adapter. This architecture enables cross-modal anomaly synthesis guided by semantic cues, allowing fine-grained control over the characteristics of generated defects. By aligning multimodal semantic features with anomaly attributes, AnomalyControl produces contextually consistent and controllable anomalies.

% The strength of Fine-Tuned Models lies in their ability to generate highly customized, context-aware anomalies tailored to specific industrial requirements. By incorporating advanced diffusion processes, multimodal integration, and semantic guidance, these methods enable precise defect replication and high anomaly fidelity. However, the complexity of fine-tuning and the need for substantial computational resources and domain-specific data can limit their applicability in data-scarce or resource-constrained environments. Nonetheless, these models are particularly valuable for applications requiring detailed anomaly synthesis to support high-precision industrial inspection tasks.

% 微调模型： 微调模型通过将预训练的大视觉模型（LVMs）适配于特定的工业或应用场景，进一步扩展了其能力。该过程涉及在特定领域数据上重新训练预训练的LVM，使其生成的合成异常样本能够更好地与目标数据集的独特特性相匹配。常用的技术包括有监督微调、强化学习以及多模态数据集成，以提高生成异常的相关性和真实性。

% 近年来，微调模型通过整合创新方法进一步增强了异常生成的潜力。Hu等人（2024）提出了AnomalyX Fusion框架，该框架旨在利用多模态数据进行异常生成。系统采用多模态集成融合（MIF）模块结合多种数据模态的嵌入，随后通过动态扩散融合（DDF）模块在扩散过程中动态调整嵌入。此方法生成了由多模态信息丰富的异常样本，具有更高的真实感和多样性。Jiang等人（2024）提出了CAGEN，该框架利用二值遮罩和文本提示微调ControlNet模型，精确控制生成异常的空间位置和样式。其方法进一步在潜在层面整合异常特征与正常样本特征，生成与实际缺陷高度相似的合成异常。这种双阶段框架增强了异常的上下文相关性和多样性。

% Li等人（2024）提出了一种带在线适配功能的混合潜在扩散模型（Blended Latent Diffusion Model with Online Adaptation），该模型具有自由扩散、编辑扩散和在线解码器适配三阶段推理策略。该多阶段策略生成了具有广泛模式变异的高质量合成异常样本，确保生成样本在多样化工业缺陷场景中的适用性。He等人（2024）开发了AnomalyControl，结合了跨模态语义建模（CSM）模块和语义引导适配器（Semantic Guided Adapter）。该架构通过语义线索实现跨模态异常合成，能够对生成缺陷的特性进行精细控制。通过将多模态语义特征与异常属性对齐，AnomalyControl生成了具有上下文一致性和可控性的异常。

% 微调模型的优势在于其能够根据具体工业需求生成高度定制化、具有上下文感知的异常样本。通过集成高级扩散流程、多模态数据融合和语义引导，这些方法实现了精确的缺陷复制和高异常保真度。然而，微调的复杂性以及对大量计算资源和领域特定数据的需求可能限制其在数据匮乏或资源有限环境中的应用。尽管如此，这些模型对于需要详细异常合成以支持高精度工业检测任务的应用场景尤为宝贵。
% \subsection{Multi-Stage Generation}
% \noindent \textbf{Multi-Stage Generation} is a sophisticated technique under the Large Vision Models (LVMs) umbrella that refines the anomaly synthesis process through iterative steps. This approach encompasses two primary interpretations: the generation of anomaly masks and multi-stage training procedures. By employing these stages, the synthesis process integrates global and local defect characteristics, progressively enhancing the realism, diversity, and contextual consistency of the generated anomalies.

\xxc{\noindent \textbf{Multi-stage synthesis} is an advanced VLM technique that provides a comprehensive pipeline for anomaly synthesis. It integrates multiple processes, including anomaly synthesis and precise mask production. By iteratively refining global context and local abnormal regions, it enhances the realism, diversity, and contextual consistency of synthesized anomalies while meeting the requirements of downstream tasks better. This complete pipeline strengthens the usability and reliability of industrial systems. Recent studies contribute notably to this field. ~\citeauthor{jin2024dualanodiff} propose a dual-branch VLM where one branch captures global context and the other targets abnormal regions,  and it leverages a pre-trained segmentation for high-quality mask generation. ~\citeauthor{shi2025few} integrate textual guidance into global information and local synthesis, introducing a novel mask algorithm that improves small anomaly synthesis and enables precise control over intensity and direction. ~\citeauthor{dai2024seas} introduce SeaS, a few-shot method that binds anomaly attributes to specific tokens using unbalanced anomaly prompts while aligning normal image features to preserve authenticity, it can also produce accurate mask annotations. Lastly, ~\citeauthor{hu2024anomalydiffusion} develop AnomalyDiffusion, incorporating textual and positional information for precise anomaly localization and employing textual inversion to learn mask embeddings.}

\noindent \textbf{Strengths and Weaknesses.} \xxc{Multi-stage synthesis integrates sequential training and precise anomaly mask generation to refine anomaly synthesis. It can capture global context and local details, enhancing the fidelity and diversity of the synthesized anomalies. The advanced mask generation enables anomaly synthesis at designated locations, further aligning with industrial needs. However, its complexity and high computational cost limit scalability in resource-constrained settings. Despite this, multi-stage synthesis remains essential for applications demanding realistic, context-aware anomalies in specific industrial scenarios.}


\xxc{
\section{Future dirction}
\label{sec:future}

\noindent \textbf{Enhance Anomaly Diversity.} The limited coverage of anomaly distributions remains a critical bottleneck in IAS. Existing methods often rely on a limited set of real anomalies, leading to overfitting and insufficient diversity in synthesized anomalies. A potential approach is adaptive anomaly synthesis techniques leveraging self-supervised and active learning algorithms. For instance, uncertainty-aware models can guide synthesis by identifying underrepresented abnormal regions and dynamically adjusting it. Additionally, a coarse-to-fine approach, first generating structures then refining details, can improve diversity. Furthermore, constructing larger, more diverse datasets remains crucial for better generalization.

\noindent \textbf{Controllable Synthesis of Anomaly Attributes.} Industrial image anomalies exhibit substantial complexity, including variations in shape, texture, and distribution. Existing approaches often struggle to handle these variations, leading to the generation of unrealistic or overly simplified anomalies. To improve this, future IAS researches require to focus on cross-class consistency modeling, leveraging advanced network architectures, such as large-scale models, to learn shared and distinct characteristics across different anomaly types. Additionally, controllable synthesis techniques should be employed to allow precise adjustments of anomaly attributes like type and location. For instance, combining local anomaly synthesis with advanced segmentation models facilitates fine-tuned modifications of anomaly attributes, ensuring seamless integration with background and improve the realism of synthesized samples. 

\noindent \textbf{Promote Multimodal Anomaly Synthesis.} Despite the increasing availability of complementary modalities such as textual descriptions, infrared imagery, and X-ray scans, their integration into IAS remains largely unexplored. Future advancements should focus on developing cross-modal alignment strategies that leverage VLM and multimodal transformers to establish semantic correlations between different modalities, enabling richer anomaly synthesis. Furthermore, incorporating contrastive learning techniques can improve cross-modal feature learning, ensuring better correspondence between generated anomalies and their real-world counterparts. Multi-source data fusion techniques can also be explored to enhance the robustness of synthesized anomalies, leveraging complementary strengths of different modalities. And integrating reinforcement learning into multimodal synthesis pipelines could enable adaptive anomaly generation, dynamically optimizing synthesis strategies based on anomaly characteristics and industrial requirements.

% These approaches will not only improve the realism and diversity of synthetic anomalies but also facilitate the development of zero-shot and few-shot learning-based systems for downstream tasks, which are crucial for industrial applications where labeled abnormal data is scarce.
}
% Recent advancements have demonstrated the versatility of multi-stage techniques in industrial anomaly generation. DualAnoDiff~\citeauthor{jin2024dualanodiff} introduced a dual-interrelated diffusion model, where one branch generates the overall image and the other focuses specifically on anomaly regions. These branches interact via attention modules, with latent space modifications in the UNet architecture under a Stable Diffusion framework, ensuring realistic and diverse anomaly synthesis. Shi et al. (2025) ~\citeauthor{shi2025few} emphasized intra-product background consistency and inter-product defect consistency in their framework, highlighting that normal backgrounds within the same product should remain consistent, while defect generation should reflect morphological similarities across products of the same category. Their approach incorporates adaptive attention-enhanced loss functions and dual perturbation strategies to model the fusion of background and defect regions, with textual information injected to guide each part. Additionally, a novel mask algorithm improves the generation accuracy of small defects, allowing precise control over defect intensity and directionality.

% Dai et al. (2024) ~\citeauthor{dai2024seas} proposed SeaS, a few-shot anomaly image generation framework utilizing separation and sharing fine-tuning. This method binds anomaly attributes to specific tokens using unbalanced anomaly (UA) text prompts and aligns normal image features through a novel normal alignment (NA) loss. By predicting and generating masks with mixed training strategies, SeaS achieves anomaly attribute consistency across generations while supporting varied anomaly token representations. Hu et al. (2024) ~\citeauthor{hu2024anomalydiffusion} developed AnomalyDiffusion, combining textual and positional information during training to enable precise anomaly localization. Their diffusion-based reconstruction generates anomalies by forcing the reconstructed normal image and the original input to pass through a discriminator, which outputs the corresponding anomaly mask. This approach ensures tight integration between the mask and the anomaly, though the method’s complexity arises from its high parameter count and computational demands.

% The iterative nature of Multi-Stage Generation ensures that outputs meet stringent quality standards, combining anomaly masks and multi-stage training processes for exceptional defect fidelity. Techniques like anomaly-specific attention mechanisms, multi-branch architectures, and hybrid training strategies allow fine-grained control over anomaly synthesis while maintaining consistency with industrial requirements. However, these methods often demand substantial computational resources and intricate optimization processes, limiting their scalability in resource-constrained environments. Despite these challenges, Multi-Stage Generation remains indispensable for applications requiring highly realistic and diverse anomalies tailored to specific industrial scenarios.

% 多阶段生成： 多阶段生成是基于大视觉模型（LVMs）的一种复杂技术，通过迭代步骤优化异常生成过程。这种方法包含两个主要方向：异常遮罩生成和多阶段训练过程。通过这些阶段，生成过程逐步集成全局和局部缺陷特性，显著提高了生成异常的真实性、多样性和上下文一致性。

% 最近的研究展示了多阶段技术在工业异常生成中的多样性和适应性。Jin等人（2024）提出了DualAnoDiff，一种双相关扩散模型，其中一个分支生成整体图像，另一个分支专注于异常区域。这些分支通过注意力模块进行交互，并在稳定扩散框架下的UNet架构中修改潜在空间，确保生成的异常既真实又多样化。Shi等人（2025）在其框架中强调了产品内部背景一致性和产品之间缺陷一致性，指出同一产品内的正常背景应保持一致，而缺陷生成应反映相同类别产品间的形态相似性。其方法结合了自适应注意力增强损失函数和双扰动策略，建模背景与缺陷区域的融合，并通过文本信息引导每一部分。此外，一种新型遮罩算法改进了小缺陷的生成精度，使缺陷强度和方向性能够被精确控制。

% Dai等人（2024）提出了SeaS，一种利用分离和共享微调的少样本异常图像生成框架。该方法使用不平衡异常（UA）文本提示绑定异常属性到特定令牌，并通过新型正常对齐（NA）损失对正常图像特征进行对齐。通过混合训练策略预测并生成遮罩，SeaS在生成一致性异常属性的同时支持多样化的异常令牌表示。Hu等人（2024）开发了AnomalyDiffusion，将文本和位置信息结合用于训练，实现了精准的异常定位。其基于扩散的重建通过强制重建的正常图像与原始输入通过判别器生成相应的异常遮罩，确保遮罩和异常之间的紧密集成。然而，该方法由于其高参数量和计算需求而显得复杂。

% 多阶段生成的迭代特性确保输出满足严格的质量要求，通过结合异常遮罩和多阶段训练流程，生成了具有卓越缺陷保真度的样本。诸如异常特定注意力机制、多分支架构以及混合训练策略等技术提供了对异常合成的精细控制，同时保持与工业需求的一致性。然而，这些方法通常需要大量的计算资源和复杂的优化过程，限制了其在资源受限环境中的可扩展性。尽管如此，多阶段生成对于需要高度逼真且多样化的异常以适配特定工业场景的应用来说仍然不可或缺。

\section{Conclusion}
\label{sec:conclusion}
In this survey, we explored recent advancements in Industrial Image Anomaly Synthesis (IAS) by first identifying three key challenges: \ding{182} limited sampling in anomalies distribution, \ding{183} difficulty in synthesizing realistic anomalies, and \ding{184} underutilization of multimodal information. To address them, we provided essential background knowledge on IAS and introduced its core methodologies. We then conducted a comprehensive review of existing IAS approaches, categorizing them into Hand-crafted, Distribution hypothesis-based, Generative models-based, and Vision language models-based synthesis. Finally, we discussed promising future research directions, such as enhancing anomaly diversity, achieving a controllable synthesis of anomaly attributes, and fully leveraging multimodal information. We believe that tackling these challenges will significantly improve the effectiveness of IAS.

\bibliographystyle{named}
\bibliography{ijcai25}

\end{document}

