\section{ZKP-Amenable LIME : LIME-Border}\label{sec:advlime}
%uniform sampling instead of gaussian, L2 norm for weighing samples, are the rest parameters default as used by tabular lime? tabular lime explanation vs what we do, quantization


Certain traditional considerations for LIME become more critical when viewed through the lens of adversarial manipulation. We describe these considerations below and give solutions to deal with them in our zero-knowledge system.

Bandwidth parameter $\sigma$ of the similarity kernel plays a key role in producing faithful explanations, as evidenced by many studies in the explanation literature which study its effect on the generated explanation and explore ways to set its value. A small value of the bandwidth parameter results in a small neighborhood around the input point with high weights, thereby leading to unstable explanations (as all the sampled points are very similar to the input making it harder to learn a classifier). On the other hand, a large value of the parameter with a large neighborhood around the input implies that a global explanation is being learnt, rather than a local one, resulting in unfaithful explanations. While these studies look at the bandwidth parameter from the lens of faithfulness of generated explanations, we observe that an adversary can use this parameter to generate explanations that match its incentives. For instance, a model developer giving discriminatory predictions for a minority group in a part of the input space can hide its intent by setting a large value of the bandwidth parameter and outputting global explanation which may be seemingly innocuous, but had it output the local explanation, the discrimination could have been apparent in the explanation. To eliminate the potential for such attacks, we propose that either (1) the prover cryptographically commit to a value of the bandwidth parameter apriori, which enforces that the same value of the bandwidth parameter is used for all input points (this value can come from regulatory suggestions), or (2) the verifier supply a value of the bandwidth parameter to be used by the prover. Note that the same recommendations can apply to other parameters.

Another important consideration for stable and faithful explanations is the spatial location of the neighborhood. Given an input far off from the decision boundary, any reasonable neighborhood \textit{around the input} will only contain samples from the same class as the input resulting in a constant function rather than the closest decision boundary when a linear classifier is learnt on such samples, leading to vacuous or degenerate explanations. Hence, as noted by \cite{}, the set of sampled points in LIME should always contain instances from different classes. To remedy the problem, \cite{laugel2018defining} propose to find the closest point to the input belonging a different class, $x_{border}$ and sample training points from a neighborhood around $x_{border}$ instead of the input. We use this technique to sample points in LIME. The resulting algorithm is called LIME-Border and is given in \ref{alg:limeborder}.

\begin{algorithm}[tbh]
\begin{algorithmic}[1]
 \caption{\textsc{LIME-Border} \cite{laugel2018defining}}
   \label{alg:limeborder}
    
    \STATE {\bfseries Input:} Input point $x$, Classifier $f$, Number of points $n$ to be sampled around input point, Length of explanation $K$, Bandwidth parameter $\sigma$ for similarity kernel

    \STATE  {\bfseries Output:} Explanation $e$
    
    \STATE $x_{border}:=$ \textsc{find\_closest\_point\_with\_different\_label($x, f$)} \hfill \textcolor{blue}{$\rhd$} Exact algorithm in App. Alg. \ref{}

    \STATE $e :=$ \textsc{LIME}($x_{border}, f, n, K, \sigma$)
    
    \STATE Return Explanation $e$
\end{algorithmic}
\end{algorithm}