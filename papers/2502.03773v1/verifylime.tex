\section{\name : Verification of Explanations}\label{sec:verifylime}
%\cy{give names to all versions of lime, 4.1 commitment, 4.2 Overview: verification- talk about the 2 versions, 4.3 verification key steps used in all algorithms}


Our system for operationalizing explanations in adversarial settings, \name, consists of two phases: (1) a One-time Commitment phase and (2) an Online verification phase which should be executed for every input.

\textbf{Commitment Phase.} To ensure model uniformity, the model owner cryptographically commits to a fixed set of model weights $\mathbf{W}$ belonging to the original model $f$, resulting in committed weights $\CW$. Architecture of model $f$ is assumed to be public. Additionally, model owner can also commit to the values of different parameters used in the explanation algorithm or these parameters can be public.%\cy{EVAN: what exactly about the architecture should be known? is the architecture public?} \el{Chhavi: yes, the architecture is completely public. The only thing that is hidden is the model weights. Granted, we can add that if there were methods to make zksnarks for model inference that hid the architecture (like a universal circuit of sorts, not sure if any papers exist on this), then our methods still are applicable)}



\textbf{Online Verification Phase.} This phase is executed every time a customer inputs a query. On receiving the query, the prover (bank) outputs a prediction, an explanation and a zero-knowledge proof of the explanation. Verifier (customer) validates the proof without looking at the model weights. If the proof passes verification, it means that the explanation is correctly computed with the committed model weights and explanation algorithm parameters.

To generate the explanation proof, a ZKP circuit which implements (a variant of) LIME is required. However since ZKPs can be computationally inefficient, instead of reimplementing the algorithm as-is in a ZKP library, we devise some smart strategies for verification, based on the fact that verification can be easier than redoing the computation. Since all the variants of LIME share some common functionalities, we next describe how the verification strategies for these functionalities. For more details on the verification for each variant, see Appendix Sec. \ref{app:sec:appexpproof}.

%has four modular functionalities, as described below.
%instead, leading to the ZKP version of LIME, called zkLIME App. Alg. \ref{}. 
%Note that we have different versions of LIME as proposed in Sec. \ref{sec:varlime} and one of these can be chosen but all of them share some similar steps.


\textit{1. Verifying Sampling (Alg.~\ref{alg:zk_check_poseidon}, \ref{alg:zk_uniform_sample}, \ref{alg:zk_gaussian_sample}).} We use the Poseidon~\cite{poseidon} hash function to generate random samples. As part of the setup phase, the prover commits to a random value $r_p$. When submitting an input for explanation, the
verifier sends another random value $r_v$. Prover generates uniformly sampled points using Poseidon with
a key $r_p + r_v$, which is uniformly random in the view of both the prover and the verifier. Then, during the proof generation phase, the prover proves that the sampled points are the correct outputs from Poseidon using \textit{ezkl}'s inbuilt efficient Poseidon verification circuit. We convert the uniform samples into Gaussian
samples using the inverse CDF, which is checked in the proof using a look-up table for the inverse CDF.
%; the prover uses this circuit along with private inputs (e.g. model weights) to generate a proof, while the verifier checks the proofâ€™s validity without seeing the private inputs
%\cy{EVAN TO DO : how? using what?}. \el{This is using a poseidon circuit. We use one that ezkl uses already, not entirely sure on the details, but also not sure if we should discuss it. maybe I should just say that there is an efficient poseidon verification circuit? I guess to clarify more, poseidon is a hash function that was created expressly for this purpose: to use in SNARKs for efficient hash proofs}

\textit{2. Verifying Exponential Kernel (Alg.~\ref{alg:zk_exponential_kernel}).} ZKP libraries do not support many non-linear functions such as exponential, which is used for the similarity kernel in LIME (Step 5 of Alg.\ref{alg:limeinclear}). To resolve this problem, we implement a look-up table for the exponential function and prove that the exponential value is correct by comparing it with the value from the look-up table.

\textit{3. Verifying Inference.} Since LIME requires predictions for the sampled points in order to learn the linear explanation, we must verify that the predictions are correct. To generate proofs for correct predictions, we use \textit{ezkl}'s inbuilt inference verification circuit. %\cy{EVAN: Is this correct?}%, which is an efficient ZKP engine for doing inferences on deep learning models.

\textit{4. Verifying LASSO Solution (Alg.~\ref{alg:zk_lasso}).} ZKP libraries only accept integers and hence all floating points have to be quantized. Consequently, the LASSO solution for Step 7 of Alg. \ref{alg:limeinclear} is also quantized in a ZKP library, leading to small scale differences between the exact and quantized solutions. To verify optimality of the quantized LASSO solution, we use the standard concept of duality gap. For a primal objective $l$ and its dual objective $g$, to prove that the objective value from primal feasible $w$ is close to that from the primal optimal $w^*$, that is $l(w) - l(w^*) \leq \epsilon$, the duality gap should be smaller than $\epsilon$ as well, $l(w) - g(u,v) \leq \epsilon$ where $u,v$ are dual feasible. Since the primal and dual of LASSO have closed forms, as long we input any dual feasible values, we can verify that the quantized LASSO solution is close to the LASSO optimal. The prover provides the dual feasible as part of the witness to the proof. See App. Sec.\ref{app:subsec:lassoprimaldual} for closed forms of the primal and dual functions and for the technique to find dual feasible.

%For LASSO, the primal optimal $w^*$ and dual optimal $v^*$ for lasso are linked by the equation $y - Xw^* = \lambda v^*$. Therefore, given a primal feasible $w$ that is close to $w^*$, it is possible to generate a dual feasible $v$ close to $v^*$.\cy{what are y and x}\cy{EVAN : make changess to this}

The complete \name protocol can be found in Alg. \ref{alg:ExpProof}; its security guarantee is given as follows.

\begin{theorem}
(Informal) Given a model $f$ and an input point $x$, \name~returns prediction $f(x)$, LIME explanation $\mathcal{E}(f, x)$ and a ZK proof for the correct computation of the explanation, without leaking anything additional about the weights of model $f$ (in the sense described in Sec.\ref{sec:probsol}).
\end{theorem}

For the complete formal security theorem and proof, refer to App. Sec. \ref{app:subsec:secproof}. The proof follows from inherent properties of ZKPs.

%$min_{w,z} (z-\nu)^{\top} z+\nu^{\top} X w+\lambda\|w\|_1$
%where $z=Xw-y$


%Your techniques for verifying LIME : volume argument for closest point, sampling done in ZKP system, exp implemented in a table lookup, lasso solution : duality gap is small (), top-K -sort and give top k, sampled exactly n points, predictions are verified with EZKL, Theorem for ZKP like in fairproof, NP like what somesh mentioned last time?

%dual: to prove $f(w) - f(w^*) \leq \epsilon$, we have to prove $f(w) - g(u,v) \leq \epsilon$ for any feasible $u,v$. We know $w$ -- the one we use in ZK system, we know the closed form of f and g.

%closest point : if volume of opposite points in the ball around $x$ of radius $\eta$ is $5\%$ and 95\% points have same label and if we need 64-bit security then P(n sampled same labels)$\leq \frac{1}{2^{64}}$ or $(0.95)^n \leq \frac{1}{2^{64}}$ which gives $n=865$ which is not a big number. If opposite labels cover 1\% of the volume then $n=4414$ which is also okay. How do you quantify the volume?