@incollection{Bengio+chapter2007,
author = {Bengio, Yoshua and LeCun, Yann},
booktitle = {Large Scale Kernel Machines},
publisher = {MIT Press},
title = {Scaling Learning Algorithms Towards {AI}},
year = {2007}
}

@article{Hinton06,
author = {Hinton, Geoffrey E. and Osindero, Simon and Teh, Yee Whye},
journal = {Neural Computation},
pages = {1527--1554},
title = {A Fast Learning Algorithm for Deep Belief Nets},
volume = {18},
year = {2006}
}

@book{goodfellow2016deep,
title={Deep learning},
author={Goodfellow, Ian and Bengio, Yoshua and Courville, Aaron and Bengio, Yoshua},
volume={1},
year={2016},
publisher={MIT Press}
}

@inproceedings{ribeiro2016should,
  title={" Why should i trust you?" Explaining the predictions of any classifier},
  author={Ribeiro, Marco Tulio and Singh, Sameer and Guestrin, Carlos},
  booktitle={Proceedings of the 22nd ACM SIGKDD international conference on knowledge discovery and data mining},
  pages={1135--1144},
  year={2016}
}


@inproceedings{anders2020fairwashing,
  title={Fairwashing explanations with off-manifold detergent},
  author={Anders, Christopher and Pasliev, Plamen and Dombrowski, Ann-Kathrin and M{\"u}ller, Klaus-Robert and Kessel, Pan},
  booktitle={International Conference on Machine Learning},
  pages={314--323},
  year={2020},
  organization={PMLR}
}



@article{yadav2022xaudit,
  title={XAudit: A Theoretical Look at Auditing with Explanations},
  author={Yadav, Chhavi and Moshkovitz, Michal and Chaudhuri, Kamalika},
  journal={arXiv preprint arXiv:2206.04740},
  year={2022}
}

@article{slack2021counterfactual,
  title={Counterfactual explanations can be manipulated},
  author={Slack, Dylan and Hilgard, Anna and Lakkaraju, Himabindu and Singh, Sameer},
  journal={Advances in neural information processing systems},
  volume={34},
  pages={62--75},
  year={2021}
}

@inproceedings{noppel2024sok,
  title={SoK: Explainable machine learning in adversarial environments},
  author={Noppel, Maximilian and Wressnegger, Christian},
  booktitle={2024 IEEE Symposium on Security and Privacy (SP)},
  pages={2441--2459},
  year={2024},
  organization={IEEE}
}


@inproceedings{GMR,
author = {Goldwasser, S and Micali, S and Rackoff, C},
title = {The Knowledge Complexity of Interactive Proof-Systems},
year = {1985},
isbn = {0897911512},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/22145.22178},
doi = {10.1145/22145.22178},
booktitle = {Proceedings of the Seventeenth Annual ACM Symposium on Theory of Computing},
pages = {291–304},
numpages = {14},
location = {Providence, Rhode Island, USA},
series = {STOC '85}
}

@article{GMW,
author = {Goldreich, Oded and Micali, Silvio and Wigderson, Avi},
title = {Proofs That Yield Nothing but Their Validity or All Languages in NP Have Zero-Knowledge Proof Systems},
year = {1991},
issue_date = {July 1991},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {38},
number = {3},
issn = {0004-5411},
url = {https://doi.org/10.1145/116825.116852},
doi = {10.1145/116825.116852},
journal = {J. ACM},
month = {jul},
pages = {690–728},
numpages = {39},
keywords = {NP, zero-knowledge, proof systems, methodological design of protocols, one-way functions, interactive proofs, graph isomorphism, cryptographic protocols, fault tolerant distributed computing}
}

@incollection{Bengio+chapter2007,
author = {Bengio, Yoshua and LeCun, Yann},
booktitle = {Large Scale Kernel Machines},
publisher = {MIT Press},
title = {Scaling Learning Algorithms Towards {AI}},
year = {2007}
}

@article{Hinton06,
author = {Hinton, Geoffrey E. and Osindero, Simon and Teh, Yee Whye},
journal = {Neural Computation},
pages = {1527--1554},
title = {A Fast Learning Algorithm for Deep Belief Nets},
volume = {18},
year = {2006}
}

@book{goodfellow2016deep,
title={Deep learning},
author={Goodfellow, Ian and Bengio, Yoshua and Courville, Aaron and Bengio, Yoshua},
volume={1},
year={2016},
publisher={MIT Press}
}



@article{garreau2020looking,
  title={Looking deeper into tabular LIME},
  author={Garreau, Damien and von Luxburg, Ulrike},
  journal={arXiv preprint arXiv:2008.11092},
  year={2020}
}

@inproceedings{bordt2022post,
  title={Post-hoc explanations fail to achieve their purpose in adversarial contexts},
  author={Bordt, Sebastian and Finck, Mich{\`e}le and Raidl, Eric and von Luxburg, Ulrike},
  booktitle={Proceedings of the 2022 ACM Conference on Fairness, Accountability, and Transparency},
  pages={891--905},
  year={2022}
}

@inproceedings{slack2020fooling,
  title={Fooling lime and shap: Adversarial attacks on post hoc explanation methods},
  author={Slack, Dylan and Hilgard, Sophie and Jia, Emily and Singh, Sameer and Lakkaraju, Himabindu},
  booktitle={Proceedings of the AAAI/ACM Conference on AI, Ethics, and Society},
  pages={180--186},
  year={2020}
}


@inproceedings{aivodji2019fairwashing,
  title={Fairwashing: the risk of rationalization},
  author={A{\"\i}vodji, Ulrich and Arai, Hiromi and Fortineau, Olivier and Gambs, S{\'e}bastien and Hara, Satoshi and Tapp, Alain},
  booktitle={International Conference on Machine Learning},
  pages={161--170},
  year={2019},
  organization={PMLR}
}

@article{shahin2022washing,
  title={Washing the unwashable: On the (im) possibility of fairwashing detection},
  author={Shahin Shamsabadi, Ali and Yaghini, Mohammad and Dullerud, Natalie and Wyllie, Sierra and A{\"\i}vodji, Ulrich and Alaagib, Aisha and Gambs, S{\'e}bastien and Papernot, Nicolas},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={14170--14182},
  year={2022}
}

@inproceedings{yan2022active,
  title={Active fairness auditing},
  author={Yan, Tom and Zhang, Chicheng},
  booktitle={International Conference on Machine Learning},
  pages={24929--24962},
  year={2022},
  organization={PMLR}
}

@article{yadav2024influence,
  title={Influence-based Attributions can be Manipulated},
  author={Yadav, Chhavi and Wu, Ruihan and Chaudhuri, Kamalika},
  journal={arXiv preprint arXiv:2409.05208},
  year={2024}
}



@inproceedings{noppel2024sok,
  title={SoK: Explainable machine learning in adversarial environments},
  author={Noppel, Maximilian and Wressnegger, Christian},
  booktitle={2024 IEEE Symposium on Security and Privacy (SP)},
  pages={2441--2459},
  year={2024},
  organization={IEEE}
}

@article{laugel2018defining,
  title={Defining locality for surrogates in post-hoc interpretablity},
  author={Laugel, Thibault and Renard, Xavier and Lesot, Marie-Jeanne and Marsala, Christophe and Detyniecki, Marcin},
  journal={arXiv preprint arXiv:1806.07498},
  year={2018}
}


@misc{yadav2024fairproofconfidentialcertifiable,
      title={FairProof : Confidential and Certifiable Fairness for Neural Networks}, 
      author={Chhavi Yadav and Amrita Roy Chowdhury and Dan Boneh and Kamalika Chaudhuri},
      year={2024},
      eprint={2402.12572},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2402.12572}, 
}

@inproceedings{garg2023experimenting,
  title={Experimenting with zero-knowledge proofs of training},
  author={Garg, Sanjam and Goel, Aarushi and Jha, Somesh and Mahloujifar, Saeed and Mahmoody, Mohammad and Policharla, Guru-Vamsi and Wang, Mingyuan},
  booktitle={Proceedings of the 2023 ACM SIGSAC Conference on Computer and Communications Security},
  pages={1880--1894},
  year={2023}
}

@article{abbaszadeh2024zero,
  title={Zero-knowledge proofs of training for deep neural networks},
  author={Abbaszadeh, Kasra and Pappas, Christodoulos and Katz, Jonathan and Papadopoulos, Dimitrios},
  journal={Cryptology ePrint Archive},
  year={2024}
}

@article{jordan2019provable,
  title={Provable certificates for adversarial examples: Fitting a ball in the union of polytopes},
  author={Jordan, Matt and Lewis, Justin and Dimakis, Alexandros G},
  journal={Advances in neural information processing systems},
  volume={32},
  year={2019}
}

@online{wikipedia_right_to_explanation,
  title = {Right to Explanation},
  author = {{Wikipedia contributors}},
  year = {2025},
  url = {https://en.wikipedia.org/wiki/Right_to_explanation},
  note = {Accessed: 2025-01-14}
}

@article{bhattacharjee2024auditing,
  title={Auditing Local Explanations is Hard},
  author={Bhattacharjee, Robi and von Luxburg, Ulrike},
  journal={arXiv preprint arXiv:2407.13281},
  year={2024}
}

@inproceedings{garreau2020explaining,
  title={Explaining the explainer: A first theoretical analysis of LIME},
  author={Garreau, Damien and Luxburg, Ulrike},
  booktitle={International conference on artificial intelligence and statistics},
  pages={1287--1296},
  year={2020},
  organization={PMLR}
}
@misc{credit,
  author       = {Yeh,I-Cheng},
  title        = {{default of credit card clients}},
  year         = {2016},
  howpublished = {UCI Machine Learning Repository},
  note         = {{DOI}: https://doi.org/10.24432/C55S3H}
}

@misc{Adult,
  author       = {Becker,Barry and Kohavi,Ronny},
  title        = {{Adult}},
  year         = {1996},
  howpublished = {UCI Machine Learning Repository},
  note         = {{DOI}: https://doi.org/10.24432/C5XW20}
}

@misc{German,
  author       = {Hofmann,Hans},
  title        = {{Statlog (German Credit Data)}},
  year         = {1994},
  howpublished = {UCI Machine Learning Repository},
  note         = {{DOI}: https://doi.org/10.24432/C5NC77}
}

@misc{ezkl2024,
  author = {Konduit},
  title = {ezkl: Efficient Zero-Knowledge Machine Learning},
  year = {2024},
  howpublished = {\url{https://github.com/zkonduit/ezkl}},
  note = {Accessed: 2025-01-21}
}

@article{paszke2019pytorch,
  title={Pytorch: An imperative style, high-performance deep learning library},
  author={Paszke, Adam and Gross, Sam and Massa, Francisco and Lerer, Adam and Bradbury, James and Chanan, Gregory and Killeen, Trevor and Lin, Zeming and Gimelshein, Natalia and Antiga, Luca and others},
  journal={Advances in neural information processing systems},
  volume={32},
  year={2019}
}

@article{pedregosa2011scikit,
  title={Scikit-learn: Machine learning in Python},
  author={Pedregosa, Fabian and Varoquaux, Ga{\"e}l and Gramfort, Alexandre and Michel, Vincent and Thirion, Bertrand and Grisel, Olivier and Blondel, Mathieu and Prettenhofer, Peter and Weiss, Ron and Dubourg, Vincent and others},
  journal={the Journal of machine Learning research},
  volume={12},
  pages={2825--2830},
  year={2011},
  publisher={JMLR. org}
}

@ARTICLE{lassodualfromfeasible,

  author={Kim, Seung-Jean and Koh, K. and Lustig, M. and Boyd, Stephen and Gorinevsky, Dimitry},

  journal={IEEE Journal of Selected Topics in Signal Processing}, 

  title={An Interior-Point Method for Large-Scale  $\ell_1$-Regularized Least Squares}, 

  year={2007},

  volume={1},

  number={4},

  pages={606-617},

  keywords={Large-scale systems;Least squares methods;Signal processing algorithms;Sparse matrices;Noise reduction;Compressed sensing;Vectors;Iterative methods;Signal reconstruction;Pursuit algorithms;Basis pursuit denoising;compressive sampling;compressed sensing;convex optimization;interior-point methods;least squares;preconditioned conjugate gradients; $\ell_1$ regularization},

  doi={10.1109/JSTSP.2007.910971}}

@inproceedings {poseidon,
author = {Lorenzo Grassi and Dmitry Khovratovich and Christian Rechberger and Arnab Roy and Markus Schofnegger},
title = {Poseidon: A New Hash Function for {Zero-Knowledge} Proof Systems},
booktitle = {30th USENIX Security Symposium (USENIX Security 21)},
year = {2021},
isbn = {978-1-939133-24-3},
pages = {519--535},
url = {https://www.usenix.org/conference/usenixsecurity21/presentation/grassi},
publisher = {USENIX Association},
month = aug
}

@misc{ezkl,
      title={Verifiable evaluations of machine learning models using zkSNARKs}, 
      author={Tobin South and Alexander Camuto and Shrey Jain and Shayla Nguyen and Robert Mahari and Christian Paquin and Jason Morton and Alex 'Sandy' Pentland},
      year={2024},
      eprint={2402.02675},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2402.02675}, 
}

@misc{halo2,
  author = "{Zcash Foundation}",
  title = "{Halo2: A Plonkish zk-SNARK implemented in Rust}",
  year = {2023},
  url = {https://github.com/zcash/halo2},
  note = {Accessed: 2025-01-27}
}

@inproceedings{dasgupta2022framework,
  title={Framework for evaluating faithfulness of local explanations},
  author={Dasgupta, Sanjoy and Frost, Nave and Moshkovitz, Michal},
  booktitle={International Conference on Machine Learning},
  pages={4794--4815},
  year={2022},
  organization={PMLR}
}

@misc{lime,
  author = "{Marco Tulio Ribeiro}",
  title = "{LIME Library}",
  year = {2025},
  url = {https://github.com/marcotcr/lime},
  note = {Accessed: 2025-01-27}
}

@inproceedings{chen2024zkml,
  title={ZKML: An Optimizing System for ML Inference in Zero-Knowledge Proofs},
  author={Chen, Bing-Jyue and Waiwitlikhit, Suppakit and Stoica, Ion and Kang, Daniel},
  booktitle={Proceedings of the Nineteenth European Conference on Computer Systems},
  pages={560--574},
  year={2024}
}

@article{laugel2017inverse,
  title={Inverse classification for comparison-based interpretability in machine learning},
  author={Laugel, Thibault and Lesot, Marie-Jeanne and Marsala, Christophe and Renard, Xavier and Detyniecki, Marcin},
  journal={arXiv preprint arXiv:1712.08443},
  year={2017}
}
%-----
@article{langer2021we,
  title={What do we want from Explainable Artificial Intelligence (XAI)?--A stakeholder perspective on XAI and a conceptual model guiding interdisciplinary XAI research},
  author={Langer, Markus and Oster, Daniel and Speith, Timo and Hermanns, Holger and K{\"a}stner, Lena and Schmidt, Eva and Sesing, Andreas and Baum, Kevin},
  journal={Artificial Intelligence},
  volume={296},
  pages={103473},
  year={2021},
  publisher={Elsevier}
}

@article{smuha2019eu,
  title={The EU approach to ethics guidelines for trustworthy artificial intelligence},
  author={Smuha, Nathalie A},
  journal={Computer Law Review International},
  volume={20},
  number={4},
  pages={97--106},
  year={2019},
  publisher={Verlag Dr. Otto Schmidt}
}

@inproceedings{kastner2021relation,
  title={On the relation of trust and explainability: Why to engineer for trustworthiness},
  author={K{\"a}stner, Lena and Langer, Markus and Lazar, Veronika and Schom{\"a}cker, Astrid and Speith, Timo and Sterz, Sarah},
  booktitle={2021 IEEE 29th International Requirements Engineering Conference Workshops (REW)},
  pages={169--175},
  year={2021},
  organization={IEEE}
}

@article{von2021transparency,
  title={Transparency and the black box problem: Why we do not trust AI},
  author={Von Eschenbach, Warren J},
  journal={Philosophy \& Technology},
  volume={34},
  number={4},
  pages={1607--1622},
  year={2021},
  publisher={Springer}
}

@article{leben2023explainable,
  title={Explainable AI as evidence of fair decisions},
  author={Leben, Derek},
  journal={Frontiers in Psychology},
  volume={14},
  pages={1069426},
  year={2023},
  publisher={Frontiers Media SA}
}


%----

@article{karimi2020survey,
  title={A survey of algorithmic recourse: definitions, formulations, solutions, and prospects},
  author={Karimi, Amir-Hossein and Barthe, Gilles and Sch{\"o}lkopf, Bernhard and Valera, Isabel},
  journal={arXiv preprint arXiv:2010.04050},
  year={2020}
}
@article{wachter2017counterfactual,
  title={Counterfactual explanations without opening the black box: Automated decisions and the GDPR},
  author={Wachter, Sandra and Mittelstadt, Brent and Russell, Chris},
  journal={Harv. JL \& Tech.},
  volume={31},
  pages={841},
  year={2017},
  publisher={HeinOnline}
}

@article{liao2021human,
  title={Human-centered explainable ai (xai): From algorithms to user experiences},
  author={Liao, Q Vera and Varshney, Kush R},
  journal={arXiv preprint arXiv:2110.10790},
  year={2021}
}
%------


@inproceedings{liu2017oblivious,
  title={Oblivious neural network predictions via minionn transformations},
  author={Liu, Jian and Juuti, Mika and Lu, Yao and Asokan, Nadarajah},
  booktitle={Proceedings of the 2017 ACM SIGSAC conference on computer and communications security},
  pages={619--631},
  year={2017}
}

@inproceedings{srinivasan2019delphi,
  title={DELPHI: A cryptographic inference service for neural networks},
  author={Srinivasan, Wenting Zheng and Akshayaram, PMRL and Ada, Popa Raluca},
  booktitle={Proc. 29th USENIX Secur. Symp},
  pages={2505--2522},
  year={2019}
}

@inproceedings{mohassel2018aby3,
  title={ABY3: A mixed protocol framework for machine learning},
  author={Mohassel, Payman and Rindal, Peter},
  booktitle={Proceedings of the 2018 ACM SIGSAC conference on computer and communications security},
  pages={35--52},
  year={2018}
}

@inproceedings{mohassel2017secureml,
  title={Secureml: A system for scalable privacy-preserving machine learning},
  author={Mohassel, Payman and Zhang, Yupeng},
  booktitle={2017 IEEE symposium on security and privacy (SP)},
  pages={19--38},
  year={2017},
  organization={IEEE}
}

@article{gupta2023sigma,
  title={SIGMA: secure GPT inference with function secret sharing},
  author={Gupta, Kanav and Jawalkar, Neha and Mukherjee, Ananta and Chandran, Nishanth and Gupta, Divya and Panwar, Ashish and Sharma, Rahul},
  journal={Cryptology ePrint Archive},
  year={2023}
}

@inproceedings{boemer2020mp2ml,
  title={MP2ML: A mixed-protocol machine learning framework for private inference},
  author={Boemer, Fabian and Cammarota, Rosario and Demmler, Daniel and Schneider, Thomas and Yalame, Hossein},
  booktitle={Proceedings of the 15th international conference on availability, reliability and security},
  pages={1--10},
  year={2020}
}

@inproceedings{juvekar2018gazelle,
  title={$\{$GAZELLE$\}$: A low latency framework for secure neural network inference},
  author={Juvekar, Chiraag and Vaikuntanathan, Vinod and Chandrakasan, Anantha},
  booktitle={27th USENIX Security Symposium (USENIX Security 18)},
  pages={1651--1669},
  year={2018}
}

@article{blum1983coin,
  title={Coin flipping by telephone a protocol for solving impossible problems},
  author={Blum, Manuel},
  journal={ACM SIGACT News},
  volume={15},
  number={1},
  pages={23--27},
  year={1983},
  publisher={ACM New York, NY, USA}
}

@inproceedings{kate2010constant,
  title={Constant-size commitments to polynomials and their applications},
  author={Kate, Aniket and Zaverucha, Gregory M and Goldberg, Ian},
  booktitle={Advances in Cryptology-ASIACRYPT 2010: 16th International Conference on the Theory and Application of Cryptology and Information Security, Singapore, December 5-9, 2010. Proceedings 16},
  pages={177--194},
  year={2010},
  organization={Springer}
}

@inproceedings{ZKDT,
author = {Zhang, Jiaheng and Fang, Zhiyong and Zhang, Yupeng and Song, Dawn},
title = {Zero Knowledge Proofs for Decision Tree Predictions and Accuracy},
year = {2020},
isbn = {9781450370899},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3372297.3417278},
doi = {10.1145/3372297.3417278},
abstract = {Machine learning has become increasingly prominent and is widely used in various applications in practice. Despite its great success, the integrity of machine learning predictions and accuracy is a rising concern. The reproducibility of machine learning models that are claimed to achieve high accuracy remains challenging, and the correctness and consistency of machine learning predictions in real products lack any security guarantees. In this paper, we initiate the study of zero knowledge machine learning and propose protocols for zero knowledge decision tree predictions and accuracy tests. The protocols allow the owner of a decision tree model to convince others that the model computes a prediction on a data sample, or achieves a certain accuracy on a public dataset, without leaking any information about the model itself. We develop approaches to efficiently turn decision tree predictions and accuracy into statements of zero knowledge proofs. We implement our protocols and demonstrate their efficiency in practice. For a decision tree model with 23 levels and 1,029 nodes, it only takes 250 seconds to generate a zero knowledge proof proving that the model achieves high accuracy on a dataset of 5,000 samples and 54 attributes, and the proof size is around 287 kilobytes.},
booktitle = {Proceedings of the 2020 ACM SIGSAC Conference on Computer and Communications Security},
pages = {2039–2053},
numpages = {15},
keywords = {zero knowledge proofs, machine learning, decision tree},
location = {Virtual Event, USA},
series = {CCS '20}
}

@article{Liu2021zkCNNZK,
  title={zkCNN: Zero Knowledge Proofs for Convolutional Neural Network Predictions and Accuracy},
  author={Tianyi Liu and Xiang Xie and Yupeng Zhang},
  journal={Proceedings of the 2021 ACM SIGSAC Conference on Computer and Communications Security},
  year={2021},
  url={https://api.semanticscholar.org/CorpusID:235349006}
}

@misc{sun2023zkdl,
      title={zkDL: Efficient Zero-Knowledge Proofs of Deep Learning Training}, 
      author={Haochen Sun and Hongyang Zhang},
      year={2023},
      eprint={2307.16273},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}
@article{vCNN,
  title={vCNN: Verifiable Convolutional Neural Network},
  author={Seunghwan Lee and Hankyung Ko and Jihye Kim and Hyunok Oh},
  journal={IACR Cryptol. ePrint Arch.},
  year={2020},
  volume={2020},
  pages={584},
  url={https://api.semanticscholar.org/CorpusID:218895602}
}
@article{Zen,
  title={ZEN: Efficient Zero-Knowledge Proofs for Neural Networks},
  author={Boyuan Feng and Lianke Qin and Zhenfei Zhang and Yufei Ding and Shumo Chu},
  journal={IACR Cryptol. ePrint Arch.},
  year={2021},
  volume={2021},
  pages={87},
  url={https://api.semanticscholar.org/CorpusID:231731893}
}

@misc{kang2022scaling,
      title={Scaling up Trustless DNN Inference with Zero-Knowledge Proofs}, 
      author={Daniel Kang and Tatsunori Hashimoto and Ion Stoica and Yi Sun},
      year={2022},
      eprint={2210.08674},
      archivePrefix={arXiv},
      primaryClass={cs.CR}
}
@article{PvCNN,
author = {Weng, Jiasi and Weng, Jian and Tang, Gui and Yang, Anjia and Li, Ming and Liu, Jia-Nan},
title = {PvCNN: Privacy-Preserving and Verifiable Convolutional Neural Network Testing},
year = {2023},
issue_date = {2023},
publisher = {IEEE Press},
volume = {18},
issn = {1556-6013},
url = {https://doi.org/10.1109/TIFS.2023.3262932},
doi = {10.1109/TIFS.2023.3262932},
abstract = {We propose a new approach for privacy-preserving and verifiable convolutional neural network (CNN) testing in a distrustful multi-stakeholder environment. The approach is aimed to enable that a CNN model developer convinces a user of the truthful CNN performance over non-public data from multiple testers, while respecting model and data privacy. To balance the security and efficiency issues, we appropriately integrate three tools with the CNN testing, including collaborative inference, homomorphic encryption (HE) and zero-knowledge succinct non-interactive argument of knowledge (zk-SNARK). We start with strategically partitioning a CNN model into a private part kept locally by the model developer, and a public part outsourced to an outside server. Then, the private part runs over the HE-protected test data sent by a tester, and transmits its outputs to the public part for accomplishing subsequent computations of the CNN testing. Second, the correctness of the above CNN testing is enforced by generating zk-SNARK based proofs, with an emphasis on optimizing proving overhead for two-dimensional (2-D) convolution operations, since the operations dominate the performance bottleneck during generating proofs. We specifically present a new quadratic matrix program (QMP)-based arithmetic circuit with a single multiplication gate for expressing 2-D convolution operations between multiple filters and inputs in a batch manner. Third, we aggregate multiple proofs with respect to a same CNN model but different testers’ test data (i.e., different statements) into one proof, and ensure that the validity of the aggregated proof implies the validity of the original multiple proofs. Lastly, our experimental results demonstrate that our QMP-based zk-SNARK performs nearly <inline-formula> <tex-math notation="LaTeX">$13.9times $ </tex-math></inline-formula> faster than the existing quadratic arithmetic program (QAP)-based zk-SNARK in proving time, and <inline-formula> <tex-math notation="LaTeX">$17.6times $ </tex-math></inline-formula> faster in Setup time, for high-dimension matrix multiplication. Besides, the limitation on handling a bounded number of multiplications of QAP-based zk-SNARK is relieved.},
journal = {Trans. Info. For. Sec.},
month = {mar},
pages = {2218–2233},
numpages = {16}
}
@misc{VI2,
title={Zator: Verified inference of a 512-layer neural network using recursive SNARKs},
howpublished={\url{https://github.com/lyronctk/zator/tree/main}},
year={2023}}

@article{ghodsi2017safetynets,
  title={Safetynets: Verifiable execution of deep neural networks on an untrusted cloud},
  author={Ghodsi, Zahra and Gu, Tianyu and Garg, Siddharth},
  journal={Advances in Neural Information Processing Systems},
  volume={30},
  year={2017}
}

@inproceedings{weng2021mystique,
  title={Mystique: Efficient conversions for $\{$Zero-Knowledge$\}$ proofs with applications to machine learning},
  author={Weng, Chenkai and Yang, Kang and Xie, Xiang and Katz, Jonathan and Wang, Xiao},
  booktitle={30th USENIX Security Symposium (USENIX Security 21)},
  pages={501--518},
  year={2021}
}

@inproceedings{singh2022zero,
  title={Zero knowledge proofs towards verifiable decentralized ai pipelines},
  author={Singh, Nitin and Dayama, Pankaj and Pandit, Vinayaka},
  booktitle={International Conference on Financial Cryptography and Data Security},
  pages={248--275},
  year={2022},
  organization={Springer}
}

@article{fan2023validating,
  title={Validating the integrity of convolutional neural network predictions based on zero-knowledge proof},
  author={Fan, Yongkai and Xu, Binyuan and Zhang, Linlin and Song, Jinbao and Zomaya, Albert and Li, Kuan-Ching},
  journal={Information Sciences},
  volume={625},
  pages={125--140},
  year={2023},
  publisher={Elsevier}
}

@article{burkhalter2021rofl,
  title={Rofl: Attestable robustness for secure federated learning},
  author={Burkhalter, Lukas and Lycklama, Hidde and Viand, Alexander and K{\"u}chler, Nicolas and Hithnawi, Anwar},
  journal={arXiv preprint arXiv:2107.03311},
  volume={21},
  year={2021}
}

@article{zhao2021veriml,
  title={Veriml: Enabling integrity assurances and fair payments for machine learning as a service},
  author={Zhao, Lingchen and Wang, Qian and Wang, Cong and Li, Qi and Shen, Chao and Feng, Bo},
  journal={IEEE Transactions on Parallel and Distributed Systems},
  volume={32},
  number={10},
  pages={2524--2540},
  year={2021},
  publisher={IEEE}
}

@inproceedings{huang2022zkmlaas,
  title={zkMLaaS: a Verifiable Scheme for Machine Learning as a Service},
  author={Huang, Chenyu and Wang, Jianzong and Chen, Huangxun and Si, Shijing and Huang, Zhangcheng and Xiao, Jing},
  booktitle={GLOBECOM 2022-2022 IEEE Global Communications Conference},
  pages={5475--5480},
  year={2022},
  organization={IEEE}
}

@article{ruckel2022fairness,
  title={Fairness, integrity, and privacy in a scalable blockchain-based federated learning system},
  author={R{\"u}ckel, Timon and Sedlmeir, Johannes and Hofmann, Peter},
  journal={Computer Networks},
  volume={202},
  pages={108621},
  year={2022},
  publisher={Elsevier}
}

@article{confidant,
title={CONFIDENTIAL PROOF OF FAIR TRAINING OF TREES},
journal={ICLR},
author={Ali Shahin Shamsabadi and Sierra Calanda Wyllie and Nicholas Franzese and Natalie Dullerud and Sébastien Gambs and Nicolas Papernot and Xiao Wang and Adrian Weller},
year={2023}}

@inproceedings{Toreini2023VerifiableFP,
  title={Verifiable Fairness: Privacy-preserving Computation of Fairness for Machine Learning Systems},
  author={Ehsan Toreini and Maryam Mehrnezhad and Aad van Moorsel},
  year={2023},
  url={https://api.semanticscholar.org/CorpusID:261696588}
}

@inproceedings{zhang2020zero,
  title={Zero knowledge proofs for decision tree predictions and accuracy},
  author={Zhang, Jiaheng and Fang, Zhiyong and Zhang, Yupeng and Song, Dawn},
  booktitle={Proceedings of the 2020 ACM SIGSAC Conference on Computer and Communications Security},
  pages={2039--2053},
  year={2020}
}

@inproceedings{sun2024zkllm,
  title={zkllm: Zero knowledge proofs for large language models},
  author={Sun, Haochen and Li, Jason and Zhang, Hongyang},
  booktitle={Proceedings of the 2024 on ACM SIGSAC Conference on Computer and Communications Security},
  pages={4405--4419},
  year={2024}
}