\section{Preliminaries}\label{sec:prelims}

\textbf{Cryptographic Primitives.} We use two cryptographic primitives in this paper, commitment schemes and Zero-Knowledge Proofs.

Commitment Scheme \cite{blum1983coin} commits to private inputs $w$ outputting a commitment string $\C_w$. A commitment scheme is \textit{hiding} meaning that $\C_w$ does not reveal anything about private input $w$ and \textit{binding} meaning that there cannot exist another input $w'$ which has the commitment $\C_w$, binding commitment $\C_w$ to input $w$.

Zero-Knowledge Proofs (ZKPs) \cite{GMR, GMW} involve a prover holding a private input $w$, and a verifier who both have access to a circuit $P$. ZKPs enable the prover to convince the verifier that, for some public input $x$, it holds a private witness $w$ such that $P(x, w)=1$ without revealing any additional information about witness $w$ to the verifier. A ZKP protocol is (1) \textit{complete}, meaning that for any inputs $(x, w)$ where $P(x, w)=1$, an honest prover will always be able to convince an honest verifier that $P(x, w)=1$ by correctly following the protocol, (2) \textit{sound}, meaning that beyond a negligible probability, a malicious prover cannot convince an honest verifier for any input $x$, that for some witness $w$, $P(x, w)=1$ when infact such a witness $w$ does not exist, even by arbitrarily deviating from the protocol, and (3) \textit{zero-knowledge}, meaning that for any input $x$ and witness $w$ such that $P(x, w)=1$ , a malicious verifier cannot learn any additional information about witness $w$ except that $P(x, w)=1$ even when arbitrarily deviating from the protocol. A classic result says that any predicate P in the class NP can be verified using ZKPs~\cite{GMW}.


\textbf{LIME.} Existing literature has put forward a wide variety of post-hoc (post-training) explainability techniques to make ML models transparent. In this paper, we focus on one of the popular ones, LIME (stands for Local Interpretable Model-Agnostic Explanations)  \cite{ribeiro2016should}.

LIME explains the prediction for an input point by approximating the local decision boundary around that point with a linear model. Formally, given an input point $x \in \X$, a complex non-interpretable classifier $f : \X \rightarrow \Y$ and an interpretable class of models $\G$, LIME explains the prediction $f(x) \in \Y$ with a local interpretable model $g \in \G$. The interpretable model $g$ is found from the class $\G$ via learning, on a set of points randomly sampled around the input point and weighed according to their distance to the input point, as measured with a similarity kernel $\pi$. The similarity kernel creates a locality around the input by giving higher weights to samples near input $x$ as compared to those far off. A natural and popular choice for the interpretable class of models $\G$ is linear models such that for any $g \in \G$, $g(z) = w_g \cdot z$ (\cite{ribeiro2016should, garreau2020looking}), where $w_g$ are the coefficients of linear model $g$. These coefficients highlight the contribution of each feature towards the prediction and therefore serve as the explanation in LIME. Learning the linear model is formulated as a weighted LASSO problem, since the sparsity induced by $\ell_1$ regularization leads to more interpretable and human-understandable explanations. Following \cite{ribeiro2016should}, the similarity kernel is set to be the exponential kernel with $\ell_2$ norm as the distance function, $\pi_x(z) = \exp \left(-\ell_2(x, z)^2 / \sigma^2\right)$ where $\sigma$ is the bandwidth parameter of the kernel and controls the locality around input $x$.

For brevity, we will denote the coefficients corresponding to the linear model $g$ as $w$ instead of $w_g$, unless otherwise noted. For readers familiar with LIME, without loss of generality we consider the transformation of the points into an interpretable feature space to be identity in this paper for simplicity of exposition. The complete LIME algorithm with linear explanations is given in Alg. \ref{alg:limeinclear}. We will also use `explanations' to mean post-hoc explanations throughout the rest of the paper.


% \begin{algorithm}[tbh]
% \begin{algorithmic}[1]
%  \caption{Linear Explanations with LIME \cite{ribeiro2016should}}
%    \label{alg:limeinclear}
    
%     \STATE {\bfseries Input:} Input point $x$, Interpretable version $x^{\prime}$ of input point, Classifier $f$, Number of points $n$ to be sampled around input point, Similarity kernel $\pi_x$, Length of explanation $K$

%     \STATE  {\bfseries Output:} Explanation $e$
    
%     \STATE Initialize set of points $\mathcal{Z} \leftarrow\{\}$
    
%     \FOR{$i \in\{1,2,3, \ldots, n\}$}
%         \STATE $z_i, z_i^{\prime} \leftarrow$ \rm{sample\_around}$\left(x^{\prime}\right)$
%         \STATE $\pi_i \leftarrow \pi_x\left(z_i\right)$
%         %\STATE $\mathcal{Z} \leftarrow \mathcal{Z} \cup\left\langle z_i^{\prime}, f\left(z_i\right), \pi_x\left(z_i\right)\right\rangle$
%     \ENDFOR

%     %\STATE $w \leftarrow \mathrm{K}$-Lasso $(\mathcal{Z}, K)$ \hfill \textcolor{blue}{$\triangleright$} with $z_i^{\prime}$ as features, $f(z)$ as target
%     \STATE $\hat{w} \in \arg \min _{w \in \mathbb{R}^{d+1}} \sum_{i=1}^n \pi_i \times \left(f\left(z_i\right)-w^{\top} z_i^{\prime}\right)^2+\|w\|_1$

%     \STATE e := top-K$(\hat{w}, K)$ \hfill \textcolor{blue}{$\rhd$} Sorts the weights according to absolute value \& returns these along with corresponding features
    
%     \STATE Return Explantion $e$
    
% \end{algorithmic}
% \end{algorithm}

\begin{algorithm}[tbh]
\begin{algorithmic}[1]
 \caption{\textsc{LIME} \cite{ribeiro2016should}}
   \label{alg:limeinclear}
    
    \STATE {\bfseries Input:} Input point $x$, Classifier $f$
    \STATE {\bfseries Parameters:} Number of points $n$ to be sampled around input point, Length of explanation $K$, Bandwidth parameter $\sigma$ for similarity kernel
    \STATE  {\bfseries Output:} Explanation $e$
    \STATE
    %\STATE Initialize set of points $\mathcal{Z} \leftarrow\{\}$
    
    \FOR{$i \in\{1,2,3, \ldots, n\}$}
        \STATE $z_i \leftarrow$ \rm{sample\_around}$\left(x\right)$
        \STATE $\pi_i \leftarrow \exp \left(-\ell_2(x, z_i)^2 / \sigma^2\right)$ %\pi_x\left(z_i\right)$
        %\STATE $\mathcal{Z} \leftarrow \mathcal{Z} \cup\left\langle z_i^{\prime}, f\left(z_i\right), \pi_x\left(z_i\right)\right\rangle$
    \ENDFOR

    %\STATE $w \leftarrow \mathrm{K}$-Lasso $(\mathcal{Z}, K)$ \hfill \textcolor{blue}{$\triangleright$} with $z_i^{\prime}$ as features, $f(z)$ as target
    \STATE $\hat{w} \in \arg \min _{w} \sum_{i=1}^n \pi_i \times \left(f\left(z_i\right)-w^{\top} z_i\right)^2+\|w\|_1$

    \STATE $e :=$ top-K$(\hat{w}, K)$ \hfill \textcolor{blue}{$\rhd$} Sorts the weights according to absolute value \& returns these along with corresponding features
    
    \STATE Return Explanation $e$
\end{algorithmic}
\end{algorithm}

\begin{algorithm}[tbh]
\begin{algorithmic}[1]
 \caption{\textsc{Standard\_Lime\_Variants}}
   \label{alg:limevarinclear}
    
    \STATE {\bfseries Input:} Input point $x$, Classifier $f$
    \STATE {\bfseries Parameters:} Number of points $n$ to be sampled around input point, Length of explanation $K$, Bandwidth parameter $\sigma$ for similarity kernel, sampling type $smpl\_type$, kernel type $krnl\_type$
    \STATE  {\bfseries Output:} Explanation $e$
    \STATE
    %\STATE Initialize set of points $\mathcal{Z} \leftarrow\{\}$
    
    \FOR{$i \in\{1,2,3, \ldots, n\}$}
    \IF{$smpl\_type$==`uniform'}
        \STATE $z_i \leftarrow$ \rm{uniformly\_sample\_around}$\left(x\right)$
    \ELSIF{$smpl\_type$==`gaussian'}
        \STATE $z_i \leftarrow$ \rm{gaussian\_sample\_around}$\left(x\right)$
    \ENDIF

    \IF{$krnl\_type$==`exponential'}
        \STATE $\pi_i \leftarrow \exp \left(-\ell_2(x, z_i)^2 / \sigma^2\right)$
    \ELSE
        \STATE $\pi_i = 1$
    \ENDIF
        %\pi_x\left(z_i\right)$
        %\STATE $\mathcal{Z} \leftarrow \mathcal{Z} \cup\left\langle z_i^{\prime}, f\left(z_i\right), \pi_x\left(z_i\right)\right\rangle$
    \ENDFOR

    %\STATE $w \leftarrow \mathrm{K}$-Lasso $(\mathcal{Z}, K)$ \hfill \textcolor{blue}{$\triangleright$} with $z_i^{\prime}$ as features, $f(z)$ as target
    \STATE $\hat{w} \in \arg \min _{w} \sum_{i=1}^n \pi_i \times \left(f\left(z_i\right)-w^{\top} z_i\right)^2+\|w\|_1$

    \STATE $e :=$ top-K$(\hat{w}, K)$
    
    \STATE Return Explanation $e$
\end{algorithmic}
\end{algorithm}