@article{Liu2021zkCNNZK,
  title={zkCNN: Zero Knowledge Proofs for Convolutional Neural Network Predictions and Accuracy},
  author={Tianyi Liu and Xiang Xie and Yupeng Zhang},
  journal={Proceedings of the 2021 ACM SIGSAC Conference on Computer and Communications Security},
  year={2021},
  url={https://api.semanticscholar.org/CorpusID:235349006}
}

@article{PvCNN,
author = {Weng, Jiasi and Weng, Jian and Tang, Gui and Yang, Anjia and Li, Ming and Liu, Jia-Nan},
title = {PvCNN: Privacy-Preserving and Verifiable Convolutional Neural Network Testing},
year = {2023},
issue_date = {2023},
publisher = {IEEE Press},
volume = {18},
issn = {1556-6013},
url = {https://doi.org/10.1109/TIFS.2023.3262932},
doi = {10.1109/TIFS.2023.3262932},
abstract = {We propose a new approach for privacy-preserving and verifiable convolutional neural network (CNN) testing in a distrustful multi-stakeholder environment. The approach is aimed to enable that a CNN model developer convinces a user of the truthful CNN performance over non-public data from multiple testers, while respecting model and data privacy. To balance the security and efficiency issues, we appropriately integrate three tools with the CNN testing, including collaborative inference, homomorphic encryption (HE) and zero-knowledge succinct non-interactive argument of knowledge (zk-SNARK). We start with strategically partitioning a CNN model into a private part kept locally by the model developer, and a public part outsourced to an outside server. Then, the private part runs over the HE-protected test data sent by a tester, and transmits its outputs to the public part for accomplishing subsequent computations of the CNN testing. Second, the correctness of the above CNN testing is enforced by generating zk-SNARK based proofs, with an emphasis on optimizing proving overhead for two-dimensional (2-D) convolution operations, since the operations dominate the performance bottleneck during generating proofs. We specifically present a new quadratic matrix program (QMP)-based arithmetic circuit with a single multiplication gate for expressing 2-D convolution operations between multiple filters and inputs in a batch manner. Third, we aggregate multiple proofs with respect to a same CNN model but different testers’ test data (i.e., different statements) into one proof, and ensure that the validity of the aggregated proof implies the validity of the original multiple proofs. Lastly, our experimental results demonstrate that our QMP-based zk-SNARK performs nearly <inline-formula> <tex-math notation="LaTeX">$13.9times $ </tex-math></inline-formula> faster than the existing quadratic arithmetic program (QAP)-based zk-SNARK in proving time, and <inline-formula> <tex-math notation="LaTeX">$17.6times $ </tex-math></inline-formula> faster in Setup time, for high-dimension matrix multiplication. Besides, the limitation on handling a bounded number of multiplications of QAP-based zk-SNARK is relieved.},
journal = {Trans. Info. For. Sec.},
month = {mar},
pages = {2218–2233},
numpages = {16}
}

@inproceedings{Toreini2023VerifiableFP,
  title={Verifiable Fairness: Privacy-preserving Computation of Fairness for Machine Learning Systems},
  author={Ehsan Toreini and Maryam Mehrnezhad and Aad van Moorsel},
  year={2023},
  url={https://api.semanticscholar.org/CorpusID:261696588}
}

@misc{VI2,
title={Zator: Verified inference of a 512-layer neural network using recursive SNARKs},
howpublished={\url{https://github.com/lyronctk/zator/tree/main}},
year={2023}}

@inproceedings{ZKDT,
author = {Zhang, Jiaheng and Fang, Zhiyong and Zhang, Yupeng and Song, Dawn},
title = {Zero Knowledge Proofs for Decision Tree Predictions and Accuracy},
year = {2020},
isbn = {9781450370899},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3372297.3417278},
doi = {10.1145/3372297.3417278},
abstract = {Machine learning has become increasingly prominent and is widely used in various applications in practice. Despite its great success, the integrity of machine learning predictions and accuracy is a rising concern. The reproducibility of machine learning models that are claimed to achieve high accuracy remains challenging, and the correctness and consistency of machine learning predictions in real products lack any security guarantees. In this paper, we initiate the study of zero knowledge machine learning and propose protocols for zero knowledge decision tree predictions and accuracy tests. The protocols allow the owner of a decision tree model to convince others that the model computes a prediction on a data sample, or achieves a certain accuracy on a public dataset, without leaking any information about the model itself. We develop approaches to efficiently turn decision tree predictions and accuracy into statements of zero knowledge proofs. We implement our protocols and demonstrate their efficiency in practice. For a decision tree model with 23 levels and 1,029 nodes, it only takes 250 seconds to generate a zero knowledge proof proving that the model achieves high accuracy on a dataset of 5,000 samples and 54 attributes, and the proof size is around 287 kilobytes.},
booktitle = {Proceedings of the 2020 ACM SIGSAC Conference on Computer and Communications Security},
pages = {2039–2053},
numpages = {15},
keywords = {zero knowledge proofs, machine learning, decision tree},
location = {Virtual Event, USA},
series = {CCS '20}
}

@article{Zen,
  title={ZEN: Efficient Zero-Knowledge Proofs for Neural Networks},
  author={Boyuan Feng and Lianke Qin and Zhenfei Zhang and Yufei Ding and Shumo Chu},
  journal={IACR Cryptol. ePrint Arch.},
  year={2021},
  volume={2021},
  pages={87},
  url={https://api.semanticscholar.org/CorpusID:231731893}
}

@article{abbaszadeh2024zero,
  title={Zero-knowledge proofs of training for deep neural networks},
  author={Abbaszadeh, Kasra and Pappas, Christodoulos and Katz, Jonathan and Papadopoulos, Dimitrios},
  journal={Cryptology ePrint Archive},
  year={2024}
}

@article{burkhalter2021rofl,
  title={Rofl: Attestable robustness for secure federated learning},
  author={Burkhalter, Lukas and Lycklama, Hidde and Viand, Alexander and K{\"u}chler, Nicolas and Hithnawi, Anwar},
  journal={arXiv preprint arXiv:2107.03311},
  volume={21},
  year={2021}
}

@inproceedings{chen2024zkml,
  title={ZKML: An Optimizing System for ML Inference in Zero-Knowledge Proofs},
  author={Chen, Bing-Jyue and Waiwitlikhit, Suppakit and Stoica, Ion and Kang, Daniel},
  booktitle={Proceedings of the Nineteenth European Conference on Computer Systems},
  pages={560--574},
  year={2024}
}

@article{confidant,
title={CONFIDENTIAL PROOF OF FAIR TRAINING OF TREES},
journal={ICLR},
author={Ali Shahin Shamsabadi and Sierra Calanda Wyllie and Nicholas Franzese and Natalie Dullerud and Sébastien Gambs and Nicolas Papernot and Xiao Wang and Adrian Weller},
year={2023}}

@article{fan2023validating,
  title={Validating the integrity of convolutional neural network predictions based on zero-knowledge proof},
  author={Fan, Yongkai and Xu, Binyuan and Zhang, Linlin and Song, Jinbao and Zomaya, Albert and Li, Kuan-Ching},
  journal={Information Sciences},
  volume={625},
  pages={125--140},
  year={2023},
  publisher={Elsevier}
}

@inproceedings{garg2023experimenting,
  title={Experimenting with zero-knowledge proofs of training},
  author={Garg, Sanjam and Goel, Aarushi and Jha, Somesh and Mahloujifar, Saeed and Mahmoody, Mohammad and Policharla, Guru-Vamsi and Wang, Mingyuan},
  booktitle={Proceedings of the 2023 ACM SIGSAC Conference on Computer and Communications Security},
  pages={1880--1894},
  year={2023}
}

@inproceedings{huang2022zkmlaas,
  title={zkMLaaS: a Verifiable Scheme for Machine Learning as a Service},
  author={Huang, Chenyu and Wang, Jianzong and Chen, Huangxun and Si, Shijing and Huang, Zhangcheng and Xiao, Jing},
  booktitle={GLOBECOM 2022-2022 IEEE Global Communications Conference},
  pages={5475--5480},
  year={2022},
  organization={IEEE}
}

@misc{kang2022scaling,
      title={Scaling up Trustless DNN Inference with Zero-Knowledge Proofs}, 
      author={Daniel Kang and Tatsunori Hashimoto and Ion Stoica and Yi Sun},
      year={2022},
      eprint={2210.08674},
      archivePrefix={arXiv},
      primaryClass={cs.CR}
}

@article{ruckel2022fairness,
  title={Fairness, integrity, and privacy in a scalable blockchain-based federated learning system},
  author={R{\"u}ckel, Timon and Sedlmeir, Johannes and Hofmann, Peter},
  journal={Computer Networks},
  volume={202},
  pages={108621},
  year={2022},
  publisher={Elsevier}
}

@inproceedings{singh2022zero,
  title={Zero knowledge proofs towards verifiable decentralized ai pipelines},
  author={Singh, Nitin and Dayama, Pankaj and Pandit, Vinayaka},
  booktitle={International Conference on Financial Cryptography and Data Security},
  pages={248--275},
  year={2022},
  organization={Springer}
}

@misc{sun2023zkdl,
      title={zkDL: Efficient Zero-Knowledge Proofs of Deep Learning Training}, 
      author={Haochen Sun and Hongyang Zhang},
      year={2023},
      eprint={2307.16273},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@inproceedings{sun2024zkllm,
  title={zkllm: Zero knowledge proofs for large language models},
  author={Sun, Haochen and Li, Jason and Zhang, Hongyang},
  booktitle={Proceedings of the 2024 on ACM SIGSAC Conference on Computer and Communications Security},
  pages={4405--4419},
  year={2024}
}

@article{vCNN,
  title={vCNN: Verifiable Convolutional Neural Network},
  author={Seunghwan Lee and Hankyung Ko and Jihye Kim and Hyunok Oh},
  journal={IACR Cryptol. ePrint Arch.},
  year={2020},
  volume={2020},
  pages={584},
  url={https://api.semanticscholar.org/CorpusID:218895602}
}

@misc{yadav2024fairproofconfidentialcertifiable,
      title={FairProof : Confidential and Certifiable Fairness for Neural Networks}, 
      author={Chhavi Yadav and Amrita Roy Chowdhury and Dan Boneh and Kamalika Chaudhuri},
      year={2024},
      eprint={2402.12572},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2402.12572}, 
}

@inproceedings{zhang2020zero,
  title={Zero knowledge proofs for decision tree predictions and accuracy},
  author={Zhang, Jiaheng and Fang, Zhiyong and Zhang, Yupeng and Song, Dawn},
  booktitle={Proceedings of the 2020 ACM SIGSAC Conference on Computer and Communications Security},
  pages={2039--2053},
  year={2020}
}

