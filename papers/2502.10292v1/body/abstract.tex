
In order to develop practical and efficient algorithms while circumventing overly pessimistic computational lower bounds, recent work has been interested in developing \emph{oracle-efficient} algorithms in a variety of learning settings.  Two such settings of particular interest are online and differentially private learning.
While seemingly different, these two fields are fundamentally connected by the requirement that successful algorithms in each case satisfy stability guarantees; in particular, recent work has demonstrated that algorithms for online learning whose performance adapts to beneficial problem instances, attaining the so-called \emph{small-loss bounds}, require a form of stability similar to that of differential privacy.  In this work, we identify the crucial role that \emph{separation} plays in allowing oracle-efficient algorithms to achieve this strong stability.  Our notion, which we term $\rho$-separation, generalizes and unifies several previous approaches to enforcing this strong stability, including the existence of small-separator sets and the recent notion of $\gamma$-approximability.  We present an oracle-efficient algorithm that is capable of achieving small-loss bounds with improved rates in greater generality than previous work, as well as a variant for differentially private learning that attains optimal rates, again under our separation condition.  In so doing, we prove a new stability result for minimizers of a Gaussian process that strengthens and generalizes previous work. \looseness=-1
