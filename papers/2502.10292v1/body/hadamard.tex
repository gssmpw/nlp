

\subsection{Proof of Proposition \ref{prop:hadamard_gap}}
\label{sec:hadamard_gap}

In order to compare our result to that of \citet{wang2022adaptive}, we consider the class of all linear functions over $\mathbb{F}_2^n$ which we refer to as the Hadamard class $\mathcal{F}_{\mathrm{Had}}$, which we now define. 

\begin{definition}[Hadamard Class]
    Let the domain be $ \mathbb{F}_2^n $ i.e. the set of all $n$-bit strings with addition modulo 2.
    The Hadamard class $\mathcal{F}_{\mathrm{Had}}$ is the set of all linear functions $f_y: \mathbb{F}_2^n \to \mathbb{F}_2 $ given by $f_y(x) = \inprod{x}{y}$ for $y \in \mathbb{F}_2^n$.
\end{definition}

By standard abuse of notation, we will associate the output $ \mathbb{F}_2 $ with $ \left\{ 0,1 \right\} \subset \mathbb{R} $.   
We first note that this class is $\rho$-separated by the uniform distribution on $\mathbb{F}_2^n$ with $\rho = 1/\sqrt{2}$. 
This follows from the fact that for any $y \neq 0 $, there exists $\mathbb{P}_{x \sim \mathbb{F}_2^n } ( \inprod{x}{y} = 0 ) = 1/2  $.
While one can show with a similar argument $\gamma$-approximability parameter of this class is $ \gamma = O(1) $, note that lead term in the regret bound \Cref{eq:wang_regret} survives even if we set $\gamma = 0$.
Thus, evaluating the regret bound of \citet{wang2022adaptive} for this class, we find that using their algorithm and plugging in \eqref{eq:wang_regret}, regret is bounded as
\begin{align}
    \ee\left[ \reg_T \right]\lesssim \left( n + \sqrt{n 2^n}\right) \cdot \left(1 + \sqrt{\Lstar} \right).
\end{align}  
On the other hand, if we use \Cref{alg:ftpl}, we see by \Cref{thm:lstar_online} that
\begin{align}\label{eq:hadamard_guassian}
    \ee\left[ \reg_T \right] \lesssim 1 + n \log(T) +  \sqrt{n \log(T) \Lstar},
\end{align}
which is an exponential improvement in $n$ in regret.  While this separation is extreme, the size of the separating set is $2^n$,  where $n$ can be considered the natural parametrization of the size of the problem, and thus the oracle complexity of both algorithms is exponential. 

We can modify the construction, however, to preserve a separation while keeping the oracle complexity polynomial.  Indeed, note that if we  consider the set $ \tilde{\mathcal{X}} = \left\{ e_i  \right\} $ where $e_i$ are the standard basis vectors of $ \mathbb{F}_2^n $, then for the uniform distribution over $ \tilde{\mathcal{X}} $, the class $ \mathcal{F}_{\mathrm{Had}} $ is $ \rho $-separated with $ \rho = 1/ \sqrt{2} $ for the same reason as before.
In this case, the regret bound of \citet{wang2022adaptive} becomes
\begin{align}
    \ee\left[ \reg_T \right] \lesssim   \left( 1 + n \right) \cdot \left(1 +  \sqrt{\Lstar} \right), 
\end{align}
while the bound from \Cref{thm:lstar_online} remains as in \eqref{eq:hadamard_guassian}.  This translates to a $\sqrt{n}$ improvement in the leading term of the regret bound of our algorithm over that of \citet{wang2022adaptive}.













