\section{Use Case 2: \\ Safe Teleoperation With Simulated Robot}\label{sec: usecase_safe_teleop_sim}

\begin{figure*}[htbp]
    \centering
    \vspace{1.5cm}  % Optional vertical space
    \begin{tikzpicture}[transform canvas={xshift=0cm}]
        % Define image size and spacing
        \def\imgwidth{15cm}  % Image width
        \def\ygap{-4} % Y-axis spacing (vertical)

        % First subfigure (Teleop 1)
        \node at (0, 0) {\includegraphics[width=\imgwidth]{figure/simulation/cabinet_sim.png}};
        % \node at (0, -2);
        % % Second subfigure (Teleop 2)
        % \node at (0, \ygap) {\includegraphics[width=\imgwidth]{figure/real_robot/cabinet_teleop.png}};
        % \node at (0, \ygap-2) {\small (b)};

    \end{tikzpicture}
    \vspace{1.5cm}
    \caption{\ref{sec: usecase_safe_teleop_sim} The first two illustrate how the robot’s hands successfully reach into a confined cabinet under user teleoperation. In the fourth figure, even when the green spheres—representing the target positions for teleoperation—move outside the cabinet, the robot’s hands stay within the safe region. This demonstrates the controller’s ability to enforce safety constraints while following user commands.}
    \label{fig: safe_teleop_sim}
\end{figure*}

\begin{figure*}[htbp]
    \centering
    \vspace{1.5cm}  % Optional vertical space
    \begin{tikzpicture}[transform canvas={xshift=0cm}] 
        % Define image size and spacing
        \def\imgwidth{15cm}  % Image width
        \def\ygap{-3} % Y-axis spacing (vertical)

        % First subfigure
        \node at (0, 0) {\includegraphics[width=\imgwidth]{figure/real_robot/Static_1.png}};


        % Second subfigure
        \node at (0, \ygap) {\includegraphics[width=\imgwidth]{figure/real_robot/Static_2.png}};


    \end{tikzpicture}
    \vspace{4.5cm}
    \caption{\ref{sec: usecase_safe_auto_real} Limb-level collision avoidance with static humanoid reference pose: the robot moves away when the human hand gets closer than \( d_{\min} \) and resumes its target position once the hand retreats and the environment is safe.
}
    \label{Static}
\end{figure*}

\begin{figure*}[htbp]
    \centering
    \vspace{1.5cm}  % Optional vertical space
    \begin{tikzpicture}[transform canvas={xshift=0cm}]
        % Define image size and spacing
        \def\imgwidth{15cm}  % Image width
        \def\ygap{-4} % Y-axis spacing (vertical)

        % First subfigure (Teleop 1)
        \node at (0, 0) {\includegraphics[width=\imgwidth]{figure/real_robot/teleop_1_masked.jpg}{}};
         % Second subfigure (Teleop 2)
        \node at (0, -3)
        {\includegraphics[width=\imgwidth]{figure/real_robot/teleop_2_masked.jpg}{}};

    \end{tikzpicture}
    \vspace{4.5cm}
    \caption{\ref{sec: usecase_safe_teleop_real} Limb-level collision avoidance with teleoperation commands: if the human user reaches for the same object as the robot, the safe controller is triggered, prioritizing collision avoidance over teleoperation commands to ensure safe interaction and prevent hazards from limited remote perception.
}
    \label{Teleop}
\end{figure*}

This section presents a user scenario in which teleoperation is performed within a simulation environment to collect human data in the absence of available hardware~\cite{wang2024teleophri,nechyporenko2024armadaaugmentedrealityrobot,chen2024arcapcollectinghighqualityhuman}. 

To meet this requirement, we configure the robot with \texttt{G1fixedBase} while selecting the simulation agent in \spark. 
By designing a \textbf{Task} module where a cabinet acts as an obstacle and the human teleoperation serves as the task goal—while taking human input through an external Apple Vision Pro block—we can retain the same \textbf{Policy} and \textbf{Safety} modules as in the previous use case (\Cref{sec: usecase_safe_teleop_real}).  

From the first two figures in \Cref{fig: safe_teleop_sim}, we observe that the robot’s hands can maneuver into a confined cabinet under user teleoperation. 
In the fourth figure, we see that when the green spheres—representing the teleoperation target positions for the hands—move outside the cabinet, the robot's hands remain inside to ensure safety, demonstrating the effectiveness of the safe controller.  

This scenario highlights the flexibility of \spark in integrating human input with simulated robots. 
It not only guarantees absolute safety for algorithm verification but also provides users with richer visual feedback that cannot be directly obtained from real robot teleoperation, such as the spatial relationship between the robot's hands and obstacles. 
Moreover, it offers an intuitive and efficient way to collect human demonstration data without relying on real robot hardware.  
