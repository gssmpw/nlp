\section{Is High Sensitivity Inevitable?}\seclab{sec:kolmogorov}

Based on the results of Lagarde and Perifel \cite{lagarde2018lempel}, one might wonder whether or not any effective compression mechanism will necessarily have \emph{high} global sensitivity. We argue that this is not necessarily the case by considering \emph{Kolmogorov compression}. The Kolmogorov compression of an input string $w$ is simply the encoding of the minimum-size Turing Machine $M$ such that the Turing Machine $M$ will eventually output $w$ when run with an initially empty input tape. It is also easy to see that the Kolmogorov compression scheme has low global sensitivity $\O{\log n}$  for strings of length $n$ as was previously noted in \cite{AFI23}. Let $\kc:\Sigma^*\rightarrow\mathfrak{M}$ be the Kolmogorov compression where $\mathfrak{M}$ is the set of all Turing machines. For a string $w\in\Sigma^n$, suppose that $\kc(w)=M\in\mathfrak{M}$. Then for a string $w'\sim w$ that differs on the $i\th$ bit, one can obtain $M'$ which outputs $w'$ by (1) running $M$ to obtain $w$, and (2) flipping the $i\th$ bit of $w$ to obtain $w'$. Then the description of $M'$ needs the description of $M$ and $i$ plus some constant. Since it takes $\log n$ bits to encode $i$, It follows that $\kc(w') \leq \left| M'\right| \leq |M| + \O{\log n} = \kc(w) + \O{\log n}$. In particular, the global sensitivity of Kolmogorov compression is upper bounded $\O{\log n}$. While  Kolmogorov compression is not computable, when it comes to efficient compression ratios, Kolmogorov compression is at least as effective as any other compression scheme, i.e., for any compression scheme $\compress$ there is a universal constant $C$ such that $\left|\kc(w)\right| \leq C + \left|\compress(w)\right|$ for all string $w \in \Sigma^*$.\footnote{The Turing Machine $M$ can implement any decompression algorithm. We can hardcode $z=\compress(w)$ to obtain a new machine $M_z$ which simulates $M$ on the input $z$ to recover $w$.} Thus, the goal of designing a compression algorithm with low global sensitivity does not need to be inconsistent with the goal of designing a compression algorithm that achieves good compression rates. 



We note that one can construct a \emph{computable} variant of Kolmogorov compression $\ckc$ that preserves low global sensitivity and is competitive with any efficiently computable compression algorithm although the compression algorithm $\ckc$ itself is computationally inefficient. Instead of outputting the minimum-size Turing machine, one can output the \emph{minimum-score} Turing machine $M$ followed by $1\circ 0^{\log t_M}$ (where $t_M$ is the running time of the machine $M$), where the \emph{score} of a Turing machine $M$ is defined as $\score(M)\coloneqq|M|+1+\log t_M$. Since the length of the compression becomes the score of the minimum-score Turing machine, one can similarly argue that this computable variant of Kolmogorov compression has global sensitivity $\O{\log n}$. It is also easy to see that the compression rate for our computable variant of Kolmogorov compression is at least as good as {\em any} efficiently computable compression algorithm, i.e., for any compression scheme $\compress$ running in time $\O{n^c}$ for some constant $c$ and {\em any} string $w \in \Sigma^n$ we have  $|\ckc(w)| \leq |\compress(w)| + \log n^c + \O{1} = |\compress(w)| + \O{\log n}$. This implies that a compression scheme which achieves good compression ratios does not necessarily have high global sensitivity. 

\newcommand{\kolcomp}{
Let $\ckc:\Sigma^*\rightarrow\mathfrak{M}\times\bin^*$ be the computable variant of Kolmogorov compression. Then $\GS_\ckc(n)=\O{\log n}$.
}
\begin{proposition}\proplab{prop:ckc}
    \kolcomp
\end{proposition}

\begin{proof}[Proof Sketch] (See \appref{app:kolcompression} for a more rigorous proof.)
    For a string $w\in\Sigma^n$, suppose that $\ckc(w)=(M,1\circ0^{t_M})$ where $M$ is the minimum-score Turing Machine that outputs $w$ running in time $t_M$. For $w'\sim w$ that differs on the $i\th$ bit, one can obtain a Turing Machine $M'$ that outputs $w'$ by running $M$ to obtain $w$ and then flipping the $i\th$ bit of $w$ to obtain $w'$. 
    Then the running time of $M'$ is $t_{M'}=t_M+\O{n}$. Furthermore, the description of $M'$ needs the description of $M$ plus $i$ plus some constant, which implies $|M'|\leq|M|+\O{\log n}$ since it takes $\log n$ bits to encode $i$.

    Let $\ckc(w')=(M'',1\circ0^{t_{M''}})$ where $M''$ is the minimum-score Turing Machine that outputs $w'$ with running time $t_{M''}$. Then by definition, we have $\score(M'')\leq\score(M')$. Hence,
    \begin{align*}
        |\ckc(w')| &= |M''|+1+\log t_{M''}   =\score(M'')
        \leq \score(M')  = |M'|+1+\log t_{M'} \\
         &\leq |M|+\O{\log n} + \log(t_M+\O{n})         \leq |M|+ \log t_M + \O{\log n} \\
         &         =|\ckc(w)| + \O{\log n},
    \end{align*}
    which implies $\displaystyle\GS_\ckc(n)=\max_{w\in\Sigma^n}\max_{w':w\sim w'}||\ckc(w)|-|\ckc(w')||=\O{\log n}$. Note that $\log(t_M+\O{n})\leq\max\{\log t_M,\log\O{n}\}+1$ and the last inequality above holds whatever the maximum is between $\log t_M$ and $\log\O{n}$. 
\end{proof}