\section{Differentially Private Compression}\seclab{sec:dpcompress}

In this section, we present a general framework that transforms any compression scheme $\compress:\Sigma^*\rightarrow(\Sigma')^*$ to another compression scheme called $\dpcompress:\Sigma^*\times\mathbb{R}\times\mathbb{R}\rightarrow(\Sigma')^*$ such that for any $\epsilon>0$ and $\delta \in(0,1)$, the algorithm  $A_{\epsilon,\delta}(w) \coloneqq \dpcompress(w,\epsilon,\delta)$ is a $(\epsilon,\delta)$-differentially private compression algorithm. Intuitively, $\dpcompress(w,\epsilon,\delta)$ works by running $\compress(w)$ and adding a random amount of padding. In particular, $\dpcompress(w,\epsilon,\delta)$ outputs $\compress(w) \circ 0\circ 1^{p-1}$ where $p$ is a random variable defined as follows: $p=\max\left\{1, \lceil Z+k\rceil \right\}$: where $Z\sim\Lap(\GS_\compress/\epsilon)$ is a random variable following Laplace distribution with mean $0$ and scale parameter $\GS_\compress/\epsilon$ and $k=\frac{\GS_\compress}{\epsilon}\ln(\frac{1}{2\delta})+\GS_\compress +1$ is a constant (see \algref{algorithm:DPCompress}). The decompression algorithm works straightforwardly as it is easy to remove padding $0\circ 1^{p-1}$ even though one does not know $p$, i.e., given the compressed string $\dpcompress(w,\epsilon,\delta)=\compress(w)\circ0\circ1^{p-1}$, we could start removing $1$'s from the right until we see $0$. After removing the $0$ as well, we get $\compress(w)$. Now we could obtain $w$ by calling $\decompress(\compress(w))$.


Intuitively, the output $Z+\left|\compress(w) \right|$ preserves $\epsilon$-DP since this is just the standard Laplacian Mechanism and the output $\lceil Z+\left|\compress(w) \right| + k\rceil =  \left|\compress(w) \right| + \lceil Z+k\rceil$ also preserves $\epsilon$-DP since it can be viewed as post-processing applied to a DP output. Finally, note that by our choice of $k$ we have $\Pr[p \neq \lceil Z+k\rceil ] =  \Pr[Z+k \leq 0] \leq \delta$. It follows that the output $\left|\compress(w) \right| + p$ preserves $(\epsilon,\delta)$-DP, as shown in \thmref{theorem_dp}.

\begin{algorithm}[ht!]
\caption{$\dpcompress(w, \epsilon, \delta)$}
\begin{algorithmic}%[\ref{algorithm:DPCompress}]

    
    \State \textbf{Input:} $w,\epsilon,\delta$

    \State \textbf{Output:} Differentially Private Padded Data.
    
    
    \State $Z \gets \Lap\left(\frac{\GS_\compress}{\epsilon}\right)$ 
    
    
    \State $k$ $\gets$ $\frac{\GS_\compress}{\epsilon}\ln(\frac{1}{2\delta})+\GS_\compress +1$ 
    
    \State $p \gets \max\left\{1, \lceil Z+k\rceil \right\}$ 
    
    
    \State \textbf{Return} $\pad(\compress(w), p) \coloneqq \compress(w)\circ0\circ1^{p-1}$
\end{algorithmic}\alglab{algorithm:DPCompress}
\end{algorithm}

\newcommand{\dptheorem}{Define $A_{\epsilon,\delta}(w) \coloneqq \dpcompress(w,\epsilon,\delta)$ then, For any $\epsilon, \delta >0$, $A_{\epsilon,\delta}$ is a  $(\epsilon,\delta)$-differentially private compression scheme. % $\lapalg(w,\epsilon,\delta)\coloneqq|\dpcompress(w,\epsilon,\delta)|$ is $(\epsilon,\delta)$-differentially private.
}

\begin{theorem}\thmlab{theorem_dp}
    \dptheorem
\end{theorem}

The proof of \thmref{theorem_dp} is straightforward using standard DP techniques and therefore is deferred to \appref{app:dpcompress}.

On average, the amount of padding added is approximately $k=\frac{\GS_\compress}{\epsilon}\ln(\frac{1}{2\delta})+\GS_\compress +1$. If $k  = o(n)$ then it will still be possible for $\dpcompress$ to achieve efficient compression ratios, i.e., $\left| \dpcompress(w,\epsilon,\delta) \right|/ n = \left| \compress(w) \right|/ n + o(1)$. On the other hand, if $k = \Omega(n)$ then the padding alone will prevent us from achieving a compression ratio of $o(1)$. Thus, our hope is to find practical compression schemes with global sensitivity $\GS_\compress = o(n)$ --- LZ78~\cite{LZ78} does not satisfy these criteria \cite{lagarde2018lempel}. This motivates our study of the global sensitivity of the LZ77 compression scheme \cite{LZ77} --- see \secref{sec:upperbound} for details.


