%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%2345678901234567890123456789012345678901234567890123456789012345678901234567890
%        1         2         3         4         5         6         7         8

\documentclass[letterpaper, 10 pt, conference]{ieeeconf}  % Comment this line out if you need a4paper

%\documentclass[a4paper, 10pt, conference]{ieeeconf}      % Use this line for a4 paper

\IEEEoverridecommandlockouts                              % This command is only needed if 
                                                          % you want to use the \thanks command

\overrideIEEEmargins                                      % Needed to meet printer requirements.

%In case you encounter the following error:
%Error 1010 The PDF file may be corrupt (unable to open PDF file) OR
%Error 1000 An error occurred while parsing a contents stream. Unable to analyze the PDF file.
%This is a known problem with pdfLaTeX conversion filter. The file cannot be opened with acrobat reader
%Please use one of the alternatives below to circumvent this error by uncommenting one or the other
%\pdfobjcompresslevel=0
%\pdfminorversion=4

% See the \addtolength command later in the file to balance the column lengths
% on the last page of the document

% The following packages can be found on http:\\www.ctan.org
\usepackage{graphics} % for pdf, bitmapped graphics files
\usepackage{epsfig} % for postscript graphics files
\usepackage{amsmath} % assumes amsmath package installed
% \usepackage[style=ieee, sorting=none]{biblatex}


% \addbibresource{references.bib} 

\title{\LARGE \bf 
Emotional EEG Classification using Upscaled Connectivity Matrices
}
\author{Chae-Won Lee$^{1}$ and Jong-Seok Lee$^{1}$% <-this % stops a space
\thanks{$^{1}$The authers are with the School of Integrated Technology, Yonsei University, Seoul 03722, Korea. E-mail: \{chae-won.lee, jong-seok.lee\}@yonsei.ac.kr}%
}

\begin{document}

\maketitle

\thispagestyle{empty}
\pagestyle{empty}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{abstract}

In recent studies of emotional EEG classification, connectivity matrices have been successfully employed as input to convolutional neural networks (CNNs), which can effectively consider inter-regional interaction patterns in EEG. However, we find that such an approach has a limitation that important patterns in connectivity matrices may be lost during the convolutional operations in CNNs. To resolve this issue, we propose and validate an idea to upscale the connectivity matrices to strengthen the local patterns. Experimental results demonstrate that this simple idea can significantly enhance the classification performance.
\end{abstract}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Introduction}

Perceptual elements, particularly emotions play an increasingly crucial role in modern intelligent services and applications. As these elements significantly influence the quality of user experience, there is a growing need for more precise methods to analyze and understand them. The ability to effectively identify emotional and cognitive states has become essential across various domains, including content recommendation systems, virtual reality environments, and human-computer interaction (HCI). Given that emotions fundamentally shape human cognition and behavior, developing methodologies for quantitative measurement and analysis of emotions has emerged as a critical research challenge \cite{dolan2002emotion}.

Traditional emotion recognition methods have primarily relied on self-report methods, such as surveys and interviews. However, these approaches have limitations in capturing real-time emotional changes and are susceptible to subjective bias. To overcome these limitations, implicit emotion analysis techniques utilizing electroencephalography (EEG) signals have gained increasing attention. EEG signals offer advantages in enabling real-time monitoring and reducing experimental bias \cite{moon2016implicit}. 

Conventional EEG-based emotion analysis methods typically extract amplitude or frequency-related features from the signals. While these methods are useful for analyzing brain activity at specific moments, they have limitations in effectively capturing interactions within complex brain networks. To address these limitations, the concept of brain connectivity has gained prominence, focusing on analyzing relationships between different brain regions \cite{horwitz2003elusive}, \cite{jang2018eeg}, \cite{jang2021eeg}.

A significant advancement in this field has been the introduction of connectivity matrices that quantify relationships between different EEG electrodes in a two-dimensional (2D) format. Generated using various connectivity metrics such as Pearson correlation coefficient (PCC), phase-locking value (PLV), and transfer entropy (TE), these matrices effectively capture complex neural interactions within specific frequency bands \cite{moon2020emotional}.

Despite the considerable success of connectivity matrix-based emotional EEG classification methods, several technical challenges persist. This study identifies a critical issue: convolutional neural network (CNN)-based models tend to struggle with effectively learning meaningful features from connectivity matrices, significantly degrading classification accuracy. Specifically, learning from raw connectivity matrices leads to suboptimal feature extraction, with the spatial structure and resolution of the matrices limiting the model's learning capability.

To address this challenge, we propose and evaluate a method that enhances both the interpretability and effectiveness of connectivity matrices. In particular, we apply interpolation techniques that upscale connectivity matrices in order to enable the model to learn meaningful patterns more efficiently. Through experimental analysis applying interpolation techniques to CNN-based emotional EEG classification models, we demonstrate that our proposed approach significantly improves classification performance.

The remainder of the paper is organized as follows. Section II reviews the related work briefly. Our approach is detailed in Section III. The experiments and their results are presented in Sections IV and V, respectively. Finally, conclusion is given in Section VI.
















\section{Related work}

\subsection{Emotional EEG analysis}

Electroencephalography (EEG) has played a crucial role in emotion analysis research as a tool for real-time measurement of brain electrical activity \cite{moon2016implicit}. EEG signals can be interpreted through both time-domain and frequency-domain analyses to understand emotional states.

Frequency domain analysis, in particular, has been widely adopted in EEG-based emotion research. Liu et al. \cite{liu2017real} conducted a study distinguishing emotions such as joy, anger, fear, and sadness in response to visual stimuli by combining power spectral density (PSD) and asymmetry indices . Furthermore, Zhang et al. \cite{zhang2016approach} demonstrated that emotional states could be more effectively estimated by introducing time-frequency distribution analysis, which combines temporal and frequency characteristics.

Recent advances in deep learning technology have revolutionized EEG signal analysis, offering superior feature extraction capabilities compared to conventional methods. Among various deep neural network models, CNNs have been a major architecture for EEG analysis. Yanagimoto and Sugimoto \cite{yanagimoto2016convolutional} demonstrated the effectiveness of automated feature learning in emotion recognition by utilizing CNN to classify emotional valence and arousal states from EEG signals. 
Li et al. \cite{li2018hierarchical} proposed a method of transforming EEG scalp maps into 2D images for CNN analysis, showcasing the potential to effectively handle EEG signal complexity while accounting for individual differences in emotional responses.


\subsection{Brain connectivity in emotion analysis}
Brain connectivity analysis has emerged as an effective approach in EEG-based emotion analysis. Previous studies have emphasized that analyzing interactions between brain regions, beyond the activation of specific brain regions, provides advantages. Costa et al. \cite{costa2006eeg} discovered significant correlations between EEG phase synchronization patterns and emotional states, while Lee and Hsieh \cite{lee2014classifying} developed and applied a connectivity measurement method combining correlation, coherence, and phase synchronization for emotion classification.
Recent research has actively explored the integration of connectivity matrices with deep learning approaches. Moon et al. \cite{moon2020emotional} demonstrated that connectivity matrices could be effectively utilized as CNN inputs to learn patterns related to emotional valence.

\begin{figure}[t]
    \centering
    \includegraphics[width=0.48\textwidth]{conmatonecol.pdf}
    \caption{Activation (right) after the first convolutional layer for a connectivity matrix (left)}
    \label{fig:actconmat}
\end{figure}

\begin{figure}[t]
    \includegraphics[width=0.48\textwidth]{cifaronecol.pdf}
    \caption{Activation (right) after the first convolutional layer for a natural image (left) from the CIFAR-10 dataset }
    \label{fig:actcifar}
\end{figure}

\begin{figure*}[t]
    \centering
    \includegraphics[width=2\columnwidth]{overview.png}  % 
    \caption{Overview of the proposed classification system}
    \label{fig:overview}
\end{figure*}




\section{Proposed method}


\subsection{Connectivity matrix approach}

In this study, we generate symmetric connectivity matrices based on the PCC to quantify linear relationships between EEG signals. PCC measures the degree of signal synchronization between electrodes and is defined as:

\[
\text{PCC}(i, k) =  \frac{\frac{1}{T} \sum_{t=1}^{T}(x_i^t - \mu_i) (x_k^t - \mu_k)}{\sigma_i \sigma_k}
\] where \( x_i^t \) and \( x_k^t \) represent the two EEG signals \( i \) and \( k \) at the temporal index \( t \), \( \mu_i \) and \( \mu_k \) represent the mean values, and \( \sigma_i\) and \( \sigma_k\) represent the standard deviations of \( x_i \) and \( x_k \) over time, respectively. \( T \) is the total number of temporal samples in the time series data. PCC ranges from -1 to 1, where values approaching 1 indicate strong positive correlation, -1 indicates strong negative correlation, and 0 suggests no linear relationship between the signals.

The electrode arrangement in the connectivity matrix follows the distance-restricted arrangement method \cite{moon2020emotional} that optimizes spatial relationships between electrodes. The method constructs connectivity matrices by integrating regional information (e.g., hemispheres) and electrode distances, emphasizing short-range connections while reducing spurious ones. Specifically, the order of the electrodes in a connectivity matrix is determined in a way that the closely located electrodes within the same hemisphere are adjacent. The matrix is then processed by a CNN to extract meaningful EEG representations for classification.


\subsection{Limitation of the conventional method}

While connectivity matrix-based approaches have been effectively utilized for classification, CNN models often struggle to learn meaningful features from these matrices. Fig. \ref{fig:actconmat} compares a row from the connectivity matrix with its corresponding activation pattern after the first convolution layer. It reveals a critical limitation: locally prominent features in the connectivity matrix are often ignored in the activation. This misalignment suggests that conventional approaches, which directly input connectivity matrices, may fail to preserve crucial structural information through the model. 

The reason behind such a limitation is mainly distinguished characteristics of the patterns appearing in connectivity matrices. To illustrate, Fig. \ref{fig:actcifar} presents the case with a natural image from the CIFAR-10 dataset \cite{krizhevsky2009learning}, which shows  the input image and the activation of the first convolutional layer of the CNN trained for image classification. It can be observed that the the input and the activation have similar trends and the CNN captures important features such as edges and textures. On the other hand, the values in a connectivity matrix represent relationships between electrodes rather than spatially continuous patterns, making it difficult for convolutional layers to learn effective feature representations. Consequently, inconsistent activation patterns not only degrade classification performance but also reduce model interpretability, as the relationship between input features and model decisions becomes obscured. This highlights the necessity of preprocessing that enhance the spatial structure of connectivity matrices before they are fed into CNNs.


\subsection{Our method}

\begin{table}[b]
\centering
\caption{Sub-frequency bands employed for EEG decomposition}
\begin{tabular}{|c|c|}
\hline
\textbf{Band} & \textbf{Frequency Range (Hz)} \\
\hline
Delta & 0-3 \\
Theta & 4-7 \\
Low-alpha & 8-9.5 \\
High-alpha & 10.5-12 \\
Alpha & 8-12 \\
Low-beta & 13-16 \\
Mid-beta & 17-20 \\
High-beta & 21-29 \\
Beta & 13-29 \\
Gamma & 30-50 \\
\hline
\end{tabular}
\label{table:freq}
\end{table}

\begin{table}[t]
\centering
\caption{CNN architecture in the proposed system. ``$r$'' refers to the upscaling factor.} 
\begin{tabular}{|c||c|c|}
\hline
\textbf{Layer} & \textbf{Type} & \textbf{Output Shape} \\
\hline
1 & Upsampling & 32r × 32r × 10 \\
2 & Convolution (ReLU) & 32r × 32r × 32 \\
3 & Convolution (ReLU) & 32r × 32r × 64 \\
4 & Max-Pooling & 16r × 16r × 64 \\
5 & Convolution (ReLU) & 16r × 16r × 128 \\
6 & Convolution (ReLU) & 16r × 16r × 256 \\
7 & Max-Pooling & 8r × 8r × 256 \\
8 & Convolution (ReLU) & 8r × 8r × 256 \\
9 & Convolution (ReLU) & 8r × 8r × 256 \\
10 & Max-Pooling & 4r × 4r × 256 \\
11 & Dense & 256 \\
12 & Dense(Softmax) & 40 \\
\hline
\end{tabular}
\label{table:model}

\centering
\caption{Hyperparameters for model training}
\begin{tabular}{|c|c|}
\hline
\textbf{Component} & \textbf{Setting/Value} \\
\hline
Loss Function & Cross-Entropy Loss \\
Optimizer & Adam \\
Learning Rate & 0.0001 \\
Scheduler & StepLR with stepsize 10, $\gamma$=0.8 \\
Batch Size & 64 \\
Early Stop Count & 20 \\
\hline
\end{tabular}
\label{table:hyper}
\end{table}

In order to overcome the aforementioned limitation, we propose a method to enhance CNN feature learning by increasing the spatial resolution of connectivity matrices based on interpolation techniques. It is aimed to emphasize useful local patterns in the connectivity matrices so that such patterns are not lost during convolutional operations and eventually improved classification performance is obtained. 

Fig. \ref{fig:overview} provides an overview of the proposed classification system. Initially, the EEG signals are denoised and cleansed of artifacts, and then segmented into 10 distinct sub-frequency bands, as presented in Table \ref{table:freq}. For each sub-frequency band, a separate 32x32 connectivity matrix is generated, representing the pair-wise interactions among the 32 EEG electrodes. This approach effectively captures subtle differences in neural responses across the frequency domain.

Subsequently, for interpolation of connectivity matrices, we employ nearest neighbor and bilinear methods. We explore various scaling ratios of 1.5, 2, 2.5, and 3, to determine the optimal resolution. 

The upscaled connectivity matrices are inputted to the CNN model. The detailed architecture of the proposed CNN is summarized in Table \ref{table:model}. This is followed by successive convolutional layers with ReLU activation and max-pooling layers. Finally, the model uses two dense layers and a softmax activation function to classify the data into 40 classes (see Section IV for the classification task).  

An important issue related to the varying resolution of connectivity matrics is the kernel size of the CNN. It basically determines the size of the receptive field of the CNN. When the resolution of the input connectivity matrices changes, the spatial range that the kernel of a certain size also changes. Thus, we examine the effect of the kernel size on the performance. We test kernel sizes of 3x3, 5x5, and 7x7.




\section{Experimental Setup}

Our evaluation employs the DEAP \cite{koelstra2011deap} dataset, which comprises EEG signals recorded from 32 participants during the viewing of 40 emotional music videos. The dataset includes emotion labels categorized by valence and arousal scales for each video stimulus. Building upon the evaluation  framework in \cite{moon2020emotional}, a classification model designed to identify which of the 40 videos was being viewed based on the recorded
EEG signals.

The preprocessing pipeline begins with EEG signal filtering. After removing noise and artifacts,
we implement bandpass filtering to extract ten distinct frequency bands as shown in Table I. This granular approach to frequency band extraction enabled detailed analysis of neural responses across different spectral components of the EEG signal.

Given the limited number of segments obtainable from the one-minute EEG signal for each trial, a straightforward non-overlapping segmentation into three-second intervals would produce only 20 segments per trial. To augment the dataset, we implement an overlapping segmentation approach with a step size of 0.5 seconds, thereby increasing the number of samples. For every three-second segment, a connectivity matrix of dimensions 32×32×10 is computed, capturing the inter-channel relationships across the ten sub-frequency bands.

From each trial, one segment is randomly chosen for validation, another randomly chosen segment is used for test, and the rest is used for training. Here, the validation (or test) segment and its neighboring segments used for training contain overlapping portions of EEG signals, which is not appropriate for fair performance evaluation. To avoid this, we enforce a strict temporal independence constraint by eliminating the training segments that overlap with validation and test segments. Finally, we obtain 119040, 1280, and 1280 segments in the training, validation, and test sets, respectively, each of which is converted to a connectivity matrix with a size of 32x32x10.

Table \ref{table:hyper} provides hyperparameter settings including the learning rate, batch size, and optimizer configurations. We repeat the experiments three times with different random seeds to initialize the CNNs. 
The Nvidia RTX 2080 GPU is for evaluation.











\begin{table}[b]
\centering

\caption{Comparison of average classification accuracy (\%). The average is taken for the casese where the training successfully converges. The best case in each upscaling factor is marked in bold. ``-'' refers to the failure of training.}
\begin{tabular}{|c||c|c|c||c|c|c|}
\hline
{\textbf{Upscaling}} &\multicolumn{3}{c||}{\textbf{Bilinear}} & \multicolumn{3}{c|}{\textbf{Nearest}} \\
\cline{2-7}
\textbf{Factor} & \textbf{3×3} & \textbf{5×5} & \textbf{7×7} & \textbf{3×3} & \textbf{5×5} & \textbf{7×7} \\
\hline
1.0 & 35.9 & 38.2 & - & 35.9 & 38.2 & - \\
1.5 & 41.3 & 52.0 & 49.0 & 48.4 & 52.8 & - \\
2.0 & 55.7 & 66.4 & 60.2 & 69.4 & - & - \\
2.5 & 57.5 & 73.3 & 50.9 & 62.5 & - & 66.8 \\
3.0 & 68.0 & 70.5 & 66.8 & \textbf{82.3} & 75.3 & 64.1 \\
\hline
\end{tabular}
\label{tab:performance_comparison}
\end{table}

\begin{table}[t]
\caption{Accuracy (\%) of three experiments with bilinear interpolation. ``-'' refers to the failure of training.}

\begin{tabular}{|c||c|c|c|}
\hline
\textbf{Factor} & \textbf{3×3} & \textbf{5×5} & \textbf{7×7} \\
\hline
1.0 & 35.9, 35.9, 35.9 & 38.2, 38.2, 38.2 & -, -, - \\
1.5 & 38.4, 43.7, 41.7 & 52.8, 51.6, 51.6 & -, -, 49.0 \\
2.0 & 52.2, 54.8, 59.4 & 64.5, 63.4, 71.2 & 56.6, 62.3, 61.8 \\
2.5 & 57.0, 61.3, 54.1 & -, -, 73.3 & -, 52.9, 48.8 \\
3.0 & 68.3, 63.4, 72.3 & 69.4, 74.5, 67.7 & -, 66.8, - \\
\hline
\end{tabular}
\label{tab:three_accuracy}
\end{table}




\section{Results}


\subsection{Overall performance}

Table IV summarizes the average accuracy for different combinations of the upscaling factor and method. Above all, upscaling the connectivity matrices improves the performance significantly. When the original connectivity matrices are used (i.e., upscaling factor=1), the accuracy remains between 35 and 40\% depending on the kernel size. However, the accuracy consistently improves as the upscaling factor increases. When the upscaling factor is 3, the best accuracy (82.3\%) is obtained with a kernel size of 3x3, which is a significant improvement compared to that with the original connectivity matrices. 

There are a few cases where the training loss diverges and the training is not successful, which is marked as ``-'' in the table. Table V details the accuracy for each of the three experiments when the bilinear interpolation method is used. As the kernel size increases, the training becomes more unstable. Therefore, smaller kernel sizes are preferable for training stability. 

\subsection{Visualization of CNN Activation}

\begin{figure}[b]
    \centering
    \includegraphics[width=0.45\textwidth]{act_ker3.png}
    \caption{Activations after first convolution layer when the nearest neighbor method is used for interpolation and the kernel size is 3x3.}
    \label{fig:act_ker5}
\end{figure}

\begin{figure*}[t]
    \includegraphics[width=1\textwidth]{allline.png}
    \caption{One-dimensional plots of the original input and the activations of the first convolutional layer along a particular row}
    \label{fig:all_line}
    \vspace{-5pt}
\end{figure*}



Investigation of the initial CNN convolution layers provided deeper insights into these results. Fig. \ref{fig:act_ker5} visualizes an example of the original input connectivity matrix and the activations (i.e., feature maps) after the first convolutional layer for different upscaling factors when the nearest neighbor interpolation method is used and the kernel size is 3x3. And, Fig. \ref{fig:all_line} provides one-dimensional plots for the input and activations along a particular row of the two-dimensional representations in Fig. \ref{fig:act_ker5}. As the upscaling factor increases, the feature maps exhibit more concentrated and well-defined activation patterns within narrow regions, indicating clearer preservation of neural connectivity patterns and fine spatial relationships.
In contrast, lower upscaling factors resulted in activation patterns that are both broader and more irregular across the feature maps, with some activations appearing in areas as small as a few pixels due to resolution limitations.




\section{Conclusion}

We presented our study on improving the performance of emtional EEG classification using CNNs by upscaling input connectivity matrices. We identified the issue of using the original connectivity matrices in comparison to natural images, and as a way to resolve the issue, we proposed a simple interpolation technique to preserve localized patterns in the connectivity matrices. Experimental results demonstrated that the classification accuracy improves significantly by our method. We also found the training instability with larger kernel sizes.




\bibliographystyle{unsrt}
\bibliography{references}
  
\end{document}
