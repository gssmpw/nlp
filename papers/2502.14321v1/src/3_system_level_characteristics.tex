\section{System-Level Communication}
In this section, we analyze LLM-MAS from the macro system-level communication. We first examine the communication architecture, highlighting how different architecture such as flat, hierarchical or society-based organize agents. Each of these architectures offers distinct approaches to agent interaction, with implications for scalability, flexibility, and efficiency in system performance. We then delve into the communication goals that decide why agents communicate, where cooperation, competition, or a mixture of both can lead to distinct multi-agent dynamics. Through specific application examples, we demonstrate the advantages, limitations, and applicable scenarios of these communication architectures and goals. As shown in Table 2, we categorize current LLM-MAS studies based on communication architecture and communication goal and divide their system internal communication in detail.

\subsection{Communication Architecture}
Communication architecture defines how agents in a LLM-based multi-agent system are organized and how information flows among them~\cite{mas_a_survey}. It thus shapes both the high-level design and the micro-level interactions. Depending on task complexity, the degree of agent autonomy, and the desired collaboration style, LLM-MAS can utilize one of the following five main architectures:


\paragraph{Flat Architecture.} A flat architecture features decentralized agents, each operating at the same level with no central controller. Agents communicate peer-to-peer, enabling rapid and flexible interactions ideal for smaller-scale or highly dynamic tasks. For instance, \cite{dataset_generation} presents a flat system where peer agents collaboratively generate synthetic dialogues. Similarly, \cite{debate_improve_llm_1} leverages multiple LLM-based agents in a fact-checking setup where they critique each other's reasoning to reduce hallucinations. While this decentralized paradigm encourages high adaptability, it can become less efficient when the number of agents grows large, necessitating more structured coordination.



\paragraph{Hierarchical Architecture.} In a hierarchical architecture, higher-level agents oversee lower-level ones, forming a tree-like structure suited for complex tasks requiring role specialization. High-level agents coordinate overall strategy, while sub-agents focus on specific subtasks. For example, CausalGPT~\cite{casualgpt_reasoning} employs a top-level evaluator to validate solutions generated by lower-level agents, improving reasoning consistency. ChatDev~\cite{chatdev_software_development} organizes software development roles such as designer, coder and tester under a senior agent for project-level oversight. Although hierarchical coordination can streamline decision flow, it risks bottlenecks or delays if the top-level agent becomes overloaded, especially in large-scale deployments.

\paragraph{Team Architecture.} In team-based architectures, agents are grouped into specialized teams, each tackling a particular aspect of a complex task. This approach leverages the complementary expertise of different agents and supports dynamic role adjustments. A prime example is MAGIS~\cite{magis_mas_for_github}, which divides agents into administrators, developers, and QA testers to streamline collaboration on GitHub issues. The POLCA framework ~\cite{polca_mas_for_political} extends team-based architectures to political coalition negotiations. The framework models the negotiation process as a series of interactions between agents, each representing the interests of a specific party to simulate negotiation dynamics and predict potential coalition outcomes. While team-based structures foster intra-team synergy, they also introduce overhead for inter-team communication and alignment.

\paragraph{Society Architecture.} Society-based architectures simulate a broader social environment, where agents follow certain norms or conventions (``social laws'') and exhibit emergent behaviors akin to human societies. Agents in these systems may have different roles and motivations, but they cooperate or compete to achieve collective goals or individual ambitions, reflecting the dynamics of human society. For example, \cite{stanf_villege} develops a sandbox environment where generative agents form friendships, organize gatherings, and adapt their actions based on past experiences. Meanwhile, \cite{sct_society} explores how agents evolve from a Hobbesian ``state of nature'' to peaceful societies governed by social contracts. In addition to social simulations, there are currently some simulations for more specific social activities such as economic activities. EconAgent~\cite{econagent} integrates market dynamics with agents' personal experiences to simulate realistic economic behaviors such as consumption, work, and investment, which provides insights into the impact of individual actions on large-scale economic phenomena. Such systems are well-suited for large-scale emergent phenomena, but can be complex to control or predict, as agent interactions evolve dynamically over time.

\paragraph{Hybrid Architecture.} Not all designs fit neatly into a particular architecture, and some architectures may contain features from several different styles. Therefore, architectures can be transformed into hybrid architectures through overlapping, nesting, and other means. Hybrid architectures are designed to complement each other, adapt to a wider range of scenarios, and arrange agents to achieve more complex, flexible, and efficient problem solving. For instance, FixAgent~\cite{fixagent_mas_for_debug} uses a three-level agent design that dynamically adapts to different debugging complexities, merging hierarchical oversight with decentralized collaboration. Likewise, ChatSim~\cite{chatsim_mas_make_scene} orchestrates scene simulation through both top-down control (scene rendering) and peer collaboration (assets integration) to overcome the limitations of previous scene simulations. ~\cite{mas_use_tool} provides another example of a hybrid architecture that allows an agent to dynamically search for the most relevant tool to complete a task. This hybrid approach integrates search, tool management, and task execution into a single framework, reducing inference costs, enhancing flexibility, and improving the agent's ability to scale across a variety of applications. Hybrid models can optimize flexibility and efficiency but may require more intricate design to avoid coordination overhead.

\subsection{Communication Goal}
Having defined the overarching communication architectures, we now turn to communication goals that fundamentally guide agent interactions in LLM-MAS. These goals significantly shape the behaviors, information-sharing patterns, and coordination strategies within the system, as they encapsulate the “why” behind the communication. In the following paragraphs, we detail three goal categories:

\paragraph{Cooperation.} Cooperation is a central feature in numerous multi-agent scenarios. Unlike traditional multi-agent systems, LLMs bring an added dimension to cooperation by providing advanced natural language understanding and generation capabilities, enabling more sophisticated and flexible forms of interaction.  In this survey, we partition cooperation into two main types:1) \textbf{\emph{Direct Cooperation}} and 2) \textbf{\emph{Cooperation Through Debate}}. Although they differ in interaction style and complexity, both approaches aim to integrate multiple agents’ expertise for improved problem-solving and decision-making. \textbf{Direct cooperation} refers to straightforward, unreserved collaboration among agents to achieve a mutual goal. This level of transparency and alignment is particularly valuable when rapid consensus or integrated expertise is paramount. For instance,   some works harness direct cooperation to enhance LLM reasoning\cite{boostrapping,casualgpt_reasoning,autoagents} ,  while others employ it in collaborative code generation \cite{chatdev_software_development,soa_code_generation,magis_mas_for_github,mas_for_software_2,fixagent_mas_for_debug} and scientific experimentation\cite{chatsim_mas_make_scene,mas_use_tool}.The research community continues to explore advanced coordination models~\cite{agentcoord,govsim,mas_benchmark} for fine-grained task allocation, robust communication protocols, and scalability in agent collectives. The implication of \textbf{collaborating through debate} is that rather than unanimously accepting each other’s information, agents engage in critical dialogues, openly scrutinizing different perspectives before converging on a refined solution. Examples include factual reasoning\cite{debate_improve_llm_1} and fact-checking\cite{debate_2}, where rigorous back-and-forth discussions help validate information and reduce the likelihood of mistakes. By facilitating deep collaboration without sacrificing critical evaluation, debate-driven approaches can yield more robust and well-rounded decisions than simple consensus-based methods.

\paragraph{Competition.} Competition in LLM-MAS emerges when agents possess conflicting objectives or vie for shared resources, or outcomes. Unlike cooperative systems, competitive settings demand that each agent contest, or even persuade others to achieve the best outcome for the individual. The game-playing ability of agents in the system has been demonstrated in research~\cite{evaluating_llm_game_ability}. In these adversarial contexts, agents actively shape the interaction by generating persuasive or deceptive narratives. For instance, \cite{social_media_regulation} employs multi-agent simulations to study how language evolves in polarizing environments. ~\cite{agent4debate} designed a dynamic multi-agent framework for competitive debate with human.  One significant advantage of competition in LLM-MAS is its potential to drive innovation and strategic sophistication. As agents continually adjust to rivals’ tactics and environmental feedback, they refine their own approaches in a never-ending loop of adaptation. For instance,~\cite{mas_for_poetry_generation} explored a poetry-generation task where agents strove to outperform each other through creative linguistic outputs. However, competition can also introduce instability or security risks, particularly if agents employ deceptive strategies or if the system lacks mechanisms to contain adversarial behavior. Balancing such complex dynamics with overall system performance is thus a core challenge for designing robust competitive environments.


\paragraph{Mixed.} While purely cooperative or purely competitive settings offer conceptual clarity, many real-world applications exhibit crossovers between the two modes. Agents may collaborate on certain subgoals but compete fiercely over others, mirroring the complexities of social, economic, or political ecosystems. In LLM-MAS, this “mixed” paradigm grants agents the flexibility to form alliances when mutually beneficial while still pursuing self-interests. In practice, such mixed interactions are pivotal for capturing nuanced, dynamic behavior in domains like social simulations~\cite{community_knowledge_flooding,sct_society}, collective problem-solving, or negotiation tasks~\cite{polca_mas_for_political,richeliey_diplomacy_society}. Allowing agents to strike a balance between cooperative and adversarial behavior makes it's possible to emerge solutions that cannot be suggested by purely cooperative or competitive environments. Nonetheless, mixed-mode interactions also introduce higher complexity in mechanism design, communication protocols, and ethical considerations, as agents must consistently evaluate whether to help or hinder their peers to optimize both individual and collective gains.