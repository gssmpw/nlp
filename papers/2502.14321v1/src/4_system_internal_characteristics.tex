\section{System Internal Communication}
Having established the overall system-level perspective, we now turn to the system internal communication of LLM-MAS. We firstly categorize and compare diverse communication strategies that determine when and in what sequence agents communicate. Next, we discuss the communication paradigms that frame the form and modality of these exchanges, followed by an examination of communication objects and content. These elements collectively define the richness, adaptability, and effectiveness of communication in LLM-MAS, ultimately shaping the system’s capacity for coordination and problem-solving.
\subsection{Communication Strategie}
In LLM-MAS, well-defined communication strategies determine how agents exchange information and manage interactions at a micro-level. These strategies specify \emph{when} and \emph{in what sequence} agents speak, often influencing the coherence, scalability, and decision-making quality of the system. In this section we highlight three widely adopted approaches:

\paragraph{One-by-One.} Agents respond in a strict turn-taking fashion, each incorporating all previous messages before contributing and then appending its new contribution. This structured process preserves context and reduces internal conflicts.  Hence, it is especially suitable for tasks demanding methodical exploration of ideas, or for scenarios where it is critical to reference and build upon earlier utterances. A typical example is \cite{chain_of_agents}, which chains multiple agents for lengthy text generation; each agent processes the previous agent’s summary to circumvent token limitations. can become time-consuming or computationally expensive when the number of agents grows. However, it will become time-consuming or computationally expensive when the number of agents grows.


\paragraph{Simultaneous-Talk.} All agents produce messages in parallel, eliminating the enforced turn-taking sequence. A key advantage of Simultaneous-Talk is the potential for richer, more diverse brainstorming. For instance, ~\cite{autoagents} builds an LLM-MAS framework that applies multiple agents to express ideas in parallel to more rapidly uncovers different perspectives or solution paths. Nevertheless, parallel communication can introduce challenges in synchronization and consistency. If each agent only partially or asynchronously receives messages, they might operate with outdated context or produce conflicting information. Moreover, as the number of agents grows, the overhead of coordinating parallel updates becomes nontrivial, potentially leading to concurrency bottlenecks.

\paragraph{Simultaneous-Talk-with-Summarizer.} This strategy builds upon Simultaneous-Talk by introducing a dedicated “summarizer” agent. After each communication round, the summarizer compiles and shares a concise summary to ensure alignment among parallel speakers. By providing a consistent global state of the conversation, the summarizer agent helps prevent misunderstanding or divergence. This strategy often appears in tasks under a hierarchical or team structure, where designated leaders or summarizers handle task allocation and summarization, such as ~\cite{casualgpt_reasoning,social_media_regulation,agentcoord,polca_mas_for_political}. However, this mechanism partly reintroduces sequential elements and poses a failure risk if the summarizer itself hallucinates or misconstrues content.

\subsection{Communication Paradigm}
In LLM-MAS, communication paradigms define how information is is represented, transmitted, and interpreted among agents, ultimately shaping the system’s interaction dynamics and performance. By leveraging the advanced language capabilities of LLMs, these paradigms enable rich, contextually nuanced exchanges that extend beyond traditional symbolic messages. Drawing on the taxonomy proposed by \cite{mas_a_survey}, we distinguish three common paradigms:

\paragraph{Message Passing.} The Message Passing paradigm enables direct communication among agents, where information delivered point-to-point or via broadcast. In LLM-MAS, the content of messages goes beyond simple data packets, often including natural language expressions with embedded reasoning and context, which leads to that this paradigm is reflected in most applications. Message Passing excels in scenarios such as large-scale simulation~\cite{simulating_opinion_dynamic} where rapid, efficient information dissemination is paramount.


\paragraph{Speech Act.} The Speech Act paradigm stems from the notion that language serves not only as a medium for information exchange but also as a tool to perform actions. Within LLM-MAS, a speaker agent might generate utterances intended to instruct, request, or persuade another agent, thus altering the system's state or achieving specific goals.This paradigm is particularly relevant in scenarios where agents need to dynamically adjust their behaviors based on the evolving context of the system, such as negotiations~\cite{polca_mas_for_political,richeliey_diplomacy_society}, collaborative problem-solving~\cite{debate_improve_llm_1}, or coordination tasks~\cite{chatdev_software_development}. However, it introduces interpretation challenges: if agents misunderstand the utterance, this can lead to confusion or suboptimal decisions. 


\paragraph{Blackboard.} The blackboard paradigm provides a centralized medium that serves as a common information repository where agents can publish updates, retrieve insights, and coordinate actions. In LLM-MAS,  blackboard allows agents to publish status summaries, action proposals, or even textual justifications. This paradigm particularly suits highly coordination systems like collaborative decision-making or distributed problem-solving, where agents require a shared information pool to align strategies and actions. A typical application example is MetaGPT~\cite{metagpt}. This system implements a shared message repository, enabling agents to exchange updates and enhance communication efficiency. However, reliance on a single repository may create bottlenecks or raise security issues, as malicious or faulty contributions on the blackboard can mislead the entire group. Hence, role-based or permission-based mechanisms are often necessary to regulate read/write privileges. 

\subsection{Communication Object}
In LLM-MAS, the communication object denotes the entity or target that an agent interacts with. It significantly influences how agents perceive and respond to their environment. Understanding different communication objects within LLM-MAS clarifies how information flow affects decision-making, coordination, and goal achievement. This section will explore the following four primary communication objects:

\paragraph{Communication with Self.} Communication with self refers to an agent's internal dialogue, encompassing thought processes, planning, and goal reflection~\cite{react}. In LLM-based systems, such self-talk is crucial for updating internal states, refining strategies, and reasoning about next steps, effectively mimicking higher-order cognition. For instance, in Agentcoord~\cite{agentcoord}, an agent might produce internal summaries, test hypothesis, or even question its own reasoning to refine its behavior.

\paragraph{Communication with Other Agents.} Communication with other agents involves exchanges of information, commands, or requests among different entities in the system, so their inter-agent communication is highly adaptive and dynamic. Almost all LLM-MAS scenarios involve communication with other agents for achieving collaborative goals, resolving conflicts, and disseminating information.

\paragraph{Communication with Environment.} Communication with environment concerns how agents receive and adapt to external surroundings, including various forms of feedback and stimuli. The environment can encompass a range of factors, from physical conditions~\cite{embodied_agents} to fluctuations system states and external data inputs~\cite{blockagents}. This feedback from environment enables agents to adapt strategies dynamically, re-evaluate decisions, and response appropriately as conditions evolve.

\paragraph{Communication with Human.} Communication with humans entails the interactions between agents and human participants. While LLM-MAS often focus on agent-to-agent communication, introducing humans as communication objects adds another layer of complexity. Human participants may issue commands, offer feedback, or request specific actions, requiring agents to interpret and respond appropriately in natural language. For instance, in PeerGPT~\cite{peergpt}, agents act as both team moderators and participants in collaborative learning with children, continuously processing children’s words and actions to refine the agents’ behavior. This highlights how LLM-MAS effectively integrate with human-driven processes.

\subsection{Communication Content}
Communication content refers to the actual information being exchanged between agents. The nature of this content influences how agents interpret and act upon messages. In LLM-MAS, content can be explicit or implicit.

\paragraph{Explicit communication.} Explicit communication entails direct information exchange with clearly defined and easily interpretable meaning. Explicit communication is divided into 1) \textbf{\textit{natural language}} and 2) \textbf{\textit {code and structured data}}. \textbf{Natural language} reamins the most common form of explicit communication in LLM-MAS. These exchanges range from basic commands to advanced conversations. Such flexibility empowers agents to convey rich, context-sensitive information and adjust language to the required level of formality or specificity. \textbf{Code and structured data} are valuable when agents must exchange precise instructions, configuration details, or factual information in a standardized manner. Structured communication is especially critical for planning, data retrieval~\cite{mas_for_defence_attack}, or algorithmic problem-solving~\cite{magis_mas_for_github}, where clarity and consistency are paramount.

\paragraph{Implicit communication.} Implicit communication occurs when agents convey information indirectly, through their actions or environmental cues, rather than through explicit statements. Implicit communication relies on agents interpreting contextual cues or feedback. Implicit communication is divided into 1) \textbf{\textit{behavioral feedback}} and 2) \textbf{\textit{environmental signal}}. \textbf{Behavioral feedback} occurs when agents communicate information to others or themselves through actions or strategy adjustments, without explicit verbal cues. In LLM-MAS, these signals are woven into ongoing interactions. In evolving environments or collaborative tasks such as in diplomatic simulation~\cite{richeliey_diplomacy_society}, behavioral feedback fosters shared understanding and effective coordination. \textbf{Environmental signals} represent another implicit communication channel, where environmental changes provide indirect feedback that shapes agent decisions and behavior. Such signals may include sensor data, system status updates~\cite{chatsim_mas_make_scene,social_media_regulation}, or contextual shifts relevant to an agent’s tasks.


