
@article{WWTD202205023,
author = {Yue F},
title = {Jade culture is the cornerstone of ancient Chinese civilization},
journal = {Cultural Relics World},
volume = {},
number = {05},
pages = {122-125},
year = {2022},
issn = {1000-0194},
}

@article{thwaites2013digital,
  title={Digital heritage: what happens when we digitize everything?},
  author={Thwaites, Harold},
  journal={Visual heritage in the digital age},
  pages={327--348},
  year={2013},
  publisher={Springer}
}

@article{jiawei2022analysis,
  title={Analysis on the Value and Inheritance of Jade Carving Works of Art},
  author={Jiawei, Zhang and others},
  journal={Tobacco Regulatory Science (TRS)},
  pages={1165--1176},
  year={2022}
}

@article{sax2004identification,
  title={The identification of carving techniques on Chinese jade},
  author={Sax, Margaret and Meeks, Nigel D and Michaelson, Carol and Middleton, Andrew P},
  journal={Journal of Archaeological Science},
  volume={31},
  number={10},
  pages={1413--1428},
  year={2004},
  publisher={Elsevier}
}

@inproceedings{lateh2017handling,
  title={Handling a small dataset problem in prediction model by employ artificial data generation approach: A review},
  author={Lateh, Masitah Abdul and Muda, Azah Kamilah and Yusof, Zeratul Izzah Mohd and Muda, Noor Azilah and Azmi, Mohd Sanusi},
  booktitle={Journal of Physics: Conference Series},
  volume={892},
  number={1},
  pages={012016},
  year={2017},
  organization={IOP Publishing}
}

@inproceedings{he2016deep,
  title={Deep residual learning for image recognition},
  author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={770--778},
  year={2016}
}

@article{hou2024conv2former,
  title={Conv2former: A simple transformer-style convnet for visual recognition},
  author={Hou, Qibin and Lu, Cheng-Ze and Cheng, Ming-Ming and Feng, Jiashi},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},
  year={2024},
  publisher={IEEE}
}

@article{jaiswal2020survey,
  title={A survey on contrastive self-supervised learning},
  author={Jaiswal, Ashish and Babu, Ashwin Ramesh and Zadeh, Mohammad Zaki and Banerjee, Debapriya and Makedon, Fillia},
  journal={Technologies},
  volume={9},
  number={1},
  pages={2},
  year={2020},
  publisher={MDPI}
}

@article{liu2021self,
  title={Self-supervised learning: Generative or contrastive},
  author={Liu, Xiao and Zhang, Fanjin and Hou, Zhenyu and Mian, Li and Wang, Zhaoyu and Zhang, Jing and Tang, Jie},
  journal={IEEE transactions on knowledge and data engineering},
  volume={35},
  number={1},
  pages={857--876},
  year={2021},
  publisher={IEEE}
}

@article{zeng2022nlfftnet,
  title={Nlfftnet: A non-local feature fusion transformer network for multi-scale object detection},
  author={Zeng, Kai and Ma, Qian and Wu, Jiawen and Xiang, Sijia and Shen, Tao and Zhang, Lei},
  journal={Neurocomputing},
  volume={493},
  pages={15--27},
  year={2022},
  publisher={Elsevier}
}

@article{hu2024overview,
  title={An overview: Attention mechanisms in multi-agent reinforcement learning},
  author={Hu, Kai and Xu, Keer and Xia, Qingfeng and Li, Mingyang and Song, Zhiqiang and Song, Lipeng and Sun, Ning},
  journal={Neurocomputing},
  pages={128015},
  year={2024},
  publisher={Elsevier}
}

@article{jia2020multi,
  title={Multi-dimensional classification via stacked dependency exploitation},
  author={Jia, Bin-Bin and Zhang, Min-Ling},
  journal={Science China Information Sciences},
  volume={63},
  pages={1--14},
  year={2020},
  publisher={Springer}
}

@article{zhou2024source,
  title={Source-free domain adaptation with class prototype discovery},
  author={Zhou, Lihua and Li, Nianxin and Ye, Mao and Zhu, Xiatian and Tang, Song},
  journal={Pattern recognition},
  volume={145},
  pages={109974},
  year={2024},
  publisher={Elsevier}
}

@article{zhuang2024mining,
  title={Mining negative samples on contrastive learning via curricular weighting strategy},
  author={Zhuang, Jin and Jing, Xiao-Yuan and Jia, Xiaodong},
  journal={Information Sciences},
  volume={668},
  pages={120534},
  year={2024},
  publisher={Elsevier}
}

@article{shi2020graphaf,
  title={Graphaf: a flow-based autoregressive model for molecular graph generation},
  author={Shi, Chence and Xu, Minkai and Zhu, Zhaocheng and Zhang, Weinan and Zhang, Ming and Tang, Jian},
  journal={arXiv preprint arXiv:2001.09382},
  year={2020}
}

@inproceedings{he2022masked,
  title={Masked autoencoders are scalable vision learners},
  author={He, Kaiming and Chen, Xinlei and Xie, Saining and Li, Yanghao and Doll{\'a}r, Piotr and Girshick, Ross},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={16000--16009},
  year={2022}
}

@inproceedings{he2020momentum,
  title={Momentum contrast for unsupervised visual representation learning},
  author={He, Kaiming and Fan, Haoqi and Wu, Yuxin and Xie, Saining and Girshick, Ross},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={9729--9738},
  year={2020}
}

@article{chen2020improved,
  title={Improved baselines with momentum contrastive learning},
  author={Chen, Xinlei and Fan, Haoqi and Girshick, Ross and He, Kaiming},
  journal={arXiv preprint arXiv:2003.04297},
  year={2020}
}

@inproceedings{chen2021empirical,
  title={An empirical study of training self-supervised vision transformers},
  author={Chen, Xinlei and Xie, Saining and He, Kaiming},
  booktitle={Proceedings of the IEEE/CVF international conference on computer vision},
  pages={9640--9649},
  year={2021}
}

@inproceedings{chen2020simple,
  title={A simple framework for contrastive learning of visual representations},
  author={Chen, Ting and Kornblith, Simon and Norouzi, Mohammad and Hinton, Geoffrey},
  booktitle={International conference on machine learning},
  pages={1597--1607},
  year={2020},
  organization={PMLR}
}

@article{grill2020bootstrap,
  title={Bootstrap your own latent-a new approach to self-supervised learning},
  author={Grill, Jean-Bastien and Strub, Florian and Altch{\'e}, Florent and Tallec, Corentin and Richemond, Pierre and Buchatskaya, Elena and Doersch, Carl and Avila Pires, Bernardo and Guo, Zhaohan and Gheshlaghi Azar, Mohammad and others},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={21271--21284},
  year={2020}
}

@inproceedings{caron2021emerging,
  title={Emerging properties in self-supervised vision transformers},
  author={Caron, Mathilde and Touvron, Hugo and Misra, Ishan and J{\'e}gou, Herv{\'e} and Mairal, Julien and Bojanowski, Piotr and Joulin, Armand},
  booktitle={Proceedings of the IEEE/CVF international conference on computer vision},
  pages={9650--9660},
  year={2021}
}

@article{chen2024context,
  title={Context autoencoder for self-supervised representation learning},
  author={Chen, Xiaokang and Ding, Mingyu and Wang, Xiaodi and Xin, Ying and Mo, Shentong and Wang, Yunhao and Han, Shumin and Luo, Ping and Zeng, Gang and Wang, Jingdong},
  journal={International Journal of Computer Vision},
  volume={132},
  number={1},
  pages={208--223},
  year={2024},
  publisher={Springer}
}

@inproceedings{fang2023eva,
  title={Eva: Exploring the limits of masked visual representation learning at scale},
  author={Fang, Yuxin and Wang, Wen and Xie, Binhui and Sun, Quan and Wu, Ledell and Wang, Xinggang and Huang, Tiejun and Wang, Xinlong and Cao, Yue},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={19358--19369},
  year={2023}
}

@inproceedings{liu2023improving,
  title={Improving pixel-based mim by reducing wasted modeling capability},
  author={Liu, Yuan and Zhang, Songyang and Chen, Jiacheng and Yu, Zhaohui and Chen, Kai and Lin, Dahua},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={5361--5372},
  year={2023}
}

@article{krizhevsky2012imagenet,
  title={Imagenet classification with deep convolutional neural networks},
  author={Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E},
  journal={Advances in neural information processing systems},
  volume={25},
  year={2012}
}

@inproceedings{DBLP:journals/corr/SimonyanZ14a,
  author       = {Karen Simonyan and
                  Andrew Zisserman},
  editor       = {Yoshua Bengio and
                  Yann LeCun},
  title        = {Very Deep Convolutional Networks for Large-Scale Image Recognition},
  booktitle    = {3rd International Conference on Learning Representations, {ICLR} 2015,
                  San Diego, CA, USA, May 7-9, 2015, Conference Track Proceedings},
  year         = {2015},
  url          = {http://arxiv.org/abs/1409.1556},
  timestamp    = {Wed, 17 Jul 2019 10:40:54 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/SimonyanZ14a.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{lin2017feature,
  title={Feature pyramid networks for object detection},
  author={Lin, Tsung-Yi and Doll{\'a}r, Piotr and Girshick, Ross and He, Kaiming and Hariharan, Bharath and Belongie, Serge},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={2117--2125},
  year={2017}
}

@inproceedings{liu2018path,
  title={Path aggregation network for instance segmentation},
  author={Liu, Shu and Qi, Lu and Qin, Haifang and Shi, Jianping and Jia, Jiaya},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={8759--8768},
  year={2018}
}

@article{vaswani2017attention,
  title={Attention is all you need},
  author={Vaswani, A},
  journal={Advances in Neural Information Processing Systems},
  year={2017}
}

@inproceedings{liu2021swin,
  title={Swin transformer: Hierarchical vision transformer using shifted windows},
  author={Liu, Ze and Lin, Yutong and Cao, Yue and Hu, Han and Wei, Yixuan and Zhang, Zheng and Lin, Stephen and Guo, Baining},
  booktitle={Proceedings of the IEEE/CVF international conference on computer vision},
  pages={10012--10022},
  year={2021}
}

@inproceedings{liu2022swin,
  title={Swin transformer v2: Scaling up capacity and resolution},
  author={Liu, Ze and Hu, Han and Lin, Yutong and Yao, Zhuliang and Xie, Zhenda and Wei, Yixuan and Ning, Jia and Cao, Yue and Zhang, Zheng and Dong, Li and others},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={12009--12019},
  year={2022}
}

@inproceedings{dong2022cswin,
  title={Cswin transformer: A general vision transformer backbone with cross-shaped windows},
  author={Dong, Xiaoyi and Bao, Jianmin and Chen, Dongdong and Zhang, Weiming and Yu, Nenghai and Yuan, Lu and Chen, Dong and Guo, Baining},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={12124--12134},
  year={2022}
}

@article{jiao2023dilateformer,
  title={Dilateformer: Multi-scale dilated transformer for visual recognition},
  author={Jiao, Jiayu and Tang, Yu-Ming and Lin, Kun-Yu and Gao, Yipeng and Ma, Andy J and Wang, Yaowei and Zheng, Wei-Shi},
  journal={IEEE Transactions on Multimedia},
  volume={25},
  pages={8906--8919},
  year={2023},
  publisher={IEEE}
}

@article{quan2023centralized,
  title={Centralized feature pyramid for object detection},
  author={Quan, Yu and Zhang, Dong and Zhang, Liyan and Tang, Jinhui},
  journal={IEEE Transactions on Image Processing},
  year={2023},
  publisher={IEEE}
}

@article{wang2019sas,
  title={SAS: painting detection and recognition via smart art system with mobile devices},
  author={Wang, Zhenyu and Lian, Jie and Song, Chunfeng and Zhang, Zhaoxiang and Zheng, Wei and Yue, Shaolong and Ji, Senrong},
  journal={IEEE Access},
  volume={7},
  pages={135563--135572},
  year={2019},
  publisher={IEEE}
}


@InProceedings{pmlr-v235-xiao24d,
  title = 	 {Improving Transformers with Dynamically Composable Multi-Head Attention},
  author =       {Xiao, Da and Meng, Qingye and Li, Shengping and Yuan, Xingyuan},
  booktitle = 	 {Proceedings of the 41st International Conference on Machine Learning},
  pages = 	 {54300--54318},
  year = 	 {2024},
  editor = 	 {Salakhutdinov, Ruslan and Kolter, Zico and Heller, Katherine and Weller, Adrian and Oliver, Nuria and Scarlett, Jonathan and Berkenkamp, Felix},
  volume = 	 {235},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {21--27 Jul},
  publisher =    {PMLR},
  pdf = 	 {https://raw.githubusercontent.com/mlresearch/v235/main/assets/xiao24d/xiao24d.pdf},
  url = 	 {https://proceedings.mlr.press/v235/xiao24d.html},
  abstract = 	 {Multi-Head Attention (MHA) is a key component of Transformer. In MHA, attention heads work independently, causing problems such as low-rank bottleneck of attention score matrices and head redundancy. We propose Dynamically Composable Multi-Head Attention (DCMHA), a parameter and computation efficient attention architecture that tackles the shortcomings of MHA and increases the expressive power of the model by dynamically composing attention heads. At the core of DCMHA is a Compose function that transforms the attention score and weight matrices in an input-dependent way. DCMHA can be used as a drop-in replacement of MHA in any transformer architecture to obtain the corresponding DCFormer. DCFormer significantly outperforms Transformer on different architectures and model scales in language modeling, matching the performance of models with 1.7x-2.0x compute. For example, DCPythia-6.9B outperforms open source Pythia-12B on both pretraining perplexity and downstream task evaluation.}
}

