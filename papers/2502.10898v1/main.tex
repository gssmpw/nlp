\documentclass[preprint,numafflabel]{elsarticle}
\usepackage[utf8]{inputenc}
\usepackage{amsthm}
\usepackage{float}
\usepackage{graphicx}
%\usepackage{ulem}
\usepackage{mathdots}
\usepackage{verbatim}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{xcolor}
\usepackage{hhline}
\usepackage{subfig}
\usepackage{amsfonts}
\usepackage{multirow}
\usepackage[colorlinks=true,linkcolor=black, citecolor=blue, urlcolor=blue]{hyperref}
\title{Cycle-lengths of Multi-Dimensional $\sigma$ Automata}
\author[1]{Avi Vadali}
\author[2]{Ari Turner}
\address[1]{California Institute of Technology, Pasadena, California 91125, USA}
\address[2]{Department of Physics, Technion, Haifa, Israel}
\newtheorem{thm}{Theorem}[section]
\newtheorem{lma}{Lemma}[section]
\newtheorem{construction}[thm]{Construction}
\newtheorem{corollary}{Corollary}[thm]
\theoremstyle{definition}
\newtheorem{dfn}{Definition}
\newtheorem{ident}{Identity}

\date{April 2022}

\begin{document}

\begin{abstract}
     When the game Lights Out is played according to an algorithm specifying the player's exact sequence of moves, it can be modeled using deterministic cellular automata. One such model reduces to the $\sigma$ automaton, which evolves according to the 2-dimensional analog of Rule 90. We consider how the cycle lengths of multi-dimensional $\sigma$ automata depend on their dimension. The main result of this work is that the cycle-lengths of 1-dimensional $\sigma$ automata and 2-dimensional $\sigma$ automata (of the same size) are equal, and we prove this by relating the eigenvalues and Jordan blocks of their respective transition matrices. We also find that cycle-lengths of higher-dimensional $\sigma$ automata are bounded (despite the number of lattice sites increasing with dimension) and eventually saturate the upper bound. On the way, we derive a general formula for the size of the largest Jordan block of the Kronecker sum of two matrices over $GF(2)$ using properties of Pascal's Triangle.
     

     % When the game Lights Out is played according to an algorithm specifying the player's exact sequence of moves at any given point, it can be modeled using deterministic cellular automata. One such model reduces to the $\sigma$ automaton, where cells evolve according to the XOR of their nearest-neighbors. In this paper, we consider the cycle lengths of $\sigma$ automata and their dependence on the automaton dimension. We prove equality between the cycle-lengths of $1$ and $2$ dimensional $\sigma$ automata by relating the eigenvalues and Jordan blocks of their respective transition matrices. We derive a general formula for the size of the largest Jordan block of the Kronecker sum of two matrices over $GF(2)$ using properties of Pascal's Triangle. Finally, we find that cycle-lengths of higher-dimensional $\sigma$ automata are bounded (despite the number of lattice sites increasing with dimension) and eventually saturate the upper bound.

     
     % We prove that the cycle-lengths of 1 and 2 dimensional $\sigma$ automata are equal by studying the Jordan normal forms and eigenvalues of their transition matrices (which are related by a Kronecker sum). 
     
     % whose rule of evolution posits that the evolved state of any cell is the sum of the current states of the adjacent cells modulo $2$. 
     
     % {\color{red}Maybe describe it in a different way? also is it confusing to say the 2d $\sigma$ automaton. Also, maybe we should say, "we consider the cycle length and how it depends on the dimension."} 

     % {\color{blue} I think we should mention $\sigma$ automaton because its useful if someone if looking for references on $\sigma$ automata to mention it in the abstract. }
     
     
     
\end{abstract}

\maketitle

\section{Introduction}
\par The original Lights Out game consists of a $5 \times 5$ grid of lights, each of which can be on or off. Pressing a light toggles the states of the light itself and the horizontally and vertically adjacent lights. The objective of Lights Out is to turn off all lights. The game naturally lends itself to mathematical analysis, as each light has a set of possible states and pressing a light has well-defined consequences. For the sake of this paper, we assume that the player does not plan ahead; rather they press lights according to an explicit rule. This specific algorithm allows Lights Out to be represented as a cellular automaton whose evolution is described by a matrix. By examining Lights Out through cellular automata, we can observe the behavior of the game without having to account for ``free will."

\par One of the first (and most obvious) algorithms for playing Lights Out is to simply take every light that is on in the current configuration and press it. This rather simplistic rule is what we will refer to as the $\sigma$ automaton, in which cells evolve according to the sum of the states of the vertically and horizontally adjacent cells modulo $2$. This automaton was first explored by Lindenmayer in \cite{lindenmayer}. Torrence (see \cite{torrence}) considered which Lights Out games could be solved by following this rule; he categorized the set of the games that can be solved by pressing all lights in the initial configuration and also considered whether iterating this procedure can solve further cases.
We will build upon Torrence's analysis of the iterations of $\sigma$, noticing that in many cases, rather than leading to a solution, a cycle begins. % {\color{red}We could say most of this green part later, and just say: ``We analyze the length of the cycles." We analyze the number of iterations it takes for the automaton state to repeat (also known as the \textit{cycle-length} of the automaton). The automaton must repeat because it contains a finite number of cells each with a finite number of possible states, so there are a finite number of configurations of the automaton, so it must return at some point to a configuration it has reached earlier and then begin repeating. Although the automaton may not return all the way to the beginning. %Additionally, the configuration that an automaton repeats on is not necessarily the first one (as we later discuss); 
% One of many reasons for this is that there might not exist a state that becomes the initial configuration under the evolution rule
% %One of many reasons for this is that it might not be possible to generate the first configuration from any other configuration
% (as noted by Guan and He in \cite{guanHe} and Kawahara et al. in \cite{Periodsin2D})}. 
Cycling automata have many fascinating potential configurations such as fixed points (that don't evolve at all) and shift points (where after some number of iterates they evolve to a spatially shifted configuration) \cite{Voorhees}. In this work we are primarily interested in characterizing the general behavior of an automaton of a given size rather than analyzing particular configurations. We consider the least common multiple of the length of cycles for all configurations (the \textit{cycle-length}), and we analyze the relationship between this quantity and the automaton dimension.

\par Now imagine 1-dimensional Lights Out where pressing a light toggles the state of the light that is pressed and the two lights adjacent to it. % {\color{red}leave out the boundary condition? or explain the boundary condition also for 2d Lights Out? Here we assume that the lights at the edges of the strip are unconnected (null boundary conditions).} 
We can follow the same strategy as in 2D to turn this into a deterministic automaton,  arriving at the $\Phi$ automaton. Like its 2-dimensional counterpart the $\sigma$ automaton, the $\Phi$ automaton will also repeat its configurations.  This automaton, including its cycle lengths, was studied as an example of the interesting variety of dynamics in cellular automata by Martin, Odlyzko, and Wolfram \cite{wolfram}. They found that the cycle lengths depend in complicated ways on the size of the system, which can be partly predicted but not completely (see Section~\ref{sec:phi_Jordan_form} for a discussion of the chaotic behavior).

\par We looked at data for the cycle lengths of the $\Phi$ and $\sigma$ automaton (see the table in Section~\ref{sec:conj_rel_CL}) and noticed that the cycle lengths are equal to one another. Below we explain this phenomenon by analyzing the relationships between the matrices of 1 and 2 dimensional automata (Guan and He use these matrices to study other properties of these cellular automata in \cite{guanHe}).
The fact that the periods have similar orders of magnitude has to do with the linearity and translational symmetry of these automata; their exact equality is a property specific to these two automata.

\begin{comment}\par Since the $\Phi$ and $\sigma$ automata both have a finite number of potential configurations, they must cycle at some point. However, an $n \times 1$ $\Phi$ automaton has $2^n$ possible states while an $n \times n$ $\sigma$ automaton has $2^{n^2}$ possible configurations, so the cycle length of $\sigma$ could be much longer. 

We looked at data for the cycle lengths (see the table in section~\ref{sec:conj_rel_CL}) and noticed that, in fact, the cycle lengths are equal to one another despite the absence of a simple pattern for the cycle lengths as a function of system size (see section ~\ref{sec:phi_Jordan_form} for a discussion of the chaotic behavior).  We will prove this by analyzing the relationships between the matrices of 1 and 2 dimensional automata (Guan and He perform a similar analysis in \cite{guanHe})
\end{comment}

% During the investigation an additional interesting result will be shown--for symmetric initial configurations of $1 \times 2n$ $\Phi$ automata, the cycle-lengths are half of what is found for asymmetric ones (see Section \ref{sec:crit_seq}). 


% \subsection{Problem Statements}
% \par We first began exploring the $\sigma$ and $\Phi$ automata because we had manually evolved a few configurations of $\sigma$ automata (with initial seed of $0$, $1$, and $2$ lights on), and we found that the configurations eventually began cycling (for the reasons discussed in the Introduction). In addition to varying the size of the $\sigma$ automata we evolved, we also changed the initial seed, as the initial configuration affects how the automaton's evolved states cycle. By doing this and keeping track of the first configuration in the cycle, we saw that cycles of $\sigma$ automata do not generally contain the initial configuration. This was an interesting result because it demonstrated that the automata were not periodic. Thus every sequence of $\sigma$ automata has two parts: the first portion begins with the initial configuration ($\boldsymbol{g_0}$) and builds to the beginning of the cycle. The second portion is the cycle itself. 

% \par We figured that the cycle-lengths of $\sigma$ automata must follow some pattern, so we resolved to continue evolving states of automata. But because manually evolving cellular automata becomes very difficult very quickly, we programmed a simulation to evolve and determine the cycle-length of $100$ different-sized (with size randomly selected between $1$ and $250$) $\sigma$ automata. We immediately saw that for certain sized automata, the cycle-lengths were of a particular form. Specifically, for automaton sizes ``near" powers of $2$, we were able to find formulae for the cycle-lengths of $\sigma$ automata. For example, the cycle-lengths of $1 \times 2^k$ and $1 \times 2^k + 1$ $\Phi$ automata are $2^{k+1} - 2$ and $2^{k+1} - 4$ respectively (the proofs are given in section $2.3$), and using the fact that the cycle-length of $\Phi$ is equal to that of $\sigma$ (this is proven in section $3.2$), these formulae also describe the cycle-lengths of $2^k \times 2^k$ and $2^{k+1} \times 2^{k+1}$ $\sigma$ automata. Additionally, there does not appear to be a general formula to determine the cycle-length of a $\sigma$ automaton of arbitrary size. We speculate that this is because there is no general method of determining the order of a particular element within a field (the algebraic structure) of characteristic $2$ by inspection (this reasoning will become clearer in Section $3.2$); however, we leave the proof that there is no general formula for the cycle-length of an arbitrary $\sigma$ automaton as a task to the reader.

% \par Out of curiosity, we decided to look up our sequence of cycle-lengths of $\sigma$ automata on OEIS (an online database of integer sequences), and (to our surprise), we got a hit on OEIS entry A268754 $\cite{oeis}$. This suggested that the cycle-lengths of the $\sigma$ automata appeared to be identical to those of the B1/S automaton. Since the B1/S is a 1-dimensional automaton, we reasoned that it was likely related to the $\Phi$ automaton in some way (I show the relationship in Theorem $4.1$).

% \par By showing that the B1/S and $\Phi$ automata are equivalent for certain initial configurations, we found that the cycle-lengths of the $\sigma$ and $\Phi$ automata ``appeared" to be equal. Since data is not sufficient for mathematicians, we sought to prove this theorem. In order to prove the existence of a relationship between the $\Phi$ and $\sigma$, we realized that representing the rules of evolution of the automata as matrices would allow us to simply compute powers of these transition matrices to determine cycle-lengths. In the Introduction, we noted that other researchers discovered a general formula for the characteristic polynomial of the transition matrix of the $\Phi$ automaton, and we used this fact to strengthen our understanding of the $\Phi$ automaton. We was able to derive expressions for the cycle-lengths of automata of particular sizes (see Theorems $2.5$ and $2.6$), and we was even able to prove the existence of critical sequences in $\Phi$ automata of even sizes (which we do in Theorem $2.7$). As we continued exploring the $\Phi$ automaton, we found more and more common properties that this specific automaton shared with the $\sigma$ automaton, so we eventually attempted to prove the equality of their cycle-lengths. This proof was separated into two parts: an equality of the Jordan forms (see section $3.1$) of the automata and a comparison of the eigenvalues of their transition matrices. After many failed attempts (which we acknowledge in Section 3.2), we saw that an eigenvalue approach combined with a meticulous analysis of automaton boundary conditions yielded an elegant proof (see Theorem $3.9$). 

% \par Upon finally proving this equality, we realized that not only did the theorem we had proven have potential applications in the field of cellular automata, but the general approach we took could also be used to study other automata. We cover many of these applications at the end of this paper, so we will now commence our rigorous exploration of the $\Phi$ automaton. 

\subsection{Experiments on the cycle lengths}
%\subsection{Conjecturing the Relation between the Cycle Lengths}
\label{sec:conj_rel_CL}

Dynamics of most automata are somewhat chaotic, so it would be reasonable to guess that cycle lengths depend in a random way on the size of a system. Besides this,  the cycle lengths should be larger when $n$ is larger.
Naively, one might expect a $1\times n$ system to have a cycle length of order $2^n$ and an $n\times n$ system to have a cycle length of order $2^{n^2}$, as these are the numbers of possible configurations of the systems. The number of steps in the longest periodic cycles for both $\sigma$ (2D) and $\Phi$
(1D) Lights Out games for various $n$'s are shown in table~\ref{fig:cycle_table}. Aside from $n=2,4$, the cycle lengths are the same for all small $n$'s.

%\begin{table}[ht]
%\begin{center}
%\begin{tabular}{||c c c||} 
% \hline
% $n$ & $CL(n)$ for $\Phi$ & $CL(n)$ for $\sigma$ \\ [0.5ex] 
% \hline\hline
% 1 & 1= $2^0\frac{(2^1-1)}{1}$ & "\\
% \hline
% 2 & 2=$2^1\frac{(2^1-1)}{1}$ &$1=2^0\frac{(2^1-1)}{1}$\\
% \hline
% 3 & 1=$2^0\frac{(2^1-1)}{1}$ &"\\
% \hline
% 4 & 6=$2^1\frac{(2^2-1)}{1}$&2=$2^1\frac{(2^1-1)}{1}$\\
% \hline
% 5 & 4=$2^2\frac{(2^1-1)}{1}$&"\\
% \hline
% 6 & 14=$2^1 \frac{(2^3-1)}{1}$&" \\ 
% \hline
% 7 & 1 = $2^0 \frac{(2^1-1)}{1}$&" \\
% \hline
% 8 & 14 = $2^1 \frac{(2^3-1)}{1}$&" \\
% \hline
% 9 & 12 = $2^2 \frac{(2^2-1)}{1}$&" \\
% \hline
% 10 & 62 = $2^1 \frac{(2^5-1)}{1}$&" \\
% \hline
% 11 & 8 = $2^3 \frac{(2^1-1)}{1}$&" \\
% \hline
% 12 & 126 = $2^1 \frac{(2^6-1)}{1}$&" \\
% \hline
% 13 & 28 = $2^2 \frac{(2^3-1)}{1}$&" \\
% \hline
% 14 & 30 = $2^1 \frac{(2^4-1)}{1}$&" \\
% \hline
% 15 & 1 = $2^0 \frac{(2^1-1)}{1}$&" \\
% \hline
% 16 & 30 = $2^1 \frac{(2^4-1)}{1}$&" \\
% \hline 
% 36 & 174762 = $2^1 \frac{(2^{18}-1)}{3}$&" \\
% \hline
%\end{tabular}
%\end{center}
%\caption{Cycle-length of 17 $\Phi$ and $\sigma$ automata with size $n$; except for $n=2,4$ they are the same. Here $CL(n)$ denotes cycle-length, and each cycle-length is of the form  $2^k \frac{(2^j-1)}{q}$ (see third column). Usually $q=1$, but there are a few cases (ex. $n=36$) when $q > 1$.}
%\label{fig:cycle_table}
%\end{table}

\begin{table}[ht]
\begin{center}
\begin{tabular}{||c c c||} 
 \hline
 $n$ & $CL(n)$ & $CL(n)$ \\ [0.5ex] 
 \hline\hline
 6 & 14 & $2^1 \frac{(2^3-1)}{1}$ \\ 
 \hline
 7 & 1 & $2^0 \frac{(2^1-1)}{1}$ \\
 \hline
 8 & 14 & $2^1 \frac{(2^3-1)}{1}$ \\
 \hline
 9 & 12 & $2^2 \frac{(2^2-1)}{1}$ \\
 \hline
 10 & 62 & $2^1 \frac{(2^5-1)}{1}$ \\
 \hline
 11 & 8 & $2^3 \frac{(2^1-1)}{1}$ \\
 \hline
 12 & 126 & $2^1 \frac{(2^6-1)}{1}$ \\
 \hline
 13 & 28 & $2^2 \frac{(2^3-1)}{1}$ \\
 \hline
 14 & 30 & $2^1 \frac{(2^4-1)}{1}$ \\
 \hline
 15 & 1 & $2^0 \frac{(2^1-1)}{1}$ \\
 \hline
 16 & 30 & $2^1 \frac{(2^4-1)}{1}$ \\
 \hline 
 36 & 174762 & $2^1 \frac{(2^{18}-1)}{3}$ \\
 \hline
\end{tabular}
\end{center}
\caption{Cycle-length of 12 $\Phi$ and $\sigma$ automata with size $n$. Here $CL(n)$ denotes cycle-length, and each cycle-length is of the form  $2^k \frac{(2^j-1)}{q}$. Usually $q=1$, but there are a few cases (ex. $n=36$) when $q > 1$.}
\label{fig:cycle_table}
\end{table}

 The fact that the cycle lengths in one and two dimensions are not exponentially different may be explained by a result of Martin, Odlyzko, and Wolfram~\cite{wolfram}. They showed that for many $d$-dimensional cellular automata with side-length $n$, the cycle-length is a divisor of $2^j(2^k-1)$, say $2^j(2^k-1)/q$. Here $j$ and $k$ are particular numbers that depend on $n$ but not on the rule of evolution or the automaton dimension! 
This is true for all automata with two properties. First, the rule of evolution is linear: the new state is given by a sum modulo 2 of the states of specific neighbors. Second, the rule is homogeneous: each site evolves according to the same rule. Note that the $\Phi$ and $\sigma$ are not exactly homogeneous because of the edges, but we will see in section \ref{sec:reflection} that they can be mapped to systems without boundaries.
%where the rule for the state change of each cell is to replace it by a sum modulo 2 of specific neighbors, that is, it is a linear rule, and such that every light follows the same rule and the boundary conditions are periodic (the $n^\mathrm{th}$ site is considered to be next to the $1^\mathrm{st}$). Note here that cell states are represented by integers modulo $2$ ($0$ for ``off'' and $1$ for ``on''). Although the boundary conditions are not periodic for the $\sigma$ and $\Phi$ automata, \cite{images} shows that they are equivalent to automata with periodic boundary conditions.


%{\color{green}The conditions for this result are that the cellular automaton must be a linear automaton represented by a circulant matrix--see section[not sure which yet]  for the explanation of this terminology.}
This result does not explain why the cycle lengths of $\Phi$ and $\sigma$ are exactly the same, as the factor $q$ can vary randomly. For example, for $n=36$ the value of $q$ is 3 in both 1 and 2 dimensions, which suggests that the cycle length is always the same.



%There is actually a reason for the cycle lengths in one and two dimensions to be similar in size (although not always equal).  Martin, Odlyzko, and Wolfram studied the cycle lengths of periodic cellular automata in one dimension, where the $1^\mathrm{st}$ and $N+1^\mathrm{st}$ site are identified.  If the cellular automaton is linear (the new states are the sum modulo 2 of lights at specific distances) and has a translational symmetry (every light follows the same rule),
%they showed the cycle length is a divisor of $2^{sord_N{2}}-1$ when $N$ is odd.  The exponent is the ``suborder" of 2 modulo $N$, which is the first power of 2 that is equal to $1$ or $-1$ mod. 2.  


%This same theorem applies in two dimensions for cellular automata on a square grid (explaining why the cycle length is not as big as $2^{N^2}$, as we might have expected).



%This also suggests that the agreement between the cycle lengths in 1 and 2 dimensions for a few sizes could be coincidences, since it is so common for the cycle length to equal to $2^{sord_N(2)}-1$ for any cellular automata (with the right type of symmetry).  Before trying to prove that the two dimensions always have the same cycle length, it is a good idea to check cycle lengths of many sizes, and especially to look for cycle lengths that do not match the limiting length.
%This is shown in the following table:

%The cycle lengths for automata of size $n$ are compared to $2^{sord_{2n+2}}-1$ because this is the size of the automaton according to the method of images.



\subsection{Automata and Matrices}
\par %The Lights Out game (for the specific algorithm we are studying) is a linear cellular automaton. 
On a Lights Out grid, we will represent a light that is on with a $1$ and a light that is off with a $0$, and the state of all lights can be represented by a vector $\textbf{v}$ of 1's and 0's. When Lights Out is treated as a deterministic automata, one can see that the state of a given light after one step becomes
the sum modulo 2 of its neighbors (not including itself).  This is a linear rule, and it can be described by $\textbf{v}\rightarrow A\textbf{v}$, where $A$ is a transition matrix.

%The $\Phi$ automata are 1-dimensional analogs of $\sigma$ automata, so the states will be $n \times 1$ vectors and the rule of evolution will be an $n \times n$ matrix.
%\par We want to represent the rule of evolution of $\Phi$ automata as an $n \times n$ transition matrix, and we can accomplish this by considering how the matrix should transform each individual cell. We define the transition matrix $A$ as follows: if the vector $\textbf{v}$ is an automaton state, then the evolved state of $\textbf{v}$ is given by $A \textbf{v}$. 
For the $\Phi$ automaton, $A$ is an $n\times n$ matrix. Sutner gives it in \cite{sutner} as
$$A_n = 
\begin{pmatrix}
0 & 1 & 0 & \dots &0 & 0 \\
1 & 0 & 1 & \dots &0 & 0 \\
0 & 1 & 0 & \dots &0 & 0 \\
\vdots & \vdots & \vdots & \ddots&0 & 1 \\
0 & 0 & 0 & \dots&1 & 0
\end{pmatrix}
$$
(We will sometimes write $A$ instead of $A_n$.)  The matrix for the $\sigma$ automaton is more complicated and will be described later on.

\par The cycle length is a meaningful quantity for both automata because the $\Phi$ and $\sigma$ automata must eventually repeat: Since they contain a finite number of cells, each with a finite number of possible states, both automata will cycle through a finite number of configurations.  The configuration does not need to return all the way to the beginning; this is related to the fact that some states can never be the state that another state evolves into, as noted by Guan and He in \cite{guanHe} and Kawahara et al. in \cite{Periodsin2D}. Hence the cycle length counts the number of states that are repeated after the cycle has begun.

\par
For an automaton represented by the matrix $X$, we can take any initial seed $\textbf{v}$ and consider its iterates $X^k\textbf{v}$. The cycle length of $\textbf{v}$ is defined as the least nonzero $i$ such that 
\begin{equation}
\label{eq_CL_def}
    X^k \textbf{v} =X^{k+i} \textbf{v}
\end{equation}
where $X^{k} \textbf{v}$ is any configuration after the beginning of the cycle\footnote{The cycle of $\textbf{v}$ is defined as the sequence of iterates $\{X^{k + j} \textbf{v} \}_{0 \leq j \leq i}$.}.
The cycle length of the \emph{matrix}, $CL(X)$, is the minimum nonzero $i$ such that the matrix $X^k=X^{k+i}$. All initial states $\textbf{v}$ have $CL(\textbf{v})$ that divide $CL(X)$.  This implies that $CL(X)$ can also be defined in terms of configurations as $\mathrm{lcm}_{\textbf{v}} CL(\textbf{v})$.  In fact, there are always configurations that take $CL(X)$ steps to repeat (see~\ref{cyclelength_state}), so  $CL(X)$ is the maximum of $CL(\textbf{v})$. From this point onward, we will use $CL(A_n)$ and $CL(\Phi_n)$ interchangeably to describe the cycle-length of an $n \times 1$ $\Phi$ automaton.

% (the cycle of $X$ consists of the iterates $X^{k + j} \textbf{v}$ for j. Additionally, we will call the sequence of configurations from $X^k \textbf{v}$ through $X^{k+i-1} \textbf{v}$ the cycle of $\textbf{v}$, and the cycle-length of $\textbf{v}$ is denoted by $CL(\textbf{v})$. 


% Different seeds may have different cycle lengths, so we will call the least number $m$ such that any configuration eventually repeats every $m$ steps the cycle length of the automaton, $CL(X)$, or in other words the least $m$ such that the powers of $X$ repeat every $m$ steps. This is just the least common multiple of all cycle lengths of specific configurations.  The cycle length of a specific configuration is called $CL(\textbf{v})$. 

%When we reference the \textit{cycle-length} of a matrix, we mean the least common multiple of the cycle-lengths of all possible initial configurations.
%\par In this paper, we will also introduce a bit of notation to represent the cycle-length of some automaton $R$ defined under some rule with matrix representation $X$. The cycle-length of $R$ is defined as the least nonzero $i$ such that $X^k(R) = X^{k+i}(R)$ where $X^k$ is any configuration after the beginning of the cycle. Additionally, we will call the cycle of $R$ (the initial automaton seed) the configurations $X ^kR$ through $X ^ {k + i - 1}R$. The cycle-length is denoted CL(R) or CL(X).

%In order to determine the cycle-lengths of $\Phi$ automata, we look at the cycle-lengths of $A$ for various sizes ($n$). 

\section{Geometrical Proofs}
\label{sec:geo_proofs}
The fact that the cycle lengths of an $n\times n$ automaton and a $1\times n$ automaton are equal will be proved in general using matrices to represent the automata. We do this by finding the Jordan normal forms for the two cases and relating them algebraically to one another.  This approach is complicated and does not provide an intuitive reason why they are related.  There is a more geometrical derivation that proves part of the result, namely $CL(\sigma_n)|2CL(\Phi_n)$, so that the cycle length in two dimensions is at most twice as large as the one dimensional cycle length. The argument starts from the fact that some patterns of the two dimensional automaton have lights along sets of parallel lines, so they can be related to patterns in the one-dimensional automata.    

\subsection{Green's functions}
The cycle length of an automaton is the least common multiple of the cycle lengths of all configurations of the automaton. However, to find the cycle lengths for the automata we consider, it is not necessary to look at all configurations.
Since the automata are linear, one can find how a configuration with $k$ lights on evolves by considering the pattern-sequences that grow out of any one of the lights by itself and adding them together modulo 2 (in analogy with Green's functions for differential equations). If the cycle lengths of these sequences are $c_1,\dots, c_k$, the full configuration will repeat every
$\mathrm{lcm}(c_1,\dots,c_k)$ steps, so its cycle length is a divisor of this.  Thus

\begin{lma}
    The general cycle length of an automaton defined by a linear rule is the least common multiple of cycle lengths of states with just one light on.\label{lma:greenfunction}
\end{lma}
Note that this is similar to Lemma 3.4 in \cite{wolfram}.

\begin{figure}
    \centering
\subfloat[a][]{\includegraphics[scale=0.5]{pictures0.pdf}}\subfloat[b][]{\includegraphics[scale = 0.5]{pictures21iterates.pdf}} \\
\subfloat[c][]{\includegraphics[scale=0.5]{picture27iterates.pdf}}\subfloat[d][]{\includegraphics[scale=0.5]{pictures73.pdf}}
    \caption{Lights Out patterns with frameworks.  Some patterns are shown that evolve from a starting point (a) with one light on, on a 63 $\times$ 63 board.  (b) is the 21st step, showing a pattern and its framework, which are parallel lines that have the lights that are on at their intersections.  The framework lines evolve according to one dimensional lights out rules on an infinite grid.   Since the lights have not reached the boundary yet, it is as if the grid is infinite. (c) is the 27th step, and shows that once the pattern reaches the boundary (the bottom side), it reflects, so the lights do not stay on the framework any more.  The patterns become much more interesting after the reflections have occurred many times, as shown in (d) (the 73rd step). The light that is on in the first picture has $(x,y)=(31,25)$.}
    \label{fig:grid}
\end{figure}

\subsection{Frameworks}

Consider infinite grids first; they are simpler since there are no boundaries. Additionally, finite grids can be related to infinite grids (as done in the next section). 
The patterns that start with one light on have a specific form: they have a framework of lines whose slope is $\pm45^\circ$, as in Fig. \ref{fig:grid}a,b.  The framework is made from two sets of lines of the forms $x=k+y$ and $x=l-y$ where $k$ and $l$ are integers.  The meaning of a framework is that they determine the lights that are on because these lights are at the intersections of the lines.  The way the pattern changes can be reduced to a rule for how the lines change: the lines which follow the $\Phi$ automaton rule. At each step, a line appears with a value of $k$ if one of the two neighboring lines (at $k\pm 1$) was present at the step before; the lines labeled by $l$'s follow the same rule.

To see that the patterns beginning from one light all have this form, we note that at any step if the lights can be described this way, the lights in the next step can be described this way as well. That is, we consider any two sets of lines $x=y+k,x=l-y$ and let the lights be on at their intersections. We show that the pattern of lights at the next step can be found by applying the $\Phi$ rule to both sets of lines and determining the new intersections.  We will assume that all the lines that are on have even $k$'s and $l$'s, or that they all have odd $k$'s and $l$'s, since otherwise the intersections of the lines are not at integer points.%For this statement we need to generalize the $\sigma$ rule because if a $k$ and an $l$ have opposite parities then the intersection points will be at points of the form $(n+\frac12,m+\frac12)$. The rule will be that the lights at these points also change based on the states of the lights at the points separated from them by $(\pm1,0),(0,\pm1)$.  Thus the lights with integer coordinates and the lights at half-integer coordinates both evolve separately by the $\sigma$ rule.

\begin{thm}
\label{diagonals}
Let $u(j)$ and $d(j)$ be two sequences of 0's and 1's (that are 0 either for odd $j$'s or for even $j$'s).  Consider the state of an infinite $\sigma$ automaton  with lights on at $(x,y)$ for each $x,y$ such that $u(x-y)=1$ and $d(x+y)=1$.  Let it evolve for $k$ steps by the $\Phi$ rule. Then the pattern after $k$ steps is formed in the same way from the patterns that evolve after $k$ steps of applying the $\sigma$ rule to $u$ and $d$.
\end{thm}
\begin{proof}
If this is true for $k=1$, then it follows for any $k$. To prove it for $k$ consider all possibilities for the neighbors of a light at $(x,y)$.  According to the $\sigma$ rule, its next state will be determined by its neighbors at $(x\pm1,y)$ and $(x,y\pm1)$.  All the possibilities for the neighbors are shown in Fig. \ref{fig:quilts}.  There are two lines passing through these neighbors in each direction, each of which can be on or off. The number of neighboring lights in these patterns that are on is 0,1,2 or 4.  Thus, the only time the light at $(x,y)$ will turn on 
is if one neighbor is on at the first step, and this is also the only case where both lines through it will turn on at the next step, following the $\Phi$ rule.  
\end{proof}
%
\begin{figure}[H]
    \centering
    $\includegraphics[scale = 0.5]{quilts.png}$
    \caption{The patterns for the neighbors of a light that can be derived from grids of lines.  The first and third can also be rotated. The state of the center light is not shown, since the state of this light at the next step does not depend on it.}
    \label{fig:quilts}
\end{figure}

\subsection{Reflection Principle{\label{sec:reflection}}}
There is not as simple of a relationship between one and two dimensions for finite Lights Out automata.  If initially one light is on, there will be a framework of lines whose intersections describe the $\sigma$ pattern only until the lights reach the boundary of the board (see Fig. \ref{fig:grid}c,d).

We can relate an automaton on a finite one or two dimensional board to an infinite automaton, using the ``method of images" (used also in electromagnetism). %Since the infinite one and two-dimensional automata are related to one another as in the last section, this relates the finite one and two-dimensional automata to each other.
Consider first the one dimensional case, the automaton $\Phi_n$ with a $1\times n$ row of lights, say at the integers $i= 1$ to $n$.  Any state of these lights can be extended to a state of an infinite array by adding lights that are off at $i=0$ and $n+1$, and treating them as mirrors that reflect the original pattern so that it repeats to infinity, as a kaleidoscope would.  That is, if the state of the automaton is defined by $f(i)$ for $1\leq i\leq n$, define $f_{\mathrm{ref}}(i)$ by finding the remainder $r$ of $i$ modulo $2n+2$ and let  $f_\mathrm{ref}(i)=0$ if $r$ is $0$ or $n+1$, $f_\mathrm{ref}(i)=f(r)$ if  $1\leq r\leq n$ and
$f_\mathrm{ref}(i)=f(2n+2-r)$ if $n+2\leq r\leq 2n+1$. Then the pattern has two reflection symmetries, $i\leftrightarrow -i$ and $i\leftrightarrow 2n+2-i$.

\begin{thm}
\label{reflection}
The evolution of a pattern in $\Phi_n$ is the same as the evolution of just the lights from 1 to n
of its infinitely reflected version. 
\end{thm}
\begin{proof}
Since the extended state $f_\mathrm{ref}$ has the two symmetries $i\leftrightarrow -i$ and $i\leftrightarrow 2n+2-i$, at the first step, it will always have these symmetries.  This implies that $f_\mathrm{ref}(i)=0$ when $(n+1)|i$ after any number of steps: At the first step each one of these lights is off by assumption, and at a later step it will be off because the lights next to it were in the same state one step before (by the reflection symmetry).

Since the lights at 0 and $n+1$ stay off, the neighbors of them change just as they would if these lights did not exist, and thus the lights between $1$ and $n$ evolve as they would in the finite automaton.
\end{proof}

An interesting result from this (but not one that is useful for finding the cycle length) is that the way one light on the finite board evolves can be found in terms of the way that one light on an infinite board evolves: When at first just one the light $i$ is on at the beginning, then the pattern after $t$ steps is 
\begin{equation}
    f(j,t)=\sum_{r=-\infty}^\infty [g(j-i-2r(n+1),t)+g(j+i-2r(n+1)],
\end{equation}
where $g(j,t)$ represents the pattern on the infinite board that starts from one light at $j=0$ when $t=0$. This is found by extending the board to an infinite one.  The initial state will have lights on at $i+2r(n+1)$ and $-i+2r(n+1)$ for all integers $r$.  The sum represents the sum of the patterns derived from these lights.  This sum is defined, because it is not really an infinite sum, since it takes time for the patterns beginning from images that are far away to reach the ``real" part of the board (between 1 and $n$).
Rather than thinking of this sum as patterns emerging from imaginary images, one can also say that when a pattern reaches the edge of the interval, it reflects off of it. Hence the pattern is the sum of what it would be without the boundary together with parts of the pattern that reflect from the boundary.

A Lights Out board in two dimensions can also be thought of as being part of an infinite board with symmetry:
Represent the $n\times n$
  board by lights at $(x,y)$ with $1\leq x,y\leq n$. Let the lights along the lines bordering it, with $x=0$ or  $n+1$ or with $y=0$ or  $n+1$ be off, and reflect the pattern in these lines so that the whole plane is covered.
  As in one dimension, the lights with $1\leq x,y\leq n$ evolve the same way as a finite Lights Out board.

Thus the pattern that grows from an initial seed of one light can be represented as a sum
of patterns from the mirror images of that light.
This is why the pattern in Fig. \ref{fig:grid}c does not follow the framework any more--the lights growing out from the reflection in the lower mirror have ``crossed into the real world'' and they do not fit on the same framework.




If initially one light is on, at $(x,y)$, then the pattern is the sum of the patterns starting from $(x,y),(-x,y),(x,-y), (-x,-y)$ and translations of these by multiples of $2n+2$ in the $x$ and the $y$ direction.
The points can be divided into 8 sets which each form a checkerboard pattern.  One of these, for example,
is the set of points made by shifting $(x,y)$ by $(2n+2)(1,\pm 1)$.  The checkerboard pattern can be represented by frameworks of $\pm45^\circ$ lines, so if it evolves by itself, it is always represented by a framework.
The full pattern can be made by summing the patterns corresponding to the eight checkerboards modulo 2. (The patterns in Fig. \ref{fig:grid} can be represented this way!)
  

%To show that $CL(\sigma_n)|CL(\Phi_n)$, $\sigma_n$ can be represented in this way, as an infinite grid. These patterns, besides the reflection symmetry, also have translational symmetry by $2n+2$ along $x$ or $y$.
%Now the patterns of this repeated version of two-dimensional Lights Out can be reduced to patterns where there is one light in the range $1\leq x,y\leq 2n+2$ and translations of it.  These patterns can be represented by intersections of $45^\circ$ lines if one makes some changes to the intersection pattern.

\subsection{Finite Boards and their Cycle Lengths}

The reflection principle maps patterns in a finite grid to patterns on an infinite plane. These patterns have a cycle length that is finite because the patterns have symmetries. In particular they have translational symmetry, so if one considers just the unit cell, they can be considered as cellular automata on a grid with \emph{periodic} boundary conditions.  We will call the automata on $1\times n$ or $n\times n$ grids with the periodic boundary conditions $\bar\Phi_n$ and $\bar{\sigma}_n$.

\begin{thm}
    $CL(\sigma_n)|CL(\bar\sigma_{2n+2})$
\end{thm}
\begin{proof}
    \label{thm:reflectionswithsquareshape} Any initial condition on $\sigma_n$ can be represented as a pattern on an infinite system by the reflection principle.  This pattern has translational symmetry by $(2n+2,0)$ and $(0,2n+2)$ so its cycle length must be a divisor of $CL(\bar\sigma_{2n+2})$.
\end{proof}
This is interesting because it shows that Ref. \cite{wolfram}'s form for the cycle length in a periodic system, $2^j(2^k-1)/q$ (see Sec. \ref{sec:conj_rel_CL}) also applies to $CL(\sigma_n)$.  This applies also to any dimension, so $CL(\sigma_n)$ has a bound that is independent of the dimension. 

To prove a more specific relationship between $CL(\sigma_n)$ and $CL(\Phi_n)$ (not just that they are both divisors of the same number), we will use the following result:

\begin{thm}
    $CL(\sigma_n)|CL(\bar\Phi_{4n+4})$\label{thm:cross}
\end{thm}
\begin{proof}
By Lemma \ref{lma:greenfunction}, the cycle length of $\sigma_n$ is the least common multiple of cycle lengths of iterates starting with one light at any point. For a light at $(x,y)$,  the reflection principle implies that the iterates are the sum modulo 2 of patterns that are defined by frameworks. One of the patterns has the lights at the points $(x,y)+(2n+2)r(1,1)+(2n+2)s(1,-1)$, where $r,s$ are integers, as the initial seed and the others are translations and reflections of this pattern. The framework lines of this pattern have coordinates of $k=(x-y)+s(4n+4)$ and $l=x+y+r(4n+4)$, which are spaced by multiples of $4n+4$ so their cycle length is the cycle length of $\bar\Phi_{4n+4}$, with one light on initially, i.e. $CL(\bar\Phi_{4n+4})$. Thus the sum of the eight patterns has a cycle length that is a divisor of this, so $CL(\sigma_n)|CL(\bar\Phi_{4n+4}).$
\end{proof}

From this it follows that
$CL(\sigma_n)|2CL(\Phi_n)$ when $n+1$ is not a power of 2 because
\begin{lma}
\label{lma:double} 
For any $k$ except a power of 2, $CL(\bar\Phi_{2k})=2CL(\bar\Phi_k)$. (This is lemma 3.6 of \cite{wolfram}.)
\end{lma}
and
\begin{lma}
For any $n$,
    $CL(\bar\Phi_{2n+2})=CL(\Phi_n)$
    \label{lma:periodicandclosed}
\end{lma}
The proofs use
\begin{lma}
    For an automaton with periodic boundary conditions, if any one light is turned on, the cycle length is equal to the cycle length of the automaton. (This is lemma 3.4 of \cite{wolfram}.) \label{lma:greenfunctionperiodic}
\end{lma}
The last lemma follows from Lemma \ref{lma:greenfunction}, because when there are periodic boundary conditions, the iterates of any one light have the same cycle length, since any light is equivalent to any other. Lemma \ref{lma:double} is true because of a self-similar property of the $\Phi$ automaton: if it is iterated two steps at a time, starting with only lights at even coordinates, then the patterns look just like patterns of an automaton evolved by one step at a time, except with the odd sites skipped. The details of the proof are in Appendix \ref{app:doublelemma}.
To prove Lemma \ref{lma:periodicandclosed}, we use Lemma \ref{lma:greenfunction}.  If one starts with one light at $i$ on this corresponds to configurations on an infinite board where the lights $\pm i+(2n+2)r$ are on (for all $r$). The cycle length must be a divisor of $\bar{\Phi}_{2n+2}$. Also, when $i=1$, the initial configuration (just $\pm 1$ and its periodic copies) is the same as the first iterate of an initial configuration where just multiples of $2n+2$ are on.  Since this configuration has just one light on, its cycle length is the same as $CL(\bar{\Phi}_{2n+2}$) by Lemma \ref{lma:greenfunctionperiodic}.  So the least common multiple of the cycle lengths for all initial sites $i$ is $CL(\bar{\Phi}_{2n+2})$.

So far, we have proved that $CL(\sigma_n)|2CL(\Phi_{n})$ only when $n+1$ is not a power of 2.  But when it is a power of 2, the lights eventually go off (see Appendix in \cite{torrence}) so the cycle length is 1 (for both $\Phi$ and $\sigma$).

We were not able to find a proof of the exact equality of the cycle lengths in one and two dimensions by this method. One can prove that $CL(\bar{\sigma}_{2n+2})=CL(\bar{\Phi}_{2n+2})$ (similarly to Theorem \ref{thm:cross} but with some extra arguments), so the only thing one has to show is $CL(\sigma_n)=CL(\bar{\sigma}_{2n+2})$, the two dimensional analogue to Lemma $\ref{lma:periodicandclosed}$.  However, the same method does not work because there is not a configuration of the $n\times n$ board that obviously has the same cycle length as a single light on the $2n+2\times 2n+2$ board with periodic boundary conditions.  For example, if initially the light $(0,0)$ at the intersection of two mirrors is on (and its symmetric images) then this does not evolve into a configuration that corresponds to a configuration
on the finite board because there are always lights on along the mirrors.
%Consider two initial conditions $u(j)=f(j)$ and $u'(2j)=f(j); u'(2j+1)=0$; i.e. they are the same except the distances between the lights are twice as big in the second configuration.  Then the $2n^\mathrm{th}$ iterate of $u'$ is the same as the $n^\mathrm{th}$ iterate of $u$ except for being scaled by 2.
%By Lemma $\ref{lma:greenfunctionperiodic}$, $CL(\bar{\Phi}_{2k})$ is the cycle length of a pattern on an infinite board with lights at multiples of $2k$. If this is iterated two steps at a time, the patterns are the same as an initial configuration with period $k$, but with the distances doubled, which implies that
%$CL(\bar{\Phi}_{2k})|2CL(\bar{\Phi})_k$.  
%They are actually equal if $k$ is not a power of 2. (If $k$ is a power of 2, the lights always turn off eventually, so $\bar{\Phi}_k=\bar{\Phi}_{2k}=1$.)




%The result can be connected to the self-similar properties of the automaton. One step of the argument uses the result that the lights do not ever turn off completely unless $k$ is a power of 2 from Martin et al. (this can also be shown using the self-similarity of the automaton, but it is easier to just use the Martin et al.'s method).
%Consider two initial conditions $u(j)=f(j)$ and $u'(2j)=f(j); u'(2j+1)=0$; i.e. they are the same except the distances between the lights are twice as big in the second configuration.  Then the $2n^\mathrm{th}$ iterate of $u'$ is the same as the $n^\mathrm{th}$ iterate of $u$ except for being scaled by 2.
%(This can be checked for $n=1$ and the general case follows by induction.)

%Now by lemma \ref{lma:greenfunction}, the cycle length of $\bar{\Phi}_k$ is the lcm of cycle lengths of initial states with just one light on in the unit cell; but this is the lcm of many numbers that are all equal to one another, since any light is equivalent when there are periodic boundary conditions. The initial pattern with one light on at 0, for $\bar{\Phi}_{2k}$ is the pattern for $\bar{\Phi}_k$ except multiplied by 2, so if the pattern for $\bar{\Phi}_{2k}$ is iterated two steps at a time, it repeats every $CL(\bar{\Phi}_k)$ pairs of steps.  A possibility that has not yet been ruled out is that it could repeat also half-way between two of these repetitions, if this would be an odd number of steps.  However, the coordinates of the lights that are on alternate between even and odd positions (since initially only even lights are on).  So the configuration cannot repeat after an odd number of steps. 



%coordinates 




%The proof of the second lemma begins by saying that any configuration of $\Phi_n$ corresponds to a configuration of $\bar\Phi_{2n+2}$ by the reflection principle, so its cycles must be a divisor of $CL(\bar\Phi_{2n+2})$.  There is one configuration whose cycle length is the same as $CL(\bar\Phi_{2n+2})$: so the cycle lengths are equal.(...)

%The reason this proof did not lead to an equality between $CL(\Phi_n)$ and $CL(\sigma_n)$ has to do with thm... 
%It only showed that $CL...$ is a divisor of $CL(...)$ because there isn't any pattern on the Lights Out board that corresponds to having just one light on per unit cell. For example, if the light at the corners is turned on, it leads to lights being on along the edges all the time, so this does not correspond to a pattern of $\sigma_n$.



%Let $\bar{\sigma}_m$ be the Lights Out automaton on an $m\times m$ board with periodic boundary conditions, that is the lights at the opposite sides of the boards are adjacent to one another.  This is equivalent to a pattern with an infinite grid that is repeated whenever $x\rightarrow x+m$ or $y\rightarrow y+m$.  Similarly, let $\bar{\Phi}_m$ be Lights Out on a $1\times m$ board with periodic boundary conditions.  The main result is that

%\begin{thm}
%    If $n$ is even, $CL(\sigma_n)|2CL(\bar{\Phi}_{n+1})$.
%\end{thm}
%\begin{proof}
%    The evolution of $\sigma_n$ can be represented as an $n\times n$ square in the repeating mirror image pattern of itself. Any starting pattern in the original $n\times n$ square gets copied three times (by reflecting it and rotating it) to make a $2n+2\times 2n+2$ square that is repeated periodically in the plane.

%    This pattern may be written as the sum of patterns with a single one in each of the $2n+2\times 2n+2$ squares. Say the lights are at $(n+1)(2h,2k)$.
%    We can nearly represent such a pattern by a framework of lines. The diagonals through the lights intersect at one extra point per unit cell, the one at the centers of the squares with corners at the lights, $(n+1)(2h+1,2k+1)$.

%Turn on these lights as well, so that the framework can be used to describe the evolution.

%Consider two steps of the automaton at a time. If at first only lights at sites with even coordinates are on, then when the automaton changes by two steps at a time, the lights that are on always have even coordinates, and if just these sites are considered the automaton follows the same rule as the original automaton (a light turns on if an odd number of its neighbors in the lattice of even coordinates were on two steps before).

%The diagonal lines have even coordinates, $x\pm y$, and the arrangement is periodic with period $2n+2$.  When two steps are considered at a time, they follow the one-dimensional $\Phi$ rule, but with lights at just the even integers. So the system can be regarded as having $n+1$ sites. So the lines in either direction form a periodic pattern of $\bar{\sigma}_{n+1}$.  So the pattern has a period of $CL(\bar{\sigma}_{n+1})$ eventually.  The lights are always at their intersections so they also repeat with this period.

%The lights with even coordinates and the lights with odd coordinates form two independently evolving patterns (when one looks only at the patterns two steps at a time):
%the sites whose coordinates are both even or both affect only other sites whose coordinates are both even or both odd respectively. 

%The initial state has lights at $(n+1)(2h,2k)$ and $(n+1)(2h+1,2k+1)$ which are independent of one another because $n+1$ is odd.
%Thus if one begins with just  the original pattern of one light per unit cell, the pattern that it makes is just the same sequence of patterns but with the odd lights turned off, and its period is $CL(\bar{\sigma}_{n+1})$.
%Since this is what happens when one looks only at every other step, the actual pattern repeats every $2CL(\bar{\sigma}_{n+1})$ steps.
%(It might repeat earlier.  If $CL(\bar{\sigma})_{n+1}$ is odd, it could repeat after this number of steps, because this would not be counted as a repetition when the automaton changes by two steps at a time. \footnote{This is actually not possible, although it is not necessary to show it since the final result is that $CL(\sigma_n)$ is a divisor of $2CL(\bar{\Phi}_{n+1}$.  The reason it is not possible is that the pattern cannot repeat after an odd number of steps. This is because the lights that are on change from being ones with $x\equiv y$ mod. 2 to ones with $x\not\equiv y$ mod. 2 in each step, so the cycle length  can be odd only if all the lights go off (and it is 1). By lemma  * of \cite{wolfram} the lights go off only when $n+1$ is a power of 2, but $n$ is even.}
%So any pattern in $\sigma_n$ also eventually has a period of $2CL(\bar{\Phi}_{n+1})$.
%\end{proof}

%We will use the following result from Wolfram's paper:
%\begin{lma}
%\label{green}
%The least common multiple of all cycle lengths of patterns with period $2(n+1)$ in one dimension
%is the same as the cycle length of a specific pattern where just one light and all its translates is on initially.  The corresponding result in two dimensions is also true.
%\end{lma}

%The reason is that any initial pattern can be made up of patterns where one light is on in each unit cell, by adding them together modulo 2.
%Now we will show that $CL(\sigma_n)|2CL(\Phi_n)$ if $n$ is even, by showing that $CL(\bar{\Phi}_{2n+2})=CL(\Phi_n)$. This implies $CL(\sigma_n)|2CL(\Phi_n)$ since by the previous theorem, $CL(\sigma_n)|2CL(\bar{\Phi}_{n+1})$, and $CL(\bar{\Phi}_{n+1}|CL(\bar{\Phi}_{2n+2})$.  That is because $\bar{\Phi}_{n+1}$ can be represented by patterns that repeat every $n+1$ sites, and these are special cases of patterns that repeat every $2n+2$ sites\footnote{It can be shown that $2CL(\bar{\Phi}_{n+1})=\bar{\Phi}_{2n+2}$ so $CL(\sigma_n)|CL(\Phi_n)$, but the details are more messy--see last footnote.}.


%Define $\bar{\Phi}_{m}$ to be the automaton with the $\Phi$ evolution rule, but on a $1\times m$ rectangle where the first and last rectangle are adjacent to one another.  This is equivalent to considering an infinite automaton with patterns that repeat every $m$ squares.
%We now see that $CL(\Phi_n)=CL(\bar{\Phi}_{2(n+1)})$:
%    By the reflection principle, all patterns of $\Phi_n$ can be represented as patterns of $\bar{\Phi}_{2(n+1)}$.
%    Thus, the cycle length of $\Phi_n$ is a \emph{divisor} of $CL(\bar{\Phi}_{2(n+1)})$.

%The cycle length for $\bar{\Phi}_{2(n+1)}$ could be larger than that for $\Phi_n$, since the patterns that do not have reflection symmetry could have larger periods. But the cycle length of $\bar{\Phi}_{2(n+1)}$ is equal to the cycle length of a configuration with one light on by lemma \ref{lma:greenfunction} (all configurations with one light on have the same cycle length).  If the light at zero is on at the first step, then at the second step the lights at $1$ and $-1$ are on, which is one of the configurations that corresponds to a pattern of $\Phi_n$.

%  The cycle length cannot be increased by starting with an initial condition that doesn't correspond to a pattern of $\Phi_n$.
%  Any initial pattern of $\bar{\Phi}_{2n+2}$ can be reduced to a linear combination (modulo 2)
%  of patterns where only lights with a specific remainder modulo $2n+2$ are on.
%  These all have the same cycle length, so no cycle length can be larger than this length. For this initial pattern (where the remainder is 0), the second step corresponds to a pattern of $\Phi_n$: the lights at $\pm 1$ are on and the light at $0$ is off, so this corresponds to a pattern of $\Phi_n$.
  
  %We have shown that
  %\begin{thm}
  %The cycle length of $\Phi_n$ equals the cycle length of $\bar{\Phi}_{2n+2}$.
  %\end{thm}

% We can also consider periodic cellular automata in two dimensions.  These are defined by a constraint that they must repeat after translations in two directions, e.g. $\bar{\sigma}_L$ has only patterns that repeat when $x$ or $y$ is increased by $L$.  We will use the following helpful result later: 
 % \begin{thm}
%  \label{green}
%  The cycle length for an automaton on a periodic board equals that of the initial state with one light on in each unit cell \cite{wolfram}.
%  \end{thm}
  %since any configuration can be formed by adding such configurations together modulo 2. All such patterns have the same cycle length. If the light that is on at first is $0$ (together with all its translates), then after one step the pattern will be one of the patterns that corresponds to $A_n$--with a light at the left end on. So the cycle length for the periodic $A_\infty$ is at most the cycle length for $A_n$, proving that the two problems have the same cycle lengths.



\begin{comment}

\section{Geometrical Proofs}
The fact that the cycle lengths of an $n\times n$ automaton and an $n\times 1$ automaton are equal will be proved in general using matrices to represent the automata. We do this by finding the Jordan normal forms for the two cases and relating them algebraically to one another.  This approach is complicated and does not provide an intuitive reason
why they are related.  There is a more geometrical derivation for part of the result: some patterns of the two dimensional automaton have lights along sets of parallel lines, so that they can be related to patterns in the one-dimensional automata.  This implies
that if $n$ is odd, $CL(\sigma_n)|2CL(\Phi_n)$, the cycle length of the two dimensional automaton is a divisor of twice the cycle length of a one dimensional one of the same size.   To prove the equality of the cycle lengths (and for both even and odd sizes) is more difficult, and we have not found simple geometrical arguments for it.

\subsection{Green's functions}
The cycle length of an automaton is the least common multiple of the cycle lengths of all configurations of the automaton.  However, to find the cycle lengths for the automata we are studying, one does not actually have to look at all configurations.
Because the automata are linear one can find how a configuration with $k$ lights on evolves by considering the pattern-sequences that grow out of any one of the lights by itself, and then adding them together modulo 2, in analogy with Green's functions for differential equations. If the cycle lengths of these sequences are $c_1,\dots, c_k$, the full configuration will repeat every
$\mathrm{lcm}(c_1,\dots,c_k)$ steps.  So its cycle length is a divisor of this.

So 
\begin{lma}
    The general cycle length of an automaton defined by a linear rule is the least common multiple of cycle lengths of states with just one light on.\label{lma:greenfunction}
\end{lma}
(This is similar to Lemma 3.4 in \cite{wolfram}.)


\subsection{Relating One and Two Dimensional One-Light Patterns}

  Consider the sequence of patterns that start from one light, in two dimensions.  Say first that the grid is infinite. 
  When one iterates, starting from a single light, the patterns have diamond shapes. One sees that each pattern can be derived from a framework of lines sloped at $\pm 45^\circ$, such that the intersections of the lines are the positions of the lights that are on, see Figure \ref{fig:grid}.
  The relation between two steps of the automaton is that
  the positions of either set of lines evolve by the $\Phi$ automaton rule: e.g., if the lines sloping upward are given by $x=y+k$ where $k$ is an integer, then at each step, the line at $k$ turns on if exactly one of its neighbors (the lines at $k\pm 1$) was on at the step before.  



To see this consider any pattern of lights formed by
 the intersections of two sets of lines of the form $x=y+k$, $x=l-y$. 
 Some of these intersection points may be at half-integer points $(n+\frac12,m+\frac12)$, so we will suppose there are lights at points of the form $(n+\frac12,m+\frac12).$ as well as at $(n,m)$.

  When patterns made this way evolve by the $\sigma$ rule they turn into other patterns of the same kind, and the frameworks evolve by the $\Phi$ rule. Since there are lights at $(n+\frac12,m+\frac 12)$, the $\sigma$ rule must be generalized to include them: 
 the neighbors that determine whether a light goes on at the next step will still be the ones that are a unit apart in the $x$ or $y$ direction.  Thus the lights at $(n,m)$ and the lights at $(n+\frac12,m+\frac12)$ will form two independent evolving patterns.
 
 
%Imagine drawing a grid of parallel lines, $x=y+k$.  The lines can also be off (invisible) or on (black).  The lines also change according to the rule of the $\sigma$ automaton--each line appears at a step if one of its neighbors appeared at the last step.  The second grid of lines is given by $x=l-y$ and it also follows the $\sigma$ rules.
\begin{figure}[H]
    \centering
    $\includegraphics[scale = 0.5]{linesandsquares.png}$
    \caption{A pattern from two-dimensional Lights Out with lines drawn through it to show the relationship to one dimensional Lights Out.IS THIS ONE OF THE PATTERNS STARTING FROM ONE LIGHT?}
    \label{fig:grid}
\end{figure}
%Any two one dimensional patterns can be mapped to a set lines at $45^\circ$, and then their intersections can be interpreted as lights on a two-dimensional board.
%Some of these intersections are at points $(x,y)$ where $x$ and $y$ are integers plus one-half. An automaton can be defined with coordinates at $\{(x,y)|x,y\in \mathbb{Z}\ \mathrm{or}\ x-\frac12,y-\frac12\in \mathbb{Z}\}$, by the same rules as $\sigma$; each non-integer point has four neighbors which are also non-integers which determine its state at the next step. 
\begin{thm}
\label{diagonals}
Let $u(j)$ and $d(j)$ be two sequences of 0's and 1's.  Consider the state of an infinite $\sigma$ automaton  with lights on at $(x,y)$ for each $x,y$ such that $u(x-y)=1$ and $d(x+y)=1$.  Let it evolve for $n$ steps by the $\Phi$ rule. Then the new pattern is formed in the same way from the patterns that evolve after $n$ steps of applying the $\sigma$ rule to $u$ and $d$.
\end{thm}
\begin{proof}
If this is proved for $n=1$, then it follows for any $n$. This is easy to see by considering all possibilities for the neighbors of a light at $(x,y)$.  According to the $\sigma$ rule, its next state will be determined by its neighbors at $(x\pm1,y)$ and $(x,y\pm1)$.  All the possibilities for the neighbors are shown in fig. \ref{fig:quilts}.  There are two lines passing through these neighbors in each direction, each of which can be on or off. The number of neighboring lights that are on is 0,1,2 or 4.  The only time the light at $(x,y)$ will turn on 
is if one neighbor is on at the first step, and this is also the only case where both lines through it will turn on at the next step, following the $\Phi$ rule.  

%


%If the number of lights is 2 or 4, then the two neighboring lines in one direction are on, so at the next step the line in between them passing through $(x,y)$ is off, so $(x,y)$ is not one of the intersection points and it also is off according to the $\Phi$ rule because an even number of its neighbors were on originally.
%If the number of neighboring lights is $0$ then in one of the two directions, no lines were on, so also $(x,y)$ will not be an intersection point at the next step which also agrees with the $\Phi$ rule.  If one neighbor is on, then the $\Phi$ rule says that $(x,y)$ will be on at the next step.  On the other hand, one line in each direction next to it is on, so the $\sigma$ rule says both lines through $(x,y)$ will be on, so it will be an intersection point of lines that are on. 


%Alternatively, the state of the $(x,y)$ at the next step
%is the sum of the neighbors modulo 2, i.e., $u(x+1-y)d(x+1+y)+u(x-1-y)d(x-1+y)+u(x-y-1)d(x+y+1)+u(x-y+1)d(x+y-1)$ mod. 2 since a light is initially on if both lines through it are on, i.e., the product of $u$ and $d$ is equal to 1. This is equal to
%$[u(x-y+1)+u(x-y-1)][d(x+y+1)+d(x+y-1)]$, and the factors describe how the upward and downward lines change at the next step by the $\sigma$ rule.
\end{proof}

\begin{figure}[H]
    \centering
    $\includegraphics[scale = 0.5]{quilts.png}$
    \caption{The patterns for the neighbors of a light that can be derived from grids of lines.  The first and third can also be rotated. The center light could be on or off at first (and the lines through it can be on or off), but this does not affect how it will change at the next step, so it is not shown.}
    \label{fig:quilts}
\end{figure}

So the pattern that forms from one light in two-dimensions, which has a framework of one line in each direction, can be reduced to one dimensional one-light patterns.

%state theorem: if initial pattern is %made up of intersections of two grids %of lines whose equations have the %form $x=y+k$ and $x=-y+l$, where %$k,l$ are integers, then the pattern %always can have lines supporting it, %and the rules for which lines are on %is the one dimensional Lights Out %rule.

%proof of this: by induction.  Maybe just look at all possible patterns for the neighbors of each light and show that the rule with lines turning on and off gives the right rule for whether the light goes on and off. Could also give formulas to make it more clear?

\subsection{Reflection Principle}
There is not as simple of a relationship in finite Lights Out automata between one and two dimensions.  If initially one light is on, the patterns of lights are at the intersections of a framework only before the lights reach the edge of the board (see Fig.).


We can relate an automaton on a finite board, with boundaries, to an infinite automaton, using the ``method of images" (as in electromagnetism).

Represent the $n\times n$
  board by lights at $(x,y)$ with $1\leq x,y\leq n$. Let the lights along the lines bordering it, $x=0, n+1$ and $y=0, n+1$ be off, and reflect the pattern through them to get four patterns in the adjacent squares.  Keep repeating this: let all lights on lines $x=r(n+1)$ or $y=r(n+1)$ where $r$ is an integer be off, and reflect through these lines.

When such a pattern evolves, the original lights will evolve as on an $n\times n$ board.  The patterns will stay symmetric always.  Therefore the lights on the mirror lines will stay off because an even number of their neighbors are always on: The neighbors that are not on the mirror lines are mirror images of one another. This implies that the original $n\times n$ part of the array evolves as before, since the lights next to it are off, so it is as if they did not exist.

A Lights Out board in one dimension ($1\leq x\leq n$) can also be reflected (in $x=0,n+1$) to get a pattern on an infinite Lights Out board that evolves the same way.

\subsection{Finite boards and their Cycle Lengths}

Let $\sigma_n$ be the $\sigma$-automaton on an $n\times n$ board, and let $\bar{\sigma}_{n}$ be the
automaton with the same rule but
with periodic boundary conditions--the $n^\mathrm{th}$ light in a row or column is adjacent to the $1^\mathrm{st}$ light in the same row or column.
Then 
\begin{lma}
    The cycle length of $\sigma_n$ is a divisor of $CL(\bar{\sigma}_{2(n+1)})$.
    \label{lma:cldivisor}
\end{lma}
\begin{proof}
    By the method of images, the iterates of any starting state can be related to iterates of a pattern in the infinite $\sigma$ automaton, with reflection symmetry.  Four copies of the $n\times n$ board form a $2(n+1)\times 2(n+1)$ board that is repeated by translations.  So this can also be thought of as $\bar{\sigma}_{2(n+1)}$.
    So configurations of $\sigma_n$ are special cases of configurations of $\bar{\sigma}_{2(n+1)}$,
    so $CL(\sigma_n)|CL(\bar{\sigma}_{2(n+1)}$.
\end{proof}

Also,
\begin{lma}
    The $\sigma$ and $\Phi$ periodic automata of the same size $m$ have the same cycle lengths.\label{lma:checkers}
\end{lma}
\begin{proof}
    By lemma \ref{lma:greenfunction}, the cycle length of either $\bar{\sigma}_m$ or $\bar{\Phi}_m$ (the periodic $1\times m$ automata) are the least common multiples of the cycle lengths of configurations beginning with one light. Because these have periodic boundary conditions they can be represented with infinite grids made of repeating patterns. From this point of view, it can be seen that the cycle length is independent of which light is turned on initially.

    Theorem \ref{diagonals}
shows that the cycle length of a state with one light on in $\Phi_m$ is the same
as the cycle length of a two-dimensional pattern where all lights at $(h,k)m$ and $(h+\frac12,k+\frac12)m$ (where $h,k$ are integers) are turned on initially: that is
there are two one light at the corners of the unit cells and one light at the centers.



If $m$
is odd, half of the lights are at non-integer coordinates and half are at integer coordinates, and lights at integer and non-integer coordinates evolve separately. So the cycle length is the same as the cycle length of either half of this pattern,
which is $CL(\bar{\sigma}_m)$.

By the next two lemmas the cycle lengths for even $m$'s are related to the cycle lengths for $m/2$ in the same way for both $\sigma$ and $\Phi$, so the result is true for all $m$'s.
\end{proof}

\begin{lma}
The lights in $\bar{\sigma}_m$ or $\bar{\Phi}_m$ eventually all turn off for any initial condition when $m$ is a power of $2$ but not for other $m$'s.
\end{lma}
\begin{proof}
(See \cite{wolfram}, lemma 3.5 and Theorem 3.5. The proof given here is basically the same but described more geometrically.)
Consider the two-dimensional case; the two cases are similar.
First, consider an infinite grid with one light on at $(0,0)$.  Then after $2^k$ steps, four lights are on at $(\pm 2^k,0)$ and $(0,\pm 2^k)$.
This is clear after one step.
At the next step, the pattern can be found by summing the patterns that form from each of the four lights. The light at $(1,0)$, by itself, would be changed to the lights at $(0,0),(1,\pm1)$ and $(0,2)$ The light at $(0,0)$ appears in all four patterns so it cancels out.
Each of the lights $(\pm1,\pm1)$ appear in two patterns, so they also cancel.  So only the lights at $(\pm2,0)$ and $(\pm0,2)$ remain.

Now to find the pattern that one light leads to after $2^k$ steps, we can consider the pattern after $2^{k-1}$ steps and replace each light by the pattern it leads to after $2^{k-1}$ steps.  If the pattern after $2^{k-1}$ steps has lights on at $(\pm2^{k-1},0)$ and $(0,\pm2^{k-1})$, then this is like the case just considered, except with $x$ and $y$ multiplied by $2^{k-1}$, so at the end there will be lights at $(\pm2^k,0)$ and $(0,\pm2^k)$.  The result follows by induction.

For the periodic $\sigma_m$, if one light is on initially, this means (when represented by a pattern on an infinite board) that all lights $(mh,mk)$ are on initially.  The patterns that evolve from this are the sums of the patterns that evolve from the individual lights.  If $m$ is a power of 2, then after $m$ steps, we can use the first result to see that all the lights go off.

If $m$ is not a power of 2, then after any number of steps that is a power of $2$, the patterns that evolve from each light do not have any lights in common, so there is no cancellation. So after any power of $2$, there are still lights on, hence there must always be some lights on at every step.

(See the similar result in \cite{wolfram}, lemma 3.5, and the first part of the proof of Theorem 3.5.)

When $m$ is not a power of 2, \cite{wolfram}, lemma 3.4 gives the following result (for the one dimensional case):
\begin{lma} $CL(\bar{\sigma}_m)=2CL(\bar{\sigma}_{m/2})$ if $m$ is even but not a power of 2.  The same result is true for $\bar{\Phi}$.
\end{lma}
\begin{proof}
    We will focus on the two dimensional case again.

    The cycle length is the length of the cycle starting with one light on.
    Say the light is at $(0,0)$ and translations of it.
    Divide the lights up into lights whose coordinates sum to an even number and lights whose coordinates sum to an odd number.  At the first step, all the lights have the first type.  At each step, the lights switch from one type to another.  So the pattern cannot repeat with an odd cycle length unless all the lights go off eventually.  This is not possible by the previous lemma.

    Thus the cycle length is even. To find the period of repetitions, it is not necessary to check every pattern, but only patterns separated by two steps.
    But in two steps, each light turns into lights spaced from it by $(\pm2,0)$ and $(0,\pm2)$, like one iterate of a light but twice as far.    We can therefore measure distances in units of 2, and we see that the pattern will repeat after $CL(m/2)$ pairs of steps.  So the cycle length is $2CL(m/2)$.
\end{proof}

Lemmas \ref{lma:cldivisor} and \ref{lma:checkers} imply that the cycle length of $\sigma_n$ is a divisor of the cycle length of $\bar{\Phi}_{2(n+1)}$.
The cycle length of $\bar{\Phi}_{2(n+1)}$ is the same as the cycle length of $\Phi_n$ though.  The cycle length of $\bar{\Phi}_{2(n+1)}$ is the cycle length when at first  just one light is on.  If initially just the light at 0 and its images $2h(n+1)$ are on, then at the next step, the lights at $\pm1$ and its images are on.  This is the same as beginning with $\Phi_n$ with just the light at 1 on, and its images.  So $\Phi_n$ has a state whose cycle length is equal to $CL(\bar{\Phi}_{2(n+1)})$.  So this is equal to the cycle length of $\Phi_n$ since the patterns in $\Phi_n$, when reflected to cover the plane, are special cases of patterns of $CL(\bar{\sigma}_{2(n+1)})$.

So
\begin{thm}
    The cycle length of $\sigma_n$ divides the cycle length of $\Phi_n$.
\end{thm}
 
 We cannot prove that the cycle lengths of $\sigma_n$ and $\bar{\sigma}_{2(n+1)}$ are equal by the same method we used in one dimension. This is because if at first the light at $(0,0)$ and its periodic images are on, this will never evolve into a configuration that could arise from the reflection principle--there will always be lights on along the lines $x=0$ and $y=0$. 


...............
\begin{thm}
    If $n$ is even, $CL(\sigma_n)|2CL(\bar{\Phi}_{n+1})$.
\end{thm}
\begin{proof}
    The evolution of $\sigma_n$ can be represented as an $n\times n$ square in the repeating mirror image pattern of itself. Any starting pattern in the original $n\times n$ square gets copied three times (by reflecting it and rotating it) to make a $2n+2\times 2n+2$ square that is repeated periodically in the plane.

    This pattern may be written as the sum of patterns with a single one in each of the $2n+2\times 2n+2$ squares. Say the lights are at $(n+1)(2h,2k)$.
    We can nearly represent such a pattern by a framework of lines. The diagonals through the lights intersect at one extra point per unit cell, the one at the centers of the squares with corners at the lights, $(n+1)(2h+1,2k+1)$.

Turn on these lights as well, so that the framework can be used to describe the evolution.

Consider two steps of the automaton at a time. If at first only lights at sites with even coordinates are on, then when the automaton changes by two steps at a time, the lights that are on always have even coordinates, and if just these sites are considered the automaton follows the same rule as the original automaton (a light turns on if an odd number of its neighbors in the lattice of even coordinates were on two steps before).

The diagonal lines have even coordinates, $x\pm y$, and the arrangement is periodic with period $2n+2$.  When two steps are considered at a time, they follow the one-dimensional $\Phi$ rule, but with lights at just the even integers. So the system can be regarded as having $n+1$ sites. So the lines in either direction form a periodic pattern of $\bar{\sigma}_{n+1}$.  So the pattern has a period of $CL(\bar{\sigma}_{n+1})$ eventually.  The lights are always at their intersections so they also repeat with this period.

The lights with even coordinates and the lights with odd coordinates form two independently evolving patterns (when one looks only at the patterns two steps at a time):
the sites whose coordinates are both even or both affect only other sites whose coordinates are both even or both odd respectively. 

The initial state has lights at $(n+1)(2h,2k)$ and $(n+1)(2h+1,2k+1)$ which are independent of one another because $n+1$ is odd.
Thus if one begins with just  the original pattern of one light per unit cell, the pattern that it makes is just the same sequence of patterns but with the odd lights turned off, and its period is $CL(\bar{\sigma}_{n+1})$.
Since this is what happens when one looks only at every other step, the actual pattern repeats every $2CL(\bar{\sigma}_{n+1})$ steps.
(It might repeat earlier.  If $CL(\bar{\sigma})_{n+1}$ is odd, it could repeat after this number of steps, because this would not be counted as a repetition when the automaton changes by two steps at a time. \footnote{This is actually not possible, although it is not necessary to show it since the final result is that $CL(\sigma_n)$ is a divisor of $2CL(\bar{\Phi}_{n+1}$.  The reason it is not possible is that the pattern cannot repeat after an odd number of steps. This is because the lights that are on change from being ones with $x\equiv y$ mod. 2 to ones with $x\not\equiv y$ mod. 2 in each step, so the cycle length  can be odd only if all the lights go off (and it is 1). By lemma  * of \cite{wolfram} the lights go off only when $n+1$ is a power of 2, but $n$ is even.}
So any pattern in $\sigma_n$ also eventually has a period of $2CL(\bar{\Phi}_{n+1})$.
\end{proof}
\end{comment}
\begin{comment}\subsection{Reflection Principle}
There is not as simple of a relationship in finite Lights Out puzzles between one and two dimensions.  If initially one light is on, there will be a framework of lines whose intersections describe the $\sigma$ pattern only until the lights reach the boundary of the board. 

We can relate an automaton on a finite one or two dimensional board to an infinite automaton, using the ``method of images" (used in electromagnetism to find the potential of a charge next to a plate or in a rectangular box). Since the infinite one and two-dimensional automata are related to one another as in the last section, this relates the finite one and two-dimensional automata to each other.

Consider the automaton $\Phi_n$ with a $1\times n$ row of lights (say at the integers $i= 1$ to $n$).  Any state of these lights can be extended to a state of an infinite array as follows:  add one light that is off at each end. Then add reflected copies of the original array beyond these new lights, and then repeat this pattern so that there are symmetries $i\leftrightarrow -i$ and $i\leftrightarrow 2n+2-i$.
In other words, if the state of the automaton is defined by $f(i)$ for $1\leq i\leq n$, we define the repeated pattern $\bar{f}(i)$ by finding the remainder $r$ of $i$ modulo $2n+2$ and letting  $\bar{f}(i)=0$ if $r$ is $0$ or $n+1$, $\bar{f}(i)=f(r)$ if  $1\leq r\leq n$ and
$\bar{f}(i)=f(2n+2-r)$ if $n+2\leq j\leq 2n+1$.

\begin{thm}
\label{reflection}
When the infinitely reflected extension of a pattern on $\Phi_n$ evolves, the lights from $1$ to $n$ will evolve the same way as on a finite board.
\end{thm}
\begin{proof}
Since the initial state $\bar{f}$ has the two symmetries $i\leftrightarrow -i$ and $i\leftrightarrow 2n+2-i$, this implies that after any number of iterates, it will still have these symmetries.  This implies that $\bar{f}(i)=0$ when $(n+1)|i$ after any number of steps: At the first step these lights are off by assumption, and at later steps they will be off because the lights to the left and the right of them at the step before were in the same state, by reflectional symmetry.

This implies that the lights between 1 and $n$ evolve just as the finite automaton does, since the lights at 0 and $n+1$ stay off, so the neighbors of them change just as they would if these lights did not exist.
\end{proof}

%We will use the following result from Wolfram's paper:
%\begin{lma}
%\label{green}
%The least common multiple of all cycle lengths of patterns with period $2(n+1)$ in one dimension
%is the same as the cycle length of a specific pattern where just one light and all its translates is on initially.  The corresponding result in two dimensions is also true.
%\end{lma}

%The reason is that any initial pattern can be made up of patterns where one light is on in each unit cell, by adding them together modulo 2.

Define $\bar{\Phi}_{m}$ to be the automaton with the $\Phi$ evolution rule, but on a $1\times m$ rectangle where the first and last rectangle are adjacent to one another.  This is equivalent to considering an infinite automaton with patterns that repeat every $m$ squares.
We now see that $CL(\Phi_n)=CL(\bar{\Phi}_{2(n+1)})$:
    by the reflection principle, all patterns of $\Phi_n$ can be represented as patterns of $\bar{\Phi}_{2(n+1)}$.
    Thus, the cycle length of $\Phi_n$ is a \emph{divisor} of $CL(\bar{\Phi}_{2(n+1)})$.

In principle, the cycle length for $\bar{\Phi}_{2(n+1)}$ could be larger than that for $\Phi_n$, because of the possibility of patterns that do not have reflection symmetry. But the cycle length of $\bar{\Phi}_{2(n+1)}$ is equal to the cycle length of a configuration with one light on.  If the light at zero is on at the first step, then at the second step the lights at $1$ and $-1$ are on, which is one of the configurations that corresponds to a 
  The cycle length cannot be increased by starting with an initial condition that doesn't correspond to a pattern of $\Phi_n$.
  Any initial pattern of $\bar{\Phi}_{2n+2}$ can be reduced to a linear combination (modulo 2)
  of patterns where only lights with a specific remainder modulo $2n+2$ are on.
  These all have the same cycle length, so no cycle length can be larger than this length. For this initial pattern (where the remainder is 0), the second step corresponds to a pattern of $\Phi_n$: the lights at $\pm 1$ are on and at $0$ is off, so this corresponds to $\Phi_n$ with only the first light on. 
  
  %We have shown that
  %\begin{thm}
  %The cycle length of $\Phi_n$ equals the cycle length of $\bar{\Phi}_{2n+2}$.
  %\end{thm}

 We can also consider periodic cellular automata in two dimensions.  These are defined by a constraint that they must repeat after translations in two directions, e.g. $\bar{\sigma}_L$ has only patterns that repeat when $x$ or $y$ is increased by $L$.  We will use the following helpful result later: 
  \begin{thm}
  \label{green}
  The cycle length for an automaton on a periodic board equals that of the initial state with one light on in each unit cell \cite{wolfram}.
  \end{thm}
  %since any configuration can be formed by adding such configurations together modulo 2. All such patterns have the same cycle length. If the light that is on at first is $0$ (together with all its translates), then after one step the pattern will be one of the patterns that corresponds to $A_n$--with a light at the left end on. So the cycle length for the periodic $A_\infty$ is at most the cycle length for $A_n$, proving that the two problems have the same cycle lengths.

  
  Now in two dimensions, one can extend the $\sigma_n$ automaton to make a periodic automaton as in one dimension.
  Represent the $n\times n$
  board by lights at $(x,y)$ with $1\leq x,y\leq n$. Let the lights along the lines bordering it, $x=0, n+1$ and $y=0, n+1$ be off, and reflect the pattern in them to cover the plane.  
  This will give a special pattern on the cellular automaton $\bar{\sigma}_{2n+2}$. As in theorem \ref{reflection},
  \begin{thm}
  \label{twokindsofbc}
  Any pattern of $\sigma_n$ and the corresponding pattern on $\bar{\sigma}_{2(n+1)}$ formed by repeated reflections have the same cycle length.  
  \end{thm}

  This implies that $CL(\sigma_n)|CL(\sigma^\mathrm{per}_{2(n+1)})$. The periods are equal (as follows from the algebraic arguments later on), but
  we cannot prove that the cycle lengths are equal by the same method we used in one dimension. This is because if initially the light at $(0,0)$ and its periodic images are on, this will never evolve into a configuration that could arise from the reflection principle (there will always be lights on along the lines $x=0$ and $y=0$).  
  
  The reflection principle has shown that
  \begin{thm}
  \label{kaleidoscope}
$CL(\Phi_n)=CL(\bar{\Phi}_{2(n+1)})$ and $CL(\sigma_n)|CL(\bar{\sigma}_{2(n+1)})$.
  \end{thm}
 

\subsection{Checkerboard Periodicity}
Now the mapping between one and two-dimensional automata (Theorem \ref{diagonals}) implies that
the one and two dimensional periodic automata (with equal dimensions $l$) have the same cycle lengths.
We will prove this for $l\equiv 2\mod 4$.  This can be combined with Theorem \ref{twokindsofbc} to show that $CL(\sigma_n)|CL(\Phi_n)$ when $n$ is even.

By Theorem \ref{green}, the maximal cycle length for $\bar{\Phi}_l$ is the cycle length when starting with one light at 0 and all lights congruent to it modulo $l$. Theorem \ref{diagonals}
shows that this is the same
as the cycle length of a two-dimensional pattern where all lights at $(h,k)l$ and $(h+\frac12,k+\frac12)l$ (where $h,k$ are integers) are turned on initially, a pattern similar to a checkerboard. This is clearly a \emph{divisor} of $CL(\bar{\sigma}_l)$.
If $l$ is odd, half of the lights are at non-integer coordinates and half are at integer coordinates, and lights at integer and non-integer coordinates evolve separately. So the cycle length is the same as the cycle length of $\{(h,k)l\}$, which is $CL(\bar{\sigma}_l)$.

We actually need the result for the case where $l$ is 2 mod 4.
In this case, notice that the cycle length $p$ of $\bar{\Phi}_l$ is even unless $l=2$.
The maximal cycle length is the same as the cycle length if, initially, the lights at multiples of $l$ are on.  Since the lights that go on at each step are one unit away from the lights that are on at the step before, and only even-numbered lights are on initially, lights alternate from being on at even sites to odd sites.  Hence the cycle length is clearly even, except if at some point all the lights go off.  This happens only when $l$ is a power of $2$ (see \cite{wolfram}) or since we assumed $l$ is twice an odd number ($l=2$).

In two dimensions, if the board starts with lights on
at $(h,k)l$ and $(h+\frac12,k+\frac12)l$ then the cycle length is also $p$ (with $p$ even). Consider these patterns as the sum of the patterns beginning with just the lights at $(h,k)l$ and the patterns beginning with just the ligths at $(h+\frac12,k+\frac12)l$.
Suppose after $j$ steps, these patterns are $P_j$ and $P_j'$ respectively.
The cycle length of each of these two patterns could theoretically be longer than $p$: it could be true that $P_j+P'_j\equiv P_{j+p}+P_{j+p}' \mod 2$ for sufficiently large $j$ even though $P_j\not\equiv P_j'$ and $P_{j+p}\not\equiv P_{j+p}'$.
 However:
\begin{lma}
If initially, in a two-dimensional cellular automaton, just $(0,0)$ is on initially, then after an even number of steps all the lights that are on have even coordinates.  
\end{lma}
\begin{proof}
After two steps, the lights that are on are at $\pm(0,2),\pm(2,0)$.
Now let us assume that after $2k$ steps all the lights on have even coordinates.  The pattern two steps later can be found by replacing each of the lights, e.g. at $(r,s)$ by what it changes to in two steps (four lights at $(r\pm 2,s\pm 2)$) and adding the result together modulo 2. The lights will still all be at even coordinates.  In fact, the pattern after $2k$ steps is identical to the pattern at $k$ steps with all coordinates multiplied by 2.  
\end{proof}  
Thus if $j$ is even, both $P_j$ and $P_{j+p}$ have lights on only at points whose coordinates are both even while $P'_{j}$ and $P'_{j+p}$ have lights on only at points whose coordinates are both odd. As a result, $P_j+P_j'\equiv P_{j+p}+P_{j+p}'$ implies $P_j\equiv P_{j+p}$.
So each pattern has to separately repeat, showing
that the cycle length of $P_j$ is $p$.

Hence
\begin{thm}
\label{1and2periodic}
When $l\equiv 1\mod 2$ or $l\equiv 2\mod 4$,
$CL(\bar{\Phi}_l)=CL(\bar{\sigma}_l)$.
\end{thm}
This theorem is true for any $l$ in fact.
We leave out the details, but it is based on a self-similarity property.
Choose a power of 2 ($2^q$). In one or two dimensions, if initially $0$ or $(0,0)$ (respectively) is on, then the pattern at steps of the form $2^qk$
is identical to the pattern at the $k^\mathrm{th}$ step but with all the coordinates multiplied by $2^q$.  This self-similarity property is true for any linear cellular automaton (independent of the dimension) as long as each cell has the same rule for how its state depends on its neighbors.

 Theorem \ref{1and2periodic} and  Theorem \ref{twokindsofbc} imply
\begin{thm}
$CL(\sigma_n)|CL(\Phi_n)$
when $n$ is even.
\end{thm}

\end{comment}


%First of all the period of $\Phi_l$ is divisible by the same power of $2$, say $2^q$, as $l$ is (this is proved below using matrices but can be proved geometrically, see Wolfram?).  But if initially $(0,0)$ is on, then every $2^q$ steps


%When $l$ is even, we need the following theorem:
%\begin{thm}
%If $2^r|l$ then $2^r|CL(\sigma^{per}_l)$.
%\end{thm}
%See 


%Now we will use theorem \ref{diagonals} to show that $A_\infty$ and $\Phi_\infty$ with periods $2(n+1)$ have the same cycle length, so that the cycle length of $\Phi_n$, in two dimensions is a multiple of the cycle length of $A_n$, or is equal to it.

%The cycle length in one dimension is the cycle length of the pattern where lights at multiples of $2(n+1)$ are on initially.
%The cycle length in two dimensions is the cycle length of the pattern
%where lights at $2(n+1)(j,k)$ for integers $j$,$k$ are on.

%Consider an initial configuration where two lights are on in each unit cell, $(0,0)$ and $(n+1,n+1)$ as well as their translations by $2(n+1)(j,k)$.
%This configuration corresponds to initial $p$ and $r$ patterns in one dimension where the lights at multiples of $2(n+1)$ are on, so its cycle length is the same as the one dimensional cycle length.

%We will now show that the extra light in the center, $(n+1,n+1)$ does not change the cycle length, so this is the same as the two dimensional cycle length.




%Now the cycle length in twowe just have to show that if just the lights at $(n+1)(2j,2k)$ are on, the


%for all in

%The same method can be used to relate a two-dimensional $\Phi_n$ to an infinite one, by adding rows and columns of zeros at $x=0,n+1$ and $y=0,n+1$ and reflecting the configuration across these lines and then repeating this.

%(reasons 2d patterns don't seem to follow lines: reflection images come in sets of two instead of 4--also need centers of squares)

%steps of proof:
%cycle length in one-dimensional strip with l lights=cycle length in one-dimensional periodic strip with 2(l+1) sites.

%cycle length in two-dimensional square ($l\times l$) is a divisor of the cycle length in a $2(l+1)\times 2(l+1)$ square with periodicity in both directions. (they are equal actually, as seen from the experimentation, but we do not know how to prove it using this method)

%cycle length for a general starting pattern in 2 dimensions with the periodicity is the cycle length starting with one light on.

%If you start with two lights on in each square at $(x,y)$ and $(x+l+1,y+l+1)$ the cycle length is the same as the cycle length in one dimension because of the line theorem.

%Having just one light on does not increase the cycle length (or decrease it, which is obvious). 
%(proof is more complicated--needs theorem that in one dimension the cycle length is divisible by $2^k$ where $2^k$ is the largest power of 2 that divides $2(l+1)$--will prove this later both by geometric and matrix proofs (maybe this is in Martin, Wolfram and Odlyzko's paper)

%So the cycle length in one dimension
%is the same as the cycle length for periodic patterns in two dimensions, which is a multiple of the cycle length in an $l\times l$ square.

% \section{$\Phi$ automata and $A_n$}
% \par On a Lights Out grid, we will represent a button that is on with a $1$ and a button that is off with a $0$. For a given cell in the $\Phi$ automaton, its next state is the exclusive-or (XOR) of both adjacent states. Since $\Phi$ automata are 1-dimensional analogs of $\sigma$ automata, the states will be $n \times 1$ vectors and the rule of evolution will be an $n \times n$ matrix.

% \par We want to represent the rule of evolution of $\Phi$ automata as an $n \times n$ transition matrix, and we can accomplish this by considering how the matrix should transform each individual cell. We define the transition matrix $A$ as follows: if the vector $\boldsymbol{v}$ is an automaton state, then the evolved state of $\boldsymbol{v}$ is given by $vA$. Sutner gives the transition matrix $A$ in \cite{sutner}
% $$A_n = 
% \begin{pmatrix}
% 0 & 1 & 0 & \dots & 0 \\
% 1 & 0 & 1 & \dots & 0 \\
% 0 & 1 & 0 & \dots & 0 \\
% \vdots & \vdots & \vdots & \dots & 1 \\
% 0 & 0 & 0 & \dots & 0
% \end{pmatrix}
% $$

% \par
% cycle length depends on the initial configuration

% We have been defining CL(n) as the least common multiple of all cycle lengths.  This is the length of the cycle when raising $A$ to consecutive powers. It can also be shown that there is always some configuration whose cycle length is actually equal to the maximal cycle length (see appendix that I will write, also there is a ref. where they noticed that most initial conditions have the maximal cycle length)


\section{Cycle Lengths and Jordan Normal Form}
\label{sec:CL_and_jordan_form}

To completely prove that the periods of $\Phi_n$ and $\sigma_n$ are the same (except for two values of $n$), we will use Jordan normal forms. Finding the Jordan normal form of a matrix %$A$
$M$ enables one to determine the period when the powers %$A^r$
$M^r$ repeat, i.e., the cycle length. In this section, we find the Jordan normal form for the $\Phi$ automata on a $1\times n$ grid. In the following section, we show a relationship between the $n\times n$ $\sigma$ automaton and the $1\times n$ $\Phi$ automaton, and we use this relationship to analyze the Jordan normal form of $\sigma$.  This will allow us in section 5 to prove that $\sigma$ and $\Phi$ have the same cycle lengths. 
%Although the Jordan forms of $\Phi$ and $\sigma$ are different , there is a relationship between them that will explain the equality of the automata cycle-lengths.

% . However, if the sizes and eigenvalues of the Jordan blocks are identical (but appearing with different multiplicities in the matrices), the cycle-lengths will be equal. Although this is not true for the $\Phi$ and $\sigma$ automata, 

% {\color{red} Is it a good idea to summarize the method here instead of later in the section, like this: Finding the Jordan normal form for $A$
% helps to find this period. In this section we will find the Jordan normal form for the $\Phi$ automata on a $1\times n$ grid. Then in the next section we will show that there is a relationship between the $n\times n$ $\sigma$ automaton and the $1\times n$ $\Phi$ automaton and use this to find the Jordan normal form of $\sigma$. The Jordan forms are different since the sizes of the matrices are different, but if the Jordan blocks are the same, but with different numbers of repetitions, the cycle lengths would be the same.  This is not true, but there is a relationship between the blocks that explains why the cycle lengths are the same.}

\par Every square matrix $L$ has a Jordan normal form $J$, defined as a representation $L = PJP^{-1}$ where $J$ is a block diagonal matrix.  Each  block must correspond to some eigenvalue $\lambda$ of $L$ and have the following form: $$\begin{pmatrix}
\lambda & 1 & 0 & \dots & 0 \\
0 & \lambda & 1 & \dots & 0 \\
0 & 0 & \lambda & \dots & 0 \\
\vdots & \vdots & \vdots & \dots & \lambda
\end{pmatrix}$$,



In order to use the Jordan normal form, we must  extend our working field GF(2) to a larger field (denoted by $\mathbb{F}$).  For $\Phi$, in particular, the characteristic polynomial $p(\lambda)$ of $A$ factors into several polynomials that are irreducible over $GF(2)$.  Thus, to ensure that $A_n$ has a complete set of eigenvalues in the field, we extend the field to include the roots of these irreducible factors (that is, to the splitting field of $p)$,  creating our working field $\mathbb{F}$. We will discuss this more in Section \ref{sec:phi_Jordan_form}, where we find the splitting field and use it to find an upper bound for the cycle length of the $1\times n$ $\Phi$ as a function of $n$.

% {\color{green} We said the next part again later on this page so I cut it out.}

% \sout{Now the period of $A^r$ is the same as the period of $J^r$. In this section we will determine this period in terms of the sizes of the blocks and the eigenvalues of $J$.}

% {\color{green} We basically summarized the paper in a similar way at the beginning of this section, so I thought we could cut it out here.  There are fewer details in the summary at the beginning of the section, so if you think we should, we could copy them from here to that summary.}
% \sout{Afterward, we will deduce the result that the cycle lengths of $\sigma$ and $\Phi$ are the same. The first part of the proof will be to find the eigenvalues and sizes of the Jordan blocks for an automaton in one dimension (see Section~\ref{sec:CL_sigma}, theorems~\ref{thm:eigen_sum}, \ref{thm:odd_alg_mult} and lemma~\ref{lma:even_alg_mult}). Then we will determine the sizes of the Jordan blocks of the 2D automaton matrix (see theorem \ref{thm:T_jordan_block}) and prove that the cycle lengths of $\Phi$ and $\sigma$ are equal (see theorem \ref{thm:CL_equal}).}% There is not a simple formula for what the cycle lengths are in each dimension


\par The cycle length of a matrix is determined by the cycle lengths of the blocks in Jordan form. This is because $A^k = PJ^kP^{-1}$, so any time powers of $J$ repeat, powers of $A$ also repeat. Furthermore, the powers of $J$ are easy to calculate because of the simple form of the blocks.   The Jordan blocks of $A$ come in two varieties: those corresponding to zero eigenvalues and those corresponding to nonzero eigenvalues. Jordan blocks of $A$ corresponding to $0$ eventually become annihilated when raised to a power that is high enough. Before the matrix can begin cycling, all the $0$ Jordan blocks must be annihilated. Thus these blocks determine how many steps it takes for a given configuration to begin cycling.

\par The Jordan blocks of $A$ corresponding to a nonzero eigenvalue all cycle from the very beginning. (If $B^r=B^{r+s}$ for a block like this, then $I=B^s$ because $B$ is invertible.)  This implies that the cycle length of $A$ is the least common multiple of the cycle lengths of blocks with nonzero eigenvalues. The period of one of these Jordan blocks $B$ is determined by two components: the order of the corresponding eigenvalue and the size of the Jordan block. Let $B$ be an $m\times m$ Jordan block. The entries along the $q^\mathrm{th}$ diagonal above the main diagonal of $B^p$ are 
\begin{equation}
\label{eq:jb_entries}
    {B^p}_{(j), (q + j)} = \binom{p}{q} \lambda ^ {p - q}
\end{equation}
for $0 \leq q < m$ and $0 \leq j \leq m - q - 1$. Here $\lambda$ is the eigenvalue corresponding to the block. To find when this is the identity, we must consider binomial coefficients mod. 2. 



%Since we consider the periods of the eigenvalues later on in section \ref{sec:CL_sigma}, we will focus on the size of the Jordan block. We saw that each eigenvalue of $A$ possesses exactly $1$ corresponding Jordan block (see \cite{sutner}), so the size of the Jordan block of $A$ is the algebraic multiplicity of the corresponding eigenvalue. With the Jordan form of $A$ and the relationship between $A$ and $T$, we determine the sizes of the Jordan blocks of $T$ (see Theorem \ref{thm:T_jordan_block}). Then we find the eigenvalues of $A$ (see Theorem \ref{thm:eigen_sum}), and we prove that the eigenvalues of $T$ are all sums of eigenvalues of $A$ (see Theorem \ref{thm:sum=prod}). Next we show that the period of a sum of eigenvalues of $A$ is identical to the lcm of the period of the individual eigenvalues (see Theorem \ref{thm:eig_lcm_equal}). Then we combine this with the analysis of the Jordan blocks to show that the sizes of the Jordan blocks are equal and the lcm of the periods of the eigenvalues are equal, so the cycle-lengths of $\Phi$ and $\sigma$ automata must be equal (see Theorem \ref{thm:CL_equal}).


% \begin{lma}
% \label{lma:lucas}
% The only integers $p$ such that $\binom{p}{q} = 0$ for all $0 < q < p$ are of the form $p = 2^n$ for some $n \in \mathbb{Z}$.
% \end{lma}
% \begin{proof}
%     Recall Lucas' Theorem (see \cite{fine}), which posits that $\binom{a}{i} = \prod_{j=0}^b \binom{a_j}{i_j} \bmod 2$ where $a_j$ and $i_j$ are the $j$th terms of the base-2 expansions of $a$ and $i$ respectively. Then suppose $a \neq 2^n$ (for some integer $n \geq 0$). This implies there exists $k \neq b$ such that $a_k = 1$. Then choose $i = 2^k$, so $i_j = 0$ for $j \neq k$ and $i_k = 1$. Evidently 
%     \begin{align*}
%         \binom{a}{i} &= \prod_{j=0}^b \binom{a_j}{i_j} \\
%         &= \binom{1}{1} \prod_{j \neq k} \binom{a_j}{0} \\
%         &= \prod_{j \neq k} 1 \\
%         &= 1
%     \end{align*}
%     Hence for $a \neq 2^n$, there will always exist some $i$ (with $0 < i < a$) such that $\binom{a}{i} = 1$). Suppose $a = 2^n$. Then clearly $\forall 1 \leq i \leq a - 1$, $\prod_{j=0}^b \binom{a_j}{i_j}  = \prod_{j=0}^b \binom{0}{i_j} = 0$. Thus $a = 2^n$ is the only integer such that $\binom{a}{i} = 0$ for all $0 < i < a$.
% \end{proof}

% \begin{corollary}
% \label{lucas_corollary}
% $\binom{b2^k}{i} = 0$ for all $0 < i < 2^k$ and $0 \leq b,k \in \mathbb{Z}$.
% \end{corollary}
\begin{thm}
    \label{thm:lucas}
    The least integer $p$ such that $\binom{p}{q} = 0$ for all $0 < q < m$ is $p = 2^k$. Here $2^k$ is the least power of $2$ that is $\geq m$.
\end{thm}
\begin{proof}
    \par Recall Lucas's Theorem (see \cite{fine}), which posits that $\binom{p}{q} = \prod_{j=0}^b \binom{p_j}{q_j} \bmod 2$ where $p_j$ and $q_j$ are the $j$th digits of the base-2 expansions of $p$ and $q$ respectively, and $b+1$ is the number of digits of $p$. When one of the factors is $\binom{0}{1}$ it is counted as 0 so $\binom{p}{q}= 0$.  (The formula is written with the assumption that zeros are added to the left of $q$'s binary expansion until $p$ and $q$ have the same number of digits.) 
    
    Suppose $p = 2^k$.
    Then $\binom{p}{q}=0\bmod 2$ for any $q$ between $1$ and $2^k-1$: 
    All the digits of $p$ aside from the first are 0 in this case, while $q$ must have a 1 to the right of this if $1<q<2^{k-1}$.
    %each of these $q$'s has a digit $q_j=1$, in a place $j<k$,while all the digits $p_j=0$.
    %and $0 < q < m$. Thus $\binom{p_j}{q_j}=0$, so $\binom{p}{q}= 0\bmod 2$.  Since $2^k\geq m$, this includes all the $q$'s such that $0<q<m$.
    %Then $q$ is less than $2^k$. It has nonzero digits $q_j$, while $p_j=0$, so $\binom{p_j}{q_j}=0$. Hence $\binom{p}{q}\equiv 0 \bmod 2$.
  
    
    \par Now suppose $p < 2^k$ and show that $\binom{p}{q}= 1\bmod 2$ for at least one $q$ satisfying $0<q<m$.  Define $q$ by starting with $p$ and replacing all its digits by zeros except for the first ``1". Then $\binom{p}{q}= 1\bmod 2$ by Lucas's theorem. This value of $q$ is less than $m$ because it is a power of 2 that is smaller than $2^k$.

    
    Thus the least integer $p$ such that $\binom{p}{q} = 0$ for all $0 < q < n$ is $p = 2^k$.
\end{proof}

% \begin{thm}
%     \label{thm:lucas}
%     The least integer $p$ such that $\binom{p}{q} = 0$ for all $0 < q < n$ is $p = 2^k$. Here $2^k$ is the least power of $2$ that is $\geq n$.
% \end{thm}
% \begin{proof}
%     \par Recall Lucas' Theorem (see \cite{fine}), which posits that $\binom{p}{q} = \prod_{j=0}^b \binom{p_j}{q_j} \bmod 2$ where $p_j$ and $q_j$ are the $j$th terms of the base-2 expansions of $p$ and $q$ respectively. Suppose $p = 2^k$, $0 < q < p$, and $\binom{p}{q} = 1$. This implies that $q_j = 0$ for all $0 \leq j < k$ because $\binom{0}{q_j} = 0$ for $q_j \neq 0$. Then $q_k = 1$ or $q_k = 0$ to ensure $\binom{p}{q} = 1$. Thus $q_k = 1 \implies q = p$ and $q_k = 0 \implies q = 0$, which both result in contradictions. Hence $\binom{p}{q} = 0$.
    
%     \par By the above argument, we know that if $p = 2^k$, then $\binom{p}{q} = \prod_{j=0}^b \binom{p_j}{q_j} = 0$ for all $0 < q < n$. Now suppose $p < 2^k$. This implies that there exists $i < b$ such that $p_i = 1$. Let ${(p)}_0^i$ denote the integer formed truncating the binary digits of $p$ at $i$. Since $i < b$, ${(p)}_0^i \leq 2^{k-1} < n$ (by the definition of $2^k$). Additionally, since $p_i = 1$, ${(p)}_0^i > 0$, so consider $\binom{p}{{(p)}_0^i}$. Clearly $\binom{p}{{(p)}_0^i} = 1$, and $0 < {{(p)}_0^i} < n$, so we reach a contradiction for $p < 2^k$. Thus the least integer $p$ such that $\binom{p}{q} = 0$ for all $0 < q < n$ is $p = 2^k$ (where $2^k$ is the least power of $2$ that is $\geq n$).
% \end{proof}

Now the period of a Jordan block can be found:
\begin{thm}
\label{thm:jb_period_1}
Let $J$ be an $m \times m$ Jordan block corresponding to an eigenvalue $\lambda \neq 0$. Let $s$ be the least integer such that $n \leq 2^s$. Let $t$ be the least positive integer such that $\lambda^t=1$. Then the period of $J$ is $t2^s$.
\end{thm}
\begin{proof}
In order to determine the period of $J$, we consider the equation $J^k = I$, and we solve for the smallest $k$. Since the diagonal of $I$ is composed of all $1$'s, the diagonal entries of $J^k$, that is, $\lambda ^k$, must also equal $1$. Thus the period of $J$ must be a multiple of $t$, the multiplicative order of $\lambda$.
\par For $J^k$ to equal the identity, also all non-diagonal entries must be equal to $0$. By equation~\ref{eq:jb_entries} this requires that $\binom{k}{i} = 0$ for $1 \leq i < m$. By theorem~\ref{thm:lucas}, the least integer $k$ satisfying this condition is $2^s$.
\par Taken together, these two constraints on the period of $J$ imply that the period of $J$ is equal to $lcm(t, 2^s)$. Since $t$ is odd, $lcm(t, 2^s) = t2^s$. 
\end{proof}
This theorem (which is also used by Guan and He in \cite{guanHe}) explicitly connects the periods of the eigenvalues and Jordan blocks of a matrix.  It implies that 
\begin{thm}
    The cycle length of a matrix (with entries in $\mathbb{Z}_2$ ) is $t2^s$ where $t$ is the least common multiple of the orders of the nonzero eigenvalues and $s=\lceil \log_2 m\rceil$ where $m$ is the size of the largest Jordan block with a nonzero eigenvalue.
\label{thm:PeriodsFromJN}
\end{thm}
% {\color{green}I think we also wrote this later on so I cut it out (it also seemed a little bit disconnected).  Do you think we explained this idea enough in other places?}
% \sout{Given the Jordan normal form of the automata, the cycle length is not immediately determined because the orders of the eigenvalues are not simple to find.  So, to prove that the cycle lengths in one and two dimensions are the same, it will be necessary to show the least common multiples of the orders of the eigenvalues are the same without finding them. This will follow from the facts that any eigenvalue of $T$ is a product of two eigenvalues of $A$ (see theorem \ref{thm:sum=prod}), which is a special property of these automata.}

\section{Jordan Normal Form for the $\Phi$ automaton}
\label{sec:phi_Jordan_form}
We will first find the Jordan normal form for $\Phi$ (see theorem \ref{thm:JordanBlocks}).
Note that this result can also be found in Guan and He~\cite{guanHe}, Sutner~\cite{sutner}, and Thomas, Stevens, and Lettieri~\cite{characteristicPolynomialRule150}, all of whom use the Jordan normal form of $A$ (the matrix of the $\Phi$ automaton) to study the dynamics of the cellular automata. 

\subsection{Exploring the Characteristic Polynomial of $A$}

\par We derive the Jordan normal form of $A$ from the characteristic polynomial (which is equivalent to the minimal polynomial in this case).  This is possible because of a result proved by Sutner~\cite{sutner}: each eigenvalue of $A$ has exactly one linearly independent eigenvector.
This implies:
\begin{thm}
  \label{min_p_co}
Each eigenvalue $\lambda$ of $A$ has exactly one Jordan block corresponding to it, and its size is equal to $\lambda$'s algebraic multiplicity as a root of the characteristic polynomial.
\end{thm}

%The minimal polynomial $p(x)$ of a matrix $A$ is defined to be the monic polynomial of least degree such that $p(A) = 0$, and it turns out that the minimal polynomial's roots are the eigenvalues of $A$ (see $\cite{hoffman}$).

%\begin{thm}
%\label{min_poly_A}
%The minimal polynomial of $A_n$ is equal to $p_n(\lambda)$, the characteristic polynomial of $A_n.$
%\end{thm}
%Sutner proves this fact in $\cite{sutner}$, and it can be seen by showing that each eigenvalue of $A$ has exactly $1$ linearly independent eigenvector. This fact will be one of the cornerstones of our analysis of the Jordan form of $A$, since many things that can be said of the minimal polynomial is true of $p(\lambda)$.
%\begin{corollary}
%\label{min_p_co}
%Each eigenvalue $\lambda$ of $A$ has exactly $1$ Jordan block corresponding to it with size equal to $\lambda$'s algebraic multiplicity.
%\end{corollary}
%This can be seen by Theorem \ref{min_poly_A}, which shows that the size of the largest Jordan block corresponding to each eigenvalue is the algebraic multiplicity of that eigenvalue (meaning there can only be $1$ Jordan block per eigenvalue). 

\par It turns out that the characteristic polynomial is actually quite a special one. As Barua proves in  \cite{barRam} it can be seen that the characteristic polynomial $p_n$ of $A$ for the $n\times 1$ automaton are Chebyshev polynomials of the second kind %(see \cite{sutner})
satisfying the recursion
\begin{equation}
\label{eq:cheb_recur}
    p_i(\lambda) = \lambda p_{i-1}(\lambda) + p_{i-2}(\lambda)
\end{equation}
with the initial conditions $p_0(\lambda)=1$ and $p_1(\lambda)=\lambda$.

These polynomials, when considered modulo 2, satisfy some special identities, which will help to find the multiplicities of the eigenvalues.
\begin{thm}
\label{thm:poly_recur}
$p_{2i} (\lambda) = (p_{i}(\lambda) + p_{i-1}(\lambda))^2$, 
$p_{2i + 1}(\lambda) = \lambda ({p_i}(\lambda))^2$
\end{thm}
These recursions (which Sutner proves in \cite{sutner}) can be derived inductively from the defining recursion of the $p_i$ polynomials.  They follow from the fact that $(a + b)^2 = a^2 + b^2$ modulo $2$.% and they will be very useful in determining the multiplicities of eigenvalues.

% \begin{lma}
% $p_k(\lambda) + p_{k + 2j}(\lambda) = \lambda p_{j-1}p_{k+j}.$
% \label{lma:cheb_sum}
% \end{lma}

% \begin{proof}
% \par
% We induct over $j$. The base case, $j=1$, is the same as Eq. \ref{eq:cheb_recur}.
% Now let $j = x$ and assume that this theorem holds for all $j < x.$ Keeping in mind that $p_k + \lambda p_{k+1} = p_{k+2}$, we arrive at the first equation below by simply applying this recursion twice to both $p_k$ and $p_{k+2x}$. 
% \begin{align*}
%     &p_k + p_{k + 2x} = (p_{k+4} + p_{k + 2x - 4}) + \lambda ^2 (p_{k+2x - 2} + p_{k+2}) \\
%     &= p_{k+x}(\lambda ^4 p_{x-2} + \lambda^3 p_{x-1} + \lambda p_{x-1} + \lambda^4 p_{x-2} + \lambda ^3 p_{x-1}) \\
%     &= \lambda p_{k+x} p_{x-1}
% \end{align*}
% \end{proof}

\begin{lma}
\label{lma:even_alg_mult}
All eigenvalues of $p_{2k}$ have algebraic multiplicity $2$, and zero is not a root.
\end{lma}
\begin{proof}
Using theorem \ref{thm:poly_recur} we can write $p_{2k}$ as $(p_k + p_{k-1})^2$.
Hence to verify that all roots have multiplicity 2, it is sufficient to prove that $p_k+p_{k-1}$ does not have repeated roots. To show this, we show that $\frac{d}{d\lambda}[p_k + p_{k-1}]$ and $[p_k + p_{k-1}]$ are relatively prime.  

If $k$ is even, we will show that $\frac{d}{d\lambda}[p_k + p_{k-1}]$ has all its roots in common with $p_{k-1}$ and no shared roots with $p_k$, so that whenever $\frac{d}{d\lambda}[p_k + p_{k-1}] = 0$, $(p_k + p_{k-1}) \neq 0$. Since $k$ is even, $p_{k-1} = \lambda {p_a}^2$ for $a = \frac{k-2}{2}$. As a result, $\frac{d}{d\lambda}[p_k + p_{k-1}] = {p_a}^2.$ The derivative of $p_k$ vanishes  modulo 2 because all the terms in $p_k$ have even exponents.
Thus all roots of $\frac{d}{d\lambda}[p_k + p_{k-1}] = {p_a}^2$ are roots of $p_a^2$, and hence of $p_{k-1}$.  On the other hand, $p_k$ and $p_{k-1}$ are relatively prime (see \cite{barRam}), so they cannot be roots of $p_k$,
proving that $\frac{d}{d\lambda}[p_k + p_{k-1}]$ and $[p_k + p_{k-1}]$ have no roots in common. This implies that 
$p_k + p_{k-1}$ has no repeated roots.
% \par\sout{ To see that zero is not a root of $p_{2k}$, use $p_{k-1}=\lambda p_a^2$ to see that it is a root of $p_{k-1}$. Since $p_k$ is prime to $p_{k-1}$ it is not a root of $p_k$.}
\par If $k$ is odd, we can apply almost the same logic to show $p_{2k}$'s roots have multiplicity 2.
\par To see that zero is not a root of $p_{2k}$ use the recursion Eq. (\ref{eq:cheb_recur}
) to show that $p_{2k}(0)=1$. 
\end{proof}
By theorem \ref{min_p_co} and lemma \ref{lma:even_alg_mult}, this means that all Jordan blocks of $A_{2k}$ have size $2$. We must also consider the sizes of Jordan blocks of $A_n$ for odd $n$. 
\begin{thm}
\label{thm:odd_alg_mult}
When $n$ is odd, all nonzero eigenvalues of $p_{n}$ have an identical algebraic multiplicity $2^{a+1}$, and the eigenvalue $0$ has algebraic multiplicity $2^{a} - 1$ where $a$ is the largest integer such that $2^a | n+1$.
\end{thm}
%\begin{thm}
%\label{thm:odd_alg_mult}
%All nonzero eigenvalues of $p_{2k+1}$ have an identical algebraic multiplicity $2^{a+1}$, and the eigenvalue $0$ has algebraic multiplicity $2^{a} - 1$ where $a$ is the largest integer such that $2^a | 2k + 2$.
%\end{thm}
\begin{proof}
\par Let $n=2k+1$. Repeatedly applying the reduction $p_{2r+1} (\lambda) = \lambda {p_r}^2$ from theorem \ref{thm:poly_recur}  shows that $p_{2k+1} (\lambda) = \lambda ^ {2^{x} - 1} {p_i}^{2^x}$, where $i$ and $x$ are natural numbers with $i$ even.
\par When reducing $p_{2k + 1}$, we stop once we reach even $i$, and this will happen after $x$ reductions. We can find the number of reductions performed by repeatedly subtracting $1$ from $2k + 1$ then dividing the result by $2$. It can be seen that after reducing $p_{2k + 1}$ $x$ times, we will have $p_i$ where $i = \frac{2k + 2}{2^x} - 1.$ This will be even only when $\frac{2k + 2}{2^x}$ is an odd integer, which will occur for the $x$ such that $x$ is the largest integer where $2^x | 2k + 2$. Thus $x = a$.

The multiplicities of the roots of $p_{2k+1}$ can be seen from $p_{2k+1}(\lambda)=\lambda^{2^a-1}p_i^{2^a}(\lambda)$.
Each root of $p_i$ has a multiplicity of two by Lemma \ref{lma:even_alg_mult}, so the multiplicities are $2^a-1$ for zero and $2\times2^a$ for nonzero eigenvalues.
\end{proof}
Lemma \ref{lma:even_alg_mult} and theorem \ref{thm:odd_alg_mult} give the multiplicities of the roots of $p_n(\lambda)$. Summarizing them together:
\begin{thm}
    \label{thm:JordanBlocks}
    If $n+1=2^ab$ where $b$ is odd, then for each nonzero eigenvalue of $A_n$ there is one Jordan block whose size is $2^{a+1}$, and for zero, there is one block whose size is $2^a-1$, unless $a=0$.  
\end{thm}
% {\color{green}We could make this a theorem and then just refer to it in sec. 5.: Summarizing them together:
% \begin{thm}
%     \label{thm:JordanBlocks}
%     If $n+1=2^ab$ where $b$ is odd, then for each nonzero eigenvalue of $A_n$ there is one Jordan block whose size is $2^{a+1}$, and for zero, there is one block whose size is $2^a-1$.  
% \end{thm}
% Old version:
% Summarizing them together: if $n+1=2^ab$ where $b$ is odd, then all nonzero eigenvalues of $A_n$ have the multiplicity $2^{a+1}$ and the multiplicity of zero is $2^a-1$.}  

In particular,
\begin{corollary}
All Jordan blocks of $A_n$ corresponding to a nonzero eigenvalue will have the same size.
\end{corollary}
 
\par We now derive a general form for the eigenvalues of $A$. 
\begin{thm}
For an $n \times 1$ $\Phi$ automaton where $n$ is even, the $n$ eigenvalues of $A$ can be written in terms of an element $\alpha$ of order $n+1$ of a field $\mathbb{F}$ that extends $GF(2)$.  They are equal to $\alpha + \alpha ^{-1}, \alpha ^2 + \alpha ^{-2}, \alpha ^ {3} + \alpha ^ {-3}, \dots, \alpha ^{\frac n2} + \alpha ^{-\frac n2}$.
\label{thm:eigen_sum}
\end{thm}
\begin{proof}
An eigenvector $\textbf{v}$ of $A$ is defined by the following property: $A \textbf{v} = \lambda \textbf{v}$ where $\lambda$ is a scalar. For convenience, we treat the eigenvectors of $A$ as functions $h(x)$ where $h(x)$ is the $x$th entry of the eigenvector, so that this equation can be written as $h_i(x+1)+h_i(x-1)=\lambda h_i(x)$ for $x=1$ to $n$.  For the cells at the two ends, there is no neighboring cell on one side, so $h_i(0)=h_i(n+1)=0$ in this equation.

\par The working field $\mathbb{F}$ can be extended such that for any eigenvalue $\lambda_i$ of $A$, $\lambda_i$ can be written as $\beta _i + {\beta_i}^{-1}$ where $\beta_i \in \mathbb{F}$. Since zero is not an eigenvalue $\beta_i\neq 1$. Then 
\begin{equation}
h_i(x+1)+h_i(x-1)=(\beta_i+\beta_i^{-1})h_i(x),
    \label{eq:recursion}
\end{equation}
for $x=1$ to $n$. This equation gives all of $h_i(x)$'s values in terms of $h_i(1)$. The case $x=1$ gives $h_i(2)$ in terms of $h_i(1)$; the case $x=2$ gives $h_i(3)$ in terms of $h_i(1)$ and $h_i(2)$, and so on.

We can multiply the eigenvector by any non-zero constant, so we can assume that  $h_i(1)=\beta_i + {\beta_i}^{-1}$. 
The case $x=1$ of Eq. (\ref{eq:recursion})
shows that $h_i(2) = (\beta_i + \beta_i^{-1})^2=\beta_i^2+\beta_i^{-2}$. We can repeat this process, finding that $h_i(x) =  {\beta_i}^x +  {\beta_i}^{-x}$, for any $x\leq n+1$.  Because this applies for $n+1$ and $h_i(n+1)=0$,  $\beta_i ^ {2n+2} = 1$. Now $x^2=1$ implies $x=1$ since the characteristic is 2, so $\beta_i^{n+1}=1$.
%Also one can easily check that if $\beta^{n+1}=1$ and $\beta\neq 1$, then $h(x)=\beta^x+\beta_^{-x}$ is an eigenfunction whose eigenvalue is $\beta+\beta^{-1}$

\par  

If the field $\mathbb{F}$ contains  $\beta_i$'s for all the distinct eigenvalues of $A$, then it must contain $n+1$ different solutions to $x^{n+1}=1$, because by lemma \ref{lma:even_alg_mult} there are $\frac n2$ eigenvalues altogether, and for each one there are two roots to $x^{n+1}$,$\beta_i$ and $\beta_i^{-1}$.  Together with 1, this gives $n+1$ distinct solutions.

The nonzero elements of a field form a cyclic group under multiplication.  Let $\mathbb{G}$ be the multiplicative group of $\mathbb{F}$, which is cyclic.
The solutions to $x^{n+1}=1$ form a subgroup of this which is also cyclic, and is generated by some element $\alpha$. It follows that the distinct eigenvalues are $\alpha^i+\alpha^{-i}$ with $1\leq i\leq\frac n2$.  (When $\frac n2<i\leq n$, $\alpha^i+\alpha^{-i}$ repeats the same values.)
 \end{proof}

When $n$ is odd $p_n$ can be written in terms of $p_i$ for some smaller even $i$, as shown while proving theorem \ref{thm:odd_alg_mult}: If $n+1=2^a b$ where $b$ is odd, $p_n(\lambda)=\lambda^{2^a-1}p_{b-1}(\lambda)^{2^a}.$
This implies that
\begin{thm}
    If $n+1=2^ab$ where $b$ is odd, the nonzero eigenvalues of $A_n$ are identical to the eigenvalues of $A_{b-1}$. These eigenvalues are $\alpha^k+\alpha^{-k}$ where $\alpha$ has order $b$, and $1\leq k\leq \frac{b-1}{2}$.
The Jordan normal form of $A_n$ has one $2^{a+1}\times 2^{a+1}$ block for each of these, and has a $(2^a-1)\times (2^a-1)$ block of eigenvalue 0.
\label{thm:powersof2}
\end{thm}

So by Theorem \ref{thm:PeriodsFromJN},
\begin{corollary}
    The cycle length of $\Phi_n$ is equal to $2^{a+1}t$ where $t$ is the least common multiple of the elements $\alpha^k+\alpha^{-k}$ of the field $\mathbb{F}$, and where $\alpha$ is a $b^\mathrm{th}$ root of unity.
    \label{cor:CL}
\end{corollary}

This result would give the cycle length of $A_n$ if one could find the orders of the eigenvalues. But the powers of $\alpha^i+\alpha^{-i}$ are complicated, so it is not easy to find their orders.  We will prove that $\sigma$ and $\Phi$ have the same cycle lengths by finding formulas that relate the eigenvalues of the matrices to one another,  without finding the orders in either case.

%Since $|\beta _i| = n+1$, there must exist some subgroup $H$ of $\mathbb{G}$ containing all elements whose order divides $n + 1$ and with $\beta_i$ as an element (not necessarily a generator). Because all eigenvalues $a_c$ of $A$ are equal to $\beta _c + {\beta_c}^{-1}$ with $\beta_c^{n+1} = 1$, $\beta_c, {\beta_c}^{-1} \in H$. This means if $\alpha$ is a generator of $H$, then any $\beta_i$ can be written as $\alpha ^ i$. Thus the $n$ eigenvalues of $A$ are $\alpha + \alpha ^{-1}, \alpha ^2 + \alpha ^{-2}, \alpha ^ {3} + \alpha ^ {-3}, \dots, \alpha ^{n} + \alpha ^{-n}.$
%\end{proof}
% If the cycle length of $\Phi_k$ is $p2^q$ where $p$ is odd, we now see that $q$ is the largest integer such that $2^q|2k+2$.
%This can also be proved by a geometrical argument.  We consider the periodic $\Phi^{\mathrm{per}}_l$. A $1\times k$ $\Phi$ automaton is equivalent to $l=2(k+1)$ by Theorem \ref{}. 
%{\color{red}
%Theorem we might want to spell out:
%\begin{thm}
%If $l=b2^a$ where $a$ is odd,
%then the cycle length of $\Phi^{\mathrm{per}}_l$ is $p2^a$ where $p$ is odd, unless $b=1$.  If $b=1$, then eventually all lights are off so the cycle length is 1.
%\end{thm}}

%\begin{proof}
%Consider first an infinite strip $\Phi_\infty$,  labelled with whole numbers.  If at first the light at zero is on, then two steps later, the light two steps away from it to the left and the right are both on.
%This is the same as the pattern that forms in one step if one light is on at first, except with the positions doubled.  It follows by induction that after $2j$ steps the coordinates of the lights that are on are twice the coordinates of the lights that are on after $j$ steps. Furthermore, if a configuration is scaled by a factor of two, and the scaled configuration is evolved two steps at a time, then the two configurations will always be scaled versions of one another.
%By induction, if a configuration and a copy of it that is scaled by $2^q$ are compared, then every $2^{q\mathrm{th}}$ configuration of the copy matches its configurations except for being scaled.


%This is a general property of any cellular automaton rule which is linear modulo 2 and where all cells follow the same rule for evolution (it is also true for higher dimensions). (find a reference)

%If at first all lights are on then after one step, they are all off. Hence if at first all lights at multiples of $2^q$ are on, then after $2^q$ steps
%they are all off.
%These are the only periods for which all lights turn off.
%If eventually all lights for period $l$ turn off

%For the periodic case with a period of $l$, the least common multiple of all cycle lengths can be found by finding the cycle length of the configuration where just lights at multiples of $l$ are on at first. Suppose $a=0$.  The cycle length cannot be even.  If it were $2k$ the same configuration would start to repeat every $2k$ steps after some patterns that do not repeat. The initial configuration can be split up into lights with even and odd coordinates, $X_0=X_{e0}+X_{o0}$. The configurations these evolve into in $j$ steps are also related the same way, $X_j=X_{ej}+X_{oj}$. $X_{ej}$ and $X_{0j}$ have lights of opposite parities. (If only even lights are on initially, the parity of the lights changes at each step.) So $X_j=X_{j+t}$ implies that $X_{ej}=X_{e,j+t}$ if $t$ is even and $X_{ej}=X_{o,j+t}$
%if $t$ is odd. So if the cycle length is $2k$, the cycle length of $X_{e0}$ is also $2k$.  But this starts out the same as $X_0$ but with all the coordinates rescaled by 2, so the patterns at even steps are the doubles of the patterns of $X_0$ at all steps, which implies $X_0$ repeats the same patterns every $k$ steps; this is a contradiction since we assumed that the cycle length was 2k!

%Now the cycle lengths for even periods can be found by relating the cycle length for $l=2^{q+1}p$ to the cycle length for $l/2$.
%The cycle length for $l$ must be even: initially only even lights are on, so after even or odd numbers of steps only even or odd lights are on.
%So patterns separated by an odd number of steps cannot match, except if no lights are on at all!






%From a pattern $\Phi(t)$, the pattern $\Phi(t+2)$ (two steps afterward) can be found by the rule that a light is on at $x$ if one of the lights at $x-2$ or $x+2$ is on in $\Phi(t)$. This implies that if one starts 

\subsection{The Fields of $\Phi$ Automata and the Eigenvalue Orders}
\label{sec:phi_fields}
%From theorem \ref{thm:powersof2}and theorem \ref{jb_period_1} it follows that 
%\begin{thm}
%    If $n+1=2^ab$ where $b$ is odd and not equal to 1,
%    then the cycle length of $\Phi_n$ is $2^{a+1}$ times the order of the group generated through multiplication of the eigenvalues $\alpha^k+\alpha^{-k}$, where $\alpha$ has order $b$.
%\end{thm}
%The reason is that the order of this group is the same as the least common multiple of the orders of the eigenvalues because it is a cyclic group.  We will next find a similar way to describe the cycle length of the $\sigma$ automaton; if the 

% {\color{green}Before we didn't define $t$ in this section and we also didn't give a formula for $k$ (in $2^k(2^j-1)/q$. I added something about it but maybe it doesn't fit that well.}

\par Upon first analyzing cycle-lengths of $\sigma$ and $\Phi$ automata (see Table~\ref{fig:cycle_table}), the cycle lengths seem to vary chaotically. As previously mentioned, there are some patterns described in \cite{wolfram} that show the cycle-lengths are of the form $2^k(2^j-1)/q$ (where $k$ and $j$ can be predicted). We now explain this result using the Jordan normal forms (\cite{wolfram} derived the results from generating functions).   The method will be useful for showing that the cycle-lengths of $\sigma$ and $\Phi$ are equal. The result (including the definition of $j$ and $k$) is the following:

% \par {\color{green}I wanted to say something a little different than what we had before.  Here is the new version:
% Upon first analyzing cycle-lengths of $\sigma$ and $\Phi$ automata (see Table~\ref{fig:cycle_table}), the cycle lengths seem to vary chaotically. But, as mentioned above, a lot of this randomness and is explained by the theorem of \cite{wolfram}, which shows that the cycle-lengths are of the form $2^k(2^j-1)/q$ where $k$ and $j$ can be predicted. We will now explain this result using the Jordan normal forms (\cite{wolfram} used generating functions) since this argument will help to show that $\sigma$ and $\Phi$.
% }

% {\color{blue}This is the old version:
% Upon first analyzing cycle-lengths of $\sigma$ and $\Phi$ automata, although most cycle-lengths are of the form $2^k(2^j-1)/q$ (see Table~\ref{fig:cycle_table}) for small $q$, cycle-lengths behave very chaotically in general. This has been understood in \cite{wolfram} using polynomial generating  functions, but we would like to repeat the explanation since it will help to understand the proof that one and two-dimensional automata have the same cycle length.  The result is that there are some patterns in the cycle length, but no explicit formula, which makes the existence of a simple equality between cycle-lengths in one and two dimensions even more surprising.}
% \par Theorem \ref{thm:powersof2} and theorem \ref{thm:jb_period_1} imply that the cycle length of $A_n$ for $n=2^ab-1$ is equal to $2^st$ where $s=a+1$. Here $t$ is the least common multiple of the orders of the eigenvalues $\alpha^r+\alpha^{-r}$ where $\alpha$ has order $b$ (as long as $b>1$). We are interested in the value of $t$; however, note that knowing $b$ is not particularly helpful when solving for $t$, suggesting that the cycle lengths will behave randomly.% (derived originally by \cite{wolfram})

% {\color{red}did we say that if b=1 all lights turn off eventually?}
% {\color{blue} No it's commented out. If we are going to say it, I think that right after theorem~\ref{thm:powersof2} would be a good place.}

\begin{thm}
    \label{thm:rdm_sord}
    Let $n+1=2^ab$ where $b$ is odd. Then the cycle length is equal to $2^{a+1}\frac{2^{\mathrm{sord}_2(b)}-1}{q}$. Here $\mathrm{sord}_2(b)$ is defined as the least $j$ such that $2^j = \pm 1 \bmod b$ (as in \cite{wolfram}) and $q$ is a divisor of $2^{\mathrm{sord}_2(b)}-1$.
\end{thm}
\begin{proof}
    \par Let the cycle length be $2^st$ where $t$ is odd. The fact that $s=a+1$ follows from Corollary \ref{cor:CL}.
    The factor $t$ is the least common multiple of the orders of the eigenvalues.  It can be better understood by considering the field used to diagonalize $A_n$. 
    % \sout{In Section~\ref{sec:CL_and_jordan_form}, we mentioned that the working field was initially $GF(2)$; however, for most $n$, $p_n(\lambda)$ factors into several polynomials that are irreducible over $GF(2)$. Thus to accommodate all roots of $p_n(\lambda)$, we extend the field to include the roots of these irreducible factors (that is, to the splitting field of $p_n$), creating our working field ($\mathbb{F}$).}{\color{green}I moved this to an earlier page.} 
    \par The field $\mathbb{F}$ used to diagonalize $A_n$ can be any field containing all its eigenvalues.  This field contains $2^j$ elements (for some integer $j$), and the set of nonzero elements within $\mathbb{F}$ forms a cyclic group $\mathbb{G}$ of order $2^j - 1$. Thus the orders of all eigenvalues divide $2^j-1$ and hence $t | 2^j - 1$. 
    \par When $\mathbb{F}$ is the smallest field that contains all the eigenvalues this reasoning places the greatest limitation on the value of $t$. Given the form of the eigenvalues $(\alpha^r + \alpha^{-r})$, it is clear that any field containing a $b^\mathrm{th}$ root of unity contains all eigenvalues. Since the elements of any finite field form a cyclic group under multiplication,
    there will be a $b^\mathrm{th}$ root of unity if $b|2^j-1$. This is equivalent to $2^j=1\bmod{2}$. So if $\mathrm{ord}_2(b)$ is the least power $j$ such that $2^j=+1\bmod{2}$, then $t|2^{\mathrm{ord}(b)}-1$.
    %The smallest field containing a $b^\mathrm{th}$ root of unity is the one with $2^{\mathrm{ord}_2(b)}$ elements. Here $\mathrm{ord}_2(b)$ is the order of $2$ under multiplication modulo $b$. Since $\mathbb{G}$ is a cyclic group whose order is divisible by $b$, $\mathbb{G}$ must contain an element of order $b$. Thus we see that $t|2^{\mathrm{ord}_2(b)}-1$. 
    
    
    \par  There is often a field with order less than $2^{\mathrm{ord}_2(b)}$ containing all eigenvalues, because the field does not have to contain $\alpha$ itself, just elements of the form $\alpha^i+\alpha^{-i}$. Given any set of nonzero elements $\lambda_i$ in a field, the order of the smallest field containing them is $2^j$ where $j$ is the least integer such that $\lambda_i^{2^j}=\lambda_i$ (see theorem 15.7.3c of \cite{artin}). Applying this to the eigenvalues yields  
    \begin{equation}
        \alpha^{i 2^j}+\alpha^{-i 2^j}=\alpha^i +\alpha^{-i}
    \end{equation}
    The above is equivalent to $\alpha^{i 2^j} = \alpha^{\pm i}$ via $x+x^{-1}=y+y^{-1} \implies x^2-(y+y^{-1})x+1=0 \implies (x-y)(x-y^{-1})=0$. This holds when $2^j = \pm 1 \bmod b$, since $b$ is the order of $\alpha$. Thus, $j=\mathrm{sord}_2(b)$.  So the smallest field containing the eigenvalues has $2^{\mathrm{sord}_2(b)}$ elements and $t|2^{\mathrm{sord}_2(b)}-1$.
\end{proof}



%If the cycle length is equal to $2^s t$, where $t$ is odd, then 
%$s$ is related to the size of the Jordan blocks.  The other factor $t$ is the least common multiple of the orders of the nonzero eigenvalues.

% The order can be understood better 
% As we mentioned back in section \ref{sec:CL_and_jordan_form}, our working field was initially GF(2); however, for most $n$, $p_n(\lambda)$ factors into several polynomials that are irreducible over GF(2). T




%By theorem \ref{thm:eigen_sum}, if the field has a root of unity of order $n+1$, it will be large enough for $p_n$ to be factored. 
% This field has $2^j$ elements for some $j$, and the set of nonzero elements in it forms a cyclic group $\mathbb{G}$.
% It is known that for any finite field $\mathbb{F}_0$, $|\mathbb{F}_0| = p^k$ where $p$ is some prime number and $k$ is a non-negative integer. Furthermore, for all finite fields $\mathbb{F}_0$, there exists a corresponding cyclic group $\mathbb{G}_0$ such that $\forall$ nonzero $x \in \mathbb{F}_0$, $x \in \mathbb{G}_0$ and $\forall y \in \mathbb{G}_0$, $y \in \mathbb{F}_0$. Thus for some arbitrary field $\mathbb{F}_0$ with order $p^k$, if $\mathbb{G}_0$ is the cyclic group generating the field, $|\mathbb{G}_0| = p^k - 1$.
% Thus the group $\mathbb{G}$ has order $2^j - 1$.
% By Fermat's Little Theorem, for all $x \in \mathbb{G}$, $x^{2^j - 1} = 1$. Therefore $t$ divides $2^j-1$. {\color{red}Maybe not clear that this is important because the eigenvalues are elements of the field}


%This may be much larger than $n+1$.  For example, for some prime numbers,
%$2^{p-1}$ is the %first power of 2 that is 1 modulo 2.
%So if $n+1=p$, $j=n-2$, and $2^j-1$ is large compared to $n$.


% $\mathbb{F}$ being the smallest field that contains all the eigenvalues places the greatest limitation on the value of $t$. Given the form of the eigenvalues, it is clear that any field containing a $b^\mathrm{th}$ root of unity contains all the eigenvalues. The smallest field containing a $b^\mathrm{th}$ root of unity is the one with $2^{\mathrm{ord}_2(b)}$ elements (where $\mathrm{ord}_2(b)$ is the order of $2$ under multiplication modulo $b$).{\color{red}Maybe we should explain more. We could also say that we are not proving this  because there is a better result in the next paragraph.} Since $\mathbb{G}$ is a cyclic group whose size is a multiple of $b$, it must have an element of order $b$.
% So $t|2^{\mathrm{ord}_2(b)}-1$.

% There is often an even smaller field containing all the eigenvalues.  Given any set of nonzero elements $\lambda_i$ in a field, the order of the field they generate is $2^j$ where $j$ is the least integer such that $\lambda_i^{2^j}=\lambda_i$ (see theorem 15.7.3c of \cite{artin}).
% Applying this to the eigenvalues gives
% \begin{equation}
% \alpha^{i2^j}+\alpha^{-i2^j}=\alpha^i+\alpha^{-i}
% \end{equation}
% This is equivalent to $\alpha^{i2^j}=\alpha^{\pm i}$ via $x+x^{-1}=y+y^{-1} \implies x^2-(y+y^{-1})x+1=0 \implies (x-y)(x-y^{-1})=0$. This is true when $2^j$ is $\pm 1$ modulo $b$, since $b$ is the order of $\alpha$. Ref. \cite{wolfram} defines $\mathrm{sord}_2(b)$ as the least $j$ such that $2^j$ is $\pm  1$ modulo $b$.
% So $t|2^{\mathrm{sord}_2(b)}-1$.

%If $2^j-1$ is divisible by $n+1$, then there is a primitive $n+1$st root of unity in the field, so it contains all the eigenvalues. The smallest value of $j$ with this property is the order of $2$ modulo $n+1$, $ord_2(n+1)$. 
%Sometimes the field can be smaller. Wolfram and Odlyzko define $sord_2(n+1)$ as the least $j$ such that either $2^j+1$ or $2^j-1$ is divisible by $n+1$. The matrix $A_n$ can be diagonalized over a field of order $2^j$.
%To see this, consider a field that contains the $n+1$st roots of 1.
%Its order is $2^{\mathrm{ord}_2(n+1)}$.
%Then $\alpha^{2^j}=\alpha^{\pm1}$ since $2^j\equiv \pm1\mathrm{\ mod\ }n+1$. So the eigenvalues all satisfy $x^{2^j}=x$. The solutions to this equation form a subfield with $2^j$ elements, so their orders all satisfy $t|2^{j}-1$.
%One can also show that there is no smaller field that contains all the eigenvalues.

%Now we know a better upper bound for $t$.  However, under multiplication, the eigenvalues might  generate only a subgroup of the field $\mathbb{F}_{2^{\mathrm{sord}_2(b)}-1}$, and then the cycle length will be $2^a\frac{2^j-1}{q}$ for some $q$ that cannot be predicted in this way.


%The unpredictable variations of the cycle lengths in Table \ref{fig:cycle_table} is mostly explained by the randomness of the relationship between $b$ and $\mathrm{sord}_2(b)$.
%(If $b$ is a prime for example, $2$'s order can be as large as $b-1$ (which implies $\mathrm{sord}_2(b)=\frac12(b-1)$), or as small as about $\log_2 b$, since if $b$ is a Mersenne prime, $2^k-1$, then $\mathrm{sord}_2(b)=k.$ 
%This ``randomness" applies to both one and two dimensions since we will see that the eigenvalues in both cases
%are contained in $\mathbb{F}_{2^\mathrm{sord}_2(b)}$. However, the cycle length occasionally takes the form $2^k\frac{2^j-1}{q}$ where the eigenvalues might generate only a proper subgroup under multiplication of this field, and there isn't an easy way to predict when this happens.

The randomness of the relationship between $b$ and $\mathrm{sord}_2(b)$ mostly explains why the cycle lengths in Table \ref{fig:cycle_table} vary unpredictably between large and small values. %We see that very often the cycle length is equal to $2^k(2^j-1)$ where $k=a+1$ and $j=\mathrm{sord}_2(b)$.
The same seemingly random behavior occurs both in one and two dimensions because the result of this theorem also applies to two-dimensional lights out. (The eigenvalues for the two-dimensional automaton are contained in the same field, as shown in the next section.)

Besides this, the cycle length sometimes takes the form $2^{a+1}\frac{(2^{\mathrm{sord}_2(b)}-1)}{q}$ where $q$ is a factor of $2^{\mathrm{sord}_2(b)}-1$ other than 1. This apparently ``rare'' form occurs if the lcm of the orders of the eigenvalues is less than the size of $\mathbb{G}$. Since determining the orders of specific elements of a finite field is known to be a difficult problem, $q$ can also behave unpredictably.

% {\color{red}:cut out next sentence?}We note an interesting sub-pattern within the cycle-lengths that follows from Theorem \ref{thm:powersof2}: the factor $(2^j-1)/q$ in the cycle length is the same for all boards of size $2^a m-1$ as $a$ is changed. 

Now that we have understood the unpredictable nature of automata cycle-lengths, we show how to prove that one and two dimensional cycle lengths are the same. We will see that formulas for the cycle lengths of $\Phi$ and $\sigma$ automata are not necessary for this proof.

% of the roots of the Chebyshev polynomial is smaller than the size of $\mathbb{G}$. However, determining the orders of specific elements of a finite field is known to be a difficult problem, so $q$ also behaves randomly. 

% {\color{red}Maybe say something about the randomness, like about powers of 2 exactly reaching 1 after one cycle for Mersenne primes, but otherwise it can cycle a long time}

% Very often the cycle length is equal to $2^k(2^j-1)$ where $k=a+1$ and $j=\mathrm{sord}_2(b)$, but sometimes it has the form $2^{k} *(2^j-1)/q$ where $q$ is a factor of $2^j-1$.
% This occurs if the least common multiple of the roots of the Chebyshev polynomial is smaller than the size of $\mathbb{G}$. However, determining the orders of specific elements of a finite field is known to be a difficult problem, so $q$ also behaves randomly. 

%\begin{thm}
%   The eigenvalues of $A$ for an $n\times 1$ board when $n$ is odd are the same as the eigenvalues for a $k\times 1$ board when $k=\frac{(n+1)}{2^a}-1$ where $2^a$ is the largest power of $2$ that divides $n+1$.
%\end{thm}
%This follows from the proof of Theorem \ref{thm:odd_alg_mult}. 




% \subsection{Cycle-lengths of $\Phi$}
% \par we will be relating the cycle-lengths of the $\Phi$ and $\sigma$ automata, so it will be useful to build some intuition about how to solve for the cycle-length of certain $\Phi$ automata. The method we use to solve for the cycle-lengths of $\Phi$ automata can theoretically be applied to uncover the cycle-length of a $\Phi$ automaton of arbitrary size; however the simplifications we make throughout the algorithm become expensive at certain points, so it is not terribly practical. 

% \begin{thm}
% For a $1 \times 2^k$ $\Phi$ automaton with an asymmetric initial seed, the cycle-length is $2^{k+1} - 2$.
% \end{thm}
% \begin{proof}
% The characteristic polynomial of $A_{2^k}$ is $p_{2^k}(\lambda) = \lambda^{2^k} + \lambda^{2^k - 2} + \lambda^{2^k - 4} + \lambda^{2^k- 8} + \dots + 1$ (see $\cite{barRam}$). We know that $p_{2^k}(\lambda) = 0$ for all eigenvalues, so then we can rewrite the characteristic polynomial as $\lambda^{2^k} = \lambda^{2^k - 2} + \lambda^{2^k - 4} + \lambda^{2^k- 8} + \dots + 1.$ There is a method commonly used when solving for the periods of elements within fields that will prove very useful here. We will multiply both sides of this equality by $\lambda$, then reduce the expression by adding the characteristic polynomial to both sides.

% \par The pattern we noticed is that every time we reduce a power of $\lambda$ using $p_{2^k}$, the exponent of the next largest power of $\lambda$ becomes $2^k - 2^a$ where $a$ is a natural number that is initially equal to $1$ and increases by $1$ with every reduction. The first two reductions are shown below. 
% \begin{align*}
%     \lambda^{2^k + 2} &= \lambda^2*\lambda^{2^k} \\
%     &= \lambda^{2^k} + \lambda^{2^k - 2} + \lambda^{2^k- 6} + \dots + \lambda^2 \\
%     &= \lambda^{2^k - 4} + \lambda^{2^k - 6} + \lambda^{2^k - 8} + \dots + \lambda^2 + 1
% \end{align*}
% \begin{align*}
%     \lambda^{2^k + 6} &= \lambda^4 * \lambda^{2^k + 2} \\
%     &= \lambda^{2^k} + \lambda^{2^k - 2} + \lambda^{2^k - 4} + \lambda^{2^k - 10} + \lambda^{2^k - 12} + \dots + \lambda^6 + \lambda^4 \\
%     &= \lambda^{2^k - 8} + \lambda^{2^k - 10} + \lambda^{2^k - 12} + \lambda^{2^k - 16} + \dots + \lambda^6 + \lambda^4 + 1
% \end{align*}


% Additionally, each time we reduce the power of $\lambda$, we increase the number of shared terms between the polynomial expansion and $p_{2^k}$ until $1$ is the only term the polynomials do not have in common, which occurs after $k$ reductions. We can then iteratively do this until the powers of $\lambda$ repeat, and it can be seen that this will occur after $\lambda ^ {2^k -1}.$ 

% \par By Theorem $2.4$, we know that the lcm of the periods of the Jordan blocks of $A_n$ is $lcm(2^k - 1, 2) = 2^{k+1} - 2$. This is because all Jordan blocks have a size less than or equal to $2$. Since the lcm of the periods of the Jordan blocks of a matrix is equal to the period of the matrix itself, the period of $A_n$ is $2^{k+1} - 2$, and this implies that $CL(\Phi) = 2^{k+1} - 2.$
% \end{proof}
% Using the cycle-length we just discovered and the recursions describing the Chebyshev polynomials of the second kind, we explore another method of uncovering the cycle-lengths of $\Phi$ automata (building off of previous results).
% \begin{thm}
% For a $1 \times 2^k + 1$ $\Phi$ automaton with an asymmetric initial seed, $CL(\Phi) = 2^{k+1} - 4$.
% \end{thm}
% \begin{proof}
% \par The characteristic polynomial of a $n \times 1$ $\Phi$ automaton where $n = 2b + 1$ is $p_{2b+1}(\lambda) = \lambda*{p_b}^2$. This means that $p_{2^k + 1}(\lambda) = \lambda*p_{{2^{k-1}}}^2$, which implies that the spectrum of $p_{2^k + 1}$ is going to be the same as that of $p_{2^{k-1}}$ except $p_{2^k + 1}$ also has $0$ as an eigenvalue (the lcm of the periods of the eigenvalues is still $2^k - 1$). In addition, since $p_{2^k + 1}(\lambda) = \lambda*p_{{2^{k-1}}}^2$, and the size of the largest Jordan block in $A_{2^{k-1}}$ is $2$, the size of the largest Jordan block in $A_{2^k + 1}$ must be $4$. Thus the lcm of the periods of the Jordan blocks will be $lcm(2^{k-1} - 1, 4) = 2^{k+1} - 4.$
% \end{proof}

% \par These examples demonstrate a method by which, given enough time, we could determine the cycle-length of a $\Phi$ automaton of arbitrary size. However, the major constraints on this technique are that it takes quite a bit of time, and the characteristic polynomial for each $\Phi$ automaton is unique, therefore they will all reduce in different ways.

% \subsection{The Existence of Critical Sequences of $\Phi$ Automata}
% \label{sec:crit_seq}
% While observing the cycle-lengths of $\Phi$ automata of even lengths, we noticed an interesting phenomenon: halfway through the cycle, the automaton configuration was simply a reflection of the initial configuration. This implies that for $\Phi$ automata of even length with a symmetric initial seed, the cycle-length is half of what we expected. We define a \textit{critical sequence} of $\Phi$ automata as a sequence of configurations in which the cycle-length of the sequence is half of the cycle-length of the $\Phi$ automaton. 

% This can be shown using the reflection principle. Consider how a pattern of $\Phi_n$ is represented on the infinite line. The pattern is repeated in the intervals
% $[k(n+1)+1,k(n+1)+n]$, with a reflection or not depending on whether $k$ is odd or even.  But if the pattern in $\Phi_n$ has a reflection symmetry (about the center of $[1,n]$)
% then all the copies are the same, so the period is $n+1$ instead of $2(n+1)$ and it also has more reflection symmetries.



% Halfway through the cycle, the configuration is the first configuration of the cycle reflected through the center of the automaton, so if $A^{2k} = I$, then $A^k = I^\tau$ where $I^\tau = 
% \begin{pmatrix}
% 0 & 0 & \dots & 0 & 1 \\
% 0 & 0 & \dots & 1 & 0 \\
% \vdots & \vdots & \iddots & 0 & 0 \\
% 0 & 1 & \dots & 0 & 0 \\
% 1 & 0 & \dots & 0 & 0
% \end{pmatrix}
% $. This is because the matrix $I^\tau$ reverses the order of the state vector of the automaton, or in other words, it reflects the automaton over the center. 

% \begin{thm}
% For a $1 \times 2n$ $\Phi$ automaton such that $A^{2k} = I$, $A^k = I^\tau.$
% \end{thm}
% \begin{proof}
% Let $A^k = {R_1}J_1{R_1}^{-1}$ where $R_1$ is the Jordan basis of $A$. Since $A^{2k} = I$, and the sizes of the Jordan blocks of $A$ are equal to $2$, the lcm of the periods of the eigenvalues of $A$ must equal $k$. This implies that the diagonal entries of ${J_1}$ are all equal to $1$. We can also decompose $I^\tau$ as $R_2J_2{R_2}^{-1}.$ It can be seen that the eigenvalues of $I^\tau$ are all $1$, which implies that the characteristic polynomial of $I^\tau$ is $c(x) = (x + 1)^{2n}$. In addition, $(I^\tau + I)^2 = 0$, which means that the size of the largest Jordan block in $J_2$  corresponding to the eigenvalue $1$ must be $2$. By noting that $I^\tau$ simply reflects the order of the elements of any vector it is applied to, we see that $I^\tau$ must have exactly $n$ linearly independent eigenvectors (the eigenvectors are just vectors symmetric over the center). Thus the number of Jordan blocks in $J_2$ is $n$, so $J_1 = J_2$.

% \par Multiplication between $I^\tau$ and $A$ is commutative, which means that multiplication between $I^\tau$ and powers of $A$ is also commutative. We then have that $A^{k}I^\tau = I^\tau A^{k}$. We know that the minimal polynomial of $A$ is equal to $A$'s characteristic polynomial. By Theorem 2.17 in \cite{elyze}, since $A$ is a non-derogatory matrix, we see that $I^\tau$ is contained in the ring generated by $A$. Thus $I^\tau$ can be written as some polynomial in $A$ (call this polynomial $f(A)$). Since $I^\tau$ has only eigenvalues equal to $1$, we see that $f(\lambda_i) = 1$ for all eigenvalues $\lambda_i$ in the spectrum of $A$. 


% If $I^\tau$ could not be written as a polynomial in $A$, then there would be multiple Jordan bases corresponding to $I^\tau$, and thus there would be no guarantee that it is a power of $A$. However, since this is not the case, $I^\tau$ has the same Jordan basis as $A$, which means that $R_1 = R_2$. Thus ${R_1}J_1{R_1}^{-1} = R_2J_2{R_2}^{-1}$, which implies that $A^k = I^\tau.$
% \end{proof}

\section{The two dimensional automaton $\sigma$ and its relation to the one dimensional $\Phi$ }
\label{sec:2d_1d_rel}
% \par Before analyzing the $\sigma$ automaton, there are several important ideas to bear in mind from previous sections. The cycle length of either the $\Phi$ or $\sigma$ automaton is given by the lcm of the periods of the Jordan blocks.  The period of a Jordan block is the order of its eigenvalue times $2^r$ where $2^r$ is the least power of 2 greater than or equal to the size of the block (see theorem \ref{thm:jb_period_1}). If the eigenvalue is zero, the period is 1.
% The Jordan form of $A_n$ is given by theorems \ref{thm:JordanBlocks} and \ref{thm:powersof2}.
% \begin{comment}We discussed the particular form of the eigenvalues of $A_n$ in
% theorems~\ref{thm:eigen_sum} and~\ref{thm:powersof2}. We found that for even $n$, the eigenvalues are $\{\alpha^j + \alpha^{-j} | j = 1, 2, \dots, \frac{n}{2} \}$ where $\alpha$ is an order $n + 1$ element of the working field $\mathbb{F}$. Then if $n = b 2^a - 1$ for odd $b$, the nonzero eigenvalues of $A_n$ are identical to those of $A_{b-1}$. There is one Jordan block whose size is $2^{a+1}$ for every nonzero eigenvalue and one of size $2^a-1$ for 0. %This gives us expressions for the eigenvalues of $A_n$ for all $n$, and we will show how to relate these eigenvalues of $A_n$ to those of $T_n$ (the adjacency matrix of the $\sigma$ automaton).
% This gives us the Jordan form for $A_n$ for all $n$, and
% \end{comment}
% We can relate these eigenvalues and sizes of blocks for $A_n$ to those of $T_n$ (the adjacency matrix of the $\sigma$ automaton). To fully equate the cycle-lengths of the $\Phi$ and $\sigma$ automata (theorem~\ref{thm:CL_equal}), we both prove equality of eigenvalue periods (theorem~\ref{thm:eig_lcm_equal}) and equality of the sizes of the large Jordan blocks of $A$ and $T$ (theorem~\ref{thm:T_jordan_block}).
% {\color{red}maybe try to make section 5 something you could read on its own?
% --say the result about the eigenvalues for 1d, and also explain how it will go-- at the end of this introduction part say what we have to show about the Jordan block and the eigenvalues}

\par This section extends the ideas of theorem~\ref{thm:powersof2} to two-dimensional automata. We will consider the $\sigma$ automaton, deriving properties of its matrix from those of the one-dimensional automata $\Phi$, and showing that $CL(\sigma)=CL(\Phi)$.  %As we have already discussed, the $\sigma$ automaton is the $2$-dimensional cellular automaton whose rule of evolution can be described by a matrix $T$. 
To represent $\sigma$ by a matrix, we will write the state of an $n \times n$ $\sigma$ automaton as an $n^2 \times 1$ vector where the $1^\mathrm{st}$ $n$ entries of the vector are the states of the bottom-most row of the automaton, then the next $n$ entries are the states of the $2^{\mathrm{nd}}$ row from the bottom, and so on.


%\par To find the matrix of $\sigma$ consider the Lights Out board and what happens when it is played by the procedure described before.
%Let $\textbf{g_0}$ be the initial configuration of the board. Then the subsequent configuration of the automaton can be described as the state generated by pressing all of the buttons that are on in $\textbf{g_0}$. Similar to our process of generating the transition matrix $A$, we can create $T$ by encoding the horizontal and vertical dependencies of each cell into a matrix. Here are a few of the rows:
%\setcounter{MaxMatrixCols}{15}
%$$\begin{pmatrix}
%0 & 1 & 0 & 0 & \dots & 1 & 0 & 0 & 0 & \dots & 0 & 0 & 0 & 0 & \dots \\
%1 & 0 & 1 & 0 & \dots & 0 & 1 & 0 & 0 & \dots & 0& 0 &0 & 0 & \dots \\
%0 & 1 & 0 & 1 & \dots & 0 & 0 & 1 & 0 & \dots & 0 & 0 & 0 & 0 & \dots \\
%&&&&&\dots&&&&\dots &&&&&\\
%1 & 0 & 0 & 0 & \dots & 0 & 1 & 0 & 0 & \dots & 1 & 0 & 0 &0 & \dots\\
%&&&&&\dots &&&&\dots &&&&&
%\end{pmatrix}$$

%\par This sparse matrix representation of $T$ is somewhat cumbersome and difficult to work with (since the shape of and patterns within $T$ vary with the size of the automaton), so we will avoid using it as much as possible. 

% \par {\color{blue}Here are some ideas about different ways to explain the formula with the Kronecker product.  Do you think either of the new versions is better than the original one? Or you could write a new one too!}

% {\color{green}The rule of evolution of a $\sigma$ automaton can be related to the $\Phi$ rule: if the outcome of applying the $\Phi$ rule to the rows is added to the result of applying the $\Phi$ rule to the columns, we recover the rule of $\sigma$.

% This can be represented by (see \cite{sarkBar})
% \begin{equation}
% \label{eq:TA_relk}
%     T_{n} = A_n \otimes I_n + I_n \otimes A_n
% \end{equation}
% where $I_n$ denotes the $n \times n$ identity matrix and $\otimes$ is the Kronecker product.}

% {\color{red}If the rows of an $n\times n$ automaton change by the one dimensional rule, this would be described by $I_n\otimes A_n$.  If the columns each change by the one dimensional rule, it would be described by $A_n\otimes I_n$, and the sum of them is the matrix that describes one step for the $\sigma$ automaton (see \cite{sarkBar}), so 
% \begin{equation}
% \label{eq:TA_relk}
%     T_{n} = A_n \otimes I_n + I_n \otimes A_n
% \end{equation}
% where $I_n$ denotes the $n \times n$ identity matrix and $\otimes$ is the Kronecker product.}


% {\color{blue}The matrix for the $\sigma$ automaton can be represented by(see \cite{sarkBar})
% \begin{equation}
% \label{eq:TA_relk}
%     T_{n} = A_n \otimes I_n + I_n \otimes A_n
% \end{equation}
% where $I_n$ denotes the $n \times n$ identity matrix and $\otimes$ is the Kronecker product.
% This shows that the $\sigma$ automaton can actually be written in terms of the $\Phi$ automata's matrix: each site is the sum of the sites next to it in the column, like the $\Phi$ rule for the column, so this is represented by $A_n\otimes I_n$; and the sites next to it in the row, which is represented by $I_n\otimes A_n$.}

Recall that the rule for evolution of an $n \times n$ $\sigma$ automaton is that at each step, the state of one of the variables changes to the sum modulo 2 of the states of the horizontal and vertical nearest-neighbor variables. Suppose $I_n$ denotes the $n \times n$ identity matrix and $\otimes$ is the Kronecker product. The matrix $I_n\otimes A_n$ evolves the rows of a $\sigma$ automaton according to the $\Phi$ rule, and the matrix $A_n\otimes I_n$ evolves the columns of a $\sigma$ automaton according to the $\Phi$ rule. Hence the sum of these two matrices describes one step of evolution for the $\sigma$ automaton (see \cite{sarkBar}). Thus the transition matrix of the $\sigma$ automaton is given by 
\begin{equation}
\label{eq:TA_relk}
    T_{n} = A_n \otimes I_n + I_n \otimes A_n
\end{equation}

\par This operation is also called the \textit{Kronecker sum}:  $T_n = A_n \oplus A_n$ (see \cite{schacke}). In the next section, \ref{sec:T_jordan} it will be useful to use the Kronecker sum of two matrices $M$ and $N$ of different dimensions.  This is defined because the identity matrices in the sum can be adjusted to accommodate the dimensions of $M$ and $N$.

\par An alternative form of $T$ (which we also will use) is given by
$$T =
\begin{pmatrix}
A & I & 0 & \dots & 0 \\
I & A & I & \dots & 0 \\
0 & I & A & \ddots & 0 \\
\vdots & \vdots & \ddots & \ddots & I \\
0 & 0 & 0 & \dots & A
\end{pmatrix}
$$
This tridiagonal form is much more tractable than writing out the full matrices, and it is interesting to work with matrices of matrices. However, the Jordan form of $T$ is most easily determined using the Kronecker sum expression for $T$.

% \sout{As we mentioned in the introduction, Sarkar and Barua (see \cite{sarkBar}) also discovered this result, and we will build on their work to strengthen the relationship between $A$ and $T$.} 
% {\color{red}I changed this paragraph because it sounded like we were going to use it right away, but the next part is about something different.  So I wanted to say that it is just an interesting result that we will use later.  But I don't think I changed it in such a good way.}

The Kronecker sum formula helps to find the Jordan form of $T_n$. One can first transform the two $A_n$'s in the Kronecker sum into their Jordan form, and sum these. The Kronecker sum of two matrices in a block diagonal form, with $n$ and $m$ blocks respectively can be changed (by rearranging the rows and columns) into a matrix of block diagonal form with $nm$ blocks, the Kronecker sums of all pairs of one block from each matrix.
Thus, if $A$'s Jordan form has $n$ blocks, $T$ will have $n^2$ blocks.
These blocks are not in Jordan form, though.

To find the cycle length of $T$ we now need to decompose each of these blocks into Jordan form, or at least find the eigenvalues and the size of the largest block of each, according to Theorem \ref{thm:PeriodsFromJN}. The Kronecker sum of two Jordan blocks with eigenvalues $\mu$ and $\theta$ has just one eigenvalue, $\mu+\theta$, because of the fact that the eigenvalues of $L\oplus B$ are the sums of all combinations of eigenvalues of $L$ and $B$ (see \cite{schacke}), where $L$ and $B$ are matrices.
This result does not determine the cycle length; although there is only one eigenvalue, there can be more than one Jordan block. The sizes of the Jordan blocks follow very interesting rules when the matrices are defined over fields of finite characteristic.  We will discuss the size of the largest block using a simple method, first for the cases that arise in the problem of the $\Phi$ and $\sigma$n automata and then in more generality to put the result in context.  The full Jordan decomposition has been found previously \cite{norman,barry} but we give a simple geometrical argument for the case of finding just the sizes of the largest Jordan blocks.





\begin{comment}The eigenvalues can be found using
\begin{thm}
$\lambda$ is an eigenvalue of $L \oplus B$ $\iff$ $\lambda = \mu + \theta$ where $\mu$ is an eigenvalue of the matrix $L$ and $\theta$ is an eigenvalue of the matrix $B$.
\label{thm:kronecker_eigen_sum}
\end{thm}
This theorem can be seen in \cite{schacke}, and it follows from the fact that the Kronecker sum of two Jordan blocks with eigenvalues $\mu,\theta$ has only one eigenvalue $\mu+\theta$. Although the Kronecker sum of two Jordan blocks has just one eigenvalue, it is usually not made of one Jordan block. There is still an additional step of breaking the Kronecker sum into separate blocks. Determining Jordan blocks of a Kronecker sum of two Jordan blocks without a modulus can be done via an algorithm described by Mastronardi and Van Dooren in \cite{mastronardi}. When working modulo a prime, one can determine the size of Jordan blocks of the Kronecker sum of matrices using a method described in \cite{norman}. The sizes follow much more complicated patterns. 
We show how to find just the size of the largest Jordan block by a simpler method, since this is sufficient for determining the automaton cycle length.  

To find the cycle length of $T$ we now just need to decompose each of these blocks into Jordan form, which requires us to find the eigenvalues and sizes of its Jordan blocks. 
The eigenvalues can be found using
\begin{thm}
$\lambda$ is an eigenvalue of $L \oplus B$ $\iff$ $\lambda = \mu + \theta$ where $\mu$ is an eigenvalue of the matrix $L$ and $\theta$ is an eigenvalue of the matrix $B$.
\label{thm:kronecker_eigen_sum}
\end{thm}
This theorem can be seen in \cite{schacke}, and it follows from the fact that the Kronecker sum of two Jordan blocks with eigenvalues $\mu,\theta$ has only one eigenvalue $\mu+\theta$. Although the Kronecker sum of two Jordan blocks has just one eigenvalue, it is usually not made of one Jordan block. There is still an additional step of breaking the Kronecker sum into separate blocks. Determining Jordan blocks of a Kronecker sum of two Jordan blocks without a modulus can be done via an algorithm described by Mastronardi and Van Dooren in \cite{mastronardi}. When working modulo a prime, one can determine the size of Jordan blocks of the Kronecker sum of matrices using a method described in \cite{norman}. The sizes follow much more complicated patterns. 
We show how to find just the size of the largest Jordan block by a simpler method, since this is sufficient for determining the automaton cycle length.  
\end{comment}



%, and it is incredibly useful because it allows us to relate the eigenvalues of $T$ to the eigenvalues of $A$. Thus rather than explicitly solving for the characteristic polynomials of different $T$'s, we can simply manipulate the solutions to the characteristic polynomials of various $A$'s.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Finding The Sizes of Jordan Blocks of $T$}
\label{sec:T_jordan}
\par %Decomposing a matrix into its Jordan normal form allows us to separate the cycle-length of the matrix into the Jordan component and the eigenvalue component, the former of which we will now explore.

\par %We will first consider the Jordan blocks of $T$ and how they relate to the Kronecker sum.   In the next section, we will  explore more generally the problem of finding the Jordan blocks of the Kronecker sum of two matrices. 

%Instead of considering the Kronecker sum of the entire matrix $A$ with itself, we can decompose the sum into the composition of the individual Kronecker sums of the Jordan blocks of $A$. 

Consider a part of $T$ which is a sum of a pair of Jordan blocks of $A_n$, say $J_\lambda,J_\mu$. We need to find the largest Jordan block in it. There are three cases depending on whether the eigenvalues are zero or nonzero.

\begin{thm}
Suppose $\lambda$ and $\mu$ are two eigenvalues of $A$. If $\lambda \neq 0$ or $\mu \neq 0$ the size of the largest Jordan block in $J_\lambda\oplus J_\mu$ is $2^{a+1}$ (where $2^{a+1}$ is the multiplicity of the nonzero eigenvalues as in \ref{thm:powersof2}). If $\lambda = \mu = 0$, then the size of the largest Jordan block in $J_\lambda\oplus J_\mu$ is $2^{a}$.
\label{thm:jordan_eigen_sum}
\end{thm}
\begin{proof}
\par We prove this in detail only for the case where both $\lambda \neq 0$ and $\mu \neq 0$, as the proofs for the other cases follow the same ideas.
\par Let $J_{\lambda}$ and $J_{\mu}$ be the Jordan blocks in $A_n$ corresponding to the eigenvalues $\lambda$ and $\mu$ respectively. Working out the form of $J_\lambda\otimes I$ and $I\otimes J_\mu$ and adding them, we find that the Kronecker sum is \begin{equation} J_{\mathrm{sum}}=\begin{pmatrix}
P & I & 0 & 0 & \dots & 0 \\
0 & P & I & 0 & \dots & 0\\
0 & 0 & P & I & \dots & 0\\
\vdots & \vdots & \vdots & \ddots & \vdots & \vdots \\
0 & 0 & \dots & 0 & P & I \\
0 & 0 & \dots & 0 & 0 & P
\end{pmatrix}\label{eq:matrixeigenvalue}
\end{equation}where $I$ is an $m \times m$ identity matrix and $P$ is an $m \times m$ Jordan block with eigenvalue $\lambda + \mu$ (where $m=2^{a+1}$). Since this is an upper triangular matrix with the same entry $\lambda+\mu$ in all the diagonal positions, the only eigenvalue is $\lambda + \mu$.  Therefore the characteristic polynomial of $J_{\mathrm{sum}}$ is $c(x) = (x -( \lambda + \mu))^{m^2}$.  Thus the minimal polynomial will be of the form $q(x) = (x + \lambda + \mu)^h$ since $q(x)$ must divide $c(x)$, and the degree of this polynomial is the size of the largest Jordan block.
\par To determine $h$ we just need to find the smallest power of $J_{\mathrm{sum}}+(\lambda+\mu)I$ that is equal to zero. %Applying $x+\lambda+\mu$ to $J_f$ simply transforms $P$ into an $m \times m$ Jordan block with eigenvalue $0$ (and period $0$). $J_f$ has $I$'s on the super-diagonal, $P$'s on the main diagonal, and $0$'s everywhere else. 
 We can calculate the powers of $J_\mathrm{sum}+(\lambda+\mu)I$ by thinking of $J_f$ as having the form of a Jordan block, but with each entry replaced by a matrix. The ones above the diagonal are replaced by the identity and the eigenvalue is replaced by the matrix $P$. Just as in our discussion of entries of powers of Jordan blocks in Section \ref{sec:CL_and_jordan_form}, a block $i$ diagonals above the main diagonal of $(J_\mathrm{sum}+(\lambda+\mu)I)^h$ will be of the form $\binom{h}{i}(P + \lambda I + \mu I)^{h-i}$ where $0 \leq i \leq 2^{a+1}-1$ ($i=0$ represents the main diagonal). For this to be zero, the main diagonal entry, $(P+(\lambda+\mu)I)^h$ must equal zero.  Since this is a $2^{a+1}\times 2^{a+1}$ Jordan block with zero as an eigenvalue, $h$ must be at least $2^{a+1}$. For $h=2^{a+1}$ the other diagonals also become zero because the binomial coefficient $\binom{2^{a+1}}{i} \bmod 2 = 0$ for $1\leq i\leq 2^{a+1}-1$.

For the other cases the argument is very similar.  First let one eigenvalue be zero and the other be nonzero.  For the way we have written the matrix above, it is easiest to let $\lambda$ be zero. Then $J_\lambda$ is a $(2^a-1)\times (2^a-1)$ matrix, so the matrix is an array of blocks with $2^{a-1}$ blocks in each row and column, and the sizes of the blocks are $2^{a+1}\times 2^{a+1}$.  Since $P$ remains the same, while there are fewer blocks, $h$ is still $2^{a+1}$. If $\mu$ and $\lambda$ are both zero, then the powers of the block on the diagonal reach zero when $h=2^a-1$, but the other blocks are not zero until $h=2^a$.
\end{proof}

% When one or two of the eigenvalues is equal to zero, the argument is slightly different because the blocks with eigenvalue $\lambda=0$ have a different size, $2^{a-1}-1$. If one of the eigenvalues is nonzero, we can assume it is the second matrix in the Kronecker sum because any two sums $L\oplus B$ and $B\oplus L$ are conjugate matrices.
% Then $P$ is still a $2^a\times 2^a$ matrix, so the same argument shows that the largest Jordan block is $2^a \times 2^a$.

% If both eigenvalues are equal to zero, then the blocks are $(2^{a-1}-1)\times (2^{a-1}-1)$.  For the matrix to be annihilated, $h$ must be at least $2^{a-1}-1$.  However, this is not large enough since the binomial coefficients will be non-zero. Increasing the power by one makes $h$ into a power of 2, so the matrix will then be annihilated. 

% \begin{lma}
% For any two Jordan blocks $J_\lambda, J_\mu$ of $A_n$ with $\lambda=\mu=0$, the largest Jordan block in $J_\lambda \oplus J_\mu$ is $2^{a-1}$ where $2^{a-1}-1$ is the multiplicity of 0 in $A_n$. If $\lambda=0$ and $\mu\neq 0$, the multiplicity is $2^a$.
% \label{lma:A_jordan_sum}
% \end{lma}

This implies 
\begin{thm}
For each nonzero eigenvalue of $T_n$, the largest Jordan block
is $2^{a+1}\times 2^{a+1}$ where $2^{a+1}$ is the largest power of 2 that divides $n+1$, if there are any non-zero eigenvalues.
\label{thm:T_jordan_block}
\end{thm}
This determines the largest power of 2 in the cycle length. Additionally, the size of the largest block with $0$ as an eigenvalue, $2^a-1$, determines the longest number of steps before a configuration starts cycling (as the block must fully annihilate before the cycle begins).

\subsection{Sums of Jordan Blocks with Other Sizes}
\label{sec:Pascal}
\par We will now explore an interesting  general problem of finding the largest Jordan block that the Kronecker sum of two blocks with sizes $a$ and $b$ respectively splits into. This is not necessary for finding the cycle length of $\sigma$, but it is an interesting aside due to its seeming simplicity and fascinating patterns. Understanding this block-splitting is useful for a variety of reasons; among them is the analysis of other two-dimensional cellular automata that are made up of two one-dimensional automata as $\sigma$ is made up of two $\Phi$'s. 


For characteristic zero, the Jordan decomposition of the Kronecker sum of two Jordan blocks has been found by Trampus in \cite{Trampus}. For this case, there is a regular pattern in the sizes of the blocks. More interesting patterns arise when working modulo a prime, and the full Jordan forms can be derived using an algorithm of Norman \cite{norman}. We will focus on the size of the largest Jordan block and describe it in terms of the binary digits of $a$ and $b$.  Barry in~\cite{barry} has expressed the full Jordan decomposition in terms of binary digits in this way\footnote{Ref.~\cite{barry} actually studies the Kronecker product instead of the Kronecker sum of two Jordan blocks, but these two problems are equivalent\cite{norman}.}, but we feel it is worthwhile to present the simplest case of finding the size of the largest Jordan block by itself, to avoid some of the complications of the more general problem.

%Analysis of block-splitting of Kronecker products of matrices over finite fields using binary sequences has been carefully performed by Barry in~\cite{barry}; however, binary expansions have yet to employed in the determination of the splitting of Kronecker sums of Jordan blocks. 

Consider the sizes of the largest Jordan blocks in the Kronecker sum of a block of size $a$ and a block of size $b$.  The size does not appear to follow a simple pattern, as shown in table~\ref{fig:jordan_table}. Two rules about the size of the block can be found using the logic in our proof of theorem \ref{thm:jordan_eigen_sum}, that the size of the largest block is bounded below by $max(a, b)$ and above by $a + b - 1$. 

\begin{table}[ht]
\begin{center}
    \begin{tabular}{ |c || c|c|c|c|c|} 
    \hline
    \multicolumn{1}{| c ||}{Size of $J_\mu$} & \multicolumn{5}{| c |}{Size of $J_\lambda$} \\
    \hline
    \hline
    & \textbf{1} & \textbf{2} & \textbf{3} & \textbf{4} & \textbf{5} \\
    \hhline{|= =|=|=|=|=|}
    \textbf{1} & 1 & 2 & 3 & 4 & 5 \\ 
    \hline
    \textbf{2} & 2 & 2 & 4 & 4 & 6\\ 
    \hline
    \textbf{3} & 3 & 4 & 4 & 4 & 7 \\ 
    \hline
    \textbf{4} & 4 & 4 & 4 & 4 & 8\\ 
    \hline
    \textbf{5} & 5 & 6 & 7 & 8 & 8\\ 
    \hline
    \end{tabular}
    \caption{Size of the largest Jordan block of $J_\mu \oplus J_\lambda$ for $25$ possible size combinations.}
    \label{fig:jordan_table}
\end{center}
\end{table}


\par As in the proof of theorem~\ref{thm:jordan_eigen_sum}, $J_{\lambda}\oplus J_{\mu}$ is given by a matrix (see Eq. \ref{eq:matrixeigenvalue}) that is like a Jordan normal form, but with  matrices as entries. $P$ is a $b\times b$ Jordan block with eigenvalue $\lambda+\mu$, and the array is an $a\times a$ array of blocks.
To find the size $h$ of the largest Jordan block that $J_\mathrm{sum}=J_\lambda \oplus J_\mu$ splits into, consider powers of $J_\mathrm{sum}+(\lambda+\mu)I$:  $h$ is the smallest power $(J_\mathrm{sum}+(\lambda+\mu)I)^h$ which is zero. 

Since the blocks of $J_\mathrm{sum}+(\lambda+\mu)I$ on the $i^\mathrm{th}$  diagonal (where $0\leq i\leq a-1$) are equal to $\binom{h}{i}(P+(\lambda+\mu)I)^{h-i}$, 
%\par In our proof of Theorem \ref{thm:jordan_eigen_sum}, we showed that if $J_\lambda$ and $J_\mu$ are Jordan blocks of size $a$ and $b$ corresponding to eigenvalues $\lambda$ and $\mu$ respectively, then $(J_\lambda \oplus J_\mu)^h$ would have the form of a Jordan block with corresponding ``eigenvalue" $P$. Here $P$ is a Jordan block corresponding to $\lambda + \mu$. If we let $J_f = J_\lambda \oplus J_\mu$, then the minimal polynomial of $J_f$ is $q(x) = (x + \lambda + \mu)^h$. We want to determine the least $h$ such that $q(J_f) = 0$, as this $h$ will be the size of the largest Jordan block that $J_\lambda \oplus J_\mu$ splits into.
there are two possibilities for how  $[J_\mathrm{sum}+(\lambda+\mu)I]^h = 0$ can be true. One is that all the powers in the matrix $(P + \lambda I + \mu I)^{h-i} $ are 0. The $b^\mathrm{th}$ power is the first power of $P+(\lambda+\mu)I$ that is zero, so this means $h-(a-1)\geq b$. The second possibility, if not all powers of $P$ are zero, is that
 $\binom{h}{i}$ is zero when the powers of $P+(\lambda+\mu)I$  are not zero. That is, $\binom{h}{i}= 0$ for $h-b+1\leq i\leq a-1$. 
 
 Thus, if $h=a+b-1$, $(J_\mathrm{sum}+(\lambda+\mu)I)^h$ is zero, but smaller powers can also be zero if some of the binomial coefficients are even. We now employ an analysis of Pascal's triangle modulo 2 to find the minimum $h$.

 
 
%There are several scenarios in which $[J_2+(\lambda+\mu)I]^h = 0$: $(P + \lambda I + \mu I)^{h-i} = 0$ for all $1 \leq i \leq max(a, b) - 1$, $\binom{h}{i} = 0$ for all $1 \leq i \leq max(a, b) - 1$, or $(P + \lambda I + \mu I)^{h-i} = 0$ for all $1 \leq i \leq c$ and $\binom{h}{i} = 0$ for all $c + 1 \leq i \leq max(a, b) - 1$ where $c$ is some integer. To minimize $h$, $c$ must be minimized.{\color{red}I didn't understand this} We employ an analysis of Pascal's Triangle modulo $2$ to minimize $c$.
\par If we take Pascal's Triangle modulo $2$, it is known that the Triangle becomes the self-similar Sierpinski Triangle shown in Fig. \ref{fig:pascal_mod_2} (adapted from \cite{pascal}). 

\begin{figure}
    \centering
    $\includegraphics[scale = 0.3]{pascal_clean.png}$
    \caption{First $32$ rows of Pascal's Triangle modulo $2$.}
    \label{fig:pascal_mod_2}
\end{figure}

To solve the problem of the largest Jordan blocks, we will have to be concerned with the triangles formed by sets of even (beige) entries of Pascal's Triangle. Within Pascal's Triangle, we define a ``triangle" as a contiguous set of only even entries  bounded on all sides by only odd entries.  Such regions are always triangles because the entries that are the highest in it cause there to be even entries in between them in the next row (because of the rule for forming Pascal's Triangle), and this keeps repeating to give a sequence of shorter and shorter rows. The number of the row of Pascal's Triangle where a triangle begins will be called its ``base."  Additionally, the ``size" of a triangle is the number of even entries within the base row of the triangle. For instance, if we allow $T$ to be the first triangle of size $7$ within Pascal's Triangle, we would be looking at a triangle whose base is row $8$ and is comprised of the set $\{\binom{8}{1}, \binom{8}{2}, \dots , \binom{8}{7}\}$. Triangles of size $1$ are allowed within this paradigm, and we will be making use of them. A triangle is said to  ``exist within a given row" if any of its entries are in that row. 

\par In terms of these triangles, the property that defines $h$ is equivalent to this question: Consider the entry $\binom{a+b-2}{a-1}$ of Pascal's Triangle. Determine whether it belongs to a triangle (i.e., is even) or not, and if it does, what is the base of the triangle? The base will become $h$ if it is in a triangle and if not $h=a+b-1$.
%Another way of looking at this problem is to consider it in terms of self-similar triangles within Pascal's Triangle: what row is the base of the triangle containing $\binom{a + b - 2}{b - 1}$ in? If $\binom{a+b-2}{b-1}$ is not in a triangle (i.e., it is odd) then $h=a+b-1$, as the only possibility in this case as that all the powers of $(P+\lambda I+\mu I)$ have to be zero.
%The row that this base is contained within will become $h$, as it is the smallest integer such that $(P + \lambda I + \mu I)^{h-i} = 0$ for all $1 \leq i \leq c$ and $\binom{h}{i} = 0$ for all $c + 1 \leq i \leq max(a, b) - 1$ where $c + 1$ is the left edge of the triangle within row $h$. Note that if $\binom{a + b - 2}{max(a, b) - 1} = 1$, then $h = a + b - 1$, as the size of the largest Jordan block must then take on the maximum possible value.
This is equivalent to the rule above for determining $h$:  This rule is about finding rows in which a sequence of entries are all even. $J_\mathrm{sum}^h$ is zero if $\binom{h}{i}=0\bmod{2}$ when
 $h-b+1\leq i\leq a-1$. The value of $h$ is the smallest with this property, or else it is $a+b-1$ if no row has this property.  It can be tested for each $h$, starting from $a+b-2$ and decreasing by 1 at a time.  The sequences of entries that are tested for different $h$'s form a V shaped region that ends at $\binom{a+b-2}{a-1}$ (see Fig.~\ref{fig:pascal_v}). If $\binom{a+b-2}{a-1}$ is even, the other rows of this V will be even up to the top row of the triangle that $\binom{a+b-2}{a-1}$ is in, so $h$ is this row. At any row before this row, there will always be some odd binomial coefficients in the $V$. (This follows from the fact that every odd number in Pascal's triangle has an odd number in the row above it, to its left or right.) If $\binom{a+b-2}{a-1}$ is odd 
the condition will not be satisfied for any $h$, so $h=a+b-1$.
\begin{figure}
    \centering
    $\includegraphics[scale = 0.3]{pascal_v_shape.png}$
    \caption{The ``V-shaped'' region comprised of the sequences of even entries for different potential values of $h$. Here $\binom{a + b - 2}{a - 1} = \binom{20}{13}$ (the entry circled in a red box).}
    \label{fig:pascal_v}
\end{figure}


Interestingly, we find that all that is required to determine $h$ is the binary representation of $a + b - 2$ and $b - 1$ (see theorem \ref{thm:tri_base}).  
%
%
%
% \begin{thm}
% \label{thm:tri_base}
%
% Given $\binom{n}{k} = 0$ exists within a triangle $T$ of size $|T|$, assume that $T$ is the first triangle of size $|T|$ in row $n$ of Pascal's Triangle.  Let $B(n, k)$ denote the base of the triangle that $\binom{n}{k}$ exists within. $$B(n, k) = \sum_{i= \lfloor log_2 k \rfloor + 1} ^ {\lfloor log_2 n \rfloor} (\left \lfloor \frac{n}{2^i} \right \rfloor - 2 \left \lfloor \frac{n}{2^{i+1}} \right \rfloor)2^i$$
% \end{thm}
% \begin{proof}
% \par Let $T_0$ denote the first triangle with size $|T|$. Allow $b(T)$ to denote the row containing the base of some triangle $T$ within Pascal's Triangle. In \cite{kubelka}, Kubelka discusses the self-similarity of Pascal's Triangle modulo $2$, showing that $b(T_0) = 2^i$ for some integer $i$. Hence we must reduce $T$ to $T_0$ to determine $B(n, k)$. From \cite{kart}, we have that for $0 \leq p \leq 2^g$ and $0 \leq m \leq 2^g - 1$, $\binom{2^{g+1} - p}{m} = \binom{2^g - p}{m}$. Likewise, for $0 \leq p \leq 2^g$ and $2^g \leq m \leq 2^{g+1} - p$, $\binom{2^{g+1} - p}{m} = \binom{2^g - p}{m - 2^g}$. From these reductions, it is clear that by repeatedly subtracting powers of $2$ from $n$, the condition $n - 2^w < k < 2^w$ will eventually be satisfied. The question becomes how to determine once $n$ has been sufficiently reduced.
%
% \par There exists $w$ such that $2^w \leq n \leq 2^{w+1}$, and if $n - 2^w < k < 2^w$, then $b(T) = 2^w$. Our goal is to determine $b(T)$, so we aim to reduce the initial $\binom{n}{k}$ to some $\binom{n^\prime}{k^\prime}$ that satisfies the previous condition.
%
% \par Let the sequence $(a_j)^c_0$ be the binary representation of $n$ where $a_0$ is the least-significant bit and $a_c$ is the most-significant bit. Allow $I(a^v_z)$ where $v \leq c$ and $z \geq 0$ denote the integer value of the binary sequence $(a_j)^v_z$. Let $m_0 = \lfloor log_2 k \rfloor$ and $m_1 = j$ such that $j$ is the least integer $\geq m_0$ with $a_j = 1$. $I(a^{m_0}_0)$ must be $\leq k$, otherwise $T$ would be the only instance of a triangle with size $|T|$, since a further reduction of $n$ would not be possible. We can ignore the case in which $I(a^{m_0}_0) = k$. If this equality holds, then $2^{m_0} = k$. This implies that $I(a^{m_0 - 1}_0) = 0$ and $I(a^{m_0}_0) = 2^{m_0}$. However, by Lucas' Theorem~\cite{fine}, since $I(a^{m_0}_0) = 2^{m_0} = k$, we have that $\binom{n}{k} = 1$, which is a contradiction. So we now proceed with the knowledge that $k > I(a^{m_0}_0)$.
%
% \par we have that $k > I(a^{m_1}_0) - 2^{m_1} = I(a^{m_0}_0)$. Additionally, since $m_1 > m_0$, $k < 2^{m_1}$. Thus by the earlier condition, if $n = I(a^{m_1}_0)$, then $n - 2^{m_1} < k < 2^{m_1}$. It's now clear that $2^{m_1}$ must be the base of $T_0$, and since $|T| = | T_0|$, $\binom{n}{k} = \binom{n^\prime}{k^\prime}$ in $T_0$. Since $n = I(a^{m_1}_0)$ satisfies the above condition, we arrive at $n ^ \prime = I(a^{m_1}_0)$. By the initial restriction that $T$ is the first triangle of size $|T|$ in row $n$, $k ^ \prime = k$. This is clear from the self-similarity of Pascal's Triangle. 
%
% \par Now to get the height of $T_0$, we take $I(a^{m_1}_0) - 2^{m_1} = I(a^{m_1 - 1}_0) = I(a^{m_0}_0)$. Finally to compute $B(n, k)$, we subtract the height of $T$ ($I(a^{m_0}_0)$) from $n$, which gives us the following expression: $$B(n, k) = I(a^{c}_0) - I(a^{m_0}_0) = I(a^{\lfloor log_2 n \rfloor}_0) - I(a^{\lfloor log_2 k \rfloor}_0) = I(a^{\lfloor log_2 n \rfloor}_{\lfloor log_2 k \rfloor + 1})$$
% \par Another way to write this binary expression is
% $$B(n, k) = \sum_{i= \lfloor log_2 k \rfloor + 1} ^ {\lfloor log_2 n \rfloor} (\left \lfloor \frac{n}{2^i} \right \rfloor - 2 \left \lfloor \frac{n}{2^{i+1}} \right \rfloor)2^i$$
% \end{proof}

\par Determining the base of the triangle ($T$) containing $\binom{n}{k}$ is a difficult problem for general $\binom{n}{k}$, as we are unaware of the size of the triangle or how far $\binom{n}{k}$ is from the edge of it. To remedy this, we introduce an algorithm that reduces $T \rightarrow T_0$, where $T_0$ is the first instance of a triangle of the size $|T|$ in Pascal's Triangle. 
%\par Suppose we have some $\binom{n}{k}$ in a triangle $T$. Recall that by the self-similarity of Pascal's triangle, successive rows are generated by copying and sliding down previous rows. This means that unless $T$ is the first triangle of size $|T|$, then $\binom{n}{k}$ was copied from some earlier entry in Pascal's triangle: The rule is that if $2^g\leq n\leq 2^{g+1}-1$, and also $k<2^g$, then $\binom{n}{k}$ is the same modulo 2 as the entry in an earlier row: %\binom{n-2^g}{k}\mathrm{mod\ 2}$.
%If $k>n-2^g$, this relationship is still correct, if the binomial coefficient is interpreted as 0.  The other possibility is that $2^g\leq k\leq n$.
%Then the entry $\binom{n}{k}$ can be reduced to is $\binom{n-2^g}{k-2^g}$.
%To find the original entry $\binom{n}{k}$ was copied from, we simply must subtract powers of $2$ from $n$ and $k$ until $k > n$. At this point, we know that $\binom{n}{k}$ has been reduced too far, as we will have obtained an entry that is not in Pascal's triangle.
 Suppose we have some $\binom{n}{k}$ in a triangle $T$. Recall that by the self-similarity of Pascal's triangle, successive rows are generated by copying and sliding down previous rows. This means that unless $T$ is the first triangle of size $|T|$, then $\binom{n}{k}$ was copied from some earlier entry in Pascal's triangle. %To find the original entry $\binom{n}{k}$ was copied from, we simply must subtract powers of $2$ from $n$ and $k$ until $k > n$. At this point, we know that $\binom{n}{k}$ has been reduced too far, as we will have obtained an entry that is not in Pascal's triangle.

The self-similarity property of Pascal's triangle states that the first $2^{g+1}$ rows of Pascal's triangle mod. 2 are made of 3 copies of the first $2^g$ rows together with a triangle of zeros.  So the rows from $2^g+1$ through $2^{g+1}$ can be constructed by taking the upper triangle of the three triangles, i.e., the first $2^g$ rows of Pascal's triangle, and translating them either to the left-hand lower triangle $(n,k)\rightarrow (n+2^g,k)$ or to the right-hand lower triangle, $(n,k)\rightarrow (n+2^g,k+2^g)$, and filling in the middle upside-down triangle with zeros. The middle triangle is the first zero-triangle of size $2^g-1$. Any entry in one of the other three triangles that is even belongs to a zero-triangle in that part, and if it is in one of the two lower triangles, the size and location of the zero-triangle can be determined by translating it back to the upper $2^g$ rows.

 
%\begin{align}
 %   \binom{n}{k}\equiv \binom{n-2^g}{k}\ (\mod\ 2)\ \mathrm{if\ }k<2^g\ nonumber\\
  %  \binom{n}{k}\equiv\binom{n-2^g}{k-2^g}\mathrm{if\ }k\geq 2^g.\\
%\end{align}
%This transformation can lead to $k>n$, i.e. to an entry outside Pascal's triangle.  This means the original entry was zero. 


This means that there is an algorithm for translating any even entry $\binom{n}{k}$ back to the corresponding entry in the earliest triangle of the same size:
%\begin{enumerate}
%    \item Let $g=\lfloor\log_2 n\rfloor$. If $2^g -n\leq k<2^g$, then $\binom{n}{k}$ is in the first triangle of its size.
%    \item Otherwise, map $n\rightarrow n-2^g$.
%    Map $k\rightarrow k-2^g$ if $k>2^g$, or $k\rightarrow k$ if not.
%    \item Repeat until an entry in the first triangle is found.
%\end{enumerate}
\begin{enumerate}
    \item Let $g = \lfloor \log_2 n \rfloor$.  Then $\binom nk$ is between the $2^g$-th and $2^{g+1}-1$-st rows.
    \item If $n-2^g< k< 2^g$ this entry is already in the first triangle of its size, which is $2^g-1$.
    \item Otherwise, map $n \rightarrow n - 2^g$. If $k > 2^g$, then also map $k \rightarrow k - 2^g$. This will give an entry in a triangle of the same size.
    \item
    Repeat steps 1-3 until case 2 is reached--i.e., the entry is in the first triangle of its size is reached, and call this entry $\binom{n_0}{k_0}$.
\end{enumerate}
An example of this algorithm applied to a triangle of size $3$ whose base has $n = 28$ is shown in Fig.~\ref{fig:pascal_algo}.

\begin{figure}
    \centering
    $\includegraphics[scale = 0.3]{pascal_algorithm.png}$
    \caption{Example of an algorithmic reduction of a triangle $T$ of size $3$ with base $n = 28$. The full reduction of $T \rightarrow T_0$ only requires two steps after initialization of $T$ (shown in the highlighted triangles).}
    \label{fig:pascal_algo}
\end{figure}



\par After simplifying this process using binary notation, we can present a formula for the reduced entry $\binom{n_0}{k_0}$.
 We first introduce a bit of useful notation. Let the sequence $(n)^c_0$ denote the binary representation of $n$ from the $0\textsuperscript{th}$ (least significant) bit to the $c\textsuperscript{th}$ bit (inclusive), and let $(n)_c^\mathrm{end}$ denote the binary digits of $n$ from the $c\textsuperscript{th}$ bit to the last (most significant) bit.
\begin{thm}
\label{thm:entry_reduce}
Given some $\binom{n}{k}$ in a triangle $T$, let $T_0$ be the first instance of a triangle in Pascal's triangle of the same size $|T|$ and let $\binom{n_0}{k_0}$ be the entry within this triangle corresponding to $\binom{n}{k}$ in $T$. In order to find $\binom{n_0}{k_0}$, suppose that $c > 0$ is the largest integer such that $(n)_0^{c-1} < (k)_0^{c-1}$. Then $n_0 = (n)_0^c$ and $k_0 = (k)_0^c$. 
%Given some $\binom{n}{k}$ in a triangle $T$, suppose that $c > 0$ is the largest integer such that $(n)_0^{c-1} < (k)_0^{c-1}$. Let $n_0 = (n)_0^c$ and $k_0 = (k)_0^c$. Then $\binom{n_0}{k_0}$ is contained within $T_0$, where $T_0$ is the first instance of a triangle of size $|T|$. 
\end{thm}
\begin{proof}
    This result follows easily from the earlier described algorithm. Given some $\binom{n}{k}$ in a triangle $T$, suppose that $c > 0$ is the greatest integer such that $(n)_0^{c-1} < (k)_0^{c-1}$. There is some integer with this property because $\binom{n}{k}$ is even, so Lucas's theorem implies that some pair of bits of $n$ and $k$ are 0 and 1 respectively. 
    \par Repeatedly subtracting powers of $2$ from $n$ and sometimes from $k$ (as in the algorithm) is equivalent to truncating the binary representations of these integers from the left one digit at a time. The algorithm stops when step 2 is reached, i.e., $n-2^g<k<2^g$ which is the same as saying that truncating $n$ again would make it smaller than $k$.  So the algorithm stops at the entry $((n)_0^{c},(k)_0^{c})$.  
    
    %So there will be some index within the binary such that for the index at that point, $n$ becomes less than $k$, so any further reductions will map $\binom{n}{k}$ to an entry outside of Pascal's triangle. We call this index $c - 1$, so by stopping the algorithm above at index $c$, we effectively map $\binom{n}{k}$ to the corresponding entry in the 1st instance of a triangle of size $|T|$. 
    % \par {\color{red}Do you want to take out the next part? } Furthermore, this theorem holds even when $T$ is the first instance of a triangle of size $|T|$. This is because if $\binom{n}{k}$ exists within the first instance of a triangle of size $|T|$, then $n - |T| \leq k \leq |T|$. Since $|T| = 2^a - 1$ (for $a = \lfloor log_2(n) \rfloor$), clearly $0 \leq (n)_0^{a-1} \leq 2^a - 2$. This implies that $(n)_0^{a-1} < (k)_0^{a-1} \implies c = a = \lfloor log_2(n) \rfloor$, which is consistent with the assumption that $T$ is the first triangle of size $|T|$.
\end{proof}

\par A simplified way to determine $c$ is to first locate the left-most bits of $n$ and $k$ that are equal to 0 and 1 respectively. Then sweep leftwards (in order of increasing significance of bits) to the first pair of bits of $n$ and $k$ that are $1$ and $0$ respectively. Then the position of these bits is $c$, because they satisfy the conditions of the construction.
\par After reducing a triangle to the first triangle of that size, we are still left with the problem of determining the base of the original triangle. Luckily, this is rather straightforward post reduction and can be done as follows.
% \begin{thm}
% \label{thm:tri_size}
%     Given some $\binom{n}{k}$ in a triangle $T$ (where $T$ is not the first instance of a triangle of its size), suppose that $c > 0$ is the least integer such that $(n)_0^c > (k)_0^c$. Then $|T| = 2^{\lfloor log_2 (n)_0^c \rfloor} - 1$. 
% \end{thm}
% \begin{proof}
%     This theorem follows easily from the algorithm we earlier proposed. By repeatedly subtracting powers of $2$ from $n$ and $k$, we are successively truncating the binary representations of these integers. So there will be some index within the binary such that at that point, $n$ becomes less than $k$, so any further reductions will map $\binom{n}{k}$ to an entry outside of Pascal's triangle. We call this index $c$, so by stopping the algorithm above at index $c$, we effectively map $\binom{n}{k}$ to the corresponding entry in the 1st instance of a triangle of size $|T|$. Thus the size of this triangle will simply be $|T| = 2^{\lfloor log_2 (n)_0^c \rfloor} - 1$.
% \end{proof}
% \par Using Theorem \ref{thm:tri_size}, we can find the size of the triangle $T$. Then we can perform a simple reduction on $\binom{n}{k}$ to map it to the corresponding entry within the first instance of $T$ in row $n$.
% \begin{thm}
% \label{thm:tri_reduce}

% Suppose $\binom{n}{k} = 0$ exists within a triangle $T$ of size $|T|$ in Pascal's Triangle such that $T$ is not the first triangle of size $|T|$. Let $k^\prime = (k)^{log_2(|T| + 1)}_0$. Then $\binom{n}{k ^ \prime}$ and $\binom{n}{k}$ are corresponding entries of triangles $T^\prime$ and $T$ respectively; however, $T ^ \prime$ is the first triangle of size $|T|$ in row $n$.
% \end{thm}

% \begin{proof}
% \par Let $T^i_0$ be the first instance of a triangle with size $2^i - 1$, meaning that $b(T^i_0) = 2^i$. Allow $P(r)$ to denote the set of the first $r$ rows of Pascal's Triangle. If we are looking at $P(2^g - 1)$ (for some integer $g$), we can easily generate $P(2^{g+1} - 1)$ by sliding down copies of $P(2^g - 1)$ to the right and left such that their tops represent $\binom{2^g}{0}$ and $\binom{2^g}{2^g}$, and they are separated by $T^g_0$ (by the self-similarity discussed by Kubelka in \cite{kubelka}). Thus for any $\binom{n}{k}$ within the second copy of $P(2^g - 1)$, by reducing the entry to $\binom{n}{k - 2^g}$ (using the translational symmetry of $P(2^{g+1} - 1)$ across $T^g_0$), that element has been mapped to the corresponding (and equivalent) element in the first copy of $P(2^g - 1)$. As a result, the problem of reducing $\binom{n}{k}$ within $P(2^{g+1} - 1)$ simplifies to the issue of reducing $\binom{n}{k - 2^g}$ within $P(2^g - 1)$. 

% \par Going back to the problem at hand, by the discussion we just provided, it is clear that if $\binom{n}{k}$ exists within $T$, we must repeatedly subtract powers of $2$ from $k$ to reduce it until we have reached an $\binom{n}{k^\prime}$ within $T^\prime$. The question is now how to determine when to stop reducing $k$. The solution is quite simple: we stop subtracting powers of $2$ from $k$ once we reach $log_2 (|T| + 1)$th bit of $k$, as $\binom{n}{k^\prime}$ was never shifted by $|T| + 1$ to reach $\binom{n}{k}$ (as $|T| + 1$ is the first row containing a triangle of size $T$). Hence $k^\prime = (k)^{log_2(|T| + 1)}_0$, so $\binom{n}{k^\prime}$ is the corresponding entry within the first triangle (in row $n$) of size $|T|$.
% \end{proof}\

\begin{thm}
\label{thm:tri_base}
    Suppose $\binom{n}{k}$ is even.  Let $\binom{n_0}{k_0}$ be the entry in $T_0$ corresponding to $\binom{n}{k}$ in $T$, with $n_0=(n)_0^c$ and $k_0=(k)_0^c$ as in the last theorem. %If $c > 0$ is the largest integer such that $(n)_0^{c-1} < (k)_0^{c-1}$, then $n_0 = (n)_0^c$ and $k_0 = (k)_0^c$. 
    Then the base of $T$ is $(n)^\mathrm{end}_c2^c$.
    %$n - n_0 + 2^{\lfloor log_2(n_0) \rfloor}$. 
\end{thm}

\begin{proof}
    This theorem is very straightforward to see, so we shall be rather brief. Given that $T_0$ is the first instance of a triangle of size $|T|$ within Pascal's Triangle, we see that the base of $T_0$ is $2^{\lfloor log_2(n_0) \rfloor}$. So the distance between $\binom{n_0}{k_0}$ and the base of $T_0$ is $n_0 - 2^{\lfloor log_2(n_0) \rfloor}$. Given that $\binom{n_0}{k_0}$ and $\binom{n}{k}$ are corresponding entries of $T_0$ and $T$ respectively, the distance between $\binom{n}{k}$ and the base of $T$ must also be $n_0 - 2^{\lfloor log_2(n_0) \rfloor}$. Hence the base of $T$ is $n - (n_0-2^{\lfloor log_2(n_0) \rfloor}) = n - n_0 +2^{\lfloor log_2(n_0) \rfloor}$. 
 This is the same as $n-(n)_0^c+2^c$.  
 By using the binary notation to subtract $n-(n)_0^c+2^c$, one sees that it is equal to $(n)_c^\mathrm{end}2^c$.  (This uses the fact that the most significant digit of $(n)_0^c$ is 1, because of how $c$ is defined.)
\end{proof}

% \par Then combining Theorem~\ref{thm:tri_base} with Theorem~\ref{thm:entry_reduce}, we propose a general formula to determine the base of the triangle $\binom{n}{k} = 0$ is within.
% \par Thus putting everything together, we now have an easy 4-step process for determining the base of the triangle that any $\binom{n}{k}$ is within:
% \begin{enumerate}
%     \item If $B(n, k) = 2^{\lfloor log_2 n \rfloor}$, then $\binom{n}{k}$ is in the first instance of a triangle of its size. Hence the base of the triangle is $2^{\lfloor log_2 n \rfloor} - 1$.
%     \item Else apply Theorem~\ref{thm:tri_size} to determine the size of the triangle $|T|$.
%     \item Apply Theorem~\ref{thm:tri_reduce} to reduce $\binom{n}{k}$ to the corresponding entry of the 1st triangle of size $|T|$ in row $n$.
%     \item Apply Theorem~\ref{thm:tri_base} to determine the base of triangle $T$.
% \end{enumerate}
% \par We treat these 4-steps as 2 separate procedures, as finding the base of the triangle containing $\binom{n}{k}$ is very easy if $B(n, k) = 2^{\lfloor log_2 n \rfloor} - 1$. Thus if this is not the case, we can combine the three steps as follows.
% \begin{thm}
%     Suppose $\binom{n}{k} = 0$. Then the base of the triangle containing $\binom{n}{k}$ is given by $$B(n, k^\prime) = \sum_{i= \lfloor log_2 k^\prime \rfloor + 1} ^ {\lfloor log_2 n \rfloor} (\left \lfloor \frac{n}{2^i} \right \rfloor - 2 \left \lfloor \frac{n}{2^{i+1}} \right \rfloor)2^i$$ Here $k^\prime = (k)^c_0$ and $c$ is the largest integer such that $(n)_0^{c -1} < (k)_0^{c-1}$.
%     \label{thm:pascal_final}
% \end{thm}
Thus we've determined a way to find $h$, the size of the largest Jordan block that $J_\lambda \oplus J_\mu$ splits into: apply this method with $n=a+b-2,k=a-1$. Then $h$ is the base of the triangle containing $\binom{n}{k}$.
Some interesting special cases of this result, which can be checked in Table \ref{fig:jordan_table}, are:
\begin{enumerate}
    \item The size of the largest block is $a+b-1$ if the binary digits of $a-1$ and $b-1$ in the corresponding places are never both equal to 1 (because by Lucas's theorem $\binom{a+b-2}{a-1}$ is odd in this case).
    \item The size of the largest block is even if it is not equal to $a+b-1$.
    \item The size is a power of $2$ if $a=b$. It is equal to $2^{\lceil\log_2 a\rceil}$ in this case.
    %\item is equal to $a$ if $b=1$; is equal to $2\lfloor\frac a2\rfloor$ if $b=2$; is equal to $a-\epsilon(a)$ if $b=3$ where $\epsilon(a)=2,2,1,0$ when $\equiv 1,2,3,4 (\mathrm{mod\ 4})$.
    \item For each specific $b$ the size is equal to $a+\epsilon(a)$, where $\epsilon(a)$ is a periodic function.  The period is $2^{\lceil \log_2 b\rceil}$.
\end{enumerate}
% \par Every triangle within Pascal's Triangle possess a left edge and a right edge; however, if a given triangle is the first instance of a triangle of its size within a certain row, determining the left and right edges is quite simple. Allow $T^i_1$ to be a triangle of size $2^i - 1$ within row $n$. Additionally, assume that $T^i_1$ is the first triangle in row $n$ of size $2^i -1$, and the base of $T^i_1$ lies in row $n$. It can be seen that if the base of a triangle of size $2^i - 1$ exists within row $n$, then $n \bmod 2^i \equiv 0 \bmod 2^i$. Then it is clear that for any $\binom{n}{k}$ within $T^i_1$, $0< k < 2^i$. However, it is important to consider the case in which the base of $T^i_1$ does not exist in row $n$. Allow $(n_j)^c_0$ to be the sequence representing the binary of $n$ where $n_0$ is the coefficient of $2^0$ in the binary representation of $n$. Then when the base of  $T^i_1$ is not in row $n$, the lower bound on $k$ becomes $(n_j)^{i-1}_0$. This is because for each row between $n$ and the base of $T^i_1$, the lower bound of $k$ increases by $1$. Thus, in general, if $T^i_1$ is the first triangle of size $2^i - 1$ in row $n$, $(n_j)^{i-1}_0 < k < 2^i$.

% \par Using this idea and Theorem $3.6$, it is possible to derive in inequality whose solution reduces any $\binom{n}{k}$ within $T^i_1$ to an $\binom{n}{k^\prime}$ within the first instance of that triangle in row $n$. We now disregard the earlier assumption that $T^i_1$ is the first triangle in row $n$ of size $2^i - 1$. Thus to sufficiently reduce $k$, all that must be done is the repeated subtraction of powers of $2$ until it lands in the first instance of a triangle of size $2^ i - 1$. If $(k_j)^b_0$ is the binary of $k$, the inequality to be solved is simply $(n_j)^{w-1}_0 < (k_j)^{w-1}_0 < 2^w$. Thus $k^\prime = (k_j)^{w-1}_0$, and from here, we simply apply Theorem $3.5$ to determine the base of $T^i_1$.



% \subsection{New Pascal Argument}


% \begin{enumerate}
%     \item Motivation of wanting to minimize $h$ and how this becomes a combinatorics problem
%     \item General definitions
%     \item Problem of determining base of entry of arbitrary triangle
%     \item Can easily determine base of 1st triangle but problem is tricky because there are multiple triangles of same size in given row
%     \item Propose algorithm for finding n-reductions and k-reductions
%     \item Show how algorithm translates into inequality which can be solved for the size of the triangle. 
%     \item Using size of the triangle we can perform the reduction $\binom{n}{k} \rightarrow \binom{n}{k^\prime}$
% \end{enumerate}
% \par Suppose we have some $\binom{n}{k}$ in a triangle $T$. Recall that by the self-similarity of Pascal's triangle, successive rows are generated by copying and sliding down previous rows. This means that unless $T$ is the first triangle of size $|T|$, then $\binom{n}{k}$ was copied from some earlier entry in Pascal's triangle. To find the original entry $\binom{n}{k}$ was copied from, we simply must subtract powers of $2$ from $n$ and $k$ until $k > n$. At this point, we know that $\binom{n}{k}$ has been reduced too far, as we will have obtained an entry that is not in Pascal's triangle. The algorithm is as follows:
% \begin{enumerate}
%     \item Let $g = \lfloor log_2 n \rfloor$.
%     \item If $k > 2^g$, then map $k \rightarrow k - 2^g$.
%     \item Map $n \rightarrow n - 2^g$.
%     \item Then repeat steps $1 - 3$ until $k > n$. At this point, $|T| = 2^g - 1$.
% \end{enumerate}
% \par Using this algorithm, we propose a formula for the size of the triangle $|T|$. 
% \begin{thm}
% \label{thm:tri_size}
%     Given some $\binom{n}{k}$ in a triangle $T$, suppose that $c > 0$ is the least integer such that $(n)_0^c > (k)_0^c$. Then $|T| = \lfloor log_2 (n)_0^c \rfloor - 1$. 
% \end{thm}
% \begin{proof}
%     This theorem follows easily from the algorithm we earlier proposed. By repeatedly subtracting powers of $2$ from $n$ and $k$, we are successively truncating the binary representations of these integers. So there will be some index within the binary such that at that point, $n$ becomes less than $k$, so any further reductions will map $\binom{n}{k}$ to an entry outside of Pascal's triangle. We call this index $c$, so by stopping the algorithm above at index $c$, we effectively map $\binom{n}{k}$ to the corresponding entry in the 1st instance of a triangle of size $|T|$. Thus the size of this triangle will simply be $|T| = \lfloor log_2 (n)_0^c \rfloor - 1$.
% \end{proof}






\subsection{Determining The Cycle-lengths of $\sigma$ Automata}
\label{sec:CL_sigma}

\par Before we prove $CL(\Phi) = CL(\sigma)$, recall that these cycle lengths are related to orders of eigenvalues that are difficult to 
predict, as shown in theorem~\ref{thm:rdm_sord} and discussed in Section~\ref{sec:phi_fields}. The eigenvalues of $T_n$ are sums of eigenvalues of $A_n$; however, the order of a sum of field elements is not related to the orders of the constituent elements by a general rule. Thus to prove that the cycle lengths of $\Phi$ and $\sigma$ are equal, we derive an additional relationship between the eigenvalues.


% We explained the unpredictability of cycle-lengths, and noted that even though we don't know the exact forms of the cycle-lengths of $\Phi$ or $\sigma$ automata, we can still equate the cycle-lengths to one another. 





% {\color{green}idea for something we could say instead of this--we know that both cases belong to the same field so the periods are divisors of $2^j-1$, but the divisor is unpredictable. Orders of a sum of numbers are hard to predict, but there is a different relationship between eigenvalues of A and T.}

\begin{thm}
\label{thm:sum=prod}
For any $n$ automaton, the sum of any two distinct nonzero eigenvalues of $A_n$ is equal to the product of two nonzero eigenvalues of $A_n$.
\end{thm}

\begin{proof} Let $n+1=2^ab$ where $b$ is odd.
By theorem \ref{thm:powersof2},
the nonzero eigenvalues are $\lambda_j=\alpha^j+\alpha^{-j}$, for $1\leq j\leq \frac{b-1}{2}$. Also, the rest of this sequence, for $\frac{b+1}{2}\leq j<\infty $ repeats just these nonzero eigenvalues, except when it is zero, which happens when $j$ is a multiple of $b$. 

Say we want to sum two distinct eigenvalues, e.g. $\lambda_i$ and $\lambda_{i+j}$.
If $j = 2k$ for an integer $k$,
then 
\begin{align}
    \lambda_i+\lambda_{i+2k}&=\alpha^i+\alpha^{-i}+\alpha^{i+2k}+\alpha^{-i-2k}\nonumber\\
    &=(\alpha^{i+k}+\alpha^{-i-k})(\alpha^{k}+\alpha^{-k})\nonumber\\
    &=\lambda_{i+k}\lambda_k.
    \label{eq:sumproduct}
\end{align}
Because the eigenvalues being added are distinct, $k\neq 0$, so $\lambda_k$ and $\lambda_{i+k}$ are nonzero.

If $j$ is odd, this does not work immediately.  However, since $\lambda_{k} = \lambda_{b - k}$ and $b$ is odd we can rewrite $\lambda_i + \lambda_{i+j}$ as $\lambda_i + \lambda_{i + 2m}$ where $m$ is some integer, so this is equal to $\lambda_{i+m}\lambda_m$.
\end{proof}

\par  We now consider two groups,
the smallest groups $G_A$ and $G_T$ under multiplication that contain all nonzero eigenvalues of $A$ and $T$ respectively.  By proving that the groups are the same, we show that the lcm of the orders of the eigenvalues of $A$ and $T$ are equal:  Since the groups are the same, any eigenvalue of $T$ is equal to the product of some eigenvalues of $A$, and vice versa, which implies the least common multiples of the orders are equal.

%By the previous theorem, $G_T\subset G_A$.
%If $n$ is odd, then $A$ has zero as an eigenvalue, so $T$'s eigenvalues, the sums $\lambda+\lambda'$ of all pairs of eigenvalues of $A$, include all of $A$'s eigenvalues (by taking $\lambda'=0$).
%Therefore $G_A=G_T$ in that case.


\begin{thm}
For an $n \times 1$ $\Phi$ automaton and an $n \times n$ $\sigma$ automaton with $n \geq 0$, the lcm of the orders of the eigenvalues of $A$ and $T$ will be equal, unless $n=2$ or 4.
\label{thm:eig_lcm_equal}
\end{thm}

\begin{proof}
\par  First off, because $T = A \oplus A$, the eigenvalues of $T$ are simply all possible sums of two eigenvalues of $A$, which means that all the eigenvalues of $T$ are products of pairs of eigenvalues of $A$ (by theorem \ref{thm:sum=prod}) or are just equal to eigenvalues of $A$ when one of the eigenvalues added together is 0.
This implies that $G_T\subset G_A$.

If $n$ is odd, then $A$ has zero as an eigenvalue, so sums of two eigenvalues of $A$ include all of $A$'s eigenvalues.
Therefore $G_A\subset G_T$ in that case, so $G_A=G_T$.

Now say $n$ is even. To show that all eigenvalues of $A$ are contained within $G_T$, we first show that $\lambda_1\in G_T$.  First, one element of $G_T$ is
 $\lambda_1+\lambda_3=\lambda_1\lambda_2$ (by eq. \ref{eq:sumproduct}).
 But $\lambda_2=\lambda_1^2$, so $\lambda_1^3\in G_T$.  Also $\lambda_3+\lambda_5=\lambda_1\lambda_4=\lambda_1^5$, so $\lambda_1^5\in G_T.$
 Thus $\lambda_1 ^ 3 \lambda_1 ^3 \lambda_1 ^ {-5} = \lambda_1 \in G_T$ since $G_T$ is closed under multiplication. 

 Now for any other eigenvalue $\lambda_i$, the product $\lambda_i\lambda_1$ is in $G_T$ because it is equal to $\lambda_{i+1}+\lambda_{i-1}$.  So $\lambda_i=(\lambda_1\lambda_i)/\lambda_1\in G_T$.

 This argument breaks down if $n+1=3$ or 5, since $\lambda_3$ and $\lambda_5$ must be nonzero eigenvalues of $A$ for this proof to be correct. 
 \end{proof}

Now we consider the cycle lengths for $\Phi$ and $\sigma$.
\begin{thm}
An $n \times 1$ $\Phi$ automaton and an $n \times n$ $\sigma$ automaton have the same cycle length, except for $n=2,4$.
\label{thm:CL_equal}
\end{thm}


\begin{proof}
As we have mentioned throughout this paper, the cycle lengths of $\Phi$ and $\sigma$ are the lcm of the periods of the Jordan blocks of $A$ and $T$.  The periods of Jordan blocks are 1 when the eigenvalue is zero and are given by Theorem \ref{thm:jb_period_1} when it is not.

Let the cycle length of $T_n$ be $2^st$, and let the cycle lengths of the Jordan blocks be $2^{s_i}t_i$ for the $i^\mathrm{th}$ Jordan block. We will find $2^s$ and $t$  by taking the lcm of $2^{s_i}$ and $t_i$.



If $n+1$ is a power of 2 then all the eigenvalues of $A_n$ and $T_n$ are zero by Theorem \ref{thm:powersof2}, so eventually all lights turn off and the cycle length is 1.

Theorem \ref{thm:eig_lcm_equal} showed that the least common multiple of the orders of the eigenvalues in two and one dimensions are the same except for $n=2$ and 4, so $t$ is the same in both dimensions.  In particular there \emph{are} nonzero eigenvalues in two dimensions if $n+1$ is not a power of 2 and is not equal to 3 or 5.\footnote{When $n+1=5$, there are also nonzero eigenvalues.} For any nonzero eigenvalue of $T$, the largest Jordan block of $T$ has the size $2^{a+1}$ (by theorem \ref{thm:T_jordan_block}), so $2^s=2^{a+1}$ by theorem \ref{thm:jb_period_1}, as in one dimension. So both $2^s$ and $t$ are the same in one and two dimensions.

Now consider the edge cases $n = 2, 4$. When $n=2$, we have $CL(\Phi_2)=2$, $CL(\sigma_2)=1$. When $n=4$, $CL(\Phi_4)=6$, $CL(\sigma_4)=2$. This can be seen by watching the evolution of the automata (one has to check just initial conditions where one light is on, see Lemma \ref{lma:greenfunction}).  The cycle lengths can also be found using the Jordan normal form, using identities for the cube roots and fifth roots of 1.

Thus the cycle lengths of $\Phi$ and.$\sigma$ are always the same except when $n=2$ or $4$.
\end{proof}
 

\begin{comment}
%The Jordan blocks of $T_n$ are Jordan blocks in $A_n\oplus A_n$, e.g., a block contained in the sum of a Jordan block with eigenvalue $\lambda$ and a Jordan block with eigenvalue $\mu$, as found earlier in this section. The odd factor of the cycle length is thus the same in one and two dimensions except when $n=2$ and $4$.
In these cases, it is the least common multiple of the orders of the eigenvalues, which we know is the same by theorem~\ref{thm:eig_lcm_equal}.


If there is a nonzero eigenvalue of $T$, then the largest Jordan blocks with nonzero eigenvalues have the size $2^{a+1}$ (by theorem \ref{thm:T_jordan_block}). The power of 2 in their period is $2^{a+1}$ by theorem \ref{thm:jb_period_1}, so
$2^s=2^{a+1}$. To see when there is a nonzero eigenvalue of $T$, consider different cases by listing $n+1$ as a power of 2 times an odd number, $1,2,4,\dots,3,3\cdot 2,3\cdot 4,\dots,5,5\cdot 2,$ etc. For the powers of 2, the only eigenvalue is 0.  For $n+1=3$, there is only one eigenvalue, $\alpha+\alpha^{-1}$ (see theorem \ref{thm:eigen_sum}) The next cases $3\cdot2^b$ also have zero as an eigenvalue, and the rest clearly have at least two eigenvalues.



\begin{comment}Consider the periods of Jordan blocks in the sum $A\oplus A$, e.g. $J_2+(\lambda+\mu)I$.
If $\lambda=\mu$, the size of the largest block is $2^a$ (where $2^a$ is the largest power of 2 in $n+1$).  The eigenvalue is zero, so the cycle length is 1.
If $\lambda\neq\mu$, the size of the largest block is $2^{a+1}$ by theorem \ref{thm:T_jordan_block} and the eigenvalue is nonzero, so the power of 2 in the period is $2^{a+1}$ by lemma \ref{thm:jb_period_1}.



%Let $\lambda_1$ and $\lambda_2$ be two different eigenvalues of $A$. Then the largest block for them is $2^{a+1}$ so the power of 2 in the cycle length of $T$ is $2^{a+1}$.  This is also the power of 2 dividing the cycle length of $A$.

There are always some pairs of different eigenvalues except when $n=2^k-1$ (when all eigenvalues are 0) or $n=2$ (when the only eigenvalue is 1). 

5,2\cdot 5, 4\cdot 5,7,2\cdot  5,


there are either at least two nonzero eigenvalues (if the odd factor of $n+1$ is greater than 3), see thm. ...., or a zero and a nonzero eigenvalue if $n+1=2^j\cdot 3$ and $j\geq1$.


If $n+1$ is divisible by an odd number greater than 3, there is more than one nonzero eigenvalue in thm. 4.5.  If $n+1$ has 3 as its only odd divisor but has factors of 2, then there is a zero eigenvalue besides the nonzero one.  The only cases that are left are $n+1=3$ and $n+1=2^k$, which have only the eigenvalue 1 and 0 respectively.  


Suppose $n\neq 2$.  If $n+1=2^a$ then the powers of 2 in the cycle length are 1 in both one and two dimensions since all eigenvalues are zero. For the values of $n+1$ that are not powers of 2, there is a nonzero eigenvalue, so $2^s=2^{a+1}$ in both one and two dimensions. Combining the results that $t$ and $s$ are the same in one and two dimensions, it follows that $CL(\Phi_n)=CL(\sigma_n)$ when $n\neq 2,4$.
Now consider the edge cases $n = 2, 4$. When $n=2$, we have $CL(\Phi_2)=2$, $CL(\sigma_2)=1$. When $n=4$, $CL(\Phi_4)=6$, $CL(\sigma_4)=2$, as can be seen by watching the evolution of the automata (one only has to check initial conditions where one light is on).  The cycle lengths found from the Jordan blocks and eigenvalues agree (as found by using identities for the cube roots and fifth roots in the working fields).

%values, various sizes up to $2^{a+1}$ (this is for nonzero eigenvalues and for zero when it is the sum of one nonzero eigenvalue with itself)
%zero: various sizes up to $2^a$
%Cycle length of the first type is $2^{a+1}$, and of the second type it is 1 because it gets to zero eventually.
%So the power of $2$ in the cycle length is $2^{a+1}$ when there is any nonzero eigenvalue, which is the same as one dimension. And it is 1 in both dimensions if the eigenvalues are all zero in both dimensions.  But the eigenvalues can be nonzero in 1d but all zero in 2d by
%All the eigenv


%Say $n+1=2^ab$ and the cycle length is $2^st$ where $b$ and $t$ are odd.

%2^s=next power of 2 after largest Jordan block with a nonzero eigenvalue
%t=lcm of periods of nonzero eigenvalues

%cases: $n=2^k-1$ all eigenvalues are zero cycle length=1
%n=2: one nonzero eigenvalue in 1d, all zeros in 2d.
%n=4: nonzero eigenvalues in both dimensions but they generate different groups
%other ns: eigenvalues generate the same groups and the sizes of the largest blocks are the same.

%As we have mentioned throughout this paper, the cycle-lengths of $\Phi$ and $\sigma$ are the lcm of the periods of the Jordan blocks of $A$ and $T$. Jordan
%If the Jordan blocks have periods of $2^{q_i}p_i$ where $p_i$ is odd,
%then $s=\mathrm{max}\ q_i$ 

%The periods of Jordan blocks are 1 (when the eigenvalue is zero) or else are equal to $2^qp$ where $p$ is odd and is the period of the eigenvalue, and $q$ depends on the size of the Jordan block (see lemma \ref{jb_period_1}).
%So if there are eigenvalues besides 0,$2^s$ is the least common multiple of $2^q$  while $t$ is the least common multiple of the $p$. If all eigenvalues are zero, the cycle length is one.





%Jordan blocks with zero as the eigenvalue have a cycle length of 1 since all powers of them larger than their size are constant (zero).  So if all eigenvalues are zero, the cycle length is 1. If this is true in 1D it is also true in 2D.

%or in two dimensions when $n+1=3$ (the one dimensional automaton for $n+1=3$ has only one eigenvalue, so all eigenvalues of the two dimensional automaton are equal to twice it.)  For the former case, the automata in both dimensions have cycle length 1 (and eventually all the lights turn off, without any strategy being used (ref. to Sutner I think?). When $n+1=3$, the one dimensional automaton has a cycle length of two, different from the 2-d automaton.

%Otherwise, there are nonzero eigenvalues. Theorem \ref{jb_period_1} implies that $s$ is determined by the size of the largest Jordan block with a nonzero eigenvalue and $t$ is the least common multiple of the orders of the eigenvalues. 
%Theorem \ref{thm:jordan_eigen_sum} shows that for each nonzero eigenvalue the largest Jordan block has the same size $2^a$ (in 1-d and 2-d) so $s=a$ in both dimensions.
%Theorem \label{thm:eig_lcm_equal} implies that the lcm of their eigenvalues are identical except when $n=4$, so $b=t$ and
%$CL(\Phi)=CL(\sigma)$.
\end{proof}

% {\color{red}Two things we could add maybe--appendix showing there is actually a state whose cycle length is CL--it is not just the lcm of all cycle lengths.}


%general result about power of 2 dividing
%cycle length of $A\oplus A$ for any matrix $A$.

\end{comment}


\section{Cycle Lengths in Higher Dimensions}
\label{sec:CL_highd}
Consider an automaton described by a $d$-dimensional lattice of cells that evolves according to following rule: each cell goes to state 0 or 1 if an even number or an odd number, respectively, of nearest-neighbor cells were in state $1$ at the previous time-step. This automaton describes the evolution of a $d$-dimensional Lights Out game.  This is described by the Kronecker sum of $d$ matrices $A_n$, where $d$ is the dimension. Although the number of sites grows with the dimension (for automata that are $n\times n\times\dots\times n$), the cycle length will not increase arbitrarily because the eigenvalues are sums of the eigenvalues in one dimension. 
Hence the eigenvalues remain in a finite field $\mathbb{F}_{2^k}$, where $k=\mathrm{sord}_2(n+1)$, and the largest order they can have is $2^k-1$.  Thus if $n+1$ is odd the cycle length of the automaton is a divisor of $2^k-1$.
Table~\ref{fig:cycle_table} shows that, at least for small values of $n$, the cycle length is often already equal to $2^k-1$ in one dimension, but sometimes it is smaller. If the one-dimensional cycle length is smaller than $2^k-1$, the two-dimensional cycle length is identical to the one-dimensional cycle length.  We will show that in higher dimensions the cycle-length will eventually saturate to the maximum possible, $2^k-1$, except when$n=2$ or 4. We focus on the case where $n$ is even. (A simpler version of the same ideas can be used when $n$ is odd.)

The eigenvalues of the automaton's matrix in $d$ dimensions are the sums of all combinations of $d$ eigenvalues of $A$. When $d$ is at least as big as the number of eigenvalues, some eigenvalues will be repeated, and pairs of repeated eigenvalues  can be left out since the arithmetic is modulo 2. Thus when $d$ is large enough and even (odd), the eigenvalues are all sums of any combination of an even (odd) number of eigenvalues of $A$.\footnote{When $n$ is odd, zero is an eigenvalue of $A_n$. Hence sums of even and odd numbers of eigenvalues are the same, making this case simpler.}


To find the cycle length, we will find the smallest group $G_d$ containing all the nonzero eigenvalues of the $d$-dimensional automaton. It will be helpful to first understand the set of sums of any number of eigenvalues of $A$, either  even or odd. This set constitutes a field, so it is the same as the working field $\mathbb{F}_{2^k}$, as that is the smallest field containing all eigenvalues. The reason it is a field is that it is closed under addition (obviously), and it is closed under multiplication. Closure under multiplication holds because if one multiplies two sums of eigenvalues, this can be expanded as a sum of terms of the form $\lambda_i\lambda_j$. This is $\lambda_{i+j}+\lambda_{j-i}$ which is the sum of two eigenvalues if $i\neq j$ and is an eigenvalue itself if $i=j$ (because then $\lambda_{j-i}=\alpha^0+\alpha^0=0$).
 Now we use the fact that all the elements have a finite order to prove that the set contains 1 and is closed under inverses (as in Theorem 5.1.2 in~\cite{Herstein}): The element $1$ belongs to this set because 1 is some power of any nonzero eigenvalue.  Closure under reciprocation follows from the fact that if $x$ is an element then $x^{-1}$ also is because $x^{-1}=x^{j-1}$ where $j$ is the order of $x$.

Assuming $n\geq6$, the sums of an even number of eigenvalues of $A$ will now be written as ratios of sums of odd numbers of eigenvalues of $A$ and vice versa.  This shows that the smallest group containing sums of an even number of eigenvalues also contains sums of odd numbers of eigenvalues and vice versa.  So this group is always the full working field (aside from 0).

If $\sigma$ is a sum of $p$ eigenvalues of $A$ and $\tau$ is a sum of $q$ eigenvalues of $A$ and there are $r$ eigenvalues in common,
then $\sigma\tau$ is a sum of $l=2pq-r$ eigenvalues, because $\lambda_i\lambda_j$ is the sum of two eigenvalues if $i\neq j$ and is one eigenvalue if $i=j$, as we found in the proof that the set of sums of eigenvalues is a field. That is, the parity of the number of the number of terms in $\sigma\tau$ is the number of common eigenvalues.

Let $\sigma$ be a sum of some number of eigenvalues. To find a way of writing $\sigma$ as a ratio of two other sums of eigenvalues, let $\tau$ be a sum of eigenvalues, multiply $\sigma$ by $\tau$ and then divide by $\tau$ again: $\sigma=\frac{\mu}{\tau}$ where $\mu=\sigma\tau$. The parity of the number of terms in $\tau$ and $\mu$ can be chosen arbitrarily since one can decide how many terms $\tau$ and $\sigma$ have in common.  The table shows what $\tau$ should be to prove that $\sigma$ is the ratio of two sums of an even(odd) number of eigenvalues when $\sigma$ is a sum of an odd(even) number of eigenvalues.  There are different cases depending on the number of terms in $\sigma$, i.e., $p$.
\begin{center}
\begin{tabular}{|c|c|c|}
 $p$ & How to choose terms in $\tau$ & $l$\\
 \hline
 odd, $p\geq 3$ & two eigenvalues of $A_n$ that are terms of $\sigma$ & $4p-2$\\
 $p=1$ & two eigenvalues of $A_n$ not in $\sigma$ & 4\\
 even & one eigenvalue of $A_n$ that is in $\sigma$ & $2p-1$\\
 \hline
\end{tabular}
\end{center}
For each case, the numbers of terms in $\mu$ (i.e., $l$) and in $\tau$ have the opposite parity from the number of terms in $\sigma$, as required. The rule cannot be applied if $A_n$ has fewer than 3 eigenvalues (the $p=1$ case is not possible then), i.e., if $n<6$.

This implies that $G_d$ in sufficiently large dimensions contains both the sums of even and odd numbers of eigenvalues of $A$, so it is equal to $\mathbb{F}_{2^k}-\{0\}$.  Hence we have shown, for the case where $n$ is even, that the cycle length reaches the maximum value $2^{\mathrm{sord}_2(n+1)}-1$, except when $n<6$.
When $n=2$ or $4$ the
cycle length alternates in even and odd dimensions. 
For $n=2$ it alternates between $2\leftrightarrow 1$ and for $n=4$ it alternates between $6\leftrightarrow 2$.  (One can find the eigenvalues for these cases and deduce the orders using the identities $\alpha^2+\alpha+1=0$ for a cube root of 1 and $\beta^4+\beta^3+\beta^2+\beta+1=0$ for a fifth root of 1.) 
%The eigenvalue for $n=2$ is $\alpha+\alpha^{-1}$ where $\alpha^3=1$.  This implies $\alpha^2+\alpha+1$, or $\alpha+\alpha^{-1}=1$.
%For $n=4$, consider the field containing a fifth root of unity $\beta$.  One can check that $\beta+\beta^{-1}$ and $\beta^2+\beta^{-2}$ have periods of 3 by using $\beta^4+\beta^3+\beta^2+\beta+1=0$ so the cycle length in an odd number of dimensions is 6. And the sum of these two eigenvalues is 1 so the cycle length is 2 in an even number of dimensions.)



\begin{comment}
The $d$-dimensional Lights Out automaton is the sum of $d$ copies of $A$, say $B_d$.
As in the proof of Theorem \ref{thm:eig_lcm_equal},
let $G_d$ be the smallest subgroup under multiplication of $\mathbb{F}$ containing the nonzero eigenvalues of $B_d$.
Then the largest odd factor of the cycle length of $B_d$ is the order of $G_d$.

%If $\mathbb{F}'$ is the smallest field containing the eigenvalues of $B_d$, $G_d$ is a subgroup under multiplication of $\mathbb{F}'$, so the largest possible order is $2^k-1$ if $\mathbb{F}'$ has $2^k$ elements. As shown in \cite{wolfram}, $k=\mathrm{sord}_2(r)$, so this upper bound of the cycle length can be found just by calculating powers of 2, without solving any complicated equations in the field.

Consider the set of sums of arbitrary combinations of eigenvalues of $A$. This set
is actually the whole field $\mathbb{F}'$.  This is because it is a field:
it is closed under multiplication because the product of two eigenvalues is equal to the sum of two other eigenvalues. So it is closed under taking inverses (since each element has a finite order, its inverse is a positive power of it). Since $\mathbb{F}'$ is the smallest field containing the eigenvalues, it is the same field.

$B_d$'s eigenvalues are sums of $d$ eigenvalues of $A$.
If $d$ is at least the number of eigenvalues of $A$ and if one of $A$'s eigenvalues is zero, then all sums of eigenvalues appear in $B_d$'s eigenvalues.  Zero is an eigenvalue when $n$ is odd. So if $n$ is odd, and $d$ is large enough ($d\geq \frac r2$ is sufficient), then $B_d$'s eigenvalues include all of $\mathbb{F}'$'s elements. Hence
the cycle length is $2^{j+1}(2^{\mathrm{sord}_2(r)}-1)$.

This shows that the period is eventually the largest possible period $2^{\mathrm{sord}_2(r)}-1$ when $n$ is odd, and in general 
\begin{thm}
\label{thm:high_d_CL}
If $n+1=2^jr$ where $r$ is odd,
then the cycle length is $2^{\mathrm{sord}_2(r)}-1$ when
the number of dimensions is large enough, unless $n+1$ is a power of 2 or $n=2$ or $4$.
\end{thm}
\begin{proof}
This can be proven by showing that $G_d$ is the cyclic group of $\mathbb{F}'$. When $n$ is odd zero is one of the eigenvalues, so the eigenvalues of $B_d$ give the whole field without multiplication.
When $n$ is even (so $j=0$ and $r=n+1$), 0 is not one of the eigenvalues so it might not be possible to represent every sum of eigenvalues as a sum of a specific number of eigenvalues, $d$. If $x$ can be written as a sum of $l$ eigenvalues then it can also be written as a sum of $l'$ eigenvalues if $l'-l$ is a positive even number, because adding other eigenvalues two times each will not change the sum. So if $S_e$ is the set of sums of even numbers of eigenvalues and $S_o$ is the set of sums of odd numbers of eigenvalues, then $B_d$'s eigenvalues are the set $S_e$ when $d$ is even and $\geq\frac r2$, and are $S_o$ when $d$ is odd.
If $S_e$ and $S_o$ overlap at all, an element of the field can be written both as a sum of an even and or an odd number of eigenvalues, which implies any sum of eigenvalues can be written in two ways, one even and one odd. If $S_e$ and $S_o$ don't overlap, they have the same size (because adding a single eigenvalue to each element of $S_e$ gives all elements of $S_o$), so each has $2^{k-1}$ elements.
What is the size $m$ of the group $\mathbb{G}_d$?  It contains either all elements of $S_o$ or all elements of $S_e$ (aside from 0). So $m\geq 2^{k-1}-1$ and $m|2^k-1$ since it is contained in the cyclic group of $\mathbb{F}'$. Either $m=2^k-1$ or else $m\leq (2^k-1)/3$ (since $2^k-1$ is odd so the largest possible divisor is 1/3 of it). This is only possible if $k=1$ or 2.
The only $r$ such that $sord_2(r)=1$ or 2 are $r=3$ and 5 respectively (i.e., n=2 or 4). When $r=1$ the only eigenvalue is $\alpha+\alpha^{-1}$ where $\alpha^3=1$. But this implies $\alpha^2+\alpha+1=0$ or $\alpha+\alpha^{-1}=1$. Thus
$S_e=\{0\}$ and $S_o=\{1\}$, so the cycle length is 2 in an odd number of dimensions while in an even number of dimensions the lights eventually go off. When $r=5$, the field to work in is generated by a fifth root $\alpha$.  Hence $\alpha^4+\alpha^3+\alpha^2+\alpha+1=0$.
The eigenvalues are $\beta=\alpha+\alpha^{-1}$ and $\alpha^2+\alpha^{-2}$ (which is $\beta^2$). The equation for $\alpha$ can be written in terms of $\beta$, $\beta^2+\beta+1=0$, which defines $\mathbb{F}_4$, so this is $\mathbb{F}'$. $S_e=\{0,\beta+\beta^2\}=\{0,1\}$ and $S_o=\{\beta,\beta^2\}$, so the order of the eigenvalues is 1 or 3 if $d$ is even or odd respectively, which means that the cycle length alternates between $2$ and $6$.
\end{proof}
\end{comment}
%\par $2^{sord(r)}-1$ is a surprising upper bound for the cycle length because it is smaller than $2^n$(the number of combinations of states in one dimension). This result is related to the automaton having translational symmetry, as the eigenfunctions can be written as $\alpha^j$. 
% maybe instead of r/2 dimensions, you could just use 3 dimensions or something small for all cases, since adding elements of a field together can change their period in a random way.
% If you use a cellular automaton which isn't translationally invariant and add it to itself $d$ times, could the cycle length increase as $2^{n^d}$? (It cannot happen forever since all the eigenvalues are still in one field, but I think it could increase for several dimensions because the field can be bigger.)




%The size $2^k$ can be found as follows: If $x$ is an element of this field, then $x^{2^k}=x$; hence $(\alpha+\alpha^{-1})^{2^k}=\alpha+\alpha^{-1}$; i.e., $\alpha'+\alpha'^{-1}=\alpha+\alpha$ where $\alpha'=\alpha^{2^k}$.
%This equation can be reduced to
%$(\alpha-\alpha')(1-\alpha^{-1}\alpha'{-1})=0$, so $\alpha'=\alpha$ or $\alpha'=\alpha^{-1}$. Since $\alpha$ has order $r$, this implies $2^k\equiv \pm 1\ \mod r$. As 2 is raised to larger and larger powers, eventually one of the powers must equal 1 or -1; the first power that is $\pm 1 \mod r$ is called $\mathrm{sord}_2(r)$. Afterward the sequence of powers keeps repeating (apart from the sign) so
%$sord_2(r)|k$. They must actually be equal--$sord_2(r)$ cannot be smaller than 2 for the following reason: Every eigenvalue $x=\alpha^j+\alpha^{-j}$ satisfies $x^{2^{sord_2(r)}}=x$.
%The set of $x$'s with this property forms a field, and it must be the whole field $\mathbb{F}'$ because $\mathbb{F}'$ is the smallest field containing all the eigenvalues. But it is not possible for $2^k$ elements
%to all satisfy an equation of degree $2^{sord_2(r)}$ if $k> sord_2(r)$.


% outline--
% size of group generated by multiplication of nonzero eigenvalues in d dimensions is the least common multiple of odd cycle lengths
% (should discuss this more in section 2.4)

% proof that sums of any size set of eigenvalues of T form the full set of elements of a field
 
% if n is odd, and $n+1=2^j r$ where r is odd, then in (r-1)/2 or more dimensions the set of eigenvalues is the full field, so the group generated by them is $\mathbb{G}$, hence the cycle length is $2^(j+1)$ times the order of $\mathbb{G}$.

% if n is even, then in $n/2$ or more dimensions, the set of eigenvalues might be half the set of elements of the field--a different set depending on whether the dimension is even or odd. But under multiplication half the elements of a field generate all of $\mathbb{G}$ (except in $\mathbb{F}_2$ or $\mathbb{F}_4$). So in this case
% the cycle length is also $2|\mathbb{G}|$.

% For Lights Out automata with $n=2$ or $n=4$, the cycle length is different in even and odd dimensions. For $n=2$, the cycle length is 2 in odd dimensions and it is 1 in even dimensions (all the lights go off after 2 steps).
% For $n=4$ the cycle length is 6 in odd dimensions and 2 in even dimensions.




% \section{Applications}
% \par Our analysis of the evolution of $\Phi$ automata has implications for other 1-dimensional automata, as it can be shown that under a certain initial condition, there exists a class of 1-dimensional automata whose evolution is identical. To describe the evolution of 1-dimensional automata, we use the B/S notation where the number following B is the number of adjacent cells required for a dead cell to be born, and the number following S is the number of adjacent cells required for a living cell to survive. 
% \begin{thm}
% When the initial seed is asymmetric and the number of dead cells between any two living cells is odd, the $B1/S, \ B1/S1, \ B1/S2,$ and $B1/S\{1, 2\}$ cellular automata produce the same configuration at every timestamp. 
% \end{thm}
% \par This means that if we restrict the initial conditions of a $\Phi$ automaton, then its evolution would be equivalent to several other 1-dimensional automata. Thus their cycle-lengths would be equal, and we could generalize our relationships between $\Phi$ automata and $\sigma$ automata to this class of 1-dimensional automata.
% \subsection{Solvability of $\sigma$ automata}
% \par Within the field of $\sigma$ automata, one of the primary topics probed is the solvability of automata. A $\sigma$ automaton $\boldsymbol{g_0}$ can be considered solvable if there exists some $\boldsymbol{v}$ such that $\boldsymbol{g_0} = \boldsymbol{v}(T + I)$. Intuitively, given some configuration of Lights Out, it would be solvable if we could press some sequence of lights to turn every light off. This problem is analogous to pressing a sequence of lights on a blank configuration to create the original configuration, so we can reduce it to a matrix problem. By determining exactly which automata are solvable are which are not, we can tell whether or not a Lights Out game is solvable simply by looking at the configuration. 

% \par For this application, we will observe the evolution of a $\sigma$ automaton where the rule of evolution is given by $M = T + I$. If we consider the sequence (generated by $\boldsymbol{g_0}$) of $\sigma$ automata $\boldsymbol{g_0}, \boldsymbol{g_1}, \boldsymbol{g_2}, \dots, \boldsymbol{g_i}$, we notice that in general, the cycle does not begin at $\boldsymbol{g_0}$. Since $M$ has Jordan blocks with eigenvalue $0$ when $T$ has blocks with eigenvalue $1$, those Jordan blocks must annihilate before the cycle can begin. However, if $\boldsymbol{g_0} = \boldsymbol{h}M^k$, then the cycle of the sequence will begin sooner than expected. This is true because the $0$ Jordan blocks of $M$ will annihilate sooner than normal, as evolving $\boldsymbol{g_0}$ once is equivalent to evolving $\boldsymbol{h}$ $k + 1$ times. So if we were to compute the entire configuration sequence generated by $\boldsymbol{g_0}$, and we noticed that the cycle began earlier than expected, we could surmise that $\boldsymbol{g_0} = \boldsymbol{h}M^k$, and thus $\boldsymbol{g_0}$ is a solvable $\sigma$ automaton. On the other hand, if the cycle began at the exact point we expected, then we know that $\boldsymbol{g_0}$ is an unsolvable $\sigma$ automaton. We can easily determine when the cycle should begin for an $n \times n$ $\sigma$ automaton by looking at the $nth$ binary Chebyshev polynomial and determining the algebraic multiplicity of $1$ (this can easily be done using the recursions mentioned in this paper). Thus if we are only given a configuration sequence of $\sigma$ automata, we can determine exactly which automata are solvable and which are not.

\section{Conclusion}
\par In this paper, we considered the relationship between the cycle-lengths of one-dimensional $\Phi$ automata and two-dimensional $\sigma$ automata. We found that the cycle-length of a $1 \times n$ $\Phi$ automaton equals that of an $n \times n$ $\sigma$ automaton. The proof involved finding the Jordan form of the transition matrices of the automata; we also provided geometrical arguments to help understand why the cycle-lengths are identical.
An additional result we discussed along the way is a general formula to determine the size of the largest Jordan block of the Kronecker sum of any two Jordan blocks over a field of characteristic 2.  Such a formula could prove useful in the analysis of other two dimensional automata that are Kronecker sums of two one-dimensional automata. 

\par A natural question arising from these results is how the cycle-lengths of higher-dimensional automata depend on the automaton dimension.
 As an automaton's dimension grows, the number of sites within the automaton increases. Thus it is surprising that the one and two dimensional automata have a similar cycle length, let alone exactly the same cycle length. This is related to the linearity of the automata, which makes the dynamics less chaotic.
 In fact, in Ref. \cite{wolfram}, Martin et al. showed that for any linear, periodic, and translationally symmetric automaton, the cycle-length can never be greater than $2^n$ (where $n$ is the ``length'' of the automaton). This bounds the cycle-lengths of high-dimensional automata even though the number of sites grows with the automaton dimension. We showed that for the $\Phi$ automaton in particular, as the dimension increases, the cycle-length eventually saturates at the specific bound given by Martin et al.,  $2^{\mathrm{sord}_2(n + 1)} - 1$, when $n$ is even (despite not explicitly possessing translation symmetry)\footnote{Although the $\Phi$ automaton does not posses periodic boundary conditions, using the reflection principle it can be mapped to a model with translation symmetry}. 
 
 
 %Thus it would be surprising if the cycle-lengths of cellular automata do not grow arbitrarily large as the dimension increases. However in \cite{wolfram}, Martin et al. showed that for a periodic and translationally symmetric linear automaton, the cycle-length can never be greater than $2^n$ (where $n$ is the ``length'' of the automaton). This bounds the cycle-lengths of high-dimensional $\Phi$ automata even though the number of sites increases with the automaton dimension. We showed that as the dimension of the $\Phi$ automaton grows, the cycle-length eventually saturates at the specific bound given by Martin et al.,  $2^{\mathrm{sord}_2(n + 1)} - 1$, when $n$ is even (despite not explicitly possessing translation symmetry) \footnote{Although the $\Phi$ automaton does not posses periodic boundary conditions, using the reflection principle it can be mapped to a model with translation symmetry}. 
 
 It would be fascinating to observe how the cycle-length changes as a function of dimension for other automata that are less special than the $\Phi$ automaton.
In particular, it would be interesting to consider automata to which Martin et al.'s result does not apply:
models without periodic boundary conditions. If one defines the $d$ dimensional version of such an automaton by taking the Kronecker sum of $d$ copies, the cycle-length will still be bounded\footnote{Taking the Kronecker sum of transition matrices does not alter the working field, so the least common multiple of the orders of the eigenvalues remains finite.}; however, the particular bound could be much larger than that of translationally-symmetric automata. If an automaton without periodic boundary conditions is added to itself $d$ times, could the cycle length increase as $2^{n^d}$ (as one might naively expect), for the first few dimensions $d$?

\par Another potential extension that could prove interesting is changing the modulus used to define the automaton. In Lights Out, each light can be in one of two states, and the evolution rule is defined by adding the states of neighbors modulo 2. If each light can be in one of $r$ possible states, the transition rule can be defined using modulo $r$ arithmetic. With a modulus of $r > 2$, would the cycle-lengths of one-dimensional $\Phi$ automata and two-dimensional $\sigma$ automata still be equal? How would the cycle-lengths differ for prime $r$ compared to composite $r$? 

% \par In this paper, we considered the deterministic evolution of one-dimensional $\Phi$ automata and two-dimensional $\sigma$ automata. We found the Jordan form of the transition matrices of the automata, and using both geometric and algebraic arguments, we proved that the cycle-length of a $1 \times n$ $\Phi$ automaton equals that of an $n \times n$ $\sigma$ automaton. 

% An additional (and tangential) result also developed a general formula to determine the size of the largest Jordan block of the Kronecker sum of any two matrices (modulo $2$). 

% \par We additionally considered higher dimensional $\sigma$ automata, and we found that the cycle-length of high-dimensional automata is bounded (even though the number of sites increases with dimension).

% One might try exploring a cellular automaton whose boundaries are not equivalent to mirrors (unlike the $\sigma$ automaton). If such an automaton is added to itself $d$ times, could the cycle length increase as $2^{n^d}$? This is in contrast to the result of \cite{wolfram} discussed in Sec. \ref{sec:phi_fields}, which implies that for a periodic and translationally symmetric automaton, the cycle length can never be greater than $2^n$. Evidently the cycle length cannot increase indefinitely since all the eigenvalues remain in the same field; however, the periods might grow according to this form for several dimensions.



% \footnote{The number of dimensions for which it keeps increasing in this way would depend on $n$, since the field containing the eigenvalues is larger when $n$ is larger.  The cycle length could keep growing as $2^{n^d}$ until $d\sim\frac{n}{\log_2 n}$: This is when $2^{n^d}$ is equal to $2^{2^n}$, and one can argue that the smallest field containing the eigenvalues of an $n\times n$-matrix can have at most $\sim 2^{2^n}$ elements.?????}



% An additional idea to consider is whether or not one can choose a local rule of evolution and set of boundary conditions for a 2-D automaton such that the cycle-length of an $n \times n$ automaton is on the order of $2^{n^2}$. It is not obvious that solely changing the boundary conditions for a $\sigma$ automaton could accomplish this, so 

\appendix
\section{Cycle lengths of configurations and cycle lengths of automata\label{cyclelength_state}}
\begin{comment}For an automaton represented by a matrix $X$,
there is always some configuration whose cycle length is a multiple of all other configurations' cycle lengths.
The Jordan normal form does not help to find the configuration whose cycle length is maximal, because finding a Jordan normal form involves changing the basis in a way that uses elements of a larger field, $\mathbb{F}$, and then it is more difficult to tell which states correspond to states which originally had coordinates of just 0s and 1s. A canonical form using just the field of 0's and 1's is the rational canonical form, see \cite{Herstein} Chapter 6 or \cite{vanderWaerden} vol. 2 Sec. 111.\end{comment}
The cycle length of an automaton is the lcm of the cycle-lengths of all configurations. Is it possible to find a configuration with a cycle-length equal to this maximum cycle-length? Consider the Jordan normal form of the transition matrix. If there is just one Jordan block, the vector $(1,0,0,\dots,0)^T$ can be shown to have a cycle length that is equal to the cycle length of the matrix itself.  If there are several Jordan blocks, take a vector that has a 1 in the first coordinate of every set of coordinates corresponding to a Jordan block. The cycle length for this vector is the least common multiple of the cycle lengths of the separate blocks, because each block evolves independently of the others. However, this does not necessarily give the configuration of the automaton that we are looking for, since the original coordinates of this vector, after transforming back from the Jordan form, are in $\mathbb{F}$ instead of $\mathbb{Z}_2$.  

A different canonical form uses just the original field consisting of $0,1$: the ``rational canonical form" (see \cite{Herstein} Chapter 6 or \cite{vanderWaerden} vol. 2 Sec. 111). Any matrix can be written in the form $X=PMP^{-1}$ where $P,M$ have entries in the same field as $X$, and $M$ has the form of a matrix of blocks where the blocks are companion matrices\footnote{Companion matrices are zero except one step below the diagonal and in the last column.  One step below the diagonal all the entries are equal to 1, and the last column can have arbitrary entries in the same field as $X$.} instead of Jordan blocks. 

For a companion matrix $C$, the cycle length of $e_1=(1,0,0,\dots,0)^T$ is always equal to the cycle length of the matrix, and thus the lcm of all configurations.  The reason is that the unit vectors $e_j$ can all be expressed as iterates of $e_1$, so their cycle lengths are divisors of $e_1$'s cycle length.  Furthermore, any other vector is a linear combination of the $e_j$'s, so its cycle length is also a divisor of $e_1$'s cycle length. 

Suppose $M$ is comprised of blocks of companion matrices and
let $\textbf{v}$ have a 1 in the positions corresponding to the first rows of blocks of $M$ and 0's in other positions. Then each block evolves independently, so the cycle length of $\textbf{v}$ is the lcm of the cycle lengths of each part of it corresponding to a block. This implies that its cycle length is the same as the cycle length of $M$. Thus we are able to construct a state with the same cycle-length as the automaton.

\section{Proof of Lemma \ref{lma:double}\label{app:doublelemma}}
The lemma follows from a self-similarity property of the $\Phi$ evolution for an infinite pattern.  Consider two initial states where one has the same pattern as the other but with the distances doubled. Let the first be $f_1(j)$, and let the second be related to the first by $f_2(2j)=f_1(j);f_2(2j+1)=0$.  Then the $2k^\mathrm{th}$ iterate of $f_2$ is the same as the $k^\mathrm{th}$ iterate of $f_1$ except transformed in the same way. First, check this for $k=1$: the first iterate of $f_2$ is given by $g(2j)=0$, $g(2j+1)=f_2(2j)+f_2(2j+2)=f_1(j)+f_1(j+1)$.  So the second iterate is given by $h(2j)=[f_1(j)+f_1(j+1)]+[f_1(j-1)+f_1(j)]=f_1(j+1)+f_1(j-1)$, $h(2j+1)=0$.  By induction it follows that the $2k^\mathrm{th}$ iterate of $f_2$ is the doubled version of the $k^\mathrm{th}$ iterate of $f_1$.

Now consider the cycle lengths of $\bar\Phi_n$ and $\bar\Phi_{2n}$.  Lemma \ref{lma:greenfunctionperiodic} shows that these are the cycle lengths for the configurations on the $1\times n$ and $1\times 2n$ boards, respectively, where one light is on at first.  To use the doubling property, represent the two automata as periodic patterns of an infinite sequence of lights.  One light being on in $\bar\Phi_{2n}$ corresponds to turning on all the lights at multiples of $2n$ in the infinite board.  If one follows the evolution of this configuration, but closes one's eyes during the odd iterates, then the arrangements of lights for the other board, i.e. the iterates of the initial state will all multiples of $n$ are on, except doubled.  Thus, the pattern will repeat after $CL(\bar\Phi_n)$ steps, but this actually means that it will repeat after $2CL(\bar\Phi_n)$ steps when we count the steps where one's eyes were closed.

However, it is possible that the pattern repeated before the $2CL(\bar\Phi_n)^\mathrm{th}$ step, after an odd number of steps when one's eyes were closed. This cannot happen though.  Initially, only lights at even coordinates are on, so at odd steps lights with odd coordinates are on and at even steps lights with even coordinates are on.  So the pattern cannot be the same for iterates that are separated by an odd number of steps, \emph{unless} all the lights are off at both iterates. 

Now we can also rule this out 
using the assumption in the lemma that $n$ is not a power of 2. We will show that in this case there will always be some lights on.   
The first state has lights at multiples of $n$.  Consider what happens after $2^k$ steps for some $k$. The pattern is the sum modulo 2 of the patterns that any one of the initial lights would evolve into after $2^k$ steps.
The light at zero, after $2^k$ steps, would cause just the lights at $\pm 2^k$ to be on.  This can be shown using the doubling property above to
reduce $2^k$ iterates to $2^{k-1}$ iterates, then to $2^{k-2}$ iterates, etc.
Similarly, the light at $rn$ causes the lights at $rn\pm2^k$ to be on.  When these patterns are added together modulo 2, there are no cancellations because a light cannot be $2^k$ to the right of some multiple of $n$ and $2^k$ to the left of another multiple of $n$, since
  $2^{k+1}$ is not divisible by $n$. Thus no matter how large $k$ is, there are always lights on after $2^k$ steps. This implies that there must be lights on after any number of steps.




\bibliographystyle{apalike}
\bibliography{references}

% \begin{thebibliography}{9}

% \bibitem{kart}
% A. Karttunen, On Pascal's Triangle Modulo 2 In Fibonacci Representation (2002).
% \bibitem{lindenmayer}
% A. Lindenmayer, Mathematical models for cellular interactions in development, \textit{Journal of Theoretical Biology} 18 (1968) 280-299.

% \bibitem{torrence}
% B. Torrence The Easiest Lights Out Games, The College Mathematics Journal (2011), 42:5, 361-372, DOI: 10.4169/college.math.j.42.5.361

% \bibitem{norman}
% C. W. Norman (1995) On the jordan form of the tensor product over fields of prime characteristic, \textit{Linear and Multilinear Algebra}, 38:4, 351-371

% \bibitem{griffiths}
% D. Griffiths, ``The Finite Square Well." Introduction to Quantum Mechanics, D. Schroeter, 3rd edition, Cambridge University Press, 2018, 93-99.

% \bibitem{hoffman}
% K. Hoffman and R. Kunze, “Linear Algebra,” 2nd Edition, Prentice Hall Inc., Upper Saddle River, 1971.

% \bibitem{schacke}
% K. Schäcke, On the Kronecker Product (2004).

% \bibitem{sutner}
% K. Sutner, $\sigma$-Automata and Chebyshev-polynomials, \textit{Theoretical Computer Science} 230 (2000) 49-73.

% \bibitem{elyze}
% M. Elyze, A. Guterman, R. Morrison, K. Šivic (2020) Higher-distance commuting varieties, \textit{Linear and Multilinear Algebra}.

% \bibitem{fine}
% N.J. Fine, Binomial coefficients modulo a prime, Am. Math. Monthly, 54 (1947), 589-592.

% % \bibitem{oeis}
% % OEIS Foundation Inc. (2021), The On-Line Encyclopedia of Integer Sequences, http://oeis.org/A268754

% \bibitem{pascal}
% OEIS Foundation Inc. (2021), The On-Line Encyclopedia of Integer Sequences, https://oeis.org/wiki/Sierpi\%C5\%84ski\%27s\_triangle
% \bibitem{sarkBar}
% P. Sarkar, R. Barua, Multidimensional $\sigma$-automata, $\pi$-polynomials, and generalised $S$-matrices, \textit{Theoretical Computer Science} 197 (1998) 111-138.

% \bibitem{barRam}
% R. Barua, S. Ramakrishnan, $\sigma$-game, $\sigma^+$-game and two-dimensional additive cellular automata, \textit{Theoretical Computer Science} 154 (1996) 349-366.

% \bibitem{kubelka}
% R. Kubelka, Self-Similarity and Symmetries of Pascal's Triangle and Simplicies Mod $p$ (2001). 

% \bibitem{images}
% H. C. Card, A. Thanailakis, W. Pries and R.D. McLeod, Analysis of Bounded Linear Cellular Automata Based on a Method of Image Charges, \textit{Journal of Computer and System Sciences} 33, 473-480 (1986).

% \bibitem{characteristicPolynomialRule150} N. Pitsianis, Ph. Tsalides, G.L. Bleris, A. Thanailakis, and H.C. Card,
% Deterministic One-Dimensional Cellular Automata, \textit{Journal of Statistical Physics} (1989).

% \bibitem{characteristicPolynomialRule90}
% Diana M. Thomas, John G. Stevens, and Steven Letteri, Characteristic and Minimal Polynomials of Linear Cellular Automata, \textit{The Rocky Mountain Journal of Mathematics} 36, pg. 1077-1092 (2006).

% \bibitem{Periodsin2D} Yasuo Kawahara, Satoru Kumamoto, Yoshihiro Mizoguchi, Masaya Nohmi, Hiroshi Ohtsuka, Takayoshi Shoudai, Period Lengths of Cellular Automata on Square Lattices with Rule 90, \textit{Journal of Mathematical Physics}36 , pg. 1435-1456 (1995).




% \bibitem{Voorhees}Burton Voorhees, Nearest Neighbor Cellular Automata with Periodic Boundary Conditions, \textit{Physica D}45, 26-35 (1990).

% \bibitem{BoyleKitchens} Mike Boyle and Bruce Kitchens, Periodic Points for Onto Cellular Automata, Indagationes Matehmaticae, 10 pg. 483-493 (1999)







% \end{thebibliography}
\end{document}