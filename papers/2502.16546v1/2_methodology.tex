
\section{Study Methodology}
\label{sec:methodology}

This study aims to investigate how the issue resolution process is implemented in practice at Mozilla Firefox to solve various software problems and tasks described in issue reports.  We investigate the major stages of the issue resolution process, described in \Cref{sub:background_issue_res}, and how developers\footnote{We hereon use \textit{developers} to refer to all stakeholders involved in issue resolution: programmers, reporters, QA members, \etc}  follow them to solve a variety of problem categories (\eg crashes, UI issues, or refactoring changes) reported in various issue report types (defects, enhancements, or tasks). 
The study addresses the following research questions (RQs):
\looseness=-1

\begin{enumerate}[label=\textbf{RQ$_\arabic*$:}, ref=\textbf{RQ$_\arabic*$}, itemindent=0cm,leftmargin=1cm]
	\item \label{rq:stages}{\textit{What issue resolution stages are found in issue reports?}} 
	\item \label{rq:interactions}{\textit{How do the resolution stages interact with each other?}}
	\item \label{rq:process}{\textit{What is the overall process of issue resolution?}}
	\item \label{rq:patterns}{\textit{What resolution patterns are found in issue reports?}}
	\item \label{rq:pattern_usefulness}{\rev{\textit{What are the potential use cases of the patterns?}} }
\end{enumerate}

\ref{rq:stages} investigates the major stages that Mozilla developers go through to address reported issues and how frequently these stages are discussed in issue reports. \ref{rq:interactions} investigates how these stages interact with one another, including how frequently these stages co-occur in issue reports. \ref{rq:process} investigates the overall issue resolution process at Mozilla Firefox.  \ref{rq:patterns} investigates recurrent instances of the resolution process, expressed as sequences of stages. \rev{\ref{rq:pattern_usefulness} examines the potential applications of the derived patterns for Mozilla developers.}
\looseness=-1



\subsection{Issue Collection}
\label{sub:issue_collection}



Mozilla's BMO is the centralized system for managing the issues of Firefox desktop and mobile~\cite{mozilla-products}. In this study, we focused on the desktop version of Mozilla Firefox, studying the issues of its two main components: \textit{Firefox} and \textit{Core}.  The \textit{Firefox} component (\aka \textit{product} in BMO) implements the graphical user interface (GUI) of the web browser, while the \textit{Core} component includes essential functionality such as web page rendering, web browsing, and networking services. 


Our study focused on \textit{FIXED} and \textit{RESOLVED} issue reports
for the selected components. To obtain recent issues within a significant period of system evolution, we downloaded all the issues created from January 1st, 2010 to April 30th, 2023 using Bugzilla's API~\cite{bugzilla-api}, including their title/summary, comments (which contain the issue description), and relevant metadata: creation time, resolution time, and others.
\rev{From 199,271 downloaded issues ($\approx$164.7k/34.5k for Core/Firefox), we randomly sampled 384 issues for analysis. This is a statistically significant sample, at a 95\% confidence level and 5\% error margin, that captures the diversity and characteristics of the entire population of \textit{Core} and \textit{Firefox} issues. This is evidenced by comparing our sample and the entire issue population in terms of the proportion of issue types (defects: 71.1\% vs 70.1\%, enhancements: 16.9\% vs 16.1\%, and tasks: 12\% vs 13.5\%), the proportion of issues per product (Core: 81.5\% vs 82.7\% and Firefox: 18.5\% vs 17.3\%), average \# of comments per issue (13.4 vs 14.6), and average resolution time (81 vs 88 days). 
	} 
The 384 issues contain 13.4 (9) comments, 30.27 (16) paragraphs, and 56.73 (25) sentences on average (median). 
\looseness=-1













\subsection{Issue Annotation}
\label{sub:issue_annotation}





\subsubsection{\textbf{Goals and Overview}}
\rev{
We qualitatively analyzed all the information provided in the issues, annotating textual content related to issue resolution by employing an iterative \textit{open coding} methodology~\cite{spencer2009card}. The annotation process was conducted by six Ph.D. students and one professor (\aka \textit{annotators}), including the authors of this paper.  The annotators have 1-9 years of research experience (particularly in qualitative text analysis), and five of them have 1-4 years of industry experience.}
\looseness=-1






\rev{The annotation targeted all the textual content written by different stakeholders in issue comments and aimed to identify: (1) \textit{themes} or \textit{codes} about different activities performed to resolve the issue 
(\eg reproduction attempts or a code review), and (2) the types of problems described in the issues (\eg crashes, UI issues, \etc), which we call \textbf{problem categories}.}


\rev{\subsubsection{\textbf{Annotation Tool and Unit}} We used the Hypothesis annotation tool~\cite{hypothesis} to directly annotate the web pages of the issue reports. The tool allowed us to collaboratively assign \textit{codes} to text snippets in the issue threads, modify the assigned codes, and discuss the annotations.

We coded \textit{text snippets} in the issue comments. The minimal annotation unit was a complete sentence. Since one or more sentences may convey the same type of
information (\ie a given resolution activity), the annotation included individual sentences, multiple sentences, paragraphs, or even entire comments. A single textual snippet was allowed to be coded with one or more codes.

\subsubsection{\textbf{Code Catalog and Coding Guidelines}}
We maintained a  \textit{code catalog} via a  Google spreadsheet shared among the annotators. The catalog included a list of codes,  code descriptions, rules to apply the codes, and text snippets from annotated issues used as examples. The code catalog also included a list of problem categories, with detailed definitions and examples of annotated issues. We also maintained a shared Google document with detailed guidelines of the annotation procedure, coding rules, and necessary resources for annotating the issues (\eg official Mozilla documentation to get familiar with Firefox's resolution process and a glossary of annotation terminology). Both the catalog and  guidelines were built from scratch and developed by all the annotators incrementally and collaboratively.}
\looseness=-1



\rev{\subsubsection{\textbf{Annotation Procedure}} 
We adopted an iterative multi-coder open-coding methodology wherein each issue report was annotated and validated by at least two annotators.  The 384 issues were distributed evenly among the seven annotators, who iteratively examined, annotated, and validated the issue comments in batches of 30-50 issues.  
The first annotator assigned codes to text snippets in the comments, and a second annotator reviewed these annotations for accuracy and completeness. Discrepancies were resolved in reconciliation sessions. Annotator roles alternated across batches, with each person either annotating from scratch or reviewing the annotations by the first annotator. To avoid fatigue and reduce potential mistakes, the annotators annotated small sets of issues with breaks in between.
\looseness=-1

The overall process for a single issue involved the first annotator thoroughly reviewing the issue, including attached patches, linked commits, and metadata (\eg\ issue commentators, tags, and status), to identify/annotate relevant content and the problem category. Codes were assigned based on the content's meaning and the code catalog. The second annotator then reviewed these annotations, verifying their accuracy, suggesting additional codes, or flagging mistakes. After processing a batch, both annotators discussed disagreements to reach a consensus.

To establish the initial coding framework, two researchers annotated the first batch of 30 issues, creating an initial set of codes and problem categories. These were refined through discussion sessions, resulting in complete definitions, examples, and rules for applying the codes. This initial annotation informed the creation of the coding guidelines, which included resources for understanding issues and general annotation rules.

Before annotating the remaining issues, training sessions were conducted with the other annotators to review the coding guidelines, discuss examples from the initial batch, and solve misunderstandings. Throughout the entire annotation process, the code catalog was continuously updated, with changes such as new codes, code merges, or renames collectively agreed upon and promptly communicated. When the catalog was updated, previously coded issues were revisited to ensure consistency. Regular communication via Zoom meetings and Slack discussions was essential to maintain the accuracy and uniformity of the catalog and annotated content.

}


















\rev{\subsubsection{\textbf{Annotation Results and Inter-coder Agreement}} During the annotation process, 28 issues, that were pull requests (PR) automatically created by the issue tracker, were discarded.
In summary, we annotated \textbf{3,707 textual snippets} in 2,574 issue comments across 356 issue reports. The annotation process resulted in 
\textbf{22 issue resolution codes}, and \textbf{17 problem categories} which we further grouped into \textbf{3 problem classes}. \Cref{tab:stages,tab:problem_categories} show examples of these elements;
our replication package contains the full catalog of codes and problems~\cite{repl_pack}. 

The annotators agreed on 3,438 annotations with an agreement rate of $\approx$93\% and a Cohen's kappa of 0.92, which indicates a high overall agreement~\cite{Cohen}. Common
sources of disagreement (269/3,707 text snippets) included misunderstandings due to ambiguous comments or unclear code definitions. If both annotators were unable to reach an agreement, a third annotator reviewed the issue to resolve the conflict. 
\looseness=-1
}













  















\subsection{Inferring and Analyzing Issue Resolution Stages}
\label{sub:resolution_stages}




The 22 codes obtained from the issue report annotation represent the information about activities performed by developers during issue resolution.
We implemented two steps for inferring the issue resolution stages from the annotation codes. In the first step, we qualitatively analyzed the code catalog and annotated issues and identified 13 codes (\ie actionable codes) that signified specific actions performed to directly address the problems (\eg reproducing the problem or implementing a solution as a code change). In the second step, we engaged in an analysis of issues/codes and a discussion to categorize the 13 codes for inferring \textit{issue resolution stages}. 
\looseness=-1

\begin{table}[t]
\caption{Issue Resolution Stages}

\label{tab:stages}
\resizebox{\columnwidth}{!}{%
\begin{tabular}{c|c|c|c}
\hline
\textbf{Stage}                & \textbf{Description}                                                                                                                                             & \textbf{Annotation Codes}                                                                                        & \textbf{\# of Issues} \\ \hline
\textbf{\ir (\texttt{\textbf{R}})}      & \begin{tabular}[c]{@{}c@{}}Developers attempt to\\ reproduce the issue.\end{tabular}                                                                             & \sc{REP\_ATT}                                                                                                        & 47 (13.2\%)        \\ \hline
\textbf{\ia (\texttt{\textbf{A}})}          & \begin{tabular}[c]{@{}c@{}}Developers analyze the issue\\ by reviewing the problem,\\ identifying the problem cause,\\ or locating the relevant code.
	\\
 \end{tabular}   & \begin{tabular}[c]{@{}c@{}}\sc{PROB\_LOC},\\ \sc{PROB\_REV},\\ \sc{CAUS\_IDENT}\end{tabular}                               & 134 (37.6\%)       \\ \hline
\textbf{\sd (\texttt{\textbf{SD}})} & \begin{tabular}[c]{@{}c@{}}Developers discuss how to\\solve the issue, \ie propose\\a potential solution or\\review a proposed solution.\end{tabular} & \begin{tabular}[c]{@{}c@{}}\sc{POT\_SOL\_DES},\\ \sc{SOL\_REV}\end{tabular}                                                & 150 (42.1\%)       \\ \hline
\textbf{\impl (\texttt{\textbf{I}})}    & \begin{tabular}[c]{@{}c@{}}Developers make the\\ necessary code changes\\ to resolve the issue.\end{tabular}                                           & \sc{CODE\_IMPL}                                                                                                       & 328 (92.1\%)       \\ \hline
\textbf{\crv (\texttt{\textbf{CR}})}     & \begin{tabular}[c]{@{}c@{}}Developers review the\\ implemented code changes.\end{tabular}                                                                                & \sc{CODE\_REV}                                                                                                        & 264 (74.2\%)       \\ \hline
\textbf{\ver (\texttt{\textbf{V}})}      & \begin{tabular}[c]{@{}c@{}}Developers verify the\\solution by testing the\\ implemented code changes.\end{tabular}                                           & \begin{tabular}[c]{@{}c@{}}\sc{SOL\_VER},\\ \sc{UPLIFT\_APRV},\\ \sc{IMPL\_REV},\\ \sc{COL\_PROB\_ANA},\\ \sc{COL\_POT\_SOL}\end{tabular} & 146 (41\%)         \\ \hline
\end{tabular}%
}
\end{table}


\begin{table}[]
\caption{Problem Categories and Classes}
\label{tab:problem_categories}
\resizebox{\columnwidth}{!}{%
\begin{tabular}{c|c|c|c}
\hline
\textbf{Problem Class}  & \textbf{Problem Categories (Examples)}        & \textbf{\# of Categ.} & \textbf{\# of Issues} \\ \hline
{Implementation} & UI Issue, Feature Development, Crash       & 12                 & 261                \\ \hline
{Refactoring}    & Code Improvement, Unnecessary Code Removal & 2                  & 51                 \\ \hline
{Testing}        & Test Failure, Test Update, Flaky Tests     & 3                  & 44                 \\ \hline
\end{tabular}%
}
\end{table}


The first step was necessary because 9 of the 22 codes were either: (1) requests to perform an action, not an action in itself; or (2) cross-cutting actions, which can be performed at any stage of the resolution process. {\sc{solution\_review\_request}} \rev{is an example of a request}, which represents a petition, made by a developer to another one, to review a proposed solution to the problem. 
{\sc{solved\_by\_other\_issue}} is an example of a cross-cutting code that represents an issue resolved in another issue. 
\looseness=-1

Based on the qualitative analysis, we identified six different issue resolution stages, namely:
\ir (\texttt{\textbf{R}}), \ia (\texttt{\textbf{A}}), \sd (\texttt{\textbf{SD}}), \impl(\texttt{\textbf{I}}), \crv (\texttt{\textbf{CR}}), and \ver (\texttt{\textbf{V}}). Each stage is represented by one to five actionable codes, each code belonging to a single stage. Examples of codes for the \ia stage (\texttt{\textbf{A}}) are {\sc{problem\_localization}} and 
{\sc{cause\_identification}}.
\Cref{tab:stages} shows all the stages with their description and codes.

To answer \ref{rq:stages}, we analyze the frequency in which the six stages appear in the issue reports, across different report types and problem classes and categories.

\subsection{Analysis of Stages Sequences and Process Inference}
\label{sub:process}

When the identified stages are aggregated in the order in which codes appear in the issue report (\ie chronologically), they create a sequence of codes, which we can then examine to understand the process adopted to resolve the issue. For example, issue \#1363344's~\cite{firefox-bug} annotation code sequence is: 
{\sc{code\_implementation}},  {\sc{code\_review}},  {\sc{code\_review}}, {\sc{code\_review}}. We created a stage sequence by utilizing the code sequence and the code-stage mapping for each issue. 
For example, for the above code sequence of issue \#1363344~\cite{firefox-bug}, the derived stage sequence is: \texttt{\textbf{I,CR,CR,CR}} which we simplified as \texttt{\textbf{I,CR}} by merging consecutive repeating stages. This process was applied to all the issues.

To answer \ref{rq:interactions}, we counted the bi-grams and tri-grams appearing in the stage sequences, as well as the number of issues where these n-grams appear. Bi-grams are pairs of consecutive stages, while tri-grams are triplets of consecutive stages in the sequences. We also analyzed the frequency with which the stages appear at the beginning or end of the sequences.
\looseness=-1

To answer \ref{rq:process}, we constructed a graph representing the overall issue resolution process, where the nodes correspond to the stages and the edges represent the transitions between stages. This graph was constructed based on the most frequent bi-grams found in the sequences and serves to validate the patterns of issue resolution we derive as part of \ref{rq:patterns} (see \Cref{sub:resolution_patterns}). 
\looseness=-1


\subsection{Inferring Issue Resolution Patterns}
\label{sub:resolution_patterns}
To answer \ref{rq:patterns}, we engaged in a qualitative analysis of the stage sequences and derived issue resolution patterns by grouping similar stage sequences into coarse-grained sequences. The derived patterns correspond to instances of the derived issue resolution process in \ref{rq:process}.

\subsubsection{\textbf{Pattern Notations}} To communicate the issue resolution patterns clearly and analyze them in different dimensions, we represent the patterns as a string based on  three  notations: 
\begin{itemize}
    \item \textbf{A?}  indicates that stage A is optional;
    \item \textbf{(A$\mid$B)} indicates that either A or B or both stages appear; 
    \item \textbf{(A,B,...,Z)+} indicates that stages A, B, ..., and Z appear more than once, and at least one subsequence of two or more stages (A,B or B,Z or A,B,Z, \etc) appears more than once.
    \looseness=-1
\end{itemize}




\subsubsection{\textbf{Deriving Issue Resolution Patterns}} At first, we identified the stage sequences where the 3rd notation, (A,B,...,Z)+, is applicable and created issue resolution patterns for those stage sequences applying the notation. For example, issue \#991812~\cite{firefox-bug-991812} with the stage sequence \texttt{\textbf{I,CR,I,CR,I,CR,V,I,V}} has \texttt{\textbf{I}}, \texttt{\textbf{CR}}, and \texttt{\textbf{V}} appearing more than once and the sub-sequence \texttt{\textbf{I,CR}} appears more than once. Hence, the sequence can be collapsed to create the issue resolution pattern \texttt{\textbf{(I,CR,V)+}}. With this notation, the order of the stages does not matter.

Second, we created groups of stage sequences that differ only by one or two stages in order and qualitatively analyzed each sequence to understand the differences among the sequences. We aimed to represent the sequences using the first two notations (\ie A? and (A$\mid$B)) to form a coarse-grained sequence. For example, issues \#698552~\cite{firefox-bug-698552}, \#676248~\cite{firefox-bug-676248}, and \#730907~\cite{firefox-bug-730907} have the stage sequences ``\texttt{\textbf{SD,I,CR}}", ``\texttt{\textbf{SD,I,CR,I}}'', and ``\texttt{\textbf{SD,I,CR,V}}", respectively. Here, all three stages, \sds, \impls, and \crvs, are included in the three issues. However, the sequences only differ by the last stage: \impls or \vers is present for the last two issues while it is not present in the first one. Hence, we can create a common pattern for these three issues, \ie\ \texttt{\textbf{SD,I,CR,(I$\mid$V)?}} which will represent all three sequences.

\rev{We meticulously created this grouping} by considering several factors (\eg the \# of issues per sequence, the presence of unique stages per sequence, and the issue resolution process of each issue in the group) so that we would not lose information or create any misleading sequence that does not represent the actual resolution process. For example, we could create a group for the sequences \texttt{\textbf{I}} and \texttt{\textbf{I,CR}} by making \texttt{\textbf{CR}} as an optional stage (\ie  \texttt{\textbf{I,CR?}}). However, the first sequence is found for 21 issues and the second sequence is found for 50 issues which implies these two sequences are already widely used and can represent two distinct ways of issue resolution. In the first sequence, no \texttt{\textbf{CR}} is performed, whereas in the second, it is performed to resolve the issue. Hence, we did not create a group from these two sequences.
\looseness=-1

In all qualitative steps, one researcher qualitatively analyzed the issue and made necessary changes by documenting the rationale behind each change which was reviewed and validated by the second researcher. Both researchers continuously discussed the patterns and solved any disagreements.













\rev{\subsubsection{\textbf{Pattern Derivation Results and Pattern Categorization}} Our analysis resulted in 47 distinct issue resolution patterns -- the  10 most frequent patterns are shown in \Cref{tab:patterns}. The patterns contain 1-6 stages and appear in 1-64 issues (7.6 issues on average). 
The more unique stages and the more interacting stages a pattern has, the more complicated a pattern is. We argue that the complexity of a pattern reflects the effort developers invest in resolving an issue, which can be quantified by the number of stages in the sequences associated with the pattern. Therefore,  we categorized the patterns as \textit{simple} or \textit{complex} based on the average number of stages in their sequences. Since the distribution of these averages is not skewed (see our replication package for the distribution~\cite{repl_pack}), the mean serves as a threshold for classification. Specifically, the process involves calculating the average number of stages ($P_a$) for each pattern, determining the overall mean across the patterns ($T=6.2$ stages), and classifying a pattern as complex if $P_a > T$ or simple if $P_a \leq T$. In \Cref{sub:results_patterns}, we discuss the pattern catalog and compare it with the derived process from \ref{rq:process} to answer \ref{rq:patterns}.}
\looseness=-1

\rev{
\subsection{Investigating Potential Use Cases of the Derived Patterns}

To answer \ref{rq:pattern_usefulness}, we conducted semi-structured interviews with two Mozilla developers, aimed to gather detailed feedback from them on the usefulness of the resolution patterns. The interviews were conducted over Zoom for 60 minutes and were structured into four sections: 

\begin{enumerate}
	\item \underline{Participant's Background}: Participants were asked to share their background and experience in software development and issue resolution at Mozilla and other companies.
	
	\item \underline{Mozilla's Issue Resolution Process}: Participants were asked to describe Mozilla's issue resolution process (both prescribed by Mozilla and implemented by developers) as well as the specific approaches they follow.
	
	\item \underline{Research Presentation}: The research team presented the study's goals, methodology, and findings, including the identified patterns. Participants were encouraged to ask questions about the patterns and findings.
	
	\item \underline{Question-Answering}: Participants were asked 11 questions that prompted for feedback on the identified patterns, with a focus on understanding their potential benefits for Mozilla.
\end{enumerate}

Follow-up questions were asked when additional information was needed. The interview questionnaire, protocol, and anonymized responses are found in our replication package~\cite{repl_pack}.

\subsubsection{\textbf{Finding Participants}} Our target population consisted of Mozilla stakeholders with experience in issue resolution.
To identify potential participants, we explored the developers' profiles from Mozilla Research's website~\cite{mozilla_research}, LinkedIn, Mozilla's issue tracker, Mozilla’s Forums~\cite{mozilla_forums}, and Matrix~\cite{mozilla_matrix}.
We created a shortlist of 42 potential participants, all of whom were invited to participate via email.


\subsubsection{\textbf{Participants' Background}} 
Two developers responded to our call and participated in the interview (\ie referred to as D1 and D2). They are current Mozilla developers with 7 to 11 years of experience at the company.
They have extensive issue resolution experience, having resolved around 1.4K issues and contributed to approximately 19K issues in total. %


\subsubsection{\textbf{Response Analysis}} We recorded and transcribed the interviews using Zoom to facilitate response analysis. We corrected inaccuracies in the transcripts, \eg\ misspellings, incorrect phrases, and punctuation. 
Using the revised transcripts, one author analyzed and grouped the participants’ answers to each question into themes representing use cases of the patterns. A second author reviewed the answers and themes for accuracy. Misinterpretations were resolved through discussion.
\looseness=-1
}


