\section{Introduction}\label{sec:intro}
A phoneme can be phonetically realized differently depending on its environment, a phenomenon known as \textit{allophony} in phonology \citep{twaddell1952phonemes, ladefoged1965nature, collins2019phoneme}. 
For instance, the English phoneme /\textipa{t}/ exhibits various allophonic realizations: [\textipa{t\textsuperscript{h}}] (aspirated stop) in \textit{tap}, [\textipa{t}] (unaspirated stop) in \textit{stop}, [\textipa{\textfishhookr}] (flap) in \textit{butter}, and [\textipa{P}] (glottal stop) in \textit{kitten}.
Accurately capturing these variations is crucial, as it reflects the full spectrum of phonetic realizations within a phoneme.
It is particularly important for atypical pronunciation assessment \citep{twaddell1952phonemes, jokisch2009multilingual, vidal2019epadb}, as it has to distinguish atypical (out-of-distribution; OOD) from atypical (in-distribution) pronunciations \citep{yeo23_interspeech}.


Before the era of deep neural networks (DNNs), allophones were modeled for speech recognition \citep{sagayama1989phoneme,lee1990allophone,young1994tree}.
However, DNN-based approaches \citep{hu2015improved, yeo23_interspeech} depend on phoneme classifiers that treat speech segments from a single phoneme as a single cluster, avoiding the complexity of modeling allophones.
This is partly due to DNN's strong classification capabilities, which rely on trained hidden features to model individual phonemes well.

\input{figures/motivation_img}


In recent years, self-supervised speech models (S3Ms) have shifted the landscape of acoustic modeling.
Unlike DNNs, S3Ms leverage their frozen features directly, without requiring additional training \citep{feng2023superb,chang2024exploring}.
Their effectiveness motivates us to revisit modeling allophones via Gaussian Mixture Models (GMMs) \citep{bilmes1998gentle,young1994tree}.
Consequently, we propose MixGoP, a GMM-based approach that models each phoneme as a set of allophonic subclusters (see \Cref{fig:summary}). 
By integrating GMMs with S3M features, we aim to directly capture the allophonic variations. 
We evaluate MixGoP with S3Ms in atypical pronunciation assessment with dysarthric and non-native speech. 


Furthermore, we analyze the S3M features on how well they capture allophonic variation compared to Mel-frequency cepstral coefficients (MFCCs) and Mel spectrograms.
While previous work has shown that S3Ms encode phonetic \citep{pasad2021layer, wells22_interspeech, abdullah2023information, choi2024self} and phonemic information \citep{martin23_interspeech, choi2024understanding}, a detailed investigation of how they capture allophony remains underexplored.

In summary, the contributions of our study are:
\begin{itemize}
    \item MixGoP, a novel pronunciation-assessment approach that considers allophonic variation.
    \item Achieving state-of-the-art performance in four out of five dysarthric and nonnative datasets.
    \item Analysis of the utility of S3M features on MixGoP for capturing allophonic variations.
\end{itemize}
