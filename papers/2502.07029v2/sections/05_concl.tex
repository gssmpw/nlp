\section{Conclusion}
We demonstrated that improved modeling of allophony can enhance performance in OOD detection for the assessment of atypical speech, and that leveraging S3M features can further improve this performance. 
Specifically, our novel approach, MixGoP, addresses the limitations of uni-modality and in-distribution assumptions by employing Gaussian mixtures, which effectively model allophones and eliminate the need for softmax probabilities. 
Additionally, we show that utilizing S3M features further enhances OOD detection performance. 
Our results also confirm that S3M features capture allophonic variation more effectively than traditional features, validating the extension of our approach to include S3Ms. 
We evaluated eight methods across five dysarthric and nonnative speech datasets, with MixGoP achieving state-of-the-art performance on four of the datasets.


Our work provides a deeper understanding of how S3M representations can be hierarchically structured, from allophones to phonemes.
Further, it sheds new light on the acoustic modeling perspective of speech, expanding the existing k-means-based speech discretization.
It shows the possibility of using atypical speech as a benchmark to measure the quality of S3M features, especially regarding OOD robustness.

\section*{Limitations}
% While we believe our contributions provide substantial value to the research community, we acknowledge several important limitations that must be considered. 
First, a key limitation is the restricted generalizability of our findings across languages. Although we aim for our work to benefit a wide range of atypical speakers, including both dysarthric and non-native speakers, our research primarily focuses on English (four English datasets and one Tamil dataset). This limitation stems from the availability of publicly accessible datasets, but we recognize the need for broader cross-linguistic research in future work to ensure that our findings are applicable across diverse languages.

Additionally, we employed different methods for forced alignment across datasets, as outlined in \Cref{subsec:dataset-details}.
Time alignments were either provided by the dataset or automatically generated using the Montreal Forced Aligner \citep{mcauliffe2017montreal}. 
However, we did not verify the quality of these alignments in our study. 
This introduces the possibility that variations in alignment quality could have impacted the GoP scores, potentially affecting the overall results.
While we do not primarily focus on comparing performance across datasets, future work could benefit from verifying alignment quality to ensure more reliable GoP scores, and cross-dataset comparisons.

We also acknowledge that our allophony analysis was primarily based on the TORGO dataset, which provided time alignments that were manually annotated by linguists. 
Extending this analysis to other datasets with similarly verified time alignments would further support the generalizability of our findings.

Finally, the method used to calculate utterance-level (\Cref{eq:1_n}) pronunciation scores can be improved. 
In our current approach, we simply averaged phoneme probabilities across each utterance; however, it is well-known that certain phonemes have a greater impact on overall pronunciation scores. 
While our initial analysis, as presented in \Cref{subsec:attn},  provides a preliminary exploration of this issue, further investigation is needed to identify more robust approaches.
Expanding upon this analysis could lead to improved techniques that more accurately evaluate atypical speech.




\section*{Ethics Statement}
The risk of atypical pronunciation assessment research primarily pertains to data handling and the potential for unintended consequences in use.


Firstly, while we used publicly available datasets that have undergone prior ethical review, it is important to recognize that these datasets still contain sensitive information, particularly speakers’ voices. 
Since no additional anonymization processes were applied in this study, we strongly recommend that any replication of this work prioritize the protection of participants’ rights and privacy to the greatest extent possible.

Secondly, concerns arise regarding the potential usage of atypical speech assessment scores. 
These assessments may unintentionally reinforce negative stereotypes or stigmas associated with speech disorders or non-native accents. 
If the results are interpreted as evaluations of an individual’s language ability or intelligence, they could further marginalize dysarthric or non-native speakers.
Also, there is a risk in placing too much emphasis on `correctness' in phoneme-level pronunciation assessment. 
Focusing heavily on accurate phoneme production prescribes a rigid, normative standard of speech, potentially penalizing linguistic diversity and variation. 
For both dysarthric and non-native speakers, such an emphasis might overshadow more functional measures of communication success, which may be more meaningful in real-world contexts.
Despite these concerns, which warrant careful consideration, we want to emphasize that our work is intended to have a significant positive impact from an ethical perspective.


Finally, we note that ChatGPT was employed for grammatical refinement and to improve the clarity of English usage in the manuscript.
We also state that every sentence generated by ChatGPT was reviewed by the authors.

% Furthermore, our work is based primarily on datasets centered on English (four English, one Tamil). 
% Caution should be exercised when interpreting the results, and undue extrapolation to other languages should be avoided. 

% \ifinterspeechfinal
% \section{Acknowledgements}
% Experiments of this work used the Bridges2 system at PSC and Delta system at NCSA through allocations CIS210014 and IRI120008P from the Advanced Cyberinfrastructure Coordination Ecosystem: Services \& Support (ACCESS) program, supported by National Science Foundation grants \#2138259, \#2138286, \#2138307, \#2137603, and \#2138296.
% \fi