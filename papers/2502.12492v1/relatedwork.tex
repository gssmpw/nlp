\section{Related Work}
\subsection{System 2 Methods in LLMs}
Recent research on large language models for System 2 tasks focus on inference-time computation optimization to stimulate the inherent reasoning ability of LLMs. Few-shot learning methods \cite{wang2022code4struct,madaan2022language} utilize the in-context-learning ability of LLMs for enhanced generation. Retrieval-augmented generation (RAG) approaches \cite{nashid2023retrieval,du2024codegragbridginggapnatural} further introduce domain knowledge into LLMs. 
Techniques such as Chain-of-Thought (CoT) \cite{yang2024chain,jiang2024self,li2023structured}, Tree-of-Thought (ToT) \cite{yao2024tree,la2024can}, and Monte Carlo Tree Search (MCTS) \cite{li2024rethinkmcts,zhang2023planning,hu2024uncertainty,hao2023reasoning,feng2024alphazeroliketreesearchguidelarge} are used to explore the inherent reasoning process, often based on the self-play mechanism to reflect on previously generated contents to learn from itself \cite{haluptzok2022language,chen2023gaining,lu2023self,chen2023teaching,madaan2024self,shinn2024reflexion}.
During inference, error position can be beneficial in improving the reliability and performance of the model. With identification and analysis of where and why errors occur, recent research \cite{yao2024mulberry, luo2024improve, wu2025error} has made significant strides in quantifying and mitigating errors during model inference. Refinement \cite{madaan2024self, gou2023critic} and reflexion \cite{shinn2024reflexion, lee2025evolving} are also powerful techniques for enhancing the inference capabilities of LLMs, usually by enabling iterative improvement and self-correction.

\subsection{Model Composition}
Model composition technique gains notable attention in cross-tasks generalization. 
Traditional methods for multiple tasks are to train models on a mixture of datasets of different skills \cite{caruana1997multitask, chen2018gradnorm}, with the high cost of data mixing and lack of scalability of the model though. Model merging is a possible solution to this. Linear merging is a classic merging method that consists of simply averaging the model weights \cite{izmailov2018averaging, smith2017investigation}. Furthermore, Task Arithmetic \cite{ilharco2022editing} computes task vectors for each model, merges them linearly, and then adds back to the base, and SLERP \cite{white2016sampling} spherically interpolates the parameters of two models. Based on Task Arithmetic framework, TIES \cite{yadav2024ties} specifies the task vectors and applies a sign consensus algorithm to resolve interference between models, and DARE \cite{yu2024language} matches the performance of original models by random pruning.

Recently, LoRA merging methods are also widely applied to cross-task generalization. CAT \cite{prabhakar2024lora} introduces learnable linear concatenation of the LoRA layers, and Mixture of Experts(MoE) \cite{buehler2024x, feng2024mixture} method has input-dependent merging coefficients. Other linear merging methods of LoRAs, such as LoRA Hub \cite{huang2023lorahub}, involve additional cross-terms compared to simple concatenation. %\whj{这句没看懂}