%%%%%%%% ICML 2024 EXAMPLE LATEX SUBMISSION FILE %%%%%%%%%%%%%%%%%

\documentclass{article}
\usepackage[T1]{fontenc}
% Recommended, but optional, packages for figures and better typesetting:
\usepackage{microtype}
\usepackage{graphicx}
\usepackage{subfigure}
\usepackage{booktabs} % for professional tables

% hyperref makes hyperlinks in the resulting PDF.
% If your build breaks (sometimes temporarily if a hyperlink spans a page)
% please comment out the following usepackage line and replace
% \usepackage{icml2024} with \usepackage[nohyperref]{icml2024} above.
\usepackage{hyperref}


% Attempt to make hyperref and algorithmic work together better:
\newcommand{\theHalgorithm}{\arabic{algorithm}}

% Use the following line for the initial blind version submitted for review:
% \usepackage{icml2024}

% If accepted, instead use the following line for the camera-ready submission:
\usepackage[accepted]{icml2024}

% For theorems and such
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{mathtools}
\usepackage{amsthm}
\usepackage{enumitem}
\usepackage{bbm}
\usepackage[export]{adjustbox}

% if you use cleveref..
\usepackage[capitalize,noabbrev]{cleveref}
\usepackage{braket}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% THEOREMS
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\theoremstyle{plain}
\newtheorem{theorem}{Theorem}[section]
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{corollary}[theorem]{Corollary}
\theoremstyle{definition}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{assumption}[theorem]{Assumption}
\theoremstyle{remark}
\newtheorem{remark}[theorem]{Remark}

% Todonotes is useful during development; simply uncomment the next line
%    and comment out the line below the next line to turn off comments
%\usepackage[disable,textsize=tiny]{todonotes}
\usepackage[textsize=tiny]{todonotes}


% The \icmltitle you define below is probably too long as a header.
% Therefore, a short form for the running title is supplied here:
\icmltitlerunning{Variational Optimization by Continuous Bandits}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% OUR COMMANDS
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newcommand{\cale}{{\mathcal E}}
\newcommand{\E}{{\mathbb E}}
\newcommand{\F}{{\mathcal F}}
\newcommand{\D}{{\mathcal D}}
\newcommand{\U}{{\mathcal U}}
\newcommand{\N}{{\mathcal N}}
\newcommand{\G}{{\mathcal G}}
\newcommand{\X}{{\mathcal X}}
\newcommand{\Y}{{\mathcal Y}}
\newcommand{\A}{{\mathcal A}}
\newcommand{\B}{{\mathcal B}}
\newcommand{\I}{{\mathcal I}}
\newcommand{\J}{{\mathcal J}}
\newcommand{\HH}{{\mathcal H}}
\newcommand{\T}{{\mathcal T}}

\newcommand{\Leb}{{\mathcal L}}
\newcommand{\ENT}{{\rm ENT}}
\newcommand{\Var}{{\mathbb V}{\rm ar}}
\newcommand{\Cov}{{\mathbb C}{\rm ov}}
\newcommand{\RR}{{\mathbb R}}
\newcommand{\CC}{{\mathbb C}}
\newcommand{\Q}{{\mathbb Q}}
\newcommand{\SG}{{\mathbb S}}
\newcommand{\Z}{{\mathbf Z}}
\newcommand{\W}{{\mathbf W}}
\newcommand{\K}{{\mathbf K}}

\newcommand{\tX}{\tilde{X}}
\newcommand{\hX}{\hat{X}}
\newcommand{\tU}{\tilde{U}}
\newcommand{\hU}{\hat{U}}
\newcommand{\tY}{\tilde{Y}}
\newcommand{\hY}{\hat{Y}}
\newcommand{\tV}{\tilde{V}}
\newcommand{\hV}{\hat{V}}
\newcommand{\tx}{\tilde{x}}
\newcommand{\hx}{\hat{x}}
\newcommand{\ty}{\tilde{y}}
\newcommand{\hy}{\hat{y}}
\newcommand{\tu}{\tilde{u}}
\newcommand{\hu}{\hat{u}}
\newcommand{\tv}{\tilde{v}}
\newcommand{\hv}{\hat{v}}

\newcommand{\uu}{{\mathbf u}}
\newcommand{\ww}{{\mathbf w}}
\newcommand{\kk}{{\mathbf k}}
\newcommand{\xx}{{\mathbf x}}
\newcommand{\ee}{{\mathbf e}}

\newcommand{\one}{\mathbf{1}}
\newcommand{\zero}{\mathbf{0}}
\newcommand{\iy}{\infty}
\newcommand{\ep}{\epsilon}
\newcommand{\bx}{\bm{x}}
\newcommand{\bX}{\bm{X}}
\newcommand{\bZ}{\bm{Z}}
\newcommand{\bs}{\bm{s}}
\newcommand{\bv}{\bm{v}}
\newcommand{\bu}{\bm{u}}
\newcommand{\bbeta}{\bm{\beta}}
\newcommand{\hbeta}{\hat{\bm{\beta}}}
\newcommand{\by}{\bm{y}}
\newcommand{\br}{\bm{r}}
\newcommand{\be}{\bm{e}}
\newcommand{\sign}{\textrm{sign}}
\newcommand{\bg}{\bm{g}}
\newcommand{\ba}{\bm{a}}
\newcommand{\bb}{\bm{b}}
\newcommand{\bW}{\bm{W}}
\newcommand{\ra}{\rightarrow}
\newcommand{\tr}{\mathrm{Tr}}

\newcommand{\tcU}{\tilde{\mathcal{U}}}
\newcommand{\tcX}{\tilde{\mathcal{X}}}
\newcommand{\hcU}{\hat{\mathcal{U}}}
\newcommand{\hcX}{\hat{\mathcal{X}}}
\newcommand{\Pro}{{\mathbb P}}
\newcommand{\vol}{{\mathcal V}}
\newcommand{\area}{{\mathcal A}}
\newcommand{\rad}{{\mathcal R}}
\newcommand{\Aut}{{\bf Aut}}
\newcommand{\dist}{{\bf dist}}
\newcommand{\taum}{\tau_{{\rm mix}}}
\newcommand{\tauh}{\wh{\tau}}
\newcommand{\dtv}{\|\Pro(X_t \in \cdot)-\pi\|_{TV}}
\newcommand{\dtwo}{\|\Pro(X_t \in \cdot)-\pi\|_2}
\newcommand{\n}{\|}
\newcommand{\bi}{\begin{itemize}}
\newcommand{\ei}{\end{itemize}}
\newcommand{\Ra}{\Rightarrow}
\newcommand{\si}{\sigma}
\newcommand{\sgn}{{\operatorname{sgn}}}
\newcommand{\supp}{{\operatorname{supp}}}
\newcommand{\lan}{\langle}
\newcommand{\ran}{\rangle}
\newcommand{\ov}{\overline}
\newcommand{\un}{\bigcup}
\newcommand{\sn}{\bigcap}
\newcommand{\wh}{\widehat}
\newcommand{\beq}{\begin{equation}}
\newcommand{\eeq}{\end{equation}}
\newcommand{\beqa}{\begin{eqnarray*}}
\newcommand{\eeqa}{\end{eqnarray*}}
\newcommand{\btm}{\begin{theorem}}
\newcommand{\etm}{\end{theorem}}
\newcommand{\bpf}{\begin{proof}}
\newcommand{\epf}{\end{proof}}
\newcommand{\bla}{\begin{lemma}}
\newcommand{\ela}{\end{lemma}}
\newcommand{\bdn}{\begin{definition}}
\newcommand{\edn}{\end{definition}}
\newcommand{\bpn}{\begin{proposition}}
\newcommand{\epn}{\end{proposition}}
\newcommand{\bcy}{\begin{corollary}}
\newcommand{\ecy}{\end{corollary}}
\newcommand{\kl}{\mathrm{kl}}

\newcommand{\MW}[1]{\textcolor{blue}{[MW: #1]}}

\def\ldotsplus{\mathinner{\ldotp\ldotp\ldotp\ldotp}}
\def\fourdots{\relax\ifmmode\ldotsplus\else$\m@th \ldotsplus\,$\fi}
\def\bigo{{\rm O}}
\def\id{{\rm id}}
\def\sfrac#1#2{{\textstyle{#1 \over #2}}}
\def\half{{\textstyle{1\over2}}}
\def\zt{{\widetilde Z}}
\def\lhh{{\widetilde l}}
\def\lh{{L}}
\def\wt{{\widetilde W}}
\def\kp {{K_p}}
\def \one {{\mathbf 1}}
\def \e {{\mathbf E}}
\def \ehat {{\mathbf {\widehat E}}}
\def\var{{\rm  \bf Var}}
\def\varhat{{\rm  \bf {\widehat Var}}}
\def\p {{ \mathbf P}}
\def\phat {{ \mathbf     { \widehat P}} }
\def\P {{ \mathbf P}}
\def\given {{\,|\,}}
\def \r {{\bf R}}

\DeclareMathOperator*{\esssup}{ess\,sup}
\begin{document}

\twocolumn[
% working title
\icmltitle{Variational Quantum Optimization with Continuous Bandits}

% It is OKAY to include author information, even for blind
% submissions: the style file will automatically remove it for you
% unless you've provided the [accepted] option to the icml2024
% package.

% List of affiliations: The first argument should be a (short)
% identifier you will use later to specify author affiliations
% Academic affiliations should list Department, University, City, Region, Country
% Industry affiliations should list Company, City, Region, Country

% You can specify symbols, otherwise they are numbered in order.
% Ideally, you should not use this facility. Affiliations will be numbered
% in order of appearance and this is the preferred way.
\icmlsetsymbol{equal}{*}

\begin{icmlauthorlist}
\icmlauthor{Marc Wanner}{equal,dsai}
\icmlauthor{Johan Jonasson}{equal,math}
\icmlauthor{Emil Carlsson}{dsai,comp}
\icmlauthor{Devdatt Dubhashi}{dsai}
\end{icmlauthorlist}

\icmlaffiliation{dsai}{Department of Data Science and AI, Chalmers University of Technology and University of Gothenburg, Gothenburg, Sweden}
\icmlaffiliation{comp}{Sleep Cycle AB, Gothenburg, Sweden}
\icmlaffiliation{math}{Department of Mathematics, Chalmers University of Technology and University of Gothenburg, Gothenburg, Sweden}

\icmlcorrespondingauthor{Marc Wanner}{wanner@chalmers.se}
%\icmlcorrespondingauthor{Firstname2 Lastname2}{first2.last2@www.uk}

% You may provide any keywords that you
% find helpful for describing your paper; these are used to populate
% the "keywords" metadata in the PDF but will not be shown in the document
\icmlkeywords{Machine Learning, ICML}

\vskip 0.3in
]

% this must go after the closing bracket ] following \twocolumn[ ...

% This command actually creates the footnote in the first column
% listing the affiliations and the copyright notice.
% The command takes one argument, which is text to display at the start of the footnote.
% The \icmlEqualContribution command is standard text for equal contribution.
% Remove it (just {}) if you do not need this facility.

%\printAffiliationsAndNotice{}  % leave blank if no need to mention equal contribution
\printAffiliationsAndNotice{\icmlEqualContribution} % otherwise use the standard text.

% TODO: adapt to focus on quantum computing applications
\begin{abstract}
We introduce a novel approach to variational Quantum algorithms (VQA) via continuous bandits. VQA are a class of hybrid Quantum-classical algorithms where the parameters of Quantum circuits are optimized by classical algorithms. Previous work has used zero and first order gradient based methods, however such algorithms suffer from the barren plateau (BP) problem where gradients and loss differences are exponentially small. We introduce an approach using bandits methods which combine global exploration with local exploitation. We show how VQA can be formulated as a best arm identification problem in a continuous space of arms with Lipschitz smoothness. While regret minimization has been addressed in this setting, existing methods for pure exploration only cover discrete spaces. We give the first results for pure exploration in a continuous setting and derive a fixed-confidence, information-theoretic, instance specific lower bound. Under certain assumptions on the expected payoff, we derive a simple algorithm, which is near-optimal with respect to our lower bound. Finally, we apply our continuous bandit algorithm to two VQA schemes: a PQC and a QAOA quantum circuit, showing that we significantly outperform the previously known state of the art methods (which used gradient based methods).
%mpresent numerical experiments that validate our theoretical bounds and provide a comparison of our algorithm's performance with that of other existing algorithms.
%This document provides a basic paper template and submission guidelines.
%Abstracts must be a single paragraph, ideally between 4--6 sentences long.
%Gross violations will trigger corrections at the camera-ready phase.
\end{abstract}

\section{Introduction}

In recent years, \emph{variational quantum computing} has gathered momentum as a promising approach for quantum computers~\cite{Abb24,Cerezo2021}, namely a \emph{hybrid} classical-quantum framework which involves a quantum circuit with gates parameterized by continuous real variables see Figure~\ref{fig:vqc}. Potential application areas range from Quantum chemistry~\cite{Cao2019}, drug discovery~\cite{Blunt2022} and material science~\cite{Lordi2021} to Finance~\cite{Herman2023}, supply chain management and manufacturing~\cite{refId0}, where the Quantum circuit is used as an accelerator for specific domain-dependent problems. The circuit is specified by giving a set of real valued parameters which are tuned iteratively to optimal values by observing the circuit output using classical optimization algorithms. This approach has become popular in part to its flexibility, opening up applications in diverse areas in basic science and machine learning, and also because of the hope that it is more robust to the constraints of near-term quantum hardware in the NISQ (Noisy Intermediate Scale Quantum) era.

\begin{figure}
    \centering
    \includegraphics[width=0.8\linewidth]{sketch_variational.png}
    \caption{Illustration of VQA inspired by~\citet{La24}}
    \label{fig:vqc}
\end{figure}

However, a big challenge for variational algorithms is that gradient based zero or first-order methods, such as COBYLA~\cite{Powell1994}, become stuck because of the landscape of the optimization problem with increasing problem size: gradients or even loss differences become exponentially small which makes it difficult to identify local descent directions as the system size increases - exponentially many samples are provably necessary to identify descent directions. This is called the \emph{barren plateau} (BP) phenomenon in Quantum computing~\cite{La24} and affects various VAQ, such as the Quantum Alternate Operator Ansatz~\cite{hadfield2019from, Fontana2024}. While significant effort has been dedicated to gradient based methods  and trying to construct VQAs avoiding barren plateaus (see~\Cref{sec:related_work}), addressing the barren plateau problem with other classical optimization techniques has received little attention.

Here we introduce a novel approach to address the BP problem which is theoretically well grounded and also easy to implement in practice. We argue that the optimization problem is very well suited to bandit methods which combine global exploration and local exploitation. The optimal setting of the circuit parameters can be regarded as an optimization problem in a continuous bandit. 

Black box optimization of noisy cost functions is a widely studied area with many applications \cite{bouneffouf2019surveypracticalapplicationsmultiarmed,Cerezo2021,maghsudi2016multi}. One approach to this problem is via \emph{bandit} algorithms, see ~\cite{lattimore2020bandit} for a textbook treatment.
%inspired by the so called one-armed bandits, a type of slot machine, which can be found in Casinos. In each round, a gambler pulls the arm of the machine and obtains a random reward. If there are several such machines, one may wonder with what strategy one can identify the machine, which gives the highest reward in average, while playing as few rounds as possible.\\
In this work, we consider the best arm identification problem in bandits ~\cite{audibert:hal-00654404}. Formally, the typical problem setup consists of a set of distributions with means $\{\mu_a\}_{a=1}^A$, where each of them corresponds to an ``arm'' $a$. An agent is then tasked to identify the parameter, or ``arm'' $a^*$, which maximizes  with a given confidence by drawing a minimal amount of samples from the distributions.

For finite set of arms, this problem is well understood and can be solved optimally by e.g. \emph{Track-and-Stop}~\cite{pmlr-v49-garivier16a} or game theoretic exploration schemes~\cite{NEURIPS2019_8d1de745}. Further extensions provide optimal sampling strategies in settings where the arms reveal contextual information~\cite{wang2021fast} or are subject to linear constraints~\cite{pmlr-v238-carlsson24a}. A common strategy is to derive an information theoretic upper bound on the expected number of rounds needed to complete the task. This bound then gives rise to a sampling strategy, which corresponding, matching algorithms aim to estimate and replicate. An important property of these algorithms is their optimality with respect to the specific problem instance, which fundamentally differs from worst case optimality.\\

We consider the extension of the problem to the \emph{continuous} setting, where the set of arms corresponds to the unit interval $[0,1]$: thus there are uncountably many arms, each corresponding to a point in the unit interval: for every $x \in [0,1]$, we have a distribution with mean $\mu(x)$. We assume the function $\mu: [0,1] \rightarrow \mathbb{R}$, to be Lipschitz. Furthermore, the noise of the drawn samples is assumed to be sub-Gaussian. The task of the agent is to identify an arm $x$, which is $\epsilon$ close to the optimal arm $x^*$ with high probability. The classical optimization problem in variational quantum algorithms corresponds exactly to this best arm identification problem in continuous bandit setting.

Continuous bandit optimization been addressed in previous work and algorithms. Two very well known works are the X Armed Bandits\cite{BubeckMSS11} and the Zooming algorithm \cite{KleinbergSU19}. These algorithms addressed the \emph{regret} version of the bandit problem which is known to differ in important ways from the best arm identification problem. The former aims to accumulate as few sub-optimal samples as possible on an infinite time horizon, while the latter seeks to identify a probably approximatly correct (PAC) optimum under a minimal amount of samples. Here we address the best arm identification problem in continuous settings, which we consider a better representation for training VQA. Our bandit methods that combine global and local optimization are also applicable to better VQA designs and could be combined into hybrid schemes with purely local gradient based methods.\\

%adaptively partition the domain have been found to be near optimal with respect to worst problem instances.\\
%However, there are no algorithms for the continuous, Lipschitz setting, which are optimal with respect to instance specific bounds. \\

Specifically, we derive an instance specific lower bound for continuous, Lipschitz bandits on $[0,1]$. Furthermore, we present a simple algorithm, whose sample complexity matches the lower bound up a log factor. Our experiments show an improvement in scaling over not instance specific methods and, due to its simplicity, substantially lower cost per iteration with respect to non-adaptive, instance optimal methods. Hence, our algorithm has a practical advantage over these methods, which turn out to be intractable when exceeding a certain number of arms.

Our main contributions are:
\begin{itemize}
    \item We introduce a novel approach to hybrid Quantum-classical algorithms such as parametrized quantum algorithms (PQC) algorithms and QAOA by formulating it as a best arm identification problem in continuous bandits.
    \item We give an information-theoretic, instance specific lower bound for continuous best arm identification (in 1 dimension).
    \item We give an algorithm via adaptive partitioning that essentially meets the lower bound (up to a log factor).
    \item We give an algorithm that serves as a proxy for the multi-dimensional extension of the continuous bandit.
    \item We apply our bandit algorithm to PQC and QAOA problem instances, showing that it beats the the previous (gradient-based) methods from literature.
\end{itemize}

\section{Related Work}\label{sec:related_work}
\paragraph*{Structured and Continuous Bandits}
Best arm identification for general bandit problems with a finite set of arms has been explored in both worst-case scenarios~\cite{10.1007/978-3-642-04414-4_7} and instance-specific settings~\cite{pmlr-v49-garivier16a, NEURIPS2019_8d1de745}. Subsequent research has extended this work to provide instance-specific bounds and algorithms for bandits incorporating contextual information, such as those with Linear or Lipschitz-continuous reward functions~\cite{wang2021fast}, as well as bandits subject to constraints~\cite{pmlr-v238-carlsson24a}. Continuous bandits have primarily been studied in the context of regret minimization~\cite{bubeck2011x, KleinbergSU19}, with further refinement in Adaptive-treed bandits~\cite{bull2015adaptive}, which, while focusing on cumulative regret, also offers PAC bounds. In the context of Quantum computing, regret minimization has been studied outside of VQA, where the task is to select an optimal observable from a finite or continuous set~\cite{Lumbreras2022multiarmedquantum, lumbreras2024learningpurequantumstates}, with regret defined as the expected measurement outcome, though the bounds in this setting are not instance-specific. Methods for pure exploration in continuous bandit settings, such as \emph{MFDOO}~\cite{demontbrun2024certified}, have been developed; however, they do not incorporate structural properties of the problem, such as the Lipschitz continuity of the reward function $\mu$, which implies that nearby arms tend to yield similar rewards. Additionally, these methods rely on worst-case analysis and lack instance-dependent performance guarantees, with no known bounds for continuous bandits with Lipschitz reward functions. Our work is the first to address this gap.
\vspace{-3mm}
\paragraph*{Mitigating BP in VQAs}
Recent research indicates a trade-off between the expressivity and trainability~\cite{Holmes_2022} of specific quantum circuit architectures, often referred to as \emph{ansatz}. If an ansatz lacks sufficient expressivity, it may be incapable of representing the target function. Conversely, provably expressive ansatzes are typically susceptible to the BP phenomenon, which complicates the task of identifying the desired model within the represented model class. 
\citet{La24} provides a summary of current techniques for mitigating BPs, a subset of which we briefly outline. One way to mitigate this issue is to find the best trade-off via adaptive structure search~\cite{Du2022} and \emph{ADAPT-VQE}~\cite{Grimsley2023}. Furthermore, most proofs of presence of BPs only apply to random parameter initialization. Therefore, employing alternative initialization strategies~\cite{NEURIPS2022_7611a3cb} can serve as an effective approach to mitigating this issue. Finally, certain architectures, such as noise-induced shallow circuits~\cite{mele2024noiseinducedshallowcircuitsabsence}, are proven not to have BPs. However, recent work suggests that the absence of BPs implies classical simulability~\cite{cerezo2024doesprovableabsencebarren}. Even in the absence of BPs, the challenge of avoiding local minima remains. Alternative training methods for VQAs, such as those proposed in~\cite{PhysRevX.7.021027} and~\cite{PhysRevA.107.032407}, generally lack formal theoretical guarantees. In this work, we introduce the application of bandit methods to this domain for the first time.

\section{Preliminaries}\label{sec:preliminaries}
In this section, we introduce the general \emph{stochastic bandit} model and connect it to VQAs. Finally, we provide a rigorous statement of the bandit problem we study in this work.
\subsection{Continuous Bandits}\label{sec:continuous_bandits}
In its general form, a \emph{stochastic bandit} is a pair $(\mathcal{X}, M)$ of a measurable space $\mathcal{X}$ and a set of random variables $M$. Each element $x \in \mathcal{X}$ is associated with a random variable $M(x) \in M$. Playing arm $x\in \mathcal{X}$ corresponds observing an i.i.d. sample from $M(x)$. In this work, we consider \emph{continuous bandits}, i.e., bandits with uncountably infinite set of arms $\mathcal{X} \subset \RR^d$, whose expected rewards are denoted by $\mu(x) = \E[M(x)]$. Typically, $\mu(x)$ is assumed to be $L$-Lipschitz and the rewards $M(x)$ to be either sub-Gaussian or restricted to a bounded domain~\cite{bubeck2011x}. Stochastic bandits describe a setting where the only way of accessing $\mu$ is to observe samples of the respective rewards. Therefore, the continuous bandit model is directly applicable to VQA, which will be outlined in the upcoming section.

\subsection{Variational Quantum Optimization}
\label{sec:bp}
As illustrated in~\Cref{fig:vqc}, in variational quantum computing, the process begins by initializing the quantum system to an $n$-qubit state $\rho$, which is then passed through a \emph{parameterized quantum circuit} (PQC). A PQC can be expressed as a sequence of $p$ parametrized unitaries 
\vspace{-2mm}
\begin{equation}
    U(\theta) = \prod_{i=1}^p U_i(\theta_i),
\end{equation}
where $\theta = (\theta_1,...,\theta_L)$ is a set of trainable parameters. After applying $U(\theta)$, the resulting state is measured with an observable $O$, yielding an outcome $o_z$, which is an eigenvalue of $O$ associated with eigenvector $\ket{z}$.\\
By the \emph{Born rule}, the probability of outcome $o_z$ associated with basis state $\ket{z}$ is given by $\bra{z} \rho(\theta) \ket{z}$, with $\rho(\theta) = U(\theta) \rho U(\theta)^\dagger$. The expected outcome is given by $Tr[\rho(\theta) O]$, which leads to the loss function 
$\ell_{\theta}(\rho, O) = Tr[\rho(\theta) O]$. The expected loss is typically approximated by repeatedly running the circuit with the same parameters and computing the empirical average.\\ %the upcoming could be cut out
Reformulating this setup as measuring the initial state $\rho$ with an observable from the set $\{\tilde{O}(\theta)\}_{\theta}$ with $\tilde{O}(\theta) = U^\dagger(\theta) O U(\theta)$ can be described as \emph{multi-armed Quantum Bandits}~\cite{Lumbreras2022multiarmedquantum}. Since the initial state $\rho$ of PQCs is known, we can circumvent this formalism and state PQCs as classical, continuous bandits. \\
Explicitly, $\mu(x) = Tr[\rho(\theta) O]$ and 
\begin{equation}
    P(M(x) = y) = \begin{cases}
        \bra{z} \rho(\theta) \ket{z}  & \text{if } y = o_z,\\
        0 &\text{otherwise}.
    \end{cases}
\end{equation}
If the eigenvalues of $O$ lie between $0$ and $1$, so does the reward distribution. This is easily achieved by linearly transforming $O$. Furthermore, general Unitaries $U(\theta_k)$ can be expressed as $e^{-i\theta_k V_k}$, where $V_k$ is Hermitian with bounded spectral norm~\cite{Holmes_2022}. Therefore, $\mu$'s gradients are bounded by some constant $L$.\\
Although our results only apply to $1$-d continuous bandits, they can be used for multidimensional continuous bandits, for example in combination with Powell's method~\cite{powell1964efficient}, which we will discuss in more detail in~\Cref{sec:algorithm}.

\subsection{Problem statement}

In~\Cref{sec:lower_bound} and~\Cref{sec:algorithm}, we consider a bandit problem $([0,1], M(x))$, which satisfies the following assumptions:

\begin{enumerate}[label=(\roman*)]
    \item The rewards $M(x)$ are $1$-sub-Gaussian.
    \item The expected reward $\mu(x)$ is $L$-Lipschitz.
    \item $\mu(x)$ has a unique optimum $x^*$. \label{ass:3}
    \item There is a constant $\rho_0$, such that $\mu$ is unimodal on every set $E \subseteq [x_i, x_i + \rho]$ for all $\rho < \rho_0$. \label{ass:4}
\end{enumerate}
The optimization algorithm aims to find an arm, which is close to the unique maximum $x^* = \mathrm{argmax}_{x\in [0,1]} \mu(x)$ with high probability. Formally, we want the learner to recommend an arm $\hat{x}$, such that, given $\ep, \delta > 0$,
\begin{equation}\label{eq:pac_learner}
    \Pr(\lVert \hat{x} - x^* \rVert_2 > \ep) \leq \delta.
\end{equation}
An optimization algorithm that satisfies~\Cref{eq:pac_learner} is often referred to as $\delta$-\emph{PAC learner}. Our goal is to design a PAC-learner, which finds an $\ep$-optimal arm with probability at least $1-\delta$ after a minimal number of steps, which we refer to by  $\tau_{\delta}^{\ep}$. In general, this stopping time is random so that we quantify the sample complexity of the algorithm by $\E[\tau_{\delta}^{\ep}]$.\\
Note that assumptions~\ref{ass:3} and~\ref{ass:4} do not hold for general PQCs. In practice, this is not an issue, as these assumptions are not needed for our algorithm to find an arm with reward $\mu(x) \leq \mu(x^*) + \ep$.
\vspace{-3mm}
\paragraph*{Notation}
In the following, we introduce some notation, which will occur throughout~\Cref{sec:lower_bound} and~\Cref{sec:algorithm}. All other definitions will be introduced in the respective subsections.
In the upcoming sections, we will consider the equivalent minimization problem for convenience. Therefore, let $v(x) \triangleq \mu(x^*) - \mu(x)$, such that $v$ has its minimum where $\mu$ has its maximum and $v(x^*) = 0$. For clarity, we sometimes write $x^*(f) \triangleq \mathrm{argmax}_{x \in [0,1]} f(x)$ in order to refer to the maximizer of a specific function, which we omit for $\mu$ and $v$.
For convenience, we assume that $\epsilon = 2^{-D}$ and $\ep = 2^{-S}\rho_0$. \\
Furthermore, we define the following level sets, i.e. sets of the form 
\begin{equation*}
    v^{-1}[a,b] \triangleq \{x \in [0,1] : a \leq v(x) \leq b\}.
\end{equation*}
Furthermore, we define $A_t = v^{-1}(2^{t-1}\epsilon, 2^t \epsilon]$ and \\
$B_t = v^{-1}(2^{-t}, 2^{-(t-1)}]$ for $t=1,\ldots,D$. Note that $A_t = B_{D-t}$. This is illustrated in \Cref{fig:sketch_sets}. We use the Lebesgue measure, which we denote by $m(\cdot)$, to express the ``length'' of the sets. \\ 
\begin{figure}\label{fig:sketch_sets}
    
    \hspace*{-0.18in}
    \includegraphics[width=0.5\textwidth, left]{illustration.pdf}
    \caption{Example for $\ep=2^{-5}$ with $\rho_0=1/4$ and $S=3$.}
    \label{fig:sketch_sets}
\end{figure}
Finally, we introduce two additional definitions.
\begin{definition}[Covering-number]
    The \emph{covering number} $N_r(X)$ is the smallest number of sets with diameter $r$ required to cover a set $X$.
\end{definition}

The covering number gives rise to the \emph{zooming dimension}, a concept, which is used in related literature, such as~\cite{KleinbergSU19}.

\begin{definition}[Zooming-dimension]
    The \emph{zooming dimension} of an instance $\mu(x)$ is defined as the smallest $\beta$, for which there is a constant $C$, such that $N_{r/8}(X_r) = Cr^{-\beta}$ for every $1/2 > r>0$ and sets $X_r \triangleq v^{-1}(r, 2r]$.
\end{definition}

The zooming dimension is a convenient tool to write regret upper and lower bounds in concise form. Conceptually, it can be thought of as the limit of the ``flatness'' of $\mu$ around its maximum. In the $1$-d setting, $\beta$ takes values from $0$ to $1$.

\section{Lower bound}\label{sec:lower_bound}

In this section, we first establish an information-theoretic lower bound, following a similar approach to that of ~\citet{pmlr-v49-garivier16a, pmlr-v238-carlsson24a}. Deriving a scheme analogous to \emph{Track-and-Stop} directly from this bound is infeasible, as explicitly solving for $w$ is intractable. Therefore, we derive a simplified, instance dependent upper bound in the subsequent section. The proofs of all theoretical results in this section are provided in~\Cref{sec:proofs_lb}.

\subsection{Continuous lower bound}

The methods to obtain a lower bound in the discrete, unstructured setting~\cite{pmlr-v49-garivier16a} can easily be adapted to the infinite-arm setting we consider. The main differences lie in the definition of the alternate set and the use of an integral instead of a sum, leading to a lower bound that closely resembles the one derived in the discrete setting.\\
Denote the \emph{alternate set} by \begin{equation}
    \mathrm{Alt}^{\ep}(\mu) \triangleq \{ \lambda \ L\text{-Lipschitz}: \lVert x^*(\mu) - x^*(\lambda) \rVert > \ep \}.
\end{equation}
For convenience, we only consider sample strategies, which have Riemann-integrable probability density and denote the respective set by $\mathcal{W}$. In the following, we present an information-theoretic lower bound for continuous bandits.

\begin{theorem}\label{thm:exact_lower_bound}
    Let $\mu$ be a bandit continuous bandit on some set $\mathcal{X}$.
    For any $(\ep, \delta)$-PAC learner,  
    \begin{equation}
        \E[\tau_{\delta}^{\ep}] \geq \frac{\log(1/\delta)}{c^*(\mu)},
    \end{equation}
    where 
    \begin{equation}\label{eq:c_star}
        c^*(\mu) = \sup_{w \in \mathcal{W}} \inf_{\lambda \in \mathrm{Alt}^{\ep}(\mu)} \int_{\mathcal{X}} w(x) (\mu(x) - \lambda(x))^2 dx.
    \end{equation}
\end{theorem}

The proof of~\Cref{thm:exact_lower_bound} can be extended to alternative definitions of $\mathrm{Alt}^{\ep}(\mu)$ and holds for a general domain $\mathcal{X}$. It is a consequence of information theoretic properties of a PAC learner. Analogously to its discrete counterpart~\cite{NEURIPS2019_8d1de745},~\Cref{eq:c_star} has a game-theoretic interpretation: the $w$-player maximizes the value in~\Cref{eq:c_star}, to which the $\lambda$-player with $\lambda$ that minimizes the objective for the given $w$. Interpreting~\Cref{eq:c_star} from this perspective will allow us to derive a more tractable lower bound, as we will see in~\Cref{sec:discrete_lower_bound}.\\
Our choice of alternate set, i.e. restricting the location of the maximum of the confusing instance $\lambda$ seems like the most natural extension of its discrete counterpart. However, in some cases, the objective may be to identify $x$, such that $\mu(x^*) - \mu(x) \leq \ep$. Consequently, one may consider alternate instances where $\max_x \mu(x) - \max_x \lambda(x) > \ep$. Though, this choice of alternate set does not accurately reflect the optimization task, as it permits the alternate instance to have its optimum at the same point as 
$\mu$. Consequently, rejecting such an instance would not be justified. Furthermore, the difficulty of distinguishing it from $\mu$ is limited in the vicinity of $\mu$'s optimum. Hence, the ``most confusing'' instances in~\Cref{thm:exact_lower_bound} would excluded, which has a direct impact on the lower bound. This argument is formalized in the following result.

\begin{corollary}\label{cor:trivial_lower_bound}
Let 
\begin{equation}
    \mathrm{Alt}^{\ep}(\mu) \triangleq \{\lambda(x) \, 1\text{-Lipschitz}:\max_x \mu(x) - \max_x \lambda(x) > \ep\}.
\end{equation} Then, 
    \begin{equation}\label{eq:c_star}
        c^*(\mu) = \ep^{2}.
    \end{equation}
\end{corollary}

The bound in~\Cref{cor:trivial_lower_bound} demonstrates that, for this choice of alternate set, the information-theoretic lower bound becomes instance independent. Furthermore, $c^*(\ep)$ is weaker than ~\Cref{thm:exact_lower_bound}, which will become apparent in the following section.

\subsection{Simplified lower bound}\label{sec:discrete_lower_bound}

In the following, we present an upper bound for\\
$c^*(\mu) = c^*(v)$,
which serves as a lower bound for $\E[\tau_{\delta}^{\ep}]$. We consider minimizing $v$ for convenience and refer to\\ 
$v'(x) = \lambda(x^*(\mu))-\lambda(x)$ as the corresponding quantity for the alternate instance, denoted by $\lambda$ in \Cref{eq:c_star}.\\
We can view $c^*(v)$ as a game, where two players compete against each other in alternating rounds: one player is trying to minimize the expression by assigning values to $v'$, whereas the other tries to maximize it by applying values to $w$. 
In the beginning, the $w$-player may try to assign $v'$, such that it equals $v$ everywhere except around the minimum, where it is slightly different, such that $v'\in \mathrm{Alt}^\ep(v)$. The $w$-player's approximately best response is to assign $w \equiv 0$ where $v'=v$ and uniform where $v' \neq v$. In some cases, the $v'$-player can now not play any $v'\in \mathrm{Alt}(v)$ in order to increase the objective for the $w$ that was played. However, $v$ may be `flat' in a certain area, where currently $w \equiv 0$. If this area is large enough, one can play a $1$-Lipschitz $v'\in \mathrm{Alt}^\ep(v)$, which attains value $-\ep$ in that area and equals $v$ in the remaining parts of the domain, yielding objective value $0$. To prevent the $v'$-player from applying this strategy in other possible parts of the domain, the $w$-player needs to respond with the uniform distribution over all such `flat' areas (properly reweighed, such that none of them is more advantageous than others). \\
This gives rise to our second result, the discrete  lower bound. 

\begin{theorem}\label{thm:approx_lower_bound}
    Let $v:[0,1]\rightarrow \RR$ satisfy the assumptions from \Cref{sec:preliminaries}. Then, 
    \begin{equation}
        \E[\tau_{\mathcal{A}}(v,\ep,\delta)]
    \geq \frac{\log(1/\delta)}{80\ep^3/L}\sum_{t=1}^{D}\frac{m(B_t)}{8^{D-t}}.
    \end{equation}
\end{theorem}

\Cref{thm:approx_lower_bound} is still instance dependent and holds for any $\rho_0 > \ep > 0$. When $\ep \rightarrow 0$, one can show that the instance dependence reduces to the \emph{zooming dimension} of $\mu$.

\begin{corollary}\label{cor:approx_lower_bound}
    Let $v:[0,1]\rightarrow \RR$ with zooming dimension $\beta$ satisfy the assumptions from \Cref{sec:preliminaries}. 
    Then, 
    \begin{equation}
        \E[\tau_{\mathcal{A}}(v,\ep,\delta)]
    \geq \boldsymbol{\Theta}(\ep^{-2 + \beta}),
    \end{equation}
    when $\ep \rightarrow 0$.
\end{corollary}

Theorem 2 from~\cite{bull2015adaptive} states that for any strategy for tree-armed bandits, the regret $r_T \gtrsim T^{-1/(\beta + 2)}$ at large enough round $T$. When setting $\ep \geq r_T$ and solving for $T$, one can observe that this coincides with~\Cref{cor:approx_lower_bound}. Note however that our result holds for any strategy.



%\textbf{Remark:} Note that the instances from the Alt-set the $v'$-player could play correspond to $d$-dimensional cones in the respective regions described by the set $R(v)$. Those cones could be with respect to different norms for further generalizations.\\



\section{Algorithm}\label{sec:algorithm}

In this section, we introduce a simple algorithm which matches the lower bound of the previous section up to a logarithmic factor. We briefly outline the algorithm and provide a convergence analysis. Finally, we outline a simple extension to multi-dimensional domains. The proofs of the theoretical results can be found in~\Cref{sec:proofs_algo}.

\subsection{Algorithm outline}

The algorithm follows the following procedure: In each round $1\leq t \leq D$, it draws sample of fixed size from points $x$ on a uniform grid on $[0,1]$. Then, we construct confidence intervals around $\E[v(x)]$ which, in combination with the Lipschitz property, allow us to exclude $x$ and their neighbourhood, when the estimated mean of $v(x)$ is below some threshold. The number of grid points is doubled after each step, and we only consider points, which do not belong to the neighbourhood of an excluded points. We stop when all points, except for an interval of length at most $\ep$, have been excluded.\\
In the following, denote the set of grid points in round $t$ by
\begin{equation}
    H_{t} = \left\{ \frac{1}{\lceil L \rceil}\left( \frac{k}{2^{t+3}} - \frac{1}{2^{t+4}} \right) \middle| 1 \leq k \leq \lceil L \rceil \cdot 2^{t+3} \right\}.
\end{equation}
Furthermore, let $E_t \subseteq [0,1]$ be the parts of the domain exclude in the end of round $t$ and $G_t$ the parts of the domain, which are left in the beginning of round $t$, such that $G_{t} = G_{t-1} \setminus E_t$. These quantities give rise to~\Cref{alg:rr}. 

\begin{algorithm}[tb]
   \caption{Reject and Refine (RR)}
   \label{alg:rr}
\begin{algorithmic}
   \STATE {\bfseries Input:} Inverted bandit $v(\cdot)$, constants $L, \ep$.
   \STATE Initialize $G_0 = [0,1]$, $t=1$.
   \REPEAT
   \FORALL{$h \in G_{t-1} \cap H_t$ \do}
   \STATE Draw $n_t$ samples from $v(h)$.
   \STATE Compute $\hat{v}(h)$
   \STATE Construct $1 - \frac{\delta}{|H_t|2^t}$ CI of length $\frac{1}{2^{t+3}}$.
   \STATE $a_t^* \leftarrow \mathrm{argmin}_{h \in H_1}\hat{v}(h)$
   \STATE $E_t \leftarrow \bigcup_{h: \hat{v}(h) - \hat{v}(a_t^*) > \frac{12}{2^{t+4}}} \left[h-\frac{1}{2^{t+4}}, h+\frac{1}{2^{t+4}}\right]$
   \STATE $G_{t} \leftarrow G_{t-1} \setminus E_t$
   \STATE $t \leftarrow t+1$
   \ENDFOR
   
   \UNTIL{$2^{-t} \leq \ep$}
   \STATE {\bfseries Output:} $a^* = \mathrm{argmin}_{a^*_t}\hat{v}(a_t^*)$.
\end{algorithmic}
\end{algorithm}

\begin{theorem}\label{thm:rr_upper_bound}
    Let $v:[0,1]\rightarrow \RR$ satisfy the assumptions from \Cref{sec:preliminaries}. Then~\Cref{alg:rr} terminates after $D\triangleq\log_2(1/\ep)$ rounds and the number of samples is bounded by
    \begin{equation}\label{eq:upper_bound}
        \tau_{\mathcal{A}}(v, \ep, \delta) \leq 2^{15}L\frac{\log_2(1/\ep)+\log(1/\delta)}{\ep^3}\sum_{t=1}^D \frac{m(B_t)}{8^{D-t}}.
    \end{equation}
\end{theorem}
This bound agrees with the lower bound from~\Cref{thm:approx_lower_bound} apart from constant and $\log(\ep^{-1})$-factors and hence, despite its simplicity, \Cref{alg:rr} is near-optimal.
In particular, the algorithm has anytime-guarantees with respect to the rounds $t$, because after $t$ rounds, $v(a^*_D)< 2^{-D}$. Therefore, the sample complexity bound from~\Cref{thm:rr_upper_bound} holds for any $\ep$ and does not require $v$ to be unimodal. Furthermore, the final set $G_D \cap H_{D}$ may contain multiple arms with $v(a) \leq \ep$. This makes~\Cref{alg:rr} fundamentally different from running discrete best arm identification algorithms, as Frank-Wolfe sampling~\cite{wang2021fast}, on a sufficiently fine partition of $[0,1]$. Such a partition may contain multiple best arms, which would hinder algorithms of this kind from terminating.\\ 
Note that each refinement step comes with a cost: in the best case, one can always exclude half of the remaining domain, so that the the number of arms remains constant. In the worst case, the number of arms doubles in each round. Since the confidence intervals of subsequent rounds require four times as many samples, the sample complexity increases by at least a factor four and at most eight. The following result clarifies this
and shows that the asymptotic performance of~\Cref{alg:rr} is at least as good \emph{Adaptive-treed bandits}. 
\begin{corollary}\label{cor:algo_complexity}
    Consider $v:[0,1]\rightarrow \RR$, which satisfies the assumptions from \Cref{sec:preliminaries} and has \emph{zooming dimension} $\beta$. Then
    \begin{equation}
        \tau_{\mathcal{A}}(v, \ep, \delta) = \mathcal{O}\left((\log{1/\delta} + \log{1/\ep})\ep^{-(\beta + 2)}\right)
    \end{equation}
    and when $\ep \rightarrow 0$
    \begin{equation}
        \E[\tau_{\mathcal{A}}(v,\ep,\delta)]
    = \boldsymbol{\Theta}\left((\log{1/\delta} + \log{1/\ep})\ep^{-(\beta + 2)}\right).
    \end{equation}
\end{corollary}

A key insight from~\Cref{cor:approx_lower_bound} and~\Cref{cor:algo_complexity} is that, in their limits, continuous best arm identification and regret minimization are nearly equivalent.
\vspace{-3mm}
\paragraph*{Application to multi-dimensional parameter optimization}
In order to overcome the limitation of~\Cref{alg:rr} to a $1$-dimensional parameter space, we employ a variety of schemes to map it to higher dimensional parameter spaces. At the heart of each strategy lies the following idea: For some function $f:[0,1]^d \rightarrow \RR$, pick a point $p$ and direction $u$, which give rise to the $1$-dimensional function \begin{equation}
    g(s) = f((p + us)_{[0,1]^d}),
\end{equation} 
reducing the problem to computing
\begin{equation}
    s^* = \underset{s\in [0,1]}{\mathrm{argmin}} \ g(s)
\end{equation}
with Lipschitz constant $L \lVert u \rVert_2$.
By subscript $[0,1]^d$, we indicate ``modulo'', i.e. a periodic parameter domain, which applies to the VQA-setting. Depending on the application, the line may be truncated to $[0,1]^d$ instead.\\
Powells method~\cite{powell1964efficient} is a well-established, gradient-free optimization method, which incorporates a scheme of this kind. Throughout the procedure, the algorithm keeps track of the directions $\{u_i\}_{i=1}^d$, initially chosen to be all unit vectors. Starting from an arbitrary $p_0$, the algorithm sweeps through the directions, always updating $p_{k+1} = p_k + s^*_k u_k$. For the first $1 \leq k \leq d$ iterations, $f$ is optimized with respect to $x_k$, keeping the other parameters fixed. After each $d$ iterations, $u_i$ is replaced by $u_{i+1}$ and $u_d$ by $p_d - p_0$. Then, using $s^* = \mathrm{argmin}_t f(p_d + u_d s)$, $p_0$ is updated as $p_d + s^* u_d$, and the same procedure repeated with the updated directions. It can be shown that Powell's method efficiently minimizes functions of quadratic form. Typically, Brent's parabolic interpolation method~\cite{brent2013algorithms} is used to find $s^*$, however, any gradient free optimizer can be applied, which makes Powell's method a well-suited extension to~\Cref{alg:rr}.
Another simple extension that falls into this category is to always choose $u_k$ at random, which we discuss in the following.
\vspace{-3mm}
\paragraph*{Notes on practical implementation}
The extensions of~\Cref{alg:rr} to higher dimensions we consider may require a large number of $1$-d optimizations. To control the sample complexity, we restrict the maximal depth of~\Cref{alg:rr} to a a threshold $D_{\mathrm{max}}$. Since most lines $g(s)$ may not contain the optimum, we terminate the procedure at depth $1$ when the values observed so far suggest that significant improvement at higher depth is unlikely. The resulting computation yields $g_k(\hat{s}_k^*) \leq g_k(s_k^*) + \ep$ in step $k$, where 
\begin{equation*}
    \hat{s}_k = \underset{x\in \boldsymbol{H}_k}{\mathrm{argmin}} \ g_k(x) \quad \text{and} \quad \boldsymbol{H}_k = \bigcup_{t=1}^{D_{\mathrm{max}}} H_t.
\end{equation*}
Observe that $g_k(0) = \hat{g}_{k-1}(\hat{s}^*_{k-1})$ in steps $k > 1$, yielding  $s_k = 0$ as additional observation. \\
When using~\Cref{alg:rr} in combination with Powell's method (RR Powell), we incorporate this by selecting the minimizer of $\boldsymbol{H}_k \cup \{0\}$ as $\hat{s}^*_k$: we only \emph{accept} $\hat{s}_k$ when it improves on the current minimum and choose $\hat{s}^*_k = 0$ otherwise, such that $p_{k+1} = p_k$. In the approach, where sample $u_k$ uniformly at random, we update $p_{k+1}$ to $p_k + \hat{s}_k u_k$
\vspace{-1mm}
\begin{enumerate}[label=(\roman*)]
    \item with some acceptance probability $a_k$, depending on $g_k(\hat{s}_k)$ and $g_k(0)$ (reject)
    \item if $g_t(t^*_k) < g_{t-1}(t^*_k)$ (AIm),
\end{enumerate}
\vspace{-1mm}
and $p_{k+1} = p_k$ otherwise. We consider $a_k = e^{-q(\hat{s}^*_{k}-\hat{s}^*_{k-1})}$ a reasonable acceptance probability. Finally, $\delta$ may also be chosen in a favourable way, since the practical performance may suffer from overly conservative multiple confidence estimates. In summary, this results in $q$, $D_{max}$, $\delta$ and $L$ as hyperparameters.

\section{Experiments}\label{sec:experiments}
We test our algorithm on two VQAs and compare it to Powell's method~\cite{powell1964efficient} and Constrained Optimization BY Linear Approximation (COBYLA)~\cite{Powell1994}. Our experiments\footnote{The code is available on \href{https://github.com/marcwannerchalmers/vqa_continuous_bandits.git}{github}.} are implemented in \emph{Python}, for the latter two, we used implementations from the \emph{SciPy} library.
\begin{figure*}
    \centering
    \hspace{-1.3cm}
    \includegraphics[width=0.8\linewidth]{results.pdf}
    \caption{Median of the sample complexity $N_{\mathrm{total}}$ for optimizing a PQC (left) and MaxCut-QAOA (right) below the thresholds $C=0.4$ and $C=0.2$, respectively. The medians are computed over $20$ and $100$ simulations. The RR methods use $\delta=20$, $D_{\max} = 1$ and $L=0.5$ and the other methods $N=10^5$ circuit evaluations iteration. Failure of convergence is indicated by a dashed line.}
    \label{fig:results}
\end{figure*}
The first example is a problem taken from~\citet{Arra21},
where the goal is to train the parameters in an $n$-qubit circuit $V(\theta)$, such that $V(\theta) \ket{0}= \ket{0}$, with the all-zero state and optimizing following local cost function 
\begin{equation}
    C(\theta) = \tr[O_L V(\theta) \ket{0}\bra{0} V^T(\theta)],
\end{equation}
where
\begin{equation}
    O_L = \mathbbm{1} - \frac{1}{n}\sum_{i=1}^n \ket{0_i}\bra{0_i}.
\end{equation}
We trained the same PQC for $n=5, \dots, 11$ qubits with $p=n$ layers, ensuring that the objective function exhibits barren plateaus. For each $n$, we conducted $20$ simulations with initial parameters sampled uniformly at random. The optimization was terminated when either a threshold of $C=0.4$ was reached or the respective algorithm converged. For all versions of RR, we found $q=400$, $D_{\max} = 1$, $\delta=20$ and $L=0.5$ to be optimal. We tested COBYLA and Powell's method with the default settings from the respective SciPy functions and used $N=10^3, 10^4, 10^5$ circuit evaluations to approximate the objective in each iteration. The latter two only converged for $N=10^5$ on all examples. The respective medians are displayed in~\Cref{fig:results}. Failure of convergence in more than half of the experiments is indicated by a dashed line. \\
Our second example demonstrates the application of QAOA~\cite{farhi2014quantumapproximateoptimizationalgorithm} to the MaxCut problem on graphs with $n=5, \dots, 15$ vertices. The graphs were at random according to the Erd\H{o}s-Rényi model~\cite{erdHos1961strength} with edge probability $0.5$. As objective, we used $1-R_a$, where $R_a$ denotes the approximation ratio. For each $n$, we performed $100$ simulations, each utilizing a randomly generated graph and initial parameters sampled uniformly at random. For RR, we used the same hyperparameters as in the previous experiments. For the other methods, we tested $N=10^3, 10^4, 10^5, 10^6$ and found that even for $N=10^6$, less than half of them converged below the threshold of $C=0.2$ for $n>11$. Their success rate of optimization varied between $1\%$ and $30\%$ for $n=15$ across all tested values of $N$.\\
Observe that our adaptation to Powell's method results in a substantial improvement.
Furthermore, RR AIm and RR reject outperform COBYLA by a factor of approximately $4$ and standard Powell's method by a factor of approximately $40$ on the PQC example. It is worth noting that the sample complexity of these two methods is significantly smaller than that reported by~\citet{Arra21}, which our algorithm outperforms by several orders of magnitude. A possible explanation for this discrepancy is that we employed a different number of shots to approximate the objective. For the QAOA example, we find that RR consistently find values below the threshold, while the other methods get stuck in local minima.

\section{Conclusion and Outlook}
In this work, we addressed the challenges of optimizing VQA with a novel approach based on continuous bandits.
We considered a continuous bandit problem and derived a general, instance-specific sample complexity upper bound for pure exploration with Lipschitz rewards on the unit interval, together with a matching near-optimal algorithm. We prove that in the limit, our bounds coincide with the ones for regret methods on an infinite time horizon. Furthermore, we provided simple extensions of our algorithm to higher dimension, for which our experiments demonstrate a significant improvement over common, gradient-free methods, in terms of sample complexity and the capability to avoid local optima. \\
Our experimental results underlines the potential of the continuous bandit model for optimizing VQAs and possible improvements of our algorithm: although we beat the baselines in this form, exploring the domain at increased depths comes with large costs in terms of sample complexity. In future work, we hope to mitigate these costs via more efficient construction of confidence intervals either by further exploiting the Lipschitz property, as~\citet{pmlr-v35-magureanu14} or more effective concentration laws, as e.g.~\citet{ramdas2023betting}. \\
While these improvements are of practical nature, there is also potential in improving the algorithm on the theoretical side. One natural future direction is the extension of our algorithm to higher dimensions. This comes with the challenge that the algorithm not only needs to choose which parts of the domain it refines, but also along which direction - an extension of this kind for our algorithm requires additional ideas.\\
Moreover, it may be possible to circumvent working with an approximate upper bound and formulate an algorithm in the style of \emph{Track-And-Stop}, which proposes new parameters based on direct approximations of the continuous lower bound.\\
Finally, our theoretical upper bounds reveal a new insight about the effect of BPs on trainability in $1$-d, which we conjecture to also hold for the multi-dimensional setting: in the asymptotic sense, flat regions only affect the performance of our algorithms when the respective function value is close to $0$. Therefore, even if BPs cannot be avoided, bandit methods have the potential to mitigate their effects.

\newpage

\section*{Impact Statement}
This paper presents work whose goal is to advance the field of Machine Learning in the context of Quantum Computing. There are many potential societal consequences of our work, none which we feel must be specifically highlighted here.
% Acknowledgements should only appear in the accepted version.
\section*{Acknowledgements}
MW and DD are supported by SSF (Swedish Foundation for Strategic Research), grant number FUS21- 0063.

JJ is partly supported by Wallenberg AI, Autonomous Systems and Software Program (WASP).

Part of this work was performed while EC was a PhD student at Chalmers University of Technology and was supported by Chalmers AI Center (CHAIR).

The computations were enabled by resources provided by the National Academic Infrastructure for Supercomputing in Sweden (NAISS), partially funded by the Swedish Research Council through grant agreement no. 2022-06725.

% In the unusual situation where you want a paper to appear in the
% references without citing it in the main text, use \nocite
\nocite{langley00}

\bibliography{sources}
\bibliographystyle{icml2024}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% APPENDIX
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newpage
\appendix
\onecolumn
\section{Proofs of \Cref{sec:lower_bound}}\label{sec:proofs_lb}
In this section, we prove the theoretical results from~\Cref{sec:lower_bound}. We begin with the proof of the continuous lower bound given in~\Cref{thm:exact_lower_bound}.
\begin{proof}
Consider a continuous bandit as defined in~\Cref{sec:preliminaries} with expected reward $\mu(x)$ on domain $\mathcal{X}$ and some policy, which proposes an \emph{action}, i.e. a point $x_t \in \mathcal{X}$ with probability density $\pi(X_t = x_t| Z_t = z_t)$ in round $t$. By $Z_t = (R_{t-1}, X_{t-1}, \dots, R_1, X_1)$, we denote the history of previously observed rewards $R_k$ and actions $X_k$. We assume that the reward distributions of the bandit and the policy have a probability density, which is true in most cases (see e.g. chapter 4.7 in~\cite{lattimore2020bandit}. For simplicity, we further only consider policies with Riemann-integrable densities. One can rewrite the following proof in terms of Lebesgue integrals, however, in the context of $1$-sub-Gaussian, Lipschitz reward distributions, we do not expect any gain from the additional generality. Now consider a bandit with reward distribution $\Lambda(x)$ and expected reward $\lambda \in \mathrm{Alt}^{\ep}(\mu)$. We now proceed similarly as in the proof of Theorem 4.1 in~\cite{kaufmann:tel-03825097}. Let $Z_t^\mu \sim P_\mu(Z_t), Z_t^\lambda \sim P_\lambda(Z_t)$ denote the History of samples under policy $\pi$ and reward distributions $M, \Lambda$, respectively. On the one hand, consider $\mathcal{E}$ to be the event that the policy returns $x_{\tau_\delta^\ep}$, such that $|x_{\tau_\delta^\ep} - x^*| \leq \ep$. If $\pi$ $\delta$-PAC, then we get
\begin{equation}\label{eq:lem_kaufmann}
    \kl(H_{\tau_\delta^\ep}, H_{\tau_\delta^\ep}) \geq \kl(\mathbb{P}_\mu(\mathcal{E}),\mathbb{P}_\lambda(\mathcal{E})) \geq \kl(1-\delta, \delta)
\end{equation}
by Lemma 0.1 in~\cite{kaufmann:tel-03825097}, where we use the same definition for $\mathbb{P}_\mu(\mathcal{E}),\mathbb{P}_\lambda(\mathcal{E})$, i.e. the expected exponents of the log-likelihood ratios. Note that the proof only makes use of the data processing inequality, which does not require a discrete action space. In the following, assume without loss of generality that $\Lambda(x)$ dominates $M(x)$ on all $x \in \mathcal{X}$. On the other hand note that

\begin{equation}
    P_\mu(Z_t) = \prod_{i=1}^t P_\mu(R_i | X_i) \pi(X_i |Z_{i-1})
\end{equation}
and 
\begin{equation}
    P_\lambda(Z_t) = \prod_{i=1}^t P_\lambda(R_i | X_i) \pi(X_i |Z_{i-1})
\end{equation}

and therefore
\begin{align}
    \E_{P_\mu, \boldsymbol{X}}\left[\log{\frac{P_\mu(Z_t)}{P_\lambda(Z_t)}}\right] &= \E_{P_\mu, \boldsymbol{X}}\left[\sum_{i=1}^t \log{\frac{P_\mu(R_i | X_i)}{P_\lambda(R_i | X_i)}}\right]\\
    &=\sum_{i=1}^t \E_{P_\mu, X_i}\left[\log{\frac{P_\mu(R_i | X_i)}{P_\lambda(R_i | X_i)}}\right] \\
    &= \sum_{i=1}^t \int_{\mathcal{X}\times \RR} w_i(x, r) \log{\frac{P_\mu(R_i =r| X_i = x)}{P_\lambda(R_i = r| X_i=x)}}d(x, r),
\end{align}
where $w_i(x,r)$ is the joint probability density of action and reward for $\pi$ in round $i$. Letting $w_i(x)$ the corresponding marginal density of the action, we obtain
\begin{align}
    &= \sum_{i=1}^t \int_{\mathcal{X}\times \RR} w_i(x) \int_{\RR} P_\mu(R_i =r| X_i = x) \log{\frac{P_\mu(R_i =r| X_i = x)}{P_\lambda(R_i = r| X_i=x)}}dr dx\\
    &= \sum_{i=1}^t \int_{\mathcal{X}\times \RR} w_i(x) \kl(M(x), \Lambda(x)) dx\\
    &=\int_{\mathcal{X}\times \RR} \left(\sum_{i=1}^t w_i(x)\right) \kl(M(x), \Lambda(x)) dx.
\end{align}
By~\Cref{eq:lem_kaufmann}, we now get
\begin{align}
    \int_{\mathcal{X}\times \RR} \left(\sum_{i=1}^t w_i(x)\right) \kl(M(x), \Lambda(x)) dx &\geq \kl(1-\delta, \delta)\\
    \Rightarrow t \int_{\mathcal{X}\times \RR} \left(\sum_{i=1}^t \frac{w_i(x)}{t}\right) \kl(M(x), \Lambda(x)) dx &\geq \kl(1-\delta, \delta).
\end{align}
Since the inequality holds for all $\Lambda$ according to our assumption, we can restate this as
\begin{equation}
    t\inf_{\Lambda: \lambda(x) \in \mathrm{Alt}^{\ep}(\mu)} \int_{\mathcal{X}\times \RR} \left(\sum_{i=1}^t \frac{w_i(x)}{t}\right) \kl(M(x), \Lambda(x)) dx \geq \kl(1-\delta, \delta)
\end{equation}    
and since $w_i$ are arbitrary and $w_i \in \mathcal{W}$,
\begin{equation}
    t\sup_{w\in \mathcal{W}}\inf_{\Lambda: \lambda(x) \in \mathrm{Alt}^{\ep}(\mu)} \int_{\mathcal{X}\times \RR} w(x) \kl(M(x), \Lambda(x)) dx \geq \kl(1-\delta, \delta)
\end{equation}
    
    
and by $M, \Lambda$ sub-Gaussian,
\begin{equation}
    t\sup_{w\in \mathcal{W}}\inf_{\Lambda: \lambda(x) \in \mathrm{Alt}^{\ep}(\mu)} \int_{\mathcal{X}\times \RR} w(x) \kl(M(x), \Lambda(x)) dx \leq t\sup_{w\in \mathcal{W}}\inf_{\lambda(x) \in \mathrm{Alt}^{\ep}(\mu)}  \int_{\mathcal{X}\times \RR} w(x) \kl(\mu(x), \lambda(x))dx.
\end{equation}
The statement follows directly.
\end{proof}
Note that the above proof works independently of the definition of $\mathrm{Alt}^{\ep}(\mu)$, given that the respective integrals remain well-defined. Hence, one may be interested in the impact of the choice of $\mathrm{Alt}^{\ep}(\mu)$. Indeed, as stated in~\Cref{cor:trivial_lower_bound}, defining 
\begin{equation}
    \mathrm{Alt}^{\ep}(\mu)  \triangleq \{\lambda(x) \, 1\text{-Lipschitz}:\max_x \mu(x) - \max_x \lambda(x) \geq \ep\}
\end{equation}
makes the lower bound much weaker, which we show in the next proof.
\begin{proof}[Proof of~\Cref{cor:trivial_lower_bound}]
    Consider
    \begin{equation}
        \mathrm{Alt}^{\ep}_\eta(\mu)  \triangleq \{\lambda(x) \, 1\text{-Lipschitz}:\max_x \mu(x) - \max_x \lambda(x) \geq \ep + \eta\}
    \end{equation}
    for some $\eta > 0$ and note that $\mathrm{Alt}^{\ep}_\eta(\mu) \overset{\eta \rightarrow 0}{\longrightarrow} \mathrm{Alt}^{\ep}(\mu)$.
    First, we show that $c^*(\mu) \leq \ep$. \\
    By the function class considered in $\mathrm{Alt}^{\ep}(\mu)$, we can choose $\lambda(x)$, such that $(\lambda(x) - \mu(x))^2 \leq (\ep + \eta)^2$ at any point $x$. Therefore,
    \begin{equation}\label{eq:c_star}
        c^*(\mu) = \sup_{w \in \mathcal{W}} \inf_{\lambda \in \mathrm{Alt}^{\ep}_\eta(\mu)} \int_{\mathcal{X}} w(x) (\mu(x) - \lambda(x))^2 dx \leq \sup_{w \in \mathcal{W}} \int_{\mathcal{X}} w(x) (\ep + \eta)^2 dx = (\ep + \eta)^2.
    \end{equation}
    For $\eta \rightarrow 0$, the results follows.\\
    Next, we show that $c^*(\mu) \geq \ep$. \\
    If we choose $w(x) = \delta_{x^*}(x)$, which is $1$ if and only if $x=x^*$, we get 
    \begin{equation}\label{eq:c_star}
        c^*(\mu) = \sup_{w \in \mathcal{W}} \inf_{\lambda \in \mathrm{Alt}^{\ep}_\eta(\mu)} \int_{\mathcal{X}} w(x) (\mu(x) - \lambda(x))^2 dx \geq \inf_{\lambda \in \mathrm{Alt}^{\ep}_\eta(\mu)} (\mu(x^*) - \lambda(x^*))^2 dx \geq (\ep + \eta)^2,
    \end{equation}
    again by definition of $\mathrm{Alt}^{\ep}_\eta(\mu)$. Letting $\eta \rightarrow 0$ yields the desired result, which concludes the proof.
\end{proof}
Now we proceed to proving~\Cref{thm:approx_lower_bound}. First, we present the arguments from~\Cref{sec:discrete_lower_bound} in a rigorous way. For convenience and with slight abuse of notation, let
\begin{equation}
     \mathrm{Alt}^{\ep}(v) \triangleq \{\lambda(x) \, L\text{-Lipschitz}: \left|\left(\mathrm{argmin}_{x \in [0,1]} v'(x) \right) - x^*\right| > \ep \}.
\end{equation}
Consider some interval $[a, b]$ contained in some level set set $A_t$. If we require $v(a)=v'(a)$ and $v(b)=v'(b)$, $v'$, the Lipschitz-constraint prevents $v'$ from obtaining the value $-\ep$ when the interval is shorter than $\frac{2}{L}(2^t + 2)\ep$. Therefore, we only need to consider intervals $[a,b]\subseteq A_t$ with $b-a \geq \frac{2}{L}(2^t + 2)\ep$.\\
By the assumption in \Cref{sec:preliminaries}, when $2^t \ep \lesssim \rho_0$, $A_t$ must be the union of exactly two intervals $[a_1, b_1], [a_2, b_2]$. Let $A_t^l$ be the largest interval among the two.
Furthermore, let 
\begin{equation}
    R(v) = \bigcup_{0 \leq t \leq S: m(A_t^l) \geq \frac{2}{L}(2^t + 2)\ep} A_t^l
\end{equation}
denote the set of indices with feasible level set. If $R(v) = \emptyset$, $v'$ can only attain some trivial solution, which is given by 
\begin{equation}
    v_0 \triangleq 
    \begin{cases}
    3 \ep + \frac{1}{L}|x - m| & x \in [\frac{m-\ep}{L}, m+\frac{\ep}{L}] \\
    4 \ep & x \in A_{\leq 2} \setminus [\frac{m-\ep}{L}, m+\frac{\ep}{L}]\\
    v(x) & \mathrm{otherwise},
    \end{cases}
\end{equation}
where $m \in A_{\leq 2}$ is chosen, such that it has distance $\ep$ from its boundary, i.e. $\inf_{x \in \partial A_{\leq 2}} \lVert m - x \rVert_2 = \frac{\ep}{L}$. This function equals $v$ on all higher level sets, and is constant on $A_{\leq 2}$ except for a small bump, which touches the boundary of $A_{\leq 2}$ and represents a reasonable ``approximate'' infimum with respect to $v'$ when the latter can not have a minimum outside of $[x^* - \frac{\ep}{L}, x^* + \frac{\ep}{L}]$ with value smaller than $0$. \\
In the following, we restrict $\mathrm{Alt}^{\ep}(v)$ to a set of functions, which equal $v$ everywhere except on some $A_t^l\in R(v)$, where they have one wedge, i.e. of the form $-\ep \frac{1}{L}|x - m|$ for some $m$. 
\begin{lemma}\label{lem:first_approx_bound}
    \begin{equation}\label{eq:rhs_lemma}
    \frac{2}{L}\sup_{w \in \mathcal{W}} \inf_{v' \in \mathrm{Alt}^{\ep}(v)} \int_{0}^{1} w(x)(v'(x)-v(x))^2dx \leq  \frac{2\ep^3}{\sum_{A_t \in R(v)} \frac{m(A_t)}{(2^t+2)^3}}.
\end{equation}
\end{lemma}
\begin{proof}
If $R(v) = \emptyset$, \Cref{eq:rhs_lemma} is trivially satisfied.
Otherwise, we restrict $v'$ to have a wedge on some $A_t^l \in R(v)$, which attains $v'(x^*(v'))=-\ep$ is equal to $v$ everywhere else. We denote the restricted alternate set by $\overline{\mathrm{Alt}}^{\ep}(v)$. Observe that $(v(x) - v'(x))^2 \leq (2^t + 2)^2 \ep^2$, which it does on a set $F_t \subseteq A_t$ of length $m(F_t) \leq  \frac{2}{L}(2^t + 2)\ep $. Therefore, 
\begin{align}
    \sup_{w \in \mathcal{W}} \inf_{v' \in \overline{\mathrm{Alt}}^{\ep}(v))} \int_{0}^{1} w(x)(v'(x)-v(x))^2dx &\leq  \sup_{w \in \mathcal{W}} \min_t \inf_{\substack{F_t \subseteq A_t^l\\ m(F_t) = \frac{2}{L}(2^t + 2)\ep}}  \int_{A_t^l} w(x)(2^t + 2)^2 \ep^2 \mathbbm{1}_{F_t} dx\\
    &\leq \sup_{w \in \mathcal{W}} \min_t \inf_{\substack{F_t \subseteq A_t^l\\ m(F_t) = \frac{2}{L}(2^t + 2)\ep}} (2^t + 2)^2 \ep^2 \int_{F_t}  w(x) dx . \label{eq:pf_lem1}
\end{align}
For $w$ to maximize~\Cref{eq:pf_lem1}, $w$ needs to be uniform over $A_t^l$, i.e. $\frac{w_t}{m(A_t^l)}$ for constants $w_t > 0$. Plugging this in yields
\begin{equation}
    \sup_{w \in \mathcal{W}} \min_t \inf_{\substack{F_t \subseteq A_t^l\\ m(F_t) = \frac{2}{L}(2^t + 2)\ep}}  (2^t + 2)^2 \ep^2 \int_{F_t}  w(x) dx \leq \sup_{ \substack{{w_t}_{A_t\in R(v)} \\ \sum_t w_t = 1} } \min_t \frac{2}{L}(2^t + 2)^3\ep^3\frac{w_t}{m(A_t^l)}.
\end{equation}
To minimize this expression, we need to choose $w_t$, such that $\frac{2}{L}(2^t + 2)^3\ep^3\frac{w_t}{m(A_t^l)}$ is the same for all $t$.
Hence, the optimal $w$ for the upper bound on $c^*(v)$ reads
\begin{equation}\label{eq:lamda_multid}
    w^*_s(x) = \begin{cases}
        \frac{m(A^l_s)/(2^s + 2)^{3}}{\sum_{A_t \in R(v)} m(A^l_t)/(2^t + 2)^{3}} & x \in A_s^l \cap R(v)\\
        0 & \mathrm{otherwise}.
    \end{cases} 
\end{equation}

Note that the factors $\frac{2}{L}$ cancel out. Plugging this into the above expression, we get
\begin{align}
    \sup_{w \in \mathcal{W}} \inf_{v' \in \mathrm{Alt}^{\ep}(v)} \int_{0}^{1} w(x)(v'(x)-v(x))^2dx &\leq \sup_{w \in \mathcal{W}} \int_{0}^{1}w(x)(v'(x)-v(x))^2dx \\
    &\leq \frac{\ep^3}{\sum_{A_t \in R(v)} \frac{m(A_t^l)}{(2^t+2)^3}} \\
    &\leq \frac{2\ep^3}{\sum_{A_t \in R(v)} \frac{m(A_t)}{(2^t+2)^3}},
\end{align}
where the last inequality follows from $m(A_t) \leq 2 m(A_t^l)$ for $A_t \in R(v)$.
\end{proof}


\begin{lemma}\label{lem:1d_assum}
    Let $v:[0,1]\rightarrow \RR$ satisfy the assumptions from \Cref{sec:preliminaries}. Then, 
    \begin{equation}\label{eq:assumption_lb}
        \sum_{t=1}^S \frac{m(A_t)}{(2^t + 2)^{3}}  \leq \max\left(2\sum_{A_t \in R(v)} \frac{m(A_t^l)}{(2^t + 2)^{3}}, \frac{\ep}{4}\right).
    \end{equation}
\end{lemma}
\begin{proof}
    If the right hand side of~\Cref{eq:rhs_lemma} is less than $16\ep^2$, the $v^*$-player takes $v^*=v'$ and otherwise she takes $v^*=v_0$.

In case $R(v)$ is empty, the $v^*$-player sets $v^*=v_0$.


Note now that
\begin{equation}
    \sum_{A_t \not\in R(v), t \leq S} \frac{m(A_t)}{(2^t+2)^3} \leq \frac{\ep}{(2^t+2)^2} < \frac{\ep}{8}.
\end{equation}
 
and if the right hand side of~\Cref{eq:rhs_lemma} is less than $16\ep^2$,
\begin{equation}
    \sum_{A_t \in R(v)} \frac{m(A_t)}{(2^t+2)^3} > \frac{\ep}{8}.
\end{equation}

Hence whenever $v^* \neq v_0$,
\begin{equation}
    \sum_{t=1}^{S} \frac{m(A_t)}{(2^t+2)^3} < 2\sum_{k \in R(v)} \frac{m(A_t)}{(2^t+2)^3}
\end{equation}

On the other hand if the right hand side is at least $16\ep^2$, then 
\begin{equation}
    \sum_{A_t \in R(v)} \frac{m(A_t)}{(2^t+2)^3} \leq \frac{\ep}{8}
\end{equation}
and so
\begin{equation}
    \sum_{t=1}^{S} \frac{m(A_t)}{(2^t+2)^3} < \frac{\ep}{4}.
\end{equation}
\end{proof}

\begin{corollary}\label{cor:lem_ass_1d}
    Let $v:[0,1]\rightarrow \RR$ satisfy the assumptions from \Cref{sec:preliminaries}. Then
    \begin{equation}
        \sup_{w \in \mathcal{W}} \int_{0}^{1}w(x)(v'(x)-v(x))^2dx \leq \frac{4\ep^3}{\sum_{t=1}^{S} \frac{m(A_t)}{(2^t+2)^3}}.
    \end{equation}
\end{corollary}
\begin{proof}
    By~\Cref{lem:1d_assum}, we have that either
    \begin{equation}
        \sum_{t=1}^S \frac{m(A_t)}{(2^t + 2)^{3}}  \leq 2\sum_{A_t \in R(v)} \frac{m(A_t^l)}{(2^t + 2)^{3}}
    \end{equation}
    or
    \begin{equation}
        \sum_{t=1}^S \frac{m(A_t)}{(2^t + 2)^{3}}  \leq \frac{\ep}{4}.
    \end{equation}
    In the former case, the statement follows directly from~\Cref{lem:first_approx_bound}.
    In the latter case, we get
    \begin{equation}
        16\ep^2 = \frac{4\ep^3}{\ep/4} \leq \frac{4\ep^3}{\sum_{t=1}^{S} \frac{m(A_t)}{(2^t+2)^3}},
    \end{equation}
    and again, the desired statement follows from~\Cref{lem:first_approx_bound}.
\end{proof}

\begin{proof}[Proof of~\Cref{thm:approx_lower_bound}]
By~\Cref{cor:lem_ass_1d}
\begin{equation}
    \frac{2}{L}c^*_\ep(v) \leq \sup_{w \in \mathcal{W}} \int_{0}^{1}w(x)(v'(x)-v(x))^2dx \leq \frac{4\ep^3}{\sum_{t=1}^{S} \frac{m(A_t)}{(2^t+2)^3}}.
\end{equation}

Since $\rho_0$ only depends on $v$ and not $\ep$, we then have for $\ep$ sufficiently small that
\begin{equation}
    \frac{2}{L}c^*_\ep(v) \leq \sup_{w \in \mathcal{W}} \int_{0}^{1}w(x)(v^*(x)-v(x))^2 dx \leq \frac{5\ep^3}{\sum_{t=1}^{T} \frac{m(A_t)}{(2^t+2)^3}}.
\end{equation}

This finally leads to

\begin{equation}
    \E[\tau_{\mathcal{A}}(v,\ep,\delta)] \geq \frac{\log(1/\delta)}{10\ep^3/L}\sum_{t=1}^{D} m(A_t)/(2^t+2)^3
\geq \frac{\log(1/\delta)}{80\ep^3/L}\sum_{t=1}^{D} \frac{m(A_t)}{8^t}.
\end{equation}
\end{proof}

\begin{proof}[Proof of~\Cref{cor:approx_lower_bound}]
    Let $C, \beta$, such that we require $Cr^{-\beta}$ sets of diameter $r/8$ to cover the sets $X_r = \{x \in [0,1]: r \leq \mu(x^*) - \mu(x) \leq r\}$ for any $r \in [0,1/2]$. Furthermore, let $\eta(\ep)$ be the largest $0 < \eta < \ep$, such that $N_{\eta}(X_{\eta}) \geq C'r^{-\beta}$. By $C'$, we denote the smallest constant, such that $\eta(\ep)$ exists for all $\rho_0>\ep > 0.$ \\
    Note that $C'$, must exist and be independent of $\ep$. Otherwise, we could construct constant $C''$ and $\beta' < \beta$, such that we can cover all $X_r$ with at most $C'' r^{-\beta'}$ sets of diameter $r/8$, which contradicts the definition of the zooming dimension.\\
    Now let $D(\ep) = \lfloor \log_2{\ep} \rfloor$. Then, by unimodality of $v$, $B_{t-1} \cup B_t$ consists of at most two intervals and therefore
    \begin{equation}
        2^t N_{2^t}(B_{t-1} \cup B_t) \leq 2\cdot (B_{t-1} \cup B_t).
    \end{equation}
    Furthermore, note that
    \begin{equation}
        X_r \subset B_{t-1} \cup B_t \quad \forall \ 2^{-t} \leq r \leq 2^{-(t-1)}.
    \end{equation}
    Thus, for $\ep < \rho_0$,
    \begin{align}\label{eq:cor_approx_lb1}
        \sum_{t=1}^{D(\ep)} 8^t m(B_t) &\geq \frac{1}{2\cdot 8} \sum_{t=2}^{D(\ep)} 8^t m(B_{t-1} \cup B_t)\\
        &\geq \frac{4^{D(\ep)}}{32} N_{2^{D(\ep)}}(B_{{D(\ep)}-1} \cup B_{D(\ep)}) \\
        &\geq \frac{4^{D(\ep)}}{32}\sup_{2^{-D(\ep)} \leq r \leq 2^{-(D(\ep)-1)}} N_r(X_r).
    \end{align}
    Since $\eta(\ep)=\ep$ in the limit, we can conclude that 
    \begin{align}
        \lim_{\ep \rightarrow 0} \sup_{2^{-D(\ep)} \leq r \leq 2^{-(D(\ep)-1)}} N_r(X_r) &= \lim_{\ep \rightarrow 0} \sup_{2^{-D(\ep)} \leq r \leq 2^{-(D(\ep)-1)}} N_r(X_r)\\
        &\geq \lim_{\ep \rightarrow 0} C' 2^{\beta D(\eta(\ep))}\\
        &= \lim_{\ep \rightarrow 0} \ep^{-\beta}.
    \end{align}
    When plugging this back into~\Cref{eq:cor_approx_lb1}, the statement follows directly.
\end{proof}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Proofs of~\Cref{sec:algorithm}}\label{sec:proofs_algo}
For illustration purposes, we start by analyzing~\Cref{alg:rr} for $L=1$. Let $G_0 \triangleq [0,1]$. The goal for this round is to exclude all points $x$, for which $v(x) \geq \frac{1}{2}$, i.e. obtain $E_1 \supseteq B_1$, with probability at least $1 - \frac{\delta}{2^1}$. 
Therefore, we pull each of the $2^{1+3} = 16$ arms in $H_1$ sufficiently many times to create symmetric confidence intervals for $v(h)$, $h \in H_1$, of length at most $1/2^{1+3}=1/16$, i.e.\ of the form 
\begin{equation*}
    v(h) = \hat{v}(h) \pm \frac{1}{2^{1+4}} = \hat{v}(h) \pm \frac{1}{32} =:[\underline{v}(h),\overline{v}(h)],
\end{equation*}
at confidence level $1-\delta/2^{2 \cdot 1+3}=1-\delta/32$, making the multiple confidence level at least $1-\delta/2$. When constructing these confidence intervals, we do this independently for each $h \in H_1$, i.e.\ without using any structure of $v$ to make inference from pulls of nearby arms. Let $E_1$ be the set of points $x \in G_0$ for which we can conclude after these pulls that $v(x)>9/32$, given that all confidence intervals are correct and let $B_{\geq t}$ for $\cup_{s \geq t}B_s$.\\
Assuming that all the confidence intervals indeed cover the true value $v(h)$, the Lipschitz property tells us that the true function value $v(a^*)$ of the arm $a^*$ with the smallest empirical mean, i.e.\ $a^*=\mathrm{argmin}_{h \in H_1}\hat{v}(h)$, is at most $1/32$. This implies that 
\begin{equation*}
    \overline{v}(a_1) \leq \frac{1}{32}+\frac{1}{16}=\frac{3}{32}.
\end{equation*}
Suppose now that $x \in B_1$, i.e.\ that $v(x)>1/2$. Then there is an $h \in H_1$ at distance at most $1/32$ from $x$, which by the Lipschitz property must satisfy $v(h)>15/32$ and hence the lower end of the confidence interval for $v(h)$ satisfies 
\begin{equation*}
    \underline{v}(h)>\frac{13}{32},
\end{equation*}
from which we can conclude that $v(x) > 12/32$ for all $x \in [h-1/32, h+1/32]$. Taken together, the above allows us to drop the simplifying assumption that $v(x^*)=0$ and leads to the conclusion
\begin{equation*}
    v(x)-v(a^*)>\frac{9}{32} \qquad \forall x \in [h-1/32, h+1/32].
\end{equation*} 
In particular, this is the case when $\hat{v}(h) - \hat{v}(a^*) > \frac{12}{32}$.
Hence $x \in E_1$ and since $x$ was arbitrary, $E_1 \supseteq B_{\geq 2}$ with probability at least $1 - \frac{\delta}{2}$.
For $G_1=G_0 \setminus E_1$, we immediately get that $G_1 \subseteq B_{\geq 2}$. Moreover, as $1/2^2 < 9/32$, we get  $B_{\geq 3} \subseteq G_1 \subseteq B_{\geq 2}$.\\
Continuing this procedure for $t=2, \dots, D$ with confidence levels $1 - \frac{\delta}{2^t}$ yields~\Cref{alg:rr}.

\begin{proof}[Proof of~\Cref{thm:rr_upper_bound}]
    
The algorithm works as follows for rounds $t=2,3,\ldots, D$. 
Pull each of the arms of $H_t \cap G_{t-1}$ sufficiently many times to obtain symmetric confidence intervals 
\begin{equation}
    v(h) = \hat{v}(h) \pm \frac{1}{2^{t+4}}
\end{equation}
at confidence level $1-\delta/(2^{t}|H_t|$. Let $E_t$ be the set of points in $G_{t-1}$, for which can conclude that $v(x)-v(a_t) > 9/2^{t+4}$, provided that all confidence intervals are correct, and set $G_{t}=G_{t-1} \setminus E_t$. This yields the sets $G_2,G_3,\ldots, G_{D}$. By the union bound, this results in a multiple confidence level of at least $1-\delta/2^t$.\\

Recall that for constructing a symmetric confidence interval on confidence level 1-$\alpha$ of length $2\ell$ for the mean of a Gaussian distribution with unit variance, it suffices that the sample size $N$ satisfies
\begin{equation}
    N \geq \frac{2\log(2/\alpha)}{\ell^2}.
\end{equation}
Hence, the number of pulls per arm is
$2^{2t+9}\log(2^{2t+4}/\delta)$ and so the total number of pulls in this round becomes
\begin{equation}
    2^{2t+9}|H_t|\mu(G_{t-1})\log(2^{t}|H_t|/\delta) = L 2^{3t+12}\mu(G_{t-1})\log(L2^{2t+4}/\delta).
\end{equation}
Let 
\begin{equation}
    a_t=\mathrm{argmin}_{h \in H_t}v(h).
\end{equation}
Then $v(a_t) \leq 1/2^{t+4}$ and thus 
\begin{equation}
    \overline{v}(a_t) \leq \frac{3}{2^{t+4}}.
\end{equation}
Consider an $x \in G_{t-1}$ for which $v(x) > 1/2^t$, if such $x$ exists. Then there exists and $h \in H_t$ such that $v(h)> 15/2^{t+4}$. If $h \in G_{t-1}$, so that the $h$-arm is actually pulled in this round, this gives 
\begin{equation}
    \underline{v}(h) > \frac{13}{2^{t+4}},
\end{equation}
from which we can conclude that $v(x) > 12/2^{t+4}$ and hence $v(x)-v(a_t)>9/2^{t+4}$ and thus $x \in E_t$ so that $x \not \in G_t$.
If on the other hand $h \not \in G_{t-1}$, we already know from the previous round that $v(h)-v(a_{t-1}) > 9/2^{t+3}$ and so $v(h)-v(a_t)>9/2^{t+3}$ and we can conclude that $v(x)-v(a_t) > 9/2^{t+3}-2^{t+4} > 9/2^{t+4}$ and thus again $x \in E_t$. Thus provided that all confidence intervals are correct, $B_{\geq t+2} \subseteq G_{t} \subseteq B_{\geq t+1}$.

\smallskip

Now run the above for $t=1,\ldots,D$. After this, we have $B_{\geq D+2} \subseteq G_{D} \subseteq B_{ \geq D+1}$, i.e.\ $v^{-1}[0,\ep/2] \subseteq G_{D} \cap v^{-1}[0,\ep]$. Hence $G_{D}$ is non-empty and all elements $x \in G$ are $\ep$-optimal arms, so any arm in $G_{D} \cap H_D$ is $\ep$-optimal.

The complexity of the algorithm is upper bounded by
\begin{equation}
    \sum_{t=0}^{D} L 2^{3t+12}\mu(G_{t-1})\log(L2^{2t+4}/\delta) \leq 2^{14} L \sum_{t=1}^{D} 8^t \mu(B_{\geq t}) (t+\log(/\delta)).
\end{equation}
Since $\sum_{j=1}^t j \, 8^j < 2t \cdot 8^t$ and $\sum_{j=1}^t 8^j < 2 \cdot 8^t$, the right hand side is bounded by
\begin{equation}
    2^{15} L\sum_{t=1}^{D} (t+\log(1/\delta))8^t \mu(B_{t}) < 2^{15}L({D}+\log(1/\delta)) \sum_{t=1}^{D} 8^t \mu(B_{t}).
\end{equation}
The expression on the right equals
\begin{equation}
    2^{15}L\frac{\log_2(1/\ep)+\log(1/\delta)}{\ep^3}\sum_{t=1}^{D} \mu(B_t)/8^{D-t}.
\end{equation}
So, in summary, the above defines an algorithm $\mathcal{A}$ with
\begin{equation}
    \tau_{\mathcal{A}} \leq 2^{15}L\frac{\log_2(1/\ep)+\log(1/\delta)}{\ep^3}\sum_{t=1}^{D} \frac{\mu(B_t)}{8^{D-t}}
= 2^{15}L(D+\log(1/\delta))\sum_{t=1}^{D} 8^t \mu(B_t).
\end{equation}
\end{proof}

Finally, we present the proof of~\Cref{cor:algo_complexity}.

\begin{proof}[Proof of~\Cref{cor:algo_complexity}]
    For convenience, we rewrite
    \begin{equation}
        \frac{1}{\ep^3}\sum_{t=1}^D \frac{m(B_t)}{8^{D-t}} = \sum_{t=1}^D 8^t m(B_t).
    \end{equation}
    For the number $N_{2^{-t}/8}(B_t)$ of sets with radius $2^{-t}/8$ required to cover $B_t$, it holds that $\frac{m(B_t)}{2^{-t}/4} \leq N_{2^{-t}/8}(B_t) \leq C 2^{-\beta t}$ and hence $m(B_t) \leq C 2^{t(\beta-1)}$ for some constant $C$. Using the formula for finite geometric sums and $\ep = 2^{-D}$, we get
    \begin{equation}
        \sum_{t=1}^D 8^t m(B_t) \leq \sum_{t=1}^D C 2^{(2+\beta)t} \leq C 2^{2+\beta)D} = \mathcal{O}(\ep^{-2+\beta}).
    \end{equation}
    The proof of the second part can be done analogously to the proof of~\Cref{cor:approx_lower_bound}.
\end{proof}


\end{document}


% This document was modified from the file originally made available by
% Pat Langley and Andrea Danyluk for ICML-2K. This version was created
% by Iain Murray in 2018, and modified by Alexandre Bouchard in
% 2019 and 2021 and by Csaba Szepesvari, Gang Niu and Sivan Sabato in 2022.
% Modified again in 2023 and 2024 by Sivan Sabato and Jonathan Scarlett.
% Previous contributors include Dan Roy, Lise Getoor and Tobias
% Scheffer, which was slightly modified from the 2010 version by
% Thorsten Joachims & Johannes Fuernkranz, slightly modified from the
% 2009 version by Kiri Wagstaff and Sam Roweis's 2008 version, which is
% slightly modified from Prasad Tadepalli's 2007 version which is a
% lightly changed version of the previous year's version by Andrew
% Moore, which was in turn edited from those of Kristian Kersting and
% Codrina Lauth. Alex Smola contributed to the algorithmic style files.
