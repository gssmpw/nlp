\section{Related Work}
\subsection{Traffic Simulation with Diffusion Models}

Predicting the motion of road users is a critical task for autonomous vehicle driving or simulation. For this reason, the number of methods which have attempted to model traffic behavior is vast. The literature contains a variety of techniques for modelling the distribution of driving behavior, including mixture models \cite{ChaiSBA19, CuiRCLNHSD19, NayakantiAZGRS23}, variational autoencoders \cite{scibior2021imagining,suo2021trafficsim}, and generative adversarial networks \cite{zhao2019multi}. 

Our work builds upon recent methods which model driving behavior using diffusion models. In CTG \cite{zhong2023guided}, the authors model the motion of each agent in the scene independently with a Diffuser \cite{JannerDTL22} based diffusion model. The authors of \cite{chang2023controllable} also model agent motions via diffusion, with a focus on controllability. By contrast, most other diffusion based traffic models model entire traffic scenes. This includes MotionDiffuser \cite{jiang2023motiondiffuser}, Scenario Diffusion \cite{pronovost2023scenario} and SceneDM \cite{guo2023scenedm} which all diffuse the joint motion of all agents in the scene. Our work builds directly on that of DJINN \cite{niedoba2024diffusion}, which utilizes a transformer based network to generate joint traffic scenarios based on a variable set of agent state observations. Crucially, due to the expensive computational cost of diffusion model sampling, only CTG \cite{zhong2023guided} utilize their model for closed-loop scenario simulation. Twice per second, they incorporate new state observations and resample trajectories for each agent. By comparison, our method does not require iterative replanning, greatly improving simulation speed.

% \subsection{Autoregressive Diffusion Models}
% Autoregressive Diffusion Models (ARDM)~\cite{hoogeboom2021autoregressive} introduce an order-agnostic autoregressive diffusion model that combines an order-agnostic autoregressive model~\cite{uria2014deep} with a discrete diffusion model~\cite{austin2021structured}. The order-agnostic nature of this model eliminates the need for generating subsequent predictions in a specific order, thereby enabling faster prediction times through parallel sampling. Additionally, relaxing the causal assumption leads to a more efficient per-time-step loss function during training. However, such a model is not suitable for our application due to the sequential nature of traffic simulation. AMD~\cite{han2024amd} proposes an auto-regressive motion generation approach for human motion given a text prompt, but unlike the Rolling Diffusion Model, it denoises one clean motion sample at a time, which is slow at prediction time. The Rolling Diffusion Model (RDM)~\cite{ruhe2024rolling} proposes a sliding window approach targeted at long video generation but does not specifically study its application in a multi-agent system, particularly for closed-loop traffic simulation. We investigate the level of reactivity when applying rolling diffusion models as a traffic scene planner.