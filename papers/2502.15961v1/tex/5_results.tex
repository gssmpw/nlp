% \section{Simulation Evaluation \& Results}\label{sec:results}

\subsection{Baseline Planners}

To evaluate the performance of \PlannerName, we compare it against several baseline methods. In the following section, we describe these baselines, their implementation details, and their respective advantages and limitations, particularly in the context of information gathering in large, high-dimensional search spaces. The simulation framework and vehicle parameters remain consistent across all planners, and each method is allowed to replan during testing.

\subsubsection{Monte-Carlo Tree Search}

Monte Carlo Tree Search (MCTS) can be a powerful technique for finding feasible and optimal paths in complex environments. It is a heuristic search algorithm that builds a search tree incrementally through repeated simulations. At each iteration, it selects a node to explore based on a selection policy (often the Upper Confidence Bound or UCB1 algorithm), expands the tree by adding possible actions from that node, runs a simulation from the newly added node, and updates the statistics of nodes along the path traversed during the simulation. 

The UCB1 (Upper Confidence Bound) algorithm is a technique commonly used in the context of multi-armed bandit problems and Monte Carlo Tree Search (MCTS) for balancing exploration and exploitation. It helps in selecting actions or nodes that are likely to yield high rewards while also exploring less-frequented options to gather more information about their potential rewards. 

We formulate our UCB score in the following manner, \\
\begin{equation*}
    UCB_\text{node} = \frac{I(X_{\text{node}})}{\alpha} + C \times \sqrt{\frac{\ln(N_\text{tree})}{N_\text{node}}}
\end{equation*}
%  $
% UCB_\text{node} = \frac{\overline{X_\text{node}}}{\alpha} + C \times \sqrt{\frac{\ln(N_\text{tree})}{N_\text{node}}}
% $ \\
Here $I(X_{\text{node}})$ denotes the estimated information gain from the node, $\alpha$ denotes the normalization factor which is given by $\frac{B}{v_\text{desired}}$, $B$ being the maximum planning budget and $v_\text{desired}$ being the desired speed of our UAV. $C$ denotes the exploration weight, and $N_\text{tree}$ denotes the number of visits to the tree root node while $N_\text{node}$ denotes the number of times the present node has been visited.

After selecting a candidate node, if it has been visited before, it is expanded by applying motion primitives to generate child nodes, growing the tree. Unvisited nodes skip this step. Following expansion, either the unvisited candidate node or one of its children is selected for the simulation phase, where the future values of nodes along the path are estimated to update the total potential information gain. This informs the selection policy in subsequent iterations. Once planning time is exhausted, the path with the highest information gain is returned.

% with authors goes here
\begin{figure}[t]
\centering
\includegraphics[trim={.7cm 0cm .5cm 1.4cm},clip,width=\columnwidth]{figs/5_/Results1v3.pdf}
\caption{The Monte Carlo simulation results for the planners. The plots show the average percent reduction in entropy over the course of the simulations, and the shading shows the 95\% confidence intervals. IA-TIGRIS outperforms all of the baselines.}
\label{fig:mc_results}
\end{figure}

While MCTS is probabilistically guaranteed to converge to the optimal path \cite{mcts_ref_1}, it is constrained to actions within a predefined set of motion primitives. Its reliance on random sampling to estimate the future value of nodes can result in poor approximations, particularly in environments with sparse, localized pockets of high information gain. This limitation is especially pronounced in large search areas or scenarios with large budgets constraints, where estimating future node values becomes increasingly expensive. As a result, in such scenarios, MCTS is often implemented with a finite planning horizon, which can restrict its ability to account for long-term consequences or dependencies in the environment.

% This property of MCTS, which causes unguided exploration of the environment, leads to increased convergence times on the optimal path, as a result of a lot of budget being spent in exploring information sparse areas of the map. 
% Also, the computation time of MCTS increases exponentially with the depth of the search tree. The time complexity of MCTS is given by $\mathcal{O}(\frac{T}{t_\text{iter}} \cdot |A|^d)$. Here, $T$ is the total planning time and $t_\text{iter}$ is the time taken per iteration of the planning loop. $|A|$ is the number of actions and $d$ represents the average depth of the search tree. 

% The above limitations are not inconsequential in the context of performing informative path planning in large high-dimensional search spaces. We compare MCTS with \PlannerName, in \ref{}, and empirically demonstrate its drawbacks and how \PlannerName, is able to outperform MCTS in the context of the mission parameters we examine in this work.  

\subsubsection{Greedy}

For the greedy planner, we iterated through each cell within the search bounds and calculated the reward for a given cell $i$ as $g_i = R(X_i) / d_i$ where $R(X_i)$ is given through \eqref{equ:reward} and $d_i$ represents the Euclidean distance between the current position the robot at the current time $t$ and the closest viewpoint to the cell. To compute this viewpoint, the yaw between the current pose of the robot and the intersected cell is first calculated. Using the robot's sensor configuration and this yaw, $x$ and $y$ coordinates are calculated that view the cell at the desired flight altitude. With this formulation, the planner prioritizes regions with a high ratio of entropy to distance. This can lead to locally optimal choices that contradict with paths that lead to higher information gain over the entire trajectory. 

% without authors goes here
% \begin{figure}[t]
% \centering
% \includegraphics[trim={.7cm 0cm .5cm 1.4cm},clip,width=\columnwidth]{figs/5_/Results1v3.pdf}
% \caption{The Monte Carlo simulation results for the planners. The plots show the average percent reduction in entropy over the course of the simulations, and the shading shows the 95\% confidence intervals. IA-TIGRIS outperforms all of the baselines.}
% \label{fig:mc_results}
% \end{figure}


\begin{figure*}[t]
    \centering
    \begin{subfigure}[b]{0.99\textwidth}
        \centering
        \includegraphics[trim={0cm 0.3cm 0cm 0cm},clip,width=\textwidth]{figs/5_/Fig2v1_target.png}
        % \caption{Slice by targets}
        % \vspace{.1cm}
    \end{subfigure}
    
    \begin{subfigure}[b]{0.99\textwidth}
        \centering
        \includegraphics[trim={0cm 0cm 0cm 0cm},clip,width=\textwidth]{figs/5_/Fig2v1_sigma.png}
        % \caption{Slice by sigma }
    \end{subfigure}
    \caption{A comparison of the methods based on the number of sampled prior clusters and the standard deviation of sampled prior clusters. IA-TIGRIS is most effective compared to the baselines when there is high variation in the search space. As the search space prior information becomes more evenly spread out, the performance gap between the methods tends to decrease.}
    \label{fig:targets_sigmas}
\end{figure*}

\subsubsection{Random}

The random planner operates by iteratively sampling points within the defined search bounds and calculating the minimum-cost path to observe each sampled point. This process is repeated until the available budget is fully expended. The random planner does not utilize any prior information about the environment or target distribution. Additionally, it does not optimize the sequence of actions, instead treating each sampled point independently without considering the global structure of the search problem. This simplicity allows the random planner to highlight the performance benefits of more sophisticated methods by providing a lower-bound comparison for evaluation.

\subsubsection{Coverage}

The coverage planner generates a plan that systematically covers the entire search space using a straightforward lawn-mower pattern. The spacing between each pass is set to match the width of the projected observation footprint at 20\% from the bottom, ensuring that no grid cells are missed. This spacing also maintains a distance that enables high-quality sensor measurements. However, due to the size of the search spaces considered, the coverage planner spends significant time surveying empty regions. This approach results in inefficient use of the budget, as it prioritizes full coverage with safe sensor overlap, even in areas with little or no valuable information. While simple and robust, this method highlights the tradeoff between exhaustive coverage and efficient, targeted exploration.

% \subsubsection{Branch and Bound}
% The branch and bound baseline is based on motion primitive planning. In each future step the drone has a set of motion primitives with future states and each of these future states also has a set of motion primitives. In this way, a tree can be built with multiple path candidates. The path candidate with the highest information gain will be selected and form the output. 

% By adding branch and bound, there will be an estimation of a node's upper bound information reward, using the node's current information reward, updated information map and the remaining budget. If this upper bound is already lower than the information reward of any other node in the tree, the corresponding node will be closed and not expanded in the future to accelerate the expansion of the tree. 



\subsection{Tests and Analysis}
% To evaluate the efficacy of IA-TIGRIS compared to the baseline methods, we conduct Monte Carlo testing as well as analyze how the prior and budget affect the performance of each method. In all of these test cases, there are no time-based or priority rewards and have horizon lengths set to the full budget. All tests were performed using an Intel Xeon CPU E5-2620 v4 @ 2.10GHz.
To evaluate the efficacy of IA-TIGRIS against baseline methods, we perform Monte Carlo testing and analyze the impact of the prior and budget on the performance of each method. In all test cases, rewards are calculated using \eqref{equ:reward}, and horizon lengths are set to match the full budget. The tests are conducted on an Intel Xeon CPU E5-2620 v4 @ 2.10GHz, ensuring consistent computational conditions across all evaluations.

% Random sample across which parameters.

% Quantitative ideas. Look into number and std of prior (metric for this? std of grid cell values, mediuan, mean,). 
% Uniform prior? 
% Split distinct regions, not smooth. 
% Compare to coverage and amount of time to reach specific amount. 
% Compare with different budgets. 
% Repeatability test. 
% Graph size vs time. 
% Look at coverage with different altitudes or widths. Something that shows long horizon vs not nature of things?
% Shape of search space?
% Time/budget to get x\% of all info gain. Have to do moving horizon. 
% Targets detected? 

% Key thought for results where I show time, our optimization does not optimize for time, only final value. Key thing to show across the different budgets. 

% \BM{Qualitative. Nayana idea of plot with example sampled case. Should add one here.} 



\subsubsection{Monte Carlo Testing}
Our simulated testing environment is a $5000\times5000$ m square with Gaussian-distributed prior information randomly placed throughout the search space. The number of prior clusters was sampled uniformly between $[4,20]$, with standard deviations between $[60,450]$, and maximum value between $[0.05,0.5]$. 

The results of $100$ Monte Carlo tests are shown in Fig.~\ref{fig:mc_results}. IA-TIGRIS clearly outperforms the other methods, achieving nearly a $40\%$ greater reduction in entropy than the next best method. Early in the simulation, the greedy method initially gains information more quickly, as expected, but this does not translate to better long-term performance. Since our method optimizes for total information gain, it generates paths that maximize information collection over the entire budget. MCTS performed slightly worse than the greedy approach.

The random paths slightly outperformed the coverage paths. This is likely because the lawnmower strategy requires sufficient overlap between passes to avoid missing areas, and its long straight paths often lead to redundant observations due to the UAV’s forward-facing camera. Changing the heading of the UAV is beneficial to viewing more of the search space, which may explain why random paths performed better.

We also conducted Monte Carlo tests where either the number of prior clusters or their standard deviation was held constant to analyze how variations in the information map affect planner performance. The results, shown in Fig.~\ref{fig:targets_sigmas}, include two cases: the upper figure fixes the number of priors, while the lower figure fixes their standard deviation. All other agent and simulation parameters remained unchanged.


% The first thing to note from these results is that for all tests the proportional performance gap between IA-TIGRIS and the baselines increases as the number and standard deviation of the Gaussian priors decreases. As the search space becomes more uniformly filled with entropy in the information map, the need for longer-horizon planning decreases and other simple or random approaches can perform satisfactorily given the testing budget. As the information becomes more sparsely distribution in the space, such as when the information is contained in separated pockets of areas, there is a greater need to plan longer-horizon paths that reason about the given budget.
% \BM{Could have figures here or refer to others}

Across these tests, the performance gap between IA-TIGRIS and the baselines widens as the number and standard deviation of the Gaussian priors decrease. When entropy is more uniformly distributed across the search space, simpler methods perform reasonably well within the given budget. However, when information is concentrated in sparse, distinct regions, longer-horizon planning becomes essential. In such cases, IA-TIGRIS demonstrates a significant advantage by effectively reasoning about the budget and prioritizing high-value regions.

% Show plot of first plans expected info gain versus planning time. (plans not executed)


\subsubsection{Budget Analysis}
To evaluate the impact of budget constraints on performance, we conducted additional tests beyond our initial Monte Carlo experiments, evaluating budgets of $5000$ m, $10000$ m, $30000$ m, and $60000$ m. Table~\ref{tab:budgets} summarizes the average entropy reduction across these budgets.

\definecolor{tabfirst}{rgb}{1, 0.7, 0.7} % red
\definecolor{tabsecond}{rgb}{1, 0.85, 0.7} % orange
\definecolor{tabthird}{rgb}{1, 1, 0.7} % yellow
\begin{table}[t]
    \centering
    \resizebox{\linewidth}{!}{
    \begin{tabular}{l|ccccc}
    & $5000$ m & 10000 m  & 15000 m& 30000 m& 60000 m\\ \hline

    % \hline
    IA-TIGRIS  &  \cellcolor{tabfirst}$9.41\pm1.0$ &  \cellcolor{tabfirst}$18.28\pm1.8$ & \cellcolor{tabfirst}$25.36\pm2.3$ & \cellcolor{tabfirst}$41.08\pm2.9$ & \cellcolor{tabfirst}$58.85\pm2.9$ \\
    Greedy  &  \cellcolor{tabsecond}$6.99\pm0.8$ &  \cellcolor{tabsecond}$13.10\pm1.5$ & \cellcolor{tabsecond}$17.97\pm2.0$ & \cellcolor{tabthird}$30.00\pm2.3$ & \cellcolor{tabsecond}$49.38\pm3.5$ \\
    MCTS  &  \cellcolor{tabthird}$6.06\pm0.7$ &  \cellcolor{tabthird}$11.80\pm1.1$ & \cellcolor{tabthird}$17.11\pm1.4$ & \cellcolor{tabsecond}$30.21\pm2.2$ & \cellcolor{tabthird}$48.68\pm2.7$ \\
    Random  &  $2.19\pm0.3$ & $4.29\pm0.7$ & $6.61\pm0.6$ & $17.50\pm1.2$ & $22.47\pm1.4$ \\
    Coverage  &  $1.58\pm0.3$ &  $2.82\pm0.4$ & $4.09\pm0.7$ & $12.04\pm1.9$ & $16.77\pm2.4$ \\

    \end{tabular}
    }
    \caption{Monte Carlo testing results given different budgets. The values are the average percent reduction in entropy and the 95\% confidence bounds. \mbox{IA-TIGRIS} had the best performance for all budgets.}
    \label{tab:budgets}
\end{table}
%$\uparrow$ 

IA-TIGRIS consistently achieved the highest entropy reduction across all budget constraints, with a statistically significant margin over alternative methods. Greedy generally ranked second but was slightly outperformed by MCTS at the $30000$ m budget level. Greedy and MCTS exhibited comparable performance throughout the tests, with their results closely tracking each other. Consistent with our previous findings, Random and Coverage methods yielded the lowest results.


Among the tested methods, only IA-TIGRIS and MCTS explicitly incorporate budget constraints into their planning algorithms. Notably, at lower budgets ($5000$ m and $10000$ m), these methods achieved higher entropy reduction compared to the equivalent time steps ($200$ s and $400$ s) in the $15000$ m budget scenario shown in Fig.~\ref{fig:mc_results}. This improved performance stems from IA-TIGRIS's optimization of total path reward under budget constraints, contrasting with the myopic next-best-action approach of the greedy method. The remaining methods---Greedy, Random, and Coverage---maintain consistent behavior regardless of budget constraints, as their planning strategies do not account for resource limitations.


The performance gap between IA-TIGRIS and the next-best method varied with budget size, showing margins of $34.6\%$, $39.5\%$, $41.1\%$, $36.0\%$, and $19.2\%$ in ascending budget order. This gap widened through the first three budget levels as problem complexity increased, before declining significantly at higher budgets. This performance pattern suggests that implementing a planning horizon could enhance efficiency by limiting tree search depth, enabling the planner to prioritize path quality optimization over exhaustive space exploration.


% percent improved from next best
% 34.6, 39.5, 41.1, 36.0, 19.2
% reasons, too long horizon is a larger search space, so less quality paths closer. Or larger horizon, more packing in


% with authors goes here
\begin{figure}[t] 
    \centering
    \renewcommand\arraystretch{0} % Adjust the height between rows here
    \setlength{\tabcolsep}{1pt} % Adjust the column separation here
    \begin{tabular}{c}
        \begin{tikzpicture}
            \node[anchor=south west, inner sep=0] (image) at (0,0) {
                \includegraphics[width=0.9\linewidth]{figs/5_/google_earth_prior.png}
            };
            \begin{scope}[x={(image.south east)},y={(image.north west)}]
                % \fill[OrangeRed] (0.02, 0.03) circle (2pt); 
                % \fill[OrangeRed] (0.51, 0.04) circle (2pt); 
                % \fill[OrangeRed] (0.61, 0.04) arc (0:90:2pt); 
                \fill[Orange, opacity=0.8] (0.74, 0.45) circle (3pt); % Adjust 
                \fill[Orange, opacity=0.8] (0.27, 0.42) circle (3pt); % Adjust 
                \fill[Orange, opacity=0.8] (0.39, 0.63) circle (3pt); % Adjust 
            \end{scope}
        \end{tikzpicture} \\
        % \includegraphics[width=0.9\linewidth]{figs/5_/google_earth_prior.png} \\
        \\
        \includegraphics[width=0.9\linewidth]{figs/5_/google_earth_path.png} 
    \end{tabular}
    \caption{Google Earth screenshots illustrating the mission planning process and execution. Top: Areas of high entropy targeted for search are highlighted in red, representing regions with a binary occupied/unoccupied probability of 0.2. Three points of particular interest, each assigned a 0.5 probability, are marked in orange. Bottom: The executed drone flight path (yellow) shows the optimized path for maximum information gain across the search space.} 
    \label{fig:google_earth}
\end{figure}
\begin{figure}[t]
\centering
% https://docs.google.com/presentation/d/1RjI-QqHpBRLHN60UAxzmQYs4EaWaVCOoSBkEkA39kk0/edit?usp=sharing
\includegraphics[width=\columnwidth]{figs/5_/m600_labeled.jpg}
\caption{Hexarotor system (DJI M600 Pro) with onboard compute and camera. Left image shows drone on the ground, right image shows drone in flight.}
\label{fig:m600}
\end{figure}


\section{Field Deployments}\label{sec:field}


\subsection{Hexarotor Deployment}
The first field experiment that we present uses a hexarotor drone to cover an urban area shown in Fig.~\ref{fig:fig1}.
We designed this field experiment to simulate classifying where cars are within a search area.  
Hence, we set the plan request to focus on parking lots at the field test site (Fig.~\ref{fig:google_earth}, top), with the addition of three chosen grid cells within the parking lots being marked as having a higher uncertainty. The plan request boundaries and priors were created with GPS coordinates in Google Earth, exported as kml files, and then converted into our plan request message format. 

The following sections details the hardware, autonomy, and experimental results for our hexarotor deployments.

% without the authors goes here
% \begin{figure}[t] 
%     \centering
%     \renewcommand\arraystretch{0} % Adjust the height between rows here
%     \setlength{\tabcolsep}{1pt} % Adjust the column separation here
%     \begin{tabular}{c}
%         \begin{tikzpicture}
%             \node[anchor=south west, inner sep=0] (image) at (0,0) {
%                 \includegraphics[width=0.9\linewidth]{figs/5_/google_earth_prior.png}
%             };
%             \begin{scope}[x={(image.south east)},y={(image.north west)}]
%                 % \fill[OrangeRed] (0.02, 0.03) circle (2pt); 
%                 % \fill[OrangeRed] (0.51, 0.04) circle (2pt); 
%                 % \fill[OrangeRed] (0.61, 0.04) arc (0:90:2pt); 
%                 \fill[Orange, opacity=0.8] (0.74, 0.45) circle (3pt); % Adjust 
%                 \fill[Orange, opacity=0.8] (0.27, 0.42) circle (3pt); % Adjust 
%                 \fill[Orange, opacity=0.8] (0.39, 0.63) circle (3pt); % Adjust 
%             \end{scope}
%         \end{tikzpicture} \\
%         % \includegraphics[width=0.9\linewidth]{figs/5_/google_earth_prior.png} \\
%         \\
%         \includegraphics[width=0.9\linewidth]{figs/5_/google_earth_path.png} 
%     \end{tabular}
%     \caption{Google Earth screenshots illustrating the mission planning process and execution. Top: Areas of high entropy targeted for search are highlighted in red, representing regions with a binary occupied/unoccupied probability of 0.2. Three points of particular interest, each assigned a 0.5 probability, are marked in orange. Bottom: The executed drone flight path (yellow) shows the optimized path for maximum information gain across the search space.} 
%     \label{fig:google_earth}
% \end{figure}
% \begin{figure}[t]
% \centering
% % https://docs.google.com/presentation/d/1RjI-QqHpBRLHN60UAxzmQYs4EaWaVCOoSBkEkA39kk0/edit?usp=sharing
% \includegraphics[width=\columnwidth]{figs/5_/m600_labeled.jpg}
% \caption{Hexarotor system (DJI M600 Pro) with onboard compute and camera. Left image shows drone on the ground, right image shows drone in flight.}
% \label{fig:m600}
% \end{figure}

\subsubsection{Hardware System}
The hardware consists of the DJI M600 Pro, shown in Fig.~\ref{fig:m600}, along with the physical sensing and onboard computer payload. The DJI M600 Pro contains a flight controller that handles pose estimation and position-based control. The DJI M600 Pro’s flight controller also handles teleloperation if human intervention is necessary. Beneath the drone's base, we mount a custom hardware payload.
That payload consists of an onboard computer, a Jetson Xavier, to run the autonomy software shown in Fig.~\ref{fig:functional_diagram}.
The payload also contains a downward-facing a camera for sensing the environment. The camera is a Seek S304SP thermal camera.
The camera intrinsics are used to calculate the frustum's intersection with the search map's cells in IA-TIGRIS.

% without authors goes here
\begin{figure}[t]
\centering
% https://lucid.app/lucidchart/f750ddb4-2809-4773-8361-d5fbb1ba49eb/edit?viewport_loc=-257%2C-116%2C2219%2C1140%2C0_0&invitationId=inv_56e8a3a9-e8cf-4cad-a280-48bd967ff651
\includegraphics[trim={0cm 0cm 0cm 0cm},clip,width=\columnwidth]{figs/5_/functional_diagram.jpeg}
\caption{Functional diagram of the DJI M600 Pro autonomy software.}
\label{fig:functional_diagram}
\end{figure}
\begin{figure}[b]
    \centering
    \begin{subfigure}[b]{0.48\columnwidth}
        \centering
        \includegraphics[width=1.0\linewidth]{figs/5_/field_test_altitude_over_time.png}
        \caption{}
        \label{fig:m600_altitude_over_time}
    \end{subfigure}
    \begin{subfigure}[b]{0.48\columnwidth}
        \centering
        \includegraphics[width=1.0\linewidth]{figs/5_/field_test_entropy_over_time.png}
        \caption{}
        \label{fig:m600_entropy_over_time}
    \end{subfigure}
    \caption{The results for our hexarotor field deployment. (a) Plot of flown altitude over time, showing large variation throughout the experiment. (b) Reduction in entropy percentage over time of field experiment.}
\end{figure}

\subsubsection{Autonomy System}
Fig.~\ref{fig:functional_diagram} illustrates the functional system diagram for the real world field test on the DJI M600. The user specifies the initial plan request prior to takeoff. The TIGRIS planner makes an initial plan on that plan request and sends a global path to the waypoint manager. The waypoint manager tracks the current waypoint within the plan and sends the next waypoint to the DJI software development kit, which then sends actuation commands to the motors. The position of the drone is used to calculate the distance from the drone to the ground and sends that distance parameter to the sensor model. The sensor model's true positive and false positive rate is used to calculate the per-cell entropy updates in the search map manager. The search map manager publishes the current information map, and the replanning node sends an updated plan request to the IA-TIGRIS planner every ten seconds.

The drone started at an altitude of $50$ m above the origin of the reference frame. The informed sampler in IA-TIGRIS was set to add states at altitudes of either $30$ m or $60$ m, creating a trade-off between observation area and detector accuracy. The budget was $2000$ m, the planning horizon was $600$ m, and the planning time was $10$ seconds. 

% % without authors goes here
% \begin{figure}[t]
% \centering
% % https://lucid.app/lucidchart/f750ddb4-2809-4773-8361-d5fbb1ba49eb/edit?viewport_loc=-257%2C-116%2C2219%2C1140%2C0_0&invitationId=inv_56e8a3a9-e8cf-4cad-a280-48bd967ff651
% \includegraphics[trim={0cm 0cm 0cm 0cm},clip,width=\columnwidth]{figs/5_/functional_diagram.jpeg}
% \caption{Functional diagram of the DJI M600 Pro autonomy software.}
% \label{fig:functional_diagram}
% \end{figure}
% \begin{figure}[b]
%     \centering
%     \begin{subfigure}[b]{0.48\columnwidth}
%         \centering
%         \includegraphics[width=1.0\linewidth]{figs/5_/field_test_altitude_over_time.png}
%         \caption{}
%         \label{fig:m600_altitude_over_time}
%     \end{subfigure}
%     \begin{subfigure}[b]{0.48\columnwidth}
%         \centering
%         \includegraphics[width=1.0\linewidth]{figs/5_/field_test_entropy_over_time.png}
%         \caption{}
%         \label{fig:m600_entropy_over_time}
%     \end{subfigure}
%     \caption{The results for our hexarotor field deployment. (a) Plot of flown altitude over time, showing large variation throughout the experiment. (b) Reduction in entropy percentage over time of field experiment.}
% \end{figure}

\subsubsection{Experimental Results}


The bottom image of Fig.~\ref{fig:google_earth} shows the path selected by IA-TIGRIS in the search area. The figure highlights how the planner dynamically adjusts altitudes over time to balance coverage and sensing resolution, maximizing information gain. Higher altitudes allow for broader area coverage, while lower altitudes provide more detailed observations where needed. Additionally, the planner prioritizes revisiting the three regions of higher uncertainty, recognizing the need for repeated observations reduce entropy. This adaptive strategy ensures that uncertain areas receive sufficient attention to improve the belief map. As a result, the entropy of the information map decreases to near zero by the end of the mission, as shown in Fig.~\ref{fig:m600_entropy_over_time}, indicating that the planner has effectively gathered the necessary information. This behavior demonstrates the planner’s ability to optimize sensing actions, balancing altitude selection, revisit frequency, and exploration to maximize mission success.

\begin{figure}[t]
\centering
% \includegraphics[width=2.5in]{fig1}
\includegraphics[trim={4cm 4cm 0cm 4cm},clip,width=\columnwidth]{figs/5_/TL1.jpg}
\caption{Fixed-wing platform used for autonomous flights with an onboard camera pitched at 10 degrees\cite{alarewebsite}}
\label{fig:tl1}
\end{figure}






\subsection{Fixed-wing Deployments}

Our proposed approach was extensively tested on the fixed-wing AlareTech TL-1 UAV, shown in Fig.~\ref{fig:tl1}. The UAV is equipped with an onboard camera pitched at 10 degrees, which introduces a more challenging planning problem due to the non-holonomic motion model and the camera's field of view. Over more than 20 flight hours and 100 flights running IA-TIGRIS, we validated our approach with the objective to search for objects of interest in a large search space across a variety of test scenarios, including different terrain types, varying environmental conditions, and diverse target distributions. An example mission from these tests is shown in Fig.~\ref{fig:fwd}. In this scenario, the planner was given the search bounds and a designated high-priority region. The resulting flight path prioritized revisiting the high-priority area twice, optimizing sensor use and ensuring maximum information gain. This strategy led to the successful detection of the object of interest, with its estimated position marked by the red dot in the figure. 

The map on the upper right in Fig.~\ref{fig:fwd} shows the information map after plan execution was complete. Due to the UAV's limited budget, the upper right and lower left corners of the map are not searched by the agent. The budget is instead utilized to search over the area of higher priority two times. Compared to the paths in Fig.~\ref{fig:google_earth}, we observe that the paths for the fixed wing are smoother and have a larger turning radius, demonstrating how IA-TIGRIS respects the motion constraints of the vehicle. We can also see the effect of wind on the path execution, where the flown path shown in green deviates from the planned path shown in yellow. This illustrates the importance of online planning in the cases where this deviation is large or would accumulate over the course of a longer mission and cause the expected observed area to be much different than actual observed area. 

\begin{figure}[t]
\centering
% \includegraphics[width=2.5in]{fig1}
% [trim={left bottom right top},clip]
\includegraphics[trim={3.0cm, 1.0cm, 3.0cm, 1.0cm},clip,width=\columnwidth]{figs/5_/ONRFig_v3.pdf}
\caption{An example path generated for the fixed-wing platform conducting a large-area search for an object of interest. The larger black rectangle denotes the search bounds, while the smaller black rectangle highlights a region of higher uncertainty. The red dot marks the estimated position of the detected object based on image detections. The upper-right map displays the information state after planning is complete, while the middle plot shows the percent change in entropy over mission time. The flown path illustrates a balance between allocating resources to the high-priority region and exploring other areas within the search space.}
\label{fig:fwd}
\end{figure}

% Also tested extensively on the AlareTech TL-1 (citation?) tube launched UAV seen in Fig.~\ref{fig:tl1}.

% Talk about amount of flights, hours. Platform. Compute. Show visualization fo example flight. Talk about objects of interest in a broad sense (no mention of water/ocean/land for targets). Follow similar figure format as previous section. Main thing we want to highlight is the differences introduced in plans by having a fixed-wing platform compared to a drone. Include image of Alare TL-1 somewhere.

% One big figure showing all the info we want to convey. 

% \BM{Pitch 10 degrees, onboard computer type, etc}


% \subsection{VTOL?}
% what would it bring?

