

% 顺序改变 模型的回答表现发生改变的例子



% 指令遵循 尤其是多约束的指令遵循很重要 
% LLM已经被广泛地应用于各个场景中,为了达到用户desirable 指令遵循很重要
Large language models (LLMs) have made impressive progress in massive natural language tasks~\cite{wan2024tnt, zhang2024linkner} and have been applied to various real-world scenarios~\cite{bai2023qwen, bi2024deepseek}. To achieve satisfactory performance, it is crucial for LLMs to understand the user's instructions and convey desired outputs, which is known as the Instruction Following capacity of LLM~\cite{yin2023llm, xu2024wizardlm}. 
% 介绍一下什么是多约束的复杂指令


% 实际场景中用户的指令往往是具有多种约束的复杂指令 pose 挑战to llm的指令遵循 这使得对于多约束的复杂指令的遵循问题成为了大模型的一个重点（？）
In practice, instructions are usually incorporated with multiple constraints of different types, e.g., format constraint which limits the model's output to a specific format. Nevertheless, existing LLMs often struggle to follow multi-constraint instructions, making multi-constraint instruction following an obstacle to hinder LLMs' real-world application~\cite{wen2024benchmarking, yin2023llm}.


\begin{figure*}[t] 
    \centering
            \includegraphics[width=1\textwidth]{method.pdf}
    % \captionsetup{font={small}} 
    \caption{The procedure of the probing task. First, we synthesize the initial instructions by sampling seed instructions and corresponding constraints. Then, we obtain instructions with different constraint orders by reordering the incorporated constraints. Finally, we conduct model inference on single and multi-round settings.}
    \label{fig:method}
\end{figure*}

% 很多工作证明llm在follow instruction时，描述xx的位置是有senstive的
% lost in the middle evaluation 时的bias
% since 多约束指令存在。。。 天然地存在position的问题无论是single multi-turn shown fig1 遵循不一样
Recently, a lot of works have demonstrated that LLMs are sensitive to the position of the referred context in many tasks, such as multi-document question answering, text evaluation, and list-wise ranking~\cite{liu2024lost,zheng2023judging, tang2024found}. Since there are usually multiple constraints coexisting in the complex instruction, the position bias problem is also significant in multi-constraint instructions. As shown in Fig.~\ref{fig:intro}, in the single-round scenario, the LLM's performance varies significantly when presented with instructions that have different constraint orders, even though the two instructions are semantically identical. When it comes to the multi-round scenario, different constraint orders impose different impacts on the intermediate responses, thus inevitably leading to a discrepancy in the quality of the final responses.

% however 现在没有任何一篇工作systematically 研究这个问题, to bridge this gap, we propose xxx we mainly focus on xx research questions
Nevertheless, the position bias of constraint orders in the multi-constraint instruction following remains an under-explored problem. Existing work manually assigns difficulty to different constraints based on a predefined rule and orders the constraints according to their difficulty. They empirically demonstrate the existence of LLMs' performance fluctuation brought by different constraint order~\cite{chen2024sifo}. However, on the one hand, handcraft difficulty categorization fails to reflect the real difficulty disparity of different constraints~\cite{dentella2024testing, srivastava2023beyond}. On the other hand, they merely analyze the constraint order in a qualitative way, lacking a quantitative metric to measure the disparity of constraint order. Additionally, none of the existing works has provided an intuitive explanation for the position bias in multi-constraint instructions. It remains unclear how the LLMs handle instructions with different constraint orders.

% The investigation is mainly hindered by three main research questions: (1) \textit{How do we quantitively measure the disparity between different constraint orders}? Existing work has found that reordering the constraints based on their difficulty will lead to a performance fluctuation of the LLMs~\cite{chen2024sifo}. However, on the one hand, they manually assign difficulty to different constraints based on a predefined rule, which is not rational due to the difference between the human and LLMs to handle the constraints~\cite{dentella2024testing, srivastava2023beyond}. On the other hand, their attempt is fairly qualitative, leaving the research question unexplored. (2) \textit{How do we obtain instructions incorporated with various constraint orders}? Existing datasets mainly focus on the complexity of instructions or the precision of evaluation, lack of position information of the constraints~\cite{jiang2023followbench, qin2024infobench}. (3) \textit{How do we explain the position bias brought by different constraint orders}? None of the existing works offers an intuitive analysis of this.

% ~\cite{dentella2024testing, srivastava2023beyond}

% % 我们提出一个metric 解释一下这个metric 一句话介绍一下怎么定义的难度
% To answer the first question, existing work~\cite{chen2024sifo} manually designates the constraints into three categories, attributing their difficulty to the context length the constraint will influence. However, it is not rational to directly apply handcrafted difficulty categorization to the LLM due to the inconsistency between the LLM and humans to handle the same constraint~\cite{dentella2024testing, srivastava2023beyond}. 


To address all the problems above, we systematically investigate the position bias problem in the multi-constraint instructions. First, we propose a novel metric called the Constraint Difficulty Distribution Index (CDDI) to quantitatively describe the disparity of constraint order from the perspective of constraint difficulty. We leverage the accuracy of the LLM to quantify the difficulty of different constraints, thus precisely reflecting their disparity. Then, for a thorough study of the position bias problem, we design a probing task. As shown in Fig.~\ref{fig:method}, we construct a large number of multi-constraint instances with different constraint orders and explore two practical scenarios: single-round inference and multi-round inference. Our experiments find existing LLMs commonly perform better with the ``hard-to-easy'' constraint orders, i.e., possibly placing harder constraints in former positions. Finally, to make an intuitive explanation of our findings, we resort to a gradient-based method~\cite{wu2023language}. We visualize the importance of different constraints located in different positions. We observe that the constraint order will affect how the LLM handle the constraints and is highly correlated to the LLM's performance on a specific constraint.

% 我们的贡献如下
In summary, our main contributions are as follows: (1) We are the first to systematically investigate the position bias problem in multi-constraint instruction following. (2) We propose a novel CDDI metric to quantify the disparity of different constraint orders in the multi-constraint instructions. (3) Through extensive experiments, we find that existing LLMs can achieve a better performance when presented with constraints in ``hard-to-easy'' orders. This finding can be generalized in both single-round and multi-round scenarios, regardless of the architecture of LLM, the size of LLM's parameters and the number of constraints. (4) Our explanation study explores how the LLMs assign attention when provided with instructions in different constraint orders and demonstrates the significant correlation between the attention patterns and the LLMs' performance on specific constraints.
% 1.first to systematically investigate the position bias in complex instrutcion following 
% 2.we propose a metric to automatically evaluate （）
% 3. through extensive experiments we find hard-to-easy 是一个最好的 （） in both single and multi-turn complex instruction following. we further provide 可解释
% 4. based on our findings we propose 



% Our findings reveal the fact that the thinking process is crucial not only in the field of mathematics and code generation but also in complex especially multi-constraint instruction following. The LLM may achieve a better performance by introducing a deeper thought about the constraints in the instructions. For example, it may consider the difficulty of different constraints and selectively follow some of them first. We hope our work can shed light on the further direction of complex instruction following. 