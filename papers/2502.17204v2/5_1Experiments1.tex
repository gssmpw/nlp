\begin{figure*}[t] 
    \centering
        \includegraphics[width=0.9\textwidth, height=5cm]{model_performance_single.pdf}
    % \captionsetup{font={small}} 
    \caption{The performance of different LLMs in the single-round inference. The left and right figures show the results with the number of constraints $n$ set to 7 and 9, respectively. With the increase of the CDDI, the constraint order changes from ``easy-to-hard'' to ``hard-to-easy''.}
    \label{fig:7cons}
\end{figure*}

\begin{figure*}[t] 
    \centering
        \includegraphics[width=0.9\textwidth,height=5cm]{model_performance_multi.pdf}
    % \captionsetup{font={small}} 
    \caption{The performance of different LLMs in the multi-round inference. The left and right figures show the results with the number of constraints $n$ set to 7 and 9, respectively. With the increase of the CDDI, the constraint order changes from ``easy-to-hard'' to ``hard-to-easy''.}
    \label{fig:multi_7cons}
\end{figure*}

\input{main_res_7cons}

\subsection{Experiment Setup}
\paragraph*{Models} For our probing task, to ensure the generalizability of our study, we conduct experiments on both closed and open-source LLMs with varying architectures and parameter sizes. Specifically, we introduce the following models: (1) LLaMA3-8B-Instruct and LLaMA3-70B-Instruct~\cite{dubey2024llama}. (2) LLaMA2-13B-Chat~\cite{touvron2023llama}. (3) Mistral-7B-Instruct~\cite{jiang2023mistral}.\footnote{We use the latest v0.3 version.} (4) Qwen2.5-7B-Instruct~\cite{yang2024qwen2}. (5) GPT4o-mini~\cite{achiam2023gpt}.

% \footnote{We use the default version, i.e., the gpt-4o-mini-2024-07-18}

\paragraph*{Datasets} We construct various multi-constraint instructions with different constraint orders (Sec.\ref{method}). We empirically set the number of constraints ${n}$ to 7. To ensure the diversity and complexity, we set the number of constraint combinations $n_{cc}$ to 10 and the number of difficulty distributions $n_{dd}$ to 12, finally obtaining $200\times10\times12=24\text{K}$ samples. To verify the influence of constraint number, we also conduct experiments on the setting when ${n=9}$. The statistic of the data for the probing task is provided in Fig.~\ref{fig:statistic}.







\subsection{Results}
\paragraph*{LLMs prefer to “hard-to-easy” constraint distribution.} As shown in Fig.~\ref{fig:7cons}, most of the LLMs exhibit a dramatic performance fluctuation on instructions with varying constraint distributions. When the constraint number is set to 7, the LLaMA3-8B-Instruct and Qwen2.5-7B-Instruct show approximately 7$\%$ and 5$\%$ performance disparity in extreme situations. This indicates the vulnerability of existing LLMs to the position bias brought by the constraint order. Also, the LLMs tend to be more performant to instructions with higher CDDI values. Even the LLaMA3-70B-Instruct exposes a clear preference for higher CDDI value as the number of constraints increases to 9, demonstrating that ``hard-to-easy'' is a superior constraint distribution for existing LLMs.

\paragraph*{Multi-round inference exhibits more severe position bias compared with the single-round inference.} The LLMs' performance in multi-round inference is presented in the Fig.~\ref{fig:multi_7cons}. Compared with the results in the single-round inference, the performance gap becomes more prominent. All the LLMs gain approximately 10$\%$ improvement on C$\_$level accuracy. Surprisingly, the  LLaMA3-8B-Instruct and LLaMA3-70B-Instruct achieve approximately 25$\%$ performance improvement by changing the constraint distribution from ``easy-to-hard'' (CDDI=-1) to ``hard-to-easy'' (CDDI=1). This indicates that the LLMs are more sensitive to the position bias problem in a multi-round scenario.

\paragraph*{LLMs perform better in multi-round inference when provided with the instructions in appropriate constraint order} Comparing the results in single-round (Fig.~\ref{fig:7cons}) and multi-round inference (Fig.~\ref{fig:multi_7cons}), we observe that the LLMs reach better performance if the incorporated constraints are arranged in an appropriate order. Specifically, when the CDDI value is negative, the performance of LLMs in multi-round inference lags behind that in single-round inference. Nevertheless, with the increase of the CDDI value, the LLMs can achieve superior performance in multi-round inference and reach their best performance in CDDI=1. An exception is the Mistral-7B-Instruct-v0.3. We attribute this to its inferiority in processing multi-round information~\cite{chen2024sifo}.

\paragraph*{Position bias varies in different types of constraints.} We present the performance of the LLaMA3-8B-Instruct across different types of constraints in Tab.~\ref{tab:main}. As observed, with the increase of the CDDI value, the model's performance across most constraint types shows an upward trend except for Startend and Content, indicating that not all the constraints can benefit from the ``hard-to-easy'' constraint distribution in single-round inference. We make a more comprehensive explanation study in Sec.~\ref{sec:experiment2} for further investigation. Regarding the multi-round inference, the model's performance only exhibits a drop tendency in the Length type as the CDDI value increases, indicating that the LLMs struggle to generate a length-controlled final response when the length constraint is applied early in the multi-round inference~\cite{yuan2024following}.








% 放附录 稳定性实验 选一个组合（tau=-0.05）跑3次证明表现差不多

\input{sensitivity}

\subsection{Robustness of CDDI}
Since the CDDI is calculated by comparing the concordant and discordant pairs of two different constraint orders, there are usually multiple constraint orders sharing the same CDDI value. Therefore, we conduct a testing experiment to assess whether the LLM exhibits significant fluctuations across different constraint orders with the same CDDI value. Specifically, we set the CDDI to -0.05, a value that includes the most constraint orders in our setting, and conduct single-round inference for 3 times. The experiment results are shown in Tab~\ref{tab:sensitivity}. We calculate the P-value of the data, finding that the P-value is much larger than 0.05. This indicates that the fluctuation of LLM's performance is negligible among different constraint orders in the same CDDI value.


