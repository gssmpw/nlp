
\documentclass[sigconf=true, nonacm=true, review=false, anonymous = false]{acmart}

\AtBeginDocument{%
  \providecommand\BibTeX{{%
    Bib\TeX}}}



% \copyrightyear{2025}
% \acmYear{2025}
% \setcopyright{acmlicensed}
\setcopyright{none}
% \acmConference[GECCO '25]{2025
% Genetic and Evolutionary Computation Conference}{July xx,
% 2025}{Malaga, Spain}
% \acmBooktitle{2025 Genetic and Evolutionary Computation Conference
%  (GECCO '25)}
% \acmPrice{15.00}






\usepackage{multirow}

\usepackage[ruled,vlined]{algorithm2e}
\usepackage{subcaption}
\usepackage{xcolor}


\newcommand{\carola}[1]{\textbf{\textcolor{red}{Carola: #1}}} 
\newcommand{\elena}[1]{\textbf{\textcolor{blue}{Elena: #1}}} 
\newcommand{\ml}[1]{\textbf{\textcolor{cyan}{ML: #1}}} 
\begin{document}


\title{Cascading CMA-ES Instances for Generating Input-diverse Solution Batches}%Cascading CMA-ES Instances for Input-diverse Solution Batches

\author{Maria Laura Santoni}
\orcid{0009-0007-7389-2555}
\affiliation{
  \institution{Sorbonne Universit\'e, CNRS, LIP6}
  \city{Paris}
  \country{France}}
\email{maria-laura.santoni@lip6.fr}

\author{Christoph DÃ¼rr}
\orcid{0000-0001-8103-5333}
\affiliation{
  \institution{Sorbonne Universit\'e, CNRS, LIP6}
  \city{Paris}
  \country{France}}
\email{christoph.durr@lip6.fr}

\author{Carola Doerr}
\orcid{0000-0002-4981-3227}
\affiliation{
  \institution{Sorbonne Universit\'e, CNRS, LIP6}
  \city{Paris}
  \country{France}}
\email{carola.doerr@lip6.fr}

\author{Mike Preuss}
\orcid{0000-0003-4681-1346}
\affiliation{
  \institution{Universiteit Leiden}
  \city{Leiden}
  \country{The Netherlands}}
\email{m.preuss@liacs.leidenuniv.nl}

\author{Elena Raponi}
\orcid{0000-0001-6841-7409}
\affiliation{
  \institution{Universiteit Leiden}
  \city{Leiden}
  \country{The Netherlands}%\\
}
\email{e.raponi@liacs.leidenuniv.nl}



\renewcommand{\shortauthors}{Santoni et al.}
\newcommand{\R}{\mathbb{R}}

\begin{abstract}

Rather than obtaining a single good solution for a given optimization problem, users often seek alternative design choices, because the best-found solution may perform poorly with respect to additional objectives or constraints that are difficult to capture into the modeling process.

Aiming for batches of diverse solutions of high quality is often desirable, as it provides flexibility to accommodate post-hoc user preferences. At the same time, it is crucial that the quality of the best solution found is not compromised.

One particular problem setting balancing high quality and diversity is fixing the required minimum distance between solutions while simultaneously obtaining the best possible fitness.
Recent work by Santoni et al. [arXiv 2024] revealed that this setting is not well addressed by state-of-the-art algorithms, performing in par or worse than pure random sampling. 

Driven by this important limitation, we propose a new approach, where parallel runs of the covariance matrix adaptation evolution strategy (CMA-ES) inherit tabu regions in a cascading fashion.   
We empirically demonstrate that our CMA-ES-Diversity Search (CMA-ES-DS) algorithm generates trajectories that allow to extract high-quality solution batches that respect a given minimum distance requirement, clearly outperforming those obtained from off-the-shelf random sampling, multi-modal optimization algorithms, and standard CMA-ES. 

\end{abstract}


\begin{CCSXML}
<ccs2012>
<concept>
<concept_id>10010147.10010178.10010205.10010209</concept_id>
<concept_desc>Computing methodologies~Randomized search</concept_desc>
<concept_significance>500</concept_significance>
</concept>
</ccs2012>
\end{CCSXML}

\ccsdesc[500]{Computing methodologies~Randomized search}


\keywords{Evolutionary Computation, Diversity, Multi-modal Optimization}

\maketitle

\section{Introduction}
Unlike traditionally taught in basic optimization courses, where the focus is on identifying a single solution of best-possible quality, practical optimization problems often demand for a different perspective. In real-world optimization scenarios, returning only one global solution is often undesirable, as the problem modeling may neglect constraints or objectives that are hard to formalize.

Instead, providing batches of diverse alternative high-quality solutions is crucial, as they allow for post-hoc choices based on the compromises a decision-maker must consider when deviating from a single proposed solution. 

An archetypal example is engineering design, where certain manufacturing constraints and costs are challenging to model into the optimization problem. Thus, final expert judgment is needed before deciding which designs are kept for more advanced stages of the development process.  

In such settings, it is crucial to provide a portfolio of diverse 
solutions to designers~\citep{raponi_kriging-assisted_2019,dommaraju_identifying_2019,yousaf_similarity-driven_2023,bujny_learning_2023}. 

However, ensuring that the proposed solutions are not only diverse but also include the best possible option is critical to enhance the utility of such methods for users.


Similar questions have been investigated across various subfields of optimization, though from perspectives that differ from the focus of this paper. For instance, Evolutionary Diversity Optimization (EDO)~\citep{ronaldFindingMultipleSolutions1995,zechmanEvolutionaryAlgorithmGenerate2004} focuses on evolving sets of solutions that meet a fixed quality threshold while maximizing diversity. Quality Diversity (QD)~\citep{DBLP:journals/firai/PughSS16,DBLP:journals/tec/CullyD18} seeks to illuminate the solution space by exploring diverse niches in the feature space and maximizing quality within each niche. Similarly, Multimodal Optimization (MMO)~\citep{Preuss2021} aims to identify multiple global and local optima by exploring various modes in the search space. 
A recent study by Santoni et al. in~\citep{santoni2024illuminatingdiversityfitnesstradeoffblackbox} explores the trade-off between input-space diversity and quality in batches of equally weighted solutions. Their results highlight that the histories generated by default approaches, e.g. MMO algorithms, are often insufficient for extracting high-quality and diverse batches of solutions under a distance constraint in the input space, which highlights the need for targeted algorithm design for this optimization scenario.

\textbf{Our Contribution:} Motivated by the findings in~\cite{santoni2024illuminatingdiversityfitnesstradeoffblackbox}, we propose a new algorithm based on the covariance matrix adaptation evolution strategy (CMA-ES)~\citep{hansen_reducing_2003}, which we extend by a cascading diversity mechanism to respect an imposed minimum distance requirement. Whereas~\cite{santoni2024illuminatingdiversityfitnesstradeoffblackbox} studies the trade-off between diversity and quality in batches of equally important solutions extracted from different initial portfolios, our approach provides a batch of $k$ solutions where the best solution is explicitly identified as a leader, complemented by $k-1$ alternative options. This modification aligns with the practical need to guarantee the availability of the optimal solution for users alongside diverse alternatives.



Following the approach in~\citep{santoni2024illuminatingdiversityfitnesstradeoffblackbox}, we consider the Euclidean distance as the input diversity metric to enforce the minimum distance requirement. This choice provides a clear and practical proof of concept. However, our approach is flexible and can easily incorporate any problem-specific diversity metric, depending on the application context. 
% address diversification, CMA-ES-Diversity Search (CMA-ES-DS) algorithm. Furthermore, we 
Using these requirements, we compare the batches extracted from the trajectory generated by our CMA-ES-Diversity Search (CMA-ES-DS) algorithm against those obtained through MMO algorithms, random sampling, and standard CMA-ES. We also compare three different ways of extracting the batches from the full search trajectories, (1) an exact but computationally expensive approach implemented using the Gurobi solver~\citep{gurobi}, (2) a faster greedy heuristic proposed in~\citep{santoni2024illuminatingdiversityfitnesstradeoffblackbox}, and (3) an even simpler ``clearing''  approach that performs a single pass over the trajectory to greedily add points that satisfy the minimum distance requirement with respect to the already selected ones, i.e., that are at distance at least $d_{\min}$ from each of the points already included in the batch. The overall process is illustrated in Fig.~\ref{fig:process_phases}. In Phase 1, an initial portfolio of $T$ points is created; through random sampling or as the trajectory of an optimization algorithm. In Phase 2, a batch of
$k$ points is extracted from this portfolio. Finally, in Phase 3, the decision maker uses this batch to make further selection or adjustments to the proposed solutions in the batch, taking into account additional objectives and constraints. This latter phase is not further addressed in our work; i.e., we focus on Phases 1 and~2. 
%
\begin{figure}[t] \center
    \includegraphics[trim=5.5cm 2.1cm 5.5cm 7.5cm, clip, width=\columnwidth]{images/3_phases.pdf}
      \caption{Three-phase optimization process: Phases 1 and 2 (covered in this paper) are in full color, while the final phase (beyond this work) is in a lighter shade.}
    \label{fig:process_phases}
\end{figure}

We empirically evaluate CMA-ES-DS on the 24 BBOB functions~\citep{hansen2021coco} in dimensions $d\in\{2,5,10\}$, using a budget of $T\in\{1k, 10k\}$ function evaluations and at least three different distance requirements per setting. These trajectories are compared to five off-the-shelf methods (random sampling, default CMA-ES, and three multi-modal optimization algorithms). We show that our algorithm generates portfolios from which superior batches of solutions can be extracted across the diverse settings, with particularly pronounced improvements observed in higher dimensions and under low-budget constraints, where the trade-off between diversity and quality becomes more challenging.



\textbf{Related work:} We call the process used in the second phase a ``clearing'' process, inspired by the clearing scheme introduced by Petrowski in~\citep{542703}. This scheme has proven effective across various optimization applications where maintaining diversity and exploring multiple solutions is relevant. For instance, it has been coupled with methods like TuRBO~\citep{eriksson2019scalable} in Bayesian optimization to discover diverse solutions~\citep{maus2023discoveringdiversesolutionsbayesian}. In the context of Multimodal Multi-objective Evolutionary Algorithms (MMMOEAs), the clearing process has been applied to maintain diversity across Pareto fronts~\citep{WANG2022100976}. Similarly, clearing-based strategies have been integrated into Differential Evolution (DE) to address multimodal optimization challenges~\citep{10.1007/978-3-642-30976-2_42}. Variants of the clearing approach, such as the Valley-Adaptive Clearing Scheme, have been employed in evolutionary search to enhance solution diversity in multimodal optimization~\citep{5363222}.


\textbf{Reproducibility:} The code for reproducing our experiments, along with the whole set of figures are available on GitHub~\citep{code1}.

\section{Problem Statement}
\label{sec:probstat}
\textbf{The general problem.} 
Building on the ideas presented in~\citep{santoni2024illuminatingdiversityfitnesstradeoffblackbox}, we adapt the general problem to address a slightly different objective. Specifically, we aim to construct a final batch of $k$ solutions that does not only satisfy a minimum pairwise distance constraint but also adheres to a lexicographic ordering of quality. In this ordering, the first solution is the best (ideally approximating the quality of the global optimum as well as possible), serving as a \textit{leader}, followed by $k-1$ alternative solutions. 

Given a (possibly unknown) function $f:S \subseteq \R^D \rightarrow \R$, a minimum distance requirement $d_{\min}>0$, and a batch size $k$, our problem is to find a collection $X^* = \{x^1, \ldots, x^k\} \subseteq S$ such that the pairwise (Euclidean) distance between any two points $x^i$ and $x^j$ with $i \neq j$ satisfies $d(x^i, x^j) \geq d_{\min}$ and such that: (i) the first point $x^1$ is the best possible solution with respect to $f$ (i.e., $x^1 = \arg\min_{x \in S} f(x)$), and (ii) the batch of $k$ suggested solutions $x^1, \ldots, x^k$ minimize the average objective value \( \sum_{i=1}^k f(x^i) / k \). 

We note that our problem could be interpreted as a multi-objective one, with the solution quality of the leader as first objective and that of the entire batch as second. However, we are not (or more precisely, not here in this work) interested in the classical multi-objective way of exploring the Pareto front formed by these two objectives. Instead, we prioritize the quality of the leader while ensuring diversity among the latter and the alternatives.

\textbf{Constructing the batch of $k$ solutions.} As in~\citep{santoni2024illuminatingdiversityfitnesstradeoffblackbox}, we first construct initial portfolios $X$ containing $T$ evaluated points. These portfolios are either randomly sampled points or the full search trajectory of an iterative black-box optimization algorithm using of total budget of $T$ function evaluations. 
% However, we adapt the subset selection problem to incorporate the lexicographic ordering constraint, as follows:
From these portfolios $X$, we then seek to identify a feasible batch of $k$ solutions that are $d_{\min}$ far apart from another. Formally, this can be modeled as a subset selection problem:  
\begin{equation}
\label{eq:problem_statement}
\begin{aligned}
\arg\min_{X^* \subset X} \quad & \sum_{i=1}^k f(x^i) / k \\
\text{s.t.} \quad & |X^*| = k, \\
& x^1 = \arg\min_{x \in X} f(x), \\
& x^i, x^j \in X^* \implies d(x^i, x^j) \geq d_{\text{min}}, \quad \forall i \neq j.
\end{aligned}
\end{equation}

This formulation ensures that the subset $X^*$ is not only diverse but also contains a leader solution. This approach simplifies the subset selection problem and aligns with our goal of providing both a globally optimal solution and meaningful alternatives. The details of how we solve this problem are provided in Sec.~\ref{sec:3_methods}.




\section{Portfolio Creation via CMA-ES-DS}
\label{sec:portfoliocreation}


Our CMA-ES-Diversity Search (CMA-ES-DS) algorithm extends the Covariance Matrix Adaptation Evolution Strategy (CMA-ES)~\citep{hansen_reducing_2003} by incorporating mechanisms to promote diversity in the history of the evaluated points to better address the quest of problem~\eqref{eq:problem_statement}. Whereas CMA-ES is a powerful algorithm for continuous domains, it does not explicitly encourage diversity among the evaluated solutions, rendering it less useful for our optimization scenario~\citep{santoni2024illuminatingdiversityfitnesstradeoffblackbox}.

CMA-ES-DS achieves diversity through a cascading control mechanism, which operates during two critical phases: the initialization of diverse starting means and the synchronized evolution of populations across multiple CMA-ES optimizers, each one referred to as an \textit{instance}. As illustrated in Fig.~\ref{fig:cascade}, the cascading influence ensures that the solutions generated by later instances respect the diversity constraints defined by the earlier ones. These mechanisms are implemented through cascading validation checks during initialization (grey boxes, green arrows in Fig.~\ref{fig:cascade}) and during population generation (pink boxes, red arrows in Fig.~\ref{fig:cascade}).

The pseudocode of the algorithm is presented in Algorithm~\ref{alg:CMAES-D-S}, which provides a high-level structure of the method. The algorithm operates with $k$ independent CMA-ES instances, each of which maintains a tabu region to ensure diversity. These instances evolve synchronously, updating their respective tabu regions dynamically.


\begin{figure*}[h!] \center
    \includegraphics[trim=0cm 0cm 0cm 0cm, clip,width=.85\textwidth]{images/cascade_01.png}
      \caption{Cascade control mechanism in CMA-ES-DS with batch size $k = 3$. The diagram highlights the two key phases: the initialization of diverse starting means (grey boxes) and the synchronized generation of populations (pink boxes) for three CMA-ES instances. Green arrows highlight the dependency during initialization, where each mean must respect a minimum distance constraint ($d_{\min}$) from previously initialized means. Red arrows represent the cascading control during population generation, preventing later instances from generating candidates within the tabu regions of earlier ones.}
    \label{fig:cascade}
\end{figure*}
\begin{algorithm}[t]
\caption{Pseudocode of the CMA-ES-DS algorithm}

\label{alg:CMAES-D-S}

\KwIn{
  $f$: objective function to minimize, 
  $d_{\min}$: minimum distance requirement, 
  $k$: nbr of CMA-ES instances ($i$-th one denoted as CMA-ES$_i$), 
  $T$: total budget of function evaluations
}

\BlankLine

\For{$i = 1 \dots k$}{
        Initialize $x_{0_i}$ respecting the minimum distance requirement with cascade check\;
        Initialize CMA-ES\textsubscript{i} starting from $x_{0_i}$\;
    }
\While{$nb\_fevals \leq T$}{
        \For{$i = 1 \dots k$}{
            \While{$nb_\_evaluated\_points < \lambda$}{
                Sample a point from the CMA-ES\textsubscript{i} distribution\;
                Check if the point is valid with cascade check:\\
                \If{point is valid}{Evaluate the point\;
                
                }
            
            }
        Update tabu region\;
        }
    }


\Return portfolio of $T$ points\;

\end{algorithm}

The key components of CMA-ES-DS are hence as follows.  

\textbf{Initialization of Diverse Starting Means:} The algorithm begins by generating an initial set of $k$ starting points ($x_{0_i}$), each serving as the initial mean of the distribution for an independent  CMA-ES instance. To ensure diversity, these means are guaranteed to be at least $d_{\min}$ apart one from another. The initialization follows a cascading approach: the first mean is generated freely, the second mean is constrained to respect the minimum distance from the first, the third mean considers both the first and the second, and so forth. This process is implemented using rejection sampling, where candidate means are drawn uniformly at random within the search space and are included only if they satisfy the distance constraint relative to previously selected means. This cascading mechanism is illustrated in Fig.~\ref{fig:cascade}, where the grey boxes represent the initialization of means, and the green arrows indicate the dependency and checks performed for each subsequent mean.
    
\textbf{Tabu Regions for Diversity Maintenance:} Each CMA-ES instance generates its own tabu region, defined as a sphere of a given radius ($d_{\min}$). Points generated by each CMA-ES instance must not fall within the tabu regions of the preceding instances, enforcing diversity across the search space.
    
\textbf{Dynamic Updates to Tabu Regions:} The tabu regions are initialized with the starting mean ($x_{0_i}$) of each CMA-ES instance as centers. At each iteration, the center is dynamically updated to the best point in terms of fitness value from the population of the respective CMA-ES instance. 

When a CMA-ES instance meets a stopping criterion, the center of its tabu region is set to the best point it has evaluated.

\textbf{Cascading Validation and Synchronized Evolution:} Each CMA-ES instance evolves its population in a synchronized manner, where all instances complete their first iteration before moving to the second, and so on. During the population generation phase, each CMA-ES instance generates candidate solutions by sampling iteratively from its multivariate normal distribution until the desired population size $\lambda$ is reached. A cascading control mechanism is applied to ensure that each candidate solution respects the tabu regions established by all preceding instances in the cascade. Specifically, candidates that fall within the tabu regions of any previously initialized instance are rejected and regenerated. This approach guarantees that the points generated by later CMA-ES instances maintain the minimum distance $d_{\min}$ from the tabu regions of earlier instances. In Fig.~\ref{fig:cascade}, the pink boxes and the red arrows highlight the influence of preceding tabu regions' instances on the population generation of subsequent ones.

\textbf{Restart Mechanism:} If all CMA-ES instances reach a stopping criterion before the total evaluation budget is exhausted, the algorithm restarts, reinitializing with a new set of diverse starting means. If fewer than all instances meet their stopping criteria, the remaining instances continue their optimization process until they either converge or the evaluation budget is used up.
    


We chose to set the center of each tabu region to be the best point in the current population. This ensures that the centers remain tied to actual high-quality solutions while straightforwardly enforcing the diversity constraints.

Other alternatives were tested, such as updating the center with the best-so-far solution from each CMA-ES instance, but this proved less effective than our chosen approach.
Another option was to use the mean of the distribution, but this approach also did not yield better results. Ultimately, centering on a specific valid solution provided the best results.


Fig.~\ref{fig:algorithm_phases} illustrates the evolution of CMA-ES-DS over the isocontour of the f2 problem from the BBOB benchmark suite~\citep{hansen2021coco} (see Sec.~\ref{sec:exset} below) in dimension 2, with a maximum of $1\,000$ function evaluations, batch size $k=5$, and distance constraint $d_{\min}=3$.

\begin{figure*}[h!] \center
    \includegraphics[width=0.82
    \textwidth]{images/isocontour_progression.pdf}
      \caption{$D = 2$, $T = 1k$. Isocontour plots of $f_2$ where dark colors correspond to better values. We show initial means $(x_0)$, tabu region centers after $1/4$ and $3/4$ of the budget, and final selected solutions after clearing. Numbers indicate CMA-ES cascade levels, and circles represent tabu regions.}
    \label{fig:algorithm_phases}
\end{figure*}




\subsection{Alternative Approaches}

We will compare our CMA-ES-DS approach to the following five algorithms, also considered in~\citep{santoni2024illuminatingdiversityfitnesstradeoffblackbox}. 

\textbf{1. Random Sampling} samples $T$ points from the search space uniformly at random (i.i.d. sampling).

\textbf{2. Covariance matrix adaptation evolution strategy (CMA-ES)~\citep{hansen_reducing_2003},} evolution strategy that adapts the covariance matrix of a multivariate normal distribution to improve the search for optimal solutions. It iteratively generates new candidate solutions based on the current population and the covariance matrix, updating the covariance matrix and the step size to guide the search towards more promising regions of the solution space.

\textbf{3. Covariance Matrix Self-Adaptation with Repelling Subpopulations (RS-CMSA)~\citep{article}}, divides the population into multiple subpopulations that evolve independently, each focusing on a different region of the search space. To maintain diversity and prevent subpopulations from converging toward the same solution, a repelling force is applied whenever two subpopulations get too close to each other. Each subpopulation uses a variant of the CMA-ES algorithm, with self-adapting covariance matrices that allow it to model the local landscape of the problem dynamically. 

\textbf{4. Hill-Valley Evolutionary Algorithm (HillVallEA)~\citep{maree2019benchmarking}} 
combines the Hill-Valley test~\citep{10.1145/3205455.3205477} with the nearest better tree concept. The Hill-Valley test groups solutions into niches by detecting whether a \textit{hill} exists between them. Intermediate solutions are sampled and clustered using Hill-Valley Clustering, forming niches used to initialize the population for the AMaLGaM-Univariate~\citep{bosman2008matching} core search strategy. The algorithm then refines solutions within each niche using univariate distributions.


\textbf{5. Weighted Gradient and Distance-Based Clustering \newline (WGraD)~\citep{9002742}} uses a novel clustering method constructing multiple spanning trees, representing potential niches. The key innovation is the dynamic weighting of gradient and distance factors: for nearby points, the gradient is weighted more heavily, promoting local connectivity, while distant points are weighted more heavily by distance to selectively link them. Then Differential Evolution is used to find the optimum within each niche.


\section{Subset Selection}
\label{sec:3_methods}
In the subset selection phase, Phase~2 in Fig.~\ref{fig:process_phases}, three methods can be used to extract a batch of diverse and high-quality solutions from the full trajectory of all evaluated points. These methods include the exact Gurobi-based optimization and a greedy approach, both discussed in~\citep{santoni2024illuminatingdiversityfitnesstradeoffblackbox} and adapted to include the use of a lexicographical order, as well as the clearing process inspired by~\citep{542703}.
The three methods differ significantly in computational cost and how they balance diversity and solution quality:

\textbf{Gurobi-based Optimization.} This approach is the computationally most expensive one, both in terms of time and memory. However, it provides an optimal solution to the selection problem, making it the most accurate approach but also the least scalable to higher dimensionalities and different evaluation budgets. 

\textbf{Greedy Selection Approach.} This method, introduced in~\citep{santoni2024illuminatingdiversityfitnesstradeoffblackbox}, greedily swaps points that violate the distance requirements, which are sequentially increased until reaching the $d_{\min}$ limit. Empirical comparison with the Gurobi approach provided in~\citep{santoni2024illuminatingdiversityfitnesstradeoffblackbox} demonstrated this approach to be quite accurate, providing batches that are of not much worse quality than the exact ones extracted using Gurobi. However, the sequential nature of this algorithm implies a computational overhead that is not negligible. 

\textbf{Clearing Process.} This is the fastest and most memory-efficient approach. It works by iteratively picking the point with the lowest fitness value and removing all other points within a specified distance of $d_{\min}$. The process continues until the desired number of points is selected, ensuring that no two points are within the minimum distance from each other. While efficient, it is less likely to find the optimal solution compared to the other methods. 

Regarding the runtime, in our problems, Gurobi runs between almost a minute to several minutes, depending on the problem's dimensionality and budget (e.g., for $D=2$, $T=1\,000$, and $d_{\min} = 1$, runtime $\approx 40$ seconds; for $D=10$, $T=10\,000$, and $d_{\min} = 10$, runtime $\approx 13$ minutes). The other proposed methods run in the order of seconds and milliseconds. Specifically, for the Clearing method, its runtime is independent of $d_{\min}$ and its range remains in the order of milliseconds depending on dimension $D$ and budget $T$ (e.g., for $D=2$ and $T=1\,000$, runtime $\approx 0.0114$ seconds, while for $D=10$ and $T=10\,000$, runtime $\approx 0.2492$ seconds). On the other hand, the greedy approach's runtime is dependent on $d_{\min}$. It can range from milliseconds to several seconds, or even one minute, for instances with large distances and budgets relative to the dimensionality (e.g., for $D=2$, $T=1\,000$ and $d_{\min} = 1$, runtime $\approx 0.1231$ seconds, while for $D=10$, $T=10\,000$ and $d_{\min} = 10$, runtime $\approx 1$ minute and a few seconds).

The comparison of the three methods is presented in Sec.~\ref{sec:compare3method}.

\section{Experimental Setup}
\label{sec:exset}
\textbf{Test functions.} For our experiments, we use the noiseless Black-Box Optimization Benchmarking (BBOB) suite of the COCO environment~\citep{hansen2021coco}.
These functions are defined on the search space $[-5,5]^D$ and are grouped into five categories based on their structural properties: separable functions (f1-f5), functions with low or moderate conditioning (f6-f9), functions with high conditioning and unimodal structure (f10-f14), multimodal functions with appropriate (f15-f19), and weak global structure (f20-f24).

To keep the computational effort at a reasonable scale and assess the robustness of different algorithms, we performed several runs on the same instance (instance ID = 0). Given the invariance properties of CMA-ES, we expect these results to generalize well to other instances of the BBOB functions. Further investigation of generalization, also beyond BBOB functions, is left for future work.
We utilize the IOHprofiler library~\citep{doerr2018iohprofiler} to facilitate integration with the optimization algorithms discussed in subsequent sections.


\begin{figure*}[t] \center
    \includegraphics[width=0.8\textwidth]{images/compare_3_method.pdf}
      \caption{$D = 2$, $T = 10k$, $d_{\min} = 3$. Comparison of the subset selection methods, Gurobi-based Optimization, Greedy Approach, and Clearing Process. y-axis represents the average loss of the batch of $k = 5$ points across 5 repetitions (individual dots).}
    \label{fig:compare_3_method}
\end{figure*}

\textbf{Performance Criteria.} 

We measure performance using the \textit{target precision}, defined as the absolute difference between the best solutionâs quality and the global minimum, available for the BBOB functions. 
To align with the goals of this work, we calculate the average target precision for the $k$ solutions obtained under a given distance constraint $d_{\min}$. This metric, referred to as \textit{average loss}, is used to assess the quality of the batch of solutions.


We compare the performance of different initial portfolio generation strategies to evaluate the effectiveness of our method CMA-ES-DS in providing histories suitable for our quest.

We use the same MMO algorithms as in~\citep{santoni2024illuminatingdiversityfitnesstradeoffblackbox}, along with some baselines. The tested methods include: uniformly random points generated in the search space using the \verb|numpy.random.uniform| Python module~\citep{harris2020array}, CMA-ES in its basic implementation~\citep{hansen_reducing_2003} with restarts, the 3 MMO algorithms, Hill-Valley Evolutionary Algorithm (HillVallEA)~\citep{maree2019benchmarking}, Covariance Matrix Self-Adaptation with Repelling Subpopulations (RS-CMSA)~\citep{article}, Weighted Gradient and Distance-Based Clustering Method (WGraD)~\citep{9002742}.

For our algorithm, the following values are used as hyperparameters: we kept the default values for the population size $\lambda$ and the stopping criteria. The population size is set to $\lambda = 4 + \lfloor 3 \log(D) \rfloor$. The size of the \textit{parent} population, the subset of selected points used to generate the next population in each iteration, is computed as $\mu = \lfloor \lambda / 2 \rfloor$. The stopping criteria include several default conditions, such as \texttt{TolX} $= 10^{-12}$, \texttt{TolFun} $= 10^{-12}$, \texttt{TolFunHist} $= 10^{-12}$, \texttt{MaxIter} $= 10^3 \cdot n^2$, and \texttt{MaxFunEvals} $= 10^4 + 10^2 \cdot n$. The initial step-size in each coordinate is set to 1 based on several trials and recommendations from~\citep{hansen_reducing_2003}.
For all other algorithms, we use their default hyperparameters as provided by their respective implementations. Each algorithm is executed independently for 5 runs.

To evaluate the potential of each algorithm under distance constraints, we applied the clearing method to their respective histories. This ensures that the solutions selected for the final batch meet the minimum distance constraint $d_{\min}$.

Experiments are conducted across three search space dimensions, $D = 2, 5, 10$. Two total evaluation budgets are considered: $T = 10\,000$ and $T = 1\,000$ function evaluations.
Various $d_{\min}$ are explored: for $D = 2 : d_{\min} \in \{1, 3, 5\}$, for $D = 5$ and $D = 10 : d_{\min} \in \{1, 3, 5, 6, 10, 12\} $.


Due to space constraints, we report only the results supporting the main observations, with some plots provided in the Appendix and the complete set available on GitHub~\citep{code1}.
\section{Results and Discussion}
\label{sec:results}
\subsection{Comparison of Subset Selection Approaches}


To illustrate the differences between the Gurobi-based Optimization, Greedy Selection Approach, and Clearing Process, we conducted experiments using the final selection phase with all three approaches. The experiments were performed in $D=2$ due to the computational constraints of using Gurobi, which becomes exceedingly time-consuming and memory-intensive in higher dimensions. The experiments were performed with the following parameters: $T = 10\,000$, $k = 5$, and $d_{\min} = 3$. We conducted 5 repetitions of CMA-ES-DS for the same settings and we applied the three different methods on the five runs.


Fig.~\ref{fig:compare_3_method} shows the differences in the resulting selected points in terms of average loss for the three methods and for the 5 repetitions. Since the results are homogeneous across functions, we only show results for one function from each BBOB group.


For f3 and f6, the results represent the most common pattern: Gurobi consistently identifies a batch of solutions with a lower average loss compared to the Greedy approach, which itself outperforms the Clearing method. This is expected, as Gurobi solves the selection problem optimally at the cost of computational expense, while the Greedy approach, though computationally cheaper, provides a close approximation. The Clearing method, being the most computationally efficient, often sacrifices solution quality.
However, rare behaviors are observed, such as in the case of f11 and f17. Here, the Greedy and Clearing methods produce batches whose average losses are higher than the batch identified by Gurobi. The Clearing method outperforms the Greedy method in this scenario. It highlights that even a simpler method like Clearing can occasionally identify solutions that are competitive or even better than Greedy under certain conditions.
In contrast, the results for f24 reveal a different dynamic. The Greedy method performs slightly better than Clearing but remains distant from the optimal solution provided by Gurobi. This behavior might be attributed to the landscape of f24, which belongs to the group of multimodal functions with a weak global structure.
An additional interesting observation is that the variance in the final results appears to be influenced more by the final phase method than by the runs of CMA-ES-DS. Specifically, we observe the highest variance with the Greedy method, followed by Clearing. In contrast, Gurobi consistently provides results with minimal variance across the 5 repetitions. This suggests that the choice of the final phase method plays a significant role in the consistency of the solutions, with Gurobi offering a more stable performance.
Overall, while Gurobi delivers the best results in terms of solution quality, its computational cost makes it less practical for large-scale problems.
Greedy offers a balanced trade-off between accuracy and efficiency, while Clearing remains a lightweight yet effective approach in cases where computational resources are limited. However, it is important to note that the numerical differences between the three methods are relatively small. Considering these minimal differences and the need for efficiency in higher dimensionalities and budgets, we decided to proceed with the Clearing method in the subsequent sections of the paper.
\label{sec:compare3method}
\subsection{Comparison of Portfolio Creation Approaches}

\label{sec:compareportfolio}
Results across the experimental settings demonstrate that our proposed approach, CMA-ES-DS, performs well, achieving competitive or superior performance compared to the other algorithms. This holds across all the various dimensions, distance constraints, and evaluation budgets tested, with one exception. Specifically, for high-dimensional search spaces ($D = 10$), small budgets ($T = 1\,000$), and minimal distance constraints ($d_{\min} = 1$), alternative algorithms such as basic CMA-ES, RS-CMSA, and HillVallEA outperform CMA-ES-DS (Fig.~\ref{fig:D101Kd1}). 
\begin{figure}[t] \center
    \includegraphics[width=\columnwidth]{images/scatter_distance1_5runs_1k_dim10_final.pdf}
      \caption{$D = 10$, $T = 1k$, $d_{\min} = 1$. Cumulative average loss across the $k = 5$ points in the batch for the 24 BBOB functions. Each subplot corresponds to a specific BBOB function, and the x-axis represents the batch points ($x=1$ to $x=5$). The y-axis shows the cumulative average loss, where each curve represents the mean performance of an algorithm over 5 independent runs.}
    \label{fig:D101Kd1}
\end{figure}
This outcome is expected, as these algorithms are not designed to enforce distance constraints and thus excel in locating high-quality solutions in global optimization tasks without strong spatial diversification.
This pattern aligns with findings in~\citep{santoni2024illuminatingdiversityfitnesstradeoffblackbox}. For instance, similar behavior would likely be observed for $d_{\min} = 0.5$ in $D = 2$ or $D = 5$. However, as the distance constraint becomes more stringent, our approach outperforms others due to its explicit handling of diversification. This trend is particularly evident in Fig.~\ref{fig:D101Kd10}, where increasing $d_{\min}$ to 10 leads to better results for CMA-ES-DS compared to all the other algorithms.
\begin{figure}[t] \center
    \includegraphics[width=\columnwidth]{images/scatter_distance10_5runs_1k_dim10_final.pdf}
      \caption{$D = 10$, $T = 1k$, $d_{\min} = 10$. Same as Fig.~\ref{fig:D101Kd1}, but for $d_{\min} = 10$.}
    \label{fig:D101Kd10}
\end{figure}

An additional observation deducted from Fig.~\ref{fig:D101Kd10} is the performance dependency on the budget $T$. For a small budget ($T = 1\,000$), the first solution identified by CMA-ES-DS is often suboptimal because the approach divides the budget equally across the diverse solutions, allocating scarce resources to the various CMA-ES instances. This contrasts with CMA-ES and MMO algorithms, which focus solely, on finding one or multiple optima respectively, without imposing distance constraints. Instead, for a larger budget $T = 10\,000$ CMA-ES-DS demonstrates good results also in the quality of the leader point while maintaining its advantage in providing diversified alternatives (Fig.~\ref{fig:D1010Kd10}).

\begin{figure}[t] \center
    \includegraphics[width=\columnwidth]{images/scatter_distance10_5runs_10k_dim10_final.pdf}
      \caption{$D = 10$, $T = 10k$, $d_{\min} = 10$. Same as Fig.~\ref{fig:D101Kd10}, but for initial portfolio size $T = 10\,000$.}
    \label{fig:D1010Kd10}
\end{figure}

Reliability is another strength of CMA-ES-DS, as evidenced by Fig.~\ref{fig:D101Kd10} and~\ref{fig:D1010Kd10}. In scenarios with strong distance constraints ($d_{\min} = 10$), some algorithms fail to identify a set of $k = 5$ solutions at the required distances across their histories. This failure is illustrated by dashed (some failed runs) or missing lines (all failed runs). Notably, algorithms based on CMA-ES and RS-CMSA often suffer from this limitation, as they tend to localize the search without adequate exploration. Their exploitative nature would leave areas of the search space, where diverse solutions could be located, completely unexplored. In contrast, CMA-ES-DS consistently identifies feasible solutions, demonstrating its reliability. For example, in Fig.~\ref{fig:D101Kd10} we have a missing or a dashed line for all functions of CMA-ES and f9 of RS-CMSA. A similar behavior is shown in Fig.~\ref{fig:D1010Kd10}, with fewer failures for CMA-ES due to the larger available budget.

Fig.~\ref{fig:D101Kd10} and~\ref{fig:D1010Kd10} also confirm the observation from~\citep{santoni2024illuminatingdiversityfitnesstradeoffblackbox} that random sampling outperforms MMO algorithms under stronger distance constraints; because the attraction basins identified by the MMO algorithms are at distances that are smaller than those enforced by the distance constraint.  

Although our approach consistently outperforms random sampling, the relative advantage decreases as $d_{\min}$ increases. For larger distance constraints, algorithms achieving a better coverage of the search space, such as random sampling, tend to perform well due to their inherent exploratory nature. 


Moreover, CMA-ES-DS is particularly beneficial when searching for diverse solutions in settings where the ratio between dimensions and total budget is large. Otherwise, all methods would achieve a sufficient coverage of the search space and perform similarly, reducing the advantage of using more sophisticated algorithms. In addition, when this ratio is large, the advantages of our approach are more pronounced for larger $d_{\min}$, where our explicit diversification strategy outperforms methods that focus solely on global optimization. As shown by our results, the benefits of CMA-ES-DS are most pronounced for $D = 5$ (see Fig.~2 in the Appendix) and $D = 10$ (see Fig.~\ref{fig:D101Kd10} and~\ref{fig:D1010Kd10}). For $D = 2$, mainly with $T = 10\,000$, all methods perform comparably (see Fig.~1 in the Appendix).
However, we can observe some exceptions for two specific landscapes. For unimodal and low-conditioned landscapes such as the sphere function (f1), random sampling can outperform our method even where this ratio is large (see Fig.~\ref{fig:D101Kd10} and~\ref{fig:D1010Kd10}). This occurs because random sampling tends to find a best solution of lower quality compared to other optimizers, which allows the remaining solutions to be placed on lower isocontour levels. In fact, we observe in both Fig.~\ref{fig:D101Kd10} and Fig.~\ref{fig:D1010Kd10} that on f1
% , with $D = 10$, $T = 10\,000$ or $T = 1\,000$, and $d_{\min} = 10$, 
random sampling achieves a worse global solution than the other methods, but batches of better average quality. However, this phenomenon is observed only when the distance constraint is significantly strong. For small distances (e.g., Fig.~\ref{fig:D101Kd1}), CMA-ES-DS significantly outperforms random sampling.
This suggests that relaxing the requirement to select as $x^1$ the best evaluated solution could improve its performance for such cases when distance constraints are strong.

In repetitive landscapes like f23, the performance of CMA-ES-DS varies significantly depending on the budget. For $D = 10$, $T = 1\,000$ and $d_{\min} = 10$ (Fig.~\ref{fig:D101Kd10}), CMA-ES-DS confirms to be the best-performing method, given the large ratio between dimensionality and total budget. For $T = 10\,000$ (Fig.~\ref{fig:D1010Kd10}), random sampling outperforms CMA-ES-DS, as the high budget allows random sampling to adequately cover the landscape, which is particularly beneficial in repetitive landscapes where the risk to converge to local optima is higher. In contrast, for $T = 1\,000$ (Fig.~\ref{fig:D101Kd10}), random sampling fails to achieve comparable performance due to the limited number of function evaluations. In this case, CMA-ES-DS stands out as it uses efficiently the small budget to identify diverse and high-quality solutions under distance constraints.
Moreover, for $T = 10\,000$ (Fig.~\ref{fig:D1010Kd10}), basic CMA-ES and HillvallEA identify a very good leader solution, highlighting their global optimization strengths. On the other hand, CMA-ES-DS produces flatter curves, reflecting the fact that it is able to detect various basins of attraction of the multimodal landscape. Notably, for $T = 1\,000$ and $d_{\min} = 10$, CMA-ES-DS emerges as the best-performing method, as it effectively balances the constraints of limited evaluations and the requirement for diverse solutions.

For the most favorable setup---high dimension $D = 10$, small budget $T = 1\,000$, and high $d_{\min} = 10$---we also conducted a robustness analysis (see Fig.~3 in the Appendix). Our method demonstrates consistent performance across different functions, avoiding the large fluctuations observed in other algorithms, which may show stable results on some functions but significantly greater dispersion on others. From this figure, we also observe that, in low-budget settings, our method does not always outperform the baselines in terms of the leader solutionâs performance. However, it consistently achieves the lowest average loss across the final batch. 
 
\section{Conclusion}
\label{sec:conslusion}

We introduced CMA-ES-DS for the identification of batches of diverse, yet high-quality solutions for single-objective optimization problems with continuous decision variables. Specifically, we addressed the particular scenario where a diversity threshold is included in the problem definition.

Our approach demonstrated consistently strong performance across all evaluated optimization scenarios, with particularly strong results in settings with a large dimension-to-budget ratio. Key advantages of CMA-ES-DS include: (1) its frequent superiority over other baselines, regardless of the landscape characteristics of the optimized function; (2) its reliability, as it always allows for the extraction of a complete solution batch from its history, unlike the point portfolios generated by other methods; and (3) its robustness, consistently producing point batches of comparable quality across different repetitions on a wide range of considered benchmarks.

In future work, we strive for a deeper understanding of the various trade-offs between leader and alternative solutions. While we evaluated three different subset selection approaches in this study, we have yet to take full advantage of the collected data to investigate the compromises among the different solutions. Beyond a purely optimization point of view, these trade-offs could offer an interesting playground for social choice theory.

We believe our CMA-ES-DS approach to be of high practical importance, and aim to integrate it into state-of-the-art optimization frameworks, to increase its usability for both academic and industrial users.



\begin{acks}
CD acknowledges funding by the European Union (ERC, ``dynaBBO'', grant no.~101125586). Views and opinions expressed are however those of the author(s) only and do not necessarily reflect those of the European Union or the European Research Council Executive Agency. Neither the European Union nor the granting authority can be held responsible for them.  
ER expresses gratitude to Juergen Branke for the initial discussions that inspired some aspects of this project.
We thank the Sorbonne Cluster for Artificial Intelligence (SCAI) for supporting our work through ML's PhD scholarship. 
% Juergen
% Computing resources (?), Mike?, xtof?
\end{acks}





\bibliographystyle{ACM-Reference-Format}
\bibliography{main}


\appendix
\section{Appendix}

\begin{figure*}[h!] \center
    \includegraphics[width=0.6\textwidth]{images/scatter_distance3_5runs_10k_dim2_final.pdf}
      \caption{$D = 2$, $T = 10k$, $d_{\min} = 3$. Cumulative average loss across the $k = 5$ points in the batch for the 24 BBOB functions. Each subplot corresponds to a specific BBOB function, and the x-axis represents the batch points ($x=1$ to $x=5$). The y-axis shows the cumulative average loss, where each curve represents the mean performance of an algorithm over 5 independent runs.}
    \label{fig:D210Kd3}
\end{figure*}
\clearpage
\begin{figure*}[h!] \center
    \includegraphics[width=0.6\textwidth]{images/scatter_distance5_5runs_1k_dim5_final.pdf}
      \caption{$D = 5$, $T = 1k$, $d_{\min} = 5$. Cumulative average loss across the $k = 5$ points in the batch for the 24 BBOB functions. Each subplot corresponds to a specific BBOB function, and the x-axis represents the batch points ($x=1$ to $x=5$). The y-axis shows the cumulative average loss, where each curve represents the mean performance of an algorithm over 5 independent runs.}
    \label{fig:D51Kd5}
\end{figure*}



\begin{figure*}[htbp]
    \centering
    \begin{subfigure}[b]{0.45\textwidth}
        \centering
        \includegraphics[width=\textwidth]{images/boxplot_leader_d10_1k_dmin10.pdf}
        \caption{Scatter plot of the leader's loss values across 5 independent runs for each algorithm. Each figure represents the leader's loss in a single run.}
        \label{fig:img1}
    \end{subfigure}
    \hspace{0.05\textwidth}
    \begin{subfigure}[b]{0.45\textwidth}
        \centering
        \includegraphics[width=\textwidth]{images/boxplot_batches_d10_1k_dmin10.pdf}
        \caption{Scatter plot of the average loss over the batch of $k = 5$ points for each algorithm. Each figure represents the average batch loss from a single run.}
        \label{fig:img2}
    \end{subfigure}
    \caption{$D = 10$, $T = 1k$, $d_{\min} = 10$.}
    \label{fig:variance}
\end{figure*}

\end{document}

