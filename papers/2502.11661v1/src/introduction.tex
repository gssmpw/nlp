\section{Introduction}

Contract design studies the interaction between a principal and an agent.
The agent undertakes costly actions that are hidden from the principal, who can only observe a stochastic outcome influenced by the agent's decisions.
%The agent takes costly actions that are not observable by the principal, who can only observe a \textcolor{red}{randomly generated outcome}.
The goal of the principal is to design an outcome-dependent payment scheme, known as a \emph{contract}, to incentivize the agent to take desirable actions.

When all the parameters of the model are known, an optimal contract can be computed efficiently through linear programming~\citep{dutting2019simple}.
%
However, this changes dramatically when uncertainty is added to the model. When Bayesian uncertainty is introduced and an agent's type, defining their actions and costs, is sampled from a probability distribution, contract design problems become intractable~\citep{castiglioni2022bayesian,guruganesh2021contracts,castiglioni2023designing}.
%
% However, this changes dramatically when uncertainty is added to the model. 
% Indeed, when Bayesian uncertainty is added to the model and an agent's type (defining agent's actions and costs) is sampled from a probability distribution, contract design problems become intractable~\citep{castiglioni2022bayesian,guruganesh2021contracts,castiglioni2023designing}.
% %
A comparable increase in the complexity of the problem occurs in online learning scenarios, where the principal interacts with an unknown agent. In this setting, uncertainty makes the problem intractable, leading to regret bounds that are nearly linear~\citep{zhu2022online}, or exponential in the instance size~\citep{bacchiocchi2023learning}.

These negative results motivate the study of simpler settings with more ``structured'' uncertainty. Drawing inspiration from mechanism design, \citet{alon2021contracts} introduced a setting in which the agent's type is single-dimensional and represents a cost per unit-of-effort, \emph{i.e.}, a parameter that multiplies the cost of the chosen action.
%
A recent line of work~\citep{alon2021contracts,alon2023bayesian,castiglioni2025reduction} shows that, while single-dimensional contract design enjoys some additional structural properties, it is computationally more similar to the multi-dimensional case than initially expected.
%
These results are culminated in \citet{castiglioni2025reduction}, who provided an almost approximation preserving reduction from multi-dimensional to single-dimensional contract design for \emph{multiplicative} approximations. 

At first glance, the above result may suggest that efficient algorithms for contract design with single-dimensional costs are unattainable.
%The above result seems to shut down any hope of efficient algorithms for contract design with single-dimensional costs. 
%However, we show that, in several aspects, single-dimensional contract design is simpler than its multi-dimensional counterpart, and achieving better results in this setting is not a pipe dream.\ma{hmmm}
However, we show that, in several key aspects, single-dimensional contract design is simpler than its multi-dimensional counterpart, and achieving better results in this setting is possible.
%
In particular, we answer positively to the following questions:
\begin{enumerate} 
    \item Is it possible to design efficient approximation algorithms for Bayesian single-dimensional contract design under additive approximations?
    \item Is it possible to design learning algorithms with sublinear regret (or with polynomial sample complexity) in online learning scenarios with single-dimensional types?
\end{enumerate}

\subsection{Our Contributions}

%We show that in certain aspects single-dimensional contract design is simpler than its multi-dimensional counterpart.
%
In the first part of the paper, we analyze the single-dimensional Bayesian contract design problem under \emph{additive} approximations. While single-dimensional and multi-dimensional problems are essentially equivalent under multiplicative approximations \cite{castiglioni2025reduction}, this is not the case for additive ones.
Indeed, we show that single-dimensional problems admit a $\PTAS$. This is in contrast to multi-dimensional problems, which do not admit a $\PTAS$ unless $\PolyClass=\NP$~\cite{guruganesh2021contracts, castiglioni2022bayesian}. 

\begin{theorem-non}[Informal, see \Cref{thm:PTAS}]
    Single-dimensional Bayesian contract design admits an additive $\PTAS$.
\end{theorem-non}

Our result relies on the following observation.
In multi-dimensional instances, all types might have very different actions, costs, and incentives. This is not the case in single-dimensional instances, where similar types share similar incentives.
Our algorithm exploits this feature by grouping agents with similar types into $k$ buckets.
Then, replacing each bucket with a representative type, we can employ algorithms for discrete types such as the one proposed by ~\citet{guruganesh2021contracts} and \citet{castiglioni2022bayesian} to solve the discretized problem. Such algorithms run in time exponential in number of types. However, if the number of representative types (and thus the number of buckets $k$) is constant, they run in polynomial time.

The core of the proof is to manage the error with respect to the optimal contract as a function of the number of buckets $k$ in which we partition the types.
The agent's type is represented by a single parameter $\theta\in [0,1]$. 
We will show that when we group two agents of types $\theta \in [0,1]$ and $\theta'\in [0,1]$ together, we make an error of order $\poly(|\theta-\theta'|)$. Thus, to guarantee an $\epsilon=O(1)$ additive error, it suffices to set $k=\poly(1/\epsilon)$, resulting in a $\PTAS$. 
To do that, we relate the value of the discretized problem to the true one. Then, we make the solution of the discretized problem robust to the slight type misspecification resulting from bucketing different types together.
%Crucially, this result does not rely on any assumption about the density of the type distribution. \mat{Crucially, ... Perchè mai ad uno dovrebbe venirgli in mente questa cosa? mettere almeno delle cit che lo assumono?}
%
%This is in contrast to multi-dimensional contract design that is $\NP$-hard (in the Bayesian setting) also for additive approximations \citep{guruganesh2021contracts, castiglioni2022bayesian}.
%
This result shows that focusing on multiplicative approximations is necessary to design an approximation-preserving reduction from multi- to single-dimensional contracts~\citep{castiglioni2025reduction}. Indeed, for additive approximations, single-dimensional contracts admit a $\PTAS$ while multi-dimensional ones are $\NP$-hard \citep{guruganesh2021contracts, castiglioni2022bayesian}. 

It is therefore natural to try to strengthen our result and ask whether an $\FPTAS$ exists for single-dimensional contracts with additive approximations. Unfortunately, we answer this question in the negative.
%It is thus natural to try to strengthen our result and ask whether there exists a $\FPTAS$ for single-dimensional contracts with additive approximations. Sadly, we answer in the negative. 
Indeed, we show that our $\PTAS$ is tight, and it is impossible to design an additive $\FPTAS$ unless $\PolyClass=\NP$.

\begin{theorem-non}[See \Cref{thm:reduction}]
    Single-dimensional Bayesian contract design does not admit an additive $\FPTAS$, unless $\PolyClass=\NP$.
\end{theorem-non}

The closest related work to this hardness result is~ \citet{castiglioni2025reduction}, which establishes the equivalence of multi-dimensional and single-dimensional contract design under multiplicative approximations. A key aspect of their approach is using exponentially decreasing costs and expected rewards, leading to an exponentially small principal's utility as the size of the instance grows. In such cases, the null contract incurs only a negligible additive error. 
%
In contrast, we focus on additive approximations and construct instances with polynomially decreasing costs and expected rewards, ensuring that the principal’s utility remains polynomially bounded. 
%
Exponentially decreasing sequences are used to ``separate'' the actions of each type from the actions of other types by using incentives. However, using polynomial sequences results in sets of actions that are less separated. Dealing with these less separated action sets is the primary challenge of the proof.



In the second part of the paper, we focus on the problem of learning approximately optimal contracts, providing bounds both on the regret rates and on the sample complexity.
%
We study a stochastic setting for which we make some mild assumptions. In particular, as in previous work on online learning in contract design \citep{zhu2022online}, we restrict to bounded contracts. Moreover, as in many previous works on single-dimensional contract design, we assume that the type distribution has bounded density~\citep{alon2021contracts,alon2023bayesian}.

There are two main challenges in obtaining no-regret algorithms in our setting.
First, the action space is continuous (being the hypercube) and lacks any obvious structural properties to exploit. This makes most techniques used in multi-dimensional contract design unfeasible, as they operate directly on this decision space and cannot leverage the simplicity of single-dimensional types~\cite{zhu2022online,bacchiocchi2023learning,ho2014adaptive}.
Second, the type distribution is continuous.
This makes standard approaches for Stackelberg-like games unfeasible. Indeed, most approaches for learning in games with commitments crucially rely on having a finite number of types  (see \emph{e.g.}, \citet{balcan2015commitment,castiglioni2020online}).

We address such challenges by considering an approximate instance with finitely many types, whose grid of discretized types is the one used in the Bayesian problem.
We show that, under the bounded density assumption, the utility of each contract does not change too much from the original instance to the discretized one, allowing us to work with discretized types.
This result is conceptually very different from the ``continuous-to-discrete'' result we establish when working towards the $\PTAS$. In particular, we now provide both upper and lower bounds on utility, but only for distributions with bounded density.
%
Then, similarly to \citet{bernasconi2023optimal} we shift the learning problem to the space of utilities. 
%
This approach allows us to avoid the exponentially large set of actions that would typically need to be considered (where bandit feedback would translate the exponential number of actions into a regret bound that grows exponentially with the instance size).
%
Indeed, in this context, the problem is an \emph{almost-}linear bandit whose dimension is equal to the number of types. It is important to note that we sacrifice the linear structure of the problem, as the discretized instance is only an approximation of the original one.
%
We deal with this almost-linear structure by resorting to \emph{misspecified linear bandits}~\citep{ghosh2017misspecified}, and by carefully balancing the effects of the discretization on the misspecification of the linear model.
Combining all these results, we obtain a regret minimization algorithm that guarantees regret of order $\widetilde O(T^{3/4})$.


\begin{theorem-non}[Informal, see \Cref{thm:regret}]
There exists an algorithm that guarantees regret
\(
R_T= \widetilde O(\poly(\mathcal{I})T^{3/4}),
\)
where $\mathcal{I}$ is the instance size.
\end{theorem-non}

Finally, we show how the same reduction to misspecified linear bandits can be exploited to construct an algorithm with polynomial sample complexity.

\begin{theorem-non}[Informal, see \Cref{thm:sample}]
    Given an $\eta>0$, there exists an algorithm that with high probability finds an $\eta$-optimal contract using $\widetilde O\left(\frac{\poly(\mathcal{I})}{\eta^4}\right)$ samples,
    where $\mathcal{I}$ is the instance size.
\end{theorem-non}

\subsection{Related Works}

In this section, we review the studies most relevant to our work. For a broader overview on algorithmic contract theory, we refer readers to the recent survey by \citet{dutting2024algorithmic}. 

The computational study of contract design has attracted growing interest in recent years, beginning with \citet{babaioff2006combinatorial}, who introduced the multi-agent setting, and \citet{dutting2021complexity}, who explored computational aspects of the single-agent model. %while \citet{dutting2019simple} examine the efficiency of linear contracts compared to optimal ones.  
%
A more recent line of work extends contract analysis to Bayesian settings, where the principal has a known probability distribution over the agent’s types~\citep{guruganesh2021contracts, castiglioni2021bayesian, alon2021contracts, alon2023bayesian}. In particular, \citet{castiglioni2023designing} introduce menus of randomized contracts and show that they can be computed efficiently. \citet{gan2022optimal} generalize the principal-agent problem to cases where the principal’s action space is potentially infinite and subject to design constraints, proving that optimal randomized mechanisms remain efficiently computable.  

%\paragraph{Multi-dimensional Contract design}


\paragraph{Single-dimensional Contract design}
The computational perspective on single-parameter models was first introduced by \citet{alon2021contracts,alon2023bayesian}.
%
The study of the single parameter setting is mainly motivated by the known computational complexity separation between single-parameter and multi-parameter settings in algorithmic mechanism design \cite{nisan1999algorithmic,daskalakis2015multi}. However, \citet{castiglioni2025reduction} showed that, in the context of contract design, the relationship between the two settings is more intricate. In particular, they provided an almost approximation-preserving reduction from multi- to single-dimensional contract design for \emph{multiplicative} approximations.

\paragraph{Learning Optimal Contracts} The problem of learning optimal contracts was first explored by \citet{ho2014adaptive}, who focused on instances with a very specific structure, similar to what is done in \citet{cohen2022learning} (see the discussion in \citet{zhu2022online} for more details about these assumptions). \citet{zhu2022online} extended this line of work by studying the problem in general principal-agent settings. They proposed an algorithm with a regret upper bound of $\widetilde O(m^{1/2} T^{1-1/(2m+1)})$ and established an almost matching lower bound of $\Omega(T^{1-1/(m+2})$. \citet{bacchiocchi2023learning} developed an algorithm that achieves cumulative regret with respect to an optimal contract upper bounded by $\widetilde O(m^n T^{4/5})$, which remains polynomial in the instance size when the number of agent actions $n$ is constant.
%
Our problem also shares connections with the more general problem of learning an optimal commitment, in repeated Stackelberg games \cite{letchford2009learning,peng2019learning,blum2014learning,balcan2015commitment} and online Bayesian persuasion \cite{castiglioni2020online,castiglioni2021multi,bernasconi2023optimal}.

% Another research direction explores extending single-agent models to settings with combinatorial actions~\citep{dutting2021complexity, dutting2022combinatorial, dutting2024combinatorial, deo2024supermodular}. Additionally, multi-agent contract design has been studied in various contexts~\citep{babaioff2006combinatorial, babaioff2012combinatorial, dutting2023multi, castiglioni23multi}.  

% Beyond computational contract theory, several studies examine robustness in classical contract design. \citet{carroll2015robustness, carroll2019robustness} investigate scenarios where the principal only knows a limited subset of the agent’s available actions (or "technologies"), showing that linear contracts are worst-case optimal. \citet{dutting2019simple} consider a related problem in which the principal has first-order moment information about action rewards and conducts a worst-case analysis in this setting.  

% Robustness has also been explored in related areas within theoretical computer science, including Stackelberg games~\citep{gan2023robust} and Bayesian persuasion~\citep{babichenko2022regret, feng2024rationality}.