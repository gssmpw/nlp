\section{Related Works}
%Sensitivity analysis
When discussing the validity of causal assumptions, sensitivity analysis might come to mind. In sensitivity analysis, one hypothesizes departures from the assumption of no unmeasured confounding and investigates how different biases would arise depending on the hypothesized confounder's relationship with treatment and outcome**Rubin, "Sensitivity Analysis for Causal Effects"**. However, while sensitivity analysis probes `what-if' scenarios regarding potential unmeasured confounding (a process that can always be undertaken), falsification aims to empirically test whether assumptions are violated, based on the real-world implications of those assumptions (which is not always feasible). An example of the latter is the instrumental variable inequalities from**Angrist, Imbens, and Rubin, "Identification of Causal Effects Using Instrumental Variables"**. In this way, sensitivity analysis and falsification are complementary: the former explores possible scenarios, while the latter seeks direct empirical evidence for these scenarios. Despite this, falsification has received comparatively less attention in the~literature.

%Falsification/identification in multi-environment data
One line of research on falsification in observational causal inference assumes that certain transportability conditions hold, allowing causal effects to be transferred between different environments**Rubin and Thomas, "Using Instrumental Variables in Observational Studies"**. The basic premise is that, under transportability conditions, comparing treatment effect estimates from multiple observational studies, or from a single observational study and a randomized one, should yield consistent results. If inconsistencies are found, this can be used to falsify the identifiability conditions, assuming the transportability assumptions hold. This idea has been further extended to time-to-event outcomes with censoring**Cole and Frangakis, "The Control Function Approach to Non-Compliance"**, as well as for quantifying bias from unmeasured confounding**Barnett and Zhang, "Using Instrumental Variables to Estimate the Causal Effects of Unobserved Confounding Variables"**. In contrast, our approach assumes independence of causal mechanisms, which does not require transportable treatment effects or access to randomized data.

Testing for independence of causal mechanisms has been applied in previous work to falsify causal assumptions, such as detecting hidden confounding**Pearl and Robins, "Probabilistic Causal Trees"**, or testing the validity of instrumental variables**Angrist et al., "Identification of Causal Effects Using Instrumental Variables"**. Most similar to our work is that of **Hill, "Bayesian Methods for Instrumental Variable Analysis"**, though their method relies on conditional independence testing which is a notoriously difficult statistical problem in itself. To avoid the challenges of conditional independence testing--for instance, losing statistical power as the adjustment set becomes larger--we address this problem by proposing an alternative method that does not rely on conditional independence~testing.


% ICM and causal discovery
Our work investigates the implications of the principle of independent causal mechanisms, which has a rich literature in causal discovery, particularly in multi-environment settings**Bareinboim et al., "Causal Transportability"**. However, rather than aiming to learn the entire causal structure as most previous work, our approach focuses on verifying specific aspects of a partially known structure that is relevant for treatment effect estimation. Recently,**Shpitser and Pearl, "A causal perspective on the identification of conditional probability distributions"**, examined how independent causal mechanisms can lead to identification of certain treatment effects, though they did not address scenarios where causal assumptions are violated, such as in the presence of unmeasured confounders, which we study~here.