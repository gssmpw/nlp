\section{Related Work}
The Introduction identifies three core challenges to ASP verification: modularity, grounding, and tool support.
%
Within each of these topics, there are a number of studies relevant to the research agenda proposed here.


% OntoDLV - \cite{ricgalschdelgrasleo09}? - couldn't access pdf

\subsection{Modularity}

The notion of external equivalence presented earlier is closely related to modular equivalence for DLP and ELP-functions~\cite{janoiktomwol09}, which are in turn related to LP-functions~\cite[Section~2]{gel02}.
%
In these studies, the idea of program modules as composable functions mapping input atoms to output atoms (using hidden auxiliary atoms) has been explored in the context of disjunctive, propositional programs.
%
The \emph{module theorem}~\cite{janoiktomwol09} provides a compositional semantics for this class of programs.\footnote{Under certain reconfigurations of program modules, the module theorem can apply even when some input, output, or hidden atoms are forgotten~\cite{gonjanknoleiwol19}.}
%
Our work on external behavior of io-programs and modular arguments of correctness uses similar results established for a different class of programs, specifically, programs with variables and arithmetic.

\emph{Templates} are a construct roughly analogous to program modules, where global (public) predicates are renamed so as to interface with an enclosing program, and local (auxiliary/hidden/private) predicates are renamed with a procedure that (very nearly) guarantees the new identifiers are universally unique~\cite{alvianpaczan23}.
%
The use of templates promotes code reusability and eases the development of industrial-scale applications~\cite{calian06}.
%
This approach has the additional benefit of being able to test that simple invariants of templates hold in the context of an enclosing program.
%ASPIDE's notion of units could be refined to use Modular ASP rather than just splitting theorem?
%
As an alternative to the re-writing strategy described above, templates can also be defined as higher-order definitions of predicates~\cite{dashaljanden15}.
%
This is more in line with the second-order characterization of external behavior given by the $SM$ operator.
%


\subsection{Grounding}
Within the domain of translational semantics for ASP, a major distinction is between grounding-free approaches, and semantics applied to grounded or propositional programs.
%
A grounding-free translational approach is the basis of this proposal -- it benefits from being more general, but suffers some restrictions that have been overcome for propositional translations.
%
For example, the limitation of completion semantics to tight programs can be circumvented in the propositional case by adding loop formulas ($LF$) to the program's ($\Pi$) completion ($COMP(\Pi) \cup LF$)~\cite[Theorem 1]{linzhao04}.\footnote{The \textsc{assat} tool based on these results uses SAT solvers to compute stable models of propositional logic programs~\cite{linzhao04}.}
%
An extension of this theorem to the first-order case exists, but relies on a grounding procedure, namely, an instantiation of $COMP(\Pi) \cup LF$ w.r.t. a finite domain to obtain a propositional theory~\cite{chenlinwanzha06}.
%
Lee and Meng (2011) provide a full generalization of loop formulas to arbitrary first-order formulas -- this could be a promising extension to the completion procedure implemented by \anthem~\cite{leemeng11}.


\subsection{Tool Support}
Tools supporting formal verification of ASP programs can be roughly divided into the categories of \textbf{testing} based and \textbf{proof} based systems.
These are complementary approaches, since testing generally cannot provide the same level of assurance but is fast and universally applicable.
\textsc{harvey} is an ASP-based system for random testing of ASP programs~\cite{greoettom17}.
\aspide is an integrated development environment (IDE) supporting unit testing~\cite{ameberric21,febleorearic13}.
Similarly to \anthem, this supports modular verification by specifying conditions on outputs for program ``units" and automatically testing that these conditions are satisfied for certain inputs.
% But external equivalence + program modules is more general and more complete than unit testing?
However, \anthem enables users to specify (possibly infinite) \emph{classes} of inputs rather than a finite set of test cases.

%small scope - \cite{oetprip√ºhschtom12}?


Examples of proof based systems are \selp~\cite{chenlinli05}, \tabeql~\cite{val04}, \textsc{lpeq}~\cite{janoik04}, and \textsc{ccT}~\cite{oetseitomwol09}.
\selp is closely related to this proposal, since it uses automated reasoning tools to check whether two logic programs are strongly equivalent.
One notable consequence of \selp's SAT checking methodology is its ability to find a counterexample, which would be an interesting addition to \anthem.
\selp differs from \anthem in its use of SAT solving instead of theorem proving; a more important difference is that \selp supports disjunctive propositional programs whereas \anthem supports normal programs with variables and arithmetic.
%
\textsc{tabeql} does not translate ASP programs into logical theories, but rather computes equilibrium models of arbitrary propositional theories using tableau calculi for here-and-there.
%
The ASP-to-ASP translation tool \textsc{LPEQ} and its variant \textsc{DLPEQ} produce logic programs whose answer sets (if any) represent counterexamples to the weak or strong equivalence of a pair of programs.\footnote{Two programs are \emph{weakly equivalent} if they have the same answer sets; this is a special case of external equivalence.}
Similarly to \selp, these systems accept disjunctive, variable-free logic programs.
A more flexible system is~\textsc{ccT}, which tests relativised strong equivalence with projection and uniform equivalence.\footnote{Uniform equivalence is a special case of strong equivalence where it is assumed that the context is a set of facts rather than an arbitrary set of rules.}
\textsc{ccT} is very similar in spirit to \anthem, \selp, and \textsc{LPEQ} given that it relies on a translation to quantified Boolean formulas evaluated by backend solvers.
This system is based on a general notion of program correspondence~\cite{eittomwol05}, and requires two sets of atoms (a \emph{context} and a \emph{projection set}) which behave similarly to \anthem's input and output predicates.
Again, \anthem is more general: rather than dealing with concrete sets of atoms, \anthem operates on classes of inputs defined by first-order assumptions.



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%