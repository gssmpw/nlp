% Fig. 1
\input{figures/tex_files/Fig_1}
Neuroimaging modalities such as functional magnetic resonance imaging (fMRI) are essential for enhancing the diagnosis and treatment of various neurological conditions. 
fMRI data are based on blood oxygen level-dependent (BOLD) signals, which measure changes in cerebral blood flow and oxygenation as an indirect indicator of neuronal activity. 
While BOLD imaging offers rich spatial detail, it requires complex infrastructure with high operational costs, and often unavailable in many clinical environments \cite{constable2023challenges}. 
In contrast, electroencephalography (EEG) is a relatively low-cost, non-invasive, and portable modality that directly records electrical activity in the brain with millisecond precision \cite{sturzbecher2012simultaneous, debener2012taking}. 
Despite these advantages, EEG lacks the spatial resolution required for precise localization of neural activity, limiting its diagnostic and research utility. 

The capability to generate fMRI data from EEG signals offers significant potential for cost-effective, real-time functional mapping in various clinical applications. 
These include resource-limited settings, continuous monitoring of neurological disorders, and the generation of synthetic fMRI images for data augmentation \cite{zhuang2019fmri}. 
Previous studies have demonstrated correlations between fMRI data and specific features of EEG signals \cite{laufs2003eeg,laufs2006bold,chang2013eeg}, highlighting EEG's potential to capture aspects of neural activity reflected in fMRI. 
Recent advancements in cross-modality synthesis using deep neural networks have further positioned EEG-to-fMRI translation as a promising and emerging research direction \cite{liu2019convolutional, calhas2020eeg, calhas2022eeg, lanzino2024nt}. 

Liu et al. \cite{liu2019convolutional} employed a pair of convolutional neural network (CNN) transcoders that directly map EEG signals to fMRI volumes and vice versa, without relying on explicit hemodynamic or leadfield models. 
In simulated datasets, the method achieved a high correlation between predicted and ground-truth data. 
While this pioneering work demonstrated the feasibility of neural transcoding, further advancements are needed to address the inherent complexities of EEG-to-fMRI synthesis, particularly in achieving robust and generalizable performance across diverse contexts. 

Calhas et al. \cite{calhas2020eeg} expanded the exploration of EEG-to-fMRI synthesis using a broader set of deep learning architectures, including autoencoders, generative adversarial networks (GAN) \cite{goodfellow2014generative} variants, and pairwise-learning approaches. 
Despite encountering the challenges of limited simultaneous EEG-fMRI datasets and variable recording conditions, they demonstrated the viability of generating fMRI-like images from EEG signals. 
Notably, their experiments revealed that while autoencoders tend to yield stable (though sometimes oversimplified) outputs, GAN models can capture richer distributional details but suffer from training instability on relatively small datasets. 
Their latest study further improved the cross-modal mapping paradigm by leveraging topographical attention graphs of EEG electrodes alongside Fourier features \cite{calhas2022eeg}. 
The approach explicitly captures non-local relationships between EEG electrodes, addressing the distributed nature of brain activity and enabling the model to better account for the spatial dynamics underlying fMRI signals. 

Lanzino et al. \cite{lanzino2024nt} introduced the Neural Transcoding Vision Transformer (NT-ViT), leveraging an encoder-decoder design optimized for generating fMRI data from EEG signals. 
The NT-ViT model incorporates a domain-matching sub-module to align latent EEG and fMRI representations, significantly enhancing the coherence and accuracy of image generation. 
The results demonstrate that NT-ViT surpasses traditional methods in producing fMRI images with greater clarity and precision, indicating its potential to enhance multimodal neuroimaging analyses. 

While these efforts have demonstrated initial feasibility, the reported studies either show modest performance with significant room for improvement \cite{liu2019convolutional,calhas2020eeg,calhas2022eeg}, require extensive hyperparameter tuning \cite{calhas2022eeg}, or rely on complex model designs \cite{lanzino2024nt}. 
In this work, we propose E2fNet, an accurate and reliable model inspired by the U-Net architecture \cite{ronneberger15unet} for EEG-to-fMRI synthesis. 
The E2fNet is specifically designed to capture and translate meaningful features from EEG across electrode channels into accurate fMRI representations. 
Our E2fNet model not only significantly outperforms previous CNN-based methods \cite{liu2019convolutional,calhas2022eeg}, by a substantial margin, but also offers a simpler design and better structural similarity index measure (SSIM) \cite{wang04ssim} scores compared to the transformer-based approach \cite{lanzino2024nt}. 
Experimental results demonstrate that E2fNet achieves state-of-the-art in terms of SSIM across three publicly available datasets. 
We make our implementation publicly available to encourage reproducibility and further research. 