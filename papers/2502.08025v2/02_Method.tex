Our E2fNet is a fully CNN specifically designed to generate fMRI from EEG data. Let $x \in \mathbb{R}^{T \times C \times F}$ be a spectrogram of multi-channel EEG data, where $T$, $C$, and $F$ correspond to the temporal, electrode channel, and frequency dimension, respectively. 
Let $y \in \mathbb{R}^{D \times W \times H}$ be an fMRI volume representation at a given time, where $D$, $W$, and $H$ correspond to the depth, width, and height. 
Fig. \ref{fig:fig_1} illustrates the overview of the proposed E2fNet. 
Our model consists of an EEG encoder $\mathcal{M}_{\mathrm{EEG}}$, a U-Net module $\mathcal{M}_{\mathrm{UNet}}$, and an fMRI decoder $\mathcal{M}_{\mathrm{fMRI}}$. 

\subsection{The EEG Encoder}
The EEG encoder is built to capture the characteristics of EEG signals effectively. 
Given EEG data \(x \in \mathbb{R}^{T \times C \times F}\), we obtain the encoded features 
\(x_{eeg} = \mathcal{M}_{\mathrm{EEG}}(x)\), where \(x_{eeg} \in \mathbb{R}^{N \times W \times H}\). 
Here, \(N\) denotes the depth (number of feature maps), and \(W \times H\) corresponds to the 
width and height of the target fMRI volume. The design of $\mathcal{M}_{\mathrm{EEG}}$ includes several key principles. 
\textit{First}, $\mathcal{M}_{\mathrm{EEG}}$ progressively expands the temporal dimension from $T \rightarrow N$ (where $N \gg T$), enabling the capture of long-term dependencies and subtle temporal dynamics critical for modeling changes over time. 
\textit{Second}, the model retains the electrode dimension $C$ throughout the convolutional process, preserving the spatial topology and relationships between electrodes. 
This preservation ensures the integrity of spatial information for downstream analyses. 
\textit{Third}, the frequency dimension $F$ is gradually reduced toward the size of $H$. 
This emphasizes the most relevant spectral features while reducing the complexity of the encoded representation. 
All of this can be done by a series of convolutional layers with kernel size of $[1 \times k]$, where $k > 1$, to progressively shrink the $F$ dimension. 

The convolutional process produces a feature tensor of size $N \times C \times H$, which is then resized to $N \times W \times H$ using bicubic interpolation to match the spatial size of the target fMRI. In this work, we designed the $\mathcal{M}_{\mathrm{EEG}}$ to output the feature's depth $N=256$ (i.e., $x_{eeg}\in \mathbb{R}^{256 \times W \times H}$). From our observations, this feature resizing approach is significantly more effective compared to traditional encoders which often compress data into a much lower dimensionality. 

\subsection{The U-Net Module and fMRI Decoder}
The encoded features $x_{eeg} \in \mathbb{R}^{N \times W \times H}$ are then fed into $\mathcal{M}_{\mathrm{UNet}}$ for further processing. 
This U-Net module consists of two down-sample blocks followed by two up-sample blocks, enabling the extraction of multi-scale features. 
Each down-sample block reduces the spatial dimensions by half while the up-sample blocks restore them. 
The number of output channels for each block is $N$ ($N=256$ in this work) and the output of this model is the same as its input, with $x_{unet}=\mathcal{M}_{\mathrm{UNet}}(x) \in \mathbb{R}^{256 \times W \times H}$. 
Here, the extraction of multi-scale features in $\mathcal{M}_{\mathrm{UNet}}$ is crucial, as our preliminary experiments revealed that the model without the U-Net module failed to accurately reconstruct the fMRI targets. 

The fMRI decoder $\mathcal{M}_{\mathrm{fMRI}}$ then gradually reduces the depth of $x_{unet}$ from $N \rightarrow D$ while maintaining the spatial size $W \times H$. 
Finally, the generated fMRI is $\hat{y} = \mathcal{M}_{\mathrm{fMRI}}(x_{unet}) = \mathrm{E2fNet}(x) \in \mathbb{R}^{D \times W \times H}$. 

\subsection{Loss Function}
To train the E2fNet model, we employed the SSIM and mean square error (MSE) losses for balanced structural and pixel-wise accuracy. 
The objective function for training is:
%% Equation (1)
\begin{equation}
\label{eq:1}
\mathcal{L}(y, \hat{y}) = \lambda_{1} \mathrm{SSIM}(y, \hat{y}) + \lambda_{2} \mathrm{MSE}(y, \hat{y}),
\end{equation}
where $y$ and $\hat{y}$ are the ground-truth and generated fMRI, respectively. 
$\lambda_{1}$ and $\lambda_{2}$ are the loss coefficients. 
For more details on the architecture and implementation, please refer to our GitHub repository. 
% Table I
\input{tables/Table_I}