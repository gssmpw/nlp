We introduce CritiQ, a novel method that automatically and mine quality criteria
from human preferences for data quality with limited human annotation and performs
efficient data selection. It uses ann agent workflow, CritiQ Flow, to
effectively summarize quality criteria from only $\sim$30 human-annotated test sets.
pairwise comparisons. CritiQ Flow achieves high accuracies on human-annotated
test sets. Efficient data selection is performed by lightweight CritiQ Scorer.
We train models on our selected subset and observe increased performance on code,
math and logic domains, compared to a uniformly sampled subset.% We release the code of CritiQ to facilitate future research.
