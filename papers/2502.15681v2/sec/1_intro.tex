\section{Introduction}
\label{sec:intro}

Diffusion models~\cite{ho2020ddpm, song2020score} are transforming generative modeling in visual domains, with impressive success in generating images~\cite{rombach2022high,saharia2022photorealistic, balaji2022ediffi}, videos~\cite{ho2022video, singer2023makeavideo}, 3D objects~\cite{luo2021diffusion, zeng2022lion}, motion~\cite{zhang2022motiondiffuse, yuan2023physdiff}, etc. However, one of the key limitations of deploying diffusion models in real-world applications is their slow and computationally expensive sampling process that involves calling the denoising neural network iteratively.
\begin{figure}[t]
    \centering
  \begin{subfigure}[b]{0.48\textwidth}
    \includegraphics[width=\textwidth]{img/sd_images_.png}
        \vspace{-12pt}
    \caption{50-step Teacher, SDXL}
  \end{subfigure}
 \hfill
  % \begin{subfigure}[b]{0.33\textwidth}
  %   \includegraphics[width=\textwidth]{img/dmd.png}
  %   \vspace{-12pt}
  %   \caption{}
  % \end{subfigure}\hfill
    \begin{subfigure}[b]{0.48\textwidth}
    \includegraphics[width=\textwidth]{img/step_14000.png}
    \vspace{-12pt}
    \caption{One-step $f$-distill}
  \end{subfigure}
    \caption{Uncurated generated samples by the 50-step teacher~(CFG=8) (a), and one-step student in \methodtext (b), using same set of prompts on SDXL.}
    \label{fig:vis-main}
    \vspace{-12pt}
\end{figure}
Early works on accelerating diffusion models relied on better numerical solvers for solving the ordinary differential equations (ODEs) or stochastic differential equations (SDEs) that describe the sampling process of diffusion models~\cite{Song2020DenoisingDI, JolicoeurMartineau2021GottaGF, lu2022dpm, Karras2022ElucidatingTD, Xu2023RestartSF}. However, these methods can only reduce the number of sampling steps to around tens of steps, due to the discretization error, accumulated with fewer steps.

More recently, distillation-based approaches aim at the ambitious goal of reducing the number of sampling steps to a single network call. These approaches can be generally grouped into two categories: 1) trajectory distillation~\cite{song2023consistency, song2023improved, geng2024consistency, lee2024truncated, lu2024simplifying} which distills the deterministic ODE mapping between noise and data intrinsic in a diffusion model to a one-step student, and 2) distribution matching approaches~\cite{yin2024one, yin2024improved, zheng2024diffusion, zhou2024score} that ignore the deterministic mappings, and instead, matches the distribution of samples generated by a one-step student to the distribution imposed by a pre-trained teacher diffusion model. Among the two categories, the latter often performs better in practice as the deterministic mapping between noise and data is deemed complex and hard to learn. Naturally, the choice of divergence in distribution matching plays a key role as it dictates how the student's distribution is matched against the teacher's. Existing works~\cite{yin2024one, yin2024improved, dao2025swiftbrush, nguyen2024swiftbrush} commonly use variational score distillation~\cite{Wang2023ProlificDreamerHA} that matches the distribution of the student and teacher by minimizing the reverse-KL divergence. However, this divergence is known to be mode-seeking~\cite{Bishop2006PatternRA} and can potentially ignore diverse modes learned by the diffusion model. 




The reverse-KL divergence is a member of the broader $f$-divergence family~\cite{Rnyi1961OnMO}. The $f$-divergence represents a large family of divergences including reverse-KL, forward-KL, Jensen-Shannon (JS), squared Hellinger, etc. These divergences come with different trade-offs, including how they penalize the student for missing modes in the teacher distribution and how they can be estimated and optimized using Monte Carlo sampling. However, the application of arbitrary $f$-divergences to diffusion distillation, and the practical estimation of the student's gradient, remain open challenges.  

In this work, we address these challenges by establishing the connection between $f$-divergence and diffusion distillation with a novel distillation framework, which we term \method. We derive the gradient of $f$-divergence distribution matching within the context of diffusion distillation, and show that it is the product of the difference in score between teacher and student (which also exists in prior works), and a weighting function that depends on density ratio and the chosen $f$-divergence (new in this work), as illustrated in Fig.~\ref{fig:teaser}. The density ratio can be readily obtained from the discriminator in the commonly used auxiliary GAN objective. We show that the previous DMD approach is a special case of our approach that corresponds to a constant weighting. We discuss how the newly derived weighting coefficient influences the tradeoffs discussed above and propose normalization techniques for stabilizing divergences with higher gradient variance. As shown in Fig.~\ref{fig:toy_diff}, we observe that the weight coefficient for less mode-seeking $f$-divergences will downweight the score difference in the areas where the teacher has low density. This is in line with the observation that score estimation in low-density regions can be inaccurate~\cite{karras2024guiding} and allows our model to adaptively rely less on matching its score with the teacher's \textit{unreliable} score on such regions. 

We further analyze the properties of various canonical $f$-divergences within our framework. For instance, forward-KL has a better mode coverage, but has a large gradient variance; JS demonstrates moderate mode-seeking and gradient saturation, particularly in early training stages, but exhibits low variance. Our analysis reveals that no single $f$-divergence consistently outperforms others across all datasets. We observe divergences with better mode coverage tendencies generally perform better on the CIFAR-10 dataset. However, on large-scale challenging datasets like ImageNet-64 and text-to-image generation with Stable Diffusion, divergences with lower variance achieve superior results. Empirically, we validate the \methodtext framework on several image generation tasks. Quantitative results demonstrate that the less mode-seeking divergences in \methodtext consistently outperform previous best variational score distillation approaches. Notably, by minimizing the less mode-seeking and lower gradient variance Jensen-Shannon divergences, \methodtext achieves new state-of-the-art one-step generation performance on ImageNet-64 and zero-shot MS-COCO (using SD v1.5). We also show that \methodtext is scalable to larger model SDXL, as shown in Fig~\ref{fig:vis-main}. Our empirical analysis also confirms that the weighting function effectively assigns smaller weights to regions with larger score differences.


\begin{figure*}[t]
    \centering
    \vspace{-0.8cm}
    \includegraphics[width=0.8\linewidth, clip=true, trim={0, 0, 0, 0.5cm,}]{img/main_3.png}
    \vspace{-8pt}
    \caption{The gradient update in \methodtext is a product of the difference between the teacher and fake scores and a weighting function determined by the chosen $f$-divergence and density ratio. The density ratio is readily available in the auxiliary GAN objective. %\wn{We can optimize the layout of this figure to save some space.}
    }
    \label{fig:teaser}
    \vspace{-10pt}
\end{figure*}

% In this work, we propose a novel generalization of the distribution matching distillation approach using the $f$-divergence, termed \method. Within our framework, we evaluate various $f$-divergences based on these properties and observe different tradeoff. For instance, forward-KL has a better mode coverage, but has a large gradient variance; JS demonstrates moderate mode-seeking and gradient saturation, particularly in early training stages, but exhibits low variance. Our analysis reveals that no single $f$-divergence consistently outperforms others across all datasets. We observe divergences with better mode coverage tendencies generally perform better on the CIFAR-10 dataset. However, on large-scale challenging datasets like ImageNet-64 and text-to-image generation with Stable Diffusion (SD), divergences with lower variance achieve superior results.

 \begin{figure}
     \centering
     \includegraphics[width=0.9\linewidth, trim=0.cm 0.2cm 0.cm 0.2cm, clip]{img/toy_2.png}
     \caption{Score difference and the weighting function on a 2D example. $h$ is the weighting function in forward-KL.  Observe that the teacher and fake scores often diverge in lower-density regions (darker colors in the bottom left figure indicate larger score differences), where larger estimation errors occur. The weighting function downweights these regions~(lighter colors in the bottom right figure) during gradient updates for \method.\looseness=-1}
     \label{fig:toy_diff}
     \vspace{-12pt}
 \end{figure}



\textbf{Contributions.} \textit{(i)} We derive the gradient of the $f$-divergence in distribution matching distillation, enabling the application of arbitrary $f$-divergences. \textit{(ii)} We discuss different trade-offs with different choices of $f$-divergence in terms of mode seeking, gradient saturation and variance. \textit{(iii)} We provide practical guidelines on reducing the variance of gradient and estimating different terms in the objective efficiently. \textit{(iv)} We empirically show that our proposed \methodtext achieves the state-of-the-art FID score in one-step generation on the ImageNet-64 and zero-shot MS-COCO text-to-image benchmark. \looseness=-1

\iffalse
Intro outline: 
\begin{enumerate}
    \item Although diffusion models gradually take over many fields, they have a slow iterative sampling process. The previous ODE/SDE fast samplers have reached their limit. To further push the speed, We should distill it into one/two-step generator.
  \item  To this end, we develop a general $f$-divergence minimization framework to match the generative distribution of teacher diffusions model and one-step student. We derive the gradient update rule for minimizing $f$, which is the product of the difference in score between teacher and student, and a weighting function that depends on density ratio and $f$. The framework encompasses previous variational score distillation, which produces high-fidelity one-step samples but has the mode-collapse issue.
  (Another way of motivating our method: Consistency models have low ceiling compared to distributional matching approaches. Among distributional matching approaches, 1. GAN is unstable, 2. Variational score distillation(DMD) produces high-fidelity one-step samples but has a mode-collapse issue. Hence, we...)
  \item   Within our framework, we evaluate various $f$-divergences based on three key properties: mode-seeking behavior, saturation, and gradient variance. We observe inherent trade-offs among these properties depending on the choice of the $f$-divergence. For instance, forward-KL is not mode-seeking, but it has a large gradient variance; JS demonstrates moderate mode-seeking and saturation, particularly in early training stages, but exhibits low variance. Our analysis reveals that no single $f$-divergence consistently outperforms others across all datasets. We observe divergences with weaker mode-seeking tendencies generally perform better on CIFAR-10. However, on large-scale datasets like ImageNet-64 and SD1.5, divergences with lower variance achieve superior results.
 \item There is an additional benefit of those divergences without mode-seeking. Their second order derivative $f''$ usually decays slower than $1/x^2$ when $x\to \infty$ (it matches the theoretical results in another paper. I can elaborate on this point), and thus the weighting function is an increasing function of $p/q$. It leads to an interesting behavior: they will down-weight the samples where the teacher's score has a larger error, which matches the intuition in the auto-guidance paper.
  \item  Empirically, our method obtains SOTA one-step FID on ImageNet-64 and MSCOCO-30K (SDv1.5) 
\end{enumerate}

\fi