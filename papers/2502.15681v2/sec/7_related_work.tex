\section{Related work}
\vspace{-3pt}
% \paragraph{Diffusion sampling acceleration.}

As the sampling process in diffusion models is essentially solving the ODEs or SDEs~\citep{song2020score}, many early works focus on reducing the sampling steps with faster numerical solvers~\citep{Song2020DenoisingDI,lu2022dpmp,Karras2022ElucidatingTD,liu2022pseudo,zheng2024dpm}. However, they usually still require more than 20 steps due to the discretization error. Diffusion distillation has recently attracted more attention due to its promising goal of reducing the number of sampling steps to one single network call. 
It mainly includes two classes of distillation approaches: 

(1) \emph{Trajectory distillation}, which trains a one-step student model to mimic the deterministic sampling process of the teacher diffusion model. Knowledge distillation~\citep{luhman2021knowledge,zheng2022fast} learns a direct mapping from noise to data. Progressive distillation~\cite{salimans2022progressive,meng2023distillation} iteratively halves the number of sampling steps via distillation. Consistency models~\citep{song2023consistency,song2023improved,geng2024consistency,lee2024truncated,lu2024simplifying} lean a consistency function that maps any noisy data along an ODE trajectory to the associated clean data. 

(2) \emph{Distribution matching}, which aligns the distribution of the one-step student with that of the teacher diffusion model. 
Adversarial distillation~\citep{sauer2023adversarial,sauer2024fast,xu2024ufogen} mainly relies on the adversarial training~\citep{goodfellow2014generative} to learn teacher output's distribution. Another line of approaches implicitly minimizes various divergences, often via variational score distillation~\citep{wang2024prolificdreamer}, such as reverse-KL~\citep{yin2024one,yin2024improved}, forward KL~\citep{luo2024diff,xie2024distillation} and fisher divergence~\citep{zhou2024score}. Score Implicit Matching~\citep{luo2024one} generalizes the fisher divergence~\citep{zhou2024score} by relaxing the score-based distance to have more general forms beyond squared $L_2$. Our method lies in this category. Different from previous methods that only minimize a particular distribution divergence, each of which may require vastly different training strategies~\citep{yin2024improved,xie2024distillation,zhou2024score}, our method unifies the class of $f$-divergences in a principled way and thus offers better flexibility in distribution matching distillation.



% \paragraph{$f$-divergence in generative learning. }