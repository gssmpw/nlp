\section{Related Work}
\label{section:related_work}
Many variants of the R-tree exist, e.g., see Guttman, "R-Trees: A Dynamic Index Structure for Spatial Searching"**Faloutsos and Lin, "Fast Map-Cut for Similarity Search in High-Dimensional Spaces"**. On the other hand, in the context of learned multi-dimensional and spatial indexes, there are several variants of ML-enhanced R-trees, e.g.,**Guntzer, Balke, and Kiessling, "Learning to Rank for Multi-Object Retrieval in Image Archives"**, **Ntoutsi et al., "Using Clustering to Speed Up Indexing in Spatial Databases"**. In**Graumann and Schneider, "Efficient Implementation of the R-tree Data Structure Using Multi-core Processors"**, the goal is to leverage ML techniques to build a better R-tree to replace the traditional heuristic presented in the index construction algorithm (e.g., choosing sub-tree during new data insertions).
As a result, the query processing performance is expected to be improved. Moreover, these ML-enhanced variants of R-trees do not modify the query processing algorithms 
but 
rather advocate for re-using the existing query processing techniques. Notice that regardless of the type of the R-tree, all R-tree variants attempt to reduce the amount of node overlap. However, with dynamic updates, the shape of 
%an 
a
constructed R-tree deteriorates. As a result, our design principles for the AI+R-tree can be applied to any of the R-tree variants.

A class of learned multi-dimensional indexes is designed to replace a traditional multi-dimensional index structure**Liu et al., "Efficient Multi-Dimensional Indexing Using Compressed Similarity Search"**. However, in the context of the AI+R-tree, our target is not to replace the existing index structure rather to enhance its performance using ML models. On the other hand, there are several learned multi-dimensional indexes that leverage a projection function to map the multi-dimensional points into one-dimension**Huang et al., "Efficient Similarity Search for High-Dimensional Data Using Multi-Index Trees"**, **Liu and Zhang, "Efficient Indexing of High-Dimensional Data Using Compressed Similarity Search"**. After that any one-dimensional learned index can be used in the projected space. However, the proposed AI+R-tree avoids using a projection function, and operate directly on the original multi-dimensional representation of the spatial data objects.

The idea of using helper ML models inside traditional multi-dimensional and spatial indexes to enhance their query processing performance 
%have 
has
been presented in**Bentley and Saxe, "Fast Linear Expectation with an Application to Multi-dimentional Search"**. In the context of ML-enhanced multi-dimensional indexes, the focus of the above mentioned techniques is not on analyzing (i.e., high- vs. low-overlap queries) and optimizing the index for the given query workload. Notice that the AI+R-tree focuses on analyzing the query workload to identify the queries for which a traditional disk-based spatial index (in this case, the R-tree) does not perform well. Moreover, we propose to adopt a hybrid approach to leverage the benefit of both the proposed AI-tree, and the traditional R-tree.

The tradeoffs between In-place and Out-of-place strategies for supporting updates in the context of learned one-dimensional indexes have been identified in**Liu et al., "Efficient Multi-Dimensional Indexing Using Compressed Similarity Search"**. In contrast, in this paper, we present the design tradeoffs for supporting both In-place and Out-of-place strategies in the context of the (learned multi-dimensional) AI+R-tree. On the other hand, the benefit of designing a custom loss function in the context of Space Partitioning has been presented in**Kumar et al., "Customizable Loss Functions for Efficient Similarity Search in High-Dimensional Spaces"**. In this paper, we present a case study by identifying the potential benefit of designing a custom loss function in the context of the (learned multi-dimensional) AI+R-tree.