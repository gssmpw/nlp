\section{Related Work}
\begin{figure*}[t]
\centering
\includegraphics[width=.96\textwidth]{fig/pipeline.png}
\caption{The processing pipeline of the proposed explanation approach; dashed lines indicate iterative processes. (Input Deepfake Image source: FaceForensics++ dataset).}
\label{fig:pipeline}
\end{figure*}

Despite the ongoing interest in developing AI-based models for detecting deepfake images and videos, the explanation of the output of these models has been investigated only to a small extent, thus far. In one of the first attempts towards explaining a deepfake detector's decision, Malolan \etal ____, examined the use of the LIME ____ and LRP ____ methods to produce visual explanations (in the form of heatmaps) about the output of an XceptionNet-based ____ detector that was trained on a subset of the FaceForensics++ dataset ____. Pino \etal ____ employed adaptations of SHAP ____, Grad-CAM ____ and self-attention methods, to explain the output of deepfake detectors (based on EfficientNet-B4 and B7 ____) that were trained on the DFDC dataset ____. Silva \etal ____, applied the Grad-CAM method ____ and focused on the computed gradients for the attention map to spot the image regions that influence the most the predictions of an ensemble of CNNs (XceptionNet ____, EfficientNet-B3 ____) and attention-based models for deepfake detection. Xu \etal ____, utilized learned features to explain the detection performance of a trained linear deepfake detector on the FaceForensics++ dataset ____, with the help of heatmap visualizations and uniform manifold approximation and projection. Jayakumar \etal ____, employed the Anchors ____ and LIME ____ methods to produce visual explanations for a trained model (based on EfficientNet-B0 ____) that detects five different types of deepfakes. Aghasanli \etal ____, used SVM and xDNN ____ classifiers to understand the behavior of a Transformer-based deepfake detector. Finally, Jia \etal ____ examined the capacity of multimodal LLMs in detecting deepfakes and providing textual explanations about their decisions.

In terms of evaluation, most of the aforementioned works evaluate the produced explanations qualitatively using a small set of samples ____. Towards a quantitative, and thus more objective, evaluation, Pino \etal ____ used tailored metrics that relate to low-level features of the obtained visual explanations, such as inter/intra-frame consistency, variance and centredness. Gowrisankar \etal ____ described a framework that applies a number of adversarial attacks, adding noise in regions of a deepfake image that correspond to the spotted salient regions after explaining the (correct) classification of its real counterpart, and evaluates the performance of an explanation method based on the observed drop in the detector's accuracy. Building on ____, Tsigos \etal ____ proposed a simpler evaluation framework, which uses the produced explanation after detecting a deepfake image and does not require access to its original counterpart. Finally, the ROAD framework ____ for evaluating attribution-based explanation methods for image classifiers, applies a similar noise-based imputation strategy. Nevertheless, the efficiency of the applied imputation has not been investigated thus far on deepfake classifiers. 

Our paper is most closely related with works that utilize ____ or evaluate ____ perturbation-based explanation methods. Nevertheless, contrary to these works, we propose the use of adversarially-generated perturbation masks and investigate their impact on inferring the importance of input features using modified versions of four SOTA perturbation-based explanation methods (RISE ____, SHAP ____, LIME ____, SOBOL ____). Moreover, in contrast to ____, that evaluate explanations only qualitatively using a small set of samples, we assess the performance of explanation methods also using a quantitative evaluation framework.