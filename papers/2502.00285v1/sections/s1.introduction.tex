\section{Introduction}\label{sec:introduction}


Trajectory similarity measures quantify the similarity between two trajectories and thus play an essential role in many spatio-temporal data mining tasks and queries, such as trajectory clustering~\cite{edr,representative_traj}, anomaly detection~\cite{laxhammar2013online,liu2020online}, and $k$-nearest neighbor ($k$NN) queries~\cite{dita,torch}. 
Conventional measures~\cite{dfrechet,edr,edwp} (a.k.a. \emph{non-learned measures}) are typically based on heuristic rules that match up the points in two trajectories. The similarity values are then determined by the distances between matched points. 
These measures often use dynamic programming to speed up the computation, which, however, remain costly for long trajectories~\cite{trajsimi_survey}.

Recent studies~\cite{neutraj,gts,t3s,st2vec,trajgat,trajcl,kgts} adopt deep learning models to learn trajectory embeddings to accelerate similarity computation (a.k.a. \emph{learned measures}).
The idea is that trajectory embeddings are pre-computed offline (or computed online once)  and are then used multiple times. Once embeddings are obtained, the similarity between two trajectories can be approximated by the distance between their embeddings, which can be computed efficiently. 


\begin{figure}[ht]
    \centering
    \hspace*{-1mm}
    \vspace{-3mm}
    \includegraphics[width=1.02\columnwidth]{figures/point_modeling_5.pdf}
    \vspace{-3mm}
    \caption{Different forms of trajectory input modeling.}\label{fig:point_modeling}
    \vspace{-2mm}
\end{figure}

While high efficiency has  been reported~\cite{t3s,tmn,trajcl}, we observe two issues with the learned measures that hinder their accuracy:

(1)~\textbf{Difficulties in modeling the movement patterns in a trajectory at different spatial granularities}: 
Existing solutions model an input trajectory as a sequence of points or a sequence of cells enclosing the trajectory points (see ``point-based'' and ``cell-based'' in Figure~\ref{fig:point_modeling}), or they use both input representations together. 
Point-based approaches consume raw GPS points that capture specific locations passed by the trajectories, while they do not reflect  explicitly the relationships between the points (i.e., movement patterns). 
Cell-based approaches discretize the underlying space with a grid and replace GPS points by the cells enclosing them. The cell-based representation only captures rough locations passed by the trajectories, and it is difficult to determine a grid granularity that retains just the right level of detail of the trajectories. 
Both approaches rely on a single granularity and may not retain the key movement patterns of different trajectories.


(2)~\textbf{Difficulties in fully 
exploiting similarity signals in training data}:
Existing solutions minimize the \emph{mean square error} (MSE) between the predicted similarity of models and the ground-truth similarity, which is typically defined by a non-learned measure.  The ground-truth similarity values can come from a large continuous domain, which may not be fully reflected by the MSE over individual training samples. Thus, it is difficult for a model to learn the similarity concept in the training data from just examining the MSE results.


To address these issues, we propose \model, \emph{a highly effective trajectory similarity learning model with a sub-view encoder and a $k$NN-guided loss}. 

The \emph{sub-view encoder} prepares and encodes multi-grained sub-views of input trajectories. 
As Figure~\ref{fig:point_modeling} shows,  
a sub-view of a trajectory is a consecutive sub-sequence of the trajectory points that captures fine-grained local movement patterns. 
The decomposition of a trajectory into sub-views is done recursively, hence forming a series of sub-views capturing  movement patterns at different granularities (Figure~\ref{fig:subview}).

The output of the sub-view encoder is fed to a one-layer trajectory encoder for trajectory embedding learning. 
This simple encoder is a side benefit of our multi-grained sub-view modeling, as much of the pattern learning task occurs in the sub-view encoder.


To train \model, we employ a \emph{$k$ nearest neighbor ($k$NN)-guided loss function} to better exploit training signals in the data. 
The intuition is that, instead of learning from individual similarity values defined by some non-learned measure (e.g., DTW~\cite{dtw}) between each trajectory pair, we examine the relative similarity between different pairs of trajectories to guide \model\ to better learn the similarity space defined by the non-learned measure. 
The $k$NN-guided loss achieves this by imposing a penalty when a trajectory and one of its  $k$NN trajectories are predicted to be less similar than the trajectory and any of its non-$k$NNs.




To sum up, our main contributions are as follows:

(1)~We propose \model, a highly effective model for trajectory similarity learning with a sub-view encoder and a $k$NN-guided loss. 
    
(2)~The sub-view encoder captures multi-grained movement patterns in individual trajectories, while the $k$NN-based loss guides \model\ to learn the  relative similarity among multiple pairs of trajectories. Together, they enable \model\ to better learn the trajectory similarity space. 
    
    
(3)~We conduct extensive experiments on three large real  datasets. The results show that \model\ can outperform the state-of-the-art models substantially and consistently, with an accuracy improvement of over 22\% on average. 
