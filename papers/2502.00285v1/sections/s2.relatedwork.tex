\section{Related Work}\label{sec:relatedwork}

\paragraph{Non-learned Trajectory Similarity Measures} 
Non-learned measures typically leverage dynamic programming or enumeration to find optimal point matches as defined by hand-crafted rules, based on which trajectory similarity values are calculated~\cite{hausdorff,dfrechet,lcss,erp,edr,dtw,edwp}. They typically have quadratic time complexity to the number of points on trajectories.


\paragraph{Learned Trajectory Similarity Measures} %\label{subsec:relatedwork_learned}  
Learned measures typically first encode trajectories into embedding vectors and then compute similarity based on the embeddings.


Earlier works mainly use recurrent neural networks (RNNs) as the trajectory encoder.
For example, NEUTRAJ~\cite{neutraj} encodes raw trajectory points. It introduces an MSE loss weighted by the similarity of the trajectories to focus on the most similar trajectories.
TMN~\cite{tmn} builds upon NEUTRAJ and directly 
takes two trajectories as input to predict a similarity value without embedding computation or reuse. 
KGTS~\cite{kgts} adopts a knowledge graph to model the grid space and learns cell embeddings and it then learns trajectory embeddings from cell embeddings with a GRU~\cite{gru}. 


More recent studies use self-attention as the trajectory encoder, such as T3S~\cite{t3s} and TrajCL~\cite{trajcl}.
Both models take raw GPS points and the cell sequence as the input. T3S applies a self-attention model and an LSTM~\cite{lstm} to encode the two types of inputs, respectively, while TrajCL introduces a dual-feature self-attention module to fuse the features of raw points and grid cells.  Unlike T3S and TrajCL, TSMini recursively constructs the features at multiple granularities from sub-trajectories.
Another work, TrajGAT~\cite{trajgat},  uses a graph-based self-attention  encoder. It utilizes a quadtree~\cite{quadtree} to partition the space into cells which form the encoder input.

Besides, TrjSR~\cite{trjsr} and ConvTraj~\cite{Convtraj} transform trajectories into 2D images and use convolutional layers to learn trajectory representation.  ConvTraj also encodes original trajectory inputs. However, the generated images are mapped to  specific spatial regions, which limits their generalizability, while our trajectory encoder does not suffer from such an issue. Further, these methods learn their own stand-alone measure, which differs from our setting of learning to approximate a given ground-truth measure. 

Unlike these methods, we use multi-grained sub-views as the input and a $k$NN-guided loss, enabling our model to capture trajectory movement patterns at different granularity and the relative similarity between trajectories.