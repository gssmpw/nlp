[
  {
    "index": 0,
    "papers": [
      {
        "key": "polyak_new_1990",
        "author": "Polyak, B. T.",
        "title": "New stochastic approximation type procedures"
      }
    ]
  },
  {
    "index": 1,
    "papers": [
      {
        "key": "david_ruppert_efficient_1988",
        "author": "David Ruppert",
        "title": "Efficient {Estimations} from a {Slowly} {Convergent} {Robbins}-{Monro} {Process}"
      }
    ]
  },
  {
    "index": 2,
    "papers": [
      {
        "key": "polyak_acceleration_1992",
        "author": "Polyak, B. T. and Juditsky, A. B.",
        "title": "Acceleration of {Stochastic} {Approximation} by {Averaging}"
      },
      {
        "key": "bach_non-strongly-convex_2013",
        "author": "Bach, Francis and Moulines, Eric",
        "title": "Non-strongly-convex smooth stochastic approximation with convergence rate {O}(1/n)"
      },
      {
        "key": "neu_iterate_2018",
        "author": "Neu, Gergely and Rosasco, Lorenzo",
        "title": "Iterate {Averaging} as {Regularization} for {Stochastic} {Gradient} {Descent}"
      },
      {
        "key": "lakshminarayanan_linear_2018",
        "author": "Lakshminarayanan, Chandrashekar and Szepesvari, Csaba",
        "title": "Linear {Stochastic} {Approximation}: {How} {Far} {Does} {Constant} {Step}-{Size} and {Iterate} {Averaging} {Go}?"
      }
    ]
  },
  {
    "index": 3,
    "papers": [
      {
        "key": "garrigos2023handbook",
        "author": "Garrigos, Guillaume and Gower, Robert M",
        "title": "Handbook of convergence theorems for (stochastic) gradient methods"
      }
    ]
  },
  {
    "index": 4,
    "papers": [
      {
        "key": "szegedy_2016_rethinking",
        "author": "Szegedy, Christian and Vanhoucke, Vincent and Ioffe, Sergey and Shlens, Jon and Wojna, Zbigniew",
        "title": "Rethinking the Inception Architecture for Computer Vision"
      }
    ]
  },
  {
    "index": 5,
    "papers": [
      {
        "key": "vaswani2017attention",
        "author": "Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\\L}ukasz and Polosukhin, Illia",
        "title": "Attention is all you need"
      }
    ]
  },
  {
    "index": 6,
    "papers": [
      {
        "key": "merity2017regularizingoptimizinglstmlanguage",
        "author": "Stephen Merity and Nitish Shirish Keskar and Richard Socher",
        "title": "Regularizing and Optimizing LSTM Language Models"
      }
    ]
  },
  {
    "index": 7,
    "papers": [
      {
        "key": "izmailov_averaging_2019",
        "author": "Pavel Izmailov and Dmitrii Podoprikhin and Timur Garipov and Dmitry Vetrov and Andrew Gordon Wilson",
        "title": "Averaging Weights Leads to Wider Optima and Better Generalization"
      }
    ]
  },
  {
    "index": 8,
    "papers": [
      {
        "key": "tarvainen2018meanteachersbetterrole",
        "author": "Antti Tarvainen and Harri Valpola",
        "title": "Mean teachers are better role models: Weight-averaged consistency targets improve semi-supervised deep learning results"
      },
      {
        "key": "athiwaratkun_there_2018",
        "author": "Athiwaratkun, Ben and Finzi, Marc and Izmailov, Pavel and Wilson, Andrew Gordon",
        "title": "There {Are} {Many} {Consistent} {Explanations} of {Unlabeled} {Data}: {Why} {You} {Should} {Average}"
      }
    ]
  },
  {
    "index": 9,
    "papers": [
      {
        "key": "yang_swalp_2019",
        "author": "Yang, Guandao and Zhang, Tianyi and Kirichenko, Polina and Bai, Junwen and Wilson, Andrew Gordon and Sa, Chris De",
        "title": "{SWALP} : {Stochastic} {Weight} {Averaging} in {Low} {Precision} {Training}"
      }
    ]
  },
  {
    "index": 10,
    "papers": [
      {
        "key": "cha_swad_2021",
        "author": "Cha, Junbum and Chun, Sanghyuk and Lee, Kyungjae and Cho, Han-Cheol and Park, Seunghyun and Lee, Yunsung and Park, Sungrae",
        "title": "{SWAD}: {Domain} {Generalization} by {Seeking} {Flat} {Minima}"
      }
    ]
  },
  {
    "index": 11,
    "papers": [
      {
        "key": "li_trainable_2022",
        "author": "Li, Tao and Huang, Zhehao and Tao, Qinghua and Wu, Yingwen and Huang, Xiaolin",
        "title": "Trainable {Weight} {Averaging}: {Efficient} {Training} by {Optimizing} {Historical} {Solutions}"
      }
    ]
  },
  {
    "index": 12,
    "papers": [
      {
        "key": "kaddour_stop_2022",
        "author": "Kaddour, Jean",
        "title": "Stop {Wasting} {My} {Time}! {Saving} {Days} of {ImageNet} and {BERT} {Training} with {Latest} {Weight} {Averaging}"
      }
    ]
  },
  {
    "index": 13,
    "papers": [
      {
        "key": "sanyal_early_2023",
        "author": "Sanyal, Sunny and Neerkaje, Atula and Kaddour, Jean and Kumar, Abhishek and Sanghavi, Sujay",
        "title": "Early {Weight} {Averaging} meets {High} {Learning} {Rates} for {LLM} {Pre}-training"
      }
    ]
  },
  {
    "index": 14,
    "papers": [
      {
        "key": "DeepSeekV3",
        "author": "DeepSeekAI",
        "title": "DeepSeek-V3: A Strong Mixture-of-Experts Language Model"
      }
    ]
  },
  {
    "index": 15,
    "papers": [
      {
        "key": "li_switch_2024",
        "author": "Li, Siyuan and Liu, Zicheng and Tian, Juanxi and Wang, Ge and Wang, Zedong and Jin, Weiyang and Wu, Di and Tan, Cheng and Lin, Tao and Liu, Yang and Sun, Baigui and Li, Stan Z.",
        "title": "Switch {EMA}: {A} {Free} {Lunch} for {Better} {Flatness} and {Sharpness}"
      },
      {
        "key": "morales_ema",
        "author": "Daniel Morales-Brotons and Thijs Vogels and Hadrien Hendrikx",
        "title": "Exponential Moving Average of Weights in Deep Learning: Dynamics and Benefits"
      }
    ]
  },
  {
    "index": 16,
    "papers": [
      {
        "key": "yaz\u0131c\u01312019avg_gan",
        "author": "Yasin Yaz\u0131c\u0131 and Chuan-Sheng Foo and Stefan Winkler and Kim-Hui Yap and Georgios Piliouras and Vijay Chandrasekhar",
        "title": "The Unusual Effectiveness of Averaging in GAN Training"
      },
      {
        "key": "song2021score_based_gen",
        "author": "Yang Song and Jascha Sohl-Dickstein and Diederik P. Kingma and Abhishek Kumar and Stefano Ermon and Ben Poole",
        "title": "Score-Based Generative Modeling through Stochastic Differential Equations"
      },
      {
        "key": "karras2024nvidia_diffusion_avg",
        "author": "Tero Karras and Miika Aittala and Jaakko Lehtinen and Janne Hellsten and Timo Aila and Samuli Laine",
        "title": "Analyzing and Improving the Training Dynamics of Diffusion Models"
      }
    ]
  },
  {
    "index": 17,
    "papers": [
      {
        "key": "garrigos2023handbook",
        "author": "Garrigos, Guillaume and Gower, Robert M",
        "title": "Handbook of convergence theorems for (stochastic) gradient methods"
      }
    ]
  },
  {
    "index": 18,
    "papers": [
      {
        "key": "sandler_training_2023",
        "author": "Sandler, Mark and Zhmoginov, Andrey and Vladymyrov, Max and Miller, Nolan",
        "title": "Training trajectories, mini-batch losses and the curious role of the learning rate"
      }
    ]
  },
  {
    "index": 19,
    "papers": [
      {
        "key": "hagele2024scaling",
        "author": "Alexander H\\\"agele and Elie Bakouch and Atli Kosson and Loubna Ben Allal and Leandro Von Werra and Martin Jaggi",
        "title": "{Scaling Laws and Compute-Optimal Training Beyond Fixed Training Durations}"
      }
    ]
  },
  {
    "index": 20,
    "papers": [
      {
        "key": "hagele2024scaling",
        "author": "Alexander H\\\"agele and Elie Bakouch and Atli Kosson and Loubna Ben Allal and Leandro Von Werra and Martin Jaggi",
        "title": "{Scaling Laws and Compute-Optimal Training Beyond Fixed Training Durations}"
      }
    ]
  },
  {
    "index": 21,
    "papers": [
      {
        "key": "DeepSeekV3",
        "author": "DeepSeekAI",
        "title": "DeepSeek-V3: A Strong Mixture-of-Experts Language Model"
      }
    ]
  },
  {
    "index": 22,
    "papers": [
      {
        "key": "defazio_road_2024",
        "author": "Defazio, Aaron and Xingyu and Yang and Mehta, Harsh and Mishchenko, Konstantin and Khaled, Ahmed and Cutkosky, Ashok",
        "title": "The {Road} {Less} {Scheduled}"
      }
    ]
  },
  {
    "index": 23,
    "papers": [
      {
        "key": "defazio_road_2024",
        "author": "Defazio, Aaron and Xingyu and Yang and Mehta, Harsh and Mishchenko, Konstantin and Khaled, Ahmed and Cutkosky, Ashok",
        "title": "The {Road} {Less} {Scheduled}"
      }
    ]
  },
  {
    "index": 24,
    "papers": [
      {
        "key": "defazio_road_2024",
        "author": "Defazio, Aaron and Xingyu and Yang and Mehta, Harsh and Mishchenko, Konstantin and Khaled, Ahmed and Cutkosky, Ashok",
        "title": "The {Road} {Less} {Scheduled}"
      }
    ]
  },
  {
    "index": 25,
    "papers": [
      {
        "key": "wortsman_model_2022",
        "author": "Wortsman, Mitchell and Ilharco, Gabriel and Gadre, Samir Ya and Roelofs, Rebecca and Gontijo-Lopes, Raphael and Morcos, Ari S. and Namkoong, Hongseok and Farhadi, Ali and Carmon, Yair and Kornblith, Simon and Schmidt, Ludwig",
        "title": "Model soups: averaging weights of multiple fine-tuned models improves accuracy without increasing inference time"
      }
    ]
  },
  {
    "index": 26,
    "papers": [
      {
        "key": "dahl_benchmarking_2023",
        "author": "Dahl, George E. and Schneider, Frank and Nado, Zachary and Agarwal, Naman and Sastry, Chandramouli Shama and Hennig, Philipp and Medapati, Sourabh and Eschenhagen, Runa and Kasimbeg, Priya and Suo, Daniel and Bae, Juhan and Gilmer, Justin and Peirson, Abel L. and Khan, Bilal and Anil, Rohan and Rabbat, Mike and Krishnan, Shankar and Snider, Daniel and Amid, Ehsan and Chen, Kongtao and Maddison, Chris J. and Vasudev, Rakshith and Badura, Michal and Garg, Ankush and Mattson, Peter",
        "title": "Benchmarking {Neural} {Network} {Training} {Algorithms}"
      }
    ]
  }
]