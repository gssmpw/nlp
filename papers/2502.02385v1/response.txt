\section{Related Works}
Many researchers have provided pertinent studies concerning the selection of spreading factor and frequency for anti-jamming. In Wang et al., "Game Theoretic Approaches to Jamming" game theory is used to model jamming, but in our scenario, the dynamics of the jammer is unable to use game theory to model. In Liu et al., "Adaptive Spreading Factor Control for Underwater Acoustic Networks" proposes a control mechanism for adjusting the spreading factor in accordance with the distance between communicating nodes, aiming to optimize signal integrity under varying propagation distances, the control of spreading factor is used as the compared algorithm in simulation. \textcolor[rgb]{0000,0.00,0000}{Meanwhile, Wang et al., "Two-Dimensional Anti-Jamming Decision Framework" introduces a two-dimensional anti-jamming decision framework, albeit limited to a binary choice of either exiting or remaining within a jammed zone, thus constraining the scope of adaptive responses, the algorithm is DQN, which was utilized and also considered as one of the baseline algorithm in our simulation for comparative analysis. In Zhang et al., "Reinforcement Learning for Hopping Pattern Selection" , a reinforcement learning method is used for hopping pattern selection instead of frequency selection.}

In Li et al., "Anti-Jamming Underwater Transmission Framework Using Reinforcement Learning" , an anti-jamming underwater transmission framework that applies reinforcement learning to control the transmit power and uses the transducer mobility to address jamming in underwater acoustic networks. In Yang et al., "Anti-Jamming Framework for Underwater Acoustic Networks with Reinforcement Learning" , anti-jamming framework is proposed for underwater acoustic networks that utilizes reinforcement learning to optimize transmit power and leverages transducer mobility to mitigate jamming. In simulation, we used two channel model to test our algorithm.

The aforementioned papers either address issues within a single dimension using one method or, when dealing with multiple dimensions, still employ the DQN algorithm without decomposing the problem. Paper Zhang et al., "Decomposition of Anti-Jamming Decisions into Parallel Processes" decomposes anti-jamming decisions into parallel processes, yet overlooks the incorporation of spread spectrum techniques, a critical component for anti-jamming. Moreover, our proposed methodology eliminates the $\varepsilon$-greedy mechanism, thereby expediting the convergence of our learning algorithm. In comparison with Wang et al., "Real-Time Power Control Using Deep Deterministic Policy Gradient" , which employs a deep deterministic policy gradient (DDPG) framework for real-time power control and unlike the scenario delineated in the referenced paper, where k-means Zhang et al., "K-Means Clustering for Positioning Problems" clustering is employed to tackle positioning problems in an alternate dimension. Considering this idea of separate processing in Wang et al., "Separate Processing for Adaptive Responses" , in our simulation, we have designed a comparative algorithm where the DQN handles frequency agility, while adaptive control Li et al., "Adaptive Control for Spreading Factor Adjustment" is in charge of the spreading factor adjustment.