\section{Introduction} \label{sec:intro}

\figHeader
\figSessions

With the enhanced understanding and reasoning capabilities of large language models (LLMs), pre-trained LLMs are increasingly being utilized in dialogue systems \citep{SPACE-3,TOD-Adapters}. Compared with traditional chatbots, LLMs can interact more flexibly with users to address diverse needs, leveraging the vast amount of commonsense knowledge stored in their parameters \citep{LLM-dialogue-survey}. However, in real-world applications, we often expect chatbots to follow specific rules and procedures to perform certain tasks (e.g., guiding users to make an appointment for appropriate hospitals, departments, and doctors \citep{STAR,SPACE-3}). The procedures that must be followed through dialogues are known as \emph{workflows}. LLMs, acting as \emph{workflow agents}, assist users via conversations and invoke relevant tools to fulfill requests \citep{FlowBench}.

Existing research can be broadly classified into two categories: rule-based and prompt-based methods.
\textbf{Rule-based} methods \citep{coze,dify,flowise} control the conversation between the agent and the user through deterministic programs, \emph{modeling the progress of dialogue as state transitions within a graph composed of nodes representing different dialogue states}, as shown in the upper part of Fig.~\ref{fig:header}(a). 
In this approach, the LLM functions as a node within the graph and cannot control the entire conversation flow. As a result, this method provides high compliance but often at the expense of the LLM's inherent \textbf{flexibility}. As illustrated in the lower part of Fig.~\ref{fig:header}(a), introducing a new flexible feature within this system (e.g., allowing users to pause an appointment booking process to inquire about a condition before resuming) requires the addition of numerous transition egeds (dashed lines), significantly increasing complexity.
In contrast, \textbf{prompt-based} methods leverage LLMs to autonomously manage dialogue by \emph{representing workflows textually} (natural language, code or other structured data, Fig.~\ref{fig:header}(b)). 
While this method imparts soft control over LLM responses (workflow as part of prompt), LLMs' probabilistic nature often leads to \textbf{compliance} issues, like hallucinating incorrect information, which can have serious repercussions (e.g., notifying a user about a successful appointment booking when it hasn't occurred) \citep{Hallucination-survey}.

This brings us to the critical question of our work: \textbf{How can we enhance LLM compliance with workflow tasks without diminishing their interaction flexibility?}
This question arises from two primary challenges: 1) \emph{How should we precisely represent workflows?} 2) \emph{How can we effectively control LLM behavior?}

To address the first challenge, as shown in Fig.~\ref{fig:header}(c), we introduce \emph{Procedure Description Language (PDL)}, which merges the fluidity of natural language with the precision of coding. PDL's flexible syntax allows for comprehensive node definitions, facilitating accurate workflow representations (see Sec.~\ref{subsec:pdl-syntax}).
To tackle the second challenge, we present the \model framework, which includes a set of controllers that manage agent behavior according to PDL-defined nodes. This system allows LLMs to make autonomous yet monitored and legally constrained decisions (see Sec.~\ref{subsec:arch}).

Fig.~\ref{fig:sessions} illustrates two sessions in a hospital appointment setting. In session 1, when a user wishes to switch from Hospital A to Hospital B during the registration process, \model demonstrates \emph{flexibility} by re-invoking the \codef{check\_hospital} API as per PDL directives. Conversely, in session 2, when the user prompts, \quotes{Just tell me the result of the appointment}, the LLM might attempt to respond without executing the necessary booking API. However, the controllers in the \model framework prevent such an occurrence by ensuring that prerequisite conditions are met before informing the user of the booking result, highlighting the \emph{compliance} offered by \model. 

Our \textbf{contributions} are threefold: \\
1. We provide a systematic analysis of existing LLM-based workflow agents, focusing on compliance and flexibility. Based on this analysis, we propose the PDL syntax, combining natural language and code to flexibly describe node relationships and workflow procedures. \\
2. We introduce the \model framework, which aids in the execution of workflow agents. By crafting PDL-driven controllers, we dynamically balance compliance and flexibility. Experiments on three datasets demonstrate \model's balanced compliance and flexibility within and beyond pre-defined workflows. \\
3. We construct a comprehensive evaluation benchmark augmenting existing datasets to assess workflow agent performance in out-of-workflow (OOW) scenarios. 
