



\section{EXPERIMENTS}\label{experiments}


\subsection{Experimental configuration}\label{exp_config}

{\textbf{The language model.} We use GPT-2-like Transformers for causal language modeling, employing the standard 11M Drug-like Zinc dataset for training. Entries with empty scaffold SMILES are excluded, and we adopt a 90/10 split for training and validation, respectively. The training process is structured into three phases: pretraining, fine-tuning, and decoding optimization, as outlined in Algorithm \algname (See appendix for more details).}






\textbf{Baselines.}
{
We compare against baseline models: DrugImprover~\citep{liu2023drugimprover}, which utilizes an LSTM-based generator with APO fine-tuning; 
Molsearch \citep{sun2022molsearch}, a Monte Carlo tree search (MCTS)-driven approach for molecular generation and optimization; MIMOSA \citep{fu2021mimosa}, a sampling-based method leveraging graph-based molecular optimization; and \fix{DrugEx v3 \citep{liu2023drugex}, which leverages transformer-based reinforcement learning for scaffold-guided drug optimization}. Additionally, we incorporate the model proposed by \citet{he2021molecular, he2022transformer,  loeffler2024reinvent}, which trains a transformer to adhere to the Matched Molecular Pair (MMP) guidelines~\citep{kenny2005structure,tyrchan2017matched}.
Specifically, given a set $\{\{X,Y,Z\}\}$, where $X$ represents the source molecule, $Y$ denotes the target molecule, and $Z$ signifies the property change between $X$ and $Y$, the model learns a mapping from $\{X, Z\} \in \ensuremath{\mathcal{X}} \times \ensuremath{\mathcal{Z}} \implies Y \in \ensuremath{\mathcal{Y}}$ during training. Here, $\ensuremath{\mathcal{X}} \times \ensuremath{\mathcal{Z}}$ denotes the input space, and $\ensuremath{\mathcal{Y}}$ denotes the target space. They defined six different types of property changes for $Z$, including MMP for user-specified alterations, various similarity thresholds, and scaffold-based modifications where molecules share the same scaffold or a generic scaffold. More specifically,
\begin{itemize}[noitemsep, topsep=0pt, partopsep=0pt]
    \item MMP: there exists user-specified property changes between molecule $X$ and $Y$.
    \item Similarity $\geq 0.5$: tanimoto similarity between molecule $X$ and $Y$ is larger than 0.5.
    \item Similarity $\in[0.5, 0.7)$: the tanimoto similarity of pair $\paren{X,Y}$ is between 0.5 and 0.7.
    \item Similarity $\geq 0.7$: tanimoto similarity between molecule $X$ and $Y$ is larger than 0.7.
    \item Scaffold: molecule $X$ and $Y$ share same scaffold.
    \item Scaffold generic: molecule $X$ and $Y$ share same generic scaffold.\XL{cite}
\end{itemize}
}
\fix{All baseline models are fine-tuned on the cancer and COVID datasets following their respective fine-tuning methods.}









\begin{table*}[t!]
\setlength{\tabcolsep}{4pt}
   \centering
    {\small
    \scalebox{0.48}{
    \begin{tabular}{l l c c c c c c c c c c }
        \toprule
        \textbf{Target} %
        & \textbf{Algorithm}
        & {\makecell[c]{Validity~$\uparrow$}}
        & {\makecell[c]{Avg \\ Norm Reward~$\uparrow$$^{{\star}}$}}
        & {\makecell[c]{Avg Top 10 \% \\ Norm Reward~$\uparrow$}}
        & {\makecell[c]{Docking ~$\downarrow$}}
        & {\makecell[c]{Druglikeliness ~$\uparrow$}}
        & {\makecell[c]{Synthesizability ~$\downarrow$}}
        & {\makecell[c]{Solubility ~$\uparrow$}}
        & {\makecell[c]{Similarity~$\uparrow$}}
        
        \\
        \midrule
        \makecell[l]{\textbf{3CLPro}} %
        &  \textbf{\makecell[l]{Original}}
        &  \makecell[l]{-}
        &  \makecell[l]{0.533}
        &  \makecell[l]{{0.689} }
        &  \makecell[l]{-8.698 }
        &  \makecell[l]{0.682 }
        &  \makecell[l]{3.920 }
        &  \makecell[l]{2.471 }
        &  \makecell[l]{-}
        \\
        (PDBID:
        &  \textbf{\makecell[l]{MMP \citep{loeffler2024reinvent}}}
        &  \makecell[l]{0.995 $\pm$ 0.001}
        &  \makecell[l]{0.628 $\pm$ 0.001}
        &  \makecell[l]{0.718 $\pm$ 0.000}
        &  \makecell[l]{-8.259 $\pm$ 0.004}
        &  \makecell[l]{0.691 $\pm$ 0.001}
        &  \makecell[l]{2.682 $\pm$ 0.004}
        &  \makecell[l]{3.109 $\pm$ 0.020}
        &  \makecell[l]{0.862 $\pm$ 0.000}
        \\
       \ 7BQY)
        &  \textbf{\makecell[l]{Similarity ($\geq$ 0.5) \citep{loeffler2024reinvent}}}
        &  \makecell[l]{0.995 $\pm$ 0.001}
        &  \makecell[l]{0.615 $\pm$ 0.000}
        &  \makecell[l]{0.706 $\pm$ 0.001}
        &  \makecell[l]{-8.165 $\pm$ 0.024}
        &  \makecell[l]{0.697 $\pm$ 0.004}
        &  \makecell[l]{2.621 $\pm$ 0.006}
        &  \makecell[l]{3.180 $\pm$ 0.029}
        &  \makecell[l]{0.782 $\pm$ 0.001}
        \\
        \textbf{ }
        &  \textbf{\makecell[l]{Similarity ([0.5, 0.7)]) \citep{loeffler2024reinvent}}}
        &  \makecell[l]{0.995 $\pm$ 0.001}
        &  \makecell[l]{0.612 $\pm$ 0.001}
        &  \makecell[l]{0.701 $\pm$ 0.001}
        &  \makecell[l]{-8.187 $\pm$ 0.010}
        &  \makecell[l]{0.691 $\pm$ 0.001}
        &  \makecell[l]{2.611 $\pm$ 0.009}
        &  \makecell[l]{3.240 $\pm$ 0.014}
        &  \makecell[l]{0.756 $\pm$ 0.003}
        \\
        \textbf{ }
        &  \textbf{\makecell[l]{Similarity ($\geq$ 0.7) \citep{loeffler2024reinvent}}}
        &  \makecell[l]{0.995 $\pm$ 0.001}
        &  \makecell[l]{0.628 $\pm$ 0.001}
        &  \makecell[l]{0.718 $\pm$ 0.001}
        &  \makecell[l]{-8.214 $\pm$ 0.002}
        &  \makecell[l]{0.691 $\pm$ 0.002}
        &  \makecell[l]{2.717 $\pm$ 0.002}
        &  \makecell[l]{3.080 $\pm$ 0.016}
        &  \makecell[l]{0.881 $\pm$ 0.002}
        \\
        \textbf{ }
        &  \textbf{\makecell[l]{Scaffold \citep{loeffler2024reinvent}}}
        &  \makecell[l]{0.995 $\pm$ 0.001}
        &  \makecell[l]{0.602 $\pm$ 0.001}
        &  \makecell[l]{0.703 $\pm$ 0.002}
        &  \makecell[l]{-8.116 $\pm$ 0.002}
        &  \makecell[l]{0.695 $\pm$ 0.001}
        &  \makecell[l]{2.728 $\pm$ 0.008}
        &  \makecell[l]{2.968 $\pm$ 0.038}
        &  \makecell[l]{0.776 $\pm$ 0.001}
        \\
        \textbf{ }
        &  \textbf{\makecell[l]{Scaffold Generic \citep{loeffler2024reinvent}}}
        &  \makecell[l]{0.994 $\pm$ 0.001}
        &  \makecell[l]{0.617 $\pm$ 0.001}
        &  \makecell[l]{0.710 $\pm$ 0.002}
        &  \makecell[l]{-8.179 $\pm$ 0.012}
        &  \makecell[l]{0.701 $\pm$ 0.000}
        &  \makecell[l]{2.645 $\pm$ 0.008}
        &  \makecell[l]{3.090 $\pm$ 0.029}
        &  \makecell[l]{0.801 $\pm$ 0.000}
        \\
        \textbf{ }
        &  \textbf{\makecell[l]{DrugImprover \citep{liu2023drugimprover}}}
        &  \makecell[l]{0.884 $\pm$ 0.005}
        &  \makecell[l]{0.432 $\pm$ 0.002} 
        &  \makecell[l]{0.493 $\pm$ 0.005} 
        &  \makecell[l]{-6.726 $\pm$ 0.007}
        &  \makecell[l]{0.506 $\pm$ 0.002}
        &  \makecell[l]{\textbf{1.306} $\pm$ 0.010}
        &  \makecell[l]{2.057 $\pm$ 0.011}
        &  \makecell[l]{0.531 $\pm$ 0.002}
        \\
        \textbf{ }
        &  \textbf{\makecell[l]{Molsearch \citep{sun2022molsearch}}}
        &  \makecell[l]{\textbf{1.000} $\pm$ 0.001}
        &  \makecell[l]{0.616 $\pm$ 0.001} 
        &  \makecell[l]{0.726 $\pm$ 0.002} 
        &  \makecell[l]{-8.855 $\pm$ 0.040}
        &  \makecell[l]{0.686 $\pm$ 0.001}
        &  \makecell[l]{3.105 $\pm$ 0.006}
        &  \makecell[l]{2.452 $\pm$ 0.008}
        &  \makecell[l]{\textbf{0.969} $\pm$ 0.001}
        \\
        \textbf{ }
        &  \textbf{\makecell[l]{MIMOSA \citep{fu2021mimosa}}}
        &  \makecell[l]{0.985 $\pm$ 0.008}
        &  \makecell[l]{0.622 $\pm$ 0.001} 
        &  \makecell[l]{0.734 $\pm$ 0.002} 
        &  \makecell[l]{-8.800 $\pm$ 0.015}
        &  \makecell[l]{0.677 $\pm$ 0.004}
        &  \makecell[l]{3.105 $\pm$ 0.008}
        &  \makecell[l]{2.711 $\pm$ 0.010}
        &  \makecell[l]{\underline{0.959} $\pm$ 0.001}
        \\
        \textbf{ }
        &  \textbf{\makecell[l]{\fix{DrugEx v3} \citep{liu2023drugex}}}
        &  \makecell[l]{\textbf{1.000} $\pm$ 0.001}
        &  \makecell[l]{0.524 $\pm$ 0.001} 
        &  \makecell[l]{0.613 $\pm$ 0.001} 
        &  \makecell[l]{-8.089 $\pm$ 0.013}
        &  \makecell[l]{0.583 $\pm$ 0.002}
        &  \makecell[l]{3.095 $\pm$ 0.005}
        &  \makecell[l]{3.932 $\pm$ 0.008}
        &  \makecell[l]{{0.495} $\pm$ 0.001}
        \\
        \textbf{ }
        &  \textbf{\makecell[l]{\algname (w/o APO \& \TOPN )}}
        &  \makecell[l]{0.951 $\pm$ 0.004}
        &  \makecell[l]{0.587 $\pm$ 0.004}
        &  \makecell[l]{0.693 $\pm$ 0.004}
        &  \makecell[l]{-8.238 $\pm$ 0.101}
        &  \makecell[l]{0.659 $\pm$ 0.014}
        &  \makecell[l]{2.865 $\pm$ 0.038}
        &  \makecell[l]{2.999 $\pm$ 0.163}
        &  \makecell[l]{0.754 $\pm$ 0.005 }
        \\
        \textbf{ }
        &  \textbf{\makecell[l]{\algname (w/o \TOPN )}}
        &  \makecell[l]{0.857 $\pm$ 0.061}
        &  \makecell[l]{0.627 $\pm$ 0.009}
        &  \makecell[l]{0.717 $\pm$ 0.004}
        &  \makecell[l]{-8.583 $\pm$ 0.075}
        &  \makecell[l]{0.727 $\pm$ 0.019}
        &  \makecell[l]{2.566 $\pm$ 0.088}
        &  \makecell[l]{3.388 $\pm$ 0.095}
        &  \makecell[l]{0.717 $\pm$ 0.028 }
        \\
        \textbf{ }
        &  \textbf{\makecell[l]{\algname (w/o APO)}}
        &  \makecell[l]{0.998 $\pm$ 0.001}
        &  \makecell[l]{\underline{0.666} $\pm$ 0.000}
        &  \makecell[l]{\underline{0.740} $\pm$ 0.001}
        &  \makecell[l]{\underline{-9.312} $\pm$ 0.018}
        &  \makecell[l]{\underline{0.734} $\pm$ 0.002}
        &  \makecell[l]{{2.698} $\pm$ 0.006 }
        &  \makecell[l]{\underline{3.676} $\pm$ 0.006 }
        &  \makecell[l]{0.813 $\pm$ 0.002 }
        \\
        \textbf{ }
        &  \textbf{\makecell[l]{\algname}}
        &  \makecell[l]{0.944 $\pm$ 0.094}
        &  \makecell[l]{\textbf{0.675} $\pm$ 0.031}
        &  \makecell[l]{\textbf{0.740} $\pm$ 0.015}
        &  \makecell[l]{\textbf{-9.343} $\pm$ 0.440}
        &  \makecell[l]{\textbf{0.746} $\pm$ 0.028}
        &  \makecell[l]{\underline{2.453} $\pm$ 0.154}
        &  \makecell[l]{\textbf{3.913} $\pm$ 0.358}
        &  \makecell[l]{0.745 $\pm$ 0.032 }
        \\
        \bottomrule
        \textbf{RTCB}
        &  \textbf{\makecell[l]{Original}}
        &  \makecell[l]{-}
        &  \makecell[l]{0.536}
        &  \makecell[l]{{0.698}}
        &  \makecell[l]{-8.572}
        &  \makecell[l]{0.709}
        &  \makecell[l]{3.005}
        &  \makecell[l]{2.299}
        &  \makecell[l]{-}
        \\
        (PDBID:
        &  \textbf{\makecell[l]{MMP \citep{loeffler2024reinvent}}}
        &  \makecell[l]{0.998 $\pm$ 0.001}
        &  \makecell[l]{0.636 $\pm$ 0.000}
        &  \makecell[l]{0.731 $\pm$ 0.001}
        &  \makecell[l]{-8.465 $\pm$ 0.021}
        &  \makecell[l]{0.709 $\pm$ 0.001}
        &  \makecell[l]{2.599 $\pm$ 0.004}
        &  \makecell[l]{3.013 $\pm$ 0.013}
        &  \makecell[l]{0.845 $\pm$ 0.001}
        \\
        \ 4DWQ)
        &  \textbf{\makecell[l]{Similarity ($\geq$ 0.5) \citep{loeffler2024reinvent}}}
        &  \makecell[l]{0.999 $\pm$ 0.001}
        &  \makecell[l]{0.626 $\pm$ 0.000}
        &  \makecell[l]{0.723 $\pm$ 0.001}
        &  \makecell[l]{-8.511 $\pm$ 0.012}
        &  \makecell[l]{0.713 $\pm$ 0.002}
        &  \makecell[l]{2.543 $\pm$ 0.002}
        &  \makecell[l]{3.082 $\pm$ 0.031}
        &  \makecell[l]{0.760 $\pm$ 0.000}
        \\
        \textbf{ }
        &  \textbf{\makecell[l]{Similarity ([0.5, 0.7)]) \citep{loeffler2024reinvent}}}
        &  \makecell[l]{0.999 $\pm$ 0.001}
        &  \makecell[l]{0.622 $\pm$ 0.001}
        &  \makecell[l]{0.718 $\pm$ 0.000}
        &  \makecell[l]{-8.486 $\pm$ 0.021}
        &  \makecell[l]{0.713 $\pm$ 0.003}
        &  \makecell[l]{2.542 $\pm$ 0.005}
        &  \makecell[l]{3.101 $\pm$ 0.005}
        &  \makecell[l]{0.740 $\pm$ 0.001}
        \\
        \textbf{ }
        &  \textbf{\makecell[l]{Similarity ($\geq$ 0.7) \citep{loeffler2024reinvent}}}
        &  \makecell[l]{0.999 $\pm$ 0.001}
        &  \makecell[l]{0.639 $\pm$ 0.000}
        &  \makecell[l]{0.734 $\pm$ 0.001}
        &  \makecell[l]{-8.496 $\pm$ 0.009}
        &  \makecell[l]{ 0.718 $\pm$ 0.001}
        &  \makecell[l]{2.628 $\pm$ 0.001}
        &  \makecell[l]{2.868 $\pm$ 0.003}
        &  \makecell[l]{0.875 $\pm$ 0.002}
        \\
        \textbf{ }
        &  \textbf{\makecell[l]{Scaffold \citep{loeffler2024reinvent}}}
        &  \makecell[l]{0.998 $\pm$ 0.001}
        &  \makecell[l]{0.609 $\pm$ 0.001}
        &  \makecell[l]{0.718 $\pm$ 0.000}
        &  \makecell[l]{-8.508 $\pm$ 0.026}
        &  \makecell[l]{0.711 $\pm$ 0.000}
        &  \makecell[l]{2.627 $\pm$ 0.002}
        &  \makecell[l]{ 2.803 $\pm$ 0.010}
        &  \makecell[l]{0.735 $\pm$ 0.002}
        \\
        \textbf{ }
        &  \textbf{\makecell[l]{Scaffold Generic \citep{loeffler2024reinvent}}}
        &  \makecell[l]{0.998 $\pm$ 0.001}
        &  \makecell[l]{0.625 $\pm$ 0.001}
        &  \makecell[l]{0.722 $\pm$ 0.000}
        &  \makecell[l]{-8.544 $\pm$ 0.009}
        &  \makecell[l]{0.722 $\pm$ 0.002}
        &  \makecell[l]{2.551 $\pm$ 0.010}
        &  \makecell[l]{2.898 $\pm$ 0.005}
        &  \makecell[l]{0.768 $\pm$ 0.004}
        \\
        \textbf{ }
        &  \textbf{\makecell[l]{DrugImprover \citep{liu2023drugimprover}}}
        &  \makecell[l]{0.920 $\pm$ 0.008}
        &  \makecell[l]{0.478 $\pm$ 0.001} 
        &  \makecell[l]{0.618 $\pm$ 0.002} 
        &  \makecell[l]{-8.701 $\pm$ 0.037}
        &  \makecell[l]{0.486 $\pm$ 0.002}
        &  \makecell[l]{\textbf{1.181} $\pm$ 0.010}
        &  \makecell[l]{2.026 $\pm$ 0.013}
        &  \makecell[l]{0.427 $\pm$ 0.001}
        \\
        \textbf{ }
        &  \textbf{\makecell[l]{Molsearch \citep{sun2022molsearch}}}
        &  \makecell[l]{\textbf{1.000} $\pm$ 0.001}
        &  \makecell[l]{0.625 $\pm$ 0.001} 
        &  \makecell[l]{0.742 $\pm$ 0.001} 
        &  \makecell[l]{-8.747 $\pm$ 0.009}
        &  \makecell[l]{0.719 $\pm$ 0.001}
        &  \makecell[l]{3.012 $\pm$ 0.004}
        &  \makecell[l]{2.273 $\pm$ 0.005}
        &  \makecell[l]{\textbf{0.950} $\pm$ 0.001}
        \\
        \textbf{ }
        &  \textbf{\makecell[l]{MIMOSA \citep{fu2021mimosa}}}
        &  \makecell[l]{0.989 $\pm$ 0.001}
        &  \makecell[l]{0.631 $\pm$ 0.001} 
        &  \makecell[l]{0.749 $\pm$ 0.001} 
        &  \makecell[l]{-8.972 $\pm$ 0.011}
        &  \makecell[l]{0.706 $\pm$ 0.003}
        &  \makecell[l]{3.080 $\pm$ 0.007}
        &  \makecell[l]{2.561 $\pm$ 0.008}
        &  \makecell[l]{\underline{0.945} $\pm$ 0.001}
        \\
        \textbf{ }
        &  \textbf{\makecell[l]{\fix{DrugEx v3} \citep{liu2023drugex}}}
        &  \makecell[l]{\textbf{1.000} $\pm$ 0.001}
        &  \makecell[l]{0.592 $\pm$ 0.001} 
        &  \makecell[l]{0.668 $\pm$ 0.001} 
        &  \makecell[l]{-8.762 $\pm$ 0.010}
        &  \makecell[l]{0.583 $\pm$ 0.002}
        &  \makecell[l]{\underline{2.488} $\pm$ 0.005}
        &  \makecell[l]{5.827 $\pm$ 0.010}
        &  \makecell[l]{0.393 $\pm$ 0.001}
        \\
        \textbf{ }
        &  \textbf{\makecell[l]{\algname (w/o APO \& \TOPN )}}
        &  \makecell[l]{0.956 $\pm$ 0.004}
        &  \makecell[l]{0.582 $\pm$ 0.007}
        &  \makecell[l]{0.700 $\pm$ 0.008}
        &  \makecell[l]{-8.214 $\pm$ 0.125}
        &  \makecell[l]{0.686 $\pm$ 0.017}
        &  \makecell[l]{2.788 $\pm$ 0.056}
        &  \makecell[l]{2.781 $\pm$ 0.214}
        &  \makecell[l]{0.707 $\pm$ 0.005 }
        \\
        \textbf{ }
        &  \textbf{\makecell[l]{\algname (w/o \TOPN)}}
        &  \makecell[l]{0.811 $\pm$ 0.074}
        &  \makecell[l]{0.639 $\pm$ 0.004}
        &  \makecell[l]{0.723 $\pm$ 0.005}
        &  \makecell[l]{-8.808 $\pm$ 0.071}
        &  \makecell[l]{0.741 $\pm$ 0.013}
        &  \makecell[l]{{2.521} $\pm$ 0.081}
        &  \makecell[l]{3.279 $\pm$ 0.067}
        &  \makecell[l]{0.730 $\pm$ 0.030 }
        \\
        \textbf{ }
        &  \textbf{\makecell[l]{\algname (w/o APO)}}
        &  \makecell[l]{0.997 $\pm$ 0.001}
        &  \makecell[l]{\underline{0.673} $\pm$ 0.001}
        &  \makecell[l]{\underline{0.755} $\pm$ 0.001}
        &  \makecell[l]{\underline{-9.659} $\pm$ 0.023}
        &  \makecell[l]{\underline{0.764} $\pm$ 0.001}
        &  \makecell[l]{{2.606} $\pm$ 0.007}
        &  \makecell[l]{\underline{3.481} $\pm$ 0.027}
        &  \makecell[l]{0.773 $\pm$ 0.003 }
        \\
        \textbf{ }
        &  \textbf{\makecell[l]{\algname}}
        &  \makecell[l]{0.826 $\pm$ 0.100}
        &  \makecell[l]{\textbf{0.682} $\pm$ 0.004}
        &  \makecell[l]{\textbf{0.756} $\pm$ 0.003}
        &  \makecell[l]{\textbf{-9.757} $\pm$ 0.057}
        &  \makecell[l]{\textbf{0.765} $\pm$ 0.013}
        &  \makecell[l]{{2.437} $\pm$ 0.059}
        &  \makecell[l]{\textbf{3.582} $\pm$ 0.043}
        &  \makecell[l]{0.747 $\pm$ 0.026 }
        \\
        \bottomrule
        \\
        \end{tabular}}}
        \caption{
        {\textbf{Main results.} A comparison of eight baselines including Original, six baselines from REINVENT \{MMP, Similarity ($\geq 0.5$), Similarity $\in [0.5,0.7)$, Similarity $\geq 0.7$, Scaffold, Scaffold Generic\}, DrugImprover, Molsearch, MIMOSA and different versions of \algname on various objectives  
        based on 3CLPro and RTCB datasets. {The top two results are highlighted as \textbf{1st} and \underline{2nd}. $^\star$ represents the top-priority target objective.} Results are reported for five experimental runs. 
        }
        }
        \label{exp:main_result}
\end{table*}



\textbf{Dataset.}
We employ, from the most recent Cancer and COVID dataset of \citet{liu2023drugimprover}, 1 million compounds from the ZINC15 dataset docked to the 3CLPro~(PDB ID: 7BQY) protein associated with SARS-CoV-2 and the RTCB (PDB ID: 4DWQ) human cancer protein. 








{
\textbf{Critics and evaluation metric.} 
In this study, we evaluate the efficacy of \algname in generating molecules with desirable attributes within the context of pharmaceutical drug discovery.
{We leverage the RDKit  \citep{landrum2016rdkit} chemoinformatics package and employ various performance metrics as follows:}
{\textbf{Validity} measures if the generated SMILES is valid in syntax.}
\textbf{Druglikeness} measures the likelihood of a molecule being a suitable candidate for drug development.
\textbf{Solubility} assesses the likelihood of a molecule's ability to mix with water, commonly referred to as the water-octanol partition coefficient (LogP). 
\textbf{Synthetizability} quantifies the ease (score of 1) or difficulty (score of 10) associated with synthesizing a given molecule \citep{ertl2009estimation}.
\textbf{Docking Score} assesses the drug's potential to bind and inhibit the target site. 
To enable efficient computation, we employ a docking surrogate model (See \appref{app:surrogate_model}) to output this score.
{
\textbf{Similarity:} We use Tanimoto similarity to evaluate the similarity between original SMILES and generated SMILES.
\textbf{Average Top 10\% Norm Reward} is the average of the normalized reward of the top 10\% of molecules based on their average normalized reward.
\textbf{Average Norm Reward} is the average of the normalized values of the docking score, druglikeness, synthesizability, solubility, and similarity across all valid molecules. This is the most important metric. \fix{ Evaluations are based on a sample of 1,280 molecules.}
}
}
\begin{remark}
A similarity score that is too high results in low structural diversity, while a score that is too low suggests the molecules have drifted too far from the original. Neither extreme is desirable. Our goal is to achieve a balanced level of similarity with meaningful variation. In this work, the primary optimization objective is the average normalized reward.
\end{remark}





\subsection{Main results.}
\XL{add molecule}
        
    














        
        
    




Table \ref{exp:main_result} shows that \algname surpasses DrugImprover and six different versions of REINVENT4 in performance measures for both virus-related and cancer-related proteins. Moreover, \algname exceeds the performance of all baseline methods and also demonstrates a decent level of Tanimoto similarity to the original drug, indicating that it preserves the advantageous features of the original drugs while improving desired properties.

Several key factors contribute to this superior performance. Although DrugImprover established a strong foundation for the drug optimization field, including a workflow and a reinforcement learning algorithm to align the generative model with multiple pharmaceutical objectives, \algname outshines DrugImprover in all benchmarks. This is because \algname employs a GPT-2-like Transformer as the basis of its generative model, whereas DrugImprover relies solely on LSTM. Consequently, the GPT-2 Transformer grants \algname enhanced scalability, capacity, and contextual understanding compared to DrugImprover.




In contrast to the current state-of-the-art approach, REINVENT4, which pre-trains a Transformer with constraints on Tanimoto similarity, their method falls short in achieving drug optimization as it overlooks the optimization of multiple pharmaceutical properties. Therefore, Table \ref{exp:main_result} reveals that although REINVENT4 achieved high similarity, the generated molecules often failed to surpass the original ones.
\algname, on the other hand, employs the APO reinforcement learning algorithm to fine-tune the pre-trained generative model and utilizes the $\TOPN$ decoding optimization strategy. These approaches ensure improvements aligned with multiple pharmaceutical objectives and enable \algname to successfully enhance the original drug across various pharmaceutical properties while maintaining a high Tanimoto similarity.





\subsection{Ablation studies.}


\begin{table*}[ht]
\setlength{\tabcolsep}{4pt}
   \centering
\scalebox{0.44}{
\begin{tabular}{|c|c|c|c|c|c|c|c|c|c|}
\hline
\textbf{Model} & \textbf{Diversity}~$\uparrow$ & \textbf{Validity}~$\uparrow$ & \textbf{Avg Norm Reward}~$\uparrow$$^\star$ & \textbf{ \makecell[c]{Avg Top 10\% \\Norm Reward}}~$\uparrow$ & \textbf{Docking}~$\downarrow$  & \textbf{Druglikeliness}~$\uparrow$ & \textbf{Synthesizability}~$\downarrow$ & \textbf{Solubility}~$\uparrow$ & \textbf{Similarity}~$\uparrow$ \\
\hline
\multicolumn{10}{|c|}{\textbf{COVID}} \\
\hline
\algname (w/o \TOPN) \TOPK & 0.988 & \textbf{0.947} & 0.645 & 0.727 & -8.726 & \textbf{0.760} & 2.418 & 3.499 & 0.697 \\
\algname (w/o \TOPN) \TOPP & 0.988 & 0.938 & 0.642 & 0.722 & -8.653 & 0.756 & 2.420 & 3.505 & 0.696 \\
\algname (w/o \TOPN) \TOPPK & \textbf{0.989} & 0.941 & 0.643 & 0.724 & -8.667 & 0.759 & \textbf{2.407} & 3.506 & 0.692 \\
\algname (\TOPN) & 0.965 & 0.944 & \textbf{0.675} & \textbf{0.740} & \textbf{-9.343} & {0.746} & {2.453} & \textbf{3.913} & \textbf{0.745} \\
\hline
\multicolumn{10}{|c|}{\textbf{CANCER}} \\
\hline
\algname (w/o \TOPN) \TOPK & 0.912 & 0.709 & 0.648 & 0.728 & -8.944 & 0.756 & 2.456 & 3.258 & 0.730 \\
\algname (w/o \TOPN) \TOPP & \textbf{0.931} & 0.704 & 0.645 & 0.729 & -8.907 & 0.756 & 2.466 & 3.226 & 0.723 \\
\algname (w/o \TOPN) \TOPPK & 0.926 & 0.719 & 0.645 & 0.727 & -8.888 & 0.757 & 2.466 & 3.219 & 0.725 \\
\algname (\TOPN) & 0.916 & \textbf{0.826} & \textbf{0.682} & \textbf{0.756} & \textbf{-9.757} & \textbf{0.765} & \textbf{2.437} & \textbf{3.582} & \textbf{0.747} \\
\hline
\end{tabular}
}
\caption{Ablation study of \TOPN, \TOPP, \TOPK and \TOPPK sampling strategies. The top result is highlighted as \textbf{1st}.  $^\star$ represents the top-priority target objective. \fix{Evaluations are based on five random seeds.} \TOPN outperforms others in most of the metrics.} 
\label{tab:stage-ablation-topn}
\end{table*}

We next present ablation studies that underscore the necessity and effectiveness of each component of \algname. These components complement each other, substantially enhancing overall performance.










\begin{wrapfigure}[9]{r}{.26\textwidth}
    \centering
\setlength{\tabcolsep}{4pt}
   \centering
\scalebox{0.51}{
\begin{tabular}{|c|c|}
\hline
\textbf{1024 SMILES} & \textbf{Details} \\
\hline
1024 & $>100$ length, $>50$ scaffold \\
\hline
\multicolumn{2}{|c|}{\textbf{Validity}} \\
\hline
One phase & 0.57 \\
Two phases & 0.68 \\
\hline
\end{tabular}}
        \caption{Ablation study of one-phase vs two-phases. \fix{Evaluations are based on five random seeds.}} 
        \label{tab:stage-ablation}
\end{wrapfigure}
\paragraph{Effectiveness of (two-phase) incremental training.}
In two-phase incremental pretraining, 
the intuition behind the first phase lies in training on critical keywords as knowledge pieces, reinforcing the memory of these key terms, particularly in longer sequences.
We conducted an ablation study comparing our novel two-phase incremental training with \fix{conventional} one-phase training in \tabref{tab:stage-ablation}.
\fix{To ensure a fair comparison in terms of total training epochs, we trained for 10 epochs in the conventional single-phase setting, and for five epochs per phase in our two-phase setting.}
The results showed that the two-phase approach improves validity compared to one-phase training, demonstrating the effectiveness of the incremental training method.




\paragraph{Effectiveness of APO Finetuning.} \algname adopts APO finetuning as the second step, following the completion of pretraining the GPT-based generator. \tabref{exp:main_result} demonstrates the effectiveness of APO through two comparisons: \algname (w/o APO, \TOPN) vs. \algname (w/o \TOPN), which shows that after applying APO finetuning, performance improved on most properties. Additionally, \algname vs. \algname (w/o APO) validates the importance of the APO component. By applying APO on top of pretraining and \TOPN decoding, performance improved. Both cases demonstrate the effectiveness of APO finetuning. \fix{ Note that APO may compromise certain reward metrics, such as similarity or validity, if this trade-off leads to improved performance in the target weighted objective.
}


\paragraph{Effectiveness of $\TOPN$ decoding strategy.} \algname adopts the $\TOPN$ decoding strategy as the final step followed by APO finetuning. \tabref{exp:main_result} demonstrates the effectiveness of $\TOPN$ through two comparisons: \algname (w/o APO, $\TOPN$) vs. \algname (w/o APO), showing that after applying the $\TOPN$ decoding strategy on top of pretrained GPT, performance improved across most properties.
Moreover, \algname vs. \algname (w/o $\TOPN$) illustrates that after applying APO on top of pretraining and RL, performance still improves on multiple attributes, surpassing all baselines.
Furthermore, by comparing \algname (w/o APO) and \algname (w/o $\TOPN$), we observe that applying $\TOPN$ decoding alone enhances performance more than applying APO alone.

\fix{
\paragraph{Ablation study of \TOPN vs \TOPP, \TOPK and \TOPPK strategies.}
\fix{Following the setup described in \secref{exp_config}, we perform an ablation study on sampling strategies.}
When removing \TOPN component, we employ multinomial generation, where multinomial sampling randomly selects the next token from the entire vocabulary based on the model's probability distribution. In the ablation study detailed in \tabref{tab:stage-ablation-topn}, we examined \TOPN over \TOPP, \TOPK, and \TOPPK  with K=20 and P=0.95. The results indicate that Top-N surpasses the other strategies in most metrics.}




\begin{table*}[t]
\setlength{\tabcolsep}{4pt}
   \centering
    {\small
    \scalebox{0.56}{
    \begin{tabular}{ l l l l l l}
        \toprule
        \textbf{\makecell[l]{ }}
        &  \makecell[l]{\textbf{Original~~~~~~~~~~~~~Scaffold}}
        &  \makecell[l]{\textbf{REINVENT}}
        &  \makecell[l]{\textbf{\algname 1}}
        &  \makecell[l]{\textbf{\algname 2}}
        &  \makecell[l]{\textbf{\algname 3}}
        \\
        \textbf{Molecule}
        & {\makecell[l]{\includegraphics[width=0.35\textwidth]{example_output_new/cancer/orig.pdf}}}
        & {\makecell[l]{\includegraphics[width=0.25\textwidth]{example_output_new/cancer_new/reinvent1.jpg}}}
        & {\makecell[l]{\includegraphics[width=0.25\textwidth]{example_output_new/cancer_new/gen1.pdf}}}
        & {\makecell[l]{\includegraphics[width=0.25\textwidth]{example_output_new/cancer_new/gen2.pdf}}}
        & {\makecell[l]{\includegraphics[width=0.25\textwidth]{example_output_new/cancer_new/gen3.pdf}}}
        \\
        \midrule
        \textbf{\makecell[l]{SMILE String}}
        &  \makecell[l]{Cc1ccc(O)c(Nc2nnc\\(-c3ccccc3)c(=O)[nH]2)c1}
        &  \makecell[l]{CCOc1ccc(O)c(Nc2nnc\\(-c3ccccc3)c(=O)[nH]2)c1}
        &  \makecell[l]{Cc1ccc(-c2nnc(Nc3ccc\\(C(C)C)cc3)[nH]c2=O)cc1} 
        &  \makecell[l]{COc1ccc(-c2nnc(Nc3cccc\\(C)c3)[nH]c2=O)cc1} 
        &  \makecell[l]{Cc1ccc(-c2nnc(Nc3cccc\\(C(C)C)c3)[nH]c2=O)cc1}
        \\
        \midrule
        \textbf{\makecell[l]{Scaffold}}
        &  \makecell[l]{O=c1[nH]c(Nc2cc\\ccc2)nnc1-c1ccccc1}
        &  \makecell[l]{c1ccc(Nc2nnc(-c3\\ccccc3)[nH]2)cc1}
        &  \makecell[l]{same as original} 
        &  \makecell[l]{same as original} 
        &  \makecell[l]{same as original}
        \\
        \textbf{\makecell[l]{Similarity}}
        &  \makecell[l]{-}
        &  \makecell[l]{0.878} 
        &  \makecell[l]{0.826} 
        &  \makecell[l]{0.911} 
        &  \makecell[l]{0.866}
        \\
        \midrule
        \textbf{\makecell[l]{Docking~$(\downarrow)$}}
        &  \makecell[l]{-10.031}
        &  \makecell[l]{-9.258}
        &  \makecell[l]{-11.478 $\checkmark$} 
        &  \makecell[l]{-11.474 $\checkmark$} 
        &  \makecell[l]{-11.087 $\checkmark$}
        \\
        \textbf{\makecell[l]{Druglikeness~$(\uparrow)$}}
        &  \makecell[l]{0.646}
        &  \makecell[l]{0.624}
        &  \makecell[l]{0.762 $\checkmark$}
        &  \makecell[l]{0.774 $\checkmark$}
        &  \makecell[l]{0.762 $\checkmark$}
        \\
         \textbf{\makecell[l]{Synthesizability~$(\downarrow)$}}
        &  \makecell[l]{2.390}
        &  \makecell[l]{2.417} 

        &  \makecell[l]{2.298 $\checkmark$} 
        &  \makecell[l]{2.257 $\checkmark$} 
        &  \makecell[l]{2.356 $\checkmark$}
        \\
         \textbf{\makecell[l]{Solubility~$(\uparrow)$}}
        &  \makecell[l]{2.590} 
        &  \makecell[l]{2.680 $\checkmark$} 
        &  \makecell[l]{4.007 $\checkmark$} 
        &  \makecell[l]{2.893 $\checkmark$} 
        &  \makecell[l]{4.007 $\checkmark$} 
        \\
        \textbf{\makecell[l]{Avg Norm Reward~$(\uparrow)$$^\star$}}
        &  \makecell[l]{0.618}
        &  \makecell[l]{0.589}        
        &  \makecell[l]{0.759 $\checkmark$} 
        &  \makecell[l]{0.753 $\checkmark$} 
        &  \makecell[l]{0.754 $\checkmark$}
        \\
        \bottomrule
    \end{tabular}}}
        \caption{One optimization example from cancer benchmark. Every generated molecules retains the scaffold, with all desired properties improved compared to the original. $^\star$ represents the top-priority target objective. $\checkmark$ indicates improved property. 
        }
        \label{viz:example1}
\end{table*}


\paragraph{Drug optimization illustration.} 
Finally, we provide three examples illustrating the effectiveness of \algname in improving upon the original molecule on the cancer benchmark, as shown in \tabref{viz:example1} (Refer to \appref{app:example_2} for the COVID benchmark). The results in \tabref{viz:example1} demonstrate that the drugs generated by \algname outperform the original drugs across all desired properties. Additionally, the comparison figure in \tabref{viz:example1} illustrates that the improved molecules preserve the original drug to a significant extent, with only minor changes highlighted in {\color{myred}red}. The results indicate that \algname effectively optimizes desired properties while preserving the beneficial properties of the original drug.







\section{Conclusion}\label{sec:con}

We have introduced \algname, a novel framework for drug optimization. This framework incorporates a unique scaffold-based GPT design, a three-step optimization process, a two-phase incremental training method, and a novel \TOPN decoding strategy that facilitates controlled reward-guided generation using GPT. To showcase the superior performance of \algname, we conduct evaluations on real-world viral and cancer-related datasets to compare it against eight competing baselines.
Our results demonstrate that \algname surpasses all baselines across the majority of performance metrics, underscoring its efficacy. 
Our work highlights \algname's effectiveness in drug optimization, as evidenced by enhancements in various pharmaceutical properties. 
\fix{Currently, \algname is limited to handling molecules in SMILES format. We are working to expand \algname's capabilities to accommodate a broader range of drug representation formats as a future direction.}

