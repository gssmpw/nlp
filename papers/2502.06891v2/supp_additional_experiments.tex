















































































































   








 \clearpage


\section{Appendix}







































































































\subsection{Pre-training and finetuning dataset}\label{app:pretrain_data}
For pretrainig, We used the ZINC dataset, filtering for Standard, In-Stock, and Drug-Like molecules, resulting in approximately 11 million molecules. 
\fix{
For preprocessing, we perform a few straightforward steps: \\
1. We first canonicalize smiles
{Chem.MolToSmiles(Chem.MolFromSmiles(mol),True)}. \\
2. We filter out molecules whose scaffold SMILES is an empty string. These preprocessing steps are also included in the huggingface data repo.
}


\fix{For finetuning, we utilize 1 million compounds from the ZINC15 dataset, docked to the 3CLPro protein (PDB ID: 7BQY) linked to SARS-CoV-2 and the RTCB protein (PDB ID: 4DWQ) associated with human cancer, as sourced from the latest Cancer and COVID dataset by \citet{liu2023drugimprover}, across all baselines.}



{
\subsection{Generation with finetuned model}\label{app:generation}
The top five epochs with the highest historical average normalized reward (as detailed in Section \ref{exp_config}) are selected. From these five epochs, the epoch with the highest product of validity and average normalized reward is chosen as the final model for generation.

With this epoch and corresponding weights, we apply the proposed decoding method (as described in section \ref{decoding_strategy}) for generation. 
}





\subsection{{BPE Tokenization}}\label{app:BPE}
The Byte Pair Encoding (BPE) algorithm involves the following steps:
\begin{enumerate}[noitemsep, topsep=0pt, partopsep=0pt]
    \item \textbf{Initialize the Vocabulary:} Start with a base vocabulary consisting of all individual characters in the text corpus.
    \item \textbf{Count Frequencies:} Count the frequency of all character pairs in the text.
    \item \textbf{Merge Most Frequent Pair:} Identify the most frequent pair of characters and merge them into a single token. Add this new token to the vocabulary.
    \item \textbf{Update Text:} Replace all occurrences of the most frequent pair with the new token in the text.
    \item \textbf{Repeat:} Repeat the process of counting frequencies, merging pairs, and updating the text until the desired vocabulary size is reached or no more merges are possible.
\end{enumerate}
BPE constructs a robust vocabulary by iteratively merging the most frequent token pairs, effectively capturing common subword units for more efficient and flexible text representation. The resulting vocabulary comprises 3,152 tokens and includes special tokens as well. For instance, the sequence $\textsc{<L>}$ is tokenized into three separate tokens: $<$, L, and $>$. The tokenizer was trained on 10 million molecules from the ZINC dataset, ensuring comprehensive coverage of chemical elements.


\subsection{Surrogate model}\label{app:surrogate_model}

{The surrogate model~\citep{vasan23} is a simplified variant of a BERT-like transformer, extensively utilized in natural language processing. In this model, tokenized SMILES strings are inputted and then embedded with positional information. The resulting outputs are subsequently fed into a series of five transformer blocks, each comprising a multi-head attention layer (21 heads), a dropout layer, layer normalization with residual connection, and a feedforward network. This feedforward network consists of two dense layers followed by dropout and layer normalization with residual connection. Following the stack of transformer blocks, a final feedforward network is employed to generate the predicted docking score.}
\fix{The validation $r^2$ values are 0.842 for 3CLPro and 0.73 for the RTCB dataset.}














\subsection{Drug Optimization illustration on COVID benchmark}\label{app:example_2}
{This is another example illustrating the effectiveness of \algname in enhancing the original molecule on the COVID benchmark. The results in \tabref{viz:example2} show that the drugs generated by \algname outperform the original drugs across all desired properties. Even though the original scaffold is altered and not present in the generated molecules, the similarity still demonstrates a decent level.}


\begin{table*}[t!]
\setlength{\tabcolsep}{4pt}
   \centering
    {\small
    \scalebox{0.75}{
    \begin{tabular}{ l l l l }
        \toprule
        \textbf{\makecell[l]{ }}
        &  \makecell[l]{\textbf{Original~~~~~~~~~~~~~~~~~~~~~~~~Scaffold}}
        &  \makecell[l]{\textbf{improved 1}}
        &  \makecell[l]{\textbf{improved 2}}
        \\
        \midrule
        \textbf{Molecule}
        & {\makecell[l]{\includegraphics[width=0.3\textwidth]{example_output_new/covid/orig.pdf}}}
        & {\makecell[l]{\includegraphics[width=0.3\textwidth]{example_output_new/covid/gen1.pdf}}}
        & {\makecell[l]{\includegraphics[width=0.3\textwidth]{example_output_new/covid/gen2.pdf}}}
        \\
        \midrule
        \textbf{\makecell[l]{SMILE String}}
        &  \makecell[l]{c1ccc(C[N@H+]2CCC3(CC[NH+]\\(Cc4nccs4)CC3)C2)nc1}
        &  \makecell[l]{CC1(c2cccc(C(=O)\\Nc3ccccc3C)c2)CCCC1} 
        &  \makecell[l]{Cc1ccc(CC2CCN\\(Cc3ccccn3)CC2)s1} 
        \\
        \midrule
        \textbf{\makecell[l]{Scaffold}}
        &  \makecell[l]{c1ccc(C[N@H+]2CCC3(CC[NH+]\\(Cc4nccs4)CC3)C2)nc1}
        &  \makecell[l]{-} 
        &  \makecell[l]{-} 
        \\
        \midrule
        \textbf{\makecell[l]{Docking~$(\downarrow)$}}
        &  \makecell[l]{-9.748}
        &  \makecell[l]{-10.184~$\checkmark$} 
        &  \makecell[l]{-10.187~$\checkmark$} 
        \\
        \textbf{\makecell[l]{Druglikeness~$(\uparrow)$}}
        &  \makecell[l]{0.839}
        &  \makecell[l]{0.840~$\checkmark$}
        &  \makecell[l]{0.847~$\checkmark$}
        \\
         \textbf{\makecell[l]{Synthesizability~$(\downarrow)$}}
        &  \makecell[l]{5.631}
        &  \makecell[l]{1.983~$\checkmark$} 
        &  \makecell[l]{2.199~$\checkmark$} 
        \\
         \textbf{\makecell[l]{Solubility~$(\uparrow)$}}
        &  \makecell[l]{0.192} 
        &  \makecell[l]{5.079~$\checkmark$} 
        &  \makecell[l]{3.906~$\checkmark$} 
        \\
        \textbf{\makecell[l]{Similarity}}
        &  \makecell[l]{-}
        &  \makecell[l]{0.335} 
        &  \makecell[l]{0.563} 
        \\
        \textbf{\makecell[l]{Avg Norm Reward~$(\uparrow)$}}
        &  \makecell[l]{0.398}
        &  \makecell[l]{0.688~$\checkmark$} 
        &  \makecell[l]{0.694~$\checkmark$} 
        \\
        \bottomrule
    \end{tabular}}}
        \caption{One molecule example from 3CLPro dataset, where scaffold and original are same. In this case the model tries to modify the scaffold, and the generated molecules does not contain scaffold. $\checkmark$ indicates improved property. 
        }
        \label{viz:example2}
\end{table*}
























































































\subsection{{Computing infrastructure {and wall-time comparison}}}\label{app:computing_infrastructure}
We trained our docking surrogate models using 4 nodes of the supercomputer 
where each node contains CPUs (64 cores) and 4 A100 GPU nodes~\citep{Polaris}.\XL{need update}
The training time for each model was approximately 3 hours.

We conducted other experiments on a cluster that includes CPU nodes (approximately 280 cores) and GPU nodes (approximately 110 Nvidia GPUs, ranging from Titan X to A6000, set up mostly in 4- and 8-GPU configurations). 

{The pretraining process utilizes 8 GPUs, while APO and generation employs a single GPU. Both processes use either V100 or A100 GPUs. Based on the computing infrastructure, we obtained the wall-time comparison in \tabref{table:wall-time} as follows.}

 \begin{table*}[ht!]
 {
    \centering
    {\scriptsize
    \scalebox{1}{
    \begin{tabular}{l c c  }
        \toprule
        \textbf{Methods}
        & {\makecell[c]{Total Run Time}}
        \\
        \midrule
        \textbf{\makecell[l]{Pretraining}}
        &  \makecell[r]{24h}
        \\
        \textbf{\makecell[l]{APO}}
        &  \makecell[r]{27h}
        \\
        \textbf{\makecell[l]{\TOPN (One Generation)}}
        &  \makecell[r]{17-20s}
        \\
        \bottomrule
    \end{tabular}}}
    \caption{{Wall-time comparison between different methods.} }
        \label{table:wall-time}   
        }
\end{table*}


\subsection{{Hyperparameters and architectures}}\label{app:hyperparameters}
Table \ref{app:tab:hyperparams_pretrain} and  \ref{app:tab:hyperparams} provides a list of hyperparameter settings we used for our experiments.\XL{need update}

For APO finetuning and experimentation, 1280 molecules were selected from each of the RTCB and 3CLPro datasets, with docking scores ranging from -14 to -6. This range is based on \citep{liu2024erp}.

{Moreover, when computing the average normalized reward for the original molecule, in the absence of similarity considerations, we use weights of $0.25$ for docking, drug-likeness, synthesizability, and solubility, respectively.
}

{
Moreover, when the generated SMILES is invalid, indicating that the reward $R_c$ cannot be calculated, we have two options: either directly subtract the reward of the original SMILES (i.e., $-R_c(X)$), or consider the advantage preference as zero instead.
}
\begin{table*}[h!]
    {
    \centering
    {\scriptsize
    \scalebox{1}{
    \begin{tabular}{c c }
        \toprule
        \textbf{Parameter} &  \textbf{Value} 
        \\
        \midrule
        {\makecell[l]{Pretraining}}
        \\
        \midrule
        {\makecell[l]{\quad Learning rate}} &  \makecell[c]{$5 \times e^{-5}$}
        \\
        \midrule
        {\makecell[l]{\quad Batch size}} &  \makecell[c]{$24$}
        \\
        \midrule
        {\makecell[l]{\quad Optimizer}} &  \makecell[c]{Adam}
        \\
        \midrule
        {\makecell[l]{\quad \# of Epochs for Training First Phase}} &  \makecell[c]{$10$} \\
        \midrule
        {\makecell[l]{\quad \# of Epochs for Training Second Phase}} &  \makecell[c]{$10$} \\
        \midrule
        {\makecell[l]{\quad Model \# of Params}} &  \makecell[c]{$124M$} 
        \\
        \midrule
        {\makecell[l]{Generation}}
        \\
        \midrule
        {\makecell[l]{\quad N (Top-N)}} &  \makecell[c]{$1$}
        \\
        \midrule
        {\makecell[l]{\quad K (Number of possible next token)}} &  \makecell[c]{$16$}
        \\
        \midrule
        {\makecell[l]{\quad TopK}} &  \makecell[c]{$[10,15,20]$}
        \\
        \midrule
        {\makecell[l]{\quad TopP}} &  \makecell[c]{[$0.85$, $0.9$, $0.95$]}
        \\


        \bottomrule
    \end{tabular}}}
        \caption{{{Hyperparameters for pretraining and generation}}. }
        \label{app:tab:hyperparams_pretrain}
        }
\end{table*}

\begin{table*}[h!]
    {
    \centering
    {\scriptsize
    \scalebox{0.7}{
    \begin{tabular}{c c }
        \toprule
        \textbf{Parameter} &  \textbf{Value} 
        \\
        \midrule
        {\makecell[l]{Shared}}
        \\
        \midrule
        {\makecell[l]{\quad \# of Molecules Optimized}} &  \makecell[c]{$1280$}
        \\
        \midrule
        {\makecell[l]{\quad Learning rate}} &  \makecell[c]{$1 \times 10^{-4}$}
        \\
        \midrule
        {\makecell[l]{\quad Optimizer}} &  \makecell[c]{Adam}
        \\
        \midrule
        {\makecell[l]{\quad \# of Epochs for Training}} &  \makecell[c]{$100$}
        \\
        \midrule
        {\makecell[l]{\quad Batch size}} &  \makecell[c]{$64$}
        \\
        \midrule
        {\makecell[l]{\quad Best-of-N}} &  \makecell[c]{$[4,6,8]$}
        \\
        \midrule
        {\makecell[l]{\quad TopK}} &  \makecell[c]{$[10,15,20]$}
        \\
        \midrule
        {\makecell[l]{\quad TopP}} &  \makecell[c]{$[0.85,0.9,0.95]$}
        \\
        \midrule
        {\makecell[l]{APO Objective Weight}}
        \\
        \midrule
        {\makecell[l]{\quad Docking Score}} &  \makecell[c]{$0.2$}
        \\
        \midrule
        {\makecell[l]{\quad Druglikeliness}} &  \makecell[c]{$0.2$}
        \\
        \midrule
        {\makecell[l]{\quad Synthesizability}} &  \makecell[c]{$0.2$}
        \\
        \midrule
        {\makecell[l]{\quad Solubility}} &  \makecell[c]{$0.2$}
        \\
        \midrule
        {\makecell[l]{\quad Tamimoto Similarity}} &  \makecell[c]{$0.2$}
        \\
        \midrule
        {\makecell[l]{APO Other}}
        \\
        \midrule
        {\makecell[l]{\quad Fingerprint Size}} &  \makecell[c]{$1024$}
        \\
        \midrule
        {\makecell[l]{\quad Normalize Min/Max}} &  \makecell[c]{$[-10, 10]$}
        \\
        \midrule
        {\makecell[l]{Advantage preference with \\ invalid generated SMILES}}
        \\
        \midrule
        {\makecell[l]{\quad 3CLPro}} &  \makecell[c]{$[0,-R_c(X)]$}
        \\
        \midrule
        {\makecell[l]{\quad RTCB}} &  \makecell[c]{$[0,-R_c(X)]$}
        \\

        \bottomrule
    \end{tabular}}}
        \caption{{{Hyperparameters for APO}}. }
        \label{app:tab:hyperparams}
        }
\end{table*}



