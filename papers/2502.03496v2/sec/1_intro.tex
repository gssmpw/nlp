\section{Introduction}
\label{sec:intro}
Benefiting from notable advancements of diffusion models~\citep{jascha2015nonequilibrium,ho2020denoising,song2021scorebased} alongside the expansion of large video datasets~\citep{bain2021frozen, Schuhmann2022laion5b}, text-to-video generation has experienced remarkable progress~\citep{ho2022imagenvideo,chenfei2022nuwa,Blattmann2023align,ge2023PYoCo,guo2023animatediff,uriel2023make-a-video,wang2023modelscope,chen2023videocrafter1}.
In ordinary videos, the content between successive frames often shows high similarity, allowing the video to be considered as a sequence of images with motion information.
Leveraging this characteristic, the architecture of video diffusion models~\citep{Blattmann2023align, wang2023modelscope, wenyi2023cogvideo, guo2023animatediff} commonly incorporates temporal or motion layers into existing image diffusion models.
In addition to model architecture, some studies, inspired by the consistent patterns observed across video frames, investigate the relationships within the initial noise prior.
Consequently, alongside research focusing on the training and sampling phases~\citep{song2021ddim, karras2022edm,lu2022dpmsolver, salimans2022progressive, song2023consistency}, another important line of research in video diffusion models is to explore noise initialization strategies, since improved noise prior can potentially yield better generation results.

Several efforts have been made to explore the noise prior, as the initial noise significantly impacts the generated outcomes~\citep{ge2023PYoCo,qiu2023freenoise,chang2024warp,gu2023reuse,mao2024lottery,wu2023freeinit}.
PYoCo~\citep{ge2023PYoCo} discovers that the noise maps corresponding to different frames, derived from a pre-trained image diffusion model, cluster in t-SNE space~\citep{van2008tsne}, indicating a strong correlation along the temporal dimension.
Based on this observation, it introduces two kinds of noise prior with correlations on the frame dimension. 
However, this change in the noise prior requires massive fine-tuning.
FreeInit~\citep{wu2023freeinit} investigates the low-frequency signal leakage phenomenon in the noise, as also demonstrated in the image domain~\citep{lin2024flaw}, and finds that the denoising process is significantly influenced by the low-frequency components of initial noise.
Leveraging these insights, it uses frequency filtering on the noise prior to enhance the temporal consistency of generated videos. 
However, despite its efforts, the generated videos suffer from excessive smoothness, limited motion dynamics, and a lack of details. 
Moreover, additional iterations are necessary to refine the noise, with a full sampling process conducted in each iteration, making FreeInit~\citep{wu2023freeinit} quite time-consuming.


To address this gap, we conduct a mathematical analysis and provide theoretical justification. Our analysis identifies the variance decay issue existing in FreeInit~\citep{wu2023freeinit}.
As depicted in Figure~\ref{fig:sigma}, we investigate the significance of the distribution of the initial noise for diffusion models.
The impact of the variance on the quality of generated videos is evident.
As $\sigma$ decreases from $1$ to $0.96$, there is a progressive loss of details alongside a reduction in motion dynamics.
The frames generated by FreeInit~\citep{wu2023freeinit} are overly smooth and lack details, as the refined noise deviates from the standard Gaussian distribution, resulting in variance decay.
Therefore, it is critically important for diffusion models that the noise prior follows standard Gaussian distribution.


\begin{figure}[t]
  \centering
  \includegraphics[width=1\linewidth]{figure/intro.pdf}
  \vspace{-10pt}
  \caption{{\bf\em (Left)} {\bf Generated video frames corresponding to Gaussian noise with different variance.} As the variance, denoted as $\sigma^2$, decreases from $1.00^2$ to $0.96^2$, the imaging quality deteriorates and background details gradually lost. 
  {\bf\em (Right)} {\bf Comparisons of our method against the FreeInit and standard Gaussian noise.} The frames generated using FreeInit appear overly smooth and blurred in the area of the highlighted red box, whereas our method preserves rich image details.}
  \vspace{-10pt}
  \label{fig:sigma}
\end{figure}

In this work, we introduce a novel noise prior called \textbf{FreqPrior}.
At the core of our approach is the noise refinement stage, where we propose a novel frequency filtering method designed for noise, which essentially is random variables.
During this stage, we retain the low-frequency signals while enriching high-frequency signals in the frequency domain, 
thereby reducing the covariance error and ensuring that the distribution of our refined noise approximates a standard Gaussian distribution. 
As illustrated in Figure~\ref{fig:sigma}, our method does not suffer from the detail loss issue present in FreeInit~\citep{wu2023freeinit}. 
Additionally, retaining low-frequency signals enhances semantic fidelity. 
Furthermore, to obtain the noise prior, we adjust the diffusion process by perturbing the latent at an intermediate step,  resulting in significant time savings without compromising the quality of the generation results.
We conduct extensive experiments on Vbench~\citep{huang2023vbench}, a comprehensive benchmark, to assess the quality of generated videos. 
The results demonstrate that our method effectively addresses the issue of limited dynamics while improving the overall quality. 
Moreover, our approach outperforms the best on VBench, highlighting the superiority of our method.
Additionally, our method achieves a time-saving of nearly 23\% compared to FreeInit~\citep{wu2023freeinit}. 

In summary, our contributions are as follows:
\textbf{(i):}
We propose a novel frequency filtering method designed to refine the noise, acquiring a better prior, termed {\bf FreqPrior}. We provide a rigorous theoretical analysis of the distribution of our prior. Numerical experiments reveal the covariance error of our method is negligible, implying that our prior closely approximates a Gaussian distribution.
\textbf{(ii):} we propose the partial sampling strategy in our framework, which perturbs the latent at a middle timestep. It can save much time without compromising quality.
\textbf{(iii):} Extensive experiments validate the effectiveness of \textbf{FreqPrior}. 
Specifically, our approach improves both video quality and semantic quality, achieving the highest total score over baselines on VBench~\citep{huang2023vbench}.
