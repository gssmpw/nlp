\section{Noise distribution analysis}
\label{appendix:noise_distribution_analysis}
\subsection{FreeInit}
\label{appendix:freeinit}
FreeInit~\citep{wu2023freeinit} uses conventional frequency filtering methods to manipulate noise, which is the key step in the framework. This step can be formulated as follows:
\begin{equation}
\label{eq:freeinit_raw}
    \bfz_T = \Re\left( \mathcal{F}_{3D}^{-1}\left(\mathcal{F}_{3D}\left(\bfz_{noise}\right)\odot\mathcal{M} + \mathcal{F}_{3D}\left(\eta\right)\odot(\bm{1}-\mathcal{M})\right) \right),
\end{equation}
where $\mathcal{F}_{3D}$ is the Fourier transform applied to both spatial and temporal dimensions. $\mathcal{M}$ is a spatial-temporal low-pass filter. $\bfz_{noise}$ is noisy latent derived from corrupting the clean latent with initial Gaussian noise to timestep $T$, while $\eta$ is another Gaussian noise. 
For analysis, we focus solely on the spatial and temporal dimensions, ignoring the batchsize and channel dimensions. Additionally, we flatten the latent $\bfz_T\in\R^{f\times h \times w}$ into a vector $\bfz \in \R^{fhw}$. The equation~\ref{eq:freeinit_raw} can be expressed in matrix form as follows:
\begin{equation}
    \bfz = \Re\left( \mF^{-1}\mLambda_x\mF\bfx + \mF^{-1}\mLambda_y\mF\bfy \right),
\end{equation}
where $\mF$ is the DFT matrix of transform $\mathcal{F}_{3D}$, $\bfx$ and $\bfy$ are random vectors corresponding to $\bfz_{noise}$ and $\eta$, and $\mLambda_x$ and
$\mLambda_y$ are diagonal matrices associated with low-pass filter $\mathcal{M}$ and high-pass filter $\bm{1}-\mathcal{M}$. Therefore it holds that $\mLambda_x+\mLambda_y=\mI$.
% Due to the property of $\mathcal{M}$, the diag 
This equation can be simplified to the following form using equation~\ref{eq:decomposition}:
\begin{equation}
    \bfz = \frac{1}{N}\left(\mA\mLambda_x\mA + \mB\mLambda_x\mB\right)\bfx 
      + \frac{1}{N}\left( \mA\mLambda_y\mA + \mB\mLambda_y\mB\right)\bfy,
\end{equation}
Under the Assumption~\ref{assumption:1}, $\bfx=\text{vec}(\bfz_{noise}) \sim\mathcal{N}\left(\mathbf{0},\mI\right)$, where $\bfx$ and $\bfy$ are independent. 
Since $\bfz$ is a linear combination of independent Gaussian random vectors, it follows that $\bfz$ is also Gaussian. To derive the distribution of $\bfz$, we only need to compute its expectation and covariance.
The expectation is straightforward and given by $\E[\bfz]=\mathbf{0}$. 
The covariance of $\bfz$ can be calculated as follows:
\begin{equation}
\label{eq:freeinit_cov1}
    \Cov\left(\bfz\right) 
    = \frac{1}{N^2}\left( \mA\mLambda_x\mA + \mB\mLambda_x\mB\right)^2 +
      \frac{1}{N^2}\left( \mA\mLambda_y\mA + \mB\mLambda_y\mB\right)^2.
\end{equation}
To simplify the expression, we denote $\mP = \frac{1}{N}\left( \mA\mLambda_x\mA+\mB\mLambda_x\mB\right)$. Then the term $\mA\mLambda_y\mA+\mB\mLambda_y\mB$ can be expressed using $\mP$:
\begin{equation}
\label{eq:freeinit_cov2}
\begin{split}
     \mA\mLambda_y\mA + 
      \mB\mLambda_y\mB & = \mA(\mI-\mLambda_x)\mA + 
      \mB(\mI-\mLambda_x)\mB \\
      & = \mA^2 + \mB^2 - \left( \mA\mLambda_x\mA+\mB\mLambda_x\mB\right) = N\mI - N\mP.
\end{split}
\end{equation}
The last equation follows from $ \mA^2+\mB^2 =N\mI$, as stated in Theorem~\ref{theorem:dft}. 
Combining Equation~(\ref{eq:freeinit_cov1}) and Equation~(\ref{eq:freeinit_cov2}), the covariance of $\bfz$ is given by:
\begin{equation}
    \Cov\left(\bfz\right) = \mP^2 + (\mI-\mP)^2.
\end{equation}
Consequently, we obtain the distribution of $\bfz$ as follows:
\begin{equation}
\label{eq:free_distribution}
    \bfz\sim\mathcal{N}\left(\mathbf{0}, \mP^2 + \left(\mI-\mP\right)^2\right).
\end{equation}
Due to the property of the low-pass filter $\mathcal{M}$ where each element lies between 0 to 1, both $\mLambda_x$ and $\mLambda_y$ are semi-definite diagonal matrices. Consequently, we can prove that both $\mP$ and $\mI-\mP$ are semi-positive definite matrices. The covariance structure resembles $a^2+(1-a)^2$, which is less than 1 for $a\in(0, 1)$. This indicates a difference between the distribution of $\bfz$ and the standard Gaussian distribution. We explore this further in Appendix~\ref{appendix:theoretical_analysis}.


\subsection{FreqPrior}
\label{appendix:freqprior}
The noise refinement stage of our method consists of three distinct steps, which are elaborated on in Section~\ref{subsec:noise_refinement}.  
To facilitate further analysis, we express these steps in matrix form.
% For simplicity, we can express these steps in the following matrix forms, which facilitate further analysis.
The first step, \textbf{noise preparation step}, can be represented as:
\begin{equation}
\label{eq:freq_x1}
    \bfx_1 = \frac{1}{\sqrt{1+\cos^2\theta}}\left(\cos\theta\cdot \bfx+\sin\theta\cdot\mathbf{\eta_1}\right),\quad
    \bfx_2 = \frac{1}{\sqrt{1+\cos^2\theta}}\left(\cos\theta\cdot \bfx+\sin\theta\cdot\mathbf{\eta}_2\right),
\end{equation}
where $\mathbf\eta_1, \mathbf\eta_2\sim\mathcal{N}\left(\mathbf{0}, \mI\right)$ and are independent. Under Assumption~\ref{assumption:1}, $\bfx\sim\mathcal{N}(\mathbf{0},\mI)$. Obviously, $\bfx, \mathbf\eta_1$, and $\mathbf\eta_2$ are independent.
Both $\bfx_1$ and $\bfx_2$ are linear combinations of independent of Gaussian random vectors. 
Their expectation can be computed directly: $\E[\bfx_1]=\mathbb{E}[\bfx_2]=\mathbf{0}$.
Next, we calculate the covariance of these variables. Specifically, the covariances are given by:
\begin{equation}
\label{eq:freq_x2}
    \Cov\left(\bfx_1\right) = \Cov\left(\bfx_2\right) = \frac{1}{1+\cos^2\theta}\mI,\quad
    \Cov(\bfx_1,\bfx_2) = \Cov(\bfx_2,\bfx_1) = \frac{\cos^2\theta}{1+\cos^2\theta}\mI.
\end{equation}
This implies that $\bfx_1$ and $\bfx_2$ are correlated, as they both share a component of $\bfx$ when $\cos\theta\ne0$.

The \textbf{noise processing} and \textbf{post-processing} steps can be expressed as follows:
\begin{equation}
    \bfz_1 = \mF^{-1}\mLambda_x\mF\bfx_1 + \mF^{-1}\mLambda_y\mF\bfy_1, \quad
    \bfz_2 = \mF^{-1}\mLambda_x\mF\bfx_2 + \mF^{-1}\mLambda_y\mF\bfy_2,
\end{equation}
\begin{equation}
\bfz = \frac{1}{\sqrt{2}}\left(\Re\left(\bfz_1\right)+\Im\left(\bfz_1\right)+\Re\left(\bfz_2\right)-\Im\left(\bfz_2\right)\right),
\end{equation}
where $\bfy_1, \bfy_2\sim\mathcal{N}\left(\mathbf{0}, \mI\right)$ are independent. 
Regarding the filters, $\mLambda_x$ and $\mLambda_y$ are diagonal matrices corresponding to the low-pass filter $\mathcal{M}$ and the high-pass filter $(\bm{1}-\mathcal{M})^{0.5}$.

The refined noise $\bfz$ can be expressed in a following form using equation~\ref{eq:decomposition}:
\begin{equation}
\label{eq:freq_z_1}
\begin{split}
\sqrt{2}N\cdot\bfz {} = {}& \phantom{\;\;\,\,\,}\left( \mA\mLambda_x\mA +\mB\mLambda_x\mB+\mA\mLambda_x\mB-\mB\mLambda_x\mA\right)\bfx_1 \\
                          & + \left( \mA\mLambda_y\mA +\mB\mLambda_y\mB+\mA\mLambda_y\mB-\mB\mLambda_y\mA\right)\bfy_1 \\
                          & + \left( \mA\mLambda_x\mA +\mB\mLambda_x\mB-\mA\mLambda_x\mB+\mB\mLambda_x\mA\right)\bfx_2 \\
                          & + \left( \mA\mLambda_y\mA +\mB\mLambda_y\mB-\mA\mLambda_y\mB+\mB\mLambda_y\mA\right)\bfy_2.
\end{split}
\end{equation}
From the mathematical form of this expression, it is evident that the matrices preceding these random vectors share similar structures.
To simplify this equation, we introduce the following notations:
\begin{equation}
\begin{split}
    \text{Let}:\quad
    \mC_x &= \mA\mLambda_x\mA +\mB\mLambda_x\mB,\quad \mD_x =\mA\mLambda_x\mB-\mB\mLambda_x\mA, \\
    \mC_y &= \mA\mLambda_y\mA +\mB\mLambda_y\mB,\quad \mD_y =\mA\mLambda_y\mB-\mB\mLambda_y\mA.
\end{split}
\end{equation}
Since $\mA$ and $\mB$ are real symmetric matrices, and $\mLambda_x$ and $\mLambda_y$ are diagonal matrices, it is straightforward to prove that $\mC_x$ and $\mC_y$ are symmetric matrices, while $\mD_x$ and $\mD_y$ are skew-symmetric matrices. 
Using these notations, Equation~(\ref{eq:freq_z_1}) can be simplified as follow:
\begin{equation}
    \sqrt{2}N\cdot\bfz = \left(\mC_x+\mD_x\right)\bfx_1+
    \left(\mC_y+\mD_y\right)\bfy_1+
    \left(\mC_x-\mD_x\right)\bfx_2+
    \left(\mC_y-\mD_y\right)\bfy_2.
\end{equation}
In the analysis of $\sqrt{2}N\cdot\bfz$ where $\bfz$ is a Gaussian-distributed vector, we need to calculate the expectation and covariance to determine its distribution.
The expectation is given by $\E[\bfz] = \mathbf{0}$. 
The covariance can be expressed as the sum of several covariance terms related to  $\bfx_1$, $\bfx_2$, $\bfy_1$ and $\bfy_2$. Specifically, the covariance of $\sqrt{2}N\cdot\bfz$ can be expressed as follows:
\begin{equation}
\begin{split}
    \Cov(\sqrt{2}N\cdot\bfz) = {}& {} \phantom{\,\;\;\,\,\,} \Cov\left(\left(\mC_x+\mD_x\right)\bfx_1\right)
    +\Cov\left(\left(\mC_x-\mD_x\right)\bfx_2\right)\\
    &+\Cov\left(\left(\mC_y+\mD_y\right)\bfy_1\right)
    +\Cov\left(\left(\mC_y-\mD_y\right)\bfy_2\right)\\
    &+\Cov\left(\left(\mC_x+\mD_x\right)\bfx_1,\left(\mC_x-\mD_x\right)\bfx_2\right)\\
    &+\Cov\left(\left(\mC_x-\mD_x\right)\bfx_2,\left(\mC_x+\mD_x\right)\bfx_1\right).
\end{split}
\end{equation}
The covariance of $\sqrt{2}N\cdot\bfz$ consists of 6 terms, with first four terms representing the covariance of each random vector. The last two terms are cross terms that arise due to the fact that $\bfx_1$ and $\bfx_2$ are not independent. 
By solving these terms, We can derive the covariance of $\bfz$.

First, we focus on the covariance terms related to $\bfy_1$ and $\bfy_2$:
\begin{equation}
\label{eq:freq_cov_part1}
\begin{split}
    &\Cov\left(\left(\mC_y+\mD_y\right)\bfy_1\right)+\Cov\left(\left(\mC_y-\mD_y\right)\bfy_2\right)\\
    ={}&\left(\mC_y+\mD_y\right)\Cov\left(\bfy_1\right)\left(\mC_y+\mD_y\right)^\top + 
    \left(\mC_y-\mD_y\right)\Cov\left(\bfy_1\right)\left(\mC_y-\mD_y\right)^\top \\
    = {} &  \left(\mC_y+\mD_y\right)\left(\mC_y-\mD_y\right) + \left(\mC_y-\mD_y\right)\left(\mC_y+\mD_y\right)
    =2\left(\mC_y^2-\mD_y^2\right).
\end{split}
\end{equation}
Similarly, we can infer $\Cov\left(\left(\mC_x+\mD_x\right)\bfx_1\right)
    +\Cov\left(\left(\mC_x-\mD_x\right)\bfx_2\right)$ combined with Equation~(\ref{eq:freq_x2}):
% Covariance x part
\begin{equation}
\label{eq:freq_cov_part2}
    \Cov\left(\left(\mC_x+\mD_x\right)\bfx_1\right)
    +\Cov\left(\left(\mC_x-\mD_x\right)\bfx_2\right)
    = \frac{2}{1+\cos^2\theta}\left(\mC_x^2-\mD_x^2\right).
\end{equation}
Having computed the first four terms, we now turn our attention to the last two cross terms. With Equation~(\ref{eq:freq_x2}), we have:
\begin{equation}
\label{eq:freq_cov_part3}
\begin{split}
    &\Cov\left(\left(\mC_x+\mD_x\right)\bfx_1,\left(\mC_x-\mD_x\right)\bfx_2\right)
    +\Cov\left(\left(\mC_x-\mD_x\right)\bfx_2,\left(\mC_x+\mD_x\right)\bfx_1\right) \\
    =&{} \left(\mC_x+\mD_x\right)\Cov(\bfx_1,\bfx_2)\left(\mC_x-\mD_x\right)^\top 
        +\left(\mC_x-\mD_x\right)\Cov(\bfx_2,\bfx_1)\left(\mC_x+\mD_x\right)^\top \\
    =&{}\frac{\cos^2\theta}{1+\cos^2\theta}\left(\mC_x+\mD_x\right)^2+\frac{\cos^2\theta}{1+\cos^2\theta}\left(\mC_x-\mD_x\right)^2 =\frac{2\cos^2\theta}{1+\cos^2\theta}\left(\mC_x^2+\mD_x^2\right).
\end{split}
\end{equation}
Substituting the expression of the covariance related to $\bfx_1$, $\bfx_2$, $\bfy_1$ and $\bfy_2$ with Equations~(\ref{eq:freq_cov_part1},~\ref{eq:freq_cov_part2},~\ref{eq:freq_cov_part3}), we can express the covariance of $\sqrt{2}N\cdot\bfz$ in the following form:
\begin{equation}
\label{eq:freq_50}
    \Cov\left(\sqrt{2}N\cdot\bfz\right) = 2\left(\mC_x^2-\mD_x^2+\mC_y^2-\mD_y^2\right)+ \frac{4\cos^2\theta}{1+\cos^2\theta}\mD_x^2.
\end{equation}
To further simplify this equation, we need to explore the properties of $\mC_x$, $\mC_y$, $\mD_x$ and $\mD_y$. 
From Theorem~\ref{theorem:dft}, which establish $\mA\mB=\mB\mA=\mathbf{0}$ and $\mA^2+\mB^2=N\mI$. We can compute the squares of matrices $\mC_x$ and $\mD_x$ as follows:
\begin{equation}
\label{eq:freq_51}
\begin{split}
    \mC_x^2 & = \mA\mLambda_x\mA^2\mLambda_x\mA + \mB\mLambda_x\mB^2\mLambda_x\mB, \\
    -\mD_x^2 & = \mA\mLambda_x\mB^2\mLambda_x\mA + \mB\mLambda_x\mA^2\mLambda_x\mB.
\end{split}
\end{equation}
Notice that the squares of $\mC_x$ and $\mD_x$ share a similar form, differing only in the middle matrix: one is $\mA^2$ and the other is $\mB^2$. This observation inspires us to calculate $\mC_x^2-\mD_x^2$, especially since we have established $\mA^2+\mB^2=N\mI$. Therefore, we can express it as follows:
\begin{equation}
\begin{split}
    \mC_x^2-\mD_x^2&= \mA\mLambda_x\left(\mA^2+\mB^2\right)\mLambda_x\mA + \mB\mLambda_x\left(\mB^2+\mA^2\right)\mLambda_x\mB\\ 
    & = N \mA\mLambda_x^2\mA + N\mB\mLambda_x^2\mB, \\
\end{split}
\end{equation}
Since $\mC_y$ and $\mD_y$ follow the same pattern with only the subscript replaced, it also holds that:
\begin{equation}
    \mC_y^2-\mD_y^2 = N \mA\mLambda_y^2\mA + N\mB\mLambda_y^2\mB. 
\end{equation}
Make use of $\mLambda_y=\left(\mI-\mLambda_x^2\right)^{\frac{1}{2}}$, we can conclude:
\begin{equation}
\label{eq:freq_54}
    \mC_x^2-\mD_x^2 + \mC_y^2-\mD_y^2 = N \mA\left(\mLambda_x^2+\mLambda_y^2\right)\mA + N\mB\left(\mLambda_x^2+\mLambda_y^2\right)\mB =N\mA^2+N\mB^2=N^2\mI.
\end{equation}
Substituting with Equations~(\ref{eq:freq_51}) and (\ref{eq:freq_54}), we can simplifies Equation~(\ref{eq:freq_50}) to express the covariance of $\sqrt{2}N\cdot\bfz$ as follows:
\begin{equation}
\label{eq:freq_55}
    \Cov\left(\sqrt{2}N\cdot\bfz\right) = 
    2N^2\mI
    -\frac{4\cos^2\theta}{1+\cos^2\theta}
    \left( \mA\mLambda_x\mB^2\mLambda_x\mA + \mB\mLambda_x\mA^2\mLambda_x\mB
    \right),
\end{equation}
Inspired by the form of $\mA\mLambda_x\mB^2\mLambda_x\mA$ and $\mB\mLambda_x\mA^2\mLambda_x\mB$ which are the matrix multiplication of $\mA\mLambda_x\mB$ and $\mB\mLambda_x\mA$. 
We creatively construct a new matrix $\mQ = \frac{1}{N}\left(\mA\mLambda_x\mB+\mB\mLambda_x\mA\right)$. It is easy to prove $\mQ$ is a symmetric matrix. The square of $\mQ$ is as follows:
\begin{equation}
\label{eq:Q_square}
    \mQ^2=\frac{1}{N^2}\left( \mA\mLambda_x\mB^2\mLambda_x\mA + \mB\mLambda_x\mA^2\mLambda_x\mB
    \right).
\end{equation}
By combining Equation~(\ref{eq:freq_55}) and Equation~(\ref{eq:Q_square}) and eliminating the constant $\sqrt{2}N$ from both sides of the equation, we can calculate the covariance of $\bfz$:
\begin{equation}
    \Cov\left(\bfz\right)=\mI - \frac{2\cos^2\theta}{1+\cos^2\theta}\mQ^2.
\end{equation}
Finally, we derive the distribution of $\bfz$ as follows:
\begin{equation}
\label{eq:freq_distribution}
    \bfz\sim\mathcal{N}\left(\mathbf{0}, \mI - \frac{2\cos^2\theta}{1+\cos^2\theta}\mQ^2\right).
\end{equation}
It is clear that the covariance of our refined noise is ``smaller'' than $\mI$. However, as $\mA\mB=\mB\mA=\mathbf{0}$ and the diagonal elements of $\Lambda_x$ ranges from 0 to 1, it gives the intuition that $\mQ$ is close to $\mathbf{0}$. 
We make further analysis in Appendix~\ref{appendix:covariance}.
