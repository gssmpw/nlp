\section{Preliminary}
\subsection{Diffusion models}
\label{appendix:preliminary}
\textbf{Diffusion models}~\citep{ho2020denoising} are a class of generative models that recover the data corrupted by the Gaussian noise through learning a reverse diffusion process.
It iteratively denoises from Gaussian noise, which corresponds to learning the reverse process of a fixed Markov Chain of length $T$.
The diffusion process is a Markov chain that gradually corrupts the data with Gaussian noise.
For the diffusion process given the variance schedule $\beta_t$:
\begin{equation}
q(x_{1:T} | x_0) = \prod_{t=1}^T q(x_t | x_{t-1} ), \qquad q(x_t|x_{t-1}) = \mathcal{N}(x_t;\sqrt{1-\beta_t}x_{t-1},\beta_t I).
\end{equation}
Using the  Markov property, we can sample $x_t$ at an arbitrary time $t$ from $x_0$ in closed form. Let $\alpha=1-\beta_t$ and $\bar{\alpha}_t=\prod_{s=1}^t\alpha_s$, we have
\begin{equation}
    q(x_t|x_0) = \mathcal{N}(x_t; \sqrt{\bar\alpha_t}x_0, (1-\bar\alpha_t)I).
\end{equation}
By the Bayes' rules, $q(x_{t-1}|x_t,x_0)$ can be expressed as follows:
\begin{align}
q(x_{t-1}|x_t,x_0) &=  \mathcal{N}(x_{t-1}; \tilde\mu_t(x_t, x_0), \tilde\beta_t I), \\
\text{where}\quad \tilde\mu_t(x_t, x_0) &= \frac{\sqrt{\bar\alpha_{t-1}}\beta_t }{1-\bar\alpha_t}x_0 + \frac{\sqrt{\alpha_t}(1- \bar\alpha_{t-1})}{1-\bar\alpha_t} x_t \quad \text{and} \quad
\tilde\beta_t = \frac{1-\bar\alpha_{t-1}}{1-\bar\alpha_t}\beta_t.
\end{align}
For the reverse process, it generates $x_0$ from $x_T$ with prior $x_T=\mathcal{N}(x_T;0,I)$ and transitions:
\begin{equation}
    p_\Theta(x_{t-1}|x_t)=\mathcal{N}(x_{t-1};\mu_\Theta(x_t, t),\Sigma_\Theta(x_t,t)).
\end{equation}
In the equation, $\Theta$ are learnable parameters of models $\epsilon_\Theta$ 
which are trained to minimize the variant of the variational bound $\E_{x,\epsilon\sim\mathcal{N}(0,I),t}\left[ \left\| \epsilon-\epsilon_{\Theta}\left(x_t, t\right) \right\|^2 \right]$.

\subsection{Fourier transform}
\label{appendix:fourier}
\textbf{Discrete Fourier Transform (DFT)} is one of the most important discrete transforms used in digital signal processing including image processing.
The discrete Fourier transform can be expressed as the \textbf{DFT} matrix, denoted as $\mF$, defined as follows:
\begin{equation}
    \mF = \left( \omega_N^{\left(m-1\right)\cdot\left(n-1\right)} \right)_{N \times N}=
\begin{bmatrix}
 \omega_N^{0 \cdot 0}     & \omega_N^{0 \cdot 1}     & \cdots & \omega_N^{0 \cdot (N-1)}     \\
 \omega_N^{1 \cdot 0}     & \omega_N^{1 \cdot 1}     & \cdots & \omega_N^{1 \cdot (N-1)}     \\
 \vdots                   & \vdots                   & \ddots & \vdots                       \\
 \omega_N^{(N-1) \cdot 0} & \omega_N^{(N-1) \cdot 1} & \cdots & \omega_N^{(N-1) \cdot (N-1)} \\
\end{bmatrix}
\end{equation}
where $\omega_N = e^{-{2\pi i/N}}$ is a primitive $N$-th root of unity. 
The inverse transform, denoted as $\mF^{-1}$ can be derived from $\mF$ as its complex conjugate transpose, scaled by $\frac{1}{N}$: $\mF^{-1} = \frac{1}{N}\mF^\ast$.

The \textbf{DFT} matrix $\mF$ can be decomposed into its real and imaginary parts, represented respectively by matrices $\mA$ and $\mB$:
\begin{equation}
\label{eq:decomposition}
    \mF = \mA + \mB i,\quad \mA = \Re\left(\mF\right),\quad \mB = \Im\left(\mF\right).
\end{equation}
This decomposition simplifies the understanding of the structure and properties of the DFT matrix, providing deeper insights. Using Eulerâ€™s formula, $\mA$ and $\mB$ can be explicitly expressed as:
\begin{equation}
    \mA = \left(\cos\left( \left(m-1\right)\left(n-1\right)\theta \right)\right)_{N\times N},\quad 
    \mB = \left(\sin\left( \left(m-1\right)\left(n-1\right)\theta \right)\right)_{N\times N},
\end{equation}
where $\theta=-\frac{2\pi}{N}$. 
Notably, both $\mA$ and $\mB$ are real symmetric matrices.

\begin{lemma}
\label{lemma:1}
    For $\theta=-\frac{2\pi}{N}$ where $N$ is a positive integer, it holds that $\sum_{k=1}^{N}\sin\left(l\left(k-1\right)\theta\right)=0$ for any integer $l$.
\end{lemma}
\begin{proof}
By applying Euler's formula, we rewrite $\sin\left(l\left(k-1\right)\theta\right)$ as $\Im\left(\omega_N^{l(k-1)}\right)$, where $\omega_N=e^{-2\pi i/N}$. Then we have:
\begin{equation}
    \sum_{k=1}^{N} \sin\left(l\left(k-1\right)\theta\right) =\sum_{k=0}^{N-1} \Im \left(\omega_N^{lk}\right) = \Im \left( \sum_{k=0}^{N-1} \omega_N^{lk}\right).
\end{equation}
The term $\sum_{k=0}^{N-1} \omega_N^{lk}$ is the sum of geometric sequence. 
If $\omega_N^{l} = 1$, then $\sum_{k=0}^{N-1} \omega_N^{lk} = N$, yielding $\Im \left( \sum_{k=0}^{N-1} \omega_N^{lk}\right)=0$.

Otherwise, if $\omega_N^{l} \ne 1$, we have $\sum_{k=0}^{N-1} \omega_N^{lk} = \left(1-\omega_N^{lN}\right)/\left(1-\omega_N^{l}\right)$. Since $\omega_N^{N}=1$, then $\sum_{k=0}^{N-1} \omega_N^{lk} = 0$, and consequently $\Im \left( \sum_{k=0}^{N-1} \omega_N^{lk}\right)=0$.

In conclusion, we have shown that $\sum_{k=1}^{N} \sin\left(l\left(k-1\right)\theta\right)=0$ for any integer $l$.
\end{proof}
This lemma offers foundational insights into the behavior of the sum of sinusoidal functions,
Now, we introduce a theorem regarding properties of the \textbf{DFT} matrix.
\begin{theorem}
\label{theorem:1}
    Given a \textbf{DFT} matrix $\mF\in \mathbb{C}^{N\times N}$, with $\mA$ and $\mB$ representing its real and imaginary parts respectively, it holds that $\mA\mB=\mB\mA=\mathbf{0}$ and $\mA^2+\mB^2=N\mI$.
\end{theorem}
\begin{proof}
Using the property of the inverse Fourier transform, we have
\begin{equation}
    \mI = \mF\mF^{-1} = \frac{1}{N} \mF \mF^{\ast} = \frac{1}{N}\left(\mA + \mB i\right)\left(\mA - \mB i\right) = \frac{1}{N}\left(\mA^2+\mB^2-\mA\mB i+\mB\mA i\right).
\end{equation}
Comparing real parts and imaginary parts of both sides, we derive:
\begin{equation}
    \mA^2+\mB^2=N\mI,\quad \mB\mA=\mA\mB.
\end{equation}
Considering the matrix $\mA\mB$, we calculate the value of the element in the $m$-th row and $n$-th column:
\begin{equation}
\begin{split}
    \left(\mA\mB\right)_{mn} &=\sum_{k=1}^{N}\cos\left( \left(m-1\right)\left(k-1\right)\theta \right)\sin\left( \left(k-1\right)\left(n-1\right)\theta \right) \\
    &=\frac{1}{2}\sum_{k=1}^{N}\left( \sin\left((m+n-2)(k-1)\theta\right) - \sin\left((m-n)(k-1)\theta\right) \right) = 0.
\end{split}
\end{equation}
The last equation holds using Lemma~\ref{lemma:1}. The equation holds for each element of $\mA\mB$.
Therefore $\mA\mB=\mB\mA=\mathbf{0}$.
\end{proof}
%%%%%%%%%%%%%   3 dimension
For the 3D Fourier transform, it can be represented as follows using the Kronecker product:
\begin{equation}
    \mF_{3D} = \mF_{T} \otimes \mF_{H} \otimes \mF_{W}.
\end{equation}
The inverse transform is given by:
\begin{equation}
    \mF_{3D}^{-1}  = \frac{1}{N_TN_HN_W} \mF_{3D}^\ast.
\end{equation}
Similarly, we decompose $\mF_{3D}$ into its real part $\mA_{3D}$ and imaginary part $\mB_{3D}$:
\begin{equation}
\begin{split}
    \mF_{3D} & =\left(\mA_T+\mB_Ti\right) \otimes \left(\mA_H+\mB_Hi\right) \otimes \left(\mA_W+\mB_Wi\right), \\
    \mA_{3D} &= \mA_T\otimes\mA_H\otimes\mA_W
    -\mA_T\otimes\mB_H\otimes\mB_W
    -\mB_T\otimes\mA_H\otimes\mB_W
    -\mB_T\otimes\mB_H\otimes\mA_W, \\
    \mB_{3D} &= \mA_T\otimes\mA_H\otimes\mB_W
    +\mA_T\otimes\mB_H\otimes\mA_W
    +\mB_T\otimes\mA_H\otimes\mA_W
    -\mB_T\otimes\mB_H\otimes\mB_W.
\end{split}
\end{equation}
By Theorem~\ref{theorem:1} and the property or Kronecker product, it still holds that:
\begin{equation}
    \mA_{3D}^2+\mB_{3D}^2=N_T N_H N_W\mI,\quad \mB_{3D}\mA_{3D}=\mA_{3D}\mB_{3D}=\mathbf{0}.
\end{equation}
It reveals that the 3D DFT matrix shares the same properties as the ordinary DFT matrix.
For convenience, we denote the DFT matrix, including multi-dimensional cases as $\mF$, with size denoted as $N$.
Employing mathematical induction, we can extend Theorem~\ref{theorem:1} from one-dimensional case to arbitrary finite dimensions:
\begin{theorem}
\label{theorem:dft}
    Given a \textbf{DFT} matrix or multi-dimension \textbf{DFT} matrix $\mF\in \mathbb{C}^{N\times N}$, with $\mA$ and $\mB$ are its real part and imaginary part respectively, it holds that $\mA\mB=\mB\mA=\mathbf{0}$ and $\mA^2+\mB^2=N\mI$.
\end{theorem}