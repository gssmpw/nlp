\makeatletter
\def\adl@drawiv#1#2#3{%
        \hskip.5\tabcolsep
        \xleaders#3{#2.5\@tempdimb #1{1}#2.5\@tempdimb}%
                #2\z@ plus1fil minus1fil\relax
        \hskip.5\tabcolsep}
\newcommand{\cdashlinelr}[1]{%
  \noalign{\vskip\aboverulesep
           \global\let\@dashdrawstore\adl@draw
           \global\let\adl@draw\adl@drawiv}
  \cdashline{#1}
  \noalign{\global\let\adl@draw\@dashdrawstore
           \vskip\belowrulesep}}
\makeatother
\begin{table}[t]
    \caption{\textbf{Main results.} 
    For different types of noise prior, we provide the settings for finding the prior and sampling steps for video generation. Evaluation metrics include {\it quality score}, {\it semantic score}, and {\it total score}. Additionally, we report the inference time, which includes the time for finding the noise prior and the time for generation.}
    \label{tab:main}
    \centering
    \resizebox{\linewidth}{!}{
    \begin{tabular}{cccccccc}
        \toprule
        \textbf{Base model}  & \textbf{Noise prior} & \textbf{Prior finding} & \textbf{Generation} & \textbf{Quality} & \textbf{Semantic} & \textbf{Total} & \textbf{Inference time} \\
        \midrule
        % VideoCrafter
        \multirow{6}{*}{VideoCrafter}
        &  Gaussian  &     /                &  25 steps     &     69.50 &     54.92 &     66.58  &  \bf 27.73s \\ 
        &  Mixed     &     /                &  25 steps     &     --    &     --    &      --    &   --    \\
        & Progressive&     /                &  25 steps     &     --    &     --    &      --    &   --    \\ \cdashlinelr{2-8}
        &  Gaussian  &     /                &  3*25 steps   &     69.75 &     58.10 &     67.42  &  83.09s \\
        &  FreeInit  &  2 full sampling     &  25 steps     &     70.62 &     58.97 &     68.29  &  83.18s \\
        &  Ours      &  2 partial sampling  &  25 steps     & \bf 70.63 & \bf 61.33 & \bf 68.77  &  \underline{63.67s} \\
        \midrule
        % ModelScope
        \multirow{6}{*}{ModelScope}
        &  Gaussian  &     /                &  50 steps     &     73.13 &     65.69 &     71.64  & \bf 19.24s  \\
        &  Mixed     &     /                &  50 steps     &     --    &     --    &      --    &   --    \\
        & Progressive&     /                &  50 steps     &     --    &     --    &      --    &   --    \\ \cdashlinelr{2-8}
        &  Gaussian  &     /                &  3*50 steps   &     73.25 &     66.31 &     71.87  & 57.72s  \\
        &  FreeInit  &  2 full sampling     &  50 steps     &     73.61 &     67.24 &     72.34  & 57.73s  \\
        &  Ours      &  2 partial sampling  &  50 steps     & \bf 74.04 & \bf 69.06 & \bf 73.04  & \underline{44.88s}  \\
        \midrule
        % AnimateDiff
        \multirow{6}{*}{AnimateDiff}
        &  Gaussian  &     /                &  25 steps     &     79.56 &     69.03 &     77.45  & \bf 23.34s  \\
        &  Mixed     &     /                &  25 steps     &     --    &     --    &      --    &   --    \\
        & Progressive&     /                &  25 steps     &     --    &     --    &      --    &   --    \\ \cdashlinelr{2-8}
        &  Gaussian  &     /                &  3*25 steps   &     79.49 &     69.71 &     77.54  & 70.22s  \\
        &  FreeInit  &  2 full sampling     &  25 steps     &     79.58 &     68.85 &     77.43  & 70.45s  \\
        &  Ours      &  2 partial sampling  &  25 steps     & \bf 80.05 & \bf 70.37 & \bf 78.11  & \underline{54.05s}  \\
        \bottomrule
    \end{tabular}
    }
\end{table}





\section{Experiments}
\label{sec:experiments}

\subsection{Experimental settings}
\paragraph{Baselines}
In our experiments, we establish the following baselines: Gaussian noise, mixed noise, progressive noise, and FreeInit~\citep{wu2023freeinit}.
Gaussian noise serves as the default prior for diffusion models.
The mixed noise prior and progressive noise prior are proposed by PYoCo~\citep{ge2023PYoCo}.
FreeInit is the pioneering work that employs Fourier transform to create a new prior.


\paragraph{Implementations}
We conduct the experiments on three open-soruce text-to-video diffusion models: VideoCrafter~\citep{chen2023videocrafter1}, ModelScope~\citep{wang2023modelscope}, and AnimateDiff~\citep{guo2023animatediff}. 
DDIM~\citep{song2021ddim} is set to the default sampler, with the scheduler's offset configured to 1.
Both FreeInit and our method require additional samplings to acquire the noise prior, with the number of extra sampling iterations set to 2. 
To ensure fairness, we use a Butterworth Filter with a normalized spatial-temporal cutoff frequency of 0.25 as the low-pass filter for both FreeInit and our method.
In our approach, the timestep $t$ is set to 321, the ratio $\cos\theta$ is set to 0.8 for ModelScope and AnimateDiff, and 0.7 for VideoCrafter. All experiments are conducted on NVIDIA V100 GPUs.
For more details, please refer to Appendix~\ref{appendix:setting}.

\paragraph{Evaluation}
To evaluate the performance of each noise prior, we use VBench~\citep{huang2023vbench}, a comprehensive benchmark that closely aligns with human perception.
VBench dissects evaluation into specific, hierarchical, and disentangled dimensions, each featuring tailored prompts and evaluation methods.
Specifically, VBench assesses performance across two primary levels: {\bf \textit{quality score}} and {\bf \textit{semantic score}}. The {\bf \textit{total score}} is calculated as the weighted average of the {\bf \textit{quality score}} and {\bf \textit{semantic score}}.
The scores range from 0 to 100, with a higher score indicating better performance in the corresponding aspects. 
For each noise prior, we generate 4730 videos for VBench evaluation. For more details, please refer to Appendix~\ref{appendix:vbench}.


\begin{figure}[t]
  \centering
  \includegraphics[width=1.0\linewidth]{figure/pyoco.pdf}
  \vspace{-15pt}
  \caption{\textbf{Generation results using PYoCo prior.} Both mixed noise prior and progressive noise prior lead to crashes on pretrained video diffusion models.}
  \label{fig:pyoco}
\end{figure}

\subsection{Main results}
\paragraph{Quantitative results} 
As shown in Table~\ref{tab:main}, our method achieves the highest scores across all metrics, {\it quality score}, {\it semantic score}, and {\it total score}, on the three different base models, underscoring the superiority of our proposed noise prior.
Our approach enhances both the video fidelity and semantic consistency of the generated videos.
In contrast, the mixed noise prior and progressive noise prior lead to crashes and failure in generating normal videos, as illustrated in Figure~\ref{fig:pyoco}. 
This is due to the significant gap between these types of prior and the standard Gaussian distribution, as these types of prior introduce correlations in the frame dimension.
The PYoCo method requires training a model specifically on these types of prior and cannot be directly applied to pre-trained diffusion models, which limits its practical applications.
FreeInit and our method require two additional samplings to acquire the noise prior, resulting in increased inference time. To investigate whether the performance improvements are attributed to more denoising steps, we triple the steps during generation for Gaussian noise.
While tripling the steps for Gaussian noise provides a slight performance boost, the improvements are modest, particularly on ModelScope and AnimateDiff, where the \textit{total score} increases by only 0.23 and 0.09, respectively. 
Although it shows a more significant improvement of 0.84 on VideoCrafter, its \textit{total score} still falls well short of both FreeInit and our proposed prior.
FreeInit generally enhances performance compared to Gaussian noise prior, it reduces the \textit{semantic score} and \textit{total score} on AnimateDiff. The reason may be the negative effects of variance decay surpass the positive effects of refinement on low-frequency signals. Our method does not have such a variance decay issue.
Overall, when compared to Gaussian noise with triple steps and FreeInit, our method outperforms all metrics while requiring the least inference time, saving approximately 23\%.
The performance gains stem from the noise refinement stage, where we introduce a new frequency filtering method targeted at the noise. 
The time savings arise from diffusing the latent at an intermediate step, resulting in partial sampling that reduces several denoising steps. 

\paragraph{Qualitative results} Figure~\ref{fig:visual} presents a comparative visualization of the results.
In the top left case, our method produces video frames with superior fidelity, featuring backgrounds reminiscent of a café, while the frames generated using Gaussian noise lack any background. FreeInit further deteriorates the result compared to Gaussian noise, blurring the area within the red box into an indistinct speck. The top right case demonstrates that the videos generated by our method exhibit finer details and better semantics.
In the middle left case, our results are aesthetically superior in terms of color and brightness, while those produced by Gaussian noise appear relatively dim. The middle right case highlights that both baselines fail to generate a guitar, whereas our method successfully creates one that aligns closely with the provided text prompt.
In the bottom left case, the example generated by FreeInit resembles “a cat sleeping in a bowl” rather than “a cat eating food out of a bowl.” In the bottom right case, the video generated from Gaussian noise is missing a “person,” while FreeInit produces an unnatural representation, lacking motion dynamics. In contrast, our method delivers the highest quality video, featuring a person walking forward.
Overall, these cases illustrate that our method outperforms these types of noise prior in both quality and semantics.

\begin{table}[h]
    \caption{{\bf Ablation study on the impact of ratio \boldmath$\cos\theta$.} We present {\bf total score} across various values of ratio $\cos\theta$. To eliminate the effects of 
    timestep $t$, it is fixed to 0.}
    \label{tab:ratio}
    \centering
    % \resizebox{\linewidth}{!}{
    \begin{tabular}{cccc}
        \toprule
        \boldmath$\cos\theta$  & \textbf{VideoCrafter} & \textbf{ModelScope} & \textbf{AnimateDiff} \\
        \midrule      
        1.0  &     69.02 &     72.82 &     78.07  \\ 
        0.9  &     68.96 &     72.92 &     78.07  \\
        0.8  &     68.91 & \bf 73.12 & \bf 78.12  \\
        0.7  & \bf 69.04 &     72.97 &     78.09  \\
        \bottomrule
    \end{tabular}
    % }
\end{table}

\begin{figure}[p]
  \centering
  \includegraphics[width=1.0\linewidth]{figure/visualization.pdf}
  \caption{\textbf{Qualitative results and comparisons.} The cases in the top row are generated using AnimateDiff, while the middle row displays cases from ModelScope, and the bottom row shows cases generated by VideoCrafter. For each case, we present the generation results from different types of noise prior along with the corresponding prompt.}
  \label{fig:visual}
\end{figure}

\subsection{Ablation study}
\begin{figure}[h]
  \centering
  \includegraphics[width=1.0\linewidth]{figure/ablation_ratio.pdf}
  \vspace{-15pt}
  \caption{\textbf{Generation results on different values of \boldmath$\cos\theta$.} Though there are some changes in the generated video frames as $\cos\theta$ varies, they are quite similar.}
  \label{fig:ratio}
  \vspace{-5pt}
\end{figure}

\paragraph{Influence of ratio \boldmath$\cos\theta$} 
The generation results are affected by two hyper-parameters, the ratio $\cos\theta$ in the noise refinement stage and the timestep $t$ in the diffusion process.
To investigate the effects of $\cos\theta$, we set timestep $t$ to $0$ to eliminate the influence of $t$.
In Equation~(\ref{eq:method_X}), both $\bfx_1^i$ and $\bfx_2^i$ contribute to low-frequency signals of $\bfz_T^{i+1}$, the initial latent for the subsequent iteration.
As $\cos\theta$ decreases, the proportion of $\bfz_{noise}^i$ in $\bfx_1^i$ and $\bfx_2^i$ diminishes, indicating a reduction in the low-frequency components rooted in $\bfz_{noise}^i$. 
$\cos\theta$ governs the extent to which low-frequency signals are retained, assuming the filter remains constant. Therefore, $\cos\theta$ can not be small.
We conducted experiments with four different values of $\cos\theta$.
% (Table ratio cos)
As shown in Table~\ref{tab:ratio}, for AnimateDiff~\citep{guo2023animatediff} and ModelScope~\citep{wang2023modelscope}, \textit{Total Score} initially increases, reaching its peak at $\cos\theta=0.8$, before declining. 
For VideoCrafter~\citep{chen2023videocrafter1}, \textit{Total Score} get the highest at $\cos\theta=0.7$.
Overall, the differences among different $\cos\theta$ values are minor, indicating the FreqPrior is robust and not sensitive to changes in $\cos\theta$.
The visualization results presented in Figure~\ref{fig:ratio} demonstrate that while varying $\cos\theta$ leads to some differences in the video frames, they are still quite similar.

% Visualization results are listed in Appendix~\ref{appendix:visualization}.


% timestep
\begin{figure}[hbt]
  \centering
  % \fbox{\rule[-.5cm]{0cm}{4cm} \rule[-.5cm]{4cm}{0cm}}
  \includegraphics[width=1.0\linewidth]{figure/timestep.pdf}
  \vspace{-15pt}
  \caption{\textbf{Ablation study on the impact of timestep \boldmath$t$.} \textit{Total Score} is assessed accross different diffusion timesteps $t$ for three distinct text-to-video diffusion models. Overall, the timestep $t$ has little effect on the evaluated metric.}
  \label{fig:timestep}
  \vspace{-5pt}
\end{figure}


\paragraph{Influence of timestep \boldmath$t$.}
Figure~\ref{fig:timestep} shows that our method consistently outperforms Gaussian noise prior and FreeInit~\citep{wu2023freeinit}  across varying timestep $t$.
While there are some fluctuations, the curve corresponding to our method on all three base models shows a slow declining trend, indicating that as the timestep $t$ increases, the quality of generated videos is likely to decrease. However, with a larger timestep, fewer denoising steps are required in each sampling iteration to find the noise prior.
Consequently, it presents a trade-off between the generation quality and the inference time. Considering both factors, we selected $t=321$ for the final setting.

