\section{Related Work}
\label{sec:related_work}

\subsection{LLM Prompting}

Recent large language models (LLMs)____ are pre-trained on large-scale text corpora curated from the Internet____. % dodge2021c4
Their advanced text understanding and generation capabilities____ have significantly revolutionized the field of natural language processing (NLP).
Consequently, the NLP paradigm is shifting toward a framework comprising pre-training, post-training, and prompting____, with post-training focusing on aligning models with human preferences____ rather than fine-tuning for specific downstream tasks____.
After the training stages, LLMs can generate satisfactory responses to natural language instructions and questions, highlighting the growing importance of prompt design____.
In this work, we propose an intuitive, general, and effective prompting method to enhance LLM performance in question-answering.

\subsection{LLM Reasoning}

Recent LLM research increasingly emphasizes reasoning abilities____.
Chain-of-Thought (CoT) is a prompting strategy that enhances problem-solving by guiding LLMs to generate intermediate reasoning steps.
Main variants include zero-shot CoT____ that uses general instructions such as ``Let's think step by step'' and few-shot CoT____ that provides exemplars with rationales to leverage in-context learning____.
Building on CoT, various reasoning techniques have emerged____.
Some studies explore optimal reasoning paths through self-consistency____ or tree-like searches____,
while others investigate self-refinement____, self-correction____, self-verification____, and self-evolution____ mechanisms.
Beyond prompting and generation-based approaches, post-training methods____, particularly those leveraging reinforcement learning (RL)____, have been developed to enhance reasoning capabilities____.
As a reasoning-eliciting prompting approach, ARR effectively complements existing research by guiding LLMs through three essential steps: intent analysis, information retrieval, and step-by-step reasoning.


\subsection{Retrieval-Augmented Generation}

Retrieval-Augmented Generation (RAG) enhances output quality by retrieving relevant information from pre-processed knowledge sources____.
The retrieving component of our ARR method is inspired by the traditional ``external RAG'' approach____, which retrieves relevant information from the explicit context or outer sources, and realizes instead a form of ``internal RAG,'' which utilizes language models as implicit knowledge bases____ and extracts references from memory (training data)____.
This retrieval mechanism is essential for enhancing LLM performance in question answering, as irrelevant information can significantly degrade accuracy____.



%%%%%%%%%% # %%%%%%%%%% # SECTION # %%%%%%%%%% # %%%%%%%%%%
%