In this section, we introduce our mutual information estimator, \infosedd, which is based on \Cref{eq:infosedd-param}. Given two random variables, $\fproc_0$ and $\fprocy_0$, mutual information can be expressed in terms of the KL-divergence between the joint distribution $\fpjoint_0$ and the product of the marginals, defined as $\fpmarginal_0 = \fp^X_0 \otimes \fp^Y_0$, where $\otimes$ denotes the Kronecker product. This leads to the standard formulation: $I(\fproc_0,\fprocy_0) = \KL{\fpjoint_0}{\fpmarginal_0}$. However, this approach presents two key limitations, which we address in the following. 

First, in high dimensional applications, a naive implementation of \Cref{eq:infosedd-param} quickly becomes unfeasible. Indeed, the size of the number of entries of the matrix $\fratesp_t$ scales with $|\support|^2$, becoming quickly untractable. 
Fortunately, in many cases of interest, the random variables can be naturally decomposed into a structured sequence of $M$ subcomponents, each taking values from a discrete set of size  $N$ \citep{lou2024discrete, austin2021structured, campbell2022continuous}, i.e. $\fproc_0=[\fproc^1_0,\dots,\fproc^{M}_0]$, leading to a total state space of size $|\support|=N^M$.This structured decomposition enables the use of sparse rate matrices, which constrain the \gls{CTMC} to modify only one subcomponent at a time, significantly reducing computational complexity:\begin{equation}\label{eq:hamming_q}
\fratesp_t(x,y) = \delta(\hamming(x,y),1)\left(\sum_{i}(1-\delta(x^i,y^i))\fratestokp_t(x_i,y_i)\right),\quad x\neq y% -\delta(\hamming(x,y),0)\sum_{z\neq x} \fratesp_t(z,x), 
\end{equation}
Since the summation in the inner expectation of \Cref{eq:infosedd-param} ( $\sum_{y\neq \fproc_{t}} \fratesp_{t}(\fproc_{t},y)\dots$ ) depends only on non-zero entries of the matrix $\fratesp_{t}(\fproc_{t},y)$, the formulation in \Cref{eq:hamming_q} greatly reduces the number of transitions that need to be considered.

Second, formulating mutual information as the KL divergence between the joint distribution and the product of marginals, $\KL{\fpjoint_0}{\fpmarginal_0}$, typically requires training two separate score models, each tailored to a specific distribution. However, a carefully chosen transition matrix can circumvent this requirement, allowing for a single unified model to be trained instead. In particular, selecting $\fratestokp_t=\sigma(t)\fratestokp_{\text{absorb}}$, with $\sigma(t)$ a fixed scalar function, and the absorbing matrix \footnote{This configuration adds an absorbing state, increasing the dimension of the support}   %$\fratestokp_{\text{absorb}}(n_1.n_2)=-\delta(n_1,n_2)+\delta(n_1,N+1)(1-\delta(n_2,N+1))$ 
\citep{lou2024discrete, campbell2022continuous, austin2021structured},
\begin{equation}
    \begin{array}{cc}
    \fratestokp_{\text{absorb}} = \begin{bmatrix}
    -1 & 0 & \cdots & 0 & 0 \\
    0 & -1 & \cdots & 0 & 0 \\
    \vdots & \vdots & \ddots & \vdots & \vdots \\
    0 & 0 & \cdots & -1 & 0 \\
    1 & 1 & \cdots & 1 & 0
    \end{bmatrix}
\end{array}
\end{equation}
ensures that the subcomponents can only transition into an absorbing state $\absorb$. %We construct $\fratestokp_t=\sigma(t)\fratestokp_{\text{absorb}}$ with $\sigma(t)$ a fixed scalar function. 
This choice is crucial because it enables the computation of marginal scores using a model trained solely on the joint distribution. Specifically, as demonstrated in \Cref{sec:free_marginal},
\begin{equation}\label{eq:free_marginal}
    \frac{\fp_t(\fproc_t=x,\fprocy_t=\absorb)}{\fp_t(\fproc_t=x',\fprocy_t=\absorb)}=\frac{\fp^X_t(x)}{\fp^X_t(x')},\quad \frac{\fp_t(\fproc_t=\absorb,\fprocy_t=y)}{\fp_t(\fproc_t=\absorb,\fprocy_t=y')}=\frac{\fp^Y_t(y)}{\fp^Y_t(y')}.
\end{equation}

This result implies that a single score model trained on the joint distribution is sufficient for computing the marginal scores as well. By integrating these design choices, we now present the full formulation of \infosedd, whose pseudocode is detailed in \Cref{alg:infosedd}.



\begin{algorithm}[H]
\caption{\infosedd: Estimate $I(\rvx,\rvy)$}
\label{alg:infosedd}
\begin{algorithmic}[1]
{\small
    \REQUIRE Initial sample $[\fproc_0,\fprocy_0]\sim \fp_0$, score network $\scorefn$
    \STATE $t\sim u(0,T)$
    \COMMENT{Sample time uniformly}
    \STATE $[\fproc_t,\fprocy_t]\sim \fp_t(\cdot | [\fproc_0,\fprocy_0])$
    \COMMENT{Perturb data}
    \STATE $\hat{I}=0$
    \FOR{$i: \fproc^i_t=\absorb$}
    \FOR{$n\in [1:N]$}
    \STATE {\scriptsize $\tilde{X}=[\fproc^1_t,\dots,\fproc^{i-1}_t,n,\fproc^{i+1}_t,\dots,\fproc^{M}_t]$}
    \STATE {\scriptsize$\hat{I}+=T\sigma(t)\left(K\left(\scorefn([\fproc_t,\fprocy_t])_{[\tilde{X},\fprocy_t]}\right)+\scorefn([\fproc_t,\absorb])_{[\tilde{X},\absorb]}-\scorefn([\fproc_t,\fprocy_t])_{[\tilde{X},\fprocy_t]}\log\left(\scorefn([\fproc_t,\absorb])_{[\tilde{X},\absorb]}\right)\right)$}
    \ENDFOR
    \ENDFOR
    \FOR{$i: \fprocy^i_t=\absorb$}
    \FOR{$n\in [1:N]$}
    \STATE {\scriptsize$\tilde{Y}=[\fprocy^1_t,\dots,\fprocy^{i-1}_t,n,\fprocy^{i+1}_t,\dots,\fprocy^{M}_t]$}
    \STATE {\scriptsize$\hat{I}+=T\sigma(t)\left(K\left(\scorefn([\fproc_t,\fprocy_t])_{[\fproc_t,\tilde{Y}]}\right)+\scorefn([\absorb,\fprocy_t])_{[\absorb,\tilde{Y}]}-\scorefn([\fproc_t,\fprocy_t])_{[\fproc_t,\tilde{Y}]}\log\left(\scorefn([\absorb,\fprocy_t])_{[\absorb,\tilde{Y}]}\right)\right)$}
    \ENDFOR
    \ENDFOR
    \RETURN $\hat{I}$}
    \end{algorithmic}
\end{algorithm}





\subsection{Estimating entropy}
Notably, the proposed class of estimators can be readily adapted for entropy estimation. The entropy of a given distribution can be expressed in terms of the \gls{KL} divergence from the uniform distribution 
$\fu_0$, as follows: $H(\fp_0) = \log N -\KL{\fp_0}{\fu_0}$. Since the ratio $\frac{\fu_t(x)}{\fu_t(\absorb)}=\ratio$, with $\cumnoise(t)=\int_0^t\sigma(s)ds$ (see \cref{sec:absorb_ratio}), we can extend the formulation of \Cref{eq:infosedd-param} to derive \textsc{info-sedd-h}, an entropy estimator. The working mechanism of this estimator is straightforward and is detailed in \Cref{alg:compute_entropy}.


\begin{algorithm}[H]
\caption{\textsc{info-sedd-h}: Estimate $H(\fproc_0)$}
\label{alg:compute_entropy}
\begin{algorithmic}[1]
{\small
  \REQUIRE Initial sample $\fproc_0\sim \fp_0$, score network $\scorefn$
    \STATE $t\sim u(0,T)$
    \COMMENT{Sample time uniformly}
    \STATE $\fproc_t\sim \fp_t(\cdot | \fproc_0)$
    \COMMENT{Perturb data}
    \STATE $\hat{H}=0$
    \FOR{$i: \fproc^i_t=\absorb$}
    \FOR{$n\in [1:N]$}
    \STATE $\tilde{X}=[\fproc^1_t,\dots,\fproc^{i-1}_t,n,\fproc^{i+1}_t,\dots,\fproc^{M}_t]$
    \STATE $\hat{H}+=T\sigma(t)\left(K\left(\scorefn(\fproc_t)_{\tilde{X}}\right)+\ratio-\scorefn(\fproc_t)_{\tilde{X}}\log\left(\ratio\right)\right)$
    \ENDFOR
    \ENDFOR
    \RETURN $\hat{H}$
}
    \end{algorithmic}
\end{algorithm}

% Putting everything together, we can calculate the entropy of $\fp_0$ as $H(\fp_0) = \log N - \expected\left[\log\frac{\fp_0}{\fu_0}\right]$

