\clearpage
\setcounter{page}{1}
\maketitlesupplementary

\renewcommand{\thesection}{\Alph{section}}
\setcounter{section}{0}

\section*{Appendix}
\label{sec:appendix}

The supplementary material includes the following additional information:

\begin{itemize}
    \item \secref{sec:sup_hyper} details the hyper-parameters used for \modelname.
    \item \secref{sec:speed} provides a comprehensive speed comparison.
    \item \secref{sec:limitation} discusses the limitations and future directions.
    \item \secref{sec:sup_vis} presents visualization samples generated by \modelname.
\end{itemize}

\section{Hyper-parameters for \modelname}
\label{sec:sup_hyper}
We list the detailed training and inference hyper-parameters in~\tabref{tab:hparams}.

\begin{table}[h!]
\centering

\tablestyle{5.0pt}{1.1}
\begin{tabular}{l|c}
config \quad\quad\quad\quad\quad\quad\quad\quad & value \\
\hline
optimizer & AdamW~\cite{kingma2014adam,loshchilov2017decoupled} \\
optimizer momentum & (0.9, 0.96) \\
weight decay & 0.02 \\
batch size & 2048 \\
learning rate schedule & cosine decay \\
peak learning rate & 4e-4 \\
ending learning rate & 1e-5 \\
total epochs & 800 \\
warmup epochs & 100 \\
dropout rate & 0.1 \\
attn dropout rate & 0.1 \\
class label dropout rate & 0.1 \\
inference mode & SDE \\
inference steps & 50 \\
\end{tabular}
\caption{\textbf{Detailed Hyper-parameters of \modelname Models.}
}
\label{tab:hparams}
\end{table}

\section{Speed Comparison.}
We compare \modelname with diffusion-, flow matching-, and autoregressive-based models in~\tabref{tab:sampling_speed}. Our most lightweight variant, \modelname-B (172M), outperforms DiT-XL (diffusion-based), SiT-XL (flow matching-based), and MAR (autoregressive-based), while achieving a 20$\times$ speedup (9.8 \vs \ 0.5 images/sec).
Additionally, \modelname-L surpasses the recent state-of-the-art model REPA, running 5.3$\times$ faster (3.2 \vs \ 0.6 images/sec).
Finally, our largest model, \modelname-H, achieves 1.24 FID on ImageNet-256, setting a new state-of-the-art, while still running 2.2$\times$ faster than REPA.

\label{sec:speed}
\begin{table}
\centering
\tablestyle{3.0pt}{1.05}
\begin{tabular}{c|ccccc}
method & type & \#params & FID$\downarrow$ & steps & images/sec \\
\shline
DiT-XL/2~\cite{dit} & Diff. & 675M & 2.27 & 250 & 0.5 \\
SiT-XL/2~\cite{sit} & Flow. & 675M & 2.02 & 250 & 0.5 \\
MAR-L~\cite{mar} & AR & 479M & 1.78 & 256 & 0.5 \\
\modelname-B &xAR&172M&1.72 &50&9.8\\
\hline
MAR-H~\cite{mar} & MAR & 943M & 1.55 & 256 & 0.3 \\
REPA~\cite{yu2024representation} & Flow. &675M& 1.42 & 250 & 0.6 \\
\modelname-L &xAR&608M&1.28 &50&3.2 \\
\hline
\modelname-H &xAR&1.1B&1.24&50&1.3 \\
\end{tabular}
\caption{\textbf{Sampling Throughput Comparison.} Throughputs are evaluated as samples generated per second on a single A100 based on their official codebases.
}
\label{tab:sampling_speed}
\end{table}


\section{Discussion and Limitations}
\label{sec:limitation}
Our empirical evaluations indicate that a square 8$\times$8 cell configuration achieves the best performance, with no noticeable difference when using rectangular cells (\eg, $k/2\times 2k$ or $2k\times k/2$), which introduce additional complexity without clear benefits.
Given that different regions in an image contain varying levels of semantic information (\eg, dense object areas \vs \ uniform sky regions), future research could explore whether dynamically shaped prediction entities provide additional benefits. However, in this work, we adopt a simple yet effective square cell design, demonstrating state-of-the-art results on the challenging ImageNet generation benchmark.



\section{Visualization of Generated Samples}
\label{sec:sup_vis}

Additional visualization results generated by \modelname-H are provided from~\figref{fig:22} to~\figref{fig:980}.

\begin{figure}[!h]
    \centering
    \includegraphics[width=\linewidth]{figures/22.pdf}
    \caption{\textbf{Generated Samples from \modelname.} \modelname is able to generate high-fidelity American eagle (22) images.}
    \label{fig:22}
\end{figure}

\begin{figure}
    \centering
    \includegraphics[width=\linewidth]{figures/88.pdf}
    \caption{\textbf{Generated Samples from \modelname.} \modelname is able to generate high-fidelity macaw (88) images.
    }
    \label{fig:88}
\end{figure}

\begin{figure}
    \centering
    \includegraphics[width=\linewidth]{figures/207.pdf}
    \caption{\textbf{Generated Samples from \modelname.} \modelname is able to generate high-fidelity golden retriever (207) images.}
    \label{fig:207}
\end{figure}

\begin{figure}
    \centering
    \includegraphics[width=\linewidth]{figures/360.pdf}
    \caption{\textbf{Generated Samples from \modelname.} \modelname is able to generate high-fidelity otter (360) images.}
    \label{fig:360}
\end{figure}

\begin{figure}
    \centering
    \includegraphics[width=\linewidth]{figures/387.pdf}
    \caption{\textbf{Generated Samples from \modelname.} \modelname is able to generate high-fidelity lesser panda (387) images.}
    \label{fig:387}
\end{figure}

\begin{figure}
    \centering
    \includegraphics[width=\linewidth]{figures/973.pdf}
    \caption{\textbf{Generated Samples from \modelname.} \modelname is able to generate high-fidelity coral reef (973) images.}
    \label{fig:973}
\end{figure}


\begin{figure}
    \centering
    \includegraphics[width=\linewidth]{figures/974.pdf}
    \caption{\textbf{Generated Samples from \modelname.} \modelname is able to generate high-fidelity geyser (974) images.}
    \label{fig:974}
\end{figure}


\begin{figure}
    \centering
    \includegraphics[width=\linewidth]{figures/979.pdf}
    \caption{\textbf{Generated Samples from \modelname.} \modelname is able to generate high-fidelity valley (979) images.}
    \label{fig:979}
\end{figure}


\begin{figure}
    \centering
    \includegraphics[width=\linewidth]{figures/980.pdf}
    \caption{\textbf{Generated Samples from \modelname.} \modelname is able to generate high-fidelity volcano (980) images.}
    \label{fig:980}
\end{figure}



