\section{Related Work}
\noindent\textbf{AR Modeling in NLP.}
Autoregressive language models~\cite{llama,gpt,gpt3,gpt4,chatgpt} have driven significant progress toward general-purpose AI. Their core principle is simple yet powerful: predicting the next token based on preceding context. This approach has demonstrated impressive scalability, guided by scaling laws, and adaptability, enabling zero-shot generalization. These strengths have extended AR modeling beyond traditional language tasks, influencing a wide range of modalities.

\noindent\textbf{AR Modeling in Vision.}
Inspired by the success of AR modeling in NLP, researchers have explored its application in vision~\cite{var,llamagen,igpt,pixelcnn,parti,yu2024randomized,vqvae2}. A pioneering effort in this direction was PixelCNN~\cite{pixelcnn}, which factorized the joint pixel distribution into a product of conditionals, enabling the model to learn complex image distributions. This idea was further refined in PixelRNN~\cite{pixelrnn}, which incorporated recurrent layers to capture richer context in both horizontal and vertical directions. iGPT~\cite{igpt} extended this pixel-level approach by leveraging Transformers~\cite{vaswani2017attention} for next-pixel prediction.
Beyond next-pixel modeling, AR methods have shifted toward more abstract token representations. VQ-VAE~\cite{vqvae} introduced discrete latent codes that could be modeled autoregressively, offering a compressed yet expressive representation of images. Later models like Parti~\cite{parti} and LlamaGen~\cite{llamagen} combined these learned tokens with Transformer-based architectures to generate high-fidelity images while maintaining scalable training.
Recently, MAR~\cite{mar} introduced a diffusion-based approach~\cite{song2019generative,diff2} to model per-token probability distributions in a continuous space, replacing categorical cross-entropy with a diffusion loss. VAR~\cite{var} extended next-token prediction to a coarse-to-fine scale prediction paradigm, progressively refining image details.
Our work unifies these approaches under a general next-X prediction framework, where X can flexibly represent tokens, scales, or our newly introduced cells, providing a more flexible and generalizable formulation for autoregressive visual modeling.

\noindent\textbf{Diffusion and Flow Matching.}
Beyond autoregressive modeling, diffusion~\cite{song2019generative,diff2,diff3} and flow matching~\cite{liu2022flow,lipman2022flow,sd3} have surpassed Generative Adversarial Networks (GANs)~\cite{gan,stylegan-xl} by employing multi-step denoising.
Latent Diffusion Models (LDMs)~\cite{ldm} improve speed and scalability by operating in a compressed latent space~\cite{vae} instead of raw pixels. Building on this, DiT~\cite{dit} and U-ViT~\cite{uvit} replace the traditional convolution-based U-Net~\cite{unet} with Transformers~\cite{vaswani2017attention} in latent space, further enhancing performance. Simple Diffusion~\cite{diff1,hoogeboom2024simpler} introduces a streamlined approach for scaling pixel-space diffusion models to high-resolution outputs, while DiMR~\cite{liu2024alleviating} progressively refines features across multiple scales, improving detail from low to high resolution.
In parallel, flow matching~\cite{liu2022flow,lipman2022flow} reformulates the generative process by directly mapping data distributions to a standard normal distribution, simplifying the transition from noise to structured data. SiT~\cite{sit} builds on this by integrating flow matching into DiTâ€™s Transformer backbone for more efficient distribution alignment. Extending this approach, SD3~\cite{sd3} introduces a Transformer-based architecture that leverages flow matching for text-to-image generation. REPA~\cite{yu2024representation} refines denoising by aligning noisy intermediate states with clean image embeddings extracted from pretrained visual encoders~\cite{dinov2}.
