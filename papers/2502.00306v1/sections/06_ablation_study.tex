\subsection{Ablation Study}
\label{sec:ablation}
Here we evaluate the impact of varying the number of queries made by our attack to the RAG (\Cref{sec:ablation_n}), as well as the impact of the number of documents retrieved as context by the RAG system (\Cref{sec:ablation_k}).

\begin{figure}
    \centering
    \includegraphics[width=0.9\linewidth]{figs/auc_vs_num_questions.pdf}
    \caption{Changes in attack performance (AUC) for our attack as the number of questions ($n$) increases, when the RAG's generator is LLaMA 3.1. We observe improvement in performance across all three datasets.}

    \label{fig:num_questions}
\end{figure}

\subsubsection{Number of Questions (\texorpdfstring{$n$}{n})}
\label{sec:ablation_n}
While we use 30 questions as the default for our attack, we vary this number ($n$) to understand its impact on attack inference.
Our evaluations show that the number of questions significantly impacts the attack AUC, with more questions improving performance. As shown in \Cref{fig:num_questions}, increasing the number of questions consistently results in higher AUC values, across all three datasets. Notably, with just 5 questions, the AUC of our attack outperforms the baselines. However, we observe diminishing returns at higher question counts, with AUC improvement stabilizing at a saturation point. This suggests that while adding more questions generally enhances performance, the marginal benefit reduces as the number of questions increases.

\begin{figure*}[t]
    \centering
    \begin{subfigure}[t]{0.32\textwidth}
        \centering
        \includegraphics[width=\textwidth]{figs/auc_vs_k_nfcorpus.pdf}
    \end{subfigure}
    \begin{subfigure}[t]{0.32\textwidth}
        \centering
        \includegraphics[width=\textwidth]{figs/auc_vs_k_scidocs.pdf}
    \end{subfigure}
    \begin{subfigure}[t]{0.32\textwidth}
        \centering
        \includegraphics[width=\textwidth]{figs/auc_vs_k_trec-covid.pdf}
    \end{subfigure}
    
    \caption{AUC for different numbers of retrieved documents ($k$) across three attacks: S$^2$MIA, MBA, and IA (Ours), when the RAG's generator is LLaMA 3.1. Each plot corresponds to one dataset. Performance drops with increasing $k$, but our attack consistently outperforms prior works.}
    \label{fig:number_retrieved_docs}
\end{figure*}

\subsubsection{Number of Retrieved Documents (\texorpdfstring{$k$}{k})}
\label{sec:ablation_k}

While our attack demonstrates robustness across different retrievers and generator models, certain other aspects of a RAG system, such as the number of documents retrieved as context ($k$), are not under the adversary's control. This optimal value of $k$ can vary across different tasks and datasets. While we set this hyperparameter to 3 in our experiments, we conduct an ablation study to examine the effect of the number of retrieved documents (\(k\)) on the attack AUCs. As shown in \Cref{fig:number_retrieved_docs}, increasing the number of retrieved documents generally decreases the attack's performance. This drop may result from the RAG generator's difficulty in handling longer contexts, as more retrieved documents increase the input length for the generator. Despite this decline, our attack consistently outperforms the baselines across all values of \(k\). It is worth noting that we excluded RAG-MIA from this study, as it does not produce AUC scores for direct comparison.


