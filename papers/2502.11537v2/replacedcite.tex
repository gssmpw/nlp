\section{Related Work}
\paragraph{Offline Multi-Modal Methods}
Large-scale token-based sequence models for modeling and generating multi-modal trajectories of agent experience were proposed in ____.
In Gato ____ and TDM ____, multi-modal inputs are first tokenized through predefined transformations, while in Unified IO ____ pretrained models are also used.
The produced tokens are then embedded and processed by the sequence model, similarly to \AlgName{}.
% Importantly, image embeddings are learned jointly with the world model, while in our method the optimization is separated.
Importantly, these methods do not learn control through RL.
Instead, they learn from expert data.
In addition, these methods use large models with billions of parameters, large vocabulary sizes, and orders-of-magnitude more data and compute compared to sample efficient world models.
Hence, it is unclear whether the design choices of these methods would be effective in an online sample-efficiency setting, where the data is non-stationary and strictly limited.
% Unified-IO ____ (not RL). 
% Gato ____ and TDM ____ do not learn control, only imitation from expert data.
% These methods use large models with billions of parameters and are not designed to adapt in online dynamic environments.
% In the context of multi-modal token-based framework, these methods use large vocabulary sizes as they as not limited to a fixed budget.
% It is the other way around, they can afford massive amounts of data and compute.
% In addition, there is no explicit interface for handling general mixed-modality inputs.
% In addition, offline methods often fail catastrophically when encountering out-of-distribution data, which is common in any complex environment.
% These methods provide no evidence regarding the potential of the multi-modal token-based model in an online learning setting and under limited data and compute budgets (sample efficiency). 



%%%% ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
\begin{figure}[t]
    \centering
    \includegraphics[width=\linewidth]{figures/craftax_results.pdf}
    \caption{Craftax-1M training curves with mean and 95\% confidence intervals. }
    \label{fig:craftax-main-results}
\end{figure}
%%%% ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~





\paragraph{World Model Agents}
Model-based RL agents where the policy is learned exclusively from simulated data generated by the learned world model were originally proposed by ____.
Later, a line of works proposed the popular Dreamer algorithms ____.
To learn dynamics, Dreamer's objective involves a Kullbackâ€“Leibler (KL) divergence term between its learned prior and posterior estimators, effectively coupling the optimization of the representation model and the recurrent neural network world model.
This design leads to a complex monolithic system that poses challenges for development and scaling.

Following the success of the Transformer architecture ____ in language modeling ____, Transformer-based variants of Dreamer ____ were proposed.
In addition, token-based world models (TBWMs), which represent trajectories as language-like token sequences, were proposed ____.
Notably, the evaluation of these methods is limited to the Atari 100K benchmark.
% Moreover, it is unclear how to extend TBWMs to support continuous inputs effectively. 

Recently, motivated by the success of diffusion generative models ____, DIAMOND ____, a diffusion-based world model agent was proposed.
Although it produces visually compelling outputs, it is currently limited to visual environments.



% Lastly, planning-based world models were proposed ____, demonstrating state-of-the-art performance on sample efficiency benchmarks.
% However, these methods are compute intensive, often requiring multiple GPUs for a single training run.
% In addition, current methods only model the rewards and return dynamics, while not modeling observation dynamics.
% This limits their generality, as downstream tasks 







%%%% ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
\begin{figure}[t]
    \centering

% \subfigure[first caption.]{\includegraphics[width=0.48\textwidth]{figures/ablations_atari_summary.pdf}}
% \subfigure[first caption.]{\includegraphics[width=0.48\textwidth]{figures/ablations_dmc_summary.pdf}}
    
\begin{subfigure}[b]{\linewidth}
   \includegraphics[width=\linewidth]{figures/ablations_atari_summary.pdf}
   \caption{Atari 100K}
   \label{fig:ablations-atari}
\end{subfigure}
\vskip 0.1in
\begin{subfigure}[b]{\linewidth}
   \includegraphics[width=\linewidth]{figures/ablations_dmc_summary.pdf}
   \caption{DeepMind Control Suite Proprioception 500K}
   \label{fig:ablations-dmc}
\end{subfigure}
    
    % \vspace{-20pt}
    \caption{Ablations results on the Atari-100K (top) and DeepMind Control Proprioception 500K (bottom) benchmarks. A subset of 8 games was used for each ablation.}
    \label{fig:ablations-results}
\end{figure}
%%%% ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~





\paragraph{Large Video World Models}
Following recent advances in video generative modeling ____, a recent body of work proposed large video world models ____.
These methods are trained offline on massive pre-collected data to predict future video frames.
However, these methods do not involve control learning, and RL in particular.
% Specifically, no RL is used.
% Consequently, there is no evidence to support the effectiveness of these methods in online RL settings. 
% These methods are not suitable for online RL settings since they are prone to failure when encountering out-of-distribution data due to their offline nature.
% Moreover, for such settings, their high computational demands make them impractical for most research labs.
% Due to their offline nature, these methods are prone to failure when encountering out-of-distribution data, while also impractical for online learning applications due to their high computational demands.
% For a comprehensive overview of world models and recent advances, we refer interested readers to____.


% \paragraph{Model-Free Sample-Efficient Methods}
% BBF