\section{Related work}
Spectral reconstruction bridges the gap between hyperspectral and multispectral imaging by enhancing spectral granularity. Early methods, such as dictionary-based approaches \cite{arad-2016} and Gaussian processes \cite{akhtar-2018}, relied on handcrafted priors but were limited in capturing non-linear spectral-spatial relationships. With the rise of deep learning, convolutional neural networks (CNNs) \cite{galliani-2017, Xiong_2017_ICCV} and attention-based transformers \cite{cai-2021} have emerged as effective tools, leveraging data-driven learning to improve reconstruction accuracy. Recent approaches, such as hybrid attention networks \cite{zheng-2021}, emphasize combining spatial and spectral attention for enhanced reconstruction quality. 

Self-supervised learning (SSL) frameworks, like masked autoencoders (MAE) \cite{mae}, naturally align with spectral reconstruction by leveraging large-scale unlabeled datasets to predict missing spectral information \cite{hackstein2024}. In hyperspectral remote sensing, studies such as \cite{linus2023SST} have demonstrated the effectiveness of self-supervised masked image reconstruction for adapting transformers to the unique characteristics of hyperspectral data. By integrating spatial-spectral self-attention, spectral positional embeddings, and blockwise patch embeddings, these models achieve significant accuracy improvements, particularly in label-scarce scenarios. Building on these insights, our work further explores spectral reconstruction with self-supervised transformers tailored for hyperspectral imagery.