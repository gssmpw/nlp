\section{Related work}
Spectral reconstruction bridges the gap between hyperspectral and multispectral imaging by enhancing spectral granularity. Early methods, such as dictionary-based approaches ____ and Gaussian processes ____, relied on handcrafted priors but were limited in capturing non-linear spectral-spatial relationships. With the rise of deep learning, convolutional neural networks (CNNs) ____ and attention-based transformers ____ have emerged as effective tools, leveraging data-driven learning to improve reconstruction accuracy. Recent approaches, such as hybrid attention networks ____, emphasize combining spatial and spectral attention for enhanced reconstruction quality. 

Self-supervised learning (SSL) frameworks, like masked autoencoders (MAE) ____, naturally align with spectral reconstruction by leveraging large-scale unlabeled datasets to predict missing spectral information ____. In hyperspectral remote sensing, studies such as ____ have demonstrated the effectiveness of self-supervised masked image reconstruction for adapting transformers to the unique characteristics of hyperspectral data. By integrating spatial-spectral self-attention, spectral positional embeddings, and blockwise patch embeddings, these models achieve significant accuracy improvements, particularly in label-scarce scenarios. Building on these insights, our work further explores spectral reconstruction with self-supervised transformers tailored for hyperspectral imagery.