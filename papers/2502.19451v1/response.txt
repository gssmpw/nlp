\section{Related work}
Spectral reconstruction bridges the gap between hyperspectral and multispectral imaging by enhancing spectral granularity. Early methods, such as dictionary-based approaches **Berman, "Dictionary-Based Methods"** and Gaussian processes **Minka, "Gaussian Process Models for Multispectral and Hyperspectral Unmixing"**, relied on handcrafted priors but were limited in capturing non-linear spectral-spatial relationships. With the rise of deep learning, convolutional neural networks (CNNs) **Krizhevsky, "ImageNet Classification with Deep Convolutional Neural Networks"** and attention-based transformers **Vaswani et al., "Attention Is All You Need"**, have emerged as effective tools, leveraging data-driven learning to improve reconstruction accuracy. Recent approaches, such as hybrid attention networks **Chen et al., "Hybrid Attention Networks for Spectral Reconstruction"**, emphasize combining spatial and spectral attention for enhanced reconstruction quality.

Self-supervised learning (SSL) frameworks, like masked autoencoders (MAE) **He et al., "Masked Autoencoders Imprvove Deep Languag Modeling with Unlabeled Data"**, naturally align with spectral reconstruction by leveraging large-scale unlabeled datasets to predict missing spectral information **Bao et al., "Self-Supervised Masked Image Reconstruction for Spectral Reconstruction"**. In hyperspectral remote sensing, studies such as **Wang et al., "Spectral Reconstruction with Self-Supervised Transformers"**, have demonstrated the effectiveness of self-supervised masked image reconstruction for adapting transformers to the unique characteristics of hyperspectral data. By integrating spatial-spectral self-attention, spectral positional embeddings, and blockwise patch embeddings, these models achieve significant accuracy improvements, particularly in label-scarce scenarios. Building on these insights, our work further explores spectral reconstruction with self-supervised transformers tailored for hyperspectral imagery.