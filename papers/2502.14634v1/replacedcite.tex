\section{Related Work}
\subsection{Reasoning in LLMs}

Recent research has explored various techniques to enhance the reasoning capabilities of LLMs. CoT prompting ____ improves multi-step reasoning by generating structured intermediate steps, leading to more transparent and interpretable solutions. Self-consistency ____ further enhances accuracy by sampling multiple reasoning paths and selecting the most consistent answer. In parallel, question decomposition methods ____ improve coherence by breaking complex queries into simpler sub-questions, though it introduces additional computational overhead. Another promising direction involves search and planning-based methods ____, which systematically explore multiple reasoning trajectories to improve problem-solving. Lastly, integrating external tools—such as web search engines and Python interpreters—extends the model’s capabilities, enabling more precise and efficient task execution across diverse domains ____.
As our approach is grounded in uncertainty estimation, we begin by reviewing existing uncertainty estimation methods, followed by an introduction to uncertainty-aware reasoning techniques, which are the most pertinent to our research.

\subsection{Uncertainty Estimation}
Uncertainty estimation methods can be broadly classified into two categories: black-box ____ and white-box ____ approaches. One approach to uncertainty estimation is training-based confidence estimation ____, which improves calibration by incorporating uncertainty estimation directly into the training process. These methods modify the training objective, introduce auxiliary loss functions, or leverage additional supervision to produce more reliable confidence estimates. 
%A notable example is uncertainty-aware pretraining, such as IDK-tuning ____, which incorporates an explicit [IDK] token into the model’s vocabulary. During continued pretraining, the model learns to allocate probability mass to this token, enabling it to express uncertainty when lacking sufficient knowledge for confident predictions. 
Another approach is verbal-based confidence estimation ____, which prompts the model to explicitly express its confidence through natural language statements. 
%By leveraging LLMs ability to self-assess uncertainty, these methods allow for direct human interpretation of self-verbalized confidence scores. 
Finally, semantic-based uncertainty estimation methods ____ cluster outputs or reasoning chains that are semantically equivalent, quantifying uncertainty based on the variability of responses within these clusters.

\subsection{Uncertainty-aware reasoning}
An emerging trend leverages uncertainty estimation as a tool to enhance various components of reasoning. One application is in improving few-shot prompting, where uncertainty estimation helps automate the selection of demonstrations ____, reducing the need for manually intensive prompt engineering. Another key contribution of uncertainty estimation in reasoning is its role in selecting the most reliable reasoning chain based on confidence ____. In such cases, uncertainty acts as a guiding signal, identifying the chain where the model exhibits the highest confidence. Our approach builds on this intuition by enabling a weighted voting mechanism to select the final answer. More importantly, instead of applying our uncertainty estimation function to every token, we focus only on critical tokens, specifically the intermediate answers in a CoT chain.

% Another contribution of uncertainty estimation in reasoning is its role in directly enhancing accuracy. 
%Specifically, CoT-decoding ____ leverages uncertainty to identify the reasoning path by considering only the final answer phrase in the generated text without requiring CoT prompting. In contrast, our method guides the LLM to generate multi-step reasoning paths while exploring different uncertainty estimation functions for both step-wise and path-wise aggregation to determine the optimal configuration. More precisely, while CoT-decoding focuses on achieving CoTs without needing a CoT prompt, we propose a confidence-based weighing of paths which takes into account critical points throughout the entire chain.