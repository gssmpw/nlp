Our research identifies the limitation of existing unlearning benchmarks, which have not explored the interconnectedness of knowledge. To overcome this issue, we define \textit{superficial unlearning} and propose a new benchmark, \ourdata, for evaluating generalization, multi-hop knowledge unlearning, and shortcut unlearning.
Using this benchmark, we empirically demonstrate that existing unlearning methods are vulnerable to superficial unlearning.
Furthermore, we propose a novel knowledge-localized unlearning method, \ourmodel, and demonstrate that it outperforms existing unlearning methods, effectively mitigating superficial unlearning.
Our paper first illuminates the phenomenon of superficial unlearning and raises a new research question for a deeper analysis of the unlearning field.
