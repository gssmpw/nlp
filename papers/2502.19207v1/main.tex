% This must be in the first 5 lines to tell arXiv to use pdfLaTeX, which is strongly recommended.
\pdfoutput=1
% In particular, the hyperref package requires pdfLaTeX in order to break URLs across lines.

\documentclass[11pt]{article}

% Remove the "review" option to generate the final version.
\usepackage{acl} % 

% Standard package includes
\usepackage{times}
\usepackage{latexsym}

% For proper rendering and hyphenation of words containing Latin characters (including in bib files)
\usepackage[T1]{fontenc}
% For Vietnamese characters
% \usepackage[T5]{fontenc}
% See https://www.latex-project.org/help/documentation/encguide.pdf for other character sets

% This assumes your files are encoded as UTF8
\usepackage[utf8]{inputenc}

% This is not strictly necessary, and may be commented out,
% but it will improve the layout of the manuscript,
% and will typically save some space.
\usepackage{microtype}

% This is also not strictly necessary, and may be commented out.
% However, it will improve the aesthetics of text in
% the typewriter font.
\usepackage{inconsolata}
\usepackage{enumitem}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{subcaption}
\usepackage{multirow}
\usepackage{graphicx,tabularx}
\usepackage{caption}
\usepackage{booktabs}
\usepackage{algorithm}
\usepackage{algorithmic}
\usepackage{xcolor}
\usepackage{newfloat}
\usepackage{listings}
\usepackage{url}
\usepackage{makecell}
% \usepackage{amsart}

\usepackage{xcolor,colortbl}
\usepackage{tabularray}

\DeclareMathOperator*{\argmax}{arg\,max}

\definecolor{myred}{RGB}{255,90,90}
\definecolor{myblue}{RGB}{90,90,255}

\newcommand\blue{\cellcolor{blue!35}}
\newcommand\red{\cellcolor{red!35}}
\newcommand\bluew{\cellcolor{blue!10}}
\newcommand\redw{\cellcolor{red!10}}


\newcommand{\ourdata}{\textsc{FaithUn}}
\newcommand{\ourmodel}{KLUE}


% If the title and author information does not fit in the area allocated, uncomment the following
%
%\setlength\titlebox{<dim>}
%
% and set <dim> to something 5cm or larger.


% \title{Knowledge-localized Unlearning for Faithful Forgetting in LLMs}
\title{\ourdata: Toward Faithful Forgetting in Language Models by Investigating the Interconnectedness of Knowledge}
% \title{\ourdata: Toward Faithful Forgetting in Language Models via the Investigation of Knowledge Interconnections}

% Assessing and Enhancing Faithful Forgetting of Language Models via Analysis of Superficial Unlearning

% FaithUn: Assessing and Enhancing Faithful Forgetting in Language Models
% MUSE: Machine Unlearning Six-Way Evaluation for Language Models
% RWKU: Benchmarking Real-World Knowledge Unlearning for Large Language Models
% The WMDP Benchmark: Measuring and Reducing Malicious Use With Unlearning
% TOFU: A Task of Fictitious Unlearning for LLMs
% MQuAKE: Assessing Knowledge Editing in Language Models via Multi-Hop Questions


\author{Nakyeong Yang$^{1}$, Minsung Kim$^{1}$, Seunghyun Yoon$^{2}$, Joongbo Shin$^{3}$ and Kyomin Jung$^{1}$ \\
  $^{1}$Seoul National University,
  $^{2}$Adobe Research,
  $^{3}$LG AI Research
  \\
  \texttt{\{yny0506, kms0805, kjung\}@snu.ac.kr}\\
  \texttt{syoon@adobe.com,}
  \texttt{jb.shin@lgresearch.ai}
  }

\begin{document}
\maketitle

\input{texts/abstract}

\section{Introduction}
\input{texts/intro}

% \section{Related Works}
\section{Unlearning in Large Language Models}
\input{texts/background}

\section{The \ourdata~Benchmark}
\input{texts/benchmark}

\section{Method: KLUE}
\input{texts/methods}

\section{Experiments}
\input{texts/experiments}

\section{Conclusion}
\input{texts/conclusion}

\section*{Limitations}
\input{texts/limitations}

\section*{Ethical Considerations}
\input{texts/ethics}

% \section*{Acknowledgements}
% \input{texts/ack}

\bibliography{custom}

\appendix
\input{texts/appendix}


\end{document}
