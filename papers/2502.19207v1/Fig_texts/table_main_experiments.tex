\begin{table}[t]
\centering
\vspace{-0.2cm}
\resizebox{\linewidth}{!}
{
\begin{tabular}{@{}c|cccc|cc@{}}
\toprule
Method & UA$^{\ddagger}$ ($\downarrow$) & TA ($\uparrow$) & SA ($\uparrow$) & MA ($\uparrow$) & Score ($\uparrow$) \\ \midrule
Default & 81.82 & 85.99 & 79.63 & 48.67 & - \\\cmidrule{1-6}
GA & 36.02 & 48.92 & 37.19 & 48.34 & 49.61 \\
GA$_{ret}$ & \textbf{34.01} & 77.58 & 66.51 & 53.21 & 65.82 \\
DPO$_{rej}$ & 41.75 & 68.96 & 63.58 & 49.67 & 60.11 \\
DPO$_{mis}$ & 37.03 & 65.01 & 51.69 & 52.89 & 58.14 \\
NPO & 38.72 & 60.84 & 52.77 & 49.50 & 56.10 \\
RMU & 46.12 & 79.02 & 67.74 & 53.05 & 63.42 \\\cmidrule{1-6} 
% \ourmodel$_{\text{RMU}}$ & 42.76 & 77.58 & 68.67 & 54.89 & 64.60 \\
\ourmodel & 36.70 & \textbf{82.97} & \textbf{74.69} & \textbf{58.16} & \textbf{69.78} \\

\bottomrule 



\end{tabular}
}
% \vspace{-0.1cm}
\vspace{-0.2cm}
\caption{
\textbf{\textbf{Gemma-2 (2B) experimental results.}} We report the results of four metrics after unlearning the forget set (5\%) in our settings. Bolded results indicate the best performance. We compute the accuracy over three trials and report the average accuracy.}
\label{table_gemma}
\end{table}