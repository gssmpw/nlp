\begin{table}[h]
\centering
\resizebox{\linewidth}{!}
{
\begin{tabular}{@{}cc|c|ccc|cc@{}}
\toprule
Model & Method & UA$^{\ddagger}$ ($\downarrow$) & TA ($\uparrow$) & SA ($\uparrow$) & MA ($\uparrow$) & Score ($\uparrow$) \\ \midrule

\multirow{6}{*}{\makecell{Llama-3.2 \\ (3B)} } & Default \rule{0pt}{2.5ex} & 90.91 & 87.28 & 85.65 & 50.57 & - \\\cmidrule{2-7}
\text{} & GA & \textbf{35.35} & 54.52 & 39.19 & 52.45 & 52.70 \\
\text{} & GA$_{ret}$ & 48.14 & 68.24 & 57.71 & 53.94 & 57.94 \\
\text{} & DPO$_{rej}$ & 46.80 & 69.68 & 55.86 & \textbf{54.02} & 58.19 \\
\text{} & DPO$_{mis}$ & 36.02 & 64.87 & 43.21 & 51.56 & 55.91 \\\cmidrule{2-7}
\text{} & \ourmodel & 45.79 & \textbf{77.58} & \textbf{65.12} & 53.99 & \textbf{62.73} \\
\bottomrule\bottomrule

\multirow{7}{*}{\makecell{Gemma-2 \\ (9B)} } & Default & 91.92 & 89.87 & 86.57 & 48.07 & - \\\cmidrule{2-7}
& GA & \textbf{29.29} & 40.52 & 30.56 & 50.46 & 48.06 \\
& GA$_{ret}$ & 45.45 & 83.84 & 68.52 & 50.72 & 64.40 \\
& DPO$_{rej}$ & 41.41 & 75.32 & 59.72 & 47.02 & 60.16 \\
& DPO$_{mis}$ & 36.36 & 63.15 & 43.06 & 55.45 & 56.32 \\\cmidrule{2-7} 
& \ourmodel & 40.40 & \textbf{89.83} & \textbf{81.48} & \textbf{60.48} & \textbf{72.85} \\
\bottomrule


\end{tabular}
}
\caption{
\textbf{\textbf{Llama-3.2 (3B) and Gemma-2 (9B) experimental results.}} We report the results of four metrics after unlearning the forget set (5\%) in our settings. Bolded results indicate the best performance.}
\label{table_extended}
\end{table}
