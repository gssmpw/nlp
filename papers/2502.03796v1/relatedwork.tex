\section{Related Work}
As large-scale high performance computing (HPC) systems evolve, power and energy efficiency have become critical priorities~\cite{DOE_goal}. 
Previous research has explored techniques such as CPU core Dynamic Voltage and Frequency Scaling (DVFS), CPU power capping, and memory DVFS to investigate the trade-offs between application performance and energy conservation \cite{ramesh2019understanding,walker2018hardware,wallace2016application,bailey2015finding,freeh2005using,ge2007cpu,hsu2005power,lim2006adaptive,rountree2007bounding, DRAM_FREQ, lefurgy2008power,petoumenos2015power,borghesi2015power}. 

Since the Sandy Bridge generation, Intel processors have enabled autonomous DVFS adjustments by modifying clock speeds and voltage dynamically, independent of software-specified settings \cite{intel-p-state,intel-p-state-2,dvfs}. Intelâ€™s RAPL interface provides mechanisms for monitoring energy consumption and setting power limits in various CPU and DRAM domains\cite{david2010rapl,khan2018rapl}. Users can access RAPL data through model-specific registers (MSRs), \textit{sysfs} interface \cite{sysfs}, \textit{perf} \cite{perf} events, or the PAPI library \cite{weaver2012measuring}. 

\begin{figure}
    \centering
    \includegraphics[width=0.8\linewidth]{figures/results/multi-gpu-saving.png}
    \caption{Multi-GPU results on Intel+4A100. The X-axis lists the benchmarks, while the Y-axis shows the corresponding metrics achieved by MAGUS and UPS against the baseline.}
    \label{fig:saving_multi_gpu}
    \vspace{-10pt}
\end{figure}

\begin{figure}
    \centering
    \includegraphics[width=0.8\linewidth]{figures/results/multi-gpu-active-saving.png}
    \caption{Active power and energy saving on Intel+4A100. Here, active power denotes the actual power consumption that a workload contributes.}
    \label{fig:multi-gpu-active-saving}
    \vspace{-5pt}
\end{figure}

With the increasing use of GPUs in HPC systems, power management has become an active research area. NVIDIA provides the NVIDIA Management Library (NVML), which enables users to control GPU power limits, core frequencies, and memory frequencies via the nvidia-smi interface \cite{NVML,nvidia-smi}. Significant efforts have been dedicated to modeling power and performance for GPU applications \cite{kandiah2021accelwattch,guerreiro2018gpgpu,arunkumar2019understanding,krzywaniak2020performance,guerreiro2019dvfs}. Research has also explored the impact of GPU core DVFS \cite{guerreiro2019dvfs,kraljic2022energy,fan2019predictable,ali2023performance} and GPU memory DVFS \cite{wang2020gpgpu} on energy efficiency in GPU workloads. 
Additionally, extensive studies are presented to optimize energy efficiency of deep learning training and inferences \cite{reguero2025energy,rajput2024benchmarking,panda2016conditional,8942147,you2023zeus}. 

Uncore frequency scaling has received relatively little attention in research and can be broadly classified into model-based and model-free approaches. In model-based approaches \cite{sundriyal2018core, zhang2024fcufs}, analytical or machine learning models predict optimal uncore frequencies by monitoring multiple hardware counters in real-time. For instance, Sundriyal et al. \cite{sundriyal2018core} develop power and performance models to adjust the uncore frequency for optimal power efficiency during application execution. Zhang et al. \cite{zhang2024fcufs} train a neural network to predict application performance and power consumption, leveraging multi-objective optimization to minimize power usage while limiting performance loss.
In contrast, model-free approaches \cite{gholkar2019uncore, guermouche2022combining} bypass complex models by dynamically detecting phase transitions between compute-intensive and memory-intensive regions to guide uncore frequency scaling. UPScavenger \cite{gholkar2019uncore} is a pioneering model-free solution that monitors multiple hardware counters to adjust uncore frequency based on workload phases.