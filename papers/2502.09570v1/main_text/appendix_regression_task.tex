\section{Additional GNN results}
\label{appendix:additional_results}

We include additional results with graph-level and hypergraph-level encodings on the Mutag dataset with GCN and GPS (Tab.~\ref{tab:mutag}) and on the social networks Collab, Imdb, and Reddit using GIN (Tab.~ \ref{tab:gin_selected}).

\begin{table*}[ht!]
\centering
\footnotesize
\begin{tabular}{|l|c|c|}
\hline
\textbf{Model (Encodings)} & \textbf{GCN} & \textbf{GPS} \\
\hline
No Encoding & $65.96 \pm 1.76$ & $80.40 \pm 1.53$ \\ \hline
LCP-FRC & $67.04 \pm 1.49$ & $83.94 \pm 2.06$ \\
LCP-ORC & $83.09 \pm 1.71$ & $84.93 \pm 1.82$ \\
19-RWPE & $71.75 \pm 2.08$ & $80.13 \pm 1.65$ \\
20-LAPE & $73.30 \pm 1.95$ & $82.27 \pm 1.57$ \\
\hline
HCP-FRC & $80.85 \pm 1.77$ & $\mathbf{89.36 \pm 1.68}$ \\
EE H-19-RWPE & $\mathbf{85.32 \pm 1.63}$ & $88.65 \pm 2.24$ \\
EN H-19-RWPE & $82.34 \pm 2.68$ & $88.49 \pm 2.12$ \\
Hodge H-20-LAPE & $83.66 \pm 1.90$ & $86.72 \pm 1.96$ \\
Norm. H-20-LAPE & $81.68 \pm 1.79$ & $86.90 \pm 1.81$ \\
\hline
\end{tabular}
\caption{GCN and GPS performance on the Mutag dataset with various graph and hypergraph encodings. We report mean and standard deviation across 50 runs.}
\label{tab:mutag}
\end{table*}


\begin{table*}[ht!]
\centering
\footnotesize
\begin{tabular}{|l|c|c|c|}
\hline
\textbf{Model (Encodings)} & \textbf{Collab} ($\uparrow$) & \textbf{Imdb} ($\uparrow$) & \textbf{Reddit} ($\uparrow$) \\
\hline
GIN (No Encoding)          & $67.44 \pm 1.13$ & $67.12 \pm 1.36$ & $75.38 \pm 1.27$ \\ \hline
GIN (LCP-FRC)              & $71.96 \pm 1.30$ & $70.18 \pm 1.44$ & $69.66 \pm 1.62$\\
GIN (LCP-ORC)              & $\mathbf{72.60 \pm 1.28}$ & $\mathbf{70.64 \pm 1.32}$ & $\mathbf{87.19 \pm 1.56}$\\
GIN (19-RWPE)                 & $71.76 \pm 1.34$ & $69.35 \pm 2.24$ & $74.40 \pm 1.68$ \\
GIN (20-LAPE)                 & $71.52 \pm 1.26$ & $68.16 \pm 2.83$ & $75.84 \pm 1.65$ \\
\hline
GIN (HCP-FRC)              & $71.44 \pm 1.46$ & $70.40 \pm 1.52$ & $70.53 \pm 1.48$ \\
GIN (HCP-ORC)              & $72.18 \pm 1.37$ & $69.92 \pm 1.50$ & $84.82 \pm 1.62$ \\
GIN (EE H-19-RWPE)            & $72.08 \pm 1.40$ & $70.23 \pm 1.78$ & $77.87 \pm 1.49$ \\
GIN (EN H-19-RWPE)            & $72.32 \pm 1.42$ & $70.53 \pm 1.80$ & $77.46 \pm 1.53$ \\
GIN (Hodge H-20-LAPE)         & $72.16 \pm 1.39$ & $69.37 \pm 1.65$ & $79.94 \pm 1.81$\\
GIN (Norm. H-20-LAPE)         & $71.95 \pm 1.35$ & $69.48 \pm 1.71$ & $79.15 \pm 1.54$\\
\hline
\end{tabular}
\caption{GIN performance with selected graph-level encodings (top) and hypergraph level encodings (bottom). We report mean and standard deviation across 50 runs for the Collab, Imdb, and Reddit datasets.}
\label{tab:gin_selected}
\end{table*}