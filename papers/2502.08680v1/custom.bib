% Use this file for citations not found in the ACL Anthology (contained in "anthology.bib").

@book{Aho:72,
    author  = {Alfred V. Aho and Jeffrey D. Ullman},
    title   = {The Theory of Parsing, Translation and Compiling},
    year    = "1972",
    volume  = "1",
    publisher = {Prentice-Hall},
    address = {Englewood Cliffs, NJ}
}

@book{APA:83,
    author  = {{American Psychological Association}},
    title   = {Publications Manual},
    year    = "1983",
    publisher = {American Psychological Association},
    address = {Washington, DC}
}

@article{Chandra:81,
	author = {Ashok K. Chandra and Dexter C. Kozen and Larry J. Stockmeyer},
	year = "1981",
	title = {Alternation},
	journal = {Journal of the Association for Computing Machinery},
	volume = "28",
	number = "1",
	pages = "114--133",
	doi = "10.1145/322234.322243",
}

@inproceedings{andrew2007scalable,
  title={Scalable training of {L1}-regularized log-linear models},
  author={Andrew, Galen and Gao, Jianfeng},
  booktitle={Proceedings of the 24th International Conference on Machine Learning},
  pages={33--40},
  year={2007},
}

@book{Gusfield:97,
    author  = {Dan Gusfield},
    title   = {Algorithms on Strings, Trees and Sequences},
    year    = "1997",
    publisher = {Cambridge University Press},
    address = {Cambridge, UK}
}

@article{rasooli-tetrault-2015,
    author    = {Mohammad Sadegh Rasooli and Joel R. Tetreault},
    title     = {Yara Parser: {A} Fast and Accurate Dependency Parser},
    journal   = {Computing Research Repository},
    volume    = {arXiv:1503.06733},
    year      = {2015},
    url       = {http://arxiv.org/abs/1503.06733},
    note    = {version 2}
}

@article{Ando2005,
	Acmid = {1194905},
	Author = {Ando, Rie Kubota and Zhang, Tong},
	Issn = {1532-4435},
	Issue_Date = {12/1/2005},
	Journal = {Journal of Machine Learning Research},
	Month = dec,
	Numpages = {37},
	Pages = {1817--1853},
	Publisher = {JMLR.org},
	Title = {A Framework for Learning Predictive Structures from Multiple Tasks and Unlabeled Data},
	Volume = {6},
	Year = {2005}
}

@inproceedings{ahn2024,
    title = "Large Language Models for Mathematical Reasoning: Progresses and Challenges",
    author = "Ahn, Janice  and
      Verma, Rishu  and
      Lou, Renze  and
      Liu, Di  and
      Zhang, Rui  and
      Yin, Wenpeng",
    editor = "Falk, Neele  and
      Papi, Sara  and
      Zhang, Mike",
    booktitle = "Proceedings of the 18th Conference of the European Chapter of the Association for Computational Linguistics: Student Research Workshop",
    month = mar,
    year = "2024",
    address = "St. Julian{'}s, Malta",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2024.eacl-srw.17",
    pages = "225--237",
    abstract = "Mathematical reasoning serves as a cornerstone for assessing the fundamental cognitive capabilities of human intelligence. In recent times, there has been a notable surge in the development of Large Language Models (LLMs) geared towards the automated resolution of mathematical problems. However, the landscape of mathematical problem types is vast and varied, with LLM-oriented techniques undergoing evaluation across diverse datasets and settings. This diversity makes it challenging to discern the true advancements and obstacles within this burgeoning field. This survey endeavors to address four pivotal dimensions: i) a comprehensive exploration of the various mathematical problems and their corresponding datasets that have been investigated; ii) an examination of the spectrum of LLM-oriented techniques that have been proposed for mathematical problem-solving; iii) an overview of factors and concerns affecting LLMs in solving math; and iv) an elucidation of the persisting challenges within this domain. To the best of our knowledge, this survey stands as one of the first extensive examinations of the landscape of LLMs in the realm of mathematics, providing a holistic perspective on the current state, accomplishments, and future challenges in this rapidly evolving field.",
}

@misc{openai2024-gpt4,
      title={GPT-4 Technical Report}, 
      author={OpenAI},
      year={2024},
      eprint={2303.08774},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2303.08774}, 
}
@misc{madaan2022-50percent,
      title={Text and Patterns: For Effective Chain of Thought, It Takes Two to Tango}, 
      author={Aman Madaan and Amir Yazdanbakhsh},
      year={2022},
      eprint={2209.07686},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2209.07686}, 
}


@misc{cobbe2021-gsm8k,
      title={Training Verifiers to Solve Math Word Problems}, 
      author={Karl Cobbe and Vineet Kosaraju and Mohammad Bavarian and Mark Chen and Heewoo Jun and Lukasz Kaiser and Matthias Plappert and Jerry Tworek and Jacob Hilton and Reiichiro Nakano and Christopher Hesse and John Schulman},
      year={2021},
      eprint={2110.14168},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2110.14168}, 
}

@inproceedings{hendrycks2021-MATH,
  title={Measuring Mathematical Problem Solving With the MATH Dataset},
  author={Hendrycks, Dan and Burns, Collin and Kadavath, Saurav and Arora, Akul and Basart, Steven and Tang, Eric and Song, Dawn and Steinhardt, Jacob},
  booktitle={Advances in Neural Information Processing Systems},
  volume={34},
  pages={24241--24253},
  year={2021},
  url={https://arxiv.org/abs/2103.03874}
}


@misc{mirzadeh2024-gsmsymbolic,
      title={GSM-Symbolic: Understanding the Limitations of Mathematical Reasoning in Large Language Models}, 
      author={Iman Mirzadeh and Keivan Alizadeh and Hooman Shahrokhi and Oncel Tuzel and Samy Bengio and Mehrdad Farajtabar},
      year={2024},
      eprint={2410.05229},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2410.05229}, 
}

                
@article{gao2022-pal,
    title={PAL: Program-aided Language Models},
    author={Gao, Luyu and Madaan, Aman and Zhou, Shuyan and Alon, Uri and Liu, Pengfei and Yang, Yiming and Callan, Jamie and Neubig, Graham},
    journal={arXiv preprint arXiv:2211.10435},
    year={2022}
}

@misc{meta2024-llama3.2,
  title = {Llama 3.2: Connect 2024 - Vision for Edge and Mobile Devices},
  author = {{Meta AI}},
  year = {2024},
  url = {https://ai.meta.com/blog/llama-3-2-connect-2024-vision-edge-mobile-devices/},
  note = {Accessed: 2024-12-20}
}

@misc{google2024-gemma2,
      title={Gemma 2: Improving Open Language Models at a Practical Size}, 
      author={Morgane Riviere and Shreya Pathak and Pier Giuseppe Sessa and Cassidy Hardin and Surya Bhupatiraju and Léonard Hussenot and Thomas Mesnard and Bobak Shahriari and Alexandre Ramé and Johan Ferret and Peter Liu and Pouya Tafti and Abe Friesen and Michelle Casbon and Sabela Ramos and Ravin Kumar and Charline Le Lan and Sammy Jerome and Anton Tsitsulin and Nino Vieillard and Piotr Stanczyk and Sertan Girgin and Nikola Momchev and Matt Hoffman and Shantanu Thakoor and Jean-Bastien Grill and Behnam Neyshabur and Olivier Bachem and Alanna Walton and Aliaksei Severyn and Alicia Parrish and Aliya Ahmad and Allen Hutchison and Alvin Abdagic and Amanda Carl and Amy Shen and Andy Brock and Andy Coenen and Anthony Laforge and Antonia Paterson and Ben Bastian and Bilal Piot and Bo Wu and Brandon Royal and Charlie Chen and Chintu Kumar and Chris Perry and Chris Welty and Christopher A. Choquette-Choo and Danila Sinopalnikov and David Weinberger and Dimple Vijaykumar and Dominika Rogozińska and Dustin Herbison and Elisa Bandy and Emma Wang and Eric Noland and Erica Moreira and Evan Senter and Evgenii Eltyshev and Francesco Visin and Gabriel Rasskin and Gary Wei and Glenn Cameron and Gus Martins and Hadi Hashemi and Hanna Klimczak-Plucińska and Harleen Batra and Harsh Dhand and Ivan Nardini and Jacinda Mein and Jack Zhou and James Svensson and Jeff Stanway and Jetha Chan and Jin Peng Zhou and Joana Carrasqueira and Joana Iljazi and Jocelyn Becker and Joe Fernandez and Joost van Amersfoort and Josh Gordon and Josh Lipschultz and Josh Newlan and Ju-yeong Ji and Kareem Mohamed and Kartikeya Badola and Kat Black and Katie Millican and Keelin McDonell and Kelvin Nguyen and Kiranbir Sodhia and Kish Greene and Lars Lowe Sjoesund and Lauren Usui and Laurent Sifre and Lena Heuermann and Leticia Lago and Lilly McNealus and Livio Baldini Soares and Logan Kilpatrick and Lucas Dixon and Luciano Martins and Machel Reid and Manvinder Singh and Mark Iverson and Martin Görner and Mat Velloso and Mateo Wirth and Matt Davidow and Matt Miller and Matthew Rahtz and Matthew Watson and Meg Risdal and Mehran Kazemi and Michael Moynihan and Ming Zhang and Minsuk Kahng and Minwoo Park and Mofi Rahman and Mohit Khatwani and Natalie Dao and Nenshad Bardoliwalla and Nesh Devanathan and Neta Dumai and Nilay Chauhan and Oscar Wahltinez and Pankil Botarda and Parker Barnes and Paul Barham and Paul Michel and Pengchong Jin and Petko Georgiev and Phil Culliton and Pradeep Kuppala and Ramona Comanescu and Ramona Merhej and Reena Jana and Reza Ardeshir Rokni and Rishabh Agarwal and Ryan Mullins and Samaneh Saadat and Sara Mc Carthy and Sarah Cogan and Sarah Perrin and Sébastien M. R. Arnold and Sebastian Krause and Shengyang Dai and Shruti Garg and Shruti Sheth and Sue Ronstrom and Susan Chan and Timothy Jordan and Ting Yu and Tom Eccles and Tom Hennigan and Tomas Kocisky and Tulsee Doshi and Vihan Jain and Vikas Yadav and Vilobh Meshram and Vishal Dharmadhikari and Warren Barkley and Wei Wei and Wenming Ye and Woohyun Han and Woosuk Kwon and Xiang Xu and Zhe Shen and Zhitao Gong and Zichuan Wei and Victor Cotruta and Phoebe Kirk and Anand Rao and Minh Giang and Ludovic Peran and Tris Warkentin and Eli Collins and Joelle Barral and Zoubin Ghahramani and Raia Hadsell and D. Sculley and Jeanine Banks and Anca Dragan and Slav Petrov and Oriol Vinyals and Jeff Dean and Demis Hassabis and Koray Kavukcuoglu and Clement Farabet and Elena Buchatskaya and Sebastian Borgeaud and Noah Fiedel and Armand Joulin and Kathleen Kenealy and Robert Dadashi and Alek Andreev},
      year={2024},
      eprint={2408.00118},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2408.00118}, 
}

@misc{jiang2023-mistral7b,
      title={Mistral 7B}, 
      author={Albert Q. Jiang and Alexandre Sablayrolles and Arthur Mensch and Chris Bamford and Devendra Singh Chaplot and Diego de las Casas and Florian Bressand and Gianna Lengyel and Guillaume Lample and Lucile Saulnier and Lélio Renard Lavaud and Marie-Anne Lachaux and Pierre Stock and Teven Le Scao and Thibaut Lavril and Thomas Wang and Timothée Lacroix and William El Sayed},
      year={2023},
      eprint={2310.06825},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2310.06825}, 
}

@misc{openai2024-gpt4o,
  title = {GPT-4o System Card},
  author = {{OpenAI}},
  year = {2024},
  url = {https://openai.com/index/gpt-4o-system-card/},
  note = {Published: August 8, 2024. Accessed: 2024-12-20}
}

@inproceedings{zhou2023-LTM,
  title={Least-to-Most Prompting Enables Complex Reasoning in Large Language Models},
  author={Zhou, Denny and Sch{\"a}rli, Nathanael and Hou, Le and Wei, Jason and Scales, Nathan and Wang, Xuezhi and Schuurmans, Dale and Cui, Claire and Bousquet, Olivier and Le, Quoc and Chi, Ed H.},
  booktitle={International Conference on Learning Representations},
  year={2023},
  url={https://arxiv.org/abs/2205.10625}
}

@misc{deng2023-RaR,
  title={Rephrase and Respond: Let Large Language Models Ask Better Questions for Themselves},
  author={Deng, Yihe and Zhang, Weitong and Chen, Zixiang and Gu, Quanquan},
  year={2023},
  eprint={2311.04205},
  archivePrefix={arXiv},
  primaryClass={cs.CL},
  url={https://arxiv.org/abs/2311.04205}
}

@article{chen2023-PoT,
  title={Program of Thoughts Prompting: Disentangling Computation from Reasoning for Numerical Reasoning Tasks},
  author={Chen, Wenhu and Ma, Xueguang and Wang, Xinyi and Cohen, William W.},
  journal={Transactions on Machine Learning Research},
  year={2023},
  url={https://arxiv.org/abs/2211.12588}
}

@inproceedings{imani2023-mathprompter,
  title={MathPrompter: Mathematical Reasoning using Large Language Models},
  author={Imani, Shima and Du, Liang and Shrivastava, Harsh},
  booktitle={Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 5: Industry Track)},
  pages={37--42},
  year={2023},
  url={https://aclanthology.org/2023.acl-industry.4}
}

@inproceedings{wei2022-CoT,
  title={Chain-of-Thought Prompting Elicits Reasoning in Large Language Models},
  author={Wei, Jason and Wang, Xuezhi and Schuurmans, Dale and Bosma, Maarten and Ichter, Brian and Xia, Fei and Chi, Ed and Le, Quoc and Zhou, Denny},
  booktitle={Advances in Neural Information Processing Systems},
  volume={35},
  pages={24827--24837},
  year={2022},
  url={https://arxiv.org/abs/2201.11903}
}

@inproceedings{patel2021-SVAMP,
  title = "Are {NLP} Models really able to Solve Simple Math Word Problems?",
  author = "Patel, Arkil  and
    Bhattamishra, Satwik  and
    Goyal, Navin",
  booktitle = "Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies",
  month = jun,
  year = "2021",
  address = "Online",
  publisher = "Association for Computational Linguistics",
  url = "https://aclanthology.org/2021.naacl-main.168",
  doi = "10.18653/v1/2021.naacl-main.168",
  pages = "2080--2094",
}
@inproceedings{lu2024-mathvista,
  title={MathVista: Evaluating Mathematical Reasoning of Foundation Models in Visual Contexts},
  author={Lu, Pan and Bansal, Hritik and Xia, Tony and Liu, Jiacheng and Li, Chunyuan and Hajishirzi, Hannaneh and Cheng, Hao and Chang, Kai-Wei and Galley, Michel and Gao, Jianfeng},
  booktitle={International Conference on Learning Representations},
  year={2024},
  url={https://arxiv.org/abs/2310.02255}
}

@inproceedings{shi2023-GSMIC,
  title={Large Language Models Can Be Easily Distracted by Irrelevant Context},
  author={Shi, Freda and Chen, Xinyun and Misra, Kanishka and Scales, Nathan and Dohan, David and Chi, Ed and Sch{\"a}rli, Nathanael and Zhou, Denny},
  booktitle={Proceedings of the 40th International Conference on Machine Learning},
  volume={202},
  pages={31210--31227},
  year={2023},
  url={https://proceedings.mlr.press/v202/shi23a.html}
}

@inproceedings{zhang2024-GSM1K,
  title={A Careful Examination of Large Language Model Performance on Grade School Arithmetic},
  author={Zhang, Hugh and Da, Jeff and Lee, Dean and Robinson, Vaughn and Wu, Catherine and Song, Will and Zhao, Tiffany and Raja, Pranav and Zhuang, Charlotte and Slack, Dylan and Lyu, Qin and Hendryx, Sean and Kaplan, Russell and Lunati, Michele and Yue, Summer},
  booktitle={Advances in Neural Information Processing Systems},
  year={2024},
  url={https://arxiv.org/abs/2405.00332}
}

@inproceedings{li2024-gsmplus,
  title={GSM-Plus: A Comprehensive Benchmark for Evaluating the Robustness of LLMs as Mathematical Problem Solvers},
  author={Li, Qintong and Cui, Leyang and Zhao, Xueliang and Kong, Lingpeng and Bi, Wei},
  booktitle={Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
  pages={2961--2984},
  year={2024},
  url={https://aclanthology.org/2024.acl-long.163},
  doi={10.18653/v1/2024.acl-long.163}
}

@inproceedings{koncel2016-mawps,
  title = "{MAWPS}: A Math Word Problem Repository",
  author = {Koncel-Kedziorski, Rik and Roy, Subhro and Amini, Aida and Kushman, Nate and Hajishirzi, Hannaneh},
  booktitle = "Proceedings of the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies",
  month = jun,
  year = {2016},
  address = {San Diego, California},
  publisher = {Association for Computational Linguistics},
  pages = {1152--1157},
  url = {https://aclanthology.org/N16-1136},
  doi = {10.18653/v1/N16-1136}
}

@inproceedings{huang2024-selfcorrect,
  title = {Large Language Models Cannot Self-Correct Reasoning Yet},
  author = {Jie Huang and Xinyun Chen and Swaroop Mishra and Huaixiu Steven Zheng and Adams Wei Yu and Xinying Song and Denny Zhou},
  booktitle = {Proceedings of the International Conference on Learning Representations (ICLR)},
  year = {2024},
  url = {https://openreview.net/forum?id=IkmD3fKBPQ}
}

@inproceedings{zhang2024-small,
  title = {Small Language Models Need Strong Verifiers to Self-Correct Reasoning},
  author = {Yunxiang Zhang and Muhammad Khalifa and Lajanugen Logeswaran and Jaekyeom Kim and Moontae Lee and Honglak Lee and Lu Wang},
  booktitle = {Findings of the Association for Computational Linguistics: ACL 2024},
  pages = {15637--15653},
  year = {2024},
  address = {Bangkok, Thailand},
  publisher = {Association for Computational Linguistics},
  url = {https://aclanthology.org/2024.findings-acl.924},
  doi = {10.18653/v1/2024.findings-acl.924}
}

@inproceedings{jiang2024-peek,
  title = {A Peek into Token Bias: Large Language Models Are Not Yet Genuine Reasoners},
  author = {Bowen Jiang and Yangxinyu Xie and Zhuoqun Hao and Xiaomeng Wang and Tanwi Mallick and Weijie J. Su and Camillo J. Taylor and Dan Roth},
  booktitle = {Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing (EMNLP)},
  year = {2024},
  address = {Singapore},
  publisher = {Association for Computational Linguistics},
  url = {https://aclanthology.org/2024.emnlp-main.272},
  doi = {10.18653/v1/2024.emnlp-main.272}
}

@inproceedings{wu2024-reasoning,
  title = {Reasoning or Reciting? Exploring the Capabilities and Limitations of Language Models Through Counterfactual Tasks},
  author = {Zhaofeng Wu and Linlu Qiu and Alexis Ross and Ekin Akyürek and Boyuan Chen and Bailin Wang and Najoung Kim and Jacob Andreas and Yoon Kim},
  booktitle = {Proceedings of the 2024 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies},
  year = {2024},
  address = {New York, NY},
  publisher = {Association for Computational Linguistics},
  url = {https://aclanthology.org/2024.naacl-main.102},
  doi = {10.18653/v1/2024.naacl-main.102}
}
@article{nezhurina2024-alice,
  title={Alice in Wonderland: Simple Tasks Showing Complete Reasoning Breakdown in State-Of-the-Art Large Language Models},
  author={Marianna Nezhurina and Lucia Cipolina-Kun and Mehdi Cherti and Jenia Jitsev},
  journal={arXiv preprint arXiv:2406.02061},
  year={2024},
  url={https://arxiv.org/abs/2406.02061}
}

@inproceedings{wang2023-SCCoT,
  title = {Self-Consistency Improves Chain of Thought Reasoning in Language Models},
  author = {Xuezhi Wang and Jason Wei and Dale Schuurmans and Quoc Le and Ed Chi and Sharan Narang and Aakanksha Chowdhery and Denny Zhou},
  booktitle = {Proceedings of the International Conference on Learning Representations (ICLR)},
  year = {2023},
  url = {https://arxiv.org/abs/2203.11171}
}
@inproceedings{brown2020-fs1,
  title = {Language Models are Few-Shot Learners},
  author = {Tom B. Brown and Benjamin Mann and Nick Ryder and Melanie Subbiah and Jared Kaplan and Prafulla Dhariwal and Arvind Neelakantan and Pranav Shyam and Girish Sastry and Amanda Askell and Sandhini Agarwal and Ariel Herbert-Voss and Gretchen Krueger and Tom Henighan and Rewon Child and Aditya Ramesh and Daniel M. Ziegler and Jeffrey Wu and Clemens Winter and Christopher Hesse and Mark Chen and Eric Sigler and Mateusz Litwin and Scott Gray and Benjamin Chess and Jack Clark and Christopher Berner and Sam McCandlish and Alec Radford and Ilya Sutskever and Dario Amodei},
  booktitle = {Advances in Neural Information Processing Systems},
  volume = {33},
  pages = {1877--1901},
  year = {2020},
  url = {https://proceedings.neurips.cc/paper/2020/file/1457c0d6bfcb4967418bfb8ac142f64a-Paper.pdf}
}


@article{cobbe2021-fs2,
  title={Training Verifiers to Solve Math Word Problems},
  author={Cobbe, Karl and Kosaraju, Vineet and Bavarian, Mohammad and Hilton, Jacob and Nakano, Reiichiro and Hesse, Christopher and Schulman, John},
  journal={arXiv preprint arXiv:2110.14168},
  year={2021},
  url={https://arxiv.org/pdf/2110.14168}
}
@article{chowdhery2022-fs3,
  title={PaLM: Scaling Language Modeling with Pathways},
  author={Aakanksha Chowdhery and Sharan Narang and Jacob Devlin and Maarten Bosma and Gaurav Mishra and Adam Roberts and Paul Barham and Hyung Won Chung and Charles Sutton and Sebastian Gehrmann and Parker Schuh and Kensen Shi and Sasha Tsvyashchenko and Joshua Maynez and Abhishek Rao and Parker Barnes and Yi Tay and Noam Shazeer and Vinodkumar Prabhakaran and Emily Reif and Nan Du and Ben Hutchinson and Reiner Pope and James Bradbury and Jacob Austin and Michael Isard and Guy Gur-Ari and Pengcheng Yin and Toju Duke and Anselm Levskaya and Sanjay Ghemawat and Sunipa Dev and Henryk Michalewski and Xavier Garcia and Vedant Misra and Kevin Robinson and Liam Fedus and Denny Zhou and Daphne Ippolito and David Luan and Hyeontaek Lim and Barret Zoph and Alexander Spiridonov and Ryan Sepassi and David Dohan and Shivani Agrawal and Mark Omernick and Andrew M. Dai and Thanumalayan Sankaranarayana Pillai and Marie Pellat and Aitor Lewkowycz and Erica Moreira and Rewon Child and Oleksandr Polozov and Katherine Lee and Zongwei Zhou and Xuezhi Wang and Brennan Saeta and Mark Diaz and Orhan Firat and Michele Catasta and Jason Wei and Kathy Meier-Hellstern and Douglas Eck and Jeff Dean and Slav Petrov and Noah Fiedel},
  journal={arXiv preprint arXiv:2204.02311},
  year={2022},
  url={https://arxiv.org/abs/2204.02311}
}


@article{qwen2024technical,
  title={Qwen2.5 Technical Report},
  author={Qwen},
  journal={arXiv preprint arXiv:2412.15115},
  year={2024},
  url={https://arxiv.org/abs/2412.15115}
}
%  author={Qwen, An Yang and Baosong Yang and Beichen Zhang and Binyuan Hui and Bo Zheng and Bowen Yu and Chengyuan Li and Dayiheng Liu and Fei Huang and Haoran Wei and others},

@misc{openai2022chatgpt,
  author       = {OpenAI},
  title        = {Introducing ChatGPT},
  year         = {2022},
  url          = {https://openai.com/index/chatgpt/},
  note         = {Accessed: 2025-01-14}
}


@inproceedings{qian2023-arithmeticerror,
  title = {Limitations of Language Models in Arithmetic and Symbolic Induction},
  author = {Qian, Jing and Wang, Hong and Li, Zekun and Li, Shiyang and Yan, Xifeng},
  booktitle = {Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
  year = {2023},
  pages = {9285--9298},
  address = {Toronto, Canada},
  publisher = {Association for Computational Linguistics},
  url = {https://aclanthology.org/2023.acl-long.516/},
  doi = {10.18653/v1/2023.acl-long.516}
}

@article{shakarian2023eval,
  title = {An Independent Evaluation of ChatGPT on Mathematical Word Problems (MWP)},
  author = {Shakarian, Paulo and Koyyalamudi, Abhinav and Ngu, Noel and Mareedu, Lakshmivihari},
  journal = {arXiv preprint arXiv:2302.13814},
  year = {2023},
  url = {https://arxiv.org/abs/2302.13814}
}

@article{hong2024caught,
  title = {Caught in the Quicksand of Reasoning, Far from AGI Summit: Evaluating LLMs' Mathematical and Coding Competency through Ontology-guided Interventions},
  author = {Hong, Pengfei and Ghosal, Deepanway and Majumder, Navonil and Aditya, Somak and Mihalcea, Rada and Poria, Soujanya},
  journal = {arXiv preprint arXiv:2401.09395},
  year = {2024},
  url = {https://arxiv.org/abs/2401.09395}
}

@article{kumar2024investigating,
  title={Investigating Implicit Bias in Large Language Models: A Large-Scale Study of Over 50 LLMs},
  author={Kumar, Ananya and Jain, Siddharth},
  journal={arXiv preprint arXiv:2410.12864},
  year={2024},
  url={https://arxiv.org/abs/2410.12864}
}


@article{tjuatja2023do,
  title={Do LLMs Exhibit Human-like Response Biases? A Case Study in Survey Design},
  author={Tjuatja, Lindia and Chen, Valerie and Wu, Sherry Tongshuang and Talwalkar, Ameet and Neubig, Graham},
  journal={arXiv preprint arXiv:2311.04076},
  year={2023},
  url={https://arxiv.org/abs/2311.04076}
}

@article{feng2024numerical,
  title={How Numerical Precision Affects Mathematical Reasoning Capabilities of LLMs},
  author={Feng, Guhao and Yang, Kai and Gu, Yuntian and Ai, Xinyue and Luo, Shengjie and Sun, Jiacheng and He, Di and Li, Zhenguo and Wang, Liwei},
  journal={arXiv preprint arXiv:2410.13857},
  year={2024}
}

@article{xie2024llm,
  title={LLM-Resistant Math Word Problem Generation via Adversarial Attacks},
  author={Xie, Roy and Huang, Chengxuan and Wang, Junlin and Dhingra, Bhuwan},
  journal={arXiv preprint arXiv:2402.17916},
  year={2024}
}


@article{stolfo2022causal,
  title={A causal framework to quantify the robustness of mathematical reasoning with language models},
  author={Stolfo, Alessandro and Jin, Zhijing and Shridhar, Kumar and Sch{\"o}lkopf, Bernhard and Sachan, Mrinmaya},
  journal={arXiv preprint arXiv:2210.12023},
  year={2022}
}

@article{hooda2024large,
  title={Do large code models understand programming concepts? a black-box approach},
  author={Hooda, Ashish and Christodorescu, Mihai and Allamanis, Miltiadis and Wilson, Aaron and Fawaz, Kassem and Jha, Somesh},
  journal={arXiv preprint arXiv:2402.05980},
  year={2024}
}

@article{guo2024learning,
  title={Learning Beyond Pattern Matching? Assaying Mathematical Understanding in LLMs},
  author={Guo, Siyuan and Didolkar, Aniket and Ke, Nan Rosemary and Goyal, Anirudh and Husz{\'a}r, Ferenc and Sch{\"o}lkopf, Bernhard},
  journal={arXiv preprint arXiv:2405.15485},
  year={2024}
}

@article{fu2023chain,
  title={Chain-of-Thought Hub: A Continuous Effort to Measure Large Language Models' Reasoning Performance},
  author={Fu, Yao and Ou, Litu and Chen, Mingyu and Wan, Yuhao and Peng, Hao and Khot, Tushar},
  journal={arXiv preprint arXiv:2305.17306},
  year={2023}
}

@article{frieder2024mathematical,
  title={Mathematical capabilities of chatgpt},
  author={Frieder, Simon and Pinchetti, Luca and Griffiths, Ryan-Rhys and Salvatori, Tommaso and Lukasiewicz, Thomas and Petersen, Philipp and Berner, Julius},
  journal={Advances in neural information processing systems},
  volume={36},
  year={2024}
}

@article{schick2023toolformer,
  title={Toolformer: Language models can teach themselves to use tools},
  author={Schick, Timo and Dwivedi-Yu, Jane and Dess{\`\i}, Roberto and Raileanu, Roberta and Lomeli, Maria and Hambro, Eric and Zettlemoyer, Luke and Cancedda, Nicola and Scialom, Thomas},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  pages={68539--68551},
  year={2023}
}


@article{li2024evaluating,
  title={Evaluating Mathematical Reasoning of Large Language Models: A Focus on Error Identification and Correction},
  author={Li, Xiaoyuan and Wang, Wenjie and Li, Moxin and Guo, Junrong and Zhang, Yang and Feng, Fuli},
  journal={arXiv preprint arXiv:2406.00755},
  year={2024}
}

@misc{zeng2024mrgsm8kmetareasoningbenchmarklarge,
      title={MR-GSM8K: A Meta-Reasoning Benchmark for Large Language Model Evaluation}, 
      author={Zhongshen Zeng and Pengguang Chen and Shu Liu and Haiyun Jiang and Jiaya Jia},
      year={2024},
      eprint={2312.17080},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2312.17080}, 
}


@article{anand2024mathify,
  title={Mathify: Evaluating Large Language Models on Mathematical Problem Solving Tasks},
  author={Anand, Avinash and Gupta, Mohit and Prasad, Kritarth and Singla, Navya and Sanjeev, Sanjana and Kumar, Jatin and Shivam, Adarsh Raj and Shah, Rajiv Ratn},
  journal={arXiv preprint arXiv:2404.13099},
  year={2024}
}

@article{kao2024solving,
  title={Solving for X and Beyond: Can Large Language Models Solve Complex Math Problems with More-Than-Two Unknowns?},
  author={Kao, Kuei-Chun and Wang, Ruochen and Hsieh, Cho-Jui},
  journal={arXiv preprint arXiv:2407.05134},
  year={2024}
}

@article{yuan2023well,
  title={How well do large language models perform in arithmetic tasks?},
  author={Yuan, Zheng and Yuan, Hongyi and Tan, Chuanqi and Wang, Wei and Huang, Songfang},
  journal={arXiv preprint arXiv:2304.02015},
  year={2023}
}


@article{yang2023gpt,
  title={Gpt can solve mathematical problems without a calculator},
  author={Yang, Zhen and Ding, Ming and Lv, Qingsong and Jiang, Zhihuan and He, Zehai and Guo, Yuyi and Bai, Jinfeng and Tang, Jie},
  journal={arXiv preprint arXiv:2309.03241},
  year={2023}
}


@article{abedin2025arithmattack,
  title={ArithmAttack: Evaluating Robustness of LLMs to Noisy Context in Math Problem Solving},
  author={Abedin, Zain Ul and Qamar, Shahzeb and Flek, Lucie and Karimi, Akbar},
  journal={arXiv preprint arXiv:2501.08203},
  year={2025}
}

@article{henighan2020scaling,
  title={Scaling laws for autoregressive generative modeling},
  author={Henighan, Tom and Kaplan, Jared and Katz, Mor and Chen, Mark and Hesse, Christopher and Jackson, Jacob and Jun, Heewoo and Brown, Tom B and Dhariwal, Prafulla and Gray, Scott and others},
  journal={arXiv preprint arXiv:2010.14701},
  year={2020}
}


@article{maltoni2024arithmetic,
  title={Arithmetic with language models: From memorization to computation},
  author={Maltoni, Davide and Ferrara, Matteo},
  journal={Neural Networks},
  volume={179},
  pages={106550},
  year={2024},
  publisher={Elsevier}
}


@article{guo2025deepseek,
  title={Deepseek-r1: Incentivizing reasoning capability in llms via reinforcement learning},
  author={Guo, Daya and Yang, Dejian and Zhang, Haowei and Song, Junxiao and Zhang, Ruoyu and Xu, Runxin and Zhu, Qihao and Ma, Shirong and Wang, Peiyi and Bi, Xiao and others},
  journal={arXiv preprint arXiv:2501.12948},
  year={2025}
}

@misc{openai_o1,
  title = {Introducing {OpenAI} o1},
  author = {{OpenAI}},
  year = {2025},
  url = {https://openai.com/o1},
  note = {Accessed February 7, 2025}
}

@misc{openai_o3_mini,
  title = {Introducing {OpenAI} o3-mini},
  author = {{OpenAI}},
  year = {2025},
  url = {https://openai.com/index/openai-o3-mini/},
  note = {Accessed February 7, 2025}
}
