@article{abedin2025arithmattack,
  title={ArithmAttack: Evaluating Robustness of LLMs to Noisy Context in Math Problem Solving},
  author={Abedin, Zain Ul and Qamar, Shahzeb and Flek, Lucie and Karimi, Akbar},
  journal={arXiv preprint arXiv:2501.08203},
  year={2025}
}

@article{anand2024mathify,
  title={Mathify: Evaluating Large Language Models on Mathematical Problem Solving Tasks},
  author={Anand, Avinash and Gupta, Mohit and Prasad, Kritarth and Singla, Navya and Sanjeev, Sanjana and Kumar, Jatin and Shivam, Adarsh Raj and Shah, Rajiv Ratn},
  journal={arXiv preprint arXiv:2404.13099},
  year={2024}
}

@misc{cobbe2021-gsm8k,
      title={Training Verifiers to Solve Math Word Problems}, 
      author={Karl Cobbe and Vineet Kosaraju and Mohammad Bavarian and Mark Chen and Heewoo Jun and Lukasz Kaiser and Matthias Plappert and Jerry Tworek and Jacob Hilton and Reiichiro Nakano and Christopher Hesse and John Schulman},
      year={2021},
      eprint={2110.14168},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2110.14168}, 
}

@article{feng2024numerical,
  title={How Numerical Precision Affects Mathematical Reasoning Capabilities of LLMs},
  author={Feng, Guhao and Yang, Kai and Gu, Yuntian and Ai, Xinyue and Luo, Shengjie and Sun, Jiacheng and He, Di and Li, Zhenguo and Wang, Liwei},
  journal={arXiv preprint arXiv:2410.13857},
  year={2024}
}

@article{frieder2024mathematical,
  title={Mathematical capabilities of chatgpt},
  author={Frieder, Simon and Pinchetti, Luca and Griffiths, Ryan-Rhys and Salvatori, Tommaso and Lukasiewicz, Thomas and Petersen, Philipp and Berner, Julius},
  journal={Advances in neural information processing systems},
  volume={36},
  year={2024}
}

@article{fu2023chain,
  title={Chain-of-Thought Hub: A Continuous Effort to Measure Large Language Models' Reasoning Performance},
  author={Fu, Yao and Ou, Litu and Chen, Mingyu and Wan, Yuhao and Peng, Hao and Khot, Tushar},
  journal={arXiv preprint arXiv:2305.17306},
  year={2023}
}

@article{guo2024learning,
  title={Learning Beyond Pattern Matching? Assaying Mathematical Understanding in LLMs},
  author={Guo, Siyuan and Didolkar, Aniket and Ke, Nan Rosemary and Goyal, Anirudh and Husz{\'a}r, Ferenc and Sch{\"o}lkopf, Bernhard},
  journal={arXiv preprint arXiv:2405.15485},
  year={2024}
}

@article{hong2024caught,
  title = {Caught in the Quicksand of Reasoning, Far from AGI Summit: Evaluating LLMs' Mathematical and Coding Competency through Ontology-guided Interventions},
  author = {Hong, Pengfei and Ghosal, Deepanway and Majumder, Navonil and Aditya, Somak and Mihalcea, Rada and Poria, Soujanya},
  journal = {arXiv preprint arXiv:2401.09395},
  year = {2024},
  url = {https://arxiv.org/abs/2401.09395}
}

@article{hooda2024large,
  title={Do large code models understand programming concepts? a black-box approach},
  author={Hooda, Ashish and Christodorescu, Mihai and Allamanis, Miltiadis and Wilson, Aaron and Fawaz, Kassem and Jha, Somesh},
  journal={arXiv preprint arXiv:2402.05980},
  year={2024}
}

@inproceedings{jiang2024-peek,
  title = {A Peek into Token Bias: Large Language Models Are Not Yet Genuine Reasoners},
  author = {Bowen Jiang and Yangxinyu Xie and Zhuoqun Hao and Xiaomeng Wang and Tanwi Mallick and Weijie J. Su and Camillo J. Taylor and Dan Roth},
  booktitle = {Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing (EMNLP)},
  year = {2024},
  address = {Singapore},
  publisher = {Association for Computational Linguistics},
  url = {https://aclanthology.org/2024.emnlp-main.272},
  doi = {10.18653/v1/2024.emnlp-main.272}
}

@article{kao2024solving,
  title={Solving for X and Beyond: Can Large Language Models Solve Complex Math Problems with More-Than-Two Unknowns?},
  author={Kao, Kuei-Chun and Wang, Ruochen and Hsieh, Cho-Jui},
  journal={arXiv preprint arXiv:2407.05134},
  year={2024}
}

@inproceedings{li2024-gsmplus,
  title={GSM-Plus: A Comprehensive Benchmark for Evaluating the Robustness of LLMs as Mathematical Problem Solvers},
  author={Li, Qintong and Cui, Leyang and Zhao, Xueliang and Kong, Lingpeng and Bi, Wei},
  booktitle={Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
  pages={2961--2984},
  year={2024},
  url={https://aclanthology.org/2024.acl-long.163},
  doi={10.18653/v1/2024.acl-long.163}
}

@article{li2024evaluating,
  title={Evaluating Mathematical Reasoning of Large Language Models: A Focus on Error Identification and Correction},
  author={Li, Xiaoyuan and Wang, Wenjie and Li, Moxin and Guo, Junrong and Zhang, Yang and Feng, Fuli},
  journal={arXiv preprint arXiv:2406.00755},
  year={2024}
}

@misc{madaan2022-50percent,
      title={Text and Patterns: For Effective Chain of Thought, It Takes Two to Tango}, 
      author={Aman Madaan and Amir Yazdanbakhsh},
      year={2022},
      eprint={2209.07686},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2209.07686}, 
}

@article{maltoni2024arithmetic,
  title={Arithmetic with language models: From memorization to computation},
  author={Maltoni, Davide and Ferrara, Matteo},
  journal={Neural Networks},
  volume={179},
  pages={106550},
  year={2024},
  publisher={Elsevier}
}

@misc{mirzadeh2024-gsmsymbolic,
      title={GSM-Symbolic: Understanding the Limitations of Mathematical Reasoning in Large Language Models}, 
      author={Iman Mirzadeh and Keivan Alizadeh and Hooman Shahrokhi and Oncel Tuzel and Samy Bengio and Mehrdad Farajtabar},
      year={2024},
      eprint={2410.05229},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2410.05229}, 
}

@inproceedings{qian2023-arithmeticerror,
  title = {Limitations of Language Models in Arithmetic and Symbolic Induction},
  author = {Qian, Jing and Wang, Hong and Li, Zekun and Li, Shiyang and Yan, Xifeng},
  booktitle = {Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
  year = {2023},
  pages = {9285--9298},
  address = {Toronto, Canada},
  publisher = {Association for Computational Linguistics},
  url = {https://aclanthology.org/2023.acl-long.516/},
  doi = {10.18653/v1/2023.acl-long.516}
}

@article{schick2023toolformer,
  title={Toolformer: Language models can teach themselves to use tools},
  author={Schick, Timo and Dwivedi-Yu, Jane and Dess{\`\i}, Roberto and Raileanu, Roberta and Lomeli, Maria and Hambro, Eric and Zettlemoyer, Luke and Cancedda, Nicola and Scialom, Thomas},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  pages={68539--68551},
  year={2023}
}

@article{shakarian2023eval,
  title = {An Independent Evaluation of ChatGPT on Mathematical Word Problems (MWP)},
  author = {Shakarian, Paulo and Koyyalamudi, Abhinav and Ngu, Noel and Mareedu, Lakshmivihari},
  journal = {arXiv preprint arXiv:2302.13814},
  year = {2023},
  url = {https://arxiv.org/abs/2302.13814}
}

@inproceedings{shi2023-GSMIC,
  title={Large Language Models Can Be Easily Distracted by Irrelevant Context},
  author={Shi, Freda and Chen, Xinyun and Misra, Kanishka and Scales, Nathan and Dohan, David and Chi, Ed and Sch{\"a}rli, Nathanael and Zhou, Denny},
  booktitle={Proceedings of the 40th International Conference on Machine Learning},
  volume={202},
  pages={31210--31227},
  year={2023},
  url={https://proceedings.mlr.press/v202/shi23a.html}
}

@article{stolfo2022causal,
  title={A causal framework to quantify the robustness of mathematical reasoning with language models},
  author={Stolfo, Alessandro and Jin, Zhijing and Shridhar, Kumar and Sch{\"o}lkopf, Bernhard and Sachan, Mrinmaya},
  journal={arXiv preprint arXiv:2210.12023},
  year={2022}
}

@article{xie2024llm,
  title={LLM-Resistant Math Word Problem Generation via Adversarial Attacks},
  author={Xie, Roy and Huang, Chengxuan and Wang, Junlin and Dhingra, Bhuwan},
  journal={arXiv preprint arXiv:2402.17916},
  year={2024}
}

@article{yang2023gpt,
  title={Gpt can solve mathematical problems without a calculator},
  author={Yang, Zhen and Ding, Ming and Lv, Qingsong and Jiang, Zhihuan and He, Zehai and Guo, Yuyi and Bai, Jinfeng and Tang, Jie},
  journal={arXiv preprint arXiv:2309.03241},
  year={2023}
}

@article{yuan2023well,
  title={How well do large language models perform in arithmetic tasks?},
  author={Yuan, Zheng and Yuan, Hongyi and Tan, Chuanqi and Wang, Wei and Huang, Songfang},
  journal={arXiv preprint arXiv:2304.02015},
  year={2023}
}

@misc{zeng2024mrgsm8kmetareasoningbenchmarklarge,
      title={MR-GSM8K: A Meta-Reasoning Benchmark for Large Language Model Evaluation}, 
      author={Zhongshen Zeng and Pengguang Chen and Shu Liu and Haiyun Jiang and Jiaya Jia},
      year={2024},
      eprint={2312.17080},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2312.17080}, 
}

