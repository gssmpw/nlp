@article{malladi2023fine,
  title={Fine-tuning language models with just forward passes},
  author={Malladi, Sadhika and Gao, Tianyu and Nichani, Eshaan and Damian, Alex and Lee, Jason D and Chen, Danqi and Arora, Sanjeev},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  pages={53038--53075},
  year={2023}
}
@article{spsa_cite,
  title={Multivariate stochastic approximation using a simultaneous perturbation gradient approximation},
  author={Spall, James C},
  journal={IEEE transactions on automatic control},
  volume={37},
  number={3},
  pages={332--341},
  year={1992},
  publisher={IEEE}
}

@article{decomfl_cite,
  title={Achieving Dimension-Free Communication in Federated Learning via Zeroth-Order Optimization},
  author={Li, Zhe and Ying, Bicheng and Liu, Zidong and Dong, Chaosheng and Yang, Haibo},
  journal={arXiv preprint arXiv:2405.15861},
  year={2024}
}
@article{fang2022communication,
  title={Communication-efficient stochastic zeroth-order optimization for federated learning},
  author={Fang, Wenzhi and Yu, Ziyi and Jiang, Yuning and Shi, Yuanming and Jones, Colin N and Zhou, Yong},
  journal={IEEE Transactions on Signal Processing},
  volume={70},
  pages={5058--5073},
  year={2022},
  publisher={IEEE}
}

@article{baffle,
  title={Does federated learning really need backpropagation},
  author={Feng, Haozhe and Pang, Tianyu and Du, Chao and Chen, Wei and Yan, Shuicheng and Lin, Min},
  journal={arXiv preprint arXiv:2301.12195},
  year={2023},
  publisher={May}
}

@inproceedings {FwdLLM,
author = {Mengwei Xu and Dongqi Cai and Yaozong Wu and Xiang Li and Shangguang Wang},
title = {{FwdLLM}: Efficient Federated Finetuning of Large Language Models with Perturbed Inferences},
booktitle = {2024 USENIX Annual Technical Conference (USENIX ATC 24)},
year = {2024},
pages = {579--596},
}

@article{spry_cite,
  title={Thinking Forward: Memory-Efficient Federated Finetuning of Language Models},
  author={Panchal, Kunjal and Parikh, Nisarg and Choudhary, Sunav and Zhang, Lijun and Brun, Yuriy and Guan, Hui},
  journal={arXiv preprint arXiv:2405.15551},
  year={2024}
}



@inproceedings{sst2_cite,
  title={Recursive deep models for semantic compositionality over a sentiment treebank},
  author={Socher, Richard and Perelygin, Alex and Wu, Jean and Chuang, Jason and Manning, Christopher D and Ng, Andrew Y and Potts, Christopher},
  booktitle={Proceedings of the 2013 conference on empirical methods in natural language processing},
  pages={1631--1642},
  year={2013}
}


@inproceedings{boolq_cite,
    title = "{B}ool{Q}: Exploring the Surprising Difficulty of Natural Yes/No Questions",
    author = "Clark, Christopher  and
      Lee, Kenton  and
      Chang, Ming-Wei  and
      Kwiatkowski, Tom  and
      Collins, Michael  and
      Toutanova, Kristina",
    
    booktitle = "Proceedings of the 2019 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)",
    month = jun,
    year = "2019",
    address = "Minneapolis, Minnesota",
    publisher = "Association for Computational Linguistics",
    doi = "10.18653/v1/N19-1300",
    pages = "2924--2936",
}

@inproceedings{wic_cite,
    title = "{W}i{C}: the Word-in-Context Dataset for Evaluating Context-Sensitive Meaning Representations",
    author = "Pilehvar, Mohammad Taher  and
      Camacho-Collados, Jose",
    booktitle = "Proceedings of the 2019 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)",
    month = jun,
    year = "2019",
    address = "Minneapolis, Minnesota",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/N19-1128",
    doi = "10.18653/v1/N19-1128",
    pages = "1267--1273",
}

@inproceedings{rte_cite,
    title = "A large annotated corpus for learning natural language inference",
    author = "Bowman, Samuel R.  and
      Angeli, Gabor  and
      Potts, Christopher  and
      Manning, Christopher D.",
    editor = "M{\`a}rquez, Llu{\'\i}s  and
      Callison-Burch, Chris  and
      Su, Jian",
    booktitle = "Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing",
    month = sep,
    year = "2015",
    address = "Lisbon, Portugal",
    publisher = "Association for Computational Linguistics",
    doi = "10.18653/v1/D15-1075",
    pages = "632--642",
}

@article{opt_cite,
  title={Opt: Open pre-trained transformer language models},
  author={Zhang, Susan and Roller, Stephen and Goyal, Naman and Artetxe, Mikel and Chen, Moya and Chen, Shuohui and Dewan, Christopher and Diab, Mona and Li, Xian and Lin, Xi Victoria and others},
  journal={arXiv preprint arXiv:2205.01068},
  year={2022}
}


% KILIAN
@article{shi2020communication,
  title={Communication-efficient edge AI: Algorithms and systems},
  author={Shi, Yuanming and Yang, Kai and Jiang, Tao and Zhang, Jun and Letaief, Khaled B},
  journal={IEEE Communications Surveys \& Tutorials},
  volume={22},
  number={4},
  pages={2167--2191},
  year={2020},
  publisher={IEEE}
}

@article{thakker2019compressing,
  title={Compressing rnns for iot devices by 15-38x using kronecker products},
  author={Thakker, Urmish and Beu, Jesse and Gope, Dibakar and Zhou, Chu and Fedorov, Igor and Dasika, Ganesh and Mattina, Matthew},
  journal={arXiv:1906.02876},
  year={2019}
}

@InProceedings{alam2022fedrolex,
  author={Alam, Samiul and Liu, Luyang and Yan, Ming and Zhang, Mi},
  title={FedRolex: Model-Heterogeneous Federated Learning with Rolling Sub-Model Extraction},
  booktitle={Advances in Neural Information Processing Systems},
  volume={35},
  pages={29677--29690},
  year={2022}
}

@Article{caldas2018expanding,
  author        = {Caldas, Sebastian and Kone{\v{c}}ny, Jakub and McMahan, H Brendan and Talwalkar, Ameet},
  title         = {Expanding the reach of federated learning by reducing client resource requirements},
  journal       = {arXiv:1812.07210},
  year          = {2018},
}

@inproceedings{wang2022progfed,
  title={ProgFed: effective, communication, and computation efficient federated learning by progressive training},
  author={Wang, Hui-Po and Stich, Sebastian and He, Yang and Fritz, Mario},
  booktitle={International Conference on Machine Learning},
  pages={23034--23054},
  year={2022},
  organization={PMLR}
}

@inproceedings{pfeiffer2023successive,
 author = {Pfeiffer, Kilian and Khalili, Ramin and Henkel, Joerg},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {A. Oh and T. Naumann and A. Globerson and K. Saenko and M. Hardt and S. Levine},
 pages = {35386--35402},
 publisher = {Curran Associates, Inc.},
 title = {Aggregating Capacity in FL through Successive Layer Training for Computationally-Constrained Devices},
 volume = {36},
 year = {2023}
}

@inproceedings{
babakniya2023slora,
title={{SL}o{RA}: Federated Parameter Efficient Fine-Tuning of Language Models},
author={Sara Babakniya and Ahmed Elkordy and Yahya Ezzeldin and Qingfeng Liu and Kee-Bong Song and MOSTAFA EL-Khamy and Salman Avestimehr},
booktitle={International Workshop on Federated Learning in the Age of Foundation Models in Conjunction with NeurIPS 2023},
year={2023},
}

@article{roberta_cite,
  title={Roberta: A robustly optimized bert pretraining approach},
  author={Liu, Yinhan},
  journal={arXiv preprint arXiv:1907.11692},
  volume={364},
  year={2019}
}

@inproceedings{hu2022lora,
title={Lo{RA}: Low-Rank Adaptation of Large Language Models},
author={Edward J Hu and Yelong Shen and Phillip Wallis and Zeyuan Allen-Zhu and Yuanzhi Li and Shean Wang and Lu Wang and Weizhu Chen},
booktitle={International Conference on Learning Representations},
year={2022},
}

@inproceedings{gao-etal-2021-making,
    title = "Making Pre-trained Language Models Better Few-shot Learners",
    author = "Gao, Tianyu  and
      Fisch, Adam  and
      Chen, Danqi",
    editor = "Zong, Chengqing  and
      Xia, Fei  and
      Li, Wenjie  and
      Navigli, Roberto",
    booktitle = "Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)",
    month = aug,
    year = "2021",
    publisher = "Association for Computational Linguistics",

}



@inproceedings{blackbox_1,
 author = {Nikolakakis, Konstantinos and Haddadpour, Farzin and Kalogerias, Dionysis and Karbasi, Amin},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {S. Koyejo and S. Mohamed and A. Agarwal and D. Belgrave and K. Cho and A. Oh},
 pages = {31525--31541},
 publisher = {Curran Associates, Inc.},
 title = {Black-Box Generalization: Stability of Zeroth-Order Learning},
 volume = {35},
 year = {2022}
}

@inproceedings{blackbox_2,
  title={A zeroth-order block coordinate descent algorithm for huge-scale black-box optimization},
  author={Cai, HanQin and Lou, Yuchen and McKenzie, Daniel and Yin, Wotao},
  booktitle={International Conference on Machine Learning},
  pages={1193--1203},
  year={2021},
  organization={PMLR}
}
@inproceedings{mcmahan2017communication,
  title={Communication-efficient learning of deep networks from decentralized data},
  author={McMahan, Brendan and Moore, Eider and Ramage, Daniel and Hampson, Seth and y Arcas, Blaise Aguera},
  booktitle={Artificial intelligence and statistics},
  pages={1273--1282},
  year={2017},
  organization={PMLR}
}

@article{baydin2022gradients,
  title={Gradients without backpropagation},
  author={Baydin, At{\i}l{\i}m G{\"u}ne{\c{s}} and Pearlmutter, Barak A and Syme, Don and Wood, Frank and Torr, Philip},
  journal={arXiv preprint arXiv:2202.08587},
  year={2022}
}

@article{pfeiffer2023federated,
  title={Federated learning for computationally constrained heterogeneous devices: A survey},
  author={Pfeiffer, Kilian and Rapp, Martin and Khalili, Ramin and Henkel, J{\"o}rg},
  journal={ACM Computing Surveys},
  volume={55},
  number={14s},
  pages={1--27},
  year={2023},
  publisher={ACM New York, NY}
}

@ARTICLE{Survey_2,
  author={Imteaj, Ahmed and Thakker, Urmish and Wang, Shiqiang and Li, Jian and Amini, M. Hadi},
  journal={IEEE Internet of Things Journal}, 
  title={A Survey on Federated Learning for Resource-Constrained IoT Devices}, 
  year={2022},
  volume={9},
  number={1},
  pages={1-24},
  keywords={Edge computing;Computational modeling;Internet of Things;Data models;Servers;Collaborative work;Training;Convergence;federated learning (FL);global model;local model;on-device training;resource-constrained Internet-of-Things (IoT) devices},
  doi={10.1109/JIOT.2021.3095077}}
