\documentclass[twocolumn]{article}

\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{amsmath,amssymb}
\usepackage{graphicx}
\usepackage{hyperref}
\hypersetup{breaklinks=true}  
\usepackage{url}
\usepackage{xurl} 
\usepackage{algorithm}
\usepackage{algorithmic}
\usepackage{float}
\usepackage{booktabs}
\usepackage{lipsum}  
\usepackage{verbatim}
\usepackage{xcolor}
\usepackage{enumitem}
\setlist[itemize]{itemsep=0.5pt} 
\usepackage{setspace} 
\usepackage{tikz}
\usepackage{subcaption}
\usepackage{amsthm}  
\newtheorem{assumption}{Assumption}
\usepackage{mdframed}
\usepackage{tcolorbox}
\usepackage{booktabs}
\usepackage{array}
\usepackage{enumitem}
\usepackage{authblk}  
\usepackage[authoryear]{natbib}
\usepackage{tabularx}
\renewcommand{\arraystretch}{0.85} 
\setlength{\tabcolsep}{1pt}



\title{Prioritized Ranking Experimental Design Using Recommender Systems in Two-Sided Platforms}

\author[1]{Mahyar Habibi}
\author[2]{Zahra Khanalizadeh}
\author[3]{Negar Ziaeian}

\affil[1]{Bocconi University}
\affil[2]{University of Washington}
\affil[3]{University of Warwick}

\date{February 2025}

\begin{document}
\raggedbottom

\maketitle

\begin{abstract}
\vspace{-10pt}
\noindent Interdependencies between units in online two-sided marketplaces complicate estimating causal effects in experimental settings. We propose a novel experimental design to mitigate the interference bias in estimating the total average treatment effect (TATE) of item-side interventions in online two-sided marketplaces. Our Two-Sided Prioritized Ranking (TSPR) design uses the recommender system as an instrument for experimentation. TSPR strategically prioritizes items based on their treatment status in the listings displayed to users. We designed TSPR to provide users with a coherent platform experience by ensuring access to all items and a consistent realization of their treatment by all users. We evaluate our experimental design through simulations using a search impression dataset from an online travel agency. Our methodology closely estimates the true simulated TATE, while a baseline item-side estimator significantly overestimates TATE.
\end{abstract}

\vspace{0.5em}
\noindent\textbf{Keywords:} Experimental design, recommender systems, two-sided platforms, causal inference, online marketplaces, interference

\section{Introduction} 
Online platforms, such as e-commerce sites and online marketplaces, frequently conduct randomized controlled experiments (e.g., A/B tests) to optimize user experience, boost engagement, and drive sales. These experiments help mitigate risks associated with changes and innovations while providing rapid product feedback \citep{kohavi2020trustworthy, bojinov2022online, xia2019safe, xu2018sqr, kohavi2009online}. 

Standard experimental designs for estimating unbiased treatment effects rely on the Stable Unit Treatment Value Assumption (SUTVA), which states that the treatment assigned to one unit does not influence the outcomes of other units \citep{rubin1974estimating, imbens2015causal}. In online marketplaces, this assumption is often violated due to the interconnected nature of users and items. For instance, in item-side experiments, modifying features of treated items---such as offering discounts---can influence demand for non-treated items due to substitution or complementary effects. Such interference, spillover, or network effects have been observed in various platforms, including ridesharing (\cite{chamandy2016experimentation}) and online pricing experiments (\cite{choi2019monetizing}). Failing to account for interference in randomized experiments can introduce substantial bias, leading to the overestimation or underestimation of the interventionâ€™s true impact \citep{blake2014marketplace, fradkin2019simulation}.

Under interference, treatment effects depend on how interventions are distributed across units,  making the Total Average Treatment Effect (TATE) a central measure in such settings. TATE quantifies the impact of treating all units compared to treating none \citep{manski2013identification, munro2024treatmenteffectsmarketequilibrium}, and it has been widely adopted in the literature as it captures the full extent of both direct effects and spillovers across units. 

We propose the Two-Sided Prioritized Ranking (TSPR) experimental design that leverages recommender systems in two-sided marketplaces by strategically reordering items in ranked listings shown to users. Our approach builds on the well-documented phenomenon of position bias, where items appearing at the top of a list have greater influence on user behavior than those positioned lower \citep{craswell2008experimental, friedberg2022causal}. Recommender systems, which match items to user queries, are the primary ranking mechanism in online marketplaces. Our design leverages this structure to provide a systematic approach for estimating the TATE of item-side interventions on user-level outcomes. This framework applies broadly to two-sided marketplaces such as Expedia, Airbnb, Amazon, and many others.

In the TSPR design, users are randomized into two groups, and items are partitioned into three subsets: the Treated group, which receives the intervention, and two distinct groups that do not, called Untreated and Placebo. For one group of users, the recommender system prioritizes Untreated items at the top of search results, while for the other group, it prioritizes Treated items. Having both Untreated and Placebo groups---with Untreated matching the size of the Treated group---ensures the balanced quality of top-ranked items across user groups. We then estimate TATE by comparing partial outcomes between the two groups of users, where partial outcomes are defined as the cumulative outcome of the prioritized Treated or Untreated items placed at the top of the listings.

To evaluate our methodology, we use an open-source dataset of hotel search impressions from Expedia containing consumer queries, clicks, and booking outcomes. We develop a model of click and booking behavior to generate semi-synthetic data for our Monte Carlo simulations. We simulate a treatment resembling a platform-wide price increase on listed items, which, if applied to all items, reduces the user conversion rate by 0.050. We then compare two estimators across 500 simulation runs. Across simulations, our proposed method estimates TATE with an average of -0.047 and an average bootstrapped standard error of 0.016. In contrast, a naive estimator, which compares the average booking rate between treated and non-treated items, significantly overestimates TATE, producing an average estimated effect of -0.091 and an average standard error of 0.014.

A key advantage of our design is its ability to preserve a coherent user experience during experimentation. It ensures that no user loses access to any items, regardless of their randomized group assignment, and provides a consistent realization of item treatment across all users. A coherent user experience is crucial for online platforms, fostering trust, satisfaction, and long-term engagement \citep{veliz2023oxford, kahneman1986fairness, kohavi2020trustworthy}. However, many existing methods for estimating TATE in two-sided platforms disrupt user experience, limiting their practicality for real-world deployment. Switchback testing \citep{robins1986new, sneider2019experiment, bojinov2023design} alternates treatment assignments over time for the same units, enabling individual-level causal estimation but at the cost of user experience coherency. Frequent treatment fluctuations, such as dynamic pricing changes, may confuse users and distort engagement patterns.

Our proposed randomization framework is similar to two-sided randomization (TSR) methods \citep{johari2022experimental, bajari2023experimental}. In TSR, users and items are partitioned into mutually exclusive treatment-control subpopulations, and each group of users interacts with either treated or non-treated items. Consequently, TSR creates a fragmented marketplace which comes at the expense of user experience by restricting access to a subset of items and may lead to lost revenue, reduced customer satisfaction, and increased churn rates \citep{liu2013website}. In contrast, our proposed two-sided randomization framework guarantees users' access to all available items despite their randomized assignment.  Despite growing attention to ethical and responsible experimentation in online platforms \citep[e.g.,][]{polonioli2023ethics, saintjacques2020fairness}, the importance of maintaining a coherent user experience within experimental design has received limited attention. By incorporating user experience coherency as a core design objective, our work is the first to bridge this gap in the causal inference literature for two-sided platforms while maintaining the statistical advantages of TSR approaches.

Maintaining statistical power is another key strength of our design, as it randomizes at the user level and avoids the limitations imposed by cluster-based approaches. Cluster-based randomization groups related users or items to minimize spillover effects, but suffers from reduced power \citep{ugander2013graphclusterrandomizationnetwork, eckles2017design, holtz2024reducing}. Moreover, defining appropriate clusters in dynamic marketplace environments is often infeasible, and poor cluster definitions can lead to severe power loss and unreliable TATE estimates. Even when suitable clusters can be defined, implementing cluster-based randomization can be computationally expensive and operationally complex \citep{candogan2023correlated}.

Although mitigating interference in ranking experiments has been studied \citep[e.g.,][]{goli2024bias, zhan2024estimating, nandy2021b, ursu2018power}, existing experimental designs have not leveraged the ranking system itself as a tool for experimentation. By integrating recommender systems into experimental design, we bridge the gap between ranking mechanisms and causal inference methods. To the best of our knowledge, this study is the first to propose using recommender systems as an instrument for experimentation in online platforms.

The remainder of this paper is organized as follows: Section \ref{sec:methodology} formally defines the Two-Sided Prioritized Ranking experimental design and outlines our estimation methodology. Section \ref{sec:data_simulation} details the data and simulation setup, followed by the results in Section \ref{sec:results}. Finally, Section \ref{sec:conclusion} concludes the paper.

\section{Methodology} \label{sec:methodology}

\subsection{Two-Sided Prioritized Ranking (TSPR) Experimentation Setup}

We model a two-sided platform as a matching mechanism between a set of queries $q \in Q$, representing user inputs, and a set of items $i \in I$, representing available options. The platform uses a recommender system to compute relevance scores $r_{q,i} \in \mathbb{R}$ for each query-item pair based on the attributes of the query $q$ and the item $i$, such as user preferences and item features. Once query $q$ is submitted, the platform ranks the available items in descending order of their relevance scores $r_{q,i}$ and presents the ranked list to the user. When a user views the listed items, their interactions determine the outcomes $y_{q,i}$ for each displayed item. For simplicity, we assume all items initially have outcome values of $0$, and post-interaction, $y_{q,i}$ takes non-negative real values, representing outcomes such as clicks, bookings, or revenue. Additionally, since we assume each user submits exactly one query, we use the terms ``user'' and ``query'' interchangeably.

In the aforementioned setting, standard A/B testing with randomized item-level intervention assignment fails to produce unbiased treatment effect estimates due to the interference between items in the same query, which violates SUTVA. Furthermore, the proposed experimental design must satisfy two key constraints: preserving universal user access to all items throughout the experiment and maintaining consistent item treatment status across users. 

Due to item-side interference, the effect of a binary treatment $T \in \{0, 1\}$ on item-query outcomes $y_{q,i}$ depends on the distribution of interventions across units. This motivates our focus on the Total Average Treatment Effect (TATE), which captures both direct effects and spillovers by measuring the difference in expected outcomes between full treatment and no treatment conditions. Given our interest in TATE, we focus on query-level outcomes $Y_q = \sum_i y_{q,i}$, which aggregate individual item-query outcomes across all items displayed in response to query $q$. For notational simplicity, we omit the query subscript $q$ and denote query-level outcomes as $Y$.  Formally, we denote TATE by $\theta$ and define it as: 
\begin{equation}
    \label{eq:tate}
    \theta = \mathbb{E}\left[Y | \forall i \in \mathcal{I}: i \in \mathcal{I}^1  \right] - \mathbb{E}\left[Y|  \forall i \in \mathcal{I}: i \in \mathcal{I}^0\right]
\end{equation}
where $\mathcal{I}^1= \{i \in I \mid T_i = 1\}$  and $\mathcal{I}^0= \{i \in I \mid T_i = 0\}$  denote the sets of treated and non-treated items, respectively. Since each item can only be assigned to one treatment condition ($T_i = 1$ or $T_i = 0$) at a time, only one of the two terms on the right-hand side of the equation is observable at any given point. 

The proposed method rests on a few implicit assumptions. First, we assume that items at the top of the listings are significantly more influential on users' behavior (\cite{craswell2008experimental}), and the influence of items gradually vanishes as we move further down the list. Consequently, the effective exposure of a user to the treatment depends on the extent to which treated items appear near the top of the ranked list, as these items receive a disproportionate share of the user's attention. By strategically changing the ordering of items, we alter the \emph{effective exposure} of a user to the treatment. Second, our method requires the average number of relevant items per query to be sufficiently large to ensure that the repositioning scheme is effective in maximizing the exposure to treated items for one group of queries while minimizing it for the other. Third, we assume that user-side interference is negligible (e.g., slack supply) and the primary source of interference is the interdependence among outcomes of the items displayed under the same listing. 

Our proposed experimental design for estimating TATE is summarized in Table \ref{tab:experiment_setup}, with Figure \ref{fig:setup} illustrating the two-sided randomization scheme and group-specific listing priorities for query results.

\begin{table}[t]
    \centering
    \small  
    \caption{\centering Two-Sided Prioritized Ranking (TSPR) Experimental Design}
    \label{tab:experiment_setup}
    \begin{tabularx}{\linewidth}{>{\raggedright\arraybackslash}X}  
        \toprule
        \textbf{Experiment Setup} \\  
        \midrule
        \begin{minipage}{\linewidth} 
        \begin{enumerate}[leftmargin=*, itemsep=1pt, topsep=0pt, partopsep=0pt]
            \item Set the probability of receiving treatment for an item $p < 0.5$, and minimum relevance threshold $\underline{r}$. 

            \item Randomize items into Treated, Untreated, and Placebo subsets with probabilities $p$, $p$, and $1-2p$, respectively. Apply the treatment only to the Treated group.

            \item For each incoming query $q$:
            \begin{enumerate}[label=3.\arabic*., leftmargin=*]
                \item Randomly assign $q$ to $Q^A$ or $Q^B$ and set the item priorities as follows:
                \begin{itemize}[leftmargin=*]
                    \item If $q \in Q^A$: 1-Untreated, 2-Placebo, and 3-Treated.
                    \item If $q \in Q^B$: 1-Treated, 2-Placebo, and 3-Untreated.
                \end{itemize}
                
                \item Filter the set of relevant items with $r_{q,i} > \underline{r}$.
                \item Rank items primarily by priority (ascending) and secondarily by relevance score (descending).  
            \end{enumerate}
        \end{enumerate}
        \end{minipage}  
        \\
        \bottomrule
    \end{tabularx}  
\end{table}

\begin{figure}[htbp]
    \centering
    \caption{\centering Two-Sided Prioritized Ranking (TSPR) Experimental Design}
    \includegraphics[width=0.45\textwidth]{fig/Figure_1.pdf}
    \parbox{0.45\textwidth}{\footnotesize{\textit{Notes:} The figure illustrates the TSPR experiment setup. Items are partitioned into three groups, and queries are divided into two subsets. The relevant items for each query are first ordered based on their group-specific priority and then by their relevance score.}}
    \label{fig:setup}
\end{figure}

As outlined in Table \ref{tab:experiment_setup}, after specifying the global parameters $p$ and $\underline{r}$, we begin by partitioning items into three subsets: Treated, Untreated, and Placebo, with probabilities $p$, $p$, and $1-2p$, respectively. The intervention is only applied to the items in the Treated subset. Incorporating the Placebo subset serves a crucial purpose in maintaining experimental balance. Without a Placebo subset, when $p < 0.5$, the Untreated subset would be larger than the Treated subset, creating an asymmetric effect in step 3 of our design. Specifically, for queries in $Q^A$ for which we prioritize non-treated items, the larger Untreated pool would yield top-ranked items of higher average quality compared to the top-ranked items from the smaller Treated pool shown to $Q^B$. This imbalance would cause the recommender system's modification to impact $Q^A$ and $Q^B$ differently, confounding our ability to isolate the intervention's effect. The  Placebo subset ensures that the Treated and Untreated are roughly equal in size, making the expected match quality per rank comparable between the two groups.

In the next step, the stream of incoming queries are randomized into $Q^A$ or $Q^B$ with equal probability. Then, depending on the randomized allocation, item priorities are assigned such that queries in $Q^A$ will face items in the following order: Untreated, Placebo, and Treated, while the queries in $Q^B$, will be given items in the order of Treated, Placebo, and Untreated. Before returning the listings, items are filtered to ensure that only items of sufficient relevance are displayed to users. Modifying the recommender system may potentially cause poor-quality matches to be included in the listing, degrade user experience, and create large distortions in user behavior. To address this concern, we introduce a filtering parameter, denoted $\underline{r}$, and only items with a relevance score $r_{q,i} > \underline{r}$ are included in the final listing. The choice of $\underline{r}$ involves a trade-off and should be chosen carefully: setting it too low risks including irrelevant items that could deteriorate user experience, while setting it too high might result in queries receiving an insufficient number of items to display.

\subsection{TATE Estimation}

Building on the observations from the experimental method described above, we propose an estimator for the Total Average Treatment Effect (TATE) that does not require specifying an exposure mapping or imposing strong assumptions about substitution patterns among items.

The experimental design produces data with two important characteristics. First, because the recommender system prioritizes items rather than exclusively displaying those from one subset, queries in $Q^B$ may see some non-treated items, while queries in $Q^A$ may encounter some treated items. Second, the number of Treated (or Untreated) items appearing at the top of listings varies across queries based on item availability and relevance. These characteristics necessitate an assumption about how the intervention's expected impact on query-level outcomes relates to the number of treated items placed at the top of listings.

We define \emph{partial outcome}, denoted by $Y^{l} = \sum_{i=1}^{l} y^{i}$, as the cumulative outcome of the first $l$ listed items. Given the assumption that individual item-level outcomes are non-negative ($y_i \geq 0$), the expected value of the partial outcome, $\mathbb{E}[Y^{l}]$, is non-decreasing in $l$, which reflects the fact that including additional items in the calculation of outcome can only increase or maintain the total observed outcome. Similarly, we define the partial treatment effect, $\theta^l$, as the expected effect on partial outcome, $Y^l$, from applying the intervention only to the first $l$ listed items. That is,
\begin{equation}
    \label{eq:partial_treatment}
    \resizebox{\linewidth}{!}{$
     \theta^l = \mathbb{E}[Y^{l}  | \forall i \leq l: i \in \mathcal{I}^{1} \land \forall i > l: i \in \mathcal{I}^{0} ] - \mathbb{E}[Y^{l}  | \forall i : i \in \mathcal{I}^0].
    $}
\end{equation}


\begin{assumption}
    For all values of $l$, the partial treatment effect, $\theta^l$, is a fraction of the total treatment effect, $\theta$, by a factor of the ratio of the expected partial outcome to the expected total outcome in the absence of treatment. Formally,
   \begin{equation}
    \label{eq:assumption}
    \begin{aligned}
        \theta^l = \frac{\mathbb{E}[Y^{l}  | \forall i: i \in \mathcal{I}^0]}{\mathbb{E}[Y | \forall i : i \in \mathcal{I}^0]} \theta, \quad \forall l.
    \end{aligned}
\end{equation}
\end{assumption}

The assumption above allows us to aggregate the outcomes of queries faced with different numbers of Treated or Untreated units at the top of their corresponding listings. Due to the declining item influence down the listing position, as $l$ increases, the marginal contribution to the expected partial outcome $\mathbb{E}[Y^{l}]$ decreases. Consequently, the marginal effect of treating an additional item at rank $l$ gradually approaches zero as we move further down the listing, reflecting the diminishing impact of lower-ranked items on the query-level outcome.

In the TSPR design, the first term in the RHS of Equation \ref{eq:partial_treatment} corresponds to queries in $Q^B$ where the Treated block contains $l$ items. The second term represents the expected partial outcome $Y^l$ when no items in the list are treated. Under TSPR, this quantity is only observed when there are no relevant Treated units for a query in $Q^A$, a scenario that may be rare in practice, making direct estimation difficult. Given our assumptions that each query has a relatively large number of available items and that lower-listed items have negligible impact on user behavior, we propose the following approximation:
\begin{equation}
\label{eq:approximation}
\mathbb{E}[Y^{l}  | \forall i : i \in \mathcal{I}^0] \approx \mathbb{E}[Y^{l}  | \forall i \leq l : i \in \mathcal{I}^{0}]
\end{equation}
where $l$ denotes the number of Untreated items. This term can be represented by a query in $Q^A$ with a block of $l$ Untreated items. The introduction of Placebo items in our design further supports the validity of this approximation.

Using Equations \ref{eq:tate}, \ref{eq:partial_treatment}, \ref{eq:assumption}, \ref{eq:approximation}, and assuming for all $l$, $\mathbb{E}[Y^{l}  | \forall i \leq l: i \in \mathcal{I}^{0}] > 0$, we have:
\begin{equation}
\label{eq:theta}
\resizebox{\linewidth}{!}{$
\begin{aligned}
\theta &\approx \mathbb{E}[Y | \forall i : i \in \mathcal{I}^0] \\
&\times\frac{\mathbb{E}[Y^{l}  | \forall i \leq l: i \in \mathcal{I}^{1} \land \forall i > l: i \in \mathcal{I}^{0}] -  \mathbb{E}[Y^{l}  | \forall i \leq l : i \in \mathcal{I}^{0}]}{\mathbb{E}[Y^{l}  | \forall i \leq l: i \in \mathcal{I}^{0}]} 
\end{aligned}
$}
\end{equation}

for any choice of $l$.

Equation \ref{eq:theta} establishes a connection between the observable differences in partial outcomes from experimental data and the TATE. The first term on the RHS of the equation can be estimated by running a \emph{pre-experiment} phase in which the modified recommender system is deployed with the same composition of Treated, Placebo, and Untreated items, \emph{before} applying any treatment to the items in the Treated group. The second term on the RHS of the equation can be estimated \emph{during the experiment} using the relative difference in partial outcomes between queries in $Q^A$ and $Q^B$ that have exactly $l$ Untreated and Treated items at the top of their listings.

To provide a single estimate of TATE, we need to combine the estimates resulted from all observed values of $l$ having at least one correspondent query in $Q^A$ and $Q^B$. Here, we use frequency weighting and estimate TATE as,
\begin{align}
    \label{eq:theta_hat}
    \hat{\theta} =  \sum_{l=1}^{L} w_l \, \bar{Y}_{0} \left( \frac{\frac{1}{|Q^{B}_{l}|} \sum_{Q^{B}_{l}}Y^{l}_{B} -  \frac{1}{|Q^{A}_{l}|} \sum_{Q^{A}_{l}}Y^{l}_{A}}{\frac{1}{|Q^{A}_{l}|} \sum_{Q^{A}_{l}}Y^{l}_{A}} \right); \notag \\
    w_l = \frac{|Q^{B}_{l}| + |Q^{A}_{l}| }{ |Q^{B}| + |Q^{A}|}
\end{align}

where $Q^{B}_{l}$ ($Q^{A}_{l}$) denote queries in $Q^{B}$ ($Q^{A}$) for which the number of Treated (Untreated) items was equal to $l$, and $\bar{Y}_{0}$ is the expected outcome estimated using pre-experiment phase with the modified recommender system. Standard errors can be obtained via bootstrapping.

\section{Data and Simulation} \label{sec:data_simulation}
To illustrate our methodology, we use an open-source dataset of hotel search impressions from Expedia \citep{expedia-personalized-sort}, capturing consumer queries and their corresponding search behaviors---specifically, clicks and booking outcomes---over an eight-month period spanning 2012 and 2013. The dataset encompasses nearly 10 million observations derived from approximately 400,000 unique search impressions. Each search impression represents the result of a consumer query, providing a list of hotels along with their observable characteristics.

Consumers interact with the platform in three stages. First, consumers initiate queries by specifying trip details (destination, travel dates, booking window, etc.). Second, they receive a ranked list of hotel results through an experimental setup: two-thirds of users see listings ranked by the platform's original recommender system, while the remaining one-third encounter randomly sorted results. This experimental variation in ranking mechanisms allows us to model how item positions influence click and booking behavior. Finally, users engage by clicking on hotels to view details and may either complete a booking or leave without purchasing.

\begin{table}[ht]
\caption{Summary Statistics of Search Impressions}
\centering
\resizebox{\linewidth}{!}{  
\begin{tabular}{lrrrr}
\hline
                        & Mean  & Median & Min & Max \\
\hline
Randomized Ranking (Yes=1)   & 0.30  & 0   & 0   & 1   \\
Total Hotels per Impression  & 24.56 & 29  & 4   & 33  \\
Clicks per Impression        & 1.11  & 1   & 1   & 30  \\
Bookings per Impression      & 0.69  & 1   & 0   & 1   \\
\hline
\end{tabular}
}  
\label{tab:summary_stats}
\end{table}


To evaluate our experimental design, we implement a series of Monte Carlo simulations that replicate consumer interactions in an online two-sided marketplace, incorporating query-driven item ranking, click behavior, and booking decisions. We assume that the platform maintains a pool of available items, denoted as $N$, and displays a subset $n_q$ in response to each query.

To model user interactions, we assume that each item displayed to a consumer has a net (hidden) utility, denoted as $v$. The relevance score $r$, which represents the recommender system's match score between a consumer's query and an item, is modeled as $r = v + \epsilon$ with $\epsilon$ following a normal distribution $N(0, \sigma^2)$. We assume that the original ranking system is decreasing in $r$. However, for randomly ranked search impressions, the sorting order is determined randomly.

Click probabilities are modeled as a logistic function of the raw and quadratic rank values, hidden utilities, and prior user clicks on lower-ranked options. Booking decisions are modeled as a logit choice among clicked items, depending solely on net utility $v$. To ensure the simulation aligns with real-world behavior, hyperparameters $\sigma_e$ and $n_q$ are selected to match simulated conversion rates with observed data. This is achieved through an iterative process, where click and booking parameters are first estimated using the data-generating process, followed by user action simulations. The simulated conversion rates are then compared with empirical rates, and hyperparameters are adjusted to minimize discrepancies. Figure \ref{fig:subplot1} shows that the simulated click-through rate closely matches the observed data, demonstrating the convergence of the simulation to real-world behavior.

\begin{figure}[htbp]
    \centering
    \caption{\centering Click-Through Rate by Item Rank}
    \includegraphics[width=0.45\textwidth]{fig/ctr_actual_vs_sim.pdf}
    \label{fig:subplot1}
    \parbox{0.45\textwidth}{\footnotesize{\textit{Notes:} This figure presents the actual click-through rate (CTR) and the simulated CTR as a function of item position in the query results from a hold-out sample not used in the estimation of the click and booking models.}}
\end{figure}

Table \ref{tab:summary_stats} presents summary statistics at the search impression level, highlighting key patterns in click and booking behaviors across random and relevance-based rankings. 


\section{Results} \label{sec:results}
We conduct counterfactual simulations for 20,000 queries using our estimated models of click and booking behavior. First, to establish a simulated ground truth for TATE, we simulate the marketplace under two extreme scenarios: one where no items receive treatment and another where all items are treated. The treatment is implemented as a constant reduction in users' hidden utility from booking an item, resembling the effect of a platform-wide price or markup increase, which translates to a 0.05 decrease in the conversion rate. In these simulations, we maintain the recommender system without any modifications.

We then implement our Two-Sided Prioritized Ranking (TSPR) experimental design to estimate TATE in a setting where treatment is applied to 25\% ($p=0.25$) of the items. Following our methodology, we randomly assign each query to either group A or B with equal probability. For one group, the recommender system is modified to prioritize Treated items in the ranking, while for the other group, it prioritizes Untreated items. The remaining items are positioned according to the experimental design outlined in Table \ref{tab:experiment_setup}, maintaining access to all items while creating the necessary variation in exposure to treatment.

Additionally, to form a baseline for comparison, we simulate an item-side randomized experiment, which is an extension of the Horvitz-Thompson estimator \citep{horvitz1952generalization} to two-sided platforms and commonly used as a baseline in the literature \citep[e.g.,][]{johari2022experimental, bajari2023experimental}. In this setup, items are randomly assigned to the treatment group ($T$) with probability $p$ or the control group ($C$) with probability $1-p$. However, no randomization at the query level takes place. TATE is estimated as the difference in means of total outcomes per query, adjusted by the inverse of the inclusion probability of treated and control items:
\begin{equation}
    \hat{\theta}_{IS} =  \frac{\sum_{i \in T} \sum_{q \in Q} y_{q,i}}{p|Q|} - \frac{\sum_{i \in C} \sum_{q \in Q} y_{q,i}}{(1-p)|Q|}
\end{equation}
where $Q$ denotes the set of all queries, and $y_{q,i}$ represents the outcome for item $i$ in query $q$. 

\begin{figure}[htbp]
    \centering
     \caption{\centering TATE Estimates}
    \includegraphics[width=0.45\textwidth]{fig/hist_tate_naive_CIs.pdf}
    \parbox{0.45\textwidth}{\footnotesize{\textit{Notes:} The figure presents Total Average Treatment Effect (TATE) estimates from 500 simulated experiments. The vertical dashed line represents the ground truth TATE, corresponding to a 0.05 reduction in booking rate.  Panel (a) plots the histogram of TATE estimates from the TSPR method with 25\% treatment coverage (\(p=0.25\)), yielding an average estimate of -0.047 (average bootstrapped SE: 0.016).  Panel (b) plots the histogram of TATE estimates from the naive estimator under the same conditions, yielding an average estimate of -0.091 (average bootstrapped SE: 0.014). TATE estimates with 95\% confidence intervals that contain the ground truth are shown in bold color.
    }}
    \label{fig:tate_est}
    
\end{figure}

Figure \ref{fig:tate_est} presents the distribution of the TATE estimates from the TSPR setup and contrasts it with the distribution of $\hat{\theta}_{IS}$ across 500 runs. TSPR estimates TATE with an average of -0.047 (average bootstrapped SE: 0.016). In contrast, the baseline estimator significantly overestimates the effect with an average of -0.091 (average bootstrapped SE: 0.014), roughly double the true value, despite using a similar treatment group size. This overestimation occurs because the baseline approach fails to account for interference between treated and non-treated items within the same listing. The proportion of the TATE estimates with 95\% confidence intervals that contain the ground truth TATE (-0.05) is considerably larger for TSPR compared to the baseline estimator.

The relevance threshold parameter $\underline{r}$ serves a dual methodological and practical purpose: maintaining partial outcomes close to the original recommender system while preserving user experience through quality control of top-positioned items. In practice, platforms can determine an appropriate value for $\underline{r}$ using historical data or pre-intervention experiments with the modified recommender system, allowing them to balance the trade-off between listing quality and estimates' accuracy. In our simulations, we set $\underline{r} = 1.7$ to keep partial outcomes under the modified recommender system close to the baseline case, as illustrated in Figure \ref{fig:par_y}. The figure demonstrates that marginal contributions to partial outcomes are substantial for small values of $l$ but rapidly diminish with increasing position. This supports our approximation (\ref{eq:approximation}) by suggesting minimal contributions from items down the list.
\begin{figure}[htbp]
    \centering
     \caption{\centering Partial Outcomes Across Ranks}
    \includegraphics[width=0.45\textwidth]{fig/partial_outcome.pdf}
    \parbox{0.45\textwidth}{\footnotesize{\textit{Notes:} The figure plots the partial outcomes $Y^l$ for rank $l$, in four scenarios across 100 simulations. The first two scenarios are under the unmodified recommender system with no treatment ($p=0.0$) and full treatment ($p=1.0$). The other two scenarios illustrate the partial outcomes for $Q^A$ and $Q^B$ in the simulated experiments when the probability of assignment to both the Treated and Untreated group is $p=0.25$.}}
    \label{fig:par_y}
\end{figure}

Figure \ref{fig:sensitivity} examines the robustness of our estimates to the choice of relevance threshold $\underline{r}$. The TATE estimates remain relatively stable under moderate changes in $\underline{r}$, suggesting that our methodology is robust to the specific choice of this parameter. However, as illustrated, higher values of $\underline{r}$ restrict the number of Treated or Untreated items that qualify for top positions and reduce the range of block sizes available for estimation in Equation \ref{eq:theta}, leading to larger standard errors in our estimates.

\begin{figure}[htbp]
    \centering
     \caption{\centering Sensitivity Analysis of the TATE Estimates to $\underline{r}$}
    \includegraphics[width=0.45\textwidth]{fig/r_values_sensitivity_results.pdf}
    \parbox{0.45\textwidth}{\footnotesize{\textit{Notes:} The figure illustrates the TATE estimates and their 95\% bootstrapped confidence intervals for different choices of $\underline{r}$ from 100 simulated experiments in the TSPR setup when the probability of assignment to both the Treated and Untreated group is $p=0.25$.}}
    \label{fig:sensitivity}
\end{figure}

\section{Conclusion} \label{sec:conclusion}
This paper introduces a novel experimental design for two-sided marketplaces that leverages recommender systems to estimate the Total Average Treatment Effect (TATE) while addressing interference and maintaining a coherent user experience. By reordering items in query listings, our Two-Sided Prioritized Ranking (TSPR) design minimizes bias from network spillovers and ensures equal access to items for all users. Using a semi-synthetic dataset of hotel search impressions, we demonstrate that our design provides reliable TATE estimates while a standard item-side estimator significantly overestimates TATE.

The TSPR method is particularly designed for platforms relying on ranking algorithms, such as e-commerce sites and online marketplaces. Our design enables such platforms to estimate treatment effects while maintaining a coherent user experience and preserving platform functionality. It addresses concerns regarding unintended consequences of randomized experiments, such as user disengagement or inequitable access to items. 

Our paper opens promising avenues for future research. First, although we evaluate our method using semi-synthetic data, validating it with real-world data from diverse platforms would enhance its generalizability and provide deeper insights into its practical implementation. Second, our design focuses on item-side interventions and assumes negligible cross-user interference. Extending it to user-side interventions or settings with significant cross-user interference remains an open challenge and would greatly expand its applicability.


\section*{Acknowledgments}
We would like to express our gratitude to Manuel Bagues, Ludovica Gazze, Avi Goldfarb, Alan Griffith, Jason Kerwin, Mohammad H. Seyedsalehi, Sadegh Shirani, and participants at the 2024 Conference in Digital Experimentation (CODE@MIT), whose valuable insights were instrumental in shaping this work.


\bibliographystyle{agsm}
\input{main.bbl}

\end{document}