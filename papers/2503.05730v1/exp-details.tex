\section{Experimental Details}
\label{sec:exp-details}

\subsection{Datasets}
\label{appendix:data}
\paragraph{Synthetic Dataset} To better reflect real-world conditions, regions are connected based on a predefined topology. We randomly generate 5,100 graphs, each with 30 nodes and 20 edges. The first 4,800 graphs are used for training, the next 200 for validation, and the remaining 100 for testing. Each node is assigned a randomly generated 10-dimensional feature vector. Next, we establish a stochastic mapping from a node’s features to its poaching count, capturing the complex relationships observed in real-world scenarios. Poaching counts are sampled from a Gamma distribution parameterized by shape and scale values.  We randomly initialize two Graph Convolutional Networks (GCNs). For each node, one of the two GCNs is selected with equal probability to map the node’s features to a continuous value, which is then scaled by a factor of 20. This value serves as the shape parameter of the Gamma distribution. The poaching count is then drawn from the Gamma distribution, where the scale parameter is set to 1 if the first GCN is chosen and 0.9 if the second is chosen.  To incorporate adversarial noise, we apply perturbations inversely proportional to the poaching count—nodes with lower poaching counts receive higher noise levels. Finally, the poaching count for each node is capped within the range \([0,40]\) and scaled by 0.2 to align the overall distribution with real-world data.


\paragraph{Real-world Dataset}
We use poaching data from Murchison Falls National Park (MFNP) in Uganda, collected between 2010 and 2021. The protected area is discretized into 1 × 1 km grid cells. For each cell, we measure ranger patrol effort (in kilometers patrolled) as the conditional variable for the diffusion model, while the monthly number of detected illegal activity instances of each cell serves as the adversarial behavior. Following~\citep{basak2016abstraction}, we represent the park as a graph to capture geospatial connectivity among these cells. To focus on high-risk regions, we subsample 20 subgraphs from the entire graph. Specifically, at each time step we identify the 20 cells with the highest poaching counts. Each of these cells is treated as a central node, and we iteratively add the neighboring cell with the highest poaching count until the subgraph reaches 20 nodes. This procedure yields 532 training samples, 62 validation samples, and 31 test samples.


\subsection{Implementation details}
\label{appendix:details}
We use a three-layer Graph Convolutional Network (GCN)~\citep{kipf2022semi} with a hidden dimension of 128 as the backbone of the diffusion model. The diffusion process follows the DDPM framework~\citep{ho2020denoising} with \( T = 1000 \) time steps and a variance schedule from \( 10^{-4} \) to \( 0.02 \). Optimization is performed using Adam~\citep{kingma2014adam} with a learning rate of \( 10^{-3} \), and the model is trained for 5000 epochs. To estimate the expected utility, we draw 500 samples from the diffusion model. All comparison methods run for 30 iterations. The mirror ascent oracle uses a step size of 0.1 and runs for 100 iterations. The step size in the mirror ascent step for the baselines is also 0.1.





The actions of the poacher and ranger in grid $j$, represented by $z_j$ and $x_j$ respectively, influence the wildlife population in the area. We model the wildlife population in grid $j$ as follows: 
$$\max(N_0(j)e^r-\alpha e^{\psi \mathbf{z}_j - \theta \mathbf{x}_j}, 0),$$
where $N_0(j)$ is the initial wildlife population in the area and $r$ denotes the natural growth rate of the wildlife. The parameter $\alpha$ captures the impact of both the ranger’s and poacher’s actions on the wildlife population, $\psi$ reflects the strength of poaching, and $\theta$ measures the effectiveness of patrol effort. The utility for the ranger is then represented as the sum of wildlife population across all grids:
$$U(\mathbf{x}, \mathbf{z}) = \sum_{j=1}^K \max(N_0(j)e^r-\alpha e^{\psi \mathbf{z}_j - \theta \mathbf{x}_j}, 0)$$.


\paragraph{Forecasting Experiments.} 
We use the poaching dataset described in Appendix~\ref{appendix:data}. 
Following~\citet{pmlr-v161-xu21a}, linear regression and Gaussian processes predict the poaching count for each $1\times 1$ km cell individually, using two features: the previous month's patrol effort in the current cell and the aggregated patrol effort from neighboring cells.
For linear regression, we employ the scikit-learn implementation, while for Gaussian processes, we use the GPy library with both the RBF and Matérn kernels. The training procedure for the diffusion model follows Appendix~\ref{appendix:details}, with its support constrained to $[0,3]$. For each test instance, we generate 500 samples and use the mean prediction.  We also attempted to impose constraints on the baseline's output but found that this only degraded its performance.







