\section{Introduction}
% \lk{Green security, attacker behavior generation --> Diffusion model is powerful, multi-modal distribution, handling uncertainty. --> Diffusion model might be imperfect because the data is noisy and limited, we propose a robust patrol strategy optimization algorithm with diffusion models.}

In green security, mitigating threats such as illegal logging, illegal fishing, poaching, and environmental pollution requires defenders to anticipate and counteract adversarial behaviors \citep{IJCAI15-fei}. For example, in wildlife conservation, rangers must predict poachers' movements and then strategically allocate patrols to protect endangered species. Over the years, numerous predictive models have been developed \citep{kar2017cloudy, gurumurthy2018exploiting, xu2020stay}, alongside robust patrol optimization methods that leverage game theory to enhance decision-making based on these predictions \citep{pmlr-v161-xu21a}.

% A critical challenge in this domain is predicting the behavior of adversaries to design effective intervention strategies~\citep{IJCAI15-fei}. For instance, in wildlife conservation, rangers must forecast the behavior of poachers to strategically allocate patrols and safeguard endangered species. Accurate behavior prediction is essential for optimizing resource allocation and minimizing environmental harm, particularly in resource-constrained settings where every decision has significant implications.




However, existing adversary predictive models either lack uncertainty quantification \citep{kar2017cloudy, gurumurthy2018exploiting} or provide only parameterized predictive distributions with limited expressiveness \citep{xu2020stay}. In reality, adversarial behaviors—such as those of poachers—are high-dimensional and highly complex, driven by diverse motivations, constraints, and strategies. Capturing the full extent of uncertainty is particularly challenging in the strategic environments, where conventional models may struggle to account for the variability of real-world threats.

% However, modeling adversarial behavior presents significant challenges due to its inherent uncertainty and multimodal nature. Adversaries, such as poachers, operate under diverse motivations, constraints, and strategies, making their actions difficult to predict. The uncertainty stems from limited data availability—since adversaries actively evade detection—and the dynamic nature of their strategies, which evolve in response to enforcement actions. Additionally, adversarial behavior is often multimodal, encompassing a range of tactics and routes, further complicating the modeling process. Capturing these complexities requires robust models capable of handling uncertainty and representing multiple plausible scenarios. Previous work in the green security domain has typically relied on linear models, Gaussian processes, and decision trees to model adversarial behavior. However, these approaches have limited expressiveness and struggle to capture the full extent of uncertainty, particularly in highly dynamic and strategic settings.\lk{Add citations}



% In this work, we propose using diffusion models to model adversarial behavior. Diffusion models provide a powerful framework for capturing complex, non-parametric distributions and have been widely applied in image modeling\lk{CITE}, video generation\lk{CITE}, and time-series forecasting\lk {CITE}. By iteratively refining samples through a denoising process, they can generate diverse and plausible scenarios, offering a more comprehensive representation of potential attacker strategies. To the best of our knowledge, ours is the first attempt to apply diffusion models in the green security domain.


% \ak{We can transition to a new paragraph starting with something like this: ``Furthermore, rather than directly applying a diffusion model, we enhance the robustness of our approach to account for potential errors and uncertainties prevalent in real-world applications. For example..''} 

% Furthermore, we enhance the robustness of our approach to account for potential errors in the learned diffusion model due to data nosie, limited data size and neural network training.
% Specifically, we assume the attacker's true mixed strategy lies within a KL-divergence ball centered around the learned diffusion model distribution. We then optimize for the worst-case expected utility within this constrained space. This formulation naturally reduces to a two-player zero-sum game: the defender optimizes their mixed strategy to maximize utility, while an adversary chooses a distribution from the constrained space to minimize it.



% \ak{We can transition to a new paragraph starting with something like ``This novel game-theoretic formulation involving diffusion models also introduces new technical challenges that have not been addressed in the literature. First...''} 

% This novel game-theoretic formulation involving diffusion models also introduces new technical challenges that have not been addressed in the literature.
% First, the KL-divergence constraint on the adversary's mixed strategy prevents the direct application of the standard double oracle method. To address this, we shift the constraints from the mixed strategy space to the pure strategy space. Specifically, we treat the original mixed strategy as a pure strategy and introduce the concept of a "mixed strategy over mixed strategies," reformulating the problem into a more tractable optimization framework. Another challenge lies in sampling from a reweighted distribution of the original diffusion model to estimate the utility. To overcome this, we employ twisted sequential Monte Carlo (SMC) sampling, ensuring asymptotic exactness when estimating the utilities.




In this work, we propose using diffusion models to capture adversarial behavior in green security. Diffusion models are a powerful framework for modeling complex, high-dimensional, non-parametric distributions, and they have been successfully applied to image modeling~\citep{ho2020denoising, rombach2021high}, video generation~\citep{ho2022video}, and time-series forecasting~\citep{yang2024survey}. By iteratively refining samples through a denoising process, diffusion models can generate diverse and plausible scenarios, offering a more comprehensive representation of potential attacker strategies. To the best of our knowledge, ours is the first attempt to apply diffusion models in green security.

To enhance the robustness of our approach against potential errors in the learned diffusion model (arising from noisy data, limited sample sizes, or imperfect network training), we assume the attacker's true mixed strategy lies within a KL-divergence ball centered around the learned model distribution. We then optimize for the worst-case expected utility within this constrained space. This formulation naturally gives rise to a two-player zero-sum game: while a defender aims to maximize the expected utility, a nature adversary selects the mixed strategy from the KL ball to minimize it.


This game-theoretic formulation involving diffusion models introduces new technical challenges that have not been addressed in the literature.
First, the KL-divergence constraint on the adversary's mixed strategy prevents the direct application of the standard double oracle method. To resolve this, we shift the constraint from the mixed strategy space to the pure strategy space, treating the original mixed strategy as a pure strategy and introducing a ``mixed strategy over mixed strategies.'' This reformulation yields a more tractable optimization problem. Another challenge arises from the need to sample from a reweighted version of the diffusion model to estimate utilities. To address this, we employ twisted sequential Monte Carlo (SMC) sampling, ensuring asymptotic correctness when evaluating the relevant expected utilities.



% To solve this continuous game, we employ the double oracle algorithm and introduce the concept of a mixed strategy over mixed strategies. This formulation allows us to effectively handle the multimodal and uncertain nature of adversarial behavior.





% \ak{Perhaps we can add a paragraph before the summary of contributions below that wraps up the introduction at a high level. For example, ``By addressing the aforementioned challenges, our work introduces a powerful framework that combines the expressive power of diffusion models with the robustness of game-theoretic models. This framework not only enhances predictive accuracy in poaching behavior but also provides a principled way to generate robust patrol strategies against adversarial behavior. Moreover, our approach may be extended beyond green security applications, offering insights into broader strategic decision-making problems under uncertainty''}


Our contributions are as follows:  
(1) \textbf{Novel Adversary Modeling:} We are the first to leverage diffusion models for modeling adversarial behavior in green security domains.  
(2) \textbf{Robust Optimization with Diffusion Model Framework:} We propose \ours to mitigate imperfections in learned adversary models by introducing a double oracle algorithm that efficiently computes robust mixed patrol strategies. 
(3) \textbf{Theoretical Guarantees:} We prove that our method converges to an \(\epsilon\)-equilibrium with high probability under a finite number of iterations and a finite number of samples. (4) \textbf{Empirical Performance:} We empirically evaluate our method on both synthetic and real-world poaching data.