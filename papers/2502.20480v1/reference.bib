@inproceedings{youcook2,
    author = {Zhou, Luowei and Xu, Chenliang and Corso, Jason J.},
    title = {Towards Automatic Learning of Procedures from Web Instructional Videos},
    year = {2018},
    booktitle = {AAAI Conference on Artificial Intelligence (AAAI)},
}

@misc{chen2023valor,
    title={{VALOR:} Vision-Audio-Language Omni-Perception Pretraining Model and Dataset},
    author={Chen, Sihan and He, Xingjian and Guo, Longteng and Zhu, Xinxin and Wang, Weining and Tang, Jinhui and Liu, Jing},
    year={2023},
    howpublished={arXiv:2304.08345 [cs.LG]}
}

@InProceedings{msvd,
  title = "Collecting Highly Parallel Data for Paraphrase Evaluation",
  author = "David L. Chen and William B. Dolan",
  booktitle = "Annual Meeting of the Association for Computational Linguistics (ACL)",
  year = {2011}
} 

@inproceedings{vidchapters,
title={{VidChapters-7M:} Video Chapters at Scale},
author={Antoine Yang and Arsha Nagrani and Ivan Laptev and Josef Sivic and Cordelia Schmid},
booktitle={Advances in Neural Information Processing Systems (NeurIPS)},
year={2023}
}

@misc{charadesego,
    title={{Charades-Ego:} A Large-Scale Dataset of Paired Third and First Person Videos},
    author={Sigurdsson, Gunnar A. and Gupta, Abhinav and Schmid, Cordelia and Farhadi, Ali and Alahari, Karteek},
    year={2018},
    howpublished={arXiv:1804.09626 [cs.CV]}
}

@misc{youkumplug,
    title={{Youku-mPLUG:} A 10 Million Large-scale Chinese Video-Language Dataset for Pre-training and Benchmarks},
    author={Xu, Haiyang and Ye, Qinghao and Wu, Xuan and Yan, Ming and Miao, Yuan and Ye, Jiabo and Xu, Guohai and Hu, Anwen and Shi, Yaya and Xu, Guangwei and Li, Chenliang and Qian, Qi and Que, Maofei and Zhang, Ji and Zeng, Xiao and Huang, Fei},
    year={2023},
    howpublished={arXiv:2306.04362 [cs.CV]}
}

@INPROCEEDINGS{msr-vtt,
  author={Xu, Jun and Mei, Tao and Yao, Ting and Rui, Yong},
  booktitle={IEEE Conference on Computer Vision and Pattern Recognition (CVPR)}, 
  title={{MSR-VTT:} A Large Video Description Dataset for Bridging Video and Language}, 
  year={2016},
  pages={5288-5296},
}

@InProceedings{vatex,
author = {Wang, Xin and Wu, Jiawei and Chen, Junkun and Li, Lei and Wang, Yuan-Fang and Wang, William Yang},
title = {{VaTeX:} A Large-Scale, High-Quality Multilingual Dataset for Video-and-Language Research},
booktitle = {International Conference on Computer Vision (ICCV)},
year = {2019}
}

@InProceedings{tvc,
author={Lei, Jie and Yu, Licheng and Berg, Tamara L. and Bansal, Mohit},
title={{TVR:} A Large-Scale Dataset for Video-Subtitle Moment Retrieval},
booktitle={European Conference on Computer Vision (ECCV)},
year={2020},
pages={447--463},
}

@InProceedings{webvid,
  author       = "Max Bain and Arsha Nagrani and G{\"u}l Varol and Andrew Zisserman",
  title        = "{Frozen in Time:} A Joint Video and Image Encoder for End-to-End Retrieval",
  booktitle    = "IEEE International Conference on Computer Vision (ICCV)",
  year         = "2021",
}

@InProceedings{cmd,
      title={{Condensed Movies:} Story Based Retrieval with Contextual Embeddings}, 
      author={Max Bain and Arsha Nagrani and Andrew Brown and Andrew Zisserman},
      booktitle={Asian Conference on Computer Vision (ACCV)},
      year={2020},
}

@InProceedings{internvid,
    title={{InternVid:} A Large-scale Video-Text Dataset for Multimodal Understanding and Generation},
    author={Wang, Yi and He, Yinan and Li, Yizhuo and Li, Kunchang and Yu, Jiashuo and Ma, Xin and Li, Xinhao and Chen, Guo and Chen, Xinyuan and Wang, Yaohui and He, Conghui and Luo, Ping and Liu, Ziwei and Wang, Yali and Wang, Limin and Qiao, Yu},
    booktitle={International Conference on Learning Representations (ICLR)},
    year={2024},
}

@InProceedings{panda70m,
    title={{Panda-70M:} Captioning 70M Videos with Multiple Cross-Modality Teachers},
    author={Chen, Tsai-Shien and Siarohin, Aliaksandr and Menapace, Willi and Deyneka, Ekaterina and Chao, Hsiang-wei and Jeon, Byung Eun and Fang, Yuwei and Lee, Hsin-Ying and Ren, Jian and Yang, Ming-Hsuan and Tulyakov, Sergey},
    booktitle={IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
    year={2024}
}

@InProceedings{videocc,
author="Nagrani, Arsha and Seo, Paul Hongsuck and Seybold, Bryan and Hauth, Anja and Manen, Santiago and Sun, Chen and Schmid, Cordelia",
title="Learning Audio-Video Modalities from Image Captions",
booktitle="European Conference on Computer Vision (ECCV)",
year="2022",
pages="407--426"
}

@inproceedings{vitt,

    title = "Multimodal Pretraining for Dense Video Captioning",
    author = "Huang, Gabriel and Pang, Bo and Zhu, Zhenhai and Rivera, Clara and Soricut, Radu",
    booktitle = "1st Conference of the Asia-Pacific Chapter of the Association for Computational Linguistics and the 10th International Joint Conference on Natural Language Processing (AACL-IJCNLP)",
    year = "2020",
    pages = "470--490"
}

@InProceedings{tgif,
  author = {Li, Yuncheng and Song, Yale and Cao, Liangliang and Tetreault, Joel and Goldberg, Larry and Jaimes, Alejandro and Luo, Jiebo},
  title = "{{TGIF:} A New Dataset and Benchmark on Animated GIF Description}",
  booktitle = {IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  year = {2016}
}

@inproceedings{activity,
    title={Dense-Captioning Events in Videos},
    author={Krishna, Ranjay and Hata, Kenji and Ren, Frederic and Fei-Fei, Li and Niebles, Juan Carlos},
    booktitle={International Conference on Computer Vision (ICCV)},
    year={2017}
}

@inproceedings{charades,
  author = {Sigurdsson, G.A. and Varol, G. and Wang, X. and Farhadi, A. and Laptev, I. and Gupta, A.},
  title = {Hollywood in Homes: Crowdsourcing Data Collection for Activity Understanding},
  booktitle = {European Conference on Computer Vision (ECCV)},
  year = {2016},
 
  pages = {510-526},
 
}

@inproceedings{howto100m,
   title={How{T}o100{M}: {L}earning a {T}ext-{V}ideo {E}mbedding by {W}atching {H}undred {M}illion {N}arrated {V}ideo {C}lips},
   author={Miech, Antoine and Zhukov, Dimitri and Alayrac, Jean-Baptiste and Tapaswi, Makarand and Laptev, Ivan and Sivic, Josef},
   booktitle={International Conference on Computer Vision (ICCV)},
   year={2019},
}

@inproceedings{hdvila,
    title={Advancing High-Resolution Video-Language Representation with Large-Scale Video Transcriptions},
    author={Xue, Hongwei and Hang, Tiankai and Zeng, Yanhong and Sun, Yuchong and Liu, Bei and Yang, Huan and Fu, Jianlong and Guo, Baining},
    booktitle={International Conference on Computer Vision and Pattern Recognition (CVPR)},
    year={2022}
}

@InProceedings{mad,
    author    = {Soldan, Mattia and Pardo, Alejandro and Alc\'azar, Juan Le\'on and Caba, Fabian and Zhao, Chen and Giancola, Silvio and Ghanem, Bernard},
    title     = {{MAD:} A Scalable Dataset for Language Grounding in Videos From Movie Audio Descriptions},
    booktitle = {IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
    year      = {2022},
    pages     = {5026-5035}
}
}

@inproceedings{movienet,
      author = {Huang, Q. and Xiong, Y. and Rao, A. and Wang, J. and Lin, D.},
      title = {{MovieNet:} A Holistic Dataset for Movie Understanding},
      booktitle = {European Conference on Computer Vision (ECCV)},
      year = {2020},
      pages = {709-727},
}

}

@inproceedings{tvsum,
  author={Yale Song and Vallmitjana, Jordi and Stent, Amanda and Jaimes, Alejandro},
  booktitle={IEEE Conference on Computer Vision and Pattern Recognition (CVPR)}, 
  title={{TVSum:} Summarizing web videos using titles}, 
  year={2015},
  pages={5179-5187},
}

@inproceedings{summe,
  author = {Gygli, M. and Grabner, H. and Riemenschneider, H. and Van Gool, L.},
  title = {Creating Summaries from User Videos},
  booktitle = {European Conference on Computer Vision (ECCV)},
  year = {2014},
  pages = {505-520},
}

@article{videoxum,
  author    = {Lin, Jingyang and Hua, Hang and Chen, Ming and Li, Yikang and Hsiao, Jenhao and Ho, Chiuman and Luo, Jiebo},
  title     = {{VideoXum:} Cross-modal Visual and Textural Summarization of Videos},
  journal   = {IEEE Transactions on Multimedia (TMM)},
  year      = {2023}
}

@misc{openai2024gpt4,
    title={{GPT-4} {T}echnical {R}eport},
    author={OpenAI},
    year={2024},
    howpublished={arXiv:2303.08774 [cs.CL]}
}

@online{canada,
  author = {Milligan, B. and Fels, D.},
  title = {{M}edia {A}ccess {C}anada ({MAC}) - Our Projects - Descriptive Video Production and Presentation Best Practices Guide for Digital Environments},
  year = {2012},
  url = {http://www.mediac.ca/DVBPGDE_V2_28Feb2012.asp},
  lastaccessed = {Feb. 18, 2025},
}

@online{netflix,
        author = {Netflix},
	title = {Audio Description Style Guide v2.5},
	url = {https://partnerhelp.netflixstudios.com/hc/en-us/articles/215510667-Audio-Description-Style-Guide-v2-5},
	language = {en},
        year = {2024},
	lastaccessed = {Feb. 18, 2025},
}

@online{ofcom2021,
        author = {Ofcom},
	title = {Ofcom’s Guidelines on the Provision of Television Access Services},
	url = {https://www.ofcom.org.uk/__data/assets/pdf_file/0025/212776/provision-of-tv-access-services-guidelines.pdf},
	language = {en},
        year = {2021},
	lastaccessed = {Feb. 18, 2025},
}

@inproceedings{metrics,
author = {Natalie, Rosiana and Loh, Jolene and Tan, Huei Suen and Tseng, Joshua and Chan, Ian Luke Yi-Ren and Jarjue, Ebrima H and Kacorri, Hernisa and Hara, Kotaro},
title = {The Efficacy of Collaborative Authoring of Video Scene Descriptions},
year = {2021},
booktitle = {ACM SIGACCESS Conference on Computers and Accessibility (ASSETS)},
}

@article{dandona_2006_lowvision,
  author = {Dandona, Lalit and Dandona, Rakhi},
  title = {Revision of visual impairment definitions in the International Statistical Classification of Diseases},
  volume = {4},
  year = {2006},
  journal = {BMC Medicine}
}

@inproceedings{zhao2023lavila,
  title={Learning Video Representations from Large Language Models},
  author={Zhao, Yue and Misra, Ishan and Kr{\"a}henb{\"u}hl, Philipp and Girdhar, Rohit},
  booktitle={IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2023}
}

@inproceedings{vid2seq,
  title={Vid2Seq: Large-Scale Pretraining of a Visual Language Model for Dense Video Captioning}, 
  author={Antoine Yang and Arsha Nagrani and Paul Hongsuck Seo and Antoine Miech and Jordi Pont-Tuset and Ivan Laptev and Josef Sivic and Cordelia Schmid},
  booktitle={IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2023}
}

@inproceedings{vast,
title={{VAST}: A Vision-Audio-Subtitle-Text Omni-Modality Foundation Model and Dataset},
author={Sihan Chen and Handong Li and Qunbo Wang and Zijia Zhao and Mingzhen Sun and Xinxin Zhu and Jing Liu},
booktitle={Advances in Neural Information Processing Systems (NeurIPS)},
year={2023}
}

@misc{merlin,
    title={Merlin: Empowering Multimodal LLMs with Foresight Minds},
    author={Yu, En and Zhao, Liang and Wei, Yana and Yang, Jinrong and Wu, Dongming and Kong, Lingyu and Wei, Haoran and Wang, Tiancai and Ge, Zheng and Zhang, Xiangyu and Tao, Wenbing},
    year={2023},
    howpublished={arXiv:2312.00589 [cs.CV]}
}

@inproceedings{yt-temporal,
      title={{MERLOT Reserve}: Neural Script Knowledge through Vision and Language and Sound}, 
      author={Rowan Zellers and Jiasen Lu and Ximing Lu and Youngjae Yu and Yanpeng Zhao and Mohammadreza Salehi and Aditya Kusupati and Jack Hessel and Ali Farhadi and Yejin Choi},
      year={2022},
      booktitle={IEEE Conference on Computer Vision and Pattern Recognition (CVPR)}
}

@inproceedings{instructiontuned,
title={Finetuned Language Models are Zero-Shot Learners},
author={Jason Wei and Maarten Bosma and Vincent Zhao and Kelvin Guu and Adams Wei Yu and Brian Lester and Nan Du and Andrew M. Dai and Quoc V Le},
booktitle={International Conference on Learning Representations (ICLR)},
year={2022},
}

@inproceedings{videollama,
    title = "Video-{LL}a{MA}: An Instruction-tuned Audio-Visual Language Model for Video Understanding",
    author = "Zhang, Hang and Li, Xin and Bing, Lidong",
    booktitle = "Conference on Empirical Methods in Natural Language Processing: System Demonstrations (EMNLP)",
    year = "2023",
    pages = "543--553"
}

@inproceedings{VideoChatGPT,
    title={{V}ideo-{C}hat{GPT}: Towards Detailed Video Understanding via Large Vision and Language Models},
    author={Maaz, Muhammad and Rasheed, Hanoona and Khan, Salman and Khan, Fahad Shahbaz},
    booktitle={62nd Annual Meeting of the Association for Computational Linguistics (ACL)},
    year={2024}
}

@misc{videollava,
    title={{V}ideo-{LL}a{VA}: Learning United Visual Representation by Alignment Before Projection},
    author={Lin, Bin and Ye, Yang and Zhu, Bin and Cui, Jiaxi and Ning, Munan and Jin, Peng and Yuan, Li},
    year={2023},
    howpublished={arXiv:2311.10122 [cs.CV]}
}

@inproceedings{vila,
      title={VILA: On Pre-training for Visual Language Models}, 
      author={Ji Lin and Hongxu Yin and Wei Ping and Yao Lu and Pavlo Molchanov and Andrew Tao and Huizi Mao and Jan Kautz and Mohammad Shoeybi and Song Han},
      year={2024},
      booktitle={IEEE Conference on Computer Vision and Pattern Recognition (CVPR)}
}

@misc{videollm,
    title={{V}ideo{LLM}: Modeling Video Sequence with Large Language Models},
    author={Chen, Guo and Zheng, Yin-Dong and Wang, Jiahao and Xu, Jilan and Huang, Yifei and Pan, Junting and Wang, Yi and Wang, Yali and Qiao, Yu and Lu, Tong and Wang, Limin},
    year={2023},
    howpublished={arXiv:2305.13292 [cs.CV]}
}

@misc{otter,
    title={Otter: A Multi-Modal Model with In-Context Instruction Tuning},
    author={Li, Bo and Zhang, Yuanhan and Chen, Liangyu and Wang, Jinghao and Yang, Jingkang and Liu, Ziwei},
    year={2023},
    howpublished={arXiv:2305.03726 [cs.CV]}
}

@misc{vtimellm,
    title={{VT}ime{LLM}: Empower LLM to Grasp Video Moments},
    author={Huang, Bin and Wang, Xin and Chen, Hong and Song, Zihan and Zhu, Wenwu},
    year={2023},
    howpublished={arXiv:2311.18445 [cs.CV]}
}

@article{gpt4video,
  title={{GPT4V}ideo: A Unified Multimodal Large Language Model for lnstruction-Followed Understanding and Safety-Aware Generation},
  author={Zhanyu Wang and Longyue Wang and Minghao Wu and Zhen Zhao and Chenyang Lyu and Huayang Li and Deng Cai and Luping Zhou and Shuming Shi and Zhaopeng Tu},
  journal = {Computing Research Repository (CoRR)},
  year={2023}
}

@misc{videochat,
    title={{V}ideo{C}hat: Chat-Centric Video Understanding},
    author={Li, KunChang and He, Yinan and Wang, Yi and Li, Yizhuo and Wang, Wenhai and Luo, Ping and Wang, Yali and Wang, Limin and Qiao, Yu},
    year={2024},
    howpublished={arXiv:2305.06355 [cs.CV]}
}

@misc{pgvideollava,
    title={{PG}-{V}ideo-{LL}a{VA}: Pixel Grounding Large Video-Language Models},
    author={Munasinghe, Shehan and Thushara, Rusiru and Maaz, Muhammad and Rasheed, Hanoona Abdul and Khan, Salman and Shah, Mubarak and Khan, Fahad},
    year={2023},
    howpublished={arXiv:2311.13435 [cs.CV]}
}

@misc{llavaone,
      title={LLaVA-OneVision: Easy Visual Task Transfer}, 
      author={Bo Li and Yuanhan Zhang and Dong Guo and Renrui Zhang and Feng Li and Hao Zhang and Kaichen Zhang and Yanwei Li and Ziwei Liu and Chunyuan Li},
      year={2024},
      howpublished={arXiv:2408.03326 [cs.CV]}
}

@online{llavanext,
  title={LLaVA-NeXT: A Strong Zero-shot Video Understanding Model},
  url={https://llava-vl.github.io/blog/2024-04-30-llava-next-video/},
  author={Zhang, Yuanhan and Li, Bo and Liu, haotian and Lee, Yong jae and Gui, Liangke and Fu, Di and Feng, Jiashi and Liu, Ziwei and Li, Chunyuan},
  year={2024},
  lastaccessed = {Feb. 18, 2025},
}

@inproceedings{mmbench,
title={MMBench: Is Your Multi-modal Model an All-around Player?}, 
author={Yuan Liu and Haodong Duan and Yuanhan Zhang and Bo Li and Songyang Zhang and Wangbo Zhao and Yike Yuan and Jiaqi Wang and Conghui He and Ziwei Liu and Kai Chen and Dahua Lin},
year={2024},
booktitle={European Conference on Computer Vision (ECCV)}
      
}

@inproceedings{dpo,
title={Direct Preference Optimization: Your Language Model is Secretly a Reward Model},
author={Rafael Rafailov and Archit Sharma and Eric Mitchell and Christopher D Manning and Stefano Ermon and Chelsea Finn},
booktitle={Advances in Neural Information Processing Systems (NeurIPS)},
year={2023},
}

@inproceedings{keyframe,
  author={Changqing Cao and Zehua Chen and Gang Xie and Shaoshuai Lei},
  booktitle={24th Chinese Control and Decision Conference (CCDC)}, 
  title={{Key Frame Extraction Based on Frame Blocks Differential Accumulation}}, 
  year={2012},
  pages={3621-3625},
}

@inproceedings{keyframe2,
  author={Du, Jingjin and Zhao, Yale and Zhuang, Shanna and Wang, Zhengyou},
  booktitle={International Conference on Information Technology and Biomedical Engineering (ICITBE)}, 
  title={Key Frame Extraction for Falling Detection}, 
  year={2021},
  pages={105-109},
}


@online{dcmp,
        author = {{DCMP}},
	title = {Description {Key} - {Quality} {Description}},
	url = {https://dcmp.org/learn/621-description-key---quality-description},
	language = {en},
        year = {2024},
	lastaccessed = {Feb. 18, 2025},
}

@online{fcc,
        author = {{Federal Communications Commission (FCC)}},
	title = {Twenty-First Century Communications and Video Accessibility Act},
	url = {https://www.fcc.gov/cvaa},
        year = {2024},
        month = {July},
	lastaccessed = {Feb. 18, 2025},
}


@online{adlab,
        author = {{ADLAB}},
	title = {{ADLAB} {Audio} {Description} guideline},
	url = {http://www.adlabproject.eu/Docs/adlab%20book/},
        year = {2024},
	lastaccessed = {Feb. 18, 2025},
}

@online{w3,
	title = {Description of {Visual} {Information}},
	url = {https://www.w3.org/WAI/media/av/description/},
	language = {en},
        year = {2024},
	lastaccessed = {Feb. 18, 2025},
	journal = {Web Accessibility Initiative (WAI)},
	author = {Initiative (WAI), W3C Web Accessibility}
}
@online{adp,
	title = {{Overview}: {DVDs} and {Blu-ray} {Discs} {With} {Audio} {Description}},
	url = {https://adp.acb.org/dvdsoverview.html#moviestudios},
	  year = {2024},
	lastaccessed = {Feb. 18, 2025},
	journal = {The Audio Description Project},
	author = {American Council of the Blind}
}

@book{fryer_introduction_2016,
	address = {London},
	title = {An {Introduction} to {Audio} {Description}: {A} practical guide},
	isbn = {978-1-315-70722-8},
	shorttitle = {An {Introduction} to {Audio} {Description}},
	publisher = {Routledge},
	author = {Fryer, Louise},
	month = may,
	year = {2016}
}

@book{remael_pictures_2015,
	address = {Trieste},
	title = {Pictures painted in words: {ADLAB} audio description guidelines},
	isbn = {978-88-8303-675-0},
	shorttitle = {Pictures painted in words},
	language = {en},
	publisher = {EUT Edizioni Università di Trieste},
	editor = {Remael, Aline},
	year = {2015},
}

@article{klie2023annotation,
  title={Annotation Error Detection: Analyzing the Past and Present for a More Coherent Future},
  author={Klie, Jan-Christoph and Webber, Bonnie and Gurevych, Iryna},
  journal={Computational Linguistics},
  pages={157--198},
  year={2023},
}

@article{chen2022msrvideo,
  title={The {MSR}-{V}ideo to Text Dataset with Clean Annotations},
  author={Chen, Haoran and Li, Jianmin and Frintrop, Simone and Hu, Xiaolin},
  journal={Computer Vision and Image Understanding (CVIU)},
  pages={103581},
  year={2022},
}

@misc{chu2024llmad,
  title={{LLM-AD}: Large Language Model based Audio Description System},
  author={Chu, Peng and Wang, Jiang and Abrantes, Andre},
  year={2024},  
  howpublished={arXiv:2405.00983 [cs.CV]}
}

@article{aafaq2019video,
  title={Video Description: A Survey of Methods, Datasets, and Evaluation Metrics},
  author={Aafaq, Nayyer and Mian, Ajmal and Liu, Wei and Gilani, Syed Zulqarnain and Shah, Mubarak},
  journal={ACM Computing Surveys (CSUR)},
  volume={52},
  number={6},
  pages={1--37},
  year={2019},
  publisher={ACM New York, NY, USA}
}

@online{usaccess,
  author = {US Access Board},
  title = {About the ICT Accessibility 508 Standards and 255 Guidelines},
  url = {https://www.access-board.gov/ict/},
  year = {2024},
  lastaccessed = {Feb. 18, 2025}
}

@article{datasetsheet,
author = {Gebru, Timnit and Morgenstern, Jamie and Vecchione, Briana and Vaughan, Jennifer Wortman and Wallach, Hanna and III, Hal Daum\'{e} and Crawford, Kate},
title = {Datasheets for datasets},
year = {2021},
number = {12},
journal = {Commun. ACM},
pages = {86–92},
}

@misc{vicuna,
  title={Instruction Tuning with GPT-4},
  author={Peng, Baolin and Li, Chunyuan and He, Pengcheng and Galley, Michel and Gao, Jianfeng},
  year={2023},
  howpublished={arXiv:2304.03277 [cs.CV]}
}

@techreport{gpt2,
  title={Language Models are Unsupervised Multitask Learners},
  author={Radford, Alec and Wu, Jeffrey and Child, Rewon and Luan, David and Amodei, Dario and Sutskever, Ilya and others},
  year={2019},
  institution={OpenAI},
  number={1},
  volume={8},
}

@inproceedings{fewshot,
 author = {Brown, Tom and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared D and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and Agarwal, Sandhini and Herbert-Voss, Ariel and Krueger, Gretchen and Henighan, Tom and Child, Rewon and Ramesh, Aditya and Ziegler, Daniel and Wu, Jeffrey and Winter, Clemens and Hesse, Chris and Chen, Mark and Sigler, Eric and Litwin, Mateusz and Gray, Scott and Chess, Benjamin and Clark, Jack and Berner, Christopher and McCandlish, Sam and Radford, Alec and Sutskever, Ilya and Amodei, Dario},
 booktitle = {Advances in Neural Information Processing Systems (NeurIPS)},
 pages = {1877--1901},
 title = {Language Models are Few-Shot Learners},
 year = {2020}
}

@inproceedings{blip2,
author = {Li, Junnan and Li, Dongxu and Savarese, Silvio and Hoi, Steven},
title = {{BLIP-2}: Bootstrapping Language-Image Pre-training with Frozen Image Encoders and Large Language Models},
year = {2023},
booktitle = {40th International Conference on Machine Learning (ICML)},
}

@inproceedings{tag2text,
title={{Tag2Text:} Guiding Vision-Language Model via Image Tagging},
author={Xinyu Huang and Youcai Zhang and Jinyu Ma and Weiwei Tian and Rui Feng and Yuejie Zhang and Yaqian Li and Yandong Guo and Lei Zhang},
booktitle={The Twelfth International Conference on Learning Representations (ICLR)},
year={2024}
}

@inproceedings{clip,
  title={Learning transferable visual models from natural language supervision},
  author={Radford, Alec and Kim, Jong Wook and Hallacy, Chris and Ramesh, Aditya and Goh, Gabriel and Agarwal, Sandhini and Sastry, Girish and Askell, Amanda and Mishkin, Pamela and Clark, Jack and others},
  booktitle={International conference on machine learning (PMLR)},
  pages={8748--8763},
  year={2021}
}

@inproceedings{oscar,
  author={Nguyen, Nguyen and Bi, Jing and Vosoughi, Ali and Tian, Yapeng and Fazli, Pooyan and Xu, Chenliang},
  booktitle={In Findings of the Association for Computational Linguistics (NAACL)}, 
  title={{OSC}a{R}: Object State Captioning and State Change Representation}, 
  year={2024},

}


@inproceedings{chi2020yuksel,
  title={Increasing Video Accessibility for Visually Impaired Users with Human-in-the-Loop Machine Learning},
  author={Yuksel, Beste and Fazli, Pooyan and Mathur, Umang and Bisht, Vaishali and Kim, Soo Jung and Lee, Joshua Junhee and Jin, Seung Jung and Siu, Yue-Ting and Miele, Joshua A and Yoon, Ilmi},
  booktitle={ACM SIGCHI Conference Extended Abstracts on Human Factors in Computing Systems (CHI)},
  year={2020},
}

@inproceedings{hitl_blv_2020,
  title={Human-in-the-Loop Machine Learning to Increase Video Accessibility for Visually Impaired and Blind Users},
  author={Yuksel, Beste and Fazli, Pooyan and Mathur, Umang and Bisht, Vaishali and Kim, Soo Jung and Lee, Joshua Junhee and Jin, Seung Jung and Siu, Yue-Ting and Miele, Joshua A and Yoon, Ilmi},
  booktitle={ACM Conference on Designing Interactive Systems (DIS)},
  pages={47--60},
  year={2020},
}


@inproceedings{bodi_2021,
author = {Bodi, Aditya and Fazli, Pooyan and Ihorn, Shasta and Siu, Yue-Ting and Scott, Andrew T and Narins, Lothar and Kant, Yash and Das, Abhishek and Yoon, Ilmi},
title = {Automated Video Description for Blind and Low Vision Users},
year = {2021},
booktitle = {ACM SIGCHI Conference Extended Abstracts on Human Factors in Computing Systems (CHI)},
}

@inproceedings{optimization_prompt,
title={Large Language Models as Optimizers},
author={Chengrun Yang and Xuezhi Wang and Yifeng Lu and Hanxiao Liu and Quoc V Le and Denny Zhou and Xinyun Chen},
booktitle={International Conference on Learning Representations (ICLR)},
year={2024}
}


@inproceedings{cot_prompt,
title={Chain of Thought Prompting Elicits Reasoning in Large Language Models},
author={Jason Wei and Xuezhi Wang and Dale Schuurmans and Maarten Bosma and brian ichter and Fei Xia and Ed H. Chi and Quoc V Le and Denny Zhou},
booktitle={Advances in Neural Information Processing Systems (NeurIPS)},
year={2022}
}

@inproceedings{bert,
  author = {Jacob Devlin and Ming{-}Wei Chang and Kenton Lee and Kristina Toutanova},
  title  = {{BERT:} Pre-training of Deep Bidirectional Transformers for Language Understanding},
  booktitle = {Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL-HLT)},
  pages        = {4171--4186},
  year         = {2019},
}

@misc{liu2023prompt,
  title={Prompt Injection attack against LLM-integrated Applications},
  author={Liu, Yi and Deng, Gelei and Li, Yuekang and Wang, Kailong and Zhang, Tianwei and Liu, Yepang and Wang, Haoyu and Zheng, Yan and Liu, Yang},
  year={2023},
  howpublished={arXiv:2306.05499 [cs.CV]}
}

@inproceedings{bleu,
author = {Papineni, Kishore and Roukos, Salim and Ward, Todd and Zhu, Wei-Jing},
title = {{BLEU:} A Method for Automatic Evaluation of Machine Translation},
year = {2002},
booktitle = {Association for Computational Linguistics (ACL)},
pages = {311–318},
}

@inproceedings{cider,
author = {Ramakrishna Vedantam and C. Lawrence Zitnick and Devi Parikh},
booktitle = {IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
title = {{CIDE}r: Consensus-based Image Description Evaluation},
year = {2015},
pages = {4566-4575}
}

@inproceedings{meteor,
author = {Lavie, Alon and Agarwal, Abhaya},
title = {Meteor: An Automatic Metric for MT Evaluation with High Levels of Correlation with Human Judgments},
year = {2007},
booktitle = {Association for Computational Linguistics (ACL)},
pages = {228–231}
}

@inproceedings{rouge,
    title = "{ROUGE}: A Package for Automatic Evaluation of Summaries",
    author = "Lin, Chin-Yew",
    year = "2004",
    booktitle = "Association for Computational Linguistics (ACL)",
    pages = "74--81",
}

@inproceedings{spice,
  title     = {SPICE: Semantic Propositional Image Caption Evaluation},
  author    = {Peter Anderson and Basura Fernando and Mark Johnson and Stephen Gould},
  year      = {2016},
  booktitle = {European Conference on Computer Vision (ECCV)}
}

@inproceedings{review_hci,
author = {Bartolome, Ava and Niu, Shuo},
title = {A Literature Review of Video-Sharing Platform Research in HCI},
year = {2023},
booktitle = {ACM SIGCHI Conference on Human Factors in Computing Systems (CHI)},
}

@online{youdescribe,
        author = {YouDescribe},
	title        = {YouDescribe},
	url = {https://www.youdescribe.org/},
        year = {2024},
        month = {Aug},
	lastaccessed = {Feb. 18, 2025},
}


@article{image_descriptions_2015,
author = {Morash, Valerie S. and Siu, Yue-Ting and Miele, Joshua A. and Hasty, Lucia and Landau, Steven},
title = {Guiding Novice Web Workers in Making Image Descriptions Using Templates},
year = {2015},
publisher = {Association for Computing Machinery},
journal = {ACM Transactions on Accessible Computing (TACCESS)},
}

@inproceedings{audio_description_wang,
author = {Wang, Yujia and Liang, Wei and Huang, Haikun and Zhang, Yongqi and Li, Dingzeyu and Yu, Lap-Fai},
title = {Toward Automatic Audio Description Generation for Accessible Videos},
year = {2021},
booktitle = {ACM SIGCHI Conference on Human Factors in Computing Systems (CHI)},
}

@inproceedings{video_digests,
author = {Pavel, Amy and Reed, Colorado and Hartmann, Bj\"{o}rn and Agrawala, Maneesh},
title = {Video Digests: A Browsable, Skimmable Format for Informational Lecture Videos},
year = {2014},
booktitle = {ACM Symposium on User Interface Software and Technology (UIST)},
pages = {573–582},
}

@inproceedings{lei-etal-2020-mart,
    title = "{MART}: Memory-Augmented Recurrent Transformer for Coherent Video Paragraph Captioning",
    author = "Lei, Jie  and
      Wang, Liwei  and
      Shen, Yelong  and
      Yu, Dong  and
      Berg, Tamara  and
      Bansal, Mohit",
    booktitle = "Association for Computational Linguistics (ACL)",
    year = "2020",
    pages = "2603--2614",
}

@inproceedings{kobayashi2009,
author = {Kobayashi, Masatomo and Fukuda, Kentarou and Takagi, Hironobu and Asakawa, Chieko},
title = {Providing Synthesized Audio Description for Online Videos},
year = {2009},
booktitle = {ACM SIGACCESS Conference on Computers and Accessibility (ASSETS)},
pages = {249–250},
}

@inproceedings{video_scene_natalie_2022,
author = {Natalie, Rosiana},
title = {Cost-effective and Collaborative Methods to Author Video’s Scene Description for Blind People.},
year = {2022},
booktitle = {ACM SIGCHI Conference Extended Abstracts on Human Factors in Computing Systems (CHI)},
}

@inproceedings{viscene,
author = {Natalie, Rosiana and Jarjue, Ebrima and Kacorri, Hernisa and Hara, Kotaro},
title = {ViScene: A Collaborative Authoring Tool for Scene Descriptions in Videos},
year = {2020},
booktitle = {ACM SIGACCESS Conference on Computers and Accessibility (ASSETS)},
}

@article{livedescribe,
author = {Carmen J. Branje and Deborah I. Fels},
title ={LiveDescribe: Can Amateur Describers Create High-Quality Audio Description?},
journal = {Journal of Visual Impairment \& Blindness (JVIB)},
number = {3},
pages = {154-165},
year = {2012},
}

@inproceedings{rescribe,
author = {Pavel, Amy and Reyes, Gabriel and Bigham, Jeffrey P.},
title = {Rescribe: Authoring and Automatically Editing Audio Descriptions},
year = {2020},
booktitle = {ACM Symposium on User Interface Software and Technology (UIST)},
pages = {747–759},
}

@inproceedings{crossa11y,
   title={CrossA11y: Identifying Video Accessibility Issues via Cross-modal Grounding},
   booktitle={ACM Symposium on User Interface Software and Technology (UIST)},
   author={Liu, Xingyu “Bruce” and Wang, Ruolin and Li, Dingzeyu and Chen, Xiang Anthony and Pavel, Amy},
   year={2022},
}

@inproceedings{shortscribe,
author = {Van Daele, Tess and Iyer, Akhil and Zhang, Yuning and Derry, Jalyn C and Huh, Mina and Pavel, Amy},
title = {Making Short-Form Videos Accessible with Hierarchical Video Summaries},
year = {2024},
booktitle = {ACM SIGCHI Conference on Human Factors in Computing Systems (CHI)},
}

@inproceedings{spica,
author = {Ning, Zheng and Wimer, Brianna L and Jiang, Kaiwen and Chen, Keyi and Ban, Jerrick and Tian, Yapeng and Zhao, Yuhang and Li, Toby Jia-Jun},
title = {SPICA: Interactive Video Content Exploration through Augmented Audio Descriptions for Blind or Low-Vision Viewers},
year = {2024},
booktitle = {ACM SIGCHI Conference on Human Factors in Computing Systems (CHI)},
}

@inproceedings{ofa,
title={OFA: Unifying Architectures, Tasks, and Modalities Through a Simple Sequence-to-Sequence Learning Framework}, 
author={Peng Wang and An Yang and Rui Men and Junyang Lin and Shuai Bai and Zhikang Li and Jianxin Ma and Chang Zhou and Jingren Zhou and Hongxia Yang},
year={2022},
booktitle = {International Conference on Machine Learning (ICML)},
}

@Inbook{tentative_criteria,
author="Fresno, Nazaret and Castell{\`a}, Judit and Soler-Vilageliu, Olga",
title="`What Should I Say?' Tentative Criteria to Prioritize Information in the Audio Description of Film Characters",
bookTitle="Researching Audio Description: New Approaches",
year="2016",
publisher="Palgrave Macmillan UK",
pages="143--167",
}

@inproceedings{context_dependent,
author = {Jiang, Lucy and Jung, Crescentia and Phutane, Mahika and Stangl, Abigale and Azenkot, Shiri},
title = {“It’s Kind of Context Dependent”: Understanding Blind and Low Vision People’s Video Accessibility Preferences Across Viewing Scenarios},
year = {2024},
booktitle = {ACM SIGCHI Conference on Human Factors in Computing Systems (CHI)},
}

@inproceedings{ad_customization,
title={Audio Description Customization}, 
author={Rosiana Natalie and Ruei-Che Chang and Smitha Sheshadri and Anhong Guo, Kotaro Hara},
year={2024},
booktitle = {International ACM SIGACCESS Conference on Computers and Accessibility (ASSETS)},
pages={1-19}
}

@inproceedings{ssnn, 
title={Shrinking Your TimeStep: Towards Low-Latency Neuromorphic Object Recognition with Spiking Neural Networks}, 
number={10}, 
booktitle={AAAI Conference on Artificial Intelligence (AAAI)}, 
author={Ding, Yongqi and Zuo, Lin and Jing, Mengmeng and He, Pei and Xiao, Yongjun}, 
year={2024}, 
pages={11811-11819} 
}

@InProceedings{dtrocr,
    author    = {Fujitake, Masato},
    title     = {DTrOCR: Decoder-Only Transformer for Optical Character Recognition},
    booktitle = {IEEE/CVF Winter Conference on Applications of Computer Vision (WACV)},
    year      = {2024},
    pages     = {8025-8035}
}






@inproceedings{bennett2018interdependence,
  title={Interdependence as a Frame for Assistive Technology Research and Design},
  author={Bennett, Cynthia L and Brady, Erin and Branham, Stacy M},
  booktitle={International ACM SIGACCESS Conference on Computers and Accessibility (ASSETS)},
  pages={pp.\ 161--173},
  year={2018},
}

@inproceedings{chi2020yuksel,
  title={Increasing Video Accessibility for Visually Impaired Users with Human-in-the-Loop Machine Learning},
  author={Yuksel, Beste and Fazli, Pooyan and Mathur, Umang and Bisht, Vaishali and Kim, Soo Jung and Lee, Joshua Junhee and Jin, Seung Jung and Siu, Yue-Ting and Miele, Joshua A and Yoon, Ilmi},
  booktitle={ACM SIGCHI Conference Extended Abstracts on Human Factors in Computing Systems (CHI)},
  year={2020},
}


@inproceedings{adya2004multi,
  title={A Multi-Radio Unification Protocol for IEEE 802.11 Wireless Networks},
  author={Adya, Atul and Bahl, Paramvir and Padhye, Jitendra and Wolman, Alec and Zhou, Lidong},
  booktitle={First International Conference on Broadband Networks},
  pages={pp.\ 344--354},
  year={2004},
  organization={IEEE},
 
}

@inproceedings{das2017visual,
  title={Visual Dialog},
  author={Das, Abhishek and Kottur, Satwik and Gupta, Khushi and Singh, Avi and Yadav, Deshraj and Moura, Jos{\'e} MF and Parikh, Devi and Batra, Dhruv},
  booktitle={IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  pages={pp.\ 326--335},
  year={2017},
 
}


@inproceedings{lu2019vilbert,
  title={ViLBERT: Pretraining Task-Agnostic Visiolinguistic Representations for Vision-and-Language tasks},
  author={Lu, Jiasen and Batra, Dhruv and Parikh, Devi and Lee, Stefan},
  booktitle={Conference on Neural Information Processing Systems (NeurIPS)},
  pages={pp.\ 13--23},
  year={2019},
}

@article{su2019vl,
  title={Vl-BERT: Pre-Training of Generic Visual-Linguistic Representations},
  author={Su, Weijie and Zhu, Xizhou and Cao, Yue and Li, Bin and Lu, Lewei and Wei, Furu and Dai, Jifeng},
  journal={arXiv:1908.08530},
  year={2019},
}

@inproceedings{vaswani2017attention,
  title={Attention is All You Need},
  author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
  booktitle={Conference on Neural Information Processing Systems (NeurIPS)},
  pages={pp.\ 5998--6008},
  year={2017},
}

@inproceedings{sun2019videobert,
  title={VideoBERT: A Joint Model for Video and Language Representation Learning},
  author={Sun, Chen and Myers, Austin and Vondrick, Carl and Murphy, Kevin and Schmid, Cordelia},
  booktitle={IEEE International Conference on Computer Vision (ICCV)},
  pages={pp.\ 7464--7473},
  year={2019},
}

@article{xie2017rethinking,
  title={Rethinking Spatiotemporal Feature Learning for Video Understanding},
  author={Xie, Saining and Sun, Chen and Huang, Jonathan and Tu, Zhuowen and Murphy, Kevin},
  journal={arXiv:1712.04851},
  volume={1},
  number={2},
  year={2017},
}

@inproceedings{szegedy2015going,
  title={Going Deeper with Convolutions},
  author={Szegedy, Christian and Liu, Wei and Jia, Yangqing and Sermanet, Pierre and Reed, Scott and Anguelov, Dragomir and Erhan, Dumitru and Vanhoucke, Vincent and Rabinovich, Andrew},
  booktitle={IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  pages={pp.\ 1--9},
  year={2015},
}

@inproceedings{carreira2017quo,
  title={Quo Vadis, Action Recognition? A New Model and the Kinetics Dataset},
  author={Carreira, Joao and Zisserman, Andrew},
  booktitle={IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  pages={pp.\ 6299--6308},
  year={2017}
}

@article{devlin2018bert,
  title={BERT: Pre-Training of Deep Bidirectional Transformers for Language Understanding},
  author={Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
  journal={arXiv:1810.04805},
  year={2018},
}

@inproceedings{zhou2018end,
  title={End-to-End Dense Video Captioning with Masked Transformer},
  author={Zhou, Luowei and Zhou, Yingbo and Corso, Jason J and Socher, Richard and Xiong, Caiming},
  booktitle={IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  pages={pp.\ 8739--8748},
  year={2018},
}

@article{zhou2017towards,
  title={Towards Automatic Learning of Procedures from Web Instructional Videos},
  author={Zhou, Luowei and Xu, Chenliang and Corso, Jason J},
  journal={arXiv:1703.09788},
  year={2017},
}


@inproceedings{singh2018pythia,
  title={Pythia - A Platform for Vision and Language Research},
  author={Singh, Amanpreet and Goswami, Vedanuj and Natarajan, Vivek and Jiang, Yu and Chen, Xinlei and Shah, Meet and Rohrbach, Marcus and Batra, Dhruv and Parikh, Devi},
  booktitle={SysML Workshop, Conference on Neural Information Processing Systems (NeurIPS)},
  year={2018},
}

@inproceedings{anderson2018bottom,
  title={Bottom-Up and Top-Down Attention for Image Captioning and Visual Question Answering},
  author={Anderson, Peter and He, Xiaodong and Buehler, Chris and Teney, Damien and Johnson, Mark and Gould, Stephen and Zhang, Lei},
  booktitle={IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  pages={pp.\ 6077--6086},
  year={2018},
}

@inproceedings{deng2009imagenet,
  title={ImageNet: A Large-Scale Hierarchical Image Database},
  author={Deng, Jia and Dong, Wei and Socher, Richard and Li, Li-Jia and Li, Kai and Fei-Fei, Li},
  booktitle={IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  pages={pp.\ 248--255},
  year={2009},
}


@article{krishna2017visual,
  title={Visual Genome: Connecting Language and Vision Using Crowdsourced Dense Image Annotations},
  author={Krishna, Ranjay and Zhu, Yuke and Groth, Oliver and Johnson, Justin and Hata, Kenji and Kravitz, Joshua and Chen, Stephanie and Kalantidis, Yannis and Li, Li-Jia and Shamma, David A and others},
  journal={International Journal of Computer Vision},
  volume={123},
  number={1},
  pages={pp.\ 32--73},
  year={2017},
  publisher={Springer},
}

@inproceedings{ren2015faster,
  title={Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks},
  author={Ren, Shaoqing and He, Kaiming and Girshick, Ross and Sun, Jian},
  booktitle={Advances in Neural Information Processing Systems},
  pages={pp.\ 91--99},
  year={2015},
}

@inproceedings{he2016deep,
  title={Deep Residual Learning for Image Recognition},
  author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  booktitle={IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  pages={pp.\ 770--778},
  year={2016},
}

@inproceedings{lin2017feature,
  title={Feature Pyramid Networks for Object Detection},
  author={Lin, Tsung-Yi and Doll{\'a}r, Piotr and Girshick, Ross and He, Kaiming and Hariharan, Bharath and Belongie, Serge},
  booktitle={IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  pages={pp.\ 2117--2125},
  year={2017},
}

@inproceedings{xie2017aggregated,
  title={Aggregated Residual Transformations for Deep Neural Networks},
  author={Xie, Saining and Girshick, Ross and Doll{\'a}r, Piotr and Tu, Zhuowen and He, Kaiming},
  booktitle={IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  pages={pp.\ 1492--1500},
  year={2017},
}

@inproceedings{lin2014microsoft,
  title={Microsoft COCO: Common Objects in Context},
  author={Lin, Tsung-Yi and Maire, Michael and Belongie, Serge and Hays, James and Perona, Pietro and Ramanan, Deva and Doll{\'a}r, Piotr and Zitnick, C Lawrence},
  booktitle={European Conference on Computer Vision (ECCV)},
  pages={pp.\ 740--755},
  year={2014},
}

@article{hochreiter1997long,
  title={Long Short-Term Memory},
  author={Hochreiter, Sepp and Schmidhuber, J{\"u}rgen},
  journal={Neural Computation},
  volume={9},
  number={8},
  pages={pp.\ 1735--1780},
  year={1997},
  publisher={MIT Press},
}

@inproceedings{donahue2015long,
  title={Long-Term Recurrent Convolutional Networks for Visual Recognition and Description},
  author={Donahue, Jeffrey and Anne Hendricks, Lisa and Guadarrama, Sergio and Rohrbach, Marcus and Venugopalan, Subhashini and Saenko, Kate and Darrell, Trevor},
  booktitle={IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  pages={pp.\ 2625--2634},
  year={2015},
}

@inproceedings{pennington2014glove,
  title={Glove: Global Vectors for Word Representation},
  author={Pennington, Jeffrey and Socher, Richard and Manning, Christopher D},
  booktitle={Conference on Empirical Methods in Natural Language Processing (EMNLP)},
  pages={pp.\ 1532--1543},
  year={2014},
}

@article{friedewald2011,
  title={Ubiquitous Computing: An Overview of Technology Impacts},
  author={Friedewald, Michael and Raabe, Oliver},
  journal={Telematics and Informatics},
  volume={28},
  number={2},
  pages={pp.\ 55--65},
  year={2011},
}

@article{weiser1991,
  title={The Computer for the 21st Century},
  author={Weiser, Mark},
  journal={Scientific American},
  volume={265},
  number={3},
  pages={pp.\ 94--105},
  year={1991},
}

@inproceedings{siu2020,
  title={Access Technology for Blind and Low Vision Accessibility},
  author={Siu, Yue-Ting and Presley, Ike},
  year={2020},
  publisher={APH Press},
  address={Louisville, KY},
}

@inproceedings{videoindexer,
  title={Microsoft Azure Video Indexer},
  url={https://azure.microsoft.com/en-us/services/media-services/video-indexer/}
}



@misc{farhadi2018,
      title={YOLOv3: An Incremental Improvement}, 
      author={Joseph Redmon and Ali Farhadi},
      year={2018},
     howpublished={arXiv:1804.02767 [cs.CV]}
}

@article{OpenImages,
  author = {Alina Kuznetsova and Hassan Rom and Neil Alldrin and Jasper Uijlings and Ivan Krasin and Jordi Pont-Tuset and Shahab Kamali and Stefan Popov and Matteo Malloci and Alexander Kolesnikov and Tom Duerig and Vittorio Ferrari},
  title = {The Open Images Dataset V4: Unified Image Classification, Object Detection, and Visual Relationship Detection at Scale},
  journal = {International Journal of Computer Vision},
  volume={128},
  pages={pp.\ 1956–1981},
  year = {2020},
}

@inproceedings{10.3115/1073083.1073135,
author = {Papineni, Kishore and Roukos, Salim and Ward, Todd and Zhu, Wei-Jing},
title = {BLEU: A Method for Automatic Evaluation of Machine Translation},
year = {2002},
booktitle={Annual Meetings of the Association for Computational Linguistics (ACL)},
pages = {pp.\ 311–318},
}


@article{levenshtein1966bcc,
  author = {Vladimir Levenshtein},
  journal = {Soviet Physics Doklady},
  keywords = {lexicography similarity},
  pages = {pp.\ 707--710},
  title = {{Binary Codes Capable of Correcting Deletions, Insertions and Reversals}},
  volume = 10,
  year = 1966
}



@inproceedings{gagnon2010computer,
  title={A Computer-Vision-Assisted System for Videodescription Scripting},
  author={Gagnon, Langis and Chapdelaine, Claude and Byrns, David and Foucher, Samuel and Heritier, Maguelonne and Gupta, Vishwa},
  booktitle={IEEE Conference on Computer Vision and Pattern Recognition (CVPR Workshops)},
  pages={pp.\ 41--48},
  year={2010},
}

@article{gagnon2009towards,
  title={Towards Computer-Vision Software Tools to Increase Production and Accessibility of Video Description for People with Vision Loss},
  author={Gagnon, Langis and Foucher, Samuel and Heritier, Maguelonne and Lalonde, Marc and Byrns, David and Chapdelaine, Claude and Turner, James and Mathieu, Suzanne and Laurendeau, Denis and Nguyen, Nath Tan and others},
  journal={Universal Access in the Information Society},
  volume={8},
  number={3},
  pages={pp.\ 199--218},
  year={2009},
}

@inproceedings{chapdelaine2009accessible,
  title={Accessible Videodescription On-Demand},
  author={Chapdelaine, Claude and Gagnon, Langis},
  booktitle={11th International ACM SIGACCESS Conference on Computers and Accessibility},
  pages={pp.\ 221--222},
  year={2009},
  organization={ACM}
}

@inproceedings{encelle2011annotation,
  title={Annotation-Based Video Enrichment for Blind People: A Pilot Study on the Use of Earcons and Speech Synthesis},
  author={Encelle, Beno{\^\i}t and Ollagnier-Beldame, Magali and Pouchot, St{\'e}phanie and Pri{\'e}, Yannick},
  booktitle={13th International ACM SIGACCESS Conference on Computers and Accessibility},
  pages={pp.\ 123--130},
  year={2011},
}

@article{krishna2017dense,
  title={Dense-Captioning Events in Videos},
  author={Krishna, Ranjay and Hata, Kenji and Ren, Frederic and Li Fei-Fei and Niebles, Juan Carlos},
  journal={IEEE International Conference on Computer Vision (ICCV)},
  pages={pp.\ 706--715},
  year={2017},
}

@article{xu2018joint,
  title={Joint Event Detection and Description in Continuous Video Streams},
  author={Xu, Huijuan and Li, Boyang and Ramanishka, Vasili and Sigal, Leonid and Saenko, Kate},
  journal={arXiv:1802.10250},
  year={2018},
}





@article{agrawal2017vqa,
  title={VQA: Visual question answering},
  author={Agrawal, Aishwarya and Lu, Jiasen and Antol, Stanislaw and Mitchell, Margaret and Zitnick, C Lawrence and Parikh, Devi and Batra, Dhruv},
  journal={International Journal of Computer Vision},
  volume={123},
  number={1},
  pages={pp.\ 4--31},
  year={2017},
  publisher={Springer}
}

@inproceedings{antol2015vqa,
  title={Vqa: Visual question answering},
  author={Antol, Stanislaw and Agrawal, Aishwarya and Lu, Jiasen and Mitchell, Margaret and Batra, Dhruv and Lawrence Zitnick, C and Parikh, Devi},
  booktitle={IEEE International Conference on Computer Vision (ICCV)},
  pages={pp.\ 2425--2433},
  year={2015}
}


@inproceedings{bar2018tangicraft,
  title={Tangicraft: A Multimodal Interface for Minecraft},
  author={Bar-El, David and Large, Thomas and Davison, Lydia and Worsley, Marcelo},
  booktitle={International ACM SIGACCESS Conference on Computers and Accessibility (ASSETS)},
  pages={pp.\ 456--458},
  year={2018},
}


@article{bourne2017magnitude,
  title={Magnitude, temporal trends, and projections of the global prevalence of blindness and distance and near vision impairment: a systematic review and meta-analysis},
  author={Bourne, Rupert RA and Flaxman, Seth R and Braithwaite, Tasanee and Cicinelli, Maria V and Das, Aditi and Jonas, Jost B and Keeffe, Jill and Kempen, John H and Leasher, Janet and Limburg, Hans and others},
  journal={The Lancet Global Health},
  volume={5},
  number={9},
  pages={pp.\ e888--e897},
  year={2017},
  publisher={Elsevier}
}


@inproceedings{caba2015activitynet,
  title={Activitynet: A large-scale Video Benchmark for Human Activity Understanding},
  author={Caba Heilbron, Fabian and Escorcia, Victor and Ghanem, Bernard and Carlos Niebles, Juan},
  booktitle={IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  pages={pp.\ 961--970},
  year={2015}
}

@online{capscribe1,
  author = {CapScribe},
  title = {},
  year = {Accessed Date 2021-01-10},
  url = {https://www.inclusivemedia.ca/capscribe.shtml},
  urldate = {2021-01-10}
}

@inproceedings{champin2010towards,
  title={Towards Collaborative annotation for video accessibility},
  author={Champin, Pierre-Antoine and Encelle, Beno{\^\i}t and Evans, Nicholas WD and O-Beldame, Magali and Pri{\'e}, Yannick and Troncy, Rapha{\"e}l},
  booktitle={International Cross Disciplinary Conference on Web Accessibility, W4A},
  pages={pp.\ 1--4},
  year={2010},
}



@inproceedings{chapdelaine2010situ,
  title={In-situ Study of Blind Individuals Listening to Audio-Visual Contents},
  author={Chapdelaine, Claude},
  booktitle={International ACM SIGACCESS Conference on Computers and Accessibility (ASSETS)},
  pages={pp.\ 59--66},
  year={2010},
}

@inproceedings{chapdelaine2012specialized,
  title={Specialized DVD player to render audio description and its usability performance},
  author={Chapdelaine, Claude},
  booktitle={International ACM SIGACCESS Conference on Computers and Accessibility (ASSETS)},
  pages={pp.\ 203--204},
  year={2012},
}

@article{cummings2004need,
  title={The need for command and control instant message adaptive interfaces: Lessons learned from Tactical Tomahawk human-in-the-loop simulations},
  author={Cummings, Mary L},
  journal={CyberPsychology \& Behavior},
  volume={7},
  number={6},
  pages={pp.\ 653--661},
  year={2004},
  publisher={Mary Ann Liebert, Inc. 2 Madison Avenue Larchmont, NY 10538 USA}
}

@inproceedings{daRochaTomeFilho:2019:LPT,
 author = {da Rocha Tom{\'e} Filho, Frederico and Mirza-Babaei, Pejman and Kapralos, Bill and Moreira Mendon\c{c}a Junior, Glaudiney},
 title = {Let's Play Together: Adaptation Guidelines of Board Games for Players with Visual Impairment},
 booktitle = {ACM SIGCHI Conference on Human Factors in Computing Systems (CHI)},
 year = {2019},
 isbn = {978-1-4503-5970-2},
 pages = {pp.\ 631:1--631:15},

} 

@article{dudley2018review,
  title={A review of user interface design for interactive machine learning},
  author={Dudley, John J and Kristensson, Per Ola},
  journal={ACM Transactions on Interactive Intelligent Systems},
  volume={8},
  number={2},
  pages={pp.\ 8},
  year={2018},
}

@misc{hodas2016adding,
  title={Adding semantic information into data models by learning domain expertise from user interaction},
  author={Hodas, Nathan Oken and Endert, Alex},
  howpublished={arXiv:1604.02935 [cs.CV]},
  year={2016}
}



@inproceedings{encelle2013towards,
  title={Towards the usage of pauses in audio-described videos},
  author={Encelle, Beno{\^\i}t and Beldame, Magali Ollagnier and Pri{\'e}, Yannick},
  booktitle={10th International Cross-Disciplinary Conference on Web Accessibility},
  pages={pp.\ 31},
  year={2013},
}

@inproceedings{freeman2017audible,
  title={Audible beacons and wearables in schools: Helping young visually impaired children play and move independently},
  author={Freeman, Euan and Wilson, Graham and Brewster, Stephen and Baud-Bovy, Gabriel and Magnusson, Charlotte and Caltenco, Hector},
  booktitle={ACM SIGCHI Conference on Human Factors in Computing Systems (CHI)},
  pages={pp.\ 4146--4157},
  year={2017},
}

@article{freitas2008speech,
  title={Speech technologies for blind and low vision persons},
  author={Freitas, Diamantino and Kouroupetroglou, Georgios},
  journal={Technology and Disability},
  volume={20},
  number={2},
  pages={pp.\ 135--156},
  year={2008},
  publisher={IOS Press}
}

@inproceedings{fusco2014using,
  title={Using computer vision to access appliance displays},
  author={Fusco, Giovanni and Tekin, Ender and Ladner, Richard E and Coughlan, James M},
  booktitle={International ACM SIGACCESS Conference on Computers and Accessibility (ASSETS)},
  pages={pp.\ 281--282},
  year={2014},
}





@inproceedings{gao2015you,
  title={Are You Talking to a Machine? Dataset and Methods for Multilingual Image Question},
  author={Gao, Haoyuan and Mao, Junhua and Zhou, Jie and Huang, Zhiheng and Wang, Lei and Xu, Wei},
  booktitle={Conference on Neural Information Processing Systems (NIPS)},
  pages={pp.\ 2296--2304},
  year={2015}
}

@inproceedings{glinert2007audiodyssey,
  title={AudiOdyssey: An Accessible Video Game for both Sighted and Non-sighted Gamers},
  author={Glinert, Eitan and Wyse, Lonce},
  booktitle={International Academic Conference on the Future of Game Design and Technology (Future Play)},
  pages={pp.\ 251--252},
  year={2007},
}

@article{gopinath2016human,
  title={Human-in-the-loop Optimization of Shared Autonomy in Assistive Robotics},
  author={Gopinath, Deepak and Jain, Siddarth and Argall, Brenna D},
  journal={IEEE Robotics and Automation Letters},
  volume={2},
  number={1},
  pages={pp.\ 247--254},
  year={2016},
  publisher={IEEE}
}

@inproceedings{green2013efficacy,
  title={The Efficacy of Human Post-editing for Language Translation},
  author={Green, Spence and Heer, Jeffrey and Manning, Christopher D},
  booktitle={ACM SIGCHI Conference on Human Factors in Computing Systems (CHI)},
  pages={pp.\ 439--448},
  year={2013},
}

@inproceedings{hermann2015teaching,
  title={Teaching Machines to Read and Comprehend},
  author={Hermann, Karl Moritz and Kocisky, Tomas and Grefenstette, Edward and Espeholt, Lasse and Kay, Will and Suleyman, Mustafa and Blunsom, Phil},
  booktitle={Conference on Neural Information Processing Systems (NIPS)},
  pages={pp.\ 1693--1701},
  year={2015}
}

@inproceedings{holzinger2016towards,
  title={Towards interactive Machine Learning (iML): applying ant colony algorithms to solve the traveling salesman problem with the human-in-the-loop approach},
  author={Holzinger, Andreas and Plass, Markus and Holzinger, Katharina and Cri{\c{s}}an, Gloria Cerasela and Pintea, Camelia-M and Palade, Vasile},
  booktitle={International Conference on Availability, Reliability, and Security},
  pages={pp.\ 81--95},
  year={2016},
  organization={Springer}
}

@inproceedings{karpathy2014large,
  title={Large-scale video classification with convolutional neural networks},
  author={Karpathy, Andrej and Toderici, George and Shetty, Sanketh and Leung, Thomas and Sukthankar, Rahul and Fei-Fei, Li},
  booktitle={IEEE conference on Computer Vision and Pattern Recognition (CVPR)},
  pages={pp.\ 1725--1732},
  year={2014}
}
@article{kay2017kinetics,
  title={The kinetics human action video dataset},
  author={Kay, Will and Carreira, Joao and Simonyan, Karen and Zhang, Brian and Hillier, Chloe and Vijayanarasimhan, Sudheendra and Viola, Fabio and Green, Tim and Back, Trevor and Natsev, Paul and others},
  journal={arXiv:1705.06950},
  year={2017}
}

@inproceedings{visualverbal,
  title={The visual made verbal: A comprehensive training manual and guide to the history and applications of audio description.},
  author={Synder, Joel},
  booktitle={ American Council of the Blind, Incorporated},
  year={2014},
}

@misc{singh2019vqa,
      title={Towards VQA Models That Can Read}, 
      author={Amanpreet Singh and Vivek Natarajan and Meet Shah and Yu Jiang and Xinlei Chen and Dhruv Batra and Devi Parikh and Marcus Rohrbach},
      year={2019},
      howpublished={arXiv:1904.08920 [cs.CV]}
}

@misc{hu2020iterative,
      title={Iterative Answer Prediction with Pointer-Augmented Multimodal Transformers for TextVQA}, 
      author={Ronghang Hu and Amanpreet Singh and Trevor Darrell and Marcus Rohrbach},
      year={2020},
      howpublished={arXiv:1911.06258 [cs.CV]}
}

@misc{kant2020spatially,
      title={Spatially Aware Multimodal Transformers for TextVQA}, 
      author={Yash Kant and Dhruv Batra and Peter Anderson and Alex Schwing and Devi Parikh and Jiasen Lu and Harsh Agrawal},
      year={2020},
      howpublished={arXiv:2007.12146 [cs.CV]}
}

@misc{yang2020tap,
      title={TAP: Text-Aware Pre-training for Text-VQA and Text-Caption}, 
      author={Zhengyuan Yang and Yijuan Lu and Jianfeng Wang and Xi Yin and Dinei Florencio and Lijuan Wang and Cha Zhang and Lei Zhang and Jiebo Luo},
      year={2020},
      howpublished={arXiv:2012.04638 [cs.CV]},
}

@misc{pavel2020rescribe,
      title={Rescribe: Authoring and Automatically Editing Audio Descriptions}, 
      author={Amy Pavel and Gabriel Reyes and Jeffrey P. Bigham},
      year={2020},
      howpublished={arXiv:2010.03667 [cs.HC]}
}

@inproceedings{kobayashi2010synthesized,
  title={Are Synthesized Video Descriptions Acceptable?},
  author={Kobayashi, Masatomo and O'Connell, Trisha and Gould, Bryan and Takagi, Hironobu and Asakawa, Chieko},
  booktitle={International ACM SIGACCESS Conference on Computers and Accessibility (ASSETS)},
  pages={pp.\ 163--170},
  year={2010},
}

@inproceedings{kuehne2011hmdb,
  title={HMDB: A Large Video Database for Human Motion Recognition},
  author={Kuehne, Hildegard and Jhuang, Hueihan and Garrote, Est{\'\i}baliz and Poggio, Tomaso and Serre, Thomas},
  booktitle={IEEE International Conference on Computer Vision (ICCV)},
  pages={pp.\ 2556--2563},
  year={2011},
}

@inproceedings{gif_access,
author = {Gleason, Cole and Pavel, Amy and Gururaj, Himalini and Kitani, Kris and Bigham, Jeffrey},
title = {Making GIFs Accessible},
year = {2020},
booktitle = {International ACM SIGACCESS Conference on Computers and Accessibility (ASSETS)},
}

@inproceedings{memes_access,
author = {Gleason, Cole and Pavel, Amy and Liu, Xingyu and Carrington, Patrick and Chilton, Lydia B. and Bigham, Jeffrey P.},
title = {Making Memes Accessible},
year = {2019},
booktitle = {International ACM SIGACCESS Conference on Computers and Accessibility (ASSETS)},
pages = {367–376},
}

@misc{rohrbach2015dataset,
      title={A Dataset for Movie Description}, 
      author={Anna Rohrbach and Marcus Rohrbach and Niket Tandon and Bernt Schiele},
      year={2015},
      howpublished={arXiv:1501.02530 [cs.CV]}
}

@misc{tu2014joint,
      title={Joint Video and Text Parsing for Understanding Events and Answering Queries}, 
      author={Kewei Tu and Meng Meng and Mun Wai Lee and Tae Eun Choe and Song-Chun Zhu},
      year={2014},
      howpublished={arXiv:1308.6628 [cs.CV]}
}

@ARTICLE{unified_videoqa,
  author={H. {Xue} and Z. {Zhao} and D. {Cai}},
  journal={IEEE Transactions on Image Processing}, 
  title={Unifying the Video and Question Attentions for Open-Ended Video Question Answering}, 
  year={2017},
  volume={26},
  number={12},
  pages={5656-5666},
}

@article{Zhao_2020,
   title={Video Question Answering on Screencast Tutorials},
   ISBN={9780999241165},
   journal={Twenty-Ninth International Joint Conference on Artificial Intelligence},
   publisher={International Joint Conferences on Artificial Intelligence Organization},
   author={Zhao, Wentian and Kim, Seokhwan and Xu, Ning and Jin, Hailin},
   year={2020},
   month={Jul}
}

@InProceedings{guinness2018caption,
title={Caption Crawler: Enabling Reusable Alternative Text Descriptions using Reverse Image Search},
author = {Guinness, Darren and Cutrell, Ed and Morris, Meredith Ringel},
booktitle = {ACM SIGCHI Conference on Human Factors in Computing Systems (CHI)},
year = {2018},
}

@misc{alamri2019audiovisual,
      title={Audio-Visual Scene-Aware Dialog}, 
      author={Huda Alamri and Vincent Cartillier and Abhishek Das and Jue Wang and Anoop Cherian and Irfan Essa and Dhruv Batra and Tim K. Marks and Chiori Hori and Peter Anderson and Stefan Lee and Devi Parikh},
      year={2019},
      howpublished={arXiv:1901.09107 [cs.CV]}
}

@inproceedings{ webin,
author = {Bigham, Jeffrey P. and Cavender, Anna C. and Brudvik, Jeremy T. and Wobbrock, Jacob O. and Ladner, Richard E.},
title = {WebinSitu: A Comparative Analysis of Blind and Sighted Browsing Behavior},
year = {2007},
booktitle = {International ACM SIGACCESS Conference on Computers and Accessibility (ASSETS)},
pages = {51–58},
}

@inproceedings{Niebles2010ModelingTS,
  title={Modeling Temporal Structure of Decomposable Motion Segments for Activity Classification},
  author={Juan Carlos Niebles and Chih-Wei Chen and Li Fei-Fei},
  booktitle={European Conference on Computer Vision (ECCV)},
  year={2010}
}

@inproceedings{Rodriguez2008ActionMA,
  title={Action MACH a spatio-temporal Maximum Average Correlation Height filter for action recognition},
  author={Mikel D. Rodriguez and Javed Ahmed and M. Shah},
  journal={IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2008},
}

@inproceedings{Laptev2008LearningRH,
  title={Learning realistic human actions from movies},
  author={I. Laptev and M. Marszalek and C. Schmid and Benjamin Rozenfeld},
  booktitle={IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2008},
}
@article{activitynet,
  title={ActivityNet: A large-scale video benchmark for human activity understanding},
  author={Fabian Caba Heilbron and Victor Escorcia and Bernard Ghanem and Juan Carlos Niebles},
  journal={2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2015},
  pages={961-970}
}

@InProceedings{Krishna_2017_ICCV,
author = {Krishna, Ranjay and Hata, Kenji and Ren, Frederic and Fei-Fei, Li and Carlos Niebles, Juan},
title = {Dense-Captioning Events in Videos},
booktitle = {IEEE International Conference on Computer Vision (ICCV)},
month = {Oct},
year = {2017}
}

@misc{zhou2017automatic,
      title={Towards Automatic Learning of Procedures from Web Instructional Videos}, 
      author={Luowei Zhou and Chenliang Xu and Jason J. Corso},
      year={2017},
      howpublished={arXiv:1703.09788 [cs.CV]}
}

@misc{alayrac2016unsupervised,
      title={Unsupervised Learning from Narrated Instruction Videos}, 
      author={Jean-Baptiste Alayrac and Piotr Bojanowski and Nishant Agrawal and Josef Sivic and Ivan Laptev and Simon Lacoste-Julien},
      year={2016},
      howpublished={arXiv:1506.09215 [cs.CV]}
}

@inproceedings{heilman-smith-2010-good,
    title = "Good Question! Statistical Ranking for Question Generation",
    author = "Heilman, Michael  and
      Smith, Noah A.",
    booktitle = "Human Language Technologies: The 2010 Annual Conference of the North {A}merican Chapter of the Association for Computational Linguistics",
    month = jun,
    year = "2010",
    address = "Los Angeles, California",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/N10-1086",
    pages = "609--617",
}

@inproceedings{twitter,
author = {Gleason, Cole and Pavel, Amy and McCamey, Emma and Low, Christina and Carrington, Patrick and Kitani, Kris M. and Bigham, Jeffrey P.},
title = {Twitter A11y: A Browser Extension to Make Twitter Images Accessible},
year = {2020},
booktitle = {ACM SIGCHI Conference on Human Factors in Computing Systems (CHI)},
pages = {1–12},
}

@inproceedings{jang2017tgif,
  title={Tgif-qa: Toward Spatio-temporal Reasoning in Visual Question Answering},
  author={Jang, Yunseok and Song, Yale and Yu, Youngjae and Kim, Youngjin and Kim, Gunhee},
  booktitle={IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  pages={pp.\ 2758--2766},
  year={2017}
}

@inproceedings{ladner2005automating,
  title={Automating Tactile Graphics Translation},
  author={Ladner, Richard E and Ivory, Melody Y and Rao, Rajesh and Burgstahler, Sheryl and Comden, Dan and Hahn, Sangyun and Renzelmann, Matthew and Krisnandi, Satria and Ramasamy, Mahalakshmi and Slabosky, Beverly and others},
  booktitle={International ACM SIGACCESS Conference on Computers and Accessibility (ASSETS)},
  pages={pp.\ 150--157},
  year={2005},
}

@inproceedings{liu2016ssd,
  title={Ssd: Single Shot Multibox Detector},
  author={Liu, Wei and Anguelov, Dragomir and Erhan, Dumitru and Szegedy, Christian and Reed, Scott and Fu, Cheng-Yang and Berg, Alexander C},
  booktitle={European Conference on Computer Vision (ECCV)},
  pages={pp.\ 21--37},
  year={2016},
  organization={Springer}
}

@inproceedings{liu2019bought,
  title={"I Bought This for Me to Look More Ordinary": A Study of Blind People Doing Online Shopping},
  author={Liu, Guanhong and Ding, Xianghua and Yu, Chun and Gao, Lan and Chi, Xingyu and Shi, Yuanchun},
  booktitle={ACM SIGCHI Conference on Human Factors in Computing Systems (CHI)},
  pages={pp.\ 372},
  year={2019},
}

@online{livedescribe1994,
  author = {LiveDescribe},
  title = {},
  year = {Accessed Date 2021-01-10},
  url = https://livedescribe.com/pages/about},
  urldate = {2021-01-10}
}

@online{magpie2001,
  author = {MAGpie 2.0},
  title = {},
  year = {Accessed Date 2019-07-17},
  url = {http://main.wgbh.org/wgbh/pages/ncam_old/webaccess/magpie/},
  urldate = {2019-07-17}
}

@inproceedings{malinowski2014multi,
  title={A multi-world approach to question answering about real-world scenes based on uncertain input},
  author={Malinowski, Mateusz and Fritz, Mario},
  booktitle={Advances in Neural Information Processing Systems},
  pages={pp.\ 1682--1690},
  year={2014}
}

@inproceedings{malinowski2015ask,
  title={Ask your neurons: A neural-based approach to answering questions about images},
  author={Malinowski, Mateusz and Rohrbach, Marcus and Fritz, Mario},
  booktitle={IEEE International Conference on Computer Vision (ICCV)},
  pages={pp.\ 1--9},
  year={2015}
}

@article{miele2006talking,
  title={Talking TMAP: Automated Generation of Audio-Tactile Maps using Smith-Kettlewell's TMAP Software},
  author={Miele, Joshua A and Landau, Steven and Gilden, Deborah},
  journal={British Journal of Visual Impairment},
  volume={24},
  number={2},
  pages={pp.\ 93--100},
  year={2006},
  publisher={Sage Publications Sage CA: Thousand Oaks, CA}
}

@book{munro2020,
  title = {Human-in-the-Loop Machine Learning},
  author = {Munro, Robert},
  year = {2020},
  publisher = {MEAP},
  isbn={9781617296741}
}

@inproceedings{paladugu2010presenting,
 author = {Paladugu, Devi Archana and Wang, Zheshen and Li, Baoxin},
 title = {On Presenting Audio-tactile Maps to Visually Impaired Users for Getting Directions},
 booktitle = {ACM SIGCHI Conference Extended Abstracts on Human Factors in Computing Systems (CHI)},
 year = {2010},
 pages = {pp.\ 3955--3960},
} 

@article{parasuraman2000model,
  title={A Model for Types and Levels of Human Interaction with Automation},
  author={Parasuraman, Raja and Sheridan, Thomas B and Wickens, Christopher D},
  journal={IEEE Transactions on systems, man, and cybernetics-Part A: Systems and Humans},
  volume={30},
  number={3},
  pages={pp.\ 286--297},
  year={2000},
}

@inproceedings{potluri2018codetalk,
  title={CodeTalk: Improving Programming Environment Accessibility for Visually Impaired Developers},
  author={Potluri, Venkatesh and Vaithilingam, Priyan and Iyengar, Suresh and Vidya, Y and Swaminathan, Manohar and Srinivasa, Gopal},
  booktitle={ACM SIGCHI Conference on Human Factors in Computing Systems (CHI)},
  pages={pp.\ 1--11},
  year={2018},
}

@inproceedings{ren2015exploring,
  title={Exploring models and data for image question answering},
  author={Ren, Mengye and Kiros, Ryan and Zemel, Richard},
  booktitle={Advances in neural information processing systems},
  pages={pp.\ 2953--2961},
  year={2015}
}

@inproceedings{sanchez2011audio,
  title={Audio Haptic Videogaming for Navigation Skills in Learners Who are Blind},
  author={S{\'a}nchez, Jaime and Espinoza, Mat{\'\i}as},
  booktitle={International ACM SIGACCESS Conference on Computers and Accessibility (ASSETS)},
  pages={pp.\ 227--228},
  year={2011},
}

@inproceedings{saray2011adaptive,
  title={An Adaptive videos enrichment system based on decision trees for people with sensory disabilities},
  author={Saray Villamizar, Jos{\'e} Francisco and Encelle, Beno{\^\i}t and Pri{\'e}, Yannick and Champin, Pierre-Antoine},
  booktitle={International Cross-Disciplinary Conference on Web Accessibility},
  pages={pp.\ 1--4},
  year={2011},
}

@inproceedings{self2016bridging,
  title={Bridging the gap between user intention and model parameters for human-in-the-loop data analytics},
  author={Self, Jessica Zeitz and Vinayagam, Radha Krishnan and Fry, JT and North, Chris},
  booktitle={Workshop on Human-In-the-Loop Data Analytics},
  pages={pp.\ 3},
  year={2016},
  organization={ACM}
}

@inproceedings{sigurdsson2016hollywood,
  title={Hollywood in homes: Crowdsourcing data collection for activity understanding},
  author={Sigurdsson, Gunnar A and Varol, G{\"u}l and Wang, Xiaolong and Farhadi, Ali and Laptev, Ivan and Gupta, Abhinav},
  booktitle={European Conference on Computer Vision (ECCV)},
  pages={pp.\ 510--526},
  year={2016},
  organization={Springer}
}

@article{Simonyan2014VeryDC,
  title={Very Deep Convolutional Networks for Large-Scale Image Recognition},
  author={Karen Simonyan and Andrew Zisserman},
  journal={CoRR},
  year={2014},
}

@article{soomro2012ucf101,
  title={UCF101: A dataset of 101 human actions classes from videos in the wild},
  author={Soomro, Khurram and Zamir, Amir Roshan and Shah, Mubarak},
  journal={arXiv:1212.0402},
  year={2012}
}

@online{un2006,
  author={United Nations},
  title={Convention on the Rights of Persons with Disabilities and Optional Protocol},
  year={2006},
  url={https://www.un.org/disabilities/documents/convention/convoptprot-e.pdf},
}

@online{usaccessboard2015,
  author={United States Access Board},
  title={Proposed Information and Communication Technology (ICT) Standards and Guidelines},
  year=2015,
  url={https://www.access-board.gov/guidelines-and-standards/communications-and-it/about-the-ict-refresh/proposed-rule},
}

@inproceedings{wall2006feeling,
  title={Feeling what you hear: tactile feedback for navigation of audio graphs},
  author={Wall, Steven and Brewster, Stephen},
  booktitle={ACM SIGCHI Conference on Human Factors in Computing Systems (CHI)},
  pages={pp.\ 1123--1132},
  year={2006},
}

@article{wang2017interactive,
  title={Interactive deep learning method for segmenting moving objects},
  author={Wang, Yi and Luo, Zhiming and Jodoin, Pierre-Marc},
  journal={Pattern Recognition Letters},
  volume={96},
  pages={pp.\ 66--75},
  year={2017},
  publisher={Elsevier}
}


@article{weston2015towards,
  title={Towards ai-complete question answering: A set of prerequisite toy tasks},
  author={Weston, Jason and Bordes, Antoine and Chopra, Sumit and Rush, Alexander M and van Merri{\"e}nboer, Bart and Joulin, Armand and Mikolov, Tomas},
  journal={arXiv:1502.05698},
  year={2015}
}

@online{who2015,
  author = {World Health Organization},
  title = {International Statistical Classification of Diseases and Related Health Problems 10th Revision (ICD-10)-2015-WHO Version},
  year = {2015},
  url = {https://icd.who.int/browse10/2015/en#/H54}
}

@inproceedings{xin2018accelerating,
  title={Accelerating human-in-the-loop machine learning: Challenges and opportunities},
  author={Xin, Doris and Ma, Litian and Liu, Jialin and Macke, Stephen and Song, Shuchen and Parameswaran, Aditya},
  booktitle={Second Workshop on Data Management for End-To-End Machine Learning},
  pages={pp.\ 1--4},
  year={2018},
}



@online{IBMWatson2019,
  author = {IBM Watson},
  title = {},
  year = {Accessed Date 2019-09-15},
  url = {https://www.ibm.com/watson},
}

@online{ASync,
  author = {Automatic Sync Technologies},
  title = {},
  year = {Accessed Date 2019-09-15},
  url = {https://www.automaticsync.com/},
}


.

@article{yu2015lsun,
  title={Lsun: Construction of a large-scale image dataset using deep learning with humans in the loop},
  author={Yu, Fisher and Seff, Ari and Zhang, Yinda and Song, Shuran and Funkhouser, Thomas and Xiao, Jianxiong},
  journal={arXiv:1506.03365},
  year={2015}
}

@article{yu2015visual,
  title={Visual madlibs: Fill in the blank image generation and question answering},
  author={Yu, Licheng and Park, Eunbyung and Berg, Alexander C and Berg, Tamara L},
  journal={arXiv:1506.00278},
  year={2015}
}

@inproceedings{zhu2016visual7w,
  title={Visual7w: Grounded question answering in images},
  author={Zhu, Yuke and Groth, Oliver and Bernstein, Michael and Fei-Fei, Li},
  booktitle={IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  pages={pp.\ 4995--5004},
  year={2016}
}

@article{zitnick2016measuring,
  title={Measuring machine intelligence through visual question answering},
  author={Zitnick, C Lawrence and Agrawal, Aishwarya and Antol, Stanislaw and Mitchell, Margaret and Batra, Dhruv and Parikh, Devi},
  journal={AI Magazine},
  volume={37},
  number={1},
  pages={pp.\ 63--72},
  year={2016}
}



%=========================================================================
@article{vision1,
	title = {Magnitude, Temporal Trends, and Projections of the Global Prevalence of Blindness and Distance and Near Vision Impairment: A Systematic Review and Meta-analysis},
	volume = {5},
	number = {9},
	journal = {Lancet Global Health},
	author = {Rupert R. A. Bourne and Seth Flaxman and Tasanee Braithwaite and Maria Vittoria Cicinelli and Aditi Das and Jost Bruno Jonas and Jill Keeffe and John H. Kempen and Janet L. Leasher and Hans Limburg, Kovin Naidoo and Konrad Pesudovs and Serge Resnikoff and Alex Silvester and Gretchen A. Stevens and Nina Tahhan and Tien Yin Wong and Hugh R. Taylor},
	year = {2017},
	pages = {pp.\ e888-e897},
}

@article{vision2,
    title = {Global Prevalence of Presbyopia and Vision Impairment from Uncorrected Presbyopia: Systematic Review, Meta-analysis, and Modelling},
    volume = {125},
    number = {10},
    journal = {Ophthalmology},
    author = {Timothy R. Fricke and Nina Tahhan and Serge Resnikoff and Eric Papas and Anthea Burnett and Suit May Ho and Thomas Naduvilath and Kovin S. Naidoo},
    year = {2018},
    pages = {pp.\ 1492--1499},
}


@ARTICLE{7968387, 
author={B. {Zhou} and A. {Lapedriza} and A. {Khosla} and A. {Oliva} and A. {Torralba}}, 
journal={IEEE Transactions on Pattern Analysis and Machine Intelligence}, 
title={Places: A 10 Million Image Database for Scene Recognition}, 
year={2018}, 
volume={40}, 
number={6}, 
pages={pp.\ 1452-1464}, 
}

@article{DBLP:journals/corr/Abu-El-HaijaKLN16,
  author    = {Sami Abu{-}El{-}Haija and
               Nisarg Kothari and
               Joonseok Lee and
               Paul Natsev and
               George Toderici and
               Balakrishnan Varadarajan and
               Sudheendra Vijayanarasimhan},
  title     = {YouTube-8M: {A} Large-Scale Video Classification Benchmark},
  journal   = {arXiv:},
  volume    = {1609.08675 [cs.CV]},
  year      = {2016},
}

@inproceedings{Xu:2015:SAT:3045118.3045336,
 author = {Xu, Kelvin and Ba, Jimmy Lei and Kiros, Ryan and Cho, Kyunghyun and Courville, Aaron and Salakhutdinov, Ruslan and Zemel, Richard S. and Bengio, Yoshua},
 title = {Show, Attend and Tell: Neural Image Caption Generation with Visual Attention},
 booktitle = {International Conference on International Conference on Machine Learning (ICML)},
 year = {2015},
 pages = {pp.\ 2048--2057},
} 

@inproceedings{4364bd,
title = {SPICE: Semantic Propositional Image Caption Evaluation},
author = {Peter Anderson and Basura Fernando and Mark Johnson and Stephen Gould},
year = {2016},
pages = {pp.\ 382--398},
booktitle = {European Conference on Computer Vision (ECCV)},
}

@inproceedings{conf/cvpr/VedantamZP15,
  author = {Vedantam, Ramakrishna and Zitnick, C. Lawrence and Parikh, Devi},
  booktitle = {Conference on Computer Vision and Pattern Recognition (CVPR)},
  pages = {pp.\ 4566-4575},
  title = {{CIDE}r: Consensus-based Image Description Evaluation},
  year = {2015},
}

@inproceedings{Lavie:2007,
 author = {Lavie, Alon and Agarwal, Abhaya},
 title = {{METEOR}: An Automatic Metric for MT Evaluation with High Levels of Correlation with Human Judgments},
 booktitle = {Second Workshop on Statistical Machine Translation (StatMT)},
 year = {2007},
 pages = {pp.\ 228--231},
} 

@inproceedings{Venugopalan:2015,
 author = {Venugopalan, Subhashini and Rohrbach, Marcus and Donahue, Jeffrey and Mooney, Raymond and Darrell, Trevor and Saenko, Kate},
 title = {Sequence to Sequence - Video to Text},
 booktitle = {IEEE International Conference on Computer Vision (ICCV)},
 year = {2015},
 pages = {pp.\ 4534--4542},
} 

@inproceedings{Lin:2004,
  author = {Lin, Chin-Yew},
  booktitle = {ACL workshop on Text Summarization Branches Out},
  title = {{ROUGE:} A Package for Automatic Evaluation of summaries},
  pages = {pp.\ 74--81},
  year = {2004},
}

@article{lecun2015deep,
  title={Deep learning},
  author={LeCun, Yann and Bengio, Yoshua and Hinton, Geoffrey},
  journal={nature},
  volume={521},
  number={7553},
  pages={pp.\ 436},
  year={2015},
  publisher={Nature Publishing Group}
}

@inproceedings{koller1991algorithmic,
  title={Algorithmic characterization of vehicle trajectories from image sequences by motion verbs},
  author={Koller, Dieter and Heinze, N and Nagel, Hans-Hellmut},
  booktitle={IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  pages={pp.\ 90--95},
  year={1991},
}

@inproceedings{brand1997inverse,
  title={The" Inverse hollywood problem": from video to scripts and storyboards via causal analysis},
  author={Brand, Matthew},
  booktitle={AAAI/IAAI},
  pages={pp.\ 132--137},
  year={1997},
  organization={Citeseer}
}

@misc{barbu2012video,
    title={Video In Sentences Out},
    author={Andrei Barbu and Alexander Bridge and Zachary Burchill and Dan Coroian and Sven Dickinson and Sanja Fidler and Aaron Michaux and Sam Mussman and Siddharth Narayanaswamy and Dhaval Salvi and Lara Schmidt and Jiangnan Shangguan and Jeffrey Mark Siskind and Jarrell Waggoner and Song Wang and Jinlian Wei and Yifan Yin and Zhiqi Zhang},
    year={2012},
    howpublished={arXiv:1204.2742 [cs.CV]}
}

@article{Hanckmann_2012,
   title={Automated Textual Descriptions for a Wide Range of Video Events with 48 Human Actions},
   ISBN={9783642338632},
   ISSN={1611-3349},
   journal={Lecture Notes in Computer Science},
   publisher={Springer Berlin Heidelberg},
   author={Hanckmann, Patrick and Schutte, Klamer and Burghouts, Gertjan J.},
   year={2012},
   pages={pp.\ 372–380},
}

@inproceedings{Das_2013,
   title={A Thousand Frames in Just a Few Words: Lingual Description of Videos through Latent Topics and Sparse Object Stitching},
   booktitle={IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
   author={Das, Pradipto and Xu, Chenliang and Doell, Richard F. and Corso, Jason J.},
   pages={pp.\ 2634--2641},
   year={2013},
}



@article{aafaq2018video,
  author    = {Nayyer Aafaq and
               Syed Zulqarnain Gilani and
               Wei Liu and
               Ajmal Mian and
               Mubarak Shah},
  title     = {Video {D}escription: {A} Survey of Methods, Datasets and Evaluation
               Metrics},
  journal   = {CoRR},
  year      = {2018}
}

@article{Antonellis_2015,
   title={Shake Table Test of Large-Scale Bridge Columns Supported on Rocking Shallow Foundations},
   volume={141},
   ISSN={1943-5606},
   number={5},
   journal={Journal of Geotechnical and Geoenvironmental Engineering},
   publisher={American Society of Civil Engineers (ASCE)},
   author={Antonellis, Grigorios and Gavras, Andreas G. and Panagiotou, Marios and Kutter, Bruce L. and Guerrini, Gabriele and Sander, Andrew C. and Fox, Patrick J.},
   year={2015},
   pages={04015009}
}

@article{simonyan2014deep,
    title={Very Deep Convolutional Networks for Large-Scale Image Recognition},
    author={Karen Simonyan and Andrew Zisserman},
    year={2015},
    journal={ICLR},
    eprint={1409.1556},
    archivePrefix={arXiv},
    primaryClass={cs.CV}
}

@inproceedings{Szegedy_2015,
   title={Going deeper with convolutions},
   booktitle={IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
   author={Szegedy, Christian and Wei Liu and Yangqing Jia and Sermanet, Pierre and Reed, Scott and Anguelov, Dragomir and Erhan, Dumitru and Vanhoucke, Vincent and Rabinovich, Andrew},
   pages={pp.\ 1--9},
   year={2015},
}

@article{Hochreiter_1997,
   title={Long Short-Term Memory},
   volume={9},
   number={8},
   journal={Neural Computation},
   publisher={MIT Press},
   author={Hochreiter, Sepp and Schmidhuber, Jurgen},
   year={1997},
   pages={pp.\ 1735--1780}
}

@article{Cho_2014,
   title={On the Properties of Neural Machine Translation: Encoder–Decoder Approaches},
   journal={In Eighth Workshop on Syntax, Semantics and Structure in Statistical Translation, SSST-8},
   publisher={Association for Computational Linguistics},
   author={Cho, Kyunghyun and van Merrienboer, Bart and Bahdanau, Dzmitry and Bengio, Yoshua},
   pages={pp.\ 103},
   year={2014}
}

@inproceedings{Graves_2013,
   title={Speech recognition with deep recurrent neural networks},
   booktitle={IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
   author={Graves, Alex and Mohamed, Abdel-rahman and Hinton, Geoffrey},
   pages={pp.\ 6645--6649},
   year={2013},
}


@incollection{sutskever2014sequence,
title = {Sequence to Sequence Learning with Neural Networks},
author = {Sutskever, Ilya and Vinyals, Oriol and Le, Quoc V},
booktitle = {Advances in Neural Information Processing Systems 27},
editor = {Z. Ghahramani and M. Welling and C. Cortes and N. D. Lawrence and K. Q. Weinberger},
pages = {pp.\ 3104--3112},
year = {2014},
publisher = {Curran Associates, Inc.},
}


@inproceedings{Roemmele2016WritingSW,
  title={Writing Stories with Help from Recurrent Neural Networks},
  author={Melissa Roemmele},
  booktitle={AAAI Conference on Artificial Intelligence (AAAI)},
  pages={pp.\ 4311--4312},
  year={2016}
}

@misc{martin2017event,
    title={Event Representations for Automated Story Generation with Deep Neural Nets},
    author={Lara J. Martin and Prithviraj Ammanabrolu and Xinyu Wang and William Hancock and Shruti Singh and Brent Harrison and Mark O. Riedl},
    year={2017},
    howpublished={arXiv:1706.01331 [cs.CV]}
}

@inproceedings{martin2018event,
  title={Event representations for automated story generation with deep neural nets},
  author={Martin, Lara J and Ammanabrolu, Prithviraj and Wang, Xinyu and Hancock, William and Singh, Shruti and Harrison, Brent and Riedl, Mark O},
  booktitle={Thirty-Second AAAI Conference on Artificial Intelligence},
  year={2018}
}

@inproceedings{Fan_2018,
   title={Hierarchical Neural Story Generation},
   booktitle={56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
   publisher={Association for Computational Linguistics},
   author={Fan, Angela and Lewis, Mike and Dauphin, Yann},
   year={2018}
}
% Huang 2016
@article{2016,
   title={Visual Storytelling},
   ISBN={9783446448100},
   journal={Storytelling: Digital - Multimedial - Social},
   publisher={Carl Hanser Verlag GmbH & Co. KG},
   year={2016},
   month={Jul},
   pages={pp.\ 109–144}
}

@inproceedings{hsu-etal-2019-visual,
    title = "Visual Story Post-Editing",
    author = "Hsu, Ting-Yao  and
      Huang, Chieh-Yang  and
      Hsu, Yen-Chia  and
      Huang, Ting-Hao",
    booktitle = "57th Annual Meeting of the Association for Computational Linguistics",
    month = jul,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/P19-1658",
    pages = {pp.\ 6581--6586},
    abstract = "We introduce the first dataset for human edits of machine-generated visual stories and explore how these collected edits may be used for the visual story post-editing task. The dataset ,VIST-Edit, includes 14,905 human-edited versions of 2,981 machine-generated visual stories. The stories were generated by two state-of-the-art visual storytelling models, each aligned to 5 human-edited versions. We establish baselines for the task, showing how a relatively small set of human edits can be leveraged to boost the performance of large visual storytelling models. We also discuss the weak correlation between automatic evaluation scores and human ratings, motivating the need for new automatic metrics.",
}

@misc{hsu2019visual,
    title={Visual Story Post-Editing},
    author={Ting-Yao Hsu and Chieh-Yang Huang and Yen-Chia Hsu and Ting-Hao 'Kenneth' Huang},
    year={2019},
    howpublished={arXiv:1906.01764 [cs.CL]}
}

@inproceedings{Das_2017,
   title={Visual Dialog},
   booktitle={IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
   author={Das, Abhishek and Kottur, Satwik and Gupta, Khushi and Singh, Avi and Yadav, Deshraj and Moura, Jose M. F. and Parikh, Devi and Batra, Dhruv},
   year={2017},
}


@misc{singh2016untrimmed,
    title={Untrimmed Video Classification for Activity Detection: submission to ActivityNet Challenge},
    author={Gurkirt Singh and Fabio Cuzzolin},
    year={2016},
    howpublished={arXiv:1607.01979 [cs.CV]}
}

@article{Dudley:2018:RUI:3232718.3185517,
 author = {Dudley, John J. and Kristensson, Per Ola},
 title = {A Review of User Interface Design for Interactive Machine Learning},
 journal = {ACM Transactions on. Interactive Intelligent Systems},
 volume = {8},
 number = {2},
 month = jun,
 year = {2018},
 pages = {pp.\ 8:1--8:37},
 publisher = {ACM},
} 

@misc{pirrung2018sharkzor,
    title={Sharkzor: Interactive Deep Learning for Image Triage, Sort and Summary},
    author={Meg Pirrung and Nathan Hilliard and Artëm Yankov and Nancy O'Brien and Paul Weidert and Courtney D Corley and Nathan O Hodas},
    year={2018},
    howpublished={arXiv:1802.05316 [cs.HC]}
}


@inproceedings{Xu:2015,
 author = {Xu, Kelvin and Ba, Jimmy Lei and Kiros, Ryan and Cho, Kyunghyun and Courville, Aaron and Salakhutdinov, Ruslan and Zemel, Richard S. and Bengio, Yoshua},
 title = {Show, Attend and Tell: Neural Image Caption Generation with Visual Attention},
 booktitle = {International Conference on Machine Learning (ICML)},
 year = {2015},
 pages = {pp.\ 2048--2057},
} 

@inproceedings{HuangFMMADGHKBZ16,
    title = "Visual Storytelling",
    author = "Huang, Ting-Hao Kenneth  and
      Ferraro, Francis  and
      Mostafazadeh, Nasrin  and
      Misra, Ishan  and
      Agrawal, Aishwarya  and
      Devlin, Jacob  and
      Girshick, Ross  and
      He, Xiaodong  and
      Kohli, Pushmeet  and
      Batra, Dhruv  and
      Zitnick, C. Lawrence  and
      Parikh, Devi  and
      Vanderwende, Lucy  and
      Galley, Michel  and
      Mitchell, Margaret",
    booktitle = "2016 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies",
    month = jun,
    year = "2016",
    address = "San Diego, California",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/N16-1147",
    pages = "pp.\ 1233--1239",
}


@inproceedings{cho-etal-2014-learning,
    title = "Learning Phrase Representations using {RNN} Encoder{--}Decoder for Statistical Machine Translation",
    author = {Cho, Kyunghyun  and
      van Merri{\"e}nboer, Bart  and
      Gulcehre, Caglar  and
      Bahdanau, Dzmitry  and
      Bougares, Fethi  and
      Schwenk, Holger  and
      Bengio, Yoshua},
    booktitle = {Conference on Empirical Methods in Natural Language Processing (EMNLP)},
    year = {2014},
    pages = "pp.\ 1724--1734",
}


@article{branje2012livedescribe,
  title={Livedescribe: Can Amateur Describers create High-Quality Audio Description?},
  author={Branje, Carmen J. and Fels, Deborah I.},
  journal={Journal of Visual Impairment and Blindness},
  volume={106},
  number={3},
  pages={pp.\ 154--165},
  year={2012},
}


@inproceedings{10.1145/3379337.3415864,
author = {Pavel, Amy and Reyes, Gabriel and Bigham, Jeffrey P.},
title = {Rescribe: Authoring and Automatically Editing Audio Descriptions},
year = {2020},
booktitle = {ACM Symposium on User Interface Software and Technology (UIST)},
pages = {pp.\ 747–759},
}


% VQA Models
@article{mostafazadeh2016generating,
  title={Generating natural questions about an image},
  author={Mostafazadeh, Nasrin and Misra, Ishan and Devlin, Jacob and Mitchell, Margaret and He, Xiaodong and Vanderwende, Lucy},
  journal={arXiv preprint arXiv:1603.06059},
  year={2016}
}



@article{fukui2016multimodal,
  title={Multimodal compact bilinear pooling for visual question answering and visual grounding},
  author={Fukui, Akira and Park, Dong Huk and Yang, Daylen and Rohrbach, Anna and Darrell, Trevor and Rohrbach, Marcus},
  journal={arXiv preprint arXiv:1606.01847},
  year={2016}
}


@article{Jiang2020InDO,
  title={In Defense of Grid Features for Visual Question Answering},
  author={Huaizu Jiang and I. Misra and Marcus Rohrbach and E. Learned-Miller and Xinlei Chen},
  journal={2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2020},
  pages={10264-10273}
}

@inproceedings{kim2018bilinear,
  title={Bilinear attention networks},
  author={Kim, Jin-Hwa and Jun, Jaehyun and Zhang, Byoung-Tak},
  booktitle={Advances in Neural Information Processing Systems},
  pages={1564--1574},
  year={2018}
}

@article{yu2018beyond,
  title={Beyond bilinear: Generalized multimodal factorized high-order pooling for visual question answering},
  author={Yu, Zhou and Yu, Jun and Xiang, Chenchao and Fan, Jianping and Tao, Dacheng},
  journal={IEEE transactions on neural networks and learning systems},
  volume={29},
  number={12},
  pages={5947--5959},
  year={2018},
  publisher={IEEE}
}

@article{andreas2016learning,
  title={Learning to compose neural networks for question answering},
  author={Andreas, Jacob and Rohrbach, Marcus and Darrell, Trevor and Klein, Dan},
  journal={arXiv preprint arXiv:1601.01705},
  year={2016}
}

@inproceedings{hu2017learning,
  title={Learning to reason: End-to-end module networks for visual question answering},
  author={Hu, Ronghang and Andreas, Jacob and Rohrbach, Marcus and Darrell, Trevor and Saenko, Kate},
  booktitle={IEEE International Conference on Computer Vision},
  pages={804--813},
  year={2017}
}



@inproceedings{li2020unicoder,
  title={Unicoder-VL: A Universal Encoder for Vision and Language by Cross-Modal Pre-Training.},
  author={Li, Gen and Duan, Nan and Fang, Yuejian and Gong, Ming and Jiang, Daxin and Zhou, Ming},
  booktitle={AAAI},
  pages={11336--11344},
  year={2020}
}

@inproceedings{lu202012,
  title={12-in-1: Multi-task vision and language representation learning},
  author={Lu, Jiasen and Goswami, Vedanuj and Rohrbach, Marcus and Parikh, Devi and Lee, Stefan},
  booktitle={IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={10437--10446},
  year={2020}
}

@article{tan2019lxmert,
  title={Lxmert: Learning cross-modality encoder representations from transformers},
  author={Tan, Hao and Bansal, Mohit},
  journal={arXiv preprint arXiv:1908.07490},
  year={2019}
}

@article{chen2019uniter,
  title={Uniter: Learning universal image-text representations},
  author={Chen, Yen-Chun and Li, Linjie and Yu, Licheng and Kholy, Ahmed El and Ahmed, Faisal and Gan, Zhe and Cheng, Yu and Liu, Jingjing},
  journal={arXiv preprint arXiv:1909.11740},
  year={2019}
}



@inproceedings{zhang2016yin,
  title={Yin and yang: Balancing and answering binary visual questions},
  author={Zhang, Peng and Goyal, Yash and Summers-Stay, Douglas and Batra, Dhruv and Parikh, Devi},
  booktitle={IEEE Conference on Computer Vision and Pattern Recognition},
  pages={5014--5022},
  year={2016}
}

@inproceedings{selvaraju2020squinting,
  title={SQuINTing at VQA Models: Introspecting VQA Models With Sub-Questions},
  author={Selvaraju, Ramprasaath R and Tendulkar, Purva and Parikh, Devi and Horvitz, Eric and Ribeiro, Marco Tulio and Nushi, Besmira and Kamar, Ece},
  booktitle={IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={10003--10011},
  year={2020}
}

@inproceedings{shah2019cycle,
  title={Cycle-consistency for robust visual question answering},
  author={Shah, Meet and Chen, Xinlei and Rohrbach, Marcus and Parikh, Devi},
  booktitle={IEEE conference on computer vision and pattern recognition},
  pages={6649--6658},
  year={2019}
}

@inproceedings{agrawal2018don,
  title={Don't just assume; look and answer: Overcoming priors for visual question answering},
  author={Agrawal, Aishwarya and Batra, Dhruv and Parikh, Devi and Kembhavi, Aniruddha},
  booktitle={IEEE Conference on Computer Vision and Pattern Recognition},
  pages={4971--4980},
  year={2018}
}

@inproceedings{ramakrishnan2018overcoming,
  title={Overcoming language priors in visual question answering with adversarial regularization},
  author={Ramakrishnan, Sainandan and Agrawal, Aishwarya and Lee, Stefan},
  booktitle={Advances in Neural Information Processing Systems},
  pages={1541--1551},
  year={2018}
}

@inproceedings{vqahat,
  title={{Human Attention in Visual Question Answering: Do Humans and Deep Networks Look at the Same Regions?}},
  author={Abhishek Das and Harsh Agrawal and C. Lawrence Zitnick and Devi Parikh and Dhruv Batra},
  booktitle={Conference on Empirical Methods in Natural Language Processing (EMNLP)},
  year={2016}
}

@inproceedings{xu2018fooling,
  title={Fooling vision and language models despite localization and attention mechanism},
  author={Xu, Xiaojun and Chen, Xinyun and Liu, Chang and Rohrbach, Anna and Darrell, Trevor and Song, Dawn},
  booktitle={IEEE Conference on Computer Vision and Pattern Recognition},
  pages={4951--4961},
  year={2018}
}

@article{tang2020semantic,
  title={Semantic Equivalent Adversarial Data Augmentation for Visual Question Answering},
  author={Tang, Ruixue and Ma, Chao and Zhang, Wei Emma and Wu, Qi and Yang, Xiaokang},
  booktitle={ECCV},
  year={2020}
}

@inproceedings{zeng2019adversarial,
  title={Adversarial attacks beyond the image space},
  author={Zeng, Xiaohui and Liu, Chenxi and Wang, Yu-Siang and Qiu, Weichao and Xie, Lingxi and Tai, Yu-Wing and Tang, Chi-Keung and Yuille, Alan L},
  booktitle={IEEE Conference on Computer Vision and Pattern Recognition},
  pages={4302--4311},
  year={2019}
}

% Paraphrase Generation
@article{prakash2016neural,
  title={Neural paraphrase generation with stacked residual lstm networks},
  author={Prakash, Aaditya and Hasan, Sadid A and Lee, Kathy and Datla, Vivek and Qadir, Ashequl and Liu, Joey and Farri, Oladimeji},
  journal={arXiv preprint arXiv:1610.03098},
  year={2016}
}
@inproceedings{mallinson2017paraphrasing,
  title={Paraphrasing revisited with neural machine translation},
  author={Mallinson, Jonathan and Sennrich, Rico and Lapata, Mirella},
  booktitle={15th Conference of the European Chapter of the Association for Computational Linguistics: Volume 1, Long Papers},
  pages={881--893},
  year={2017}
}

@article{wieting2017learning,
  title={Learning paraphrastic sentence embeddings from back-translated bitext},
  author={Wieting, John and Mallinson, Jonathan and Gimpel, Kevin},
  journal={arXiv preprint arXiv:1706.01847},
  year={2017}
}

@article{kumar2020syntax,
  title={Syntax-guided Controlled Generation of Paraphrases},
  author={Kumar, Ashutosh and Ahuja, Kabir and Vadapalli, Raghuram and Talukdar, Partha},
  journal={arXiv preprint arXiv:2005.08417},
  year={2020}
}

@article{goyal2020neural,
  title={Neural Syntactic Preordering for Controlled Paraphrase Generation},
  author={Goyal, Tanya and Durrett, Greg},
  journal={arXiv preprint arXiv:2005.02013},
  year={2020}
}

@article{iyyer2018adversarial,
  title={Adversarial example generation with syntactically controlled paraphrase networks},
  author={Iyyer, Mohit and Wieting, John and Gimpel, Kevin and Zettlemoyer, Luke},
  journal={arXiv preprint arXiv:1804.06059},
  year={2018}
}

@article{li2017paraphrase,
  title={Paraphrase generation with deep reinforcement learning},
  author={Li, Zichao and Jiang, Xin and Shang, Lifeng and Li, Hang},
  journal={arXiv preprint arXiv:1711.00279},
  year={2017}
}
@inproceedings{wang2019task,
  title={A task in a suit and a tie: paraphrase generation with semantic augmentation},
  author={Wang, Su and Gupta, Rahul and Chang, Nancy and Baldridge, Jason},
  booktitle={AAAI Conference on Artificial Intelligence},
  volume={33},
  pages={7176--7183},
  year={2019}
}

@article{gupta2017deep,
  title={A deep generative framework for paraphrase generation},
  author={Gupta, Ankush and Agarwal, Arvind and Singh, Prawaan and Rai, Piyush},
  journal={arXiv preprint arXiv:1709.05074},
  year={2017}
}

% Contrastive Learning % 

@inproceedings{liu2016large,
  title={Large-margin softmax loss for convolutional neural networks.},
  author={Liu, Weiyang and Wen, Yandong and Yu, Zhiding and Yang, Meng},
  booktitle={ICML},
  volume={2},
  number={3},
  pages={7},
  year={2016}
}

@article{Oord2018RepresentationLW,
  title={Representation Learning with Contrastive Predictive Coding},
  author={A. Oord and Y. Li and Oriol Vinyals},
  journal={ArXiv},
  year={2018},
  volume={abs/1807.03748}
}

@article{gupta2020contrastive,
  title={Contrastive Learning for Weakly Supervised Phrase Grounding},
  author={Gupta, Tanmay and Vahdat, Arash and Chechik, Gal and Yang, Xiaodong and Kautz, Jan and Hoiem, Derek},
  booktitle={ECCV},
  year={2020}
}

@article{chen2020simple,
  title={A simple framework for contrastive learning of visual representations},
  author={Chen, Ting and Kornblith, Simon and Norouzi, Mohammad and Hinton, Geoffrey},
  journal={arXiv preprint arXiv:2002.05709},
  year={2020}
}

@inproceedings{he2020momentum,
  title={Momentum contrast for unsupervised visual representation learning},
  author={He, Kaiming and Fan, Haoqi and Wu, Yuxin and Xie, Saining and Girshick, Ross},
  booktitle={IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  pages={9729--9738},
  year={2020}
}

@article{chen2020improved,
  title={Improved baselines with momentum contrastive learning},
  author={Chen, Xinlei and Fan, Haoqi and Girshick, Ross and He, Kaiming},
  journal={arXiv preprint arXiv:2003.04297},
  year={2020}
}

@article{chen2020big,
  title={Big Self-Supervised Models are Strong Semi-Supervised Learners},
  author={Chen, Ting and Kornblith, Simon and Swersky, Kevin and Norouzi, Mohammad and Hinton, Geoffrey},
  journal={arXiv preprint arXiv:2006.10029},
  year={2020}
}

@article{wu2018unsupervised,
  title={Unsupervised feature learning via non-parametric instance-level discrimination},
  author={Wu, Zhirong and Xiong, Yuanjun and Yu, Stella and Lin, Dahua},
  journal={arXiv preprint arXiv:1805.01978},
  year={2018}
}

@article{henaff2019data,
  title={Data-efficient image recognition with contrastive predictive coding},
  author={H{\'e}naff, Olivier J and Srinivas, Aravind and De Fauw, Jeffrey and Razavi, Ali and Doersch, Carl and Eslami, SM and Oord, Aaron van den},
  journal={arXiv preprint arXiv:1905.09272},
  year={2019}
}

@article{li2020oscar,
  title={Oscar: Object-semantics aligned pre-training for vision-language tasks},
  author={Li, Xiujun and Yin, Xi and Li, Chunyuan and Hu, Xiaowei and Zhang, Pengchuan and Zhang, Lei and Wang, Lijuan and Hu, Houdong and Dong, Li and Wei, Furu and others},
  journal={arXiv preprint arXiv:2004.06165},
  year={2020}
}

@inproceedings{mikolov2013distributed,
  title={Distributed representations of words and phrases and their compositionality},
  author={Mikolov, Tomas and Sutskever, Ilya and Chen, Kai and Corrado, Greg S and Dean, Jeff},
  booktitle={Advances in neural information processing systems},
  pages={3111--3119},
  year={2013}
}

@inproceedings{Mnih2012AFA,
  title={A fast and simple algorithm for training neural probabilistic language models},
  author={A. Mnih and Y. Teh},
  booktitle={ICML},
  year={2012}
}

@article{Gutmann2012NoiseContrastiveEO,
  title={Noise-Contrastive Estimation of Unnormalized Statistical Models, with Applications to Natural Image Statistics},
  author={M. Gutmann and A. Hyv{\"a}rinen},
  journal={J. Mach. Learn. Res.},
  year={2012},
  volume={13},
  pages={307-361}
}


@inproceedings{datta2019align2ground,
  title={Align2ground: Weakly supervised phrase grounding guided by image-caption alignment},
  author={Datta, Samyak and Sikka, Karan and Roy, Anirban and Ahuja, Karuna and Parikh, Devi and Divakaran, Ajay},
  booktitle={IEEE International Conference on Computer Vision},
  pages={2601--2610},
  year={2019}
}


@article{fodor1988connectionism,
  title={Connectionism and cognitive architecture: A critical analysis},
  author={Fodor, Jerry A and Pylyshyn, Zenon W and others},
  year={1988}
}



@article{hoffman1983parts,
  title={Parts of recognition},
  author={Hoffman, Donald D and Richards, Whitman},
  year={1983}
}


@inproceedings{glove,
  author = {Jeffrey Pennington and Richard Socher and Christopher D. Manning},
  booktitle = {Empirical Methods in Natural Language Processing (EMNLP)},
  title = {GloVe: Global Vectors for Word Representation},
  year = {2014},
  pages = {1532--1543},
  url = {http://www.aclweb.org/anthology/D14-1162},
}

@inproceedings{resnet,
  title={Deep residual learning for image recognition},
  author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  booktitle={IEEE conference on computer vision and pattern recognition (CVPR)},
  pages={770--778},
  year={2016}
}


@inproceedings{ribeiro-etal-2019-red,
    title = "Are Red Roses Red? Evaluating Consistency of Question-Answering Models",
    author = "Ribeiro, Marco Tulio  and
      Guestrin, Carlos  and
      Singh, Sameer",
    booktitle = "57th Annual Meeting of the Association for Computational Linguistics",
    month = jul,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/P19-1621",
    pages = "6174--6184",
    abstract = "Although current evaluation of question-answering systems treats predictions in isolation, we need to consider the relationship between predictions to measure true understanding. A model should be penalized for answering {``}no{''} to {``}Is the rose red?{''} if it answers {``}red{''} to {``}What color is the rose?{''}. We propose a method to automatically extract such implications for instances from two QA datasets, VQA and SQuAD, which we then use to evaluate the consistency of models. Human evaluation shows these generated implications are well formed and valid. Consistency evaluation provides crucial insights into gaps in existing models, while retraining with implication-augmented data improves consistency on both synthetic and human-generated implications.",
}

@InProceedings{Hu_2017_ICCV,
author = {Hu, Ronghang and Andreas, Jacob and Rohrbach, Marcus and Darrell, Trevor and Saenko, Kate},
title = {Learning to Reason: End-To-End Module Networks for Visual Question Answering},
booktitle = {The IEEE International Conference on Computer Vision (ICCV)},
month = {Oct},
year = {2017}
}

@inproceedings{wu:blackboxnlp19,
title={Faithful Multimodal Explanation for Visual Question Answering},
author={Jialin Wu and Raymond J. Mooney},
booktitle={Second BlackboxNLP Workshop at ACL},
month={Aug},
address={Florence, Italy},
pages={103-112},
url="http://www.cs.utexas.edu/users/ai-labpub-view.php?PubID=127758",
year={2019}
}
@article{Selvaraju_2019,
   title={Grad-CAM: Visual Explanations from Deep Networks via Gradient-Based Localization},
   volume={128},
   ISSN={1573-1405},
   number={2},
   journal={International Journal of Computer Vision},
   publisher={Springer Science and Business Media LLC},
   author={Selvaraju, Ramprasaath R. and Cogswell, Michael and Das, Abhishek and Vedantam, Ramakrishna and Parikh, Devi and Batra, Dhruv},
   year={2019},
   month={Oct},
   pages={336–359}
}


@article{mochihashi2006learning,
  title={Learning an optimal distance metric in a linguistic vector space},
  author={Mochihashi, Daichi and Kikui, Genichiro and Kita, Kenji},
  journal={Systems and computers in Japan},
  volume={37},
  number={9},
  pages={12--21},
  year={2006},
  publisher={Wiley Online Library}
}

@inproceedings{li2013distance,
  title={Distance weighted cosine similarity measure for text classification},
  author={Li, Baoli and Han, Liping},
  booktitle={International Conference on Intelligent Data Engineering and Automated Learning},
  pages={611--618},
  year={2013},
  organization={Springer}
}

@article{palangi2017deep,
  title={Deep learning of grammatically-interpretable representations through question-answering},
  author={Palangi, Hamid and Smolensky, Paul and He, Xiaodong and Deng, Li},
  journal={arXiv preprint arXiv:1705.08432},
  year={2017}
}

@inproceedings{ren2015faster,
  title={Faster r-cnn: Towards real-time object detection with region proposal networks},
  author={Ren, Shaoqing and He, Kaiming and Girshick, Ross and Sun, Jian},
  booktitle=NIPS,
  year={2015}
}

@article{simonyan2014very,
  title={Very deep convolutional networks for large-scale image recognition},
  author={Simonyan, Karen and Zisserman, Andrew},
  journal={arXiv preprint arXiv:1409.1556},
  year={2014}
}

@inproceedings{Adda_CVPR2017,
author={Eric Tzeng and Judy Hoffman and Trevor Darrell and Kate Saenko},
title={Adversarial Discriminative Domain Adaptation},
booktitle=CVPR,
year={2017},
}

@inproceedings{louppe2017learning,
  title={Learning to Pivot with Adversarial Networks},
  author={Louppe, Gilles and Kagan, Michael and Cranmer, Kyle},
  booktitle=NIPS,
  pages={982--991},
  year={2017}
}

@article{mirza2014conditional,
  title={Conditional generative adversarial nets},
  author={Mirza, Mehdi and Osindero, Simon},
  journal={arXiv preprint arXiv:1411.1784},
  year={2014}
}

@inproceedings{dai2017towards,
  title={Towards Diverse and Natural Image Descriptions via a Conditional GAN},
  author={Dai, Bo and Fidler, Sanja and Urtasun, Raquel and Lin, Dahua},
  booktitle=CVPR,
  year={2017}
}

@inproceedings{zhang2017stackgan,
  title={Stackgan: Text to photo-realistic image synthesis with stacked generative adversarial networks},
  author={Zhang, Han and Xu, Tao and Li, Hongsheng and Zhang, Shaoting and Huang, Xiaolei and Wang, Xiaogang and Metaxas, Dimitris},
  booktitle=ICCV,
  year={2017}
}

@inproceedings{johnson2017clevr,
  title={CLEVR: A diagnostic dataset for compositional language and elementary visual reasoning},
  author={Johnson, Justin and Hariharan, Bharath and van der Maaten, Laurens and Fei-Fei, Li and Zitnick, C Lawrence and Girshick, Ross},
  booktitle={Computer Vision and Pattern Recognition (CVPR), 2017 IEEE Conference on},
  pages={1988--1997},
  year={2017},
  organization={IEEE}
}

@inproceedings{zhang2016yin,
  title={Yin and yang: Balancing and answering binary visual questions},
  author={Zhang, Peng and Goyal, Yash and Summers-Stay, Douglas and Batra, Dhruv and Parikh, Devi},
  booktitle={Computer Vision and Pattern Recognition (CVPR), 2016 IEEE Conference on},
  pages={5014--5022},
  year={2016},
  organization={IEEE}
}

@inproceedings{agrawal2016analyzing,
  title={Analyzing the Behavior of Visual Question Answering Models},
  author={Agrawal, Aishwarya and Batra, Dhruv and Parikh, Devi},
  booktitle={2016 Conference on Empirical Methods in Natural Language Processing},
  pages={1955--1960},
  year={2016}
}

@inproceedings{zhu2016visual7w,
  title={Visual7w: Grounded question answering in images},
  author={Zhu, Yuke and Groth, Oliver and Bernstein, Michael and Fei-Fei, Li},
  booktitle={CVPR},
  year={2016}
}


@article{burns2018women,
  title={Women also Snowboard: Overcoming Bias in Captioning Models},
  author={Burns, Kaylee and Hendricks, Lisa Anne and Darrell, Trevor and Rohrbach, Anna},
  journal={arXiv preprint arXiv:1803.09797},
  year={2018}
}

@inproceedings{gurari2018vizwiz,
  title={VizWiz Grand Challenge: Answering Visual Questions from Blind People},
  author={Gurari, Danna and Li, Qing and Stangl, Abigale J and Guo, Anhong and Lin, Chi and Grauman, Kristen and Luo, Jiebo and Bigham, Jeffrey P},
  booktitle={IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2018}
}

@inproceedings{torralba2011unbiased,
  title={Unbiased look at dataset bias},
  author={Torralba, Antonio and Efros, Alexei A},
  booktitle={IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  pages={1521--1528},
  year={2011},
}

@inproceedings{gordon2013reporting,
  title={Reporting bias and knowledge acquisition},
  author={Gordon, Jonathan and Van Durme, Benjamin},
  booktitle={2013 workshop on Automated knowledge base construction},
  pages={25--30},
  year={2013},
  organization={ACM}
}

@inproceedings{kafle2017analysis,
  title={An Analysis of Visual Question Answering Algorithms},
  author={Kafle, Kushal and Kanan, Christopher},
  booktitle={ICCV},
  year={2017}
}

@inproceedings{visdial,
  title={{V}isual {D}ialog},
  author={Abhishek Das and Satwik Kottur and Khushi Gupta and Avi Singh and Deshraj Yadav and Jos\'e M.F. Moura and
    Devi Parikh and Dhruv Batra},
  booktitle={IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2017}
}


@article{ishan,
  title={From Red Wine to Red Tomato: Composition with Context},
  author={Ishan Misra and Abhinav Gupta and Martial Hebert},
  journal={2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2017},
  pages={1160-1169}
}

@article{Krishna2016VisualGC,
  title={Visual Genome: Connecting Language and Vision Using Crowdsourced Dense Image Annotations},
  author={Ranjay Krishna and Yuke Zhu and Oliver Groth and Justin Johnson and Kenji Hata and Joshua Kravitz and Stephanie Chen and Yannis Kalantidis and Li-Jia Li and David A. Shamma and Michael S. Bernstein and Li Fei-Fei},
  journal={International Journal of Computer Vision},
  year={2016},
  volume={123},
  pages={32-73}
}


@article{Xie_2017,
   title={Aggregated Residual Transformations for Deep Neural Networks},
   journal={IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
   author={Xie, Saining and Girshick, Ross and Dollar, Piotr and Tu, Zhuowen and He, Kaiming},
   year={2017}
}


@article{LSTM,
  added-at = {2016-11-15T08:49:43.000+0100},
  author = {Hochreiter, Sepp and Schmidhuber, J{\"u}rgen},
  biburl = {https://www.bibsonomy.org/bibtex/2a4a80026d24955b267cae636aa8abe4a/dallmann},
  interhash = {0692b471c4b9ae65d00affebc09fb467},
  intrahash = {a4a80026d24955b267cae636aa8abe4a},
  journal = {Neural computation},
  keywords = {lstm rnn},
  number = 8,
  pages = {1735--1780},
  publisher = {MIT Press},
  timestamp = {2016-11-15T08:49:43.000+0100},
  title = {Long short-term memory},
  volume = 9,
  year = 1997
}

@inproceedings{schroff2015facenet,
  title={Facenet: A unified embedding for face recognition and clustering},
  author={Schroff, Florian and Kalenichenko, Dmitry and Philbin, James},
  booktitle={IEEE conference on computer vision and pattern recognition},
  pages={815--823},
  year={2015}
}

@article{Khosla2020SupervisedCL,
  title={Supervised Contrastive Learning},
  author={Prannay Khosla and Piotr Teterwak and Chen Wang and Aaron Sarna and Yonglong Tian and Phillip Isola and A. Maschinot and Ce Liu and Dilip Krishnan},
  journal={ArXiv},
  year={2020},
  volume={abs/2004.11362}
}

@article{Wolf2019HuggingFacesTS,
  title={HuggingFace's Transformers: State-of-the-art Natural Language Processing},
  author={Thomas Wolf and Lysandre Debut and Victor Sanh and Julien Chaumond and Clement Delangue and Anthony Moi and Pierric Cistac and Tim Rault and Rémi Louf and Morgan Funtowicz and Joe Davison and Sam Shleifer and Patrick von Platen and Clara Ma and Yacine Jernite and Julien Plu and Canwen Xu and Teven Le Scao and Sylvain Gugger and Mariama Drame and Quentin Lhoest and Alexander M. Rush},
  journal={ArXiv},
  year={2019},
  volume={abs/1910.03771}
}

@INPROCEEDINGS{1640964,
  author={R. {Hadsell} and S. {Chopra} and Y. {LeCun}},
  booktitle={2006 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'06)}, 
  title={Dimensionality Reduction by Learning an Invariant Mapping}, 
  year={2006},
  volume={2},
  number={},
  pages={1735-1742},}


@InProceedings{10.1007/978-3-319-46475-6_28,
author="Zhang, Liliang
and Lin, Liang
and Liang, Xiaodan
and He, Kaiming",
editor="Leibe, Bastian
and Matas, Jiri
and Sebe, Nicu
and Welling, Max",
title="Is Faster R-CNN Doing Well for Pedestrian Detection?",
booktitle="Computer Vision -- ECCV 2016",
year="2016",
publisher="Springer International Publishing",
}

@InProceedings{mariannmt,
  title     = {Marian: Fast Neural Machine Translation in {C++}},
  author    = {Junczys-Dowmunt, Marcin and Grundkiewicz, Roman and
               Dwojak, Tomasz and Hoang, Hieu and Heafield, Kenneth and
               Neckermann, Tom and Seide, Frank and Germann, Ulrich and
               Fikri Aji, Alham and Bogoychev, Nikolay and
               Martins, Andr\'{e} F. T. and Birch, Alexandra},
  booktitle = {Proceedings of ACL 2018, System Demonstrations},
  pages     = {116--121},
  publisher = {Association for Computational Linguistics},
  year      = {2018},
  month     = {July},
  address   = {Melbourne, Australia},
  url       = {http://www.aclweb.org/anthology/P18-4020}
}

@article{Zhu2015AligningBA,
  title={Aligning Books and Movies: Towards Story-Like Visual Explanations by Watching Movies and Reading Books},
  author={Yukun Zhu and Ryan Kiros and Richard S. Zemel and Ruslan Salakhutdinov and Raquel Urtasun and Antonio Torralba and Sanja Fidler},
  journal={2015 IEEE International Conference on Computer Vision (ICCV)},
  year={2015},
  pages={19-27}
}


@article{Paszke2019PyTorchAI,
  title={PyTorch: An Imperative Style, High-Performance Deep Learning Library},
  author={Adam Paszke and S. Gross and Francisco Massa and A. Lerer and J. Bradbury and G. Chanan and T. Killeen and Z. Lin and N. Gimelshein and L. Antiga and Alban Desmaison and Andreas K{\"o}pf and E. Yang and Zach DeVito and Martin Raison and Alykhan Tejani and Sasank Chilamkurthy and B. Steiner and Lu Fang and Junjie Bai and Soumith Chintala},
  journal={ArXiv},
  year={2019},
  volume={abs/1912.01703}
}

@inproceedings{krizhevsky2012imagenet,
  title={Imagenet classification with deep convolutional neural networks},
  author={Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E},
  booktitle={Advances in neural information processing systems},
  pages={1097--1105},
  year={2012}
}

@inproceedings{youcook,
author = {Das, P. and Xu, C. and Doell, R. F. and Corso J. J.},
booktitle = {{Proceedings of IEEE Conference on Computer Vision
and Pattern Recognition}},
title = {A Thousand Frames in Just a Few Words: Lingual Description
of Videos through Latent Topics and Sparse Object Stitching},
year = {2013}
}

@article{mcmillen2017,
    author={R. McMillen and F. Alter},
    title={Social media, social inclusion, and museum disability access},
    journal={Museums and Social Issues},
    volume={12},
    number={2},
    pages={pp.\ 115--125},
    year={2017}
}

@article{crudden1999,
    author={A. Crudden and L. W. McBroom},
    title={Barriers to employment: A survey of employed persons who are visually impaired},
    journal={Journal of Visual Impairment and Blindness},
    volume={93},
    number={6},
    pages={pp.\ 341--350},
    year={1999}
}

@article{shaw2007,
    author={A. Shaw, D. Gold and K. Wolffe},
    title={Employment-related experiences of youths who are visually impaired: How are these youths faring?},
    journal={Journal of Visual Impairment and Blindness},
    volume={101},
    number={1},
    pages={pp.\ 7--21},
    year={2007}
}

@article{bell2018,
    author={Edward C. Bell and Arielle M. Silverman},
    title={Rehabilitation and employment outcomes for adults who are blind or visually impaired: An updated report},
    journal={Journal of Blindness Innovation and Research},
    volume={8},
    number={1},
    year={2018}
}

@article{mcdonnall2019,
    author={M. McDonnall and Z. Sui},
    title={Employment and unemployment rates of people who are blind or visually
impaired: Estimates from multiple sources},
    journal={Journal of Visual Impairment and Blindness},
    volume={113},
    number={6},
    pages={pp.\ 481--492},
    year={2019}
}

@article{kirchner2005,
    author={C. Kirchner and B. Smith},
    title={Transition to what? Education and employment outcomes for visually
impaired youths after high school},
    journal={Journal of Visual Impairment and Blindness},
    volume={99},
    number={8},
    pages={pp.\ 499--504},
    year={2005}
}


@article{plummer2015,
    author={B. Plummer, L. Wang, C. M. Cervantes, J. C. Caicedo, J. Hockenmaier and S. Lazebnik},
    title={Flickr30k entities: Collecting region-to-phrase correspondences for richer image-to-sentence models},
    journal={IEEE International Conference on Computer Vision, ICCV},
    year={2015}
}


@book{meyers2016applied,
  title={Applied multivariate research: Design and interpretation},
  author={Meyers, Lawrence S and Gamst, Glenn and Guarino, Anthony J},
  year={2016},
  publisher={Sage Publications}
}

@book{warner2012applied,
  title={Applied statistics: From bivariate through multivariate techniques},
  author={Warner, Rebecca M},
  year={2012},
  publisher={Sage Publications}
}


https://adrianroselli.com/2020/06/accessibe-will-get-you-sued.html


@inproceedings{siri_talks,
author = {Abdolrahmani, Ali and Kuber, Ravi and Branham, Stacy M.},
title = {"Siri Talks at You": An Empirical Investigation of Voice-Activated Personal Assistant (VAPA) Usage by Individuals Who Are Blind},
year = {2018},
booktitle = {International ACM SIGACCESS Conference on Computers and Accessibility (ASSETS)},
pages = {249–258},
}


@article{audio_benefit,
author = {Pablo Romero-Fresco and Louise Fryer},
title ={Could Audio-Described Films Benefit from Audio Introductions? An Audience Response Study},
journal = {Journal of Visual Impairment and Blindness},
volume = {107},
number = {4},
pages = {287-295},
year = {2013},
}

@article{gain_loss,
author = {Perego, Elisa},
year = {2016},
month = {09},
pages = {424-444},
title = {Gains and losses of watching audio described films for sighted viewers},
volume = {28},
journal = {Target. International Journal of Translation Studies},
}


@book{ellis2019disability,
  title={Disability and digital television cultures: Representation, access, and reception},
  author={Ellis, Katie},
  year={2019},
  publisher={Routledge}
}

@article{packer2015overview,
  title={An overview of video description: history, benefits, and guidelines},
  author={Packer, Jaclyn and Vizenor, Katie and Miele, Joshua A},
  journal={Journal of Visual Impairment \& Blindness},
  volume={109},
  number={2},
  pages={83--93},
  year={2015},
}

@article{morash2015guiding,
  title={Guiding novice web workers in making image descriptions using templates},
  author={Morash, Valerie S and Siu, Yue-Ting and Miele, Joshua A and Hasty, Lucia and Landau, Steven},
  journal={ACM Transactions on Accessible Computing},
  volume={7},
  number={4},
  pages={1--21},
  year={2015},
}

@article{warren1976blindness,
  title={Blindness and early development: Issues in research methodology},
  author={Warren, David H},
  journal={Journal of Visual Impairment and Blindness},
  volume={70},
  number={2},
  pages={53--60},
  year={1976},
}


@inproceedings{bodi_2021,
author = {Bodi, Aditya and Fazli, Pooyan and Ihorn, Shasta and Siu, Yue-Ting and Scott, Andrew T and Narins, Lothar and Kant, Yash and Das, Abhishek and Yoon, Ilmi},
title = {Automated Video Description for Blind and Low Vision Users},
year = {2021},
booktitle = {ACM SIGCHI Conference Extended Abstracts on Human Factors in Computing Systems (CHI)},
}


@inproceedings{omniscribe,
author = {Chang, Ruei-Che and Ting, Chao-Hsien and Hung, Chia-Sheng and Lee, Wan-Chen and Chen, Liang-Jin and Chao, Yu-Tzu and Chen, Bing-Yu and Guo, Anhong},
title = {OmniScribe: Authoring Immersive Audio Descriptions for 360° Videos},
year = {2022},
booktitle = {ACM Symposium on User Interface Software and Technology (UIST)},
}

@misc{ihorn2021narrationbot,
  title={NarrationBot and InfoBot: A Hybrid System for Automated Video Description},
  author={Ihorn, Shasta and Siu, Yue-Ting and Bodi, Aditya and Narins, Lothar and Castanon, Jose M and Kant, Yash and Das, Abhishek and Yoon, Ilmi and Fazli, Pooyan},
  year={2021},
  howpublished={arXiv:2111.03994 [cs.CV]}
}

@inproceedings{yuksel2020increasing,
  title={Increasing video accessibility for visually impaired users with human-in-the-loop machine learning},
  author={Yuksel, Beste F and Kim, Soo Jung and Jin, Seung Jung and Lee, Joshua Junhee and Fazli, Pooyan and Mathur, Umang and Bisht, Vaishali and Yoon, Ilmi and Siu, Yue-Ting and Miele, Joshua A},
  booktitle={ACM SIGCHI Conference Extended Abstracts on Human Factors in Computing Systems (CHI)},
  pages={1--9},
  year={2020}
}

@misc{chuang2023clearvid,
      title={CLearViD: Curriculum Learning for Video Description}, 
      author={Cheng-Yu Chuang and Pooyan Fazli},
      year={2023},
      howpublished={arXiv:2311.04480 [cs.CV]}
}

@inproceedings{yoon2019video,
  title={Video accessibility for the visually impaired},
  author={Yoon, Ilmi and Mathur, Umang and Gibson, Brenna and Fazli, Tirumalashetty Pooyan and Miele, Joshua},
  booktitle={International conference on machine learning AI for social good workshop},
  volume={1},
  pages={1},
  year={2019}
}

@inproceedings{liu2024artificial,
  title={Artificial Intelligence in Virtual Reality for Blind and Low Vision Individuals: Literature Review},
  author={Liu, Tianhang and Fazli, Pooyan and Jeong, Heejin},
  booktitle={Proceedings of the Human Factors and Ergonomics Society Annual Meeting},
  pages={10711813241266832},
  year={2024},
  organization={SAGE Publications Sage CA: Los Angeles, CA}
}

@misc{li2024vidhalluc,
      title={VidHalluc: Evaluating Temporal Hallucinations in Multimodal Large Language Models for Video Understanding}, 
      author={Chaoyu Li and Eun Woo Im and Pooyan Fazli},
      year={2024},
      howpublished={arXiv:2412.03735 [cs.CV]}
}

@misc{cheema2024nowuser,
      title={Describe Now: User-Driven Audio Description for Blind and Low Vision Individuals}, 
      author={Maryam Cheema and Hasti Seifi and Pooyan Fazli},
      year={2024},
      howpublished={arXiv:2411.11835 [cs.HC]}
}