@inproceedings{VideoChatGPT,
    title={{V}ideo-{C}hat{GPT}: Towards Detailed Video Understanding via Large Vision and Language Models},
    author={Maaz, Muhammad and Rasheed, Hanoona and Khan, Salman and Khan, Fahad Shahbaz},
    booktitle={62nd Annual Meeting of the Association for Computational Linguistics (ACL)},
    year={2024}
}

@article{aafaq2019video,
  title={Video Description: A Survey of Methods, Datasets, and Evaluation Metrics},
  author={Aafaq, Nayyer and Mian, Ajmal and Liu, Wei and Gilani, Syed Zulqarnain and Shah, Mubarak},
  journal={ACM Computing Surveys (CSUR)},
  volume={52},
  number={6},
  pages={1--37},
  year={2019},
  publisher={ACM New York, NY, USA}
}

@inproceedings{activity,
    title={Dense-Captioning Events in Videos},
    author={Krishna, Ranjay and Hata, Kenji and Ren, Frederic and Fei-Fei, Li and Niebles, Juan Carlos},
    booktitle={International Conference on Computer Vision (ICCV)},
    year={2017}
}

@inproceedings{bert,
  author = {Jacob Devlin and Ming{-}Wei Chang and Kenton Lee and Kristina Toutanova},
  title  = {{BERT:} Pre-training of Deep Bidirectional Transformers for Language Understanding},
  booktitle = {Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL-HLT)},
  pages        = {4171--4186},
  year         = {2019},
}

@inproceedings{bleu,
author = {Papineni, Kishore and Roukos, Salim and Ward, Todd and Zhu, Wei-Jing},
title = {{BLEU:} A Method for Automatic Evaluation of Machine Translation},
year = {2002},
booktitle = {Association for Computational Linguistics (ACL)},
pages = {311–318},
}

@inproceedings{blip2,
author = {Li, Junnan and Li, Dongxu and Savarese, Silvio and Hoi, Steven},
title = {{BLIP-2}: Bootstrapping Language-Image Pre-training with Frozen Image Encoders and Large Language Models},
year = {2023},
booktitle = {40th International Conference on Machine Learning (ICML)},
}

@inproceedings{bodi_2021,
author = {Bodi, Aditya and Fazli, Pooyan and Ihorn, Shasta and Siu, Yue-Ting and Scott, Andrew T and Narins, Lothar and Kant, Yash and Das, Abhishek and Yoon, Ilmi},
title = {Automated Video Description for Blind and Low Vision Users},
year = {2021},
booktitle = {ACM SIGCHI Conference Extended Abstracts on Human Factors in Computing Systems (CHI)},
}

@inproceedings{charades,
  author = {Sigurdsson, G.A. and Varol, G. and Wang, X. and Farhadi, A. and Laptev, I. and Gupta, A.},
  title = {Hollywood in Homes: Crowdsourcing Data Collection for Activity Understanding},
  booktitle = {European Conference on Computer Vision (ECCV)},
  year = {2016},
 
  pages = {510-526},
 
}

@misc{charadesego,
    title={{Charades-Ego:} A Large-Scale Dataset of Paired Third and First Person Videos},
    author={Sigurdsson, Gunnar A. and Gupta, Abhinav and Schmid, Cordelia and Farhadi, Ali and Alahari, Karteek},
    year={2018},
    howpublished={arXiv:1804.09626 [cs.CV]}
}

@article{chen2022msrvideo,
  title={The {MSR}-{V}ideo to Text Dataset with Clean Annotations},
  author={Chen, Haoran and Li, Jianmin and Frintrop, Simone and Hu, Xiaolin},
  journal={Computer Vision and Image Understanding (CVIU)},
  pages={103581},
  year={2022},
}

@misc{chen2023valor,
    title={{VALOR:} Vision-Audio-Language Omni-Perception Pretraining Model and Dataset},
    author={Chen, Sihan and He, Xingjian and Guo, Longteng and Zhu, Xinxin and Wang, Weining and Tang, Jinhui and Liu, Jing},
    year={2023},
    howpublished={arXiv:2304.08345 [cs.LG]}
}

@inproceedings{cider,
author = {Ramakrishna Vedantam and C. Lawrence Zitnick and Devi Parikh},
booktitle = {IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
title = {{CIDE}r: Consensus-based Image Description Evaluation},
year = {2015},
pages = {4566-4575}
}

@InProceedings{cmd,
      title={{Condensed Movies:} Story Based Retrieval with Contextual Embeddings}, 
      author={Max Bain and Arsha Nagrani and Andrew Brown and Andrew Zisserman},
      booktitle={Asian Conference on Computer Vision (ACCV)},
      year={2020},
}

@inproceedings{cot_prompt,
title={Chain of Thought Prompting Elicits Reasoning in Large Language Models},
author={Jason Wei and Xuezhi Wang and Dale Schuurmans and Maarten Bosma and brian ichter and Fei Xia and Ed H. Chi and Quoc V Le and Denny Zhou},
booktitle={Advances in Neural Information Processing Systems (NeurIPS)},
year={2022}
}

@inproceedings{crossa11y,
   title={CrossA11y: Identifying Video Accessibility Issues via Cross-modal Grounding},
   booktitle={ACM Symposium on User Interface Software and Technology (UIST)},
   author={Liu, Xingyu “Bruce” and Wang, Ruolin and Li, Dingzeyu and Chen, Xiang Anthony and Pavel, Amy},
   year={2022},
}

@inproceedings{fewshot,
 author = {Brown, Tom and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared D and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and Agarwal, Sandhini and Herbert-Voss, Ariel and Krueger, Gretchen and Henighan, Tom and Child, Rewon and Ramesh, Aditya and Ziegler, Daniel and Wu, Jeffrey and Winter, Clemens and Hesse, Chris and Chen, Mark and Sigler, Eric and Litwin, Mateusz and Gray, Scott and Chess, Benjamin and Clark, Jack and Berner, Christopher and McCandlish, Sam and Radford, Alec and Sutskever, Ilya and Amodei, Dario},
 booktitle = {Advances in Neural Information Processing Systems (NeurIPS)},
 pages = {1877--1901},
 title = {Language Models are Few-Shot Learners},
 year = {2020}
}

@techreport{gpt2,
  title={Language Models are Unsupervised Multitask Learners},
  author={Radford, Alec and Wu, Jeffrey and Child, Rewon and Luan, David and Amodei, Dario and Sutskever, Ilya and others},
  year={2019},
  institution={OpenAI},
  number={1},
  volume={8},
}

@article{gpt4video,
  title={{GPT4V}ideo: A Unified Multimodal Large Language Model for lnstruction-Followed Understanding and Safety-Aware Generation},
  author={Zhanyu Wang and Longyue Wang and Minghao Wu and Zhen Zhao and Chenyang Lyu and Huayang Li and Deng Cai and Luping Zhou and Shuming Shi and Zhaopeng Tu},
  journal = {Computing Research Repository (CoRR)},
  year={2023}
}

@inproceedings{hdvila,
    title={Advancing High-Resolution Video-Language Representation with Large-Scale Video Transcriptions},
    author={Xue, Hongwei and Hang, Tiankai and Zeng, Yanhong and Sun, Yuchong and Liu, Bei and Yang, Huan and Fu, Jianlong and Guo, Baining},
    booktitle={International Conference on Computer Vision and Pattern Recognition (CVPR)},
    year={2022}
}

@inproceedings{hitl_blv_2020,
  title={Human-in-the-Loop Machine Learning to Increase Video Accessibility for Visually Impaired and Blind Users},
  author={Yuksel, Beste and Fazli, Pooyan and Mathur, Umang and Bisht, Vaishali and Kim, Soo Jung and Lee, Joshua Junhee and Jin, Seung Jung and Siu, Yue-Ting and Miele, Joshua A and Yoon, Ilmi},
  booktitle={ACM Conference on Designing Interactive Systems (DIS)},
  pages={47--60},
  year={2020},
}

@inproceedings{howto100m,
   title={How{T}o100{M}: {L}earning a {T}ext-{V}ideo {E}mbedding by {W}atching {H}undred {M}illion {N}arrated {V}ideo {C}lips},
   author={Miech, Antoine and Zhukov, Dimitri and Alayrac, Jean-Baptiste and Tapaswi, Makarand and Laptev, Ivan and Sivic, Josef},
   booktitle={International Conference on Computer Vision (ICCV)},
   year={2019},
}

@misc{ihorn2021narrationbot,
  title={NarrationBot and InfoBot: A Hybrid System for Automated Video Description},
  author={Ihorn, Shasta and Siu, Yue-Ting and Bodi, Aditya and Narins, Lothar and Castanon, Jose M and Kant, Yash and Das, Abhishek and Yoon, Ilmi and Fazli, Pooyan},
  year={2021},
  howpublished={arXiv:2111.03994 [cs.CV]}
}

@InProceedings{internvid,
    title={{InternVid:} A Large-scale Video-Text Dataset for Multimodal Understanding and Generation},
    author={Wang, Yi and He, Yinan and Li, Yizhuo and Li, Kunchang and Yu, Jiashuo and Ma, Xin and Li, Xinhao and Chen, Guo and Chen, Xinyuan and Wang, Yaohui and He, Conghui and Luo, Ping and Liu, Ziwei and Wang, Yali and Wang, Limin and Qiao, Yu},
    booktitle={International Conference on Learning Representations (ICLR)},
    year={2024},
}

@article{klie2023annotation,
  title={Annotation Error Detection: Analyzing the Past and Present for a More Coherent Future},
  author={Klie, Jan-Christoph and Webber, Bonnie and Gurevych, Iryna},
  journal={Computational Linguistics},
  pages={157--198},
  year={2023},
}

@inproceedings{kobayashi2010synthesized,
  title={Are Synthesized Video Descriptions Acceptable?},
  author={Kobayashi, Masatomo and O'Connell, Trisha and Gould, Bryan and Takagi, Hironobu and Asakawa, Chieko},
  booktitle={International ACM SIGACCESS Conference on Computers and Accessibility (ASSETS)},
  pages={pp.\ 163--170},
  year={2010},
}

@inproceedings{lei-etal-2020-mart,
    title = "{MART}: Memory-Augmented Recurrent Transformer for Coherent Video Paragraph Captioning",
    author = "Lei, Jie  and
      Wang, Liwei  and
      Shen, Yelong  and
      Yu, Dong  and
      Berg, Tamara  and
      Bansal, Mohit",
    booktitle = "Association for Computational Linguistics (ACL)",
    year = "2020",
    pages = "2603--2614",
}

@article{livedescribe,
author = {Carmen J. Branje and Deborah I. Fels},
title ={LiveDescribe: Can Amateur Describers Create High-Quality Audio Description?},
journal = {Journal of Visual Impairment \& Blindness (JVIB)},
number = {3},
pages = {154-165},
year = {2012},
}

@InProceedings{mad,
    author    = {Soldan, Mattia and Pardo, Alejandro and Alc\'azar, Juan Le\'on and Caba, Fabian and Zhao, Chen and Giancola, Silvio and Ghanem, Bernard},
    title     = {{MAD:} A Scalable Dataset for Language Grounding in Videos From Movie Audio Descriptions},
    booktitle = {IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
    year      = {2022},
    pages     = {5026-5035}
}
}

@misc{merlin,
    title={Merlin: Empowering Multimodal LLMs with Foresight Minds},
    author={Yu, En and Zhao, Liang and Wei, Yana and Yang, Jinrong and Wu, Dongming and Kong, Lingyu and Wei, Haoran and Wang, Tiancai and Ge, Zheng and Zhang, Xiangyu and Tao, Wenbing},
    year={2023},
    howpublished={arXiv:2312.00589 [cs.CV]}
}

@inproceedings{meteor,
author = {Lavie, Alon and Agarwal, Abhaya},
title = {Meteor: An Automatic Metric for MT Evaluation with High Levels of Correlation with Human Judgments},
year = {2007},
booktitle = {Association for Computational Linguistics (ACL)},
pages = {228–231}
}

@inproceedings{metrics,
author = {Natalie, Rosiana and Loh, Jolene and Tan, Huei Suen and Tseng, Joshua and Chan, Ian Luke Yi-Ren and Jarjue, Ebrima H and Kacorri, Hernisa and Hara, Kotaro},
title = {The Efficacy of Collaborative Authoring of Video Scene Descriptions},
year = {2021},
booktitle = {ACM SIGACCESS Conference on Computers and Accessibility (ASSETS)},
}

@inproceedings{movienet,
      author = {Huang, Q. and Xiong, Y. and Rao, A. and Wang, J. and Lin, D.},
      title = {{MovieNet:} A Holistic Dataset for Movie Understanding},
      booktitle = {European Conference on Computer Vision (ECCV)},
      year = {2020},
      pages = {709-727},
}

}

@INPROCEEDINGS{msr-vtt,
  author={Xu, Jun and Mei, Tao and Yao, Ting and Rui, Yong},
  booktitle={IEEE Conference on Computer Vision and Pattern Recognition (CVPR)}, 
  title={{MSR-VTT:} A Large Video Description Dataset for Bridging Video and Language}, 
  year={2016},
  pages={5288-5296},
}

@InProceedings{msvd,
  title = "Collecting Highly Parallel Data for Paraphrase Evaluation",
  author = "David L. Chen and William B. Dolan",
  booktitle = "Annual Meeting of the Association for Computational Linguistics (ACL)",
  year = {2011}
}

@inproceedings{ofa,
title={OFA: Unifying Architectures, Tasks, and Modalities Through a Simple Sequence-to-Sequence Learning Framework}, 
author={Peng Wang and An Yang and Rui Men and Junyang Lin and Shuai Bai and Zhikang Li and Jianxin Ma and Chang Zhou and Jingren Zhou and Hongxia Yang},
year={2022},
booktitle = {International Conference on Machine Learning (ICML)},
}

@inproceedings{optimization_prompt,
title={Large Language Models as Optimizers},
author={Chengrun Yang and Xuezhi Wang and Yifeng Lu and Hanxiao Liu and Quoc V Le and Denny Zhou and Xinyun Chen},
booktitle={International Conference on Learning Representations (ICLR)},
year={2024}
}

@inproceedings{oscar,
  author={Nguyen, Nguyen and Bi, Jing and Vosoughi, Ali and Tian, Yapeng and Fazli, Pooyan and Xu, Chenliang},
  booktitle={In Findings of the Association for Computational Linguistics (NAACL)}, 
  title={{OSC}a{R}: Object State Captioning and State Change Representation}, 
  year={2024},

}

@InProceedings{panda70m,
    title={{Panda-70M:} Captioning 70M Videos with Multiple Cross-Modality Teachers},
    author={Chen, Tsai-Shien and Siarohin, Aliaksandr and Menapace, Willi and Deyneka, Ekaterina and Chao, Hsiang-wei and Jeon, Byung Eun and Fang, Yuwei and Lee, Hsin-Ying and Ren, Jian and Yang, Ming-Hsuan and Tulyakov, Sergey},
    booktitle={IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
    year={2024}
}

@inproceedings{rescribe,
author = {Pavel, Amy and Reyes, Gabriel and Bigham, Jeffrey P.},
title = {Rescribe: Authoring and Automatically Editing Audio Descriptions},
year = {2020},
booktitle = {ACM Symposium on User Interface Software and Technology (UIST)},
pages = {747–759},
}

@inproceedings{shortscribe,
author = {Van Daele, Tess and Iyer, Akhil and Zhang, Yuning and Derry, Jalyn C and Huh, Mina and Pavel, Amy},
title = {Making Short-Form Videos Accessible with Hierarchical Video Summaries},
year = {2024},
booktitle = {ACM SIGCHI Conference on Human Factors in Computing Systems (CHI)},
}

@inproceedings{spica,
author = {Ning, Zheng and Wimer, Brianna L and Jiang, Kaiwen and Chen, Keyi and Ban, Jerrick and Tian, Yapeng and Zhao, Yuhang and Li, Toby Jia-Jun},
title = {SPICA: Interactive Video Content Exploration through Augmented Audio Descriptions for Blind or Low-Vision Viewers},
year = {2024},
booktitle = {ACM SIGCHI Conference on Human Factors in Computing Systems (CHI)},
}

@inproceedings{spice,
  title     = {SPICE: Semantic Propositional Image Caption Evaluation},
  author    = {Peter Anderson and Basura Fernando and Mark Johnson and Stephen Gould},
  year      = {2016},
  booktitle = {European Conference on Computer Vision (ECCV)}
}

@inproceedings{tag2text,
title={{Tag2Text:} Guiding Vision-Language Model via Image Tagging},
author={Xinyu Huang and Youcai Zhang and Jinyu Ma and Weiwei Tian and Rui Feng and Yuejie Zhang and Yaqian Li and Yandong Guo and Lei Zhang},
booktitle={The Twelfth International Conference on Learning Representations (ICLR)},
year={2024}
}

@InProceedings{tvc,
author={Lei, Jie and Yu, Licheng and Berg, Tamara L. and Bansal, Mohit},
title={{TVR:} A Large-Scale Dataset for Video-Subtitle Moment Retrieval},
booktitle={European Conference on Computer Vision (ECCV)},
year={2020},
pages={447--463},
}

@inproceedings{vast,
title={{VAST}: A Vision-Audio-Subtitle-Text Omni-Modality Foundation Model and Dataset},
author={Sihan Chen and Handong Li and Qunbo Wang and Zijia Zhao and Mingzhen Sun and Xinxin Zhu and Jing Liu},
booktitle={Advances in Neural Information Processing Systems (NeurIPS)},
year={2023}
}

@InProceedings{vatex,
author = {Wang, Xin and Wu, Jiawei and Chen, Junkun and Li, Lei and Wang, Yuan-Fang and Wang, William Yang},
title = {{VaTeX:} A Large-Scale, High-Quality Multilingual Dataset for Video-and-Language Research},
booktitle = {International Conference on Computer Vision (ICCV)},
year = {2019}
}

@misc{vicuna,
  title={Instruction Tuning with GPT-4},
  author={Peng, Baolin and Li, Chunyuan and He, Pengcheng and Galley, Michel and Gao, Jianfeng},
  year={2023},
  howpublished={arXiv:2304.03277 [cs.CV]}
}

@inproceedings{vid2seq,
  title={Vid2Seq: Large-Scale Pretraining of a Visual Language Model for Dense Video Captioning}, 
  author={Antoine Yang and Arsha Nagrani and Paul Hongsuck Seo and Antoine Miech and Jordi Pont-Tuset and Ivan Laptev and Josef Sivic and Cordelia Schmid},
  booktitle={IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2023}
}

@inproceedings{video_scene_natalie_2022,
author = {Natalie, Rosiana},
title = {Cost-effective and Collaborative Methods to Author Video’s Scene Description for Blind People.},
year = {2022},
booktitle = {ACM SIGCHI Conference Extended Abstracts on Human Factors in Computing Systems (CHI)},
}

@InProceedings{videocc,
author="Nagrani, Arsha and Seo, Paul Hongsuck and Seybold, Bryan and Hauth, Anja and Manen, Santiago and Sun, Chen and Schmid, Cordelia",
title="Learning Audio-Video Modalities from Image Captions",
booktitle="European Conference on Computer Vision (ECCV)",
year="2022",
pages="407--426"
}

@inproceedings{videollama,
    title = "Video-{LL}a{MA}: An Instruction-tuned Audio-Visual Language Model for Video Understanding",
    author = "Zhang, Hang and Li, Xin and Bing, Lidong",
    booktitle = "Conference on Empirical Methods in Natural Language Processing: System Demonstrations (EMNLP)",
    year = "2023",
    pages = "543--553"
}

@misc{videollava,
    title={{V}ideo-{LL}a{VA}: Learning United Visual Representation by Alignment Before Projection},
    author={Lin, Bin and Ye, Yang and Zhu, Bin and Cui, Jiaxi and Ning, Munan and Jin, Peng and Yuan, Li},
    year={2023},
    howpublished={arXiv:2311.10122 [cs.CV]}
}

@article{videoxum,
  author    = {Lin, Jingyang and Hua, Hang and Chen, Ming and Li, Yikang and Hsiao, Jenhao and Ho, Chiuman and Luo, Jiebo},
  title     = {{VideoXum:} Cross-modal Visual and Textural Summarization of Videos},
  journal   = {IEEE Transactions on Multimedia (TMM)},
  year      = {2023}
}

@inproceedings{vitt,

    title = "Multimodal Pretraining for Dense Video Captioning",
    author = "Huang, Gabriel and Pang, Bo and Zhu, Zhenhai and Rivera, Clara and Soricut, Radu",
    booktitle = "1st Conference of the Asia-Pacific Chapter of the Association for Computational Linguistics and the 10th International Joint Conference on Natural Language Processing (AACL-IJCNLP)",
    year = "2020",
    pages = "470--490"
}

@misc{vtimellm,
    title={{VT}ime{LLM}: Empower LLM to Grasp Video Moments},
    author={Huang, Bin and Wang, Xin and Chen, Hong and Song, Zihan and Zhu, Wenwu},
    year={2023},
    howpublished={arXiv:2311.18445 [cs.CV]}
}

@InProceedings{webvid,
  author       = "Max Bain and Arsha Nagrani and G{\"u}l Varol and Andrew Zisserman",
  title        = "{Frozen in Time:} A Joint Video and Image Encoder for End-to-End Retrieval",
  booktitle    = "IEEE International Conference on Computer Vision (ICCV)",
  year         = "2021",
}

@inproceedings{youcook2,
    author = {Zhou, Luowei and Xu, Chenliang and Corso, Jason J.},
    title = {Towards Automatic Learning of Procedures from Web Instructional Videos},
    year = {2018},
    booktitle = {AAAI Conference on Artificial Intelligence (AAAI)},
}

@misc{youkumplug,
    title={{Youku-mPLUG:} A 10 Million Large-scale Chinese Video-Language Dataset for Pre-training and Benchmarks},
    author={Xu, Haiyang and Ye, Qinghao and Wu, Xuan and Yan, Ming and Miao, Yuan and Ye, Jiabo and Xu, Guohai and Hu, Anwen and Shi, Yaya and Xu, Guangwei and Li, Chenliang and Qian, Qi and Que, Maofei and Zhang, Ji and Zeng, Xiao and Huang, Fei},
    year={2023},
    howpublished={arXiv:2306.04362 [cs.CV]}
}

@inproceedings{yt-temporal,
      title={{MERLOT Reserve}: Neural Script Knowledge through Vision and Language and Sound}, 
      author={Rowan Zellers and Jiasen Lu and Ximing Lu and Youngjae Yu and Yanpeng Zhao and Mohammadreza Salehi and Aditya Kusupati and Jack Hessel and Ali Farhadi and Yejin Choi},
      year={2022},
      booktitle={IEEE Conference on Computer Vision and Pattern Recognition (CVPR)}
}

@inproceedings{yuksel2020increasing,
  title={Increasing video accessibility for visually impaired users with human-in-the-loop machine learning},
  author={Yuksel, Beste F and Kim, Soo Jung and Jin, Seung Jung and Lee, Joshua Junhee and Fazli, Pooyan and Mathur, Umang and Bisht, Vaishali and Yoon, Ilmi and Siu, Yue-Ting and Miele, Joshua A},
  booktitle={ACM SIGCHI Conference Extended Abstracts on Human Factors in Computing Systems (CHI)},
  pages={1--9},
  year={2020}
}

@inproceedings{zhao2023lavila,
  title={Learning Video Representations from Large Language Models},
  author={Zhao, Yue and Misra, Ishan and Kr{\"a}henb{\"u}hl, Philipp and Girdhar, Rohit},
  booktitle={IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2023}
}

