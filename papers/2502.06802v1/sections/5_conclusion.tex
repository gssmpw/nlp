\section{Conclusion}

\subsection{Summary}
In this paper, we proposed a novel approach to improving game recommendations on Roblox by leveraging in-game text understanding and large language models (LLMs). Our method consists of two stages: Game Profile Generation, which extracts and structures raw in-game text into meaningful profiles, and an LLM-Based Reranker, which validates the effectiveness of these profiles through personalized reranking. It successfully demonstrates the value of in-game text understanding in enhancing recommendation relevance and aligning results more closely with user interests. Experimental results show that incorporating content-driven insights can improve recommendation quality, providing a strong foundation for future improvements in game recommendation systems.

\subsection{Limitations}
Despite its effectiveness, our method faces several limitations. First, the game features and taxonomies generated by LLMs remain somewhat vague and lack fine-grained distinctions. For example, while Roblox hosts a variety of games broadly categorized as simulation, adventure, or obby, user preferences often require more granular profiling to accurately capture nuanced interests. Second, the reranker, in its current form, relies solely on the LLM's general knowledge and lacks the ability to incorporate dataset-specific popularity and statistical features. This limitation arises because the LLM is not fine-tuned on the Roblox dataset, preventing it from fully leveraging platform-specific trends and user behavior patterns. Lastly, while the dynamic nature of Roblox introduces challenges in profiling new games, this can largely be addressed by profiling games only after they surpass a certain popularity or usage threshold, minimizing computational overhead. Together, these challenges highlight the need for improvements in granularity, dataset-specific adaptation, and profiling strategies.

\subsection{Future Work}
To address these limitations, future work should focus on several key areas. First, enhancing the game profile generation process to produce finer-grained and more detailed representations of user preferences and game attributes will be critical for improving personalization. Second, fine-tuning LLMs on Roblox-specific data is an essential next step to better capture platform-specific statistics and popularity trends. This fine-tuning will enable the reranker to incorporate dataset-specific insights, such as the relative popularity of games and temporal user behavior patterns, alongside general content-based understanding. Additionally, integrating multimodal data, such as game visuals, audio cues, and user interaction logs, will provide a richer context for recommendations. Future developments should also explore personalized sort generation. By leveraging the personalized reranking strategy, it would be possible to create user-specific ranking lists with tailored sort names that align with individual preferences. For example, users with a strong interest in adventure games could receive a customized "Top Adventures for You" sort, enhancing engagement through more relatable and intuitive categorizations.