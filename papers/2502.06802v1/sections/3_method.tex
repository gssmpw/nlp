\input{figures/in_game_text}

\section{Proposed Method}
In this section, we present a two-part pipeline designed to integrate content-driven insights into Roblox’s recommendation system. The pipeline comprises (1) Game Profile Generation, which involves extracting and structuring in-game text into detailed game profiles, and (2) LLM-Based Reranker, where these profiles are leveraged to re-rank existing recommendations and validate their effectiveness in enhancing relevance and personalization.

\subsection{Game Profile Generation}
The first component of our method is Game Profile Generation, which focuses on creating high-quality, structured profiles from raw in-game text. Given the diversity of games on Roblox and the inconsistency in developer-provided descriptions, we approach this by analyzing text that appears naturally within gameplay, as developers often guide players through instructions and cues during play. The main steps in this process are as follows:

\subsubsection{In-Game Text Extraction}
We start by extracting all in-game text elements that players encounter within the game environment, including instructions, background descriptions, button prompts, and other guidance. This text provides valuable insights into the game’s genre, objectives, themes, mechanics, and language. To effectively capture this information, we aggregate all in-game text into a single file, which serves as the input for the LLM. This approach, inspired by code understanding techniques, allows the model to analyze the game content holistically.

If the concatenated in-game text exceeds the LLM’s maximum token limit, we employ random sampling to reduce the text length, ensuring that diverse game content is represented while fitting within the token limit. Rather than directly filtering out noisy text, we use carefully designed prompts to instruct the LLM to focus on relevant game aspects, ignoring irrelevant content. This prompt-based approach helps the LLM extract useful information about the game’s core elements, such as gameplay objectives, genre, and mechanics, without manual preprocessing. To illustrate, Figure~\ref{fig:in_game_text} shows various types of in-game text that enhance our understanding of the game, including gameplay instructions, background context, action prompts, and language cues. By consolidating this text and guiding the LLM’s focus, we generate accurate, structured game profiles that support enhanced recommendations.

\subsubsection{Game Profile Generation via LLMs}
After preparing the in-game text file, we employ a specially crafted prompt for the LLM to generate a structured game profile, focusing on essential attributes while filtering out irrelevant information. The prompt directs the LLM to produce a concise summary that highlights the game’s main theme, storyline, primary objectives, and core mechanics. This summary helps the recommendation system grasp the game’s core characteristics, enabling more personalized matches with user preferences. Additionally, the LLM identifies the game genre—such as “obby” (obstacle course), “simulator,” “adventure,” or “role-playing”—which further aids in categorizing the game according to its play style. The prompt also guides the LLM to determine the target audience, considering factors such as age appropriateness (e.g., kids, teens, all ages) and gameplay appeal (e.g., casual or competitive players), ensuring that recommendations align with demographic interests.

Beyond the general overview, the prompt enables the LLM to extract key features, such as multiplayer modes, customization options, in-game purchases, and unique controls, which distinguish the game and enhance its engagement potential. It also directs the model to note any additional content, including seasonal updates, exclusive items, or special events, which contribute to the game’s dynamic appeal. If the game language is specified as “NONE,” the prompt instructs the LLM to determine the language based on the in-game text, enhancing accessibility for players by allowing language-based recommendations. Finally, the LLM assesses the game’s scale, considering aspects like game world size, level count, and gameplay duration, to provide a sense of the game’s scope and depth, which can influence player engagement. This well-structured prompt allows the LLM to output a JSON-formatted profile encompassing all vital attributes, essential for robust, content-driven recommendations. For the full prompt details and structure, refer to the appendix.

\subsection{LLM-Based Reranker}
With the game profiles generated, the next step is to assess their effectiveness using an LLM-Based Reranker. This component re-evaluates the initial recommendations by incorporating content-rich game profiles, enabling us to measure how well in-game text understanding enhances recommendation quality. The reranker focuses specifically on the top 30 recommendations from the initial ranking list, despite the full list containing up to 250 games. This focus on the top 30 is based on two main factors: user engagement patterns and the benefits of a concise input for the LLM. Firstly, user data shows that players primarily interact with the top 30 games, making this subset the most relevant for testing and improving recommendation quality. Prioritizing the top 30 ensures that the reranker optimizes suggestions within the list segment most likely to impact user experience.

The LLM-Based Reranker consists of three sequential steps, each designed to enhance recommendation quality by incorporating user preferences directly into the reranking process. This reranker builds on the generated game profiles and user-specific data to adapt recommendations in a personalized, content-driven manner. Detailed prompts for each step are provided in the appendix to offer transparency and replicability in how these results are achieved.

\subsubsection{User Profile Generation}
The first step in the reranking process is to create a user profile that captures individual preferences. Using the generated game profiles as context, we take the user’s play history over the past seven days and convert each game ID in this history into its corresponding game profile. This conversion produces a sequence of game profiles that reflects the user’s recent interactions and interests. We then use a specially designed user profile prompt to guide the LLM in summarizing this sequence, producing a comprehensive user profile that highlights the user’s preferred genres, themes, mechanics, and gameplay styles.

\subsection{Personalized Reranking Strategy Generation}
With the user profile generated, the next step is to create a personalized reranking strategy tailored to the current user’s preferences. By feeding the user profile into the LLM, we generate a customized strategy that outlines specific attributes or themes the reranker should prioritize for this user. This strategy acts as a guideline for the reranking process, informing the LLM about the most relevant aspects of game content for the user—such as preferred genres, gameplay mechanics, or unique features—so it can adjust the recommendations accordingly.

\subsubsection{Reranking the Top 30 List}
In the final step, the reranker applies the personalized strategy to re-evaluate and reorder the top 30 recommendations. Working with this concise list focuses the LLM’s attention on the most impactful portion of the ranking, where user engagement is highest. By following the guidelines outlined in the personalized reranking strategy, the LLM re-ranks these top 30 games based on their alignment with the user profile. This process prioritizes games that closely match the user’s preferences, delivering a refined recommendation list that is both relevant and engaging.

