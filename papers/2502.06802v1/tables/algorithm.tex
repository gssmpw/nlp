\begin{algorithm}[htbp]
\caption{Game Profile Generation and LLM-Based Reranking}
\label{alg:reranking}
\DontPrintSemicolon
\SetKwInOut{Input}{Input}\SetKwInOut{Output}{Output}

\Input{
- Set of games $\mathcal{G}$

- For each game $g \in \mathcal{G}$, in-game text $T_g$

- User $u$, with play history $\mathcal{H}_u$ (games played in last 7 days)

- Initial recommendation list $\mathcal{R}_u$ (up to 250 games)
}

\Output{Re-ranked top 30 recommendation list $\mathcal{R}'_u$}

\BlankLine

\textbf{Game Profile Generation:}

\ForEach{game $g \in \mathcal{G}$}{
    Extract in-game text $T_g$\;
    \If{length of $T_g$ exceeds LLM's max token limit}{
        Apply random sampling to reduce length of $T_g$\;
    }
    Generate game profile $P_g$ using LLM with prompt, based on $T_g$\;
}

\BlankLine
\textbf{LLM-Based Reranking:}

\textbf{User Profile Generation:}

Retrieve user's play history $\mathcal{H}_u$\;

Obtain game profiles $\{P_h \mid h \in \mathcal{H}_u\}$\;

Generate user profile $P_u$ using LLM with prompt, based on $\{P_h \mid h \in \mathcal{H}_u\}$\;

\BlankLine
\textbf{Personalized Reranking Strategy Generation:}

Generate personalized reranking strategy $S_u$ using LLM with prompt, based on $P_u$\;

\BlankLine
\textbf{Reranking the Top 30 List:}

Extract top 30 games $\mathcal{R}_u^{30}$ from initial recommendation list $\mathcal{R}_u$\;

Obtain game profiles $\{P_g \mid g \in \mathcal{R}_u^{30}\}$\;

Re-rank $\mathcal{R}_u^{30}$ to obtain $\mathcal{R}'_u$, based on alignment between $P_g$ and $P_u$, guided by $S_u$\;
\end{algorithm}
