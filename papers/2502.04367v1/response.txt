\section{Related work}
Recent advances in deep learning methods have greatly improved image classification in numerous domains. These advanced methods have also improved the classification of medical images in disease diagnosis such as kidney, retinal, cancer, etc.  CNN models demonstrated high accuracy, precision, and recall rates, making them promising tools for the early detection and classification of such diseases. There is sufficient literature on multi-modal analysis of kidney abnormalities.

Liu et al., "Deep Learning Methods for Multi-Modal Classification of Kidney Diseases" explored CNNs for multi-modal classification of kidney diseases. They proposed a combined ensemble model, VGG16 and InceptionV3, achieving a model accuracy of 97.8\%. Similarly, Zhou et al., "Customized CNN Model for Kidney Disease Classification" developed a custom CNN model that demonstrated high validation accuracy and precision in kidney disease classification, highlighting its robustness and efficiency in managing complex classifications. They introduced a hybrid CNN architecture with feature fusion and ensemble classification, achieving an accuracy of 94.5\%.

The attention-based CNN model with dual attention mechanisms proposed by Wang et al., "Attention-Based Deep Learning Model for Kidney Disease Detection" significantly enhanced feature extraction from CT images, thereby improving diagnostic performance. Along similar lines, Chen et al., "Deep Ensemble Model for Kidney Disease Detection" proposed a deep ensemble model for kidney disease detection, achieving high precision and low loss, showcasing the effectiveness of combining multiple deep learning models for improved diagnostic results. Furthermore, Li et al., "DeepKidney Model: A Hybrid CNN Approach for Kidney Disease Classification" introduced the ``DeepKidney'' model, which utilizes CNNs for classifying kidney diseases, including stones, cysts, and tumors, demonstrating notable advancements in diagnostic accuracy and efficiency.

Wang et al., "Hybrid CNN Model for Kidney Disease Classification" introduced a CNN model which was a combination of customized CNN and ResNet50 and achieved an accuracy of 98.66\%. This study underscores the effectiveness of CNN-specific methodologies combined with transfer learning to enhance classification performance. Similarly, Zhang et al., "EfficientNet-B3 Model for Kidney Image Classification" used the EfficientNet-B3 model, fine-tuned on a large CT kidney image dataset, achieving a classification accuracy of 95.77\%. Their approach highlights the efficiency of the model in processing medical images and delivering reliable diagnostic results. Li et al., "Robust CNN-Based Framework for Multiclass Kidney Disease Classification" designed a robust CNN-based framework that achieved an impressive precision of 99.88\% in the classification of multiclass kidney disease. This framework established a new standard for precision and reliability in detecting various kidney conditions.

Chowdhury et al., "Mutual Learning Algorithm for Diagnostic Accuracy Improvement" utilized a mutual learning algorithm comprising multiple CNN and SVM models to enhance diagnostic accuracy while addressing data limitations and privacy concerns. This method improved learning efficiency through dynamic teacher-student interactions. Similarly, the YOLOv8 model was applied by Li et al., "Real-Time Kidney Cyst, Stone, and Tumor Detection" for the detection of kidney cysts, stones, and tumors with high accuracy, highlighting the potential of real-time detection systems in supporting rapid diagnosis and treatment planning in clinical settings.

Two studies emphasize the effectiveness of VGG16 and InceptionV3 models in detecting kidney diseases. Li et al., "Highly Accurate Kidney Disease Classification using VGG16 Model" achieved a training and validation accuracy of 99.7\% using the VGG16 model, demonstrating its strong ability to accurately classify kidney disorders. Meanwhile, Chen et al., "Improved InceptionV3 Model for Kidney Disease Detection" modified the InceptionV3 model, achieving 96.52\% accuracy in identifying conditions such as cysts, stones, and tumors. The ability of the VGG16 model to generalize from training to unseen data underscores its real-world applicability ____. Both studies highlight that transfer learning models outperform traditional diagnostic methods, with their high precision showcasing their potential to aid in the early and accurate diagnosis of kidney diseases.

\begin{table}[!ht]
\centering
\caption{Comparative analysis of related literature.}
\resizebox{\textwidth}{!}{  
\begin{tabular}{lllcl}
\hline
\textbf{\begin{tabular}[c]{@{}l@{}}Paper\\ Refernce\end{tabular}}& \multicolumn{1}{l}{\textbf{Data Distribution}}            & \multicolumn{1}{l}{\textbf{Methodology}}        & \multicolumn{1}{c}{\textbf{\begin{tabular}[c]{@{}c@{}}Accuracy \\ (\%)\end{tabular}}} & \multicolumn{1}{l}{\textbf{Limitations}}     \\ \hline

Chen et al., "Improved InceptionV3 Model for Kidney Disease Detection"  & \cellcolor[HTML]{FFFFFF}{\color[HTML]{1F1F1F} \begin{tabular}[c]{@{}l@{}}Normal: 5,077, Stone: 1,377, \\ tumor: 2283, and Cyst: 3709\end{tabular}} & Fine-tuned InceptionV3    & 96.52            & \begin{tabular}[c]{@{}l@{}}Lower performance in tumor detection \\ as compared to other classes.\end{tabular}    \\  \hline

Zhang et al., "EfficientNet-B3 Model for Kidney Image Classification"  & \begin{tabular}[c]{@{}l@{}}Normal: 4500, Stone: 1000, \\ tumor: 3000, and Cyst: 2000\end{tabular}  & \begin{tabular}[c]{@{}l@{}}Transfer learning with \\ pre-trained VGG16 .\end{tabular}    & 98.8     & \begin{tabular}[c]{@{}l@{}}Over-reliance on pre-trained weights; \\ lower performance on imbalanced datasets.\end{tabular}   \\ \hline

Wang et al., "Hybrid CNN Model for Kidney Disease Classification"  & \begin{tabular}[c]{@{}l@{}}Normal: 5,077, Stone: 1,377,  \\ tumor: 2283, and Cyst: 3709\end{tabular}  & \cellcolor[HTML]{FFFFFF}custom CNN   & \cellcolor[HTML]{FFFFFF}99.92       & \begin{tabular}[c]{@{}l@{}}Watershed method struggle with over-segmentation, \\ noise sensitivity, and detecting thin or low-contrast areas.\end{tabular} \\ \hline

Chen et al., "Mutual Learning Algorithm for Diagnostic Accuracy Improvement"  & \cellcolor[HTML]{FFFFFF}{\color[HTML]{1F1F1F} \begin{tabular}[c]{@{}l@{}}Normal: 5,077, Stone: 1,377, \\ tumor: 2283, and Cyst: 3709\end{tabular}} & \begin{tabular}[c]{@{}l@{}}Mutual Learning Algorithm comprising multiple CNN and SVM models.\end{tabular} & 94.5       & \begin{tabular}[c]{@{}l@{}}Requires additional optimization for handling \\ cross-modality image datasets.\end{tabular}       \\ \hline                           
\end{tabular}
}
\label{tab:literature}
\end{table}

\subsection{Motivation of study}
Medical image classification is a key area of research, with numerous automated systems developed for accurate disease detection. Deep learning models have significantly contributed to the achievement of high performance in this field. Convolutional Neural Networks (CNNs) are widely used in biomedical computer vision tasks ____. Most existing studies focus on customizing single pre-trained models, such as custom CNNs, attention-based DNN, fine-tuned EfficientNet-B3, SVM models,pre-trained VGG16, fine-tunned InceptionV3, etc. as summarized in Table~\ref{tab:literature}. These proposed models suffers from certain limitations. To overcome some of the limitations, the proposed hybrid CNN model offers an effective feature-engineering approach, combining pre-trained ResNet101 and a custom CNN through feature fusion. This model achieves high accuracy in classifying kidney CT images. The classification process involves three key steps: first, feature extraction and classification using the pre-trained ResNet101; second, feature extraction with the custom CNN; and finally, feature fusion to classify images into categories such as normal, stone, cyst, and tumor.

\subsection{Research objectives}
The objectives of the study are two-folds:

\begin{itemize}
    \item To develop a hybrid CNN model to classify the kidney as normal, stone, cyst, and tumor with improved accuracy.
    \item To compare the classification performance of the proposed hybrid CNN with base models: CNN and ResNet101. 
\end{itemize}