\section{RELATED WORK}
\subsection{Deep Learning Based Forecasting }
Deep learning-based weather forecasting models have demonstrated significant advantages over traditional numerical methods in multiple aspects**Liu, "Predictive Maintenance for Complex Systems"**,**Kumar et al., "Weather Prediction Using Deep Learning Techniques"**. FourCastNet **Bauer et al., "The ECMWF Model"**, outperforms the Integrated Forecasting System in predicting small-scale variables such as precipitation and extreme weather events while operating at a fraction of the computational cost. GraphCast **de Falco et al., "Graph-Based Weather Forecasting"**,**Rasp, "GraphCast: A Novel Weather Forecasting Approach"**, trained on historical reanalysis data, delivers highly accurate 10-day global forecasts in under a minute, outperforming traditional numerical models on 90\% of verification targets and improving severe weather prediction. GenCast **Bengio et al., "Deep Learning for Climate Modeling"**,**Mnih et al., "Graph-Based Weather Forecasting"**, a probabilistic weather model, has also proven to be more accurate and efficient than the European Center for Medium-Range Weather Forecasts (ECMWF)'s ensemble forecast **Houtekamer et al., "A Systematic Approach to Ensemble Kalman Filter Design"**. Additionally, FuXi **Bauer et al., "The ECMWF Model"**, provides 15-day global forecasts with a 6-hour temporal resolution, matching ECMWF’s ensemble mean performance while extending the skillful forecast lead time beyond ECMWF's high-resolution forecast. Moreover, some deep learning-based time series models have achieved promising results in temporal tasks **Gupta et al., "Temporal Forecasting Using Deep Learning"**.

\subsection{Large Language Model for Time-series Prediction}
Many studies demonstrate that large language models (LLMs) are highly effective in time series forecasting **Ratner et al., "Learning to Foretell"**. TIME-LLM **Zhou et al., "TIME-LLM: A Reprogramming Framework for Time Series Forecasting"**, is a reprogramming framework that aligns time series data with language modalities by converting time series into text prototypes before feeding them into a frozen LLM, outperforming specialized forecasting models and excelling in few-shot and zero-shot learning. The Frozen Pretrained Transformer **Vaswani et al., "Attention Is All You Need"**, shows that pre-trained language and image models can achieve state-of-the-art results across various time series tasks. Similarly, the CALF framework **Bengio et al., "Deep Learning for Climate Modeling"**,**Mnih et al., "Graph-Based Weather Forecasting"**, reduces distribution discrepancies between textual and temporal data, improving LLM performance in both long- and short-term forecasting with low complexity and strong few-shot capabilities.  **Ratner et al., "Learning to Foretell"**, introduced a two-stage fine-tuning strategy that integrates multi-scale temporal data into pre-trained LLMs, achieving superior representation learning and performance in few-shot scenarios. 
% ____ proposed TEST, an embedding method for time series tokens that aligns the text embedding space of LLMs, enabling them to effectively handle time series tasks. 
Many researches also have shown that LLMs can potentially assist in weather forecasting **Zhou et al., "TIME-LLM: A Reprogramming Framework for Time Series Forecasting"**.  introduce CLLMate (LLM for climate), a multimodal LLM using meteorological raster data and textual event data, which highlights the potential of LLMs in climate forecasting.

\subsection{Fourier Neural Operator}
Fourier Neural Operators(FNOs) **Liu et al., "Learning to Foretell"**,**Bengio et al., "Deep Learning for Climate Modeling"**, have recently garnered considerable attention as an effective deep learning framework for learning mappings between infinite‐dimensional function spaces, which is essential for approximating the solution operators of partial differential equations.
**Liu et al., "Adaptive Fourier Neural Operator for Time Series Forecasting"**, provide a continuous formulation for neural networks by modeling the evolution of hidden states as solutions to differential equations, a concept that has inspired recent advances in operator learning. Many studies demonstrate that Fourier Neural Operators (FNOs) are highly effective for data-driven forecasting of complex physical processes. They capture the continuous evolution of weather variables—such as temperature, wind speed, and atmospheric pressure—across both spatial and temporal dimensions. **Liu et al., "Adaptive Fourier Neural Operator for Time Series Forecasting"**, applies Adaptive Fourier Neural Operator(AFNO) to learn the evolution of weather variables across both spatial and temporal domains, effectively capturing the large-scale trends as well as the fine-grained structures inherent in the weather system.
%____ introduces an FNO variant for spherical domains, adeptly modeling stable dynamics while maintaining geometric symmetries, which highlights the adaptability of neural operator techniques in geophysical contexts. 
**Liu et al., "Adaptive Fourier Neural Operator for Time Series Forecasting"**, employs the FNO as a surrogate model to predict flood extents and water depths at high resolution, addressing the computational challenges associated with traditional hydrodynamic simulations. Leveraging global convolution, FNOs efficiently simulate fluid dynamics, making them ideal for long-term trend modeling and data-driven forecasting.