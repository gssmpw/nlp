\section{RELATED WORK}
\subsection{Deep Learning Based Forecasting }
Deep learning-based weather forecasting models have demonstrated significant advantages over traditional numerical methods in multiple aspects~\cite{leinonen2023latent, li2024cllmatemultimodalllmweather, salman2015weather,hewage2021deep}. FourCastNet \cite{pathak2022fourcastnet} outperforms the Integrated Forecasting System in predicting small-scale variables such as precipitation and extreme weather events while operating at a fraction of the computational cost. GraphCast \cite{lam2022graphcast}, trained on historical reanalysis data, delivers highly accurate 10-day global forecasts in under a minute, outperforming traditional numerical models on 90\% of verification targets and improving severe weather prediction. GenCast \cite{price2023gencast}, a probabilistic weather model, has also proven to be more accurate and efficient than the European Center for Medium-Range Weather Forecasts (ECMWF)'s ensemble forecast \cite{molteni1996ecmwf}. Additionally, FuXi \cite{chen2023fuxi} provides 15-day global forecasts with a 6-hour temporal resolution, matching ECMWF’s ensemble mean performance while extending the skillful forecast lead time beyond ECMWF's high-resolution forecast. Moreover, some deep learning-based time series models have achieved promising results in temporal tasks ~\citep{zhou2022fedformer,zhang2023crossformer,eldele2024tslanet,yi2024fouriergnn}.

\subsection{Large Language Model for Time-series Prediction}
Many studies demonstrate that large language models (LLMs) are highly effective in time series forecasting \cite{chang2023llm4ts,sun2024testtextprototypealigned}. TIME-LLM \cite{jin2023time} is a reprogramming framework that aligns time series data with language modalities by converting time series into text prototypes before feeding them into a frozen LLM, outperforming specialized forecasting models and excelling in few-shot and zero-shot learning. The Frozen Pretrained Transformer \cite{zhou2023fitsallpowergeneraltime} shows that pre-trained language and image models can achieve state-of-the-art results across various time series tasks. Similarly, the CALF framework \cite{liu2024calfaligningllmstime} reduces distribution discrepancies between textual and temporal data, improving LLM performance in both long- and short-term forecasting with low complexity and strong few-shot capabilities. \citet{chang2024llm4tsaligningpretrainedllms} introduced a two-stage fine-tuning strategy that integrates multi-scale temporal data into pre-trained LLMs, achieving superior representation learning and performance in few-shot scenarios. 
% \citet{sun2024testtextprototypealigned} proposed TEST, an embedding method for time series tokens that aligns the text embedding space of LLMs, enabling them to effectively handle time series tasks. 
Many researches also have shown that LLMs can potentially assist in weather forecasting \cite{wang2024exploringlargelanguagemodels, wang2024newsforecastintegratingevent, li2024cllmatemultimodalllmweather}. \citet{li2024cllmatemultimodalllmweather} introduce CLLMate (LLM for climate), a multimodal LLM using meteorological raster data and textual event data, which highlights the potential of LLMs in climate forecasting.


\subsection{Fourier Neural Operator}
Fourier Neural Operators(FNOs) \cite{li2020ddtcdr} have recently garnered considerable attention as an effective deep learning framework for learning mappings between infinite‐dimensional function spaces, which is essential for approximating the solution operators of partial differential equations.
\citet{chen2019neuralordinarydifferentialequations} provide a continuous formulation for neural networks by modeling the evolution of hidden states as solutions to differential equations, a concept that has inspired recent advances in operator learning.
Many studies demonstrate that Fourier Neural Operators (FNOs) are highly effective for data-driven forecasting of complex physical processes. They capture the continuous evolution of weather variables—such as temperature, wind speed, and atmospheric pressure—across both spatial and temporal dimensions. \citet{pathak2022fourcastnet} applies Adaptive Fourier Neural Operator(AFNO) to learn the evolution of weather variables across both spatial and temporal domains, effectively capturing the large-scale trends as well as the fine-grained structures inherent in the weather system.
%\citet{bonev2023spherical} introduces an FNO variant for spherical domains, adeptly modeling stable dynamics while maintaining geometric symmetries, which highlights the adaptability of neural operator techniques in geophysical contexts. 
\citet{sun2023rapid} employs the FNO as a surrogate model to predict flood extents and water depths at high resolution, addressing the computational challenges associated with traditional hydrodynamic simulations. Leveraging global convolution, FNOs efficiently simulate fluid dynamics, making them ideal for long-term trend modeling and data-driven forecasting.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%