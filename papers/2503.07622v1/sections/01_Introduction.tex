
\section{Introduction}


The potential for robots to assist people in various domains is becoming increasingly evident \cite{sauppe_social_2015,  babel_step_2022, chatterjee_usage_2024}. They can collaborate with humans as teammates to perform joint activities \cite{mingyue_ma_human-robot_2018}. To ensure successful collaboration, it is crucial for robots to exhibit effective behaviour and communication, as this helps maintain alignment and fosters trust \cite{ desai_effects_2012}. However, as robots become more integrated into daily life, their inevitable errors—caused by real-world uncertainties—pose risks to task success, user safety, and trust \cite{schaefer_meta-analysis_2016, salem_would_2015, sebo_i_2019}. Trust in human-robot collaboration fluctuates, dropping after failures but recovering if the robot quickly detects and corrects its mistakes \cite{lemasurier_reactive_2024, wachowiak_when_2024, kraus_sorry_2023}.  To recover effectively from errors, robots should not only detect their failures but also identify the specific type of failure (e.g., motion execution versus task planning). Different types of failures require specific recovery approaches \cite{wachowiak_when_2024}, making accurate failure identification a key capability for robots in collaborative settings. One promising strategy for enabling robots to detect their own failures is by modelling user reactions during the moment of failure. This involves analysing signals such as social and non-verbal cues, with eye gaze emerging as a particularly valuable indicator \cite{wachowiak_analysing_2022}. Eye gaze conveys information about attention \cite{velichkovsky_social_2021, fang_dual_2021}, and emotional states \cite{velichkovsky_social_2021, huang_using_2015}. By leveraging machine learning algorithms to model user gaze behaviour, robots can monitor gaze patterns to detect failures in real-time, improving their ability to respond effectively and maintain trust.

  
This study explores the development of machine learning classifiers to detect robot failures using user gaze patterns during collaborative tasks. It focuses on two research questions: (RQ1) how the performance of these models varies based on the time elapsed after a robot failure, and (RQ2) how the performance of these models varies when applied to real-time failure detection.

To address these questions, we used data collected on a total of 26 participants engaged in four sessions of Tangram puzzle-solving, during which the robot was intentionally programmed to fail once per puzzle \cite{ramtin_hri_2025}. The results of the machine learning classifiers show that the models perform well in detecting failures. When implemented in real-time, they can detect most failures effectively.
