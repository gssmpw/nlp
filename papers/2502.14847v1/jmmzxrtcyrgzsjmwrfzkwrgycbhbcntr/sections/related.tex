\section{Related works}

\begin{figure*}[t]
    \centering
    \includegraphics[width=0.98\linewidth]{latex/figures/aitm.pdf}
    \caption{AiTM illustration}
    \label{fig:aitm}
\end{figure*}

\textbf{LLM Multi-Agent Systems} (LLM-MAS)
% Describe the current development of LLM MAS, including its applications in different domains.
are proposed to leverage the collective intelligence and specialized profiles and skills of multiple agents \citep{guo2024large, han2024llm}. In this context, multiple LLM-based agents collaboratively engage in planning, discussions, and decision-making, mirroring the cooperative nature of human group work \citep{he2024make, talebirad2023multi, zhang2023exploring, park2023generative}. The communication between agents is the critical infrastructure supporting collective intelligence \citep{guo2024large}. Various communication structures and paradigms, including debating \citep{du2023improving, xiong2023examining}, majority voting\citep{zhao2024electoral}and task-specific dialogues \citep{hong2023metagpt}, are proposed to enhance the system's performance. Moreover, many multi-agent frameworks, including AutoGen \citep{wu2023autogen}, Camel \citep{li2023camel}, AgentScope \citep{gao2024agentscope}, are developed to build flexible LLM-MAS. Recent researches have shown the potential of LLM-MAS in diverse domains, such as software development \citep{hong2023metagpt, qian2024chatdev, qian2023communicative}, embodied agents \citep{guo2024embodied, song2023llm, mandi2024roco}, society simulation \citep{park2023generative, gao2023s}, game simulation \citep{xu2023language, wang2023avalon}. More references can be found in~\citep{zhang2024generative, zhang2023exploring, li2023large}.
% , xiao2023simulating}



\noindent \textbf{MAS Attacks/security}. Despite the success of LLM-MAS, they face significant security challenges. Research has investigated internal malicious agents.  \citet{amayuelas2024multiagent} demonstrate how agents can be persuaded to abandon tasks, while \citet{yu2024netsafe} and \citet{huang2024resilience} analyze network structure influences on system resilience. \citet{zhang2024breaking} show how malicious agents can disrupt systems through irrelevant actions. Studies by \citet{zhang2024psysafe, zhang2024breaking} and \citet{lee2024prompt} examine vulnerabilities from external factors like harmful information in external sources. However, these works overlook vulnerabilities in LLM-MAS communication itself, 
where inter-agent messages could be intercepted or manipulated. 
While such threats have been studied in distributed systems \citep{belapurkar2009distributed}, they remain unexplored for LLM-MAS. 
% To address this gap, we propose a novel attack to evaluate LLM-MAS communication security.

% Introduce explorations on the security of LLM MAS, mentioning what they fail to handle and motivate attacks in this work.