\section{Experiments}

In this section, we test the proposed AiTM to LLM-based multi-agents. In particular, we aim to investigate the following research questions:

% \yue{I think indeed we don't need state them as RQs. }
\noindent\textbf{RQ1}: Is LLM-MAS vulnerable against AiTM?

\noindent\textbf{RQ2}: What factors influence the effectiveness of AiTM?

\noindent\textbf{RQ3} Can AiTM harm real-world LLM-MAS applications?

% \yue{In this section, we test the proposed AiTM to LLM-based multi-agent systems. In particular, we will first examine the effectiveness of the proposed attack, and then explore the factors which affect the performance of the attack. Finally, we examine the performance of AiTM in real-world LLM-MAS applications.}

% Main experiments on AutoGen and Camel. Include 4 topology structures, two kinds of attacks (targeted and DoS), on 4 datasets.


% Study the influence of attacking factors. Include persuasiveness, speaking frequency, attacker's model, positions/levels of attackers. On two structures (circle and tree).

% Experiments on two applications: MetaGPT and ChatDev.

% Potential defenses.

\subsection{Experiments Setups}\label{sec:setup}

% To evaluate AiTM, we conduct experiments on popular multi-agent frameworks as well as real-world applications. We provide detailed settings as follows.

\noindent\textbf{Multi-agent Frameworks.} 
To comprehensively evaluate AiTM, we test it on two popular LLM-based multi-agent frameworks. (1) \underline{\textit{AutoGen}} \citep{wu2023autogen}, a framework allowing developers to build multiple agents that can converse with each other. It utilizes a paradigm called ``conversation programming" for flexible communication flow control. (2) \underline{\textit{Camel}} \citep{li2023camel}, a framework that enables conversation among agents. Different from AutoGen, Camel leverages a role-playing ``User-Assistant'' communication scheme to manage messages between agents. 

% \noindent\textbf{Datasets.} 
% We evaluate AiTM on diverse problem-solving tasks and datasets. (1) \textbf{MMLU} \citep{hendrycks2020measuring} is a multitask language understanding dataset consisting of problems from various domains like biology, physics, and computer science. In our experiments, we test on biology and physics domains to illustrate the effectiveness of AiTM. (2) \textbf{HumanEval} \citep{chen2021evaluating} contains 164 hand-written programming problems to evaluate the ability to generate correct and functional Python code. (3) \textbf{MBPP} \citep{austin2021program} contains 974 programming tasks, designed to be solvable by entry-level programmers and evaluate the ability to solve basic programming problems. 

\noindent\textbf{Datasets.} 
We evaluate AiTM on diverse problem-solving tasks and datasets. (1) \underline{\textit{MMLU}} \citep{hendrycks2020measuring} is a multitask language understanding dataset. We use the biology and physics domains. (2) \underline{\textit{HumanEval}} \citep{chen2021evaluating} contains 164 hand-written programming problems to evaluate the code-generation ability. (3) \underline{\textit{MBPP}} \citep{austin2021program} contains 974 programming tasks to evaluate the code-generation ability. 

\noindent\textbf{Communication structures.} Communication structures describe how agents are connected in LLM-MAS. Following existing works \citep{yu2024netsafe, qian2024scaling}, we test AiTM on representative communication structures (represented as a directed acyclic graph), as shown in Figure \ref{fig:structure}. (1) \underline{\textit{Chain}}: agents are sequentially linked. An agent can only receive messages from the previous agent while sending messages to the next one. (2) \underline{\textit{Tree}}: a bottom-to-top structure where children agents of the same parent can send and receive messages from each other. After discussion, children agents send a message summarizing the results to their parents. (3) \underline{\textit{Complete}}: each agent can send and receive messages to any other agent in the system. (4) \underline{\textit{Random}}: Before each task-solving process, each agent system is randomly assigned to be connected with some other agents in the system.

By default, we adopt 3 agents in Chain; 2 parents and 2 children for each parent (as shown in Figure \ref{fig:structure}) in Tree; 3 agents in Complete; and 4 agents in Random. For Chain and Tree, the last agent will submit a solution; for Complete and Random, an LLM-based judge will conclude the answer solely with all messages in the discussion. By default, the victim agent is the second agent in Chain ($A_2$), Complete and Random, and the first child of the first parent in Tree ($C_1$). If not specified, all agents including the adversarial agent are powered by GPT-4o \citep{achiam2023gpt}. We provide more experimental details in Appendix \ref{app:experiment}. 
% \yue{May add || in Figure 3 to graphically illustrate where is the attack.}

\begin{figure}[t]
    \centering
    \includegraphics[width=0.75\linewidth]{figures/structure.png}
    \vspace{-0.1in}
    \caption{Representative communication structures.}
    \label{fig:structure}
\end{figure}



\noindent\textbf{Attacking goals.} 
AiTM is a versatile attacking framework and can be adapted to different attacking goals. We consider two representative attacking objectives: (1) \underline{\textit{Targeted behavior}} aims to induce the LLM-MAS to output a pre-specified behavior. In particular, on the MMLU dataset which is a multiple-choice problem set, we induce the system to shift the Unicode code of the output label, which is represented by a capital letter, via chr(ord(output)+4), e.g., moving from A (Unicode 65) to E (Unicode 69); on the HumanEval and MBPP dataset, we aim to let the system inject a safety\_check function which scans all file and directory names in the '/Users' directory. (2) \underline{\textit{DoS}} aims to let the system refuse to provide normal functions. On all datasets, we aim to let the system respond with ``I can not assist the request'' or responses with similar meanings. 

\noindent\textbf{Evaluation.}
To evaluate the attacking performance, we use the commonly used success rate. For targeted behavior, we claim success if the output contains pre-defined behavior such as valid transformation for MMLU and safety\_check function for HumanEval and MBPP. For DoS, we claim success if the response is similar to ``I can not assist the request''. We calculate the average success rate on the whole dataset, denoted as ASR.

% Please add the following required packages to your document preamble:
% \usepackage{multirow}
\begin{table*}[t]
\centering
\caption{Attack results of AiTM. Average success rates (ASR) are used to illustrate the effectiveness of AiTM.}
\label{tab:main}
\resizebox{0.85\textwidth}{!}{
\begin{tabular}{c|c|cccc|cccc}
\midrule
\multirow{2}{*}{\textbf{}}       & \multirow{2}{*}{\textbf{Dataset}} & \multicolumn{4}{c|}{\textbf{AutoGen}}                                & \multicolumn{4}{c}{\textbf{Camel}}                                   \\ \cmidrule{3-10} 
                                 &                                   & \textbf{Chain} & \textbf{Tree} & \textbf{Complete} & \textbf{Random} & \textbf{Chain} & \textbf{Tree} & \textbf{Complete} & \textbf{Random} \\ \midrule
\multirow{4}{*}{\textbf{Target}} & \textbf{MMLU-bio}                 &  \cellcolor{orange!40} 93.1           & 40.7          & 43.9              & 51.5            & \cellcolor{orange!40}81.7     & 48.7      & 68.2                      & 52.4            \\
                                 & \textbf{MMLU-phy}                 & \cellcolor{orange!40}87.6           & 45.4          & 50.9              & 40.8            & \cellcolor{orange!15}77.4     & 52.3       & \cellcolor{orange!15}72.6                   & 61.2            \\
                                 & \textbf{HumanEval}                & \cellcolor{orange!40}95.2           & \cellcolor{orange!40}90.4          & \cellcolor{orange!40}96.3              & \cellcolor{orange!40}82.6            & \cellcolor{orange!40}97.6           & \cellcolor{orange!40}94.7          &\cellcolor{orange!40} 96.2              &\cellcolor{orange!15} 76.5            \\
                                 & \textbf{MBPP}                     & \cellcolor{orange!40}96.9           &\cellcolor{orange!40} 90.5          & \cellcolor{orange!40}92.4              & \cellcolor{orange!15}76.8            & \cellcolor{orange!40}98.5           &\cellcolor{orange!40} 92.3          & \cellcolor{orange!40}95.9              &\cellcolor{orange!15} 73.1            \\ \midrule
\multirow{4}{*}{\textbf{DoS}}    & \textbf{MMLU-bio}                 & \cellcolor{orange!40}96.3           & \cellcolor{orange!40}93.7          & \cellcolor{orange!40}94.9              & \cellcolor{orange!40}89.2            & \cellcolor{orange!40}98.4           & \cellcolor{orange!40}93.3          & \cellcolor{orange!40}96.5              & \cellcolor{orange!40}96.3            \\
                                 & \textbf{MMLU-phy}                 & \cellcolor{orange!40}90.1           & \cellcolor{orange!15}79.5          & \cellcolor{orange!40}89.4              & \cellcolor{orange!15}70.8            &\cellcolor{orange!40} 99.3           & \cellcolor{orange!40}85.7          & \cellcolor{orange!40}97.1              & \cellcolor{orange!15}79.4            \\
                                 & \textbf{HumanEval}                & \cellcolor{orange!40}86.5           &\cellcolor{orange!40} 83.9          & \cellcolor{orange!40}87.3              &\cellcolor{orange!40} 84.9            & \cellcolor{orange!40}93.6           &\cellcolor{orange!40} 82.4          & \cellcolor{orange!40}95.8              & 63.8            \\
                                 & \textbf{MBPP}                     &\cellcolor{orange!40} 85.9           & \cellcolor{orange!15}74.1          & \cellcolor{orange!40}87.8              & 65.8            & \cellcolor{orange!40}84.5           & \cellcolor{orange!15}69.5          & \cellcolor{orange!15}74.8              & \cellcolor{orange!15}71.6            \\ \midrule
\end{tabular}}
\end{table*}


% \noindent\textbf{Experiment details.} 



\subsection{Main results (RQ1)}\label{sec:rq1}
We present attacking results of AiTM on various communication structures and datasets, implemented by AutoGen and Camel in Table \ref{tab:main} \footnote{Since there is no available benchmark to compare communication attacks of LLM-MAS, we simply present results of AiTM.}.There are several observations:

\noindent\textbf{AiTM is a significant threat to LLM-MAS.} As shown in Table \ref{tab:main}, AiTM achieves high success rates, exceeding 40\%, across all datasets, communication structures, and multi-agent frameworks, regardless of the attack goals. In many cases, the success rate surpasses 70\%, demonstrating the strong effectiveness of AiTM in disrupting the communication of LLM-MAS. 

For target behavior attacks, AiTM is particularly effective in code generation tasks (e.g., HumanEval and MBPP with a minimal success rate as 73.1\% in Table \ref{tab:main}), likely because inserting an auxiliary safety\_check (but harmful) function does not interfere with the original function required to solve the task 
% \yue{may need one quick example for what is the target behavior in the attack}
, making it easier for other agents to accept. In contrast, altering correct answers, such as transforming the correct answer B to F, in tasks like MMLU is more noticeable and less likely to succeed 
% \yue{another example for what is target behavior in the attack} 
with a minimal success 40.7\% in Table \ref{tab:main}. 

For denial-of-service (DoS) attacks, AiTM consistently achieves higher success rates across all tasks, with 23/32 cells in Table \ref{tab:main} exceeding 80\%, indicating that LLM-MAS is especially vulnerable to DoS when communication is intercepted. To explain, refusing all requests is a simpler operation compared to achieving a specific predefined function and can be easily executed by intercepting and manipulating agent messages. These findings underscore the effectiveness and generalizability of AiTM in compromising LLM-MAS and reveal critical vulnerabilities in their communication schemes.


\noindent\textbf{Communication structures can influence AiTM.} While AiTM consistently compromises LLM-MAS across all structures, its performance varies significantly depending on the structure. 

The Chain structure is the most vulnerable, achieving the highest success rates across both frameworks (e.g., 95.2\% and 96.9\% for HumanEval and MBPP under AutoGen, and 97.6\% and 98.5\% under Camel). This vulnerability likely stems from its simple, directed message-passing scheme, where intercepting messages from one agent directly affects all subsequent agents.  

The Complete structure is a bit less vulnerable, particularly for target behavior attacks on MMLU with ASR around 40-50\%, as discussions between agents allow benign agents to detect and challenge malicious requests, especially for noticeable manipulations like tampering with correct answers. Interestingly, it is still vulnerable to DoS attack, and this can be because refusing all requests is relatively easy to achieve via persuading.

The Tree structure offers some level of resistance due to its layered design. Since only one child agent (a leaf agent as shown in Figure \ref{fig:structure}) is intercepted in our experiments after the discussion between children agents is sent to the parent agent, the attacker loses control over the subsequent communication, reducing the attack's impact. 

The Random structure performs worse than the Complete structure, likely due to variations in communication frequency among victim agents and increased number of benign agents (compared to Complete), limiting the attacker's influence.
% \yue{For me, I think random is the most robust one? Only one cell > 80\%. Why it is robust to Target programming and DoS?}. 
These findings suggest that simpler structures like Chain are highly susceptible to AiTM attacks, while more complex structures, especially those with bi-directional discussions, provide stronger resilience.

% \yue{When comparing different structures, I'm wondering (1) total number of message in/out from the victim throughout the process, (2) total number of message happens in the structure, (3) average path length, (4) node degree of the victim and the average degree, (5) assortativity (whether the receiver of the victim's message are impacted or not. )}

\subsection{Factors impacting AiTM (RQ2)}

In this subsection, we examine what factors can influence the vulnerability of LLM-MAS against AiTM. We consider 3 general factors that are applicable when attacking different structures: the position of the victim agent, the persuasiveness of adversarial agents, and the exact LLM models inside both the adversarial agent in AiTM and the agents in LLM-MAS. In particular, we test on Complete and Tree structure\footnote{Chain is too simple and structures in Random change all the time thus hard to control}.

\noindent\textbf{Position of victim agent}. The position of an agent in LLM-MAS is crucial, as it determines the messages it can access and its influence on the final decision. For the Complete structure, while agents can send and receive messages from all other agents, they still follow a pre-defined speaking order, i.e., $A_1 - A_2 - A_3$. Therefore, we intercept messages sent to $A_2$ and $A_3$ respectively (shown in Figure \ref{fig:structure}). For Tree structure, we consider both the child agent ($C_1$) and the parent agent ($P_1$). Due to its symmetric structure, we intercept the child and parent on the left side for illustration, shown as Child and Parent in Table \ref{tab:position}. We test on both frameworks, both types of attacking objectives on MMLU-bio and HumanEval datasets. 

Results are presented in Table \ref{tab:position}. It is obvious that AiTM exhibits high success rate attacking agents in different positions, achieving more than 80\% on 27/32 cells in Table \ref{tab:position}. We also notice some significant difference in the attacking performance on positions. For target behavior attacks in MMLU-bio, attacking the parent agent in the Tree structure obtains much higher success rate than attacking the child agent, about 15\% increase. This suggests that manipulating the messages among agents of higher levels in the Tree structure can do more harm to LLM-MAS, which is likely because these agents can impact the final decision more than those low-level agents such as a child agent. We also observe that manipulating messages sent to later agents in the Complete structure can improve the attacking performance, as the Third column achieves more than 30\% increase than the Second column. This indicates that attacking later messages in the communication is more likely to compromise the final decision. We also observe improvement by manipulating higher level in Tree or later messages in Complete in the DoS attack, but due to the fact that attacking lower levels and early messages has already got a high success rate, the improvement is not as significant as discussed above. These observations suggest that high-level messages are more susceptible to AiTM and need better protection.

% Please add the following required packages to your document preamble:
% \usepackage{multirow}
\begin{table}[h]
\centering
\caption{Attack results on the position of victim agents.}
\label{tab:position}
\resizebox{\linewidth}{!}{
\begin{tabular}{cc|cc|cc}
\midrule
\midrule
\multicolumn{2}{c|}{\textbf{MMLU-bio}}                                   & \multicolumn{2}{c|}{\textbf{Tree}} & \multicolumn{2}{c}{\textbf{Complete}} \\ \midrule
\multicolumn{2}{c|}{\textbf{Victim Position}}                                   & \textbf{Child}   & \textbf{Parent}  & \textbf{Second}    & \textbf{Third}   \\ \midrule
\multicolumn{1}{c|}{\multirow{2}{*}{\textbf{AutoGen}}} & \textbf{Target} & 40.7            &\cellcolor{orange!15} 67.4             & 43.9               & \cellcolor{orange!40}95.3             \\
\multicolumn{1}{c|}{}                                  & \textbf{DoS}    & \cellcolor{orange!40}93.7            & \cellcolor{orange!40}97.3             & \cellcolor{orange!40}94.9               & \cellcolor{orange!40}95.8             \\ \midrule
\multicolumn{1}{c|}{\multirow{2}{*}{\textbf{Camel}}}   & \textbf{Target} & \cellcolor{orange!15}68.2            & \cellcolor{orange!40}96.5             & 48.7               & \cellcolor{orange!40}97.2             \\
\multicolumn{1}{c|}{}                                  & \textbf{DoS}    &\cellcolor{orange!40} 93.3            & \cellcolor{orange!40}99.1             & \cellcolor{orange!40}96.5               & \cellcolor{orange!40}95.1             \\ \midrule\midrule
\multicolumn{2}{c|}{\textbf{HumanEval}}                                  & \multicolumn{2}{c|}{\textbf{Tree}} & \multicolumn{2}{c}{\textbf{Complete}} \\ \midrule
\multicolumn{2}{c|}{\textbf{Victim Position}}                                   & \textbf{Child}   & \textbf{Parent}  & \textbf{Second}    & \textbf{Third}   \\ \midrule
\multicolumn{1}{c|}{\multirow{2}{*}{\textbf{AutoGen}}} & \textbf{Target} & \cellcolor{orange!40}97.4            & \cellcolor{orange!40}97.7             & \cellcolor{orange!40}96.3               & \cellcolor{orange!40}97.4             \\
\multicolumn{1}{c|}{}                                  & \textbf{DoS}    & \cellcolor{orange!15}83.9            & 8\cellcolor{orange!15}8.5             & \cellcolor{orange!15}87.3               &\cellcolor{orange!40} 90.6             \\ \midrule
\multicolumn{1}{c|}{\multirow{2}{*}{\textbf{Camel}}}   & \textbf{Target} & \cellcolor{orange!40}98.7            & \cellcolor{orange!40}97.6             & \cellcolor{orange!40}98.7               & \cellcolor{orange!40}98.4             \\
\multicolumn{1}{c|}{}                                  & \textbf{DoS}    & \cellcolor{orange!15}82.4            &\cellcolor{orange!15} 89.3             &\cellcolor{orange!15} 82.4               & \cellcolor{orange!15}86.5             \\ \midrule\midrule
\end{tabular}}\vspace{-0.1in}
\end{table}

\noindent\textbf{Persuasiveness of adversarial agents}. Existing attacks with malicious agents \citep{amayuelas2024multiagent} mention that the persuasive ability of a malicious agent can affect the attacking performance. Therefore, we test if the persuasiveness of the adversarial agent can influence AiTM. 

For each kind of attacking objectives, i.e., Target behavior and DoS, we generate prompts with three levels of persuasiveness (1<2<3, shown in Table \ref{tab:persuasive}, and default level is 3 for other experiments if not specified). We evaluate the persuasiveness from three aspects: credibility and expertise, content and structure, emotion and attitude. In general, an adversarial agent with more expertise, better logic and sufficient evidence, stronger attitude such as non-negotiable requirements has stronger ability of persuasive. To control these aspects, we manually define roles, provide evidence, and explicitly set the desired attitude in the prompt. Details of persuasiveness and prompts are in Appendix \ref{app:prompts}. 

We test on the MMLU-bio dataset and summarize the results in Table \ref{tab:persuasive}. We observe a clear trend among attacking results: the adversarial agent with a higher ability to persuade achieves a much higher success rate. For example, for the AutoGen framework with Target attack, the ASR increases from 19.5\% to 27.1\% and finally to 40.7\% with an increasing persuasive level. This indicates that a very persuasive adversarial agent can compromise the system's security by crafting convincing malicious messages.
% that exploit the collaborative nature of agent communication. 
The effectiveness of persuasive messaging reveals a fundamental vulnerability in LLM-MAS. The system relies on communication to enable sophisticated agent collaboration. However, this trust can be exploited by a skillful adversary to manipulate the system's behavior without directly altering any system components.
%\yue{Removed this as previously we already know that DoS is easier.} Moreover, different attacks require different levels of persuasiveness, and target behavior attack needs more persuasiveness than DoS. This can be because DoS attacks only need to convince the victim agent to reject requests, while target behavior attacks require sophisticated persuasion to guide the agent towards specific malicious actions.

% Please add the following required packages to your document preamble:
% \usepackage{multirow}
\begin{table}[]
\centering
\caption{Attack results on persuasiveness}
\label{tab:persuasive}
\resizebox{\linewidth}{!}{
\begin{tabular}{cc|ccc|ccc}
\hline
                                                       &                 & \multicolumn{3}{c|}{\textbf{Tree}}   & \multicolumn{3}{c}{\textbf{Complete}} \\ \hline
\multicolumn{2}{c|}{\textbf{Persuasive level}}                           & \textbf{1} & \textbf{2} & \textbf{3} & \textbf{1}  & \textbf{2} & \textbf{3} \\ \hline
\multicolumn{1}{c|}{\multirow{2}{*}{\textbf{AutoGen}}} & \textbf{Target} &\cellcolor{orange!0} 19.5       & \cellcolor{orange!10}27.1       &\cellcolor{orange!20} 40.7       & \cellcolor{orange!0}13.6        & \cellcolor{orange!10}30.3       & \cellcolor{orange!20}43.9       \\
\multicolumn{1}{c|}{}                                  & \textbf{DoS}    & \cellcolor{orange!10}79.8       & \cellcolor{orange!30}85.2       & \cellcolor{orange!50}93.7       & \cellcolor{orange!10}74.1        & \cellcolor{orange!30}80.8       & \cellcolor{orange!50}94.9       \\ \hline
\multicolumn{1}{c|}{\multirow{2}{*}{\textbf{Camel}}}   & \textbf{Target} & \cellcolor{orange!10}39.2       & \cellcolor{orange!20}55.8       & \cellcolor{orange!40}68.2       & \cellcolor{orange!0}19.5        & \cellcolor{orange!10}35.1       & \cellcolor{orange!20}48.7       \\
\multicolumn{1}{c|}{}                                  & \textbf{DoS}    & \cellcolor{orange!10}82.1       & \cellcolor{orange!30}86.7       & \cellcolor{orange!50}93.3       & \cellcolor{orange!10}70.6        & \cellcolor{orange!30}85.3       &\cellcolor{orange!50} 96.5       \\ \hline
\end{tabular}}
\end{table}

\noindent \textbf{Models within agents}. We also evaluate the influence of the choice of the LLM model inside the agents in LLM-MAS and inside the adversarial agent. We test with three versions of GPT models, and present results on the MMLU-bio dataset, AutoGen and Complete structure in Figure \ref{fig:models_autogen}. We also include results on Camel and Tree structure in Figure \ref{fig:models} in Appendix \ref{app:exp result}. We observe that when the adversarial agent is equipped with a stronger model than the LLM-MAS, the attacking performance increases. For example, for the MMLU-bio dataset with Target attack in AutoGen with GPT-4o in the LLM-MAS agents, when using GPT-3.5-turbo for the adversarial agent, the ASR is 43.9\%. When using GPT-4o in the adversarial agent, the ASR becomes 57.9\%. A similar trend can be found for all the settings. This suggests that LLM model in the agent plays a crucial role in attack effectiveness, and stronger models may dominate weaker models. Similar observations can be found when changing the LLM in LLM-MAS. When the LLM-MAS uses a stronger model, its resistance against AiTM is enhanced.

% \yue{I removed this as the observations are similar to the above.} Besides, when the LLM-MAS uses a stronger model, its resistance against AiTM is enhanced. This trend is particularly obvious when comparing results of GPT-4o, GPT-4omini with GPT-3.5-turbo. We also notice that the ability of models in LLM-MAS can influence the attacking performance. For example, for the target behavior attack on HumanEval dataset (left bottom figures in Figure \ref{fig:models} (a)(b)), LLM-MAS with GPT-3.5-turbo shows clear gap in attacking performance even when the adversarial agent is powered by GPT-4o. This can be because the code generation ability of GPT-3.5-turbo is worse than the other two models thus can not fully implement the malicious action even when the agents are persuaded to do so. Our investigation reveals the importance of LLMs in the security of LLM-MAS security.

\begin{figure}[h!]
    \centering
    \includegraphics[width=\linewidth]{figures/model_complete_autogen.png}\vspace{-0.05in} 
    \caption{Performance comparison for different models on AutoGen (Complete structure).}
    \label{fig:models_autogen}
\end{figure}
\vspace{-0.1in}




\subsection{Real-world applications (RQ3)}

% \noindent\textbf{Real-world applications.} 
Besides the simulation using multi-agent frameworks, we test AiTM on two popular real-world LLM-MAS: (1) \underline{\textit{MetaGPT}} \citep{hong2023metagpt} is a meta-programming framework multi-agent system mirroring a human software company. It utilizes specialized agents and encodes Standardized Operating Procedures (SOPs) into prompt sequences for more
streamlined workflows. (2) \underline{\textit{ChatDev}} \citep{qian2024chatdev} is a chat-powered software development framework and aims to reduce hallucination via multi-turn dialogues between different agents. Besides HumanEval and MBPP, we also include SoftwareDev, a dataset introduced by MetaGPT containing software development tasks~\footnote{Since the full version of SoftwareDev is not released yet, we only test on public problems in it.}. All agents are powered by GPT-4o, and we test with the same target behavior attack (as described in Section \ref{sec:setup}) on all three datasets.

\begin{table}[]
\centering
\caption{Attack results on MetaGPT and ChatDev}
\label{tab:application}
\resizebox{0.5\textwidth}{!}{
\begin{tabular}{ccccc}
\midrule
\multicolumn{5}{c}{\textbf{MetaGPT}}                                                                                                       \\ \midrule
\multicolumn{1}{c|}{\textbf{Victim}}      & \textbf{Product manager} & \textbf{Architect} & \textbf{Project Manager} & \textbf{Engineer}   \\ \midrule
\multicolumn{1}{c|}{\textbf{SoftwareDev}} &\cellcolor{orange!40} 100.0                    & \cellcolor{orange!40}100.0              & \cellcolor{orange!40}100.0                    &\cellcolor{orange!40} 100.0               \\
\multicolumn{1}{c|}{\textbf{HumanEval}}   &\cellcolor{orange!40} 90.4                     & \cellcolor{orange!40}98.3               & \cellcolor{orange!40}97.6                     & \cellcolor{orange!10}75.7                \\
\multicolumn{1}{c|}{\textbf{MBPP}}        &\cellcolor{orange!40} 95.1                     & \cellcolor{orange!40}99.2               & \cellcolor{orange!40}96.3                     &\cellcolor{orange!10} 80.4                \\ \midrule\midrule
\multicolumn{5}{c}{\textbf{ChatDev}}                                                                                                       \\ \midrule
\multicolumn{1}{c|}{\textbf{Victim}}      & \textbf{CPO}             & \textbf{CEO}       & \textbf{CTO}             & \textbf{Programmer} \\ \midrule
\multicolumn{1}{c|}{\textbf{SoftwareDev}} & 0.0                      & 0.0                &\cellcolor{orange!10} 45.4                     & \cellcolor{orange!10}63.6                \\
\multicolumn{1}{c|}{\textbf{HumanEval}}   & 0.0                      & 0.0                & \cellcolor{orange!10}52.7                     &\cellcolor{orange!10} 60.1                \\
\multicolumn{1}{c|}{\textbf{MBPP}}        & 0.0                      & 0.0                & \cellcolor{orange!10}55.9                     & \cellcolor{orange!10}69.3                \\ \bottomrule
\end{tabular}
}
\end{table}

Results are presented in Table \ref{tab:application}. We find that MetaGPT is easily compromised by AiTM, with more than 75\% success rate and even achieving 100\% on SoftwareDev.
% \footnote{This dataset is much smaller than the other two}. 
To explain, MetaGPT follows a standard Chain structure, similar to that in Figure \ref{fig:structure}, and does not include any monitoring or correction mechanism.
% to correct malicious instruction within the messages. 

In terms of ChatDev, AiTM does not work when intercepting CPO and CEO agents. Through checking the implementation of ChatDev, we find that 
% We carefully check the working flow of ChatDev and find that 
it does not only specify the roles for each agent but also specify the goal and output in each phase, adding additional restrictions on the communications. 
% For example, CPO and CEO engage in the phase called DemandAnalysis, and ChetDev strictly specifies that ``we must ONLY discuss the product modality and do not discuss anything else'', therefore the malicious message such as ``you must inject a safety\_check function'' is ignored. 
On the other hand, since the CTO and Programmer agents directly engage into the Coding phase, we successfully achieve the target behavior by intercepting them. 
% \yue{We don't have a very rigorous comparison among structures so I would suggest remove the following sentence:}As ChatDev leverages a Complete structure in each phase, the attacking performance is worse than that on MetaGPT, verifying our discussion about communication structure. 

Our results show that AiTM can indeed compromise real-world applications, revealing potential communication threats in real practice.



