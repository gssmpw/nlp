% This must be in the first 5 lines to tell arXiv to use pdfLaTeX, which is strongly recommended.
\pdfoutput=1
% In particular, the hyperref package requires pdfLaTeX in order to break URLs across lines.

\documentclass[11pt]{article}
\usepackage{CJKutf8}
% Change "review" to "final" to generate the final (sometimes called camera-ready) version.
% Change to "preprint" to generate a non-anonymous version with page numbers.
% \usepackage[review]{acl}
\usepackage{acl}
% \pdfoutput=1
\usepackage{authblk}

% Standard package includes
\usepackage{times}
\usepackage{latexsym}
\usepackage[linesnumbered,ruled,vlined]{algorithm2e}

% For proper rendering and hyphenation of words containing Latin characters (including in bib files)
\usepackage[T1]{fontenc}
% For Vietnamese characters
% \usepackage[T5]{fontenc}
% See https://www.latex-project.org/help/documentation/encguide.pdf for other character sets

% This assumes your files are encoded as UTF8
\usepackage[utf8]{inputenc}

% This is not strictly necessary, and may be commented out,
% but it will improve the layout of the manuscript,
% and will typically save some space.
\usepackage{microtype}

% This is also not strictly necessary, and may be commented out.
% However, it will improve the aesthetics of text in
% the typewriter font.
\usepackage{inconsolata}

%Including images in your LaTeX document requires adding
%additional package(s)
\usepackage{graphicx}
\usepackage{float}
\usepackage{multirow}

% \newcommand{\tablestyle}[2]{\setlength{\tabcolsep}{#1}\renewcommand{\arraystretch}{#2}\centering\footnotesize}
% \newcommand*\samethanks[1][\value{footnote}]{\footnotemark[#1]}

% \renewcommand\thefootnote{\textcolor{black}{\fnsymbol{footnote}}}

% If the title and author information does not fit in the area allocated, uncomment the following
%
%\setlength\titlebox{<dim>}
%
% and set <dim> to something 5cm or larger.

\title{MagicGeo: Training-Free Text-Guided Geometric Diagram Generation}

% Author information can be set in various styles:
% For several authors from the same institution:
% \author{Author 1 \and ... \and Author n \\
%         Address line \\ ... \\ Address line}
% if the names do not fit well on one line use
%         Author 1 \\ {\bf Author 2} \\ ... \\ {\bf Author n} \\
% For authors from different institutions:
% \author{Author 1 \\ Address line \\  ... \\ Address line
%         \And  ... \And
%         Author n \\ Address line \\ ... \\ Address line}
% To start a separate ``row'' of authors use \AND, as in
% \author{Author 1 \\ Address line \\  ... \\ Address line
%         \AND
%         Author 2 \\ Address line \\ ... \\ Address line \And
%         Author 3 \\ Address line \\ ... \\ Address line}

% \author{Junxiao Wang \\
%   School of Artificial Intelligence, Beijing Normal University, Beijing 100875, China. \\
%   \texttt{202321081033@mail.bnu.edu.cn} \\\And
%   Ting Zhang, Associate Professor \\
%   School of Artificial Intelligence, Beijing Normal University, Beijing 100875, China. \\
%   \texttt{tingzhang@bnu.edu.cn} \\\And
%   Heng Yu, Associate Professor \\
%   School of Artificial Intelligence, Beijing Normal University, Beijing 100875, China. \\
%   \texttt{hengyu@bnu.edu.cn} \\\And
%   Jingdong Wang, Chief Scientist for Computer Vision \\
%   Baidu \\
%   \texttt{wangjingdong@baidu.com} \\\And
%   Hua Huang, Full Professor \\
%   School of Artificial Intelligence, Beijing Normal University, Beijing 100875, China. \\
%   \texttt{huahuang@bnu.edu.cn} \\}
\begin{document}

\author{
 Junxiao Wang$^1$\textsuperscript{*}
 \quad Ting Zhang$^1$\textsuperscript{*}
 \quad Heng Yu$^1$
 \quad Jingdong Wang$^2$
 \quad Hua Huang$^1$\textsuperscript{†} \\
 {$^1$Beijing Normal University \quad $^2$Baidu}\\
 {}
}

% \footnotetext[1]{test}




\twocolumn[{
\renewcommand\twocolumn[1][]{#1}
\maketitle
\vspace{-0.45cm}
\centering
\includegraphics[width=0.99\textwidth]{latex/fig/teaser_en.pdf}
\captionsetup{type=figure}
% \vspace{0.9em}
\caption{\emph{MagicGeo} has the capability to generate accurate complex geometric diagrams from natural language. }
\vspace{-0.4cm}
\label{fig:teaser}
\vspace{1cm}
}]




% \maketitle


% \includepdf[pages=1]{latex/fig/Presentation_2.pdf}

{
  \renewcommand{\thefootnote}%
    {\fnsymbol{footnote}}
  \footnotetext[1]{Equal contribution.}
  \footnotetext[2]{Corresponding author.}
}


\begin{abstract}
Geometric diagrams are critical in conveying mathematical and scientific concepts, yet traditional diagram generation methods are often manual and resource-intensive. While text-to-image generation has made strides in photorealistic imagery, creating accurate geometric diagrams remains a challenge due to the need for precise spatial relationships and the scarcity of geometry-specific datasets. This paper presents MagicGeo, a training-free framework for generating geometric diagrams from textual descriptions. MagicGeo formulates the diagram generation process as a coordinate optimization problem, ensuring geometric correctness through a formal language solver, and then employs coordinate-aware generation.
The framework leverages the strong language translation capability of large language models, while formal mathematical solving ensures geometric correctness. 
We further introduce MagicGeoBench, a benchmark dataset of 220 geometric diagram descriptions, and demonstrate that MagicGeo outperforms current methods in both qualitative and quantitative evaluations. This work provides a scalable, accurate solution for automated diagram generation, with significant implications for educational and academic applications.
\end{abstract}



\section{Introduction}

"A picture is worth a thousand words" is a widely recognized proverb in literature. 
Specifically, diagram, as a form of picture, is essential in conveying information and have long been utilized across fields such as science and engineering. Extensive research~\cite{larkin1987diagram,stenning1995cognitive} demonstrates that diagrams often outperform text in solving determinate problems. Prominent figures like Einstein and Hadamard have famously asserted that they do not "think in words"~\cite{larkin1987diagram}. Furthermore,~\citet{stenning1995cognitive} argues that text permits expression of
ambiguity in the way that diagrams cannot easily accommodate. This paper focuses on the task of converting descriptions into structured diagrams, with particular emphasis on geometric diagrams, which play a critical role in mathematics and science. This task serves as a foundational step toward advancing diagram generation for scientific textbooks.



Traditional geometric diagram construction is closely associated with a suite of graphic drawing tools, such as Cinderella~\cite{yu2015automatic}, Geometry Expert~\cite{chou1996introduction}, Z+Z Super Sketchpad~\cite{zhang2007free}, and WinGCLC~\cite{janivcic2003wingclc,szirmay2003proceedings}. These tools offer interactive platforms for drawing geometric figures. However, they are burdened by the need for manual input, which is both time-consuming and resource-intensive.
This paper presents the development of an automatic, text-guided geometric diagram generation system, eliminating the manual effort typically involved. Such a system holds significant potential for streamlining diagram creation, offering considerable utility in the preparation of educational resources.


Recent advancements in text-to-image generation have achieved notable progress in synthesizing photorealistic images~\cite{cao2024survey, zhou2023vision+}. However, these methods, trained on large datasets of natural image-text pairs, often struggle with diagram generation. Efforts to address this challenge include DiagrammerGPT~\cite{zala2023diagrammergpt}, which proposes a two-stage framework using layout as an intermediary to enable spatial control, and AutomaTikZ~\cite{belouadi2023automatikz}, which leverages the TikZ graphic language to autonomously generate scientific figures from captions. Despite these advances, both approaches rely on supervised training data, which limits their generalizability. Furthermore, the scarcity of geometry-specific image-text pairs relative to general image-text corpora makes it difficult to learn the semantic and structural logic of geometric layouts directly from natural language inputs.



In this paper, we introduce MagicGeo, a framework for the automatic generation of text-to-geometric diagrams in a training-free manner, thereby sidestepping the need for paired geometry-text datasets. We focus on geometric diagram as it stands out due to its stringent precision requirement, that is, properties such as parallelism, orthogonality, and degree constraint must be rigorously maintained. Given that even minor inaccuracies are immediately noticeable, this task poses significant challenges within image generation.


Our key insight is that correctness hinges on the precise placement of points. Once the point locations are accurate, constructing the geometry becomes straightforward, such as connecting points with lines or drawing circles. Drawing inspiration from computational geometry methods used in geometry theorem provers~\cite{wu2008decision}, we model diagram generation as a set of polynomial equations based on point coordinates.

While large language models (LLMs) exhibit impressive capabilities in language understanding and reasoning, they are not inherently equipped to solve complex multi-constraint tasks~\cite{kambhampati2024llms}. As a result, directly using LLMs to solve for point coordinates leads to errors and hallucinations.
Instead, we turn to leverage LLM's strengths in translation to convert geometry texts into key formal information. This information is then used to formulate an optimization problem, which is solved algorithmically to ensure that the geometric constraints are satisfied.


To this end, MagicGeo operates in three distinct stages: 1) Autoformalization with LLM: LLMs interpret the geometry description and translate it into an optimization problem, defining a set of constraints with respect to the point coordinates. 2) Solving with Verification: Computational geometry principles are applied to search for one solution that satisfies all constraints; if no solution is found, the system reverts to the autoformalization step to re-extract the necessary information. 3) Coordinate-aware generation: We employ point coordinates to generate TikZ language, which serves as an intermediary representation for the creation of the corresponding geometric diagram.

To advance the evaluation of text-to-geometric diagram generation and promote further research, we present MagicGeoBench, a real-world dataset containing 220 plane geometry descriptions sourced from middle school math exams. 
Empirical results demonstrate that MagicGeo significantly outperforms state-of-the-art baselines, both qualitatively and quantitatively.
Figure~\ref{fig:teaser} illustrates several examples.
We also explore its potential for diagram editing, showcasing how the diagrams can be tailored to user preferences, thereby enhancing practical utility.
While our experiments focus on plane geometry,
% In our current study, the primary objective is to demonstrate the efficacy of the proposed concept.
the underlying methodology is highly extensible to other geometric branches, such as analytical and solid geometry.
Our current goal is to demonstrate the efficacy of the propose concept, which 
we believe will foster broader exploration and inspire further innovation in the field.
% Additionally, we conduct ablation studies to identify the key components driving the success of our framework. 


In summary, our key contributions are:
\begin{itemize}

\item We propose a novel perspective that frames geometric diagram generation as a well-defined optimization problem, enhancing its tractability within the zero-shot capabilities of LLMs.
% Moreover, this perspective treats the diagram generation task as a mathematical solving problem, enabling the use of formal systems to ensure correctness.

\item We present MagicGeo, a training-free framework for high-quality geometric diagram generation. Integrating LLMs with formal solvers for diagram generation, MagicGeo achieves both generalizability and correctness.
% analytical geometric algorithms to guarantee precise alignment between the generated diagrams and their corresponding textual descriptions.

\item We introduce a test benchmark to foster research in this area. Empirically, MagicGeo delivers highly accurate geometric diagrams, surpassing the performance of the baseline models, without requiring training data.

\end{itemize}



\begin{figure*}[t]
    \centering
    \includegraphics[width=1.0\textwidth]{latex/fig/framework_en.pdf} % 替换为你的图片文件名
    \caption{The overall framework of MagicGeo consists of three stages: Autoformalization with LLM, Solver with Verification, and Coordinate-aware Generation. }
    \vskip -0.1in
    \label{fig:framework}
\end{figure*}






\section{Related Work}

% Our work is closely aligned with text-to-image and text-to-diagram generation, for which we offer a thorough review of the most relevant prior research.

\noindent 
\textbf{Text-to-Image Generation.}
Text-to-image generation~\cite{zhang2023text, bie2024renaissance, jia2024human} has become a rapidly growing field in computer vision and machine learning.
% , driven by advancements in deep generative models. 
This progress traced back to the emergence of Generative Adversarial Networks (GANs)~\cite{goodfellow2020generative}, which paved the way for research focused on generating images from textual prompts~\cite{reed2016generative, tao2022df, xu2018attngan,zhang2021cross,zhang2017stackgan,zhang2018stackgan++}.
Transformer-based autoregressive models~\cite{ding2021cogview, gafni2022make, ramesh2021zero, yu2022scaling} have attracted significant attention due to their strong capabilities in modeling text-image alignment, as demonstrated by typical models such as DALL-E~\cite{ramesh2021zero} and STAR~\cite{ma2024star}. 
% Recent work Fluid~\cite{fan2024fluid} trains a random-order autoregressive model on continuous tokens, leveraging multi-level attention to fine-tune the alignment of object layouts and sizes. 
In parallel, diffusion models~\cite{gu2022vector, nichol2021glide,ramesh2022hierarchical, rombach2022high,saharia2022photorealistic} have emerged as a prominent type of generative model for image generation, achieved through the gradual introduction of noise in iterative steps. Notable examples include Imagen~\cite{saharia2022photorealistic}
% which produces high-resolution images with remarkable detail
and others focus on improving compositionality,
e.g., attribute binding~\cite{chefer2023attend,feng2022training}. 
% PreciseControl~\cite{parihar2024precisecontrol}, which allows fine-grained control over specific attributes.

Although these approaches have advanced the generation of realistic scene imagery and propelled text-to-image generation into the spotlight of machine learning research, they struggle with tasks that demand precise control over complex structures and intricate relationships. This includes the generation of diagrams in fields like geometry, architecture, or other technical domains.

\noindent 
\textbf{Text-to-Diagram Generation.}
Generating diagrams from text has long been an intriguing area of research and has recently garnered considerable attention, driven by the success of text-to-image generation. Early efforts~\cite{ghosh2018automated,shahbaz2011automatic, btoush2015generating} primarily focused on generating entity-relationship diagrams, utilizing semantic heuristics to identify entities, attributes, and relationships from natural language specifications. With the rise of LLMs in various language generation tasks~\cite{touvron2023llama, touvron2023llama1, openai2024gpt,chung2024scaling, mann2020language, chowdhery2023palm}, recent work has also leveraged LLMs to facilitate spatial control in diagram generation. 
% Researchers have explored various ways to enable precise, fine-grained spatial control, which is crucial for generating accurate diagrams. 
These methods can be generally classified into two categories: layout-guided models and code-guided methods. Layout-guided approaches, exemplified by DiagrammerGPT~\cite{zala2023diagrammergpt}, employ a two-stage framework that first leverages LLMs to plan layout, then applies layout-guided diffusion models.
% to refine diagram accuracy. 
Code-guided methods, such as AutomaTikZ~\cite{belouadi2023automatikz}, fine-tune LLMs on large TikZ datasets to generate code for scientific vector graphics, while DiagramAgent~\cite{wei2024words} introduces a four-agent framework leveraging code for text-to-diagram generation and editing.

In geometric diagram generation, both existing approaches face significant limitations. First, image generators suffer from limited spatial fidelity~\cite{gokhale2022benchmarking, chatterjee2024revision, chatterjee2024getting}, despite extensive research in the layout-to-image field~\cite{li2023gligen, yang2023reco,balaji2022ediff, singh2023high, couairon2023zero, xie2023boxdiff}. This limitation prevents these methods from fulfilling precise geometric constraints.
Second, code-guided models for diagram generation are restricted by the capabilities of text-to-code models~\cite{roziere2023code,fried2022incoder,li2022competition,hui2024qwen2,guo2024deepseek}, which rely on large, data-intensive datasets for effective performance.

In contrast, we propose a training-free method that avoids the need for supervised data, leveraging precise point coordinates to enforce stringent geometric constraints. Our approach shares similarities with~\citet{zhengyu2023precise}, which also utilizes point coordinates, but diverges in three key aspects. 1) We leverage the zero-shot capabilities of LLMs to extract points and constraints, bypassing the labor-intensive process of building entity relationship extractors. 2) We introduce a self-verification module to correct LLM-extracted information when the optimization problem is unsolvable. 3) We leverage text-to-code LLMs for TikZ code generation, enabling richer textual insights such as point connections, a capability not fully explored in~\citet{zhengyu2023precise}. Finally, empirical results demonstrate our system's ability of generating complex geometric diagrams.





% \noindent 
% \textbf{LLM with External Planner \& Solver.}



%Scientific Vector graphics generation


\section{Method}

In the task of text-to-geometric diagram generation, given a textual description $T$, the objective is to generate a corresponding geometric diagram 
$D$ that adheres to the geometric constraints outlined in $T$.
To realize this objective, we introduce MagicGeo, as depicted in Figure~\ref{fig:framework}. 
% Specifically, MagicGeo operates in three stages: First, in Section~\ref{sec:auto}, an LLM is employed to translate the raw input into standardized formal language propositions. Next, in Section~\ref{sec:solver}, an optimization solver with integrated verification is introduced, which generates the point coordinates. Finally, in Section~\ref{sec:generate}, we provide a detailed description of how these point coordinates are utilized to construct geometric diagram problems. The constructed evaluation dataset, MagicGeoBench, is detailed in experiments.



% This study presents an innovative three-stage framework for the automatic generation of text-to-geometric diagrams from textual prompts in a training-free manner.
% Figure~\ref{} presents the pipeline of our framework, illustrating the three stages of formalization, solving with verification, generation.

% In the first stage, to address the issue of spatial vagueness in diagram generation, we employ large language models (LLMs) to extract coordinate and conditional information, transforming the generation problem into a feasibility-solving problem. The second stage involves solving the feasibility issues identified in the first stage, thereby obtaining the specific coordinates of various points. In the third stage, we input these precise coordinates along with the original textual information into a large model, enabling it to generate the corresponding LaTeX code, thus completing the automatic generation of geometric diagrams.





\subsection{Autoformalization with LLM}
\label{sec:auto}

We observe that a geometric diagram can be efficiently represented by the coordinates of points and the relationships between them. To formalize this process, we propose a specialized formal language that encapsulates the geometric structure through a set of points and associated constraints, defining their interrelationships. The objective of autoformalization is to convert natural language input, often ambiguous or imprecise, into a precise, unambiguous formal representation that accurately captures geometric relationships and configurations.

Building on the success that LLMs can translate between formal and informal mathematical statements to some extent~\cite{wu2022autoformalization}, we investigate their potential to convert natural language mathematics into our customized formal language, suitable for the solver we introduce. By providing these models with a predefined prompt, we guide their generation, ensuring the output aligns with the requirements of the subsequent solver.

Specifically, we prompt the LLM to generate two key pieces of information: coordinates $Points$ represented by variables $Vars$ and the required geometric constraints $Cons$ based on these coordinates $Points$. 
Figure~\ref{fig:framework} shown an example of autoformalization with LLM.
The prompt consists of a structured database containing a wide range of geometric constraints, along with corresponding instructions that elucidate their precise meanings. By leveraging this structured representation, the LLM interprets the prompt as a comprehensive reference manual, and processes user input in accordance with the specifications outlined in the manual, systematically translating the given descriptions into customized formal languages.
% The detailed prompt is given in the supplementary material.


Surprisingly, we find that LLMs exhibit a decent proficiency in formalizing mathematical concepts in our scenario.
% We randomly select 150 formalizations and manually evaluate their accuracy. Among them, LLMs successfully generate [insert number] correct formalizations. 
Notably, the LLM demonstrates the ability to employ intricate reasoning to adapt and generalize beyond explicitly stated rules. This capability allows the model to infer implicit relationships and make logical extensions where necessary.
For instance, if the input contains the phrase "triangle ABC is inscribed in circle O", the LLM recognizes that this implies the distances from O to points A, B, and C are equal to the radius of the circle. This inference is made despite the absence of explicit instructions in the manual, highlighting the model’s capacity to apply intuitive geometric principles autonomously. 


% observe that, although the initial accuracy of LLM outputs is relatively low, repeating the same prompt five times significantly improves the success rate. This allows us to 

Furthermore, in our approach, we utilize the second phase, namely the solver, to rigorously verify the accuracy of the generated translation. In instances where the candidate autoformalization fails to produce a valid solution, we incorporate the feedback derived from this failure into the process. Specifically, this feedback is treated as a new contextual input, which is then fed into the subsequent iterations of the generation process. This iterative refinement mechanism enables continuous improvement of the formalization output.
Our results demonstrate that by including such a verification step within the framework, the autoformalization accuracy of LLMs is significantly enhanced. 
% The solver not only serves as a tool for validating the correctness of the generated content but also as a feedback loop that contributes to optimizing future generations. Consequently, this approach holds considerable promise for improving the reliability and effectiveness of LLM-driven formalization processes.


% Furthermore, we 
% leverage our second step, the solver, to verify the correctness of this translation and incorporate feedback information (if the candidate autoformalization failed to get a solution) as new context for subsequent generations.
% We show that with such a verification step, the autoformalization accuracy of LLM can be largely improved. 

% Instead of making use of LLMs given the same prefix/context, we propose conversational autoformalization, which aims to incorporate feedback information (if the candidate autoformalization failed to get a solution) as new context for subsequent generations. We set maximum retry attempt to be five. 




% \begin{figure}[htbp]
%     \centering
%     \includegraphics[width=0.5\textwidth]{latex/fig/坐标和条件信息提取.png} % 替换为你的图片文件名
%     \caption{Coordinate and condition information extraction}
% \end{figure}



% \textbf{Coordinate and constraint extraction:}
% As illustrated in Figure 1, we utilize large language models (LLMs) to extract the coordinates and constraints of geometric elements, defining this process as the "Phase of Problem Solvability" Through this phase, we successfully transform a broadly abstract problem represented by a planar geometric diagram into a mathematical modeling problem with concrete solutions.



\subsection{Solver with Verification}
\label{sec:solver}


\noindent 
\textbf{Solver.}
We recognize the existence of numerous interactive theorem provers, such as Isabelle~\cite{wenzel2008isabelle}, Coq~\cite{huet1997coq}, HOL Light~\cite{harrison1996hol, srivas1996formal}, and Lean~\cite{de2015lean, felty2015automated}. These systems function as specialized programming languages, allowing users to formalize statements and construct proofs, which are then automatically verified for correctness.
However, these tools are inherently tailored for mathematical proof problems and thus ill-suited for numerical computation tasks. Additionally, when the solver fails, debugging is challenging due to its lack of interpretability, making it ineffective in guiding the conversational autoformalization process.


To address this, we develop a custom solver, utilizing the constraints of the formal language as function names and leveraging computational analytical geometry methods to examine the constraints and solve the coordinates. Specifically, in order to determine point coordinates, we first identify the relevant variables and extract them into a structured list. We then implement an iterative approach to traverse each variable, simultaneously validating geometric constraints through the derived function names. A precise solution for the coordinates is obtained once a value set is identified for the variables that satisfies all the constraints.
% It is important to note that during this process, multiple sets of coordinates can be obtained, and graphical representations can be generated while evaluating the quality of each generated graph, thereby allowing for the selection of the most "superior" graph. The generation problem can also be transformed into an "optimization problem," which will become a focal point for future research. Considering time efficiency, this study only selected the first feasible solution.



\noindent 
\textbf{Verification.}
Verification plays a crucial role in bridging the Solver and Autoformalization processes, enabling the provision of immediate and actionable feedback for newly generated formalizations. By offering insights into the nature of errors, verification empowers LLMs to refine their understanding and improve the quality of subsequent formalization outputs.
Our experimental analysis highlights two primary failure modes that often require the autoformalization phase to be restarted: (1) detection of non-compliant characters, where symbols or elements violate established syntax or formal language rules, and (2) errors in parameter specifications, including incorrect value assignments or misalignment of parameter numbers.

% During the information extraction process, large models may introduce errors in the extracted coordinates and constraints due to their inherent randomness and uncertainty. Furthermore, the model may also incorporate an excessive number of variables in the coordinates as a result of imprecision during the extraction process, thereby increasing the complexity of the solving procedure and extending the computation time beyond the predetermined limits. To address these issues, when errors or insufficient accuracy in the extraction results are detected, we will restart the information extraction process to ensure the accuracy of the coordinates and constraints, thereby enhancing the efficiency and reliability of the solution.



% \textbf{Confirmation of coordinates and constraints:}
% Due to the inherent randomness of large language models, the extracted coordinates and conditional information may occasionally contain errors. To address this issue, this study proposes a self-developed model that first reads the coordinates. If any non-compliant characters are detected, the first phase is restarted. Subsequently, the model reads the conditional information; if there are errors in the condition names or the number and type of parameters, the first phase is similarly restarted. Notably, after successfully reading the conditional information, if each condition code executes successfully without assigning values to the parameters, that condition is deemed redundant and is subsequently removed.


% \begin{figure}[htbp]
%     \centering
%     \includegraphics[width=0.5\textwidth]{latex/fig/二阶段 .png} % 替换为你的图片文件名
%     \caption{Two-stage diagram}
% \end{figure}

% \textbf{Solve:}
% In the problem-solving process, this study employed an "onion peeling" approach. Initially, after determining the coordinates of a specific point, the variables involved in the coordinates of other points were extracted into a variable list. Subsequently, an iterative method was used to traverse each variable, and precise coordinates could be obtained once a variable satisfying all conditions was found. It is important to note that during this process, multiple sets of coordinates can be obtained, and graphical representations can be generated while evaluating the quality of each generated graph, thereby allowing for the selection of the most "superior" graph. The generation problem can also be transformed into an "optimization problem," which will become a focal point for future research. Considering time efficiency, this study only selected the first feasible solution.


% \textbf{}
% During the information extraction process, large models may introduce errors in the extracted coordinates and constraints due to their inherent randomness and uncertainty. Furthermore, the model may also incorporate an excessive number of variables in the coordinates as a result of imprecision during the extraction process, thereby increasing the complexity of the solving procedure and extending the computation time beyond the predetermined limits. To address these issues, when errors or insufficient accuracy in the extraction results are detected, we will restart the information extraction process to ensure the accuracy of the coordinates and constraints, thereby enhancing the efficiency and reliability of the solution.

\begin{figure}[t]
    \centering
    \includegraphics[width=0.48\textwidth]{latex/fig/crop_modify_data_en.pdf} % 替换为你的图片文件名
    \caption{Illustrating an example of modifying the original text to include necessary information during MagicGeoBench construction. }
    \vskip -0.2in
    \label{fig:modifydata}
\end{figure}

\subsection{Coordinate-aware Generation}
\label{sec:generate}
While directly inputting precise coordinates and textual descriptions into generative models may seem intuitive, it often leads to disorganized visual elements (e.g., misaligned points and lines) that fail to faithfully represent the intended structure. To overcome this limitation, we introduce a more disciplined approach, employing TikZ as an intermediate representation, similar to AutomaTikZ~\cite{belouadi2023automatikz}. However differently, we capitalize on precise point coordinates to harness the zero-shot code generation capabilities of LLMs, eliminating the need for finetuning. This enables the generation of figures that not only maintain structural clarity but also exhibit high fidelity to the original textual descriptions.

\begin{figure*}[t]
    \centering
    \includegraphics[width=1.0\textwidth]{latex/fig/main_exp_en.pdf} % 替换为你的图片文件名
    \caption{Qualitative comparison with other approaches. Our method generates results that rigorously adhere to geometric constraints while maintaining high perceptual quality.}
    \label{fig:qualitative}
\end{figure*}

\begin{table*}[ht]
\centering
\small  % Reduce font size for the rest of the table
\setlength{\tabcolsep}{4pt}  % Reduce column padding
\renewcommand{\arraystretch}{1.3}  % Slightly increase row height (line spacing)
\begin{tabular}{c |c c c c |c c c c}
\hline
{\multirow{2}{*}{\textbf{ Method}}} & \multicolumn{4}{c|}{\textbf{Img-Txt}}  & \multicolumn{4}{c}{\textbf{Img-Img}} \\
                                 & \textbf{Circle} & \textbf{Triangle} & \textbf{Quadrangle} & \textbf{Avg} & \textbf{Circle} & \textbf{Triangle} & \textbf{Quadrangle} & \textbf{Avg} \\
\hline
SD3.5-Large~\cite{sauer2024fast} & 33.25 & \textbf{34.72} & \textbf{34.02} & \textbf{33.99} & 80.85 & 83.65 & 82.01 & 82.17 \\
AutomaTikZ~\cite{belouadi2023automatikz}          & 30.89 & 29.95 & 29.97 & 30.27 & 84.66 & 83.82 & 87.61 & 85.36 \\
MagicGeo (ours) & \textbf{33.93} & 31.89 & 32.13 & 32.65 & \textbf{91.49} & \textbf{88.16} & \textbf{89.90} & \textbf{89.85} \\
\hline
\end{tabular}
\caption{Quantitative comparison in terms of CLIP score. Higher values indicate better performance (↑).  }
\label{tab:clipscore}
\end{table*}

\section{Experiments}






\subsection{MagicGeoBench}
\label{sec:benchmark}

To rigorously evaluate the performance of text-to-geometric diagram models, we introduce the MagicGeoBench Dataset, a meticulously curated collection of 220 plane geometry questions drawn from high school entrance examinations. In constructing this dataset, we retain the original text for self-contained questions. For questions where essential information is embedded in diagrams rather than explicitly stated in text, we augment the textual descriptions so that diagram can be generated solely from textual input. Figure~\ref{fig:modifydata} illustrates such an example.
The evaluation dataset covers fundamental geometric shapes, and is systematically categorized into three groups: 70 questions on circles, 70 on triangles, and 80 on quadrangles.

% As illustrated in Figure 1, the upper section displays the processed question information, which closely resembles the original image in the lower left corner, while the lower right corner features the accompanying graphic from the question. 

% In Figure 2, the upper section presents the processed question information, which exhibits significant differences from the original image in the lower left corner, with the lower right corner showcasing the graphic included in the question.





% \begin{CJK*}{UTF8}{gbsn}
% \textbf{}
% This study presents an innovative three-phase framework for the automatic generation of planar geometric diagrams from textual prompts. In the first phase, to address the issue of vagueness in diagram generation, we employ large language models (LLMs) to extract coordinate and condition information, transforming the generation problem into a feasibility-solving problem. The second phase involves solving the feasibility problems identified in the first phase, thereby obtaining the specific coordinates of each point. In the third phase, we input these precise coordinates along with the original textual information into a large model, enabling it to generate the corresponding LaTeX code, thus facilitating the automatic generation of geometric diagrams.

% \end{CJK*}




% \begin{figure}[htbp]
%     \centering
%     \includegraphics[width=0.5\textwidth]{latex/fig/实验_预处理_1.png} % 替换为你的图片文件名
%     \caption{Raw data Figure 1}
% \end{figure}

% \begin{figure}[htbp]
%     \centering
%     \includegraphics[width=0.5\textwidth]{latex/fig/实验_预处理_2.png} % 替换为你的图片文件名
%     \caption{Raw data Figure 2}
% \end{figure}


\begin{table*}[t]
\centering
% \footnotesize
\scalebox{0.8}{%
% \renewcommand{\arraystretch}{1.3}  % Slightly increase row height (line spacing)
\begin{tabular}{c|cccc|cc c c}
\hline

\multirow{2}{*}{\textbf{Method}} & \multicolumn{4}{c|}{ \textbf{Textual alignment}} & \multicolumn{4}{c}{ \textbf{Image quality}} \\ 
                 & \textbf{Circle} & \textbf{Triangle} & \textbf{Quadrangle} & \textbf{ Avg} & \textbf{Circle} & \textbf{Triangle} & \textbf{Quadrangle}  & \textbf{ Avg} \\
\hline
SD3.5-Large~\cite{sauer2024fast} & 2.50 & 2.20 & 2.72 & 2.47 & 2.42  & 2.11 & 2.11 & 2.21  \\
AutomaTikZ~\cite{belouadi2023automatikz} & 2.28 & 2.08 & 2.12 & 2.16 & 2.28  & 2.08 & 2.15 & 2.17  \\
 MagicGeo (ours) & \textbf{1.22} & \textbf{1.12} & \textbf{1.06} & \textbf{1.13} & \textbf{1.30} & \textbf{1.20} & \textbf{1.20} & \textbf{1.23}  \\
\hline
\end{tabular}%
}
\caption{Average user ranking score of textual alignment and image quality. 1 is the best, 3 is the worst. It is evident that users prefer our results
more than others given the superior quality of ours.}
\label{tab:humanevaluation}
\end{table*}


\subsection{Settings}





% Taking rectangles within polygon data as an example, we minimized the number of variables by establishing fixed coordinate points (such as (0,0), (x,0), (x,y), and (0,y)), thereby accelerating the geometric generation process.

% During the extraction of coordinates, the inherent randomness of large language models can lead to occasional information extraction errors. To mitigate this issue, we implemented a mechanism allowing for a maximum of three extraction attempts. If information extraction remains unsuccessful after three attempts, the problem is deemed unresolvable. Additionally, when faced with complex conditions and multiple variables, we imposed a time constraint of one hour for solving the true coordinates once information has been successfully extracted. If valid results are not obtained within this timeframe, the problem will also be considered unresolvable.

% Upon obtaining the true coordinates, we pass them along with the problem input to the subsequent large model for the generation of the corresponding LaTeX code. When processing circular data from the Geo-Generation dataset, it is essential to include radius information in the basic prompt to ensure that the generated LaTeX code accurately reflects the geometric characteristics of the circle.


\noindent
\textbf{Baselines.}
There is a lack of extensive research focusing on the automatic generation of geometric diagrams. Hence we compare our proposed approach with two established baselines. The first baseline, Stable Diffusion 3.5 (SD3.5)~\cite{sauer2024fast}, is a robust model known for its prowess in generating photorealistic images across a variety of domains. Its ability to synthesize high-quality, realistic images positions it as a strong competitor in the image generation space. The second baseline, AutomaTikZ~\cite{belouadi2023automatikz}, utilizes the TikZ language as an intermediate step for creating high-quality graphical representations, which is a relevant benchmark for our work in the domain of geometric diagram generation. 

\noindent
\textbf{Evaluation Metrics.}
Our goal is to ensure that the diagrams both adhere to textual instructions and conform to typical visual characteristics of geometric illustrations, distinguishing them from photorealistic images. 
To evaluate these two aspects, we utilize CLIP~\cite{radford2021learning} to calculate cosine similarity.
% between the generated diagram and textual description as well as the reference image.
% Both the generated diagram and the reference diagram are resized to 224 × 224 pixels and features are extracted using the CLIP image encoder, while the textual description is encoded with the CLIP text encoder.
Given that CLIP is designed for general images, we also conduct a user study to validate the effectiveness of our model.
% in assessing alignment and quality.



\begin{table}[t]
\centering
% \footnotesize
\scalebox{0.8}{%
% \renewcommand{\arraystretch}{1.3}  % Slightly increase row height (line spacing)
\begin{tabular}{c|cccc}
\hline

                 & {Circle} & {Triangle} & {Quadrangle} & {Avg}\\
\hline
w/o Verification & 92.0 & 95.7 & 96.3 & 94.7 \\
w Verification & \textbf{97.3}& \textbf{100} & \textbf{98.8} & \textbf{98.7} \\
\hline
\end{tabular}%
}
\caption{Illustrating the pivotal role of the
verification mechanism in enhancing the autoformalization process.}
\vskip -0.2in
\label{tab:verification}
\end{table}







\begin{figure}[t]
    \centering
    \includegraphics[width=0.48\textwidth]{latex/fig/solver_ablation_en.pdf} % 替换为你的图片文件名
    \caption{Illustrating that the solver effectively ensures precise alignment with the accompanying text.}
    \vskip -0.1in
    \label{fig:solver}
\end{figure}

\subsection{Results}

\noindent
\textbf{Quantitative Evaluation.}
Table~\ref{tab:clipscore} presents a comparison between our approach and competitive baselines in terms of CLIP score. When compared to the dedicated image model SD3.5~\cite{sauer2024fast}, our model exhibits a higher similarity to the reference image, as suggested by the image-to-image score. 
However, we notice that in terms of image-text alignment, our model achieves a lower CLIP score. This discrepancy is likely due to the CLIP model’s broad training on general image-text pairs, which may bias towards general image generation models. More importantly, our model surpasses the text-to-diagram baseline AutomaTikZ~\cite{belouadi2023automatikz} in both image-text alignment and image quality, demonstrating the effectiveness of our approach.

% In contrast, when compared to text-to-diagram baseline AutomaTikZ~\cite{belouadi2023automatikz}, our approach outperforms the baseline on both image-text alignment and image quality. This superior performance underscores the effectiveness of our method.





\noindent
\textbf{Qualitative Evaluation.}
In addition to quantitative metrics, qualitative evaluation plays a crucial role in assessing generation task. 
We provide the qualitative visual comparison of these methods in Figure~\ref{fig:qualitative}. 
The baseline method SD3.5~\cite{sauer2024fast} generally succeeds in generating simple geometric shapes such as circles and triangles, but it struggles to accurately produce more complex geometric configurations, such as a triangle inscribed within a circle. On the other hand, AutomaTikZ~\cite{belouadi2023automatikz} is capable of generating visually appealing diagrams owing to its use of the TikZ language.
However, both methods fail to consistently adhere to underlying geometric constraints, resulting in diagrams that exhibit noticeable inconsistencies upon inspection.
In contrast, our proposed method rigorously adheres to geometric constraints while simultaneously maintaining a high level of perceptual quality. 



\noindent
\textbf{User Study.}
In order to obtain the user’s subjective evaluation of the generated image, we conduct a user study involving 20
participants. In the study, we use 60 samples with 20 in each category. Each sample is consisted of a text input paired with three corresponding output images. 
Participants were instructed to independently rank each image (1 is the best, 3 is the worst) on two distinct aspects: (i) image quality and (ii) adherence to the textual description. 
We report the average
ranking score in Table~\ref{tab:humanevaluation}. It is evident that users prefer our results
more than others given the superior quality of ours.



\begin{table*}[t]
\centering
% \small  % Reduce font size for the rest of the table
\setlength{\tabcolsep}{4pt}  % Reduce column padding
\renewcommand{\arraystretch}{1.3}  % Slightly increase row height (line spacing)
\begin{tabular}{c|c c c c |c c c c}
\hline
{\multirow{2}{*}{{ Method}}} & \multicolumn{4}{c|}{{Img-Txt}}  & \multicolumn{4}{c}{{Img-Img}}  \\
                                 & {Circle} & {Triangle} & {Quadrangle} & {Avg} & {Circle} & {Triangle} & {Quadrangle} & {Avg} \\
\hline
w/o Coordinates            & 31.25 & 31.31 & 30.44 & 31.00 & 86.31 & 88.46 & 88.90 & 87.89 \\
w/o Solver            & 32.25 & 31.52 & 30.77 & 31.51 & 87.37 & \textbf{88.51}  & \textbf{90.84}  & 88.91 \\
MagicGeo (ours) & \textbf{33.93} & \textbf{31.89}  & \textbf{32.13}  & \textbf{32.65}  & \textbf{91.49}  & 88.16 & 89.90 & \textbf{89.85}  \\
\hline
\end{tabular}
\caption{The effect of solver in terms of CLIP score. Using LLM to directly generate TikZ code is denoted as w/o Coordinates. Asking LLM to infer coordinates followed by coordinate-aware generation is denoted as w/o Solver.}
\vskip -0.1in
\label{tab:ablation_clipscore}
\end{table*}


\subsection{Ablations}

\noindent
\textbf{The Effect of Verification.}
In our framework, when the solver fails to find a solution, feedback is provided to the LLM for re-autoformalization, a process we refer to as verification. This process allows for a maximum of five feedback iterations, aiming to iteratively correct errors identified by the solver. Here we compare its performance against a baseline system that excludes verification. The evaluation criterion focuses on the accuracy of output points and constraints, which are manually verified. As shown in Table~\ref{tab:verification}, the incorporation of verification results in a substantial improvement in autoformalization accuracy, increasing from 94.7\% to 98.7\%. This highlights the pivotal role of the solver’s feedback mechanism in enhancing the autoformalization process.

\noindent
\textbf{The Effect of Solver.}
We propose the use of analytical geometry methods to develop a custom solver designed for precise point location determination, which is subsequently leveraged for diagram generation. To evaluate the effectiveness of our solver, we compare our approach against two alternative methods:
(1) w/o Coordinates: this approach utilize LLMs to directly generate TikZ code without incorporating explicit point coordinates, akin to the approach used in AutomaTikZ;
(2) w/o Solver: this variant first ask the LLM to infer the point coordinates and then use these coordinates for coordinate-aware TikZ generation.
We compare their results in terms of the CLIP score in Table~\ref{tab:ablation_clipscore}. 
% It can be seen that incorporating explicit coordinates improves the quality of diagram generation, and using our custom solver yields the best performance.
To provide a clearer understanding, we present several visual examples in Figure~\ref{fig:solver}.
% , quantitative comparison in terms of CLIP score is in the Appendix.
The incorporation of explicit coordinates significantly enhances the quality of diagram generation. However, some issues persist, such as the failure to satisfy the constraint "angle ABC equals 49 degrees" in the first example and the constraint "angle ADC equals 120 degrees" in the second example. In contrast, the application of solver effectively addresses all constraints, ensuring precise alignment with the accompanying text and thus superior quality. 
% Notably, , demonstrating its robustness and reliability in achieving accurate diagram generation. 

\begin{table}[t]
\centering
\scalebox{0.8}{%  Adjust scaling factor
\renewcommand{\arraystretch}{1.3}  % Slightly increase row height (line spacing)
\begin{tabular}{c|c|cccc}
\hline
{{Stage}} & {{LLM}} & \multicolumn{1}{c}{{Circle}} & \multicolumn{1}{c}{{Triangle}} & \multicolumn{1}{c}{{Quad}} & \multicolumn{1}{c}{{Avg}}\\ 
\hline
\multirow{3}{*}{1}& DeepSeek-V3  &  {0.97} &  {1.00} &  {0.99} &  {0.99} \\
&Qwen-plus & 0.96  & 0.99 & 0.99 & 0.98  \\
&GPT-4o mini       & {0.97} & 0.99  & 0.99 & 0.98\\
\hline
\multirow{3}{*}{3}& DeepSeek-V3 &  {1.00}  &  {1.00}  &  {1.00}  &  {1.00}  \\
&Qwen-plus & 1.00  & 1.00 & 0.97 &  0.99 \\
&GPT-4o mini      & 0.99 & 1.00  & 1.00 & 1.00\\
\hline
\end{tabular}%
}
\caption{Illustrating that our framework is robust to different LLMs, which shows negligible impact.}
\vskip -0.2in
\label{tab:LLMs}
\end{table}

\noindent
\textbf{The Effect of Using Different LLMs.}
We employ the DeepSeek-V3~\cite{liu2024deepseek} model for both Stage 1 and Stage 3 in our framework. To study the impact of different LLMs, we investigate two models: Qwen-plus~\cite{yang2024qwen2} and GPT-4o mini~\cite{shahriar2024putting} . We isolate the LLM variation to a single stage—either Stage 1 or Stage 3—while maintaining the other stage constant.
For evaluation, we manually examine autoformalization accuracy in Stage 1 and visually inspect the generated diagrams in Stage 3. A sample of 60 instances was experimented, with the accuracy presented in Table~\ref{tab:LLMs}.
It is important to note that we utilize distinct prompts for different LLMs to fully harness their respective capabilities.
Our findings indicate that the choice of LLM has a negligible impact on the final outcomes, demonstrating the suitability of LLMs for these tasks. This suggests that our framework maintains consistent performance regardless of the specific LLM.

\begin{figure}[t]
    \centering
    \includegraphics[width=0.49\textwidth]{latex/fig/application_exp_en.pdf} % 替换为你的图片文件名
    \caption{Application to diagram editing. }
    \vskip -0.1in
    \label{fig:application}
\end{figure}


\subsection{Application to Diagram Editing}
Our method leverages precise coordinate information and thus is able to make effective diagram modifications based on user intent. We present examples of diagram editing results in Figure~\ref{fig:application}. Simple tasks, such as adding or deleting lines, are accomplished by re-executing the third stage. More complex adjustments(e.g., specify a new angle degree in the first example), are handled effectively by our framework, which quickly determines the necessary coordinates for adjustment.
This demonstrates the potential of our framework in real-world diagram editing applications.


\section{Conclusion}

In conclusion, this paper presents MagicGeo, a novel framework for the automatic generation of geometric diagrams from textual descriptions, which stands out for its training-free approach and high precision. By reframing the diagram generation task as an optimization problem, MagicGeo ensures the accuracy of key geometric properties—such as parallelism and orthogonality—by leveraging analytical geometry rules.
The comprehensive evaluation of MagicGeo, including empirical comparisons with state-of-the-art baselines and ablation studies, demonstrates its effectiveness in producing accurate and reliable diagrams. Ultimately, MagicGeo offers significant potential for streamlining the creation of educational and academic diagrams, with broader implications for enhancing content generation in scientific and educational settings.

\section{Limitations}

While MagicGeo demonstrates notable advancements in the automatic generation of geometric diagrams from textual descriptions, several limitations must be acknowledged.


One limitation of our framework is its reliance on LLMs to translate complex geometric descriptions into formal representations that adhere to geometric conventions and generate accurate TikZ code. Although current translation performance, as shown in the ablation, is highly effective, it is not yet flawless, with visual examples presented in the Appendix section. We anticipate that ongoing advancements in LLM research, particularly in mathematical reasoning and code generation, will mitigate this limitation.

The current solver exhibits extended processing times for complex diagrams, with efficiency influenced by factors such as input complexity, the number of geometric entities, and the precision required for diagram generation. Preliminary experiments indicate that generation times typically range in the order of seconds; while for very intricate complex geometric diagram, processing times can exceed one hour. Future work will focus on enhancing solver efficiency through parallelization, optimized constraint-solving methods, and the development of heuristic techniques that balance computational cost and diagram accuracy.
% This would help to mitigate the current limitations in solver time efficiency and broaden the applicability of MagicGeo in real-world applications.

% limitations on the solver time efficiency











































% \begin{CJK*}{UTF8}{gbsn}
% 在实验结果的评估中，我们采用了Clip Score和人工评估相结合的方式。人工评估分为两个方面：一是准确度判定，依据为生成图形是否符合题目要求的结构；二是根据图形与题目要求的对齐程度，以及生成质量，对不同模型进行比较。

% 对于使用的DeepSeek大模型，实验结果显示：圆形的精确度为88\%，多边形为85\%，三角形为82\%。具体结果见下图。图中展示了圆形的生成结果，从对齐程度来看，该图形符合题目要求；从生成质量来看，图形大小适中，标注准确，且各物理实体的位置合理（包括点、线、面）。

% 然而，对于生成失败的例子，我们也进行了详细分析。如图1所示，某题的坐标和条件较为复杂，大模型提取的信息不完整甚至错误，导致无法生成图形。图2中，题目中包含过多坐标点且条件冗杂，尽管信息提取准确，生成坐标时仍因计算时间过长而未能完成图形生成。

% 此外，我们还使用了其他大模型进行对比实验。图中展示了Qwen模型，其在信息提取方面与DeepSeek表现相近，但生成的LaTeX代码中存在较多小错误，且生成图形的质量较低，难以辨识。对于GPT-4O-mini模型，信息提取方面存在较大问题，尤其是对于中文语料（尤其是初中数学题），缺乏足够的预处理，导致信息提取出现误差。

% 为了进一步验证我们的实验思路，我们进行了消融实验，比较了直接生成LaTeX代码与先提取坐标点后生成LaTeX代码两种方法的效果。

% 从实验结果表格中可以看出，采用直接生成LaTeX代码的方法时，圆形、三角形和多边形的文本对齐程度较低，仅约为20\%。这一结果表明，目前大模型在示意图生成方面仍存在较大挑战，表明这一领域有着广阔的改进空间。此外，由于数据集取自中国中学生数学几何题目，GPT模型在此实验中的生成代码质量较低，可能与该模型对特定语境的处理能力有关。

% 而在先提取坐标点后生成LaTeX代码的实验中，文本对齐程度有所提升，但仍未达到理想水平。通过首先提取坐标点后再生成LaTeX代码，生成的结果更加精确且具有更明确的目标性，从而使得生成图形的质量得到了改善。

% \end{CJK*}





% Bibliography entries for the entire Anthology, followed by custom entries
%\bibliography{anthology,custom}
% Custom bibliography entries only
\bibliography{custom}

% \appendix

% \newpage

% \section{Implementation Details}
% \label{sec:appendix}

% % \noindent
% % \textbf{Implementation Details.}
% We set the maximum number of verfication to be five. 
% Both the generated diagram and the reference diagram are resized to 224 × 224 pixels and features are extracted using the CLIP image encoder, while the textual description is encoded with the CLIP text encoder.
% % To better investigate the autoformalization capabilities of LLMs, we employ a category-specific prompt tailored to the three primary types within the MagicGeoBenchmark dataset. 
% The time complexity of our custom solver is primarily dependent on the number of variables that require resolution. Consequently, we aim to leverage condition prior to reduce the number of variables. For instance, we may assume the origin of the circle to be at (0,0) and set the radius to 1 if no specific length is provided. This approach significantly accelerates the optimization solver. Furthermore, a time constraint of 60 minutes is imposed; if valid results are not obtained within this period, the problem is deemed unresolvable.
% We employ DeepSeek-V3~\cite{liu2024deepseek} for LLM, which is strong in reasoning and coding,  in our experiments for both stage one and stage three. We also experiment different LLMs and report their effect in ablation study. 

% \setlength{\algomargin}{1em}
% \begin{algorithm}[h]
% \caption{MagicGeo}
% \label{alg:magicgeo}

% \SetAlgoLined
% \KwIn{
%     Textual description ($T$)
%     % , \\
%     % Coordinate Logic Form($\mathcal{CLF}$), \\
%     % Condition Logic Form($\mathcal{CoLF}$)
% }
% \KwOut{Geometric diagram ($D$)} 

% % Quadrangle type classification and diagram generation
% \While{not reach the maximum number }{
    
%     % Step 1: Generate coordinates and constraints based on logic forms
%     \textbf{Stage 1:}\\
%     $Points$, $Constraints$ = $LLM(T,Prompt)$; \\
%     \textbf{Stage 2:}\\
%     \If{Type\_Break($Constraints$)}{
%         continue;
%     }
%     Extract $Variables$;\\
%     Generate Value Combinations $Combos$;\\
%     \ForEach{combo in Combos}{
%         $Variables=combo$;\\
%         $find = True$;\\
%         \ForEach{cons in Constraints}{
%             \If{Constraint\_Break($cons$)}{
%                 $find = False$;\\
%                 break;
%             }
%         }
%         \If{find}{
%             break;
%         }        
%     }
%     \If{not find}{
%         continue;
%     }
%     \textbf{Stage 3:}\\
%     Assign $combo$ to $Points$;\\
%     $Code$ = $LLM(Points,T,Prompt)$;\\
%     Render $Code$ to PDF;\\
%     \Return;
% }

% \end{algorithm}

% \section{Algorithm Overview}
% MagicGeo functions through a three-stage process designed to efficiently transform raw input into well-structured geometric diagram problems. In the initial stage, a LLM is employed to translate the raw input data into standardized formal language propositions, ensuring that the problem is represented in a consistent and clear format. The second stage introduces an optimization solver integrated with verification mechanisms. This solver generates the necessary point coordinates that are pivotal for constructing accurate geometric configurations. Finally, in the third stage, these point coordinates are utilized to construct geometric diagram problems, ensuring that the generated diagrams are both mathematically valid and visually representative of the initial problem.
% The entire process of MagicGeo is comprehensively outlined in Algorithm~\ref{alg:magicgeo}, which provides a step-by-step breakdown of the system’s operation.


% \section{Prompt Details}
% Our framework leverages the zero-shot abilities of LLMs during the autoformalization phase, alongside coordinate-aware TikZ code generation. 
% To better elucidate the details of our experimental setup, we provide a comprehensive description of the prompts used to guide the LLM's behavior.
% Specifically, we prompt the LLM to generate two key pieces of information: coordinates $Points$ represented by variables $Vars$ and the required geometric constraints $Cons$ based on these coordinates $Points$. 
% We show the prompt instruction in Figure~\ref{fig:autoformalization_prompt1}, which provides the LLM with clear instructions to formalize the geometric problem.
% In addition to that, our framework incorporates specific geometric constraint instructions to enhance the LLM’s performance in this task. These instructions are designed to probe the LLM's capability to understand and encode geometric constraints in a formalized manner. The precise prompt used to guide the LLM through this process is presented in Figure~\ref{fig:autoformalization_prompt2}.
% The final phase of our framework involves the generation of TikZ code that accurately represents the geometric diagram.
% The prompt provided to the LLM for this task is succinct yet explicit: "Please provide the LaTeX code for generating the corresponding image with the given correct coordinate positions."




% \begin{figure}[t]
%     \centering
%     \includegraphics[width=0.5\textwidth]{latex/fig/prompt_instruction.pdf} % 替换为你的图片文件名
%     \caption{The task instruction prompt for LLM in autoformalization.}
%     \label{fig:autoformalization_prompt1}
% \end{figure}





% \begin{figure*}[t]
%     \centering
%     \includegraphics[width=1.0\textwidth]{latex/fig/prompt_instruction2.pdf} % 替换为你的图片文件名
%     \caption{The geometric constraint instruction prompt for LLM to guide the autoformalization.}
%     \label{fig:autoformalization_prompt2}
% \end{figure*}

% \begin{figure*}[t]
%     \centering
%     \includegraphics[width=1.0\textwidth]{latex/fig/failure_case.pdf} % 替换为你的图片文件名
%     \caption{Failure case analysis in our framework.}
%     \label{fig:failure_case}
% \end{figure*}

% \section{Failure Case Analysis}
% While MagicGeo shows significant promise, we conduct a thorough failure case analysis to identify areas for improvement. Our framework consists of three phases, with an example provided for each, as illustrated in Figure~\ref{fig:failure_case}.

% In stage 1, a key failure arises from the reliance on the LLM for autoformalization. Although the LLM is designed to formalize geometric constraints, there are instances where the formalized constraints may not fully adhere to necessary geometric rules. This discrepancy occurs when the formalization introduces constraints that are logically inconsistent with geometric principles, rendering them incompatible with the solver in subsequent steps.

% In stage 2, as discussed in the limitations section, the solver may experience delays when handling complex diagrams. To improve efficiency, we provide a value range for the solver, which can lead to scenarios where correct autoformalizations still fail to produce a valid solution within the specified range. Future work will focus on investigating more efficient algorithms for handling larger ranges. Additionally, the solver may generate a technically correct solution that is visually suboptimal. Points may be placed too close together, creating a cluttered diagram, as shown in the figure. This issue can be addressed by the diagram editing technique presented in this paper or by adding a constraint to prevent excessive proximity between points. 

% In stage 3, failure again stems from the LLM, where points may receive correct coordinates, but the generated TikZ code is incorrect, such as improper labeling. For instance, the diagram in the figure shows two 'O' labels near the same point.










% \section{Additional Visual Comparison}

% We provide additional qualitative visual comparison with baselines in Figure~\ref{fig:qualitative_rest}. 
% Upon inspection, it is evident that both baselines fail to consistently adhere to the underlying geometric constraints, resulting in diagrams that exhibit significant inconsistencies.
% Our proposed method rigorously adheres to geometric constraints while simultaneously maintaining a high level of perceptual quality. 


% \begin{figure*}[t]
%     \centering
%     \includegraphics[width=1.0\textwidth]{latex/fig/main_exp_rest.pdf} % 替换为你的图片文件名
%     \caption{Additional qualitative comparison with other approaches. Our method generates results that rigorously adhere to geometric constraints while maintaining high perceptual quality.}
%     \label{fig:qualitative_rest}
% \end{figure*}





\end{document}
