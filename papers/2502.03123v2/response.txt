\section{Related Work}
Current approaches in unsupervised disentangled representation learning are predominantly based on Variational Autoencoder (VAE) **Higgins, "Disentangling Disentanglement"** or information-theoretic Generative Adversarial Network (InfoGAN) **Chen et al., "InfoGAN: Interpretable Loss for Image Recognition Adversarial Training"**
 frameworks. These methods generally share a core principle: introducing additional regularization terms into the model's loss function to reduce statistical dependencies among latent variables, thereby promoting disentangled representations.
\paragraph{VAE-based Methods.} Among VAE-based approaches, **Higgins et al., "Î²-VAE: Learning Basic Object Appearance and Arrangement"** stands as a seminal work. By introducing a tunable hyperparameter $\beta$ into the Evidence Lower Bound (ELBO) loss function, this method constrains the posterior distribution of latent variables. While its objective is to encourage alignment between the posterior distribution and a predefined independent prior (typically an isotropic Gaussian), increasing the weight of the KL divergence term ($\beta > 1$) effectively restricts the latent space capacity and induces lower statistical dependencies across dimensions. However, selecting an optimal $\beta$ remains challenging, as higher values may degrade reconstruction fidelity. 

To more directly minimize statistical dependencies, **Kim et al., "Disentangling Factors of Variation using Early-Ensembles"** employs an adversarial learning strategy. It introduces a discriminator to distinguish between latent codes sampled from the aggregated posterior distribution and those from an independent prior distribution, thereby explicitly penalizing the Total Correlation (TC) of latent variables. This approach directly optimizes the aggregated posterior to approximate an independent distribution.

Building upon this, **Burgess et al., "Compositional Video Prediction"** decomposes the KL divergence term in the VAE objective into three components: index-code mutual information, total correlation (TC), and dimension-wise KL divergence. By assigning distinct weights to these components, $\beta$-TCVAE achieves finer-grained control over latent dependencies. Its central innovation lies in explicitly penalizing TC to reduce interdimensional correlations.
\paragraph{GAN-based Methods.} Within the domain of GAN-based methods, **Chen et al., "InfoGAN: Interpretable Loss for Image Recognition Adversarial Training"** a significant contribution, giving rise to a series of InfoGAN-based variants, including InfoGAN-CR**[authors], "InfoGAN with Contrastive Regularizer"** and PS-SC GAN**[authors], "PS-SC GAN: Progressive Spatial-Spectral Consistency Generative Adversarial Network"**. The objective of InfoGAN is to learn interpretable latent representations by maximizing the mutual information between a subset of the latent variables and the output of the generator. Although its primary objective is not the direct minimization of statistical dependencies across all latent variables, InfoGAN indirectly facilitates a reduction in statistical dependencies between specific latent variables encoding semantic features and the remaining latent variables. This effect contributes to the emergence of disentangled representations. 

InfoGAN-CR, a variant of InfoGAN with a contrastive regularizer, generates multiple images by fixing one dimension, denoted $c_i$, of the latent representation, while randomly sampling the other dimensions, denoted $c_j(i \neq j)$. A classifier is then trained to identify which latent dimension was fixed based on the generated images. The contrastive regularizer promotes differentiation among latent representation dimensions, thereby supporting disentanglement.

\begin{figure*}[htbp] 
\centering 
\includegraphics[width=\textwidth]{pics/framework.pdf} 
\caption{ The framework of the proposed DiD. The blue points denote $\mathbf{c}$ sampled from the uniform distribution, the red points represent samples obtained from two orthogonal axes.} 
\label{fig::model}