In this section, we empirically compare the proposed algorithm on both sequence windows and time windows with existing methods.
\paragraph{Datasets} For the sequence-based model, we used two synthetic datasets and two cross-language datasets. The statistics of the datasets are provided in Table \ref{table:statistics}:

\begin{table}[t]
    \centering
    \caption{The statistics of the datasets. The datasets satisfy $1 \leq \|\vx\|\|\vy\| \leq R $.}
    \label{table:statistics}
    \begin{tabular}{|c|c|c|c|c|c|}
    \hline
        Dataset & $n$ & $m_x$ & $m_y$ & $N$ & $R$ \\ \hline
        SYNTHETIC(1) & 100,000 & 1,000 & 2,000 & 50,000 & 65 \\ \hline
        SYNTHETIC(2) & 100,000 & 1,000 & 2,000 & 50,000 & 724 \\ \hline
        APR & 23,235 & 28,017 & 42,833 & 10,000 & 773 \\ \hline
        PAN11 & 88,977 & 5,121 & 9,959 & 10,000 & 5,548 \\ \hline
        EURO & 475,834 & 7,247 & 8,768 & 100,000 & 107,840 \\ \hline
    \end{tabular}
\end{table}

\begin{itemize}
    \item Synthetic: The elements of the two synthetic datasets are initially uniformly sampled from the range (0,1), then multiplied by a coefficient to adjust the maximum column squared norm $R$. The X matrix has 1,000 rows, and the Y matrix has 2,000 rows, each with 100,000 columns. The window size is set to 50,000.
    \item APR: The Amazon Product Reviews (APR) dataset is a publicly available collection containing product reviews and related information from the Amazon website. This dataset consists of millions of sentences in both English and French. We structured it into a review matrix where the X matrix has 28,017 rows, and the Y matrix has 42,833 rows, with both matrices sharing 23,235 columns. The window size is 10,000.
    \item PAN11: PANPC-11 (PAN11) is a dataset designed for text analysis, particularly for tasks such as plagiarism detection, author identification, and near-duplicate detection. The dataset includes texts in English and French. The X and Y matrices contain 5,121 and 9,959 rows, respectively, with both matrices having 88,977 columns. The window size is 10,000.
\end{itemize}
We evaluate the time-based model on another real-world dataset:
\begin{itemize}
    \item EURO: The Europarl (EURO) dataset is a widely used multilingual parallel corpus, comprising the proceedings of the European Parliament. We selected a subset of its English and French text portions. The X and Y matrices contain 7,247 and 8,768 rows, respectively, and both matrices share 475,834 columns. Timestamps are generated using the $Poisson$ $Arrival$ $Process$ with a rate parameter of $\lambda=2$. The window size is set to 100,000, with approximately 30,000 columns of data on average in each window.
\end{itemize}

\paragraph{Setup} For the sequence-based model, we compare the proposed hDS-COD and  aDS-COD with EH-COD~\cite{yao2024approximate} and DI-COD~\cite{yao2024approximate}. We do not consider the Sampling algorithm as a baseline, as its performance is inferior to that of EH-COD and DI-CID, as demonstrated in \cite{yao2024approximate}. %The hDS-COD is adjusted by the parameter $\ell$ and the maximum number of levels $L = \log{R}$, where $R$ is the prior estimate of the maximum squared column norm of the dataset. DI-COD similarly requires a prior estimate of $R$ to limit the maximum number of levels $L = \log{(R/\varepsilon})$. In contrast, aDS-COD and EH-COD do not require an estimate of $R$; their error-space balance is controlled by the parameter $\ell = \frac{1}{\varepsilon}$. 
For the time-based model, we compare the proposed hDS-COD and  aDS-COD with EH-COD and the Sampling algorithm since DI-COD cannot be applied to time-based sliding window model. To achieve the same error bound, the maximum number of levels for hDS-COD is set to $L = \log{(\varepsilon NR)}$, and the initial threshold for aDS-COD is set to $1$.

Our experiments aim to illustrate the trade-offs between space and approximation errors. The x-axis represents two metrics for space: final sketch size and total space cost. The final sketch size refers to the number of columns in the result sketches $\mA$ and $\mB$ generated by the algorithm, representing a compression ratio. The total space cost refers to the maximum space required during the algorithm's execution, measured by the number of columns.We evaluate the approximation performance of all algorithms based on correlation errors $\operatorname{corr-err}(\mathbf{X}_W \mathbf{Y}_W^\top, \mathbf{A} \mathbf{B}^\top)$, which is reflected on the y-axis. Every 1,000 iterations, all algorithms query the window and record the average and maximum errors across all sampled windows.

The experiments for all algorithms were conducted using MATLAB (R2023a), with all algorithms running on a Windows server equipped with 32GB of memory and a single processor of Intel i9-13900K.

\paragraph{Performance} Figure \ref{fig:error vs l} and Figure \ref{fig:error vs space} illustrate the space efficiency comparison of the algorithms on sequence-based datasets. Panels (a-d) show the average errors across all sampled windows, while panels (e-h) display the maximum errors.

Figure \ref{fig:error vs l} evaluates the compression effect of the final sketch. The hDS-COD, aDS-COD, and EH-COD show similar compression performances. But the DS series is more stable, particularly on the synthetic datasets, where they significantly outperform EH-COD and DI-COD. The performance of hDS-COD and aDS-COD is nearly the same, indicating that the adaptive threshold trick in aDS-COD does not have a noticeable negative impact on it, maintaining the same error as hDS-COD.

Figure \ref{fig:error vs space} measures the total space cost of the algorithms. hDS-COD and aDS-COD show a significant advantage over existing methods, as they can achieve the  $\varepsilon$-approximation error with much less space. For the same space cost, the correlation errors of hDS-COD and aDS-COD are much smaller than those of EH-COD and DI-COD. Also, aDS-COD has better space efficiency than hDS-COD because aDS only uses a single-level structure while hDS requires $\log R+1$ levels. We find that hDS-COD requires more space on  SYNTHETIC(2) dataset compared to SYNTHETIC(1) dataset. This phenomenon occurs because SYNTHETIC(2) dataset has a larger $R$, which confirms the dependence on $R$ as stated in Theorem~\ref{thm:hds}. 

Figure \ref{fig:time-based} compares the performance of algorithms on time-based windows. Panels (a) and (b) present the error against the final sketch size, which show that our aDS-COD and hDS-COD algorithms enjoy similar performance as EH-COD and significantly outperform the sampling algorithm. On the other hand, as shown in panels (c) and (d), our methods outperform baselines in terms of total space cost.
