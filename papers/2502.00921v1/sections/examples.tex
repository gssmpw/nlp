\section{Examples of critical windows}\label{sec:eg_theory}
In this section, we analytically compute $\Tbefore, \Tafter$ for diverse stochastic localization samplers and models of data, including diffusion and autoregression processes. In these natural settings, the critical window is small in the sense of having a size which shrinks or does not depend on the dimension or context length. We shall also connect our framework to in-context learning and the all-or-nothing phenomenon. \footnote{Proofs are deferred to Appendix~\ref{app:eg_theory}.}

\subsection{Diffusion}
We first consider two examples of Gaussian Mixture Models and a diffusion model. We show that with two isotropic Gaussians, the critical window appears around a single point, $\ln \|\mu\|$, with width independent of the dimension.

\begin{restatable}[Two Isotropic Gaussians]{example}{diffusiontwogaussian}\label{ex:twogmm}  Let $\Theta=\{\pm 1\}$, $p^{+1} = \mathcal{N}(\mu,\mathrm{Id})$, $p^{-1} = \mathcal{N}(-\mu,\mathrm{Id})$. Then, we have a critical window transitioning from sampling from both components to the component $+1$ between $\Tbefore = \ln \|\mu\| +\ln 2 + \ln 1/\epsilon$ and $\Tafter = \ln \|\mu\| -\ln \ln \frac{1}{2 \epsilon^2}$. When $\wh{T} \leq \Tafter$, then $\TV(\modrevlaw{+1}{\wh{T}}{},p^{+1}) \lesssim \epsilon$. When $\wh{T} \geq \Tbefore$, $\TV(\modrevlaw{+1}{\wh{T}}{},p)\lesssim \epsilon$. 
\end{restatable}


\noindent For an isotropic Gaussian mixture model with randomly selected means, the critical window between sampling from one component to the entire mixture is also narrow. Note that we derive dimension-free widths in Example~\ref{example:gaussianrandommeans}, an improvement over~\citep{li2024criticalwindowsnonasymptotictheory} who had a $\ln \ln d$ dependence on dimension for isotropic Gaussians.

\begin{restatable}[Random mean spherical Gaussians]{example}{gaussianrandommeans}\label{example:gaussianrandommeans} We first sample $\mu_i \sim \mathcal{N}(0,\mathrm{Id})$ for $i \in [K]$ i.i.d. and let $\Theta=\{\mathcal{N}(\mu_i,\mathrm{Id})\}_{i \in [K]}$. We let $\Sbefore=\Theta$ and $\Safter=\{\mu_1\}$. Then, we can compute $\Tbefore = \max_{j \in [K]} \ln \|\mu_i-\mu_j\|+\ln (1/\epsilon)$ and $\Tafter = \min_{j \in [K],i\ne j} \ln \|\mu_i-\mu_j\| -\frac12\ln 8\ln \frac{K}{\epsilon}.$ Furthermore, with high probability over the selection of the means, $\Tbefore-\Tafter = O_{K,\epsilon}(1)$ as $d \to \infty$. 
\end{restatable}
We also compute the critical windows of a discrete diffusion model. As the context length $T$ goes infinity, we show that the length of the critical window goes to $0$.
\begin{restatable}[Two Dirac delta functions with a random masking procedure]{example}{randommaskingdirac}\label{example:random_mask}  
Let $p \in \{\pm 1\}^T$, and consider a forward process with index set $\I=[0,1]$, $Y_0=X$, and $Y_t \in \{\pm 1,\mathrm{[MASKED]}\}^T$. For $t \in \I$, we let all the value at index $i \in [T]$ be set to $\mathrm{[MASKED]}$ with probability $t$ independently. For a mixture of two Dirac delta functions, we can express the critical window in terms of the \emph{Hamming distance} between the corresponding strings. Let $\Theta=\{\theta_{\pm 1}\}, \ell_{\pm 1} \in \{\pm 1\}^T, p^{\theta_{\pm 1}} \sim \delta_{\ell_{\pm 1}}, w_{\pm 1}=\frac{1}{2}$. Then, on component $1$ we have the critical window 
\begin{align}
\Tbefore = \exp\left[\frac{\ln (1-\epsilon)}{d_H(\delta_{\ell_{1}},\delta_{\ell_{-1}})}\right],\Tafter = \exp\left[\frac{\ln \epsilon^2}{d_H(\delta_{\ell_{1}},\delta_{\ell_{-1}})}\right]
\end{align}
For sufficiently large $d_H(\delta_{\ell_{1}},\delta_{\ell_{-1}})$, the window size $\Tbefore -\Tafter= O\left(\frac{1}{d_H(\delta_{\ell_{1}},\delta_{\ell_{-1}})}\right)$. If $d_H(\delta_{\ell_{1}},\delta_{\ell_{-1}})$ increases with $T$, then the width of the critical window negligible. 
\end{restatable}
\subsection{Autoregression}

\noindent We first present a theoretical model for important critical windows in LLMs, e.g., jailbreaks that occur over the first few tokens in the generation and the Yellowstone example~\citep{anthropicyellowstone,qi2024safetyalignmentjusttokens}.
\begin{restatable}[``Critical Tokens'' for Jailbreaks and Yellowstone~\citep{qi2024safetyalignmentjusttokens,anthropicyellowstone}]{example}{arjailbreaking}\label{example:ar_jailbreak}  
Again consider an autoregressive language model, with $\mathcal{A}$ denoting the vocabulary, $p \in \mathcal{A}^T$, a forward process indexed by $\I=\{0,1,2,\dots,T\}$, and $Y_t$ to be the first $T-t$ tokens of $X$. Let $\Theta=\{\theta_\textbf{harmful},\theta_\textbf{safe}\}$ (or $\{\theta_{\textbf{Googling Yellowstone}},\theta_{\textbf{coding}}\}$). We assume that these two modes do not differ until some $T-T' \in \I$. Between $T-T'$ and $T-T'-k$, the distributions become nearly disjoint, $P_{x \sim p_{T-T'-k}^{\theta_\textbf{harmful}}}\left(x\in \supp(p_{T-T'-k}^{\theta_\textbf{safe}})\right) \leq \epsilon.$ In the jailbreaking example, $T'=0$ and they are disjoint because the first tokens generated in the safe mode is always some form of refusal. In the Yellowstone example, they are disjoint the first time the agent decides to Google Yellowstone pictures. Then, on component $\theta_\textbf{harmful}$ we have the critical window $\Tbefore= T-T'$ and $\Tafter  = T-T'-k$. 
\end{restatable}
Notice that we can actually mitigate the effect of these critical windows by finetuning on examples of corrections to increase $P_{x \sim p_{T-T'-k}^{\theta_\textbf{harmful}}}\left(x\in \supp(p_{T-T'-k}^{\theta_\textbf{safe}})\right)$. This explains the effectiveness of finetuning on corrections in~\citep{qi2024safetyalignmentjusttokens}. Furthermore, the quantity that measures probability of mode-switching, $p^{\theta_\textbf{harmful}}/p$, suggests using a likelihood ratio to distinguish between harmful and benign prompts. In App.~\ref{app:jailbreak_dataset}, we test a class of likelihood ratio methods that obtain recall 5-10$\times$ the false positive rate for $5$ different types of jailbreaks (Table~\ref{tab:log_ratio_table}). We can also identify a critical window for a stylized model of solving a math problem as a random walk. 
\begin{restatable}[Math problem-solving as a random walk]{example}{arbinomialbiased}\label{example:ar_binomial} We model solving a math problem as taking a random walk on $\Z$ with stepsize $1$ of length $T$. If the random walk hits $+A$, then it has `solved` the problem; if the random walk hits $-A$, then it has obtained an incorrect solution. Assume that we have two modes: a strong problem solving mode (denoted $+1$), which takes a $+1$ step with probability $0.5+\Delta$, and a weak problem solving mode (denoted $-1$), which takes a $+1$ step with probability $0.5-\Delta$. Assuming that $\frac{\ln (2/\epsilon^2)}{2\Delta^2} < A$ and  $\epsilon^2 < 10^{-3}(0.5-\Delta)(0.5+\Delta)$, there is a critical window for the strong problem solving window of $\Tbefore= T-\frac{\epsilon^2}{\Delta^2}+2$ and $\Tafter  = T-\frac{\ln (2/\epsilon^2)}{2\Delta^2}.$ Note the critical window has width $\Theta(1/\Delta^2)$ independent of $T$. 
\end{restatable}
\noindent We defer an example of a critical window for an autoregressive model which expresses the outputs as emissions from a random walk of an underlying concept variable, akin to the model in~\citep{arora2019latentvariablemodelapproach}, to Appendix~\ref{app:autoregressive_gmm}.

\subsubsection{In-context learning}
Autoregressive critical windows can also be applied to describe in-context learning. In particular, we can capture the idea that with sufficiently many in-context examples, we learn the $\theta^* \in \Theta$ that generated the transitions for in-context examples, with a sample complexity in terms of $\Tafter$.
\begin{example}[Informal, see Example~\ref{ex:app:corrollary_icl}]
Consider an in-context learning setup, where the context $$[x_1,y_1,o,\dots,x_{T+1},y_{T+1},o]$$ consists of question-answer pairs $(x_i,y_i)$, delimiters $o$, and $x_i \to y_i$ sampled from $p^{\theta^*}$ for some $\theta^* \in \Theta$. In the forward-reverse experiment, we truncate it to $[x_1,y_1,o,\dots,x_{T+1}]$, and then resample with $p$ to produce $[x_1,\dots,x_{T+1},\tilde{y}_{T+1},o]$. The total variation between the sequences $[x_1,y_1,o,\dots,x_{T+1}]$ and $[x_1,\dots,x_{T+1},\tilde{y}_{T+1},o]$ can be viewed as the average-case error of the in-context learner and can be bounded within our critical windows framework. We have $\Tafter=3T+3-O_{\epsilon}(1)$, with $O_{\epsilon}(1)$ independent of $T$ ($\Safter \triangleq\{\theta^*\}$). Note that $\Tafter$ is the order of how many samples that can be erased so that we still are able to learn $\theta^* \in \Theta$. 
\end{example}
One might ask if there is a $\Tbefore$ for in-context learning, a threshold such that it is impossible to distinguish between $\Safter,\Sbefore$ with that many samples. In the next section, we will provide an example of a $\Tbefore$ for in-context learning with the all-or-nothing phase transition.
\subsubsection{All-or-nothing phenomenon}
Here we elucidate a formal connection between the critical windows phenomenon in in-context learning and the \emph{all-or-nothing} phenomenon. To begin, we first define the notions of strong and weak detection:
\begin{definition}
    Let $(N_s)$ be an increasing sequence of integers. Given sequences of distributions $(p_s), (q_s)$ over $z\in\R^{N_s}$, a sequence of test statistics $(\mathcal{A}_s: \R^{N_s} \to \R)$ with threshold $(\tau_s)$ achieves:
    \begin{itemize}
        \item \emph{strong detection} if $\limsup_{s\to\infty} \{\Pr_{z\sim p_s}[\mathcal{A}_s(z) < \tau_s] + \Pr_{z\sim q_s}[\mathcal{A}_s(z) \ge \tau_s]\} = 0$.
        \item \emph{weak detection} if $\limsup_{s\to\infty} \{\Pr_{z\sim p_s}[\mathcal{A}_s(z) < \tau_s] + \Pr_{z\sim q_s}[\mathcal{A}_s(z) \ge \tau_s]\} < 1$.
    \end{itemize}
\end{definition}
By the operational characterization of TV distance, strong detection is (information-theoretically) possible if and only if $\liminf_{s\to\infty}\TV(p_s,q_s) = 1$, and weak detection is (information-theoretically) possible if and only if $\liminf_{s\to\infty}\TV(p_s,q_s) > 0$. 

Now we consider the following Bayesian inference problem, given by a joint distribution $\pi$ over $(\theta,z) \in \R^n\times \R^m$. Nature samples unknown signal $\theta \in \R^n$ from $\pi_\theta$. Given sample size $N$, we receive observations $\{z_i\}_{i=1}^N$ drawn i.i.d. from $\pi_{z\mid \theta}$; the goal is to infer $\theta$ from these observations. Let $\pi^{(N)}$ denote the distribution over $\{z_i\}_{i=1}^N$, the mixture of product measures parametrized by $\theta$.
\begin{definition}
    Let $(\pi_s)$ be a sequence of inference tasks over $\R^{n_s}\times \R^{m_s}$ and $(\pi^{\mathsf{null}_s})$ be a sequence of distributions over $\R^{m_s}$. $(\pi_s)$ exhibits an \emph{all-or-nothing phase transition at threshold $(N_s)$ with respect to null models $(\pi^{\mathsf{null}_s})$} if:
    \begin{itemize}[noitemsep,topsep=0pt]
        \item For any $\beta < 1$: weak detection between $(\pi^{(\beta N_s)})$ and $((\pi^{\mathsf{null}_s})^{\otimes \beta N_s})$ is information-theoretically impossible
        \item For any $\beta > 1$: strong detection between the planted model $(\pi^{(\beta N_s)})$ and the null model $((\pi^{\mathsf{null}_s})^{\otimes \beta N_s})$ is information-theoretically possible
    \end{itemize}
\end{definition}

All-or-nothing phase transitions have been established for a number of natural inference tasks like sparse linear regression~\citep{reeves2019allornothingphenomenonsparselinear,gamarnik2019highdimensionalregressionbinarycoefficients}, sparse PCA~\citep{NEURIPS2020_cd0b43ea}, generalized linear models~\citep{barbier2020allornothingstatisticalcomputationalphase}, group testing~\citep{truong2021allornothingbehaviorbernoulligroup,pmlr-v178-coja-oghlan22a}, linear and phase retrieval models~\citep{scarlett2016limitssupportrecoveryprobabilistic,truong2020supportrecoveryphaseretrieval}, planted subgraphs~\citep{pmlr-v195-mossel23a}, and planted Gaussian perceptron~\citep{nilesweed2023allnothingsharpphase}. Here is an example for sparse linear regression:

\begin{theorem}[\cite{reeves2019allornothingphenomenonsparselinear}]\label{thm:formal_aon_sparse}
Let $\pi_s$ be the distribution over $\R^{n_s} \times \R^{m_s}$ for $n_s = s$ and $m_s = s+1$ where the marginal over $\theta$ is given by the uniform distribution over $k_s$-sparse vectors in $\{0,1\}^s$, and the conditional distribution $\pi_{z\mid \theta}$ is given by sampling $x\sim \mathcal{N}(0,\Id_s)$, taking $y = \langle \theta, x\rangle + \xi$ for $\xi\sim \mathcal{N}(0,\sigma^2_s)$, and outputting observation $z = (x,y)$. The null model $\pi^{\sf null}_s$ is given by sampling $x\sim \mathcal{N}(0,\Id_s)$ and outputting $y = \mathcal{N}(0,k_s + \sigma^2_s)$.

If $\sigma^2_s \ll k_s \le s^{0.499}$, then $(\pi_s)$ exhibits an all-or-nothing phase transition at threshold $(N^*_s)$ with respect to null models $(\pi^{\mathsf{null}}_s)$ for $N^*_s \triangleq \frac{2k_s \log(s / k_s)}{\log(1 + k_s/\sigma^2_s)}$.
\end{theorem}

Having defined the all-or-nothing phenomenon, we rigorously instantiate it as a critical window for in-context learning. We first define a mixture model $p^\Theta_{(N)}$ for sequence lengths $N$ onto which we will identify a critical window.
\begin{definition}\
    To any inference task $\pi$, null model $\pi^{\sf null}$, and sequence length $N$, we can associate the following in-context learning task. Let $\Theta = \Theta_{\sf signal} \sqcup \{\mathsf{NULL}\}$ where $\Theta_{\sf signal} \triangleq \mathrm{supp}(\pi_{\theta})$. Given $\theta\in\mathrm{\supp}(\pi_\theta)$, let $p_{(N)}^\theta$ denote the distribution over sequences $(z_1,\ldots,z_N,\mathrm{?},\theta)$ where $z_1,\ldots,z_N$ are i.i.d. samples from $p_{z\mid \theta}$. Let $p_{(N)}^{\mathsf{null}}$ denote the distribution over observations $(z_1,\ldots,z_N,\mathrm{?},\mathsf{NULL})$ where $z_1,\ldots,z_N$ are i.i.d. samples from $\pi^{\sf null}$. We then take $p^\Theta_{(N)} \triangleq \E_{\theta\sim \frac12 \pi_\theta + \frac12\delta_{\mathsf{NULL}}} p_{(N)}^\theta$.
\end{definition}
Under this model of data, we have the following theorem expressing the all-or-nothing phase transition in terms of $\Tbefore,\Tafter$.
\begin{restatable}{theorem}{aoncritwindow}
\label{thm:AoN_critwindow}
    Suppose $(\pi_s)$ is a sequence of inference tasks that exhibits an all-or-nothing phase transition at threshold $(N^*_s)$ with respect to null models $(\pi^{\sf}_s)$. Given $N_s \ge N^*_s$, let $(p_{(N_s)}^{s;\theta})_{\theta\in \Theta_s}$ denote the sequence of in-context learning tasks. For any constant $0 < \epsilon < 1$, there exist constants $\delta, \underline{s}$ such that for all $s \ge \underline{s}$, next-token prediction for $(p_{(N_s)}^{s;\theta})_{\theta\in \Theta_s}$ exhibits a critical window over $[N_s + 2 - (1 + \delta)N^*_s, N_s + 2 - - (1 - \delta)N^*_s]$ in which we transition from sampling a distribution $O(\epsilon)$-close in TV to $S_{\rm before} = \Theta_{s; \mathsf{signal}}$, to sampling from a distribution $O(\epsilon)$-close in TV to $S_{\rm after} = \Theta_s$. 
    
    In other words, we have $\Tbefore\triangleq N+2-(1 - \delta)N^*_s$ and $\Tafter\triangleq N+2-(1+ \delta)N^*_s$. 
\end{restatable}
The proof of Theorem~\ref{thm:AoN_critwindow} is essentially immediate from Theorem~\ref{thm:masters_theorem} and the definition of the all-or-nothing phase transition:
\begin{proof} 
    Let us first apply Theorem~\ref{thm:masters_theorem} to $S_{\rm init} = S_{\rm targ} = \Theta_{s;\mathsf{signal}}$. By the definition of $D_\Theta$, the parameter $W$ therein is $1$. Furthermore, we trivially have that $T_{\rm end}(\epsilon) = 0$. Finally, because strong detection is possible provided there are $N \ge \beta N^*_s$ in-context examples for $\beta > 1$, there exists $\delta_1$ depending only on $\epsilon$ for which $\TV(p^{S_{\rm targ}}_t, p^{\Theta_s - S_{\rm targ}}_t) \ge 1 - \epsilon^2$ for $t = N_s + 2 - (1 + \delta_1)N^*_s$. By Theorem~\ref{thm:masters_theorem} we conclude that $\TV(p^{S_{\rm init}, N_s + 2 - (1 + \delta_1)N^*_s}) \lesssim \epsilon$. Next, let us apply Theorem~\ref{thm:masters_theorem} to $S_{\rm init} = \Theta_{s;\mathsf{signal}}$ and $S_{\rm targ} = \Theta_s$. The parameter $W$ therein is now $0$. Furthermore, we trivially have that $T_{\rm end}(\epsilon) = N_s + 2$. Finally, because weak detection is impossible provided there are $N \le \beta N^*_s$ in-context examples for $\beta < 1$, there exists $\delta_2$ depending only on $\epsilon$ for which $\TV(p^{S_{\rm init}}_t, p^{S_{\rm targ}}_t) \le \epsilon$ for $t = N_s + 2 - (1 - \delta_2)N^*_s$. By Theorem~\ref{thm:masters_theorem} we conclude that $\TV(p^{S_{\rm init}, N_s + 2 - (1 - \delta_2)N^*_s}) \le \epsilon$. Taking $\delta = \max(\delta_1, \delta_2)$ concludes the proof.
\end{proof}