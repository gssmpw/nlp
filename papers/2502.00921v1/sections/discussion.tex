\section{Discussion}\label{sec:discussion}
In this work, we developed a simple yet general theory for critical windows for stochastic localization samplers like diffusion and autoregressive models. Already, practitioners have applied critical windows to make LLMs  safer~\citep{qi2024safetyalignmentjusttokens} and reason better~\citep{abdin2024phi4technicalreport,lin2024criticaltokensmattertokenlevel}. Our theory significantly streamlines our understanding of critical windows and provides concrete insights for practitioners. We pair our theory with extensive experiments, and demonstrate its usefulness in monitoring for jailbreaks and understanding reasoning failures.

\paragraph{Limitations.} The theory applies to the most prominent and empirically successful generative models (autoregressive language models, continuous diffusion and flow matching models). However, some less widely-used generative models do not belong to the family of localization-based samplers. Generative adversarial networks \citep{goodfellow2014generativeadversarialnetworks} and consistency models \citep{song2023consistencymodels} both use a singular evaluation of a neural network to map noise into an image. However, we argue the restriction to the localization-based samplers is extremely minor because these models are either not widely used in practice or based on localization-based samplers. 

\paragraph{Future Work.} While we instantiate our theory in many settings (Section~\ref{sec:eg_theory}), an important future direction is compute the location of critical windows in other settings and connect it to statistical physics predictions for other models of data, e.g., the random hierarchy model~\citep{sclocchi2024probinglatenthierarchicalstructure}. 

\paragraph{Impact statement.} Though this paper is largely theoretical in nature, it does describe a theory for jailbreaks which could impact model safety in the future. We hope the insights in this manuscript about jailbreaks lead to better alignment strategies and training methods. 

