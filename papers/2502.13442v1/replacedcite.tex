\section{Related Work}
\paragraph{Math Word Problem Benchmark}
Numerous math word problem datasets of different difficulty have been proposed in previous research, most notable examples including GSM8K ____ and MATH ____.

Many benchmarks have been developed to measure the robustness of mathematical reasoning. ____ perturb or rewrite math word problems to measure the robustness of mathematical reasoning. ____ developed GSM-Symbolic, a new benchmark derived from the GSM8K dataset by modifying numerical values, entity names, and question complexity. 
% They found that LLMs are sensitive to variations in numerical values or redundant conditions. 

Recently, ____ introduced MathGAP, a framework for evaluating LLMs using synthetic math word problems
with controllable proof tree characteristics. 
% and the problems can be made arbitrarily complex. They find that LLMs show a decrease in performance when proof complexity increases, or the order of sentences is perturbed.
In contrast to their approach, the tree structure in our problem-generation procedure is fundamentally different. In our work, each node represents a variable, and the questioned variable appears as a leaf. In their work, however, each node represents a logical statement, with the answer represented by the root. More importantly, we focus on unanswerable math word problems, an aspect that their study did not address.
% It is unclear how to adapt their data generation process to this scenario. Some nodes in their tree represent operations, and removing these does not necessarily result in an unanswerable problem.

\paragraph{Unanswerable Math Problems}

____ introduced SelfAware, consisting
of unanswerable questions from five diverse categories. It includes less than 300 unanswerable mathematical problems. ____ and ____ generate unanswerable questions by prompting GPT4 to eliminate a necessary condition from the original problem, an then the modified questions are further checked or refined by human annotators.
____ task human annotators to modify original questions in existing MWP datasets to make them unanswerable, creating a dataset composed of 2,600 answerable questions and 2,600 unanswerable questions. ____ prompt GPT4 to modify problems from GSM8K, generating the Unreasonable Math Problem benchmark. 

\begin{table*}[t!]
    \centering
    \small
    \renewcommand{\arraystretch}{1} % Reduce row spacing
    \begin{tabular}{c|ccccccc}
        \toprule
        \texttt{ansDepth} & \textbf{Llama-8B} & \textbf{Llama-70B} & \textbf{Qwen-7B} & \textbf{Qwen-72B} & \textbf{GPT-4o} & \textbf{o3-mini} \\
        \midrule
2 & 79\% & 22\% & 85\% & 61\% & 14\% & 42\% \\
4 & 84\% & 35\% & 89\% & 86\% & 19\% & 23\% \\
6 & 84\% & 63\% & 95\% & 89\% & 45\% & 18\% \\
8 & 84\% & 63\% & 93\% & 84\% & 61\% & 23\% \\
        \bottomrule
    \end{tabular}
    \captionsetup{skip=3pt}
    \caption{\small Percentage of hallucination of various LLMs at different \texttt{ansDepth} values for unanswerable problems}
    \label{tab:unknown}
\end{table*}

\begin{table*}[h]
    \centering
    \small
    \renewcommand{\arraystretch}{1} % Reduce row spacing
    \label{tab:known}
    \begin{tabular}{c|ccccccc}
        \toprule
        \texttt{ansDepth} & \textbf{Llama-8B} & \textbf{Llama-70B} & \textbf{Qwen-7B} & \textbf{Qwen-72B} & \textbf{GPT-4o} & \textbf{o3-mini} \\
        \midrule
2 & 68\% (14\%) & 95\% (1\%) & 87\% (2\%) & 95\% (1\%) & 99\% (1\%) & 100\% (0\%) \\
4 & 28\% (12\%) & 82\% (6\%) & 31\% (6\%) & 86\% (6\%) & 94\% (0\%) & 100\% (0\%) \\
6 & 17\% (16\%) & 83\% (3\%) & 12\% (9\%) & 80\% (7\%) & 85\% (3\%) & 100\% (0\%) \\
8 & 5\% (12\%) & 76\% (7\%) & 7\% (10\%) & 68\% (8\%) & 84\% (2\%) & 100\% (0\%) \\
        \bottomrule
    \end{tabular}
    \captionsetup{skip=3pt}
    \caption{\small Accuracy of various LLMs at different \texttt{ansDepth} levels for answerable problems. The percentage in parentheses represents the proportion of answerable questions incorrectly identified as unanswerable.}
\end{table*}