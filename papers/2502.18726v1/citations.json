[
  {
    "index": 0,
    "papers": [
      {
        "key": "shin2023good",
        "author": "Shin, Jiho and Wei, Moshi and Wang, Junjie and Shi, Lin and Wang, Song",
        "title": "The good, the bad, and the missing: Neural code generation for machine learning tasks"
      }
    ]
  },
  {
    "index": 1,
    "papers": [
      {
        "key": "lai2023ds",
        "author": "Lai, Yuhang and Li, Chengxi and Wang, Yiming and Zhang, Tianyi and Zhong, Ruiqi and Zettlemoyer, Luke and Yih, Wen-tau and Fried, Daniel and Wang, Sida and Yu, Tao",
        "title": "DS-1000: A natural and reliable benchmark for data science code generation"
      }
    ]
  },
  {
    "index": 2,
    "papers": [
      {
        "key": "chan2024mle",
        "author": "Chan, Jun Shern and Chowdhury, Neil and Jaffe, Oliver and Aung, James and Sherburn, Dane and Mays, Evan and Starace, Giulio and Liu, Kevin and Maksin, Leon and Patwardhan, Tejal and others",
        "title": "Mle-bench: Evaluating machine learning agents on machine learning engineering"
      }
    ]
  },
  {
    "index": 3,
    "papers": [
      {
        "key": "chen2021evaluating",
        "author": "Mark Chen and Jerry Tworek and Heewoo Jun and Qiming Yuan and Henrique Pond{\\'e} and Jared Kaplan and Harrison Edwards and Yura Burda and Nicholas Joseph and Greg Brockman and Alex Ray and Raul Puri and Gretchen Krueger and Michael Petrov and Heidy Khlaaf and Girish Sastry and Pamela Mishkin and Brooke Chan and Scott Gray and Nick Ryder and Mikhail Pavlov and Alethea Power and Lukasz Kaiser and Mohammad Bavarian and Clemens Winter and Philippe Tillet and Felipe Petroski Such and David W. Cummings and Matthias Plappert and Fotios Chantzis and Elizabeth Barnes and Ariel Herbert-Voss and William H. Guss and Alex Nichol and Igor Babuschkin and Suchir Balaji and Shantanu Jain and Andrew Carr and Jan Leike and Joshua Achiam and Vedant Misra and Evan Morikawa and Alec Radford and Matthew M. Knight and Miles Brundage and Mira Murati and Katie Mayer and Peter Welinder and Bob McGrew and Dario Amodei and Sam McCandlish and Ilya Sutskever and Wojciech Zaremba",
        "title": "Evaluating Large Language Models Trained on Code"
      }
    ]
  },
  {
    "index": 4,
    "papers": [
      {
        "key": "hao2022aixbench",
        "author": "Hao, Yiyang and Li, Ge and Liu, Yongqiang and Miao, Xiaowei and Zong, He and Jiang, Siyuan and Liu, Yang and Wei, He",
        "title": "Aixbench: A code generation benchmark dataset"
      }
    ]
  },
  {
    "index": 5,
    "papers": [
      {
        "key": "cassano2022multipl",
        "author": "Cassano, Federico and Gouwar, John and Nguyen, Daniel and Nguyen, Sydney and Phipps-Costin, Luna and Pinckney, Donald and Yee, Ming-Ho and Zi, Yangtian and Anderson, Carolyn Jane and Feldman, Molly Q and others",
        "title": "Multipl-e: A scalable and extensible approach to benchmarking neural code generation"
      }
    ]
  },
  {
    "index": 6,
    "papers": [
      {
        "key": "cassano2022multipl",
        "author": "Cassano, Federico and Gouwar, John and Nguyen, Daniel and Nguyen, Sydney and Phipps-Costin, Luna and Pinckney, Donald and Yee, Ming-Ho and Zi, Yangtian and Anderson, Carolyn Jane and Feldman, Molly Q and others",
        "title": "Multipl-e: A scalable and extensible approach to benchmarking neural code generation"
      }
    ]
  },
  {
    "index": 7,
    "papers": [
      {
        "key": "austin2021program",
        "author": "Jacob Austin and Augustus Odena and Maxwell Nye and Maarten Bosma and Henryk Michalewski and David Dohan and Ellen Jiang and Carrie J. Cai and Michael Terry and Quoc V. Le and Charles Sutton",
        "title": "Program Synthesis with Large Language Models"
      }
    ]
  },
  {
    "index": 8,
    "papers": [
      {
        "key": "yu2018spider",
        "author": "Yu, Tao and Zhang, Rui and Yang, Kai and Yasunaga, Michihiro and Wang, Dongxu and Li, Zifan and Ma, James and Li, Irene and Yao, Qingning and Roman, Shanelle and others",
        "title": "Spider: A large-scale human-labeled dataset for complex and cross-domain semantic parsing and text-to-sql task"
      }
    ]
  },
  {
    "index": 9,
    "papers": [
      {
        "key": "yu2024codereval",
        "author": "Yu, Hao and Shen, Bo and Ran, Dezhi and Zhang, Jiaxin and Zhang, Qi and Ma, Yuchi and Liang, Guangtai and Li, Ying and Wang, Qianxiang and Xie, Tao",
        "title": "Codereval: A benchmark of pragmatic code generation with generative pre-trained models"
      }
    ]
  },
  {
    "index": 10,
    "papers": [
      {
        "key": "hendrycks2measuring",
        "author": "Hendrycks, Dan and Basart, Steven and Kadavath, Saurav and Mazeika, Mantas and Arora, Akul and Guo, Ethan and Burns, Collin and Puranik, Samir and He, Horace and Song, Dawn and others",
        "title": "Measuring Coding Challenge Competence With APPS"
      }
    ]
  },
  {
    "index": 11,
    "papers": [
      {
        "key": "zhang2023repocoder",
        "author": "Zhang, Fengji and Chen, Bei and Zhang, Yue and Keung, Jacky and Liu, Jin and Zan, Daoguang and Mao, Yi and Lou, Jian-Guang and Chen, Weizhu",
        "title": "Repocoder: Repository-level code completion through iterative retrieval and generation"
      }
    ]
  },
  {
    "index": 12,
    "papers": [
      {
        "key": "yu2024codereval",
        "author": "Yu, Hao and Shen, Bo and Ran, Dezhi and Zhang, Jiaxin and Zhang, Qi and Ma, Yuchi and Liang, Guangtai and Li, Ying and Wang, Qianxiang and Xie, Tao",
        "title": "Codereval: A benchmark of pragmatic code generation with generative pre-trained models"
      }
    ]
  },
  {
    "index": 13,
    "papers": [
      {
        "key": "hendrycks2measuring",
        "author": "Hendrycks, Dan and Basart, Steven and Kadavath, Saurav and Mazeika, Mantas and Arora, Akul and Guo, Ethan and Burns, Collin and Puranik, Samir and He, Horace and Song, Dawn and others",
        "title": "Measuring Coding Challenge Competence With APPS"
      }
    ]
  }
]