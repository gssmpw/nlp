\section{Method}

We conduct a systematic literature review to address our research question. Following prior method~\cite{nightingale2009guide}, we aim to identify relevant research papers on RPAs and provide a comprehensive summary of the literature. We selected four widely used academic databases: Google Scholar, ACM Digital Library, IEEE Xplore, and ACL Anthology. These databases encompass a broad spectrum of research across AI, human-computer interaction, and computational linguistics. Given the rapid advancements in LLM research, we included both peer-reviewed and preprint studies (e.g., from arXiv) to capture the latest developments. Below, we detail our paper selection and annotation process.

\input{Figures/agent_attribute_definitions_and_examples}

\subsection{Literature Search and Screening Method}

\begin{figure}
    \includegraphics[width=\linewidth]{Figures/simple-PRISMA-1.png}
    % \vspace{-1em}
    \caption{Screening process of literature review. We initially retrieved $1,676$ papers published between 2021 and 2024, and narrowed down to $122$ final selections.}
    \vspace{-1em}
    \label{fig:prisma}
\end{figure}

Our literature review focuses on LLM agents that role-play human behaviors, such as decision-making, reasoning, and deliberate actions. We specifically focus on studies where LLM agents demonstrate the ability to simulate human-like cognitive processes in their objectives, methodologies, or evaluation techniques. To ensure methodological rigor, we define explicit inclusion and exclusion criteria (Tab.~\ref{tab:criteria} in Appendix~\ref{tab: inclusion and exclusion criteria}). 

The inclusion criteria require that an LLM agent in the study exhibits human-like behavior, engages in cognitive activities such as decision-making or reasoning, and operates in an open-ended task environment. We excluded studies where LLM agents primarily serve as chatbots, task-specific assistants, evaluators, or agents operating within predefined and finite action spaces. Additionally, studies focusing solely on perception-based tasks (e.g., computer vision or sensor-based autonomous driving) without cognitive simulation were also excluded.

Using this scope, we searched four databases using the query string provided in Appendix~\ref{query string}, retrieving $1,676$ papers published between January 2021 to December 2024. After removing duplicates, $1,573$ unique papers remained. Two authors independently screened the paper titles and abstracts based on the inclusion criteria. If at least one author deemed a paper relevant, it proceeded to full-text screening, where two authors reviewed the paper in detail and resolved any disagreements through discussion (Fig.~\ref{fig:prisma}). The final set of selected studies comprised $122$ publications.


\subsection{Paper Annotation Method}
Our team followed established open coding procedures \cite{brod2009qualitative} to conduct an inductive coding process to identify key themes. Three co-authors with extensive experience in LLM agents (``annotators,'' hereinafter) collaboratively annotated the papers on three dimensions: \textbf{agent attributes}, \textbf{task attributes}, and \textbf{evaluation metrics}. 

To ensure consistency, two annotators independently annotated the same 20\% of articles and then held a meeting to discuss and refine an initial set of categories for the three dimensions. After reaching a consensus, each annotator annotated half of the remaining papers and cross-validated the other half annotated by the other annotator. Once the annotations were completed, a third annotator reviewed the coded data and identified potential discrepancies. 
Any discrepancies were discussed among the annotators to ensure consistency until disagreements were resolved, ensuring reliability and validity through an iterative refinement process.