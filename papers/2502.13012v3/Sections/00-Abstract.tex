\begin{abstract}
Role-Playing Agent (RPA) is an increasingly popular type of LLM Agent that simulates human-like behaviors in a variety of tasks. 
However, evaluating RPAs is challenging due to diverse task requirements and agent designs.
This paper proposes an evidence-based, actionable, and generalizable evaluation design guideline for LLM-based RPA by systematically reviewing $1,676$ papers published between Jan. 2021 and Dec. 2024.
Our analysis identifies six agent attributes, seven task attributes, and seven evaluation metrics from existing literature.
Based on these findings, we present an RPA evaluation design guideline to help researchers develop more systematic and consistent evaluation methods.

\end{abstract}


% to synthesize what agent attributes and task attributes prior literature have considered influence the selection of evaluation metrics, as well as the relationships between these factors.
% For each agent attribute and task category, we summarize its distinct associations with RPLA's evaluation metrics, providing practical guidance on comprehensive based on their RPLA's design. Additionally, we explore the  between agent attributes and downstream tasks to support researchers in refining RPLA design choices.