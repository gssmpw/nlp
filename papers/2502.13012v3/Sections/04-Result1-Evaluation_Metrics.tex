% \section{RPA Evaluation Design Guideline}
\section{Survey Findings}

Building on the annotated data, we systematically categorized agent attributes, task attributes, and evaluation metrics. 
We then present a structured RPA evaluation design guideline, outlining how to select appropriate evaluation metrics based on agent and task attributes.


\input{Figures/task_definition}

\input{Figures/metrics_definition}

\subsection{Agent Attributes}
We identified six categories of agent attributes, as shown in Tab.~\ref{attr_def}. 
\textit{Activity history} refers to an agent's longitudinal behaviors, such as browsing history~\cite{10.1145/3613904.3642363} or social media activity~\cite{Navarro2024DesigningRE}. 
\textit{Belief and value} encompass the principles, attitudes, and ideological stances that shape an agent's perspectives, including political leanings~\cite{Mou2024UnveilingTT} or religious affiliations~\cite{lv2024coggpt}. 
\textit{Demographic information} includes personal details such as name, age, education, location, career status, and household income. 
\textit{Psychological traits} include an agent's personality~\cite{NEURIPS2023_21f7b745}, emotions, and cognitive tendencies~\cite{castricato2024personareproducibletestbedpluralistic}. 
\textit{Skill and expertise} describe an agent's knowledge and proficiency in specific domains, such as technology proficiency or specialized professional skills. 
Lastly, \textit{social relationships} define the social interactions, roles, and communication styles between agents, including aspects like parenting styles~\cite{ye2024simulating} or relationships between players~\cite{ge2024scaling}.



\subsection{Task Attributes}
We identified seven key types of RPA downstream task attributes (Tab.~\ref{task_def}). These tasks fall into two broad categories: those that use simulation as a research goal and those that use simulation as a tool to support specific research domains.


Among them, simulated individuals and simulated society primarily use simulation as the research goal. 
\textit{Simulated individuals} involve modeling specific individuals or groups, such as end-users~\cite{chen2024seeing}, to study their behaviors and interactions in a controlled setting. 
\textit{Simulated Society} focuses on social interactions, including cooperation~\cite{bouzekri2024chatgpt}, competition~\cite{wu2024shall}, and communication~\cite{mishra-etal-2023-e}, aiming to explore emergent social dynamics.\looseness=-1

In contrast, the other task attributes employ simulation as a means to serve specific research domains. 
\textit{Opinion dynamics} entails simulating political views~\cite{neuberger2024sauce}, legal perspectives~\cite{chen2024agentcourt}, and social media discourse~\cite{liu2024tiny} to analyze the formation and evolution of opinions. \textit{Decision making} addresses the decision-making processes of stakeholders in investment~\cite{sreedhar2024simulating} and public policy~\cite{ji2024srap}, providing insights into strategic behaviors. \textit{Psychological experiments} explore human traits such as personality~\cite{bose2024assessing}, ethics~\cite{lei2024fairmindsim}, emotions~\cite{zhao2024esc}, and mental health~\cite{de2025introducing}, using simulated scenarios to study cognitive and behavioral responses. 
\textit{Educational training} supports personalized learning by simulating teachers and learners, enhancing pedagogical approaches and adaptive education systems~\cite{Liu2024PersonalityawareSS}. Finally, \textit{writing} involves modeling readers or characters to facilitate character development~\cite{10.1145/3613904.3642406} and audience engagement~\cite{choi2024proxona}, contributing to storytelling and content generation research.

\begin{figure*}[t]
    \centering
    \includegraphics[width=0.9\linewidth]{Figures/agent-attr-metrics.png}
    % \vspace{-0.5em}
    \caption{Proportional distribution of agent-oriented metrics across different agent attributes.}
    \label{fig:pie-chart-agent-oriented}
    % \vspace{-0.5em}
\end{figure*}


\begin{figure*}
    \centering
    \includegraphics[width=\linewidth]{Figures/task-metrics.png}
    % \vspace{-1em}
    \caption{Proportional distribution of task-oriented metrics across different task attributes.}
    \label{fig:pie-chart-task-oriented}
    % \vspace{-1em}
\end{figure*}



\subsection{Agent- and Task-Oriented Metrics}
We derived seven categories of evaluation metrics (Tab.~\ref{metrics_def}) that are shared by agent- and task-oriented metrics despite differences in the specific metrics. 
% Both agent-oriented and task-oriented metrics share the same broad categories but differ in their specific evaluation metrics.

\input{Figures/top3-agent}
\input{Figures/top3-task}

\textbf{Agent-oriented metrics} focus on intrinsic, task-agnostic properties that define an RPA's essential ability, such as underlying reasoning, consistency, and adaptability. 
These include \textit{performance} metrics like memorization, \textit{psychological} metrics such as emotional responses measured via entropy of valence and arousal, and \textit{social and decision-making} metrics like social value orientation. 
Additionally, agent-oriented evaluations emphasize \textit{internal consistency} metrics (e.g., consistency of information across interactions), \textit{external alignment} metrics (e.g., hallucination detection), and \textit{content and textual} metrics such as clarity. 
These evaluations ensure logical coherence, factual accuracy, and alignment with expected behavioral and cognitive frameworks, independent of any specific task. 

\textbf{Task-oriented metrics} evaluate an RPA's effectiveness in performing specific downstream tasks, focusing on task-related aspects such as accuracy, consistency, social impact, and ethical considerations. 
\textit{Performance} measures how well RPAs execute designated tasks, such as prediction accuracy. 
\textit{Psychological} metrics assess human psychological responses to RPAs, including self-awareness and emotional states; for example, the Big Five Inventory. 
\textit{External alignment} evaluates how closely RPAs align with external ground truth or human behavior; for instance, alignment between model and human. 
\textit{Internal consistency} ensures coherence between an RPA’s predefined traits, contextual expectations, and behavior; for example, personality-behavior alignment. 
\textit{Social and decision-making} metrics analyze RPAs’ influence on negotiation, societal welfare, and social dynamics; for instance, the social conflict count. 
\textit{Content and textual quality} focuses on the coherence, linguistic style, and engagement of RPAs’ generated text, such as content similarity. 
Lastly, \textit{bias, fairness, and ethics} metrics examine biases, extreme content, or stereotypes; for instance, the factual error rate.
Together, these seven metrics provide a comprehensive framework for evaluating RPAs' task performance and broader impact.




\subsection{RPA Evaluation Design Guideline}
Building on our previous classification of agent attributes, task attributes, and evaluation metrics, we observed that both agent design and evaluation can be broadly divided into two categories: \textbf{agent-oriented} and \textbf{task-oriented}. This distinction led us to investigate patterns between agent design and evaluation, aiming to develop systematic guidelines for selecting evaluation metrics in future research.


\paragraph{Step 1. Selecting Agent-Oriented Metrics Based on Agent Attributes}
We analyzed the distribution of agent attributes and agent-oriented metrics, as illustrated in Fig.~\ref{fig:pie-chart-agent-oriented}. Our analysis reveals that, for each agent attribute, the top three categories of agent-oriented metrics account for the majority of all metric types. Based on this observation, our first guideline recommends selecting agent-oriented metrics according to agent attributes. Specifically, we suggest referring to Tab.~\ref{tab: top3-agent} to identify the top three corresponding metrics. For instance, for Activity History, the recommended metrics are external alignment, internal consistency, and content and textual metrics. Likewise, for Beliefs and Values, the most relevant choices are psychological metrics and bias, fairness, and ethics metrics.
In particular, there are no established agent-oriented evaluation metrics for social relationships. Based on Social Exchange Theory~\cite{cropanzano2005social}, which explains relationship formation through reciprocal interactions and resource exchanges, we propose assessing social relationships with psychological metrics, external alignment metrics, and social and decision-making metrics.

\paragraph{Step 2: Selecting Task-Oriented Metrics Based on Task Attributes}
Additionally, we analyzed the distribution of task attributes and task-oriented metrics, as shown in Fig.~\ref{fig:pie-chart-task-oriented}. Consistent with our previous findings, we observed that for each category of task attributes, the top three task-oriented metrics account for the vast majority of all metrics. Based on this, our second guideline recommends selecting task-oriented metrics according to task attributes. Specifically, we suggest referring to Tab.~\ref{tab: top3-task}  to identify the top three corresponding metrics. For instance, for the \textit{Simulated Society} task, the recommended metrics are social and decision-making, performance, and psychological metrics. Similarly, for the \textit{Opinion Dynamics} task, the most relevant choices are performance, external alignment, bias, fairness, and ethics metrics.

However, these two steps should not be treated as one-time decisions. As the agent design process evolves, evaluation results may prompt adjustments to the attributes of the agent and the task, thereby influencing the selection of evaluation metrics. Therefore, this two-step evaluation guideline should be used iteratively to ensure that the evaluation remains adaptive to changing agent capabilities and task requirements. This iterative approach enhances the reliability, relevance, and robustness of RPA evaluation experiments.



% To establish a comprehensive evaluation framework, our RPA evaluation design guideline recommends selecting the three most frequently used metrics for each agent attribute. These metrics ensure logical consistency, external alignment, and meaningful content generation.

% For activity history, the key metrics include external alignment, internal consistency, and content/textual metrics, ensuring an agent’s longitudinal actions align with its characteristics, maintain coherence, and produce meaningful outputs. Beliefs and values are primarily assessed through psychological metrics and bias, fairness, and ethics metrics to evaluate cognitive alignment and ethical considerations. Demographic information relies on psychological, internal consistency, and external alignment metrics to ensure profile coherence and alignment with external benchmarks. Psychological traits are examined through psychological, internal consistency, and content/textual metrics, capturing cognitive attributes while maintaining textual coherence. Skills and expertise are evaluated using external alignment, internal consistency, and content/textual metrics, ensuring expertise consistency and high-quality content generation.

% Notably, no established agent-oriented evaluation metrics exist for social relationships. Based on Social Exchange Theory~\cite{cropanzano2005social}, which explains relationship formation through reciprocal interactions and resource exchanges, we propose assessing social relationships with psychological metrics (e.g., trust and reciprocity), external alignment metrics (e.g., adherence to social norms), and social/decision-making metrics (e.g., cooperative behavior and negotiation success).

% Our RPA evaluation design guideline recommends selecting the top three most frequently used metrics for each task attribute, ensuring a balanced assessment across different task categories.

% For simulated society, key metrics include social and decision-making, performance, and psychological metrics, which collectively evaluate societal interactions, decision-making processes, and behavioral patterns. Simulated individuals are primarily assessed using psychological, performance, and internal consistency metrics, focusing on personal behaviors, cognitive processes, and coherence. Opinion dynamics rely on performance, external alignment, and bias, fairness, and ethics metrics to ensure the robustness, validity, and ethical considerations of opinion formation and propagation. Decision-making tasks are evaluated using social and decision-making, performance, and psychological metrics, ensuring decisions are effective, consistent, and aligned with agent attitudes. Psychological experiments require psychological, content and textual, and performance metrics, offering a comprehensive assessment of cognitive processes, textual coherence, and experimental effectiveness. Educational training is best measured through psychological, performance, and content and textual metrics, capturing learning effectiveness, comprehension, and knowledge transfer. Finally, writing tasks emphasize content and textual, psychological, and performance metrics to ensure high-quality, coherent, and meaningful outputs.












% \subsubsection{Performance metrics}
% Performance metrics evaluate the capability of RPAs during task execution (e.g., information gathering, reasoning, interaction, and coordination) and the task outcomes (e.g., success rate, accuracy, and reliability). Among the eight categories of evaluation metrics, performance metrics are the most widely used, reflecting the central role of task execution and outcomes in assessing RPAs. They are particularly prevalent in two types of tasks where simulation is the ultimate goal (simulated society and simulated individuals) and three types where simulation serves as a method for specific research fields (opinion dynamics, social media, and decision-making). 

% Notably, different research goals result in different performance metrics. When simulation is the primary goal, performance metrics emphasize general capabilities such as knowledge accuracy, reasoning, conversation quality, task execution, and prediction performance. For instance, WikiRoleEval~\cite{} measures knowledge accuracy, CharacterEval~\cite{} assesses dialogue quality. Conversely, when simulation is applied as a research tool, performance metrics focus on task-specific and domain-specific effectiveness, particularly in decision-making. For example, metrics like decision volatility and alignment with real-world outcomes are used to evaluate decision-making performance.

% Approximately 70\% of studies using performance metrics rely on automated evaluation approaches. This preference is likely due to the existence of objective, formulaic definitions and established benchmarks for assessing RPAs' task execution and outcomes. Additionally, frequent and precise performance assessments are often necessary for improving RPAs, making human evaluation impractical to be used on a large scale or at high frequency due to its time cost. LLM-based evaluation methods are also not widely adopted for performance due to accuracy limitations and potential bias.


% \subsubsection{Psychological and Sentiment Metrics}
% Psychological and sentiment metrics have two folds: they measure human psychological responses toward RPAs, and the agent's internal self-cognition and emotional state. These metrics are used across various downstream tasks but are most frequently applied in psychological experiments and educational training, with notable use also in simulated individual and simulated society tasks. When psychological and sentiment metrics are employed to measure human responses toward RPAs, they typically encompass three categories of psychological reactions: positive responses, such as trust, enjoyment, pleasure, liking, engagement, and intimacy; neutral responses, including emotions, attitudes, beliefs, and cognitive load; and negative responses, such as risk, loss, and selfishness. On the other hand, when these metrics assess the agent's internal self-cognition and emotional state, the most common indicators focus on the agent's personality.

% Given the subjective nature of psychological and sentiment metrics, these indicators are typically evaluated through a combination of automatic and human evaluation, with minimal reliance on LLMs for assessment. While automation offers scalability and consistency, human evaluators are invaluable in capturing subjective nuances, such as subtle emotional cues and individual biases, which automated systems may overlook.
% % add examples
% The balance between automated and manual evaluation ensures that both efficiency and accuracy are maintained in assessing the complexity of human emotions and agent behaviors.


% \subsubsection{External Alignment Metrics}
% External alignment metrics measure the alignment of RPAs with external ground truth or how closely RPAs' responses match human behavior or judgments.
% These metrics are primarily used in four downstream tasks: simulated society, simulated individuals, opinion dynamics, and decision-making. Half of the external alignment metrics rely on automatic evaluation, while the other half involve human evaluation.

% External alignment can be categorized into two levels: cognitive consistency and behavioral consistency. Cognitive consistency evaluates whether an RPA understands its environment, tasks, and context, enabling it to make judgments aligned with human reasoning. For instance, Strategy accuracy measures whether an RPA makes human-like strategic choices in a Social Dilemma Game, while human-model alignment (Kappa correlation coefficient, MAE) assesses how closely the model's decisions match human expectations. Behavioral consistency examines whether an RPA's external behavior aligns with human behavioral patterns, enhancing realism and credibility in interactions. This includes human-like dynamic responses, emotional expressions, and social behaviors, evaluated through tests such as the Turing Test or metrics like Believability of behavior.

% The scarcity of external alignment metrics in research is likely due to the high resource demands for evaluation. Collecting large-scale ground truth data or employing human evaluators is both time-consuming and costly, making these metrics less frequently used in RPA assessments.



% \subsubsection{Internal Consistency Metrics}
% Internal consistency metrics evaluate the coherence among an RPA's predefined characteristics (e.g., personality), contextual expectations, and behavior.
% These metrics are primarily applied through automatic evaluation methods, mainly in simulated individuals tasks, with limited use in psychological experiments, writing, and social media tasks. Internal consistency metrics assess three key aspects: within-attribute consistency, between-attribute consistency, and temporal consistency. Within-attribute consistency ensures the internal coherence of data within a single attribute, such as semantic consistency, perception consistency, motivation consistency, and behavior consistency. Since attributes can influence one another, between-attribute consistency examines the alignment between different attributes, such as cultural background-behavior consistency and personality-behavior consistency. Temporal consistency evaluates whether an agent's behavior and interactions with users remain stable over time, as reflected in measures like the similarity between initial and post preferences and future self-continuity.


% \subsubsection{Social and Economic Metrics}
% Social and economic metrics measure the social interactions and economic decisions of RPAs, evaluating their impact on negotiation, societal welfare, macroeconomics, market behavior, and social interaction. The application of these metrics is closely tied to specific downstream tasks, such as simulated societies, economic experiments, and decision-making. While most evaluations rely on automatic methods, a smaller proportion involve human or LLM-based assessments.

% \subsubsection{Content and Textual Metrics}
% Content and textual metrics assess the quality, coherence, and diversity of RPAs' generated text, including its semantic understanding, linguistic style, and conversation engagement. These metrics are applied in simulated societies, simulated individuals, psychological experiments, educational training, and writing. They primarily rely on automatic simulation, with most of these automated metrics coming from the NLP field (e.g., BERTScore, ROUGE-L, perplexity). Their use is also closely related to downstream tasks, and they are typically chosen when the task focuses on the quality of text-level data.

% \subsubsection{Bias, Fairness, and Ethic Metrics}
% Bias, fairness, and ethics metrics evaluate the presence and impact of biases in agent behavior, assess the agent's ability to avoid extreme or unbalanced responses, and measure its promotion of fairness, equality, and diversity in interactions. These metrics are primarily used in the downstream tasks of simulated society, simulated individual, and opinion dynamics, with most relying on automated evaluation, likely to avoid subjective biases in human or LLM-based assessments. Human evaluation may be influenced by personal experiences, cultural backgrounds, or ideological leanings, while LLMs assessing their own biases could create feedback loops, making it difficult to identify blind spots. Additionally, automated evaluation ensures repeatability and scalability, making it suitable for large-scale social simulations and individual behavior modeling, such as measuring opinion polarization or bias propagation patterns in groups. However, automated methods may have limitations in capturing subtle ethical issues, such as implicit discrimination or moral dilemmas, and certain biases (e.g., cultural or ideological biases) may still require qualitative analysis for a more comprehensive understanding.




% another section for benchmarks?
