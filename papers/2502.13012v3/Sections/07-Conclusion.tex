\section{Conclusion}
RPA evaluation lacks consistency due to varying tasks, domains, and agent attributes. Our systematic review of $1,676$ papers reveals that task-specific requirements shape agent attributes, while both task characteristics and agent design influence evaluation metrics. By identifying these interdependencies, we propose guidelines to enhance RPA assessment reliability, contributing to a more structured and systematic evaluation framework.