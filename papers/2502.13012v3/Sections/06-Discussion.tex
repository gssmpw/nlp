% \newpage 
% \newpage


\section{Discussion}
\label{sec:discussion}


\subsection{RPA: an Algorithm v.s. a System}

Unlike traditional algorithmic innovations in NLP, the design of RPAs can not only support technical innovations to improve LLMs' humanoid capabilities but also enable RPA-based simulation systems for practical benefits.
For instance, from the perspective of psychology, RPAs support the exploration of human cognitive and behavioral activities in controlled yet highly scalable experiments, even in hypothetical scenarios.
In social science, RPAs can deployed as proxies or pilot experiments to analyze and audit social systems, power dynamics, and human societal behaviors at scale.
For the machine learning community, RPAs shed light on dynamic and human-centered model evaluations that are aligned with real-world scenarios by incorporating human and societal factors into consideration.
Last but not least, HCI researchers are particularly intrigued by the implications of RPA systems that can provide personalized assistance with human-centered applications in various sectors, such as medicine, healthcare, and education. 

Nevertheless, RPAs' capability and flexibility are a double-edged sword; they not only have the potential to bring benefits to stakeholders but also expose potential risks and even harm if not responsibly designed.
To what extent do RPAs' responses align with genuine human cognitive activities, whether the cultural, linguistic, and contextual biases learned from the training data of LLMs impact predicted behaviors, and how to ensure RPAs' robustness and consistency under different scenarios, are critical but under-explored challenges for both technical developers and system designers.


As a result, the design of RPAs should incorporate system design considerations while advancing technical explorations.
For instance, RPA design should focus on target users from the very beginning of system design, emphasize the diversity of user backgrounds and perspectives, and iteratively refine the system, as suggested by \citet{gould1985designing} and \citet{shneiderman2010designing} in established design guidelines for system usability.
Nevertheless, differences in cultural norms, linguistic subtleties, and domain-specific knowledge can introduce variability in how RPAs are designed and perceived.
Designers and developers must focus on a balance between generalization and specificity to ensure RPAs are both adaptable and effective across a wide range of scenarios. 
% Establishing best practices for defining agent characteristics and integrating contextual information is a critical area for future research, as it will help standardize the development of RPAs while ensuring their relevance in diverse applications.


\subsection{The Design of RPA Persona}

One of RPAs' key strengths is their ability to adapt to diverse personas, tasks, and environments. But how can RPA personas be designed to ensure that LLMs faithfully and believably reflect the agents' cognitive behaviors within a given task?
Persona descriptions must strike a careful balance between intrinsic agent characteristics and contextual factors, ensuring thoughtful consideration of both the agents' intrinsic characteristics and the contextual information of the specific environments for which the agents are designed. 


% persona related
% \subsection{Designing RPAs: Characteristics and Contextual Descriptions}

% How to design RPAs' descriptions that can guide LLMs faithfully and believably reflect the agents' cognitive and physical behaviors? 
% The descriptions of RPAs have to be sufficiently detailed in both intrinsic and extrinsic factors but not consist of irrelevant content. 
% In particular, the design of RPAs requires careful consideration of both the agents' \textbf{intrinsic characteristics} and the \textbf{contextual information} of the specific environments where the agents are located. 


The \textit{intrinsic characteristics} of RPAs, such as their personal characteristics, education experience, domain expertise, emotional expressiveness, and decision-making processes, must be \textit{aligned with the purpose} of the applications of RPAs.
For example, an RPA designed for psychological experiments should prioritize cognitive characteristics like personality and empathy ability, whereas an RPA developed for economic simulations might emphasize negotiation tactics, competitive reasoning, and adaptability to changing conditions.



% A key strength of RPAs lies in their ability to adapt to diverse personas, tasks, and scenarios, but achieving this flexibility demands thoughtful design strategies. 
% The characteristics of RPAs, such as their personal attributes, knowledge boundaries, reasoning style, emotional expressiveness, and decision-making processes, must align with the goals of the application. 
% For example, an RPA designed for psychological experiments might prioritize empathy, consistency, and transparency, whereas an RPA developed for economic simulations might emphasize negotiation tactics, competitive reasoning, and adaptability to changing conditions.
On the other hand, \textit{contextual information}, such as task- and scenario-specific details, factors, and specifications, is equally critical in shaping the behaviors of RPAs. 
In healthcare applications, for instance, RPAs may simulate caregivers' emotional responses to patients' changing health status but still operate under clinical protocols, such as the ICU visitor rules.
The granularity and fidelity of contextual information heavily influence the believability and effectiveness of the agents' behaviors.



% The role of contextual descriptions is equally critical in shaping the behavior of RPAs. 
% These descriptions provide the scaffolding for the agent’s responses that incorporate task-specific details, user expectations, and environmental factors into their behavior. 
% In healthcare applications, for instance, RPAs may need to simulate a caregiver’s sensitivity to patient emotions while operating within the constraints of clinical protocols. 
% Conversely, in educational settings, RPAs might focus on fostering engagement and curiosity, tailoring their explanations to the learner’s background. 
% The granularity and fidelity of these contextual descriptions heavily influence the believability and effectiveness of the agent’s behavior.



% Evaluation Challenges
\subsection{The Challenges of RPA Evaluation}


% Evaluating RPAs systematically within and across tasks and user scenarios presents a complex challenge. 
The versatility of RPAs, which allows them to function in diverse roles and contexts, makes it infeasible to have a ``one-solution-fits-all'' evaluation metric for systematically evaluate RPAs both within and across tasks and user scenarios.
One major difficulty lies in designing and determining task-oriented and agent-oriented evaluation metrics. 
Despite our work recommending an RPA evaluation design guideline based on a comprehensive review of the literature, existing evaluation metrics may not be sufficient to measure the performance of RPAs for different domain-specific applications.


% \textit{Task-oriented} metrics, such as the accuracy of decision-making, capture the agent’s effectiveness in specific applications. 
% Conversely, \textit{agent-oriented} metrics, which assess qualities like consistency, robustness, and diversity, are essential to understand the role-play capabilities of the agents.

The diversity of user scenarios further exacerbates the evaluation challenge. 
Different tasks may prioritize different aspects of RPAs, making it difficult to develop a one-size-fits-all evaluation framework.
For instance, RPAs designed for psychological research focus on believable emotional responses, whereas RPAs for policymaking simulations underscore robustness to policy changes.


Moreover, cross-task evaluations pose significant challenges due to inconsistencies in how metrics are designed and applied across studies. 
The lack of standardized evaluation criteria complicates systematic benchmarking in RPA development and impedes interdisciplinary collaboration.

Addressing these challenges will require the development of systematic, multi-faceted evaluation frameworks that can accommodate the diverse applications and capabilities of RPAs while providing consistency and comparability across studies.


% \subsection{Practical Implications of RPAs in Various Research Domains}

% Role-Playing Language Agents (RPAs) represent a transformative leap in leveraging large language models to simulate human behavior and cognitive activities from both single-agent and multi-agents' perspectives, and being further extended to interaction patterns and societal dynamics.
% RPAs' ability to role-play diverse personas and perform complex, non-predefined tasks opens a broad avenue of opportunities and challenges across multiple research domains. 
% As this technical advance evolves, critical considerations must be addressed to maximize its potential while mitigating associated potential risks.

% \subsubsection{Psychological and Behavioral Research}
% From the perspective of psychology, for example, RPAs offer unprecedented opportunities to \textbf{explore human cognitive and behavioral activities in controlled yet highly scalable experiments}. 
% By simulating cognitive processes such as reasoning, decision-making, and empathy, RPAs offer researchers a novel approach to replicate and extend psychological studies without suffering from a number of critical but inherent limitations of traditional human subject studies.
% In particular, RPA simulations are ethical and risk-free because they do not rely on human participants, which is a game-changer for experiments with vulnerable populations. 
% Further, RPA simulations can easily mitigate sampling biases and recruitment difficulties by augmenting agent personas and executing the same or different settings on the same group of personas repeatedly and ethically.
% RPAs can also simulate responses in hypothetical scenarios, which was hardly possible for human subject studies and offer new avenues for topics like personality, social interactions, and mental health. 
% However, this potential also raises concerns about experiment validity and ethical boundaries. 
% While RPAs can mimic human behavior, the extent to which their responses align with genuine human cognitive activities remains underexplored. 
% Over-reliance on such tools in psychological research risks conflating simulation with reality, which could potentially lead to flawed conclusions about human behavior.

% \subsubsection{Social Science Research and Policy Analysis}
% In social science, RPAs provide a powerful means to \textbf{analyze and audit social systems, power dynamics, and human societal behaviors at scale}. 
% For instance, applications in studying opinion dynamics or testing ethical decision-making scenarios have already demonstrated RPAs' utility. 
% Additionally, RPAs can be deployed as proxies or pilot experiments to explore sensitive or ethically challenging scenarios, such as understanding the impact of bias or discrimination in institutional settings and testing different policies in virtual environments without harm to any human. 
% However, RPAs' integration into social science research is not without challenges. 
% The interpretability of agent-generated behavior and the potential biases, which are learned from the models' training data and embedded within the underlying models, could amplify existing social inequities rather than mitigate them. 
% Moreover, the deployment of RPAs in the real world must carefully consider cultural, linguistic, and contextual factors to ensure their applicability and fairness across diverse populations.

% ref bibliometrics: AI paper vs HCI paper
% \subsubsection{Machine Learning Development and Evaluation}
% For the machine learning community, RPAs serve as a testbed to advance models and their applications in real-world, human-centered scenarios. 
% Inherent divergences exist between the standardized model development process with static training and testing datasets versus the complicated real-world users' workflows with constantly changing environments.
% In particular, human and societal factors are critical to the technologies' real-world usability when models are integrated into a user-facing system, but none of these factors were considered in the earlier model development stage.
% To bridge the gaps, RPAs shed light on \textbf{dynamic and human-centered model evaluations} that are aligned with real-world user scenarios to support the development and evaluation of robust, generalizable, and adaptive technologies.
% Despite the promising landscape, few have been explored, and challenges are still multifold. 
% The inherent complexity of human cognition poses significant obstacles in creating agents that are realistic and contextually aware.
% How to responsibly develop robust, consistent, and systematic evaluation benchmarks while benefiting from the flexibility of RPAs will be challenging but of significant practical benefits to the broader research community. 

% % human over-expectation of persona

% \subsubsection{Human-Computer Interaction and Design Practices}
% Human-computer interaction (HCI) researchers are particularly intrigued by the implications of RPAs for \textbf{designing systems that seamlessly integrate into human workflows and interactions}. 
% Their ability to simulate empathy, adapt to user preferences, and engage in natural conversations offers immense potential to provide personalized assistance with human-centered applications in various sectors, such as medicine, healthcare, and education. 
% For instance, RPAs can act as virtual tutors, providing personalized feedback and support to learners, or as virtual companions for mental health support, offering empathic interactions that mimic human therapists.
% In healthcare, RPAs can help train clinicians by simulating diverse patient scenarios, testing different intervention strategies harmlessly and ethically, and helping clinicians develop diagnostic and communication skills for hard conversations, such as in palliative care. 
% Furthermore, RPAs' role in designing inclusive and accessible systems is particularly promising, as they can simulate interactions for users with disabilities or language barriers. 

% Nevertheless, RPAs' high degree of flexibility is a double-edged sword; not only has the potential to bring a lot of benefits to stakeholders' workflow but also exposes potential risks and even harm if not responsibly designed.
% Established responsible design guidelines will be indispensable in the interaction design of RPAs, such as ensuring transparency and trustworthiness and preventing misuse, biases and harm. 
% New human-AI collaboration frameworks may emerge to guide the user interface design that enables end-users to understand, control, and collaborate effectively with these novel agents. 
% In addition, the ethical implications of anthropomorphism in RPAs must be carefully examined, as overly human-like behaviors may blur the line between machine and human interaction and lead to unintended emotional or social consequences.

% disciplinary divide


% \subsection{Toward a Unified Research Agenda}


% Looking forward, the interdisciplinary nature of RPAs demands a collaborative effort among different disciplines, particularly between domain experts and technical experts, to explore the aforementioned opportunities while addressing the potential challenges. 
% First, the development of a systematic guideline for RPAs' evaluation frameworks is critical.
% The unified guideline outlined in this study for the evaluation and deployment of RPAs is essential to ensure their effectiveness, safety, and ethical alignment that accounts for task-specific performance and agent-specific attributes. 
% % Moreover, it is crucial to incorporate perspectives from diverse stakeholders, including researchers, policymakers, and end-users, to establish guidelines that are inclusive and contextually sensitive.



% Ethical and inclusive practices must also be prioritized to mitigate the biases embedded in LLMs.
% Ensuring that RPAs are designed and deployed in ways that promote fairness and inclusivity is essential, particularly as they are increasingly applied in sensitive contexts such as healthcare, education, and social research. 
% The anthropomorphic nature of RPAs introduces additional ethical complexities, as overly human-like behaviors performed by RPAs may blur the line between machine and human interaction and lead to unintended emotional or social consequences.
% Careful consideration of these aspects will help ensure that RPAs are used responsibly and ethically.

% Interdisciplinary collaboration plays a critical role in advancing the potential of RPAs. Psychology, social science, machine learning, HCI, and more disciplines bring unique perspectives and methodologies to the table. 
% By promoting conversation and collaboration between researchers from these fields, it is possible to leverage their respective strengths to address both technical and societal challenges. 
% Such collaboration would facilitate the integration of human-centered design principles with advanced computational techniques for the design of RPAs that are technically robust and aligned with user needs.

% Finally, exploring real-world applications of RPAs is an essential step in understanding their broader implications. 
% Investigating how RPAs can enhance human-AI collaboration in practical scenarios, such as education, mental health support, or policy simulation, will provide valuable insights into their usability, safety, and societal impact. 
% These efforts must be guided by an overarching commitment to ensuring that RPAs contribute meaningfully to human welfare and knowledge creation.

% % In summary, a unified research agenda for RPAs should focus on establishing systematic evaluation frameworks, promoting ethical and inclusive practices, fostering interdisciplinary collaboration, and exploring real-world applications. By addressing these priorities, the research community can unlock the transformative potential of RPAs to advance knowledge, drive innovation, and create meaningful societal impact.

% % The evaluation still needs the effort of human/experts

% % Potential risks of anthropomorphism 
% % intentionally misuse the RPA to do harmful things

% \subsection{From Human-in-the-Loop to Human-on-the-Loop and Beyond}

% The advent of RPAs marks a significant shift in the traditional paradigms of human-AI collaboration. 
% Unlike conventional AI systems, which typically operate within a pre-defined prediction space for AI models and rely on human-in-the-loop mechanisms to monitor and evaluate AI systems' performance, RPAs offer new paradigms of interaction enabled by the freedom and generative capabilities of LLMs.
% This shift introduces two emerging collaboration paradigms: \textbf{human-on-the-loop}, where humans monitor and guide AI systems executing semi-autonomous actions, and \textbf{human-out-of-the-loop}, where AI agents operate independently without real-time human intervention. 
% Both paradigms present unique opportunities and challenges that require careful exploration.

% The human-on-the-loop paradigm positions RPAs as semi-autonomous collaborators that can execute a series of tasks with minimal but critical human supervision. 
% This paradigm offers significant advantages in dynamic or high-stakes environments where continuous human monitoring of AI performance is expensive, inaccessible, or impractical. 
% For example, RPAs can autonomously simulate negotiation strategies, generate alternative solutions, or interact with multiple stakeholders in real time, which allows human supervisors to intervene only when necessary. 
% This paradigm can enhance efficiency by reducing cognitive and operational burdens on human users while still maintaining human supervision to ensure the safety and reliability of RPA-based AI systems in humans' workflow. 
% % In domains such as healthcare, policy simulation, and collaborative problem-solving, human-on-the-loop systems can streamline workflows and enable more scalable applications of AI.
% However, this paradigm introduces concerns regarding the scope and reliability of human supervision. Effective human-on-the-loop collaboration depends on the system’s ability to communicate its reasoning, limitations, and uncertainties to the human supervisor. 
% Without adequate explainability and transparency, humans may either over-rely on the AI or intervene unnecessarily, undermining the benefits of the paradigm. 

% The human-out-of-the-loop paradigm, where RPAs operate independently without real-time human intervention, represents an even more transformative opportunity. 
% In scenarios such as large-scale simulations, long-term automated interactions, or environments where immediate human involvement is infeasible, human-out-of-the-loop RPA systems can autonomously generate and evaluate solutions, collect data, and adapt their strategies based on dynamically changing contextual information. 
% This capability is particularly valuable in domains such as economic modeling, environmental simulations, and social system analysis, where the complexity and scale of the tasks make human real-time intervention impractical.
% Despite its potential, the human-out-of-the-loop paradigm also raises significant concerns. 
% The autonomy granted to RPAs increases the risk of unintended or undesirable outcomes, particularly when the agent encounters scenarios that fall outside its training data or reasoning capabilities. 
% Ensuring that RPAs adhere to ethical principles and domain-specific constraints without direct human involvement requires robust pre-deployment safeguards, including rigorous testing, built-in fail-safes, and post-hoc evaluation mechanisms. 
% Moreover, the potential for RPAs to make decisions that could have real-world consequences—such as in policy recommendations or behavioral studies—necessitates the development of regulatory frameworks to govern their deployment.

% These new paradigms also shift the traditional role of humans in AI collaborations. Instead of actively intervening in decision-making processes, humans are increasingly tasked with designing, monitoring, and evaluating the systems that perform autonomous or semi-autonomous actions. 
% This shift emphasizes the importance of interdisciplinary research, combining expertise from HCI, machine learning, and ethics to ensure that these new collaboration paradigms are effective, transparent, and aligned with human values. 
% As RPAs continue to evolve, understanding how to balance autonomy with accountability will be a critical factor in their success across various domains.