\section{Related Work}

\begin{figure}[t]
    \centering
    \includegraphics[width=.98\linewidth]{Figures/RPA-classification.pdf}
    \vspace{-0.5em}
    \caption{Taxonomy of RPAs.}
    \vspace{-1.5em}
    \label{fig:rpa-taxonomy}
\end{figure}

\subsection{Taxonomy of RPAs}
Existing literature~\cite{chen2024from,tseng-etal-2024-two,chen2024oscars,mou2024individual} classifies RPAs along two independent dimensions: Simulation Target and Simulation Scale. The Simulation Target dimension differentiates between agents that simulate specific individuals (e.g., historical figures, fictional characters, or individualized personas) and those that simulate group characteristics (e.g., artificial personas)~\cite{chen2024from,tseng-etal-2024-two,chen2024oscars}. The Simulation Scale dimension categorizes agents by the complexity of their interactions, ranging from single-agent simulations with no social interaction to multi-agent systems that replicate structured or emergent societal behaviors~\cite{mou2024individual}.

To unify these perspectives, we introduce an integrated taxonomy for RPAs (Fig.\ref{fig:rpa-taxonomy}). The \textit{Simulation Target} axis distinguishes between individual-focused and group-focused agents. Examples of individual-focused agents include digital twins, which model an individual's decision-making process~\cite{rossetti2024social}, and personas, which emulate specific human-like characteristics~\cite{10.1145/3613904.3642363}. Group-focused agents include social simulacra, which model interactions between specific individuals within a group (e.g., the relationship dynamics in Detective Conan)~\cite{wu2024role}, and synthetic societies, which replicate large-scale social structures and emergent group behaviors~\cite{park2023generative}. The \textit{Simulation Scale} axis differentiates between single-agent and multi-agent systems. Single-agent RPAs operate at an individual level, such as digital twins used for personalized recommendations or personas that generalize group characteristics for interaction. Multi-agent RPAs involve more complex interactions, with social simulacra capturing interpersonal dynamics within small, predefined groups, and synthetic societies modeling large-scale collective decision-making and societal structures.


\subsection{Evaluation of RPAs}
Existing surveys on the evaluation of RPAs~\cite{gao2024large, chen2024from, tseng-etal-2024-two, chen2024oscars, mou2024individual} provide a unified classification of RPA evaluation metrics from the perspective of evaluation approaches. However, they lack a comprehensive and consistent taxonomy for versatile evaluation metrics, leading to arbitrary metrics selection in practices.

Prior works~\cite{gao2024large,mou2024individual} categorize RPA evaluations into three types: automatic evaluations, human-based evaluations, and LLM-based assessments. Automatic evaluations are efficient and objective, but lack context sensitivity, failing to capture nuances like persona consistency. Human-based evaluations provide deep insight into character alignment and engagement, but they are costly, less scalable, and prone to subjectivity. LLM-based evaluations are automatic and offer scalability and speed, but may not always align with human judgments.

The classification of evaluation metrics in prior works varies significantly, leading to inconsistency and ambiguity. For instance, \citet{gao2024large} focuses on realness validation and ethics evaluation, whereas \citet{chen2024from} differentiates between character persona and individualized persona. Furthermore, \citet{chen2024oscars} classifies evaluation into conversation ability, role-persona consistency, role-behavior consistency, and role-playing attractiveness, which partially overlap with \citet{mou2024individual}'s individual simulation and scenario evaluation. These discrepancies indicate a lack of standardized taxonomy, making it difficult to compare results across studies and select appropriate evaluation metrics for specific applications.

While existing surveys offer different taxonomies of RPA evaluation, they do not provide concrete evaluation design guidelines. Our work addresses this gap by proposing a structured framework that systematically links evaluation metrics to RPA attributes and real-world applications.




















% Existing surveys on RPAs~\cite{gao2024large, chen2024from,tseng-etal-2024-two,chen2024oscars,mou2024individual} primarily classify the evaluation metrics into two categories: Evaluation Approaches and Evaluation Perspectives. 
% Evaluation Approaches~\cite{} divide RPA evaluations into three types: automated evaluations using objective metrics, subjective evaluations based on human annotations, and evaluations conducted by other LLMs acting as assessors. 
% Evaluation Perspectives address various dimensions, including the similarity~\cite{} between generated and real data, consistency~\cite{}, explainability~\cite{}, personality~\cite{}, linguistic style~\cite{}, ethical considerations~\cite{}, and performance in downstream tasks~\cite{}.
% While these taxonomies effectively categorize existing evaluation metrics, they fall short of providing a practical guideline for RPA evaluation. Specifically, they do not fully elucidate the causal relationships between agent attributes, downstream tasks, and metric selection, leaving metric selection prone to inconsistency, incompleteness, and arbitrariness in practice.


% The evaluation of role-playing language agents (RPAs) encompasses diverse scenarios, such as behavioral research~\cite{} and emotional support~\cite{}. This evaluation typically focuses on two key dimensions: positive effects and negative impacts. Positive effects primarily relate to persona fidelity, while negative impacts include bias and hallucination.

% \textbf{Fidelity.} Persona fidelity involves aspects such as personality alignment and cultural adaptability. For instance, Wang et al. proposed an interview-based evaluation framework using psychological scales to verify whether personas realistically simulate assigned personality traits. Similarly, Kwok et al. conducted questionnaire-based psychological experiments to evaluate whether RPAs accurately reflect the characteristics of their assigned nationalities. However, past studies often adopt varying definitions and focal points, leading to evaluations that address only a subset of RPA fidelity. Cheng et al. proposed a more comprehensive framework to evaluate RPA caricature, decomposing it into two components: individualization (capturing nuanced human behavior) and exaggeration (avoiding misleading descriptions, stereotypes, or essentializing narratives about demographic groups). They measured these dimensions by analyzing the differences between the target persona and a base persona. Notably, they argued that while eliminating caricatures is necessary for high-quality simulations, it alone does not preclude the presence of stereotypes.

% \textbf{Bias.} Research on RPA bias focuses on identifying and analyzing the biases these agents exhibit and comparing them to human biases. Gupta et al. demonstrated that despite appearing impartial on the surface, large language models (LLMs) often harbor deeply ingrained biases against various demographic groups. While LLMs may overtly reject stereotypes when queried explicitly, they frequently exhibit stereotypical and inaccurate assumptions in role-playing contexts. Giorgi et al. compared human biases with those of role-based LLMs and found notable discrepancies, such as differences in hate speech annotations, revealing how RPA biases diverge from human biases in specific scenarios.

% \textbf{Hallucination.} Studies have investigated various causes of RPA hallucination, including errors related to known and unknown knowledge, role-playing time points, and external attacks. Zhang et al. emphasized the need to examine known knowledge errors and unknown knowledge errors during role-playing. They proposed an agent-based reasoning method, Self-Recollection and Self-Doubt, to enhance error detection. Ahn et al. explored time-point-induced hallucinations, where RPAs must avoid contradictions, such as presenting knowledge inconsistent with their assigned personasâ€™ identities or historical timelines. They introduced TimeChara, a benchmark for evaluating point-in-time character hallucinations in role-playing LLMs. Tang et al. viewed hallucination as a form of attack on RPAs, developing RoleBreakEval, a dataset for assessing hallucination mitigation techniques. They also proposed a novel defense strategy that enhances contextual background through narrative generation to mitigate role-query conflicts and improve query generalization.


% Existing literature~\cite{chen2024from,tseng-etal-2024-two,chen2024oscars,mou2024individual} classifies RPAs along two independent dimensions: \textit{Simulation Target} and \textit{Simulation Scale}. The Simulation Target dimension distinguishes between agents that replicate the characteristics of specific groups (e.g., personas) and those that impersonate specific individuals, including historical, fictional, or real-world figures~\cite{chen2024from,tseng-etal-2024-two,chen2024oscars}. The Simulation Scale dimension categorizes agents based on the scale of their interactions, ranging from mimicking a single agent without social interactions to organizing multiple agents within defined scenarios or simulating complex societal interactions~\cite{mou2024individual}.

% To unify the two orthogonal and complementary perspectives, we integrate them into a new taxonomy for RPAs, as illustrated in Fig.~\ref{}. The \textbf{Simulation Target} axis differentiates between agents designed to simulate either \textit{specific groups} or \textit{individuals}, while the \textbf{Simulation Scale} axis separates agents simulating the behavior of a \textit{single agent} from those replicating social dynamics among \textit{multiple agents}.

% \hl{add the RPA 2x2 table/figure}


