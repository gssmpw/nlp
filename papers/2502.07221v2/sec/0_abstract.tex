\begin{abstract}
Pathology plays a critical role in diagnosing a wide range of diseases, yet existing approaches often rely heavily on task-specific models trained on extensive, well-labeled datasets. These methods face sustainability challenges due to the diversity of pathologies and the labor-intensive nature of data collection. To address these limitations, we highlight the need for universal multimodal embeddings that can support multiple downstream tasks. Previous approaches involve fine-tuning CLIP-based models, which handle images and texts separately, limiting their ability to capture complex multimodal relationships. Additionally, these models are evaluated across diverse datasets without a unified benchmark. In this paper, we explore the possibility of applying Multimodal Large Language Models (MLLMs) to generate pathology universal embeddings to address these challenges. Our contributions can be summarized in the following aspects: 1) We propose MLLM4PUE, a novel framework that leverages MLLMs to generate embeddings for various pathology downstream tasks. 2) We further introduce the Pathology Multimodal Embedding Benchmark (PMEB), a comprehensive benchmark designed to assess the quality of pathology multimodal embeddings, which comprises 16 original tasks drawn from 15 datasets. 3) Extensive experimental results demonstrate the superiority of MLLM4PUE, illustrating MLLM-based models can effectively support a wide range of downstream tasks and unify the research direction for foundation models in pathology.

\end{abstract}
\vspace{-2ex}