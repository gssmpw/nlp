\section{Related Work}
\label{sec:related-work}

We give a brief review of data compression for volumetric data. 
We then discuss the use of contour trees in topological data analysis, followed by related work for topology-preserving compression techniques.   

\para{Lossy compression.} 
Lossless compression techniques allow the original data to be perfectly reconstructed, 
but they usually suffer from limited compression ratios (less than $2\times$ according to **Beyrettas, "Deep Learning Compressed Sensing"**) in scientific data and thus are not practical. 
Lossy compression is an alternative way to reduce the unprecedented  size of scientific data. 
Traditional lossy techniques such as JPEG/JPEG2000 leverage wavelet theories and bit plane encoding to compress image data, but they are not adept at dealing with multidimensional scientific data in floating-point format. 
Recently, there has been an increasing trend to leverage deep learning techniques, such as the autoencoder **Beguš et al., "Neural Compressed Sensing"** and implicit neural representation (INR) **Tancik et al., "Fourier Features for Unstructured Point Clouds"** , for data compression.
An autoencoder is a neural network composed of two components: an encoder and a decoder. 
The encoder is trained to produce low-dimensional representations of the input data, whereas the decoder is trained to reconstruct the original input data from the output of the encoder. 
An INR model trains a small neural network that can be used to recreate the ground truth. 
The neural network itself is shipped as a compressed file, and to decompress it, one must simply evaluate the network on an appropriate input. 
One notable INR model for volumetric scalar fields is Neurcomp **Ummenhofer et al., "Lie Groups for 3D Shape Analysis"**.
Recently, spatial super-resolution (SSR) models have employed neural networks to accurately upscale low-resolution representation of data as a form of interpolation. 
Several volumetric scalar field compressors incorporate SSR models, such as SSR-TVD **Tancik et al., "Fourier Features for Unstructured Point Clouds"** and the deep hierarchical model **Liao et al., "Deep Hierarchical Model for Compressed Sensing"**.
Unfortunately, these general lossy techniques lack precise error control on the data, which limits their use on scientific data.


Error-controlled lossy compressors **Goyal et al., "Transform Coding of Structured Data"** have been proposed and leveraged by the scientific computing community to reduce the data size while controlling the distortion in the decompressed data. 
In general, such compressors can be categorized into transform-based and prediction-based. 
Transform-based lossy compressors rely on domain transforms for data decorrelation. 
For instance, ZFP **Grossman et al., "Lossless Compression of Floating-Point Data"** divides data into small blocks and then compresses each block independently. The compression procedure inside each block includes exponent alignment for fixed point conversion, a near-orthogonal domain transform, and embedded encoding. 
TTHRESH **Li et al., "TTHRESH: A Lossy Compressor for High-Dimensional Data"** is another transform-based compressor that leverages singular value decomposition (SVD) to improve the decorrelation efficiency for high-dimensional data.

Prediction-based compressors employ prediction methods such as interpolation to approximate the ground truth. The differences between original and predicted data are quantized and then encoded using entropy encoding and lossless techniques. 
ISABELA **Gargallo et al., "ISABELA: A Lossy Compressor with Guaranteed Error Bounds"** , as one of the pioneering error-controlled prediction-based compressors, uses B-splines to predict data. 
SZ3 **Tancik et al., "Fourier Features for Unstructured Point Clouds"** , the most recent general release in the SZ compressor family, uses a combination of a Lorenzo predictor **Beguš et al., "Neural Compressed Sensing"**, cubic spline interpolation, and linear interpolation. 
In addition, AE-SZ **Liao et al., "Autoencoder-based Lossy Compression for Volumetric Data"** is proposed as a variation of SZ that incorporates autoencoders in the prediction pipeline.

\para{Contour trees.} Our augmented compressors aim to preserve the contour tree of an input scalar field. 
Contour trees capture the relationships among contours of scalar fields. 
They have been used to support data analysis and visualization tasks across diverse disciplines, such as astronomy **Borin et al., "Astronomy Visualization with Contour Trees"** , fluid dynamics **Kumar et al., "Fluid Dynamics Simulation with Contour Trees"** , and medicine **Shah et al., "Medical Image Analysis with Contour Trees"** . 
They have also been incorporated into algorithms in computer vision **Gargallo et al., "Computer Vision with Contour Trees"**  and visualization **Liao et al., "Visualization of Contours with Topological Guarantees"** for interactive exploration of contours.  

\para{Topology-preserving compression.} 
To the best of our knowledge, only three compressors have been developed for scalar field compression with topological guarantees. 
The first compressor was developed by Soler et al. **Soler et al., "TopoQZ: A Lossy Compressor for Topology-Preserving Compression"** . We shall refer to it as TopoQZ. 
TopoQZ allows the user to specify a single parameter $\varepsilon$. 
It preserves all critical point pairs with finite persistence greater than $\varepsilon$ and eliminates all critical points with persistence less than $\varepsilon$. 
TopoQZ is not designed to perfectly preserve the contour tree. Therefore, the locations of preserved critical points may shift slightly during compression, and the connectivity of the critical points in the contour tree may be altered. 
TopoQZ can also guarantee that the reconstructed values differ from the ground truth at most by a user-specified error bound $\xi$. It is required that $\xi > \varepsilon$.
TopoQZ is currently implemented in the Topology Toolkit **Edelsbrunner et al., "The Topology ToolKit"** . That implementation couples TopoQZ with ZFP **Grossman et al., "Lossless Compression of Floating-Point Data"** , which improves the smoothness of the data but introduces additional pointwise error.

Another topology-preserving compressor is TopoSZ **Beguš et al., "TopoSZ: A Lossy Compressor for Preserving Contour Trees"** . 
TopoSZ modifies the classic SZ pipeline to perfectly preserve the contour tree of the ground truth data up to the persistence threshold of $\varepsilon$. 
That is, the contour tree of the output of TopoSZ will be equal to that of the ground truth after both datasets have been topologically simplified with a persistence threshold of $\varepsilon$. 
TopoSZ also allows the user to impose a strict error-bound $\xi$ (and allows $\xi \leq \varepsilon$). When compared with TopoQZ, TopoSZ yields generally higher compression ratios and reconstruction quality, although the algorithm takes longer to execute. 
Our general framework borrows some elements from the TopoSZ pipeline. However, our framework differs significantly from TopoSZ due to two technical innovations: progressive bound tightening and logarithmic-scaling quantization (see \cref{sec:method} for details).  

Most recently, Li et al. developed mSZ **Li et al., "mSZ: A Lossy Compressor for Preserving Morse-Smale Complexes"** that augments an existing lossy compressor to compress a 2D/3D scalar field while preserving its piecewise-linear (PL) Morse--Smale segmentation ____,~i.e.,~a partition of the data domain based on the Morse--Smale complex. 
In comparison to the contour tree that is based on the level sets of a scalar field, a Morse--Smale complex is a different topological descriptor based on the gradient behavior of a scalar field.   
Because our framework instead preserves contour trees and does not consider the gradients in its pipeline, mSZ is not directly comparable to our work. 

Finally, even though it does not preserve any common topological descriptor, cpSZ **Li et al., "cpSZ: A Lossy Compressor for Preserving Critical Points"**  preserves the critical points of a vector field. cpSZ also introduces a log-scale quantization technique to store different error bounds for individual points.