\section{Related Work}
\label{sec:related-work}

We give a brief review of data compression for volumetric data. 
We then discuss the use of contour trees in topological data analysis, followed by related work for topology-preserving compression techniques.   

\para{Lossy compression.} 
Lossless compression techniques allow the original data to be perfectly reconstructed, 
but they usually suffer from limited compression ratios (less than $2\times$ according to____) in scientific data and thus are not practical. 
Lossy compression is an alternative way to reduce the unprecedented  size of scientific data. 
Traditional lossy techniques such as JPEG/JPEG2000 leverage wavelet theories and bit plane encoding to compress image data, but they are not adept at dealing with multidimensional scientific data in floating-point format. 
Recently, there has been an increasing trend to leverage deep learning techniques, such as the autoencoder____ and implicit neural representation (INR)____, for data compression.
An autoencoder is a neural network composed of two components: an encoder and a decoder. 
The encoder is trained to produce low-dimensional representations of the input data, whereas the decoder is trained to reconstruct the original input data from the output of the encoder. 
An INR model trains a small neural network that can be used to recreate the ground truth. 
The neural network itself is shipped as a compressed file, and to decompress it, one must simply evaluate the network on an appropriate input. 
One notable INR model for volumetric scalar fields is Neurcomp____.
Recently, spatial super-resolution (SSR) models have employed neural networks to accurately upscale low-resolution representation of data as a form of interpolation. 
Several volumetric scalar field compressors incorporate SSR models, such as SSR-TVD____ and the deep hierarchical model____.
Unfortunately, these general lossy techniques lack precise error control on the data, which limits their use on scientific data.


Error-controlled lossy compressors____ have been proposed and leveraged by the scientific computing community to reduce the data size while controlling the distortion in the decompressed data. 
In general, such compressors can be categorized into transform-based and prediction-based. 
Transform-based lossy compressors rely on domain transforms for data decorrelation. 
For instance, ZFP____ divides data into small blocks and then compresses each block independently. The compression procedure inside each block includes exponent alignment for fixed point conversion, a near-orthogonal domain transform, and embedded encoding. 
TTHRESH____ is another transform-based compressor that leverages singular value decomposition (SVD) to improve the decorrelation efficiency for high-dimensional data.

Prediction-based compressors employ prediction methods such as interpolation to approximate the ground truth. The differences between original and predicted data are quantized and then encoded using entropy encoding and lossless techniques. 
ISABELA____, as one of the pioneering error-controlled prediction-based compressors, uses B-splines to predict data. 
SZ3____, the most recent general release in the SZ compressor family, uses a combination of a Lorenzo predictor____, cubic spline interpolation, and linear interpolation. 
In addition, AE-SZ____ is proposed as a variation of SZ that incorporates autoencoders in the prediction pipeline.

\para{Contour trees.} Our augmented compressors aim to preserve the contour tree of an input scalar field. 
Contour trees capture the relationships among contours of scalar fields. 
They have been used to support data analysis and visualization tasks across diverse disciplines, such as astronomy ____, fluid dynamics ____, and medicine ____. 
They have also been incorporated into algorithms in computer vision ____ and visualization ____ for interactive exploration of contours.  

\para{Topology-preserving compression.} 
To the best of our knowledge, only three compressors have been developed for scalar field compression with topological guarantees. 
The first compressor was developed by Soler et al. ____. We shall refer to it as TopoQZ. 
TopoQZ allows the user to specify a single parameter $\varepsilon$. 
It preserves all critical point pairs with finite persistence greater than $\varepsilon$ and eliminates all critical points with persistence less than $\varepsilon$. 
TopoQZ is not designed to perfectly preserve the contour tree. Therefore, the locations of preserved critical points may shift slightly during compression, and the connectivity of the critical points in the contour tree may be altered. 
TopoQZ can also guarantee that the reconstructed values differ from the ground truth at most by a user-specified error bound $\xi$. It is required that $\xi > \varepsilon$.
TopoQZ is currently implemented in the Topology Toolkit ____. That implementation couples TopoQZ with ZFP ____, which improves the smoothness of the data but introduces additional pointwise error.

Another topology-preserving compressor is TopoSZ ____. 
TopoSZ modifies the classic SZ pipeline to perfectly preserve the contour tree of the ground truth data up to the persistence threshold of $\varepsilon$. 
That is, the contour tree of the output of TopoSZ will be equal to that of the ground truth after both datasets have been topologically simplified with a persistence threshold of $\varepsilon$. 
TopoSZ also allows the user to impose a strict error-bound $\xi$ (and allows $\xi \leq \varepsilon$). When compared with TopoQZ, TopoSZ yields generally higher compression ratios and reconstruction quality, although the algorithm takes longer to execute. 
Our general framework borrows some elements from the TopoSZ pipeline. However, our framework differs significantly from TopoSZ due to two technical innovations: progressive bound tightening and logarithmic-scaling quantization (see \cref{sec:method} for details).  

Most recently, Li et al. developed mSZ____ that augments an existing lossy compressor to compress a 2D/3D scalar field while preserving its piecewise-linear (PL) Morse--Smale segmentation ____,~i.e.,~a partition of the data domain based on the Morse--Smale complex. 
In comparison to the contour tree that is based on the level sets of a scalar field, a Morse--Smale complex is a different topological descriptor based on the gradient behavior of a scalar field.   
Because our framework instead preserves contour trees and does not consider the gradients in its pipeline, mSZ is not directly comparable to our work. 

Finally, even though it does not preserve any common topological descriptor, cpSZ ____---a variation of SZ---preserves the critical points of a vector field. cpSZ also introduces a log-scale quantization technique to store different error bounds for individual points.