\section{Introduction}
\label{sec:introduction}

Modern scientific simulations generate enormous amounts of data, such that it is not practical to store all of the data produced \cite{cappello2019use}.
Data compression helps reduce the size of data, making data storage more practical.
%for storage and transmission in scientific data management systems. 
There are two types of compression techniques: lossy and lossless.
Lossy compression techniques allow for some distortion of the data to achieve smaller compressed file sizes and have wide applicability in the compression of images \cite{hussain2018image}, audio \cite{kavitha2016survey}, and scientific data \cite{cappello2019use}. 
Among them, error-bounded lossy compressors, such as SZ \cite{liang2022sz3}, ZFP \cite{lindstrom2014fixed}, and TTHRESH \cite{ballester2019tthresh}, play a crucial role in reducing the storage demand of large-scale scientific data. 
Not only can such compressors significantly reduce the data volume, but also they can control the data distortion and guarantee the validity of the reconstructed data for post hoc analysis, based on user-defined error bounds~\cite{LiuDiZhao2022}. 
For instance, error-bounded lossy compressors have been shown to reduce file size dramatically without significant degradation of the visual quality on the reconstructed (decompressed) data (e.g.,~\cite{LiangDiTao2019, ballester2019tthresh,zhao2021optimizing}). 

In the analysis of scientific data, topological data analysis (TDA) employs topological descriptors, such as contour trees~\cite{carr2003computing} and Morse--Smale complexes~\cite{edelsbrunner2001hierarchical}, to describe, summarize, and draw conclusions about scientific data (e.g.,\cite{aydogan2014characterization, cazals2003molecular,rosen2021using}); see~\cite{YanMasoodSridharamurthy2021} for a survey. 
Although error-bounded lossy compressors typically allow the user to impose pointwise error bounds that are maintained during compression, such compressors seldom make guarantees about how the compression will affect the geometry and topology of the reconstructed data. 

For example, Lu et al.~\cite{lu2018understanding} examined the impact of lossy compression on data fidelity and complex scientific data analytics.
They studied the detection of \emph{blobs}, features used by fusion scientists to study the trajectory of high-energy particles. 
Blobs are defined by areas with high electric potentials, i.e., areas enclosed by contours above certain thresholds. 
Their experiments demonstrated that as the error bound increases, the blobs will change in both number and position. 
They concluded that ``lossy compression may seriously distort
data, thus having a disastrous impact on data analytics,'' and therefore ``determining a proper error bound is key to performing
meaningful lossy compression in science production.''~\cite{lu2018understanding} 
We argue that determining a proper error bound is only part of the story. It is also important to develop error-bounded lossy compressors that explicitly preserve features of interest to domain scientists---such as topological features---during compression. 

In this paper, we introduce a general framework that augments \emph{any} lossy compressor for volumetric scalar fields---error bounded or not---in order to impose topological control, while maintaining a user-specified pointwise error bound.  
Specifically, our framework augments any lossy compressor in order to preserve the \emph{contour tree} in terms of its critical points and the connectivity among those critical points. 
Preserving the contour tree of the reconstructed data is crucial to support a variety of post hoc scientific visualization tasks, since the contour tree has been used for feature extraction, tracking, comparison, and interactive contour exploration (e.g.,~\cite{zhou2009automatic, kopp2022temporal}). 

Previous work by Yan et al.~\cite{yan2023toposz} modified the classic SZ compressor with a customized error-controlled quantization strategy to preserve the contour tree. 
Instead of modifying any \emph{single} compressor~\cite{yan2023toposz}, our general framework can augment \emph{any} scalar field compressor, with \emph{no restrictions} on the base compressor. We effectively leverage the capabilities of a wide variety of data compressors to preserve the contour tree. 
Additionally, as data compressors continue to improve, our framework can be used to augment increasingly effective compressors and thereby achieve better results. 
 
During augmentation, our framework introduces a progressive strategy to compute upper and lower error bounds for specific data points, which, if maintained, will guarantee that the contour tree is preserved and the pointwise error bound is maintained. 
The classic algorithm constructs a contour tree by combining two merge trees~\cite{carr2003computing} (i.e., a join tree and a split tree, see~\cref{sec:merge-and-contour-tree} for details).  
Our progressive strategy works with these merge trees: if the merge trees are preserved, then so is the contour tree.
Our framework is \emph{progressive} in the sense that it works through a merge tree computation, preserving one branch at a time. 
Only a small portion of the merge tree is computed more than once during the error bound tightening process.
This is in contrast with TopoSZ, which iteratively recomputes the entire contour tree many times. Thus, our progressive approach shows significant speedups compared with TopoSZ.
Our strategy then uses a novel variable-precision encoding scheme to store any adjustments that must be made to the output of an augmented compressor in order to ensure that these upper and lower bounds are maintained.  
Our contributions include: 
\begin{itemize}[noitemsep,leftmargin=*]
\item A novel progressive strategy that efficiently refines upper and lower bounds during the merge tree computations (subroutines for contour tree computation) without computing contour trees explicitly (as in TopoSZ). These error bounds correspond to adjustments that must be made to the output of any compressor in order to preserve the contour tree.   
\item A custom variable-precision encoding scheme to efficiently store these adjustments.
\item A systemic comparative study that evaluates five lossy compressors (ZFP, SZ3, Cubic Spline, TTHRESH, Neurcomp) augmented with topological control, and two state-of-the-art topology-preserving compressors, across a number of scientific datasets.  
\end{itemize}
Our experimental study demonstrates the effectiveness and efficiency of our framework in enabling topological controls for a wide variety of lossy compressors.