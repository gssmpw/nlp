\section{Experimental Results}
\label{sec:results}

\begin{figure*}[!ht]
    \centering
    \begin{subfigure}{0.02\textwidth}
    \raisebox{0.1\height}{\includegraphics[angle=90,width=\textwidth]{fig-colorBar}}
    \end{subfigure}
    \begin{subfigure}{0.92\textwidth}
    \includegraphics[width=\textwidth]{fig-vr_table_smaller.png}
    \end{subfigure}
    \vspace{-3mm}
    \caption{Scientific datasets compressed using different augmented compressors with topological controls. From left to right: the original input dataset, the reconstructed datasets from Augmented ZFP, Augmented SZ3, and Augmented TTHRESH, 
    respectively, that preserve the contour trees up to a persistence threshold $\varepsilon = 0.04$. From top to bottom: Tangaroa, Miranda, S3D datasets, respectively. We also display the PSNR and compression ratio next to each decompressed dataset.}    
    \label{fig:volume-render}
    \vspace{-6mm}
\end{figure*}

We provide an overview in~\cref{sec:results-overview}, describing the base compressors and datasets used in our experiments, highlighting the main takeaways, and introducing the evaluation metrics. 
We include compressor configurations and implementation details in~\cref{sec:configurations}. 
In \cref{sec:augmented-compressors} we describe the main utilities of our augmented compressors in preserving contour trees in the reconstructed data.
We evaluate a number of augmented compressors qualitatively and quantitatively, followed by a comparison against the state-of-the-art topology-preserving compressors in \cref{sec:compare-topology}.
We end this section with a run time analysis in \cref{sec:run-time}.

%---------------------------------------
\subsection{An Overview of Experiments}
\label{sec:results-overview}

We present a comparative analysis of five error-bounded lossy compressors augmented with our framework, including the classic compressors ZFP \cite{lindstrom2014fixed}, SZ3 \cite{liang2022sz3}, and TTHRESH \cite{ballester2019tthresh}, a custom-built cubic spline interpolation (CSI) model, and a deep learning-based compressor Neurcomp \cite{lu2021compressive}. 
We test these augmented compressors---denoted as Augmented ZFP, Augmented SZ3, and so on---against two state-of-the-art topology-preserving compressors, TopoSZ~\cite{soler2018topologically} and TopoQZ~\cite{yan2023toposz}. 

We test the five augmented compressors and two topology-preserving compressors on nine volumetric datasets from scientific simulations. The Nyx dataset is very topologically complex---its contour tree has over twenty million nodes---and it is included as a stress test. See \cref{tab:datasets} and \cref{sec:datasets} for details on these datasets.

We further conduct an ablation study demonstrating the effectiveness of logarithmic-scaling quantization and progressive error bound tightening. In every trial, logarithmic-scaling quantization leads to higher compression ratios, whereas progressive tightening results in faster compression times. We also analyze the individual effects of varying $\varepsilon$ and $\xi$; see~\cref{sec:other-experiments} for details on these experiments and the ablation study.

\begin{table}[!ht]
\scriptsize
\centering{
\begin{tabu}{c|*{2}{c}}
\toprule
\textbf{Dataset}  & \textbf{Dimension} & \textbf{Size (MB)}  \\ 
\midrule
QMCPACK      & $69 \times 69 \times 115$          & 4.4         \\
Tangaroa     & $300 \times 180 \times 200$         & 27.0        \\
Earthquake   & $175 \times 188 \times 50$          & 28.2        \\
Ionization   & $310 \times 128 \times 128$         & 40.6       \\
Isabel       & $500 \times 500 \times 90$          & 105.0     \\
Miranda      & $384 \times 384 \times 256$         & 302.0      \\
Nyx          & $512 \times 512 \times 512$         & 641.4      \\
S3D          & $500 \times 500 \times 500$         & 1000.0    \\
SCALE-LETKF  & $1200 \times 1200 \times 98$        & 1129.0    \\
\bottomrule
\end{tabu}
}
\vspace{-2mm}
\caption{Scientific datasets used for compression analysis.}
\label{tab:datasets}
\vspace{-4mm}
\end{table}

\para{Highlighted results.}
We highlight our experimental results below. 
\begin{itemize}[noitemsep,leftmargin=*]
\item Applying any of the five original base compressors to any of the nine datasets produces a large number of topological false cases in the reconstruction, even with a small pointwise error bound. On the other hand, augmenting any compressor with our general framework completely eliminates these false cases while maintaining a user-specified error bound (\cref{sec:augmented-compressors}).
\item Augmented TTHRESH and Augmented ZFP respectively yield the best compression ratios and run times among all the augmented compressors (\cref{sec:augmented-compressors}).
\item Our augmented compressors generally have a better trade off between bit-rate and reconstruction quality compared to TopoQZ and TopoSZ while taking similar or less time to run (\cref{sec:compare-topology}).
\item Our framework has a worst-case time complexity of $O(F h n \log n)$, where $h$ is the maximum height of the contour tree during tightening and $F$ is the number of false cases during computation. The majority of the compression time is spent on computing merge trees (\cref{sec:run-time}).
\end{itemize}

\para{Evaluation metrics.} 
We evaluate whether the contour tree has been perfectly preserved in the reconstructed (decompressed) data. 
We also evaluate the standard compression metrics of compression ratio, bit-rate, and peak signal-to-noise ratio (PSNR).
We further employ topology-based metrics of the bottleneck distances $d_B$~\cite{cohen2005stability} and the Wasserstein distances $d_W$ \cite[page 183]{edelsbrunner2022computational} to quantify the topological similarity between the original data and the reconstructed data. 
The evaluation metrics are described in detail in \cref{sec:evaluationMetrics}.

In general, higher values of PSNR indicate better reconstruction quality, and lower values of $d_B$ and $d_W$ indicate higher topological similarity. 
We measure the total compression time for each compressor, which includes (a) the total time to run the base compressor, and (b) the time to augment the output of the base compressor. We also measure decompression time for each compressor. We measure compression and decompression time for TopoSZ and TopoQZ as well. For our framework and TopoSZ, we decompress to RAW binary format. Because TopoQZ is integrated in the Topology Toolkit, an extension for ParaView, we decompress to VTK image format.

% ---------------------------------------
\subsection{Compressor Configurations and Implementation}
\label{sec:configurations}

In addition to augmenting the out-of-box base compressors SZ3, TTHRESH, ZFP, and Neurcomp, we implement and augment our own super-resolution compressor, a simple custom-built cubic spline interpolation (CSI) model.
It compresses a dataset by downsampling the data by a user-defined ratio in each direction (called a target scale factor) and uses a cubic spline interpolation technique for reconstruction that is similar to the one implemented in SZ3.
%We also considered the Sliced Wasserstein Autoencoder \cite{kolouri2018sliced} used in the AE-SZ compressor \cite{liu2021exploring}. 
%However, this model is excluded from our experiments since it performed significantly worse than the other compressors during initial tests.   

We compare our augmented compressors to TopoSZ and TopoQZ. We use the TopoQZ implementation in TTK~\cite{TiernyFavelierLevine2017}. 

Our general framework requires two user-defined parameters, a persistence threshold $\varepsilon$ and a global absolute pointwise error bound $\xi$.
$\varepsilon$ represents, as a percentage of the range, the level of persistence  simplification. 
For example, $\varepsilon = 0.01$ corresponds to a persistence simplification by $1\%$ of the range of the scalar function. Similarly, $\xi$ is the percentage of the range that will be used as an absolute error bound.

Each base compressor takes a number of intrinsic parameters in order to run. 
Both ZFP and SZ3 require an absolute error bound, denoted as $\delta$ and $\eta$, respectively. 
CSI requires a target scale factor $s$.
TTHRESH takes in a target RMSE of $\tau$. 
Neurcomp requires a target compression ratio $c$. 
Changing the intrinsic parameters of a base compressor will cause it to generate different intermediate data which will be augmented differently. 
As a result, even though our augmented compressor guarantees topology preservation and maintains the user-defined global error bound, the compression results may vary. 

For our experiments, we set the error parameter for each base compressor (except CSI and Neurcomp) to be equal to $k\xi$ for some $k \in \R$ that is compressor-dependent. Specifically, we set $\delta = 5\xi$, $\eta = 0.25\xi$, and $\tau = 0.05\xi$. To decide each value of $k$, we conduct a grid search and observe the effects of different values of $k$ across different values of $\xi$ and different datasets. The optimal value of $k$ varies between datasets and values of $\xi$, but the values that we chose are always approximately optimal. Hypothesized explanations as to why these values of $k$ improve results are described in \cref{sec:base-compressor-parameters}. We also set $c = 100$ and $s = 7$. We chose these configurations because they empirically led to the highest compression ratios.

To differentiate from the persistence threshold $\varepsilon$ used by an augmented compressor, TopoQZ takes a persistence threshold $e$. The TTK implementation of TopoQZ is tightly coupled with ZFP, which requires an error bound $\zeta$, allowing for a total pointwise error upper-bounded by $e+\zeta$.
To measure compression ratio and compression times while respecting a topological constraint $\varepsilon$ and an error bound $\xi$, we measure how each augmented compressor and TopoSZ perform for $\varepsilon = 0.04$ and $\xi = 0.012$. When testing TopoQZ, to ensure that it respects both $\varepsilon$ and $\xi$, we set $e = \zeta = 0.006$ so that the max error is less than $0.012$.

To measure the trade off between compression ratio and reconstruction quality, for TopoSZ and each augmented compressor, we set $\varepsilon = 0.04$ and vary $\xi \in \{$0.003, 0.006, 0.009, 0.012, 0.015, 0.018$\}$. In some cases we need to vary $\xi$ (and $\zeta$, for TopoQZ) in a different range in order to obtain a meaningful curve. Notably, for TopoQZ, we set $e = 0.04$ and vary $\zeta \in \{$0.003, 0.11, 0.22, 0.33, 0.44, 0.55$\}$. We further discuss our methodology for choosing parameters and provide the parameter used in \cref{sec:reconstruction-quality-extra}. 

The combination of a chosen compressor, a fixed dataset, a value of $\varepsilon$ and $\xi$, is a trial.
We perform each trial on a single cluster node running an Intel Xeon Sandy Bridge-E processor with 16 cores and 64GB of RAM.
For Neurcomp, we perform the training on an RTX 2080ti GPU with 32GB of RAM.

\begin{figure}[!ht]
\begin{subfigure}{0.02\linewidth}
\raisebox{2.2\height}{
\includegraphics[angle=90, width=\linewidth]{fig-colorBar.png}}
\end{subfigure}
\begin{subfigure}{0.97\linewidth}
    \includegraphics[width=\linewidth]{fig-scale_lattice_2.png}
\end{subfigure}
\vspace{-6mm}
\caption{Zoomed-in views of the critical points of the contour trees of the Ionization (top) and SCALE-LETKF (bottom) datasets with persistence simplification $\varepsilon = 0.04$. For each dataset, arrows indicate one example where compression with TTHRESH led to critical points shifting. Local maxima are in orange, local minima are in dark blue, 1-saddles are in light blue, 2-saddles are in light orange. Top row: Ionization. Bottom row: SCALE-LETKF.}
\label{fig:zoom}

\centering{
\begin{tabular}{c|cc|c}
\hline
Dataset    & ZFP       & TTHRESH       & Total \#edges \\ \hline
QMCPACK    & (23,23,0) & (8,8,0)     & 69          \\ 
Tangaroa   &  (90, 92, 0) & (39, 46, 0) & 418         \\ 
Earthquake & (20, 19, 0) & (26, 25, 0)     & 169         \\
Ionization & (181, 187, 0)  & (37, 44, 0) & 568         \\
Isabel     & (16, 15, 0) & (15, 16, 0)  & 29          \\
Miranda    & (6, 6, 0) & (3, 3, 0)     & 11          \\ 
Nyx        & (133, 132, 0) & (2, 373, 0) & 743 \\
S3D       & (100, 100, 0) & (74, 80, 0) & 1013 \\
SCALE-LETKF & (152, 153, 0) & (129, 127, 0) & 401 \\ \hline
\end{tabular}
}
\vspace{-2mm}
\captionof{table}{Reporting the number of false cases (false positives, false negatives, false types) produced by base compressors SZ3 and TTHRESH, respectively, together with the total number of edges of the input (ground truth) contour tree. Contour trees are simplified with $\varepsilon=0.04$.}
\label{tab:base-false-cases}
\vspace{-6mm}
\end{figure}

%---------------------------------------
\subsection{Comparative Analysis of Augmented Compressors}
\label{sec:augmented-compressors}

In this section, we perform a comparative analysis of five augmented compressors, qualitatively and quantitatively. 
We visualize three scientific datasets before and after compression with {three of our augmented compressors} in \cref{fig:volume-render}. We also display the PSNR and compression ratio next to each decompressed dataset. 
Compression ratios and times for a single combination of $\varepsilon$ and $\xi$ are reported in \cref{tab:compression-task}. Charts showing the reconstruction quality on two datasets is reported in \cref{fig:reconstruction-quality}. Similar charts for the remaining datasets and compressors are shown in \cref{sec:reconstruction-quality-extra}. Results demonstrating the effect of independently varying $\varepsilon$ or $\xi$ on the evaluation metrics are given in \cref{sec:other-experiments}.

\subsubsection{Topological Guarantees}
When compressing a dataset with any base compressor, the contour tree of the data is often significantly distorted with a large number of false cases, whereas it is always perfectly preserved using our augmented compressor. This observation has been validated empirically in every trial: the contour tree is perfectly preserved in terms of the locations of its critical points and their connectivity.

For instance, we visualize the Isabel dataset in \cref{fig:teaser} using TTHRESH and augmented TTHRESH. We highlight parts of the contour trees via zoomed-in views before and after compression. In a bottom zoomed-in view, TTHRESH (middle) fails to preserve a few critical points of the contour tree. In a top zoomed-in view, TTHRESH (middle) preserves the locations of the critical points, but not their connectivity. In contrast, the augmented TTHRESH preserves both the locations and connectivity among the critical points.

We further provide zoomed-in views for the Ionization and SCALE-LETKF datasets in~\cref{fig:zoom}. We observe clearly that TTHRESH fails to predict many critical points, whereas augmented TTHRESH preserves them all.

In \cref{tab:base-false-cases}, we report the number of false cases, including both extremum-saddle and saddle-saddle connections in the contour tree reconstructed with ZFP and TTHRESH. We again use parameter configurations that produce the same compression ratios as their augmented versions with $\varepsilon = 0.04$ and $\xi = 0.012$ (for those configurations see \cref{sec:base-compressor-parameters}). In \cref{tab:base-false-cases}, we can see that ZFP and TTHRESH produce many false cases.

\begin{table}[!t]
\setlength{\tabcolsep}{2pt}
\resizebox{\columnwidth}{!}{
\begin{tabular}{cccccccc}
\hline
Dataset     & A-ZFP            & A-SZ3   & A-CSI         & A-TTHRESH      & \multicolumn{1}{c|}{A-Neurcomp} & TopoQZ             & TopoSZ          \\ \hline
\multicolumn{8}{c}{Compression Ratio}                                                                                                                \\ \hline
QMCPACK     & 58.7             & 86.1    & 102.3           & \textbf{104.8} & \multicolumn{1}{c|}{23.9}       & 23.4               & 27.8            \\
Tangaroa    & 37.3             & 43      & 33.5            & \textbf{44.8}  & \multicolumn{1}{c|}{15.3}       & --                 & 24.3            \\
Earthquake  & 86.1             & 127.4   & 79.4            & \textbf{129.2} & \multicolumn{1}{c|}{63.5}       & 13.4               & 50.1            \\
Ionization  & 118.8            & 121.5   & 119.9           & \textbf{170.5} & \multicolumn{1}{c|}{72.7}       & 30.0               & 25.1            \\
Isabel      & 47.4             & 103.5   & 70.6            & \textbf{182.2} & \multicolumn{1}{c|}{41.6}       & --                 & 37.6            \\
Miranda     & 172.3            & 198.6   & 157.2           & \textbf{318.7} & \multicolumn{1}{c|}{95.0}       & 76.5               & 95.9            \\
Nyx         & 65.3             & 69.5    & 70.4            & \textbf{84.5}  & \multicolumn{1}{c|}{18.9}       & --                 & --              \\
S3D         & 38.4             & 46.6    & 43.6            & \textbf{59.6}  & \multicolumn{1}{c|}{6.0}        & 9.2                & --              \\
SCALE-LETKF & 69.5             & 74.4    & 58.5            & \textbf{114.2} & \multicolumn{1}{c|}{8.6}        & 11.4               & --              \\ \hline
\multicolumn{6}{c|}{Total Compression and Augmentation Time}                                                  & \multicolumn{2}{c}{Compression Time} \\ \hline
QMCPACK     & 1.27             & 1.36    & 1.21            & 1.45           & \multicolumn{1}{c|}{172.08}     & \textbf{1.05}      & 10.46           \\
Tangaroa    & 9.51             & 10.99   & \textbf{9.33}   & 11.98          & \multicolumn{1}{c|}{1519.21}    & --                 & 314.56          \\
Earthquake  & \textbf{7.08}    & 7.39    & \textbf{7.08}   & 8.66           & \multicolumn{1}{c|}{1039.94}    & 8.08               & 48.17           \\
Ionization  & \textbf{8.68}    & 10.00   & 14.08           & 15.16          & \multicolumn{1}{c|}{1221.12}    & 10.40              & 425.31          \\
Isabel      & \textbf{33.77}   & 35.49   & 42.69           & 42.67          & \multicolumn{1}{c|}{7147.86}    & --                 & 367.10          \\
Miranda     & 223.52           & 284.18  & 248.51          & 348.72         & \multicolumn{1}{c|}{9359.59}    & \textbf{160.60}    & 434.98          \\
Nyx         & \textbf{1059.06} & 1137.33 & 5664.46         & 25594.54       & \multicolumn{1}{c|}{38959.73}   & --                 & --              \\
S3D         & 209.83           & 253.82  & \textbf{173.09} & 253.72         & \multicolumn{1}{c|}{34610.78}   & 633.13             & --              \\
SCALE-LETKF & \textbf{221.49}  & 399.32  & 343.58          & 371.19         & \multicolumn{1}{c|}{40887.62}   & 524.05             & --              \\ \hline
\multicolumn{8}{c}{Decompression Time}                                                                                                               \\ \hline
QMCPACK     & 0.14             & 0.32    & 0.14            & 0.17           & \multicolumn{1}{c|}{4.24}       & 0.63               & \textbf{0.01}   \\
Tangaroa    & 0.49             & 0.52    & 0.51            & 0.96           & \multicolumn{1}{c|}{16.32}      & --                 & \textbf{0.12}   \\
Earthquake  & 0.38             & 0.41    & 0.37            & 0.55           & \multicolumn{1}{c|}{8.50}       & 5.50               & \textbf{0.07}   \\
Ionization  & 0.48             & 0.54    & 0.54            & 0.83           & \multicolumn{1}{c|}{11.62}      & 5.08               & \textbf{0.10}   \\
Isabel      & 1.43             & 1.35    & 1.34            & 2.64           & \multicolumn{1}{c|}{79.61}      & --                 & \textbf{0.41}   \\
Miranda     & 2.92             & 3.1     & 3.38            & 4.53           & \multicolumn{1}{c|}{175.61}     & 53.2               & \textbf{0.67}   \\
Nyx         & \textbf{6.72}    & 8.05    & 9.71            & 9.49           & \multicolumn{1}{c|}{2457.91}    & --                 & --              \\
S3D         & \textbf{11.52}   & 11.47   & 11.84           & 16.33          & \multicolumn{1}{c|}{2135.47}    & 390.94             & --              \\
SCALE-LETKF & \textbf{11.59}   & 11.92   & 12.89           & 21.50          & \multicolumn{1}{c|}{2629.48}    & 351.61             & --              \\ \hline
\end{tabular}
}
\vspace{-2mm}
\caption{Compression ratio, compression time, and decompression time for each compressor with $\varepsilon = 0.04$ and error bound $\xi = 0.012$ (except TopoQZ has $e = \zeta = 0.006$).
Times are in seconds.
Trials that did not finish are marked with a dash. 
TopoQZ ran out of memory on Nyx and it crashed on Isabel and Tangaroa due to unknown reasons. 
TopoSZ ran out of memory on Nyx, S3D, and SCALE-LETKF. 
}
\label{tab:compression-task}

\includegraphics[width=\columnwidth]{fig-rate_distortion_2.png}
    \vspace{-4mm}
    \captionof{figure}{PSNR, bottleneck distance, and Wasserstein distance versus bit-rate for each compressor for the QMCPACK and Earthquake datasets with $\varepsilon = 0.04$ ($e = 0.04$ for TopoQZ). These curves are given for other datasets in \cref{sec:reconstruction-quality-extra}.}
    \label{fig:reconstruction-quality}
    \vspace{-4mm}
\end{table}

%---------------------------------------
\subsubsection{Evaluation Metrics}
\label{sec:augmented-compressors-evaluation-metrics}

Compression ratio and times are reported in \cref{tab:compression-task} for a fixed parameter configuration of $\varepsilon = 0.04$ and $\xi = 0.012$.
We chose this parameter configuration because a small amount of persistence simplification preserves a large number of topological features in the input data, generating complex test cases for topology-preserving compression. For the reconstruction quality demonstrated in \cref{fig:reconstruction-quality}, $\varepsilon = 0.04$ is chosen similarly, and $\xi$ is varied between $0.003$ and $0.018$ to yield a variety of different compression ratios while still remaining small.
In this section, we compare the different augmented compressors. We leave the comparison with TopoQZ and TopoSZ to \cref{sec:compare-topology}.

\para{Compression ratios.} 
As shown in \cref{tab:compression-task}, Augmented TTHRESH produces the best compression ratios in every trial. Augmented Neurcomp performs noticeably worse than the other compressors.

\para{Reconstruction quality.}
In every trial, our framework successfully maintains a pointwise error bound $\xi$. There is a natural trade off between compression ratio and reconstruction quality. As shown in \cref{fig:reconstruction-quality}, Augmented SZ3 and Augmented TTHRESH have the best trade off between bit-rate, PSNR, $d_W$ and $d_B$, and perform equally well. Augmented Neurcomp performs the worst based on above metrics.

When visualized, we find that the decompressed volumes generally resemble the ground truth. However, when using certain transfer functions, visual artifacts may become visible. Artifacts appear more in visualizations that are sensitive to small changes in the transfer function. For the volume renderings in this paper, we chose transfer functions that led to fewer visual artifacts; see~\cref{sec:visual-artifacts} for adversarial examples.

In practice, we find that upper and lower bound tightening does not affect PSNR very much; most of the reconstruction quality is determined by the initial upper and lower bounds. \cref{fig:errorMap} shows a map of the absolute error of each point for a topologically complex slice of the Ionization dataset before and after tightening. We can see that tightening does not have a significant effect on the average error.

\begin{figure}[!t]
    \begin{subfigure}[b]{0.06\linewidth}
        \raisebox{0.5\height}{\includegraphics[width=\linewidth]{fig-colorBar-error.png}}
    \end{subfigure}
    \hfill
    \begin{subfigure}[b]{0.46\linewidth}
    \centering
        \includegraphics[width=\linewidth]{fig-errorMapPre.png}
        (A)
    \end{subfigure}
    \hfill
    \begin{subfigure}[b]{0.46\linewidth}
    \centering
        \includegraphics[width=\linewidth]{fig-errorMapPost.png}
        (B)
    \end{subfigure}
    \vspace{-5mm}
    \caption{Error map of a topologically complex slice of the Ionization dataset (A) before error bound tightening and (B) after error bound tightening.}
    \label{fig:errorMap}
    \vspace{-8mm}
\end{figure}

\para{Run time analysis.} 
There are significant differences in run time among the augmented compressors.
As discussed in \cref{sec:run-time}, these times are affected by factors other than the base compression time. However, Augmented Neurcomp is the slowest because Neurcomp compresses data by training a neural network.  
Of the remaining four compressors, ZFP is typically the fastest, and TTHRESH the slowest, although this observation does not hold for all trials. For decompression time, ZFP is the fastest, while Neurcomp remains the slowest.

\para{Highlighted results.} 
There is no clear best augmented compressor that outperforms others across all metrics. Other than augmented Neurcomp, utilizing any augmented compressor plays a trade off between compression ability and speed. For the remainder of our analysis, we will primarily focus on Augmented ZFP, which is the fastest augmented compressor, and Augmented TTHRESH, which yields the best compression ratios and reconstruction quality.

%---------------------------------------
\subsection{Comparison with TopoQZ and TopoSZ}
\label{sec:compare-topology}

\para{Topological guarantees.}
Our framework preserves the contour tree during compression, and achieves the same topological guarantee as TopoSZ. TopoQZ ensures that all critical point pairs are preserved above a persistence threshold $\varepsilon$, but their locations and connectivity may be distorted after compression.

\para{Compression ratio.} 
In terms of compression ratio, when maintaining a strict topological constraint $\varepsilon = 0.04$ and error bound $\xi = 0.012$, every augmented compressor except Augmented Neurcomp outperforms both TopoQZ and TopoSZ in every trial.

\para{Reconstruction quality.} 
The curves in \cref{fig:reconstruction-quality} show that every augmented compressor except Augmented Neurcomp can match the PSNR of TopoQZ and TopoSZ,  while using less space. In terms of topological distance, the augmented compressors except Augmented Neurcomp outperform TopoSZ in terms of $d_W$ and $d_B$. They also outperform TopoQZ in terms of $d_B$, but are comparable in terms of $d_W$.

\para{Run time analysis.} 
In terms of compression time, the augmented compressors except Augmented Neurcomp produce times that are comparable to or better than TopoQZ, and significantly outperform TopoQZ on the largest datasets. 
These four augmented compressors are also significantly faster than TopoSZ across all trials. 

In terms of decompression time, the augmented compressors except Augmented Neurcomp perform slower than TopoSZ but faster than TopoQZ. There are several possible reasons why our decompression times are slower than TopoSZ. First and most notably, our decompression process is more complex, as it involves a decompression with the base compressor and then an augmentation of the decompressed results. This process requires more operations and has a higher I/O overhead. Second, we use XZ along with tar archives for lossless compression, which is slower than ZSTD used by TopoSZ. See \cref{sec:more-running-time} for a more detailed analysis of the decompression time.   

%---------------------------------------
\subsection{Analysis of Compression Time}
\label{sec:run-time}

\para{Asymptotic analysis.}
Let $n$ be the number of vertices in the rectilinear mesh. Our algorithm utilizes heap merges~\cite{gueunet2017task} during the merge tree computation; however, we use binary heaps (stored in arrays) instead of Fibonacci heaps from~\cite{gueunet2017task}. For a binary heap with $m$ elements, a single insertion operation has a worst-case time complexity of $O(\log m)$. 
Following~\cite{gueunet2017task}, from bottom to top, constructing an edge $e$ in a merge tree requires merging its heap with the heaps of its descendants, which takes $O(n \log n)$. Let $h$ denotes the \emph{height} of the tree, which corresponds to the maximum number of ancestor edges.
Then constructing a merge tree using these insertion-based heap merges takes $O(h n \log n)$. During the progressive tightening process, let $F$ denote the total number of detected false cases, each of which triggers a (partial) recomputation of the merge tree. Therefore, our algorithm takes $O(F h n \log n) = O(n^3 \log n)$. 

In practice, $F \ll n$ as shown in \cref{tab:time}. 
Additionally, $h \ll n$. We found that $\frac{h}{n}$ ranged from $0.0004$ (Miranda, A-ZFP) to $0.025$ (Nyx, A-Neurcomp). Excluding Augmented Neurcomp, $\frac{h}{n} < 0.01$ in $97\%$ of trials.  
On the other hand, using Fibonacci heaps to construct a merge tree~\cite{gueunet2017task} takes $O(n \log n)$ due to constant time heap merges; however, in our setting, we have found that binary heaps have lower run time in practice. Likewise, it is possible to merge heaps in linear time, but we instead merge by repeatedly inserting each element of the smaller heap into the larger one, as doing so has a much lower run time in practice.

\para{Empirical analysis.} To analyze the run time empirically, we calculate the amount of time for each portion of our algorithm with Augmented ZFP and Augmented TTHRESH,  with $\varepsilon = 0.04$ and $\xi = 0.012$. These run times are shown in \cref{tab:time}.

In \cref{tab:time}, the most time-consuming task is the computation of merge and contour trees. We compute the contour tree of the input data at the beginning of the algorithm. During the error bound tightening steps we also compute the contour tree of the decompressed data. These run times are shown in \cref{tab:time} under the `CT' and `Grow' columns, and account for $35-77\%$ of the total run time for each trial in \cref{tab:time}. 

For most of the trials, the time to run the base compressor, shown in the `BC' column, is a relatively small percentage of the overall compression time. 
However, if a base compressor produces results that nearly preserve the contour tree and does not produce too many extra branches, including those of persistence below $\varepsilon$, the augmentation time may be lower. This phenomenon suggests that the accuracy of the base compressor may have more effect on the total compression and augmentation time than just base compression.
In general, the run time of each base compressor is much faster than its augmented counterpart; see~\cref{sec:more-running-time} for a comparison. 

\begin{table}[!ht]
\setlength{\tabcolsep}{2pt}
\centering
\vspace{-2mm}
\resizebox{\columnwidth}{!}{
\begin{tabular}{cccccccccc}
\hline
\multicolumn{1}{c|}{Dataset}     & BC    & CT     & ULB     & Grow     & \%B    & \#FC & Fix      & File  & Total    \\ \hline
\multicolumn{10}{c}{Augmented ZFP}                                                                                  \\ \hline
\multicolumn{1}{c|}{QMCPack}     & 0.15  & 0.34   & 0.21   & 0.38     & 0.17\% & 0    & 0.0      & 0.27  & 1.35     \\
\multicolumn{1}{c|}{Tangaroa}    & 1.42  & 2.16   & 2.80   & 1.34     & 0.43\% & 14   & 0.0004   & 1.84  & 9.57     \\
\multicolumn{1}{c|}{Earthquake}  & 0.45  & 1.56   & 1.26   & 2.88     & 0.79\% & 2    & 0.0001   & 0.97  & 7.12     \\
\multicolumn{1}{c|}{Ionization}  & 0.70  & 1.56   & 2.09   & 3.10     & 1.15\% & 10   & 0.0009   & 1.35  & 8.81     \\
\multicolumn{1}{c|}{Isabel}      & 4.73  & 4.61   & 8.95   & 9.48     & 0.54\% & 1    & 0.0647   & 6.17  & 34.01    \\
\multicolumn{1}{c|}{Miranda}     & 4.00  & 156.79 & 17.92  & 37.85    & 1.21\% & 0    & 0.0      & 7.02  & 223.58   \\
\multicolumn{1}{c|}{NYX}         & 24.75 & 695.26 & 150.27 & 142.16   & 0.47\% & 6    & 4.60     & 42.21 & 1084.05  \\
\multicolumn{1}{c|}{S3D}         & 14.2  & 27.93  & 69.11  & 56.40    & 1.04\% & 39   & 0.01411  & 38.44 & 206.63   \\
\multicolumn{1}{c|}{SCALE-LETKF} & 15.2  & 16.15  & 61.67  & 92.99    & 0.63\% & 37   & 0.003408 & 35.34 & 221.47   \\ \hline
\multicolumn{10}{c}{Augmented TTHRESH}                                                                              \\ \hline
\multicolumn{1}{c|}{QMCPack}     & 0.23  & 0.34   & 0.21   & 0.45     & 0.77\% & 0    & 0.0      & 0.22  & 1.45     \\
\multicolumn{1}{c|}{Tangaroa}    & 3.34  & 2.2    & 2.79   & 1.92     & 0.77\% & 18   & 0.0001   & 1.59  & 11.84    \\
\multicolumn{1}{c|}{Earthquake}  & 1.53  & 1.56   & 1.25   & 3.33     & 0.65\% & 4    & 0.0001   & 0.91  & 8.58     \\
\multicolumn{1}{c|}{Ionization}  & 1.93  & 1.54   & 2.08   & 8.09     & 1.48\% & 5    & 0.0120   & 1.24  & 14.94    \\
\multicolumn{1}{c|}{Isabel}      & 13.13 & 4.62   & 9.01   & 10.24    & 0.54\% & 1    & 0.0666   & 5.62  & 42.69    \\
\multicolumn{1}{c|}{Miranda}     & 12.73 & 156.48 & 17.73  & 153.69   & 2.33\% & 0    & 0.0      & 7.24  & 347.87   \\
\multicolumn{1}{c|}{NYX}         & 57.87 & 687.03 & 132.49 & 15838.88 & 0.82\% & 89   & 97.82    & 37.52 & 27286.05 \\
\multicolumn{1}{c|}{S3D}         & 66.35 & 27.89  & 67.27  & 56.51    & 1.14\% & 47   & 0.0136   & 32.11 & 250.79   \\
\multicolumn{1}{c|}{SCALE-LETKF} & 69.21 & 16.10  & 60.00  & 193.18   & 0.54\% & 46   & 0.0032   & 29.71 & 368.35   \\ \hline
\end{tabular}
}
\vspace{-2mm}
\caption{Runtime analysis for each component of the augmented framework involving Augmented ZFP and Augmented TTHRESH with $\varepsilon = 0.04$ and $\xi = 0.012$. 
All times are in seconds. 
BC: running the base compressor.
CT: computing the contour tree of the input data.
ULB: calculating the initial upper and lower bounds. 
Grow: time growing the contour tree of the reconstructed data.
\%B: percent of branches in the reconstructed contour tree whose growth was recomputed.
\#FC: number of false cases corrected after upper and lower bounds are set.
Fix: average time to fix a false case, excluding regrowing branches.
File: average time to write the compressed output to a file.}
\label{tab:time}
\vspace{-6mm}
\end{table}