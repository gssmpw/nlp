\section{Causal Effect Learning} \label{sec:CEL}
This section aims to provide a detailed introduction to causal effect learning. We categorize \acrshort{CEL} into three groups based on the underlying causal structure: \acrshort{CEL} with 1) i.i.d. data \citep{kunzel2019metalearners,athey2019generalized}, 2) Markov transition state \citep{liu2018breaking,jiang2016doubly,kallus2022efficiently}, and 3) panel data \citep{viviano2022synthetic,lechner2011estimation}. 
Our aim is to provide a systematic review of estimation techniques for the average treatment effect, the heterogeneous treatment effect, and the mediation effect under the above three scenarios.

In the context of \acrshort{CEL}, we aim to answer the following question:
\begin{center}
    \textit{What is the causal effect of some intervention/treatment/policy? \\If it's well-defined, then how can we quantify it stably and efficiently?}
\end{center}
This question mainly concludes the three main tasks in the realm of \acrshort{CEL}: identification, estimation, and inference. 

Let's take \acrshort{MIMIC-III} data as an example. Once the causal structure of the data (including all potential confounders and mediators) has been determined, the next step is to quantify the effect of intravenous input on the mortality status of patients. This problem involves identifying under reasonable assumptions (such as no latent confounders), estimating the average effect of IV input across all patients, estimating personalized treatment effects on mortality status, and ultimately finding the optimal policy to tailor individualized medical treatments to minimize the overall mortality rate.

Among these four tasks, we are interested in different causal estimands: \acrfull{ATE}, \acrfull{HTE}, and mediation effect. In the next subsections, we will mix the four main tasks and three main estimands together to conduct a comprehensive review according to the data structure of different paradigms.

\subsection{Why Causal Effect Learning is Needed for Causal Decision Making}

\acrshort{CEL} aims to accurately quantify the causal effect of some intervention/policy on a group of units. As an intermediate stage of causal decision-making, \acrshort{CEL} plays an important role in conducting primary analysis on a given causal diagram, as well as providing necessary information for post-stage policy learning and decision-making. The internal connections are multi-fold and detailed below.


\begin{comment}
\textbf{\acrshort{CEL} offers increased flexibility in modeling given a causal structure.} When expert knowledge is not enough to establish a definitive causal diagram, \acrshort{CSL} becomes attractive in being able to combine causal discovery and causal effect estimation under the identified causal structure \citep{cai2020anoce}. While it is powerful to kill two birds with one stone, this approach may be constrained by model assumptions, such as those inherent in a linear structural equation model. Conversely, when a causal diagram is already known, either derived from data or expert knowledge, \acrshort{CEL} becomes more adaptable in handling estimation and inference under both causal structure modeling and potential outcome framework. For example, existing work in \acrshort{ATE},  \acrshort{HTE} and mediation effect estimation span both parametric and semi-parametric settings \citep{chernozhukov2018double,kunzel2019metalearners}, with versatile extensions capable of handling assumption violations like unmeasured confounders \citep{wang2018bounded}, interference \citep{savje2021average}, and more. This renders \acrshort{CEL} a more comprehensive and versatile way of evaluating the causal effects of interest.


\textbf{As a downstream task of CSL,  \acrshort{CEL} exhibits adaptability to more general data structures.} Existing work in \acrshort{CEL} encompasses diverse data structures, including but not limited to single-stage, multi-stage dynamic treatment regimes, and infinite-horizon Markov decision processes. Depending on intervention strategies (i.e. experimental design or observational study), an extensive body of literature exists, offering methodologies for handling \acrshort{ATE} \citep{zhang2013robust, chernozhukov2018double},  \acrshort{HTE} \citep{kunzel2019metalearners, nie2021quasi, kennedy2020optimal, van2006statistical, lee2017doubly, athey2019generalized, shi2019adapting}, and mediation effect estimations \citep{hicks2011causal, hong2010ratio, imai2010general, pearl2022direct, tchetgen2012semiparametric}. 

\end{comment}
First, \acrshort{CEL} provides \textit{primary insights} for decision making.
To answer the question of  ``which policy yields the highest reward or desired outcome within a given population'', a fundamental prerequisite is comprehending how a given policy impacts distinct units within that population in a heterogeneous manner. This challenge, often encapsulated in the estimation of \acrshort{HTE}, aligns with the domain of \acrshort{CEL} perfectly.  %In fact, \acrshort{CEL} is not only a primary requis
In experimental design, A/B testing is a widely used method in industry to measure the effectiveness of changes or interventions. In observational studies, \acrshort{HTE} estimation (such as $\tau(s) = \mathbb{E}[R(1)- R(0)\mid S = s]$ in a binary action space) can be directly applied to decision-making by selecting the action $\boldsymbol{1}\{\tau(s) > 0\}$. In general, \acrshort{CEL} with observational data provides valuable insights into the effectiveness of specific treatments in a more cost-efficient manner.


Second, \acrshort{CEL} offers \textit{a systematic identification framework} that supports the \textit{validity} of decision-making.
Firstly, while not always stated explicitly, most decision-making methods in \acrshort{RL} rely on certain causal assumptions, such as \acrshort{SUTVA} and \acrshort{NUC}, as outlined in Section \ref{sec:prelim_assump}. These assumptions, though sometimes restrictive, ensure the identifiability of specific value functions, which is essential for conducting valid policy learning. Secondly, in more complex scenarios with interference issues \citep{savje2021average} or unmeasured confounders \citep{wang2018bounded}, \acrshort{CEL} incorporates techniques like instrumental variables or specifying interference structures (see Section \ref{sec:assump_violated}), supporting reliable decision-making based on effect estimates. For example, when assessing whether smoking increases the risk of lung cancer, genetic predisposition serves as a confounder, as it may causally influence both the likelihood of smoking and the risk of developing lung cancer. Properly accounting for this unseen factor is essential to avoid misleading conclusions.
In summary, \acrshort{CEL} acts as a ``safeguard'', formalizing the identification framework to ensure that effect learning remains estimable and that subsequent decision-making is valid.

Third, \acrshort{CEL} \textit{filters out ineffective treatment options with confidence} for better decision making.
Beyond providing value estimates, \acrshort{CEL} also serves as a platform for statistical inference based on the causal effects of interest \citep{mealli2011statistical,benkeser2017doubly,athey2018approximate,xu2022quantile}. For example, consider a decision-making problem in recommending personalized treatments for patients in a clinical trial. While point estimates of the value function for different treatment options reflect the expected outcomes, accurate statistical inference that often bounded within \acrshort{CEL} framework goes further by quantifying uncertainty, which further helps determine the necessity of quasi-control treatment options and simplifies the decision-making process with greater confidence.

\begin{comment}
In both industry and research, (heterogeneous) causal effect estimation is often viewed as central to decision-making, and in some cases, the two are treated as synonymous. This perspective is widely applied in various contexts, such as determining the optimal discount policy in online retail \citep{miller2020personalized}, maximizing social welfare through treatment assignment under budget constraints \citep{bhattacharya2012inferring}, and optimizing financial service strategies via uplift modeling \citep{kane2014mining}. However, recent work has increasingly recognized that causal effect estimation and decision-making are not the same \citep{fernandez2022causal}. The assumption that they are equivalent only holds in simplified scenarios where specific conditions on causality and action assignments are met. Relying solely on causal effect estimation for decision-making can lead to biased action selection in the presence of unmeasured confounders. Moreover, this approach may hinder effective decision-making by introducing unnecessary complexity, particularly in sequential decision-making settings, where direct action learning may be more efficient than estimating intermediate effects. Therefore, it is important to critically assess the role of effect learning within a more integrated framework to guide more informed and accurate decision-making.
\end{comment}
%CEL: (1) more flexible on assumptions (2) allow more paradigms 

%downstream task of CSL

%CEL: a special case of CPL


\subsection{\acrshort{CEL} in Single Stage (Paradigm 1)}\label{sec:CEL_p1}

\begin{comment}
%refer to the paper - a survey on causal inference

\begin{itemize}
    \item \acrshort{ATE}: three \acrshort{ATE} estimation methods 
    \item \acrshort{ATE}: stratification \& matching to adjust for covariates imbalance
    \item \acrshort{HTE}: our current reviewed methods are enough
    \item representation learning methods?
    \item multi-task learning methods?
\end{itemize}
\end{comment}

Over the past decades, there has been extensive study on conducting causal inference in the classical single-stage setup. Next, we will detail some representative approaches according to the specific tasks they are dealing with: i) \acrshort{ATE}, ii) \acrshort{HTE}, and iii) mediation effect.

\subsubsection{\acrshort{ATE}}

Based on the ``big three assumptions’’ of causal inference (see Assumption \ref{assump:SUTVA}-\ref{assump:Positivity} in Section \ref{sec:prelim_assump}), there are representative \acrshort{ATE} estimation methods in literature, commonly referred to as the \acrfull{DM}, \acrfull{IPW} estimator, and \acrfull{DR} estimator. As we move to later chapters, we will see that the concept of DR estimation is widely applied in various effect estimations, including \acrshort{HTE} and mediation analysis, across both single-stage and infinite-horizon frameworks.

The intricacy of causal inference manifests prominently in the challenge of counterfactual estimation. It is inherently impossible to directly observe the outcomes users would obtain had they chosen differently at the time of treatment assignment. However, failing to observe counterfactuals doesn’t mean that we cannot estimate/infer interested quantities under some reasonable assumptions, which are detailed in Section \ref{sec:prelim_assump}. When \acrshort{SUTVA}, \acrshort{NUC}, and Positivity assumptions hold, the potential outcomes can be rewritten as $\mathbb{E}[R(a)|\boldsymbol{S}=\boldsymbol{s}] = \mathbb{E}[R|\boldsymbol{S}=\boldsymbol{s}, A=a]$, where the right-hand side is entirely estimable from observational data. Therefore, the most intuitive way is to estimate the counterfactual part via a regression model. This yields the first estimator, known as the direct method, as outlined below:
\begin{equation} \label{eq:CEL_p1_DM}
\begin{aligned} \widehat{\text{ATE}}_{\text{DM}} = \frac{1}{n}\sum_{i=1}^n \{\hat{\mu}(\boldsymbol{S_i}, 1) - \hat{\mu}(\boldsymbol{S_i}, 0)\} ,
\end{aligned}
\end{equation}
where $\hat{\mu}(\boldsymbol{s},a)$ is the estimated outcome regression model for $\mathbb{E}[R|\boldsymbol{S}=\boldsymbol{s}, A=a]$.

The second type of estimator is called the \acrfull{IPW} estimator, or \acrfull{IS} estimator in \acrshort{RL} literature. Define propensity score $\mathbb{P}(A=1|\boldsymbol{S})$ as the probability of receivting treatmente $A=1$. \acrshort{IPW} estimator uses propensity scores to reweight observations, balancing the distribution of covariates between the treated and control groups by mimicing a randomized experiment.
\begin{equation} \label{eq:CEL_p1_IS}
\begin{aligned} 
\widehat{\text{ATE}}_{\text{IS}} =\frac{1}{n}\sum_{i=1}^n \left\{\frac{A_iR_i}{\hat\pi(\boldsymbol{S_i})} - \frac{(1-A_i)R_i}{1-\hat\pi(\boldsymbol{S_i})} \right\}. 
\end{aligned} 
\end{equation}

By combining both estimators, the DR estimator (or augmented \acrshort{IPW}, i.e. \acrshort{AIPW}) is consistent as long as either the outcome regression model or the propensity score model is correctly specified. 
\begin{equation} \label{eq:CEL_p1_DR}
\begin{aligned} 
\widehat{\text{ATE}}_{\text{DR}} = \frac{1}{n}\sum_{i=1}^n \left\{\hat{\mu}(\boldsymbol{S_i},1)- \hat{\mu}(\boldsymbol{S_i},0)+\frac{A_i(R_i - \hat{\mu}(\boldsymbol{S_i},1))}{\hat{\pi}(\boldsymbol{S_i})} - \frac{(1-A_i)(R_i-\hat{\mu}(\boldsymbol{S_i},0))}{1-\hat{\pi}(\boldsymbol{S_i})} \right\}. 
\end{aligned} 
\end{equation}

Under certain mild entropy conditions or through sample splitting, the DR estimator is also a semi-parametrically efficient estimator when the convergence rate of both $\hat{\mu}$ and $\hat{\pi}$ are at least $o(n^{-1/4})$. The innovative approach of incorporating sample splitting into treatment effect estimation was conceptually formalized in Double Machine Learning (DML) by \citet{chernozhukov2018double}.

Although the \acrshort{AIPW} estimator guarantees double robustness, it may still result in a poor estimator when both the propensity score and outcome regression models are not correctly specified. In addressing this challenge, an alternative line of research has emerged, focusing on reducing estimation bias via the optimization of model parameters \citep{vermeulen2016data, yang2020doubly}. Additionally, to address estimates that fall outside the admissible parameter range (e.g., a mortality rate outside $[0,1]$), \acrfull{TMLE} \citep{gruber2010targeted, gruber2012tmle} was developed to incrementally adjust the estimator while maintaining the double robustness of \acrshort{AIPW} method.

\begin{comment}
Another concern associated with the classical AIPW estimator is the potential for estimates to fall outside the admissible parameter range. For example, in MIMIC3 data where the outcome of interest is the mortality rate of patients, we may yield a completely impractical estimator where the estimated death rate exceeds $1$ or falls below $0$ if the data is substantially noisy or the model fitting process doesn't perform well. 


Targeted Maximum Likelihood Estimation \citep{gruber2010targeted, gruber2012tmle}, or TMLE,  was designed to handle this problem. Starting from an initial estimator, TMLE aims to gradually adjust it by fitting it to the data where it matters most for the target estimand. As a special kind of AIPW estimator, TMLE not only inherits the advantageous properties of double robustness and semi-parametric efficiency in large-sample performance but also demonstrates compelling finite-sample performance. TMLE typically adheres to the parameter range of the estimand, ensuring practicality in its outcomes. Additionally, it also partly improves the estimation stability against near violation of the positivity assumption.
\end{comment}
Under the ideal scenario where the treatment and control groups share similar covariates distributions, the aforementioned estimators are expected to perform well. However, when there is strong selection bias, matching techniques \citep{heckman1998matching, abadie2006large, abadie2008failure, abadie2011bias, caliendo2008some} offer a valuable avenue to improve the performance of the estimation. As the gold standard of causal inference, randomized experiments impose fewer assumptions for identification and estimation. Therefore, the fundamental idea of matching is a way to find the closest ``randomized experiment'' hidden inside the observational study, so as to adjust for covariate imbalances between groups. Under a certain distance metric, one of the most intuitive ways is to select the top $k$ nearest neighbors for each unit, and conduct an average to estimate the corresponding counterfactuals \citep{abadie2008failure}. 

However, in scenarios with a relatively large number of covariates, traditional distance metrics for neighbor selection may encounter challenges due to the curse of dimensionality. To address this, propensity score \citep{rosenbaum1983central, austin2008critical, abadie2016matching} and prognostic score \citep{hansen2008prognostic} are commonly used as two representative balancing scores to conduct dimensionality reduction when adjusting for covariate imbalance. Later on, \acrfull{DS} matching \citep{leacy2014joint, antonelli2018doubly, yang2023multiply} was proposed to jointly combine the above two scores, which further improves the matching performance. This method is double robust in the sense that the DS matching estimator remains consistent for \acrshort{ATE} if either the propensity score or the prognostic score is correctly specified. %In practical applications, a selection of well-constructed working models with carefully chosen covariates for matching often yields highly satisfactory results. 
For further practical insights into matching methodologies, refer to \cite{zhang2022practical}.

Overall, the methods of \acrshort{ATE} estimation have been thoroughly studied in literature over the past decades. For other related review papers, we refer to \citet{yao2021survey} under potential outcome's framework and \citet{pearl2009causal} under \acrshort{SCM}. In most decision-making contexts involving a specific population, \acrshort{ATE} estimation plays a crucial role in quantifying the overall impact of different decision rules. This is applied across various domains, including, but not limited to, assessing the effectiveness of advertising campaigns \citep{farahat2012effective}, labor market interventions in public policy \citep{dehejia1999causal}, and epidemiology \citep{hernan2006estimating}. In summary, \acrshort{ATE} estimation serves as a fundamental tool for determining the population or sub-population level effects of different treatments.

\subsubsection{\acrshort{HTE}}\label{sec:CEL_HTE_p1}

In real applications, our focus usually extends beyond the average treatment effect from the population level; rather, the estimation of personalized treatment effects for individuals or within specific subgroups often intrigues our interests. In \acrshort{MIMIC-III} data, our ultimate goal is to figure out the optimal IV input strategy for patients, which often starts with understanding the personalized treatment effect from an individual level. 


Existing work in single-stage \acrshort{HTE} estimation starts from meta-learners \citep{kunzel2019metalearners} and subsequently extends to more comprehensive approaches, which either demonstrate improved theoretical properties in statistical inference \citep{kennedy2020optimal} or exhibit enhanced performance in specific settings \citep{nie2021quasi, shi2019adapting}. We will detail some representative methods below.

The first type of learners are meta-learners, which consist of S-learner, T-learner, and X-learner. Under the \acrshort{SUTVA}, \acrshort{NUC}, and positivity assumptions, we have 
\begin{equation*}
    \tau(\boldsymbol{s}) = \mathbb{E}[R(1) - R(0)|\boldsymbol{S}=\boldsymbol{s}] = \mathbb{E}[R|\boldsymbol{S} = \boldsymbol{s}, A=1] - \mathbb{E}[R|\boldsymbol{S} = \boldsymbol{s}, A=0].
\end{equation*}
If we estimate $\mathbb{E}[R|\boldsymbol{S}=\boldsymbol{s}, A=1]$ and $\mathbb{E}[R|\boldsymbol{S}=\boldsymbol{s}, A=0]$ together by fitting $R\sim (\boldsymbol{S},A)$, we obtain what is known as the S-learner. Conversely, if we divide the data into treated and control groups, and fit $\mathbb{E}[R|\boldsymbol{S} = \boldsymbol{s}, A=1]$ and $\mathbb{E}[R|\boldsymbol{S} = \boldsymbol{s}, A=0]$ separately with two independent models, this gives rise to the T-learner. While both learners are straightforward to implement, S-learner tends to exhibit slightly better performance when the treated group and control group share a similar reward structure. Conversely, T-learner may be preferable due to its ability to differentiate action $A$ from all other covariates $X$ in reward modeling. This distinction prevents the risk of neglecting the ``action" among other covariates, which could occur with S-learner. Based on the two base learners, X-learner was proposed by \citet{kunzel2019metalearners}, which shows more favorable performance especially when dealing with sample size imbalance between treatment and control group, or when the separate parts of the X-learner can exploit the structural properties (such as smoothness or sparsity) of the reward and treatment effect functions.

Later on, several additional learners were proposed, including R-learner \citep{nie2021quasi}, DR-learner, and Lp-R-learner \citep{kennedy2020towards}, all following a two-step approach and demonstrating promising theoretical results.  The concept of R-learner originated from \citet{robinson1988root} in 1988 and was formalized by \citet{nie2021quasi} in 2021. R-learner, which stands for ``residual'' learner, is a two-step methodology that involves regressing reward residuals on propensity score residuals, which is able to adapt to various modeling needs and ensure a quasi-oracle property with penalized kernel regression. DR-learner, introduced by \citet{kennedy2020towards}, integrates insights from the \acrshort{DR} estimator to construct an \acrshort{HTE} estimator at the first stage, followed by regression on pseudo outcomes to obtain the final learner. In the same paper, the Lp-R-learner combines residual regression with local polynomial adaptation, employing cross-fitting to relax conditions for achieving the oracle convergence rate. Despite providing promising theoretical results, this algorithm may incur computational intensity when applying local polynomial regressions to a large degree.

Recently, a new stream of work incorporates neural networks in \acrshort{HTE} estimation to provide potentially more flexible modeling choices. The majority of existing work shares a similar two-step pattern in \acrshort{HTE} estimation: In Step 1, the nuisance functions (including propensity score and outcome models) are fitted via some NN-based methods; In Step 2, fitted nuisance functions are combined to estimate the  \acrshort{HTE} via some downstream estimating equation (e.g., plug-in estimator, IPW estimator, or \acrshort{DR} estimator). Notably,  \citet{shi2019adapting} proposed a novel neural network architecture based on the sufficiency of the propensity score for causal estimation in Step 1, and a regularization procedure in Step 2 to optimize nonparametric performance. Similar neural network-based approaches are explored in related works such as \citet{johansson2016learning, shalit2017estimating, hassanpour2019learning}. For a comprehensive review and comparison of these different approaches, we refer to \citet{curth2021nonparametric} for a more detailed review.

In many application scenarios, effect learning is often a crucial pre-step before making decisions. The relationship between \acrshort{HTE} and decision-making can be as simple as $\boldsymbol{1}\{\tau(\boldsymbol{s}) > 0\}$, or it can be adapted to more realistic concerns such as resource or budget constraints. For example, decisions can be made by selecting treatments for patients whose predicted treatment effect exceeds a decision threshold \citep{dorresteijn2011estimating} in clinical trials. Alternatively, decision-making may involve a more complex function of \acrshort{HTE}, incorporating factors such as costs and pricing associated with actions \citep{miller2020personalized}, or serve as an intermediate step feeding into downstream optimization tasks under resource constraints \citep{qiu2022individualized}. The flexibility of the \acrshort{HTE} methods introduced above allows decision-makers to select the most appropriate approach based on their specific needs.


\subsubsection{Mediation Effect}\label{sec:sel_med}

Mediators are variables that are causally affected by action $A$ and, in turn, influence the reward modeling of $R$. They create an additional causal pathway from action to reward, which is often considered when analyzing complex causal relationships. In Section \ref{sec:med_dag}, we discussed several key methods in \acrshort{CSL} for identifying mediators in causal graphs, with particular attention to recent advances in score-based approaches \citep{cai2020anoce} that address mediator identification and effect learning simultaneously. While it is great to kill two birds with one stone, this type of approach may suffer from potential limitations in modeling such as linearity. 

In this section, we shift our focus to \acrshort{CEL}, specifically in the context of single mediator when the causal structure is already known. Mediation effect estimation approaches can be roughly divided into three categories: (1) classical approaches based on parametric modeling, (2) non-parametric and semi-parametric causal mediation analysis, and (3) later extensions. Compared to the methods discussed in Section \ref{sec:med_dag}, the more recent techniques emphasize flexible modeling, which can be particularly advantageous when focusing solely on effect learning with a known mediation structure.

Causal mediation analysis is well-developed in single-stage settings. Recently, there has been a growing body of work focused on extending these approaches to \acrshort{MDP}s and other data structures, such as \acrshort{DTR}. Here, we will briefly summarize the main approaches in paradigm 1 and refer to some review papers for further reading.



We will start by introducing the classical approaches \citep{mackinnon2007mediation}. In the presence of a mediator $M$, the causal relationship between action $A$ and reward $R$ is illustrated in Figure \ref{fig:mediation_1}. Classical approaches focus on decomposing the strength of the causal paths using three parametric models:
\begin{equation}\label{eq:mediation_2}
    \begin{aligned}
        R &= \beta_1 + cA + \epsilon_1\\
        R & = \beta_2 + c'A + bM +\epsilon_2\\
        M & = \beta_3 + aA +\epsilon_3,
    \end{aligned}
\end{equation}
where the coefficients $(a,b,c,c')$ correspond to the strength of the causal relationships depicted in Figure \ref{fig:mediation_1}. There are three main approaches based on these equations, which are (i) causal steps \citep{baron1986moderator}, (ii) difference in coefficients \citep{mackinnon1993estimating}, and (iii) product of coefficients \citep{alwin1975decomposition}. The causal step approach is a four-step regression-based procedure to decompose the significance and strength of different paths in Figure \ref{fig:mediation_1}. The difference in coefficients approach approximates the mediated effect by calculating $\hat{c}-\hat{c}'$, while the product of the coefficients approach estimates the mediated effect by $\hat{a}\hat{b}$. The last two estimators are equivalent when modeling with linear regression. All three approaches are widely used in practical applications due to their simplicity and interpretability. Later on, there are some follow-up reviews under the \acrfull{LSEM} \citep{hayes2017introduction,bollen1987total,imai2010identification,mackinnon2002comparison,pearl2022direct} that allows to measure the causal relationships between multiple variables in a more flexible way. However, these approaches also may suffer from the drawbacks of parametric assumptions such as linearity.

\begin{figure}[tbh]
    \centering
    \includegraphics[width = 0.75\linewidth]{Figure/mediation_effect.jpg}
    \caption{Mediation effect}
    \label{fig:mediation_1}
\end{figure}


The second type of estimator is based on more recent studies on causal mediation analysis under the potential outcomes framework \citep{imai2010general}. In recent years, extensive work has focused on non-parametric identification and non(semi)-parametric estimation and inference of mediated direct and indirect effects \citep{tchetgen2012semiparametric}. Similar to \acrshort{ATE} estimation, researchers have proposed corresponding versions of \acrshort{DM} \cite{imai2010general}, \acrshort{IPW} \citep{hong2010ratio}, and \acrshort{DR} \citep{tchetgen2012semiparametric} estimators for estimating direct and indirect effects in mediation analysis. Notably, the \acrshort{DR} mediation effect estimands proposed by \citet{tchetgen2012semiparametric} achieve semi-parametric efficiency.


%In the presence of a mediator $M$, the potential outcome depends not only on the action but also on $M$. Traditional mediation analysis IN literature measures different causal paths using a series of linear models, with coefficients representing the causal strength of each path. This approach helps explain the natural direct and indirect effects \cite{baron1986moderator, mackinnon2012introduction}. Although simple to implement, this type of approach can be restrictive due to parametric assumptions. To extend Average Treatment Effect (ATE) analysis to causal structures, 

%Principal Stratification (PS) \cite{frangakis2002principal,rubin2004direct,vanderweele2008simple,gallop2009mediation}. 

The third stream of work focuses on extending certain NUC assumptions or modeling requirements. For instance, some studies handle binary mediators using principal stratification \citep{rubin2004direct, vanderweele2008simple, gallop2009mediation}. Others relax the linear assumptions in LSEM by employing alternative regression models \cite{mackinnon2007intermediate} or by incorporating exposure-by-covariate and mediator-by-covariate interactions \citep{hayes2017introduction}. Additionally, some work allows for the presence of specific types of confounders \citep{vanderweele2009conceptual, vanderweele2015explanation}. Recently, there has been some work to handle mediation effect estimation in reinforcement learning (paradigm 2) \citep{ge2023reinforcement} and dynamic treatment regimes (paradigm 3) \citep{selig2009mediation, zheng2017longitudinal, roth2013mediation}. These approaches are gaining increasing attention for their flexibility in handling various multi-stage decision-making scenarios. For more detailed discussions on specific modeling and assumptions, please refer to these review papers \citep{hayes2017introduction, ten2012review, rijnhart2021mediation, preacher2015advances}.

\subsection{\acrshort{CEL} under \acrshort{MDP} (Paradigm 2)}
In some real cases, researchers may encounter longitudinal data with long horizons or even infinite horizons. For example, in clinical trials, the doctor will periodically check the health status of patients to provide them with personalized treatment each time they visit. Under this scenario, we aim to estimate the long-term causal effect of taking a specific treatment across all stages. 
Under the Markovian assumption, this problem is referred to as causal effect estimation within an \acrshort{MDP} framework, as detailed in Definition \ref{def:MDP}. 

Unlike the single-stage setting where much work focuses on estimating the difference in potential outcomes under $A = 1$ and $A=0$, the definition of causal effect becomes more general in multi-stage settings after introducing the concept of \textit{policy}. As defined in Definition \ref{def:policy}, a policy $\pi: \mathcal{S}\rightarrow \mathcal{A}$ is a mapping from state to action space that quantifies the treatment assignment strategy for different actions in $\mathcal{A}$. 
The causal effect estimation problem is thus generalized to estimating the state-value function $V^{\pi}(s) = \sum_{t'=t}^T \mathbb{E}^{\pi}[\gamma^{t-t'}R_{t'}|S_t = s]$, a discounted cumulative reward aggregated under policy $\pi$. Following similar logic in single stage, we can still define  \acrshort{HTE} and \acrshort{ATE} under \acrshort{MDP} or any other multi-stage settings as the difference in the value function under two policies ($\pi$ and $\pi_0$), i.e.,
\begin{equation*}
    \text{HTE}(s) = V^{\pi}(s) -  V^{\pi_0}(s), \;\;\; \text{and} \;\;\;
    \text{ATE} =\mathbb{E}_{s\sim \mathcal{S}}\Big[ V^{\pi}(s) -  V^{\pi_0}(s) \Big].
\end{equation*}


While we can naively estimate the quantities using techniques in single-stage \acrshort{CEL} by regarding $\pi$ and $\pi_0$ as two treatments, this approach overlooks the unique Markovian structure in state transitions, resulting in less efficient estimates.
Instead, by leveraging the sequential decision-making structure and the Markovian assumptions, we can derive estimators that converge much faster. 

By involving the definition of \textit{policy}, the problem of \acrshort{HTE} and \acrshort{ATE} estimation can be regarded as a direct byproduct of conducting policy evaluation on the value function $V^{\pi}(s)$ \citep{tang2022reinforcement,shi2023dynamic}.
In the RL literature, this is widely known as \acrfull{OPE}. As this part highly overlaps with \acrshort{CPL} in paradigm 2, we will leave the main discussion to Section \ref{sec:OPE}.

\subsection{\acrshort{CEL} in Panel Data (Paradigm 1)}\label{sec:CEL_p3}
Panel data analysis examines data collected over time from the same individuals, companies, or entities (known as \textit{panels}), often under varying treatment conditions. This approach is commonly used by governments and organizations to assess the long-term effects of policies on outcomes such as income, health, and education. By leveraging longitudinal data, panel analysis supports informed decision-making and provides valuable insights into the lasting impacts of policy interventions. The traditional literature in panel data analysis primarily focuses on estimating the \acrfull{ATT}, defined as the expected difference in outcomes between treated and control units:
\begin{equation}
\mathbb{E}[R_{i,t}(1)-R_{i,t}(0)|G_i =1],
\end{equation}
where $G_i \in \{0,1\}$ indicates whether unit $i$ is in the treatment group ($G_i=1$) or the control group ($G_i=0$). Different from single-stage \acrshort{ATE}/\acrshort{HTE} estimation, panel data analysis aims to quantify the change of causal effect over time. Based on SUTVA, a classical assumption in causal inference, \acrshort{ATT} can be identified from observed data. Since $R_{i,t}$ can be observed to unbiasedly estimate $\mathbb{E}[R_{t}(1)|G_i=1]$, the main challenge of panel data analysis is to impute the missing values for $R_{i,t}(0)$ for treated units. That is, we would like to answer the question of 

\textit{``What would happen to the treated units if they were exposed to control back to the treatment time?”}

Since the true answer is unobservable to us, we need to rely on additional assumptions to leverage existing information, particularly control units, for counterfactual estimation. 
To address this problem, there are two main streams of work in literature: \acrfull{DiD} \citep{lechner2011estimation} and \acrfull{SC} \citep{abadie2003economic, li2020statistical}. \acrshort{DiD} approach relies on the parallel trend assumption, where we learn the change of causal effect over time for control units and apply them to treated units for counterfactual estimation. Conversely, \acrshort{SC} approximates each treated unit with a weighted combination of controls, so as to borrow this weighted information for estimation. To be clearer, \acrshort{DiD} borrows the information of control units over time and inherits it to treated units; while \acrshort{SC} borrows the information of pre-treated stage over units and inherits it to post-treatment time. Due to the difference in estimation strategy, \acrshort{DiD} is often used when we are willing to assume the parallel trend assumption, while \acrshort{SC} is often applied to cases where only a few units are exposed to treatment.

Later, \citet{athey2021matrix} proposed a unified approach to integrate \acrshort{DiD} and \acrshort{SC} using matrix completion. Unlike \acrshort{DiD} and \acrshort{SC}, which rely on specific parallel or orthogonal assumptions, \citet{athey2021matrix} reframed causal effect estimation as a missing data imputation problem, assuming a low-rank structure to estimate counterfactuals in $\boldsymbol{R}(0)$. Recent advancements include but not limited to (1) R-DiD \citep{nie2019nonparametric}, which extends classical DiD by relaxing linear functional assumptions to accommodate more flexible estimands, (2) Synthetic DiD (SDiD) \citep{arkhangelsky2021synthetic}, combining the benefits of DiD and SC by re-weighting and matching pre-exposure trends to mitigate parallel assumptions while remaining invariant to additive unit-level shifts, (3) Synthetic Learner \citep{viviano2023synthetic}, an ensemble method enhancing precision through model-free inference, and (4) H1SL and H2SL \citet{shen2022heterogeneous}, which enable  \acrshort{HTE} estimation in panel data with one-sided and two-sided synthetic learners.

%Recently, \citet{shen2022heterogeneous} extended the previous works on ITE/ATE to estimate  \acrshort{HTE} in panel data settings, proposing novel one-side and two-side synthetic learners that can pool information from both treatments and controls to learn counterfactuals in different use cases. 
This field is rapidly evolving, offering greater flexibility in modeling choices and relaxing assumptions. 
Classical literature in panel data analysis primarily emphasizes effect estimation under relatively simple decision choices, often by examining patterns of change before and after treatment assignment, with less focus on directly modeling policy learning. Recent work, such as \citet{harris2024strategyproof}, introduces a strategy-proof framework for policy learning that maps pre-treatment outcomes to various intervention choices. This advancement has helped define policy learning explicitly within the context of panel data. For an in-depth overview, see the recent review by \citet{hsiao2022analysis} and \citet{arkhangelsky2023causal}.
%Traditional literature in econometrics often stops at causal effect quantification, although the ultimate goal is to optimize the 

\begin{comment}
\subsection{Benchmark Datasets}
\subsubsection{MIMIC III}\label{sec:mimic3}

Mimic III is a large open-access anonymized single-center database which consists of comprehensive clinical data of 61,532 critical care admissions from 2001–2012 collected at a Boston teaching hospital. Dataset consists of 47 features (including demographics, vitals, and lab test results) on a cohort of sepsis patients who meet the sepsis-3 definition criteria. Our objective is to (1) uncover the most causally influential connections between factors. (2) assess the impact of intravenous (IV) input on the mortality status of these patients and, (3) in the process, find out the optimal treatment strategy based on each patient's clinical history and current health status.


\subsubsection{Movielens}
Movie Lens is a website that helps users who joined MovieLens in 2000. It helps users find the movies they like and where they will rate the recommended movies. MovieLens 1M dataset is a publically available dataset which contains 1,000,209 anonymous ratings of approximately 3,900 movies made by 6,040 users, and is widely used to generate data for online bandit simulation studies. In bandits framework, every time a user visits the website, the agent will recommend a movie genre ($A_t$) to the user, and then the user will give a rating ($R_t$) to the genre recommended. The goal of our analysis is to (1) learn the expected ratings of users for each movie genre by \acrshort{CEL}, and (2) recommend the optimal movie genres to the users to optimize the cumulative user satisfaction. 

\end{comment}


