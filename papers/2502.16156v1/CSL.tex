\section{Causal Structure Learning}\label{Sec:CSL}

Most existing methodologies for average/heterogeneous treatment effects and personalized decision-making rely on a known causal structure. This enables us to locate the right variables to control (e.g., confounders), to intervene (e.g., treatments), and to optimize (e.g., rewards). However, such convenience is violated in many emerging real applications with unknown causal structures. Causal discovery thus has attracted more and more attention recently, as it allows inferring causal structure from data and disentangling the complex relationship among variables.  In this section, we present state-of-the-art techniques for learning the skeleton of unknown causal relationships among input variables with embedded treatments. We start to detail why \acrshort{CSL} is needed for causal decision-making, then introduce commonly proposed causal graphical models in Paradigm 1 and present existing representative classes of causal discovery methods, followed by discussions and extensions to Paradigms 2 and 3. 

% This section presents state-of-the-art techniques for learning the skeleton of unknown causal relationships among input variables. With preliminaries of causal graphical model \citep{pearl2009causal,peters2014identifiability} introduced, we present three representative classes of causal discovery methods, including testing-based learners \citep{spirtes2000constructing,kalisch2007estimating}, functional-based learners \citep{shimizu2006linear,buhlmann2014cam}, and score-based learners \citep{zheng2018dags,yu2019dag}, followed by advances in causal mediation analysis \citep{cai2020anoce} with complex graph structure.

% \subsection{Preliminaries}
% \subsubsection{General Causal Graph Terminology}
% %Consider a graph $\mathcal{G} =(\mathbf{Z},\mathbf{E})$ with a node set $\mathbf{Z}$ and an edge set $\mathbf{E}$. A node $Z_i$ is said to be a parent of $Z_j$ if there is a directed edge from $Z_i$ to $Z_j$. Let the set of all parents of node $Z_j$ in $\mathcal{G}$ as $PA_{Z_j} (\mathcal{G})$. A directed graph that does not contain directed cycles is called a directed acyclic graph (DAG). Suppose a DAG $\mathcal{G}=(\mathbf{Z},\mathbf{E})$ that characterizes the causal relationship among $|\mathbf{Z}|=d$ nodes, where $\mathbf{Z}=[Z_1,Z_2,\cdots,Z_d]^\top $ represents a random vector and an edge $Z_i\rightarrow Z_j$ means that $Z_i$ is a direct cause of $Z_j$. 
% Consider a graph $\mathcal{G} =(\boldsymbol{X},\boldsymbol{D}_{\boldsymbol{X}})$ with a node set $\boldsymbol{X}$ and an edge set $\boldsymbol{D}_{\boldsymbol{X}}$. There is at most one edge between any pair of nodes. If there is an edge between $X_i$ and $X_j$, then $X_i$ and $X_j$ are adjacent. A node $X_i$ is said to be a parent of $X_j$ if there is a directed edge from $X_i$ to $X_j$, i.e., $X_i$ is a direct cause of $X_j$. A node $X_k$ is said to be an ancestor of $X_j$ if there is a directed path from $X_k$ to $X_j$ regulated by at least one additional node $X_i$ for $i\not =k$ and $i \not =j$, i.e., $X_k$ is an indirect cause of $X_j$. Let the set of all parents/ancestors of node $X_j$ in $\mathcal{G}$ as $\textsc{PA}_{X_j} (\mathcal{G})$. A path from $X_i$ to $X_j$ in $\mathcal{G}$ is a sequence of distinct vertices, $\pi := \{a_0, a_1,\cdots,a_L\}\subset V$ such that $a_0 =X_i$, and $a_L=X_j$. A directed path from $X_i$ to $X_j$ is a path between $X_i$ and $X_j$ where all edges are directed towards $X_j$.  A directed graph $\mathcal{G}$ that does not contain directed cycles is called a directed acyclic graph (DAG). A directed graph is acyclic if and only if it has a topological ordering. 

% A general causal DAG, $\mathcal{G}$, may not be identifiable from the distribution of $\boldsymbol{X}$. According to \cite{pearl2000causality}, a DAG only encodes conditional independence relationships through the concept of $d$-separation. In general, several DAGs can encode the same conditional independence relationships, and such DAGs form a Markov equivalence class. Two DAGs belong to the same Markov equivalence class if and only if they have the same skeleton and the same v-structures \citep{kalisch2007estimating}. A Markov equivalence class of DAGs can be uniquely represented by a completed partially directed acyclic graph (CPDAG) \citep{spirtes2000constructing}, which is a graph that can contain both directed and undirected edges. A CPDAG satisfies the following: $X_i \leftrightarrow X_j$ in the CPDAG if the Markov equivalence class contains a DAG including $X_i \rightarrow X_j$, as well as another DAG including $X_j \rightarrow X_i$. The Markov equivalence class for a fixed CPDAG $\mathcal{C}$ is denoted by $\operatorname{MEC}(\mathcal{C})$, which is a set containing all DAGs $\mathcal{G}$ that have the CPDAG structure $\mathcal{C}$. 
% % In general, if the error distribution is joint Gaussian with different diagonal elements in the LSEM satisfying our structure assumption, the data distribution can only give a CPDAG and thus a MEC \citep{shimizu2006linear}. In the linear setting, however, if the error distribution is non-Gaussian, the distribution of $X$ will completely give a unique DAG; see Theorem 11.4 in \cite{neal2020introduction}. Since in practice we usually do not know whether the error is Gaussian, it is safer to assume that we can only obtain a CPDAG instead of a DAG from the data. 
% If we can obtain the true DAG from the data, we can simply treat it as a special case of the "MEC" containing only this DAG, i.e., $\operatorname{MEC}(\mathcal{G})= \{ \mathcal{G} \}$. %For simplicity, we denote the corresponding causal structure for the mediators $M$ as $\mathcal{G}_M$, which can be obtained by deleting nodes $C, A, Y$, and the corresponding edges from $\mathcal{G}$. 
% % Specially, we denote the causal structure of mediators as $\mathcal{G}_{M}$. 
% % Obviously, the adjacency matrix $\mathcal{G}_{M}$ satisfies $\mathcal{G}_{M} = \big[ \mathcal{{G}}_{kk} \big]_{k \in \{ t + 1, \ldots, t + p\}}$. 
% % The CPDAG of mediators is similarly denoted as $\mathcal{C}_M$. For simplicity and with a minor stretch of notation, we employ $\mathcal{G}_{M}$ and $\mathcal{C}_M$ to denote the causal DAG and CPDAG of $X$, respectively, such that their corresponding mediators' causal DAG and CPDAG are represented by $\mathcal{G}_{M}$ and $\mathcal{C}_M$ exactly.

% \subsubsection{Causal Graphical Model}

% The structural causal model (SCM) characterizes the causal relationship among $|\boldsymbol{X}|=d$ nodes via a DAG $\mathcal{G}$ and noises $\boldsymbol{e}_{\boldsymbol{X}} = [e_{X_1},\cdots,e_{X_d}]^\top$ such that
% $X_i := h_i\{\textsc{PA}_{X_i} (\mathcal{G}), e_{X_i}\}$ for some unknown $h_i$ and $i=1,\cdots,d$. Here, we allow the collections of nodes to take different causal roles in the causal graph. For instance, let $A \in \mathbb{R}$ be an exposure/treatment, $M := (M_1,M_2,\cdots,M_p)^{\top} \in \mathbb{R}^p$ be mediators with dimension $p$ in its support $\boldsymbol{M} = \mathcal{M}_1 \times \cdots \times \mathcal{M}_p \subseteq \mathbb{R}^p$, and $R \in \mathbb{R}$ be the outcome of interest. Additionally, we also consider that there are $t - 1$ confounders $\boldsymbol{S}: = (S_1, \ldots, S_{t - 1})^{\top} \in \mathbb{R}^{t - 1}$ in its support $\mathcal{S} \subseteq \mathbb{R}^{t - 1}$. We would just let $t = 1$ here to represent the absence of confounders, that is $\mathcal{S} = \varnothing$. Suppose that there exists a DAG $\mathcal{G} =(\boldsymbol{X},\boldsymbol{D}_{\boldsymbol{X}})$ that characterizes the causal relationship among $\boldsymbol{X}=(\boldsymbol{S}^{\top}, A, \boldsymbol{M}^\top, R)^\top$, where the dimension of $\boldsymbol{X}$ is $d = t + p + 1$. In such a scenario, we can also define the potential outcome framework through the `do-operator' \citep{pearl2009causal}. Let $R(\boldsymbol{Z}=\boldsymbol{z})$ be the potential value of $R$ that would be observed after setting variable $\boldsymbol{Z}$ as $\boldsymbol{z}$. This is equivalent to the value of $R$ by imposing a `do-operator' of $do(\boldsymbol{Z}=\boldsymbol{z})$ as in \citet{pearl2009causal}. Similarly, one can define the potential outcome,  $R(Z_i=z_i)$, by setting an individual variable $Z_i$ as $z_i$, while keeping the rest model unchanged.  
% % In this paper, we allow the dimension of mediator $p = p_n$ can increase with the sample size $n$. 
% We suppose we observe i.i.d data on $X = (\boldsymbol{S}^{\top}, A, \boldsymbol{M}^\top, R)^\top$ is collected for $n$ subjects. We introduce some commonly considered causal graphical models as follows.

% \smallskip


\subsection{Why \acrshort{CSL} is Needed for Causal Decision Making}

 

% \textit{[add more literature to support the following points]}
 
\acrshort{CSL} is a crucial step in understanding the underlying mechanisms that govern changes in a system. It involves identifying the causal relationships between variables, which is fundamental for any subsequent analysis aiming to understand causal effects and make causal decisions. The important reasons for \acrshort{CSL} ahead of \acrshort{CEL} and \acrshort{CPL} can be summarized as follows.

% First of all, \acrshort{CSL} is the first step of causal decision making. 
% \subsubsection{Real Motivating Examples}
% \textbf{Example 1:  Causal Graph for Heterogeneous Treatment Effect and Personalized Decision Making}

% \noindent\textbf{Example 2: Causal Graph for Causal Mediation Analysis}

% \noindent\textbf{Example 3: Causal Graph for Mediated Personalized Decision Making}

 

% \textbf{Informing Intervention and Policy Design.} 
First, \acrshort{CSL} is the \textit{first} step of causal decision-making. More specifically, \acrshort{CSL} is essential for \textit{designing effective interventions and policies} by identifying the exposure or treatment in the causal graph \citep[see e.g.,][]{spirtes2000constructing,chickering2002optimal,shimizu2006linear,kalisch2007estimating,harris2013pc,buhlmann2014cam,ramsey2017million,zhang2018non}. In fields such as epidemiology \citep{hernan2004definition}, medicine \citep{hernan2000marginal},  and economics \citep{panizza2014public}, the underlying causal mechanism among variables of interest is typically unknown. \acrshort{CSL} allows intervention evaluators or policymakers to understand the potential ramifications of their actions by revealing how different factors interact causally.
 

% \textbf{Understanding Causality, Not Correlation.} 
% Traditional statistical methods can be very effective at finding correlations between variables but often fail to establish causality. \acrshort{CSL} goes beyond correlation to determine which relationships are truly causal. This understanding is essential for making predictions about the effects of interventions, which is the goal of causal effect learning, as well as 


\begin{figure}[!thp] 
\centering 
 \includegraphics[width=0.32\linewidth]{Figure/t-para-1.png}~~~~
 \includegraphics[width=0.3\linewidth]{Figure/t-para-3.png} 
 \includegraphics[width=0.32\linewidth]{Figure/t-para-2.png} 
 
 \caption{An illustration of Simpson's Paradox.}\label{fig:t-para}
 \end{figure}
 
%\textbf{Making Valid Analyses.} 
Second, understanding the causal pathway is essential when estimating the impact of changes in one variable on another to inform decision-making. Interventions based on \textit{incomplete causal knowledge risks yielding biased outcomes}, as depicted in Figure \ref{fig:t-para}. This figure illustrates the complexities of discerning the relationship between the value-price ratio and customer trust. A simplistic regression that ignores confounders suggests a counterintuitive negative correlation: higher value-price ratios correspond to lower customer trust, as shown in the figure's left panel. However, this analysis is flawed due to omitted variable bias. The middle panel of Figure \ref{fig:t-para} introduces a complete causal graph that accounts for potential confounders, offering a more accurate representation of the relationship. When product information is incorporated, the apparent contradiction resolves—higher value-price ratios actually correlate with increased trust in both laptop and drink product categories. This scenario exemplifies Simpson's Paradox \citep{blyth1972simpson}, where aggregated data can mask or reverse trends present within stratified groups.
% to estimate the effect of changing one variable on another (i.e., the causal effect) and take the best action, it's important to know the causal pathway. Without knowledge of the causal structure, any intervention might lead to biased effects (see Figure \ref{fig:t-para}) or incorrect conclusions if it affects not only the target variable but also other variables within the system. Specifically, in the example of Figure \ref{fig:t-para}, we are interested in the relationship between the value price ratio and customer trust. Without considering any confounders in this study simply regressing the level of customer trust on the value-price ratio will produce a negative impact (see the left panel of Figure \ref{fig:t-para}), i.e., with a higher value-price ratio the customer trust will decrease. This is counter-intuitive as the analyses are biased and misleading without considering the complete causal graph (i.e., the middle panel of Figure \ref{fig:t-para}). Indeed, with additional information from the product, we can separate the group and show that with a higher value-price ratio customer trust will increase in both groups of laptop products and drink products. Such a problem is also well known as Simpson’s Paradox.

 
 
Third, with \acrshort{CSL}, we can \textit{avoid spurious relationships}. %CSL helps identify spurious relationships caused by confounding variables. %Confounders are external variables that influence both the independent and the dependent variables, creating a false impression of a direct causal relationship between them. In complex systems with many interacting variables, \acrshort{CSL} helps to simplify the model by identifying the most relevant causal relationships. This simplification can make models more understandable, efficient, and less prone to overfitting.
Building upon the causal graphical model \citep[see e.g., ]%[for a comprehensive review of recent advances in the analysis of causes and counterfactuals]
[]{pearl2009causal}, many \acrshort{CSL} algorithms have been developed \citep[see e.g.,][]{spirtes2000constructing,chickering2002optimal,shimizu2006linear,kalisch2007estimating,buhlmann2014cam,ramsey2017million,zheng2018dags,yu2019dag,zhu2019causal,cai2020anoce} but rely on the assumption of causal sufficiency (the absence of unmeasured confounders). In real-world applications, to satisfy such an assumption, we strive to learn large-scale causal graphs \citep[see e.g.,][]{nandy2017estimating,chakrabortty2018inference,tang2020long,niu2021counterfactual}, in the hopes of {sufficiently} describing how an outcome of interest depends on its relevant variables.  
In addition to sufficiency, it is also crucial to account for the concept of {necessity} by excluding redundant variables in explaining the outcome of interest. Failure to do so can result in the inclusion of spurious variables in the learned causal graphs, which are highly correlated with but have no causal impact on the outcome. These variables can impede causal estimation with limited data and lead to falsely discovered spurious relationships, leading to poor generalization performance for downstream prediction \citep{scholkopf2021toward}. For instance, it might be observed that men aged 30 to 40 who buy diapers are also likely to purchase beer. However, beer purchase is a spurious feature for diaper purchases: their correlation is not necessarily causal, as both purchases might be confounded by a shared cause, such as new fathers buying diapers for childcare while also buying beer to alleviate stress. Therefore, merely increasing the availability of diapers or beer will not causally enhance the demand for the other (see also Figure \ref{fig:0}(left)).

\begin{figure}[!t] 
\centering 
%\vspace{-0.3cm} 
  \includegraphics[width=0.45\linewidth]{Figure/examnew2.png} 
  %\vspace{-0.1cm} 
  \includegraphics[width=0.45\linewidth]{Figure/intro_graph.png} 
  %\vspace{-0.1cm}  
%\vspace{-0.3cm} 
\caption{\textbf{Left}: Illustration of the causal relationship between the customer being a new father or not, beer purchasing, and diaper purchasing, where solid lines represent the true model, and the dashed line corresponds to the spurious correlation between beer purchasing and diaper purchasing. \textbf{Right}: Relationship between various causal structures. Nodes $A$, $B$, and $C$ belong to the necessary and sufficient causal graph for the target outcome $Y$ and are depicted inside the green solid square. Among them, nodes $B$ and $C$ are members of the Markov blanket of $Y$, enclosed by the blue dotted square. Node $S$ is the spurious variable to $Y$, while nodes $N$ and $M$ are unrelated to the target.} \label{fig:0}
% \vspace{-0.3cm}
\end{figure}  

Fourth, with \acrshort{CSL}, we aim to \textit{simplify complex models} by identifying the most relevant causal relationships for decision making. This simplification can make models more understandable, efficient, and less prone to overfitting. The number of variables causally relevant to the outcome of interest is often considerably smaller than the number of variables included in estimating a causal graph (see  Figure \ref{fig:0}(right)). For example, while an individual's genome may encompass 4 to 5 million \acrfull{SNPs}, only a limited number of non-spurious genes or proteins are found to systematically regulate the expression of the phenotype of interest \citep[e.g.,][]{chakrabortty2018inference}. Similarly, in natural language processing tasks, excluding spurious embeddings such as writing style and dialect can enhance model accuracy and downstream prediction performance \citep[e.g.,][]{feder2021causal}. %Thus, a more parsimonious causal graph is required to unveil the {necessary} and {sufficient} causal dependencies.

% \textbf{Transferring Knowledge Across Domains and Generalization.} A learned causal structure can sometimes be transferred or adapted to new but related domains. Understanding causality, rather than merely associations, allows for more robust generalizations and applications of learned models. By understanding the true causal mechanisms, models are less likely to be fooled by patterns in the data that are specific to the particular sample at hand. This improves the generalization of the causal model to new data.

% 6. **Facilitating Counterfactual Reasoning:** \acrshort{CSL} supports counterfactual reasoning, which involves asking "what-if" questions. Knowing the causal structure allows us to reason about hypothetical scenarios and the outcomes of potential interventions.

% \textbf{Simplifying Complex Models and Simplifying Complex Models.} In complex systems with many interacting variables, \acrshort{CSL} helps to simplify the model by identifying the most relevant causal relationships. This simplification can make models more understandable, efficient, and less prone to overfitting.

% 8. **Improving Generalization:** By understanding the true causal mechanisms, models are less likely to be fooled by patterns in the data that are specific to the particular sample at hand. This improves the generalization of the causal model to new data.

% In practice, \acrshort{CSL} often involves using algorithms and statistical methods to construct a causal graph or network that visually represents the relationships between variables. Techniques such as Directed Acyclic Graphs (DAGs), Bayesian networks, and constraint-based or score-based approaches can be used to infer causal structures. Once the structure is learned, various methods for causal effect estimation, such as do-calculus, potential outcomes framework, or causal Bayesian network techniques, can be applied to estimate the magnitude and sign of causal effects.

\subsection{Decision-Oriented \acrshort{CSL} under Paradigm 1 }\label{sec:CSL_P1}

This section presents state-of-the-art techniques for learning the skeleton of unknown causal relationships among input variables with the presence of treatments or decision variables under Paradigm 1. 

\subsubsection{Overview of Decision-Oriented Causal Discovery}
Under a general treatment-embedded causal graph, the treatment or exposure may have a direct effect on the outcome and also an indirect effect regulated by a set of mediators (or intermediate variables), confounded by some baseline covariates. 
In the era of the causal revolution, identifying the causal effect of exposure on the outcome of interest is an important problem in many areas \citep[see e.g., ][]{chakrabortty2018inference,cai2020anoce,watson2023heterogeneous}. 
An analysis of causal effects that interprets the causal mechanism contributed through mediators is hence challenging but on demand, and naturally bridged the gap between \acrshort{CSL} and \acrshort{CEL}, and learned results further served as the middle step for \acrshort{CPL}. 

Existing statistical and machine learning tools for learning the causal graphs with multiple mediators \citep[see e.g.,][]{chakrabortty2018inference,cai2020anoce,shi2021testing} %within an unknown graph structure usually 
comprise the following three principal steps. Initially, \acrshort{CSL} methodologies \citep[see e.g.,][]{spirtes2000constructing,chickering2002optimal,nandy2018high,li2019likelihood,yuan2019constrained,li2023inference} are applied to estimate the causal graph, often presented by a \acrshort{DAG}, using observational data. 
With preliminaries of the causal graphical model \citep{pearl2009causal,peters2014identifiability} introduced in Section \ref{sec:assum_csl}, we present three representative classes of causal discovery methods, including testing-based learners \citep{spirtes2000constructing,kalisch2007estimating}, functional-based learners \citep{shimizu2006linear,buhlmann2014cam}, and score-based learners \citep{zheng2018dags,yu2019dag}, in Section \ref{sec:learn_dag}. In the absence of additional assumptions \citep{shimizu2006linear, neal2020introduction}, the graph is only identified up to a \acrfull{MEC}, and a \acrfull{CPDAG} in such a class is often used to represent the graph structure (see details in Section \ref{sec:iden_dag}). 
%Common methodologies for this estimation include the PC algorithm \citep{spirtes2000constructing}, greedy equivalence search (GES) \citep{chickering2002optimal}, and the adaptively restricted greedy equivalence search (ARGES) \citep{nandy2018high}. 
% In the absence of additional assumptions \citep{shimizu2006linear, neal2020introduction}, the graph is only identified up to a Markov equivalence class (MEC), and a completed partially directed acyclic graph (CPDAG) in such a class is often used to represent the graph structure (see details in Section \ref{sec:iden_dag}). 
%The preference for estimating a CPDAG rather than a fully directed acyclic graph (DAG) is due to the potential non-identifiability of the true causal structure, or Directed Acyclic Graph (DAG), from observations alone in the absence of additional assumptions \citep{shimizu2006linear, neal2020introduction}. 
%In the era of the causal revolution, identifying the causal effect of exposure on the outcome of interest is an important problem in many areas. 
%Under a general causal graph, the exposure may have a direct effect on the outcome and also an indirect effect regulated by a set of mediators. 
Following advances in causal mediation analysis \citep{cai2020anoce} with complex graph structure (see details in Section \ref{sec:med_dag}), 
the subsequent step is the estimation of the causal effects of mediators based on the \acrshort{DAG} or \acrshort{CPDAG} obtained from the initial phase. For this task, a variety of estimation techniques have been proposed, including the application of \acrfull{OLS} estimators \citep{vanderweele2014causal,lin2017interventional,chakrabortty2018inference}, parametric models \citep{vanderweele2014mediation,vanderweele2016causal,chen2023discovery}, and nonparametric methods \citep{an2022opening,brand2023recent}. % (see details in Section \ref{sec:med_dag}). 
%In this section, we mainly focused on the decision-oriented \acrshort{CSL} Methods under Paradigm 1.

% followed by advances in causal mediation analysis \citep{cai2020anoce} with complex graph structure. In this section, we mainly focused on the decision-oriented \acrshort{CSL} Methods under Paradigm 1.


% (see details in Section \ref{sec:learn_dag}). 
%The final step is to conduct inferences based on the estimated effects, which often requires finding the exact (asymptotic) distributions of the estimators. As pointed out in \cite{chen2023discovery}, such an inference is often regarded a separate task and has received less attention in recent causal graph literature.
%with various challenges still yet to be resolved.

% \subsubsection{Causal Graphical Models
% in Paradigm 1 }

%  We introduce some commonly considered causal graphical models as follows under Paradigm 1.

% \smallskip

% \noindent\textbf{Linear Structural Equation Model.} 
% Let $B=\{b_{i,j}\}_{1\leq i\leq d,1\leq j\leq d}$ be a $d\times d$ matrix, where $b_{i,j}$ is the weight of the edge $Z_i\rightarrow Z_j \in \mathbf{E}$, and $b_{i,j}=0$ otherwise. Then, we say that $\mathcal{G} =(\mathbf{Z},\mathbf{E})$ is a weighted DAG with the node set $\mathbf{Z}$ and the weighted adjacency matrix $B$ (the edge set $\mathbf{E}$ is nested in $B$). The linear structural equation model (LSEM) \citep{sobel1987direct} such that $\mathbf{Z}$ characterized by the pair ($\mathcal{G}$, $\epsilon$) is generated by 
% \begin{equation}\label{lsem_x}
% \mathbf{Z}=B^\top \mathbf{Z} +\epsilon,
% \end{equation}
% where $\epsilon $ is a  random vector of jointly independent error variables.

% \smallskip

% \noindent\textbf{Additive Noise Model.} 
% Suppose there exists a weighted DAG $\mathcal{G}=(\mathbf{Z},\mathbf{E})$ that characterizes the causal relationship among $|\mathbf{Z}|=d$ nodes. Each variable $Z_i$ is associated with a node $i$ in the DAG $\mathcal{G}$, and the observed value of $Z_i$ is obtained as a function of its parents in the graph plus an independent additive noise $n_i$, as the additive noise model \citep{buhlmann2014cam}, i.e., 
% \begin{equation}\label{anm}
% Z_i := f_i\{PA_{Z_i} (\mathcal{G})\} + n_i,i = 1,2,...,d, 
% \end{equation}
% where $PA_{Z_i} (\mathcal{G})$ denotes the set of parent variables of $Z_i$ so that there is an edge from $Z_j\in PA_{Z_i} (\mathcal{G})$ to $Z_i$ in the graph, and the noises $n_i$ are assumed to be jointly independent. Here, Model \eqref{lsem_x} is a special case of Model \eqref{anm}. 

% \smallskip

% \noindent\textbf{Generalized LSEM.} 
% To handle complex relationships, a generalized version of LSEM has been studied \citep{yu2019dag} as
% \begin{equation}\label{g_lsem}
% f_2(\mathbf{Z})=B^\top f_2(\mathbf{Z}) +f_1(\epsilon),
% \end{equation}
% where the parameterized functions $f_1$ and $f_2$ effectively perform (possibly nonlinear) transforms on $\epsilon$ and $\mathbf{Z}$, respectively. Here, Model \eqref{lsem_x} is also a special case of Model \eqref{g_lsem}. 

% \smallskip

%  \subsubsection{Markov Equivalence Class}

% A general causal DAG, $\mathcal{G}$, may not be identifiable from the distribution of $\boldsymbol{X}$. According to \cite{pearl2000causality}, a DAG only encodes conditional independence relationships through the concept of $d$-separation. In general, several DAGs can encode the same conditional independence relationships, and such DAGs form a Markov equivalence class. Two DAGs belong to the same Markov equivalence class if and only if they have the same skeleton and the same v-structures \citep{kalisch2007estimating}. A Markov equivalence class of DAGs can be uniquely represented by a completed partially directed acyclic graph (CPDAG) \citep{spirtes2000constructing}, which is a graph that can contain both directed and undirected edges. A CPDAG satisfies the following: $X_i \leftrightarrow X_j$ in the CPDAG if the Markov equivalence class contains a DAG including $X_i \rightarrow X_j$, as well as another DAG including $X_j \rightarrow X_i$. CPDAGs can be estimated from observational data using various algorithms, such as the algorithms in \cite{kalisch2007estimating}, \cite{harris2013pc}, and \cite{zhang2018non}. The Markov equivalence class for a fixed CPDAG $\mathcal{C}$ is denoted by $\operatorname{MEC}(\mathcal{C})$, which is a set containing all DAGs $\mathcal{G}$ that have the CPDAG structure $\mathcal{C}$. 
% % In general, if the error distribution is joint Gaussian with different diagonal elements in the LSEM satisfying our structure assumption, the data distribution can only give a CPDAG and thus a MEC \citep{shimizu2006linear}. In the linear setting, however, if the error distribution is non-Gaussian, the distribution of $X$ will completely give a unique DAG; see Theorem 11.4 in \cite{neal2020introduction}. Since in practice we usually do not know whether the error is Gaussian, it is safer to assume that we can only obtain a CPDAG instead of a DAG from the data. 
% If we can obtain the true DAG from the data, we can simply treat it as a special case of the "MEC" containing only this DAG, i.e., $\operatorname{MEC}(\mathcal{G})= \{ \mathcal{G} \}$. %For simplicity, we denote the corresponding causal structure for the mediators $M$ as $\mathcal{G}_M$, which can be obtained by deleting nodes $C, A, Y$, and the corresponding edges from $\mathcal{G}$. 
% % Specially, we denote the causal structure of mediators as $\mathcal{G}_{M}$. 
% % Obviously, the adjacency matrix $\mathcal{G}_{M}$ satisfies $\mathcal{G}_{M} = \big[ \mathcal{{G}}_{kk} \big]_{k \in \{ t + 1, \ldots, t + p\}}$. 
% % The CPDAG of mediators is similarly denoted as $\mathcal{C}_M$. For simplicity and with a minor stretch of notation, we employ $\mathcal{G}_{M}$ and $\mathcal{C}_M$ to denote the causal DAG and CPDAG of $X$, respectively, such that their corresponding mediators' causal DAG and CPDAG are represented by $\mathcal{G}_{M}$ and $\mathcal{C}_M$ exactly.

% CPDAGs can be estimated from observational data using various algorithms, such as the algorithms in \cite{kalisch2007estimating}, \cite{harris2013pc}, and \cite{zhang2018non}. 


\subsubsection{Preliminaries in Decision-Oriented Causal Discovery under Paradigm 1}\label{sec:assum_csl}

As commonly imposed in the works of \acrshort{CSL} \citep[e.g.,][]{spirtes2000causation,peters2014causal}, we assume the Causal Markov and faithfulness %, and causal sufficiency 
assumptions. To detail these assumptions, we first introduce the concept of the D-separation.
\begin{definition}[D-separation]\label{def-d-sep}
Nodes, $X$ and $Y$, are d-separated by a set of nodes, $Z$, if and only if for every path, $\pi$, there exists a node, $m\in Z$, that extends $\pi$ ($i\to m\to j$) or forks $\pi$ ($i\xleftarrow{} m\to j$) and for any node, $c$, along $\pi$ that is a so-called collider ($i\to m\xleftarrow{} j$), $c$ and all descendents of $c$ are not in $Z$ \citep{pearl2009causal}.
\end{definition}
Given that $Z$ d-separates $X$ and $Y$ and $X$ preceeds $Y$ causally, the implication of d-seperation is that $X\perp Y|Z$.
\begin{assumption}[Causal Markov assumption]
For a given causal graph, $\mathcal{G} =(\mathbf{Z},\mathbf{E})$, the set of independences among the nodes, $\mathbf{Z}$, contains the set of independences implied by d-separation.
\end{assumption}
\begin{assumption}[Faithfulness assumption]
For a given causal graph, $\mathcal{G} =(\mathbf{Z},\mathbf{E})$, the set of independences among the nodes, $\mathbf{Z}$, is \textbf{exactly} described by the set of independences implied by applying d-separation to $\mathcal{G}$.
\end{assumption}

% \begin{definition}[Causal sufficiency assumption]
% The set of variables, $Z$, includes all of the common causes among every pair in $Z$. That is to say, there is no unmeasured variable, $U$, that is the common parent of any pair in $Z$.
% \end{definition}
Note that the assumptions made in this review paper are commonly imposed in the literature of causal inference. Please refer to \cite{pearl2000causality, pearl2009causal, athey2015machine, nandy2017estimating, wager2018estimation, kunzel2019metalearners, nie2021quasi} for discussions of these assumptions and their impact. There are a few future extensions to relax or diagnose these assumptions. For instance, a full sensitivity analysis of the assumptions would be useful to the field when it is hard to include all variables causally related to any variable in the data in practice. In addition, utilizing the instrumental variables in the context of causal graphs with multiple mediators may be beneficial in addressing no unmeasured confounders, as specified below.

% Under no unmeasured confounders, the Markov condition, the faithfulness condition, the causal sufficiency assumption, and t

% {Assumptions for \acrshort{CSL} and Identifiablities}
% To characterize the model, we consider the following assumptions.

\begin{assumption}[Causal Sufficiency assumption]
    The causal graph $\mathcal{G}$ satisfies \textit{Causal Sufficiency} \citep{hasan2023a}. The random vector $\mathbf{X}$ satisfies the structure assumption: (i) No potential mediator is a direct cause of confounders $\mathbf{S}$; (ii) The outcome $R$ has no descendant; (iii) The only parents of treatment $A$ are confounders.
\end{assumption}

In many instances, the accessible data offers an incomplete view of the inherent causal structure.  To address this gap, \textit{Causal Markov Condition}, \textit{Causal Faithfulness Condition}, and \textit{Causal Sufficiency} in the above assumption provide a sufficient condition for causal discovery in i.i.d. data contexts  \citep{lee2020towards,assaad2022survey,hasan2023a}. The rigorous definitions for them and related details can be found in Section 2.4 in \cite{hasan2023a}. Furthermore, the structural assumptions for decision-oriented \acrshort{CSL} aim at ensuring the identifiability of the causal model, which are similar to Consistency Assumption and Sequential Ignorability Assumption in \cite{tchetgen2012semiparametric}, and the structure assumptions in Section 2.4 of \cite{chakrabortty2018inference}.  We introduce some commonly considered causal graphical models as follows under Paradigm 1.

\smallskip

\noindent\textbf{Linear Structural Equation Model.} 
Let $\boldsymbol{B}=\{b_{i,j}\}_{1\leq i\leq d,1\leq j\leq d}$ be a $d\times d$ matrix, where $b_{i,j}$ is the weight of the edge $X_i\rightarrow X_j \in \mathbf{E}$, and $b_{i,j}=0$ otherwise. Then, we say that $\mathcal{G} =(\boldsymbol{X},\mathbf{E})$ is a weighted DAG with the node set $\boldsymbol{X}$ and the weighted adjacency matrix $\boldsymbol{B}$ (the edge set $\mathbf{E}$ is nested in $\boldsymbol{B}$). The \acrfull{LSEM} \citep{sobel1987direct} such that $\boldsymbol{X} = (\boldsymbol{S}^{\top}, A, \boldsymbol{M}^\top, R)^\top$ characterized by the pair ($\mathcal{G}$, $\epsilon$) is generated by 
\begin{equation}\label{lsem_x}
\boldsymbol{X}=\boldsymbol{B}^\top \boldsymbol{X} +\epsilon,
\end{equation}
where $\epsilon $ is a random vector of jointly independent error variables. 
We next explicitly characterize the weighted adjacency matrix  $\boldsymbol{B}$ that satisfies Model (\ref{lsem_x}) based on causal knowledge among $\boldsymbol{S}, A, \boldsymbol{M},$ and $R$, in the decision-oriented \acrshort{CSL}. Specifically, 
% since we have:
% \begin{enumerate}
% % \vspace{-0.3cm}
%     \item the $p$-dimensional states $\boldsymbol{S}$ has no parents, i.e.,  $ g_1(\boldsymbol{B})=\sum_{j=1}^p \sum_{i=1}^{d} |b_{i,j}| = 0;$
%     % \vspace{-0.25cm}
%     \item the only parents of $A$ are $\boldsymbol{S}$, i.e., $g_2(\boldsymbol{B})=\sum_{i=p+1}^{d} |b_{i,{p+1}}|= 0; $ and
%     % \vspace{-0.25cm}
%     \item $R$ has no descendants, i.e.,  $g_3(\boldsymbol{B})=\sum_{i=1}^{d} |b_{d,i}| = 0.$
%     % \vspace{-0.25cm}
%     % \item the interaction $\boldsymbol{X}A$ also does not have parents, i.e.,  $g_4(\boldsymbol{B})=\sum_{j=p+2}^{2p+1}\sum_{i=1}^{2p+s+2} |b_{i,j}| = 0.$
%     % \vspace{-0.3cm}
% \end{enumerate}
% The conditions in $ g_1(\boldsymbol{B})$ to $ g_3(\boldsymbol{B})$ yield 
the following matrix  $\boldsymbol{B}^\top$ consists of unknown parameters whose  sparsity is due to prior causal information:
\[\boldsymbol{B}^\top = \begin{bmatrix}
\boldsymbol{0}_{p\times p}&\boldsymbol{0}_{p\times 1}&\boldsymbol{0}_{p\times s}&\boldsymbol{0}_{p\times 1}\\
\boldsymbol{\delta_S}&0&\boldsymbol{0}_{1\times s}&0\\
% \boldsymbol{0}_{p\times p}&\boldsymbol{0}_{p\times 1}&\boldsymbol{0}_{p\times p}&\boldsymbol{0}_{p\times s}&\boldsymbol{0}_{p\times 1}\\
\boldsymbol{B_S}^\top&\boldsymbol{\beta}_A& \boldsymbol{B_M}^\top&\boldsymbol{0}_{s\times 1}\\
\boldsymbol{\gamma_S}&\gamma_A& \boldsymbol{\gamma_M}&0
\end{bmatrix},\]
where $\boldsymbol{0}_{a\times b}$ is a $a\times b$ zero matrix/vector, and the parameters $\boldsymbol{\delta_S},\boldsymbol{B_S}^\top,$ and $\boldsymbol{\gamma_S}$ represent the influence of $\boldsymbol{S}$, on the treatment $A$, the mediators $\boldsymbol{M}$, and the outcome $R$, respectively. Likewise, $\boldsymbol{\beta}_A$ and $\gamma_A$ represent the influence of $A$ on $\boldsymbol{M}$ and $R$, respectively, and $\boldsymbol{\gamma_M}$ represent the influence of $\boldsymbol{M}$ on $R$. $\boldsymbol{B_M}^\top$ represents the influence of the mediators on other mediators. If $\boldsymbol{B_M}^\top = \boldsymbol{0}_{s\times s}$ for the $s$-dimensional mediators, then we say that mediators are \textit{parallel}, otherwise they are \textit{sequentially ordered}. The extension to the \acrshort{LSEM} with the interaction between the possible moderators and the treatment can be found in \citet{watson2023heterogeneous}.
%Finally, $\boldsymbol{B}^\top_{\boldsymbol{X}A}$ and $\boldsymbol{\gamma}_{\boldsymbol{X}A}$ represent the influences of the interaction between the possible moderators and the treatment, $\boldsymbol{X}A$, on $\boldsymbol{M}$ and $Y$. This gives the proposed model the capability to characterize moderation to allow heterogeneity and multiple sequentially ordered mediators to allow complexity. 

\smallskip

\noindent\textbf{Additive Noise Model.} 
Suppose there exists a weighted DAG $\mathcal{G}=(\boldsymbol{X},\mathbf{E})$ that characterizes the causal relationship among $|\boldsymbol{X}|=d$ nodes in $\boldsymbol{X} = (\boldsymbol{S}^{\top}, A, \boldsymbol{M}^\top, R)^\top$. Each variable $X_i$ is associated with a node $i$ in the \acrshort{DAG} $\mathcal{G}$, and the observed value of $X_i$ is obtained as a function of its parents in the graph plus an independent additive noise $n_i$, as the additive noise model \citep{buhlmann2014cam}, i.e., 
\begin{equation}\label{anm}
X_i := f_i\{PA_{X_i} (\mathcal{G})\} + n_i,i = 1,2,...,d, 
\end{equation}
where $PA_{X_i} (\mathcal{G})$ denotes the set of parent variables of $X_i$ so that there is an edge from $X_j\in PA_{X_i} (\mathcal{G})$ to $X_i$ in the graph, and the noises $n_i$ are assumed to be jointly independent. Here, Model \eqref{lsem_x} is a special case of Model \eqref{anm}. 

\smallskip

\noindent\textbf{Generalized \acrshort{LSEM}.} 
To handle complex relationships, a generalized version of LSEM has been studied \citep{yu2019dag} as
\begin{equation}\label{g_lsem}
f_2(\boldsymbol{X})=B^\top f_2(\boldsymbol{X}) +f_1(\epsilon),
\end{equation}
where the parameterized functions $f_1$ and $f_2$ effectively perform (possibly nonlinear) transforms on $\epsilon$ and $\boldsymbol{X}$, respectively. Here, Model \eqref{lsem_x} is also a special case of Model \eqref{g_lsem}. 

% \smallskip

 
 


 
% \subsubsection{Real Motivating Examples}
% \textbf{Example 1:  Causal Graph for Heterogeneous Treatment Effect and Personalized Decision Making}

% \noindent\textbf{Example 2: Causal Graph for Causal Mediation Analysis}

% \noindent\textbf{Example 3: Causal Graph for Mediated Personalized Decision Making}


% \subsubsection{Causal Graphical Models}

% \textbf{Linear Structural Equation Model.} 
% Let $B=\{b_{i,j}\}_{1\leq i\leq d,1\leq j\leq d}$ be a $d\times d$ matrix, where $b_{i,j}$ is the weight of the edge $Z_i\rightarrow Z_j \in \mathbf{E}$, and $b_{i,j}=0$ otherwise. Then, we say that $\mathcal{G} =(\mathbf{Z},B)$ is a weighted DAG with the node set $\mathbf{Z}$ and the weighted adjacency matrix $B$ (the edge set $\mathbf{E}$ is nested in $B$). Under no unmeasured confounders, the Markov condition, the faithfulness condition, the causal sufficiency assumption, and the linear structural equation model (LSEM) such that $\mathbf{Z}$ characterized by the pair ($\mathcal{G}$, $\epsilon$) is generated by 
% \begin{equation}\label{lsem_x}
% \mathbf{Z}=B^\top \mathbf{Z} +\epsilon,
% \end{equation}
% where $\epsilon $ is a  random vector of jointly independent error variables.


% \noindent\textbf{Additive Noise Model.} 
% Suppose there exists a weighted DAG $\mathcal{G}=(\mathbf{Z},\mathbf{E})$ that characterizes the causal relationship among $|\mathbf{Z}|=d$ nodes. Each variable $Z_i$ is associated with a node $i$ in the DAG $\mathcal{G}$, and the observed value of $Z_i$ is obtained as a function of its parents in the graph plus an independent additive noise $n_i$, i.e., 
% \begin{equation}\label{anm}
% Z_i := f_i\{PA_{Z_i} (\mathcal{G})\} + n_i,i = 1,2,...,d, 
% \end{equation}
% where $PA_{Z_i} (\mathcal{G})$ denotes the set of parent variables of $Z_i$ so that there is an edge from $Z_j\in PA_{Z_i} (\mathcal{G})$ to $Z_i$ in the graph, and the noises $n_i$ are assumed to be jointly independent. Here, Model 1 is a special case of Model 2. 

% \noindent\textbf{Generalized LSEM.} 
% To handle complex relationships, a generalized version of LSEM has been studied by Yu et al. (2019) as
% \begin{equation} 
% f_2(\mathbf{Z})=B^\top f_2(\mathbf{Z}) +f_1(\epsilon),
% \end{equation}
% where the parameterized functions $f_1$ and $f_2$ effectively perform (possibly nonlinear) transforms on $\epsilon$ and $\mathbf{Z}$, respectively. Here, Model 1 is also a special case of Model 3. 

 

\subsubsection{Decision-Oriented Causal Discovery Methods under Paradigm 1}\label{sec:learn_dag}
% This section presents state-of-the-art techniques for learning the skeleton of unknown causal relationships among input variables with the presence of treatments or decision variables. 

 In this section, we mainly focused on the decision-oriented \acrshort{CSL} methods under Paradigm 1. Plentiful \acrshort{CSL} methods have been proposed, with the large literature categorized into three types. 
The testing-based methods \citep[e.g.,][for the well-known PC algorithm]{spirtes2000constructing} rely on the conditional independence tests to find the causal skeleton and edge orientations under the linear \acrshort{SEM}. Based on additional model assumptions, the functional-based methods handle both linear \acrshort{SEM} \citep[e.g.,][]{shimizu2006linear} and non-linear \acrshort{SEM} \citep[e.g.,][]{buhlmann2014cam}. Recently, the score-based methods formulate the \acrshort{CSL} problem into optimization by certain score functions, for both linear \acrshort{SEM} \citep[e.g.,][]{ramsey2017million,zheng2018dags} and non-linear \acrshort{SEM} \citep[e.g.,][]{yu2019dag,zhu2019causal,zheng2020learning,rolland2022score}. However, all these methods treat nodes in the graph as generic variables without any causal meaning. In the following, we review a few recent works that learn causal graphs with decision variables oriented.



% Plentiful causal structural learning (CSL) methods have been proposed to learn the unknown causal
% structure within a class of directed acyclic graphs from observed data. 
% The large literature can be categorized into three types. 
% The testing-based methods \citep[e.g.,][for the well-known PC algorithm]{spirtes2000constructing} rely on the conditional independence tests to find the causal skeleton and edge orientations under the linear structural equation model (SEM). Based on additional and proper assumptions on noises and models, the functional-based methods handle both linear SEM \citep[e.g.,][]{shimizu2006linear} and non-linear SEM \citep[e.g.,][]{buhlmann2014cam}. Recently, the score-based methods formulate the \acrshort{CSL} problem into optimization by certain score functions, for both linear SEM \citep[e.g.,][]{ramsey2017million,zheng2018dags} and non-linear SEM \citep[e.g.,][]{yu2019dag,zhu2019causal,zheng2020learning,rolland2022score}. 
% With preliminaries of causal graphical model \citep{pearl2009causal,peters2014identifiability} introduced, we present three representative classes of causal discovery methods, including testing-based learners \citep{spirtes2000constructing,kalisch2007estimating}, functional-based learners \citep{shimizu2006linear,buhlmann2014cam}, and score-based learners \citep{zheng2018dags,yu2019dag}, followed by advances in causal mediation analysis \citep{cai2020anoce} with complex graph structure. In this section, we mainly focused on the decision-oriented \acrshort{CSL} Methods under Paradigm 1.


% \subsubsection{Decision Oriented Testing-based Learner}

%Causal discovery attracts more and more attention recently to infer causal structure from data and disentangles the complex relationship among variables. 
% In this section, we detail a state-of-the-art type of causal discovery learner, based on conditional independent testings, so-called the testing-based learner. 
To start with, we briefly introduce the \acrfull{PC} algorithm \citep{spirtes2000causation}, named by the first two authors, Pater and Clark, 
as one of the oldest testing-based (or constraint-based) algorithms for causal discovery, and the existing decision-oriented \acrshort{CSL} methods based on the \acrfull{PC} algorithm. 
To learn the underlying causal structure, the PC algorithm depends largely on \acrfull{CI} tests. If two variables are statistically independent or conditional independent, there is no causal link between them.  
\citet{maathuis2009estimating} started to use an unknown \acrshort{DAG} without hidden variables to estimate the causal effects from the high-dimensional observational data based on the \acrshort{PC} algorithm. Later, \citet{nandy2017estimating} extended the work of \citet{maathuis2009estimating} with the linear structure equation model. More recently, following these works, \citet{chakrabortty2018inference} firstly introduced the treatment or decision variable into the linear structure equation model, and further 
defined the individual mediation effect. To identify such a causal graph,  \citet{chakrabortty2018inference} fixed the first variable as the treatment or decision and the last variable as the outcome of interest, and then applied the PC algorithm to the rest of the model, i.e., the multiple mediators which influence the outcome but controlled by the treatment. More specifically, their algorithm finds and orients the v-structures or colliders (i.e. $\mathrm{X} \rightarrow \mathrm{Y} \leftarrow \mathrm{Z}$) based on the d-separation set of node pairs (see Definition \ref{def-d-sep}). 
All of these models rely on the PC algorithm to search the Markov equivalence class of the partial \acrshort{DAG}, and usually require strong sparsity and normality assumptions due to the computational limit. 

% Our ANOCE is established under the same causal structure of \citet{chakrabortty2018inference} but without sparsity and normality assumptions. 



 
%We specifically review the PC algorithm in the following three steps. In the first step, the PC algorithm starts with a fully connected undirected graph using all variables in the data. Then, it eliminates the edges based on unconditionally and conditionally independent pairs, given a certain testing procedure such as the Fisher-z test with a level of thresholding, e.g., a p-value of 0.05. This step is known as skeleton detection. In the next step of V-structures determination, 


% The PC algorithm finds and orients the v-structures or colliders (i.e. $\mathrm{X} \rightarrow \mathrm{Y} \leftarrow \mathrm{Z}$ ) based on the d-separation set of node pairs (see Definition \ref{def-d-sep}). 
%In the final step of edge orientations, PC orients the remaining edges based on two aspects: i) availability of no new v-structures, and ii) not allowing any cycle formation. 


% Given the observational data, based on assumptions of acyclicity, causal faithfulness, and causal sufficiency, a PC algorithm can learn the causal graph up to a CPDAG. 
% Its computational complexity is of $\mathcal{O}(p^p)$ for $p$ as the number of nodes/variables in the data, and thus it is computationally more feasible for sparse graphs.  
% A number of testing-based learners have been developed over the past decades using the PC algorithm as a base learner to perform the CI tests, including the Fast Causal Inference (FCI) algorithm \citep{spirtes2013causal}, Really Fast Causal Inference (RFCI) \citep{colombo2012learning}, PC-stable \citep{colombo2014order}, etc. Recently, a number of follow-up works \citep[e.g.,][]{maathuis2009estimating,nandy2017estimating,chakrabortty2018inference} have been developed to estimate the causal graphs with multiple mediators in the linear SEM. 
% In summary, the testing-based method for identifying causal graphs, 
% %exemplified by the classical PC algorithm, 
% presents a nuanced balance of advantages and disadvantages in specific application situations. When applied in scenarios where noises are normally distributed and causal relationships among nodes are linear, this approach offers several benefits. Firstly, it provides p-values of local conditional independence tests, aiding in the construction of a causal graph. Secondly, it simplifies statistical inference on the estimated graph, ensuring robustness. Lastly, the results remain consistent regardless of data transformations, enhancing its reliability. 
% However, there are notable limitations. The method demands equal variances in noise for the identification of a unique graph. %, which can be a restrictive prerequisite. 
% Furthermore, it struggles in high-dimensional settings unless a strong assumption of sparsity is justifiable. Perhaps most significantly, the method is not equipped to handle non-linear relationships, as this greatly complicates conditional testing. 

%The PC algorithm, specifically, employs the Fisher-z test for conditional independence testing to determine the orientation of edges between nodes. This balanced view highlights the method's suitability for certain contexts, while acknowledging its constraints in more complex scenarios.


% \subsubsection{Decision Oriented Testing-based Learner}

% %Causal discovery attracts more and more attention recently to infer causal structure from data and disentangles the complex relationship among variables. 
% In this section, we detail a state-of-the-art type of causal discovery learner, based on conditional independent testings, so-called the testing-based learner. 
% To start with, we introduce the Peter-Clark (PC) Algorithm \citep{spirtes2000causation}, named by the first two authors, Pater and Clark, as one of the oldest testing-based (or constraint-based) algorithms for causal discovery. 
% To learn the underlying causal structure, this approach depends largely on conditional independence (CI) tests. If two variables are statistically independent or conditional independent, there is no causal link between them. Given the observational data, based on assumptions of acyclicity, causal faithfulness, and causal sufficiency, a PC algorithm can learn the causal graph up to a CPDAG.

% We specifically review the PC algorithm in the following three steps. In the first step, the PC algorithm starts with a fully connected undirected graph using all variables in the data. Then, it eliminates the edges based on unconditionally and conditionally independent pairs, given a certain testing procedure such as the Fisher-z test with a level of thresholding, e.g., a p-value of 0.05. This step is known as skeleton detection. In the next step of V-structures determination, 
% the PC algorithm finds and orients the v-structures or colliders (i.e. $\mathrm{X} \rightarrow \mathrm{Y} \leftarrow \mathrm{Z}$ ) based on the d-separation set of node pairs (see Definition \ref{def-d-sep}). In the final step of edge orientations, PC orients the remaining edges based on two aspects: i) availability of no new v-structures, and ii) not allowing any cycle formation. 
% Its computational complexity is of $\mathcal{O}(p^p)$ for $p$ as the number of nodes/variables in the data, and thus it is computationally more feasible for sparse graphs. 

% A number of testing-based learners have been developed over the past decades using the PC algorithm as a base learner to perform the CI tests, including the Fast Causal Inference (FCI) algorithm \citep{spirtes2013causal}, Really Fast Causal Inference (RFCI) \citep{colombo2012learning}, PC-stable \citep{colombo2014order}, etc. 
% In summary, the testing-based method for identifying causal graphs, exemplified by the classical PC algorithm, presents a nuanced balance of advantages and disadvantages in specific application situations. When applied in scenarios where noises are normally distributed and causal relationships among nodes are linear, this approach offers several benefits. Firstly, it provides p-values of local conditional independence tests, aiding in the construction of a causal graph. Secondly, it simplifies statistical inference on the estimated graph, ensuring robustness. Lastly, the results remain consistent regardless of data transformations, enhancing its reliability.

% However, there are notable limitations. The method demands equal variances in noise for the identification of a unique graph, which can be a restrictive prerequisite. Furthermore, it struggles in high-dimensional settings unless a strong assumption of sparsity is justifiable. Perhaps most significantly, the method is not equipped to handle non-linear relationships, as this greatly complicates conditional testing. The PC algorithm, specifically, employs the Fisher-z test for conditional independence testing to determine the orientation of edges between nodes. This balanced view highlights the method's suitability for certain contexts, while acknowledging its constraints in more complex scenarios.

% Application situations: 
    
% 1. The noises are normally distributed. 
% 2. The causal relationship among nodes is linear.

% Advantage of the learner:

% 1. Provide the p-value of local conditional independence tests to find a causal graph;
% 2. Easy to establish statistical inference on the estimated graph;
% 3. Results are invariant to data trasformation. 
    
% Disadvantage of the learner:

% 1. Require noises with equal variances for the identification of a unique graph;
% 2. Cannot handle high-dimensional nodes unless strong sparsity is reasonable;
% 3. Cannot handle non-linear cases due to hardness of conditional teatings. 


% The classical PC algorithm (Spirtes et al., 2000) proposes to leverage the Fisher-z test for conditional independence testing, in order to determine the orientation/direction of the edge between each pair of the nodes. The implementation is available through the py-causal package at %https://github.com/bd2kccd/py-causal, written in highly optimized Java codes. Also see examples here https://github.com/bd2kccd/py-causal/blob/development/example/py-causal%20-%20PC-ALL%20in%20Action.ipynb.


% \subsubsection{Decision Oriented Functional-based Learner}

% We next detail another type of causal discovery learner, stemming from the ICA-LiNGAM algorithm \citep{shimizu2006linear}, as a functional-based learner. 
% The Linear non-Gaussian Acyclic Model (LiNGAM) aims to uncover the causal structure when data is generated by the linear model in equation \eqref{lsem_x}.
% Given the assumption of non-Gaussianity, the causal direction is identifiable if the variables have a linear relation with non-Gaussian noises \citep{shimizu2006linear}. Similarly, from the observational data under additional assumptions of acyclicity, causal faithfulness, and causal sufficiency, the LiNGAM algorithm can learn the causal graph up to a CPDAG.
%  More specifically, the LiNGAM algorithm uses the independent component analysis (ICA) \citep{comon1994independent} that the predictor and regression residuals should be independent of each other to determine the causal links. 
%  Take two variables $X$ and $Y$ for example, with its causal structure model as $Y=X+\varepsilon$. Here, if $X$ and $\varepsilon$ are non-Gaussian, the predictor and regression residuals of $(Y$ given $X)$ should be independent of each other; while we see that for the regression in the anti-causal or backward direction $(X$ given $Y)$, the regression residual and the predictor are not independent as earlier. That is, for the non-Gaussian cases, independence between regression residual and predictor occurs only for the correct causal direction. 
% % There are 3 properties of the LiNGAM algorithm. First, the variables $x_i=x_1, x_2, \ldots, x_n$ are arranged in a causal order $k(i)$ such that the cause always preceedes the effect. Second, each variable $x_i$ is assigned a value as per the Equation 6 where $e_i$ is the noise/disturbance term and $b_{i j}$ denotes the causal strength between $x_i$ and $x_j$. Third, the exogenous noise $e_i$ follows a non-Gaussian distribution, with zero mean and non-zero variance, and are independent of each other which implies that there is no hidden confounder. 
% %Python implementation of the LiNGAM algorithm is available at https://github.com/cdt15/lingam as well as in the gCastle package (Zhang et al. (2021b)). 
% % Any standard ICA algorithm that can estimate independent components of many different distributions can be used in the LiNGAM to recover the weighted adjacency matrix, followed by thresholding the weights before outputting the inferred graph.  
% Its computational complexity is of $\mathcal{O}(p^3)$ for $p$ as the number of nodes/variables in the data. %, and thus it is computationally more feasible for sparse graphs. 
% % However, the original implementation uses the FastICA (Hyvarinen (1999)) algorithm.
% % $$
% % x_i=\sum_{k(j)<k(i)} b_{i j} x_j+e_i
% % $$
% % The ICA-LiNGAM algorithm assumes a linear non-Gaussian additive model (see the model in equation \eqref{lsem_x}) for data generating procedure and applies Independent Component Analysis (ICA) to recover the weighted adjacency matrix, followed by thresholding on the weights before outputting the inferred graph.
% There are many recent extensions for the functional-based learners, including handling the additive noise models \citep[e.g.,][]{hoyer2008nonlinear} (see the model in Equation \eqref{anm}), the Causal Additive Model (CAM) \citep{buhlmann2014cam}, and Causal Autoregressive Flow Models (CAREFL) \citep{huang2018neural}, etc. 
% The functional-based 
% %method for identifying causal graphs is particularly advantageous in specific application contexts and presents its own set of strengths and weaknesses. This 
% approach excels when dealing with non-Gaussian noises and when the functional form among nodes is predetermined. One of its primary advantages is the capability to handle non-linear causal graphs \citep[e.g.,][]{buhlmann2014cam} with non-Gaussian noises, making it suitable for a broader range of real-world scenarios. Additionally, this method allows for the unique identification of the graph in various cases, offering clarity and precision in analysis. Another benefit is the invariance of results to data transformation, ensuring consistent outcomes regardless of data manipulation. 
% Yet, the method is not without its drawbacks. A significant limitation is its inability to process data with Gaussian noises effectively, restricting its applicability in certain common statistical environments and conducting statistical inference. Furthermore, it requires prior knowledge of the functional form, necessitating a certain level of pre-existing understanding or hypothesis about the system being analyzed. %This prerequisite can limit its use in exploratory studies where such information is not readily available. %In summary, while the functional-based method is powerful in handling non-linear and non-Gaussian scenarios, its utility is constrained by its requirements for specific noise types and prior functional knowledge.

% \subsubsection{Decision Oriented Functional-based Learner}

% In the section, we detail another type of causal discovery learner, stemming from the ICA-LiNGAM algorithm \citep{shimizu2006linear}, as a functional-based learner.
% The Linear non-Gaussian Acyclic Model (LiNGAM) aims to uncover the causal structure when data is generated by the linear model in equation \eqref{lsem_x}.
% Given the assumption of non-Gaussianity, the causal direction is identifiable if the variables have a linear relation with non-Gaussian noises \citep{shimizu2006linear}. Similarly, from the observational data under additional assumptions of acyclicity, causal faithfulness, and causal sufficiency, the LiNGAM algorithm can learn the causal graph up to a CPDAG.
 

% More specifically, the LiNGAM algorithm uses the independent component analysis (ICA) \citep{comon1994independent} that the predictor and regression residuals should be independent of each other to determine the causal links. Take two variables $X$ and $Y$ for example, with its causal structure model as $Y=X+\varepsilon$. Here, if $X$ and $\varepsilon$ are non-Gaussian, the predictor and regression residuals of $(Y$ given $X)$ should be independent of each other; while we see that for the regression in the anti-causal or backward direction $(X$ given $Y)$, the regression residual and the predictor are not independent as earlier. That is, for the non-Gaussian cases, independence between regression residual and predictor occurs only for the correct causal direction. 
% % There are 3 properties of the LiNGAM algorithm. First, the variables $x_i=x_1, x_2, \ldots, x_n$ are arranged in a causal order $k(i)$ such that the cause always preceedes the effect. Second, each variable $x_i$ is assigned a value as per the Equation 6 where $e_i$ is the noise/disturbance term and $b_{i j}$ denotes the causal strength between $x_i$ and $x_j$. Third, the exogenous noise $e_i$ follows a non-Gaussian distribution, with zero mean and non-zero variance, and are independent of each other which implies that there is no hidden confounder. 
% %Python implementation of the LiNGAM algorithm is available at https://github.com/cdt15/lingam as well as in the gCastle package (Zhang et al. (2021b)). 
% Any standard ICA algorithm that can estimate independent components of many different distributions can be used in the LiNGAM to recover the weighted adjacency matrix, followed by thresholding the weights before outputting the inferred graph.  
% Its computational complexity is of $\mathcal{O}(p^3)$ for $p$ as the number of nodes/variables in the data.%, and thus it is computationally more feasible for sparse graphs. 
% % However, the original implementation uses the FastICA (Hyvarinen (1999)) algorithm.
% % $$
% % x_i=\sum_{k(j)<k(i)} b_{i j} x_j+e_i
% % $$

% % The ICA-LiNGAM algorithm assumes a linear non-Gaussian additive model (see the model in equation \eqref{lsem_x}) for data generating procedure and applies Independent Component Analysis (ICA) to recover the weighted adjacency matrix, followed by thresholding on the weights before outputting the inferred graph.

% There are many recent extensions for the functional-based learners, including handling the additive noise models \citep[e.g.,][]{hoyer2008nonlinear} (see the model in Equation \eqref{anm}), the Causal Additive Model (CAM) \citep{buhlmann2014cam}, and Causal Autoregressive Flow Models (CAREFL) \citep{huang2018neural}, etc. 
% The functional-based 
% %method for identifying causal graphs is particularly advantageous in specific application contexts and presents its own set of strengths and weaknesses. This 
% approach excels when dealing with non-Gaussian noises and when the functional form among nodes is predetermined. One of its primary advantages is the capability to handle non-linear causal graphs \citep[e.g.,][]{buhlmann2014cam} with non-Gaussian noises, making it suitable for a broader range of real-world scenarios. Additionally, this method allows for the unique identification of the graph in various cases, offering clarity and precision in analysis. Another benefit is the invariance of results to data transformation, ensuring consistent outcomes regardless of data manipulation.

% Yet, the method is not without its drawbacks. A significant limitation is its inability to process data with Gaussian noises effectively, restricting its applicability in certain common statistical environments. Furthermore, it requires prior knowledge of the functional form, necessitating a certain level of pre-existing understanding or hypothesis about the system being analyzed. This prerequisite can limit its use in exploratory studies where such information is not readily available. In summary, while the functional-based method is powerful in handling non-linear and non-Gaussian scenarios, its utility is constrained by its requirements for specific noise types and prior functional knowledge.


% The ICA-LiNGAM is implemented with default hyper-parameters through the lingam package for all settings. See their repository at https://github.com/cdt15/lingam.


% Application situations: 
    
% 1. The noises are non-Gaussian. 
% 2. The functional form among nodes is pre-specified.

% Advantage of the learner:

% 1. Handle non-linear causal graph with non-Gaussian noises;
% 2. Graph can be uniquely identified in various cases;
% 3. Results are invariant to data trasformation. 
    
% Disadvantage of the learner:

% 1. Cannot handle data with Gaussian noises;
% 2. Require prior knowledge on the functional form. 


% \subsubsection{Decision Oriented Score-based Learner}\label{se:iden_dag}


Next, we focus on another type of causal discovery approach, the score-based methods, including greedy equivalence search ~\citep{chickering2002optimal,ramsey2017million,huang2018generalized} and acyclicity optimization methods~\citep{zheng2018dags,yu2019dag,zhu2019causal,lachapelle2019gradient,cai2020anoce,zheng2020learning,vowels2021d}. In the following, we detail a score-based learner, NOTEARS \citep{zheng2018dags} as an example and extend to recent decision-oriented \acrshort{CSL} methods.  \citet{zheng2018dags}  constructed an optimization with an acyclicity constraint under the \acrshort{LSEM}, i.e. the NOTEARS. A follow-up work using a variational autoencoder parameterized by a graph neural network that generalizes \acrshort{LSEM} was proposed in \citet{yu2019dag} with a more computational-friendly constraint, namely DAG-GNN. Also, see \citet{zhu2019causal} and \citet{lachapelle2019gradient} for other cutting-edge score-based structural learning methods. Yet, these methods cannot be directly applied to decision-oriented causal graphs.
To address this challenge, \citet{cai2020anoce}
considered a new constrained structural learning, by incorporating the background knowledge (the temporal causal relationship among variables) into the score-based algorithms. They formulated such prior information as the identification constraint and added it as the penalty term in the objective function for the causal discovery. In the following, we typically detail the NOTEARS for an illustration, which can be easily extended to other score-based algorithms. Specifically, we can write the linear structural model in Equation \eqref{lsem_x} under the causal sufficiency assumption without states as an example as
\begin{eqnarray}\label{lsem}
\begin{bmatrix}

   			A\\
   			\boldsymbol{M}\\
			R\\
		\end{bmatrix}
		=\boldsymbol{B}^\top \begin{bmatrix}
   			A\\
   			\boldsymbol{M}\\
			R\\
		\end{bmatrix}+\epsilon
		=\begin{bmatrix}
   			0& \textbf{0}_{p\times1} &0\\
			\boldsymbol{\alpha}&B_M^\top&0\\
   			\gamma&\boldsymbol{\beta}^\top&0\\
		\end{bmatrix}
		\begin{bmatrix}
   			A\\
   			\boldsymbol{M}\\
			R\\
		\end{bmatrix}
		+\begin{bmatrix}
   			\epsilon_A\\
   			\epsilon_{M_p}\\
			\epsilon_R\\
		\end{bmatrix},
\end{eqnarray}
where $\gamma$ is a scalar, $\boldsymbol{\alpha}$, $\boldsymbol{\beta} $, and $\textbf{0}_{p\times1}$ are $p\times 1$ vectors, $B_M$ is a $p\times p$ matrix, and $\epsilon\equiv [\epsilon_A,\epsilon_{M}^\top, \epsilon_R]^\top $. Here, $\gamma$ presents the weight of the edge $A\rightarrow R$, the $i$-th element of $\boldsymbol{\alpha}$ corresponds to the weight of the edge $A\rightarrow M_i$, and the  $i$-th element of $\boldsymbol{\beta} $ is the weight of the edge $M_i \rightarrow R$. Note that by the causal Sufficiency assumption, we have the exposure $A$ has no parents and the outcome $R$ has no descendants, so equivalently, the first row and the last column of $\boldsymbol{B}^\top$ are all zeros (i.e., the first column and the last row of $\boldsymbol{B}$ are all zeros). 
%In a similar vein, from the observational data with additional assumptions of acyclicity, causal faithfulness, and causal sufficiency, the NOTEARS algorithm can only recover a CPDAG. Relying on the linear structural equation model (LSEM) in Equation \eqref{lsem_x}, NOTEARS aims 
To estimate the weighted adjacency matrix $B$, %where $\epsilon$ is a  random vector of jointly independent error variables. To this end, 
the score-based learners formulate the acyclicity constraint \citep{yu2019dag,zheng2018dags}  as 
$    h_1(\boldsymbol{B})\equiv \text{tr}\big[(I_{d+1}+t \boldsymbol{B} \circ \boldsymbol{B})^{d+1}\big]-(d+1)=0 $, 
where $I_{d+1}$ is a $d+1$-dimensional identity matrix, and $\text{tr}(\cdot)$ is the trace of a matrix and $t$ is a hyperparameter that depends on the estimated largest eigenvalue of $\boldsymbol{B}$. 
The task of learning DAG is transformed into a constrained optimization problem with the loss by the augmented Lagrangian as
% \begin{eqnarray}\label{loss1}
$L(\boldsymbol{B},\theta,\lambda)=f(\boldsymbol{B},\theta)+\lambda h_1(\boldsymbol{B})$, 
% \end{eqnarray}
where $f(\boldsymbol{B},\theta)$ is some loss such as the least square error in NOTEARS \citep{zheng2018dags} or the Kullback-Leibler divergence in DAG-GNN \citep{yu2019dag} with parameters $\theta$, and $\lambda$ is the Lagrange multiplier.  
Other causal structural leaning algorithms \citep[see e.g.,][]{spirtes2000constructing,chickering2002optimal,shimizu2006linear,kalisch2007estimating,buhlmann2014cam,ramsey2017million,zhu2019causal} can also be applied by formulating the corresponding score or loss function. 

In order for $\boldsymbol{B}$ to satisfy  structural constraints under decision-oriented \acrshort{CSL}, such as $g_1(\boldsymbol{B})$ to $ g_3(\boldsymbol{B})$ (see Section \ref{sec:assum_csl}), it must satisfy: $
h_2(\boldsymbol{B}) =\sum_{i=1}^3 g_i(\boldsymbol{B}) =0.$ As remarked earlier, more structural constraints can be added and any added would be included in $h_2(\boldsymbol{B})$. Combining the two constraints above ($h_1$ and $h_2$) yields the following objective loss by an augmented Lagrangian 
\citep{cai2020anoce}, 
\begin{align*}
    L(\boldsymbol{B},\theta) = f(\boldsymbol{B},\theta) + \lambda_1 h_1(\boldsymbol{B})  +  \lambda_2 h_2(\boldsymbol{B}) + c|h_1(\boldsymbol{B})|^2 + d|h_2(\boldsymbol{B})|^2,
\end{align*}
where model parameter $\theta$, $\lambda_1$ and $\lambda_2$ are Lagrange multipliers, and $c$ and $d$ are tuning parameters to ensure a hard constraint on $h_1$ and $h_2$. 

% The computational complexity of NOTEARS is $\mathcal{O}(p^3)$ where $p$ is the number of nodes following \citet{zheng2018dags}. Refer to \citep{yu2019dag,zhu2019causal,lachapelle2019gradient,zheng2020learning,cai2020anoce,vowels2021d} for additional cutting-edge score-based learners.
%  %The score-based method for causal graph identification presents a set of advantages and disadvantages, particularly suited for specific application contexts. 
%  This type of method is well-suited for scenarios involving moderate or high-dimensional nodes and when the causal model or the nature of the noises is unknown. A key advantage of this approach is its ability to handle general causal graphs with a variety of noise types, making it highly versatile. Additionally, it offers the potential for unique graph identification in various cases, providing clarity in complex scenarios. Another significant benefit is its computational efficiency, especially in high-dimensional settings, which is crucial for handling large datasets. 
% However, a notable drawback of the score-based method is that its results are not invariant to data transformation. This limitation means that the outcome of the analysis can vary with changes in the scale or form of the data, potentially leading to inconsistencies in interpretation or the need for careful data preprocessing. %In summary, while the score-based method is flexible and efficient for high-dimensional and complex causal analysis, its sensitivity to data transformation requires careful consideration in its application.

% \subsubsection{Decision Oriented Score-based Learner}\label{se:iden_dag}


% In the section, we focus on the third class, the score-based methods, including greedy equivalence search (GES)~\citep{chickering2002optimal,ramsey2017million,huang2018generalized} and acyclicity optimization methods~\citep{zheng2018dags,yu2019dag,zhu2019causal,lachapelle2019gradient,cai2020anoce,zheng2020learning,vowels2021d}. 
% In the following, we detail a score-based learner, NOTEARS \citep{zheng2018dags} as an example.
% In a similar vein, from the observational
% data with additional assumptions of acyclicity, causal faithfulness, and causal sufficiency, the
% NOTEARS algorithm can only recover a CPDAG. Relying on the linear structural equation model (LSEM) in Equation \eqref{lsem_x}, NOTEARS aims to estimate the weighted adjacency matrix $B$ where $\epsilon$ is a  random vector of jointly independent error variables. To this end, the score-based learners formulate the acyclicity constraint \citep{yu2019dag,zheng2018dags}  as 
% \begin{equation*}
%     h(\boldsymbol{B})\equiv \text{tr}\big[(I_{d+1}+t \boldsymbol{B} \circ \boldsymbol{B})^{d+1}\big]-(d+1)=0,
% \end{equation*}
% where $I_{d+1}$ is a $d+1$-dimensional identity matrix, and $\text{tr}(\cdot)$ is the trace of a matrix and $t$ is a hyperparameter that depends on the estimated largest eigenvalue of $\boldsymbol{B}$. 
% The task of learning DAG is transformed into a constrained optimization problem with the loss by the augmented Lagrangian as
% \begin{eqnarray}\label{loss1}
% L(\boldsymbol{B},\theta,\lambda)=f(\boldsymbol{B},\theta)+\lambda h(\boldsymbol{B}),
% \end{eqnarray}
% where $f(\boldsymbol{B},\theta)$ is some loss such as the least square error in NOTEARS \citep{zheng2018dags} or the Kullback-Leibler divergence in DAG-GNN \citep{yu2019dag} with parameters $\theta$, and $\lambda$ is the Lagrange multiplier. Other causal structural leaning algorithms \citep[see e.g.,][]{spirtes2000constructing,chickering2002optimal,shimizu2006linear,kalisch2007estimating,buhlmann2014cam,ramsey2017million,zhu2019causal} can also be applied by formulating the corresponding score or loss function. The computational complexity of NOTEARS is $\mathcal{O}(p^3)$ where $p$ is the number of nodes following \citet{zheng2018dags}. 
% Refer to \citep{yu2019dag,zhu2019causal,lachapelle2019gradient,cai2020anoce,zheng2020learning,vowels2021d} for additional cutting-edge score-based learners.

% The score-based method for causal graph identification presents a set of advantages and disadvantages, particularly suited for specific application contexts. This method is well-suited for scenarios involving moderate or high-dimensional nodes and when the causal model or the nature of the noises is unknown. A key advantage of this approach is its ability to handle general causal graphs with a variety of noise types, making it highly versatile. Additionally, it offers the potential for unique graph identification in various cases, providing clarity in complex scenarios. Another significant benefit is its computational efficiency, especially in high-dimensional settings, which is crucial for handling large datasets.

% However, a notable drawback of the score-based method is that its results are not invariant to data transformation. This limitation means that the outcome of the analysis can vary with changes in the scale or form of the data, potentially leading to inconsistencies in interpretation or the need for careful data preprocessing. In summary, while the score-based method is flexible and efficient for high-dimensional and complex causal analysis, its sensitivity to data transformation requires careful consideration in its application.

% Application situations: 
    
% 1. Moderate or high-dimensional nodes;
% 2. Unknown causal model or noises.

% Advantage of the learner:

% 1. Handle general causal graph with general noises;
% 2. Graph can be uniquely identified in various cases;
% 3. Computational fast in high-dimensional setting.
    
% Disadvantage of the learner:

% 1. Results is not invariant to data trasformation. 


\subsubsection{Model Identifiablities}\label{sec:iden_dag}

In the absence of further assumptions regarding the form of functions and/or noises, the model in \eqref{lsem_x} can only be identified up to \acrshort{MEC} following the Markov and faithful assumptions \citep{spirtes2000constructing,peters2014causal}. Below, we explore the conditions for the unique identifiability of the DAG and potential strategies for addressing scenarios involving the \acrshort{MEC}. More specifically, a general causal \acrshort{DAG}, $\mathcal{G}$, may not be identifiable from the distribution of $\boldsymbol{X}$. According to \cite{pearl2000causality}, a \acrshort{DAG} only encodes conditional independence relationships through the concept of $d$-separation. In general, several \acrshort{DAG}s can encode the same conditional independence relationships, and such \acrshort{DAG}s form a Markov equivalence class. Two \acrshort{DAG}s belong to the same Markov equivalence class if and only if they have the same skeleton and the same v-structures \citep{kalisch2007estimating}. A Markov equivalence class of DAGs can be uniquely represented by a \acrfull{CPDAG} \citep{spirtes2000constructing}, which is a graph that can contain both directed and undirected edges. A \acrshort{CPDAG} satisfies the following: $X_i \leftrightarrow X_j$ in the \acrshort{CPDAG} if the Markov equivalence class contains a \acrshort{DAG} including $X_i \rightarrow X_j$, as well as another \acrshort{DAG} including $X_j \rightarrow X_i$. The Markov equivalence class for a fixed CPDAG $\mathcal{C}$ is denoted by $\operatorname{MEC}(\mathcal{C})$, which is a set containing all \acrshort{DAG}s $\mathcal{G}$ that have the \acrshort{CPDAG} structure $\mathcal{C}$. 
% In general, if the error distribution is joint Gaussian with different diagonal elements in the LSEM satisfying our structure assumption, the data distribution can only give a CPDAG and thus a MEC \citep{shimizu2006linear}. In the linear setting, however, if the error distribution is non-Gaussian, the distribution of $X$ will completely give a unique DAG; see Theorem 11.4 in \cite{neal2020introduction}. Since in practice we usually do not know whether the error is Gaussian, it is safer to assume that we can only obtain a CPDAG instead of a DAG from the data. 
If we can obtain the true DAG from the data, we can simply treat it as a special case of the ``\acrshort{MEC}'' containing only this \acrshort{DAG}, i.e., $\operatorname{MEC}(\mathcal{G})= \{ \mathcal{G} \}$. %For simplicity, we denote the corresponding causal structure for the mediators $M$ as $\mathcal{G}_M$, which can be obtained by deleting nodes $C, A, Y$, and the corresponding edges from $\mathcal{G}$. 
% Specially, we denote the causal structure of mediators as $\mathcal{G}_{M}$. 
% Obviously, the adjacency matrix $\mathcal{G}_{M}$ satisfies $\mathcal{G}_{M} = \big[ \mathcal{{G}}_{kk} \big]_{k \in \{ t + 1, \ldots, t + p\}}$. 
% The CPDAG of mediators is similarly denoted as $\mathcal{C}_M$. For simplicity and with a minor stretch of notation, we employ $\mathcal{G}_{M}$ and $\mathcal{C}_M$ to denote the causal DAG and CPDAG of $X$, respectively, such that their corresponding mediators' causal DAG and CPDAG are represented by $\mathcal{G}_{M}$ and $\mathcal{C}_M$ exactly. 

Initially, we consolidate cases where the DAG is uniquely identifiable. In the context of the \acrshort{LSEM}, when the noises $\boldsymbol{\epsilon}$ follow a Gaussian distribution, the resulting model corresponds to the standard linear-Gaussian model class, as investigated in \citet{spirtes2000constructing} and \citet{peters2017elements}. In instances where the noises $\boldsymbol{\epsilon}$ maintain equal variances, according to \citet{peters2014identifiability}, the \acrshort{DAG} $\mathcal{G}$ can be uniquely identified from observational data. Further, when the functions are linear but the noises are non-Gaussian, one can derive the LiNGAM as described in \citet{shimizu2006linear}, where the true \acrshort{DAG} can be uniquely identified under certain favorable conditions. In addition, as cited in \citet{zheng2020learning,rolland2022score}, the nonlinear additive model can be identified from observational data. Another scenario of note arises when the corresponding \acrshort{MEC} encompasses only one \acrshort{DAG}; here, the \acrshort{DAG} can be inherently identified from observational data. Recent score-based causal discovery algorithms \citep{zheng2018dags,yu2019dag,zhu2019causal,cai2020anoce} typically take into account synthetic datasets generated from fully identifiable models, which provides practical relevance in evaluating the estimated graph in relation to the true \acrshort{DAG}.

In instances where the true \acrshort{DAG} is not identifiable, a \acrshort{CPDAG} uniquely symbolizes a MEC of DAGs that yield the same joint distribution of variables. This \acrshort{CPDAG} can be inferred from observational data via a variety of causal discovery algorithms \citep[see e.g.,][]{spirtes2000constructing,chickering2002optimal,shimizu2006linear,kalisch2007estimating,harris2013pc,buhlmann2014cam,ramsey2017million,zhang2018non}. One feasible approach to dealing with \acrshort{MEC} involves enumerating all \acrshort{DAG}s in the \acrshort{MEC} derived from a given \acrshort{CPDAG} \citep{chakrabortty2018inference}. It is conventional to encapsulate a range of potential effects or probabilities by their average or the minimum absolute value \citep{chakrabortty2018inference,shi2021testing}. However, such an approach typically proves computationally prohibitive for large graphs, necessitating computational shortcuts to acquire the causal effects or probabilities of causation without enumerating all \acrshort{DAG}s in the \acrshort{MEC} of the estimated \acrshort{CPDAG}. With the additional identification constraints in the decision-oriented \acrshort{CSL}, the size of \acrshort{MEC} is smaller and thus easier to uniquely identify based on the observational data.

 



\subsubsection{Decision-Oriented Causal Mediation Analysis}\label{sec:med_dag} %for decision making}
%treatment embedded

%In the era of the causal revolution, identifying the causal effect of exposure on the outcome of interest is an important problem in many areas. Under a general causal graph, the exposure may have a direct effect on the outcome and also an indirect effect regulated by a set of mediators. An analysis of causal effects that interprets the causal mechanism contributed through mediators is hence challenging but on demand. 

Causal mediation analysis holds significant importance in causal decision-making, particularly due to its ability to interpret causal mechanisms through mediators. This analysis is challenging yet highly sought after as it effectively bridges the gap between \acrshort{CSL} and \acrshort{CEL}. The integration of causal mediation analysis into decision-making processes enables a deeper understanding of how different variables and interventions interact and influence each other, leading to more informed and effective decisions. Another key motivation behind the use of causal mediation analysis is its role in \acrshort{CPL}. By understanding the pathways through which causal effects are transmitted, policymakers and researchers can develop more nuanced and effective strategies.
Identifying the causality among variables enables us to understand the key factors that influence the target variable, quantify the causal effect of an exposure on the outcome of interest, and use these effects to further guide downstream machine-learning tasks. %The approach offers a more comprehensive understanding of causal structures and effects, facilitating the development of policies that target the most influential mediators. 
% Moreover, the debate between joint modeling/end-to-end procedures and two-step procedures in causal analysis is pertinent here. Causal mediation analysis often requires sophisticated methodologies that can handle the complexity of real-world data and decision-making scenarios. This includes considering how to best model the interactions between variables and the sequential nature of decision processes. Ultimately, the choice of methodology can significantly impact the effectiveness and applicability of the findings in practical decision-making contexts.



%An analysis of causal effects that interprets the causal mechanism contributed through mediators is hence challenging but on demand, and naturally bridged the gap between causal structural learning and causal effect learning, and learned results further served as the middle step for causal policy learning. 

% \textbf{+CPL for CSL\\
% + joint modeling / end-to-end v.s. two-step procedure.\\
% bringing the gap between csl+sel}

% \bigskip
% \bigskip




 

% Analysis of Causal Effects with Causal Discovery

 
To visualize causes and counterfactuals, \citet{pearl2009causal} proposed to use the causal graphical model and the `do-operator' to quantify the causal effects. A number of follow-up works \citep[e.g.,][]{maathuis2009estimating,nandy2017estimating,chakrabortty2018inference} have been developed recently to estimate direct and indirect causal effects that are regulated by mediators in the linear SEM. These studies relied on the PC algorithm \citep{spirtes2000constructing} which requires strong assumptions of graph sparsity and noise normality due to computational limits. To overcome these difficulties,  \citet{cai2020anoce} proposed to leverage score-based \acrshort{CSL} methods \citep[e.g.,][]{ramsey2017million,zheng2018dags,yu2019dag,zhu2019causal} with background causal knowledge to estimate mediation effects. %These works assumed no moderator in their linear SEMs, such that the causal graph or effect learned is on the population level, and thus cannot access the heterogeneity.  
 In the following, we detail the \acrfull{ANOCE} \citep{cai2020anoce}.   
% Analysis of Causal Effects from Treatment
Let $A$ be the exposure/treatment, $\mathbf{M}=[M_1,M_2,\cdots,M_p]^\top $ be mediators with dimension $p$, and $R$ be the outcome of interest. Suppose there exists a weighted \acrshort{DAG} $\mathcal{G}=(\mathbf{Z},B)$ that characterizes the causal relationship among $\mathbf{Z}=[A, \mathbf{M}^\top, R]^\top $, where the dimension of $\mathbf{Z}$ is $d=p+2$.  We next give the \acrlong{TE} ($TE$), the natural \acrlong{DE} that is not mediated by mediators ($DE$), and the natural \acrlong{IE} that is regulated by mediators ($IE$) defined in Pearl (2009).
\begin{equation*}
\begin{split}
TE &={\partial E\{R|do(A=a)\} / \partial a}= E\{R|do(A=a+1)\}-E\{R|do(A=a)\},\\
DE &= E\{R|do(A=a+1, \mathbf{M}=\mathbf{m}^{(a)})\}-E\{R|do(A=a)\},\\
IE &= E\{R|do(A=a, \mathbf{M}=\mathbf{m}^{(a+1)})\}-E\{R|do(A=a)\},
\end{split}
\end{equation*}
where $do(A=a)$ is a mathematical operator to simulate physical interventions that hold $A$ constant as $a$ while keeping the rest of the model unchanged, which corresponds to removing edges into $A$ and replacing $A$ by the constant $a$ in $\mathcal{G}$. Here,  $\mathbf{m}^{(a)}$ is the value of $\mathbf{M}$ if setting $do(A=a)$, and $\mathbf{m}^{(a+1)}$ is the value of $\mathbf{M}$ if setting $do(A=a+1)$. Refer to \citet{pearl2009causal} for more details of `do-operator'. 
% ### Analysis of Causal Effects from Mediators
First, we will define the natural direct effect of an individual mediator ($DM$). 
\begin{eqnarray*}
    &&DM_i=  \Big[E\{M_i|do(A=a+1)\}-E\{M_i|do(A=a)\}\Big] \\
&&~~~~~~~~\times \Big[E\{R|do(A=a, M_i=m^{(a)}_i+1, \Omega_i=o^{(a)}_i)\}- E\{R|do(A=a)\}\Big], 
\end{eqnarray*}  
% DM_i=  \Big[E\{M_i|do(A=a+1)\}-E\{M_i|do(A=a)\}\Big] \\
% \times \Big[E\{R|do(A=a, M_i=m^{(a)}_i+1, \Omega_i=o^{(a)}_i)\}- E\{R|do(A=a)\}\Big], 
% \end{equation}
where $m^{(a)}_i$ is the value of $ M_i$ when setting $do(A=a)$, $\Omega_i=\mathbf{M}\setminus M_i$ is the set of mediators except $M_i$, and $o^{(a)}_i$ is the value of $\Omega_i$ when setting $do(A=a)$. 
The natural indirect effect for an individual mediator ($IM$) can be defined similarly.
\begin{eqnarray*}
    &&\label{def_IM} 
IM_i= \Big[E\{M_i|do(A=a+1)\}-E\{M_i|do(A=a)\}\Big] \\
&&~~~~~~~~ \times \Big[E\{R|do(A=a, M_i=m^{(a)}_i+1)\}-E\{R|do(A=a, M_i=m^{(a)}_i+1, \Omega_i=o^{(a)}_i)\}\Big]. 
\end{eqnarray*}  



% ### Table of Analysis of Causal Effects

Based on the result $TE = DE+ IE$ in Pearl (2009) and the above definitions, we summarize the defined causal effects and their relationship in Table \ref{anoce_table} for the \acrfull{ANOCE}. Firstly, the causal effect of $A$ on $Y$ has two sources, the direct effect from $A$ and the indirect effect via $p$ mediators $\mathbf{M}$ ($M_1,\cdots, M_p$). Next, the direct source has the degree of freedom ($d.f.$) as 1, while the indirect source has $d.f.$ as $p$ from $p$ mediators. Note the true $d.f.$ of the indirect effect may be smaller than $p$, since $A$ may not be regulated by all mediators. Then, the causal effect for the direct source is the $DE$ and for the indirect source is the $IE$, where the $IE$ can be further decomposed into $p$ $DM$s and each component corresponds to the natural direct effect for a specific mediator. The last row in the table shows that the $DE$ and the $IE$ compose the total effect $TE$ with $d.f.$ as $p+1$. 
The ANOCE-CVAE learner \citep{cai2020anoce} is a constrained \acrshort{CSL} method by incorporating a novel identification constraint that specifies the temporal causal relationship of variables. The above decision-oriented causal mediation analysis involves causal structure with possibly multiple mediators under the structural equation model. In Section \ref{sec:sel_med}, we will detail the semi-parametric efficient estimation of mediation effects with a single mediator in the framework of causal effect learning.

\begin{table}[!t]
\centering
\caption{Table of Analysis of Causal Effects (\acrshort{ANOCE} Table).}
\label{anoce_table}
%\vspace{-0.35cm}
\scalebox{1}{
\begin{tabular}{ccc}
\toprule
Source                  & Degree of freedom    & Causal effects   \\ 
\hline
Direct effect from $A$      & 1           & $DE$           \\
%&&\\
Indirect effect via $M$    & $p$       & $IE$          \\
$\quad \quad \quad   \quad \quad \quad \quad \quad \quad \quad \quad 
	\left\{\begin{array}{ll}
		M_1\\
		M_2\\
		\vdots\\
		M_p\\
	\end{array}
	\right.
$&
$\quad \quad \quad  
	\left\{\begin{array}{ll}
		1\\
		1\\
		\vdots\\
		1\\
	\end{array}
	\right.
$&
$\quad \quad \quad \quad \quad 
	\left\{\begin{array}{ll}
		DM_1\\
		DM_2\\
		\vdots\\
		DM_p\\
	\end{array}
	\right.
$\\
\hline
Total                     & $1+p$           & $TE$          \\
\bottomrule
\end{tabular}}
\end{table}

\subsection{Decision-Oriented Causal Discovery for Paradigm 1+}

Recent advances in causal discovery for time series data have significantly pushed the boundaries of this field to non-i.i.d. settings. Traditional methods like Granger causality \citep{Granger1969} have been supplemented by more sophisticated techniques that address nonlinearity and high dimensionality. The PCMCI algorithm, as developed by \cite{Runge2019}, represents a notable advance, effectively dealing with complex dependencies in time series data. Furthermore, machine learning approaches have shown promise, particularly Gaussian process-based methods for non-linear causal inference \citep{LopezPaz2017}. More recently, the development of deep learning frameworks such as the \acrfull{TCDF} has offered novel insights by identifying cause-effect relationships through attention mechanisms \citep{Nauta2019}. Additionally, the integration of transfer entropy with deep learning models has opened new avenues for understanding causal dynamics in multivariate series \citep{Tank2021}. These innovations have not only improved the accuracy of causal analyses but have also broadened their applicability in real-world scenarios. However, to the best of our knowledge, none of these works consider the treatment or decision in their setting, leaving the decision-oriented causal discovery for Paradigms 2 and 3 still a missing piece in the existing literature.

%The code is publicly available at an anonymous repository at https://github.com/anoce-cvae/ANOCE-CVAE.
%The proposed algorithm is applied to investigate the causal effects of 2020 Hubei lockdowns on reducing the spread of the coronavirus in Chinese major cities out of Hubei.


% \subsection{Benchmark Datasets}

% \subsubsection{Spread of COVID-19}

% In the era of the causal revolution, identifying the causal effect of exposure on the outcome of interest is an important problem in many areas. Under a general causal graph, the exposure may have a direct effect on the outcome and also an indirect effect regulated by a set of mediators (or intermediate variables). For instance, during the outbreak of Coronavirus disease 2019 (COVID-19), the Chinese government has taken extreme measures to stop the virus from spreading such as locking Wuhan down on Jan 23rd, 2020, followed by 12 other cities in Hubei, known as the ``2020 Hubei lockdowns”. This approach (viewed as the exposure), directly blocked infected people leaving from Hubei; and also stimulated various quarantine measures taken by cities outside of Hubei (as the mediators), which further decreased the migration countrywide in China, and thus indirectly controlled the spread of COVID-19. Quantifying the causal effects of the 2020 Hubei lockdowns on reducing the COVID-19 spread regulated by different cities outside Hubei is challenging but of great interest for the current COVID-19 crisis. An analysis of causal effects that interprets the causal mechanism contributed via individual mediators is thus very important.

% \subsubsection{Gene Expression Traits in Yeast}

% Over recent decades, the causal discovery has attracted more and more attention by disentangling the complex causal relationship in various fields. Compared to 4 to 5 million single nucleotide polymorphisms (SNPs) in a person’s genome, much fewer non-spurious genes/proteins that systematically regulate the expression of the phenotype of interest are identified. We focus on a real application of gene expression traits in yeast (Brem \& Kruglyak, 2005) to discover important causal features in explaining the gene expression of interest. This dataset collected 104 yeast segregants simulated by two genetically diverse strains, BY4716 and RM11-1a, and each segregant contains thousands of genotypes that contribute to rich phenotypic diversity. A primary goal in genetics is to study how different genotypes influence the target heritable traits of interest. Due to high-dimensional genes, formally named quantitative trait loci (QTLs), involved in this study, identifying a more parsimonious causal graph is desired to reveal the true necessary dependencies that present the essential causality towards the outcome of interest. In this study, we are interested in identifying the genes whose expression levels affect the genetic variant YER124C, which is a daughter cell-specific protein, that may participate in pathways regulating cell wall metabolism; deletion affects cell separation after division and sensitivity to drugs targeted against the cell wall.



% To address this open question, 

%\subsection{Extensions and Discussions}

% \begin{enumerate}
%     \item to bandits: CEL for online decision making (specifically for CEL) in cumulative reward
%     \item Extensions and Discussions
% \end{enumerate}