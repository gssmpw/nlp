@article{alon1997finding,
  title={Finding and counting given length cycles},
  author={Alon, Noga and Yuster, Raphael and Zwick, Uri},
  journal={Algorithmica},
  volume={17},
  number={3},
  pages={209--223},
  year={1997},
  publisher={Springer}
}

@article{bo2023specformer,
  title={Specformer: Spectral graph neural networks meet transformers},
  author={Bo, Deyu and Shi, Chuan and Wang, Lele and Liao, Renjie},
  journal={arXiv preprint arXiv:2303.01028},
  year={2023}
}

@article{choi2024topology,
  title={Topology-Informed Graph Transformer},
  author={Choi, Yun Young and Park, Sun Woo and Lee, Minho and Woo, Youngho},
  journal={arXiv preprint arXiv:2402.02005},
  year={2024}
}

@article{flum2004parameterized,
  title={The parameterized complexity of counting problems},
  author={Flum, J{\"o}rg and Grohe, Martin},
  journal={SIAM Journal on Computing},
  volume={33},
  number={4},
  pages={892--922},
  year={2004},
  publisher={SIAM}
}

@article{giscard2019general,
  title={A general purpose algorithm for counting simple cycles and simple paths of any length},
  author={Giscard, Pierre-Louis and Kriege, Nils and Wilson, Richard C},
  journal={Algorithmica},
  volume={81},
  pages={2716--2737},
  year={2019},
  publisher={Springer}
}

@inproceedings{graziani2023no,
  title={No PAIN no Gain: More Expressive GNNs with Paths},
  author={Graziani, Caterina and Drucks, Tamara and Bianchini, Monica and Scarselli, Franco and G{\"a}rtner, Thomas and others},
  booktitle={NeurIPS 2023 Workshop: New Frontiers in Graph Learning},
  year={2023}
}

@inproceedings{he2023generalization,
  title={A generalization of vit/mlp-mixer to graphs},
  author={He, Xiaoxin and Hooi, Bryan and Laurent, Thomas and Perold, Adam and LeCun, Yann and Bresson, Xavier},
  booktitle={International conference on machine learning},
  pages={12724--12745},
  year={2023},
  organization={PMLR}
}

@article{johnson1975finding,
  title={Finding all the elementary circuits of a directed graph},
  author={Johnson, Donald B},
  journal={SIAM Journal on Computing},
  volume={4},
  number={1},
  pages={77--84},
  year={1975},
  publisher={SIAM}
}

@inproceedings{luo2024enhancing,
  title={Enhancing Graph Transformers with Hierarchical Distance Structural Encoding},
  author={Luo, Yuankai and Li, Hongkang and Shi, Lei and Wu, Xiao-Ming},
  booktitle={The Thirty-eighth Annual Conference on Neural Information Processing Systems},
  year={2024}
}

@inproceedings{michel2023path,
  title={Path neural networks: Expressive and accurate graph neural networks},
  author={Michel, Gaspard and Nikolentzos, Giannis and Lutzeyer, Johannes F and Vazirgiannis, Michalis},
  booktitle={International Conference on Machine Learning},
  pages={24737--24755},
  year={2023},
  organization={PMLR}
}

@article{perepechko2009number,
  title={The number of fixed length cycles in an undirected graph. Explicit formulae in case of small lengths},
  author={Perepechko, SN and Voropaev, AN},
  journal={Mathematical Modeling and Computational Physics (MMCP2009)},
  volume={148},
  year={2009}
}

@article{rampavsek2022recipe,
  title={Recipe for a general, powerful, scalable graph transformer},
  author={Ramp{\'a}{\v{s}}ek, Ladislav and Galkin, Michael and Dwivedi, Vijay Prakash and Luu, Anh Tuan and Wolf, Guy and Beaini, Dominique},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={14501--14515},
  year={2022}
}

@inproceedings{shirzad2023exphormer,
  title={Exphormer: Sparse transformers for graphs},
  author={Shirzad, Hamed and Velingker, Ameya and Venkatachalam, Balaji and Sutherland, Danica J and Sinop, Ali Kemal},
  booktitle={International Conference on Machine Learning},
  pages={31613--31632},
  year={2023},
  organization={PMLR}
}

@inproceedings{topping2022understanding,
title={Understanding over-squashing and bottlenecks on graphs via curvature},
author={Jake Topping and Francesco Di Giovanni and Benjamin Paul Chamberlain and Xiaowen Dong and Michael M. Bronstein},
booktitle={International Conference on Learning Representations},
year={2022},
url={https://openreview.net/forum?id=7UmjRGzp-A}
}

@article{vaswani2017attention,
  title={Attention is all you need},
  author={Vaswani, A},
  journal={Advances in Neural Information Processing Systems},
  year={2017}
}

@article{wu2021representing,
  title={Representing long-range context for graph neural networks with global attention},
  author={Wu, Zhanghao and Jain, Paras and Wright, Matthew and Mirhoseini, Azalia and Gonzalez, Joseph E and Stoica, Ion},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={13266--13279},
  year={2021}
}

@article{ying2021transformers,
  title={Do transformers really perform badly for graph representation?},
  author={Ying, Chengxuan and Cai, Tianle and Luo, Shengjie and Zheng, Shuxin and Ke, Guolin and He, Di and Shen, Yanming and Liu, Tie-Yan},
  journal={Advances in neural information processing systems},
  volume={34},
  pages={28877--28888},
  year={2021}
}

