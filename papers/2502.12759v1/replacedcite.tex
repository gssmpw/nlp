\section{Related Work}
\label{sec:related-work}

\textbf{Neural Vocoders.} There has been a long line of work on synthesizing realistic audio signals. The predominant approach has been to leverage a two-stage synthesis by first generating an intermediate representation such as a mel spectrogram, and then synthesizing the audio waveform given the intermediate representation. The Griffin-Lim algorithm____ was an early approach to synthesize audio by estimating the phase from a magnitude spectrogram. However, due to compounding errors in the mel spectrogram inversion, this often lead the generated audio to sound unnatural____. More recently, there have been various approaches inspired by GANs. MelGAN____ generates audio waveforms using a stack of transposed convolution layers, together with multi-scale discriminators for better quality and efficiency in real-time applications. HiFi-GAN____ outperformed MelGAN by using a generator with transposed convolutions and residual blocks, combined with multi-scale and multi-period discriminators. BigVGAN____ and the concurrent work BigVGAN-v2 are able to synthesize high-fidelity 44.1 kHz audio by leveraging a scaled-up architecture with periodic activations and anti-aliased representations.

\textbf{Neural Audio Codecs.} While advancements in neural vocoding have significantly enhanced audio synthesis, similar progress has been observed in the domain of neural audio codecs. SoundStream____ introduced the residual vector quantization to encode audio into a highly compressed discrete latent space. EnCodec____ builds on SoundStream by using a similar encoder-decoder architecture to learn a low-dimensional quantized latent space using a reconstruction loss, a perceptual loss, and an adversarial loss. Descript Audio Codec (DAC)____ introduced several enhancements, including a reduction of codebook collapse and a multi-scale mel loss, enabling it to obtain better reconstruction of high-frequencies and reduced perceptual audio artifacts.