@article{BigVGAN,
  title        = {{BigVGAN}: A universal neural vocoder with large-scale training},
  author       = {Lee, Sang-gil and Ping, Wei and Ginsburg, Boris and Catanzaro, Bryan and Yoon, Sungroh},
  journal      = {arXiv preprint arXiv:2206.04658},
  year         = {2022},
  doi          = {10.48550/arXiv.2206.04658},
  url          = {https://doi.org/10.48550/arXiv.2206.04658}
}

@article{HiFiGAN,
  title        = {{HiFi-GAN}: Generative adversarial networks for efficient and high fidelity speech synthesis},
  author       = {Kong, Jungil and Kim, Jaehyeon and Bae, Jaekyoung},
  journal      = {Advances in neural information processing systems},
  volume       = {33},
  pages        = {17022--17033},
  year         = {2020},
  doi          = {},
  url          = {https://proceedings.neurips.cc/paper_files/paper/2020/file/c5d736809766d46260d816d8dbc9eb44-Paper.pdf}
}

@article{DAC,
  title        = {High-fidelity audio compression with improved {RVQGAN}},
  author       = {Kumar, Rithesh and Seetharaman, Prem and Luebs, Alejandro and Kumar, Ishaan and Kumar, Kundan},
  journal      = {Advances in Neural Information Processing Systems},
  volume       = {36},
  year         = {2024},
  doi          = {},
  url          = {https://proceedings.neurips.cc/paper_files/paper/2023/file/58d0e78cf042af5876e12661087bea12-Paper-Conference.pdf}
}

@article{EnCodec,
  title        = {High fidelity neural audio compression},
  author       = {D{\'e}fossez, Alexandre and Copet, Jade and Synnaeve, Gabriel and Adi, Yossi},
  journal      = {arXiv preprint arXiv:2210.13438},
  year         = {2022},
  doi          = {10.48550/arXiv.2210.13438},
  url          = {https://doi.org/10.48550/arXiv.2210.13438}
}


@conference {Jamendo,
  title        = {The {MTG-Jamendo} Dataset for Automatic Music Tagging},
  author       = {Bogdanov, Dmitry and Won, Minz and Tovstogan, Philip and Porter, Alastair and Serra, Xavier},
  booktitle    = {Machine Learning for Music Discovery Workshop, International Conference on Machine Learning (ICML 2019)},
  year         = {2019},
  address      = {Long Beach, CA, United States},
  doi          = {}, 
  url          = {http://hdl.handle.net/10230/42015}
}


@article{AudioLDM,
  title        = {{AudioLDM}: Text-to-Audio Generation with Latent Diffusion Models},
  author       = {Liu, Haohe and Chen, Zehua and Yuan, Yi and Mei, Xinhao and Liu, Xubo and Mandic, Danilo and Wang, Wenwu and Plumbley, Mark D},
  journal      = {Proceedings of the International Conference on Machine Learning},
  year         = {2023},
  pages        = {21450-21474},
  doi          = {},
  url          = {https://proceedings.mlr.press/v202/liu23f.html}
}


@inproceedings{ViSQOL,
  title        = {{ViSQOL} v3: An open source production ready objective speech and audio metric},
  author       = {Chinen, Michael and Lim, Felicia SC and Skoglund, Jan and Gureev, Nikita and O'Gorman, Feargus and Hines, Andrew},
  booktitle    = {2020 twelfth international conference on quality of multimedia experience (QoMEX)},
  pages        = {1--6},
  year         = {2020},
  organization = {IEEE},
  doi          = {10.1109/QoMEX48832.2020.9123150},
  url          = {https://doi.org/10.1109/QoMEX48832.2020.9123150}
}

@inproceedings{MR-STFT,
  title        = {Parallel {WaveGAN}: A fast waveform generation model based on generative adversarial networks with multi-resolution spectrogram},
  author       = {Yamamoto, Ryuichi and Song, Eunwoo and Kim, Jae-Min},
  booktitle    = {ICASSP 2020-2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  pages        = {6199--6203},
  year         = {2020},
  organization = {IEEE},
  doi          = {10.1109/ICASSP40776.2020.9053795},
  url          = {https://doi.org/10.1109/ICASSP40776.2020.9053795}
}


% METHOD - Objectives

@inproceedings{LS-GAN,
  title        = {Least squares generative adversarial networks},
  author       = {Mao, Xudong and Li, Qing and Xie, Haoran and Lau, Raymond YK and Wang, Zhen and Paul Smolley, Stephen},
  booktitle    = {Proceedings of the IEEE international conference on computer vision},
  pages        = {2794--2802},
  year         = {2017},
  doi          = {10.1109/ICCV.2017.304},
  url          = {https://doi.org/10.1109/ICCV.2017.304}
}


@article{MUSHRA,
  title        = {Method for the subjective assessment of intermediate sound quality ({MUSHRA})},
  author       = {Recommendation, ITUR and others},
  journal      = {ITU, BS},
  pages        = {1543--1},
  year         = {2001},
  doi          = {},
  url          = {https://www.itu.int/dms_pubrec/itu-r/rec/bs/R-REC-BS.1534-3-201510-I!!PDF-E.pdf}
}

@article{wang2017tacotron,
  title={Tacotron: Towards end-to-end speech synthesis},
  author={Wang, Yuxuan and Skerry-Ryan, RJ and Stanton, Daisy and Wu, Yonghui and Weiss, Ron J and Jaitly, Navdeep and Yang, Zongheng and Xiao, Ying and Chen, Zhifeng and Bengio, Samy and others},
  journal={arXiv preprint arXiv:1703.10135},
  year={2017}
}

@article{griffin1984signal,
  title={Signal estimation from modified short-time Fourier transform},
  author={Griffin, Daniel and Lim, Jae},
  journal={IEEE Transactions on acoustics, speech, and signal processing},
  volume={32},
  number={2},
  pages={236--243},
  year={1984},
  publisher={IEEE}
}

@article{kumar2019melgan,
  title={{MelGAN}: Generative adversarial networks for conditional waveform synthesis},
  author={Kumar, Kundan and Kumar, Rithesh and De Boissiere, Thibault and Gestin, Lucas and Teoh, Wei Zhen and Sotelo, Jose and De Brebisson, Alexandre and Bengio, Yoshua and Courville, Aaron C},
  journal={Advances in neural information processing systems},
  volume={32},
  year={2019}
}

@article{zeghidour2021soundstream,
  title={{SoundStream}: An end-to-end neural audio codec},
  author={Zeghidour, Neil and Luebs, Alejandro and Omran, Ahmed and Skoglund, Jan and Tagliasacchi, Marco},
  journal={IEEE/ACM Transactions on Audio, Speech, and Language Processing},
  volume={30},
  pages={495--507},
  year={2021},
  publisher={IEEE}
}

@article{Forsgren_Martiros_2022,
  title = {{Riffusion - Stable diffusion for real-time music generation}},
  author = {Forsgren, Seth* and Martiros, Hayk*},
  url = {https://riffusion.com/about},
  year = {2022}
}

@article{van2016wavenet,
  title={{WaveNet}: A generative model for raw audio},
  author={Van Den Oord, Aaron and Dieleman, Sander and Zen, Heiga and Simonyan, Karen and Vinyals, Oriol and Graves, Alex and Kalchbrenner, Nal and Senior, Andrew and Kavukcuoglu, Koray and others},
  journal={arXiv preprint arXiv:1609.03499},
  volume={12},
  year={2016}
}

@inproceedings{oord2018parallel,
  title={Parallel {WaveNet}: Fast high-fidelity speech synthesis},
  author={Oord, Aaron and Li, Yazhe and Babuschkin, Igor and Simonyan, Karen and Vinyals, Oriol and Kavukcuoglu, Koray and Driessche, George and Lockhart, Edward and Cobo, Luis and Stimberg, Florian and others},
  booktitle={International conference on machine learning},
  pages={3918--3926},
  year={2018},
  organization={PMLR}
}

@article{di2022mel,
  title={Mel spectrogram inversion with stable pitch},
  author={Di Giorgi, Bruno and Levy, Mark and Sharp, Richard},
  journal={arXiv preprint arXiv:2208.12782},
  year={2022}
}

@article{schoeffler2018webmushra,
  title={{webMUSHRA} — A comprehensive framework for web-based listening tests},
  author={Schoeffler, Michael and Bartoschek, Sarah and St{\"o}ter, Fabian-Robert and Roess, Marlene and Westphal, Susanne and Edler, Bernd and Herre, J{\"u}rgen},
  year={2018}
}


@inproceedings{LibriTTS,
  title        = {{LibriTTS}: A Corpus Derived from {LibriSpeech} for Text-to-Speech},
  author       = {Heiga Zen and Viet Dang and Rob Clark and Yu Zhang and Ron J. Weiss and Ye Jia and Zhifeng Chen and Yonghui Wu},
  year         = 2019,
  booktitle    = {Proc. Interspeech 2019},
  pages        = {1526--1530},
  issn         = {2958-1796},
  doi          = {10.21437/Interspeech.2019-2441},
  url          = {https://doi.org/10.21437/Interspeech.2019-2441}
}

@inproceedings{AudioSet,
  title        = {{Audio Set}: An ontology and human-labeled dataset for audio events}, 
  author       = {Gemmeke, Jort F. and Ellis, Daniel P. W. and Freedman, Dylan and Jansen, Aren and Lawrence, Wade and Moore, R. Channing and Plakal, Manoj and Ritter, Marvin},
  booktitle    = {2017 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}, 
  year         = {2017},
  volume       = {},
  number       = {},
  pages        = {776-780},
  doi          = {10.1109/ICASSP.2017.7952261},
  url          = {https://doi.org/10.1109/ICASSP.2017.7952261}
}

@misc{MUSDB18-HQ,
  title        = {{MUSDB18-HQ} - an uncompressed version of {MUSDB18}},
  author       = {Rafii, Zafar and Liutkus, Antoine and Stöter, Fabian-Robert and Mimilakis, Stylianos Ioannis and Bittner, Rachel},
  month        = aug,
  year         = 2019,
  doi          = {10.5281/zenodo.3338373},
  url          = {https://doi.org/10.5281/zenodo.3338373}
}

@inproceedings{UnivNet,
  title        = {{UnivNet}: A Neural Vocoder with Multi-Resolution Spectrogram Discriminators for High-Fidelity Waveform Generation},
  author       = {Won Jang and Dan Lim and Jaesam Yoon and Bongwan Kim and Juntae Kim},
  year         = 2021,
  booktitle    = {Proc. Interspeech 2021},
  pages        = {2207--2211},
  doi          = {10.21437/Interspeech.2021-1016},
  url          = {https://doi.org/10.21437/Interspeech.2021-1016},
  issn         = {2958-1796}
}

@article{snake,
  title        = {Neural networks fail to learn periodic functions and how to fix it},
  author       = {Ziyin, Liu and Hartwig, Tilman and Ueda, Masahito},
  journal      = {Advances in Neural Information Processing Systems},
  volume       = {33},
  pages        = {1583--1594},
  year         = {2020}
}

@inproceedings{feature-matching,
  title        = {Autoencoding beyond pixels using a learned similarity metric},
  author       = {Larsen, Anders Boesen Lindbo and S{\o}nderby, S{\o}ren Kaae and Larochelle, Hugo and Winther, Ole},
  booktitle    = {International conference on machine learning},
  pages        = {1558--1566},
  year         = {2016},
  organization = {PMLR}
}


@article{AdamW,
  title        = {Decoupled weight decay regularization},
  author       = {Loshchilov, Ilya and Hutter, Frank},
  journal      = {arXiv preprint arXiv:1711.05101},
  year         = {2017},
  doi          = {10.48550/arXiv.1711.05101},
  url          = {https://doi.org/10.48550/arXiv.1711.05101}
}


@INPROCEEDINGS{PESQ,
  title        = {Perceptual evaluation of speech quality ({PESQ})-a new method for speech quality assessment of telephone networks and codecs}, 
  author       = {Rix, A.W. and Beerends, J.G. and Hollier, M.P. and Hekstra, A.P.},
  booktitle    = {2001 IEEE International Conference on Acoustics, Speech, and Signal Processing. Proceedings (Cat. No.01CH37221)},
  year         = {2001},
  volume       = {2},
  number       = {},
  pages        = {749-752 vol.2},
  keywords     = {Speech analysis;Quality assessment;Distortion measurement;Nonlinear distortion;Nonlinear filters;Telephony;Signal processing;Delay effects;Speech codecs;Degradation},
  doi          = {10.1109/ICASSP.2001.941023},
  url          = {https://doi.org/10.1109/ICASSP.2001.941023}
}

@inproceedings{CDPAM,
  title        = {{CDPAM}: Contrastive learning for perceptual audio similarity},
  author       = {Manocha, Pranay and Jin, Zeyu and Zhang, Richard and Finkelstein, Adam},
  booktitle    = {ICASSP 2021-2021 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  pages        = {196--200},
  year         = {2021},
  organization = {IEEE}
}