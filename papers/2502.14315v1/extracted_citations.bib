@inproceedings{10.1145/3397271.3401247,
author = {Liu, Ao and Yuan, Shuai and Zhang, Chenbin and Luo, Congjian and Liao, Yaqing and Bai, Kun and Xu, Zenglin},
title = {Multi-Level Multimodal Transformer Network for Multimodal Recipe Comprehension},
year = {2020},
isbn = {9781450380164},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3397271.3401247},
doi = {10.1145/3397271.3401247},
abstract = {Multimodal Machine Comprehension ($rm M^3C$) has been a challenging task that requires understanding both language and vision, as well as their integration and interaction. For example, the RecipeQA challenge, which provides several $rm M^3C$ tasks, requires deep neural models to understand textual instructions, images of different steps, as well as the logic orders of food cooking. To address this challenge, we propose a Multi-Level Multi-Modal Transformer (MLMM-Trans) framework to integrate and understand multiple textual instructions and multiple images. Our model can conduct intensive attention mechanism at multiple levels of objects (e.g., step level and passage-image level) for sequences of different modalities. Experiments have shown that our model can achieve the state-of-the-art results on the three multimodal tasks of RecipeQA.},
booktitle = {Proceedings of the 43rd International ACM SIGIR Conference on Research and Development in Information Retrieval},
pages = {1781â€“1784},
numpages = {4},
keywords = {multimodal machine reading comprehension, multimodal recipe comprehension, question answering},
location = {Virtual Event, China},
series = {SIGIR '20}
}

@misc{amini2020proceduralreadingcomprehensionattributeaware,
      title={Procedural Reading Comprehension with Attribute-Aware Context Flow}, 
      author={Aida Amini and Antoine Bosselut and Bhavana Dalvi Mishra and Yejin Choi and Hannaneh Hajishirzi},
      year={2020},
      eprint={2003.13878},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2003.13878}, 
}

@misc{cao2023culturaladaptationrecipes,
      title={Cultural Adaptation of Recipes}, 
      author={Yong Cao and Yova Kementchedjhieva and Ruixiang Cui and Antonia Karamolegkou and Li Zhou and Megan Dare and Lucia Donatelli and Daniel Hershcovich},
      year={2023},
      eprint={2310.17353},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2310.17353}, 
}

@inproceedings{dalvi-etal-2018-tracking,
    title = "Tracking State Changes in Procedural Text: a Challenge Dataset and Models for Process Paragraph Comprehension",
    author = "Dalvi, Bhavana  and
      Huang, Lifu  and
      Tandon, Niket  and
      Yih, Wen-tau  and
      Clark, Peter",
    editor = "Walker, Marilyn  and
      Ji, Heng  and
      Stent, Amanda",
    booktitle = "Proceedings of the 2018 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long Papers)",
    month = jun,
    year = "2018",
    address = "New Orleans, Louisiana",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/N18-1144/",
    doi = "10.18653/v1/N18-1144",
    pages = "1595--1604",
    abstract = "We present a new dataset and models for comprehending paragraphs about processes (e.g., photosynthesis), an important genre of text describing a dynamic world. The new dataset, ProPara, is the first to contain natural (rather than machine-generated) text about a changing world along with a full annotation of entity states (location and existence) during those changes (81k datapoints). The end-task, tracking the location and existence of entities through the text, is challenging because the causal effects of actions are often implicit and need to be inferred. We find that previous models that have worked well on synthetic data achieve only mediocre performance on ProPara, and introduce two new neural models that exploit alternative mechanisms for state prediction, in particular using LSTM input encoding and span prediction. The new models improve accuracy by up to 19{\%}. We are releasing the ProPara dataset and our models to the community."
}

@inproceedings{gupta-durrett-2019-tracking,
    title = "Tracking Discrete and Continuous Entity State for Process Understanding",
    author = "Gupta, Aditya  and
      Durrett, Greg",
    editor = "Martins, Andre  and
      Vlachos, Andreas  and
      Kozareva, Zornitsa  and
      Ravi, Sujith  and
      Lampouras, Gerasimos  and
      Niculae, Vlad  and
      Kreutzer, Julia",
    booktitle = "Proceedings of the Third Workshop on Structured Prediction for {NLP}",
    month = jun,
    year = "2019",
    address = "Minneapolis, Minnesota",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/W19-1502/",
    doi = "10.18653/v1/W19-1502",
    pages = "7--12",
    abstract = "Procedural text, which describes entities and their interactions as they undergo some process, depicts entities in a uniquely nuanced way. First, each entity may have some observable discrete attributes, such as its state or location; modeling these involves imposing global structure and enforcing consistency. Second, an entity may have properties which are not made explicit but can be effectively induced and tracked by neural networks. In this paper, we propose a structured neural architecture that reflects this dual nature of entity evolution. The model tracks each entity recurrently, updating its hidden continuous representation at each step to contain relevant state information. The global discrete state structure is explicitly modelled with a neural CRF over the changing hidden representation of the entity. This CRF can explicitly capture constraints on entity states over time, enforcing that, for example, an entity cannot move to a location after it is destroyed. We evaluate the performance of our proposed model on QA tasks over process paragraphs in the ProPara dataset and find that our model achieves state-of-the-art results."
}

@inproceedings{huang-etal-2021-reasoning,
    title = "Reasoning over Entity-Action-Location Graph for Procedural Text Understanding",
    author = "Huang, Hao  and
      Geng, Xiubo  and
      Pei, Jian  and
      Long, Guodong  and
      Jiang, Daxin",
    editor = "Zong, Chengqing  and
      Xia, Fei  and
      Li, Wenjie  and
      Navigli, Roberto",
    booktitle = "Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)",
    month = aug,
    year = "2021",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.acl-long.396/",
    doi = "10.18653/v1/2021.acl-long.396",
    pages = "5100--5109",
    abstract = "Procedural text understanding aims at tracking the states (e.g., create, move, destroy) and locations of the entities mentioned in a given paragraph. To effectively track the states and locations, it is essential to capture the rich semantic relations between entities, actions, and locations in the paragraph. Although recent works have achieved substantial progress, most of them focus on leveraging the inherent constraints or incorporating external knowledge for state prediction. The rich semantic relations in the given paragraph are largely overlooked. In this paper, we propose a novel approach (REAL) to procedural text understanding, where we build a general framework to systematically model the entity-entity, entity-action, and entity-location relations using a graph neural network. We further develop algorithms for graph construction, representation learning, and state and location tracking. We evaluate the proposed approach on two benchmark datasets, ProPara, and Recipes. The experimental results show that our method outperforms strong baselines by a large margin, i.e., 5.0{\%} on ProPara and 3.2{\%} on Recipes, illustrating the utility of semantic relations and the effectiveness of the graph-based reasoning model."
}

@inproceedings{rajaby-faghihi-kordjamshidi-2021-time,
    title = "Time-Stamped Language Model: Teaching Language Models to Understand The Flow of Events",
    author = "Rajaby Faghihi, Hossein  and
      Kordjamshidi, Parisa",
    editor = "Toutanova, Kristina  and
      Rumshisky, Anna  and
      Zettlemoyer, Luke  and
      Hakkani-Tur, Dilek  and
      Beltagy, Iz  and
      Bethard, Steven  and
      Cotterell, Ryan  and
      Chakraborty, Tanmoy  and
      Zhou, Yichao",
    booktitle = "Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies",
    month = jun,
    year = "2021",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.naacl-main.362/",
    doi = "10.18653/v1/2021.naacl-main.362",
    pages = "4560--4570",
    abstract = "Tracking entities throughout a procedure described in a text is challenging due to the dynamic nature of the world described in the process. Firstly, we propose to formulate this task as a question answering problem. This enables us to use pre-trained transformer-based language models on other QA benchmarks by adapting those to the procedural text understanding. Secondly, since the transformer-based language models cannot encode the flow of events by themselves, we propose a Time-Stamped Language Model (TSLM) to encode event information in LMs architecture by introducing the timestamp encoding. Our model evaluated on the Propara dataset shows improvements on the published state-of-the-art results with a 3.1{\%} increase in F1 score. Moreover, our model yields better results on the location prediction task on the NPN-Cooking dataset. This result indicates that our approach is effective for procedural text understanding in general."
}

@inproceedings{tang-etal-2020-understanding-procedural,
    title = "Understanding Procedural Text using Interactive Entity Networks",
    author = "Tang, Jizhi  and
      Feng, Yansong  and
      Zhao, Dongyan",
    editor = "Webber, Bonnie  and
      Cohn, Trevor  and
      He, Yulan  and
      Liu, Yang",
    booktitle = "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)",
    month = nov,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2020.emnlp-main.591/",
    doi = "10.18653/v1/2020.emnlp-main.591",
    pages = "7281--7290",
    abstract = "The task of procedural text comprehension aims to understand the dynamic nature of entities/objects in a process. Here, the key is to track how the entities interact with each other and how their states are changing along the procedure. Recent efforts have made great progress to track multiple entities in a procedural text, but usually treat each entity separately and ignore the fact that there are often multiple entities interacting with each other during one process, some of which are even explicitly mentioned. In this paper, we propose a novel Interactive Entity Network (IEN), which is a recurrent network with memory equipped cells for state tracking. In each IEN cell, we maintain different attention matrices through specific memories to model different types of entity interactions. Importantly, we can update these memories in a sequential manner so as to explore the causal relationship between entity actions and subsequent state changes. We evaluate our model on a benchmark dataset, and the results show that IEN outperforms state-of-the-art models by precisely capturing the interactions of multiple entities and explicitly leverage the relationship between entity interactions and subsequent state changes."
}

@inproceedings{wu-etal-2022-understanding,
    title = "Understanding Multimodal Procedural Knowledge by Sequencing Multimodal Instructional Manuals",
    author = "Wu, Te-Lin  and
      Spangher, Alex  and
      Alipoormolabashi, Pegah  and
      Freedman, Marjorie  and
      Weischedel, Ralph  and
      Peng, Nanyun",
    editor = "Muresan, Smaranda  and
      Nakov, Preslav  and
      Villavicencio, Aline",
    booktitle = "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = may,
    year = "2022",
    address = "Dublin, Ireland",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.acl-long.310/",
    doi = "10.18653/v1/2022.acl-long.310",
    pages = "4525--4542",
    abstract = "The ability to sequence unordered events is evidence of comprehension and reasoning about real world tasks/procedures. It is essential for applications such as task planning and multi-source instruction summarization. It often requires thorough understanding of temporal common sense and multimodal information, since these procedures are often conveyed by a combination of texts and images. While humans are capable of reasoning about and sequencing unordered procedural instructions, the extent to which the current machine learning methods possess such capability is still an open question. In this work, we benchmark models' capability of reasoning over and sequencing unordered multimodal instructions by curating datasets from online instructional manuals and collecting comprehensive human annotations. We find current state-of-the-art models not only perform significantly worse than humans but also seem incapable of efficiently utilizing multimodal information. To improve machines' performance on multimodal event sequencing, we propose sequence-aware pretraining techniques exploiting the sequential alignment properties of both texts and images, resulting in {\ensuremath{>}} 5{\%} improvements on perfect match ratio."
}

