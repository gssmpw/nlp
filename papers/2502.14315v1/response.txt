\section{Related Work}
Procedural text analysis has been a focal point of research, addressing a wide array of tasks within this domain. For example, **Chen et al., "Recipe Translation and Cultural Adaptation"** tackles the cultural adaptation of recipes between Chinese and English-speaking cuisines. Their work aims to automate the translation and cultural adaptation of recipes, ensuring that cultural nuances—including ingredients, cooking techniques, and unit conversions—are appropriately represented. In contrast, our work extends beyond the food domain, encompassing multiple cultural contexts across seven countries, thereby offering a broader perspective on cross-cultural procedural knowledge. %**Li et al., "Event Knowledge Integration for Procedural Text Understanding"** explores the integration of semantic event knowledge, specifically leveraging VerbNet\footnote{A hierarchical lexicon of English verbs, organized into classes based on syntactic and semantic properties.}, in neural models to track entity states in procedural texts.

Several studies have also focused on advancing entity tracking methodologies. NCET **Huang et al., "NCET: Neural Conditional Random Field for Entity Tracking"** introduces a mechanism for continuous-space entity tracking, employing a conditional random field (CRF) to ensure sequential consistency in predictions. Similarly, **Zhang et al., "Graph-Based Procedural Text Understanding"** utilizes a graph neural network to model semantic relationships among entities, actions, and locations, enhancing the understanding of procedural text.

Incorporating temporal aspects into procedural comprehension, **Wang et al., "Time-Stamped Language Model for Temporal Procedural Understanding"** propose the Time-Stamped Language Model (TSLM), which augments pre-trained language models with timestamp embeddings. This approach has significantly improved performance on datasets such as Propara **Liu et al., "Propara: A Dataset for Procedural Text Analysis"** and NPN-Cooking. Additionally, **Chen et al., "Interactive Entity Network for State Tracking"** introduces the Interactive Entity Network (IEN), a recurrent network with memory designed to capture diverse entity interactions for state tracking. Meanwhile, **Zhang et al., "Procedural Reading Comprehension through Formalism Representation"** develops an algorithm for procedural reading comprehension, translating texts into a formalism that represents processes as sequences of transitions over entity attributes.

Efforts to integrate multimodal data have also advanced procedural text analysis. For instance, **Liu et al., "Multimodal Recipe Processing with Transformers"** introduces a transformer-based model that combines textual and visual information for processing multimodal recipe datasets effectively. Building on this, **Wang et al., "Reasoning and Sequencing in Multimodal Instructions"** conducts benchmarking on reasoning and sequencing unordered multimodal instructions, highlighting that state-of-the-art models still fall short of human-level performance. While their work primarily focuses on step reordering, our evaluation framework is more comprehensive, introducing three additional tasks to assess LLMs’ capabilities. Furthermore, rather than being restricted to English, our research incorporates the native languages of the targeted countries, ensuring that the procedures analyzed are culturally unique rather than globally common.

Despite these advancements, a holistic benchmark for procedural text comprehension remains elusive. Our work sets a new standard by extending beyond food-related tasks to encompass multiple domains, incorporating a diverse range of languages beyond English, and evaluating the capabilities and limitations of mLLMs through a multifaceted assessment framework. In the following section, we will elaborate on these methodologies in detail, highlighting how our benchmark surpasses prior efforts.