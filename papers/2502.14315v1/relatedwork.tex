\section{Related Work}
Procedural text analysis has been a focal point of research, addressing a wide array of tasks within this domain. For example, \citet{cao2023culturaladaptationrecipes} tackles the cultural adaptation of recipes between Chinese and English-speaking cuisines. Their work aims to automate the translation and cultural adaptation of recipes, ensuring that cultural nuances—including ingredients, cooking techniques, and unit conversions—are appropriately represented. In contrast, our work extends beyond the food domain, encompassing multiple cultural contexts across seven countries, thereby offering a broader perspective on cross-cultural procedural knowledge. %\citep{kazeminejad-palmer-2023-event} explores the integration of semantic event knowledge, specifically leveraging VerbNet\footnote{A hierarchical lexicon of English verbs, organized into classes based on syntactic and semantic properties.}, in neural models to track entity states in procedural texts.

Several studies have also focused on advancing entity tracking methodologies. NCET \citep{gupta-durrett-2019-tracking} introduces a mechanism for continuous-space entity tracking, employing a conditional random field (CRF) to ensure sequential consistency in predictions. Similarly, \citet{huang-etal-2021-reasoning} utilizes a graph neural network to model semantic relationships among entities, actions, and locations, enhancing the understanding of procedural text.

Incorporating temporal aspects into procedural comprehension, \citet{rajaby-faghihi-kordjamshidi-2021-time} propose the Time-Stamped Language Model (TSLM), which augments pre-trained language models with timestamp embeddings. This approach has significantly improved performance on datasets such as Propara \cite{dalvi-etal-2018-tracking} and NPN-Cooking. Additionally, \citep{tang-etal-2020-understanding-procedural} introduces the Interactive Entity Network (IEN), a recurrent network with memory designed to capture diverse entity interactions for state tracking. Meanwhile, \citet{amini2020proceduralreadingcomprehensionattributeaware} develops an algorithm for procedural reading comprehension, translating texts into a formalism that represents processes as sequences of transitions over entity attributes.

Efforts to integrate multimodal data have also advanced procedural text analysis. For instance, \citep{10.1145/3397271.3401247} introduces a transformer-based model that combines textual and visual information for processing multimodal recipe datasets effectively. Building on this, \citep{wu-etal-2022-understanding} conducts benchmarking on reasoning and sequencing unordered multimodal instructions, highlighting that state-of-the-art models still fall short of human-level performance. While their work primarily focuses on step reordering, our evaluation framework is more comprehensive, introducing three additional tasks to assess LLMs’ capabilities. Furthermore, rather than being restricted to English, our research incorporates the native languages of the targeted countries, ensuring that the procedures analyzed are culturally unique rather than globally common.

Despite these advancements, a holistic benchmark for procedural text comprehension remains elusive. Our work sets a new standard by extending beyond food-related tasks to encompass multiple domains, incorporating a diverse range of languages beyond English, and evaluating the capabilities and limitations of mLLMs through a multifaceted assessment framework. In the following section, we will elaborate on these methodologies in detail, highlighting how our benchmark surpasses prior efforts.

%%%%%%%%%%%%%%%%%%%%%%  CAPTex  %%%%%%%%%%%%%%%%%%%%%%