\section{Related Works}
With the evolution of deep learning paradigm, notable advances have been done in image super-resolution. Exhaustive surveys ____ have been done to summarize the prominent works done in deep learning based image super-resolution. In this section, we mention few notable works discussed in the literature.

\subsection{Supervised Super-resolution}
Due to the ill-posed nature of image super-resolution, the primary challenge lies in determining how to effectively perform upsampling—converting low-resolution (LR) input into high-resolution (HR) output. Despite the wide range of model architectures, they can generally be grouped into four primary frameworks.

\subsubsection{Pre-Upsampling Super-resolution}
Given the difficulty of directly learning the mapping from low-dimensional to high-dimensional space, a practical solution involves utilizing traditional upsampling techniques to generate higher-resolution images, followed by refinement using deep neural networks (DNNs). Dong et al. ____ were the first to adopt this pre-upsampling framework, proposing SRCNN. In this approach, LR images are initially upsampled to coarse HR images of the desired size using standard methods such as bicubic interpolation. Afterward, deep CNNs are employed to enhance the fine details. Since the upsampling step, which is computationally demanding, has already been carried out, the CNNs only need to refine the upsampled images, thus lowering the complexity of the learning task. Additionally, these models can handle interpolated images of arbitrary sizes and scaling factors, offering performance comparable to single-scale SR models ____. This framework has gained widespread popularity ____, with variations primarily in the design of the posterior model and learning strategies. However, pre-defined upsampling can lead to side effects, such as noise amplification and blurring. Furthermore, performing operations in high-dimensional space incurs higher computational and memory costs compared to other frameworks ____.

\subsubsection{Post-Upsampling Super-resolution}
To enhance computational efficiency and maximize the benefits of deep learning for resolution enhancement, researchers have proposed conducting most computations in low-dimensional space, with end-to-end learnable upsampling layers applied at the network’s output. This framework, called post-upsampling SR, avoids the pre-defined upsampling step by feeding the LR images directly into deep CNNs, leaving the resolution increase for the final stage. This design significantly reduces both computational and spatial complexity since the feature extraction—which is computationally intensive—occurs in low-dimensional space, and resolution is only increased during the final stage. As a result, this approach has become one of the most widely adopted frameworks ____. The differences across models within this framework largely lie in the design of learnable upsampling layers, the preceding CNN structures, and the learning strategies used.
\subsubsection{Progressive Upsampling Super-resolution}
While the post-upsampling framework offers a significant reduction in computational cost, it still faces challenges. Upsampling is performed in a single step, which increases the difficulty of learning when handling large scaling factors (e.g., 4x, 8x). Moreover, separate models must be trained for different scaling factors, which limits flexibility for multi-scale SR tasks. To overcome these limitations, the progressive upsampling framework was introduced by Laplacian pyramid SR network (LapSRN) ____. This framework incrementally reconstructs HR images through a cascade of CNNs, with each stage progressively upsampling and refining the images. Other models, such as MS-LapSRN ____ and progressive SR (ProSR) ____, have adopted this framework and achieved high performance. In contrast to LapSRN and MS-LapSRN, which treat intermediate reconstructed images as ``base images" for subsequent modules, ProSR maintains a central information stream, reconstructing intermediate-resolution images using separate heads.

\subsubsection{Iterative Up-and-Down Sampling Super-resolution}
To better model the interdependence between LR and HR image pairs, an efficient iterative refinement process known as back-projection ____ has been incorporated into super-resolution models ____. This framework, referred to as iterative up-and-down sampling SR, iteratively applies back-projection refinement, computing reconstruction errors and using them to adjust HR image intensities. Haris et al. ____ introduced DBPN, which alternates between upsampling and downsampling layers, ultimately reconstructing the HR output from a series of intermediate reconstructions. Likewise, SRFBN ____ employs an iterative feedback mechanism with dense skip connections to enhance representational learning, while RBPN ____ applies this framework to video super-resolution, combining context from multiple video frames to produce recurrent HR outputs through a back-projection module.

\subsection{Unsupervised Super-resolution}
Most super-resolution methods to date have focused on supervised learning, relying on matched LR-HR image pairs for training. However, in practice, it is often difficult to obtain images of the same scene at different resolutions, leading to datasets where LR images are generated through predefined degradation processes applied to HR images. As a result, the models trained using these datasets may not generalize well to real-world scenarios.

\subsubsection{Zero-Shot Super-resolution}
Acknowledging that the internal image statistics within a single image provide enough information for super-resolution, Shocher et al. ____ proposed zero-shot super-resolution (ZSSR). ZSSR addresses unsupervised SR by training image-specific SR networks during the testing phase, rather than relying on a generic model trained on large external datasets. Specifically, a degradation kernel is estimated from a single image ____, and a small dataset is created by applying degradations and augmentations to the image using various scaling factors. A CNN is then trained on this small dataset for SR, leveraging the internal cross-scale recurrence found within the image. This approach significantly outperforms prior methods, especially in non-ideal conditions (e.g., noisy, blurry, or compressed images), with improvements of up to 1 dB for estimated kernels and 2 dB for known kernels. However, the method requires training a different network for each test image, resulting in longer inference times.

\subsubsection{Weakly-Supervised Super-resolution}
Because predefined degradation is suboptimal, learning degradation from unpaired LR-HR datasets presents a promising alternative. Bulat et al. ____ proposed a two-stage process where an HR-to-LR GAN is trained using unpaired LR-HR images to learn degradation, followed by training an LR-to-HR GAN for SR using the generated LR-HR image pairs. Specifically, the HR-to-LR GAN generates LR images from HR inputs that are required to match not only the LR images produced through downscaling (e.g., via average pooling) but also the distribution of real LR images. Once trained, this generator is used to create LR-HR pairs. The LR-to-HR GAN (which serves as the SR model) then uses these generated LR images to predict HR outputs. Inspired by CycleGAN ____, Yuan et al. ____ proposed the cycle-in-cycle SR network (CinCGAN), which consists of four generators and two discriminators forming two CycleGANs that model noisy LR to clean LR and clean LR to clean HR mappings. In the first CycleGAN, the noisy LR image is passed through a generator that outputs an image matching the distribution of real clean LR images, which is then used as input for the second generator to recover the original HR image.

\subsubsection{Deep Image Prior Super-resolution}
Prior-guided FSR methods consistently harness the potential of facial priors to enhance face super-resolution ____. Chen et al. ____ carried out face reconstruction from a coarse to fine level, utilizing prior information specific to faces. Kim et al. ____ created multiple multi-resolution facial images through a progressive training approach. Ma et al. ____ integrated facial super-resolution (FSR) with landmark estimation, using an iterative and recursive method for face reconstruction. Yin et al. ____ introduced a multi-task framework that simultaneously learns face landmarks and super-resolution, where the tasks mutually support each other. Wang et al. ____ introduced an innovative dual closed-loop network (DCLNet) based on CNNs to reduce the potential mapping space. Li et al. ____ developed a five-branch network focusing on five key regions of the human face for face hallucination. Kalarot et al. ____ improved FSR outcomes using facial component attention maps. Similarly, methods leveraging face semantic information and heat maps are increasingly being explored. For addressing higher magnification factors, Liu et al. ____ proposed an FSR method that incorporates face parsing maps. Zhao and Zhang ____ introduced adaptive FSR using face semantic attention. Zhang et al. ____ combined a deep neural network (DNN) with both a face image super-resolution branch and a semantic face parsing branch. Wang et al. ____ designed a novel heat map-aware convolution utilizing spatially variant kernels, rather than the conventional spatially shared kernel, to restore different facial regions. Additionally, Wang et al. ____ created a new FSR network that employs resolved maps to directly extract face prior information from low-resolution images for subsequent use.
\subsection{Face Super-Resolution -- A Domain Specific SR }
Face super-resolution is a domain-specific problem within the realm of super-resolution. FSR has attracted increased attention in research communities and achieved significant advancements. In literature, FSR has broadly been categorized into two types on the basis of their approach to upsample a given image. These include Network Architecture Design-based FSR and Facial Prior-guided FSR. We shall discuss both of these briefly.\\
\subsubsection{Network Architecture Design-based FSR}
Due to the rapid advancements in deep convolutional neural networks (CNNs), deep learning techniques have been extensively applied to computer vision tasks ____. Over the past few years, there has been a notable increase in leveraging deep CNN models for face super-resolution (FSR) ____, resulting in continuous improvements in performance. Early deep learning approaches to FSR primarily focused on designing efficient network architectures. For example, Zhou et al. ____ introduced a bi-channel network to extract informative features, which were then fused for FSR. Huang et al. ____ proposed a wavelet-based CNN method designed to ultra-resolve extremely low-resolution facial images. Drawing inspiration from attention mechanisms ____, Chen et al. [24] created face attention units specifically tailored for FSR. To improve feature representation, Lu et al. ____ introduced the global-local split-attention network, which applies local attention to groups of feature maps while achieving global attention. Jiang et al. ____, without relying on extra prior knowledge, developed a dual-path deep fusion network consisting of two distinct branches to accomplish face image super-resolution. Chen et al. ____ proposed a lightweight single-image super-resolution network that integrates multi-level features to tackle the typical issues of blurred image edges, the rigid selection of convolution kernel sizes, and slow convergence during training caused by redundant network structures in existing image super-resolution algorithms. In ____, authors propose an innovative deep hybrid feature-based attention model specifically designed for FSR.

Drawing inspiration from generative adversarial networks (GAN), Yu et al. ____ developed the first GAN-based FSR method, URDGN, to reconstruct realistic face images. ATFaceGAN ____ adopts a dual-path training approach to improve facial images, while HiFaceGAN ____ presents a suppression module specifically designed to enhance high-frequency details effectively. To address the shortcomings of traditional GANs in FSR, a supervised pixel-wise GAN is specifically designed to enhance low-resolution face images ____. However, training the discriminator to recognize the entire face image poses challenges. To overcome this, Dou et al. ____ break down the face images into different components, allowing the discriminator to gradually learn these parts. The approach in ____ introduces a generative and controllable FSR framework, while ECSRNet ____ directly captures both low- and high-frequency details using a progressive asymmetric architecture to perform face hallucination. 
\subsubsection{Facial Prior Guided FSR}
Prior-guided FSR methods consistently harness the potential of facial priors to enhance face super-resolution ____. Chen et al. ____ carried out face reconstruction from a coarse to fine level, utilizing prior information specific to faces. Kim et al. ____ created multiple multi-resolution facial images through a progressive training approach. Ma et al. ____ integrated facial super-resolution (FSR) with landmark estimation, using an iterative and recursive method for face reconstruction. Yin et al. ____ introduced a multi-task framework that simultaneously learns face landmarks and super-resolution, where the tasks mutually support each other. Wang et al. ____ introduced an innovative dual closed-loop network (DCLNet) based on CNNs to reduce the potential mapping space. Li et al. ____ developed a five-branch network focusing on five key regions of the human face for face hallucination. Kalarot et al. ____ improved FSR outcomes using facial component attention maps. Similarly, methods leveraging face semantic information and heat maps are increasingly being explored. For addressing higher magnification factors, Liu et al. ____ proposed an FSR method that incorporates face parsing maps. Zhao and Zhang ____ introduced adaptive FSR using face semantic attention. Zhang et al. ____ combined a deep neural network (DNN) with both a face image super-resolution branch and a semantic face parsing branch. Wang et al. ____ designed a novel heat map-aware convolution utilizing spatially variant kernels, rather than the conventional spatially shared kernel, to restore different facial regions. Additionally, Wang et al. ____ created a new FSR network that employs resolved maps to directly extract face prior information from low-resolution images for subsequent use.










\begin{figure*}
    \centering
    \includegraphics[scale=0.105]{images/archSR1.png}
    \caption{\label{arc} The network architecture of AffectSRNet. The super-resolution backbone consists of the RRDB and upsampling blocks from ESRGAN____. Facial landmarks extracted with Mediapipe____ are passed through GCN block to get graph embeddings. These are integrated into the super-resolution backbone, with MSAF block performing cross-modal fusion.}
   
\end{figure*}