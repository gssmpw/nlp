\section{Related Works}
With the evolution of deep learning paradigm, notable advances have been done in image super-resolution. Exhaustive surveys **Kim et al., "Deeply-Recursive Convolutional Network for Image Super-Resolution"**__**Li et al., "Natural Image Texture Classification Using Deep Neural Networks"** have been done to summarize the prominent works done in deep learning based image super-resolution. In this section, we mention few notable works discussed in the literature.

\subsection{Supervised Super-resolution}
Due to the ill-posed nature of image super-resolution, the primary challenge lies in determining how to effectively perform upsampling—converting low-resolution (LR) input into high-resolution (HR) output. Despite the wide range of model architectures, they can generally be grouped into four primary frameworks.

\subsubsection{Pre-Upsampling Super-resolution}
Given the difficulty of directly learning the mapping from low-dimensional to high-dimensional space, a practical solution involves utilizing traditional upsampling techniques to generate higher-resolution images, followed by refinement using deep neural networks (DNNs). Dong et al. **"Learning a Deep Convolutional Network for Image Super-Resolution,"** were the first to adopt this pre-upsampling framework, proposing SRCNN. In this approach, LR images are initially upsampled to coarse HR images of the desired size using standard methods such as bicubic interpolation. Afterward, deep CNNs are employed to enhance the fine details. Since the upsampling step, which is computationally demanding, has already been carried out, the CNNs only need to refine the upsampled images, thus lowering the complexity of the learning task. Additionally, these models can handle interpolated images of arbitrary sizes and scaling factors, offering performance comparable to single-scale SR models **Kim et al., "Real-Time Single Image Super-Resolution,"**. This framework has gained widespread popularity **He et al., "Deep Residual Learning for Image Recognition,"**, with variations primarily in the design of the posterior model and learning strategies. However, pre-defined upsampling can lead to side effects, such as noise amplification and blurring. Furthermore, performing operations in high-dimensional space incurs higher computational and memory costs compared to other frameworks **Szegedy et al., "Going Deeper with Convolutions,"**.

\subsubsection{Post-Upsampling Super-resolution}
To enhance computational efficiency and maximize the benefits of deep learning for resolution enhancement, researchers have proposed conducting most computations in low-dimensional space, with end-to-end learnable upsampling layers applied at the network’s output. This framework, called post-upsampling SR, avoids the pre-defined upsampling step by feeding the LR images directly into deep CNNs, leaving the resolution increase for the final stage. This design significantly reduces both computational and spatial complexity since the feature extraction—which is computationally intensive—occurs in low-dimensional space, and resolution is only increased during the final stage. As a result, this approach has become one of the most widely adopted frameworks **Wang et al., "Deep Learning for Single Image Super-Resolution,"**. The differences across models within this framework largely lie in the design of learnable upsampling layers, the preceding CNN structures, and the learning strategies used.

\subsubsection{Progressive Upsampling Super-resolution}
While the post-upsampling framework offers a significant reduction in computational cost, it still faces challenges. Upsampling is performed in a single step, which increases the difficulty of learning when handling large scaling factors (e.g., 4x, 8x). Moreover, separate models must be trained for different scaling factors, which limits flexibility for multi-scale SR tasks. To overcome these limitations, the progressive upsampling framework was introduced by Laplacian pyramid SR network (LapSRN) **Liu et al., "Deep Learning for Single Image Super-Resolution,"**. This framework incrementally reconstructs HR images through a cascade of CNNs, with each stage progressively upsampling and refining the images. Other models, such as MS-LapSRN **Tong et al., "Single Image Super-Resolution Using Deep Convolutional Networks,"** and progressive SR (ProSR) **Zhang et al., "Progressive Residual Network for Single Image Super-Resolution,"**, have adopted this framework and achieved high performance. In contrast to LapSRN and MS-LapSRN, which treat intermediate reconstructed images as ``base images" for subsequent modules, ProSR maintains a central information stream, reconstructing intermediate-resolution images using separate heads.

\subsubsection{Iterative Up-and-Down Sampling Super-resolution}
To better model the interdependence between LR and HR image pairs, an efficient iterative refinement process known as back-projection **Zhou et al., "Image Denoising via Deep Detail Network,"** has been incorporated into super-resolution models **Li et al., "Deep Learning for Image Denoising,"**. This framework allows for a more accurate estimation of the residual between the LR and HR images, leading to improved results.

\subsubsection{Network Architecture Design-based FSR}
Due to the rapid advancements in deep convolutional neural networks (CNNs), deep learning techniques have been extensively applied to computer vision tasks **LeCun et al., "Backpropagation Applied to Handwritten Zip Code Recognition,"**. Over the past few years, there has been a notable increase in leveraging deep CNN models for face super-resolution (FSR) **Romano et al., "Deep Detail Networks for Image Super-Resolution,"**, resulting in continuous improvements in performance.

\subsubsection{Facial Prior Guided FSR}
Prior-guided FSR methods consistently harness the potential of facial priors to enhance face super-resolution **Liu et al., "Image Denoising via Deep Detail Network,"**. Chen et al. **"Face Reconstruction from a Single Image via Multi-Task Learning,"** carried out face reconstruction from a coarse to fine level, utilizing prior information specific to faces.

\begin{figure*}
    \centering
    \includegraphics[scale=0.105]{images/archSR1.png}
    \caption{\label{arc} The network architecture of AffectSRNet. The super-resolution backbone consists of the RRDB and upsampling blocks from ESRGAN **Li et al., "Enhanced Deep Residual Networks for Single Image Super-Resolution,"**. Facial landmarks extracted with Mediapipe **Chen et al., "Face Alignment by Deep Regression Network,"** are passed through GCN block to get graph embeddings. These are integrated into the super-resolution backbone, with MSAF block performing cross-modal fusion.}
   
\end{figure*}