
\section{Main Results}
\label{sec:results}

% \yu{In this section, we need to highlight our contribution. That is, propose the main theorem and introduce our novelty. The following formulations and assumptions can be moved into the Preliminaries.}\yuhaoDone

% \yu{Maybe we can rearrange this section in such flow:

% 1. Introduce the main convergence theorem\yuhaoDone

% 2. Compare to the preivous results in stochastic interpolant\yuhaoDone

% 3. When coming to a well-known instance, we can provide an algorithm with novel stepsizes inspired by our convergence result. Then compare our result to some comparable works.\yuhaoDone

% 5. Further discuss other application to various cases.}

% \yu{I think we can desribe the SDE in Preliminaries}\yuhaoDone

%\longbo{I feel that this should be moved here. also, expand this more, so that people know what the schedule means}
%\longbo{improve this }

In this section, we present a novel analysis for the discrete-time stochastic interpolant framework. Specifically, we focus on the following formulation: given a schedule $\{t_k\}_{k=0}^N\subseteq[0,1]$ where $t_0<t_1<\cdots<t_{N-1}<t_N$, we define an estimated process using the following SDE: 
%\longbo{estimated SDE? is this the common name?}{\color{green} [maybe not, so I moved it below and give an explanation]} SDE
\begin{equation}
\dd\hat{X}_t^F=\hat{b}_F(t_k,\hat{X}_{t_k}^F)\dd t+\sqrt{2\epsilon}\dd W_t,\quad t\in[t_k,t_{k+1}).
\label{eq:estimated-sde}
\end{equation}
In practice, we can express this as:
\begin{equation}
    \begin{aligned}
        X_{t_{k+1}}^F=&X_{t_k}^F+(t_{k+1}-t_k)\hat{b}_F(t_k,\hat{X}_{t_k}^F)\\
        &+\sqrt{2\epsilon(t_{k+1}-t_k)}w_k,\qquad w_k\in N(0,I_d)
    \end{aligned}
    \label{eq:sampler}
\end{equation}
for $k=0,1,\dots,N-1$. 
Here $\hat{b}_F(t,X_t^F)$ represents an estimator of the true drift term $b_F$. 
Equation (\ref{eq:estimated-sde}), or equivalently (\ref{eq:sampler}), corresponds to the Euler-Maruyama discretization of the continuous-time SDE \cite{chen2023improved,chen2023score}. In this paper, we refer to (\ref{eq:estimated-sde}) as the estimated SDE, while (\ref{eq:forward-sde}) is referred to as the true SDE.


%Usually, in real-world applications, we can only access an estimator $\hat{b}_F$ instead of $b_F$. 
% {\color{green}  [\text{Done}]}
%\longbo{I don't understand this sentence. why only finitely many times?} {\color{green}  [\text{Removed, I don't think it should be here now.}]}
% Also, the SDE solver can access the estimator only finitely many times, which means that the interval needs to be cut into small sub-intervals. 


%\longbo{move this to the schedule design? or after theorem 4.3?}
% Moreover, later we choose $0<t_0<t_N<1$. The estimated SDE starts at $\rho(t_0)$ instead of $\rho_0$, and gives an estimate of $\rho(t_N)$ instead of $\rho_1$. This estimate is acceptable when $t_N$ is sufficiently close to $1$.



Below, we present our analysis for the discrete-time stochastic interpolant.  
We begin by introducing the main assumptions, which will be crucial for bounding the error between the estimated distribution and the true target distribution.
% TODO: (done)
% explain the assumptions.
% compare to related works, add references.
\begin{assumption}
    The joint measure $\nu$ defined in the stochastic interpolants (\ref{eq:stochastic-interpolant}) satisfies $\underset{(x_0,x_1)\sim\nu}{\mathbb{E}}\Vert x_0-x_1\Vert^8<\infty$,  
 %$$\underset{(x_0,x_1)\sim\nu}{\mathbb{E}}\Vert x_0-x_1\Vert^8<\infty,$$
    and the interpolation function  is such that
    $$\underset{(x_0,x_1)\sim\nu}{\mathbb{E}}\Vert\partial_t^2I(t,x_0,x_1)\Vert^2\le M_2<\infty,\quad \forall t\in[0,1].$$
    \label{a:regularity}
\end{assumption} 
The first moment bound assumes that the initial and target distributions, $\rho_0$ and $\rho_1$, are not excessively far apart. In fact, the inequality (\ref{eq:I-lip}) further implies that $\mathbb{E}\Vert\partial_tI(t,x_0,x_1)\Vert^8<\infty$ for any $t\in[0,1]$. The second part of the assumption ensures that the time derivative of the interpolation function does not exhibit significant variations. Assumption \ref{a:regularity}  is similar to previous assumptions on stochastic interpolants, with the exception of the first part, which utilizes the eighth moment instead of the fourth moment (see \citealt{interpolation} or Appendix \ref{appendix:preliminaries}).

\begin{assumption}
    The estimator $\hat{b}_F$ satisfies 
    $$\begin{aligned}
        \sum_{k=0}^{N-1}(t_{k+1}-t_k)\mathbb{E}\Vert\hat{b}_F(t_k,x_{t_k})-b_F(t_k,x_{t_k})\Vert^2\le\varepsilon_{b_F}^2,
    \end{aligned}$$
    where the expectations is taken over $x_{t_k}\sim\rho(t_k)$.
    \label{a:estimation}
\end{assumption} 
Assumption \ref{a:estimation} assumes that we have a sufficiently accurate estimator for the drift term $b_F(t,x)$ at the discretized time points. This assumption is analogous to common assumptions employed in the theoretical analysis of diffusion models \cite{dlinear, chen2023improved}. 

%\longbo{why this sentence?}{\color{green}  [\text{Removed, add a few words in the previous part}]}
% Here we consider the case of estimating $b_F$ on $\{t_k\}_{k=0}^{N-1}$ which is used in the discrete-time sampler.

Now we are ready to present our main theorem.

% TODO: under assumptions... (done)
\begin{theorem}
    \label{thm:main}
    Suppose we start with an initial distribution $\hat{\rho}(t_0)$ and evolve the process
    according to the estimated SDE (\ref{eq:estimated-sde}) with $\epsilon=O(1)$ until time $t=t_N$. 
   % Take $\epsilon=\Theta(1)$. Suppose we start from $t=t_0$ and initial distribution $\hat{\rho}(t_0)$, and then evolves through the SDE \eqref{eq:estimated-sde} until time $t=t_N$. 
    Let $\hat{\rho}(t_N)$ be the distribution obtained at time $t=t_N$. Denote the ground truth marginal distributions by $\{\rho(t)\}_{t\in[0,1]}$, and define $\bar{\gamma}_k=\min_{t\in[t_k,t_{k+1}]}\gamma(t)$. We have  under Assumptions \ref{a:regularity} and \ref{a:estimation} that: 
    $$\begin{aligned}
        &\qquad \textnormal{KL}(\rho(t_N)\Vert\hat{\rho}(t_N))\\
        &\lesssim\textnormal{KL}(\rho(t_0)\Vert\hat{\rho}(t_0))+\varepsilon_{b_F}^2+\epsilon^{-1}\sum_{k=0}^{N-1}(t_{k+1}-t_k)^3\\
&\qquad\qquad\cdot\left[M_2+\bar{\gamma}_k^{-6}d^3+\bar{\gamma}_k^{-2}d\sqrt{\mathbb{E}\Vert x_0-x_1\Vert^{8}}\right]\\
        &\qquad+\sum_{k=0}^{N-1}(t_{k+1}-t_k)^2\bar{\gamma}_k^{-2}d\left[\sqrt{\mathbb{E}\Vert x_0-x_1\Vert^4}+\bar{\gamma}_k^{-2}d\right]
    \end{aligned}$$
Here the notation $f\lesssim g$ denotes  $f=O(g)$.
\end{theorem} 
%\longbo{i think we need to explain why we start with $t_0$}

%\longbo{the text after the theorem is a bit unorganized. I think one flow could be: 1. we remark that the theorem is the first result on discrete-time SI, and it offers insight  and theoretical characterization about different factors, and it is drastically different from existing results. 2. then, you give a slightly more detailed explanation about what each term means. here you can connect to previous results in existing work. why we do it in 0-1 can also be stated here. 
%3. we state that this can also be used to optimize the time-schedule design, and point to the later section where we do it. }\yuhaoDone
%\longbo{explain what is $\lesssim$ } {\color{orange}[done]}
\Cref{thm:main} provides the first finite-time error bound for the  discrete-time stochastic interpolant framework (\ref{eq:forward-sde}), i.e., SDE (\ref{eq:estimated-sde}). It explicitly quantifies the impact of the initial distribution mismatch (i.e., $\text{KL}(\rho(t_0)\Vert\hat{\rho}(t_N))$) and the $b_F$ estimation error (i.e.,  $\varepsilon_{b_F}^2$), demonstrates their dependence on the choice of latent scale $\gamma(t)$ and the time discretization schedule $\{t_k\}_{k=0}^N$. Notably, the bound offers a novel theoretical explanation for how the convergence behavior depends on the distance between the source and destination distributions, as reflected in the terms involving $\mathbb{E}\Vert x_0-x_1\Vert^p$ with $p=4$ and $p=8$.

Now we explain the terms in \Cref{thm:main}.

The terms $(t_{k+1}-t_k)^3\left[M_2+\bar{\gamma}_k^{-2}d\sqrt{\mathbb{E}\Vert x_0-x_1\Vert^8}\right]$ and $(t_{k+1}-t_k)^2\bar{\gamma}_k^{-2}d\sqrt{\mathbb{E}\Vert x_0-x_1\Vert^4}$ quantify the discretization error associated with the velocity function $v(t,x)$ (\Cref{def:v}), which is a component of the drift term $b_F(t,x)$. Notably, the distance of form $\mathbb{E}\Vert x_0-x_1\Vert^p$ is involved here, highlighting the influence of the distance between the source and target distributions on the discretization error. 

Conversely, the terms $(t_{k+1}-t_k)^3\bar{\gamma}_k^{-6}d^3$ and $(t_{k+1}-t_k)^2\bar{\gamma}_k^{-4}d^2$ quantify the discretization error arising from the score function $s(t,x)$. This component of the discretization error exhibits a stronger dependence on the latent scale $\gamma(t)$ and the data dimension $d$. Specifically, assuming sufficiently small step sizes, the dependence of the score discretization error on $\gamma(t)$ is $\bar{\gamma}_k^{-4}$ (if we assume sufficiently small step sizes), which aligns with the findings for diffusion models \cite{chen2023improved, dlinear}.

Since $\gamma(0)=\gamma(1)=0$, the discretization error will become unbounded if we were to simulate the estimated SDE (\ref{eq:estimated-sde}) from $t_0=0$ to $t_N=1$. To address this, we choose $0<t_0<t_N<1$ to ensure that $\bar{\gamma}_k$ is lower bounded, thereby maintaining a finite discretization error bound in \Cref{thm:main}. Under this approach, the SDE is simulated within the interval $[t_0,t_N]$, and an estimation of $\rho(t_N)$ is obtained instead of $\rho_1$. This is acceptable when $t_N$ is sufficiently close to $1$, as $\rho(t_N)$ will be sufficiently close to $\rho_1$ (e.g., in terms of Wasserstein distance). This practice of choosing $t_N<1$ is analogous to the early stopping technique commonly employed in diffusion models \cite{song2021scorebased,chen2023improved,dlinear}. % \longbo{add one more ref using early stopping}.

The term $\text{KL}(\rho(t_0)\Vert\hat{\rho}(t_0))$ quantifies the effect of choosing a slightly different base distribution. As discussed earlier, we typically choose $t_0>0$, and in many cases, the true base distribution $\rho(t_0)$ may not be readily available. This bound theoretically supports the use of a similar base distribution $\hat{\rho}(t_0)$ as an approximation for the true base distribution. 

Finally, the term $\varepsilon_{b_F}^2$ accounts for the error in estimating the drift term $b_F(t,x)$. % \longbo{is this function or the coefficient?}. 
Compared to previous continuous-time analyses of the stochastic interpolant framework, which typically measure the estimation error by an averaged error over the entire time interval \cite{flows, interpolation}, our analysis evaluates the estimation error using a weighted average of the errors at the discretized time points.

The bound provided by \Cref{thm:main} explicitly depends on the choice of latent scale $\gamma(t)$ and the time schedule $\{t_k\}_{k=0}^N$. This dependence can be leveraged to assess the computational complexity for a given time schedule under a specific choice of $\gamma(t)$. In Section \ref{sec:instance}, we will develop a time schedule that achieves a fast convergence rate. %for a common  $\gamma(t)$.

% \longbo{why make this a remark? waht message you want to convey?}

% \textbf{Remark:} For the choice of $\hat{\rho}(t_0)$, Theorem 3.2 in \cite{interpolation} considers $I(t,x_0,x_1)=x_0$ for some interval $t\in[0,\delta]$ where $\delta>0$, and then $\rho(t_0)$ for $t_0<\delta$,  if we can sample from $\rho_0$. It was used for the  case where $\rho_0$ is a single data point. %{\color{green}  [\text{Modified}]}

% % TODO: compare the technical points with existing work. highlight technical novelty.
% % TODO: (done)

% \longbo{explain why we start from $t_0$ instead of 0}\yuhaoDone\longbo{i am not sure if this is done? check}

% \Cref{thm:main} provides the very first discrete-time error bound for the stochastic interpolant  framework (\ref{eq:estimated-sde}). It explicitly quantifies the impact of the initial distribution shift, i.e., $\textnormal{KL}(\rho(t_0)\Vert\hat{\rho}(t_0))$, and offers a theoretical explanation about how the convergence depends on the distance between the source and destination distributions, i.e., the terms involving $\mathbb{E}\Vert x_0-x_1\Vert$. 
% % 
% %that considers a discretized process instead of a continuous process. 
% Since $\gamma(0)=\gamma(1)=0$, if $\gamma(t)>0$ for all $t\in(0,1)$, by taking $0<t_0<t_N<1$, we can lower bound $\bar{\gamma}_k$ so that KL upper bound is finite. In contrast, if we choose $t_0=0$ or $t_N=1$, the bound in \Cref{thm:main} is infinite, which is the reason we choose to simulate the SDE in the interval $[t_0,t_N]$ instead of in the whole interval $[0,1]$. When $t_N$ is sufficiently close to $1$, $\rho(t_N)$ is sufficiently close to $\rho_1$ (e.g., in Wasserstein distances){\color{green}[Modified]} so it is acceptable \longbo{what is "acceptable"?} to use $\rho(t_N)$ to estimate $\rho_1$. After a concrete choice of schedule $\{t_k\}_{k=0}^N$, we can apply \Cref{thm:main} to directly compute an upper bound of distribution estimation error. 

% The first term $\textnormal{KL}(\rho(t_0)\Vert\hat{\rho}(t_0))$ indicates how close $\hat{\rho}(t_0)$ is to $\rho(t_0)$, and it limits the error caused by using a slightly different base distribution. This indicates that when $\rho(t_0)$ is not available, we can use a similar $\hat{\rho}(t_0)$ with available samples instead (for example, take $\hat{\rho}(t_0)=\rho_0$).
% % This implies that $\rho(t_0)$ can be replaced by $\rho_0$ as long as they are sufficiently close when implementing a sampler.
% % One application is that we can just replace $\rho(t_0)$ with $\rho_0$ when they are sufficiently close. 
% %\longbo{what do you mean by "application"?}{\color{green}[Modified]}
% The term $\varepsilon_{b_F}^2$ comes from Assumption \ref{a:estimation}, which only depends on the quality of the estimator. The first two terms are independent of the step sizes. The terms $M_2$, $\gamma_k^{-2}d\sqrt{\mathbb{E}\Vert x_0-x_1\Vert^8}$ and $\gamma_k^{-2}d\sqrt{\mathbb{E}\Vert x_0-x_1\Vert^4}$ come from the discretization error on the velocity function $v(t,x)=\mathbb{E}[\partial_tI(t,x_0,x_1)|x_t=x]$, which is part of the function $b_F$. The distribution distance terms (i.e. $\mathbb{E}\Vert x_0-x_1\Vert^4$ and $\mathbb{E}\Vert x_0-x_1\Vert^8$) depend on both the distance between two distributions and the choice of joint distribution $\nu$, where the dependence on $\nu$ indicates how well the data are coupled. This fits the intuition that for data distributions that are close or well coupled, the distribution estimation error is smaller. The terms $\gamma_k^{-6}d^3$ and $\gamma_k^{-4}d^2$ comes from the discretization error on the score function $s(t,x)$, which is another part of $b_F$. As we show in Section \ref{sec:instance}, when the time schedule $\{t_k\}_{k=1}^N$ is well chosen, the terms with dependences $(t_{k+1}-t_k)^3$ on the step sizes are dominated by the other terms. \longbo{some where highlight that we establish the $\gamma_k^{-2}d\sqrt{\mathbb{E}\Vert x_0-x_1\Vert^4}$ type bound, which helps to quantify the impact of distribution similarity}

% %\longbo{compare it with existing results? --- more refs}{\color{green}  [\text{Done?}]}

% % TODO: rewrite, add references (done)
% Compared to results given by \cite{interpolation}, \Cref{thm:main} gives a bound for the case when the discretization error is considered. The estimation error is measured using $\varepsilon^2$, which is a weighted sum for the estimation error at each time point we estimate $b_F$ instead of an averaged estimation error over the whole time interval. Also, the dependence on $\bar{\gamma}_k$ is $\bar{\gamma}_k^{-4}$ (in the dominating term), which is the same as the results for diffusion models \cite{chen2023improved,dlinear}. In fact, choosing $1-t_N>0$ is similar to early stopping which is frequently used in the diffusion models (\cite{song2021scorebased}). \longbo{a ref for this last statement?}
% We also assume $t_0>0$ and $t_N<1$ so that $\bar{\gamma}_k$ is lower bounded so that the bound is finite, which is similar to early stopping in the diffusion models.

% TODO: list the main steps (done)
% 技术上创新点，哪些地方之前的结果不能用，我们开发了什么新的技术，哪些地方不同

We now provide a proof sketch for  Theorem \ref{thm:main}. 
%\longbo{try to improve. right now the sketch contains three independent steps.}

\paragraph{Proof Sketch of Theorem \ref{thm:main}}
% \yu{It is a little werid that we make a single subsection here. Maybe use paragraph?} 
The proof of \Cref{thm:main} contains two key steps. In step one, we establish a bound on the KL divergence due to discretization error in the drift term $b_F(t,x)$ of the SDE, based on Girsanov's theorem. 
%adapt Girsanov's theorem to bound the KL divergence by discretization error in the drift term $b_F(t, x)$ of the SDE. 
Then, in step two, we exploit special structure of the $b_F(t,x)$ by expressing its derivatives as conditional covariances, enabling the application of relevant expectation inequalities and eventually bounding the discretization error. 

%we bound this discretization error by carefully partitioning it into {\color{orange}several derivatives of the drift term $b_F(t,x)$}. \longbo{can you highlight the novel steps?}
%A key technique for bounding these derivatives involves expressing them as conditional covariances, enabling the application of relevant expectation inequalities.


%To prove \Cref{thm:main}, we first adapt Girsanov's theorem to bound the KL divergence by discretization error in the drift term $b_F(t, x)$ of the SDE. Subsequently, we bound this discretization error by carefully partitioning it into several derivatives. A key technique for bounding these derivatives involves expressing them as conditional covariances, enabling the application of relevant expectation inequalities.

%\longbo{highlight hte technical novelty of the steps, by comparing them to existing methods/analysis}\yuhaoDone
%\yu{We do not need to make the proof rigorous. But make sure the story you tell here is consistent and easy to follow.}

%\longbo{give a high level summary here first in 1-2 sentences, so that people know what to expect. connect them to the terms in the theorem}\yuhaoDone


\paragraph{Step One: Bounding the KL-divergence with Discretization Error.}

Leveraging the results provided by \citet{chen2023ddpm} (see Proposition \ref{prop:girsanov}), which are derived using Girsanov's theorem, we obtain the following bound:
$$\begin{aligned}
    &\qquad\textnormal{KL}(\rho(t_N)\Vert\hat{\rho}(t_N))\\
    &\le\text{KL}(\rho(t_0)\Vert\hat{\rho}(t_0))+\text{KL}(P\Vert Q)\\
    &=\underbrace{\text{KL}(\rho(t_0)\Vert\hat{\rho}(t_0))}_{\text{Initialization error}}\\
    &\quad+\frac{1}{4\epsilon}\sum_{k=0}^{N-1}\int_{t_k}^{t_{k+1}}\mathbb{E}[\Vert b_F(t,X_t^F)-\hat{b}_F(t_k,X_{t_k}^F)\Vert^2]\dd t
\end{aligned}$$
where $P$ and $Q$ represent the path measures of the solutions to the true SDE (\ref{eq:forward-sde}) and estimated SDE (\ref{eq:estimated-sde}), respectively, both with the same initial distribution $\rho(t_0)$. Applying the triangle inequality yields: 
$$\begin{aligned}
    &\qquad\mathbb{E}[\Vert b_F(t,X_t^F)-\hat{b}_F(t_k,X_{t_k}^F)\Vert^2]\\
    &\le2\underbrace{\mathbb{E}[\Vert b_F(t,X_t^F)-b_F(t_k,X_{t_k}^F)\Vert^2]}_{\text{Discretization error}}\\
    &\quad+2\underbrace{\mathbb{E}[\Vert b_F(t_k,X_{t_k}^F)-\hat{b}_F(t_k,X_{t_k}^F)\Vert^2}_{\text{Estimation error}}]
\end{aligned}$$
The second term on the right-hand-side corresponds to the estimation error of $\hat{b}_F(t,x)$, and its summation can be bounded by $\varepsilon_{b_F}^2$ according to Assumption \ref{a:estimation}. The first term, on the other hand, represents the discretization error associated with $b_F(t,x)$ and requires further analysis.

% 把这一步和下一步合并
\paragraph{Step Two: Bound the Discretization Error.} 
We now bound the discretization error above. 
A central tool in this part is the It\^o's formula. By applying It\^o's formula, we obtain:
\begin{equation}
    \begin{aligned}
        \int_{t_k}^t\dd b_F(s,X_s^F)&=\int_{t_k}^t\partial_sb_F(s,X_s^F)\dd s\\
        &\quad+\int_{t_k}^t\nabla b_F(s,X_s^F)\cdot b_F(s,X_s^F)\dd s\\
        &\quad+\int_{t_k}^t\epsilon\Delta b_F(s,X_s^F)\dd s\\
        &\quad+\int_{t_k}^t\sqrt{2\epsilon}\nabla b_F(s,X_s^F)\cdot\dd W_s.
    \end{aligned}
    \label{eq:ito-bf}
\end{equation}
% 不要罗列技术细节，大概讲一下
While the application of It\^o's formula is analogous to that of \citet{dlinear}, we refrain from eliminating the three linear terms due to their more complex forms in the context of stochastic interpolants. Instead, we apply Jensen's inequality on the integrals with respect to time and apply It\^o's isometry (\citealt{le2016brownian}, Equation 5.8) on the integral with respect to Brownian motion, so that we can bound the term by the derivatives of $b_F(t,x)$ %\longbo{can you highlight the novelty if possible} 
(i.e., terms like $\partial_tb_F(t,x)$ and $\nabla_xb_F(t,x)$, see Lemma \ref{lem:discretize}). 

%\longbo{i don't understand the connection between these following two paragraphs with the above. they are more technical but less clear in the big picture. improve} 

Since $b_F(t,x)$ can be expressed as a linear combination of $v(t,x)$ and $s(t,x)$, it remains to bound the derivatives of both $v(t,x)$ and $s(t,x)$, respectively.  %\longbo{write the full form, i.e., $v(t,x)$ and $s(t,x)$. otherwise it can be confusing}.
Note that $v(t,x)$ and $s(t,x)$ can be written as the conditional expectations of $\partial_tI$ and $\gamma^{-1}z=\frac{x_t-I}{\gamma^2}$ given $x_t=x$. To bound the derivatives of these conditional expectations, we employ the following key equality:
$$\begin{aligned}
    \partial_{\alpha}\mathbb{E}[f|x_t=x]
    &=\mathbb{E}[\partial_{\alpha}f|x_t=x]\\
    &+\text{Cov}(f,\partial_{\alpha}[-\Vert x-I\Vert^2/2\gamma^2]|x_t=x).\\
\end{aligned}$$
Here $\alpha$ can represent either $x$ or $t$. This equality crucially relies on the Gaussian latent term $\gamma(t)z$ introduced in the stochastic interpolant framework. This generalizes the result for $s(t,x)=\nabla\log\rho(t,x)=\mathbb{E}[\gamma^{-2}(I-x_t)|x_t=x]$ %\longbo{write the full form of $f$ and $s$?}{\color{orange}[modified]} 
in diffusion models, as found in previous works (see, e.g., \citealt{manifold, dlinear}). We apply this equality extensively and derive bounds for both $s(t,x)$ and $v(t,x)$, where the function $v(t,x)$ does not appear or appears in a much simpler form (such as $x$) in the context of diffusion model theories. Subsequently, we apply a series of inequalities to ultimately bound the expectation over $x_t$. Detailed derivations and proofs can be found in \ref{appendix:lemmas}.
% $$\begin{aligned}
%     \mathbb{E}\Vert\partial_tb_F(t,X_t^F)\Vert^2,\\
%     \mathbb{E}\Vert\nabla b_F(t,X_t^F)\cdot b_F(t,X_t^F)\Vert^2,\\
%         \mathbb{E}\Vert\Delta b_F(t,X_t^F)\Vert^2,\\
%         \mathbb{E}\Vert\nabla b_F(t,X_t^F)\Vert_F^2,
% \end{aligned}$$
% and then use It\^o's isometry and Jensen's inequality to further bound the discretization error.

% \paragraph{Bounding the Derivatives} (Lemmas \ref{lem:v-time}-\ref{lem:s-laplace})

% According to (\ref{eq:ito-bf}) and the previous paragraph, we want to bound the derivatives of $b_F$. Since we can write $b_F(t,x)$ by a linear combination of $v(t,x)$ and $s(t,x)$, we can study the derivatives for $v$ and $s$ respectively and finally combine them to obtain the full bound.

% We first observe that $v(t,x)$ and $s(t,x)$ can be written in the form of expectations under the condition $x_t=x$. The key idea is to derive the following equality for a conditional expectation of form $\mathbb{E}[f|x_t=x]$:
% $$\begin{aligned}
%     \partial_{\alpha}\mathbb{E}[f|x_t=x]
%     &=\mathbb{E}[\partial_{\alpha}f|x_t=x]\\
%     &+\text{Cov}(f,\partial_{\alpha}[-\Vert x-I\Vert^2/2\gamma^2]|x_t=x),\\
% \end{aligned}$$
% where $\alpha$ is one of $x$ and $t$. The above equality highly relies on the Gaussian latent term $\gamma(t)z$ introduced in the stochastic interpolants. This extends the case for $f=s=\nabla\log\rho$ in diffusion models, which can be found in previous works (see e.g. \cite{manifold, dlinear}). We use the above equality much more often and developed the bounds for $v$, which does not appear (or appears as a very simple form such as $x$) in the theories of diffusion model. We then apply a series of inequalities to finally bound the expectation taken over $x_t$.

%\yu{It is a little confused why we should bound these terms. We should show why in a general reason. If you want to list these terms, make sure that you can introduce the details for each term respectively.}
%\yu{I think we can just say that we need to bound the derivatives of $b_F$. Then explain how this term contribute to final complexity. Then show the main intuition of our proof to bound derivative. Finally give references and say for more details, please refer to the details in appendix.}\yuhaoDone

% First we already know that $X_t^F$ have the same distribution as $x_t\sim\rho(t)$ because $X_t^F$ is evolved through the true forward SDE. The key idea is to show that for a conditional expectation of form $\mathbb{E}[f|x_t=x]$, we have
% $$\begin{aligned}
%     \partial_t\mathbb{E}[f|x_t=x]
%     &=\mathbb{E}[\partial_tf|x_t=x]\\
%     &+\text{Cov}(f,\partial_t[-\Vert x-I\Vert^2/2\gamma^2]|x_t=x),\\
%     \nabla_x\mathbb{E}[f|x_t=x]
%     &=\mathbb{E}[\nabla_xf|x_t=x]\\
%     &+\text{Cov}(f,\nabla_x[-\Vert x-I\Vert^2/2\gamma^2]|x_t=x).
% \end{aligned}$$
% In fact, when $f=\nabla\log\rho$, the second equality above can be found in previous works (see e.g. \cite{manifold, dlinear}). We generalize the ideas and then use this equality much more often. By writing the derivatives in the form of conditional covariances, we can use the Cauchy-Schwarz inequalities to upper bound the norm of the derivatives, and use Jensen's inequality to bound the overall expectation taken over $x_t$. Check Appendix \ref{appendix:lemmas} for details.