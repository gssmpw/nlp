
\section{More Details of Numerical Experiments}
\label{appendix:experiments}

% \subsection{Details for Experiments on 2-dimensional Data}
% \label{appendix:2dim}

To parameterize the estimator $\hat{b}_F(t,x)$ for two-dimensional data, we utilize a simple multilayer perceptron (MLP) network. The input of the network comprises a three-dimensional vector $(x,t)$, and its output is a two-dimensional vector $\hat{b}_F(t,x)$. The MLP architecture consists of three hidden layers, each with $256$ neurons, followed by ReLU activation functions \cite{nair2010rectified}. 

To train the estimator $\hat{b}_F(t,x)$, we leverage a simple quadratic objective (see Appendix \ref{appendix:preliminaries} for details) whose optimizer is the real drift $b_F(t,x)$. Given the estimator, data batches, and sampled time points, we are ready to compute an empirical loss. We employ the Adam optimizer \cite{adam} to train the network using the gradient computed on the empirical loss. 

We set $t_0=0.001$ and $t_N=0.999$ to ensure that the initial density $\rho(t_0)$ is close to $\rho_0$ and the estimated density $\rho(t_N)$ closely approximates $\rho_1$. We implement the discretized sampler as defined in Equation (\ref{eq:sampler}). We use more than $10,000$ data samples to empirically visualize the densities in Figures \ref{fig:1}, \ref{fig:2} and \ref{fig:4}.

In addition, for TV distance estimation used in Figures \ref{fig:3} and \ref{fig:5}, we utilize $60,000$ samples from both the target density and the generated densities, partition the area $[-10,10]\times[-10,10]$ into a $100\times100$ grid, and estimate the true density function based on the number of samples within each cell.
%\longbo{which optimizer exactly?} {\color{orange}[I thought Adam was here]}

\begin{figure}[htb]
    \centering
    \includegraphics[width=0.4\linewidth]{images/tvdist3.png}
    \caption{Estimated TV distance for different step size schedules, where we use $\gamma^2(t)=(1-t)^2t$. The red curve denotes the distance when we use the schedule designed in \Cref{appendix:another}, while the green curve denotes the distance when we use the uniform schedule.}
    \label{fig:a1}
\end{figure}


\subsection{Additional Experiments for $\gamma(t)=\sqrt{(1-t)^2t}$}

We implement the schedule discussed in \Cref{appendix:another} and compare it to the uniform schedule. We choose $(t_0,t_N)=(0.001,0.97)$ since $\gamma^2(t)$ is $\Theta((1-t)^2)$ near $t=1$. We choose $\rho_0$ as the ``checkerboard" density and $\rho_1$ as the ``spiral" density. We estimate the TV distance $\text{TV}(\rho(t_N)\Vert\hat{\rho}(t_N))$ to indicate how close the estimated distribution is to the target distribution. The comparison is shown in Figure \ref{fig:a1}.

% \subsection{Details for Experiments on Image Datasets}

% In this part of our experiments, we test the sampler on the Oxford flowers dataset \cite{nilsback2006visual}. The images are clipped and resized to $128\times 128$. The score $\hat{s}(t,x)$ and velocity $\hat{v}(t,x)$ networks are parameterized with the U-Net implementation provided by the public diffusion code \href{https://github.com/lucidrains/denoising-diffusion-pytorch}{https://github.com/lucidrains/denoising-diffusion-pytorch}. We follow the choice of hyper-parameters as \cite{flows} but replace the hidden dim by $64$.

% We choose $I(t,x_0,x_1)=(1-t)x_0+tx_1$ and $\gamma(t)=\sqrt{2t(1-t)}$ in the stochastic interpolant. We consider an image-to-image generation case where both $\rho_0$ and $\rho_1$ are the Oxford flowers dataset, with three different choices of joint distribution $\nu$: (i) $x_0=x_1$; (ii) $x_0$ and $x_1$ are different, but they are sampled from the same class of flowers; (iii) (independent) $x_0$ and $x_1$ are arbitrarily coupled in the dataset. We train the score and velocity estimators for all three cases, and then compare the convergence using different schedules. Figure \ref{fig:flowers1-2} visualizes the comparison. When comparing different choices of $\nu$, we can see that the coupling $x_0=x_1$ has the fastest convergence rate. When comparing different choice of schedules, we can see that the generated images in Figure \ref{fig:flowers2} have more ``Gaussian-like" noise than the images in Figure \ref{fig:flowers1}, while the overall structures (e.g. the shape and the background blurring) converge at a similar rate.

% \begin{figure}[htb]
%     \centering
%     \begin{subfigure}[b]{0.75\linewidth}
%         \includegraphics[width=\linewidth]{images/flowers-convergence-exponential.png}
%         \caption{The generated images using the exponentially decaying schedule in Section \ref{sec:instance}.}
%         \label{fig:flowers1}
%     \end{subfigure}

%     \begin{subfigure}[b]{0.75\linewidth}
%         \includegraphics[width=\linewidth]{images/flowers-convergence-uniform.png}
%         \caption{The generated images using the uniform schedule.}
%         \label{fig:flowers2}
%     \end{subfigure}
%     \caption{A comparison of different choice of $\nu$ and different choice of schedule. Here $\rho_0$ and $\rho_1$ are the same Oxford flowers dataset, and the only difference is how the data $(x_0,x_1)$ is coupled. (i) refers to the coupling $x_0=x_1$, (ii) refers to the coupling s.t. each pair $(x_0,x_1)$ is sampled from the same class, and (iii) refers to the case where $x_0$ and $x_1$ are arbitrarily coupled.}
%     \label{fig:flowers1-2}
% \end{figure}

