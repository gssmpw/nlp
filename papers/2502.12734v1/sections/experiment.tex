\section{Experiment Results}  
\label{sec:exp}
\vspace{-0.2cm}
We conduct extensive experiments to comprehensively evaluate the defense performance of our \defensename and also reveal the vulnerability of the current defense strategy with the adversarial examples generated by \attackname.

\begin{table*}[ht]
\centering
\renewcommand\arraystretch{1.8}
\footnotesize
\resizebox{\textwidth}{!}{
\begin{tabular}{c c c c c c c c c c c c c}
\toprule
\multirow{2}{*}{\textbf{Category}} 
& \multirow{2}{*}{\textbf{Method}} 
& \multirow{2}{*}{\textbf{Metric}} 
& \multicolumn{1}{c}{\textbf{Baseline}} 
& \multicolumn{6}{c}{\textbf{Adversarial Data Augmentation}} 
& \multicolumn{3}{c}{\textbf{Adversarial Training}} \\
\cmidrule(lr){4-4} \cmidrule(lr){5-10} \cmidrule(lr){11-13}
& & 
& F.t.XLM-RoBERTa-Base 
& EP & PP & CERT-ED & RanMask & Text-RS & Text-CRS 
& VAT & TAVAT & \defensename \\
\midrule

\multirow{12}{*}{\makecell{\textbf{Text} \\ \textbf{Perturbation}}}

& \textbf{\emph{Mixed Edit}} 
& \emph{ASR(\%)$\downarrow$}  
& 34.65 & \cellcolor{green!50}{4.58} & 32.33 & 16.74 & 17.00 & 22.81 & 15.34 & 33.19 & 37.50 & 8.85 \\

& \textbf{\emph{Paraphrasing}}
& \emph{ASR(\%)$\downarrow$} 
& 70.58 & 54.65 & 6.27 & 32.10 & 40.20 & 59.58 & 26.67 & 67.98 & 65.90 & \cellcolor{green!50}{3.45} \\

& \textbf{\emph{Code-switching MF}$^{*}$}
& \emph{ASR(\%)$\downarrow$} 
& 50.58 & 38.37 & 34.08 & 29.19 & 27.78 & 48.80 & 27.15 & 36.71 & 47.52 & \cellcolor{green!50}{1.13} \\

& \textbf{\emph{Code-switching MR}$^{*}$}
& \emph{ASR(\%)$\downarrow$}  
& 47.91 & 31.23 & 30.21 & 5.30  & 10.80 & 16.98 & 14.36 & 38.03 & 46.46 & \cellcolor{green!50}{1.02} \\

& \textbf{\emph{Human Obfuscation}}
& \emph{ASR(\%)$\downarrow$}  
& 18.42 & 22.19 & 27.00 & 13.64 & 18.86 & 18.05 & 15.24 & 25.35 & 24.17 & \cellcolor{green!50}{0.86} \\

& \textbf{\emph{Emoji-cogen}}
& \emph{ASR(\%)$\downarrow$} 
& 32.19 & 46.55 & 44.17 & 11.41 & 22.23 & 17.72 & 27.10 & 52.35 & 40.33 & \cellcolor{green!50}{0.47} \\

& \textbf{\emph{Typo-cogen}}
& \emph{ASR(\%)$\downarrow$} 
& 60.10 & 61.57 & 59.72 & 27.29 & 38.82 & 37.09 & 44.79 & 70.26 & 63.04 & \cellcolor{green!50}{1.08} \\

& \textbf{\emph{ICL}} 
& \emph{ASR(\%)$\downarrow$}
& 1.40 & 1.41 & 1.30 & 1.72 & 0.83 & 1.89 & 0.67 & 1.13 & 1.88 & \cellcolor{green!50}{0.20} \\

& \textbf{\emph{Prompt Paraphrasing}}
& \emph{ASR(\%)$\downarrow$} 
& \cellcolor{green!50}{0.00} & 0.69 & \cellcolor{green!50}{0.00} & 0.70 & \cellcolor{green!50}0.00 & \cellcolor{green!50}{0.00} & \cellcolor{green!50}0.00 & \cellcolor{green!50}0.00 & \cellcolor{green!50}0.00 & 0.23 \\

& \textbf{\emph{CSGen}}
& \emph{ASR(\%)$\downarrow$}  
& 25.44 & 22.81 & 6.14 & 10.65 & 1.70 & 2.41 & 23.95 & 26.88 & 27.52 & \cellcolor{green!50}0.00 \\

\cdashline{2-13}[1pt/1pt]

& \textbf{\emph{Avg.}} 
& \emph{ASR(\%)$\downarrow$}  
& 34.13 & 28.41 & 24.12 & 14.87 & 17.82 & 22.53 & 19.53 & 35.19 & 35.43 & \cellcolor{green!50}1.73 \\

\midrule

\multirow{12}{*}{\makecell{\textbf{Adversarial} \\ \textbf{Attack}} }

& \multirow{2}{*}{\textbf{\emph{PWWS}}} 
& \emph{ASR(\%)$\downarrow$}
& 61.45 & 48.47 & 49.06 & 11.07 & 14.83 & 16.13 & 19.15 & 53.56 & 62.68 & \cellcolor{green!50}5.91 \\
& 
& \emph{Queries$\uparrow$} 
& 1197.95 & 1237.62 & 1235.01 & 1371.28 & 1361.15 & 1356.67 & 1342.15 & 1226.53 & 1180.87 & \cellcolor{green!50}1390.69 \\

& \multirow{2}{*}{\textbf{\emph{TextFooler}}} 
& \emph{ASR(\%)$\downarrow$} 
& 72.29 & 70.76 & 70.02 & 11.07 & 17.43 & 19.56 & 22.98 & 69.25 & 94.02 & \cellcolor{green!50}6.11 \\
& 
& \emph{Queries$\uparrow$} 
& 690.92 & 724.23 & 713.77 & 1362.17 & 1291.35 & 1271.34 & 1237.18 & 780.51 & 440.28 & \cellcolor{green!50}1396.52 \\

& \multirow{2}{*}{\textbf{\emph{BERTAttack}}} 
& \emph{ASR(\%)$\downarrow$}
& 71.49 & 69.34 & 63.52 & 6.04 & 12.42 & 12.30 & 16.94 & 69.45 & 93.81 & \cellcolor{green!50}5.70 \\
& 
& \emph{Queries$\uparrow$} 
& 411.54 & 446.64 & 425.68 & 710.56 & 682.29 & 680.14 & 667.82 & 450.57 & 279.02 & \cellcolor{green!50}718.84 \\

& \multirow{2}{*}{\textbf{\emph{A2T}}} 
& \emph{ASR(\%)$\downarrow$}
& 45.47 & 37.45 & 50.10 & 6.24 & 11.22 & 14.52 & 14.31 & 29.12 & 54.64 & \cellcolor{green!50}5.09 \\
& 
& \emph{Queries$\uparrow$} 
& 293.26 & 320.88 & 302.18 & 516.07 & 499.89 & 493.25 & 488.91 & 361.88 & 207.15 & \cellcolor{green!50}519.77 \\

& \multirow{2}{*}{\textbf{\emph{GREATER-A(ours)}}} 
& \emph{ASR(\%)$\downarrow$} 
& 96.58 & 87.08 & 84.34 & 62.17 & 63.58 & 75.25 & 82.29 & 89.26 & 85.02 & \cellcolor{green!50}46.08 \\
& 
& \emph{Queries$\uparrow$} 
& 62.63 & 66.71 & 68.53 & 99.56 & 98.92 & 106.08 & 75.98 & 63.57 & 67.17 & \cellcolor{green!50}190.64 \\

\cdashline{2-13}[1pt/1pt]

& \multirow{2}{*}{\textbf{\emph{Avg.}}} 
& \emph{ASR(\%)$\downarrow$} 
& 69.46 & 62.62 & 63.41 & 19.32 & 23.90 & 27.55 & 31.13 & 62.13 & 78.03 & \cellcolor{green!50}13.78 \\
& 
& \emph{Queries$\uparrow$}
& 531.26 & 559.22 & 549.03 & 811.93 & 786.72 & 781.50 & 762.41 & 576.61 & 434.90 & \cellcolor{green!50}843.29 \\

\midrule
% ----- Total (Overall ASR) Row -----
\multirow{1}{*}{\textbf{Total}} & \textbf{\emph{Avg.}} & \emph{ASR(\%)$\downarrow$} 
& 45.90 & 39.81 & 37.22 & 16.36 & 19.85 & 24.21 & 23.40 & 44.17 & 49.63 & \cellcolor{green!50}5.75\\
\bottomrule
\end{tabular}
}
\caption{\textbf{Performance of defense methods under different attacks.} 
The best results are highlighted in \colorbox{green!50}{green} background.
${*}$ means that Code-switching MF and Code-switching MR are two variations of Code-switching method.}
\vspace{-0.5cm}
\label{tab:all_results_modified}
\end{table*}


\subsection{Defense Performance for \defensename}
\fakeparagraph{Experiment Setting.}
We evaluate our defense model \defensename against 14 text perturbation and adversarial attack methods, whose detailed introductions are outlined in the Appendix~\ref{sec:pert}. 
The competitors include \textbf{i) data augmentation methods:} Editing Pretrained (EP) \cite{wang2024comprehensive}, Paraphrasing Pretrained (PP) \cite{wang2024comprehensive}, CERT-ED \cite{huang2024cert}, RanMask \cite{zeng2023certified}, Text-RS \cite{zhang2024random}, Text-CRS \cite{zhang2024text}.
\textbf{ii) adversarial training methods:}
Virtual Adversarial Training (VAT) \cite{miyato2016virtual}, Token Aware Virtual Adversarial Training (TAVAT) \cite{li2021tavat}.
Detailed introduction and implementation are presented in Appendix \ref{apdx:defmethod} and \ref{appdx:implementation}. The dataset we use is presented in Appendix~\ref{apdx:dataset}.

\fakeparagraph{Experiment results.}
We present the defense performance of \defensename in Table~\ref{tab:all_results_modified} and unveil the following three key insights:
1) \textbf{Best defense performance.}
Our method exhibits the best defense performance against different attacks among all competitors.
The average Attack Success Rate (ASR) drops to \textbf{1.73\%} for text perturbation attack and \textbf{13.78\%} for adversarial attack, respectively, which is lower by \textbf{13.15\%} and \textbf{5.54\%} compared with the second-best defense method.
2) \textbf{Most effort needed for adversarial attack.}
We observe that it takes adversarial attack more resources to conduct a successful attack to \defensename.
\textbf{843.29} queries are required in average, which is \textbf{31.36} more than other defense methods.
Moreover, the average ASR against \defensename is only \textbf{13.78\%} for adversarial attacks. 
It illustrates that \defensename makes adversarial attacks both inefficient and ineffective.
3) \textbf{Generalized Defense to Different Attacks.}
We notice that \defensename significantly reduces the ASR of different kinds of attacks even though it is trained with \attackname.
As an exemplary method, EP performs better than \defensename when defending Mixed Edit Attack but cannot withstand other attacks.
The defense against a wide variety of attacks demonstrates the generalized defense effect of \defensename.
\vspace{-0.1cm}

\subsection{Attack Performance for \attackname}
\label{sec:GeneratorResult}
In this section, we evaluate the effectiveness of \attackname in the black-box setting using the metrics detailed in Appendix~\ref{apdx:metric}.
We categorize the comparison methods into two classes:
i) \textit{Query-based methods}, which query the target model for output to adjust attack strategy, including PWWS~\cite{ren2019generating}, TextFooler~\cite{jin2020bert}, BERTAttack~\cite{li2020bert},
HQA~\cite{liu2024hqa}, ABP~\cite{yu2024query}, T-PGD~\cite{yuan2023bridge}, and FastTextDodger~\cite{hu2024fasttextdodger}.
ii) \textit{Zero-query methods}, which conducts attack without any information from the target model, including WordNet~\cite{zhou2024humanizing}, Back Translation~\cite{zhou2024humanizing}, Rewrite~\cite{zhou2024humanizing}, 
T-PGD~\cite{yuan2023bridge}, and HMGC~\cite{zhou2024humanizing}.
To further demonstrate the effectiveness of \attackname, we also incorporate A2T~\cite{yoo2021towards},  a SOTA white-box method in query-based methods.
Detailed introduction of these attack methods are listed in Appendix~\ref{sec:attack}.
Note that \attackname is a query-based method.
However, for a fair comparison, we also implement our method in a zero-query setting where we query the surrogate model for feedback. 
Among all the attacks, we employ a fine-tuned XLM-RoBERTa-Base model \cite{conneau2019unsupervised}
as the target detector.

\fakeparagraph{Experiment Results.}
We show the experiment results in Table \ref{tab:merged_attack_results}.
We find \attackname performs the best in three dimensions: effectiveness, efficiency, and stealthy.
\attackname achieves 96.58\% and 69.11\% in terms of ASR in query and zero-query settings, respectively, which significantly outperforms all other methods.
Moreover, in the query-based setting, it only takes 62.63 queries for \attackname to conduct a successful attack, which is four times fewer than its competitors.
As for the stealthy, the texts edited by \attackname achieves the lowest perplexity and has the best readability implied by the highest USE and lowest readability change in query-based scenario.
In the zero-query setting, \attackname performs second-best in terms of readability after Back Translation which can rarely conduct a successful attack.
\begin{table}[ht]
\centering
\renewcommand{\arraystretch}{1.8}
\resizebox{0.45\textwidth}{!}{%
\begin{tabular}{c c c c c c c c}
\toprule
\textbf{{Attack Type}} & \textbf{Method} & \textbf{Avg Queries $\downarrow$} & \textbf{ASR (\%) $\uparrow$} & \textbf{Pert. (\%) $\downarrow$} & \(\Delta\mathrm{PPL}\) $\downarrow$ & \textbf{USE $\uparrow$} & \(\Delta r\) $\downarrow$ \\
\midrule
\multirow{9}{*}{\textbf{Query-based}} 
    & PWWS                & 1197.95               & 61.45                      & \cellcolor{green!50}4.71 & 37.85   & 0.9488 & 12.76  \\
    & TextFooler          & 690.92                & 72.29                      & 6.26                          & 46.89   & 0.9302 & 21.07  \\
    & BERTAttack          & 411.54                & 71.49                      & 5.79                         & 36.15   & 0.9402 & 15.78  \\
    & HQA                 & 283.89                & 88.13                      & 23.57                         & 102.87  & 0.8854 & 72.16  \\
    & FastTextDodger      & 745.75                & 63.78                      & 13.29                         & 76.15   & 0.9188 & 55.14  \\
    & ABP                 & 785.18                & 75.65                      & 14.63                         & 39.61   & 0.8709 & 26.40  \\
    & T-PGD               & 354.75                & 49.90                      & 38.01                         & 181.31  & 0.8197 & 35.09  \\
    & \attackname          & \cellcolor{green!50}62.63 & \cellcolor{green!50}96.58 & 7.26              & \cellcolor{green!50}35.22  & \cellcolor{green!50}0.9506 & \cellcolor{green!50}9.21 \\
    & A2T (White Box)     & 293.26                & 45.47                      & 7.01                          & 62.84   & 0.9215 & 32.07  \\
\midrule
\multirow{6}{*}{\textbf{Zero-query}}
    & WordNet             & -                     & 42.60                      & -                               & 26.27   & 0.90   & 4.26   \\
    & Back Translation    & -                     & 2.40                       & -                               & \cellcolor{green!50}6.40   & 0.91   & \cellcolor{green!50}3.06   \\
    & Rewrite             & -                     & 36.47                      & -                               & 92.08   & 0.79   & 15.62  \\
    & T-PGD               & -                     & 62.40                      & -                               & 140.13  & 0.82   & 44.99  \\
    & HMGC                & -                     & 30.00                      & -                               & 12.94   & 0.84   & 36.90  \\
    & \attackname          & -                     & \cellcolor{green!50}69.11                      & -                               & 43.11   & \cellcolor{green!50}0.92  & 4.55   \\
\bottomrule
\end{tabular}%
}
\caption{\textbf{Attack results of the query and zero-query attack methods on the target model.} 
Note that perturbation rates are not reported for zero-query methods because the zero-query methods rewrite the whole text.
The best result in each group is highlighted with a \colorbox{green!50}{green} background.}
\label{tab:merged_attack_results}
\end{table}
\vspace{-0.2cm}
