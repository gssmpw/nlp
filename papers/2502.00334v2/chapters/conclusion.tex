\section{Conclusion}\label{sec: conclusion}

In this study, we propose {\benchmark}, a comprehensive undergraduate-level physics benchmark, and the {\judge} answer scoring framework to evaluate LLMs' capabilities in solving physics problems.
Through our extensive experiments, we find that although current LLMs excel in mathematical reasoning, there remains considerable potential for improvement in their performance on physics problems.
We believe our dataset and codes will be valuable for the future development of AI with strong physics reasoning abilities.