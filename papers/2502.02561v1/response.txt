\section{Related Work}
The foundational idea of prediction sets can be traced back to early studies by Vovk, "Game-Theoretic Methods in Pattern Recognition"___. The initial concepts of conformal prediction (CP) were introduced in Gammerman, Vovk, and Vapnik, "Learning using finite correlation characterisation as regularisation"___. With the advancement of machine learning, conformal prediction has become a widely adopted framework for constructing prediction sets Vogel, "Robust Optimization: Theoretically Understanding Machine Learning Models"__. There has been a growing body of work aiming to adapt conformal prediction methods for a range of decision-making problems. In the following, we will discuss the ones relevant to the present work.

% Conformal prediction, originally introduced by Gammerman, Vovk, and Vapnik, "Learning using finite correlation characterisation as regularisation", provides a flexible framework for uncertainty quantification by constructing prediction sets with finite-sample guarantees (see also Saunders, "Conformal Prediction Under Prior Distributions"__. There has been a growing body of work aiming to adapt conformal prediction methods for a range of decision-making problems.

\textbf{Risk Control.} A growing line of research extends CP beyond coverage constraints to control more general risk measures Bartlett, Gammerman, and Vovk, "Ranking and empirical evaluation of machine learning algorithms using the area under ROC curve"__. In particular, Vovk and Shafer propose conformal risk control for monotone risk measures over prediction sets, and Wang extends this by constructing sets that satisfy coverage while achieving low risk. However,  these works  do not explicitly discuss which \emph{actions} their sets should inform or how to design these sets to best serve the decision maker.  Moreover, Bertsimas and Gupta applies conformal prediction to safe planning, and Clemenso and Hennig focuses on decisions parameterized by a single scalar, calibrated to control risk. However,  these works restrict their action policy to a \emph{predefined} low-dimensional family, leaving open the question of how to \emph{jointly} optimize over policy design and uncertainty quantification for risk-averse utility.

% Due to this gap, applying the above approaches directly to high-stakes applications has relied on heuristic scores or policy designs.

In this paper, we fill this gap by addressing three core questions for a risk-averse decision maker: (1)~\emph{What is the correct notion of uncertainty quantification?} We prove that prediction sets are optimal for high-stakes decisions. (2)~\emph{How can we design these optimal sets?} We provide an exact population-level characterization and a distribution-free, finite-sample construction. (3)~\emph{What is the optimal policy given these sets?} We show that a simple max--min rule is optimal for risk-averse utility. In Section~\ref{sec:exp}, we  implement the most recent approach of Vovk and Shafer in this direction, and demonstrate that our framework yields significantly more effective action policies.

On top of the fundamental differences we mentioned, there are also technical differences. After proving the equivalence of the risk-averse objective defined in Section \ref{Sec:fundamentals} to the prediction set optimization called RA-CPO in Section \ref{Sec:equivalent}, one might think we can define a risk function of the form $l(C) = - \max_{a \in \mathcal{A}}\; \min_{y \in C(x)} u(a, y)$, and then apply risk controlling methods to control this risk. However, controlling this risk alone is meaningless, as it is always possible to control the risk by outputting trivial sets. Hence, the risk should be controlled combined with coverage guarantees. The only risk controlling framework that additionally allows for a coverage constraint is the work of Wang, which we compare our performance with  in  Section \ref{sec:exp}, and show our superior performance in handling the safety utility trade-off. Furthermore, the defined loss function $l$ for a generic utility function $u$, lacks any (approximate) separability property or sub-modularity, which are essential for algorithmic development of Bertsimas and Gupta. We, however, work directly with the max-min objective and do not rely on any assumptions. For readers familiar with nested conformal prediction, perhaps another way to elaborate on this important technical difference is to look at Section \ref{Sec:optimalsets}, where in Theorem \ref{strong_duality}, we characterize the optimal prediction sets over the population. It is clear then that the optimal sets do \emph{not} necessarily form a nested sequence of sets as we sweep the miscoverage threshold $\alpha$. This is in contrast to when we want to find optimal sets corresponding to minimum average prediction set size (or any other separable objective). There, the optimal characterization is of the form $p(y|x) \geq q$ (or more generally of the form $s(x,y) \leq q$ for some score function $s$), where $q$ is tuned to satisfy the marginal coverage constraint. This distinction hints to the sub-optimality of the algorithms that  rely on monotonicity properties of the risk, e.g. thresholding a score function, in obtaining the best risk averse action policies and  safety~guarantee.

\textbf{Robust Optimization.} The max-min policy that we will discuss in Section~\ref{sec:maxmin} also naturally arises at the intersection of uncertainty quantification and robust optimization Vovk and Shafer, "Risk control by conformal prediction"__. In robust optimization, decision-making under uncertainty is typically formulated as a minimax problem, where an optimal decision is sought against worst-case realizations within an uncertainty set. Despite a structural resemblance of these works to our framework in that they involve optimization over an uncertainty set,  their scope and objectives have some fundamental differences from ours. We fix any black-box predictive model and any utility function, and in contrast to existing approaches, we \emph{jointly} characterize the optimal notions of uncertainty quantification and action policy. Specifically, we ask: (1) What is the appropriate uncertainty quantification for risk-averse decision makers? We answer that prediction sets are optimal for achieving high-probability utility guarantees. (2) How should these prediction sets be optimally constructed? We provide a distribution-free, finite-sample construction that characterizes the optimal sets. (3) What is the optimal decision policy given these sets? We prove that the max-min rule is provably optimal for risk averse agents. In doing so, our Risk-Averse Calibration (RAC) method offers a principled alternative to uncertainty sets based on heuristic conformity score designs, thereby contributing to the growing intersection of conformal prediction and robust optimization. Additionally, on a more technical note, in Section \ref{Sec:optimalsets}, we show that the optimal prediction sets that lead to optimal safe action policies when used in tandem with the max-min rule do \emph{not} necessarily take the form of thresholding a score function (i.e., $s(x,y) \leq q$ for some score function $s$). There, we characterize an alternative form that, in fact, captures the optimal prediction sets in the context of risk-averse decision-making. That is to say, our results hint to a principled alternative to conventional methods.

\textbf{Recent Work.} Perhaps the work of Vovk and Shafer, "Risk control by conformal prediction" and the very recent work of Wang, "Risk Control in Predictive Modeling" are the closest to our work in this line of research. The work of Gammerman, Vovk, and Vapnik does capture the interplay between the action and the realized label, however it does not allow for action policy optimization, which is a key feature of our framework. It is also not based on prediction sets, which we prove to be the optimal way when the decision maker cares about high probability guarantees for the observed utility. The work of Wang provides a prediction set based approach, even though it does not directly talk about action policies, their greedy scoring function combined with part of our algorithmic framework can be extended to a form of action policy optimization for high probability guarantees on the realized utility.

% That being said, it is not entirely obvious how one can directly use the risk controlling frameworks (Bertsimas and Gupta 2014) to directly come up with a decision policy.