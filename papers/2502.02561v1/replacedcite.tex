\section{Related Work}
The foundational idea of prediction sets can be traced back to early studies by ____. The initial concepts of conformal prediction (CP) were introduced in ____. With the advancement of machine learning, conformal prediction has become a widely adopted framework for constructing prediction sets ____. There has been a growing body of work aiming to adapt conformal prediction methods for a range of decision-making problems. In the following, we will discuss the ones relevant to the present work. 

% Conformal prediction, originally introduced by ____, provides a flexible framework for uncertainty quantification by constructing prediction sets with finite-sample guarantees (see also ____). There has been a growing body of work aiming to adapt conformal prediction methods for a range of decision-making problems. In the following, we will discuss the one relevant to the present work. 
 

\textbf{Risk Control.} A growing line of research extends CP beyond coverage constraints to control more general risk measures ____. In particular, ____ propose conformal risk control for monotone risk measures over prediction sets, and ____ extend this by constructing sets that satisfy coverage while achieving low risk. However,  these works  do not explicitly discuss which \emph{actions} their sets should inform or how to design these sets to best serve the decision maker.  Moreover, ____ applies conformal prediction to safe planning, and  ____ focuses on decisions parameterized by a single scalar, calibrated to control risk. However,  these works restrict their action policy to a \emph{predefined} low-dimensional family, leaving open the question of how to \emph{jointly} optimize over policy design and uncertainty quantification for risk-averse utility. 
% Due to this gap, applying the above approaches directly to high-stakes applications has relied on heuristic scores or policy designs.

In this paper, we fill this gap by addressing three core questions for a risk-averse decision maker: (1)~\emph{What is the correct notion of uncertainty quantification?} We prove that prediction sets are optimal for high-stakes decisions. (2)~\emph{How can we design these optimal sets?} We provide an exact population-level characterization and a distribution-free, finite-sample construction. (3)~\emph{What is the optimal policy given these sets?} We show that a simple max--min rule is optimal for risk-averse utility. In Section~\ref{sec:exp}, we  implement the most recent
approach in this direction ____, and demonstrate that our framework yields significantly more effective action policies.

On top of the fundamental differences we mentioned, there are also technical differences. After proving the equivalence of the risk-averse objective defined in Section \ref{Sec:fundamentals} to the prediction set optimization called RA-CPO in Section \ref{Sec:equivalent}, one might think we can define a risk function of the form $l(C) = - \max_{a \in \mathcal{A}}\; \min_{y \in C(x)} u(a, y)$, and then apply risk controlling methods to control this risk. However, controlling this risk alone is meaningless, as it is always possible to control the risk by outputting trivial sets. Hence, the risk should be controlled combined with coverage guarantees. The only risk controlling framework that additionally allows for a coverage constraint is the work of ____, which we compare our performance with  in  Section \ref{sec:exp}, and show our superior performance in handling the safety utility trade-off. Furthermore, the defined loss function $l$ for a generic utility function $u$, lacks any (approximate) separability property or sub-modularity, which are essential for algorithmic development of ____. We, however, work directly with the max-min objective and do not rely on any assumptions. For readers familiar with nested conformal prediction ____, perhaps another way to elaborate on this important technical difference is to look at Section \ref{Sec:optimalsets}, where in Theorem \ref{strong_duality}, we characterize the optimal prediction sets over the population. It is clear then that the optimal sets do \emph{not} necessarily form a nested sequence of sets as we sweep the miscoverage threshold $\alpha$. This is in contrast to when we want to find optimal sets corresponding to minimum average prediction set size (or any other separable objective). There, the optimal characterization is of the form $p(y|x) \geq q$ (or more generally of the form $s(x,y) \leq q$ for some score function $s$), where $q$ is tuned to satisfy the marginal coverage constraint ____. This distinction hints to the sub-optimality of the algorithms that  rely on monotonicity properties of the risk, e.g. thresholding a score function, in obtaining the best risk averse action policies and  safety~guarantee.

\textbf{Robust Optimization.} The max-min policy that we will discuss in Section~\ref{sec:maxmin} also naturally arises at the intersection of uncertainty quantification and robust optimization ____. 
In robust optimization, decision-making under uncertainty is typically formulated as a minimax problem, where an optimal decision is sought against worst-case realizations within an uncertainty set. Despite a structural resemblance of these works to our framework in that they involve optimization over an uncertainty set,  their scope and objectives have some fundamental differences from ours. We fix any black-box predictive model and any utility function, and in contrast to existing approaches, we \emph{jointly} characterize the optimal notions of uncertainty quantification and action policy. Specifically, we ask: (1) What is the appropriate uncertainty quantification for risk-averse decision makers? We answer that prediction sets are optimal for achieving high-probability utility guarantees. (2) How should these prediction sets be optimally constructed? We provide a distribution-free, finite-sample construction that characterizes the optimal sets. (3) What is the optimal decision policy given these sets? We prove that the max-min rule is provably optimal for risk averse agents. In doing so, our Risk-Averse Calibration (RAC) method offers a principled alternative to uncertainty sets based on heuristic conformity score designs, thereby contributing to the growing intersection of conformal prediction and robust optimization. Additionally, on a more technical note, in Section \ref{Sec:optimalsets}, we show that the optimal prediction sets that lead to optimal safe action policies when used in tandem with the max-min rule do \emph{not} necessarily take the form of thresholding a score function (i.e., $s(x,y) \leq q$ for some score function $s$). There, we characterize an alternative form that, in fact, captures the optimal prediction sets in the context of risk-averse decision-making. That is to say, our results hint to a principled alternative to conventional score-based prediction sets in the pipeline of robust optimization to avoid suboptimality.

\textbf{Further Related Work.} The potential connection of CP ideas to decision making has also been explored in ____, from the point of view of conformal predictive distributions. Conformal predictive distributions produce calibrated distributions rather than prediction sets--see e.g. ____. Therefore, they are best to be compared with calibrated forecasts as the methodologies developed in ____ are also targeting expectation maximizer--i.e. risk neutral-- agents. We, however, focus on risk averse decision making using prediction sets. In particular, we show that prediction sets are a sufficient statistic for risk averse agents that aim to optimize their value at risk. 

Although our primary aim is to develop a general framework to construct prediction sets for  high-stakes decision-making, we note that conformal prediction sets have  been explored in a wide range of specific applications and domains of high-stakes nature. For instance, CP methods have been adapted and used in medical tasks ____, power and energy systems ____, formal verification and control ____,  chance-constrained optimization ____, and more generally ____. Our framework could potentially be extended to these domains, yet each may present additional, domain-specific challenges that lie beyond the scope of this work.





% Despite our focus on developing a general framework for high stake decision making, the literature for informed decision making with conformal prediction sets is more broad if we look into the methods developed for specific high stake applications. To name a few, conformal prediction sets have been used for robust optimization ____, medical tasks ____, power energy systems ____, verification and control ____, and chance constraint optimization ____. Our framework can potentially be extended to be applied to these applications, although each of these application might also have some domain-specific challenges to overcome, which is beyond the scope of this work.

% All of these works can be seen as a way to inform the downstream decision maker of the uncertainty lies in the predictions.  However, these works either overlook the direct modeling of the action space or the corresponding full action policies for the decision-maker or simplify the decision-making process by assuming a pre-specified class of policies governed by a scalar parameter, which is subsequently calibrated. In contrast, we study the complete decision-making pipeline, encompassing features, labels, actions, and a generic utility function, providing a comprehensive approach to decision-making under uncertainty. Our work fundamentally differs in several ways. Specifically, we directly address the question of what the optimal action policy should be for a risk-averse decision-maker. That is to say:

% 1) We show that prediction sets are the correct notion of uncertainty quantification (UQ) for high-stakes applications. We formally prove that the optimal action policy can be derived through a maxmin algorithm over an optimal prediction set.

% 2) We precisely characterize the optimal prediction sets in the population regime and provide a distribution-free method for estimating these sets in finite samples.

% That being said, in the experiments section, we also implement a recent method from this line of research and compare our results with theirs to highlight the advantages of our approach.

% Perhaps the work of ____ and the very recent work of ____ are the closest to our work in this line of research. The work of ____ does capture the interplay between the action and the realized label, however it does not allow for action policy optimization, which is a key feature of our framework. It is also not based on prediction sets, which we prove to be the optimal way when the decision maker cares about high probability guarantees for the observed utility. The work of ____ provides a prediction set based approach, even though it does not directly talk about action policies, their greedy scoring function combined with part of our algorithmic framework can be extended to a form of action policy optimization for high probability guarantees on the realized utility. In particular, In section \ref{exp}, we will extend their method, applying the max-min policy over their prediction sets, which is an optimal policy by the findings of our paper, and we showcase how our fundamental approach to decision making can improve over their method.


% That being said, it is not entirely obvious how one can directly use the risk controlling frameworks (____ for example) to directly come up with a decision policy.


%