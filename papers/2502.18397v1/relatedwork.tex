\section{Related Work}
\textbf{RAG Models.} 
RAG models have shown superior performance in QA tasks~\cite{lewis2020retrieval,izacard2020leveraging,ram2023context}. 
These models typically employ the \textit{retriever-reader} architecture, which consists of a retriever~\cite{karpukhin2020dense,wang2022text,fang2023kgpr} % for retrieving relevant documents 
and a reader~\cite{izacard2020leveraging,jiang2023active}. 
Efforts to improves RAG models generally follows three main directions: 
(1) enhance the retriever for better retrieval performance~\cite{izacard2021distilling,shi2023replug,wang2024richrag}; 
(2) enhance the reader for better comprehension and answer generation~\cite{lin2024ra,xu2024unsupervised,wang2024rear}; 
(3) introduce additional modules to bridge the retriever and the reader~\cite{yu2023generate,xu2023recomp,ye2024r}. 

\vspace{0.5em} \noindent \textbf{Iterative RAG Models for Multi-Hop QA.}
Iterative RAG models~\cite{trivedi2023interleaving,shao2023enhancing,asai2024self,liu2024ra,yao2024seakr} address multi-hop QA by performing multiple steps of retrieval and reasoning. 
For instance, IRCoT~\cite{trivedi2023interleaving} use LLM-generated chain-of-thoughts for retrieval, while  DRAGIN~\cite{su2024dragin} dynamically decides when and what to retrieve based on the LLM's information needs. 
However, these models all rely on LLM-generated thoughts, making them prone to hallucination. In contrast, \OURS{} employs knowledge triples and a trained retriever to actively identify and retrieve missing information, enabling a more reliable and accurate retrieval for multi-hop QA. 

\vspace{0.5em} \noindent \textbf{KG-Enhanced RAG Models.} 
Recently, KGs have been integrated into RAG models~\cite{peng2024graph}. Some studies leverage information from existing KGs~\cite{vrandevcic2014wikidata} for additional context~\cite{yu2022kg,sun2024think}, while others generate KGs from documents to improve knowledge organisation~\cite{edge2024local,gutierrez2024hipporag,chen2024kg} or enhance reader comprehension~\cite{li2023leveraging,fang2024reano,fang2024trace,panda2024holmes}. 
These models primarily follow the standard RAG pipeline, whereas our work focuses on the iRAG pipelines. Moreover, while they rely on single-step retrieval with pre-existing retrievers, \OURS{} employs a trained retriever tailored for iterative retrieval, allowing it to dynamically adapt to the evolving information needs in multi-step reasoning.