\section{Related Work}
Research has been conducted to understand and measure the unwanted effects of biases in LMs, such as those related to gender, religion, race, and politics \citep{zhao-etal-2017-men, naous-etal-2024-beer, blodgett-etal-2020-language, motoki2023more, hartmann2023politicalideologyconversationalai}.  To the best of our knowledge, no prior work has analyzed how LMs align with specific demographics in perceiving social and moral norms. For subjective labeling tasks, annotators need to use their own judgement which has been shown to be influenced by human demographics \citep{sap-etal-2022-annotators, luo-etal-2020-detecting, goyal2022toxicity}. Other studies have shown that knowing annotator demographic information can help predict annotation disagreement \citep{wan2023demographic}. %Recently, \citet{naous-etal-2024-beer} showed how multilingual and Arabic LMs exhibit bias towards entities associated with Western culture.