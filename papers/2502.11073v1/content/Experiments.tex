\subsection{Hateful Meme Classification} 
% Table \ref{tab:experimental-results} displays the evaluation results of the state-of-the-art PT-VLMs on the three benchmark datasets. We have reported the average score and standard deviation across five random seeds, highlighting the best performance highlighted in bold. Both the xIntMeme$_\text{InstructBLIP}$ and IntMeme$_\text{mPLUG-Owl}$ variants outperform the state-of-the-art PT-VLMs baselines across all three datasets (i.e., by $\geq$ 2.54, $\geq$ 0.9, and $\geq$ 1.01 percentage points of absolute AUC performance, respectively). The superior performance and low standard deviation indicate the effectiveness of our proposed framework in the hateful meme detection task. Furthermore, itâ€™s worth noting that IntMeme$_\text{InstructBLIP}$ and IntMeme$_\text{mPLUG-Owl}$ consistently achieve comparable results, with IntMeme$_\text{InstructBLIP}$ and IntMeme$_\text{mPLUG-Owl}$ obtaining the best accuracy performance and the best AUC performance across all three datasets. This suggests that both the mPLUG-Owl and InstructBLIP LMM excel in generating highly informative meme interpretations that aid in the hatefu meme detection task. Nevertheless, the informativeness and effectiveness of the meme interpretations warrant further analysis, which will be discussed in the analysis section.

Table \ref{tab:experimental-results} displays the evaluation results of state-of-the-art baselines on three benchmark datasets. We report the average score and standard deviation across five random seeds and highlight the best performance in bold. Both the IntMeme$_\text{InstructBLIP}$ and IntMeme$_\text{mPLUG-Owl}$ variants outperform the state-of-the-art baselines across all three datasets, improving by 2.54, 0.9, and 1.01 percentage points in absolute AUC performance, respectively. The superior performance and low standard deviation underscore the effectiveness of our proposed framework in the hateful meme detection task. Notably, both model variants consistently achieve better performance, with IntMeme$_\text{InstructBLIP}$ securing the highest accuracy and IntMeme$_\text{mPLUG-Owl}$ the best AUC performance across the datasets. These results suggest that both the mPLUG-Owl and InstructBLIP LMMs excel in generating highly informative meme interpretations that enhance hateful meme detection. Nevertheless, the informativeness and effectiveness of these interpretations warrant further analysis, which we will discuss in the empirical analysis section.



\subsection{Ablation Study}

% To investigate the effectiveness of providing an generated meme interpretation and using distinct modules for information encoding, we conducted two separate ablation studies on the FHM-FG dataset. The first ablation study examines the hateful meme classification performance based on the generated meme interpretation solely, and the performance gained from including the generated interpretations. The second ablation study remove one module from \textsf{IntMeme} at a time and examine the performance difference. To provide a better comparison, we also present the performance of a FLAVA model fine-tuned with the generated meme interpretations. Table \ref{tab:ablation-modules} shows the the ablation results on \textsf{IntMeme} and FLAVA model.

We conducted two ablation studies to examine the effectiveness of generated meme interpretations and distinct encoding modules. In the first study, we evaluated the effectiveness of the generated interpretations by comparing the performance of three setups: using only the generated interpretations (the ``MIE module''), using only the meme (the ``VLA module''), and using both the interpretations and the meme together (the "MIE + VLA modules"). The second study focused on the importance of separate encoding modules, comparing a fine-tuned FLAVA model, which uses concatenated meme and interpretation data for hateful meme classification, against the \textsf{IntMeme} model. Table \ref{tab:ablation-modules} presents the results of these ablation studies for both the \textsf{IntMeme} and FLAVA models.

\paragraph{Meme Interpretation.} 
% Firstly, we notice that despite the significant performance degradation, the \textsf{IntMeme} model variant fine-tuned with the meme interpretation alone achieve comparable performance with the state-of-the-art PT-VLMs baselines. This underscores the informative nature of the generated meme interpretations, suggesting their potential to serve as competitive substitutes for visual cues and modality interactions within memes. Subsequently, our investigation reveals that both IntMeme$_\text{InstructBLIP}$ and IntMeme$_\text{mPLUG-Owl}$ significantly outperforms outperform their respective model counterparts lacking the meme interpretation (i.e., 2.54 and 2.99 percentage points of absolute AUROC performance, respectively). Furthermore, the FLAVA model, fine-tuned with meme interpretations from InstructBLIP or mPLUG-Owl, outperforms the model variant solely fine-tuned on memes (i.e. 0.47 and 0.94 percentage points of absolute AUROC performance, respectively). The latter observations highlight the effectiveness of using frozen pre-trained LMMs to generate and using these explicit meme interpretation to fine-tune PT-VLMs.
% The ablation results demonstrate that the IntMeme$_\text{InstructBLIP}$ and IntMeme$_\text{mPLUG-Owl}$ significantly outperform their respective counterparts that lack meme interpretation, with improvements of 2.54 and 2.99 percentage points in absolute AUROC performance, respectively. Additionally, the FLAVA model, when fine-tuned with meme interpretations from InstructBLIP or mPLUG-Owl, outperforms its variant that was solely fine-tuned on memes by 0.47 and 0.94 percentage points in absolute AUROC performance, respectively. These findings underscore the effectiveness of leveraging frozen pre-trained LMMs to generate meme interpretations for detecting hateful memes. Another observation is that the \textsf{IntMeme} model variant, when fine-tuned with the meme interpretation solely, achieves performance comparable to that of the state-of-the-art baselines. This observation underscores the informative value of the generated meme interpretations.

Firstly, we observe that, despite a notable decrease in performance, the \textsf{IntMeme} model variant fine-tuned solely with meme interpretations achieves performance levels comparable to the state-of-the-art PT-VLMs baselines. This highlights the informative nature of the generated meme interpretations, suggesting their potential as competitive substitutes for visual cues and modality interactions in memes. Our investigation further reveals that both model variants, which combine meme interpretations with meme data, significantly outperform their counterparts trained solely on memes (with improvements of 2.54 and 2.99 percentage points in absolute AUROC performance, respectively). Additionally, the FLAVA model fine-tuned with meme interpretations from InstructBLIP or mPLUG-Owl outperforms the variant fine-tuned solely on memes, with gains of 0.47 and 0.94 percentage points in absolute AUROC performance, respectively. These findings underscore the informative value of the generated meme interpretations.

\begin{table*}[t]
  \small
  \centering
    \resizebox{1\linewidth}{!}{$
  \begin{tabular}{c|p{8.1cm}|p{8.1cm}}
  \hline
  
    \multirow{2}{*}{\textbf{Memes}}
    
    & \begin{minipage}[!b]{0.80\columnwidth}
      \centering
      \raisebox{-.7\height}{\includegraphics[width=\linewidth]{images/case-studies/18306_pixelated.png}}
         \newline (a)
     \end{minipage}  
     &
    \begin{minipage}[!b]{0.80\columnwidth}
  \centering
  \raisebox{-.5\height}{\includegraphics[width=\linewidth]{images/case-studies/43175.png}}
         \newline (b)
 \end{minipage}\\
    \hline 
    % \textbf{Ground Truth}  & Hateful (Race) & Hateful (Sex) \\\hline
    % %\textbf{Prediction} & \color{red} Non-hateful & \color{red} Non-hateful & \color{red} Non-hateful & \color{red} Hateful\\\hline
    % \textbf{FLAVA} & \textcolor{red}{Non-Hateful} & \textcolor{red}{Non-Hateful} \\\hline
    % \textbf{IntMeme$_\text{mPLUG-Owl}$} &Hateful & Hateful \\\hline
    % \textbf{\makecell{Interpretation \\ (mPLUG-Owl)}} & The underlying message of the meme is that the young girl is holding a gun and posing for a picture, possibly during their first day of school. [...] Additionally, the overlaid text ``white kids dreaming" implies that white children are more likely to engage in such activities or have a different perception of guns compared to children from other racial or ethnic backgrounds. The potential bias conveyed in the image is the stereotypical association of white people with guns and violence, reinforcing the idea that they are perceived as more aggressive or prone to dangerous behavior. & The underlying message of the meme is that the woman with large breasts is using her physical attributes to manipulate or control men. [...] she can use her sexual appeal to get men to do whatever she wants them to, which could be interpreted as a form of objectification or exploitation. This mnemonic may be perceived as sexist or promoting gender stereotypes [...]

    \textbf{\makecell{Interpretation \\ (mPLUG-Owl)}} &
    The underlying message of the meme is that the young girl is holding a gun and posing for a picture, possibly during their first day of school. This could be interpreted as a playful or rebellious act, as guns are not typically associated with school settings. Additionally, the overlaid text ``white kids dreaming" implies that white children are more likely to engage in such activities or have a different perception of guns compared to children from other racial or ethnic backgrounds. The potential bias conveyed in the image is the stereotypical association of white people with guns and violence, reinforcing the idea that they are perceived as more aggressive or prone to dangerous behavior. &
    % The underlying message of the meme is that the woman with large breasts is using her physical attributes to manipulate or control men. The sign on the wall suggests that she can use her sexual appeal to get men to do whatever she wants them to, which could be interpreted as a form of objectification or exploitation. This mnemonic may be perceived as sexist or promoting gender stereotypes, as it implies that women with larger breast sizes have more power over men and can easily manipulate them. Additionally, the overlaid text on top of this memento further reinforces this message, suggesting that this woman is taking advantage of her appearance to achieve her goals.
    The underlying message of the meme seems to be that the presence of a large crowd of people holding rainbow flags on the street suggests that there is a high prevalence of mental illness in the community. The overlaid text, ``when was the last time you saw so many mentally ill people on a street," implies that this is an uncommon sight and that it may be a cause for concern. However, it is important to note that mental health issues can affect people from all walks of life, and the use of stereotypes and stigmatizing language can reinforce negative perceptions and discrimination against individuals with mental disorders.
    \\
    \hline
    \end{tabular}
    $}
  \caption{Case study analysis on two randomly chosen hateful memes and their interpretations.}
  \label{tab:case-study-analysis}
\end{table*}



\begin{table}[t]
  % \small
  \centering
  \begin{tabular}{lrrrrr}
    \toprule
    & \textbf{Cl.}&\textbf{Acc.} &\textbf{Rel.}&\textbf{Help.} & \textbf{Rec.} \\
    \midrule
    \#. Avg Score $\leq$ 3 & 38 & 66 & 63 & 71 & 67 \\
    \#. Avg Score $\geq$ 4 & 112 & 84 & 87 & 79 & 83 \\
    \midrule
    Mean & 3.78 & 3.21 & 3.38 & 3.15 & 3.23 \\
    Median & 4.00 & 3.33 & 3.67 & 3.33 & 3.33 \\
    Mode & 4.67 & 4.00 & 5.00 & 5.00 & 4.67 \\
    \bottomrule
\end{tabular}
\caption{Statistic breakdown of the human evaluation results for 150 memes, evenly sampled from FHM, HarMeme, and MAMI datasets: Clarity (Cl.), Accuracy (Acc.), Cultural Relevance (Rel.), Helpfulness (Help.) and Recognition of Hateful Elements (Rec.).}
\label{tab:human-evaluation}
\end{table}

\paragraph{Encoder Modules.} 
The superior performance of both \textsf{IntMeme} variants (IntMeme$\text{InstructBLIP}$ and IntMeme$\text{mPLUG-Owl}$) compared to the FLAVA model fine-tuned for meme interpretation, with absolute score improvements of 2.05 and 2.07, highlights the benefits of using separate encoder modules for processing the meme and its interpretation. Importantly, removing either the Visual Language Adapter (VLA) or the Meme Interpretation Encoder (MIE) from IntMeme's architecture leads to a noticeable drop in performance, particularly when the VLA module is omitted. The VLA module likely addresses the inaccuracies or gaps in meme interpretation and enhances the model's ability to integrate information across modalities. This finding emphasizes the importance of incorporating a VLA module for effectively encoding meme interactions, further supporting its role in the task of hateful meme classification.