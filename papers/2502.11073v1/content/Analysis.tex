

% In addition to conducting quantitative evaluations for the hateful meme detection task, we also perform a case study analysis to gain a deeper understanding of the utility and limitations of meme interpretation in explaining IntMeme’s predictions. To ensure brevity and efficient use of space, our empirical analysis focuses on the top-performing baseline model (FLAVA) and the most effective proposed model (IntMeme$_\text{mPLUG-Owl}$). We randomly select memes that were misclassified by FLAVA but correctly classified by IntMeme$_\text{mPLUG-Owl}$. This selection allows us to assess the corrective potential of meme interpretation. Lastly, we will discuss about the limitations and future directions for this line of work involving generative LMMs.

We conducted a human evaluation study and performed a case study analysis to understand the real-world utility of meme interpretation in explaining IntMeme's decisions. For the case study analysis, we randomly sampled two hateful memes misclassified by FLAVA but correctly classified by IntMeme. Subsequently, we used LIME \cite{lime}, a model-agnostic explainer, to understand and explain the influence of meme interpretations on the IntMeme$_\text{mPLUG-Owl}$'s decisions. Lastly, we will discuss the limitations and future directions for this line of work involving generative LMMs.




% \begin{table}[t]
%   \small
%   \centering
%   \begin{tabular}{lccccc}
%     \toprule
%     & \textbf{C.}&\textbf{Acc.} &\textbf{Cult. Rel.}&\textbf{Help.} & \textbf{Rec.} \\
%     \midrule
%     Eval \#1 & & \\   
%     $-$  $\leq$ 3 & 5 & 5 & 5 & 5 & 5 \\
%     $-$  $\geq$ 4 & 5 & 5 & 5 & 5 & 5 \\
%     $-$  AVG. & 5.13 & 5.23 & 5.34 & 5.45 & 5.55 \\
%     \midrule
%     Eval \#2 & & \\   
%     $-$  $\leq$ 3 & 5 & 5 & 5 & 5 & 5 \\
%     $-$  $\geq$ 4 & 5 & 5 & 5 & 5 & 5 \\
%     $-$  AVG. & 5.13 & 5.23 & 5.34 & 5.45 & 5.55 \\
%     \midrule
%     Eval \#3 & & \\   
%     $-$  $\leq$ 3 & 5 & 5 & 5 & 5 & 5 \\
%     $-$  $\geq$ 4 & 5 & 5 & 5 & 5 & 5 \\
%     $-$  AVG. & 5.13 & 5.23 & 5.34 & 5.45 & 5.55 \\
%     \midrule
%     \bottomrule
% \end{tabular}
% \caption{Ablation study w.r.t \textsf{IntMeme} and its distinct modules on FHM-FG dataset. The top scores across the metrics are presented in \textbf{bold}.}
% \label{tab:human-evaluation}
% \end{table}

% \begin{table}[t]
%   \small
%   \centering
%   \begin{tabular}{lrrrrr}
%     \toprule
%     & \textbf{Cl.}&\textbf{Acc.} &\textbf{Cult. Rel.}&\textbf{Help.} & \textbf{Rec.} \\
%     \midrule
%     \#. Avg Score $\leq$ 3 & 38 & 66 & 63 & 71 & 67 \\
%     \#. Avg Score $\geq$ 4 & 112 & 84 & 87 & 79 & 83 \\
%     \midrule
%     Mean & 3.78 & 3.21 & 3.38 & 3.15 & 3.23 \\
%     Median & 4.00 & 3.33 & 3.67 & 3.33 & 3.33 \\
%     Mode & 4.67 & 4.00 & 5.00 & 5.00 & 4.67 \\
%     \bottomrule
% \end{tabular}
% \caption{Statistic breakdown of the human evaluation results for 150 memes, evenly sampled from FHM, HarMeme, and MAMI datasets: Clarity (Cl.), Accuracy (Acc.), Cultural Relevance (Cult. Rel.), Helpfulness (Help.) and Recognition of Hateful Elements (Rec.).}
% \label{tab:human-evaluation}
% \end{table}


% \begin{table}[t]
%   \small
%   \centering
%   \begin{tabular}{lrrrrr}
%     \toprule
%     Avg. Score & \textbf{C.}&\textbf{Acc.} &\textbf{Cult. Rel.}&\textbf{Help.} & \textbf{Rec.} \\
%     \midrule
%     [0, 1] $\leq$ 3 & 38 & 66 & 63 & 71 & 67 \\
%     (1, 2] $\geq$ 4 & 112 & 84 & 87 & 79 & 83 \\
%     (2, 3] $\geq$ 4 & 112 & 84 & 87 & 79 & 83 \\
%     (3, 4] $\geq$ 4 & 112 & 84 & 87 & 79 & 83 \\
%     (4, 5] $\geq$ 4 & 112 & 84 & 87 & 79 & 83 \\
% \end{tabular}
% \caption{Statistic breakdown of the human evaluation results for 150 memes, evenly sampled from FHM, HarMeme, and MAMI datasets.}
% \label{tab:human-evaluation}
% \end{table}


% \begin{table}[t]
%   \small
%   \centering
%   \begin{tabular}{llrrrrr}
%     \toprule
%     & & \textbf{C.}&\textbf{Acc.} &\textbf{Cult. Rel.}&\textbf{Help.} & \textbf{Rec.} \\
%     \midrule
%     \parbox[t]{2mm}{\multirow{2}{*}{\rotatebox[origin=c]{90}{Cnt.}}} & $\leq$ 3 & 38 & 66 & 63 & 71 & 67 \\
%     & $\geq$ 4 & 112 & 84 & 87 & 79 & 83 \\
%     \midrule
%     \parbox[t]{2mm}{\multirow{2}{*}{\rotatebox[origin=c]{90}{Stats.}}} & Mean. & 3.78 & 3.21 & 3.38 & 3.15 & 3.23 \\
%     & Median. & 4.67 & 4.0 & 5.0 & 5.0 & 4.67 \\
%     \bottomrule
% \end{tabular}
% \caption{Ablation study w.r.t \textsf{IntMeme} and its distinct modules on FHM-FG dataset. The top scores across the metrics are presented in \textbf{bold}.}
% \label{tab:human-evaluation}
% \end{table}


% \begin{table}[t]
%   \small
%   \centering
%   \begin{tabular}{lcrrrrr}
%     \toprule
%     & &\textbf{C.}&\textbf{Acc.} &\textbf{Cult. Rel.}&\textbf{Help.} & \textbf{Rec.} \\
%     \midrule
%      \parbox[t]{2mm}{\multirow{3}{*}{\rotatebox[origin=c]{90}{Eval \#1}}} & $\leq$ 3 & 5 & 5 & 5 & 5 & 5 \\
%     & $\geq$ 4 & 5 & 5 & 5 & 5 & 5 \\
%     & AVG. & 5.13 & 5.23 & 5.34 & 5.45 & 5.55 \\
%     \midrule
%      \parbox[t]{2mm}{\multirow{3}{*}{\rotatebox[origin=c]{90}{Eval \#2}}} & $\leq$ 3 & 5 & 5 & 5 & 5 & 5 \\
%     & $\geq$ 4 & 5 & 5 & 5 & 5 & 5 \\
%     & AVG. & 5.13 & 5.23 & 5.34 & 5.45 & 5.55 \\
%     \midrule
%      \parbox[t]{2mm}{\multirow{3}{*}{\rotatebox[origin=c]{90}{Eval \#3}}} & $\leq$ 3 & 5 & 5 & 5 & 5 & 5 \\
%     & $\geq$ 4 & 5 & 5 & 5 & 5 & 5 \\
%     & AVG. & 5.13 & 5.23 & 5.34 & 5.45 & 5.55 \\
%     \midrule
%     \bottomrule
% \end{tabular}
% \caption{Ablation study w.r.t \textsf{IntMeme} and its distinct modules on FHM-FG dataset. The top scores across the metrics are presented in \textbf{bold}.}
% \label{tab:human-evaluation}
% \end{table}




\subsection{Human Evaluation Study} 

\paragraph{Study Design.} 
% The goal of this study is to investigates the quality and utility of the meme interpretations. For quality, we evaluate the meme interpretation’s clarity (how easily understood they are), accuracy (how closely they reflect the intended meaning) and cultural relevance (how well they capture cultural context) using a 5-point Likert scale, where 1 indicates low and 5 indicates high quality. Similarly, we evaluate utility by determining the interpretations' helpfulness in understanding the meme's message and their effectiveness in identifying hateful element, also using a 5-point Likert scale. This approach allows us to quantitatively measure the interpretative value of memes in a structured manner.

This study aims to evaluate the quality and utility of meme interpretations based on \textit{clarity}, \textit{accuracy}, \textit{cultural relevance}, and their \textit{helpfulness} in identifying hateful content, employing a 5-point Likert scale for assessment. Quality metrics focus on the ease of understanding, faithfulness to the meme's intended message, and alignment with cultural context, while utility is measured by the interpretations' helpfulness in revealing the meme's message and detecting hatefulness. The evaluation was conducted by three English-proficient university students, ensuring a rigorous examination of the generated interpretations' impact on understanding and classifying memes.

%The goal of this study is to investigate the quality and utility of meme interpretations. For quality, we assess the interpretations' clarity (ease of understanding), accuracy (faithfulness to the intended meaning of the meme), and cultural relevance (alignment with the cultural context). Similarly, we evaluate utility by measuring the helpfulness of these interpretations in understanding the meme's message and their efficiency in identifying any hateful content. We use a 5-point Likert scale for all these assessments, where a score of 1 signifies low quality and 5 signifies high quality. To conduct this evaluation, we engaged three university students who are proficient in English.

\paragraph{Study Execution.}

The human evaluators assessed 150 hateful memes sourced equally from the FHM, HarMeme, and MAMI datasets. To standardize their evaluations, the evaluators participated in two preliminary rounds of review, aimed at harmonizing their assessment criteria. To further ensure the study's reliability, we introduced 15 control questions featuring memes with deliberately mismatched interpretations. Evaluators are expected to recognize these incongruities and assign low-quality scores, thereby validating the consistency and reliability of their assessments.

%We recruited three university students proficient in English to assess 150 hateful memes, evenly drawn from the FHM, HarMeme, and MAMI datasets. The evaluators underwent two preliminary rounds of evaluation to align their understanding. Additionally, we incorporated 15 control questions consisting of memes helps to validate the reliability of the study. These control questions consisted of memes paired with mismatched interpretations, which the evaluators should identify and assign a low-quality score.

\paragraph{Results Analysis.}

Table \ref{tab:human-evaluation} details the results of our human evaluation study, summarized by average scores assigned to each meme interpretation on a 5-point scale. The interpretations of most hateful memes scored above 3, demonstrating their effectiveness and utility. Furthermore, the analysis of central tendency measures indicates a left-skewed distribution across all evaluated metrics. This skewness implies that a majority of the interpretations were rated highly, receiving scores on the upper end of the scale, with fewer instances of low scores. Such a distribution underscores the interpretations' success in accurately conveying the memes' intended messages, affirming their overall effectiveness.

%Table \ref{tab:human-evaluation} presents a detailed statistical analysis of the human evaluation study, computed based on the average scores for each meme. The analysis shows that most hateful memes' interpretations scored above 3 on a 5-point scale, indicating their effectiveness and utility. Additionally, the central tendency measures reveal a left-skewed distribution for all measures. These distributions mean that most interpretations received higher scores, with fewer lower scores, further supporting their overall effectiveness in conveying the intended messages of the memes.

\subsection{Case Study Analysis}

\paragraph{Meme Interpretation.} 
% Table \ref{tab:case-study-analysis} showcases the details of the two randomly chosen memes and their corresponding interpretations. We notice that the generated interpretation of meme \ref{tab:case-study-analysis}(a) is highly informative and accurate in explaining the implicit hate message concealed within the meme. The interpretation effectively utilizes both textual and visual cues to provide an accurate depiction of the meme’s background setting. Subsequently, the interpretation captures the underlying hate implication that white children have a stronger tendency for acts of violence or terrorism, stemming from a stereotypical bias associated with white individuals. On the other hand, the interpretation for meme \ref{tab:case-study-analysis}(b) contains a high level of inaccuracies. While the interpretation initially connects the idea of a ``large crowd of people waving rainbow flags” with a ``high prevalence of mental illness in the community”, it subsequently misunderstands that the meme is discussing about mentally ill people on a street. This misunderstanding completely alters the implicit hate message, distorting the original intention of the meme. Nevertheless, the generated interpretation still discourages the use of stereotypical bias and stigmatizing language against people with mental disorders.



Table \ref{tab:case-study-analysis} showcases the details of randomly chosen hateful memes and their corresponding interpretations from the FHM and MAMI datasets, respectively. We notice that the generated interpretation of meme \ref{tab:case-study-analysis}(a) effectively utilizes both textual and visual information to depict the meme. Subsequently, the interpretation captures the underlying hate implication that white children are more prone to acts of violence or terrorism, stemming from a stereotypical bias associated with white individuals. On the other hand, the interpretation for meme \ref{tab:case-study-analysis}(b) contains a high level of inaccuracies. Although the interpretation initially connects the idea of a ``large crowd of people waving rainbow flags'' with a ``high prevalence of mental illness in the community'', it mistakenly assumes that the meme discusses mentally ill people on the street. This misunderstanding completely alters the implicit hate message, distorting the original intention of the meme. Nevertheless, the generated interpretation still discourages the use of stereotypical bias and stigmatizing language against people with mental disorders.


\begin{figure}[t]
\centering
\includegraphics[width=\linewidth]{images/IntMeme-Explainability.drawio.pdf}
\caption{LIME's visualization of the meme interpretation’s contribution towards IntMeme$_\text{mPLUG-Owl}$ model's prediction}
\label{fig:lime-visualization}
\end{figure}

\paragraph{Enhanced Model Explainability.} 
% IntMeme$_\text{mPLUG-Owl}$ conditions the classification of hateful memes based on both the meme and its interpretation. Therefore, we utilized \textit{Locally Interpretable Model-Agnostic Explanations} (\textbf{LIME}), a model-agnostic explainer, to further explain the influence of meme interpretations on the model’s classification results. The visualization of the interpretation’s contribution to the IntMeme$_\text{mPLUG-Owl}$  model’s classification is illustrated in Figure \ref{fig:lime-visualization}. We observed that stereotypical related terms such as “white”, “dangerous”, “school” and “violence” contributes significantly to the model’s classification for meme \ref{tab:case-study-analysis}(a), which aligns to our case study findings. Similarly, words related to mental disability, such as "mentally," "mental," and "ill," play a substantial role in the model's classification for meme \ref{tab:case-study-analysis}(b). It is important to highlight that many of these highly contributing words are absent in the original meme's text, underscoring how the generated interpretations assist in clarifying the model's decision, which would otherwise be challenging to explain. In summary, our LIME analysis reinforces our belief that having meme interpretation is useful for improving and explaining the classification of hateful meme.

IntMeme$_\text{mPLUG-Owl}$ conditions the classification of hateful memes based on both the meme and its interpretation. Therefore, we utilized \textit{Locally Interpretable Model-Agnostic Explanations} \cite{ribeiro2016should}, a model-agnostic explainer, to further explain the influence of meme interpretations on the model’s classification results. The visualization of the interpretation’s contribution to the IntMeme$_\text{mPLUG-Owl}$ model’s classification is illustrated in Figure \ref{fig:lime-visualization}. We observed that stereotypical related terms such as “white”, “dangerous”, “school” and “violence” contributes significantly to the model’s classification for meme \ref{tab:case-study-analysis}(a), which aligns to our case study findings. Similarly, words related to mental disability, such as "mentally," "mental," and "ill," play a substantial role in the model's classification for meme \ref{tab:case-study-analysis}(b). It is important to highlight that many of these highly contributing words are absent in the original meme's text, underscoring how the generated interpretations assist in clarifying the model's decision, which would otherwise be challenging to explain. In summary, our LIME analysis reinforces our belief that having meme interpretation is useful for improving and explaining the classification of hateful meme.

%\subsection{Discussion} 
% Given the rapid advancement of various LMMs demonstrating outstanding performance in multiple visual perception and cognitive tasks, the development of efficient methodologies for leveraging LMM in downstream applications has gained heightened significance \cite{yang2023dawn,fu2023mme}. However, using LMM in such tasks presents notable challenges. Firstly, the fine-tuning of LMM’s parameters can be computationally expensive and time-consuming. Addressing this, a recent research have found ways to perform parameter-efficient fine-tuning \cite{houlsby2019parameter}, which reduces the need for computation resources and time. Nevertheless, addressing answer extraction and mitigating hallucinations during natural language generation remains a persistent challenge \cite{ji2023survey}. This has even spurred a new research area focused on analyzing and enhancing the faithfulness of text generation. In our work, we focused on an zero-shot inference approach as opposed to fine-tuning LMMs, where we used LMMs to generate interim interpretation of memes. This approach reduces the computational complexity for fine-tuning a LMM, while retaining its powerful language generation capabilities.

% The downstream applications of LMMs has gained heightened significance \cite{yang2023dawn,fu2023mme}. However, using LMMs in such tasks presents significant challenges. Firstly, fine-tuning LMMs can be computationally expensive and time-consuming. Secondly, extracting answer from the generated text can be difficult. Lastly, hallucinations remains a persistent challenge \cite{ji2023survey}.

%The applications of LMMs in downstream tasks have garnered significant attention \cite{yang2023dawn,fu2023mme}. However, using LMMs for such tasks presents several challenges. Firstly, fine-tuning LMMs is computationally expensive and time-consuming. Secondly, extracting answers from the generated text can be difficult. Lastly, the issue of hallucinations remains a persistent challenge \cite{ji2023survey}. Hence, we introduce a more efficient approach in using LMMs, specifically to produce high-quality interpretations of memes for the purpose of classifying hateful memes.

%Nevertheless, our human evaluation study and manual examination uncovered numerous challenges in generating interpretations with LMMs. Although most interpretations are of good quality, a significant portion needs improvements to become more informative and helpful to end-users. We have pinpointed three main issues with these problematic interpretations: Firstly, inaccuracies in identifying visual elements cause confusion. Secondly, an inability to recognize sarcasm and wordplay results in literal interpretations. Thirdly, interpretations can be incomplete due to premature termination from LMMs. These challenges highlight the limitations of using open-source LMMs for meme interpretation and suggest avenues for future exploration in LMMs.
% classification.