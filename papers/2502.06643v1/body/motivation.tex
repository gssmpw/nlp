\section{Challenges and Motivation}

As we scale MoE models to include more experts, several challenges arise, affecting both memory and communication efficiency.
% 
While increasing the number of experts enhances model capacity, it also significantly raises the memory footprint.
% 
To address this, MoE models are distributed across multiple devices to alleviate memory constraints.
% 
State-of-the-art expert parallelism techniques have been developed to manage these memory bottlenecks~\cite{fastermoe,deepspeed-moe,li2023accelerating,exflow}.
% 
% However, these methods introduce complex inter-GPU communication patterns due to token routing, resulting in performance bottlenecks.
%
% For example, distributing experts across devices necessitates all-to-all communication to access parameters that are not located on the same device where computations are performed.
%
While these works mitigate compute and communication bottlenecks through optimized token dispatch mechanisms or locality-aware expert placement, they still suffer from inherent load imbalance and communication tail latency.
%
Expanding the number of experts exacerbates inter-GPU communication, as only a small subset of tokens is typically processed by local experts on a given GPU, requiring frequent token dispatches to remote GPUs.
% 
In distributed multi-node environments, communication costs often surpass computation time, with all-to-all token routing causing network congestion and bandwidth limitations.
% 
Figure~\ref{fig:time-distribution} illustrates the time distribution of representative operations during the forward pass of an MoE model, highlighting that communication time dominates as the system scales to multiple nodes.
% 
Maintaining balanced loads across GPUs is crucial in large-scale deployments, as skewed token distributions can lead to significant delays, reduced throughput, and inefficient resource utilization.

\begin{figure}
    \centering
    \includesvg[width=1.0\linewidth]{figures/time-distribution.svg}
    \vspace{-2em}
    \caption{Time distribution of representative operations during the forward pass of Mixtral-8x7B. The inference time is primarily dominated by all-to-all communication between GPU pairs, particularly in multi-node environments.}
    \label{fig:time-distribution}
    \vspace{-2ex}
\end{figure}

\subsection{Challenges with Expert Parallelism}

\begin{figure}
    \centering
    \includesvg[width=1.0\linewidth]{figures/expert-load-imbalance.svg}
    \vspace{-1.5em}
    \caption{Expert activation frequency of Mixtral-8x7B, highlighting significant load imbalance across layers. Darker regions indicate a higher skew. For example, in layer 14, experts 0 and 1 process 64\% of the total tokens. 
    % \todoseokjin{do we need the numbers here? the figure is too congested? And the label should also highlight that dark means higher skew. Also, 10000K should be 10M in the label.}
    }
    \label{fig:expert-load-imbalance}
    \vspace{-2ex}
\end{figure}

\niparagraph{Expert load imbalance.}
%
A significant challenge in distributing experts across devices is the occurrence of load imbalance, driven by skewed token routing distributions.
% 
Current approaches distribute experts primarily based on memory requirements, often neglecting the compute load, which depends on the number of tokens processed by each expert.
% 
This can result in certain experts receiving a disproportionate share of tokens, causing the GPUs to host these experts and experience higher processing loads. The imbalance leads to higher tail latencies, where some GPUs complete their computations early and remain idle while waiting for others to finish.
% 
Figure~\ref{fig:expert-load-imbalance} highlights the expert activation frequency across layers, demonstrating a clear skew in the number of tokens processed per expert.
%
We observe that in layers with high skew, certain GPUs suffer from a significantly higher token processing load than others.
%
For instance, in layers 14 and 23, GPUs 0 and 3 process over 64\% and 69\% of the total tokens in each layer, respectively.
%
These inefficiencies are especially detrimental in high-throughput scenarios, as idle GPU time directly reduces overall throughput and resource utilization.
% 
Addressing this load imbalance is essential to ensure efficient MoE processing and maximize hardware utilization.

\noindent\fbox{%
    \parbox{\columnwidth}{%
       \textbf{Challenge: Unbalanced token processing load across GPUs.} Token distribution across GPUs can become uneven due to imbalances in the number of tokens routed to different experts. Prior work only distributes experts to alleviate the memory footprint, this results in some GPUs becoming idle while others are overburdened due to token processing skew, leading to increased processing latency and reduced overall throughput.}
       }

\noindent\fbox{%
    \parbox{\columnwidth}{%
       \textbf{Insight: Token Routing-Based Expert Placement.} Strategic expert placement, rather than solely focusing on memory size mitigation, can significantly reduce load imbalance by evenly redistributing token workloads across GPUs in each layer.
        %
        By maximizing GPU utilization and minimizing idle times, this approach effectively reduces token processing latencies, improving MoE model performance in both single-node and multi-node configurations.}%
}
\vspace{0.5em}


\niparagraph{Tail latency due to skewed token load and inter-GPU communication.}
%
Due to the distribution of experts across GPUs, inter-GPU communication introduces significant overhead.
% 
Efficient inter-GPU communication is a critical challenge in expert-parallel MoE systems, as poorly planned expert placement can lead to communication tail latencies.
% 
Frequent routing of tokens between remote GPUs, caused by suboptimal expert distribution, generates heavy all-to-all traffic patterns.
% 
This issue is further exacerbated by token processing imbalances, which amplify communication skews across GPU pairs.
% 
As a result, certain GPU pairs handle significantly higher communication volumes, leading to underutilized interconnect bandwidth and increased tail latencies, as other GPUs stall while waiting for communication operations to complete.
% 
Figure~\ref{fig:token-dispatching} illustrates the disparity in token dispatching across GPU pairs, highlighting how some GPUs bear a disproportionately large communication load due to imbalanced token routing among distributed experts.

\begin{figure}[h!]
    \centering
    \includesvg[width=1.0\linewidth]{figures/token-dispatching.svg}
    \vspace{-1.5em}
    \caption{Number of tokens dispatched across different GPU pairs. Certain GPU pairs experience substantially higher communication volumes compared to others.}
    \label{fig:token-dispatching}
\end{figure}


\noindent\fbox{%
    \parbox{\columnwidth}{%
\noindent \textbf{Challenge: Skewed Communication Patterns.} Routing tokens to experts on different GPUs generates substantial all-to-all communication. Without optimization, this can cause congestion and inefficient interconnect bandwidth utilization, ultimately limiting system scalability and performance.}}

\noindent\fbox{%
    \parbox{\columnwidth}{%
\noindent \textbf{Insight: Affinity Towards Certain Experts Across Layers.} Optimizing expert placement to account for inter-expert token routing patterns, remote token routing can be minimized, and communication loads can be distributed more evenly across GPU pairs.
% 
This approach improves interconnect resource utilization, reduces latency, and ensures more predictable and efficient communication in large-scale MoE deployments.}}


\subsection{Inter-layer Token Routing Dependency}

While expert parallelism offers a scalable approach for deploying MoE models across multiple GPUs, its effectiveness hinges on efficient management of both processing load and inter-GPU communication.
%
Achieving this balance necessitates optimization of expert placement and token routing mechanisms.
%
To address these challenges, we exploit the observation that inter-layer expert token routing exhibits significant dependencies: when a token is routed to a specific expert in layer  \( l \), it is more likely to be routed to certain experts in layer \( l+1 \), and these patterns often persist across subsequent layers.
% 
This reveals that token paths across layers are not random but instead follow structured and predictable patterns, driven by the underlying model dynamics and characteristics.
%
% This insight motivates the need for a global expert placement framework that goes beyond layer-by-layer optimization.

\begin{figure}[h!]
    \centering
    \includesvg[width=1.0\linewidth]{figures/expert-dependency-table.svg}
    \vspace{-1.5em}
    \caption{Dependency table of Mixtral-8x7B illustrating inter-layer routing dependencies during inference. Most tokens routed to specific experts in one layer are directed to particular experts in the next layer. For instance, tokens processed by expert 1 at layer 14 are predominantly routed to expert 2 at layer 15, highlighting strong routing dependencies.}
    \label{fig:expert-dependency-table}
    \vspace{-3ex}
\end{figure}

Figure~\ref{fig:intro-tokenrouting} and~\ref{fig:expert-dependency-table} illustrate inter-layer routing dependencies, showing the frequency of token transitions between specific experts across layers.
% 
These structured dependency chains provide a key opportunity for optimization. By aligning the physical placement of frequently interacting experts with these routing patterns, we can significantly reduce inter-GPU communication, improve load balance, and minimize latency across large-scale deployments.
%
This insight motivates the need for a global expert placement framework that goes beyond just alleviating memory overheads or being limited to layer-by-layer optimization.
% 
By considering the holistic routing patterns across the model, such a framework ensures more efficient utilization of both computational and communication resources.
% 
This approach directly tackles both the challenges of inter-GPU communication overhead and load imbalance, enabling more efficient and scalable MoE systems.
