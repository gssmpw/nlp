\section{Conclusion}
We present \expertune, a method that optimizes MoE models by enhancing token dispatching and load balancing across GPUs.
%
Our experiments on Mixtral-8x7B demonstrated significant reductions in both tail latency and average token processing time, particularly in layers with high token routing skew. 
%
Furthermore, \expertune~mitigates the impact of inter-GPU communication overhead by balancing remote token dispatching and ensuring efficient all-to-all communication.
%
%By addressing communication bottlenecks and optimizing load distribution, \expertune~enables more scalable and efficient MoE inference, making it a promising solution for large-scale deployments.


% \begin{figure}[t]
%     \centering
%     % First subfigure (a)
%     \begin{subfigure}[b]{0.485\linewidth}
%         \centering
%         \includesvg[width=1\linewidth]{figures/processing-load-vanilla.svg}
%         \caption{Token processing load distribution (Megatron-LM).}
%         \label{fig:processing-load-baseline}
%     \end{subfigure}
%     \hspace{0.01\linewidth}  % Add horizontal space between the subfigures
%     % Second subfigure (b)
%     \begin{subfigure}[b]{0.485\linewidth}
%         \centering
%         \includesvg[width=1\linewidth]{figures/processing-load-custom.svg}
%         \caption{Token processing load distribution (\expertune).}
%         \label{fig:processing-load-expertune}
%     \end{subfigure}
%     \vspace{-2em}
%     \caption{Distribution of tokens processed by a single GPU per layer. Each box plot summarizes the variation in token processing load across GPUs for a single layer. \expertune~significantly reduces both the variation and peak load, demonstrating improved load balancing across GPUs.}
%     \label{fig:processing-load}
% \end{figure}


% \begin{figure}[t]
%     \centering
%     % First subfigure (a)
%     \begin{subfigure}[b]{\linewidth}
%         \centering
%         \includesvg[width=1\linewidth]{figures/tail-latency-communication_1node.svg}  % Update file name if needed
%         \vspace{-1.8em}
%         \caption{Single node: Average and tail latency of all-to-all time across GPUs in each neighboring layers.}
%         \vspace{0.5em}
%         \label{fig:tail-latency-communication-1node}
%     \end{subfigure}
%     % Second subfigure (b)
%     \begin{subfigure}[b]{\linewidth}
%         \centering
%         \includesvg[width=1\linewidth]{figures/tail-latency-communication_2nodes.svg}  % Update file name if needed
%         \vspace{-1.8em}
%         \caption{Multi node: Average and tail latency of token processing time across GPUs in each neighboring layers.}
%         \label{fig:tail-latency-communication-2nodes}
%     \end{subfigure}
%     \vspace{-2em}
%     \caption{Comparison of average and tail latency of all-to-all communication in each layer for single-node and multi-node setups. \expertune~provides substantial reduction in tail latency and average latency.}
%     \label{fig:communication-tail-latency-comparison}
% \end{figure}


% \begin{figure}[t]
%     \centering
%     % First subfigure (a)
%     \begin{subfigure}[b]{0.485\linewidth}
%         \centering
%         \includesvg[width=1\linewidth]{figures/comm-volume-vanilla.svg}
%         \caption{Token dispatching distribution (Megatron-LM).}
%         \label{fig:comm-vanilla}
%     \end{subfigure}
%     \hspace{0.01\linewidth}  % Add horizontal space between the subfigures
%     % Second subfigure (b)
%     \begin{subfigure}[b]{0.485\linewidth}
%         \centering
%         \includesvg[width=1\linewidth]{figures/comm-volume-custom.svg}
%         \caption{Token dispatching distribution (\expertune).}
%         \label{fig:comm-custom}
%     \end{subfigure}
%     \vspace{-2em}
%     \caption{Distribution of total token dispatching between individual GPU pairs across neighboring layers, measured for a single-node configuration. Each data point in a box plot represents the total number of tokens dispatched between a specific GPU pair (e.g., GPU0-GPU1) across all iterations. 
%     % Seokjin: Made cuts since caption was too long.
%     %\expertune~significantly reduces both the variation and the maximum number of tokens dispatched per layer.
%     }
%     \vspace{-1em}
%     \label{fig:comm-volume}
% \end{figure}
