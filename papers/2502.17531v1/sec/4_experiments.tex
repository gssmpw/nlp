\section{Experiments}
\label{sec:experiments}

In this section we show the effectiveness of our method. 
We mainly compare against the robust point cloud Laplacian~\cite{sharp2020nonmanifold} as a baseline and use the mesh Laplacian as the ground-truth on data generated from a given mesh instead of renderings only (see \cref{sub:exp:evaluation}).
We show superior performance on the computation of heat diffusion and the derivied geodesic distance (\cref{sub:exp:heatandgeo}), shape matching (\cref{sub:exp:matching}), and the adaptation of training the Gaussian splatting using the LBO for filtering (\cref{sub:exp:adapted}). 
All experiments were done a NVIDIA RTX 4090 with 64 GB RAM. 

\subsection{Evaluations and Comparisons}\label{sub:exp:evaluation}

\paragraph{Dataset.}
We build the dataset from TOSCA~\cite{MB08} that provides $8$ classes of non-rigid shapes with correspondence with at least 3 different poses in each class. We use blender to generate the image dataset for training, validation and testing. 
For each class we select 5 poses if any and generate 100 images of each shape for training, 50 images for validation and 30 images for testing. For simplicity, we downscale the object by $\frac{1}{20}$ before capturing the images to fit into a default camera frame.
In comparison to other common 3DGS datasets such as Mip-NeRF360~\cite{barron2022mip}, TOSCA contains meshes well-suited for geometry processing applications and a clean ground-truth mesh which we can use to quantitatively evaluate our method. 
We will publish this dataset with reconstructed 3DGS from TOSCA and correspondences between both with this paper to allow better evaluation of geometry processing applications on 3DGS.


\paragraph{Evaluation Metrics.}
The LBO matrices of different 3D representations cannot be compared directly because the discretization can vary significantly. 
We will use the eigenvalues and selected functions on the surface for comparing the performance of different approaches. 
The discretization differences also exist for these functions but the function values can be more easily projected onto a different discretization. 
In order to compare, we assume the smoothness of the functions between the existing samples and then project each vertex of the ground truth mesh onto the other representations (point cloud, 3D Gaussians, mesh from GOF) by distance. For each representation, we denote this correspondence by $I_\cdot$.

\textit{Eigenfunctions. } For the eigenvalues, the paper of~\cite{belkin2006convergence} shows the convergence of the Laplacian operator in the spectrum regime. 
The eigenfunctions of the point cloud Laplacian converges to the eigenfunctions of the Laplacian-Beltrami operator in the underlying manifold in $L_2$ norm with improved sampling. 
Thus, we propose to compare the eigenvalues and the eigenfunctions of the normalized Laplacian matrix, that is to solve $Lx = \lambda Mx$ and compute the first $K=100$ eigenvalues (the lower the more stable) for all experiments. 
Since the eigenvalue is inversely proportional to the scale of the surface area, we calculate the normalized difference $S|\lambda_i - \lambda_i^{gt}|$ for $i = 1,\ldots, 100$ for comparing eigenvalues. 
For the eigenfunctions, we apply the $l_2$ metric and the normalized $l_2$ metric 
\[
\begin{array}{rl}
    L_2(f_1, f'_1) &= \|\frac{f_1}{\|f_1\|_2} - \frac{f'_1}{\|f'_1\|_2} \|_2 \\[0.3em]
    L_2^w(f_1, f'_1) &= \|\frac{f_1}{\|f_1\|_w} - \frac{f'_1}{\|f'_1\|_w} \|_w
\end{array}
\]
where $\|f\|_w = f^TMf$ and $M$ is the mass matrix of the ground truth mesh and $f'$ the eigenfunction of a different representation projected onto the ground-truth mesh.

\textit{Other Functions. }
We apply the same projection before any comparisons also for the heat diffusion, geodesic distance and matching errors.
We are able to compute the losses $L_2(f(I), f_{gt})$ and $L_2^w(f(I), f_{gt})$ of the respective functions.

\paragraph{Comparisons}
We compare our method to the following baselines since there are no targeted competitiors for LBO on Gaussian splatting:
\begin{itemize}
    \item \textbf{Point Cloud:} the point cloud Laplacian on the point cloud computed from centers of the 3D Gaussian splats,
    \item \textbf{Mesh (GOF):} reconstructing the mesh from a 3DGS using the SOTA approach of Gaussian opacity fields~\cite{yu2024gaussian},
    \item \textbf{Ours (Euclid):} our GS Laplacian using the k-nearest neighbors in Euclidean distance to compute the normal direction (as in \cite{sharp2020nonmanifold}), applied on the 3DGS filtered,
    \item \textbf{Ours (M+normal):} our GS Laplacian using the lowest magnitude variance direction as normal direction and using the k-nearest neighbors in Mahalanobis distance, applied on the 3DGS filtered,
    \item \textbf{Ours(AT+M+normal):} our GS Laplacian using the lowest magnitude variance direction as normal direction and using the k-nearest neighbors in Mahalanobis distance, applied on the 3DGS after adaptive training.
\end{itemize}
The ground-truth Laplace-Beltrami operator is computed from the ground-truth meshes (if given), and we use the state-of-the-art approach~\cite{sharp2020nonmanifold} to compute the Laplacian operator on both point clouds, meshes and our adaption (also see \cref{sub:bg:lbo}). 

\subsection{Function Comparison}

Since the LBO matrix itself is not directly comparable (see \cref{sub:exp:evaluation}), we compare descriptive functions on the surface of each representation. 
We choose (i) the eigenfunctions of the LBO, (ii) heat diffusion applied from a collection of source points, and (iii) the geodesic distance computed using Geodesics in Heat~\cite{crane2017heat}.

\paragraph{Eigenfunctions. }

We take the first $10$ eigenfunctions computed from each Laplace operator and compare their values to the eigenfunctions from the LBO on the ground-truth mesh in TOSCA. 
\cref{table:eigvec_quant} shows the average over these $10$ eigenfunctions for each class and operator.
Our method and Mesh~(GOF) perform on-par while both are much better than the point cloud Laplacian. 
However, Mesh~(GOF) requires an extra step to extract a (very high resolution) mesh from the Gaussian splatting which is expensive to compute while our methods operates directly on the given data.



\begin{figure}[ht]
    \centering
    \includegraphics[width=1.0\linewidth]{tikz_figures/eigval_mahalanobis.tex}
    \caption{Statistical analysis over all the objects on the loss of eigenvalues. The index represents the order of the eigenvalue by magnitude. The line represent the average of the loss and one std is used for the confidence interval.}
    \label{fig:eigval}
\end{figure}


\begin{table*}[ht]
\begin{center}
\small
\begin{tabular}{c c c c c c c c c c c c c c c c}
\hline
\multirow{2}{*}{Class} & \multirow{2}{*}{\#Num} &\multicolumn{2}{c}{Point Cloud} & &\multicolumn{2}{c}{Mesh~(GOF)} & &\multicolumn{2}{c}{Ours~(Euclid)} & &\multicolumn{2}{c}{Ours~(M+normal)} & &\multicolumn{2}{c}{Ours~(AT+M+normal)}\\ \cline{3-4} \cline{6-7}\cline{9-10}\cline{12-13} \cline{15-16}
         &         & $L_2$     & $L_2^w$    & & $L_2$     & $L_2^w$    & & $L_2$     & $L_2^w$    & & $L_2$     & $L_2^w$ & & $L_2$ & $L_2^w$ \\ \hline
     Cat & 5       & 0.529   & 0.546    & & 0.383    & 0.423    & & 0.392   & 0.386    & & 0.409   & 0.342 & & \bf{0.340}&\bf{0.268}\\
     Centaur & 4   & 0.610   & 0.669    & & 0.842   & 1.285    & & 0.488   & 0.490    & & \bf{0.479}   & \bf{0.496} & & 0.485& 0.523\\
     David & 5     & 0.410   & 0.443    & & 0.493   & 0.642    & & \bf{0.338}   & \bf{0.312}    & & 0.360   & 0.387 & & 0.357&0.400\\
     Dog & 3       & 0.632   & 0.682    & & 0.506   & 0.537    & & 0.497  & 0.504    & & \bf{0.470}  & \bf{0.445} & & 0.547&0.582\\
     Horse & 3     & 0.800   & 0.949    & & 1.230   & 1.783    & & 0.786   & 0.926    & & \bf{0.773}   & 0.884 & & 0.776&\bf{0.846}\\
     Michael & 5   & 0.709   & 0.949    & & 0.796   & 1.140    & & 0.617   & 0.838    & & 0.605   & 0.779 & & \bf{0.589}&\bf{0.767}\\
     Victoria & 5  & 0.909   & 1.131    & & \bf{0.593}   & \bf{0.791}    & & 0.917   & 1.159    & & 0.685   & 0.861 & & 0.680 & 0.861\\
     Wolf & 3      & 0.300   & 0.259    & & \bf{0.043}   & \bf{0.002}    & & 0.106   & 0.017    & & 0.087   & 0.011 & & 0.135&0.032\\ \hline
     Total &   33    & 0.619   &0.718     & & 0.607       &0.821           & & 0.528  & 0.599     & & \lightbold{0.491}   & \bf{0.541}   & & \bf{0.489} & \lightbold{0.544}\\
\hline
\end{tabular}
\end{center}
\caption{$L_2$ distance between eigenfunction of each operator and the ground-truth mesh eigenfunctions. See \cref{sub:exp:evaluation} for definition of the metrics. While Mesh~(GOF) and our method perform on-par, our method does not require the extraction of a mesh. \label{table:eigvec_quant} }
\end{table*}


\begin{figure}[ht]
    \centering
    \includegraphics[width=1.0\linewidth]{tikz_figures/eigvec_mahalanobis.tex}
    \includegraphics[width=1.0\linewidth]{tikz_figures/eigvec_mahalanobis_weighted.tex}
    \caption{Statistical analysis of (weighted) loss on the eigenfunctions over all the objects.  The index represents the order of the eigenvalue by magnitude. The line represent the average of the loss and one std is used for the confidence interval.}
    \label{fig:eigvec}
\end{figure}

\paragraph{Curvature}\label{sub:exp:curvature}
As an intrinsic property, the mean curvature can be derived from the Laplace-Beltrami operator via the equation $\Delta p = -2Hn$, where $p$ denotes the coordinates, $H$ the mean curvature and $n$ the normal. This property can be used to evaluate the quality of the Laplacian Beltrami operator. We report qualitative and quantitative results in \cref{fig:mean_curvature} and \cref{tab:mean_curvature}. It turns out that our Laplacian is much closer to the ground truth mesh curvature than the curvature computed with the Laplacian on a mesh extracted from the 3DGS. 
The large discrepancy stems from the artifacts on the extracted mesh.
\begin{table}[ht]
    \centering
    \resizebox{\columnwidth}{!}{
    
    \begin{tabular}{c|c|c|c|c}
    \hline
       Type  &  Mesh(GOF) & Point Cloud & Ours(M+normal) & Ours(AT+M+normal)\\
       \hline
        Avg & 43.049 & 17.746 & 16.317 & \bf{16.023} \\
        Min  & 12.720 & 7.954 & 6.332 & \bf{6.202} \\
        Max  & 129.369 & 33.621 & 29.867 & \bf{29.306}\\
        \hline
    \end{tabular}
    }
    \caption{$L_1$-error of the mean curvature computed from the Laplacian operator on an extracted mesh, point cloud, ours with Mahalanobis distance and ours with adaptive training.}
    \label{tab:mean_curvature}
\end{table}

\begin{figure}
    \centering
    \includegraphics[width=0.32\linewidth]{figures/curvature_fess.png}
    \includegraphics[width=0.292\linewidth]{figures/curvature_head.png}
    \includegraphics[width=0.08\linewidth]{figures/color_bar.png}
    \caption{The mean curvature computed from the Laplacian operator. From left to right: ground truth curvature, curvature on the extracted mesh, curvature on 3DGS. Higher value represents larger mean curvature(absolute value). The extracted mesh contains many small artifacts manifested in the noise of the computed curvature. Our method is more similar to the ground truth.}
    \label{fig:mean_curvature}
\end{figure}

\paragraph{Geodesic Distance}\label{sub:exp:heatandgeo}
The geodesic distance represents the shortest path between two points on a surface, or more generally a Riemannian manifold. We use the exact "single source, all destination" algorithm proposed by Michell et al.~\cite{mitchell1987discrete} to compute the distance on the ground-truth meshes. 
For non-mesh data structures, Crane et al.\cite{crane2017heat} proposed the heat method to approximate the distance using the Laplace operator on any domain that allows the computation of gradient and divergence.

For each object, we uniformly sample $100$ sources and compute the mean of the errors as $$\mathcal{E}_{geo}(\Delta) = \frac{1}{100}\frac{1}{\sqrt{S}}\sum_{i=1}^{100} \sum_{j=1}^N|d^j - d_{\Delta}^j|$$ where $S$ is the surface area, $N$ is the number of points of the ground-truth mesh, $d^j$ is the exact geodesic distance~\cite{mitchell1987discrete} from the point $j$ to the source point and $d_{\Delta}^j$ is the geodesic distance from $j$ to the source point using the LBO $\Delta$.

\cref{table:heat} shows the comparison of geodesic distance errors. All methods are computed using Geodesics in Heat and compared to the exact distance. The Mesh~(GT) column is given as a reference to see the error induced by the Geodesics in Heat, not as a direct competitor as the ground truth mesh is not known in practice. Our method is as good as and often better than the mesh reconstruction, and is much better than the center point cloud Laplacian. 


\begin{table}[h]
\label{table:heat}
\centering
    \resizebox{\columnwidth}{!}{%
\begin{tabular}{c c c c c c c}
\hline
     Category & Mesh(GT) & Point Cloud & Mesh(GOF) & Ours(Euclid) & Ours(M+normal) & Ours(AT+M+normal)\\ \hline
     Cat & 0.017     & 0.045 &  0.028 &0.034  & \lightbold{0.027} & \bf{0.026} \\
     Centaur & 0.018 & 0.036 &  0.024 & \lightbold{0.023}  & \lightbold{0.023} & \bf{0.022} \\
     David & 0.036   & 0.050 & 0.058 & \lightbold{0.038}  & \bf{0.035} & \bf{0.035} \\
     Dog & 0.016     & 0.050 & 0.037 & 0.036  & \bf{0.031} & \lightbold{0.032} \\
     Horse & 0.016   & 0.046 & 0.029 & \bf{0.022}  & \bf{0.022} & \bf{0.022}\\
     Michael & 0.038 & 0.051 &  0.065 & \bf{0.046}  & \lightbold{0.047} & \bf{0.046} \\
     Victoria & 0.035& 0.117 &  \bf{0.078} &0.113  &0.095 & \lightbold{0.082}\\
     Wolf & 0.012    & 0.036 &  \bf{0.010} & \lightbold{0.017}  &0.018 & 0.018 \\
\hline
    Total & 0.025 & 0.056 & 0.045 & 0.045 & \lightbold{0.040} & \bf{0.038} \\ \hline
\end{tabular}%
}
\caption{Average error in geodesic computation $\mathcal{E}_{geo}$ by heat method~\cite{crane2017heat} in comparison to the exact distance on the ground-truth mesh. The bold represents the best score and the gray represents the second best.}
\end{table}


\begin{figure}[h]
    \centering
    \includegraphics[width=0.23\linewidth]{figures/wolf0_gt1.png}
    \includegraphics[width=0.23\linewidth]{figures/wolf0_gof1.png}
    \begin{overpic}[width=0.23\linewidth]{figures/wolf0_pc1.png}
    \put(46,15){\color{red}\circle{18}}
    \put(15,75){\color{red}\circle{18}}
    \end{overpic}
    \includegraphics[width=0.23\linewidth]{figures/wolf0_f_pc1.png}
    \caption{Geodesics in Heat~\cite{crane2017heat} computed on (from left to right) the ground-truth mesh, the reconstructed mesh (GOF), the center point cloud (unfiltered) and the filtered Gaussian splatting (ours). The filtering significantly improves the results (see red circles). }
    \label{fig:heat_qualitative}
\end{figure}



\subsection{Shape Matching}\label{sub:exp:matching}
A fundamental problem in geometry processing is finding correspondences between pairs of non-rigid 3D shapes. 
The approach of functional maps~\cite{ovsjanikov2012functional} provides an efficient framework to compute these in functional space where the Laplace-Beltrami basis is used for dimensionality reduction. 
We will use this application to show the effectiveness of our Laplace-Beltrami operator on 3DGS by comparing accuracy in representing correspondences.
Given the ground-truth correspondence in form of a permutation $P$, it can be projected into functional map representation by taking
\begin{equation}
    C = \Phi_t^\top M_t P \Phi_s
\end{equation}
where $\Phi_\cdot$ is the matrix of the first (ordered by frequency) $k$ stacked eigenvectors of the source and target shape, respectively, and $M_t$ the mass matrix on the target shape. 
A correspondence $\text{Corr}_{(s, t)}$ can be extracted by taking nearest neighbors in the aligned spectral space between the points in $\Phi_t$ and $C\Phi_s$.
Since we do not want to evaluate a specific matching algorithm, this projection of the ground-truth, which still leads to errors due to the dimension reduction, gives us a measure of the quality of the eigenbasis used, and in turn of our Laplace Beltrami operator.

For computational reasons, we use $k=100$ eigenfunctions and uniformly sample 1000 vertices to compute the geodesic error. 
We do the experiments on the TOSCA dataset.  
Since the vertices on the meshes are different from those derived from the 3D Gaussians, we are only able to compute the approximate geodesic error
\[
\begin{array}{rl}
    q^{gt} &= \text{Corr}_{gt}(p^s) \\[0.3em]
    q^{\Delta} &= P_{pc \to m}^t\text{Corr}_{(s, t)}(P_{m\to pc}^s p^s)) \\[0.3em]
    \mathcal{E}_{corr}^{(s, t)}(p^s) &= \frac{1}{\sqrt{S^t}}\text{dist}(q^{gt}, q^{\Delta})
\end{array}
\] %
where $p^s$ is a vertex on the mesh of the source object, $P_{pc\to m}^t$ denotes the projection from the point cloud derived from 3D Gaussians to the mesh of the target object and $P_{m\to pc}^s$ denotes the projection from the mesh of the source object to the point cloud of the source object. $\text{Corr}_{(s, t)}$ is the point-wise correspondence from the source object to the target object computed using the eigenfunction of $\Delta^s$ and $\Delta^t$ \cite{ovsjanikov2012functional} as described above.
While extracting the mesh via GOF performs slightly better, our method outperforms the point cloud Laplacian as visible in \cref{fig:quant:shape_matching} and \cref{fig:cmap:shape_matching}.

\begin{figure}[h]
    \centering
    \includegraphics[width=1.0\linewidth]{tikz_figures/shape_matching_quant_mahalanobis.tex} 
    \caption{Geodesic error representing the ground-truth correspondence in a low-dimensional LBO basis, averaged over all the categories. For each category, we take a loop to select the pairs. For example, centaur0$\to$ centaur2, centaur2$\to$centaur3, centaur3$\to$centaur4, centaur4$\to$centaur0 are selected pairs in the centaur category. The line represent the average of the error.}
    \label{fig:quant:shape_matching}
\end{figure}

\begin{figure}[ht]
    \centering
    \begin{overpic}[width=0.9\linewidth]{figures/ColorMap.png}
        \put(14,1){\colorbox{white}{\footnotesize{GOF}}}
        \put(11,32){\colorbox{white}{\footnotesize{GT target}}}
        \put(43,17){\colorbox{white}{\footnotesize{Source}}}
        \put(60,1){\colorbox{white}{\footnotesize{Ours(Mahalanobis+normal)}}}
        \put(72,32){\colorbox{white}{\footnotesize{Point cloud}}}
    \end{overpic}
    \caption{Color map for shape matching in the horse category. 
    The source map (center) is colored by coordinate and the colors transferred with the correspondence computed by each method to the surrounding shapes.
    Inconsistencies in color indicate problems with the correspondence.
    }
    \label{fig:cmap:shape_matching}
\end{figure}

\subsection{Adaptive Training of 3DGS}\label{sub:exp:adapted}
We use our adaptive training technique (\cref{sub:method:adaptive}) and point cloud filtering (\cref{sub:method:filter}) to improve the geometry of the results when training 3DGS.
Specifically, we filter every $N=2000$ iterations and remove all except the $k=1$ biggest components at the same time. Note that finding all the connected components can be achieved by breadth-first search in complexity $O(N)$, hence the extra cost of computation is insignificant during training.

Remarkably, this training scheme leads to a very clean geometry with nearly no outlier splats in the geometry (see \cref{fig:filtering}). It achieves on-par performance with other versions of our method and mesh reconstruction method in the comparison of eigenfunctions in \cref{table:eigvec_quant} and a slightly closer spectrum to the ground truth as visible in in \cref{fig:eigval}. 
In addition to having the best geometry in the sense of the spectrum of Laplacian operator, the adaptive training produces a much more compact representation (in terms of number of points) compared to the reconstructed meshes, the 3D Gaussian splats from GOF, the filtered 3D Gaussian splats, and even the original meshes.

\begin{table}
\centering
    \resizebox{\columnwidth}{!}{%
\begin{tabular}{c c c c c c}
\hline
Category & Mesh~(GT) &GOF training & Mesh~(GOF) & Graph filtration~(ours) & Adaptive training \\ \hline
     Cat & 27894     & 15522 &  157639 &14005 & \bf{10701}\\
     Centaur & \bf{15768} & 24792 &  248178 & 22769  & 18556 \\
     David & 52565   & 17822 & 184600 & 16389  &\bf{13468}\\
     Dog & 25290     & 13066 & 142177 & 12088  & \bf{10479}\\
     Horse & 19248  &  39442& 382236 & 35891 & \bf{28686}\\
     Michael & 52565 & 16762&  174251& 15432 &\bf{13431}\\
     Victoria & 45659& 14560 &  146665 &13330  &\bf{10922} \\
     Wolf & \bf{4344}   & 13188&  143172 &12202 & 9943 \\
\hline
\end{tabular}%
}
\caption{Comparison of the size of different representations. For the mesh we report the number of vertices. For 3D Gaussian splatting we report the number of 3D Gaussian splats.}
\label{table:size}
\end{table}

During the training of 3D Gaussian splatting, we can also monitor the behavior of the spectrum of the Laplacian operator. We found that PSNR does not capture geometric information well. This can be seen from the different convergence behavior of PSNR and the first 8 eigenvalues in \cref{fig:training}. PSNR converges around iteration 12k while the geometry stabilizes at the iteration 22k. Thus, the spectrum can be used as an augmenting measure to check the stabilization of the geometry during training.


\begin{figure}[ht]
    \includegraphics[width=1.0\linewidth]{tikz_figures/training_metrics_psnr.tex}
    \includegraphics[width=1.0\linewidth]{tikz_figures/training_metric_eigval.tex}
    \caption{Evaluation metrics of PSNR (top) and spectrum (bottom) during training.}
    \label{fig:training}
\end{figure}



\section{Geometry Smoothing}
As an additional experiment from the area of geometry processing, we show how the optimized geometry can be manipulated easily with the LBO operator. 
We compute the LBO on the 3DGS and use the first 500 eigenfunctions to form a low frequency function space, denoted by $\phi \in \mathbb{R}^{n \times 500}$. %
Then, we project the xyz-coordinate functions onto $\phi$ to perform a low pass filtering (smoothing): $$v = \phi\phi^TM v, v \in\{x, y, z\},$$ where $M$ is the mass matrix.
We show the results using $k=500$ on the chair shape in \cref{fig:teaser} where even view dependent lighting effects are preserved under this smoothing operation.
