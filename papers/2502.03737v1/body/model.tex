\begin{comment}
\section{Rating Model with Participation Bias}
In this section, we introduce our basic model of the rating process with participation bias. Suppose the underlying rating of agent $i$ is $x_i\in\{1,2,\cdots,M\}$, which is an integer in $1$ and $M$. We assume $x_i$ is independently drawn from the same underlying distribution in $\Delta(\{1,2,\cdots,M\})$. We use a M-dimensional vector $\vp\in[0,1]^M$ to denote the rating distribution.

However, not all agents are motivated to provide their feedback due to the participation bias. To capture the bias, we assume there exists a participation function $g(x)$, indicating the probability of reporting their underlying ratings when the rating is $x$. We assume $g(x)\in [q,1]$ for any $x\in\{1,2,\cdots,M\}$, which is lower bounded by a known parameter $q$. In practice, $q$ can be estimated by the empirical data. In the subsequent sections, we will discuss the errors caused by inaccurate $q$. $g$ can be denoted by a vector $\vg$ in $[q,1]^M$. For simplicity, we assume the rating is $0$ when the agent does not participate the rating. 

The rule-maker only observes a modified rating $\hat{\vx}$ such that

\begin{equation*}
    \hat{x}_i=\left\{\begin{aligned}
        &x_i&\quad z_i\le g(x_i)\\
        &0&\quad z_i>g(x_i)\\
    \end{aligned}
    \right
    .
\end{equation*}

where $z_i$ is an independent and uniform random variable in $[0,1]$.

The rule-maker needs to determine an aggregating rule $f:X^n\to [1,M]$ to recover the true expectation $\mu=\E_{\rx\sim\vp}[\rx]$ from the observed ratings $\hat{\vx}$ without knowing the participation function $g$. Assume the regret is $R(f,\vp,\vg)=\E\left[\left(f(\hat{\vx})-\frac{1}{n}\sum_i x_i\right)^2\right]$. To ensure a robust aggregator, we want to minimize the error of our aggregator in the worst case. That is, we want to solve the minimax problem:

$$\min_f \max_{\vp,\vg}R(f,\vp,\vg)$$

We mainly discuss two scenarios. In the first scenario such as the education evaluation or polling
, we assume the number of agents $n$ is known (e.g., total number of students). In the second scenario such as the online movie rating, the number of agents $n$ is unknown and hard to estimate. 

\end{comment}



\section{Rating Aggregation with Known Sample Size}
\label{sec:known}
This section will discuss the setting with a known number of agents $n$. We provide the Balanced Extremes Aggregator (BEA), which performs near-optimal numerically in various cases. 

%in this setting. To approximate the empirical average $\frac{1}{n}\sum_i x_i$, we only need to estimate the expectation of the unobserved ratings: $\E[\rx_i|\hat{\rx}_i=0]$\ljl{change}. 

BEA estimates the expectation of the unobserved ratings, \(\hat{\mu}_u\), using a convex combination of extreme ratings, given by: $\hat{\mu}_u = \alpha \times 1 + (1-\alpha) \times m$ where \(\alpha\) is a parameter that depends on the observed ratings. Intuitively, \(\alpha\) increases with the number of observed ratings of 1. BEA then combines \(\hat{\mu}_u\) with the average observed ratings to produce a final aggregated result. 

\begin{comment}
\begin{figure}[h]
  \centering
  \includegraphics[width=0.47\textwidth,keepaspectratio]{picture/N=20.pdf}
  \caption{Regret of different aggregators, $n=20$. The x-axis is the lower bound of the participation probability $q$ and the y-axis is the natural logarithm of the regret. The regret of BEA almost reaches the theoretical lower bound.}
  \label{fig:N=20}
\end{figure}

\begin{figure}[h]
  \centering
  \includegraphics[width=0.47\textwidth,keepaspectratio]{picture/N=10.pdf}
  \caption{Regret of different aggregators, $n=10$.}
  \label{fig:N=10}
\end{figure}
\end{comment}




\begin{definition}[Balanced Extremes Aggregator]
Given sample size $n$, the observed ratings $\hat{\vx}$, the aggregator's output is defined as
\(f^{BEA}(\hat{\vx})=\frac{n_o\hat{\mu}_o+n_u \hat{\mu}_u}{n}.\) Here $n_o=\sum_i \mathbbm{1}(\hat{x}_i\neq 0)$ is the number of observed ratings, $n_u=n-n_o$ is the number of unobserved ratings. $\hat{\mu}_o=\frac{\sum_i \hat{x}_i}{n_o}$ is the average of the observed ratings, $\hat{\mu}_u=\alpha\times 1+(1-\alpha)\times m$ is the estimation of the unobserved ratings' expectation. \(\alpha\) \footnote{$\alpha=\frac{(a^*q)^{n_1-n_m}}{(a^*q)^{n_1-n_m}+(1-a^*)^{n_1-n_m}}$. $a^*$ is the solution to
 $$\max_a \sum_{s,t} \binom{n}{t}\binom{n-t}{s}a^{n-t}(1-a)^tq^s(1-q)^{n-s-t}\left(\frac{(n-s-t)(m-1)(1-a)^{s-t}}{n((aq)^{s-t}+(1-a)^{s-t})}\right)^2$$.} depends on the difference between the count of ratings of 1 and the count of ratings of \(m\), denoted as \(n_1-n_m\), and the lower bound of the participation probability, denoted as $q$.
% $$f(\hat{\vx})=\frac{n_o\hat{\mu}_o+\left(\alpha(n_1,n_m)+m(1-\alpha(n_1,n_m))\right)*n_u}{n}$$ where $$n_1=\sum_i \mathbbm{1}(\hat{x}_i=1),n_m=\sum_i \mathbbm{1}(\hat{x}_i=m),$$
% $$n_o=\sum_i \mathbbm{1}(\hat{x}_i\ne 0),\hat{\mu}_o=\frac{1}{n_o}\sum_i \hat{x}_i,$$
% $$n_u=\sum_i \mathbbm{1}(\hat{x}_i=0),\alpha(n_1,n_m)=\frac{(a^*q)^{n_1-n_m}}{(a^*q)^{n_1-n_m}+(1-a^*)^{n_1-n_m}}$$
\end{definition}

The design of BEA is based on a specific mixture of information structures which helps to establish a lower bound for the regret. In particular, solving $\min_f\max_{\vp,\vg} R(f,\vp,\vg)$ is equivalent to solving a zero-sum game between nature who selects an information structure $(\vp,\vg)$, and a decision-maker who selects the aggregator $f$. We will present a specific mixed strategy of the nature, and use this mixed strategy to establish a lower bound for the regret. BEA is the best response to this mixed strategy. 

\begin{lemma}[Lower Bound of the Regret]\label{lem:lower}
    Consider a pair of information structures:  
    \begin{itemize}
        \item $\theta_1=(\vp_1=[a,0,\cdots,0,1-a],\vg_1=[q,1,\cdots, 1,1])$
        \item $\theta_2=(\vp_2=[1-a,0,\cdots,0,a],\vg_2=[1,1,\cdots, 1,q])$
    \end{itemize}
    where $q$ is the lower bound of the participation probability, and $a\in[0,1]$ is a parameter. For any aggregator $f$, the regret has a lower bound
    \begin{footnotesize}
        \begin{align*}
            &\max_{\vp,\vg} 
            R(f,\vp,\vg)\\
            &\ge\max(R(f,\vp_1,\vg_1),R(f,\vp_2,\vg_2))\\
            &\ge\sum_{s,t} \binom{n}{t}\binom{n-t}{s}a^{n-t}(1-a)^tq^s(1-q)^{n-s-t}\left(\frac{(n-s-t)(m-1)(1-a)^{s-t}}{n((aq)^{s-t}+(1-a)^{s-t})}\right)^2.
        \end{align*}
    \end{footnotesize}
\end{lemma}

\paragraph{Proof Sketch}
We provide a proof sketch here, and the complete proof is deferred to \Cref{sec:apx}.

Consider a mixture of these two information structures: $\theta=\theta_1$ or $\theta_2$ with equal probability. Then given the observed ratings $\hat{\rvx}$, we can compute the posterior
$\Pr[\theta=\theta_1|\hat{\rvx}]$. The best predictor for the expectation of unobserved ratings will be the conditional expectation $\E[\rx|\hat{\rx}=0]$ given the information structure is $\theta$. Then we can calculate the regret of the best predictor to obtain our lower bound.


By enumerating all possible $a$, we obtain a corollary 

\begin{corollary}\label{cor:lower}
For any aggregator $f$, 
\begin{footnotesize}
\begin{align*}
    &\max_{\vp,\vg}R(f,\vp,\vg)\\
    \ge&\max_a \sum_{s,t} \binom{n}{t}\binom{n-t}{s}a^{n-t}(1-a)^tq^s(1-q)^{n-s-t}\left(\frac{(n-s-t)(m-1)(1-a)^{s-t}}{n((aq)^{s-t}+(1-a)^{s-t})}\right)^2
\end{align*}
\end{footnotesize}
\end{corollary}




Let \begin{scriptsize}
    $a^*=\arg\max_a \sum_{s,t} \binom{n}{t}\binom{n-t}{s}a^{n-t}(1-a)^tq^s(1-q)^{n-s-t}\left(\frac{(n-s-t)(m-1)(1-a)^{s-t}}{n((aq)^{s-t}+(1-a)^{s-t})}\right)^2$,
\end{scriptsize} then according to our proof of \Cref{lem:lower}, BEA is the best response to $\theta_1(a^*),\theta_2(a^*)$. That is, for BEA,

\begin{footnotesize}

\begin{align*}
    &R(f,\theta_1(a^*))=R(f,\theta_2(a^*))\\
    =&\max_a \sum_{s,t}\binom{n}{t}\binom{n-t}{s}a^{n-t}(1-a)^tq^s(1-q)^{n-s-t}\left(\frac{(n-s-t)(m-1)(1-\mu)}{n}\right)^2
\end{align*}
\end{footnotesize}

Based on \Cref{cor:lower}, BEA outperforms any other aggregator in our lower bound situation. Regarding general situations, we evaluate the performance of BEA numerically using Matlab. \Cref{fig:regret} shows the results, where the grey line is the theoretical lower bound given by \Cref{cor:lower}, the red line is BEA and the blue line is the simple averaging. BEA is almost optimal for a wide range of the parameter $q$, and outperforms simple averaging especially when $q$ is small. When $q$ is close to $1$, indicating there is almost no bias, BEA is not optimal. We will discuss more details in \Cref{sec:fig}.

\begin{figure}[htbp]
    \centering
    \begin{subfigure}[t]{0.45\columnwidth}
        \centering
        \includegraphics[width=\textwidth]{picture/m=3/N=20.pdf}
        \caption{$n=20$, $m=3$}
    \end{subfigure}
    \hfill
    \begin{subfigure}[t]{0.45\columnwidth}
        \centering
        \includegraphics[width=\textwidth]{picture/m=3/N=10.pdf}
        \caption{$n=10$, $m=3$}
    \end{subfigure}
    
    \vspace{0.01\textheight} 
    
    \begin{subfigure}[t]{0.45\columnwidth}
        \centering
        \includegraphics[width=\textwidth]{picture/m=5/N=20.pdf}
        \caption{$n=20$, $m=5$}
    \end{subfigure}
    \hfill
    \begin{subfigure}[t]{0.45\columnwidth}
        \centering
        \includegraphics[width=\textwidth]{picture/m=5/N=10.pdf}
        \caption{$n=10$, $m=5$}
    \end{subfigure}
    
    \caption{Simple averaging vs. BEA for different sample size $n$ and the number of rating categories $m$. The x-axis is the lower bound of the participation probability, $q$, and the y-axis is the natural logarithm of the regret. The regret of BEA almost matches the theoretical lower bound for a wide range of $q$.}
    \label{fig:regret}
\end{figure}



\begin{comment}
\subsection{Try to prove}
\paragraph{Proof Sketch}
We reduce the original problem into other problems step by step.

\begin{proof}
Denote $(f(\vx)-\mu)^2=R(\vx)$, if $R$ is convex, we have

\begin{align*}
\E[(f(\hat{\vx})-\mu)^2]&=\sum_{\vx} \Pr[\vx]R(\vx)\\
&=\sum_{\vx} \Pr[\vx]R(x_1,\vx_{-1})\\
&=\sum_{\vx} \Pr[\vx_{-1}]\sum_{x_1}\Pr{x_1}R(x_1,\vx_{-1})\\
&\le \sum_{\vx} \Pr[\vx_{-1}](\Pr[x_1=0]R(0,\vx_{-1})\\
& +\sum_{x_1\ne 0}\alpha_\mu(f(1,\vx_{-1})-\mu)^2+(1-\alpha_\mu)(f(M,\vx_{-1})-\mu)^2)
\tag{convexity of $f$}
\end{align*}


Thus we can create a new information structure such that $supp(x_1)={0,1,M}$ with higher loss. Due to the symmetries, we can obtain an information structure such that for any $i$, $supp(x_i)={0,1,M}$.

Next, consider $g(1),g(M)$. We use $a,b$ to represent the number of experts reporting $1$ and $M$.

\begin{align*}
    \E[(f(\hat{\vx})-\mu)^2]&=\sum_{a,b} \Pr[a,b]f^2(a,b)+constant\\
\end{align*}



Since $R(a,b)$ is monotone with $a,b$ 


First fix $g(1)$, then $R$ is increasing with $g(M)$

\end{proof}





\end{comment}






\section{Rating Aggregation with Unknown Sample Size}
\label{sec:unknown}

This section will discuss the case where the number of agents $n$ is unknown. Fortunately, when $n\to\infty$, meaning that we have a large number of agents, we can obtain a closed-form of the optimal aggregator, which is called the Polarizing-Averaging Aggregator.

When $n$ is unknown, the aggregator only has access to the observed histogram $n_1,n_2,\cdots,n_m$. PAA outputs the average of the empirical mean of two modified histograms. For the first histogram, we identify a threshold $k_1$, and only keep $q$ fraction of the counts for ratings above $k_1$. In the second histogram, we identify a threshold $k_2$, and only keep $q$ fraction of the counts for ratings below $k_2$. 

Notice that in the described process, only the empirical mean of histograms is relevant. Therefore, we can use the normalized histograms, specifically the empirical distribution, $\hat{p}_r=\frac{n_r}{\sum_j n_j},\forall r\in[m]$, as input.




% Intuitively, PAA computes the upper and lower bounds of the expected underlying rating when the observed rating distribution is $\hat{\vp}$. Then, we use the average of the upper and lower bounds as the aggregated result. The upper bound is calculated by a weighted average with a threshold $k_1$ such that for any rating $r\le k_1$, its weight is $\hat{p}_r/q$ and for any rating $r>k_1$, its weight is $\hat{p}_r$. Similarly, for the lower bound, there exists a threshold $k_2$ such that for any rating $r\le k_1$, its weight is $\hat{p}_r$ and for any rating $r>k_1$, its weight is $\hat{p}_r/q$.

\begin{definition}[Polarizing-Averaging Aggregator]\label{def:paa}
   Define the Polarizing-Averaging Aggregator $f^{PAA}(\hat{\vp})=\frac{u(\hat{\vp})+l(\hat{\vp})}{2}$,
    where         $$l(\hat{\vp})=\frac{\sum_{r=1}^{k_1(\hat{\vp})}r\times \hat{p}_r+q\sum_{r=k_1(\hat{\vp})+1}^{m}r\times\hat{p}_r}{\sum_{r=1}^{k_1(\hat{\vp})}\hat{p}_r+q\sum_{r=k_1(\hat{\vp})+1}^{m}\hat{p}_r} \footnote{$$k_1(\hat{\vp})=\arg\max_{1\leq k\leq m}\sum_{r=1}^{k-1}(r-k)\hat{p}_r+q\sum_{r=k+1}^{m}(r-k)\hat{p}_r\geq 0$$},$$
    $$u(\hat{\vp})=\frac{q\sum_{r=1}^{k_2(\hat{\vp})}r\times \hat{p}_r+\sum_{r=k_2(\hat{\vp})+1}^{m}r\times \hat{p}_r}{q\sum_{r=1}^{k_2(\hat{\vp})}\hat{p}_r+\sum_{r=k_2(\hat{\vp})+1}^{m}\hat{p}_r}\footnote{$$k_2(\hat{\vp})=\arg\max_{1\leq k\leq m}q \sum_{r=1}^{k-1}(r-k)\hat{p}_r+\sum_{r=k+1}^{m}(r-k)\hat{p}_r\geq 0.$$}.$$
    
\end{definition}

We will show that $l(\hat{\vp})$ is the lower bound of the true expectation $\mu$ given the empirical distribution $\hat{\vp}$ and the lower bound of the participation probability $q$, and $u(\hat{\vp})$ is the upper bound. 

\subsection{Analysis of PAA in the asymptotic case}

This section will analyze PAA in the asymptotic case. We first show that in the asymptotic case, PAA is optimal. We will then present the regret and the worst information structure of PAA in the asymptotic case.

\subsubsection{Optimality of PAA}

\begin{theorem}\label{thm:PAA}
    When $n\to\infty$, PAA is optimal.
\end{theorem}



\paragraph{Proof Sketch}
We provide a proof sketch here, the complete proof is deferred to \Cref{sec:apx}. 

We first notice that when $n\to\infty$, the regret is the loss. When $n\to\infty$, the ideal aggregator who observes full ratings knows the true distribution $\vp$. Therefore, the regret of $f$ to the ideal aggregator equals the loss $\max_{\vp,\vg}(f(\hat{\vp})-\E_{\rx\sim\vp}[\rx])^2$. The problem becomes solving $\min_f\max_{\vp,\vg}(f(\hat{\vp})-\E_{\rx\sim\vp}[\rx])^2$ conditional on knowing the empirical distribution of the observed ratings $\hat{\vp}$. 

Furthermore, when $n\to\infty$, $\hat{\vp}$ is propositional to the element-wise product\footnote{For any vectors $\vx,\vy$, their element-wise product is $\vx\circ\vy=(x_1y_1,\cdots,x_ny_n).$} of the true distribution $\vp$ and the participation probabilities $\vg$: $\hat{\vp}\propto \vp\circ\vg$. 

% we have 
% \begin{small}
%     $$\max_{\vp,\vg}(f(\hat{\vp})-\E_{\rx\sim\vp}[\rx])^2=\max\{(f(\hat{\vp})-l^*(\hat{\vp}))^2,(f(\hat{\vp})-u^*(\hat{\vp}))^2\}\geq (u^*(\hat{\vp})-l^*(\hat{\vp}))^2/4$$
% \end{small}


% The equality holds if and only if $f(\hat{\vp})=(u^*(\hat{\vp})+l^*(\hat{\vp}))/2$, so 

The proof is divided into the following steps. 

\paragraph{Optimal aggregator is the midpoint of extremes} Given $\hat{\vp}$, define the lower bound of the expectation of $\vp$ which satisfy the propositional constraint $l^*(\hat{\vp})=\min_{\vp,\vg:\hat{\vp}\propto \vp\circ\vg}\E_{\rx\sim\vp}[\rx]$ and the upper bound $u^*(\hat{\vp})=\max_{\vp,\vg:\hat{\vp}\propto \vp\circ\vg}\E_{\rx\sim\vp}[\rx]$. 

Since $(f(\hat{\vp})-\E_{\rx\sim\vp}[\rx])^2$ measures the squared distance to $\E_{\rx\sim\vp}[\rx]$, the best aggregator must be the midpoint between the extreme values to minimize this squared distance. That is, the best $f$ has the format of $(u^*(\hat{\vp})+l^*(\hat{\vp}))/2$. 


It's left to show that $l^*(\hat{\vp})=l(\hat{\vp})$ and $u^*(\hat{\vp})=u(\hat{\vp})$ where $l(\hat{\vp})$ and $u(\hat{\vp})$ are described in the definition of PAA (\Cref{def:paa}).

\paragraph{Minimize or maximize $\E_{\rx\sim\vp}[\rx]$ given $\hat{\vp}$} Given $\hat{\vp}$, we start to find $(\vp',\vg')$ to minimize or maximize $\E_{\rx\sim\vp}[\rx]$, conditional on $\hat{\vp}\propto \vp\circ\vg$. We first characterize $\vg'$. Here are two properties of the optimal $\vg'$. 
\begin{itemize}
    \item $\vg'$ is extreme: $g_r=1$ or $q$ for any rating $r$.
    \item $\vg'$ is monotonic: $g_r\le g_{r+1}$ or $g_r\ge g_{r+1}$ for any rating $r$.
\end{itemize}

Here is how we derive the above properties. Given $\hat{\vp}$, because $\hat{\vp}\propto \vp\circ\vg$, $\E_{\rx\sim\vp}[\rx]$ can be viewed as a function, denoted as $F$, of $\vg$. By calculating the partial derivative of $F$, we observe the sign of $\frac{dF}{dg_r}$ is independent with $g_r$ as long as $g_r$ is positive. The sign of $\frac{dF}{dg_r}$ can be determined by $F(\vg)-r$.

Using these two properties of $\vg'$, $\vg'$ can be constructed as follows: for the minimum, there exists an index $k_1(\hat{\vp})$ such that $g_r=q$ for any $r\le k_1(\hat{\vp})$ and $g_r=1$ otherwise. While for the maximum, there exists an index $k_2(\hat{\vp})$ such that $g_r=1$ for any $r\le k_2(\hat{\vp})$ and $g_r=q$ otherwise.

To find the optimal $k_1(\hat{\vp}),k_2(\hat{\vp})$, we can simply enumerate all the $m$ values, but we make a more careful analysis to give the closed-form of the optimal $k_1(\hat{\vp}),k_2(\hat{\vp})$ in the appendix. 

This finishes the proof sketch of the optimality of PAA in the asymptotic case. 

\begin{figure}[h]
  \centering
  \includegraphics[width=0.3\textwidth,keepaspectratio]{picture/PAA.pdf}
  \caption{Simple averaging vs. PAA for a specific case where the number of rating categories is $m=3$: The x-axis is the lower bound of the participation probability, $q$, and the y-axis is the natural logarithm of the regret.}
  \label{fig:PAA}
\end{figure}

\subsubsection{Regret and the worst information structure of PAA}

We also obtain the closed forms of regret and the corresponding worst information structure of PAA.

\begin{proposition}
    \label{prop:PAA}
    When $n\to\infty$, the regret of PAA is $\left(\frac{(m-1)(1-q)}{2(1+q)}\right)^2$. In addition, the corresponding worst pair of information structure is 
    \begin{itemize}
        \item $\theta_1=(\vp_1=[\frac{1}{q+1},0,\cdots,0,\frac{q}{q+1}],\vg_1=[q,1,\cdots,1,1])$
        \item $\theta_2=(\vp_2=[\frac{q}{q+1},0,\cdots,0,\frac{1}{q+1}],\vg_2=[1,1,\cdots, 1,q])$
    \end{itemize}
    
    That is, $$R(f^{PAA},\theta_1)=R(f^{PAA},\theta_2)=\left(\frac{(m-1)(1-q)}{2(1+q)}\right)^2.$$
\end{proposition}

\paragraph{Proof Sketch}

Fix the optimal aggregator PAA, we aim to find the worst information structure $(\vp^*,\vg^*)$ that maximizes the loss/regret $(f^{PAA}(\hat{\vp})-\E_{\rx\sim\vp}[\rx])^2$. 

We have proved that the optimal aggregator is the midpoint of the extremes $l(\hat{\vp})$ and $u(\hat{\vp})$. The maximal loss is $\left(u(\hat{\vp})-l(\hat{\vp})\right)^2/4$. To obtain the maximal loss, we aim to find $\hat{\vp}^*$ to maximize $u(\hat{\vp})-l(\hat{\vp})$. We analyze the maximizer in the following four steps.

\begin{itemize}
    \item We first show that $\hat{\vp}^*$ has at most three non-zero entries: $|\{r:\hat{p}_r>0\}|\le 3$.
    \item We further show that $\hat{\vp}^*$ has exactly two non-zero entries: $|\{r:\hat{p}_r^*>0\}|= 2$.
    \item We then obtain the concrete value: $\hat{\vp}^*=(\frac{1}{2},0,\cdots,0,\frac{1}{2})$.
    \item Finally, we construct two worst information structures $$\theta_1=(\vp_1=[\frac{1}{q+1},0,\cdots,0,\frac{q}{q+1}],\vg_1=[q,1,\cdots,1,1]),$$
    $$\theta_2=(\vp_2=[\frac{q}{q+1},0,\cdots,0,\frac{1}{q+1}],\vg_2=[1,1,\cdots, 1,q]).$$ In particular, $\theta_1$ is the maximizer of $\E_{\rx\sim\vp}[\rx]$ given $\hat{\vp}=\hat{\vp}^*$. $\theta_2$ is the minimizer of $\E_{\rx\sim\vp}[\rx]$ given $\hat{\vp}=\hat{\vp}^*$. 
\end{itemize}

\textbf{First Step:} For any empirical distribution $\hat{\vp}$, recall that the participation probabilities in the maximizer of $\E_{\rx\sim\vp}[\rx]$ given $\hat{\vp}$ has the format that $g_r=1$ for any $r\le k_1(\hat{\vp})$ and $g_r=q$ otherwise. The participation probabilities in the minimizer of $\E_{\rx\sim\vp}[\rx]$ given $\hat{\vp}$ has the format that $g_r=q$ for any $r\le k_2(\hat{\vp})$ and $g_r=1$ otherwise. 

The aim is to maximize the gap $u(\hat{\vp})-l(\hat{\vp})$. We first divide $\hat{\vp}$ into three components by $k_1(\hat{\vp})\leq k_2(\hat{\vp})$. Then we prove that by alternately concentrating all probabilities in the first component at rating $1$ and all probabilities in the third component at rating $m$, we can achieve a new distribution with a non-decreasing gap. Note that in the new distribution, the threshold will also change. We repeat this concentration step until the distribution stabilizes at $\hat{\vp}'$, which has the following form: $(\hat{p}_1',0,\cdots,0,\hat{p}_{k_1(\hat{\vp}')+1}',\cdots,\hat{p}_{k_2(\hat{\vp}')}',0,\cdots,0,\hat{p}_m')$. At last we concentrate all probabilities in the second component of $\hat{\vp}'$ at one of rating $(k_1(\hat{\vp}')+1)$ and rating $k_2(\hat{\vp}')$ to obtain a final distribution with a non-decreasing gap and at most three non-zero entries.

\textbf{Second Step:} Now we have proved that $\hat{\vp}^*$ has at most three non-zero entries at position $1,k\in(1,m),m$. We further find that we can redistribute the density at the middle position $k$ to one of the end positions $1,m$ will not decrease the gap $u(\hat{\vp})-l(\hat{\vp})$. Thus, we show that $\hat{\vp}^*$ has exactly two non-zero entries: $|\{r:\hat{p}_r^*>0\}|= 2$.


%Then we prove the worst $\hat{\vp}$ is binary through some classification discussion of the optimal index of the new distribution $\vp'$ and some straightforward calculation.

\textbf{Third Step:} Given the simple format of $\hat{\vp}^*$, we obtain its value by differentiation.

\textbf{Fourth Step:} Finally, we calculate the worst information structures $(\vp^*,\vg^*)$ given $\hat{\vp}^*$ by computing the maximizer and the minimizer of $\E_{\rx\sim\vp}[\rx]$ given $\hat{\vp}=\hat{\vp}^*$. 

\subsection{Analysis of PAA in the finite case}

PAA is also applicable for the finite case. Though PAA is not optimal when $n$ is finite, we prove that it is near-optimal, with the error bound depending on the sample size $n$, and the number of rating categories $m$.

\begin{theorem}\label{thm:finite}
When $m=o\left((\frac{n}{\ln n})^{\frac{1}{4}}\right)$, PAA is $O\left(m^2\sqrt{\frac{\ln n}{n}}\right)$-optimal. That is, for any aggregator $f$,
$$\max_{\vp,\vg} R(f^{PAA},\vp,\vg)\le \max_{\vp,\vg} R(f,\vp,\vg)+O\left(m^2\sqrt{\frac{\ln n}{n}}\right).$$ 
\end{theorem}

\paragraph{Proof Sketch}
The input to \( f^{PAA} \) is the empirical distribution of observed ratings. In the asymptotic scenario, this corresponds to \( \vp \circ \vg \), and we have demonstrated that \( f^{PAA} \) is optimal under these conditions. However, in finite sample situations, the empirical distribution is only an approximate version of \( \vp \circ \vg \). Consequently, the performance of \( f^{PAA} \) hinges on the quality of this approximation. We will further analyze the performance by employing the Chernoff bound and union bound to assess the approximation's accuracy.

Furthermore, when $n$ is finite, unlike the asymptotic case, the regret is not the loss. When $n$ is different, the ideal aggregator is also different. The analysis should also consider this. 

% For clarity, we define $R_n(f^{PAA},\vp,\vg)$, which is the regret when the sample size is $n$. Suppose $f^*_n$ is the optimal aggregator in the finite case. It is equivalent to prove $$\max_{\vp,\vg} R_n(f^{PAA},\vp,\vg)\le \max_{\vp,\vg} R_n(f^*_n,\vp,\vg)+O\left(m^2\sqrt{\frac{\ln n}{n}}\right)$$

% Use $R_n(f^*)$ to denote the optimal regret when the sample size is $n$ (i.e. $R_n(f^*)=\max_{\vp,\vg} R_n(f^*_n,\vp,\vg)$), and $R^*$ is the optimal regret when $n \to \infty$. First note $R_n(f^*)$ is a non-increasing function with respect to $n$ since we can always choose the aggregator which only uses part of the ratings, so $R_n(f^*)\geq R^*$. Then we bound the difference between $R_n(f^{PAA},\vp,\vg)$ and $R^*$ by the concentration bound. 




% By Chernoff bound and union bound, first with probability at least 1-$O(\frac{1}{n})$, the number of ratings $r$: $n_r$, the number of observed ratings $r$: $\hat{n}_r$ and the sum of all observed ratings: $\sum_r \hat{n}_r$ will concentrate on their expectations. When these ratings concentrate, the difference can be bounded by $O(m^2\sqrt{\frac{\ln n}{n}})$. Otherwise, we bound the difference by $O(m^2)$. Putting the two pieces together, the difference between $R_n(f^{PAA},\vp,\vg)$ and $R_{\infty}(f^{PAA},\vp,\vg)$ is bounded by $O(m^2\sqrt{\frac{\ln n}{n}})$. Since for any $\vp,\vg$ the inequality holds, we have $$\max_{\vp,\vg} R_n(f^{PAA},\vp,\vg)\leq \max_{\vp,\vg} R_{\infty}(f^{PAA},\vp,\vg)+O\left(m^2\sqrt{\frac{\ln n}{n}}\right)$$

% So for any sample size $n$,
% \begin{align*}
%     \max_{\vp,\vg} R_n(f^{PAA},\vp,\vg)&\leq \max_{\vp,\vg} R_{\infty}(f^{PAA},\vp,\vg)+O\left(m^2\sqrt{\frac{\ln n}{n}}\right)\\
%     &=R^*+O\left(m^2\sqrt{\frac{\ln n}{n}}\right)\\
%     &\leq R_n(f^*)+O\left(m^2\sqrt{\frac{\ln n}{n}}\right)\\
%     &= \max_{\vp,\vg } R(f_n^*,\vp,\vg)+O\left(m^2\sqrt{\frac{\ln n}{n}}\right)
% \end{align*}

% The first equality holds since $f^{PAA}$ is the optimal aggregator when $n \to \infty$.


    
\begin{comment}


\gyk{Bound the regret of this aggregator in the finite case by the concentration ineq.}
\gyk{what if we cannot estimate $q$. For example, let $|q-q'|=\epsilon$. How much error will be introduced.}

When $\epsilon$ is small, the error is linear on $\epsilon$.




    \begin{lemma}
    Fix $(x,y)$, $|f_q(x,y)-\frac{m+1}{2}|$ is a monotonically increasing function with respect to $q$.
\end{lemma}
    

\begin{proof}
    Suppose $x=\sum_i \mathbbm{1}(\hat{x}_i=1),y=\sum_i \mathbbm{1}(\hat{x}_i=m)$. $$f(x,y)=1+\frac{m-1}{2}(\frac{y}{\frac{x}{q}+y}+\frac{y}{qx+y})$$
    $$sa(x,y)=\frac{x+my}{x+y}=1+\frac{m-1}{2}\frac{2y}{x+y}$$
    \begin{align*}
        f(x,y)-sa(x,y)&=\frac{m-1}{2}(\frac{y}{\frac{x}{q}+y}+\frac{y}{qx+y}-\frac{2y}{x+y})\\
        &=\frac{m-1}{2}\left(\frac{(1/q+q)x+2y}{x^2+y^2+(1/q+q)xy}-\frac{2y}{x+y}\right)
    \end{align*}
    
    Fix $x,y$. Define $t=\frac{1}{q}+q \in [2,\infty)$, 
    \begin{align*}
        F(t)&=f(x,y)-sa(x,y)\\
        &=\frac{m-1}{2}\left(\frac{tx+2y}{x^2+y^2+txy}-\frac{2y}{x+y}\right)\\
    \end{align*}
    \begin{align*}
        \frac{dF}{dt}&=\frac{m-1}{2}\frac{x(x^2+y^2+txy)-xy(tx+2y)}{(x^2+y^2+txy)^2}\\
        &=\frac{m-1}{2}\frac{x(x^2-y^2)}{(x^2+y^2+txy)^2}
    \end{align*}
\end{proof}
\end{comment}

