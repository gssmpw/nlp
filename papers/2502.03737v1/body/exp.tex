\section{Experiment}
\label{sec:exp}
\subsection{Experiment on real-world data}

We validate our aggregators on a real-world dataset about the ratings of hotels \cite{karaman2021online}. This dataset includes  96,646 survey ratings and 47,820 online reviews on a scale from 1 to 10. Survey ratings are privately collected and are considered to be true ratings of survey takers. Then survey takers are invited to post their hotel experience as online reviews, which is the observed ratings we used to test our aggregators. The detailed distributions of the data is in \Cref{sec:fig}.

For simplicity, we cut the range of ratings by mapping agent $i$'s old rating $s(i)$ into a new rating $s'(i)$ as follows,
\begin{equation*}
    s'(i):=\begin{cases}
    1 & 1\leq s(i) \leq 4;\\
    s(i)-3 & 5 \leq s(i)\leq 10.
    \end{cases}
\end{equation*}

\begin{table}[h]
\centering
\resizebox{0.3\textwidth}{!}{
\begin{tabular}{|c|c|c|c|}
\hline
AVG & PAA & BEA & Ground truth\\
\hline
5.75 & \textbf{5.66} & 6.03 & 5.53\\
\hline
\end{tabular}
}
\caption{Result of PAA, BEA and the simple average (AVG) for $q=0.3$. PAA is closest to the ground truth.}
\label{table:res}
\end{table}

\Cref{table:res} shows the result of our aggregators and the simple average aggregator. We set $q=0.3$, which is a little smaller than the empirical average participation probability $\frac{47820}{96646}$. The true empirical mean is $5.53$ and all aggregators overestimate the ratings. While PAA is closer to the true empirical mean than the simple average, BEA\footnote{Since the gap $n_1-n_m$ between the number of agents rating $1$ and the number of agents rating $m=7$ is large, we use the Monte Carol method to estimate $a^*$.} has a higher regret than the simple average. A possible reason is that ratings often exhibit a smoother distribution in real-world scenarios. BEA, designed to mitigate the impact of extreme ratings in the worst scenario, may not be well-suited for datasets with smoother rating distributions.

\subsection{Comparison with other aggregators}

We also compare our aggregator to the spectral method (SPE) \cite{xiao2017score} which takes an observed rating matrix as input. In the single-item setting, SPE degenerates to the root sum squared,i.e.
$$
    f^{SPE}(\hat{\vx})=\sqrt{\frac{\sum_{\hat{x}_i\neq 0}{\hat{x}_i^2}}{\sum_i \mathbbm{1}(\hat{x}_i\neq 0)}}.
$$
\Cref{fig:SPE} illustrates the result. Both BEA and PAA outperform SPE in the worst-case scenario.

\begin{figure}[h]
  \centering
  \includegraphics[width=0.3\textwidth,keepaspectratio]{picture/SPE.pdf}
  \caption{Regret of different aggregators when $n=20, m=5$. The x-axis is the lower bound of the participation probability $q$, and the y-axis is the natural logarithm of the regret. Both BEA and PAA outperform the spectral method (SPE) for any $q$.}
  \label{fig:SPE}
\end{figure}


