\section{Conclusion}
In this work, we explored the problem of rating aggregation with the participation. We focus on two scenarios where the sample size may be either known or unknown. For the known case, we introduced the Balanced Extremes Aggregator (BEA), which balances the extreme ratings by predicting the unobserved ratings with the observed ratings. We evaluate its performance by numerical results. For the unknown sample size setting, we presented the Polarizing-Averaging Aggregator (PAA), which achieves near-optimal performance by averaging two polarized true distributions given the observed ratings. We validate both BEA and PAA in a real-world dataset and compare them to other aggregators. The experiment shows the advantages of our aggregators.

As for the future work, we could explore adaptive algorithms that dynamically adjust to varying participation probabilities over time could enhance robustness, especially in rapidly changing environments like e-commerce and social media platforms.

In this work, we assume the ratings are independent. Incorporating user behavior analysis, such as identifying and adjusting for systematic biases based on user demographics or past behavior, could yield more general aggregators.

Another promising direction involves extending our aggregators to handle multi-dimensional ratings, which are common in modern applications where users rate multiple attributes (e.g., service, quality, and price).
