\section{Error Analysis and Statistical Significance}
\label{app:error}

For the error analysis, two separate random variables, $X_0$ and $X_1$, are considered. The symbol $X$ represents one of the metrics discussed in Sec.~\ref{sec:experiments_evaluation}, while $0$ and $1$ stand for two approaches that are to be compared, like standard Adam and Coupled Adam, for instance.
For each of the two random variables $i = \{ 0, 1 \}$, we conduct and evaluate $S$ training runs with different seeds, yielding results 
\begin{align}
\{ X_i^{(1)}, \ldots, X_i^{(S)} \}
\end{align}
While it is desirable to have a large sample size $S$, it is  prohibitively expensive for large model and dataset sizes to repeat training runs. We use
\begin{align}
S &= 3
\label{eq:error_S3}
\end{align}
except for the large-scale experiments (Sec.~\ref{sec:experiments_L}), where we restrict ourselves to
\begin{align}
S &= 1
\label{eq:error_S1}
\end{align}
We are interested in the difference 
\begin{align}
d = X_1 - X_0
\label{eq:error_d}
\end{align}
For $S=1$, it can be computed straight forwardly. However, no statement about the statistical uncertainty or significance of $d$ can be made.
In the case of $S = 3$, we apply a one-sided Student's t-test with a confidence level of 
\begin{align}
\alpha = 95\%
\label{eq:error_confidence_level_alpha}
\end{align}
First, the sample means
\begin{align}
\bar X_i &= \frac{1}{S} \sum_{s=1}^S X_i^{(s)}
\label{eq:student_mean_i}
\end{align}
and the corrected sample standard deviations
\begin{align}
\hat \sigma_i^2 &= \frac{1}{S-1} \sum_{s=1}^S \left( X_i^{(s)} - \bar X_i \right)^2
\label{eq:student_std_i}
\end{align}
for the two samples $i \in \{0, 1\}$ are estimated.
The sample means from Eq.~(\ref{eq:student_mean_i}) are combined to an estimate for their difference,
\begin{align}
\bar d &= \bar X_1 - \bar X_0
\label{eq:student_mean_d}
\end{align}
and the sample standard deviations from Eq.~(\ref{eq:student_std_i}) are propagated to the sample standard deviation of $d$ via Gaussian error propagation:
\begin{align}
\hat \sigma_d &= 
\sqrt{\left( \frac{\partial d}{\partial X_0} \cdot \hat \sigma_0 \right)^2 + \left( \frac{\partial d}{\partial X_1} \cdot \hat \sigma_1 \right)^2} \nonumber \\
&\stackrel{(\ref{eq:error_d})}{=} \sqrt{\hat \sigma_0^2 + \hat \sigma_1^2}
\label{eq:sigmad}
\end{align}

Student's t-distribution for the chosen confidence level $\alpha$ (see Eq.~(\ref{eq:error_confidence_level_alpha})) and the
\begin{align}
\nu &= S - 1 \stackrel{(\ref{eq:error_S3})}{=} 2 
\end{align}
degrees of freedom yields
\begin{align}
t_{\alpha, \nu} = 2.92
\label{eq:talphanu}
\end{align}
With $S$, $\sigma_d$ and $t_{\alpha, \nu}$ from Eqs.~(\ref{eq:error_S3}), (\ref{eq:sigmad}) and (\ref{eq:talphanu}) as ingredients, the one-sided confidence threshold for the difference can be computed as
\begin{align}
d_{\rm significance}
&= t_{\alpha, \nu} \cdot \frac{\hat \sigma_d}{\sqrt{S}}
\label{eq:studentonesidedconfidencethreshold}
\end{align}
Hence, the estimate $\bar d$ from Eq.~(\ref{eq:student_mean_d}) is considered a statistically significant improvement of approach $i=1$ over approach $i=0$ if
\begin{align}
\bar d < - d_{\rm significance}
\label{eq:student_signficance_loss}
\end{align}
for metrics where smaller values are desirable (e.g. $\Loss$), and 
\begin{align}
\bar d > d_{\rm significance}
\label{eq:student_signficance_other}
\end{align}
for metrics where larger values are better (e.g. $\Acc$).
