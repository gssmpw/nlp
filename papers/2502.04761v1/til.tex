\section{Transitive Relation Learning}
\label{sec:til}
%
In this section, we present our novel model checking algorithm \emph{Transitive Relation
Learning} (TRL) in detail, see \Cref{alg}.
%
Here and in the following, for all
$i,j \in \NN_+ = \NN \setminus \{0\}$
%JG added definition of N_+
we define $\mu_{i,j}(x') \Def \ind{x}{i+j}$ if $x' \in \vec{x}'$ and $\mu_{i,j}(x) \Def \ind{x}{i}$, otherwise.
%
So in particular, we have $\mu_{i,j}(\vec{x}) = \ind{\vec{x}}{i}$ and $\mu_{i,j}(\vec{x}') = \ind{\vec{x}}{i+j}$, where we assume that $\ind{\vec{x}}{1},\ind{\vec{x}}{2}, \ldots \in \VV^d$ are disjoint vectors of pairwise different fresh variables.
%
Intuitively, the variables $\ind{\vec{x}}{i}$ represent the $i^{th}$ state in a run, and applying $\mu_{i,j}$ to a relational formula yields a formula that relates the $i^{th}$ and the $(i+j)^{th}$ state of a run.
%
For convenience, we define $\mu_{i} \Def \mu_{i,1}$ for all $i \in \NN$, i.e., $\mu_i(\vec{x}) = \ind{\vec{x}}{i}$ and $\mu_i(\vec{x}') = \ind{\vec{x}}{i+1}$.
%
As in SMT-based BMC, TRL uses an incremental SMT solver to unroll the transition relation step by step (\Cref{alg:unroll}), but in contrast to BMC, TRL infers \emph{learned relations} on the fly (\Cref{alg:learn2}).
%
The \emph{input formula} $\tau$ as well as all learned relations are stored in $\vec{\pi}$.
%
Before each unrolling, we set a backtracking point with the command $\push$ and add a suitably variable-renamed version of the description of the error states to the SMT problem in \Cref{alg:err1}.
%
Then the command $\checksat$ checks for reachability of error states, and the command $\pop$ removes all formulas from the SMT problem that have been added since the last invocation of $\push$ (\Cref{alg:err2}), i.e., it removes the encoding of the error states (unless the check succeeds, so that TRL fails).
%
For each unrolling, suitably variable renamed variants of $\vec{\pi}$'s elements are added to the underlying SMT problem with the command $\add$ in \Cref{alg:unroll}.
%
If no error state is reachable after $b-1$ steps, but the transition relation cannot be
unrolled $b$ times (i.e., the SMT problem that corresponds to the $b$-fold unrolling is
unsatisfiable), then the diameter of the analyzed system (including learned relations) has
been reached, and hence safety has been proven (\Cref{alg:safe}).

The remainder of this section is structured as follows:
%
First, \Cref{sec:basics} introduces \emph{conjunctive variable projections} that are used to
compute the \emph{trace} (\Cref{alg:trace} of \Cref{alg}).
%
Next, \Cref{sec:loops} defines \emph{loops} and
discusses how to find \emph{non-redundant loops} that are suitable for learning new relations (\Cref{alg:loop,alg:model,alg:redundant,alg:learn1}).
%
Then, \Cref{sec:transitiveProjections} introduces \emph{transitive projections}
that are used to learn relations (\Cref{alg:trans,alg:learn2}).
% FF that sounds weird, I think
%, and discuss their transitivity (see \Cref{alg:trans}).
%JG ok
\report{Afterwards}\paper{Finally}, \Cref{sec:block} presents
\emph{blocking clauses}, which ensure that learned re\-la\-tions are preferred over other (sequences of) transitions
% needed for \Cref{alg:block1}, \ref{alg:safe}, and
(\Cref{alg:block1,alg:pick,alg:block2,alg:backtrack}).
\report{Finally, we illustrate \Cref{alg} with
a complete example in \Cref{sec:example}.}

\begin{algorithm}[t]
  $b \gets 0; \quad \vec{\pi} \gets [\tau]; \quad \blocked \gets \emptyset$\; \label{alg:init}
  $\add(\mu_{1}(\psi_\init))$ \tcp*{encode the initial states}
  \While(\tcp*[f]{main loop}){$\top$}{
    $b\increment; \quad \push(); \quad \add(\mu_{b}(\psi_\err))$ \tcp*{encode the error states} \label{alg:err1}
    \leIf{$\checksat()$}{
      \Return{$\unknown$} \label{alg:err2}
    }{
      $\pop()$ \tcp*[f]{check their reachability\hspace{-.9em}}
    }
    $\push()$ \tcp*{add backtracking point}
    \lIf(\tcp*[f]{encode transitivity}){$b>1$}{$\add(\ind[\id]{x}{b} \doteq 1 \lor
      \ind[\id]{x}{b} \not\doteq \ind[\id]{x}{b-1})$} \label{alg:trans}
    $\add(\mu_{b}(\bigvee_{n=1}^{|\vec{\pi}|} (\pi_n \land x_\id \doteq n)))$ \tcp*{encode
      $\to_\tau$ and learned relations} \label{alg:unroll}
    $\add(\bigwedge_{(b,\pi) \in \blocked} \pi)$ \tcp*{add blocking clauses for this $b$} \label{alg:block1}
    \lIf{$\neg\checksat()$}{
      \Return{$\safe$} \label{alg:safe} \tcp*[f]{check if the search space is exhausted}}
    $\sigma \gets \getmodel(); \quad \vec{\tau} \gets \trace_b(\sigma,\vec{\pi})$ \label{alg:trace} \tcp*{build trace from current model}
    \If(\tcp*[f]{search loop}){$[\tau_s,\ldots,\tau_{s+\ell-1}]$ is a loop \label{alg:loop}}{
      $\sigma_{\Loop} \gets [x / \sigma(\mu_{s,\ell}(x)) \mid x \in \vec{x} \cup \vec{x}']$ \label{alg:model}\tcp*{build the valuation for the loop}
      \If(\tcp*[f]{redundancy check}){no $\pi \in \tail(\vec{\pi})$ is consistent with $\sigma_{\Loop}$ \label{alg:redundant}}{
        $\tau_{\Loop} \gets \mu_{s,\ell}^{-1}(\bigwedge_{i=s}^{s+\ell-1} \mu_{i}(\tau_i))$ \label{alg:learn1} \tcp*{build the loop}
        $\vec{\pi} \gets \vec{\pi}\concat\tip(\tau_{\Loop}, \sigma \circ \mu_{s,\ell})$ \label{alg:learn2} \tcp*[f]{learn relation}
      }
      $\text{let } \pi \in \tail(\vec{\pi}) \text{ and } \overline{\sigma} \supseteq
      \sigma_{\Loop}$ s.t.\ $\overline{\sigma} \models
\pi$ \tcp*{pick suitable learned rel.} \label{alg:pick}
      $\blocked.\add(s+\ell-1,\blockingclause(s,\ell,\pi,\overline{\sigma}))$ \tcp*{block the loop} \label{alg:block2}
      \lWhile{$b > s$}{$\{ \, \pop(); \ b\decrement \,\}$ \tcp*[f]{backtrack to the start of the loop}\label{alg:backtrack}}
    }
  }
  \caption{TRL -- Input: a safety problem $\TT = (\psi_\init,\tau,\psi_\err)$}
  \label{alg}
\end{algorithm}

\subsection{Conjunctive Variable Projections and Traces}
\label{sec:basics}

To decide when to learn a new relation, TRL inspects the \emph{trace} (Lines \ref{alg:trace} and \ref{alg:loop}).
%
The trace is a sequence of transitions induced by the formulas that have been added to the SMT problem while unrolling the transition relation, and by the current model (\Cref{alg:trace}).
%
To compute them,  we use \emph{conjunctive variable projections}, which are like
\emph{model based projections} \cite{spacer}, but always 
yield\paper{ \pagebreak[3]} conjunctions.%
%
\begin{definition}[Conjunctive Variable Projection]
  \label{def:projections}
  A function $\mbip$ is called a \emph{conjunctive variable projection} if

  \vspace{-0.5em}
  \noindent
  \begin{minipage}[t]{0.49\textwidth}
    \begin{enumerate}
    \item $\sigma \models \mbip(\tau,\sigma,X)$,
    \item $\mbip(\tau,\sigma,X) \models \tau$,
    \item $\{\mbip(\tau,\theta,X) \mid \theta \models \tau\}$ is finite,
    \end{enumerate}
  \end{minipage}
  \begin{minipage}[t]{0.49\textwidth}
    \begin{enumerate}
      \setcounter{enumi}{3}
    \item $\VV(\mbip(\tau,\sigma,X)) \subseteq X \cap \VV(\tau)$, and
    \item $\mbip(\tau,\sigma,X) \in \QF_\land(\Sigma)$
    \end{enumerate}
  \end{minipage}
  \medskip

  \noindent
  for all $\tau \in \QF(\Sigma)$, $X \subseteq \VV$, and $\sigma \models
  \tau$.
  %
  We abbreviate $\mbip(\tau,\sigma,\vec{x} \cup \vec{x}')$ by $\mbip(\tau,\sigma)$.
\end{definition}
%
So like model based projection, $\mbip$ under-approximates quantifier elimination by projecting to the variables $X$ (by (2) and (4)).
%
To do so, it implicitly performs a finite case analysis (by (3)), which is driven by
the model $\sigma$ (by (1)).
%
In contrast to model based projections, $\mbip$ always yields conjunctions (by (5)).
%
% FF I think the following remark does not make much sense with the new version of (4):
% "Note that by (1) and (4), $\mbip(\tau,\sigma,X)$ only contains variables from $\dom(\sigma) \cap X\cap \VV(\tau)$."
% The reason is that we explicitly say $\VV(\mbip(\tau,\sigma,X)) \subseteq X \cap \VV(\tau)$, and we have $\VV(\tau) \subseteq \dom(\sigma)$ by definition of $\models$.
% Hence, this remark is equivalent to (4).
%JG The purpose of this remark was to remind the reader that (1) implies
%$\VV(\mbip(\tau,\sigma,X)) \subseteq \dom(\sigma)$. This is due to our definition of
%$\models$ which is not the standard one in logic. Thus, I added this part of the remark again.
Note that by (1),
$\mbip(\tau,\sigma,X)$ may only contain variables from $\dom(\sigma)$.


\begin{remark}[$\mbip$ and $\mathsf{mbp}$]
  Conjunctive variable projections are obtained by combining a model based projection $\mathsf{mbp}$ (which satisfies \Cref{def:projections} (1--4)) with \emph{syntactic implicant projection} $\sip$ \cite{adcl}, where $\sip(\tau,\sigma)$ is the conjunction of all literals of $\tau$'s negation normal form that are satisfied by $\sigma$.
  %
  Then $\mbip(\tau,\sigma) \Def \sip(\mathsf{mbp}(\tau,\sigma),\sigma)$.
\end{remark}
%
\begin{remark}[$\mbip$ and Quantifier Elimination]
  \Cref{def:projections} (1--3) imply
  \begin{align*}
        \exists \vec{y}.\ \tau & {} \equiv \bigvee \{\mbp(\tau,\sigma) \mid \sigma \models \tau\} \label{mbp-property} \qquad \text{where $\vec{y}$ are $\tau$'s extra variables.}
\end{align*}
So $\mbp$ yields a quantifier elimination procedure $\mathsf{qe}$ which maps $\exists
\vec{y}.\ \tau$ to $\mathit{res}$:
%JG added argument of qe. This shows that this is the same argument that is used for qe
%four lines later.

\report{\vspace{-1.6em}}


\algorithmstyle{plain}
\begin{algorithm}[h!]
\nonl $\mathit{res} \gets \bot;\hspace{.75em}$ \lWhile{$\tau$ has a model $\sigma$}{$\{\mathit{res} \gets \mathit{res} \lor \mbp(\tau,\sigma);\hspace{.75em} \tau \gets \tau \land \neg \mbp(\tau,\sigma)\}$}
\end{algorithm}

\paper{\vspace{-.2em}}
\report{\vspace{-2em}}

\noindent
But for a single model $\sigma$, $\mbp(\tau,\sigma)$ under-ap\-prox\-i\-mates quantifier elimination.
\end{remark}
%
The details of implementing $\mbip$ are beyond the scope of this paper.
%
A good intuition\paper{ \pagebreak[3]} is that $\mbip(\tau,\sigma)$ just computes one disjunct of $\mathsf{qe}(\exists \vec{y}.\ \tau)$ which is satisfied by $\sigma$.
%
However, like model based projection, $\mbip$ can be implemented efficiently for many theories with effective, but very expensive quantifier elimination procedures.%
%
\begin{example}[$\mbip$]
  \label{ex:projections}
  Consider the following formula $\ind{\tau}{1 \twodots 3}$:
  \small
  \[
    \begin{array}{rcl}
      (w \doteq 0 \land \ind{x}{2} \doteq x + 1 \land \ind{y}{2} \doteq y + 1) & \lor & (\ind{w}{2} \doteq w \land w \doteq 1 \land \ind{x}{2} \doteq x - 1 \land \ind{y}{2} \doteq y - 1) \land {} \\
      (\ind{w}{2} \doteq 0 \land x' \doteq \ind{x}{2} + 1 \land y' \doteq \ind{y}{2} + 1) & \lor & (w' \doteq \ind{w}{2} \land \ind{w}{2} \doteq 1 \land x' \doteq \ind{x}{2} - 1 \land y' \doteq \ind{y}{2} - 1)
    \end{array}
  \]
  \normalsize It encodes two steps with \Cref{ex:ex1},
  where $\ind{\vec{x}}{2} = [\ind{w}{2},\ind{x}{2},\ind{y}{2}]$ represents the values after one
  step.
  In \Cref{alg:trace}, \Cref{alg} might find a run like $\sigma(\ind{\vec{x}}{1}) \to_\tau \sigma(\ind{\vec{x}}{2}) \to_\tau \sigma(\ind{\vec{x}}{3})$ for
  \[
  \begin{array}{rcl@{\;\;}l@{\;\;}l}
  \sigma & \Def  & [\ind{w}{1}/\ind{x}{1}/\ind{y}{1}/0, & \ind{w}{2}/\ind{x}{2}/\ind{y}{2}/1, & \ind{w}{3}/1,\ind{x}{3}/\ind{y}{3}/0].
  \end{array}
  \]
 Here, $[w/x/y/c, \ldots]$ abbreviates $[w/c, x/c, y/c, \ldots]$.
  %
  Then the variable renaming $\mu_{1,2}$ allows us to
instantiate the pre- and post-variables
by the first and last state,
resulting in the following model of
$\ind{\tau}{1 \twodots 3}$:
  %
   \[
    \sigma' \Def \sigma \circ \mu_{1,2} = \sigma \cup [w/x/y/0,\;\; w'/1,x'/y'/0] \qquad \text{where } (\sigma \circ \mu_{1,2})(x) = \sigma(\mu_{1,2}(x))
  \]
  %
  To get rid of $\ind{w}{2},\ind{x}{2},\ind{y}{2}$, one could compute $\mathsf{qe}(\exists \ind{w}{2},\ind{x}{2},\ind{y}{2}.\ \ind{\tau}{1 \twodots 3})$, resulting in:
  \begin{align}
    & w \doteq 0 \land w' \doteq 0 \land x' \doteq x+2 \land y' \doteq y+2 \tag{\ensuremath{\inc}} \\
    {} \lor {} & w \doteq 0 \land w' \doteq 1 \land x' \doteq x \land y' \doteq y \label{eq:mbp-ex} \tag{\ensuremath{\mathsf{eq}}}\\
    {} \lor {} &w \doteq 1 \land w' \doteq 1 \land x' \doteq x-2 \land y' \doteq y-2. \tag{\ensuremath{\dec}}
  \end{align}
  Instead, we may have $\mbp(\ind{\tau}{1 \twodots 3},\sigma') = \eqref{eq:mbp-ex}$, as
  $\sigma' \models \eqref{eq:mbp-ex}$.
  %JG Changed  $\sigma \models
   % \eqref{eq:mbp-ex}$ to $\sigma' \models
   % \eqref{eq:mbp-ex}$.
\end{example}
%
Intuitively, a relational formula $\tau$ describes how states can change, so it is composed of many different cases.
%
These cases may be given explicitly (by disjunctions) or implicitly (by
extra variables, which express non-determinism).
%
Given a model $\sigma$ of $\tau$ that describes a \emph{concrete} change of state, $\mbip$ computes a description of the corresponding case.
%
Computing \emph{all} cases amounts to eliminating all extra variables and converting the result to DNF, which is impractical.

When unrolling the transition relation in \Cref{alg:unroll} of \Cref{alg}, we identify
each relational formula $\pi_n$ with its index $n$ in the sequence $\vec{\pi}$.
%
To this end, we use a fresh variable $x_\id$, and our SMT encoding forces
$\ind[\id]{x}{i}$ to be the identifier of the relation that is used for the $i^{th}$ step.
%
Similarly to \cite{abmc}, the \emph{trace} is the sequence of transitions that results from applying $\mbip$ to the unrolling
of the transition relation that is constructed by \Cref{alg} in \Cref{alg:unroll}.
%
So a trace is a sequence of transitions that can be applied subsequently, starting in an initial state.
%
\begin{definition}[Trace]
  \label{def:trace}
  Let $\vec{\pi}$ be a sequence of relational formulas, let
  \begin{align}
    \label{eq:trace}
    \paper{\textstyle}
    \sigma \models \bigwedge_{i=1}^{b} \mu_{i}\left(\bigvee_{n=1}^{|\vec{\pi}|} (\pi_n \land x_\id \doteq n)\right) \qquad \text{where $b \in \NN_+$},
  \end{align}
  and let $\id(i) \Def \sigma(\ind[\id]{x}{i})$.
  %
  Then the \emph{trace induced by $\sigma$} is
  \[
    \trace_b(\sigma,\vec{\pi}) \Def [\mbip(\pi_{\id(i)}, \sigma \circ \mu_{i})]_{i=1}^{b}.
  \]
\end{definition}

Recall that $\mu_i$ renames $\vec{x}$ and $\vec{x}'$ into $\ind{\vec{x}}{i}$ and
$\ind{\vec{x}}{i+1}$, and $\id(i) = \sigma(\ind[\id]{x}{i})$ is the index of the
relation from $\vec{\pi}$ that is used for the $i^{th}$ step.\comment[NONE]{FF If
  we have this remark here, then we should remove the similar remark ``i.e.,
  $\mu_i(\vec{x}) = \ind{\vec{x}}{i}$
  and $\mu_i(\vec{x}') =\ind{\vec{x}}{i+1}$.\\
  JG Ok, but only if it at least saves a line. Otherwise, we can just as well keep the
  remark there as well.}
%
So each model $\sigma$ of \eqref{eq:trace} corresponds to a run $\sigma(\mu_1(\vec{x}))
\to_{\pi_{\id(1)}} \ldots \to_{\pi_{\id(b)}} \sigma(\mu_{b}(\vec{x}'))$,\paper{ \pagebreak[3]} and the trace
induced by $\sigma$ contains the transitions that were used in this run.

%
\begin{example}[Trace]
  \label{ex:trace}
  Consider the extension of $\sigma$ from \Cref{ex:projections} with $[\ind[\id]{x}{1}/1,\;
    \ind[\id]{x}{2}/1]$:
  \[
  \sigma \Def [\ind{w}{1}/\ind{x}{1}/\ind{y}{1}/0,\ind[\id]{x}{1}/1, \quad
    \ind{w}{2}/\ind{x}{2}/\ind{y}{2}/\ind[\id]{x}{2}/1, \quad \ind{w}{3}/1,\ind{x}{3}/\ind{y}{3}/0],
  \]
  Thus, $\id(1) = \sigma(\ind[\id]{x}{1}) = 1$, $\id(2) =  \sigma(\ind[\id]{x}{2}) = 1$, and
  $\pi_{\id(1)} = \pi_{\id(2)} =
  \pi_1 = \tau$.
  %
  Then
  \begin{align*}
    & \trace_2(\sigma, [\tau,\tau]) = [\mbip(\tau,\sigma \circ \mu_{1}), \mbip(\tau,\sigma \circ \mu_{2})]           \\
    {} = {} & [\mbip(\tau,[w/x/y/0, \; w'/x'/y'/1]), \mbip(\tau,[w/x/y/1, \; w'/1,x'/y'/0])] = [\tau_\inc, \tau_\dec].
  \end{align*}
\end{example}

\subsection{Loops}
\label{sec:loops}

As $\vec{\pi}$ only gives rise to finitely many transitions, the trace is bound to contain \emph{loops}, eventually (unless \Cref{alg} terminates beforehand).
%
\begin{definition}[Loop]
  A sequence of transitions $\tau_1,\ldots,\tau_k$ is called a \emph{loop} if there are $\vec{v}_0,\ldots,\vec{v}_{k+1} \in \CC^d$ such that $\vec{v}_0 \to_{\tau_1} \ldots \to_{\tau_k} \vec{v}_{k} \to_{\tau_1} \vec{v}_{k + 1}$.
\end{definition}
%
Intuitively, these loops are the reason why BMC may diverge.
%
To prevent divergence, TRL learns a new relation when a loop is detected (\Cref{alg:loop}).
%
\begin{remark}[Finding Loops]
  Loops can be detected by SMT solving.
  %JG I think that it is not correct to say that something is detected by "SMT". I think
  %it should be "SMT solving".
%
A cheaper way is to look for duplicates, but then loops are found ``later'', as
%
a trace $[\ldots, \pi, \pi, \ldots]$\linebreak is needed to detect a loop $\pi$, but one occurrence of $\pi$ is insufficient.
%
As a trade-off between precision and efficiency, our im\-ple\-men\-ta\-tion uses \emph{dependency graphs} \cite{abmc}.
\end{remark}

\begin{remark}[Disregarding ``Learned'' Loops]
  \label{remark:loops}
    One should disregard ``loops'' consisting of a single \emph{learned transition}, i.e., a transition that results from applying $\mbip$ to some $\pi \in \tail(\vec{\pi})$.
    %
    Here, $\tail(\tau\concat\vec{\pi}') \Def \vec{\pi}'$ contains all learned relations, as the first element of $\vec{\pi}$ is the input formula $\tau$.
    %
    The reason is that our goal is to deduce transitive relations, but learned relations are already transitive.
    %
    In the sequel, we assume that the check in \Cref{alg:loop} fails for such loops.
\end{remark}
%
If there are several choices for $s$ and $\ell$ in \Cref{alg:loop}, then our implementation only considers loops of minimal length and, among those, it minimizes $s$.
%
\begin{example}[Detecting Loops]
  \label{ex:loops}
  Consider the model
  \[
    \sigma \Def [\ind{w}{1}/\ind{x}{1}/\ind{y}{1}/0, \ind[\id]{x}{1}/1, \quad \ind{w}{2}/0,\ind{x}{2}/\ind{y}{2}/1]
  \]
  %
for $\tau$ from our running example (\Cref{ex:ex1}).
   Then $\trace_1(\sigma, [\tau]) = [\tau_\inc]$.
  %
  As $\tau_\inc$ is a loop, TRL learns a relation like $\tau^+_{\inc}$ at this point.
\end{example}
%
TRL only learns relations from loops that are \emph{non-redundant} w.r.t.\ all relations that have been learned before \cite{adcl}.
%
\begin{definition}[Redundancy]
  \label{def:redundancy}
  If ${\to_\tau} \subseteq {\to_{\tau'}}$, then $\tau$ is \emph{redundant} w.r.t.\ $\tau'$.
\end{definition}
% FF I think it's fine to omit the title of examples if they are directly preceded by the
% corresponding definition
% JG ok
\begin{example}
  The relation $\tau_\inc$ is redundant w.r.t.\ $\tau^+_\inc$, but $\tau_\dec$ is not.
\end{example}
%
\Cref{alg:redundant} uses a sufficient criterion for non-redundancy:
%
If all learned relations are falsified by the values before and after the loop, then
$\tau_s, \ldots, \tau_{s + \ell -1}$ cannot be simulated by a previously learned relation, so it is non-redundant and we learn a new relation.
%
The values before and after the loop are obtained from the current model $\sigma$ by
setting $\vec{x}$ to $\sigma(\ind{\vec{x}}{s})$ and $\vec{x}'$ to
$\sigma(\ind{\vec{x}}{s+\ell})$, i.e., we use $\sigma \circ \mu_{s,\ell}$ in
\Cref{alg:model}.

To learn a new relation,
we first compute the  relation\paper{ \pagebreak[3]} 
\begin{equation}
  \label{eq:loop-formula}
  \paper{\textstyle}
  \tau_\Loop \Def \mu_{s,\ell}^{-1}(\phi_\Loop) \qquad \text{where} \qquad \phi_\Loop \Def
  \bigwedge_{i=s}^{s+\ell-1} \mu_{i}(\tau_i) 
\end{equation}
of the loop in \Cref{alg:learn1}, where $\mu^{-1}_{s,\ell}$ is the inverse of $\mu_{s,\ell}$.
%
So in \Cref{ex:loops}, we have $\sigma \circ \mu_{1,1} \supseteq [w/x/y/0,\,
  w'/0,x'/y'/1]$ and $\tau_\Loop \Def \mu^{-1}_{1,1}(\mu_1(\tau_\inc)) = \tau_\inc$ as $s = \ell = 1$.
%
So $\sigma \circ \mu_{s,\ell}$ indeed corresponds to one evaluation of the loop, as $\sigma \circ \mu_{s,\ell} \models \tau_\Loop$.

To see that $\tau_\Loop$ is also the desired relation in general, note that $\phi_\Loop$ is the conjunction of the transitions that constitute the loop, where all variables are renamed as in \Cref{alg:unroll} of \Cref{alg}, i.e., in such a way that the post-variables of the $i^{th}$ step are equal to the pre-variables of the $(i+1)^{th}$ step.
%
So we have $\sigma \models \phi_\Loop$ and thus $\sigma \circ \mu_{s,\ell} \models \tau_\Loop$.
%
Hence,
we can use $\tau_\Loop$ and $\sigma \circ \mu_{s,\ell}$ to learn a new relation via
so-called \emph{transitive projections}
in \Cref{alg:learn2}.


\subsection{Transitive Projections}
\label{sec:transitiveProjections}



We now define \emph{transitive projections} that approximate transitive closures of loops.
%
As explained in \Cref{sec:overview}, we do not restrict ourselves to under- or over-approximations, but we allow ``mixtures'' of both.
%
Analogously to $\mbip$, transitive projections perform a finite case analysis that is
driven by the provided model $\sigma$.

\begin{definition}[Transitive Projection]
  \label{def:ti}
  A function $\tip$ is called a \emph{transitive projection}
  if the following holds for all transitions $\tau \in \QF(\Sigma)$ and all $\sigma \models \tau$:
  \begin{minipage}[t]{0.49\textwidth}
    \begin{enumerate}
    \item $\tip(\tau,\sigma)$ is consistent with $\sigma$
    \item $\{\tip(\tau,\theta) \mid \theta \models \tau\}$ is finite
    \end{enumerate}
  \end{minipage}
  \begin{minipage}[t]{0.49\textwidth}
    \begin{enumerate}
      \setcounter{enumi}{2}
    \item $\to_{\tip(\tau,\sigma)}$ is transitive
    \end{enumerate}
  \end{minipage}
\end{definition}

\begin{example}
  \label{ex:Transition Invariants}
  For \Cref{ex:ex1}, $\tau_\ti \Def x' - x \doteq y' - y$ over-approximates the transitive
  closure $\to^+_\tau$.
  %
  Such over-approximations are also called \emph{transition invariants} \cite{transition_invariants}.
  %
  With $\tau_\ti$, one can prove safety for any $\psi_\init$ with $\psi_\init \models x \doteq y$, as then $\psi_\init \land \tau_\ti \models x' \doteq y'$, which shows that no error state with $w \doteq 1 \land x \leq 0 \land y > 0$ is reachable.

  By using $\mbip$, TRL instead considers $\tau_\inc$ and $\tau_\dec$ separately and learns
  \begin{align*}
    \tip(\tau_\inc,\sigma_\inc) & {} \Def w \doteq 0 \land x' > x \land x' - x \doteq y' - y                   \tag{$\tau^+_{\inc}$} \\
    \tip(\tau_\dec,\sigma_\dec) & {} \Def w' \doteq w \land w \doteq 1 \land x' < x \land x' - x \doteq y' - y \tag{$\tau^+_{\dec}$}
  \end{align*}
  if $\sigma_\inc \models \tau_\inc$ and $\sigma_\dec \models \tau_\dec$.
  %
  In this way, \Cref{alg} can learn disjunctive relations like $\tau^+_{\inc} \lor \tau^+_{\dec}$, even if $\tip$ only yields conjunctive relational formulas (which is true for our current implementation of $\tip$ -- see \Cref{sec:rec} -- but not enforced by \Cref{def:ti}).
\end{example}
%
In contrast to conjunctive variable projections, $\tip(\tau,\sigma)$ may contain extra variables that do not occur in $\tau$ (which will be exploited in \Cref{sec:rec}).
%
Hence, instead of $\sigma \models \tip(\tau,\sigma)$ we require consistency with $\sigma$, i.e., $\sigma(\tip(\tau,\sigma))$ must be satisfiable.

\begin{remark}[Properties of $\tip$]
  \label{remark:properties-tip}
 Due to \Cref{def:ti} (1), our definition of $\tip$ implies
 \[
  \paper{\textstyle}
  \tau \models \exists \vec{y}. \, \bigvee_{\sigma \models \tau} \tip(\tau,\sigma), \quad \text{and thus,}
  \quad
  {\to_{\tau}} \subseteq \bigcup_{\sigma \models \tau}
  {\to_{\tip(\tau,\sigma)}},
\]
where $\vec{y}$ are the extra variables of $\bigvee_{\sigma \models \tau} \tip(\tau,\sigma)$.
%
However, \Cref{def:ti} does \emph{not} ensure
${\to^+_\tau} \subseteq \bigcup_{\sigma \models \tau}
  {\to_{\tip(\tau,\sigma)}}$.
  %
  So there is no guarantee that $\tip$ covers $\to^+_\tau$ entirely, i.e., $\tip$ cannot be used to compute transition invariants, in general.
  % 
  \Cref{def:ti} does not ensure ${\to^+_\tau} \supseteq \bigcup_{\sigma \models \tau}
  {\to_{\tip(\tau,\sigma)}}$ either, as $\tip(\tau,\sigma)$ does not imply $\sigma(\vec{x}) \to^+_\tau \sigma(\vec{x}')$.
\end{remark}

\begin{example}
  \label{Counterex-tip}
  To see that $\tip$ computes no over- or under-approximations, let
  \[
    \tau \Def x' \doteq x + 1 \land y' \doteq y + x.\paper{\pagebreak[3]}
  \]
  Then for all $\sigma \models \tau$, we might have:
  \[
    \tip(\tau,\sigma) =
    \begin{cases}
      x \geq 0 \land x' > x \land y' \geq y, & \text{if } \sigma(x) \geq 0 \\
      x < 0 \land x' > x \land y' < y,   & \text{if } \sigma(x) < 0
    \end{cases}
  \]
  However, $(x \geq 0 \land x' > x \land y' \geq y) \lor (x < 0 \land x' > x \land y' < y)$ is not an over-approximation of $\to^+_\tau$ (i.e., ${\to^+_\tau} \not\subseteq \bigcup_{\sigma \models \tau}
    {\to_{\tip(\tau,\sigma)}}$), as we have, e.g.,
  \[
    (-1,0) \to_\tau (0,-1) \to_\tau (1,-1) \to_\tau (2,0), \qquad \text{but} \qquad (-1,0) \not\to_{\tip(\tau,\sigma)} (2,0)
  \]
  for all $\sigma \models \tau$.
  % 
  Moreover, we also have ${\to^+_\tau} \not\supseteq \bigcup_{\sigma \models \tau} {\to_{\tip(\tau,\sigma)}}$, since
  \[
    (-1,0) \to_{\tip(\tau,\sigma)} (10,-20), \qquad \text{but} \qquad (-1,0) \not\to^+_\tau (10,-20)
  \]
  if $\sigma(x) < 0$.
  %
  In contrast to $\tip(\tau, \sigma)$, linear over-approximations for $\to^+_\tau$ like $x' > x$
  cannot distinguish whether $y$ increases or decreases.
\end{example}

As TRL proves safety via \emph{blocking clauses} (\Cref{sec:block}) that only block steps that are cov\-er\-ed by learned relations, the fact that $\tip$ does not yield over-ap\-prox\-i\-ma\-tions does not affect soundness.
%
However, it may cause divergence (\Cref{remark:termination}).

Recall that our SMT encoding forces $\ind[\id]{x}{i}$ to be the identifier of the relation that\linebreak is used for the $i^{th}$ step (\Cref{alg:unroll}).
%
To exploit transitivity of $\tip$, we add the constraint
$\ind[\id]{x}{b} \doteq 1 \lor \ind[\id]{x}{b} \not\doteq \ind[\id]{x}{b-1}$ in
\Cref{alg:trans}, so that learned relations (with an index $>1$) are not used several times in a row, since this is unnecessary for transitive relations.

Clearly, the specifics of $\tip$ depend on the underlying theory.
%
Our implementation for quantifier-free linear integer arithmetic will be explained in \Cref{sec:rec}.


\subsection{Blocking Clauses}
\label{sec:block}

In \Cref{alg:pick}, we are guaranteed to find a learned relation $\pi$ which is consistent
with $\sigma_\Loop$: If our sufficient criterion for non-redundancy in
\Cref{alg:redundant} failed, then the existence of $\pi$ is guaranteed.
%
Otherwise, we learned a new relation $\pi$ in \Cref{alg:learn2} which is consistent with $\sigma_\Loop \subseteq \sigma \circ \mu_{s,\ell}$ by definition of $\tip$.
%
Thus, we can use $\pi$ and a model $\overline{\sigma} \supseteq \sigma_\Loop$ of $\pi$ to record a \emph{blocking clause} in \Cref{alg:block2}.
%
\begin{definition}[Blocking Clauses]
  \label{def:blocking}
  We define:
  \[
    \blockingclause(s,\ell,\pi,\overline{\sigma}) \Def
    \begin{cases}
      \mu_{s,\ell}(\neg \mbip(\pi, \overline{\sigma})) \lor \ind[\id]{x}{s} > 1, & \text{if } \ell = 1 \\
      \mu_{s,\ell}(\neg \mbip(\pi, \overline{\sigma})),                         & \text{if } \ell > 1
    \end{cases}
  \]
\end{definition}
%
Here, $s$ and $\ell$ are natural numbers such that $[\tau_i]_{i=s}^{s+\ell-1}$ is a (possibly) redundant loop on the trace.
%
Blocking clauses exclude models that correspond to runs
\begin{equation}
  \label{blockedRun}
  \vec{v}_1 \to_{\tau_1} \ldots \to_{\tau_{s-1}} \vec{v}_s \to_{\tau_{s}} \ldots \to_{\tau_{s+\ell-1}} \vec{v}_{s+\ell}
\end{equation}
where $\vec{v}_{s} \to_{\pi} \vec{v}_{s+\ell}$. Intuitively, if $\ell = 1$ then
$\blockingclause(s,\ell,\pi,\overline{\sigma})$ states that one may still evaluate 
$\vec{v}_s$ to
$\vec{v}_{s+\ell}$, but one has to use a learned transition. If $\ell > 1$, then
$\blockingclause(s,\ell,\pi,\overline{\sigma})$
states that one may still  evaluate 
$\vec{v}_s$ to
$\vec{v}_{s+\ell}$, but not in $\ell$ steps.
More precisely, 
blocking clauses take into account that%

\vspace{-0.8em}
\noindent
\begin{minipage}{0.44\textwidth}
  \begin{equation}
    \label{prefix}
    \vec{v}_1 \to_{\tau_1} \ldots \to_{\tau_{s+\ell-2}} \vec{v}_{s+\ell-1}
  \end{equation}
\end{minipage}
\begin{minipage}{0.1\textwidth}
  \begin{equation*}
    \text{and}
  \end{equation*}
\end{minipage}
\begin{minipage}{0.44\textwidth}
  \begin{equation}
    \label{unblockedRun}
    \vec{v}_1 \to_{\tau_1} \ldots \to_{\tau_{s-1}} \vec{v}_s \to_{\pi} \vec{v}_{s+\ell}
  \end{equation}
\end{minipage}

\medskip
\noindent
must not be blocked to ensure that $\vec{v}_2,\ldots,\vec{v}_{s+\ell}$ remain reachable.
%
For the former, note that blocking clauses affect the suffix $\vec{v}_{s} \to_{\tau_s} \ldots \to_{\tau_{s+\ell-1}} \vec{v}_{s+\ell}$ of \eqref{blockedRun} (as they contain $\mu_{s,\ell}(\neg \mbip(\pi, \overline{\sigma}))$), but not \eqref{prefix}, so $\vec{v}_{2},\ldots,\vec{v}_{s+\ell-1}$ remain reachable.

Regarding \eqref{unblockedRun},\paper{ \pagebreak[3]} first consider the case $\ell > 1$.
%
Then \eqref{unblockedRun} is not affected by the blocking clause, as it requires less than $s+\ell$ steps.
%
If $\ell = 1$, then the loop that needs to be blocked is a single \emph{original transition} (i.e., a transition that results from applying $\mbip$ to $\tau$) due to \Cref{remark:loops}.
%
So $\ind[\id]{x}{s} > 1$ is falsified by \eqref{blockedRun}, as $\tau_s$ is an original transition, i.e., using it for the $s^{th}$ step implies $\ind[\id]{x}{s} \doteq 1$.
%
However, $\ind[\id]{x}{s} > 1$ is satisfied by \eqref{unblockedRun}, as $\pi$ is a learned
transition, so using it implies
$\ind[\id]{x}{s} > 1$.

\begin{remark}[Extra Variables and Negation]
In \Cref{def:blocking}, $\mbip$ is used to project $\pi$ according to the model $\overline{\sigma}$.
%
In this way, negation has the intended effect, i.e., 
\[
  [\vec{x}/\vec{v},\vec{x}'/\vec{v}'] \models \neg\mbip(\ldots) \qquad \text{iff} \qquad \vec{v} \not\to_{\mbip(\ldots)} \vec{v}',
\]
as $\mbip(\ldots)$ has no extra variables.
%
To see why this is important here, consider the relation $\tau \Def n > 0 \land x' \doteq x + n$, where $n$ is an extra variable.
%
Then $0 \to_\tau 1$, but
\[
  \neg\tau[x/0,x'/1] = (n \leq 0 \lor x' \not\doteq x + n)[x/0,x'/1] = n \leq 0 \lor 1 \not\doteq n
\]
is satisfiable, so $\neg\tau$ is not a suitable characterization of $\not\to_\tau$.
%
The reason is that $n$ is implicitly existentially quantified in $\tau$.
%
So to characterize $\not\to_\tau$, we have to negate $\exists n.\ \tau$ instead of $\tau$, resulting in $\forall n.\ n \leq 0 \lor x' \not\doteq x + n$.
%
Then, as desired,
\[
  (\forall n.\ n \leq 0 \lor x' \not\doteq x + n)[x/0,x'/1] = \forall n.\ n \leq 0 \lor 1 \not\doteq n
\]
is invalid.
%
To avoid quantifiers, we eliminate extra variables via $\mbip$ instead.
\end{remark}

In \Cref{alg:block2}, a pair consisting of $s + \ell - 1$ and the blocking clause is added to $\blocked$.
%
The first component means that the blocking clause has to be added to the SMT encoding when the transition relation is unrolled for the $(s+\ell-1)^{th}$ time, i.e., when $b = s + \ell - 1$.
%
So blocking clauses are added to the SMT encoding ``on demand'' (in \Cref{alg:block1}) to block
loops that have been found on the trace at some point.
%
Afterwards, TRL backtracks to the last step before the loop in \Cref{alg:backtrack}.

\begin{remark}[Adding Blocking Clauses]
To see why blocking clauses must only be added to the SMT encoding
in the $(s+\ell-1)^{th}$ unrolling, assume $\pi \equiv \top$.
%
Then, e.g., $\blockingclause(1,2,\pi,\overline{\sigma}) \equiv \bot$.
%
This means that unrolling the transition relation twice is superfluous, as every state can be reached in a single step with $\pi$, so the diameter is $1$.
%
But after learning $\pi$ when $b=2$ and backtracking to $b=0$, adding such a blocking clause too early (e.g., before the first unrolling of the transition relation) would \emph{immediately} result in an unsatisfiable SMT problem.
\end{remark}


\begin{example}[Blocking Redundant Loops]
  \label{ex:redundant}
  Consider the model
  \[
    \sigma \Def [\ind{w}{1}/\ind{x}{1}/\ind{y}{1}/0,\ind[\id]{x}{1}/2, \quad
      \ind{w}{2}/0,\ind{x}{2}/\ind{y}{2}/2,\ind[\id]{x}{2}/1, \quad
      \ind{x}{3}/\ind{y}{3}/3]
  \]
  and assume that TRL has already learned the relation $\tau^+_\inc$ (i.e., $\vec{\pi} = [\tau,\tau^+_\inc]$).
  %
  Moreover, assume that the trace is $[\tau^+_\inc,\tau_\inc]$, so that TRL detects the loop $\tau_\inc$.
  %
  To check for non-redundancy, we instantiate the pre- and post-variables in $\tau^+_\inc$ according to $\sigma$, taking the renaming $\mu_{2}$ into account (note that here $s = 2$, $\ell = 1$, and $\mu_{s,\ell} = \mu_{2,1} = \mu_2$):
  \[
    \sigma(\mu_{2}(\tau^+_\inc)) = \tau^+_\inc[w/0,x/y/2,x'/y'/3] \equiv \top.
  \]
  So our sufficient criterion for non-redundancy fails, as $\tau_\inc$ is indeed redundant w.r.t.\ $\tau^+_\inc$.
  %
  Thus, TRL records that the following blocking clause has to be added for the second unrolling (i.e., when $b = s + \ell -1 = 2$).
  \paper{\begin{align*}
            & \mu_{s,\ell}(\neg\mbip(\tau^+_\inc,\overline{\sigma})) \lor \ind[\id]{x}{s}
      > 1 \hspace{.4em} = \hspace{.4em} \mu_{s,\ell}(\neg\tau^+_\inc) \lor \ind[\id]{x}{s}
      > 1 \tag{as $\tau^+_\inc$ is a transition} \end{align*}
    \paper{ \vspace*{-.3cm}\pagebreak[3]}
   \begin{align*}  
   {} = {} & \mu_{2}(\neg (w \doteq 0 \land x' > x \land x' - x \doteq y' - y)) \lor \ind[\id]{x}{2} > 1\\ 
    {} = {} & (w \not\doteq 0 \lor x' \leq x \lor x' - x \not\doteq y' - y)[w/\ind{w}{2}, x/\ind{x}{2},y/\ind{y}{2}, x'/\ind{x}{3},y'/\ind{y}{3}] \lor \ind[\id]{x}{2} > 1 \\
    {} = {} & \ind{w}{2} \not\doteq 0 \lor \ind{x}{3} \leq \ind{x}{2} \lor \ind{x}{3} - \ind{x}{2} \not\doteq \ind{y}{3} - \ind{y}{2} \lor \ind[\id]{x}{2} >1
  \end{align*}}
  \report{\begin{align*}
            & \mu_{s,\ell}(\neg\mbip(\tau^+_\inc,\overline{\sigma})) \lor \ind[\id]{x}{s} > 1 \hspace{.4em} = \hspace{.4em} \mu_{s,\ell}(\neg\tau^+_\inc) \lor \ind[\id]{x}{s} > 1 \tag{as $\tau^+_\inc$ is a transition} \\
    {} = {} & \mu_{2}(\neg (w \doteq 0 \land x' > x \land x' - x \doteq y' - y)) \lor
    \ind[\id]{x}{2} > 1\\
    {} = {} & (w \not\doteq 0 \lor x' \leq x \lor x' - x \not\doteq y' - y)[w/\ind{w}{2}, x/\ind{x}{2},y/\ind{y}{2}, x'/\ind{x}{3},y'/\ind{y}{3}] \lor \ind[\id]{x}{2} > 1 \\
    {} = {} & \ind{w}{2} \not\doteq 0 \lor \ind{x}{3} \leq \ind{x}{2} \lor \ind{x}{3} - \ind{x}{2} \not\doteq \ind{y}{3} - \ind{y}{2} \lor \ind[\id]{x}{2} >1
  \end{align*}}  
  As this blocking clause is falsified by $\sigma$, it prevents TRL from finding the same model again after backtracking in \Cref{alg:backtrack}, so that TRL makes progress.
\end{example}
%
The following theorem states that our approach is sound.
%
%\paper{See \cite{arxiv} for all proofs.}%
%JG I mentioned that in the intro now.
%
\begin{restatable}
  {theorem}{soundness}
  \label{thm:soundness}
  If $\text{TRL}(\TT)$ returns $\safe$, then $\TT$ is safe.
\end{restatable}
\makeproof*{thm:soundness}{
  \soundness*
  \begin{proof}
    Consider the SMT problem that is checked in \Cref{alg:safe}.
    %
    In the $m^{th}$ iteration (starting with $m=1$), this problem is of the form $\varphi(m) \Def$
    \begin{align*}
       & \overbrace{\mu_{1}(\psi_\init)}^{\substack{\text{initial states}                                             \\
      \text{\Cref{alg:init}}}} \land                                                                                                 \\
                      & \overbrace{\bigwedge_{j=1}^{b(m)}}^{\substack{\text{one conjunct}                                          \\
        \text{per step}}}
      \left( \overbrace{(\ind[\id]{x}{j} \doteq 1 \lor \ind[\id]{x}{j} \not\doteq \ind[\id]{x}{j-1})}^{\substack{\text{transitivity} \\
          \text{\Cref{alg:trans}}}}
      \land \overbrace{\bigvee_{i=1}^{\ell'(m)} \mu_{j}(\pi_i \land x_{\id} \doteq i)}^{\substack{\text{transition relation}       \\
          \text{\Cref{alg:unroll}}}} \land \overbrace{\bigwedge_{(j,\pi) \in \blocked(m)}
      \pi}^{\mathclap{\substack{\text{blocking clauses}                                                                              \\
            \text{\Cref{alg:block1}}}}} \right)
    \end{align*}
    where $b(m)$, $\ell'(m)$, and $\blocked(m)$ are the value of $b$, the length of $\vec{\pi}$, and the values of $\blocked$ in \Cref{alg:safe} in the $m^{th}$ iteration, respectively.
    %
    For simplicity, here we use an additional variable $\ind[\id]{x}{0}$ which only occurs in the first transitivity constraint (which is not generated by \Cref{alg}):
    \[
      \ind[\id]{x}{1} \doteq 1 \lor \ind[\id]{x}{1} \not\doteq \ind[\id]{x}{0}
    \]
    Therefore, this constraint is trivially satisfiable (e.g., by setting $\ind[\id]{x}{0}$ to $1$).

    Assume that $\TT$ is unsafe, but \Cref{alg} returns $\safe$.
    %
    Then there is some $k \in \NN$ such that $\varphi(k)$ is unsatisfiable, and $\varphi(k')$ is satisfiable for all $1 \leq k' < k$ (otherwise, \Cref{alg} would have returned $\safe$ in an earlier iteration).

    As \Cref{alg} backtracks in \Cref{alg:backtrack}, we consider the sequence of natural numbers $1 \leq i_1 < \ldots < i_{b(k)} = k$ such that for all $1 \leq c \leq b(k)$, $i_c$ is the last iteration where $b=c$ in \Cref{alg:safe}.
    %
    Then for all $1 \leq B \leq b(k)$, we have $\varphi(i_B) = \phi(B)$ where
    \begin{align*}
      \phi(B) \Def & \mu_{1}(\psi_\init) \land \\
                   & \bigwedge_{j=1}^{B}
      \left( (\ind[\id]{x}{j} \doteq 1 \lor \ind[\id]{x}{j} \not\doteq \ind[\id]{x}{j-1}) \land \bigvee_{i=1}^{\ell(B)}\mu_{j}(\pi_i \land x_{\id} \doteq i) \land \bigwedge_{(j,\pi) \in \blocked(k)} \pi \right).
    \end{align*}
    Here, we have $\ell(B) \Def \ell'(i_B)$.
    %
    A blocking clause $\pi$ is only added to the SMT encoding if $(j,\pi) \in \blocked$ and $b=j$ (see \Cref{alg:block1}) and \Cref{alg} backtracks until $b \leq j$ whenever such an element is added to $\blocked$ (see \Cref{alg:backtrack}).
    %
    So when only considering the iterations $i_1, \ldots, i_{b(k)}$, then $b(i_B) = B$ and all blocking clauses of the form $(j,\pi) \in \blocked(k)$ where $j < B$ are already present when unrolling the transition relation for the $B^{th}$ time, i.e., they are already contained in $\blocked(i_B)$.

    %
    In other words, we have
    \[
      \{(j,\pi) \mid (j,\pi) \in \blocked(k) \mid j < B\} \subseteq \blocked(i_B).
    \]
    Thus, we may use $\blocked(k)$ instead of $\blocked(i_B)$ in the definition of
    $\phi$.

    Let $c \in \NN$ and $\vec{v}_0,\ldots\vec{v}_c \in \CC^d$ be arbitrary but fixed where $[\vec{x}/\vec{v}_0] \models \psi_\init$ and
    %
    \[
      \vec{v}_0 \to_{\tau} \ldots \to_{\tau} \vec{v}_c.
    \]
    %
    We use induction on $c$ to show that\footnote{While $\phi(B)$ only corresponds to a formula that is checked by \Cref{alg} if $B > 0$, $\phi(0) \equiv \mu_1(\psi_\init)$ is well defined, too.}
    \begin{multline}
      \label{eq:goal}
      \forall 0 \leq i \leq c.\ \exists B(i) < b(k), h(0,i) < \ldots < h(B(i),i).\ h(0,i) = 0 \land h(B(i),i) = i\\
      {} \land \phi(B(i)) \text{ is consistent with } [\mu_{j+1}(\vec{x})/\vec{v}_{h(j,i)} \mid 0 \leq j \leq B(i)].
    \end{multline}
    Intuitively, $B(i)$ is the number of steps that are needed to reach $\vec{v}_i$ when also using learned relations, and $\vec{v}_{h(j,i)}$ is the $j^{th}$ state in the resulting run that leads to $\vec{v}_i$.
    %
    Thus, \eqref{eq:goal} shows that for all (arbitrary long) runs that start in a state satifying $\psi_\init$, all states that are reachable with $\to_\tau$ in arbitrarily many steps can also be reached in less than $b(k)$ steps (i.e., in constantly many steps) if one may also use the (transitive) learned relations.
    %
    Of course, this only holds provided that \Cref{alg} returns $\safe$ in the $k^{th}$ iteration.

    Once we have shown \eqref{eq:goal}, we can prove the theorem:
    %
    We had assumed that $\TT$ is unsafe, i.e., that there is a reachable error state $\vec{v}_c$ and that $\varphi(k) = \varphi(i_{b(k)}) = \phi(b(k))$ is unsatisfiable.
    %
    We use \eqref{eq:goal} for $i = c$:
    %
    By \eqref{eq:goal}, there is some $B(c) < b(k)$ such that
    \[
      \phi(B(c)) \text{ is consistent with } [\mu_{j+1}(\vec{x})/\vec{v}_{h(j,c)} \mid 0 \leq j \leq B(c)].
    \]
    Moreover, as $\vec{v}_c$ is an error state, $\psi_\err$ is consistent with $[\vec{x}/\vec{v}_{c}]$ and hence,
    \[
      \mu_{B(c)+1}(\psi_\err) \text{ is consistent with } [\mu_{B(c)+1}(\vec{x})/\vec{v}_{c}] = [\mu_{B(c)+1}(\vec{x})/\vec{v}_{h(B(c),c)}].
    \]
    Thus,
    \[
      \phi(B(c)) \land \mu_{B(c)+1}(\psi_\err) \text{ is consistent with } [\mu_{j+1}(\vec{x})/\vec{v}_{h(j,c)} \mid 0 \leq j \leq B(c)].
    \]
    Hence,
    \begin{equation}
      \label{eq:contradiction}
      \text{\Cref{alg} returns $\unknown$ in \Cref{alg:err2} in iteration $i_{B(c)+1}$}
    \end{equation}
    or earlier.
    %
    The reason is that we have $b = B(c)+1$ in iteration $i_{B(c)+1}$, so in this iteration \Cref{alg} checks satisfiability of the formula $\phi(B(c)) \land \mu_{B(c)+1}(\psi_\err)$ in \Cref{alg:err2}.
    %
    As we have $b(k) > B(c)$, we get $k = i_{b(k)} \geq i_{B(c)+1}$.
    %
    Hence, \eqref{eq:contradiction} contradicts the assumption that \Cref{alg} returns $\safe$ in \Cref{alg:safe} in iteration $k$. 

    We now prove \eqref{eq:goal}. 
    In the induction base, we have
    \begin{align*}
                             & [\vec{x}/\vec{v}_0] \models \psi_\init                                                     \\
      {} \curvearrowright {} & [\mu_{1}(\vec{x})/\vec{v}_0] \models \mu_{1}(\psi_\init)                                   \\
      {} \curvearrowright {} & [\mu_{1}(\vec{x})/\vec{v}_0] \models \phi(0) \tag{as $\phi(0) \equiv \mu_{1}(\psi_\init)$}
    \end{align*}
    Hence, the claim follows for
    \[
      B(0) = 0 = h(0,0).
    \]
    In the induction step, the induction hypothesis implies
    \begin{multline}
      \label{eq:IH}
      \forall 0 \leq i < c.\ \exists B(i) < b(k), h(0,i) < \ldots < h(B(i),i).\ h(0,i) = 0 \land h(B(i),i) = i\\
      {} \land \phi(B(i)) \text{ is consistent with } [\mu_{j+1}(\vec{x})/\vec{v}_{h(j,i)} \mid 0 \leq j \leq B(i)].
    \end{multline}
    Let:
    \begin{align*}
      I & {} \Def \min \{i \mid 0 \leq i < c, 1 \leq j \leq \ell(B(i)+1), \vec{v}_i \to_{\pi_j} \vec{v}_c\} \\
      J & {} \Def \max \{j \mid 1 \leq j \leq \ell(B(I)+1), \vec{v}_I \to_{\pi_j} \vec{v}_c\}
    \end{align*}
    So $I$ is the minimal index such that we can make a step from $\vec{v}_I$ to $\vec{v}_c$, and among the relational formulas that can be used for this step, $\pi_J$ is the one that was learned last.
    %
    Note that $I$ (and hence also $J$) exists, as we have $\vec{v}_{c-1} \to_{\tau} \vec{v}_c$ and $\tau = \pi_1$.
    %
    By \eqref{eq:IH},
    \[
      \phi(B(I)) \text{ is consistent with } [\mu_{j+1}(\vec{x})/\vec{v}_{h(j,I)} \mid 0 \leq j \leq B(I)].
    \]
    Let $\theta_I$ be an extension of $[\mu_{j+1}(\vec{x})/\vec{v}_{h(j,I)} \mid 0 \leq j \leq B(I)]$ such that $\theta_I \models \phi(B(I))$, and let $\theta$ be an extension of
    \begin{equation}
      \label{eq:theta}
      \theta_I \uplus [\mu_{B(I)+2}(\vec{x})/\vec{v}_c] \uplus [\mu_{B(I)+1}(x_{\id}) / J]
    \end{equation}
    such that $\theta \models \mu_{B(I)+1}(\pi_J)$, which exists as we have:
    \begin{align*}
      & \theta(\mu_{B(I)+1}(\vec{x})) \\
      {} = {} & \theta_I(\mu_{B(I)+1}(\vec{x})) \tag{by \eqref{eq:theta}} \\
      {} = {} & \vec{v}_{h(B(I),I)} \tag{def.\ of $\theta_I$} \\
      {} = {} & \vec{v}_I  \tag{as $h(B(I),I) = I$} \\
      {} \to_{\pi_J} {} & \vec{v}_c \tag{def.\ of $J$}\\
      {} = {} & \mu_{B(I)+1}(\vec{x}')[\mu_{B(I)+1}(\vec{x}')/\vec{v}_c] \\
      {} = {} & \mu_{B(I)+1}(\vec{x}')[\mu_{B(I)+2}(\vec{x})/\vec{v}_c] \tag{as $\mu_{B(I)+2}(\vec{x}) = \mu_{B(I)+1}(\vec{x}')$} \\
      {} = {} & \theta(\mu_{B(I)+1}(\vec{x}')) \tag{by \eqref{eq:theta}}
    \end{align*}
    %
    So we have
    \[
      \theta(\ind{\vec{x}}{B(I)+1}) = \theta_I(\ind{\vec{x}}{B(I)+1}) = \vec{v}_{h(B(I),I)} = \vec{v}_I
    \]
    and
    \[
      \theta(\ind{\vec{x}}{B(I)+2}) = \vec{v}_c.
    \]

    We now show $\theta \models \phi(B(I)+1)$.
    %
    Then we get $B(c) = B(I) + 1$, $h(j,c) = h(j,I)$ for all $j \leq B(I)$, and $h(B(c),c) = c$, which finishes the proof of \eqref{eq:goal}.

    Since $\theta$ is an extension of $\theta_I$, we have $\theta \models \phi(B(I))$, so we only need to show
    \[
      \theta \models (\ind[\id]{x}{B(I)+1} \doteq 1 \lor \ind[\id]{x}{B(I)+1} \not\doteq \ind[\id]{x}{B(I)}) \land \bigvee_{i=1}^{\ell(B(I)+1)}\mu_{B(I)+1}(\pi_i \land x_{\id} \doteq i) \land \bigwedge_{\mathclap{(B(I)+1,\pi) \in \blocked(k)}} \pi,
    \]
    i.e., we only need to show that $\theta$ is a model of the last conjunct of $\phi(B(I)+1)$.
    %
    For the disjunction
    \begin{equation}
      \label{eq:disjunction}
      \bigvee_{i=1}^{\ell(B(I)+1)}\mu_{B(I)+1}(\pi_i \land x_{\id} \doteq i),
    \end{equation}
    note that $J \leq \ell(B(I)+1)$.
    %
    Thus, to show $\theta \models \eqref{eq:disjunction}$, it suffices if
    \[
      \theta \models \mu_{B(I)+1}(\pi_J \land x_{\id} \doteq J),
    \]
    which holds by construction of $\theta$.
    %
    Thus, it remains to show
    \[
      \theta \models (\ind[\id]{x}{B(I)+1} \doteq 1 \lor \ind[\id]{x}{B(I)+1} \not\doteq \ind[\id]{x}{B(I)}) \land \bigwedge_{\mathclap{(B(I)+1,\pi) \in \blocked(k)}} \pi.
    \]

    We first consider the disjunction $\ind[\id]{x}{B(I)+1} \doteq 1 \lor \ind[\id]{x}{B(I)+1} \not\doteq \ind[\id]{x}{B(I)}$.
    %
    We show that we always have $J=1$ or $\theta(\ind[\id]{x}{B(I)}) \neq J$.
    %
    Then this disjunction is clearly satisfied by $\theta$ since $\theta(\ind[\id]{x}{B(I)+1}) = J$.
    %
    To see why $J=1$ or $\theta(\ind[\id]{x}{B(I)}) \neq J$ holds, assume that $\theta(\ind[\id]{x}{B(I)}) = J > 1$.
    %
    Then:
    \begin{align*}
                             & \theta \models \phi(B(I)) \tag {as $\theta$ is an extension of $\theta_I$} \\
      {} \curvearrowright {} & \theta \models \mu_{B(I)}(\pi_J \land x_{\id} \doteq J) \tag{as $\theta(\ind[\id]{x}{B(I)}) = J$ by assumption}                                                                                 \\
      {} \curvearrowright {} & \mu_{B(I)}(\pi_J) \text{ is consistent with } [\mu_{j+1}(\vec{x})/\vec{v}_{h(j,I)} \mid 0 \leq j \leq B(I)] \tag{as $[\mu_{j+1}(\vec{x})/\vec{v}_{h(j,I)} \mid 0 \leq j \leq B(I)] \subseteq \theta$} \\
      {} \curvearrowright {} & \mu_{B(I)}(\pi_J) \text{ is consistent with } [\mu_{B(I)}(\vec{x})/\vec{v}_{h(B(I)-1,I)},\mu_{B(I)+1}(\vec{x})/\vec{v}_{h(B(I),I)}] \tag{by instantiating $j$ with $B(I)-1$ and $B(I)$}           \\
      {} \curvearrowright {} & \pi_J \text{ is consistent with } [\vec{x}/\vec{v}_{h(B(I)-1,I)},\vec{x}'/\vec{v}_{h(B(I),I)}]                                                                                                      \\
      {} \curvearrowright {} & \pi_J \text{ is consistent with } [\vec{x}/\vec{v}_{h(B(I)-1,I)},\vec{x}'/\vec{v}_{I}] \tag{as $h(B(I),I) = I$}                                                                                     \\
      {} \curvearrowright {} & \vec{v}_{h(B(I)-1,I)} \to_{\pi_J} \vec{v}_{I}.
    \end{align*}
    By the definition of $I$ and $J$, we also have $\vec{v}_{I} \to_{\pi_J} \vec{v}_{c}$.
    %
    So by transitivity of $\to_{\pi_J}$ (which holds since $J > 1$), we get $\vec{v}_{h(B(I)-1,I)} \to_{\pi_J} \vec{v}_{c}$.
    %
    As we have $h(B(I)-1,I) < I$ by definition of $h$, this contradicts minimality of $I$.
    %
    Note that here is the only point where we need the transitivity of learned relations.

    Therefore, it remains to show
    \[
      \theta \models \bigwedge_{\mathclap{(B(I)+1,\pi) \in \blocked(k)}} \pi.
    \]
    The elements of $\blocked(k)$ have the form $(s + \ell - 1, \blockingclause(s,\ell,\pi_j,\overline{\sigma}))$ where $[\tau_i]_{i=s}^{s+\ell-1}$ is a loop on the trace, $\pi_j \in \tail(\vec{\pi})$ is a learned relation, and $\overline{\sigma} \models \pi_j$.
    %
    Moreover, we have $s + \ell - 1 = B(I) + 1$.
    %
    We now perform a case analysis for the two cases where $\ell = 1$ and $\ell > 1$.

    In Case 1 (where $\ell = 1$), the blocking clause has the form
    $\blockingclause(s,1,\linebreak \pi_j,\overline{\sigma})$ for $s = B(I)+1$.
    %
    Thus, we show that $\theta$ cannot violate a blocking clause of the form
    \[
      \blockingclause(B(I),1,\pi_j,\overline{\sigma}) = \mu_{B(I)+1}(\neg\mbip(\pi_j,\overline{\sigma})) \lor \ind[\id]{x}{B(I)+1} > 1.
    \]
    To see this, we first consider the case where the negation of the first disjunct holds and prove that then the second disjunct is true.
    %
    The reason is that we have:
    \begin{align*}
                             & \theta \models \mu_{B(I)+1}(\mbip(\pi_j, \overline{\sigma}))                                                                                     \\
      {} \curvearrowright {} & \theta \circ \mu_{B(I)+1} \text{ is consistent with } \pi_j \tag{since $\mbip(\pi_j,\overline{\sigma}) \models \pi_j$ by \Cref{def:projections}} \\
      {} \curvearrowright {} & \theta(\mu_{B(I)+1}(\vec{x})) \to_{\pi_j} \theta(\mu_{B(I)+1}(\vec{x}'))                                                                \\
      {} \curvearrowright {} & \theta(\mu_{B(I)+1}(\vec{x})) \to_{\pi_j} \theta(\mu_{B(I)+2}(\vec{x}))                                                                \\
      {} \curvearrowright {} & \vec{v}_{h(B(I),I)} \to_{\pi_j} \vec{v}_{c} \tag{def.\ of $\theta$}                                                                 \\
      {} \curvearrowright {} & \vec{v}_{I} \to_{\pi_j} \vec{v}_{c} \tag{as $h(B(I),I) = I$}
    \end{align*}
    So the step fom $\vec{v}_{I}$ to $\vec{v}_{c}$ can be done by a learned relation $\pi_j$.
    %
    As $\pi_j$ is a learned relation, we have $j > 1$.
    %
    This implies $\theta(\ind[\id]{x}{B(I)+1}) = J > 1$, as $J$ is maximal and hence $J \geq j > 1$.

    Now we consider the case where the negation of the first disjunct does not hold and prove that then the first disjunct is true.
    %
    The reason is that due to the completeness of $\AA$, $\theta \centernot\models \mu_{B(I)+1}(\mbip(\pi_j, \overline{\sigma}))$ implies $\theta \models \mu_{B(I)+1}(\neg\mbip(\pi_j, \overline{\sigma}))$.
    %
    So in this case the blocking clause is satisfied as well.

    In Case 2 (where $\ell > 1$), we show that $\theta$ cannot violate a blocking clause of the form
    \[
      \blockingclause(s,\ell,\pi_j,\overline{\sigma}) = \mu_{s,\ell}(\neg\mbip(\pi_j, \overline{\sigma}))
    \]
    where $s + \ell - 1 = B(I)+1$, i.e., $s + \ell = B(I) + 2$.
    %
    The reason is that we have
    \begin{align*}
                             & \theta \centernot\models \mu_{s,\ell}(\neg\mbip(\pi_j, \overline{\sigma}))                                                                       \\
      {} \curvearrowright {} & \theta \models \mu_{s,\ell}(\mbip(\pi_j, \overline{\sigma})) \tag{as $\AA$ is complete} \\
      {} \curvearrowright {} & \theta \circ \mu_{s,\ell} \text{ is consistent with } \pi_j \tag{since $\mbip(\pi_j,\overline{\sigma}) \models \pi_j$ by \Cref{def:projections}} \\
      {} \curvearrowright {} & \theta(\mu_{s,\ell}(\vec{x})) \to_{\pi_j} \theta(\mu_{s,\ell}(\vec{x}'))                                                              \\
      {} \curvearrowright {} & \vec{v}_{h(s-1,I)} \to_{\pi_j} \vec{v}_{c} \tag{def.\ of $\theta$, as $s+\ell = B(I)+2$}
    \end{align*}
    For the last step, note that
    \begin{align*}
      \theta(\mu_{s,\ell}(\vec{x})) & {} = \theta(\mu_{s}(\vec{x})) = \theta_I(\mu_{s}(\vec{x})) = \vec{v}_{h(s-1,I)} & \text{and} \\
      \theta(\mu_{s,\ell}(\vec{x}')) & {} = \theta(\ind{\vec{x}}{s + \ell}) = \theta(\ind{\vec{x}}{B(I)+2}) = \vec{v}_{c}.
    \end{align*}
    We have $s - 1 < B(I)$ and thus $h(s-1,I) < h(B(I),I) = I$, which contradicts minimality of $I$.
    %
    This finishes the proof of \eqref{eq:goal}.
    \qed
  \end{proof}
}

\begin{remark}[Termination]
  \label{remark:termination}
In general, \Cref{alg} does not terminate, since
 $\tip$ decomposes the relation into finitely many cases and
approximates their transitive closures independently, but
${\to^+_{\tau_\Loop}} \subseteq \bigcup_{\sigma \models \tau_{\Loop}}
{\to_{\tip(\tau_{\Loop},\sigma)}}$ is not guaranteed (\Cref{remark:properties-tip}).
%
To see why this may prevent termination, consider a loop $\tau_{\Loop}$ and assume that there are reachable states
$\vec{v},\vec{v}'$ with $\vec{v} \to_{\tau_\Loop}^+ \vec{v}'$, but $\vec{v}
\not\to_{\tip(\tau_{\Loop},\sigma)} \vec{v}'$ for all models $\sigma$ of
$\tau_\Loop$.
%
Then TRL may find a model that corresponds to a run from $\vec{v}$ to $\vec{v}'$.
%
Unless $\vec{v}$ can be evaluated to $\vec{v}'$ with another learned transition $\pi \notin \{\tip(\tau_{\Loop},\sigma) \mid \sigma \models \tau_{\Loop}\}$ by coincidence, this loop cannot be blocked and TRL learns a new relation.
%
Thus, TRL may keep learning new relations as long as there are loops whose transitive closure is not yet covered by learned relations.

As the elements of $\{\tip(\tau,\sigma) \mid \sigma \models \tau\}$ are independent of each other, a more ``global'' view may help to enforce convergence.
%
We leave that to future work.
\end{remark}

\paper{
  \begin{example}[\Cref{ex:ex1} Finished]
    After learning $\tau^+_\dec$ and $\tau^+_\inc$, the underlying SMT problem becomes unsatisfiable when $b=3$ after adding appropriate blocking clauses, so that $\tau^+_\dec$ and $\tau^+_\inc$ are preferred over $\tau_\dec$ and $\tau_\inc$.
    %
    The reason is that $\tau^+_\dec$ and $\tau^+_\inc$ must not be used twice in a row due to \Cref{alg:trans} of \Cref{alg}, and $\tau^+_\inc$ cannot be used after $\tau^+_\dec$, as it requires $w \doteq 0$, but $\tau^+_\dec$ sets $w$ to $1$.
    %
    Thus, \Cref{alg} returns $\safe$.
    %
    See \cite{arxiv} for a detailed run of
\Cref{alg} 
on \Cref{ex:ex1}.
  \end{example}
}

\report{
\subsection{A Complete Example}
\label{sec:example}

For a complete run of TRL on our example, assume that we obtain the following traces (where the detected loops are underlined):
\begin{enumerate}
  \item \label{it:a}
        $[\underline{\tau_\inc}]$, resulting in the learned relation $\tau^+_\inc$ and the blocking clause $\mu_{1}(\neg\tau^+_\inc \lor x_\id > 1)$ which ensures that if $b = 1$, then we cannot use $\tau_\inc$ but would have to use $\tau^+_\inc$.
  \item \label{it:b}
        $[\underline{\tau_\dec}]$, resulting in the learned relation $\tau^+_\dec$ and the blocking clause $\mu_{1}(\neg\tau^+_\dec \lor x_\id > 1)$ which ensures that if $b = 1$, then we cannot use $\tau_\dec$ but would have to use $\tau^+_\dec$.
  \item \label{it:c}
        $[\tau^+_\inc,\underline{\tau_\inc}]$, resulting in the blocking clause $\mu_{2}(\neg\tau^+_\inc \lor x_\id > 1)$ which ensures that if $b = 2$, then we cannot use $\tau_\inc$.
        %
        Using $\tau^+_\inc$ twice after each other is also not possible due to transitivity (\Cref{alg:trans}).
  \item \label{it:d}
        $[\tau^+_\dec,\underline{\tau_\dec}]$, resulting in the blocking clause $\mu_{2}(\neg\tau^+_\dec \lor x_\id > 1)$ which ensures that if $b = 2$, then we cannot use $\tau_\dec$.
        %
        Using $\tau^+_\dec$ twice after each other is also not possible due to transitivity (\Cref{alg:trans}).
  \item \label{it:e}
        $[\tau^+_\inc, \tau^+_\dec, \underline{\tau_\dec}]$, resulting in the blocking clause $\mu_{3}(\neg\tau^+_\dec \lor x_\id > 1)$ which ensures that if $b = 3$, then we cannot use $\tau_\dec$.
\end{enumerate}
Now we are in the following situation:
\begin{itemize}
  \item The first element of the trace cannot be $\tau_\inc$ or $\tau_\dec$ due to \eqref{it:a} and \eqref{it:b}.
  \item If the first element of the trace is $\tau^+_\inc$, then:
        \begin{itemize}
          \item The second element of the trace cannot be $\tau_\inc$ or $\tau_\dec$ due to \eqref{it:c} and \eqref{it:d}.
          \item The second element of the trace cannot be $\tau^+_\inc$ due to \Cref{alg:trans}.
          \item If the second element of the trace is $\tau^+_\dec$, then:
                \begin{itemize}
                  \item The third element of the trace cannot be $\tau_\inc$ or $\tau^+_\inc$, as $\tau^+_\dec$ sets $w$ to $1$, but $\tau_\inc$ and $\tau^+_\inc$ require $w = 0$.
                  \item The third element of the trace cannot be $\tau_\dec$ due to \eqref{it:e}.
                  \item The third element of the trace cannot be $\tau^+_\dec$ due to \Cref{alg:trans}.
                \end{itemize}
        \end{itemize}
        So this case becomes infeasible with the $3^{rd}$ unrolling of the transition relation.
  \item If the first element of the trace is $\tau^+_\dec$, then:
        \begin{itemize}
          \item The second element of the trace cannot be $\tau_\inc$ or $\tau^+_\inc$, as $\tau^+_\dec$ sets $w$ to $1$, but $\tau_\inc$ and $\tau^+_\inc$ require $w = 0$.
          \item The second element of the trace cannot be $\tau_\dec$ due to \eqref{it:d}.
          \item The second element of the trace cannot be $\tau^+_\dec$ due to \Cref{alg:trans}.
        \end{itemize}
        So this case becomes infeasible with the $2^{nd}$ unrolling of the transition relation.
\end{itemize}
Thus, the underlying SMT problem becomes unsatisfiable when $b=3$, such that $\safe$ is returned in \Cref{alg:safe}.
}
