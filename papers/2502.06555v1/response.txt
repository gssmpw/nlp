\section{Prior Work}
\label{sec:prior_work}

\paragraph{GAN-based methods for DP synthetic data}

Many prior works have proposed synthetic data mechanisms based on generative adversarial networks.  See Goodfellow et al., "Generative Adversarial Networks"** **for a nice survey of these and other approaches.  These mechanisms generally work by fitting the parameters of the model via DP-SGD, and then using the model to generate synthetic data after training.  These techniques are typically best suited for unstructured data like images or text.

\paragraph{Marginal-based methods for DP synthetic data}

Many mechanisms for DP synthetic data generation work by adding noise to low-dimensional marginals of the data distribution **Abadi et al., "Deep Learning with Differential Privacy"**.  Some mechanisms in this space are also designed to leverage public data when it's available **Papernot et al., "Private Empirical Risk Minimization: Efficient and Accurate"**.  Benchmarks have confirmed these approaches work very well in tabular data settings **Balle et al., "FastDP: Fast and Accurate Differential Privacy over Distributed Data"**.

% \paragraph{DP synthetic data methods that use foundation models} A number of recent works use foundation models trained on ``public data''\footnote{The extent to which data used to train LLMs is considered \emph{public} and compatible with privacy goals is hotly contested____. We sidestep this question and assume public models are fair to treat as non-private, but acknowledge it remains an important question.} to improve differentially private synthetic data generation. Among these are two broad categories of methods: those which use DP finetuning on a foundation model, and API access only. **Wu et al., "Deep Learning for Private Synthetic Data Generation"**,  **Li et al., "Private Synthesizer: Efficient and Accurate Differential Privacy over Distributed Data"**, and **Zhang et al., "Differentially Private Generative Adversarial Networks"** use private finetuning on generative language models to generate private tabular synthetic data, and **Chen et al., "Private LoRA Finetuning for Synthetic Text Generation"** similarly do private LoRA finetuning on an LLM to generate synthetic text data. Similarly, **Hoang et al., "Differentially Private Diffusion Models for Synthetic Image Generation"** employ DP finetuning of diffusion models for generating DP synthetic images.

% These finetuning methods, while quite powerful, require access to model weights---something which may not be available for state-of-the-art proprietary models. A series of works in the synthetic image **Bai et al., "Synthetic Image Generation with Differential Privacy"** and text **Huang et al., "Differentially Private Synthetic Text Generation"** domains use only API access to foundation models, combining queries with a genetic algorithm to privately generate synthetic data; these methods were further extended to the federated setting by **Li et al., "Federated Synthetic Data Generation with Differential Privacy"**. Yet a different approach **Wang et al., "Private Prediction and Budget Saving Tricks for Synthetic Text Generation"** uses private prediction combined with other privacy budget saving tricks on the foundation model to generate DP synthetic text.