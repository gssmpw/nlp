@inproceedings{caronEmergingPropertiesSelfSupervised2021,
  title = {Emerging {{Properties}} in {{Self-Supervised Vision Transformers}}},
  author = {Caron, Mathilde and Touvron, Hugo and Misra, Ishan and Jégou, Hervé and Mairal, Julien and Bojanowski, Piotr and Joulin, Armand},
  year = {2021},
  pages = {9650--9660},
  url = {https://openaccess.thecvf.com/content/ICCV2021/html/Caron_Emerging_Properties_in_Self-Supervised_Vision_Transformers_ICCV_2021_paper},
  urldate = {2024-09-03},
  booktitle = {Proceedings of the {{IEEE}}/{{CVF International Conference}} on {{Computer Vision}}},
  langid = {english}
}

@online{zhouDINOWMWorldModels2024,
  title = {{{DINO-WM}}: {{World Models}} on {{Pre-trained Visual Features}} Enable {{Zero-shot Planning}}},
  shorttitle = {{{DINO-WM}}},
  author = {Zhou, Gaoyue and Pan, Hengkai and LeCun, Yann and Pinto, Lerrel},
  year = {2024},
  eprint = {2411.04983},
  eprinttype = {arXiv},
  doi = {10.48550/arXiv.2411.04983},
  url = {http://arxiv.org/abs/2411.04983},
  urldate = {2024-12-14},
  langid = {american},
  pubstate = {prepublished}
}

@inproceedings{chenEmpiricalStudyTraining2021,
  title = {An {{Empirical Study}} of {{Training Self-Supervised Vision Transformers}}},
  author = {Chen, Xinlei and Xie, Saining and He, Kaiming},
  year = {2021},
  pages = {9640--9649},
  url = {https://openaccess.thecvf.com/content/ICCV2021/html/Chen_An_Empirical_Study_of_Training_Self-Supervised_Vision_Transformers_ICCV_2021_paper.html},
  urldate = {2024-09-03},
  booktitle = {Proceedings of the {{IEEE}}/{{CVF International Conference}} on {{Computer Vision}}},
  langid = {english}
}

@inproceedings{heMomentumContrastUnsupervised2020,
  title = {Momentum {{Contrast}} for {{Unsupervised Visual Representation Learning}}},
  author = {He, Kaiming and Fan, Haoqi and Wu, Yuxin and Xie, Saining and Girshick, Ross},
  year = {2020},
  pages = {9729--9738},
  url = {https://openaccess.thecvf.com/content_CVPR_2020/html/He_Momentum_Contrast_for_Unsupervised_Visual_Representation_Learning_CVPR_2020_paper.html},
  urldate = {2024-12-05},
  booktitle = {Proceedings of the {{IEEE}}/{{CVF Conference}} on {{Computer Vision}} and {{Pattern Recognition}}},
  langid = {american}
}

@inproceedings{radfordLearningTransferableVisual2021,
  title = {Learning {{Transferable Visual Models From Natural Language Supervision}}},
  booktitle = {Proceedings of the 38th {{International Conference}} on {{Machine Learning}}},
  author = {Radford, Alec and Kim, Jong Wook and Hallacy, Chris and Ramesh, Aditya and Goh, Gabriel and Agarwal, Sandhini and Sastry, Girish and Askell, Amanda and Mishkin, Pamela and Clark, Jack and Krueger, Gretchen and Sutskever, Ilya},
  year = {2021},
  pages = {8748--8763},
  publisher = {PMLR},
  url = {https://proceedings.mlr.press/v139/radford21a.html},
  urldate = {2024-07-22},
  eventtitle = {International {{Conference}} on {{Machine Learning}}},
  langid = {english}
}

@inproceedings{liBLIPBootstrappingLanguageImage2022,
  title = {{{BLIP}}: {{Bootstrapping Language-Image Pre-training}} for {{Unified Vision-Language Understanding}} and {{Generation}}},
  shorttitle = {{{BLIP}}},
  booktitle = {Proceedings of the 39th {{International Conference}} on {{Machine Learning}}},
  author = {Li, Junnan and Li, Dongxu and Xiong, Caiming and Hoi, Steven},
  year = {2022},
  pages = {12888--12900},
  publisher = {PMLR},
  url = {https://proceedings.mlr.press/v162/li22n.html},
  urldate = {2023-11-13},
  eventtitle = {International {{Conference}} on {{Machine Learning}}},
  langid = {english}
}

@inproceedings{liBLIP2BootstrappingLanguageImage2023,
  title={Blip-2: Bootstrapping language-image pre-training with frozen image encoders and large language models},
  author={Li, Junnan and Li, Dongxu and Savarese, Silvio and Hoi, Steven},
  booktitle={International conference on machine learning},
  pages={19730--19742},
  year={2023},
  organization={PMLR}
}

@online{chenBigSelfSupervisedModels2020,
  title = {Big {{Self-Supervised Models}} Are {{Strong Semi-Supervised Learners}}},
  author = {Chen, Ting and Kornblith, Simon and Swersky, Kevin and Norouzi, Mohammad and Hinton, Geoffrey},
  year = {2020},
  eprint = {2006.10029},
  eprinttype = {arXiv},
  doi = {10.48550/arXiv.2006.10029},
  url = {http://arxiv.org/abs/2006.10029},
  urldate = {2024-11-12},
  langid = {american},
  pubstate = {prepublished}
}

@inproceedings{chenSimpleFrameworkContrastive2020,
  title = {A {{Simple Framework}} for {{Contrastive Learning}} of {{Visual Representations}}},
  booktitle = {Proceedings of the 37th {{International Conference}} on {{Machine Learning}}},
  author = {Chen, Ting and Kornblith, Simon and Norouzi, Mohammad and Hinton, Geoffrey},
  year = {2020},
  pages = {1597--1607},
  publisher = {PMLR},
  url = {https://proceedings.mlr.press/v119/chen20j.html},
  urldate = {2024-08-30},
  eventtitle = {International {{Conference}} on {{Machine Learning}}},
  langid = {english}
}

@article{pearlInterpretationIdentificationCausal2014,
  title = {Interpretation and Identification of Causal Mediation},
  author = {Pearl, Judea},
  year = {2014},
  journaltitle = {Psychological Methods},
  volume = {19},
  number = {4},
  pages = {459--481},
  publisher = {American Psychological Association},
  location = {US},
  issn = {1939-1463},
  doi = {10.1037/a0036434}
}

@book{pearl2016causal,
  title={Causal inference in statistics: a primer},
  author={Pearl, Judea},
  year={2016},
  publisher={John Wiley \& Sons}
}

@incollection{pearl2022direct,
  title={Direct and indirect effects},
  author={Pearl, Judea},
  booktitle={Probabilistic and causal inference: the works of Judea Pearl},
  pages={373--392},
  year={2022}
}

@article{pearl1995causal,
  title={Causal diagrams for empirical research},
  author={Pearl, Judea},
  journal={Biometrika},
  volume={82},
  number={4},
  pages={669--688},
  year={1995},
  publisher={Oxford University Press}
}


@inproceedings{liuLargeScaleLongTailedRecognition2019,
  title = {Large-{{Scale Long-Tailed Recognition}} in an {{Open World}}},
  booktitle = {Proceedings of the {{IEEE}}/{{CVF Conference}} on {{Computer Vision}} and {{Pattern Recognition}}},
  author = {Liu, Ziwei and Miao, Zhongqi and Zhan, Xiaohang and Wang, Jiayun and Gong, Boqing and Yu, Stella X.},
  year = {2019},
  pages = {2532--2541},
  publisher = {IEEE},
  location = {Long Beach, CA, USA},
  doi = {10.1109/CVPR.2019.00264},
  url = {https://ieeexplore.ieee.org/document/8953407/},
  urldate = {2021-06-02},
  eventtitle = {Proceedings of the {{IEEE}}/{{CVF Conference}} on {{Computer Vision}} and {{Pattern Recognition}}},
  isbn = {978-1-7281-3293-8},
  langid = {english}
}

@article{russakovskyImagenetLargeScale2015,
  title = {Imagenet Large Scale Visual Recognition Challenge},
  author = {Russakovsky, Olga and Deng, Jia and Su, Hao and Krause, Jonathan and Satheesh, Sanjeev and Ma, Sean and Huang, Zhiheng and Karpathy, Andrej and Khosla, Aditya and Bernstein, Michael},
  year = {2015},
  journaltitle = {International journal of computer vision},
  volume = {115},
  number = {3},
  pages = {211--252}
}

@article{pearl2014interpretation,
  title={Interpretation and identification of causal mediation.},
  author={Pearl, Judea},
  journal={Psychological methods},
  volume={19},
  number={4},
  pages={459},
  year={2014},
  publisher={American Psychological Association}
}

@article{luLearningConceptDrift2019,
  title = {Learning under {{Concept Drift}}: {{A Review}}},
  shorttitle = {Learning under {{Concept Drift}}},
  author = {Lu, Jie and Liu, Anjin and Dong, Fan and Gu, Feng and Gama, João and Zhang, Guangquan},
  year = {2019},
  journaltitle = {IEEE Transactions on Knowledge and Data Engineering},
  volume = {31},
  number = {12},
  pages = {2346--2363},
  issn = {1558-2191},
  doi = {10.1109/TKDE.2018.2876857},
  url = {https://ieeexplore.ieee.org/abstract/document/8496795},
  urldate = {2024-02-21}
}


@misc{yang2024adaptingmultimodallargelanguage,
      title={Adapting Multi-modal Large Language Model to Concept Drift From Pre-training Onwards}, 
      author={Xiaoyu Yang and Jie Lu and En Yu},
      year={2024},
      eprint={2405.13459},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2405.13459}, 
}

@article{pearl2000models,
  title={Models, reasoning and inference},
  author={Pearl, Judea and others},
  journal={Cambridge, UK: CambridgeUniversityPress},
  volume={19},
  number={2},
  pages={3},
  year={2000}
}


@article{oordRepresentationLearningContrastive2019,
  title={Representation learning with contrastive predictive coding},
  author={Oord, Aaron van den and Li, Yazhe and Vinyals, Oriol},
  journal={arXiv preprint arXiv:1807.03748},
  year={2018}
}

@inproceedings{yangCausalAttentionVisionLanguage2021,
  title = {Causal {{Attention}} for {{Vision-Language Tasks}}},
  author = {Yang, Xu and Zhang, Hanwang and Qi, Guojun and Cai, Jianfei},
  year = {2021},
  pages = {9847--9857},
  url = {https://openaccess.thecvf.com/content/CVPR2021/html/Yang_Causal_Attention_for_Vision-Language_Tasks_CVPR_2021_paper.html},
  urldate = {2024-12-31},
  booktitle = {Proceedings of the {{IEEE}}/{{CVF Conference}} on {{Computer Vision}} and {{Pattern Recognition}}},
  langid = {english}
}

@article{rohekarCausalInterpretationSelfAttention2023,
  title = {Causal {{Interpretation}} of {{Self-Attention}} in {{Pre-Trained Transformers}}},
  author = {Rohekar, Raanan Y. and Gurwicz, Yaniv and Nisimov, Shami},
  year = {2023},
  journaltitle = {Advances in Neural Information Processing Systems},
  volume = {36},
  pages = {31450--31465},
  url = {https://proceedings.neurips.cc/paper_files/paper/2023/hash/642a321fba8a0f03765318e629cb93ea\\-Abstract-Conference.html},
  urldate = {2024-12-30},
  langid = {english}
}

@inproceedings{gowdaPullingCausalBootstraps2021,
  title = {Pulling up by the Causal Bootstraps: {{Causal}} Data Augmentation for Pre-Training Debiasing},
  shorttitle = {Pulling up by the Causal Bootstraps},
  booktitle = {Proceedings of the 30th {{ACM International Conference}} on {{Information}} \& {{Knowledge Management}}},
  author = {Gowda, Sindhu CM and Joshi, Shalmali and Zhang, Haoran and Ghassemi, Marzyeh},
  year = {2021},
  pages = {606--616},
  url = {https://dl.acm.org/doi/abs/10.1145/3459637.3482380},
  urldate = {2024-12-30}
}

@inproceedings{lvCausalityInspiredRepresentation2022,
  title = {Causality {{Inspired Representation Learning}} for {{Domain Generalization}}},
  author = {Lv, Fangrui and Liang, Jian and Li, Shuang and Zang, Bin and Liu, Chi Harold and Wang, Ziteng and Liu, Di},
  year = {2022},
  pages = {8046--8056},
  url = {https://openaccess.thecvf.com/content/CVPR2022/html/Lv_Causality_Inspired_Representation_Learning_for_Domain_Generalization_CVPR_2022_paper.html},
  urldate = {2024-12-30},
  booktitle = {Proceedings of the {{IEEE}}/{{CVF Conference}} on {{Computer Vision}} and {{Pattern Recognition}}},
  langid = {english}
}

@online{miaoDomainGeneralizationContrastive2022,
  title = {Domain {{Generalization}} via {{Contrastive Causal Learning}}},
  author = {Miao, Qiaowei and Yuan, Junkun and Kuang, Kun},
  year = {2022},
  eprint = {2210.02655},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2210.02655},
  url = {http://arxiv.org/abs/2210.02655},
  urldate = {2024-12-30},
  pubstate = {prepublished}
}

@article{choiC2LCausallyContrastive2022,
  title = {{{C2L}}: {{Causally Contrastive Learning}} for {{Robust Text Classification}}},
  shorttitle = {{{C2L}}},
  author = {Choi, Seungtaek and Jeong, Myeongho and Han, Hojae and Hwang, Seung-won},
  year = {2022},
  journaltitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  volume = {36},
  number = {10},
  pages = {10526--10534},
  issn = {2374-3468},
  doi = {10.1609/aaai.v36i10.21296},
  url = {https://ojs.aaai.org/index.php/AAAI/article/view/21296},
  urldate = {2024-12-30},
  issue = {10},
  langid = {english}
}

@inproceedings{liuShowDeconfoundTell2022,
  title = {Show, {{Deconfound}} and {{Tell}}: {{Image Captioning With Causal Inference}}},
  shorttitle = {Show, {{Deconfound}} and {{Tell}}},
  author = {Liu, Bing and Wang, Dong and Yang, Xu and Zhou, Yong and Yao, Rui and Shao, Zhiwen and Zhao, Jiaqi},
  year = {2022},
  pages = {18041--18050},
  url = {https://openaccess.thecvf.com/content/CVPR2022/html/Liu_Show_Deconfound_and_Tell_Image_Captioning_With_Causal_Inference_CVPR_2022_paper.html},
  urldate = {2024-12-12},
  booktitle = {Proceedings of the {{IEEE}}/{{CVF Conference}} on {{Computer Vision}} and {{Pattern Recognition}}},
  langid = {english}
}

@online{xuShowAttendTell2016,
  title = {Show, {{Attend}} and {{Tell}}: {{Neural Image Caption Generation}} with {{Visual Attention}}},
  shorttitle = {Show, {{Attend}} and {{Tell}}},
  author = {Xu, Kelvin and Ba, Jimmy and Kiros, Ryan and Cho, Kyunghyun and Courville, Aaron and Salakhutdinov, Ruslan and Zemel, Richard and Bengio, Yoshua},
  year = {2016},
  eprint = {1502.03044},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.1502.03044},
  url = {http://arxiv.org/abs/1502.03044},
  urldate = {2025-01-09},
  pubstate = {prepublished}
}


@article{yangDeconfoundedImageCaptioning2023,
  title = {Deconfounded {{Image Captioning}}: {{A Causal Retrospect}}},
  shorttitle = {Deconfounded {{Image Captioning}}},
  author = {Yang, Xu and Zhang, Hanwang and Cai, Jianfei},
  year = {2023},
  journaltitle = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  volume = {45},
  number = {11},
  pages = {12996--13010},
  issn = {1939-3539},
  doi = {10.1109/TPAMI.2021.3121705},
  url = {https://ieeexplore.ieee.org/abstract/document/9583890},
  urldate = {2025-01-09},
  eventtitle = {{{IEEE Transactions}} on {{Pattern Analysis}} and {{Machine Intelligence}}}
}

@inproceedings{wuUnsupervisedFeatureLearning2018a,
  title = {Unsupervised {{Feature Learning}} via {{Non-Parametric Instance Discrimination}}},
  author = {Wu, Zhirong and Xiong, Yuanjun and Yu, Stella X. and Lin, Dahua},
  year = {2018},
  pages = {3733--3742},
  url = {https://openaccess.thecvf.com/content_cvpr_2018/html/Wu_Unsupervised_Feature_Learning_CVPR_2018_paper.html},
  urldate = {2025-01-11},
  booktitle = {Proceedings of the {{IEEE Conference}} on {{Computer Vision}} and {{Pattern Recognition}}}
}



@article{yangTdistributedSphericalFeature2023,
  title = {T-Distributed {{Spherical Feature Representation}} for {{Imbalanced Classification}}},
  author = {Yang, Xiaoyu and Chen, Yufei and Yue, Xiaodong and Xu, Shaoxun and Ma, Chao},
  year = {2023},
  journal = {Proceedings of the AAAI Conference on Artificial Intelligence},
  volume = {37},
  year = {2023},
  number = {9},
  pages = {10825--10833},
  issn = {2374-3468},
  doi = {10.1609/aaai.v37i9.26284},
  url = {https://ojs.aaai.org/index.php/AAAI/article/view/26284},
  urldate = {2024-03-06},
  issue = {9},
  langid = {english}
}

@article{guiGOODGraphOutofDistribution2022,
  title = {{{GOOD}}: {{A Graph Out-of-Distribution Benchmark}}},
  shorttitle = {{{GOOD}}},
  author = {Gui, Shurui and Li, Xiner and Wang, Limei and Ji, Shuiwang},
  year = {2022-12-06},
  journal= {Advances in Neural Information Processing Systems},
  volume = {35},
  year = {2022},
  pages = {2059--2073},
  url = {https://proceedings.neurips.cc/paper_files/paper/2022/hash/0dc91de822b71c66a7f54fa121d8cbb9-Abstract-Datasets_and_Benchmarks.html},
  urldate = {2024-03-27},
  langid = {english}
}


@article{liuOpenLongTailedRecognition2022,
  title = {Open {{Long-Tailed Recognition In A Dynamic World}}},
  author = {Liu, Ziwei and Miao, Zhongqi and Zhan, Xiaohang and Wang, Jiayun and Gong, Boqing and Yu, Stella X.},
  year = {2022},
  journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  pages = {1--15},
  year = {2022},
  issn = {1939-3539},
  doi = {10.1109/TPAMI.2022.3200091}
}

@article{caiLUNALocalizingUnfamiliarity2022,
  title = {{{LUNA}}: {{Localizing Unfamiliarity Near Acquaintance}} for {{Open-Set Long-Tailed Recognition}}},
  shorttitle = {{{LUNA}}},
  author = {Cai, Jiarui and Wang, Yizhou and Hsu, Hung-Min and Hwang, Jenq-Neng and Magrane, Kelsey and Rose, Craig S.},
  year = {2022-06-28},
  journal = {Proceedings of the AAAI Conference on Artificial Intelligence},
  volume = {36},
  year = {2022},
  number = {1},
  pages = {131--139},
  issn = {2374-3468},
  doi = {10.1609/aaai.v36i1.19887},
  url = {https://ojs.aaai.org/index.php/AAAI/article/view/19887},
  urldate = {2023-04-12},
  langid = {english}
}

@article{wangOpenWorldLongtailed2023,
  title = {Open World Long-Tailed Data Classification through Active Distribution Optimization},
  author = {Wang, Min and Zhou, Lei and Li, Qian and Zhang, An-an},
  year = {2023-03-01},
  journal = {Expert Systems with Applications},
  shortjournal = {Expert Systems with Applications},
  volume = {213},
  year = {2023},
  pages = {119054},
  issn = {0957-4174},
  doi = {10.1016/j.eswa.2022.119054},
  url = {https://www.sciencedirect.com/science/article/pii/S0957417422020723},
  urldate = {2023-04-12},
  langid = {english}
}

@inproceedings{wangPartialAsymmetricContrastive2022,
  title = {Partial and {{Asymmetric Contrastive Learning}} for {{Out-of-Distribution Detection}} in {{Long-Tailed Recognition}}},
  booktitle = {Proceedings of the 39th {{International Conference}} on {{Machine Learning}}},
  author = {Wang, Haotao and Zhang, Aston and Zhu, Yi and Zheng, Shuai and Li, Mu and Smola, Alex J. and Wang, Zhangyang},
  year = {2022-06-28},
  year = {2022},
  pages = {23446--23458},
  publisher = {PMLR},
  url = {https://proceedings.mlr.press/v162/wang22aq.html},
  urldate = {2023-03-30},
  eventtitle = {International {{Conference}} on {{Machine Learning}}},
  langid = {english}
}

@inproceedings{weiOpenSamplingExploringOutofDistribution2022,
  title = {Open-{{Sampling}}: {{Exploring Out-of-Distribution}} Data for {{Re-balancing Long-tailed}} Datasets},
  shorttitle = {Open-{{Sampling}}},
  booktitle = {Proceedings of the 39th {{International Conference}} on {{Machine Learning}}},
  author = {Wei, Hongxin and Tao, Lue and Xie, Renchunzi and Feng, Lei and An, Bo},
  year = {2022-06-28},
  year = {2022},
  pages = {23615--23630},
  publisher = {PMLR},
  url = {https://proceedings.mlr.press/v162/wei22c.html},
  urldate = {2024-03-28},
  eventtitle = {International {{Conference}} on {{Machine Learning}}},
  langid = {english}
}

@article{weiEATLongTailedOutofDistribution2024,
  title = {{{EAT}}: {{Towards Long-Tailed Out-of-Distribution Detection}}},
  shorttitle = {{{EAT}}},
  author = {Wei, Tong and Wang, Bo-Lin and Zhang, Min-Ling},
  year = {2024-03-24},
  journal = {Proceedings of the AAAI Conference on Artificial Intelligence},
  volume = {38},
  number = {14},
  pages = {15787--15795},
  year = {2024},
  issn = {2374-3468},
  doi = {10.1609/aaai.v38i14.29508},
  url = {https://ojs.aaai.org/index.php/AAAI/article/view/29508},
  urldate = {2024-03-28},
  issue = {14},
  langid = {english}
}

@inproceedings{liTrustworthyLongTailedClassification2022,
  title = {Trustworthy {{Long-Tailed Classification}}},
  author = {Li, Bolian and Han, Zongbo and Li, Haining and Fu, Huazhu and Zhang, Changqing},
  year = {2022},
  year = {2022},
  pages = {6970--6979},
  url = {https://openaccess.thecvf.com/content/CVPR2022/html/Li_Trustworthy_Long-Tailed_Classification_CVPR_2022_paper.html},
  urldate = {2024-03-28},
  booktitle = {Proceedings of the {{IEEE}}/{{CVF Conference}} on {{Computer Vision}} and {{Pattern Recognition}}},
  langid = {english}
}


@inproceedings{raunakLongTailedPhenomenaNeural2020,
  title = {On {{Long-Tailed Phenomena}} in {{Neural Machine Translation}}},
  booktitle = {Findings of the {{Association}} for {{Computational Linguistics}}: {{EMNLP}} 2020},
  author = {Raunak, Vikas and Dalmia, Siddharth and Gupta, Vivek and Metze, Florian},
  editor = {Cohn, Trevor and He, Yulan and Liu, Yang},
  year = {2020-11},
  pages = {3088--3095},
  publisher = {Association for Computational Linguistics},
  location = {Online},
  doi = {10.18653/v1/2020.findings-emnlp.276},
  url = {https://aclanthology.org/2020.findings-emnlp.276},
  urldate = {2024-04-21},
  eventtitle = {Findings 2020}
}


@article{mingDelvingOutofDistributionDetection2022a,
  title = {Delving into {{Out-of-Distribution Detection}} with {{Vision-Language Representations}}},
  author = {Ming, Yifei and Cai, Ziyang and Gu, Jiuxiang and Sun, Yiyou and Li, Wei and Li, Yixuan},
  year = {2022},
  journal = {Advances in Neural Information Processing Systems},
  volume = {35},
  pages = {35087--35102},
  url = {https://proceedings.neurips.cc/paper_files/paper/2022/hash/e43a33994a28f746dcfd53eb51ed3c2d-Abstract-Conference.html},
  urldate = {2024-04-23},
  langid = {english}
}



@book{mardiaDirectionalStatistics2000,
  title = {Directional Statistics},
  author = {Mardia, K. V. and Jupp, Peter E.},
  year = {2000},
  series = {Wiley Series in Probability and Statistics},
  publisher = {J. Wiley},
  location = {Chichester ; New York},
  isbn = {978-0-471-95333-3},
  langid = {english},
  pagetotal = {429}
}

@unpublished{decaoPowerSphericalDistribution2020,
  title = {The Power Spherical Distribution},
  author = {De Cao, Nicola and Aziz, Wilker},
  year = {2020},
  eprint = {2006.04437},
  eprinttype = {arxiv}
}


@article{banerjeeClusteringUnitHypersphere2005,
  title   = {Clustering on the {{Unit Hypersphere}} Using von {{Mises}}-{{Fisher Distributions}}.},
  author  = {Banerjee, Arindam and Dhillon, Inderjit S. and Ghosh, Joydeep and Sra, Suvrit and Ridgeway, Greg},
  year    = {2005},
  journal = {Journal of Machine Learning Research},
  volume  = {6},
  number  = {9},
  pages   = {1345--1382},
}

@article{vandermaatenVisualizingDataUsing2008,
  title   = {Visualizing Data Using T-{{SNE}}.},
  author  = {{Van der Maaten}, Laurens and Hinton, Geoffrey},
  year    = {2008},
  journal = {Journal of machine learning research},
  volume  = {9},
  number  = {11}
}

@online{mingHowExploitHyperspherical2023,
  title = {How to Exploit Hyperspherical Embeddings for Out-of-Distribution Detection?},
  author = {Ming, Yifei and Sun, Yiyou and Dia, Ousmane and Li, Yixuan},
  year = {2023},
  eprint = {2203.04450},
  eprinttype = {arxiv},
  url = {http://arxiv.org/abs/2203.04450},
  urldate = {2023-03-24},
  pubstate = {preprint}
}

@inproceedings{sunOutofDistributionDetectionDeep2022,
  title = {Out-of-{{Distribution Detection}} with {{Deep Nearest Neighbors}}},
  booktitle = {Proceedings of the 39th {{International Conference}} on {{Machine Learning}}},
  author = {Sun, Yiyou and Ming, Yifei and Zhu, Xiaojin and Li, Yixuan},
  year = {2022},
  pages = {20827--20840},
  publisher = {PMLR},
  issn = {2640-3498},
  url = {https://proceedings.mlr.press/v162/sun22d.html},
  urldate = {2023-03-24},
  eventtitle = {International {{Conference}} on {{Machine Learning}}},
  langid = {english}
}

@online{dosovitskiyImageWorth16x162021,
  title = {An {{Image}} Is {{Worth}} 16x16 {{Words}}: {{Transformers}} for {{Image Recognition}} at {{Scale}}},
  shorttitle = {An {{Image}} Is {{Worth}} 16x16 {{Words}}},
  author = {Dosovitskiy, Alexey and Beyer, Lucas and Kolesnikov, Alexander and Weissenborn, Dirk and Zhai, Xiaohua and Unterthiner, Thomas and Dehghani, Mostafa and Minderer, Matthias and Heigold, Georg and Gelly, Sylvain and Uszkoreit, Jakob and Houlsby, Neil},
  year = {2021},
  eprint = {2010.11929},
  eprinttype = {arxiv},
  doi = {10.48550/arXiv.2010.11929},
  url = {http://arxiv.org/abs/2010.11929},
  urldate = {2024-03-11},
  pubstate = {preprint}
}

@inproceedings{xieAggregatedResidualTransformations2017,
  title = {Aggregated {{Residual Transformations}} for {{Deep Neural Networks}}},
  author = {Xie, Saining and Girshick, Ross and Dollar, Piotr and Tu, Zhuowen and He, Kaiming},
  year = {2017},
  pages = {1492--1500},
  url = {https://openaccess.thecvf.com/content_cvpr_2017/html/Xie_Aggregated_Residual_Transformations_CVPR_2017_paper.html},
  urldate = {2024-05-02},
  booktitle = {Proceedings of the {{IEEE Conference}} on {{Computer Vision}} and {{Pattern Recognition}}}
}



@misc{devlin2019bert,
      title={BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding}, 
      author={Jacob Devlin and Ming-Wei Chang and Kenton Lee and Kristina Toutanova},
      year={2019},
      eprint={1810.04805},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@inproceedings{liBLIPBootstrappingLanguageImage2022,
  title = {{{BLIP}}: {{Bootstrapping Language-Image Pre-training}} for {{Unified Vision-Language Understanding}} and {{Generation}}},
  shorttitle = {{{BLIP}}},
  booktitle = {Proceedings of the 39th {{International Conference}} on {{Machine Learning}}},
  author = {Li, Junnan and Li, Dongxu and Xiong, Caiming and Hoi, Steven},
  year = {2022},
  pages = {12888--12900},
  publisher = {PMLR},
  url = {https://proceedings.mlr.press/v162/li22n.html},
  urldate = {2023-11-13},
  eventtitle = {International {{Conference}} on {{Machine Learning}}},
  langid = {english}
}


@inproceedings{vanhornINaturalistSpeciesClassification2018,
  title = {The {{INaturalist Species Classification}} and {{Detection Dataset}}},
  author = {Van Horn, Grant and Mac Aodha, Oisin and Song, Yang and Cui, Yin and Sun, Chen and Shepard, Alex and Adam, Hartwig and Perona, Pietro and Belongie, Serge},
  year = {2018},
  pages = {8769--8778},
  url = {https://openaccess.thecvf.com/content_cvpr_2018/html/Van_Horn_The_INaturalist_Species_CVPR_2018_paper.html},
  urldate = {2024-05-02},
  booktitle = {Proceedings of the {{IEEE Conference}} on {{Computer Vision}} and {{Pattern Recognition}}}
}

@article{daiInstructBLIPGeneralpurposeVisionLanguage2023a,
  title = {{{InstructBLIP}}: {{Towards General-purpose Vision-Language Models}} with {{Instruction Tuning}}},
  shorttitle = {{{InstructBLIP}}},
  author = {Dai, Wenliang and Li, Junnan and Li, Dongxu and Tiong, Anthony and Zhao, Junqi and Wang, Weisheng and Li, Boyang and Fung, Pascale N. and Hoi, Steven},
  year = {2023},
  journal = {Advances in Neural Information Processing Systems},
  volume = {36},
  pages = {49250--49267},
  url = {https://proceedings.neurips.cc/paper_files/paper/2023/hash/9a6a435e75419a836fe47ab6793623e6-Abstract-Conference.html},
  urldate = {2024-05-02},
  langid = {english}
}

@inproceedings{netzerReadingDigitsNatural2011,
  title = {Reading Digits in Natural Images with Unsupervised Feature Learning},
  booktitle = {{{NIPS}} Workshop on Deep Learning and Unsupervised Feature Learning},
  author = {Netzer, Yuval and Wang, Tao and Coates, Adam and Bissacco, Alessandro and Wu, Baolin and Ng, Andrew Y.},
  year = {2011},
  volume = {2011},
  pages = {7},
  publisher = {Granada, Spain},
  url = {http://research.google.com/pubs/archive/37648.pdf},
  urldate = {2024-05-03}
}

@article{krizhevskyLearningMultipleLayers2009,
  title = {Learning Multiple Layers of Features from Tiny Images},
  author = {Krizhevsky, Alex and Hinton, Geoffrey},
  year = {2009},
  url = {http://www.cs.utoronto.ca/~kriz/learning-features-2009-TR.pdf},
  urldate = {2024-05-03}
}

@article{zhouPlaces10Million2017,
  title = {Places: {{A}} 10 Million Image Database for Scene Recognition},
  shorttitle = {Places},
  author = {Zhou, Bolei and Lapedriza, Agata and Khosla, Aditya and Oliva, Aude and Torralba, Antonio},
  year = {2017},
  journal = {IEEE transactions on pattern analysis and machine intelligence},
  volume = {40},
  number = {6},
  pages = {1452--1464},
  url = {https://ieeexplore.ieee.org/abstract/document/7968387/},
  urldate = {2024-05-03}
}

@inproceedings{cimpoiDescribingTexturesWild2014,
  title = {Describing {{Textures}} in the {{Wild}}},
  author = {Cimpoi, Mircea and Maji, Subhransu and Kokkinos, Iasonas and Mohamed, Sammy and Vedaldi, Andrea},
  year = {2014},
  pages = {3606--3613},
  url = {https://openaccess.thecvf.com/content_cvpr_2014/html/Cimpoi_Describing_Textures_in_2014_CVPR_paper.html},
  urldate = {2024-05-03},
  booktitle = {Proceedings of the {{IEEE Conference}} on {{Computer Vision}} and {{Pattern Recognition}}}
}

@online{yuLSUNConstructionLargescale2016,
  title = {{{LSUN}}: {{Construction}} of a {{Large-scale Image Dataset}} Using {{Deep Learning}} with {{Humans}} in the {{Loop}}},
  shorttitle = {{{LSUN}}},
  author = {Yu, Fisher and Seff, Ari and Zhang, Yinda and Song, Shuran and Funkhouser, Thomas and Xiao, Jianxiong},
  year = {2016-06-04},
  eprint = {1506.03365},
  eprinttype = {arxiv},
  url = {http://arxiv.org/abs/1506.03365},
  urldate = {2024-05-03},
  pubstate = {preprint}
}

@online{xuTurkerGazeCrowdsourcingSaliency2015,
  title = {{{TurkerGaze}}: {{Crowdsourcing Saliency}} with {{Webcam}} Based {{Eye Tracking}}},
  shorttitle = {{{TurkerGaze}}},
  author = {Xu, Pingmei and Ehinger, Krista A. and Zhang, Yinda and Finkelstein, Adam and Kulkarni, Sanjeev R. and Xiao, Jianxiong},
  year = {2015-05-20},
  eprint = {1504.06755},
  eprinttype = {arxiv},
  url = {http://arxiv.org/abs/1504.06755},
  urldate = {2024-05-03},
  pubstate = {preprint}
}

@inproceedings{devlinBERTPretrainingDeep2019,
  title = {{{BERT}}: {{Pre-training}} of {{Deep Bidirectional Transformers}} for {{Language Understanding}}},
  shorttitle = {{{BERT}}},
  booktitle = {Proceedings of the 2019 {{Conference}} of the {{North American Chapter}} of the {{Association}} for {{Computational Linguistics}}: {{Human Language Technologies}}, {{Volume}} 1 ({{Long}} and {{Short Papers}})},
  author = {Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
  year = {2019},
  pages = {4171--4186},
  publisher = {{Association for Computational Linguistics}},
  location = {{Minneapolis, Minnesota}},
  doi = {10.18653/v1/N19-1423},
  url = {https://aclanthology.org/N19-1423},
  urldate = {2023-10-17},
  conference = {{{NAACL-HLT}} 2019},
}

@inproceedings{zhongImprovingCalibrationLongtailed2021,
  title = {Improving Calibration for Long-Tailed Recognition},
  booktitle = {Proceedings of the {{IEEE}}/{{CVF Conference}} on {{Computer Vision}} and {{Pattern Recognition}}},
  author = {Zhong, Zhisheng and Cui, Jiequan and Liu, Shu and Jia, Jiaya},
  year = {2021},
  pages = {16489--16498}
}

@inproceedings{renBalancedMetaSoftmaxLongTailed2020,
  title = {Balanced {{Meta-Softmax}} for {{Long-Tailed Visual Recognition}}},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  author = {Ren, Jiawei and Yu, Cunjun and {sheng}, shunan and Ma, Xiao and Zhao, Haiyu and Yi, Shuai and Li, hongsheng},
  year = {2020},
  volume = {33},
  pages = {4175--4186},
  publisher = {Curran Associates, Inc.},
  url = {https://proceedings.neurips.cc/paper_files/paper/2020/hash/2ba61cc3a8f44143e1f2f13b2b729ab3-Abstract.html},
  urldate = {2024-05-07}
}

@inproceedings{huangLearningDeepRepresentation2016,
  title = {Learning {{Deep Representation}} for {{Imbalanced Classification}}},
  author = {Huang, Chen and Li, Yining and Loy, Chen Change and Tang, Xiaoou},
  year = {2016},
  pages = {5375--5384},
  url = {https://openaccess.thecvf.com/content_cvpr_2016/html/Huang_Learning_Deep_Representation_CVPR_2016_paper.html},
  urldate = {2024-05-07},
  booktitle = {Proceedings of the {{IEEE Conference}} on {{Computer Vision}} and {{Pattern Recognition}}}
}

@inproceedings{caiAceAllyComplementary2021,
  title = {Ace: {{Ally}} Complementary Experts for Solving Long-Tailed Recognition in One-Shot},
  shorttitle = {Ace},
  booktitle = {Proceedings of the {{IEEE}}/{{CVF International Conference}} on {{Computer Vision}}},
  author = {Cai, Jiarui and Wang, Yizhou and Hwang, Jenq-Neng},
  year = {2021},
  pages = {112--121}
}

@inproceedings{wangLongtailedRecognitionRouting2020,
  title = {Long-Tailed {{Recognition}} by {{Routing Diverse Distribution-Aware Experts}}},
  booktitle = {International {{Conference}} on {{Learning Representations}}},
  author = {Wang, Xudong and Lian, Long and Miao, Zhongqi and Liu, Ziwei and Yu, Stella},
  year = {2020},
  url = {https://openreview.net/forum?id=D9I3drBz4UC},
  urldate = {2021-11-03},
  eventtitle = {International {{Conference}} on {{Learning Representations}}},
  langid = {english}
}

@inproceedings{cuiParametricContrastiveLearning2021,
  title = {Parametric {{Contrastive Learning}}},
  author = {Cui, Jiequan and Zhong, Zhisheng and Liu, Shu and Yu, Bei and Jia, Jiaya},
  year = {2021},
  pages = {715--724},
  url = {https://openaccess.thecvf.com/content/ICCV2021/html/Cui_Parametric_Contrastive_Learning_ICCV_2021_paper.html},
  urldate = {2022-06-08},
  booktitle = {Proceedings of the {{IEEE}}/{{CVF International Conference}} on {{Computer Vision}}},
  langid = {english}
}

@inproceedings{liNestedCollaborativeLearning2022,
  title = {Nested {{Collaborative Learning}} for {{Long-Tailed Visual Recognition}}},
  author = {Li, Jun and Tan, Zichang and Wan, Jun and Lei, Zhen and Guo, Guodong},
  year = {2022},
  pages = {6949--6958},
  url = {https://openaccess.thecvf.com/content/CVPR2022/html/Li_Nested_Collaborative_Learning_for_Long-Tailed_Visual_Recognition_CVPR_2022_paper.html},
  urldate = {2024-05-07},
  booktitle = {Proceedings of the {{IEEE}}/{{CVF Conference}} on {{Computer Vision}} and {{Pattern Recognition}}},
  langid = {english}
}

@inproceedings{longMutualExclusiveModulator2023,
  title = {Mutual {{Exclusive Modulator}} for {{Long-Tailed Recognition}}},
  author = {Long, Haixu and Zhang, Xiaolin and Liu, Yanbin and Luo, Zongtai and Liu, Jianbo},
  year = {2023},
  pages = {4891--4900},
  url = {https://openaccess.thecvf.com/content/CVPR2023W/L3D-IVU/html/Long_Mutual_Exclusive_Modulator_for_Long-Tailed_Recognition_CVPRW_2023_paper.html},
  urldate = {2024-04-16},
  booktitle = {Proceedings of the {{IEEE}}/{{CVF Conference}} on {{Computer Vision}} and {{Pattern Recognition}}},
  langid = {english}
}

@inproceedings{kangDecouplingRepresentationClassifier2019,
  title = {Decoupling {{Representation}} and {{Classifier}} for {{Long-Tailed Recognition}}},
  booktitle = {Eighth {{International Conference}} on {{Learning Representations}} ({{ICLR}})},
  author = {Kang, Bingyi and Xie, Saining and Rohrbach, Marcus and Yan, Zhicheng and Gordo, Albert and Feng, Jiashi and Kalantidis, Yannis},
  year = {2019},
  url = {https://openreview.net/forum?id=r1gRTCVFvB},
  urldate = {2021-11-03},
  eventtitle = {International {{Conference}} on {{Learning Representations}}},
  langid = {english}
}

@inproceedings{kimProxyAnchorLoss2020,
  title = {Proxy {{Anchor Loss}} for {{Deep Metric Learning}}},
  author = {Kim, Sungyeon and Kim, Dongwon and Cho, Minsu and Kwak, Suha},
  year = {2020},
  pages = {3238--3247},
  url = {https://openaccess.thecvf.com/content_CVPR_2020/html/Kim_Proxy_Anchor_Loss_for_Deep_Metric_Learning_CVPR_2020_paper.html},
  urldate = {2024-05-08},
  booktitle = {Proceedings of the {{IEEE}}/{{CVF Conference}} on {{Computer Vision}} and {{Pattern Recognition}}}
}

@online{winkensContrastiveTrainingImproved2020,
  title = {Contrastive {{Training}} for {{Improved Out-of-Distribution Detection}}},
  author = {Winkens, Jim and Bunel, Rudy and Roy, Abhijit Guha and Stanforth, Robert and Natarajan, Vivek and Ledsam, Joseph R. and MacWilliams, Patricia and Kohli, Pushmeet and Karthikesalingam, Alan and Kohl, Simon and Cemgil, Taylan and Eslami, S. M. Ali and Ronneberger, Olaf},
  year = {2020-07-10},
  eprint = {2007.05566},
  eprinttype = {arxiv},
  doi = {10.48550/arXiv.2007.05566},
  url = {http://arxiv.org/abs/2007.05566},
  urldate = {2024-05-08},
  pubstate = {preprint}
}

@inproceedings{tackCSINoveltyDetection2020,
  title = {{{CSI}}: {{Novelty Detection}} via {{Contrastive Learning}} on {{Distributionally Shifted Instances}}},
  shorttitle = {{{CSI}}},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  author = {Tack, Jihoon and Mo, Sangwoo and Jeong, Jongheon and Shin, Jinwoo},
  year = {2020},
  volume = {33},
  pages = {11839--11852},
  publisher = {Curran Associates, Inc.},
  url = {https://proceedings.neurips.cc/paper/2020/hash/8965f76632d7672e7d3cf29c87ecaa0c-Abstract.html},
  urldate = {2024-05-08}
}


@inproceedings{sehwagSSDUnifiedFramework2020,
  title = {{{SSD}}: {{A Unified Framework}} for {{Self-Supervised Outlier Detection}}},
  shorttitle = {{{SSD}}},
  author = {Sehwag, Vikash and Chiang, Mung and Mittal, Prateek},
  year = {2021},
  url = {https://openreview.net/forum?id=v5gjXpmR8J},
  urldate = {2024-05-08},
  booktitle = {International {{Conference}} on {{Learning Representations}}},
  langid = {english}
}



@article{ILSVRC15,
Author = {Olga Russakovsky and Jia Deng and Hao Su and Jonathan Krause and Sanjeev Satheesh and Sean Ma and Zhiheng Huang and Andrej Karpathy and Aditya Khosla and Michael Bernstein and Alexander C. Berg and Li Fei-Fei},
Title = {{ImageNet Large Scale Visual Recognition Challenge}},
Year = {2015},
journal   = {International Journal of Computer Vision (IJCV)},
doi = {10.1007/s11263-015-0816-y},
volume={115},
number={3},
pages={211-252}
}


@inproceedings{kobayashiTvMFSimilarityRegularizing2021,
  title = {T-{{vMF Similarity For Regularizing Intra-Class Feature Distribution}}},
  booktitle = {2021 {{IEEE}}/{{CVF Conference}} on {{Computer Vision}} and {{Pattern Recognition}} ({{CVPR}})},
  author = {Kobayashi, Takumi},
  year = {2021-06},
  pages = {6612--6621},
  publisher = {IEEE},
  location = {Nashville, TN, USA},
  doi = {10.1109/CVPR46437.2021.00655},
  url = {https://ieeexplore.ieee.org/document/9578219/},
  urldate = {2022-02-21},
  eventtitle = {2021 {{IEEE}}/{{CVF Conference}} on {{Computer Vision}} and {{Pattern Recognition}} ({{CVPR}})},
  isbn = {978-1-66544-509-2},
  langid = {english}
}


@inproceedings{koryckiConceptDriftDetection2021,
  title = {Concept {{Drift Detection}} from {{Multi-Class Imbalanced Data Streams}}},
  booktitle = {2021 {{IEEE}} 37th {{International Conference}} on {{Data Engineering}} ({{ICDE}})},
  author = {Korycki, Lukasz and Krawczyk, Bartosz},
  year = {2021-04},
  pages = {1068--1079},
  doi = {10.1109/ICDE51399.2021.00097},
  url = {https://ieeexplore.ieee.org/abstract/document/9458692},
  urldate = {2024-03-14},
  eventtitle = {2021 {{IEEE}} 37th {{International Conference}} on {{Data Engineering}} ({{ICDE}})}
}


@article{liuComprehensiveActiveLearning2021,
  title = {A Comprehensive Active Learning Method for Multiclass Imbalanced Data Streams with Concept Drift},
  author = {Liu, Weike and Zhang, Hang and Ding, Zhaoyun and Liu, Qingbao and Zhu, Cheng},
  year = {2021},
  journal = {Knowledge-Based Systems},
  shortjournal = {Knowledge-Based Systems},
  volume = {215},
  pages = {106778},
  issn = {0950-7051},
  doi = {10.1016/j.knosys.2021.106778},
  url = {https://www.sciencedirect.com/science/article/pii/S0950705121000411},
  urldate = {2024-05-20}
}


@ARTICLE{9802893,
  author={Jiao, Botao and Guo, Yinan and Gong, Dunwei and Chen, Qiuju},
  journal={IEEE Transactions on Neural Networks and Learning Systems}, 
  title={Dynamic Ensemble Selection for Imbalanced Data Streams With Concept Drift}, 
  year={2024},
  volume={35},
  number={1},
  pages={1278-1291},
  keywords={Training;Bagging;Adaptation models;Data models;Learning systems;Control engineering;Sun;Concept drift;data stream;dynamic ensemble selection (DES);imbalance learning;oversampling},
  doi={10.1109/TNNLS.2022.3183120}
  }


@article{taghiaBayesianEstimationVonMises2014,
  title = {Bayesian {{Estimation}} of the Von-{{Mises Fisher Mixture Model}} with {{Variational Inference}}},
  author = {Taghia, Jalil and Ma, Zhanyu and Leijon, Arne},
  year = {2014-09},
  journaltitle = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  volume = {36},
  number = {9},
  pages = {1701--1715},
  issn = {1939-3539},
  doi = {10.1109/TPAMI.2014.2306426}
}

@article{zheDirectionalStatisticsbasedDeep2019,
  title = {Directional Statistics-Based Deep Metric Learning for Image Classification and Retrieval},
  author = {Zhe, Xuefei and Chen, Shifeng and Yan, Hong},
  year = {2019-09-01},
  journaltitle = {Pattern Recognition},
  shortjournal = {Pattern Recognition},
  volume = {93},
  pages = {113--123},
  issn = {0031-3203},
  doi = {10.1016/j.patcog.2019.04.005},
  url = {https://www.sciencedirect.com/science/article/pii/S0031320319301451},
  urldate = {2021-09-17},
  langid = {english}
}



@article{de2020power,
  title={The power spherical distribution},
  author={De Cao, Nicola and Aziz, Wilker},
  journal={arXiv preprint arXiv:2006.04437},
  year={2020}
}

@inproceedings{yu2024online,
  title={Online Boosting Adaptive Learning under Concept Drift for Multistream Classification},
  author={Yu, En and Lu, Jie and Zhang, Bin and Zhang, Guangquan},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={38},
  number={15},
  pages={16522--16530},
  year={2024}
}


@article{jiao2022reduced,
  title={Reduced-space Multistream Classification based on Multi-objective Evolutionary Optimization},
  author={Jiao, Botao and Guo, Yinan and Yang, Shengxiang and Pu, Jiayang and Gong, Dunwei},
  journal={IEEE Transactions on Evolutionary Computation},
  year={2022},
  publisher={IEEE}
}

@inproceedings{hendrycksBaselineDetectingMisclassified2022,
  title = {A {{Baseline}} for {{Detecting Misclassified}} and {{Out-of-Distribution Examples}} in {{Neural Networks}}},
  author = {Hendrycks, Dan and Gimpel, Kevin},
  year = {2022-07-21},
  url = {https://openreview.net/forum?id=Hkg4TI9xl},
  urldate = {2024-05-21},
  eventtitle = {International {{Conference}} on {{Learning Representations}}},
  langid = {english}
}


@inproceedings{liangEnhancingReliabilityOutofdistribution2018,
  title = {Enhancing {{The Reliability}} of {{Out-of-distribution Image Detection}} in {{Neural Networks}}},
  author = {Liang, Shiyu and Li, Yixuan and Srikant, R.},
  year = {2018},
  url = {https://openreview.net/forum?id=H1VGkIxRZ},
  urldate = {2024-05-21},
  booktitle = {International {{Conference}} on {{Learning Representations}}},
  langid = {english}
}

@inproceedings{liuEnergybasedOutofdistributionDetection2020a,
  title = {Energy-Based {{Out-of-distribution Detection}}},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  author = {Liu, Weitang and Wang, Xiaoyun and Owens, John and Li, Yixuan},
  year = {2020},
  volume = {33},
  pages = {21464--21475},
  publisher = {Curran Associates, Inc.},
  url = {https://proceedings.neurips.cc/paper/2020/hash/f5496252609c43eb8a3d147ab9b9c006-Abstract.html},
  urldate = {2024-05-21}
}

@inproceedings{hsuGeneralizedODINDetecting2020,
  title = {Generalized {{ODIN}}: {{Detecting Out-of-Distribution Image Without Learning From Out-of-Distribution Data}}},
  shorttitle = {Generalized {{ODIN}}},
  author = {Hsu, Yen-Chang and Shen, Yilin and Jin, Hongxia and Kira, Zsolt},
  year = {2020},
  pages = {10951--10960},
  url = {https://openaccess.thecvf.com/content_CVPR_2020/html/Hsu_Generalized_ODIN_Detecting_Out-of-Distribution_Image_Without_Learning_From_Out-of-Distribution_Data_CVPR_2020_paper.html},
  urldate = {2024-05-21},
  eventtitle = {Proceedings of the {{IEEE}}/{{CVF Conference}} on {{Computer Vision}} and {{Pattern Recognition}}}
}

@inproceedings{weiMitigatingNeuralNetwork2022a,
  title = {Mitigating {{Neural Network Overconfidence}} with {{Logit Normalization}}},
  booktitle = {Proceedings of the 39th {{International Conference}} on {{Machine Learning}}},
  author = {Wei, Hongxin and Xie, Renchunzi and Cheng, Hao and Feng, Lei and An, Bo and Li, Yixuan},
  year = {2022-06-28},
  pages = {23631--23644},
  publisher = {PMLR},
  issn = {2640-3498},
  url = {https://proceedings.mlr.press/v162/wei22d.html},
  urldate = {2024-05-21},
  eventtitle = {International {{Conference}} on {{Machine Learning}}},
  langid = {english}
}

@inproceedings{leeSimpleUnifiedFramework2018,
  title = {A {{Simple Unified Framework}} for {{Detecting Out-of-Distribution Samples}} and {{Adversarial Attacks}}},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  author = {Lee, Kimin and Lee, Kibok and Lee, Honglak and Shin, Jinwoo},
  year = {2018},
  volume = {31},
  publisher = {Curran Associates, Inc.},
  url = {https://proceedings.neurips.cc/paper/2018/hash/abdeb6f575ac5c6676b747bca8d09cc2-Abstract.html},
  urldate = {2024-05-21}
}



@article{salaberriaImageCaptioningEffective2023,
  title = {Image Captioning for Effective Use of Language Models in Knowledge-Based Visual Question Answering},
  author = {Salaberria, Ander and Azkune, Gorka and Lopez de Lacalle, Oier and Soroa, Aitor and Agirre, Eneko},
  year = {2023-02-01},
  journaltitle = {Expert Systems with Applications},
  shortjournal = {Expert Systems with Applications},
  volume = {212},
  pages = {118669},
  issn = {0957-4174},
  doi = {10.1016/j.eswa.2022.118669},
  url = {https://www.sciencedirect.com/science/article/pii/S0957417422017055},
  urldate = {2023-11-16},
  abstract = {Integrating outside knowledge for reasoning in visio-linguistic tasks such as visual question answering (VQA) is an open problem. Given that pretrained language models have been shown to include world knowledge, we propose to use a unimodal (text-only) train and inference procedure based on automatic off-the-shelf captioning of images and pretrained language models. More specifically, we verbalize the image contents and allow language models to better leverage their implicit knowledge to solve knowledge-intensive tasks. Focusing on a visual question answering task which requires external knowledge (OK-VQA), our contributions are: (i) a text-only model that outperforms pretrained multimodal (image-text) models of comparable number of parameters; (ii) confirmation that our text-only method is specially effective for tasks requiring external knowledge, as it is less effective in standard a VQA task (VQA 2.0); and (iii) our method attains results in the state-of-the-art when increasing the size of the language model. We also significantly outperform current multimodal systems, even though augmented with external knowledge. Our qualitative analysis on OK-VQA reveals that automatic captions often fail to capture relevant information in the images, which seems to be balanced by the better inference ability of the text-only language models. Our work opens up possibilities to further improve inference in visio-linguistic tasks.},
  keywords = {Deep learning,Image captioning,Language models,Visual question answering},
}


@online{chungScalingInstructionFinetunedLanguage2022,
  title = {Scaling {{Instruction-Finetuned Language Models}}},
  author = {Chung, Hyung Won and Hou, Le and Longpre, Shayne and Zoph, Barret and Tay, Yi and Fedus, William and Li, Yunxuan and Wang, Xuezhi and Dehghani, Mostafa and Brahma, Siddhartha and Webson, Albert and Gu, Shixiang Shane and Dai, Zhuyun and Suzgun, Mirac and Chen, Xinyun and Chowdhery, Aakanksha and Castro-Ros, Alex and Pellat, Marie and Robinson, Kevin and Valter, Dasha and Narang, Sharan and Mishra, Gaurav and Yu, Adams and Zhao, Vincent and Huang, Yanping and Dai, Andrew and Yu, Hongkun and Petrov, Slav and Chi, Ed H. and Dean, Jeff and Devlin, Jacob and Roberts, Adam and Zhou, Denny and Le, Quoc V. and Wei, Jason},
  year = {2022-12-06},
  eprint = {2210.11416},
  eprinttype = {arxiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2210.11416},
  url = {http://arxiv.org/abs/2210.11416},
  urldate = {2023-11-15},
  pubstate = {preprint},
  keywords = {Computer Science - Computation and Language,Computer Science - Machine Learning},
}


@online{kirillovSegmentAnything2023,
  title = {Segment {{Anything}}},
  author = {Kirillov, Alexander and Mintun, Eric and Ravi, Nikhila and Mao, Hanzi and Rolland, Chloe and Gustafson, Laura and Xiao, Tete and Whitehead, Spencer and Berg, Alexander C. and Lo, Wan-Yen and Dollár, Piotr and Girshick, Ross},
  year = {2023-04-05},
  eprint = {2304.02643},
  eprinttype = {arxiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2304.02643},
  url = {http://arxiv.org/abs/2304.02643},
  urldate = {2023-11-08},
  pubstate = {preprint},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning},
}


@inproceedings{zhuUnpairedImagetoimageTranslation2017,
  title = {Unpaired Image-to-Image Translation Using Cycle-Consistent Adversarial Networks},
  booktitle = {Proceedings of the {{IEEE}} International Conference on Computer Vision},
  author = {Zhu, Jun-Yan and Park, Taesung and Isola, Phillip and Efros, Alexei A.},
  year = {2017},
  pages = {2223--2232},
  keywords = {GAN,GD,Generation,JPG,Methods},
  annotation = {Methods: GAN-CycleGAN},
}


@inproceedings{girshickFastRCNN2015,
  title = {Fast {{R-CNN}}},
  author = {Girshick, Ross},
  year = {2015},
  pages = {1440--1448},
  url = {https://openaccess.thecvf.com/content_iccv_2015/html/Girshick_Fast_R-CNN_ICCV_2015_paper.html},
  urldate = {2023-11-04},
  conference = {Proceedings of the {{IEEE International Conference}} on {{Computer Vision}}},
}


@online{redmonYOLOv3IncrementalImprovement2018,
  title = {{{YOLOv3}}: {{An Incremental Improvement}}},
  shorttitle = {{{YOLOv3}}},
  author = {Redmon, Joseph and Farhadi, Ali},
  year = {2018-04-08},
  eprint = {1804.02767},
  eprinttype = {arxiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.1804.02767},
  url = {http://arxiv.org/abs/1804.02767},
  urldate = {2023-11-04},
  abstract = {We present some updates to YOLO! We made a bunch of little design changes to make it better. We also trained this new network that's pretty swell. It's a little bigger than last time but more accurate. It's still fast though, don't worry. At 320x320 YOLOv3 runs in 22 ms at 28.2 mAP, as accurate as SSD but three times faster. When we look at the old .5 IOU mAP detection metric YOLOv3 is quite good. It achieves 57.9 mAP@50 in 51 ms on a Titan X, compared to 57.5 mAP@50 in 198 ms by RetinaNet, similar performance but 3.8x faster. As always, all the code is online at https://pjreddie.com/yolo/},
  pubstate = {preprint},
  keywords = {Computer Science - Computer Vision and Pattern Recognition}
}


@inproceedings{tanEfficientNetRethinkingModel2019,
  title = {{{EfficientNet}}: {{Rethinking Model Scaling}} for {{Convolutional Neural Networks}}},
  shorttitle = {{{EfficientNet}}},
  booktitle = {Proceedings of the 36th {{International Conference}} on {{Machine Learning}}},
  author = {Tan, Mingxing and Le, Quoc},
  year = {2019-05-24},
  pages = {6105--6114},
  publisher = {{PMLR}},
  url = {https://proceedings.mlr.press/v97/tan19a.html},
  urldate = {2023-11-04},
  abstract = {Convolutional Neural Networks (ConvNets) are commonly developed at a fixed resource budget, and then scaled up for better accuracy if more resources are given. In this paper, we systematically study model scaling and identify that carefully balancing network depth, width, and resolution can lead to better performance. Based on this observation, we propose a new scaling method that uniformly scales all dimensions of depth/width/resolution using a simple yet highly effective compound coefficient. We demonstrate the effectiveness of this method on MobileNets and ResNet. To go even further, we use neural architecture search to design a new baseline network and scale it up to obtain a family of models, called EfficientNets, which achieve much better accuracy and efficiency than previous ConvNets. In particular, our EfficientNet-B7 achieves stateof-the-art 84.4\% top-1 / 97.1\% top-5 accuracy on ImageNet, while being 8.4x smaller and 6.1x faster on inference than the best existing ConvNet (Huang et al., 2018). Our EfficientNets also transfer well and achieve state-of-the-art accuracy on CIFAR-100 (91.7\%), Flower (98.8\%), and 3 other transfer learning datasets, with an order of magnitude fewer parameters.},
  conference = {International {{Conference}} on {{Machine Learning}}},
  langid = {english},
  annotation = {object-cxr},
}


@article{zhengTimNetTextimageMatching2021,
  title = {{{TimNet}}: A Text-Image Matching Network Integrating Multi-Stage Feature Extraction with Multi-Scale Metrics},
  shorttitle = {{{TimNet}}},
  author = {Zheng, Xiaoqi and Tao, Yingfan and Zhang, Ruikai and Yang, Wenming and Liao, Qingmin},
  year = {2021},
  journaltitle = {Neurocomputing},
  volume = {465},
  pages = {540--548},
  url = {https://www.sciencedirect.com/science/article/pii/S0925231221013552},
  urldate = {2023-11-04},
  annotation = {object-CXR}
}



@article{objectcxr,
title= {Object-CXR - Automatic detection of foreign objects on chest X-rays},
keywords= {radiology},
author= {JF Healthcare},
abstract= {## Data
5000 frontal chest X-ray images with foreign objects presented and 5000 frontal chest X-ray images without foreign objects were filmed and collected from about 300 township hosiptials in China. 12 medically-trained radiologists with 1 to 3 years of experience annotated all the images. Each annotator manually annotates the potential foreign objects on a given chest X-ray presented within the lung field. Foreign objects were annotated with bounding boxes, bounding ellipses or masks depending on the shape of the objects. Support devices were excluded from annotation. A typical frontal chest X-ray with foreign objects annotated looks like this:

https://i.imgur.com/SFUZy80.jpg


## Annotation

Object-level annotations for each image, which indicate the rough location of each foreign object using a closed shape.

Annotations are provided in csv files and a csv example is shown below.

```csv
image_path,annotation
/path/#####.jpg,ANNO_TYPE_IDX x1 y1 x2 y2;ANNO_TYPE_IDX x1 y1 x2 y2 ... xn yn;...
/path/#####.jpg,
/path/#####.jpg,ANNO_TYPE_IDX x1 y1 x2 y2
...
```

Three type of shapes are used namely rectangle, ellipse and polygon. We use `0`, `1` and `2` as `ANNO_TYPE_IDX` respectively.

- For rectangle and ellipse annotations, we provide the bounding box (upper left and lower right) coordinates in the format `x1 y1 x2 y2` where `x1` < `x2` and `y1` < `y2`.

- For polygon annotations, we provide a sequence of coordinates in the format `x1 y1 x2 y2 ... xn yn`.

> ### Note:
> Our annotations use a Cartesian pixel coordinate system, with the origin (0,0) in the upper left corner. The x coordinate extends from left to right; the y coordinate extends downward.

## Organizers
[JF Healthcare](http://www.jfhealthcare.com/) is the primary organizer of this challenge.
},
terms= {},
license= {https://creativecommons.org/licenses/by-nc/4.0/},
superseded= {},
url= {https://web.archive.org/web/20201127235812/https://jfhealthcare.github.io/object-CXR/}
}



@inproceedings{nagarajaModelingContextObjects2016,
  title = {Modeling {{Context Between Objects}} for {{Referring Expression Understanding}}},
  booktitle = {Computer {{Vision}} – {{ECCV}} 2016},
  author = {Nagaraja, Varun K. and Morariu, Vlad I. and Davis, Larry S.},
  editor = {Leibe, Bastian and Matas, Jiri and Sebe, Nicu and Welling, Max},
  year = {2016},
  series = {Lecture {{Notes}} in {{Computer Science}}},
  pages = {792--807},
  publisher = {{Springer International Publishing}},
  location = {{Cham}},
  doi = {10.1007/978-3-319-46493-0_48},
  abstract = {Referring expressions usually describe an object using properties of the object and relationships of the object with other objects. We propose a technique that integrates context between objects to understand referring expressions. Our approach uses an LSTM to learn the probability of a referring expression, with input features from a region and a context region. The context regions are discovered using multiple-instance learning (MIL) since annotations for context objects are generally not available for training. We utilize max-margin based MIL objective functions for training the LSTM. Experiments on the Google RefExp and UNC RefExp datasets show that modeling context between objects provides better performance than modeling only object properties. We also qualitatively show that our technique can ground a referring expression to its referred region along with the supporting context region.},
  isbn = {978-3-319-46493-0},
  langid = {english},
  keywords = {Comprehension Task,Context Region,Loss Function,Multiple Instance Learn,Positive Instance},
}


@inproceedings{linMicrosoftCOCOCommon2014,
  title = {Microsoft {{COCO}}: {{Common Objects}} in {{Context}}},
  shorttitle = {Microsoft {{COCO}}},
  booktitle = {Computer {{Vision}} – {{ECCV}} 2014},
  author = {Lin, Tsung-Yi and Maire, Michael and Belongie, Serge and Hays, James and Perona, Pietro and Ramanan, Deva and Dollár, Piotr and Zitnick, C. Lawrence},
  editor = {Fleet, David and Pajdla, Tomas and Schiele, Bernt and Tuytelaars, Tinne},
  year = {2014},
  series = {Lecture {{Notes}} in {{Computer Science}}},
  pages = {740--755},
  publisher = {{Springer International Publishing}},
  location = {{Cham}},
  doi = {10.1007/978-3-319-10602-1_48},
  abstract = {We present a new dataset with the goal of advancing the state-of-the-art in object recognition by placing the question of object recognition in the context of the broader question of scene understanding. This is achieved by gathering images of complex everyday scenes containing common objects in their natural context. Objects are labeled using per-instance segmentations to aid in precise object localization. Our dataset contains photos of 91 objects types that would be easily recognizable by a 4 year old. With a total of 2.5 million labeled instances in 328k images, the creation of our dataset drew upon extensive crowd worker involvement via novel user interfaces for category detection, instance spotting and instance segmentation. We present a detailed statistical analysis of the dataset in comparison to PASCAL, ImageNet, and SUN. Finally, we provide baseline performance analysis for bounding box and segmentation detection results using a Deformable Parts Model.},
  isbn = {978-3-319-10602-1},
  langid = {english},
  keywords = {Common Object,Object Category,Object Detection,Object Instance,Scene Understanding},
}


@inproceedings{yuModelingContextReferring2016,
  title = {Modeling {{Context}} in {{Referring Expressions}}},
  booktitle = {Computer {{Vision}} – {{ECCV}} 2016},
  author = {Yu, Licheng and Poirson, Patrick and Yang, Shan and Berg, Alexander C. and Berg, Tamara L.},
  editor = {Leibe, Bastian and Matas, Jiri and Sebe, Nicu and Welling, Max},
  year = {2016},
  series = {Lecture {{Notes}} in {{Computer Science}}},
  pages = {69--85},
  publisher = {{Springer International Publishing}},
  location = {{Cham}},
  doi = {10.1007/978-3-319-46475-6_5},
  abstract = {Humans refer to objects in their environments all the time, especially in dialogue with other people. We explore generating and comprehending natural language referring expressions for objects in images. In particular, we focus on incorporating better measures of visual context into referring expression models and find that visual comparison to other objects within an image helps improve performance significantly. We also develop methods to tie the language generation process together, so that we generate expressions for all objects of a particular category jointly. Evaluation on three recent datasets - RefCOCO, RefCOCO+, and RefCOCOg (Datasets and toolbox can be downloaded from https://github.com/lichengunc/refer), shows the advantages of our methods for both referring expression generation and comprehension.},
  isbn = {978-3-319-46475-6},
  langid = {english},
  keywords = {Generation,Language,Language and vision,Referring expression generation},
}


@inproceedings{maoGenerationComprehensionUnambiguous2016,
  title = {Generation and Comprehension of Unambiguous Object Descriptions},
  booktitle = {Proceedings of the {{IEEE}} Conference on Computer Vision and Pattern Recognition},
  author = {Mao, Junhua and Huang, Jonathan and Toshev, Alexander and Camburu, Oana and Yuille, Alan L. and Murphy, Kevin},
  year = {2016},
  pages = {11--20},
  url = {http://openaccess.thecvf.com/content_cvpr_2016/html/Mao_Generation_and_Comprehension_CVPR_2016_paper.html},
  urldate = {2023-10-19},
  annotation = {Dataset - RefCOCOg}
}


@inproceedings{liu2020tbx11k,
    title={Rethinking computer-aided tuberculosis diagnosis},
    author={Liu, Yun and Wu, Yu-Huan and Ban, Yunfeng and Wang, Huifang and Cheng, Ming-Ming},
    booktitle={IEEE/CVF Conference on Computer Vision and Pattern Recognition},
    pages={2646--2655},
    year={2020}
  }
@inproceedings{wang2017chestx,
  title={Chestx-ray8: Hospital-scale chest x-ray database and benchmarks on weakly-supervised classification and localization of common thorax diseases},
  author={Wang, Xiaosong and Peng, Yifan and Lu, Le and Lu, Zhiyong and Bagheri, Mohammadhadi and Summers, Ronald M},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={2097--2106},
  year={2017}
}


@article{shih2019augmenting,
  title={Augmenting the national institutes of health chest radiograph dataset with expert annotations of possible pneumonia},
  author={Shih, George and Wu, Carol C and Halabi, Safwan S and Kohli, Marc D and Prevedello, Luciano M and Cook, Tessa S and Sharma, Arjun and Amorosa, Judith K and Arteaga, Veronica and Galperin-Aizenberg, Maya and others},
  journal={Radiology: Artificial Intelligence},
  volume={1},
  number={1},
  pages={e180041},
  year={2019},
  publisher={Radiological Society of North America}
}


@misc{vicuna2023,
    title = {Vicuna: An Open-Source Chatbot Impressing GPT-4 with 90\%* ChatGPT Quality},
    url = {https://lmsys.org/blog/2023-03-30-vicuna/},
    author = {Chiang, Wei-Lin and Li, Zhuohan and Lin, Zi and Sheng, Ying and Wu, Zhanghao and Zhang, Hao and Zheng, Lianmin and Zhuang, Siyuan and Zhuang, Yonghao and Gonzalez, Joseph E. and Stoica, Ion and Xing, Eric P.},
    month = {March},
    year = {2023}
}


@online{touvronLLaMAOpenEfficient2023,
  title = {{{LLaMA}}: {{Open}} and {{Efficient Foundation Language Models}}},
  shorttitle = {{{LLaMA}}},
  author = {Touvron, Hugo and Lavril, Thibaut and Izacard, Gautier and Martinet, Xavier and Lachaux, Marie-Anne and Lacroix, Timothée and Rozière, Baptiste and Goyal, Naman and Hambro, Eric and Azhar, Faisal and Rodriguez, Aurelien and Joulin, Armand and Grave, Edouard and Lample, Guillaume},
  year = {2023-02-27},
  eprint = {2302.13971},
  eprinttype = {arxiv},
  url = {http://arxiv.org/abs/2302.13971},
  urldate = {2023-10-18},
  abstract = {We introduce LLaMA, a collection of foundation language models ranging from 7B to 65B parameters. We train our models on trillions of tokens, and show that it is possible to train state-of-the-art models using publicly available datasets exclusively, without resorting to proprietary and inaccessible datasets. In particular, LLaMA-13B outperforms GPT-3 (175B) on most benchmarks, and LLaMA-65B is competitive with the best models, Chinchilla-70B and PaLM-540B. We release all our models to the research community.},
  pubstate = {preprint},
  keywords = {Computer Science - Computation and Language},
}







@misc{jiang2023clip,
      title={From CLIP to DINO: Visual Encoders Shout in Multi-modal Large Language Models}, 
      author={Dongsheng Jiang and Yuchen Liu and Songlin Liu and Xiaopeng Zhang and Jin Li and Hongkai Xiong and Qi Tian},
      year={2023},
      eprint={2310.08825},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@misc{chen2023shikra,
      title={Shikra: Unleashing Multimodal LLM's Referential Dialogue Magic}, 
      author={Keqin Chen and Zhao Zhang and Weili Zeng and Richong Zhang and Feng Zhu and Rui Zhao},
      year={2023},
      eprint={2306.15195},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@inproceedings{liuLearningAssembleNeural2019,
  title = {Learning to {{Assemble Neural Module Tree Networks}} for {{Visual Grounding}}},
  author = {Liu, Daqing and Zhang, Hanwang and Wu, Feng and Zha, Zheng-Jun},
  year = {2019},
  pages = {4673--4682},
  url = {https://openaccess.thecvf.com/content_ICCV_2019/html/Liu_Learning_to_Assemble_Neural_Module_Tree_Networks_for_Visual_Grounding_ICCV_2019_paper.html},
  urldate = {2023-10-10},
  conference = {Proceedings of the {{IEEE}}/{{CVF International Conference}} on {{Computer Vision}}},
}



@inproceedings{liuImprovingReferringExpression2019,
  title = {Improving {{Referring Expression Grounding With Cross-Modal Attention-Guided Erasing}}},
  author = {Liu, Xihui and Wang, Zihao and Shao, Jing and Wang, Xiaogang and Li, Hongsheng},
  year = {2019},
  pages = {1950--1959},
  url = {https://openaccess.thecvf.com/content_CVPR_2019/html/Liu_Improving_Referring_Expression_Grounding_With_Cross-Modal_Attention-Guided_Erasing_CVPR_2019_paper.html},
  urldate = {2023-10-10},
  conference = {Proceedings of the {{IEEE}}/{{CVF Conference}} on {{Computer Vision}} and {{Pattern Recognition}}},
}



@inproceedings{yangDynamicGraphAttention2019,
  title = {Dynamic {{Graph Attention}} for {{Referring Expression Comprehension}}},
  author = {Yang, Sibei and Li, Guanbin and Yu, Yizhou},
  year = {2019},
  pages = {4644--4653},
  url = {https://openaccess.thecvf.com/content_ICCV_2019/html/Yang_Dynamic_Graph_Attention_for_Referring_Expression_Comprehension_ICCV_2019_paper.html},
  urldate = {2023-10-10},
  conference = {Proceedings of the {{IEEE}}/{{CVF International Conference}} on {{Computer Vision}}},
}


@misc{vaswani2017attention,
      title={Attention Is All You Need}, 
      author={Ashish Vaswani and Noam Shazeer and Niki Parmar and Jakob Uszkoreit and Llion Jones and Aidan N. Gomez and Lukasz Kaiser and Illia Polosukhin},
      year={2017},
      eprint={1706.03762},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@online{xuMPLUG2ModularizedMultimodal2023,
  title = {{{mPLUG-2}}: {{A Modularized Multi-modal Foundation Model Across Text}}, {{Image}} and {{Video}}},
  shorttitle = {{{mPLUG-2}}},
  author = {Xu, Haiyang and Ye, Qinghao and Yan, Ming and Shi, Yaya and Ye, Jiabo and Xu, Yuanhong and Li, Chenliang and Bi, Bin and Qian, Qi and Wang, Wei and Xu, Guohai and Zhang, Ji and Huang, Songfang and Huang, Fei and Zhou, Jingren},
  year = {2023-02-01},
  eprint = {2302.00402},
  eprinttype = {arxiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2302.00402},
  url = {http://arxiv.org/abs/2302.00402},
  urldate = {2023-07-25}
}

@inproceedings{chen2020uniter,
  title={Uniter: Universal image-text representation learning},
  author={Chen, Yen-Chun and Li, Linjie and Yu, Licheng and El Kholy, Ahmed and Ahmed, Faisal and Gan, Zhe and Cheng, Yu and Liu, Jingjing},
  booktitle={European conference on computer vision},
  pages={104--120},
  year={2020},
  organization={Springer}
}

@article{yang2021crossing,
  title={Crossing the format boundary of text and boxes: Towards unified vision-language modeling},
  author={Yang, Zhengyuan and Gan, Zhe and Wang, Jianfeng and Hu, Xiaowei and Ahmed, Faisal and Liu, Zicheng and Lu, Yumao and Wang, Lijuan},
  journal={arXiv preprint arXiv:2111.12085},
  volume={2},
  number={3},
  pages={8},
  year={2021}
}

@inproceedings{kamath2021mdetr,
  title={Mdetr-modulated detection for end-to-end multi-modal understanding},
  author={Kamath, Aishwarya and Singh, Mannat and LeCun, Yann and Synnaeve, Gabriel and Misra, Ishan and Carion, Nicolas},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={1780--1790},
  year={2021}
}

@article{gan2020large,
  title={Large-scale adversarial training for vision-and-language representation learning},
  author={Gan, Zhe and Chen, Yen-Chun and Li, Linjie and Zhu, Chen and Cheng, Yu and Liu, Jingjing},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={6616--6628},
  year={2020}
}

@inproceedings{yang2022unitab,
  title={Unitab: Unifying text and box outputs for grounded vision-language modeling},
  author={Yang, Zhengyuan and Gan, Zhe and Wang, Jianfeng and Hu, Xiaowei and Ahmed, Faisal and Liu, Zicheng and Lu, Yumao and Wang, Lijuan},
  booktitle={European Conference on Computer Vision},
  pages={521--539},
  year={2022},
  organization={Springer}
}

@misc{brown2020language,
      title={Language Models are Few-Shot Learners}, 
      author={Tom B. Brown and Benjamin Mann and Nick Ryder and Melanie Subbiah and Jared Kaplan and Prafulla Dhariwal and Arvind Neelakantan and Pranav Shyam and Girish Sastry and Amanda Askell and Sandhini Agarwal and Ariel Herbert-Voss and Gretchen Krueger and Tom Henighan and Rewon Child and Aditya Ramesh and Daniel M. Ziegler and Jeffrey Wu and Clemens Winter and Christopher Hesse and Mark Chen and Eric Sigler and Mateusz Litwin and Scott Gray and Benjamin Chess and Jack Clark and Christopher Berner and Sam McCandlish and Alec Radford and Ilya Sutskever and Dario Amodei},
      year={2020},
      eprint={2005.14165},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}


@misc{raffel2020exploring,
      title={Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer}, 
      author={Colin Raffel and Noam Shazeer and Adam Roberts and Katherine Lee and Sharan Narang and Michael Matena and Yanqi Zhou and Wei Li and Peter J. Liu},
      year={2020},
      eprint={1910.10683},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{hoffmann2022training,
      title={Training Compute-Optimal Large Language Models}, 
      author={Jordan Hoffmann and Sebastian Borgeaud and Arthur Mensch and Elena Buchatskaya and Trevor Cai and Eliza Rutherford and Diego de Las Casas and Lisa Anne Hendricks and Johannes Welbl and Aidan Clark and Tom Hennigan and Eric Noland and Katie Millican and George van den Driessche and Bogdan Damoc and Aurelia Guy and Simon Osindero and Karen Simonyan and Erich Elsen and Jack W. Rae and Oriol Vinyals and Laurent Sifre},
      year={2022},
      eprint={2203.15556},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@article{chowdhery2022palm,
  title={Palm: Scaling language modeling with pathways},
  author={Chowdhery, Aakanksha and Narang, Sharan and Devlin, Jacob and Bosma, Maarten and Mishra, Gaurav and Roberts, Adam and Barham, Paul and Chung, Hyung Won and Sutton, Charles and Gehrmann, Sebastian and others},
  journal={arXiv preprint arXiv:2204.02311},
  year={2022}
}
@misc{chowdhery22palm,
      title={PaLM: Scaling Language Modeling with Pathways}, 
      author={Aakanksha Chowdhery and Sharan Narang and Jacob Devlin and Maarten Bosma and Gaurav Mishra and Adam Roberts and Paul Barham and Hyung Won Chung and Charles Sutton and Sebastian Gehrmann and Parker Schuh and Kensen Shi and Sasha Tsvyashchenko and Joshua Maynez and Abhishek Rao and Parker Barnes and Yi Tay and Noam Shazeer and Vinodkumar Prabhakaran and Emily Reif and Nan Du and Ben Hutchinson and Reiner Pope and James Bradbury and Jacob Austin and Michael Isard and Guy Gur-Ari and Pengcheng Yin and Toju Duke and Anselm Levskaya and Sanjay Ghemawat and Sunipa Dev and Henryk Michalewski and Xavier Garcia and Vedant Misra and Kevin Robinson and Liam Fedus and Denny Zhou and Daphne Ippolito and David Luan and Hyeontaek Lim and Barret Zoph and Alexander Spiridonov and Ryan Sepassi and David Dohan and Shivani Agrawal and Mark Omernick and Andrew M. Dai and Thanumalayan Sankaranarayana Pillai and Marie Pellat and Aitor Lewkowycz and Erica Moreira and Rewon Child and Oleksandr Polozov and Katherine Lee and Zongwei Zhou and Xuezhi Wang and Brennan Saeta and Mark Diaz and Orhan Firat and Michele Catasta and Jason Wei and Kathy Meier-Hellstern and Douglas Eck and Jeff Dean and Slav Petrov and Noah Fiedel},
      year={2022},
      eprint={2204.02311},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{zhang2022opt,
      title={OPT: Open Pre-trained Transformer Language Models}, 
      author={Susan Zhang and Stephen Roller and Naman Goyal and Mikel Artetxe and Moya Chen and Shuohui Chen and Christopher Dewan and Mona Diab and Xian Li and Xi Victoria Lin and Todor Mihaylov and Myle Ott and Sam Shleifer and Kurt Shuster and Daniel Simig and Punit Singh Koura and Anjali Sridhar and Tianlu Wang and Luke Zettlemoyer},
      year={2022},
      eprint={2205.01068},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}
@misc{touvron2023llama,
      title={LLaMA: Open and Efficient Foundation Language Models}, 
      author={Hugo Touvron and Thibaut Lavril and Gautier Izacard and Xavier Martinet and Marie-Anne Lachaux and Timothée Lacroix and Baptiste Rozière and Naman Goyal and Eric Hambro and Faisal Azhar and Aurelien Rodriguez and Armand Joulin and Edouard Grave and Guillaume Lample},
      year={2023},
      eprint={2302.13971},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{workshop2023bloom,
      title={BLOOM: A 176B-Parameter Open-Access Multilingual Language Model}, 
      author={BigScience Workshop and : and Teven Le Scao and Angela Fan and Christopher Akiki and Ellie Pavlick and Suzana Ilić and Daniel Hesslow and Roman Castagné and Alexandra Sasha Luccioni and François Yvon and Matthias Gallé and Jonathan Tow and Alexander M. Rush and Stella Biderman and Albert Webson and Pawan Sasanka Ammanamanchi and Thomas Wang and Benoît Sagot and Niklas Muennighoff and Albert Villanova del Moral and Olatunji Ruwase and Rachel Bawden and Stas Bekman and Angelina McMillan-Major and Iz Beltagy and Huu Nguyen and Lucile Saulnier and Samson Tan and Pedro Ortiz Suarez and Victor Sanh and Hugo Laurençon and Yacine Jernite and Julien Launay and Margaret Mitchell and Colin Raffel and Aaron Gokaslan and Adi Simhi and Aitor Soroa and Alham Fikri Aji and Amit Alfassy and Anna Rogers and Ariel Kreisberg Nitzav and Canwen Xu and Chenghao Mou and Chris Emezue and Christopher Klamm and Colin Leong and Daniel van Strien and David Ifeoluwa Adelani and Dragomir Radev and Eduardo González Ponferrada and Efrat Levkovizh and Ethan Kim and Eyal Bar Natan and Francesco De Toni and Gérard Dupont and Germán Kruszewski and Giada Pistilli and Hady Elsahar and Hamza Benyamina and Hieu Tran and Ian Yu and Idris Abdulmumin and Isaac Johnson and Itziar Gonzalez-Dios and Javier de la Rosa and Jenny Chim and Jesse Dodge and Jian Zhu and Jonathan Chang and Jörg Frohberg and Joseph Tobing and Joydeep Bhattacharjee and Khalid Almubarak and Kimbo Chen and Kyle Lo and Leandro Von Werra and Leon Weber and Long Phan and Loubna Ben allal and Ludovic Tanguy and Manan Dey and Manuel Romero Muñoz and Maraim Masoud and María Grandury and Mario Šaško and Max Huang and Maximin Coavoux and Mayank Singh and Mike Tian-Jian Jiang and Minh Chien Vu and Mohammad A. Jauhar and Mustafa Ghaleb and Nishant Subramani and Nora Kassner and Nurulaqilla Khamis and Olivier Nguyen and Omar Espejel and Ona de Gibert and Paulo Villegas and Peter Henderson and Pierre Colombo and Priscilla Amuok and Quentin Lhoest and Rheza Harliman and Rishi Bommasani and Roberto Luis López and Rui Ribeiro and Salomey Osei and Sampo Pyysalo and Sebastian Nagel and Shamik Bose and Shamsuddeen Hassan Muhammad and Shanya Sharma and Shayne Longpre and Somaieh Nikpoor and Stanislav Silberberg and Suhas Pai and Sydney Zink and Tiago Timponi Torrent and Timo Schick and Tristan Thrush and Valentin Danchev and Vassilina Nikoulina and Veronika Laippala and Violette Lepercq and Vrinda Prabhu and Zaid Alyafeai and Zeerak Talat and Arun Raja and Benjamin Heinzerling and Chenglei Si and Davut Emre Taşar and Elizabeth Salesky and Sabrina J. Mielke and Wilson Y. Lee and Abheesht Sharma and Andrea Santilli and Antoine Chaffin and Arnaud Stiegler and Debajyoti Datta and Eliza Szczechla and Gunjan Chhablani and Han Wang and Harshit Pandey and Hendrik Strobelt and Jason Alan Fries and Jos Rozen and Leo Gao and Lintang Sutawika and M Saiful Bari and Maged S. Al-shaibani and Matteo Manica and Nihal Nayak and Ryan Teehan and Samuel Albanie and Sheng Shen and Srulik Ben-David and Stephen H. Bach and Taewoon Kim and Tali Bers and Thibault Fevry and Trishala Neeraj and Urmish Thakker and Vikas Raunak and Xiangru Tang and Zheng-Xin Yong and Zhiqing Sun and Shaked Brody and Yallow Uri and Hadar Tojarieh and Adam Roberts and Hyung Won Chung and Jaesung Tae and Jason Phang and Ofir Press and Conglong Li and Deepak Narayanan and Hatim Bourfoune and Jared Casper and Jeff Rasley and Max Ryabinin and Mayank Mishra and Minjia Zhang and Mohammad Shoeybi and Myriam Peyrounette and Nicolas Patry and Nouamane Tazi and Omar Sanseviero and Patrick von Platen and Pierre Cornette and Pierre François Lavallée and Rémi Lacroix and Samyam Rajbhandari and Sanchit Gandhi and Shaden Smith and Stéphane Requena and Suraj Patil and Tim Dettmers and Ahmed Baruwa and Amanpreet Singh and Anastasia Cheveleva and Anne-Laure Ligozat and Arjun Subramonian and Aurélie Névéol and Charles Lovering and Dan Garrette and Deepak Tunuguntla and Ehud Reiter and Ekaterina Taktasheva and Ekaterina Voloshina and Eli Bogdanov and Genta Indra Winata and Hailey Schoelkopf and Jan-Christoph Kalo and Jekaterina Novikova and Jessica Zosa Forde and Jordan Clive and Jungo Kasai and Ken Kawamura and Liam Hazan and Marine Carpuat and Miruna Clinciu and Najoung Kim and Newton Cheng and Oleg Serikov and Omer Antverg and Oskar van der Wal and Rui Zhang and Ruochen Zhang and Sebastian Gehrmann and Shachar Mirkin and Shani Pais and Tatiana Shavrina and Thomas Scialom and Tian Yun and Tomasz Limisiewicz and Verena Rieser and Vitaly Protasov and Vladislav Mikhailov and Yada Pruksachatkun and Yonatan Belinkov and Zachary Bamberger and Zdeněk Kasner and Alice Rueda and Amanda Pestana and Amir Feizpour and Ammar Khan and Amy Faranak and Ana Santos and Anthony Hevia and Antigona Unldreaj and Arash Aghagol and Arezoo Abdollahi and Aycha Tammour and Azadeh HajiHosseini and Bahareh Behroozi and Benjamin Ajibade and Bharat Saxena and Carlos Muñoz Ferrandis and Danish Contractor and David Lansky and Davis David and Douwe Kiela and Duong A. Nguyen and Edward Tan and Emi Baylor and Ezinwanne Ozoani and Fatima Mirza and Frankline Ononiwu and Habib Rezanejad and Hessie Jones and Indrani Bhattacharya and Irene Solaiman and Irina Sedenko and Isar Nejadgholi and Jesse Passmore and Josh Seltzer and Julio Bonis Sanz and Livia Dutra and Mairon Samagaio and Maraim Elbadri and Margot Mieskes and Marissa Gerchick and Martha Akinlolu and Michael McKenna and Mike Qiu and Muhammed Ghauri and Mykola Burynok and Nafis Abrar and Nazneen Rajani and Nour Elkott and Nour Fahmy and Olanrewaju Samuel and Ran An and Rasmus Kromann and Ryan Hao and Samira Alizadeh and Sarmad Shubber and Silas Wang and Sourav Roy and Sylvain Viguier and Thanh Le and Tobi Oyebade and Trieu Le and Yoyo Yang and Zach Nguyen and Abhinav Ramesh Kashyap and Alfredo Palasciano and Alison Callahan and Anima Shukla and Antonio Miranda-Escalada and Ayush Singh and Benjamin Beilharz and Bo Wang and Caio Brito and Chenxi Zhou and Chirag Jain and Chuxin Xu and Clémentine Fourrier and Daniel León Periñán and Daniel Molano and Dian Yu and Enrique Manjavacas and Fabio Barth and Florian Fuhrimann and Gabriel Altay and Giyaseddin Bayrak and Gully Burns and Helena U. Vrabec and Imane Bello and Ishani Dash and Jihyun Kang and John Giorgi and Jonas Golde and Jose David Posada and Karthik Rangasai Sivaraman and Lokesh Bulchandani and Lu Liu and Luisa Shinzato and Madeleine Hahn de Bykhovetz and Maiko Takeuchi and Marc Pàmies and Maria A Castillo and Marianna Nezhurina and Mario Sänger and Matthias Samwald and Michael Cullan and Michael Weinberg and Michiel De Wolf and Mina Mihaljcic and Minna Liu and Moritz Freidank and Myungsun Kang and Natasha Seelam and Nathan Dahlberg and Nicholas Michio Broad and Nikolaus Muellner and Pascale Fung and Patrick Haller and Ramya Chandrasekhar and Renata Eisenberg and Robert Martin and Rodrigo Canalli and Rosaline Su and Ruisi Su and Samuel Cahyawijaya and Samuele Garda and Shlok S Deshmukh and Shubhanshu Mishra and Sid Kiblawi and Simon Ott and Sinee Sang-aroonsiri and Srishti Kumar and Stefan Schweter and Sushil Bharati and Tanmay Laud and Théo Gigant and Tomoya Kainuma and Wojciech Kusa and Yanis Labrak and Yash Shailesh Bajaj and Yash Venkatraman and Yifan Xu and Yingxin Xu and Yu Xu and Zhe Tan and Zhongli Xie and Zifan Ye and Mathilde Bras and Younes Belkada and Thomas Wolf},
      year={2023},
      eprint={2211.05100},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}


@misc{radford2021learning,
      title={Learning Transferable Visual Models From Natural Language Supervision}, 
      author={Alec Radford and Jong Wook Kim and Chris Hallacy and Aditya Ramesh and Gabriel Goh and Sandhini Agarwal and Girish Sastry and Amanda Askell and Pamela Mishkin and Jack Clark and Gretchen Krueger and Ilya Sutskever},
      year={2021},
      eprint={2103.00020},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@misc{li2022grounded,
      title={Grounded Language-Image Pre-training}, 
      author={Liunian Harold Li and Pengchuan Zhang and Haotian Zhang and Jianwei Yang and Chunyuan Li and Yiwu Zhong and Lijuan Wang and Lu Yuan and Lei Zhang and Jenq-Neng Hwang and Kai-Wei Chang and Jianfeng Gao},
      year={2022},
      eprint={2112.03857},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}
@article{alayrac2022flamingo,
  title={Flamingo: a visual language model for few-shot learning},
  author={Alayrac, Jean-Baptiste and Donahue, Jeff and Luc, Pauline and Miech, Antoine and Barr, Iain and Hasson, Yana and Lenc, Karel and Mensch, Arthur and Millican, Katherine and Reynolds, Malcolm and others},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={23716--23736},
  year={2022}
}

@misc{alayrac2022flamingo1,
      title={Flamingo: a Visual Language Model for Few-Shot Learning}, 
      author={Jean-Baptiste Alayrac and Jeff Donahue and Pauline Luc and Antoine Miech and Iain Barr and Yana Hasson and Karel Lenc and Arthur Mensch and Katie Millican and Malcolm Reynolds and Roman Ring and Eliza Rutherford and Serkan Cabi and Tengda Han and Zhitao Gong and Sina Samangooei and Marianne Monteiro and Jacob Menick and Sebastian Borgeaud and Andrew Brock and Aida Nematzadeh and Sahand Sharifzadeh and Mikolaj Binkowski and Ricardo Barreira and Oriol Vinyals and Andrew Zisserman and Karen Simonyan},
      year={2022},
      eprint={2204.14198},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@misc{li2023blip2,
      title={BLIP-2: Bootstrapping Language-Image Pre-training with Frozen Image Encoders and Large Language Models}, 
      author={Junnan Li and Dongxu Li and Silvio Savarese and Steven Hoi},
      year={2023},
      eprint={2301.12597},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@misc{zhu2023minigpt4,
      title={MiniGPT-4: Enhancing Vision-Language Understanding with Advanced Large Language Models}, 
      author={Deyao Zhu and Jun Chen and Xiaoqian Shen and Xiang Li and Mohamed Elhoseiny},
      year={2023},
      eprint={2304.10592},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}


@misc{chen2022pix2seq,
      title={Pix2seq: A Language Modeling Framework for Object Detection}, 
      author={Ting Chen and Saurabh Saxena and Lala Li and David J. Fleet and Geoffrey Hinton},
      year={2022},
      eprint={2109.10852},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@misc{wang2022ofa,
      title={OFA: Unifying Architectures, Tasks, and Modalities Through a Simple Sequence-to-Sequence Learning Framework}, 
      author={Peng Wang and An Yang and Rui Men and Junyang Lin and Shuai Bai and Zhikang Li and Jianxin Ma and Chang Zhou and Jingren Zhou and Hongxia Yang},
      year={2022},
      eprint={2202.03052},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}




@misc{brown2020language,
      title={Language Models are Few-Shot Learners}, 
      author={Tom B. Brown and Benjamin Mann and Nick Ryder and Melanie Subbiah and Jared Kaplan and Prafulla Dhariwal and Arvind Neelakantan and Pranav Shyam and Girish Sastry and Amanda Askell and Sandhini Agarwal and Ariel Herbert-Voss and Gretchen Krueger and Tom Henighan and Rewon Child and Aditya Ramesh and Daniel M. Ziegler and Jeffrey Wu and Clemens Winter and Christopher Hesse and Mark Chen and Eric Sigler and Mateusz Litwin and Scott Gray and Benjamin Chess and Jack Clark and Christopher Berner and Sam McCandlish and Alec Radford and Ilya Sutskever and Dario Amodei},
      year={2020},
      eprint={2005.14165},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}


@misc{raffel2020exploring,
      title={Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer}, 
      author={Colin Raffel and Noam Shazeer and Adam Roberts and Katherine Lee and Sharan Narang and Michael Matena and Yanqi Zhou and Wei Li and Peter J. Liu},
      year={2020},
      eprint={1910.10683},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{hoffmann2022training,
      title={Training Compute-Optimal Large Language Models}, 
      author={Jordan Hoffmann and Sebastian Borgeaud and Arthur Mensch and Elena Buchatskaya and Trevor Cai and Eliza Rutherford and Diego de Las Casas and Lisa Anne Hendricks and Johannes Welbl and Aidan Clark and Tom Hennigan and Eric Noland and Katie Millican and George van den Driessche and Bogdan Damoc and Aurelia Guy and Simon Osindero and Karen Simonyan and Erich Elsen and Jack W. Rae and Oriol Vinyals and Laurent Sifre},
      year={2022},
      eprint={2203.15556},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}





@article{scao2022bloom,
  title={Bloom: A 176b-parameter open-access multilingual language model},
  author={Scao, Teven Le and Fan, Angela and Akiki, Christopher and Pavlick, Ellie and Ili{\'c}, Suzana and Hesslow, Daniel and Castagn{\'e}, Roman and Luccioni, Alexandra Sasha and Yvon, Fran{\c{c}}ois and Gall{\'e}, Matthias and others},
  journal={arXiv preprint arXiv:2211.05100},
  year={2022}
}



@article{johnson2019mimic,
  title={MIMIC-CXR, a de-identified publicly available database of chest radiographs with free-text reports},
  author={Johnson, Alistair EW and Pollard, Tom J and Berkowitz, Seth J and Greenbaum, Nathaniel R and Lungren, Matthew P and Deng, Chih-ying and Mark, Roger G and Horng, Steven},
  journal={Scientific data},
  volume={6},
  number={1},
  pages={317},
  year={2019},
  publisher={Nature Publishing Group UK London}
}

@article{nguyen2022vindr,
  title={VinDr-CXR: An open dataset of chest X-rays with radiologist’s annotations},
  author={Nguyen, Ha Q and Lam, Khanh and Le, Linh T and Pham, Hieu H and Tran, Dat Q and Nguyen, Dung B and Le, Dung D and Pham, Chi M and Tong, Hang TT and Dinh, Diep H and others},
  journal={Scientific Data},
  volume={9},
  number={1},
  pages={429},
  year={2022},
  publisher={Nature Publishing Group UK London}
}

@article{lian2021structure,
  title={A structure-aware relation network for thoracic diseases detection and segmentation},
  author={Lian, Jie and Liu, Jingyu and Zhang, Shu and Gao, Kai and Liu, Xiaoqing and Zhang, Dingwen and Yu, Yizhou},
  journal={IEEE Transactions on Medical Imaging},
  volume={40},
  number={8},
  pages={2042--2052},
  year={2021},
  publisher={IEEE}
}


@inproceedings{irvin2019chexpert,
  title={Chexpert: A large chest radiograph dataset with uncertainty labels and expert comparison},
  author={Irvin, Jeremy and Rajpurkar, Pranav and Ko, Michael and Yu, Yifan and Ciurea-Ilcus, Silviana and Chute, Chris and Marklund, Henrik and Haghgoo, Behzad and Ball, Robyn and Shpanskaya, Katie and others},
  booktitle={Proceedings of the AAAI conference on artificial intelligence},
  volume={33},
  number={01},
  pages={590--597},
  year={2019}
}

@inproceedings{yang2020improving,
  title={Improving one-stage visual grounding by recursive sub-query construction},
  author={Yang, Zhengyuan and Chen, Tianlang and Wang, Liwei and Luo, Jiebo},
  booktitle={Computer Vision--ECCV 2020: 16th European Conference, Glasgow, UK, August 23--28, 2020, Proceedings, Part XIV 16},
  pages={387--404},
  year={2020},
  organization={Springer}
}

@inproceedings{boecking2022making,
  title={Making the most of text semantics to improve biomedical vision--language processing},
  author={Boecking, Benedikt and Usuyama, Naoto and Bannur, Shruthi and Castro, Daniel C and Schwaighofer, Anton and Hyland, Stephanie and Wetscherek, Maria and Naumann, Tristan and Nori, Aditya and Alvarez-Valle, Javier and others},
  booktitle={European conference on computer vision},
  pages={1--21},
  year={2022},
  organization={Springer}
}



@inproceedings{liu-etal-2021-contrastive,
    title = "Contrastive Attention for Automatic Chest {X}-ray Report Generation",
    author = "Liu, Fenglin  and
      Yin, Changchang  and
      Wu, Xian  and
      Ge, Shen  and
      Zhang, Ping  and
      Sun, Xu",
    booktitle = "Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021",
    month = aug,
    year = "2021",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.findings-acl.23",
    doi = "10.18653/v1/2021.findings-acl.23",
    pages = "269--280",
}

@misc{chen2022crossmodal,
      title={Cross-modal Memory Networks for Radiology Report Generation}, 
      author={Zhihong Chen and Yaling Shen and Yan Song and Xiang Wan},
      year={2022},
      eprint={2204.13258},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{huang2023kiut,
      title={KiUT: Knowledge-injected U-Transformer for Radiology Report Generation}, 
      author={Zhongzhen Huang and Xiaofan Zhang and Shaoting Zhang},
      year={2023},
      eprint={2306.11345},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}


@misc{zhou2023advancing,
      title={Advancing Radiograph Representation Learning with Masked Record Modeling}, 
      author={Hong-Yu Zhou and Chenyu Lian and Liansheng Wang and Yizhou Yu},
      year={2023},
      eprint={2301.13155},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@misc{zhang2022contrastive,
      title={Contrastive Learning of Medical Visual Representations from Paired Images and Text}, 
      author={Yuhao Zhang and Hang Jiang and Yasuhide Miura and Christopher D. Manning and Curtis P. Langlotz},
      year={2022},
      eprint={2010.00747},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@article{Huang2021GLoRIAAM,
  title={GLoRIA: A Multimodal Global-Local Representation Learning Framework for Label-efficient Medical Image Recognition},
  author={Shih-Cheng Huang and Liyue Shen and Matthew P. Lungren and Serena Yeung},
  journal={2021 IEEE/CVF International Conference on Computer Vision (ICCV)},
  year={2021},
  pages={3922-3931}
}

@article{Zhou_2022,
	doi = {10.1038/s42256-021-00425-9},
  
	url = {https://doi.org/10.1038%2Fs42256-021-00425-9},
  
	year = 2022,
	month = {jan},
  
	publisher = {Springer Science and Business Media {LLC}
},
  
	volume = {4},
  
	number = {1},
  
	pages = {32--40},
  
	author = {Hong-Yu Zhou and Xiaoyu Chen and Yinghao Zhang and Ruibang Luo and Liansheng Wang and Yizhou Yu},
  
	title = {Generalized radiograph representation learning via cross-supervision between images and free-text radiology reports},
  
	journal = {Nature Machine Intelligence}
}

@misc{geng2022multimodal,
      title={Multimodal Masked Autoencoders Learn Transferable Representations}, 
      author={Xinyang Geng and Hao Liu and Lisa Lee and Dale Schuurmans and Sergey Levine and Pieter Abbeel},
      year={2022},
      eprint={2205.14204},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@misc{wang2022multigranularity,
      title={Multi-Granularity Cross-modal Alignment for Generalized Medical Visual Representation Learning}, 
      author={Fuying Wang and Yuyin Zhou and Shujun Wang and Varut Vardhanabhuti and Lequan Yu},
      year={2022},
      eprint={2210.06044},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}


@misc{chen2023medical,
      title={Medical Phrase Grounding with Region-Phrase Context Contrastive Alignment}, 
      author={Zhihao Chen and Yang Zhou and Anh Tran and Junting Zhao and Liang Wan and Gideon Ooi and Lionel Cheng and Choon Hua Thng and Xinxing Xu and Yong Liu and Huazhu Fu},
      year={2023},
      eprint={2303.07618},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@misc{li2021referring,
      title={Referring Transformer: A One-step Approach to Multi-task Visual Grounding}, 
      author={Muchen Li and Leonid Sigal},
      year={2021},
      eprint={2106.03089},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@inproceedings{du2022visual,
  title={Visual grounding with transformers},
  author={Du, Ye and Fu, Zehua and Liu, Qingjie and Wang, Yunhong},
  booktitle={Proceedings of the International Conference on Multimedia and Expo},
  year={2022}
}

@incollection{Zhu_2022,
	doi = {10.1007/978-3-031-19833-5_35},
  
	url = {https://doi.org/10.1007%2F978-3-031-19833-5_35},
  
	year = 2022,
	publisher = {Springer Nature Switzerland},
  
	pages = {598--615},
  
	author = {Chaoyang Zhu and Yiyi Zhou and Yunhang Shen and Gen Luo and Xingjia Pan and Mingbao Lin and Chao Chen and Liujuan Cao and Xiaoshuai Sun and Rongrong Ji},
  
	title = {{SeqTR}: A Simple Yet Universal Network for Visual Grounding},
  
	booktitle = {Lecture Notes in Computer Science}
}

@InProceedings{Deng_2021_ICCV,
    author    = {Deng, Jiajun and Yang, Zhengyuan and Chen, Tianlang and Zhou, Wengang and Li, Houqiang},
    title     = {TransVG: End-to-End Visual Grounding With Transformers},
    booktitle = {Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV)},
    month     = {October},
    year      = {2021},
    pages     = {1769-1779}
}


@article{demner2016preparing,
  title={Preparing a collection of radiology examinations for distribution and retrieval},
  author={Demner-Fushman, Dina and Kohli, Marc D and Rosenman, Marc B and Shooshan, Sonya E and Rodriguez, Laritza and Antani, Sameer and Thoma, George R and McDonald, Clement J},
  journal={Journal of the American Medical Informatics Association},
  volume={23},
  number={2},
  pages={304--310},
  year={2016},
  publisher={Oxford University Press}
}


@misc{wu2023medklip,
      title={MedKLIP: Medical Knowledge Enhanced Language-Image Pre-Training in Radiology}, 
      author={Chaoyi Wu and Xiaoman Zhang and Ya Zhang and Yanfeng Wang and Weidi Xie},
      year={2023},
      eprint={2301.02228},
      archivePrefix={arXiv},
      primaryClass={eess.IV}
}


    # 1. cohen
@article{cohen2020covid,
  title={COVID-19 image data collection},
  author={Joseph Paul Cohen and Paul Morrison and Lan Dao},
  journal={arXiv 2003.11597},
  url={https://github.com/ieee8023/covid-chestxray-dataset},
  year={2020}
}

    # 4.SIRM
@ARTICLE{SIRM9144185,
  author={Chowdhury, Muhammad E. H. and Rahman, Tawsifur and Khandakar, Amith and Mazhar, Rashid and Kadir, Muhammad Abdul and Mahbub, Zaid Bin and Islam, Khandakar Reajul and Khan, Muhammad Salman and Iqbal, Atif and Emadi, Nasser Al and Reaz, Mamun Bin Ibne and Islam, Mohammad Tariqul},
  journal={IEEE Access}, 
  title={Can AI Help in Screening Viral and COVID-19 Pneumonia?}, 
  year={2020},
  volume={8},
  number={},
  pages={132665-132676},
  doi={10.1109/ACCESS.2020.3010287}
}
    # 4.sirm
@article{SIRM_RAHMAN2021104319,
title = {Exploring the effect of image enhancement techniques on COVID-19 detection using chest X-ray images},
journal = {Computers in Biology and Medicine},
volume = {132},
pages = {104319},
year = {2021},
issn = {0010-4825},
doi = {https://doi.org/10.1016/j.compbiomed.2021.104319},
url = {https://www.sciencedirect.com/science/article/pii/S001048252100113X},
author = {Tawsifur Rahman and Amith Khandakar and Yazan Qiblawey and Anas Tahir and Serkan Kiranyaz and Saad Bin {Abul Kashem} and Mohammad Tariqul Islam and Somaya {Al Maadeed} and Susu M. Zughaier and Muhammad Salman Khan and Muhammad E.H. Chowdhury},
}

    #7 COVID-19-NY-SBU
@article{COVID-19-NY-SBU,
  title={Stony brook university covid-19 positive cases},
  author={Saltz, Joel and Saltz, Mary and Prasanna, Prateek and Moffitt, Richard and Hajagos, Janos and Bremer, Erich and Balsamo, Joseph and Kurc, Tahsin},
  url={https://doi.org/10.7937/TCIA.BBAG-2923},
  journal={the cancer imaging archive},
  volume={4},
  year={2021}
}


@misc{vaya2020bimcv,
      title={BIMCV COVID-19+: a large annotated dataset of RX and CT images from COVID-19 patients}, 
      author={Maria de la Iglesia Vayá and Jose Manuel Saborit and Joaquim Angel Montell and Antonio Pertusa and Aurelia Bustos and Miguel Cazorla and Joaquin Galant and Xavier Barber and Domingo Orozco-Beltrán and Francisco García-García and Marisa Caparrós and Germán González and Jose María Salinas},
      year={2020},
      eprint={2006.01174},
      archivePrefix={arXiv},
      primaryClass={eess.IV}
}

    #5 RICORD
@misc{RICORD2021,
      title={Data from Medical Imaging Data Resource Center (MIDRC) - RSNA International COVID Radiology Database (RICORD) Release 1c - Chest x-ray, Covid+ (MIDRC-RICORD-1C)}, 
      author={Tsai, E., Simpson, S., Lungren, M.P., Hershman, M., Roshkovan, L., Colak, E., Erickson, B.J., Shih, G., Stein, A.,Kalpathy-Cramer, J., Shen, J.,Hafez, M.A.F., John, S., Rajiah, P., Pogatchnik, B.P., Mongan, J.T., Altinmakas, E., Ranschaert, E., Kitamura, F.C., Topff, L., Moy, L., Kanne, J.P., & Wu, C.},
      year={2021},
      archivePrefix={The Cancer Imaging Archive},
    url={ https://doi.org/10.7937/91ah-v663}
}

@article{chen2023pali,
  title={PaLI-3 Vision Language Models: Smaller, Faster, Stronger},
  author={Chen, Xi and Wang, Xiao and Beyer, Lucas and Kolesnikov, Alexander and Wu, Jialin and Voigtlaender, Paul and Mustafa, Basil and Goodman, Sebastian and Alabdulmohsin, Ibrahim and Padlewski, Piotr and others},
  journal={arXiv preprint arXiv:2310.09199},
  year={2023}
}


@misc{liu2023improved,
      title={Improved Baselines with Visual Instruction Tuning}, 
      author={Haotian Liu and Chunyuan Li and Yuheng Li and Yong Jae Lee},
      year={2023},
      eprint={2310.03744},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}



@misc{GPT-4V,
      title={GPT-4V(ision) System Card}, 
      author={OpenAI},
      year={2023},
      url={https://cdn.openai.com/papers/GPTV_System_Card.pdf},
}



@article{tsai2021rsna,
  title={The RSNA international COVID-19 open radiology database (RICORD)},
  author={Tsai, Emily B and Simpson, Scott and Lungren, Matthew P and Hershman, Michelle and Roshkovan, Leonid and Colak, Errol and Erickson, Bradley J and Shih, George and Stein, Anouk and Kalpathy-Cramer, Jayashree and others},
  journal={Radiology},
  volume={299},
  number={1},
  pages={E204--E213},
  year={2021},
  publisher={Radiological Society of North America}
}
@Article{Wang2020CXR-4,
    author={Wang, Linda and Lin, Zhong Qiu and Wong, Alexander},
    title={COVID-Net: a tailored deep convolutional neural network design for detection of COVID-19 cases from chest X-ray images},
    journal={Scientific Reports},
    year={2020},
    month={Nov},
    day={11},
    volume={10},
    number={1},
    pages={19549},
    issn={2045-2322},
    doi={10.1038/s41598-020-76550-z},
    url={https://doi.org/10.1038/s41598-020-76550-z}
}

@inproceedings{gengHumanPoseCompositional2023,
  title = {Human {{Pose As Compositional Tokens}}},
  author = {Geng, Zigang and Wang, Chunyu and Wei, Yixuan and Liu, Ze and Li, Houqiang and Hu, Han},
  year = {2023},
  pages = {660--671},
  year = {2023},
  url = {https://openaccess.thecvf.com/content/CVPR2023/html/Geng_Human_Pose_As_Compositional_Tokens_CVPR_2023_paper.html},
  urldate = {2024-04-07},
  conference = {Proceedings of the {{IEEE}}/{{CVF Conference}} on {{Computer Vision}} and {{Pattern Recognition}}},
  langid = {english}
}

@article{xuViTPoseSimpleVision2022,
  title = {{{ViTPose}}: {{Simple Vision Transformer Baselines}} for {{Human Pose Estimation}}},
  shorttitle = {{{ViTPose}}},
  author = {Xu, Yufei and Zhang, Jing and Zhang, Qiming and Tao, Dacheng},
  year = {2022-12-06},
  journaltitle = {Advances in Neural Information Processing Systems},
  volume = {35},
  year = {2022},
  pages = {38571--38584},
  url = {https://proceedings.neurips.cc/paper_files/paper/2022/hash/fbb10d319d44f8c3b4720873e4177c65-Abstract-Conference.html},
  urldate = {2024-04-07},
  langid = {english}
}

@inproceedings{luUNIFIEDIOUnifiedModel2022,
  title = {{{UNIFIED-IO}}: {{A Unified Model}} for {{Vision}}, {{Language}}, and {{Multi-modal Tasks}}},
  shorttitle = {{{UNIFIED-IO}}},
  author = {Lu, Jiasen and Clark, Christopher and Zellers, Rowan and Mottaghi, Roozbeh and Kembhavi, Aniruddha},
  year = {2022-09-29},
  year = {2022},
  url = {https://openreview.net/forum?id=E01k9048soZ},
  urldate = {2024-04-07},
  conference = {The {{Eleventh International Conference}} on {{Learning Representations}}},
  langid = {english}
}

@inproceedings{wangImagesSpeakImages2023,
  title = {Images {{Speak}} in {{Images}}: {{A Generalist Painter}} for {{In-Context Visual Learning}}},
  shorttitle = {Images {{Speak}} in {{Images}}},
  author = {Wang, Xinlong and Wang, Wen and Cao, Yue and Shen, Chunhua and Huang, Tiejun},
  year = {2023},
  
  pages = {6830--6839},
  url = {https://openaccess.thecvf.com/content/CVPR2023/html/Wang_Images_Speak_in_Images_A_Generalist_Painter_for_In-Context_Visual_CVPR_2023_paper.html},
  urldate = {2024-04-07},
  conference = {Proceedings of the {{IEEE}}/{{CVF Conference}} on {{Computer Vision}} and {{Pattern Recognition}}},
  langid = {english}
}

@online{gengInstructDiffusionGeneralistModeling2023,
  title = {{{InstructDiffusion}}: {{A Generalist Modeling Interface}} for {{Vision Tasks}}},
  shorttitle = {{{InstructDiffusion}}},
  author = {Geng, Zigang and Yang, Binxin and Hang, Tiankai and Li, Chen and Gu, Shuyang and Zhang, Ting and Bao, Jianmin and Zhang, Zheng and Hu, Han and Chen, Dong and Guo, Baining},
  year = {2023-09-07},
  eprint = {2309.03895},
  year = {2023},
  eprinttype = {arxiv},
  doi = {10.48550/arXiv.2309.03895},
  url = {http://arxiv.org/abs/2309.03895},
  urldate = {2024-03-07},
  pubstate = {preprint}
}

@inproceedings{kimReSTRConvolutionFreeReferring2022,
  title = {{{ReSTR}}: {{Convolution-Free Referring Image Segmentation Using Transformers}}},
  shorttitle = {{{ReSTR}}},
  author = {Kim, Namyup and Kim, Dongwon and Lan, Cuiling and Zeng, Wenjun and Kwak, Suha},
  year = {2022},
  pages = {18145--18154},
  url = {https://openaccess.thecvf.com/content/CVPR2022/html/Kim_ReSTR_Convolution-Free_Referring_Image_Segmentation_Using_Transformers_CVPR_2022_paper.html},
  urldate = {2024-04-07},
  conference = {Proceedings of the {{IEEE}}/{{CVF Conference}} on {{Computer Vision}} and {{Pattern Recognition}}},
  langid = {english}
}


@article{liuCrossModalProgressiveComprehension2022,
  title = {Cross-{{Modal Progressive Comprehension}} for {{Referring Segmentation}}},
  author = {Liu, Si and Hui, Tianrui and Huang, Shaofei and Wei, Yunchao and Li, Bo and Li, Guanbin},
  year = {2022-09},
  journaltitle = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  volume = {44},
  number = {9},
  pages = {4761--4775},
  issn = {1939-3539},
  doi = {10.1109/TPAMI.2021.3079993},
  url = {https://ieeexplore.ieee.org/abstract/document/9430750},
  urldate = {2024-04-07},
  conference = {{{IEEE Transactions}} on {{Pattern Analysis}} and {{Machine Intelligence}}}
}


@inproceedings{huiLinguisticStructureGuided2020,
  title = {Linguistic {{Structure Guided Context Modeling}} for {{Referring Image Segmentation}}},
  booktitle = {Computer {{Vision}} – {{ECCV}} 2020},
  author = {Hui, Tianrui and Liu, Si and Huang, Shaofei and Li, Guanbin and Yu, Sansi and Zhang, Faxi and Han, Jizhong},
  editor = {Vedaldi, Andrea and Bischof, Horst and Brox, Thomas and Frahm, Jan-Michael},
  year = {2020},
  pages = {59--75},
  publisher = {Springer International Publishing},
  location = {Cham},
  doi = {10.1007/978-3-030-58607-2_4},
  isbn = {978-3-030-58607-2},
  langid = {english}
}



@inproceedings{huBiDirectionalRelationshipInferring2020,
  title = {Bi-{{Directional Relationship Inferring Network}} for {{Referring Image Segmentation}}},
  author = {Hu, Zhiwei and Feng, Guang and Sun, Jiayu and Zhang, Lihe and Lu, Huchuan},
  year = {2020},
  pages = {4424--4433},
  url = {https://openaccess.thecvf.com/content_CVPR_2020/html/Hu_Bi-Directional_Relationship_Inferring_Network_for_Referring_Image_Segmentation_CVPR_2020_paper.html},
  urldate = {2024-04-07},
  conference = {Proceedings of the {{IEEE}}/{{CVF Conference}} on {{Computer Vision}} and {{Pattern Recognition}}}
}




@inproceedings{chenSeeThroughTextGroupingReferring2019,
  title = {See-{{Through-Text Grouping}} for {{Referring Image Segmentation}}},
  author = {Chen, Ding-Jie and Jia, Songhao and Lo, Yi-Chen and Chen, Hwann-Tzong and Liu, Tyng-Luh},
  year = {2019},
  pages = {7454--7463},
  url = {https://openaccess.thecvf.com/content_ICCV_2019/html/Chen_See-Through-Text_Grouping_for_Referring_Image_Segmentation_ICCV_2019_paper.html},
  urldate = {2024-04-07},
  conference = {Proceedings of the {{IEEE}}/{{CVF International Conference}} on {{Computer Vision}}}
}

@inproceedings{yangLAVTLanguageAwareVision2022,
  title = {{{LAVT}}: {{Language-Aware Vision Transformer}} for {{Referring Image Segmentation}}},
  shorttitle = {{{LAVT}}},
  author = {Yang, Zhao and Wang, Jiaqi and Tang, Yansong and Chen, Kai and Zhao, Hengshuang and Torr, Philip H. S.},
  year = {2022},
  pages = {18155--18165},
  url = {https://openaccess.thecvf.com/content/CVPR2022/html/Yang_LAVT_Language-Aware_Vision_Transformer_for_Referring_Image_Segmentation_CVPR_2022_paper.html},
  urldate = {2024-04-07},
  conference = {Proceedings of the {{IEEE}}/{{CVF Conference}} on {{Computer Vision}} and {{Pattern Recognition}}},
  langid = {english}
}

@inproceedings{liuPolyFormerReferringImage2023a,
  title = {{{PolyFormer}}: {{Referring Image Segmentation As Sequential Polygon Generation}}},
  shorttitle = {{{PolyFormer}}},
  author = {Liu, Jiang and Ding, Hui and Cai, Zhaowei and Zhang, Yuting and Satzoda, Ravi Kumar and Mahadevan, Vijay and Manmatha, R.},
  year = {2023},
  pages = {18653--18663},
  url = {https://openaccess.thecvf.com/content/CVPR2023/html/Liu_PolyFormer_Referring_Image_Segmentation_As_Sequential_Polygon_Generation_CVPR_2023_paper.html},
  urldate = {2024-03-13},
  conference = {Proceedings of the {{IEEE}}/{{CVF Conference}} on {{Computer Vision}} and {{Pattern Recognition}}},
  langid = {english}
}

@inproceedings{wangCRISCLIPDrivenReferring2022,
  title = {{{CRIS}}: {{CLIP-Driven Referring Image Segmentation}}},
  shorttitle = {{{CRIS}}},
  author = {Wang, Zhaoqing and Lu, Yu and Li, Qiang and Tao, Xunqiang and Guo, Yandong and Gong, Mingming and Liu, Tongliang},
  year = {2022},
  pages = {11686--11695},
  url = {https://openaccess.thecvf.com/content/CVPR2022/html/Wang_CRIS_CLIP-Driven_Referring_Image_Segmentation_CVPR_2022_paper.html},
  urldate = {2024-04-07},
  conference = {Proceedings of the {{IEEE}}/{{CVF Conference}} on {{Computer Vision}} and {{Pattern Recognition}}},
  langid = {english}
}


@article{zhang2023gpt4roi,
  title={Gpt4roi: Instruction tuning large language model on region-of-interest},
  author={Zhang, Shilong and Sun, Peize and Chen, Shoufa and Xiao, Min and Shao, Wenqi and Zhang, Wenwei and Chen, Kai and Luo, Ping},
  journal={arXiv preprint arXiv:2307.03601},
  year={2023}
}

@article{chen2023position,
  title={Position-enhanced visual instruction tuning for multimodal large language models},
  author={Chen, Chi and Qin, Ruoyu and Luo, Fuwen and Mi, Xiaoyue and Li, Peng and Sun, Maosong and Liu, Yang},
  journal={arXiv preprint arXiv:2308.13437},
  year={2023}
}

@article{wu2022grit,
  title={Grit: A generative region-to-text transformer for object understanding},
  author={Wu, Jialian and Wang, Jianfeng and Yang, Zhengyuan and Gan, Zhe and Liu, Zicheng and Yuan, Junsong and Wang, Lijuan},
  journal={arXiv preprint arXiv:2212.00280},
  year={2022}
}

@article{peng2023kosmos,
  title={Kosmos-2: Grounding multimodal large language models to the world},
  author={Peng, Zhiliang and Wang, Wenhui and Dong, Li and Hao, Yaru and Huang, Shaohan and Ma, Shuming and Wei, Furu},
  journal={arXiv preprint arXiv:2306.14824},
  year={2023}
}

@article{yuan2023osprey,
  title={Osprey: Pixel Understanding with Visual Instruction Tuning},
  author={Yuan, Yuqian and Li, Wentong and Liu, Jian and Tang, Dongqi and Luo, Xinjie and Qin, Chi and Zhang, Lei and Zhu, Jianke},
  journal={arXiv preprint arXiv:2312.10032},
  year={2023}
}

@inproceedings{juHumanArtVersatileHumanCentric2023,
  title = {Human-{{Art}}: {{A Versatile Human-Centric Dataset Bridging Natural}} and {{Artificial Scenes}}},
  shorttitle = {Human-{{Art}}},
  author = {Ju, Xuan and Zeng, Ailing and Wang, Jianan and Xu, Qiang and Zhang, Lei},
  year = {2023},
  pages = {618--629},
  url = {https://openaccess.thecvf.com/content/CVPR2023/html/Ju_Human-Art_A_Versatile_Human-Centric_Dataset_Bridging_Natural_and_Artificial_Scenes_CVPR_2023_paper.html},
  urldate = {2024-04-10},
  eventtitle = {Proceedings of the {{IEEE}}/{{CVF Conference}} on {{Computer Vision}} and {{Pattern Recognition}}},
  langid = {english}
}

@inproceedings{yu2021ap,
  title={AP-10K: A Benchmark for Animal Pose Estimation in the Wild},
  author={Yu, Hang and Xu, Yufei and Zhang, Jing and Zhao, Wei and Guan, Ziyu and Tao, Dacheng},
  booktitle={Thirty-fifth Conference on Neural Information Processing Systems Datasets and Benchmarks Track (Round 2)},
  year={2021}
}


@article{krishnaVisualGenomeConnecting2017,
  title = {Visual {{Genome}}: {{Connecting Language}} and {{Vision Using Crowdsourced Dense Image Annotations}}},
  shorttitle = {Visual {{Genome}}},
  author = {Krishna, Ranjay and Zhu, Yuke and Groth, Oliver and Johnson, Justin and Hata, Kenji and Kravitz, Joshua and Chen, Stephanie and Kalantidis, Yannis and Li, Li-Jia and Shamma, David A. and Bernstein, Michael S. and Fei-Fei, Li},
  year = {2017-05-01},
  journaltitle = {International Journal of Computer Vision},
  shortjournal = {Int J Comput Vis},
  volume = {123},
  number = {1},
  pages = {32--73},
  issn = {1573-1405},
  doi = {10.1007/s11263-016-0981-7},
  url = {https://doi.org/10.1007/s11263-016-0981-7},
  urldate = {2024-04-10},
  langid = {english}
}

@misc{lin2015microsoft,
      title={Microsoft COCO: Common Objects in Context},
      author={Tsung-Yi Lin and Michael Maire and Serge Belongie and Lubomir Bourdev and Ross Girshick and James Hays and Pietro Perona and Deva Ramanan and C. Lawrence Zitnick and Piotr Dollár},
      year={2015},
      eprint={1405.0312},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}


@inproceedings{yu2021ap,
  title={AP-10K: A Benchmark for Animal Pose Estimation in the Wild},
  author={Yu, Hang and Xu, Yufei and Zhang, Jing and Zhao, Wei and Guan, Ziyu and Tao, Dacheng},
  booktitle={Thirty-fifth Conference on Neural Information Processing Systems Datasets and Benchmarks Track (Round 2)},
  year={2021}
}


@online{kirillovSegmentAnything2023,
  title = {Segment {{Anything}}},
  author = {Kirillov, Alexander and Mintun, Eric and Ravi, Nikhila and Mao, Hanzi and Rolland, Chloe and Gustafson, Laura and Xiao, Tete and Whitehead, Spencer and Berg, Alexander C. and Lo, Wan-Yen and Dollár, Piotr and Girshick, Ross},
  year = {2023-04-05},
  eprint = {2304.02643},
  eprinttype = {arxiv},
  doi = {10.48550/arXiv.2304.02643},
  url = {http://arxiv.org/abs/2304.02643},
  urldate = {2023-11-08},
  pubstate = {preprint}
}


@article{lai2023lisa,
  title={Lisa: Reasoning segmentation via large language model},
  author={Lai, Xin and Tian, Zhuotao and Chen, Yukang and Li, Yanwei and Yuan, Yuhui and Liu, Shu and Jia, Jiaya},
  journal={arXiv preprint arXiv:2308.00692},
  year={2023}
}

@inproceedings{kirillov2023segment,
  title={Segment anything},
  author={Kirillov, Alexander and Mintun, Eric and Ravi, Nikhila and Mao, Hanzi and Rolland, Chloe and Gustafson, Laura and Xiao, Tete and Whitehead, Spencer and Berg, Alexander C and Lo, Wan-Yen and others},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={4015--4026},
  year={2023}
}


@inproceedings{youFerretReferGround2023,
  title = {Ferret: {{Refer}} and {{Ground Anything Anywhere}} at {{Any Granularity}}},
  shorttitle = {Ferret},
  author = {You, Haoxuan and Zhang, Haotian and Gan, Zhe and Du, Xianzhi and Zhang, Bowen and Wang, Zirui and Cao, Liangliang and Chang, Shih-Fu and Yang, Yinfei},
  year = {2023-10-13},
  url = {https://openreview.net/forum?id=2msbbX3ydD},
  urldate = {2024-04-13},
  booktitle = {The {{Twelfth International Conference}} on {{Learning Representations}}},
  langid = {english}
}

@misc{yang2024enhancing,
      title={Enhancing Visual Grounding and Generalization: A Multi-Task Cycle Training Approach for Vision-Language Models}, 
      author={Xiaoyu Yang and Lijian Xu and Hao Sun and Hongsheng Li and Shaoting Zhang},
      year={2024},
      eprint={2311.12327},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      journal={arXiv preprint arXiv:2311.12327},
}


@article{liDDGDataDistributionGeneration2022,
  title = {{{DDG-DA}}: {{Data Distribution Generation}} for {{Predictable Concept Drift Adaptation}}},
  shorttitle = {{{DDG-DA}}},
  author = {Li, Wendi and Yang, Xiao and Liu, Weiqing and Xia, Yingce and Bian, Jiang},
  year = {2022-06-28},
  journaltitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  volume = {36},
  number = {4},
  pages = {4092--4100},
  issn = {2374-3468},
  doi = {10.1609/aaai.v36i4.20327},
  url = {https://ojs.aaai.org/index.php/AAAI/article/view/20327},
  urldate = {2024-09-28},
  langid = {english}
}

@inproceedings{xuLearningImbalancedData2023,
  title = {Learning {{Imbalanced Data With Vision Transformers}}},
  author = {Xu, Zhengzhuo and Liu, Ruikang and Yang, Shuo and Chai, Zenghao and Yuan, Chun},
  year = {2023},
  pages = {15793--15803},
  url = {https://openaccess.thecvf.com/content/CVPR2023/html/Xu_Learning_Imbalanced_Data_With_Vision_Transformers_CVPR_2023_paper.html},
  urldate = {2024-09-29},
  booktitle = {Proceedings of the {{IEEE}}/{{CVF Conference}} on {{Computer Vision}} and {{Pattern Recognition}}},
  langid = {english}
}


@online{dongLPTEfficientTraining2024,
  title = {{{LPT}}++: {{Efficient Training}} on {{Mixture}} of {{Long-tailed Experts}}},
  shorttitle = {{{LPT}}++},
  author = {Dong, Bowen and Zhou, Pan and Zuo, Wangmeng},
  year = {2024-09-17},
  eprint = {2409.11323},
  eprinttype = {arXiv},
  eprintclass = {cs},
  year = {2024},
  doi = {10.48550/arXiv.2409.11323},
  url = {http://arxiv.org/abs/2409.11323},
  urldate = {2024-09-29},
  pubstate = {prepublished}
}

@online{maSimpleLongTailedRecognition2021,
  title = {A {{Simple Long-Tailed Recognition Baseline}} via {{Vision-Language Model}}},
  author = {Ma, Teli and Geng, Shijie and Wang, Mengmeng and Shao, Jing and Lu, Jiasen and Li, Hongsheng and Gao, Peng and Qiao, Yu},
  year = {2021-11-29},
  eprint = {2111.14745},
  eprinttype = {arXiv},
  doi = {10.48550/arXiv.2111.14745},
  url = {http://arxiv.org/abs/2111.14745},
  urldate = {2024-03-25},
  year = {2021},
  pubstate = {prepublished}
}

@article{wangExploringVisionLanguageModels2024,
  title = {Exploring {{Vision-Language Models}} for {{Imbalanced Learning}}},
  author = {Wang, Yidong and Yu, Zhuohao and Wang, Jindong and Heng, Qiang and Chen, Hao and Ye, Wei and Xie, Rui and Xie, Xing and Zhang, Shikun},
  year = {2024-01-01},
  journaltitle = {International Journal of Computer Vision},
  shortjournal = {Int J Comput Vis},
  volume = {132},
  number = {1},
  pages = {224--237},
  issn = {1573-1405},
  year = {2024},
  doi = {10.1007/s11263-023-01868-w},
  url = {https://doi.org/10.1007/s11263-023-01868-w},
  urldate = {2024-09-29},
  langid = {english}
}

@inproceedings{shiLongTailLearningFoundation2024,
  title = {Long-{{Tail Learning}} with {{Foundation Model}}: {{Heavy Fine-Tuning Hurts}}},
  shorttitle = {Long-{{Tail Learning}} with {{Foundation Model}}},
  author = {Shi, Jiang-Xin and Wei, Tong and Zhou, Zhi and Shao, Jie-Jing and Han, Xin-Yan and Li, Yu-Feng},
  year = {2024},
  year = {2024-06-06},
  url = {https://openreview.net/forum?id=ccSSKTz9LX},
  urldate = {2024-09-26},
  booktitle = {Forty-First {{International Conference}} on {{Machine Learning}}},
  langid = {english}
}

@inproceedings{tianVLLTRLearningClasswise2022,
  title = {{{VL-LTR}}: {{Learning Class-wise Visual-Linguistic Representation}} for~{{Long-Tailed Visual Recognition}}},
  shorttitle = {{{VL-LTR}}},
  booktitle = {Computer {{Vision}} – {{ECCV}} 2022},
  author = {Tian, Changyao and Wang, Wenhai and Zhu, Xizhou and Dai, Jifeng and Qiao, Yu},
  editor = {Avidan, Shai and Brostow, Gabriel and Cissé, Moustapha and Farinella, Giovanni Maria and Hassner, Tal},
  year = {2022},
  pages = {73--91},
  publisher = {Springer Nature Switzerland},
  location = {Cham},
  doi = {10.1007/978-3-031-19806-9_5},
  isbn = {978-3-031-19806-9},
  langid = {english}
}

@inproceedings{suhLongTailedRecognitionMutual2023,
  title = {Long-{{Tailed Recognition}} by {{Mutual Information Maximization}} between {{Latent Features}} and {{Ground-Truth Labels}}},
  booktitle = {Proceedings of the 40th {{International Conference}} on {{Machine Learning}}},
  author = {Suh, Min-Kook and Seo, Seung-Woo},
  year = {2023-07-03},
  year = {2023},
  pages = {32770--32782},
  publisher = {PMLR},
  url = {https://proceedings.mlr.press/v202/suh23a.html},
  urldate = {2024-09-29},
  eventtitle = {International {{Conference}} on {{Machine Learning}}},
  langid = {english}
}

@article{dongLPTLongtailedPrompt2023,
  title = {{{LPT}}: {{Long-tailed}} Prompt Tuning for Image Classification},
  shorttitle = {{{LPT}}},
  author = {DONG, Bowen and ZHOU, Pan and YAN, Shuicheng and ZUO, Wangmeng},
  year = {2023},
  year = {2023-05-01},
  journaltitle = {Proceedings of The Eleventh International Conference on Learning Representations, ICLR 2023, Kigali, Rwanda, May 1-5},
  pages = {1--20},
  url = {https://ink.library.smu.edu.sg/sis_research/8982}
}



@inproceedings{heMaskedAutoencodersAre2022,
  title = {Masked {{Autoencoders Are Scalable Vision Learners}}},
  author = {He, Kaiming and Chen, Xinlei and Xie, Saining and Li, Yanghao and Dollár, Piotr and Girshick, Ross},
  year = {2022},
  pages = {16000--16009},
  url = {https://openaccess.thecvf.com/content/CVPR2022/html/He_Masked_Autoencoders_Are_Scalable_Vision_Learners_CVPR_2022_paper.html},
  urldate = {2023-06-08},
  booktitle = {Proceedings of the {{IEEE}}/{{CVF Conference}} on {{Computer Vision}} and {{Pattern Recognition}}},
  langid = {english}
}

@inproceedings{touvronDeiTIIIRevenge2022,
  title = {{{DeiT III}}: {{Revenge}} of~the~{{ViT}}},
  shorttitle = {{{DeiT III}}},
  booktitle = {Computer {{Vision}} – {{ECCV}} 2022},
  author = {Touvron, Hugo and Cord, Matthieu and Jégou, Hervé},
  editor = {Avidan, Shai and Brostow, Gabriel and Cissé, Moustapha and Farinella, Giovanni Maria and Hassner, Tal},
  year = {2022},
  pages = {516--533},
  publisher = {Springer Nature Switzerland},
  location = {Cham},
  doi = {10.1007/978-3-031-20053-3_30},
  isbn = {978-3-031-20053-3},
  langid = {english}
}

@inproceedings{kandpalLargeLanguageModels2023,
  title = {Large {{Language Models Struggle}} to {{Learn Long-Tail Knowledge}}},
  booktitle = {Proceedings of the 40th {{International Conference}} on {{Machine Learning}}},
  author = {Kandpal, Nikhil and Deng, Haikang and Roberts, Adam and Wallace, Eric and Raffel, Colin},
  year = {2023-07-03},
  year = {2023},
  pages = {15696--15707},
  publisher = {PMLR},
  issn = {2640-3498},
  url = {https://proceedings.mlr.press/v202/kandpal23a.html},
  urldate = {2024-03-14},
  eventtitle = {International {{Conference}} on {{Machine Learning}}},
  langid = {english}
}



@article{liAlignFuseVision2021,
  title = {Align before Fuse: {{Vision}} and Language Representation Learning with Momentum Distillation},
  shorttitle = {Align before Fuse},
  author = {Li, Junnan and Selvaraju, Ramprasaath and Gotmare, Akhilesh and Joty, Shafiq and Xiong, Caiming and Hoi, Steven Chu Hong},
  year = {2021},
  journaltitle = {Advances in neural information processing systems},
  volume = {34},
  pages = {9694--9705},
  url = {https://proceedings.neurips.cc/paper_files/paper/2021/hash/505259756244493872b7709a8a01b536-Abstract.html},
  urldate = {2024-11-19}
}

@inproceedings{wangLearningRobustGlobal2019,
  title = {Learning {{Robust Global Representations}} by {{Penalizing Local Predictive Power}}},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  author = {Wang, Haohan and Ge, Songwei and Lipton, Zachary and Xing, Eric P},
  year = {2019},
  volume = {32},
  publisher = {Curran Associates, Inc.},
  url = {https://proceedings.neurips.cc/paper/2019/hash/3eefceb8087e964f89c2d59e8a249915-Abstract.html},
  urldate = {2024-11-20}
}


@article{zhouLearningPromptVisionLanguage2022,
  title = {Learning to {{Prompt}} for {{Vision-Language Models}}},
  author = {Zhou, Kaiyang and Yang, Jingkang and Loy, Chen Change and Liu, Ziwei},
  year = {2022},
  journaltitle = {International Journal of Computer Vision},
  shortjournal = {Int J Comput Vis},
  volume = {130},
  number = {9},
  pages = {2337--2348},
  issn = {1573-1405},
  doi = {10.1007/s11263-022-01653-1},
  url = {https://doi.org/10.1007/s11263-022-01653-1},
  urldate = {2024-11-20},
  langid = {english}
}

@inproceedings{jiaVisualPromptTuning2022,
  title = {Visual {{Prompt Tuning}}},
  booktitle = {Computer {{Vision}} – {{ECCV}} 2022},
  author = {Jia, Menglin and Tang, Luming and Chen, Bor-Chun and Cardie, Claire and Belongie, Serge and Hariharan, Bharath and Lim, Ser-Nam},
  editor = {Avidan, Shai and Brostow, Gabriel and Cissé, Moustapha and Farinella, Giovanni Maria and Hassner, Tal},
  year = {2022},
  pages = {709--727},
  publisher = {Springer Nature Switzerland},
  location = {Cham},
  doi = {10.1007/978-3-031-19827-4_41},
  isbn = {978-3-031-19827-4},
  langid = {english}
}

@inproceedings{choDistributionAwarePromptTuning2023,
  title = {Distribution-{{Aware Prompt Tuning}} for {{Vision-Language Models}}},
  author = {Cho, Eulrang and Kim, Jooyeon and Kim, Hyunwoo J.},
  year = {2023},
  pages = {22004--22013},
  url = {https://openaccess.thecvf.com/content/ICCV2023/html/Cho_Distribution-Aware_Prompt_Tuning_for_Vision-Language_Models_ICCV_2023_paper.html},
  urldate = {2024-11-20},
  booktitle = {Proceedings of the {{IEEE}}/{{CVF International Conference}} on {{Computer Vision}}},
  langid = {english}
}



@article{tangUncoveringIntrinsicData2022,
  title = {Towards {{Uncovering}} the {{Intrinsic Data Structures}} for {{Unsupervised Domain Adaptation Using Structurally Regularized Deep Clustering}}},
  author = {Tang, Hui and Zhu, Xiatian and Chen, Ke and Jia, Kui and Chen, C. L. Philip},
  year = {2022-10},
  journaltitle = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  volume = {44},
  number = {10},
  pages = {6517--6533},
  issn = {1939-3539},
  doi = {10.1109/TPAMI.2021.3087830},
  url = {https://ieeexplore.ieee.org/abstract/document/9449976},
  urldate = {2024-11-20},
  eventtitle = {{{IEEE Transactions}} on {{Pattern Analysis}} and {{Machine Intelligence}}}
}

@inproceedings{grillBootstrapYourOwn2020,
  title = {Bootstrap {{Your Own Latent}} - {{A New Approach}} to {{Self-Supervised Learning}}},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  author = {Grill, Jean-Bastien and Strub, Florian and Altché, Florent and Tallec, Corentin and Richemond, Pierre and Buchatskaya, Elena and Doersch, Carl and Avila Pires, Bernardo and Guo, Zhaohan and Gheshlaghi Azar, Mohammad and Piot, Bilal and {kavukcuoglu}, koray and Munos, Remi and Valko, Michal},
  year = {2020},
  volume = {33},
  pages = {21271--21284},
  publisher = {Curran Associates, Inc.},
  url = {https://proceedings.neurips.cc/paper/2020/hash/f3ada80d5c4ee70142b17b8192b2958e-Abstract.html},
  urldate = {2025-01-11}
}

@inproceedings{vaswaniAttentionAllYou2017,
  title = {Attention Is {{All}} You {{Need}}},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  author = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, Lukasz and Polosukhin, Illia},
  year = {2017},
  volume = {30},
  publisher = {Curran Associates, Inc.},
  url = {https://proceedings.neurips.cc/paper/2017/hash/3f5ee243547dee91fbd053c1c4a845aa-Abstract.html},
  urldate = {2023-01-06},
  langid = {american}
}

@inproceedings{chenExploringSimpleSiamese2021,
  title = {Exploring {{Simple Siamese Representation Learning}}},
  author = {Chen, Xinlei and He, Kaiming},
  year = {2021},
  pages = {15750--15758},
  url = {https://openaccess.thecvf.com/content/CVPR2021/html/Chen_Exploring_Simple_Siamese_Representation_Learning_CVPR_2021_paper.html},
  urldate = {2025-01-12},
  booktitle = {Proceedings of the {{IEEE}}/{{CVF Conference}} on {{Computer Vision}} and {{Pattern Recognition}}},
  langid = {english}
}

@online{yangMaskedImageContrastive2024,
  title = {Masked {{Image Contrastive Learning}} for {{Efficient Visual Conceptual Pre-training}}},
  author = {Yang, Xiaoyu and Xu, Lijian},
  year = {2024},
  eprint = {2411.09858},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2411.09858},
  url = {http://arxiv.org/abs/2411.09858},
  urldate = {2025-01-13},
  pubstate = {prepublished}
}

@article{muennighoffScalingDataConstrainedLanguage2023,
  title = {Scaling {{Data-Constrained Language Models}}},
  author = {Muennighoff, Niklas and Rush, Alexander and Barak, Boaz and Le Scao, Teven and Tazi, Nouamane and Piktus, Aleksandra and Pyysalo, Sampo and Wolf, Thomas and Raffel, Colin A.},
  year = {2023},
  journaltitle = {Advances in Neural Information Processing Systems},
  volume = {36},
  pages = {50358--50376},
  url = {https://proceedings.neurips.cc/paper_files/paper/2023/hash/9d89448b63ce1e2e8dc7af72c984c196-\\Abstract-Conference.html},
  urldate = {2025-01-13},
  langid = {english}
}

@article{hendrycks2016baseline,
  title={A baseline for detecting misclassified and out-of-distribution examples in neural networks},
  author={Hendrycks, Dan and Gimpel, Kevin},
  journal={arXiv preprint arXiv:1610.02136},
  year={2016}
}

@article{liu2020energy,
  title={Energy-based out-of-distribution detection},
  author={Liu, Weitang and Wang, Xiaoyun and Owens, John and Li, Yixuan},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={21464--21475},
  year={2020}
}

@article{hendrycks2019scaling,
  title={Scaling out-of-distribution detection for real-world settings},
  author={Hendrycks, Dan and Basart, Steven and Mazeika, Mantas and Zou, Andy and Kwon, Joe and Mostajabi, Mohammadreza and Steinhardt, Jacob and Song, Dawn},
  journal={arXiv preprint arXiv:1911.11132},
  year={2019}
}

@inproceedings{wang2022vim,
  title={Vim: Out-of-distribution with virtual-logit matching},
  author={Wang, Haoqi and Li, Zhizhong and Feng, Litong and Zhang, Wayne},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={4921--4930},
  year={2022}
}

@article{sun2021react,
  title={React: Out-of-distribution detection with rectified activations},
  author={Sun, Yiyou and Guo, Chuan and Li, Yixuan},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={144--157},
  year={2021}
}

@article{lee2018simple,
  title={A simple unified framework for detecting out-of-distribution samples and adversarial attacks},
  author={Lee, Kimin and Lee, Kibok and Lee, Honglak and Shin, Jinwoo},
  journal={Advances in neural information processing systems},
  volume={31},
  year={2018}
}

@inproceedings{li2023rethinking,
  title={Rethinking out-of-distribution (ood) detection: Masked image modeling is all you need},
  author={Li, Jingyao and Chen, Pengguang and He, Zexin and Yu, Shaozuo and Liu, Shu and Jia, Jiaya},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={11578--11589},
  year={2023}
}

@article{liMOODv2MaskedImage2024,
  title = {{{MOODv2}}: {{Masked Image Modeling}} for {{Out-of-Distribution Detection}}},
  shorttitle = {{{MOODv2}}},
  author = {Li, Jingyao and Chen, Pengguang and Yu, Shaozuo and Liu, Shu and Jia, Jiaya},
  year = {2024},
  journaltitle = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  volume = {46},
  number = {12},
  pages = {8994--9003},
  issn = {0162-8828},
  doi = {10.1109/TPAMI.2024.3412004},
  url = {https://www.computer.org/csdl/journal/tp/2024/12/10553645/1XH2Iao33Z6},
  urldate = {2025-01-13},
  langid = {american}
}


@inproceedings{cimpoi2014describing,
  title={Describing textures in the wild},
  author={Cimpoi, Mircea and Maji, Subhransu and Kokkinos, Iasonas and Mohamed, Sammy and Vedaldi, Andrea},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={3606--3613},
  year={2014}
}

@inproceedings{van2018inaturalist,
  title={The inaturalist species classification and detection dataset},
  author={Van Horn, Grant and Mac Aodha, Oisin and Song, Yang and Cui, Yin and Sun, Chen and Shepard, Alex and Adam, Hartwig and Perona, Pietro and Belongie, Serge},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={8769--8778},
  year={2018}
}

@inproceedings{huangMOSScalingOutofDistribution2021,
  title = {{{MOS}}: {{Towards Scaling Out-of-Distribution Detection}} for {{Large Semantic Space}}},
  shorttitle = {{{MOS}}},
  author = {Huang, Rui and Li, Yixuan},
  year = {2021},
  pages = {8710--8719},
  url = {https://openaccess.thecvf.com/content/CVPR2021/html/Huang_MOS_Towards_Scaling_Out-of-Distribution_Detection_for_Large_Semantic_Space_CVPR_2021_paper.html},
  urldate = {2025-01-16},
  booktitle = {Proceedings of the {{IEEE}}/{{CVF Conference}} on {{Computer Vision}} and {{Pattern Recognition}}},
  langid = {english}
}



@inproceedings{vanhornINaturalistSpeciesClassification2018a,
  title = {The {{INaturalist Species Classification}} and {{Detection Dataset}}},
  author = {Van Horn, Grant and Mac Aodha, Oisin and Song, Yang and Cui, Yin and Sun, Chen and Shepard, Alex and Adam, Hartwig and Perona, Pietro and Belongie, Serge},
  year = {2018},
  pages = {8769--8778},
  url = {https://openaccess.thecvf.com/content_cvpr_2018/html/Van_Horn_The_INaturalist_Species_CVPR_2018_paper.html},
  urldate = {2025-01-20},
  booktitle = {Proceedings of the {{IEEE Conference}} on {{Computer Vision}} and {{Pattern Recognition}}}
}

@inproceedings{hendrycksManyFacesRobustness2021,
  title = {The {{Many Faces}} of {{Robustness}}: {{A Critical Analysis}} of {{Out-of-Distribution Generalization}}},
  shorttitle = {The {{Many Faces}} of {{Robustness}}},
  author = {Hendrycks, Dan and Basart, Steven and Mu, Norman and Kadavath, Saurav and Wang, Frank and Dorundo, Evan and Desai, Rahul and Zhu, Tyler and Parajuli, Samyak and Guo, Mike and Song, Dawn and Steinhardt, Jacob and Gilmer, Justin},
  year = {2021},
  pages = {8340--8349},
  url = {https://openaccess.thecvf.com/content/ICCV2021/html/Hendrycks_The_Many_Faces_of_Robustness_A_Critical_Analysis_of_Out-of-Distribution_ICCV_2021_paper.html},
  urldate = {2024-11-21},
  booktitle = {Proceedings of the {{IEEE}}/{{CVF International Conference}} on {{Computer Vision}}},
  langid = {english}
}



@inproceedings{rechtImageNetClassifiersGeneralize2019,
  title = {Do {{ImageNet Classifiers Generalize}} to {{ImageNet}}?},
  booktitle = {Proceedings of the 36th {{International Conference}} on {{Machine Learning}}},
  author = {Recht, Benjamin and Roelofs, Rebecca and Schmidt, Ludwig and Shankar, Vaishaal},
  year = {2019},
  pages = {5389--5400},
  publisher = {PMLR},
  url = {https://proceedings.mlr.press/v97/recht19a.html},
  urldate = {2025-01-21},
  eventtitle = {International {{Conference}} on {{Machine Learning}}},
  langid = {english}
}

@inproceedings{hendrycksNaturalAdversarialExamples2021,
  title = {Natural {{Adversarial Examples}}},
  author = {Hendrycks, Dan and Zhao, Kevin and Basart, Steven and Steinhardt, Jacob and Song, Dawn},
  year = {2021},
  pages = {15262--15271},
  url = {https://openaccess.thecvf.com/content/CVPR2021/html/Hendrycks_Natural_Adversarial_Examples_CVPR_2021_paper.html},
  urldate = {2024-11-21},
  eventtitle = {Proceedings of the {{IEEE}}/{{CVF Conference}} on {{Computer Vision}} and {{Pattern Recognition}}},
  langid = {english}
}

@inproceedings{wangViMOutofDistributionVirtualLogit2022,
  title = {{{ViM}}: {{Out-of-Distribution With Virtual-Logit Matching}}},
  shorttitle = {{{ViM}}},
  author = {Wang, Haoqi and Li, Zhizhong and Feng, Litong and Zhang, Wayne},
  year = {2022},
  pages = {4921--4930},
  url = {https://openaccess.thecvf.com/content/CVPR2022/html/Wang_ViM_Out-of-Distribution_With_Virtual-Logit_Matching_CVPR_2022_paper.html},
  urldate = {2025-01-21},
  eventtitle = {Proceedings of the {{IEEE}}/{{CVF Conference}} on {{Computer Vision}} and {{Pattern Recognition}}},
  langid = {english}
}

@online{ridnikImageNet21KPretrainingMasses2021,
  title = {{{ImageNet-21K Pretraining}} for the {{Masses}}},
  author = {Ridnik, Tal and Ben-Baruch, Emanuel and Noy, Asaf and Zelnik-Manor, Lihi},
  year = {2021},
  eprint = {2104.10972},
  eprinttype = {arXiv},
  doi = {10.48550/arXiv.2104.10972},
  url = {http://arxiv.org/abs/2104.10972},
  urldate = {2025-01-21},
  pubstate = {prepublished}
}

@article{yuDetectingGroupConcept2023,
  title = {Detecting Group Concept Drift from Multiple Data Streams},
  author = {Yu, Hang and Liu, Weixu and Lu, Jie and Wen, Yimin and Luo, Xiangfeng and Zhang, Guangquan},
  year = {2023},
  journaltitle = {Pattern Recognition},
  shortjournal = {Pattern Recognition},
  volume = {134},
  pages = {109113},
  issn = {0031-3203},
  doi = {10.1016/j.patcog.2022.109113},
  url = {https://www.sciencedirect.com/science/article/pii/S0031320322005933},
  urldate = {2024-04-26}
}

@article{wangSelfadaptiveEnsembleUser2024,
  title = {A Self-Adaptive Ensemble for User Interest Drift Learning},
  author = {Wang, Kun and Xiong, Li and Liu, Anjin and Zhang, Guangquan and Lu, Jie},
  year = {2024},
  journaltitle = {Neurocomputing},
  shortjournal = {Neurocomputing},
  volume = {577},
  pages = {127308},
  issn = {0925-2312},
  doi = {10.1016/j.neucom.2024.127308},
  url = {https://www.sciencedirect.com/science/article/pii/S0925231224000791},
  urldate = {2024-02-21}
}

@article{jiaoDynamicEnsembleSelection2024,
  title = {Dynamic {{Ensemble Selection}} for {{Imbalanced Data Streams With Concept Drift}}},
  author = {Jiao, Botao and Guo, Yinan and Gong, Dunwei and Chen, Qiuju},
  year = {2024},
  journaltitle = {IEEE Transactions on Neural Networks and Learning Systems},
  volume = {35},
  number = {1},
  pages = {1278--1291},
  issn = {2162-2388},
  doi = {10.1109/TNNLS.2022.3183120},
  url = {https://ieeexplore.ieee.org/abstract/document/9802893},
  urldate = {2024-05-20}
}

@article{cerqueiraSTUDDStudentTeacher2023,
  title = {{{STUDD}}: A Student–Teacher Method for Unsupervised Concept Drift Detection},
  shorttitle = {{{STUDD}}},
  author = {Cerqueira, Vitor and Gomes, Heitor Murilo and Bifet, Albert and Torgo, Luis},
  year = {2023},
  journaltitle = {Machine Learning},
  shortjournal = {Mach Learn},
  volume = {112},
  number = {11},
  pages = {4351--4378},
  issn = {1573-0565},
  doi = {10.1007/s10994-022-06188-7},
  url = {https://doi.org/10.1007/s10994-022-06188-7},
  urldate = {2024-03-04},
  langid = {english}
}

@article{yuLearnadaptConceptDrift2022,
  title = {Learn-to-Adapt: {{Concept}} Drift Adaptation for Hybrid Multiple Streams},
  shorttitle = {Learn-to-Adapt},
  author = {Yu, En and Song, Yiliao and Zhang, Guangquan and Lu, Jie},
  year = {2022},
  journaltitle = {Neurocomputing},
  shortjournal = {Neurocomputing},
  volume = {496},
  pages = {121--130},
  issn = {0925-2312},
  doi = {10.1016/j.neucom.2022.05.025},
  url = {https://www.sciencedirect.com/science/article/pii/S0925231222005550},
  urldate = {2024-03-04}
}

@inproceedings{dengComprehensiveKnowledgeDistillation2021,
  title = {Comprehensive {{Knowledge Distillation}} with {{Causal Intervention}}},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  author = {Deng, Xiang and Zhang, Zhongfei},
  year = {2021},
  volume = {34},
  pages = {22158--22170},
  publisher = {Curran Associates, Inc.},
  url = {https://proceedings.neurips.cc/paper/2021/hash/b9f35816f460ab999cbc168c4da26ff3-Abstract.html},
  urldate = {2024-12-13},
  langid = {american}
}


@online{zhangCausalWalkDebiasing2024,
  title = {Causal {{Walk}}: {{Debiasing Multi-Hop Fact Verification}} with {{Front-Door Adjustment}}},
  shorttitle = {Causal {{Walk}}},
  author = {Zhang, Congzhi and Zhang, Linhai and Zhou, Deyu},
  year = {2024},
  eprint = {2403.02698},
  eprinttype = {arXiv},
  doi = {10.48550/arXiv.2403.02698},
  url = {http://arxiv.org/abs/2403.02698},
  urldate = {2025-01-09},
  langid = {american},
  pubstate = {prepublished}
}




@inproceedings{tangLongTailedClassificationKeeping2021,
  title = {Long-{{Tailed Classification}} by {{Keeping}} the {{Good}} and {{Removing}} the {{Bad Momentum Causal Effect}}},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  author = {Tang, Kaihua and Huang, Jianqiang and Zhang, Hanwang},
  year = {2021},
  url = {https://proceedings.neurips.cc//paper/2020/file/1091660f3dff84fd648efe31391c5524-Paper.pdf},
  urldate = {2021-06-09},
  eventtitle = {Advances in {{Neural Information Processing Systems}}},
  langid = {english}
}







@inproceedings{wangDenseContrastiveLearning2021a,
  title = {Dense {{Contrastive Learning}} for {{Self-Supervised Visual Pre-Training}}},
  author = {Wang, Xinlong and Zhang, Rufeng and Shen, Chunhua and Kong, Tao and Li, Lei},
  year = {2021},
  pages = {3024--3033},
  url = {https://openaccess.thecvf.com/content/CVPR2021/html/Wang_Dense_Contrastive_Learning_for_Self-Supervised_Visual_Pre-Training_CVPR_2021_paper.html},
  urldate = {2025-01-29},
  booktitle = {Proceedings of the {{IEEE}}/{{CVF Conference}} on {{Computer Vision}} and {{Pattern Recognition}}},
  langid = {english}
}

@article{lu2020data,
  title={Data-driven decision support under concept drift in streamed big data},
  author={Lu, Jie and Liu, Anjin and Song, Yiliao and Zhang, Guangquan},
  journal={Complex \& intelligent systems},
  volume={6},
  number={1},
  pages={157--163},
  year={2020},
  publisher={Springer}
}