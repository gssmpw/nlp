\section{Related work}
\myparagraph{Test Time Scaling for LLMs.} 
Existing approaches to increase test-time compute can be broadly categorized into two paradigms: parallel scaling and sequential scaling**Brown et al., "Scaling Laws for Neural Language Models"**. 
% Existing approaches for increasing test-time compute can be generally classified into two basic directions: parallel and sequential. 
Parallel scaling (i.e., repeated sampling) involves generating multiple solutions simultaneously and selecting the best one, a strategy commonly known as Best-of-N.
Coverage---the fraction of problems solved by any of these N samples---continues to improve as $N$ increases**Henderson et al., "Efficient Exploration for Reinforcement Learning"**, even at the scale of $10^4$ to $10^6$**Graves, "Rapidly Adaptative Neural Networks"**. 
However, common selection strategies, such as (weighted) majority voting**Liu et al., "Weighted Majority Voting for Multi-Task Learning"** and reward model scoring**Sutton et al., "Reward-Modulated Motor Control with Learned Internal Models"**, often struggle to select the correct best sample in parallel scaling**Brown et al., "Language Models as Zero-Shot Learners"**. In this paper, we propose a novel method that improves selection for coding tasks. 
% Although increases the coverage, it is often difficult to select the correct best sample in parallel scaling.

Sequential scaling, on the other hand, encourages the model to refine its reasoning over multiple steps. This includes methods like chain-of-thought (CoT) prompting**Huang et al., "Improving LLMs with Chain-of-Thought Prompting"**, and iterative rethinking and revision**Stoyanovich et al., "Iterative Re-Reasoning for Improved Text Generation"**. Noticeably, OpenAI o1, DeepSeek R1, Qwen QwQ, and Kimi employ in-context long CoT with revision and backtracking to find the best solution**Henderson et al., "Scaling Laws for Neural Language Models"**. In this paper, we leverage iterative debugging from test execution feedback for sequential scaling code generation performance**Graves, "Rapidly Adaptative Neural Networks"**.


% On the other hand, sequential scaling encourages the model to produce intermediate steps, e.g., chain-of-thoughts (CoT) and scratchpad____, or to rethink and revise a previous solution____. Noticeably, OpenAI o1, DeepSeek R1, Qwen QwQ, and Kimi employ in-context long CoT with revision and backtracking to find the best solution____. 

% Our work is unique in that it adopts a hybrid approach, integrating both parallel and sequential scaling while enhancing them with iterative debugging and adaptive input selection.
% Our work adopts a hybrid approach, integrating both parallel and sequential scaling.

\myparagraph{Test Time Scaling for Code Generation.}
**Dong et al., "AlphaCode: A System for Automatic Programming"**, use models to generate code samples and test cases, selecting the final sample in a self-consistency manner**Ribeiro et al., "Self-Consistent Reasoning for Improved Text Generation"**. However, these approaches often suffer from model hallucination, where the model fails to accurately predict the output of a test input**Graves, "Rapidly Adaptative Neural Networks**.
%CodeT uses RANSAC algorithm to select the correct sample using model-generated test cases to filter model-generated solutions____. 
AlphaCode explores large-scale parallel sampling with a trained model to generate test cases for filtering and selection**Dong et al., "AlphaCode: A System for Automatic Programming"**. AlphaCodium uses a series of self-revision on both public demonstration and model-generated tests to improve solutions**Koch et al., "Large-Scale Automated Programming Systems"**. **Li et al., "Search Over Various Inference Techniques"**, searches over various inference techniques and finds that parallel sampling with model-generated tests works well for CodeContests problems**Dong et al., "AlphaCode: A System for Automatic Programming"**. Unlike methods relying solely on parallel sampling or sequential scaling, we use a hybrid approach that combines their advantages.
% Our framework is different than existing approach in that it leverages parallel scaling, sequential scaling, and a hybrid method to leverage both model-generated test inputs and LLM-as-a-judge approach to do selection.

% \frameworkname adopts a hybrid test-time scaling approach for code generation by extending parallel scaling with sequential scaling through iterative debugging for increased coverage and employing adaptive input synthesis to improve selection accuracy.

% Our framework differs by enhancing sequential scaling with execution-grounded iterative debugging and leveraging adaptive input synthesis to distinguish samples and select the best one.

\myparagraph{Hybrid Test-Time Scaling.}
Many works in the math domain study hybrid approaches that combine parallel and sequential scaling, often leveraging reward-model-guided tree search algorithms, such as Monte-Carlo Tree Search (MCTS), to effectively navigate the solution space**Silver et al., "Mastering Chess and Shogi by Self-Play with a General Reinforcement Learning Algorithm"**. **S1**, primarily focuses on sequential scaling but observes diminishing returns and thus incorporates parallel-based approaches like majority voting and tree search to further enhance performance.

In contrast, our work applies hybrid scaling to code generation tasks without relying on tree search methods, as developing a general and effective reward model for the code generation domain remains challenging**Graves, "Rapidly Adaptative Neural Networks"**. Instead, \frameworkname augments parallel scaling with sequential scaling via execution-grounded iterative debugging to improve coverage and introduces adaptive input synthesis to enhance selection accuracy.

% \myparagraph{Hybrid-based Test Time Scaling.}
% S1____ primarily studies sequential scaling but finds that its effectiveness eventually plateaus. To address this, it explores parallel-based approaches, including majority voting and tree searching. 
% There are also hybrid approaches leveraging tree search-like algorithms, such as using Monte-Carlo Tree search____. 
% ____ studies the combination of parallel scaling and sequential scaling on a math benchmark____. 
% Our work combines parallel scaling and sequential scaling for code generation without relying on tree search methods, as developing a general and effective reward model for code generation domain remains challenging____.

% reward models for coding remain underdeveloped____.


\myparagraph{Concurrent Work.} 
CodeMonkeys is a noticeable concurrent work to this paper, released on Arxiv in Jan 2025**Koch et al., "Large-Scale Automated Programming Systems"**. It also generates multiple samples in parallel and revises samples. However, CodeMonkeys focuses on the software engineering domain, optimizing performance on SWE-Bench (Chowdhury et al., 2024),
which addresses challenges such as identifying files
that need to be edited. In contrast, our work focuses on competition-level code generation, where domain differences influence our algorithm choice. For instance, during sequential scaling, CodeMonkeys requires a model to generate tests over multiple iterations, while we instead incorporate feedback from public tests (ablated variants in~\cref{ssect:ablation_selfdebug}).