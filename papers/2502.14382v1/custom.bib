% Use this file for citations not found in the ACL Anthology (contained in "anthology.bib").

@book{Aho:72,
    author  = {Alfred V. Aho and Jeffrey D. Ullman},
    title   = {The Theory of Parsing, Translation and Compiling},
    year    = "1972",
    volume  = "1",
    publisher = {Prentice-Hall},
    address = {Englewood Cliffs, NJ}
}

@book{APA:83,
    author  = {{American Psychological Association}},
    title   = {Publications Manual},
    year    = "1983",
    publisher = {American Psychological Association},
    address = {Washington, DC}
}

@article{Chandra:81,
	author = {Ashok K. Chandra and Dexter C. Kozen and Larry J. Stockmeyer},
	year = "1981",
	title = {Alternation},
	journal = {Journal of the Association for Computing Machinery},
	volume = "28",
	number = "1",
	pages = "114--133",
	doi = "10.1145/322234.322243",
}

@inproceedings{andrew2007scalable,
  title={Scalable training of {L1}-regularized log-linear models},
  author={Andrew, Galen and Gao, Jianfeng},
  booktitle={Proceedings of the 24th International Conference on Machine Learning},
  pages={33--40},
  year={2007},
}

@book{Gusfield:97,
    author  = {Dan Gusfield},
    title   = {Algorithms on Strings, Trees and Sequences},
    year    = "1997",
    publisher = {Cambridge University Press},
    address = {Cambridge, UK}
}

@article{rasooli-tetrault-2015,
    author    = {Mohammad Sadegh Rasooli and Joel R. Tetreault},
    title     = {Yara Parser: {A} Fast and Accurate Dependency Parser},
    journal   = {Computing Research Repository},
    volume    = {arXiv:1503.06733},
    year      = {2015},
    url       = {http://arxiv.org/abs/1503.06733},
    note    = {version 2}
}

@article{Ando2005,
	Acmid = {1194905},
	Author = {Ando, Rie Kubota and Zhang, Tong},
	Issn = {1532-4435},
	Issue_Date = {12/1/2005},
	Journal = {Journal of Machine Learning Research},
	Month = dec,
	Numpages = {37},
	Pages = {1817--1853},
	Publisher = {JMLR.org},
	Title = {A Framework for Learning Predictive Structures from Multiple Tasks and Unlabeled Data},
	Volume = {6},
	Year = {2005}
}

@inproceedings{langley00,
 author    = {P. Langley},
 title     = {Crafting Papers on Machine Learning},
 year      = {2000},
 pages     = {1207--1216},
 editor    = {Pat Langley},
 booktitle     = {Proceedings of the 17th International Conference
              on Machine Learning (ICML 2000)},
 address   = {Stanford, CA},
 publisher = {Morgan Kaufmann}
}

@misc{beeching2024dvts,
      title={Scaling test-time compute with open models},
      author={Edward Beeching and Lewis Tunstall and Sasha Rush},
      url={https://huggingface.co/spaces/HuggingFaceH4/blogpost-scaling-test-time-compute},
}

@TechReport{mitchell80,
  author = 	 "T. M. Mitchell",
  title = 	 "The Need for Biases in Learning Generalizations",
  institution =  "Computer Science Department, Rutgers University",
  year = 	 "1980",
  address =	 "New Brunswick, MA",
}

@phdthesis{kearns89,
  author = {M. J. Kearns},
  title =  {Computational Complexity of Machine Learning},
  school = {Department of Computer Science, Harvard University},
  year =   {1989}
}

@Book{MachineLearningI,
  editor = 	 "R. S. Michalski and J. G. Carbonell and T.
		  M. Mitchell",
  title = 	 "Machine Learning: An Artificial Intelligence
		  Approach, Vol. I",
  publisher = 	 "Tioga",
  year = 	 "1983",
  address =	 "Palo Alto, CA"
}

@Book{DudaHart2nd,
  author =       "R. O. Duda and P. E. Hart and D. G. Stork",
  title =        "Pattern Classification",
  publisher =    "John Wiley and Sons",
  edition =      "2nd",
  year =         "2000"
}

@misc{anonymous,
  title= {Suppressed for Anonymity},
  author= {Author, N. N.},
  year= {2021}
}

@InCollection{Newell81,
  author =       "A. Newell and P. S. Rosenbloom",
  title =        "Mechanisms of Skill Acquisition and the Law of
                  Practice", 
  booktitle =    "Cognitive Skills and Their Acquisition",
  pages =        "1--51",
  publisher =    "Lawrence Erlbaum Associates, Inc.",
  year =         "1981",
  editor =       "J. R. Anderson",
  chapter =      "1",
  address =      "Hillsdale, NJ"
}


@Article{Samuel59,
  author = 	 "A. L. Samuel",
  title = 	 "Some Studies in Machine Learning Using the Game of
		  Checkers",
  journal =	 "IBM Journal of Research and Development",
  year =	 "1959",
  volume =	 "3",
  number =	 "3",
  pages =	 "211--229"
}

@misc{openai_learning_to_reason_2024,
  author       = {OpenAI},
  title        = {Learning to Reason with LLMs},
  year         = {2024},
  howpublished = {\url{https://openai.com/index/learning-to-reason-with-llms/}},
  note         = {Accessed: 2024-11-20}
}

@article{snell2024scaling,
  title={Scaling llm test-time compute optimally can be more effective than scaling model parameters},
  author={Snell, Charlie and Lee, Jaehoon and Xu, Kelvin and Kumar, Aviral},
  journal={arXiv preprint arXiv:2408.03314},
  year={2024}
}

@misc{deepseek_r1_lite_2024,
  author       = {DeepSeek},
  title        = {DeepSeek-R1-Lite-Preview Release},
  year         = {2024},
  howpublished = {\url{https://api-docs.deepseek.com/news/news1120}},
  note         = {Accessed: 2024-11-20}
}

@misc{qwen_qwq_2024,
  author       = {Qwen},
  title        = {QwQ: Reflect Deeply on the Boundaries of the Unknown},
  year         = {2024},
  howpublished = {\url{https://qwenlm.github.io/blog/qwq-32b-preview/}}
}

@article{hendrycks2021measuring,
  title={Measuring coding challenge competence with apps},
  author={Hendrycks, Dan and Basart, Steven and Kadavath, Saurav and Mazeika, Mantas and Arora, Akul and Guo, Ethan and Burns, Collin and Puranik, Samir and He, Horace and Song, Dawn and others},
  journal={arXiv preprint arXiv:2105.09938},
  year={2021}
}

@article{achiam2023gpt,
  title={Gpt-4 technical report},
  author={Achiam, Josh and Adler, Steven and Agarwal, Sandhini and Ahmad, Lama and Akkaya, Ilge and Aleman, Florencia Leoni and Almeida, Diogo and Altenschmidt, Janko and Altman, Sam and Anadkat, Shyamal and others},
  journal={arXiv preprint arXiv:2303.08774},
  year={2023}
}

@article{hui2024qwen2,
  title={Qwen2. 5-Coder Technical Report},
  author={Hui, Binyuan and Yang, Jian and Cui, Zeyu and Yang, Jiaxi and Liu, Dayiheng and Zhang, Lei and Liu, Tianyu and Zhang, Jiajun and Yu, Bowen and Dang, Kai and others},
  journal={arXiv preprint arXiv:2409.12186},
  year={2024}
}
@article{qwen2,
    title={Qwen2 Technical Report},
    author={An Yang and Baosong Yang and Binyuan Hui and Bo Zheng and Bowen Yu and Chang Zhou and Chengpeng Li and Chengyuan Li and Dayiheng Liu and Fei Huang and Guanting Dong and Haoran Wei and Huan Lin and Jialong Tang and Jialin Wang and Jian Yang and Jianhong Tu and Jianwei Zhang and Jianxin Ma and Jin Xu and Jingren Zhou and Jinze Bai and Jinzheng He and Junyang Lin and Kai Dang and Keming Lu and Keqin Chen and Kexin Yang and Mei Li and Mingfeng Xue and Na Ni and Pei Zhang and Peng Wang and Ru Peng and Rui Men and Ruize Gao and Runji Lin and Shijie Wang and Shuai Bai and Sinan Tan and Tianhang Zhu and Tianhao Li and Tianyu Liu and Wenbin Ge and Xiaodong Deng and Xiaohuan Zhou and Xingzhang Ren and Xinyu Zhang and Xipin Wei and Xuancheng Ren and Yang Fan and Yang Yao and Yichang Zhang and Yu Wan and Yunfei Chu and Yuqiong Liu and Zeyu Cui and Zhenru Zhang and Zhihao Fan},
    journal={arXiv preprint arXiv:2407.10671},
    year={2024}
}


@article{lightman2023let,
  title={Let's verify step by step},
  author={Lightman, Hunter and Kosaraju, Vineet and Burda, Yura and Edwards, Harri and Baker, Bowen and Lee, Teddy and Leike, Jan and Schulman, John and Sutskever, Ilya and Cobbe, Karl},
  journal={arXiv preprint arXiv:2305.20050},
  year={2023}
}

@article{wei2022chain,
  title={Chain-of-thought prompting elicits reasoning in large language models},
  author={Wei, Jason and Wang, Xuezhi and Schuurmans, Dale and Bosma, Maarten and Xia, Fei and Chi, Ed and Le, Quoc V and Zhou, Denny and others},
  journal={Advances in neural information processing systems},
  volume={35},
  pages={24824--24837},
  year={2022}
}

@article{khattab2023dspy,
  title={Dspy: Compiling declarative language model calls into self-improving pipelines},
  author={Khattab, Omar and Singhvi, Arnav and Maheshwari, Paridhi and Zhang, Zhiyuan and Santhanam, Keshav and Vardhamanan, Sri and Haq, Saiful and Sharma, Ashutosh and Joshi, Thomas T and Moazam, Hanna and others},
  journal={arXiv preprint arXiv:2310.03714},
  year={2023}
}

@article{madaan2024self,
  title={Self-refine: Iterative refinement with self-feedback},
  author={Madaan, Aman and Tandon, Niket and Gupta, Prakhar and Hallinan, Skyler and Gao, Luyu and Wiegreffe, Sarah and Alon, Uri and Dziri, Nouha and Prabhumoye, Shrimai and Yang, Yiming and others},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@article{ye2024physics,
  title={Physics of Language Models: Part 2.2, How to Learn From Mistakes on Grade-School Math Problems},
  author={Ye, Tian and Xu, Zicheng and Li, Yuanzhi and Allen-Zhu, Zeyuan},
  journal={arXiv preprint arXiv:2408.16293},
  year={2024}
}

@article{zheng2023judging,
  title={Judging llm-as-a-judge with mt-bench and chatbot arena},
  author={Zheng, Lianmin and Chiang, Wei-Lin and Sheng, Ying and Zhuang, Siyuan and Wu, Zhanghao and Zhuang, Yonghao and Lin, Zi and Li, Zhuohan and Li, Dacheng and Xing, Eric and others},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  pages={46595--46623},
  year={2023}
}

@article{chen2022codet,
  title={Codet: Code generation with generated tests},
  author={Chen, Bei and Zhang, Fengji and Nguyen, Anh and Zan, Daoguang and Lin, Zeqi and Lou, Jian-Guang and Chen, Weizhu},
  journal={arXiv preprint arXiv:2207.10397},
  year={2022}
}

@article{chen2023teaching,
  title={Teaching large language models to self-debug},
  author={Chen, Xinyun and Lin, Maxwell and Sch{\"a}rli, Nathanael and Zhou, Denny},
  journal={arXiv preprint arXiv:2304.05128},
  year={2023}
}

@article{liu2024lost,
  title={Lost in the middle: How language models use long contexts},
  author={Liu, Nelson F and Lin, Kevin and Hewitt, John and Paranjape, Ashwin and Bevilacqua, Michele and Petroni, Fabio and Liang, Percy},
  journal={Transactions of the Association for Computational Linguistics},
  volume={12},
  pages={157--173},
  year={2024},
  publisher={MIT Press One Broadway, 12th Floor, Cambridge, Massachusetts 02142, USA~â€¦}
}

@article{jain2024livecodebench,
  title={Livecodebench: Holistic and contamination free evaluation of large language models for code},
  author={Jain, Naman and Han, King and Gu, Alex and Li, Wen-Ding and Yan, Fanjia and Zhang, Tianjun and Wang, Sida and Solar-Lezama, Armando and Sen, Koushik and Stoica, Ion},
  journal={arXiv preprint arXiv:2403.07974},
  year={2024}
}

@article{chen2021evaluating,
  title={Evaluating large language models trained on code},
  author={Chen, Mark and Tworek, Jerry and Jun, Heewoo and Yuan, Qiming and Pinto, Henrique Ponde De Oliveira and Kaplan, Jared and Edwards, Harri and Burda, Yuri and Joseph, Nicholas and Brockman, Greg and others},
  journal={arXiv preprint arXiv:2107.03374},
  year={2021}
}

@article{hendrycksapps2021,
  title={Measuring Coding Challenge Competence With APPS},
  author={Dan Hendrycks and Steven Basart and Saurav Kadavath and Mantas Mazeika and Akul Arora and Ethan Guo and Collin Burns and Samir Puranik and Horace He and Dawn Song and Jacob Steinhardt},
  journal={NeurIPS},
  year={2021}
}

@article{li2022competition,
  title={Competition-level code generation with alphacode},
  author={Li, Yujia and Choi, David and Chung, Junyoung and Kushman, Nate and Schrittwieser, Julian and Leblond, R{\'e}mi and Eccles, Tom and Keeling, James and Gimeno, Felix and Dal Lago, Agustin and others},
  journal={Science},
  volume={378},
  number={6624},
  pages={1092--1097},
  year={2022},
  publisher={American Association for the Advancement of Science}
}

@article{brown2024large,
  title={Large language monkeys: Scaling inference compute with repeated sampling},
  author={Brown, Bradley and Juravsky, Jordan and Ehrlich, Ryan and Clark, Ronald and Le, Quoc V and R{\'e}, Christopher and Mirhoseini, Azalia},
  journal={arXiv preprint arXiv:2407.21787},
  year={2024}
}

@article{muennighoff2025s1,
  title={s1: Simple test-time scaling},
  author={Muennighoff, Niklas and Yang, Zitong and Shi, Weijia and Li, Xiang Lisa and Fei-Fei, Li and Hajishirzi, Hannaneh and Zettlemoyer, Luke and Liang, Percy and Cand{\`e}s, Emmanuel and Hashimoto, Tatsunori},
  journal={arXiv preprint arXiv:2501.19393},
  year={2025}
}

@article{ehrlich2025codemonkeys,
  title={CodeMonkeys: Scaling Test-Time Compute for Software Engineering},
  author={Ehrlich, Ryan and Brown, Bradley and Juravsky, Jordan and Clark, Ronald and R{\'e}, Christopher and Mirhoseini, Azalia},
  journal={arXiv preprint arXiv:2501.14723},
  year={2025}
}

@misc{sky_t1_2025,
  author       = {NovaSky Team},
  title        = {Sky-T1: Train your own O1 preview model within 450 dollars},
  howpublished = {https://novasky-ai.github.io/posts/sky-t1},
  note         = {Accessed: 2025-01-09},
  year         = {2025}
}


@article{wang2022self,
  title={Self-consistency improves chain of thought reasoning in language models},
  author={Wang, Xuezhi and Wei, Jason and Schuurmans, Dale and Le, Quoc and Chi, Ed and Narang, Sharan and Chowdhery, Aakanksha and Zhou, Denny},
  journal={arXiv preprint arXiv:2203.11171},
  year={2022}
}

@article{christiano2017deep,
  title={Deep reinforcement learning from human preferences},
  author={Christiano, Paul F and Leike, Jan and Brown, Tom and Martic, Miljan and Legg, Shane and Amodei, Dario},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}

@article{chollet2019measure,
  title={On the measure of intelligence},
  author={Chollet, Fran{\c{c}}ois},
  journal={arXiv preprint arXiv:1911.01547},
  year={2019}
}

@article{irvine2023rewarding,
  title={Rewarding chatbots for real-world engagement with millions of users},
  author={Irvine, Robert and Boubert, Douglas and Raina, Vyas and Liusie, Adian and Zhu, Ziyi and Mudupalli, Vineet and Korshuk, Aliaksei and Liu, Zongyi and Cremer, Fritz and Assassi, Valentin and others},
  journal={arXiv preprint arXiv:2303.06135},
  year={2023}
}

@inproceedings{wang2024math,
  title={Math-shepherd: Verify and reinforce llms step-by-step without human annotations},
  author={Wang, Peiyi and Li, Lei and Shao, Zhihong and Xu, Runxin and Dai, Damai and Li, Yifei and Chen, Deli and Wu, Yu and Sui, Zhifang},
  booktitle={Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
  pages={9426--9439},
  year={2024}
}

@article{hassid2024larger,
  title={The Larger the Better? Improved LLM Code-Generation via Budget Reallocation},
  author={Hassid, Michael and Remez, Tal and Gehring, Jonas and Schwartz, Roy and Adi, Yossi},
  journal={arXiv preprint arXiv:2404.00725},
  year={2024}
}

@article{stroebl2024inference,
  title={Inference Scaling fLaws: The Limits of LLM Resampling with Imperfect Verifiers},
  author={Stroebl, Benedikt and Kapoor, Sayash and Narayanan, Arvind},
  journal={arXiv preprint arXiv:2411.17501},
  year={2024}
}

@article{nye2021show,
  title={Show your work: Scratchpads for intermediate computation with language models},
  author={Nye, Maxwell and Andreassen, Anders Johan and Gur-Ari, Guy and Michalewski, Henryk and Austin, Jacob and Bieber, David and Dohan, David and Lewkowycz, Aitor and Bosma, Maarten and Luan, David and others},
  journal={arXiv preprint arXiv:2112.00114},
  year={2021}
}

@article{hou2025advancing,
  title={Advancing Language Model Reasoning through Reinforcement Learning and Inference Scaling},
  author={Hou, Zhenyu and Lv, Xin and Lu, Rui and Zhang, Jiajie and Li, Yujiang and Yao, Zijun and Li, Juanzi and Tang, Jie and Dong, Yuxiao},
  journal={arXiv preprint arXiv:2501.11651},
  year={2025}
}

@article{lee2025evolving,
  title={Evolving Deeper LLM Thinking},
  author={Lee, Kuang-Huei and Fischer, Ian and Wu, Yueh-Hua and Marwood, Dave and Baluja, Shumeet and Schuurmans, Dale and Chen, Xinyun},
  journal={arXiv preprint arXiv:2501.09891},
  year={2025}
}

@article{huang2022large,
  title={Large language models can self-improve},
  author={Huang, Jiaxin and Gu, Shixiang Shane and Hou, Le and Wu, Yuexin and Wang, Xuezhi and Yu, Hongkun and Han, Jiawei},
  journal={arXiv preprint arXiv:2210.11610},
  year={2022}
}

@article{min2024imitate,
  title={Imitate, explore, and self-improve: A reproduction report on slow-thinking reasoning systems},
  author={Min, Yingqian and Chen, Zhipeng and Jiang, Jinhao and Chen, Jie and Deng, Jia and Hu, Yiwen and Tang, Yiru and Wang, Jiapeng and Cheng, Xiaoxue and Song, Huatong and others},
  journal={arXiv preprint arXiv:2412.09413},
  year={2024}
}

@article{guo2025deepseek,
  title={Deepseek-r1: Incentivizing reasoning capability in llms via reinforcement learning},
  author={Guo, Daya and Yang, Dejian and Zhang, Haowei and Song, Junxiao and Zhang, Ruoyu and Xu, Runxin and Zhu, Qihao and Ma, Shirong and Wang, Peiyi and Bi, Xiao and others},
  journal={arXiv preprint arXiv:2501.12948},
  year={2025}
}

@article{team2025kimi,
  title={Kimi k1. 5: Scaling Reinforcement Learning with LLMs},
  author={Team, Kimi and Du, Angang and Gao, Bofei and Xing, Bowei and Jiang, Changjiu and Chen, Cheng and Li, Cheng and Xiao, Chenjun and Du, Chenzhuang and Liao, Chonghua and others},
  journal={arXiv preprint arXiv:2501.12599},
  year={2025}
}

@article{gao2024interpretable,
  title={Interpretable contrastive monte carlo tree search reasoning},
  author={Gao, Zitian and Niu, Boye and He, Xuzheng and Xu, Haotian and Liu, Hongzhang and Liu, Aiwei and Hu, Xuming and Wen, Lijie},
  journal={arXiv preprint arXiv:2410.01707},
  year={2024}
}

@article{wang2024theoretical,
  title={A Theoretical Understanding of Self-Correction through In-context Alignment},
  author={Wang, Yifei and Wu, Yuyang and Wei, Zeming and Jegelka, Stefanie and Wang, Yisen},
  journal={arXiv preprint arXiv:2405.18634},
  year={2024}
}

@article{saad2024archon,
  title={Archon: An architecture search framework for inference-time techniques},
  author={Saad-Falcon, Jon and Lafuente, Adrian Gamarra and Natarajan, Shlok and Maru, Nahum and Todorov, Hristo and Guha, Etash and Buchanan, E Kelly and Chen, Mayee and Guha, Neel and R{\'e}, Christopher and others},
  journal={arXiv preprint arXiv:2409.15254},
  year={2024}
}

@article{li2024rethinkmcts,
  title={RethinkMCTS: Refining Erroneous Thoughts in Monte Carlo Tree Search for Code Generation},
  author={Li, Qingyao and Xia, Wei and Du, Kounianhua and Dai, Xinyi and Tang, Ruiming and Wang, Yasheng and Yu, Yong and Zhang, Weinan},
  journal={arXiv preprint arXiv:2409.09584},
  year={2024}
}

@article{hao2023reasoning,
  title={Reasoning with language model is planning with world model},
  author={Hao, Shibo and Gu, Yi and Ma, Haodi and Hong, Joshua Jiahua and Wang, Zhen and Wang, Daisy Zhe and Hu, Zhiting},
  journal={arXiv preprint arXiv:2305.14992},
  year={2023}
}

@article{silver2016mastering,
  title={Mastering the game of Go with deep neural networks and tree search},
  author={Silver, David and Huang, Aja and Maddison, Chris J and Guez, Arthur and Sifre, Laurent and Van Den Driessche, George and Schrittwieser, Julian and Antonoglou, Ioannis and Panneershelvam, Veda and Lanctot, Marc and others},
  journal={nature},
  volume={529},
  number={7587},
  pages={484--489},
  year={2016},
  publisher={Nature Publishing Group}
}

@article{wu2024inference,
  title={Inference scaling laws: An empirical analysis of compute-optimal inference for problem-solving with language models},
  author={Wu, Yangzhen and Sun, Zhiqing and Li, Shanda and Welleck, Sean and Yang, Yiming},
  journal={arXiv preprint arXiv:2408.00724},
  year={2024}
}

@article{AceCoder,
    title={AceCoder: Acing Coder RL via Automated Test-Case Synthesis},
    author={Zeng, Huaye and Jiang, Dongfu and Wang, Haozhe and Nie, Ping and Chen, Xiaotong and Chen, Wenhu},
    journal={ArXiv},
    year={2025},
    volume={2502.01718}
}

@article{ridnik2024code,
  title={Code generation with alphacodium: From prompt engineering to flow engineering},
  author={Ridnik, Tal and Kredo, Dedy and Friedman, Itamar},
  journal={arXiv preprint arXiv:2401.08500},
  year={2024}
}

@misc{chowdhury2024introducing,
  title={Introducing swe-bench verified},
  author={Chowdhury, Neil and Aung, James and Shern, Chan Jun and Jaffe, Oliver and Sherburn, Dane and Starace, Giulio and Mays, Evan and Dias, Rachel and Aljubeh, Marwan and Glaese, Mia and others},
  year={2024},
  publisher={Aug}
}

@article{li2023taco,
  title={Taco: Topics in algorithmic code generation dataset},
  author={Li, Rongao and Fu, Jie and Zhang, Bo-Wen and Huang, Tao and Sun, Zhihong and Lyu, Chen and Liu, Guang and Jin, Zhi and Li, Ge},
  journal={arXiv preprint arXiv:2312.14852},
  year={2023}
}

@article{gulwani4foundations,
  title={Foundations and trends in programming languages},
  author={Gulwani, Sumit and Polozov, Oleksandr and Singh, Rishabh},
  journal={Bd},
  volume={4},
  pages={1--119}
}

@article{liu2023your,
  title={Is your code generated by chatgpt really correct? rigorous evaluation of large language models for code generation},
  author={Liu, Jiawei and Xia, Chunqiu Steven and Wang, Yuyao and Zhang, Lingming},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  pages={21558--21572},
  year={2023}
}

@article{li2024numinamath,
  title={Numinamath: The largest public dataset in ai4maths with 860k pairs of competition math problems and solutions},
  author={Li, Jia and Beeching, Edward and Tunstall, Lewis and Lipkin, Ben and Soletskyi, Roman and Huang, Shengyi and Rasul, Kashif and Yu, Longhui and Jiang, Albert Q and Shen, Ziju and others},
  journal={Hugging Face repository},
  volume={13},
  pages={9},
  year={2024}
}

@article{huang2023enhancing,
  title={Enhancing large language models in coding through multi-perspective self-consistency},
  author={Huang, Baizhou and Lu, Shuai and Chen, Weizhu and Wan, Xiaojun and Duan, Nan},
  journal={arXiv preprint arXiv:2309.17272},
  year={2023}
}

@article{jiao2024preference,
  title={Preference Optimization for Reasoning with Pseudo Feedback},
  author={Jiao, Fangkai and Guo, Geyang and Zhang, Xingxing and Chen, Nancy F and Joty, Shafiq and Wei, Furu},
  journal={arXiv preprint arXiv:2411.16345},
  year={2024}
}

@article{gu2024cruxeval,
  title={Cruxeval: A benchmark for code reasoning, understanding and execution},
  author={Gu, Alex and Rozi{\`e}re, Baptiste and Leather, Hugh and Solar-Lezama, Armando and Synnaeve, Gabriel and Wang, Sida I},
  journal={arXiv preprint arXiv:2401.03065},
  year={2024}
}

@article{jimenez2023swe,
  title={Swe-bench: Can language models resolve real-world github issues?},
  author={Jimenez, Carlos E and Yang, John and Wettig, Alexander and Yao, Shunyu and Pei, Kexin and Press, Ofir and Narasimhan, Karthik},
  journal={arXiv preprint arXiv:2310.06770},
  year={2023}
}

@article{pan2024swegym,
  title   = {Training Software Engineering Agents and Verifiers with SWE-Gym},
  author  = {Jiayi Pan and Xingyao Wang and Graham Neubig and Navdeep Jaitly and Heng Ji and Alane Suhr and Yizhe Zhang},
  year    = {2024},
  journal = {arXiv preprint arXiv: 2412.21139}
}

@article{li2025llms,
  title={LLMs Can Easily Learn to Reason from Demonstrations Structure, not content, is what matters!},
  author={Li, Dacheng and Cao, Shiyi and Griggs, Tyler and Liu, Shu and Mo, Xiangxi and Patil, Shishir G and Zaharia, Matei and Gonzalez, Joseph E and Stoica, Ion},
  journal={arXiv preprint arXiv:2502.07374},
  year={2025}
}

@article{lambert2024t,
  title={T$\backslash$" ulu 3: Pushing frontiers in open language model post-training},
  author={Lambert, Nathan and Morrison, Jacob and Pyatkin, Valentina and Huang, Shengyi and Ivison, Hamish and Brahman, Faeze and Miranda, Lester James V and Liu, Alisa and Dziri, Nouha and Lyu, Shane and others},
  journal={arXiv preprint arXiv:2411.15124},
  year={2024}
}

@article{robertson2009probabilistic,
  title={The probabilistic relevance framework: BM25 and beyond},
  author={Robertson, Stephen and Zaragoza, Hugo and others},
  journal={Foundations and Trends{\textregistered} in Information Retrieval},
  volume={3},
  number={4},
  pages={333--389},
  year={2009},
  publisher={Now Publishers, Inc.}
}