@inproceedings{NEURIPS2023_06fc38f5,
 author = {Wang, Kaiwen and Zhou, Kevin and Wu, Runzhe and Kallus, Nathan and Sun, Wen},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {A. Oh and T. Naumann and A. Globerson and K. Saenko and M. Hardt and S. Levine},
 pages = {2275--2312},
 publisher = {Curran Associates, Inc.},
 title = {The Benefits of Being Distributional: Small-Loss Bounds for Reinforcement Learning},
 url = {https://proceedings.neurips.cc/paper_files/paper/2023/file/06fc38f5c21ae66ef955e28b7a78ece5-Paper-Conference.pdf},
 volume = {36},
 year = {2023}
}

@article{bauerle2011markov,
  title={Markov decision processes with average-value-at-risk criteria},
  author={B{\"a}uerle, Nicole and Ott, Jonathan},
  journal={Mathematical Methods of Operations Research},
  volume={74},
  pages={361--379},
  year={2011},
  publisher={Springer}
}

@book{bdr2022,
    title={Distributional Reinforcement Learning},
    author={Marc G. Bellemare and Will Dabney and Mark Rowland},
    publisher={{MIT} Press},
    note={\url{http://www.distributional-rl.org}},
    year={2023}
}

@inproceedings{bellemare2017distributional,
  title={A distributional perspective on reinforcement learning},
  author={Bellemare, Marc G and Dabney, Will and Munos, R{\'e}mi},
  booktitle={International conference on machine learning},
  pages={449--458},
  year={2017},
  organization={PMLR}
}

@inproceedings{bellemare2019distributional,
  title={Distributional reinforcement learning with linear function approximation},
  author={Bellemare, Marc G and Le Roux, Nicolas and Castro, Pablo Samuel and Moitra, Subhodeep},
  booktitle={The 22nd International Conference on Artificial Intelligence and Statistics},
  pages={2203--2211},
  year={2019},
  organization={PMLR}
}

@inproceedings{bertsekas1995neuro,
  title={Neuro-dynamic programming: an overview},
  author={Bertsekas, Dimitri P and Tsitsiklis, John N},
  booktitle={Proceedings of 1995 34th IEEE conference on decision and control},
  volume={1},
  pages={560--564},
  year={1995},
  organization={IEEE}
}

@inproceedings{bhandari2018finite,
  title={A finite time analysis of temporal difference learning with linear function approximation},
  author={Bhandari, Jalaj and Russo, Daniel and Singal, Raghav},
  booktitle={Conference on learning theory},
  pages={1691--1692},
  year={2018},
  organization={PMLR}
}

@article{chen2024lyapunov,
  title={A lyapunov theory for finite-sample guarantees of markovian stochastic approximation},
  author={Chen, Zaiwei and Maguluri, Siva T and Shakkottai, Sanjay and Shanmugam, Karthikeyan},
  journal={Operations Research},
  volume={72},
  number={4},
  pages={1352--1367},
  year={2024},
  publisher={INFORMS}
}

@article{chow2014algorithms,
  title={Algorithms for CVaR optimization in MDPs},
  author={Chow, Yinlam and Ghavamzadeh, Mohammad},
  journal={Advances in neural information processing systems},
  volume={27},
  year={2014}
}

@inproceedings{dalal2018finite,
  title={Finite sample analyses for TD (0) with function approximation},
  author={Dalal, Gal and Sz{\"o}r{\'e}nyi, Bal{\'a}zs and Thoppe, Gugan and Mannor, Shie},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={32},
  year={2018}
}

@inproceedings{duan2023finite,
  title={A finite-sample analysis of multi-step temporal difference estimates},
  author={Duan, Yaqi and Wainwright, Martin J},
  booktitle={Learning for Dynamics and Control Conference},
  pages={612--624},
  year={2023},
  organization={PMLR}
}

@article{durmus2024finite,
  title={Finite-Time High-Probability Bounds for Polyak--Ruppert Averaged Iterates of Linear Stochastic Approximation},
  author={Durmus, Alain and Moulines, Eric and Naumov, Alexey and Samsonov, Sergey},
  journal={Mathematics of Operations Research},
  year={2024},
  publisher={INFORMS}
}

@inproceedings{huo2023bias,
  title={Bias and extrapolation in Markovian linear stochastic approximation with constant stepsizes},
  author={Huo, Dongyan and Chen, Yudong and Xie, Qiaomin},
  booktitle={Abstract Proceedings of the 2023 ACM SIGMETRICS International Conference on Measurement and Modeling of Computer Systems},
  pages={81--82},
  year={2023}
}

@inproceedings{lakshminarayanan2018linear,
  title={Linear stochastic approximation: How far does constant step-size and iterate averaging go?},
  author={Lakshminarayanan, Chandrashekar and Szepesvari, Csaba},
  booktitle={International conference on artificial intelligence and statistics},
  pages={1347--1355},
  year={2018},
  organization={PMLR}
}

@article{li2023online,
  title={Online statistical inference for nonlinear stochastic approximation with markovian data},
  author={Li, Xiang and Liang, Jiadong and Zhang, Zhihua},
  journal={arXiv preprint arXiv:2302.07690},
  year={2023}
}

@article{li2024high,
  title={High-probability sample complexities for policy evaluation with linear function approximation},
  author={Li, Gen and Wu, Weichen and Chi, Yuejie and Ma, Cong and Rinaldo, Alessandro and Wei, Yuting},
  journal={IEEE Transactions on Information Theory},
  year={2024},
  publisher={IEEE}
}

@article{li2024q,
  title={Is Q-learning minimax optimal? a tight sample complexity analysis},
  author={Li, Gen and Cai, Changxiao and Chen, Yuxin and Wei, Yuting and Chi, Yuejie},
  journal={Operations Research},
  volume={72},
  number={1},
  pages={222--236},
  year={2024},
  publisher={INFORMS}
}

@inproceedings{lyle2019comparative,
  title={A comparative analysis of expected and distributional reinforcement learning},
  author={Lyle, Clare and Bellemare, Marc G and Castro, Pablo Samuel},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={33},
  pages={4504--4511},
  year={2019}
}

@inproceedings{mou2020linear,
  title={On linear stochastic approximation: Fine-grained Polyak-Ruppert and non-asymptotic concentration},
  author={Mou, Wenlong and Li, Chris Junchi and Wainwright, Martin J and Bartlett, Peter L and Jordan, Michael I},
  booktitle={Conference on Learning Theory},
  pages={2947--2997},
  year={2020},
  organization={PMLR}
}

@inproceedings{mou2022optimal,
  title={Optimal and instance-dependent guarantees for Markovian linear stochastic approximation},
  author={Mou, Wenlong and Pananjady, Ashwin and Wainwright, Martin and Bartlett, Peter},
  booktitle={Conference on Learning Theory},
  pages={2060--2061},
  year={2022},
  organization={PMLR}
}

@inproceedings{noorani2023exponential,
  title={Exponential TD Learning: A Risk-Sensitive Actor-Critic Reinforcement Learning Algorithm},
  author={Noorani, Erfaun and Mavridis, Christos N and Baras, John S},
  booktitle={2023 American Control Conference (ACC)},
  pages={4104--4109},
  year={2023},
  organization={IEEE}
}

@inproceedings{patil2023finite,
  title={Finite time analysis of temporal difference learning with linear function approximation: Tail averaging and regularisation},
  author={Patil, Gandharv and Prashanth, LA and Nagaraj, Dheeraj and Precup, Doina},
  booktitle={International Conference on Artificial Intelligence and Statistics},
  pages={5438--5448},
  year={2023},
  organization={PMLR}
}

@article{pires2025optimizing,
  title={Optimizing Return Distributions with Distributional Dynamic Programming},
  author={Pires, Bernardo {\'A}vila and Rowland, Mark and Borsa, Diana and Guo, Zhaohan Daniel and Khetarpal, Khimya and Barreto, Andr{\'e} and Abel, David and Munos, R{\'e}mi and Dabney, Will},
  journal={arXiv preprint arXiv:2501.13028},
  year={2025}
}

@InProceedings{pmlr-v202-wu23s,
  title = 	 {Distributional Offline Policy Evaluation with Predictive Error Guarantees},
  author =       {Wu, Runzhe and Uehara, Masatoshi and Sun, Wen},
  booktitle = 	 {Proceedings of the 40th International Conference on Machine Learning},
  pages = 	 {37685--37712},
  year = 	 {2023},
  editor = 	 {Krause, Andreas and Brunskill, Emma and Cho, Kyunghyun and Engelhardt, Barbara and Sabato, Sivan and Scarlett, Jonathan},
  volume = 	 {202},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {23--29 Jul},
  publisher =    {PMLR},
  pdf = 	 {https://proceedings.mlr.press/v202/wu23s/wu23s.pdf},
  url = 	 {https://proceedings.mlr.press/v202/wu23s.html},
}

@InProceedings{pmlr-v97-qu19b,
  title = 	 {Nonlinear Distributional Gradient Temporal-Difference Learning},
  author =       {Qu, Chao and Mannor, Shie and Xu, Huan},
  booktitle = 	 {Proceedings of the 36th International Conference on Machine Learning},
  pages = 	 {5251--5260},
  year = 	 {2019},
  editor = 	 {Chaudhuri, Kamalika and Salakhutdinov, Ruslan},
  volume = 	 {97},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {09--15 Jun},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v97/qu19b/qu19b.pdf},
  url = 	 {https://proceedings.mlr.press/v97/qu19b.html},
  abstract = 	 {We devise a distributional variant of gradient temporal-difference (TD) learning. Distributional reinforcement learning has been demonstrated to outperform the regular one in the recent study \citep{bellemare2017distributional}. In the policy evaluation setting, we design two new algorithms called distributional GTD2 and distributional TDC using the Cram{Ã©}r distance on the distributional version of the Bellman error objective function, which inherits advantages of both the nonlinear gradient TD algorithms and the distributional RL approach. In the control setting, we propose the distributional Greedy-GQ using similar derivation. We prove the asymptotic almost-sure convergence of distributional GTD2 and TDC to a local optimal solution for general smooth function approximators, which includes neural networks that have been widely used in recent study to solve the real-life RL problems. In each step, the computational complexity of above three algorithms is linear w.r.t. the number of the parameters of the function approximator, thus can be implemented efficiently for neural networks.}
}

@inproceedings{rowland2018analysis,
  title={An analysis of categorical distributional reinforcement learning},
  author={Rowland, Mark and Bellemare, Marc and Dabney, Will and Munos, R{\'e}mi and Teh, Yee Whye},
  booktitle={International Conference on Artificial Intelligence and Statistics},
  pages={29--37},
  year={2018},
  organization={PMLR}
}

@inproceedings{rowland2023statistical,
  title={The statistical benefits of quantile temporal-difference learning for value estimation},
  author={Rowland, Mark and Tang, Yunhao and Lyle, Clare and Munos, R{\'e}mi and Bellemare, Marc G and Dabney, Will},
  booktitle={International Conference on Machine Learning},
  pages={29210--29231},
  year={2023},
  organization={PMLR}
}

@article{rowland2024analysis,
  title={An analysis of quantile temporal-difference learning},
  author={Rowland, Mark and Munos, R{\'e}mi and Azar, Mohammad Gheshlaghi and Tang, Yunhao and Ostrovski, Georg and Harutyunyan, Anna and Tuyls, Karl and Bellemare, Marc G and Dabney, Will},
  journal={Journal of Machine Learning Research},
  volume={25},
  pages={1--47},
  year={2024}
}

@inproceedings{samsonov2024improved,
  title={Improved High-Probability Bounds for the Temporal Difference Learning Algorithm via Exponential Stability},
  author={Samsonov, Sergey and Tiapkin, Daniil and Naumov, Alexey and Moulines, Eric},
  booktitle={The Thirty Seventh Annual Conference on Learning Theory},
  pages={4511--4547},
  year={2024},
  organization={PMLR}
}

@article{speedy,
author = {B\"{o}ck, Markus and Heitzinger, Clemens},
title = {Speedy Categorical Distributional Reinforcement Learning and Complexity Analysis},
journal = {SIAM Journal on Mathematics of Data Science},
volume = {4},
number = {2},
pages = {675-693},
year = {2022},
doi = {10.1137/20M1364436},
URL = { 
        https://doi.org/10.1137/20M1364436
},
eprint = { 
        https://doi.org/10.1137/20M1364436
}
,
}

@inproceedings{srikant2019finite,
  title={Finite-time error bounds for linear stochastic approximation andtd learning},
  author={Srikant, Rayadurgam and Ying, Lei},
  booktitle={Conference on Learning Theory},
  pages={2803--2830},
  year={2019},
  organization={PMLR}
}

@article{tang2022nature,
  title={The nature of temporal difference errors in multi-step distributional reinforcement learning},
  author={Tang, Yunhao and Munos, Remi and Rowland, Mark and Avila Pires, Bernardo and Dabney, Will and Bellemare, Marc},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={30265--30276},
  year={2022}
}

@article{tang2024off,
  title={Off-policy Distributional Q ($lambda $): Distributional RL without Importance Sampling},
  author={Tang, Yunhao and Rowland, Mark and Munos, R{\'e}mi and Pires, Bernardo {\'A}vila and Dabney, Will},
  journal={arXiv preprint arXiv:2402.05766},
  year={2024}
}

@article{tsitsiklis1996analysis,
  title={Analysis of temporal-diffference learning with function approximation},
  author={Tsitsiklis, John and Van Roy, Benjamin},
  journal={Advances in neural information processing systems},
  volume={9},
  year={1996}
}

@inproceedings{wiltzer2024dsm,
    title={A Distributional Analogue to the Successor Representation},
    author={Harley Wiltzer and Jesse Farebrother and Arthur Gretton and Yunhao Tang and Andr\'e Barreto and Will Dabney and Marc G Bellemare and Mark Rowland},
    booktitle = {International Conference on Machine Learning (ICML)}, 
    year={2024},
}

@article{wu2024statistical,
  title={Statistical Inference for Temporal Difference Learning with Linear Function Approximation},
  author={Wu, Weichen and Li, Gen and Wei, Yuting and Rinaldo, Alessandro},
  journal={arXiv preprint arXiv:2410.16106},
  year={2024}
}

@article{zhang2023estimation,
  title={Estimation and Inference in Distributional Reinforcement Learning},
  author={Zhang, Liangyu and Peng, Yang and Liang, Jiadong and Yang, Wenhao and Zhang, Zhihua},
  journal={arXiv preprint arXiv:2309.17262},
  year={2023}
}

