% In the task of distributional policy evaluation, our goal is to minimize $\mu_\pi$-weighted $1$-Wasserstein error $W_{1,\mu_\pi}(\bm{\eta}_{\bar\bw_T},\bm{\eta}^\pi)$.
In the task of distributional policy evaluation, the quality of estimator $\bm{\eta}_{\bar\bw_T}$ can be measured by $\mu_\pi$-weighted $1$-Wasserstein error $W_{1,\mu_\pi}(\bm{\eta}_{\bar\bw_T},\bm{\eta}^\pi)$.
By triangle inequality, the error can be decomposed as approximation error and estimation error: $W_{1,\mu_\pi}(\bm{\eta}^\pi,\bm{\eta}_{\bar\bw_T})\leq W_{1,\mu_\pi}(\bm{\eta}^\pi,\bm{\eta}_{\bw^{\star}})+W_{1,\mu_\pi}(\bm{\eta}_{\bw^{\star}},\bm{\eta}_{\bar\bw_T})$.
% According to Proposition~\ref{prop:approx_error}, we have an upper bound for the approximation error $W_{1,\mu_\pi}(\bm{\eta}^\pi,\bm{\eta}_{\bw^{\star}})$.
Proposition~\ref{prop:approx_error} provides an upper bound for the approximation error $W_{1,\mu_\pi}(\bm{\eta}^\pi,\bm{\eta}_{\bw^{\star}})$, so it suffices to control the estimation error $\gL(\bar\bw_T):=W_{1,\mu_\pi}(\bm{\eta}_{\bw^{\star}},\bm{\eta}_{\bar\bw_T})$.
% According to Proposition~\ref{prop:approx_error}, to make the approximation error $W_{1,\mu_{\pi}}(\bm{\eta}^\pi,\bm{\eta}_{\bw^{\star}})\leq \varepsilon$, we need to take at least $K\geq \varepsilon^{-2}(1-\gamma)^{-3}$.

In the following, we give non-asymptotic convergence rates of $\gL(\bar\bw_T)$.
We start from the generative model setting, \ie\ in the $t$-th iteration, we collect samples $s_t\sim\mu_{\pi}(\cdot), a_t\sim\pi(\cdot|s_t), r_t\sim \gP_R(\cdot|s_t,a_t), s_t^\prime\sim P(\cdot|s_t,a_t)$ from the generative model (we need to replace $s_{t+1}$ with $s_t^\prime$ in {\LCTD} Eqn.~\eqref{eq:linear_CTD}).
We give $L^p$ and high-probability convergence results in this setting.
Then, we move back to the Markovian setting (\ie\  using the streaming data $\brc{\prn{s_t,a_t,r_t}}_{t=0}^\infty$ introduced in Section~\ref{Subsection:policy_eval_and_TD}), and give high-probability convergence results.

To facilitate the comparison of our results with those of {\LTD}, in the following, we denote by $\btheta_0=\prn{\bC\otimes \bI_d}\bw_0$ (resp. $\btheta^\star=\prn{\bC\otimes \bI_d}\bw^\star$) the initial (resp. optimal) parameters under CDF representation, where $\bC$ is defined in Eqn.~\eqref{eq:def_C}.
See Appendix~\ref{Appendix:cdf_representation} for details of CDF representation. 
\subsection{\texorpdfstring{$L^2$}{L2} Convergence}\label{Subsection:L2_convergence}
We first provide non-asymptotic convergence rates of $\EB^{1/2}[(\gL(\bar\bw_T))^2]$.
\begin{theorem}[$L^2$ Convergence]\label{thm:l2_error_linear_ctd}
Suppose $K\geq (1-\gamma)^{-1}$, $T\geq 2$, $\alpha\in(0,(1-\sqrt\gamma)/76)$ and $\bw_0\in\RB^{dK}$ is the initialization, then it holds that
    \begin{equation*}
       \begin{aligned}
        \EB^{1/2}[(\gL(\bar\bw_T))^2]\lesssim&\frac{\frac{1}{\sqrt{K}(1-\gamma)}\norm{\btheta^{\star}}_{\bI_K\otimes\bSigma_{\bphi}}+1}{\sqrt{T}(1-\gamma)\sqrt{\lambda_{\min}}}\prn{1+\sqrt{\frac{\alpha}{(1-\gamma)\lambda_{\min}}}}+\frac{\frac{1}{\sqrt{K}(1-\gamma)}\norm{\btheta^{\star}}_{\bI_K\otimes\bSigma_{\bphi}}+1}{T\sqrt{\alpha }(1-\gamma)^{\frac{3}{2}}\lambda_{\min}}\\
        &+\frac{(1-\frac{1}{2}\alpha (1-\sqrt\gamma)\lambda_{\min} )^{T/2}}{T \sqrt{\alpha}(1-\gamma)\sqrt{\lambda_{\min}}}\prn{\frac{1}{\sqrt\alpha}{+}\frac{1}{\sqrt{ (1{-}\gamma)\lambda_{\min}}}}\frac{1}{\sqrt{K}(1-\gamma)}\norm{\btheta_0-\btheta^{\star}}.
       \end{aligned}
    \end{equation*}
\end{theorem}
To prove Theorem~\ref{thm:l2_error_linear_ctd}, we conduct a fine-grained analysis of the linear-categorical Bellman equation and apply the exponential stability argument \citep[Theorem~1][]{samsonov2024improved}, which is outlined in Section~\ref{Section:proof_outline}.
And the $L^p$ ($p>2$) convergence results can be found in Theorem~\ref{thm:lp_error_linear_ctd}.
Theorem~\ref{thm:l2_error_linear_ctd} implies that learning the distribution of the return is as easy as learning its expectation (value function) with linear function approximation.
\citet{rowland2024nearminimaxoptimal, peng2024statistical} discovered this phenomenon in the tabular setting, and we extend it to the function approximation setting.
\begin{remark}\label{remark:theory_match}
The only difference between our Theorem~\ref{thm:l2_error_linear_ctd} and the $L^2$ convergence rate of classic {\LTD} \citep[Theorem~3][]{samsonov2024improved} lies in replacing $\norm{\bm{\psi}^{\star}}_{\bSigma_{\bphi}}$ (resp. $\norm{\bm{\psi}_0{-}\bm{\psi}^{\star}}$) with $K^{-1/2}(1{-}\gamma)^{-1}\norm{\btheta^{\star}}_{\bI_K\otimes\bSigma_{\bphi}}$ (resp. $K^{-1/2}(1{-}\gamma)^{-1}\norm{\btheta_0{-}\btheta^{\star}}$). 
We claim that the two pairs should be of the same order respectively.
Note that $\norm{\btheta^{\star}}_{\bI_K\otimes\bSigma_{\bphi}},\norm{\btheta_0{-}\btheta^{\star}}$ are of the order $O(\sqrt{K})$ (also dependent on $\bphi$, we omit it for brevity) if ${\eta}_{\bw^{\star}}(s), {\eta}_{\bw_0}(s)$ are valid probability distributions for all $s\in\gS$.
This is because in this case, the vector of CDF $\bF_{\btheta}(s)=(\btheta(k)^\intercal\bphi(s){+}({k{+}1})/({K{+}1}))_{k=0}^{K{-}1}\in \brk{0, 1}^K$ for $\btheta\in\brc{\btheta^{\star}, \btheta_0}$.
While, in classic {\LTD} (Section~\ref{subsection:linear_td}), a proper estimate $\bm{\psi}$ should satisfy $V_{\bm{\psi}}(s)=\bpsi^{\intercal}\bphi(s)\in\brk{0,(1{-}\gamma)^{-1}}$.
It is thus reasonable to consider the two pairs as being of the same order, respectively.
Similar arguments also holds in other convergence results presented in this paper.
Therefore, in this sense, our results match those of classic {\LTD}.
\end{remark}
One can translate Theorem~\ref{thm:l2_error_linear_ctd} into a sample complexity bound.
\begin{corollary}\label{coro:l2_sample_complexity_linear_ctd}
Under the same conditions as Theorem~\ref{thm:l2_error_linear_ctd}, for any $\varepsilon>0$, suppose
    \begin{equation*}
    \begin{aligned}
        T\gtrsim&\frac{\frac{1}{K(1-\gamma)^2}\norm{\btheta^{\star}}^2_{\bI_K\otimes\bSigma_{\bphi}}+1}{\varepsilon^2(1-\gamma)^2\lambda_{\min}}\prn{1+\frac{\alpha}{(1-\gamma)\lambda_{\min}}} +\frac{\frac{1}{\sqrt{K}(1-\gamma)}\norm{\btheta^{\star}}_{\bI_K\otimes\bSigma_{\bphi}}+1}{\varepsilon\sqrt{\alpha }(1-\gamma)^{\frac{3}{2}}\lambda_{\min}}\\
        &+\frac{1}{\alpha (1-\gamma) \lambda_{\min}}\prn{\log\frac{\norm{\btheta_0{-}\btheta^{\star}}}{\varepsilon\sqrt{K}(1{-}\gamma)}+\log\prn{ \frac{1}{T \sqrt{\alpha}(1{-}\gamma)\sqrt{\lambda_{\min}}}\prn{\frac{1}{\sqrt\alpha}{+}\frac{1}{\sqrt{ (1{-}\gamma)\lambda_{\min}}}}}},   
    \end{aligned}
    \end{equation*}
    % where 
    % \begin{equation*}
    %     R_1=\frac{1}{T \sqrt{\alpha}(1-\gamma)\sqrt{\lambda_{\min}}}\prn{\frac{1}{\sqrt\alpha}+\frac{1}{\sqrt{ (1-\gamma)\lambda_{\min}}}},
    % \end{equation*}
    then it holds that $ \EB^{1/2}[(\gL(\bar\bw_T))^2]\leq \varepsilon$.
\end{corollary}
\paragraph{Instance-Independent Step Size.}
If we take the largest possible instance-independent step size, \ie\ $\alpha\simeq (1-\gamma)$, and consider $\varepsilon\in(0, 1)$, we obtain the sample complexity bound
\begin{equation}\label{eq:largest_step_size_l2_sample_complexity}
    T=\wtilde{O}\prn{\frac{\frac{1}{K(1-\gamma)^2}\norm{\btheta^{\star}}^2_{\bI_K\otimes\bSigma_{\bphi}}+1}{\varepsilon^2(1-\gamma)^2\lambda_{\min}^2}}.
\end{equation}
% \begin{equation}\label{eq:largest_step_size_l2_sample_complexity}
%     T=\wtilde{O}\prn{\frac{\frac{1}{K(1-\gamma)^2}\norm{\btheta^{\star}}^2_{\bI_K\otimes\bSigma_{\bphi}}+1}{\varepsilon\min\brc{\varepsilon, 1}(1-\gamma)^2\lambda_{\min}^2}+\frac{1}{(1-\gamma)^2\lambda_{\min}}\log\frac{\norm{\btheta_0-\btheta^{\star}}}{\varepsilon\sqrt{K}(1-\gamma)}},
% \end{equation}
\paragraph{Optimal Instance-Dependent Step Size.}
If we take the optimal instance-dependent step size $\alpha\simeq (1-\gamma)\lambda_{\min}$ which involves the unknown $\lambda_{\min}$, we obtain a better sample complexity bound
\begin{equation}\label{eq:instance_dependent_step_size_l2_sample_complexity}
    T=\wtilde{O}\prn{ \frac{\frac{1}{K(1-\gamma)^2}\norm{\btheta^{\star}}^2_{\bI_K\otimes\bSigma_{\bphi}}+1}{\varepsilon^2(1-\gamma)^2\lambda_{\min}}},
\end{equation}
when we consider small enough $\varepsilon=\tilde{O}\prn{\sqrt{\lambda_{\min}}}$, or equivalently, large enough total update steps
\begin{equation}\label{eq:sample_size_barrier}
    T=\wtilde{\Omega}\prn{\frac{\frac{1}{K(1-\gamma)^2}\norm{\btheta^{\star}}^2_{\bI_K\otimes\bSigma_{\bphi}}+1}{(1-\gamma)^2\lambda_{\min}^2}}.
\end{equation}
These theoretical results match the recent results for classic {\LTD} with constant step size \citep{patil2023finite, li2024high, samsonov2024improved}. 
It is possible to break the sample size barrier (Eqn.~\eqref{eq:sample_size_barrier}) as in classic {\LTD} by applying the variance-reduction techniques \citep{li2023accelerated}
% or using polynomial-decaying step sizes \citep{wu2024statistical}
, we leave it as a future work.
\subsection{Convergence with High Probability and Markovian Samples}
By applying the $L^p$ convergence result (Theorem~\ref{thm:lp_error_linear_ctd}) with $p=2\log(1/\delta)$
% \red{(Take $p_\delta=2\log\frac{1}{\delta}/\log\log\frac{1}{\delta}<2\log\frac{1}{\delta}$, then you can check that $\prn{1/\delta}^{p_\delta}=\sqrt{\log\frac{1}{\delta}}$)} 
and Markov's inequality, we obtain the high-probability convergence result.
\begin{theorem}[High-Probability Convergence]\label{thm:whp_error_linear_ctd}
For any $\varepsilon>0$ and $\delta\in(0,1)$, suppose $K\geq (1{-}\gamma)^{-1}$, $\alpha\in(0,(1{-}\sqrt\gamma){/}[38\log(T{/}\delta^2)])$, $\bw_0\in\RB^{dK}$ is the initialization, and total update steps $T=$
    \begin{equation*}
    \begin{aligned}
        \wtilde{O}\Bigg(&\frac{\frac{1}{K(1{-}\gamma)^2}\!\norm{\btheta^{\star}}^2_{\bI_K{\otimes}\bSigma_{\bphi}}\!\!\!{+}1}{\varepsilon^2(1-\gamma)^2\lambda_{\min}}\!\prn{1{+}\frac{\alpha\log\frac{1}{\delta}}{(1{-}\gamma)\lambda_{\min}}}\!\log\!\frac{1}{\delta} {+}\frac{\frac{1}{\sqrt{K}(1{-}\gamma)}\!\norm{\btheta^{\star}}_{\bI_K{\otimes}\bSigma_{\bphi}}\!\!\!{+}1}{\varepsilon\sqrt{\alpha }(1-\gamma)^{\frac{3}{2}}\lambda_{\min}}\!\log\!\frac{1}{\delta}{+}\frac{\log\!\frac{\norm{\btheta_0{-}\btheta^{\star}}}{\varepsilon\sqrt{K}(1{-}\gamma)}}{\alpha (1{-}\gamma) \lambda_{\min}}\Bigg),   
    \end{aligned}
    \end{equation*}
then with probability at least $1-\delta$, it holds that $\gL\prn{\bar\bw_T}\leq\varepsilon$.
Here, the $\wtilde{O}\prn{\cdot}$ does not hide polynomials of $\log(1/\delta)$ (but hides logarithm terms of $\log(1/\delta)$).
\end{theorem}
Again, we will obtain concrete sample complexity bounds as in Eqn.~\eqref{eq:largest_step_size_l2_sample_complexity} or Eqn.~\eqref{eq:instance_dependent_step_size_l2_sample_complexity} if we use different step sizes, we omit these for brevity.
Compared with the theoretical results for classic {\LTD}, our results match \citep[Theorem~4][]{samsonov2024improved} that also considers the constant step size, but has a worse dependence on $\log\prn{1/\delta}$ than \citep[Theorem~3.1][]{wu2024statistical} which considers the polynomial-decaying step size $\alpha_t=\alpha_0 t^{-\beta}$ with $\beta\in(1/2, 1)$ instead.
% \red{TBD: State a minimax lower bound here, as a corollary of \citep[Theorem~2][]{li2024high}.}
\begin{remark}[Markovian Setting]
Using the same argument as in the proof of \citep[Theorem~6][]{samsonov2024improved}, one can immediately derive a high-probability sample complexity bound in the Markovian setting.
Compared with the bound in the generative model setting (Theorem~\ref{thm:whp_error_linear_ctd}), the bound in the Markovian setting will have an additional dependency on $t_{\operatorname{mix}}\log(T/\delta)$, where $t_{\operatorname{mix}}$ is the mixing time of the Markov chain $\brc{s_t}_{t=0}^{\infty}$ in $\gS$.
We omit this result for brevity.
\end{remark}



