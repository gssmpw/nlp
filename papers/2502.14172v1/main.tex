\documentclass[11pt]{article}
% \documentclass{article}
% \usepackage{neurips_2024}
%% \usepackage[utf8]{inputenc} % allow utf-8 input
%% \usepackage[T1]{fontenc}    % use 8-bit T1 fonts

\input{command.tex}
\newcommand{\zly}[1]{\textcolor{blue}{\textbf{[zly: }#1\textbf{]}}}
\usepackage{enumerate}
\usepackage{natbib}
% \usepackage{enumitem}

\newtheorem{claim}{Claim}[section]
\newtheorem{lemma}[claim]{Lemma}
\newtheorem{assumption}{Assumption}
\newtheorem{definition}{Definition}
\newtheorem{theorem}{Theorem}[section]
\newtheorem{example}{Example}[section]
\newtheorem{proposition}{Proposition}[section]
\newtheorem{remark}{Remark}
\newtheorem{corollary}{Corollary}[section]


% \onehalfspacing
\linespread{1.5}
\usepackage{xr}

\title{Finite Sample Analysis of Distributional TD Learning with Linear Function Approximation}


\author{
Yang Peng\thanks{School of Mathematical Sciences, Peking University; email: \texttt{pengyang@pku.edu.cn}.} \and
Kaicheng Jin\thanks{School of Mathematical Sciences, Peking University; email: \texttt{kcjin@pku.edu.cn}.} \and
Liangyu Zhang,~\thanks{School of Statistics and Data Science, Shanghai University of Finance and Economics; email: \texttt{zhangliangyu@sufe.edu.cn}.} \and
Zhihua Zhang\thanks{School of Mathematical Sciences, Peking University; email: \texttt{zhzhang@math.pku.edu.cn}.}
}



\begin{document}
\maketitle
\begin{abstract}%
In this paper, we investigate the finite-sample statistical rates of distributional temporal difference (TD) learning with linear function approximation.
The aim of distributional TD learning is to estimate the return distribution of a discounted Markov decision process for a given policy $\pi$.
Prior works on statistical analysis of distributional TD learning mainly focus on the tabular case.
In contrast, we first consider the linear function approximation setting and derive sharp finite-sample rates.
Our theoretical results demonstrate that the sample complexity of linear distributional TD learning matches that of the classic linear TD learning.
This implies that, with linear function approximation, learning the full distribution of the return using streaming data is no more difficult than learning its expectation (\ie\ the value function).
To derive tight sample complexity bounds, we conduct a fine-grained analysis of the linear-categorical Bellman equation, and employ the exponential stability arguments for products of random matrices.
Our findings provide new insights into the statistical efficiency of distributional reinforcement learning algorithms.
\end{abstract}
\tableofcontents
\section{Introduction}\label{Section:intro}
\input{intro}
% \section{Backgrounds}\label{Section:background}
% \input{background}
\section{Backgrounds}\label{Section:background}
\input{background_zly}
\section{Linear-Categorical TD Learning}\label{Section:linear_ctd}
\input{linear_CTD}
\section{Non-Asymptotic Statistical Analysis}\label{Section:analysis_linear_ctd}
\input{analysis_linear_CTD}
\section{Proof Outlines}\label{Section:proof_outline}
\input{proof_outline}
\section{Conclusions}\label{Section:conclusion}
\input{conclusion}


\bibliography{ref}
\bibliographystyle{abbrvnat}
\newpage

\appendix
% \section{Notation Table}\label{Appendix_notation_table}
% \input{notation_table}
\section{Kronecker Product}\label{Appendix_kronecker}
\input{kronecker}
\section{Omitted Results and Proofs in Section~\ref{Section:background}}
\input{omit_proof_background}
\section{Omitted Results and Proofs in Section~\ref{Section:linear_ctd}}
\input{omit_proof_linear_ctd}
\section{Omitted Results and Proofs in Section~\ref{Section:analysis_linear_ctd}}
\input{omit_proof_analysis}
\section{Other Technical Lemmas}\label{Appendix_technical_lemmas}
\input{technical_lemma}

\end{document}
