

\subsection{Generalized Random Choice}
\label{sec:general}
We now consider two generalizations to the model that are amenable to the same analysis technique as in \cref{sec:random_small}. We present the model and the program in each case, and except for one canonical instance, we omit the easy computation of the numerical bounds for distortion. 

\paragraph{Concave Bias.} In the first generalization, the outcome of deliberation is less dominated by extremely biased voters. The model now has a concave, non-decreasing function $g$, with $g(0) = 0$ and $g(1) = 1$. For any pair of outcomes $W,X$, given a multiset $S$ of voter locations of size $k$, the probability the outcome of deliberation is the favorite outcome of $i \in S$ is proportional to $g(|\B_i(W,X)|)$. The Random Choice model considered so far had $g(x) = x$. Note that as $g$ becomes more concave (away from linear), the model favors a more uniformly random voter in the deliberating group, as opposed to a more biased voter.

For any such $g$, the function $\frac{g(x)}{g(x) + c}$ is also concave and non-decreasing in $x$. We can re-derive the optimization problem in \cref{eq:opt2} by analogously applying Jensen's inequality. This yields
\begin{equation} 
\label{eq:opt3}
\zeta_k := \max_{\omega, \alpha \in [0,1]} (1-\alpha) - \alpha \cdot \omega \qquad \mbox{s.t.} \qquad \E_{\ell \sim \mathtt{Bernoulli}(k,\alpha)} \left[ \frac{\ell \cdot g(\omega)}{\ell \cdot g(\omega) + k-\ell } \right] \ge \frac{1}{2}.
\end{equation}
for a distortion of at most $\left( \frac{1+\zeta_k}{1-\zeta_k}\right)^2$ by \cref{thm:distort1}. It is now easy to compute the distortion for any fixed function $g$. We plot the distortion as a function of $k$ for $g(x) = \sqrt{x}$ in \cref{fig2}. Observe that the distortion is at most $2.98$ for $k = 3$, and asymptotically approaches $2$ as $k \rightarrow \infty$.  

This shows that the asymptotic distortion bound of $1$ in \cref{thm:asymp1} is specific to the model with $g(x) = x$, and making $g(x)$ more concave leads to asymptotically larger distortion. This is intuitive, since if  $g(x) = 1$, then the model reduces to random dictatorship, which has distortion  $3$.

\paragraph{Opinion Change of Voters.} In the second generalization, we model a voter in the group $S$ as changing their opinion. Let $S_1 \subseteq S$ denote the set of voters who perfer $W$ to $X$, and let $S_2 \subseteq S$ denote those that prefer $X$ to $W$. Let $A = \sum_{i \in S_1} |\B_i(W,X)|$ denote the total normalized bias of voters preferring $W$, and let $B = \sum_{i \in S_2} |\B_i(W,X)|$ be that for $X$. 

There is a parameter $\beta \in [0,1]$. During deliberation, suppose every voter in $S_1$ independently changes their opinion to $X$ with probability $\beta \cdot \frac{B}{A+B}$, and similarly, every voter in $S_2$ changes their opinion to $W$ with probability $\beta \cdot \frac{A}{A+B}$. Subsequently, the opinion of a randomly chosen voter in the group is implemented. It can be checked that
$$ p_k(W,X) = \beta \cdot \frac{A}{A+B} + (1-\beta) \cdot \frac{|S_1|}{|S|}.$$
Note that if $\beta = 1$, this is exactly the random choice model, whereas if $\beta = 0$, this is simply random dictatorship. The parameter $\beta$ captures the extent of opinion change. For any $\beta \in [0,1]$, we can upper bound the distortion using the same technique as in \cref{sec:random_small}. Indeed, \cref{eq:opt2} becomes:
\begin{equation*} 
%\label{eq:opt10}
\zeta_k := \max_{\omega, \alpha \in [0,1]} (1-\alpha) - \alpha \cdot \omega \qquad \mbox{s.t.} \qquad 
\beta \cdot \sum_{\ell = 1}^k {k \choose \ell} \alpha^{\ell} (1-\alpha)^{k-\ell} \cdot
\left[ \frac{\ell \cdot \omega}{\ell \cdot \omega + k-\ell } \right] + (1-\beta) \cdot \alpha \ge \frac{1}{2},
\end{equation*}
which can be optimized  as in \cref{sec:random_small} for any fixed $\beta$. As with the previous generalization, the distortion bound will be asymptotically larger than $1$ if $\beta < 1$.