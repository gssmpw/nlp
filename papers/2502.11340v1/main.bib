@article{koop2010bayesian,
  title={Bayesian multivariate time series methods for empirical macroeconomics},
  author={Koop, Gary and Korobilis, Dimitris and others},
  journal={Foundations and Trends{\textregistered} in Econometrics},
  volume={3},
  number={4},
  pages={267--358},
  year={2010},
  publisher={Now Publishers, Inc.}
}

@article{nguyen2021forecasting,
  title={Forecasting COVID-19 hospital census: A multivariate time-series model based on local infection incidence},
  author={Nguyen, Hieu M and Turk, Philip J and McWilliams, Andrew D},
  journal={JMIR Public Health and Surveillance},
  volume={7},
  number={8},
  pages={e28195},
  year={2021},
  publisher={JMIR Publications Toronto, Canada}
}

@article{angryk2020multivariate,
  title={Multivariate time series dataset for space weather data analytics},
  author={Angryk, Rafal A and Martens, Petrus C and Aydin, Berkay and Kempton, Dustin and Mahajan, Sushant S and Basodi, Sunitha and Ahmadzadeh, Azim and Cai, Xumin and Filali Boubrahimi, Soukaina and Hamdi, Shah Muhammad and others},
  journal={Scientific data},
  volume={7},
  number={1},
  pages={227},
  year={2020},
  publisher={Nature Publishing Group UK London}
}

@article{hsieh2004nonlinear,
  title={Nonlinear multivariate and time series analysis by neural network methods},
  author={Hsieh, William W},
  journal={Reviews of Geophysics},
  volume={42},
  number={1},
  year={2004},
  publisher={Wiley Online Library}
}

@article{sorjamaa2007methodology,
  title={Methodology for Long-Term Prediction of Time Series},
  author={Sorjamaa, A},
  journal={Neurocomputing},
  year={2007}
}

@inproceedings{chen2021data,
  title={Data-driven prediction of general Hamiltonian dynamics via learning exactly-symplectic maps},
  author={Chen, Renyi and Tao, Molei},
  booktitle={International Conference on Machine Learning},
  pages={1717--1727},
  year={2021},
  organization={PMLR}
}

@misc{nerlove1971time,
  title={Time Series Analysis, Forecasting, and Control.},
  author={Nerlove, Marc},
  year={1971},
  publisher={JSTOR}
}

@book{hyndman2018forecasting,
  title={Forecasting: principles and practice},
  author={Hyndman, RJ},
  year={2018},
  publisher={OTexts}
}

@book{bloomfield2004fourier,
  title={Fourier analysis of time series: an introduction},
  author={Bloomfield, Peter},
  year={2004},
  publisher={John Wiley \& Sons}
}

@book{durbin2012time,
  title={Time series analysis by state space methods},
  author={Durbin, James and Koopman, Siem Jan},
  volume={38},
  year={2012},
  publisher={OUP Oxford}
}

@inproceedings{chen2021crossvit,
  title={Crossvit: Cross-attention multi-scale vision transformer for image classification},
  author={Chen, Chun-Fu Richard and Fan, Quanfu and Panda, Rameswar},
  booktitle={Proceedings of the IEEE/CVF international conference on computer vision},
  pages={357--366},
  year={2021}
}

@article{elman1990finding,
  title={Finding structure in time},
  author={Elman, Jeffrey L},
  journal={Cognitive science},
  volume={14},
  number={2},
  pages={179--211},
  year={1990},
  publisher={Wiley Online Library}
}

@article{hochreiter1997long,
  title={Long Short-term Memory},
  author={Hochreiter, S},
  journal={Neural Computation MIT-Press},
  year={1997}
}

@inproceedings{graves2013speech,
  title={Speech recognition with deep recurrent neural networks},
  author={Graves, Alex and Mohamed, Abdel-rahman and Hinton, Geoffrey},
  booktitle={2013 IEEE international conference on acoustics, speech and signal processing},
  pages={6645--6649},
  year={2013},
  organization={Ieee}
}

@article{gers2000learning,
  title={Learning to forget: Continual prediction with LSTM},
  author={Gers, Felix A and Schmidhuber, J{\"u}rgen and Cummins, Fred},
  journal={Neural computation},
  volume={12},
  number={10},
  pages={2451--2471},
  year={2000},
  publisher={MIT press}
}

@article{vaswani2017attention,
  title={Attention is all you need},
  author={Vaswani, A},
  journal={Advances in Neural Information Processing Systems},
  year={2017}
}

@inproceedings{zeng2023transformers,
  title={Are transformers effective for time series forecasting?},
  author={Zeng, Ailing and Chen, Muxi and Zhang, Lei and Xu, Qiang},
  booktitle={Proceedings of the AAAI conference on artificial intelligence},
  volume={37-9},
  pages={11121--11128},
  year={2023}
}

@article{liu2023itransformer,
  title={itransformer: Inverted transformers are effective for time series forecasting},
  author={Liu, Yong and Hu, Tengge and Zhang, Haoran and Wu, Haixu and Wang, Shiyu and Ma, Lintao and Long, Mingsheng},
  journal={arXiv preprint arXiv:2310.06625},
  year={2023}
}

@inproceedings{yang2024neural,
  title={Neural McKean-Vlasov Processes: Distributional Dependence in Diffusion Processes},
  author={Yang, Haoming and Hasan, Ali and Ng, Yuting and Tarokh, Vahid},
  booktitle={International Conference on Artificial Intelligence and Statistics},
  pages={262--270},
  year={2024},
  organization={PMLR}
}

@article{wang2025mamba,
  title={Is mamba effective for time series forecasting?},
  author={Wang, Zihan and Kong, Fanheng and Feng, Shi and Wang, Ming and Yang, Xiaocui and Zhao, Han and Wang, Daling and Zhang, Yifei},
  journal={Neurocomputing},
  volume={619},
  pages={129178},
  year={2025},
  publisher={Elsevier}
}

@article{ahamed2024timemachine,
  title={Timemachine: A time series is worth 4 mambas for long-term forecasting},
  author={Ahamed, Md Atik and Cheng, Qiang},
  journal={arXiv preprint arXiv:2403.09898},
  year={2024}
}

@misc{xusst,
  title={SST: Multi-Scale Hybrid Mamba-Transformer Experts for Long-Short Range Time Series Forecasting}, 
  author={Xiongxiao Xu and Canyu Chen and Yueqing Liang and Baixiang Huang and Guangji Bai and Liang Zhao and Kai Shu},
  journal={https://arxiv.org/abs/2404.14757}, 
  year={2024},
}

@article{nie2022time,
  title={A time series is worth 64 words: Long-term forecasting with transformers},
  author={Nie, Yuqi and Nguyen, Nam H and Sinthong, Phanwadee and Kalagnanam, Jayant},
  journal={arXiv preprint arXiv:2211.14730},
  year={2022}
}

@article{gu2023mamba,
  title={Mamba: Linear-time sequence modeling with selective state spaces},
  author={Gu, Albert and Dao, Tri},
  journal={arXiv preprint arXiv:2312.00752},
  year={2023}
}

@article{lieber2024jamba,
  title={Jamba: A hybrid transformer-mamba language model},
  author={Lieber, Opher and Lenz, Barak and Bata, Hofit and Cohen, Gal and Osin, Jhonathan and Dalmedigos, Itay and Safahi, Erez and Meirom, Shaked and Belinkov, Yonatan and Shalev-Shwartz, Shai and others},
  journal={arXiv preprint arXiv:2403.19887},
  year={2024}
}

@article{gu2021efficiently,
  title={Efficiently modeling long sequences with structured state spaces},
  author={Gu, Albert and Goel, Karan and R{\'e}, Christopher},
  journal={arXiv preprint arXiv:2111.00396},
  year={2021}
}

@article{gu2020hippo,
  title={Hippo: Recurrent memory with optimal polynomial projections},
  author={Gu, Albert and Dao, Tri and Ermon, Stefano and Rudra, Atri and R{\'e}, Christopher},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={1474--1487},
  year={2020}
}

@article{bahdanau2014neural,
  title={Neural machine translation by jointly learning to align and translate},
  author={Bahdanau, Dzmitry},
  journal={arXiv preprint arXiv:1409.0473},
  year={2014}
}

@article{gong2023patchmixer,
  title={Patchmixer: A patch-mixing architecture for long-term time series forecasting},
  author={Gong, Zeying and Tang, Yujin and Liang, Junwei},
  journal={arXiv preprint arXiv:2310.00655},
  year={2023}
}

@inproceedings{zhang2023crossformer,
  title={Crossformer: Transformer utilizing cross-dimension dependency for multivariate time series forecasting},
  author={Zhang, Yunhao and Yan, Junchi},
  booktitle={The eleventh international conference on learning representations},
  year={2023}
}

@inproceedings{zhou2022fedformer,
  title={Fedformer: Frequency enhanced decomposed transformer for long-term series forecasting},
  author={Zhou, Tian and Ma, Ziqing and Wen, Qingsong and Wang, Xue and Sun, Liang and Jin, Rong},
  booktitle={International conference on machine learning},
  pages={27268--27286},
  year={2022},
  organization={PMLR}
}

@article{li2023revisiting,
  title={Revisiting long-term time series forecasting: An investigation on linear mapping},
  author={Li, Zhe and Qi, Shiyi and Li, Yiduo and Xu, Zenglin},
  journal={arXiv preprint arXiv:2305.10721},
  year={2023}
}

@article{wu2022timesnet,
  title={Timesnet: Temporal 2d-variation modeling for general time series analysis},
  author={Wu, Haixu and Hu, Tengge and Liu, Yong and Zhou, Hang and Wang, Jianmin and Long, Mingsheng},
  journal={arXiv preprint arXiv:2210.02186},
  year={2022},
  publisher={arXivpreprint}
}

@inproceedings{lai2018modeling,
  title={Modeling long-and short-term temporal patterns with deep neural networks},
  author={Lai, Guokun and Chang, Wei-Cheng and Yang, Yiming and Liu, Hanxiao},
  booktitle={The 41st international ACM SIGIR conference on research \& development in information retrieval},
  pages={95--104},
  year={2018}
}

@article{wu2021autoformer,
  title={Autoformer: Decomposition transformers with auto-correlation for long-term series forecasting},
  author={Wu, Haixu and Xu, Jiehui and Wang, Jianmin and Long, Mingsheng},
  journal={Advances in neural information processing systems},
  volume={34},
  pages={22419--22430},
  year={2021}
}

@inproceedings{zhou2021informer,
  title={Informer: Beyond efficient transformer for long sequence time-series forecasting},
  author={Zhou, Haoyi and Zhang, Shanghang and Peng, Jieqi and Zhang, Shuai and Li, Jianxin and Xiong, Hui and Zhang, Wancai},
  booktitle={Proceedings of the AAAI conference on artificial intelligence},
  volume={35},
  number={12},
  pages={11106--11115},
  year={2021}
}

@book{box2015time,
  title={Time series analysis: forecasting and control},
  author={Box, George EP and Jenkins, Gwilym M and Reinsel, Gregory C and Ljung, Greta M},
  year={2015},
  chapters={14},
  pages={505-506},
  publisher={John Wiley \& Sons}
}

@book{horn2012matrix,
  title={Matrix analysis},
  author={Horn, Roger A and Johnson, Charles R},
  year={2012},
  publisher={Cambridge university press}
}