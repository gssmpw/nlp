@InProceedings{Su_2020_CVPR,
author = {Su, Shaolin and Yan, Qingsen and Zhu, Yu and Zhang, Cheng and Ge, Xin and Sun, Jinqiu and Zhang, Yanning},
title = {Blindly Assess Image Quality in the Wild Guided by a Self-Adaptive Hyper Network},
booktitle = {IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
month = {June},
year = {2020}
}

@article{alkin2024visionlstm,
  title={Vision-LSTM: xLSTM as Generic Vision Backbone},
  author={Benedikt Alkin and Maximilian Beck and Korbinian P{\"o}ppel and Sepp Hochreiter and Johannes Brandstetter},
  journal={arXiv preprint arXiv:2406.04303},
  year={2024}
}

@article{beck2024xlstm,
  title={xLSTM: Extended Long Short-Term Memory},
  author={Beck, Maximilian and P{\"o}ppel, Korbinian and Spanring, Markus and Auer, Andreas and Prudnikova, Oleksandra and Kopp, Michael and Klambauer, G{\"u}nter and Brandstetter, Johannes and Hochreiter, Sepp},
  journal={arXiv preprint arXiv:2405.04517},
  year={2024}
}

@article{chen2024learning,
  title={Learning to Evaluate the Artness of AI-generated Images},
  author={Chen, Junyu and An, Jie and Lyu, Hanjia and Kanan, Christopher and Luo, Jiebo},
  journal={IEEE Transactions on Multimedia},
  year={2024},
  publisher={IEEE}
}

@article{dosovitskiy2020image,
  title={An image is worth 16x16 words: Transformers for image recognition at scale},
  author={Dosovitskiy, Alexey and Beyer, Lucas and Kolesnikov, Alexander and Weissenborn, Dirk and Zhai, Xiaohua and Unterthiner, Thomas and Dehghani, Mostafa and Minderer, Matthias and Heigold, Georg and Gelly, Sylvain and others},
  journal={arXiv preprint arXiv:2010.11929},
  year={2020}
}

@inproceedings{he2016deep,
  title={Deep residual learning for image recognition},
  author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={770--778},
  year={2016}
}

@article{hochreiter1997long,
  title={Long Short-term Memory},
  author={Hochreiter, S},
  journal={Neural Computation MIT-Press},
  year={1997}
}

@article{hou2014blind,
  title={Blind image quality assessment via deep learning},
  author={Hou, Weilong and Gao, Xinbo and Tao, Dacheng and Li, Xuelong},
  journal={IEEE transactions on neural networks and learning systems},
  volume={26},
  number={6},
  pages={1275--1286},
  year={2014},
  publisher={IEEE}
}

@inproceedings{hu2023tifa,
  title={Tifa: Accurate and interpretable text-to-image faithfulness evaluation with question answering},
  author={Hu, Yushi and Liu, Benlin and Kasai, Jungo and Wang, Yizhong and Ostendorf, Mari and Krishna, Ranjay and Smith, Noah A},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={20406--20417},
  year={2023}
}

@inproceedings{kang2014convolutional,
  title={Convolutional neural networks for no-reference image quality assessment},
  author={Kang, Le and Ye, Peng and Li, Yi and Doermann, David},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={1733--1740},
  year={2014}
}

@article{kirstain2023pick,
  title={Pick-a-pic: An open dataset of user preferences for text-to-image generation},
  author={Kirstain, Yuval and Polyak, Adam and Singer, Uriel and Matiana, Shahbuland and Penna, Joe and Levy, Omer},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  pages={36652--36663},
  year={2023}
}

@inproceedings{li2022blip,
  title={Blip: Bootstrapping language-image pre-training for unified vision-language understanding and generation},
  author={Li, Junnan and Li, Dongxu and Xiong, Caiming and Hoi, Steven},
  booktitle={International conference on machine learning},
  pages={12888--12900},
  year={2022},
  organization={PMLR}
}

@article{li2023agiqa,
  title={Agiqa-3k: An open database for ai-generated image quality assessment},
  author={Li, Chunyi and Zhang, Zicheng and Wu, Haoning and Sun, Wei and Min, Xiongkuo and Liu, Xiaohong and Zhai, Guangtao and Lin, Weisi},
  journal={IEEE Transactions on Circuits and Systems for Video Technology},
  year={2023},
  publisher={IEEE}
}

@article{li2024aigiqa,
  title={Aigiqa-20k: A large database for ai-generated image quality assessment},
  author={Li, Chunyi and Kou, Tengchuan and Gao, Yixuan and Cao, Yuqin and Sun, Wei and Zhang, Zicheng and Zhou, Yingjie and Zhang, Zhichao and Zhang, Weixia and Wu, Haoning and others},
  journal={arXiv preprint arXiv:2404.03407},
  volume={2},
  number={3},
  pages={5},
  year={2024}
}

@inproceedings{liu2024ntire,
  title={NTIRE 2024 Quality Assessment of AI-Generated Content Challenge},
  author={Liu, Xiaohong and Min, Xiongkuo and Zhai, Guangtao and Li, Chunyi and Kou, Tengchuan and Sun, Wei and Wu, Haoning and Gao, Yixuan and Cao, Yuqin and Zhang, Zicheng and others},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={6337--6362},
  year={2024}
}

@article{lu2024llmscore,
  title={Llmscore: Unveiling the power of large language models in text-to-image synthesis evaluation},
  author={Lu, Yujie and Yang, Xianjun and Li, Xiujun and Wang, Xin Eric and Wang, William Yang},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@article{mittal2012making,
  title={Making a “completely blind” image quality analyzer},
  author={Mittal, Anish and Soundararajan, Rajiv and Bovik, Alan C},
  journal={IEEE Signal processing letters},
  volume={20},
  number={3},
  pages={209--212},
  year={2012},
  publisher={IEEE}
}

@inproceedings{peng2024aigc,
  title={Aigc image quality assessment via image-prompt correspondence},
  author={Peng, Fei and Fu, Huiyuan and Ming, Anlong and Wang, Chuanming and Ma, Huadong and He, Shuai and Dou, Zifei and Chen, Shu},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops},
  volume={6},
  year={2024}
}

@inproceedings{radford2021learning,
  title={Learning transferable visual models from natural language supervision},
  author={Radford, Alec and Kim, Jong Wook and Hallacy, Chris and Ramesh, Aditya and Goh, Gabriel and Agarwal, Sandhini and Sastry, Girish and Askell, Amanda and Mishkin, Pamela and Clark, Jack and others},
  booktitle={International conference on machine learning},
  pages={8748--8763},
  year={2021},
  organization={PMLR}
}

@article{shi2023blind,
  title={Blind Image Quality Assessment via Transformer Predicted Error Map and Perceptual Quality Token},
  author={Shi, Jinsong and Gao, Pan and Smolic, Aljosa},
  journal={IEEE Transactions on Multimedia},
  year={2023},
  publisher={IEEE}
}

@inproceedings{sun2022blind,
  title={Blind quality assessment for in-the-wild images via hierarchical feature fusion strategy},
  author={Sun, Wei and Duan, Huiyu and Min, Xiongkuo and Chen, Li and Zhai, Guangtao},
  booktitle={2022 IEEE International Symposium on Broadband Multimedia Systems and Broadcasting (BMSB)},
  pages={01--06},
  year={2022},
  organization={IEEE}
}

@article{sun2022graphiqa,
  title={GraphIQA: Learning distortion graph representations for blind image quality assessment},
  author={Sun, Simeng and Yu, Tao and Xu, Jiahua and Zhou, Wei and Chen, Zhibo},
  journal={IEEE Transactions on Multimedia},
  volume={25},
  pages={2912--2925},
  year={2022},
  publisher={IEEE}
}

@article{vaswani2017attention,
  title={Attention is all you need},
  author={Vaswani, A},
  journal={Advances in Neural Information Processing Systems},
  year={2017}
}

@article{wang2022diffusiondb,
  title={Diffusiondb: A large-scale prompt gallery dataset for text-to-image generative models},
  author={Wang, Zijie J and Montoya, Evan and Munechika, David and Yang, Haoyang and Hoover, Benjamin and Chau, Duen Horng},
  journal={arXiv preprint arXiv:2210.14896},
  year={2022}
}

@inproceedings{wang2023aigciqa2023,
  title={Aigciqa2023: A large-scale image quality assessment database for ai generated images: from the perspectives of quality, authenticity and correspondence},
  author={Wang, Jiarui and Duan, Huiyu and Liu, Jing and Chen, Shi and Min, Xiongkuo and Zhai, Guangtao},
  booktitle={CAAI International Conference on Artificial Intelligence},
  pages={46--57},
  year={2023},
  organization={Springer}
}

@inproceedings{wang2023exploring,
  title={Exploring clip for assessing the look and feel of images},
  author={Wang, Jianyi and Chan, Kelvin CK and Loy, Chen Change},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={37},
  number={2},
  pages={2555--2563},
  year={2023}
}

@inproceedings{wang2024large,
  title={Large multi-modality model assisted ai-generated image quality assessment},
  author={Wang, Puyi and Sun, Wei and Zhang, Zicheng and Jia, Jun and Jiang, Yanwei and Zhang, Zhichao and Min, Xiongkuo and Zhai, Guangtao},
  booktitle={Proceedings of the 32nd ACM International Conference on Multimedia},
  pages={7803--7812},
  year={2024}
}

@article{wang2024understanding,
  title={Understanding and Evaluating Human Preferences for AI Generated Images with Instruction Tuning},
  author={Wang, Jiarui and Duan, Huiyu and Zhai, Guangtao and Min, Xiongkuo},
  journal={arXiv preprint arXiv:2405.07346},
  year={2024}
}

@article{wu2023better,
  title={Better aligning text-to-image models with human preference},
  author={Wu, Xiaoshi and Sun, Keqiang and Zhu, Feng and Zhao, Rui and Li, Hongsheng},
  journal={arXiv preprint arXiv:2303.14420},
  volume={1},
  number={3},
  year={2023}
}

@article{wu2023q,
  title={Q-bench: A benchmark for general-purpose foundation models on low-level vision},
  author={Wu, Haoning and Zhang, Zicheng and Zhang, Erli and Chen, Chaofeng and Liao, Liang and Wang, Annan and Li, Chunyi and Sun, Wenxiu and Yan, Qiong and Zhai, Guangtao and others},
  journal={arXiv preprint arXiv:2309.14181},
  year={2023}
}

@article{wu2023qalign,
  title={Q-align: Teaching lmms for visual scoring via discrete text-defined levels},
  author={Wu, Haoning and Zhang, Zicheng and Zhang, Weixia and Chen, Chaofeng and Liao, Liang and Li, Chunyi and Gao, Yixuan and Wang, Annan and Zhang, Erli and Sun, Wenxiu and others},
  journal={arXiv preprint arXiv:2312.17090},
  year={2023}
}

@inproceedings{wu2024q,
  title={Q-instruct: Improving low-level visual abilities for multi-modality foundation models},
  author={Wu, Haoning and Zhang, Zicheng and Zhang, Erli and Chen, Chaofeng and Liao, Liang and Wang, Annan and Xu, Kaixin and Li, Chunyi and Hou, Jingwen and Zhai, Guangtao and others},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={25490--25500},
  year={2024}
}

@article{xu2016blind,
  title={Blind image quality assessment based on high order statistics aggregation},
  author={Xu, Jingtao and Ye, Peng and Li, Qiaohong and Du, Haiqing and Liu, Yong and Doermann, David},
  journal={IEEE Transactions on Image Processing},
  volume={25},
  number={9},
  pages={4444--4457},
  year={2016},
  publisher={IEEE}
}

@article{xu2024imagereward,
  title={Imagereward: Learning and evaluating human preferences for text-to-image generation},
  author={Xu, Jiazheng and Liu, Xiao and Wu, Yuchen and Tong, Yuxuan and Li, Qinkai and Ding, Ming and Tang, Jie and Dong, Yuxiao},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@article{xue2014blind,
  title={Blind image quality assessment using joint statistics of gradient magnitude and Laplacian features},
  author={Xue, Wufeng and Mou, Xuanqin and Zhang, Lei and Bovik, Alan C and Feng, Xiangchu},
  journal={IEEE Transactions on Image Processing},
  volume={23},
  number={11},
  pages={4850--4862},
  year={2014},
  publisher={IEEE}
}

@article{yang2020blind,
  title={Blind image quality assessment based on multi-scale KLT},
  author={Yang, Chao and Zhang, Xinfeng and An, Ping and Shen, Liquan and Kuo, C-C Jay},
  journal={IEEE Transactions on Multimedia},
  volume={23},
  pages={1557--1566},
  year={2020},
  publisher={IEEE}
}

@article{yang2020ttl,
  title={TTL-IQA: Transitive transfer learning based no-reference image quality assessment},
  author={Yang, Xiaohan and Li, Fan and Liu, Hantao},
  journal={IEEE Transactions on Multimedia},
  volume={23},
  pages={4326--4340},
  year={2020},
  publisher={IEEE}
}

@inproceedings{yang2024moe,
  title={Moe-agiqa: Mixture-of-experts boosted visual perception-driven and semantic-aware quality assessment for ai-generated images},
  author={Yang, Junfeng and Fu, Jing and Zhang, Wei and Cao, Wenzhi and Liu, Limei and Peng, Han},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={6395--6404},
  year={2024}
}

@inproceedings{yu2024sf,
  title={Sf-iqa: Quality and similarity integration for ai generated image quality assessment},
  author={Yu, Zihao and Guan, Fengbin and Lu, Yiting and Li, Xin and Chen, Zhibo},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={6692--6701},
  year={2024}
}

@article{yuan2023pku,
  title={Pku-i2iqa: An image-to-image quality assessment database for ai generated images},
  author={Yuan, Jiquan and Cao, Xinyan and Li, Changjin and Yang, Fanyi and Lin, Jinlong and Cao, Xixin},
  journal={arXiv preprint arXiv:2311.15556},
  year={2023}
}

@article{zhang2014blind,
  title={Blind image quality assessment using the joint statistics of generalized local binary pattern},
  author={Zhang, Min and Muramatsu, Chisako and Zhou, Xiangrong and Hara, Takeshi and Fujita, Hiroshi},
  journal={IEEE Signal Processing Letters},
  volume={22},
  number={2},
  pages={207--210},
  year={2014},
  publisher={IEEE}
}

@article{zhang2015feature,
  title={A feature-enriched completely blind image quality evaluator},
  author={Zhang, Lin and Zhang, Lei and Bovik, Alan C},
  journal={IEEE Transactions on Image Processing},
  volume={24},
  number={8},
  pages={2579--2591},
  year={2015},
  publisher={IEEE}
}

@article{zhang2018blind,
  title={Blind image quality assessment using a deep bilinear convolutional neural network},
  author={Zhang, Weixia and Ma, Kede and Yan, Jia and Deng, Dexiang and Wang, Zhou},
  journal={IEEE Transactions on Circuits and Systems for Video Technology},
  volume={30},
  number={1},
  pages={36--47},
  year={2018},
  publisher={IEEE}
}

@inproceedings{zhang2023blind,
  title={Blind image quality assessment via vision-language correspondence: A multitask learning perspective},
  author={Zhang, Weixia and Zhai, Guangtao and Wei, Ying and Yang, Xiaokang and Ma, Kede},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={14071--14081},
  year={2023}
}

@inproceedings{zhang2023perceptual,
  title={A perceptual quality assessment exploration for aigc images},
  author={Zhang, Zicheng and Li, Chunyi and Sun, Wei and Liu, Xiaohong and Min, Xiongkuo and Zhai, Guangtao},
  booktitle={2023 IEEE International Conference on Multimedia and Expo Workshops (ICMEW)},
  pages={440--445},
  year={2023},
  organization={IEEE}
}

@article{zhou2024adaptive,
  title={Adaptive mixed-scale feature fusion network for blind AI-generated image quality assessment},
  author={Zhou, Tianwei and Tan, Songbai and Zhou, Wei and Luo, Yu and Wang, Yuan-Gen and Yue, Guanghui},
  journal={IEEE Transactions on Broadcasting},
  year={2024},
  publisher={IEEE}
}

@article{zhu2022blind,
  title={Blind image quality assessment via cross-view consistency},
  author={Zhu, Yucheng and Li, Yunhao and Sun, Wei and Min, Xiongkuo and Zhai, Guangtao and Yang, Xiaokang},
  journal={IEEE Transactions on Multimedia},
  volume={25},
  pages={7607--7620},
  year={2022},
  publisher={IEEE}
}

