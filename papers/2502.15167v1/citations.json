[
  {
    "index": 0,
    "papers": [
      {
        "key": "mittal2012making",
        "author": "Mittal, Anish and Soundararajan, Rajiv and Bovik, Alan C",
        "title": "Making a \u201ccompletely blind\u201d image quality analyzer"
      }
    ]
  },
  {
    "index": 1,
    "papers": [
      {
        "key": "xue2014blind",
        "author": "Xue, Wufeng and Mou, Xuanqin and Zhang, Lei and Bovik, Alan C and Feng, Xiangchu",
        "title": "Blind image quality assessment using joint statistics of gradient magnitude and Laplacian features"
      },
      {
        "key": "zhang2014blind",
        "author": "Zhang, Min and Muramatsu, Chisako and Zhou, Xiangrong and Hara, Takeshi and Fujita, Hiroshi",
        "title": "Blind image quality assessment using the joint statistics of generalized local binary pattern"
      },
      {
        "key": "zhang2015feature",
        "author": "Zhang, Lin and Zhang, Lei and Bovik, Alan C",
        "title": "A feature-enriched completely blind image quality evaluator"
      },
      {
        "key": "xu2016blind",
        "author": "Xu, Jingtao and Ye, Peng and Li, Qiaohong and Du, Haiqing and Liu, Yong and Doermann, David",
        "title": "Blind image quality assessment based on high order statistics aggregation"
      }
    ]
  },
  {
    "index": 2,
    "papers": [
      {
        "key": "hou2014blind",
        "author": "Hou, Weilong and Gao, Xinbo and Tao, Dacheng and Li, Xuelong",
        "title": "Blind image quality assessment via deep learning"
      },
      {
        "key": "kang2014convolutional",
        "author": "Kang, Le and Ye, Peng and Li, Yi and Doermann, David",
        "title": "Convolutional neural networks for no-reference image quality assessment"
      },
      {
        "key": "zhang2018blind",
        "author": "Zhang, Weixia and Ma, Kede and Yan, Jia and Deng, Dexiang and Wang, Zhou",
        "title": "Blind image quality assessment using a deep bilinear convolutional neural network"
      },
      {
        "key": "yang2020ttl",
        "author": "Yang, Xiaohan and Li, Fan and Liu, Hantao",
        "title": "TTL-IQA: Transitive transfer learning based no-reference image quality assessment"
      },
      {
        "key": "yang2020blind",
        "author": "Yang, Chao and Zhang, Xinfeng and An, Ping and Shen, Liquan and Kuo, C-C Jay",
        "title": "Blind image quality assessment based on multi-scale KLT"
      },
      {
        "key": "sun2022blind",
        "author": "Sun, Wei and Duan, Huiyu and Min, Xiongkuo and Chen, Li and Zhai, Guangtao",
        "title": "Blind quality assessment for in-the-wild images via hierarchical feature fusion strategy"
      },
      {
        "key": "zhu2022blind",
        "author": "Zhu, Yucheng and Li, Yunhao and Sun, Wei and Min, Xiongkuo and Zhai, Guangtao and Yang, Xiaokang",
        "title": "Blind image quality assessment via cross-view consistency"
      },
      {
        "key": "sun2022graphiqa",
        "author": "Sun, Simeng and Yu, Tao and Xu, Jiahua and Zhou, Wei and Chen, Zhibo",
        "title": "GraphIQA: Learning distortion graph representations for blind image quality assessment"
      }
    ]
  },
  {
    "index": 3,
    "papers": [
      {
        "key": "zhang2018blind",
        "author": "Zhang, Weixia and Ma, Kede and Yan, Jia and Deng, Dexiang and Wang, Zhou",
        "title": "Blind image quality assessment using a deep bilinear convolutional neural network"
      }
    ]
  },
  {
    "index": 4,
    "papers": [
      {
        "key": "Su_2020_CVPR",
        "author": "Su, Shaolin and Yan, Qingsen and Zhu, Yu and Zhang, Cheng and Ge, Xin and Sun, Jinqiu and Zhang, Yanning",
        "title": "Blindly Assess Image Quality in the Wild Guided by a Self-Adaptive Hyper Network"
      }
    ]
  },
  {
    "index": 5,
    "papers": [
      {
        "key": "sun2022blind",
        "author": "Sun, Wei and Duan, Huiyu and Min, Xiongkuo and Chen, Li and Zhai, Guangtao",
        "title": "Blind quality assessment for in-the-wild images via hierarchical feature fusion strategy"
      }
    ]
  },
  {
    "index": 6,
    "papers": [
      {
        "key": "he2016deep",
        "author": "He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian",
        "title": "Deep residual learning for image recognition"
      }
    ]
  },
  {
    "index": 7,
    "papers": [
      {
        "key": "radford2021learning",
        "author": "Radford, Alec and Kim, Jong Wook and Hallacy, Chris and Ramesh, Aditya and Goh, Gabriel and Agarwal, Sandhini and Sastry, Girish and Askell, Amanda and Mishkin, Pamela and Clark, Jack and others",
        "title": "Learning transferable visual models from natural language supervision"
      }
    ]
  },
  {
    "index": 8,
    "papers": [
      {
        "key": "li2022blip",
        "author": "Li, Junnan and Li, Dongxu and Xiong, Caiming and Hoi, Steven",
        "title": "Blip: Bootstrapping language-image pre-training for unified vision-language understanding and generation"
      }
    ]
  },
  {
    "index": 9,
    "papers": [
      {
        "key": "dosovitskiy2020image",
        "author": "Dosovitskiy, Alexey and Beyer, Lucas and Kolesnikov, Alexander and Weissenborn, Dirk and Zhai, Xiaohua and Unterthiner, Thomas and Dehghani, Mostafa and Minderer, Matthias and Heigold, Georg and Gelly, Sylvain and others",
        "title": "An image is worth 16x16 words: Transformers for image recognition at scale"
      }
    ]
  },
  {
    "index": 10,
    "papers": [
      {
        "key": "wang2023exploring",
        "author": "Wang, Jianyi and Chan, Kelvin CK and Loy, Chen Change",
        "title": "Exploring clip for assessing the look and feel of images"
      }
    ]
  },
  {
    "index": 11,
    "papers": [
      {
        "key": "zhang2023blind",
        "author": "Zhang, Weixia and Zhai, Guangtao and Wei, Ying and Yang, Xiaokang and Ma, Kede",
        "title": "Blind image quality assessment via vision-language correspondence: A multitask learning perspective"
      }
    ]
  },
  {
    "index": 12,
    "papers": [
      {
        "key": "shi2023blind",
        "author": "Shi, Jinsong and Gao, Pan and Smolic, Aljosa",
        "title": "Blind Image Quality Assessment via Transformer Predicted Error Map and Perceptual Quality Token"
      }
    ]
  },
  {
    "index": 13,
    "papers": [
      {
        "key": "vaswani2017attention",
        "author": "Vaswani, A",
        "title": "Attention is all you need"
      }
    ]
  },
  {
    "index": 14,
    "papers": [
      {
        "key": "wu2023better",
        "author": "Wu, Xiaoshi and Sun, Keqiang and Zhu, Feng and Zhao, Rui and Li, Hongsheng",
        "title": "Better aligning text-to-image models with human preference"
      }
    ]
  },
  {
    "index": 15,
    "papers": [
      {
        "key": "kirstain2023pick",
        "author": "Kirstain, Yuval and Polyak, Adam and Singer, Uriel and Matiana, Shahbuland and Penna, Joe and Levy, Omer",
        "title": "Pick-a-pic: An open dataset of user preferences for text-to-image generation"
      }
    ]
  },
  {
    "index": 16,
    "papers": [
      {
        "key": "xu2024imagereward",
        "author": "Xu, Jiazheng and Liu, Xiao and Wu, Yuchen and Tong, Yuxuan and Li, Qinkai and Ding, Ming and Tang, Jie and Dong, Yuxiao",
        "title": "Imagereward: Learning and evaluating human preferences for text-to-image generation"
      }
    ]
  },
  {
    "index": 17,
    "papers": [
      {
        "key": "li2022blip",
        "author": "Li, Junnan and Li, Dongxu and Xiong, Caiming and Hoi, Steven",
        "title": "Blip: Bootstrapping language-image pre-training for unified vision-language understanding and generation"
      }
    ]
  },
  {
    "index": 18,
    "papers": [
      {
        "key": "wang2022diffusiondb",
        "author": "Wang, Zijie J and Montoya, Evan and Munechika, David and Yang, Haoyang and Hoover, Benjamin and Chau, Duen Horng",
        "title": "Diffusiondb: A large-scale prompt gallery dataset for text-to-image generative models"
      }
    ]
  },
  {
    "index": 19,
    "papers": [
      {
        "key": "chen2024learning",
        "author": "Chen, Junyu and An, Jie and Lyu, Hanjia and Kanan, Christopher and Luo, Jiebo",
        "title": "Learning to Evaluate the Artness of AI-generated Images"
      }
    ]
  },
  {
    "index": 20,
    "papers": [
      {
        "key": "zhang2023perceptual",
        "author": "Zhang, Zicheng and Li, Chunyi and Sun, Wei and Liu, Xiaohong and Min, Xiongkuo and Zhai, Guangtao",
        "title": "A perceptual quality assessment exploration for aigc images"
      }
    ]
  },
  {
    "index": 21,
    "papers": [
      {
        "key": "li2023agiqa",
        "author": "Li, Chunyi and Zhang, Zicheng and Wu, Haoning and Sun, Wei and Min, Xiongkuo and Liu, Xiaohong and Zhai, Guangtao and Lin, Weisi",
        "title": "Agiqa-3k: An open database for ai-generated image quality assessment"
      }
    ]
  },
  {
    "index": 22,
    "papers": [
      {
        "key": "wang2023aigciqa2023",
        "author": "Wang, Jiarui and Duan, Huiyu and Liu, Jing and Chen, Shi and Min, Xiongkuo and Zhai, Guangtao",
        "title": "Aigciqa2023: A large-scale image quality assessment database for ai generated images: from the perspectives of quality, authenticity and correspondence"
      }
    ]
  },
  {
    "index": 23,
    "papers": [
      {
        "key": "li2024aigiqa",
        "author": "Li, Chunyi and Kou, Tengchuan and Gao, Yixuan and Cao, Yuqin and Sun, Wei and Zhang, Zicheng and Zhou, Yingjie and Zhang, Zhichao and Zhang, Weixia and Wu, Haoning and others",
        "title": "Aigiqa-20k: A large database for ai-generated image quality assessment"
      }
    ]
  },
  {
    "index": 24,
    "papers": [
      {
        "key": "yuan2023pku",
        "author": "Yuan, Jiquan and Cao, Xinyan and Li, Changjin and Yang, Fanyi and Lin, Jinlong and Cao, Xixin",
        "title": "Pku-i2iqa: An image-to-image quality assessment database for ai generated images"
      }
    ]
  },
  {
    "index": 25,
    "papers": [
      {
        "key": "zhou2024adaptive",
        "author": "Zhou, Tianwei and Tan, Songbai and Zhou, Wei and Luo, Yu and Wang, Yuan-Gen and Yue, Guanghui",
        "title": "Adaptive mixed-scale feature fusion network for blind AI-generated image quality assessment"
      }
    ]
  },
  {
    "index": 26,
    "papers": [
      {
        "key": "liu2024ntire",
        "author": "Liu, Xiaohong and Min, Xiongkuo and Zhai, Guangtao and Li, Chunyi and Kou, Tengchuan and Sun, Wei and Wu, Haoning and Gao, Yixuan and Cao, Yuqin and Zhang, Zicheng and others",
        "title": "NTIRE 2024 Quality Assessment of AI-Generated Content Challenge"
      }
    ]
  },
  {
    "index": 27,
    "papers": [
      {
        "key": "zhang2023blind",
        "author": "Zhang, Weixia and Zhai, Guangtao and Wei, Ying and Yang, Xiaokang and Ma, Kede",
        "title": "Blind image quality assessment via vision-language correspondence: A multitask learning perspective"
      }
    ]
  },
  {
    "index": 28,
    "papers": [
      {
        "key": "peng2024aigc",
        "author": "Peng, Fei and Fu, Huiyuan and Ming, Anlong and Wang, Chuanming and Ma, Huadong and He, Shuai and Dou, Zifei and Chen, Shu",
        "title": "Aigc image quality assessment via image-prompt correspondence"
      }
    ]
  },
  {
    "index": 29,
    "papers": [
      {
        "key": "yu2024sf",
        "author": "Yu, Zihao and Guan, Fengbin and Lu, Yiting and Li, Xin and Chen, Zhibo",
        "title": "Sf-iqa: Quality and similarity integration for ai generated image quality assessment"
      }
    ]
  },
  {
    "index": 30,
    "papers": [
      {
        "key": "yang2024moe",
        "author": "Yang, Junfeng and Fu, Jing and Zhang, Wei and Cao, Wenzhi and Liu, Limei and Peng, Han",
        "title": "Moe-agiqa: Mixture-of-experts boosted visual perception-driven and semantic-aware quality assessment for ai-generated images"
      }
    ]
  },
  {
    "index": 31,
    "papers": [
      {
        "key": "hu2023tifa",
        "author": "Hu, Yushi and Liu, Benlin and Kasai, Jungo and Wang, Yizhong and Ostendorf, Mari and Krishna, Ranjay and Smith, Noah A",
        "title": "Tifa: Accurate and interpretable text-to-image faithfulness evaluation with question answering"
      }
    ]
  },
  {
    "index": 32,
    "papers": [
      {
        "key": "lu2024llmscore",
        "author": "Lu, Yujie and Yang, Xianjun and Li, Xiujun and Wang, Xin Eric and Wang, William Yang",
        "title": "Llmscore: Unveiling the power of large language models in text-to-image synthesis evaluation"
      }
    ]
  },
  {
    "index": 33,
    "papers": [
      {
        "key": "wu2023q",
        "author": "Wu, Haoning and Zhang, Zicheng and Zhang, Erli and Chen, Chaofeng and Liao, Liang and Wang, Annan and Li, Chunyi and Sun, Wenxiu and Yan, Qiong and Zhai, Guangtao and others",
        "title": "Q-bench: A benchmark for general-purpose foundation models on low-level vision"
      }
    ]
  },
  {
    "index": 34,
    "papers": [
      {
        "key": "wu2024q",
        "author": "Wu, Haoning and Zhang, Zicheng and Zhang, Erli and Chen, Chaofeng and Liao, Liang and Wang, Annan and Xu, Kaixin and Li, Chunyi and Hou, Jingwen and Zhai, Guangtao and others",
        "title": "Q-instruct: Improving low-level visual abilities for multi-modality foundation models"
      }
    ]
  },
  {
    "index": 35,
    "papers": [
      {
        "key": "wu2023qalign",
        "author": "Wu, Haoning and Zhang, Zicheng and Zhang, Weixia and Chen, Chaofeng and Liao, Liang and Li, Chunyi and Gao, Yixuan and Wang, Annan and Zhang, Erli and Sun, Wenxiu and others",
        "title": "Q-align: Teaching lmms for visual scoring via discrete text-defined levels"
      }
    ]
  },
  {
    "index": 36,
    "papers": [
      {
        "key": "wang2024large",
        "author": "Wang, Puyi and Sun, Wei and Zhang, Zicheng and Jia, Jun and Jiang, Yanwei and Zhang, Zhichao and Min, Xiongkuo and Zhai, Guangtao",
        "title": "Large multi-modality model assisted ai-generated image quality assessment"
      }
    ]
  },
  {
    "index": 37,
    "papers": [
      {
        "key": "wang2024understanding",
        "author": "Wang, Jiarui and Duan, Huiyu and Zhai, Guangtao and Min, Xiongkuo",
        "title": "Understanding and Evaluating Human Preferences for AI Generated Images with Instruction Tuning"
      }
    ]
  },
  {
    "index": 38,
    "papers": [
      {
        "key": "wang2023aigciqa2023",
        "author": "Wang, Jiarui and Duan, Huiyu and Liu, Jing and Chen, Shi and Min, Xiongkuo and Zhai, Guangtao",
        "title": "Aigciqa2023: A large-scale image quality assessment database for ai generated images: from the perspectives of quality, authenticity and correspondence"
      }
    ]
  },
  {
    "index": 39,
    "papers": [
      {
        "key": "hochreiter1997long",
        "author": "Hochreiter, S",
        "title": "Long Short-term Memory"
      }
    ]
  },
  {
    "index": 40,
    "papers": [
      {
        "key": "beck2024xlstm",
        "author": "Beck, Maximilian and P{\\\"o}ppel, Korbinian and Spanring, Markus and Auer, Andreas and Prudnikova, Oleksandra and Kopp, Michael and Klambauer, G{\\\"u}nter and Brandstetter, Johannes and Hochreiter, Sepp",
        "title": "xLSTM: Extended Long Short-Term Memory"
      }
    ]
  },
  {
    "index": 41,
    "papers": [
      {
        "key": "alkin2024visionlstm",
        "author": "Benedikt Alkin and Maximilian Beck and Korbinian P{\\\"o}ppel and Sepp Hochreiter and Johannes Brandstetter",
        "title": "Vision-LSTM: xLSTM as Generic Vision Backbone"
      }
    ]
  }
]