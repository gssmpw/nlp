\section{Related Work}
\mypara{LLM Memorization}
Memorization in LLMs refers to the model's tendency to store and reproduce exact phrases or passages from the training data rather than generating novel or generalized outputs ____. It has been proved to play a significant role in simple, knowledge-intensive tasks ____, but include rare, unrelated details before overfitting, a phenomenon called "unintended memorization" ____. This unintended memorization raises privacy concerns, especially on domain-specific models ____. Several studies have examined how factors such as model size, training data repetition, context length, and fine-tuning strategies influence LLM memorization ____.



\mypara{PII Leakage}
Due to the unintended memorization of LLMs, malicious attackers can exploit this vulnerability to steal sensitive data from training sets, including Personally Identifiable Information (PII), resulting in PII leakage. ____ emphasize the need to address this issue, proposing a pipeline for extracting sensitive information from the Codex model. PII leakage attacks can be classified into three categories according to the adversaryâ€™s capabilities: extraction attacks ____, reconstruction attacks ____, and inference attacks____. One technique to mitigate these risks is directly editing model weights, though no universal defense methods exist yet ____. Further attacks can bypass model alignment and recover sensitive training data ____.