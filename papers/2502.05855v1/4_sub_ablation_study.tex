\subsection{Ablation Study}
\label{sec:ablation}

\begin{table}[t]
  \centering
  \caption{\textbf{Ablation results on action head architecture.} DexVLA (UNet) denotes the variant with a smaller UNet-based action head(93M). We reported the average score on shirt folding task.}
  % soap, hang cup,toothpaste,towel
  \label{tbl:ablate_head}
  \resizebox{1\linewidth}{!}{
      \begin{tabular}{c|ccc}
        \toprule
        Models & UNet(93M) & Diffusion Expert(1B) & Averaged Score \\
        \midrule
        DexVLA (UNet) & \checkmark &  & 0.17 \\
        DexVLA &  & \checkmark & 0.92 \\
        \bottomrule
      \end{tabular}
    }
\end{table}

\begin{table}[t]
  \centering
  \caption{\textbf{Ablation study of sub-step reasoning.} The \checkmark in each stage indicates the use of sub-step reasoning data during that stage. We report the average score on the shirt-folding task.}
  % soap, hang cup,toothpaste,towel
  \label{tbl:ablate_substep}
  \resizebox{0.75\linewidth}{!}{
      \begin{tabular}{c|ccc}
        \toprule
         Stage 1 & Stage 2 & Averaged Score \\
        \midrule
          & \checkmark & 0.07 \\
         \checkmark &  & 0 \\
        \midrule
         \checkmark & \checkmark & 0.92 \\
        \bottomrule
      \end{tabular}
    }
\end{table}


\begin{table}[t]
  \centering
  \caption{\textbf{Ablation study of stage 1 training}. To quantify the impact of stage 1 training, we performed an ablation study, training DexVLA without pre-training the diffusion expert. We compared two variants: Stage 2-Only (DexVLA trained only on single-embodiment data) and Stage 1$+$2 (DexVLA trained on combined cross- and single-embodiment data).}
  \label{tbl:ablate_scratch}
  \resizebox{1\linewidth}{!}{
      \begin{tabular}{c|ccc}
        \toprule
        Models / Data & Stage 1  & Stage 2 & Averaged Score \\
        \midrule
        DexVLA (Stage2-Only) &  & \checkmark & 0 \\
        DexVLA (Stage1$+$2) & \checkmark & \checkmark & 0 \\
        \midrule
        DexVLA &  & \checkmark & 0.92 \\
        \bottomrule
      \end{tabular}
    }
\end{table}

Our key contribution is a novel vision-language-action (VLA) model architecture incorporating a diffusion expertâ€”a significantly larger action expert based on a diffusion transformer. We also introduce a new, effective training approach. Crucially, we leverage substep annotations to train both the diffusion expert and the VLA model within a unified framework. This enables our model to handle extremely complex tasks, such as laundry folding, without relying on a high-level policy model. This section investigates these three aspects, addressing the following questions: 1) Does the larger diffusion transformer architecture of the diffusion expert offer advantages over a smaller UNet model? 2) Is the stage 1 training phase essential for our model's performance? 3) How critical is training with substep reasoning for complex tasks?


\textbf{Does our diffusion expert offer advantages over a smaller model?} Our method uses a diffusion expert based on a one-billion-parameter Transformer architecture. While the scaling law, where larger models lead to greater capacity and improved performance and generalization, has been shown in areas like large language models and image generation, its applicability to robot learning is unclear.  Therefore, we investigate whether increasing the action expert's model size provides benefits compared to smaller models.

To this end, we utilize the standard Diffusion Policy architecture with a UNet model as a baseline.  We chose the UNet architecture because the original paper noted training difficulties with their Transformer-based version. This UNet architecture has 93 million parameters.  Following the same training strategy and using the same amount of data, we trained this network. As shown in Table~\ref{tbl:ablate_head}, the UNet-based action expert performs significantly worse than our method, barely completing the shirt folding task with an average scores of 0.17.  Empirically, we observed greater oscillation in the robot's movements with the UNet model compared to our diffusion expert. We hypothesize that the UNet's fewer parameters contribute to interference between different actions in the parameter space, hindering the model's ability to learn the correct actions.

\textbf{Is diffusion expert pretraining necessary?} Our work employs a three-stage training strategy tailored to our proposed architecture. One might question the necessity of separately training the diffusion expert.  Therefore, we conducted experiments under two alternative training regimes.  The first condenses the three stages into two: we initially pre-train the entire~\methodname~model using all our training data and then fine-tune it on embodied-specific data. The second approach directly trains the model from scratch using only the embodied-specific data.  We evaluated both settings on shirt folding, easy bin picking, and easy bussing table tasks, none of which require the post-training stage. The results, shown in Table~\ref{tbl:ablate_scratch}, demonstrate that neither alternative training strategy successfully completed any of the tasks.  Both models failed to train effectively. We hypothesize that the large number of parameters in the diffusion expert makes optimization challenging.  The stage 1 training in our method not only enables the diffusion expert to learn actions but also ``warms up" its parameters, allowing it to better understand complex visual cues and language instructions.

\textbf{Does sub-step reasoning help?} A key strength of our method is its ability to handle extremely long and complex tasks, such as folding randomly crumpled shirts from a basket.  It also enables the model to complete multi-stage tasks like shirt folding and bin picking without requiring post-training.  Therefore, we now examine the importance of substep reasoning. We conducted an ablation study with two setups: 1) The diffusion expert is trained with direct prompting (each task has only one language instruction), while the VLA-diffusion expert is trained with substep reasoning. 2) Both stage 1 and stage 2 are trained with direct prompting data.  The results are shown in Table~\ref{tbl:ablate_substep}. Training the diffusion expert with direct prompting, even for a relatively simple task like shirt folding, reduces the averaged score from 0.92 to 0.07.  Furthermore, removing substep reasoning from both stages results in a complete failure (0 score). This is a significant observation. It suggests that learning long-horizon tasks within a shared parameter space can sometimes lead to conflicts. We hypothesize that substep reasoning allows the model to learn a more disentangled action space, similar to mapping a continuous action space to a discrete one~\cite{wu2024discrete}. This effectively segments the shared parameter space, allocating a smaller set of parameters to each substep~\cite{wang2023fleet, wang2024poco, wang2024scaling}. This avoids parameter conflicts, leading to improved performance and generalization.