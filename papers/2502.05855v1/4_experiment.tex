\section{Real World Experiments}
\begin{figure}[t]
    \centering
    \includegraphics[width=0.48\textwidth]{images/wo-post-training-task.pdf}
    \caption{\textbf{Examples of tasks without task-specific adaptation.} We assessed our model's performance after stage 2 training using three tasks: \textbf{bin-picking easy} (top), \textbf{shirt folding} (middle), and \textbf{table bussing easy} (bottom). Successful execution of these tasks necessitates a combination of dexterous manipulation skills.}\label{fig:easy_task_suite}
\end{figure}
\begin{figure}[t]
    \centering
    \includegraphics[width=0.45\textwidth]{images/zero_shot_tasks.pdf}
    \caption{\textbf{Results on tasks without task-specific adaptation.} We compared our model against Octo, OpenVLA, and Diffusion Policy. Performance was evaluated across 10 trials for each model, with scores averaged across these trials.}\label{fig:zero_shot_tasks_results}
\end{figure}




\subsection{Evaluating Model without Task-Specific Adaptation}
\label{sec:no_post_training}
This section evaluates the model's performance before task-specific adaptation (Stage 3). The evaluated tasks, visualized in Figure~\ref{fig:easy_task_suite}, all use the model with one set of parameters.

\begin{itemize}
    \item \textbf{Shirt folding (Bimanual AgileX)}: The shirt is placed flattened on the table, and the robot is asked to fold a t-shirt. We evaluate two shirts, a yellow shirt of medium size and a blue shirt of large size. 
    \item \textbf{Bin picking easy (Franka with gripper)}: The model needs to pick up all items from the right panel to the left tray. All items are seen in the dataset. 
    \item \textbf{Bussing table easy (Bimanual AgileX)}: The robot must clean a table, place dishes and cutlery in a bin, and trash into a trash bin.
\end{itemize}

These tasks vary significantly in trajectory length and complexity, with some requiring high dexterity and intricate manipulation (e.g., shirt folding). We benchmark our approach against OpenVLA~\cite{kim24openvla}, a state-of-the-art 7B-parameter VLA model pre-trained on the Open X-Embodiment (OXE)~\cite{o2023open-x} dataset, and Octo~\cite{octo}, a compact 93M parameter model that employs a diffusion-based policy for action generation. We used the open-sourced pre-trained weights for these two models. All baselines are fine-tuned on the same dataset and for the same number of epochs as our Stage 2 training, ensuring a fair comparison. We also compare to the Diffusion Policy~\cite{diffusion-policy}, a strong baseline. Notably, neither Octo nor OpenVLA has previously demonstrated success on tasks of this complexity. While proprietary VLA models like $\pi_{0}$ and RT-2~\cite{rt-2} represent strong competitors, their closed-source implementations and reliance on private training data preclude direct empirical comparison. 

Following $\pi_{0}$, we use a normalized score averaged over 10 episodes per task and method as our evaluation metric.  Detailed scoring rubrics for each task are provided in the Appendix. As shown in Figure~\ref{fig:zero_shot_tasks_results}, DexVLA significantly outperforms all baselines on all tasks without task-specific adaptation.  Notably, baseline methods, including OpenVLA, Octo, and Diffusion Policy, struggled to complete any steps of the shirt folding task, highlighting its complexity.  In contrast, DexVLA achieves a 0.92 point on shirt folding without any task-specific adaptation.  A similar phenomenon is observed in the bin picking and table bussing tasks.  While these challenging tasks sometimes see limited success from the baselines, their overall scores remain low. DexVLA, however, achieves substantially better performance on these tasks.


\begin{figure}[t]
    \centering
    \includegraphics[width=0.48\textwidth]{images/learning_new_tasks.pdf}
    \caption{\textbf{Example of tasks for learning dexterous skills on new embodiment.} We evaluate our model on two new embodiments with \textbf{packing (top)} and \textbf{drink pouring (bottom)} tasks, which are not included in stage 1 \& 2 train data.}\label{fig:new_task_suite}
\end{figure}



\begin{figure}[t]
    \centering
    \includegraphics[width=0.4\textwidth]{images/new_task_results.pdf}
    \caption{\textbf{Results on learning dexterous skills from new embodiment.} We evaluated our model with four three baselines: Diffusion Policy, Octo, and OpenVLA. Diffusion Policy is directly trained on these novel tasks from scratch.}\label{fig:new_tasks_results}
    % \vspace{-2em}
\end{figure}




\subsection{Learning Dexterous Skills on New Embodiment}
\label{sec:new_embodiment}
This section evaluates our model's ability to learn dexterous skills on the new embodiments as shown in Figure~\ref{fig:new_task_suite}. Specifically, the new embodiments are not involved in either Stage 1 or Stage 2 training. We aim to demonstrate the effectiveness of our proposed framework in acquiring new skills quickly on any new embodiment without the necessity of pre-training.
\begin{itemize}
    \item \textbf{Drink pouring (Franka with dexterous hand)}: The drink is placed on the right of the table and a cup is placed on the left. The robot needs to grab the drink and pour it into the cup. This task includes 100 demonstrations. 
    \item \textbf{Packing (Bimanual UR5)}: The robot is asked to pick up objects on both sides and place them into the box for packing. This task includes 100 demonstrations. 
\end{itemize}

These tasks involve two novel robotic systems absent from training data: 1) \textbf{A Franka arm} integrated with a \textbf{dexterous hand} have 12 DoF, serves as a more complex robotic system than a simple gripper, posing a greater challenge for the model to learn. 2) \textbf{A bimanual UR5e} system featuring humanoid-inspired kinematic design and its articulation fundamentally differs from conventional dual-arm platforms like the AgileX bimanual robot.
We evaluate our approach against three baseline methods: Diffusion Policy, Octo, and OpenVLA, the same baseline as in the previous section. This section aims to validate the adaptability of our pre-trained model to new embodiments and tasks. To this end, we directly fine-tune our Stage 2 pre-trained model on the novel tasks. For OpenVLA and Octo, we employ their publicly available checkpoints pre-trained on the OXE dataset. The Diffusion Policy — a method specialized for learning dexterous tasks from limited data — is trained exclusively on the two novel tasks. All methods are trained on individual tasks, and to ensure fairness, each baseline undergoes the same number of training epochs.

Figure~\ref{fig:new_tasks_results} compares the performance of the methods on two novel tasks. For each method and task, we report the averaged scores over 10 trials (detailed scoring criteria are provided in the Appendix). DexVLA achieves an average of 0.90 point across two tasks, while OpenVLA and Octo struggle. DexVLA significantly outperforms Diffusion Policy, achieving a substantial performance lead. These results highlight DexVLA’s ability to efficiently adapt to new embodiments and master complex skills with only 100 demonstrations.  These results are particularly meaningful as our method outperforms both extensively pre-trained VLA models (OpenVLA) and methods specifically designed for learning new tasks (Diffusion Policy).


\begin{figure}[t]
    \centering
    \includegraphics[width=0.48\textwidth]{images/post_training_tasks_results.pdf}
    \caption{\textbf{Average scores on tasks requiring stage 3 training}. We compared our model against two baselines: Octo and OpenVLA. Averaging scores over 10 trials, our method significantly outperformed both baselines across all tasks. Note that sorting was not included in the pre-training data.}\label{fig:post_training_results}
\end{figure}

\subsection{Complex Long-Horizon Tasks with Direct Prompting}
\label{sec:direct_prompting}
In this set of experiments, we tackle a range of challenging multi-stage tasks via a combination of task-specific post-training and self-generated reasoning capability. For some of these tasks, data is present in pre-training, but fine-tuning is required to attain mastery. For some, no data is present in pre-training. The tasks in this evaluation, shown in Figure~\ref{fig:hard_task_suite}, are:

\begin{itemize}
    \item \textbf{Laundry folding (Bimanual AgileX)}: This task requires a static (non-mobile) bimanual system to fold articles of clothing. The clothing items start in a randomized crumpled state in a bin, and the goal is to take out the item, fold it, and place it on top of a stack of previously folded items. The randomized initial configuration of the crumpled laundry presents a major challenge since the policy needs to generalize to any configuration. This task is present in pre-training.
    \item \textbf{Dryer unloading (Bimanual AgileX)}: Here, the AgileX mobile robot has to take the laundry out of a dryer and place it into a hamper. This task is present in pre-training.
    \item \textbf{Sorting (Franka with gripper)}: The model needs to pick up all items from the right panel, and place them in the correct subsection of the left tray. The left tray is divided into four subsections. All new objects belong to the same category as these four sections. This task includes 200 demonstrations. This task is not in the pre-training data. 
    \item \textbf{Bin picking hard (Franka with gripper)}: The model needs to pick up all items from the right panel to the left tray. Unlike the easy version, all objects are new and only present at test time. This task is present in pre-training.
    \item \textbf{Bussing table hard (Bimanual AgileX)}: The robot must clean a table, place dishes and cutlery in a bin, and trash into a trash bin. Unlike the easy version, all objects are new. In particular, we use dishes with unseen colors and trash with different appearances. This task is present in pre-training.
\end{itemize}

These tasks involve extended-horizon challenges. For instance, laundry folding requires more than 2 minutes to collect a single episode, and the soft, deformable fabric of clothing generates numerous unseen shapes and states, posing significant challenges for recognition and task completion. In the sorting task, the model must pick up 5–8 randomly placed objects in a cluttered scene and relocate them to predefined target positions.


We evaluate all models using averaged scores over 10 trials (detailed scoring criteria are provided in the Appendix). Conduct comparisons on these tasks is challenging due to the scarcity of prior models capable of operating at this scale. While $\pi_0$ represents the state-of-the-art in laundry folding, as mentioned before, its closed-source implementation and reliance on proprietary training data prevent direct benchmarking. Consequently, we compare our method only against OpenVLA and Octo. As demonstrated in Figure~\ref{fig:post_training_results}, DexVLA consistently surpasses all baselines and achieves a 0.8 point in the dryer unloading task. Even facing the most complicated task, laundry folding, our method attains a 0.4 point which proves its potential in handling extremely complicated scenarios. Through comprehensive evaluations, DexVLA demonstrates the capability to perform versatile, complex, and dexterous tasks via the combination of our proposed embodied curriculum learning method, scalable diffusion expert, and our novel VLA framework. We argue that DexVLA provides a promising approach for constructing VLA systems that effectively handle heterogeneous robotics data and master intricate manipulation tasks.
