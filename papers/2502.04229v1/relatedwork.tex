\section{Related Works}
\noindent \textbf{Dataset Distillation.} DD aims to condense the richness of large-scale datasets into compact small datasets that effectively preserve training performance~\cite{yu2023dataset}.
Coreset selection~\cite{du2024sequential} is an early-stage research in data-efficient learning. Most methods rely on heuristics to select representatives. 
Unlike this paradigm, DD~\cite{wang2018dataset} aims to learn how to synthesize a tiny dataset that trains models to perform comparably to those trained on the complete dataset. Wang~\textit{et al.}~\cite{wang2018dataset} first proposed a bi-level meta-learning approach, which optimizes a synthetic dataset so that neural networks trained on it achieve the lowest loss on the raw dataset.
% , and thus the performance of models trained by synthetic and real datasets is matched.

Following this research, many researchers have focused on reducing the computational cost of the inner loop by introducing closed-form solutions, such as kernel ridge regression~\cite{loo2022efficient,chenprovable,xu2023kernel}. 
Zhao~\textit{et al.}~\cite{zhao2021dataset} proposed an approach that makes parameters trained on condensed data approximate the target parameters, formulating a gradient matching objective that simplifies the DD process from a parameter perspective. In~\cite{zhao2021datasetdsa}, the authors enhanced the process by incorporating Differentiable Siamese Augmentation~(DSA), which enables effective data augmentation on synthetic data and results in the distillation of more informative images. Additionally, Du~\textit{et al.}~\cite{du2024sequential} proposed a sequential DD method to extract the high-level features learned by the DNN in later epochs. 
By combining meta-learning and parameter matching, Cazenavette~\textit{et al.}~\cite{cazenavette2022dataset} proposed Matching Training Trajectories~(MTT) and achieved satisfactory performance. Besides, a recent work, TESLA~\cite{cui2023scaling}, reduced GPU memory consumption and can be viewed as a memory-efficient version of MTT. 
% Instead of matching gradients or parameters, recent works proposed to condense datasets by matching distributions~\cite{wang2022cafe}.

\noindent \textbf{Backdoor Attack.} Backdoor attacks introduce malicious behavior into the model without degrading its performance on the original task by poisoning the dataset. Gu~\textit{et al.}~\cite{gu2019badnets} introduced the backdoor threat in DL with BadNets, which injects visible triggers into randomly selected training samples and mislabels them as a specified target class. To enhance attack stealthiness, Chen~\textit{et al.}~\cite{chen2017targeted} proposed a blended strategy to make poisoned images indistinguishable from benign ones, improving their ability to evade human inspection. Furthermore, subsequent works explored stealthier attacks: WaNet~\cite{nguyen2020wanet} used image warping; ISSBA~\cite{li2021invisible} employed deep steganography; Feng~\textit{et al.}~\cite{feng2022fiba} and Wang~\textit{et al.}~\cite{wang2022invisible} embedded triggers in the frequency domain; Yang~\textit{et al.}~\cite{yang2024inject} injected the trigger into the measurement domain; and Color Backdoor~\cite{jiang2023color} utilized uniform color space shifts as triggers. 

Although existing works have demonstrated the vulnerability of deep networks to backdoor attacks, the exploration of such vulnerabilities in the context of DD remains limited. Only a few studies have evaluated the security risks associated with DD~\cite{liu2023backdoor,chung2024rethinking}. This highlights the urgent need for a deeper investigation into the potential threats and vulnerabilities specific to DD. 

%