\section{Related Works}
\noindent \textbf{Dataset Distillation.} DD aims to condense the richness of large-scale datasets into compact small datasets that effectively preserve training performance____.
Coreset selection____ is an early-stage research in data-efficient learning. Most methods rely on heuristics to select representatives. 
Unlike this paradigm, DD____ aims to learn how to synthesize a tiny dataset that trains models to perform comparably to those trained on the complete dataset. Wang~\textit{et al.}____ first proposed a bi-level meta-learning approach, which optimizes a synthetic dataset so that neural networks trained on it achieve the lowest loss on the raw dataset.
% , and thus the performance of models trained by synthetic and real datasets is matched.

Following this research, many researchers have focused on reducing the computational cost of the inner loop by introducing closed-form solutions, such as kernel ridge regression____. 
Zhao~\textit{et al.}____ proposed an approach that makes parameters trained on condensed data approximate the target parameters, formulating a gradient matching objective that simplifies the DD process from a parameter perspective. In____, the authors enhanced the process by incorporating Differentiable Siamese Augmentation~(DSA), which enables effective data augmentation on synthetic data and results in the distillation of more informative images. Additionally, Du~\textit{et al.}____ proposed a sequential DD method to extract the high-level features learned by the DNN in later epochs. 
By combining meta-learning and parameter matching, Cazenavette~\textit{et al.}____ proposed Matching Training Trajectories~(MTT) and achieved satisfactory performance. Besides, a recent work, TESLA____, reduced GPU memory consumption and can be viewed as a memory-efficient version of MTT. 
% Instead of matching gradients or parameters, recent works proposed to condense datasets by matching distributions____.

\noindent \textbf{Backdoor Attack.} Backdoor attacks introduce malicious behavior into the model without degrading its performance on the original task by poisoning the dataset. Gu~\textit{et al.}____ introduced the backdoor threat in DL with BadNets, which injects visible triggers into randomly selected training samples and mislabels them as a specified target class. To enhance attack stealthiness, Chen~\textit{et al.}____ proposed a blended strategy to make poisoned images indistinguishable from benign ones, improving their ability to evade human inspection. Furthermore, subsequent works explored stealthier attacks: WaNet____ used image warping; ISSBA____ employed deep steganography; Feng~\textit{et al.}____ and Wang~\textit{et al.}____ embedded triggers in the frequency domain; Yang~\textit{et al.}____ injected the trigger into the measurement domain; and Color Backdoor____ utilized uniform color space shifts as triggers. 

Although existing works have demonstrated the vulnerability of deep networks to backdoor attacks, the exploration of such vulnerabilities in the context of DD remains limited. Only a few studies have evaluated the security risks associated with DD____. This highlights the urgent need for a deeper investigation into the potential threats and vulnerabilities specific to DD. 

%