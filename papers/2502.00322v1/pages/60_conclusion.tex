\section{Conclusion}

We propose DQFS and design \model, which controls individual document speakers, to write well-covered, balanced summaries.
\model has potential utility past DQFS, such as in code-switching~\cite{gao2019code}, multi-modal generation~\cite{dai2022enabling}, and full-stack design~\cite{si2024design2code}, where balancing diverse inputs (languages, modalities) is crucial.
We also show that content planning with outlines largely enhances DQFS quality.
Future work can explore the direct application of our outline to tasks with opposing stances, like pro/con generation~\cite{kumar2023apcs}, document contradiction detection~\cite{deusser2023contradiction}, or key point analysis~\cite{kunneman2018aspect}.
While \model excels in DQFS, romising extensions to our task would still challenge our model, such as document misinformation~\cite{sung2023not} or aligning summaries with and against expressed or observed \textit{user} perspectives~\cite{balepur2024smart}.
These insights, along with our new DebateQFS dataset and citation metrics, will be key toward~building models that can handle diverse, opposing perspectives.


% Along with DQFS and \model, we release new datasets and metrics.
% DebateQFS will lead to models that can synthesize new arguments using general document content, going past retrieving existing arguments in expert-labeled evidence corpora.
% Further, our proposed citation metrics show that citations can help evaluate text beyond factuality, such as coverage and balance.
% In all, we~provide many tools to advance generation work in balancing opposing document perspectives, offering novel tasks, methods, datasets, metrics, and~insights.

%Future works could study other downstream tasks to use with $\mathcal{O}$, such as pro-con analysis~\cite{kumar2023apcs}, key point summarization~\cite{kunneman2018aspect, cattan2023key}, or document contradiction detection~\cite{deusser2023contradiction, xu2024sparsecl}.