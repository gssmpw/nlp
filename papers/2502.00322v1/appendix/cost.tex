\begin{table*}[]
\small
\centering
\setlength{\tabcolsep}{3.5pt}
\renewcommand{\arraystretch}{0.8}
\begin{tabular}{@{}cl|ccccc@{}}
\toprule
\textbf{\# Topics} & \textbf{Model} & \multicolumn{1}{l}{\textbf{\# Input Tokens}} & \multicolumn{1}{l}{\textbf{\# Output Tokens}} & \multicolumn{1}{l}{\textbf{\# LLM Calls}} & \multicolumn{1}{l}{\textbf{Cost (GPT-4)}} & \multicolumn{1}{l}{\textbf{Time (seconds)}} \\ \midrule
\multirow{3}{*}{2} & \modelTopic & 21383.08 & 3412.02 & 25.45 & 0.32 & 117.60 \\
 & Hierarchical & 31130.02 & 2536.66 & 13.15 & 0.39 & 83.13 \\
 & Incremental-\textit{Topic} & 59010.66 & 6115.04 & 15.15 & 0.77 & 214.39 \\ \midrule
\multirow{3}{*}{3} & \modelTopic & 30208.20 & 5040.38 & 37.38 & 0.45 & 149.54 \\
 & Hierarchical & 31144.83 & 2649.78 & 13.15 & 0.39 & 68.60 \\
 & Incremental-\textit{Topic} & 61344.07 & 8442.54 & 16.15 & 0.87 & 197.33 \\ \midrule
\multirow{3}{*}{4} & \modelTopic & 38286.40 & 6440.23 & 47.91 & 0.58 & 163.91 \\
 & Hierarchical & 31144.31 & 2740.31 & 13.15 & 0.39 & 88.75 \\
 & Incremental-\textit{Topic} & 62877.46 & 9966.45 & 17.15 & 0.93 & 312.55 \\ \midrule
\multirow{3}{*}{5} & \modelTopic & 47008.59 & 7918.92 & 58.94 & 0.71 & 186.32 \\
 & Hierarchical & 31160.88 & 2850.24 & 13.15 & 0.40 & 61.70 \\
 & Incremental-\textit{Topic} & 64893.95 & 11965.84 & 18.15 & 1.01 & 262.07 \\ \bottomrule
\end{tabular}
\caption{\label{appendix:table:cost_cqa} Number of LLM input/output tokens, LLM calls, GPT-4 Cost (USD), and Time (seconds) needed to run inference on a single DFQS example on ConflictingQA with the top-3 models. We report 5 runs and 20 examples.}
\end{table*}

\begin{table*}[]
\small
\centering
\setlength{\tabcolsep}{3.5pt}
\renewcommand{\arraystretch}{0.8}
\begin{tabular}{@{}cl|ccccc@{}}
\toprule
\multicolumn{1}{l}{\textbf{Dataset}} & \textbf{Model} & \multicolumn{1}{l}{\textbf{\# Input Tokens}} & \multicolumn{1}{l}{\textbf{\# Output Tokens}} & \multicolumn{1}{l}{\textbf{\# LLM Calls}} & \multicolumn{1}{l}{\textbf{Cost (GPT-4)}} & \multicolumn{1}{l}{\textbf{Time (seconds)}} \\ \midrule
\multirow{3}{*}{2} & \modelTopic & 17183.75 & 2722.40 & 20.30 & 0.25 & 94.81 \\
 & Hierarchical & 19181.59 & 2040.39 & 10.25 & 0.25 & 63.68 \\
 & Incremental-\textit{Topic} & 41656.87 & 5062.44 & 12.25 & 0.57 & 182.19 \\ 
 \midrule
\multirow{3}{*}{3} & \modelTopic & 24801.22 & 4136.12 & 30.40 & 0.37 & 126.83 \\
 & Hierarchical & 19182.58 & 2141.91 & 10.25 & 0.26 & 53.32 \\
 & Incremental-\textit{Topic} & 43119.51 & 6532.92 & 13.25 & 0.63 & 152.44 \\ \midrule
\multirow{3}{*}{4} & \modelTopic & 30677.67 & 5037.31 & 38.00 & 0.46 & 120.64 \\
 & Hierarchical & 19203.30 & 2253.17 & 10.25 & 0.26 & 73.35 \\
 & Incremental-\textit{Topic} & 43922.02 & 7327.88 & 14.25 & 0.66 & 241.54 \\ \midrule
\multirow{3}{*}{5} & \modelTopic & 36988.41 & 6049.93 & 46.09 & 0.55 & 139.71 \\
 & Hierarchical & 19211.74 & 2356.01 & 10.25 & 0.26 & 49.41 \\
 & Incremental-\textit{Topic} & 45113.12 & 8504.59 & 15.25 & 0.71 & 186.40 \\ \bottomrule
\end{tabular}
\caption{\label{appendix:table:cost_debate} Number of LLM input/output tokens, LLM calls, GPT-4 Cost (USD), and Time (seconds) needed to run inference on a single DFQS example on DebateQFS with the top-3 models. We report 5 runs and 20 examples.}
\end{table*}

\begin{table*}[]
\small
\centering
\setlength{\tabcolsep}{3.5pt}
\renewcommand{\arraystretch}{0.8}
\begin{tabular}{@{}cl|ccccc@{}}
\toprule
\multicolumn{1}{l}{\textbf{\# Topics}} & \textbf{Model} & \multicolumn{1}{l}{\textbf{\# Input Tokens}} & \multicolumn{1}{l}{\textbf{\# Output Tokens}} & \multicolumn{1}{l}{\textbf{\# LLM Calls}} & \multicolumn{1}{l}{\textbf{Cost (GPT-4)}} & \multicolumn{1}{l}{\textbf{Time (seconds)}} \\ 
\midrule
\multirow{3}{*}{ConflictingQA} & \modelTopic & 47008.59 & 7918.92 & 58.94 & 0.71 & 186.32 \\
 & \modelTopic Pick All & 53733.70 & 9596.75 & 71.75 & 0.83 & 303.13 \\
 & Hierarchical-\emph{Topic} & 168160.85 & 7485.50 & 66.75 & 1.91 & 210.80 \\ \midrule
\multirow{3}{*}{DebateQFS} & \modelTopic & 36988.41 & 6049.93 & 46.09 & 0.55 & 139.71 \\
& \modelTopic Pick All & 43098.85 & 7612.45 & 57.25 & 0.66 & 242.35 \\
& Hierarchical-\emph{Topic} & 105237.25 & 5278.35 & 52.25 & 1.21 & 139.96 \\ \bottomrule
\end{tabular}
\caption{\label{appendix:table:cost_weird} Number of LLM input/output tokens, LLM calls, GPT-4 Cost (USD), and Time (seconds) needed to run inference on a single DFQS example on ConflictingQA and DebateQFS with \modelTopic, the version of \modelTopic with no Moderator, and the version of Hierarchical merging that runs on each topic paragraph ($m=5$). We report 5 runs and 20 examples.}
\end{table*}

