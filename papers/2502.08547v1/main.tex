\documentclass{article}
%%%% use packages
\usepackage[a4paper, top=1.1in, bottom=1.1in, left=1in, right=1in]{geometry}
\usepackage[utf8]{inputenc}
\usepackage[english]{babel}
\usepackage[T1]{fontenc}
\usepackage{rotating}
\usepackage{amsmath}
\usepackage{booktabs}
\usepackage{longtable}
\usepackage{subcaption}
\usepackage{multirow}
\usepackage{float}
\usepackage{makecell}
\usepackage{tikz}
\usepackage{lipsum}
\usepackage[semicolon, numbers,sort&compress]{natbib}
\usepackage{adjustbox}
\usepackage{amsfonts}
\usepackage{colortbl}
\usepackage{graphicx}
\usepackage{hyperref}
\newtheorem{theorem}{Theorem}
\usepackage{setspace}
\onehalfspacing
\usepackage{xcolor}
\usepackage[linesnumbered,ruled,vlined]{algorithm2e}
\usepackage{mathrsfs}
\usepackage{xr-hyper}




\def\red{\color{red}} 
\def\blue{\color{blue}} 
%%%% notations
\def\Csc{\mathcal{C}}
\def\Isc{\mathcal{I}}
\def\PPMI{\mathbb{PPMI}}
\def\Rscr{\mathscr{R}}
\def\Ubb{\mathbb{U}}
\def\suphalf{^{\scriptscriptstyle \half}}
\def\half{\frac{1}{2}}



\def\RR{\mathbb{R}}

\def\V{\mathbf{V}}
\def\X{\mathbf{X}}
\def\Y{\mathbf{Y}}
\def\Z{\mathbf{Z}}
\def\W{\mathbf{W}}
\def\U{\mathbf{U}}
\def\x{\mathbf{x}}
\def\y{\mathbf{y}}
\def\z{\mathbf{z}}
\def\bOmega{\mathbf{\Omega}}
\def\trans{^{\scriptscriptstyle \sf T}}

\definecolor{green}{RGB}{000,150,100}
\newcommand{\lcomm}[1]{{\footnotesize\bf\green \fbox{#1}}}
\def\green{\color{green}}
\def\gray{\color{gray}}

\newcommand{\tcomm}[1]{\fbox{\bf\scriptsize\color{blue} #1}}

\newcommand\mycommfont[1]{\footnotesize\ttfamily\textcolor{blue}{#1}}
\SetCommentSty{mycommfont}
\SetKwInput{KwInput}{Input}                % Set the Input
\SetKwInput{KwOutput}{Output}              % set the Output

%%%%% title

\begin{document}
\title{Representation Learning to Advance Multi-institutional Studies with Electronic Health Record Data}
\date{}

\author{Doudou Zhou$^{1}$\thanks{Equal contributions as first authors}, Han Tong$^{2*}$, Linshanshan Wang$^{3*}$, Suqi Liu$^{4*}$, Xin Xiong$^3$,\\
Ziming Gan$^5$, Romain Griffier$^{6,7}$,  Boris Hejblum$^{6,8}$, Yun-Chung Liu$^9$, \\
Chuan Hong$^9$, Clara-Lea Bonzel$^{3,4}$, Tianrun Cai$^{10,11}$, 
Kevin Pan$^{12}$, Yuk-Lam Ho$^{10}$, \\
Lauren Costa$^{10}$, Vidul A. Panickan$^{4,10}$, J. Michael Gaziano$^{4,10,11}$,  Kenneth Mandl$^{13}$, \\
Vianney Jouhet$^{6,7}$, Rodolphe Thiebaut$^{6,7,8}$, Zongqi Xia$^{14}$, Kelly Cho$^{4,10,11}$,
\\ Katherine Liao$^{10,11}$\thanks{Email:kliao@bwh.harvard.edu},  Tianxi Cai$^{3,4,10}$\thanks{Email:tcai@hsph.harvard.edu} \\
\textsuperscript{1} Department of Statistics and Data Science, National University of Singapore, SG \\
\textsuperscript{2} Department of Statistics, Columbia University, NY, USA \\
\textsuperscript{3} Harvard T.H. Chan School of Public Health, MA, USA \\ 
\textsuperscript{4} Harvard Medical School, MA, USA \\
\textsuperscript{5} Department of Statistics, University of Chicago, Chicago, IL, USA  \\
\textsuperscript{6} Univ. Bordeaux, INSERM, Bordeaux Population Health Research Center, Bordeaux, France \\
\textsuperscript{7} CHU de Bordeaux, Service d’Information Médicale,  Bordeaux, France \\
\textsuperscript{8} Inria SISTM Team, Talence, France \\
\textsuperscript{9} 
Duke University, Durham, NC, USA \\
\textsuperscript{10} VA Boston Healthcare System, Boston, MA, USA\\
\textsuperscript{11} Brigham and Women's Hospital, Boston, MA, USA \\ 
\textsuperscript{12} 
Brown University,  Providence, RI, USA \\
\textsuperscript{13} Computational Health Informatics Program, Boston Children’s Hospital, Boston, MA, USA\\
\textsuperscript{14} Department of Neurology, University of Pittsburgh, Pittsburgh, PA, USA
}





\maketitle

\begin{abstract}
The adoption of EHRs has expanded opportunities to leverage data-driven algorithms in clinical care and research. A major bottleneck in effectively conducting multi-institutional EHR studies is the data heterogeneity across systems with numerous codes that either do not exist or represent different clinical concepts across institutions. The need for data privacy further limits the feasibility of including multi-institutional patient-level data required to study similarities and differences across patient subgroups. To address these challenges, we developed the GAME algorithm. Tested and validated across 7 institutions and 2 languages, GAME integrates data in several levels: (1) at the institutional level with knowledge graphs to establish relationships between codes and existing knowledge sources, providing the medical context for standard codes and their relationship to each other; (2) between institutions, leveraging language models to determine the relationships between institution-specific codes with established standard codes; and (3) quantifying the strength of the relationships between codes using a graph attention network. Jointly trained embeddings are created using transfer and federated learning to preserve data privacy. In this study, we demonstrate the applicability of GAME in selecting relevant features as inputs for AI-driven algorithms in a range of conditions, e.g., heart failure, rheumatoid arthritis. We then highlight the application of GAME harmonized multi-institutional EHR data in a study of Alzheimer’s disease outcomes and suicide risk among patients with mental health disorders, without sharing patient-level data outside individual institutions. In summary, the GAME algorithm advances the feasibility of multi-institution EHR studies providing a method for code translation and harmonization at the scale with the adaptability needed for high-dimensional data-driven algorithms in clinical research and care. Moreover, we demonstrate that the valuable clinical information necessary for identifying and studying patient subgroups is retained in the GAME embeddings, offering an alternative to sharing patient-level data outside the institution for collaborative studies.
\end{abstract}

\noindent {\bf Keywords:} Electronic health records, graph attention networks, large language models, representation learning,  knowledge graph. 
 

\section{Introduction}

Electronic health record (EHR) data have become a major resource for clinical and translational studies using real-world data. With information on diagnoses, prescriptions, laboratory results, and detailed clinical information in progress notes on millions of patients, these data have supported the creation of robust phenotyping algorithms to establish patient cohorts for studies on risk factors, outcomes, and patient subgroup analyses \citep{bai2018ehr, Xiong2023.09.29.23296239,liao2015development}. Additionally, these data have facilitated the creation of clinical decision support tools 
\citep{federico2015gnaeus} and epidemiological surveillance \citep{ferte2022benefit}. A promise of EHR-based studies is the potential for multicenter studies, which can include more diverse populations, produce generalizable results, and offer insights into differential associations within subpopulations \citep{cai2022consensus}.  However, a major challenge in carrying out multi-center EHR studies at scale lies in the heterogeniety of data across EHR and healthcare systems; important codes in one system may not exist in another, highlighting a large unmet need in an approach that can harmonize the data for integrative analyses. 


Standardized coding systems such as the International Classification of Diseases (ICD)  \citep{world1988international,bramer1988international} and the Logical Observation Identifiers Names and Codes (LOINC) for laboratory tests \citep{mcdonald2003loinc} provide a foundation for a common dataset across systems. However, healthcare systems adopt some, but not all of these ontologies; ICD is universally used in the United States, but LOINC codes are not.  Thus, a laboratory test used for a study may be identified with a LOINC code at one institution but may only be identified using an institution-specific code at another site, referred to in this study as a local code. In recent years, artificial intelligence (AI) has enabled the creation of robust algorithms trained on hundreds to thousands of features.  This increasing complexity underscores an unmet need for automated approaches that can accurately translate local codes to standardized representation at scale. Manually mapping codes from one institution to another is no longer a feasible option.


Another major challenge for multi-institutional collaborations for EHR-based research is the need to maintain privacy. The traditional paradigm for multi-institutional collaborations in biomedical research requires the collaborating institutions to share patient-level data to a centralized location to train a model. However, this \textit{collective data sharing} approach is difficult to scale when a large number of institutions are involved due to the time and resources needed in obtaining permission to share the data \citep{chen2016privacy}. Federated Learning (FL) methods \citep{Federated_learning, dou_fed, molaei2024federated} were developed to train models without requiring patient-level data being shared. In FL, summary statistics or model parameters, known as local models, are shared with a trusted central aggregator. This approach requires that either the codes are the same, or for example that a local laboratory code unique to one institution can be mapped to a LOINC code representing the same laboratory test.  

Semantic embedding has emerged as a powerful approach for harmonizing EHR data across different institutions in an automated and privacy-preserving manner \citep{bengio2000neural, mikolov2013distributed,pennington2014glove}. By representing each EHR code as a numeric vector in a low-dimensional space, the embeddings can capture the similarity and relatedness of medical concepts,  facilitating the translation of institution-specific EHR codes between institutions. One such approach is the Knowledge Graph (KG) embedding \cite{wang2014knowledge,balavzevic2019tucker,yao2019kg,yuan2022coder,Yucong_disease}, which projects components of a KG, such as entities and their relations, into low-dimensional embedding vectors. KG embeddings are typically trained using structured knowledge bases such as the Unified Medical Language System (UMLS) \cite{UMLS}, which contains relational information between entity pairs. However, a key limitation of this approach is that EHR code pairs without an established relationship cannot be included in KG training. 

An alternative method leverages the co-occurrence patterns of medical codes observed in EHR data to generate the code embeddings  \cite{choi2016multi,kartchner2017code2vec,hong2021clinical,gan2023arch}. For instance, \cite{gan2023arch} utilized a positive pointwise mutual information (PPMI) matrix derived from medical code co-occurrence patterns in patient records and computed code embeddings using singular value decomposition (SVD). This PPMI-SVD approach has been demonstrated by \cite{levy2014neural} to be a variant of the word2vec algorithm \citep{mikolov2013distributed}.
Importantly, this approach is privacy-preserving, as the embeddings are trained on population-level summary EHR data rather than individual patient records. 

Despite the promising potential of existing approaches, several limitations hinder their broader applicability for EHR code translation. First, KG embeddings trained using textual data from existing biomedical knowledge sources such as UMLS do not adequately capture real-world disease patterns and clinical relationships present in the EHR data. As a result, these embeddings often underperform in key clinical tasks because they cannot capture the nuances of medical events occurring in real world healthcare settings \cite{gan2023arch}. For example, as shown in Section \ref{sec:result}, SapBERT \citep{liu-2021-sapbert} and CODER \citep{yuan2022coder} perform unsatisfactory in detecting clinically related code pairs, achieving AUCs of only $0.756$ and $0.664$, respectively.


Second, while EHR-derived embeddings based on co-occurrence patterns of medical codes offer a privacy-preserving alternative, their generalizability across multiple institutions is limited. These algorithms underperform in settings where different medical institutions have overlapping but non-identical EHR codes. Without incorporating additional information from code descriptions or external biomedical ontologies, the resulting embeddings lack the robustness required for accurate cross-institutional code mapping, particularly in institutions that have diverse coding practices \citep{joint_learning, MIKGI}.



To address these challenges, we developed an approach to co-train KG embeddings with multi-institutional EHR data, \textbf{G}raph \textbf{A}lignment for \textbf{M}ulti-institutional \textbf{E}HR Data (GAME). The GAME algorithm introduces a robust approach for identifying equivalent codes across institutions by leveraging comprehensive biomedical knowledge resources, i.e., UMLS, pretrained language models (PLMs), and EHR data, to train the model. Importantly, only summary-level EHR data are required, protecting patient privacy while facilitating the training of models across multiple institutions. GAME generates multi-institutional embeddings enabling code mapping across different institutions, allowing models trained at one institution to be easily transported and applied to others, regardless of coding systems, including local codes, and across languages. Lastly, to evaluate the effectiveness of GAME embeddings, we applied the GAME embeddings to patient stratification with FL for two conditions. These analyses were conducted using EHR data from six institutions in the United States and one in France. The framework is illustrated in Figure~\ref{fig:outline}. 



\begin{figure}[ht]
    \centering
    \includegraphics[width=0.99\textwidth]{fig/outline.pdf}
    \caption{Overview of GAME approach with (a) data source, extraction, processing, and algorithm, and (b) key steps in the validation of the approach.}
    \label{fig:outline}
\end{figure}

\def\Esc{\mathcal{E}}
\def\Ssc{\mathcal{S}}
\def\Rsc{\mathcal{R}}
\def\Lscr{\mathscr{L}}

\section{Methods}\label{sec:method}
The GAME algorithm is built upon the Graph Attention Network (GAT) \cite{GAT}, a variant of graph neural networks (GNNs) \cite{gori2005new}, which serves as its backbone. Its key novelty lies in the precise construction of hard negatives within the contrastive learning framework, optimizing representation learning and enhancing the integration of heterogeneous information from EHRs and existing knowledge bases. In this framework, EHR codes from multiple institutions are represented as nodes within the GAT, aiming to learn unified embeddings that integrate data from several sources. This section is divided into five parts. In Section~\ref{sec:data}, we first introduce the EHR data from seven institutions and detail the data preprocessing steps. Next, we describe the creation of initial embeddings using EHR data and PLMs in Section \ref{sec:initial embed}. We then outline the curation of KG edges used as labels for GAT training, in Section~\ref{sec:kg}, and provide a detailed workflow of the GAME algorithm in Section~\ref{sec:GAME}. Finally, we highlight the validation of the GAME embeddings through a variety of tasks, including detecting known relations, code alignment, feature selection, and patient stratification.


\subsection{EHR data sources and preprocessing}
\label{sec:data}

\begin{figure}[ht]
    \centering
    \includegraphics[width=0.99\textwidth]{fig/input.pdf}
    \caption{The data processing procedure of the GAME algorithm.}
    \label{fig:input_plot}
\end{figure}

We utilized EHR data from seven hospital systems: Boston Children’s Hospital (BCH), Bordeaux University Hospital (BDX), Duke Clinical Research Datamart (Duke), Mass General Brigham (MGB), Medical Information Mart for Intensive Care IV (MIMIC)  \citep{mimiciV}, University of Pittsburgh Medical Center (UPMC), and Veteran Affairs healthcare (VA). In this study, BCH contains $251$K patients from $2009$ to $2022$; BDX EHR data covers $2.5$ million patients from $2010$ to $2023$; Duke includes data on over $6$ million patients from $2014$ to $2023$; MGB EHR data contains $2.5$ million patients from $1998$ to $2018$; and the VA Corporate Data Warehouse (CDW) aggregates data from $150$ VA facilities into a single data warehouse, with records from $1999$ to $2019$ covering $12.6$ million patients. BCH, BDX, Duke, and VA include inpatient and outpatient codified data from patients with at least one visit, while MGB includes only patients with at least three visits spanning more than $30$ days. The MIMIC dataset contains data on over $65$K ICU admissions and over $200$K emergency department admissions at Beth Israel Deaconess Medical Center in Boston, Massachusetts, spanning $2008$ to $2019$. The UPMC EHR data includes $95$K patients from $2004$ to $2022$, focusing on individuals with at least one occurrence of ICD codes related to Alzheimer’s disease and dementia  or multiple sclerosis. 


We map ICD codes codes to PheCodes using the PheWAS catalog\footnote{\url{https://phewascatalog.org/phecodes}}. Diagnostic codes that cannot be mapped to PheCodes are retained as individual codes. All CPT, HCPCS, and ICD procedure codes are grouped into Clinical Classification Software (CCS) categories using the CCS mapping\footnote{\url{https://www.hcup-us.ahrq.gov/toolssoftware/ccs_svcsproc/ccssvcproc.jsp}}. The BDX uses the Classification Commune des Actes Médicaux (CCAM) \cite{bousquet2010evaluation}, totaling $5246$ distinct codes, for procedures. 
For laboratory tests, all laboratory codes from MGB and BCH are mapped to LOINC, whereas the laboratory codes from VA, UPMC, Duke, MIMIC-IV, and BDX largely comprise local codes. Similarly, for medication codes, we group them into ingredient level RxNorm codes whenever possible and retain local medication codes, mostly from UPMC and BDX, as local codes. In this study, we refer to PheCode, CCS, LOINC, and RxNorm as standard codes, while other codes that occur in local institutions are referred to as local codes. The goal of the algorithm is to accurately map local codes to the appropriate
standard code (Figure~\ref{fig:map-codes-gpt4}).

\def\Vsc{\mathcal{V}}

When constructing the PPMI matrix, co-occurrences fewer than 10 times are set to 0, and any code that co-occurs with other codes fewer than 10 times is removed to reduce noise from rare codes. Since laboratory tests are frequently analyzed at the first level of LOINC PART (LP) codes—parent codes representing groups of individual LOINC codes—we further aim to create embeddings for these LP codes. Including LP codes, we have 5,745 codes at BCH, 26,632 codes at BDX, 3,125 codes at Duke, 6,969 codes at MGB, 4,341 codes at MIMIC, 17,271 codes at UPMC, and 6,660 codes at VA. In total, we obtained 70,743 codes, of which \( N = 50,738 \) were unique. Our goal is to create unified embeddings for these \( N \) unique EHR codes, denoted by \(\mathcal{V}\). A detailed summary of the codes used is provided in Table~\ref{stat}.

\begin{table}
\footnotesize
    \centering
    \resizebox{\textwidth}{!}{
 \begin{tabular}{|ccc|cccccc|} \hline 
 \multirow{2}{*}{ \textbf{Institution}} & \multirow{2}{*}{ \textbf{Location}} & \multirow{2}{*}{ \textbf{Patients}} & \multicolumn{6}{c|}{\textbf{Unique codes}} \\
 & & & \textbf{PheCode} &  \textbf{CCS} &  \textbf{LOINC} & \textbf{RxNorm} & \textbf{Non-Standard Code} & \textbf{Total} \\ \hline 
 BCH  & {\scriptsize Northeast US} & $251$K  & 1405  &  199  & 3024 & 1117 & 0 & 5745 \\ 
BDX & {\scriptsize France}  &  $2.5$M &  1656 &  0&   2935 & 1103  &  20938 & 26632 \\ 
Duke & {\scriptsize Southeast US} & $6.0$M & 1439 &  0 &   554 & 278     & 854  & 3125 \\ 
MGB & {\scriptsize Northeast US}  & $2.5$M & 1772  & 243 & 3719 & 1235 & 0    & 6969 \\ 
MIMIC & {\scriptsize Northeast US} & $265$K & 637 &  129 & 0  & 959    & 2616 & 4341\\ 
UPMC & {\scriptsize Northeast US} & $95$K & 1841 & 245 & 5127 & 1987  & 8071 & 17271\\  
VA   & {\scriptsize US} & $12.6$M & 1776 & 224 & 730 & 1469   & 2461 & 6660 \\ \hline
 Total & - &  24.2M & 1869 & 248 & 9410 & 4271 & 34940 & 50738\\ \hline 
\end{tabular} }
    \caption{ Types of EHR codes studied across the $7$ institutions. BCH $=$ Boston Children’s Hospital, BDX $=$  Bordeaux University Hospital, Duke $=$ Duke Clinical Research Datamart, MGB $=$ Mass General Brigham, MIMIC $=$ Medical Information Mart for Intensive Care IV, UPMC $=$ University of Pittsburgh Medical Center, and VA $=$ Veteran Affairs healthcare system. }
    \label{stat}
\end{table}




\subsection{Generating multi-source initial embeddings}
\label{sec:initial embed} 


This section outlines the generation of two sets of initial embeddings for the $N$ unique EHR codes: institutional PPMI-SVD embeddings and textual description embeddings, essential for capturing clinical and semantic information of medical codes. Figure~\ref{fig:input_plot} intuitively illustrates the process of generating the initial embeddings.


\subsubsection{Institution-specific PPMI-SVD embeddings from co-occurrence patterns}
\label{sec:PPMI emb}
We construct a co-occurrence matrix to derive PPMI-SVD embeddings for each institution to capture the interactions between EHR codes based on their co-occurrence within patient records, following the methodology described in \cite{beam2018clinical} and \cite{hong2021clinical}. For each institution $m \in \{1, \ldots, M\}$, the matrix $\Csc_m = \big[\Csc_m(i,j)\big]$ records the frequency of co-occurrences between the $i$-th and $j$-th codes within $30$-day windows. We generate PPMI-SVD embeddings for all codes in the $m$th institution by applying SVD to the PPMI. To create initial embeddings for LP codes, we initialize the embedding of each LP code as a weighted average of the embeddings of their associated child LOINC codes. Detailed steps for generating the PPMI-SVD embeddings for both the EHR base codes and LP codes in the $m$th institution are provided in Supplementary~\ref{supp:ppmi}. The resulting $d$-dimensional PPMI-SVD embeddings are denoted by $\V_{m}$. For ease of implementation, we transform $\V_m$ into a matrix $N\times d$ to represent the embeddings of the $N$ unique EHR codes throughout the $M$ institution by padding with $0$ for the codes that do not appear in the $m$th institution. 



\subsubsection{Embedding textual description using pre-trained language models} 
\label{sec:predesc}

Pre-trained language models (PLMs) have proven to be highly effective in identifying biomedical relationships and generating high-quality semantic embeddings \cite{lee2020biobert, shin2020biomegatron, gu2021pubbert,liu-2021-sapbert,yuan2022coder,chen2024bge}. 
We used SapBERT embeddings \cite{liu-2021-sapbert}, a PLM fine-tuned on UMLS synonymous relationships, to extract semantic information from the textual descriptions of EHR codes. However, the effectiveness of these embeddings depends significantly on the quality and specificity of the underlying descriptions. Many local codes, unfortunately, have abbreviated or vague descriptions. For example, the VA local lab code 1000023750 is described as merely ``TIBC,'' whereas its more detailed and informative description is ``Iron binding capacity [Mass/volume] in Serum or Plasma.'' To address this limitation, we employ GPT-4 to generate more detailed and informative descriptions for local codes. We first expand laboratory test acronyms into full names using resources such as the Laboratory Alliance's list of test abbreviations.\footnote{\href{https://www.laboratoryalliance.com/healthcare-providers/laboratory-services/test-abbreviations/}{https://www.laboratoryalliance.com/healthcare-providers/laboratory-services/test-abbreviations/}} Next, we prompt GPT-4 to produce comprehensive descriptions for the local codes. For French descriptions from BDX, we first use GPT-4 to translate the text into English, ensuring compatibility with SapBERT. Based on these GPT-expanded descriptions, we create SapBERT embeddings for all codes in $\Vsc$, denoted by $\X$.


While SapBERT embeddings are used as input to the GAME algorithm, we also generate other PLM embeddings, including BioBERT \citep{lee2020biobert}, PubmedBERT \citep{gu2021pubbert}, CODER \cite{yuan2022coder}, BGE \cite{chen2024bge}, and OpenAI text-embedding-3-small (OpenAI)\footnote{\url{https://platform.openai.com/docs/guides/embeddings/embedding-models}}. These embeddings help identify candidate code pairs for GPT-4, which is then used to generate similarity labels used during the contrastive learning step of GAME training, as detailed in Section~\ref{sec:GPT}.
 

\subsection{Curation of the adjacency matrix from existing knowledge databases and large-language models}
\label{sec:kg}

In this section, we detail the construction of a comprehensive adjacency matrix from multiple knowledge sources, as shown in Figure~\ref{fig:input_plot}, which serves as input to the GAT model in the GAME algorithm. The matrix integrates edges from three primary sources: (1) hierarchical code structures, including PheCode, LOINC, RxNorm, and CCAM; (2) relationships provided by UMLS; and (3) additional edges generated using GPT-4. We categorize relation pairs into two groups: similar pairs and related pairs. The following subsections detail the process of constructing edges between different EHR codes. A summary of the number and types of edges is provided in Table~\ref{edge_count} in Supplementary~\ref{sec:S1}. The final set of edges, representing the curated knowledge graph, is denoted as $\mathcal{E}$.

\subsubsection{Hierarchical information from common ontologies}
 \label{sec:hie}

We derive edges from the hierarchical structures of PheCode, RxNorm, LOINC, and CCAM to capture relationships between similar codes. In PheCode, more digits indicate greater specificity (e.g., PheCode:296 for mood disorders is the parent of PheCode:296.1 for bipolar disorder and PheCode:296.2 for depression, with PheCode:296.22 for major depressive disorder as a further refinement). We connect PheCodes sharing the same integer. In LOINC, edges link codes to their parent LP codes and between codes with the same LP parent. For RxNorm, where all codes we use are leaf codes, we create edges between those with common parents. For CCAM, codes sharing the first four characters (e.g., ``GLLD015'' and ``GLLD008'') are connected.

\subsubsection{UMLS} 
\label{sec:UMLS}

UMLS includes a broad range of annotations, capturing similarity and relatedness, on medical relationships between entity pairs. For similarity, in addition to the hierarchical relationships discussed in Section~\ref{sec:hie}, UMLS includes non-hierarchical relationships which do not follow a strict parent-descendant structure. For relatedness, we consider relationships like ``associated with,'' ``may treat,'' and ``co-occurs with,'' as detailed in Table~\ref{num_table} in Supplementary~\ref{sec:S1}. However, since the UMLS concepts are mostly encoded as CUIs, their relationships cannot be directly translated to relationships for EHR codes. We map CUIs to EHR codes using both existing mappings (RxNorm, CCS, LOINC to CUIs)\footnote{\url{https://bioportal.bioontology.org/ontologies}} and GPT-4 (PheCode to CUIs). Specifically, for PheCode to CUIs, we use SapBERT to choose the most similar PheCode for each CUI whose semantic type is ``Disease or Syndrome.'' We then prompt GPT-4 to annotate whether the CUI can be mapped to the selected PheCode and choose the positive pairs as the CUI-PheCode mapping.


\subsubsection{Graph expansion derived using GPT-4}
\label{sec:GPT}

While ontology hierarchies and UMLS provide valuable insights into medical relationships, they are sparse and insufficient for diverse downstream tasks. First, they lack connections between EHR codes from different institutions, such as relationships involving local codes. Second, they indicate whether two codes are related but do not quantify the closeness of these relationships, limiting their precision. To address these gaps, we leverage GPT-4 in a denoising process to curate edges, for code mapping and identifying related codes, as additional training labels.

\begin{figure}[!ht]
    \centering
    \includegraphics[width=1\textwidth]{7inst_result/pic_3/code_map.pdf} 
    \caption{Mapping local codes to standard codes using GPT-4.}
    \label{fig:map-codes-gpt4}
\end{figure}

\paragraph{GPT-4 guided mapping pairs.} 
To assist in the training of embeddings for local codes, we generate edges to map these codes to common ontologies. For each local code, we calculate its cosine similarity with standardized codes using different PLM embeddings (SapBERT, CODER, BGE, and OpenAI), as shown in Figure~\ref{fig:map-codes-gpt4}. For example, we map local VA lab codes to LOINC, and local BDX procedure codes to CCS. For each local code, we identify the top $20$ standardized codes with the highest cosine similarity for each embedding method, selecting their union as potential mapping candidates. GPT-4 is then used to classify these candidate pairs as correct and incorrect mappings. These GPT-4-labeled correct and incorrect mappings will be used as training data in the contrastive learning step. These ``hard-negative''  pairs highlight cases where existing embeddings struggle to differentiate codes, making further training in the GAME algorithm necessary to refine their representations. 

\paragraph{GPT-4 confirmed relevance pairs.} A key advantage of PPMI-SVD embeddings from EHR data is their ability to capture positive and negative pair information. We further leverage GPT-4 to create related edges and ``hard-negative'' related pairs. To do this, we first calculate the cosine similarity for each pair of codes using the PPMI-SVD embedding $\V_m$ from each of the $M$ institutions. For each type of code combination (e.g. RxNorm-PheCode, LOINC-LOINC), we identify the top $0.1\%$ of pairs with the highest cosine similarity across any $\V_m$ and take their union. Among these selected pairs, we use GPT-4 to label whether they are clinically related. This process yields $130,801$ positively related pairs and $467,580$ negative pairs, as summarized in Table~\ref{edge_count} in Supplementary~\ref{sec:S1}. 


\subsection{The GAME algorithm}
\label{sec:GAME}


The training of the GAME algorithm comprises two key steps: (1) learning initial embeddings by aligning $M$ sets of PPMI-SVD embeddings into a shared representation space, enhanced with knowledge graph information, using GAT; and (2) sequentially learning similarity and relatedness embeddings by integrating these initial embeddings with PLM embeddings through GAT combined with contrastive learning. This process utilizes positive and hard-negative similarity and relatedness labels from multiple sources, as described above.


\begin{figure}[!htbp]
    \centering
    \includegraphics[width=\textwidth]{fig/alg.pdf}
    \caption{Overview of key steps in the GAME algorithm: (a) aligning embeddings into a shared representation space, (b) sequentially learning the similarity and relatedness with contrastive learning.}
    \label{fig:enter-label}
\end{figure}


\subsubsection{KG enhanced alignment of PPMI embeddings through GAT} 

We first train an initial set of harmonized embeddings for all EHR codes $\Vsc$ by aligning PPMI-SVD embeddings $\{\mathbf{V}_{m}\}_{m=1,...,M}$, incorporating curated knowledge graph $\mathcal{E}$ using GAT. As detailed in Algorithm~\ref{alg:align_sppmi} in Supplementary~\ref{alg}, a GAT is trained for each institution, taking 
$\mathbf{V}_{m}$ and $\mathcal{E}$ as inputs, and outputting embeddings  $\mathbf{Y}_m$:
\begin{align}
    \mathbf{Y}_m &=  \text{Linear}^{(m)}\left\{\textbf{GAT}^{(m)}\left(\V_m,\mathcal{E}\right)\right\},  \label{Align}
\end{align}
where the linear layer, $\text{Linear}^{(m)}$, further aligns the institutional embedding into a shared space. The GAT training is regularized with the alignment loss   
\begin{equation}
    \sum_{m_1, m_2 \in \{1,2,\ldots,M\}}\|\mathbf{Y}_{m_1}[\Isc_{m_1}, : ] -  \mathbf{Y}_{m_2}[\Isc_{m_1}, : ] \|_{\rm F}^2 ,
\label{align_loss}
\end{equation}
where $\Isc_m$ indexes codes appearing in the $m$th institution. This loss minimizes the difference between the embeddings of corresponding medical codes across institutions. The initial harmonized embeddings are obtained as
$\mathbf{Y} = \Rscr\left\{\sum_{m=1}^M\mathbf{Y}_m\right\}$, where $\Rscr(\mathbf{V})$ normalizes a given vector $\mathbf{V}$ into unit norm. 


\subsubsection{Sequential GAME embedding training with contrastive learning}
\label{train2}

We concatenate the PLM embeddings for code descriptions, 
$\X$, with the initial harmonized embeddings, 
$\Y$, to serve as input for sequentially training similarity and relatedness GAME embeddings. The goal is to generate a set of unified GAME embedding $\Z = [\Z_{\Ssc}, \Z_{\Rsc}]$ that integrates descriptive code information and EHR knowledge across institutions. Here, $\Z_{\Ssc}$ is specifically optimized to capture semantic similarity, while the full embedding $\Z$ is designed to support more complex downstream tasks. Since similarity represents a stronger and more direct relationship, low-dimensional embeddings are sufficient for its representation. In contrast, tasks involving relatedness demand richer representations to capture broader and more nuanced semantic relationships. To achieve this, training is performed using GAT with contrastive learning, leveraging the edge set $\Esc$. Various edge types contribute to different components of the contrastive loss, incorporating hard-negatives derived from ontology hierarchies as well as those generated by GPT-4.

We start with learning similarity embeddings using GAT, formulated as: 
\begin{equation}
    \Z_{\mathcal{S}} =  \Rscr \left\{
\text{Linear}_{\mathcal{S}}\left\{\text{GAT}_{\mathcal{S}}\left([\X,\Y],\mathcal{E} \right)\right\} 
    \right\}.
    \label{SIMI} 
\end{equation}
This is optimized with a similarity contrastive loss $\Lscr_{\Ssc}$, where positive and negative pairs are derived from UMLS similarity relations, ontology hierarchy, and GPT-enhanced edges. The inclusion of hard-negatives from the ontology and GPT further strengthens the training process.   
To train $\Z=[\Z_{\Ssc}, \Z_{\Rsc}]$, we fix $\Z_{\mathcal{S}}$ from the first step and learn $\Z_{\mathcal{R}}$ using another GAT:
\begin{equation}
    \Z_{\mathcal{R}} =  \Rscr\left\{
\text{Linear}_{\mathcal{R}}\left\{\textbf{GAT}_{\mathcal{R}}\left([\X,\Y], \mathcal{E} \right)\right\} 
    \right\}.
    \label{RELA} 
\end{equation}
This is optimized using a relatedness contrastive loss $\Lscr_{\Rsc}$ that integrates UMLS relatedness edges with GPT-enhanced edges derived from EHR PPMI, enabling robust learning of more nuanced and complex semantic relationships.

The contrastive losses $\Lscr_{\Ssc}$ and $\Lscr_{\Rsc}$ are constructed based on the Multi-Similarity (MS) loss \citep{wang2019multi}, which effectively handles tasks with multiple semantic relationships by dynamically balancing the pulling of positive pairs and pushing apart negative pairs. For the $i$th ancor code with a set of positive pairs $\mathcal{P}_i$ and a set of negative pairs $\mathcal{N}_i$, the MS loss is defined as follows:
\begin{equation} \mathcal{L}^{(i)} (\mathbf{Z}) = \frac{1}{\alpha} \log \left( 1 + \frac{1}{|\mathcal{P}_i|} \sum_{j \in \mathcal{P}_i} e^{-\alpha (\mathbf{Z}_i^\top \mathbf{Z}_j - \lambda)} \right) + \frac{1}{\beta}\log \left( 1 + \frac{1}{|\mathcal{N}_i|} \sum_{j \in \mathcal{N}_i} e^{\beta (\mathbf{Z}_i^\top \mathbf{Z}_j - \lambda)} \right). \label{M_S} \end{equation}
Here, $\alpha$, $\beta$, and $\lambda$ are hyperparameters that control the strength of the loss.  See Supplementary~\ref{loss} for details on the losses and Algorithm~\ref{alg:encoder} in Supplementary~\ref{alg} for details on the sequential GAME embedding training.


\subsection{Validation of the GAME Algorithm}\label{sec:val}

We performed a wide range of validation studies to evaluate the quality and clinical utility of GAME embeddings and compare them to benchmark embedding models. The validation tasks included: (1) detecting similar and related clinical relationships; (2) cross-institutional local code mapping; (3) feature selection;  (4) federated patient risk profiling using trained embeddings for (a) suicide-related behaviors; and (b) Alzheimer’s disease (AD) progression across multiple institutions. For benchmark models, we included the original PPMI-SVD embeddings from individual institutions, PubMedBert (PBERT), SAPBERT (SBERT), CODER, BGE (BAAI general embedding) ($768$ dimensions), OpenAI text-embedding-3-small ($1536$ dimensions). In addition, we trained a standard $768$-dimensional GAT embedding model (GAT-S) \cite{lee2020harmonized} as an additional benchmark, for which UMLS edges and binarized PPMI matrices serve as key input. See Supplementary~\ref{sec:naive} for details on GAT-S.


\subsubsection{Detecting similarity and relatedness between codes}

We first evaluated the quality of embeddings with respect to their ability in detecting similarity and relatedness between EHR codes. We split the known similarity and relatedness pairs from PheCode, RxNorm, LOINC, CCAM, and UMLS into training and validation, as detailed in Supplementary~\ref{supp:split}. For each relationship type, we computed cosine similarities between the embeddings of related pairs and randomly selected pairs, calculating the AUC to distinguish known pairs from random ones. Random pairs were chosen to match the semantic types of related pairs. For example, in analyzing ``may\_treat'' or ``may\_prevent'' relationships, we focused on disease-drug pairs. Relationships were also categorized by code types (e.g., ``PheCode-RxNorm'') to ensure clear summaries and stable AUC results.

\subsubsection{Translating and mapping codes across EHR systems}
\label{sec:code_map}

We evaluated the accuracy of mapping local codes to a common ontology using embeddings against gold standard labels assembled via human curation. We considered four sets of mappings: 1) local VA lab codes to the first level LP codes with $11,808$ curated mappings; 2) BDX CCAM procedure codes to CCS with $537$ curated mappings; 3) UPMC local procedure codes to CCS with $199$ curated mappings; and 4) UPMC local lab codes to LP codes with $1,814$ curated mappings. 

Out of these four sets of mappings, only the VA mappings were previously curated at scale with detailed background knowledge about the codes in the Observational Medical Outcomes Partnership (OMOP) \cite{OMOP}, which allows us to examine the top $k$ accuracy of the codes for each set of embeddings. The top $k$ accuracy is defined as the proportion of test cases in which the correct mapping for a given code appears among the top 
$k$ predictions generated by the embeddings. 

The remaining three sets were curated only for a subset of pairs sampled according to the embedding-based cosine similarities, as detailed in Supplementary~\ref{sec:code_map_supp}. Because of  potential ambiguity in the code descriptions for these three sets, the annotators assigned ``yes,'' confirming that the mapping is correct, ``possible,'' suggesting that the mapping is potentially correct but could be more precise, and ``no'' that the mapping was incorrect. We evaluated the Spearman's Rank Correlation between the embedding-assigned cosine similarities from each method and the annotated labels.


\subsubsection{Feature selection}
Feature selection is a critical step in many downstream predictive modeling tasks, as it directly impacts the quality and interpretability of the results. GAME embeddings aim to enhance this process by improving the identification and selection of relevant features. To evaluate the effectiveness of GAME embeddings, we focused on eight diseases: Heart Failure (HF), Depression, Rheumatoid Arthritis (RA), Alzheimer's Disease (AD), Type 1 Diabetes (T1D), Type 2 Diabetes (T2D), Crohn's Disease (CD), and Ulcerative Colitis (UC).

For each disease, we applied all aformentioned embedding methods to identify the top 100 features with the highest cosine similarity to the disease’s PheCode. Additionally, we included 100 randomly sampled features as negative controls. The union of these selected features formed the feature set for assessment against each disease. For each disease, we computed the cosine similarity between every feature in the feature set and the target PheCode across all embedding methods. We then evaluated the relevance of each feature to the target disease on a scale from 0 to 1, as determined by GPT-4. To compare embedding methods, we assessed the concordance between their cosine similarity scores and GPT-4 relevance ratings using the concordance index (C-index), treating GPT-4 assessments as a high-quality reference standard. A higher C-index indicates that an embedding method is more effective at ranking features based on their importance to the disease.




\subsubsection{Joint patient stratification across institutions}
\label{method:strat}
We further explored the potential of leveraging code embeddings for unsupervised clustering of patients' clinical profiles, aiming to stratify patients into subgroups with distinct disease progression patterns. Existing research on unsupervised clustering has primarily focused on single EHR systems utilizing aggregated EHR feature counts \cite{doshi2014comorbidity, li2015identification} or embedding-based approaches \cite{landi2020deep}. While extending clustering algorithms to multi-institutional EHR data presents a unique opportunity to enhance generalizability, this endeavor has traditionally faced significant challenges due to 
inter-institutional heterogeneity, particularly in coding systems. Harmonized embeddings, such as GAME, address inter-institutional gaps by enabling joint modeling of patient profiles across institutions, even with differences in coding systems. By training code embeddings in a shared representation space, GAME allows patient-level EHR data to be seamlessly integrated, supporting unified analysis. This consistent representation facilitates tasks such as identifying "patients like me" and enables robust patient clustering and stratification across diverse healthcare systems.


To illustrate the utility of GAME embeddings, we applied this approach to cluster patient profiles to predict: (1) progression of Alzheimer’s disease (AD) and (2) risk of suicide-related behaviors. For each condition, we defined a baseline period to extract relevant feature counts and computed patient embeddings as the weighted sum of feature embeddings. The weights were determined by multiplying the standard TF-IDF score by the cosine similarity between each feature embedding and the embedding of the target disease's PheCode (290.11 for AD and 297 for suicide), as detailed in Supplementary \ref{supp: patident embedding}. 
To ensure relevance, we included only features with cosine similarity exceeding the 99th percentile of random pair similarities. Patient embeddings were constructed independently for each institution. To enable joint clustering, we first reduced the embeddings' dimensions using a 3-dimensional t-SNE, approximated with variational autoencoder. We then applied federated k-means clustering. Clustering performance was validated by evaluating the association between cluster membership and the risk of developing a relevant clinical outcome. To study the importance of each EHR code in driving the difference between the clusters, we computed the odds ratio associated with the cluster membership, along with the p-values.


\paragraph{Alzheimer's disease} Although AD commonly presents as an amnestic syndrome, patients exhibit heterogeneous clinical profiles and experience highly variable rates of morbidity and mortality \cite{armstrong2022predictors, zheng2024predictors, abdelnour2022perspectives}. Stratification among AD patients at the time of diagnosis can enable better prognosis and disease management for patients \cite{Wangstrat}. To that end, we performed AD patient profiling across three institutions (UPMC, MGB, Duke) based on patients' EHR-derived data up to 2 years leading to the first AD diagnosis code (time$_0$) to predict future risk of nursing home admission. Admission to a nursing home, which indicates a loss of functional independence, is routinely documented in clinical practice and can be derived from the EHR. We defined nursing home admission as having at least one diagnosis code for admission to any residential institution (e.g., skilled nursing facility, assisted living facility, long-term care facility). We used the Cox proportional hazards model to investigate the association between cluster membership and future risk of nursing home admission,  using data from the 2 years leading up to time$_0$, adjusting for age, gender, and race/ethnicity.  


\paragraph{Suicide risk assessment} Mental health conditions such as depression, sleep disorders, anxiety disorders have been identified as risk factors that can increase the risk of suicide ideation or attempts \cite{favril2022risk, sutar2023suicide}. We clustered patients with a mental health disorder into subgroups based on their EHR-derived clinical profiles two years after the first diagnosis of mental health disorder (detailed in Supplementary \ref{tab:mental_phecode}) and hypothesized that such patient clustering based on GAME-generated patient representation may enable early stratification of future elevated risk of suicide among patients with mental disorders. We performed profiling of mental health disorders in patients across two institutions (MGB and Duke) based on EHR-derived data up to $2$ years from the time of first mental health diagnosis. As risk factors of suicidal behaviors are known to vary by age \cite{fazel2020suicide}, we stratified patients into five age groups ($\text{age} < 18$, $18 \le \text{age} \le 25$, $26 \le \text{age} \le 49$, $50\le \text{age} \le 65$  and $\text{age} > 65$ years) and performed patient profiling separately for each group. We used the Cox proportional hazards model to investigate the association between cluster membership and future risk of suicide ideation and suicide attempt, adjusting for age, gender, and race/ethnicity.



\section{Results}
\label{sec:result}

In this section,
we evaluate the performance of the GAME embedding on several downstream tasks.
First, we compare the capability of the model in recovering known similarity and
relatedness relationships
and in mapping the local lab codes from one site to LOINC and LP codes.
Later, we show the application of the embedding for feature selection in diverse conditions as well as patient stratification in Alzheimer's disease and mental health disorders.

\subsection{Detecting similarity and relatedness between clinical concepts}

The quality of the GAME embedding is evaluated by how well it is
in detecting the similar and related clinical concepts through their proximity.
Figure~\ref{P2_AUC} presents the AUCs for detecting similar and related clinical concept pairs against randomly sampled pairs.
The GAME embedding achieved AUCs of $0.913$ for similarity relationship and $0.925$ for relatedness relationship,
demonstrating strong performance for both tasks.
Detailed description of the data is available in Supplementary Table~\ref{R2}
with the number of validation pairs detailed in Supplementary Table~\ref{num_table}.
The AUCs for specific relationship types are also provided in Supplementary Table~\ref{R_sim}.

\begin{figure}[!ht]
\centering
\begin{minipage}{.499\textwidth}       \centering
\includegraphics[height=0.3\textheight]{7inst_result/pic_3/AUC_similar.pdf}
\end{minipage}%
\hfill
\begin{minipage}{.499\textwidth}
    \centering
    \includegraphics[height=0.3\textheight]{7inst_result/pic_3/AUC_related.pdf}
\end{minipage}
\caption{ 
Comparison of AUCs for detecting similarity (left) and relatedness (right) relationships
using embeddings from different methods or PLMs.
PPMI AVE stands for the average AUC by using the institutional PPMI embeddings.
}
\label{P2_AUC}
\end{figure}

We found that BGE (768 dimensions) and OpenAI (1,536 dimensions) embeddings performed well in detecting similarity pairs, while GAME (256 dimensions) achieved comparable performance with lower-dimensional representations.
In our validation, instead of directly using individual pairs,
we employ a more rigorous approach by splitting hierarchical similarity pairs by branches;
further details are provided in Supplementary~\ref{supp:split}.
Moreover, GAME significantly outperformed all other methods in detecting relatedness between EHR concepts, further highlighting its effectiveness.
This comparison underscores GAME's ability to achieve both high similarity AUC and exceptional relatedness AUC, setting it apart from other approaches.

To provide a strong baseline, we used institutional PPMI embeddings to compute the AUC by evaluating pairs within each institution and then calculated the average AUC across PPMI sources.
We found that the PPMI-SVD embeddings,
while mostly maintaining the within-institutional relationships,
failed to detect relationships across different institutions.
In contrast, GAME consistently excelled in detecting broader relationships, both within and across institutions.

Additionally, we observed that the standard GAT baseline embeddings did not perform as well as GAME in detecting similar and related pairs.
Even though the standard GAT baseline leverages some signals from the PPMI matrix, it fails to fully capture the intricate relationships between similar and related entities.

\subsection{Mapping codes between EHR systems} 

\begin{table}[H]
\centering
\setlength{\tabcolsep}{2pt}
\begin{tabular}{c|cccccccc}
\hline
\textbf{Measure} & PBERT& BBERT & SBERT &CODER & OpenAI  & BGE & GAT-S& GAME \\ \hline
\textbf{TOP1}     & 11.2\% &    20.8\%    & 59.7\%           & 55.6\%    & 62.2\%  & 61.9\% & 19.5\%  &\textbf{74.2\%}         \\ 
\textbf{TOP5}     & 18.3\% &    32.1\%    & 79.0\%           & 75.9\%    & 86.4\% & 79.0\%     & 33.8\%        & \textbf{88.0\%}        \\ 
\textbf{TOP10}     & 21.9\% &   36.7\%     & 82.9\%           & 85.0\%    & 89.6\%  & 84.3\%     & 39.3\%       & \textbf{90.7\%}         \\ 
\textbf{TOP20}      & 27.0\% &  42.5\%    & 85.7\%           & 89.7\%    & 92.6\%  & 89.7\%     & 47.5\%   & \textbf{92.7\%}        \\ \hline
\end{tabular}
\caption{Accuracy of mapping VA local lab codes to LOINC/LP codes using different methods.
TOP$k$ accuracy refers to the correct mapping of the standard code being present within the local code's top $k$ closest codes based on cosine similarities.}
\label{R1}
\end{table}

We further show the capability of the GAME embedding in recovering the correct mapping
from VA local lab codes to LOINC/LP codes.
The ground truth is created from manual mapping by clinical experts.
Table~\ref{R1} presents the accuracy of recovering the correct mapping using the embeddings from PLMs.
It is clear that the GAME embedding significantly outperformed all other methods by a wide margin.
GAME achieved a TOP1 accuracy of $74.2\%$, while no other approach exceeded $62.2\%$.
Additionally, GAME showed a high TOP10 accuracy of $90.7\%$.
Notably, these results were obtained using only the similarity component of the GAME embedding with a dimensionality of $256$, whereas the other methods relied on higher-dimensional embeddings, as described in Section~\ref{sec:val}. To further highlight the efficacy of GAME embedding, we also compared the accuracy of code mapping using lower-dimensional BGE and OpenAI embeddings, with the results shown in Supplementary Table~\ref{R1_GPT}.

\begin{figure}[!ht]
    \centering
    \includegraphics[width=1\linewidth]{7inst_result/pic_3/map_corr.pdf}
    \caption{Correlation between cosine similarities assigned by GAME and other PLMs compared to human mapping of local codes to standard codes at BDX and UPMC; BDX, CCAM to CCS; UPMC local lab codes to LOINC/LP, local PX code to CCS.}
    \label{fig:code_map_corr}
\end{figure}

Figure~\ref{fig:code_map_corr} shows the Spearman's Rank Correlation results between cosine similarities and human annotations for mapping UPMC Local PX and BDX CCAM to CCS, and for mapping UPMC Local Lab to LOINC/LP. In all three tasks, the cosine similarity of GAME embeddings aligns best with human annotations, achieving the highest Spearman's Rank Correlation. Besides GAME, OpenAI and BGE also perform well in parts of the tasks. The corresponding data table is shown in Supplementary Table~\ref{R2_code_map_2}.

Results for the PPMI-SVD, BioBERT, and PubMedBERT embeddings were not presented in Figure~\ref{fig:code_map_corr}, as their accuracy was close to zero. Additionally, the GAT-S embedding performed poorly compared to SapBERT, CODER, OpenAI, and BGE.


\subsection{Feature selection}
We summarize the key feature selection results in Figure~\ref{P3_}, with detailed results provided in Supplementary Table~\ref{R3_}. For clarity and conciseness, we report the average PPMI-SVD results across institutions (PPMI AVE) for each disease. Methods such as BioBERT, PubMedBERT, SapBERT, and CODER were excluded from the figure due to their poor performance in feature selection. The comparison focuses on methods that performed relatively well, including PPMI AVE, BGE, OpenAI, GAT-S, and GAME.

In Figure~\ref{P3_}, we observe that the C-index of GPT-4 assigned scores and cosine similarity of GAME embeddings are better than those of other methods. This demonstrates that the cosine similarity of the GAME embedding accurately reflects the relative importance of features to the target diseases. Additionally, we find that OpenAI embedding performs relatively well for diseases such as UC and RA, while GAME embeddings consistently perform well across all conditions. This demonstrates the superiority of GAME embeddings in feature selection for target diseases.

\begin{figure}[!htbp]%
    \centering
    \includegraphics[height=0.32\textheight]{7inst_result/pic_3/c_stat.pdf}
    \caption{The C-index between the cosine similarities of the candidate features and the GPT-4 scores for 8 target diseases. The axis labels represent the concordance values for different methods. Note: the plots are scaled based on the maximum and minimum C-index.}
    \label{P3_}
\end{figure}



\subsection{Joint patient stratification across multiple institutions}

\subsubsection{Alzheimer's disease}
The AD cohorts at UPMC, MGB and Duke consist of $16411$, $17770$ and $13438$ patients, respectively, with about $64.1\%$ to $65\%$ females and an average age of $79.7-81.2$ years at the time of the first AD diagnosis. The median follow-up time was 78 months at UPMC, 81 months at MGB and 36 months at Duke. Detailed demographic information is presented in Supplementary Table \ref{tab:AD_demo}. AD patient embeddings from all three institutions are visualized in Supplementary Figure \ref{fig:AD_tsne}. As expected, by representing EHR code in each institution with GAME code embeddings, patients from different institutions can be projected to the same embedding space, allowing for co-clustering of patient across multiple institutions (Figure \ref{fig:AD_tsne}). The federated $k$-means clustering of the GAME-based patient embeddings at the time of AD diganosis resulted in two subgroups: a fast-decline group (group 1) consisting of $34.3\%$ to $59.3\%$ of the patients across the institutions, and a slow-decline group (group 2) formed by the remaining patients.

Cluster membership was significantly associated with the future risk of nursing home admission, adjusting for age, gender and race/ethinicity (Figure \ref{fig:AD_HR}). The KM curve for the time to nursing home admission for each cluster in shown in Supplementary Figure \ref{fig:AD_KM}. The fast-decline group had a higher risk of nursing home admission compared to the slow decline group (median time to nursing home UPMC: Fast $37.1$ months, Slow $86.3$ months; MGB: Fast $43.9$ months, Slow $106.2$ months; Duke: Fast $94.0$ months, Slow not reached). 


\begin{figure}[htpb!]
    \centering
    \includegraphics[width=0.6\textwidth]{fig/AD/AD_survival_HR.jpeg}
    \caption{Comparison of hazard ratios (HR) between AD subgroups identified by GAME embedding with future nursing home admission, adjusted by age, sex, and self-reported race and ethnicity at UPMC, MGB and Duke; $95\%$ confidence intervals shown with HR point estimates.}
    \label{fig:AD_HR}
\end{figure}


Figure \ref{fig:AD_phewas} highlights the features driving the differences between the fast and slow decline groups in each institution.  The fast decline groups are characterized by higher intensity of mental disorders, including neurological disorders, mood disorders, depression, as well as more prescription of anti-psychotics such as quetiapine and olanzapine \cite{cipriani2011comparative, arvanitis1997multiple} across all institutions. This pattern further suggests that cognitive and psychiatric comorbidities may have compounded the presentation of Alzheimer's disease in the fast decline group \cite{ismail2022psychosis}, leading to more rapid cognitive deterioration and a more challenging clinical trajectory. Abnormal movement, essential hypertension, and malaise and fatigue were also found to be associated with fast decline group at all institutions. From UPMC and Duke, patients in the fast decline groups were more frequently prescribed AD-related medication that can improve memory and cognitive function (e.g., memantine, a type of N-Methyl-D-Aspartate (NMDA) receptor antagonists) \cite{liu2019role, tariot2004memantine} before diagnosis than patients in the slow decline groups. Prescription of AD-related medications may indicate that these patients experience cognitive and functional decline before definitive AD diagnosis. This may be attributable to the superimposition of comorbidity-related cognitive decline and AD-related cognitive decline, or may be indicative of diagnostic delay in the fast decline group. This pattern was not observed at MGB, potentially due to the difference in clinical or coding practice.

\subsubsection{Mental health disorders}
GAME effectively stratified mental health patients in each age group into two subgroups, each with distinct future risks of suicidal ideation and suicidal attempts. Demographic information of the mental health cohorts at MGB and Duke is detailed in Supplementary Tables \ref{tab:mental_demo_0-18} - \ref{tab:mental_demo_66-110} and patient embeddings from both institutions are visualized in Supplementary Figure \ref{fig:suicide_tsne}. Patients in the same age group from different institutions were projected to the same embedding space, which enabled cross-institutional co-clustering. 

The subgroups had differential risk of future suicidal ideation across all age groups without adjustment and after adjusting for age, gender and race/ethnicity (Figure \ref{fig:suicide_HR}). The risk of future suicidal attempt was also significantly associated with the cluster membership across all age groups, except for the oldest age group (age$>65$; Figure \ref{fig:suicide_HR}). The KM curve of time to suicidal ideation and time to suicidal attempt are shown in Supplementary Figure \ref{fig:KM_rpdr}. 

\begin{figure}[!htbp]
    \centering
    \includegraphics[width=13cm]{fig/mental/depression_survival_HR}
    \caption{Comparison of hazard ratios (HR) across mental health subgroups identified by GAME embeddings with future suicidal ideation or suicidal attempt, stratified by age at MGB and Duke; models were adjusted by age, sex, and self-report race and ethnicity; $95\%$ confidence intervals shown with HR point estimates.}
    \label{fig:suicide_HR}
\end{figure}


Key diagnostic and medication/procedure codes driving the difference between the clusters within each age group at MGB and Duke are shown in Supplementary Figures \ref{fig:suicide_phewas_phe} and \ref{fig:suicide_phewas_oth}. Differences were primarily characterized by mental health conditions, such as mood disorders, major depressive disorder, and generalized anxiety disorder. In older age groups, conditions such as insomnia, essential hypertension, GERD, and symptoms like joint/back pain, nausea, vomiting, and fatigue also emerged as important differentiators between clusters.

\section{Discussion}

In this paper, we introduce GAME, a unified approach for collaborative multi-institutional EHR studies. By leveraging knowledge graphs and LLMs, GAME enables cross-institutional EHR data harmonization by converting heterogeneous, institution-specific data into embeddings. GAME outperformed existing language model-based embeddings in matching institution-specific codes to standardized terminologies, detecting relatedness among EHR concepts, and selecting key features for clinical conditions. These advantages stem, in part, from GAME’s use of EHR-derived PPMI matrices, which capture real-world relationships between medical codes. 

Unlike traditional methods, GAME only requires sharing summary-level PPMI matrices rather than raw patient data, allowing institutions to collaboratively train embeddings while preserving privacy and minimizing regulatory barriers. We demonstrated GAME’s robustness across institutions with diverse demographics, geographic locations, and languages. Designed as a transparent, end-to-end solution, GAME is accessible to institutions with varying levels of resources, ensuring broad applicability in real-world healthcare settings.

GAME embeddings offer a scalable alternative to manual code mapping, automatically aligning institution-specific codes with standardized terminologies across institutions. This enhances the scope of data-driven algorithms for both clinical research and care while maintaining the ability to analyze similarities and differences across patient subgroups, a crucial aspect of personalized medicine. By integrating with federated learning methods, such as federated $k$-means clustering and predictive modeling, GAME facilitates collaborative learning essential for precision medicine. As demonstrated in clinical applications—including Alzheimer’s disease stratification and suicide risk prediction—GAME embeddings effectively enable federated learning to identify clinically meaningful patient subgroups across institutions.


GAME differs from existing approaches in its ability to harmonize structured EHR data at scale while remaining adaptable to evolving coding practices. Although existing tools have improved EHR data accessibility and reproducibility, they primarily rely on predefined mapping strategies or rule-based transformations \cite{heumos2024open}, which can be limiting across multiple institutions. Rule-based methods also struggle to accommodate new codes—for instance, in 2024 alone, 395 new billable ICD-10 codes were introduced. Furthermore, while most U.S. institutions currently use ICD-10, the World Health Organization (WHO) released ICD-11 in 2019\footnote{\url{https://www.wolterskluwer.com/en/expert-insights/2024-icd10-code-updates}}, signaling an inevitable transition.

GAME overcomes these challenges by leveraging EHR-specific KGs, dynamic medical knowledge sources such as UMLS, and state-of-the-art LLMs to continuously refine relationships between codes within and across EHR systems. By integrating both current knowledge repositories and real-world EHR data, GAME remains highly adaptable, allowing for efficient updates as coding systems evolve. This dynamic approach ensures greater flexibility and scalability compared to static rule-based methods, which struggle to keep pace with the constant introduction of new medical codes and terminology changes. GAME also builds on Fast Healthcare Interoperability Resources (FHIR)\footnote{\url{https://docs.smarthealthit.org/}}, a widely adopted standard for healthcare data exchange. FHIR provides guidelines for interoperability, ensuring a consistent format and baseline information for medical codes. GAME utilizes this structured data in combination with other contextual information to infer the overall meaning of codes and their relationships within and beyond an institution’s EHR system.


The medical code embeddings generated by GAME can also be utilized within individual institutions. Clinical care teams generate much of the EHR data, but they primarily interact through a graphical user interface (GUI) without directly seeing the underlying medical codes. When extracted from the database, these codes may lack clear meaning or context, making it difficult to interpret their relationships to standardized terminologies. By aligning these representations into a shared embedding space, GAME facilitates both institution-specific analyses and cross-institutional studies, enhancing interoperability and data-driven insights.


A limitation of GAME is its current focus on harmonizing structured concepts, leaving opportunities to further enrich embeddings with information from clinical notes to capture conditions and other concepts that may be poorly coded or missing from structured data. Future work includes improving GAME’s efficiency by enabling incremental updates without requiring full retraining, using zero- or few-shot learning strategies. Additionally, the PPMI-SVD approach offers a way to identify institutional data quality variations, such as sparsity or inconsistencies. Further research into data-adaptive methods to down-weight lower-quality data sources could enhance GAME’s robustness and overall performance. 


In summary, GAME is a scalable, adaptable, and transparent solution for harmonizing and interpreting EHR data across institutions, facilitating seamless collaboration in clinical research. It provides a comprehensive pipeline, transforming raw EHR data into generalizable embeddings that support federated learning and the identification of clinically meaningful patient subgroups. While many machine learning algorithms include an embedding layer for encoding EHR features, these embeddings are often domain- or dataset-dependent, limiting their transferability to new settings or unseen concepts. GAME addresses this limitation by generating broadly applicable embeddings that serve as prior knowledge in downstream machine learning models, enhancing their cross-institutional transportability and robustness. As AI-driven algorithms become increasingly integral to healthcare, GAME provides a foundational framework for the development, validation, and continuous refinement of EHR-based models. Whether for clinical decision-support tools or multi-institutional research, GAME ensures that EHR-driven algorithms remain robust, generalizable, and optimized for advancing clinical care.



\bibliographystyle{plainnat}
\bibliography{ref}

\appendix
\clearpage
\begin{center}
    {\LARGE Supplementary Material} \\[10pt]
    {\Large Representation Learning to Advance Multi-Institutional Studies with Electronic Health Record Data}
\end{center}
\bigskip



\renewcommand{\thefigure}{S\arabic{figure}} % Prefix figures with 'S'
\renewcommand{\thetable}{S\arabic{table}}   % Prefix tables with 'S'
\setcounter{figure}{0} % Reset figure counter
\setcounter{table}{0}  % Reset table counter
\renewcommand{\thesection}{S.\arabic{section}}
\section{Training and validation data base}
\subsection{Training and validation splitting}
\label{supp:split}
For non-hierarchical similarity pairs and related pairs, we randomly split them into training and validation sets using a 7:3 training-to-validation ratio. However, for similar hierarchical pairs, we split the training and validation sets based on their branches rather than individual pairs to ensure fairness, maintaining the same 7:3 ratio at the branch level. The reason for splitting similar hierarchical pairs in this manner is to prevent information leakage between the training and validation sets. For example, if the edges (PheCode 296.22, PheCode 296.2) and (PheCode 296.2, PheCode 296.1) are placed in the training set while the edge (PheCode 296.22, PheCode 296.1) is in the validation set, it would effectively leak information from the training phase. 

To avoid this, we first group PheCodes, RxNorm, LOINC, and CCAM codes into branches and then split these branches into the training and validation sets. For PheCodes, codes with the same integer part are treated as belonging to the same branch. Since all the RxNorm codes used are leaf codes, we designate RxNorm codes with the same ``grandparent'' as a branch. In the case of LOINC, we consider the parent codes of the highest-level LOINC codes in our dataset as the original ancestors, and all codes sharing the same ancestor are grouped into the same branch. For CCAM, we group codes that share the first four characters into the same branch.

By organizing codes into branches, we ensure that all edges derived from the same branch are placed in the same set—either training or validation—thereby preventing information leakage during model training. Returning to the previous example, PheCode 296.22, PheCode 296.2, and PheCode 296.1 are grouped into the same branch, and all their corresponding edges are included together in either the training or validation set.





\subsection{Training set edges and contrastive pairs}
\label{sec:S1}
\begin{table}[H]
\centering
\begin{tabular}{c | c c r}
\hline
\textbf{Category} & \textbf{Source} & \textbf{Detail} & \textbf{Count} \\
\hline
\multirow{13}{*}{Similar}  & \multirow{5}{*}{Similar Pairs from code hierarchy and UMLS} & LOINC Hierarchy & 20917 \\
 & & PheCode Hierarchy & 3131 \\
 & & RXNORM Hierarchy & 21841 \\
 & & CCAM Hierarchy & 23716 \\
 & & Non-Hierarchical & 4844 \\
\cline{2-4}
 & \multirow{10}{*}{GPT-4 Local-Code mapping} & VA local-lab positive & 12402 \\
 & & VA local-lab negative & 162657 \\
 & & UPMC local-lab positive & 8643 \\
 & & UPMC local-lab negative &  142816\\
 & & UPMC medication positive & 4578 \\
 & & UPMC medication positive &  129097\\
  & & UPMC procedure positive & 2430 \\
 & & UPMC procedure positive & 21029 \\
 & & BDX procedure positive &  8860 \\
 & & BDX procedure negative &  242208\\
\hline
\multirow{3}{*}{Related} & Related Pairs from UMLS & - & 6542 \\
\cline{2-4}
 & \multirow{2}{*}{GPT-4 PPMI feature selection} & Positive pairs & 130801 \\
 & & Negative pairs & 467580 \\
 \hline
\end{tabular}
\caption{Summary of edges and pairs in the training set: All relationships, except negative pairs, are used as edges; positive and negative pairs are utilized in the contrastive loss function.}
\label{edge_count}
\end{table}

\subsection{Validation set relation pairs}
\begin{table}[H]
\centering
\setlength{\tabcolsep}{2pt}
\resizebox{1\textwidth}{!}{%
\begin{tabular}{c|c|ccccccc|c}
\hline
\multirow{2}{*}{\textbf{Type}} & \multirow{2}{*}{\textbf{Source}} & \multicolumn{7}{c|}{\textbf{PPMI-SVD}} & \multirow{2}{*}{\textbf{PLM}}\\
 & & \textbf{BCH} & \textbf{BDX} & \textbf{Duke} & \textbf{MGB} & \textbf{MIMIC} & \textbf{UPMC} & \textbf{VA} &  \\
\hline
\multirow{9}{*}{\textbf{Similar}}  
 & LOINC Hierarchy & 655 & 975 & 55 & 1062 &  & 2625 & 313 & 6192\\
 & RXNORM Hierarchy & 403 & 383 & 91 & 503 & 458 & 1469 & 489 &4753\\
 & CCAM Hierarchy & & 4301 & & & & & &4301\\
 & PheCode Hierarchy & 603 & 1072 & 618 & 1199 & 221 & 1258 & 1245 & 1300\\
 & isa & 548 & 629 & 542 & 686 & 111 & 773 & 702 & 856\\
 & CHD:NA & 444 & 520 & 418 & 574 & 71 & 617 & 571 & 677\\
 & classifies & 108 & 126 & 109 & 115 & 20 & 134 & 131 & 137\\
 & part of &  &  &  &  &  & 88 &  & 123\\
 & mapped to & 77 & 91 & 76 & 95 & 19 & 102 & 98 & 104\\
\hline
\multirow{16}{*}{\textbf{Related}} 
 & may treat & 365 & 477 & 26 & 556 &  & 627 & 516 & 755\\
 & clinically associated with & 305 & 396 & 307 & 457 & 270 & 478 & 453 & 482\\
 & has contraindicated drug & 217 & 249 & 10 & 335 &  & 365 & 283 & 449\\
 & manifestation of & 175 & 222 & 181 & 236 & 10 & 238 & 222 & 243\\
 & RO:NA & 103 & 133 & 98 & 151 & 18 & 171 & 149 & 198\\
 & may prevent & 85 & 102 &  & 116 &  & 124 & 107 & 149\\
 & co-occurs with & 78 & 82 & 67 & 114 & 41 & 117 & 113 & 118\\
 & associated morphology of & 66 & 72 & 66 & 74 & 10 & 87 & 85 &87\\
 & RB:NA & 48 & 58 & 41 & 57 & 11 & 61 & 62 & 81\\
 & associated with & 21 & 29 & 18 & 38 &  & 38 & 29 & 44\\
 & active ingredient of &  &  &  &  &  & 14 &  & 40\\
 & ssc & 31 & 28 & 31 & 34 & 25 & 36 & 36 & 36\\
 & related to & 15 & 18 & 15 & 20 & 18 & 20 & 20 & 20\\
 & disease may have finding & 13 & 17 & 13 & 18 & 18 & 18 & 18 & 18\\
 & RQ:NA & 14 & 12 & 11 & 16 & 15 & 16 & 15 & 17\\
 & causative agent of & 13 & 13 &  & 11 &  & 13 &  & 16\\
\hline
\end{tabular}
}
\caption{Number of pairs used to evaluate each source in detecting known similar and related relationships. PLM refers to non-PPMI-SVD embeddings, as mentioned in Table~\ref{R_sim}. All pairs used for evaluating PLM embeddings are shared across institutions. However, for PPMI-SVD embeddings, we only use relations existing in the original institution for evaluation.}
\label{num_table}
\end{table}


\section{Additional method details}
\subsection{PPMI building}
\label{supp:ppmi}
\begin{figure}[ht]
    \centering
    \includegraphics[width=0.92\textwidth]{fig/dt_pipe.pdf}
    \caption{The generation of the institutional PPMI-SVD embeddings.}
    \label{fig:PPMI}
\end{figure}
This section explains the process of building PPMI embeddings, as described in Section~\ref{sec:PPMI emb} and illustrated in Figure~\ref{fig:PPMI}. Specifically, we compute the Positive Pointwise Mutual Information (PPMI) as follows:
\begin{equation}
\mathbb{PPMI}_m(i,j) = \max\left\{0, \log\frac{\Csc_m(i,j)\Csc_m(\cdot,\cdot)}{\Csc_m(i,\cdot) \Csc_m(j,\cdot)}\right\},
\label{PPMI_1}
\end{equation}
where $\Csc_m(i,\cdot)$ represent the sum of all occurrences for codes $i$, and $\Csc_m(\cdot,\cdot)$ is the total sum of the co-occurrence. We then apply SVD to the PPMI matrix as $\PPMI_m = \U_m\rm{diag}(\Lambda_{m,1}, ...,\Lambda_{m,n_m})\U_m\trans$ and generate the embeddings
\begin{equation}
    \V_{m}^0 = \U^{(d)}_{m} \rm{diag} \left(\Lambda_{m,1}\suphalf, ..., \Lambda_{m,d}\suphalf \right)\,,
    \label{PPMI_2}
\end{equation}
where $\U^{(d)}_{m}$ represents the first $d$ singular vectors with positive eigenvalues.

Additionally, the initial co-occurrence matrix does not account for LP codes. To address this, we compute LP code embeddings by taking a weighted sum of their child PPMI-SVD embeddings, weighted by occurrence frequency. The final embeddings for each institution concatenate the base and LP code embeddings:
\begin{equation}
    \V_{m} = \Rscr\left \{ \begin{bmatrix} \V_{m}^0 \\ \mathbf{V}_{m}^{LP} \end{bmatrix} \right \}.
    \label{PPMI_5}
\end{equation}
where $\Rscr(\cdot)$ is a normalization function that standardizes each row of the matrix to unit length.

Let $\Isc_m$ represent the set of EHR codes (both base and LP codes) for the $m$-th institution and $\Isc = \cup_{m} \Isc_m$ denote the unified code set across all institutions, with $N = |\Isc|$ unique codes. To handle missing codes of single institution, we pad the corresponding entries in each institution's embedding matrix with zeros, ensuring that $\mathbf{V}_{m} \in \mathbb{R}^{N \times d}$ is consistent across institutions, with each row representing the same EHR code. 

\subsection{Loss function in two-step training}
\label{loss}
In Section~\ref{train2}, we explore the various loss components used in the similarity and relatedness training steps. These losses are defined based on distinct sets of positive and negative relations. In this section, we provide a detailed explanation of how these positive and negative relation sets are constructed.

Specifically, in the similarity training step, we apply a similarity-based loss \eqref{sim_loss} to train $\Z_{\mathcal{S}}$ for similarity tasks. In the second step, a relatedness-based loss \eqref{rel_loss} is used to optimize $\Z_{\mathcal{R}}$, enabling it to capture more complex relationships.
\begin{align}
    \mathcal{L}_{\mathcal{S}} &= c_{\rm sim,h}\sum_{i} \mathcal{L}^{(i)}_{\rm sim,h} 
    + c_{\rm sim,nh}\sum_{i} \mathcal{L}^{(i)}_{\rm sim,nh} 
    + c_{\rm map} \sum_{i}\mathcal{L}^{(i)}_{\rm map}, 
    \label{sim_loss} \\
    \mathcal{L}_{\mathcal{R}} &= c_{\rm fea}\mathcal{L}_{\rm fea} 
    + c_{\rm rel}\sum_{i}\mathcal{L}^{(i)}_{\rm rel}.
    \label{rel_loss} 
\end{align}

The losses $\mathcal{L}^{(i)}_{\rm sim,h}$, $\mathcal{L}^{(i)}_{\rm sim,nh}$, $\mathcal{L}^{(i)}_{\rm map}$, and $\mathcal{L}^{(i)}_{\rm rel}$ represent the losses for similar hierarchical pairs, similar non-hierarchical pairs, local code mapping pairs, and related pairs, respectively, for code $i$. We define the positive set \(\mathcal{P}_i\) and negative set \(\mathcal{N}_i\) in the loss functions \eqref{sim_loss} and \eqref{rel_loss} as follows:
For the hierarchical similarity loss $\mathcal{L}^{(i)}_{\rm sim,h}$, \(\mathcal{P}_i\) consists of sibling codes of $i$, while \(\mathcal{N}_i\) includes cousin codes, which share the same grandparent but have different parent codes from $i$, as detailed in Section~\ref{sec:hie}.
For the non-hierarchical similarity loss $\mathcal{L}^{(i)}_{\rm sim,nh}$ and the relatedness loss $\mathcal{L}^{(i)}_{\rm rel}$, \(\mathcal{P}_i\) consists of codes identified as non-hierarchical similar or related to code $i$ in UMLS, as described in Section~\ref{sec:UMLS}, while \(\mathcal{N}_i\) contains randomly sampled codes of the same type as those in \(\mathcal{P}_i\).
For the local code mapping loss $\mathcal{L}^{(i)}_{\rm map}$, \(\mathcal{P}_i\) refers to the positive standard codes for a given local code $i$, as determined by GPT-4, while \(\mathcal{N}_i\) represents the candidate standard codes for code $i$ that were not selected by GPT-4, as described in Section~\ref{sec:GPT}.

Although the definitions of \(\mathcal{P}_i\) and \(\mathcal{N}_i\) vary depending on the context, they consistently differentiate between positive and negative relations that were previously difficult to distinguish. This approach enables our loss function to better capture the semantic relationships between medical codes using GAT.

For the feature selection loss, \(\mathcal{L}_{\rm fea}\), the definition slightly differs as it is not based on every individual code $i$. Instead, it is defined as:

\begin{equation}
\mathcal{L}_{\rm fea}(\mathbf{Z}) = \frac{1}{\alpha} \log \left( 1 + \sum_{(i,j) \in \mathcal{P}_{\rm fea}} e^{-\alpha (\mathbf{Z}_i^\top \mathbf{Z}_j - \lambda)} \right) + \frac{1}{\beta}\log \left( 1 + \sum_{(i,j) \in \mathcal{N}_{\rm fea}} e^{\beta (\mathbf{Z}_i^\top \mathbf{Z}_j - \lambda)} \right). 
\label{M_S_2} 
\end{equation}

Here, $\mathcal{P}_{\rm fea}$ and $\mathcal{N}_{\rm fea}$ denote the sets of positive and negative pairs for feature selection, as identified in Section~\ref{sec:GPT}.

To ensure that each part of the embedding focuses on specific knowledge, we update $\Z_{\mathcal{S}}$ using the similarity loss $\mathcal{L}_{\mathcal{S}}$ in \ref{sim_loss}, and $\Z_{\mathcal{R}}$ using the relatedness loss $\mathcal{L}_{\mathcal{R}}$ in \ref{rel_loss}. In the second step, we compute the loss using the combined embedding $\mathbf{Z} = [\mathbf{Z}_\mathcal{S}, \mathbf{Z}_\mathcal{R}]$. Although $\Z_{\mathcal{S}}$ remains fixed during the second step, this approach enhances the integration between $\Z_{\mathcal{S}}$ and $\Z_{\mathcal{R}}$.


\subsection{Algrithms}
\label{alg}
\begin{algorithm}[H]
\DontPrintSemicolon
  \KwInput{Set of institutions $\Isc = \cup_{m=1}^M \Isc_m$, with union of all $|\mathcal{I}| = N$ EHR codes , institutional co-occurrence matrix $\mathcal{C}_m$ for each $m$th institution, edge set $\mathcal{E}$, $\textit{InitLoss} = \infty$, and maximum epochs $T$}
  \KwOutput{Aligned PPMI embedding $\mathbf{Y}$ across different institutions}
  \ForEach{$m \in \{1,2,\dots,M\}$}{
   \tcc{Build initial PPMI embedding for every institution}
      Compute $\mathbb{PPMI}^{(m)}$ using equation~\eqref{PPMI_1}
      
      Obtain $\mathbf{V}^{0}_m$ using PPMI-SVD algorithm in equation~\eqref{PPMI_2} 
      
      Pad LOINC:LP rows in $\mathbf{V}^{LP}_m$ in institution $m$, Normalize the row and pad zeros for missing codes to obtain $\mathbf{V}_m$ using equation~\eqref{PPMI_5}
  }
  \For{$\textit{epoch} = 1$ \KwTo $T$}{
    \tcc{Use the initial embeddings, edges, and loss function to train the Graph Attention Network}
    \ForEach{$m \in \{1,2,\dots,M\}$}{
        Use $\mathbf{V}_m$ for $m$th institution and all edges in $\mathcal{E}$ to compute $\mathbf{Y}_m$ using equation~\eqref{Align}
    }
    
    Compute $\textit{Loss}$ using the loss function defined in equation~\eqref{align_loss}.
    
    \If{$\textit{Loss} < \textit{InitLoss}$}{
        $\textit{InitLoss} = \textit{Loss}$ 
        
        \textit{epoch} $+= 1$
    }
    \Else{
        \text{break}
    }
    Apply transformation in equation~\eqref{Align} to compute $\mathbf{Y}$
  }
  \Return{$\mathbf{Y}$} \tcc{Return the aligned PPMI-SVD embedding}
\caption{Aligning the Institutional PPMI-SVD Embeddings}
\label{alg:align_sppmi}
\end{algorithm}
\begin{algorithm}[H]
\DontPrintSemicolon

   \KwInput{Set of institutions $\Isc = \cup_{m=1}^M \Isc_m$, with union of EHR codes  $|\mathcal{I}| = N$, institutional co-occurrence matrix $\mathcal{C}_m$ for each $m$th institution, edge set $\mathcal{E}$, descriptions of medical codes $\mathcal{D}$, $\textit{InitAcc} = 0$, $\textit{InitCorr} = -\infty$, and maximum epochs $T$}
   
  \KwOutput{Embedding ${\Z}$ across different institutions}

  Use Algorithm~\ref{alg:align_sppmi} to obtain the aligned PPMI embedding $\Y$

  Use descriptions of medical codes $\mathcal{D}$ to acquire the SapBERT embedding $\X$
  
  \For{$\textit{epoch} = 1$ \KwTo $T$}{
    \tcc{Train the Graph Attention Network using $[\X,\Y]$, edges, and the loss function (Similarity step).}
    
    Use $[\X,\Y]$ as the initial input and all edges in $\mathcal{E}$ to compute $\Z_{\mathcal{S}}^{epoch}$ using equation \eqref{SIMI}

    Compute $\textit{Loss}^{epoch}$ using the embedding $\Z_{\mathcal{S}}^{epoch}$ defined in equation \eqref{M_S} and \eqref{sim_loss}

    Compute accuracy $\textit{Acc}$ of Code Mapping Using $\Z_{\mathcal{S}}^{epoch}$ 

    \If{$\textit{Acc} > \textit{InitAcc}$}{
        $\textit{InitAcc} = \textit{Acc}$ 
        
        $\Z_{\mathcal{S}} = \Z_{\mathcal{S}}^{epoch}$ 
    }
    }
    \tcc{Output the similarity part of the embedding $ \Z_{\mathcal{S}}$.}

    \For{$\textit{epoch} = 1$ \KwTo $T$}{
        \tcc{Train the Graph Attention Network using $[\X,\Y]$, edges, and the loss function (Relatedness step).}
        
        Use $[\X,\Y]$ as the initial input and all edges in $\mathcal{E}$ to compute $\Z_{\mathcal{R}}^{epoch}$ using equation \eqref{RELA}
    
        Compute $\textit{Loss}^{epoch}$ defined in equation \eqref{M_S} and \eqref{rel_loss} using the embedding $[\Z_{\mathcal{S}}, \Z_{\mathcal{R}}^{epoch}]$

        Compute average correlation $\textit{Corr}$ of Feature Selection Using $\Z_{\mathcal{R}}^{epoch}$ 
        
        \If{$\textit{Corr} > \textit{InitCorr}$}{
            $\textit{InitCorr} = \textit{Corr}$ 
    
             $\Z_{\mathcal{R}} = \Z_{\mathcal{R}}^{epoch}$ 
        }
    }
    \tcc{Output the relatedness part of the embedding $\Z_{\mathcal{R}}$.}
    
    Obtain the complete embedding $\Z=[\Z_{\mathcal{S}}, \Z_{\mathcal{R}}]$.
    
  \Return{${\Z}$} 
  \tcc{Return the final embedding.}
\caption{Two-step Training}
\label{alg:encoder}
\end{algorithm}



\subsection{Tuning parameters}
\label{Tune}
In our training process, we use the Stochastic Gradient Descent (SGD) optimizer, setting the learning rate to \(1 \times 10^{-4}\) for the aligned PPMI-SVD embedding step in Algorithm \ref{alg:align_sppmi} and \(1 \times 10^{-6}\) for the two-step training in Algorithm \ref{alg:encoder}. An exponential decay scheduler is applied with a decay rate of \(0.99\) and a minimum learning rate of \(5 \times 10^{-7}\). A drop edge rate of 0.5 is applied in every step of GAT training. 

The aligned PPMI-SVD training is stopped when the loss starts to increase, as detailed in Algorithm \ref{alg:align_sppmi}. In the similarity training step, we save the embedding with the highest code mapping accuracy, as detailed in Algorithm~\ref{alg:encoder}. In the relatedness training step, we save the embedding with the highest feature selection correlation, also detailed in Algorithm~\ref{alg:encoder}. 

When splitting the training and validation sets, we divide the similar hierarchical pairs according to their branches, as described in Section~\ref{supp:split}, with a splitting ratio of 7:3. For non-hierarchical pairs (comprising parts of the similar and all of the related pairs), we perform a random split with the same 7:3 ratio for training, and validation sets. These pairs are used in both the edge construction and loss functions, with further information available in Section~\ref{sec:UMLS}.

Since SapBERT embeddings use a feature dimension of \(d = 768\), which is a common cohice for many pre-trianed language models, we maintain this dimension for building the SapBERT embeddings \(\X\), PPMI-SVD embeddings \(\V_{m}\)'s, aligned PPMI-SVD embeddings \(\Y\), and the final embeddings \(\Z\). For the similarity embeddings \(\Z_{\mathcal{S}}\), we reduce the dimension to $256$, allowing the relatedness embeddings \(\Z_{\mathcal{R}}\) to have a dimension of $512$.

For the loss weights in \eqref{sim_loss} and \eqref{rel_loss}, we set \(c_{\rm sim,h} = 1\),  \(c_{\rm sim,nh} = 1\), \(c_{\rm map} = 30\), \(c_{\rm rel} = 5\), and \(c_{\rm fea} = 0.1\). For the contrastive loss in \eqref{M_S} and \eqref{M_S_2}, we use \(\alpha = 1\), \(\beta = 5\), and \(\lambda = 0.5\).


\subsection{Details of patient stratification procedure}
\label{supp: patident embedding}

The joint patient stratification involves $4$ steps: (1) feature selection, (2) generate patient embeddings, (3) dimension reduction, and (4) federated clustering. This section provides detialed implementation of each step.
\paragraph{Feature selection}
To ensure relevance of the clusters, we only included features with high relevance to the disease/outcome of interest based on the trained GAME embeddings. To select features, we randomly sampled pairs of codes and calculated the cosine similarity between their code embeddings. We then set the $99$th percentile of these similarities as the threshold and included only features whose cosine similarity with the target codes (290.11 for Alzheimer's disease and 297 for suicide) exceeded this value.

\paragraph{Generate patient embeddings}
We generated embeddings for the ith patient using the following weighted TF-IDF procedure: $$ \W_i^{[j]} = \sum_{c\in\mathcal V_{tar}^{[j]}} cos(\widehat\Z_{tar}, \widehat\Z_c)\log(a_{ic}^{[j]}+1)/\log(b_c^{[j]}+1) \cdot \widehat\Z_{c}. $$ where $\mathcal V_{tar}^{[j]}$ is the selected feature set that are in in EHR system at institution $j$, $a_{ic}^{[j]}$ is the count of occurrence of feature $c$ in the EHR of the $i$th patient and $b_c^{[j]}$ is the occurrence of feature $c$ in all patients from the same institution.

\paragraph{Encoder for dimension reduction of patient embeddings}
\label{tsne}
We used t-sne for dimension reduction of patient embeddings on the central site (AD: UPMC, mental health disorders: MGB). To learn the emapping from the high-dimensional patient embedding to the low dimensional t-sne representation, we trained a fully-connect neural network with three hidden layers, each with 30, 20 and 10 nodes. To avoid overfitting, we added a dropout layer with dropout rate of 0.2. We used the Adam optimizer with learning rate of $1\times 10^{-4}$.

\paragraph{Federated clustering}
We used federated k-means clustering proposed by \cite{garst2024fed}. After each institution has calculated one iteration of k-means on their local data, they send their cluster means as well as the amount of samples per cluster back to the central server. The server then concatenates all cluster means, and aggregates them. It does so by running a k-means clustering on the received local means until convergence (using the global k parameter), to align clusters from different institutions to each other. This global k-means is weighted by the amount of samples per cluster found, such that a cluster with lots of samples in it will have a bigger impact on the aggregation step compared to a cluster with
fewer samples.



\subsection{Standard baseline GAT with binary PPMI matrix}
\label{sec:naive}

To better illustrate the superiority of GAME, we trained a baseline standard GNN model using binarized PPMI matrices as edges with GAT (GAT-S). After generating PPMI matrices for different institutions (Section~\ref{sec:PPMI emb}), we established PPMI edges by connecting codes $i$ and $j$ if $\mathbb{PPMI}_{m}(i,j)$ for any institution $m$ exceeded the 99th percentile of non-zero values, following a traditional approach \cite{lee2020harmonized}. The baseline model used SapBERT embeddings refined with GPT-4 descriptions as the initial embedding, incorporating PPMI, similar, and related edges but without GPT-4 labels for local code mapping or feature selection (Section~\ref{sec:GPT}). We employed a "one-step training" process using the loss functions $\mathcal{L}^{(i)}_{sim,h}$, $\mathcal{L}^{(i)}_{sim,nh}$, and $\mathcal{L}^{(i)}_{rel}$ for similarity and relatedness tasks.


\section{Supplementary vadilation and results}
\label{sec:S2}
\subsection{Detecting clinical similarity and relatedness relationship}
\begin{table}[H]
\centering
\begin{tabular}{cc|cc}
\hline
\multicolumn{2}{c}{\textbf{Method}} & \textbf{Similarity AUC} & \textbf{Relatedness AUC} \\ \hline 
\multirow{7}{*}{PPMI-SVD} 
 & BCH & 0.783 & 0.706 \\ 
 & {BDX} & 0.863 & 0.773 \\ 
 & {Duke} & 0.741 & 0.734 \\
 & {MGB} & 0.916 & 0.787 \\ 
 & {MIMIC} & 0.693 & 0.712 \\ 
 & {UPMC} & 0.836 & 0.715 \\ 
 & {VA} & 0.898 & 0.756 \\
\multicolumn{2}{c|}{{AVE}} & 0.819 & 0.740 \\ \hline
\multicolumn{2}{c|}{{BBERT}} & 0.634 & 0.604 \\ 
\multicolumn{2}{c|}{{PBERT}} & 0.675 & 0.627 \\ 
\multicolumn{2}{c|}{{SBERT}} & 0.802 & 0.756 \\ 
\multicolumn{2}{c|}{{CODER}} & 0.878 & 0.664 \\  
\multicolumn{2}{c|}{{BGE}} & 0.920 & 0.834 \\ 
\multicolumn{2}{c|}{{OpenAI}} & \textbf{0.943} & 0.813 \\ 
\multicolumn{2}{c|}{{GAT-S}} & 0.849 & 0.838 \\ 
\multicolumn{2}{c|}{{GAME}} & 0.913 & \textbf{0.925} \\ \hline
\end{tabular}
\caption{AUC for detecting similarity and relatedness relationships using various methods. AVE represents the average PPMI AUC across different sources. BBERT represents BioBERT, PBERT represents PubmedBERT, SBERT represents SapBERT, and GAT-S represents the standard GAT baseline embedding. For simplicity, the notations below are the same and are omitted.}
\label{R2}
\end{table}


\begin{table}[H]
\centering
\setlength{\tabcolsep}{2pt}
\resizebox{1\textwidth}{!}{%
\begin{tabular}{c|c|ccccccc|c|cccccccc}
\hline
\multirow{2}{*}{\textbf{Type}} & \multirow{2}{*}{\textbf{Source}} & \multicolumn{7}{c|}{\textbf{PPMI-SVD}} & \multirow{2}{*}{\textbf{AVE}} &
\multirow{2}{*}{\textbf{BBERT}} & \multirow{2}{*}{\textbf{PBERT}} & \multirow{2}{*}{\textbf{SBERT}} & \multirow{2}{*}{\textbf{CODER}} & \multirow{2}{*}{\textbf{BGE}} & \multirow{2}{*}{\textbf{OpenAI}} & \multirow{2}{*}{\textbf{GAT-S}} & \multirow{2}{*}{\textbf{GAME}} \\
 & & \textbf{BCH} & \textbf{BDX} & \textbf{Duke} & \textbf{MGB} & \textbf{MIMIC} & \textbf{UPMC} & \textbf{VA} &  & & & & & & & & \\
\hline
\multirow{9}{*}{\textbf{Similar}}  & LOINC Hierarchy & 0.935 & 0.899 & 0.862 & 0.963 &  & 0.855 & 0.941 & 0.909 & 0.753 & 0.737 & 0.954 & 0.847 & 0.968 & 0.956 & 0.907 & \textbf{0.977} \\
 & RXNORM Hierarchy & 0.646 & 0.765 & 0.436 & 0.762 & 0.693 & 0.750 & 0.769 & 0.689 & 0.640 & 0.584 & 0.617 & 0.792 & 0.818 & \textbf{0.894} & 0.698 & 0.778 \\
 & CCAM Hierarchy & & 0.846 & & & & & & 0.846 & 0.661 & 0.627 & 0.819 & 0.953 & \textbf{0.976} & 0.980 & 0.848 & 0.956 \\
 & PheCode Hierarchy & 0.835 & 0.937 & 0.835 & 0.961 & 0.787 & 0.956 & 0.964 & 0.896 & 0.566 & 0.568 & 0.821 & \textbf{0.959} & 0.935 & 0.956 & 0.886 & 0.929 \\
 & isa & 0.730 & 0.823 & 0.718 & 0.868 & 0.607 & 0.796 & 0.871 &  0.773 & 0.543 & 0.557 & 0.762 & 0.858 & 0.872 & 0.878 & 0.857 & \textbf{0.907} \\
 & CHD:NA & 0.748 & 0.884 & 0.741 & 0.920 & 0.723 & 0.854 & 0.887 & 0.832 & 0.584 & 0.571 & 0.829 & 0.887 & 0.914 & 0.923 & 0.887 & \textbf{0.933} \\
 & classifies & 0.791 & 0.850 & 0.736 & 0.923 & 0.750 & 0.879 & 0.897 & 0.822 & 0.536 & 0.568 & 0.763 & 0.921 & \textbf{0.954} & 0.944 & 0.899 & 0.944 \\
 & part of & 0.808 & & 0.794 & & & 0.677 & & 0.760 &  0.273 & 0.197 & 0.440 & 0.941 & 0.785 & 0.977 & 0.905 & \textbf{0.966} \\
 & mapped to & 0.808 & 0.867 & 0.794 & 0.910 & 0.684 & 0.832 & 0.898 & 0.828 & 0.542 & 0.503 & 0.773 & 0.906 & 0.878 & 0.933 & 0.881 & \textbf{0.958} \\
\hline
\multirow{16}{*}{\textbf{Related}} & may treat & 0.696 & 0.825 & 0.692 & 0.836 & & 0.802 & 0.796 & 0.775 & 0.697 & 0.675 & 0.793 & 0.581 & 0.889 & 0.886 & 0.879 & \textbf{0.962} \\
 & clinically associated with & 0.717 & 0.773 & 0.865 & 0.784 & 0.705 & 0.707 & 0.745 & 0.757 & 0.562 & 0.570 & 0.720 & 0.665 & 0.769 & 0.673 & 0.819 & \textbf{0.888} \\
 & has contraindicated drug & 0.586 & 0.657 & 0.410 & 0.588 & & 0.584 & 0.565 & 0.565 & 0.703 & 0.591 & 0.755 & 0.467 & 0.812 & 0.771 & 0.820 & \textbf{0.917} \\
 & manifestation of & 0.746 & 0.692 & 0.570 & 0.738 & 0.360 & 0.641 & 0.674 & 0.632 & 0.588 & 0.547 & 0.654 & 0.629 & 0.732 & 0.709 & 0.739 & \textbf{0.865} \\
 & RO:NA & 0.727 & 0.854 & 0.701 & 0.841 & 0.722 & 0.789 & 0.836 &  0.781 & 0.548 & 0.569 & 0.726 & 0.830 & 0.869 & 0.884 & 0.863 & \textbf{0.886} \\
 & may prevent & 0.649 & 0.823 & & 0.821 & & 0.813 & 0.816 & 0.784& 0.733 & 0.612 & 0.787 & 0.588 & 0.919 & 0.926 & 0.889 & \textbf{0.958} \\
 & co-occurs with & 0.798 & 0.873 & 0.818 & 0.879 & 0.699 & 0.838 & 0.879 & 0.826& 0.689 & 0.597 & 0.787 & 0.785 & 0.899 & 0.856 & 0.833 & \textbf{0.913} \\
 & associated morphology of & 0.703 & 0.735 & 0.679 & 0.779 & 0.410 & 0.666 & 0.721 & 0.670& 0.403 & 0.483 & 0.718 & 0.724 & 0.798 & 0.816 & 0.787 & \textbf{0.827} \\
 & RB:NA & 0.664 & 0.860 & 0.738 & 0.815 & 0.603 & 0.760 & 0.836 & 0.754 & 0.522 & 0.578 & 0.798 & 0.802 & 0.899 & 0.871 & 0.833 & \textbf{0.918} \\
 & associated with & 0.707 & 0.658 & 0.611 & 0.819 & & 0.738 & 0.806 & 0.723 & 0.579 & 0.537 & 0.865 & 0.868 & 0.868 & 0.871 & 0.879 & \textbf{0.929} \\
 & active ingredient of & & & & & & 0.633 & & 0.633 & 0.549 & 0.468 & 0.639 & 0.825 & 0.933 & 0.954 & 0.912 & \textbf{0.966} \\
 & ssc & 0.908 & 0.856 & 0.852 & 0.846 & 0.760 & 0.698 & 0.861 & 0.826 & 0.640 & 0.698 & 0.816 & 0.869 & 0.789 & 0.873 & 0.903 & \textbf{0.937} \\
 & related to & 0.716 & 0.867 & 0.556 & 0.943 & 0.867 & 0.843 & 0.878 & 0.810 & 0.480 & 0.613 & 0.718 & 0.830 & 0.900 & 0.943 & 0.798 & \textbf{0.903} \\
 & disease may have finding & 0.734 & 0.924 & 0.746 & 0.676 & 0.676 & 0.778 & 0.667 & 0.743 & 0.478 & 0.750 & 0.620 & 0.497 & 0.719 & 0.694 & \textbf{0.806} & 0.772 \\
 & RQ:NA & 0.786 & 0.806 & 0.669 & 0.996 & 0.871 & 0.910 & 0.871 & 0.844 & 0.654 & 0.374 & 0.889 & 0.796 & 0.872 & 0.882 & 0.796 & \textbf{0.962} \\
 & causative agent of & 0.763 & 0.763 & & 0.777 & & 0.722 & & 0.756 & 0.504 & 0.688 & 0.754 & 0.871 & 0.898 & 0.879 & 0.672 & \textbf{0.910} \\
\hline
\end{tabular}
}
\caption{AUCs of between-vector cosine similarity in detecting known similar and related pairs with GAME embedding. Empty entries indicate that no such source exists for that institution. }
\label{R_sim}
\end{table}

\subsection{Cross-institutional code mapping}
\label{sec:code_map_supp}

As described in Section~\ref{sec:code_map}, we have detailed VA local lab codes to the LOINC codes. As a result, we evaluated the top \( k \) accuracy for each local lab in the following way. We selected the LOINC codes with the highest cosine similarity across different embeddings. Accuracy was measured by verifying if the correct mappings were included among the top \( k \) selected LOINC/LP codes (based on cosine similarity), specifically evaluating at the top $1$, $5$, $10$, and $20$ selections. For local lab mappings, we assessed accuracy at the LP level, meaning that if a local lab code mapped to either the parent or sibling of the correct LOINC leaf codes, it was considered accurate. 

Secondly, since UPMC local labs and both UPMC and BDX local procedures lacked predefined standard mappings, we manually annotated a portion of these mappings. We focused on mapping UPMC local labs to LOINC and UPMC and BDX local procedure codes to CCS. Using embeddings from SapBERT, CODER, BGE, and OpenAI, we selected the top 20 potential mappings for each local code by calculating cosine similarity between local codes and standard codes (LOINC or CCS). Additionally, we included negative samples for human annotation. Each mapping was scored as follows: $1$ for ``yes,'' $0.5$ for ``possible,'' and $0$ for ``no.'' This process resulted in $199$ UPMC procedure mappings to CCS, $537$ BDX CCAM mappings to CCS, and $1,814$ UPMC lab mappings to LOINC.


\begin{table}[H]
\centering
\resizebox{1\textwidth}{!}{%
\begin{tabular}{c|c|c|c}
\hline
\textbf{Method} & \textbf{UPMC PX-CCS } & \textbf{BDX CCAM-CCS } & \textbf{UPMC LAB-LOINC } \\ \hline
BBERT        & 0.059     & 0.138     & 0.102  \\ 
PBERT        & 0.001     & 0.317     & 0.112  \\ 
SBERT        & 0.313     & 0.423     & 0.529  \\ 
CODER        & 0.418     & 0.540     & 0.554  \\ 
BGE      & 0.409     & 0.615     & 0.610  \\ 
OpenAI  & 0.484     & 0.616     & 0.583  \\ 
GAT-S   & 0.498     & 0.431     & 0.505  \\ 
GAME     & \textbf{0.574} & \textbf{0.671} & \textbf{0.654} \\ \hline
Pairs Num &199 & 537& 1814 \\
Standard Code Num & 10 & 29&84\\ \hline
\end{tabular}
}
\caption{Spearman's Rank Correlation between cosine similarity scores and human annotations. A higher rank correlation indicates that cosine similarity better reflects the relationship between local codes and standard codes. ``Pairs Num'' refers to the total number of evaluated pairs, while ``Standard Code Num'' denotes the total number of unique standard codes.}
\label{R2_code_map_2}
\end{table}




As shown in Table~\ref{R1_GPT}, we observed that BGE and OpenAI embeddings with fewer dimensions (256, same as the dimensionality of the similarity part of the GAME embedding) performed noticeably worse than their higher-dimensional counterparts. This suggests that the GAME embedding provides a more efficient lower-dimensional representation without sacrificing performance.


\begin{table}[H]
\centering
\begin{tabular}{|c|c|c|c|c|c|}
\hline
\multirow{2}{*}{\textbf{Dimension}} & \multicolumn{2}{c|}{\textbf{BGE}} & \multicolumn{3}{c|}{\textbf{OpenAI}} \\ \cline{2-6}
 & \textbf{256} & \textbf{768} & \textbf{256} & \textbf{768} & \textbf{1536} \\ \hline
\textbf{TOP1}      & 57.2\%       & 61.9\%       & 56.8\%       & 62.2\%       & 61.9\%        \\ \hline
\textbf{TOP5}      & 76.5\%       & 79.0\%       & 78.5\%       & 86.4\%       & 85.9\%        \\ \hline
\textbf{TOP10}     & 83.8\%       & 84.3\%       & 84.2\%       & 89.6\%       & 89.8\%        \\ \hline
\textbf{TOP20}     & 87.8\%       & 89.7\%       & 87.9\%       & 92.6\%       & 92.6\%        \\ \hline
\end{tabular}
\caption{Accuracy of code mapping using BGE and OpenAI embeddings across different dimensions}
\label{R1_GPT}
\end{table}

Additionally, we present the results of code mapping using SapBERT and CODER embeddings based on uncorrected descriptions in Table~\ref{tab:before_GPT}, without applying the GAME algorithm. The results demonstrate that GPT-4-corrected descriptions significantly improve code mapping, and GAME further enhances accuracy substantially.

\begin{table}[H]
\centering
\begin{tabular}{|c|ccc|ccc|}
\hline
\multirow{2}{*}{\textbf{Desc}} & \multicolumn{3}{c|}{\textbf{SapBERT}} & \multicolumn{3}{c|}{\textbf{CODER}} \\ \cline{2-7}
 & \textbf{short} & \textbf{+dict} & \textbf{+GPT-4}& \textbf{short} & \textbf{+dict} & \textbf{+GPT-4} \\ \hline
\textbf{TOP1}   & 52.2\% &  54.7\%    & 59.7\%   & 52.7\% & 53.2\%  & 55.6\%        \\ \hline
\textbf{TOP5}   & 67.3\% &  70.8\%    & 79.0\%   & 71.7\% & 72.5\%  & 75.9\%        \\ \hline
\textbf{TOP10}  & 71.1\% &  74.6\%    & 82.9\%   & 77.8\% & 78.7\%  & 85.0\%         \\ \hline
\textbf{TOP20}  & 74.7\% &  77.7\%    & 85.7\%   & 82.4\% & 83.3\%  & 89.7\%          \\ \hline
\end{tabular}
\caption{Accuracy of code mapping after each step of refining descriptions.}
\label{tab:before_GPT}
\end{table}







\subsection{Feature selection}


\begin{table}[H]
\centering
\setlength{\tabcolsep}{2pt}
\begin{tabular}{cc|cccccccc}
\hline
 \multicolumn{2}{c|}{\textbf{Method}}& \textbf{HF} & \textbf{Depression} & \textbf{RA} & \textbf{AD} & \textbf{T1D} & \textbf{T2D} & \textbf{CD} & \textbf{UC} \\
\hline
\multirow{7}{*}{{PPMI-SVD}}
& {BCH} & 0.661 & 0.600 & 0.601 & - & 0.514 & 0.530 & 0.593 & 0.564 \\
& {BDX} & 0.644 & 0.630 & 0.607 & 0.589 & 0.573 & 0.572 & 0.588 & 0.602 \\
& {Duke} & 0.625 & 0.559 & 0.511 & - & 0.496 & 0.515 & 0.504 & 0.506 \\
& {MGB} & 0.703 & 0.670 & 0.642 & 0.575 & 0.566 & 0.602 & 0.616 & 0.609 \\
& {MIMIC} & 0.606 & 0.527 & 0.426 & 0.529 & 0.497 & 0.529 & 0.506 & 0.506 \\
& {UPMC} & 0.641 & 0.596 & 0.588 & 0.572 & 0.591 & 0.610 & 0.547 & 0.550 \\
& {VA} & 0.705 & 0.635 & 0.639 & 0.570 & 0.592 & 0.612 & 0.578 & 0.572 \\
\multicolumn{2}{c|}{{AVE}} & 0.655 & 0.603 & 0.573 & 0.567 & 0.547 & 0.567 & 0.561 & 0.558 \\
\hline
\multicolumn{2}{c|}{{BBERT}} & 0.478 & 0.425 & 0.541 & 0.490 & 0.441 & 0.454 & 0.432 & 0.490 \\
\multicolumn{2}{c|}{{PBERT}} & 0.424 & 0.460 & 0.488 & 0.490 & 0.452 & 0.471 & 0.469 & 0.455 \\
\multicolumn{2}{c|}{{SBERT}} & 0.641 & 0.434 & 0.521 & 0.584 & 0.563 & 0.546 & 0.531 & 0.512 \\
\hline
\multicolumn{2}{c|}{{CODER}} & 0.615 & 0.551 & 0.572 & 0.581 & 0.641 & 0.639 & 0.538 & 0.552 \\
\multicolumn{2}{c|}{{BGE}} & 0.663 & 0.588 & 0.579 & 0.595 & 0.622 & 0.612 & 0.551 & 0.544 \\
\multicolumn{2}{c|}{{OpenAI}} & 0.686 & 0.683 & 0.672 & 0.643 & 0.688 & 0.706 & 0.615 & \textbf{0.668} \\
\multicolumn{2}{c|}{GAT-S} & 0.645 & 0.609 & 0.653 & 0.594 & 0.692 & 0.688 & 0.582 & 0.581 \\
\multicolumn{2}{c|}{{GAME}} & \textbf{0.749} & \textbf{0.732} & \textbf{0.677} & \textbf{0.684} & \textbf{0.741} & \textbf{0.717} & \textbf{0.683} & 0.665 \\
\hline
\end{tabular}
\caption{The C-index between cosine similarities and GPT-4 scores for target diseases. Results are partly missing because AD does not exist in these institutions.}
\label{R3_}
\end{table}



\subsection{Joint patient stratification}
\begin{table}[H]
    \centering
    \scriptsize
    \begin{tabular}{l c c c c c c c c c}
\toprule
& \multicolumn{3}{c}{\textbf{UPMC}}&
\multicolumn{3}{c}{\textbf{MGB}}&
\multicolumn{3}{c}{\textbf{Duke}} \\
\cmidrule(r){2-4}\cmidrule(l){5-7}\cmidrule(l){8-10}
& Overall & Fast (1) & Slow (2) & Overall & Fast (1) & Slow (2) & Overall & Fast (1) & Slow (2)  \\
\bottomrule
\textbf{Number of Patients, $N(\%)$} & 16411 & 6726 & 9685 &  17770 & 6089 & 11681 & 10660 & 3972 & 6688 \\
\bottomrule
\textbf{Age at AD diagnosis, mean (SD)} & 81.2 & 79.8 & 82.1 & 79.7 & 79.9 & 79.5 & 79.6 & 79.6 & 79.6 \\
 & (9.0) & (9.6) & (8.4) & (9.5) & (9.1) & (9.7) & (9.0) & (8.7) & (9.2)\\
\bottomrule
\textbf{Gender, $N(\%)$}\\
Women & 10559  & 4266  & 6293 & 10795 & 3644 & 7151 & 6760 & 2481 & 4279 \\
 & (64.3\%) & (63.4\%) & (65.0\%) & (60.7\%) & (59.8\%) & (61.2\%) & (63.4\%) & (62.5\%) & (64.0\%) \\
Men & 5852 & 2460 & 3392 & 6975 & 2445 & 4530 & 3900 & 1491 & 2409 \\
 & (35.7\%) & (36.6\%) & (35.0\%) & (39.3\%) & (40.2\%) & (38.8\%) & (36.6\%) & (37.5\%) & (36.0\%) \\
\bottomrule
\textbf{Race/Ethnicity, $N(\%)$} \\
Non-Hispanic White & 15105 & 6214 & 8891 & 15793 & 5324 & 10469 & 7512 & 2854 & 4658 \\
 & (92.0\%) & (92.4\%) & (91.8\%) & (88.9\%) & (87.4\%) & (89.6\%) & (70.5\%) & (71.9\%) & (69.6\%) \\
Others & 1306 & 512 & 794 & 1977 & 765 & 1212 & 3148 & 1118 & 2030 \\
 & (8.0\%) & (7.6\%) & (8.2\%) & (11.1\%) & (12.6\%) & (10.4\%) & (29.5\%) & (28.1\%) & (30.4\%) \\
\bottomrule
\end{tabular}
\caption{Demographics of AD patients in each cluster at UPMC, MGB, and Duke.}
\label{tab:AD_demo}
\end{table}


\begin{figure}[H]
    \centering
    \includegraphics[width=13cm]{fig/AD/AD_flowchart.png}
    \caption{Schematic of joint stratification of AD patients across three instituitons (UPMC, MGB and Duke).}
    \label{fig:AD_flow}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=.9\textwidth]{fig/AD/tsne_all_AD.jpg}
    \caption{Projected t-sne visualization of patient embedding for $5000$ randomly sampled AD patients at each insitution (UPMC, MGB and Duke).}
    \label{fig:AD_tsne}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.3\textwidth]{fig/AD/KM_nh_upmc_com.png}\hfill
    \includegraphics[width=0.3\textwidth]{fig/AD/KM_nh_mgb_com.png}\hfill
    \includegraphics[width=0.3\textwidth]{fig/AD/KM_nh_duke_com_10232024.png}
    \caption{Kaplan Meier curve of time to nursing home admission for each cluster of AD patients in UPMC, MGB and Duke.}
    \label{fig:AD_KM}
\end{figure}


\begin{table}[H]
\centering
\begin{tabular}{ll}
  \hline
PheCode & Description \\ 
  \hline
PheCode:295 & schizophrenia and other psychotic disorders \\ 
  PheCode:295.1 & schizophrenia \\ 
  PheCode:295.2 & paranoid disorders \\ 
  PheCode:295.3 & psychosis \\ 
  PheCode:296 & mood disorders \\ 
  PheCode:296.1 & bipolar \\ 
  PheCode:296.2 & depression \\ 
  PheCode:296.22 & major depressive disorder \\ 
  PheCode:300 & anxiety, phobic and dissociative disorders \\ 
  PheCode:300.1 & anxiety disorder \\ 
  PheCode:300.11 & generalized anxiety disorder \\ 
  PheCode:300.12 & agorophobia, social phobia, and panic disorder \\ 
  PheCode:300.13 & phobia \\ 
  PheCode:300.3 & obsessive-compulsive disorders \\ 
  PheCode:300.4 & dysthymic disorder \\ 
  PheCode:300.8 & acute reaction to stress \\ 
  PheCode:300.9 & posttraumatic stress disorder \\ 
  PheCode:301 & personality disorders \\ 
  PheCode:301.1 & schizoid personality disorder \\ 
  PheCode:301.2 & antisocial/borderline personality disorder \\ 
  PheCode:302 & sexual and gender identity disorders \\ 
  PheCode:302.1 & decreased libido \\ 
  PheCode:303 & psychogenic and somatoform disorders \\ 
  PheCode:303.1 & dissociative disorder \\ 
  PheCode:303.3 & psychogenic disorder \\ 
  PheCode:303.31 & gastrointestinal malfunction arising from mental factors \\ 
  PheCode:303.4 & somatoform disorder \\ 
  PheCode:304 & adjustment reaction \\ 
  PheCode:305.2 & eating disorder \\ 
  PheCode:305.21 & anorexia nervosa \\ 
   \hline
\end{tabular}
\caption{Phecodes indicating mental health disorders. }
\label{tab:mental_phecode}
\end{table}




\begin{figure}[p]
    \centering
    \includegraphics[width=\textwidth]{fig/AD/AD_OR_all_phe.jpeg}
    \includegraphics[width=\textwidth]{fig/AD/AD_OR_all_others.jpeg}
    % \includegraphics[width=\textwidth]{fig/AD/AD_OR_all_new.png}
    \caption{For AD patient stratification, the association between AD-related EHR codes (top: diagnosis codes, bottom: other codes) and cluster membership (cluster 1 vs clsuter 2) in each institution (UPMC, MGB and Duke). Each dot/line represent a unqiue code, and the length shows $-\log_{10}(\text{p-value})$ of the association. Diagnosis codes are grouped into disease categories and other codes are grouped into code categories. Top 12 diagnosis features and top 8 other features are labeled with the code description and odds ratio. }
    \label{fig:AD_phewas}
\end{figure}

\begin{table}[H]
    \centering
    \scriptsize
    \begin{tabular}{l c c c c c c}
\toprule
& \multicolumn{3}{c}{\textbf{MGB}}&
\multicolumn{3}{c}{\textbf{Duke}}\\
\cmidrule(r){2-4}\cmidrule(l){5-7}
& Overall & Higher risk (1) & Lower risk (2) & Overall & Higher risk (1) & Lower risk (2)  \\
\bottomrule
\textbf{Number of Patients, $N(\%)$} & 24048 & 9070 & 14978 & 31576 & 10589 & 20987 \\
\bottomrule
\textbf{Age at AD diagnosis, mean (SD)} & 12.3 & 13.0 & 11.9 & 10.8 & 10.9 & 10.8 \\
 & (4.0) & (3.5) & (4.2) & (4.6) & (4.4) & (4.6) \\
\bottomrule
\textbf{Gender, $N(\%)$}\\
Women & 14199 & 5215 & 8984 & 16422 & 5052 & 11370 \\
 & (59.0\%) & (57.5\%) & (60.0\%) & (52.0\%) & (47.7\%) & (54.2\%) \\
Men & 9847 & 3855 & 5992 & 15154 & 5537 & 9617 \\
 & (40.9\%) & (42.5\%) & (40.0\%) & (48.0\%) & (52.3\%) & (45.8\%) \\
\bottomrule
\textbf{Race/Ethnicity, $N(\%)$} \\
Non-Hispanic White & 16594 & 6960 & 9634 & 16013 & 6227 & 9786 \\
 & (69.0\%) & (76.7\%) & (64.3\%) & (50.7\%) & (58.8\%) & (46.6\%)  \\
Others & 7454 & 2110 & 5344 & 15563 & 4362 & 11201 \\
 & (31.0\%) & (23.3\%) & (35.7\%) & (49.3\%) & (41.2\%) & (53.4\%) \\
\bottomrule
\end{tabular}
\caption{Demographics of mental health patients in each cluster at MGB and Duke for the $age < 18$ group.}
\label{tab:mental_demo_0-18}
\end{table}


\begin{table}[H]
    \centering
    \scriptsize
    \begin{tabular}{l c c c c c c}
\toprule
& \multicolumn{3}{c}{\textbf{MGB}}&
\multicolumn{3}{c}{\textbf{Duke}}\\
\cmidrule(r){2-4}\cmidrule(l){5-7}
& Overall & Higher risk (1) & Lower risk (2) & Overall & Higher risk (1) & Lower risk (2)  \\
\bottomrule
\textbf{Number of Patients, $N(\%)$} & 36666 & 16527 & 20139 & 23271 & 13591 & 9680 \\
\bottomrule
\textbf{Age at AD diagnosis, mean (SD)} & 21.8 & 21.7 & 21.8 & 21.6 & 21.7 & 21.5 \\
 & (2.2) & (2.2) & (2.2) & (2.3) & (2.3) & (2.4) \\
\bottomrule
\textbf{Gender, $N(\%)$}\\
Women & 25989 & 11132 & 14857 & 15443 & 9480 & 5963 \\
 & (70.9\%) & (67.4\%) & (73.8\%) & (66.4\%) & (69.8\%) & (61.6\%) \\
Men & 10676 & 5395 & 5281 & 7828 & 4111 & 3717 \\
 & (29.1\%) & (32.6\%) & (26.2\%) & (33.6\%) & (30.2\%) & (38.4\%) \\
\bottomrule
\textbf{Race/Ethnicity, $N(\%)$} \\
Non-Hispanic White & 26907 & 12614 & 14293 & 13816 & 8770 & 5046 \\
 & (73.4\%) & (76.3\%) & (71.0\%) & (59.4\%) & (64.5\%) & (52.1\%) \\
Others & 9759 & 3913 & 5846 & 9455 & 4821 & 4634 \\
 & (26.6\%) & (23.7\%) & (29.0\%) & (40.6\%) & (35.5\%) & (47.9\%) \\
\bottomrule
\end{tabular}
\caption{Demographics of mental health patients in each cluster at MGB and Duke for the $19 \le age \le 25$ group.}
\label{tab:mental_demo_19-25}
\end{table}



\begin{table}[H]
    \centering
    \scriptsize
    \begin{tabular}{l c c c c c c}
\toprule
& \multicolumn{3}{c}{\textbf{MGB}}&
\multicolumn{3}{c}{\textbf{Duke}}\\
\cmidrule(r){2-4}\cmidrule(l){5-7}
& Overall & Higher risk (1) & Lower risk (2) & Overall & Higher risk (1) & Lower risk (2)  \\
\bottomrule
\textbf{Number of Patients, $N(\%)$} & 123034 & 59938 & 63096 & 94846 & 63501 & 31345 \\
\bottomrule
\textbf{Age at AD diagnosis, mean (SD)} & 37.5 & 37.6 & 37.4 & 37.9 & 38.2 & 37.3 \\
 & (6.9) & (7.0) & (6.9) & (6.9) & (6.9) & (6.9) \\
\bottomrule
\textbf{Gender, $N(\%)$}\\
Women & 84869 & 39308 & 45561 & 62622 & 43261 & 19361 \\
 & (69.0\%) & (65.6\%) & (72.2\%) & (66.0\%) & (68.1\%) & (61.8\%)  \\
Men & 38162 & 20629 & 17533 & 32224 & 20240 & 11984 \\
 & (31.0\%) & (34.4\%) & (27.8\%) & (34.0\%) & (31.9\%) & (38.2\%) \\
\bottomrule
\textbf{Race/Ethnicity, $N(\%)$} \\
Non-Hispanic White & 28238 & 13376 & 14862 & 60462 & 41307 & 19155 \\
 &  (23.0\%) & (22.3\%) & (23.6\%) & (63.7\%) & (65.0\%) & (61.1\%)\\
Others & 94796 & 46562 & 48234 & 34384 & 22194 & 12190 \\
 &  (77.0\%) & (77.7\%) & (76.4\%) & (36.3\%) & (35.0\%) & (38.9\%) \\
\bottomrule
\end{tabular}
\caption{Demographics of mental health patients in each cluster at MGB and Duke for the $26 \le age \le 49$ group.}
\label{tab:mental_demo_26-49}
\end{table}


\begin{table}[H]
    \centering
    \scriptsize
    \begin{tabular}{l c c c c c c}
\toprule
& \multicolumn{3}{c}{\textbf{MGB}}&
\multicolumn{3}{c}{\textbf{Duke}}\\
\cmidrule(r){2-4}\cmidrule(l){5-7}
& Overall & Higher risk (1) & Lower risk (2) & Overall & Higher risk (1) & Lower risk (2)  \\
\bottomrule
\textbf{Number of Patients, $N(\%)$} & 72482 & 37230 & 35252 & 70651 & 47152 & 23499 \\
\bottomrule
\textbf{Age at AD diagnosis, mean (SD)} & 56.8 & 56.9 & 56.8 & 57.4 & 57.6 & 57.0 \\
 & (4.5) & (4.5) & (4.2) & (4.6) & (4.6) & (4.5)\\
\bottomrule
\textbf{Gender, $N(\%)$}\\
Women & 47135 & 23366 & 23769 & 45357 & 30512 & 14845 \\
 & (65.0\%) & (62.8\%) & (67.4\%) & (64.2\%) & (64.7\%) & (63.2\%) \\
Men & 25345 & 13864 & 11481 & 25294 & 16640 & 8654 \\
 & (35.0\%) & (37.2\%) & (32.6\%) & (35.8\%) & (35.3\%) & (36.8\%) \\
\bottomrule
\textbf{Race/Ethnicity, $N(\%)$} \\
Non-Hispanic White & 61660 & 31522 & 30138 & 49966 & 32831 & 17135 \\
 & (85.1\%) & (84.7\%) & (85.5\%) & (70.7\%) & (69.6\%) & (72.9\%) \\
Others & 10822 & 5708 & 5114 & 20685 & 14321 & 6364 \\
 & (14.9\%) & (15.3\%) & (14.5\%) & (29.3\%) & (30.4\%) & (27.1\%) \\
\bottomrule
\end{tabular}
\caption{Demographics of mental health patients in each cluster at MGB and Duke for the $50\le age \le 65$ group.}
\label{tab:mental_demo_50-65}
\end{table}



\begin{table}[H]
    \centering
    \scriptsize
    \begin{tabular}{l c c c c c c}
\toprule
& \multicolumn{3}{c}{\textbf{MGB}}&
\multicolumn{3}{c}{\textbf{Duke}}\\
\cmidrule(r){2-4}\cmidrule(l){5-7}
& Overall & Higher risk (1) & Lower risk (2) & Overall & Higher risk (1) & Lower risk (2)  \\
\bottomrule
\textbf{Number of Patients, $N(\%)$} & 39509 & 19887 & 19622 & 51867 & 43157 & 8710 \\
\bottomrule
\textbf{Age at AD diagnosis, mean (SD)} & 74.0 & 74.2 & 73.8 & 73.8 & 74.0 & 72.7 \\
 & (6.4) & (6.5) & (6.3) & (6.5) & (6.5) & (6.1) \\
\bottomrule
\textbf{Gender, $N(\%)$}\\
Women & 26233 & 12911 & 13322 & 34248 & 28433 & 5815 \\
 & (66.4\%) & (64.9\%) & (67.9\%) & (66.0\%) & (65.9\%) & (66.8\%) \\
Men & 13274 & 6976 & 6298 & 17619 & 14724 & 2895 \\
 & (33.6\%) & (35.1\%) & (32.1\%) & (34.0\%) & (34.1\%) & (33.2\%) \\
\bottomrule
\textbf{Race/Ethnicity, $N(\%)$} \\
Non-Hispanic White & 35190 & 17719 & 17471 & 41159 & 33917 & 7242 \\
 & (89.1\%) & (89.1\%) & (89.0\%) & (79.4\%) & (78.6\%) & (83.1\%) \\
Others & 4319 & 2168 & 2151 & 10708 & 9240 & 1468 \\
 & (10.9\%) & (10.9\%) & (11.0\%) & (20.6\%) & (21.4\%) & (16.9\%) \\
\bottomrule
\end{tabular}
\caption{Demographics of mental health patients in each cluster at MGB and Duke for the $age \ge 66$ group.}
\label{tab:mental_demo_66-110}
\end{table}

\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth]{fig/mental/tsne_all.jpg}
    \caption{Projected t-sne plots for $5000$ randomly samples mental health patients in each age group at each institution (Duke and MGB).}
    \label{fig:suicide_tsne}
\end{figure}


\begin{figure}[H]
    \centering
    \includegraphics[width=3cm]{fig/mental/KM_ideation_0-18.png}
    \includegraphics[width=3cm]{fig/mental/KM_ideation_18-25.png}
    \includegraphics[width=3cm]{fig/mental/KM_ideation_26-49.png}
    \includegraphics[width=3cm]{fig/mental/KM_ideation_50-65.png}
    \includegraphics[width=3cm]{fig/mental/KM_ideation_66-110.png}
    \includegraphics[width=3cm]{fig/mental/KM_attempt_0-18.png}
    \includegraphics[width=3cm]{fig/mental/KM_attempt_18-25.png}
    \includegraphics[width=3cm]{fig/mental/KM_attempt_26-49.png}
    \includegraphics[width=3cm]{fig/mental/KM_attempt_50-65.png}
    \includegraphics[width=3cm]{fig/mental/KM_attempt_66-110.png}
    
    \includegraphics[width=3cm]{fig/mental/Duke/KM_ideation_0-18_10312024.png}
    \includegraphics[width=3cm]{fig/mental/Duke/KM_ideation_18-25_10312024.png}
    \includegraphics[width=3cm]{fig/mental/Duke/KM_ideation_26-49_10312024.png}
    \includegraphics[width=3cm]{fig/mental/Duke/KM_ideation_50-65_10312024.png}
    \includegraphics[width=3cm]{fig/mental/Duke/KM_ideation_66-110_10312024.png}
    \includegraphics[width=3cm]{fig/mental/Duke/KM_attempt_0-18_10312024.png}
    \includegraphics[width=3cm]{fig/mental/Duke/KM_attempt_18-25_10312024.png}
    \includegraphics[width=3cm]{fig/mental/Duke/KM_attempt_26-49_10312024.png}
    \includegraphics[width=3cm]{fig/mental/Duke/KM_attempt_50-65_10312024.png}
    \includegraphics[width=3cm]{fig/mental/Duke/KM_attempt_66-110_10312024.png}
    \caption{Kaplan Meier curve of time to suicidal ideation (top) or suicidal attempt (bottom) since the time of first mental health related EHR code for each group, stratified by age group. (Blue) MGB, (Red) Duke.}
    \label{fig:KM_rpdr}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=.8\textwidth]{fig/mental/depression_OR_all_phe.jpeg}
    \caption{The association between suicide-related diagnosis codes and cluster membership (cluster 1 vs clsuter 2) in each institution (MGB and Duke). Each dot/line represent a unqiue code, and the length shows $-\log_{10}(\text{p-value})$ of the association. Diagnosis codes are grouped into disease categories. Top 12 diagnosis features are labeled with the code description and odds ratio.}
    \label{fig:suicide_phewas_phe}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=.8\textwidth]{fig/mental/depression_OR_all_oth.jpeg}
    \caption{the association between other EHR codes (non-diagnosis codes) and cluster membership (cluster 1 vs clsuter 2) in each institution (MGB and Duke). Each dot/line represent a unqiue code, and the length shows $-\log_{10}(\text{p-value})$ of the association. The codes are grouped into categories. Top 8 features are labeled with the code description and odds ratio.}
    \label{fig:suicide_phewas_oth}
\end{figure}

\end{document}