\section{Introduction}
\label{sec:introduction}
The proliferation of web applications has brought significant advancements but also introduced new security challenges. Among the various web-based attacks~\cite{10008276, aaa9491117}, Cross-site scripting (XSS)~\cite{RODRIGUEZ2020106960} stands out as one of the most critical concerns. XSS attacks pose a significant threat as they can compromise user data, steal information, and spread worms. Malicious actors exploit vulnerabilities in web applications to inject harmful scripts, which are then unknowingly executed by users' browsers. To mitigate XSS attacks, robust detection methods and strong input validation techniques are essential to safeguard user data and system integrity. 

Researchers have focused on the XSS vulnerability discovery, employing either static or dynamic analysis. 
Static analysis methods scrutinize the source code to identify potential attacks~\cite{doupe2013dedacota,steinhauser2016static,mohammadi2017detecting,kronjee2018discovering}, but their application might not scale to the size of modern web applications or might result in overconservative results, with several false positives, due to the presence of programming constructs that are difficult to handle statically.  
Dynamic analysis, on the other hand, simulates user operations to detect attacks~\cite{lekies2013detection,stock2014precise,fazzini2015automatically}. However, this approach suffers from a high false negative rate as test cases cannot cover all possible scenarios. To address these limitations, researchers have proposed methods to detect the injection of XSS scripts at runtime, complementing XSS vulnerability discovery before release. In the early approaches, machine learning techniques with manual feature extraction were extensively used~\cite{likarish2009obfuscated,nunan2012automatic,wang2014machine,rathore2017xssclassifier,mereani2018howe}, followed by the advent of Deep Learning (DL) and the use of Deep Neural Networks (DNNs) for XSS detection~\cite{fang2018deepxss,mokbal2019mlpxss,tekerek2021novel}.


While DNNs have shown great promise, they are vulnerable to adversarial attacks~\cite{goodfellow2014generative}, where slight changes to input data can deceive the model. These attacks have successfully compromised DNNs used for XSS attack detection as well. A reference paper by Chen et al.~\cite{CHEN2022102831} proposed a Reinforcement Learning (RL) strategy to generate XSS adversarial examples and attack state-of-the-art (SOTA) XSS attack detectors based on DNNs. Their approach involves preprocessing, tokenization, and word vector representation using the Word2Vec model~\cite{mikolov2013efficient}. The authors achieved almost perfect detection results (over 99\% accuracy) and an impressive Escape Rate (ER)\footnote{he ER represents the percentage of adversarial examples that are not detected as malicious by the detector.} of more than 90\% against all DNN-based detectors.


However, we identified several threats to validity in the work by Chen et al.~\cite{CHEN2022102831}. The first threat to validity is that the application of a sequence of actions could deteriorate the characteristics of the XSS script, and the authors did not apply any strategy to evaluate if the applied sequence of mutations is semantically preserving. The second threat is that the preprocessing pipeline of the detectors does not consider any potentially adversarial example, such that a mutation may potentially result in an out-of-vocabulary token (OOV) that is replaced by `None' in the word vector representation. As a consequence, the input  to the detector is  no longer recognized as an XSS. The last threat concerns the lack of availability of different parts of the reference work, leading to a difficult replication, evaluation, and comparison.

In this paper, we replicate Chen et al.~\cite{CHEN2022102831} using a publicly available dataset and introduce an Oracle for XSS to test the occurrence of the hypothesized threats to validity. We extend the approach towards a more effective strategy by integrating the Oracle into the training process, addressing the identified threats while preserving the effectiveness of the original method. The proposed adversarial agent achieved a performance comparable to the reference work (less than 2\% worse) while completely removing the threats to validity (more than 90\% mitigation), demonstrating a more transparent evaluation strategy and a more effective training strategy. 

The technical contributions of this paper are as follows: 
\begin{itemize}
   \item We replicate a reference work on deep reinforcement learning for XSS adversarial attacks, using publicly available data and the public release of results.
   
   \item We identify the threats to the validity of the reference work and propose a method to mitigate them.
   
   \item We extend the reference work towards a more effective evaluation strategy by introducing an XSS Oracle and integrating it into the training process, effectively addressing the identified threats to validity.
\end{itemize}


The rest of the paper is organized as follows. Section~\ref{sec:backgroud} explores the background related to XSS, Reinforcement Learning (RL), and XSS adversarial approaches, which are needed as preliminaries to understand the reference work.
Section~\ref{sec:reference} analyzes the reference work, with a focus on the possible threats to validity.
Section~\ref{sec:method} presents the proposed method, focusing on the usage of an XSS Oracle and its integration into the reference work.
Section~\ref{sec:empirical_study} describes the research questions, the experimental setting, and the process followed to replicate and extend the reference work.
Section~\ref{sec:results} analyzes the results, Section~\ref{sec:threats} describes the threats-to-validity of our work, while Section~\ref{sec:conclusion} concludes the paper.
