@article{achiam2017surprise,
  title={Surprise-based intrinsic motivation for deep reinforcement learning},
  author={Achiam, Joshua and Sastry, Shankar},
  journal={arXiv preprint arXiv:1703.01732},
  year={2017}
}

@article{aubret2019survey,
  title={A survey on intrinsic motivation in reinforcement learning},
  author={Aubret, Arthur and Matignon, Laetitia and Hassas, Salima},
  journal={arXiv preprint arXiv:1908.06976},
  year={2019}
}

@incollection{barto2013intrinsic,
  title={Intrinsic motivation and reinforcement learning},
  author={Barto, Andrew G},
  booktitle={Intrinsically motivated learning in natural and artificial systems},
  pages={17--47},
  year={2013},
  publisher={Springer}
}

@article{burda2018large,
  title={Large-scale study of curiosity-driven learning},
  author={Burda, Yuri and Edwards, Harri and Pathak, Deepak and Storkey, Amos and Darrell, Trevor and Efros, Alexei A},
  journal={arXiv preprint arXiv:1808.04355},
  year={2018}
}

@article{haber2018learning,
  title={Learning to play with intrinsically-motivated, self-aware agents},
  author={Haber, Nick and Mrowca, Damian and Wang, Stephanie and Fei-Fei, Li F and Yamins, Daniel L},
  journal={Advances in neural information processing systems},
  volume={31},
  year={2018}
}

@techreport{hawkins_why_2017,
	type = {preprint},
	title = {Why {Does} the {Neocortex} {Have} {Columns}, {A} {Theory} of {Learning} the {Structure} of the {World}},
	url = {http://biorxiv.org/lookup/doi/10.1101/162263},
	abstract = {Neocortical regions are organized into columns and layers. Connections between layers run mostly perpendicular to the surface suggesting a columnar functional organization. Some layers have long-range excitatory lateral connections suggesting interactions between columns. Similar patterns of connectivity exist in all regions but their exact role remain a mystery. In this paper, we propose a network model composed of columns and layers that performs robust object learning and recognition. Each column integrates its changing input over time to learn complete predictive models of observed objects. Excitatory lateral connections across columns allow the network to more rapidly infer objects based on the partial knowledge of adjacent columns. Because columns integrate input over time and space, the network learns models of complex objects that extend well beyond the receptive field of individual cells. Our network model introduces a new feature to cortical columns. We propose that a representation of location relative to the object being sensed is calculated within the sub-granular layers of each column. The location signal is provided as an input to the network, where it is combined with sensory data. Our model contains two layers and one or more columns. Simulations show that using Hebbian-like learning rules small single-column networks can learn to recognize hundreds of objects, with each object containing tens of features. Multi-column networks recognize objects with significantly fewer movements of the sensory receptors. Given the ubiquity of columnar and laminar connectivity patterns throughout the neocortex, we propose that columns and regions have more powerful recognition and modeling capabilities than previously assumed.},
	language = {en},
	urldate = {2021-07-25},
	institution = {Neuroscience},
	author = {Hawkins, Jeff and Ahmad, Subutai and Cui, Yuwei},
	month = jul,
	year = {2017},
	doi = {10.1101/162263},
}

@article{hole2021thousand,
  title={A thousand brains: toward biologically constrained AI},
  author={Hole, Kjell J{\o}rgen and Ahmad, Subutai},
  journal={SN Applied Sciences},
  volume={3},
  number={8},
  pages={1--14},
  year={2021},
  publisher={Springer}
}

@inproceedings{klyubin2005empowerment,
  title={Empowerment: A universal agent-centric measure of control},
  author={Klyubin, Alexander S and Polani, Daniel and Nehaniv, Chrystopher L},
  booktitle={2005 ieee congress on evolutionary computation},
  volume={1},
  pages={128--135},
  year={2005},
  organization={IEEE}
}

@article{lecun2022path,
  title={A path towards autonomous machine intelligence version 0.9. 2, 2022-06-27},
  author={LeCun, Yann},
  journal={Open Review},
  volume={62},
  year={2022}
}

@inproceedings{mittal2020learning,
  title={Learning to combine top-down and bottom-up signals in recurrent neural networks with attention over modules},
  author={Mittal, Sarthak and Lamb, Alex and Goyal, Anirudh and Voleti, Vikram and Shanahan, Murray and Lajoie, Guillaume and Mozer, Michael and Bengio, Yoshua},
  booktitle={International Conference on Machine Learning},
  pages={6972--6986},
  year={2020},
  organization={PMLR}
}

@article{mohamed2015variational,
  title={Variational information maximisation for intrinsically motivated reinforcement learning},
  author={Mohamed, Shakir and Jimenez Rezende, Danilo},
  journal={Advances in neural information processing systems},
  volume={28},
  year={2015}
}

@inproceedings{pathak2017curiosity,
  title={Curiosity-driven exploration by self-supervised prediction},
  author={Pathak, Deepak and Agrawal, Pulkit and Efros, Alexei A and Darrell, Trevor},
  booktitle={International conference on machine learning},
  pages={2778--2787},
  year={2017},
  organization={PMLR}
}

@inproceedings{pathak2019self,
  title={Self-supervised exploration via disagreement},
  author={Pathak, Deepak and Gandhi, Dhiraj and Gupta, Abhinav},
  booktitle={International conference on machine learning},
  pages={5062--5071},
  year={2019},
  organization={PMLR}
}

@inproceedings{sequeira2011emotion,
  title={Emotion-based intrinsic motivation for reinforcement learning agents},
  author={Sequeira, Pedro and Melo, Francisco S and Paiva, Ana},
  booktitle={International conference on affective computing and intelligent interaction},
  pages={326--336},
  year={2011},
  organization={Springer}
}

@article{singh2010intrinsically,
  title={Intrinsically motivated reinforcement learning: An evolutionary perspective},
  author={Singh, Satinder and Lewis, Richard L and Barto, Andrew G and Sorg, Jonathan},
  journal={IEEE Transactions on Autonomous Mental Development},
  volume={2},
  number={2},
  pages={70--82},
  year={2010},
  publisher={IEEE}
}

@article{stadie2015incentivizing,
  title={Incentivizing exploration in reinforcement learning with deep predictive models},
  author={Stadie, Bradly C and Levine, Sergey and Abbeel, Pieter},
  journal={arXiv preprint arXiv:1507.00814},
  year={2015}
}

