\section{Literature Review}
\paragraph{Adversarial Attacks (AA).}
AAs vary between white-box attacks, where the attacker has full knowledge of the neural network and black-box attacks, where they have limited, or no, such knowledge. The latter include, e.g., Zeroth Order Optimization (ZOO) ____, Boundary Attack ____, and Query-limited Attack ____. Of more relevance to us are the former attacks, originally focused on the \emph{pointwise} \(l_{p}\)-bounded image distortions, including Fast Gradient Sign Method (FGSM) ____, Projected Gradient Descent (PGD) ____, CW attack ____. A useful benchmark for \(l_{p}\)-robustness of neural networks is provided by AutoAttack ____, an ensemble of various attack methods. More recently, a broader class of \emph{distributional threats} has been considered, see ____, and ____ proposed the first AA associated to such threats using Wasserstein distances. 

\paragraph{Adversarial Training.}
A variety of adversarial training methods, designed to withstand AAs,  have been introduced, including data augmentation, loss regularization, parameter fine-tuning, etc. 
To augment the training data, researchers have used adversarial examples, generated with AAs, see ____, as well as random modifications, e.g., using generative models such as GANs and diffusion models, see ____. 
____ consider the trade-off between robustness and accuracy of a neural network via TRADES, a regularized loss. Analogous research includes MART ____ and SCORE ____. 
Loss regularization methods, e.g., adversarial weight perturbation ____, have been shown to smooth the loss landscape and improve the robustness. 
In addition, various training techniques can be overlaid to improve robustness, including drop-out layers, early stopping and parameter fine-tuning ____.
Among various robust training methods, ____ are directly related to our work as they employ Wasserstein penalization and constraint respectively. In contrast, we use sensitivity analysis of ____, to design novel robust training methods. Conceptually close to our work is the adversarial distributional training (ADT) of ____ with the key difference that we employ Wasserstein distances instead of an entropic regularization. 


\paragraph{Distributionally Robust Optimization (DRO).}
DRO provides a unifying language across many papers mentioned above. 
Mathematical formulation involves a min-max problem
\begin{equation}
    \label{eqn-dro}
    \inf_{\theta\in \Theta} \sup_{Q\in\scrP} \E_{Q}[f_{\theta}(Z)],
\end{equation}
where we minimize the worst-case loss over all possible distributions \(Q\in\scrP\). 
In financial economics, such criteria appear in the context of multi-prior preferences, see ____. We refer to ____ for a survey of the DRO. 

Here, we focus on the ambiguity set \(\scrP=B_{\delta}(P)\) given by a ball centered at the reference distribution \(P\) with radius \(\delta\) in the Wasserstein distance, and refer to ____ for a discussion of many advantages of this optimal-transport induced distance compared to other, e.g., divergence based, metrics. Importantly for capturing data perturbations, measures with different supports can be close in Wasserstein distance, see ____. Traditional \emph{pointwise} adversarial training can be seen as a special case of Wasserstein DRO (W-DRO) problem, ____.
More recently, ____ unified various classical adversarial training methods, such as PGD-AT, TRADES, and MART, under the W-DRO framework. We also mention ____ who used W-DRO to improve network performance on unseen data distributions.  

W-DRO, while very compelling, comes at a cost of an optimization over the space of probability measures, often intractable and/or computationally prohibitively expensive. To address this, one can use convex duality to rewrite \eqref{eqn-dro}, changing the $\sup$ to a univariate $\inf$ featuring a transform of $f_\theta$, see ____ for the data-driven case, ____ for general probability measures and ____ for a further application with coresets. Another approach, pioneered in ____, considers the first order approximation to the original W-DRO problem in the size of the uncertainty radius $\delta$. It was recently employed in ____ to devise distributional AAs, and we use it here to construct novel robust training methods. 

\paragraph{Fine-tuning.} \label{subsec:finetuning-litreview}
Fine-tuning, in which an already trained model undergoes a limited additional training, often plays an important role in ML applications. 
In particular, a widely adopted strategy in transfer learning is to fine-tune only the final layers of a large pre-trained model, leaving earlier layers frozen. This approach is used not only in robustness tasks, but also in a broad range of scenarios such as domain adaptation ____ and continual learning ____.
Recent work has shown that fine-tuning can substantially improve both standard and adversarial robustness of large pre-trained models ____. 
By \emph{randomizing} (or re-initializing) the last layer while freezing previous layers, one effectively learns a new ``head'' on top of features that were trained for robustness ____. 
Such partial re-initialization can avoid catastrophic forgetting of already-acquired robust representations ____, while still adapting to new threats, including distributional attacks considered in this paper. 
Empirical results suggest that this strategy promotes better generalization in low-data regimes and helps preserve robust features, as noise or domain shifts are mainly absorbed by the newly learned final layer ____. Furthermore, combining randomization of the last layer with additional regularization (for instance, adversarial weight perturbations or loss smoothing) can reduce overfitting and stabilize fine-tuning ____. 
These observations align with the methods introduced in this paper, where we selectively re-initialize the final layer, or apply minimal random perturbations to all layers, to enhance distributional robustness while preserving core capabilities learned through previous training.