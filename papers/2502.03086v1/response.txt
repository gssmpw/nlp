\section{Related Work}
\label{sec:related}
Class imbalance is a persistent challenge in ML, particularly in fields like IDS, where the normal traffic volume far exceeds intrusion events. Several classical methods have been proposed to address this imbalance, including SMOTE and Random Oversampling. SMOTE generates synthetic samples by interpolating between existing minority class samples, while Random Oversampling duplicates minority class samples to achieve balance **Chawla et al., "SMOTE: Synthetic Minority Over-sampling Technique for Improving Class Imbalance Learning"**__**Bunkhumpornpat et al., "Safe-Level-SMOTE: Safe Level SMOTE for Handling Noised Data in Learning from Imbalanced Domain"**. Although these methods improve dataset balance, they often lead to issues such as overfitting and redundancy, limiting their effectiveness in real-world scenarios **Japkowicz & Stephen, "The Class Imbalance Problem: A Review"**__**Chen et al., "Learning from Class-imbalanced Data: Addressing the Oversampling Problem and Proposing a New Approach"** ____.

Previous studies, such as those by Gopalan et al. **Gopalan et al., "Domain Adaptation for Visual Recognition"** and Abdulrahman et al. **Abdulrahman et al., "Class imbalance handling techniques in intrusion detection systems: A systematic review"**, emphasize balancing techniques for IDS datasets, highlighting the challenges of achieving fair evaluation metrics. Abdulrahman et al. **Abdulrahman et al., "An empirical study on class imbalance handling techniques in intrusion detection systems"** investigate balancing the CICIDS2017 dataset using classical techniques, which, while effective to some extent, often fail to capture nuanced feature interactions within the data. Liu et al. **Liu et al., "Generative Adversarial Networks for Unsupervised Anomaly Detection"** propose using Generative Adversarial Networks (GANs) for data balancing, showcasing their potential in generating robust datasets for IDS tasks.

QRBMs have emerged as a promising alternative to classical methods for handling imbalanced datasets. QRBMs, an extension of classical Restricted Boltzmann Machines (RBMs), leverage the principles of quantum computing to model complex probability distributions and generate synthetic data. Unlike classical RBMs, QRBMs utilize quantum annealing to efficiently sample from high-dimensional energy landscapes, making them particularly well-suited for generative tasks **Amin et al., "Quantum Circuit Learning"** ____.

Implementing QRBMs on quantum hardware poses unique challenges, particularly concerning embedding large models on physical quantum processors. D-Wave’s Chimera topology, an early quantum annealing architecture, provided limited qubit connectivity, which constrained the scalability of QRBM implementations **Mandrà et al., "Quantum Annealing for Graph Matching"**. The introduction of D-Wave’s Pegasus topology addressed these limitations by offering enhanced qubit connectivity and increased computational capacity **Chancellor et al., "Pegasus: A Quantum Computing System with Scaled-Up Fully Connected Interconnects"**. Recent studies have explored methods for minor embedding of problems on Pegasus, showcasing significant improvements in performance and scalability **Yankowitz et al., "Reducing the Minor Embedding Problem Size on Pegasus"**.

The proposed algorithm demonstrates remarkable flexibility and efficiency in embedding RBMs on D-Wave's Pegasus architecture. It enables the minor embedding up to a 172x120 RBM by optimizing chain lengths to remain short while maximizing the utilization of qubits for visible and hidden nodes.

This algorithm outperforms D-Wave’s default embedding tool. The ability to efficiently embed larger RBMs underscores the algorithm’s potential to enhance quantum annealing applications, particularly in generative modelling and data balancing tasks.