% This must be in the first 5 lines to tell arXiv to use pdfLaTeX, which is strongly recommended.
\pdfoutput=1
% In particular, the hyperref package requires pdfLaTeX in order to break URLs across lines.

%https://tex.stackexchange.com/questions/83101/option-clash-for-package-xcolor
\PassOptionsToPackage{table,dvipsnames}{xcolor}

\documentclass[11pt]{article}

% Change "review" to "final" to generate the final (sometimes called camera-ready) version.
% Change to "preprint" to generate a non-anonymous version with page numbers.
%\usepackage[review]{acl}
\usepackage{acl}

% Standard package includes
\usepackage{times}
\usepackage{latexsym}

% For proper rendering and hyphenation of words containing Latin characters (including in bib files)
\usepackage[T1]{fontenc}
% For Vietnamese characters
% \usepackage[T5]{fontenc}
% See https://www.latex-project.org/help/documentation/encguide.pdf for other character sets

% This assumes your files are encoded as UTF8
\usepackage[utf8]{inputenc}

% This is not strictly necessary, and may be commented out,
% but it will improve the layout of the manuscript,
% and will typically save some space.
\usepackage{microtype}

% This is also not strictly necessary, and may be commented out.
% However, it will improve the aesthetics of text in
% the typewriter font.
\usepackage{inconsolata}

% If the title and author information does not fit in the area allocated, uncomment the following
%
%\setlength\titlebox{<dim>}
%
% and set <dim> to something 5cm or larger.

%Including images in your LaTeX document requires adding
%additional package(s)
\usepackage{listings}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{booktabs}
\usepackage{comment}
\usepackage{multirow}
\usepackage{fdsymbol} % For author marks
\usepackage[normalem]{ulem} % for underlining
\useunder{\uline}{\ul}{}
\usepackage{tabularray}

% Define the style for JSON
\lstdefinestyle{jsonstyle}{
    basicstyle=\ttfamily\footnotesize,
    stringstyle=\color{red},
    stepnumber=1,
    showstringspaces=false,
    breaklines=true,
    frame=single,
    backgroundcolor=\color{Gray!30},
    string=[s]{"}{"},
    comment=[l]{:\ "},
    morecomment=[l]{:"},
    literate=
     *{0}{{{\color{blue}0}}}{1}
      {1}{{{\color{blue}1}}}{1}
      {2}{{{\color{blue}2}}}{1}
      {3}{{{\color{blue}3}}}{1}
      {4}{{{\color{blue}4}}}{1}
      {5}{{{\color{blue}5}}}{1}
      {6}{{{\color{blue}6}}}{1}
      {7}{{{\color{blue}7}}}{1}
      {8}{{{\color{blue}8}}}{1}
      {9}{{{\color{blue}9}}}{1}
      {:}{{{\color{purple}:}}}{1}
      {,}{{{\color{purple},}}}{1}
      {\{}{{{\color{orange}\{}}}{1}
      {\}}{{{\color{orange}\}}}}{1}
      {[}{{{\color{orange}[}}}{1}
      {]}{{{\color{orange}]}}}{1},
}
% Define the style for JSON
\lstdefinestyle{textstyle}{
    basicstyle=\ttfamily\footnotesize,
    stringstyle=\color{Cerulean},
    stepnumber=1,
    showstringspaces=false,
    breaklines=true,
    backgroundcolor=\color{GreenYellow!15},
    string=[s]{\#}{:},
    comment=[l]{:\ "},
    tabsize=1,
    morecomment=[l]{:"},
    literate=
     *{0}{{{\color{blue}0}}}{1}
      {1}{{{\color{blue}1}}}{1}
      {2}{{{\color{blue}2}}}{1}
      {3}{{{\color{blue}3}}}{1}
      {4}{{{\color{blue}4}}}{1}
      {5}{{{\color{blue}5}}}{1}
      {6}{{{\color{blue}6}}}{1}
      {7}{{{\color{blue}7}}}{1}
      {8}{{{\color{blue}8}}}{1}
      {9}{{{\color{blue}9}}}{1}
      {:}{{{\color{purple}:}}}{1}
      {,}{{{\color{purple},}}}{1}
      {\{}{{{\color{orange}\{}}}{1}
      {\}}{{{\color{orange}\}}}}{1}
      {[}{{{\color{orange}[}}}{1}
      {]}{{{\color{orange}]}}}{1},
}
\lstdefinestyle{reviews}{
    basicstyle=\ttfamily\footnotesize,
    stepnumber=1,
    showstringspaces=false,
    breaklines=true,
    frame=single,
    backgroundcolor=\color{GreenYellow!15},
    string=[s]{"}{"},
    stringstyle=\color{red},
    comment=[s]{:\ "}{"},
    commentstyle=\color{green!50!black}
}

\title{eC-Tab2Text: Aspect-Based Text Generation from e-Commerce \\Product Tables}

\author{
Luis Antonio Gutiérrez Guanilo$^{\clubsuit}$ \enspace Mir Tafseer Nayeem$^{\vardiamondsuit}$\thanks{\ Corresponding authors.}  \\ 
\bf Cristian López$^{\clubsuit}$ \enspace Davood Rafiei$^{\vardiamondsuit}$\footnotemark[1] \\
$^{\clubsuit}$University of Engineering and Technology (UTEC) \enspace 
$^{\vardiamondsuit}$University of Alberta\\
\texttt{\{mnayeem, drafiei\}@ualberta.ca} \enspace  \enspace \texttt{\{luis.gutierrez.g, clopezd\}@utec.edu.pe} \\
}


\begin{document}
\maketitle

\begin{abstract}
Large Language Models (LLMs) have demonstrated exceptional versatility across diverse domains, yet their application in e-commerce remains underexplored due to a lack of domain-specific datasets. To address this gap, we introduce \textbf{eC-Tab2Text}, a novel dataset designed to capture the intricacies of e-commerce, including detailed product attributes and user-specific queries. Leveraging eC-Tab2Text, we focus on text generation from product tables, enabling LLMs to produce high-quality, attribute-specific product reviews from structured tabular data. Fine-tuned models were rigorously evaluated using standard Table2Text metrics, alongside correctness, faithfulness, and fluency assessments. Our results demonstrate substantial improvements in generating contextually accurate reviews, highlighting the transformative potential of tailored datasets and fine-tuning methodologies in optimizing e-commerce workflows. This work highlights the potential of LLMs in e-commerce workflows and the essential role of domain-specific datasets in tailoring them to industry-specific challenges\footnote{Our code, dataset, evaluation, model outputs, and other resources are publicly available at \href{https://github.com/Luis-ntonio/eC-Tab2Text}{eC-Tab2Text}.
%for research purposes.
}.
\end{abstract}

\begin{figure}[t]
    \centering
    \includegraphics[scale = 0.56]{figures/task-def.pdf}
    \caption{Overview of \textbf{eC-Tab2Text}. Illustration of aspect-based text generation from e-commerce product tables, where an LLM generates summaries for user-specific aspects like ``Camera'' and ``Design \& Display.''}
    \label{fig:task-def}
\end{figure}

\section{Introduction}
E-commerce relies heavily on tabular data, such as product details and features, while user interactions, including assistant agents and Q\&A, predominantly occur in natural language. This disparity underscores the need for models that can effectively parse tabular data and engage users through coherent, context-aware communication \cite{zhao-etal-2023-investigating}.
%
Table-to-text generation addresses this challenge by transforming structured data into natural language, enabling applications such as product reviews, personalized descriptions, and tailored summaries in e-commerce. Beyond e-commerce, this capacity extends to domains such as healthcare, where structured patient records are converted into concise summaries for doctors \cite{he2023survey}, and finance, where tabular financial data is transformed into analytical reports \cite{Varshney_2024}. However, generating text that is coherent, contextually relevant, and aligned with user-specific requirements remains a significant challenge, particularly for user- or query-centric tasks that demand domain-specific knowledge.
% 
Existing table-to-text datasets often focus on general-purpose applications and lack the depth required for specialized domains. % like product reviews \cite{macková2023promapdatasetsproductmapping}. 
For instance, datasets like QTSumm \cite{zhao2023qtsummqueryfocusedsummarizationtabular} offer tabular summaries unrelated to the product domain, limiting their relevance for generating attribute-specific product reviews. E-commerce text generation requires handling diverse attributes (e.g., battery life, display quality), reasoning across different attributes (e.g., battery life and display size) and adapting to various user intents, such as crafting targeted product reviews \cite{macková2023promapdatasetsproductmapping}. 

\input{tables/datasets}

While Large Language Models (LLMs) excel in general-purpose text generation \cite{touvron2023llama, kabir-etal-2024-benllm}, and fine-tuned models like \texttt{LLama2} \cite{touvron2023llama}, resulting in \texttt{StructLM} \cite{zhuang2024structlm} have shown improved performance on table-based datasets, these approaches often struggle with the complexities of product-specific domains. Addressing these intricacies requires tailored datasets to capture the nuanced requirements of attribute-specific text generation. Table-to-text generation has benefited from datasets like WikiTableT \cite{chen2021wikitabletlargescaledatatotextdataset}, TabFact \cite{2019TabFactA}, and ROTOWIRE \cite{wiseman2017challengesdatatodocumentgeneration}.
%, which offer structured data and annotated summaries.  WikiTableT focuses on generating descriptions from Wikipedia tables, TabFact supports fact-checking, and ROTOWIRE generates sports summaries. 
However, these datasets, designed for tasks like Wikipedia table descriptions, fact-checking, and sports summaries, lack the relevance for product-specific applications. Similarly,  LogicNLG \cite{chen2020logicalnaturallanguagegeneration} and ToTTo \cite{parikh2020tottocontrolledtabletotextgeneration} emphasize logical inferences and refined sentence extraction but fall short in addressing the demands of e-commerce text generation \cite{He2023ReviewOS}.

This paper introduces a tailored table-to-text dataset for the products domain and explores the potential of fine-tuned LLMs to bridge the gap between general-purpose capabilities and domain-specific needs. By leveraging domain-specific datasets and fine-tuning techniques, this work aims to empower e-commerce platforms to generate more precise and engaging product reviews given user aspects and tables (see Figure \ref{fig:task-def}), enhancing customer satisfaction and business outcomes.


Our main contributions are as follows: 

\begin{itemize}
    \item We present \textbf{eC-Tab2Text}, a novel domain-specific dataset for table-to-text generation in the e-commerce domain. The dataset features attribute-rich product tables paired with user-specific queries and outputs.
        
    \item We fine-tune open-source LLMs on the \textbf{eC-Tab2Text} dataset, resulting in significant improvements in text generation performance across various metrics. %using JSON-based table serialization techniques. This fine-tuning 
        
    \item We provide a detailed analysis of domain robustness by comparing models trained on \textbf{eC-Tab2Text} with those trained on QTSumm, highlighting the critical need for domain-specific datasets to achieve superior performance in e-commerce applications.
\end{itemize}



\section{Related Work}

\paragraph{Table-to-Text Generation} 
Table-to-text generation has advanced through datasets tailored to diverse domains and applications, as summarized in Table \ref{tab:datasets}. Early efforts, such as WikiTableT \cite{chen2021wikitabletlargescaledatatotextdataset}, focused on generating natural language descriptions from Wikipedia tables, while TabFact \cite{2019TabFactA} introduced fact-checking capabilities and ROTOWIRE \cite{wiseman2017challengesdatatodocumentgeneration} generated detailed sports summaries. However, these datasets are limited in their relevance to product-specific domains. Later datasets like LogicNLG \cite{chen2020logicalnaturallanguagegeneration} emphasized logical inference and reasoning, and ToTTo \cite{parikh2020tottocontrolledtabletotextgeneration} supported controlled text generation by focusing on specific table regions. HiTab \cite{cheng-etal-2022-hitab} extended these capabilities with hierarchical table structures and reasoning operators. Despite these advancements, none of these datasets provide the contextual and attribute-specific depth necessary for e-commerce applications, where generating meaningful descriptions requires reasoning across heterogeneous attributes, such as linking battery capacity to battery life or associating display size with user experience. 


\paragraph{Query-Focused Summarization (QFS)} 
Advances in text summarization have improved multi-document summarization through abstractive methods like paraphrastic fusion \cite{10.1145/3132847.3133106, nayeem-etal-2018-abstractive}, compression \cite{10.1007/978-3-030-15719-7_14, chowdhury-etal-2021-unsupervised}, and diverse fusion models \cite{FUAD2019216, nayeem2017methods}, among others \cite{nayeem-chali-2017-extract, chali-etal-2017-towards}. These approaches lay the groundwork for query-focused summarization (QFS), which tailors summaries to user-specific queries. Initially formulated as a document summarization task, QFS aims to generate summaries tailored to specific user queries \cite{dang-2006-duc}. Despite its potential real-world applications, QFS remains a challenging task due to the lack of datasets. In the textual domain, QFS has been explored in multi-document settings \cite{giorgi-etal-2023-open} and meeting summarization \cite{zhong-etal-2021-qmsum}. Recent datasets like QTSumm \cite{zhao2023qtsummqueryfocusedsummarizationtabular} extend QFS to a new modality, using tables as input. However, QTSumm's general-purpose nature limits its applicability to product reviews, which require nuanced reasoning over attributes and user-specific contexts. Additionally, its queries are often disconnected from real-world e-commerce scenarios. In contrast, our proposed dataset, \textbf{eC-Tab2Text}, bridges this gap by providing attribute-specific and query-driven summaries tailored to e-commerce product tables. 



\section{eC-Tab2Text: Dataset Construction}
\label{sec:dataset-contruction}

To address the gap in table-to-text generation for user-specific aspects or queries, such as ``Camera'' and ``Design \& Display'' (as illustrated in Figure \ref{fig:task-def}), we developed the \textbf{eC-Tab2Text} dataset. This dataset comprises e-commerce product tables and is designed to facilitate aspect-based text generation by fine-tuning LLMs on our dataset. The pipeline for creating \textbf{eC-Tab2Text} is outlined in Figure \ref{fig:data-pipeline} and described in detail below.


\begin{figure*}[t] 
    \centering
    \includegraphics[scale = 0.64]{figures/eC-Tab2Text.pdf} 
    \caption{Data collection pipeline for our \textbf{eC-Tab2Text} dataset.}
    \label{fig:data-pipeline} 
\end{figure*}

\paragraph{Data Sources} 
The dataset was constructed using product reviews and specifications (i.e., tables) extracted from the Pricebaba website\footnote{\url{https://pricebaba.com}, last accessed August 2024.}. Pricebaba provides comprehensive information on electronic products, including mobile phones and laptops. For this study, the focus was exclusively on mobile phone data due to the richness of product specifications (attribute-value pairs) and the availability of detailed expert reviews as summaries. Additionally, the number of samples available for mobile phones is significantly larger than for laptops. Each sample includes feature-specific details such as camera performance, battery life, and display quality.


\paragraph{Data Extraction and Format} 
Data extraction was performed using web scraping techniques, with the extracted data stored in JSON format to serialize the table structure and to ensure compatibility with modern data processing workflows. Two JSON files were generated (Appendix \ref{Appendix: eC-Tab2Text Data Collection}): one containing aspect-based product reviews and the other containing product specifications. The review JSON file captures user aspects alongside their associated textual descriptions collected from the ``Quick Review'' section of the website, while the specifications JSON file stores key-value pairs for both key specifications and full technical details. The structures of the sample inputs and outputs are depicted in Figures \ref{fig:pricebaba-review-structure} and \ref{fig:pricebaba-spec-structure} in the Appendix.

\paragraph{Data Cleaning, Normalization, and Integration} 
To ensure consistency, usability, and completeness, the extracted data underwent rigorous cleaning, normalization, and integration, similar to previous approaches \cite{nayeem-rafiei-2023-role, nayeem-rafiei-2024-kidlm, nayeem2024lfosum}. The process includes \textbf{(1)} standardizing all text values to lowercase for uniformity, \textbf{(2)} replacing special characters (e.g., \texttt{\&} with ``and'') to improve readability, and \textbf{(3)} normalizing keys to maintain logical and contextual coherence.
For example, the key \texttt{Display \& Design} was transformed into \texttt{Design and Display} to improve readability and alignment with naming conventions.

To further enhance the dataset quality, irrelevant and redundant entries were removed through a systematic filtering process: \textbf{(1)} reviews lacking textual content in the text field were discarded, \textbf{(2)} specifications containing only generic or minimal information (e.g., entries labeled as  \texttt{General}) were excluded, \textbf{(3)} overly simplistic reviews categorized as \texttt{Overview} were omited to maintain a focus on detailed and meaningful content.

Finally, the reviews and specifications JSON files were merged into a unified dataset by aligning entries based on their unique product URLs. This integration consolidated each product's reviews and specifications into a single, cohesive record, creating a streamlined and comprehensive dataset for downstream applications.


\input{tables/eC-Tab2Text-statistics}

%\paragraph{eC-Tab2Text Statistics}

Our \textbf{eC-Tab2Text} dataset provides a comprehensive resource for table-to-text generation tasks based on user queries, as summarized in Table~\ref{table:eC-Tab2Text-statistics}. The input JSON files contain attribute-rich product specifications, averaging 59.8 attribute-value pairs per table, with the largest entries containing up to 68 pairs. The dataset includes 3,354 queries, averaging 2.31 queries per table, with concise outputs averaging 56.61 words per query. This design supports query-specific training and evaluation of LLMs, enabling precise and contextually relevant text generation tailored to user queries.


\section{eC-Tab2Text: Models}
\label{sec:models}

This section outlines the methodology for table serialization and provides details on the selection and fine-tuning of LLMs using our dataset.

\paragraph{Table Serialization} 
The representation of tabular data in machine learning has been addressed through various serialization techniques, including markdown format, comma-separated values (CSV), HTML \cite{fang2024large, singha2023tabular}, and LaTeX \cite{jaitly2023betterserializationtabulardata}. However, for our specific problem involving semi-structured tables with nested structures, we adopt JSON serialization. This approach effectively addresses two critical needs: \textbf{(1)} representing the nested structures inherent in product tables and \textbf{(2)} enabling query-specific generation and evaluation \cite{gao2024jsontuninggeneralizablerobustcontrollable}.

In our eC-Tab2Text dataset, both input tables and query-specific outputs are serialized using JSON. The input JSON captures structured product specifications, while the output JSON aligns queries (e.g., ``Design and Display'' or ``Battery'') as keys and their corresponding generated texts as values. This unified representation facilitates efficient querying and maintains alignment between inputs and outputs, ensuring consistency across the dataset. Additional implementation details can be found in Appendix \ref{appendix:fine-tuning-models} (Listing \ref{code:Prompt Dataset 1} prompt).

\paragraph{Model Selection and Characteristics} 
To evaluate the effectiveness of the eC-Tab2Text dataset, we fine-tuned three open-source LLMs: \textbf{LLaMA 2-Chat 7B} \cite{touvron2023llama}, \textbf{Mistral 7B-Instruct} \cite{jiang2023mistral}, and \textbf{StructLM 7B} \cite{zhuang2024structlm}. These models were selected due to their distinct pretraining paradigms, which address diverse data modalities and tasks. Detailed descriptions of these models are provided in Appendix \ref{sec:fine-tuning-models} and summarized below.

\begin{itemize}
    \item \textbf{LLaMA 2-Chat 7B}\footnote{\href{https://huggingface.co/meta-llama/Llama-2-7b-chat-hf}{Llama-2-7b-chat-hf}}: This model, pretrained on 2 trillion tokens of publicly available text data, is fine-tuned on over one million human-annotated examples. It excels in general-purpose conversational and language understanding tasks \cite{touvron2023llama}.
    \item \textbf{Mistral 7B-Instruct}\footnote{\href{https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.3}{Mistral-7B-Instruct-v0.3}}: Leveraging a mix of text and code during training, this model demonstrates strong performance in tasks that require natural language understanding and programming-related reasoning \cite{jiang2023mistral}.
    \item \textbf{StructLM 7B}\footnote{\href{https://huggingface.co/TIGER-Lab/StructLM-7B}{StructLM-7B }}: Pretrained on structured data, including databases, tables, and knowledge graphs, StructLM is optimized for structured knowledge grounding, making it particularly effective for domain-specific tasks \cite{zhuang2024structlm}.
\end{itemize}

\paragraph{Fine-Tuning Process} 
The fine-tuning process adapts these models to the e-commerce domain using the eC-Tab2Text dataset. This dataset focuses on attribute-specific and context-aware text generation tailored to user queries, such as detailed reviews of ``Camera'' or ``Design \& Display.'' The fine-tuning process follows best practices in instruction tuning and domain-specific dataset alignment \cite{Zhang2023InstructionTF, Chang2023ASO}. Optimization of hyperparameters ensured computational efficiency while maintaining high-quality performance, as detailed Table~\ref{table:hyperparameters}. 

By leveraging these diverse models and aligning them with the eC-Tab2Text dataset, this work aims to advance the state-of-the-art in domain-specific language generation for e-commerce applications.

\input{tables/app-qtsumm-structure}
\input{tables/hyperparameters}
\input{tables/app-parameters}


\section{Evaluation} 
\label{sec:evaluation}


\input{tables/main-results}

\input{tables/robustness-results}

In this section, we evaluate the performance of the eC-Tab2Text models described in Section \ref{sec:models} along with several closed-source models, including GPT-4o-mini and Gemini-1.5-flash. The evaluation follows standard metrics commonly used in table-to-text generation, as outlined in \cite{zhao2023qtsummqueryfocusedsummarizationtabular}. These metrics include BLEU \cite{Reiter2018A}, the F-1 scores of ROUGE-1 and ROUGE-L \cite{Ganesan2015ROUGE}, METEOR \cite{Dobre2015ACB}, and BERTScore \cite{zhang2020bertscoreevaluatingtextgeneration}, following \cite{akash-etal-2023-shironaam, shohan-etal-2024-xl}. To assess the correctness, faithfulness, and fluency of the generated text, we employ PROMETHEUS 2 \cite{kim2024prometheus2opensource} and an open-source LLM-based evaluator as an alternative to the closed-source G-Eval \cite{liu2023gevalnlgevaluationusing}. Our objective is to benchmark the performance of various LLMs under both zero-shot and fine-tuned settings using the proposed eC-Tab2Text dataset. 



\paragraph{Experimental Setup} The fine-tuning process was conducted on a NVIDIA RTX 4070 Ti Super GPU with 16GB of VRAM, ensuring efficient training while managing memory-intensive operations. The AdamW optimizer \cite{loshchilov2018decoupled} was configured with a learning rate of $2\times 10^{-4}$, chosen for its effectiveness in maintaining stability and convergence during training. To optimize resource usage, the \textit{bitsandbytes} library\footnote{\url{https://github.com/bitsandbytes-foundation/bitsandbytes}} was employed for 4-bit quantization, reducing VRAM requirements without significant performance loss. Table~\ref{tab:eC-Tab2Text Aditional parameters} outlines the key parameters used, including `\texttt{float16}' for computation data type and `\texttt{nf4}' for quantization type. The `\texttt{use\_nested\_quant}' option was set to `False' to ensure compatibility across models. 



Detailed information on the evaluation metrics is included in Appendix \ref{sec:evaluation-metrics}. Our eC-Tab2Text dataset was divided into training and testing subsets, using an 80\%-20\% split. This ensures a sufficient volume of data for training while preserving a reliable subset for evaluation.



\subsection{Robustness Evaluation} 
We evaluate the robustness of the models under domain differences, focusing on their performance with in-domain and out-of-domain training data. The primary objective is to analyze how models perform when fine-tuned on data from different domains and to emphasize the importance of our proposed eC-Tab2Text dataset for the e-commerce product domain. For this evaluation, we compare the performance of models fine-tuned on the QTSumm dataset \cite{zhao2023qtsummqueryfocusedsummarizationtabular}, which contains Wikipedia tables with queries, against those fine-tuned on our eC-Tab2Text dataset, which consists of product tables with user-specific queries.

\paragraph{QTSumm Dataset Details} The QTSumm dataset, obtained from Hugging Face\footnote{\url{https://huggingface.co/datasets/yale-nlp/QTSumm}} provides structured data that facilitates query-specific text summarization tasks. The detailed structure of QTSumm is outlined in Table \ref{tab:qtsumm_structure}. This dataset's structure ensures a systematic alignment between the input queries, the corresponding structured data, and the generated summaries, making it a valuable benchmark for fine-tuning and evaluating the performance of LLMs in handling structured data. Its focus on query-specific summarization provided an excellent foundation for testing the robustness and adaptability of the proposed methodologies.


For fine-tuning, we utilized the same models described in Section \ref{sec:models}, employing identical hyperparameters. The models were trained using prompts structured consistently with those designed for the eC-Tab2Text dataset. However, in the QTSumm setup, the prompts included row-level content tailored to the dataset's structure, as outlined in Appendix \ref{appendix:fine-tuning-models} (Listing \ref{code:Prompt Dataset 2}). This alignment ensured methodological consistency while accounting for the unique characteristics of the QTSumm dataset. By highlighting these differences, our evaluation underscores the critical need for domain-specific datasets, such as eC-Tab2Text, to achieve robust and accurate performance in the 
%e-commerce 
product domain.


\subsection{Results \& Analysis}
Our experimental results, illustrated in Table~\ref{table:results1}, demonstrate that fine-tuning open-source 7B models on our dataset leads to substantial performance improvements. These fine-tuned models significantly outperform major proprietary models, such as GPT-4o-mini and Gemini-1.5-flash, across text-based metrics, including BLEU, ROUGE-1, ROUGE-L, METEOR, and BERTScore, while achieving competitive results in model-based metrics like faithfulness, correctness, and fluency, narrowing the gap with proprietary counterparts. This is significant given the relatively small size of our dataset compared to the much larger datasets used for training many proprietary models. Notably, Mistral\_Instruct, fine-tuned on our dataset, excels by achieving the highest scores across all metrics, surpassing both zero-shot and fine-tuned models. 
 

As highlighted in Table~\ref{table:results}, the robustness of our dataset is further evidenced by comparing it against the QTSUMM dataset; models trained with our dataset consistently outperform those trained on QTSUMM across both in-domain and out-of-domain tasks, with Mistral\_Instruct leading, followed closely by StructLM. Although both datasets share similar task objectives, the domain differences significantly affect the models' performance. 

Outputs generated by different open-source models are presented in Mistral (Listing \ref{code:JSON-Mistral-eC-Tab2Text}), StructLM (Listing \ref{code:JSON-StructLM}), and Llama2 (Listing \ref{code:JSON-Llama2}), as well as by closed-source models GPT-4o-mini (Listing \ref{code:JSON-GPT4}) and Gemini1.5-flash (Listing \ref{code:JSON-Gemini}). Notably, the closed-source models tend to produce longer outputs compared to the open-source models, with their outputs often containing nested keys and detailed information.


\section{Discussion and Future Directions}
\label{sec:discussion-future}

This section highlights the need for better numerical reasoning in table-to-text generation and improved evaluation methods. 
%Future work will improve LLMs' numerical reasoning and attribute-specific evaluation.

\paragraph{Numerical Reasoning} Product tables, with their semi-structured and nested attributes (e.g., battery capacity in mAh, display size in inches), demand advanced numerical reasoning to generate meaningful text. Models must analyze relationships, such as how battery life depends on capacity and display size, or how display dimensions impact user experience. Unlike Wikipedia tables \cite{zhao2023qtsummqueryfocusedsummarizationtabular, nahid-rafiei-2024-tabsqlify}, which focus on factual text generation, our eC-Tab2Text dataset challenges models to integrate numerical reasoning with qualitative text generation \cite{islam-etal-2024-large}. This unique focus enables LLMs to synthesize structured data into nuanced, human-readable summaries, providing a benchmark for evaluating and improving reasoning capabilities in real-world applications \cite{10.1145/3583780.3615172, akhtar-etal-2023-exploring, zhao-etal-2024-docmath}. Future work could explore pushing the boundaries of LLMs capabilities in numerical and qualitative reasoning using our dataset.

\paragraph{Evaluation} Although we evaluated the correctness, faithfulness, and fluency of the generated text using PROMETHEUS 2 \cite{kim2024prometheus2opensource}, attribute-specific text evaluation against product tables requires a more nuanced approach. Future evaluations could involve extracting attribute-value pairs from the generated text \cite{shinzato-etal-2023-unified, brinkmann2024extractgptexploringpotentiallarge}, verifying their correctness and contextual relevance, and comparing them with the corresponding values in the source tables to enable more fine-grained and precise assessments.

\section{Conclusion}
This work introduces \textbf{eC-Tab2Text}, a novel dataset for table-to-text generation in the e-commerce domain, addressing the limitations of existing general-purpose datasets. By fine-tuning open-source LLMs, we demonstrate substantial improvements in generating attribute-specific, contextually accurate product reviews. Our evaluation highlights the robustness of \textbf{eC-Tab2Text}, outperforming comparable datasets like QTSumm, and underscores the importance of domain-specific datasets for advancing LLM performance in industry-specific applications. This study lays the groundwork for future research in expanding dataset scope, evaluation methodologies, and enhancing numerical reasoning in e-commerce workflows.

%limitations and ethics
\input{sections/Limitations.tex}
\input{sections/Ethics.tex}
\input{sections/Acknowledgements.tex}

\bibliography{main}

\input{sections/Appendix}

\end{document}
