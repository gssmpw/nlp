% Use this file for citations not found in the ACL Anthology (contained in "anthology.bib").
@misc{banerjee2025navigatingculturalkaleidoscopehitchhikers,
      title={Navigating the Cultural Kaleidoscope: A Hitchhiker's Guide to Sensitivity in Large Language Models}, 
      author={Somnath Banerjee and Sayan Layek and Hari Shrawgi and Rajarshi Mandal and Avik Halder and Shanu Kumar and Sagnik Basu and Parag Agrawal and Rima Hazra and Animesh Mukherjee},
      year={2025},
      eprint={2410.12880},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2410.12880}, 
}


@misc{hazra2024safetyarithmeticframeworktesttime,
      title={Safety Arithmetic: A Framework for Test-time Safety Alignment of Language Models by Steering Parameters and Activations}, 
      author={Rima Hazra and Sayan Layek and Somnath Banerjee and Soujanya Poria},
      year={2024},
      eprint={2406.11801},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2406.11801}, 
}


@article{gongane2022detection,
  title={Detection and moderation of detrimental content on social media platforms: current status and future directions},
  author={Gongane, Vaishali U and Munot, Mousami V and Anuse, Alwin D},
  journal={Social Network Analysis and Mining},
  volume={12},
  number={1},
  pages={129},
  year={2022},
  publisher={Springer}
}

@article{arora23,
author = {Arora, Arnav and Nakov, Preslav and Hardalov, Momchil and Sarwar, Sheikh Muhammad and Nayak, Vibha and Dinkov, Yoan and Zlatkova, Dimitrina and Dent, Kyle and Bhatawdekar, Ameya and Bouchard, Guillaume and Augenstein, Isabelle},
title = {Detecting Harmful Content on Online Platforms: What Platforms Need vs. Where Research Efforts Go},
year = {2023},
issue_date = {March 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {56},
number = {3},
issn = {0360-0300},
url = {https://doi.org/10.1145/3603399},
doi = {10.1145/3603399},
journal = {ACM Comput. Surv.},
month = oct,
articleno = {72},
numpages = {17},
}

@article{Naslund2020,
  author = {Naslund, John A and Bondre, Ameya and Torous, John and Aschbrenner, Kelly A},
  title = {Social Media and Mental Health: Benefits, Risks, and Opportunities for Research and Practice},
  journal = {Journal of Technology in Behavioral Science},
  volume = {5},
  number = {3},
  pages = {245-257},
  year = {2020},
  month = {September},
  doi = {10.1007/s41347-020-00134-x},
  pmid = {33415185},
  pmc = {PMC7785056},
  publisher = {Springer},
}

@book{SurgeonGeneral2023,
  author = {{Office of the Surgeon General (OSG)}},
  title = {Social Media and Youth Mental Health: The U.S. Surgeon General’s Advisory},
  publisher = {US Department of Health and Human Services},
  year = {2023},
  address = {Washington, DC},
  abstract = {Social media use by youth is nearly universal. Up to 95% of youth ages 13–17 report using a social media platform, with more than a third saying they use social media “almost constantly.” Although age 13 is commonly the required minimum age used by social media platforms in the U.S., nearly 40% of children ages 8–12 use social media. Despite this widespread use among children and adolescents, robust independent safety analyses on the impact of social media on youth have not yet been conducted. There are increasing concerns among researchers, parents and caregivers, young people, healthcare experts, and others about the impact of social media on youth mental health.},
  language = {English},
  type = {Review, Book},
  pmid = {37721985},
  bookaccession = {NBK594761},
  url = {https://www.ncbi.nlm.nih.gov/books/NBK594761/}
}





@article{Ando2005,
	Acmid = {1194905},
	Author = {Ando, Rie Kubota and Zhang, Tong},
	Issn = {1532-4435},
	Issue_Date = {12/1/2005},
	Journal = {Journal of Machine Learning Research},
	Month = dec,
	Numpages = {37},
	Pages = {1817--1853},
	Publisher = {JMLR.org},
	Title = {A Framework for Learning Predictive Structures from Multiple Tasks and Unlabeled Data},
	Volume = {6},
	Year = {2005}
}

@ARTICLE{10494986,
  author={Maity, Krishanu and Poornash, A. S. and Bhattacharya, Shaubhik and Phosit, Salisa and Kongsamlit, Sawarod and Saha, Sriparna and Pasupa, Kitsuchart},
  journal={IEEE Transactions on Computational Social Systems}, 
  title={HateThaiSent: Sentiment-Aided Hate Speech Detection in Thai Language}, 
  year={2024},
  volume={11},
  number={5},
  pages={5714-5727},
  keywords={Hate speech;Social networking (online);Annotations;Feature extraction;Multitasking;COVID-19;Detection algorithms;Sentiment analysis;Capsule networks;hate speech detection (HD);multitask (MT);sentiment},
  doi={10.1109/TCSS.2024.3376958}}

@INPROCEEDINGS{10191363,
  author={Jain, Raghav and Maity, Krishanu and Jha, Prince and Saha, Sriparna},
  booktitle={2023 International Joint Conference on Neural Networks (IJCNN)}, 
  title={Generative Models vs Discriminative Models: Which Performs Better in Detecting Cyberbullying in Memes?}, 
  year={2023},
  volume={},
  number={},
  pages={1-8},
  keywords={Analytical models;Sentiment analysis;Annotations;Neural networks;Cyberbullying;Multitasking;Transformers;Cyberbullying;Multitasking;Multimodality;Natural language generation;Memes},
  doi={10.1109/IJCNN54540.2023.10191363}}

@inproceedings{jha-etal-2024-meme,
    title = "Meme-ingful Analysis: Enhanced Understanding of Cyberbullying in Memes Through Multimodal Explanations",
    author = "Jha, Prince  and
      Maity, Krishanu  and
      Jain, Raghav  and
      Verma, Apoorv  and
      Saha, Sriparna  and
      Bhattacharyya, Pushpak",
    editor = "Graham, Yvette  and
      Purver, Matthew",
    booktitle = "Proceedings of the 18th Conference of the European Chapter of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = mar,
    year = "2024",
    address = "St. Julian{'}s, Malta",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2024.eacl-long.56/",
    pages = "930--943",
    abstract = "Internet memes have gained significant influence in communicating political, psychological, and sociocultural ideas. While meme are often humorous, there has been a rise in the use of memes for trolling and cyberbullying. Although a wide variety of effective deep learning-based models have been developed for detecting offensive multimodal memes, only a few works have been done on explainability aspect. Recent laws like {\textquotedblleft}right to explanations{\textquotedblright} of General Data Protection Regulation, have spurred research in developing interpretable models rather than only focusing on performance. Motivated by this, we introduce MultiBully-Ex, the first benchmark dataset for multimodal explanation from code-mixed cyberbullying memes. Here, both visual and textual modalities are highlighted to explain why a given meme is cyberbullying. A Contrastive Language-Image Pretraining (CLIP) projection based multimodal shared-private multitask approach has been proposed for visual and textual explanation of a meme. Experimental results demonstrate that training with multimodal explanations improves performance in generating textual justifications and more accurately identifying the visual evidence supporting a decision with reliable performance improvements."
}

@misc{openai2024gpt4ocard,
      title={GPT-4o System Card}, 
      author={OpenAI and : and Aaron Hurst and Adam Lerer and Adam P. Goucher et al.},
      year={2024},
      eprint={2410.21276},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2410.21276}, 
}

@misc{geminiteam2024geminifamilyhighlycapable,
      title={Gemini: A Family of Highly Capable Multimodal Models}, 
      author={Gemini Team and Rohan Anil and Sebastian Borgeaud et al.},
      year={2024},
      eprint={2312.11805},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2312.11805}, 
}

@misc{qwen2025qwen25technicalreport,
      title={Qwen2.5 Technical Report}, 
      author={Qwen and : and An Yang and Baosong Yang and Beichen Zhang and Binyuan Hui and Bo Zheng and Bowen Yu and Chengyuan Li and Dayiheng Liu and Fei Huang and Haoran Wei and Huan Lin and Jian Yang and Jianhong Tu and Jianwei Zhang and Jianxin Yang and Jiaxi Yang and Jingren Zhou and Junyang Lin and Kai Dang and Keming Lu and Keqin Bao and Kexin Yang and Le Yu and Mei Li and Mingfeng Xue and Pei Zhang and Qin Zhu and Rui Men and Runji Lin and Tianhao Li and Tianyi Tang and Tingyu Xia and Xingzhang Ren and Xuancheng Ren and Yang Fan and Yang Su and Yichang Zhang and Yu Wan and Yuqiong Liu and Zeyu Cui and Zhenru Zhang and Zihan Qiu},
      year={2025},
      eprint={2412.15115},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2412.15115}, 
}

@inproceedings{sharma-etal-2023-memex,
    title = "{MEMEX}: Detecting Explanatory Evidence for Memes via Knowledge-Enriched Contextualization",
    author = "Sharma, Shivam  and
      S, Ramaneswaran  and
      Arora, Udit  and
      Akhtar, Md. Shad  and
      Chakraborty, Tanmoy",
    editor = "Rogers, Anna  and
      Boyd-Graber, Jordan  and
      Okazaki, Naoaki",
    booktitle = "Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = jul,
    year = "2023",
    address = "Toronto, Canada",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.acl-long.289/",
    doi = "10.18653/v1/2023.acl-long.289",
    pages = "5272--5290",
    abstract = "Memes are a powerful tool for communication over social media. Their affinity for evolving across politics, history, and sociocultural phenomena renders them an ideal vehicle for communication. To comprehend the subtle message conveyed within a meme, one must understand the relevant background that facilitates its holistic assimilation. Besides digital archiving of memes and their metadata by a few websites like knowyourmeme.com, currently, there is no efficient way to deduce a meme`s context dynamically. In this work, we propose a novel task, MEMEX - given a meme and a related document, the aim is to mine the context that succinctly explains the background of the meme. At first, we develop MCC (Meme Context Corpus), a novel dataset for MEMEX. Further, to benchmark MCC, we propose MIME (MultImodal Meme Explainer), a multimodal neural framework that uses external knowledge-enriched meme representation and a multi-level approach to capture the cross-modal semantic dependencies between the meme and the context. MIME surpasses several unimodal and multimodal systems and yields an absolute improvement of 4{\%} F1-score over the best baseline. Lastly, we conduct detailed analyses of MIME`s performance, highlighting the aspects that could lead to optimal modeling of cross-modal contextual associations."
}

@misc{agarwal2024mememqamultimodalquestionanswering,
      title={MemeMQA: Multimodal Question Answering for Memes via Rationale-Based Inferencing}, 
      author={Siddhant Agarwal and Shivam Sharma and Preslav Nakov and Tanmoy Chakraborty},
      year={2024},
      eprint={2405.11215},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2405.11215}, 
}

@inproceedings{shin-narihira-2021-transformer,
    title = "Transformer-Exclusive Cross-Modal Representation for Vision and Language",
    author = "Shin, Andrew  and
      Narihira, Takuya",
    editor = "Zong, Chengqing  and
      Xia, Fei  and
      Li, Wenjie  and
      Navigli, Roberto",
    booktitle = "Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021",
    month = aug,
    year = "2021",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.findings-acl.240/",
    doi = "10.18653/v1/2021.findings-acl.240",
    pages = "2719--2725"
}

@misc{zhang2024visionlanguagemodelsvisiontasks,
      title={Vision-Language Models for Vision Tasks: A Survey}, 
      author={Jingyi Zhang and Jiaxing Huang and Sheng Jin and Shijian Lu},
      year={2024},
      eprint={2304.00685},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2304.00685}, 
}

@misc{radford2021learningtransferablevisualmodels,
      title={Learning Transferable Visual Models From Natural Language Supervision}, 
      author={Alec Radford and Jong Wook Kim and Chris Hallacy and Aditya Ramesh and Gabriel Goh and Sandhini Agarwal and Girish Sastry and Amanda Askell and Pamela Mishkin and Jack Clark and Gretchen Krueger and Ilya Sutskever},
      year={2021},
      eprint={2103.00020},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2103.00020}, 
}

@misc{mazhar2025figurativecumcommonsenseknowledgeinfusionmultimodal,
      title={Figurative-cum-Commonsense Knowledge Infusion for Multimodal Mental Health Meme Classification}, 
      author={Abdullah Mazhar and Zuhair hasan shaik and Aseem Srivastava and Polly Ruhnke and Lavanya Vaddavalli and Sri Keshav Katragadda and Shweta Yadav and Md Shad Akhtar},
      year={2025},
      eprint={2501.15321},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2501.15321}, 
}

@misc{liu2024incontextvectorsmakingcontext,
      title={In-context Vectors: Making In Context Learning More Effective and Controllable Through Latent Space Steering}, 
      author={Sheng Liu and Haotian Ye and Lei Xing and James Zou},
      year={2024},
      eprint={2311.06668},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2311.06668}, 
}

@misc{brown2020languagemodelsfewshotlearners,
      title={Language Models are Few-Shot Learners}, 
      author={Tom B. Brown and Benjamin Mann and Nick Ryder and Melanie Subbiah and Jared Kaplan and Prafulla Dhariwal and Arvind Neelakantan and Pranav Shyam and Girish Sastry and Amanda Askell and Sandhini Agarwal and Ariel Herbert-Voss and Gretchen Krueger and Tom Henighan and Rewon Child and Aditya Ramesh and Daniel M. Ziegler and Jeffrey Wu and Clemens Winter and Christopher Hesse and Mark Chen and Eric Sigler and Mateusz Litwin and Scott Gray and Benjamin Chess and Jack Clark and Christopher Berner and Sam McCandlish and Alec Radford and Ilya Sutskever and Dario Amodei},
      year={2020},
      eprint={2005.14165},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2005.14165}, 
}

@misc{alayrac2022flamingovisuallanguagemodel,
      title={Flamingo: a Visual Language Model for Few-Shot Learning}, 
      author={Jean-Baptiste Alayrac and Jeff Donahue and Pauline Luc and Antoine Miech and Iain Barr and Yana Hasson and Karel Lenc and Arthur Mensch and Katie Millican and Malcolm Reynolds and Roman Ring and Eliza Rutherford and Serkan Cabi and Tengda Han and Zhitao Gong and Sina Samangooei and Marianne Monteiro and Jacob Menick and Sebastian Borgeaud and Andrew Brock and Aida Nematzadeh and Sahand Sharifzadeh and Mikolaj Binkowski and Ricardo Barreira and Oriol Vinyals and Andrew Zisserman and Karen Simonyan},
      year={2022},
      eprint={2204.14198},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2204.14198}, 
}

@misc{peng2024livelearnableincontextvector,
      title={LIVE: Learnable In-Context Vector for Visual Question Answering}, 
      author={Yingzhe Peng and Chenduo Hao and Xu Yang and Jiawei Peng and Xinting Hu and Xin Geng},
      year={2024},
      eprint={2406.13185},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2406.13185}, 
}

@misc{hendel2023incontextlearningcreatestask,
      title={In-Context Learning Creates Task Vectors}, 
      author={Roee Hendel and Mor Geva and Amir Globerson},
      year={2023},
      eprint={2310.15916},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2310.15916}, 
}

@misc{todd2024functionvectorslargelanguage,
      title={Function Vectors in Large Language Models}, 
      author={Eric Todd and Millicent L. Li and Arnab Sen Sharma and Aaron Mueller and Byron C. Wallace and David Bau},
      year={2024},
      eprint={2310.15213},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2310.15213}, 
}

@misc{li2023configuregoodincontextsequence,
      title={How to Configure Good In-Context Sequence for Visual Question Answering}, 
      author={Li Li and Jiawei Peng and Huiyi Chen and Chongyang Gao and Xu Yang},
      year={2023},
      eprint={2312.01571},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2312.01571}, 
}

@misc{yang2024exploringdiverseincontextconfigurations,
      title={Exploring Diverse In-Context Configurations for Image Captioning}, 
      author={Xu Yang and Yongliang Wu and Mingzhuo Yang and Haokun Chen and Xin Geng},
      year={2024},
      eprint={2305.14800},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2305.14800}, 
}

@article{Yin_2024,
   title={A survey on multimodal large language models},
   volume={11},
   ISSN={2053-714X},
   url={http://dx.doi.org/10.1093/nsr/nwae403},
   DOI={10.1093/nsr/nwae403},
   number={12},
   journal={National Science Review},
   publisher={Oxford University Press (OUP)},
   author={Yin, Shukang and Fu, Chaoyou and Zhao, Sirui and Li, Ke and Sun, Xing and Xu, Tong and Chen, Enhong},
   year={2024},
   month=nov }

@inproceedings{qian-etal-2019-benchmark,
    title = "A Benchmark Dataset for Learning to Intervene in Online Hate Speech",
    author = "Qian, Jing  and
      Bethke, Anna  and
      Liu, Yinyin  and
      Belding, Elizabeth  and
      Wang, William Yang",
    editor = "Inui, Kentaro  and
      Jiang, Jing  and
      Ng, Vincent  and
      Wan, Xiaojun",
    booktitle = "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)",
    month = nov,
    year = "2019",
    address = "Hong Kong, China",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/D19-1482/",
    doi = "10.18653/v1/D19-1482",
    pages = "4755--4764",
    abstract = "Countering online hate speech is a critical yet challenging task, but one which can be aided by the use of Natural Language Processing (NLP) techniques. Previous research has primarily focused on the development of NLP methods to automatically and effectively detect online hate speech while disregarding further action needed to calm and discourage individuals from using hate speech in the future. In addition, most existing hate speech datasets treat each post as an isolated instance, ignoring the conversational context. In this paper, we propose a novel task of generative hate speech intervention, where the goal is to automatically generate responses to intervene during online conversations that contain hate speech. As a part of this work, we introduce two fully-labeled large-scale hate speech intervention datasets collected from Gab and Reddit. These datasets provide conversation segments, hate speech labels, as well as intervention responses written by Mechanical Turk Workers. In this paper, we also analyze the datasets to understand the common intervention strategies and explore the performance of common automatic response generation methods on these new datasets to provide a benchmark for future research."
}

@misc{jha2024memeguardllmvlmbasedframework,
      title={MemeGuard: An LLM and VLM-based Framework for Advancing Content Moderation via Meme Intervention}, 
      author={Prince Jha and Raghav Jain and Konika Mandal and Aman Chadha and Sriparna Saha and Pushpak Bhattacharyya},
      year={2024},
      eprint={2406.05344},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2406.05344}, 
}

@inproceedings{10.1145/3543507.3583388,
author = {He, Bing and Ahamad, Mustaque and Kumar, Srijan},
title = {Reinforcement Learning-based Counter-Misinformation Response Generation: A Case Study of COVID-19 Vaccine Misinformation},
year = {2023},
isbn = {9781450394161},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3543507.3583388},
doi = {10.1145/3543507.3583388},
abstract = {The spread of online misinformation threatens public health, democracy, and the broader society. While professional fact-checkers form the first line of defense by fact-checking popular false claims, they do not engage directly in conversations with misinformation spreaders. On the other hand, non-expert ordinary users act as eyes-on-the-ground who proactively counter misinformation – recent research has shown that 96\% counter-misinformation responses are made by ordinary users. However, research also found that 2/3 times, these responses are rude and lack evidence. This work seeks to create a counter-misinformation response generation model to empower users to effectively correct misinformation. This objective is challenging due to the absence of datasets containing ground-truth of ideal counter-misinformation responses, and the lack of models that can generate responses backed by communication theories. In this work, we create two novel datasets of misinformation and counter-misinformation response pairs from in-the-wild social media and crowdsourcing from college-educated students. We annotate the collected data to distinguish poor from ideal responses that are factual, polite, and refute misinformation. We propose MisinfoCorrect, a reinforcement learning-based framework that learns to generate counter-misinformation responses for an input misinformation post. The model rewards the generator to increase the politeness, factuality, and refutation attitude while retaining text fluency and relevancy. Quantitative and qualitative evaluation shows that our model outperforms several baselines by generating high-quality counter-responses. This work illustrates the promise of generative text models for social good – here, to help create a safe and reliable information ecosystem. The code and data is accessible on https://github.com/claws-lab/MisinfoCorrect.},
booktitle = {Proceedings of the ACM Web Conference 2023},
pages = {2698–2709},
numpages = {12},
keywords = {misinformation, reinforcement learning, text generation},
location = {Austin, TX, USA},
series = {WWW '23}
}

@inproceedings{SchiebGoverningHS,
  title={Governing hate speech by means of counterspeech on Facebook},
  author={Carla Schieb and Mike Preuss},
  url={https://api.semanticscholar.org/CorpusID:273236574}
}

@misc{mathew2018analyzinghatecounterspeech,
      title={Analyzing the hate and counter speech accounts on Twitter}, 
      author={Binny Mathew and Navish Kumar and Ravina and Pawan Goyal and Animesh Mukherjee},
      year={2018},
      eprint={1812.02712},
      archivePrefix={arXiv},
      primaryClass={cs.SI},
      url={https://arxiv.org/abs/1812.02712}, 
}

@misc{ghosh2024exploringfrontiervisionlanguagemodels,
      title={Exploring the Frontier of Vision-Language Models: A Survey of Current Methodologies and Future Directions}, 
      author={Akash Ghosh and Arkadeep Acharya and Sriparna Saha and Vinija Jain and Aman Chadha},
      year={2024},
      eprint={2404.07214},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2404.07214}, 
}

@misc{dong2024surveyincontextlearning,
      title={A Survey on In-context Learning}, 
      author={Qingxiu Dong and Lei Li and Damai Dai and Ce Zheng and Jingyuan Ma and Rui Li and Heming Xia and Jingjing Xu and Zhiyong Wu and Tianyu Liu and Baobao Chang and Xu Sun and Lei Li and Zhifang Sui},
      year={2024},
      eprint={2301.00234},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2301.00234}, 
}

@misc{zeng2024mllmsperformtexttoimageincontext,
      title={Can MLLMs Perform Text-to-Image In-Context Learning?}, 
      author={Yuchen Zeng and Wonjun Kang and Yicong Chen and Hyung Il Koo and Kangwook Lee},
      year={2024},
      eprint={2402.01293},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2402.01293}, 
}

@misc{dettmers2023qloraefficientfinetuningquantized,
      title={QLoRA: Efficient Finetuning of Quantized LLMs}, 
      author={Tim Dettmers and Artidoro Pagnoni and Ari Holtzman and Luke Zettlemoyer},
      year={2023},
      eprint={2305.14314},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2305.14314}, 
}

@misc{wang2021comprehensivesurveyexperimentalcomparison,
      title={A Comprehensive Survey and Experimental Comparison of Graph-Based Approximate Nearest Neighbor Search}, 
      author={Mengzhao Wang and Xiaoliang Xu and Qiang Yue and Yuxiang Wang},
      year={2021},
      eprint={2101.12631},
      archivePrefix={arXiv},
      primaryClass={cs.IR},
      url={https://arxiv.org/abs/2101.12631}, 
}

@inproceedings{lin-2004-rouge,
    title = "{ROUGE}: A Package for Automatic Evaluation of Summaries",
    author = "Lin, Chin-Yew",
    booktitle = "Text Summarization Branches Out",
    month = jul,
    year = "2004",
    address = "Barcelona, Spain",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/W04-1013/",
    pages = "74--81"
}

@inproceedings{papineni-etal-2002-bleu,
    title = "{B}leu: a Method for Automatic Evaluation of Machine Translation",
    author = "Papineni, Kishore  and
      Roukos, Salim  and
      Ward, Todd  and
      Zhu, Wei-Jing",
    editor = "Isabelle, Pierre  and
      Charniak, Eugene  and
      Lin, Dekang",
    booktitle = "Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics",
    month = jul,
    year = "2002",
    address = "Philadelphia, Pennsylvania, USA",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/P02-1040/",
    doi = "10.3115/1073083.1073135",
    pages = "311--318"
}

@inproceedings{
Zhang*2020BERTScore:,
title={BERTScore: Evaluating Text Generation with BERT},
author={Tianyi Zhang* and Varsha Kishore* and Felix Wu* and Kilian Q. Weinberger and Yoav Artzi},
booktitle={International Conference on Learning Representations},
year={2020},
url={https://openreview.net/forum?id=SkeHuCVFDr}
}

@inproceedings{Rahutomo2012SemanticCS,
  title={Semantic Cosine Similarity},
  author={Faisal Rahutomo and Teruaki Kitasuka and Masayoshi Aritsugi},
  year={2012},
  url={https://api.semanticscholar.org/CorpusID:18411090}
}

@misc{banerjee2024safeinfercontextadaptivedecoding,
      title={SafeInfer: Context Adaptive Decoding Time Safety Alignment for Large Language Models}, 
      author={Somnath Banerjee and Sayan Layek and Soham Tripathy and Shanu Kumar and Animesh Mukherjee and Rima Hazra},
      year={2024},
      eprint={2406.12274},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2406.12274}, 
}

@inproceedings{saha-etal-2024-zero,
    title = "On Zero-Shot Counterspeech Generation by {LLM}s",
    author = "Saha, Punyajoy  and
      Agrawal, Aalok  and
      Jana, Abhik  and
      Biemann, Chris  and
      Mukherjee, Animesh",
    editor = "Calzolari, Nicoletta  and
      Kan, Min-Yen  and
      Hoste, Veronique  and
      Lenci, Alessandro  and
      Sakti, Sakriani  and
      Xue, Nianwen",
    booktitle = "Proceedings of the 2024 Joint International Conference on Computational Linguistics, Language Resources and Evaluation (LREC-COLING 2024)",
    month = may,
    year = "2024",
    address = "Torino, Italia",
    publisher = "ELRA and ICCL",
    url = "https://aclanthology.org/2024.lrec-main.1090/",
    pages = "12443--12454",
    abstract = "With the emergence of numerous Large Language Models (LLM), the usage of such models in various Natural Language Processing (NLP) applications is increasing extensively. Counterspeech generation is one such key task where efforts are made to develop generative models by fine-tuning LLMs with hatespeech - counterspeech pairs, but none of these attempts explores the intrinsic properties of large language models in zero-shot settings. In this work, we present a comprehensive analysis of the performances of four LLMs namely GPT-2, DialoGPT, ChatGPT and FlanT5 in zero-shot settings for counterspeech generation, which is the first of its kind. For GPT-2 and DialoGPT, we further investigate the deviation in performance with respect to the sizes (small, medium, large) of the models. On the other hand, we propose three different prompting strategies for generating different types of counterspeech and analyse the impact of such strategies on the performance of the models. Our analysis shows that there is an improvement in generation quality for two datasets (17{\%}), however the toxicity increase (25{\%}) with increase in model size. Considering type of model, GPT-2 and FlanT5 models are significantly better in terms of counterspeech quality but also have high toxicity as compared to DialoGPT. ChatGPT are much better at generating counter speech than other models across all metrics. In terms of prompting, we find that our proposed strategies help in improving counter speech generation across all the models."
}

@inproceedings{stab-etal-2018-cross,
    title = "Cross-topic Argument Mining from Heterogeneous Sources",
    author = "Stab, Christian  and
      Miller, Tristan  and
      Schiller, Benjamin  and
      Rai, Pranav  and
      Gurevych, Iryna",
    editor = "Riloff, Ellen  and
      Chiang, David  and
      Hockenmaier, Julia  and
      Tsujii, Jun{'}ichi",
    booktitle = "Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing",
    month = oct # "-" # nov,
    year = "2018",
    address = "Brussels, Belgium",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/D18-1402/",
    doi = "10.18653/v1/D18-1402",
    pages = "3664--3674",
    abstract = "Argument mining is a core technology for automating argument search in large document collections. Despite its usefulness for this task, most current approaches are designed for use only with specific text types and fall short when applied to heterogeneous texts. In this paper, we propose a new sentential annotation scheme that is reliably applicable by crowd workers to arbitrary Web texts. We source annotations for over 25,000 instances covering eight controversial topics. We show that integrating topic information into bidirectional long short-term memory networks outperforms vanilla BiLSTMs by more than 3 percentage points in F1 in two- and three-label cross-topic settings. We also show that these results can be further improved by leveraging additional data for topic relevance using multi-task learning."
}