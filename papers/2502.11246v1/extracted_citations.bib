@inproceedings{10.1145/3543507.3583388,
author = {He, Bing and Ahamad, Mustaque and Kumar, Srijan},
title = {Reinforcement Learning-based Counter-Misinformation Response Generation: A Case Study of COVID-19 Vaccine Misinformation},
year = {2023},
isbn = {9781450394161},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3543507.3583388},
doi = {10.1145/3543507.3583388},
abstract = {The spread of online misinformation threatens public health, democracy, and the broader society. While professional fact-checkers form the first line of defense by fact-checking popular false claims, they do not engage directly in conversations with misinformation spreaders. On the other hand, non-expert ordinary users act as eyes-on-the-ground who proactively counter misinformation – recent research has shown that 96\% counter-misinformation responses are made by ordinary users. However, research also found that 2/3 times, these responses are rude and lack evidence. This work seeks to create a counter-misinformation response generation model to empower users to effectively correct misinformation. This objective is challenging due to the absence of datasets containing ground-truth of ideal counter-misinformation responses, and the lack of models that can generate responses backed by communication theories. In this work, we create two novel datasets of misinformation and counter-misinformation response pairs from in-the-wild social media and crowdsourcing from college-educated students. We annotate the collected data to distinguish poor from ideal responses that are factual, polite, and refute misinformation. We propose MisinfoCorrect, a reinforcement learning-based framework that learns to generate counter-misinformation responses for an input misinformation post. The model rewards the generator to increase the politeness, factuality, and refutation attitude while retaining text fluency and relevancy. Quantitative and qualitative evaluation shows that our model outperforms several baselines by generating high-quality counter-responses. This work illustrates the promise of generative text models for social good – here, to help create a safe and reliable information ecosystem. The code and data is accessible on https://github.com/claws-lab/MisinfoCorrect.},
booktitle = {Proceedings of the ACM Web Conference 2023},
pages = {2698–2709},
numpages = {12},
keywords = {misinformation, reinforcement learning, text generation},
location = {Austin, TX, USA},
series = {WWW '23}
}

@inproceedings{SchiebGoverningHS,
  title={Governing hate speech by means of counterspeech on Facebook},
  author={Carla Schieb and Mike Preuss},
  url={https://api.semanticscholar.org/CorpusID:273236574}
}

@article{Yin_2024,
   title={A survey on multimodal large language models},
   volume={11},
   ISSN={2053-714X},
   url={http://dx.doi.org/10.1093/nsr/nwae403},
   DOI={10.1093/nsr/nwae403},
   number={12},
   journal={National Science Review},
   publisher={Oxford University Press (OUP)},
   author={Yin, Shukang and Fu, Chaoyou and Zhao, Sirui and Li, Ke and Sun, Xing and Xu, Tong and Chen, Enhong},
   year={2024},
   month=nov }

@misc{alayrac2022flamingovisuallanguagemodel,
      title={Flamingo: a Visual Language Model for Few-Shot Learning}, 
      author={Jean-Baptiste Alayrac and Jeff Donahue and Pauline Luc and Antoine Miech and Iain Barr and Yana Hasson and Karel Lenc and Arthur Mensch and Katie Millican and Malcolm Reynolds and Roman Ring and Eliza Rutherford and Serkan Cabi and Tengda Han and Zhitao Gong and Sina Samangooei and Marianne Monteiro and Jacob Menick and Sebastian Borgeaud and Andrew Brock and Aida Nematzadeh and Sahand Sharifzadeh and Mikolaj Binkowski and Ricardo Barreira and Oriol Vinyals and Andrew Zisserman and Karen Simonyan},
      year={2022},
      eprint={2204.14198},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2204.14198}, 
}

@misc{banerjee2024safeinfercontextadaptivedecoding,
      title={SafeInfer: Context Adaptive Decoding Time Safety Alignment for Large Language Models}, 
      author={Somnath Banerjee and Sayan Layek and Soham Tripathy and Shanu Kumar and Animesh Mukherjee and Rima Hazra},
      year={2024},
      eprint={2406.12274},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2406.12274}, 
}

@misc{banerjee2025navigatingculturalkaleidoscopehitchhikers,
      title={Navigating the Cultural Kaleidoscope: A Hitchhiker's Guide to Sensitivity in Large Language Models}, 
      author={Somnath Banerjee and Sayan Layek and Hari Shrawgi and Rajarshi Mandal and Avik Halder and Shanu Kumar and Sagnik Basu and Parag Agrawal and Rima Hazra and Animesh Mukherjee},
      year={2025},
      eprint={2410.12880},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2410.12880}, 
}

@misc{brown2020languagemodelsfewshotlearners,
      title={Language Models are Few-Shot Learners}, 
      author={Tom B. Brown and Benjamin Mann and Nick Ryder and Melanie Subbiah and Jared Kaplan and Prafulla Dhariwal and Arvind Neelakantan and Pranav Shyam and Girish Sastry and Amanda Askell and Sandhini Agarwal and Ariel Herbert-Voss and Gretchen Krueger and Tom Henighan and Rewon Child and Aditya Ramesh and Daniel M. Ziegler and Jeffrey Wu and Clemens Winter and Christopher Hesse and Mark Chen and Eric Sigler and Mateusz Litwin and Scott Gray and Benjamin Chess and Jack Clark and Christopher Berner and Sam McCandlish and Alec Radford and Ilya Sutskever and Dario Amodei},
      year={2020},
      eprint={2005.14165},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2005.14165}, 
}

@misc{dong2024surveyincontextlearning,
      title={A Survey on In-context Learning}, 
      author={Qingxiu Dong and Lei Li and Damai Dai and Ce Zheng and Jingyuan Ma and Rui Li and Heming Xia and Jingjing Xu and Zhiyong Wu and Tianyu Liu and Baobao Chang and Xu Sun and Lei Li and Zhifang Sui},
      year={2024},
      eprint={2301.00234},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2301.00234}, 
}

@misc{ghosh2024exploringfrontiervisionlanguagemodels,
      title={Exploring the Frontier of Vision-Language Models: A Survey of Current Methodologies and Future Directions}, 
      author={Akash Ghosh and Arkadeep Acharya and Sriparna Saha and Vinija Jain and Aman Chadha},
      year={2024},
      eprint={2404.07214},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2404.07214}, 
}

@misc{hazra2024safetyarithmeticframeworktesttime,
      title={Safety Arithmetic: A Framework for Test-time Safety Alignment of Language Models by Steering Parameters and Activations}, 
      author={Rima Hazra and Sayan Layek and Somnath Banerjee and Soujanya Poria},
      year={2024},
      eprint={2406.11801},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2406.11801}, 
}

@misc{hendel2023incontextlearningcreatestask,
      title={In-Context Learning Creates Task Vectors}, 
      author={Roee Hendel and Mor Geva and Amir Globerson},
      year={2023},
      eprint={2310.15916},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2310.15916}, 
}

@misc{jha2024memeguardllmvlmbasedframework,
      title={MemeGuard: An LLM and VLM-based Framework for Advancing Content Moderation via Meme Intervention}, 
      author={Prince Jha and Raghav Jain and Konika Mandal and Aman Chadha and Sriparna Saha and Pushpak Bhattacharyya},
      year={2024},
      eprint={2406.05344},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2406.05344}, 
}

@misc{li2023configuregoodincontextsequence,
      title={How to Configure Good In-Context Sequence for Visual Question Answering}, 
      author={Li Li and Jiawei Peng and Huiyi Chen and Chongyang Gao and Xu Yang},
      year={2023},
      eprint={2312.01571},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2312.01571}, 
}

@misc{mathew2018analyzinghatecounterspeech,
      title={Analyzing the hate and counter speech accounts on Twitter}, 
      author={Binny Mathew and Navish Kumar and Ravina and Pawan Goyal and Animesh Mukherjee},
      year={2018},
      eprint={1812.02712},
      archivePrefix={arXiv},
      primaryClass={cs.SI},
      url={https://arxiv.org/abs/1812.02712}, 
}

@misc{peng2024livelearnableincontextvector,
      title={LIVE: Learnable In-Context Vector for Visual Question Answering}, 
      author={Yingzhe Peng and Chenduo Hao and Xu Yang and Jiawei Peng and Xinting Hu and Xin Geng},
      year={2024},
      eprint={2406.13185},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2406.13185}, 
}

@inproceedings{qian-etal-2019-benchmark,
    title = "A Benchmark Dataset for Learning to Intervene in Online Hate Speech",
    author = "Qian, Jing  and
      Bethke, Anna  and
      Liu, Yinyin  and
      Belding, Elizabeth  and
      Wang, William Yang",
    editor = "Inui, Kentaro  and
      Jiang, Jing  and
      Ng, Vincent  and
      Wan, Xiaojun",
    booktitle = "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)",
    month = nov,
    year = "2019",
    address = "Hong Kong, China",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/D19-1482/",
    doi = "10.18653/v1/D19-1482",
    pages = "4755--4764",
    abstract = "Countering online hate speech is a critical yet challenging task, but one which can be aided by the use of Natural Language Processing (NLP) techniques. Previous research has primarily focused on the development of NLP methods to automatically and effectively detect online hate speech while disregarding further action needed to calm and discourage individuals from using hate speech in the future. In addition, most existing hate speech datasets treat each post as an isolated instance, ignoring the conversational context. In this paper, we propose a novel task of generative hate speech intervention, where the goal is to automatically generate responses to intervene during online conversations that contain hate speech. As a part of this work, we introduce two fully-labeled large-scale hate speech intervention datasets collected from Gab and Reddit. These datasets provide conversation segments, hate speech labels, as well as intervention responses written by Mechanical Turk Workers. In this paper, we also analyze the datasets to understand the common intervention strategies and explore the performance of common automatic response generation methods on these new datasets to provide a benchmark for future research."
}

@misc{todd2024functionvectorslargelanguage,
      title={Function Vectors in Large Language Models}, 
      author={Eric Todd and Millicent L. Li and Arnab Sen Sharma and Aaron Mueller and Byron C. Wallace and David Bau},
      year={2024},
      eprint={2310.15213},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2310.15213}, 
}

@misc{yang2024exploringdiverseincontextconfigurations,
      title={Exploring Diverse In-Context Configurations for Image Captioning}, 
      author={Xu Yang and Yongliang Wu and Mingzhuo Yang and Haokun Chen and Xin Geng},
      year={2024},
      eprint={2305.14800},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2305.14800}, 
}

