% ------- LLMs -------
% Vicuna
@misc{vicuna2023,
    title = {Vicuna: An Open-Source Chatbot Impressing GPT-4 with 90\%* ChatGPT Quality},
    url = {https://lmsys.org/blog/2023-03-30-vicuna/},
    author = {Chiang, Wei-Lin and Li, Zhuohan and Lin, Zi and Sheng, Ying and Wu, Zhanghao and Zhang, Hao and Zheng, Lianmin and Zhuang, Siyuan and Zhuang, Yonghao and Gonzalez, Joseph E. and Stoica, Ion and Xing, Eric P.},
    month = {March},
    year = {2023}
}

% LLaMa
@misc{touvron2023llamaopenefficientfoundation,
      title={LLaMA: Open and Efficient Foundation Language Models}, 
      author={Hugo Touvron and Thibaut Lavril and Gautier Izacard and Xavier Martinet and Marie-Anne Lachaux and Timothée Lacroix and Baptiste Rozière and Naman Goyal and Eric Hambro and Faisal Azhar and Aurelien Rodriguez and Armand Joulin and Edouard Grave and Guillaume Lample},
      year={2023},
      eprint={2302.13971},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2302.13971}, 
}

% Flan
@misc{chung2022scalinginstructionfinetunedlanguagemodels,
      title={Scaling Instruction-Finetuned Language Models}, 
      author={Hyung Won Chung and Le Hou and Shayne Longpre and Barret Zoph and Yi Tay and William Fedus and Yunxuan Li and Xuezhi Wang and Mostafa Dehghani and Siddhartha Brahma and Albert Webson and Shixiang Shane Gu and Zhuyun Dai and Mirac Suzgun and Xinyun Chen and Aakanksha Chowdhery and Alex Castro-Ros and Marie Pellat and Kevin Robinson and Dasha Valter and Sharan Narang and Gaurav Mishra and Adams Yu and Vincent Zhao and Yanping Huang and Andrew Dai and Hongkun Yu and Slav Petrov and Ed H. Chi and Jeff Dean and Jacob Devlin and Adam Roberts and Denny Zhou and Quoc V. Le and Jason Wei},
      year={2022},
      eprint={2210.11416},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2210.11416}, 
}

@misc{ouyang2022traininglanguagemodelsfollow,
      title={Training language models to follow instructions with human feedback}, 
      author={Long Ouyang and Jeff Wu and Xu Jiang and Diogo Almeida and Carroll L. Wainwright and Pamela Mishkin and Chong Zhang and Sandhini Agarwal and Katarina Slama and Alex Ray and John Schulman and Jacob Hilton and Fraser Kelton and Luke Miller and Maddie Simens and Amanda Askell and Peter Welinder and Paul Christiano and Jan Leike and Ryan Lowe},
      year={2022},
      eprint={2203.02155},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2203.02155}, 
}

% GPT-4
@misc{openai2024gpt4technicalreport,
      title={GPT-4 Technical Report}, 
      author={OpenAI and Josh Achiam and Steven Adler and Sandhini Agarwal and Lama Ahmad and Ilge Akkaya and Florencia Leoni Aleman and Diogo Almeida and Janko Altenschmidt and Sam Altman and Shyamal Anadkat and Red Avila and Igor Babuschkin and Suchir Balaji and Valerie Balcom and Paul Baltescu and Haiming Bao and Mohammad Bavarian and Jeff Belgum and Irwan Bello and Jake Berdine and Gabriel Bernadett-Shapiro and Christopher Berner and Lenny Bogdonoff and Oleg Boiko and Madelaine Boyd and Anna-Luisa Brakman and Greg Brockman and Tim Brooks and Miles Brundage and Kevin Button and Trevor Cai and Rosie Campbell and Andrew Cann and Brittany Carey and Chelsea Carlson and Rory Carmichael and Brooke Chan and Che Chang and Fotis Chantzis and Derek Chen and Sully Chen and Ruby Chen and Jason Chen and Mark Chen and Ben Chess and Chester Cho and Casey Chu and Hyung Won Chung and Dave Cummings and Jeremiah Currier and Yunxing Dai and Cory Decareaux and Thomas Degry and Noah Deutsch and Damien Deville and Arka Dhar and David Dohan and Steve Dowling and Sheila Dunning and Adrien Ecoffet and Atty Eleti and Tyna Eloundou and David Farhi and Liam Fedus and Niko Felix and Simón Posada Fishman and Juston Forte and Isabella Fulford and Leo Gao and Elie Georges and Christian Gibson and Vik Goel and Tarun Gogineni and Gabriel Goh and Rapha Gontijo-Lopes and Jonathan Gordon and Morgan Grafstein and Scott Gray and Ryan Greene and Joshua Gross and Shixiang Shane Gu and Yufei Guo and Chris Hallacy and Jesse Han and Jeff Harris and Yuchen He and Mike Heaton and Johannes Heidecke and Chris Hesse and Alan Hickey and Wade Hickey and Peter Hoeschele and Brandon Houghton and Kenny Hsu and Shengli Hu and Xin Hu and Joost Huizinga and Shantanu Jain and Shawn Jain and Joanne Jang and Angela Jiang and Roger Jiang and Haozhun Jin and Denny Jin and Shino Jomoto and Billie Jonn and Heewoo Jun and Tomer Kaftan and Łukasz Kaiser and Ali Kamali and Ingmar Kanitscheider and Nitish Shirish Keskar and Tabarak Khan and Logan Kilpatrick and Jong Wook Kim and Christina Kim and Yongjik Kim and Jan Hendrik Kirchner and Jamie Kiros and Matt Knight and Daniel Kokotajlo and Łukasz Kondraciuk and Andrew Kondrich and Aris Konstantinidis and Kyle Kosic and Gretchen Krueger and Vishal Kuo and Michael Lampe and Ikai Lan and Teddy Lee and Jan Leike and Jade Leung and Daniel Levy and Chak Ming Li and Rachel Lim and Molly Lin and Stephanie Lin and Mateusz Litwin and Theresa Lopez and Ryan Lowe and Patricia Lue and Anna Makanju and Kim Malfacini and Sam Manning and Todor Markov and Yaniv Markovski and Bianca Martin and Katie Mayer and Andrew Mayne and Bob McGrew and Scott Mayer McKinney and Christine McLeavey and Paul McMillan and Jake McNeil and David Medina and Aalok Mehta and Jacob Menick and Luke Metz and Andrey Mishchenko and Pamela Mishkin and Vinnie Monaco and Evan Morikawa and Daniel Mossing and Tong Mu and Mira Murati and Oleg Murk and David Mély and Ashvin Nair and Reiichiro Nakano and Rajeev Nayak and Arvind Neelakantan and Richard Ngo and Hyeonwoo Noh and Long Ouyang and Cullen O'Keefe and Jakub Pachocki and Alex Paino and Joe Palermo and Ashley Pantuliano and Giambattista Parascandolo and Joel Parish and Emy Parparita and Alex Passos and Mikhail Pavlov and Andrew Peng and Adam Perelman and Filipe de Avila Belbute Peres and Michael Petrov and Henrique Ponde de Oliveira Pinto and Michael and Pokorny and Michelle Pokrass and Vitchyr H. Pong and Tolly Powell and Alethea Power and Boris Power and Elizabeth Proehl and Raul Puri and Alec Radford and Jack Rae and Aditya Ramesh and Cameron Raymond and Francis Real and Kendra Rimbach and Carl Ross and Bob Rotsted and Henri Roussez and Nick Ryder and Mario Saltarelli and Ted Sanders and Shibani Santurkar and Girish Sastry and Heather Schmidt and David Schnurr and John Schulman and Daniel Selsam and Kyla Sheppard and Toki Sherbakov and Jessica Shieh and Sarah Shoker and Pranav Shyam and Szymon Sidor and Eric Sigler and Maddie Simens and Jordan Sitkin and Katarina Slama and Ian Sohl and Benjamin Sokolowsky and Yang Song and Natalie Staudacher and Felipe Petroski Such and Natalie Summers and Ilya Sutskever and Jie Tang and Nikolas Tezak and Madeleine B. Thompson and Phil Tillet and Amin Tootoonchian and Elizabeth Tseng and Preston Tuggle and Nick Turley and Jerry Tworek and Juan Felipe Cerón Uribe and Andrea Vallone and Arun Vijayvergiya and Chelsea Voss and Carroll Wainwright and Justin Jay Wang and Alvin Wang and Ben Wang and Jonathan Ward and Jason Wei and CJ Weinmann and Akila Welihinda and Peter Welinder and Jiayi Weng and Lilian Weng and Matt Wiethoff and Dave Willner and Clemens Winter and Samuel Wolrich and Hannah Wong and Lauren Workman and Sherwin Wu and Jeff Wu and Michael Wu and Kai Xiao and Tao Xu and Sarah Yoo and Kevin Yu and Qiming Yuan and Wojciech Zaremba and Rowan Zellers and Chong Zhang and Marvin Zhang and Shengjia Zhao and Tianhao Zheng and Juntang Zhuang and William Zhuk and Barret Zoph},
      year={2024},
      eprint={2303.08774},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2303.08774}, 
}

% LLaMA-Adapter
@misc{zhang2024llamaadapterefficientfinetuninglanguage,
      title={LLaMA-Adapter: Efficient Fine-tuning of Language Models with Zero-init Attention}, 
      author={Renrui Zhang and Jiaming Han and Chris Liu and Peng Gao and Aojun Zhou and Xiangfei Hu and Shilin Yan and Pan Lu and Hongsheng Li and Yu Qiao},
      year={2024},
      eprint={2303.16199},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2303.16199}, 
}

@inproceedings{gu_mamba_2024,
	title = {Mamba: {Linear}-{Time} {Sequence} {Modeling} with {Selective} {State} {Spaces}},
	shorttitle = {Mamba},
	url = {https://openreview.net/forum?id=tEYskw1VY2#discussion},
	language = {en},
	urldate = {2025-02-18},
	booktitle = {First {Conference} on {Language} {Modeling}},
	author = {Gu, Albert and Dao, Tri},
	month = aug,
	year = {2024},
}

% ------- VLMs -------
% LLava
@misc{liu2023visualinstructiontuning,
      title={Visual Instruction Tuning}, 
      author={Haotian Liu and Chunyuan Li and Qingyang Wu and Yong Jae Lee},
      year={2023},
      eprint={2304.08485},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2304.08485}, 
}

% CLIP
@misc{radford2021learningtransferablevisualmodels,
      title={Learning Transferable Visual Models From Natural Language Supervision}, 
      author={Alec Radford and Jong Wook Kim and Chris Hallacy and Aditya Ramesh and Gabriel Goh and Sandhini Agarwal and Girish Sastry and Amanda Askell and Pamela Mishkin and Jack Clark and Gretchen Krueger and Ilya Sutskever},
      year={2021},
      eprint={2103.00020},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2103.00020}, 
}

% ViT
@misc{dosovitskiy2021imageworth16x16words,
      title={An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale}, 
      author={Alexey Dosovitskiy and Lucas Beyer and Alexander Kolesnikov and Dirk Weissenborn and Xiaohua Zhai and Thomas Unterthiner and Mostafa Dehghani and Matthias Minderer and Georg Heigold and Sylvain Gelly and Jakob Uszkoreit and Neil Houlsby},
      year={2021},
      eprint={2010.11929},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2010.11929}, 
}

% BLIP
@misc{li2022blipbootstrappinglanguageimagepretraining,
      title={BLIP: Bootstrapping Language-Image Pre-training for Unified Vision-Language Understanding and Generation}, 
      author={Junnan Li and Dongxu Li and Caiming Xiong and Steven Hoi},
      year={2022},
      eprint={2201.12086},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2201.12086}, 
}

% BLIP-2
@misc{li2023blip2bootstrappinglanguageimagepretraining,
      title={BLIP-2: Bootstrapping Language-Image Pre-training with Frozen Image Encoders and Large Language Models}, 
      author={Junnan Li and Dongxu Li and Silvio Savarese and Steven Hoi},
      year={2023},
      eprint={2301.12597},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2301.12597}, 
}

% PaLM-E
@misc{driess2023palmeembodiedmultimodallanguage,
      title={PaLM-E: An Embodied Multimodal Language Model}, 
      author={Danny Driess and Fei Xia and Mehdi S. M. Sajjadi and Corey Lynch and Aakanksha Chowdhery and Brian Ichter and Ayzaan Wahid and Jonathan Tompson and Quan Vuong and Tianhe Yu and Wenlong Huang and Yevgen Chebotar and Pierre Sermanet and Daniel Duckworth and Sergey Levine and Vincent Vanhoucke and Karol Hausman and Marc Toussaint and Klaus Greff and Andy Zeng and Igor Mordatch and Pete Florence},
      year={2023},
      eprint={2303.03378},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2303.03378}, 
}

% OpenFlamingo
@article{awadalla2023openflamingo,
  title={OpenFlamingo: An Open-Source Framework for Training Large Autoregressive Vision-Language Models},
  author={Anas Awadalla and Irena Gao and Josh Gardner and Jack Hessel and Yusuf Hanafy and Wanrong Zhu and Kalyani Marathe and Yonatan Bitton and Samir Gadre and Shiori Sagawa and Jenia Jitsev and Simon Kornblith and Pang Wei Koh and Gabriel Ilharco and Mitchell Wortsman and Ludwig Schmidt},
  journal={arXiv preprint arXiv:2308.01390},
  year={2023}
}

@misc{zhao_cobra_2025,
	title = {Cobra: {Extending} {Mamba} to {Multi}-{Modal} {Large} {Language} {Model} for {Efficient} {Inference}},
	shorttitle = {Cobra},
	url = {http://arxiv.org/abs/2403.14520},
	doi = {10.48550/arXiv.2403.14520},
	urldate = {2025-02-18},
	publisher = {arXiv},
	author = {Zhao, Han and Zhang, Min and Zhao, Wei and Ding, Pengxiang and Huang, Siteng and Wang, Donglin},
	month = jan,
	year = {2025},
	note = {arXiv:2403.14520 [cs]},
}

@inproceedings{liu_pite_2024,
	address = {Berlin, Heidelberg},
	title = {{PiTe}: {Pixel}-{Temporal} {Alignment} for {Large} {Video}-{Language} {Model}},
	isbn = {978-3-031-72651-4},
	shorttitle = {{PiTe}},
	url = {https://doi.org/10.1007/978-3-031-72652-1_10},
	doi = {10.1007/978-3-031-72652-1_10},
	urldate = {2025-02-18},
	booktitle = {Computer {Vision} – {ECCV} 2024: 18th {European} {Conference}, {Milan}, {Italy}, {September} 29–{October} 4, 2024, {Proceedings}, {Part} {V}},
	publisher = {Springer-Verlag},
	author = {Liu, Yang and Ding, Pengxiang and Huang, Siteng and Zhang, Min and Zhao, Han and Wang, Donglin},
	month = oct,
	year = {2024},
	pages = {160--176},
}

% ------- VLMs in Robotics-------
% Cap
@misc{liang2023codepolicieslanguagemodel,
      title={Code as Policies: Language Model Programs for Embodied Control}, 
      author={Jacky Liang and Wenlong Huang and Fei Xia and Peng Xu and Karol Hausman and Brian Ichter and Pete Florence and Andy Zeng},
      year={2023},
      eprint={2209.07753},
      archivePrefix={arXiv},
      primaryClass={cs.RO},
      url={https://arxiv.org/abs/2209.07753}, 
}

% Saycan
@inproceedings{saycan2022arxiv,
    title={Do As I Can and Not As I Say: Grounding Language in Robotic Affordances},
    author={Michael Ahn and Anthony Brohan and Noah Brown and Yevgen Chebotar and Omar Cortes and Byron David and Chelsea Finn and Chuyuan Fu and Keerthana Gopalakrishnan and Karol Hausman and Alex Herzog and Daniel Ho and Jasmine Hsu and Julian Ibarz and Brian Ichter and Alex Irpan and Eric Jang and Rosario Jauregui Ruano and Kyle Jeffrey and Sally Jesmonth and Nikhil Joshi and Ryan Julian and Dmitry Kalashnikov and Yuheng Kuang and Kuang-Huei Lee and Sergey Levine and Yao Lu and Linda Luu and Carolina Parada and Peter Pastor and Jornell Quiambao and Kanishka Rao and Jarek Rettinghouse and Diego Reyes and Pierre Sermanet and Nicolas Sievers and Clayton Tan and Alexander Toshev and Vincent Vanhoucke and Fei Xia and Ted Xiao and Peng Xu and Sichun Xu and Mengyuan Yan and Andy Zeng},
    booktitle={arXiv preprint arXiv:2204.01691},
    year={2022}
}

% SpatialBot
@misc{cai2024spatialbotprecisespatialunderstanding,
      title={SpatialBot: Precise Spatial Understanding with Vision Language Models}, 
      author={Wenxiao Cai and Iaroslav Ponomarenko and Jianhao Yuan and Xiaoqi Li and Wankou Yang and Hao Dong and Bo Zhao},
      year={2024},
      eprint={2406.13642},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2406.13642}, 
}

% ------- VLAs -------
% RT-2
@misc{brohan2023rt2visionlanguageactionmodelstransfer,
      title={RT-2: Vision-Language-Action Models Transfer Web Knowledge to Robotic Control}, 
      author={Anthony Brohan and Noah Brown and Justice Carbajal and Yevgen Chebotar and Xi Chen and Krzysztof Choromanski and Tianli Ding and Danny Driess and Avinava Dubey and Chelsea Finn and Pete Florence and Chuyuan Fu and Montse Gonzalez Arenas and Keerthana Gopalakrishnan and Kehang Han and Karol Hausman and Alexander Herzog and Jasmine Hsu and Brian Ichter and Alex Irpan and Nikhil Joshi and Ryan Julian and Dmitry Kalashnikov and Yuheng Kuang and Isabel Leal and Lisa Lee and Tsang-Wei Edward Lee and Sergey Levine and Yao Lu and Henryk Michalewski and Igor Mordatch and Karl Pertsch and Kanishka Rao and Krista Reymann and Michael Ryoo and Grecia Salazar and Pannag Sanketi and Pierre Sermanet and Jaspiar Singh and Anikait Singh and Radu Soricut and Huong Tran and Vincent Vanhoucke and Quan Vuong and Ayzaan Wahid and Stefan Welker and Paul Wohlhart and Jialin Wu and Fei Xia and Ted Xiao and Peng Xu and Sichun Xu and Tianhe Yu and Brianna Zitkovich},
      year={2023},
      eprint={2307.15818},
      archivePrefix={arXiv},
      primaryClass={cs.RO},
      url={https://arxiv.org/abs/2307.15818}, 
}

% RoboFlanmingo
@misc{li2024visionlanguagefoundationmodelseffective,
      title={Vision-Language Foundation Models as Effective Robot Imitators}, 
      author={Xinghang Li and Minghuan Liu and Hanbo Zhang and Cunjun Yu and Jie Xu and Hongtao Wu and Chilam Cheang and Ya Jing and Weinan Zhang and Huaping Liu and Hang Li and Tao Kong},
      year={2024},
      eprint={2311.01378},
      archivePrefix={arXiv},
      primaryClass={cs.RO},
      url={https://arxiv.org/abs/2311.01378}, 
}

% OpenVLA
@misc{kim2024openvlaopensourcevisionlanguageactionmodel,
      title={OpenVLA: An Open-Source Vision-Language-Action Model}, 
      author={Moo Jin Kim and Karl Pertsch and Siddharth Karamcheti and Ted Xiao and Ashwin Balakrishna and Suraj Nair and Rafael Rafailov and Ethan Foster and Grace Lam and Pannag Sanketi and Quan Vuong and Thomas Kollar and Benjamin Burchfiel and Russ Tedrake and Dorsa Sadigh and Sergey Levine and Percy Liang and Chelsea Finn},
      year={2024},
      eprint={2406.09246},
      archivePrefix={arXiv},
      primaryClass={cs.RO},
      url={https://arxiv.org/abs/2406.09246}, 
}

@inproceedings{ding_quar-vla_2024,
	address = {Berlin, Heidelberg},
	title = {{QUAR}-{VLA}: {Vision}-{Language}-{Action} {Model} for {Quadruped} {Robots}},
	isbn = {978-3-031-72651-4},
	shorttitle = {{QUAR}-{VLA}},
	url = {https://doi.org/10.1007/978-3-031-72652-1_21},
	doi = {10.1007/978-3-031-72652-1_21},
	urldate = {2025-02-18},
	booktitle = {Computer {Vision} – {ECCV} 2024: 18th {European} {Conference}, {Milan}, {Italy}, {September} 29–{October} 4, 2024, {Proceedings}, {Part} {V}},
	publisher = {Springer-Verlag},
	author = {Ding, Pengxiang and Zhao, Han and Zhang, Wenjie and Song, Wenxuan and Zhang, Min and Huang, Siteng and Yang, Ningxi and Wang, Donglin},
	month = oct,
	year = {2024},
	pages = {352--367},
}

@misc{tong_quart-online_2024,
	title = {{QUART}-{Online}: {Latency}-{Free} {Large} {Multimodal} {Language} {Model} for {Quadruped} {Robot} {Learning}},
	shorttitle = {{QUART}-{Online}},
	url = {http://arxiv.org/abs/2412.15576},
	doi = {10.48550/arXiv.2412.15576},
	urldate = {2025-02-18},
	publisher = {arXiv},
	author = {Tong, Xinyang and Ding, Pengxiang and Wang, Donglin and Zhang, Wenjie and Cui, Can and Sun, Mingyang and Fan, Yiguo and Zhao, Han and Zhang, Hongyin and Dang, Yonghao and Huang, Siteng and Lyu, Shangke},
	month = dec,
	year = {2024},
	note = {arXiv:2412.15576 [cs]},
}

@article{yue2024deer,
  title={DeeR-VLA: Dynamic Inference of Multimodal Large Language Models for Efficient Robot Execution},
  author={Yue, Yang and Wang, Yulin and Kang, Bingyi and Han, Yizeng and Wang, Shenzhi and Song, Shiji and Feng, Jiashi and Huang, Gao},
  journal={NeurIPS},
  year={2024}
}

@article{zhang2025gevrm,
  title={GEVRM: Goal-Expressive Video Generation Model For Robust Visual Manipulation},
  author={Zhang, Hongyin and Ding, Pengxiang and Lyu, Shangke and Peng, Ying and Wang, Donglin},
  journal={arXiv preprint arXiv:2502.09268},
  year={2025}
}

@inproceedings{shah_mutex_2023,
	title = {{MUTEX}: {Learning} {Unified} {Policies} from {Multimodal} {Task} {Specifications}},
	shorttitle = {{MUTEX}},
	url = {https://proceedings.mlr.press/v229/shah23b.html},
	language = {en},
	urldate = {2024-12-08},
	booktitle = {Proceedings of {The} 7th {Conference} on {Robot} {Learning}},
	publisher = {PMLR},
	author = {Shah, Rutav and Martín-Martín, Roberto and Zhu, Yuke},
	month = dec,
	year = {2023},
	note = {ISSN: 2640-3498},
	pages = {2663--2682},
}

% ------- Benchmark-------
% Calvin
@misc{mees2022calvinbenchmarklanguageconditionedpolicy,
      title={CALVIN: A Benchmark for Language-Conditioned Policy Learning for Long-Horizon Robot Manipulation Tasks}, 
      author={Oier Mees and Lukas Hermann and Erick Rosete-Beas and Wolfram Burgard},
      year={2022},
      eprint={2112.03227},
      archivePrefix={arXiv},
      primaryClass={cs.RO},
      url={https://arxiv.org/abs/2112.03227}, 
}

%Imitation Learning
@misc{ross2011reductionimitationlearningstructured,
      title={A Reduction of Imitation Learning and Structured Prediction to No-Regret Online Learning}, 
      author={Stephane Ross and Geoffrey J. Gordon and J. Andrew Bagnell},
      year={2011},
      eprint={1011.0686},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/1011.0686}, 
}

% RAG
@misc{zhao2024retrievalaugmentedgenerationrag,
      title={Retrieval Augmented Generation (RAG) and Beyond: A Comprehensive Survey on How to Make your LLMs use External Data More Wisely}, 
      author={Siyun Zhao and Yuqing Yang and Zilong Wang and Zhiyuan He and Luna K. Qiu and Lili Qiu},
      year={2024},
      eprint={2409.14924},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2409.14924}, 
}

% ------- need modify? -------
@incollection{Bengio+chapter2007,
author = {Bengio, Yoshua and LeCun, Yann},
booktitle = {Large Scale Kernel Machines},
publisher = {MIT Press},
title = {Scaling Learning Algorithms Towards {AI}},
year = {2007}
}

@article{Hinton06,
author = {Hinton, Geoffrey E. and Osindero, Simon and Teh, Yee Whye},
journal = {Neural Computation},
pages = {1527--1554},
title = {A Fast Learning Algorithm for Deep Belief Nets},
volume = {18},
year = {2006}
}

@book{goodfellow2016deep,
title={Deep learning},
author={Goodfellow, Ian and Bengio, Yoshua and Courville, Aaron and Bengio, Yoshua},
volume={1},
year={2016},
publisher={MIT Press}
}

@article{anil2023palm,
  title={Palm 2 technical report},
  author={Anil, Rohan and Dai, Andrew M and Firat, Orhan and Johnson, Melvin and Lepikhin, Dmitry and Passos, Alexandre and Shakeri, Siamak and Taropa, Emanuel and Bailey, Paige and Chen, Zhifeng and others},
  journal={arXiv preprint arXiv:2305.10403},
  year={2023}
}
@article{brohan2022rt,
  title={Rt-1: Robotics transformer for real-world control at scale},
  author={Brohan, Anthony and Brown, Noah and Carbajal, Justice and Chebotar, Yevgen and Dabis, Joseph and Finn, Chelsea and Gopalakrishnan, Keerthana and Hausman, Karol and Herzog, Alex and Hsu, Jasmine and others},
  journal={arXiv preprint arXiv:2212.06817},
  year={2022}
}
@article{achiam2023gpt,
  title={GPT-4 technical report (2023)},
  author={Achiam, Josh and Adler, Steven and Agarwal, Sandhini and Ahmad, Lama and Akkaya, Ilge and Aleman, Florencia Leoni and Almeida, Diogo and Altenschmidt, Janko and Altman, Sam and Anadkat, Shyamal and others},
  journal={URL https://api. semanticscholar. org/CorpusID},
  volume={257532815},
  year={2023}
}

% Speech
@misc{yu_connecting_2023,
	title = {Connecting {Speech} {Encoder} and {Large} {Language} {Model} for {ASR}},
	url = {http://arxiv.org/abs/2309.13963},
	doi = {10.48550/arXiv.2309.13963},
	urldate = {2024-07-21},
	publisher = {arXiv},
	author = {Yu, Wenyi and Tang, Changli and Sun, Guangzhi and Chen, Xianzhao and Tan, Tian and Li, Wei and Lu, Lu and Ma, Zejun and Zhang, Chao},
	month = sep,
	year = {2023},
	note = {arXiv:2309.13963 [cs, eess]},
}

% Whisper
@inproceedings{radford_robust_2023,
	address = {Honolulu, Hawaii, USA},
	series = {{ICML}'23},
	title = {Robust speech recognition via large-scale weak supervision},
	volume = {202},
	urldate = {2024-08-27},
	booktitle = {Proceedings of the 40th {International} {Conference} on {Machine} {Learning}},
	publisher = {JMLR.org},
	author = {Radford, Alec and Kim, Jong Wook and Xu, Tao and Brockman, Greg and McLeavey, Christine and Sutskever, Ilya},
	month = jul,
	year = {2023},
	pages = {28492--28518},
}

% RT-H
@misc{belkhale_rt-h_2024,
	title = {{RT}-{H}: {Action} {Hierarchies} {Using} {Language}},
	shorttitle = {{RT}-{H}},
	url = {http://arxiv.org/abs/2403.01823},
	doi = {10.48550/arXiv.2403.01823},
	urldate = {2024-03-23},
	publisher = {arXiv},
	author = {Belkhale, Suneel and Ding, Tianli and Xiao, Ted and Sermanet, Pierre and Vuong, Quon and Tompson, Jonathan and Chebotar, Yevgen and Dwibedi, Debidatta and Sadigh, Dorsa},
	month = mar,
	year = {2024},
	note = {arXiv:2403.01823 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Robotics, /unread},
}

% 3D-VLA
@inproceedings{zhen_3d-vla_2024,
	title = {{3D}-{VLA}: {A} {3D} {Vision}-{Language}-{Action} {Generative} {World} {Model}},
	shorttitle = {{3D}-{VLA}},
	url = {https://proceedings.mlr.press/v235/zhen24a.html},
	language = {en},
	urldate = {2024-09-30},
	booktitle = {Proceedings of the 41st {International} {Conference} on {Machine} {Learning}},
	publisher = {PMLR},
	author = {Zhen, Haoyu and Qiu, Xiaowen and Chen, Peihao and Yang, Jincheng and Yan, Xin and Du, Yilun and Hong, Yining and Gan, Chuang},
	month = jul,
	year = {2024},
	note = {ISSN: 2640-3498},
	pages = {61229--61245},
}

% Robot CoT 
@inproceedings{
zawalski2024robotic,
    title={Robotic Control via Embodied Chain-of-Thought Reasoning},
    author={Micha{\l} Zawalski and William Chen and Karl Pertsch and Oier Mees and Chelsea Finn and Sergey Levine},
    booktitle={8th Annual Conference on Robot Learning},
    year={2024},
    url={https://openreview.net/forum?id=S70MgnIA0v}
}

% VITA
@misc{fu_vita_2024,
	title = {{VITA}: {Towards} {Open}-{Source} {Interactive} {Omni} {Multimodal} {LLM}},
	shorttitle = {{VITA}},
	url = {http://arxiv.org/abs/2408.05211},
	doi = {10.48550/arXiv.2408.05211},
	urldate = {2024-09-30},
	publisher = {arXiv},
	author = {Fu, Chaoyou and Lin, Haojia and Long, Zuwei and Shen, Yunhang and Zhao, Meng and Zhang, Yifan and Dong, Shaoqi and Wang, Xiong and Yin, Di and Ma, Long and Zheng, Xiawu and He, Ran and Ji, Rongrong and Wu, Yunsheng and Shan, Caifeng and Sun, Xing},
	month = sep,
	year = {2024},
	note = {arXiv:2408.05211 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language, Computer Science - Computer Vision and Pattern Recognition},
}

% ESPnet
@inproceedings{hayashi_espnet-tts_2020,
	address = {Barcelona, Spain},
	title = {Espnet-{TTS}: {Unified}, {Reproducible}, and {Integratable} {Open} {Source} {End}-to-{End} {Text}-to-{Speech} {Toolkit}},
	shorttitle = {Espnet-{TTS}},
	doi = {10.1109/ICASSP40776.2020.9053512},
	language = {en},
	booktitle = {International {Conference} on {Acoustics}, {Speech} and {Signal} {Processing}},
	author = {Hayashi, Tomoki and Yamamoto, Ryuichi and Inoue, Katsuki and Yoshimura, Takenori and Watanabe, Shinji and Toda, Tomoki and Takeda, Kazuya and Zhang, Yu and Tan, Xu},
	month = may,
	year = {2020},
	note = {ISSN: 2379-190X},
	keywords = {Automatic speech recognition, Conferences, Signal processing, Speech processing, text-to-speech, end-to-end, Open source software, Open-source, Reproducibility of results, Supervised learning},
	pages = {7654--7658},
}

% VITS
@inproceedings{kim_conditional_2021,
	title = {Conditional {Variational} {Autoencoder} with {Adversarial} {Learning} for {End}-to-{End} {Text}-to-{Speech}},
	url = {https://proceedings.mlr.press/v139/kim21f.html},
	language = {en},
	urldate = {2024-09-30},
	booktitle = {Proceedings of the 38th {International} {Conference} on {Machine} {Learning}},
	publisher = {PMLR},
	author = {Kim, Jaehyeon and Kong, Jungil and Son, Juhee},
	month = jul,
	year = {2021},
	note = {ISSN: 2640-3498},
	pages = {5530--5540},
}

% LibriTTS
@inproceedings{zen_libritts_2019,
	title = {{LibriTTS}: {A} {Corpus} {Derived} from {LibriSpeech} for {Text}-to-{Speech}},
	shorttitle = {{LibriTTS}},
	url = {https://www.isca-archive.org/interspeech_2019/zen19_interspeech.html},
	doi = {10.21437/Interspeech.2019-2441},
	language = {en},
	urldate = {2024-09-30},
	booktitle = {Interspeech 2019},
	publisher = {ISCA},
	author = {Zen, Heiga and Dang, Viet and Clark, Rob and Zhang, Yu and Weiss, Ron J. and Jia, Ye and Chen, Zhifeng and Wu, Yonghui},
	month = sep,
	year = {2019},
	pages = {1526--1530},
}

% LibriSpeech
@inproceedings{panayotov_librispeech_2015,
	title = {Librispeech: {An} {ASR} corpus based on public domain audio books},
	shorttitle = {Librispeech},
	url = {https://ieeexplore.ieee.org/document/7178964},
	doi = {10.1109/ICASSP.2015.7178964},
	urldate = {2024-09-30},
	booktitle = {2015 {IEEE} {International} {Conference} on {Acoustics}, {Speech} and {Signal} {Processing} ({ICASSP})},
	author = {Panayotov, Vassil and Chen, Guoguo and Povey, Daniel and Khudanpur, Sanjeev},
	month = apr,
	year = {2015},
	note = {ISSN: 2379-190X},
	keywords = {Bioinformatics, Blogs, Corpus, Electronic publishing, Genomics, Information services, LibriVox, Resource description framework, Speech Recognition},
	pages = {5206--5210},
}

% MCIL
@inproceedings{lynch_language_2021,
	title = {Language {Conditioned} {Imitation} {Learning} {Over} {Unstructured} {Data}},
	isbn = {978-0-9923747-7-8},
	url = {http://www.roboticsproceedings.org/rss17/p047.pdf},
	doi = {10.15607/RSS.2021.XVII.047},
	language = {en},
	urldate = {2024-09-30},
	booktitle = {Robotics: {Science} and {Systems} {XVII}},
	publisher = {Robotics: Science and Systems Foundation},
	author = {Lynch*, Corey and Sermanet*, Pierre},
	month = jul,
	year = {2021},
}

% HULC
@article{mees2022hulc,
  author = {Oier Mees and Lukas Hermann and Wolfram Burgard},
  title = {What Matters in Language Conditioned Robotic Imitation Learning Over Unstructured Data},
  journal = {IEEE Robotics and Automation Letters (RA-L)}, 
  volume = {7},
  number = {4},
  pages = {11205-11212},
  year = {2022}
}

% Add for rebuttal
@misc{laurencon_obelics_2023,
	title = {{OBELICS}: {An} {Open} {Web}-{Scale} {Filtered} {Dataset} of {Interleaved} {Image}-{Text} {Documents}},
	shorttitle = {{OBELICS}},
	url = {http://arxiv.org/abs/2306.16527},
	doi = {10.48550/arXiv.2306.16527},
	publisher = {arXiv},
	author = {Laurençon, Hugo and Saulnier, Lucile and Tronchon, Léo and Bekman, Stas and Singh, Amanpreet and Lozhkov, Anton and Wang, Thomas and Karamcheti, Siddharth and Rush, Alexander M. and Kiela, Douwe and Cord, Matthieu and Sanh, Victor},
	month = aug,
	year = {2023},
	note = {arXiv:2306.16527},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Information Retrieval},
}

@inproceedings{karamcheti_prismatic_2024,
	title = {Prismatic {VLMs}: {Investigating} the {Design} {Space} of {Visually}-{Conditioned} {Language} {Models}},
	shorttitle = {Prismatic {VLMs}},
	url = {https://proceedings.mlr.press/v235/karamcheti24a.html},
	language = {en},
	urldate = {2024-11-27},
	booktitle = {Proceedings of the 41st {International} {Conference} on {Machine} {Learning}},
	publisher = {PMLR},
	author = {Karamcheti, Siddharth and Nair, Suraj and Balakrishna, Ashwin and Liang, Percy and Kollar, Thomas and Sadigh, Dorsa},
	month = jul,
	year = {2024},
	note = {ISSN: 2640-3498},
	pages = {23123--23144},
}

@inproceedings{lu_unified-io_2024,
	address = {Seattle, WA, USA},
	title = {Unified-{IO} 2: {Scaling} {Autoregressive} {Multimodal} {Models} with {Vision}, {Language}, {Audio}, and {Action}},
	copyright = {https://doi.org/10.15223/policy-029},
	isbn = {9798350353006},
	shorttitle = {Unified-{IO} 2},
	url = {https://ieeexplore.ieee.org/document/10657364/},
	doi = {10.1109/CVPR52733.2024.02497},
	language = {en},
	urldate = {2024-11-27},
	booktitle = {2024 {IEEE}/{CVF} {Conference} on {Computer} {Vision} and {Pattern} {Recognition} ({CVPR})},
	publisher = {IEEE},
	author = {Lu, Jiasen and Clark, Christopher and Lee, Sangho and Zhang, Zichen and Khosla, Savya and Marten, Ryan and Hoiem, Derek and Kembhavi, Aniruddha},
	month = jun,
	year = {2024},
	pages = {26429--26445},
}

@misc{team_gemini_2024,
	title = {Gemini: {A} {Family} of {Highly} {Capable} {Multimodal} {Models}},
	shorttitle = {Gemini},
	url = {http://arxiv.org/abs/2312.11805},
	doi = {10.48550/arXiv.2312.11805},
	urldate = {2024-11-27},
	publisher = {arXiv},
	author = {Team, Gemini and Anil, Rohan and Borgeaud, Sebastian and Alayrac},
	month = jun,
	year = {2024},
	note = {arXiv:2312.11805},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language, Computer Science - Computer Vision and Pattern Recognition},
}

@misc{li_llava-next-interleave_2024,
	title = {{LLaVA}-{NeXT}-{Interleave}: {Tackling} {Multi}-image, {Video}, and {3D} in {Large} {Multimodal} {Models}},
	shorttitle = {{LLaVA}-{NeXT}-{Interleave}},
	url = {http://arxiv.org/abs/2407.07895},
	doi = {10.48550/arXiv.2407.07895},
	language = {en-US},
	urldate = {2024-11-27},
	publisher = {arXiv},
	author = {Li, Feng and Zhang, Renrui and Zhang, Hao and Zhang, Yuanhan and Li, Bo and Li, Wei and Ma, Zejun and Li, Chunyuan},
	month = jul,
	year = {2024},
	note = {arXiv:2407.07895},
	keywords = {Computer Science - Computation and Language, Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning},
}

@inproceedings{lin_video-llava_2024,
	address = {Miami, Florida, USA},
	title = {Video-{LLaVA}: {Learning} {United} {Visual} {Representation} by {Alignment} {Before} {Projection}},
	shorttitle = {Video-{LLaVA}},
	url = {https://aclanthology.org/2024.emnlp-main.342},
	urldate = {2024-11-27},
	booktitle = {Proceedings of the 2024 {Conference} on {Empirical} {Methods} in {Natural} {Language} {Processing}},
	publisher = {Association for Computational Linguistics},
	author = {Lin, Bin and Ye, Yang and Zhu, Bin and Cui, Jiaxi and Ning, Munan and Jin, Peng and Yuan, Li},
	editor = {Al-Onaizan, Yaser and Bansal, Mohit and Chen, Yun-Nung},
	month = nov,
	year = {2024},
	pages = {5971--5984},
}

@inproceedings{zhang_video-llama_2023,
	address = {Singapore},
	title = {Video-{LLaMA}: {An} {Instruction}-tuned {Audio}-{Visual} {Language} {Model} for {Video} {Understanding}},
	shorttitle = {Video-{LLaMA}},
	url = {https://aclanthology.org/2023.emnlp-demo.49},
	doi = {10.18653/v1/2023.emnlp-demo.49},
	urldate = {2024-11-27},
	booktitle = {Proceedings of the 2023 {Conference} on {Empirical} {Methods} in {Natural} {Language} {Processing}: {System} {Demonstrations}},
	publisher = {Association for Computational Linguistics},
	author = {Zhang, Hang and Li, Xin and Bing, Lidong},
	editor = {Feng, Yansong and Lefever, Els},
	month = dec,
	year = {2023},
	pages = {543--553},
}

@misc{cheng_videollama_2024,
	title = {{VideoLLaMA} 2: {Advancing} {Spatial}-{Temporal} {Modeling} and {Audio} {Understanding} in {Video}-{LLMs}},
	shorttitle = {{VideoLLaMA} 2},
	url = {http://arxiv.org/abs/2406.07476},
	doi = {10.48550/arXiv.2406.07476},
	language = {en-US},
	urldate = {2024-11-27},
	publisher = {arXiv},
	author = {Cheng, Zesen and Leng, Sicong and Zhang, Hang and Xin, Yifei and Li, Xin and Chen, Guanzheng and Zhu, Yongxin and Zhang, Wenqi and Luo, Ziyang and Zhao, Deli and Bing, Lidong},
	month = oct,
	year = {2024},
	note = {arXiv:2406.07476},
}

@misc{han_imagebind-llm_2023,
	title = {{ImageBind}-{LLM}: {Multi}-modality {Instruction} {Tuning}},
	shorttitle = {{ImageBind}-{LLM}},
	url = {http://arxiv.org/abs/2309.03905},
	doi = {10.48550/arXiv.2309.03905},
	urldate = {2024-11-27},
	publisher = {arXiv},
	author = {Han, Jiaming and Zhang, Renrui and Shao, Wenqi and Gao, Peng and Xu, Peng and Xiao, Han and Zhang, Kaipeng and Liu, Chris and Wen, Song and Guo, Ziyu and Lu, Xudong and Ren, Shuai and Wen, Yafei and Chen, Xiaoxin and Yue, Xiangyu and Li, Hongsheng and Qiao, Yu},
	month = sep,
	year = {2023},
}

@misc{openai2024gpt4,
  author       = {OpenAI},
  title        = {GPT-4: Generative Pre-trained Transformer 4},
  year         = {2024},
  howpublished = {\url{https://openai.com/index/hello-gpt-4o/}}
}