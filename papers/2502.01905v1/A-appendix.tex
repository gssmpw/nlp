\section*{Appendix}
\appendix
\numberwithin{equation}{section}

\section{Removing negative ties}
\label{appendix-rem}
When controllers are unable to detect or observe negative edges in the network, i.e. $w_{ij}=max(0,w_{ij})$, the optimisation problem reduces to
\begin{align}
    p_{A}^* &= \text{argmax}_{p_{A}} X_{A}^{*(\phi)}(L^{(\phi)},p_{B},B_{A}).
\end{align}

where $L^{(\phi)}$ is the updated Laplacian. 
Following the same process as before we use the gradient $\nabla_{p_{A}} X_{A}^{(\phi)} = 1/N \Vec{1}^{T} [L^{(\phi)}+diag(p_{A}+p_{B})]^{-1}(I - diag(x_{A}^{(\phi)})$ to optimise allocations $p_{A}^*$ in a gradient ascent algorithm $GA^{(\phi)}$. Here $    x_{A,i}^{*(\phi)} = (p_{A,i} + \sum\limits_{j}^{k_a}w_{ji} x_{A,j}^{(\phi)}) / (\sum\limits_{j}^{k_a}w_{ji} + p_{A,i} + p_{B,i})$.


We then run $GA$, $GA^{(+)}$ and $GA^{(\phi)}$ on the Bitcoin network and present the respective gains in vote-shares in \cref{rem}.


  \begin{figure}
  \centering
    \includegraphics[width=0.7\textwidth]{figures/Appendix_A.eps}
    \caption{Figure showing gain in vote-shares when comparing the negative-tie sensitive optimisation approach $GA$, to traditional approaches, $GA^{(+)}$ and $GA^{(\phi)}$ for budget ratios $B_{A}/B_{B} \in [0.05,1]$. Controller B here targets the network uniformly.}
    \label{rem}
  \end{figure}

We find that the method assuming negative edges in the network to be positive $GA^{(+)}$ consistently outperforms $GA^{(\phi)}$, where negative edges are not considered at all. 
To further show that the vote-shares obtained through both methods are identical in undirected networks (and that comparing our results to only $GA^{(+)}$ is sufficient), we look at the allocation expression in \cref{pos-allo}. Here we find that the optimal allocation, in the absence of any knowledge of negative edges, depends solely on the individual budgets of the controllers and the adversarial allocations on the nodes, but not on the degrees of the nodes.   

\section{Limiting case}
\label{appendix-A}
We begin with the series expansion of the steady-state equation in \cref{XA-MF} to obtain,
\begin{align}
    X_{A} = \langle \frac{a_{k_{a}k_{b}}}{k_{a}} \rangle + \langle \frac{k_{b}}{k_{a}} \rangle + \langle 1 - \frac{a_{k_{a}k_{b}}+b_{k_{a}k_{b}}+k_{b}}{k_{a}} \rangle  \langle x_{a} \rangle - \langle \frac{k_{b}}{k_{a}} \rangle \langle x_{b} \rangle,
    \label{x-exp}
\end{align}
where a second-order expansion for $\langle x_{a} \rangle$ gives us, 
\begin{align}
    \langle x_{a} \rangle = \frac{a+\langle k_{b} \rangle - \langle \frac{(a+k_{b})(a+b+2k_{b})}{k_{a}} \rangle }{a+b+2\langle k_{b} \rangle} + \frac{a+\langle k_{b} \rangle }{(a+b+2k_{b})^2}\Bigg( \langle \frac{k_{b}^2}{k_{a}} \rangle + \langle \frac{(a+b+k_{b})(a+b+3k_{b})}{k_{a}} \rangle \Bigg),
    \label{xa-exp}
\end{align}
and a zero-order expansion for $\langle x_{b} \rangle$ gives us
\begin{align}
  \langle x_{b} \rangle = \frac{a+\langle k_{b} \rangle}{a+b+\langle k_{b} \rangle}.
  \label{xb-exp}
\end{align}

Finally, replacing \cref{xa-exp,xb-exp} in \cref{x-exp} and ignoring higher-order terms, we obtain
\begin{equation}
\begin{split}
    X_{A} \approx \langle \frac{a_{k_{a}k_{b}}}{k_{a}} \rangle + \langle \frac{k_{b}}{k_{a}} \rangle + \frac{a_{k_{a}k_{b}}+\langle k_{b} \rangle}{a_{k_{a}k_{b}}+b_{k_{a}k_{b}}+2\langle k_{b} \rangle} - \frac{\langle \frac{(a_{k_{a}k_{b}}+k_{b})(a_{k_{a}k_{b}}+b_{k_{a}k_{b}}+2k_{b})}{k_{a}} \rangle}{a_{k_{a}k_{b}}+b_{k_{a}k_{b}}+2\langle k_{b} \rangle} \\ + \frac{a_{k_{a}k_{b}}+\langle k_{b} \rangle}{(a_{k_{a}k_{b}}+b_{k_{a}k_{b}}+2\langle k_{b} \rangle)^2}\Bigg( \langle \frac{k_{b}^2}{k_{a}} \rangle  + \langle \frac{(a_{k_{a}k_{b}}+b_{k_{a}k_{b}}+k_{b})(a_{k_{a}k_{b}}+b_{k_{a}k_{b}}+3k_{b})}{k_{a}} \rangle \\ 
    - \langle \frac{a_{k_{a}k_{b}}+b_{k_{a}k_{b}}+k_{b}}{k_{a}} \rangle \frac{a_{k_{a}k_{b}}+\langle k_{b} \rangle }{a_{k_{a}k_{b}}+b_{k_{a}k_{b}}+2\langle k_{b}\rangle} - \langle \frac{k_{b}}{k_{a}} \rangle  \frac{a_{k_{a}k_{b}}+\langle k_{b}\rangle}{a_{k_{a}k_{b}}+b_{k_{a}k_{b}}+\langle k_{b}\rangle}  \Bigg).
\end{split}
\label{app-X}
\end{equation}
Note that all terms in \cref{app-X} are averaged over the joint positive and negative degree distribution $P_{k_{a}k_{b}}$.

We can now apply the Lagrange method to maximise vote-shares $X_{A}$ against a passive controller B. The Lagrangian is derived as $\mathcal{L} = X_{A} + \lambda (\sum_{k_{a}k{b}} P_{k_{a}k_{b}} a_{k_{a}k_{b}} - \langle a_{k_{a}k_{b}} \rangle N) $, where $\lambda$ is the Lagrangian multiplier. Differentiating $\mathcal{L}$ wrt allocations $a_{k_{a}k_{b}}$ we obtain

\begin{equation}
    \begin{split}
    \frac{\partial \mathcal{L}}{\partial a_{k_{a}k_{b}}} = \frac{1}{k_{a}} - \frac{2a_{k_{a}k_{b}}+b_{k_{a}k_{b}}+3k_{b}}{\langle a_{k_{a}k_{b}} \rangle+ \langle b_{k_{a}k_{b}} \rangle +2\langle k_{b} \rangle} \frac{1}{k_{a}} + 2 \frac{\langle a_{k_{a}k_{b} \rangle}+\langle k_{b} \rangle }{(\langle a_{k_{a}k_{b}} \rangle + \langle b_{k_{a}k_{b} \rangle}+2\langle k_{b} \rangle)^2} \frac{a_{k_{a}k_{b}}+b_{k_{a}k_{b}}+2k_{b}}{k_{a}} \\
    - \frac{\langle a_{k_{a}k_{b}} \rangle +2\langle k_{b} \rangle}{\langle a_{k_{a}k_{b}}\rangle + \langle b_{k_{a}k_{b}} \rangle+2\langle k_{b} \rangle} \frac{1}{k_{a}} + \lambda = 0.
    \end{split}
\end{equation}

Solving for $a_{k_{a}k_{b}}$ gives us,

\begin{equation}
    \begin{split}
        \implies a_{k_{a}k_{b}} = \frac{1}{2} \Bigg( \frac{\langle a_{k_{a}k_{b}} \rangle - \langle b_{k_{a}k_{b}}\rangle}{\langle b_{k_{a}k_{b}} \rangle +\langle k_{b} \rangle} b_{k_{a}k_{b}} + \frac{\langle a_{k_{a}k_{b}} \rangle - 3\langle b_{k_{a}k_{b}} \rangle -2 \langle k_{b} \rangle}{\langle b_{k_{a}k_{b}} \rangle +\langle k_{b} \rangle} k_{b} \\ + \langle a_{k_{a}k_{b}}\rangle + \langle b_{k_{a}k_{b}}\rangle+2\langle k_{b} \rangle + \langle k_{a} \rangle \frac{\lambda (\langle a_{k_{a}k_{b}}\rangle + \langle b_{k_{a}k_{b}} \rangle+2\langle k_{b} \rangle)^2}{\langle b_{k_{a}k_{b}\rangle+\langle k_{b} \rangle}} \Bigg),
  \end{split}
  \label{allo}
\end{equation}
which still contains the Lagrangian multiplier $\lambda$. To appropriately deal with $\lambda$ we average over \cref{allo} and assume the budget per node $\langle a_{k_{a}k_{b}} \rangle$ is sufficiently large. Therefore $\frac{\lambda (\langle a_{k_{a}k_{b}}\rangle + \langle b_{k_{a}k_{b}} \rangle+2\langle k_{b} \rangle)^2}{\langle b_{k_{a}k_{b}\rangle+\langle k_{b} \rangle}} \rightarrow 0$, which finally gives us the expression for the optimal allocation,

\begin{equation}
        a_{k_{a}k_{b}}^* = \frac{1}{2} \Bigg( \frac{\langle a_{k_{a}k_{b}}\rangle - \langle b_{k_{a}k_{b}}\rangle}{\langle b_{k_{a}k_{b}} \rangle +\langle k_{b} \rangle}  b_{k_{a}k_{b}} + \frac{\langle a_{k_{a}k_{b}} \rangle - 3\langle b_{k_{a}k_{b}} \rangle -2 \langle k_{b} \rangle}{\langle b_{k_{a}k_{b}} \rangle +\langle k_{b} \rangle} k_{b} + \langle a_{k_{a}k_{b}}\rangle + \langle b_{k_{a}k_{b}}\rangle+2\langle k_{b} \rangle \Bigg).
  \label{allo-final}
\end{equation}


\section{Uniformly distributed negative edges and uniform adversarial allocations}
\label{gain0}

When a controller cannot observe negative edges, the expression for optimal allocation is given as,

\begin{align}
    a_{k} = \frac{1}{2} \Bigg( \frac{\langle a_{k}\rangle - \langle b_{k}\rangle}{\langle b_{k} \rangle}  b_{k} + \langle a_{k}\rangle + \langle b_{k}\rangle \Bigg).
    \label{pos-allo}
\end{align}
where $k = k_{a}+k_{b}$.

The final vote-share in this case $X_{A}^{(+)}$ is obtained by replacing \cref{pos-allo} in \cref{app-X}. 
Gain in vote-shares can therefore be quantified as, 

\begin{align*}
    X_{A} - X_{A}^{(+)} &= \frac{1}{\langle a_{k_{a}k_{b}} \rangle + \langle b_{k_{a}k_{b}} \rangle +2\langle k_{b} \rangle}\Big( (\langle b_{k_{a}k_{b}} \rangle+\langle k_{b} \rangle) \langle \frac{a_{k_{a}k_{b}}-a_{k}}{k_{a}} \rangle \\
    & + \frac{\langle a_{k_{a}k_{b}} \rangle +\langle k_{b} \rangle}{\langle a_{k_{a}k_{b}} \rangle + \langle a_{k_{a}k_{b}} \rangle + 2\langle k_{b} \rangle} \langle \frac{(a_{k_{a}k_{b}}-a_{k})(a_{k_{a}k_{b}}+a_{k}+2\langle b_{k_{a}k_{b}} \rangle+4k_{b})}{k_{a}} \rangle \\
    & - \langle \frac{(a_{k_{a}k_{b}}-a_{k})(a_{k_{a}k_{b}}+a_{k}+ \langle b_{k_{a}k_{b}} \rangle +3k_{b})}{k_{a}} \rangle \Big).
\end{align*}


Furthermore, the term $a_{k_{a}k_{b}} - a_{k}$ in the above expression can be derived using \cref{allo-final,pos-allo} as, 
\begin{align}
    a_{k_{a}k_{b}} - a_{k}  =  \Big( 1 - \frac{\langle a_{k_{a}k_{b}} \rangle - \langle b_{k_{a}k_{b}} \rangle }{2\langle b_{k_{a}k_{b}} \rangle}\frac{b_{k_{a}k{b}}}{\langle b_{k_{a}k_{b}} \rangle+\langle k_{b} \rangle} \Big) \langle k_{b} \rangle + \frac{\langle a_{k_{a}k_{b}} \rangle-3\langle b_{k_{a}k_{b}} \rangle-2\langle k_{b} \rangle}{2(\langle b_{k_{a}k_{b}} \rangle+\langle k_{b} \rangle)} k_{b}.
    \label{diff-allo}
\end{align}


We consider networks with regular negative graphs, $k_{b}=\langle k_{b} \rangle$ where an adversary uniformly targets the network, $b_{k_{a}k_{b}} = \langle b_{k_{a}k_{b}} \rangle$. The above relations further simplify \cref{diff-allo} as,

\begin{align*}
    a_{k_{a}k_{b}} - a_{k} &= \Bigg( \Big( 1 - \frac{\langle a_{k_{a}k_{b}} \rangle- \langle b_{k_{a}k_{b}} \rangle}{2(\langle b_{k_{a}k_{b}} \rangle+\langle k_{b} \rangle)} \Big) + \frac{\langle a_{k_{a}k_{b}} \rangle -3 \langle b_{k_{a}k_{b}} \rangle -2\langle k_{b} \rangle}{2(\langle b_{k_{a}k_{b}} \rangle +\langle k_{b} \rangle)} \Bigg) \langle k_{b} \rangle=0.
\end{align*}

Therefore, it follows that gain $ X_{A} - X_{A}^{(+)}  = 0$, against an adversary targeting all nodes uniformly, in networks with regular negative components.
