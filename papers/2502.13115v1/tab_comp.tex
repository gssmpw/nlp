

\begin{table}
\centering
\renewcommand{\arraystretch}{1.3}
\begin{tabular}{|c|c|c|c|c|}
\hline
Setting & Results & Regret bound & Gen & Adv  \\
\hline
\multirow{4}{*}{Joint DP} & \citet{shariff2018differentially} & $d\sqrt{T}+\frac{d^{3/4}\sqrt{T}}{\sqrt{\alpha}}$ & \yes & \yes \\\cline{2-5}
                         & \cref{thm:regret-upper-JDP} & $\sqrt{d^5T}+\frac{d^{5/2}}{\alpha}$ & \yes & \no \\\cline{2-5}
                         & \cref{thm:regret-upper-JDP-better} ($|\cA|=\bigO{1}$) & $\sqrt{dT}+\frac{d^{3/2}}{\alpha}$ & \no & \no \\\cline{2-5}
                         & Lower bound~\citep{he2022reduction} & $\sqrt{dT\log|\cA|}+\frac{d}{\alpha}$ & / & / \\
\hline
\multirow{6}{*}{Local DP} & \citet{zheng2020locally} & $(dT)^{3/4}/\alpha$ & \yes & \yes \\\cline{2-5}
                         & \citet{han2021generalized}$^\dagger$ & $\sqrt{d\log|\cA|\cdot T}/(\lmins \alpha)$ & \yes & \yes \\\cline{2-5}
                         & \citet{li2024optimal} & $|\cA|^2\log^d(T)\cdot \sqrt{T}/\alpha$ & \no & \no \\\cline{2-5}
                         & \citet{chen2024private} & $ \sqrt{d^3T}/\alpha$ & \yes & \yes \\\cline{2-5}
                         & \cref{thm:regret-upper-LDP} & $\sqrt{d^5T}/\alpha$ & \yes & \no \\\cline{2-5}
                         & Lower bound~\citep{chen2024private} & $\sqrt{d^2T}/\alpha$ & / & / \\
\hline
\end{tabular}
\caption{Summary of the existing results for private learning in (generalized) linear contextual bandits. 
The ``Gen'' column indicates whether similar regret bounds can be obtained under generalized linear contextual bandits.
The ``Adv'' column indicates whether the contexts are allowed to be adversarial (as opposed to stochastic contexts considered in the present paper).
$\dagger$The assumptions of \citet{han2021generalized} are slightly stronger than $\lmins>0$, and their regret bound is always lower bounded by $\sqrt{d\log|\cA|\cdot T}/(\lmins \alpha)$ stated in the table. Note that $\lmins\leq \frac{1}{d}$ always holds.
}
\label{tab:comp}
\end{table}
