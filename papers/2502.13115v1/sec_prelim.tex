



Differential privacy (DP) is a widely adopted framework for ensuring privacy in data analysis. In this section, we will introduce the definition of joint DP and local DP algorithms for both offline and interactive settings.  We first review the notion of differentially private (DP) channels.
\newcommand{\pDP}{$\alpha$-DP}
\newcommand{\aDP}{$(\alpha,\beta)$-DP}
\begin{definition}[DP channel]
For the latent observation space $\cZ$ and the noisy observation space $\cO$, a channel $\pr$ is a measurable map  $\cZ\to\DO$. %
A channel $\pr$ is \aDP~if for $z, z'\in\cZ$, any measurable set $E\subseteq \cO$,
\begin{align*}
    \pr(E|z)\leq e^\alpha\pr(E|z')+\beta.
\end{align*}
\cfedit{In this paper, we focus on the regime $\alpha,\beta\in(0,1)$. }
\end{definition}

The Gaussian channel is a standard example of the \aDP~channels (see e.g., \citep{balle2018improving}).
\begin{definition}[Gaussian channel]\label{def:Guassian-channel}
Suppose that $\alpha,\beta\in(0,1)$, and denote $\siga=\frac{2\sqrt{\log(1.25/\beta)}}{\alpha}$. For any given function $F:\cZ\to\R^d$, we let $\Delta(F)\defeq \sup_{z,z'} \nrm{F(z)-F(z')}_2$. Then, for any $\Delta\geq \Delta(F)$, the channel $\pr(\cdot|z)=\normal{ F(z), \siga^2 \Delta^2 }$ is a \aDP~channels.
\end{definition}

In the following, we denote by $\priv[\Delta]{v}=\normal{v, 4\siga^2\Delta^2}$ the Gaussian channel with \emph{sensitivity} $\Delta$. It is guaranteed that for any function $F$ with $\nrm{F(z)}\leq \Delta$, the channel $z\mapsto \priv{F(z)}$ is \aDP. Further, for any symmetric matrix $V\in\Rdd$, we denote $\sympriv{V}$ to be the distribution of $V+Z$, where $Z$ is a symmetric Gaussian random matrix, i.e., $Z_{ij}=Z_{ji}\sim \normal{0,4\siga^2\Delta^2}$ independently. 







\paragraph{Joint DP}
We first recall the definition of (joint) DP algorithms for \emph{non-interactive} problems. In this setting, an \emph{algorithm} maps the dataset $\cD=\set{z_1,\cdots,z_T}\in\cZ^T$ to a distribution over the output decision $\Pi$. The two dataset $\cD=(z_1,\cdots,z_T), \cD'=(z_1',\cdots,z_T')\in \cZ^T$ are neighbored if there is at most one index $i$ such that $z_i\neq z_i'$.

\begin{definition}[JDP for non-interactive algorithms]
An algorithm $\alg$ preserves \aJDP~if for any neighbored dataset $\cD, \cD'$ and any measurable set $E\subseteq \DPi$,
\begin{align*}
    \alg(E|\cD)\leq \ea \alg(E|\cD')+\beta.
\end{align*}
\end{definition}

On the other hand, a $T$-round (interactive) algorithm $\alg$ for contextual bandit problem is specified by a sequence of mapping $\set{ \pi_t(\cdot\mid\cdot) }$, where the $t$-th mapping $\pi\ind{t}(\cdot\mid{}\cH\ind{t-1},x_t)$ specifies the distribution of $a_t\in\cA$ based on the history $\cH\ind{t-1}=\set{ z_s=(x_s,a_s,r_s) }_{s\leq t-1}$ and the current context $x_t$. As the algorithm has to ensure the whole sequence $(a_1,\cdots,a_T)$ protects privacy, it's a more challenging task compared to the non-interactive setting. 
In this work, we consider the following notion of joint DP with interaction.

\begin{definition}[Anticipating JDP]\label{def:JDP-interactive}
An algorithm $\alg$ is said to \emph{preserve \aJDP} (or simply \emph{be \aJDP)} 
\cfreplace{
if for every $t\in[T]$ and any two neighbored trajectory $\cH_T, \cH_T'$ differing only at round $t$, conditioning on the trajectory we have
\begin{align*}
    \PP\sups{\alg}\paren{ (a_{t+1},\cdots,a_T)\in E|\cH_T }\leq \ea\PP\sups{\alg}\paren{ (a_{t+1},\cdots,a_T)\in E|\cH_T' }+\beta, \qquad \forall E\subseteq \cA^{T-t},
\end{align*}
where the probability $\PP\sups{\alg}$ only accounts the randomness of $\alg$, i.e., for $\cH_T=\set{(x_t,a_t,r_t)}_{t\in[T]}$,
\begin{align*}
    \PP\sups{\alg}\paren{ a_{t+1},\cdots,a_T|\cH_T }=\prod_{t'=t+1}^T \pi_{t'}(a_{t'}|(x_s,a_s,r_s)_{s<t'},x_{t'}).
\end{align*}
}{
if for every round $t\in[T]$, any two neighbored history $\cH_t, \cH_t'$ differing only at round $t$, and any sequence of possible future observations $\cD_{t+1:T}=\sset{(x_{t'},r_{t'})}_{t'\in[t+1,T]}$, we have
\begin{align*}
    \PP\sups{\alg}\paren{ (a_{t+1},\cdots,a_T)\in E|\cH_t, \cD_{t+1:T} }\leq \ea\PP\sups{\alg}\paren{ (a_{t+1},\cdots,a_T)\in E|\cH_t', \cD_{t+1:T} }+\beta, \qquad \forall E\subseteq \cA^{T-t},
\end{align*}
where the probability $\PP\sups{\alg}$ only accounts the randomness of $\alg$, i.e., for $\cH_t=\set{(x_t,a_t,r_t)}_{t\in[T]}$,
\begin{align*}
    \PP\sups{\alg}\paren{ a_{t+1},\cdots,a_T|\cH_t, \cD_{t+1:T} }=\prod_{t'=t+1}^T \pi_{t'}(a_{t'}|(x_s,a_s,r_s)_{s<t'},x_{t'}).
\end{align*}
}
\end{definition}



\cref{def:JDP-interactive} is the most widely-adopted definition of privacy-preserving procedures in the literature of contextual bandits~\citep{shariff2018differentially, azize2024open} and episodic RL~\citep{vietri2020private}, and it can be interpreted as following.
Assume that a malicious adversary is trying to identify the private information $(x_t,a_t,r_t)$ of the unit which is treated at round $t\in[T]$, and it can adversarially design the context $x_{s}$ and reward $r_s$ after round $t$. An algorithm is private if the adversary cannot infer the private information  $(x_t,a_t,r_t)$ from the output actions $a_{>t}$ of the algorithm no matter what the history $\cH_{t-1}$ is and how the agent designs the input 
$\{x_{>t},r_{>t}\}$. Since the algorithm is \emph{non-anticipating}, %
the history output $a_{<t}$ will also not be impacted by $(x_t,a_t,r_t)$. In the meanwhile, the output $a_t$ will unavoidably contain information about $x_t$, otherwise no non-trivial regret guarantee could be attained, as proved by~\citet{shariff2018differentially}.


\paragraph{Local DP}
Parallel to the above model of DP, a line of work~\citep{kasiviswanathan2011can,duchi2013local,duchi2016local} studies the \emph{local differential privacy} (LDP) model that provides stronger protection of privacy. It is adopted in scenarios where each individual wants to protect their personal privacy and does not fully trust the data collector, so users locally perturb or add noise to their data before sending it, ensuring that even the collecting party cannot learn the exact original information, but only privatized observation $o \in \cO$. 




For a $T$-round algorithm $\alg$ operating on observation space $\cZ$ and decision space $\Pi$, $\alg$ is said to preserve \aLDP~if it adopts the following protocol for each round $t=1,...,T$:
\begin{itemize}
  \setlength{\parskip}{2pt}
    \item $\alg$ selects a decision $\pi_t\in \Pi$ and a \aDP~channel $\pr_t$ based on the history $\cH_{t-1}=\{\pi_1,o_1 ,\cdots, \pi_{t-1}, o_{t-1}\}$.
    \item The environment generates an observation $z_t\in \cZ$ sampled via $z_t\sim \Mstar(\pi_t)$, where $\Mstar$ is the underlying \emph{model} of the environment. %
    \item $\alg$ receives a noisy observation $o_t\sim \pr_t(\cdot|z_t)$.
\end{itemize}
In other words, an algorithm that preserves local DP never has direct access to the observation $z_t\in\cZ$, and only the ``privatized'' observation $o_t\sim \pr_t(\cdot|z)$ is revealed. Therefore, an LDP algorithm has to adaptively select both the decision $\pi_t$ and also the private channel $\pr_t$ to obtain information from the environment. 







\paragraph{Generalized linear models}
In this paper, we also study the generalized linear models, an important sub-problem of the generalized linear contextual bandits. 
\begin{definition}\label{def:GLM}
In generalized linear models (GLM), a covariate space $\cC\subseteq \Bone$ and a link function $\link:[-1,1]\to[-1,1]$ is given, and the latent observation space is $\cZ=\cC\times [-1,1]$. The ground truth model $\Mstar\in\DZ$ is specified as
\begin{align*}
    (\x,y)\sim \Mstar: \quad \x\sim \pph, ~~
    \EE[y|\x]=\link(\lr \x,\ths\rr),
\end{align*}
where $\pph$ is a covariate distribution over $\cC$, and $\ths\in\Bone$ is the ground truth parameter. 
\end{definition}

Canonical examples of GLM include the \emph{linear models}, where $\link(t)=t$, and the \emph{logistic models}, where $\link(t)=\frac{1}{1+e^{-t}}$. 
In this paper, we assume the link function $\link$ is well-conditioned.
\begin{assumption}\label{asmp:link}
There exists constant $0<\mug\leq \Lipg$ such that $\mug\leq \link'(t)\leq \Lipg$ for all $t\in[-1,1]$, and we denote $\kpg\defeq \frac{\Lipg}{\mug}$ to be the condition number of the link function $\link$.
\end{assumption}
