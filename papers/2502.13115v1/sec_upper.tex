



In this section, we build upon the techniques of \citet{chen2024private} to provide an optimal estimation guarantee under $L_1$-error. 
For linear regression, \citet{chen2024private} provides a near-optimal convergence rate under \Lone-error, based on the DEC framework and the \ExO~algorithm. For each round, the \ExO~algorithm in some sense estimates a ``worst-case'' context distribution $p$, and \citet{chen2024private} utilize such a context distribution to compute a normalization matrix $U$:
\begin{align}\label{def:U}
    \EE_{\x\sim p}\brac{ \frac{U\x\x\tp U}{\nrm{U\x}} }+\lambda U=\id,
\end{align}
where $\lambda>0$ is a regularization parameter. \citet{chen2024private} then bound the DEC based on the normalization $(U,\lambda)$, hence providing the desired convergence rate through the DEC framework.

However, it is unclear whether the normalization matrix $U$ can be useful \emph{algorithmically}.
As the main motivation of our approach, we first discuss in \cref{ssec:U-intuition} how such a normalization matrix $U$, satisfying the following relaxed equation,
\begin{align}\label{def:U-app}
    \frac12\id\preceq \EE_{\x\sim p}\brac{ \frac{U\x\x\tp U}{\nrm{U\x}} }+\lambda U\preceq 2\id,
\end{align}
can be helpful in $L_1$-regression. We then provide a private procedure (\cref{ssec:U-alg}) that learns a normalization $(U,\lambda)$ satisfying \eqref{def:U-app}, and develop our private reweighted regression method with near-optimal convergence guarantee in \cref{ssec:L1-regression-rates}.


\subsection{Key idea: Reweighting based on normalization matrix}\label{ssec:U-intuition}


For generalized linear models with link function $\link$, we can consider the following loss objective,
\begin{align*}%
\textstyle
    \Lgl(\theta)\defeq \Exy{ \ellg(\lr \x,\theta\rr, y) },
\end{align*}
where the \emph{integral loss} $\ellg$ associated with $\link$ is defined as $\ellg(t,y)\defeq -yt+\int_{0}^t \link(s)ds$. The basic property of $\Lgl$ is that $\nabla \Lgl(\theta)=\Exy{ \paren{\link(\lr \x,\theta \rr) -y }\cdot \x }$,
and hence $\nabla \Lgl(\ths)=0$, i.e., $\ths$ is a global minimizer of $\Lgl$. %


\newcommand{\constrth}{\nrm{\theta}\leq 1}
\newcommand{\constrw}{\nrm{Uw}\leq 1}
\paragraph{Reweighted objective}
Given a normalization matrix $U$ and a parameter together satisfying \eqref{def:U-app}, we may reweigh and regularize the objective function $\Lgl$ according to  
\begin{align*}
    \Lnrm(\theta)\defeq \Exy{ \frac{\ellg(\lr \x,\theta\rr, y)}{\nrm{U\x}} }+\frac{\Lipg\lambda}2\nrm{\theta}^2_{U\iv}.
\end{align*}
By \cref{asmp:link} and \eqref{def:U-app}, we know that $\frac12\mug\cdot  U\iq \preceq \nabla^2 \Lnrm(\theta) \preceq 2\Lipg \cdot U\iq$ for any $\constrth$.
Therefore, the objective $\Lnrm$ is well-conditioned after suitable linear transformation $\theta=Uw$. Specifically, we define
\begin{align}\label{def:Lnew}
    \Lnew(w)\defeq \Exy{ \frac{\ellg(\lr U\x,w\rr, y)}{\nrm{U\x}} }+\frac{\Lipg\lambda}{2}\nrm{w}^2_{U},
\end{align}
and then $\Lnew$ is $(2\Lipg)$-smooth and $(\mug/2)$-strongly convex over the domain $\cW_U\defeq \set{w\in\R^d: \constrw}$. Further, the gradient of $\Lnew$ can be derived as
\begin{align*}
    \nabla \Lnew(w)=\Exy{ \frac{U\x}{\nrm{U\x}}\paren{ \link(\lr U\x, w\rr)-y }} +\lambda \Lipg \cdot Uw.
\end{align*}

The following lemma indicates that, any approximate minimizer of $\Lnew$ is provides a good approximation of the ground truth parameter (under the $\Lone$-error).

\newcommand{\wstar}{w^\star}
\newcommand{\hwst}{\widehat{w}^\star_U}
\begin{lemma}\label{lem:Lnew}
Suppose that $(U,\lambda)$ satisfies \eqref{def:U-app}. We let $\hwst\defeq \argmin_{w: \nrm{Uw}\leq 1} \Lnew(w)$ and $\wstar\defeq U^{-1}\ths$.
Then it holds that $\nrm{\hwst-\wstar}\leq 4\lambda$. Further, the following holds:

(1) Estimation error: for any $w\in\cW$, we have
\begin{align}\label{eq:l1-est-error-bound}
    \errloneg{Uw}\leq \Lipg\errlone{Uw}\leq 2\sqrt{d}\Lipg \nrm{w-\wstar}
\end{align}

(2) Confidence interval: $\forall\x\in\Rd$, $\abs{ \lr \x, Uw\rr - \lr \x,\ths \rr }\leq \nrm{U\x}\cdot \nrm{w-\wstar},$
and $\Ex{\nrm{U\x}}\leq 2d$.
\end{lemma}

Therefore, with $N$ samples, the privatized gradient descent produces a solution $\hw$ with $\nrm{\hw-\hwst}\leq \tbO{N^{-1/2}}$, hence providing the desired convergence rate under $\Lone$-error through \eqref{eq:l1-est-error-bound}.
Note that this bypasses the lower bounds of \cref{prop:lower-linear-est}, because the objective $\Lnew$ is different from the standard squared loss objective. 


\subsection{Learning normalization matrix privately}\label{ssec:U-alg}

We start by describing how we can learn the \um~$U$ satisfying \eqref{def:U-app} from data privately. 
Indeed, even when the covariate distribution $p$ is known, it is not clear how to compute a \um~$U$, and \citet{chen2024private} have to invoke a fixed-point argument (Brouwer's theorem) to prove its existence. 
Our key observation is that the following spectral iterates converge to solution to \eqref{def:U}:
\begin{align}\label{eqn:spectral-exact}
    \cov\kk=\Ep{\uxxu[U\kk]}+\lambda U\kk, \qquad
    U\kp=\sym(\cov\kk\isq U\kk),
\end{align}
with the initial point $U\kz=\id$. Specifically, it holds that
\begin{align*}
    \lmin(\cov\kk)\sq\leq \lmin(\cov\kp)\leq \lmax(\cov\kp)\leq \lmax(\cov\kk)\sq.
\end{align*}
Therefore, if the iteration \cref{eqn:spectral-exact} is exact, the matrix $\cov\kk$ converges to the identity matrix at a quadratic rate, implying that $\bigO{\log\log(1/\lambda)}$ iterations are enough to achieve sufficient accuracy.

\paragraph{Approximate spectral iteration} 
In general, the covariate distribution $p$ is also not known, and we have to approximately implement the update rule \cref{eqn:spectral-exact}. To this end, we propose \cref{alg:U-JDP}, which privately approximates \eqref{eqn:spectral-exact} by \eqref{eq:spectral-approx-JDP} with batched samples.

\newcommand{\dataset}{\cD}
\newcommand{\errpara}{parameter}
\begin{algorithm}
\caption{Subroutine $\JDPLU$ %
}\label{alg:U-JDP}
\begin{algorithmic}
\REQUIRE Dataset $\cD=\sset{(\x_t,y_t)}_{t\in[T]}$, \errpara~$\delta\in(0,1)$.
\REQUIRE Epoch $K\geq 1$, batch size $N=\floor{\frac{T}{K}}$, parameters $\lambda\kz,\cdots,\lambda\kc$. %
\STATE Initialize $U\kz=\id$.
\FOR{$k=0,\cdots,K-1$}
    \STATE Compute the estimate on the split dataset $\dataset\kk=\sset{(\x_t,y_t)}_{t\in[kN+1,(k+1)N]}$:
    \begin{align}\label{eq:spectral-approx-JDP}
        H\kk=\frac1N\sumkn \usqx[U\kk][t].
    \end{align}
    \STATE Privatize $\til H\kk\sim \sympriv[1/N]{ H\kk }$.
    \STATE Update
    \begin{align*}
        \cov\kk=U\kk\sq \til H\kk U\kk\sq+\lambda\kk U\kk, \qquad
        U\kp=\sym(\cov\kk\isq U\kk).
    \end{align*}
\ENDFOR
\ENSURE \Um~$U=U\kc$ and normalization parameter $\lambda=\lambda\kc$.
\end{algorithmic}
\end{algorithm}





\cref{alg:U-JDP} preserves \aJDP~by the composition property of joint DP mechanisms, as proved in \cref{appdx:JDP-verify}. 
\begin{lemma}\label{lem:U-JDP-preserve}
    Subroutine $\JDPLU$~(\cref{alg:U-JDP}) preserves \aJDP.
\end{lemma}
We demonstrate that the iterates of \cref{alg:U-JDP} converge to a solution of \eqref{def:U-app}, as follows. The details are deferred to \cref{appdx:proof-U-JDP}.

\begin{proposition}\label{prop:alg-U-JDP}
Let $T\geq 1, K\geq 1$, $\delta\in(0,1)$, and $\epsN\defeq C_0\paren{ \sqrt{\frac{\log(K/\delta)}{N}}+\frac{\siga\sqrt{d+\log(K/\delta)}}{N} }$, where $C_0$ is an absolute constant chosen according to \cref{lem:spectral-concen-JDP}. Suppose that \cref{alg:U-JDP} is instantiated with parameters $\lambda\kk=(2k+5)\epsN$, and then \whp,
\begin{align*}
    \exp\paren{ -\frac{\log(1/\lambda_0)}{2^{k-1}} }\id \preceq \Ep{ \uxxu[U\kk] }+\lambda\kk U\kk \preceq \exp\paren{ \frac{12}{k} }\id.
\end{align*}
In particular, as long as $K\geq \max\sset{\log\log(N),20}$, \cref{alg:U-JDP} outputs $(U,\lambda)$ that satisfies \eqref{def:U-app} \whp, where $\lambda\defeq \lambda\kc=(2K+5)\epsN$.
\end{proposition}




\subsection{Private regression with reweighting}\label{ssec:L1-regression-rates}


In the following, we present \cref{alg:JDP-L1-regression} for private \Lone-regression, which is based on (1) first learning the normalization $(U,\lambda)$ by the subroutine $\JDPLU$ (\cref{alg:U-JDP}), and then (2) running the private batched SGD subroutine (\cref{alg:JDP-SGD}) on the reweighted objective $\Lnew$ defined in \eqref{def:Lnew}. The batched SGD subroutine is standard and hence deferred to \cref{appdx:JDP-l1-regression}.

\newcommand{\lamgd}{\uline{\boldsymbol{\epsilon}}}
\newcommand{\lamall}{\overline{\boldsymbol{\epsilon}}}

\begin{algorithm}
\caption{$\AlgJDPRegression$ %
}\label{alg:JDP-L1-regression}
\begin{algorithmic}[1]
\REQUIRE Dataset $\dataset=\sset{(\x_t,y_t)}_{t\in[T]}$, \errpara~$\delta\in(0,1)$.
\STATE Split the dataset $\dataset=\dataset_0 \cup \cD_1$ equally.
\STATE Set $(U,\lambda) \leftarrow \JDPLU(\dataset_0,\delta)$.
\STATE Set $\hw\leftarrow \AlgJDPGD(\Lnew,\cD_1)$.
\ENSURE Normalization $(U,\lambda)$, estimator $\hth=U\hw$, and estimation error $\lamall$.
\end{algorithmic}
\end{algorithm}







\begin{theorem}[Generalized linear regression with JDP]\label{thm:JDP-L1-regression}
Let $T\geq 1, \delta\in(0,1)$, and the subroutines of \cref{alg:JDP-L1-regression} are suitably instantiated according to \cref{appdx:JDP-l1-regression}. Then, under generalized linear model, \cref{alg:JDP-L1-regression} preserves \aJDP, and the following holds:

(1) \Whp, the normalization $(U,\lambda)$ satisfies \eqref{def:U-app}, and the returned estimator $\hw$ satisfies $\Lipg \nrm{\hw-\hwst}\leq \lamgd$, where 
\begin{align*}
    \lambda := \lambda(T,\delta)= &~ \tbO{ \sqrt{\frac{\log(1/\delta)}{T}}+ \siga \frac{\sqrt{d\log(1/\delta)}}{T}}, \\
    \lamgd := \lamgd (T,\delta)= &~ \tbO{ \kpg^{3/2}\sqrt{\frac{\log(1/\delta)}{T}} + \siga (\kpg^{3/2}+\kpg\sqrt{d})\frac{\sqrt{\log(1/\delta)}}{T} },
\end{align*}
are defined in \cref{prop:alg-U-JDP} and \cref{prop:JDP-GD},
respectively, and 
$\tbO{\cdot}$ hides polynomial factors of $\log(T)$. The overall estimation error $\lamall$ is defined as $\lamall(T,\delta)\defeq 4\Lipg\lambda(T,\delta)+\lamgd(T,\delta)$.

(2) In particular, under the success event of (1), we have (by \cref{lem:Lnew})
\begin{align*}
    \errloneg{\hth}\leq \Lipg\cdot \errlone{\hth}\leq  2\sqrt{d} \cdot \lamall,
\end{align*}
and for all $\x\in\Rd$, the confidence bound holds: $\absn{ \nu(\lr \x, \hth\rr) - \nu(\lr \x,\ths \rr) }\leq \nrm{U\x} \lamall$.
\end{theorem}

Therefore, \cref{alg:JDP-L1-regression} is an $\Lone$-regression oracle in the sense of \cref{def:L1-oracle}.
In particular, for linear models, we have $\kpg=1$, and hence the convergence rate can further be simplified to $\tbO{ \sqrt{\frac{d}{T}}+\frac{d}{\alpha T} }$. The first term matches the minimax-optimal convergence rate of non-private \Lone-regression (given by the least squares), and the second term (``price-of-privacy'') is of lower order compared to the first term.


\paragraph{Extension: Local DP}
As an LDP extension of \cref{alg:JDP-L1-regression}, we propose \cref{alg:LDP-L1-regression} that preserves local DP while achieving near-optimal \Lone-regression guarantee.
\begin{theorem}[Generalized linear regression with LDP]\label{thm:LDP-L1-regression}
Let $T\geq 1, \delta\in(0,1)$. \cref{alg:LDP-L1-regression} (described in \cref{appdx:LDP-l1-regression}) preserves \aLDP, and it returns estimator $\hth$ such that \whp,
\begin{align*}
    \errloneg{\hth}
    \leq \tbO{\siga (\kpg d+\sqrt{\kpg^3d} ) \sqrt{\frac{\log(1/\delta)}{T}}},
\end{align*}
where $\tbO{\cdot}$ hides polynomial factors of $\log(T)$.
Further, the total number of switches (or, changes) of the deployed private channels is bounded by $\bigO{\kpg \log T}$.
\end{theorem}

For linear models, the upper bound of \cref{thm:LDP-L1-regression} simplifies to $\tbO{\frac{d}{\alpha\sqrt{T}}}$. Such a nearly minimax-optimal convergence rate is first derived by~\citet{chen2024private}, using an algorithm that solves an \emph{exponential-time} optimization problem for each round.





