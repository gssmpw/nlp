


\begin{lemma}[Gaussian concentration]\label{lem:Gaussian-concen}
For the random vector $z\in\R^d$ with i.i.d. $\normal{0,\sigma^2}$ entries, \whp, 
\begin{align*}
    \frac{\nrm{z}^2}{\sigma^2}\leq d+2\sqrt{d\log(1/\delta)}+2\log(1/\delta)\leq 2d+3\log(1/\delta).
\end{align*}
For the random symmetric matrix $Z\in\Rdd$ with i.i.d. Gaussian entries $Z_{ij}=Z_{ji}\sim \normal{0,\sigma^2}$ $(1\leq i\leq j\leq d)$, \whp,
\begin{align*}
    \nrmop{Z}\leq C\sigma\sqrt{d+\log(1/\delta)},
\end{align*}
where $C$ is an absolute constant.
\end{lemma}

\begin{lemma}[Matrix Bernstein's inequality ({\citet[Theorem 5.4.1]{vershynin2019high}})]\label{lem:Bernstein}
Let $X_1, X_2, \dots, X_n$ be i.i.d. zero-mean symmetric matrices in $\Rdd$. Suppose that $\nrmop{X_1} \leq R$ almost surely, and let $\sigma^2 = \nrmop{\mathbb{E}[X_1^2]}$.
Then, for all \( t \geq 0 \),
\[
\mathbb{P} \left( \left\| \sum_{i=1}^n X_i \right\| \geq t \right) \leq 2d \exp \left( - \frac{t^2 / 2}{n\sigma^2 + Rt/3} \right).
\]
\end{lemma}

\begin{lemma}\label{lem:cov-concen}
Suppose that $V_1,\cdots,V_n$ are i.i.d. positive semi-definite random matrices such that $\EE[V_i]=\Sigma$ and $\nrmop{V_i}\leq 1$ almost surely. Then for any fixed parameter $c\in[0,1]$, \whp:
\begin{align*}
    (1-c)\Sigma-\frac{4\log(2d/\delta)}{nc}\id \preceq \frac1n\sum_{i=1}^n V_i\preceq (1+c)\Sigma+\frac{4\log(2d/\delta)}{nc}.
\end{align*}
\end{lemma}

\begin{proof}
Fix a $\lambda>0$ to be specified later. Let $\til V_i=(\Sigma+\lambda \id)\isq V_i(\Sigma+\lambda \id)\isq$. Note that $\nrmopn{\til V_i}\leq \frac{1}{\lambda}$ and $\EE{\til V}\preceq \id$, and hence
\begin{align*}
    \EE{\til V_i}^2\preceq \EE{\frac1\lambda\til V_i}\preceq \frac{1}{\lambda}\id.
\end{align*}
Then by \cref{lem:Bernstein}, \whp,
\begin{align*}
    \nrmop{\sum_{i=1}^n \til V_i-\EE{\til V_i}}\leq \sqrt{\frac{2n}{\lambda}\log(2d/\delta)}+\frac{2\log(2d/\delta)}{3\lambda}=:c_\lambda.
\end{align*}
Under this event, we have $v\tp\paren{\sum_{i=1}^n \til V_i-\EE{\til V_i}}v\leq c_\lambda\nrm{v}^2$ for all $v\in\Rd$, and hence
\begin{align*}
    n\Sigma-c_\lambda(\Sigma+\lambda\id)\preceq \sum_{i=1}^n V_i \preceq n\Sigma+c_\lambda(\Sigma+\lambda\id).
\end{align*}
Therefore, we choose $\lambda=\frac{4\log(2d/\delta)}{nc^2}$, which ensures $c_\lambda\leq nc$ and
\begin{align*}
    (1-c)\Sigma-c\lambda\id \preceq \frac1n\sum_{i=1}^n V_i\preceq (1+c)\Sigma+c\lambda\id,
\end{align*}
\whp.
\end{proof}

\begin{lemma}\label{lem:vec-Hoeffding}
Suppose that $(X_t)_t$ is a vector-valued martingale-difference sequence adapted to the filtration $(\cF_t)_{t}$. Assume that $\ltwo{X_t}\leq c_t$ almost surely. Then it holds that $\forall x\geq 0$
\begin{align*}
    \PP\paren{\nrm{\sum_{t=1}^n X_i}_2\geq \sqrt{\sum_{t=1}^nc_t^2}+x}\leq \exp\paren{-\frac{x^2}{2\sum_{t=1}^nc_t^2}}.
\end{align*}
\end{lemma}

\begin{proof}
This is a direct corollary of Azuma's inequality by considering the martingale $(Z_t)$ given by $Z_t=\EE[\ltwo{S_n}|\cF_t]$, where $S_n=\sum_{t=1}^n X_i$. We have $Z_0=\EE[\ltwo{S_n}]$, $Z_n=\ltwo{S_n}$, and $\abs{Z_{t+1}-Z_t}\leq c_{t+1}$ for $0\leq t\leq n-1$. Therefore, Azuma's inequality implies that
\begin{align*}
    \PP\paren{Z_n-Z_0\geq x}\leq \exp\paren{-\frac{x^2}{2\sum_{t=1}^nc_t^2}}.
\end{align*}
The desired inequality follows from the fact that $Z_0=\EE[\ltwo{S_n}]\leq \sqrt{\EE\ltwo{S_n}^2}\leq \sqrt{\sum_{t=1}^nc_t^2}.$
\end{proof}


\begin{lemma}\label{lem:uxxu}
For any vector $\x\in\R^d$ and positive-definite matrix $U$, the matrix $\Phi=\usqx$ is bounded under the Frobenius norm: $\nrmF{\Phi}\leq \nrm{\phi}$.
\end{lemma}

\begin{proof}
Denote $U^{1/2}\phi=(v_1, \cdots, v_d)$, then 
$\Phi=\|U\phi\|^{-1}(v_i v_j)_{i,j}\in\Rdd$, and hence
\[
\begin{aligned}
    \|\Phi\|_F &=\|U\phi\|^{-1}\paren{\sum_{i=1}^d v_i^2} 
    = \|U\phi\|^{-1} \nrm{U^{1/2}\phi}^2 
    = \|U\phi\|^{-1} \phi^{T} U \phi
   \le \|U\phi\|^{-1} \|U\phi\| \|\phi\| =\|\phi\|.
\end{aligned}
\]
\end{proof}

\begin{lemma}[Monotone matrix operation]\label{lem:matrix-monotone}
Suppose that $A, B\in\Rdd$ are PSD matrices, $B$ is invertible, and $A\preceq B$. Then it holds that $A\iv\succeq B\iv$ and $A\sq \preceq B\sq$.
\end{lemma}
\begin{proof}
Because $A\preceq B$, we have $(A\sq B\isq)\tp (A\sq B\isq)=B\isq A B\isq\preceq \id$, and hence $A\sq B\iv A\sq = (A\sq B\isq)(A\sq B\isq)\tp\preceq \id$, which implies $B\iv\preceq A\iv$.

Similarly, we have $\nrm{A\sq v}\leq \nrm{B\sq v}$ for all $v\in\R^d$, and hence $\nrmop{A\sq B\isq}\leq 1$. Let $D=B\sups{-1/4}A\sq B\sups{-1/4}$. Because $D$ is symmetric, all eigenvalues of $D$ are real numbers. For any eigenvalue $\lambda$ of $D$, we take an eigenvector $v$ of $\lambda$, i.e., $Dv=\lambda v$. Then, $A\sq B\isq (B\sups{1/4}v)=\lambda (B\sups{1/4}v)$, and hence $\abs{\lambda}\leq 1$. Therefore, we can conclude that all eigenvalues of $D$ are bounded by $1$, and hence $\nrmop{D}\leq 1$, which implies $A\sq\preceq B\sq$.
\end{proof}

\begin{lemma}\label{lem:cov-k-converge}
Let $\bSigma$ be a positive semi-definite matrix with $\bSigma\preceq \id$, and $\eta\in[0,1]$. For any integer $k\geq 0$,  we have $\nrmop{\bSigma\sq (\id-\eta\bSigma)^k}\leq \sqrt{\frac{2e}{\eta k}}$.
\end{lemma}

\paragraph{Proof}
Let the $1\geq \lambda_1\geq \cdots\geq \lambda_d\geq 0$ be the spectrum of $\bSigma$. Then 
\begin{align*}
    \nrmop{\bSigma\sq (\id-\eta\bSigma)^k}=\max_{i\in[d]}\sqrt{\lambda_i}(1-\eta\lambda_i)^k
    \leq\sup_{\lambda\in[0,1]} \sqrt{\lambda}e^{-\eta k\lambda}\leq \sqrt{\frac{2e}{\eta k}}.
\end{align*}
\qed
