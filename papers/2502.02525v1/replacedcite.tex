\section{Related Work}
\label{Related Work}
This section first reviews the object pose and size estimation methods, dividing them into instance-level and category-level methods, and then reviews recent diffusion model-based methods and explains how our proposed method differs from them. Finally, we review the object pose estimation-based robotic grasping methods.

\vspace{-1.25em}
\subsection{Instance-Level Methods}
Instance-level methods are trained on known objects ____ and can be mainly divided into three categories: correspondence-based, template-based, and direct regression-based. Correspondence-based methods can be further divided into 2D-3D correspondence and 3D-3D correspondence. 2D-3D correspondence methods____ first define the keypoints between RGB image and object CAD model. This is followed by training a model to predict the 2D keypoints and using the Perspective-n-Points (PnP) algorithm to solve the object pose. 3D-3D correspondence methods____ define the keypoints on the object CAD model directly and use the observed point cloud to predict the predefined 3D keypoints. Next, they apply the least squares algorithm to solve the object pose. However, most correspondence-based methods rely heavily on rich texture information and may not work well when applied to textureless objects.

\par There are some point cloud-based template methods, which are based on point cloud registration ____. Specifically, the template is the object CAD model with the canonical pose, and the purpose of these methods is to find the optimal relative pose that aligns the observed point cloud with the template. Besides these methods, RGB-based template methods____ also exist, which require collecting and annotating object images from various perspectives during the training phase to create templates. After that, these methods train a template matching model to find the closest template to the observed image and use the template pose as the actual pose of the object. Overall, template-based methods can be effectively applied to textureless objects, however, the template-matching process is generally time-consuming.

\par With the rapid advancement of deep learning technology, direct regression-based methods____ have recently gained popularity. These methods use the ground-truth object poses for supervision and train models to regress the object pose end-to-end. Specifically, DenseFusion____ fuses the RGB and depth features and proposes a pixel-level dense fusion network for pose regression. FFB6D____ further designs a bidirectional feature fusion network to fully fuse the RGB and depth features. GDR-Net____ proposes a geometry-guided network for end-to-end monocular object pose regression. HFF6D____ designs a hierarchical feature fusion framework for object pose tracking in dynamic scenes. Although instance-level methods have achieved high accuracy, they are restricted to fixed instances, meaning that they only work for specific objects on which they are trained.

\vspace{-1em}
\subsection{Category-Level Methods}
Research in the domain of category-level methods has received substantial attention given their potential for generalization to unknown objects within the given object categories. 
NOCS____ introduces a normalized object coordinate space, providing a standardized representation for a category of objects, and recovers object pose using the Umeyama algorithm. SPD____ leverages shape prior deformation to solve the problem of diverse shape variations between intra-class objects. Due to the superior performance achieved by SPD, other prior-based methods are also subsequently proposed. CR-Net____ designs a recurrent framework for iterative residual refinement to improve the shape prior-based deformation and coarse to fine object pose estimation. SGPA____ utilizes the structure similarity between the shape prior and the observed intra-class unknown object to dynamically adapt the shape prior. 6D-ViT____ introduces Pixelformer and Pointformer networks, based on the Transformer architecture, to extract more refined features of the observed objects. STG6D____ goes a step further and fuses the difference features between the shape prior and the observed objects, enabling more refined deformation. RBP-Pose____ designs a geometry-guided residual object bounding box projection network to solve the insufficient pose-sensitive feature extraction.
%SSP-Pose____ introduces an end-to-end method via integrating shape prior into a direct pose estimation network, avoiding the use of the undifferentiable Umeyama algorithm.
CATRE____ proposes a pose refinement method based on the alignment of the observed point cloud and the shape prior, which can be used to further refine the object pose estimated by the above methods. GeoReF ____ builds upon CATRE ____ to tackle the geometric variation issue by incorporating hybrid scope layers and learnable affine transformations. Although prior-based methods significantly improve accuracy, constructing CAD model libraries is cumbersome and time-consuming. 

\par Besides these prior-based methods, DualPoseNet____ introduces a dual pose encoder with refined learning of pose consistency and regresses object pose via two parallel pose decoders. FS-Net____ proposes a shape-based 3D graph convolution network and performs decoupled regression for translation, rotation, and size. GPV-Pose____ harnesses geometry-guided point-wise voting to enhance the learning of category-level pose-sensitive features. HS-Pose____ further proposes a hybrid scope feature extraction network, addressing the limitations associated with the size and translation invariant properties of 3D graph convolution. IST-Net____ explores the necessity of shape priors for category-level pose estimation and proposes an implicit space transformation-based prior-free method. VI-Net____ addresses the problem of poor rotation estimation by decoupling rotation into viewpoint and in-plane rotations. While these methods do not depend on shape priors, they still require large amounts of real-world annotated data for training, which hinders their practical applicability.

\par To address the problem of insufficient real-world training data, CPPF____ performs pose estimation in the wild by introducing a category-level point pair feature voting method. SAR-Net____ proposes to explore the shape alignment of each intra-class unknown object against its corresponding shape prior without using real-world training data. SSC6D____ proposes a self-supervised method using DeepSDF____ for deep implicit shape representation. UDA-COPE____ utilizes a teacher-student self-supervised learning framework to achieve domain adaptation. RePoNet____ proposes a self-supervised method based on pose and shape differentiable rendering. DPDN____ designs a parallel deep prior deformation-based domain generalization learning scheme. More recently, TTA-COPE____ introduces a test-time adaptation method, which initially trains the model on labeled synthetic data and subsequently utilizes the pretrained model for test-time adaptation in real-world data during inference. Nevertheless, the performance of these methods is limited by the huge domain gap between the rendered synthetic domain and the real world.

\begin{figure*}[htbp]
\centering
\includegraphics[width=\textwidth]{Fig2.jpg}
\vspace{-2em}
\caption{Some visualizations of the reverse diffusion process, representing the diffusion from Gaussian noise poses to objects poses in the observed scene.}
\label{Fig2}
\vspace{-1em}
\end{figure*}

\vspace{-1em}
\subsection{Diffusion Model-Based Methods}
\par More recently, diffusion models gained popularity in object pose estimation. In terms of instance-level methods, DiffusionReg ____ proposes a point cloud registration framework leveraging the SE(3) diffusion model. This model gradually perturbs the optimal rigid transformation of a pair of point clouds by continuously injecting perturbations through the SE(3) forward diffusion process. The SE(3) reverse denoising process is then used to progressively denoise, approaching the optimal transformation for precise pose estimation. 6D-Diff ____ develops a diffusion-based framework that formulates 2D keypoint detection as a denoising process, enabling more accurate 2D-3D correspondences. As for category-level methods, GenPose ____ introduces a score-based diffusion model to tackle the multi-hypothesis issue in symmetric objects and partial point clouds. Their approach first uses the score-based diffusion model to generate multiple pose candidates and then employs an energy-based diffusion model to eliminate abnormal poses. DiffusionNOCS ____ first diffuses the NOCS map of the object using multi-modal input as a condition, and then uses an offline registration algorithm to align and solve the object pose.

\par In general, DiffusionReg ____ and 6D-Diff ____ are instance-level methods. GenPose ____ and DiffusionNOCS ____ mainly focus on 6-DoF pose (excluding 3D size). Moreover, GenPose does not focus on solving the problem of domain generalization, and the diffusion target of DiffusionNOCS is the NOCS map. Different from the above methods, we aim to develop a category-level 9-DoF object pose estimation method suitable for real-world robotic applications using only rendered synthetic data for training. This approach faces two main challenges: \textbf{1)} The significant domain gap between synthetic and real-world data, which adversely affects the performance of conventional regression models. We propose using a denoising diffusion probabilistic model to frame object pose estimation as a generative process. The diffusion model performs extensive sampling on the Markov chain, which can effectively expand the distribution of the synthetic pose data, making the data distribution more uniform ____, thus contributing to reducing the impact of the domain gap on the pose estimation model. \textbf{2)} Efficient pose estimation is crucial due to the limited computational resources available in robotics. To address this problem, we design a simple yet effective network structure, employing lightweight baseline networks (ResNet18 ____ for RGB image and PointNet ____ for point cloud) and using only global features as conditions. Additionally, given the sparsity of object pose data (only 15 values), our approach differs from dense diffusion tasks like image generation and can be efficient with fewer diffusion steps.

\vspace{-1em}
\subsection{Object Pose Estimation-Based Robotic Grasping}
To investigate the application of object pose estimation technology for robotic grasping, Zhang \emph{et al.}____ developed a practical robotic grasping system based on pose estimation with protective correction. GenPose ____ proposes a score-based diffusion method for 6-DoF object pose estimation and explores its application for robotic manipulation. Liu \emph{et al.}____ introduced a difference-aware shape adjustment method based on fine segmentation. They also built a robotic grasping platform to verify the practical performance of the pose estimation. For applications where depth images are not practical, e.g., under strong or low light conditions or for transparent and reflective objects, Wolnitza \emph{et al.}____ proposed a monocular method for 3D object reconstruction and object pose estimation and used it for robotic grasping. BDR6D____ is another method that first predicts the depth information from a monocular image and then utilizes a bidirectional depth residual network for pose estimation. The proposed method is then deployed with a UR5 robot to perform grasping and manipulating tasks. More recently, STG6D____ develops a robotic continuous grasping system via a category-level method and proposes a pre-defined vector orientation-based grasping strategy. DGPF6D____ introduces a contrastive learning-guided shape prior-free category-level method for domain-generalized robotic picking. Yu \emph{et al.}____ proposed a self-supervised-based category-level object pose estimation method for robotic grasping. Chen \emph{et al.}____ explored a sim-to-real method by iterative self-training for robotic bin picking.

\par Side-stepping from the above object pose estimation methods for robotic grasping, this paper proposes a DDPM-based novel paradigm for domain-generalized category-level 9-DoF object pose estimation, redefining the pose estimation process from a generative perspective. Leveraging the latent generalization ability of the diffusion model, the proposed method achieves training solely with rendered synthetic images for generalization to real-world robotic grasping scenarios.

\vspace{-0.5em}