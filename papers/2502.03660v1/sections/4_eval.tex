\vspace{-0.2cm}
\section{MLIP Metrology: Testing \& Interpretability} \label{sec:eval}
\vspace{-0.1cm}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

Since MLIPs serve as materials design tools for scientific end-users, they can benefit from being intuitive, reliable, and easy to test and analyze. As such, the development of \emph{MLIP metrology} to reliably analyze properties, behavior, and limitations for MLIPs becomes important. Based on current research, we suggest a preliminary start of MLIP metrology techniques, which help build towards a greater understanding of the capabilities and limitations of MLIPs, focused on: 1. large-scale benchmarking across materials and conditions as described in detail in \Cref{app:sec:mlip-eval}; 2. MLIP visualization and analysis, such as energy landscape visualization \citep{bihani2024lowdimensional}; 3. stability based analysis methods to enhance simulation reliability \citep{brandstetter2022message,raja2024stability,ibayashi2023allegro}; 4. interpretability studies to understand MLIP inner workings \citep{leeDeconstructingEquivariantRepresentations2024}. 

\textbf{Challenge 4.1} \textit{Develop MLIP metrology relying on large-scale evaluation of MLIPs in diverse materials, visualizing the energy landscape instead of simple pairwise interactions, and analyses of stability during MD simulations.} 

In the case of interpretability, for example, recent work has shown a lack of understanding and transparency in the learned representations of equivariant models using spherical harmonics and tensor products commonly used in current MLIPs. \citet{leeDeconstructingEquivariantRepresentations2024} showed that latent embeddings of an equivariant model projected and visualized with manifold structure preserving methods like PHATE \citep{moonVisualizingStructureTransitions2019} showed no discernable structure, highlighting a strong need for both new projection methods \emph{and} control over training dynamics for these methods. One potential architectural remedy relates to ``white-box'' or ``glass-box'' models, named so due to their intrinsic transparency and comprehensibility (i.e. intentionally simple structure) or through post-hoc explanation \citep{esdersAnalyzingAtomicInteractions2025,goethalsNonlinearNatureCost2022, esders2024analyzing, wangX2GNNPhysicalMessage2024}. While there have been traditional modelling efforts dedicated to comprehensible models, they receive significantly less attention to their black-box counterparts. \citet{pfauAccurateComputationQuantum2024} provides a framework for showing state-of-the-art modelling whilst remaining highly intuitive to computational chemists by infusing chemical first principles into the neural network. 

An important consequence of the paradigm proposed by \citet{pfauAccurateComputationQuantum2024} is the ability for learned representations and intermediate solutions to pass property tests, in contrast to black-box MLIPs: eigenvalues and vectors from derived solutions behave as physical models do (e.g. electron spin), and in the context of comprensiblilty, the ability to obtain \emph{variational} bounds on results means that quantitative behavior is well-understood. Intermediate approaches towards comprehensible models for materials modeling could borrow ideas from interpretable modeling choices, such as generalized additive models (GAM) \citep{hastieGeneralizedAdditiveModels1986,woodGeneralizedAdditiveModels2024} and derivatives like explainable boosting machines \citep{louIntelligibleModelsClassification2012}. 
An example hybrid approach that marries existing approaches with interpretable methods could be mapping equivariant features embedded as irreducible representations to outputs with GAMs---in doing so, we preserve physically motivated and intuitive signals (i.e. learned features with specific symmetries), and are able to understand \emph{why} a prediction is made through decomposition. Relating to \citet{leeDeconstructingEquivariantRepresentations2024}, this may unlock further improvements in model design and hyperparameter choice.

\textbf{Challenge 4.2} \textit{Develop interpretable architectures and methods that probe MLIPs, making them transparent and interpretable, either by design or post-hoc analysis.}

