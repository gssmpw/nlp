\vspace{-0.2cm}
\section{Alternative Viewpoints \& Approaches}
\vspace{-0.1cm}
\textbf{AV1: DFT is Good Enough \& MLIPs Are Already Universal.} One reasonable alternative viewpoint is that current methods that aim to replicate DFT-level accuracy for property prediction provide enough functional accuracy to perform large-scale materials screening leading to a downselection mechanism for further analysis. From that perspective, the main goal of MLIPs is to provide an accelerated way of filtering material candidates through reasonable property prediction and reduce the number of required downstream experiments. Additionally, MLIPs and DFT validation have already shown their effectiveness in validating the predicting of diverse materials generative models \citep{merchant2023scaling, levy2024symmcd, jiao2024space, zeni2025generative, miller2024flowmm, ding2024matexpert, gruver2024finetuned} that could provide valuable input to materials designers. As described in \Cref{sec:dft-limits}, DFT generally provides a reasonable trade-off between accuracy and computational cost, which largely underlies its popularity for high-throughput simulation and data generation. On top of that, there are cases where DFT is known to simulate properties well, informing both materials discovery and understanding. We believe that DFT, as well as MLIPs trained on DFT, will continue to have a role in future research at the intersection of ML and materials science but argue that we can utilize MLIPs for more ambitious purposes. Furthermore, recent research works claim and provide reasonable generalization of MLIPs to a set of cases not stricly observed in the DFT-based training data \citep{yang2024mattersim, merchant2023scaling, batatia2023foundation}. These results are encouraging that generalizeable MLIPs can be built, yet the evidence they provide is far from conclusive given conflicting results in other works \citep{bihani2024egraffbench, gonzales2024benchmarking}, indicating the need for further research work. While such challenges may be improved with additional data generation, eventually the limitations of DFT as the source of the data will become the limiation for the underlying MLIP.

\textbf{AV2: Large-Scale Experimental Data is Required to Train ML Models for Materials Discovery.} One of the primary reasons for the success of AlphaFold \citep{jumper2021highly} was the availability of high-quality sequence-structure data obtained by experimental measurements \citep{wwpdb2019protein}. Given the importance of aligning to experimental measurements as the most pertinent ground truth as described in \Cref{sec:mat-limits}, the approach of developing large, ML compatible databases appears attractive. We believe large-scale experimental data collection is a promising idea, yet most of the experimental datasets in materials remain small in large part due to the vast diversity of materials compounds and experimental conditions, as well as the large cost of experimental measurements \citep{xu2023small}. While interesting ideas exist related to driving automated data collection with AI-enabled, self-driving laboratories \citep{miret2024llms, sim2024chemos}, much research remains to be able to scale automated, reproducible experiment execution and data collection in the vast majority of materials design cases. Given this challenge, new research emerged to accelerate the planning, execution and analysis of materials science experiments with machine learning methods \citep{miret2024perspective}. As such, in silico materials design with performant simulation methods will continue to play an important part in materials discovery with MLIPs playing an important role. Furthermore, whereas the initial capabilities of AlphaFold represented a significant breakthrough, further challenges remain in aligning model predictions for real-world conditions \citep{terwilliger2024alphafold}, similar to the ones described in \Cref{sec:materials}. MLIPs integrated with atomistic simulations can be tested against targeted, small-scale experimental measurements, which in turn will drive further understanding of materials behavior.



\textbf{AV3: MLIPs are Not Required for Device Simulations. } Multiscale simulation approaches, which rely mostly on partial differential equations (PDEs) to model different length and time scales, provide a viable alternative to MLIPs for device scale simulation. On top of that, promising approaches for ML-based PDE acceleration are actively being developed \citep{kovachki2023neural, brunton2024promising, brandstetter2022message, takamoto2022pdebench}. We acknowledge that is a valid perspective and that the scalability and accuracy of MLIPs to device scale simulations remains an open research question that requires solving both the engineering and scientific challenges outlined in \Cref{sec:computation}. Evidently, until such challenges can be addressed with new methods, multiscale methods remain the best practical solution. 

\vspace{-0.2cm}
\section{Conclusion}
\vspace{-0.1cm}
For MLIPs to disruptively accelerate materials discovery, the community requires new research priorities that ultimately lead to fully atomistic device scale simulations with quantum mechanical accuracy. These types of simulations will unlock new realms of insight for how the composition of materials affects device performance. Using this guiding principle, we propose a number of interdisciplinary research challenges related to higher quality first-principles data generation, architecture and workflow design, proper inferencing, and algorithmic improvements for computational performance; all of which will require expertise from materials scientists, ML researchers, and software engineers.
