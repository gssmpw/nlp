\section{MLIPs for Materials Science Simulations} \label{sec:materials}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

Current gaps in MLIP research include the reliance on DFT for training data generation (\Cref{sec:dft-limits}) and the underrepresentation of diverse materials in MLIP datasets and evaluation methods (\Cref{sec:mat-limits}).
\Cref{sec:mat-limits} also describes the modeling of materials under realistic conditions, including how applying MLIPs jointly with MD simulations enables benchmarking against experimentally measured properties. \Cref{sec:mlip-dev} outlines recommendations for new research directions towards future MLIP training and development. 

\subsection{Limitations of DFT for Training Data Generation} \label{sec:dft-limits}
\textbf{DFT Methods Have Limited Accuracy:} A critical aspect for dataset quality is the quality of the method used to obtain ground truth labels. While DFT methods are by far the most common source of data for both ML research and materials scientists alike, the implementations used rely on a hierarchy of approximations. The accuracy of DFT rests primary on the quality of the functional form (see \Cref{sec:background}), and its shortcomings in the description of many \emph{key} chemical and physical phenomena are well-documented throughout the literature \citep{schuch2009computational}. The weaknesses of DFT manifest themselves in multiple forms, such as inaccuracies in calculating band gaps \citep{perdewDensityFunctionalTheory1985,bystromAddressingBandGap2024a}, fractional charges \citep{cohenChallengesDensityFunctional2012}, and general systems that demonstate static/strong electron correlation \citep{cohenFractionalSpinsStatic2008,suDescribingStrongCorrelation2018}. Recent DFT benchmarking work by \citet{araujoAdsorptionEnergiesTransition2022} shows that, without intricate corrections, the commonly applied PBE+D3 functional results in errors on the order of tens of kcal/mol (${\sim}0.5$\,eV) for adsorption energies on transition metal surfaces, making it impossible to model catalytic activity with uniform accuracy across the periodic table. Given the parametric approximations required for DFT, it is also easy to significantly overfit when modeling energy \citep{medvedevDensityFunctionalTheory2017}, resulting in poor generalization to other material properties. These errors can then further propagate to MLIP-based property prediction models.


\textbf{DFT Introduces Inconsistencies and Reproducibility Issues Across Different Codes:} 
The reproducibility of DFT calculations across different electronic structure codes presents a significant challenge for MLIP data generation. Even when using identical exchange-correlation functionals, variations in implementation details, basis sets, pseudopotentials, and numerical parameters can lead to discrepancies in computed energies and forces \citep{schuch2009computational,bootsmaPopularIntegrationGrids2019}. These inconsistencies, as prominently displayed in \citet{lejaeghere2016reproducibility,bosoniHowVerifyPrecision2024}, become particularly problematic when training MLIPs, as the resulting models inherently encode code-specific biases---not necessarily physical behavior. Another challenge is the DFT data generated by open-source code \textit{viz-a-viz} closed source packages. Most public DFT datasets (and workflows to generate those), such as MPTrj, OMat24 \citep{barroso2024open}, and Alexandria, rely on Vienna Ab-initio Simulation Package (VASP) \citep{kresse1994ab}, a closed-source commercial package. We encourage the use of open-source codes, such as Quantum Espresso \citep{giannozzi2009quantum} and CP2K \citep{kuhne2020cp2k}, to make data generation more accessible and reproducible. Even though these methods still suffer from implementation-specific variance, they enable greater scientific transparency.


\textbf{Data Generation with Higher Accuracy Methods:} Overall, we argue that the utility of continuing to apply DFT for large-scale data generation has diminishing returns due to known limitations and inaccuracies of the method. As such, we advocate for changing data generation methods to higher accuracy methods to avoid running into previously encountered obstacles with ML for atomistic modeling. Applying DFT for data generation and MLIP training may still be useful in targeted cases that further the understanding of specialized systems \citep{wang2024perovs, louIntelligibleModelsClassification2012} or novel scientific vantage points for materials science. However, MLIP performance is ultimately gated by the availability of high quality data, which necessitates more accurate simulation methods and targeted real-world experiments. Otherwise, many of the machine learning discoveries may be prone to hacking \citep{ghugare2024searching, govindarajan2024crystal} or materials with limited experimental utility \citep{cheetham2024artificial}. In our opinion, perhaps the strongest advantage of MLIPs is the ability to improve physical accuracy at constant computational inference cost: if an MLIP architecture approximates DFT [$\mathcal{O}(N^3-N^5)$], the true benefit lies in approximating a higher quality, higher cost function with the same number of floating point operations such as CCSD(T) [$\mathcal{O}(N^7)$], or even full configuration interaction [$\mathcal{O}(N!)$] as exact solutions to the non-relativistic electronic Schr\"{o}dinger equation. Given the computational cost of generating these labels, more research is required to effectively bootstrap high volume, low quality data (DFT) into low volume, high quality data (CCSD(T)). 

\textbf{Challenge 3.1.1.} \textit{Develop targeted higher accuracy simulation datasets (e.g., CCSD(T)) to enable the training and evaluation of MLIPs on higher quality data. The dataset generation methods should employ open-source ab-initio packages to enhance transparency, repoducibility, and accessibility to avoid previsouly encountered challenges with large-scale dataset generation based on DFT.}


\textbf{Hybrid ML+QM Approaches:} One interesting related research direction consists of ``hybrid'' solutions that aim to improve how quantum mechanical models are solved with machine learning: parameterized models are used as a basis or ans\"{a}tze for the solution of classical methods; i.e. bounded solutions to the exact Schr\"{o}dinger equation. A strong example of this approach is the variational Monte Carlo approach from \citet{pfauAccurateComputationQuantum2024} built on top of Psiformer/FermiNet \citep{pfau2020ferminet,glehnSelfAttentionAnsatzAbinitio2023}. These methods show significant promise for yielding accurate models for electronic and nuclear properties beyond simple energy and force regression targets. The difficulty faced by these approaches mainly lies in domain adaptation (e.g. periodic boundary conditions for solid-state structures) and scaling (i.e. larger and more diverse atomic systems). An important distinction to emphasize is that one quality target noted in \citet{pfauAccurateComputationQuantum2024} is based on \emph{experimental} measurements. 
When benchmarking MLIPs, experimental observations should be one of the most important criteria, even though these observations contain pertinent uncertainties. For example, spectroscopic and spectrometric methods remain the only way to infer the success of materials synthesis using incomplete signals based on pattern matching. This means that if a material has certain spectroscopic signatures, then it has a high chance of being the material of interest. 
As research in MLIPs progresses, the application of ML models for materials science should aim to reproduce or \emph{predict} the same expected signatures \citep{cheng2024determining}.

\textbf{Challenge 3.1.2.} \textit{Develop hybrid ML+QM methods that improve predictive accuracy against experimental data, such as observable properties and spectroscopic signatures.}


\subsection{Exploring Broader Ranges of Materials Under Realistic Application Conditions} \label{sec:mat-limits}

Current large datasets, such as MPtrj \citep{deng2023chgnet}, which several universal potentials have been trained on, have primarily focused on a limited set of materials. They sometimes even neglect broad classes of materials present in real-world applications, such as metallic glasses, disordered materials, metal organic frameworks, polymers, alloys, and doped semiconductors \citep{burner2023arc, wang2024perovs, vita2023colabfit, downs2003american}. Moreover, the current datasets like MPtrj are biased towards specific families of materials and elements. \Cref{fig:mptrj-data} shows that certain elements such as H, Li, Mg, Si, P, and O, along with their possible compounds, are overrepresented, with 89 elements completely missing. This highlights a significant gap in data availability for many materials systems, many of which are relevant to real-world applications. 

\begin{figure}[h]
    \vspace{-0.35cm}
    \centering
    \includegraphics[width=0.98\columnwidth]{figures/MPtrj_dataset.png}
    \vspace{-0.35cm}
    \caption{Frequency of elements in MPtrj dataset. The color bar in the figure represents a logarithmic scale ranging from low to high values, with the corresponding numbers indicating the frequency of each element's presence in the MPtraj dataset.}
    \label{fig:mptrj-data}
    \vspace{-0.35cm}
\end{figure}

In addition to the aforementioned limitations on DFT accuracy, the limited set of systems studied imposes additional constraints on MLIP models generalizing to new designs. This is further compounded by many DFT calculations only being evaluated in ideal conditions, meaning zero temperature and pressure, which does not properly approximate most application conditions. Some initial work has shown promise in ML models generalizing across different temperatures, pressures, and excited states \citep{merchant2023scaling, batatia2023foundation, westermayr2020machine}, but further work remains in understanding the abilities of MLIPs to model materials across a diversity of relevant application conditions. Variations may include temperature, pressure, inclusion of defects, and phase changes to name a few.


\textbf{Interface and Multi-Material Interactions:}
Most DFT datasets and benchmarks to date, with a notable exception of OpenCatalyst \citep{chanussot2021open, tran2023open}, have focused on modeling the properties of structures that represent a single bulk crystal or small molecules. While valuable to bootstrap the development of MLIPs, this is not sufficient to enable MLIP-based device scale simulation. Materials in modern devices interact with other materials around them to fulfill various complex performance requirements. As shown in \Cref{fig:mlip-req}, a modern transistor requires the intricate combination of multiple materials \citep{reddy2022comprehensive}, each of which provide essential functions. The need to model multiple materials and their interfaces reliably and accurately introduces a significantly more complex task than what is available in current training datasets.

\textbf{Aligning MLIP-Based Simulation Evaluation Towards Experimental Properties:} Given the vast set of applications for different materials, it is important to be able to model diverse sets of properties. One of the main advantages of MLIP-based simulations is the ability to model experimentally measurable properties, such as elastic moduli, thermal expansion, and thermal conductivity. Moreover, while considering the experimental properties, aligning the corresponding synthesis and testing conditions are important to make a meaningful comparison with the corresponding simulations. Thus, the measurements should be aligned to real-world conditions and properly documented. Such a database could potentially serve two purposes: i) Benchmarking MLIPs based on realistic scenarios encountered during applications; ii) Applying experimental data to train MLIPs for more accurate property prediction. Differentiable simulation frameworks provide an interesting framework to further the development of MLIPs by back-propagating directly through simulation trajectories to update MLIP and simulation parameters. Given the nascense of differentiable simulation frameworks, more research is needed to develop performant and rigorous simulation and theoretical frameworks \citep{gangan2024force, metz2021gradients}.  

\textbf{Challenge 3.2.} \textit{Systematically map and address data sparsity in materials databases through strategic generation of datasets for underrepresented chemical spaces and material families, enabling more comprehensive coverage of the materials genome in real-world conditions. Scale data generation to complex materials systems involving interfaces, reactions, and other complex interactions while driving greater aligment to experimental measurements.}

\subsection{MLIP Training \& Representation Learning} \label{sec:mlip-dev}

Most of today's MLIPs are based on message passing graph neural networks (GNNs) with geometric inductive biases that infuse different types of symmetries \citep{duval2023hitchhiker}. Many of these models have been trained and evaluated using regression objectives for energy and forces or other materials properties \citep{riebesell2023matbench, chanussot2021open, choudhary2020joint, lee2023matsciml}. Recently, new models have emerged that have made use of multiple datasets in their training pipeline \citep{barroso2024open, neumann2024orb} to achieve better overall performance and generalization. Compared to other fields, few methods have been proposed for self-supervised MLIP pretraining \citep{DeNS}. The success of denoising-based pretraining for effective representation learning in adjacent fields, such as proteins \citep{abramson2024accurate, zhang2023protein} and small molecules \citep{zaidi2023pretraining}, as well as the increasing data diversity related to MLIPs create the need to explore effective representation learning methods. 

As the scale of datasets increases, the computational requirements of pretraining will also increase, thereby prompting further investigation into scaling laws for MLIPs \citep{frey2023neural}. As both training and inference scale requirements increase, the utility of inductive biases will continue to remain a pertinent question. Recent work indicates that GNNs provide useful inductive biases \citep{alampara2024mattext} even though conflicting evidence has emerged in adjacent fields. Further, in the limit of large data regimes, invariant GNNs may perform as well as equivariant ones at lower cost~\cite{qu2024importance,brehmer2024does, JMLR:v25:23-0680}. Thus, a critical analysis of the inductive biases required while considering scalability and accuracy is needed to identify optimal architectures. Message passing in GNNs, for example, can become a bottleneck when deployed in simulations given the iterative nature of the inference pass needed to cover large graphs. This has prompted architectures without message passing that provide similar performance as GNNs \citep{bochkarev2024graph}. Additionally, given the tight coupling between MLIPs and data generation methods, the field could also benefit from data-centric ML research related to designing datasets and continued model improvement \citep{oala2024dmlr}, as well as knowledge distillation described in \Cref{app:distillation}.

\textbf{Challenge 3.3.} \textit{Creation of MLIPs architectures with relevant feature engineering, inductive biases, and training methods. Novel MLIPs should utilize larger and more heterogenous datasets, potentially drawing on ideas from large-scale representation learning for greater generalization.} 
