\section{Notation and Preliminaries}\label{sec:notation}

We work with a countable universe $\cX$, and countable hypothesis class $\cH$ to ensure sufficient measurability conditions.\footnote{See, e.g., \cite{measureone} and  \cite{measuretwo} for more sufficient measurability assumptions} We will write random variables $ \rx $ with boldface letters, and non-random $ x $ with non-bold face letters.  

We use $(\cX\times\{-1,1\})^{m}$ to denote training sequences of length $m$, with repetition. Further, we let $(\cX\times\{-1,1\})^{*}=\cup_{i=1}^{\infty}(\cX\times\{-1,1\})^{i}$ denote all possible finite training sequences. For sequences $S,T\in (\cX\times\{-1,1\})^{*}$, we write $S\sqcup T$ for the concatenation/union of the two sequences, i.e., $[S^T,T^T]^T$ where $^{T}$ denotes the transpose of the sequence, i.e. with repetitions. Furthermore, we call $ S' $  a sub training sequence of $ S $ if, for every $ (x,y)\in S' $, we have $ (x,y)\in S $. We sometimes write this as $S'\sqsubseteq S$. Note that $ S' $ may have a different multiplicity of a training example $ (x,y) $ than $ S $, possibly larger. For a set $A\subset \cX$ (without repetitions) we write $S\sqcap A$ for the training sequence $[S_{l}\mid S_{l,1}\in A]$, i.e., the sub training sequence of training examples $S_{l}$ of $S$ that has their feature $S_{l,1}$ in $A$.    

For $ a,b\in \mathbb{R} $ with $ a<b $, we write $ [a:b]=\{ x\in\mathbb{R} \mid a\leq x\leq b  \} $ and $ [a:b]^{*}=\cup_{i=1}^{\infty}[a:b]^{i} $ and $ ([a:b]^{*})^{*}=\cup_{i,j\in \mathbb{N}}([a:b]^{j})^{i} $. For $ a,b\in \mathbb{N} $ with $ a<b $, we write $ \{  a:b\}=\{ x\in\mathbb{N} \mid a\leq x \leq b \} $, with similar definitions for $ \{ a:b \}^{*} $ and $ (\{ a:b \}^{*} )^{*}$. When we for a random variable $ \rr $ write $ \rr\sim ([a:b]^{*})^{*} $, we mean that the $ \rr_{i,j} $'s are i.i.d. random variables uniformly drawn from $ [a:b] $. Similarly, for $ \rw \sim (\{ a:b \}^{*})^{*} $.  


For a distribution $ \cD $ over $ (\cX\times \{-1,1\}) $, we define the error under $ \cD $ as  $ \ls_{\cD}(h)=\p_{(\rx,\ry)\sim \cD}[h(x)\not=y]$ for $ h\in\{-1,1\}^{\cX} $. Furthermore, for a distribution $ \cD $ over $ \cX $  and a target concept $ c \in \cH$, we define the distribution $ \cD_{c} $ over $ (\cX\times \{-1,1\})^{*} $  as having measure $ \p_{\rx\sim \cD}[(\rx,c(\rx))\in A] $ for $ A \subset (\cX\times \{-1,1\})^{*}$.  

For a training sequence $ S\in(\cX\times \{-1,1\})^{*} $ and a hypothesis class $ \cH $, we say that $ S $ is realizable by $ \cH $ if there exists $h\in\cH  $ such that for all examples $(x,y) \in S $,  we have $ h(x)=y $.
For a training sequence $ S\in(\cX\times \{-1,1\})^{*} $ and a target concept $ c\in \cH $, we say that $ S $ is realizable by $ c $ if for all examples $(x,y) \in S $, we have $ c(x)=y $. Furthermore, for a distribution $ \cD $ over $ (\cX\times\{-1,1\})^{*} $ and $ \cH $, we say that $ \cD $ is realizable by $ \cH $ if, for any $ m\in\mathbb{N} $ and any realization $ S $ of $ \rS\sim \cD^{m} $, $ S$ is realizable by $ \cH $.          

We say that a learning algorithm is a $ \erm $ learning algorithm for a hypothesis class $ \cH $  if, given a realizable training sequence $ S \in(\cX\times\{-1,1\})^{*}$ by $ \cH $, it outputs $h=\erm(S) $ such that $ S $ is realizable by $ h $ and $ h\in \cH $.   

We define the VC-dimension of a hypothesis class $ \cH\subset \{ -1,1 \}^{\cX} $ as the largest number $ d $ such that there exists a point set $ x_1,\ldots,x_d \in \cX$ where, for each $ y\in\{ -1,1 \}^{d} $, there exists $ h\in \cH $ such that $ (h(x_1),\ldots,h(x_{d}))=y$. For a hypothesis class $ \cH $ and  $t\in\mathbb{N}$, we write $\dlh=\{f:f=\sum_{i=1}^{t} h_{t}/t, \forall i\in\{1:t\}, h_{i}\in \cH\}$ for the class of linear combination of $ t $ classifiers in $ \cH $.       
We assume that the following operations cost one unit of computation: reading an entry, comparing two numbers, adding, multiplying, calculating $\exp(\cdot)$ and $\ln{\left(\cdot \right)}$, rounding to a natural number


For a $ \erm $ algorithm for a hypothesis class $ \cH $  we define the training cost  $ \text{U}_{\text{Train}}(\cdot):=\Utrain(\cdot):\mathbb{N}\rightarrow\mathbb{N}$ for $ m\in\mathbb{N} $    as the maximal number of operations needed to find the function $ \erm(S) \in \cH$ given any consistent training sequence $S\in (\cX\times\{-1,1\})^{m}$ of size $ m $, i.e.,    $$\Utrain(m):=\sup_{\stackrel{S\in (\cX\times\{-1,1\})^{m}}{S \text{ consistent with } \cH}} \# \{ \text{Operations to}\text{ find } \erm(S)  \}.$$  Further we define the inference cost $\text{U}_{\text{Inference}}:= \Uinf\in \mathbb{N}$ as the maximal number of operations needed to calculate the value of $ h(x) $ for any $ x $ given any $ h=\erm(S)$, where $ S\in (\cX\times \{-1,1\})^{*} $ is consistent with $ \cH $, i.e., 
$$\Uinf=\sup_{\stackrel{h=\erm(S), S\in (\cX\times\cY)^{*}}{S \text{ consistent with } \cH,\text{ }x\in\cX}} \# \{ \text{Operations to calculate } h(x)  \}.$$
%And alternative definition of $ \Uinf $ could also have taking a parameter $ m $ which specifies the length of the consistent training sequence the $ \erm $-algorithm was run on, but we choose to opt for the simpler and more worst case definition. 

For a learning algorithm $ \cA:(\cX\times \{ -1,1 \} )^{*}\rightarrow \{ -1,1 \}^{\cX} $, we define the training complexity of $ \cA $ for an integer $ m $ as the worst case number of operations made by the learning algorithm when given a realizable training sequence by $ \cH $ of length $ m $ , i.e.  $$\sup_{\stackrel{S\in(\cX\times \{-1,1\})^{m}}{ S \text{ realizable by } \cH  }} \# \{\text{Operations to find } \cA(S)\}.$$ The inference complexity of a learning algorithm $ \cA $ for an integer $ m $ we define as the worst case cost of predicting a new point $ x\in \cX $ for the learned mapping $f= \cA(S) $, given a realizable training sequence by $ \cH $ of length $ m $   i.e. $$ \sup_{\stackrel{f=\cA(S),S\in (\cX\times \{-1,1\})^{m}}{ S \text{ is realizable by } \cH, \text{ } x\in \cX}} \#\{\text{Operations to calculate } f(x)\}.$$