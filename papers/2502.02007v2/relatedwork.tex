\section{Related Work}
\paragraph{Next-Token Prediction and Other Training Methods.}
% Next token prediction is a classic and widely adopted method for training LLMs, enabling them to acquire fundamental expressive capabilities. 
Recent studies have deepened our understanding of NTP through various perspectives. For instance, \citep{zhao2024implicit, thrampoulidisimplicit} analyze the geometric properties of word and context embeddings in the logits domain, revealing the mechanisms behind the sparsity and low-rank structures in logits space. Theoretical explorations by \citep{madden2024nexttokenpredictioncapacitygeneral} further investigate the capacity of NTP in single-layer transformers, focusing on the interplay between model parameters and output dimensions. Additionally, \citep{MechanicsofNextTokenPredictionwithSelf-Attention} leverage knowledge graphs to provide mechanistic insights into the NTP learning strategy, while \citep{heLawNextTokenPrediction2024} establish empirical scaling laws for NTP across diverse language models. Despite its widespread use, concerns about the limitations of NTP have spurred the development of alternative training paradigms. Recent work by \citep{pmlr-v235-bachmann24a, gloeckle2024better} highlights the potential of novel learning methods to address these limitations. For example, RHO-1 \citep{rho1} introduces a token-level scoring mechanism, selectively training on high-scoring samples to improve efficiency. Similarly, Phi-4 \citep{abdin2024phi4technicalreport} demonstrates significant advancements in reasoning capabilities by prioritizing high-quality data during training. While these innovations mark important progress, the relationship between different training methodologies and their corresponding generalization capabilities remains underexplored. A deeper understanding of this relationship is crucial for advancing the field and developing more robust and efficient LLMs.

% \paragraph{Initial Bias in Transformers}
% Regularization is an unavoidable issue in training neural networks. In recent years, the randomness introduced by Stochastic Gradient Descent (SGD) has been shown to lead to flatter solutions with better generalization, a result confirmed both empirically and theoretically \citep{smith2021on, barrett2022implicitgradientregularization, pmlr-v202-andriushchenko23b}. Beyond training implicit regularization, the initial bias introduced in \citep{InitialGuessingBias} significantly influences the features learned by neural networks. The concept of neural redshift, proposed by \citep{Teney_2024_CVPR}, demonstrates that the activation function, layer normalization, and depth of the Transformer largely determine the initial complexity of a network, thereby influencing the frequency of functions the network learns. Furthermore, \citep{Position} find that pretrained LLMs generate lower complexity sequences compared to untrained LLMs, highlighting the critical role of the NTP training method.

\paragraph{\textbf{Implicit Bias for Noise-Induced Regularization Techniques.}}
Implicit bias introduced by noise-induced regularization techniques has been widely studied in recent years. Different forms of noise often have a significant impact on the training process and the final performance of the model~\citep{zhu2019anisotropic}. Among the noise-induced regularization techniques, stochastic gradient descent (SGD) is the most widely studied. A series of works have shown that the noise introduced by SGD can improve the generalization ability of models by making the loss landscape flatter \citep{wu2020noisy,feng2021inverse,xie2020diffusion}. Specifically, \citep{mori2021power} highlight that the magnitude of SGD noise depends on the loss landscape, which is crucial for helping SGD converge to flatter minima. An alternative line of research \citep{wu2018sgd,ma2021linear} links SGD's preference for flatter minima to the dynamical stability of minima.
Dropout is another widely used technique to improve model generalization~\citep{dropdim, dropattention, drophead, li2023dropkey, demand_dropout, UniDrop, he2024matterstransformersattentionneeded}. A series of studies have shown that the noise introduced by dropout can enhance generalization ability from different perspectives~\citep{mianjy2018implicit, bank2020etf, lengerich2022dropout, cavazza2018dropout, wei2020implicit, zhang2023stochastic}. \citet{zhang2024implicit} find the noise introduced by dropout can foster model condensation and improve the flatness of the loss landscape, explaining the reasons for dropoutâ€™s improvement of model generalization from two aspects. In this work, we draw an analogy between NTP and noise-induced training methods, and explore the impact of NTP on the model's reasoning capabilities.