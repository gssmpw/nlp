\begin{algorithm}[t]
\caption{DiBO}
\label{alg}
\begin{algorithmic}[1]
    \STATE \textbf{Input:} 
        Initial dataset \(\mathcal{D}_0\);
        Max rounds \(R\);
        Batch size \(B\); 
        Buffer size \(L\); 
        % Local search steps \(J\);
        % Temperature \(\beta\);
        Diffusion model $p_{\theta}$, $p_{\psi}$;
        Proxy $f_{\phi_1},\cdots f_{\phi_K}$
    % \STATE \textbf{Output:}
    %     Optimal design $\mathbf{x}^{*}$
    \FOR{\(r = 0, \ldots, R-1\)}
        % \STATE Initialize $p_{\theta}$ and $f_{\phi_1},\cdots f_{\phi_M}$
        \STATE \textbf{Phase 1. Training Models}
        % \STATE Initialize $p_{\theta}$ and $f_{\phi_1},\cdots f_{\phi_M}$
        % \STATE Compute weights for \((\mathbf{x}, y) \in \mathcal{D}_r\) \eqref{weighted sampler}
        % \STATE Train Proxies \(f_{\phi_i}(\mathbf{x})\) \eqref{proxy}, and Prior \(p_\theta(\mathbf{x})\) 
        %         \eqref{prior}
        \STATE Compute weights $w(y, \mathcal{D}_r)$ with \cref{eq:weighted sampler}
        \STATE Train $f_{\phi_1},\cdots f_{\phi_K}$ with \cref{eq:proxy}
        \STATE Train $p_{\theta}$ with \cref{eq:prior}
        \STATE
        \STATE \textbf{Phase 2. Sampling Candidates}
        \STATE Initialize $p_{\psi}\leftarrow p_{\theta}$
        \STATE Train  $p_\psi$ with \cref{eq:Posterior} using $\mathbf{x}_{0:T}$ from $p_{\psi}$ or from the dataset $\mathcal{D}_r$
        \STATE Sample \(\{\mathbf{x}_i\}_{i=1}^M \sim p_\psi(\mathbf{x})\)
        \STATE Update \(\{\mathbf{x}_i\}_{i=1}^M\) into \(\{\mathbf{x}_i^{*}\}_{i=1}^M\) with \cref{eq:local search1}
        \STATE Filter top-$B$ samples \(\{\mathbf{x}_b\}_{b=1}^B\) among \(\{\mathbf{x}_i^{*}\}_{i=1}^M\)
        % \FOR{j=0, ..., J-1}
        \STATE
        \STATE \textbf{Evaluation and Moving Dataset}
        \STATE Evaluate $y_b=f(\mathbf{x}_b),\quad\forall b=1,\cdots,B$
        \STATE Update \(\mathcal{D}_{r+1} \leftarrow\mathcal{D}_r\cup\{(\mathbf{x}_b, y_b)\}_{b=1}^B\)
        \IF{$\vert\mathcal{D}_{r+1}\vert>L$}
            \STATE Remove bottom-$(\vert\mathcal{D}_{r+1}\vert-L)$ samples from $\mathcal{D}_{r+1}$
        \ENDIF
        % \STATE $\{\mathbf{x}^{j+1}_i\}_{i=1}^M \leftarrow$ \textbf{Local Search} $(\{\mathbf{x}^j_i\}_{i=1}^M)$ \eqref{local search}
        % \ENDFOR
        %\STATE Select top $B$ samples with \(\frac{1}{\beta}\,r_\phi(\mathbf{\hat{x}}_j) + \log p(\mathbf{\hat{x}}_j)\). 
        % \STATE \(\{\mathbf{x}_i\}_{i=1}^B \leftarrow 
        %     \textbf{Filtering } \bigl(\{\mathbf{x}_i^J\}_{i=1}^M\bigr)\) \eqref{filtering}
        % \STATE \(\mathcal{D}_{r+1} \leftarrow 
        %     \mathcal{D}_r \cup 
        %     \bigl\{\mathbf{x}_i, f(\mathbf{x}_i)\bigr\}_{i=1}^B\)
        % \STATE $\mathcal{D}_{r+1} \leftarrow $\textbf{Buffer Management} $(\mathcal{D}^{r+1})$ \eqref{buffer management}
    \ENDFOR
\end{algorithmic}
\end{algorithm}