\section{Related work}
\textbf{Neural Temporal Point Processes (NTPP).} With the ability of deep learning models to handle sequential data, various architectures of neural point processes have emerged in recent years. Most of these models implement RNNs ____ or attention mechanisms ____ as their base architecture. Compared to RNN-based models, attention-based models have shown better performance in applications that benefit from long-term dependency computation. Compared to classical temporal point process models such as the Hawkes process ____ or Poisson processes ____, these neural models show superior performance because of their ability to handle continuous state spaces and by offering greater flexibility in modeling state transition functions. With recent rapid advancements in NTPP model architectures, their applications are beginning to gain traction in various domains.

\vspace{10pt}

\noindent\textbf{Interpretable clinical event onset prediction.} Attention mechanisms ____ shine in their ability to elucidate a model's decisions by emphasizing the features to which the model allocates the most attention. They have also proven invaluable in the realm of clinical event onset prediction. Consequently, a majority of interpretable clinical event onset prediction models leverage attention to determine feature importance ____. While NTPPs can be a powerful tool in addressing interpretability by predicting events preceding the event of interest, their effectiveness within clinical contexts remains largely unexplored.