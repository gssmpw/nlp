\section{Algorithms}\label{sec:algorithm}


In this section, we present five algorithms to find a good subgraph for our \prbstrwk problem. 
First, we propose an algorithm based on integer linear programming that finds a near-optimal or exact solution for our problem in Section~\ref{sec:ip}. Next, we state a polynomial time algorithm that solves a linear program in Section~\ref{sec:lp} followed by three heuristics presented in Sections~\ref{sec:stc-dense} and~\ref{sec:greedy}.


\subsection{Exact solution using integer programming}\label{sec:ip}

In this section, we present an integer linear programming~(ILP) based algorithm that can be used to find an exact solution for \prbstrwk.
To solve \prbstrwk we need the following auxiliary problem. The proofs for this section are given in Appendix~\ref{appendix:ip}.


\begin{problem}[$\prbstrwk(\alpha)$]
\label{pr:label-subgrap-str-wk-alpha}
Given a graph $G = (V, E)$, a weight parameter $\lambda$, and a number $\alpha$, find a subset of vertices $U \subseteq V$ and a labeling $L$ of the edges such that the \stc property is satisfied in $(U, E(U))$ and $m_s(U, L) + \lambda m_w(U, L) - \alpha \abs{U}$ is maximized.
\end{problem}

The following proposition, which is an instance of fractional programming~\citep{dinkelbach1967nonlinear}, shows the relationship between $\prbstrwk(\alpha)$ and \prbstrwk.

\begin{proposition}
\label{prop:frac}
Let $U(\alpha)$ and $L(\alpha)$ be the subgraph and the corresponding labeling solving $\prbstrwk(\alpha)$. Similarly, let $U^*$ with labeling $L^*$ be the solution for \prbstrwk. Write $\alpha^* = \score{U^*, L^*}$. If $\alpha > \alpha^*$, then $U(\alpha) = \emptyset$. If $\alpha < \alpha^*$, then $U(\alpha) \neq \emptyset$ and $\score{U(\alpha), L(\alpha)} > \alpha$.
\end{proposition}



We can use the proposition to solve \prbstrwk: we find the (almost) largest $\alpha$ for which $\prbstrwk(\alpha)$ yields a nonempty solution. Then $\prbstrwk(\alpha)$ for such $\alpha$ yields an (almost) optimal solution.

We can solve $\prbstrwk(\alpha)$ with an integer linear program,
\begin{alignat}{3}
\textsc{maximize}&\quad&\sum x_{ij} + \lambda \sum z_{ij}  & - \alpha \sum y_i \label{obj} \textstyle  & 
	\\  
	\textsc{subject to}&& x_{ij} + z_{ij} & \leq y_i &  ij & \in E \label{ip_con_1}\\
	&&x_{ij} + z_{ij} & \leq y_j &  ij & \in E \label{ip_con_2}\\
        &&x_{ij}  + x_{jk} & \leq y_j &  (i, j, k) & \in Z \label{ip_con_3}\\
        &&x_{ij}, z_{ij} & \in \{0,1\} &  ij & \in E \label{var_x_z}\\
	% & z_{ij} \in \{0,1\} & \forall ij \in E\\
        &&y_{i} & \in \{0,1\} &  i & \in V \label{var_v} \quad.
\end{alignat}
Here, $G = (V, E)$ is the input graph and $Z$ is the set of all wedges in $G$.

To see why this program solves $\prbstrwk(\alpha)$,
let $S \subseteq V$ and $L$ be a solution to our $\prbstrwk(\alpha)$. The indicator variable $y_i$ denotes whether the node $i \in S$ or not. The indicator variables $x_{ij}$ and $z_{ij}$ denote if the edge $(i,j)$ is strong or not and $(i,j) $ is weak or not, respectively.
Constraints~\ref{ip_con_1}-\ref{ip_con_2} guarantee that each edge within $S$ is labeled either as strong or weak. Constraint~\ref{ip_con_3} ensures that the \stc constraint is satisfied.  

Proposition~\ref{prop:frac}
allows us to maximize $\alpha$
with a binary search. Here, we set the initial interval $(L, U)$ to $L = 0$ and $U = \frac{n - 1}{2}$, and keep halving the interval until $\abs{ U - L} \leq  \epsilon L$, where $\epsilon > 0$  is an input parameter, and return the solution to $\prbstrwk(L)$. We refer to this algorithm as \algip.
Next, we state that \algip yields an approximation guarantee of  $1/(1+\epsilon)$.

\begin{proposition}
Assume a graph $G = (V, E)$, $\lambda \in [0,\;1]$, and $\epsilon > 0$. 
Let $\alpha$ be the score of the solution returned by $\algip$ and let $\alpha^*$ be the optimal score of \prbstrwk. Then $\alpha \geq \alpha^*/(1 + \epsilon)$.
\label{prop:opt-ip-approx}
\end{proposition}


Next, we will show that if $\epsilon$ is small enough, we are guaranteed to find the exact solution.

\begin{proposition}
Assume a graph $G$ with $n$ nodes. Assume that the weight parameter $\lambda$ is a rational number $\lambda = \frac{a}{b}$. Then, if we set   $\epsilon = \frac{2}{bn^3}$, \algip returns an exact solution for the \prbstrwk problem in $\bigO{\log n + \log b}$ number of iterations.
\label{prop:opt-ip-exact}
\end{proposition}


\algip requires $\bigO{\log n - \log \epsilon}$ iterations, solving an integer linear program in each round. Note that solving an
ILP is \np-hard~\cite{Schrijver1998}, and the fastest known algorithm to solve an ILP exactly runs in ${\log h}^{\bigO{h}}$ time where $h$ is the number of variables~\cite{reis2023subspace}. In practice, we can solve $\prbstrwk(\alpha)$ for moderately sized graphs but for larger graphs solving the ILP becomes computationally infeasible.


This approach is related to two prior works. First, the algorithm by \citet{goldberg1984finding} for finding the densest subgraph problem uses a similar approach, except without the variables $z_{ij}$. In such a case, the program can be solved exactly with a minimum cut.
Secondly, \citet{adriaens2020relaxing} use a linear program with similar wedge constraints to approximate \prbminSTC.


\subsection{Algorithm based on linear programming}\label{sec:lp}

In this section, we present an algorithm, named \alglpstc, based on a linear program obtained by relaxing the integrality requirements of the integer linear program given in the previous section. More specifically,
we first find a fractional solution by solving a linear program~(LP) and then derive a good subgraph via a rounding algorithm. Note that solving linear programs can be done in polynomial time~\citep{karmarkar1984new, van2020deterministic}, and solvers are efficient in practice. The proofs for this section are given in Appendix~\ref{appendix:lp}.

Consider a relaxed version of the ILP, where we replace the constraints in Eqs.~\ref{var_x_z}--\ref{var_v} with $x_{ij}, z_{ij} \in [0, 1]$ and $y_i \in [0, 1]$. We will refer to this optimization problem as $\prbstrwkr(\alpha)$.

Note that we used $\prbstrwk(\alpha)$ combined with the binary search to solve \prbstrwk. We can define a relaxed version of \prbstrwk which then can be analogously solved with $\prbstrwkr(\alpha)$.

\begin{problem}[\prbstrwkr]
Given a graph $G = (V,E)$, a weight parameter $\lambda$, find a nonnegative set of variables $x_{e}$, $y_i$, $z_{e}$, where $e \in E$ and $i \in V$ maximizing
\[
    r(x, y, z) = \frac{\sum x_e + \lambda \sum z_e}{ \sum y_i}
    \quad\text{such that}\quad\text{Eqs.~\ref{ip_con_1}--\ref{ip_con_3} hold}.
\]
\end{problem}

\prbstrwkr is a relaxed version of \prbstrwk:
if we were to require that the variables in \prbstrwkr are binary numbers, then the problems become equivalent. The next proposition is an analog to Proposition~\ref{prop:frac}.

\begin{proposition}
\label{prop:frac2}
 Let $(x^*, y^*, z^*)$ be a solution to \prbstrwkr. Write $\alpha^* = r(x^*, y^*, z^*)$.
Similarly, let $(x(\alpha), y(\alpha), z(\alpha))$ be a solution $\prbstrwkr(\alpha)$.
 If $\alpha > \alpha^*$, then $\sum y_i(\alpha) = 0$. On the other hand, if $\alpha < \alpha^*$, then $\sum y_i(\alpha) > 0$ and $r(x(\alpha), y(\alpha), z(\alpha)) > \alpha$.
\end{proposition}



Proposition~\ref{prop:frac2} allows us to solve \prbstrwkr with $\prbstrwkr(\alpha)$ and a binary search, similar to \algip. However, we can solve \prbstrwkr directly with a single linear program, that is,


\begin{alignat*}{3}
	\textsc{maximize}&\quad& \sum x_{ij} & + \lambda  \sum z_{ij}   & 
	\\  
	\textsc{subject to} &&  x_{ij} + z_{ij} & \leq y_i &  ij & \in E \\
	&& x_{ij} + z_{ij} & \leq y_j &  ij & \in E\\
   && \sum y_i & = 1 \\
    && x_{ij}  + x_{jk} & \leq y_j & (i, j, k) & \in Z\\
        && x_{ij}, z_{ij} & \geq 0 &  ij & \in E\\
	% & z_{ij} \geq 0 & \forall ij \in E\\
        && y_{i} & \geq 0 &  i & \in V
\end{alignat*}

\begin{proposition}
\label{prop:lp}
The LP given above solves \prbstrwkr.
\end{proposition}

Our LP is related to the LP proposed  by~\citet{charikar2000greedy}, which is used to solve the densest subgraph problem exactly. 
We extend Charikar's LP by adding strong edges and additional \stc constraints.
Another related work is the LP proposed by~\citet{adriaens2020relaxing} which provides a $2$-approximation for \prbminSTC using similar wedge constraints.

\textbf{Rounding phase}:
Next, we describe the heuristic used to obtain the subgraph and the labeling from the variables. 
Let ($x^*$, $y^*$, $z^*$) be the solution to \prbstrwkr.
% Rounding algorithm as follows:
First we define a collection of sets $\calS =\{S_1, S_2, \ldots , S_n\}$ where $S_j = \{ i: y^{*}_i \geq  y_j^{*}\}$.
Then we enumerate over the collection of subgraphs induced by $\calS$. 

For each $S_j$, we initially set all the edges as weak. Then we enumerate over each edge $e \in E(S_j)$ starting from the largest $z_{e}^*$. Each edge $e$ is labeled as strong if the \stc property is not violated. This means that we check if there is any edge adjacent to any of the endpoints of $e$ which is already labeled as strong and still creates a wedge with $e$. We continue the same process for all the edges $e \in E(S_j)$ in the descending order of its $z_{e}^*$ value. Finally, out of all the subgraphs we pick the subgraph and the labeling that maximizes our score.

Constructing a labeling for a single $S_j$ amounts to enumerating over the wedges in $\bigO{nm}$ time, leading to a total time of $\bigO{n^2m}$ for the rounding.

\subsection{Label, find the densest subgraph, and relabel} \label{sec:stc-dense}
Next, we explain two algorithms that combine the existing methods for finding the densest subgraph and finding the STC-compliant labeling in an entire graph.

The approach is as follows.
First, we label the edges of the entire graph using \algminstc (see Section~\ref{sec:related}). Then we construct a weighted version of the graph assigning a weight of $1$ for strong edges and a weight of $\lambda$ for weak edges. Next, we search for the densest subgraph using \algdg or \algdc (see Section~\ref{sec:related}) in the new weighted graph.  
Finally, we relabel {\em only} the subgraph induced by the returned solution. Relabeling is used to improve the score since some of the edges might be marked as weak since they contributed to certain wedges in the original graph, nevertheless, some edges no longer contribute to all of those wedges.
The pseudo-code for this method is given in Algorithm~\ref{alg:dense}. We call the algorithm as \algdenseg or \algdensec
based on the subroutine used in Line~\ref{alg:dense-subgraph} of Algorithm~\ref{alg:dense}.

\begin{algorithm}[t!]
\caption{$\algdenseg(G, \lambda)$ and $\algdensec(G, \lambda)$, both find a subgraph $U$ and a labeling $L$ with good $\score{U, L; \lambda}$.}
\label{alg:dense}
    $L \define \algminstc(G)$\;
    $H \define$ the weighted graph by setting $1$ to strong edges and $\lambda$ to  weak edges of $G$\;
    $U \define  \algdg(H)$~\cite{goldberg1984finding}  or $\algdc(H)$~\cite{ charikar2000greedy}\label{alg:dense-subgraph}\;
    $L' \define \algminstc(G(U))$\;
    \Return subgraph $U$\ and its labeling $L'$\;
\end{algorithm}

Next, we present the computational complexities of the \algdensec and \algdenseg algorithms.

\begin{proposition}
Assume a graph $G$ with $n$ nodes and $m$ edges. Assume that the wedge graph $Z(G)$ contains $n'$ nodes and $m'$ edges.
Then the running time of \algdensec is in
\begin{align*}
	\bigO{\sum_{v \in V} \deg(v)^2 + (m + n \log n) + (m' + n')}  \subseteq \bigO{nm} \quad.
\end{align*}
\label{prop:dense}
\end{proposition}

\begin{proof}
The number of wedges in $G$, and hence the number of edges in $Z(G)$ is in $\bigO{\sum_{v \in V} \deg(v)^2} \subseteq \bigO{n\sum_{v \in V} \deg(v)}  \subseteq \bigO{nm}$. 
The number of vertices, $n'$, in the wedge graph $Z(G)$ is in $\bigO{m}$.
\algminstc estimates the minimum vertex cover problem with a maximum matching for $Z(G)$ and the subgraph, which has a running time of $\bigO{n' + m'}$ when the adjacency list representation is used for the graph~\cite{cormen2022introduction}. We can execute
\algdc in $\bigO{m + n \log n}$ time. The claim follows.
\end{proof}

\begin{proposition}
Assume a graph $G$ with $n$ nodes and  $m$ edges. Assume that the wedge graph $Z(G)$ contains $n'$ nodes and $m'$ edges.
Then the running time of \algdenseg  is in
\begin{align*}
\bigO{mn + n (n + m) \log n + (m' + n')} \subseteq \bigO{ mn \log n} \quad.
\end{align*} 

\label{prop:dense-goldberg}
\end{proposition}

\begin{proof}
The only change compared to Proposition~\ref{prop:dense} is that we are using an exact algorithm instead of an approximation algorithm for finding the densest subgraph.
The exact algorithm for an edge-weighted graph takes $\bigO{ M(n, n + m)\log n}$ time, and $M(n, n + m)$ is the time taken to solve the min-cut problem for a graph with $n$ number of nodes and $(n + m)$ number of edges.
It takes $\bigO{n (n + m)}$ to find the minimum cut
\cite{orlin2013max}. The claim follows.
\end{proof}

\subsection{Peeling with continuous relabeling}\label{sec:greedy}

The \algdensec algorithm, given in the previous section, first finds a labeling and then uses \algdc that constructs a set of subgraphs among which the subgraph with the highest score is selected. During this search, the labeling remains fixed. Our final algorithm modifies this approach by relabeling the graph as we are constructing the subgraphs.

Our approach is as follows. 
We start from the whole graph $G$ and label the edges as either strong or weak using \algminstc. 
Given a labeling $L$ and a subgraph $U$, let the weighted degree for a vertex $\scorev{v, U, L, \lambda}$ be defined as the sum of strong edges and weak edges in $U$ incident to $v$ weighted by $\lambda$, i.e., $\scorev{v, U, L} = \deg_s(v, U, L) + \lambda \deg_w(v, U, L)$ We drop $L$, $U$ or $\lambda$ when it is clear from the context.
At each iteration, we delete the node that has the minimum weighted degree $\scorev{v}$. After removing each vertex we relabel the remaining set of edges. Finally, we choose the subgraph $U$ which corresponds to the maximum score \score{U, \lambda} out of all the iterations.
The naive version for this method is given in Algorithm~\ref{alg:greedy}.

\begin{algorithm}[t!]
\caption{$\alggreedy(G, \lambda)$, finds a subgraph $U$ and a labeling $L$ with good $\score{U, L; \lambda}$}
\label{alg:greedy}
    $U \define V$\;
    \While {there are nodes} {
        $L \define \algminstc(G(U))$\label{alg:minstc-step}\;
	$u \define \displaystyle\arg\min_{ v \in U} \scorev{v, U, L, \lambda}$\label{alg:score-step}\;
	$U \define U \setminus \set{u}$\;
    }
	\Return best tested $U$ and its labeling $L$\;
\end{algorithm}


Next, we explain several tricks to speed up the naive implementation of Algorithm \ref{alg:greedy}. 
We focus on updating the wedge graph, modifying the minimum vertex cover, and updating individual scores of each vertex without computing them from scratch.

\textbf{Maintain wedge graph}: Note that on Line~\ref{alg:minstc-step} of Algorithm~\ref{alg:greedy}, we need to repeatedly construct a wedge graph to solve \prbminSTC.
We can avoid this by maintaining the existing wedge graph as vertices are deleted.


When a node is deleted we need to consider only {\em deleting} respective edges in the wedge graph since new wedges cannot be introduced. Note that an edge in the original graph~$G$ corresponds to a node in the wedge graph $Z(G)$ and edges in $Z(G)$ represent wedges in $G$. Next, we state how to maintain $Z(G)$ when a vertex is deleted in Proposition \ref{prop:wedge}.

\begin{proposition}
\label{prop:wedge}
Let $G = (V, E)$ be a graph.
Let $v$ be a vertex in $G$. Define $G' = G(V \setminus \set{v}, E \setminus N(v))$, where $N(v)$ is the set of adjacent edges of vertex $v$ in $G$.
Then, a new wedge graph $Z(G')$ is formed by deleting the vertices in $Z(G)$ corresponding to $N(v)$. 
\end{proposition}
We omit the straightforward proof.

 

\textbf{Dynamic vertex cover using maximal matching}:
Next, we consider updating the vertex cover after a vertex deletion. 

Recall that we use maximum matching to approximate the vertex cover in \algminstc.
Given a maximal matching of the current graph, \citet{ivkovic1993fully} presented a simple algorithm to maintain the cover when an {\em edge} is deleted or inserted. Here we modify their algorithm slightly to adapt to a node deletion from $G$. 
Let us consider the case where the vertex $v$ is deleted from the original graph $G$. 
Note that $N(v)$ is a set of edges in $G$ which corresponds to a subset of nodes in $Z(G)$.
According to Proposition~\ref{prop:wedge},
the set of nodes corresponding to $N(v)$ should be deleted from the wedge graph $Z(G)$ to compensate for the deleted vertex. We assume that a maximal matching~$M$ of $Z(G)$ is given.


The algorithm is as follows.
We iterate over the elements in $N(v)$ and pick a node $a \in N(v)$ in $Z(G)$. We then test whether there is an edge $(a, b)$ in $M$ for some $b$. There can be only one, and if there is, we delete it. Upon such deletion, $M$ may no longer be maximal since $b$ may have a single adjacent edge that can be added. We search for such an edge and add it if one is found. 

The pseudocode is given in Algorithm~\ref{alg:dynamic-vc-node-pov}.
Algorithm~\ref{alg:dynamic-vc-node-pov} still produces a maximal matching; thus a $2$-approximation for \prbcovermin is guaranteed.


\begin{algorithm}[t!]
\caption{$\algdynvc(M,  v)$, maintains a vertex cover (a maximal matching $M$) when a node $v$ is deleted}
\label{alg:dynamic-vc-node-pov}
    \ForEach {$a \in N(v)$} {
        \If {there is $b$ such that $(a, b) \in M$} {
            delete $(a, b)$ from $M$\;
            \If {$b \notin N(v)$ \AND there is $t \notin N(v)$ such that $t$ is not an endpoint of any edge in $M$ and $(b, t) \in E(Z(G))$} {
                add $(b, t)$ to $M$\;
            }
        }
    }
    \Return $M$\;
\end{algorithm}

\textbf{Speeding the vertex selection}:
We can speed up finding the next vertex by maintaining $\scorev{v, \lambda}$ in a priority queue.
Once a vertex is deleted, we need to update the degree of its neighboring nodes. Also, we may need to update the weighted degree of the affected vertices if the vertex cover of $Z(G)$ changes. However, the number of changed edges in the vertex cover is constant.
The final version of the algorithm is presented in Algorithm~\ref{alg:greedy-fast-2}. 

\begin{algorithm}[ht!]
\caption{$\alggreedyfastest(G, \lambda)$, finds a subgraph $U$ and a labeling $L$ with good $\score{U, L; \lambda}$}
\label{alg:greedy-fast-2}
    $L \define \algminstc(G)$\;
    $P \define$ priority queue where each node is ranked by $\scorev{v, L}$\;
    $U \define V$\;
    \While {there are nodes} {
	$u \define \displaystyle\arg\min_{ v \in U} \scorev{v, U, L} \label{alg:score-step-pq}$\;
        $U \define U \setminus \set{u}$\;
        Update the wedge graph $Z((U, E(U)))$\;
        Update labeling $L$ using Algorithm~\ref{alg:dynamic-vc-node-pov}\;
        Update $P$\;
    }
    \Return best tested $U$ and its labeling $L$\;
\end{algorithm}

Next, we state the computational complexity of \alggreedyfastest.

\begin{proposition}
Assume a graph $G$ with $n$ nodes and  $m$ edges. Assume that the wedge graph $Z(G)$ contains $n'$ nodes and $m'$ edges.
Then the running time of \alggreedyfastest is in
\[
\bigO{ mn  + (n' + m') + m \log n + nm} \subseteq \bigO{nm} \quad.
\]
\label{prop:greedy}
\end{proposition}
\begin{proof}
Let $G_i$ be the graph at $i$th iteration. Consider deleting vertex $u$ from $G_i$.
Upon deletion, we need to update the priorities of the affected nodes in the queue.

When $u$ is deleted from $G_i$, we need to delete the set of nodes in $Z(G)$ which corresponds to the adjacent edges of $u$. 
For each deleted vertex in $Z(G)$, there can be at most one adjacent edge that belongs to the existing matching set.
Therefore, to compensate for the edge that is removed from the maximal matching set, we need to add at most one edge to the matching.
The two endpoints of the newly added edge correspond to two edges in $G_{i+1}$.
Therefore, the total number of vertices that require updating priorities is at most $4$. 
Moreover, deleting one edge from the existing matching set will affect the priorities of at most $2$ vertices.

In summary, $\bigO{\deg u}$ nodes need to be updated when we delete $u$. Consequently, the total update time of $P$ is in $\bigO{m \log n}$.
Moreover, the total update time for $Z(G)$ is in $\bigO{n' + m'}$. Updating $M$ requires finding a new edge which may cost $\bigO{n}$ time, consequently, updating $M$ requires $\bigO{nm}$ total time. Finally, the update time for $(U, E(U))$ is in $\bigO{m}$.

Initially, constructing $Z(G)$ requires  $\bigO{\sum_{v \in V} \deg(v)^2} \subseteq \bigO{nm}$ time and \algvcm requires $\bigO{n' + m'} \subseteq \bigO{nm}$ time.

Combining these times proves the claim.
\end{proof}

