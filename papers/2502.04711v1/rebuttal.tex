\documentclass[9pt,conference]{IEEEtran}
\IEEEoverridecommandlockouts
\usepackage{cite}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{algorithmic}
\usepackage{graphicx}
\usepackage{textcomp}
\usepackage{xcolor}
\usepackage{multirow}
\usepackage{makecell}
\usepackage{amsfonts}
\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
    T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}

\begin{document}

\title{Responses to Reviewers' Comments}


To Reviewer1 \\

\textbf{To be honest, it was difficult to remain calm after reading the reviewer's comments. Reviewer 1 completely fails to understand the methodology described in this paper and ignores the experimental results of this paper. Regardless, we appreciate the reviewer's efforts. We have addressed all of Reviewer 1's concerns point below. We sincerely hope that Reviewer 1 can take the review process seriously so that the efforts of everyone involved are not wasted.} \\

\textbf{Q1: The authors claim their novely as frequency-adaptive knowledge distillation, but the adaptive process seems too naive. They simply split the TF features into two parts, i.e., high-frequency and low-frequency parts and claim that the speech components mainly distributes in the LF part while noise mainly distributes in the HF part. On the one hand, I do not quite agree with this point because speech and noise are usually mixed in both LF and HF parts. On the other hand, there is no garantee that the teacher models are aware of this point.}

It appears that there may have been a misunderstanding on the part of Reviewer 1 regarding the central concept of our paper. We did not claim that low frequencies are exclusively associated with speech, nor that high frequencies are solely related to noise. What we propose is that the combination of different types of noise and various speakers' voices will exhibit distinct patterns. For instance, the frequency distribution of a male voice and a female voice, when mixed with identical noise, will inherently differ. Our methodology is designed to adaptively segment the frequency spectrum into high and low components based on these inherent differences.

Furthermore, our approach guides the high- and low-frequency components with tailored loss functions, enabling the model to learn the nuances of Speech Enhancement(SE) within each frequency band during the training phase, thereby enhancing its overall SE capabilities. Empirical evidence from our experiments indicates that our method not only augments the SE performance of the student model but also outperforms other existing methods, thereby validating the rationality and efficacy of our approach.

The fundamental postulate underlying the Knowledge Distillation (KD) algorithm is the presupposition of superior performance in the Teacher Model as compared to the Student Model. This premise enables the Student Model to emulate the Teacher Model's behavior and acquire its knowledge through the distillation process. Given that the Teacher Model is multiple times larger than the Student Model, it follows that the Teacher Model exhibits enhanced capabilities in noise reduction and in the perception of both high- and low-frequency components. Consequently, the teacher model is more aware of the split point than the student model and the Student Model can benefit from the Teacher Model.

Additionally, we have conducted an exhaustive investigation into our proposed algorithm, which, as noted by Reviewer 4, has not been adequately addressed in prior SE studies. Our work represents a meaningful contribution to the field of SE, a domain that has been overlooked by previous research efforts.\\

\textbf{Q2: On the contrary, the subband-KD paper proposed to train different teacher models for different subbands for sub-band knowledge distillation, this is more reasonable.}

We posit that the SubandKD approach, which segments the frequency spectrum into 4 discrete equal parts, fails to account for the nuanced characteristics of the acoustic scene, which we contend is a critical oversight. The requirement for training a Teacher Model across these distinct frequency bands necessitates a substantial allocation of training resources and does not facilitate the extension of SE models into the time domain. Our experimental findings demonstrate that our proposed scheme markedly surpasses the performance of SubandKD across various models and test sets. But Reviewer 1 has overlooked these compelling results. \\

\textbf{Q3: The illustration in Section 2.B is not clear. For me, I can barely understand how to get the split index of HF and LF part. In more detail, if $t_k$ has the max value, according to Eq (2) where $f_i$= max($t_0$, $t_1$, $t_2$, ..., $t_i$), then $f_k$, $f_{k+1}$, ... all have the same value, their first-order derivatives will equal to 0. But obviously, the split index should be larger than k in the two scearios shown in Fig. 2. }

If $t_k$ has the maximum value, according to eq(2) and eq(3), it is obvious that the max first-order derivatives will be generated from 0-k. Combining the definitions of eq(5), eq(6), and Figure 2, it is clear that the split index should be smaller than k. It is obvious that Reviewer 1 did not read and understand our method carefully. \\

\textbf{Q4: For Eq (7), the athors claim that they use cos($T_o$, $S_o$)-1 instead of cos($T_o$, $S_o$) is because "This modification ensures a consistent update direction for the network, facilitating more effective training and optimization". But the gradient of the two formula are totally the same.}

The domain of the original cosine function, denoted as cos($T_o$, $S_o$), is conventionally bounded within the interval [-1, 1]. Typically, the KD loss is concatenated with the original training loss of the network as delineated in equation (11). This concatenation serves a dual purpose: it ensures the proportional contribution of the $L_kd$ to the total loss remains consistent, and it avoids the potential issue of negative loss values. To address these considerations, we introduce equation (7) as a proposed solution. \\

\textbf{Q5: The experimental results shown in Table 2 prove that the DFKD method only marginally improve the performance upon the non-distilled student models (Scratch row).}

It is evident from our empirical analysis that our proposed method demonstrates superior performance over other distillation techniques in the majority of test scenarios. Furthermore, in select experimental cases, such as DCCRN-CL-small/Tiny and DPTNet-small, our method not only matches but exceeds the performance of the Teacher Models with arithmetic complexities that are 2X and 4X higher. It appears that Reviewer 1 has overlooked these significant experimental outcomes, which underscore the efficacy of our approach.\\

To Reviewer2 \\

\textbf{Q1: The reason the results of ConvTasNet-small/tiny with ABC-KD/Suband-KD are not provided is not convincing. }

The ABC-KD mainly distills the GRU/LSTM part in the middle of Encoder-GRU/LSTM-decoder architecture, while ConvTasNet does not have this structure and the ABC-KD can not be applied.

The SubandKD posits the training of a Teacher Model across distinct frequency bands to facilitate the distillation process for the Student Model. In contrast, ConvTasNet, as a time-domain model, does not permit the training of a Teacher Model within a specific frequency band.

\end{document}
