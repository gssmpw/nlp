\section{Related Work}
\label{Sec:related}
%
\textbf{Deep NLOS Reconstruction:} Compared to traditional algorithms \cite{nam2021low,pei2021dynamic}, deep learning algorithms can learn scene priors, extract features, and reconstruct hidden objects. Hybrid methods \cite{meng_gap-net_2020,mou_deep_2022,wt_dense_2021,zhang_ista-net_2018} introduce several multi-scale iterative model-guided unfolding networks for Confocal NLOS (C-NLOS) reconstruction. Recent work \cite{su2023multi, ye2024plug} transforms traditional optimization into iterative learning but focuses solely on reconstruction performance without testing on corrupted cases. Inspired by but different from previous researches \cite{Neural_Transient2021,liu2021non,wt_dense_2021, mou_deep_2022, NeuS2023, zhu2023compressive}, our proposed \xnet develops a multi-scale graph-based network for C-NLOS reconstruction.
\begin{figure}[!t]
    \centering
 \includegraphics[width=0.9\linewidth]{fig/fig_forward.pdf}
    % \vspace2{-1em}
    \caption{A schematic diagram of the C-NLOS system.}
    % \vspace2{-1em}
    \label{fig:fig_forward}
\end{figure}

\begin{figure*}[htbp]
    % \vspace2{-1.5em}
    \centering
    \subfloat[Framework]{\label{fig:frame}
    \hspace{-0.5em}
\includegraphics[width=0.7\linewidth,trim= 0 0 0 0,clip]{fig/frame.pdf}
    }
    %
    \subfloat[Graph Module]{\label{fig:graph}
    \includegraphics[width=0.14\linewidth,trim= 0 0 0 0,clip]{fig/grapher.pdf}
    }
    \subfloat[Channel]{\label{fig:channel}
    \hspace{-0.5em}
\includegraphics[width=0.14\linewidth,trim= 1 8 0 1,clip]{fig/channel.pdf}
    }
    % \vspace2{-0.75em}
    \caption{
    \textbf{(a) Structure of the two-stage learning pipeline:}  The loss functions including Albedo and Depth are calculated in triple scales, respectively. Finally, the output voxels of two branches are combined for the optimized reconstruction. \textbf{(b) Structure of graph module.}
    \textbf{(c) Structure of channel fusion.} Each module adopts the Resnet skip connection mechanism.
    }
\end{figure*}

\noindent\textbf{Graph Learning:} GNNs are designed to process graph data by establishing long-range correlations in non-Euclidean space. Micheli~\cite{micheli2009neural} introduced the spatial graph convolutional network with nonrecursive layers. Instead of directly aggregating features from neighboring nodes, EdgeConv~\cite{wang2021object} obtains local neighborhood information by subtracting the central vertex's feature from that of neighboring vertices.  \cite{yang2020distilling} introduced a highway GNN for user geo-location in social media graphs, using `highway' gates to enhance gradient flow. Their research indicated a decline in performance beyond 6 layers. \cite{xu2017scene} proposed a \emph{Jump Knowledge Network} to determine graph neighbors for each node based on the graph's structure. GNN applications in computer vision~\cite{landrieu2018large} include point cloud classification, scene graph generation, and action recognition. Point clouds are 3D points typically collected by LiDAR scans. GCNs have been used for classifying and segmenting point clouds~\cite{landrieu2018large,edgeconv}.