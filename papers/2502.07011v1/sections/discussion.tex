\section{Discussion}
\label{sec:discussion}

Our study highlights the critical role that learning configurations and attacker strategies play in the success of targeted backdoor attacks in FL. Existing defenses often focus on narrow and fixed configurations, making it difficult to assess their robustness under realistic and diverse setups while the performance across different learning configurations (\ie local learning rate, batch size, training epochs) varies dramatically. We believe future evaluations should consider a broader range of configurations to better capture real-world deployment scenarios. Our results provide a starting point by identifying "danger zones"—configurations that enable stealthy attacks to succeed—and we encourage researchers to test their defenses across these configurations to better understand where defenses are effective and where they fail. This approach ensures that robustness claims are not limited to specific configurations but hold across diverse settings. We recommend future evaluations to include, among other configurations, \textbf{low learning rates and small batch sizes, as these have been shown to increase the stealthiness of backdoor attacks}. 

While our threat model assumes static adversaries, a promising direction for future research is to evaluate our design under adaptive adversaries capable of evolving their attack strategies over time. Such adversaries could dynamically adjust their behavior based on observed defense mechanisms or leverage additional clean data for post-attack fine-tuning. Evaluating defenses under these dynamic conditions would provide a more realistic assessment of their robustness and highlight areas where existing methods may fall short. \anshuman{Emphasize that adaptive adversaries are a broader idea for FL and we don't just mean adaptive attacks against our defense, but adaptive attacks against defenses in general in the context of FL (are there any such attacks?)} \georgios{Yes they do exist and some FL papers mention them and test against them. One very simple example is to have another Loss term which all it does is ensure that the euclidean distance between a benign and a malicious update is as low as possible. Of course, this would have taken running all these experiments that we have 2x. Maybe we can do it for the rebuttal?}\anshuman{I think we should plan some anticipatory adaptive attack experiments, and also think of ways we could improve non-iid (need not be 0 ASR, but at least better than others)}

To address the aforementioned inconsistent assumptions across FL defense works—such as client sampling, static vs. adaptive adversaries, and non-IID data splits—that hinder fair comparisons and reproducibility, we advocate for a systematic study of threat models and evaluation protocols. A "Systematization of Knowledge" (SoK) could establish a standardized baseline, fostering more consistent evaluations and enabling meaningful progress in the field.

\shortsection{Limitations} While DROP demonstrates robust performance against targeted backdoor attacks, it has some limitations that warrant further exploration. First, the current evaluation is restricted to image-based datasets (CIFAR-10, EMNIST) \anshuman{If that is true for most FL defenses, phrase it that way. Shouldn't sound like this is a limitation just in our work}, limiting its applicability to other data modalities such as text, or tabular data commonly encountered in real-world FL scenarios \anshuman{Mention that DROPlet could work there still}. Second, although DROP’s additional compute overhead from the knowledge distillation step remains manageable, it is still significant, especially when compared to lightweight baselines. However, this overhead is notably lower than client-side approaches like FLIP, which involve adversarial training. Finally, despite the near-total mitigation of backdoor attacks, the observed reduction in MTA may not be acceptable in certain high-utility applications. Future work could focus on mitigating the MTA loss through improved model-distillation techniques or more effective aggregation mechanisms.
