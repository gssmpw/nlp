\section{Calculations}
\label{sec:calculations}

\subsection{Chernoff Bound Analysis}
\label{sec:chernoff_appendix}

In this section, we provide the detailed steps used to compute the probability bound for the number of malicious clients exceeding a certain threshold in any given round. Specifically, we apply the Chernoff bound to analyze the probability that the number of malicious clients \( M \) in a randomly selected subset of clients exceeds half the total number of selected clients \( C \).

The Chernoff bound provides the following inequality for the probability that \( M \) exceeds \((1 + \delta)\) times its expected value:
\begin{equation}
    \mathbb{P}\left(M \geq (1 + \delta) \cdot \rho \cdot C \right) \leq \exp\left(-\frac{\delta^2 \cdot \rho \cdot C}{2 + \delta}\right),
\end{equation}
where:
\begin{itemize}
    \item \( \rho \) is the malicious client ratio (MCR), i.e., the fraction of total clients that are adversarial.
    \item \( C \) is the total number of clients selected in each round.
    \item \( \delta \) controls how much larger \( M \) is compared to its expected value \( \mathbb{E}[M] = \rho \cdot C \).
\end{itemize}

% \noindent \textbf{Step 1: Setting the threshold}
\shortsection{Step 1: Setting the threshold}
We aim to compute the probability that the number of malicious clients \( M \) exceeds 50\% of the selected clients, i.e., \( M \geq \frac{C}{2} \). Given \( C = 20 \) and \( \rho = 0.4 \), we want:
\[
(1 + \delta) \cdot \rho \cdot C = 10.
\]
Substituting the values of \( \rho \) and \( C \):
\begin{align}
    (1 + \delta) \cdot 0.4 \cdot 20 & = 10,     \nonumber
\end{align}
which gives us $\delta = 0.25$.
% \[
% (1 + \delta) \cdot 8 = 10,
% \]
% \[
% 1 + \delta = \frac{10}{8} = 1.25,
% \]
% \[
% \delta = 1.25 - 1 = 0.25.
% \]

\shortsection{Step 2: Applying the bound}
% \noindent \textbf{Step 2: Applying the bound}
Now, we plug in \( \delta = 0.25 \), \( \rho = 0.4 \), and \( C = 20 \) into the Chernoff bound:
\begin{align}
    \mathbb{P}(M \geq 10) & \leq \exp\left(-\frac{(0.25)^2 \cdot 0.4 \cdot 20}{2 + 0.25}\right) \\
    & = \approx 0.8007374
\end{align}
% \[
% \mathbb{P}(M \geq 10) \leq \exp\left(-\frac{(0.25)^2 \cdot 0.4 \cdot 20}{2 + 0.25}\right),
% \]
% \[
% = \exp\left(-\frac{0.5}{2.25}\right),
% \]
% \[
% = \exp\left(-0.22222\ldots\right),
% \]
% \[
% \approx 0.8007374.
% \]
Thus, the probability that the number of malicious clients exceeds half of the selected clients in a given round is approximately 0.80, indicating that such an event is relatively likely under this configuration. This highlights the need for robust mechanisms that can handle varying malicious client ratios across rounds.

\section{Normal Approximation for Probability of Malicious Majority (Using M and B)}
\label{appendix:normal-approx-MB}

Assume the following setup:
\begin{itemize}
  \item $N$ = total number of clients.
  \item $M_{\text{tot}}$ = total number of malicious clients, where
        $
            M_{\text{tot}} 
            = (\text{MCR}) \times N.
        $
  \item $B_{\text{tot}} = N - M_{\text{tot}}$ = total number of benign (non-malicious) clients.
  \item Each client is selected (independently) with probability 
        $
          p = \frac{C}{N}.
        $
        Thus, the expected number of clients selected in each round is $C$.
\end{itemize}

Let
\[
    M \;\sim\; \mathrm{Binomial}\bigl(M_{\text{tot}},\, p\bigr),
    \quad
    B \;\sim\; \mathrm{Binomial}\bigl(B_{\text{tot}},\, p\bigr),
\]
where 
\[
   B_{\text{tot}} \;=\; N - M_{\text{tot}}.
\]
The random variables $M$ and $B$ are assumed independent, since each client (malicious or benign) is selected via its own independent Bernoulli$(p)$ trial.

\subsection*{Goal}
We want to find the probability that malicious clients \emph{form a strict majority} among the selected clients, that is:
\[
   \Pr\bigl(M > B\bigr).
\]
For large $N$, we can apply the Central Limit Theorem to approximate these binomial distributions by normal distributions:
\[
    M 
    \;\approx\; 
    \mathcal{N}\bigl(\mu_{M}, \;\sigma_{M}^2\bigr),
    \qquad
    B 
    \;\approx\;
    \mathcal{N}\bigl(\mu_{B}, \;\sigma_{B}^2\bigr),
\]
where
\[
    \mu_{M} 
    \;=\; 
    M_{\text{tot}}\,p 
    \;=\; 
    \bigl(\text{MCR}\times N\bigr) 
    \,\frac{C}{N}
    \;=\;
    (\text{MCR}) \times C,
    \quad
    \sigma_{M}^2 
    \;=\;
    M_{\text{tot}}\, p\,(1-p),
\]
\[
    \mu_{B} 
    \;=\;
    B_{\text{tot}}\,p
    \;=\;
    \bigl(N - M_{\text{tot}}\bigr)\,\frac{C}{N}
    \;=\;
    \bigl(1 - \text{MCR}\bigr)\,C,
    \quad
    \sigma_{B}^2 
    \;=\;
    B_{\text{tot}}\,p\,(1-p).
\]
Since $M$ and $B$ are independent, the difference $(M - B)$ is approximately normally distributed with
\[
    M - B 
    \;\approx\;
    \mathcal{N}\bigl(\mu_{M} - \mu_{B},\;
                     \sigma_{M}^2 + \sigma_{B}^2 \bigr).
\]
Observe that
\[
    \mu_{M} - \mu_{B}
    \;=\;
    (\text{MCR}\cdot C) - \bigl((1 - \text{MCR})\cdot C\bigr)
    \;=\;
    C\,\bigl(2\,\text{MCR} - 1\bigr),
\]
and
\[
  \sigma_{M}^2 + \sigma_{B}^2
  \;=\;
  M_{\text{tot}}\,p\,(1-p)
  \;+\;
  B_{\text{tot}}\,p\,(1-p)
\]
\[
  =\;
  \bigl(M_{\text{tot}} + B_{\text{tot}}\bigr)\,p\,(1-p)
  \;=\;
  N\,\frac{C}{N}\,\Bigl(1 - \tfrac{C}{N}\Bigr)
\]
\[
  \;\approx\;
  C.
\]
assuming $C \ll N$. Thus,
\[
    M - B
    \;\approx\;
    \mathcal{N}\Bigl( C\,\bigl(2\,\text{MCR} - 1\bigr), \; C \Bigr).
\]
We want $\Pr(M > B)$, i.e.\ $\Pr(M - B \ge 0)$. We standardize the variable:
\[
  \Pr\bigl(M - B \;\ge\; 0\bigr)
  \;=\;
  \Pr\!\Bigl(\,
    \frac{M - B \;-\; \bigl[C\,(2\,\text{MCR} - 1)\bigr]}{\sqrt{C}}
    \;\ge\;
    \frac{-\,C\,(2\,\text{MCR} - 1)}{\sqrt{C}}
  \Bigr).
\]

If $Z$ is a standard normal random variable, then
\[
  \Pr\bigl(M - B \;\ge\; 0\bigr)
  \;\approx\;
  \Pr\!\Bigl(
    Z \;\ge\; -\,\frac{C\,(2\,\text{MCR} - 1)}{\sqrt{C}}
  \Bigr)
\]
\[
  =
  \Pr\!\Bigl(
    Z \;\le\; \frac{C\,(2\,\text{MCR} - 1)}{\sqrt{C}}
  \Bigr).
\]


Because $1 - \Phi(-x) = \Phi(x)$ for the standard normal CDF $\Phi$, it follows that
\[
    \Pr\bigl(M > B\bigr)
    \;\approx\;
    \Phi\!\Bigl(\sqrt{C}\,\bigl[2\,\text{MCR} - 1\bigr]\Bigr).
\]

\paragraph{Interpretation.}
\begin{itemize}
    \item If $\text{MCR} < 0.5$, then $2\,\text{MCR} - 1 < 0$, and the argument of $\Phi(\,\cdot\,)$ is negative and becomes more negative as $C$ increases. Hence, $\Pr(M > B)$ goes to $0$.
    \item If $\text{MCR} = 0.5$, then the argument of $\Phi$ is zero, so the probability is $0.5$.
    \item If $\text{MCR} > 0.5$, then $2\,\text{MCR} - 1 > 0$, and as $C$ increases, the argument of $\Phi$ becomes large positive. Hence, $\Pr(M > B)$ goes to $1$.
\end{itemize}

This derivation shows that, for large $N$ and not-too-large $C$ (so $p = C/N \ll 1$), the probability of a \emph{malicious majority} in a binomially sampled subset is well approximated by
\[
    \Pr\bigl(\text{Malicious majority}\bigr)
    \;\approx\;
    \Phi\Bigl(\sqrt{C}\,\bigl[2\,\text{MCR} - 1\bigr]\Bigr),
\]
where $\Phi(\,\cdot\,)$ is the standard normal cumulative distribution function.
