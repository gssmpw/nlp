@book{Clark-etal-2011,
	author = {Clark, Alexander  and Lappin, Shalom},
	title = {Linguistic Nativism and the Poverty of the Stimulus},
	publisher = {Wiley-Blackwell},
	year = {2011},
}

@article{Constantinescu-tacl2025,
    author = {Constantinescu, Ionut and Pimentel, Tiago and Cotterell, Ryan and Warstadt, Alex},
    title = {Investigating Critical Period Effects in Language Acquisition through Neural Language Models},
    journal = {Transactions of the Association for Computational Linguistics},
    volume = {13},
    pages = {96-120},
    year = {2025},
    month = {01},
    abstract = {Humans appear to have a critical period (CP) for language acquisition: Second language (L2) acquisition becomes harder after early childhood, and ceasing exposure to a first language (L1) after this period (but not before) typically does not lead to substantial loss of L1 proficiency. It is unknown whether these CP effects result from innately determined brain maturation or as a stabilization of neural connections naturally induced by experience. In this study, we use language models (LMs) to test the extent to which these phenomena are peculiar to humans, or shared by a broader class of language learners. We vary the age of exposure by training LMs on language pairs in various experimental conditions, and find that LMs, which lack any direct analog to innate maturational stages, do not show CP effects when the age of exposure of L2 is delayed. Our results contradict the claim that CP effects are an inevitable result of statistical learning, and they are consistent with an innate mechanism for CP effects. We show that we can reverse-engineer the CP by introducing a regularizer partway through training to simulate a maturational decrease in plasticity. All in all, our results suggest that L1 learning on its own may not be enough to induce a CP, and additional engineering is necessary to make language models more cognitively plausible.},
    issn = {2307-387X},
    doi = {10.1162/tacl_a_00725},
    url = {https://doi.org/10.1162/tacl\_a\_00725},
    eprint = {https://direct.mit.edu/tacl/article-pdf/doi/10.1162/tacl\_a\_00725/2499749/tacl\_a\_00725.pdf},
}

@article{JOHNSON198960,
title = {Critical period effects in second language learning: The influence of maturational state on the acquisition of English as a second language},
journal = {Cognitive Psychology},
volume = {21},
number = {1},
pages = {60-99},
year = {1989},
issn = {0010-0285},
doi = {https://doi.org/10.1016/0010-0285(89)90003-0},
url = {https://www.sciencedirect.com/science/article/pii/0010028589900030},
author = {Jacqueline S Johnson and Elissa L Newport},
abstract = {Lenneberg (1967) hypothesized that language could be acquired only within a critical period, extending from early infancy until puberty. In its basic form, the critical period hypothesis need only have consequences for first language acquisition. Nevertheless, it is essential to our understanding of the nature of the hypothesized critical period to determine whether or not it extends as well to second language acquisition. If so, it should be the case that young children are better second language learners than adults and should consequently reach higher levels of final proficiency in the second language. This prediction was tested by comparing the English proficiency attained by 46 native Korean or Chinese speakers who had arrived in the United States between the ages of 3 and 39, and who had lived in the United States between 3 and 26 years by the time of testing. These subjects were tested on a wide variety of structures of English grammar, using a grammatically judgment task. Both correlational and t-test analyses demonstrated a clear and strong advantage for earlier arrivals over the later arrivals. Test performance was linearly related to age of arrival up to puberty; after puberty, performance was low but highly variable and unrelated to age of arrival. This age effect was shown not to be an inadvertent result of differences in amount of experience with English, motivation, self-consciousness, or American identification. The effect also appeared on every grammatical structure tested, although the structures varied markedly in the degree to which they were well mastered by later learners. The results support the conclusion that a critical period for language acquisition extends its effects to second language acquisition.}
}

@article{Kirkpatrick-etal-2017,
author = {James Kirkpatrick  and Razvan Pascanu  and Neil Rabinowitz  and Joel Veness  and Guillaume Desjardins  and Andrei A. Rusu  and Kieran Milan  and John Quan  and Tiago Ramalho  and Agnieszka Grabska-Barwinska  and Demis Hassabis  and Claudia Clopath  and Dharshan Kumaran  and Raia Hadsell },
title = {Overcoming catastrophic forgetting in neural networks},
journal = {Proceedings of the National Academy of Sciences},
volume = {114},
number = {13},
pages = {3521-3526},
year = {2017},
doi = {10.1073/pnas.1611835114},
URL = {https://www.pnas.org/doi/abs/10.1073/pnas.1611835114},
eprint = {https://www.pnas.org/doi/pdf/10.1073/pnas.1611835114},
abstract = {Deep neural networks are currently the most successful machine-learning technique for solving a variety of tasks, including language translation, image classification, and image generation. One weakness of such models is that, unlike humans, they are unable to learn multiple tasks sequentially. In this work we propose a practical solution to train such models sequentially by protecting the weights important for previous tasks. This approach, inspired by synaptic consolidation in neuroscience, enables state of the art results on multiple reinforcement learning problems experienced sequentially. The ability to learn tasks in a sequential fashion is crucial to the development of artificial intelligence. Until now neural networks have not been capable of this and it has been widely thought that catastrophic forgetting is an inevitable feature of connectionist models. We show that it is possible to overcome this limitation and train networks that can maintain expertise on tasks that they have not experienced for a long time. Our approach remembers old tasks by selectively slowing down learning on the weights important for those tasks. We demonstrate our approach is scalable and effective by solving a set of classification tasks based on a hand-written digit dataset and by learning several Atari 2600 games sequentially.}}

@article{McCoy-etal-2020,
    author = {McCoy, R. Thomas and Frank, Robert and Linzen, Tal},
    title = {Does Syntax Need to Grow on Trees? Sources of Hierarchical Inductive Bias in Sequence-to-Sequence Networks},
    journal = {Transactions of the Association for Computational Linguistics},
    volume = {8},
    pages = {125-140},
    year = {2020},
    month = {01},
    abstract = {Learners that are exposed to the same training data might generalize differently due to differing inductive biases. In neural network models, inductive biases could in theory arise from any aspect of the model architecture. We investigate which architectural factors affect the generalization behavior of neural sequence-to-sequence models trained on two syntactic tasks, English question formation and English tense reinflection. For both tasks, the training set is consistent with a generalization based on hierarchical structure and a generalization based on linear order. All architectural factors that we investigated qualitatively affected how models generalized, including factors with no clear connection to hierarchical structure. For example, LSTMs and GRUs displayed qualitatively different inductive biases. However, the only factor that consistently contributed a hierarchical bias across tasks was the use of a tree-structured model rather than a model with sequential recurrence, suggesting that human-like syntactic generalization requires architectural syntactic structure.},
    issn = {2307-387X},
    doi = {10.1162/tacl_a_00304},
    url = {https://doi.org/10.1162/tacl\_a\_00304},
    eprint = {https://direct.mit.edu/tacl/article-pdf/doi/10.1162/tacl\_a\_00304/1923427/tacl\_a\_00304.pdf},
}

@article{NEWPORT199011,
title = {Maturational constraints on language learning},
journal = {Cognitive Science},
volume = {14},
number = {1},
year = {1990},
issn = {0364-0213},
doi = {https://doi.org/10.1016/0364-0213(90)90024-Q},
url = {https://www.sciencedirect.com/science/article/pii/036402139090024Q},
author = {Elissa L. Newport},
abstract = {This paper suggests that there are constraints on learning required to explain the acquisition of language, in particular, mului ultonol constraints. First, empirical evidence for this daim is reviewed. The evidence from several studies of both first and second languoge acquisition suggests that normal language learning occurs only when exposure to the languoge begins early in life. With exposure beginning later in life, asymptotic performance in the language declines: the effects over oge of first exposure are approximately linear through childhood, with a flattening of the function in adulthood. These outcomes argue that some type of constraints ensuring successful languoge learning exist early in life, and weaken with increasing maturation. Second, two hypotheses are considered as to the nature of these maturational changes. One hypothesis is that constraints on learning particular to languoge acquisition undergo maturational decay. A second hypothesis, which is considered in more detail, suggests that language learning abilities decline because of the expansion of nonlinguisftc cognitive abilities.}
}

@article{Wilcox-etal-2024,
    author = {Wilcox, Ethan Gotlieb and Futrell, Richard and Levy, Roger},
    title = {Using Computational Models to Test Syntactic Learnability},
    journal = {Linguistic Inquiry},
    volume = {55},
    number = {4},
    pages = {805-848},
    year = {2024},
    month = {10},
    abstract = {We studied the learnability of English filler-gap dependencies and the “island” constraints on them by assessing the generalizations made by autoregressive (incremental) language models that use deep learning to predict the next word given preceding context. Using factorial tests inspired by experimental psycholinguistics, we found that models acquire not only the basic contingency between fillers and gaps, but also the unboundedness and hierarchical constraints implicated in the dependency. We evaluated a model’s acquisition of island constraints by demonstrating that its expectation for a filler-gap contingency is attenuated within an island environment. Our results provide empirical evidence against the argument from the poverty of the stimulus for this particular structure.},
    issn = {0024-3892},
    doi = {10.1162/ling_a_00491},
    url = {https://doi.org/10.1162/ling\_a\_00491},
    eprint = {https://direct.mit.edu/ling/article-pdf/55/4/805/2473564/ling\_a\_00491.pdf},
}

@book{chomsky1965,
  abstract = {Standard-TG},
  added-at = {2007-02-16T16:53:53.000+0100},
  address = {Cambridge},
  author = {Chomsky, Noam},
  biburl = {https://www.bibsonomy.org/bibtex/2634ef0838fe6ad268105e0be37a3be8c/vittorio.loreto},
  citeulike-article-id = {867124},
  interhash = {10dff7148609d28159a0602fcd6c7cbb},
  intrahash = {634ef0838fe6ad268105e0be37a3be8c},
  keywords = {RMP_CFL generative-grammar linguistics syntax chomsky 1965},
  priority = {1},
  publisher = {The MIT Press},
  timestamp = {2007-02-16T16:53:53.000+0100},
  title = {Aspects of the Theory of Syntax},
  url = {http://www.amazon.com/Aspects-Theory-Syntax-Noam-Chomsky/dp/0262530074},
  year = 1965
}

@article{ellis2000age,
  author       = {Ellis, Andrew W. and Lambon Ralph, Matthew A.},
  journal      = {Journal of Experimental Psychology: Learning, Memory, and Cognition},
  number       = {5},
  pages        = {1103--1123},
  title        = {{A}ge of acquisition effects in adult lexical processing reflect loss of plasticity in maturing systems: {Insights} from connectionist networks.},
  volume       = {26},
  year         = {2000},
  url={https://pubmed.ncbi.nlm.nih.gov/11009247/}
}

@book{elman1996rethinking,
  author    = {Jeffrey L. Elman and Elizabeth A. Bates and Mark H. Johnson and Annette Karmiloff-Smith and Domenico Parisi and Kim Plunkett},
  title     = {Rethinking Innateness: A Connectionist Perspective on Development},
  year      = {1996},
  publisher = {MIT Press},
}

@article{hartshorne2018critical,
  author       = {Hartshorne, Joshua K. and Tenenbaum, Joshua B. and Pinker, Steven},
  journal      = {Cognition},
  pages        = {263--277},
  title        = {{A} critical period for second language acquisition: {Evidence} from 2/3 million {English} speakers},
  url          = {https://www.sciencedirect.com/science/article/pii/S0010027718300994},
  volume       = {177},
  year         = {2018}
}

@article{mayberry1989looking,
  author       = {Mayberry, Rachel I. and Fischer, Susan D.},
  doi          = {10.3758/BF03202635},
  issn         = {0090-502X, 1532-5946},
  journal      = {Memory \& Cognition},
  language     = {en},
  month        = nov,
  number       = {6},
  pages        = {740--754},
  shorttitle   = {Looking through phonological shape to lexical meaning},
  title        = {{L}ooking through phonological shape to lexical meaning: {The} bottleneck of non-native sign language processing},
  url          = {http://link.springer.com/10.3758/BF03202635},
  urldate      = {2023-10-26},
  volume       = {17},
  year         = {1989}
}

@article{penfield1965conditioning,
  author       = {Penfield, Wilder},
  doi          = {10.1093/brain/88.4.787},
  issn         = {0006-8950},
  journal      = {Brain},
  number       = {4},
  pages        = {787--798},
  title        = {{C}onditioning the uncommitted cortex for language learning},
  url          = {https://doi.org/10.1093/brain/88.4.787},
  volume       = {88},
  year         = {1965}
}

@book{pinker1994language,
  author    = {Steven Pinker},
  title     = {The Language Instinct: How the Mind Creates Language},
  year      = {1994},
  publisher = {William Morrow and Company},
}

@incollection{seidenberg2006connectionist,
  author       = {Seidenberg, Mark S. and Zevin, Jason D.},
  booktitle    = {Processes of {Change} in {Brain} and {Cognitive} {Development}},
  editor       = {Munakata, Yuko and Johnson, Mark H},
  pages        = {585--612},
  shorttitle   = {Connectionist models in developmental cognitive neuroscience},
  title        = {{C}onnectionist models in developmental cognitive neuroscience: {Critical} periods and the paradox of success},
  url          = {https://academic.oup.com/book/54488/chapter/422571818},
  year         = {2006},
  publisher = {Oxford University Press}
}

@inproceedings{warstadt-etal-2023-findings,
    title = "Findings of the {B}aby{LM} Challenge: Sample-Efficient Pretraining on Developmentally Plausible Corpora",
    author = "Warstadt, Alex  and
      Mueller, Aaron  and
      Choshen, Leshem  and
      Wilcox, Ethan  and
      Zhuang, Chengxu  and
      Ciro, Juan  and
      Mosquera, Rafael  and
      Paranjabe, Bhargavi  and
      Williams, Adina  and
      Linzen, Tal  and
      Cotterell, Ryan",
    booktitle = "Proceedings of the BabyLM Challenge at the 27th Conference on Computational Natural Language Learning",
    month = dec,
    year = "2023",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.conll-babylm.1",
    doi = "10.18653/v1/2023.conll-babylm.1",
    pages = "1--34",
}

