\section*{Impact Statement}
\noindent \textbf{Ethical Consideration.} This research addresses the vulnerability of VLLMs to adversarial attacks, specifically focusing on the bypassing of content moderators. While the exploration of such weaknesses is critical for enhancing model security and robustness, we are mindful of the ethical implications associated with this work. Our goal is to improve the safety and reliability of VLLMs by understanding and mitigating adversarial risks.
We aim to identify and address the limitations of current content moderation systems to ensure that they can better withstand harmful input and output generation. The findings of this work are intended to inform the development of more resilient AI models and content moderation strategies, ultimately enhancing the user experience while preventing harmful content dissemination. 