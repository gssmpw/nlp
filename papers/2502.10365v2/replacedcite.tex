\section{Related Work}
\label{appendix: related_work}



\paragraph{Generative Protein Modeling}
Generative protein modeling primarily includes sequence-based language models and structure-based score generative models. Language models are trained on protein sequence datasets using masked prediction____ or auto-regressive prediction____. These models are often fine-tuned for specific domains like antibodies, with examples including AbLang____, AntiBERTa____, IgLM____, and nanoBERT____.
%
Additionally, various sequence optimization strategies have been investigated____.
%
Language models have also been explored for modeling tokenized protein structures____.
%


Score-based models, such as diffusion-based and flow matching models, mainly focus on generating protein structures. \textbf{(1)} Diffusion-based models like RFdiffusionAA____ and AlphaFold3____ generate structures through coordinate denoising. RFdiffusionAA has been applied to antibody design____, but its code is not open-sourced. Chroma____ introduces property-specific guidance into diffusion models but does not research antibody design. Similarly, ____ incorporates force-field guidance but struggles to capture realistic structures due to the simplicity of the diffusion model.
%
\textbf{(2)} Flow matching models have shown greater effectiveness and efficiency compared to diffusion models. Recent studies like AlphaFlow____ and FoldFlow-2____ explore sequence-conditioned flow matching for protein structure generation. In this work, we utilize the AlphaFlow framework for antibody sequence design due to its demonstrated effectiveness.
%
It is worth noting that score-based models have also been applied to model discrete biological sequences____ and to broader design tasks____

\paragraph{Co-teaching}
%
Co-teaching____ is a robust technique for addressing label noise by utilizing two collaborative models. Each model identifies small-loss samples from a noisy mini-batch to train the other. Co-teaching is conceptually related to decoupling____ and co-training____, as all these approaches involve collaborative learning between two models. 
%
While sample selection techniques are commonly used to identify or reweight clean data from noisy datasets____, in our study, we adapt co-teaching to work with biophysical binding energy data rather than a noisy dataset. Specifically, the sequence-based predictor identifies clean samples for training the structure-based predictor, and vice versa.
%