@inproceedings{srinivasan2021wit,
  title={Wit: Wikipedia-based image text dataset for multimodal multilingual machine learning},
  author={Srinivasan, Krishna and Raman, Karthik and Chen, Jiecao and Bendersky, Michael and Najork, Marc},
  booktitle={Proceedings of the 44th international ACM SIGIR conference on research and development in information retrieval},
  pages={2443--2449},
  year={2021}
}

@article{lewis2020retrieval,
  title={Retrieval-augmented generation for knowledge-intensive nlp tasks},
  author={Lewis, Patrick and Perez, Ethan and Piktus, Aleksandra and Petroni, Fabio and Karpukhin, Vladimir and Goyal, Naman and K{\"u}ttler, Heinrich and Lewis, Mike and Yih, Wen-tau and Rockt{\"a}schel, Tim and others},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={9459--9474},
  year={2020}
}

@article{chen2024bge,
  title={Bge m3-embedding: Multi-lingual, multi-functionality, multi-granularity text embeddings through self-knowledge distillation},
  author={Chen, Jianlv and Xiao, Shitao and Zhang, Peitian and Luo, Kun and Lian, Defu and Liu, Zheng},
  journal={arXiv preprint arXiv:2402.03216},
  year={2024}
}

@article{zhu2024murar,
  title={Murar: A simple and effective multimodal retrieval and answer refinement framework for multimodal question answering},
  author={Zhu, Zhengyuan and Lee, Daniel and Zhang, Hong and Harsha, Sai Sree and Feujio, Loic and Maharaj, Akash and Li, Yunyao},
  journal={arXiv preprint arXiv:2408.08521},
  year={2024}
}

@article{ma2024multi,
  title={Multi-modal Retrieval Augmented Multi-modal Generation: A Benchmark, Evaluate Metrics and Strong Baselines},
  author={Ma, Zi-Ao and Lan, Tian and Tu, Rong-Cheng and Hu, Yong and Huang, Heyan and Mao, Xian-Ling},
  journal={arXiv preprint arXiv:2411.16365},
  year={2024}
}

@article{burns2023wikiweb2m,
  title={Wikiweb2m: A page-level multimodal wikipedia dataset},
  author={Burns, Andrea and Srinivasan, Krishna and Ainslie, Joshua and Brown, Geoff and Plummer, Bryan A and Saenko, Kate and Ni, Jianmo and Guo, Mandy},
  journal={arXiv preprint arXiv:2305.05432},
  year={2023}
}

@inproceedings{chang2022webqa,
  title={WebQA: A Multimodal Multihop NeurIPS Challenge},
  author={Chang, Yingshan and Bisk, Yonatan},
  booktitle={NeurIPS 2021 Competitions and Demonstrations Track},
  pages={232--245},
  year={2022},
  organization={PMLR}
}

@inproceedings{shrivastava2014defense,
  title={In defense of minhash over simhash},
  author={Shrivastava, Anshumali and Li, Ping},
  booktitle={Artificial Intelligence and Statistics},
  pages={886--894},
  year={2014},
  organization={PMLR}
}

@article{TF-IDF,
  title={Index term weighting},
  author={Jones, Karen Sparck},
  journal={Information storage and retrieval},
  volume={9},
  number={11},
  pages={619--633},
  year={1973},
  publisher={Elsevier}
}

@misc{BGE,
      title={C-Pack: Packaged Resources To Advance General Chinese Embedding}, 
      author={Shitao Xiao and Zheng Liu and Peitian Zhang and Niklas Muennighoff and Defu Lian and Jian-Yun Nie},
      year={2024},
      eprint={2309.07597},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2309.07597}, 
}

@article{zhu2024rageval,
  title={Rageval: Scenario specific rag evaluation dataset generation framework},
  author={Zhu, Kunlun and Luo, Yifan and Xu, Dingling and Wang, Ruobing and Yu, Shi and Wang, Shuo and Yan, Yukun and Liu, Zhenghao and Han, Xu and Liu, Zhiyuan and others},
  journal={arXiv preprint arXiv:2408.01262},
  year={2024}
}

@article{yagcioglu2018recipeqa,
  title={Recipeqa: A challenge dataset for multimodal comprehension of cooking recipes},
  author={Yagcioglu, Semih and Erdem, Aykut and Erdem, Erkut and Ikizler-Cinbis, Nazli},
  journal={arXiv preprint arXiv:1809.00812},
  year={2018}
}




@misc{kaggle,
  year         = "\textit{n.d}",
  url= "https://www.kaggle.com/datasets/ahmedhgabr/technical-illustration/data",
}
@misc{manual,
  year         = "\textit{n.d}",
  url="https://www.manualslib.com",
}

@article{wang2024mineru,
  title={Mineru: An open-source solution for precise document content extraction},
  author={Wang, Bin and Xu, Chao and Zhao, Xiaomeng and Ouyang, Linke and Wu, Fan and Zhao, Zhiyuan and Xu, Rui and Liu, Kaiwen and Qu, Yuan and Shang, Fukai and others},
  journal={arXiv preprint arXiv:2409.18839},
  year={2024}
}



@article{zhao2024retrieval,
  title={Retrieval-augmented generation for ai-generated content: A survey},
  author={Zhao, Penghao and Zhang, Hailin and Yu, Qinhan and Wang, Zhengren and Geng, Yunteng and Fu, Fangcheng and Yang, Ling and Zhang, Wentao and Cui, Bin},
  journal={arXiv preprint arXiv:2402.19473},
  year={2024}
}

@article{QAE,
  title={QAEncoder: Towards Aligned Representation Learning in Question Answering System},
  author={Wang, Zhengren and Yu, Qinhan and Wei, Shida and Li, Zhiyu and Xiong, Feiyu and Wang, Xiaoxing and Niu, Simin and Liang, Hao and Zhang, Wentao},
  journal={arXiv preprint arXiv:2409.20434},
  year={2024}
}

@article{petroni2020kilt,
  title={KILT: a benchmark for knowledge intensive language tasks},
  author={Petroni, Fabio and Piktus, Aleksandra and Fan, Angela and Lewis, Patrick and Yazdani, Majid and De Cao, Nicola and Thorne, James and Jernite, Yacine and Karpukhin, Vladimir and Maillard, Jean and others},
  journal={arXiv preprint arXiv:2009.02252},
  year={2020}
}

@inproceedings{li2018vqa,
  title={Vqa-e: Explaining, elaborating, and enhancing your answers for visual questions},
  author={Li, Qing and Tao, Qingyi and Joty, Shafiq and Cai, Jianfei and Luo, Jiebo},
  booktitle={Proceedings of the European Conference on Computer Vision (ECCV)},
  pages={552--567},
  year={2018}
}

@article{es2023ragas,
  title={Ragas: Automated evaluation of retrieval augmented generation},
  author={Es, Shahul and James, Jithin and Espinosa-Anke, Luis and Schockaert, Steven},
  journal={arXiv preprint arXiv:2309.15217},
  year={2023}
}

@article{zhang2019bertscore,
  title={Bertscore: Evaluating text generation with bert},
  author={Zhang, Tianyi and Kishore, Varsha and Wu, Felix and Weinberger, Kilian Q and Artzi, Yoav},
  journal={arXiv preprint arXiv:1904.09675},
  year={2019}
}


@article{MSMARCO,
  title={MS MARCO: A Human Generated MAchine Reading COmprehension Dataset},
  author={Nguyen, Tri and Rosenberg, Mir and Song, Xia and Gao, Jianfeng and Tiwary, Saurabh and Majumder, Rangan and Deng, Li},
  journal={choice},
  volume={2640},
  pages={660},
  year={2016}
}


@article{Naturalquestions,
  title={Natural questions: a benchmark for question answering research},
  author={Kwiatkowski, Tom and Palomaki, Jennimaria and Redfield, Olivia and Collins, Michael and Parikh, Ankur and Alberti, Chris and Epstein, Danielle and Polosukhin, Illia and Devlin, Jacob and Lee, Kenton and others},
  journal={Transactions of the Association for Computational Linguistics},
  volume={7},
  pages={453--466},
  year={2019},
  publisher={MIT Press One Rogers Street, Cambridge, MA 02142-1209, USA journals-info~…}
}

@inproceedings{joshi2017triviaqa,
  title={TriviaQA: A Large Scale Distantly Supervised Challenge Dataset for Reading Comprehension},
  author={Joshi, Mandar and Choi, Eunsol and Weld, Daniel and Zettlemoyer, Luke},
  booktitle={Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
  year={2017},
  organization={Association for Computational Linguistics}
}

@inproceedings{yang2018hotpotqa,
  title={HotpotQA: A Dataset for Diverse, Explainable Multi-hop Question Answering},
  author={Yang, Zhilin and Qi, Peng and Zhang, Saizheng and Bengio, Yoshua and Cohen, William and Salakhutdinov, Ruslan and Manning, Christopher D},
  booktitle={Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing},
  year={2018},
  organization={Association for Computational Linguistics}
}

@inproceedings{fan2019eli5,
  title={ELI5: Long Form Question Answering},
  author={Fan, Angela and Jernite, Yacine and Perez, Ethan and Grangier, David and Weston, Jason and Auli, Michael},
  booktitle={Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics},
  pages={3558--3567},
  year={2019}
}



@inproceedings{antol2015vqa,
  title={Vqa: Visual question answering},
  author={Antol, Stanislaw and Agrawal, Aishwarya and Lu, Jiasen and Mitchell, Margaret and Batra, Dhruv and Zitnick, C Lawrence and Parikh, Devi},
  booktitle={Proceedings of the IEEE international conference on computer vision},
  pages={2425--2433},
  year={2015}
}

@article{talmor2021multimodalqa,
  title={Multimodalqa: Complex question answering over text, tables and images},
  author={Talmor, Alon and Yoran, Ori and Catav, Amnon and Lahav, Dan and Wang, Yizhong and Asai, Akari and Ilharco, Gabriel and Hajishirzi, Hannaneh and Berant, Jonathan},
  journal={arXiv preprint arXiv:2104.06039},
  year={2021}
}


@inproceedings{2020RAG,
  author       = {Patrick S. H. Lewis and
                  Ethan Perez and
                  Aleksandra Piktus and others},
  title        = {Retrieval-Augmented Generation for Knowledge-Intensive {NLP} Tasks},
  booktitle    = {NeurIPS},
  year         = {2020},
}

@article{koukounas2024jina,
  title={jina-clip-v2: Multilingual Multimodal Embeddings for Text and Images},
  author={Koukounas, Andreas and Mastrapas, Georgios and Wang, Bo and Akram, Mohammad Kalim and Eslami, Sedigheh and G{\"u}nther, Michael and Mohr, Isabelle and Sturua, Saba and Martens, Scott and Wang, Nan and others},
  journal={arXiv preprint arXiv:2412.08802},
  year={2024}
}

@inproceedings{papineni2002bleu,
  title={Bleu: a method for automatic evaluation of machine translation},
  author={Papineni, Kishore and Roukos, Salim and Ward, Todd and Zhu, Wei-Jing},
  booktitle={Proceedings of the 40th annual meeting of the Association for Computational Linguistics},
  pages={311--318},
  year={2002}
}

@article{Edmonds_1965, title={Paths, Trees, and Flowers}, volume={17}, DOI={10.4153/CJM-1965-045-4}, journal={Canadian Journal of Mathematics}, author={Edmonds, Jack}, year={1965}, pages={449–467}}

@inproceedings{lin-2004-rouge,
    title = "{ROUGE}: A Package for Automatic Evaluation of Summaries",
    author = "Lin, Chin-Yew",
    booktitle = "Text Summarization Branches Out",
    month = jul,
    year = "2004",
    address = "Barcelona, Spain",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/W04-1013/",
    pages = "74--81"
}

@article{devlin2018bert,
  title={Bert: Pre-training of deep bidirectional transformers for language understanding},
  author={Devlin, Jacob},
  journal={arXiv preprint arXiv:1810.04805},
  year={2018}
}

@article{lin2022retrieval,
  title={Retrieval augmented visual question answering with outside knowledge},
  author={Lin, Weizhe and Byrne, Bill},
  journal={arXiv preprint arXiv:2210.03809},
  year={2022}
}

@article{liu2024mmdu,
  title={MMDU: A Multi-Turn Multi-Image Dialog Understanding Benchmark and Instruction-Tuning Dataset for LVLMs},
  author={Liu, Ziyu and Chu, Tao and Zang, Yuhang and Wei, Xilin and Dong, Xiaoyi and Zhang, Pan and Liang, Zijian and Xiong, Yuanjun and Qiao, Yu and Lin, Dahua and others},
  journal={arXiv preprint arXiv:2406.11833},
  year={2024}
}

@article{zhou2024vega,
  title={VEGA: Learning Interleaved Image-Text Comprehension in Vision-Language Large Models},
  author={Zhou, Chenyu and Zhang, Mengdan and Chen, Peixian and Fu, Chaoyou and Shen, Yunhang and Zheng, Xiawu and Sun, Xing and Ji, Rongrong},
  journal={arXiv preprint arXiv:2406.10228},
  year={2024}
}

@article{team2024gemini,
  title={Gemini 1.5: Unlocking multimodal understanding across millions of tokens of context},
  author={Team, Gemini and Georgiev, Petko and Lei, Ving Ian and Burnell, Ryan and Bai, Libin and Gulati, Anmol and Tanzer, Garrett and Vincent, Damien and Pan, Zhufeng and Wang, Shibo and others},
  journal={arXiv preprint arXiv:2403.05530},
  year={2024}
}

@article{liu2024deepseek,
  title={DeepSeek-V3 Technical Report},
  author={Liu, Aixin and Feng, Bei and Xue, Bing and Wang, Bingxuan and Wu, Bochao and Lu, Chengda and Zhao, Chenggang and Deng, Chengqi and Zhang, Chenyu and Ruan, Chong and others},
  journal={arXiv preprint arXiv:2412.19437},
  year={2024}
}

@article{wang2024qwen2,
  title={Qwen2-vl: Enhancing vision-language model's perception of the world at any resolution},
  author={Wang, Peng and Bai, Shuai and Tan, Sinan and Wang, Shijie and Fan, Zhihao and Bai, Jinze and Chen, Keqin and Liu, Xuejing and Wang, Jialin and Ge, Wenbin and others},
  journal={arXiv preprint arXiv:2409.12191},
  year={2024}
}

@article{chen2024expanding,
  title={Expanding performance boundaries of open-source multimodal models with model, data, and test-time scaling},
  author={Chen, Zhe and Wang, Weiyun and Cao, Yue and Liu, Yangzhou and Gao, Zhangwei and Cui, Erfei and Zhu, Jinguo and Ye, Shenglong and Tian, Hao and Liu, Zhaoyang and others},
  journal={arXiv preprint arXiv:2412.05271},
  year={2024}
}

@article{dubey2024llama,
  title={The llama 3 herd of models},
  author={Dubey, Abhimanyu and Jauhri, Abhinav and Pandey, Abhinav and Kadian, Abhishek and Al-Dahle, Ahmad and Letman, Aiesha and Mathur, Akhil and Schelten, Alan and Yang, Amy and Fan, Angela and others},
  journal={arXiv preprint arXiv:2407.21783},
  year={2024}
}

@article{gpt4o,
  title={Hello GPT-4o},
  author={OpenAI},
  journal={OpenAI Blog},
  year={2024},
  url={https://openai.com/index/hello-gpt-4o/}
}

@article{gpt4o_mini,
  title={GPT-4o mini: advancing cost-efficient intelligence},
  author={OpenAI},
  journal={OpenAI Blog},
  year={2024},
  url={https://openai.com/index/gpt-4o-mini-advancing-cost-efficient-intelligence//}
}

@misc{anthropic_claude_2024,
  author       = {Anthropic},
  title        = {Claude 3.5 Sonnet},
  howpublished = {\url{https://www.anthropic.com/news/claude-3-5-sonnet}},
  year         = 2024,
}

@article{BM25,
  author       = {Stephen E. Robertson and
                  Hugo Zaragoza},
  title        = {The Probabilistic Relevance Framework: {BM25} and Beyond},
  journal      = {FTIR},
  volume       = {3},
  number       = {4},
  pages        = {333--389},
  year         = {2009}
}



@article{lu2022reacc,
  title={Reacc: A retrieval-augmented code completion framework},
  author={Lu, Shuai and Duan, Nan and Han, Hojae and Guo, Daya and Hwang, Seung-won and Svyatkovskiy, Alexey},
  journal={arXiv preprint arXiv:2203.07722},
  year={2022}
}

@article{chen2022re,
  title={Re-imagen: Retrieval-augmented text-to-image generator},
  author={Chen, Wenhu and Hu, Hexiang and Saharia, Chitwan and Cohen, William W},
  journal={arXiv preprint arXiv:2209.14491},
  year={2022}
}

@article{chen2022murag,
  title={Murag: Multimodal retrieval-augmented generator for open question answering over images and text},
  author={Chen, Wenhu and Hu, Hexiang and Chen, Xi and Verga, Pat and Cohen, William W},
  journal={arXiv preprint arXiv:2210.02928},
  year={2022}
}

@article{gui2021kat,
  title={Kat: A knowledge augmented transformer for vision-and-language},
  author={Gui, Liangke and Wang, Borui and Huang, Qiuyuan and Hauptmann, Alex and Bisk, Yonatan and Gao, Jianfeng},
  journal={arXiv preprint arXiv:2112.08614},
  year={2021}
}

@article{karpukhin2020dense,
  title={Dense passage retrieval for open-domain question answering},
  author={Karpukhin, Vladimir and O{\u{g}}uz, Barlas and Min, Sewon and Lewis, Patrick and Wu, Ledell and Edunov, Sergey and Chen, Danqi and Yih, Wen-tau},
  journal={arXiv preprint arXiv:2004.04906},
  year={2020}
}

@article{raffel2020exploring,
  title={Exploring the limits of transfer learning with a unified text-to-text transformer},
  author={Raffel, Colin and Shazeer, Noam and Roberts, Adam and Lee, Katherine and Narang, Sharan and Matena, Michael and Zhou, Yanqi and Li, Wei and Liu, Peter J},
  journal={Journal of machine learning research},
  volume={21},
  number={140},
  pages={1--67},
  year={2020}
}

@article{dosovitskiy2020image,
  title={An image is worth 16x16 words: Transformers for image recognition at scale},
  author={Dosovitskiy, Alexey},
  journal={arXiv preprint arXiv:2010.11929},
  year={2020}
}


@inproceedings{radford2021learning,
  title={Learning transferable visual models from natural language supervision},
  author={Radford, Alec and Kim, Jong Wook and Hallacy, Chris and Ramesh, Aditya and Goh, Gabriel and Agarwal, Sandhini and Sastry, Girish and Askell, Amanda and Mishkin, Pamela and Clark, Jack and others},
  booktitle={International conference on machine learning},
  pages={8748--8763},
  year={2021},
  organization={PMLR}
}


@article{hallucination,
  title={A survey on hallucination in large language models: Principles, taxonomy, challenges, and open questions},
  author={Huang, Lei and Yu, Weijiang and Ma, Weitao and Zhong, Weihong and Feng, Zhangyin and Wang, Haotian and Chen, Qianglong and Peng, Weihua and Feng, Xiaocheng and Qin, Bing and others},
  journal={arXiv preprint arXiv:2311.05232},
  year={2023}
}

@article{gupta2024rag,
  title={RAG vs Fine-tuning: Pipelines, Tradeoffs, and a Case Study on Agriculture},
  author={Gupta, Aman and Shirgaonkar, Anup and Balaguer, Angels de Luis and Silva, Bruno and Holstein, Daniel and Li, Dawei and Marsman, Jennifer and Nunes, Leonardo O and Rouzbahman, Mahsa and Sharp, Morris and others},
  journal={arXiv preprint arXiv:2401.08406},
  year={2024}
}

@inproceedings{liu2023learning,
  title={Learning customized visual models with retrieval-augmented knowledge},
  author={Liu, Haotian and Son, Kilho and Yang, Jianwei and Liu, Ce and Gao, Jianfeng and Lee, Yong Jae and Li, Chunyuan},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={15148--15158},
  year={2023}
}

@article{COT,
  title={Chain-of-thought prompting elicits reasoning in large language models},
  author={Wei, Jason and Wang, Xuezhi and Schuurmans, Dale and Bosma, Maarten and Xia, Fei and Chi, Ed and Le, Quoc V and Zhou, Denny and others},
  journal={Advances in neural information processing systems},
  volume={35},
  pages={24824--24837},
  year={2022}
}



@inproceedings{rajpurkar2016squad,
  title={SQuAD: 100,000+ Questions for Machine Comprehension of Text},
  author={Rajpurkar, Pranav and Zhang, Jian and Lopyrev, Konstantin and Liang, Percy},
  booktitle={Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing},
  year={2016},
  organization={Association for Computational Linguistics}
}

@inproceedings{marino2019ok,
  title={Ok-vqa: A visual question answering benchmark requiring external knowledge},
  author={Marino, Kenneth and Rastegari, Mohammad and Farhadi, Ali and Mottaghi, Roozbeh},
  booktitle={Proceedings of the IEEE/cvf conference on computer vision and pattern recognition},
  pages={3195--3204},
  year={2019}
}

@inproceedings{wei2025uniir,
  title={Uniir: Training and benchmarking universal multimodal information retrievers},
  author={Wei, Cong and Chen, Yang and Chen, Haonan and Hu, Hexiang and Zhang, Ge and Fu, Jie and Ritter, Alan and Chen, Wenhu},
  booktitle={European Conference on Computer Vision},
  pages={387--404},
  year={2025},
  organization={Springer}
}


@article{wang2024comprehensive,
  title={A comprehensive review of multimodal large language models: Performance and challenges across different tasks},
  author={Wang, Jiaqi and Jiang, Hanqi and Liu, Yiheng and Ma, Chong and Zhang, Xu and Pan, Yi and Liu, Mengyuan and Gu, Peiran and Xia, Sichen and Li, Wenjun and others},
  journal={arXiv preprint arXiv:2408.01319},
  year={2024}
}


@inproceedings{caffagni2024wiki,
  title={Wiki-LLaVA: Hierarchical Retrieval-Augmented Generation for Multimodal LLMs},
  author={Caffagni, Davide and Cocchi, Federico and Moratelli, Nicholas and Sarto, Sara and Cornia, Marcella and Baraldi, Lorenzo and Cucchiara, Rita},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={1818--1826},
  year={2024}
}

@article{bai2024hallucination,
  title={Hallucination of multimodal large language models: A survey},
  author={Bai, Zechen and Wang, Pichao and Xiao, Tianjun and He, Tong and Han, Zongbo and Zhang, Zheng and Shou, Mike Zheng},
  journal={arXiv preprint arXiv:2404.18930},
  year={2024}
}

@software{Liu_LlamaIndex_2022,
author = {Liu, Jerry},
doi = {10.5281/zenodo.1234},
month = {11},
title = {{LlamaIndex}},
url = {https://github.com/jerryjliu/llama_index},
year = {2022}
}


@inproceedings{schwenk2022okvqa,
  title={A-okvqa: A benchmark for visual question answering using world knowledge},
  author={Schwenk, Dustin and Khandelwal, Apoorv and Clark, Christopher and Marino, Kenneth and Mottaghi, Roozbeh},
  booktitle={European conference on computer vision},
  pages={146--162},
  year={2022},
  organization={Springer}
}

@article{jiang2024mmsearch,
  title={Mmsearch: Benchmarking the potential of large models as multi-modal search engines},
  author={Jiang, Dongzhi and Zhang, Renrui and Guo, Ziyu and Wu, Yanmin and Lei, Jiayi and Qiu, Pengshuo and Lu, Pan and Chen, Zehui and Song, Guanglu and Gao, Peng and others},
  journal={arXiv preprint arXiv:2409.12959},
  year={2024}
}

@article{zhang2023internlm,
  title={Internlm-xcomposer: A vision-language large model for advanced text-image comprehension and composition},
  author={Zhang, Pan and Dong, Xiaoyi and Wang, Bin and Cao, Yuhang and Xu, Chao and Ouyang, Linke and Zhao, Zhiyuan and Duan, Haodong and Zhang, Songyang and Ding, Shuangrui and others},
  journal={arXiv preprint arXiv:2309.15112},
  year={2023}
}