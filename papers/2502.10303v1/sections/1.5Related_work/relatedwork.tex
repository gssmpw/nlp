There are a lot of related work that reviewed the
reinforcement learning in strategy-based and atari games. Arulkumaran et
al\cite{I9} this paper serves as a foundational reference that outlines 
the evolution and state-of-the-art developments in DRL up to its 
publication. It also offers insights into how combining deep learning 
with reinforcement learning has led to significant advancements in 
areas such as game playing, robotics, and autonomous decision-making 
systems. Zhao et al.\cite{I10} surveys how DRL combines 
capabilities of deep learning with the decision-making processes of 
reinforcement learning, enabling systems to make control decisions 
directly from input images. It also analysis the development of 
AlphaGo, and examines the algorithms and techniques that contributed 
to AlphaGo's success, providing insights into the integration of DRL 
in complex decision-making tasks. Tang et
al.\cite{I11} also surveys how AlphaGo marked a significant 
milestone by defeating human champions in the game of Go, and its 
architecture and training process; then delves into AlphaGo Zero. 
Shao et al.\cite{I12} categorize DRL methods into three primary 
approaches: value-based, policy gradient, and model-based algorithms, 
offering a comparative analysis of their techniques and properties.
The survey delves into the implementation of DRL across various video 
game types, ranging from classic arcade games to complex real-time 
strategy games.
It highlights how DRL agents, equipped with deep neural network-based 
policies, process high-dimensional inputs to make decisions that 
maximize returns in an end-to-end learning framework.
this review also discusses the achievement of superhuman performance 
by DRL agents in several games, underscoring the significant progress 
in this field.
However, it also addresses ongoing challenges such as exploration-exploitation 
balance, sample efficiency, generalization and transfer learning, 
multi-agent coordination, handling imperfect information, and managing 
delayed sparse rewards.\\
Our paper is similar to Shao et al.\cite{I12}, as we discussed the 
developments that Google DeepMind made in developing AI models for 
games and the advancments that they made over the last years to develop 
the models and the future directions of implementating the DRL in games; 
how this implementation helps in developing real life applications. The
main contribution in our paper is the comprehensive details of the three 
models AlphaGo, AlphaGo Zero, and MuZero, focusing on the key Innovations for 
each model, how the training process was done, challenges that each model
faced and the improvements that were made, and the preformance benchmarks. 
Studying each on of these models in details helps in understanding how 
RL was developed in games reaching to the current state, by which it is 
now used in real life applications.
Also we discussed the advancments in these three AI models, 
reaching to the future directions.