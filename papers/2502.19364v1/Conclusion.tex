%----------------------------------------------------------------------------------------
%
% Conclusion Générale
%
%----------------------------------------------------------------------------------------
\addchap{Conclusion and future works}
\label{conlusion_globale}

\section*{Overview Of Contributions}

The work presented in this thesis brings significant progress to the field of 
time series analysis, particularly in areas concerning supervised and unsupervised 
learning, benchmarking machine learning models, foundation models for time series 
classification, generative models and model complexity reduction. Through comprehensive 
experimentation and rigorous evaluation, the thesis has developed and 
demonstrated several novel methodologies for addressing some of the most 
challenging aspects of time series data, such as high-dimensionality, 
multivariate dependencies, and limited labeled data.

Chapter~\ref{chapitre_1} lays the groundwork for the research, providing an extensive 
review of the state-of-the-art techniques for time series analysis. 
It introduces both supervised and unsupervised learning methods, including Time 
Series Classification and Extrinsic Regression. In addition, the chapter discusses 
self-supervised learning techniques, paving the way for the novel approaches 
later introduced in the thesis. This chapter serves as an essential foundation, 
offering insight into existing challenges and the research landscape in deep learning for 
time series analysis.

A central contribution of this thesis is the introduction of more refined tools for
model benchmarking in time series analysis especially discriminative models. Chapter~\ref{chapitre_2}
critiques traditional methods like the Critical Difference Diagram (CDD)~\cite{demsar-cdd-paper}, 
which suffers from instabilities and overlooks the magnitude of performance differences. 
The Multiple Comparison Matrix (MCM) is introduced as an alternative, offering more 
reliable comparisons across datasets, addressing weaknesses in existing statistical tests. 
This new method improves the precision of model evaluation and provides clearer insights 
into relative model performance.

In Chapter~\ref{chapitre_3}, the search for foundational models that can generalize 
across time series data is explored. A key contribution here is the development of 
pre-trained models capable of adapting to various classification tasks. This 
includes PHIT (Pre-trained H-InceptionTime), which shows significant improvements 
in performance when compared to non-pre-trained models across a large number of 
time series datasets. By establishing a foundation for transfer learning in time series, 
this chapter paves the way for future applications of foundational models.
These models leverages a second key contribution introduced in this chapter, the hand-crafted convolution
filters that help generalization of the deep learning models by offering prior non-trainable filters
to detect specific patterns in the time series.
Extensive experiments on the UCR archive~\cite{ucr-archive} highlights how our proposed domain 
foundation models outperforms classical baseline deep learning techniques with no pre-training.

Chapter~\ref{chapitre_4} presents the LITE and LITEMV models, showing significant 
advancements in reducing the computational complexity of deep learning models 
for Time Series Classification. LITE offers a simplified architecture based on 
Inception~\cite{inceptiontime-paper}, reducing the number of parameters while 
maintaining competitive performance. Additionally, LITEMV adapts this architecture 
for multivariate time series, incorporating DepthWise Convolutions~\cite{mobilenets}
to handle data from multiple channels more efficiently. These models represent a major 
step toward making deep learning more accessible in resource-constrained environments.
Experiments on both the UCR archive (univariate)~\cite{ucr-archive} and the UEA archive 
(multivariate)~\cite{uea-archive} demonstrate that smaller models can be just as 
effective as complex ones. This is achieved with only a few boosting techniques 
to address the trade off between model complexity and performance.
%MDC: I don't understand the last part of the sentence. HFC: fixed

Building on the challenges of acquiring labeled data, Chapter~\ref{chapitre_5} 
introduces TRILITE, a self-supervised model using triplet loss~\cite{triplet-loss-paper} 
to learn representations from unlabeled time series data. This model excels in 
situations where labeled data is scarce, offering a solution for improving classifier 
performance in both supervised and semi-supervised scenarios. The use of data augmentation 
adapted to time series enhances its ability to learn meaningful patterns. 
This work opens up new possibilities for applying self-supervised learning 
techniques to time series tasks beyond classification.
Extensive experiments on the UCR archive showcase the performance of TRILITE in two cases, 
where the dataset lacks a lot labeled samples, and when the datasets lacks a lot of samples even 
if they are labeled.

% MDC: as the application is not yet mentioned in the conclusion, 
% I would say something more general like : "In order to 
% valorize the theorical contributions, we explored their adaptation 
% on a more applicative contexte like human motion analysis. 
% Hence CHapter 6 focuses on...". HFC: fixed
In order to highlight the practical relevance of the theoretical contributions 
made in this thesis, we explored their application in a real-world context, 
such as human motion analysis.
Hence Chapter~\ref{chapitre_6} focuses on the analysis of human movement using time 
series data captured by Kinect cameras~\cite{kinect-paper}. The model LITEMVTime, 
introduced earlier, is applied to classify the quality of human movements 
in rehabilitation contexts. Using datasets such as Kimore~\cite{kimore-paper}, the model 
provides accurate assessments of patient movements, outperforming other deep learning 
architectures.
Additionally, the chapter introduces generation pipelines for generating realistic 
human motion sequences, including a prototyping method through a novel approach we proposed 
called ShapeDBA and a CNN-based deep Supervised Variational Autoencoder (SVAE). 
Both models, capable of generating high-fidelity and diverse human motion sequences, 
are particularly beneficial for applications in the medical and entertainment domains. 
This generation capability opens the door for further exploration in areas like real-time 
motion generation in gaming and rehabilitation contexts.

In Chapter~\ref{chapitre_7}, we revisit the topic of evaluation introduced in 
Chapter~\ref{chapitre_2}, but with a specific focus on evaluating generative models.
% MDC: this last sentence sounds a bit like "oral". HFC: fixed
The challenges of evaluating generative models 
for human motion are addressed. A new metric, Warping Path Diversity (WPD), 
is introduced to account for temporal distortions in generated sequences, 
complementing traditional metrics like Fréchet Inception Distance (FID)~\cite{fid-original-paper}. 
This unified evaluation framework helps in assessing both the fidelity and diversity 
of generated human movements. These metrics are essential for applications like 
video games and medical simulations, where realism and variability are crucial.

Chapter~\ref{chapitre_8} highlights the importance of reproducibility in 
machine learning research. A significant contribution here is the development 
of the open-source \emph{aeon} package~\cite{aeon-paper}, which integrates the models 
and methodologies presented throughout the thesis. This package, available to the research 
community, ensures that experiments are reproducible and that tools developed can be 
widely used and extended. By providing detailed documentation and modular code, 
this thesis promotes transparency and collaboration in time series research.

While the contributions of this research have provided strong foundations for time series 
classification and analysis, several areas remain ripe for future exploration.
In the following section we discuss some of the future perspectives for the advancements
in this field.

\section*{Discussion Of Future Works}

While the benchmarking contributions have provided a more comprehensive 
way to evaluate models, the introduction of more sophisticated statistical tools 
could refine these comparisons further. As models become increasingly complex, 
it will be essential to develop new methods for evaluating not just their 
performance, but also their scalability, robustness, and interpretability. 
Developing tools that combine the insights from MCM with other multi-objective 
optimization techniques might provide more holistic evaluation metrics.

While this thesis has laid the groundwork for foundation models in time series 
classification tasks, future work could explore extending these models to time 
series forecasting. Forecasting presents unique challenges, such as the need to
predict future data points based on past observations, which requires models to 
capture long-term dependencies effectively. Future research could investigate 
how pre-trained foundation models, like PHIT, can be adapted to handle time 
series forecasting~\cite{forecasting-foundatio}, potentially incorporating attention mechanisms to focus 
on relevant parts of the data~\cite{foundation-models-example-paper}. Another area of interest would be transfer 
learning techniques for forecasting tasks~\cite{transfer-learning-forecasting}, enabling models trained on one 
domain to generalize effectively to another, such as transitioning from medical 
time series data to financial market predictions. This extension would significantly 
broaden the applicability of foundation models in real-world scenarios.

An additional key area of future work is the development of lightweight and efficient 
models like LITE and LITEMV. These models have demonstrated great promise in low-resource 
environments, but more research is needed to optimize them for even larger and more 
complex datasets. Additionally, extending these models to other domains such as real-time 
streaming data or applications in Internet of Things (IoT)~\cite{iot-tsc} systems could unlock further potential.

Another potential direction is the extension of TRILITE and similar self-supervised 
models to other types of time series tasks beyond classification. Future research 
could explore how these models might be adapted for tasks such as time series forecasting~\cite{self-sup-forecasting}, 
anomaly detection~\cite{self-sup-anom-detection}, or even generative tasks. Moreover, there is considerable room to 
improve the data augmentation techniques used in triplet loss frameworks to further 
enhance their robustness in diverse scenarios~\cite{series2vec}.

The generative models introduced in this thesis, particularly for human motion 
generation, have shown promise in generating realistic motion sequences. However, 
future work could focus on improving the temporal diversity of these generated motions. 
Current models can generate high-quality movements but may lack variability in timing 
and execution styles. Incorporating techniques such as adversarial training or variational 
approaches could enhance the diversity of generated motions, making them more useful 
for applications like virtual reality, gaming, and medical simulations.
Furthermore, exploring multimodal data inputs, such as combining visual data with motion 
sensor data, could improve the robustness of generated sequences, allowing models 
to better mimic real-world human movements. This would broaden the scope of 
applications for human motion data generation, particularly in scenarios where 
subtle variations in motion are crucial, such as in rehabilitation exercises or 
fine motor skill training.
Regarding the Warping Path Diversity, it takes into consideration DTW based warping distortions,
however exploring the disentanglement of shape and temporal patterns~\cite{marteau2019separation}
could improve upon traditional DTW, enabling a more detailed and nuanced analysis of time series variability.

Moreover, the \emph{aeon} package's continued development~\cite{aeon-paper} should focus on incorporating 
more advanced deep learning architectures, as well as improving the ease with which 
users can contribute and extend the framework. Incorporating more interactive 
visualization tools that allow researchers to explore model outputs and hyper-parameters 
could enhance the usability of the package.

Finally, deep learning for Time Series Extrinsic Regression~\cite{tser-archive} remains an unfinished 
area of research, largely because most existing models are adaptations of architectures 
originally designed for classification tasks. While classification tasks aim to 
categorize time series data into discrete classes~\cite{bakeoff-tsc-1}, extrinsic regression deals with 
predicting continuous values, which often requires handling more nuanced relationships 
in the data. The current approach involves repurposing classification models~\cite{deep-tsc-tser}, 
such as convolutional or recurrent networks, to perform regression by simply 
changing the final layer to output continuous values. However, this overlooks 
the fundamental differences between the tasks, especially in terms of loss 
functions and evaluation metrics. No models have been specifically designed 
with the unique challenges of extrinsic regression in mind, such as effectively 
capturing long-range dependencies and handling variability in the magnitude of 
predictions. A dedicated architecture tailored for regression tasks, which could 
leverage techniques like dynamic temporal scaling or specific optimization for 
continuous outputs, would be a crucial step forward in making deep learning 
models more effective for time series extrinsic regression. This gap presents 
an opportunity for future research to innovate and address the complexities 
that are unique to regression in time series data.

These directions point to a broad set of possibilities that build upon the 
foundation laid by this thesis. By continuing to focus on model efficiency, 
self-supervised learning, benchmarking, and reproducibility, the field of 
time series analysis will be well-positioned to address both current and future challenges.
