\section{Conclusion} \label{conclusion}
In this work, we introduced several key enhancements to the EGL algorithm, resulting in OHGL, a powerful black-box optimization tool capable of addressing various complex problems. We demonstrated improvements such as second-order gradient approximation, optimistic gradients, and trust region enhancements, which collectively led to faster convergence and more robust performance, particularly in high-dimensional and intricate tasks.

Our experiments showcased OHGL's superiority over state-of-the-art methods, especially in tasks where computational efficiency and precision are paramount, such as adversarial attacks on vision models and optimizing code generation. OHGLâ€™s ability to navigate complex optimization spaces while minimizing computational cost demonstrates its utility across various applications.

% Looking ahead, Future research should explore new applications of black-box optimization algorithms like OHGL. While OHGL has shown promise in high-dimensional tasks, its efficiency could be further improved. Our research utilized dimension-reduction methods such as \cite{lora}. Similar techniques (\cite{zhao2024galore, anil2020scalable}) can help calculate the Hessian more efficiently.

In conclusion, OHGL presents a novel BBO algorithm design, providing a robust framework for solving complex optimization problems. However, the true potential of BBO algorithms lies in their broader applicability, and future research should focus on unlocking new avenues for their use, especially in generative models and other cutting-edge areas.
