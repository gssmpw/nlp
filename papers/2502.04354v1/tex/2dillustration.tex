\section{Illustrative Examples in Dimension Two}
\label{app:2Dilustration}
\textbf{Experiment Setups}
In this experiment, we provide a two-dimensional example of the comparisons made by each strategy. The ground truth reward was defined as the log probability of a mixture of two Gaussians, centered at $(-2.5, -2.5)$ and $(2.5, 2.5)$ with a variance of 0.25. Preference data was simulated using the BT model, and we attempted to learn the reward function with a 3-layer MLP with $16$ hidden units. For each round, $1000$ points were sampled from a standard normal distribution, and $200$ comparisons were selected using different strategies. $4$ rounds are shown in \cref{fig:what_were_compared}.%, with a zoomed-in version in \cref{fig:what_were_compared-big}.
\begin{figure}[htp]
    \centering
    %\vspace{-0.58cm}
    \includegraphics[width=1.0\linewidth]{Figs/2D_GM_illustration.pdf}\vspace{-0.35cm}
    \caption{\small Comparisons drawn by different strategies to learn a 2D bimodal reward function. The heat map showed the estimated functions. Red dots connected by lines are \textbf{selected pairs} and gray dots on the first column are candidate points to choose from.} %\vspace{-0.42cm}
    \label{fig:what_were_compared}
\end{figure}

\textbf{What were compared in dimension two?}
We observed that D-optimal selects diverse samples with many anchoring points, often comparing multiple points to a single one, spreading out the level set in the original space. Entropy sampling, similar to random sampling, focuses on points near reward values, effectively traversing the reward function's level set. Coreset also selects diverse comparisons, though not always among points with similar reward values. The best design matrix method behaves similarly to coreset, emphasizing diversity in comparisons. In contrast, the max difference method tends to compare extreme values with many others, promoting exploration but potentially yielding less informative comparisons. BatchBALD also selects diverse comparisons, though without a clear pattern. These observations suggest that most methods encourage exploration, entropy sampling prioritizes informative comparisons, and D-optimal seeks a balance between the two.