\clearpage
\section{Additional Experiment Results}
%\input{tex/app-zoomed-in-2d}


\subsection{Comparing Annotation Efficiency on the \texttt{Helpful} Dataset}
\label{appdx:more_results_results_main}

\paragraph{In-Prompt Annotation} efficiency is provided in Figure~\ref{fig:results_main_helpful} (as supplementary of Figure~\ref{fig:results_main} in the main text).

\begin{figure}[h!]
    \centering
    \includegraphics[width=1.0\linewidth]{Figs/Main_xpromptFalse_hidden64_cand500_320_SPLIT_helpful.pdf}
    \caption{Comparing annotation efficiency of different methods. (\texttt{Helpful} Dataset, 3 Models, 8 Methods). First row: 1 - Spearman's Correlation (lower is better); second row: Best-of-N reward. Experiments are repeated with 5 seeds.}
    \label{fig:results_main_helpful}
\end{figure}

\paragraph{Cross-Prompt Annotation} efficiency is provided in Figure~\ref{fig:results_main_xprompt_helpful} (as supplementary of Figure~\ref{fig:results_main_xprompt} in the main text).

\begin{figure}[h!]
    \centering
    \includegraphics[width=1.0\linewidth]{Figs/Main_xpromptTrue_hidden64_cand500_320_SPLIT_helpful.pdf}
    \caption{\small Comparing annotation efficiency of different methods under the \textbf{Cross-Prompt} annotation setups. (\texttt{Helpful} Dataset, 3 Models, 8 Methods). First row: 1 - Spearman's Correlation (lower is better); second row: Best-of-N reward. Experiments are repeated with 5 seeds.}
    \label{fig:results_main_xprompt_helpful}
\end{figure}





\subsection{Annotation Batch Size}
\label{appdx:more_results_annotation_bs}
\paragraph{Results on All Models}
Due to the space limit of the main text, we deferred the experiment results with Gemma7B and the LLaMA3-8B model when studying the effect of different annotation batch sizes in the following Figures (Figure~\ref{fig:results_annotation_bs_gemma2b_zoom}, Figure~\ref{fig:results_annotation_bs_gemma7b_zoom}, Figure~\ref{fig:results_annotation_bs_llama38b_zoom}). 
To summarize the main takeaways --- we observe the same trend as we have observed with the Gemma2B model, the proposed methods achieve better performances in the small batch size setups (more online setups). The stability of small batch setups is in general higher than the large batch setups.


\begin{figure}[h!]
    \centering
    \includegraphics[width=0.8\linewidth]{Figs/CompareAnnoBatch_gemma2b_64_xpromptFalse_h=7.pdf}
    \caption{\small Investigating how annotation batch size choices affect learning performance of different methods. Model: Gemma 2B.}
    \label{fig:results_annotation_bs_gemma2b_zoom}
\end{figure}


\begin{figure}[h!]
    \centering
    \includegraphics[width=0.8\linewidth]{Figs/CompareAnnoBatch_gemma7b_64_xpromptFalse_h=7.pdf}
    \caption{\small Investigating how annotation batch size choices affect learning performance of different methods. Model: Gemma 7B.}
    \label{fig:results_annotation_bs_gemma7b_zoom}
\end{figure}

\begin{figure}[h!]
    \centering
    \includegraphics[width=0.8\linewidth]{Figs/CompareAnnoBatch_llama38b_64_xpromptFalse_h=7.pdf}
    \caption{\small Investigating how annotation batch size choices affect learning performance of different methods. Model: LLaMA3-8B.}
    \label{fig:results_annotation_bs_llama38b_zoom}
\end{figure}

\paragraph{Results with All Methods.}
In addition, we use the figures below (Figure~\ref{fig:results_annotation_bs_gemma2b_total}, Figure~\ref{fig:results_annotation_bs_gemma7b_total}, Figure~\ref{fig:results_annotation_bs_llama38b_total}) for a full analysis on the annotation batch size choices for all methods. For other methods, we do not observe a clear trend on the effect of increasing or decreasing annotation batch sizes.


\begin{figure}[h!]
    \centering
    \includegraphics[width=1.0\linewidth]{Figs/CompareAnnoBatch_gemma2b_64_xpromptFalse.pdf}
    \caption{\small Investigating how annotation batch size choices affect learning performance of different methods. Model: Gemma 2B.}
    \label{fig:results_annotation_bs_gemma2b_total}
\end{figure}


\begin{figure}[h!]
    \centering
    \includegraphics[width=1.0\linewidth]{Figs/CompareAnnoBatch_gemma7b_64_xpromptFalse.pdf}
    \caption{\small Investigating how annotation batch size choices affect learning performance of different methods. Model: Gemma 7B.}
    \label{fig:results_annotation_bs_gemma7b_total}
\end{figure}

\begin{figure}[h!]
    \centering
    \includegraphics[width=1.0\linewidth]{Figs/CompareAnnoBatch_llama38b_64_xpromptFalse.pdf}
    \caption{\small Investigating how annotation batch size choices affect learning performance of different methods. Model: LLaMA3 8B.}
    \label{fig:results_annotation_bs_llama38b_total}
\end{figure}

\newpage
\subsection{Compare Cross-Prompt Comparisons and In-Prompt Comparisons}
\label{appdx:more_results_xprompt-in-prompt_comparison}
In this section, we provide direct comparisons of learning efficiency when using cross-prompt annotations and in-prompt annotations. In most cases, annotating comparisons using cross-prompt comparison improves learning efficiency, and this can be observed across all methods. Specifically, with the entropy-based method, cross-prompt annotations bring a noticeable boost to learning efficiency and reward model performance.

\begin{figure}[h!]
    \centering
    \includegraphics[width=1.0\linewidth]{Figs/CompareXprompt_gemma2b_rnds80.pdf}
\caption{\small Cross-Prompt preference annotation improves overall annotation efficiency. Annotation batch size 500. Model: Gemma2B.}
    \label{fig:results_xprompt_inprompt_abs500_gemma2b}
\end{figure} 


\begin{figure}[h!]
    \centering
    \includegraphics[width=1.0\linewidth]{Figs/CompareXprompt_gemma7b_rnds80.pdf}
\caption{\small Cross-Prompt preference annotation improves overall annotation efficiency. Annotation batch size 500. Model: Gemma7B.}
    \label{fig:results_xprompt_inprompt_abs500_gemma7b}
\end{figure} 


\begin{figure}[h!]
    \centering
    \includegraphics[width=1.0\linewidth]{Figs/CompareXprompt_llama38b_rnds80.pdf}
    \caption{\small Cross-Prompt preference annotation improves overall annotation efficiency. Annotation batch size 500. Model: LLaMA3-8B.}
    \label{fig:results_xprompt_inprompt_abs500_llama38b}
\end{figure} 


% \begin{figure}[h!]
%     \centering
%     \includegraphics[width=1.0\linewidth]{Figs/CompareXprompt_gemma2b_rnds320.pdf}
% \caption{\small Cross-Prompt preference annotation improves overall annotation efficiency. Annotation batch size 125. Model: Gemma2B.}
%     \label{fig:results_xprompt_inprompt_abs125_gemma2b}
% \end{figure}\\


% \begin{figure}[h!]
%     \centering
%     \includegraphics[width=1.0\linewidth]{Figs/CompareXprompt_gemma7b_rnds320.pdf}
% \caption{\small Cross-Prompt preference annotation improves overall annotation efficiency. Annotation batch size 125. Model: Gemma7B.}
%     \label{fig:results_xprompt_inprompt_abs125_gemma7b}
% \end{figure}  \\


% \begin{figure}[h!]
%     \centering
%     \includegraphics[width=1.0\linewidth]{Figs/CompareXprompt_llama38b_rnds320.pdf}
%     \caption{\small Cross-Prompt preference annotation improves overall annotation efficiency. Annotation batch size 125. Model: LLaMA3-8B.}
%     \label{fig:results_xprompt_inprompt_abs125_llama38b}
% \end{figure} \\% 

\clearpage
\subsection{Hyper-Parameter Sensitivity Analysis}
\label{appdx:more_results_hyper_param_sensitivity}

\paragraph{Number of Candidate Numbers}
In the main text, our empirical pipeline starts by sampling $500$ candidates (\texttt{candidate number}) from the training prompts, and then randomly generates $20000$ pairs of comparisons using either in-prompt comparison or cross-prompt comparison. Then, we select \texttt{annotation batch size} number of comparisons to annotate. In this section, we evaluate the performance difference by using a larger \texttt{candidate number} $1000$. 

In experiments, we find those setups do not significantly change the performance of different methods. The performance of D-opt and Past-Aware D-opt are especially robust to those hyper-parameter choices.

% \begin{figure}[h!]
%     \centering
%     % \includegraphics[width=1.0\linewidth]{Figs/CompareCandidates_gemma2b_rnds40.pdf}
%     % \includegraphics[width=1.0\linewidth]{Figs/CompareCandidates_gemma2b_rnds80.pdf}
%     \includegraphics[width=1.0\linewidth]{Figs/CompareCandidates_gemma2b_rnds320.pdf}
%     \caption{\small Preference annotation with different \texttt{candidate number} choices. Annotation batch size 125. Model: Gemma2B.}
%     \label{fig:results_candidate_abs125_gemma2b}
% \end{figure}

\begin{figure}[h!]
    \centering
    \includegraphics[width=1.0\linewidth]{Figs/CompareCandidates_gemma2b_rnds80.pdf}
    \caption{\small Preference annotation with different \texttt{candidate number} choices. Annotation batch size 500. Model: Gemma2B.}
    \label{fig:results_candidate_abs500_gemma2b} 
\end{figure}
% \begin{figure}[h!]
%     \centering
%     \vspace{-1.3cm}
%     % \includegraphics[width=1.0\linewidth]{Figs/CompareCandidates_gemma2b_rnds40.pdf}
%     % \includegraphics[width=1.0\linewidth]{Figs/CompareCandidates_gemma2b_rnds80.pdf}
%     \includegraphics[width=1.0\linewidth]{Figs/CompareCandidates_gemma7b_rnds320.pdf}
%     \caption{\small Preference annotation with different \texttt{candidate number} choices. Annotation batch size 125. Model: Gemma2B.}
%     \label{fig:results_candidate_abs125_gemma7b} 
% \end{figure}

\begin{figure}[h!]
    \centering
    % \includegraphics[width=1.0\linewidth]{Figs/CompareCandidates_gemma2b_rnds40.pdf}
    % \includegraphics[width=1.0\linewidth]{Figs/CompareCandidates_gemma2b_rnds80.pdf}
    \includegraphics[width=1.0\linewidth]{Figs/CompareCandidates_gemma7b_rnds80.pdf}
    \caption{\small Preference annotation with different \texttt{candidate number} choices. Annotation batch size 500. Model: Gemma7B.}
    \label{fig:results_candidate_abs500_gemma7b} 
\end{figure}



% \begin{figure}[h!]
%     \centering
%     % \includegraphics[width=1.0\linewidth]{Figs/CompareCandidates_gemma2b_rnds40.pdf}
%     % \includegraphics[width=1.0\linewidth]{Figs/CompareCandidates_gemma2b_rnds80.pdf}
%     \includegraphics[width=1.0\linewidth]{Figs/CompareCandidates_llama38b_rnds320.pdf}
%     \caption{\small Preference annotation with different \texttt{candidate number} choices. Annotation batch size 125. Model: LLaMA3-8B.}
%     \label{fig:results_candidate_abs125_llama38b} 
% \end{figure}

\begin{figure}[h!]
    \centering
    % \includegraphics[width=1.0\linewidth]{Figs/CompareCandidates_gemma2b_rnds40.pdf}
    % \includegraphics[width=1.0\linewidth]{Figs/CompareCandidates_gemma2b_rnds80.pdf}
    \includegraphics[width=1.0\linewidth]{Figs/CompareCandidates_llama38b_rnds80.pdf}
    \caption{\small Preference annotation with different \texttt{candidate number} choices. Annotation batch size 500. Model: LLaMA3-8B.}
    \label{fig:results_candidate_abs500_llama38b} 
\end{figure} 


\newpage
\paragraph{Number of Hidden Units in 3-Layer MLPs}
In all main text experiments, we use 3-layer MLPs with $64$ \textbf{hidden units}. In this section, we evaluate the performance difference by using a larger \texttt{hidden unit} $128$. 


\begin{figure}[h!]
    \centering
    \includegraphics[width=1.0\linewidth]{Figs/CompareHidden_gemma2b_80_xpromptFalse.pdf}
    \caption{\small Experiments with different \texttt{hidden unit} choices. Annotation batch size 500. Model: Gemma 2B.}
    \label{fig:results_hidden_abs500_gemma2b} 
\end{figure} 


\begin{figure}[h!]
    \centering
    \includegraphics[width=1.0\linewidth]{Figs/CompareHidden_gemma7b_80_xpromptFalse.pdf}
    \caption{\small Experiments with different \texttt{hidden unit} choices. Annotation batch size 500. Model: Gemma 7B.}
    \label{fig:results_hidden_abs500_gemma7b} 
\end{figure} 

\begin{figure}[h!]
    \centering
    \includegraphics[width=1.0\linewidth]{Figs/CompareHidden_llama38b_80_xpromptFalse.pdf}
    \caption{\small Experiments with different \texttt{hidden unit} choices. Annotation batch size 500. Model: LLaMA3-8B.}
    \label{fig:results_hidden_abs500_llama38b} 
\end{figure} 



