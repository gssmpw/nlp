% A foundation model is a machine learning or deep learning model that is trained on *Broad Data* such that it can be applied across a *Wide Range of Use Cases*.

% Image Generation

% HumanSD: A Native Skeleton-Guided Diffusion Model for Human Image Generation
% Broad Data: three large-scale human-centric datasets containing high-quality images and the corresponding 2D skeletal information and text descriptions: GHI (1M), LAION-Human (1M), and Human-Art (50K).
% Wide Use Cases: multi-scenario human-centric image generation with precise pose control.


% HyperHuman: Hyper-Realistic Human Generation with Latent Structural Diffusion
% Broad Data: 340M images with comprehensive annotations like human pose, depth, and surface-normal.
% Wide Use Cases: simultaneously generates the coarse RGB, depth, normal, and high-resolution images conditioned on text and skeleton. Both photo-realistic images and stylistic renderings can be created.

% CosmicMan: A Text-to-Image Foundation Model for Humans
% Broad Data: 6 Million high-quality real-world human images in a mean resolution of 1488Ã—1255, and attached with precise text annotations deriving from 115 Million attributes in diverse granularities.
% Wide Use Cases: human-centric content generation tasks: Text to Image, 2D Human Editing, 3D Human Reconstruction



% Video Generation

% Human4DiT: 360-degree Human Video Generation with 4D Diffusion Transformer
% Broad Data: we collect a new multi-dimensional dataset comprises human images, videos, multiview videos, 3D data, as well as a small amount of 4D data spanning different viewpoints and time steps. It contains 5k 3D human scans capture by camera rigs, 10k videos from YouTube/Bilibili, and 100 animatable human models from artists.
% Wide Use Cases: monocular video generation, 360-degree video generation, 3D static video generation, multiview video generation

% Body of Her: A Preliminary Study on End-to-End Humanoid Agent
% SOLAMI: Social Vision-Language-Action Modeling for Immersive Interaction with 3D Autonomous Characters

% Applications
% DynVideo-E: Harnessing Dynamic NeRF for Large-Scale Motion- and View-Change Human-Centric Video Editing



% Motion Generation

% Large Motion Model for Unified Multi-Modal Motion Generation
% Broad Data: We consolidate datasets with different modalities, formats and tasks into a comprehensive yet unified motion generation dataset, MotionVerse, comprising 10 tasks, 16 datasets, a total of 320k sequences, and 100 million frames.
% Wide Use Cases: text to motion, action to motion, speech to gesture, music to dance, motion prediction

% Exploring Vision Transformers for 3D Human Motion-Language Models with Motion Patches
% Broad Data: HumanML3D and KIT Motion-Language dataset.
% Wide Use Cases: text to motion, motion to text, cross-skeleton recognition, zero-shot motion classification, human interaction recognition

% FreeMotion: MoCap-Free Human Motion Synthesis with Multimodal Large Language Models
% Broad Data: without any motion data (?)
% Wide Use Cases: motion synthesis, style transfer, human-scene interaction, and stepping stones


% HOI


% ManiVideo: Generating Hand-Object Manipulation Video with Dexterous and Generalizable Grasping


% Paper list

% Image X GAN

% StyleGAN-Human: A Data-Centric Odyssey of Human Generation
% Text2Human: Text-Driven Controllable Human Image Generation
% UnitedHuman: Harnessing Multi-Source Data for High-Resolution Human Generation

% Image X Diffusion
% HumanDiffusion: a Coarse-to-Fine Alignment Diffusion Framework for Controllable Text-Driven Person Image Generation