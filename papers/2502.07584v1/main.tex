\documentclass[12pt,cleveref]{colt2025} % Anonymized submission
%\documentclass[final,12pt]{colt2024} % Include author names

% The following packages will be automatically loaded:
% amsmath, amssymb, natbib, graphicx, url, algorithm2e


%%%%%%%%%%%%%%%%%% Our packages and commands %%%%%%%%%%%%%%%%%%
\usepackage{hyperref}       % hyperlinks
\usepackage{url}            % simple URL typesetting
\usepackage{booktabs}       % professional-quality tables
\usepackage{amsfonts}       % blackboard math symbols
\usepackage{nicefrac}       % compact symbols for 1/2, etc.
\usepackage{microtype}      % microtypography
\usepackage{xcolor}         % colors
\usepackage{amsmath}
% \usepackage{natbib} % May not be compatible

\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{mathtools}
% WARNING: thm-restate may create bugs
\usepackage{thm-restate}
% \usepackage{amsthm} % Not compatible with COLT template

\usepackage{bbm}

\usepackage{array}
\usepackage{threeparttable}
\usepackage{siunitx}

\usepackage{enumerate}

%%%%%%%%%%%% enumitem %%%%%%%%%% 
\usepackage{enumitem}

\usepackage{wrapfig}

% A few commands
\usepackage{dsfont}
\usepackage{comment}
\usepackage{xspace}
\newcommand{\resp}{{\textit{ resp.}}\xspace}
\newcommand{\eg}{e.g.\xspace}
\newcommand{\as}{a.s.\xspace}
\newcommand{\aka}{{\textit{ a.k.a.}}\xspace}
\newcommand{\wrt}{{\textit{ w.r.t.}}\xspace}
\newcommand{\iid}{\xspace}
\newcommand{\Zcal}{\mathcal{Z}}
\newcommand{\ie}{{\textit{ i.e.}}\xspace}
\newcommand{\Scal}{\mathcal{S}}
\newcommand{\defeq}{:=}
\newcommand{\R}{\mathds{R}}
\newcommand{\risk}{\mathcal{R}}
\newcommand{\er}{\widehat{\mathcal{R}}_S}
\newcommand{\erprime}{\widehat{\mathcal{R}}_{S'}}
\newcommand{\el}{\widehat{L}_S}
\newcommand{\ef}{\widehat{F}_S}
\newcommand{\totalmutual}{\text{I}_\infty}
\newcommand{\mutual}{\text{I}_1}
\newcommand{\zcal}{\mathcal{Z}}
\newcommand{\wcal}{\mathcal{W}}
\newcommand{\wcalsu}{\mathcal{W}_{S,U}}
\newcommand{\ycal}{\mathcal{Y}}
\newcommand{\ycalu}{\mathcal{Y}_{U}}
\newcommand{\wgen}{\sup_{w\in\wcalsu} \left( F(w) - \ef(w) \right)}
\newcommand{\wygen}{\sup_{y\in\ycalu} \left( F(w) - \ef(w) \right)}
\newcommand{\Rd}{{\R^d}}
\newcommand{\levy}{L_t^\alpha}
\newcommand{\upperbox}{\overline{\dim}_{\text{\normalfont{B}}}}
\newcommand{\gnabla}{ \sup_{w \in \ycalu} \Vert \nabla\ef(w) - \nabla F(w) \Vert}
\newcommand{\E}{\mathds{E}}
\newcommand{\Eof}[2][]{\mathds{E}_{#1} \left[ #2 \right]}
\newcommand{\Eofunder}[2][]{\mathop{\mathbb{E}}_{#1}\left[ #2 \right]}
\newcommand{\Pof}[2][]{\mathds{P}_{#1} \left( #2 \right)}
\newcommand{\haus}{\mathcal{H}^{\alpha}}
\newcommand{\symb}{\boldsymbol{\Psi}}
\newcommand{\prob}{\mathds{P}}
\newcommand{\normof}[1]{\left\Vert #1 \right\Vert}
\newcommand{\klb}[2]{\text{\normalfont{{KL}}}\left(#1 || #2 \right)}
\newcommand{\klbx}[2]{\text{\normalfont{{KL}}}^x\left(#1 || #2 \right)}
\newcommand{\klbp}[3][P]{\text{\normalfont{{KL}}}_{#1}\left(#2 || #3 \right)}
\newcommand{\diam}{\text{\normalfont{diam}}}
\newcommand{\hausdim}{\dim_{\text{\normalfont{H}}}}
\newcommand{\sgn}{\text{\normalfont{sgn}}}
\newcommand{\support}{\text{\normalfont{supp}}}
\newcommand{\nll}{\centernot{\ll}}
\newcommand{\multiindex}{{\boldsymbol{i}}}
\newcommand{\partialmean}[1][j]{\overline{\partial_{#1}}}
\newcommand{\intr}{\int_{-\infty}^\infty}
\newcommand{\phieps}{\varphi_\epsilon}
\DeclareMathOperator*{\esssup}{ess\,sup}
\newcommand{\dimvalue}{\gamma}
\newcommand{\op}[1]{I\left[ #1 \right] }
\newcommand{\steady}{\bar{u}_\infty}
\newcommand{\bregmanphi}[2]{B_\Phi(#1, #2)}
\newcommand{\bregman}[3][2]{B_{#1}\left(#2, #3\right)}
\newcommand{\uinftybar}{\bar{u}_\infty}
\newcommand{\entphi}[2]{\text{\normalfont Ent}_{#1}^\Phi \left(#2\right)}
\newcommand{\setof}[1]{\left\{ #1 \right\} }
\newcommand{\datadist}{\mu_z^{\otimes n}}
\newcommand{\Sd}{{\mathds{S}^{d-1}}}
\newcommand{\chisq}[2]{\chi^2\left(#1 \right|\left| #2 \right)}
\newcommand{\fraclap}{ \left( -\Delta \right)^{\frac{\alpha}{2}}}
\newcommand{\red}[1]{{\color{red}#1}}
\newcommand{\blue}[1]{{\color{blue}#1}}
\newcommand{\equald}{\overset{\mathbf{d}}{=}}
\newcommand{\landau}[2][]{\mathcal{O}_{#1} \left( #2 \right)}
\newcommand{\fcal}{\mathcal{F}}
\newcommand{\acal}{\mathcal{A}}
\newcommand{\limit}[1]{\underset{#1}{\longrightarrow}}
\newcommand{\renyi}[3][2]{R_{#1}(#2, #3)}
\newcommand{\ealpha}[3][2]{E_{#1}(#2, #3)}
\newcommand{\rinfo}[3][\beta]{I_{#1}(#2, #3)}
\newcommand{\der}{\text{\normalfont d}}
\newcommand{\calphad}{C_{\alpha,d}}
\newcommand{\kalphad}{K_{\alpha,d}}
\newcommand{\intrd}{\int_{\Rd}}
\newcommand{\intsd}{\int_{\mathds{S}^{d - 1}}}
\newcommand{\intrdzero}{\int_{\Rd\backslash\setof{0}}}
\newcommand{\gammaof}[1]{\Gamma \left( #1 \right)}
\newcommand{\timeder}{\frac{d}{dt}}
\newcommand{\forcediff}{\mathfrak{D}}
\newcommand{\sensitivity}{\mathcal{S}}
\newcommand{\by}[1]{\quad\text{(#1)}}
\newcommand{\parenthesis}[1]{\left( #1 \right)}
\newcommand{\normal}[1][\sigma]{\mathcal{N}(0,{#1}^2 I_d)}
\newcommand{\tv}{\mathrm{TV}}
\newcommand{\dataW}{W_{\vartheta_S} }
\newcommand{\ecal}{\mathcal{E}}
\newcommand{\bcal}{\mathcal{B}}
\newcommand{\borel}{\mathcal{B}(\mathds{R}^d)}
\newcommand{\pcal}{\mathcal{P}}
\newcommand{\probameasures}{\mathcal{P}(\Rd)}
\newcommand{\var}{\mathrm{Var}}
\newcommand{\N}{{\mathds{N}}}
\newcommand{\ent}[2][\pi]{\mathrm{Ent}_{#1}\left( #2 \right)}
\newcommand{\cd}{\mathrm{CD}}
\newcommand{\C}{\mathds{C}}
\newcommand{\lcal}{{\mathcal{L}}}
\newcommand{\qcal}{{\mathcal{Q}}}
\newcommand{\law}{{\mathrm{Law}}}

\newcommand{\boxedthm}[1]{\vspace{0.2cm}
\noindent\fcolorbox{black}{gray!30}{\parbox{\textwidth}{#1}}\vspace{0.2cm}}


\usepackage{crossreftools}
\pdfstringdefDisableCommands{%
    \let\Cref\crtCref
    \let\cref\crtcref
}

% Some added packages

\usepackage{empheq}
\usepackage{times}
% \usepackage[capitalise]{cleveref}

% Adding assumption as ah environment
\newtheorem{assumption}{Assumption}
\crefname{assumption}{assumption}{assumptions}
\Crefname{assumption}{Assumption}{Assumptions}


\usepackage{fancyhdr}
\fancypagestyle{firstpage}{%
    \fancyhf{} % Clear all headers and footers
    \renewcommand{\headrulewidth}{0pt}
}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% \newcommand{\umut}[1]{{\color{red} Umut: #1}}
% \newcommand{\ben}[1]{{\color{purple} Ben: #1}}
% \newcommand{\maxime}[1]{{\color{orange} Maxime: #1}}
% \newcommand{\george}[1]{{\color{gfirstreen} George: #1}}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% \usepackage{soul}
\usepackage[normalem]{ulem}




\title[Poissonized Generalization Bounds for Markov Algorithms]{Understanding the Generalization Error of Markov algorithms through Poissonization}

% Use \Name{Author Name} to specify the name.
% If the surname contains spaces, enclose the surname
% in braces, e.g. \Name{John {Smith Jones}} similarly
% if the name has a "von" part, e.g \Name{Jane {de Winter}}.
% If the first letter in the forenames is a diacritic
% enclose the diacritic in braces, e.g. \Name{{\'E}louise Smith}

% Two authors with the same address
% \coltauthor{\Name{Author Name1} \Email{abc@sample.com}\and
%  \Name{Author Name2} \Email{xyz@sample.com}\\
%  \addr Address}

% Three or more authors with the same address:
% \coltauthor{\Name{Author Name1} \Email{an1@sample.com}\\
%  \Name{Author Name2} \Email{an2@sample.com}\\
%  \Name{Author Name3} \Email{an3@sample.com}\\
%  \addr Address}

% Authors with different addresses:
\coltauthor{%
 \Name{Benjamin Dupuis} \Email{benjamin.dupuis@inria.fr}\\
 \addr INRIA - Département d’Informatique de l’Ecole Normale Supérieure\\
 \addr PSL Research University - CNRS\\
 \addr Paris, France
 \AND
 \Name{Maxime Haddouche} \Email{maxime.haddouche@inria.fr}\\
 \addr INRIA - Département d’Informatique de l’Ecole Normale Supérieure \\
 \addr PSL Research University - CNRS\\
 \addr Paris, France
 \AND
 \Name{George Deligiannidis} \Email{george.deligiannidis@stats.ox.ac.uk}\\
 \addr Department of Statistics, University of Oxford \\
 \addr Oxford, UK
 \AND
 \Name{Umut Simsekli} \Email{umut.simsekli@inria.fr}\\
 \addr INRIA - Département d’Informatique de l’Ecole Normale Supérieure\\
 \addr PSL Research University - CNRS\\
 \addr Paris, France
 }



\begin{document}

\maketitle
\thispagestyle{firstpage}


\begin{abstract}%
Using continuous-time stochastic differential equation (SDE) proxies to stochastic optimization algorithms has proven fruitful for understanding their generalization abilities. A significant part of these approaches are based on the so-called `entropy flows', which greatly simplify the generalization analysis.
Unfortunately, such well-structured entropy flows cannot be obtained for most discrete-time algorithms, and the existing SDE approaches remain limited to specific noise and algorithmic structures.
We aim to alleviate this issue by introducing a generic framework for analyzing the generalization error of Markov algorithms through `Poissonization', a continuous-time approximation of discrete-time processes with formal approximation guarantees.
Through this approach, we first develop a novel entropy flow, which directly leads to PAC-Bayesian generalization bounds.
We then draw novel links to \emph{modified} versions of the celebrated logarithmic Sobolev inequalities (LSI), identify cases where such LSIs are satisfied, and obtain improved bounds.
Beyond its generality, our framework allows exploiting specific properties of learning algorithms. 
In particular, we incorporate the noise structure of different algorithm types—namely, those with additional noise injections (noisy) and those without (non-noisy)—through various technical tools.
This illustrates the capacity of our methods to achieve known (yet, Poissonized) and new generalization bounds.
\end{abstract}

\begin{keywords}%
  Generalization Bounds, Markov Algorithms, Poissonization, Log-Sobolev Inequalities.%
\end{keywords}

\section{Introduction}
\label{sec:introduction}

%\maxime{What we do: Extend the machinery that works well for continuous-time algorithms to any discrete Markov algorithm. In particular, we have bounds on a weighted trajectory of SGD without approximating SGD by SGLD (with Gaussian or Levy noise)}
Understanding the generalization ability of machine learning algorithms remains a crucial challenge.
% as we have little understanding of deep learning models in overparametrized settings with many more parameters than training data.
We model such learning problems by a tuple $(\ell, \zcal, \mu_z, \mathcal{H})$ where $\mathcal{H}$ is a parameter space ($\mathcal{H}=\Rd$ in our study), $\zcal$ is a data space, $\mu_z$ a data distribution and $\ell : \mathcal{H} \times \zcal \to \R$ is a loss function. 
The aim is to minimize the \emph{population risk} $\risk(w) := \Eof[z \sim \mu_z]{\ell(w,z)}$ over the parameter space $\mathcal{H}$. Unfortunately, as $\mu_z$ is unknown, practitioners resort to the minimization of the \emph{empirical risk} $\er(w) = \frac1{n} \sum_{i=1}^n \ell(w,z_i)$, where $S := (z_1,\dots,z_n)\sim\datadist$ is a dataset sampled from $\mu_z$.

Modern machine learning systems achieve this minimization through the use of \emph{stochastic optimization algorithms}. In our study, we focus on iterative algorithms with a Markov chain structure: $X_{k+1}^S = F(X_k^S, U_{k}, S)$ where $S\in\zcal^n$ and $U_k$ denotes the external randomness of the algorithm, independent of $S$. This encompasses many popular algorithms, including stochastic gradient descent (SGD) with constant step size \citep{dieuleveut_bridging_2018} and stochastic gradient Langevin dynamics (SGLD) (see \citep{camuto_fractal_2021,hodgkinson2022generalizationboundsusinglower} for a more detailed list). 
To assess the learning quality beyond $S$, it is classical to provide \emph{generalization bounds} on the learned parameter $X_k^S$, \ie upper bounds on the quantity $G_S(X_k^S)$ where $G_S(w) := \risk(w) - \er(w)$. 
To provide computable guarantees, a popular approach is to derive high probability bounds of the form\footnote{We use $\lesssim$ for informal statements omitting absolute constants or weakly relevant terms.}:
% Generalization bounds are a popular tool to grasp the generalization phenomenon.
% To make these bounds empirical, the high-probability approach is often considered. 
% These bounds take the following form: for a learning problem defined by a tuple $(\mathcal{H},\mathcal{Z}, S,\ell)$ where $\mathcal{H}$ is the predictor space, $\mathcal{Z}$ the data space, $S\in\mathcal{Z}^n\sim\datadist$ the \emph{i.i.d.} training set and $\ell:\mathcal{H}\times\mathcal{Z}\rightarrow \mathbb{R}$ the loss modelizing the learning problem, we have, with probability at least $1-\zeta$ over $S\sim\datadist$,
% \ben{introduce the algorithm here, and they we want a bound on ...}
\begin{align}
    \label{eq:informal-high-probability-bound}
     \Pof[S\sim\datadist]{\Eof{G_S(X_k^S)|S} \lesssim \sqrt{\frac{\texttt{Complexity} + \log(1/\zeta)}{n}}} \geq 1 - \zeta,
\end{align}
% where $G_S(w) := \risk(w) - \er(w)$ is the \emph{generalization gap} with $\risk(w):= \Eof{\ell(w,z)}$ and $\er(w)= \frac{1}{n}\sum_{i=1}^n\ell(w,z_i$.
where the term \texttt{Complexity} translates a certain facet of the learning problem, for instance, the Rademacher complexity \citep{bartlett2002rademacher} or the VC dimension \citep{vapnik2000learning}.

\paragraph{Generalization bounds for iterative algorithms.} 
% Unfortunately, these approaches do to not fully exploit the structure of the learning algorithm.
The classical algorithm- and data-independent approaches cannot fully exploit the problem structure. 
Thus, other techniques have been proposed, such as algorithmic stability \citep{bousquet_stability_2002}, yielding generalization bounds for SGD under certain assumptions on the loss (convexity, Lipschitz, and/or Lipschitz gradient) \citep{hardt_train_2016,feldman_high_2019}. Unfortunately, these bounds might not be time-uniform in non-convex settings with constant step size \citep{bassily_stability_2020}.  
Recently, \citet{zhu_uniform--time_2023-1} proved Wasserstein stability bounds by relying on the Markov properties of SGD.
This iterative structure was also exploited by \citet{camuto_fractal_2021,hodgkinson2022generalizationboundsusinglower,andreeva_topological_2024} through geometric properties, at the cost of having non-explicit mutual information terms in the bounds.
% This argument was extended to Wasserstein stability \citep{farghly_time-independent_2021}, notably by exploiting the Markov properties of SGD \citep{zhu_uniform--time_2023-1}.
% \citet{hodgkinson2022generalizationboundsusinglower,camuto_fractal_2021,andreeva_topological_2024} also exploited the iterative or Markov structure of such algorithms through statistical and geometric properties, at the cost of non-explicit mutual information terms.
Another prospect is that of information-theoretic bounds, which provided \emph{expected} bounds for noisy algorithms (\eg, SGLD) \citep{xu_information-theoretic_2017,negrea_information-theoretic_2020,haghifam_sharpened_2020} and have been extended to SGD by \citet{neu_information-theoretic_2021} at the expense of potential time and dimension-dependence.

Of particular interest to us are PAC-Bayesian bounds \citep{mcallester_pac-bayesian_1999,catoni_pac-bayesian_2007} where the term \texttt{Complexity} in \Cref{eq:informal-high-probability-bound} is typically expressed as $\klb{\law(X_k^S)}{\pi}$, where $\pi$ is a data-independent `prior' distribution, $\law(X_k^S)$ is called the `posterior' distribution and $\klb{\cdot}{\cdot}$ is the Kullback-Leibler divergence (KL). In particular, \citet{clerico_generalisation_2023} proved PAC-Bayesian bounds which can handle even deterministic algorithms as well as SGD under gradient-Lipschitz losses and small learning rate, but with a potentially diverging dependence on the number of iterations.

% \maxime{
% These generic techniques are an adequate starting point to derive localized results for specific algorithms, such as SGD.

% A natural start is to focus on the celebrated Stochastic Gradient Descent (SGD). A possible route lies in the PAC-Bayes framework, where $\mathrm{Q},\mathrm{P}$, distributions over $\mathcal{H}$ are considered and $\texttt{Complexity} = \klb{\mathrm{Q}}{\mathrm{P}}$ is the \emph{Kullback-Leibler (KL) divergence} \ben{use $Law(X_k)$}. For judicious choices of $\mathrm{Q};\mathrm{P}$, several work have been able to control the KL term and provide generalisation bounds: \citet{neu_information-theoretic_2021} obtained result at the cost of the dimension, which does not fit the overparametrized setting and \citet{clerico_generalisation_2023} obtained results for gradient-lipschitz losses. Another strategy consists in designing a class of algorithms satisfying a common desirable property, deriving bounds with respect to it and then recovering results for a single algorithm as a particular case. A famous example of this lies in  the class of \emph{algorithmic stable} algorithms, \citep{bousquet_stability_2002,bousquet_sharper_2020} \maxime{TODO other refs} encompassing the case of SGD when the loss function satisfies assumptions such as (strong) convexity, lipschitzness,gradient-lipschitzness \citep{hardt_train_2016}. 
% }

% \paragraph{Generalization from continuous-time analysis.}

% \ben{for SGD, there are approximations such as SGLD}

% \ben{try to not only motivate with SGD. Say there is these techniques for SGD but (1) we don't know the quality of the approximation and (2) we want to go beyond SGD. No algorithm-specific formulation of the approximation}

% \ben{say sth about time homogeneity, \ie, fixed learning rate from SGD, but it is the case of a lot of papers [cite...]. We make the analysis more general for constant step size.}

\paragraph{Continuous-time analysis.} 
% The empirical study of \citet{tran2024empirical} recently showed that assumptions such as convexity or gradient-lipschitz continuity may not fit the case of deep neural networks. 
Another popular route is to analyze the generalization error of `continuous-time algorithms' $(Y_t^S)_{t\geq 0}$, typically represented by stochastic differential equations (SDE), for their structure is often easier to understand (\eg, existence of a Fokker-Planck equation) and they may provide insights for discrete-time algorithms.
% Another popular route, allowing to avoid such assumptions, is the analysis of continuous-time algorithms $(Y_t^S)_{t\in \R}$ \ben{This is not true, most continuous-time papers have these assumptions}.
Indeed, for specific noise distributions, continuous-time analysis can be used to derive bounds on the discrete-time counterparts \citep{mou_generalization_2017,dupuis_generalization_2024} and continuous-time algorithms are often viewed as approximations of discrete ones. 
A fundamental example is SGD, approximated by Langevin processes \citep{li_stochastic_2018,cheng_stochastic_2020,li_validity_2021,arous2023highdimensionallimittheoremssgd,mandt_variational_2016,anastasiou2019normalapproximationstochasticgradient,xie2021diffusiontheorydeeplearning} and heavy-tailed SDEs \citep{simsekli_tail-index_2019,gurbuzbalaban2020heavy,raj2023algorithmic2,raj2023algorithmic}.

% Such noisy versions of SGD, such as stochastic Gradient Langevin Dynamics (SGLD) or heavy-tailed SGD have also been studied for their capacity to escape local minima \citep{raginsky_non-convex_2017} or in connexion with differential privacy \citep{ryffel_differential_2022,simsekli_differential_2024}.

Among these continuous-time algorithms, the generalization error of the continuous Langevin dynamics (CLD) (and its discrete-time counterpart SGLD) has been widely studied through a variety of approaches \citep{raginsky_non-convex_2017,farghly_time-independent_2021,dupuis_uniform_2024}.
% The generalization error of SGLD has been widely understood through the consideration of its continuous-time counterpart, namely the continuous Langevin Dynamics (CLD) \citep{farghly_time-independent_2021,raginsky_non-convex_2017}.
Several methods rely on PAC-Bayesian theory and information-theoretic tools \citep{mou_generalization_2017,li_generalization_2020,futami_time-independent_2023} where the goal is typically to upper bound the KL divergence $\klb{\law(Y_T^S)}{\pi_T}$, where $\pi_T$ is a potentially time-dependent prior distribution. These techniques often rely on the so-called (relative) \emph{entropy flow}, which has proven very useful in numerous settings:
    \begin{align}
        \label{eq:informal-entropy-flow-sgld}
        \frac{\der}{\der t} \klb{\law(Y_t^S)}{\pi_t} = \left( F_1 - J \right) \leq \left( F_2 - \gamma \klb{\law(Y_t^S)}{\pi_t} \right),
    \end{align}
    where $F_1$ and $F_2$ are quantities usually dependent on the stochastic gradient norms, $J$ is a Fisher information term \citep{chafai_logarithmic_2017} and the inequality above is a consequence of the celebrated logarithmic Sobolev inequality (LSI) \citep{gross_logarithmic_1975-1,bakry_analysis_2014}. When combined with classical information-theoretic bounds \citep{germain_pac-bayesian_2009,pensia_generalization_2018}, \Cref{eq:informal-entropy-flow-sgld} leads to time-uniform generalization bounds. This entropy flow technique was recently extended to $\alpha$-stable noise by \citet{dupuis_generalization_2024} and has been adapted to analyze the differential privacy of noisy algorithms \citep{chourasia_differential_2022}.
    One of its advantages is to open the door to time-uniform bounds through a more flexible set of assumptions, compared to other approaches mentioned above.
    % to rely on more flexible assumptions compared to other approaches mentioned above.
    
    Despite its success, this approach remains essentially limited to Gaussian (or $\alpha$-stable) noises.
    In particular, the interpolation techniques used by \citet{mou_generalization_2017,dupuis_generalization_2024} to deduce discrete-time bounds from continuous-time analysis rely on this noise structure. 
    % , which prevents its use for different noising schemes or non-noisy algorithms.
    Moreover, the approximation of discrete-time optimizers by continuous-time dynamics remains largely disputed \citep{li_validity_2021,wojtowytsch2021stochasticgradientdescentnoise} and restricted to rather unrealistic settings, like small learning rates \citep{li_stochastic_2018} or high-dimensional limits \citep{ben-arous_high_dimensional_2022}.
    % \maxime{Then, what motivates the use of continuous-time processes as approximations for non-noisy algorithms ? The question remains largely disputed, and while empirical elements of answer arose for small step-size for CLD \citep{li_validity_2021} or large step-size for heavy-tailed SDEs \citep{simsekli_tail-index_2019}, there remains a lack of theoretical justifications. \ben{Maybe replace these refs by those showing it does not work \citep{li_validity_2021} what other refs?}}
    %Moreover, the quality of the approximation of practically used algorithms though continuous-time SDEs remains largely disputed and is typically valid for small step-size for CLD \citep{li_validity_2021} or large step-size for heavy-tailed SDEs \citep{simsekli_tail-index_2019}. \ben{improve, they lack rigorous approximation}

    % \ben{these approaches lack rigorous approximation.
    % We are going continuous-time with a more rigorous approximation: geometric / invariant lemma and studying this approximation is well-studied, and it is the same approximation for every algorithm. }


% Also,

    \paragraph{Extending the scope of continuous-time analysis.}In this work, we aim to alleviate these issues and extend the entropy flow technique by utilizing a new class of continuous approximations of discrete-time Markov algorithms\footnote{Such a focus on Markov algorithms is not new in the generalization field \citep{camuto_fractal_2021,hodgkinson2022generalizationboundsusinglower,chandramoorthy_generalization_2022,zhu_uniform--time_2023-1}.} with formal approximation guarantees, which we now describe.
    % We focus on Markov algorithms, \ie, iterative dynamics of the form $X_{k+1}^S = F(X_k^S, U_k, S)$, where $U_k$ denotes the external randomness of the algorithm. 
    For a given Markov algorithm $X_{k+1}^S = F(X_k^S, U_k, S)$, we define the \emph{Poissonization} of $(X_k^S)_{k\in\N}$ as the continuous-time process $Y_t^S := X^S_{N_t}$, where $N_t$ is a Poisson process \citep{lasota_chaos_1994} (see \Cref{def:poisson-process}) . 
     %We call $(Y_t^S)_{t\in\R_+}$ the \emph{Poissonization} of $(X_k^S)_{k\in\N}$. 
    This technique has been classically used in the analysis of the convergence of Markov chains \citep{diaconis_logarithmic_1996,chen_logarithmic_2008,caputo_entropy_2024,del_moral_contraction_2003,wang_transport-information_2020}, notably by relying on modified versions of LSIs. Moreover, contrary to all continuous-time approximations of discrete-time algorithms, Poissonization is not problem-specific, meaning that it can be applied similarly to all Markov algorithms.
     % 
    Recently, Poissonization\footnote{It is called \emph{continuization} by \citet{even_continuized_2021} and \emph{continuous-time semigroup} by \citet{diaconis_logarithmic_1996}.
    % The name \emph{continuization} is used by \citep{even_continuized_2021}. Other names are found in the literature \citep{diaconis_logarithmic_1996}.
    }
    emerged in optimization theory in \cite{even_continuized_2021} to study Nesterov acceleration. 
    
    A major innovation in our work is to connect Poissonization with the theory of generalization and thus, unveiling new links between generalization and convergence of Markov algorithms. 
    Through an elegant formulation of the entropy flow, Poissonization acts as a tractable method to leverage the continuous-time machinery to analyze discrete-time algorithms.
    
  
  % , and it does not change the noise structure of the initial dynamics, while, for instance, Gaussian noise is often used in continuous approximations of SGD \citep{mandt_variational_2016}.

    
    
     
    %We demonstrate that Poissonization greatly simplifies the problem structure, at the cost of replacing $(X_k^S)_{k\in\N}$ by $(Y_t^S)_{t\in\R_+}$, \ie, we bound the \emph{Poissonized generalization error} $\Eof{G_S(Y_t^S) \vert S}$. 
    %However, we argue that this is a reasonable simplification of the problem for several reasons.
    %First, the matter of reconstructing the initial sequence from its Poissonization is a well-studied (yet, highly technical) problem \citep{jacquet_analytical_1998,vallee_depoissonisation_2018} (see \Cref{sec:depoissonization}). We further provide rigorous approximation lemmas for ergodic processes.
    %Second, contrary to all continuous-time approximations of discrete-time algorithms, Poissonization is not problem-specific, meaning that it can be applied seamlessly to any learning algorithm.   
    %The limitation of this approach is to restrict our analysis to Markov algorithms. Note however that this condition has been largely used for generalization bounds \citep{camuto_fractal_2021,hodgkinson2022generalizationboundsusinglower,chandramoorthy_generalization_2022,zhu_uniform--time_2023-1}. Our approach has the advantage to be general across all Markov algorithms.
    
    
    % \ben{define Poissonization $Y_t^S = X_{N_t}^S$, where $N_t$ is a Poisson process, definition given in ...} 
    % This includes all versions of SGD or noisy SGD with a constant learning rate or other popular algorithms such as RPROP \citep{rprop}. 
    % More precisely, to keep away from the discrete structure of MAs, we restrict the analysis to the so-called ``Poissonization'' of these algorithms. 
    
    % Poissonization consists of defining a continuous-time process naturally associated with a discrete process. 

    % \ben{Put more emphasis on convergence. Here we make a new link between convergence and generalization. Maybe cite \citep{chandramoorthy_generalization_2022} and \citep{camuto_fractal_2021}}

    % \ben{mention $Y_t^S$, use $Law(Y_t^S)$, and use it in the contributions}

    % \ben{We want a gen bound on $Y_t^S$}

    \paragraph{Contributions.} We summarize our contributions as follows:
    % \ben{maybe merge the first two items together and present it as a framework.}
    \begin{enumerate}[noitemsep]
     \item We propose in \Cref{sec:poissonization-entropy-flow} a framework to analyze the generalization error of Poissonized Markov algorithms by \textit{(i)} deriving a closed-form expression of the associated entropy flow and \textit{(ii)} showing that the Poissonized generalization error is a sound approximation in certain cases.
        % \item \ben{We show that when $X_k$ is converging ,... Geometric ergodicity, which has been a long-standing topic for SGD, we reduce the approximation error to CV in TV, say it is a sufficient condition. We then directly focus on $G_S(Y_t^S)$}
        % \item We derive a close-form expression of the entropy flow of Poissonized Markov algorithms. Our formula has the form of a difference of two terms, \ie, $\frac{\der}{\der t} K(t) = \Delta (t) - D_\Phi(t)$, and yields a formal similarity with the case of CLD.
         % \item We show that (\Cref{prop:poissonization-invariant-measure-convergence}) if the algorithm $(X_k^S)_{k\in\N}$ is convergent in either total variation or Wasserstein distances (as $k\to\infty$), the generalization error $G_S(Y_k^S)$ induced the Poissonized process (at time $t=k$) will become close to $G_S(X_k^S)$ at a rate matching the convergence of $(X_k^S)_{k\in\N}$.      
         % This complements the existing literature on ``depoissonization'' (see \Cref{sec:technical-background,sec:depoissonization}) to show that Poissonized generalization bounds can be informative in numerous cases (even outside of the particular setting of \Cref{prop:poissonization-invariant-measure-convergence}).
         \item We show that if the algorithm $(X_k^S)_{k\in\N}$ is convergent as $k\to\infty$, the Poissonized generalization error $G_S(Y_k^S)$ (at time $t=k$) will coincide with $G_S(X_k^S)$ at a rate matching the convergence of $(X_k^S)_{k\in\N}$.      
         In addition to the existing literature on ``depoissonization'', which suggests that Poissonized generalization bounds can be informative in numerous cases, our result provides an alternative sufficient condition, which further highlights this fact.  
         
         % to show that Poissonized generalization bounds can be informative in numerous cases (even outside of the particular setting of \Cref{prop:poissonization-invariant-measure-convergence}).
         
         % this substantiates the study of Poissonized generalization bounds, even in more general cases.
         % i.e., $|G_S(X_k^S) - G_S(Y_k^S)| \to 0$ as $k \to \infty$, and the rate of this convergence depends on how fast $(X_k^S)_{k\in\N}$ converges to a (not necessarily unique) invariant distribution. 
         % \item We show that (\Cref{prop:poissonization-invariant-measure-convergence}) if the original algorithm $(X_k^S)_{k\in\N}$ is convergent in either total variation or Wasserstein distances (as $k$ tends to infinity), the generalization error induced by the Poissonized process $(Y_t^S)_{t\geq 0}$ will closely match the one of $(X_k^S)_{k\in\N}$: i.e., $|G_S(X_k^S) - G_S(Y_k^S)| \to 0$ as $k \to \infty$, and the rate of this convergence depends on how fast $(X_k^S)_{k\in\N}$ converges to a (not necessarily unique) invariant distribution. 
        \item Our entropy flow formula is formally similar to the previously studied \Cref{eq:informal-entropy-flow-sgld} and can be written as $\frac{\der}{\der t} \klb{\law(Y_t^S)}{\pi_t} = \Delta(t) - D_\Phi(t)$, where the first term $\Delta(t)$ is a new notion of `local distance' between a prior and a posterior dynamics.
        % It is formally similar to \Cref{eq:informal-entropy-flow-sgld}.
        % \begin{align*}
        %     \frac{\der}{\der t} \klb{\law(Y_t^S)}{\pi_t} = \Delta(t) - D_\Phi(t).
        % \end{align*}   
        We unveil the structure of the entropy flow in \Cref{sec:poisson-sobolev} by showing that the second term $D_\Phi(t)$ is connected to a class of modified LSIs that have been initially introduced for the convergence analysis of discrete Markov chains. We further prove that these modified LSIs can lead to time-uniform bounds and are satisfied by a certain class of probability distributions.
        % which is of great importance for our study. 
        \item In \Cref{sec:applications}, we apply our methods to two types of Markov algorithms, given that the noise distribution is continuous (\eg, SGLD) or singular (\eg, SGD). This allows us to recover known results and propose new generalization bounds under specific assumptions. 
        % \item We push the analysis of the entropy flow for noisy algorithms and non-noisy algorithms. For noisy algorithms, we provide general results (valid for any noising scheme) and in particular recover existing generalization bounds for SGLD. We then apply our framework to non-noisy algorithms (especially SGD) and derive new generalization bounds under specific assumptions.
    \end{enumerate}


% Stochastic optimization algorithms are at the heart of modern machine learning. In a supervised learning setup, they aim at solving the following population risk minimization,
% \begin{align*}
%     \min_{w\in\Rd} \setof{\risk(w):= \Eof[z \sim \mu_z]{\ell(w,z)}},
% \end{align*}
% where $\ell : \Rd \times \zcal \longrightarrow \R_+$ is a loss function acting on a parameter space $w\in\Rd$ and a data space $\zcal$ and $\mu_z$ is a probability distribution on the data space. This data distribution is unknown in practice but one usually has access to a dataset $S := (z_1,\dots,z_n) \sim \datadist$ sampled \iid from the data distribution. For this reason, the quantity that is being minimized in practice is the following empirical risk:
% \begin{align*}
%     \er (w) := \frac{1}{n} \sum_{i=1}^n \ell (w, z_i).
% \end{align*}
% The minimization of the empirical risk is usually achieved by randomized iterative learning algorithms

% Because of the difference between the population and empirical risks, it is crucial to provide \textit{generalization bounds}, \ie, upper bounds on the generalization error $G_S(w) := \risk(w) - \er (w)$, where $w$ is the output of the learning algorithm.


% \ben{
%   \begin{itemize}
%     \item Present SGD
%     \item Noisy SGD has been analyzed in place of SGD through the entropy flow method
%     \item PAC-Bayes + Entropy flow technique + it has also been used for differential privacy.
%     \item The entropy flow is unfortunately limited to certain classes of algorithms (Fokker-Planck equation)
%     \item We bridge this gap by introducing Poissonization and extending the entropy flow technique to all Markov algorithms. Quickly define Markov algorithms.
%     \item Insist on the fact that we introduce a framework for analyzing the generalization error of Markov algorithms.
%     \item We extend the machinery that works well for continuous-time algorithms to any discrete Markov algorithm. In particular, we have bounds on a weighted trajectory of SGD without approximating SGD by SGLD (with Gaussian or Levy noise)
%   \end{itemize}
%   Related works: stability, ...
% }


% \ben{Potentially, this is included in the beginning of the introduction}

% \ben{Stability, PAC-Bayes, ... In particular mention \citep{clerico_generalisation_2023,neu_information-theoretic_2021}}


% \subsection{Contributions}
% \label{sec:contributions}


% \ben{To be reformulated}

% We summarize our contributions as follows.

% \begin{itemize}
%     \item We derive a closed-form expression of the relative entropy flow between Poissonized processes. Our result can be expressed as:
%     \begin{align*}
%         \frac{\der}{\der t} \mathrm{KL}(t) = \Delta(t) - D_\Phi(t),
%     \end{align*}
%     where $\mathrm{BI}(t) \geq 0$ will be referred to as the ``Bregman integral'' and $\Delta_{P,P_S}(v_t)$ is the ``expansion'' term and can be understood as measuring the distance between the Markov kernels $P_S$ and $P$. The notation $v_t$ refers to the Radon-Nykodym derivative $\der \rho_t^S / \der \pi_t$.
%     \item We unveil the structure of the Bregman integral term and show that it is related to a class of (modified) logarithmic Sobolev inequalities (LSI) classically connected to discrete-time Markov processes \citep{diaconis_logarithmic_1996}.
%     These inequalities have the form $BI(t) \geq \gamma \klb{\rho_t^S}{\pi_t}$ and may provide time-uniform generalization bounds, as soon as the expansion term can be appropriately bounded.
%     % We show that such inequalities, which we call Poisson-Sobolev inequalities (PSI) imply generalization bounds of the following form:
%     % \begin{align*}
%     %     \Eof[w\sim\rho_T^S]{G_S(w)} \lesssim \sqrt{\int_0^T e^{-\gamma (T - t)}  |\Delta_t (P,P_S)| \der t},
%     % \end{align*}
%     % with $\gamma > 0$ a parameter appearing in the PSI inequality. We show that Gaussian priors satisfy PSI, which is new to the best of our knowledge.
%     \item To achieve such bounds, we specify our framework in two particular contexts. First, in the case of noisy algorithms, we further upper bound the entropy flow and recover known results for stochastic gradient Langevin dynamics (SGLD) \citep{mou_generalization_2017}. 
%     \item For non-noisy algorithms, we show that under certain regularity assumptions, the expansion term can be related to ``local'' Wasserstein distances $W_2(\delta_x P, \delta_x P_S)$. Finally, under strengthened assumptions, we extend our methods to prove generalization bounds for regularized SGD.
%     % of the form:
%     % \begin{align*}
%     %   \Eof[w\sim\rho_T^S]{G_S(w)} \lesssim \sqrt{\int_0^T e^{-\lambda \eta (T - t)}  \Eof[\rho_t^S]{\normof{\nabla \er}^2} \der t + \landau{\eta^2} },
%     % \end{align*}
%     % where $\eta > 0$ is the learning rate and $\lambda > 0$ the $\ell^2$-regularization coefficient.
% \end{itemize}


\section{Technical Background}
\label{sec:technical-background}

% \subsection{Markov kernels}
% \label{sec:markov-processes}

% Given some topological space $X$, the Borel sets of $X$ are denoted $\bcal(X)$. The set of Borel probability measures on $X$ will be denoted $\pcal(X)$.
\paragraph{Markov kernels.} Let $\borel$ and $\probameasures$ denote the Borel sets and the Borel probability measures on $\Rd$.
Given a time-homogeneous Markov process $(X_k)_{k\in\N}$ in $\Rd$, the \emph{Markov kernel} $P(x, A)$ describes the probability of observing $X_{k+1}$ in a Borel set $A$, given that $X_k = x$. 
More precisely, it is a map $P: \Rd \times \bcal(\Rd) \to \R_+$ such that $\forall x \in \Rd, ~ P(x,\cdot) \in \probameasures$ and for all $A \in \borel$, the map $x \mapsto P(x,A)$ is measurable.
% \begin{definition}[Markov kernel]
%     \label{def:markov-kernel}
%     A Markov kernel on $\Rd$ is a map $P: \Rd \times \bcal(\Rd) \longrightarrow \R_+$ s.t.
%     \begin{enumerate}[noitemsep]
%         \item For all $x \in \Rd$, $P(x,\cdot)$ is a Borel probability measure.
%         \item For all $A \in \borel$, the map $x \longmapsto P(x,A)$ is measurable.
%     \end{enumerate}
% \end{definition}
Classically $P$ induces maps $P : \probameasures \to \probameasures$ and $P : L^\infty (\Rd) \to L^\infty (\Rd)$ defined for $\mu \in \probameasures, ~ A \in \borel$ and $f \in L^\infty (\Rd)$ by:
\begin{align*}
    \mu P (A) := \Eof[x\sim\mu]{P(x,A)}, \quad Pf (x) := \Eof[y\sim P(x,\cdot)]{f(y)}.
\end{align*}
The operator $P : L^\infty (\Rd) \to L^\infty (\Rd)$ may be extended outside of $L^\infty (\Rd)$, when it is well-defined.
    
A probability measure $\pi$ is said to be \emph{invariant} under $P$ (or stationary) if $\pi P = \pi$ and it is said to be \emph{reversible} if for all $f,g \in L^\infty (\Rd) $, one has $\Eof[\pi]{fPg} = \Eof[\pi]{gPf}$.

Let $\mu \in \bcal(\Rd)$ having density $u$ with respect to the Lebesgue measure $\mathrm{Leb}(\Rd)$. If also $P\mu \ll \mathrm{Leb}(\Rd)$, we will denote its density by $P^\star u$, so that for $f\in L^1(\mu P)$, we have:
    \begin{align}
        \label{eq:ipp-markov-operator}
        \int Pf(x) u(x) \der x = \int f(x) P^\star u(x) dx.
    \end{align}

% In the sequel, we will use repeatedly the notations introduced in the following definition.
% \begin{definition}[Adjoint]
%     \label{def:adjoint-l2-dx}
%     Let $\mu \in \bcal(\Rd)$ having density $u$ \wrt the Lebesgue measure $\mathrm{Leb}(\Rd)$. If also $P\mu \ll \mathrm{Leb}(\Rd)$, we will denote its density by $P^\star u$, so that for $f\in L^1(\mu P)$, we have:
%     \begin{align}
%         \label{eq:ipp-markov-operator}
%         \int Pf(x) u(x) \der x = \int f(x) P^\star u(x) dx.
%     \end{align}
% \end{definition}

% \begin{remark}
%     In our paper, we assume that $P^\star$ exists for the Markov processes we consider (see \Cref{ass:phi-regularity}). 
%     While this simplifies some technical aspects, it should be noted that some of our findings, namely \Cref{thm:poissonized_entropy_flow}, remain true without this absolute continuity. Finally, let us highlight that $P^\star$ may be seen as an adjoint of $P$ in $L^2(\der x)$, whenever Riesz theorem is applicable.
% \end{remark}

% \begin{example}[SGD]
%     \ben{TODO}
% \end{example}



% \subsection{Poissonization}
% \label{sec:poissonization-technical-background}

\paragraph{Poissonization.} In all the following, we fix a Poisson process $(N_t)_{t\geq 1}$ with intensity $1$, as defined below \citep{lasota_chaos_1994}. It is assumed to be independent of all the other random variables.
% Let us first recall the definition of a Poisson process \citep{lasota_chaos_1994}.
% \maxime{We could save space by removing the definition environment for Poisson processes}
\begin{definition}[Poisson process]
    \label{def:poisson-process}
    A Poisson process $(N_t)_{t\geq 0}$ with intensity $\lambda > 0$ is a Lévy process with values in $\mathds{N}$, almost surely increasing, such that $N_0=0$ and $ \forall k \in \mathds{N}, ~ \Pof{N_t=k} = e^{-\lambda t} \frac{(\lambda t)^k}{k!}$.
    % \begin{align*}
    %    \forall k \in \mathds{N}, ~ \Pof{N_t=k} = e^{-\lambda t} \frac{(\lambda t)^k}{k!}.
    % \end{align*}
\end{definition}
% In all the following, we fix such a Poisson process with intensity $\lambda = 1$, which is assumed to be independent of all the other random variables.
We refer to \citep{schilling_introduction_2016} for the definition of a Lévy process.
Given a time-homogeneous Markov process $(X_k)_{k \in \mathds{N}}$, we define the \emph{Poissonized process} as $Y_t := X_{N_t}$ \citep{teugels_note_1972,lasota_chaos_1994}. Note that equivalent definitions of Poissonization exist. For instance, \citet{even_continuized_2021} used a stochastic integral formulation in their study of Nesterov acceleration and other authors favored an approach based on semigroups \citep{diaconis_logarithmic_1996}.
% Poissonization has been classically used in the analysis of the convergence of Markov chains \citep{diaconis_logarithmic_1996,chen_logarithmic_2008,caputo_entropy_2024,del_moral_contraction_2003,wang_transport-information_2020}. In the context of learning theory, it has been considered by \citet{even_continuized_2021} in their study of continuized Nesterov acceleration.
% \begin{align}
%     \label{eq:poissonized_process}
%     Y_t := X_{N_t}.
% \end{align}
One of the main features of Poissonized processes is that their probability density function (PDF) $u_t(\cdot)$ satisfies a simple differential equation, sometimes referred to as the ``Boltzmann equation'' \citet[Equation $8.3.7$]{lasota_chaos_1994}. This equation can be written as (a rigorous proof is provided in \Cref{sec:proofs-technical-background}):
\begin{align}
    \label{eq:poisson-boltzmann}
        \frac{\partial u_t}{\partial t} = (P^{\star} - I) u_t.
\end{align}
% where $u_t(x) = u(t,x)$ denotes the PDF of the Poissonized process $Y_t$ and the notation $P^\star$ has been introduced in \Cref{def:adjoint-l2-dx}. We provide in \Cref{sec:proofs-technical-background} a rigorous proof of this result.
% In order to rigorously state this equation, we define the following assumption.

% \begin{assumption}[Local growth]
%     \label{ass:local-growth-assumption}
%     $X_k$ has a PDF $p_k$ and $\forall x \in \Rd,~ \exists c_x > 0, ~p_k (x) = \landau[k\to\infty]{k^{c_x}}$.   
%     % Let $p_k$ be the density of $X_k$ with respect to the Lebesgue measure. We say that $(X_k)$ satisfies the local growth assumption if for every $x \in \Rd$, there exists $c_x>0$, such that $p_k (x) = \landau[k\to\infty]{k^{c_x}}$ (the constant in $\mathcal{O}$ may also depend on $x$, hence the term ``local'').
% \end{assumption}

% \ben{I think this assumption is actually not necessary, as it th case in \citep{lasota_chaos_1994}, I'm updating the appendix to check that we can remove it}

% In words, we ask that densities to grow at most polynomially with the number of iterations $k$. This is a relatively mild assumptions, and we assume it for all considered Markov chains in this work.

% With these notations, we have the following proposition (inspired from \citep[Equation $8.3.7$]{lasota_chaos_1994}), which gives a partial differential equation satisfied by the density of the Poissonized process $Y_t$.
% We can now give the Boltzman equation for the Poissonized process.

% The proof is referred to \Cref{sec:proofs-technical-background}. As part of \Cref{ass:local-growth-assumption}, we assumed that the law of $X_k$ is absolutely continuous with respect to the Lebesgue measure.
% \ben{It is actually possible to avoid assuming that $P$ preserves the absolute continuity by writing \Cref{eq:poisson-boltzmann} in a weak form, as formalized by \Cref{rq:poisson-boltzmann-weak-form}. We assume the existence of PDFs for the sake of clarity.}

\paragraph{Depoissonization.} 
% The question of recovering the original process from its Poissonization is a legitimate concern.
A discrete-time Markov chain and its Poissonized version are known to have comparable properties \citep{jacquet_analytical_1998,levin_markov_2017,caputo_entropy_2024}. That being said, reconstructing the depoissonized distribution of $X_k$ from $Y_t$ is a technical and long-standing problem \citep{teugels_note_1972,vallee_depoissonisation_2018,jacquet_analytical_1998} for which we give a quick introduction in \Cref{sec:depoissonization}. In \Cref{prop:poissonization-invariant-measure-convergence} below, we further show that Poissonization provides a sound approximation of the generalization error of convergent Markov algorithms.

% \subsection{PAC-Bayesian bounds}

% \maxime{Should we put this in the appendix? Given there is almost no proof in the main, I am wondering about the relevance of detailing PAC-Bayes here. } \ben{I think it should be here but short}
\paragraph{PAC-Bayesian bounds.} Analyzing the generalization error of stochastic optimization algorithms leads to the consideration of randomized predictors, which have been classically studied by PAC-Bayesian theory (see \citep{alquier2024user} for an introduction). More precisely, given $S\in\zcal^n$, we define the posterior $\rho_S \in \probameasures$ to be the distribution\footnote{More precisely, $(\rho_S)_{S\in\zcal^n}$ is a Markov kernel on $\zcal^n \times \Rd$.} of the random output of the algorithm (\eg, SGD). Given a prior (\ie, data-independent) distribution $\pi \in \probameasures$, a wide variety of PAC-Bayesian bounds have related the generalization error to the KL divergence $\klb{\rho_S}{\pi}$ \citep{mcallester_pac-bayesian_1999,mcallester_pac-bayesian_2003,maurer_note_2004,catoni_pac-bayesian_2007,germain_pac-bayesian_2009,seeger_pac-bayesian_2002} (to name a few). 

In our study, we assume that $\ell$ is $s^2$-subgaussian, \ie, $\forall \lambda,~ \Eof{e^{\lambda (\ell(w,z) - \Eof[z']{\ell(w,z')})}} \leq e^{\frac{\lambda^2 s^2}{2}}$.
% as defined by the following assumption.
% \begin{assumption}[Subgaussian loss]
%     \label{ass:subgaussian}
%     The loss $\ell(w,z)$ is $s^2$-subgaussian for $z\sim \mu_z$, \ie, for all $w\in\Rd$ we have $\forall \lambda \in \R, ~\Eof{e^{\lambda (\ell(w,z) - \Eof{\ell(w,z)})}} \leq e^{\frac{\lambda^2 s^2}{2}}$.
% \end{assumption}
To utilize this assumption, we use the PAC-bayesian bound proposed by \citet{dupuis_generalization_2024}, which is similar to that of \citet{mcallester_pac-bayesian_2003,germain_pac-bayesian_2009} in the case of bounded losses.
\begin{theorem}
\label{thm:subgaussian-pac-bayes}
    Assume that for all $S\in\zcal^n$, we have $\rho_S\ll \pi$ and that $\ell$ is $s^2$-subgaussian. Then:
    \begin{align*}
        \Pof[S\sim\datadist]{\Eof[\rho_S]{G_S(w)} \leq 2s \sqrt{\frac{\klb{\rho_S}{\pi} + \log(3/\zeta)}{n}}} \geq 1 - \zeta.
    \end{align*}
\end{theorem}



% \section{Main Results}

\section{Poissonized Markov Algorithms}
\label{sec:poissonization-entropy-flow}

In this section, we express the entropy flow between Poissonized processes, which underlies all our main results.
We introduce our framework in \Cref{sec:poissonization-notations-and-convergence} and derive the entropy flow in \Cref{sec:entropy-flow-subsection}.
% This finding, presented in \Cref{thm:poissonized_entropy_flow}, underlies all our main results.

\subsection{A framework for the Poissonization of generalization bounds}
\label{sec:poissonization-notations-and-convergence}

% As explained above, our approach is based on PAC-Bayesian theory, hence, we are required to define both a posterior and a prior distribution. We extend this concept by introducing the notions of posterior and prior dynamics, where the posterior dynamics is the (Markov) learning algorithm under examination and the prior is another data-independent dynamics.
In our paper, we apply PAC-Bayesian bounds on distributions that are induced by posterior dynamics (\ie, the learning algorithm) and prior dynamics (\ie, data-independent).
The precise definitions are given below and we provide a summary of these notations in \Cref{tab:notations}.
\begin{itemize}[noitemsep]
    \item \textbf{Posterior dynamics.} It is a \emph{data-dependent} time-homogeneus Markov process $(X_k^S)_{k \geq 0}$ with kernel denoted $P_S$ for a dataset $S\in \zcal^n$. The Poissonization (see \Cref{sec:technical-background}) of $(X_k^S)_{k \geq 0}$ is denoted $(Y_t^S)_{t \geq 0}$.  We will write $\rho_t^S$ for the probability distribution of $Y_t^S$ and $\mu_k^S$ for the probability distribution of $X_k^S$. The PDF of $Y_t^S$ is denoted $u_t^S(\cdot)$ (when it is defined). We assume that $(X_k^S)_{k \geq 0}$ is initialized from a smooth probability density $p_0$ and denote $X_0 \sim p_0$. 
    \item \textbf{Prior dynamics.} It is a \emph{data-independent} Markov process $(X_k)_{k\geq 0}$ with kernel $P$. We denote by $\mu_k$ the probability distribution of $X_k$. The prior Poissonized process is denoted $(Y_t)_{t\geq 0}$, its probability distribution is denoted $\pi_t$, and its PDF is denoted $u_t$. 
\end{itemize}
% Additionally, we use the notations $L_S := P_S - I$ and $L = P - I$, \maxime{can we avoid those notations? After a command Z, I remark that $L_S$ only appears sevent imes in the whole document} which corresponds to the infinitesimal generators of the Poissonized processes. 

We use the \emph{Poissonized} distributions $\rho_t^S$ and $\pi_t$ as the posterior and prior distributions in \Cref{thm:subgaussian-pac-bayes} to provide generalization bounds for the Poissonized algorithm, \ie, $\Eof[w\sim\rho_t^S]{G_S(w)}$.
Whether this provides pertinent information about the non-Poissonized iterates is a legitimate concern. Beyond the classical depoissonization results mentioned in \Cref{sec:technical-background,sec:depoissonization}, we show 
in \Cref{prop:poissonization-invariant-measure-convergence} 
that $\Eof[w\sim\rho_k^S]{G_S(w)}$ (with $t=k$) approximates $\Eof[w\sim\mu_k^S]{G_S(w)}$ for certain Markov processes. Below $\tv$ denotes the total variation distance and the proof can be found in \Cref{sec:proofs-entropy-flow}.

\begin{restatable}{theorem}{depoissonizationInvariant}
    \label{prop:poissonization-invariant-measure-convergence}
    % Let $X_k$ be a discrete-time-homogeneus Markov process and $(K_t)_{t\in\R_+}$ its Poissonized semigroup. 
    Assume that $|\ell| \leq B < \infty$ and that $\tv(\mu_k^S, \mu^S) \longrightarrow 0$ for some $\mu^S \in\probameasures$, \as for $S$.
    Then, \as, $\Eof{|G_S(X_k^S) - G_S(Y_k^S)| \big\vert S} \longrightarrow  0 $.
    % \begin{align*}
    %     \tv(\rho_t, \mu) \underset{t\to\infty}{\longrightarrow} 0,
    % \end{align*}
    % where $\rho_t$ is the distribution of $Y_t$. 
    If moreover there exists $C>0$ and $a_S \in (0,1)$ such that, \as, $\tv (\mu_k^S,\mu^S) \leq C_S a_S^k$, then, \as, $\Eof{|G_S(X_k^S) - G_S(Y_k^S)| \big\vert S} \leq 4B C_S e^{-(1 - a_S)k}$. 
    % $ \forall k \in \N,~ \tv(\rho_k, \mu_k) \leq 2C e^{-(1 - a) k}$. {\color{red} Similarly, if $\|\ell\|_\infty \leq B$, then $\mathbb{E}|G_S(X_k) - G_S(Y_k)| \leq 2BC e^{-(1 - a) k}  $. }
    % \begin{align*}
    %     \forall t > 0,~ \tv(\rho_t, \mu) \leq C e^{-(1 - a) t}.
    % \end{align*}
    If $\ell$ is $L$-Lipschitz, then we can replace $\tv$ by the $1$-Wasserstein distance $W_1$ (and $2B$ by $L$) in these statements, \eg, if $W_1 (\mu_k^S,\mu^S) \leq C_S a_S^k$, then $\Eof{|G_S(X_k^S) - G_S(Y_k^S)| \big\vert S} \leq 2L C_S e^{-(1 - a_S)k}$.
\end{restatable}

The conditions $\tv (\mu_k^S,\mu^S) \leq C_S a_S^k$ (resp. $W_1 (\mu_k^S,\mu^S) \leq C_S a_S^k$) used above are related to \emph{geometric} (resp. \emph{Wasserstein}) ergodicity \citep{meyn_markov_1993,gallegos_herrada_equivalences_2023} that has been widely studied in the context of convergence of Markov chains \citep{rudolf_perturbation_2017}. 
Note that, our condition is weaker than geometric ergodicity: we do not assume the uniqueness of the invariant distribution. 
These concepts have received growing attention in learning theory for their connections with SGD \citep{zhu_uniform--time_2023-1} and differential privacy \citep{simsekli_differential_2024}. While our study is not specific to ergodic Markov chains, \Cref{prop:poissonization-invariant-measure-convergence} provides a \emph{sufficient} condition for ensuring that Poissonization is a relevant continuous-time approximation of discrete dynamics.



\subsection{Poissonized entropy flow}
\label{sec:entropy-flow-subsection}

When it is defined, we denote $v_t$ for the Radon-Nykodym derivative between $\rho_t^S$ and $\pi_t$:
\begin{align*}
    v_t := \frac{u_t^S}{u_t} = \frac{\der \rho_t^S}{\der \pi_t} \quad \text{(we omit the dependence on $S\in\zcal^n$ in $v_t$)}.
\end{align*}
Our theory relies on regularity conditions on $v_t$, which we now explain. In all the following, we consider the convex function $\Phi(x) = x\log(x)$ (and $\Phi(0) = 0$). We also fix a time horizon $T>0$.

\begin{assumption}[Regularity]
    \label{ass:phi-regularity}
    Let $t\in[0,T]$ and $k\in\N$, we have $\ell \in L^1(\rho_t^S \otimes \mu_z)$.
    Moreover, $\mu_k,\mu_k^S \ll \mathrm{Leb}(\Rd)$, we have $\rho_t^S \ll \pi_t $, the function $v_t = \der \rho_t^S / \der \pi_t$ is positive, $v_t \in \mathcal{C}^2(\Rd)$, and:
    \begin{enumerate}[noitemsep,label=\textbf{H.\arabic*}]
        \item \label{ass:domination} (Domination)
        % $u_t, v_t$ are time-differentiable, 
        In every compact time interval $I$, there exists a positive function $\psi_I \in L^1(\der x)$ such that $\forall t\in I,~ \left| \frac{\der}{\der t} \left( u_t \Phi(v_t) \right) \right| \leq \psi_I$. 
        \item \label{ass:logarithmic-regularity} (Logarithmic regularity) For $x\in\Rd, ~t\in[0,T]$, we have $v_t \in L^1(\delta_x P)$, $P(\Phi(v_t)) \in L^1(\pi_t)$, and 
        $\log(v_t) \in L^1(\rho_t^S) \cap L^1(\rho_t^S P) \cap L^1(\rho_t^S P_S)$.
        % \item \label{ass:local_growth} (Local growth) For all $k\in\N$, $X_k$ and $X_k^S$ have PDFs $p_k$ and $p_k^S$ \wrt $\mathrm{Leb}(\Rd)$ and $\forall x \in \Rd,~ \exists c_x > 0, ~p_k (x), p_k^S(x) = \landau[k\to\infty]{k^{c_x}}$.
    \end{enumerate}
\end{assumption}


% \begin{table}[!t]
\begin{wraptable}{R}{0.6\columnwidth}
\small
\centering
\begin{threeparttable}
\begin{tabular}{l c c} 
\toprule
 & {Posterior}  & {Prior}\\
\midrule
    Markov kernels & {$P_S$} & {$P$} \\
    Discrete Markov process & {$(X_k^S)_{k\in\N}$} & {{$(X_k)_{k\in\N}$}} \\
    Poissonized Markov process & {$(Y_t^S)_{t>0}$} & {{$(Y_t)_{t>0}$}} \\
    Dist.\ of the discrete process & {$\mu_k^S$, $k \in \N$} & {$\mu_k$, $k \in \N$} \\
    Dist.\ of the Poissonized process & {$\rho_t^S$, $t>0$} & {$\pi_t$, $t>0$} \\
    Density of the Poissonized process & {$u_t^S$} & {$u_t$} \\
    % Infinitesimal generators & {$L_S = P_S - I$} & {$L = P - I$} \\
\bottomrule
\end{tabular}
\caption{Notations for posterior and prior dynamics.}
\label{tab:notations}
% \vspace{-5mm}
\end{threeparttable}
% \end{table} 
\end{wraptable}

The assumptions $\rho_t^S \ll \pi_t$ and $\ell \in L^1(\rho_t^S \otimes \mu_z)$ are natural in our PAC-Bayesian approach. We suppose that $\mu_k$ and $\mu_k^S$ are absolutely continuous mainly for simplicity as this can be relaxed, as briefly discussed in \Cref{rq:poisson-boltzmann-weak-form}.
Requiring that $v_t$ is positive and twice continuously differentiable is a relatively mild assumption. 
Indeed, if the initialization $X_0 \sim p_0$ is everywhere positive, then this property is preserved for the Poissonized distributions $u_t^S$. The fact that $v_t \in \mathcal{C}^2(\Rd)$ implies that the algorithm is not creating singularities during training.
It can be satisfied even by non-noisy algorithms such as for SGD with a gradient-Lipschitz loss and small learning rate \citep{clerico_generalisation_2023}.

Conditions \ref{ass:domination} and \ref{ass:logarithmic-regularity} regard the minimal integrability properties of $v_t$  to ensure the existence of various terms defined below. 
% regard the integrability properties of $v_t$ and consist in the minimalist framework to ensure the existence of various terms defined below. 
In particular, Condition \ref{ass:domination} allows us to differentiate the relative entropy $\klb{\rho_t^S}{\pi_t}$, which is the purpose of our framework. 
These conditions can be expected to be mild in practice. For instance, $\log(v_t) \in L^1(\rho_t^S)$ is equivalent to $\klb{\rho_t^S}{\pi_t} < +\infty$ and the other integrability conditions on $\log v_t$ are satisfied as soon as $\exists K>0,~|\log(v_t)(y)| = \landau{\normof{y}^K}$ and $\rho_t^S P$ and $\rho_t^S P_S$ have finite moments of order $K$ (it typically holds for Gaussian distributions). Finally, in the case where $\pi_t = \pi$ is an invariant measure for $P$, the conditions $v_t\in L^1(\delta_x P)$ and $P(\Phi(v_t)) \in L^1(v_t)$ are implied by the other conditions \citep[Lemma 3.6]{rudolf_explicit_2012}. \Cref{ass:phi-regularity} is similar to \citep[Assumption 3.3]{dupuis_generalization_2024} made in the case of heavy-tailed SDEs. 

% Finally, Condition \ref{ass:local_growth} is a very mild assumption that ensure that the densities of the discrete-time process are pointwise at most polynomial in time, this ensures that the densities of the Poissonized process can be characterized by a PDE that is described in \Cref{sec:proofs-technical-background}.

% \ben{maybe add more details, potentially in the appendix}



% \begin{assumption}[$\Phi$-regularity]
%     \label{ass:phi-regularity}
%     We define the following conditions:
%     \begin{enumerate}
%         \item For all $t>0$, the law of $Y_t^S$ is absolutely continuous with respect to the law of $Y_t$.
%         \item $\forall x \in \Rd, ~\forall t > 0,~ v_t \in L^1(\delta_x P)\cap L^1(\delta_x P_S)$.
%         \item $\forall t \geq 0, ~ Pv_t, ~\Phi \circ v_t,~ P(\Phi \circ v_t), ~ P(v_t \Phi'\circ v_t) \in L^1(u_t)$.\label{ass:h2}
%         \item $v_t P_S(\Phi'\circ v_t), ~v_t P(\Phi'\circ v_t) \in L^1(\pi_t)$.\label{ass:h3}
%         \item In every compact time interval $I$, there exists a positive function $\psi \in L^1(\der x)$ such that $\forall t\in I,~ \left| \frac{\der}{\der t} u_t \Phi(v_t) \right| \leq \psi$. \label{ass:domination}
%         \item $\forall t \geq 0,~ v_t \in \mathcal{C}_2^b$.
%         % \item $u_t$ and $u_t^S$ are of class $\mathcal{C}^1$ in time and of class $\mathcal{C}^2$ in space.
%     \end{enumerate}
% \end{assumption}

Based on \Cref{ass:phi-regularity}, we can now state the main result of this section, which is a closed-form expression for the entropy flow between the Poissonized processes $Y_t^S$ and $Y_t$. 

\begin{restatable}[Poissonized entropy flow]{theorem}{thmPoissonizedFlow}
    \label{thm:poissonized_entropy_flow}
    Under \Cref{ass:phi-regularity}, the entropy flow is given by:
    \begin{align}
        \label{eq:poissonized-entropy-flow}
        \frac{\der}{\der t} \klb{\rho^S_t}{\pi_t} =  \Delta_{P,P_S}(v_t) - \Eof[x\sim\pi_t,y\sim\delta_x P]{D_\Phi \left( v_t(x), v_t(y) \right)},
    \end{align}
    where $D_\Phi(a,b) := \Phi(a) - \Phi(b) - \Phi'(b)(a - b)$ is the Bregman divergence. We call the first term $\Delta_{P,P_S}(v_t):=\Eof[\rho_t^S]{(P_S - P) \log (v_t)}$ the \textbf{expansion term} and the second the \textbf{Bregman term}.
    % where $\Delta_{P,P_S}(v_t):=\Eof[\rho_t^S]{(P_S - P) \log (v_t)}$ is the \textbf{expansion term} and $D_\Phi$ is the Bregman divergence $D_\Phi(a,b) := \Phi(a) - \Phi(b) - \Phi'(b)(a - b)$. We call the second term of \Cref{eq:poissonized-entropy-flow} the \textbf{Bregman term}.
\end{restatable}

\begin{proof} (Sketch, see \Cref{sec:proofs-entropy-flow})
    By \Cref{ass:domination}, we have $\frac{\der}{\der t} \klb{\rho^S_t}{\pi_t} =  \int \frac{\partial}{\partial t} (\Phi(v_t) u_t) \der x$.
    % \begin{align*}
    %     \frac{\der}{\der t} \klb{\rho^S_t}{\pi_t} =  \int \frac{\partial}{\partial t} (\Phi(v_t) u_t) \der x.
    % \end{align*}
    The crucial step is to use the Boltzmann Equation \eqref{eq:poisson-boltzmann}, along with \Cref{eq:ipp-markov-operator} and \Cref{ass:logarithmic-regularity} to make the Markov operators $P$ and $P_S$ appear in the expression. The result follows by rearranging the terms. Let us note that this proof technique is not specific to $\Phi(x) = x\log(x)$ and can be seamlessly extended to the so-called $\Phi$-entropies \citep[Section 7.6.1]{bakry_analysis_2014}.
\end{proof}
 \Cref{thm:poissonized_entropy_flow} expresses the entropy flow as the difference between the \emph{expansion} term and the \emph{Bregman} term.
 The expansion term represents a discrepancy between the posterior dynamics $P_S$ and the prior one $P$ and \Cref{sec:applications} is dedicated to its analysis.
 %It involves the difference between the Markov operators $P_S$ and $P$, which we see as a ``distance'' between the prior and posterior dynamics. \Cref{sec:applications} is dedicated to its analysis in several contexts. 
 % We refer to the second term of \Cref{eq:poissonized-entropy-flow} as the \emph{Bregman term}.
 By convexity of $\Phi$, the Bregman term has a non-positive contribution to the entropy flow, analogously to the role of the Fisher information appearing in \citep[Proposition 2]{mou_generalization_2017} and the ``Bregman integral'' considered by \citet{dupuis_generalization_2024} in their study of heavy-tailed SDEs. The Bregman term crucially connects our framework to \emph{modified} logarithmic Sobolev inequalities, as we explain in \Cref{sec:poisson-sobolev}.
 %The second term of \Cref{eq:poissonized-entropy-flow} will be referred to as the \emph{Bregman term}.
 %By convexity of $\Phi$, this term has a non-positive contribution to the entropy flow, which is analogous to the role of the Fisher information appearing in \citep[Proposition 2]{mou_generalization_2017} and the ``Bregman integral'' observed by \citet{dupuis_generalization_2024} in their study of heavy-tailed SDEs. The Bregman term is at the heart of our framework through its links with \emph{modified} logarithmic Sobolev inequalities, as we explain in \Cref{sec:poisson-sobolev}.



% \begin{remark}
%     \label{rq:phi-entropies}
%     As it can be seen in the proof of \Cref{thm:poissonized_entropy_flow}, this result extends to more general convex functions $\Phi$, under an appropriate adaptation of \Cref{ass:phi-regularity}. Therefore, our theory can be used to derive entropy flows on the so-called $\Phi$-entropies \citep[Section 7.6.1]{bakry_analysis_2014}. In particular, these $\Phi$-entropy flows could be applied to differential privacy, where these quantities have been considered in the case of Langevin dynamics and differentially private SGD \citep{chourasia_differential_2022,vempala_rapid_2022,ryffel_differential_2022}.
% \end{remark}





\section{Towards Time-uniform Generalization Bounds}
\label{sec:poisson-sobolev}

% We have shown in \Cref{thm:poissonized_entropy_flow} that the entropy flow is a difference between two terms. 
In this section, we study the Bregman term appearing in \Cref{thm:poissonized_entropy_flow}. We first show in \Cref{sec:bregman-to-lsi} that it can be related to well-studied \emph{modified} logarithmic Sobolev inequalities (LSI) \citep{diaconis_logarithmic_1996} and that such modified LSIs can notably improve our generalization bounds. In \Cref{sec:psi-diffusive-priors}, we show that such modified LSIs are satisfied by a certain class of prior dynamics.


\subsection{From Bregman integral to modified LSIs}
\label{sec:bregman-to-lsi}

% \ben{
% \begin{itemize}
%     \item $\ent[\pi]{f}$ notation and classical LSI
%     \item Dirichlet form
%     \item entropy flow with Dirichlet form (in the case of an invariant prior measure)
%     \item define LSI and the modified LSI
%     \item discuss the literature about it
%     \item present and sketch the proof of the generic generalization bound
% \end{itemize}
% }

We recall the notion of (classical) LSI (see \citealp{bakry_analysis_2014,chafai_logarithmic_2017} for modern introductions). Let $\nu$ be a Borel probability measure, we associate to $\nu$ an \emph{entropy} functional, defined as $\ent[\nu]{f} = \entphi{\nu}{f} := \Eof[\nu]{\Phi(f)} - \Phi(\Eof[\nu]{f}), \text{ with }\Phi(x) = x\log(x).$
\begin{comment}
    \begin{align}
    \label{def:entropy-definition}
    \ent[\nu]{f} := \Eof[\nu]{\Phi(f)} - \Phi(\Eof[\nu]{f}), \text{ with: }\Phi(x) = x\log(x).
\end{align}
\end{comment}
The entropy generalizes the KL divergence, in the sense that $\ent[\nu]{\der \mu / \der \nu} = \klb{\mu}{\nu}$ as soon as $\mu \ll \nu$. 

A probability measure $\pi$ is said to satisfy the $\beta$-LSI if for all positive $f \in L^1(\pi)\cap \mathcal{C}^1(\Rd)$ we have the inequality
$\ent[\pi]{f} \leq \frac{2}{\beta} \Eof[\pi]{\normof{\nabla \sqrt{f}}^2}$. 
% \begin{align}
%     \label{eq:classical-lsi}
%    \ent[\pi]{f} \leq \frac{2}{\beta} \Eof[\pi]{\normof{\nabla \sqrt{f}}^2}
% \end{align}

% for every positive $f\in L^1(\pi)\cap \mathcal{C}^1(\Rd)$, we have $ \ent[\pi]{f} \leq \frac{2}{\beta} \Eof[\pi]{\normof{\nabla \sqrt{f}}^2}$.

% We give below the definition of LSIs, which are an upper bound on $\ent[\nu]{f}$.

% \begin{definition}[Logarithmic Sobolev inequality (LSI)]
% \label{def:lsi}
%     A probability measure $\pi$ is said to satisfy the $\beta$-LSI if for every positive $f\in L^1(\pi)\cap \mathcal{C}^1(\Rd)$, we have $ \ent[\pi]{f} \leq \frac{2}{\beta} \Eof[\pi]{\normof{\nabla \sqrt{f}}^2}$.
%     % The integral appearing on the right-hand side of this inequality is the celebrated Fisher information.
% \end{definition}

% \begin{example}
%     \label{example:gaussian-LSI}
%     The distribution $\mathcal{N}(0,\sigma^2 I_d)$ satisfies $1/\sigma^2$-LSI, see for instance the introduction of \citep{chafai_logarithmic_2017}. The Gaussian logarithmic Sobolev inequalities has been first proven in the seminal work of \citet{gross_logarithmic_1975-1}.
% \end{example}

For instance,  the Gaussian distribution $\mathcal{N}(0,\sigma^2 I_d)$ satisfies a $1/\sigma^2$-LSI \citep{gross_logarithmic_1975-1}.
Such inequalities have been extensively studied for their links with the convergence of Markov processes \citep{bakry_analysis_2014} and geometry \citep{bobkov_functional_1996,otto_generalization_2000}. In learning theory, they have been used for the generalization analysis of noisy algorithms \citep{mou_generalization_2017,li_generalization_2020}, differential privacy \citep{chourasia_differential_2022,ryffel_differential_2022} and PAC-Bayesian bounds \citep{haddouche_pac-bayesian_2024,casado_pac-bayes-chernoff_2024}. 
In the study of (Poissonized) discrete Markov processes, it has been shown that the $\beta$-LSI should be replaced by a functional inequality that takes into account the Markov kernel. %\citep{diaconis_logarithmic_1996,bobkov_modified_1998}. 
This leads to the following notion of \emph{modified} LSI.
% \footnote{Note that this is different from the ``modified LSIs'' considered by \citet{adamczak_modified_2022,ollivier_ricci_2007}}.

\begin{definition}[Modified LSI]
     \label{def:dirichlet-modified-lsi}
    An invariant\footnote{\citet{bobkov_modified_2006} defined this inequality for reversible measures, we seamlessly extend it to the invariant case.} measure $\pi$ of the Markov kernel $P$ satisfies a modified $\gamma$-LSI if for any positive $f$ s.t. $\forall x, ~f, \log f \in L^1(\delta_x P)$ and $f \log f,~ f P\log f \in L^1(\pi)$, we have:
    \begin{align}
        \label{eq:dirichlet-modified-lsi}
        \ecal_\pi(\log(f),f) \geq \gamma \ent{f},
        % \ent{f} \leq \frac{1}{\gamma} \ecal_\pi(\log(f),f),
    \end{align}
    where $\ecal_\pi$ is called the \textbf{Dirichlet form}\footnote{This is a Dirichlet form when $\pi$ is reversible for $P$, which makes $\ecal_\pi$ symmetric \citep{diaconis_logarithmic_1996}.} and is defined as $\ecal_\pi (f, g) := \Eof[\pi]{ g (I - P) f }$.
\end{definition}
% \begin{definition}[Dirichlet form]
%     \label{def:dirichlet-form}
%     Let $\pi$ be an invariant measure for $P$.
%     For measurable functions $f$ and $g$, the Dirichlet form associated with $(P,\pi)$ is $\ecal_\pi (f, g) := \Eof[\pi]{ g (I - P) f } = -\Eof[\pi]{g Lf}$.
% \end{definition}
%Dirichlet forms are a fundamental tool in the study of Markov processes \citep{bakry_analysis_2014} used to generalize the notion of LSI.
Such inequalities were introduced by \citet{diaconis_logarithmic_1996} and extensively studied by \citet{bobkov_modified_2006,bobkov_modified_1998,goel_modified_2004,wu_new_2000,ane_logarithmic_2000} to analyze the convergence rate of Markov chains. 
\citet{bobkov_modified_2006} used the term ``modified'' to avoid confusion with other inequalities, and we adopted this terminology in our study.
In order to involve modified LSIs, we remark that the Bregman term of \Cref{thm:poissonized_entropy_flow} can be expressed as a Dirichlet form if the prior is an invariant measure of $P$,
% with respect to an invariant measure, 
as proven in the following corollary.
%he following corollary makes the link between $\ecal_\pi$ and \Cref{thm:poissonized_entropy_flow}. 

\begin{restatable}{corollary}{corFlowSemigroup}
\label{cor:entropy-flow-semigroup-formulation}
    Assume that \Cref{ass:phi-regularity} holds and that $P$ has an invariant measure $\pi$. We have
    \begin{align*}
        \frac{\der}{\der t} \klb{\rho^S_t}{\pi} = \Eof[\rho_t^S]{(P_S - P)(\log v_t)}  - \ecal_\pi(\log v_t, v_t).
    \end{align*}
    % $\frac{\der}{\der t} \klb{\rho^S_t}{\pi} = \Eof[\rho_t^S]{(P_S - P)(\log v_t)}  - \ecal_\pi(\log v_t, v_t).$ \ben{if enough space center it}.
\end{restatable}


%Such inequalities were introduced by \citet{diaconis_logarithmic_1996} and extensively studied by \citet{bobkov_modified_2006,bobkov_modified_1998,goel_modified_2004,wu_new_2000,ane_logarithmic_2000} to analyze the convergence rate of Markov chains. 
%\citet{goel_modified_2004} used the term ``modified'' to avoid confusion with other inequalities and we adopt this terminology in our study.
% \Cref{def:dirichlet-modified-lsi} is called a modified inequality by \citet{goel_modified_2004,bobkov_modified_2006} because it is implied by another inequality.
% a stronger inequality, namely $\ent{f} \leq \frac{2}{\gamma} \ecal_\pi(\sqrt{f}, \sqrt{f})$, classically referred to as logarithmic Sobolev inequality (but not the same as in \Cref{def:lsi}).
% In our paper, without any confusion, we call \Cref{eq:dirichlet-modified-lsi} a \emph{modified} LSI.

Then, in the next theorem, we exploit modified LSIs to reach a novel generalization bound.
\begin{restatable}[Generalization error of Poissonized algorithms]{theorem}{thmGenericGeneralization}
\label{thm:generalization-under-modified-lsi}
    Assume that $\ell$ is $s^2$-subgaussian, \Cref{ass:phi-regularity} holds, and the prior dynamics has an invariant measure $\pi$ which satisfies a modified LSI with constant $\gamma$, in the sense of \Cref{def:dirichlet-modified-lsi}. Then, with probability at least $1 - \zeta$ under $S \sim \datadist$:
    \begin{align*}
        \Eof[w \sim \rho_T^S]{G_S(w)} \leq \frac{2s}{\sqrt{n}} \left\{  \int_0^T e^{-\gamma(T - t)}  \Delta_{P,P_S}(v_t)  \der t + e^{-\gamma T} \klb{p_0}{\pi} + \log \left( \frac{3}{\zeta} \right) \right\}^{\frac{1}{2}} .
    \end{align*}
\end{restatable}

\begin{proof} (Sketch, see \Cref{sec:proofs-lsi}) We start by using the entropy flow formula of \Cref{cor:entropy-flow-semigroup-formulation} to obtain the inequality:
$\frac{\der}{\der t} \klb{\rho_t^S}{\pi} = \Delta_{P,P_S}(v_t) - \ecal_\pi(\log v_t, v_t) \leq  \Delta_{P,P_S}(v_t)  - \gamma \klb{\rho_t^S}{\pi}.$

The result follows by solving this differential inequality and plugging the result in \Cref{thm:subgaussian-pac-bayes}.
\end{proof}

\Cref{thm:generalization-under-modified-lsi} shows that priors satisfying modified LSIs induce an exponential decay $e^{-\gamma(T - t)}$ in our generalization bound. This is analogous to the role of LSIs for Gaussian \citep{mou_generalization_2017} or heavy-tailed \citep{dupuis_generalization_2024} SDEs. 
Thus, determining which measure satisfies a modified LSI is a key question tackled in \Cref{sec:psi-diffusive-priors}.
%In particular, the bound might be time-uniform when the expansion term $\Delta_{P,P_S}(v_t)$ can be controlled, see \Cref{sec:applications}. 
\Cref{thm:generalization-under-modified-lsi} reduces the problem of controlling time-uniformly $\Eof[w \sim \rho_T^S]{G_S(w)}$ for upper-bounding $\Delta_{P,P_S}(v_t)$. Such a conclusion is analogous to \Cref{thm:subgaussian-pac-bayes}, reduces the generalization problem to the control of $\klb{\rho_t^S}{\pi_t}$. This is why in \Cref{sec:applications}, we often directly present upper bounds on either $\Delta_{P,P_S}(v_t)$ or $\klb{\rho_t^S}{\pi_t}$. 
%For the sake of clarity, we often present in what follows, upper bounds on either the KL divergence $\klb{\rho_t^S}{\pi_t}$ or the expansion term $\Delta_{P,P_S}(v_t)$, keeping in mind that they imply generalization bounds as a consequence of \Cref{thm:subgaussian-pac-bayes} and \Cref{thm:generalization-under-modified-lsi}.

% \ben{add some discussion of this result. In particular the fact that it holds for invariant measures but can easily be generalized.}
% \ben{say that in the remaining of the paper we just write bounds on the KL, ...}




\subsection{Modified logarithmic Sobolev inequalities for diffusive priors}
\label{sec:psi-diffusive-priors}

To exploit \Cref{thm:generalization-under-modified-lsi}, it is essential to identify which measures satisfy a modified LSI. Several works proposed modified LSIs for specific Markov chains \citep{diaconis_logarithmic_1996,goel_modified_2004,ane_logarithmic_2000,bobkov_modified_2006}. In particular, \citet{Erbar_2012} obtained modified LSIs under a Ricci curvature condition for discrete Markov chains.
However, most of these results are constrained to finite or countable state spaces, which is inconsistent with the continuous distributions involved in this work.
%While this could be of interest to study the generalization error of learning algorithms with a finite state space, it is not adapted to our PAC-Bayesian approach with absolutely continuous measures \wrt $\mathrm{Leb}(\Rd)$.
Inspired by the theory of classical LSIs, we consider the class of prior Markov kernels $P$ that can be represented by diffusions in the following sense.

\begin{definition}
    \label{def:representable-kernels}
    Consider a twice differentiable gradient-Lipschitz potential $V:\Rd \to \R$ such that $e^{-V} \in L^1(\Rd)$, $e^{-V}$ has finite moments of order $2$, and the Langevin equation $\der Z_t = -\nabla V (Z_t) \der t + \sqrt{2} \der B_t$,
    % \begin{align}
    %     \label{eq:general-langevin-equation}
    %     \der Z_t = -\nabla V (Z_t) \der t + \sqrt{2} \der B_t,
    % \end{align}
    where $(B_t)_{t\geq 0}$ is a standard Wiener process. We say that a Markov kernel $P$ is representable by this equation at time $t_0 > 0$ if for all $x \in \Rd$, we have $P(x,.) = \mathrm{Law}(Z_{t_0} | Z_0 = x)$. 
\end{definition}

% \begin{remark}
%     In terms of semigroup theory, \Cref{def:representable-kernels} means that the diffusion semigroup $(P_t)_{t\geq 0}$ associated with \Cref{eq:general-langevin-equation} satisfies $P_{t_0} = P$. We provide in \Cref{sec:diffusion-semigroups-background} an introduction to diffusion semigroups, which we are essential to some of our proofs. The interested reader may also consult \citep{bakry_analysis_2014,chafai_logarithmic_2017}.
% \end{remark}
% \ben{Explain that this case is interesting for regularized algorithms}

The main outcome of this section is that prior dynamics satisfying \Cref{def:representable-kernels} satisfy a modified LSI if the invariant measure of the underlying Langevin equation satisfies a classical LSI.

\begin{restatable}[Modified LSI for diffusive priors]{theorem}{thmPSIDiffusivepriors}
    \label{thm:psi-diffusive-priors}
    Assume the Markov kernel $P$ to be representable at time $t_0$ by a diffusion with an ergodic invariant measure $\pi$, as in \Cref{def:representable-kernels}. Let $K>0$ and $f\in \mathcal{C}^2(\Rd)$ a positive function s.t. $\forall x,~f, \log(f) \in L^1(\delta_x P) $, and $f\log(f), ~Pf \log(f) \in L^1(\pi)$.
    If $\pi$ satisfies a LSI with constant $K$, then we have the modified LSI:
    \begin{align}
        \label{eq:weak-modified-lsi}
        \ecal_\pi (\log f, f) \geq c_{\mathrm{LSI}} \ent{f},
    \end{align}
    with $c_{\mathrm{LSI}} = \frac{Kt_0}{1 + Kt_0}$.
    If we have $\nabla^2 V \succeq K I_d$, then the constant is improved to $c_{\mathrm{LSI}} =  1 - e^{-K t_0} $.
    % \begin{align}
    %     \label{eq:strong-modified-lsi}
    %     \ecal_\pi (\log f, f) \geq \left( 1 - e^{-K t_0} \right) \ent{f}.
    % \end{align}
\end{restatable}

% \begin{remark}
%     \label{rq:strong-psi-semigroup}
%     The proof of \Cref{thm:psi-diffusive-priors}, presented in \Cref{sec:proofs-lsi}, yields a slightly stronger result. Indeed, the first step of this proof provides a lower bound $\ecal_\pi(\log f, f) \geq \bar{\ecal}_\pi (f)$. It is subsequently proven that \Cref{thm:psi-diffusive-priors} can be written with $\bar{\ecal}_\pi$ in place of $\ecal_\pi$. The definition of $\bar{\ecal}_\pi$ uses diffusion semigroups and is reported to \Cref{sec:proofs-lsi}. We will use this stronger version of \Cref{thm:psi-diffusive-priors} to apply our theory to noisy algorithms in \Cref{sec:applications}.
% \end{remark}

We give two examples of diffusive priors of particular interest to this work. First, the following corollary corresponds to the case of Gaussian priors. Similar to \citep{mou_generalization_2017}, we use this Gaussian prior in the case of an algorithm featuring $\ell^2$-regularization, see \Cref{sec:applications}.

\begin{restatable}{corollary}{corPSIGaussian}
    \label{cor:psi-discrete-ornstein-Uhlenbeck}
    Consider the Markov process defined by $X_{k+1} = (1 - \gamma) X_k + \sigma \mathcal{N}(0, I_d)$ with $\gamma \in (0,1),\sigma>0$. 
    % Let $P$ and $\pi$ be the Markov kernel and the invariant measure corresponding to $(X_k)_{k\in \N}$.
    Then the associated Dirichlet form $\ecal_\pi$ satisfies a modified LSI with constant $\gamma$.
\end{restatable}

\begin{proof}
    (Sketch, see \Cref{sec:proofs-psi-diffusive-priors}) We show that the recursion $X_{k+1} = (1 - \gamma) X_k + \sigma \mathcal{N}(0, I_d)$ is representable by the SDE $\der Z_t = -c Z_t \der t + \sqrt{2} \der B_t$ at time $t_0$ for certain values of $t_0$ and $c$ explicitly given in \Cref{sec:proofs-psi-diffusive-priors}. The result follows from \Cref{thm:psi-diffusive-priors}, by the strong convexity of $x \mapsto \frac{c}{2}\normof{x}^2$.
\end{proof}

Second, inspired by \citep{amir_thinking_2022,dupuis_mutual_2023,dupuis_uniform_2024}, our framework makes it possible to use the population risk $\risk$ as a potential function in \Cref{def:representable-kernels}, leading to the use of the SDE $\der Z_t = -c \nabla \risk(Z_t) \der t + \sqrt{2} \der B_t$. Under certain assumptions on $\risk$ (see \citep{li_generalization_2020}), the invariant measure satisfies an LSI, making it compatible with \Cref{thm:psi-diffusive-priors}.
% For the sake of clarity, we focus our main applications on simple prior dynamics.
These examples shed new light on the choice of the prior in information-theoretic generalization bounds.
%This shows that our framework opens the door to the study of more informative priors.

% \begin{example}[Expected dynamics]
%     Inspired by \citep{amir_thinking_2022,dupuis_mutual_2023,dupuis_uniform_2024}, one could be interested in using the population risk as a potential function in \Cref{def:representable-kernels}, leading to the use of the SDE $\der Z_t = -c \nabla \risk(Z_t) \der t + \sqrt{2} \der B_t$. Under certain assumptions on $\risk$ (such as dissipativity, see \citep{li_generalization_2020}), the invariant measure of this SDE satisfies a LSI, which makes our \Cref{thm:psi-diffusive-priors} compatible with such considerations.
% \end{example}

% \ben{TODO: add a remark about the use of expected dynamics (+ link convergence - generalization?)}



\section{Controlling the Discrepancy Between Markov Kernels for Concrete Algorithms}
\label{sec:applications}

In \Cref{sec:poisson-sobolev}, we have controlled the Bregman term appearing in \Cref{thm:poissonized_entropy_flow} through modified LSIs and then proved that such inequalities were satisfied by diffusive priors. The last step to apply our theory to practical algorithms is to analyze the expansion term $\Delta_{P,P_S}(v_t)$.
We present two sets of tools to achieve this, depending on the structure of the algorithm. First, we consider \emph{noisy} algorithms in \Cref{sec:noisy-algorithms} and then turn to non-noisy algorithms in \Cref{sec:singular-algorithms}.

\subsection{Poissonized bounds for noisy algorithms and SGLD}
\label{sec:noisy-algorithms}

% \ben{
% \begin{itemize}
%     \item quick literature review on noisy iterative algorithms
%     \item Define noisy algorithm + noisy SGD as the typical example
%     \item State the general result with $\klb{\delta_x P_S}{\delta_x P}$, as a warm-up
%     \item Explain the case of regularized SGLD and open the door to more general results and extensions of the proof technique.
% \end{itemize}
% }

The generalization error of noisy iterative algorithm has been extensively studied \citep{haghifam_sharpened_2020,xu_information-theoretic_2017,negrea_information-theoretic_2020,bu_tightening_2020-1}.
In our work, we say that a Markov algorithm is \emph{noisy} if for all $S \in \zcal^n$ and all $x \in \Rd$, we have $P_S(x, \cdot) \ll \mathrm{Leb}(\Rd)$.
In all this section, we consider prior dynamics such that for all $x\in\Rd$, $\delta_x P$ is equivalent to the Lebesgue measure $\mathrm{Leb}(\Rd)$ (\ie, $\delta_x p \ll \mathrm{Leb}(\Rd)$ and $\mathrm{Leb}(\Rd) \ll \delta_x P$). 
% This is for instance the case of the diffusive priors studied in \Cref{sec:psi-diffusive-priors}.
% Our definition of noisy Markov algorithms encompasses all the forms of noisy SGD with constant step-size, for which notations are formally introduced in the following example.
Our main example of a noisy algorithm is noisy SGD, for which we introduce some notations in the following example.

\begin{example}[SGD and noisy SGD]
    \label{ex:noisy-sgd-noisy-algorithm}
    We define $ X_{k+1} = (1 - \lambda \eta) X_k - \eta \widehat{g}_S(X_k, U_k) + \zeta_k$,
    % \begin{align}
    %     \label{eq:noisy-sgd}
    %     X_{k+1} = (1 - \lambda \eta) X_k - \eta \widehat{\nabla}\er(X_k, U_k) + \zeta_k,
    % \end{align}
    with learning rate $\eta > 0$, regularization coefficient $\lambda \geq 0$ (potentially $0$), stochastic gradient $\widehat{g}_S(x, U_k)$, and added noise $\zeta_k$.
    The random variable $U_k$ represents the randomness of the batch indices. SGLD corresponds to the case where $\zeta_k \sim \mathcal{N}(0, \sigma^2 I_d)$. We use these notations in several discussions below.
\end{example}

\paragraph{Warm up.} We start with a generic bound of the entropy flow for noisy algorithms, which applies to a general class of noise distributions. The following corollary is a direct consequence of \Cref{thm:poissonized_entropy_flow} and an application of Donsker-Varadhan's formula, the proof can be found in \Cref{sec:proofs-applications}.

% \maxime{Why do we need Prop 11 instead of Thm 4} \ben{because the terms $\klb{\delta_x P_S}{\delta_x P}$ are easy to express in a lot of cases (eg, SGLD), while the expansion term is not.} \maxime{Then we need to make crystal clear the impact of POissonization in this part given we seem to avoid most of the benefits of Section 3 and 4}

\begin{restatable}{corollary}{propNoisyGenericBound}
    \label{prop:poissonized-flow-noisy-algorithm}
    Under the above conditions and \Cref{ass:phi-regularity}, a noisy algorithm satisfies: 
    % \umut{what is $\sim$? } \ben{By $\mu \sim \nu$ I mean that $\mu \ll \nu $ and $\nu \ll \mu$, I removed it because it might not be a very classical notation indeed.}
    \begin{align}
        \label{eq:noisy-algorithm-general-bound}
         \klb{\rho_T^S}{\pi_T} \leq \klb{p_0}{\pi_0} + \int_0^T \Eof[\rho_t^S]{\klb{\delta_x P_S}{\delta_x P}}  \der t - \int_0^T \Eof[\pi_t]{D_\Phi (v_t, Pv_t)} \der t.
    \end{align}
    If $P$ has an invariant measure $\pi$ and we use $\forall t,~\pi_t = \pi$, then we can simplify the last term as $\Eof[\pi_t]{D_\Phi (v_t, Pv_t)} = \klb{\rho_t^S}{\rho_t^S P^\dag} $,
    % \begin{align*}
    %     \klb{\rho_T^S}{\pi} \leq \klb{p_0}{\pi} + \int_0^T \Eof[\rho_t^S]{\klb{\delta_x P_S}{\delta_x P}}  \der t - \int_0^T \klb{\rho_t^S}{\rho_t^S Q} \der t,
    % \end{align*}
    where $P^\dag$ is the adjoint of $P$ in $L^2(\pi)$.
    % \umut{can't we just use $P^\star$ instead of $Q$? like $\Eof[\pi_t]{D_\Phi (v_t, Pv_t)} = \klb{\rho_t^S}{\rho_t^S P^\star} $, where $P^\star$ is the adjoint of $P$ in $L^2(\pi)$}
\end{restatable}

% {\color{purple}
% \begin{remark}
%     In the above setting, we can show that:
%     \begin{align*}
%         \frac{\der}{\der t} \klb{\rho_t^S}{\pi} \leq \Eof[\rho_t^S]{\klb{\delta_x P_S}{\delta_x P}} - \sqrt{\frac1{C}_T \ecal_\pi(f, \log f) },
%     \end{align*}
%     with $C_T := \sup_{0\leq t \leq T} \sup_{x\in\Rd} |\log(v_t)|$. Hence, under a $\gamma$-modified LSI, the problem boils down to a differential inequality of the form $\varphi' \leq k(t) - c \sqrt{\varphi}$.
% \end{remark}
% }

% \begin{remark}
%     In the particular case where the prior kernel $P$ admits a reversible distribution $\pi$, then the last integrand of \Cref{eq:noisy-algorithm-general-bound} can be expressed as $\Eof[\pi_t]{D_\Phi (v_t, Pv_t)} = \klb{\rho_t^S}{\rho_t^S P}$.
% \end{remark}

 To analyze the above proposition, let us compare with a discrete-time (naive) bound of the form $\klb{\mu_N^S}{\mu_N} \leq \klb{p_0}{\mu_0} + \sum_{k=0}^{N-1} \Eof[x\sim\mu_k^S]{\klb{\delta_x P_S}{\delta_x P}}$,
% \Cref{prop:poissonized-flow-noisy-algorithm} is to be compared with the discrete-time bound:
% \begin{align}
%     \label{eq:noisy-algo-discrete-bound}
%     \forall N \in \N^\star,~ \klb{\rho_N^S}{\pi_N} \leq \klb{\rho_0}{\pi_0} + \sum_{k=0}^N \Eof[x\sim\mu_k^S]{\klb{\delta_x P_S}{\delta_x P}}.
% \end{align}
which can be obtained by using the data-processing inequality and the chain rule, see \citep{neu_information-theoretic_2021,negrea_information-theoretic_2020} for similar ideas. As we consider a Poisson process $(N_t)_{t>0}$ of intensity $1$, the previous sum is analogous to the first integral in \Cref{eq:noisy-algorithm-general-bound}. We note that \Cref{eq:noisy-algorithm-general-bound} provides a better bound, with a negative term that can be seen as an estimate of the error made by the previous reasoning.

The ``local'' KL divergence $\klb{\delta_x P_S}{\delta_x P}$ can be estimated in numerous cases. For noisy SGD with Gaussian or Laplace-distributed noise, up to a relevant choice of prior $P$ (\ie, corresponding to $X_{k+1} = (1 - \eta\lambda) X_k + \zeta_k$ with the notations of \Cref{ex:noisy-sgd-noisy-algorithm}), we have $\klb{\delta_x P_S}{\delta_x P} \lesssim \Eof[U]{\normof{\widehat{g}_S(x,U)}^2}$. Hence, our framework provides informative bounds for various noising schemes, such as Laplace noise, which has been considered for differential privacy \citep{kuru_differentially_2022}.

% Finally, let us note that for noisy SGD with Gaussian noise distribution, \ie, $\lambda = 0$ and $\zeta_k \sim \mathcal{N}(0,\sigma^2 I_d)$ in \Cref{ex:noisy-sgd-noisy-algorithm}, we can classically obtain $\klb{\delta_x P_S}{\delta_x P} \leq \frac{\eta^2}{2\sigma^2} \Eof[U_k]{\widehat{g}(x, U_k)}$ with a Gaussian prior. Our framework opens the door to an improvement of this and applies to any noising scheme \citep{zhu_uniform--time_2023-1}, as long as a bound on the KL divergence can be derived.

% \begin{remark}[Strong Bregman term]
%     \ben{TODO, also mention $\klb{\rho_t^S}{\rho_t^S P}$}
% \end{remark}

% As an easy consequence of this formula, by using the positivity of the Bregman divergence we have, for any $T>0$:
% \begin{align}
%     \label{eq:noisy-algorithms-naive-bound}
%         \klb{\rho_T^S}{\pi_T} \leq \int_0^T \Eof[x\sim\rho_t^S]{\klb{\delta_x P_S}{\delta_x P}}  \der t.
% \end{align}

% \begin{remark}
%     If moreover the operator $P$ is reversible for $\pi$, then we have that $ \Eof[\pi]{D_\Phi (v_t, Pv_t)} = \klb{\rho_t^S}{\rho_t^S P}$, which leads to:
%     \begin{align*}
%          \klb{\rho_T^S}{\pi_T} \leq  \int_0^T \Eof[x\sim\rho_t^S]{\klb{\delta_x P_S}{\delta_x P}}  \der t - \int_0^T \klb{\rho_t^S}{\rho_t^S P} \der t.
%     \end{align*}
%     % \begin{align*}
%     %     \Eof[\pi]{D_\Phi (v_t, Pv_t)} = \klb{\rho_t^S}{\rho_t^S P}
%     % \end{align*}
%     % By using the joint convexity of the Kl divergence, we obtain the following improvement of \Cref{eq:noisy-algorithms-naive-bound}:
%     % \begin{align*}
%     %      \klb{\rho_T^S}{\pi_T} \leq  \int_0^T \Eof[x\sim\rho_t^S]{\klb{\delta_x P_S}{\delta_x P}}  \der t - T \klb{\bar{\rho}^S_T}{\bar{\rho}^S_T P},
%     % \end{align*}
%     % where $\bar{\rho}^S_T := (1/T) \int_0^T \rho^S_T\der t$.
% \end{remark}

\paragraph{The case of SGLD.} The term $\Eof[\pi_t]{D_\Phi(v_t,Pv_t)}$ appearing in \Cref{prop:poissonized-flow-noisy-algorithm} is different (by Jensen's inequality, it is smaller) from the Bregman term featured in \Cref{thm:poissonized_entropy_flow}.
This suggests that modified LSIs using this term instead of $\ecal_\pi(\log f, f)$ would lead to improved bounds with a form similar to \Cref{thm:generalization-under-modified-lsi}.
In the case of SGLD, we were able to circumvent the need for such stronger inequality and applied our Poissonization framework to prove the following result (see the proof in \Cref{sec:proofs-sgld-bounds}).
 % \maxime{This paragraph is strange: modified LSIs leads to better bounds but in fact we don't care and we do smth else?} \ben{the point is: we see the bound seems to be better but we could not express explicitly the term $\Eof[\pi_t]{D_\Phi(v_t,Pv_t)}$, so we found a slightly modified approach which works only for SGLD} \maxime{We need to precise the impact of Poissonization then imo}
 
\begin{restatable}[Poissonized SGLD]{theorem}{thmSGLDKLBound}
    \label{thm:sgld-kl-bound}
    Consider the Markov kernel $P_S$ corresponding to SGLD with $\eta\lambda < 1$ and take $P$ and $\pi$ to be the Markov kernel and the invariant distribution of the recursion $X_{k+1} = (1 - \lambda \eta) X_k + \sigma \mathcal{N}(0, I_d)$. Assume that \Cref{ass:phi-regularity} holds, then we have:
    \begin{align}
        \label{eq:sgld-bound}
        \klb{\rho_T^S}{\pi} \leq \frac{\eta^2 (2 - \lambda \eta)}{2  \sigma^2} \int_0^T e^{-\lambda \eta (T - t)}\Eof[x \sim \rho_t^S, U]{\normof{\widehat{g}_S(x,U)}^2}  \der t.
    \end{align}
\end{restatable}
% \ben{Should we present it as a generalization bound directly?}
% \maxime{I think so, especially if we remove the PAC-Bayesian part from the main. Maybe we can keep the focus on the KL eqsuation and add below the associated generalisation bound?}
\Cref{thm:sgld-kl-bound} is proven in \Cref{sec:proofs-sgld-bounds}.
Together with \Cref{thm:subgaussian-pac-bayes}, this result provides a generalization bound for Poissonized SGLD. Because the underlying Poisson process is of intensity $1$, we note that the order of magnitude of the different terms in \Cref{eq:sgld-bound} are of the same order of magnitude as the results of \citet{mou_generalization_2017} obtained under similar assumptions. Hence, the Poissonization framework is general enough to recover Poissonized counterparts of classical results.
%The proof of \Cref{thm:sgld-kl-bound}, presented in \Cref{sec:proofs-sgld-bounds}, relies on \Cref{thm:poissonized_entropy_flow}, Donsker-Varadhan's formula and an inequality we prove in the proof of \Cref{thm:psi-diffusive-priors}. 

% \ben{TODO: quick analysis of the bound. proof with stronger LSI + discrete OU prior + \citep{mou_generalization_2017}}

% \begin{remark}
%     The proof uses the stronger version of our modified LSis, mentioned in \Cref{rq:strong-psi-semigroup}.
% \end{remark}

\subsection{Analysis of non-noisy algorithms}
\label{sec:singular-algorithms}

% \ben{\begin{itemize}
%     \item In the absence of absolute continuity of the kernels for all $x\in\Rd$, we cannot apply Donsker Varadhan.
%     \item Idea: Taylor expansion of $P_S - P$ around $P$
%     \item First and second-order analysis
% \end{itemize}}

Unfortunately, various popular procedures, starting with SGD, are not included in the noisy algorithms class. Then, can the Poissonization framework cover non-noisy procedures, \ie, when the absolute continuity property $\delta_x P_S \ll \delta_x P$ does not hold? The answer is positive: 
%while this prevents us from introducing the KL divergence $\klb{\delta_x P_S}{\delta_x P}$, 
We extend the entropy flow technique beyond noisy algorithms (under specific assumptions) and reach informative generalization bounds encompassing both noisy and non-noisy methods, with a focus on SGD. 
%Note also that the presented results are compatible with noisy algorithms. 

% In this section, we handle the Markov kernel difference $P_S - P$ appearing in the expansion term by performing Taylor expansions ``around $P$''. We first present a first-order version of this reasoning and then look at the case of SGD through a second-order expansion. 

% \ben{For the first-order analysis:
% \begin{itemize}
%     \item State the bound on the expansion term
%     \item Discuss the local Wasserstein term \citep{rudolf_perturbation_2017,zhu_uniform--time_2023-1,simsekli_differential_2024-1,ollivier_ricci_2007}
%     \item Discuss the linear growth assumption
%     \item We show that the score function is important for generalization (new to the best of our knowledge)
%     \item Discuss the terms $\normof{P_S}_t$: does $\rho_t^S$ reduce the dimension? Is it a sum of eigenvalues?
% \end{itemize}
% }

\paragraph{First-order analysis.} To avoid the condition $\delta_x P_S \ll \delta_x P$, our main idea is to perform an expansion of $P_S$ ``around $P$''.  This is made more precise by the following proposition, which is inspired by \citep[Proposition $1$]{polyanskiy_wasserstein_2016} and \citep[Lemma 3.5]{raginsky_non-convex_2017}. 
% This result can be seen as a Taylor expansion of $P_S$ of order $1$.

% Let $p : \R^d \to \R_+$ be a density of a probability distribution \wrt to an arbitrary measure. The score function of $p$ is classically defined as $s(x) := \nabla \log p(x)$. \ben{ add references}.

\begin{restatable}{proposition}{propScoreWasserstein}
    \label{prop:first-term-bound-f-regular}
    Assume that, for all $t\in [0,T]$, there exist constants $c_1,c_2>0$ such that $v_t$ satisfies the linear growth condition $\forall x \in \Rd,~\normof{\nabla \log v_t(x)} \leq c_1 \normof{x} + c_2$, then we have:
    \begin{align*}
        \Delta_{P,P_S}(v_t) \leq \Eof[\rho_t^S]{W_2(\delta_x P, \delta_x P_S)^2}^{\frac1{2}}\left(\frac{c_1}{2} \normof{P}_t + \frac{c_1}{2}\normof{P_S}_t + c_2 \right),
    \end{align*}
    with $\normof{P}_t^2 := \Eof[x\sim\rho_t^S, w \sim \delta_x P]{\normof{w}^2}$ (resp. $P_S$) and $W_2$ the Wasserstein distance (\Cref{sec:proofs-singular-algorithms}).
\end{restatable}

% \ben{it's like a tail assumption, so compare with the literature? Info about choosing the prior?}

% W term
The main feature of \Cref{prop:first-term-bound-f-regular}, proved in \Cref{sec:proofs-singular-algorithms}, is to relate the expansion term to the Wasserstein distance $W_2(\delta_x P_S, \delta_x P)$. Note that this term is local, \ie, it is computed for every point $x\in\Rd$ and expected over the posterior distribution. In the case of SGD, with a relevant choice of $P$, we typically have $W_2(\delta_x P, \delta_x P_S)^2 \leq \eta^2 \Eof[U]{\normof{\widehat{g}_S(x,U)}^2}$, with the notations of \Cref{ex:noisy-sgd-noisy-algorithm}. Similar Wasserstein distances between Markov kernels have been extensively studied in the context of convergence and geometry of Markov chains \citep{rudolf_perturbation_2017,ollivier_ricci_2007} and have been used by \citep{zhu_uniform--time_2023-1} to obtain stability-based bounds for SGD.
Therefore, \Cref{prop:first-term-bound-f-regular} connects our framework and the prior art through these Wasserstein terms.
% \Cref{prop:first-term-bound-f-regular} suggests that these Wasserstein expansion terms have even more general connections to the generalization error.

% assumption + score function
\Cref{prop:first-term-bound-f-regular} relies on a condition of linear growth of $\nabla \log v_t = \nabla \log u_t^S - \nabla \log \pi_t$.
This assumption can be seen as an assumption on the tail of the posterior density $u_t^S$ and can hint towards good choices of prior, \ie, with similar tails as the posterior density. 
For instance, if we use a Gaussian prior as in \Cref{cor:psi-discrete-ornstein-Uhlenbeck}, it boils down to a linear growth assumption on the score\footnote{Given a probability density function $p$, the score function is defined as $x \mapsto \nabla \log p(x)$.} of the posterior density.
Finally, note that a related condition was used by \citet[Section A.4]{li_generalization_2020}.

% To the best of our knowledge, such critical role of the score function is new in the study of generalization error. 

% norm terms?
% \ben{TODO: discuss the $\normof{P_S}_t$ terms. does $\rho_t^S$ reduce the dimension? Is it a sum of eigenvalues?}


% \ben{For the second-order analysis:
% \begin{itemize}
%     \item The main issue with the above technique is that the type of priors for which $\normof{P_S}$ and $\normof{P}$ would not explode with $d$ do not trivially satisfy the modified LSIs.
%     \item Our solution to this is to push the reasoning to a second-order Taylor expansion.
%     \item This approach is only presented for regularized SGD but could be extended (see \Cref{sec:proofs-applications}).
% \end{itemize}
% }

\paragraph{Second-order analysis.}  \Cref{prop:first-term-bound-f-regular} contains kernel norm terms $\normof{P_S}_t$ and $\normof{P}_t$ possibly large  when $c_1>0$. In particular, the diffusive priors studied in \Cref{sec:psi-diffusive-priors}, make the term $\normof{P}_t$ of order $\sqrt{d}$, leading to a multiplicative constant of order $\sqrt{c_1} d^{1/4}/\sqrt{n}$ in the final generalization bound. 

To address this potential issue, we observe that the proof of \Cref{prop:first-term-bound-f-regular} can be seen as a $1^{\text{st}}$-order Taylor expansion of the $P_S$ and propose to extend it to a $2^{\text{nd}}$-order expansion through stronger assumptions. For the sake of simplicity, we focus in \Cref{thm:second-taylor-regularized-sgd-simple-version} on the case of regularized SGD, \ie, $X_{k+1} = (1 - \lambda \eta) X_k - \eta \widehat{g}_S(X_k, U_k) $ with the notations of \Cref{ex:noisy-sgd-noisy-algorithm}. Nevertheless, the methods presented here may be more generally applied to other algorithms, see \Cref{sec:proofs-singular-algorithms}. 
%This approach leads to the following generalization bound. 

\begin{restatable}[Generalization bound for regularized SGD]{theorem}{thmTaylorRegularizedSGD}
    \label{thm:second-taylor-regularized-sgd-simple-version}
    Assume that $\ell$ is $s^2$-subgaussian and \Cref{ass:phi-regularity} holds with $\pi$ the invariant measure of the Markov process of \Cref{cor:psi-discrete-ornstein-Uhlenbeck} with $\gamma = \lambda \eta$ and $\sigma > 0$ a noise scale. We further assume that there exists $\beta \geq 0$ such that $0 \preceq \nabla^2 \log(v_t) \preceq \beta I_d$, for all $t \in [0,T]$. Then, we have, with probability at least $1 - \zeta$ over $S\sim \datadist$ that:
    \begin{align*}
        \Eof[\rho_T^S]{G_S} \leq \frac{2s}{\sqrt{n}} \left\{ \int_0^T e^{-\lambda \eta (T - t)} \eta  \Eof[x\sim\rho_t^S,U]{ Q\left( \normof{\widehat{g}_S (x,U)}, \normof{x} \right)} \der t + e^{-\lambda \eta T } K_0 + \log\frac{3}{\zeta}\right\}^{\frac{1}{2}},
    \end{align*}
    where $Q(X,Y) := X\left( \beta Y + \normof{\nabla \log u_t^S (0)} \right) + \eta \beta \left( X^2 + \lambda^2 Y^2 \right)$ is a $2^{\text{nd}}$-order bivariate polynomial, $K_0 := \klb{p_0}{\pi}$ and $U$ is the randomness of the batches in the stochastic gradient $\widehat{g}_S$.
    % \begin{align*}
    %     \Eof[\rho_T^S]{G_S} \leq \frac{2s}{\sqrt{n}} \left\{ \int_0^T e^{-\lambda \eta (T - t)} \eta  \Eof[\rho_t^S, \nu]{ C_1 \normof{\widehat{\nabla} \er (x)}^2 + C_2 \normof{x}^2 + C_3 } \der t + K_T + \log\frac{3}{\zeta}\right\}^{\frac{1}{2}}
    % \end{align*}
    % with $C_1 := 1 + \beta \eta$, $C_2 := \beta \lambda^2 \eta + \frac{\beta^2}{2}$, $C_3 := \frac1{2} \normof{\nabla \log u_t^S (0)}^2$ and $K_T :=e^{-\lambda \eta T } \klb{u_0}{\pi}$. By the notation $\mathds{E}_{\rho_t^S,U}$ we mean that we integrate over $(x,U) \sim \rho_t^S \otimes \nu$, with $\nu$ being the random batch indices in the stochastic gradient $\widehat{\nabla} \er$.
\end{restatable}
% \ben{maybe add the $\alpha$ and discuss $\alpha = 0$ case}
Let us first note that the assumption $0 \preceq \nabla^2 \log v_t \preceq \beta I_d$ implies the linear growth assumption of \Cref{prop:first-term-bound-f-regular} (with $c_1 = \beta$ and $c_2 = \normof{\nabla \log v_t(0)}$). The lower bound of this condition ($0 \preceq \nabla^2 \log v_t $) implies that the Radon-Nykodym derivative $v_t$ is convex and non-bounded, which is non-trivial but still a priori compatible with \Cref{ass:phi-regularity}. 
Moreover, in \Cref{thm:second-taylor-regularized-sgd-simple-version} the prior $\pi$ is chosen to be a Gaussian distribution $\mathcal{N}(0,\sigma_\pi^2 I_d)$, thus, $\nabla^2 \log v_t = \nabla^2 \log u_t^S + 1/\sigma_\pi^2$. Therefore, in the case where a condition of the form $-b I_d \preceq \nabla^2\log(u_t^S) \preceq b I_d$ holds, \Cref{thm:second-taylor-regularized-sgd-simple-version} suggests to choose $\pi$ so that $\nabla^2 \log v_t \succeq 0$. Once such a prior is chosen, \Cref{ass:phi-regularity} remains the sole regularity condition conducing to \Cref{thm:second-taylor-regularized-sgd-simple-version}. 
% This transfers the complexity of the assumptions of \Cref{thm:second-taylor-regularized-sgd-simple-version} on whether \Cref{ass:phi-regularity} still holds with this choice of prior. 
As can be seen from the proof in \Cref{sec:proofs-singular-algorithms}, this positive semi-definite condition can be relaxed to $-\beta I_d \preceq \nabla^2 \log(u_t^S) \preceq \beta I_d$, at the cost of introducing dimension-dependent terms in the bound.
% and as long as there exists $b>0$ such that $0 \preceq \nabla^2 \log v_t$
% $-b I_d \preceq \nabla^2\log(u_t^S) \preceq b I_d$ (holds for Gaussian distributions), then we can choose $\sigma$ such that \Cref{ass:phi-regularity} holds. 
%so that the assumption reads: if $\nabla^2 \log u_t^S$ is bounded and we choose $\sigma$ such that $0 \preceq \nabla^2 \log v_t $, then if \Cref{ass:phi-regularity} still holds we can apply the theorem. 


Finally, we see that \Cref{thm:second-taylor-regularized-sgd-simple-version} relates the generalization error of SGD to the stochastic gradient norms, averaged over the posterior distribution. Similar quantities classically appear in the study of noisy SGD \citep{mou_generalization_2017,negrea_information-theoretic_2020,haghifam_sharpened_2020,dupuis_generalization_2024} and were already involved for non-noisy SGD in the bounds of \citet{neu_information-theoretic_2021}. Compared to \citep{neu_information-theoretic_2021}, the main advantage of \Cref{thm:second-taylor-regularized-sgd-simple-version} is the presence of the exponential decay $e^{-\lambda \eta (T - t)}$.

% \ben{
%     \begin{itemize}
%         \item $0 \preceq \nabla^2 \log(v_t)$ is a strong assumption because it in particular implies that the Radon-Nykodym derivative will be unbounded (and even explode)
%         \item That being said, while strong this assumption can still be compatible with the assumptions of our main theorems
%         \item The assumption can be relaxed at the cost of introducing dimension-dependence
%         \item Possibility to push further the Taylor expansion technique, it improves the bound but it introduces very intricate terms. Do we even present it in the appendix?
%     \end{itemize}
% }

% \ben{Possibility to push further the Taylor expansion technique, it improves the bound but it introduces very intricate terms. Do we even present it in the appendix?}



\section{Conclusion and Future Work}
We introduced a framework to understand the generalization error of Markov algorithms through Poissonization. We found a closed-form expression of the associated entropy flow and connected it with a class of modified log-Sobolev inequalities. We showed the relevance of such inequalities in several cases of interest. 
We further demonstrated the efficiency of our method for both noisy (\eg, SGLD and noisy SGD) and non-noisy algorithms (\eg, SGD).

\paragraph{Future directions.} We focused our analysis on KL-based bounds through the function $\Phi(x) = x\log(x)$ and modified LSIs. Another route would be to change $\Phi$ to $\Phi_2(x) := \normof{x}^2$, in which case our proof technique of \Cref{thm:psi-diffusive-priors} leads to a Poincaré (or spectral gap) inequality. Combined with the theory of Ricci curvature of Markov chains \citep{ollivier_ricci_2007}, this opens new research directions to obtain new generalization bounds and differential privacy guarantees. 
% 
Finally, the extension of Poissonization to other algorithms (like ADAM) is an important direction for future work. 
% $\ecal_\pi(f,f) \geq (1 - e^{-Kt_0}) \var_\pi (f)$, with $\var_\pi(f) := \Eof[\pi]{f^2} - \Eof[\pi]{f}^2$, when $\nabla^2 V \geq K I_d$, which for the Ornstein-Uhlenbeck process coincides with the inequality obtained by \citet[Corollary 30]{ollivier_ricci_2007} through his theory of Ricci curvature of a Markov chain. 

% \paragraph{Future directions.} We focused our analysis on KL-based bounds through the function $\Phi(x) = x\log(x)$ and modified LSIs. Another route would be to change $\Phi$ to $\Phi_2(x) := \normof{x}^2$, in which case our proof technique of \Cref{thm:psi-diffusive-priors} leads to a Poincaré (or spectral gap) inequality $\ecal_\pi(f,f) \geq (1 - e^{-Kt_0}) \var_\pi (f)$, with $\var_\pi(f) := \Eof[\pi]{f^2} - \Eof[\pi]{f}^2$, when $\nabla^2 V \geq K I_d$, which for the Ornstein-Uhlenbeck process coincides with the inequality obtained by \citet[Corollary 30]{ollivier_ricci_2007} through his theory of Ricci curvature of a Markov chain. This opens new research directions to obtain new generalization bounds and differential privacy guarantees.
% In particular, our entropy flow computations could be naturally extended to provide differential privacy guarantees. 
% Moreover, having a better understanding of other noise structures than those used in this paper and deriving the corresponding modified LSIs would greatly impact our framework.

% \umut{isn't adam markovian in the extended space?}
% \ben{Yes (with constant learning rate) but it is not obvious how the computations would work, in particular it seems to me that the distributions in the extended space are singular so the PAC-Bayes could not work, at least it might not be a trivial extension} \umut{I see, but saying non-markovian might be misleading} \ben{true, I suggest to just say we extend to other algorithms}\umut{ok}

% \begin{remark}[The spectral gap route]
% \umut{I think this can go to the conclusion} \ben{good idea}
%     In this study, we focus our analysis on the function $\Phi(x) = x\log(x)$ and, therefore, modified LSIs. This choice is well-adapted to KL-based PAC-Bayesian. Another route is to change $\Phi$ to $\Phi_2(x) := \normof{x}^2$, in which case the same proof technique as \Cref{thm:psi-diffusive-priors} leads to a Poincaré (or spectral gap) inequality $\ecal_\pi(f,f) \geq (1 - e^{-Kt^0})$ whenever $\nabla^2 V \geq I_d$, which for the discrete Ornstein-Uhlenbeck process coincides with the inequality obtained by \citet{ollivier_ricci_2007} through his theory of Ricci curvature of a Markov chain.
% \end{remark}


% Acknowledgments---Will not appear in the anonymized version
\acks{U.\c{S}. is partially supported by the French government under the management of
Agence Nationale de la Recherche as part of the ``Investissements d'avenir'' program, reference
ANR-19-P3IA-0001 (PRAIRIE 3IA Institute). B.D., M.H., and U.\c{S}. are partially supported by the European Research Council Starting Grant
DYNASTY – 101039676.}


\bibliography{main}

\clearpage

\appendix

The appendix is organized as follows:
\begin{itemize}[noitemsep]
    \item In \Cref{sec:diffusion-semigroups-background}, we present additional technical background related to semigroups and their infinitesimal generator, which we use in some of our proofs.
    \item In \Cref{sec:proofs-technical-background,sec:proofs-entropy-flow,sec:proofs-lsi,sec:proofs-applications}, we present all the omitted proofs of our main results.
    \item \Cref{sec:depoissonization} presents additional background on depoissonization, to complement the discussion of \Cref{sec:technical-background,sec:poissonization-entropy-flow}.
\end{itemize}

\section{Additional background on semigroup theory}
\label{sec:diffusion-semigroups-background}
% \label{sec:additional-technical-background}


% \subsection{Logarithmic Sobolev inequalities}
% \label{sec:lsi-additional-background}

% In this section, we remind the reader of the classical logarithmic Sobolev inequalities (LSI) and Poincaré inequalities. We also refer the reader to the very nice tutorial of \citet{chafai_logarithmic_2017}. A more in-depth introduction can be found in the book of \citet{bakry_analysis_2014}.

% While these classical results are different from the Poisson-Sobolev inequalities (PSI) that we use in this paper, they constitute a fundamental building block for proving PSIs for particular Markov processes. 

% Let us first give the definition of the $\Phi$-entropy.

% \begin{definition}
%     \label{def:phi_entropy}
%     Let $\Phi:\R_+ \to \R$ be a convex function and $\mu$ a probability measure on $\Rd$. for $f\in L^1$, we define the $\Phi$-entropy relatively to $\mu$ as:
%     \begin{align*}
%         \entphi{\mu}{f} := \int \Phi(f) d\mu - \Phi \left( \int f d \mu \right).
%     \end{align*}
%     Note that this may be infinite if $\Phi(f)$ is not $\mu$-integrable.
% \end{definition}

% When $\Phi(x) = \Phi_{\log}(x) := x \log(x)$, we recover the usual notion of entropy and simply denoted $\ent[\mu]{f}$. If $\Phi(x) = x^2$, $\entphi{\mu}{f}$ corresponds to the variance of $f$ relatively to $\mu$ and we denoted it $\var_\mu (f)$.

% Let us now state the logarithmic Sobolev inequality.

% \begin{definition}[Logarithmic Sobolev inequality (LSI)]
% \label{def:lsi}
%     Let $\nu$ be a probability measure on $\Rd$ and $\alpha > 0$. $\nu$ is said to satisfy the $\beta$-LSI if for every non-negative, smooth and integrable function $f:\Rd \to \R_+$, we have:
%     \begin{align*}
%        \ent[\nu]{f} \leq \frac1{2\beta}  \int \frac{\normof{\nabla f(x)}^2}{f(x)} \der \nu(x) .
%     \end{align*}
%     The integral appearing in the right-hand side of this inequality is the celebrated Fisher information, denoted as:
%     \begin{align}
%         \label{eq:fisher-information}
%         I_\nu (f) :=  \int \frac{\normof{\nabla f(x)}^2}{f(x)} \der \nu(x) .
%     \end{align}
% \end{definition}

% \begin{example}
%     \label{example:gaussian-LSI}
%     The distribution $\mathcal{N}(0,\sigma^2 I_d)$ satisfies $1/\sigma^2$-LSI, see for instance the introduction of \citep{chafai_logarithmic_2017}. The Gaussian logarithmic Sobolev inequalities has been first proven in the seminal work of \citet{gross_logarithmic_1975-1}.
% \end{example}



In this subsection, we briefly introduce Markov semigroups, to present concepts and notations that we use in some of our proofs. For elementary introductions, we refer the reader to the tutorials of \citet[Section 5]{schilling_introduction_2016} and, specifically for diffusion semigroups, \citet{chafai_logarithmic_2017}. More detailed accounts can be found in \citep{bakry_analysis_2014,xiao_random_2004}. 

In all this section, we consider the Banach space $\mathcal{C}_\infty$ of functions $\Rd \to \R$ that are continuous and vanish at infinity ($\lim_{\normof{x}\to\infty} f(x) = 0$), equipped with the uniform norm $\normof{\cdot}_\infty$.

A stochastic process $(X_t)_{t\geq 0}$ is a time-homogeneous Markov process if the law of $(X_s)_{s\geq t}$ given $(X_s)_{s\leq t}$ is the same as the law of $(X_s)_{s\geq t}$ given $X_t$ and the law of $(X_s)_{s\geq 0}$ given $X_0$. 

The semigroup of $X$ is a family of operators $(P_t : L^\infty(\Rd) \to L^\infty(\Rd))_{t\geq 0}$ defined as $P_t f(x) = \mathds{E}^x[f(X_t)]$, where $\mathds{E}^x$ means that the process is initialized by $X_0 = x\in\Rd$. This is called a semigroup because of the so-called semigroup property, \ie, $P_t \circ P_s = P_{s+t}$. 

\begin{definition}[Infinitesimal generators]
    \label{def:infinitesimal-generator}
    The generator $L$ of the semigroup $(P_t)_{t\geq 0}$ is defined as the following limit in $\left( \mathcal{C}_\infty, \normof{\cdot}_\infty \right)$:
    \begin{align*}
        Lf = \lim_{t \to 0} \frac{P_t f - f}{t}.
    \end{align*}
    The \emph{domain} $\mathcal{D}(L)$ of $L$ is the set of functions for which the above limit exists.
\end{definition}

Under appropriate conditions (see \Citep[Lemma 5.4]{schilling_introduction_2016}), $L$ satisfies the backward Kolmogorov equations $\frac{\der}{\der t} P_t f = LP_t f = P_t L f$, which we use in several places. These equations justify the (informal) exponential notation of the semigroup by $P_t = e^{tL}$.

% \begin{align*}
%     \frac{\der}{\der t} P_t f = LP_t f = P_t L f.
% \end{align*}


\begin{remark}[About $\mathcal{D}(L)$]
    In the above definitions, we used the Banach space $\mathcal{C}_\infty$, because it provides a good framework to define semigroups and generators properly \citep{schilling_introduction_2016}. For the semigroups we consider (Ornstein-Uhlenbeck and Langevin semigroups with regular enough potential) we mostly work in the space $\mathcal{C}^2_b(\Rd)$ of bounded twice continuously differentiable functions with bounded derivatives of order $1$ and $2$ \citep{chafai_logarithmic_2017}.
\end{remark}

Let us quickly give two examples of semigroups and generators of particular interest: Poissonized and Langevin semigroups.

\paragraph{Discrete-time Markov processes.} A stochastic process $(X_k)_{k\in\N}$ is a time-homogeneous Markov process if, for all $k\in\N$, the law of $X_{k+1}$ given $(X_0,\dots,X_k)$ is the same as the law of $X_{k+1}$ given $X_k$ and is independent of $k$. 

Let us provide a semigroup formulation of the Poissonization procedure displayed in \Cref{sec:technical-background}.

\begin{example}[Semigroup formulation of Poissonization]
    Let us consider a discrete-time Markov process $(X_k)_{k\in\N}$ with kernel $P$ and its Poissonization $(Y_t)_{t\geq 0}$ as defined in \Cref{sec:technical-background}. Then $(Y_t)_{t\geq 0}$ is a Markov process and we can consider its semigroup $(Q_t)_{t\geq 0}$. As noted by \citet[Section 2.1]{diaconis_logarithmic_1996}, it can be expressed as:
    \begin{align*}
        Q_t f(x) = e^{-t} \sum_{k=0}^{+\infty} \frac{t^k}{k!} P^k f(x)
    \end{align*}
    Moreover, the infinitesimal generator of the Poissonized semigroup is $L = P - I$.
\end{example}

\paragraph{Langevin semigroups.} Finally, let us consider the SDE $\der Z_t = -\nabla V(Z_t) \der t + \sqrt{2} \der B_t$, as in \Cref{def:representable-kernels}. Then the infinitesimal generator of $(Z_t)_{t\geq 0}$ is $Lf = \Delta f - \langle \nabla f, \nabla V \rangle$. Moreover, if we introduce the so-called ``carré du champ'' operator\footnote{The French term is used even in English \citep{bakry_analysis_2014,chafai_logarithmic_2017}.} $\Gamma(f) := \normof{\nabla f}^2$, then $L$ satisfies for smooth functions $\varphi,\psi: \Rd \to \R$ the following \emph{diffusion} property $L \varphi (f) = \varphi'(f) Lf + \varphi''(f) \Gamma (f)$, and the integration by part formula $\int \phi L \psi \der \pi = - \int \langle \nabla \varphi, \nabla \psi \rangle \der \pi$, where $\pi \propto e^{-V}$ is a reversible measure for the process.
% \begin{align*}
%     L \varphi (f) = \varphi'(f) Lf + \varphi''(f) \Gamma (f),
% \end{align*}
We refer the reader to \citep{bakry_analysis_2014,chafai_logarithmic_2017} for more background on diffusion semigroups and, in particular, the associated Poincaré and logarithmic Sobolev inequalities, which we will use in some proofs (with appropriate references).




% \subsection{Semigroup formulation of Poissonization}
% \label{sec:poissonization-semigroup-fornulation}

% \subsection{Stochastic integral formulation of Poissonization}
% \label{sec:stochastic-integral-formulation}



\section{Omitted proofs of \Cref{sec:technical-background}}
\label{sec:proofs-technical-background}

In this section, we provide the omitted proofs of the technical results mentioned in \Cref{sec:technical-background}, in particular the ``Boltzmann'' equation \eqref{eq:poisson-boltzmann}.
We start with the following technical lemma.

\begin{lemma}
    \label{lemma:technical-lemma-for-boltzmann}
    let $(X_k)_{k\in\N}$ be a sequence of absolutely continuous random variables in $\Rd$ with probability density functions (PDF) denoted $p_k$ and $(c_k)_{k\in\N}$ a sequence of positive numbers such that $\sum_{k\in\N} c_k = 1$. Let $Z$ be a random variable independent of $(X_k)_{k\in\N}$ s.t. $\forall k \in \N,~ \Pof{Z=k} = c_k$ and define $Y:=X_Z$. Then, the PDF of $Y$ is given by $x \mapsto \sum_{k\in\N} c_k p_k(x)$. In particular, the latter sum is almost surely finite in $\Rd$.
\end{lemma}

\begin{proof}
    Let $A \in \mathcal{B}(\Rd)$, we have:
    \begin{align*}
        \Pof{Y \in A} &= \Pof{\bigcup_{k=0}^{+\infty} \setof{X_Z \in A, Z = k} } \\
        &= \Pof{\bigcup_{k=0}^{+\infty} \setof{X_k \in A, Z = k} } \\
        &= \sum_{k=0}^\infty \Pof{X_k \in A, Z = k } \\
        &= \sum_{k=0}^\infty \Pof{X_k \in A} \Pof{Z = k }  \by{independence}\\
        % &= \sum_{k=0}^\infty \Pof{X_k \in A} c_k\\
        &= \int_A   \sum_{k=0}^\infty c_k p_k(x)  \der x.\by{Tonelli's theorem}
    \end{align*}
    By definition of the Radon-Nykodym derivative, we obtain the desired PDF for $Y$.
\end{proof}

We can now present the proof of the Boltzmann equation \eqref{eq:poisson-boltzmann}. It should be noted that the proof is formally similar to the proof of \citep[Equation $8.3.7$]{lasota_chaos_1994}, which we adapt to our setting. We report it here because both setups are slightly different and to justify our technical assumptions.

\begin{restatable}[Boltzman equation]{lemma}{boltzmann}
\label{lemma:boltzman-equation}
Let $(X_k)_{k\in\N}$ be a discrete-time Markov chain in $\Rd$ such that for all $k\in\N$, $X_k$ has a PDF denoted $p_k$. Let $(Y_t)_{t>0}$ be the Poissonized process as defined in \Cref{sec:technical-background}.
Then, $Y_t$ has a PDF $u_t(x)=u(t,x)$ which satisfies the following Boltzmann equation:
\begin{align*}
        \frac{\partial u_t}{\partial t} = (P^{\star} - I) u_t.
    \end{align*}
\end{restatable}

\begin{proof}
    Let $t>0$, we first apply \Cref{lemma:technical-lemma-for-boltzmann} with $Z = N_t$ and $c_k = e^{-t} t^k / k!$.
    % Let $A \in \mathcal{B}(\Rd)$, we also denote $p_k$ the density of $X_k$ with respect to the Lebesgue measure, which exists for all $k \geq 0$ by \Cref{ass:local-growth-assumption}. For all $t\geq 0$, we have:
    % \begin{align*}
    %     \Pof{Y_t \in A} &= \Pof{\bigcup_{k=0}^{+\infty} \setof{Y_t \in A, N_t = k} } \\
    %     &= \Pof{\bigcup_{k=0}^{+\infty} \setof{X_k \in A, N_t = k} } \\
    %     &= \sum_{k=0}^\infty \Pof{X_k \in A, N_t = k } \\
    %     &= \sum_{k=0}^\infty \Pof{X_k \in A} \Pof{N_t = k }  \by{independence}\\
    %     &= \sum_{k=0}^\infty \Pof{X_k \in A} e^{-t} \frac{t^k}{k!} \by{Poisson distribution}\\
    %     &= \int_A e^{-t}  \sum_{k=0}^\infty \frac{t^k}{k!} p_k(x)  \der x.\by{Tonelli's theorem}
    % \end{align*}
    Therefore, we have the following \textbf{expression of the density of $Y_t$}:
    \begin{align*}
        \boxed{
        u(t,x) = e^{-t} \sum_{k=0}^\infty \frac{t^k}{k!} p_k(x) .
        }
    \end{align*}
    Now let $a < b$ and consider $t \in (a,b)$, we apply again \Cref{lemma:technical-lemma-for-boltzmann} with $c_0 = 0$ and $c_k = e^{-b} b^{k-1} / (k - 1)!$  for $k\geq 1$, this gives in particular that the sum $\sum_{k\geq 1} b^{k-1} / (k - 1)! p_k(x)$ is finite for almost all $x\in \Rd$. Thus, we can differentiate under the sum \citep[Corollary 2.8.7]{bogachev_measure_2007} and obtain that for almost all $x\in\Rd$, we have:
    \begin{align*}
        \frac{\partial u}{\partial t} (t,x) &= - e^{-t} \sum_{k=0}^\infty \frac{t^k}{k!} p_k(x) + e^{-t} \sum_{k=1}^\infty \frac{t^{k-1}}{(k-1)!} p_k(x) \\
        &= -u(t,x) + e^{-t} \sum_{k=0}^\infty \frac{t^k}{k!} P^\star p_k(x),
    \end{align*}
    where we used that $p_{k+1} = P^\star p_k$ by the notations of \Cref{eq:ipp-markov-operator} (recall that $p_k$ denotes the PDF of $X_k$).  
    Using Tonelli's theorem twice, we get that for any $A \in \mathcal{B}(\Rd)$, we have:
    \begin{align*}
        \int_A e^{-t} \sum_{k=0}^\infty \frac{t^k}{k!} P^\star p_k(x) \der x &= e^{-t} \sum_{k=0}^\infty \frac{t^k}{k!}  \int_A P^\star p_k (x) \der x\\
        &= e^{-t} \sum_{k=0}^\infty \frac{t^k}{k!} \int P \mathds{1}_A (x)  p_k (x) \der x\\
        &= \int P \mathds{1}_A (x) u(t,x) \der x
        % &= \int_A P^\star u(t,\cdot) (x) \der x.
    \end{align*}
    Moreover, the function $x \mapsto \sum_{k\in\N} \frac{t^k}{k!} P^\star p_k(x)$ is Borel measurable as a limit superior of measurable functions.
    This shows that, if $\rho_t$ denotes the law of $Y_t$, then $\rho_t P$ has a PDF given by the preceding sum. 
    Thus, according to \Cref{eq:ipp-markov-operator}, we can write:
    \begin{align*}
        \int P \mathds{1}_A (x) u(t,x) \der x = \int_A P^\star u(t,\cdot) (x) \der x.
    \end{align*}
    This implies that for all $A \in \mathcal{B}(\Rd)$, we have:
    \begin{align*}
        \int_A \frac{\partial u}{\partial t} (t,x) \der x = \int_A \left\{ -u(t,x) + P^\star u(t,x) \right\} \der x.
    \end{align*}
    This finally implies the desired equation.
    % \begin{align*}
    %     \frac{\partial u}{\partial t} = (P^{\star} - I) u.
    % \end{align*}
\end{proof}

% Let us make the following remark about potential weakening of the assumptions of the above lemma.

\begin{remark}[Weak form of the Boltzmann equation]
    \label{rq:poisson-boltzmann-weak-form}
    Let us denote by $\rho_t$ the probability distribution of the Poissonized process $Y_t$. Then we can write:
    \begin{align}
    \label{eq:poisson-boltzmann-weak-form}
        \boxed{
            \frac{\partial \rho_t}{\partial t} = \rho_t (P - I) .
        }
    \end{align}
    \Cref{eq:poisson-boltzmann-weak-form} should be understood in a weak sense, \ie, for all test function $f$ we have:
    \begin{align*}
        \frac{\der}{\der t} \int f \der \rho_t = \int f \der (\rho_t P) - \int f \der \rho_t.
    \end{align*}
\end{remark}


\section{Omitted proofs of \Cref{sec:poissonization-entropy-flow}}
\label{sec:proofs-entropy-flow}

We first prove \Cref{prop:poissonization-invariant-measure-convergence}, concerning invariant measures of Poissonized processes.

\depoissonizationInvariant*

We use the convention: $\tv(\mu, \nu) := \sup_{A \in \borel} |\mu(A) - \nu(A)|$. 

\begin{proof}
    \textbf{First part of the statement.} Let us fix $S\in\zcal^n$ such that the convergences that are assumed almost surely hold (\ie, $\tv(\mu_k^S,\mu^S) \longrightarrow 0$).
    Let $\mu_k^S$ denote the law of $X_k^S$, we have, for any $A\in\borel$ (see \Cref{lemma:boltzman-equation}):
    \begin{align*}
        \rho_t^S(A) = e^{-t} \sum_{k=0}^{\infty} \frac{t^k}{k!} \mu_k^S(A).
    \end{align*}
    As $\mu_k^S$ converges to $\mu^S$ in total variation, for all $\varepsilon> 0$ there exists $K \in \mathds{N}$, such that for all $k\geq K$ and all $A \in \borel$,  $|\mu_k^S(A) - \mu^S(A)| \leq \varepsilon$ (\ie, $K$ does not depend on $A$). Therefore, we have:
    \begin{align*}
        \forall A \in \borel,~|\rho_t^S(A) - \mu^S(A)| \leq \varepsilon + 2 e^{-t} \sum_{k=0}^{K-1} \frac{t^k}{k!},
    \end{align*}
    where the last term is smaller than $\varepsilon$ for all $t$ greater than some $t_0(K)$, depending only on $K$. This shows that $\tv(\rho_t^S, \mu_S) \longrightarrow 0$, hence, by the triangle inequality and boundedness of $\ell$, we get:
    \begin{align*}
        \Eof{|G_S(X_k^S) - G_S(Y_k^S)| \big\vert S} \leq 2 \normof{\ell}_\infty \tv(\mu_k^S,\rho_k^S) \underset{k\to\infty}{\longrightarrow}  0 .
    \end{align*}

    Now we assume that there exists $C_S>0$ and $a_S \in (0,1)$ such that $\forall k \in \N,~ \tv (\mu_k^S,\mu^S) \leq C_S a_S^k$, then we have, for any $A\in\borel$:
    \begin{align*}
        |\rho_t^S(A) - \mu^S(A)| \leq e^{-t} \sum_{k=0}^{\infty} \frac{t^k}{k!}  |\mu_k^S(A) - \mu^S(A)| \leq C_S e^{-t} \sum_{k=0}^{\infty} \frac{(a_S t)^k}{k!} = C_S e^{-(1 - a_S) t}.
    \end{align*}
    Thus, by the triangle inequality for total variation, we get, for all $k \in \N$:
    \begin{align*}
        \tv(\mu_k^S, \rho_k^S) \leq \tv(\mu_k^S, \mu^S) + \tv(\rho_k^S, \mu^S) \leq C_Sa_S^k + C_Se^{-(1 - a_S) k} \leq 2C_Se^{-(1 - a_S) k} ,
    \end{align*}
    where we used that $a \leq e^{-(1 - a)}$, hence, $\Eof{|G_S(X_k) - G_S(Y_k)| \big\vert S} \leq 4 \normof{\ell}_\infty C_Se^{-(1 - a_S) k}$.

    \textbf{Second part of the statement.} We now assume that $\ell$ is $L$-Lipschitz continuous and use Wasserstein distance instead of $\tv$. We sketch the proof as it is similar to the previous case. The main argument, is that by convexity of the Wasserstein distance $W_1$ (see \citep[Lemma 2.3]{farghly_time-independent_2021} and \citep[Theorem 4.8]{villani_optimal_2009}), we have:
    \begin{align}
    \label{eq:wasserstein-convexity-poissonization}
    W_1(\rho_t^S, \mu_S) &=  W_1 \left(e^{-t} \sum_{k\in\N} \frac{t^k}{k!} \mu_k^S, e^{-t} \sum_{k\in\N} \frac{t^k}{k!} \mu^S \right) \\
    &\leq e^{-t} \sum_{k\in\N} \frac{t^k}{k!} W_1(\mu_k^S, \mu_S).
    \end{align}
Then, if we assume that $W_1(\mu_k^S, \mu^S) \longrightarrow 0$ and fix $\varepsilon > 0$, we know that there exists $K\in\N$ such that $\forall k \geq K,~ W_1(\mu_k^S, \mu^S) \leq \varepsilon$ and we obtain that $W_1(\rho_t^S, \mu_S) \longrightarrow 0$ by noting that:
\begin{align*}
    W_1(\rho_t^S, \mu_S) \leq \varepsilon + \left( \max_{0\leq k \leq K}  W_1(\mu_k^S, \mu^S) \right) e^{-t} \sum_{k=0}^{K-1} \frac{t^k}{k!} \longrightarrow 0.
\end{align*}
We conclude by Kantorovith duality \citep[Theorem 5.10]{villani_optimal_2009} and the triangle inequality.

Finally, under a Wasserstein ergodicity assumption, \ie, $W_1(\rho_t^S, \mu_S) \leq C_S a_S^k$ with $C_S>0$ and $a_S \in (0,1)$, \Cref{eq:wasserstein-convexity-poissonization} implies that $W_1(\rho_t^S, \mu_S) \leq C_Se^{-(1 - a_S)t}$. We conclude again by Kantorovith duality and the triangle inequality for $W_1$.

\end{proof}

% \ben{
% Wasserstein distance is jointly convex in its arguments, see \citep[Lemma 2.3]{farghly_time-independent_2021} and \citep[Theorem 4.8]{villani_optimal_2009}. So if we use the notations above and assume Wasserstein ergodicity we have:
% \begin{align*}
%     W_1(\rho_t^S, \mu_S) &=  W_1 \left(e^{-t} \sum_{k\in\N} \frac{t^k}{k!} \mu_k^S, e^{-t} \sum_{k\in\N} \frac{t^k}{k!} \mu^S \right) \\
%     &\leq e^{-t} \sum_{k\in\N} \frac{t^k}{k!} W_1(\mu_k^S, \mu_S) \\
%     &\leq e^{-t} \sum_{k\in\N} \frac{t^k}{k!} C a^k \\
%     &= Ce^{-(1 - a) t}.
% \end{align*}
% }

We can now prove our entropy flow formula, \ie, \Cref{thm:poissonized_entropy_flow}.

\thmPoissonizedFlow*

\begin{proof}
    In this proof, we use the notation $\partial_t$ as a shortcut for $\partial / \partial t$. We also recall the notation $\Phi(x) = x\log(x)$ (the reader may note that this proof is valid for more general convex functions $\Phi$). We also use the notations $L_S := P_S - I$ and $L := P - I$ (which correspond to the infinitesimal generators of the Poissonized processes). We denote accordingly $L_S^\star = P_S^\star - I$ and $L^\star = P^\star - I$.

    We start by noticing that \Cref{ass:phi-regularity} additionally implies $Pv_t \in L^1(\pi_t)$, indeed, if we let $y_0 = \inf_{y\geq 0} \setof{\Phi(y) \geq 1}$, we can show that $0\leq Pv_t \leq y_0 + \frac{2}{e} + P \Phi(f)$, which is in $L^1(\pi_t)$ by \Cref{ass:phi-regularity}.
    Thus, by \Cref{ass:domination} in \Cref{ass:phi-regularity} and \Cref{eq:ipp-markov-operator}, we obtain:
    \begin{align*}
        \frac{\der}{\der t} \klb{\rho^S_t}{\pi_t} &= \frac{\der}{\der t} \int \Phi(v_t) u_t \der x \\
         &= \int \Phi'(v_t) (\partial_t v_t) u_t \der x +  \int \Phi(v_t) (\partial_t u_t)  \der x\\
         &= \int \Phi'(v_t) L_S^\star u_t^S \der x - \int \Phi'(v_t) v_t L^\star u_t \der x +  \int \Phi(v_t) L^\star u_t  \der x\\
         &= \int L_S \left(  \Phi'(v_t) \right) u_t^S \der x - \int L \left(\Phi'(v_t) v_t \right)u_t \der x +  \int L \left(\Phi(v_t) \right) u_t  \der x\\
         &= \int L_S \left(  \Phi'(v_t) \right) u_t^S \der x\\
         & \hspace{-1cm} + \iint u_t(x) \left[ v_t(x) \Phi'(v_t(x)) - v_t(y) \Phi'(v_t(y)) + \Phi(v_t(y)) - \Phi(v_t(x)) \right] P(x, \der y) \der x.
    \end{align*}
    Note that by the fact that $Pv_t \in L^1(\pi_t)$ and \Cref{ass:phi-regularity}, all the integrals above are well-defined.
    By recognizing part of the desired Bregmann divergence, we obtain:
    \begin{align*}
         \frac{\der}{\der t} \klb{\rho^S_t}{\pi_t} &= \int L_S \left(  \Phi'(v_t) \right) u_t^S \der x - \int P \left(  \Phi'(v_t) \right) v_t u_t \der x + \int u_t v_t \Phi'(v_t)\der x  \\&\quad \quad -  \iint D_\Phi \left( v_t(x), v_t(y) \right) u_t(x) P(x, \der y) \der x,
    \end{align*}
    which leads to the result by recalling that $L=P-I$ and noting that by definition $L_S - L = P_S - P$ and $u_t v_t = u_t^S$ as well as the obvious fact that $\Phi'(x) = 1 + \log x$.
\end{proof}


\section{Omitted proofs of \Cref{sec:poisson-sobolev}}
\label{sec:proofs-lsi}

\subsection{Omitted proofs of \Cref{sec:bregman-to-lsi}}
\label{sec:proofs-bregman-to-lsi}

% We start by the proof of \Cref{cor:entropy-flow-semigroup-formulation}.

\corFlowSemigroup*

\begin{proof}
    Let $\Phi(x) = x\log(x)$. By \Cref{ass:phi-regularity} and invariance of $\pi$ under $P$, we have (with $f = v_t$):
    \begin{align*}
        \ecal_\pi(\Phi' \circ f,f) &= \int f (I - P) (\Phi'\circ f) \der \pi \\
            &= \iint f(x) (\Phi'(f(x)) - \Phi'(f(y))) P(x,\der y) \der \pi (x) \\
            &= \iint \left[ \Phi(f(x)) - \Phi(f(y)) + f(x) (\Phi'(f(x)) - \Phi'(f(y))) \right] P(x,\der y) \der \pi (x) \\
            &= \iint \left[ \Phi(f(x)) - \Phi(f(y)) + f(y) \Phi'(f(y)) - f(x)\Phi'(f(y)) \right] P(x,\der y) \der \pi (x) \\
            &= \iint D_\Phi (f(x),f(y)) P(x,\der y) \der \pi (x).
    \end{align*}
    This completes the proof.
\end{proof}

\thmGenericGeneralization*


\begin{proof}
    By the subgaussian assumption on the loss $\ell$, we can apply \Cref{thm:subgaussian-pac-bayes} to get that:
    \begin{align}
        \label{eq:proof-generic-bound-step-1}
        \Pof[S \sim \datadist]{\Eof[\rho_t^S]{G_S} \leq 2s \sqrt{\frac{\klb{\rho_t^S}{\pi} + \log(3/\zeta)}{n}}} \geq 1 - \zeta .
    \end{align}
    Now by \Cref{ass:phi-regularity}, we apply \Cref{cor:entropy-flow-semigroup-formulation}, which gives:
    \begin{align*}
        \frac{\der}{\der t} \klb{\rho_t^S}{\pi} = \Delta_{P,P_S}(v_t)- \ecal_\pi (\log (v_t), v_t) \leq \Delta_{P,P_S}(v_t) -\gamma \klb{\rho_t^S}{\pi},
    \end{align*}
    where the inequality follows from the modified LSI and noting that $\ent[\pi]{v_t}$. 
    % By the modified logarithmic Sobolev inequality (assumed in the theorem), we have:
    % \begin{align*}
    %     \frac{\der}{\der t} \klb{\rho_t^S}{\pi} \leq \Delta_{P,P_S,u_0}(t) -\gamma \ent[\pi]{v_t}.
    % \end{align*}
    Now we solve this differential inequality by looking at $F(t) := e^{\gamma t} \klb{\rho_t^S}{\pi}$. A simple calculation provides $ F'(t) \leq e^{\gamma t} \Delta_{P,P_S}(v_t)$. By integrating, we immediately obtain:
    \begin{align*}
        \klb{u_t^S}{\pi} \leq e^{-\gamma t} \klb{u_0}{\pi} + \int_0^t e^{-\gamma (t - s)} \Delta_{P,P_S}(v_s) \der s.
    \end{align*}
    The result follows by using this inequality inside \Cref{eq:proof-generic-bound-step-1}.
\end{proof}



\subsection{Omitted proofs of \Cref{sec:psi-diffusive-priors}}
\label{sec:proofs-psi-diffusive-priors}

For a probability measure $\nu$ and a function $f$, we recall the notation for the entropy functional:
\begin{align*}
    \entphi{\nu}{f} := \Eof[\nu]{\Phi(f)} - \Phi \left( \Eof[\nu]{f} \right).
\end{align*}

\thmPSIDiffusivepriors*

% \boxedthm{
% \begin{theorem}
%     \label{thm:inequalities-representable-kernels}
%     Let us assume that $P$ is representable by the diffusion $(H_t)$ at time $t_0 > 0$ and that it admits a reversible probability measure $\pi$. We further assume that $(H_t)$ satisfies the $\cd(K,\infty)$ condition for some $K>0$. Let $f \in L^1(\pi) \cap \mathcal{C}^2(\Rd, \R)$ be a positive function.
%     We have the modified logarithmic Sobolev inequality (in the sense of \Cref{def:dirichlet-modified-lsi}):
%     \begin{align}
%         \label{eq:log-sobolev-representable}
%         \ecal_\pi(\log(f), f) \geq \frac{e^{K t_0} - 1}{e^{Kt_0}} \ent[\pi]{f}.
%     \end{align}

%     We also have the Poincaré inequality, for $f\in L^2(\pi) \cap \mathcal{C}^2(\Rd, \R)$:
%     \begin{align}
%         \label{eq:poincare-representable}
%         \ecal_\pi(f, f) \geq 2 \frac{e^{K t_0} - 1}{e^{K t_0}} \var_\pi (f).
%     \end{align}
% \end{theorem}
% }

\begin{proof} In this proof, we use the function $\Phi(x) = x\log(x)$. We will use repeatedly the operator $\Gamma$ associated with the Langevin equation of \Cref{def:representable-kernels}, $\Gamma(\psi) := \normof{\nabla \psi}^2$. It has been briefly introduced in \Cref{sec:diffusion-semigroups-background}, see \citep{chafai_logarithmic_2017,bakry_analysis_2014} for more details.

 \textbf{Step 1: }Let $f\in \mathcal{C}^2(\Rd)$ satisfy the assumptions of the theorem.

    % We start the proof with slightly more general derivations, which may be of independent interest. Let $\Phi: \R_+ \to \R$ be any convex function satisfying \Cref{ass:assumption-on-phi} (it encompasses our main case of interest, \ie, $x\mapsto x^2$ and $x\mapsto x\log x$).
    
    Let $\ecal_\pi$ be the Dirichlet form associated to $P$, (see \Cref{cor:entropy-flow-semigroup-formulation}) and $(H_t)$ the diffusion semigroup representing $P$ in the sense of \Cref{def:representable-kernels}. We denote by $L_H$ the infinitesimal generator of $(H_t)$. It is known that the invariant measure $\pi$ is reversible for the semigroup $(H_t)$ \citep[Chapter 5]{chafai_logarithmic_2017} Using the concavity of $\Phi'$ we get:
    \begin{align*}
         \ecal_\pi(\Phi'\circ f, f) &= \int f \Phi'(f) \der \pi - \int f P \Phi'(f) \der \pi \\
         &= \int f \Phi'(f) \der \pi - \int f H_{t_0} \Phi'(f) \der \pi \by{representability} \\
          &= \int f \Phi'(f) \der \pi - \int H_{\frac{t_0}{2}}f H_{\frac{t_0}{2}} \Phi'(f) \der \pi \by{reversibility and semigroup property} \\
          &\geq \int f \Phi'(f) \der \pi - \int H_{\frac{t_0}{2}}f \Phi'( H_{\frac{t_0}{2}}f) \der \pi \by{Jensen's inequality} \\
          &= \int H_{\frac{t_0}{2}}(f \Phi'(f)) \der \pi - \int H_{\frac{t_0}{2}}f \Phi'( H_{\frac{t_0}{2}}f) \der \pi \by{invariance} \\
          &=: \bar{\ecal}_\pi (f).
    \end{align*}
    Note that $H_{\frac{t_0}{2}}f \Phi'( H_{\frac{t_0}{2}}f) \in L^1(\pi)$ in virtue of the inequalities $-1/e \leq H_{\frac{t_0}{2}}f \Phi'( H_{\frac{t_0}{2}}f) \leq H_{\frac{t_0}{2}}\Phi(f) + H_{\frac{t_0}{2}} f$, which is in $L^1(\pi)$ by \Cref{ass:phi-regularity}.
    
    We will now prove an inequality satisfied by $\bar{\ecal}_\pi (f)$.
    As a first step, we additionally assume that $f$ is bounded from below by a positive constant (\ie $f\geq \epsilon > 0$) and that $f$ is bounded and has bounded derivatives or order $1$ and $2$. This ensures that all the derivations below are justified.
    Let $\Psi(x) := x \Phi'(x) - \Phi(x)$, which is convex (for our choice of function $\Phi$, it is the identity) and obtain:
    \begin{align*}
         \bar{\ecal}_\pi (f) = \int \mathrm{Ent}^{\Psi + \Phi}_{H_{\frac{t_0}{2}}} \der \pi =  \int \entphi{H_{\frac{t_0}{2}}}{f} \der \pi + \int \mathrm{Ent}^\Psi_{H_{\frac{t_0}{2}}} (f) \der \pi 
         \geq \int \entphi{H_{\frac{t_0}{2}}}{f} \der \pi.
    \end{align*}
    Additionally, let's recall the following two classical computations, which follow from the diffusion property of $L_H$ and the integration by parts formula for $L_H$ \citep[Section 5]{chafai_logarithmic_2017}.
    \begin{align}
        \label{eq:derivative-entropy-1}
        \frac{\der}{\der t} \int \entphi{H_t}{f}(x) \der \pi(x) = - \int \Phi'(H_t f) L_H H_t f \der \pi = \int \Phi''(H_t f) \Gamma (H_t f) \der \pi,
    \end{align} 
    and by ergodicity we have $\entphi{H_0}{f} = 0 = \lim_{t \to \infty}  \entphi{\pi}{H_t f}$.
    Similarly:
    \begin{align}
        \label{eq:derivative-entropy-2}
        \frac{\der}{\der t} \entphi{\pi}{H_t f}  = \int \Phi'(H_t f) L_H H_t f \der \pi = - \int \Phi''(H_t f) \Gamma (H_t f) \der \pi.
    \end{align}  
    From \Cref{eq:derivative-entropy-1} we deduce that:
    \begin{align}
        \label{eq:lsi-proof-step-1}
         \bar{\ecal}_\pi (f) \geq \int \entphi{H_{\frac{t_0}{2}}}{f} \der \pi = \int_0^{\frac{t_0}{2}} \int \Gamma (H_s f) \Phi''(H_s f) \der \pi \der s.
    \end{align}

    \textbf{Proof of \Cref{eq:weak-modified-lsi}:} Now we can apply the logarithmic Sobolev inequality for $\pi$ to obtain:
    \begin{align*}
        \bar{\ecal}_\pi (f) &\geq \int_0^{\frac{t_0}{2}} \int \frac{\Gamma (H_s f)}{H_s f} \der \pi \der s  \\
        &\geq 2K \int_0^{\frac{t_0}{2}} \ent[\pi]{H_s f} \der s \\
        &= 2K \int_0^{\frac{t_0}{2}} \int_s^{+\infty} \int \frac{\Gamma (H_u f)}{H_u f} \der \pi \der u \der s \by{\Cref{eq:derivative-entropy-2} and ergodicity} \\
        &= 2K \int_0^{+\infty} \min \left( u, \frac{t_0}{2} \right) \int \frac{\Gamma (H_u f)}{H_u f} \der \pi \der u \\
        &\geq Kt_0\int_{\frac{t_0}{2}}^{+\infty} \int \frac{\Gamma (H_u f)}{H_u f} \der \pi \der u.
    \end{align*}
    Combining both inequalities gives us that, for any $a \in [0,1]$, we have:
    \begin{align*}
        \bar{\ecal}_\pi (f) \geq (1 - a) \int_0^{\frac{t_0}{2}} \int \frac{\Gamma (H_u f)}{H_u f} \der \pi \der u + a Kt_0\int_{\frac{t_0}{2}}^{+\infty} \int \frac{\Gamma (H_u f)}{H_u f} \der \pi \der u,
    \end{align*}
    which leads to:
    \begin{align*}
        \bar{\ecal}_\pi (f) &\geq \sup_{0 \leq a \leq 1} \min (1 - a, aKt_0) \int_{0}^{+\infty} \int \frac{\Gamma (H_u f)}{H_u f} \der \pi \der u \\
        &= \frac{Kt_0}{Kt_0+1} \ent[\pi]{f},
    \end{align*}
    where we used that by \Cref{eq:derivative-entropy-1}, we have:
    \begin{align*}
        \ent[\pi]{f} = \int_{0}^{+\infty} \int \frac{\Gamma (H_s f)}{H_s f} \der \pi \der s.
    \end{align*}
    \textbf{Case where $\nabla^2 V \succeq K I_d$:}
    Because of the strong convexity assumption on $V$, by \citep[Lemma 5.6]{chafai_logarithmic_2017}, we know that the semigroup $(H_t)_{t>0}$ satisfies the $\mathrm{CD}(K,\infty)$ conditions (see \citep{bakry_analysis_2014,chafai_logarithmic_2017}). 
    
    By the formula for $\bar{\ecal}_\pi (f)$ and the reversed local LSI \citep[Theorem 5.5.2]{bakry_analysis_2014} we have:
    \begin{align*}
        \bar{\ecal}_\pi (f) \geq \int \entphi{H_{\frac{t_0}{2}}}{f} \der \pi\geq \frac{e^{Kt_0} - 1}{2K} \int \frac{\Gamma (H_{\frac{t_0}{2}}f)}{H_{\frac{t_0}{2}}f} \der \pi.
    \end{align*}
    By the $\mathrm{CD}(K,\infty)$ condition and ergodicity of $\pi$, it is known that $\pi$ satisfies the (classical) LSI with constant $K$ \citep[Theorem 5.10]{chafai_logarithmic_2017}. Thus, by this LSI and \Cref{eq:derivative-entropy-2}, we get:
    \begin{align}
        \label{eq:lsi-proof-step-2}
       \bar{\ecal}_\pi (f) \geq \left( e^{Kt_0} - 1 \right) \ent{H_{\frac{t_0}{2}} f} = \left( e^{Kt_0} - 1 \right) \int_{\frac{t_0}{2}}^{+\infty} \int \frac{\Gamma (H_s f)}{H_s f} \der \pi \der s.
    \end{align}
    Combining \Cref{eq:lsi-proof-step-1} and \Cref{eq:lsi-proof-step-2}, we obtain as in the previous case that:
    \begin{align*}
       \bar{\ecal}_\pi (f) &\geq \sup_{a \in [0,1]} \min \left(a, (1 - a)\left(e^{Kt_0} - 1 \right) \right) \int_{0}^{+\infty} \int \frac{\Gamma (H_s f)}{H_s f} \der \pi \der s\\
        &= \frac{e^{Kt_0} - 1}{e^{Kt_0}} \int_{0}^{+\infty} \int \frac{\Gamma (H_s f)}{H_s f} \der \pi \der s.
    \end{align*}
    % which implies the desired inequality by noting that by \Cref{eq:derivative-entropy-1}:
    % \begin{align*}
    %     \ent[\pi]{f} = \int_{0}^{+\infty} \int \frac{\Gamma (H_s f)}{H_s f} \der \pi \der s.
    % \end{align*}

    \textbf{Step 2:} We have proven two inequalities of the form $\bar{\ecal}_\pi(f) \geq c_{\text{LSI}}\ent[\pi]{f}$ for functions $f$ satisfying the assumptions of the theorem and bounded from below and with bounded derivatives of order $0$, $1$ and $2$ (the constant $c_{\text{LSI}}>0$ depends on whether or not we assume $\nabla^2 V \succeq K I_d$). We finish the proof by classical approximation arguments, see for instance \citep{otto_generalization_2000}. 

    Let $f$ satisfy the assumptions of the theorem.
    First, we assume that $f$ is additionally bounded from below by some $\epsilon > 0$.
    Let $\varphi_n \in \mathcal{C}_c^\infty (\Rd)$ be a sequence of smooth functions with compact support such that $0 \leq \varphi_n \leq 1$ and $\varphi_n \longrightarrow 1$ pointwise (it can be constructed through the theorem of partitions of unity, see \citep[Theorem 2.17]{grubb_distributions_2009}). Let $f_n := \epsilon + \varphi_n (f - \epsilon)$. Then we have $|\Phi(f_n)| \leq f \left( 2 |\log(\epsilon)| + \log(f) \right) \in L^1(\pi)$, hence by the dominated convergence theorem:
    \begin{align*}
        \ent[\pi]{f_n} \longrightarrow \ent[\pi]{f}.
    \end{align*}
    By a similar argument, we have $\int H_{\frac{t_0}{2}}f_n \log H_{\frac{t_0}{2}} f_n \der \pi \longrightarrow \int Pf \log f \der \pi$. This is enough to extend the inequalities to functions $f$ that are bounded from below. 

    We now extend to general $f$ satisfying the assumptions of the theorem. For $n \geq 1$, let $\bar{f}_n := f_n + \frac1{n}$. Using the properties of $\Phi$, we prove that $-\frac1{e} \leq 2 |\Phi(f)| + 2\log(2) (1 + f) \in L^1(\pi)$, hence, by the dominated convergence theorem we have $\ent[\pi]{\bar{f}_n} \longrightarrow \ent[\pi]{f}$. We also clearly have $H_t f_n \to H_t f$ pointwise. Moreover, by Jensen's inequality, we have:
    \begin{align*}
        \frac{-1}{e} \leq H_{\frac{t_0}{2}}\bar{f}_n \log H_{\frac{t_0}{2}} \bar{f}_n \leq H_{\frac{t_0}{2}} (\bar{f}_n \log \bar{f}_n) \leq H_{\frac{t_0}{2}} \left( 2 |\Phi(f)| + 2\log(2) (1 + f) \right),
    \end{align*}  
    % for $n\geq 3$, the sequence of functions $\bar{f}_n := \max \setof{\frac1{n}, f}$ (note that using $\frac1{n}+f$ would also work). Using the properties of the function $\Phi :x \mapsto x \log(x)$, we prove that $\forall n \geq 3,~ |\Phi(\bar{f}_n)| \leq \frac1{e} + |\Phi(f)| \in L^1(\pi)$, hence, by the dominated convergence theorem we have $\ent[\pi]{\bar{f}_n} \longrightarrow \ent[\pi]{f}$. We also clearly have $Pf_n \to Pf$ pointwise. Moreover, by Jensen's inequality, we have:
    % \begin{align*}
    %     \frac{-1}{e} \leq P_{\frac{t_0}{2}}\bar{f}_n \log P_{\frac{t_0}{2}} \bar{f}_n \leq P_{\frac{t_0}{2}} (\bar{f}_n \log \bar{f}_n) \leq P \left( \frac1{e} + |\Phi(f)| \right),
    % \end{align*}
    hence, $H_{\frac{t_0}{2}}\bar{f}_n \log H_{\frac{t_0}{2}} \leq \frac{2}{e} + P (|\Phi(f)|) \in L^1(\pi)$. Therefore we conclude again by the dominated convergence theorem that $\int H_{\frac{t_0}{2}}\bar{f}_n \log H_{\frac{t_0}{2}} \bar{f}_n \der \pi \longrightarrow \int Pf \log f \der \pi$. This concludes the proof.
\end{proof}

% We now give the proof of \Cref{cor:psi-discrete-ornstein-Uhlenbeck}.

\corPSIGaussian*


\begin{proof}
    First, let us note that the Markov process $(X_k)_{k\in\N}$ admits an invariant distribution $\pi = \mathcal{N}(0,\sigma_\pi^2)$ with $\sigma_\pi := \sigma / \sqrt{1 - (1 - \gamma^2)}$.
    % \begin{align*}
    %     \sigma_\pi = \frac{\sigma}{\sqrt{1 - (1 - \gamma^2)}}.
    % \end{align*}
    Consider an Ornstein-Uhlenbeck process $\der Z_t = -V(Z_t)\der t + \sqrt{2} \der B_t$ with $V(x) := \frac{c}{2} \normof{x}^2$ and set:
    \begin{align*}
        c := \frac1{\sigma_\pi^2} = \frac{1 - (1 - \gamma)^2}{\sigma^2}, \quad t_0 := \frac1{c} \log \left( \frac1{1 - \gamma} \right).
    \end{align*}
    Let $(H_t)$ be the semigroup of $(Z_t)$.
    By Mehler's formula (see \citep{chafai_logarithmic_2017}), one may note that $P = H_{t_0}$ and that the invariant measure of $(Z_t)$ is $\pi$.    
    Finally, we note that $\nabla^2 V = c I_d$ and that $ct_0 = -\log(1 - \gamma)$.
    The inequality then follows from \Cref{thm:psi-diffusive-priors}.
\end{proof}

\section{Omitted proofs of \Cref{sec:applications}}
\label{sec:proofs-applications}

\propNoisyGenericBound*


\begin{proof}
    \Cref{thm:poissonized_entropy_flow} gives us that:
    \begin{align*}
        \frac{\der}{\der t} \klb{\rho_t^S}{\pi_t} = \Eof[x\sim \pi_t]{v_t (P_S - P) \log v_t} - \Eof[x\sim \pi_t, y \sim \delta_x P]{D_\Phi (v_t(x),v_t(y))}.
    \end{align*}
    By the inequality $a (\log a - \log b) - (a - b) \geq 0$, we have $v_t P(\log v_t) \leq v_t \log P v_t \leq v_t \log v_t - v_t + Pv_t$, which by \Cref{ass:phi-regularity} implies that $v_t  \log P v_t \in L^1(\pi_t)$ (we have proven that $Pv_t \in L^1(\pi_t)$ in the proof of \Cref{thm:poissonized_entropy_flow}).
    Therefore, by Donsker-Varadhan's formula, absolute continuity property, and the positivity of $v_t$ we have:
    \begin{align*}
        \forall x \in \Rd,~ P_S \log v_t (x) \leq \klb{\delta_x P_S}{\delta_x P} + \log P v_t(x).
    \end{align*}
    Therefore, using the expression of the Bregman divergence of $\Phi(x) = x\log(x)$, we can write:
    \begin{align*}
        \frac{\der}{\der t}\klb{\rho_t^S}{\pi_t} & \leq  ~\Eof[x\sim\rho_t^S]{\klb{\delta_x P_S}{\delta_x P}} + \Eof[x \sim \pi_t]{v_t (x) \log P v_t(x) - v_t(x) P\log v_t(x)} \\
         & \quad \quad - \Eof[x \sim \pi_t]{v_t(x)(\log v_t(x) - P\log v_t(x) ) - (v_t(x) - P v_t(x)) } \\
         &\leq \Eof[x\sim\rho_t^S]{\klb{\delta_x P_S}{\delta_x P}} - \Eof[\pi_t]{v_t \left( \log v_t - \log P v_t  \right) - \left( v_t - Pv_t \right)}.
    \end{align*}
    % Thus:
    % \begin{align*}
    %     \frac{\der}{\der t} \klb{\rho_t^S}{\pi_t} \leq \Eof[x\sim\rho_t^S]{\klb{\delta_x P_S}{\delta_x P}} - \Eof[\pi_t]{v_t \left( \log v_t - \log P v_t  \right) - \left( v_t - Pv_t \right)}.
    % \end{align*}
    The result follows by integrating and recognizing the Bregman divergence of $\Phi:x\mapsto x\log (x)$. Finally, we assume that $\pi$ is an invariant measure for $P$. As we assumed $\delta_x P \sim \mathrm{Leb}(\Rd)$, we can introduce the conditional density $p(y\vert x) \der y = P(x, \der y)$. By Bayes theorem and invariance of $\pi$, we can write $\pi(x) p(y\vert x) = \pi(y) q(x \vert y)$, where $q(x \vert y) \der x = P^\dag (y, \der x)$. We then conclude by:
    \begin{align*}
        \Eof[\pi]{v_t \left(\log v_t - \log Pv_t \right)} = \Eof[\rho_t^S]{\log \frac{u_t^S}{\pi}} - \Eof[\rho_t^S]{\frac1{\pi(x)}\int u_t^S(y) q(x \vert y) \der y} = \klb{\rho_t^S}{\rho_t^S P^\dag},
    \end{align*}
    where we recognized the integral to be the expression of the PDF of $\rho_t^S P^\dag$.
\end{proof}


\subsection{Proof of our bounds for SGLD}
\label{sec:proofs-sgld-bounds}

Before proving \Cref{thm:sgld-kl-bound}, we start by establishing the following more general result.


\begin{proposition}
    \label{prop:sgld-exponential-decay}
    Let's assume that the prior Markov kernel $P$ is representable in the sense of \Cref{def:representable-kernels}, \ie, there exists a diffusion semigroup $(P_t)_{t\geq 0}$ with reversible ergodic distribution $\pi$ and $t_0 > 0$ such that $P = P_{t_0}$. Assume further that $\nabla^2 V \succeq K I_d$ ($K>0$) with the notations of \Cref{def:representable-kernels} and that \Cref{ass:phi-regularity} holds for $K = P$, then we have:
    \begin{align*}
        \klb{\rho_T^S}{\pi} \leq \frac1{q} \int_0^T e^{-\frac{T - t}{\tau_0}}\Eof[x\sim\rho_t^S]{\klb{\delta_x P_S}{\delta_x P}}  \der t,
    \end{align*}
    with the constants $q$ and $\tau_0$ given by:
    \begin{align*}
        q =  \frac{1 - e^{-Kt_0} }{1 - e^{-2Kt_0}}, \quad   \frac1{\tau_0} = 1 - e^{-Kt_0}.
    \end{align*}
\end{proposition}

\begin{proof}
    The first step of the proof is a refinement of the proof of \Cref{prop:poissonized-flow-noisy-algorithm}. Let us denote by $\pi$ the reversible (and invariant) distribution of $(P_t)_{t\geq 0}$ and by $\lcal$ its infinitesimal generator. As before, we denote $L = P - I$ ($L$ is the generator of the Poissonized semigroup while $\lcal$ is the generator of the semigroup $(P_t)_{t\geq 0}$). Note that we have proven in the proofs of \Cref{thm:poissonized_entropy_flow} and \Cref{prop:poissonized-flow-noisy-algorithm} that \Cref{ass:phi-regularity} implies $v_t \log Pv_t \in L^1(\pi)$, which justifies the computations below.
    
    As $\pi$ is invariant under $P$, we can apply \Cref{cor:entropy-flow-semigroup-formulation} to write:
    \begin{align*}
        \frac{\der}{\der \tau} \klb{\rho_\tau^S}{\pi} = \Eof[\pi]{v_\tau(P_S - P) \log v_{\tau}} - \ecal_\pi (\log v_{\tau}, v_{\tau}),
    \end{align*}
    where we used $\tau$ as the time variable to avoid later confusion with $(P_t)_{t\geq 0}$.
    
     By Donsker-Varhadan formula, we have, for all $\tau > 0$, $S \in \zcal^n$, $q \in (0,1]$ and $x \in \Rd$:
    \begin{align}
        \label{eq:sgld-decay-step-1}
        P_S \log v_\tau (x) = \frac1{q} P_S \log \left(  v_\tau^q\right)(x) \leq \frac1{q} \klb{\delta_x P_S}{\delta_x P} + \frac1{q} \log \left( P (v_\tau^q)(x) \right).
    \end{align}   
    Note that Hölder's inequality implies that $v_\tau^q \in L^1(\delta_x P)$.
    Consider a differentiable function $q : [t_0/2, t_0] \to (0,1]$, which will be determined later.
    Let $f : \Rd \to \R$ be a $\mathcal{C}^2$ positive function s.t. $\forall x \in \Rd, ~ \log f \in L^1(\delta_x P)\cap L^1(\delta_x P_S)$ and $f\log f \in L^1(\delta_x P)$. We first assume that $f$ is bounded from below and has bounded derivatives of order $0$, $1$, and $2$. We introduce the quantity:
    \begin{align*}
        \alpha (t) := \frac1{q(t)} \log P_t \left( f^{q(t)} \right).
    \end{align*}
    Let us denote $g_t := P_t \left( f^{q(t)} \right)$, by the chain rule we have:
    \begin{align*}
        \alpha'(t) = - \frac{q'(t)}{q(t)^2} \log g_t + \frac1{q(t)} \frac{\lcal g_t}{g_t} + \frac{q'(t)}{q(t)} \frac{P_t \left( f^{q(t)} \log(f) \right)}{g_t}.
    \end{align*}
    Let us denote $\Gamma$ the carré du champ operator, \ie, in our case $\Gamma(\psi) := \normof{\nabla \psi}^2 $, see \Cref{sec:diffusion-semigroups-background}. By the diffusion property (see \citep[Section 5.4]{chafai_logarithmic_2017}), we have:
    \begin{align*}
        \alpha'(t) &= - \frac{q'(t)}{q(t)^2} \log g_t + \frac1{q(t)} \left( \lcal \log g_t + \frac{\Gamma(g_t)}{g_t^2} \right) + \frac{q'(t)}{q(t)} \frac{P_t \left( f^{q(t)} \log(f) \right)}{g_t} \\
        &= - \frac{q'(t)}{q(t)^2} \log g_t + \frac1{q(t)} \left( \lcal \log g_t + \frac{\Gamma(g_t)}{g_t^2} \right) + \frac{q'(t)}{q(t)^2} \frac{\ent[P_t]{f^{q(t)}} + g_t \log g_t }{g_t} \\
        &= \frac1{q(t)} \left( \lcal \log g_t + \frac{\Gamma(g_t)}{g_t^2} \right) + \frac{q'(t)}{q(t)^2} \frac{\ent[P_t]{f^{q(t)}}}{g_t}.
    \end{align*}
    Now we assume that $\forall t\geq 0, ~ q'(t) \leq 0$ and we note that by \citep[Lemma 5.6]{chafai_logarithmic_2017} $\nabla^2 V \succeq K I_d$ is equivalent to the semigroup $(P_t)_{t\geq 0}$ satisfying the $\cd(K,\infty)$ condition (see \citep{bakry_analysis_2014}). Thus, by the reverse local logarithmic Sobolev inequality \citep[Theorem 5.5.2 (v)]{bakry_analysis_2014}, we have:
    \begin{align*}
        \alpha'(t) \leq \frac1{q(t)} \left( \lcal \log g_t + \frac{\Gamma(g_t)}{g_t^2} \right) + \frac{q'(t)}{q(t)^2} \frac{e^{2Kt} - 1}{2K} \frac{\Gamma(g_t)}{g_t^2}.
    \end{align*}
    Based on this inequality, we choose the function $q$ on $t \in [t_0 / 2, t_0]$ to be (recall that $P = P_{t_0}$):
    \begin{align*}
       q(t) := \exp \left( - \int_{\frac{t_0}{2}}^{t} \frac{2K}{e^{2Ku} - 1} \der u \right).
    \end{align*}
    This leads to the following differential inequality, for all $t_0 / 2 \leq t \leq t_0$:
    \begin{align*}
        \alpha'(t) \leq \frac1{q(t)} \lcal \log(g_t) = \lcal \alpha(t).
    \end{align*}
    We can now write for $t_0 / 2 \leq s \leq t_0$ that:
    \begin{align*}
        \frac{\der}{\der s} \left( P_{t_0 - s} \alpha(s) \right) = - \lcal P_{t_0 - s} \alpha(s) + P_{t_0 - s} \alpha'(s) \leq - \lcal P_{t_0 - s} \alpha(s) + P_{t_0 - s} \lcal \alpha(s)  = 0,
    \end{align*}
    where we used that the semigroup $(P_t)_{t\geq 0}$ commutes with its infinitesimal generator $\lcal$. Therefore, the map $s \to P_{t_0 - s} \alpha(s) $ is decreasing. In particular, by using $q(t_0/2) = 1$ and the interpolation condition $P = P_{t_0}$ we have:
    \begin{align}
        \label{eq:sgld-proof-crucial-step}
       \frac1{q(t_0)} \log P \left( f^{q(t_0)} \right) =  \alpha (t_0) \leq P_{\frac{t_0}{2}} \alpha \left( \frac{t_0}{2} \right) = P_{\frac{t_0}{2}} \log P_{\frac{t_0}{2}} f.
    \end{align}
    By using similar classical approximation arguments as at the end of the proof of \Cref{thm:psi-diffusive-priors}, we extend the above inequality to positive twice continuously differentiable functions $f:\Rd \to \R$ such that $\forall x \in \Rd, ~ \log f \in L^1(\delta_x P)\cap L^1(\delta_x P_S)$ and $f\log f, fP\log (f) \in L^1(\pi)$. By reasoning as in the proof of \Cref{prop:poissonized-flow-noisy-algorithm}, this also implies that $f \log P(f^{q(t_0)}) \in L^1(\pi)$.
    By \Cref{ass:phi-regularity}, $v_\tau$ satisfies these conditions.
    Thus, by reversibility of $\pi$ under the semigroup $(P_t)_{t> 0}$, we have:
    \begin{align*}
       \frac1{q(t_0)} \Eof[\pi]{v_\tau\log P \left( v_\tau^{q(t_0)} \right)}  \leq  \Eof[\pi]{P_{\frac{t_0}{2}} v_\tau \log P_{\frac{t_0}{2}} v_\tau}.
    \end{align*}
    We now plug this into \Cref{eq:sgld-decay-step-1} and get:
    \begin{align*}
        \frac{\der}{\der \tau} \klb{\rho_\tau^S}{\pi} \leq \frac1{q(t_0)} \Eof[\rho_t^S]{\klb{\delta_x P_S}{\delta_x P}} &+ \Eof[\pi]{ P_{\frac{t_0}{2}} v_\tau\log P_{\frac{t_0}{2}} v_\tau - v_\tau P \log(v_\tau)} \\&+ 
        \Eof[\pi]{v_\tau P \log(v_\tau) - v_\tau \log v_\tau},
    \end{align*}
    which by invariance of $\pi$ under $P_{t_0/2}$ leads to:
    \begin{align*}
        \frac{\der}{\der \tau} \klb{\rho_\tau^S}{\pi} &\leq \frac1{q(t_0)} \Eof[\rho_t^S]{\klb{\delta_x P_S}{\delta_x P}} + \Eof[\pi]{P_{\frac{t_0}{2}} v_\tau \log P_{\frac{t_0}{2}} v_\tau - P_{\frac{t_0}{2}} \left( v_\tau \log(v_\tau) \right)} \\
        &= \frac1{q(t_0)} \Eof[\rho_t^S]{\klb{\delta_x P_S}{\delta_x P}} - \Eof[\pi]{\ent[P_{\frac{t_0}{2}}]{v_\tau}} .
    \end{align*}
    Finally, we note that $\Eof[\pi]{\ent[P_{\frac{t_0}{2}}]{v_\tau}} = \bar{\ecal}_\pi(v_\tau)$, where $\bar{\ecal}_\pi$ has been introduced in the proof of \Cref{thm:psi-diffusive-priors}. By the same proof we obtain:
    \begin{align*}
         \frac{\der}{\der \tau} \klb{\rho_\tau^S}{\pi} \leq \frac1{q(t_0)} \Eof[\rho_t^S]{\klb{\delta_x P_S}{\delta_x P}} - \left( 1 - e^{-K t_0} \right) \klb{\rho_\tau^S}{\pi}.
    \end{align*}
    We conclude by solving this differential inequality and using $\exp \left( \int_{\frac{t_0}{2}}^{t_0} \frac{-2K}{e^{2Ku} - 1} \der u \right) = \frac{1 - e^{-Kt_0}}{1 - e^{-2Kt_0}}$.
    % \begin{align*}
    %     \exp \left( \int_{\frac{t_0}{2}}^{t_0} \frac{2K}{1 - e^{2Ku}} \der u \right) = \frac{e^{-Kt_0} - 1}{e^{-2Kt_0} - 1}.
    % \end{align*}
\end{proof}

We can now prove \Cref{thm:sgld-kl-bound} as a corollary of the above proposition.

\thmSGLDKLBound*

\begin{proof}
    We apply \Cref{prop:sgld-exponential-decay} by introducing the same SDE as in the proof of \Cref{cor:psi-discrete-ornstein-Uhlenbeck}. The KL divergence $\klb{\delta_x P_S}{\delta_x P}$ is bounded by classical arguments, see \citep[Lemma 4]{neu_information-theoretic_2021}.
\end{proof}

\subsection{Omitted proofs of \Cref{sec:singular-algorithms}}
\label{sec:proofs-singular-algorithms}

Before stating the proof of \Cref{prop:first-term-bound-f-regular}, let's recall the definition of Wasserstein distance.

\begin{definition}[Wasserstein distance]
    \label{def:wasserstein}
    let $\mu$ and $\nu$ be two probability measures. We denote by $\Gamma(\mu,\nu)$ the set of all \emph{couplings} between $\mu$ and $\nu$. The Wasserstein's distance $W_2$ is then defined as:
    \begin{align*}
        W_2(\mu,\nu) = \inf_{\gamma \in \Gamma(\mu,\nu)} \left\{ \iint \normof{x - y}^2 \der \gamma(x,y)  \right\}^{\frac{1}{2}}.
    \end{align*}
\end{definition}

\propScoreWasserstein*

The proof is inspired by \citep[Proposition 1]{polyanskiy_wasserstein_2016} and \citet{raginsky_non-convex_2017}. 


\begin{proof}
Let $\gamma_x \in \Gamma (\delta_x P, \delta_x P_S)$ that is optimal (see for instance \citep{alfonsi_evolution_2016}) for the Wasserstein distance $W_2 (\delta_x P, \delta_x P_S)$ and $(U,V) \sim \gamma_x$. We denote by $\rho_t^S \otimes \gamma_x$ the joint distribution of $x \sim \rho_t^S$ and $(U,V) \sim \gamma_x$.

By the linear growth condition, we have almost surely:
\begin{align*}
    \log v_t(U) - \log v_t (V) &= \int_0^1 \langle \nabla \log v_t (s U + (1 - s)V), U - V \rangle \der s \\
    &\leq \normof{U - V} \left( \frac{c_1}{2} \normof{U} + \frac{c_1}{2} \normof{V} + c_2 \right). \by{Cauchy-Schwarz's inequality}
\end{align*}
By integrating over $\rho_t^S \otimes \gamma_x$ and using Cauchy-Schwarz and triangle inequalities we obtain:
\begin{align*}
    (P_S - P)(\log v_t)(x) &= \Eof[(U,V) \sim \gamma_x]{\log v_t(U) - \log v_t(V)} \\
                    &\leq \Eof[\rho_t^S]{W_2 (\delta_x P, \delta_x P_S)^2}^{\frac1{2}}\normof{\frac{c_1}{2} \normof{U} + \frac{c_1}{2} \normof{V} + c_2}_{L^2(\rho_t^S \otimes \gamma_x)} \\
                    &\leq \Eof[\rho_t^S]{W_2 (\delta_x P, \delta_x P_S)^2}^{\frac1{2}}\left(\frac{c_1}{2} \normof{P}_t + \frac{c_1}{2}\normof{P_S}_t + c_2 \right).
\end{align*}
\end{proof}


\subsection{Proof of \Cref{thm:second-taylor-regularized-sgd-simple-version}}

\thmTaylorRegularizedSGD*

Before providing the proof of this result, we introduce a few notations. We write the posterior and prior Markov operators in the following form:
\begin{align*}
    P_S f(x) = \Eof[U_1 \sim \nu_1]{g_S(x,U_1)}, \quad Pf(x) = \Eof[U_2 \sim \nu_2]{g_S(x,U_2)}
\end{align*}
% \begin{align*}
%     P_Sf(x) = \int_\Xi f(x - \eta g_S(x,\omega_1)) \der \nu_1 (\omega_1), \quad Pf(x) = \int_\Xi f(x - \eta g(x,\omega_2)) \der \nu_2 (\omega_2)
% \end{align*}
where $g$ and $g_S$ are called the stochastic gradient functions and the probability measures $\nu_1$ and $\nu_2$ represent the randomness of the stochastic gradients (recall that $S\in\zcal^n$ denotes the dataset). To simplify the notations, we introduce an arbitrary coupling $\nu \in \Gamma (\nu_1, \nu_2)$ between $\nu_1$ and $\nu_2$ and, up to a slight abuse of notations, we write $U := (U_1, U_2)$ and: 
\begin{align*}
    P_Sf(x) = \Eof[U]{f(x - \eta g_S(x,U))}\quad Pf(x) = \Eof[U]{f(x - \eta g(x,U))}.
\end{align*}
In the case of \Cref{thm:second-taylor-regularized-sgd-simple-version}, we have $g_S(x,U_1) := \widehat{g}_S(x,U_1) + \lambda x$ in the notations of \Cref{ex:noisy-sgd-noisy-algorithm} (and there is no additional noise, \ie, $\zeta_k = 0$), where $\widehat{g}_S(x,U)$ represents the unbiased stochastic gradient, and $g(x, U_2) = \lambda x + (\sigma/\eta) \mathcal{N}(0, I_d)$. 

Equipped with these notations, we derive the proof of \Cref{thm:second-taylor-regularized-sgd-simple-version}. These general notations show that our proof yields a more general result. The proof is based on a Taylor expansion technique of $v_t$. We note that different Taylor expansions have already been used for SGD \citep{dieuleveut_bridging_2018}.

\begin{proof}
    Consider the function $\Phi(x) = x\log(x)$. Let $S\in\zcal^n$, we denote the expansion term as before by $\Delta_{P,P_S} (v_t) := \Eof[\pi]{(P_S - P) (\Phi' \circ v_t) v_t}$.
%     \begin{align*}
%     A_S (f) := \Eof[\pi]{(P_S - P) (\Phi' \circ f) f}.
% \end{align*}
    By \Cref{ass:phi-regularity}, $v_t$ is twice continuously differentiable, thus, by Taylor expansions around $\eta=0$ of the functions $\eta \mapsto v_t(x - \eta g_S(x,U))$ and $\eta \mapsto v_t(x - \eta g(x,U))$, we can write:
    \begin{align*}
     \Delta_{P,P_S} (v_t) = -\eta \Eof[\pi]{ v_t\Phi''(v_t) \nabla v_t \cdot \Delta_S  } + \eta^2 \Eof[\pi]{ v_t(x) \int_0^1 (1 - u) \left( H^S_x(u) - H_x(u) \right) \der u },
    \end{align*}
    with $\Delta_S$ the expected gradient difference given by $\Delta_S(x) = \Eof[U\sim\nu]{ g_S(x, U) - g(x,U) }$.  
    The quantities $H_x^S$ and $H_x$ correspond to the following Hessian ``norms'', given by:
    \begin{align*}
        \left\{
        \begin{aligned}
        H_x^S (u) &= \Eof[U\sim\nu]{ g_S (x, U)^T \nabla^2 (\Phi'\circ v_t) (x - u\eta g_S(x,U)) g_S(x, U) } \\
        H_x (u) &= \Eof[U\sim\nu]{ g (x, U)^T \nabla^2 (\Phi'\circ v_t) (x - u\eta g(x,U)) g(x, U)}.
        \end{aligned}
        \right.
    \end{align*}
    In our case, because $\widehat{g}_S$ is an unbiased stochastic gradient, we simply have $\Delta_S = \nabla\er(x)$. By the assumptions on $\nabla^2 \log v_t$, this simplifies into:
    \begin{align*}
        \Delta_{P,P_S} (v_t) \leq -\eta \Eof[\rho_t^S]{ \langle \nabla \log v_t(x) ,  \nabla\er(x) \rangle } + \frac{\eta^2\beta}{2} \Eof[\rho_t^S \otimes \nu]{\normof{g_S(x,U)}^2}.
    \end{align*}
     By our assumptions on $\nabla^2 \log v_t$, we see that $\nabla \log v_t$ is in particular $\beta$-Lispchitz-continuous. Moreover, we note that $\nabla \log v_t(0) = \nabla \log u_t^S(0) $, as $v_t = u_t^S / \pi$ and $\pi$ is a centered Gaussian distribution. Therefore, we can write, by the Cauchy-Schwarz and triangle inequalities (we omit the randomness of the batch indices $U$ in $\widehat{g}_S(x)$ to simplify the notations):
     \begin{align*}
         \Delta_{P,P_S} (v_t) &\leq -\eta \Eof[\rho_t^S]{ \langle\nabla \log v_t(x) ,  \nabla\er(x) \rangle } + \frac{\eta^2\beta}{2} \Eof[\rho_t^S \otimes \nu]{\normof{\widehat{g}_S(x) + \lambda x}^2} \\
         & \leq \eta  \Eof[\rho_t^S]{ \left( \beta \normof{x} + \normof{\nabla \log u_t^S(0)} \right) \normof{\nabla \er(x)} } + \eta^2 \beta \Eof[\rho_t^S \otimes \nu]{\normof{\widehat{g}_S(x)}^2 + \lambda^2 \normof{x}^2} \\
         &\leq \eta \Eof[\rho_t^S \otimes \nu]{\left( \beta \normof{x} + \normof{\nabla \log u_t^S(0)} \right) \normof{\widehat{g}_S(x)} + \eta^2 \beta \left(  \normof{\widehat{g}_S(x)}^2 + \lambda^2 \normof{x}^2\right)},
     \end{align*}
     where the last line follows from Jensen's inequality.

     Finally, by \Cref{cor:psi-discrete-ornstein-Uhlenbeck}, the prior dynamics satisfies a modified LSI with constant $\gamma = \lambda \eta$. Therefore, we can directly conclude by applying \Cref{thm:generalization-under-modified-lsi}.

    
    % By Young's inequality and recalling that $v_t \der \pi := \der \rho_t^S$, we have that for any $C>0$:
    % \begin{align*}
    %     A_S(v_t) &\leq \frac{\eta C}{2} \Eof[\pi]{v_t \normof{\nabla \er}^2} + \frac{\eta}{2C} \Eof[\pi]{\frac{\normof{\nabla v_t}^2}{v_t}} + \frac{\eta^2\beta}{2} \Eof[\rho_t^S \otimes \nu]{\normof{g_S(x,\omega)}^2} \\
    %     &= \frac{\eta C}{2} \Eof[\rho_t^S]{\normof{\nabla \er}^2} + \frac{\eta}{2C} \Eof[\rho_t^S]{\normof{\nabla \log v_t}^2} + \frac{\eta^2\beta}{2} \Eof[\rho_t^S \otimes \nu]{\normof{g_S(x,\omega)}^2}.
    % \end{align*}
    % By our assumptions on $\nabla^2 \log v_t$, we see that $\nabla \log v_t$ is in particular $\beta$-Lispchitz-continuous. Moreover, we note that $\nabla \log v_t(0) = \nabla \log u_t^S(0) $, as $v_t = u_t^S / \pi$ and $\pi$ is a centered Gaussian distribution. By the triangle inequality and choosing $C = $, this gives:

\end{proof}


\section{Additional background on depoissonization}
\label{sec:depoissonization}

In this short subsection, complement the discussion of \Cref{sec:technical-background} on depoissonization, \ie, the process of deducing asymptotic properties of a Markov chain from bounds on the Poissonized distribution.
We present part of the analysis of \citet{jacquet_analytical_1998} on this matter. See \Cref{sec:technical-background} for additional references on this well-studied topic.

As in \Cref{sec:technical-background}, we denote $(Y_t)_{t\geq 0}$ the Poissonized version of a discrete-time process $(X_k)_{k\in\N}$.

We first note that, for an integrable function $f$, by Fubini's theorem and independence we have:
\begin{align*}
    \Eof{f(Y_t)} = \sum_{k=0}^\infty \Eof{f(X_k) \mathds{1}\setof{N_t = k}} = e^{-t} \sum_{k=0}^{+\infty} \Eof{f(X_k)} \frac{t^k}{k!}.
\end{align*}

We call such an expression a ``Poisson transform''.
Our theory typically provides bounds on quantities like $\Eof{f(Y_t)}$ (where $f$ is the generalization error $G_S$). In this context, the goal of depoissonization would be to obtain guarantees on $\Eof{f(X_k)}$ from these bounds on $\Eof{f(Y_t)}$.
To generalize the above formula, we consider a sequence $(g_n)_{n\in\N}$ and extend the Poisson transform to the whole complex plane as follows:
\begin{align}
    \label{eq:poisson-transform}
    \forall z \in \C, ~ \Tilde{G}(z) := e^{-z} \sum_{k=0}^{+\infty} g_k \frac{z^k}{k!}.
\end{align}
We make the following assumption on the Poisson transform. For technical background on complex analysis, we refer the reader to \citep{lang_complex_1999,freitag_complex_2005}.
\begin{assumption}
    \label{ass:poisson-entire-function}
    We assume that the series defining $\Tilde{G}(z)$ converges normally for all $z \in \C$ and that $\Tilde{G}$ is holomorphic in the entire complex plane, \ie, it is an entire function.
\end{assumption}

First note that $(g_n)_{n\in\N}$ can be reconstructed if we have full knowledge of $\Tilde{G}(z)$, at least on a countour around $0$ in $\C$. Indeed, if $C$ is a circle centered at $0$, we have, by Cauchy's formula \citep[Theorem 2.3.4]{freitag_complex_2005}:
\begin{align*}
    g_n = \frac{n!}{2 \pi i} \oint_C \frac{e^z \Tilde{G}(z)}{z^{n+1}} \der z = \frac{n!}{n^n 2\pi} \int_{-\pi}^\pi \Tilde{G}(ne^{it}) \exp \left( ne^{it} \right) e^{-nit} \der t.
\end{align*}
However, in most practical cases we have little information on the entire Poisson transform (\ie, we only know it on the real line). 
\citet{jacquet_analytical_1998} provided general results to derive the asymptotics of the initial sequence from that of $\Tilde{G}$, \ie, to show that $\Tilde{G}(k) \approx g_k$ when $k \to \infty$. 
The main difficulty is that the proof of such results requires asymptotics of the Poisson transform in regions that are bigger than the positive real line. This is formalized by the following definition.

\begin{definition}[Linear cones]
    \label{def:linear-cones}
    Let $|\theta| < \pi/2$, the $\theta$-linear cone is $\mathcal{S}_\theta := \setof{z \in \C, ~ |\arg (z)| \leq \theta}$.
    % \begin{align*}
    %     \mathcal{S}_\theta := \setof{z \in \C, ~ |\arg (z)| \leq \theta}.
    % \end{align*}
\end{definition}

Equipped with this definition, we can state a basic depoissonization. Note that \citet{jacquet_analytical_1998} also provide more general depoissonization results. For the sake of simplicity, we focus on the basic result.


\begin{theorem}[Basic depoissonization lemma, \citep{jacquet_analytical_1998}]
    \label{thm:basic-depoissonization}
    Assume that \Cref{ass:poisson-entire-function} holds and that there exists $|\theta| < \pi/2$, $A,B,R > 0$, $\beta \in \R$ and $\alpha < 1$ such that the following assumptions hold:
    \begin{enumerate}[noitemsep]
        \item For all $z \in \mathcal{S}_\theta$, we have $|z| > R \implies |\Tilde{G}(z)| \leq B |z|^\beta$.
        \item For all $z \in \C \backslash \mathcal{S}_\theta$, we have $|z| > R \implies |\Tilde{G}(z)e^z| \leq A e^{\alpha |z|}$.
    \end{enumerate}
    Then we have $g_k = \Tilde{G}(k) + \landau[k \to \infty]{k^{\beta - 1}}$.
\end{theorem}

For instance, if $(X_k^S)_{k\in\N}$ is the posterior dynamics (\ie, learning algorithm) for some $S\in\zcal^n$ as defined in \Cref{sec:poissonization-entropy-flow}, and we consider the associated Poisson transform:first version 
\begin{align*}
   \forall z \in \C,~ \Tilde{G}_S(z) := e^{-z}\sum_{k\in\N}^{\infty} \frac{z^k}{k!}\Eof{G_S(X_k^S)| S}.
\end{align*}
Then, if for all $S\in\zcal^n$, $\Tilde{G}_S$ satisfies the assumptions of \Cref{thm:basic-depoissonization} with a constant $\beta_S < 1$ and if $(Y_t^S)_{t\geq 0}$ denotes the Poissonized process (see \Cref{sec:technical-background}), then we have the following approximation of the generalization error by its Poissonized counterpart:
\begin{align}
    \label{eq:basic-depoissonization-generalization-error}
    \Eof{G_S(X_k^S)|S} =  \Eof{G_S(Y_k^S)|S} + \landau{\frac1{k^{1 - \beta_S}}}.
\end{align}
This result complements the depoissonization result obtained in \Cref{prop:poissonization-invariant-measure-convergence}.


% \begin{example}
%     In our main case of interest, if we assume that the function $$z \longmapsto \Tilde{G}(z) = e^{-z} \sum_{k=0}^{+\infty} \Eof[\acal]{G_S(X_k^S)} \frac{z^k}{k!}$$ satisfies the assumptions of \Cref{thm:basic-depoissonization}, we have:
%     \begin{align*}
%         \Eof[\acal]{G_S(X_k^S)} = \Tilde{G}(k) + \landau[k \to \infty]{k^{\beta - 1}} =  \Eof[\acal,N]{G_S(X_{N_k})} + \landau[k \to \infty]{k^{\beta - 1}},
%     \end{align*}
%     which would imply, if $\beta < 1$, that the generalization error of the Poissonized process approximates that of the ``true'' iterates.
% \end{example}


\crefalias{section}{appendix} % uncomment if you are using cleveref





\end{document}
