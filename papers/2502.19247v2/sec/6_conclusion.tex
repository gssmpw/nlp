\section{Conclusion}
% 在这篇文章中我们提出了Proxy Transformation，实时多模态点云增强模型，来解决ego-centric 3D visual grounding中的渲染点云的语义缺失和噪声较大的问题。借助deformable point clustering，模型可以集中场景中更加重要的目标区域，减少处理冗余点云带来的额外的计算开销，提高模型的效率，同时网格先验保留了适当的原始空间先验信息，缓解训练初期的不稳定问题。随后，注意到文本信息提供全局的相对位置关系，图像信息提供局部的语义细节within each submanifold，我们针对得到的点云子流形设计广义的proxy attention来对点云局部变换的生成进行引导。进而获取高质量的点云结构，优化后续特征空间的高维流形。额外的实验表明我们不仅超越了所有的现有方法，还极大地提高了注意力模块的计算效率，为EmbodiedScanbenchmark设置了新的sota。这些结果表明在ego-centric 3D visual grounding语境下，使用多模态信息实时增强点云结构的有效性与鲁棒性，为未来具身智能实现在真实场景中的人机交互提供新的insight。
In this work, we propose Proxy Transformation, a real-time multimodal point cloud enhancement model, to address issues of geometric loss and unexpected noise in 3D points within ego-centric 3D visual grounding. This approach yields a high-quality point cloud structure for feature learning. Extensive experiments show that our model not only outperforms all existing methods but also improves the computational efficiency of attention modules, setting a new SOTA on the EmbodiedScan benchmark.
These results demonstrate the effectiveness and robustness of using multimodal information for real-time point cloud enhancement in ego-centric 3D visual grounding, offering fresh insights for advancing embodied AI and enabling human-computer interaction in real-world environments.

%Through deformable point clustering, our model focuses on the most crucial target regions in the scene, reducing the extra computation overhead caused by redundant point clouds and improving efficiency. Additionally, a grid prior preserves essential original spatial information, mitigating early training instability. Recognizing that text information provides global positional relationships among different submanifolds and image information offers local semantic details within each submanifold, we designed generalized proxy attention to guide local transformations of the selected point cloud submanifolds. 