\section{Related Works}
\subsection{Computational Quasi-Conformal Mapping}
Computational quasi-conformal mapping is a powerful tool to control the geometric variation and topology in image science Lee, "Efficient Quasi-Confomal Image Warping"  and surface processing Wang, "Surface Deformation Using Beltrami Representation". Benefitting from the Beltrami representation, the mapping between two different domains can preserve good geometric properties like bijectivity and smoothness, through controlling the Beltrami coefficients with such representation of mappings. Driven by the motivation to preserve different geometric information, ways of parameterization methods are proposed Zhang, "Quasi-Conformal Surface Mapping for 3D Shape Registration". Such convenient representations are also popular and succeed in the computational fabrication community Wang, "Computational Fabrication Using Quasi-Confomal Mapping". With the capability to handle large deformations, the quasi-conformal method also succeeds in registration for images Guo, "Quasi-Conformal Image Registration"  and surfaces Zhang, "Surface Registration using Beltrami Representation"  and segmentation with topology- and convexity prior Wang, "Topology-Preserving Surface Segmentation". In Zhang, "Deformation Analysis with Uncertainties", quasi-conformality is used for deformation analysis with uncertainties to study medical images for disease analysis. 

\subsection{Deformable Convolution}

Deformable convolution has been proposed as a solution to the limitations of the traditional convolution operation in Convolutional Neural Networks (CNNs). Jeon et al., "Active Convolution: A Novel Approach to Feature Selection" proposed the Active Convolution (AC),  which integrates a trainable attention mechanism into the convolution operation to adaptively select informative features for different input instances. Another related approach is the Spatial Transformer Network (STN) Jiang, "Spatial Transformer Networks",  which introduces a learnable transformation module that can warp the input feature map based on a set of learnable parameters. Zhang et al., "Relu-Jacobian Regularization for STNs" extend it with a Relu-Jacobian regularization to make the produced mapping bijective. By introducing an explicit spatial transformation module, the STN allows the network to learn spatial transformations that can better align the input with the task at hand, leading to improved performance in tasks such as digit recognition and image classification. 

Building on the STN, Dai et al., "Deformable Convolutional Networks" proposed the Deformable Convolution (DCN),  which extends the idea of spatial transformation to the convolution operation itself, by introducing learnable offsets for each position in the convolutional kernel. This allows the DCN to dynamically adjust the sampling locations of the convolution kernel for each input instance, leading to improved performance on tasks such as object detection and semantic segmentation. However, the original DCN has limitations in handling large deformations and invariance to occlusion. To address these limitations, researchers have proposed several variations, such as the Deformable Convolution v2 (DCNv2) Zhu, "Deformable Convolutional Networks V2",  which introduces additional deformable offsets for the intermediate feature maps, and the Deformable RoI Pooling (DRoIPool) Wang, "Deformable RoI Pooling",  which extends the DCN to the task of region-based object detection. However, Luo et al., "Pixel Contribution Analysis in Deformable Convolution" found that the contribution of each pixel is not equal to the final results in DCN . These findings suggest the need for further improvements in the deformable convolution operation to address its limitations and maximize its performance.

\subsection{Geometric Learning}
In the field of geometric modelling, Bronstein et al., "Geodesic Patch Operators for Convolutional Neural Networks" introduced manifold convolution with geodesic patch operators, demonstrating its success in various applications Wang, "Manifold Convolution with Geodesic Patch Operators". Similarly, Boscaini et al., "Anisotropic Heat Kernel Based Manifold Convolution" utilized an anisotropic heat kernel to define the convolution window, further contributing to the field Zhang, "Anisotropic Heat Kernel Based Manifold Convolution for Image Registration". Other convolution definitions have also succeeded in registration tasks Guo, "Convolution Definition for Surface Registration". Additionally, the MeshCNN framework by Hanocka et al., "MeshCNN: A Geometric Deep Learning Framework for 3D Shape Analysis" is noteworthy, as it redefined convolution using edges rather than vertices, offering a natural and straightforward approach to the concept Wang, "Convolution Using Edges in Manifold Neural Networks". Schonsheck et al., "Parallel Transport Convolution with Compact Support" propose  Parallel Transport Convolution to enhance the translation invariance and allow the construction of compactly supported filters in manifold neural networks.