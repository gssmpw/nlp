\section{Experiments}
This section provides the details of the implementation of our experiments and discusses their results. We evaluate the performance of our proposed model in comparison with other methods, such as PTCNet and GCNN. The experiments encompass a variety of tasks, including image classification on manifolds, craniofacial analysis, and segmentation of facial lesions. Additionally, to analyze the impact of different network architectures and hyperparameter configurations, we conduct ablation studies to test our model under various setups.

The experimental setting is described in detail below.

\noindent\textbf{Computational Resources and Parameters}
The training parameters are set as follows: \(\lambda_\text{bc} = 0.01\), \(\lambda_\text{lap} = 0.0001\), and the learning rate \(lr = 1.0 \times 10^{-5}\). The training is conducted on a CentOS 8.1 central cluster computing node equipped with two Intel Xeon Gold 5220R 24-core CPUs and two NVIDIA V100 Tensor Core GPUs.

\noindent\textbf{Conformal Convolutional Neural Network} The proposed model's ability to learn an adaptive convolution through the mapping $f$ in Equation \eqref{eq:formulationQCCNNsingle} is a key advantage. To assess the benefits of these learnable features, we also evaluate a baseline approach, the Conformal Convolutional Neural Network (CCNN), which relies solely on a non-trainable parametrized manifold convolution operation from conformal parameterization as introduced by Definition \ref{def:conformalconv}. By comparing results from CCNN and our model across various experiments, we reveal the significant advantages brought by the learned optimal parametrized manifold convolution.
%In the CCNN framework, a standard 2D CNN is directly applied to the parametrized feature map $\tilde{h}$ without incorporating quasi-conformal mapping estimation to deform the shape of convolution kernels.
\subsection{Image Classification on Riemann Surfaces}
\input{tClassification}

%In this section, we evaluate the performance of our method on classification tasks using the MNIST dataset, which contains 60,000 handwritten digits. To conduct our experiments, we project these images onto randomly generated 2D manifolds. To demonstrate the versatility of QCCNN on different types of surfaces, we test on both simple and complex surfaces.
In this section, we evaluate the performance of our proposed method on image classification tasks involving MNIST digits mapped onto Riemann surfaces. The MNIST dataset consists of 60,000 handwritten digits spanning ten classes (0-9). To assess the effectiveness of QCCNN, we conduct experiments on Riemann surfaces exhibiting both simple and complex geometric structures.
Simple surfaces are relatively flat, making the classification tasks of MNIST data on them easier. In contrast, complex surfaces are irregular and exhibit significant geometric fluctuations, posing substantial challenges for the classification tasks. Examples of these surfaces with MNIST digits on them are shown in Figure~\ref{fig:mnist_surfaces}. 

For comparison, we benchmark our results against GCNN and PTCNet in Table \ref{tb:classification}. All networks are designed to include only one convolutional layer and one fully connected layer, consistent with the approach in \cite{schonsheck2022parallel}, to ensure a fair evaluation. Our network structure is illustrated in Figure \ref{fig:diagram1}. The network takes the geometric information of the surface, including Gaussian curvature and mean curvature, together with the texture information as the input to output the optimal quasi-conformal map associated with the best parameterized manifold convolution for the classification task.

In practice, we first compute the curvatures of the surface \cite{Dastan2025}, and then map the surface to a 2D domain \cite{meng2016conformal} as the input of both the estimator and the classifier. In the training stage, the batch size is fixed at 64 for all models. For QCCNN, we first train the classifier independently for 500 epochs, followed by alternating training of the classifier and the estimator for another 500 epochs, with the training alternating every 100 epochs. The loss function is given by

\begin{equation}\label{loss_total}
    \mathcal{L}_\text{total} = \lambda_\text{entropy} \mathcal{L}_\text{entropy} + \lambda_\text{bc} \mathcal{L}_\text{bc} + \lambda_\text{lap} \mathcal{L}_\text{lap},
\end{equation}
where $\mathcal{L}_\text{entropy}$ is the cross entropy loss and $\mathcal{L}_\text{bc}$ and $\mathcal{L}_\text{lap}$ are as defined in Equation (\ref{eq:losses}). $\lambda_\text{entropy}=1$, $\lambda_\text{bc}=0.01$ and $\lambda_\text{lap}=0.0001$ are positive weighting coefficients.

\begin{figure}
    \centering
    \includegraphics[width=\linewidth]{im/mnist_surfaces3_edit.png}
    \caption{MNIST images printed on simple surfaces (left) and complex surfaces (right)}
    \label{fig:mnist_surfaces}
\end{figure}

\begin{figure}
    \centering
    \includegraphics[height=50mm]{im/diagram1.png}
    \caption{Illustration diagram of QCCNN for classification of MNIST on Riemann surfaces.}
    \label{fig:diagram1}
\end{figure}

\subsubsection{Classification on Simple Manifold}
For simple surfaces, we generate them using basic trigonometric functions to produce $z$-coordinate in a range of $[-0.2,0.2]$ given $x \in [0,1]$, $y \in [0,1]$, which is similar to the approach in PTCNet experiments. 
% For instance, the surfaces are the graphs of $z = r \cos(\alpha x + x_0) \sin(\beta y + y_0)$ and $z = r \cos(\alpha x + x_0) + r \sin(\beta y + y_0)$. The constants $r, \alpha, \beta$ are randomized while $r$ should be limited so that $z \in [0,0.2]$ for every $x \in [0,1]$, $y \in [0,1]$.

Two distinct setups are considered for simple manifolds: single-simple and multi-simple. In the single-simple setup, we use a single surface for both training and testing. In contrast, the multi-simple setup involves training on four surfaces and testing on a different, unseen surface. These setups are inspired by \cite{schonsheck2022parallel}, and the results for GCNN and PTCNet are taken from the same reference. As shown in Table \ref{tb:classification}, our model achieves the highest accuracy, outperforming both PTCNet and GCNN.

\subsubsection{Classification on Complex Manifold}
For complex surfaces, we first randomly sample 24 points within $[-0.2, 1.2]^2 \subset \mathbb{R}^2$, which contains the unit square $[0,1]^2$. Then, each point is assigned with a random height value in $[-0.4,0.4]$ as the $z$-coordinate. The surface $S$ is then constructed through biharmonic spline interpolation among these points and the subset $S'=\{(x,y,z) \in S : (x,y) \in [0,1]^2\} \subset S$ is the desired surface for the learning task. Such cropping ensures that any over-fluctuating boundary can be removed, but $S$ may still contain some points with $z$-coordinate outside $[-0.4,0.4]$. Due to the significantly larger range and variance of $z$-coordinates compared to simple surfaces, these complex surfaces are much more irregular and challenging, posing a significant test for surface learning models.

As with the experiments for simple manifolds, two setups are considered: single-complex and multi-complex. In the single-complex setup, one surface is used for both training and testing. In the multi-complex setup, 50 surfaces are used for training, and another set of 50 unseen surfaces is used for testing.

We follow the same training protocol for QCCNN as used in the simple manifold experiments. As shown in Table \ref{tb:classification}, our model achieves the highest accuracy, surpassing both GCNN and PTCNet.


\subsection{Craniofacial Analysis}
\input{tCraniofacial}



\begin{figure}
    \centering
    \includegraphics[height=50mm]{im/diagram2.png}
    \caption{Illustration diagram of QCCNN for craniofacial analysis.}
    \label{fig:diagram2}
\end{figure}

\begin{figure}
    \centering
    \includegraphics[width=\linewidth]{im/faceosa_example.png}
    \caption{Craniofacial analysis examples for faces with different nasal structures.}
    \label{fig:faceosa}
\end{figure}
Craniofacial analysis aims to study the structure and relationships of the bones and tissues of the skull and face, with important applications in orthodontics, forensic science, reconstructive surgery, and medical image analysis. For instance, craniofacial analysis has been used to study nasal structure to evaluate facial asymmetries, plan surgical interventions, and serve as an excellent clinical parameter for various orthodontic treatments \cite{nehra2009nasal,burstone1958integumental} and disease diagnoses \cite{matthews2022static}.

A dataset of 2D human facial surfaces is used, consisting of two groups with 500 subjects each. Each group exhibits distinct nasal structural patterns that may include variations in size, symmetry, and other characteristics. Among these samples, 70\% are used for training, while the remaining 30\% are reserved for testing. Representative examples from the two groups, showing different nasal structural patterns, are presented in Figure \ref{fig:faceosa}.

%Since our model learns the optimal parametrized manifold convolution tailored to different surface geometries, it is particularly advantageous for tasks where classification heavily depends on data in different complex geometries. A notable application is craniofacial analysis. Studies have shown that craniofacial geometry, particularly the shape and size of the nose, serves as an excellent clinical parameter for assessing the anteroposterior position of the maxilla \cite{nehra2009nasal,burstone1958integumental}.
%and for the early prediagnosis of obstructive sleep apnea \cite{cetinoglu2019three}.

%In this experiment, we classify individuals by the size of their noses, which can accelerate the clinical measurement and diagnosis \cite{matthews2022static}. Specifically, we synthesize a dataset comprising 500 small-nose faces and 500 normal-nose faces. The data is generated using the 3D Morphable Model (3DMM) framework \cite{blanz2003face}, where the parameter controlling the nose size is adjusted to simulate the two groups. Among these samples, 70\% is used for training, and the remaining 30\% is reserved for testing. Representative examples are presented in Figure \ref{fig:faceosa}, with the left 2 columns exhibiting faces with small noses and the right 2 columns exhibiting faces with normal-sized noses.
During the parameterization process, each 3D facial surface is mapped to a 2D image of size $128 \times 128$. For the classification task, we use a neural network architecture comprising two convolutional layers and three fully connected layers, as shown in Figure \ref{fig:diagram2}. Gaussian curvature and mean curvature, which together provide a comprehensive set of geometric descriptors of the Riemann surface, along with texture information, are input into the network. The network outputs the quasiconformal mapping associated with the optimal QCC and the classification result. A batch size of 50 is used for training. For QCCNN, the classifier and estimator are trained alternately for 100 epochs each, resulting in a total of 1000 epochs. As in the previous experiment, Equation \ref{loss_total} is used as the loss function for this classification task.
%During the parameterization process, each 3D facial surface is mapped into a 2D image of size $128 \times 128$. For the classification task, we employ a neural network architecture consisting of two convolutional layers and three fully connected layers, as shown in Figure \ref{fig:diagram2}. The feature maps extracted during the process from texture information, Gaussian curvature, and mean curvature, provide a comprehensive set of geometric descriptors. A batch size of 50 is used for training. For QCCNN, we train the classifier and estimator alternatively for 100 epochs each, for a total of 1000 epochs. Similar to the previous experiment, Equation \ref{loss_total} is used as the loss function of this classification task.

The results of this study, as summarized in Table \ref{tb:Craniofacial}, demonstrate that our QCCNN outperforms Parallel Transport Convolutional Networks (PTCNet), Geodesic Convolutional Neural Networks (GCNN), and Conformal Convolutional Neural Networks (CCNN) in classifying nasal structural differences on Riemann surfaces. This improvement can be attributed to the flexibility of the QCCNN framework, which dynamically adapts convolution operations based on both texture and geometric information through the use of quasi-conformal mappings. Unlike traditional networks and CCNN, which rely on predefined convolution operations, QCCNN enables the convolution process to account for subtle variations in different surface geometries. This adaptability enhances the ability of the model to extract discriminative features, resulting in superior performance.
%The results of this study, as summarized in Table \ref{tb:Craniofacial}, demonstrate that our QCCNN outperforms Parallel Transport Convolutional Networks (PTCNet), Geodesic Convolutional Neural Networks (GCNN) and Conformal Convolutional Neural Networks (CCNN) in classifying nasal structural differences on Riemann surfaces. This improvement can be attributed to the flexibility of the QCCNN framework, which dynamically adapts convolution operations based on both texture and geometric information through the use of quasi-conformal mappings. Unlike traditional networks and CCNN, which rely on predefined convolution operation, QCCNN enables the convolution process to account for subtle variations in different surface geometries. This adaptability enhances the model's ability to extract discriminative features, resulting in superior performance.



\subsection{Facial Lesion Segmentation}
\label{sec:self_ablation}

\input{tFaceSeg}

\begin{figure}
    \centering
    \includegraphics[height=50mm]{im/diagram3.png}
    \caption{Illustration diagram of QCCNN for face lesion experiment.}
    \label{fig:diagram3}
\end{figure}

\begin{figure}
    \centering
    \includegraphics[width=\linewidth]{im/facelesion_result.png}
    \caption{Qualitative comparison of facial lesion segmentation results.}
    \label{fig:facelesion}
\end{figure}

Segmentation on Riemann surfaces has a broad range of applications, including skin lesion segmentation, facial feature extraction, and medical image analysis. In this experiment, we evaluate our proposed framework for the segmentation task on Riemann surfaces. Specifically, we apply our framework to segment skin lesions on human faces. The experiments are conducted on a dataset of 4000 human faces with skin lesions located in various regions. Each face is accompanied by a ground truth segmentation mask. Of the 4000 labeled samples, 3200 are used for training, while the remaining 800 are reserved for testing the supervised surface segmentation deep neural network. 

To evaluate the necessity and advantages of incorporating quasi-conformal mappings within our QCC framework, we compare its performance against the Geodesic Convolutional Neural Network (GCNN) and the Conformal Convolutional Neural Network (CCNN). The results highlight the importance of learnable convolutions enabled by QCCNN and demonstrate its significant benefits over alternative methods.
%Face lesions are critical to be detected and diagnosed early due to their potential impact on health. Accurate segmentation of facial lesions helps monitor their progressions and treatment planning. Automatic segmentation of facial lesions is especially important because it enables consistent and rapid analysis, reducing the need for manual intervention. 

%To demonstrate the effectiveness of our method, we apply it to face lesion segmentation tasks. The dataset was synthesized using a 3D Morphable Model (3DMM) \cite{blanz2003face} to generate human face surfaces. Random regions within each face are selected as lesion areas. Lesion regions from the HAM10000 \cite{tschandl2018ham10000} dataset are extracted using their masks and superimposed onto the selected regions of the human faces. To simulate the effect of lesions on the face geometry, vertical displacements proportional to the relative colors of the lesions are applied to the face surfaces. Among the synthesized $4000$ pairs of data, $3200$ of them are used for training and the remaining $800$ are used for testing. Comparisons are made with the Geodesic Convolutional Neural Network (GCNN) and Conformal Convolutional Neural Network (CCNN) to evaluate the necessity and advantages of incorporating quasi-conformal mappings within our QCC framework. These comparisons underscore the importance of learnable convolutions enabled by QCCNN and highlight its significant benefits.

During the parameterization stage, the surfaces are conformally mapped into images of size $128 \times 128$. The training process is conducted with a batch size of 50. The architecture of the QCCNN for the segmentation task on Riemann surfaces is illustrated in Figure \ref{fig:diagram3}. The network incorporates QC estimators to compute the quasiconformal mappings associated with the optimal QC convolution for each input surface. A UNet architecture with three downsampling layers is employed for segmentation. The inputs to the network include texture information, Gaussian curvature, and mean curvature. The loss function is given by

\begin{equation}\label{loss_seg}
    \mathcal{L}_\text{seg} = \lambda_\text{mse} \mathcal{L}_\text{mse} + \lambda_\text{bc} \mathcal{L}_\text{bc} + \lambda_\text{lap} \mathcal{L}_\text{lap},
\end{equation}
where $\mathcal{L}_\text{mse}$ is the mean square loss and $\mathcal{L}_\text{bc}$ and $\mathcal{L}_\text{lap}$ are as defined in Equation \ref{eq:losses}. $\lambda_\text{mse}=100$, $\lambda_\text{bc}=0.01$ and $\lambda_\text{lap}=0.0001$ are positive weighting coefficients.

Qualitative results are shown in Figure \ref{fig:facelesion}. In the first two rows, false-positive regions appear in both CCNN and GCNN results due to closely matching texture patterns and intrinsic geometric features in non-lesion areas, leading to segmentation inaccuracies. In the third to fifth rows, GCNN fails to segment the entire lesion region. Similar failures are observed in the results from CCNN, emphasizing the advancements introduced by the proposed QCCNN method, particularly its use of adaptive and learnable convolutions.

Quantitative results are provided in Table \ref{tb:leision}. The proposed method outperforms the competing approaches in both standard metrics, such as the Dice coefficient, and geometric metrics, such as HD95. These results demonstrate the robustness of the QCCNN in accurately segmenting lesion regions by effectively leveraging adaptive, data-aware convolution kernels and kernel shapes.

\subsection{Self Ablation}

In this section, we perform self-ablation studies to analyze the impact of various factors in the proposed Quasi-conformal Convolutional Network (QCCNN) model on overall performance.

\input{tSelfAblation}

\noindent\textbf{Test on Downsample Levels} We investigate the effect of the number of downsampling layers on the performance of the deformation estimation task. For this study, we use MNIST images on a single-complex test. The batch size is set to 64, and the model is trained as the manifold image classification task. The input consists of five-channel manifolds, including Gaussian curvature, mean curvature, and the RGB channels. We evaluate the performance using different numbers of downsampling layers: 1, 2, 3, and 4 downsampling layers.

Our results indicate that using 2 downsampling layers is sufficient to achieve good performance, as reflected by the prediction accuracy in Table \ref{tb:convdepth}. Increasing the number of downsampling layers beyond 2 does not lead to significant improvements in accuracy, but it does increase computational and memory costs. These additional costs are demonstrated by several factors, including the number of trainable parameters, the forward/backward passes (storage used for all output features from each layer in the model, which indicates the amount of memory required for each pass through the network), the storage size required to store the parameters, and the overall total size of the model.


\medskip

\noindent\textbf{Test on Weighting for BC Loss} We examine the significance of the Beltrami coefficient regularization term proposed in our model. For this study, we use MNIST images on a single-complex test. Specifically, we experiment with the following values for the regularization parameter: \(\lambda_\text{bc} = 0, 10^{-4}, 10^{-3}, 10^{-2}, 10^{-1}, 1\). Table \ref{tb:self} reports the quantitative measurements of classification accuracy. The results show that the highest Dice score is achieved when the weighting for the BC loss is \(10^{-2}\), which also ensures the bijectivity of the mapping, as reflected by the infinity norm of the Beltrami coefficient. A weighting of \(10^{-3}\) does not significantly degrade the results. However, when the weighting is too small, such as \(10^{-4}\), or when the BC loss is omitted entirely, the results degrade noticeably due to the loss of bijectivity, as indicated by the infinity norm (the maximum) of the associated Beltrami coefficient. On the other hand, when the weighting exceeds \(10^{-1}\), the deformation prediction becomes over-constrained, preventing efficient training of the deformation estimator and leading to suboptimal results, even though the mapping remains bijective.