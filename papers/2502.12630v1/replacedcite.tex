\section{Related Work}
The landscape of large language model vulnerabilities has been extensively studied in recent literature ____, that propose detailed taxonomies of threats. These works categorize LLM attacks into distinct types, such as adversarial attacks, data poisoning, and specific vulnerabilities related to prompt engineering. Among these, prompt injection attacks have emerged as a significant and distinct category, underscoring their relevance to LLM security.

The following high-level overview of the collected taxonomy of LLM vulnerabilities is defined in ____:
\begin{itemize}
    \item Adversarial Attacks: Data Poisoning, Backdoor Attacks
    \item Inference Attacks: Attribute Inference, Membership Inferences
    \item Extraction Attacks
    \item Bias and Unfairness
Exploitation
    \item Instruction Tuning Attacks: Jailbreaking, Prompt Injection.
\end{itemize}
Prompt injection attacks are further classified in ____ into the following: Goal hijacking and \textbf{Prompt leakage}.

The reviewed taxonomies underscore the need for comprehensive frameworks to evaluate LLM security. The agentic approach introduced in this paper builds on these insights, automating adversarial testing to address a wide range of scenarios, including those involving prompt leakage and role-specific vulnerabilities.

\subsection{Prompt Injection and Prompt Leakage}

Prompt injection attacks exploit the blending of instructional and data inputs, manipulating LLMs into deviating from their intended behavior. Prompt injection attacks encompass techniques that override initial instructions, expose private prompts, or generate malicious outputs ____. A subset of these attacks, known as prompt leakage, aims specifically at extracting sensitive system prompts embedded within LLM configurations. In ____, authors differentiate between prompt leakage and related methods such as goal hijacking, further refining the taxonomy of LLM-specific vulnerabilities.

\subsection{Defense Mechanisms}

Various defense mechanisms have been proposed to address LLM vulnerabilities, particularly prompt injection and leakage ____. We focused on cost-effective methods like instruction postprocessing and prompt engineering, which are viable for proprietary models that cannot be retrained. Instruction preprocessing sanitizes inputs, while postprocessing removes harmful outputs, forming a dual-layer defense. Preprocessing methods include perplexity-based filtering ____ and token-level analysis ____. Postprocessing employs another set of techniques, such as censorship by LLMs ____, and use of canary tokens and pattern matching ____, although their fundamental limitations are noted ____. Prompt engineering employs carefully designed instructions ____ and advanced techniques like spotlighting ____ to mitigate vulnerabilities, though no method is foolproof ____. Adversarial training, by incorporating adversarial examples into the training process, strengthens models against attacks ____.

\subsection{Security Testing for Prompt Injection Attacks}

Manual testing, such as red teaming ____ and handcrafted "Ignore Previous Prompt" attacks ____, highlights vulnerabilities but is limited in scale. Automated approaches like PAIR ____ and GPTFUZZER ____ achieve higher success rates by refining prompts iteratively or via automated fuzzing. Red teaming with LLMs ____ and reinforcement learning ____ uncovers diverse vulnerabilities, including data leakage and offensive outputs. Indirect Prompt Injection (IPI) manipulates external data to compromise applications ____, adapting techniques like SQL injection to LLMs ____. Prompt secrecy remains fragile, with studies showing reliable prompt extraction ____. Advanced frameworks like Token Space Projection ____ and Weak-to-Strong Jailbreaking Attacks ____ exploit token-space relationships, achieving high success rates for prompt extraction and jailbreaking.

\subsection{Agentic Frameworks for Evaluating LLM Security}

The development of multi-agent systems leveraging large language models (LLMs) has shown promising results in enhancing task-solving capabilities ____. A key aspect across various frameworks is the specialization of roles among agents ____, which mimics human collaboration and improves task decomposition.

Agentic frameworks and the multi-agent debate approach benefit from agent interaction, where agents engage in conversations or debates to refine outputs and correct errors ____. For example, debate systems improve factual accuracy and reasoning by iteratively refining responses through collaborative reasoning ____, while AG2 allows agents to autonomously interact and execute tasks with minimal human input.

These frameworks highlight the viability of agentic systems, showing how specialized roles and collaborative mechanisms lead to improved performance, whether in factuality, reasoning, or task execution. By leveraging the strengths of diverse agents, these systems demonstrate a scalable approach to problem-solving.

Recent research on testing LLMs using other LLMs has shown that this approach can be highly effective ____. Although the papers do not explicitly employ agentic frameworks they inherently reflect a pattern similar to that of an "attacker" and a "judge". ____  This pattern became a focal point for our work, where we put the judge into a more direct dialogue, enabling it to generate attacks based on the tested agent response in an active conversation.

A particularly influential paper in shaping our approach is Jailbreaking Black Box Large Language Models in Twenty Queries ____. This paper not only introduced the attacker/judge architecture but also provided the initial system prompts used for a judge.