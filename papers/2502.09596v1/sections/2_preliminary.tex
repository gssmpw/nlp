\section{Preliminary}

\subsection{LLM-based Multi-Agent System}
\mypar{Agent.}
In this paper, ``agent'', abbreviated from ``LLM-based agent'', is usually characterized as a paradigm of LLM-centric applications that employ LLM to mimic human brain~\cite{agent_intro}.
With the reasoning capability of LLMs~\cite{wei2022chain, yao2024tree, liu2023llm+, lu2024chameleon}, an agent can decompose a complex task into subtasks that can be solved more reliably;
meanwhile, LLM can make decisions so that an agent can dynamically decide when and how to use tools (i.e., APIs of different external functionalities, such as query portal of current weather of a city) given a task~\cite{yao2022react, parisi2022talm, schick2023toolformer}; finally, with a memory for maintaining context and related knowledge~\cite{shinn2024reflexion, hatalis2023memory}, agents can generate appropriate answers in long conversations or utilize external knowledge.
In this paper, we relax the definition of an agent so that it may contain only a subset of these three elements.

\mypar{Multi-agent and pipeline.}
At the current stage, an agent's performance is not satisfying given complicated tasks.
For example, end-to-end code generation~\cite{hongmetagpt} or have a large number of tools for selection.
Multi-agent systems represent an emerging paradigm, where multiple agents, each specialized in some specific tasks, collaborate to solve complex tasks. 
Some of the multi-agent frameworks are conversational~\cite{wu2023autogen, li2023camel}, where multiple agents collaborate and communicate with each other by generating messages in natural language generated by LLM.
Some other multi-agent frameworks~\cite{hongmetagpt} emphasize the diverse capabilities of LLMs to break down tasks into modular components, allowing individual agents to specialize in specific roles such as information retrieval, reasoning, or decision-making. 
By communicating and exchanging intermediate outputs, agents collectively achieve goals that exceed the capabilities of a single LLM operating in isolation. 
There are also many multi-agent systems that are designed for specific tasks, including medical~\cite{tang2023medagents}, coding~\cite{yang2024swe}, and evaluation~\cite{chan2023chateval}.
Although the above work may have implementation differences, the main idea is still to decompose complex tasks into simple subtasks and let each agent work as an information processing node in a \emph{pipeline}.




\subsection{Knowledge-intensive QA}
RAG is one of the most popular techniques coupled with LLMs, designed to address knowledge-intensive tasks, particularly those requiring high-confidence answers or involving private knowledge unavailable during the model's training phase. 
In the early stages, when language models lacked strong in-context learning capabilities, RAG techniques primarily relied on training or fine-tuning models to integrate retrieved knowledge~\cite{izacard2020leveraging, borgeaud2022improving}. 
However, with the rapid advancement of language models and their demonstrated ability to perform in-context learning, a more efficient and cost-effective approach has emerged. 
This strategy involves appending retrieved text chunks as additional prompts to the LLM input, avoiding the need for task-specific fine-tuning~\cite{ram2023context}. 
In parallel, significant research has been dedicated to improving retrieval mechanisms to ensure higher-quality inputs, such as dense retrieval methods that enhance the relevance of retrieved text~\cite{karpukhin2020dense}. 
These developments highlight the ongoing evolution of RAG techniques and their critical role in extending the capabilities of LLMs for real-world applications.
