%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
% STRINGS
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% IEEE Journals

% @string{ieeetip   = "IEEE Trans. Image Processing"}
% @string{pieee     = "Proceedings of the IEEE"}
% @string{ieeetassp = "IEEE Trans. Acoustics, Speech, and Signal Processing"}
% @string{ieeetsp   = "IEEE Trans. Signal Processing"}
% @string{ieeespl   = "IEEE Signal Processing Letters"}
% @string{ieeespm   = "IEEE Signal Processing Magazine"}
% @string{ieeem     = "IEEE Multimedia"}
% @string{ieeetm    = "IEEE Trans. Multimedia"}
% @string{ieeetmi   = "IEEE Trans. Medical Imaging"}
% @string{ieeetpami = "IEEE Trans. Pattern Analysis and Machine Intelligence"}
% @string{ieeetit   = "IEEE Trans. Information Theory"}
% @string{ieeetra   = "IEEE Trans. Robotics and Automation"}
% @string{ieeetnn   = "IEEE Trans. Neural Networks"}
% @string{ieeetcas  = "IEEE Trans. Circuits and Systems"}
% @string{ieeetcas1 = "IEEE Trans. Circuits and Systems I -- Fundamental Theory and Applications"}
% @string{ieeetcas2 = "IEEE Trans. Circuits and Systems II -- Analog and Digital Signal Processing"}
% @string{ieeetcsvt = "IEEE Trans. Circuits and Systems for Video Tech."}
% @string{ieeetcom  = "IEEE Trans. Communications"}
% @string{ieeecoml  = "IEEE Communication Letters"}
% @string{ieeecomm  = "IEEE Comm. Magazine"}
% @string{ieeejsac  = "IEEE Journal on Selected Areas in Comm."}
% @string{ieeetn    = "IEEE/ACM Trans. Networking"}
% @string{ieeetsmc  = "IEEE Trans. System, Man and Cybernetics"}
% @string{ieeetsmcA = "IEEE Trans. System, Man and Cybernetics, Part A: Systems and Humans"}
% @string{ieeecga   = "IEEE Computer Graphics and Applications"}
% @string{ieeetedu  = "IEEE Trans. Education"}
% @string{ieeetb    = "IEEE Trans. Broadcasting"}
% @string{ieeetkde  = "IEEE Trans. Knowledge and Data Engineering"}

% % Other Journals

% @string{sp        = "Signal Processing"}
% @string{pr        = "Pattern Recognition"}
% @string{prl       = "Pattern Recognition Letters"}
% @string{jei       = "Journal of Electronic Imaging"}
% @string{spic      = "Signal Processing: Image Communication"}
% @string{eletters  = "IEE Electronics Letters"}
% @string{commacm   = "Comm. of the ACM"}
% @string{oe        = "Optical Engineering"}
% @string{vcir      = "Journal of Visual Communication and Image Representation"}
% @string{josa      = "Journal of Optical Society of America"}
% @string{josaa     = "Journal of Optical Society of America A"}
% @string{vr        = "Vision Research"}
% @string{ejasp     = "EURASIP Journal on Applied Singal Processing"}
% @string{ijcv      = "International Journal of Computer Vision"}

% % IEEE Conferences

% @string{icassp    = "Proc. IEEE Int. Conf. Acoust., Speech, and Signal Processing"}
% @string{icip      = "Proc. IEEE Int. Conf. Image Proc."}
% @string{icme      = "Proc. IEEE Int. Conf. Multimedia and Expo"}
% @string{icpr      = "Proc. IEEE Int. Conf. Pattern Recognition"}
% @string{cvpr      = "Proc. IEEE Int. Conf. Computer Vision and Pattern Recognition"}
% @string{iccv      = "Proc. IEEE Int. Conf. Computer Vision"}
% @string{icsmc     = "Proc. IEEE Int. Conf. System, Man and Cybernetics"}
% @string{asilomar  = "Proc. IEEE Asilomar Conf. on Signals, Systems, and Computers"}
% @string{iscas     = "Proc. IEEE Int. Sym. Circuits and Systems"}

% % Other Conferences

% @string{spie46am  = "SPIE's 46th Annual Meeting"}
% @string{pspie     = "Proc. SPIE"}
% @string{vcip      = "Proc. SPIE Visual Comm. and Image Processing"}
% @string{nips      = "Nerual Information Processing Systems"}
% @string{eccv      = "European Conference on Computer Vision"}
% @string{icml      = "Proc. Int. Conf. Machine Learning"}
% @string{bmvc      = "British Machine Vision Conference"}
% @string{iclr      = "Proc. Int. Conf. Learning Representations"}

@String(PAMI  = {IEEE Transactions on Pattern Analysis and Machine Intelligence})
@String(IJCV  = {International Journal of Computer Vision})
@String(ICLR  = {International Conference on Learning Representations})
@String(CVPR  = {IEEE Conference on Computer Vision and Pattern Recognition})
@String(WACV  = {Proceedings of the IEEE Winter Conference on Applications of Computer Vision})
@String(ICCV  = {IEEE International Conference on Computer Vision})
@String(NIPS  = {Neural Information Processing Systems})
@String(BMVC  =	{British Machine Vision Conference})
@String(TOG   = {ACM Transactions on Graphics})
@String(TIP   = {IEEE Transactions on Image Processing})
@String(TCSVT   = {IEEE Transactions on Circuits and Systems for Video Technology})
@String(TMM   = {IEEE Transactions on Multimedia})
@String(IJCAI = {International Joint Conference on Artificial Intelligence})
@String(PR = {Pattern Recognition})
@String(AAAI = {AAAI Conference on Artificial Intelligence})
@String(TIE = {IEEE Transactions on Industrial Electronics})
@String(JV  = {Journal of Vision})


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%new
@inproceedings{he2016deep,
  title={Deep residual learning for image recognition},
  author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  booktitle=CVPR,
  pages={770--778},
  year={2016}
}

@inproceedings{liu2021swin,
  title={{Swin Transformer}: Hierarchical vision transformer using shifted windows},
  author={Liu, Ze and Lin, Yutong and Cao, Yue and Hu, Han and Wei, Yixuan and Zhang, Zheng and Lin, Stephen and Guo, Baining},
  booktitle=CVPR,
  pages={10012--10022},
  year={2021}
}

@inproceedings{yang2022tvformer,
  title={{TVFormer}: Trajectory-guided visual quality assessment on 360Â° images with transformers},
  author={Yang, Li and Xu, Mai and Liu, Tie and Huo, Liangyu and Gao, Xinbo},
  booktitle={ACM International Conference on Multimedia},
  pages={799--808},
  year={2022}
}

@article{sendjasni2023attention,
  title={Attention-Aware Patch-Based CNN for Blind 360-Degree Image Quality Assessment},
  author={Sendjasni, Abderrezzaq and Larabi, Mohamed-Chaker},
  journal={Sensors},
  volume={23},
  number={21},
  pages={8676},
  year={2023},
}


% spa-net
@inproceedings{yang2021spatial,
  title={Spatial attention-based non-reference perceptual quality prediction network for omnidirectional images},
  author={Yang, Li and Xu, Mai and Deng, Xin and Feng, Bo},
  booktitle={IEEE International Conference on Multimedia and Expo},
  pages={1--6},
  year={2021},
}


% AHGCN
@inproceedings{fu2022adaptive,
  title={Adaptive hypergraph convolutional network for no-reference 360-degree image quality assessment},
  author={Fu, Jun and Hou, Chen and Zhou, Wei and Xu, Jiahua and Chen, Zhibo},
  booktitle={ACM International Conference on Multimedia},
  pages={961--969},
  year={2022}
}
% joint network
@inproceedings{zhang2022no,
  title={No-reference omnidirectional image quality assessment based on joint network},
  author={Zhang, Chaofan and Liu, Shiguang},
  booktitle={ACM International Conference on Multimedia},
  pages={943--951},
  year={2022}
}




% % 2D IQA

@inproceedings{wang2017begin,
  title={Begin with the end in mind: A unified end-to-end quality-of-experience monitoring, optimization and management framework},
  author={Wang, Zhou and Rehman, Abdul},
  booktitle={SMPTE 2017 Annual Technical Conference and Exhibition},
  pages={1--11},
  year={2017},
}

@article{fang2021superpixel,
  title={Superpixel-based quality assessment of multi-exposure image fusion for both static and dynamic scenes},
  author={Fang, Yuming and Zeng, Yan and Jiang, Wenhui and Zhu, Hanwei and Yan, Jiebin},
  journal=TIP,
  volume={30},
  pages={2526--2537},
  year={2021},
}

@article{ding2021comparison,
  title={Comparison of full-reference image quality models for optimization of image processing systems},
  author={Ding, Keyan and Ma, Kede and Wang, Shiqi and Simoncelli, Eero P},
  journal=IJCV,
  volume={129},
  pages={1258--1281},
  year={2021},
}

@article{kim2019deep,
  title={Deep virtual reality image quality assessment with human perception guider for omnidirectional image},
  author={Kim, Hak Gu and Lim, Heoun-Taek and Ro, Yong Man},
  journal=TCSVT,
  volume={30},
  number={4},
  pages={917--928},
  year={2019},
}

@inproceedings{lim2018vr,
  title={{VR IQA NET}: Deep virtual reality image quality assessment using adversarial learning},
  author={Lim, Heaun-Taek and Kim, Hak Gu and Ra, Yang Man},
  booktitle={IEEE International Conference on Acoustics, Speech and Signal Processing},
  pages={6737--6741},
  year={2018},
}

@article{sun2019mc360iqa,
  title={{MC360IQA}: A multi-channel CNN for blind 360-degree image quality assessment},
  author={Sun, Wei and Min, Xiongkuo and Zhai, Guangtao and Gu, Ke and Duan, Huiyu and Ma, Siwei},
  journal={IEEE Journal of Selected Topics in Signal Processing},
  volume={14},
  number={1},
  pages={64--77},
  year={2019},
}

@article{zhou2021omnidirectional,
  title={Omnidirectional image quality assessment by distortion discrimination assisted multi-stream network},
  author={Zhou, Yu and Sun, Yanjing and Li, Leida and Gu, Ke and Fang, Yuming},
  journal=TCSVT,
  volume={32},
  number={4},
  pages={1767--1777},
  year={2021},
}


@inproceedings{jabbari2023st360iq,
  title={{ST360IQ}: No-Reference Omnidirectional Image Quality Assessment with Spherical Vision Transformers},
  author={Jabbari Tofighi, Nafiseh and Hedi Elfkir, Mohamed and Imamoglu, Nevrez and Ozcinar, Cagri and Erdem, Erkut and Erdem, Aykut},
  booktitle={IEEE International Conference on Acoustics, Speech and Signal Processing},
  year={2023}
}

@inproceedings{wu2024assessor360,
  title={Assessor360: Multi-sequence network for blind omnidirectional image quality assessment},
  author={Wu, Tianhe and Shi, Shuwei and Cai, Haoming and Cao, Mingdeng and Xiao, Jing and Zheng, Yinqiang and Yang, Yujiu},
  booktitle={Advances in Neural Information Processing Systems},
  pages={1--14},
  year={2024}
}

@inproceedings{duan2018perceptual,
  title={Perceptual quality assessment of omnidirectional images},
  author={Duan, Huiyu and Zhai, Guangtao and Min, Xiongkuo and Zhu, Yucheng and Fang, Yi and Yang, Xiaokang},
  booktitle={IEEE International Symposium on Circuits and Systems},
  pages={1--5},
  year={2018},
}

@inproceedings{sun2018large,
  title={A large-scale compressed 360-degree spherical image database: From subjective quality evaluation to objective model comparison},
  author={Sun, Wei and Gu, Ke and Ma, Siwei and Zhu, Wenhan and Liu, Ning and Zhai, Guangtao},
  booktitle={IEEE 20th International Workshop on Multimedia Signal Processing},
  pages={1--6},
  year={2018},
}

@inproceedings{fang2022perceptual,
  title={Perceptual quality assessment of omnidirectional images},
  author={Fang, Yuming and Huang, Liping and Yan, Jiebin and Liu, Xuelin and Liu, Yang},
  booktitle={AAAI Conference on Artificial Intelligence},
  volume={36},
  number={1},
  pages={580--588},
  year={2022}
}

@article{radenovic2018fine,
  title={Fine-tuning {CNN} image retrieval with no human annotation},
  author={Radenovi{\'c}, Filip and Tolias, Giorgos and Chum, Ond{\v{r}}ej},
  journal=PAMI,
  volume={41},
  number={7},
  pages={1655--1668},
  year={2018},
}

@article{kingma2014adam,
  title={Adam: A method for stochastic optimization},
  author={Kingma, Diederik P and Ba, Jimmy},
  journal={arXiv preprint arXiv:1412.6980},
  year={2014}
}

@article{hands2001recency,
  title={Recency and duration neglect in subjective assessment of television picture quality},
  author={Hands, David S and Avons, SE},
  journal={Applied Cognitive Psychology: The Official Journal of the Society for Applied Research in Memory and Cognition},
  volume={15},
  number={6},
  pages={639--657},
  year={2001},
  publisher={Wiley Online Library}
}

@inproceedings{video2000final,
  title={Final report from the video quality experts group on the validation of objective models of video quality assessment},
  author={Video Quality Experts Group},
  booktitle={VQEG},
  year={2000}
}

@inproceedings{tu2022maxvit,
  title={{MaxVit}: Multi-axis vision transformer},
  author={Tu, Zhengzhong and Talebi, Hossein and Zhang, Han and Yang, Feng and Milanfar, Peyman and Bovik, Alan and Li, Yinxiao},
  booktitle=ECCV,
  pages={459--479},
  year={2022},
}

@article{wang2004image,
  title={Image quality assessment: From error visibility to structural similarity},
  author={Wang, Zhou and Bovik, Alan C and Sheikh, Hamid R and Simoncelli, Eero P},
  journal=TIP,
  volume={13},
  number={4},
  pages={600--612},
  year={2004},
}

@article{fang2017objective,
  title={Objective quality assessment of screen content images by uncertainty weighting},
  author={Fang, Yuming and Yan, Jiebin and Liu, Jiaying and Wang, Shiqi and Li, Qiaohong and Guo, Zongming},
  journal=TIP,
  volume={26},
  number={4},
  pages={2016--2027},
  year={2017},
}

@inproceedings{kang2014convolutional,
  title={Convolutional neural networks for no-reference image quality assessment},
  author={Kang, Le and Ye, Peng and Li, Yi and Doermann, David},
  booktitle=CVPR,
  pages={1733--1740},
  year={2014}
}

@article{kim2017deep,
  title={Deep convolutional neural models for picture-quality prediction: Challenges and solutions to data-driven image quality assessment},
  author={Kim, Jongyoo and Zeng, Hui and Ghadiyaram, Deepti and Lee, Sanghoon and Zhang, Lei and Bovik, Alan C},
  journal={IEEE Signal Processing Magazine},
  volume={34},
  number={6},
  pages={130--141},
  year={2017},
}

@article{zhang2018blind,
  title={Blind image quality assessment using a deep bilinear convolutional neural network},
  author={Zhang, Weixia and Ma, Kede and Yan, Jia and Deng, Dexiang and Wang, Zhou},
  journal=TCSVT,
  volume={30},
  number={1},
  pages={36--47},
  year={2018},
}

@inproceedings{su2020blindly,
  title={Blindly assess image quality in the wild guided by a self-adaptive hyper network},
  author={Su, Shaolin and Yan, Qingsen and Zhu, Yu and Zhang, Cheng and Ge, Xin and Sun, Jinqiu and Zhang, Yanning},
  booktitle=CVPR,
  pages={3667--3676},
  year={2020}
}

@inproceedings{liu2017rankiqa,
  title={{RankIQA}: Learning from rankings for no-reference image quality assessment},
  author={Liu, Xialei and Van De Weijer, Joost and Bagdanov, Andrew D},
  booktitle=ICCV,
  pages={1040--1049},
  year={2017}
}

@article{ma2017dipiq,
  title={{dipIQ}: Blind image quality assessment by learning-to-rank discriminable image pairs},
  author={Ma, Kede and Liu, Wentao and Liu, Tongliang and Wang, Zhou and Tao, Dacheng},
  journal=TIP,
  volume={26},
  number={8},
  pages={3951--3964},
  year={2017},
}

@inproceedings{zhu2020metaiqa,
  title={{MetaIQA}: Deep meta-learning for no-reference image quality assessment},
  author={Zhu, Hancheng and Li, Leida and Wu, Jinjian and Dong, Weisheng and Shi, Guangming},
  booktitle=CVPR,
  pages={14143--14152},
  year={2020}
}

@article{wang2021active,
  title={Active fine-tuning from gMAD examples improves blind image quality assessment},
  author={Wang, Zhihua and Ma, Kede},
  journal=PAMI,
  volume={44},
  number={9},
  pages={4577--4590},
  year={2021},
}

@inproceedings{yu2015framework,
  title={A framework to evaluate omnidirectional video coding schemes},
  author={Yu, Matt and Lakshman, Haricharan and Girod, Bernd},
  booktitle={IEEE International Symposium on Mixed and Augmented Reality},
  pages={31--36},
  year={2015},
}

@article{sun2017weighted,
  title={Weighted-to-spherically-uniform quality evaluation for omnidirectional video},
  author={Sun, Yule and Lu, Ang and Yu, Lu},
  journal={IEEE Signal Processing Letters},
  volume={24},
  number={9},
  pages={1408--1412},
  year={2017},
}

@inproceedings{zakharchenko2016quality,
  title={Quality metric for spherical panoramic video},
  author={Zakharchenko, Vladyslav and Choi, Kwang Pyo and Park, Jeong Hoon},
  booktitle={The Optics and Photonics for Information Processing X},
  volume={9970},
  pages={57--65},
  year={2016},
}

@inproceedings{chen2018spherical,
  title={Spherical structural similarity index for objective omnidirectional video quality assessment},
  author={Chen, Sijia and Zhang, Yingxue and Li, Yiming and Chen, Zhenzhong and Wang, Zhou},
  booktitle={IEEE International Conference on Multimedia and Expo},
  pages={1--6},
  year={2018},
}

@inproceedings{zhou2018weighted,
  title={Weighted-to-spherically-uniform SSIM objective quality evaluation for panoramic video},
  author={Zhou, Yufeng and Yu, Mei and Ma, Hualin and Shao, Hua and Jiang, Gangyi},
  booktitle={IEEE International Conference on Signal Processing},
  pages={54--57},
  year={2018},
}

@article{jiang2021cubemap,
  title={Cubemap-based perception-driven blind quality assessment for 360-degree images},
  author={Jiang, Hao and Jiang, Gangyi and Yu, Mei and Zhang, Yun and Yang, You and Peng, Zongju and Chen, Fen and Zhang, Qingbo},
  journal=TIP,
  volume={30},
  pages={2364--2377},
  year={2021},
}

@inproceedings{yan2020blind,
  title={Blind stereoscopic image quality assessment by deep neural network of multi-level feature fusion},
  author={Yan, Jiebin and Fang, Yuming and Huang, Liping and Min, Xiongkuo and Yao, Yiru and Zhai, Guangtao},
  booktitle={IEEE International Conference on Multimedia and Expo},
  pages={1--6},
  year={2020}
}


@article{wu2020end,
  title={End-to-end blind image quality prediction with cascaded deep neural network},
  author={Wu, Jinjian and Ma, Jupo and Liang, Fuhu and Dong, Weisheng and Shi, Guangming and Lin, Weisi},
  journal=TIP,
  volume={29},
  pages={7414--7426},
  year={2020}
}

% % new add cite

@article{gu2019blind,
  title={Blind image quality assessment via learnable attention-based pooling},
  author={Gu, Jie and Meng, Gaofeng and Xiang, Shiming and Pan, Chunhong},
  journal={Pattern Recognition},
  volume={91},
  pages={332--344},
  year={2019},
}

@article{su2023distortion,
  title={From distortion manifold to perceptual quality: A data efficient blind image quality assessment approach},
  author={Su, Shaolin and Yan, Qingsen and Zhu, Yu and Sun, Jinqiu and Zhang, Yanning},
  journal={Pattern Recognition},
  volume={133},
  pages={109047},
  year={2023},
}

@article{wang2023toward,
  title={Toward a blind image quality evaluator in the wild by learning beyond human opinion scores},
  author={Wang, Zhihua and Tang, Zhi-Ri and Zhang, Jianguo and Fang, Yuming},
  journal={Pattern Recognition},
  volume={137},
  pages={109296},
  year={2023},
}

@article{xu2020blind,
  title={Blind omnidirectional image quality assessment with viewport oriented graph convolutional networks},
  author={Xu, Jiahua and Zhou, Wei and Chen, Zhibo},
  journal=TCSVT,
  volume={31},
  number={5},
  pages={1724--1737},
  year={2020},
}

@inproceedings{li2020norm,
  title={Norm-in-norm loss with faster convergence and better performance for image quality assessment},
  author={Li,b Dingquan and Jiang, Tingting and Jiang, Ming},
  booktitle={ACM International Conference on Multimedia},
  pages={789--797},
  year={2020}
}

@article{fang2017no,
  title={No reference quality assessment for screen content images with both local and global feature representation},
  author={Fang, Yuming and Yan, Jiebin and Li, Leida and Wu, Jinjian and Lin, Weisi},
  journal=TIP,
  volume={27},
  number={4},
  pages={1600--1610},
  year={2017},
}

@article{mittal2012making,
  title={Making a âcompletely blindâ image quality analyzer},
  author={Mittal, Anish and Soundararajan, Rajiv and Bovik, Alan C},
  journal={IEEE Signal Processing Letters},
  volume={20},
  number={3},
  pages={209--212},
  year={2012}
}

@article{zhang2023data,
  title={Data-driven single image deraining: A comprehensive review and new perspectives},
  author={Zhang, Zhao and Wei, Yanyan and Zhang, Haijun and Yang, Yi and Yan, Shuicheng and Wang, Meng},
  journal={Pattern Recognition},
  pages={109740},
  year={2023}
}

@article{zhou2023surroundnet,
  title={{SurroundNet}: Towards effective low-light image enhancement},
  author={Zhou, Fei and Sun, Xin and Dong, Junyu and Zhu, Xiaoxiang},
  journal={Pattern Recognition},
  volume={141},
  pages={109602},
  year={2023}
}

% % unused cite

@article{dosovitskiy2020image,
  title={An image is worth 16x16 words: Transformers for image recognition at scale},
  author={Dosovitskiy, Alexey and Beyer, Lucas and Kolesnikov, Alexander and Weissenborn, Dirk and Zhai, Xiaohua and Unterthiner, Thomas and Dehghani, Mostafa and Minderer, Matthias and Heigold, Georg and Gelly, Sylvain and others},
  journal={arXiv preprint arXiv:2010.11929},
  year={2020}
}

@article{fang2017objective,
  title={Objective quality assessment of screen content images by uncertainty weighting},
  author={Fang, Yuming and Yan, Jiebin and Liu, Jiaying and Wang, Shiqi and Li, Qiaohong and Guo, Zongming},
  journal=TIP,
  volume={26},
  number={4},
  pages={2016--2027},
  year={2017},
}


% % example