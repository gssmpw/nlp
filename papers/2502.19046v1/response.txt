\section{Related work}
\label{sec:rw}

In this section, we first briefly introduce blind image quality assessment (BIQA) models for general 2D images. Then, we describe OIQA models in detail.

\subsection{BIQA Models}

Most of the early BIQA models (also called traditional models) follow the same paradigm, \ie, extract hand-crafted features based on prior knowledge and predict perceptual quality using a shallow machine learning algorithm (\eg, support vector regression) **Kang et al., "Deep IQA Using Convolutional Neural Networks"** or a distance metric **Zhang, "Image Quality Assessment Based on Feature Similarity"**. This is the mainstream framework before the deep learning era. Limited by the representation ability of hand-crafted features and the learning ability of the shallow machine learning algorithms, the performance of traditional models has been largely surpassed by deep learning-based models.  

To the best of our knowledge, Kang~\et **Kang et al., "Deep IQA Using Convolutional Neural Networks"** presented a pioneering study on IQA using a CNN, and it can be trained end-to-end. After that, many CNN-based BIQA models have been successively proposed **Zhang et al., "Image Quality Assessment Based on Deep Learning"**, where most of them are adapted from the CNNs for image classification **Simonyan et al., "Very Deep Convolutional Networks for Large-Scale Image Recognition"**. In addition, some CNN-based BIQA models target solving the data-scarcity problem, since CNN is data-hungry while the amount of public image quality data is very small. For example, this two studies introduce pair-wise ranking learning to solve the data problem, where the discriminable image pairs with preference labels can be generated automatically without any constraint. Some works focus on improving the model's generalization ability by integrating advanced computer vision techniques, such as meta-learning **Zhu et al., "Meta-Learning for Image Quality Assessment"**, active learning **Saha et al., "Active Learning for Image Quality Assessment"**, and \emph{etc}. Besides, Su~\et **Su et al., "Learning to Predict Image Distortion Manifold for Blind Image Quality Assessment"** proposed an alternative solution to improve model generalizability, where it learns an image distortion manifold to capture common degradation patterns, and the quality prediction of an image can be obtained by projecting the image to the distortion manifold.

\subsection{OIQA Models}

Due to the substantial difference between the data format of OIs and general 2D images, the 2D-IQA models can not be directly used to estimate the quality of OIs. Some researchers made attempts to adapt the 2D-IQA models to solve the OIQA issue. Yu~\et **Yu et al., "S-PSNR: Single Image Quality Assessment Based on Projection"** proposed S-PSNR, which projects an OI to the ERP format and calculates the PSNR value between the reference OI and distorted OI. Sun~\et **Sun et al., "Weighted Spatial PSNR for Quality Assessment of Omnidirectional Images"** proposed WS-PSNR, which assigns different weights to the pixels at different positions. Zakharchenko~\et **Zakharchenko et al., "CPP-PSNR: Craster Parabolic Projection-Based Quality Assessment"** proposed CPP-PSNR, which maps the OIs to the Craster Parabolic Projection (CPP) format and then calculates the PSNR. Besides, some researchers tried to adapt SSIM **Wang et al., "Image Quality Assessment Based on Structural Similarity"** to design OIQA models, such as S-SSIM **Chen et al., "S-SSIM: Single Image Quality Assessment Using Structural Similarity"**, and WS-SSIM **Ma et al., "Weighted Spatial SSIM for Quality Assessment of Omnidirectional Images"**. 


For the BOIQA models, they can be divided into three types, including ERP-based, other projection format-based, and viewport-based. The main idea of the first type of BOIQA model is to directly extract features from the ERP image. Yang~\et **Yang et al., "SAP-net: Spatial Attention-Based Quality Assessment Network for Omnidirectional Images"** proposed a spatial attention-based model named SAP-net, which fuses the error map generated by the difference between the impaired image and the enhanced image into the backbone to 
explicitly emphasize the objective degradation. Sendjasni~\et **Sendjasni et al., "Attention-Aware Patch-Based Quality Assessment for Omnidirectional Images"** proposed an attention-aware patch-based OIQA model that considers the exploration behavior and latitude-based selection in the sampling process. Kim~\et **Kim et al., "Adversarial Neural Networks for Quality Assessment of Omnidirectional Images"** proposed an OIQA method based on adversarial neural networks which divides the ERP image into uniform and non-overlapping patches, and uses the feature extracted from these patches to predict quality score. The second type is mainly to overcome the obvious stretching and deformation of ERP images at the poles, and some researchers tried to project OIs to other formats. Jiang~\et **Jiang et al., "Quality Assessment Using Features Extracted from Six Projected Images in CMP Format"** proposed to extract features from the six projected images in the CMP format. Sun~\et **Sun et al., "MC360IQA: Multi-Channel CNN for Quality Assessment of Omnidirectional Images"** proposed an OIQA model using a multi-channel CNN named MC360IQA to simulate the real viewing process of the subjects. This model projects each OI into six viewports and uses a multi-channel CNN to extract features, then the extracted features are fused and used to predict the quality score. 
Xu~\et **Xu et al., "Viewport-Oriented Graph Neural Network for Quality Assessment of Omnidirectional Images"** proposed a novel viewport-oriented graph neural network (GNN) named VGCN, which considers local viewport quality and global image quality simultaneously. Yang~\et **Yang et al., "TVFormer: Transformer-Based Quality Assessment for Omnidirectional Images"** proposed a novel Transformer-based model named TVFormer, which generates the viewport sequence by a trajectory-aware module and predicts the perceptual quality of OIs in a manner of video quality assessment (VQA). Fang~\et **Fang et al., "BOIQA: Bridging the Gap Between Quality Assessment and Human Perception"** proposed a BOIQA model that incorporates the subject viewing conditions to maintain consistency with human viewing behavior. Wu~\et **Wu et al., "Assessor360: Multi-Sequence Network for Quality Assessment of Omnidirectional Images"** proposed a multi-sequence network called Assessor360 which generates multiple pseudo viewport sequences as the inputs.


\begin{figure*}[]
\centering
\includegraphics[width=1\linewidth]{figs/architecture.pdf}
\caption{The architecture of our proposed Max360IQ. It mainly consists of three parts: a backbone, a multi-scale feature integration (MSFI) module, and a quality regression (QR) module. Note that the GRUs component in Max360IQ is optional for optimal performance in different scenarios, \ie, non-uniformly and uniformly distorted OIs.}
\label{fig:max360iq}