\subsection{Baseline Evaluation}  

\textbf{Experimental Setup.}  
We train all baseline models using the AdamW optimizer with Focal Loss. TCN-based models, including \emph{Neural + TCN}, have a receptive field of 8 minutes, sufficient to capture \emph{CE} patterns in the 5-minute training data. Early stopping is applied based on validation loss, and results are averaged over 10 random seeds. Additional training details are provided in Appendix~\ref{sec:baseline-training}. The Pretrained Feature Encoder and the \emph{Neural AE} classifier used in the experiment are described in Appendix~\ref{sec:pretrained-encoder}.


\textbf{Metrics.}  
We evaluate performance using the $F1$ score for each \emph{CE} class $e_i$ and report two aggregated scores:  
\begin{enumerate}[leftmargin=1.5em,nosep]
    \item \emph{Macro $F1$} ($F1\_all$): The unweighted average $F1$ across all classes ($e_0$ to $e_{10}$).
    \item \emph{Positive $F1$} ($F1\_pos$): The average $F1$ over positive event classes ($e_1$ to $e_{10}$), excluding the less important ``negative'' label $e_0$. This serves as our key metric.
\end{enumerate}  
A higher $F1$ score indicates better precision-recall balance, reflecting both correctness and completeness.  



\textbf{Results.}  
We evaluate model performance across different training set sizes, as shown in Fig.~\ref{fig:ce_different_trainingsizes_boxplot}. The results indicate that \emph{\textbf{Mamba achieves the best performance}}, followed by LSTM. The \emph{Neural + X} models underperform compared to end-to-end models, likely due to errors and noise introduced by the \emph{Neural AE} classifier. This also explains why the \emph{Neural AE} + FSM model, despite incorporating correct human-written complex event rules, performs worse. Detailed $F1$ scores for each \emph{CE}, including per-class \emph{F1} scores, are provided in Table~\ref{tab:baseline-results}.


Additionally, we test model generalization on {out-of-distribution (OOD) complex events lasting 15 and 30 minutes, following the same \emph{CE} rules but with extended temporal spans. As shown in Table~\ref{tab:baseline_different_temporal_span}, Mamba generalizes better than LSTM to unseen test data. \emph{\textbf{Training with more labeled sensor data improves performance on 5-minute test data and enhances generalization to longer unseen traces.}} However, we still observe a performance drop as temporal span increases. Moreover, the data-hungry nature of these neural network baselines imposes significant real-world data collection and labeling costs.



% The AE + FSM model incorporates correct complex event rules; its performance declines greatly with longer traces due to cumulative errors from imperfect atomic event inference. While the Mamba model showed the best generalization on the OOD test sets, we still noted a performance drop as the temporal span increased. Additionally, the data required to train these neural network baselines incurs significant data collection and labeling costs in the real world.

% (Also add a figure of Mamba generalization ability w.r.t training size.) however, it's costly to infinitely increase the training data amount




% \begin{figure}[t]
%     \centering
% \includegraphics[width=0.95\columnwidth]{figs/ce_train_results.png}
%     \caption{Average F1 scores of models on complex events with different temporal spans.}
%     \label{fig:ce_train_results}
% \end{figure}

\begin{figure}[t]
    \centering
        \setlength{\abovecaptionskip}{0.cm}
    \setlength{\belowcaptionskip}{0.cm}
\includegraphics[width=0.95\columnwidth]{figs/ce_different_trainingsizes_boxplot.png}
    \caption{Positive $F1$ scores of models on complex events with different training data.}
    \label{fig:ce_different_trainingsizes_boxplot}
    \vspace{-1em}
\end{figure}

% \begin{figure}[t]
%     \centering
% \includegraphics[width=0.95\columnwidth]{figs/ce_different_trainingsizes_barplot.png}
%     \caption{(barplot) Average F1 scores of models on complex events with different training data.}
%     \label{fig:ce_different_trainingsizes_barplot}
% \end{figure}

\begin{table}[t]
    \centering
    \small
    \setlength{\tabcolsep}{4pt}
    % \setlength{\tabcolsep}{4pt} % Reduce space between columns
    \caption{Positive $F1$ scores with a 2-sigma confidence interval for Mamba and LSTM tested on 5-minute and OOD test sets with longer \emph{CE} temporal patterns.}
    \vskip 0.15in
    \begin{tabular}{c c c c c} % Ensure correct column count
        \toprule
        \textbf{Model} &  \textbf{Training} & \multicolumn{3}{c}{\textbf{Positive $F1$}}\\
        \cmidrule(lr){3-5}
         & \textbf{Data Size} & \textbf{5min} & \textbf{15min (OOD)} & \textbf{30min (OOD)} \\
        % \cmidrule(lr){3-5} % Horizontal line under merged column
        % \textbf{data size} & \textbf{data size} & \textbf{5min} & \textbf{15min} & \textbf{30min} \\
        \midrule
        Mamba  & 2000 & .75 $\pm$ .08 & .65 $\pm$ .09 & .51 $\pm$ .11 \\
               & 4000 & .85 $\pm$ .08 & .75 $\pm$ .11 & .66 $\pm$ .16 \\
               & 6000 & .89 $\pm$ .05 & .79 $\pm$ .07 & .69 $\pm$ .14 \\
               & 8000 & .90 $\pm$ .08 & .77 $\pm$ .09 & .70 $\pm$ .12 \\
               & 10000 & .89 $\pm$ .09 & .81 $\pm$ .06 & .73 $\pm$ .06 \\
        \midrule
        LSTM & 10000 & .88 $\pm$ .11 & .74 $\pm$ .17  & .65 $\pm$ .20 \\
        \bottomrule
    \end{tabular}
    \label{tab:baseline_different_temporal_span}
    \vskip -0.1in
\end{table}



