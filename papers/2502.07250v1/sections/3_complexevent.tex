\section{Online Complex Event Detection}
\subsection{Complex Event Definitions}

% \textit{\textbf{Atomic Events (AEs)} are low-level, short-time, and the smallest building blocks of complex events.} Usually, they are instantaneous events that most popular deep learning models can easily recognize. For example, an image classification, a 2-second audio clip classification, human activity recognition or an object detection.

% \textit{\textbf{Complex Events (CEs)} are higher-level events defined by atomic events following some temporal patterns.} Suppose we have a set of atomic events $A$ with $n$ elements $A = \{a_1, a_2, \ldots, a_n\}$. Additionally, we have a set of complex events of interest with $k$ elements $E = \{e_1, e_2, \ldots, e_k\}$. Each complex event $e_i$ is defined by a subset of atomic events $A_i$, following some specific rules:
% \begin{align}
%     &e_i = R_i(A_i) = R_i(a_i^1, a_i^2, \ldots, a_i^{n_i}),\nonumber\\ &\textrm{where }a_i^j \in A_i, \quad 1 \leq j \leq n_i, \quad 1 \leq i \leq k.
% \end{align}
% Here, $R_i$ represents the temporal pattern function that maps the relevant atomic events into a complex event $e_i$, $A_i \subseteq A$, and $n_i$ is the number of atomic events in the subset $A_i$.
\begin{definition}
\label{def:AE}
\emph{Atomic events} (\emph{AE}s) are low-level, short-duration, and fundamental building blocks of complex events. They are typically instantaneous or span a small time window and are directly detectable by models such as image classification, object detection, or activity recognition models.
\end{definition}

\begin{definition}
\label{def:CE}
\emph{Complex events} (\emph{CE}s) are high-level events that are defined as sequences or patterns of atomic events (\emph{AE}s) occurring in specific temporal or logical relationships.
\end{definition}
Let $A = \{a_1, a_2, \ldots, a_n\}$ denote the set of all atomic events, where $n$ is the total number of atomic events. Each $a_i$ is associated with a start time and an end time. Similarly, $E = \{e_1, e_2, \ldots, e_k\}$ denote the set of all complex events of interest, where $k$ is the total number of complex events.

Each complex event $e_i \in E$ is defined as:
\[
e_i = R_i(A_i) = R_i(a_i^1, a_i^2, \ldots, a_i^{n_i}),
\]
where $A_i \subseteq A$ is the subset of atomic events relevant to $e_i$, $R_i$ is a \textit{pattern function} that defines the temporal or logical relationship among the atomic events in $A_i$, and $n_i = |A_i|$ is the number of atomic events involved in defining $e_i$. Each $e_i$ is associated with a time $t_{e_i}$, which is the specific time (or time interval) at which the pattern $R_i$ is satisfied, i.e., when the complex event $e_i$ occurs.

\textbf{Temporal Pattern Function ($R_i$):}
The function $R_i$ maps a subset of atomic events $A_i$ to a complex event $e_i$ by defining specific patterns among the atomic events. In this work, we considered four main categories of patterns: \emph{Sequential Patterns}, \emph{Temporal Patterns}, \emph{Repetition Patterns}, and \emph{Combination Patterns}. Some groups have one or more subcategories; their definitions and examples are provided in Table~\ref{tab:ce_patterns}. Importantly, all patterns considered in this work are {\emph{bounded to finite states}, enabling them to be represented by finite state machines (FSMs).

\begin{table*}[t]
\centering
\caption{Category of Complex Event Patterns.}
{\scriptsize
\begin{tabular}{@{}p{2.5cm}p{7.5cm}p{6.5cm}@{}}
\toprule
\textbf{\emph{CE} Category} & \textbf{Features} & \textbf{Examples} \\ \midrule

\textbf{Sequential Patterns} \\ - \emph{Relaxed} & 
Key \emph{AE}s must be in order, may contain unrelated \emph{AE}s in between &
$A \rightarrow u^* \rightarrow B \rightarrow u^* \rightarrow C$, \newline where $u$ represents user-deinfed unrelated \emph{AE}s.\dag \\ \midrule

\textbf{Temporal Patterns} \\ - \emph{Duration Based} & 
Count the time for specific \emph{AE}(s) & ``Wash hands continuously for at least 20 seconds.'' \newline ``Inadequate brushing teeth that lasts less than 2 minutes, allowing a 10-second grace period in case brushing stops temporarily.'' \\

- \emph{Timing Relationship} & 
Relative timing between different \emph{AE}s, such as \emph{min}, \emph{max} timing constraints & 
``After washing hands, eat within 2 minutes.'' \\ \midrule

\textbf{Repetition Patterns} \\- \emph{Frequency Based} & 
Count the occurrences of specific \emph{AE}(s) over time constraints. & 
``Click the mouse 5 times within 10 seconds.'' \\ 

- \emph{Contextual Count} & 
Count the occurrences of specific \emph{AE}(s) over timing related to other \emph{AE}(s). & 
``After eating, wait for at least 10 minutes to work..'' \\ \midrule

\textbf{Combination \newline Patterns} & 
Sequential + Temporal Patterns & 
``Use Restroom $\rightarrow$ Wash (20s) $\rightarrow$ Work'', \newline (After using the restroom, ensure hands are washed for at least 20 seconds consecutively before returning to work.) \\ \bottomrule
\end{tabular}
}
\vspace{-0.5em}% reduce some space between the table and the footnote

\parbox{0.95\linewidth}{%
\raggedright % Left-align the notes
\scriptsize
\textbf{Notes:} \dag for example, the unrelated \emph{AE} $u$ can be any \emph{AE} other than the \emph{key AE}s $=\{A,B,C\}$. $u^*$ means we allow for zero or more unrelated \emph{AE}, $u$, in sequence. 
}
\label{tab:ce_patterns}
\vspace{-1em}
\end{table*}

% here limited to activities are bounded by vocabulary, use whole set \setmunius {A,B,C} to express
% fix the definition here: before c at least a B, before B no C and at least one A
% mention that all of the current CEs are expressable in FSMs
% e.g.,express the sequential pattern as state transition (state-level trace)
% neurosymbolic we map to a window-level trace
\subsection{Online Detection Task Formalization}\label{sec:CED-task}

\begin{figure}[t]
    \centering
        \setlength{\abovecaptionskip}{0.cm}
    \setlength{\belowcaptionskip}{0.cm}
\centerline{\includegraphics[width=1\columnwidth]{figs/ced-illustration.png}}
\caption{An illustration of the Online Complex Event Detection task. The example on the right shows that ``\textit{Using Restroom}" and ``\textit{Eating}" without ``\textit{Washing hands}" triggers the complex event detection, but only at the last action ``\textit{Washing hands}" we attach the corresponding \textit{CE} label ``1".}
\label{fig:ced-illustration}
\vspace{-1em}
\end{figure}

Without loss of generality, let's assume a system receives a raw data stream $\mathbf{X}$ from a single sensor with some modalities $M$. The sensor operates at a sampling rate $r$. The system processes the data stream using a non-overlapping sliding window with a fixed length $\Delta t$. At the $t$th sliding window, the system extracts a data segment:
\begin{equation}
    \mathbf{D}_t=\mathbf{X}(t),
\end{equation}
where $\mathbf{X}(t) \in \mathbb{R}^{(r \times \Delta t) \times m}$, with $m$ being the feature dimension of sensors data from modality $M$.

At each sliding window $t$, there is a corresponding ground-truth \emph{CE} label $y_t$, which represents the complex event occurring at that time. As shown in Fig.~\ref{fig:ced-illustration}, $y_t$ relies on \emph{AE}s that happened in the previous $t-1$ windows and the current window $t$. The example on the right illustrates the online \emph{CE} labeling approach we adopt. Suppose the full pattern of a complex event spans from $t_1$ to $t_2$, i.e., $t_2$ is the exact time when the complex event is observed to occur. In this case, only $y_{t_2}$ is the corresponding \emph{CE} label. All \textit{CE} labels from $y_{t_1}$ to $y_{t_2 - 1}$ are ``0"s, indicating that no complex event is detected before $t_2$. 

For data streams with up to $T$ sliding window clips, the objective of the system with a real-time CED system $f$ is to accurately predict the complex event label at each sliding window $t$, i.e., to minimize the difference between the predicted \emph{CE} label $\hat{y_t}$ and the ground-truth \emph{CE} label ${y_t}$:
\begin{equation}\label{eq:1}
    \min |\hat{y_t} - y_t|, \quad \textrm{ where }\hat{y_t} = f\left(\mathbf{D}_t\right), \quad 1 \leq t \leq T,
\end{equation}
This constitutes a \textit{multi-label multi-class classification} problem. Let $\mathbf{y} = {y_1, y_2, \ldots, y_T}$ represent the ground-truth complex event label sequence. Equation~\ref{eq:1} can be expressed in a vector form as
\begin{equation}
    \min ||f(\mathbf{D}) - \mathbf{y}||, \quad \textrm{ where } \mathbf{D} = \left\{\mathbf{X}(1),\ldots, \mathbf{X}(T)\right\}.
\end{equation}

In other words, for data-driven methods, the supervision only comes from the \textbf{\emph{high-level, coarse CE labels}}. The fine-grained ground-truth \emph{AE} labels will not be provided during training. However, the model must interpret the semantics of \emph{AEs} at each window while simultaneously learning the \emph{CE} rules. This makes the task a \textbf{unique} and \textbf{challenging} combination of \emph{distant supervision}—where labels are only provided at the event level—and \emph{weak supervision}, where the provided labels are high-level and sparse, offering limited direct guidance for learning the lower-level semantics.






