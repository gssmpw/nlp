\section{Experiments}

\subsection{Experimental Setup}
We train both the \emph{CE} NAR and the sensor adapter of \narce{} using the AdamW optimizer with Focal Loss. Further training details are in Appendix~\ref{sec:narce-training}. Synthetic \emph{AE} concept traces are generated using the LLM Synthesizer, producing datasets of 20k, 40k, and 80k samples. The labeled sensor dataset is identical to that used in the baseline experiment.



\subsection{Evaluation}  

We compare the performance of baseline Mamba models, \emph{Neural AE} + FSM, and \narce{} trained on 40k pseudo \emph{AE} concept traces. Results are shown in Fig.~\ref{fig:narce_different_temporal_spans_boxplot}. Additionally, we conduct a Wilcoxon Signed-Rank Test~\cite{wilcoxon} with $\alpha=0.05$ to assess statistical significance. The results indicate that narce\_4k significantly outperforms mamba\_4k, while no significant difference is detected between narce\_4k vs. mamba\_10k and narce\_2k vs. mamba\_4k. This confirms that \textbf{\narce{} achieves comparable or superior performance to baseline models while requiring significantly fewer labeled sensor samples}, validating \emph{Hypothesis II}. Detailed statistical hypotheses and p-values are provided in Appendix~\ref{sec:wilcoxon}.  

We also analyze the impact of synthetic training data size on \narce{}'s performance. As shown in Table~\ref{tab:narce_trainsize}, \textbf{increasing the number of synthetic \emph{AE} concept traces improves both performance and generalization to extended \emph{CE} sequences}, given the same amount of labeled sensor data. The improvement is more significant when sensor data is limited to 2000 samples. However, training with 80k concept traces provides only marginal improvement over 40k, likely due to model capacity limitations, suggesting an upper bound on its effectiveness.  


\begin{figure}[t]
    \centering
\includegraphics[width=0.95\columnwidth]{figs/narce_different_temporal_spans_boxplot.png}
    \caption{Positive $F1$ scores of models trained with different amount of labeled sensor data, on \emph{CE}s with different temporal spans. For example, Mamba\_2k means the Mamba model is trained on 2000 labeled sensor data, similarly, \narce{}\_2k means the \narce{} (Sensor Adapter) is trained on 2000 sensor data.}
    \label{fig:narce_different_temporal_spans_boxplot}
    \vspace{-1em}
\end{figure}


% \begin{figure}[t]
%     \centering
% \includegraphics[width=0.95\columnwidth]{figs/narce_different_temporal_spans_barplot.png}
%     \caption{(barplot) Positive $F1$ scores of models trained with different amount of labeled sensor data, on \emph{CE}s with different temporal spans. For example, Mamba\_2k means the Mamba model is trained on 2000 labeled sensor data, similarly, \narce{}\_2k means the \narce{} (Sensor Adapter) is trained on 2000 sensor data.}
%     \label{fig:narce_different_temporal_spans_barplot}
% \end{figure}

\begin{table}[t]
    \centering
    \small
    % \renewcommand{\arraystretch}{1.1}
    \setlength{\tabcolsep}{3pt}
    % \setlength{\tabcolsep}{4pt} % Reduce space between columns
    \caption{Positive $F1$ scores with a 2-sigma confidence interval for \narce{} with different NAR and sensor training data sizes.}
    \vskip 0.15in
    \begin{tabular}{c c c c c} % Ensure correct column count
        \toprule
        \textbf{Sensor} & \textbf{NAR} & \multicolumn{3}{c}{\textbf{F1 (positive)}}\\
        \cmidrule(lr){3-5}
        \textbf{Data Size} & \textbf{Data Size} & \textbf{5min} & \textbf{15min} & \textbf{30min} \\
        % \cmidrule(lr){3-5} % Horizontal line under merged column
        % \textbf{data size} & \textbf{data size} & \textbf{5min} & \textbf{15min} & \textbf{30min} \\
        \midrule
        \multirow{3}{*}{2,000} & 20,000 & .78 $\pm$ .06 & .66 $\pm$ .13 & .60 $\pm$ .09 \\
                               & 40,000 & \textbf{.85} $\pm$ .09 & .73 $\pm$ .10 & \textbf{.67} $\pm$ .09 \\
                               & 80,000 & .81 $\pm$ .11 & \textbf{.75} $\pm$ .18 & \textbf{.67} $\pm$ .14 \\
        \midrule
        \multirow{3}{*}{4,000} & 20,000 & .86 $\pm$ .08 & .77 $\pm$ .09 & \textbf{.71} $\pm$ .10 \\
                               & 40,000 & \textbf{.89} $\pm$ .06 & .77 $\pm$ .08 & \textbf{.71} $\pm$ .06 \\
                               & 80,000 & \textbf{.89} $\pm$ .09 & \textbf{.79} $\pm$ .06 & \textbf{.71}  $\pm$ .01\\
        \bottomrule
    \end{tabular}
    \label{tab:narce_trainsize}
    \vskip -0.1in
\end{table}


\subsection{Ablation Study}
We conduct an ablation study to evaluate the effectiveness of the Focal Loss (FL) we propose for online CED tasks. In Table~\ref{tab:fl_ablation}, we compare the following models: (1) a \narce{} where the NAR is trained using FL, while the Sensor Adapter is trained with CrossEntropy Loss, (2) a \narce{} where both NAR and Adapter are trained with CrossEntropy Loss, and (3) Our standard \narce{}, where FL is applied to both components. The results show that FL plays a crucial role in training both the NAR and Sensor Adapter. While model (2) achieves strong performance on 5-minute data, it generalizes poorly on OOD test data (15-minute and 30-minute). In contrast, our standard \narce{} with FL excels, particularly when the number of labeled sensor data samples is limited to 2,000, demonstrating better generalization and robustness across all test sets.


\begin{table}[t]
    \centering
    \small
    % \renewcommand{\arraystretch}{1.1}
    \setlength{\tabcolsep}{3pt}
    % \setlength{\tabcolsep}{4pt} % Reduce space between columns
    \caption{Ablation study results. The best $F1$ score for 2,000 sensor data case is \underline{underlined}, and for 4,000 sensor data case is \textbf{bolded}.}
    \vskip 0.15in
    \begin{tabular}{c c c c c} % Ensure correct column count
        \toprule
         & \textbf{Sensor} & \multicolumn{3}{c}{\textbf{F1 (positive)}}\\
        \cmidrule(lr){3-5}
        \textbf{Model}& \textbf{Data Size} & \textbf{5min} & \textbf{15min} & \textbf{30min} \\
        % \cmidrule(lr){3-5} % Horizontal line under merged column
        % \textbf{data size} & \textbf{data size} & \textbf{5min} & \textbf{15min} & \textbf{30min} \\
        \midrule
        \multirow{2}{*}{Adapter w/o FL} & 2,000 & .72 $\pm$ .11 & .55 $\pm$ .18 & .42 $\pm$ .21 \\ 
                               & 4,000 & .86 $\pm$ .12 & .75 $\pm$ .14 & .68 $\pm$ .17 \\
        \midrule
        NAR \& Adapter & 2,000 & \underline{.90} $\pm$ .07 & .72 $\pm$ .09 & .59 $\pm$ .10 \\
         w/o FL                       & 4,000 & \textbf{.90} $\pm$ .07 & .70 $\pm$ .09 & .54 $\pm$ .17 \\
        \midrule
        \multirow{2}{*}{\narce{}} & 2,000 & .85 $\pm$ .09 & \underline{.73} $\pm$ .10 & \underline{.67} $\pm$ .09\\
                               & 4,000 & .89 $\pm$ .06 & \textbf{.77} $\pm$ .08 & \textbf{.71} $\pm$ .06 \\
        \bottomrule
    \end{tabular}
    \label{tab:fl_ablation}
    \vskip -0.1in
    \vspace{-1em}
\end{table}

