\section{\narce{} Framework}
\subsection{Overview}
We propose \narce{}, a framework designed to reduce the need for labeled sensor data by decoupling complex event rule learning from sensor-specific variations, as hypothesized in \emph{Hypothesis II}. Inspired by the Neural Algorithmic Reasoning (NAR) paradigm, which uses Graph Neural Networks (GNNs) to represent and learn algorithms by using symbolic algorithm input-output pairs for training, in \narce{}, we analogously treat each complex event rule as a type of algorithm and leverage Mamba, a state-space model well-suited for long-range dependencies, to learn them.

To achieve this, \narce{} follows a two-stage training process, as shown in Fig.~\ref{fig:narce_overview}. In \textbf{Stage 1}: It learns complex event rules from synthetic concept traces without using sensor data. In \textbf{Stage 2}: It adapts to real sensor data by training a Sensor Adapter that maps sensor embeddings into the latent space of the pretrained \emph{CE} NAR.

\subsection{Stage I: Training \emph{CE} NAR on Concept Traces}
In this stage, we train the \textbf{Mamba-based \emph{CE} NAR} to learn complex event rules independently of sensor data. Instead of using sensor sequences, we generate pseudo \emph{AE} concept traces, sequences of \emph{AE}, governed by the same \emph{CE} rules we aim to detect. These traces are produced by an \textbf{LLM-based Synthesizer}, which simulates human activity sequences in \emph{5-second} windows by: (1) structuring activities into \emph{semantic groups} (e.g., hygiene, work, restroom); (2) defining \emph{probabilistic transitions} between groups and atomic events; (3) assigning \emph{variable durations} for each group and atomic event; and (4) dynamically adjusting \emph{transition probabilities} to ensure the presence of target complex events.

Since LLMs struggle with complex event reasoning, we do not rely on them for online \emph{CE} labeling. Instead, we use FSMs to generate online \emph{CE} labels from concept traces, ensuring reliable supervision. A case study on this limitation is provided in Appendix~\ref{sec:llm_eval}. Detailed prompts used for the LLM synthesizer are provided in Appendix~\ref{sec:llm_synthesizer}.

Once generated, the \emph{AE} concept traces are tokenized and paired with \emph{CE} labels to train the \emph{CE} NAR. Specifically, we:
\begin{enumerate}[leftmargin=1em,nosep]
    \item Tokenize \emph{AE} traces with the \textbf{\emph{AE} Tokenizor}, using a lookup vocabulary table.
    \item Pass tokens through a learnable embedding matrix, the \textbf{Embedding Encoder $f$}, which maps the tokens to a 128-dimensional latent space.
    \item Train the \emph{CE} NAR, a 12-layer Mamba model, identical to the baseline Mamba, using Focal Loss (FL)~[\ref{eq:fl}].
\end{enumerate}

After training, the \emph{CE} NAR is frozen and used as a reasoning module in Stage 2.


\subsection{Stage II: Training the Sensor Adapter}
Once the \emph{CE} NAR is trained on concept traces, we adapt it to real sensor data by training a \textbf{Sensor Adapter $f'$}. The goal of the Sensor Adapter is to map raw sensor embeddings into the latent space of NAR, allowing it to process sensor inputs while preserving the learned event reasoning capabilities.
To achieve this:
\begin{itemize}[leftmargin=1em,nosep]
    \item The Embedding Encoder from Stage 1 is removed, and the Sensor Adapter is introduced.
    \item The \emph{CE} NAR remains frozen, ensuring that the event reasoning remains intact.
    \item The Sensor Adapter is trained using labeled sensor data with online \emph{CE} labels to learn the mapping.
\end{itemize}

We use a 6-layer Mamba block for the Sensor Adapter, though other neural network models can be used. This setup enables online CE detection, allowing the model to infer complex event occurrences from raw sensor streams.


% We bring out \narce{}, as shown in Fig.~\ref{fig:narce_overview}, a framework that aims to reduce the data hunger for labeled sensor data. We hypothesize in \emph{Hypothesis II} that decoupling the learning of complex event rules from noisy sensor data improves data efficiency. \narce{} draws insights from the Neural Algorithmic Reasoning (NAR) paradigm (cite), which uses neural networks, particularly Graph Neural Networks (GNNs), to represent and learn algorithms by using symbolic algorithm input-output pairs for training. Analogously, in \narce{}, we treat each complex event rule as one type of algorithm and use a well-suited backbone model for CED, Mamba, to learn those rules. \narce{} contains a \emph{CE} NAR, which is a Mamba-based NAR, which leverages synthetic concept traces to learn \emph{CE} rules. Concept traces are sequences of atomic events governed by the same \emph{CE} rules we aim to detect generated using large language models (LLMs),  representing abstracted event sequences that encode rule-driven patterns without noisy sensor data. 

% \subsection{Framework Overview}
% Figure~\ref{fig:narce_overview} illustrates the two-stage process of \narce{}. In Stage 1, we pretrain the Mamba-Based \emph{CE} NAR using pseudo AE concept traces—sequences of atomic events generated by an LLM Synthesizer based on predefined complex event rules. These traces are tokenized and paired with corresponding online CE labels to train the embedding encoder and the NAR model, independent of sensor data.

% In Stage 2, we freeze the trained CE NAR and replace its embedding encoder with a Sensor Adapter $f'$. This adapter is trained to map real sensor embeddings into the latent space where the CE NAR operates, allowing the model to reason over real-world sensor inputs and produce online CE labels. This two-stage approach ensures the model first learns robust event reasoning before adapting to sensor-specific variations.


% \subsection{Generating \emph{AE} Concept Trace Dataset}
% To generate pseudo \emph{AE} concept traces for training the \emph{CE} NAR, we use an LLM-based synthesizer that mimics human activity sequences in 5-second windows. The LLM generates simulation codes by (1) structuring activities into semantic groups (e.g., hygiene, work, restroom) with related \emph{AE}s, (2) defining probabilistic transitions between semantic groups and \emph{AE} to maintain natural behavior, (3) assigning variable durations for each group and \emph{AE}, and (4) dynamically adjusting transition probabilities to ensure the presence of target complex events while introducing slight noise for diversity. Users specify a target event scenario and a predefined \emph{AE} set to guide the simulation. Full details, including the exact prompt, are provided in Appendix~\ref{sec:llm_synthesizer}.

% One last thing is the online \emph{CE} labels. We use the prementioned FSMs to generate \emph{CE} labels. The reason why we do not also use LLM is due to the concern that LLMs cannot do CE reasoning reliably. We also did a small case study showing that LLMs are not reliable in our attempt, see Appendix~\ref{sec:llm_eval}.



% \subsection{Training \emph{CE} NAR}
% \textbf{\emph{AE} Tokenizor \& Embedding Encoder.}
% Before feeding AE traces to \emph{CE} NAR, we tokenize the \emph{AE} concept traces into token traces by creating a lookup vocabulary table for each \emph{AE}. The tokens are then passed an Embedding Encoder, which is a learnable embedding matrix that maps the tokens to the high-dimensial latent space. The dimension is 128.

% \textbf{Mamba-based \emph{CE} NAR.}
% We use a 12-layer Mamba,  same as the baseline Mamba models, to serve as the backbone of the NAR. The training loss is also the same Focal Loss (FL)[\ref{eq:fl}].

% \subsection{Training Sensor Adapter}
% We freeze the \emph{CE} NAR after training it with pseudo \emph{AE} concept traces. The sensor adapter, which aims to maps from sensor embedding to the latent reasnignspace of the NAR is trained using labeled sensor data. We use a 6-layer Mamba block, but it can be replaced by any other NN models. 



% We bring out \narce{}, as shown in Fig.~\ref{fig:narce_overview}, a framework that aims to reduce the data hunger for labeled sensor data. We hypothesize in \emph{Hypothesis II} that decoupling the learning of complex event rules from noisy sensor data improves data efficiency. \narce{} draws insights from the Neural Algorithmic Reasoning (NAR) paradigm (cite), which uses neural networks, particularly Graph Neural Networks (GNNs), to represent and learn algorithms by using symbolic algorithm input-output pairs for training. Analogously, in \narce{}, we treat each complex event rule as one type of algorithm and use a well-suited backbone model for CED, Mamba, to learn those rules. \narce{} contains a \emph{CE} NAR, which is a Mamba-based NAR, which leverages synthetic concept traces to learn \emph{CE} rules. Concept traces are sequences of atomic events governed by the same \emph{CE} rules we aim to detect generated using large language models (LLMs),  representing abstracted event sequences that encode rule-driven patterns without noisy sensor data. 



% Decoupling the CE Learning Task
% NARCE simplifies CE detection by decoupling the task into two stages:

% Learning CE Rules from Concept Traces: The reasoning module (Mamba-based NAR) is pretrained using synthetic concept traces to learn CE rules.
% Mapping Sensor Data to CE Rules: An encoder is trained to project sensor data embeddings into the latent space of the pretrained reasoning module.

% Key Claims of the NARCE Framework.
% Concept Samples Are Easier to Obtain and Verify
% Generating and verifying concept (or abstract) traces is significantly more efficient than collecting and annotating large sensor datasets. For example, consider the complex event rule: “The same person carrying a handbag appears nearby three times in an hour.” A corresponding concept trace for a fixed camera sampling rate might look like:

% ["None", "None", "pedestrian A with a handbag", "None", "pedestrian B", "None",  "pedestrian A with a handbag", "None", "None", "pedestrian A with a handbag", ...]
% Concept traces, such as the one above, provide structured and interpretable examples of rule-based behaviors. Using LLMs, we can efficiently generate simulation code for a given complex event rule, producing numerous concept samples for training. These synthetic samples are cheaper to obtain and easier to verify than real-world sensor data, which is often noisy, expensive to annotate, and time-intensive to collect.

% Decoupling the CE Learning Task Simplifies the Problem
% NARCE simplifies the original CE learning task by decoupling it into two stages:

% Stage 1: Learning CE Rules from Concept Traces
% Mamba-based NAR is pretrained on synthetic concept traces to learn latent representations of CE rules. This stage abstracts away the need for raw sensor inputs, focusing solely on understanding the logic and structure of complex events.
% Stage 2: Mapping Sensor Data to NAR Latent Space
% A separate encoder is trained to project sensor data embeddings into the latent space of the pretrained NAR. This two-stage approach allows the reasoning module to generalize across diverse rules while reducing the complexity of sensor data interpretation.
% This decoupled approach enables the framework to leverage the efficiency of pretrained NAR models and ensures that the sensor data processing does not interfere with the core task of rule reasoning. Furthermore, the pretrained NAR module serves as a reusable reasoning core that can generalize across multiple CE detection tasks.