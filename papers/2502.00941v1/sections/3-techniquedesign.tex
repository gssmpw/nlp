We designed a novel approach, Progressive Refinement for the Inspection of Multiscale Objects (PRIMO), to enable the inspection of dense, homogeneous objects. We opted to design a new approach because using traditional 2D methods: (1) the 3D nature and irregularity of the defects would require a user to go through multiple slices of data to try to understand the defects; (2) the user would likely have a lower understanding of the defect if constrained to 2D slices; and (3) it would be more difficult for the user to achieve a higher spatial awareness while navigating (by using VR we can have peripheral view as well as stereoscopy).

The initial requirements we defined included the need for a progressive approach (from global to localized visualizations) based on level of detail rendering (to render large objects but also focus on details), with reduced disorientation (to maintain smooth camera movement transitions while navigating) that achieved minimal to no simulator sickness and provided efficient navigation between levels of scale.

\subsection{Supporting Two Types of Navigation}
One of the first distinctions we made was acknowledging the difference and complementary nature between traditional navigation and multiscale navigation. While traditional navigation deals with translations and rotations across six degrees of freedom (DoF), multiscale navigation adds another three independent degrees of freedom. Managing them separately allows us to optimize them rather than trying to find a specific mapping that could control all nine DoFs together. Therefore, we opted to use a simple real-walking approach (via head tracking) for providing traditional navigation at the current level of scale. This technique is natural, intuitive to users, and less prone to simulator sickness.

For navigation across scales, we then decided to use uniform scaling with discrete levels. Prior research has shown that the act of scaling down into an object can produce simulator sickness \cite{krekhov_gullivr_2018, piumsomboon_superman_2018, cmentowski_outstanding_2019, abtahi_im_2019}. By defining discrete levels of scale and using simple clicks to scale up or down across levels, we could perform fast and precise multiscale traversals (half a second duration in our prototype). Such ``dashes'' have been repeatedly reported as reducing or eliminating simulator sickness \cite{krekhov_gullivr_2018, cmentowski_outstanding_2019}.

\subsection{Clipping Plane}
Another issue was determining an effective way to see the inside of a solid object. X-ray vision or other strategies that remove certain parts of the object \cite{bane_interactive_2004, lisle_clean_2022} would not be effective, as the object is homogeneous and defects may be spread through the entire volume. Our solution was to adopt a traditional clipping plane, often used in volume rendering systems \cite{viega_3d_1996, sousa_vrrrroom_2017}, such as for medical scan data and architectural modeling, to render part of the object invisible in real-time.

By allowing users to move the clipping plane with their 6-DoF hand controller, they could view any point inside the object. Initially, we provided clipping planes that could be translated or rotated arbitrarily. For the purposes of our prototype, we later decided to constrain them to 1-DoF movement along the vertical axis with no rotations, which still allowed access to any point but with a simple up-and-down movement. Users control the clipping plane through direct selection and manipulation using a simple virtual hand technique \cite{laviola_3d_2017}.

\subsection{Multiscale Navigation Style}
The next challenge was defining the levels of scale within the object and the navigation style for selecting a lower level of scale as the new focus. We decided to follow the concept of progressive refinement because of the characteristics of objects created in advanced manufacturing. As they are homogeneous and do not have clear structures to use as reference points, we needed a more systematic way of mapping the options available to users. One method is to divide the object into octants at each level of scale, giving users a simple way to keep track of the current subvolume and which subvolumes had already been inspected. Selecting an octant scales it up and makes it the new focus. We call this \textsc{structured} navigation. On the other hand, if \textsc{structured} navigation is too inflexible, we could allow users to position a cube freely inside the area of current focus, and scale up the region inside the cube to make it the new focus. We call this \textsc{unstructured} navigation. A comparison of the \textsc{structured} and \textsc{unstructured} approaches can be seen in \autoref{fig:teaser}). In both methods, the selection volume is controlled through a raycast \cite{laviola_3d_2017}.

\subsection{Display Mode}
We define the focus volume as the currently selected subvolume. To reduce occlusion and distraction, it may be beneficial to hide parts of the object outside the focus volume. This allows users to focus on their selected volume clearly, be able to see it from all sides, and easily select lower levels of scale within it. We call this the \textsc{selection} display mode. On the other hand, hiding parts of the object could affect a user's location awareness as they navigate, so we also define a second display mode called \textsc{everything}, in which the entire object (with the exception of the parts that are hidden by the clipping plane) remains visible as the user navigates through levels of scale.

\subsection{Scaling and Animation}
Instead of scaling the user down, we opted to scale the object up. The reasoning is that there are fewer modifications to camera attributes that could further impact simulator sickness \cite{krekhov_gullivr_2018}. When the user selects a lower level of scale, the system enlarges the object by a uniform scale factor of 2, animated for half a second (following suggestions from the literature \cite{krekhov_gullivr_2018, piumsomboon_superman_2018, cmentowski_outstanding_2019, abtahi_im_2019}). Thus, one octant (0.5 x 0.5 x 0.5) of the original object enlarges and takes up the same amount of space as the original object after scaling.

\subsection{Colors at Top Level}
At the top level of scale, we decided to paint the octants with unique colors. Our objective was to provide some degree of differentiation to the user that could be general enough to be applied to objects regardless of their geometry. Such colors can guide them to better understand direction and location, helping them keep track of which octants have already been inspected. Initially, we planned to change colors on the lower levels as the user moved into lower levels of scale, but the range of colors would get smaller at each lower level and make it difficult for the user to differentiate between them---our preliminary pilots showed it could lead to more confusion.