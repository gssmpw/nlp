
@inproceedings{pierce_navigation_2004,
	title = {Navigation with place representations and visible landmarks},
	doi = {10.1109/VR.2004.1310071},
	booktitle = {{IEEE} {Virtual} {Reality} 2004},
	author = {Pierce, J.S. and Pausch, R.},
	year = {2004},
	keywords = {Navigation, USA Councils, Virtual reality},
	pages = {173--288},
}

@inproceedings{viega_3d_1996,
	address = {New York, NY, USA},
	series = {{UIST} '96},
	title = {{3D} magic lenses},
	isbn = {0-89791-798-7},
	url = {https://doi.org/10.1145/237091.237098},
	doi = {10.1145/237091.237098},
	booktitle = {Proceedings of the 9th {Annual} {ACM} {Symposium} on {User} {Interface} {Software} and {Technology}},
	publisher = {Association for Computing Machinery},
	author = {Viega, John and Conway, Matthew J. and Williams, George and Pausch, Randy},
	year = {1996},
	note = {event-place: Seattle, Washington, USA},
	keywords = {3D graphics, clipping planes, magic lenses, transparent user interfaces, virtual reality},
	pages = {51--58},
}

@inproceedings{fernandes_combating_2016,
	title = {Combating {VR} sickness through subtle dynamic field-of-view modification},
	doi = {10.1109/3DUI.2016.7460053},
	booktitle = {2016 {IEEE} {Symposium} on {3D} {User} {Interfaces} ({3DUI})},
	author = {Fernandes, Ajoy S and Feiner, Steven K.},
	year = {2016},
	keywords = {Cameras, Geometry, Stereo image processing, Tracking, VR sickness, Virtual environments, Visual perception, cybersickness, field of view, head-worn display, virtual reality},
	pages = {201--210},
}

@inproceedings{sousa_vrrrroom_2017,
	address = {New York, NY, USA},
	series = {{CHI} '17},
	title = {{VRRRRoom}: {Virtual} {Reality} for {Radiologists} in the {Reading} {Room}},
	isbn = {978-1-4503-4655-9},
	url = {https://doi.org/10.1145/3025453.3025566},
	doi = {10.1145/3025453.3025566},
	abstract = {Reading room conditions such as illumination, ambient light, human factors and display luminance, play an important role on how radiologists analyze and interpret images. Indeed, serious diagnostic errors can appear when observing images through everyday monitors. Typically, these occur whenever professionals are ill-positioned with respect to the display or visualize images under improper light and luminance conditions. In this work, we show that virtual reality can assist radiodiagnostics by considerably diminishing or cancel out the effects of unsuitable ambient conditions. Our approach combines immersive head-mounted displays with interactive surfaces to support professional radiologists in analyzing medical images and formulating diagnostics. We evaluated our prototype with two senior medical doctors and four seasoned radiology fellows. Results indicate that our approach constitutes a viable, flexible, portable and cost-efficient option to traditional radiology reading rooms.},
	booktitle = {Proceedings of the 2017 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Sousa, Maurício and Mendes, Daniel and Paulo, Soraia and Matela, Nuno and Jorge, Joaquim and Lopes, Daniel Simões},
	year = {2017},
	note = {event-place: Denver, Colorado, USA},
	keywords = {interaction design, medical visualization, multitouch surfaces, virtual reality},
	pages = {4057--4062},
}

@inproceedings{bane_interactive_2004,
	title = {Interactive tools for virtual x-ray vision in mobile augmented reality},
	doi = {10.1109/ISMAR.2004.36},
	booktitle = {Third {IEEE} and {ACM} {International} {Symposium} on {Mixed} and {Augmented} {Reality}},
	author = {Bane, R. and Hollerer, T.},
	year = {2004},
	keywords = {Augmented reality, Buildings, Data security, Data visualization, Floors, Layout, Prototypes, Solids, System testing, Wireless networks},
	pages = {231--239},
}

@inproceedings{lisle_clean_2022,
	address = {Los Alamitos, CA, USA},
	title = {Clean the {Ocean}: {An} {Immersive} {VR} {Experience} {Proposing} {New} {Modifications} to {Go}-{Go} and {WiM} {Techniques}},
	url = {https://doi.ieeecomputersociety.org/10.1109/VRW55335.2022.00311},
	doi = {10.1109/VRW55335.2022.00311},
	abstract = {In this paper we present our solution to the 2022 3DUI Contest challenge. We aim to provide an immersive VR experience to increase player\&\#x27;s awareness of trash pollution in the ocean while improving the current interaction techniques in virtual environments. To achieve these objectives, we adapted two classic interaction techniques, Go-Go and World in Miniature (WiM), to provide an engaging minigame in which the user collects the trash in the ocean. To improve the precision and address occlusion issues in the traditional Go-Go technique we propose ReX Go-Go. We also propose an adaptation to WiM, referred to as Rabbit-Out-of-the-Hat to allow an exocentric interaction for easier object retrieval interaction.},
	booktitle = {2022 {IEEE} {Conference} on {Virtual} {Reality} and {3D} {User} {Interfaces} {Abstracts} and {Workshops} ({VRW})},
	publisher = {IEEE Computer Society},
	author = {Lisle, L. and Lu, F. and Davari, S. and Tahmid, I. and Giovannelli, A. and Llo, C. and Pavanatto, L. and Zhang, L. and Schlueter, L. and Bowman, D. A.},
	month = mar,
	year = {2022},
	keywords = {conferences, oceans, pollution, three-dimensional displays, user interfaces, virtual environments},
	pages = {920--921},
}

@article{bakker_effects_2003,
	title = {Effects of {Head}-{Slaved} {Navigation} and the {Use} of {Teleports} on {Spatial} {Orientation} in {Virtual} {Environments}},
	volume = {45},
	url = {https://doi.org/10.1518/hfes.45.1.160.27234},
	doi = {10.1518/hfes.45.1.160.27234},
	number = {1},
	journal = {Human Factors},
	author = {Bakker, Niels H. and Passenier, Peter O. and Werkhoven, Peter J.},
	year = {2003},
	pmid = {12916588},
	note = {\_eprint: https://doi.org/10.1518/hfes.45.1.160.27234},
	pages = {160--169},
}

@article{chheang_enabling_nodate,
	title = {Enabling {Additive} {Manufacturing} {Part} {Inspection} of {Digital} {Twins} via {Collaborative} {Virtual} {Reality}},
	abstract = {Digital twins (DTs) are an emerging capability in additive manufacturing (AM), set to revolutionize design optimization, inspection, in situ monitoring, and root cause analysis. AM DTs typically incorporate multimodal data streams, ranging from machine toolpaths and in-process imaging to X-ray CT scans and performance metrics. Despite the evolution of DT platforms, challenges remain in effectively inspecting them for actionable insights, either individually or in a multidisciplinary team setting. Quality assurance, manufacturing departments, pilot labs, and plant operations must collaborate closely to reliably produce parts at scale. This is particularly crucial in AM where complex structures require a collaborative and multidisciplinary approach. Additionally, the large-scale data originating from different modalities and their inherent 3D nature pose significant hurdles for traditional 2D desktop-based inspection methods. To address these challenges and increase the value proposition of DTs, we introduce a novel virtual reality (VR) framework to facilitate collaborative and real-time inspection of DTs in AM. This framework includes advanced features for intuitive alignment and visualization of multimodal data, visual occlusion management, streaming large-scale volumetric data, and collaborative tools, substantially improving the inspection of AM components and processes to fully exploit the potential of DTs in AM.},
	language = {en},
	author = {Chheang, Vuthea and Narain, Saurabh and Hooten, Garrett and Cerda, Robert and Au, Brian and Giera, Brian and Bremer, Peer-Timo and Miao, Haichao},
}

@inproceedings{zhao_l-wim_2022,
	address = {Singapore, Singapore},
	title = {L-{WiM}: {Collaborative} {Exploration} in {Immersive} {Environments}},
	isbn = {978-1-66545-365-3},
	shorttitle = {L-{WiM}},
	url = {https://ieeexplore.ieee.org/document/9974567/},
	doi = {10.1109/ISMAR-Adjunct57072.2022.00031},
	abstract = {An immersive environment provides multiple users a shared space for collaborative data explorations through head-mounted displays (HMDs). Effective collaboration is built based on different strategies, including the ability to focus on one’s own tasks, be aware of others’ location, orientation and scale, as well as share data/insights when needed. However, for astronomical data exploration, it might be the case that abundant information is distributed at multiple levels of magnitude. Therefore, it is difﬁcult to observe others’ contextual situations and exchange insights efﬁciently due to the reason that collaborators’ avatars may be too far or even in different scales. In this work, we use World-in-Miniature (WiM) to show the virtual environment at the level of each user. Based on that, we propose L-WiM, a novel interactive user interface for collaborative astronomical data exploration that links multiple WiMs. Through L-WiM, collaborators can see their contextual information at a glance, such as the scales, spatial locations, view directions as well as the surrounding environment. Users are supported to communicate via voice messages and visual cues after they select other users’ WiMs.},
	language = {en},
	urldate = {2023-02-22},
	booktitle = {2022 {IEEE} {International} {Symposium} on {Mixed} and {Augmented} {Reality} {Adjunct} ({ISMAR}-{Adjunct})},
	publisher = {IEEE},
	author = {Zhao, Lixiang and Cao, Nieyu and He, Shuqi and Liang, Hai-Ning and Yu, Lingyun},
	month = oct,
	year = {2022},
	note = {0 citations (Crossref) [2024-04-24]},
	pages = {118--123},
}

@inproceedings{ware_context_1997,
	address = {Providence, Rhode Island, United States},
	title = {Context sensitive flying interface},
	isbn = {978-0-89791-884-8},
	url = {http://portal.acm.org/citation.cfm?doid=253284.253319},
	doi = {10.1145/253284.253319},
	abstract = {The requirement to change scale frequently is common t o many 2D and 3D applications. Users must “zoom in” t o examine details and “zoom out” to appreciate the context. This presents a problem in the context of “fly by” interfaces that use a flying metaphor to enable the user to change the point of view and explore a data space. The problem is that radical changes in velocity sensitivity may needed when working at different scales. A method is described that uses continous depth sampling to modulate the flying speed. The distribution of depths in the current frame of animation i s used to set the Device to Control ratio so that it is always comfortable when operating over a range of scales. This i s called Depth Modulated Flying (DMF). A family of related methods are evaluated in a task that requires subjects to search for small targets in a scene. The results show that scaling the velocity control by the near point in the scene and by the average point in the scene are equally effective.},
	language = {en},
	urldate = {2023-02-22},
	booktitle = {Proceedings of the 1997 symposium on {Interactive} {3D} graphics  - {SI3D} '97},
	publisher = {ACM Press},
	author = {Ware, Colin and Fleet, Daniel},
	year = {1997},
	note = {40 citations (Crossref) [2024-04-24]},
	pages = {127--ff.},
}

@inproceedings{wingrave_overcoming_2006,
	address = {Alexandria, VA, USA},
	title = {Overcoming {World} in {Miniature} {Limitations} by a {Scaled} and {Scrolling} {WIM}},
	isbn = {978-1-4244-0225-0},
	url = {http://ieeexplore.ieee.org/document/1647500/},
	doi = {10.1109/VR.2006.106},
	abstract = {The World In Miniature (WIM) technique has effectively allowed users to interact and travel efficiently in Virtual Environments. However, WIM fails to work in worlds with tasks at various levels of scale. Such an example is using the WIM to arrange furniture and then leaving the room to travel the city using the WIM for navigation and wayfinding. To address this problem, scaling and scrolling were added to the WIM to create the Scaled Scrolling World In Miniature (SSWIM). The interface and testbed were iteratively created under expert evaluation and multiple formative user evaluations led to the final design. The WIM and SSWIM were then compared inside three differently sized cities by users who located a sphere and traveled into it to read the label at the sphere’s center. Users were administered two standard psychology tests to account for spatial orientation (Cube Comparison Test) and spatial scanning (Maze Tracing Test) factors. The results show that the SSWIM’s added functionality, and hence complexity, caused no significant hit in user performance and additionally that users were able to use SSWIM effectively after a short instructional period. To better understand the effect of experience, a follow-up experiment was performed showing performance plateaued after ten to fifteen minutes of use.},
	language = {en},
	urldate = {2023-02-16},
	booktitle = {{3D} {User} {Interfaces} ({3DUI}'06)},
	publisher = {IEEE},
	author = {Wingrave, C.A. and Haciahmetoglu, Y. and Bowman, D.A.},
	year = {2006},
	note = {25 citations (Crossref) [2024-04-24]},
	pages = {11--16},
}

@article{zhang_multiscale_2009,
	title = {Multiscale traveling: crossing the boundary between space and scale},
	volume = {13},
	issn = {1359-4338, 1434-9957},
	shorttitle = {Multiscale traveling},
	url = {http://link.springer.com/10.1007/s10055-009-0114-5},
	doi = {10.1007/s10055-009-0114-5},
	abstract = {Adding multiscale interaction capabilities to 3D virtual environments may permit work with huge virtual worlds that might otherwise be too large to manage. Multiscale technology has shown potential to support user interactions. This paper reports an experimental study of two multiscale traveling techniques. Our results show that while allowing a ﬂexible control on travel speed and accuracy is beneﬁcial, directly traversing the space-scale could be a challenge for users, probably due to difﬁculties in perceiving scalable virtual space and executing scaling operations. The results suggest that more research is needed to improve the understanding of the coupling of space and scale in multiscale user interface and to harness the full potentials of multiscale traveling techniques.},
	language = {en},
	number = {2},
	urldate = {2023-02-03},
	journal = {Virtual Reality},
	author = {Zhang, Xiaolong (Luke)},
	month = jun,
	year = {2009},
	note = {15 citations (Crossref) [2024-04-24]},
	pages = {101--115},
}

@inproceedings{trindade_improving_2011,
	address = {TaiChung Taiwan},
	title = {Improving {3D} navigation in multiscale environments using cubemap-based techniques},
	isbn = {978-1-4503-0113-8},
	url = {https://dl.acm.org/doi/10.1145/1982185.1982454},
	doi = {10.1145/1982185.1982454},
	abstract = {Navigation in virtual 3D environments, especially those with multiscale features, is still a problem for many users. In this regard, a good design of the navigation interfaces is critical to ensure that the users navigate with the best possible eﬃciency and comfort. In this paper, we present improvements made to two well-known interfaces: ﬂy, including support to collision treatment and automatic navigation speed adjustment in relation to scale, and examine, with automatic pivot point. Such techniques are based on the cubemap structure. Usability tests have shown a signiﬁcant improvement in the execution of navigation tasks.},
	language = {en},
	urldate = {2023-02-16},
	booktitle = {Proceedings of the 2011 {ACM} {Symposium} on {Applied} {Computing}},
	publisher = {ACM},
	author = {Trindade, Daniel R. and Raposo, Alberto B.},
	month = mar,
	year = {2011},
	note = {19 citations (Crossref) [2024-04-24]},
	pages = {1215--1221},
}

@inproceedings{mirhosseini_automatic_2017,
	address = {Los Angeles, CA, USA},
	title = {Automatic speed and direction control along constrained navigation paths},
	isbn = {978-1-5090-6647-6},
	url = {http://ieeexplore.ieee.org/document/7892228/},
	doi = {10.1109/VR.2017.7892228},
	abstract = {For many virtual reality applications, a pre-calculated ﬂy-through path is the de facto standard navigation method. Such a path is convenient for users and ensures coverage of critical areas throughout the scene. Traditional applications use constant camera speed, allow for fully user-controlled manual speed adjustment, or use automatic speed adjustment based on heuristics from the scene. We introduce two novel methods for constrained path navigation and exploration in virtual environments which rely on the natural orientation of the user’s head during scene exploration. Utilizing head tracking to obtain the user’s area of focus, we perform automatic camera speed adjustment to allow for natural off-axis scene examination. We expand this to include automatic camera navigation along the pre-computed path, abrogating the need for any navigational inputs from the user. Our techniques are applicable for any scene with a pre-computed navigation path, including medical applications such as virtual colonoscopy, coronary ﬂy-through, or virtual angioscopy, and graph navigation. We compare the traditional methods (constant speed and manual speed adjustment) and our two methods (automatic speed adjustment and automatic speed/direction control) to determine the effect of speed adjustment on system usability, mental load, performance, and user accuracy. Through this evaluation we observe the effect of automatic speed adjustment compared to traditional methods. We observed no negative impact from automatic navigation, and the users performed as well as with the manual navigation.},
	language = {en},
	urldate = {2023-02-16},
	booktitle = {2017 {IEEE} {Virtual} {Reality} ({VR})},
	publisher = {IEEE},
	author = {Mirhosseini, Seyedkoosha and Gutenko, Ievgeniia and Ojal, Sushant and Marino, Joseph and Kaufman, Arie E.},
	year = {2017},
	note = {10 citations (Crossref) [2024-04-24]},
	pages = {29--36},
}

@article{piumsomboon_superman_2018,
	title = {Superman vs {Giant}: {A} {Study} on {Spatial} {Perception} for a {Multi}-{Scale} {Mixed} {Reality} {Flying} {Telepresence} {Interface}},
	volume = {24},
	issn = {1077-2626, 1941-0506, 2160-9306},
	shorttitle = {Superman vs {Giant}},
	url = {https://ieeexplore.ieee.org/document/8466636/},
	doi = {10.1109/TVCG.2018.2868594},
	abstract = {The advancements in Mixed Reality (MR), Unmanned Aerial Vehicle, and multi-scale collaborative virtual environments have led to new interface opportunities for remote collaboration. This paper explores a novel concept of flying telepresence for multi-scale mixed reality remote collaboration. This work could enable remote collaboration at a larger scale such as building construction. We conducted a user study with three experiments. The first experiment compared two interfaces, static and dynamic IPD, on simulator sickness and body size perception. The second experiment tested the user perception of a virtual object size under three levels of IPD and movement gain manipulation with a fixed eye height in a virtual environment having reduced or rich visual cues. Our last experiment investigated the participant’s body size perception for two levels of manipulation of the IPDs and heights using stereo video footage to simulate a flying telepresence experience. The studies found that manipulating IPDs and eye height influenced the user’s size perception. We present our findings and share the recommendations for designing a multi-scale MR flying telepresence interface.},
	language = {en},
	number = {11},
	urldate = {2023-01-30},
	journal = {IEEE Transactions on Visualization and Computer Graphics},
	author = {Piumsomboon, Thammathip and Lee, Gun A. and Ens, Barrett and Thomas, Bruce H. and Billinghurst, Mark},
	month = nov,
	year = {2018},
	note = {37 citations (Crossref) [2024-04-24]},
	pages = {2974--2982},
}

@inproceedings{taunay_distributed_2019,
	address = {Rio de Janeiro, Brazil},
	title = {A {Distributed} {Approach} for {Automatic} {Speed} {Adjustment} {During} {Navigation} in {3D} {Multiscale} {Virtual} {Environments}},
	isbn = {978-1-72815-434-3},
	url = {https://ieeexplore.ieee.org/document/8921324/},
	doi = {10.1109/SVR.2019.00036},
	abstract = {Multiscale virtual environments (MSVEs) are virtual environments that encapsulate elements with different scales within a same shared space. They may contain elements with extremely different levels of scale in the same environment and can be found in geographical maps and engineering virtual environments (VEs). Due to its complexity and diverging levels of scale, this type of environment could be accessed using its hierarchical structure to navigate between the levels of scale. But, in geographical maps and engineering VEs users may need to freely navigate through the levels of scale seamlessly to provide improved spatial knowledge. Common approaches to navigate within these 3D virtual environments are based on the Automatic Speed Adjustment approach, where the scene is pre-processed in a data structure and then accessed in real-time to determine optimal speed. A common trend is to migrate this process from the CPU to GPU, but the works that use this approach are still limited to static and/or smaller virtual environments. As the scene grows in complexity, the computational power needed to render the 3D scene and determine optimal speed may be too costly. We propose RMNS (Remote Multiscale Network System) to solve this problem by using a service-oriented approach to compute speed and is asynchronously accessed to determine optimal speed. Our results show that our approach enables the use of dynamic scenes, as the rendering and speed adjustment are decoupled. Finally, the asynchronous nature of our approach showed that the response time is enough to support automatic speed adjustment, while maintaining the rendering in real-time.},
	language = {en},
	urldate = {2023-01-30},
	booktitle = {2019 21st {Symposium} on {Virtual} and {Augmented} {Reality} ({SVR})},
	publisher = {IEEE},
	author = {Taunay, Henrique and Medeiros, Daniel and Raposo, Alberto},
	month = oct,
	year = {2019},
	note = {3 citations (Crossref) [2024-04-24]},
	pages = {140--146},
}

@inproceedings{stoakley_virtual_1995,
	address = {Denver, Colorado, United States},
	title = {Virtual reality on a {WIM}: interactive worlds in miniature},
	isbn = {978-0-201-84705-5},
	shorttitle = {Virtual reality on a {WIM}},
	url = {http://portal.acm.org/citation.cfm?doid=223904.223938},
	doi = {10.1145/223904.223938},
	abstract = {This paper explores a user interface technique which augments an immersive head tracked display with a hand-held miniature copy of the virtual environment. We call this interface technique the Worlds in Miniature (WIM) metaphor. In addition to the first-person perspective offered by a virtual reality system, a World in Miniature offers a second dynamic viewport onto the virtual environment. Objects may be directly manipulated either through the immersive viewport or through the three-dimensional viewport offered by the WIM.},
	language = {en},
	urldate = {2023-01-30},
	booktitle = {Proceedings of the {SIGCHI} conference on {Human} factors in computing systems - {CHI} '95},
	publisher = {ACM Press},
	author = {Stoakley, Richard and Conway, Matthew J. and Pausch, Randy},
	year = {1995},
	note = {486 citations (Crossref) [2024-04-24]},
	pages = {265--272},
}

@article{pouke_plausibility_2021,
	title = {The {Plausibility} {Paradox} for {Resized} {Users} in {Virtual} {Environments}},
	volume = {2},
	issn = {2673-4192},
	url = {https://www.frontiersin.org/articles/10.3389/frvir.2021.655744/full},
	doi = {10.3389/frvir.2021.655744},
	abstract = {This paper identiﬁes and conﬁrms a perceptual phenomenon: when users interact with simulated objects in a virtual environment where the users’ scale deviates greatly from normal, there is a mismatch between the object physics they consider realistic and the object physics that would be correct at that scale. We report the ﬁndings of two studies investigating the relationship between perceived realism and a physically accurate approximation of reality in a virtual reality experience in which the user has been scaled by a factor of ten. Study 1 investigated perception of physics when scaled-down by a factor of ten, whereas Study 2 focused on enlargement by a similar amount. Studies were carried out as within-subjects experiments in which a total of 84 subjects performed simple interaction tasks with objects under two different physics simulation conditions. In the true physics condition, the objects, when dropped and thrown, behaved accurately according to the physics that would be correct at that either reduced or enlarged scale in the real world. In the movie physics condition, the objects behaved in a similar manner as they would if no scaling of the user had occurred. We found that a signiﬁcant majority of the users considered the movie physics condition to be the more realistic one. However, at enlarged scale, many users considered true physics to match their expectations even if they ultimately believed movie physics to be the realistic condition. We argue that our ﬁndings have implications for many virtual reality and telepresence applications involving operation with simulated or physical objects in abnormal and especially small scales.},
	language = {en},
	urldate = {2023-01-30},
	journal = {Frontiers in Virtual Reality},
	author = {Pouke, Matti and Mimnaugh, Katherine J. and Chambers, Alexis P. and Ojala, Timo and LaValle, Steven M.},
	month = apr,
	year = {2021},
	note = {7 citations (Crossref) [2024-04-24]},
	pages = {655744},
}

@inproceedings{lee_designing_2023,
	address = {Shanghai, China},
	title = {Designing {Viewpoint} {Transition} {Techniques} in {Multiscale} {Virtual} {Environments}},
	isbn = {9798350348156},
	url = {https://ieeexplore.ieee.org/document/10108464/},
	doi = {10.1109/VR55154.2023.00083},
	abstract = {Viewpoint transitions have been shown to improve users’ spatial orientation and help them build a cognitive map when they are navigating an unfamiliar virtual environment. Previous work has investigated transitions in single-scale virtual environments, focusing on trajectories and continuity. We extend this work with an in-depth investigation of transition techniques in multiscale virtual environments (MVEs). We identify challenges in navigating MVEs with nested structures and assess how different transition techniques affect spatial understanding and usability. Through two user studies, we investigated transition trajectories, interactive control of transition movement, and speed modulation in a nested MVE. We show that some types of viewpoint transitions enhance users’ spatial awareness and confidence in their spatial orientation and reduce the need to revisit a target point of interest multiple times.},
	language = {en},
	urldate = {2023-08-14},
	booktitle = {2023 {IEEE} {Conference} {Virtual} {Reality} and {3D} {User} {Interfaces} ({VR})},
	publisher = {IEEE},
	author = {Lee, Jong-In and Asente, Paul and Stuerzlinger, Wolfgang},
	month = mar,
	year = {2023},
	note = {2 citations (Crossref) [2024-04-24]},
	pages = {680--690},
}

@inproceedings{mccrae_multiscale_2009,
	address = {Boston Massachusetts},
	title = {Multiscale {3D} navigation},
	isbn = {978-1-60558-429-4},
	url = {https://dl.acm.org/doi/10.1145/1507149.1507151},
	doi = {10.1145/1507149.1507151},
	language = {en},
	urldate = {2023-02-09},
	booktitle = {Proceedings of the 2009 symposium on {Interactive} {3D} graphics and games},
	publisher = {ACM},
	author = {McCrae, James and Mordatch, Igor and Glueck, Michael and Khan, Azam},
	month = feb,
	year = {2009},
	note = {59 citations (Crossref) [2024-04-24]},
	pages = {7--14},
}

@inproceedings{menzner_above_2020,
	title = {Above {Surface} {Interaction} for {Multiscale} {Navigation} in {Mobile} {Virtual} {Reality}},
	doi = {10.1109/VR46266.2020.00057},
	booktitle = {2020 {IEEE} {Conference} on {Virtual} {Reality} and {3D} {User} {Interfaces} ({VR})},
	author = {Menzner, Tim and Gesslein, Travis and Otte, Alexander and Grubert, Jens},
	year = {2020},
	note = {8 citations (Crossref) [2024-04-24]},
	pages = {372--381},
}

@inproceedings{laviola_hands-free_2001,
	title = {Hands-free multi-scale navigation in virtual environments},
	isbn = {978-1-58113-292-2},
	url = {https://dl.acm.org/doi/10.1145/364338.364339},
	doi = {10.1145/364338.364339},
	abstract = {This paper presents a set of interaction techniques for hands-free multi-scale navigation through virtual environments. We believe that hands-free navigation, unlike the majority of navigation techniques based on hand motions, has the greatest potential for maximizing the interactivity of virtual environments since navigation modes are ofﬂoaded from modal hand gestures to more direct motions of the feet and torso. Not only are the users’ hands freed to perform tasks such as modeling, notetaking and object manipulation, but we also believe that foot and torso movements may inherently be more natural for some navigation tasks. The particular interactions that we developed include a leaning technique for moving small and medium distances, a foot-gesture controlled Step WIM that acts as a ﬂoor map for moving larger distances, and a viewing technique that enables a user to view a full 360 degrees in only a three-walled semi-immersive environment by subtly amplifying the mapping between their torso rotation and the virtual world. We formatively designed and evaluated our techniques in existing projects related to archaeological reconstructions, free-form modeling, and interior design. In each case, our informal observations have indicated that motions such as walking and leaning are both appropriate for navigation and are effective in cognitively simplifying complex virtual environment interactions since functionality is more evenly distributed across the body.},
	language = {en},
	urldate = {2023-01-30},
	booktitle = {Proceedings of the 2001 symposium on {Interactive} {3D} graphics},
	publisher = {ACM},
	author = {LaViola, Joseph J. and Feliz, Daniel Acevedo and Keefe, Daniel F. and Zeleznik, Robert C.},
	month = mar,
	year = {2001},
	note = {132 citations (Crossref) [2024-04-24]},
	pages = {9--15},
}

@inproceedings{lee_evaluating_2020,
	address = {Virtual Event Canada},
	title = {Evaluating {Automatic} {Parameter} {Control} {Methods} for {Locomotion} in {Multiscale} {Virtual} {Environments}},
	isbn = {978-1-4503-7619-8},
	url = {https://dl.acm.org/doi/10.1145/3385956.3418961},
	doi = {10.1145/3385956.3418961},
	abstract = {Virtual environments with a wide range of scales are becoming commonplace in Virtual Reality applications. Methods to control locomotion parameters can help users explore such environments more easily. For multi-scale virtual environments, point-and-teleport locomotion with a well-designed distance control method can enable mid-air teleportation, which makes it competitive to flying interfaces. Yet, automatic distance control for point-and-teleport has not been studied in such environments. We present a new method to automatically control the distance for point-and-teleport. In our first user study, we used a solar system environment to compare three methods: automatic distance control for point-and-teleport, manual distance control for point-and-teleport, and automatic speed control for flying. Results showed that automatic control significantly reduces overshoot compared with manual control for pointand-teleport, but the discontinuous nature of teleportation made users prefer flying with automatic speed control. We conducted a second study to compare automatic-speed-controlled flying and two versions of our teleportation method with automatic distance control, one incorporating optical flow cues. We found that pointand-teleport with optical flow cues and automatic distance control was more accurate than flying with automatic speed control, and both were equally preferred to point-and-teleport without the cues.},
	language = {en},
	urldate = {2023-01-30},
	booktitle = {26th {ACM} {Symposium} on {Virtual} {Reality} {Software} and {Technology}},
	publisher = {ACM},
	author = {Lee, Jong-In and Asente, Paul and Kim, Byungmoon and Kim, Yeojin and Stuerzlinger, Wolfgang},
	month = nov,
	year = {2020},
	note = {4 citations (Crossref) [2024-04-24]},
	pages = {1--10},
}

@inproceedings{klacansky_virtual_2022,
	title = {Virtual {Inspection} of {Additively} {Manufactured} {Parts}},
	doi = {10.1109/PacificVis53943.2022.00017},
	booktitle = {2022 {IEEE} 15th {Pacific} {Visualization} {Symposium} ({PacificVis})},
	author = {Klacansky, Pavol and Miao, Haichao and Gyulassy, Attila and Townsend, Andrew and Champley, Kyle and Tringe, Joseph and Pascucci, Valerio and Bremer, Peer-Timo},
	year = {2022},
	note = {3 citations (Crossref) [2024-04-24]},
	keywords = {Computational modeling, Computed tomography, Design automation, Human-centered computing—Visualization—Empirical studies in visualization, Human-centered computing—Visualization—Visualization application domains—Scientific visualization, Human-centered computing—Visualization—Visualization systems and tools, Solid modeling, Three-dimensional displays, Virtual reality, Volume measurement},
	pages = {81--90},
}

@inproceedings{krekhov_gullivr_2018,
	address = {Melbourne VIC Australia},
	title = {{GulliVR}: {A} {Walking}-{Oriented} {Technique} for {Navigation} in {Virtual} {Reality} {Games} {Based} on {Virtual} {Body} {Resizing}},
	isbn = {978-1-4503-5624-4},
	shorttitle = {{GulliVR}},
	url = {https://dl.acm.org/doi/10.1145/3242671.3242704},
	doi = {10.1145/3242671.3242704},
	language = {en},
	urldate = {2023-01-30},
	booktitle = {Proceedings of the 2018 {Annual} {Symposium} on {Computer}-{Human} {Interaction} in {Play}},
	publisher = {ACM},
	author = {Krekhov, Andrey and Cmentowski, Sebastian and Emmerich, Katharina and Masuch, Maic and Krüger, Jens},
	month = oct,
	year = {2018},
	note = {36 citations (Crossref) [2024-04-24]},
	pages = {243--256},
}

@article{kouril_hyperlabels_2021,
	title = {{HyperLabels}: {Browsing} of {Dense} and {Hierarchical} {Molecular} {3D} {Models}},
	volume = {27},
	issn = {1077-2626, 1941-0506, 2160-9306},
	shorttitle = {{HyperLabels}},
	url = {https://ieeexplore.ieee.org/document/9007694/},
	doi = {10.1109/TVCG.2020.2975583},
	abstract = {We present a method for the browsing of hierarchical 3D models in which we combine the typical navigation of hierarchical structures in a 2D environment—using clicks on nodes, links, or icons—with a 3D spatial data visualization. Our approach is motivated by large molecular models, for which the traditional single-scale navigational metaphors are not suitable. Multi-scale phenomena, e. g., in astronomy or geography, are complex to navigate due to their large data spaces and multi-level organization. Models from structural biology are in addition also densely crowded in space and scale. Cutaways are needed to show individual model subparts. The camera has to support exploration on the level of a whole virus, as well as on the level of a small molecule. We address these challenges by employing HyperLabels: active labels that—in addition to their annotational role—also support user interaction. Clicks on HyperLabels select the next structure to be explored. Then, we adjust the visualization to showcase the inner composition of the selected subpart and enable further exploration. Finally, we use a breadcrumbs panel for orientation and as a mechanism to traverse upwards in the model hierarchy. We demonstrate our concept of hierarchical 3D model browsing using two exemplary models from meso-scale biology.},
	language = {en},
	number = {8},
	urldate = {2023-01-30},
	journal = {IEEE Transactions on Visualization and Computer Graphics},
	author = {Kouril, David and Isenberg, Tobias and Kozlikova, Barbora and Meyer, Miriah and Groller, M. Eduard and Viola, Ivan},
	month = aug,
	year = {2021},
	note = {8 citations (Crossref) [2024-04-24]},
	pages = {3493--3504},
}

@inproceedings{kopper_design_2006,
	address = {Alexandria, VA, USA},
	title = {Design and {Evaluation} of {Navigation} {Techniques} for {Multiscale} {Virtual} {Environments}},
	isbn = {978-1-4244-0224-3},
	url = {http://ieeexplore.ieee.org/document/1667642/},
	doi = {10.1109/VR.2006.47},
	abstract = {The design of virtual environments for applications that have several levels of scale has not been deeply addressed. In particular, navigation in such environments is a signiﬁcant problem. This paper describes the design and evaluation of two navigation techniques for multiscale virtual environments (MSVEs). Issues such as spatial orientation and understanding were addressed in the design process of the navigation techniques. The evaluation of the techniques was done with two experimental and two control groups. The results show that the techniques we designed were signiﬁcantly better than the control conditions with respect to the time for task completion and accuracy.},
	language = {en},
	urldate = {2023-01-30},
	booktitle = {{IEEE} {Virtual} {Reality} {Conference} ({VR} 2006)},
	publisher = {IEEE},
	author = {Kopper, R. and {Tao Ni} and Bowman, D.A. and Pinho, M.},
	year = {2006},
	note = {46 citations (Crossref) [2024-04-24]},
	pages = {175--182},
}

@inproceedings{langbehn_scale_2016,
	address = {Greenville, SC, USA},
	title = {Scale matters! {Analysis} of dominant scale estimation in the presence of conflicting cues in multi-scale collaborative virtual environments},
	isbn = {978-1-5090-0842-1},
	url = {http://ieeexplore.ieee.org/document/7460054/},
	doi = {10.1109/3DUI.2016.7460054},
	abstract = {Multi-scale collaborative virtual environments (MCVEs) provide an important platform for many 3D application domains as they allow several users to cooperate in a virtual environment (VE) at different scale levels, ranging from magniﬁed detail views to miniﬁed overall views. However, in such MCVEs, the natural relations between a user’s self-representation, i. e., her virtual body, and the environment in terms of size, scale, proportion, capabilities, or affordances are subject to change during the interaction.},
	language = {en},
	urldate = {2023-01-30},
	booktitle = {2016 {IEEE} {Symposium} on {3D} {User} {Interfaces} ({3DUI})},
	publisher = {IEEE},
	author = {Langbehn, Eike and Bruder, Gerd and Steinicke, Frank},
	month = mar,
	year = {2016},
	note = {17 citations (Crossref) [2024-04-24]},
	pages = {211--220},
}

@inproceedings{freitag_automatic_2016,
	address = {Greenville, SC, USA},
	title = {Automatic speed adjustment for travel through immersive virtual environments based on viewpoint quality},
	isbn = {978-1-5090-0842-1},
	url = {http://ieeexplore.ieee.org/document/7460033/},
	doi = {10.1109/3DUI.2016.7460033},
	abstract = {When traveling virtually through large scenes, long distances and different detail densities render ﬁxed movement speeds impractical. However, to manually adjust the travel speed, users have to control an additional parameter, which may be uncomfortable and requires cognitive effort. Although automatic speed adjustment techniques exist, many of them can be problematic in indoor scenes. Therefore, we propose to automatically adjust travel speed based on viewpoint quality, originally a measure of the informativeness of a viewpoint. In a user study, we show that our technique is easy to use, allowing users to reach targets faster and use less cognitive resources than when choosing their speed manually.},
	language = {en},
	urldate = {2023-02-09},
	booktitle = {2016 {IEEE} {Symposium} on {3D} {User} {Interfaces} ({3DUI})},
	publisher = {IEEE},
	author = {Freitag, Sebastian and Weyers, Benjamin and Kuhlen, Torsten W.},
	month = mar,
	year = {2016},
	note = {18 citations (Crossref) [2024-04-24]},
	pages = {67--70},
}

@article{kennedy_simulator_1993,
	title = {Simulator {Sickness} {Questionnaire}: {An} {Enhanced} {Method} for {Quantifying} {Simulator} {Sickness}},
	volume = {3},
	issn = {1050-8414, 1532-7108},
	shorttitle = {Simulator {Sickness} {Questionnaire}},
	url = {http://www.tandfonline.com/doi/abs/10.1207/s15327108ijap0303_3},
	doi = {10.1207/s15327108ijap0303_3},
	language = {en},
	number = {3},
	urldate = {2023-02-09},
	journal = {The International Journal of Aviation Psychology},
	author = {Kennedy, Robert S. and Lane, Norman E. and Berbaum, Kevin S. and Lilienthal, Michael G.},
	month = jul,
	year = {1993},
	note = {3340 citations (Crossref) [2024-04-24]},
	pages = {203--220},
}

@inproceedings{furnas_space-scale_1995,
	address = {USA},
	series = {{CHI} '95},
	title = {Space-{Scale} {Diagrams}: {Understanding} {Multiscale} {Interfaces}},
	isbn = {0-201-84705-1},
	url = {https://doi.org/10.1145/223904.223934},
	doi = {10.1145/223904.223934},
	booktitle = {Proceedings of the {SIGCHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {ACM Press/Addison-Wesley Publishing Co.},
	author = {Furnas, George W. and Bederson, Benjamin B.},
	year = {1995},
	note = {140 citations (Crossref) [2024-04-24]
event-place: Denver, Colorado, USA},
	pages = {234--241},
}

@inproceedings{hartman_does_2020,
	address = {Virtual Event SC USA},
	title = {Does scaling player size skew one’s ability to correctly evaluate object sizes in a virtual environment?},
	isbn = {978-1-4503-8171-0},
	url = {https://dl.acm.org/doi/10.1145/3424636.3426908},
	doi = {10.1145/3424636.3426908},
	abstract = {This study attempts to evaluate whether a navigation technique based on scaling the user’s avatar impacts the user’s ability to correctly assess the size of virtual objects in a virtual environment. This study was realized during the CERN Open Days with data from 177 participants over eighteen years old. We were able to observe well-established phenomena such as the effect of interpupillary distance (IPD) on perception of scale, as well as original results associated with scaling factor and avatar embodiment. We observed that the user is more prone to overestimate object sizes from the Virtual Environment (VE) when provided with an avatar, while scaling the IPD according to the scale of the user’s avatar contributes to a reduction in the overestimation of object sizes within the VE.},
	language = {en},
	urldate = {2023-01-30},
	booktitle = {Motion, {Interaction} and {Games}},
	publisher = {ACM},
	author = {Hartman, Neal and Delahaye, Mathias and Decroix, Hugo and Herbelin, Bruno and Boulic, Ronan},
	month = oct,
	year = {2020},
	note = {1 citations (Crossref) [2024-04-24]},
	pages = {1--6},
}

@article{hildebrandt_assisting_2014,
	title = {An assisting, constrained {3D} navigation technique for multiscale virtual {3D} city models},
	volume = {18},
	issn = {1384-6175, 1573-7624},
	url = {http://link.springer.com/10.1007/s10707-013-0189-8},
	doi = {10.1007/s10707-013-0189-8},
	abstract = {Virtual 3D city models serve as integration platforms for complex geospatial and georeferenced information and as medium for effective communication of spatial information. In order to explore these information spaces, navigation techniques for controlling the virtual camera are required to facilitate wayfinding and movement. However, navigation is not a trivial task and many available navigation techniques do not support users effectively and efficiently with their respective skills and tasks. In this article, we present an assisting, constrained navigation technique for multiscale virtual 3D city models that is based on three basic principles: users point to navigate, users are lead by suggestions, and the exploitation of semantic, multiscale, hierarchical structurings of city models. The technique particularly supports users with low navigation and virtual camera control skills but is also valuable for experienced users. It supports exploration, search, inspection, and presentation tasks, is easy to learn and use, supports orientation, is efficient, and yields effective view properties. In particular, the technique is suitable for interactive kiosks and mobile devices with a touch display and low computing resources and for use in mobile situations where users only have restricted resources for operating the application. We demonstrate the validity of the proposed navigation technique by presenting an implementation and evaluation results. The implementation is based on service-oriented architectures, standards, and image-based representations and allows exploring massive virtual 3D city models particularly on mobile devices with limited computing resources. Results of a user study comparing the proposed navigation technique with standard techniques suggest that the proposed technique provides the targeted properties, and that it is more advantageous to novice than to expert users.},
	language = {en},
	number = {3},
	urldate = {2023-01-30},
	journal = {GeoInformatica},
	author = {Hildebrandt, Dieter and Timm, Robert},
	month = jul,
	year = {2014},
	note = {14 citations (Crossref) [2024-04-24]},
	pages = {537--567},
}

@article{darken_navigating_1996,
	title = {Navigating large virtual spaces},
	volume = {8},
	url = {https://doi.org/10.1080/10447319609526140},
	doi = {10.1080/10447319609526140},
	number = {1},
	journal = {International Journal of Human–Computer Interaction},
	author = {Darken, Rudolph P. and Sibert, John L.},
	year = {1996},
	note = {190 citations (Crossref) [2024-04-24]
Publisher: Taylor \& Francis
\_eprint: https://doi.org/10.1080/10447319609526140},
	pages = {49--71},
}

@article{bacim_design_2013,
	title = {Design and evaluation of {3D} selection techniques based on progressive refinement},
	volume = {71},
	issn = {10715819},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S1071581913000384},
	doi = {10.1016/j.ijhcs.2013.03.003},
	abstract = {Issues such as hand and tracker jitter negatively affect user performance with 3D selection techniques based on the ray-casting metaphor. This makes it difﬁcult for users to select objects that have a small visible area, since small targets require high levels of precision. We introduce an approach to address this issue that uses progressive reﬁnement of the set of selectable objects to reduce the required precision of the task. We present three exemplar techniques (sphere-casting reﬁned by QUAD menu (SQUAD), discrete zoom, and continuous zoom) and derive a preliminary design space for progressive reﬁnement from their characteristics. We explore the trade-offs between progressive reﬁnement and immediate selection techniques in two studies: ﬁrst comparing SQUAD to ray-casting; and second comparing the zooming techniques to ray-casting. In both studies, an analytical evaluation based on a distal pointing model and an empirical evaluation demonstrates that progressive reﬁnement selection can provide signiﬁcant beneﬁts compared to immediate techniques. In the ﬁrst study, SQUAD was much more accurate than ray-casting, and SQUAD was faster than ray-casting with small targets and less cluttered environments. The issue with SQUAD, however, is that it requires all selectable objects to be visually distinct. The zooming techniques address this issue by exploring other areas of the progressive reﬁnement design space. They allow users to use the spatial relationships among objects as criteria for selection and to increase precision without requiring precision in pointing. The results of the second study show that while the zooming techniques were signiﬁcantly slower than ray-casting, accuracy was much higher. Additionally, depending on the size of the target, users chose not to use zoom and, therefore, performed as fast as with ray-casting.},
	language = {en},
	number = {7-8},
	urldate = {2023-02-09},
	journal = {International Journal of Human-Computer Studies},
	author = {Bacim, Felipe and Kopper, Regis and Bowman, Doug A.},
	month = jul,
	year = {2013},
	note = {42 citations (Crossref) [2024-04-24]},
	pages = {785--802},
}

@inproceedings{cho_evaluating_2014,
	address = {MN, USA},
	title = {Evaluating dynamic-adjustment of stereo view parameters in a multi-scale virtual environment},
	isbn = {978-1-4799-3624-3},
	url = {http://ieeexplore.ieee.org/document/6798848/},
	doi = {10.1109/3DUI.2014.6798848},
	abstract = {Dynamic view parameter adjustment can reduce visual fatigue issues in stereo displays. In a multi-scale virtual environment, which has geometric details ranging over several orders of magnitude, these adjustments are particularly important. We evaluate how two adjustment techniques interact with 7 degree-offreedom navigation in desktop VR and a CAVE. The travel task has two stages, an initial targeted zoom and detailed geometric inspection. The results show benefits of the adjustments both for reducing fusion problems and for task completion time, but only in certain condition combinations. Peculiar view configuration examples show the difficulty of creating robust adjustment rules.},
	language = {en},
	urldate = {2023-02-09},
	booktitle = {2014 {IEEE} {Symposium} on {3D} {User} {Interfaces} ({3DUI})},
	publisher = {IEEE},
	author = {Cho, Isaac and Li, Jialei and Wartell, Zachary},
	month = mar,
	year = {2014},
	note = {4 citations (Crossref) [2024-04-24]},
	pages = {91--98},
}

@inproceedings{carvalho_dynamic_2011,
	address = {Uberlandia, TBD, Brazil},
	title = {Dynamic {Adjustment} of {Stereo} {Parameters} for {Virtual} {Reality} {Tools}},
	isbn = {978-1-4577-0661-5},
	url = {http://ieeexplore.ieee.org/document/5951836/},
	doi = {10.1109/SVR.2011.30},
	abstract = {Due to emerging new technologies in the development of interactive 3D applications (eg games and virtual reality), stereoscopic visualization is becoming a common feature. However, this fact does not solve some problems (nausea and headaches - cybersickness) related with the generation of this type of visualization. Some parameters have to be carefully chosen to create a comfortable stereo view, for example, eye distance, zero parallax plane distance, and the treatment of partially clipped objects in negative parallax. This paper presents a technique based on a CubeMap structure to dynamically adjust stereo parameters during the usage of two virtual reality tools in multi-scale 3D scenarios.},
	language = {en},
	urldate = {2023-02-09},
	booktitle = {2011 {XIII} {Symposium} on {Virtual} {Reality}},
	publisher = {IEEE},
	author = {Carvalho, Felipe and Trindade, Daniel R. and Dam, Peter F. and Raposo, Alberto and Santos, Ismael H. F. dos},
	month = may,
	year = {2011},
	note = {5 citations (Crossref) [2024-04-24]},
	pages = {66--72},
}

@inproceedings{cmentowski_outstanding_2019,
	address = {Barcelona Spain},
	title = {Outstanding: {A} {Multi}-{Perspective} {Travel} {Approach} for {Virtual} {Reality} {Games}},
	isbn = {978-1-4503-6688-5},
	shorttitle = {Outstanding},
	url = {https://dl.acm.org/doi/10.1145/3311350.3347183},
	doi = {10.1145/3311350.3347183},
	language = {en},
	urldate = {2023-01-30},
	booktitle = {Proceedings of the {Annual} {Symposium} on {Computer}-{Human} {Interaction} in {Play}},
	publisher = {ACM},
	author = {Cmentowski, Sebastian and Krekhov, Andrey and Krüger, Jens},
	month = oct,
	year = {2019},
	note = {27 citations (Crossref) [2024-04-24]},
	pages = {287--299},
}

@article{cho_multi-scale_2018,
	title = {Multi-{Scale} {7DOF} {View} {Adjustment}},
	volume = {24},
	issn = {1077-2626, 1941-0506, 2160-9306},
	url = {https://ieeexplore.ieee.org/document/7852469/},
	doi = {10.1109/TVCG.2017.2668405},
	abstract = {Multi-scale virtual environments contain geometric details ranging over several orders of magnitude and typically employ out-of-core rendering techniques. When displayed in virtual reality systems this entails using a 7 degree-of-freedom (DOF) view model where view scale is a separate 7th DOF in addition to 6DOF view pose. Dynamic adjustment of this and other view parameters become very important to usability. In this paper, we evaluate how two adjustment techniques interact with uni- and bi-manual 7DOF navigation in DesktopVR and a CAVE. The travel task has two stages, an initial targeted zoom and a detailed geometric inspection. The results show beneﬁts of the auto-adjustments on completion time and stereo fusion issues, but only in certain circumstances. Peculiar view conﬁguration examples show the difﬁculty of creating robust adjustment rules.},
	language = {en},
	number = {3},
	urldate = {2023-01-30},
	journal = {IEEE Transactions on Visualization and Computer Graphics},
	author = {Cho, Isaac and Li, Jialei and Wartell, Zachary},
	month = mar,
	year = {2018},
	note = {5 citations (Crossref) [2024-04-24]},
	pages = {1331--1344},
}

@inproceedings{argelaguet_adaptive_2014,
	address = {Minneapolis, MN},
	title = {Adaptive navigation for virtual environments},
	isbn = {978-1-4799-3624-3},
	url = {http://ieeexplore.ieee.org/document/7027325/},
	doi = {10.1109/3DUI.2014.7027325},
	abstract = {Navigation speed for most navigation interfaces is still determined by rate-control devices (e.g. joystick). The interface designer is in charge of adjusting the range of optimal speeds according to the scale of the environment and the desired user experience. However, this approach is not valid for complex environments (e.g. multi-scale environments). Optimal speeds might vary for each section of the environment, leading to non-desired side effects such as collisions or simulator sickness. Thereby, we propose a speedadaptation algorithm based on the spatial relationship between the user and the environment and the user’s perception of motion. The computed information is used to adjust the navigation speed in order to provide an optimal navigation speed and avoid collisions. Two main beneﬁts of our approach is ﬁrstly, the ability to adapt the navigation speed in multi-scale environments and secondly, the capacity to provide a smooth navigation experience by decreasing the jerkiness of described trajectories. The evaluation showed that our approach provides comparable performance as existing navigation techniques but it signiﬁcantly decreases the jerkiness of described trajectories.},
	language = {en},
	urldate = {2023-02-09},
	booktitle = {2014 {IEEE} {Symposium} on {3D} {User} {Interfaces} ({3DUI})},
	publisher = {IEEE},
	author = {Argelaguet, Ferran},
	month = mar,
	year = {2014},
	note = {21 citations (Crossref) [2024-04-24]},
	pages = {123--126},
}

@inproceedings{bacim_wayfinding_2009,
	address = {Lafayette, LA, USA},
	title = {Wayfinding techniques for {multiScale} virtual environments},
	isbn = {978-1-4244-3965-2},
	url = {http://ieeexplore.ieee.org/document/4811207/},
	doi = {10.1109/3DUI.2009.4811207},
	abstract = {Wayﬁnding in multiscale virtual environments can be rather complex, as users can and sometimes have to change their scale to access the entire environment. Hence, this work focuses on the understanding and classiﬁcation of information needed for travel, as well as on the design of navigation techniques that provide this information. To this end, we ﬁrst identiﬁed two kinds of information necessary for traveling effectively in this kind of environment: hierarchical information, based on the hierarchical structure formed by the levels of scale; and spatial information, related to orientation, distance between objects in different levels of scale and spatial localization. Based on this, we designed and implemented one technique for each kind of information. The developed techniques were evaluated and compared to a baseline set of travel and wayﬁnding aid techniques for traveling through multiple scales. Results show that the developed techniques perform better and provide a better solution for both travel and wayﬁnding aid.},
	language = {en},
	urldate = {2023-02-03},
	booktitle = {2009 {IEEE} {Symposium} on {3D} {User} {Interfaces}},
	publisher = {IEEE},
	author = {Bacim, Felipe and Bowman, Doug and Pinho, Marcio},
	year = {2009},
	note = {11 citations (Crossref) [2024-04-24]},
	pages = {67--74},
}

@article{al_zayer_virtual_2020,
	title = {Virtual {Locomotion}: {A} {Survey}},
	volume = {26},
	issn = {1077-2626, 1941-0506, 2160-9306},
	shorttitle = {Virtual {Locomotion}},
	url = {https://ieeexplore.ieee.org/document/8580399/},
	doi = {10.1109/TVCG.2018.2887379},
	abstract = {Virtual reality (VR) has enjoyed signiﬁcant popularity in recent years. Where navigation has been a fundamental appeal of 3D applications for decades, facilitating this in VR has been quite a challenge. Over the past decades, various virtual locomotion techniques (VLTs) have been developed that aim to offer natural, usable and efﬁcient ways of navigating VR without inducing VR sickness. Several studies of these techniques have been conducted in order to evaluate their performance in various study conditions and virtual contexts. Taxonomies have also been proposed to either place similar techniques in meaningful categories or decompose them to their underlying design components. In this survey, we aim to aggregate and understand the current state of the art of VR locomotion research and discuss the design implications of VLTs in terms of strengths, weaknesses and applicability.},
	language = {en},
	number = {6},
	urldate = {2023-01-30},
	journal = {IEEE Transactions on Visualization and Computer Graphics},
	author = {Al Zayer, Majed and MacNeilage, Paul and Folmer, Eelke},
	month = jun,
	year = {2020},
	note = {100 citations (Crossref) [2024-04-24]},
	pages = {2315--2334},
}

@inproceedings{argelaguet_giant_2016,
	address = {Munich Germany},
	title = {{GiAnt}: stereoscopic-compliant multi-scale navigation in {VEs}},
	isbn = {978-1-4503-4491-3},
	shorttitle = {{GiAnt}},
	url = {https://dl.acm.org/doi/10.1145/2993369.2993391},
	doi = {10.1145/2993369.2993391},
	abstract = {Navigation in multi-scale virtual environments (MSVE) requires the adjustment of the navigation parameters to ensure optimal navigation experiences at each level of scale. In particular, in immersive stereoscopic systems, e.g. when performing zoom-in and zoomout operations, the navigation speed and the stereoscopic rendering parameters have to be adjusted accordingly. Although this adjustment can be done manually by the user, it can be complex, tedious and strongly depends on the virtual environment. In this work we propose a new multi-scale navigation technique named GiAnt (GIant/ANT) which automatically and seamlessly adjusts the navigation speed and the scale factor of the virtual environment based on the user’s perceived navigation speed. The adjustment ensures an almost-constant perceived navigation speed while avoiding diplopia effects or diminished depth perception due to improper stereoscopic rendering conﬁgurations. The results from the conducted user evaluation shows that GiAnt is an efﬁcient multi-scale navigation which minimizes the changes of the scale factor of the virtual environment compared to state-of-the-art multi-scale navigation techniques.},
	language = {en},
	urldate = {2023-01-30},
	booktitle = {Proceedings of the 22nd {ACM} {Conference} on {Virtual} {Reality} {Software} and {Technology}},
	publisher = {ACM},
	author = {Argelaguet, Ferran and Maignant, Morgant},
	month = nov,
	year = {2016},
	note = {16 citations (Crossref) [2024-04-24]},
	pages = {269--277},
}

@inproceedings{abtahi_im_2019,
	address = {Glasgow Scotland Uk},
	title = {I'm a {Giant}: {Walking} in {Large} {Virtual} {Environments} at {High} {Speed} {Gains}},
	isbn = {978-1-4503-5970-2},
	shorttitle = {I'm a {Giant}},
	url = {https://dl.acm.org/doi/10.1145/3290605.3300752},
	doi = {10.1145/3290605.3300752},
	language = {en},
	urldate = {2023-01-30},
	booktitle = {Proceedings of the 2019 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {ACM},
	author = {Abtahi, Parastoo and Gonzalez-Franco, Mar and Ofek, Eyal and Steed, Anthony},
	month = may,
	year = {2019},
	note = {52 citations (Crossref) [2024-04-24]},
	pages = {1--13},
}

@article{al_zayer_virtual_2020-1,
	title = {Virtual {Locomotion}: {A} {Survey}},
	volume = {26},
	doi = {10.1109/TVCG.2018.2887379},
	number = {6},
	journal = {IEEE Transactions on Visualization and Computer Graphics},
	author = {Al Zayer, Majed and MacNeilage, Paul and Folmer, Eelke},
	year = {2020},
	keywords = {Legged locomotion, Monitoring, Navigation, Space exploration, Task analysis, Three-dimensional displays, Virtual reality, Visualization, survey, taxonomy, virtual locomotion, virtual navigation},
	pages = {2315--2334},
}

@misc{chheang_virtual_2024,
	title = {A {Virtual} {Environment} for {Collaborative} {Inspection} in {Additive} {Manufacturing}},
	author = {Chheang, Vuthea and Weston, Brian Thomas and Cerda, Robert William and Au, Brian and Giera, Brian and Bremer, Peer-Timo and Miao, Haichao},
	year = {2024},
	note = {\_eprint: 2403.08940},
}

@article{stone_color_2001,
	title = {Color and brightness appearance issues in tiled displays},
	volume = {21},
	doi = {10.1109/38.946632},
	number = {5},
	journal = {IEEE Computer Graphics and Applications},
	author = {Stone, M.C.},
	year = {2001},
	keywords = {Brightness, Cathode ray tubes, Computer displays, Filters, Lenses, Liquid crystal displays, Mirrors, Optical imaging, Optical scattering, Wheels},
	pages = {58--66},
}

@inproceedings{ens_ethereal_2014,
	address = {Honolulu Hawaii USA},
	title = {Ethereal planes: a design framework for {2D} information space in {3D} mixed reality environments},
	isbn = {978-1-4503-2820-3},
	shorttitle = {Ethereal planes},
	url = {https://dl.acm.org/doi/10.1145/2659766.2659769},
	doi = {10.1145/2659766.2659769},
	abstract = {Information spaces are virtual workspaces that help us manage information by mapping it to the physical environment. This widely influential concept has been interpreted in a variety of forms, often in conjunction with mixed reality. We present Ethereal Planes, a design framework that ties together many existing variations of 2D information spaces. Ethereal Planes is aimed at assisting the design of user interfaces for next-generation technologies such as head-worn displays. From an extensive literature review, we encapsulated the common attributes of existing novel designs in seven design dimensions. Mapping the reviewed designs to the framework dimensions reveals a set of common usage patterns. We discuss how the Ethereal Planes framework can be methodically applied to help inspire new designs. We provide a concrete example of the framework’s utility during the design of the Personal Cockpit, a window management system for head-worn displays.},
	language = {en},
	urldate = {2024-02-02},
	booktitle = {Proceedings of the 2nd {ACM} symposium on {Spatial} user interaction},
	publisher = {ACM},
	author = {Ens, Barrett and Hincapié-Ramos, Juan David and Irani, Pourang},
	month = oct,
	year = {2014},
	pages = {2--12},
}

@article{pavanatto_virtual_2023,
	title = {Virtual monitors vs. physical monitors: an empirical comparison for productivity work},
	volume = {4},
	issn = {2673-4192},
	url = {https://www.frontiersin.org/articles/10.3389/frvir.2023.1215820},
	doi = {10.3389/frvir.2023.1215820},
	journal = {Frontiers in Virtual Reality},
	author = {Pavanatto, Leonardo and Davari, Shakiba and Badea, Carmen and Stoakley, Richard and Bowman, Doug A.},
	year = {2023},
}

@inproceedings{hunan_university_china_multi-view_2023,
	title = {Multi-view visualization layout design method for large displays based on quantitative analysis of situation awareness},
	isbn = {978-1-912294-59-6},
	url = {https://dl.designresearchsociety.org/iasdr/iasdr2023/fullpapers/171},
	doi = {10.21606/iasdr.2023.481},
	language = {en},
	urldate = {2023-12-14},
	booktitle = {{IASDR} 2023: {Life}-{Changing} {Design}},
	publisher = {Design Research Society},
	author = {{Hunan University, China} and Ji, Peng},
	month = oct,
	year = {2023},
}

@article{ullah_exploring_2023,
	title = {Exploring {Users} {Pointing} {Performance} on {Large} {Displays} with {Different} {Curvatures} in {Virtual} {Reality}},
	volume = {29},
	issn = {1077-2626, 1941-0506, 2160-9306},
	url = {https://ieeexplore.ieee.org/document/10269032/},
	doi = {10.1109/TVCG.2023.3320242},
	abstract = {Large curved displays inside Virtual Reality environments are becoming popular for visualizing high-resolution content during analytical tasks, gaming or entertainment. Prior research showed that such displays provide a wide field of view and offer users a high level of immersion. However, little is known about users’ performance (e.g., pointing speed and accuracy) on them. We explore users’ pointing performance on large virtual curved displays. We investigate standard pointing factors (e.g., target width and amplitude) in combination with relevant curve-related factors, namely display curvature and both linear and angular measures. Our results show that the less curved the display, the higher the performance, i.e., faster movement time. This result holds for pointing tasks controlled via their visual properties (linear widths and amplitudes) or their motor properties (angular widths and amplitudes). Additionally, display curvatures significantly affect the error rate for both linear and angular conditions. Furthermore, we observe that curved displays perform better or similar to flat displays based on throughput analysis. Finally, we discuss our results and provide suggestions regarding pointing tasks on large curved displays in VR.},
	language = {en},
	number = {11},
	urldate = {2023-12-14},
	journal = {IEEE Transactions on Visualization and Computer Graphics},
	author = {Ullah, A K M Amanat and Delamare, William and Hasan, Khalad},
	month = nov,
	year = {2023},
	pages = {4535--4545},
}

@inproceedings{cheng_interactionadapt_2023,
	address = {San Francisco CA USA},
	title = {{InteractionAdapt}: {Interaction}-driven {Workspace} {Adaptation} for {Situated} {Virtual} {Reality} {Environments}},
	isbn = {9798400701320},
	shorttitle = {{InteractionAdapt}},
	url = {https://dl.acm.org/doi/10.1145/3586183.3606717},
	doi = {10.1145/3586183.3606717},
	language = {en},
	urldate = {2023-11-08},
	booktitle = {Proceedings of the 36th {Annual} {ACM} {Symposium} on {User} {Interface} {Software} and {Technology}},
	publisher = {ACM},
	author = {Cheng, Yi Fei and Gebhardt, Christoph and Holz, Christian},
	month = oct,
	year = {2023},
	pages = {1--14},
}

@article{noauthor_investigating_2024,
	title = {Investigating {Rotational} and {Translational} {Mid}-{Air} {Interactions} in {Extended} {Reality}},
	language = {en},
	year = {2024},
}

@article{shikdar_office_2007,
	title = {Office {Ergonomics}: {Deficiencies} in {Computer} {Workstation} {Design}},
	volume = {13},
	issn = {1080-3548, 2376-9130},
	shorttitle = {Office {Ergonomics}},
	url = {https://www.tandfonline.com/doi/full/10.1080/10803548.2007.11076722},
	doi = {10.1080/10803548.2007.11076722},
	language = {en},
	number = {2},
	urldate = {2023-09-15},
	journal = {International Journal of Occupational Safety and Ergonomics},
	author = {Shikdar, Ashraf A. and Al-Kindi, Mahmoud A.},
	month = jan,
	year = {2007},
	pages = {215--223},
}

@article{xiong_augmented_2021,
	title = {Augmented reality and virtual reality displays: emerging technologies and future perspectives},
	volume = {10},
	issn = {2047-7538},
	shorttitle = {Augmented reality and virtual reality displays},
	url = {https://www.nature.com/articles/s41377-021-00658-8},
	doi = {10.1038/s41377-021-00658-8},
	abstract = {With rapid advances in high-speed communication and computation, augmented reality (AR) and virtual reality (VR) are emerging as next-generation display platforms for deeper human-digital interactions. Nonetheless, to simultaneously match the exceptional performance of human vision and keep the near-eye display module compact and lightweight imposes unprecedented challenges on optical engineering. Fortunately, recent progress in holographic optical elements (HOEs) and lithography-enabled devices provide innovative ways to tackle these obstacles in AR and VR that are otherwise difﬁcult with traditional optics. In this review, we begin with introducing the basic structures of AR and VR headsets, and then describing the operation principles of various HOEs and lithographyenabled devices. Their properties are analyzed in detail, including strong selectivity on wavelength and incident angle, and multiplexing ability of volume HOEs, polarization dependency and active switching of liquid crystal HOEs, device fabrication, and properties of micro-LEDs (light-emitting diodes), and large design freedoms of metasurfaces.},
	language = {en},
	number = {1},
	urldate = {2023-09-14},
	journal = {Light: Science \& Applications},
	author = {Xiong, Jianghao and Hsiang, En-Lin and He, Ziqian and Zhan, Tao and Wu, Shin-Tson},
	month = oct,
	year = {2021},
	pages = {216},
}

@article{blinded_virtual_2023,
	title = {Virtual {Monitors} vs. {Physical} {Monitors}: an {Empirical} {Comparison} for {Productivity} {Work}},
	journal = {To Appear in Frontiers in Virtual Reality},
	author = {Blinded},
	year = {2023},
}

@inproceedings{logas_conversational_2021,
	address = {Rovaniemi Finland},
	title = {Conversational {Partner}’s {Perception} of {Subtle} {Display} {Use} for {Monitoring} {Notifications}},
	isbn = {978-1-4503-8428-5},
	url = {https://dl.acm.org/doi/10.1145/3458709.3458942},
	doi = {10.1145/3458709.3458942},
	abstract = {We examine whether the gaze direction of a user reveals the use of a subtle display during a face-to-face conversation with a partner who is not initially aware of the display. We measure twelve participants’ perceptions of a casual conversational partner’s engagement between a control condition of no notification and notifications displayed behind the participant’s head at 0, 10, and 20 degrees to the right of the conversational partner’s line of sight. No differences in reported conversational engagement were found. However, once the presence of the display was revealed, engagement scores went down over all conditions compared to the prior uninformed variant of the experiment. Still, no difference was found between the control and the subtle display conditions, and informed participants were only 40\% accurate on average in detecting the use of the display. In a second study comparing subtle display user engagement with smartwatch user engagement, six participants rated a conversational partner more distracted when the partner used a smartwatch to monitor notifications than when the partner used a display secretly mounted behind the participant’s head. Participants in both studies did not realize the presence of the display until it was revealed. These results suggest that eye movement when using a subtle display detracts less from the conversational experience than the use of a smartwatch.},
	language = {en},
	urldate = {2023-09-13},
	booktitle = {Augmented {Humans} {Conference} 2021},
	publisher = {ACM},
	author = {Logas, Jacob and Lin, Georgianna and Belan, Kelsie and Gogate, Advait and Starner, Thad},
	month = feb,
	year = {2021},
	pages = {101--110},
}

@inproceedings{koelle_dont_2015,
	address = {Copenhagen Denmark},
	title = {Don't look at me that way!: {Understanding} {User} {Attitudes} {Towards} {Data} {Glasses} {Usage}},
	isbn = {978-1-4503-3652-9},
	shorttitle = {Don't look at me that way!},
	url = {https://dl.acm.org/doi/10.1145/2785830.2785842},
	doi = {10.1145/2785830.2785842},
	abstract = {Data glasses do carry promising potential for hands-free interaction, but also raise various concerns amongst their potential users. In order to gain insights into the nature of those concerns, we investigate how potential usage scenarios are perceived by device users and their peers. We present results of a two-step approach: a focus group discussion with 7 participants, and a user study with 38 participants. In particular, we look into differences between the usage of data glasses and more established devices such as smart phones. We provide quantitative measures for scenario-related social acceptability and point out factors that can inﬂuence user attitudes. Based on our quantitative and qualitative results, we derive design implications that might support the development of head-worn devices and applications with an improved social acceptability.},
	language = {en},
	urldate = {2023-09-13},
	booktitle = {Proceedings of the 17th {International} {Conference} on {Human}-{Computer} {Interaction} with {Mobile} {Devices} and {Services}},
	publisher = {ACM},
	author = {Koelle, Marion and Kranz, Matthias and Möller, Andreas},
	month = aug,
	year = {2015},
	pages = {362--372},
}

@inproceedings{laviola_using_2015,
	title = {Using augmented reality to tutor military tasks in the wild},
	booktitle = {Proceedings of the {Interservice}/{Industry} {Training} {Simulation} \& {Education} {Conference}, {Orlando}, {Florida}},
	author = {LaViola, J and Williamson, B and Brooks, Conner and Veazanchin, Sergiu and Sottilare, Robert and Garrity, Pat},
	year = {2015},
}

@article{steed_wild_2016,
	title = {An ‘{In} the {Wild}’ {Experiment} on {Presence} and {Embodiment} using {Consumer} {Virtual} {Reality} {Equipment}},
	volume = {22},
	issn = {1077-2626},
	url = {http://ieeexplore.ieee.org/document/7383331/},
	doi = {10.1109/TVCG.2016.2518135},
	language = {en},
	number = {4},
	urldate = {2023-09-13},
	journal = {IEEE Transactions on Visualization and Computer Graphics},
	author = {Steed, Anthony and Frlston, Sebastian and Lopez, Maria Murcia and Drummond, Jason and Pan, Ye and Swapp, David},
	month = apr,
	year = {2016},
	pages = {1406--1414},
}

@inproceedings{schmelter_towards_2023,
	address = {Hamburg Germany},
	title = {Towards {More} {Inclusive} and {Accessible} {Virtual} {Reality}: {Conducting} {Large}-scale {Studies} in the {Wild}},
	isbn = {978-1-4503-9422-2},
	shorttitle = {Towards {More} {Inclusive} and {Accessible} {Virtual} {Reality}},
	url = {https://dl.acm.org/doi/10.1145/3544549.3583888},
	doi = {10.1145/3544549.3583888},
	language = {en},
	urldate = {2023-09-13},
	booktitle = {Extended {Abstracts} of the 2023 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {ACM},
	author = {Schmelter, Thereza and Kruse, Lucie and Karaosmanoglu, Sukran and Rings, Sebastian and Steinicke, Frank and Hildebrand, Kristian},
	month = apr,
	year = {2023},
	pages = {1--5},
}

@inproceedings{petersen_pedagogical_2021,
	address = {Yokohama Japan},
	title = {Pedagogical {Agents} in {Educational} {VR}: {An} in the {Wild} {Study}},
	isbn = {978-1-4503-8096-6},
	shorttitle = {Pedagogical {Agents} in {Educational} {VR}},
	url = {https://dl.acm.org/doi/10.1145/3411764.3445760},
	doi = {10.1145/3411764.3445760},
	abstract = {Pedagogical agents are theorized to increase humans’ efort to understand computerized instructions. Despite the pedagogical promises of VR, the usefulness of pedagogical agents in VR remains uncertain. Based on this gap, and inspired by global eforts to advance remote learning during the COVID-19 pandemic, we conducted an educational VR study in-the-wild (N = 161). With a 2 × 2 + 1 between subjects design, we manipulated the appearance and behavior of a virtual museum guide in an exhibition about viruses. Factual and conceptual learning outcomes as well as subjective learning experience measures were collected. In general, participants reported high enjoyment and had signifcant knowledge acquisition. We found that the agent’s appearance and behavior impacted factual knowledge gain. We also report an interaction efect between behavioral and visual realism for conceptual knowledge gain. Our fndings nuance classical multimedia learning theories and provide directions for employing agents in immersive learning environments.},
	language = {en},
	urldate = {2023-09-13},
	booktitle = {Proceedings of the 2021 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {ACM},
	author = {Petersen, Gustav Bøg and Mottelson, Aske and Makransky, Guido},
	month = may,
	year = {2021},
	pages = {1--12},
}

@inproceedings{ragozin_mazerunvr_2020,
	address = {Honolulu HI USA},
	title = {{MazeRunVR}: {An} {Open} {Benchmark} for {VR} {Locomotion} {Performance}, {Preference} and {Sickness} in the {Wild}},
	isbn = {978-1-4503-6819-3},
	shorttitle = {{MazeRunVR}},
	url = {https://dl.acm.org/doi/10.1145/3334480.3383035},
	doi = {10.1145/3334480.3383035},
	abstract = {Locomotion in virtual reality (VR) is one of the biggest problems for large scale adoption of VR applications. Yet, to our knowledge, there are few studies conducted in-the-wild to understand performance metrics and general user preference for different mechanics. In this paper, we present the ﬁrst steps towards an open framework to create a VR locomotion benchmark. As a viability study, we investigate how well the users move in VR when using three different locomotion mechanics. It was played in over 124 sessions across 10 countries in a period of three weeks. The included prototype locomotion mechanics are arm swing, walk-in-place and trackpad movement. We found that overall, users performed signiﬁcantly faster using arm swing and trackpad when compared to walk-in-place. For subjective preference, arm swing was signiﬁcantly more preferred over the other two methods. Finally for induced sickness, walkin-place was the overall most sickness-inducing locomotion method.},
	language = {en},
	urldate = {2023-09-13},
	booktitle = {Extended {Abstracts} of the 2020 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {ACM},
	author = {Ragozin, Kirill and Kunze, Kai and Marky, Karola and Pai, Yun Suen},
	month = apr,
	year = {2020},
	pages = {1--8},
}

@misc{arora_thinking_2021,
	title = {Thinking {Outside} the {Lab}: {VR} {Size} \& {Depth} {Perception} in the {Wild}},
	shorttitle = {Thinking {Outside} the {Lab}},
	url = {http://arxiv.org/abs/2105.00584},
	abstract = {Size and distance perception in Virtual Reality (VR) have been widely studied, albeit in a controlled laboratory setting with a small number of participants. We describe a fully remote perceptual study with a gamified protocol to encourage participant engagement, which allowed us to quickly collect high-quality data from a large, diverse participant pool (N=60). Our study aims to understand medium-field size and egocentric distance perception in real-world usage of consumer VR devices. We utilized two perceptual matching tasks—distance bisection and size matching—at the same target distances of 1–9 metres. While the bisection protocol indicated a near-universal trend of nonlinear distance compression, the size matching estimates were more equivocal. Varying eye-height from the floor plane showed no significant effect on the judgements. We also discuss the pros and cons of a fully remote perceptual study in VR, the impact of hardware variation, and measures needed to ensure high-quality data. CCS Concepts: • Human-centered computing → Virtual reality; • Computing methodologies → Perception.},
	language = {en},
	urldate = {2023-09-13},
	publisher = {arXiv},
	author = {Arora, Rahul and Li, Jiannan and Shi, Gongyi and Singh, Karan},
	month = may,
	year = {2021},
	note = {arXiv:2105.00584 [cs]},
	keywords = {Computer Science - Human-Computer Interaction, H.1.2, H.5.1},
}

@misc{steed_lessons_2021,
	title = {Some {Lessons} {Learned} {Running} {Virtual} {Reality} {Experiments} {Out} of the {Laboratory}},
	url = {http://arxiv.org/abs/2104.05359},
	abstract = {In the past twelve months, our team has had to move rapidly from conducting most of our user experiments in a laboratory setting, to running experiments in the wild away from the laboratory and without direct synchronous oversight from an experimenter. This has challenged us to think about what types of experiment we can run, and to improve our tools and methods to allow us to reliably capture the necessary data. It has also offered us an opportunity to engage with a more diverse population than we would normally engage with in the laboratory. In this position paper we elaborate on the challenges and opportunities, and give some lessons learned from our own experience.},
	language = {en},
	urldate = {2023-09-13},
	publisher = {arXiv},
	author = {Steed, Anthony and Archer, Daniel and Congdon, Ben and Friston, Sebastian and Swapp, David and Thiel, Felix J.},
	month = apr,
	year = {2021},
	note = {arXiv:2104.05359 [cs]},
	keywords = {Computer Science - Human-Computer Interaction},
}

@inproceedings{colley_hedonic_2017,
	address = {Maui Hawaii},
	title = {Hedonic design for winter {UbiMount}: illuminated snowboard in-the-wild},
	isbn = {978-1-4503-5190-4},
	shorttitle = {Hedonic design for winter {UbiMount}},
	url = {https://dl.acm.org/doi/10.1145/3123024.3124442},
	doi = {10.1145/3123024.3124442},
	abstract = {We present a functional prototype of an interactive illuminated snowboard, which was trialed in-the-wild. We discuss the challenges in prototyping and evaluating ubiquitous computing demos in-the-wild in the winter mountain context. Equipment related issues such as reduced battery capacity, and camera functionality at low temperatures are identified as particular problems. Prototype design should enable operation whilst wearing gloves, for example switching test modes, via motion gestures. The necessity to open prototype devices to make adjustment whilst in-thewild should be avoided.},
	language = {en},
	urldate = {2023-09-13},
	booktitle = {Proceedings of the 2017 {ACM} {International} {Joint} {Conference} on {Pervasive} and {Ubiquitous} {Computing} and {Proceedings} of the 2017 {ACM} {International} {Symposium} on {Wearable} {Computers}},
	publisher = {ACM},
	author = {Colley, Ashley and Häkkilä, Jonna},
	month = sep,
	year = {2017},
	pages = {1027--1032},
}

@inproceedings{colley_skiing_2015,
	address = {Tampere Finland},
	title = {Skiing in a blended virtuality: an in-the-wild experiment},
	isbn = {978-1-4503-3948-3},
	shorttitle = {Skiing in a blended virtuality},
	url = {https://dl.acm.org/doi/10.1145/2818187.2818288},
	doi = {10.1145/2818187.2818288},
	abstract = {In this paper we describe a concept of using a Head Mounted Display (HMD) whilst downhill skiing and snowboarding, and experimenting with it in-the-wild on a skiing slope. The wearer experiences an alternative Virtual Reality (VR) visually through the HMD whilst their other sensory inputs experience the full sensation of real-world skiing, creating a blended virtual/real experience. To enable accurate tracking of the wearer’s motion, we implemented a ‘snow mouse’ device, which rotates on the snow as the skier moves and enables dead-reckoning of the user’s position. The prototype device was evaluated in-the-wild, on downhill ski slopes by both a skier and a snowboarder. Initial feedback suggests the level of immersion achieved is high, and particularly, users noticed the non-visual aspects of the experience.},
	language = {en},
	urldate = {2023-09-13},
	booktitle = {Proceedings of the 19th {International} {Academic} {Mindtrek} {Conference}},
	publisher = {ACM},
	author = {Colley, Ashley and Väyrynen, Jani and Häkkilä, Jonna},
	month = sep,
	year = {2015},
	pages = {89--91},
}

@incollection{rogers_why_2007,
	address = {Berlin, Heidelberg},
	title = {Why {It}’s {Worth} the {Hassle}: {The} {Value} of {In}-{Situ} {Studies} {When} {Designing} {Ubicomp}: ({Nominated} for the {Best} {Paper} {Award})},
	volume = {4717},
	isbn = {978-3-540-74852-6 978-3-540-74853-3},
	shorttitle = {Why {It}’s {Worth} the {Hassle}},
	url = {http://link.springer.com/10.1007/978-3-540-74853-3_20},
	abstract = {How should Ubicomp technologies be evaluated? While lab studies are good at sensing aspects of human behavior and revealing usability problems, they are poor at capturing context of use. In-situ studies are good at demonstrating how people appropriate technologies in their intended setting, but are expensive and difficult to conduct. Here, we show how they can be used more productively in the design process. A mobile learning device was developed to support teams of students carrying out scientific inquiry in the field. An initial in-situ study showed it was not used in the way envisioned. A contextualized analysis led to a comprehensive understanding of the user experience, usability and context of use, leading to a substantial redesign. A second in-situ study showed a big improvement in device usability and collaborative learning. We discuss the findings and conclude how in-situ studies can play an important role in the design and evaluation of Ubicomp applications and user experiences.},
	language = {en},
	urldate = {2023-09-13},
	booktitle = {{UbiComp} 2007: {Ubiquitous} {Computing}},
	publisher = {Springer Berlin Heidelberg},
	author = {Rogers, Yvonne and Connelly, Kay and Tedesco, Lenore and Hazlewood, William and Kurtz, Andrew and Hall, Robert E. and Hursey, Josh and Toscos, Tammy},
	editor = {Hutchison, David and Kanade, Takeo and Kittler, Josef and Kleinberg, Jon M. and Mattern, Friedemann and Mitchell, John C. and Naor, Moni and Nierstrasz, Oscar and Pandu Rangan, C. and Steffen, Bernhard and Sudan, Madhu and Terzopoulos, Demetri and Tygar, Doug and Vardi, Moshe Y. and Weikum, Gerhard and Krumm, John and Abowd, Gregory D. and Seneviratne, Aruna and Strang, Thomas},
	year = {2007},
	doi = {10.1007/978-3-540-74853-3_20},
	note = {Series Title: Lecture Notes in Computer Science},
	pages = {336--353},
}

@inproceedings{jambon_user_2009,
	address = {Boston MA USA},
	title = {User experience evaluation in the wild},
	isbn = {978-1-60558-247-4},
	url = {https://dl.acm.org/doi/10.1145/1520340.1520619},
	doi = {10.1145/1520340.1520619},
	abstract = {This article details experience feedback resulting from a user experience study in the wild (i.e. in-situ). The system under test was a mobile device for skiers, which aimed at improving their users’ experience. The skiers were equipped with a mini-camera, an accelerometer and a geo-localization system. Thanks to a smartphone, they could replay, on trails, theirs best performances (video, maximum speed, ...). The article focuses both on the methodological and the technological issues encountered during these experimentations, and proposes recommendations.},
	language = {en},
	urldate = {2023-09-13},
	booktitle = {{CHI} '09 {Extended} {Abstracts} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {ACM},
	author = {Jambon, Francis and Meillon, Brigitte},
	month = apr,
	year = {2009},
	pages = {4069--4074},
}

@inproceedings{brown_into_2011,
	address = {Vancouver BC Canada},
	title = {Into the wild: challenges and opportunities for field trial methods},
	isbn = {978-1-4503-0228-9},
	shorttitle = {Into the wild},
	url = {https://dl.acm.org/doi/10.1145/1978942.1979185},
	doi = {10.1145/1978942.1979185},
	abstract = {Field trials of experimental systems ‘in the wild’ have developed into a standard method within HCI - testing new systems with groups of users in relatively unconstrained settings outside of the laboratory. In this paper we discuss methodological challenges in running user trials. Using a ‘trial of trials’ we examined the practices of investigators and participants - documenting ‘demand characteristics’, where users adjust their behaviour to ﬁt the expectations of those running the trial, the interdependence of how trials are run and the result they produce, and how trial results can be dependent on the insights of a subset of trial participants. We develop three strategies that researchers can use to leverage these challenges to run better trials.},
	language = {en},
	urldate = {2023-09-13},
	booktitle = {Proceedings of the {SIGCHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {ACM},
	author = {Brown, Barry and Reeves, Stuart and Sherwood, Scott},
	month = may,
	year = {2011},
	pages = {1657--1666},
}

@article{rogers_interaction_2011,
	title = {Interaction design gone wild: striving for wild theory},
	volume = {18},
	issn = {1072-5520, 1558-3449},
	shorttitle = {Interaction design gone wild},
	url = {https://dl.acm.org/doi/10.1145/1978822.1978834},
	doi = {10.1145/1978822.1978834},
	language = {en},
	number = {4},
	urldate = {2023-09-13},
	journal = {Interactions},
	author = {Rogers, Yvonne},
	month = jul,
	year = {2011},
	pages = {58--62},
}

@inproceedings{giovannelli_exploring_2022,
	title = {Exploring the {Impact} of {Visual} {Information} on {Intermittent} {Typing} in {Virtual} {Reality}},
	doi = {10.1109/ISMAR55827.2022.00014},
	booktitle = {2022 {IEEE} {International} {Symposium} on {Mixed} and {Augmented} {Reality} ({ISMAR})},
	author = {Giovannelli, Alexander and Lisle, Lee and Bowman, Doug A.},
	year = {2022},
	pages = {8--17},
}

@inproceedings{tahmid_evaluating_2022,
	title = {Evaluating the {Benefits} of {Explicit} and {Semi}-{Automated} {Clusters} for {Immersive} {Sensemaking}},
	doi = {10.1109/ISMAR55827.2022.00064},
	booktitle = {2022 {IEEE} {International} {Symposium} on {Mixed} and {Augmented} {Reality} ({ISMAR})},
	author = {Tahmid, Ibrahim A. and Lisle, Lee and Davidson, Kylie and North, Chris and Bowman, Doug A.},
	year = {2022},
	pages = {479--488},
}

@inproceedings{lisle_sensemaking_2021,
	title = {Sensemaking {Strategies} with {Immersive} {Space} to {Think}},
	doi = {10.1109/VR50410.2021.00077},
	booktitle = {2021 {IEEE} {Virtual} {Reality} and {3D} {User} {Interfaces} ({VR})},
	author = {Lisle, Lee and Davidson, Kylie and Gitre, Edward J.K. and North, Chris and Bowman, Doug A.},
	year = {2021},
	pages = {529--537},
}

@inproceedings{cheng_semanticadapt_2021,
	address = {New York, NY, USA},
	series = {{UIST} '21},
	title = {{SemanticAdapt}: {Optimization}-{Based} {Adaptation} of {Mixed} {Reality} {Layouts} {Leveraging} {Virtual}-{Physical} {Semantic} {Connections}},
	isbn = {978-1-4503-8635-7},
	url = {https://doi.org/10.1145/3472749.3474750},
	doi = {10.1145/3472749.3474750},
	abstract = {We present an optimization-based approach that automatically adapts Mixed Reality (MR) interfaces to different physical environments. Current MR layouts, including the position and scale of virtual interface elements, need to be manually adapted by users whenever they move between environments, and whenever they switch tasks. This process is tedious and time consuming, and arguably needs to be automated for MR systems to be beneficial for end users. We contribute an approach that formulates this challenge as a combinatorial optimization problem and automatically decides the placement of virtual interface elements in new environments. To achieve this, we exploit the semantic association between the virtual interface elements and physical objects in an environment. Our optimization furthermore considers the utility of elements for users’ current task, layout factors, and spatio-temporal consistency to previous layouts. All those factors are combined in a single linear program, which is used to adapt the layout of MR interfaces in real time. We demonstrate a set of application scenarios, showcasing the versatility and applicability of our approach. Finally, we show that compared to a naive adaptive baseline approach that does not take semantic associations into account, our approach decreased the number of manual interface adaptations by 33\%.},
	booktitle = {The 34th {Annual} {ACM} {Symposium} on {User} {Interface} {Software} and {Technology}},
	publisher = {Association for Computing Machinery},
	author = {Cheng, Yifei and Yan, Yukang and Yi, Xin and Shi, Yuanchun and Lindlbauer, David},
	year = {2021},
	note = {event-place: Virtual Event, USA},
	keywords = {Adaptive user interfaces, Computational interaction, Mixed Reality},
	pages = {282--297},
}

@article{abowd_charting_2000,
	title = {Charting {Past}, {Present}, and {Future} {Research} in {Ubiquitous} {Computing}},
	volume = {7},
	issn = {1073-0516},
	url = {https://doi.org/10.1145/344949.344988},
	doi = {10.1145/344949.344988},
	abstract = {The proliferation of computing into the physical world promises more than the ubiquitous availability of computing infrastructure; it suggest new paradigms of interaction inspired by constant access to information and computational capabilities. For the past decade, application-driven research on abiquitous computing (ubicomp) has pushed three interaction themes:natural interfaces, context-aware applications,andautomated capture and access. To chart a course for future research in ubiquitous computing, we review the accomplishments of these efforts and point to remaining research challenges. Research in ubiquitious computing implicitly requires addressing some notion of scale, whether in the number and type of devices, the physical space of distributed computing, or the number of people using a system. We posit a new area of applications research, everyday computing, focussed on scaling interaction with respect to time. Just as pushing the availiability of computing away from the traditional desktop fundamentally changes the relationship between humans and computers, providing continuous interaction moves computing from a localized tool to a constant companion. Designing for continous interaction requires addressing interruption and reumption of intreaction, representing passages of time and providing associative storage models. Inherent in all of these interaction themes are difficult issues in the social implications of ubiquitous computing and the challenges of evaluating\&gt; ubiquitious computing research. Although cumulative experience points to lessons in privacy, security, visibility, and control, there are no simple guidelines for steering research efforts. Akin to any efforts involving new technologies, evaluation strategies form a spectrum from technology feasibility efforts to long-term use studies—but a user-centric perspective is always possible and necessary},
	number = {1},
	journal = {ACM Trans. Comput.-Hum. Interact.},
	author = {Abowd, Gregory D. and Mynatt, Elizabeth D.},
	month = mar,
	year = {2000},
	note = {Place: New York, NY, USA
Publisher: Association for Computing Machinery},
	keywords = {augmented reality, capture and access, context-aware applications, evaluation, everyday computing, natural interfaces, social implications, ubiquitous computing, user interfaces},
	pages = {29--58},
}

@inproceedings{lischke_screen_2016,
	address = {Oulu Finland},
	title = {Screen arrangements and interaction areas for large display work places},
	isbn = {978-1-4503-4366-4},
	url = {https://dl.acm.org/doi/10.1145/2914920.2915027},
	doi = {10.1145/2914920.2915027},
	abstract = {Size and resolution of computer screens are constantly increasing. Individual screens can easily be combined to wallsized displays. This enables computer displays that are folded, straight, bow shaped or even spread. As possibilities for arranging the screens are manifold, it is unclear what arrangements are appropriate. Moreover, it is unclear how content and applications should be arranged on such large displays. To determine guidelines for the arrangement of multiple screens and for content and application layouts, we conducted a design study. In the study, we asked 16 participants to arrange a large screen setup as well as to create layouts of multiple common application windows. Based on the results we provide a classiﬁcation for screen arrangements and interaction areas. We identiﬁed, that screen space should be divided into a central area for interactive applications and peripheral areas, mainly for displaying additional content.},
	language = {en},
	urldate = {2023-08-14},
	booktitle = {Proceedings of the 5th {ACM} {International} {Symposium} on {Pervasive} {Displays}},
	publisher = {ACM},
	author = {Lischke, Lars and Mayer, Sven and Wolf, Katrin and Henze, Niels and Reiterer, Harald and Schmidt, Albrecht},
	month = jun,
	year = {2016},
	pages = {228--234},
}

@article{schneider_reconviguration_2019,
	title = {{ReconViguRation}: {Reconfiguring} {Physical} {Keyboards} in {Virtual} {Reality}},
	volume = {25},
	doi = {10.1109/TVCG.2019.2932239},
	number = {11},
	journal = {IEEE Transactions on Visualization and Computer Graphics},
	author = {Schneider, Daniel and Otte, Alexander and Gesslein, Travis and Gagel, Philipp and Kuth, Bastian and Damlakhi, Mohamad Shahm and Dietz, Oliver and Ofek, Eyal and Pahud, Michel and Kristensson, Per Ola and Müller, Jörg and Grubert, Jens},
	year = {2019},
	pages = {3190--3201},
}

@inproceedings{hoppe_qvrty_2018,
	address = {Cham},
	title = {{qVRty}: {Virtual} {Keyboard} with a {Haptic}, {Real}-{World} {Representation}},
	isbn = {978-3-319-92279-9},
	abstract = {Virtual Reality systems offer great possibilities to analyze and interact with data. However, they still lack a commonly accepted, efficient text input technique that allows users to record their findings. To provide users with an efficient technique for text input, a real keyboard and the user's hands are transferred into the virtual world. This allows real haptic feedback of the device and, as a user study shows, results in fast and accurate text writing. The proposed approach shows that a real-world ability can be transmitted directly into the virtual world without much loss.},
	booktitle = {{HCI} {International} 2018 – {Posters}' {Extended} {Abstracts}},
	publisher = {Springer International Publishing},
	author = {Hoppe, Adrian H. and Otto, Leonard and van de Camp, Florian and Stiefelhagen, Rainer and Unmüßig, Gabriel},
	editor = {Stephanidis, Constantine},
	year = {2018},
	pages = {266--272},
}

@inproceedings{lu_exploration_2021,
	address = {New York, NY, USA},
	series = {{SUI} '21},
	title = {Exploration of {Techniques} for {Rapid} {Activation} of {Glanceable} {Information} in {Head}-{Worn} {Augmented} {Reality}},
	isbn = {978-1-4503-9091-0},
	url = {https://doi.org/10.1145/3485279.3485286},
	doi = {10.1145/3485279.3485286},
	abstract = {Future augmented reality (AR) glasses may provide pervasive and continuous access to everyday information. However, it remains unclear how to address the issue of virtual information overlaying and occluding real-world objects and information that are of interest to users. One approach is to keep virtual information sources inactive until they are explicitly requested, so that the real world remains visible. In this research, we explored the design of interaction techniques with which users can activate virtual information sources in AR. We studied this issue in the context of Glanceable AR, in which virtual information resides at the periphery of the user’s view. We proposed five techniques and evaluated them in both sitting and walking scenarios. Our results demonstrate the usability, user preference, and social acceptance of each technique, as well as design recommendations to achieve optimal performance. Our findings can inform the design of lightweight techniques to activate virtual information displays in future everyday AR interfaces.},
	booktitle = {Proceedings of the 2021 {ACM} {Symposium} on {Spatial} {User} {Interaction}},
	publisher = {Association for Computing Machinery},
	author = {Lu, Feiyu and Davari, Shakiba and Bowman, Doug},
	year = {2021},
	note = {event-place: Virtual Event, USA},
	keywords = {adaptive interface, augmented reality, glanceable information, interaction technique, user study},
}

@inproceedings{kim_effects_2019,
	address = {New York, NY, USA},
	series = {{SUI} '19},
	title = {Effects of {Dark} {Mode} on {Visual} {Fatigue} and {Acuity} in {Optical} {See}-{Through} {Head}-{Mounted} {Displays}},
	isbn = {978-1-4503-6975-6},
	url = {https://doi.org/10.1145/3357251.3357584},
	doi = {10.1145/3357251.3357584},
	abstract = {Light-on-dark color schemes, so-called “Dark Mode,” are becoming more and more popular over a wide range of display technologies and application fields. Many people who have to look at computer screens for hours at a time, such as computer programmers and computer graphics artists, indicate a preference for switching colors on a computer screen from dark text on a light background to light text on a dark background due to perceived advantages related to visual comfort and acuity, specifically when working in low-light environments. In this paper, we investigate the effects of dark mode color schemes in the field of optical see-through head-mounted displays (OST-HMDs), where the characteristic “additive” light model implies that bright graphics are visible but dark graphics are transparent. We describe a human-subject study in which we evaluated a normal and inverted color mode in front of different physical backgrounds and among different lighting conditions. Our results show that dark mode graphics on OST-HMDs have significant benefits for visual acuity, fatigue, and usability, while user preferences depend largely on the lighting in the physical environment. We discuss the implications of these effects on user interfaces and applications.},
	booktitle = {Symposium on {Spatial} {User} {Interaction}},
	publisher = {Association for Computing Machinery},
	author = {Kim, Kangsoo and Erickson, Austin and Lambert, Alexis and Bruder, Gerd and Welch, Greg},
	year = {2019},
	note = {event-place: New Orleans, LA, USA},
	keywords = {Augmented Reality, Dark Mode, Eye Fatigue, Optical See-Through Display, User Experience, Visual Acuity},
}

@inproceedings{orlosky_dynamic_2013,
	address = {New York, NY, USA},
	series = {{IUI} '13},
	title = {Dynamic {Text} {Management} for {See}-through {Wearable} and {Heads}-up {Display} {Systems}},
	isbn = {978-1-4503-1965-2},
	url = {https://doi.org/10.1145/2449396.2449443},
	doi = {10.1145/2449396.2449443},
	abstract = {Reading text safely and easily while mobile has been an issue with see-through displays for many years. For example, in order to effectively use optical see through Head Mounted Displays (HMDs) or Heads Up Display (HUD) systems in constantly changing dynamic environments, variables like lighting conditions, human or vehicular obstructions in a user's path, and scene variation must be dealt with effectively.This paper introduces a new intelligent text management system that actively manages movement of text in a user's field of view. Research to date lacks a method to migrate user-centric content such as e-mail or text messages throughout a user's environment while mobile. Unlike most current annotation and view management systems, we use camera tracking to find dark, uniform regions along the route on which a user is travelling in real time. We then implement methodology to move text from one viable location to the next to maximize readability. A pilot experiment with 19 participants shows that the text placement of our system is preferred to text in fixed location configurations.},
	booktitle = {Proceedings of the 2013 {International} {Conference} on {Intelligent} {User} {Interfaces}},
	publisher = {Association for Computing Machinery},
	author = {Orlosky, Jason and Kiyokawa, Kiyoshi and Takemura, Haruo},
	year = {2013},
	note = {event-place: Santa Monica, California, USA},
	keywords = {content stabilization, heads up display, scene analysis, text placement, view management, wearable display},
	pages = {363--370},
}

@article{gattullo_effect_2015,
	title = {Effect of {Text} {Outline} and {Contrast} {Polarity} on {AR} {Text} {Readability} in {Industrial} {Lighting}},
	volume = {21},
	doi = {10.1109/TVCG.2014.2385056},
	number = {5},
	journal = {IEEE Transactions on Visualization and Computer Graphics},
	author = {Gattullo, Michele and Uva, Antonio Emmanuele and Fiorentino, Michele and Monno, Giuseppe},
	year = {2015},
	pages = {638--651},
}

@article{medeiros_shielding_2022,
	title = {From {Shielding} to {Avoidance}: {Passenger} {Augmented} {Reality} and the {Layout} of {Virtual} {Displays} for {Productivity} in {Shared} {Transit}},
	issn = {1077-2626, 1941-0506, 2160-9306},
	shorttitle = {From {Shielding} to {Avoidance}},
	url = {https://ieeexplore.ieee.org/document/9873972/},
	doi = {10.1109/TVCG.2022.3203002},
	abstract = {Passengers spend considerable periods of time in shared transit spaces, relying on smartphones and laptops for work. However, these displays are limited in size and ergonomics compared to typical multi-monitor setups used in the ofﬁce, impairing productivity. Augmented Reality (AR) headsets could provide large, ﬂexible virtual workspaces during travel, enabling passengers to work more efﬁciently. This paper investigates the factors affecting how passengers choose to layout virtual displays in car, train, subway and plane environments, studying the affordances of each mode of transport and the presence of others. Results from our experiment showed: signiﬁcant usage of the physical environment to align displays; strong social effects meant avoiding placing displays over other passengers or their belongings; and use of displays for shielding oneself from others. Our ﬁndings show the unique challenges posed by the mode of transport and presence of others on the use of AR for mobile productivity in the future.},
	urldate = {2022-09-13},
	journal = {IEEE Transactions on Visualization and Computer Graphics},
	author = {Medeiros, Daniel and McGill, Mark and Ng, Alexander and McDermid, Robert and Pantidi, Nadia and Williamson, Julie and Brewster, Stephen},
	year = {2022},
	pages = {1--11},
}

@inproceedings{tan_wincuts_2004,
	address = {Vienna Austria},
	title = {{WinCuts}: manipulating arbitrary window regions for more effective use of screen space},
	isbn = {978-1-58113-703-3},
	shorttitle = {{WinCuts}},
	url = {https://dl.acm.org/doi/10.1145/985921.986106},
	doi = {10.1145/985921.986106},
	abstract = {Each window on our computer desktop provides a view into some information. Although users can currently manipulate multiple windows, we assert that being able to spatially arrange smaller regions of these windows could help users perform certain tasks more efficiently. In this paper, we describe a novel interaction technique that allows users to replicate arbitrary regions of existing windows into independent windows called WinCuts. Each WinCut is a live view of a region of the source window with which users can interact. We also present an extension that allows users to share WinCuts across multiple devices. Next, we classify the set of tasks for which WinCuts may be useful, both in single as well as multiple device scenarios. We present high level implementation details so that other researchers can replicate this work. And finally, we discuss future work that we will pursue in extending these ideas.},
	language = {en},
	urldate = {2023-04-17},
	booktitle = {{CHI} '04 {Extended} {Abstracts} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {ACM},
	author = {Tan, Desney S. and Meyers, Brian and Czerwinski, Mary},
	month = apr,
	year = {2004},
	note = {104 citations (Crossref) [2023-04-17]},
	pages = {1525--1528},
}

@article{tan_women_2003,
	title = {Women {Go} {With} the ({Optical}) {Flow}},
	abstract = {Previous research reported interesting gender effects involving specific benefits for females navigating with wider fields of view on large displays. However, it was not clear what was driving the 3D navigation performance gains, and whether or not the effect was more tightly coupled to gender or to spatial abilities. The study we report in this paper replicates and extends previous work, demonstrating that the gender-specific navigation benefits come from the presence of optical flow cues, which are better afforded by wider fields of view on large displays. The study also indicates that the effect may indeed be tied to gender, as opposed to spatial abilities. Together, the findings provide a significant contribution to the HCI community, as we provide strong recommendations for the design and presentation of 3D environments, backed by empirical data. Additionally, these recommendations reliably benefit females, without an accompanying detriment to male navigation performance.},
	language = {en},
	number = {5},
	journal = {NEW HORIZONS},
	author = {Tan, Desney S},
	year = {2003},
}

@inproceedings{ni_increased_2006,
	address = {CAN},
	series = {{GI} '06},
	title = {Increased {Display} {Size} and {Resolution} {Improve} {Task} {Performance} in {Information}-{Rich} {Virtual} {Environments}},
	isbn = {1-56881-308-2},
	abstract = {Physically large-size high-resolution displays have been widely applied in various fields. There is a lack of research, however, that demonstrates empirically how users benefit from the increased size and resolution afforded by emerging technologies. We designed a controlled experiment to evaluate the individual and combined effects of display size and resolution on task performance in an Information-Rich Virtual Environment (IRVE). We also explored how a wayfinding aid would facilitate spatial information acquisition and mental map construction when users worked with various displays. We found that users were most effective at performing IRVE search and comparison tasks on large high-resolution displays. In addition, users working with large displays became less reliant on wayfinding aids to form spatial knowledge. We discuss the impact of these results on the design and presentation of IRVEs, the choice of displays for particular applications, and future work to extend our findings.},
	booktitle = {Proceedings of {Graphics} {Interface} 2006},
	publisher = {Canadian Information Processing Society},
	author = {Ni, Tao and Bowman, Doug A. and Chen, Jian},
	year = {2006},
	note = {event-place: Quebec, Canada},
	keywords = {Information-Rich Virtual Environment (IRVE), experiment, field of view, large high-resolution displays, user study, wayfinding aid},
	pages = {139--146},
}

@inproceedings{tao_ni_survey_2006,
	address = {Alexandria, VA, USA},
	title = {A {Survey} of {Large} {High}-{Resolution} {Display} {Technologies}, {Techniques}, and {Applications}},
	isbn = {978-1-4244-0224-3},
	url = {http://ieeexplore.ieee.org/document/1667648/},
	doi = {10.1109/VR.2006.20},
	abstract = {Continued advances in display hardware, computing power, networking, and rendering algorithms have all converged to dramatically improve large high-resolution display capabilities. We present a survey on prior research with large high-resolution displays. In the hardware conﬁgurations section we examine systems including multi-monitor workstations, reconﬁgurable projector arrays, and others. Rendering and the data pipeline are addressed with an overview of current technologies. We discuss many applications for large high-resolution displays such as automotive design, scientiﬁc visualization, control centers, and others. Quantifying the effects of large high-resolution displays on human performance and other aspects is important as we look toward future advances in display technology and how it is applied in different situations. Interacting with these displays brings a different set of challenges for HCI professionals, so an overview of some of this work is provided. Finally, we present our view of the top ten greatest challenges in large highresolution displays.},
	language = {en},
	urldate = {2023-04-04},
	booktitle = {{IEEE} {Virtual} {Reality} {Conference} ({VR} 2006)},
	publisher = {IEEE},
	author = {{Tao Ni} and Schmidt, G.S. and Staadt, O.G. and Livingston, M.A. and Ball, R. and May, R.},
	year = {2006},
	pages = {223--236},
}

@article{rampin_taguette_2021,
	title = {Taguette: open-source qualitative data analysis},
	volume = {6},
	url = {https://doi.org/10.21105/joss.03522},
	doi = {10.21105/joss.03522},
	number = {68},
	journal = {Journal of Open Source Software},
	author = {Rampin, Rémi and Rampin, Vicky},
	year = {2021},
	note = {Publisher: The Open Journal},
	pages = {3522},
}

@inproceedings{elkin_aligned_2021,
	address = {New York, NY, USA},
	series = {{UIST} '21},
	title = {An {Aligned} {Rank} {Transform} {Procedure} for {Multifactor} {Contrast} {Tests}},
	isbn = {978-1-4503-8635-7},
	url = {https://doi.org/10.1145/3472749.3474784},
	doi = {10.1145/3472749.3474784},
	abstract = {Data from multifactor HCI experiments often violates the assumptions of parametric tests (i.e., nonconforming data). The Aligned Rank Transform (ART) has become a popular nonparametric analysis in HCI that can find main and interaction effects in nonconforming data, but leads to incorrect results when used to conduct post hoc contrast tests. We created a new algorithm called ART-C for conducting contrast tests within the ART paradigm and validated it on 72,000 synthetic data sets. Our results indicate that ART-C does not inflate Type I error rates, unlike contrasts based on ART, and that ART-C has more statistical power than a t-test, Mann-Whitney U test, Wilcoxon signed-rank test, and ART. We also extended an open-source tool called ARTool with our ART-C algorithm for both Windows and R. Our validation had some limitations (e.g., only six distribution types, no mixed factorial designs, no random slopes), and data drawn from Cauchy distributions should not be analyzed with ART-C.},
	booktitle = {The 34th {Annual} {ACM} {Symposium} on {User} {Interface} {Software} and {Technology}},
	publisher = {Association for Computing Machinery},
	author = {Elkin, Lisa A. and Kay, Matthew and Higgins, James J. and Wobbrock, Jacob O.},
	year = {2021},
	note = {event-place: Virtual Event, USA},
	keywords = {Statistical methods, aligned rank transform., data analysis, experiments, nonparametric statistics, quantitative methods},
	pages = {754--768},
}

@inproceedings{wobbrock_aligned_2011,
	address = {Vancouver BC Canada},
	title = {The aligned rank transform for nonparametric factorial analyses using only anova procedures},
	isbn = {978-1-4503-0228-9},
	url = {https://dl.acm.org/doi/10.1145/1978942.1978963},
	doi = {10.1145/1978942.1978963},
	abstract = {Nonparametric data from multi-factor experiments arise often in human-computer interaction (HCI). Examples may include error counts, Likert responses, and preference tallies. But because multiple factors are involved, common nonparametric tests (e.g., Friedman) are inadequate, as they are unable to examine interaction effects. While some statistical techniques exist to handle such data, these techniques are not widely available and are complex. To address these concerns, we present the Aligned Rank Transform (ART) for nonparametric factorial data analysis in HCI. The ART relies on a preprocessing step that “aligns” data before applying averaged ranks, after which point common ANOVA procedures can be used, making the ART accessible to anyone familiar with the F-test. Unlike most articles on the ART, which only address two factors, we generalize the ART to N factors. We also provide ARTool and ARTweb, desktop and Web-based programs for aligning and ranking data. Our re-examination of some published HCI results exhibits advantages of the ART.},
	language = {en},
	urldate = {2023-03-13},
	booktitle = {Proceedings of the {SIGCHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {ACM},
	author = {Wobbrock, Jacob O. and Findlater, Leah and Gergle, Darren and Higgins, James J.},
	month = may,
	year = {2011},
	note = {893 citations (Crossref) [2023-03-13]},
	pages = {143--146},
}

@inproceedings{danyluk_evaluating_2019,
	address = {Cham},
	title = {Evaluating the {Performance} of {Virtual} {Reality} {Navigation} {Techniques} for {Large} {Environments}},
	isbn = {978-3-030-22514-8},
	abstract = {We present results from two studies comparing the performance of four different navigation techniques (flight, teleportation, world-in-miniature, and 3D cone-drag) and their combinations in large virtual reality map environments. While prior work has individually examined each of these techniques in other settings, our study presents the first direct comparison between them in large open environments, as well as one of the first comparisons in the context of current-generation virtual reality hardware. Our first study compared common techniques (flight, teleportation, and world-in-miniature) for search and navigation tasks. A follow-up study compared these techniques against 3D cone drag, a direct-manipulation navigation technique used in contemporary tools like Google Earth VR. Our results show the strength of flight as a stand-alone navigation technique, but also highlight five specific ways in which viewers can combine teleportation, world-in-miniature, and 3D cone drag with flight, drawing on the relative strengths of each technique to compensate for the weaknesses of others.},
	booktitle = {Advances in {Computer} {Graphics}},
	publisher = {Springer International Publishing},
	author = {Danyluk, Kurtis and Willett, Wesley},
	editor = {Gavrilova, Marina and Chang, Jian and Thalmann, Nadia Magnenat and Hitzer, Eckhard and Ishikawa, Hiroshi},
	year = {2019},
	note = {3 citations},
	pages = {203--215},
}

@inproceedings{blanch_semantic_2004,
	address = {Vienna Austria},
	title = {Semantic pointing: improving target acquisition with control-display ratio adaptation},
	isbn = {978-1-58113-702-6},
	shorttitle = {Semantic pointing},
	url = {https://dl.acm.org/doi/10.1145/985692.985758},
	doi = {10.1145/985692.985758},
	abstract = {We introduce semantic pointing, a novel interaction technique that improves target acquisition in graphical user interfaces (GUIs). Semantic pointing uses two independent sizes for each potential target presented to the user: one size in motor space adapted to its importance for the manipulation, and one size in visual space adapted to the amount of information it conveys. This decoupling between visual and motor size is achieved by changing the control-to-display ratio according to cursor distance to nearby targets. We present a controlled experiment supporting our hypothesis that the performance of semantic pointing is given by Fitts’ index of difﬁculty in motor rather than visual space. We apply semantic pointing to the redesign of traditional GUI widgets by taking advantage of the independent manipulation of motor and visual widget sizes.},
	language = {en},
	urldate = {2023-01-30},
	booktitle = {Proceedings of the {SIGCHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {ACM},
	author = {Blanch, Renaud and Guiard, Yves and Beaudouin-Lafon, Michel},
	month = apr,
	year = {2004},
	note = {159 citations (Crossref) [2023-01-30]},
	pages = {519--526},
}

@inproceedings{feng_comparison_2015,
	address = {Los Angeles California USA},
	title = {Comparison of {Device}-{Based}, {One} and {Two}-{Handed} {7DOF} {Manipulation} {Techniques}},
	isbn = {978-1-4503-3703-8},
	url = {https://dl.acm.org/doi/10.1145/2788940.2788942},
	doi = {10.1145/2788940.2788942},
	abstract = {We evaluate three bimanual 7 degree-of-freedom (7DOF) object manipulation techniques that use a pair of precision grasped isotonic devices called buttonballs. 7DOF manipulation means changing position, orientation and scale. We compare the techniques in a (stereo) Fish-tank Virtual Reality (VR) system. The user study displays multiple randomly located boxes of different sizes and the user must dock (i.e. align) each target box with an objective box at the screen center. Comparing task completion times shows that in cases where target and objective boxes are the same size, all three techniques perform equivalently. When the sizes differ--requiring a scale change--two of the technique’s, Spindle+Wheel and a minor variant of Grab-andScale perform similarly, and are both faster than the third technique, One-Hand+Scale. We compare and contrast our results with other work including free-hand versus held device input and also with 7DOF object manipulation versus 7DOF view manipulation.},
	language = {en},
	urldate = {2023-01-30},
	booktitle = {Proceedings of the 3rd {ACM} {Symposium} on {Spatial} {User} {Interaction}},
	publisher = {ACM},
	author = {Feng, Jinbo and Cho, Isaac and Wartell, Zachary},
	month = aug,
	year = {2015},
	note = {8 citations (Crossref) [2023-01-30]},
	pages = {2--9},
}

@article{frees_prism_2007,
	title = {{PRISM} interaction for enhancing control in immersive virtual environments},
	volume = {14},
	issn = {1073-0516, 1557-7325},
	url = {https://dl.acm.org/doi/10.1145/1229855.1229857},
	doi = {10.1145/1229855.1229857},
	abstract = {When directly manipulating 3D objects in an immersive environment we cannot normally achieve the accuracy and control that we have in the real world. This reduced accuracy stems from hand instability. We present PRISM, which dynamically adjusts the C/D ratio between the hand and the controlled object to provide increased control when moving slowly and direct, unconstrained interaction when moving rapidly. We describe PRISM object translation and rotation and present user studies demonstrating their effectiveness. In addition, we describe a PRISM-enhanced version of ray casting which is shown to increase the speed and accuracy of object selection.},
	language = {en},
	number = {1},
	urldate = {2023-01-30},
	journal = {ACM Transactions on Computer-Human Interaction},
	author = {Frees, Scott and Kessler, G. Drew and Kay, Edwin},
	month = may,
	year = {2007},
	note = {90 citations (Crossref) [2023-01-30]},
	pages = {2},
}

@inproceedings{bergstrom_how_2021,
	address = {Yokohama Japan},
	title = {How to {Evaluate} {Object} {Selection} and {Manipulation} in {VR}? {Guidelines} from 20 {Years} of {Studies}},
	isbn = {978-1-4503-8096-6},
	shorttitle = {How to {Evaluate} {Object} {Selection} and {Manipulation} in {VR}?},
	url = {https://dl.acm.org/doi/10.1145/3411764.3445193},
	doi = {10.1145/3411764.3445193},
	abstract = {The VR community has introduced many object selection and manipulation techniques during the past two decades. Typically, they are empirically studied to establish their benefts over the stateof-the-art. However, the literature contains few guidelines on how to conduct such studies; standards developed for evaluating 2D interaction often do not apply. This lack of guidelines makes it hard to compare techniques across studies, to report evaluations consistently, and therefore to accumulate or replicate fndings. To build such guidelines, we review 20 years of studies on VR object selection and manipulation. Based on the review, we propose recommendations for designing studies and a checklist for reporting them. We also identify research directions for improving evaluation methods and ofer ideas for how to make studies more ecologically valid and rigorous.},
	language = {en},
	urldate = {2023-01-25},
	booktitle = {Proceedings of the 2021 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {ACM},
	author = {Bergström, Joanna and Dalsgaard, Tor-Salve and Alexander, Jason and Hornbæk, Kasper},
	month = may,
	year = {2021},
	note = {10 citations (Crossref) [2023-01-25]},
	pages = {1--20},
}

@inproceedings{frees_precise_2005,
	address = {Bonn, Germany},
	title = {Precise and rapid interaction through scaled manipulation in immersive virtual environments},
	isbn = {978-0-7803-8929-8},
	url = {http://ieeexplore.ieee.org/document/1492759/},
	doi = {10.1109/VR.2005.1492759},
	abstract = {A significant benefit of an immersive virtual environment is that it provides users the ability to interact with objects in a very natural, direct way; often realized by using a tracked, hand-held wand or stylus to “grab” and position objects. In the absence of force feedback or props, it is difficult and frustrating for users to move their arms, hands, or fingers to precise positions in 3D space, and more difficult to hold them at a constant position, or to move them in a uniform direction over time. The imprecision of user interaction in virtual environments is a fundamental problem that limits the complexity of the environment the user can interact with directly.},
	language = {en},
	urldate = {2023-01-25},
	booktitle = {{IEEE} {Proceedings}. {VR} 2005. {Virtual} {Reality}, 2005.},
	publisher = {IEEE},
	author = {Frees, S. and Kessler, G.D.},
	year = {2005},
	note = {5 citations (Crossref) [2023-01-25]},
	pages = {99--106},
}

@inproceedings{kopper_rapid_2011,
	address = {Singapore, Singapore},
	title = {Rapid and accurate {3D} selection by progressive refinement},
	isbn = {978-1-4577-0063-7},
	url = {http://ieeexplore.ieee.org/document/5759219/},
	doi = {10.1109/3DUI.2011.5759219},
	abstract = {Issues such as hand and tracker jitter negatively affect user performance with the ray-casting selection technique in 3D environments. This makes it difﬁcult for users to perform tasks that require them to select objects that have a small visible area, since small targets require high levels of precision. We introduce an approach to address this issue that uses progressive reﬁnement of the set of selectable objects to reduce the required precision of the task. We present a design space of progressive reﬁnement techniques and an exemplar technique called Sphere-casting reﬁned by QUAD-menu (SQUAD). We explore the tradeoffs between progressive reﬁnement and immediate selection techniques in an evaluation comparing SQUAD to ray-casting. Both an analytical evaluation based on a distal pointing model and an empirical evaluation demonstrate that progressive reﬁnement selection can be better than immediate selection. SQUAD was much more accurate than ray-casting, and SQUAD was faster than ray-casting with small targets and less cluttered environments.},
	language = {en},
	urldate = {2023-01-25},
	booktitle = {2011 {IEEE} {Symposium} on {3D} {User} {Interfaces} ({3DUI})},
	publisher = {IEEE},
	author = {Kopper, Regis and Bacim, Felipe and Bowman, Doug A.},
	month = mar,
	year = {2011},
	note = {64 citations (Crossref) [2023-01-25]},
	pages = {67--74},
}

@inproceedings{osawa_automatic_2006,
	address = {Hong Kong China},
	title = {Automatic adjustments for efficient and precise positioning and release of virtual objects},
	isbn = {978-1-59593-324-9},
	url = {https://dl.acm.org/doi/10.1145/1128923.1128943},
	doi = {10.1145/1128923.1128943},
	abstract = {We describe automatic adjustment methods for positioning and releasing a 3D virtual object efficiently and precisely by direct hand manipulation in an immersive virtual reality environment. The methods are release adjustment, position adjustment, and viewpoint adjustment. Combinations of these methods enable users to manipulate a virtual object efficiently and precisely. An experimental evaluation showed that these methods are effective and useful in terms of the number of task completions and subjective preference for a small target.},
	language = {en},
	urldate = {2023-01-25},
	booktitle = {Proceedings of the 2006 {ACM} international conference on {Virtual} reality continuum and its applications},
	publisher = {ACM},
	author = {Osawa, Noritaka},
	month = jun,
	year = {2006},
	note = {6 citations (Crossref) [2023-01-25]},
	pages = {121--128},
}

@article{ha_automatic_2020,
	title = {Automatic {Control} of {Virtual} {Mirrors} for {Precise} {3D} {Manipulation} in {VR}},
	volume = {8},
	issn = {2169-3536},
	url = {https://ieeexplore.ieee.org/document/9174978/},
	doi = {10.1109/ACCESS.2020.3019012},
	abstract = {Popular virtual reality systems today allow us to experience highly immersive applications in which virtual objects are realistically perceived via stereoscopic displays and can be directly manipulated based on hand-eye coordination in a very similar way as in the real world. However, the insufﬁciency of sensory feedback as well as the limited degrees-of-freedom of input motion still hinders precise and elaborate manipulation in virtual reality. Aiming at more precise 3D manipulation, we present a new method of extending the user’s spatial perception ability with the ‘virtual mirrors’, which expose the hidden spatial information of given virtual scenes to the user. The movement of a virtual mirror is automatically controlled by solving an optimization problem iteratively, in which the objective function prefers the placement of the mirror that can highlight the spatial relationship between the manipulated object and the object nearest to it. The optimization process is handled efﬁciently for each time step based on our method for ﬁnding the closest gap between any two objects based on the OBB (oriented bounding box) trees and our sampling-based approximate approach to the optimization problem. The usefulness of our method is demonstrated by several pilot applications under various usage scenarios, such as assembling construction toys and solving 3D dissection puzzles. The quantitative results of our user study show that the virtual mirror is very helpful in increasing the precision in 3D manipulation tasks in virtual reality.},
	language = {en},
	urldate = {2023-01-25},
	journal = {IEEE Access},
	author = {Ha, Wansu and Choi, Myung Geol and Lee, Kang Hoon},
	year = {2020},
	note = {2 citations (Crossref) [2023-01-25]},
	pages = {156274--156284},
}

@inproceedings{hayatpur_plane_2019,
	address = {New Orleans LA USA},
	title = {Plane, {Ray}, and {Point}: {Enabling} {Precise} {Spatial} {Manipulations} with {Shape} {Constraints}},
	isbn = {978-1-4503-6816-2},
	shorttitle = {Plane, {Ray}, and {Point}},
	url = {https://dl.acm.org/doi/10.1145/3332165.3347916},
	doi = {10.1145/3332165.3347916},
	abstract = {We present Plane, Ray, and Point, a set of interaction techniques that utilizes shape constraints to enable quick and precise object alignment and manipulation in virtual reality. Users create the three types of shape constraints, Plane, Ray, and Point, by using symbolic gestures. The shape constraints are used like scaffoldings and limit and guide the movement of virtual objects that collide or intersect with them. The same set of gestures can be performed with the other hand, which allow users to further control the degrees of freedom for precise and constrained manipulation. The combination of shape constraints and bimanual gestures yield a rich set of interaction techniques to support object transformation. An exploratory study conducted with 3D design experts and novice users found the techniques to be useful in 3D scene design workflows and easy to learn and use.},
	language = {en},
	urldate = {2023-01-25},
	booktitle = {Proceedings of the 32nd {Annual} {ACM} {Symposium} on {User} {Interface} {Software} and {Technology}},
	publisher = {ACM},
	author = {Hayatpur, Devamardeep and Heo, Seongkook and Xia, Haijun and Stuerzlinger, Wolfgang and Wigdor, Daniel},
	month = oct,
	year = {2019},
	note = {14 citations (Crossref) [2023-01-25]},
	pages = {1185--1195},
}

@inproceedings{mendes_benefits_2016,
	address = {Munich Germany},
	title = {The benefits of {DOF} separation in mid-air {3D} object manipulation},
	isbn = {978-1-4503-4491-3},
	url = {https://dl.acm.org/doi/10.1145/2993369.2993396},
	doi = {10.1145/2993369.2993396},
	abstract = {Object manipulation is a key feature in almost every virtual environment. However, it is difﬁcult to accurately place an object in immersive virtual environments using mid-air gestures that mimic interactions in the physical world, although being a direct and natural approach. Previous research studied mouse and touch based interfaces concluding that separation of degrees-of-freedom (DOF) led to improved results. In this paper, we present the ﬁrst user evaluation to assess the impact of explicit 6 DOF separation in mid-air manipulation tasks. We implemented a technique based on familiar virtual widgets that allow single DOF control, and compared it against a direct approach and PRISM, which dynamically adjusts the ratio between hand and object motions. Our results suggest that full DOF separation beneﬁts precision in spatial manipulations, at the cost of additional time for complex tasks. From our results we draw guidelines for 3D object manipulation in mid-air.},
	language = {en},
	urldate = {2023-01-25},
	booktitle = {Proceedings of the 22nd {ACM} {Conference} on {Virtual} {Reality} {Software} and {Technology}},
	publisher = {ACM},
	author = {Mendes, Daniel and Relvas, Filipe and Ferreira, Alfredo and Jorge, Joaquim},
	month = nov,
	year = {2016},
	note = {44 citations (Crossref) [2023-01-25]},
	pages = {261--268},
}

@article{van_veldhuizen_effect_2021,
	title = {The {Effect} of {Semi}-{Transparent} and {Interpenetrable} {Hands} on {Object} {Manipulation} in {Virtual} {Reality}},
	volume = {9},
	issn = {2169-3536},
	url = {https://ieeexplore.ieee.org/document/9319674/},
	doi = {10.1109/ACCESS.2021.3050881},
	abstract = {Manipulating objects with the hand is a common task in Virtual Reality (VR). However, some issues can occur during these manipulations. Occlusion is one issue that happens when the virtual hand covers an object, and therefore the perception of that object is hindered. Semi-transparent hands could solve this problem. Another issue is the difﬁculty of delicate hand object manipulation. By using interpenetrable hands, turning off the physics of the hands, this difﬁculty might decrease. Still, there is a lack of research into how signiﬁcant the impact is while using these methods. In this paper, with the designs of semi-transparent hands and interpenetrable hands, we present the results of our conducted user study focusing on the effect of semi-transparent and interpenetrable hands on hand object manipulation tasks in virtual reality. The user study includes a VR environment where participants are asked to perform tasks. These tasks are recorded in objective results of accuracy and speed. Afterwards, they ﬁll out a questionnaire about their opinion on the difﬁculty while using the different methods in which the subjective ﬁndings are recorded. Additionally, we improved the semi-transparent hands by adding a feature that smoothly transitions the hand from opaque to semi-transparent. As an input device, we used the Leap Motion Controller (LMC) for this user study. However, any hand tracking sensor that tracks hands from the VR headset’s point of view could be used. Semi-transparent and interpenetrable hands have shown signiﬁcant improvement for precise manipulation, which was veriﬁed by user feedback from the questionnaire and the data from the tasks.},
	language = {en},
	urldate = {2023-01-25},
	journal = {IEEE Access},
	author = {Van Veldhuizen, Michiel and Yang, Xubo},
	year = {2021},
	note = {3 citations (Crossref) [2023-01-25]},
	pages = {17572--17583},
}

@inproceedings{ro_dynamic_2017,
	address = {Banff, AB},
	title = {A dynamic depth-variable ray-casting interface for object manipulation in ar environments},
	isbn = {978-1-5386-1645-1},
	url = {http://ieeexplore.ieee.org/document/8123063/},
	doi = {10.1109/SMC.2017.8123063},
	abstract = {In this paper, a new object manipulation method is proposed by applying the ray’s depth information to the raycasting-based interface. Ray-casting has been widely used in handheld device interfaces for manipulating objects in threedimensional (3D) space, such as augmented reality or virtual reality environments. However, the traditional ray-casting interface has limited object manipulation because it cannot designate a specific location in 3D space; it also has poor accuracy in manipulating objects at far distances. In this study, a user could register the virtual object in the real 3D space by specifying the arbitrary position using ray-depth information. We also improved the virtual object manipulation accuracy of the ray-casting interface by compensating the sensitivity according to the distance between the user and the object. To verify the manipulation accuracy of the interface implemented with the proposed technology, this study conducted a comparative experiment with existing interfaces. This verified the performance improvement in 3D space.},
	language = {en},
	urldate = {2023-01-25},
	booktitle = {2017 {IEEE} {International} {Conference} on {Systems}, {Man}, and {Cybernetics} ({SMC})},
	publisher = {IEEE},
	author = {Ro, Hyocheol and Chae, Seungho and Kim, Inhwan and Byun, Junghyun and Yang, Yoonsik and Park, Yoonjung and Han, Tackdon},
	month = oct,
	year = {2017},
	note = {16 citations (Crossref) [2023-01-25]},
	pages = {2873--2878},
}

@article{kumar_push-poke_nodate,
	title = {Push-{Poke}: {Collision} based {Direct} {Manipulation} {Technique} for {Plane} {Alignment} in {Virtual} {Reality}},
	abstract = {Medical operation planning requires high precision due to the health risks involved. In virtual reality-based osteotomy operation planning, medical professionals would like to use their hands instead of the controllers for osteotomy plane manipulation. However, using hands as an input method in virtual reality is challenging due to noisy hand tracking. We explored the perceptual structure of precise plane manipulation by conducting a controlled experiment to compare: (1) separable Push-Poke which dynamically selects plane manipulation parameters, (2) separable custom axis with Control-Display gain widget which provides user to select object manipulation parameters, (3) integral pinch-based direct manipulation. The perceptual structure of hand-based plane manipulation techniques is composed of (1) integral and fast direct manipulation and (2) separable slow technique that dynamically selects manipulation parameters.},
	language = {en},
	author = {Kumar, Sriram and Kangas, Jari and Mehtonen, Helena and Järnstedt, Jorma and Raisamo, Roope},
}

@article{delrieu_precise_nodate,
	title = {Precise and realistic grasping and manipulation in {Virtual} {Reality} without force feedback},
	abstract = {This paper introduces a physically-based approach of grasping and manipulation regarding virtual objects that would enable ﬁne and stable grasping without haptic force feedback. The main contribution is to enhance an existing method which couples a virtual kinematic hand with a visual hand tracking system. The mismatches between the tracked and virtual hands often yield unstable grasps, especially for small objects. This is overcome by the implementation of grasping assistance based on virtual springs between the tracked and virtual hands. The assistance is triggered based on an analysis of usual grasping criteria, to determine whether a grasp is feasible or not. The proposed method has been validated in a supervised experiment which showed that our assistance improves speed and accuracy for a ”pick and place” task involving an exhaustive object set, sized for precision grasp. Moreover, users’ feedback shows a clear preference for the present approach in terms of naturalness and efﬁciency.},
	language = {en},
	author = {Delrieu, Thibauld and Weistroffer, Vincent and Gazeau, Jean Pierre},
}

@inproceedings{huang_ubii_2015,
	address = {Brisbane Australia},
	title = {Ubii: {Towards} {Seamless} {Interaction} between {Digital} and {Physical} {Worlds}},
	isbn = {978-1-4503-3459-4},
	shorttitle = {Ubii},
	url = {https://dl.acm.org/doi/10.1145/2733373.2806266},
	doi = {10.1145/2733373.2806266},
	abstract = {We present Ubii (Ubiquitous interface and interaction), an interface system that aims to expand people’s perception and interaction from the digital space to the physical world. The centralized user interface is broken into pieces woven in the domain environment. Augmented user interface is paired to the physical objects, where physical and digital presentations are displayed in the same context. The augmented interface and physical aﬀordance respond as one control to provide seamless interaction. By connecting digital interface with physical objects, the system presents a nearby embodiment to aﬀord users sense of awareness to interact with domain objects. Integrated on wearable devices as Google Glass, a less intrusive and more convenient interaction is aﬀorded. Our research illustrates the great potential of direct mapping of interaction between digital interfaces and physical aﬀordance by converging wearable devices and augmented reality (AR) technology.},
	language = {en},
	urldate = {2023-01-23},
	booktitle = {Proceedings of the 23rd {ACM} international conference on {Multimedia}},
	publisher = {ACM},
	author = {Huang, Zhanpeng and Li, Weikai and Hui, Pan},
	month = oct,
	year = {2015},
	note = {23 citations (Crossref) [2023-01-23]},
	keywords = {⭐⭐⭐⭐},
	pages = {341--350},
}

@inproceedings{houben_activityspace_2014,
	address = {Dresden Germany},
	title = {{ActivitySpace}: {Managing} {Device} {Ecologies} in an {Activity}-{Centric} {Configuration} {Space}},
	isbn = {978-1-4503-2587-5},
	shorttitle = {{ActivitySpace}},
	url = {https://dl.acm.org/doi/10.1145/2669485.2669493},
	doi = {10.1145/2669485.2669493},
	abstract = {Mobile devices have become an intrinsic part of people’s everyday life. They are multifunctional devices providing ubiquitous access to many different sources of information. Together with traditional personal computers, these devices form a device ecology that provides access to an overlapping information space. Previous studies have shown that users encounter a number of fundamental problems when interacting with these device ecologies, such as lack of transparency, control, intelligibility and context. To mitigate these problems, we introduce ActivitySpace: an activity-centric conﬁguration space that enables the user to integrate and work across several devices by utilizing the space between the devices. This paper presents the conceptual background and design of ActivitySpace and reports on a study with nine participants. Our study shows that ActivitySpace helps users to easily manage devices and their allocated resources while also exposing a number of usage patterns.},
	language = {en},
	urldate = {2023-01-23},
	booktitle = {Proceedings of the {Ninth} {ACM} {International} {Conference} on {Interactive} {Tabletops} and {Surfaces}},
	publisher = {ACM},
	author = {Houben, Steven and Tell, Paolo and Bardram, Jakob E.},
	month = nov,
	year = {2014},
	note = {33 citations (Crossref) [2023-01-23]},
	keywords = {⭐⭐⭐},
	pages = {119--128},
}

@inproceedings{brasier_ar-enhanced_2021,
	address = {Toulouse \& Virtual France},
	title = {{AR}-enhanced {Widgets} for {Smartphone}-centric {Interaction}},
	isbn = {978-1-4503-8328-8},
	url = {https://dl.acm.org/doi/10.1145/3447526.3472019},
	doi = {10.1145/3447526.3472019},
	abstract = {We contribute a detailed investigation of AR-enhanced widgets for smartphones, where AR technology is not only used to ofoad widgets from the phone to the air around it, but to give users more control on input precision as well. Such widgets have the obvious beneft of freeing up screen real-estate on the phone, but their other potential benefts remain largely theoretical. Their limitations are not well understood, most particularly in terms of input performance. We compare diferent AR-enhanced widget designs against their state-of-the-art touch-only counterparts with a series of exploratory studies in which participants had to perform three tasks: command trigger, parameter value adjustment, and precise 2D selection. We then derive guidelines from our empirical observations.},
	language = {en},
	urldate = {2023-01-23},
	booktitle = {Proceedings of the 23rd {International} {Conference} on {Mobile} {Human}-{Computer} {Interaction}},
	publisher = {ACM},
	author = {Brasier, Eugenie and Pietriga, Emmanuel and Appert, Caroline},
	month = sep,
	year = {2021},
	note = {1 citations (Crossref) [2023-01-23]},
	pages = {1--12},
}

@inproceedings{buschel_miria_2021,
	address = {Yokohama Japan},
	title = {{MIRIA}: {A} {Mixed} {Reality} {Toolkit} for the {In}-{Situ} {Visualization} and {Analysis} of {Spatio}-{Temporal} {Interaction} {Data}},
	isbn = {978-1-4503-8096-6},
	shorttitle = {{MIRIA}},
	url = {https://dl.acm.org/doi/10.1145/3411764.3445651},
	doi = {10.1145/3411764.3445651},
	language = {en},
	urldate = {2023-01-23},
	booktitle = {Proceedings of the 2021 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {ACM},
	author = {Büschel, Wolfgang and Lehmann, Anke and Dachselt, Raimund},
	month = may,
	year = {2021},
	note = {14 citations (Crossref) [2023-01-23]},
	pages = {1--15},
}

@inproceedings{grubert_multifi_2015,
	address = {Seoul Republic of Korea},
	title = {{MultiFi}: {Multi} {Fidelity} {Interaction} with {Displays} {On} and {Around} the {Body}},
	isbn = {978-1-4503-3145-6},
	shorttitle = {{MultiFi}},
	url = {https://dl.acm.org/doi/10.1145/2702123.2702331},
	doi = {10.1145/2702123.2702331},
	abstract = {Display devices on and around the body such as smartwatches, head-mounted displays or tablets enable users to interact on the go. However, diverging input and output ﬁdelities of these devices can lead to interaction seams that can inhibit eﬃcient mobile interaction, when users employ multiple devices at once. We present MultiFi, an interactive system that combines the strengths of multiple displays and overcomes the seams of mobile interaction with widgets distributed over multiple devices. A comparative user study indicates that combined headmounted display and smartwatch interfaces can outperform interaction with single wearable devices.},
	language = {en},
	urldate = {2023-01-23},
	booktitle = {Proceedings of the 33rd {Annual} {ACM} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {ACM},
	author = {Grubert, Jens and Heinisch, Matthias and Quigley, Aaron and Schmalstieg, Dieter},
	month = apr,
	year = {2015},
	note = {64 citations (Crossref) [2023-01-23]},
	keywords = {⭐⭐⭐},
	pages = {3933--3942},
}

@inproceedings{prouzeau_visual_2019,
	address = {Daejeon Republic of Korea},
	title = {Visual {Link} {Routing} in {Immersive} {Visualisations}},
	isbn = {978-1-4503-6891-9},
	url = {https://dl.acm.org/doi/10.1145/3343055.3359709},
	doi = {10.1145/3343055.3359709},
	abstract = {In immersive display environments, such as virtual or augmented reality, we can make explicit the connections between data points in visualisations and their context in the world, or in other visualisations. This paper considers the requirements and design space for drawing such links in order to minimise occlusion and clutter. A novel possibility in immersive environments is to optimise the link layout with respect to a particular point of view. In collaborative scenarios there is the need to do this for multiple points of view. We present an algorithm to achieve such link layouts and demonstrate its applicability in a variety of practical use cases.},
	language = {en},
	urldate = {2023-01-23},
	booktitle = {Proceedings of the 2019 {ACM} {International} {Conference} on {Interactive} {Surfaces} and {Spaces}},
	publisher = {ACM},
	author = {Prouzeau, Arnaud and Lhuillier, Antoine and Ens, Barrett and Weiskopf, Daniel and Dwyer, Tim},
	month = nov,
	year = {2019},
	note = {10 citations (Crossref) [2023-01-23]},
	pages = {241--253},
}

@inproceedings{turner_cross-device_2014,
	address = {Safety Harbor Florida},
	title = {Cross-device gaze-supported point-to-point content transfer},
	isbn = {978-1-4503-2751-0},
	url = {https://dl.acm.org/doi/10.1145/2578153.2578155},
	doi = {10.1145/2578153.2578155},
	abstract = {Within a pervasive computing environment, we see content on shared displays that we wish to acquire and use in a speciﬁc way i.e., with an application on a personal device, transferring from point-to-point. The eyes as input can indicate intention to interact with a service, providing implicit pointing as a result. In this paper we investigate the use of gaze and manual input for the positioning of gaze-acquired content on personal devices. We evaluate two main techniques, (1) Gaze Positioning, transfer of content using gaze with manual input to conﬁrm actions, (2) Manual Positioning, content is selected with gaze but ﬁnal positioning is performed by manual input, involving a switch of modalities from gaze to manual input. A ﬁrst user study compares these techniques applied to direct and indirect manual input conﬁgurations, a tablet with touch input and a laptop with mouse input. A second study evaluated our techniques in an application scenario involving distractor targets. Our overall results showed general acceptance and understanding of all conditions, although there were clear individual user preferences dependent on familiarity and preference toward gaze, touch, or mouse input.},
	language = {en},
	urldate = {2023-01-23},
	booktitle = {Proceedings of the {Symposium} on {Eye} {Tracking} {Research} and {Applications}},
	publisher = {ACM},
	author = {Turner, Jayson and Bulling, Andreas and Alexander, Jason and Gellersen, Hans},
	month = mar,
	year = {2014},
	note = {34 citations (Crossref) [2023-01-23]},
	keywords = {⭐⭐⭐},
	pages = {19--26},
}

@inproceedings{darbar_exploring_2021,
	title = {Exploring {Smartphone}-enabled {Text} {Selection} in {AR}-{HMD}},
	booktitle = {Graphics {Interface} 2021},
	author = {Darbar, Rajkumar and Prouzeau, Arnaud and Odicio-Vilchez, Joan and Lainé, Thibault and Hachet, Martin},
	year = {2021},
}

@inproceedings{zhu_bishare_2020,
	address = {Honolulu HI USA},
	title = {{BISHARE}: {Exploring} {Bidirectional} {Interactions} {Between} {Smartphones} and {Head}-{Mounted} {Augmented} {Reality}},
	isbn = {978-1-4503-6708-0},
	shorttitle = {{BISHARE}},
	url = {https://dl.acm.org/doi/10.1145/3313831.3376233},
	doi = {10.1145/3313831.3376233},
	abstract = {In pursuit of a future where HMD devices can be used in tandem with smartphones and other smart devices, we present BISHARE, a design space of cross-device interactions between smartphones and ARHMDs. Our design space is unique in that it is bidirectional in nature, as it examines how both the HMD can be used to enhance smartphone tasks, and how the smartphone can be used to enhance HMD tasks. We then present an interactive prototype that enables cross-device interactions across the proposed design space. A 12-participant user study demonstrates the promise of the design space and provides insights, observations, and guidance for the future.},
	language = {en},
	urldate = {2023-01-23},
	booktitle = {Proceedings of the 2020 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {ACM},
	author = {Zhu, Fengyuan and Grossman, Tovi},
	month = apr,
	year = {2020},
	note = {46 citations (Crossref) [2023-01-23]},
	keywords = {⭐⭐⭐⭐},
	pages = {1--14},
}

@inproceedings{surale_tabletinvr_2019,
	address = {Glasgow Scotland Uk},
	title = {{TabletInVR}: {Exploring} the {Design} {Space} for {Using} a {Multi}-{Touch} {Tablet} in {Virtual} {Reality}},
	isbn = {978-1-4503-5970-2},
	shorttitle = {{TabletInVR}},
	url = {https://dl.acm.org/doi/10.1145/3290605.3300243},
	doi = {10.1145/3290605.3300243},
	abstract = {Complex virtual reality (VR) tasks, like 3D solid modelling, are challenging with standard input controllers. We propose exploiting the affordances and input capabilities when using a 3D-tracked multi-touch tablet in an immersive VR environment. Observations gained during semi-structured interviews with general users, and those experienced with 3D software, are used to define a set of design dimensions and guidelines. These are used to develop a vocabulary of interaction techniques to demonstrate how a tablet’s precise touch input capability, physical shape, metaphorical associations, and natural compatibility with barehand mid-air input can be used in VR. For example, transforming objects with touch input, “cutting” objects by using the tablet as a physical “knife”, navigating in 3D by using the tablet as a viewport, and triggering commands by interleaving bare-hand input around the tablet. Key aspects of the vocabulary are evaluated with users, with results validating the approach.},
	language = {en},
	urldate = {2023-01-23},
	booktitle = {Proceedings of the 2019 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {ACM},
	author = {Surale, Hemant Bhaskar and Gupta, Aakar and Hancock, Mark and Vogel, Daniel},
	month = may,
	year = {2019},
	note = {58 citations (Crossref) [2023-01-23]},
	keywords = {⭐⭐},
	pages = {1--13},
}

@inproceedings{houben_watchconnect_2015,
	address = {Seoul Republic of Korea},
	title = {{WatchConnect}: {A} {Toolkit} for {Prototyping} {Smartwatch}-{Centric} {Cross}-{Device} {Applications}},
	isbn = {978-1-4503-3145-6},
	shorttitle = {{WatchConnect}},
	url = {https://dl.acm.org/doi/10.1145/2702123.2702215},
	doi = {10.1145/2702123.2702215},
	abstract = {People increasingly use smartwatches in tandem with other devices such as smartphones, laptops or tablets. This allows for novel cross-device applications that use the watch as both input device and output display. However, despite the increasing availability of smartwatches, prototyping cross-device watch-centric applications remains a challenging task. Developers are limited in the applications they can explore as available toolkits provide only limited access to different types of input sensors for cross-device interactions. To address this problem, we introduce WatchConnect, a toolkit for rapidly prototyping cross-device applications and interaction techniques with smartwatches. The toolkit provides developers with (i) an extendable hardware platform that emulates a smartwatch, (ii) a UI framework that integrates with an existing UI builder, and (iii) a rich set of input and output events using a range of built-in sensor mappings. We demonstrate the versatility and design space of the toolkit with five interaction techniques and applications.},
	language = {en},
	urldate = {2023-01-23},
	booktitle = {Proceedings of the 33rd {Annual} {ACM} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {ACM},
	author = {Houben, Steven and Marquardt, Nicolai},
	month = apr,
	year = {2015},
	note = {74 citations (Crossref) [2023-01-23]},
	keywords = {⭐⭐⭐},
	pages = {1247--1256},
}

@inproceedings{brudy_cross-device_2019,
	address = {Glasgow Scotland Uk},
	title = {Cross-{Device} {Taxonomy}: {Survey}, {Opportunities} and {Challenges} of {Interactions} {Spanning} {Across} {Multiple} {Devices}},
	isbn = {978-1-4503-5970-2},
	shorttitle = {Cross-{Device} {Taxonomy}},
	url = {https://dl.acm.org/doi/10.1145/3290605.3300792},
	doi = {10.1145/3290605.3300792},
	abstract = {Designing interfaces or applications that move beyond the bounds of a single device screen enables new ways to engage with digital content. Research addressing the opportunities and challenges of interactions with multiple devices in concert is of continued focus in HCI research. To inform the future research agenda of this field, we contribute an analysis and taxonomy of a corpus of 510 papers in the crossdevice computing domain. For both new and experienced researchers in the field we provide: an overview, historic trends and unified terminology of cross-device research; discussion of major and under-explored application areas; mapping of enabling technologies; synthesis of key interaction techniques spanning across multiple devices; and review of common evaluation strategies. We close with a discussion of open issues. Our taxonomy aims to create a unified terminology and common understanding for researchers in order to facilitate and stimulate future cross-device research.},
	language = {en},
	urldate = {2023-01-23},
	booktitle = {Proceedings of the 2019 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {ACM},
	author = {Brudy, Frederik and Holz, Christian and Rädle, Roman and Wu, Chi-Jui and Houben, Steven and Klokmose, Clemens Nylandsted and Marquardt, Nicolai},
	month = may,
	year = {2019},
	note = {93 citations (Crossref) [2023-01-23]},
	keywords = {⭐⭐⭐⭐},
	pages = {1--28},
}

@inproceedings{rekimoto_augmented_1999,
	address = {Pittsburgh, Pennsylvania, United States},
	title = {Augmented surfaces: a spatially continuous work space for hybrid computing environments},
	isbn = {978-0-201-48559-2},
	shorttitle = {Augmented surfaces},
	url = {http://portal.acm.org/citation.cfm?doid=302979.303113},
	doi = {10.1145/302979.303113},
	abstract = {This paperdescribesourdesignandimplementationof acomputer augmentedenvironment that allows usersto smoothly interchange digital information among their portable computers, table and wall displays, and other physical objects. Supported by a camera-basedobject recognition system, userscan easily integratetheir portable computerswith the pre-installed ones in the environment. Users can use displays projectedon tablesandwalls asa spatially continuous extension of their portable computers. Using an interaction technique called hyperdragging, users can transfer information from one computerto another,by only knowing the physicalrelationship betweenthem. We alsoprovide amechanismfor attachingdigital datato physical objects,suchasa videotapeor a documentfolder, to link physical and digital spaces.},
	language = {en},
	urldate = {2023-01-23},
	booktitle = {Proceedings of the {SIGCHI} conference on {Human} factors in computing systems the {CHI} is the limit - {CHI} '99},
	publisher = {ACM Press},
	author = {Rekimoto, Jun and Saitoh, Masanori},
	year = {1999},
	note = {359 citations (Crossref) [2023-01-23]},
	keywords = {⭐⭐},
	pages = {378--385},
}

@inproceedings{serrano_gluey_2015,
	address = {Copenhagen Denmark},
	title = {Gluey: {Developing} a {Head}-{Worn} {Display} {Interface} to {Unify} the {Interaction} {Experience} in {Distributed} {Display} {Environments}},
	isbn = {978-1-4503-3652-9},
	shorttitle = {Gluey},
	url = {https://dl.acm.org/doi/10.1145/2785830.2785838},
	doi = {10.1145/2785830.2785838},
	language = {en},
	urldate = {2023-01-23},
	booktitle = {Proceedings of the 17th {International} {Conference} on {Human}-{Computer} {Interaction} with {Mobile} {Devices} and {Services}},
	publisher = {ACM},
	author = {Serrano, Marcos and Ens, Barrett and Yang, Xing-Dong and Irani, Pourang},
	month = aug,
	year = {2015},
	note = {40 citations (Crossref) [2023-01-23]},
	keywords = {⭐⭐⭐⭐⭐},
	pages = {161--171},
}

@inproceedings{langner_marvis_2021,
	address = {Yokohama Japan},
	title = {{MARVIS}: {Combining} {Mobile} {Devices} and {Augmented} {Reality} for {Visual} {Data} {Analysis}},
	isbn = {978-1-4503-8096-6},
	shorttitle = {{MARVIS}},
	url = {https://dl.acm.org/doi/10.1145/3411764.3445593},
	doi = {10.1145/3411764.3445593},
	language = {en},
	urldate = {2023-01-23},
	booktitle = {Proceedings of the 2021 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {ACM},
	author = {Langner, Ricardo and Satkowski, Marc and Büschel, Wolfgang and Dachselt, Raimund},
	month = may,
	year = {2021},
	note = {19 citations (Crossref) [2023-01-23]},
	pages = {1--17},
}

@inproceedings{li_devicear_2020,
	address = {Virtual Event Mexico},
	title = {{DeviceAR}: techniques for device-oriented augmented reality interactions},
	isbn = {978-1-4503-8076-8},
	shorttitle = {{DeviceAR}},
	url = {https://dl.acm.org/doi/10.1145/3410530.3414324},
	doi = {10.1145/3410530.3414324},
	abstract = {We present DeviceAR, a set of techniques to facilitate AR-based interactions with connected devices. These techniques allow HoloLens to discover and establish communication with devices, control them, and seamlessly exchange digital information using holographic interfaces.},
	language = {en},
	urldate = {2023-01-23},
	booktitle = {Adjunct {Proceedings} of the 2020 {ACM} {International} {Joint} {Conference} on {Pervasive} and {Ubiquitous} {Computing} and {Proceedings} of the 2020 {ACM} {International} {Symposium} on {Wearable} {Computers}},
	publisher = {ACM},
	author = {Li, Hanchuan and Capone, Tony and Lymberopoulos, Dimitrios},
	month = sep,
	year = {2020},
	note = {0 citations (Crossref) [2023-01-23]},
	pages = {188--190},
}

@inproceedings{wu_megereality_2020,
	address = {Honolulu HI USA},
	title = {"{Megereality}": {Leveraging} {Physical} {Affordances} for {Multi}-{Device} {Gestural} {Interaction} in {Augmented} {Reality}},
	isbn = {978-1-4503-6819-3},
	shorttitle = {"{Megereality}"},
	url = {https://dl.acm.org/doi/10.1145/3334480.3383170},
	doi = {10.1145/3334480.3383170},
	abstract = {We present a novel gestural interaction strategy for multi-device interactions in augmented reality (AR), in which we leverage existing physical affordances of everyday products and spaces for intuitive interactions in AR. To explore this concept, we designed and prototyped three demo scenarios: pulling virtual sticky notes from a tablet, pulling a 3D model from a computer display, and ‘slurping’ color from the real-world environment to smart lights with a virtual eyedropper. By merging the boundary of digital and physical, utilizing metaphors in AR and embodying the abstract process, we demonstrate an interaction strategy that harnesses the physical affordances to assist digital interaction in AR with hand gestures.},
	language = {en},
	urldate = {2023-01-23},
	booktitle = {Extended {Abstracts} of the 2020 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {ACM},
	author = {Wu, Shengzhi and Byrne, Daragh and Steenson, Molly Wright},
	month = apr,
	year = {2020},
	note = {3 citations (Crossref) [2023-01-23]},
	pages = {1--4},
}

@inproceedings{ren_understanding_2020,
	address = {Honolulu HI USA},
	title = {Understanding {Window} {Management} {Interactions} in {AR} {Headset} + {Smartphone} {Interface}},
	isbn = {978-1-4503-6819-3},
	url = {https://dl.acm.org/doi/10.1145/3334480.3382812},
	doi = {10.1145/3334480.3382812},
	abstract = {We envision a combinative use of an AR headset and a smartphone in the future that can provide a more extensive display and precise touch input simultaneously. In this way, the input/output interface of these two devices can fuse to redeﬁne how a user can manage application windows seamlessly on the two devices. In this work, we conducted a formative interview with ten people to provide an understanding of how users would prefer to manage multiple windows on the fused interface. Our interview highlighted that the desire to use a smartphone as a window management interface shaped users’ interaction practices of window management operations. This paper reports how their desire to use a smartphone as a window manager is manifested.},
	language = {en},
	urldate = {2023-01-23},
	booktitle = {Extended {Abstracts} of the 2020 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {ACM},
	author = {Ren, Jie and Weng, Yueting and Zhou, Chengchi and Yu, Chun and Shi, Yuanchun},
	month = apr,
	year = {2020},
	note = {4 citations (Crossref) [2023-01-23]},
	pages = {1--8},
}

@inproceedings{di_verdi_arwin_2003,
	address = {Tokyo, Japan},
	title = {{ARWin} - a desktop augmented reality {Window} {Manager}},
	isbn = {978-0-7695-2006-3},
	url = {http://ieeexplore.ieee.org/document/1240729/},
	doi = {10.1109/ISMAR.2003.1240729},
	abstract = {We present ARWin, a single user 3D augmented reality desktop. We explain our design considerations and system architecture and discuss a variety of applications and interaction techniques designed to take advantage of this new platform.},
	language = {en},
	urldate = {2023-01-23},
	booktitle = {The {Second} {IEEE} and {ACM} {International} {Symposium} on {Mixed} and {Augmented} {Reality}, 2003. {Proceedings}.},
	publisher = {IEEE Comput. Soc},
	author = {Di Verdi, S. and Nurmi, D. and Hollerer, T.},
	year = {2003},
	note = {15 citations (Crossref) [2023-01-23]},
	pages = {298--299},
}

@inproceedings{marquardt_airconstellations_2021,
	address = {Virtual Event USA},
	title = {{AirConstellations}: {In}-{Air} {Device} {Formations} for {Cross}-{Device} {Interaction} via {Multiple} {Spatially}-{Aware} {Armatures}},
	isbn = {978-1-4503-8635-7},
	shorttitle = {{AirConstellations}},
	url = {https://dl.acm.org/doi/10.1145/3472749.3474820},
	doi = {10.1145/3472749.3474820},
	language = {en},
	urldate = {2023-01-23},
	booktitle = {The 34th {Annual} {ACM} {Symposium} on {User} {Interface} {Software} and {Technology}},
	publisher = {ACM},
	author = {Marquardt, Nicolai and Henry Riche, Nathalie and Holz, Christian and Romat, Hugo and Pahud, Michel and Brudy, Frederik and Ledo, David and Park, Chunjong and Nicholas, Molly Jane and Seyed, Teddy and Ofek, Eyal and Lee, Bongshin and Buxton, William A.S. and Hinckley, Ken},
	month = oct,
	year = {2021},
	note = {2 citations (Crossref) [2023-01-23]},
	pages = {1252--1268},
}

@inproceedings{du_opportunistic_2022,
	address = {New Orleans LA USA},
	title = {Opportunistic {Interfaces} for {Augmented} {Reality}: {Transforming} {Everyday} {Objects} into {Tangible} {6DoF} {Interfaces} {Using} {Ad} hoc {UI}},
	isbn = {978-1-4503-9156-6},
	shorttitle = {Opportunistic {Interfaces} for {Augmented} {Reality}},
	url = {https://dl.acm.org/doi/10.1145/3491101.3519911},
	doi = {10.1145/3491101.3519911},
	language = {en},
	urldate = {2023-01-23},
	booktitle = {{CHI} {Conference} on {Human} {Factors} in {Computing} {Systems} {Extended} {Abstracts}},
	publisher = {ACM},
	author = {Du, Ruofei and Olwal, Alex and Le Goc, Mathieu and Wu, Shengzhi and Tang, Danhang and Zhang, Yinda and Zhang, Jun and Tan, David Joseph and Tombari, Federico and Kim, David},
	month = apr,
	year = {2022},
	note = {2 citations (Crossref) [2023-01-23]},
	pages = {1--4},
}

@inproceedings{alan_scott_first_2022,
	address = {Daejeon Republic of Korea},
	title = {First {Impressions}: {A} {Visual} {Catalogue} for {Understanding} {Interactions} with {Novel} {Interfaces} in {Augmented} {Reality}},
	isbn = {978-1-4503-9147-4},
	shorttitle = {First {Impressions}},
	url = {https://dl.acm.org/doi/10.1145/3490149.3502259},
	doi = {10.1145/3490149.3502259},
	abstract = {Although Augmented Reality (AR) has become increasingly common, the design of AR interfaces has predominantly relied on importing traditional 2D digital GUI interface elements. These do not always translate successfully to novel, three-dimensional, AR interfaces. To understand how users develop a folk understanding of AR interfaces, we conducted six workshops with participants to investigate their initial interactions with off-the-shelf puzzle interfaces, across three modes: tangible, handheld tablet, and head-mounted display (HMD) AR systems. We captured multiple points-ofview video data and co-analyzed it with participants. Our study (1) presents a catalogue of interactional gestures across the three modes; (2) highlights how errors are perceived as features in AR systems; (3) analyzes the evolution of gestures; and (4) identifies implications of occlusion and spatial judgement errors.},
	language = {en},
	urldate = {2023-01-23},
	booktitle = {Sixteenth {International} {Conference} on {Tangible}, {Embedded}, and {Embodied} {Interaction}},
	publisher = {ACM},
	author = {Alan Scott, Steven and Khan, Awais Hameed and Matthews, Ben},
	month = feb,
	year = {2022},
	note = {0 citations (Crossref) [2023-01-23]},
	pages = {1--14},
}

@inproceedings{normand_enlarging_2018,
	address = {Munich, Germany},
	title = {Enlarging a {Smartphone} with {AR} to {Create} a {Handheld} {VESAD} ({Virtually} {Extended} {Screen}-{Aligned} {Display})},
	isbn = {978-1-5386-7459-8},
	url = {https://ieeexplore.ieee.org/document/8613758/},
	doi = {10.1109/ISMAR.2018.00043},
	abstract = {We investigate using augmented reality to extend the screen of a smartphone beyond its physical limits with a virtual surface that is co-planar with the phone and that follows as the phone is moved. We call this extension a VESAD, or Virtually Extended Screen-Aligned Display. We illustrate and describe several ways that a VESAD could be used to complement the physical screen of a phone, and describe two novel interaction techniques: one where the user performs a quick rotation of the phone to switch the information shown in the VESAD, and another called “slide-and-hang” whereby the user can detach a VESAD and leave it hanging in mid-air, using the phone to establish the initial position and orientation of the virtual window. We also report an experiment that compared three interfaces used for an abstract classiﬁcation task: the ﬁrst using only a smartphone, the second using the phone for input but with a VESAD for output, and the third where the user performed input in mid-air on the VESAD (as detected by a Leap Motion). The second user interface was found to be superior in time and selection count (a metric of mistakes committed by users) and was also subjectively preferred over the other two interfaces. This demonstrates the added value of a VESAD for output over a phone’s physical screen, and also demonstrates that input on the phone’s screen was better than input in mid-air in our experiment.},
	language = {en},
	urldate = {2023-01-23},
	booktitle = {2018 {IEEE} {International} {Symposium} on {Mixed} and {Augmented} {Reality} ({ISMAR})},
	publisher = {IEEE},
	author = {Normand, Erwan and McGuffin, Michael J.},
	month = oct,
	year = {2018},
	note = {24 citations (Crossref) [2023-01-23]},
	pages = {123--133},
}

@inproceedings{saidi_holobar_2021,
	address = {Yokohama Japan},
	title = {{HoloBar}: {Rapid} {Command} {Execution} for {Head}-{Worn} {AR} {Exploiting} {Around} the {Field}-of-{View} {Interaction}},
	isbn = {978-1-4503-8096-6},
	shorttitle = {{HoloBar}},
	url = {https://dl.acm.org/doi/10.1145/3411764.3445255},
	doi = {10.1145/3411764.3445255},
	abstract = {Inefcient menu interfaces lead to system and application commands being tedious to execute in Immersive Environments. HoloBar is a novel approach to ease the interaction with multi-level menus in immersive environments: with HoloBar, the hierarchical menu splits between the feld of view (FoV) of the Head Mounted Display and the smartphone (SP). Command execution is based on around-the-FoV interaction with the SP, and touch input on the SP display. The HoloBar ofers a unique combination of features, namely rapid mid-air activation, implicit selection of top-level items and preview of second-level items on the SP, ensuring rapid access to commands. In a frst study we validate its activation method, which consists in bringing the SP within an activation distance from the FoV. In a second study, we compare the HoloBar to two alternatives, including the standard HoloLens menu. Results show that the HoloBar shortens each step of a multi-level menu interaction (menu activation, top-level item selection, second-level item selection and validation), with a high success rate. A follow-up study confrms that these results remain valid when compared with the two validation mechanisms of HoloLens (Air-Tap and clicker).},
	language = {en},
	urldate = {2023-01-23},
	booktitle = {Proceedings of the 2021 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {ACM},
	author = {Saidi, Houssem and Dubois, Emmanuel and Serrano, Marcos},
	month = may,
	year = {2021},
	note = {5 citations (Crossref) [2023-01-23]},
	pages = {1--17},
}

@inproceedings{lee_post-post-it_2021,
	address = {Yokohama Japan},
	title = {Post-{Post}-it: {A} {Spatial} {Ideation} {System} in {VR} for {Overcoming} {Limitations} of {Physical} {Post}-it {Notes}},
	isbn = {978-1-4503-8095-9},
	shorttitle = {Post-{Post}-it},
	url = {https://dl.acm.org/doi/10.1145/3411763.3451786},
	doi = {10.1145/3411763.3451786},
	abstract = {Post-it notes are great problem-solving tools. However, physical Post-it notes have limitations: surfaces for attaching them can run out; rearranging them can be labor-intensive; documenting and storing them can be cumbersome. We present Post-Post-it, a novel VR interaction system that overcomes these physical limitations. We derived design requirements from a formative study involving a problem-solving meeting using Post-it notes. Then, through physical prototyping, using physical materials such as Post-it notes, transparent acrylic panels, and masking tape, we designed a set of lifelike VR interactions based on hand gestures that the user can perform easily and intuitively. With our system, the user can create and place Post-it notes in an immersive space that is large enough to ideate freely, quickly move, copy, or delete many Post-it notes at once, and easily manage the results.},
	language = {en},
	urldate = {2023-01-23},
	booktitle = {Extended {Abstracts} of the 2021 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {ACM},
	author = {Lee, Joon Hyub and Ma, Donghyeok and Cho, Haena and Bae, Seok-Hyung},
	month = may,
	year = {2021},
	note = {3 citations (Crossref) [2023-01-23]},
	pages = {1--7},
}

@article{darbar_exploring_nodate,
	title = {Exploring {Smartphone}-enabled {Text} {Selection} in {AR}-{HMD}},
	abstract = {Text editing is important and at the core of most complex tasks, like writing an email or browsing the web. Efﬁcient and sophisticated techniques exist on desktops and touch devices, but are still underexplored for Augmented Reality Head Mounted Display (AR-HMD). Performing text selection, a necessary step before text editing, in AR display commonly uses techniques such as hand-tracking, voice commands, eye/head-gaze, which are cumbersome and lack precision. In this paper, we explore the use of a smartphone as an input device to support text selection in AR-HMD because of its availability, familiarity, and social acceptability. We propose four eyes-free text selection techniques, all using a smartphone — continuous touch, discrete touch, spatial movement, and raycasting. We compare them in a user study where users have to select text at various granularity levels. Our results suggest that continuous touch, in which we used the smartphone as a trackpad, outperforms the other three techniques in terms of task completion time, accuracy, and user preference.},
	language = {en},
	author = {Darbar, Rajkumar and Prouzeau, Arnaud and Odicio-Vilchez, Joan and Hachet, Martin and Laine, Thibault},
}

@article{biener_quantifying_2022,
	title = {Quantifying the {Effects} of {Working} in {VR} for {One} {Week}},
	volume = {28},
	doi = {10.1109/TVCG.2022.3203103},
	number = {11},
	journal = {IEEE Transactions on Visualization and Computer Graphics},
	author = {Biener, Verena and Kalamkar, Snehanjali and Nouri, Negar and Ofek, Eyal and Pahud, Michel and Dudley, John J. and Hu, Jinghui and Kristensson, Per Ola and Weerasinghe, Maheshya and Pucihar, Klen Copic and Kljun, Matjaz and Streuber, Stephan and Grubert, Jens},
	year = {2022},
	pages = {3810--3820},
}

@inproceedings{pavanatto_monitors_2021,
	title = {Do we still need physical monitors? {An} evaluation of the usability of {AR} virtual monitors for productivity work},
	copyright = {All rights reserved},
	doi = {10.1109/VR50410.2021.00103},
	booktitle = {2021 {IEEE} {Virtual} {Reality} and {3D} {User} {Interfaces} ({VR})},
	author = {Pavanatto, Leonardo and North, Chris and Bowman, Doug A. and Badea, Carmen and Stoakley, Richard},
	year = {2021},
	pages = {759--767},
}

@article{schade_having_2021,
	title = {Having to {Work} from {Home}: {Basic} {Needs}, {Well}-{Being}, and {Motivation}},
	volume = {18},
	issn = {1660-4601},
	shorttitle = {Having to {Work} from {Home}},
	url = {https://www.mdpi.com/1660-4601/18/10/5149},
	doi = {10.3390/ijerph18105149},
	abstract = {During the COVID-19 pandemic, many employees were asked to start working from home for an extended time. The current study investigated how well employees worked and felt in this novel situation by following n = 199 German employees—56\% of them female, 24\% with childcare duties—over the course of two working weeks in which they reported once daily on their well-being (PANAS-20, detachment) and motivation (work engagement, ﬂow). Participants reported on organizational and personal resources (emotional exhaustion, emotion regulation, segmentation preference, role clarity, job control, social support). Importantly, they indicated how well their work-related basic needs, i.e., autonomy, competence, and relatedness, were met when working from home and how these needs had been met in the ofﬁce. Multilevel models of growth showed that work engagement, ﬂow, affect and detachment were on average positive and improving over the two weeks in study. Higher competence need satisfaction predicted better daily work engagement, ﬂow, and affect. In a network model, we explored associations and dynamics between daily variables. Overall, the results suggest that people adapted well to the novel situation, with their motivation and well-being indicators showing adequate levels and increasing trajectories. Avenues for improving work from home are job control and social support.},
	language = {en},
	number = {10},
	urldate = {2022-11-10},
	journal = {International Journal of Environmental Research and Public Health},
	author = {Schade, Hannah M. and Digutsch, Jan and Kleinsorge, Thomas and Fan, Yan},
	month = may,
	year = {2021},
	pages = {5149},
}

@misc{biener_content_2022,
	title = {Content {Transfer} {Across} {Multiple} {Screens} with {Combined} {Eye}-{Gaze} and {Touch} {Interaction} -- {A} {Replication} {Study}},
	url = {http://arxiv.org/abs/2210.13283},
	abstract = {In this paper, we describe the results of replicating one of our studies from two years ago [1] which compares two techniques for transferring content across multiple screens in VR. Results from the previous study have shown that a combined gaze and touch input can outperform a bimanual touch-only input in terms of task completion time, simulator sickness, task load and usability. Except for the simulator sickness, these ﬁndings could be validated by the replication. The difference with regards to simulator sickness and variations in absolute scores of the other measures could be explained by a different set of user with less VR experience.},
	language = {en},
	urldate = {2022-11-10},
	publisher = {arXiv},
	author = {Biener, Verena and Grubert, Jens},
	month = oct,
	year = {2022},
	note = {arXiv:2210.13283 [cs]},
	keywords = {Computer Science - Human-Computer Interaction, I.3.7},
}

@article{dembla_eect_nodate,
	title = {The {Eﬀect} of {Several} {Tradeoﬀs} in the {Implementation} of {Large} {Displays} on the {Performance} of the {Users} of the {Displays}},
	language = {en},
	author = {Dembla, Shivam},
	pages = {68},
}

@article{ebert_tiled_2010,
	title = {Tiled++: {An} {Enhanced} {Tiled} {Hi}-{Res} {Display} {Wall}},
	volume = {16},
	issn = {1077-2626},
	shorttitle = {Tiled++},
	url = {http://ieeexplore.ieee.org/document/4967580/},
	doi = {10.1109/TVCG.2009.57},
	abstract = {In recent years, high-resolution displays have become increasingly important to decision makers and scientists because large screens combined with a high pixel count facilitate content rich, simultaneous display of computer-generated imagery and highdefinition video data from multiple sources. Tiled displays are attractive due to their extended screen real estate, scalability, and low cost. LCD panels are usually preferred over projectors because of their superior resolution. One of the drawbacks of LCD-based tiled displays is the fact that users sometimes get distracted by the screens’ bezels, which cause discontinuities in rendered images, animations, or videos. Most conventional solutions either ignore the bezels and display all pixels, causing objects to become distorted, or eliminate the pixels that would normally fall under the bezels, causing pixels to be missing in the display of static images. In animations, the missing pixels will eventually reappear when the object moves, providing an experience that is similar to looking through a French window. In this paper, we present a new scalable approach that leads neither to discontinuities nor to significant loss of information. By projecting onto the bezels, we demonstrate that a combination of LCD-based tiled displays and projection significantly reduces the bezel problem. Our technique eliminates ambiguities that commonly occur on tiled displays in the fields of information visualization, visual data analysis, human-computer interaction, and scientific data display. It improves the usability of multimonitor systems by virtually eliminating the bezels. We describe a setup and provide results from an evaluation experiment conducted on a 3 Â 3 and on a 10 Â 5 tiled display wall.},
	language = {en},
	number = {1},
	urldate = {2022-11-09},
	journal = {IEEE Transactions on Visualization and Computer Graphics},
	author = {Ebert, A. and Thelen, S. and Olech, P.-S. and Meyer, J. and Hagen, H.},
	month = jan,
	year = {2010},
	pages = {120--132},
}

@misc{fereydooni_virtual_2020,
	title = {Virtual {Reality} as a {Remote} {Workspace} {Platform}: {Opportunities} and {Challenges}},
	url = {https://www.microsoft.com/en-us/research/publication/virtual-reality-as-a-remote-workspace-platform-opportunities-and-challenges/},
	publisher = {Microsoft},
	author = {Fereydooni, Nadia and Walker, Bruce N.},
	month = aug,
	year = {2020},
}

@inproceedings{mcguffin_augmented_2019,
	title = {Augmented {Reality} {Knowledge} {Work}: {Towards} a {Research} {Agenda}},
	abstract = {This paper argues that the most likely new display technology to achieve widespread adoption is augmented reality (AR) head-mounted displays (HMDs), and further argues that the way this will happen is through making them useful to knowledge workers who use them with laptops and smartphones. Research questions related to these use cases are identified.},
	language = {en},
	booktitle = {Workshop on {Immersive} {Analytics}: {Interaction} {Design} and {Prototyping} for {Immersive} {Analytics}},
	author = {McGuffin, Michael J},
	year = {2019},
	pages = {11},
}

@inproceedings{cockburn_3d_2001,
	address = {New York, NY, USA},
	series = {{CHI} '01},
	title = {{3D} or {Not} {3D}? {Evaluating} the {Effect} of the {Third} {Dimension} in a {Document} {Management} {System}},
	isbn = {1-58113-327-8},
	url = {https://doi.org/10.1145/365024.365309},
	doi = {10.1145/365024.365309},
	abstract = {Several recent research systems have provided interactive three-dimensional (3D) visualisations for supporting everyday work such as file and document management. But what improvements do these 3D interfaces offer over their traditional 2D counterparts? This paper describes the comparative evaluation of two document management systems that differ only in the number of dimensions used for displaying and interacting with the data. The 3D system is heavily based on Robertson et al.'s Data Mountain, which supports users in storing, organising and retrieving “thumbnail” representations of documents such as bookmarked Web-pages. Results show that our subjects were faster at storing and retrieving pages in the display when using the 2D interface, but not significantly so. As expected, retrieval times significantly increased as the number of thumbnails increased. Despite the lack of significant differences between the 2D and 3D interfaces, subjective assessments showed a significant preference for the 3D interface.},
	booktitle = {Proceedings of the {SIGCHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Cockburn, Andy and McKenzie, Bruce},
	year = {2001},
	note = {event-place: Seattle, Washington, USA},
	keywords = {3D user interfaces, document management, information visualisation, spatial memory},
	pages = {434--441},
}

@article{jones_spatial_1986,
	title = {The {Spatial} {Metaphor} for {User} {Interfaces}: {Experimental} {Tests} of {Reference} by {Location} versus {Name}},
	volume = {4},
	issn = {1046-8188},
	url = {https://doi.org/10.1145/5401.5405},
	doi = {10.1145/5401.5405},
	abstract = {The enduring dichotomy between spatial and symbolic modes of representation and retrieval acquires an added pragmatic dimension through recent developments in computer-based information retrieval. The standard name-based approach to object reference is now supplemented on some systems by a spatial alternative-often driven by an office or desktop metaphor. Little rigorous evidence is available, however, to support the supposition that spatial memory in itself is more effective than symbolic memory.The accuracy of spatial versus symbolic reference was assessed in three experiments. In Experiment 1 accuracy of location reference in a location-only filing condition was initially comparable to that in a name-only condition, but deteriorated much more rapidly with increases in the number of objects filed. In Experiment 2 subjects placed objects in a two-dimensional space containing landmarks (drawings of a desk, table, filing cabinets, etc.) designed to evoke an office metaphor, and in Experiment 3 subjects placed objects in an actual, three-dimensional mock office. Neither of these enhancements served to improve significantly the accuracy of location reference, and performance remained below that of a name-only condition in Experiment 1. The results raise questions about the utility of spatial metaphor over symbolic filing and highlight the need for continuing research in which considerations of technological and economic feasibility are balanced by considerations of psychological utility.},
	number = {1},
	journal = {ACM Trans. Inf. Syst.},
	author = {Jones, William P. and Dumais, Susan T.},
	month = jan,
	year = {1986},
	note = {Place: New York, NY, USA
Publisher: Association for Computing Machinery},
	pages = {42--63},
}

@inproceedings{smith_croquet_2004,
	title = {Croquet: a menagerie of new user interfaces},
	doi = {10.1109/C5.2004.1314362},
	booktitle = {Proceedings. {Second} {International} {Conference} on {Creating}, {Connecting} and {Collaborating} through {Computing}, 2004.},
	author = {Smith, D.A. and Raab, A. and Reed, D.P. and Kay, A.},
	year = {2004},
	pages = {4--11},
}

@inproceedings{robertson_data_1998,
	address = {New York, NY, USA},
	series = {{UIST} '98},
	title = {Data {Mountain}: {Using} {Spatial} {Memory} for {Document} {Management}},
	isbn = {1-58113-034-1},
	url = {https://doi.org/10.1145/288392.288596},
	doi = {10.1145/288392.288596},
	booktitle = {Proceedings of the 11th {Annual} {ACM} {Symposium} on {User} {Interface} {Software} and {Technology}},
	publisher = {Association for Computing Machinery},
	author = {Robertson, George and Czerwinski, Mary and Larson, Kevin and Robbins, Daniel C. and Thiel, David and van Dantzich, Maarten},
	year = {1998},
	note = {event-place: San Francisco, California, USA},
	keywords = {3D user interfaces, desktop VR, document mangement, information visualization, spatial cognition, spatial memory},
	pages = {153--162},
}

@inproceedings{cockburn_evaluating_2002,
	address = {New York, NY, USA},
	series = {{CHI} '02},
	title = {Evaluating the {Effectiveness} of {Spatial} {Memory} in {2D} and {3D} {Physical} and {Virtual} {Environments}},
	isbn = {1-58113-453-3},
	url = {https://doi.org/10.1145/503376.503413},
	doi = {10.1145/503376.503413},
	abstract = {User interfaces can improve task performance by exploiting the powerful human capabilities for spatial cognition. This opportunity has been demonstrated by many prior experiments. It is tempting to believe that providing greater spatial flexibility-by moving from flat 2D to 3D user interfaces-will further enhance user performance. This paper describes an experiment that investigates the effectiveness of spatial memory in real-world physical models and in equivalent computer-based virtual systems. The different models vary the user's freedom to use depth and perspective in spatial arrangements of images representing web pages. Results show that the subjects' performance deteriorated in both the physical and virtual systems as their freedom to locate items in the third dimension increased. Subjective measures reinforce the performance measures, indicating that users found interfaces with higher dimensions more 'cluttered' and less efficient},
	booktitle = {Proceedings of the {SIGCHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Cockburn, Andy and McKenzie, Bruce},
	year = {2002},
	note = {event-place: Minneapolis, Minnesota, USA},
	keywords = {3D user interfaces, document management, information visualization, spatial memory},
	pages = {203--210},
}

@article{gajendran_good_2007,
	title = {The good, the bad, and the unknown about telecommuting: {Meta}-analysis of psychological mediators and individual consequences.},
	volume = {92},
	issn = {1939-1854(Electronic),0021-9010(Print)},
	doi = {10.1037/0021-9010.92.6.1524},
	abstract = {What are the positive and negative consequences of telecommuting? How do these consequences come about? When are these consequences more or less potent? The authors answer these questions through construction of a theoretical framework and meta-analysis of 46 studies in natural settings involving 12,883 employees. Telecommuting had small but mainly beneficial effects on proximal outcomes, such as perceived autonomy and (lower) work-family conflict. Importantly, telecommuting had no generally detrimental effects on the quality of workplace relationships. Telecommuting also had beneficial effects on more distal outcomes, such as job satisfaction, performance, turnover intent, and role stress. These beneficial consequences appeared to be at least partially mediated by perceived autonomy. Also, high-intensity telecommuting (more than 2.5 days a week) accentuated telecommuting's beneficial effects on work-family conflict but harmed relationships with coworkers. Results provide building blocks for a more complete theoretical and practical treatment of telecommuting. (PsycInfo Database Record (c) 2020 APA, all rights reserved)},
	journal = {Journal of Applied Psychology},
	author = {Gajendran, Ravi S. and Harrison, David A.},
	year = {2007},
	note = {Place: US
Publisher: American Psychological Association},
	keywords = {*Telecommuting, *Virtual Teams, *Working Conditions, Consequence},
	pages = {1524--1541},
}

@article{crosbie_worklife_2004,
	title = {Work–life {Balance} and {Working} from {Home}},
	volume = {3},
	doi = {10.1017/S1474746404001733},
	number = {3},
	journal = {Social Policy and Society},
	author = {Crosbie, Tracey and Moore, Jeanne},
	year = {2004},
	note = {Publisher: Cambridge University Press},
	pages = {223--233},
}

@article{bloom_does_2014,
	title = {Does {Working} from {Home} {Work}? {Evidence} from a {Chinese} {Experiment}},
	volume = {130},
	issn = {0033-5533},
	url = {https://doi.org/10.1093/qje/qju032},
	doi = {10.1093/qje/qju032},
	abstract = {A rising share of employees now regularly engage in working from home (WFH), but there are concerns this can lead to “shirking from home.” We report the results of a WFH experiment at Ctrip, a 16,000-employee, NASDAQ-listed Chinese travel agency. Call center employees who volunteered to WFH were randomly assigned either to work from home or in the office for nine months. Home working led to a 13\% performance increase, of which 9\% was from working more minutes per shift (fewer breaks and sick days) and 4\% from more calls per minute (attributed to a quieter and more convenient working environment). Home workers also reported improved work satisfaction, and their attrition rate halved, but their promotion rate conditional on performance fell. Due to the success of the experiment, Ctrip rolled out the option to WFH to the whole firm and allowed the experimental employees to reselect between the home and office. Interestingly, over half of them switched, which led to the gains from WFH almost doubling to 22\%. This highlights the benefits of learning and selection effects when adopting modern management practices like WFH.},
	number = {1},
	journal = {The Quarterly Journal of Economics},
	author = {Bloom, Nicholas and Liang, James and Roberts, John and Ying, Zhichun Jenny},
	month = nov,
	year = {2014},
	note = {\_eprint: https://academic.oup.com/qje/article-pdf/130/1/165/30629971/qju032.pdf},
	pages = {165--218},
}

@inproceedings{lu_evaluating_2021,
	address = {Lisboa, Portugal},
	title = {Evaluating the {Potential} of {Glanceable} {AR} {Interfaces} for {Authentic} {Everyday} {Uses}},
	isbn = {978-1-66541-838-6},
	url = {https://ieeexplore.ieee.org/document/9417649/},
	doi = {10.1109/VR50410.2021.00104},
	abstract = {In the near future, augmented reality (AR) glasses are envisioned to become the next-generation personal computing platform. They could be always on and worn all day, delivering continuous and pervasive AR experiences for general-purpose everyday use cases. However, it remains unclear how we could enable unobtrusive and easy information access without distracting users, while being acceptable to use at the same time. To address this question, we implemented two prototypes based on the Glanceable AR paradigm, a promising way of managing and acquiring information through glancing at the periphery of AR head-worn displays (HWDs). We conducted two separate studies to evaluate our designs. In the ﬁrst study, we obtained feedback from a large sample of participants of varied age and background about a video prototype that showcased some envisioned scenarios of using Glanceable AR for everyday tasks. In the second study, we asked participants to use a working prototype during authentic real-world activities for three days. We found that users appreciated the Glanceable AR approach. They found it less distracting or intrusive than existing devices in authentic everyday use cases, and would like to use the interface on a daily basis if the form factor of the AR headset was more like eyeglasses.},
	language = {en},
	urldate = {2022-10-23},
	booktitle = {2021 {IEEE} {Virtual} {Reality} and {3D} {User} {Interfaces} ({VR})},
	publisher = {IEEE},
	author = {Lu, Feiyu and Bowman, Doug A.},
	month = mar,
	year = {2021},
	pages = {768--777},
}

@article{garcia-sanjuan_toward_2016,
	title = {Toward a {General} {Conceptualization} of {Multi}-{Display} {Environments}},
	volume = {3},
	issn = {2297-198X},
	url = {http://journal.frontiersin.org/Article/10.3389/fict.2016.00020/abstract},
	doi = {10.3389/fict.2016.00020},
	language = {en},
	urldate = {2022-10-23},
	journal = {Frontiers in ICT},
	author = {Garcia-Sanjuan, Fernando and Jaen, Javier and Nacher, Vicente},
	month = sep,
	year = {2016},
}

@inproceedings{yuan_understanding_2022,
	address = {New York, NY, USA},
	series = {{CHI} '22},
	title = {Understanding {Multi}-{Device} {Usage} {Patterns}: {Physical} {Device} {Configurations} and {Fragmented} {Workflows}},
	isbn = {978-1-4503-9157-3},
	url = {https://doi.org/10.1145/3491102.3517702},
	doi = {10.1145/3491102.3517702},
	abstract = {To better ground technical (systems) investigation and interaction design of cross-device experiences, we contribute an in-depth survey of existing multi-device practices, including fragmented workflows across devices and the way people physically organize and configure their workspaces to support such activity. Further, this survey documents a historically significant moment of transition to a new future of remote work, an existing trend dramatically accelerated by the abrupt switch to work-from-home (and having to contend with the demands of home-at-work) during the COVID-19 pandemic. We surveyed 97 participants, and collected photographs of home setups and open-ended answers to 50 questions categorized in 5 themes. We characterize the wide range of multi-device physical configurations and identify five usage patterns, including: partitioning tasks, integrating multi-device usage, cloning tasks to other devices, expanding tasks and inputs to multiple devices, and migrating between devices. Our analysis also sheds light on the benefits and challenges people face when their workflow is fragmented across multiple devices. These insights have implications for the design of multi-device experiences that support people’s fragmented workflows.},
	booktitle = {Proceedings of the 2022 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Yuan, Ye and Riche, Nathalie and Marquardt, Nicolai and Nicholas, Molly Jane and Seyed, Teddy and Romat, Hugo and Lee, Bongshin and Pahud, Michel and Goldstein, Jonathan and Vishkaie, Rojin and Holz, Christian and Hinckley, Ken},
	year = {2022},
	note = {event-place: New Orleans, LA, USA},
	keywords = {cross-device computing, distributed user interfaces, multi-device},
}

@article{zeitz_bringing_2018,
	title = {Bringing {Interactive} {Visual} {Analytics} to the {Classroom} for {Developing} {EDA} {Skills}},
	volume = {33},
	issn = {1937-4771},
	abstract = {This paper addresses the use of visual analytics in education for teaching Exploratory Data Analysis (EDA) skills. EDA is inherently a creative, knowledge discovery process that often takes place before formal technical statistical analyses. A challenge in teaching EDA is that there is often no right nor wrong way to conduct EDA, yet, given a dataset, some EDA can be more comprehensive or insightful than others, based on the kinds of insights made. Also, in the face of high-dimensional data, students are often limited by how they relate to the data and their technical skills for EDA. How can students make complex insights from high-dimensional data, if they do not have the technical skills to explore the data from multiple, highdimensional perspectives? In this paper, we use our own tool called Andromeda that enables human-computer interaction with a common, easy to interpret visualization method called Weighted Multidimensional Scaling (WMDS) to promote the idea of making complex insights. We present Andromeda and report findings from a series of classroom assignments to 18 graduate students. These assignments progress from spreadsheet manipulations to statistical software such as R and finally to the use of Andromeda. In parallel with the assignments, we saw students' cognitive dimensionality (CD) begin low and improve.},
	number = {3},
	journal = {J. Comput. Sci. Coll.},
	author = {Zeitz, Jessica and Self, Nathan and House, Leanna and Evia, Jane Robertson and Leman, Scotland and North, Chris},
	month = jan,
	year = {2018},
	note = {Place: Evansville, IN, USA
Publisher: Consortium for Computing Sciences in Colleges},
	pages = {115--125},
}

@article{wenskovitch_towards_2018,
	title = {Towards a {Systematic} {Combination} of {Dimension} {Reduction} and {Clustering} in {Visual} {Analytics}},
	volume = {24},
	doi = {10.1109/TVCG.2017.2745258},
	number = {1},
	journal = {IEEE Transactions on Visualization and Computer Graphics},
	author = {Wenskovitch, John and Crandell, Ian and Ramakrishnan, Naren and House, Leanna and Leman, Scotland and North, Chris},
	year = {2018},
	pages = {131--141},
}

@inproceedings{chen_be_2016,
	title = {Be the data: {A} new approach for lmmersive analytics},
	doi = {10.1109/IMMERSIVE.2016.7932380},
	booktitle = {2016 {Workshop} on {Immersive} {Analytics} ({IA})},
	author = {Chen, Xin and Self, Jessica Zeitz and House, Leanna and North, Chris},
	year = {2016},
	pages = {32--37},
}

@inproceedings{bradel_multi-model_2014,
	title = {Multi-model semantic interaction for text analytics},
	doi = {10.1109/VAST.2014.7042492},
	booktitle = {2014 {IEEE} {Conference} on {Visual} {Analytics} {Science} and {Technology} ({VAST})},
	author = {Bradel, Lauren and North, Chris and House, Leanna and Leman, Scotland},
	year = {2014},
	pages = {163--172},
}

@article{ogunseiju_sensing_2021,
	title = {Sensing {Technologies} in {Construction} {Engineering} and {Management} {Programs}: {A} {Comparison} of {Industry} {Expectations} and {Faculty} {Perceptions}},
	url = {https://par.nsf.gov/biblio/10232747},
	journal = {Proceedings of 57th Associated Schools of Construction Conference},
	author = {Ogunseiju, Omobolanle and Akanmu, Abiola and Bairaktarova, Diana},
	year = {2021},
}

@article{ogunseiju_holographic_2020,
	title = {Holographic {Learning} {Environment} for {Bridging} the {Technical} {Skill} {Gap} of the {Future} {Smart} {Construction} {Engineering} {Students}},
	url = {https://par.nsf.gov/biblio/10232746},
	journal = {Enabling the Development and Implementation of Digital Twins: Proceedings of the 20th International Conference on Construction Applications of Virtual Reality},
	author = {Ogunseiju, Omobolanle and Akanmu, Abiola and Bairaktarova, Diana},
	editor = {Dawood, Nashwan and Rahimian, Farzad P. and Seyedzadeh, Saleh and Sheikhkhoshkar, Moslem},
	year = {2020},
}

@article{ogunseiju_mixed_2022,
	title = {Mixed {Reality} {Environment} for {Learning} {Sensing} {Technology} {Applications} in {Construction}: {A} {Usability} {Study}},
	journal = {To appear in Advanced Engineering Informatics.},
	author = {Ogunseiju, Omobolanle O and Akanmu, Abiola A and Bairaktarova, Diana and Bowman, Doug A. and Jazizadeh, F},
	year = {2022},
}

@article{ogunseiju_mixed_2021,
	title = {Mixed reality based environment for learning sensing technology applications in construction},
	volume = {26},
	number = {46},
	journal = {Journal of Information Technology in Construction (ITcon)},
	author = {Ogunseiju, Omobolanle O and Akanmu, Abiola A and Bairaktarova, Diana},
	year = {2021},
	pages = {863--885},
}

@inproceedings{kelly_wear_2016,
	address = {San Jose California USA},
	title = {The {WEAR} {Scale}: {Developing} a {Measure} of the {Social} {Acceptability} of a {Wearable} {Device}},
	isbn = {978-1-4503-4082-3},
	shorttitle = {The {WEAR} {Scale}},
	url = {https://dl.acm.org/doi/10.1145/2851581.2892331},
	doi = {10.1145/2851581.2892331},
	abstract = {The factors affecting the social acceptability of wearable devices are not well understood, yet they have a strong influence on whether a new wearable succeeds or fails. Factors uniquely affecting wearable acceptability as compared to other technology include manners, moral codes, the symbolic communication of dress, habits of dress, fashion, context of use, form, and aesthetics.},
	language = {en},
	urldate = {2022-05-20},
	booktitle = {Proceedings of the 2016 {CHI} {Conference} {Extended} {Abstracts} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {ACM},
	author = {Kelly, Norene and Gilbert, Stephen},
	month = may,
	year = {2016},
	pages = {2864--2871},
}

@inproceedings{zhou_-depth_2022,
	address = {New Orleans LA USA},
	title = {In-{Depth} {Mouse}: {Integrating} {Desktop} {Mouse} into {Virtual} {Reality}},
	isbn = {978-1-4503-9157-3},
	shorttitle = {In-{Depth} {Mouse}},
	url = {https://dl.acm.org/doi/10.1145/3491102.3501884},
	doi = {10.1145/3491102.3501884},
	language = {en},
	urldate = {2022-05-03},
	booktitle = {{CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {ACM},
	author = {Zhou, Qian and Fitzmaurice, George and Anderson, Fraser},
	month = apr,
	year = {2022},
	pages = {1--17},
}

@misc{lenovo_thinkreality_2022,
	title = {{ThinkReality} {A3} {Smart} {Glasses}},
	url = {https://www.lenovo.com/us/en/thinkrealitya3/},
	publisher = {Lenovo},
	author = {Lenovo},
	year = {2022},
}

@misc{microsoft_research_mt_2022,
	title = {Mt. {Rogers}: {Head}-worn virtual displays - {Microsoft} {Research}},
	url = {https://www.microsoft.com/en-us/research/project/mt-rogers-head-worn-virtual-displays/},
	publisher = {Microsoft},
	author = {Microsoft Research},
	year = {2022},
}

@misc{engadget_facebooks_2022,
	title = {Facebook's {Infinite} {Office} is a virtual office space for the {WFH} crowd},
	url = {https://www.engadget.com/facebook-infinite-office-181634992.html},
	publisher = {Engadget},
	author = {Engadget},
	year = {2022},
}

@article{kirshenbaum_traces_2021,
	title = {Traces of {Time} through {Space}: {Advantages} of {Creating} {Complex} {Canvases} in {Collaborative} {Meetings}},
	volume = {5},
	url = {https://doi.org/10.1145/3488552},
	doi = {10.1145/3488552},
	abstract = {Technology have long been a partner of workplace meeting facilitation. The recent outbreak of COVID-19 and the cautionary measures to reduce its spread have made it more prevalent than ever before in the form of online-meetings. In this paper, we recount our experiences during weekly meetings in three modalities: using SAGE2 - a collaborative sharing software designed for large displays - for co-located meetings, using a conventional projector for co-located meetings, and using the Zoom video-conferencing tool for distributed meetings. We view these meetings through the lens of effective meeting attributes and share ethnographic observations and attitudinal survey conducted in our research lab. We discuss patterns of content sharing, either sequential, parallel, or semi-parallel, and the potential advantages of creating complex canvases of content. We see how the SAGE2 tool affords parallel content sharing to create complex canvases, which represent queues of ideas and contributions (past, present, and future) using the space on a large display to suggest the progression of time through the meeting.},
	number = {ISS},
	journal = {Proc. ACM Hum.-Comput. Interact.},
	author = {Kirshenbaum, Nurit and Davidson, Kylie and Harden, Jesse and North, Chris and Kobayashi, Dylan and Theriot, Ryan and Tabalba, Roderick S. and Rogers, Michael L. and Belcaid, Mahdi and Burks, Andrew T. and Bharadwaj, Krishna N. and Renambot, Luc and Johnson, Andrew E. and Long, Lance and Leigh, Jason},
	month = nov,
	year = {2021},
	note = {Place: New York, NY, USA
Publisher: Association for Computing Machinery},
	keywords = {collaboration, content sharing, large displays, sage2, technology mediated meeting, video-conferencing},
}

@article{pavanatto_usability_2022,
	title = {Usability {Considerations} for {High} {Readability} {Virtual} {Monitors}},
	copyright = {All rights reserved},
	journal = {In review},
	author = {Pavanatto, Leonardo and Davari, Shakiba and Bowman, Doug and Badea, Carmen and Stoakley, Richard},
	year = {2022},
}

@inproceedings{davari_occlusion_2020,
	title = {Occlusion {Management} {Techniques} for {Everyday} {Glanceable} {AR} {Interfaces}},
	doi = {10.1109/VRW50115.2020.00072},
	booktitle = {2020 {IEEE} {Conference} on {Virtual} {Reality} and {3D} {User} {Interfaces} {Abstracts} and {Workshops} ({VRW})},
	author = {Davari, Shakiba and Lu, Feiyu and Bowman, Doug A.},
	year = {2020},
	pages = {324--330},
}

@inproceedings{dittrich_legibility_2013,
	address = {Berlin, Heidelberg},
	title = {Legibility of {Letters} in {Reality}, {2D} and {3D} {Projection}},
	isbn = {978-3-642-39405-8},
	abstract = {Virtual prototypes are essential for engineers to understand the complex structures and arrangements of mechatronic products like automobiles. Currently, Virtual Environments (VE) are used for visual analysis and interaction with virtual models. In the next years more supplementary information will be integrated in the VE, completing the 3D-model. This includes names of single parts, corresponding materials or masses. However, up till now there is little explicit research on the psychological effects of additional text visualization in VE's. For example it unclear if it is possible to visualize the textual information like on paper prints or on 2D displays. The current study empirically compares these types of different output mediums to advise rules for visualization of text in 3D Virtual Environments. Results show, that textual information has to be slightly enlarged for the 3D Virtual Environment. In addition, subjects performed better in conditions with projected textual information compared to real text.},
	booktitle = {Virtual {Augmented} and {Mixed} {Reality}. {Designing} and {Developing} {Augmented} and {Virtual} {Environments}},
	publisher = {Springer Berlin Heidelberg},
	author = {Dittrich, Elisabeth and Brandenburg, Stefan and Beckmann-Dobrev, Boris},
	editor = {Shumaker, Randall},
	year = {2013},
	pages = {149--158},
}

@article{gabbard_effects_2006,
	title = {The {Effects} of {Text} {Drawing} {Styles}, {Background} {Textures}, and {Natural} {Lighting} on {Text} {Legibility} in {Outdoor} {Augmented} {Reality}},
	volume = {15},
	doi = {10.1162/pres.2006.15.1.16},
	number = {1},
	journal = {Presence},
	author = {Gabbard, Joseph L. and Swan, J. Edward and Hix, Deborah},
	year = {2006},
	pages = {16--32},
}

@inproceedings{grout_reading_2015,
	address = {New York, NY, USA},
	series = {{CHINZ} 2015},
	title = {Reading {Text} in an {Immersive} {Head}-{Mounted} {Display}: {An} {Investigation} into {Displaying} {Desktop} {Interfaces} in a {3D} {Virtual} {Environment}},
	isbn = {978-1-4503-3670-3},
	url = {https://doi-org.ezproxy.lib.vt.edu/10.1145/2808047.2808055},
	doi = {10.1145/2808047.2808055},
	abstract = {This paper describes an experiment conducted as part of a larger project investigating the possibilities of using a virtual environment for users performing day-to-day computing tasks. The experiment is a user study analyzing the performance of reading tasks typical of a general purpose computing environment conducted in immersive virtual reality headsets. Results of this study are evaluated, and suggest that reading tasks can be performed with near equivalent performance in the virtual environment when compared to performance values obtained from baseline tasks on a traditional display.},
	booktitle = {Proceedings of the 15th {New} {Zealand} {Conference} on {Human}-{Computer} {Interaction}},
	publisher = {Association for Computing Machinery},
	author = {Grout, Cameron and Rogers, William and Apperley, Mark and Jones, Steve},
	year = {2015},
	note = {event-place: Hamilton, New Zealand},
	keywords = {Application redirection, Fonts hinting, Readability, Rendering techniques, Virtual reality},
	pages = {9--16},
}

@inproceedings{jankowski_integrating_2010,
	address = {New York, NY, USA},
	series = {{CHI} '10},
	title = {Integrating {Text} with {Video} and {3D} {Graphics}: {The} {Effects} of {Text} {Drawing} {Styles} on {Text} {Readability}},
	isbn = {978-1-60558-929-9},
	url = {https://doi-org.ezproxy.lib.vt.edu/10.1145/1753326.1753524},
	doi = {10.1145/1753326.1753524},
	abstract = {There have been many studies of computer based text reading. However, only a few have considered text integrated with video and 3D graphics. This paper presents an investigation into the effects of varying (a) text drawing style (plain, billboard, Anti-Interference, shadow), (b) image polarity (positive and negative), and (c) background style (video and 3D) on text readability. Reading speed and accuracy were measured and subjective views of participants recorded.Results showed that: (a) there was little difference in reading performance for the video and 3D backgrounds; (b) the negative presentation outperformed the positive presentation; (c) the billboard drawing styles supported the best performance; subjective comments showed a preference for the billboard style. We therefore suggest, for reading tasks, that designers of interfaces for games, video, and augmented reality provide billboard style to maximize readability for the widest range of applications.},
	booktitle = {Proceedings of the {SIGCHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Jankowski, Jacek and Samp, Krystian and Irzynska, Izabela and Jozwowicz, Marek and Decker, Stefan},
	year = {2010},
	note = {event-place: Atlanta, Georgia, USA},
	keywords = {3d graphics, aesthetics, augmented reality, image polarity, legibility, readability, text drawing styles},
	pages = {1321--1330},
}

@article{ofek_towards_2020,
	title = {Towards a practical virtual office for mobile knowledge workers},
	journal = {arXiv preprint arXiv:2009.02947},
	author = {Ofek, Eyal and Grubert, Jens and Pahud, Michel and Phillips, Mark and Kristensson, Per Ola},
	year = {2020},
}

@inproceedings{kojic_user_2020,
	title = {User experience of reading in virtual reality—finding values for text distance, size and contrast},
	booktitle = {2020 {Twelfth} {International} {Conference} on {Quality} of {Multimedia} {Experience} ({QoMEX})},
	publisher = {IEEE},
	author = {Kojić, Tanja and Ali, Danish and Greinacher, Robert and Möller, Sebastian and Voigt-Antons, Jan-Niklas},
	year = {2020},
	keywords = {3},
	pages = {1--6},
}

@inproceedings{wei_reading_2020,
	title = {Reading on {3D} surfaces in virtual environments},
	booktitle = {2020 {IEEE} {Conference} on {Virtual} {Reality} and {3D} {User} {Interfaces} ({VR})},
	publisher = {IEEE},
	author = {Wei, Chunxue and Yu, Difeng and Dingler, Tilman},
	year = {2020},
	keywords = {5},
	pages = {721--728},
}

@inproceedings{dingler_vr_2018,
	title = {Vr reading uis: {Assessing} text parameters for reading in vr},
	booktitle = {Extended {Abstracts} of the 2018 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	author = {Dingler, Tilman and Kunze, Kai and Outram, Benjamin},
	year = {2018},
	keywords = {3},
	pages = {1--6},
}

@inproceedings{obrien_wikipedia_2019,
	title = {Wikipedia in {Virtual} {Reality} and {HowText}-based {Media} can be {Explore} in {Virtual} {Reality}},
	booktitle = {Proceedings of the 2019 {International} {Conference} on {Artificial} {Intelligence} and {Advanced} {Manufacturing}},
	author = {O'Brien, Eoin and Jacquouton, Baptiste and Moineau, Antoine and Campbell, Abraham G},
	year = {2019},
	keywords = {2},
	pages = {1--9},
}

@inproceedings{tan_similar_2003,
	address = {New York, NY, USA},
	series = {{CHI} '03},
	title = {With {Similar} {Visual} {Angles}, {Larger} {Displays} {Improve} {Spatial} {Performance}},
	isbn = {1-58113-630-7},
	url = {https://doi.org/10.1145/642611.642650},
	doi = {10.1145/642611.642650},
	booktitle = {Proceedings of the {SIGCHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Tan, Desney S. and Gergle, Darren and Scupelli, Peter and Pausch, Randy},
	year = {2003},
	note = {event-place: Ft. Lauderdale, Florida, USA},
	keywords = {field of view, immersion, large display, presence, spatial task, visual angle},
	pages = {217--224},
}

@article{jeuris_hidden_2018,
	title = {The {Hidden} {Cost} of {Window} {Management}},
	url = {http://arxiv.org/abs/1810.04673},
	abstract = {Most window management systems support multitasking by allowing users to open, resize, position, and switch between application windows. Although multitasking has become a way of life for most knowledge workers, our current understanding of how users use window management features to switch between multiple tasks---which may comprise multiple application windows---is limited. In this paper, we present a study providing an in-depth analysis of how task switching is supported in Windows 7. As part of analysis, we developed an interface-agnostic classification of common task switching operations supported by window managers which can be used to quantify the time spent on each constituting action. Our study shows that task switching is a time intensive activity and highlights the dominant actions that contribute to task switch time. Furthermore, our classification highlights the specific operations that are optimized by more recent and experimental window managers and allows identifying opportunities for design that could further reduce the overhead of switching between tasks.},
	language = {en},
	urldate = {2022-02-10},
	journal = {arXiv:1810.04673 [cs]},
	author = {Jeuris, Steven and Tell, Paolo and Houben, Steven and Bardram, Jakob E.},
	month = oct,
	year = {2018},
	note = {arXiv: 1810.04673},
	keywords = {Computer Science - Human-Computer Interaction, H.5.2},
}

@inproceedings{waldner_display-adaptive_2011,
	address = {Kobe, Japan},
	title = {Display-adaptive window management for irregular surfaces},
	isbn = {978-1-4503-0871-7},
	url = {http://dl.acm.org/citation.cfm?doid=2076354.2076394},
	doi = {10.1145/2076354.2076394},
	abstract = {Current projectors can easily be combined to create an everywhere display, using all suitable surfaces in ofﬁces or meeting rooms for the presentation of information. However, the resulting irregular display is not well supported by traditional desktop window managers, which are optimized for rectangular screens. In this paper, we present novel displayadaptive window management techniques, which provide semi-automatic placement for desktop elements (such as windows or icons) for users of large, irregularly shaped displays. We report results from an exploratory study, which reveals interesting emerging strategies of users in the manipulation of windows on large irregular displays and shows that the new techniques increase subjective satisfaction with the window management interface.},
	language = {en},
	urldate = {2022-02-10},
	booktitle = {Proceedings of the {ACM} {International} {Conference} on {Interactive} {Tabletops} and {Surfaces} - {ITS} '11},
	publisher = {ACM Press},
	author = {Waldner, Manuela and Grasset, Raphael and Steinberger, Markus and Schmalstieg, Dieter},
	year = {2011},
	pages = {222},
}

@article{jeuris_dedicated_2016,
	title = {Dedicated workspaces: {Faster} resumption times and reduced cognitive load in sequential multitasking},
	volume = {62},
	issn = {07475632},
	shorttitle = {Dedicated workspaces},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0747563216302308},
	doi = {10.1016/j.chb.2016.03.059},
	abstract = {Studies show that virtual desktops have become a widespread approach to window management within desktop environments. However, despite their success, there is no experimental evidence of their eﬀect on multitasking. In this paper, we present an experimental study incorporating 16 participants in which a traditional Windows 7 environment is compared to one augmented by virtual desktops. Within the experimental condition, each virtual desktop acts as a dedicated workspace devoted to an independent goal-oriented task, as opposed to the control condition where only one single workspace is available to perform the same tasks. Results show that adopting virtual desktops as dedicated workspaces allows for faster task resumption (10s faster on average) and reduced cognitive load during sequential multitasking. Within our experiment the majority of users already beneﬁted from using dedicated workspaces after three switches to a previously suspended task, as the time lost on setting up workspaces was compensated for by faster subsequent task resumption. These results provide a strong argument for supporting goal-oriented dedicated workspaces within desktop environments.},
	language = {en},
	urldate = {2022-02-10},
	journal = {Computers in Human Behavior},
	author = {Jeuris, Steven and Bardram, Jakob E.},
	month = sep,
	year = {2016},
	pages = {404--414},
}

@inproceedings{guo_mixed_2019,
	title = {Mixed {Reality} {Office} {System} {Based} on {Maslow}’s {Hierarchy} of {Needs}: {Towards} the {Long}-{Term} {Immersion} in {Virtual} {Environments}},
	doi = {10.1109/ISMAR.2019.00019},
	booktitle = {2019 {IEEE} {International} {Symposium} on {Mixed} and {Augmented} {Reality} ({ISMAR})},
	author = {Guo, J. and Weng, D. and Zhang, Z. and Jiang, H. and Liu, Y. and Wang, Y. and Duh, H. B.},
	year = {2019},
	pages = {224--235},
}

@article{andrews_information_2011,
	title = {Information visualization on large, high-resolution displays: {Issues}, challenges, and opportunities},
	volume = {10},
	url = {https://doi.org/10.1177/1473871611415997},
	doi = {10.1177/1473871611415997},
	number = {4},
	journal = {Information Visualization},
	author = {Andrews, Christopher and Endert, Alex and Yost, Beth and North, Chris},
	year = {2011},
	pages = {341--355},
}

@inproceedings{bi_comparing_2009,
	address = {New York, NY, USA},
	series = {{CHI} ’09},
	title = {Comparing {Usage} of a {Large} {High}-{Resolution} {Display} to {Single} or {Dual} {Desktop} {Displays} for {Daily} {Work}},
	isbn = {978-1-60558-246-7},
	url = {https://doi.org/10.1145/1518701.1518855},
	doi = {10.1145/1518701.1518855},
	booktitle = {Proceedings of the {SIGCHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Bi, Xiaojun and Balakrishnan, Ravin},
	year = {2009},
	note = {event-place: Boston, MA, USA},
	keywords = {large display, personal desktop work},
	pages = {1005--1014},
}

@article{biener_breaking_2020,
	title = {Breaking the {Screen}: {Interaction} {Across} {Touchscreen} {Boundaries} in {Virtual} {Reality} for {Mobile} {Knowledge} {Workers}},
	doi = {10.1109/TVCG.2020.3023567},
	journal = {IEEE Transactions on Visualization and Computer Graphics},
	author = {Biener, V. and Schneider, D. and Gesslein, T. and Otte, A. and Kuth, B. and Kristensson, P. O. and Ofek, E. and Pahud, M. and Grubert, J.},
	year = {2020},
	pages = {1--1},
}

@article{rau_speed_2018,
	title = {Speed reading on virtual reality and augmented reality},
	volume = {125},
	journal = {Computers \& Education},
	author = {Rau, Pei-Luen Patrick and Zheng, Jian and Guo, Zhi and Li, Jiaqi},
	year = {2018},
	note = {Publisher: Elsevier},
	pages = {240--245},
}

@inproceedings{falk_legibility_2021,
	title = {Legibility and readability in {Augmented} {Reality}},
	booktitle = {2021 13th {International} {Conference} on {Quality} of {Multimedia} {Experience} ({QoMEX})},
	publisher = {IEEE},
	author = {Falk, Julia and Eksvärd, Siri and Schenkman, Bo and Andrén, Börje and Brunnström, Kjell},
	year = {2021},
	pages = {231--236},
}

@article{sawyer_glanceable_2020,
	title = {Glanceable, legible typography over complex backgrounds},
	volume = {63},
	number = {7},
	journal = {Ergonomics},
	author = {Sawyer, Ben D and Wolfe, Benjamin and Dobres, Jonathan and Chahine, Nadine and Mehler, Bruce and Reimer, Bryan},
	year = {2020},
	note = {Publisher: Taylor \& Francis},
	pages = {864--883},
}

@inproceedings{kruijff_perceptual_2010,
	title = {Perceptual issues in augmented reality revisited},
	booktitle = {2010 {IEEE} {International} {Symposium} on {Mixed} and {Augmented} {Reality}},
	publisher = {IEEE},
	author = {Kruijff, Ernst and Swan, J Edward and Feiner, Steven},
	year = {2010},
	pages = {3--12},
}

@inproceedings{kang_lightweight_2008,
	title = {Lightweight task/application performance using single versus multiple monitors: a comparative study},
	booktitle = {Proceedings of graphics interface 2008},
	author = {Kang, Youn-ah and Stasko, John},
	year = {2008},
	pages = {17--24},
}

@inproceedings{rzayev_reading_2021,
	title = {Reading in {VR}: {The} {Effect} of {Text} {Presentation} {Type} and {Location}},
	booktitle = {Proceedings of the 2021 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	author = {Rzayev, Rufat and Ugnivenko, Polina and Graf, Sarah and Schwind, Valentin and Henze, Niels},
	year = {2021},
	pages = {1--10},
}

@inproceedings{grossman_exploring_2007,
	title = {Exploring and reducing the effects of orientation on text readability in volumetric displays},
	booktitle = {Proceedings of the {SIGCHI} conference on {Human} factors in computing systems},
	author = {Grossman, Tovi and Wigdor, Daniel and Balakrishnan, Ravin},
	year = {2007},
	pages = {483--492},
}

@article{gattullo_effect_2014,
	title = {Effect of text outline and contrast polarity on {AR} text readability in industrial lighting},
	volume = {21},
	number = {5},
	journal = {IEEE transactions on visualization and computer graphics},
	author = {Gattullo, Michele and Uva, Antonio Emmanuele and Fiorentino, Michele and Monno, Giuseppe},
	year = {2014},
	note = {Publisher: IEEE},
	pages = {638--651},
}

@article{erickson_extended_2021,
	title = {An extended analysis on the benefits of dark mode user interfaces in optical see-through head-mounted displays},
	volume = {18},
	number = {3},
	journal = {ACM Transactions on Applied Perception (TAP)},
	author = {Erickson, Austin and Kim, Kangsoo and Lambert, Alexis and Bruder, Gerd and Browne, Michael P and Welch, Gregory F},
	year = {2021},
	note = {Publisher: ACM New York, NY, USA},
	pages = {1--22},
}

@inproceedings{klose_text_2019,
	title = {Text presentation for augmented reality applications in dual-task situations},
	booktitle = {2019 {IEEE} {Conference} on {Virtual} {Reality} and {3D} {User} {Interfaces} ({VR})},
	publisher = {IEEE},
	author = {Klose, Elisa Maria and Mack, Nils Adrian and Hegenberg, Jens and Schmidt, Ludger},
	year = {2019},
	pages = {636--644},
}

@inproceedings{ens_personal_2014,
	title = {The personal cockpit: a spatial interface for effective task switching on head-worn displays},
	booktitle = {Proceedings of the {SIGCHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	author = {Ens, Barrett M and Finnegan, Rory and Irani, Pourang P},
	year = {2014},
	pages = {3171--3180},
}

@article{knierim_nomadic_2021,
	title = {The {Nomadic} {Office}: {A} {Location} {Independent} {Workspace} {Through} {Mixed} {Reality}},
	volume = {20},
	number = {4},
	journal = {IEEE Pervasive Computing},
	author = {Knierim, Pascal and Kosch, Thomas and Schmidt, Albrecht},
	year = {2021},
	note = {Publisher: IEEE},
	pages = {71--78},
}

@inproceedings{kobayashi_translating_2021,
	title = {Translating {The} {Benefits} {Of} {Wide}-band {Display} {Environments} {Into} {An} {XR} {Space}},
	booktitle = {Symposium on {Spatial} {User} {Interaction}},
	author = {Kobayashi, Dylan and Kirshenbaum, Nurit and Tabalba, Roderick S and Theriot, Ryan and Leigh, Jason},
	year = {2021},
	pages = {1--11},
}

@inproceedings{buttner_influence_2020,
	title = {The influence of text rotation, font and distance on legibility in {VR}},
	booktitle = {2020 {IEEE} {Conference} on {Virtual} {Reality} and {3D} {User} {Interfaces} {Abstracts} and {Workshops} ({VRW})},
	publisher = {IEEE},
	author = {Büttner, Andre and Grünvogel, Stefan M and Fuhrmann, Arnulph},
	year = {2020},
	pages = {662--663},
}

@incollection{knaack_improving_2019,
	title = {Improving {Readability} of {Text} in {Realistic} {Virtual} {Reality} {Scenarios}: {Visual} {Magnification} {Without} {Restricting} {User} {Interactions}},
	booktitle = {Proceedings of {Mensch} und {Computer} 2019},
	author = {Knaack, Lars and Lache, Ann-Karolin and Preikszas, Oliver and Reinhold, Sascha and Teistler, Michael},
	year = {2019},
	pages = {749--753},
}

@inproceedings{lee_projective_2018,
	title = {Projective windows: bringing windows in space to the fingertip},
	booktitle = {Proceedings of the 2018 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	author = {Lee, Joon Hyub and An, Sang-Gyun and Kim, Yongkwan and Bae, Seok-Hyung},
	year = {2018},
	pages = {1--8},
}

@inproceedings{fender_heatspace_2017,
	title = {Heatspace: {Automatic} placement of displays by empirical analysis of user behavior},
	booktitle = {Proceedings of the 30th {Annual} {ACM} {Symposium} on {User} {Interface} {Software} and {Technology}},
	author = {Fender, Andreas and Lindlbauer, David and Herholz, Philipp and Alexa, Marc and Müller, Jörg},
	year = {2017},
	pages = {611--621},
}

@article{gallagher_does_2021,
	title = {Does using multiple computer monitors for office tasks affect user experience? a systematic review},
	volume = {63},
	number = {3},
	journal = {Human Factors},
	author = {Gallagher, Kaitlin M and Cameron, Laura and De Carvalho, Diana and Boulé, Madison},
	year = {2021},
	note = {Publisher: SAGE Publications Sage CA: Los Angeles, CA},
	pages = {433--449},
}

@inproceedings{shen_mental_2019,
	title = {Mental fatigue of long-term office tasks in virtual environment},
	booktitle = {2019 {IEEE} {International} {Symposium} on {Mixed} and {Augmented} {Reality} {Adjunct} ({ISMAR}-{Adjunct})},
	publisher = {IEEE},
	author = {Shen, Ruiying and Weng, Dongdong and Chen, Shanshan and Guo, Jie and Fang, Hui},
	year = {2019},
	pages = {124--127},
}

@misc{meade_seeing_2015,
	title = {Seeing the {Big} {Picture}: {A} {Digital} {Desktop} for {Researchers}},
	publisher = {THETA},
	author = {Meade, Bernard and Fluke, Christopher and Sinnott, Richard and Manos, Steven and Killeen, Neil and Mignone, Paul and Wang, Michael},
	year = {2015},
}

@article{beier_smaller_2019,
	title = {Smaller visual angles show greater benefit of letter boldness than larger visual angles},
	volume = {199},
	journal = {Acta psychologica},
	author = {Beier, Sofie and Oderkerk, Chiron AT},
	year = {2019},
	note = {Publisher: Elsevier},
	pages = {102904},
}

@article{gabbard_usability_2008,
	title = {Usability engineering for augmented reality: {Employing} user-based studies to inform design},
	volume = {14},
	number = {3},
	journal = {IEEE Transactions on visualization and computer graphics},
	author = {Gabbard, Joe L and Swan II, J Edward},
	year = {2008},
	note = {Publisher: IEEE},
	pages = {513--525},
}

@article{satriadi_maps_2020,
	title = {Maps around me: {3D} multiview layouts in immersive spaces},
	volume = {4},
	number = {ISS},
	journal = {Proceedings of the ACM on Human-Computer Interaction},
	author = {Satriadi, Kadek Ananta and Ens, Barrett and Cordeil, Maxime and Czauderna, Tobias and Jenny, Bernhard},
	year = {2020},
	note = {Publisher: ACM New York, NY, USA},
	pages = {1--20},
}

@article{klinke_analysis_2014,
	title = {Analysis of the influence of screen size and resolution on work efficiency},
	author = {Klinke, Hermann and Krieger, Christoph and Pickl, Sebastian},
	year = {2014},
}

@inproceedings{le_vxslate_2021,
	title = {{VXSlate}: {Exploring} combination of head movements and mobile touch for large virtual display interaction},
	booktitle = {Designing {Interactive} {Systems} {Conference} 2021},
	author = {Le, Khanh-Duy and Tran, Tanh Quang and Chlasta, Karol and Krejtz, Krzysztof and Fjeld, Morten and Kunz, Andreas},
	year = {2021},
	pages = {283--297},
}

@article{debernardis_text_2013,
	title = {Text readability in head-worn displays: {Color} and style optimization in video versus optical see-through devices},
	volume = {20},
	number = {1},
	journal = {IEEE transactions on visualization and computer graphics},
	author = {Debernardis, Saverio and Fiorentino, Michele and Gattullo, Michele and Monno, Giuseppe and Uva, Antonio Emmanuele},
	year = {2013},
	note = {Publisher: IEEE},
	pages = {125--139},
}

@article{fiorentino_augmented_2013,
	title = {Augmented reality text style readability with see-through head-mounted displays in industrial context},
	volume = {22},
	number = {2},
	journal = {Presence: Teleoperators and Virtual Environments},
	author = {Fiorentino, Michele and Debernardis, Saverio and Uva, Antonio E and Monno, Giuseppe},
	year = {2013},
	note = {Publisher: MIT Press One Rogers Street, Cambridge, MA 02142-1209, USA journals-info …},
	pages = {171--190},
}

@inproceedings{pavanatto_designing_2021,
	title = {Designing {Augmented} {Reality} {Virtual} {Displays} for {Productivity} {Work}},
	copyright = {All rights reserved},
	doi = {10.1109/ISMAR-Adjunct54149.2021.00107},
	booktitle = {2021 {IEEE} {International} {Symposium} on {Mixed} and {Augmented} {Reality} {Adjunct} ({ISMAR}-{Adjunct})},
	author = {Pavanatto, Leonardo},
	year = {2021},
	pages = {459--460},
}

@article{slater_simulating_2010,
	title = {Simulating {Virtual} {Environments} within {Virtual} {Environments} as the {Basis} for a {Psychophysics} of {Presence}},
	volume = {29},
	issn = {0730-0301},
	url = {https://doi.org/10.1145/1778765.1778829},
	doi = {10.1145/1778765.1778829},
	abstract = {A new definition of immersion with respect to virtual environment (VE) systems has been proposed in earlier work, based on the concept of simulation. One system (A) is said to be more immersive than another (B) if A can be used to simulate an application as if it were running on B. Here we show how this concept can be used as the basis for a psychophysics of presence in VEs, the sensation of being in the place depicted by the virtual environment displays (Place Illusion, PI), and also the illusion that events occurring in the virtual environment are real (Plausibility Illusion, Psi). The new methodology involves matching experiments akin to those in color science. Twenty participants first experienced PI or Psi in the initial highest level immersive system, and then in 5 different trials chose transitions from lower to higher order systems and declared a match whenever they felt the same level of PI or Psi as they had in the initial system. In each transition they could change the type of illumination model used, or the field-of-view, or the display type (powerwall or HMD) or the extent of self-representation by an avatar. The results showed that the 10 participants instructed to choose transitions to attain a level of PI corresponding to that in the initial system tended to first choose a wide field-of-view and head-mounted display, and then ensure that they had a virtual body that moved as they did. The other 10 in the Psi group concentrated far more on achieving a higher level of illumination realism, although having a virtual body representation was important for both groups. This methodology is offered as a way forward in the evaluation of the responses of people to immersive virtual environments, a unified theory and methodology for psychophysical measurement.},
	number = {4},
	journal = {ACM Trans. Graph.},
	author = {Slater, Mel and Spanlang, Bernhard and Corominas, David},
	month = jul,
	year = {2010},
	note = {Place: New York, NY, USA
Publisher: Association for Computing Machinery},
	keywords = {Markov chain, immersive virtual environments, place illusion, plausibility, presence, response function},
}

@inproceedings{ng_passenger_2021,
	title = {The {Passenger} {Experience} of {Mixed} {Reality} {Virtual} {Display} {Layouts} in {Airplane} {Environments}},
	doi = {10.1109/ISMAR52148.2021.00042},
	booktitle = {2021 {IEEE} {International} {Symposium} on {Mixed} and {Augmented} {Reality} ({ISMAR})},
	author = {Ng, Alexander and Medeiros, Daniel and McGill, Mark and Williamson, Julie and Brewster, Stephen},
	year = {2021},
	pages = {265--274},
}

@inproceedings{grudin_partitioning_2001,
	address = {New York, NY, USA},
	series = {{CHI} '01},
	title = {Partitioning {Digital} {Worlds}: {Focal} and {Peripheral} {Awareness} in {Multiple} {Monitor} {Use}},
	isbn = {1-58113-327-8},
	url = {https://doi-org.ezproxy.lib.vt.edu/10.1145/365024.365312},
	doi = {10.1145/365024.365312},
	abstract = {Software today does not help us partition our digital worlds effectively. We must organize them ourselves. This field study of users of multiple monitors examines how people with a lot of display space arrange information. Second monitors are generally used for secondary activities related to principal tasks, for peripheral awareness of information that is not the main focus, and for easy access to resources. A second monitor improves efficiency in ways that are difficult to measure yet can have substantial subjective benefit. The study concludes with illustrations of shortcomings of today's systems and applications: the way we work could be improved at relatively low cost.},
	booktitle = {Proceedings of the {SIGCHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Grudin, Jonathan},
	year = {2001},
	note = {event-place: Seattle, Washington, USA},
	keywords = {awareness, displays, multiple monitors},
	pages = {458--465},
}

@inproceedings{jetter_vr_2020,
	address = {New York, NY, USA},
	title = {"{In} {VR}, {Everything} is {Possible}!": {Sketching} and {Simulating} {Spatially}-{Aware} {Interactive} {Spaces} in {Virtual} {Reality}},
	isbn = {978-1-4503-6708-0},
	url = {https://doi.org/10.1145/3313831.3376652},
	abstract = {We propose using virtual reality (VR) as a design tool for sketching and simulating spatially-aware interactive spaces. Using VR, designers can quickly experience their envisioned spaces and interactions by simulating technologies such as motion tracking, multiple networked devices, or unusual form factors such as spherical touchscreens or bezel-less display tiles. Design ideas can be rapidly iterated without restrictions by the number, size, or shape and availability of devices or sensors in the lab. To understand the potentials and challenges of designing in VR, we conducted a user study with 12 interaction designers. As their tool, they used a custom-built virtual design environment with finger tracking and physics simulations for natural interactions with virtual devices and objects. Our study identified the designers' experience of space in relation to their own bodies and playful design explorations as key opportunities. Key challenges were the complexities of building a usable yet versatile VR-based "World Editor".},
	booktitle = {Proceedings of the 2020 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Jetter, Hans-Christian and Rädle, Roman and Feuchtner, Tiare and Anthes, Christoph and Friedl, Judith and Klokmose, Clemens Nylandsted},
	year = {2020},
	pages = {1--16},
}

@inproceedings{cetin_visual_2018,
	title = {Visual {Analytics} on {Large} {Displays}: {Exploring} {User} {Spatialization} and {How} {Size} and {Resolution} {Affect} {Task} {Performance}},
	doi = {10.1109/BDVA.2018.8534027},
	booktitle = {2018 {International} {Symposium} on {Big} {Data} {Visual} and {Immersive} {Analytics} ({BDVA})},
	author = {Cetin, G. and Stuerzlinger, W. and Dill, J.},
	year = {2018},
	pages = {1--10},
}

@inproceedings{ballendat_proxemic_2010,
	address = {New York, NY, USA},
	series = {{ITS} '10},
	title = {Proxemic {Interaction}: {Designing} for a {Proximity} and {Orientation}-{Aware} {Environment}},
	isbn = {978-1-4503-0399-6},
	url = {https://doi.org/10.1145/1936652.1936676},
	doi = {10.1145/1936652.1936676},
	abstract = {In the everyday world, much of what we do is dictated by how we interpret spatial relationships, or proxemics. What is surprising is how little proxemics are used to mediate people's interactions with surrounding digital devices. We imagine proxemic interaction as devices with fine-grained knowledge of nearby people and other devices – their position, identity, movement, and orientation – and how such knowledge can be exploited to design interaction techniques. In particular, we show how proxemics can: regulate implicit and explicit interaction; trigger such interactions by continuous movement or by movement of people and devices in and out of discrete proxemic regions; mediate simultaneous interaction of multiple people; and interpret and exploit people's directed attention to other people and objects. We illustrate these concepts through an interactive media player running on a vertical surface that reacts to the approach, identity, movement and orientation of people and their personal devices.},
	booktitle = {{ACM} {International} {Conference} on {Interactive} {Tabletops} and {Surfaces}},
	publisher = {Association for Computing Machinery},
	author = {Ballendat, Till and Marquardt, Nicolai and Greenberg, Saul},
	year = {2010},
	note = {event-place: Saarbrücken, Germany},
	keywords = {explicit interaction, implicit interaction, location and orientation aware, proxemics, proximity},
	pages = {121--130},
}

@inproceedings{bonada_personalized_2016,
	address = {New York, NY, USA},
	series = {{ISS} '16 {Companion}},
	title = {Personalized {Views} for {Immersive} {Analytics}},
	isbn = {978-1-4503-4530-9},
	url = {https://doi.org/10.1145/3009939.3009953},
	doi = {10.1145/3009939.3009953},
	abstract = {In this paper we present work-in-progress toward a vision of personalized views of visual analytics interfaces in the context of collaborative analytics in immersive spaces. In particular, we are interested in the sense of immersion, responsiveness, and personalization afforded by gaze-based input. Through combining large screen visual analytics tools with eye-tracking, a collaborative visual analytics system can become egocentric while not disrupting the collaborative nature of the experience. We present a prototype system and several ideas for real-time personalization of views in visual analytics.},
	booktitle = {Proceedings of the 2016 {ACM} {Companion} on {Interactive} {Surfaces} and {Spaces}},
	publisher = {Association for Computing Machinery},
	author = {Bonada, Santiago and Veras, Rafael and Collins, Christopher},
	year = {2016},
	note = {event-place: Niagara Falls, Ontario, Canada},
	keywords = {eye tracking, gaze, immersive analytics, proxemics, visual analytics},
	pages = {83--89},
}

@inproceedings{schuchardt_benefits_2007,
	address = {New York, NY, USA},
	series = {{VRST} '07},
	title = {The {Benefits} of {Immersion} for {Spatial} {Understanding} of {Complex} {Underground} {Cave} {Systems}},
	isbn = {978-1-59593-863-3},
	url = {https://doi.org/10.1145/1315184.1315205},
	doi = {10.1145/1315184.1315205},
	abstract = {A common reason for using immersive virtual environments (IVEs) in visualization is the hypothesis that IVEs should provide a higher level of spatial understanding for complex 3D structures, such as those found in underground cave systems. Therefore, we aimed to explore the use of IVEs for visualization of underground caves, and to determine the benefits of immersion for viewing such models. We ran an experiment in which domain experts answered questions with two different levels of immersion. The results show that for certain tasks the more immersive system significantly improved accuracy, speed, and comprehension over the non-immersive environment, and that 3D visualization overall is a good match for the underground cave data.},
	booktitle = {Proceedings of the 2007 {ACM} {Symposium} on {Virtual} {Reality} {Software} and {Technology}},
	publisher = {Association for Computing Machinery},
	author = {Schuchardt, Philip and Bowman, Doug A.},
	year = {2007},
	note = {event-place: Newport Beach, California},
	keywords = {cave, immersion, spatial understanding, visualization},
	pages = {121--124},
}

@inproceedings{kister_bodylenses_2015,
	address = {New York, NY, USA},
	series = {{ITS} '15},
	title = {{BodyLenses}: {Embodied} {Magic} {Lenses} and {Personal} {Territories} for {Wall} {Displays}},
	isbn = {978-1-4503-3899-8},
	url = {https://doi.org/10.1145/2817721.2817726},
	doi = {10.1145/2817721.2817726},
	abstract = {Magic lenses are popular tools to provide locally altered views of visual data. In this paper, we introduce the concept of BodyLenses, special kinds of magic lenses for wall displays that are mainly controlled by body interactions. After motivating the rationale for body-centric lenses, we present a comprehensive design space of BodyLenses, where we analyse fundamental aspects such as appearance, function, interaction and use in multi-user contexts. Within that space, we investigated and implemented a number of design alternatives and propose solutions for lens positioning, dynamic shape modification, distance-based parameter mappings and the use of BodyLenses as portable tool belts. We demonstrate the practicality of our novel concepts with four realised application scenarios. With this work, we hope to lay the foundation for future research and systems based on body-driven lenses.},
	booktitle = {Proceedings of the 2015 {International} {Conference} on {Interactive} {Tabletops} \&amp; {Surfaces}},
	publisher = {Association for Computing Machinery},
	author = {Kister, Ulrike and Reipschläger, Patrick and Matulic, Fabrice and Dachselt, Raimund},
	year = {2015},
	note = {event-place: Madeira, Portugal},
	keywords = {body-centric interaction, co-located collaboration, embodied interaction, magic lenses, proxemic interaction, territoriality},
	pages = {117--126},
}

@inproceedings{russell_social_2002,
	address = {Berlin, Heidelberg},
	title = {Social {Aspects} of {Using} {Large} {Public} {Interactive} {Displays} for {Collaboration}},
	isbn = {978-3-540-45809-8},
	abstract = {Large displays have several natural affordances that can simplify small group collaborative work. They are large enough to hold multiple work areas, they are easy to see and can be manipulated directly via touch. When placed into group and public spaces, such displays create pervasively available working surfaces for lightweight, temporary walkup use. The BlueBoard is a large plasma display with touch sensing and a badge reader to identify individuals using the board. The onboard software acts as a thin client giving access to each participant's web-based content (e.g., home pages, project pages). The client also has a set of tools and mechanisms that support rapid exchange of content between those present. The overall design of the BlueBoard is one that is easily learnable (under 5 minutes), very simple to use, and permits novel uses for collaboration. Our initial field study revealed a number of social issues about the use of a large pervasively available display surface, yet indicates that a shared public display space truly has distinct properties that lend themselves to sharing content. Extreme learnability \& overall simplicity of design makes BlueBoard a tool for collaboration that supports intermittent, but effective use for side-by-side collaboration between colleagues.},
	booktitle = {{UbiComp} 2002: {Ubiquitous} {Computing}},
	publisher = {Springer Berlin Heidelberg},
	author = {Russell, Daniel M. and Drews, Clemens and Sue, Alison},
	editor = {Borriello, Gaetano and Holmquist, Lars Erik},
	year = {2002},
	pages = {229--236},
}

@inproceedings{ryall_exploring_2004,
	address = {New York, NY, USA},
	series = {{CSCW} '04},
	title = {Exploring the {Effects} of {Group} {Size} and {Table} {Size} on {Interactions} with {Tabletop} {Shared}-{Display} {Groupware}},
	isbn = {1-58113-810-5},
	url = {https://doi.org/10.1145/1031607.1031654},
	doi = {10.1145/1031607.1031654},
	abstract = {Interactive tabletops have been previously proposed and studied in the domain of co-located group applications. However, little fundamental research has been done to explore the issue of size. In this paper we identify a number of size considerations for tabletop design, and present an experiment to explore some of these issues, in particular the effects of group size and table size on the speed at which the task was performed, the distribution of work among group members, issues of shared resources, and user preference for table size. Our findings shed light on (1) how work strategies are affected by group size, (2) how social interaction varies with respect to table size, and (3) how the speed of task performance is influenced by group size but not by table size. In addition, our experiments revealed that for larger groups, designers might need to add additional vertical displays for shared information. This finding opens the door for extending single-display groupware to shared-display groupware settings that involve multiple, shared displays.},
	booktitle = {Proceedings of the 2004 {ACM} {Conference} on {Computer} {Supported} {Cooperative} {Work}},
	publisher = {Association for Computing Machinery},
	author = {Ryall, Kathy and Forlines, Clifton and Shen, Chia and Morris, Meredith Ringel},
	year = {2004},
	note = {event-place: Chicago, Illinois, USA},
	keywords = {multi-user interfaces, shared-display groupware, tabletop interfaces},
	pages = {284--293},
}

@inproceedings{peltonen_its_2008,
	address = {New York, NY, USA},
	series = {{CHI} '08},
	title = {It's {Mine}, {Don}'t {Touch}! {Interactions} at a {Large} {Multi}-{Touch} {Display} in a {City} {Centre}},
	isbn = {978-1-60558-011-1},
	url = {https://doi.org/10.1145/1357054.1357255},
	doi = {10.1145/1357054.1357255},
	abstract = {We present data from detailed observations of CityWall, a large multi-touch display installed in a central location in Helsinki, Finland. During eight days of installation, 1199 persons interacted with the system in various social configurations. Videos of these encounters were examined qualitatively as well as quantitatively based on human coding of events. The data convey phenomena that arise uniquely in public use: crowding, massively parallel interaction, teamwork, games, negotiations of transitions and handovers, conflict management, gestures and overt remarks to co-present people, and "marking" the display for others. We analyze how public availability is achieved through social learning and negotiation, why interaction becomes performative and, finally, how the display restructures the public space. The multi-touch feature, gesture-based interaction, and the physical display size contributed differentially to these uses. Our findings on the social organization of the use of public displays can be useful for designing such systems for urban environments.},
	booktitle = {Proceedings of the {SIGCHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Peltonen, Peter and Kurvinen, Esko and Salovaara, Antti and Jacucci, Giulio and Ilmonen, Tommi and Evans, John and Oulasvirta, Antti and Saarikko, Petri},
	year = {2008},
	note = {event-place: Florence, Italy},
	keywords = {multi-user interfaces, situated public displays, urban environments},
	pages = {1285--1294},
}

@book{hartson_ux_2012,
	title = {The {UX} {Book}: {Process} and guidelines for ensuring a quality user experience},
	publisher = {Elsevier},
	author = {Hartson, Rex and Pyla, Pardha S},
	year = {2012},
}

@article{wilson_six_2002,
	title = {Six views of embodied cognition},
	volume = {9},
	issn = {1531-5320},
	url = {https://doi.org/10.3758/BF03196322},
	doi = {10.3758/BF03196322},
	abstract = {The emerging viewpoint of embodied cognition holds that cognitive processes are deeply rooted in the body’s interactions with the world. This position actually houses a number of distinct claims, some of which are more controversial than others. This paper distinguishes and evaluates the following six claims: (1) cognition is situated; (2) cognition is time-pressured; (3) we off-load cognitive work onto the environment; (4) the environment is part of the cognitive system; (5) cognition is for action; (6) offline cognition is body based. Of these, the first three and the fifth appear to be at least partially true, and their usefulness is best evaluated in terms of the range of their applicability. The fourth claim, I argue, is deeply problematic. The sixth claim has received the least attention in the literature on embodied cognition, but it may in fact be the best documented and most powerful of the six claims.},
	number = {4},
	journal = {Psychonomic Bulletin \& Review},
	author = {Wilson, Margaret},
	month = dec,
	year = {2002},
	pages = {625--636},
}

@inproceedings{pinho_cooperative_2002,
	address = {New York, NY, USA},
	series = {{VRST} '02},
	title = {Cooperative {Object} {Manipulation} in {Immersive} {Virtual} {Environments}: {Framework} and {Techniques}},
	isbn = {1-58113-530-0},
	url = {https://doi.org/10.1145/585740.585769},
	doi = {10.1145/585740.585769},
	abstract = {Cooperative manipulation refers to the simultaneous manipulation of a virtual object by multiple users in an immersive virtual environment. This paper describes a framework supporting the development of collaborative manipulation techniques, and example techniques we have tested within this framework. We describe the modeling of cooperative interaction techniques, methods of combining simultaneous user actions, and the awareness tools used to provide the necessary knowledge of partner activities during the cooperative interaction process. Our framework is based on a Collaborative Metaphor concept that defines rules to combine user interaction techniques. The combination is based on the separation of degrees of freedom between two users. Finally, we present novel combinations of two interaction techniques (Simple Virtual Hand and Ray-casting).},
	booktitle = {Proceedings of the {ACM} {Symposium} on {Virtual} {Reality} {Software} and {Technology}},
	publisher = {Association for Computing Machinery},
	author = {Pinho, Márcio S. and Bowman, Doug A. and Freitas, Carla M.D.S.},
	year = {2002},
	note = {event-place: Hong Kong, China},
	keywords = {cooperative interaction, interaction in virtual environments},
	pages = {171--178},
}

@inproceedings{rashid_cost_2012,
	address = {New York, NY, USA},
	series = {{AVI} '12},
	title = {The {Cost} of {Display} {Switching}: {A} {Comparison} of {Mobile}, {Large} {Display} and {Hybrid} {UI} {Configurations}},
	isbn = {978-1-4503-1287-5},
	url = {https://doi.org/10.1145/2254556.2254577},
	doi = {10.1145/2254556.2254577},
	abstract = {Attaching a large external display can help a mobile device user view more content at once. This paper reports on a study investigating how different configurations of input and output across displays affect performance, subjective workload and preferences in map, text and photo search tasks. Experimental results show that a hybrid configuration where visual output is distributed across displays is worst or equivalent to worst in all tasks. A mobile device-controlled large display configuration performs best in the map search task and equal to best in text and photo search tasks (tied with a mobile-only configuration). After conducting a detailed analysis of the performance differences across different UI configurations, we give recommendations for the design of distributed user interfaces.},
	booktitle = {Proceedings of the {International} {Working} {Conference} on {Advanced} {Visual} {Interfaces}},
	publisher = {Association for Computing Machinery},
	author = {Rashid, Umar and Nacenta, Miguel A. and Quigley, Aaron},
	year = {2012},
	note = {event-place: Capri Island, Italy},
	keywords = {distributed user interfaces, map search, mobile input, multi-display environments, photo search, text search},
	pages = {99--106},
}

@inproceedings{whitlock_graphical_2020,
	title = {Graphical {Perception} for {Immersive} {Analytics}},
	doi = {10.1109/VR46266.2020.00084},
	booktitle = {2020 {IEEE} {Conference} on {Virtual} {Reality} and {3D} {User} {Interfaces} ({VR})},
	author = {Whitlock, M. and Smart, S. and Szafir, D. A.},
	year = {2020},
	pages = {616--625},
}

@inproceedings{sereno_supporting_2019,
	title = {Supporting {Volumetric} {Data} {Visualization} and {Analysis} by {Combining} {Augmented} {Reality} {Visuals} with {Multi}-{Touch} {Input}},
	isbn = {978-3-03868-088-8},
	doi = {10.2312/eurp.20191136},
	booktitle = {{EuroVis} 2019 - {Posters}},
	publisher = {The Eurographics Association},
	author = {Sereno, Mickael and Besançon, Lonni and Isenberg, Tobias},
	year = {2019},
}

@article{olson_distance_2000,
	title = {Distance {Matters}},
	volume = {15},
	url = {https://doi.org/10.1207/S15327051HCI1523_4},
	doi = {10.1207/S15327051HCI1523_4},
	number = {2-3},
	journal = {Human–Computer Interaction},
	author = {Olson, Gary M. and Olson, Judith S.},
	year = {2000},
	note = {Publisher: Taylor \& Francis
\_eprint: https://doi.org/10.1207/S15327051HCI1523\_4},
	pages = {139--178},
}

@book{cook_illuminating_2005,
	title = {Illuminating the {Path}: {The} {Research} and {Development} {Agenda} for {Visual} {Analytics}},
	url = {https://www.osti.gov/biblio/912515},
	publisher = {United States. Department of Homeland Security},
	author = {Cook, Kristin A and Thomas, James J},
	year = {2005},
}

@article{hill_group_1982,
	title = {Group versus individual performance: {Are} {N} + 1 heads better than one?},
	volume = {91},
	issn = {1939-1455(Electronic),0033-2909(Print)},
	doi = {10.1037/0033-2909.91.3.517},
	abstract = {Analyzed experimental comparison of groups and individuals on 4 dimensions: task, process, individual differences, and methodology. A standardized terminology based on a study by I. Lorge et al (see record 1959-11098-001) is developed to preserve operational definitions in the comparisons of (a) group vs individual, (b) group vs the most competent individual in an aggregate, (c) group vs pooled responses of an aggregate, and (d) group vs math models of performance. Research supported I. D. Steiner's (1972) theory of process loss but also suggested evidence for process gain. To avoid confounding group conditions and S variables, this review focused on the results of random assignment of Ss to conditions. (2½ p ref) (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
	number = {3},
	journal = {Psychological Bulletin},
	author = {Hill, Gayle W.},
	year = {1982},
	note = {Place: US
Publisher: American Psychological Association},
	keywords = {*Group Performance, *Individual Differences, *Literature Review, *Methodology, Performance},
	pages = {517--539},
}

@inproceedings{mahmood_building_2018,
	title = {Building {Multiple} {Coordinated} {Spaces} for {Effective} {Immersive} {Analytics} through {Distributed} {Cognition}},
	doi = {10.1109/BDVA.2018.8533893},
	booktitle = {2018 {International} {Symposium} on {Big} {Data} {Visual} and {Immersive} {Analytics} ({BDVA})},
	author = {Mahmood, T. and Butler, E. and Davis, N. and Huang, J. and Lu, A.},
	year = {2018},
	pages = {1--11},
}

@inproceedings{marai_interdisciplinary_2016,
	title = {Interdisciplinary immersive analytics at the electronic visualization laboratory: {Lessons} learned and upcoming challenges},
	doi = {10.1109/IMMERSIVE.2016.7932384},
	booktitle = {2016 {Workshop} on {Immersive} {Analytics} ({IA})},
	author = {Marai, G. E. and Forbes, A. G. and Johnson, A.},
	year = {2016},
	pages = {54--59},
}

@inproceedings{buschel_investigating_2017,
	address = {New York, NY, USA},
	series = {{ISS} '17},
	title = {Investigating the {Use} of {Spatial} {Interaction} for {3D} {Data} {Visualization} on {Mobile} {Devices}},
	isbn = {978-1-4503-4691-7},
	url = {https://doi.org/10.1145/3132272.3134125},
	doi = {10.1145/3132272.3134125},
	abstract = {Three-dimensional visualizations employing traditional input and output technologies have well-known limitations. Immersive technologies, natural interaction techniques, and recent developments in data physicalization may help to overcome these issues. In this context, we are specifically interested in the usage of spatial interaction with mobile devices for improved 3D visualizations. To contribute to a better understanding of this interaction style, we implemented example visualizations on a spatially-tracked tablet and investigated their usage and potential. In this paper, we report on a qualitative study comparing spatial interaction with inplace 3D visualizations to classic touch interaction regarding typical visualization tasks: navigation of unknown datasets, comparison of individual data objects, and the understanding and memorization of structures in the data. We identify several distinct usage patterns and derive recommendations for using spatial interaction in 3D data visualization.},
	booktitle = {Proceedings of the 2017 {ACM} {International} {Conference} on {Interactive} {Surfaces} and {Spaces}},
	publisher = {Association for Computing Machinery},
	author = {Büschel, Wolfgang and Reipschläger, Patrick and Langner, Ricardo and Dachselt, Raimund},
	year = {2017},
	note = {event-place: Brighton, United Kingdom},
	keywords = {3D Data Visualization, Immersive Visualization, Mobile Devices, Spatial Input, Tangible Displays},
	pages = {62--71},
}

@inproceedings{klapperstuck_contextuwall_2016,
	title = {{ContextuWall}: {Peer} {Collaboration} {Using} ({Large}) {Displays}},
	doi = {10.1109/BDVA.2016.7787047},
	booktitle = {2016 {Big} {Data} {Visual} {Analytics} ({BDVA})},
	author = {Klapperstuck, M. and Czauderna, T. and Goncu, C. and Glowacki, J. and Dwyer, T. and Schreiber, F. and Marriott, K.},
	year = {2016},
	pages = {1--8},
}

@inproceedings{butscher_clusters_2018,
	address = {New York, NY, USA},
	series = {{CHI} '18},
	title = {Clusters, {Trends}, and {Outliers}: {How} {Immersive} {Technologies} {Can} {Facilitate} the {Collaborative} {Analysis} of {Multidimensional} {Data}},
	isbn = {978-1-4503-5620-6},
	url = {https://doi.org/10.1145/3173574.3173664},
	doi = {10.1145/3173574.3173664},
	abstract = {Immersive technologies such as augmented reality devices are opening up a new design space for the visual analysis of data. This paper studies the potential of an augmented reality environment for the purpose of collaborative analysis of multidimensional, abstract data. We present ART, a collaborative analysis tool to visualize multidimensional data in augmented reality using an interactive, 3D parallel coordinates visualization. The visualization is anchored to a touch-sensitive tabletop, benefiting from well-established interaction techniques. The results of group-based, expert walkthroughs show that ART can facilitate immersion in the data, a fluid analysis process, and collaboration. Based on the results, we provide a set of guidelines and discuss future research areas to foster the development of immersive technologies as tools for the collaborative analysis of multidimensional data.},
	booktitle = {Proceedings of the 2018 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Butscher, Simon and Hubenschmid, Sebastian and Müller, Jens and Fuchs, Johannes and Reiterer, Harald},
	year = {2018},
	note = {event-place: Montreal QC, Canada},
	keywords = {3d parallel coordinates, augmented reality, collaboration, immersive analytics, multi-touch table},
	pages = {1--12},
}

@article{jakobsen_up_2014,
	title = {Up {Close} and {Personal}: {Collaborative} {Work} on a {High}-{Resolution} {Multitouch} {Wall} {Display}},
	volume = {21},
	issn = {1073-0516},
	url = {https://doi.org/10.1145/2576099},
	doi = {10.1145/2576099},
	abstract = {Multitouch wall-sized displays afford new forms of collaboration: They can be used up close by several users simultaneously, offer high resolution, and provide sufficient space for intertwining individual and joint work. The difference to displays without these capabilities is not well understood. To better understand the collaboration of groups around high-resolution multitouch wall displays, we conducted an exploratory study. Pairs collaborated on a problem-solving task using a 2.8m × 1.2m multitouch display with 24.8 megapixels. The study examines how participants collaborate; navigate relative to the display and to each other; and interact with and share the display. Participants physically navigated among different parts of the display, switched fluidly between parallel and joint work, and shared the display evenly. The results contrast earlier research that suggests difficulties in sharing and collaborating around wall displays. The study suggests that multitouch wall displays can support different collaboration styles and fluid transitions in group work.},
	number = {2},
	journal = {ACM Trans. Comput.-Hum. Interact.},
	author = {Jakobsen, Mikkel R. and HornbÆk, Kasper},
	month = feb,
	year = {2014},
	note = {Place: New York, NY, USA
Publisher: Association for Computing Machinery},
	keywords = {Large high-resolution display, colocated collaboration, group work, multi-touch, proxemics, territoriality, user study, user tracking, wall-display},
}

@inproceedings{lisle_evaluating_2020,
	title = {Evaluating the {Benefits} of the {Immersive} {Space} to {Think}},
	doi = {10.1109/VRW50115.2020.00073},
	booktitle = {2020 {IEEE} {Conference} on {Virtual} {Reality} and {3D} {User} {Interfaces} {Abstracts} and {Workshops} ({VRW})},
	author = {Lisle, L. and Chen, X. and Gitre, J. K. Edward and North, C. and Bowman, D. A.},
	year = {2020},
	pages = {331--337},
}

@inproceedings{sereno_subjective_2020,
	title = {Subjective {Views} in {Co}-{Located} {Augmented} {Reality}-{Initial} {Design}},
	booktitle = {{IEEE} {Visualization}},
	publisher = {IEEE},
	author = {Sereno, Mickael and Isenberg, Tobias},
	year = {2020},
}

@incollection{billinghurst_collaborative_2018,
	address = {Cham},
	title = {Collaborative {Immersive} {Analytics}},
	isbn = {978-3-030-01388-2},
	url = {https://doi.org/10.1007/978-3-030-01388-2_8},
	abstract = {Many of the problems being addressed by Immersive Analytics require groups of people to solve. This chapter introduces the concept of Collaborative Immersive Analytics (CIA) and reviews how immersive technologies can be combined with Visual Analytics to facilitate co-located and remote collaboration. We provide a definition of Collaborative Immersive Analytics and then an overview of the different types of possible collaboration. The chapter also discusses the various roles in collaborative systems, and how to support shared interaction with the data being presented. Finally, we summarize the opportunities for future research in this domain. The aim of the chapter is to provide enough of an introduction to CIA and key directions for future research, so that practitioners will be able to begin working in the field.},
	booktitle = {Immersive {Analytics}},
	publisher = {Springer International Publishing},
	author = {Billinghurst, Mark and Cordeil, Maxime and Bezerianos, Anastasia and Margolis, Todd},
	editor = {Marriott, Kim and Schreiber, Falk and Dwyer, Tim and Klein, Karsten and Riche, Nathalie Henry and Itoh, Takayuki and Stuerzlinger, Wolfgang and Thomas, Bruce H.},
	year = {2018},
	doi = {10.1007/978-3-030-01388-2_8},
	pages = {221--257},
}

@incollection{buschel_interaction_2018,
	address = {Cham},
	title = {Interaction for {Immersive} {Analytics}},
	isbn = {978-3-030-01388-2},
	url = {https://doi.org/10.1007/978-3-030-01388-2_4},
	abstract = {In this chapter, we briefly review the development of natural user interfaces and discuss their role in providing human-computer interaction that is immersive in various ways. Then we examine some opportunities for how these technologies might be used to better support data analysis tasks. Specifically, we review and suggest some interaction design guidelines for immersive analytics. We also review some hardware setups for data visualization that are already archetypal. Finally, we look at some emerging system designs that suggest future directions.},
	booktitle = {Immersive {Analytics}},
	publisher = {Springer International Publishing},
	author = {Büschel, Wolfgang and Chen, Jian and Dachselt, Raimund and Drucker, Steven and Dwyer, Tim and Görg, Carsten and Isenberg, Tobias and Kerren, Andreas and North, Chris and Stuerzlinger, Wolfgang},
	editor = {Marriott, Kim and Schreiber, Falk and Dwyer, Tim and Klein, Karsten and Riche, Nathalie Henry and Itoh, Takayuki and Stuerzlinger, Wolfgang and Thomas, Bruce H.},
	year = {2018},
	doi = {10.1007/978-3-030-01388-2_4},
	pages = {95--138},
}

@inproceedings{cordeil_imaxes_2017,
	address = {New York, NY, USA},
	series = {{UIST} '17},
	title = {{ImAxes}: {Immersive} {Axes} as {Embodied} {Affordances} for {Interactive} {Multivariate} {Data} {Visualisation}},
	isbn = {978-1-4503-4981-9},
	url = {https://doi.org/10.1145/3126594.3126613},
	doi = {10.1145/3126594.3126613},
	abstract = {We introduce ImAxes immersive system for exploring multivariate data using fluid, modeless interaction. The basic interface element is an embodied data axis. The user can manipulate these axes like physical objects in the immersive environment and combine them into sophisticated visualisations. The type of visualisation that appears depends on the proximity and relative orientation of the axes with respect to one another, which we describe with a formal grammar. This straight-forward composability leads to a number of emergent visualisations and interactions, which we review, and then demonstrate with a detailed multivariate data analysis use case.},
	booktitle = {Proceedings of the 30th {Annual} {ACM} {Symposium} on {User} {Interface} {Software} and {Technology}},
	publisher = {Association for Computing Machinery},
	author = {Cordeil, Maxime and Cunningham, Andrew and Dwyer, Tim and Thomas, Bruce H. and Marriott, Kim},
	year = {2017},
	note = {event-place: Québec City, QC, Canada},
	keywords = {immersion, immersive analytics, immersive visualization, information visualization, multidimensional data visualization, virtual reality},
	pages = {71--83},
}

@article{kister_grasp_2017,
	title = {{GraSp}: {Combining} {Spatially}-aware {Mobile} {Devices} and a {Display} {Wall} for {Graph} {Visualization} and {Interaction}},
	volume = {36},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/cgf.13206},
	doi = {https://doi.org/10.1111/cgf.13206},
	abstract = {Abstract Going beyond established desktop interfaces, researchers have begun re-thinking visualization approaches to make use of alternative display environments and more natural interaction modalities. In this paper, we investigate how spatially-aware mobile displays and a large display wall can be coupled to support graph visualization and interaction. For that purpose, we distribute typical visualization views of classic node-link and matrix representations between displays. The focus of our work lies in novel interaction techniques that enable users to work with personal mobile devices in combination with the wall. We devised and implemented a comprehensive interaction repertoire that supports basic and advanced graph exploration and manipulation tasks, including selection, details-on-demand, focus transitions, interactive lenses, and data editing. A qualitative study has been conducted to identify strengths and weaknesses of our techniques. Feedback showed that combining mobile devices and a wall-sized display is useful for diverse graph-related tasks. We also gained valuable insights regarding the distribution of visualization views and interactive tools among the combined displays.},
	number = {3},
	journal = {Computer Graphics Forum},
	author = {Kister, U. and Klamka, K. and Tominski, C. and Dachselt, R.},
	year = {2017},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/cgf.13206},
	keywords = {Categories and Subject Descriptors (according to ACM CCS), H.5.2 Information Interfaces and Presentation: User Interfaces—Interaction styles},
	pages = {503--514},
}

@article{cordeil_immersive_2017,
	title = {Immersive {Collaborative} {Analysis} of {Network} {Connectivity}: {CAVE}-style or {Head}-{Mounted} {Display}?},
	volume = {23},
	doi = {10.1109/TVCG.2016.2599107},
	number = {1},
	journal = {IEEE Transactions on Visualization and Computer Graphics},
	author = {Cordeil, M. and Dwyer, T. and Klein, K. and Laha, B. and Marriott, K. and Thomas, B. H.},
	year = {2017},
	pages = {441--450},
}

@inproceedings{tang_collaborative_2006,
	address = {New York, NY, USA},
	series = {{CHI} '06},
	title = {Collaborative {Coupling} over {Tabletop} {Displays}},
	isbn = {1-59593-372-7},
	url = {https://doi.org/10.1145/1124772.1124950},
	doi = {10.1145/1124772.1124950},
	abstract = {Designing collaborative interfaces for tabletops remains difficult because we do not fully understand how groups coordinate their actions when working collaboratively over tables. We present two observational studies of pairs completing independent and shared tasks that investigate collaborative coupling, or the manner in which collaborators are involved and occupied with each other's work. Our results indicate that individuals frequently and fluidly engage and disengage with group activity through several distinct, recognizable states with unique characteristics. We describe these states and explore the consequences of these states for tabletop interface design.},
	booktitle = {Proceedings of the {SIGCHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Tang, Anthony and Tory, Melanie and Po, Barry and Neumann, Petra and Carpendale, Sheelagh},
	year = {2006},
	note = {event-place: Montréal, Québec, Canada},
	keywords = {collaborative coupling, collaborative tabletop displays, coordination, mixed focus collaboration, single display groupware},
	pages = {1181--1190},
}

@article{reipschlager_personal_2020,
	title = {Personal {Augmented} {Reality} for {Information} {Visualization} on {Large} {Interactive} {Displays}},
	doi = {10.1109/TVCG.2020.3030460},
	journal = {IEEE Transactions on Visualization and Computer Graphics},
	author = {Reipschläger, P. and Flemisch, T. and Dachselt, R.},
	year = {2020},
	pages = {1--1},
}

@article{skarbez_immersive_2019,
	title = {Immersive {Analytics}: {Theory} and {Research} {Agenda}},
	volume = {6},
	issn = {2296-9144},
	url = {https://www.frontiersin.org/article/10.3389/frobt.2019.00082},
	doi = {10.3389/frobt.2019.00082},
	abstract = {Advances in a variety of computing fields, including “big data,” machine learning, visualization, and augmented/mixed/virtual reality, have combined to give rise to the emerging field of immersive analytics, which investigates how these new technologies support analysis and decision making. Thus far, we feel that immersive analytics research has been somewhat ad hoc, possibly owing to the fact that there is not yet an organizing framework for immersive analytics research. In this paper, we address this lack by proposing a definition for immersive analytics and identifying some general research areas and specific research questions that will be important for the development of this field. We also present three case studies that, while all being examples of what we would consider immersive analytics, present different challenges, and opportunities. These serve to demonstrate the breadth of immersive analytics and illustrate how the framework proposed in this paper applies to practical research.},
	journal = {Frontiers in Robotics and AI},
	author = {Skarbez, Richard and Polys, Nicholas F. and Ogle, J. Todd and North, Chris and Bowman, Doug A.},
	year = {2019},
	pages = {82},
}

@incollection{marriott_immersive_2018,
	address = {Cham},
	title = {Immersive {Analytics}: {Time} to {Reconsider} the {Value} of {3D} for {Information} {Visualisation}},
	isbn = {978-3-030-01388-2},
	url = {https://doi.org/10.1007/978-3-030-01388-2_2},
	abstract = {Modern virtual reality display technologies engender spatial immersion by using a variety of depth cues such as perspective and head-tracked binocular presentation to create visually realistic 3D worlds. While 3D visualisations are common in scientific visualisation, they are much less common in information visualisation. In this chapter we explore whether immersive analytic applications should continue to use traditional 2D information visualisations or whether there are situations when 3D may offer benefits. We identify a number of potential applications of 3D depth cues for abstract data visualisation: using depth to show an additional data dimension, such as in 2.5D network layouts, views on non-flat surfaces and egocentric views in which the data is placed around the viewer, and visualising abstract data with a spatial embedding. Another important potential benefit is the ability to arrange multiple views in the 3D space around the user and to attach abstract visualisations to objects in the real world.},
	booktitle = {Immersive {Analytics}},
	publisher = {Springer International Publishing},
	author = {Marriott, Kim and Chen, Jian and Hlawatsch, Marcel and Itoh, Takayuki and Nacenta, Miguel A. and Reina, Guido and Stuerzlinger, Wolfgang},
	editor = {Marriott, Kim and Schreiber, Falk and Dwyer, Tim and Klein, Karsten and Riche, Nathalie Henry and Itoh, Takayuki and Stuerzlinger, Wolfgang and Thomas, Bruce H.},
	year = {2018},
	doi = {10.1007/978-3-030-01388-2_2},
	pages = {25--55},
}

@inproceedings{scott_territoriality_2004,
	address = {New York, NY, USA},
	series = {{CSCW} '04},
	title = {Territoriality in {Collaborative} {Tabletop} {Workspaces}},
	isbn = {1-58113-810-5},
	url = {https://doi.org/10.1145/1031607.1031655},
	doi = {10.1145/1031607.1031655},
	abstract = {Researchers seeking alternatives to traditional desktop computers have begun exploring the potential collaborative benefits of digital tabletop displays. However, there are still many open issues related to the design of collaborative tabletop interfaces, such as whether these systems should automatically orient workspace items or enforce ownership of workspace content. Understanding the natural interaction practices that people use during tabletop collaboration with traditional media (e.g., pen and paper) can help to address these issues. Interfaces that are modeled on these practices will have the additional advantage of supporting the interaction skills people have developed over years of collaborating at traditional tables. To gain a deeper understanding of these interaction practices we conducted two observational studies of traditional tabletop collaboration in both casual and formal settings. Our results reveal that collaborators use three types of tabletop territories to help coordinate their interactions within the shared tabletop workspace: \textit{personal, group}, and \textit{storage} territories. Findings from a spatial analysis of collaborators' tabletop interactions reveal important properties of these tabletop territories. In order to provide a comprehensive picture of the role of tabletop territoriality in collaboration, we conclude with a synthesis of our findings and previous research findings and with several relevant design implications.},
	booktitle = {Proceedings of the {ACM} {Conference} on {Computer} {Supported} {Cooperative} {Work}},
	publisher = {Association for Computing Machinery},
	author = {Scott, Stacey D. and Carpendale, M. Sheelagh T. and Inkpen, Kori},
	year = {2004},
	note = {event-place: Chicago, Illinois, USA},
	keywords = {CSCW, co-located collaboration, observational studies, qualitative analysis, tabletop displays, territoriality},
	pages = {294--303},
}

@inproceedings{fisher_distributed_2012,
	address = {New York, NY, USA},
	series = {{CHI} '12},
	title = {Distributed {Sensemaking}: {Improving} {Sensemaking} by {Leveraging} the {Efforts} of {Previous} {Users}},
	isbn = {978-1-4503-1015-4},
	url = {https://doi.org/10.1145/2207676.2207711},
	doi = {10.1145/2207676.2207711},
	abstract = {We examine the possibility of distributed sensemaking: improving a user's sensemaking by leveraging previous users' work without those users directly collaborating or even knowing one another. We asked users to engage in sensemaking by organizing and annotating web search results into "knowledge maps," either with or without previous users' maps to work from. We also recorded gaze patterns as users examined others' knowledge maps. Our findings show the conditions under which distributed sensemaking can improve sensemaking quality; that a user's sensemaking process is readily apparent to a subsequent user via a knowledge map; and that the organization of content was more useful to subsequent users than the content itself, especially when those users had differing goals. We discuss the role distributed sensemaking can play in schema induction by helping users make a mental model of an information space and make recommendations for new tool and system development.},
	booktitle = {Proceedings of the {SIGCHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Fisher, Kristie and Counts, Scott and Kittur, Aniket},
	year = {2012},
	note = {event-place: Austin, Texas, USA},
	keywords = {collaboration, knowledge mapping, search, sensemaking},
	pages = {247--256},
}

@article{isenberg_collaborative_2011,
	title = {Collaborative visualization: {Definition}, challenges, and research agenda},
	volume = {10},
	url = {https://doi.org/10.1177/1473871611412817},
	doi = {10.1177/1473871611412817},
	abstract = {The conflux of two growing areas of technology – collaboration and visualization – into a new research direction, collaborative visualization, provides new research challenges. Technology now allows us to easily connect and collaborate with one another – in settings as diverse as over networked computers, across mobile devices, or using shared displays such as interactive walls and tabletop surfaces. Digital information is now regularly accessed by multiple people in order to share information, to view it together, to analyze it, or to form decisions. Visualizations are used to deal more effectively with large amounts of information while interactive visualizations allow users to explore the underlying data. While researchers face many challenges in collaboration and in visualization, the emergence of collaborative visualization poses additional challenges, but it is also an exciting opportunity to reach new audiences and applications for visualization tools and techniques.The purpose of this article is (1) to provide a definition, clear scope, and overview of the evolving field of collaborative visualization, (2) to help pinpoint the unique focus of collaborative visualization with its specific aspects, challenges, and requirements within the intersection of general computer-supported cooperative work and visualization research, and (3) to draw attention to important future research questions to be addressed by the community. We conclude by discussing a research agenda for future work on collaborative visualization and urge for a new generation of visualization tools that are designed with collaboration in mind from their very inception.},
	number = {4},
	journal = {Information Visualization},
	author = {Isenberg, Petra and Elmqvist, Niklas and Scholtz, Jean and Cernea, Daniel and Ma, Kwan-Liu and Hagen, Hans},
	year = {2011},
	note = {\_eprint: https://doi.org/10.1177/1473871611412817},
	pages = {310--326},
}

@article{tam_framework_2006,
	title = {A framework for asynchronous change awareness in collaborative documents and workspaces},
	volume = {64},
	issn = {1071-5819},
	url = {http://www.sciencedirect.com/science/article/pii/S1071581906000218},
	doi = {https://doi.org/10.1016/j.ijhcs.2006.02.004},
	abstract = {Change awareness is the ability of individuals to track the asynchronous changes made to a collaborative document or graphical workspace by other participants over time. We develop a framework that articulates what change awareness information is critical if people are to track and maintain change awareness. Information elements include: knowing who changed the artifact, what those changes involve, where changes occur, when changes were made, how things have changed and why people made the changes. The framework accounts for people's need to view these changes from different perspectives: an artifact-based view, a person-based view and a workspace-based view. Each information element is further broken down into distinguishing features and matched against these perspectives, e.g., location history within the where category prompts the questions ‘where was this artifact when I left’ in the artifact-based view, ‘where in the workspace has a person visited’ in the person-based view and ‘where have people been in the workspace’ in the workspace-based view. The framework can be used both to inform and critique change awareness tools.},
	number = {7},
	journal = {International Journal of Human-Computer Studies},
	author = {Tam, James and Greenberg, Saul},
	year = {2006},
	keywords = {Asynchronous awareness, Change awareness},
	pages = {583 -- 598},
}

@article{erickson_social_2000,
	title = {Social {Translucence}: {An} {Approach} to {Designing} {Systems} {That} {Support} {Social} {Processes}},
	volume = {7},
	issn = {1073-0516},
	url = {https://doi.org/10.1145/344949.345004},
	doi = {10.1145/344949.345004},
	abstract = {We are interested in desiging systems that support communication and collaboration among large groups of people over computing networks. We begin by asking what properties of the physical world support graceful human-human communication in face-to-face situations, and argue that it is possible to design digital systems that support coherent behavior by making participants and their activites visible to one another. We call such systems “socially translucent systems” and suggest that they have three characteristics—visbility, awareness, and accountability—which enable people to draw upon their experience and expertise to structure their interactions with one another. To motivate and focus our ideas we develop a vision of knowledge communities, conversationally based systems that support the creation, management and reuse of knowledge in a social context. We describe our experience in designing and deploying one layer of functionality for knowledge communities, embodied in a working system called “Barbie” and discuss research issues raised by a socially translucent approach to design.},
	number = {1},
	journal = {ACM Transactions on Computer-Human Interaction},
	author = {Erickson, Thomas and Kellogg, Wendy A.},
	month = mar,
	year = {2000},
	note = {Place: New York, NY, USA
Publisher: Association for Computing Machinery},
	keywords = {CMC, CMI, CSCW, computer-mediated communication, social computing, social navigation, social visualization, visualization},
	pages = {59--83},
}

@article{hollan_distributed_2000,
	title = {Distributed {Cognition}: {Toward} a {New} {Foundation} for {Human}-{Computer} {Interaction} {Research}},
	volume = {7},
	issn = {1073-0516},
	url = {https://doi.org/10.1145/353485.353487},
	doi = {10.1145/353485.353487},
	abstract = {We are quickly passing through the historical moment when people work in front of a single computer, dominated by a small CRT and focused on tasks involving only local information. Networked computers are becoming ubiquitous and are playing increasingly significant roles in our lives and in the basic infrastructures of science, business, and social interaction. For human-computer interaction to advance in the new millennium we need to better understand the emerging dynamic of interaction in which the focus task is no longer confined to the desktop but reaches into a complex networked world of information and computer-mediated interactions. We think the theory of distributed cognition has a special role to play in understanding interactions between people and technologies, for its focus has always been on whole environments: what we really do in them and how we coordinate our activity in them. Distributed cognition provides a radical reorientation of how to think about designing and supporting human-computer interaction. As a theory it is specifically tailored to understanding interactions among people and technologies. In this article we propose distributed cognition as a new foundation for human-computer interaction, sketch an integrated research framework, and use selections from our earlier work to suggest how this framework can provide new opportunities in the design of digital work materials.},
	number = {2},
	journal = {ACM Transactions on Computer-Human Interaction},
	author = {Hollan, James and Hutchins, Edwin and Kirsh, David},
	month = jun,
	year = {2000},
	note = {Place: New York, NY, USA
Publisher: Association for Computing Machinery},
	keywords = {cognitive science, distributed cognition, ethnography, human-computer interaction, research methodology},
	pages = {174--196},
}

@inproceedings{wallace_effect_2014,
	address = {New York, NY, USA},
	series = {{PerDis} '14},
	title = {Effect of {Bezel} {Presence} and {Width} on {Visual} {Search}},
	isbn = {978-1-4503-2952-1},
	url = {https://doi.org/10.1145/2611009.2611019},
	doi = {10.1145/2611009.2611019},
	abstract = {We investigate how the presence and width of interior bezels impacts visual search performance across tiled displays. In spite of a potential benefit from structured segmentation, we do not find significant differences in visual search time, and note a small effect size of less than 0.5\% for bezel width. However, we find participants are more accurate when searching for targets spanning a bezel. Based on these findings, we suggest two implications for the design of tiled displays: 1) that additional costs associated with thinner bezels may not provide significant return on investment; and 2) that bezels may act as visual anchors, and be useful for the placement of interface elements.},
	booktitle = {Proceedings of {The} {International} {Symposium} on {Pervasive} {Displays}},
	publisher = {Association for Computing Machinery},
	author = {Wallace, James R. and Vogel, Daniel and Lank, Edward},
	year = {2014},
	note = {event-place: Copenhagen, Denmark},
	keywords = {Bezels, Perception, Tiled Displays, Visual Search},
	pages = {118--123},
}

@inproceedings{feiner_windows_1993,
	address = {New York, NY, USA},
	series = {{UIST} '93},
	title = {Windows on the {World}: {2D} {Windows} for {3D} {Augmented} {Reality}},
	isbn = {0-89791-628-X},
	url = {https://doi.org/10.1145/168642.168657},
	doi = {10.1145/168642.168657},
	booktitle = {Proceedings of the 6th {Annual} {ACM} {Symposium} on {User} {Interface} {Software} and {Technology}},
	publisher = {Association for Computing Machinery},
	author = {Feiner, Steven and MacIntyre, Blair and Haupt, Marcus and Solomon, Eliot},
	year = {1993},
	note = {event-place: Atlanta, Georgia, USA},
	keywords = {X11, augmented reality, head-mounted displays, hypertext/hypermedia, mobile computing, portable computers, virtual reality, virtual worlds, window systems},
	pages = {145--155},
}

@inproceedings{lu_glanceable_2020,
	title = {Glanceable {AR}: {Evaluating} {Information} {Access} {Methods} for {Head}-{Worn} {Augmented} {Reality}},
	doi = {10.1109/VR46266.2020.00113},
	booktitle = {2020 {IEEE} {Conference} on {Virtual} {Reality} and {3D} {User} {Interfaces} ({VR})},
	author = {Lu, F. and Davari, S. and Lisle, L. and Li, Y. and Bowman, D. A.},
	year = {2020},
	pages = {930--939},
}

@inproceedings{li_holodoc_2019,
	address = {New York, NY, USA},
	series = {{CHI} '19},
	title = {{HoloDoc}: {Enabling} {Mixed} {Reality} {Workspaces} {That} {Harness} {Physical} and {Digital} {Content}},
	isbn = {978-1-4503-5970-2},
	url = {https://doi.org/10.1145/3290605.3300917},
	doi = {10.1145/3290605.3300917},
	abstract = {Prior research identified that physical paper documents have many positive attributes, for example natural tangibility and inherent physical flexibility. When documents are presented on digital devices, however, they can provide unique functionality to users, such as the ability to search, view dynamic multimedia content, and make use of indexing. This work explores the fusion of physical and digital paper documents. It first presents the results of a study that probed how users perform document-intensive analytical tasks when both physical and digital versions of documents were available. The study findings then informed the design of HoloDoc, a mixed reality system that augments physical artifacts with rich interaction and dynamic virtual content. Finally, we present the interaction techniques that HoloDoc affords, and the results of a second study that assessed HoloDoc's utility when working with digital and physical copies of academic articles.},
	booktitle = {Proceedings of the 2019 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Li, Zhen and Annett, Michelle and Hinckley, Ken and Singh, Karan and Wigdor, Daniel},
	year = {2019},
	note = {event-place: Glasgow, Scotland Uk},
	keywords = {augmented reality, digital pen input, mixed reality, reading behavior},
	pages = {1--14},
}

@article{grubert_towards_2017,
	title = {Towards {Pervasive} {Augmented} {Reality}: {Context}-{Awareness} in {Augmented} {Reality}},
	volume = {23},
	doi = {10.1109/TVCG.2016.2543720},
	number = {6},
	journal = {IEEE Transactions on Visualization and Computer Graphics},
	author = {Grubert, J. and Langlotz, T. and Zollmann, S. and Regenbrecht, H.},
	year = {2017},
	pages = {1706--1724},
}

@article{henderson_rooms_1986,
	title = {Rooms: {The} {Use} of {Multiple} {Virtual} {Workspaces} to {Reduce} {Space} {Contention} in a {Window}-{Based} {Graphical} {User} {Interface}},
	volume = {5},
	issn = {0730-0301},
	url = {https://doi.org/10.1145/24054.24056},
	doi = {10.1145/24054.24056},
	abstract = {A key constraint on the effectiveness of window-based human-computer interfaces is that the display screen is too small for many applications. This results in “window thrashing,” in which the user must expend considerable effort to keep desired windows visible. Rooms is a window manager that overcomes small screen size by exploiting the statistics of window access, dividing the user's workspace into a suite of virtual workspaces with transitions among them. Mechanisms are described for solving the problems of navigation and simultaneous access to separated information that arise from multiple workspaces.},
	number = {3},
	journal = {ACM Trans. Graph.},
	author = {Henderson, D. Austin and Card, Stuart},
	month = jul,
	year = {1986},
	note = {Place: New York, NY, USA
Publisher: Association for Computing Machinery},
	pages = {211--243},
}

@inproceedings{ringel_when_2003,
	address = {New York, NY, USA},
	series = {{CHI} {EA} '03},
	title = {When {One} {Isn}'t {Enough}: {An} {Analysis} of {Virtual} {Desktop} {Usage} {Strategies} and {Their} {Implications} for {Design}},
	isbn = {1-58113-637-4},
	url = {https://doi.org/10.1145/765891.765976},
	doi = {10.1145/765891.765976},
	abstract = {Screen space is a limited resource for computer users-multiple monitors are one means of workspace expansion, and "virtual desktops" are yet another way to increase screen real-estate. We present a taxonomy of organization strategies based on our observations during a series of interviews with virtual desktop users. Additionally, we explore causes of varying user preferences for physical versus virtual means of screen-space expansion. Finally, we discuss the design implications of our findings.},
	booktitle = {{CHI} '03 {Extended} {Abstracts} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Ringel, Meredith},
	year = {2003},
	note = {event-place: Ft. Lauderdale, Florida, USA},
	keywords = {information organization, multiple monitors, virtual desktops},
	pages = {762--763},
}

@inproceedings{eiberger_effects_2019,
	address = {New York, NY, USA},
	series = {{SUI} '19},
	title = {Effects of {Depth} {Layer} {Switching} between an {Optical} {See}-{Through} {Head}-{Mounted} {Display} and a {Body}-{Proximate} {Display}},
	isbn = {978-1-4503-6975-6},
	url = {https://doi.org/10.1145/3357251.3357588},
	doi = {10.1145/3357251.3357588},
	abstract = {Optical see-through head-mounted displays (OST HMDs) typically display virtual content at a fixed focal distance while users need to integrate this information with real-world information at different depth layers. This problem is pronounced in body-proximate multi-display systems, such as when an OST HMD is combined with a smartphone or smartwatch. While such joint systems open up a new design space, they also reduce users’ ability to integrate visual information. We quantify this cost by presenting the results of an experiment (n=24) that evaluates human performance in a visual search task across an OST HMD and a body-proximate display at 30 cm. The results reveal that task completion time increases significantly by approximately 50\% and the error rate increases significantly by approximately 100\% compared to visual search on a single depth layer. These results highlight a design trade-off when designing joint OST HMD-body proximate display systems.},
	booktitle = {Symposium on {Spatial} {User} {Interaction}},
	publisher = {Association for Computing Machinery},
	author = {Eiberger, Anna and Kristensson, Per Ola and Mayr, Susanne and Kranz, Matthias and Grubert, Jens},
	year = {2019},
	note = {event-place: New Orleans, LA, USA},
	keywords = {accomodation, augmented reality, multi-display environments, perception, vergence},
}

@inproceedings{ruvimova_transport_2020,
	address = {New York, NY, USA},
	series = {{CHI} '20},
	title = {"{Transport} {Me} {Away}": {Fostering} {Flow} in {Open} {Offices} through {Virtual} {Reality}},
	isbn = {978-1-4503-6708-0},
	url = {https://doi.org/10.1145/3313831.3376724},
	doi = {10.1145/3313831.3376724},
	abstract = {Open offices are cost-effective and continue to be popular. However, research shows that these environments, brimming with distractions and sensory overload, frequently hamper productivity. Our research investigates the use of virtual reality (VR) to mitigate distractions in an open office setting and improve one's ability to be in flow. In a lab study, 35 participants performed visual programming tasks in four combinations of physical (open or closed office) and virtual environments (beach or virtual office). While participants both preferred and were in flow more in a closed office without VR, in an open office, the VR environments outperformed the no VR condition in all measures of flow, performance, and preference. Especially considering the recent rapid advancements in VR, our findings illustrate the potential VR has to improve flow and satisfaction in open offices.},
	booktitle = {Proceedings of the 2020 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Ruvimova, Anastasia and Kim, Junhyeok and Fritz, Thomas and Hancock, Mark and Shepherd, David C.},
	year = {2020},
	note = {event-place: Honolulu, HI, USA},
	keywords = {flow, open offices, virtual reality, work},
	pages = {1--14},
}

@inproceedings{raskar_office_1998,
	address = {New York, NY, USA},
	series = {{SIGGRAPH} '98},
	title = {The {Office} of the {Future}: {A} {Unified} {Approach} to {Image}-{Based} {Modeling} and {Spatially} {Immersive} {Displays}},
	isbn = {0-89791-999-8},
	url = {https://doi.org/10.1145/280814.280861},
	doi = {10.1145/280814.280861},
	booktitle = {Proceedings of the 25th {Annual} {Conference} on {Computer} {Graphics} and {Interactive} {Techniques}},
	publisher = {Association for Computing Machinery},
	author = {Raskar, Ramesh and Welch, Greg and Cutts, Matt and Lake, Adam and Stesin, Lev and Fuchs, Henry},
	year = {1998},
	keywords = {autocalibration, calibration, depth, display, image-based modeling, image-based rendering, intensity blending, projection, range, reflectance, spatially immersive display, virtual environments},
	pages = {179--188},
}

@inproceedings{bellgardt_utilizing_2017,
	title = {Utilizing immersive virtual reality in everydaywork},
	doi = {10.1109/WEVR.2017.7957708},
	booktitle = {2017 {IEEE} 3rd {Workshop} on {Everyday} {Virtual} {Reality} ({WEVR})},
	author = {Bellgardt, M. and Pick, S. and Zielasko, D. and Vierjahn, T. and Weyers, B. and Kuhlen, T. W.},
	year = {2017},
	pages = {1--4},
}

@inproceedings{benko_multi-monitor_2005,
	address = {New York, NY, USA},
	series = {{CHI} {EA} '05},
	title = {Multi-{Monitor} {Mouse}},
	isbn = {1-59593-002-7},
	url = {https://doi.org/10.1145/1056808.1056878},
	doi = {10.1145/1056808.1056878},
	abstract = {Multiple-monitor computer configurations significantly increase the distances that users must traverse with the mouse when interacting with existing applications, resulting in increased time and effort. We introduce the Multi-Monitor Mouse (M3) technique, which virtually simulates having one mouse pointer per monitor when using a single physical mouse device. M3 allows for conventional control of the mouse within each monitor's screen, while permitting immediate warping across monitors when desired to increase mouse traversal speed. We report the results of a user study in which we compared three implementations of M3 and two cursor placement strategies. Our results suggest that using M3 significantly increases interaction speed in a multi-monitor environment. All eight study participants strongly preferred M3 to the regular mouse behavior.},
	booktitle = {{CHI} '05 {Extended} {Abstracts} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Benko, Hrvoje and Feiner, Steven},
	year = {2005},
	note = {event-place: Portland, OR, USA},
	keywords = {interaction technique, mouse pointer, multi-monitor},
	pages = {1208--1211},
}

@article{mcgill_expanding_2020,
	title = {Expanding the {Bounds} of {Seated} {Virtual} {Workspaces}},
	volume = {27},
	issn = {1073-0516},
	url = {https://doi.org/10.1145/3380959},
	doi = {10.1145/3380959},
	abstract = {Mixed Reality (MR), Augmented Reality (AR) and Virtual Reality (VR) headsets can improve upon existing physical multi-display environments by rendering large, ergonomic virtual display spaces whenever and wherever they are needed. However, given the physical and ergonomic limitations of neck movement, users may need assistance to view these display spaces comfortably. Through two studies, we developed new ways of minimising the physical effort and discomfort of viewing such display spaces. We first explored how the mapping between gaze angle and display position could be manipulated, helping users view wider display spaces than currently possible within an acceptable and comfortable range of neck movement. We then compared our implicit control of display position based on head orientation against explicit user control, finding significant benefits in terms of user preference, workload and comfort for implicit control. Our novel techniques create new opportunities for productive work by leveraging MR headsets to create interactive wide virtual workspaces with improved comfort and usability. These workspaces are flexible and can be used on-the-go, e.g., to improve remote working or make better use of commuter journeys.},
	number = {3},
	journal = {ACM Trans. Comput.-Hum. Interact.},
	author = {Mcgill, Mark and Kehoe, Aidan and Freeman, Euan and Brewster, Stephen},
	month = may,
	year = {2020},
	note = {Place: New York, NY, USA
Publisher: Association for Computing Machinery},
	keywords = {Virtual reality, augmented reality, display space, displays, mixed reality, multi-monitor, productivity, rotational gain, virtual desktops, virtual displays, workspaces},
}

@article{gabbard_effects_2019,
	title = {Effects of {AR} {Display} {Context} {Switching} and {Focal} {Distance} {Switching} on {Human} {Performance}},
	volume = {25},
	doi = {10.1109/TVCG.2018.2832633},
	number = {6},
	journal = {IEEE Transactions on Visualization and Computer Graphics},
	author = {Gabbard, J. L. and Mehra, D. G. and Swan, J. E.},
	year = {2019},
	pages = {2228--2241},
}

@inproceedings{czerwinski_women_2002,
	address = {New York, NY, USA},
	series = {{CHI} '02},
	title = {Women {Take} a {Wider} {View}},
	isbn = {1-58113-453-3},
	url = {https://doi.org/10.1145/503376.503412},
	doi = {10.1145/503376.503412},
	abstract = {Published reports suggest that males significantly outperform females in navigating virtual environments. A novel navigation technique reported in CHI 2001, when combined with a large display and wide field of view, appeared to reduce that gender bias. That work has been extended with two navigation studies in order to understand the finding under carefully controlled conditions. The first study replicated the finding that a wide field of view coupled with a large display benefits both male and female users and reduces gender bias. The second study suggested that wide fields of view on a large display were useful to females despite a more densely populated virtual world. Implications for design of virtual worlds and large displays are discussed. Specifically, women take a wider field of view to achieve similar virtual environment navigation performance to men},
	booktitle = {Proceedings of the {SIGCHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Czerwinski, Mary and Tan, Desney S. and Robertson, George G.},
	year = {2002},
	note = {event-place: Minneapolis, Minnesota, USA},
	keywords = {3D navigation, cognitive maps, field of view, gender effects, landmark knowledge, spatial abilities},
	pages = {195--202},
}

@inproceedings{robertson_scalable_2004,
	address = {New York, NY, USA},
	series = {{AVI} '04},
	title = {Scalable {Fabric}: {Flexible} {Task} {Management}},
	isbn = {1-58113-867-9},
	url = {https://doi.org/10.1145/989863.989874},
	doi = {10.1145/989863.989874},
	abstract = {Our studies have shown that as displays become larger, users leave more windows open for easy multitasking. A larger number of windows, however, may increase the time that users spend arranging and switching between tasks. We present Scalable Fabric, a task management system designed to address problems with the proliferation of open windows on the PC desktop. Scalable Fabric couples window management with a flexible visual representation to provide a focus-plus-context solution to desktop complexity. Users interact with windows in a central focus region of the display in a normal manner, but when a user moves a window into the periphery, it shrinks in size, getting smaller as it nears the edge of the display. The window "minimize" action is redefined to return the window to its preferred location in the periphery, allowing windows to remain visible when not in use. Windows in the periphery may be grouped together into named tasks, and task switching is accomplished with a single mouse click. The spatial arrangement of tasks leverages human spatial memory to make task switching easier. We review the evolution of Scalable Fabric over three design iterations, including discussion of results from two user studies that were performed to compare the experience with Scalable Fabric to that of the Microsoft Windows XP TaskBar.},
	booktitle = {Proceedings of the {Working} {Conference} on {Advanced} {Visual} {Interfaces}},
	publisher = {Association for Computing Machinery},
	author = {Robertson, George and Horvitz, Eric and Czerwinski, Mary and Baudisch, Patrick and Hutchings, Dugald Ralph and Meyers, Brian and Robbins, Daniel and Smith, Greg},
	year = {2004},
	note = {event-place: Gallipoli, Italy},
	keywords = {interaction, scaling, spatial memory, task management},
	pages = {85--89},
}

@inproceedings{hutchings_display_2004,
	address = {New York, NY, USA},
	series = {{AVI} '04},
	title = {Display {Space} {Usage} and {Window} {Management} {Operation} {Comparisons} between {Single} {Monitor} and {Multiple} {Monitor} {Users}},
	isbn = {1-58113-867-9},
	url = {https://doi.org/10.1145/989863.989867},
	doi = {10.1145/989863.989867},
	abstract = {The continuing trend toward greater processing power, larger storage, and in particular increased display surface by using multiple monitor supports increased multi-tasking by the computer user. The concomitant increase in desktop complexity has the potential to push the overhead of window management to frustrating and counterproductive new levels. It is difficult to adequately design for multiple monitor systems without understanding how multiple monitor users differ from, or are similar to, single monitor users. Therefore, we deployed a tool to a group of single monitor and multiple monitor users to log window management activity. Analysis of the data collected from this tool revealed that usage of interaction components may change with an increase in number of monitors, and window visibility can be a useful measure of user display space management activity, especially for multiple monitor users. The results from this analysis begin to fill a gap in research about real-world window management practices.},
	booktitle = {Proceedings of the {Working} {Conference} on {Advanced} {Visual} {Interfaces}},
	publisher = {Association for Computing Machinery},
	author = {Hutchings, Dugald Ralph and Smith, Greg and Meyers, Brian and Czerwinski, Mary and Robertson, George},
	year = {2004},
	note = {event-place: Gallipoli, Italy},
	keywords = {UI logs, automation, multiple monitors, space management, user interaction, window management},
	pages = {32--39},
}

@inproceedings{tan_effects_2003,
	title = {Effects of visual separation and physical discontinuities when distributing information across multiple displays},
	volume = {3},
	booktitle = {Proc. {Interact}},
	author = {Tan, Desney S and Czerwinski, Mary},
	year = {2003},
	pages = {252--255},
}

@inproceedings{endert_designing_2012,
	address = {New York, NY, USA},
	series = {{AVI} '12},
	title = {Designing {Large} {High}-{Resolution} {Display} {Workspaces}},
	isbn = {978-1-4503-1287-5},
	url = {https://doi.org/10.1145/2254556.2254570},
	doi = {10.1145/2254556.2254570},
	abstract = {Large, high-resolution displays have enormous potential to aid in scenarios beyond their current usage. Their current usages are primarily limited to presentations, visualization demonstrations, or conducting experiments. In this paper, we present a new usage for such systems: an everyday workspace. We discuss how seemingly small large-display design decisions can have significant impacts on users' perceptions of these workspaces, and thus the usage of the space. We describe the effects that various physical configurations have on the overall usability and perception of the display. We present conclusions on how to broaden the usage scenarios of large, high-resolution displays to enable frequent and effective usage as everyday workspaces while still allowing transformation to collaborative or presentation spaces.},
	booktitle = {Proceedings of the {International} {Working} {Conference} on {Advanced} {Visual} {Interfaces}},
	publisher = {Association for Computing Machinery},
	author = {Endert, Alex and Bradel, Lauren and Zeitz, Jessica and Andrews, Christopher and North, Chris},
	year = {2012},
	note = {event-place: Capri Island, Italy},
	keywords = {large high-resolution displays},
	pages = {58--65},
}

@inproceedings{ball_move_2007,
	address = {New York, NY, USA},
	series = {{CHI} '07},
	title = {Move to {Improve}: {Promoting} {Physical} {Navigation} to {Increase} {User} {Performance} with {Large} {Displays}},
	isbn = {978-1-59593-593-9},
	url = {https://doi.org/10.1145/1240624.1240656},
	doi = {10.1145/1240624.1240656},
	abstract = {In navigating large information spaces, previous work indicates potential advantages of physical navigation (moving eyes, head, body) over virtual navigation (zooming, panning, flying). However, there is also indication of users preferring or settling into the less efficient virtual navigation. We present a study that examines these issues in the context of large, high resolution displays. The study identifies specific relationships between display size, amount of physical and virtual navigation, and user task performance. Increased physical navigation on larger displays correlates with reduced virtual navigation and improved user performance. Analyzing the differences between this study and previous results helps to identify design factors that afford and promote the use of physical navigation in the user interface.},
	booktitle = {Proceedings of the {SIGCHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Ball, Robert and North, Chris and Bowman, Doug A.},
	year = {2007},
	note = {event-place: San Jose, California, USA},
	keywords = {embodied interaction, large displays, physical navigation, virtual navigation},
	pages = {191--200},
}

@inproceedings{czerwinski_large_2006,
	address = {New York, NY, USA},
	series = {{CHI} {EA} '06},
	title = {Large {Display} {Research} {Overview}},
	isbn = {1-59593-298-4},
	url = {https://doi.org/10.1145/1125451.1125471},
	doi = {10.1145/1125451.1125471},
	abstract = {As large displays become more affordable, researchers are investigating their effects on productivity, and techniques for making the large display user experience more effective. Recent work has demonstrated significant productivity benefits, but has also identified numerous usability issues with current software design not scaling well. Studies show that larger displays enable users to create and manage many more windows, as well as to engage in more complex multitasking behavior. In this overview, various usability issues, including problems around accessing windows and icons at a distance, window management, and task management, will be discussedSeveral novel interaction techniques that address these issues and make users more productive across multiple sizes of displays will be explored.},
	booktitle = {{CHI} '06 {Extended} {Abstracts} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Czerwinski, Mary and Robertson, George and Meyers, Brian and Smith, Greg and Robbins, Daniel and Tan, Desney},
	year = {2006},
	note = {event-place: Montréal, Québec, Canada},
	keywords = {information visualization, interaction, large displays},
	pages = {69--74},
}

@inproceedings{czerwinski_toward_2003,
	title = {Toward characterizing the productivity benefits of very large displays.},
	volume = {3},
	booktitle = {Interact},
	author = {Czerwinski, Mary and Smith, Greg and Regan, Tim and Meyers, Brian and Robertson, George G and Starkweather, Gary K},
	year = {2003},
	pages = {9--16},
}

@article{robertson_large-display_2005,
	title = {The large-display user experience},
	volume = {25},
	doi = {10.1109/MCG.2005.88},
	number = {4},
	journal = {IEEE Computer Graphics and Applications},
	author = {Robertson, G. and Czerwinski, M. and Baudisch, P. and Meyers, B. and Robbins, D. and Smith, G. and Tan, D.},
	year = {2005},
	pages = {44--51},
}

@inproceedings{ball_effects_2005,
	address = {New York, NY, USA},
	series = {{CHI} {EA} '05},
	title = {Effects of {Tiled} {High}-{Resolution} {Display} on {Basic} {Visualization} and {Navigation} {Tasks}},
	isbn = {1-59593-002-7},
	url = {https://doi.org/10.1145/1056808.1056875},
	doi = {10.1145/1056808.1056875},
	abstract = {Large high-resolution screens are becoming increasingly available and less expensive. This creates potential advantages for data visualization in that more dense data and fine details are viewable at once. Also, less navigation may be needed to see more data. However, little work has been done to determine the effectiveness of large high-resolution displays, especially for basic low-level data visualization and navigation tasks. This paper describes an exploratory study on the effects of a large tiled display with a resolution of 3840x3072 as compared to two smaller displays (1560x2048 and 1280x1024). We conclude that, with finely detailed data, higher resolution displays that use physical navigation significantly outperform smaller displays that use pan and zoom navigation. Qualitatively, we also conclude that use of the larger display is less stressful and creates a better sense of confidence than the smaller displays.},
	booktitle = {{CHI} '05 {Extended} {Abstracts} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Ball, Robert and North, Chris},
	year = {2005},
	note = {event-place: Portland, OR, USA},
	keywords = {high-resolution display, information visualization},
	pages = {1196--1199},
}

@misc{noauthor_hololens_nodate,
	title = {{HoloLens} 2},
	url = {https://www.microsoft.com/en-us/hololens},
	urldate = {2020-05-10},
}

@incollection{hancock_development_1988,
	series = {Advances in {Psychology}},
	title = {Development of {NASA}-{TLX} ({Task} {Load} {Index}): {Results} of {Empirical} and {Theoretical} {Research}},
	volume = {52},
	url = {http://www.sciencedirect.com/science/article/pii/S0166411508623869},
	abstract = {The results of a multi-year research program to identify the factors associated with variations in subjective workload within and between different types of tasks are reviewed. Subjective evaluations of 10 workload-related factors were obtained from 16 different experiments. The experimental tasks included simple cognitive and manual control tasks, complex laboratory and supervisory control tasks, and aircraft simulation. Task-, behavior-, and subject-related correlates of subjective workload experiences varied as a function of difficulty manipulations within experiments, different sources of workload between experiments, and individual differences in workload definition. A multi-dimensional rating scale is proposed in which information about the magnitude and sources of six workload-related factors are combined to derive a sensitive and reliable estimate of workload.},
	booktitle = {Human {Mental} {Workload}},
	publisher = {North-Holland},
	author = {Hart, Sandra G. and Staveland, Lowell E.},
	editor = {Hancock, Peter A. and Meshkati, Najmedin},
	year = {1988},
	doi = {10.1016/S0166-4115(08)62386-9},
	note = {ISSN: 0166-4115},
	pages = {139 -- 183},
}

@article{grubert_office_2018,
	title = {The {Office} of the {Future}: {Virtual}, {Portable}, and {Global}},
	volume = {38},
	number = {6},
	journal = {IEEE Computer Graphics and Applications},
	author = {Grubert, J. and Ofek, E. and Pahud, M. and Kristensson, P. O.},
	year = {2018},
	pages = {125--133},
}

@inproceedings{harrison_omnitouch_2011,
	address = {New York, NY, USA},
	series = {{UIST} ’11},
	title = {{OmniTouch}: {Wearable} {Multitouch} {Interaction} {Everywhere}},
	isbn = {978-1-4503-0716-1},
	url = {https://doi.org/10.1145/2047196.2047255},
	doi = {10.1145/2047196.2047255},
	booktitle = {Proceedings of the 24th {Annual} {ACM} {Symposium} on {User} {Interface} {Software} and {Technology}},
	publisher = {Association for Computing Machinery},
	author = {Harrison, Chris and Benko, Hrvoje and Wilson, Andrew D.},
	year = {2011},
	note = {event-place: Santa Barbara, California, USA},
	keywords = {appropriated surfaces, finger tracking, object classification, on-body computing, on-demand interfaces},
	pages = {441--450},
}

@article{henderson_opportunistic_2010,
	title = {Opportunistic {Tangible} {User} {Interfaces} for {Augmented} {Reality}},
	volume = {16},
	number = {1},
	journal = {IEEE Transactions on Visualization and Computer Graphics},
	author = {Henderson, S. and Feiner, S.},
	year = {2010},
	pages = {4--16},
}

@inproceedings{soares_evaluating_2019,
	address = {New York, NY, USA},
	series = {{SUI} ’19},
	title = {Evaluating the {Impact} of {Point} {Marking} {Precision} on {Situated} {Modeling} {Performance}},
	copyright = {All rights reserved},
	isbn = {978-1-4503-6975-6},
	url = {https://doi.org/10.1145/3357251.3357586},
	doi = {10.1145/3357251.3357586},
	booktitle = {2019 {ACM} {Symposium} on {Spatial} {User} {Interaction} ({SUI})},
	publisher = {Association for Computing Machinery},
	author = {Soares, Leonardo Pavanatto and Bowman, Doug A. and Pinho, Márcio Sarroglia},
	year = {2019},
	note = {event-place: New Orleans, LA, USA},
	keywords = {3d modeling, augmented reality, user studies},
}

@inproceedings{duchowski_binocular_2000,
	address = {New York, NY, USA},
	series = {{ETRA} ’00},
	title = {Binocular {Eye} {Tracking} in {Virtual} {Reality} for {Inspection} {Training}},
	isbn = {1-58113-280-8},
	url = {https://doi.org/10.1145/355017.355031},
	doi = {10.1145/355017.355031},
	booktitle = {Proceedings of the 2000 {Symposium} on {Eye} {Tracking} {Research} \& {Applications}},
	publisher = {Association for Computing Machinery},
	author = {Duchowski, Andrew T. and Shivashankaraiah, Vinay and Rawls, Tim and Gramopadhye, Anand K. and Melloy, Brian J. and Kanki, Barbara},
	year = {2000},
	note = {event-place: Palm Beach Gardens, Florida, USA},
	keywords = {eye tracking, virtual reality, visual inspection},
	pages = {89--96},
}

@inproceedings{bowman_evaluation_1997,
	address = {New York, NY, USA},
	series = {{I3D} ’97},
	title = {An {Evaluation} of {Techniques} for {Grabbing} and {Manipulating} {Remote} {Objects} in {Immersive} {Virtual} {Environments}},
	isbn = {0-89791-884-3},
	url = {https://doi.org/10.1145/253284.253301},
	doi = {10.1145/253284.253301},
	booktitle = {Proceedings of the 1997 {Symposium} on {Interactive} {3D} {Graphics}},
	publisher = {Association for Computing Machinery},
	author = {Bowman, Doug A. and Hodges, Larry F.},
	year = {1997},
	note = {event-place: Providence, Rhode Island, USA},
	pages = {35--ff.},
}

@inproceedings{andrews_space_2010,
	address = {New York, NY, USA},
	series = {{CHI} ’10},
	title = {Space to {Think}: {Large} {High}-{Resolution} {Displays} for {Sensemaking}},
	isbn = {978-1-60558-929-9},
	url = {https://doi.org/10.1145/1753326.1753336},
	doi = {10.1145/1753326.1753336},
	booktitle = {Proceedings of the {SIGCHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Andrews, Christopher and Endert, Alex and North, Chris},
	year = {2010},
	note = {event-place: Atlanta, Georgia, USA},
	keywords = {high-resolution displays, large},
	pages = {55--64},
}

@article{lipowski_sensory_1975,
	title = {Sensory and information inputs overload: {Behavioral} effects},
	volume = {16},
	issn = {0010-440X},
	url = {http://www.sciencedirect.com/science/article/pii/0010440X75900474},
	doi = {10.1016/0010-440X(75)90047-4},
	number = {3},
	journal = {Comprehensive Psychiatry},
	author = {Lipowski, Z.J.},
	month = may,
	year = {1975},
	pages = {199--221},
}

@misc{the_national_autistic_society_autism_2016,
	title = {Autism {TMI} {Virtual} {Reality} {Experience}},
	url = {https://www.youtube.com/watch?v=DgDR_gYk_a8},
	author = {The National Autistic Society},
	year = {2016},
}

@article{robertson_sensory_2017,
	title = {Sensory perception in autism},
	volume = {18},
	issn = {1471-0048},
	url = {https://doi.org/10.1038/nrn.2017.112},
	doi = {10.1038/nrn.2017.112},
	abstract = {Sensory symptoms have been observed since early reports of autism spectrum conditions but historically were thought to represent secondary consequences of differences in social-cognitive processing.Developmental research suggests that sensory symptoms manifest early in development and contribute unique variance to the diagnostic criteria of autism.Neuroimaging evidence suggests that sensory symptoms originate from differences in low-level processing in sensory-dedicated regions in the autistic brain and offer insight into circuit-level alterations.Although common behavioural paradigms are not yet in place, sensory-processing differences are evident in genetic animal models of the condition and may represent promising translatable biomarkers of autism.},
	number = {11},
	journal = {Nature Reviews Neuroscience},
	author = {Robertson, Caroline E. and Baron-Cohen, Simon},
	month = nov,
	year = {2017},
	pages = {671--684},
}

@article{hazen_sensory_2014,
	title = {Sensory {Symptoms} in {Autism} {Spectrum} {Disorders}},
	volume = {22},
	issn = {1067-3229},
	url = {https://journals.lww.com/hrpjournal/Fulltext/2014/03000/Sensory_Symptoms_in_Autism_Spectrum_Disorders.6.aspx},
	abstract = {The aim of this review is to summarize the recent literature regarding abnormalities in sensory functioning in individuals with autism spectrum disorder (ASD), including evidence regarding the neurobiological basis of these symptoms, their clinical correlates, and their treatment. Abnormalities in responses to sensory stimuli are highly prevalent in individuals with ASD. The underlying neurobiology of these symptoms is unclear, but several theories have been proposed linking possible etiologies of sensory dysfunction with known abnormalities in brain structure and function that are associated with ASD. In addition to the distress that sensory symptoms can cause patients and caregivers, these phenomena have been correlated with several other problematic symptoms and behaviors associated with ASD, including restrictive and repetitive behavior, self-injurious behavior, anxiety, inattention, and gastrointestinal complaints. It is unclear whether these correlations are causative in nature or whether they are due to shared underlying pathophysiology. The best-known treatments for sensory symptoms in ASD involve a program of occupational therapy that is specifically tailored to the needs of the individual and that may include sensory integration therapy, a sensory diet, and environmental modifications. While some empirical evidence supports these treatments, more research is needed to evaluate their efficacy, and other means of alleviating these symptoms, including possible psychopharmacological interventions, need to be explored. Additional research into the sensory symptoms associated with ASD has the potential to shed more light on the nature and pathophysiology of these disorders and to open new avenues of effective treatments.},
	number = {2},
	journal = {Harvard Review of Psychiatry},
	author = {Hazen, Eric P. and Stornelli, Jennifer L. and O’Rourke, Julia A. and Koesterer, Karmen and McDougle, Christopher J.},
	year = {2014},
	keywords = {autism spectrum disorder, pervasive developmental delay, sensory integration, sensory overresponsitivity, sensory processing},
}

@inproceedings{schinke_visualization_2010,
	address = {New York, NY, USA},
	series = {{MobileHCI} '10},
	title = {Visualization of {Off}-screen {Objects} in {Mobile} {Augmented} {Reality}},
	isbn = {978-1-60558-835-3},
	url = {http://doi.acm.org/10.1145/1851600.1851655},
	doi = {10.1145/1851600.1851655},
	booktitle = {Proceedings of the 12th {International} {Conference} on {Human} {Computer} {Interaction} with {Mobile} {Devices} and {Services}},
	publisher = {ACM},
	author = {Schinke, Torben and Henze, Niels and Boll, Susanne},
	year = {2010},
	note = {event-place: Lisbon, Portugal},
	keywords = {augmented reality, mobile phone, orientation},
	pages = {313--316},
}

@inproceedings{wagner_first_2003,
	address = {Washington, DC, USA},
	series = {{ISWC} '03},
	title = {First {Steps} {Towards} {Handheld} {Augmented} {Reality}},
	isbn = {0-7695-2034-0},
	url = {http://dl.acm.org/citation.cfm?id=946249.946910},
	booktitle = {Proceedings of the 7th {IEEE} {International} {Symposium} on {Wearable} {Computers}},
	publisher = {IEEE Computer Society},
	author = {Wagner, Daniel and Schmalstieg, Dieter},
	year = {2003},
	keywords = {Augmented Reality, Mobile Computing, PDA, Tracking},
	pages = {127--},
}

@article{mulloni_enhancing_2012,
	title = {Enhancing handheld navigation systems with augmented reality},
	journal = {Service Oriented Mapping},
	author = {Mulloni, Alessandro and Schmalstieg, Dieter},
	year = {2012},
	pages = {63--80},
}

@inproceedings{reitmayr_collaborative_2003,
	title = {Collaborative {Augmented} {Reality} for {Outdoor} {Navigation} and {Information} {Browsing}},
	language = {English},
	booktitle = {Proceedings of the 2nd {Symposium} on {Location} {Based} {Services} and {TeleCartography}},
	publisher = {.},
	author = {Reitmayr, Gerhard and Schmalstieg, Dieter},
	year = {2003},
	pages = {53--62},
}

@phdthesis{sida_li_augmented_2016,
	type = {{PhD} {Thesis}},
	title = {Augmented {Reality} {Persistent} {Annotation}},
	school = {Graduate Dissertations and Theses at University of Illinois at Urbana-Champaign},
	author = {Sida Li, David Forsyth},
	month = apr,
	year = {2016},
}

@article{narzt_augmented_2006,
	title = {Augmented reality navigation systems},
	volume = {4},
	issn = {1615-5297},
	url = {https://doi.org/10.1007/s10209-005-0017-5},
	doi = {10.1007/s10209-005-0017-5},
	abstract = {The augmented reality (AR) research community has been developing a manifold of ideas and concepts to improve the depiction of virtual objects in a real scene. In contrast, current AR applications require the use of unwieldy equipment which discourages their use. In order to essentially ease the perception of digital information and to naturally interact with the pervasive computing landscape, the required AR equipment has to be seamlessly integrated into the user's natural environment. Considering this basic principle, this paper proposes the car as an AR apparatus and presents an innovative visualization paradigm for navigation systems that is anticipated to enhance user interaction.},
	number = {3},
	journal = {Universal Access in the Information Society},
	author = {Narzt, Wolfgang and Pomberger, Gustav and Ferscha, Alois and Kolb, Dieter and Müller, Reiner and Wieghardt, Jan and Hörtner, Horst and Lindinger, Christopher},
	month = mar,
	year = {2006},
	pages = {177--187},
}

@inproceedings{azuma_making_1999,
	address = {Natick, MA, USA},
	series = {{IWAR} '98},
	title = {Making {Augmented} {Reality} {Work} {Outdoors} {Requires} {Hybrid} {Tracking}},
	isbn = {1-56881-098-9},
	url = {http://dl.acm.org/citation.cfm?id=322690.322709},
	booktitle = {Proceedings of the {International} {Workshop} on {Augmented} {Reality} : {Placing} {Artificial} {Objects} in {Real} {Scenes}: {Placing} {Artificial} {Objects} in {Real} {Scenes}},
	publisher = {A. K. Peters, Ltd.},
	author = {Azuma, Ronald T. and Hoff, Bruce R. and Neely, III, Howard E. and Sarfaty, Ronald and Daily, Michael J. and Bishop, Gary and Vicci, Leandra and Welch, Greg and Neumann, Ulrich and You, Suya and You, Suya and Nichols, Rich and Cannon, Jim},
	year = {1999},
	note = {event-place: Bellevue, Washington, USA},
	pages = {219--224},
}

@book{whitelegg_hikar_2019,
	title = {Hikar - {Augmented} reality for hikers {Developing} an app and framework for outdoor {AR}},
	author = {Whitelegg, Nick},
	month = mar,
	year = {2019},
	note = {Published: FOSDEM 19' Conference},
}

@inproceedings{piekarski_bread_2002,
	title = {Bread {Crumbs}: a technique for modelling large outdoor ground features},
	doi = {10.1109/ISMAR.2002.1115107},
	booktitle = {Proceedings of the {International} {Symposium} on {Mixed} and {Augmented} {Reality}},
	author = {Piekarski, Wayne and Thomas, Bruce H.},
	month = oct,
	year = {2002},
	keywords = {Augmented reality, Bread Crumbs, Cameras, Control systems, Fingers, Geometry, Lakes, Mobile computing, Solid modeling, User interfaces, Wearable computers, augmented reality, complex outdoor geometry, large outdoor ground feature modelling, mobile augmented reality system, mobile computing, on-campus large grassy area, user physical presence},
	pages = {269--321},
}

@inproceedings{lages_enhanced_2019,
	title = {Enhanced {Geometric} {Techniques} for {Point} {Marking} in {Augmented} {Reality}},
	booktitle = {Proceedings of the {International} {Symposium} on {Mixed} and {Augmented} {Reality}},
	author = {Lages, Wallace and Li, Yuan and Lisle, Lee and Höllerer, Tobias and Bowman, Doug},
	year = {2019},
}

@article{klerk_usability_2019,
	title = {Usability studies on building early stage architectural models in virtual reality},
	volume = {103},
	issn = {0926-5805},
	url = {http://www.sciencedirect.com/science/article/pii/S0926580517311378},
	doi = {https://doi.org/10.1016/j.autcon.2019.03.009},
	abstract = {Despite its marked success in recent years, it is still not clear how Virtual Reality (VR) can assist architects at the early stages of ideation and design. In this paper, we approach VR to build and explore maquettes at different scales in early design stages. To this end we developed a VR environment where user interactions are supported by untethered, easy to operate, peripherals, using a mobile virtual reality headset to provide virtual immersion and simplified geometric information to create voxel-based maquettes. Usability studies with laypeople suggest that the proposed system is both easier to use and more effective [better suited] than current CAD software to rapidly create simplified models. Additionally, tests with architects have shown the system's potential to improve their toolset. This is partly due to VR combining real-time performance with immersive exploration of the content, where body-scale relationships become visible to support the creative process, allowing architects to become both builders and explores of spatial constructs.},
	journal = {Automation in Construction},
	author = {Klerk, Rui de and Duarte, André Mendes and Medeiros, Daniel Pires and Duarte, José Pinto and Jorge, Joaquim and Lopes, Daniel Simões},
	year = {2019},
	keywords = {Architectural design, Box shaped objects, Case studies, Early stage maquette, Professional evaluation, User participation, Virtual reality, Voxel-based modeling},
	pages = {104 -- 116},
}

@article{jackson_lift-off:_2016,
	title = {Lift-{Off}: {Using} {Reference} {Imagery} and {Freehand} {Sketching} to {Create} {3D} {Models} in {VR}},
	volume = {22},
	issn = {1077-2626},
	doi = {10.1109/TVCG.2016.2518099},
	number = {4},
	journal = {IEEE Transactions on Visualization and Computer Graphics},
	author = {Jackson, B. and Keefe, D. F.},
	month = apr,
	year = {2016},
	keywords = {2D curve, 2D sketch, 3D User Interfaces, 3D sailboat model, 3D scaffolding, Animals, Art, Artiodactyla, Computational modeling, Computer Graphics, Equipment Design, Humans, Imaging, Immersive 3D Modeling, Lift-Off, Models, Shape, Sketch-based Modeling, Solid modeling, Surface treatment, Theoretical, Three-Dimensional, Three-dimensional displays, User interfaces, User-Computer Interface, VR interface, VR-based 3D modeling tool, Virtual Reality, art, freehand sketching, handcrafted style, image processing, image processing algorithm, immersive 3D interface, reference imagery, scratch, user interfaces, virtual reality},
	pages = {1442--1451},
}

@inproceedings{bunnun_outlinar:_2008,
	address = {Washington, DC, USA},
	series = {{ISMAR} '08},
	title = {{OutlinAR}: {An} {Assisted} {Interactive} {Model} {Building} {System} with {Reduced} {Computational} {Effort}},
	isbn = {978-1-4244-2840-3},
	url = {https://doi.org/10.1109/ISMAR.2008.4637325},
	doi = {10.1109/ISMAR.2008.4637325},
	booktitle = {Proceedings of the 7th {IEEE}/{ACM} {International} {Symposium} on {Mixed} and {Augmented} {Reality}},
	publisher = {IEEE Computer Society},
	author = {Bunnun, Pished and Mayol-Cuevas, Walterio W.},
	year = {2008},
	pages = {61--64},
}

@inproceedings{soares_evaluation_2018,
	title = {Evaluation of {Selection} {Techniques} on a {Mobile} {Augmented} {Reality} {Game}},
	copyright = {All rights reserved},
	doi = {10.1109/SBGAMES.2018.00024},
	booktitle = {2018 17th {Brazilian} {Symposium} on {Computer} {Games} and {Digital} {Entertainment} ({SBGames})},
	author = {Soares, L. P. and Musse, S. R. and Pinho, M. S. and Boussu, J. B.},
	month = oct,
	year = {2018},
	keywords = {3D interaction techniques, Birds, Games, Performance evaluation, Prototypes, Solid modeling, Task analysis, Three-dimensional displays, augmented reality, computer games, crowds behavior, different metaphors, flocking behavior, game, interactive systems, mobile augmented reality game, mobile computing, selection techniques, surface interaction metaphor, user interaction, virtual reality},
	pages = {127--136},
}

@inproceedings{soares_collaborative_2016,
	title = {Collaborative hybrid virtual environment},
	copyright = {All rights reserved},
	doi = {10.1109/3DUI.2016.7460081},
	booktitle = {2016 {IEEE} {Symposium} on {3D} {User} {Interfaces} ({3DUI})},
	author = {Soares, Leonardo Pavanatto and De Oliveira, Thomas Volpato and Sangalli, Vicenzo Abichequer and Pinho, Márcio Sarroglia and Kopper, Regis},
	month = mar,
	year = {2016},
	pages = {283--284},
}

@inproceedings{soares_design_2017,
	title = {Design and preliminary evaluation of an {EGO}-exocentric technique for cooperative manipulation},
	copyright = {All rights reserved},
	doi = {10.1109/3DUI.2017.7893342},
	booktitle = {2017 {IEEE} {Symposium} on {3D} {User} {Interfaces} ({3DUI})},
	author = {Soares, Leonardo Pavanatto and Pinho, Márcio Sarroglia and Kopper, Regis},
	month = mar,
	year = {2017},
	pages = {203--204},
}

@inproceedings{copstein_image_2018,
	title = {Image {Processing} {Strategies} for {Automatic} {Detection} of {Common} {Gastroenterological} {Diseases}},
	volume = {01},
	copyright = {All rights reserved},
	doi = {10.1109/COMPSAC.2018.00090},
	booktitle = {2018 {IEEE} 42nd {Annual} {Computer} {Software} and {Applications} {Conference} ({COMPSAC})},
	author = {Copstein, Rafael Neujahr and Abichequer, Vicenzo and Andrade, Matheus Cruz and Machado, Lucas Almeida and Rodrigues, Evandro and Soares, Leonardo Pavanatto and Pinho, Márcio Sarroglia},
	month = jul,
	year = {2018},
	keywords = {Bars, CLE, Cancer, Esophagus, GLCM attributes, Histograms, LBP attributes, Machine learning, Training, baseline classifier, classic texture description techniques, confocal laser endomicroscopy, diseases, endoscopes, esophageal cancer, gastroenterological diseases, gray level co-occurrence matrices, image classification, image processing, image processing strategies, image texture, local binary patterns, machine learning, manual analysis, medical image processing, optical microscopy, texture analysis techniques, wrong diagnostics},
	pages = {593--598},
}

@inproceedings{sangalli_sculptar:_2017,
	title = {{SculptAR}: {An} augmented reality interaction system},
	copyright = {All rights reserved},
	doi = {10.1109/3DUI.2017.7893371},
	booktitle = {2017 {IEEE} {Symposium} on {3D} {User} {Interfaces}  ({3DUI})},
	author = {Sangalli, Vicenzo Abichequer and De Oliveira, Thomas Volpato and Soares, Leonardo Pavanatto and Pinho, Márcio Sarroglia},
	month = mar,
	year = {2017},
	pages = {260--261},
}

@inproceedings{endsley_situation_1988,
	title = {Situation awareness global assessment technique ({SAGAT})},
	doi = {10.1109/NAECON.1988.195097},
	booktitle = {Proceedings of the {IEEE} 1988 {National} {Aerospace} and {Electronics} {Conference}},
	author = {Endsley, M. R.},
	month = may,
	year = {1988},
	keywords = {Aircraft, Current measurement, Decision making, Displays, Human factors, Jacobian matrices, Process design, SAGAT methology, System performance, Vehicle driving, aircraft design, aircraft instrumentation, cockpits, human factors, military systems, pilot-vehicle interface designs, situation-awareness global assessment technique},
	pages = {789--795 vol.3},
}

@inproceedings{zhi-hua_design_2008,
	title = {Design of {UAV} {Telepresence} and {Simulation} {Platform} {Based} on {VR}},
	doi = {10.1109/CW.2008.113},
	booktitle = {2008 {International} {Conference} on {Cyberworlds}},
	author = {Zhi-Hua, Q. and Yi-Bo, L. and Shao-Peng, K. and Qiong, Z.},
	month = sep,
	year = {2008},
	keywords = {Aerospace control, Aircraft manufacture, Cameras, Computational modeling, Computer displays, Feedback, Geography, Prototypes, UAV control method, UAV pilot training, UAV telepresence, Unmanned aerial vehicles, Virtual reality, aerospace engineering, aircraft, digital simulation, geography data information, man-control aircraft, man-in-the-onboard-loop, remotely operated vehicles, simulation platform, telepresence virtual reality technology, training, virtual reality},
	pages = {520--524},
}

@inproceedings{zhang_deep_2018,
	title = {Deep {Imitation} {Learning} for {Complex} {Manipulation} {Tasks} from {Virtual} {Reality} {Teleoperation}},
	doi = {10.1109/ICRA.2018.8461249},
	booktitle = {2018 {IEEE} {International} {Conference} on {Robotics} and {Automation} ({ICRA})},
	author = {Zhang, T. and McCarthy, Z. and Jow, O. and Lee, D. and Chen, X. and Goldberg, K. and Abbeel, P.},
	month = may,
	year = {2018},
	keywords = {Grippers, Head, Neural networks, PR2 robot, RGB-D images, Robots, Task analysis, Three-dimensional displays, Visualization, consumer-grade Virtual Reality headsets, control engineering computing, deep imitation learning, deep neural network policies, hand tracking hardware, human-robot interaction, learning by example, manipulation tasks, manipulators, neural nets, raw pixels, robot programming, robot skill acquisition, robot vision, telerobotics, virtual reality, virtual reality teleoperation},
	pages = {1--8},
}

@article{sheridan_humanrobot_2016,
	title = {Human–{Robot} {Interaction}: {Status} and {Challenges}},
	volume = {58},
	url = {https://doi.org/10.1177/0018720816644364},
	doi = {10.1177/0018720816644364},
	abstract = {Objective:The current status of human–robot interaction (HRI) is reviewed, and key current research challenges for the human factors community are described.Background:Robots have evolved from continuous human-controlled master–slave servomechanisms for handling nuclear waste to a broad range of robots incorporating artificial intelligence for many applications and under human supervisory control.Methods:This mini-review describes HRI developments in four application areas and what are the challenges for human factors research.Results:In addition to a plethora of research papers, evidence of success is manifest in live demonstrations of robot capability under various forms of human control.Conclusions:HRI is a rapidly evolving field. Specialized robots under human teleoperation have proven successful in hazardous environments and medical application, as have specialized telerobots under human supervisory control for space and repetitive industrial tasks. Research in areas of self-driving cars, intimate collaboration with humans in manipulation tasks, human control of humanoid robots for hazardous environments, and social interaction with robots is at initial stages. The efficacy of humanoid general-purpose robots has yet to be proven.Applications:HRI is now applied in almost all robot tasks, including manufacturing, space, aviation, undersea, surgery, rehabilitation, agriculture, education, package fetch and delivery, policing, and military operations.},
	number = {4},
	journal = {Human Factors},
	author = {Sheridan, Thomas B.},
	year = {2016},
	pmid = {27098262},
	pages = {525--532},
}

@article{sheridan_teleoperation_1995,
	title = {Teleoperation, telerobotics and telepresence: {A} progress report},
	volume = {3},
	issn = {0967-0661},
	url = {http://www.sciencedirect.com/science/article/pii/096706619400078U},
	doi = {https://doi.org/10.1016/0967-0661(94)00078-U},
	abstract = {This paper briefly surveys and reports progress in the field of teleoperation, meaning human control of remote sensors and actuators. Included is the subclass of teleoperation called telerobotics, which means human supervisory control of remote semiautomatic systems, and the phenomenon of telepresence, in which special sensing and display technology enables the human to feel present at the remote location even though not really there. Current and new applications are reviewed. Techniques for human-computer cooperation in planning, commanding, and sensing are described. The telerobot is considered as a paradigm for any complex vehicle or process having many separate automatic control loops all of which are supervised by a human; some current examples are presented. Finally, opinions are given as to the current status of the field.},
	number = {2},
	journal = {Control Engineering Practice},
	author = {Sheridan, T. B.},
	year = {1995},
	keywords = {artificial intelligence, computer interfaces, human factors, man-machine systems, manipulation, robotics, telerobotics},
	pages = {205 -- 214},
}

@book{sheridan_telerobotics_1992,
	title = {Telerobotics, automation, and human supervisory control},
	publisher = {MIT press},
	author = {Sheridan, Thomas B},
	year = {1992},
}

@inproceedings{rakita_motion_2017,
	address = {New York, NY, USA},
	series = {{HRI} '17},
	title = {A {Motion} {Retargeting} {Method} for {Effective} {Mimicry}-based {Teleoperation} of {Robot} {Arms}},
	isbn = {978-1-4503-4336-7},
	url = {http://doi.acm.org/10.1145/2909824.3020254},
	doi = {10.1145/2909824.3020254},
	booktitle = {Proceedings of the 2017 {ACM}/{IEEE} {International} {Conference} on {Human}-{Robot} {Interaction}},
	publisher = {ACM},
	author = {Rakita, Daniel and Mutlu, Bilge and Gleicher, Michael},
	year = {2017},
	note = {event-place: Vienna, Austria},
	keywords = {kinematics, motion retargeting, robot control interface, telemanipulation, teleoperation},
	pages = {361--370},
}

@inproceedings{mamessier_calibration_2014,
	address = {Cham},
	title = {Calibration of {Online} {Situation} {Awareness} {Assessment} {Systems} {Using} {Virtual} {Reality}},
	isbn = {978-3-319-07725-3},
	abstract = {In an attempt to predict and prevent accident situations in complex socio-technical systems, one needs to be able to model and simulate concepts such as situation awareness (SA) and processes responsible for maintaining it. This is particularly true in the case of online support systems and adaptive displays which cannot rely on SA measurement techniques based on freeze probe techniques. This work investigates the state of the art in computational models of situation awareness and proposes a method to calibrate and evaluate such models using virtual reality human-in-the-loop experiments. This work introduces a new methodology to evaluate and calibrate online SA assessment systems taking advantage of the flexibility and reconfigurable power of virtual reality environments. This technology provides the experimenter with full control on the scenarios, cockpit types and interfaces. It also allows testing of off-nominal situations such as the loss of an instrument and more severe failures. Moreover, eye tracking capabilities provide an accurate way of registering monitoring events and feed SA assessment models with realistic data.},
	booktitle = {Digital {Human} {Modeling}. {Applications} in {Health}, {Safety}, {Ergonomics} and {Risk} {Management}},
	publisher = {Springer International Publishing},
	author = {Mamessier, Sebastien and Dreyer, Daniel and Oberhauser, Matthias},
	editor = {Duffy, Vincent G.},
	year = {2014},
	pages = {124--135},
}

@inproceedings{maeda_pathfinder_2014,
	title = {Pathfinder {Vision}: {Tele}-operation {Robot} {Interface} in {Consideration} of {Geometry} for {Supporting} {Future} {Prediction}.},
	booktitle = {{ICAT}-{EGVE}},
	author = {Maeda, Naoya and Morita, Jun and Sugimoto, Maki},
	year = {2014},
	pages = {29--35},
}

@inproceedings{higuchi_immerseboard:_2015,
	address = {New York, NY, USA},
	series = {{CHI} '15},
	title = {{ImmerseBoard}: {Immersive} {Telepresence} {Experience} {Using} a {Digital} {Whiteboard}},
	isbn = {978-1-4503-3145-6},
	url = {http://doi.acm.org/10.1145/2702123.2702160},
	doi = {10.1145/2702123.2702160},
	booktitle = {Proceedings of the 33rd {Annual} {ACM} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {ACM},
	author = {Higuchi, Keita and Chen, Yinpeng and Chou, Philip A. and Zhang, Zhengyou and Liu, Zicheng},
	year = {2015},
	note = {event-place: Seoul, Republic of Korea},
	keywords = {collaboration, immersive experience, telepresence},
	pages = {2383--2392},
}

@article{gardner_examining_2017,
	title = {Examining the feasibility and predictive validity of the {SAGAT} tool to assess situation awareness among medical trainees},
	volume = {12},
	number = {1},
	journal = {Simulation in Healthcare},
	author = {Gardner, Aimee K and Kosemund, Matthew and Martinez, Joseph},
	year = {2017},
	pages = {17--21},
}

@incollection{jones_chapter_2017,
	address = {Boston},
	edition = {Second Edition},
	title = {Chapter 29 - {Enhancing} {Situation} {Awareness} in {Power} {Systems}: {Overcoming} {Uncertainty} and {Variability} with {Renewable} {Resources}},
	isbn = {978-0-12-809592-8},
	url = {http://www.sciencedirect.com/science/article/pii/B9780128095928000299},
	abstract = {Reliable, sustained operation of today's highly interconnected electric power systems cannot be accomplished safely and effectively without high levels of situation awareness (SA). As the industry advances toward a renewable, energy-friendly smart grid, compensating for the complications and challenges that variable generation imposes on operator SA within transmission and distribution control centers becomes increasingly important. This chapter discusses how to overcome uncertainty and variability with renewable resources through the use of SA-Oriented Design to ensure that system operators are presented with the right information at the right time in an effective, integrated manner so that they can fully understand the state of a complex and dynamically changing system, project future changes, and respond in a timely manner.},
	booktitle = {Renewable {Energy} {Integration} ({Second} {Edition})},
	publisher = {Academic Press},
	author = {Endsley, Mica R. and Connors, Erik S.},
	editor = {Jones, Lawrence E.},
	year = {2017},
	doi = {10.1016/B978-0-12-809592-8.00029-9},
	keywords = {Decision support tools, Display design, Renewable energy situation awareness, Uncertainty, Visualization},
	pages = {395 -- 404},
}

@article{endsley_theoretical_2000,
	title = {Theoretical underpinnings of situation awareness: {A} critical review},
	volume = {1},
	journal = {Situation awareness analysis and measurement},
	author = {Endsley, Mica R and Garland, Daniel J and {others}},
	year = {2000},
	pages = {24},
}

@book{council_virtual_1995,
	title = {Virtual reality: scientific and technological challenges},
	publisher = {National Academies Press},
	author = {Council, National Research and {others}},
	year = {1995},
}

@inproceedings{coad_training_2017,
	title = {Training in divergent and convergent force fields during 6-{DOF} teleoperation with a robot-assisted surgical system},
	doi = {10.1109/WHC.2017.7989900},
	booktitle = {2017 {IEEE} {World} {Haptics} {Conference} ({WHC})},
	author = {Coad, M. M. and Okamura, A. M. and Wren, S. and Mintz, Y. and Lendvay, T. S. and Jarc, A. M. and Nisky, I.},
	month = jun,
	year = {2017},
	keywords = {6-DOF teleoperation, Force, Grippers, Instruments, Robot kinematics, Surgery, Training, convergent force fields, da Vinci research kit, divergent force fields, force fields, human motor learning, learning (artificial intelligence), learning mechanisms, manipulation task, manipulators, medical robotics, minimally invasive surgery training, patient outcomes, peg transfer task, point-to-point reaching tasks, surgeons, surgery, teleoperated robot-assisted surgical system, teleoperation systems, telerobotics},
	pages = {195--200},
}

@article{casper_human-robot_2003,
	title = {Human-robot interactions during the robot-assisted urban search and rescue response at the {World} {Trade} {Center}},
	volume = {33},
	issn = {1083-4419},
	doi = {10.1109/TSMCB.2003.811794},
	number = {3},
	journal = {IEEE Transactions on Systems, Man, and Cybernetics, Part B (Cybernetics)},
	author = {Casper, J. and Murphy, R. R.},
	month = jun,
	year = {2003},
	keywords = {Cities and towns, Computer science, Disaster management, HRI, Human robot interaction, Informatics, Information analysis, Inspection, Performance analysis, Terrorism, Video recording, World Trade Center rescue, assistive interfaces, emergency services, group organization, human-robot interactions, man-machine systems, perceptual interfaces, robots, urban search and rescue response, user confidence studies},
	pages = {367--385},
}

@inproceedings{casper_workflow_2002,
	title = {Workflow study on human-robot interaction in {USAR}},
	volume = {2},
	doi = {10.1109/ROBOT.2002.1014834},
	booktitle = {Proceedings 2002 {IEEE} {International} {Conference} on {Robotics} and {Automation} ({Cat}. {No}.{02CH37292})},
	author = {Casper, J. L. and Murphy, R. R.},
	month = may,
	year = {2002},
	keywords = {Fires, Frequency, Human robot interaction, Intelligent robots, Mobile robots, Prototypes, Robot sensing systems, Robotics and automation, Terrorism, Testing, USAR, collaborative teleoperation, emergency services, fire rescue department, human-robot interaction, man-machine systems, mobile robots, multirobot strategy, stairwell search, tactical mobile robots, topological search, urban rescue, urban search, workflow study},
	pages = {1997--2003 vol.2},
}

@techreport{bruemmer_intelligent_2002,
	title = {Intelligent robots for use in hazardous {DOE} environments},
	institution = {IDAHO NATIONAL ENGINEERING AND ENVIRONMENTAL LAB IDAHO FALLS},
	author = {Bruemmer, David J and Marble, Julie L and Dudenhoeffer, Donald D and Anderson, Matthew O and McKay, Mark D},
	year = {2002},
}

@book{van_someren_think_1994,
	edition = {1st},
	title = {The think aloud method: a practical approach to modelling cognitive},
	isbn = {0-12-714270-3},
	publisher = {Academic Press},
	author = {Van Someren, MW and Barnard, YF and Sandberg, JAC},
	year = {1994},
}

@book{thompson_architectural_2016,
	edition = {2nd},
	title = {Architectural design procedures},
	publisher = {Routledge},
	author = {Thompson, Arthur},
	year = {2016},
}

@book{jacoby_drawing_2016,
	edition = {1st},
	title = {Drawing {Architecture} and the {Urban}},
	publisher = {John Wiley \& Sons},
	author = {Jacoby, Sam},
	year = {2016},
}

@misc{sokolowska_progression_nodate,
	title = {Progression of simple design process from geometric shape architecture diagram {\textbar} {ARCH}-student.com},
	url = {http://arch-student.com/pin/progression-of-simple-design-process-from-geometric-shape-architecture-diagram/},
	urldate = {2019-02-16},
	author = {Sokolowska, Kamila},
}

@techreport{mine_virtual_1995,
	title = {Virtual environment interaction techniques},
	author = {Mine, Mark R},
	year = {1995},
	pages = {1--18},
}

@misc{noauthor_3d_nodate,
	title = {{3D} {Modeling} {Online} {Free} {\textbar} {3D} {Warehouse} {Models} {\textbar} {SketchUp}},
	url = {https://www.sketchup.com/products/sketchup-viewer},
	urldate = {2019-02-17},
}

@misc{noauthor_flat_nodate,
	title = {Flat isometric city {Vector}},
	url = {https://www.freepik.com/free-vector/flat-isometric-city_844261.htm},
	urldate = {2019-02-16},
}

@misc{noauthor_microsoft_nodate,
	title = {Microsoft {HoloLens} {\textbar} {The} leader in mixed reality technology},
	url = {https://www.microsoft.com/en-us/hololens},
	urldate = {2018-12-24},
}

@misc{noauthor_unity_nodate,
	title = {Unity},
	url = {https://unity3d.com/},
	urldate = {2018-12-24},
}

@misc{noauthor_xbox_nodate,
	title = {Xbox {Wireless} {Controller} {\textbar} {Xbox}},
	url = {https://www.xbox.com/en-US/xbox-one/accessories/controllers/xbox-wireless-controller},
	urldate = {2019-02-16},
}

@phdthesis{piekarski_interactive_2004,
	type = {{PhD} {Thesis}},
	title = {Interactive 3d modelling in outdoor augmented reality worlds},
	school = {University of South Australia},
	author = {Piekarski, Wayne},
	year = {2004},
}

@article{holloway_registration_1997,
	title = {Registration {Error} {Analysis} for {Augmented} {Reality}},
	volume = {6},
	doi = {10.1162/pres.1997.6.4.413},
	number = {4},
	journal = {Presence: Teleoperators and Virtual Environments},
	author = {Holloway, Richard L.},
	month = aug,
	year = {1997},
	pages = {413--432},
}

@article{thomas_using_1999,
	title = {Using augmented reality to visualize architecture designs in an outdoor environment},
	volume = {1},
	number = {Special Issue on Design Computing on the Net},
	journal = {International Journal of Design Computing},
	author = {Thomas, Bruce and Piekarski, Wayne and Gunther, Bernard},
	year = {1999},
}

@article{piekarski_arquake:_2002,
	title = {{ARQuake}: the outdoor augmented reality gaming system},
	volume = {45},
	issn = {00010782},
	doi = {10.1145/502269.502291},
	number = {1},
	journal = {Communications of the ACM},
	author = {Piekarski, Wayne and Thomas, Bruce H.},
	month = jan,
	year = {2002},
	pages = {36--38},
}

@article{piekarski_3d_2006,
	title = {{3D} modeling with the {Tinmith} mobile outdoor augmented reality system},
	volume = {26},
	issn = {0272-1716},
	doi = {10.1109/MCG.2006.3},
	number = {1},
	journal = {IEEE Computer Graphics and Applications},
	author = {Piekarski, Wayne},
	month = jan,
	year = {2006},
	pmid = {16463474},
	pages = {14--17},
}

@article{nister_efficient_2004,
	title = {An efficient solution to the five-point relative pose problem},
	volume = {26},
	issn = {0162-8828},
	doi = {10.1109/TPAMI.2004.17},
	number = {6},
	journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
	author = {Nistér, David},
	month = jun,
	year = {2004},
	pmid = {18579936},
	keywords = {Camera calibration, Ego-motion estimation, Imaging geometry, Motion, Relative orientation, Scene reconstruction, Structure from motion},
	pages = {756--770},
}

@article{langlotz_sketching_2012,
	title = {Sketching up the world: in situ authoring for mobile {Augmented} {Reality}},
	volume = {16},
	issn = {1617-4909},
	doi = {10.1007/s00779-011-0430-0},
	number = {6},
	journal = {Personal and Ubiquitous Computing},
	author = {Langlotz, Tobias and Mooslechner, Stefan and Zollmann, Stefanie and Degendorfer, Claus and Reitmayr, Gerhard and Schmalstieg, Dieter},
	month = aug,
	year = {2012},
	keywords = {Content Authoring, Mixed and augmented reality},
	pages = {623--630},
}

@article{kaufmann_construct3d:_2000,
	title = {{Construct3D}: {A} {Virtual} {Reality} {Application} for {Mathematics} and {Geometry} {Education}},
	volume = {5},
	issn = {1573-7608},
	doi = {10.1023/A:1012049406877},
	number = {4},
	journal = {Education and Information Technologies},
	author = {Kaufmann, Hannes and Schmalstieg, Dieter and Wagner, Michael},
	month = dec,
	year = {2000},
	pages = {263--276},
}

@article{hollerer_exploring_1999,
	title = {Exploring {MARS}: developing indoor and outdoor user interfaces to a mobile augmented reality system},
	volume = {23},
	issn = {00978493},
	doi = {10.1016/S0097-8493(99)00103-X},
	number = {6},
	journal = {Computers \& Graphics},
	author = {Höllerer, Tobias and Feiner, Steven and Terauchi, Tachio and Rashid, Gus and Hallaway, Drexel},
	month = dec,
	year = {1999},
	keywords = {augmented reality, hypermedia, mobile computing, user interfaces, wearable computing},
	pages = {779--785},
}

@article{feiner_touring_1997,
	title = {A touring machine: {Prototyping} {3D} mobile augmented reality systems for exploring the urban environment},
	volume = {1},
	issn = {0949-2054},
	doi = {10.1007/BF01682023},
	number = {4},
	journal = {Personal Technologies},
	author = {Feiner, Steven and MacIntyre, Blair and Höllerer, Tobias and Webster, Anthony},
	month = dec,
	year = {1997},
	keywords = {Augmented Reality, Computer System, Reality System, Urban Environment, User Interface},
	pages = {208--217},
}

@article{cirulis_3d_2013,
	title = {{3D} {Outdoor} {Augmented} {Reality} for {Architecture} and {Urban} {Planning}},
	volume = {25},
	issn = {18770509},
	doi = {10.1016/j.procs.2013.11.009},
	journal = {Procedia Computer Science},
	author = {Cirulis, Arnis and Brigmanis, Kristaps Brigis},
	month = nov,
	year = {2013},
	keywords = {Augmented reality (AR), Markerless tracking, Urban planning, Virtual reality (VR)},
	pages = {71--79},
}

@article{billinghurst_magicbook_2001,
	title = {The {MagicBook} - {Moving} seamlessly between reality and virtuality},
	volume = {21},
	issn = {02721716},
	doi = {10.1109/38.920621},
	number = {3},
	journal = {IEEE Computer Graphics and Applications},
	author = {Billinghurst, Mark and Kato, Hirokazu and Poupyrev, Ivan},
	month = jun,
	year = {2001},
	pmid = {25246403},
	pages = {6--8},
}

@article{bowman_introduction_2001,
	title = {An {Introduction} to 3-{D} {User} {Interface} {Design}},
	volume = {10},
	issn = {1054-7460},
	doi = {10.1162/105474601750182342},
	number = {1},
	journal = {Presence: Teleoperators and Virtual Environments},
	author = {Bowman, Doug A. and Kruijff, Ernst and LaViola, Joseph J. and Poupyrev, Ivan},
	month = feb,
	year = {2001},
	pmid = {21166522},
	pages = {96--108},
}

@article{azuma_survey_1997,
	title = {A {Survey} of {Augmented} {Reality}},
	volume = {6},
	issn = {1054-7460},
	doi = {10.1162/pres.1997.6.4.355},
	number = {4},
	journal = {Presence: Teleoperators and Virtual Environments},
	author = {Azuma, Ronald T.},
	month = aug,
	year = {1997},
	pmid = {9708264137},
	pages = {355--385},
}

@article{van_krevelen_survey_2010,
	title = {A survey of augmented reality technologies, applications and limitations},
	volume = {9},
	number = {2},
	journal = {International Journal of Virtual Reality},
	author = {Van Krevelen, DWF and Poelman, Ronald},
	year = {2010},
	pages = {1--19},
}

@inproceedings{billinghurst_glass_2014,
	title = {The glass class: {Designing} wearable interfaces},
	doi = {10.1109/ISMAR.2014.6948515},
	booktitle = {Proceedings of the 2014 {IEEE} {International} {Symposium} on {Mixed} and {Augmented} {Reality}},
	author = {Billinghurst, M.},
	month = sep,
	year = {2014},
	keywords = {Design methodology, Educational institutions, Glass, Google, Sensors, Wearable computers},
}

@inproceedings{thomas_wearable_1998,
	title = {A wearable computer system with augmented reality to support terrestrial navigation},
	isbn = {0-8186-9074-7},
	doi = {10.1109/ISWC.1998.729549},
	booktitle = {Proceedings of the 2nd {International} {Symposium} on {Wearable} {Computers}},
	author = {Thomas, Bruce and Demczuk, Victor and Piekarski, Wayne and Hepworth, David and Gunther, Bernard},
	month = oct,
	year = {1998},
	pages = {168--171},
}

@inproceedings{simon_-situ_2010,
	title = {In-{Situ} {3D} {Sketching} {Using} a {Video} {Camera} as an {Interaction} and {Tracking} {Device}},
	booktitle = {Proceedings of the 31st {Annual} {Conference} of the {European} {Association} for {Computer} {Graphics}},
	author = {Simon, Gilles},
	month = may,
	year = {2010},
}

@inproceedings{schall_virtual_2008,
	series = {{ISMAR} '08},
	title = {Virtual {Redlining} for {Civil} {Engineering} in {Real} {Environments}},
	isbn = {978-1-4244-2840-3},
	doi = {10.1109/ISMAR.2008.4637332},
	booktitle = {Proceedings of the 7th {IEEE}/{ACM} {International} {Symposium} on {Mixed} and {Augmented} {Reality}},
	author = {Schall, Gerhard and Mendez, Erick and Schmalstieg, Dieter},
	month = sep,
	year = {2008},
	pages = {95--98},
}

@inproceedings{piekarski_augmented_2004,
	title = {Augmented {Reality} {Working} {Planes}: {A} {Foundation} for {Action} and {Construction} at a {Distance}},
	isbn = {0-7695-2191-6},
	doi = {10.1109/ISMAR.2004.17},
	booktitle = {Proceedings of the 3rd {IEEE} and {ACM} {International} {Symposium} on {Mixed} and {Augmented} {Reality}},
	author = {Piekarski, Wayne and Thomas, Bruce H.},
	month = nov,
	year = {2004},
	pages = {162--171},
}

@inproceedings{piekarski_interactive_2003,
	title = {Interactive augmented reality techniques for construction at a distance of {3D} geometry},
	isbn = {3-905673-00-2},
	doi = {10.1145/769953.769956},
	booktitle = {Proceedings of the 2003 {Workshop} on {Virtual} {Environments}},
	author = {Piekarski, Wayne and Thomas, Bruce H.},
	month = may,
	year = {2003},
	pages = {19--28},
}

@inproceedings{piekarski_tinmith-metro:_2001,
	title = {Tinmith-{Metro}: new outdoor techniques for creating city models with an augmented reality wearable computer},
	isbn = {0-7695-1318-2},
	doi = {10.1109/ISWC.2001.962093},
	booktitle = {Proceedings of the 5th {International} {Symposium} on {Wearable} {Computers}},
	author = {Piekarski, Wayne and Thomas, B.H.},
	month = oct,
	year = {2001},
	keywords = {3d modelling, Augmented reality, constructive solid geometry, mobile user interfaces},
	pages = {31--38},
}

@inproceedings{milgram_augmented_1995,
	title = {Augmented reality: a class of displays on the reality-virtuality continuum},
	volume = {2351},
	isbn = {0277786X},
	doi = {10.1.1.83.6861},
	booktitle = {Proceedings of the {Telemanipulator} and {Telepresence} {Technologies}},
	author = {Milgram, Paul and Takemura, Haruo and Utsumi, Akira and Fumio, Kishino},
	month = dec,
	year = {1995},
	pmid = {11743703},
	keywords = {augmented reality, augmented virtuality, mixed reality, stereoscopic displays, taxonomy, telerobotic control, virtual control, virtual reality},
	pages = {282--292},
}

@inproceedings{kurmann_sculptor-tool_1995,
	title = {Sculptor-{A} tool for intuitive architectural design},
	booktitle = {Proceedings of the 6th {International} {Conference} on {Computer}-{Aided} {Architectural} {Design} {Futures}},
	author = {Kurmann, David},
	month = sep,
	year = {1995},
	pages = {323--330},
}

@inproceedings{julier_information_2000,
	title = {Information filtering for mobile augmented reality},
	doi = {10.1109/ISAR.2000.880917},
	booktitle = {Proceedings of the {IEEE} and {ACM} {International} {Symposium} on {Augmented} {Reality}},
	author = {Julier, S. and Lanzagorta, M. and Baillot, Y. and Rosenblum, L. and Feiner, S. and Hollerer, T. and Sestito, S.},
	month = oct,
	year = {2000},
	pages = {3--11},
}

@inproceedings{interrante_distance_2006,
	title = {Distance perception in immersive virtual environments, revisited},
	booktitle = {Proceedings of the 2006 {IEEE} {Virtual} {Reality} {Conference}},
	author = {Interrante, Victoria and Ries, Brian and Anderson, Lee},
	month = mar,
	year = {2006},
	pages = {3--10},
}

@inproceedings{henderson_evaluating_2009,
	title = {Evaluating the benefits of augmented reality for task localization in maintenance of an armored personnel carrier turret},
	volume = {00},
	doi = {10.1109/ISMAR.2009.5336486},
	booktitle = {Proceedings of the 8th {IEEE} {International} {Symposium} on {Mixed} and {Augmented} {Reality}},
	author = {Henderson, S. J. and Feiner, S.},
	month = oct,
	year = {2009},
	pages = {135--144},
}

@inproceedings{collins_computer-assisted_2014,
	title = {Computer-{Assisted} {Laparoscopic} myomectomy by augmenting the uterus with pre-operative {MRI} data},
	doi = {10.1109/ISMAR.2014.6948434},
	booktitle = {Proceedings of the 2014 {IEEE} {International} {Symposium} on {Mixed} and {Augmented} {Reality}},
	author = {Collins, T. and Pizarro, D. and Bartoli, A. and Canis, M. and Bourdel, N.},
	month = sep,
	year = {2014},
	keywords = {AR, AR-based image guidance system, CAI, Deformable models, Laparoscopes, MIS, Magnetic resonance imaging, Solid modeling, Surgery, Three-dimensional displays, Transforms, augmented reality, biomedical MRI, computer assisted intervention, computer-assisted laparoscopic myomectomy, deformable model, image registration, laparoscopic minimal invasive surgery, laparoscopic video, magnetic resonance imaging, medical image processing, preoperative MRI data, surgery, video signal processing},
	pages = {243--248},
}

@inproceedings{chen_poster:_2009,
	title = {Poster: {A} hybrid direct visual editing method for architectural massing study in virtual environments},
	isbn = {978-1-4244-3965-2},
	doi = {10.1109/3DUI.2009.4811227},
	booktitle = {Proceedings of the 2009 {IEEE} {Symposium} on {3D} {User} {Interfaces}},
	author = {Chen, Jian and Bowman, Doug A. and Laidlaw, David H.},
	month = mar,
	year = {2009},
	keywords = {3D interaction, Computer-aided massing study, Hybrid environment, Physics-based object manipulation},
	pages = {143--144},
}

@inproceedings{belcher_mxr_2008,
	title = {{MxR} {A} physical model-based mixed reality interface for design collaboration, simulation,visualization and form generation},
	booktitle = {Proceedings of the 28th {Annual} {Conference} of the {Association} for {Computer} {Aided} {Design} in {Architecture}},
	author = {Belcher, Daniel and Johnson, Brian},
	month = oct,
	year = {2008},
	pages = {464--471},
}

@inproceedings{baillot_authoring_2001,
	title = {Authoring of physical models using mobile computers},
	isbn = {0-7695-1318-2},
	doi = {10.1109/ISWC.2001.962094},
	booktitle = {Proceedings of the 5th {International} {Symposium} on {Wearable} {Computers}},
	author = {Baillot, Yohan and Brown, Dennis and Julier, Simon},
	month = oct,
	year = {2001},
	keywords = {augmented reality, modeling, tracking, wearable computing},
	pages = {39--46},
}

@inproceedings{sareika_urban_2007,
	title = {Urban {Sketcher}: {Mixed} {Reality} on {Site} for {Urban} {Planning} and {Architecture}},
	isbn = {978-1-4244-1749-0},
	doi = {10.1109/ISMAR.2007.4538821},
	booktitle = {Proceedings of the 6th {IEEE} and {ACM} {International} {Symposium} on {Mixed} and {Augmented} {Reality}},
	author = {Sareika, Markus and Schmalstieg, Dieter},
	month = nov,
	year = {2007},
	keywords = {Architecture, Augmented reality, Collaboration, Mixed reality, Natural multimodal interaction, Urban planning},
	pages = {27--30},
}

@inproceedings{lages_evaluation_2018,
	title = {Evaluation of {Environment}-{Independent} {Techniques} for {3D} {Position} {Marking} in {Augmented} {Reality}},
	isbn = {978-1-5386-3365-6},
	doi = {10.1109/VR.2018.8446055},
	booktitle = {Proceedings of the 2018 {IEEE} {Conference} on {Virtual} {Reality} and {3D} {User} {Interfaces}},
	author = {Lages, Wallace S. and Li, Yuan and Bowman, Doug A.},
	month = mar,
	year = {2018},
	keywords = {Augmented reality, H.5.2: User Interfaces-Pointing, H5.1 [Information interfaces and presentation]: Mu, interaction, marker placement},
	pages = {615--616},
}

@inproceedings{ragan_simulation_2009,
	title = {Simulation of {Augmented} {Reality} {Systems} in {Purely} {Virtual} {Environments}},
	doi = {10.1109/VR.2009.4811058},
	booktitle = {Proceedings of the 2009 {IEEE} {Virtual} {Reality} {Conference}},
	author = {Ragan, E. and Wilkes, C. and Bowman, D. A. and Hollerer, T.},
	month = mar,
	year = {2009},
	keywords = {AR simulation, Augmented reality, Computational modeling, Computer science, Computer simulation, Displays, Error correction, System testing, Usability, Virtual environment, Virtual reality, augmented reality, augmented reality system, digital simulation, motor control, object manipulation, registration error, system simulation, task performance, usability evaluation, virtual environment},
	pages = {287--288},
}

@book{ching_architecture:_2007,
	edition = {3rd},
	title = {Architecture: {Form}, space, and order},
	isbn = {978-0-471-75216-5},
	publisher = {John Wiley \& Sons},
	author = {Ching, Francis DK},
	year = {2007},
}

@article{cavallaro_foxtrax_1997,
	title = {The {FoxTrax} hockey puck tracking system},
	volume = {17},
	issn = {0272-1716},
	doi = {10.1109/38.574652},
	number = {2},
	journal = {IEEE Computer Graphics and Applications},
	author = {Cavallaro, R.},
	month = mar,
	year = {1997},
	keywords = {Broadcasting, Cameras, Fox Sports, FoxTrax hockey puck tracking system, Frequency, Image sensors, Infrared image sensors, Lenses, Multimedia communication, NHL coverage, Optical computing, Puck Truck, Radar, Repeaters, sport, television, tracking, tracking system},
	pages = {6--12},
}

@inproceedings{harborth_exploring_2017,
	title = {Exploring the {Hype}: {Investigating} {Technology} {Acceptance} {Factors} of {Pokémon} {Go}},
	doi = {10.1109/ISMAR.2017.32},
	booktitle = {Proceedings of the 2017 {IEEE} {International} {Symposium} on {Mixed} and {Augmented} {Reality}},
	author = {Harborth, D. and Pape, S.},
	month = oct,
	year = {2017},
	keywords = {AR smart-phone game, Augmented reality, Games, Information systems, Laboratories, Mathematical model, Mobile communication, PLS-SEM approach, Pokémon Go, Solid modeling, UTAUT2 model, augmented reality, behavioral intention, computer games, mobile computing, smart phones, statistical analysis, technology acceptance factors},
	pages = {155--168},
}

@inproceedings{haouchine_image-guided_2013,
	title = {Image-guided simulation of heterogeneous tissue deformation for augmented reality during hepatic surgery},
	doi = {10.1109/ISMAR.2013.6671780},
	booktitle = {Proceedings of the 2013 {IEEE} {International} {Symposium} on {Mixed} and {Augmented} {Reality}},
	author = {Haouchine, N. and Dequidt, J. and Peterlik, I. and Kerrien, E. and Berger, M. and Cotin, S.},
	month = oct,
	year = {2013},
	keywords = {Biological system modeling, Biomechanics, Computational modeling, Deformable models, H.5.1 [Information Interfaces and Presentation]: Multimedia Information Systems—Artificial, I.3.5 [Computer Graphics]: Computational Geometry and Object Modeling—Physically based modeling, Liver, Surgery, Three-dimensional displays, anatomical structures, and virtual realities, anisotropic tissue, augmented, augmented reality, computerised tomography, hepatic surgery, heterogeneous tissue deformation, image-guided simulation, internal structures, laparoscopic view, liver, medical image processing, minimally invasive liver surgery, minimally invasive surgery, partial three-dimensional liver surface motion, phantom data, phantoms, preoperative CT scans, real-time augmentation, real-time biomechanical model, real-time systems, solid modelling, state-of-the-art method, surgery, surgery guidance, tumors, tumours, vascular network, volumetric displacement field},
	pages = {199--208},
}

@inproceedings{bichlmeier_laparoscopic_2007,
	title = {Laparoscopic {Virtual} {Mirror} for {Understanding} {Vessel} {Structure} {Evaluation} {Study} by {Twelve} {Surgeons}},
	doi = {10.1109/ISMAR.2007.4538836},
	booktitle = {Proceedings of the 6th {IEEE} and {ACM} {International} {Symposium} on {Mixed} and {Augmented} {Reality}},
	author = {Bichlmeier, C. and Heining, S. M. and Rustaee, M. and Navab, N.},
	month = nov,
	year = {2007},
	keywords = {Augmented reality, Biomedical optical imaging, Blood vessels, Cameras, Data visualization, Laparoscopes, Liver neoplasms, Mirrors, Navigation, Surgery, augmented reality, blood vessels, laparoscopic virtual mirror, laparoscopy, liver, liver tissue, medical augmented reality system, medical computing, medical visualization, medical volumetric data, navigated surgery, navigational tool, tumor, tumours, user interaction, vessel structure evaluation},
	pages = {125--128},
}

@article{kim_revisiting_2018,
	title = {Revisiting {Trends} in {Augmented} {Reality} {Research}: {A} {Review} of the 2nd {Decade} of {ISMAR} (2008–2017)},
	volume = {24},
	issn = {1077-2626},
	doi = {10.1109/TVCG.2018.2868591},
	number = {11},
	journal = {IEEE Transactions on Visualization and Computer Graphics},
	author = {Kim, K. and Billinghurst, M. and Bruder, G. and Duh, H. B. and Welch, G. F.},
	month = nov,
	year = {2018},
	keywords = {Augmented reality, Calibration, ISMAR conferences, ISMAR publications, Indexes, Industries, International Symposium on Mixed and Augmented Reality, Market research, Rendering (computer graphics), Sensors, augmented reality, mixed reality, rendering, rendering (computer graphics), survey, trends},
	pages = {2947--2962},
}

@book{laviola_3d_2017,
	edition = {2nd},
	title = {{3D} {User} {Interfaces}: {Theory} and {Practice}},
	isbn = {978-0-13-403432-4},
	publisher = {Addison-Wesley Professional},
	author = {LaViola, Joseph J. and Kruijff, Ernst and McMahan, Ryan P. and Bowman, Doug A. and Poupyrev, Ivan P.},
	year = {2017},
}

@book{schmalstieg_augmented_2016,
	edition = {1st},
	title = {Augmented {Reality}: {Principles} and {Practice}},
	isbn = {978-0-321-88357-5},
	publisher = {Addison-Wesley Professional},
	author = {Schmalstieg, Dieter and Höllerer, Tobias},
	year = {2016},
}

@book{neufert_neufert_2000,
	edition = {3rd},
	title = {Neufert {Architects}' {Data}},
	isbn = {978-0-632-03776-6},
	publisher = {Wiley-Blackwell},
	author = {Neufert, Ernst and Neufert, Peter},
	year = {2000},
}
