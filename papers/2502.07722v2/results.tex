\section{Numerical Study} \label{results}

We complement the theoretical analysis with experiments. For this, we consider an artificial, repetitive geometry that splits a cube into two subdomains, an intracellular subdomain in the center with connections to the outside via all faces of the cubes and an extracellular domain around it (see~\Cref{fig:mesh}). This way, each intracellular subdomain has both an interface to an extracellular subdomain (via a cell membrane) and to other intracellular subdomains (via gap junctions). For this study, we consider a linear gap junction for the interfaces between intracellular subdomains and the Aliev-Panfilov ionic model \cite{aliev} for the gating variables between intra- and extracellular subdomains. If not stated otherwise, the conductivity coefficients $\sigma_i$ are fixed to $3 \frac{\text{mS}}{\text{cm}}$ for intra- and $20 \frac{\text{mS}}{\text{cm}}$ for extra-cellular subdomains. To improve load balancing, we decompose the extracellular domain into subdomains using regular continuous finite elements. On the interfaces between those subdomains, we do not need to consider any discontinuities. We use the BDDC implementation in the software library Ginkgo \cite{ginkgo} as a preconditioner for a Conjugate Gradient (CG) method. The stopping criterion evaluates the $L^2$-norm of the residual against a pre-set threshold. All tests have been performed on the CPU partition of the EuroHPC machine Karolina\footnote{https://www.it4i.cz/en/infrastructure/karolina} on compute nodes with two AMD Zen 2 EPYCâ„¢ 7H12 CPUs, totalling 128 CPU cores and 256 GB of main memory per node. 

\begin{figure}[h!]
    \centering
    \includegraphics[width=.3\textwidth]{figures/mesh3x1}
    \includegraphics[width=.3\textwidth]{figures/mesh3x3}
    \includegraphics[width=.3\textwidth]{figures/mesh4x4}
    \caption{Repetitive test geometry with 3x3x1 (left), 3x3x3 (middle) and 4x4x4 (right) cells. Each cell is an intracellular subdomain inside a cube that can be stacked in all dimensions, resulting in a mesh where all intracellular subdomains have interfaces with extracellular space via a cell membrane model and with other intracellular domains via a linear gap junction.}
    \label{fig:mesh}
\end{figure}

\subsection{Scalability}
For a weak scaling study, we consider the linear system in an EMI model simulation at the same time step (0.01 ms) for a growing number of subdomains, starting with $3\times 3\times 1$ cells and reaching up to $7\times 7\times 7$ cells. The observed convergence behavior aligns with the theory: as we increase the number of subdomains but leave $\frac{H}{h}$ constant, the number of iterations needed to converge as well as the condition number estimate remain roughly constant, see \Cref{tab:weak_scaling}.

\begin{table}[h]
    \centering
    \begin{tabular}{ccccccccccc}
         \hline 
         \multirow{2}{1cm}{\#cells} & \multirow{2}{0.8cm}{\#SD} & \multirow{2}{1cm}{GD} & \multicolumn{4}{c}{VEF} & \multicolumn{4}{c}{VE} \\
         &&& it & $\kappa$ & CD & time & it & $\kappa$ & CD & time \\\hline
         3x3x1 & 18 & 4493 & 7 & 2.3158 & 73 & 2.9 & 14 & 17.4721 & 40 & 2.5\\
         3x3x2 & 36 & 8718 & 7 & 2.2712 & 207 & 3.3 & 16 & 12.2331 & 123 & 2.8\\
         3x3x3 & 54 & 12943 & 7 & 2.2587 & 341 & 3.8 & 15 & 11.9005 & 206 & 3.3\\
         4x4x4 & 128 & 30209 & 7 & 2.2605 & 919 & 5.4 & 15 & 11.7062 & 567 & 6\\
         5x5x5 & 250 & 58461 & 7 & 2.2602 & 1929 & 5.8 & 15 & 11.3865 & 1204 & 6.2\\
         6x6x6 & 432 & 100405 & 7 & 2.2602 & 3491 & 9.1 & 15 & 11.6549 & 2195 & 6.6\\
         7x7x7 & 686 & 158747 & 7 & 2.2602 & 5725 & 15.6 & 15 & 11.6975 & 3618 & 15.5 \\\hline
    \end{tabular}
    \caption{Weak scalability for an increasing number of cells from $3\times 3\times 1$ to $7\times 7\times 7$. Each intra- and extracellular subdomain is discretized with 512 tetrahedral finite elements. We report the number of subdomains (SD), the global dimension (GD) of the linear problem, the number of preconditioner CG iterations (it), a condition number estimate ($\kappa$) computed with the Lanczos estimate, the dimension of the coarse problem (CD), and the time needed for a preconditioner application in ms. The stopping criterion tolerance for this test is a residual norm of $10^{-8}$.}
    \label{tab:weak_scaling}
\end{table}

To evaluate the stability of the method, we consider a setup where we run the solver with random right-hand-side vectors. For this study, we generate 100 different right-hand-side vectors filled with random values in $(-1,1)$ for each of the test cases and record the iteration count needed to converge to a relative residual norm tolerance of $10^{-6}$. \Cref{fig:rand_rhs} confirms the expectation that the choice of right-hand side does not impact the convergence of our method significantly. In terms of compute time, we see two major jumps: the first when inter-node communication over the network is needed starting at 128 subdomains, and the second when the solution of the coarse problem starts dominating the runtime. The latter effect can possibly be alleviated by employing a second level of BDDC on the coarse problem to improve scalability.

\begin{figure}
    \centering
    \begin{subfigure}[b]{0.4\textwidth}
        \includegraphics[width=\textwidth]{figures/iter_rand_rhs.png}
    \end{subfigure}
    \begin{subfigure}[b]{0.4\textwidth}
        \includegraphics[width=\textwidth]{figures/cond_rand_rhs.png}
    \end{subfigure}
    \caption{Iterations needed to converge to a relative residual tolerance of $10^{-6}$ (left) and condition number estimates (right) for random right-hand side vectors. The results colored in blue consider a full primal space containing vertex values as well as edge and face averages. The results colored in red consider only vertex values and edge averages in the primal space. The solid lines show the mean over 100 different random right-hand sides, the colored areas represent the range of iterations or condition numbers for each test case, respectively.}
    \label{fig:rand_rhs}
\end{figure}

\subsection{Robustness w.r.t.\ conductivity coefficients}
The theoretical results obtained in \Cref{sec:proof} reveal that the condition number of the preconditioned operator is bounded independently of the conductivity coefficients $\sigma_i$. In order to evaluate this experimentally, we show in \Cref{fig:rand_sigma} the convergence behavior for random conductivity coefficients in the extracellular and intracellular subdomains. As the extracellular subdomains together represent one continuous space, we assign the same coefficient to all of them, while each of the intracellular subdomains is assigned a random conductivity coefficient. One can observe the same behavior as for fixed $\sigma_i$ with a slightly wider range of needed iterations.

\begin{figure}
    \centering
    \begin{subfigure}[b]{0.4\textwidth}
        \includegraphics[width=\textwidth]{figures/iter_rand_coef.png}
    \end{subfigure}
    \begin{subfigure}[b]{0.4\textwidth}
        \includegraphics[width=\textwidth]{figures/cond_rand_coef.png}
    \end{subfigure}
    \caption{Iterations needed to converge to a relative residual tolerance of $10^{-6}$ (left) and condition number estimates (right) for random conductivity coefficients \newline $\sigma_i \in (1, 20) \frac{\text{mS}}{\text{cm}}$. For each test case, we generate the preconditioner 100 times with different, random conductivity coefficients, the solid lines show the mean of the iterations needed to converge and the condition number estimates.}
    \label{fig:rand_sigma}
\end{figure}

\subsection{Optimality tests}
In this section, we evaluate the poly-logarithmic convergence behavior of the preconditioned linear operator. For this, we refine a mesh of $3\times 3\times 3$ cells in order to increase the value of $\frac{H}{h}$. In each refinement level, the number of degrees of freedom doubles in each dimension, so $\frac{H}{h}$ also increases by a factor of 2. \Cref{fig:refinement} reveals that the iteration count increases as expected. From the theoretical results, we expect the condition number to grow asymptotically with $(1 + \log\frac{H}{h})^2$ (dashed blue line).

The estimated condition number grow aligns with this expectation. For the reduced coarse space only consisting of edge and vertex constraints, the condition number growth aligns more with linear growth (red dotted line), while flattening out with increasing refinement level.

As our repetitive mesh is constructed out of cells with a potentially problematic geometry (they are not convex), we simplify the geometry to the meshes shown in \Cref{fig:simple-meshes}. This way, we intend to observe the asymptotic behavior of the condition number also for the reduced coarse space in \Cref{fig:refinement-simple}. We note that while the estimated condition number of the preconditioned operator reflects the theoretical asymptotic bounds perfectly for the full coarse space and for the reduced coarse space, this is only obvious for the simplest mesh. The actual convergence behavior by iterations reflects poly-logarithmic growth in all cases.

\begin{figure}
    \centering
    \begin{subfigure}[b]{0.4\textwidth}
        \includegraphics[width=\textwidth]{figures/iter_refinement_cube.png}
    \end{subfigure}
    \begin{subfigure}[b]{0.4\textwidth}
        \includegraphics[width=\textwidth]{figures/cond_refinement_cube.png}
    \end{subfigure}
    \caption{Iterations needed to converge to a relative residual tolerance of $10^{-6}$ (left) and condition number estimates (right) for an increasing refinement level. Refining the problem increases $\frac{H}{h}$, resulting in poly-logarithmic increase in the condition number and in the iteration count (dashed lines). For the coarse space containing only vertex and edge constraints, the actual growth of the condition number appears to be closer to linear (dotted line). Here, the dashed line is the graph of $\bigg(1 + \log\frac{H}{h}\bigg)^2$ scaled such that it intersects with the first measured data point and the dotted line is a linear interpolation of the first two measured data points.}
    \label{fig:refinement}
\end{figure}

\begin{figure}
    \centering
    \begin{subfigure}[b]{0.4\textwidth}
        \includegraphics[width=\textwidth]{figures/eight_cells.png}
    \end{subfigure}
    \begin{subfigure}[b]{0.4\textwidth}
        \includegraphics[width=\textwidth]{figures/two_cells.png}
    \end{subfigure}
    \caption{Simplified meshes containing 8 (left) and 2 (right) convex myocytes floating in extracellular space.}
    \label{fig:simple-meshes}
\end{figure}

\begin{figure}
    \centering
    \begin{subfigure}[b]{0.4\textwidth}
        \includegraphics[width=\textwidth]{figures/cond_refinement_cell8.png}
    \end{subfigure}
    \begin{subfigure}[b]{0.4\textwidth}
        \includegraphics[width=\textwidth]{figures/cond_refinement_cell2.png}
    \end{subfigure}
    \caption{Condition number estimates for increasing refinement levels of simple geometries as shown in \Cref{fig:simple-meshes}. For the mesh made up from 8 cells (left), we already see a stronger sub-linear trend than for our repetitive test geometry while for the simplest case containing only two convex cells (right), the behavior shows a poly-logarithmic trend, aligning with the theoretical results. We note that for the simplest geometry, the condition number estimates are generally higher than for the more complex geometries, which is most likely due to the complete lack of primal (vertex) constraints.}
    \label{fig:refinement-simple}
\end{figure}