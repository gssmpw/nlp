\section{Conclusion}
\label{sec:conclusion}

In this paper, we propose the Hydra-Transformer Hybrid (\ours{}) diffusion model, a large-scale framework designed to push the boundaries of applying state space models (SSMs) to high-resolution image and long video generation. Our experiments show that using simple scanning strategies, models built with sequential and subquadratic token mixers, such as bidirectional SSMs, can achieve performance comparable to Transformer-based models while demonstrating superior inference efficiency and the potential to zero-shot higher-resolution images. We identify essential limitations and future directions of SSM-based generative models and share them in Appendix~\ref{appsec:limitations}.
We hope our findings will provide valuable insights and inspire future research on leveraging state space models and broader, more efficient sub-quadratic complexity architectures to tackle complex visual generation problems. 

