\section{Introduction}
Class Incremental Learning (CIL) necessitates that the model dynamically acquires knowledge of new classes while preserving the knowledge of previously learned classes within an infinite sequence of tasks \cite{wang2019forward,ke2021achieving,NEURIPS2023_15294ba2}. 
CIL is realistic but a great challenge for deep neural networks \cite{parisi2019continual}, where existing works devoted to overcoming catastrophic forgetting (CF) and encouraging knowledge transfer across different tasks \cite{mccloskey1989catastrophic,ye2020heterogeneous,zhao2021mgsvf,wang2024comprehensive}.
With the rapid advancement of CIL, a growing number of methods \cite{yoon2019scalable,li2024hessian,shan2024order} have been introduced to address the problem of CF from the perspective of the order in which classes appear (or task order).
In practice, the arrival order of each class and the tasks to which they belong are random and the order in which tasks arrive is uncontrollable \cite{bell2022effect}, further resulting in \textit{Class order sensitivity} and \textit{Intra-task class conflicts} \cite{lin2023theory}. 
Therefore, designing an order-robust CIL method is essential for the community.

\begin{figure}[t]
    \centering
    \includegraphics[width=1\linewidth]{figures/1.pdf}
    \caption{The crucial challenges of CIL (illustration on CIFAR100 dataset). On the left subfigure (a), each model’s performance is shown under varying class orders, testing its robustness to class order sensitivity. On the right subfigure (b), the model’s performance is shown when classes within the same task are similar, evaluating its resilience to intra-task classes with high similarities.}
    \label{fig: intro}
\end{figure}

\textit{Class order sensitivity} refers to the model exhibiting significant performance variations depending on the sequence in which classes are introduced \cite{shan2024order}. 
This phenomenon is prevalent in real-world applications (see \autoref{fig: intro}(a)). 
For instance, in online recommendation systems, the order in which user data classes are received at different time points is difficult to control. If the system initially receives data from relatively few classes, the introduction of subsequent classes may impair the system’s adaptability, resulting in unstable model performance on new tasks.
Furthermore, the model’s parameters may be overfitted to the classes of early tasks, diminishing its ability to generalize to subsequent task with new classes.
Although existing research, such as APD \cite{yoon2019scalable} and HALRP \cite{li2024hessian}, have attempted to mitigate the class order sensitivity problem by modifying network structures, their effectiveness remains limited and has not fundamentally addressed this challenge. 
Thus, designing a model capable of maintaining stable performance across varying class orders remains a critical unsolved issue in CIL.

\textit{Intra-task class conflicts} refers to the discrepancies in model performance caused by the similarity between classes that are trained simultaneously in a specific task (see \autoref{fig: intro}(b)). 
In real-world applications, where the arrival of classes in the data stream is uncontrollable, significant similarities among classes can severely impact the model's resilience. 
For example, in a specific task from a sequence of tasks, a model may be trained to recognize different breeds within the same species. Within this task, due to the high similarity of features across categories, the model needs to develop resilience in distinguishing between closely related classes.
However, existing CIL methods struggle to address this challenge, primarily due to the inherent limitations of the task setting. As CIL incrementally processes different classes, it cannot globally account for all class information, causing class conflicts to accumulate during training and negatively impact model performance. Thus, alleviating class conflicts and improving the model’s generalization ability remains a significant challenge in CIL.

Hence, to tackle the challenges of class order sensitivity and Intra-task class similarity sensitivity, we first conduct an in-depth analysis beyond existing theories. 
Our theoretical findings suggest that as class similarity decreases in CIL, the model's robustness to class order increases, which, in turn, mitigates knowledge conflicts both across different tasks and within individual tasks.
Then, we propose a similarity graph-based dynamic grouping method, called \textbf{Graph-Driven Dynamic Similarity Grouping (GDDSG)}, to maintain the centroids of existing classes and dynamically groups tasks based on class similarity, assigning classes with lower similarity to the same group.
This approach innovatively organizes class groups in CIL by utilizing a graph-based technique to minimize inter-group similarity. It dynamically assigns classes based on adaptive similarity thresholds and optimal graph coloring, thereby enhancing model robustness and computational efficiency across tasks.
In the incremental learning process, GDDSG continuously updates existing groups or creates new ones, training a separate model for each group. Consequently, during the prediction phase, decisions are made by aggregating the outputs of multiple models.

Hence, our contributions can be summarised as follows:
\begin{itemize}
    \item In this paper, we elaborate on existing theories and derive an important Corollary: when the similarity between classes is low, the model's sensitivity to class order is significantly reduced, leading to a decrease in class conflicts.

    \item Then, we provide a detailed introduction to the proposed GDDSG method, including its foundational algorithms and basic processes.

    \item Additionally, we conduct extensive comparative experiments to validate the effectiveness of GDDSG, highlighting its advantages and potential in incremental learning tasks.
\end{itemize}