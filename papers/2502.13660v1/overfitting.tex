In this section, we demonstrate that GNNs trained with RNIs fail to converge to solutions that are invariant to the values of the IDs. 
We hypothesize that this lack of invariance may contribute to the poor empirical performance of RNIs in practice, and show in Section~\ref{sec:experiments} that generalization improves when improving invariance to IDs.

\paragraph{Experimental Setting}
We evaluate GraphConv \cite{morris2021weisfeiler}, GIN~\cite{gin}, and GAT~\cite{gat} with RNIs, on
four Open Graph Benchmark (OGB)~\cite{ogb} datasets, which cover node and graph classification tasks. 


For each dataset and model, we sampled random features as IDs. We compute the average \textit{invariance ratio} with respect to the training set $S$, defined as follows. 
 The invariance ratio of a model on an example $x$ is $\max_{i\in L} P[f(x)=i]$ where $P$ is the distribution over random indices, and $L$ is the set of possible model outputs (e.g., classes). This measures the degree to which all random indices result in the same label.
The maximum value of the invariance ratio is 1 (i.e., same output label for all random indices) and the minimal value is $\nicefrac{1}{L}$.
 We define the invariance ratio of $S$ as the average of the invariance ratios for all $x\in S$.
To estimate this ratio, we resampled IDs 10,000 times after each epoch for each sample.

\paragraph{Datasets}
For node classification, we use ogbn-arxiv \cite{ogb}, a citation network where nodes represent academic papers and edges denote citation relationships. Node features are derived from word embeddings of paper titles and abstracts, and the task involves predicting the subject area of each paper. For graph classification, we used three molecular property prediction datasets \cite{ogb}. In ogbg-molhiv the task was to predict whether a molecule inhibits HIV replication, a binary classification task based on molecular graphs with atom-level features and bond-level edge features. ogbg-bbbp involves predicting blood-brain barrier permeability, a crucial property for drug development, while ogbg-bace focuses on predicting the ability of a molecule to bind to the BACE1 enzyme, associated with Alzheimerâ€™s disease. See more details in the Appendix.





\paragraph{Evaluation Protocol}
We used the training-validation-test splits introduced in~\cite{ogb}. Models were trained on the training set and hyperparameters were tuned by evaluating performance on the validation set. For testing, each model was trained with the best hypermarameters using three random seeds, and we report the average performance with these three seeds. Each network was trained for $500$ epochs. Detailed hyperparameters for each model and dataset are provided in the Appendix.

\paragraph{Results}
Figure~\ref{fig:invariance_curves} presents the invariance ratios for the different GNNs and datasets. The results indicate that the models did not achieve invariance with respect to the IDs. Notably, most invariance ratios continue to decrease rather than increase throughout the training process. This suggests that the GNNs not only fail to converge toward invariance but also tend to overfit as training progresses.


We observe that at the beginning of training, the invariance ratios are relatively high. It is important to note that a model can achieve invariance simply by ignoring the IDs (i.e., not use them at any part of the computation). As training progresses, the invariance ratio drops, which suggests that the IDs are in fact used by the model, but in a non-invariant manner. This suggests that reassignment of random IDs during training is insufficient to guarantee invariance. In the next section, we theoretically analyze GNNs with IDs and consider approaches to achieve invariance.