


In this section, we evaluate \ourmethod~on diverse real-world  and synthetic datasets.\footnote{Code is provided in \url{https://github.com/mayabechlerspeicher/ICON}} We demonstrate its ability to consistently improve invariance to IDs and, as a result, to often enhance generalization.

\subsection{Real-world Datasets}\label{subsec:real_data}
To assess the effectiveness of {\ourmethod} on real datasets, we evaluate it on diverse tasks from the Open Graph Benchmark (OGB)~\cite{hu2021opengraphbenchmarkdatasets}. We test {\ourmethod} across multiple GNN architectures, including GraphConv \cite{morris2021weisfeiler}, GIN \cite{gin}, and GAT \cite{gat}.  We note that {\ourmethod} is simple to add to any existing method. We focus on these three here due to their widespread use and to demonstrate the efficacy of {\ourmethod} across GNN architectures.


\paragraph{Datasets} We used ogbn-arxiv for node-classification and ogbg-molhiv, ogbg-bbbp, and ogbg-bace for graph-classification \cite{ogb}. The datasets are described in detail in Section~\ref{sec:overfitting}. Dataset statistics can be found in the Appendix.


\paragraph{Setup}
For each dataset and GNN, we evaluated three configurations: the baseline model without IDs, the model with RNI, and the model with \ourmethod. 
For each configuration,  we conducted a grid search by training on the training set and evaluating on the validation set. We selected the model performing model over the validation set. We then report the average ROC-AUC score and std of the selected configuration with $3$ seeds.
We also calculate the final invariance ratios as defined in Section~\ref{sec:overfitting} for both RNI and \ourmethod.




\paragraph{Results} Table~\ref{tab:invariance_ratios_ogb} presents the invariance ratios of \ourmethod~ and RNI across all datasets and models, with respect to the train and test sets. Across all datasets and models, \ourmethod~ significantly improves invariance with respect to both the train and the test set. In some cases, it reaches full invariance. 
Table~\ref{tab:final_accuracy} presents the average ROC-AUC scores for each model and dataset. Across all models and datasets, \ourmethod~ improves upon RNI, with the maximal margin being 22.08 ROC-AUC points on the ogbg-molhiv datasets with GAT. In $6$ out of the 12 cases, \ourmethod~improved generalization also upon the baseline model and was on par with the baseline models in 4 other cases, which shows that improving invariance can improve generalization. 

\subsection{Synthetic Datasets}

We next examine the performance of \ourmethod~ and RNI on synthetic datasets with three synthetic tasks where. MPGNNs without IDs are provably unable to solve these tasks \cite{chen2020graphneuralnetworkscount, garg2020generalizationrepresentationallimitsgraph, abboud2021surprisingpowergraphneural} but MPGNNS that employ unique IDs and are sufficiently large can solve these tasks \cite{abboud2021surprisingpowergraphneural}.

\subsubsection{The ``Is In Triangle'' Task}

\paragraph{Dataset}
The isInTriangle task is a binary node classification where the goal is to determine whether a given node is part of a triangle. It was shown in~\citet{chen2020graphneuralnetworkscount, garg2020generalizationrepresentationallimitsgraph} that MPGNNs without IDs cannot solve the isInTriangle task. With IDs, GNNs can solve the task, yet they can do so by either overfitting to the IDs or with an IDs-invariant solution. We show the existence of an IDs-invariant solution for this task in the proof of Theorem~\ref{thm:only_last_layer}.

The dataset consists of 100 graphs with 100 nodes each, generated using the preferential attachment (BA) model \citep{badist}, in which graphs are constructed by incrementally adding new nodes with $m$ edges and connecting them to existing nodes with a probability proportional to the degrees of those nodes. We adopt an inductive setting, where the graphs used during testing are not included in the training set. 
We used $m=2$ for the training graphs and evaluate two test sets: an interpolation setting where the graphs are drawn from the BA distribution with $m=2$, and an extrapolation setting where the graphs are drawn from a different distribution then the train graphs, a BA distribution with $m=3$.
The train set and test set consist of $500$ nodes each.


\paragraph{Setup}
We repeat the setup from Sections~\ref{sec:overfitting} and \ref{subsec:real_data}.
As in this task nodes have no features, for the baseline models where IDs are not used, we use a constant 1 feature for all nodes.
For each task, we conducted a grid search by training on the training set and evaluating on the validation set. We selected the model performing model over the validation set.
We then report the average accuracy and std of the selected configuration with $3$ seeds.
We also calculate the final invariance ratios as in Sections~\ref{sec:overfitting} and \ref{subsec:real_data} for both RNI and {\ourmethod}.

\begin{table}[h!]
\centering
\caption{Accuracy (\%)$\uparrow$ on the isInTriangle task, in interpolation and extrapolation settings, with different GNNs. In all cases, \ourmethod~ outperforms RNI and the baseline. }
\label{tab:int_vs_exp}
\vskip 0.15in
\begin{tabular}{lcc}
\toprule
& \multicolumn{2}{c}{\textbf{Setting}} \\
\cmidrule(lr){2-3}
\textbf{Method} & Interp. & Extrap. \\ \toprule
  GraphConv+Constant &  75.35$_{\pm 2.09}$ & 53.70$_{\pm 1.67}$ \\
GraphConv+RNI    &      74.87$_{\pm 3.06}$       &      57.02$_{\pm 3.39}$     \\ 
GraphConv+\ourmethod   &      \textbf{88.45$_{\pm 2.04}$}         &            \textbf{78.20$_{\pm 2.53}$} \\ 
\midrule
  GIN+Constant &  76.10$_{\pm 1.83}$ & 56.29$_{\pm 1.55}$\\
GIN+RNI    &   72.15$_{\pm 2.01}$ & 55.01$_{\pm 1.30}$\\
GIN+\ourmethod  & \textbf{90.95$_{\pm 1.27}$} & \textbf{71.20$_{\pm 1.94}$}\\
\midrule
  GAT+Constant &  74.99$_{\pm 2.10}$ & 56.07$_{\pm 2.11}$\\
GAT+RNI    &   71.20$_{\pm 1.48}$ & 58.92$_{\pm 1.57}$\\
GAT+\ourmethod  & \textbf{89.71$_{\pm 1.27}$} & 79.30$_{\pm 1.90}$\\ 
\bottomrule
\end{tabular}
\vskip 0.15in
\end{table}


\begin{table}[h!]
\centering
\caption{Invariance ratios with respect to the train set and test set when training GNNs with RNI vs. with \ourmethod~, over the isInTriangle task. \ourmethod~ achieves perfect invariance.}
\label{tab:is_triangle_invariance}
\begin{tabular}{lcc}
\\
\toprule
& \multicolumn{2}{c}{\textbf{Set}} \\
\cmidrule(lr){2-3}
  \textbf{Method}   & Train & Test \\
  \toprule
GraphConv+RNI    &    0.95$_{\pm 0.01}$ & 0.93$_{\pm 0.08}$\\ 
GraphConv+\ourmethod   & \textbf{1.00$_{\pm 0.00}$} & \textbf{1.00$_{\pm 0.00}$}\\ 
\midrule
GIN+RNI    &    0.95$_{\pm 0.02}$ & 0.94$_{\pm 0.02}$\\
GIN+\ourmethod  & \textbf{1.00$_{\pm 0.00}$} & \textbf{0.99$_{\pm 0.00}$}\\
\midrule
GAT+RNI    &   0.88$_{\pm 0.09}$ & 0.88$_{\pm 0.13}$\\
GAT+\ourmethod  &\textbf{1.00$_{\pm 0.00}$} &  \textbf{1.00$_{\pm 0.00}$}\\ 
\bottomrule
\end{tabular}
\end{table}

\begin{figure}[t]
    \centering

      \subfigure[EXP]{\label{figure:exp_1_test_acc} \includegraphics[width=0.47\textwidth]{figures/exp_1_test_acc.png}}\quad
      \subfigure[CEXP]{\label{figure:cexp_05_test_acc}\includegraphics[width=0.47\textwidth]{figures/cexp_05_test_acc.png}}

    \caption{The test accuracy learning curves of RNI and \ourmethod~on the EXP and CEXP daatasets. While both methods reach almost perfect accuracy, \ourmethod~offers faster convergence.}
    \label{Figure:exp_cexp}
\end{figure}



\paragraph{Results}

Table~\ref{tab:is_triangle_invariance} presents the invariance ratios of \ourmethod~ and RNI across all models, for the interpolation and extrapolation settings. Across all models, \ourmethod~ drastically improves invariance both with respect to the train and the test set. In some cases it reaches full invariance. 
Table~\ref{tab:int_vs_exp} presents the average accuracy for each model for the interpolation and extrapolation setup. Across all models \ourmethod~ improves upon RNI and the baseline, with the maximal margin being 18.80 accuracy percentage in the interpolation setting and 21.18 accuracy percentage in the extrapolation setting.
 


\subsubsection{EXP and CEXP}
\citet{abboud2021surprisingpowergraphneural} presented the EXP and CEXP datasets as an example of the improved expressiveness RNI provides, as these tasks cannot be solved with MPGNNs without IDs. However, it was shown that to improve upon the MPGNNs accuracy, much longer training time is required. In the current experiment, we set out to test if {\ourmethod} can achieve the same accuracy of RNI while improving the training time.

\paragraph{Datasets} EXP and CEXP \citep{abboud2021surprisingpowergraphneural} contain 600 pairs of graphs (1,200 graphs in total) that cannot be distinguished by 1\&2-WL tests. The goal is to classify each graph into one of two isomorphism classes. Splitting is done by stratified five-fold cross-validation. CEXP is a modified version of EXP, where 50\% of pairs are slightly modified to be distinguishable by 1-WL. It was shown in \cite{abboud2021surprisingpowergraphneural} that a GraphConv \citep{abboud2021surprisingpowergraphneural} with RNI reaches perfect accuracy on the test set.

\paragraph{Setup}
We repeat the protocol from \citet{abboud2021surprisingpowergraphneural}, who evaluated RNI. We use a GraphConv GNN~\citep{morris2021weisfeiler} with RNI and \ourmethod~with $8$ layers, $64$ random features, $64$ hidden dimensions, over 500 epochs, with $3$ random seeds.


\paragraph{Results}
Figure~\ref{Figure:exp_cexp} presents the learning curves of accuracy during training for \ourmethod~and RNI. Both methods reach a test accuracy of almost 100\%, but \ourmethod~convergence is faster in both tasks, highlighting the effect of explicit regularization towards IDs-invariance as introduced by \ourmethod~ vs. an implicit one as done in RNI using random resampling of IDs during training.
\newline\newline 

