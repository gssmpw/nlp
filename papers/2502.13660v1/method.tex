

\input{invariance_tab}
\input{real_data_tab}

In this section, we build on our analysis in Section~\ref{sec:theory}, and propose \ourmethod, an approach to improve the ability of GNNs to use IDs.
Specifically, Theorem~\ref{thm:mpnnwithidsepxressivity} indicates that the enforcement of invariance in all network layers is not only unnecessary but also does not contribute to the expressive power of the model. Furthermore, Theorem~\ref{thm:only_last_layer} reveals that enforcing invariance solely at the final layer is sufficient to achieve ID-invariance while simultaneously improving the network's expressiveness.
Based on these insights, we propose to explicitly enforce invariance at the network's last layer using a regularizer. By avoiding unnecessary invariance constraints in the intermediate layers, \ourmethod~ maintains and enhances the modelâ€™s capacity to differentiate and leverage IDs effectively.

We consider a GNN layer of the following form:
\begin{equation*}
    \label{eq:general_gnn}
{H}^{(l+1)} = \textsc{GNN}_{\theta^{(l)}}({H}^{(l)}; G),
\end{equation*}
where $\textsc{GNN}_{\theta^{(l)}}$ is the $l$-th layer, and it depends on the input graph structure $G$ and the latest node features ${H}^{(l-1)}$. The layer is associated with a set of learnable weights \( \theta^{(l)} \) at each layer \( l \in \{0, 1, \dots, L-1\} \). The initial node features $H^{(0)}$ of a graph $G$ over $n$ nodes are composed of the concatenation of input node features $X  \in \mathbb{R}^{n \times d}$ and random IDs $I \in \mathbb{R}^{n \times r}$, therefore $H^{(0)} \in \mathbb{R}^{n \times (d+r)}$.

The key idea in {\ourmethod} is to add a term that regularizes models towards invariance to the random idea values. Before describing the regularizer term, we recall the ``standard'' supervised task-loss term.

Given a downstream task, such as graph classification or regression, we compute the task loss $ \mathcal{L}_{\text{task}}$ based on the output of the final GNN layer ${H}^{(L)}$. Specifically, we use a standard linear classifier $g: \mathbb{R}^{d} \rightarrow \mathbb{R}^{d_{\rm{out}}}$, where ${d_{\rm{out}}}$ is the desired dimension of the output (e.g., number of classes), to obtain the final prediction $\hat{y} = g({H}^{(L)})$. This output is fed into a standard supervised loss (e.g., mean-squared error or cross-entropy). Formally, the task loss reads:
\begin{equation*}
    \label{eq:task_loss}
\mathcal{L}_{\text{task}} = \text{Loss}( \hat{y}, y), 
\end{equation*}
where \( y \) is the ground truth label.

To achieve invariance to the IDs, {\ourmethod} utilizes a regularizer 
$\mathcal{L}_{\text{reg}}$ that is computed as follows.
Assume our training sample is \( G_1 = (V, E, {X}) \) with node identifiers $R_1$. 
We sample additional random node IDs $R_2$. Our goal is to make the network
output similar for these two random IDs. Namely, the model should be invariant to the specific values of the node IDs. Let \( {H}_i^{(L)} \) denote the final embeddings for the model with node IDs $R_i$. Namely  \( {H}_i^{(L)} \) is obtained by propagating the inputs with IDs $R_i$ through the network up to the last GNN layer (prior to the final prediction layer).
 To impose ID-invariance, we consider a loss that aims to reduce the difference between these embeddings. There are several options and metrics possible here, and we choose $\ell_2$ for simplicity. Namely we consider the regularizer:
\begin{equation*}
\label{eq:residual_loss}\mathcal{L}_{\text{reg}} =  \|{H}_1^{(L)}- {H}_2^{(L)}\|_2^2.
\end{equation*}

Then, the overall loss per training example in \ourmethod~ is:
\begin{equation*}
    \mathcal{L} = \mathcal{L}_{\text{task}} +  \mathcal{L}_{\text{reg}}.
\end{equation*}
The loss is minimized via standard stochastic gradient descent, where this is the per-sample loss.
Note that it is possible to sample more than two random IDs per training example and adapt the loss accordingly. Here we opt for the simplest version where the sample regularizer only uses two samples.
