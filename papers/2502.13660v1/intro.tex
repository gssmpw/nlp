Graph Neural Networks (GNNs), and in particular Message-Passing Graph Neural Networks (MPGNNs) \citep{morris2021weisfeiler} are limited in their expressive power because they may represent distinct graphs in the same way \citep{garg2020generalizationrepresentationallimitsgraph}. However, when unique node identifiers (IDs) are provided, this limitation is overcome and MPGNNs become Turing complete \citep{loukas2020graphneuralnetworkslearn, cyclesgnns}.

There are several ways to attach unique IDs to nodes. A simple approach is to add features with random values as identifiers and resample them during the training process \cite{sato2021randomfeaturesstrengthengraph, abboud2021surprisingpowergraphneural}. 
This strategy, which we refer to as RNI, almost surely assigns unique IDs to each node.
Consequently, RNIs transform MPGNNs into universal approximators of invariant and equivariant graph functions \cite{abboud2021surprisingpowergraphneural}.
Nonetheless, RNI has been shown to not improve generalization on real-world datasets \citep{murphy2019relational, you2021identity, gpse_canturk, eliasof2024granola, papp2021dropgnnrandomdropoutsincrease, bevilacqua2022equivariant, eliasof2023graph}.


Note that although IDs are used as GNN features, specific ID values should not affect network output. Namely, two different assignments to the IDs should ideally result in the same output. Otherwise, different ID assignments would result in different predictions for the graph label, and therefore at least one of them would be wrong. We refer to this desirable property as ``invariance to ID values''. Intuitively, if such an invariance does not hold, generalization is negatively impacted.

Surprisingly, we find that in practice this invariance often does not hold for GNNs learned with RNIs. This is shown across multiple GNN architectures, real-world, and synthetic datasets, even when resampling IDs per batch. 
These results align with prior research on the implicit bias of GNNs trained with gradient-based methods, which demonstrated a tendency to overfit to graph structures even in scenarios where such structures should be disregarded \cite{bechlerspeicher2024graphneuralnetworksuse}. Consequently, although GNNs are theoretically capable of converging to ID-invariant solutions, they fail to do so.
This lack of invariance leads to overfitting. 
Thus, we set out to improve the ID-invariance of learned GNNs. 


There are several ways of constraining models to be invariant to IDs. For example, one can constrain the output of the first GNN layer to have the same output for all assignments of node IDs. However, we prove that this severely limits the expressive power of the  GNN. Consequently, we conclude that improving expressiveness requires including layers that are not invariant to IDs. Additionally, we demonstrate that a three-layer architecture, with only the final layer being invariant to IDs, suffices to achieve invariance to IDs and expressiveness beyond that of the 1-WL test.



Building on our theoretical findings, we introduce {\ourmethod}: ID-Invariance through Contrast, an approach that achieves ID invariance through explicit regularization. We evaluate \ourmethod~ on both real-world and synthetic datasets across various GNN architectures, demonstrating that \ourmethod~ significantly enhances ID invariance and generalization in many cases. Furthermore, we show that \ourmethod~ improves extrapolation capabilities and accelerates training convergence.


\textbf{Main Contributions:} In this paper, we show how to improve the utilization of node IDs in GNNs, by making models ID-invariant. Our key contributions are:
\begin{enumerate}
    \item  We show, on a series of real-world datasets, that GNNs with RNI fail to learn invariance to IDs, despite resampling. This is an undesirable property, potentially leading to overfitting.
    
 \item We theoretically analyze the properties of GNNs with IDs and derive concrete and practical requirements to achieve invariance to IDs while improving expressiveness with respect to GNNs without IDs. 
 \item Based on our theoretical analysis, we present \ourmethod~ --  an efficient method, that is compatible with any GNN, to achieve invariance to IDs while improving expressiveness.
 \item  We evaluate {\ourmethod} on real-world and synthetic datasets with a variety of GNNs, and show that {\ourmethod} significantly improves invariance to IDs and often improves generalization. Finally, we demonstrate how {\ourmethod} can improve extrapolation capabilities and accelerate training convergence.
\end{enumerate}
