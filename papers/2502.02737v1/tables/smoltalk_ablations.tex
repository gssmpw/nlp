\begin{table}[h]
\caption{Performance on instruction-tuning datasets. MagPie-Ultra$\overset{+}{}$ refers to MagPie-Ultra combined with Smol-Constraints, Smol-Rewrite, and Smol-Summarization. MagPie-Pro-MT is multi-turn while MagPie-Pro is the single turn version. 
All comparisons were performed by fine-tuning the SmolLM2 base model on each dataset for 1 epoch. SmolLM2-SFT$^\dagger$, the final supervised fine-tuned version of SmolLM2, was trained for 2 epochs on SmolTalk.
}
%$^\dagger$ indicates the SmolLM2 SFT checkpoint trained on 2 epochs of the full SmolTalk. All other runs are trained for 1 epoch on the specified dataset using the same training parameters. }
\label{tab:instruction-tuning-ablations}
\centering
% \small                      
% \setlength{\tabcolsep}{4pt}% reduce column spacing
% \renewcommand{\arraystretch}{0.95}% slightly tighten row spacing
\begin{tabular}{l r r r r r r}
\toprule
\textbf{Dataset} & \textbf{IFEval} & \textbf{MTB} 
                 & \textbf{GSM8K}  & \textbf{MATH} & \textbf{ARC-C} & \textbf{MMLU-Pro} \\
\midrule
\multicolumn{7}{c}{Instruction datasets comparison}\\
\cmidrule{1-7}
OpenHermes                    & 30.01 & 1.02 & \textbf{42.91}  & 12.76 & 40.27 & \textbf{20.32} \\
UltraChat                     & 27.26 & 4.66 & 30.40 & 9.06 & \textbf{41.21} & 15.79 \\
MagPie-Pro                    & 30.45 & 4.31 & 14.56 & 6.64 & 36.01 & 12.19  \\
MagPie-Pro-MT                    & 31.66 & \textbf{5.40} & 20.55 & 7.84 & 36.69 & 11.97 \\
MagPie-Ultra                & 35.49 & 5.22 & 24.34 & \textbf{13.56} & 37.71 & 12.01  \\
MagPie-Ultra$\overset{+}{}$                & \textbf{48.16} & 5.28 & 19.94 & 12.74 & 38.91 & 12.43 \\
\midrule  
\multicolumn{7}{c}{Math datasets comparison} \\
\cmidrule{1-7}
MagPie-Ultra$\overset{+}{}$ 
 + MathInstruct               & \textbf{47.05} & 5.43 & 30.1 & 14.0 & \textbf{38.99} & \textbf{13.65}  \\
MagPie-Ultra$\overset{+}{}$ 
 + MetaMathQA                  & 44.98 & 5.02 & \textbf{47.08} & 17.56 & 36.77 & 12.18 \\
MagPie-Ultra$\overset{+}{}$ 
 + NuminaMath-CoT                  & 46.27 & \textbf{5.99} & 25.32 & \textbf{18.00} & 37.88 & 12.58 \\
\midrule
\multicolumn{7}{c}{Full SmolTalk}\\
\cmidrule{1-7}
SmolTalk  & 46.67 & 5.49 & 43.75 & 18.60 & 40.02 & 18.19 \\
SmolLM2-SFT$^\dagger$  & \textbf{57.09} & \textbf{6.11} & \textbf{47.54} & \textbf{19.64} & \textbf{42.49} & \textbf{19.06} \\
\bottomrule
\end{tabular}
\end{table}

% \begin{table}[t]
% \caption{Performance on instruction-tuning datasets. Magpie-Ultra+ denotes Magpie Ultra mixed with Smol-Contraints. Top section compares general instruction datasets, while bottom section shows the impact of adding 20\% specialized math data to 80\% of MagPie-Ultra+}
% \label{tab:instruction-tuning-ablations}
% \centering
% \small                      % or \footnotesize if you need extra shrinking
% \setlength{\tabcolsep}{4pt}% reduce column spacing
% \renewcommand{\arraystretch}{0.95}% slightly tighten row spacing
% \begin{tabular}{lcccccc}
% \toprule
% Model & IFEVAL & BBH & GSM8K & MATH & ARC-C & MMLU-Pro\\
% \midrule
% \multicolumn{7}{c}{\textit{Instruction datasets}}\\
% \cmidrule{1-7}
% ultrachat & 27.28 & 0.02 & 12.05 & 3.62 & 41.81 & 15.94 \\
% Infinity-500k & 25.04 & 0.54 & 24.41 & 5.0 & 39.76 & 16.31 \\
% Magpie-Ultra & 30.36 & 0.04 & 14.71 & 4.96 & 38.4 & 11.7 \\
% Magpie-Ultra+ & 36.37 & 0.03 & 10.46 & 5.14 & 37.97 & 12.04 \\
% \midrule
% \multicolumn{7}{c}{\textit{80\% Magpie-Ultra+, 20\% Math data}}\\
% \cmidrule{1-7}
% MathInstruct & 33.67 & 0.06 & 15.92 & 5.5 & 37.54 & 12.44 \\
% MetaMathQA & 36.17 & 0.01 & 35.03 & 9.92 & 38.82 & 12.34 \\
% Numina & 35.04 & 0.06 & 16.38 & 7.44 & 38.4 & 11.91 \\
% MetaMathQA-Numina & 36.39 & 0.0 & 31.61 & 11.34 & 37.37 & 11.84 \\
% \midrule
% MagpieU+   & 45.47 & \textbf{5.77} & 30.34 & 32.90 & 4.89 \\
% MathInstruct                & 45.66 & 5.63 & \textbf{33.25} & 31.46 & 9.93 \\
% MetaMathQA                  & \textbf{47.50} & 5.66 & 30.08 & \textbf{51.71 }& 14.37 \\
% Numina-CoT                  & 45.47 & 5.37 & 32.15 & 41.32 & \textbf{18.00} \\
% \bottomrule
% \end{tabular}
% \end{table}
