\section{Research Opportunities}
\label{sec:research-agenda}

\systemname shows the potential of LLM-based agents to orchestrate actions, evaluate function outputs, detect errors, and generate additional needed functions. However, there are still open research opportunities to expand the system's capabilities.
Below we outline some of the immediate steps towards these opportunities.


% ----------------------------------------------------
\myparagraph{Agent Evaluation \& Benchmarks} 
Most existing evaluation benchmarks are focused on isolated tasks, such as schema matching or entity linking~\cite{koutras2021valentine, liu2024magneto, wang2021machamp}. 
However, agentic systems create a need for end-to-end evaluation benchmarks and metrics to measure progress effectively. Recently, researchers have started developing benchmarks for evaluating agents in various tasks, including data analysis and ML engineering~\cite{chan2024mle, hu2024infiagent, zhang2024benchmarking, huang2024mlagentbench}. 
The data management community should follow this lead and create benchmarks tailored for data integration, ensuring that LLMs improve in these areas.


\myparagraph{Data Integration Primitives}
\label{sec:proposed-primitives}
Some features, such as \emph{uncertainty} quantification and \emph{explanations}, should be exposed by the primitives to guide decision-making~\cite{uncertainty2009}.
Uncertainty in data integration arises from factors like ambiguous schema mappings and data values~\cite{WangHM2018}. \systemname tackles this by exposing similarity scores through its primitives. For example, a value matcher can return similarity scores, so the agent can strategically trigger complementary primitives (e.g., value mapping) for deeper analysis. A key challenge is conveying the meaning of uncertainty measures from diverse primitive mechanisms to both LLMs and end users, and instructing LLMs on how to use and act on them properly~\cite{dagstuhl2029explanation}.

On the same note, LLMs often lack transparency~\cite{pmlr-v235-huang24x}, so primitives must provide \textit{interpretable explanations} to promote user trust. Primitives should offer clear usage documentation and expose their decision rationale. For instance, a matching algorithm description should document whether its similarity scores derive from syntactic similarity, semantic embeddings, or value distribution analysis. LLMs can also explain their decisions based on domain knowledge and primitive instructions, helping users better understand why a particular path was chosen~\cite{explainability2024,TableMeetsLLM2024}. A key opportunity is training agents to discern when to rely on LLM explanations, apply alternative strategies, or engage with the user directly.

Mapping data between schemata involves resolving entities and transforming data~\cite{dataexchange2018}. LLM-based methods have proven helpful in entity resolution~\cite{narayan-vldb2022, fan2024cost}, generating or finding transformations functions~\cite{zdnet-github-copilot, trummer2022codexdb,autotables2023, autoformula2024, dtt2024, SheetAgent2024}, and evaluating LLM performance on such tasks~\cite{ma2024spreadsheetbench}.
However, integrating these methods into agent-based systems requires consistency across diverse data models and alignment with broader agent goals.
Also, we need methods that allow agents to identify and recommend appropriate attribute transformations and suitable functions for a given input dataset. This is especially in challenging cases such as table restructuring or non-standard formats~\cite{autotables2023}.
Another immediate step is to curate a library of transformation functions specialized in data transformation tasks that agentic systems can readily reuse.


\myparagraph{Robustness and Reliability}
LLMs have shown inconsistency across various scenarios (e.g., as text summarization evaluators~\cite{stureborg2024large}), often producing varying results when executed multiple times~\cite{barrie2024prompt}. This variability can undermine reproducibility and reliability, particularly in critical applications where consistent mappings or transformations are crucial. In our experiments, we observed that while the LLM typically identified and fixed incorrect mappings, it occasionally failed to do so (even when provided with the same prompts).

Handling large and complex tables with many attributes poses additional challenges, as these can lead to long chat histories that exceed the LLM context window. When this occurs, the LLM may lose access to earlier relevant information, thereby affecting the robustness. While approaches have been proposed to mitigate context window limitations (e.g., \cite{jin2024llm} \cite{ma2024megalodon}), 
it is not clear if they address the issues in agent systems. 
Equipping agents with access to read and store data in external databases (such as the Provenance DB discussed in Section ~\ref{sec:agentic-data-harmonization}) may be an effective solution to this issue.

\myparagraph{User-Agent Interaction} To improve usability, agentic systems must go beyond natural language (NL) interfaces. While NL is flexible, it is also often ambiguous and may lead to under-specified task descriptions~\cite{zhang2023clarify}. 
Since the same task can be expressed in multiple unpredictable ways, a mismatch between the user task descriptions and agent prompt specifications may occur. Therefore, detecting when clarifications are needed may help increase overall success~\cite{zhang2023clarify}.
These issues could also be potentially addressed by action-oriented UIs that recommend actions linked to predefined prompts. Moreover, using rich visual representations may be more effective at conveying information to the user.

\myparagraph{Provenance-Aware Agents} 
Provenance collection systems have demonstrated promising results in data science pipelines ~\cite{rupprechtVLDB2020,chapmanCapturing2020}.
In data harmonization pipelines, we can track all interactions that contribute to obtaining a specific value mapping. For example, we could record all user-agent and agent-primitive interactions involved in determining the mapping of ``\texttt{FIGO grade 1}'' to ``\texttt{G1}'' (see Figure \ref{fig:mapping-spec}). 
This would allow tracing the lineage of all values in the output data. Moreover, this information could potentially be used to learn user preferences that reduce the need for user interactions.
% Such systems not only enhance transparency but also reduce the need for user interactions, particularly for new practitioners. 
By learning from provenance and pipelines accumulated over time, a system could further streamline the harmonization process by automating all steps and presenting final results directly to users.
% For instance, a provenance system could streamline the harmonization process by bypassing intermediate steps and presenting final results directly to new users.


\myparagraph{Data Harmonization Pipelines} 
In our system, data harmonization is expressed as a pipeline where multiple primitives (predefined, user-defined, or agent-defined) are interconnected through their inputs and outputs to produce the final harmonized dataset. 
% The pipeline can have various objectives, such as creating a dataset with a desired minimum number of rows, returning a sample result in a few seconds, or generating a high-quality dataset based on a chosen quality metric. 
The pipeline can have various objectives, such as maximining the number of correct column matches and value matches, minimizing the number of interactions with users, or minimizing the computational costs (e.g., runtime or LLM calls).
Achieving these objectives represents an optimization problem, requiring the system to navigate a complex search space and balance multiple objectives to determine an optimal sequence of operations.

Recent work has explored large search spaces for building end-to-end pipelines for various tasks~\cite{lopez2023alphad3m,substrat2022,autopipeline2012vldb,volcanoVLDB2021}. AutoML provides a relevant example where the focus is usually on model quality, and the system selects the best algorithms, features, and hyperparameters~\cite{lopez2023alphad3m}. Pipeline generation for data harmonization can build on such advancements. 
%Still, the task is further complicated by the input data's inherent uncertainty and variability.
An immediate step is building optimizers that measure and balance multiple objectives like harmonization success and computational costs.
Also, our system integrates human-in-the-loop interactions to iteratively refine pipelines based on user feedback and domain expertise. 
An open challenge is determining how to effectively balance automation and human input~\cite{human-in-the-loopdataintegration2017}.

\myparagraph{Acknowledgments}
This work was supported by NSF awards IIS-2106888 and OAC-2411221, and the DARPA
% Automating Scientific Knowledge Extraction and Modeling (ASKEM) program,
ASKEM program
Agreement No. HR0011262087. The views, opinions, and findings expressed are those of the authors and should not be interpreted as representing the official views or policies of the DARPA, the U.S. Government, or NSF.
