% \documentclass[aps,showpacs,preprintnumbers,amsmath,amssymb]{revtex4}
\documentclass[linenumbers, showpacs]{aastex631}

\oddsidemargin 1pt
\evensidemargin 1pt
\textwidth=476pt
\textheight=680pt
\topmargin=-50pt

\newcommand{\vdag}{(v)^\dagger}
\newcommand\aastex{AAS\TeX}
\newcommand\latex{La\TeX}


% \UseRawInputEncoding
% \usepackage{graphicx}
% \usepackage{epstopdf}
% \usepackage{color}
% \usepackage{subfig}
% \usepackage{aasmacros}
% \usepackage{accents}
\usepackage{natbib}
\usepackage{booktabs}


% \bibliographystyle{apsrev4-2}
\begin{document}
\nolinenumbers
% \captionsetup{justification=raggedright,singlelinecheck=false}
\baselineskip=0.8cm
\title{BCDDM: Branch-Corrected Denoising Diffusion Model for Black Hole Image Generation}

\author{Ao liu}
\altaffiliation{These authors contributed equally to this work.}
\affiliation{College of information science and engineering, Hunan Normal University, Changsha,410081, People's Republic of China}

\author{Zelin Zhang}
\altaffiliation{These authors contributed equally to this work.}
\affiliation{Department of Physics, Institute of Interdisciplinary Studies, Key Laboratory of Low Dimensional Quantum Structures and Quantum Control of Ministry of Education, Synergetic Innovation Center for Quantum Effects and Applications, Hunan Normal University,  Changsha, Hunan 410081, People's Republic of China}

% \collaboration{20}{(AAS Journals Data Editors)}

\author{Songbai Chen}
\altaffiliation{Corresponding author: csb3752@hunnu.edu.cn}
\affiliation{Department of Physics, Institute of Interdisciplinary Studies, Key Laboratory of Low Dimensional Quantum Structures and Quantum Control of Ministry of Education, Synergetic Innovation Center for Quantum Effects and Applications, Hunan Normal University,  Changsha, Hunan 410081, People's Republic of China}
\affiliation{Center for Gravitation and Cosmology, College of Physical Science and Technology, Yangzhou University, Yangzhou 225009, People's Republic of China}

\author{Cuihong Wen}
\altaffiliation{Corresponding author:cuihongwen@hunnu.edu.cn}
\affiliation{College of information science and engineering, Hunan Normal University, Changsha,410081, People's Republic of China}

% \author{Ao liu$^{1}$\protect\footnote{These authors contributed equally to this work.} ,
% Zelin Zhang$^{2}$\protect\footnote{These authors contributed equally to this work.} ,
% Songbai Chen$^{2,3}$\protect\footnote{Corresponding author: csb3752@hunnu.edu.cn} ,
% Cuihong Wen$^{1}$\protect \footnote{Corresponding author:cuihongwen@hunnu.edu.cn}}
% \affiliation{
% $^1$ College of information science and engineering, Hunan Normal University, Changsha,410081, People's Republic of China\\
% $^2$Department of Physics, Institute of Interdisciplinary Studies, Key Laboratory of Low Dimensional Quantum Structures and Quantum Control of Ministry of Education, Synergetic Innovation Center for Quantum Effects and Applications, Hunan Normal University,  Changsha, Hunan 410081, People's Republic of China
% \\
% $^3$Center for Gravitation and Cosmology, College of Physical Science and Technology, Yangzhou University, Yangzhou 225009, People's Republic of China}

\begin{abstract}
\nolinenumbers
    \baselineskip=0.6 cm
    The properties of black holes and accretion flows can be inferred by fitting Event Horizon Telescope (EHT) data to simulated images generated through general relativistic ray tracing (GRRT). However, due to the computationally intensive nature of GRRT, the efficiency of generating specific radiation flux images needs to be improved. This paper introduces the Branch Correction Denoising Diffusion Model (BCDDM), which uses a branch correction mechanism and a weighted mixed loss function to improve the accuracy of generated black hole images based on seven physical parameters of the radiatively inefficient accretion flow (RIAF) model. Our experiments show a strong correlation between the generated images and their physical parameters. By enhancing the GRRT dataset with BCDDM-generated images and using ResNet50 for parameter regression, we achieve significant improvements in parameter prediction performance. This approach reduces computational costs and provides a faster, more efficient method for dataset expansion, parameter estimation, and model fitting.
\end{abstract}
% \maketitle

\pacs{ 04.70.Dy, 95.30.Sf, 97.60.Lf }
\newpage


\section{Introduction}
The recent release of black hole images by the Event Horizon Telescope (EHT) collaboration provides direct evidence for the existence of black holes in the universe \cite{2019ApJ...875L...1E,2022ApJ...930L..12E,2024A&A...681A..79E}. These observations offer a unique opportunity to probe the electromagnetic interactions, material distribution, and accretion processes near black holes, further testing the validity of gravity theories and accretion disk models \cite{2018NatAs...2..585M,2021ApJ...910L..12E,2021ApJ...910L..13E,2021ApJ...912...35N,2024ApJ...964L..26E,2024ApJ...964L..25E,2022ApJ...930L..17E,2022ApJ...930L..16E,2022SCPMA..6520411L,2022CoTPh..74i7401W,2022EPJC...82..835Z,2022ApJ...938....2Q,2023SCPMA..6660401C,2024JCAP...09..027Z,Zhang:2024lsf,2024arXiv240907248H}. Accretion disks, as the primary sources of visible light around black holes, significantly influence the resulting images. For the current EHT targets, M87* and Sgr A*, the surrounding hot plasma is considered to be part of a radiatively inefficient accretion flow (RIAF) \cite{2003ApJ...592.1042I,2003PASJ...55L..69N,2014ARA&A..52..529Y,2019ApJ...875L...5E, 2022ApJ...930L..16E,2022MNRAS.511.3795N}. Such flows are typically hot, geometrically thick, and optically thin, making it possible to observe features close to the event horizon, such as the photon ring and the inner shadow \cite{2019PhRvD.100b4018G,2020SciA....6.1310J}. At an observational frequency of 230 GHz, the emission we primarily detected comes from synchrotron radiation produced by relativistic electrons.
However, in the strong gravitational field near black holes, it is not possible to directly infer information about the plasma density, temperature, velocity, or magnetization of accretion disks from the observed images alone. This is typically achieved through general relativistic ray tracing (GRRT) \cite{1979A&A....75..228L,2011CQGra..28v5011V,2016ApJ...820..105P,2021ApJ...912...39G,2022ApJS..262...28W,2024JCAP...11..054H}. By fitting observational data from the EHT to simulated images produced by GRRT, one can effectively extract information about the black hole and the surrounding accretion flow \cite{2020ApJ...897..139B,2021ApJ...910L..13E,2024ApJ...964L..26E,2024MNRAS.535.3181Y}. GRRT involves calculating simulated images of the black hole as seen by the observer, starting with backward ray tracing from the observer to the black hole, followed by radiation transfer calculations through the radiative regions of the accretion disk. However, due to the computationally intensive nature of this process, substantial computational resources are often required. On one hand, to cover a large parameter space, simulations often require the generation of millions of images, demanding significant computational power. On the other hand, Bayesian parameter estimation of the model requires rapid generation of images corresponding to different parameter sets, placing high demands on computational speed \cite{2024MNRAS.535.3181Y}. Some implementations have incorporated GPU acceleration or adaptive ray-tracing methods, yielding significant improvements in computational efficiency \cite{2021ApJ...912...39G,2023ApJS..265...22M}. Recently, advancements in deep neural networks have enabled the generation of black hole images through deep learning, providing a promising new approach for efficiently obtaining such images.

Deep learning models possess powerful feature learning and pattern recognition capabilities, enabling them to extract valuable information from limited data \cite{Krizhevsky2012, Hochreiter1997, 2014Very}. Recent applications of deep learning have shown notable effectiveness in black hole parameter identification \cite{2020A&A...636A..94V,2023MNRAS.520.4867Q} and image reconstruction tasks \cite{2018ApJ...864....7M,2023ApJ...947L...7M}. Several highly effective models have been developed for image generation tasks, offering robust methods for synthesizing realistic, high-quality images.
Generative Adversarial Networks (GANs), which are based on game theory \cite{Generative2014}, use adversarial training to enable two neural networks, namely the generator and the discriminator, to compete with each other, thereby enhancing the generator's ability to produce high-quality samples. While GANs can generate highly realistic images through this adversarial process, the training can be unstable and is prone to mode collapse.
Variational Autoencoders (VAEs) are another class of generative models that learn the probability distribution of data and can generate new samples similar to the training data \cite{kingma2022}. Compared to GANs, VAEs training is more stable; however, VAEs typically produce less realistic images, especially in terms of fine details.
The generation of black hole images had been successfully achieved using both GANs \cite{2024MNRAS.52710965M} and VAEs \cite{2024ApJ...967..140S}.
Compared with GANs and VAEs, diffusion models have a wider range of practical applications \cite{Jonathan2020}. Due to the direct optimization of the logarithmic likelihood of the generation process during training, the diffusion model avoids the common mode collapse problem in GANs. The diffusion model gradually recovers the original data from Gaussian noise through a multi-step denoising process, and the generated samples have very high quality, especially in image generation tasks. The generated images have rich details and high resolution, avoiding the blurring problem of VAEs generated images.

Therefore, we propose a novel black hole image generation method, Branch-Corrected Denoising Diffusion Model (BCDDM), designed to rapidly produce high-quality black hole data and facilitate data augmentation for other algorithms. Diffusion models, as advanced image generation models, have demonstrated their capability to generate high-fidelity images across various domains. However, to the best of our knowledge, no prior research has applied them to black hole image generation. This study aims to explore whether BCDDM can learn the mapping between black hole parameters and images during the generation process. Concurrently, we attempt to train a ResNet50 regressor using the augmented data, with the expectation of enhancing the model's predictive capacity for black hole parameters. 
% In this study, we utilized black hole images generated by the RIAF model as our experimental data. However, our approach has the potential to be extended to the use of real black hole data in the future.

The main contributions of this article are as follows: 
Firstly, this paper presents an innovative diffusion architecture model, BCDDM, which addresses the limitations of traditional methods in accurately mapping images to physical parameters during black hole image generation. By incorporating parameter correction branches and a mixed loss function, BCDDM significantly enhances the precision and diversity of the generated images.
Additionally, BCDDM is the first to apply diffusion algorithms to black hole image generation. The experimental results demonstrate that the model is capable of producing high-quality black hole images with a strong correlation to physical parameters, thereby offering novel tools and methodologies for astronomical observations and theoretical studies.
Finally, the integration of a ResNet50-based black hole parameter regressor confirms the high fidelity of images produced by BCDDM and underscores the model's substantial contribution to improving the performance of data-driven regressors in parameter prediction.


\section{Methods}

\begin{figure}[ht!]
     \centering
     \includegraphics[width=1\linewidth]{fig1.png}
     \caption{\label{fig1}\textbf{BCDDM architecture for black hole image generation. }The diffusion process and denoising process use the same Unet model, and the specific model architecture is explained in the Figure \ref{fig9}. }
\end{figure}

As illustrated in Figure \ref{fig1}, the architecture of BCDDM begins by encoding the timestep and physical parameters, followed by integrating the encoded information with the black hole image. Subsequently, the forward diffusion process is applied, gradually adding noise to the input image until it is transformed into a noise distribution approximating a Gaussian. Then, a trained branch-corrected noise prediction network is utilized to perform reverse denoising on the random noise, ultimately generating new data samples from pure noise.


\subsection{Black hole image dateset}
We generate a dataset using the RIAF model with the GRRT code \textit{ipole} \cite{2018MNRAS.475...43M}, which calculates the radiation intensity distribution for simulated observational images. These images are produced at a frequency of 230 GHz, with a camera field of view of \( 128 \times 128 \ \mu \mathrm{as} \) and resolution of \( 256 \times 256 \). To align with the M87 case, we fix the observer inclination angle at \( 163^\circ \) and adjust the total radiative flux to \( 0.5 \ \mathrm{Jy} \) \cite{2019ApJ...875L...5E}. Seven physical parameters are varied in the simulation, with their respective value ranges provided in Table \ref{tab:parameter}. The rotation direction of the accretion disk is randomly selected between \( -1 \) (clockwise) and \( 1 \) (counterclockwise), while the other six parameters are uniformly sampled within their respective ranges. Ultimately, we generate a set of 1912 images for training BCDDM.

\begin{table}[ht]
     \caption{\centering{Parameter ranges used in the RIAF black hole images generation.}}
    \centering
    \begin{tabular}{|c|c|c|}
        \hline
        \textbf{Parameter} & \textbf{Symbol} & \textbf{Range} \\
        \hline
        Black hole spin & \(a\) & \([-1, 1]\) \\
        Black hole mass & \(M_{\mathrm{BH}}\) & \([2 \times 10^9 M_{\odot}, 10^{10} M_{\odot}]\) \\
        Electron temperature & \(T_e\) & \([10^9 \, \mathrm{K}, 10^{12} \, \mathrm{K}]\) \\
        Accretion disk thickness & \(h_{\mathrm{disk}}\) & \([0.1, 0.8]\) \\
        Keplerian factor & \(k\) & \([0, 1]\) \\
        Position angle & \(PA\) & \([0^\circ, 360^\circ]\) \\
        Fluid direction & \(F_{\mathrm{dir}}\) & \(-1 \) ,\( 1\) \\
        \hline
    \end{tabular}
    \label{tab:parameter}
\end{table}

\subsection{Z-score normalization}
In the study of black hole physics, due to the extreme physical properties of black holes themselves, the datasets involved often contain extreme values that may differ significantly in magnitude from other data. In deep learning frameworks, the inconsistency of data scales can lead to numerical computation problems such as gradient explosion or vanishing, which can seriously affect the training effectiveness and convergence performance of the model. To alleviate these numerical instabilities, we introduce Z-score normalization technique to preprocess black hole parameters \cite{Fei2021}. Z-score quantifies the standard deviation of a single data point relative to the mean of the entire dataset. Through Z-score, the raw data is transformed into a standard normal distribution, with its mean adjusted to 0 and standard deviation to 1, ensuring consistency in data scale. We assume that r represents the parameter category, x is the initial black hole parameter value, $\mu$ is the average of the initial black hole parameters, $\sigma$ is the standard deviation of the initial black hole parameters, z is the normalized black hole parameter value, and the Z-score normalization formula is as follows:
\begin{equation}
     z_{r} = \frac{x_{r} - \mu_{r}}{\sigma_{r}}, \quad \text{for} \quad r \in \{1, 2, \ldots, 7\}
\end{equation}
Z-score normalization is a reversible linear transformation, which means we can also restore the black hole parameters output by the regressor.

\subsection{Derivation of BCDDM algorithm}
 We integrate black hole parameters such as spin, electron temperature, mass, etc. into the label encoding of the model architecture. The parameter encoding structure is shown in the Figure \ref{fig9}. By mapping the parameter features of the black hole to a high-dimensional embedding space, the model can understand the information in the feature space from multiple scales. During the training process, we add standard Gaussian noise $N(0,1)$ to the black hole image and convert it to pure Gaussian noise through T-step Gaussian noise addition. We assume that $\beta_t$ is the diffusion coefficient at time step $t$, and the conversion formula from step $t-1$ to step $t$ is as follows:

\begin{equation}
     q(x_t | x_{t-1}) = \mathcal{N}(x_t; \sqrt{1 - \beta_t} x_{t-1}, \beta_t I)
\end{equation}

We define $\epsilon_t$ as the noise sampled from the standard normal distribution $N(0,1)$, so the formula is also equivalent to another representation.

\begin{equation}
     x_t = \sqrt{1 - \beta_t} x_{t-1} + \sqrt{\beta_t} \epsilon_t
\end{equation}

Therefore, the forward adding noise process of black hole images can be represented as:
\begin{equation}
     q(x_{1:T} | x_0) = \prod_{t=1}^T q(x_t | x_{t-1})
\end{equation}

The denoising process is the process of calculating the current denoised image $X_{t-1}$ given the initial black hole image $X_{0}$ and the current noisy image $X_{t}$. The denoising result is a Gaussian distribution with a mean of $\mu_t$ and a variance of $\beta_t $.
\begin{equation}
     q(x_{t-1} | x_t, x_0) = \mathcal{N}(x_{t-1}; \mu_t, \beta_t I)
\end{equation}

We define $\alpha_t = 1 -\beta_t  $, $\bar{\alpha}_t = \prod_{s=1}^t \alpha_s$,  so the mean and variance can be proven as follows:
\begin{equation}
     \mu_t = \frac{\alpha_t}{\sqrt{1 - \alpha_t}} \left ( x_t - \frac{\sqrt{1 - \bar{\alpha}_t}}{\sqrt{1 - \alpha_t}} \epsilon_t \right )
\end{equation}
\begin{equation}
     \beta_t = \frac{1 - \bar{\alpha}_{t-1}}{1 - \bar{\alpha}_t} \beta_t
\end{equation}

During the training process, we use U-Net to predict the noise $\epsilon_\theta(x_t,t)$, and then calculate the residual between the output of U-Net and the actual added noise $\epsilon$. This residual is used to calculate the loss function, and the specific loss function formula is explained in Section \ref{loss}. By minimizing this loss function, the U-Net network can learn how to more accurately predict noise, thereby training the BCDDM to extract the distribution of high-quality black hole images from Gaussian noise.

\subsection{\label{loss}Parameter Corrector Branch}

\begin{figure}[ht!]
     \centering
     \includegraphics[width=1\linewidth]{fig9.png}
     \caption{\label{fig9}\textbf{Encoding and Decoding architecture embedded in BCDDM. }The only part of the model that requires training parameters is the input encoded label vector and black hole image, and the output prediction parameters and prediction noise. }
\end{figure}

In our study, we make innovative improvements to the U-Net structure in BCDDM, as shown in the Figure \ref{fig9}. After the lowest point of the downsampling path in U-Net, we add a parameter corrector branch. This branch is responsible for encoding the extracted features to find the mapping between image distribution and physical parameters. We construct a mixed loss function consisting of two parts: noise loss $L_{noise}$ and parameter label loss $L_{label}$ \cite{Wan2000}. Among them, $L_{noise}$ is the same loss function used in general diffusion models, which measures the difference between U-net predicted noise and actual noise to ensure the clarity of the generated image. Assuming that $\theta$ represents the parameters of the model, the $L_{noise}$ calculation formula is
\begin{equation}
      L_{\text{noise}} = \mathbf{E}_{t, x_0, \epsilon} \left[ \left( \epsilon - \epsilon_{\theta}(x_t, t) \right)^2 \right]
\end{equation}

The images generated by DDPM have randomness, while $L_{label}$ will have a corrective effect on the generated images. Improving U-net ensures consistency between generated images and input black hole parameters by measuring the difference between encoded features and label vectors. Assuming $k$ is the feature vector extracted by U-net downsampling, $f(k)$ is the fully connected encoding function of $k$, and $l$ is the input parameter label. So the calculation formula for $L_{label}$ is

\begin{equation}
     L_{\text{label}} = \mathbf{E}_{x_0, l} \left[ \left( f(k) - l \right)^2 \right]
\end{equation}

We add weights $\lambda_1$ and $\lambda_2$ to the mixed loss function to ensure that the model optimizes both directions with equal emphasis. The final mixed loss function can be expressed as:
\begin{equation}
     L = \lambda_1 L_{\text{noise}} + \lambda_2 L_{\text{label}}
\end{equation}


\section{Results}
\subsection{Generate Black Hole Image Results}
We have set up a diffusion model with a diffusion step T=1000, as shown in Figure \ref{fig8}. The diffusion process of the model starts from a 1-channel black hole image of 256 * 256, and the diffusion coefficient b starts from 10e-4 and ends at 0.02. We set the initial learning rate to 3e-4 and gradually decrease it with the training batch to help the model converge better. We constructe a small-scale dataset using 1912 RIAF black hole images for BCDDM training, and the training results are as follows.
\begin{figure}[ht!]
     \centering
     \includegraphics[width=1\linewidth]{fig8.png}
     \caption{\label{fig8}\textbf{The diffusion process of black hole images. }We output the image every 100 steps for a total of 1000 times to observe the changes in the diffusion process of the image. }
\end{figure}

We train the model for 5000 epochs and record the changes in loss, as shown in the Figure \ref{fig3}. We can observe that the loss of the initial model decreases rapidly and slowly converges to 0 in the later stage. We generate some synthetic black hole images at epoch 100, 1000, 2500, and 5000 to observe the performance changes of the generated model. It can be seen that as the loss decreases, the images gradually become clearer.
\begin{figure}
     \centering
     \includegraphics[width=0.85\linewidth]{fig3.png}
     \caption{\label{fig3}\textbf{The change curve of losses during the training process. }As the training epochs increase, the prediction error of the model gradually decreases until convergence, and the imaging effect of the black hole gradually becomes clearer. }
\end{figure}

We use the model saved in the 5000th epoch to generate images directly from physical parameters and random noise, as shown in the Figure \ref{fig10}. We randomly selecte 5 images from the RIAF dataset and reconstruct the black hole image using the corresponding five sets of black hole parameters. We demonstrate the differences between generated images with the same parameters using different methods, and attache the output results of the parameter corrector branch. From the comparison of the generated images, it is evident that under identical parameter conditions, the images produced by BCDDM are nearly indistinguishable from those generated by classical methods. This demonstrates that the parameter correction branch enables the model to precisely learn the mapping between images and physical parameters, highlighting the stability and reliability of BCDDM.

\begin{figure}
     \centering
     \includegraphics[width=0.85\linewidth]{fig10.png}
     \caption{\label{fig10}\textbf{Randomly selected 5 sample images and reconstructed output.}The figure shows the comparison between the original image and the reconstructed image. The first row of parameters is the original parameters, which are also used as initial parameters for the reconstructed image. The second row of parameters is the output of the parameter corrector branch. }
\end{figure}


\subsection{Parameter Regression Evaluator}
After obtaining the synthesized image data, we integrate it with RIAF black hole images to obtain a multi class mixed dataset. Our goal is to create a deep learning based black hole parameter regression model and demonstrate that BCDDM synthesized black hole images can help improve the accuracy of black hole parameter detection. 

We utilize the RIAF dataset to construct real dataset(RLDs), validation set, and test set. Subsequently, we employ the maximum and minimum values of physical parameters in the dataset as boundaries, uniformly distributing them to generate reconstruction parameters, and subsequently produce corresponding black hole images. We use RTX3090 graphics card, which can generate images at a speed of 5.25 seconds per sheet. After generating the black hole images, we create fake dataset(FKDs) and mixed dataset(MXDs). FKDs comprises synthesized black hole images, while MXDs is the combination of RLDs and FKDs. The sizes of all datasets are presented in the Table \ref{tab1}.

\begin{table}
     \caption{\label{tab1}\centering{Dataset size.}}
     \centering
     \resizebox{0.25\textwidth}{!}{
     \begin{tabular}{cccc}
     \hline
     Dataset & Train & Val & Test\\
     \hline
     RLDs & 1548 & 172 & 192   \\
     FKDs & 1563 & 172 & 192   \\
     MXDs & 3111 & 172 & 192   \\
     \hline
     \end{tabular}
     }
\end{table}

As shown in the Figure \ref{fig5}, we constructed three datasets, one from a deep generative learning model and the other from the RIAF dataset. We trained three regressors with different parameters based on the classic model ResNet50 \cite{He2016}, and conducted $R^2$ evaluations on the test sets from RIAF data.

\begin{figure}[ht!]
     \centering
     \includegraphics[width=0.85\linewidth]{fig5.png}
     \caption{\label{fig5}\textbf{Workflow of Constructing Datasets from Multiple Sources and Evaluating Regression Model Performance. }This figure outlines the process of constructing datasets from diverse sources and evaluating the performance of a regression model. It highlights two primary data sources: RIAF Datasets and BCDDM Datasets. The figure underscores the critical step of using a test set to validate the $R^2$ metric, culminating in the output of the $R^2$ score to assess the model's performance.} 
\end{figure}


We use $R^2$ to evaluate our proposed method, which is a commonly used metric for regression analysis in machine learning. The range of $R^2$ values is from 0 to 1, and the closer it is to 1, the better the fit of the model to the data. We assume that $y_i$ is the i-th observation of the dependent variable, $ \hat{y}_i$ is the model's predicted value for the i-th observation, and n is the number of observations. So the calculation formula for $R^2$ can be expressed as
\begin{equation}
     R^2 = 1 - \frac{\sum_{i=1}^{n} (y_i - \hat{y}_i)^2}{\sum_{i=1}^{n} (y_i - \bar{y})^2}
\end{equation}

\begin{table}
     \caption{\label{tab2}\centering{$R^2$ values for different parameters in three datasets.}}
     \centering
     \resizebox{\textwidth}{!}{
     \begin{tabular}{ccccccc}
     \hline
     Trainset & $a$ & $T_{e}$ & $h_{disk}$ & $M_{BH}$ & $k$  & $PA$\\
     \hline
     RLDs & 0.7181 & 0.9603 & 0.9347 & 0.9921 & 0.9157  & 0.8734 \\
     FKDs & 0.7195($\uparrow$0.0014) & 0.7792($\downarrow$0.1811) & 0.8953($\downarrow$0.0394) & 0.9486($\downarrow$0.0435) & 0.8360($\downarrow$0.0797) & 0.8612($\downarrow$0.0122) \\
     MXDs & 0.8120($\uparrow$0.0939) & 0.9654($\uparrow$0.0051) & 0.9628($\uparrow$0.0281) & 0.9944($\uparrow$0.0023) & 0.9310 ($\uparrow$0.0153)& 0.8926($\uparrow$0.0192) \\
     \hline
     \end{tabular}
     }
\end{table}

The Table \ref{tab2} shows the $R^2$ scores of three datasets experiments. We observe that although the FKDs composed of synthesized images scored lower than RLDs, the model trained on reconstructed images is acceptable for predicting RIAF black hole images. The more important point is that for each parameter, the $R^2$ score of MXDs is significantly higher than that of RLDs. This indicates that the addition of synthetic images exposes the model to a wider range of feature combinations during the training process. Increased the diversity and quantity of training data, effectively reducing the overfitting phenomenon of the model. Meanwhile, the increase in $R^2$ value also proves in reverse that BCDDM can learn the mapping relationship between black hole images and black hole parameters. The synthesized images generated by BCDDM not only visually resemble real images, but also have a high degree of consistency in statistical properties and physical meaning. This result demonstrates the feasibility of BCDDM in synthesizing black hole images. By generating high-quality synthetic images, BCDDM provides a new data augmentation method for black hole research, which helps overcome the problem of data scarcity and promotes the development of astrophysics.

\begin{figure}[ht!]
     \centering
     \includegraphics[width=0.85\linewidth]{fig7.png}
     \caption{\label{fig7}\textbf{The binary confusion matrix of $F_{dir}$.}The datasets corresponding to the three images are RLDs (left), FKDs (middle), and MXDs (right). The classification accuracies of three training sets for fluid-direction are 92.19\%, 89.58\% and 94.27\%. }
\end{figure}

\begin{figure}
     \centering
     \includegraphics[width=0.85\linewidth]{fig6.png}
     \caption{\label{fig6}\textbf{The fitting results of RLDs and MXDs on the test set samples.}The prediction error of the test set after training with RLDs for 5000 epochs (left) and the prediction error of the test set after training with MXDs for 5000 epochs (right). }
\end{figure}

At the same time, as shown in the Figure \ref{fig7}, the confusion matrix for binary classification of fluid-dirction also indicates that MXDs has the best classification performance. This indicates that our method can perform data augmentation on small-scale datasets, increasing the size of the training dataset and helping the regressor to more accurately understand the mapping relationship between black hole parameters and images.

In addition, in the Figure \ref{fig6}, we show the fitting results of the test set samples for RLDs and MXDs. We sorted the label points by numerical value from small to large and plotted the regressor's predictions and errors for the samples. We can clearly see that compared to RLDs, the predicted results of MXDs are closer to the true values. We have ample reason to believe that our proposed method can accurately generate clear black hole images while preserving the characteristics of black hole parameters. This achievement is expected to provide strong support and assistance for other data-driven algorithms.

\section{Conclusion}
In this study, we propose an innovative black hole image generation method named Branch Correction Denoising Diffusion Model, aimed at effectively enhancing limited scale black hole image data stes and accelerate the generation of black hole images. By innovatively improving the architecture of the classical diffusion model, we introduce a parameter correction branch and use a mixed loss function to ensure that the model can learn both image distribution and black hole parameters simultaneously. The experimental results show that BCDDM can not only generate clear and high-quality black hole images from noisy images, but also ensure that the features of the generated images correspond accurately to the initial parameters.

In addition, our research also indicates that the dataset generated by BCDDM is highly consistent with the training set in terms of statistical properties and physical significance. By mixing generated data with real data for training a regressor, we found that its performance was significantly better than a regressor trained solely on real data. This improvement is attributed to the significant increase in the number and diversity of the training set generated by the data, thereby improving the model's generalization ability.
In the experiment, we used a single RTX 3090 GPU to generate images with a specific radiative flux, achieving an efficient performance with a generation time of just 5.25 seconds per image. Although the simulated dataset used in this study is derived from the RIAF model, the BCDDM method is broadly applicable and can be extended to data from other accretion disk model, with future applications anticipated for a wider range of accretion disk models.

\section*{Acknowledgments}
This work was supported by the National Natural Science Foundation of China under Grants No. 12374408, 12475051, 12275078, 12035005;  the Natural Science Foundation of Hunan Province under grant No. 2023JJ30384;  the science and technology innovation Program of Hunan Province under grant No. 2024RC1050; and the innovative research group of Hunan Province under Grant No. 2024JJ1006.


\newcommand{\JournalTitle}{}
\bibliography{sample}{}
\bibliographystyle{aasjournal}

\end{document}
