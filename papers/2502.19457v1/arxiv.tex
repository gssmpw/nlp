\documentclass[journal]{IEEEtran}
\IEEEoverridecommandlockouts
% The preceding line is only needed to identify funding in the first footnote. If that is unneeded, please comment it out.
\usepackage{cite}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{algorithmic}
\usepackage{graphicx}
\usepackage{textcomp}
\usepackage[table]{xcolor}
\usepackage{booktabs}
\usepackage{tikz}
\usepackage{multirow}
\usepackage{array}
\usepackage{caption}
\usepackage{tikz}
\usepackage{hyperref}
\usepackage{orcidlink}

\usetikzlibrary{shapes.geometric, arrows, positioning}

\newcommand{\enzo}[1]{\textcolor{red}{Enzo: #1}}
\newcommand{\CN}[1]{\textcolor{blue}{Chaonig: #1}}

\usetikzlibrary{arrows.meta, positioning}
\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
    T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}

\tikzstyle{box} = [rectangle, rounded corners, minimum width=3cm, minimum height=1cm, text centered, draw=black, fill=blue!20]
\tikzstyle{arrow} = [thick,->,>=stealth]

\begin{document}


\title{Compression in 3D Gaussian Splatting: A Survey of Methods, Trends, and Future Directions}

% \author{Muhammad Salman Ali,
% {Marco Cagnazzo \orcidlink{0000-0001-6731-3755}}, \IEEEmembership{Senior Member, IEEE},
% {Enzo Tartaglione \orcidlink{0000-0003-4274-8298}}, \IEEEmembership{Senior Member, IEEE},
% {Giuseppe Valenzise \orcidlink{0000-0002-5840-5743}}, \IEEEmembership{Senior Member, IEEE},
% {Chaoning Zhang \orcidlink{0000-0001-6007-6099}}, \IEEEmembership{Senior Member, IEEE}, and 
% {Sung-Ho Bae \orcidlink{0000-0003-2677-3186}}, \IEEEmembership{Member, IEEE}
\author{
    Muhammad Salman Ali, 
    Chaoning Zhang \orcidlink{0000-0001-6007-6099}, 
    \IEEEmembership{Senior Member, IEEE}, 
    Marco Cagnazzo \orcidlink{0000-0001-6731-3755}, 
    \IEEEmembership{Senior Member, IEEE}, 
    Giuseppe Valenzise \orcidlink{0000-0002-5840-5743}, 
    \IEEEmembership{Senior Member, IEEE}, 
    Enzo Tartaglione \orcidlink{0000-0003-4274-8298}, 
    \IEEEmembership{Senior Member, IEEE}, and \\
    Sung-Ho Bae \orcidlink{0000-0003-2677-3186}, 
    \IEEEmembership{Member, IEEE}

%\corresp{Corresponding Author: Sung Ho Bae (email: shbae@khu.ac.kr).}

\thanks{  Muhammad Salman Ali and Sung-Ho Bae are with the Department of Computer Science and Engineering, Kyung Hee University, South Korea (email: salmanali@khu.ac.kr).

        Chaoning Zhang is with School of Computer Science and Engineering, University of Electronic Science and Technology of China (UESTC), Chengdu, China. 

        Marco Cagnazzo is with LTCI, T\'el\'ecom Paris, Institut Polytechnique de Paris, France and Università degli Studi di Padova, Padua, Italy. 
        
        Giuseppe Valenzise is with the CNRS, CentraleSup\'elec, Laboratoire des Signaux et Systèmes, Université Paris-Saclay, France.
        
        Enzo Tartaglione is with LTCI, T\'el\'ecom Paris, Institut Polytechnique de Paris, France.

        }}

\maketitle
\begin{abstract}
%3D Gaussian Splatting (3DGS) has recently emerged as a novel technique in explicit radiance fields and computer graphics. 3DGS utilizes millions of learnable 3D Gaussians representing a major shift from conventional neural radiance field methods, which primarily employ implicit, coordinate-based models to map spatial coordinates to pixel values. 3DGS positions itself as a potential game-changer for the next generation of 3D reconstruction and representation due to its inherent explicit scene representation and differentiable rendering algorithm. 
%3D Gaussian Splatting (3DGS) has recently emerged as a pioneering approach in explicit scene rendering and computer graphics. Unlike traditional neural radiance field methods, which typically rely on implicit, coordinate-based models to map spatial coordinates to pixel values, 3DGS utilizes millions of learnable 3D Gaussians. Its differentiable rendering technique and inherent capability for explicit scene representation and manipulation positions 3DGS as a potential game-changer for the next generation of 3D reconstruction and representation technologies. This enables 3DGS to deliver real-time rendering speeds while offering unparalleled editability levels. However, despite rapid advancements, the literature regarding the scalability of these models is still in its infancy \CN{if there isn't much work, why bother a survey?}. This work shall present a comprehensive overview focusing on the scalability and compression \CN{in the title, only compression, but here both} of 3DGS. We will \CN{avoid using future tense, just say we begin with} begin with a detailed background overview of 3DGS and an overview of 3DGS compression techniques. Additionally, we shall provide insights into how we can draw inspiration from efficient Neural Radiance Field (NeRF) techniques for future advancements. We will conclude the survey by identifying present challenges in the research and potential directions to be explored in the future. \CN{overall, future tense is not necessary}
%3D Gaussian Splatting (GS) has recently emerged as a transformative technique in explicit radiance fields and computer graphics. This innovative approach, characterized by the use of millions of learnable 3D Gaussians, marks a significant departure from mainstream neural radiance field methods, which predominantly employ implicit, coordinate-based models to map spatial coordinates to pixel values. With its explicit scene representation and differentiable rendering algorithm, 3D GS not only promises real-time rendering capabilities but also introduces unprecedented levels of editability. This positions 3D GS as a potential game-changer for the next generation of 3D reconstruction and representation. In this paper, we provide the first systematic overview of recent developments and critical contributions in the domain of 3D GS compression. We begin with a detailed exploration of the underlying principles of compression and the driving forces behind the emergence of 3D GS, laying the groundwork for understanding its significance and how it can be integrated with compression principles. A focal point of our discussion is the compressibility of 3D GS, complemented by a comparative analysis of recent compressed 3D GS models, evaluated across various benchmark tasks to highlight their performance and practical utility. The survey concludes by identifying current challenges and suggesting potential avenues for future research in this domain.
3D Gaussian Splatting (3DGS) has recently emerged as a pioneering approach in explicit scene rendering and computer graphics. Unlike traditional neural radiance field (NeRF) methods, which typically rely on implicit, coordinate-based models to map spatial coordinates to pixel values, 3DGS utilizes millions of learnable 3D Gaussians. Its differentiable rendering technique and inherent capability for explicit scene representation and manipulation positions 3DGS as a potential game-changer for the next generation of 3D reconstruction and representation technologies. This enables 3DGS to deliver real-time rendering speeds while offering unparalleled editability levels. However, despite its advantages, 3DGS suffers from substantial memory and storage requirements, posing challenges for deployment on resource-constrained devices. In this survey, we provide a comprehensive overview focusing on the scalability and compression of 3DGS. We begin with a detailed background overview of 3DGS, followed by a structured taxonomy of existing compression methods. Additionally, we analyze and compare current methods from the topological perspective, evaluating their strengths and limitations in terms of fidelity, compression ratios, and computational efficiency. Furthermore, we explore how advancements in efficient NeRF representations can inspire future developments in 3DGS optimization. Finally, we conclude with current research challenges and highlight key directions for future exploration.
\end{abstract}


\section{Introduction}
\IEEEPARstart{T}{ransforming} a collection of views, images, or video capturing a scene into a 3D model such that computers can process it is the goal of image-based 3D scene reconstruction. This complex and enduring problem is crucial for enabling machines to understand the complexities of real-world environments, paving the way to a diverse range of applications including 3D animation and modeling,  navigation of robots, scene preservation, virtual/augmented reality, and autonomous driving~\cite{kalkofen2008comprehensible,patney2016towards,albert2017latency}. The evolution of 3D scene reconstruction precedes the rise of deep learning, with initial efforts focusing on light fields and fundamental scene reconstruction techniques~\cite{gortler2023lumigraph,levoy2023light,buehler2023unstructured}. However, these early works faced limitations due to their dependence on dense sampling and structured capture, which presented significant challenges in managing complex scenes and lighting variations. The introduction of structure-from-motion~\cite{snavely2006photo,goesele2007multi} and the subsequent enhancements in multiview stereo algorithms offered a more resilient foundation for 3D scene reconstruction. However, these approaches encountered difficulties in synthesizing novel views and lacked alignment with deep scene understanding models.

Before Gaussian Splatting gained its popularity for the task of 3D reconstruction, NeRFs~\cite{mildenhall2020nerf} constituted as a go-to method, representing a significant breakthrough in this advancement. Using fully connected neural networks, NeRFs facilitate the direct mapping of spatial coordinates to color and density. The success of NeRFs lies in their capability to generate continuous, volumetric scene functions, yielding results with remarkable detail and realism~\cite{liao2024ov,lin2025dynamic,sheng2024open,zhu2024dfie3d,ding2024ray}. However, like any emerging technology, this implementation incurs certain costs.
\begin{enumerate}
    \item Computational Complexity: NeRF-based methods have significantly high computational complexity~\cite{chen2022tensorf,garbin2021fastnerf,takikawa2021neural}, often requiring long training times and significant resources for rendering, particularly for high-resolution outputs. 
    \item Scene Editability: Performing implicit scenes can be challenging, as modifying the neural network’s weights does not directly correspond to changes in the geometry or appearance of the scene~\cite{ali2024elmgs,qian20233dgs,lee2023compact}.
\end{enumerate}

\input{Tables/Taxonomy_Table}
\input{Display_Figures/taxonomy}



% \begin{figure}[t]
%     \centering
%     \includegraphics[width=0.8\linewidth]{Figures/Teaser_Figure_again.pdf}
%     \caption{Graph showing the number of publications and corresponding Github stars in 3DGS from July 2023.%\enzo{graphically ugly... looks like an excel screenshot}
%     }
%     \label{fig:teaser}
% \end{figure}


% In this context, 3D Gaussian Splatting (3DGS)~\cite{kerbl20233d} presents a novel approach to scene representation and rendering. 

Although NeRFs are adept at producing photorealistic images, there is a growing need for faster and more efficient rendering techniques, especially for applications where low latency is essential. 3D Gaussian Splatting (3DGS) solves this problem by employing millions of learnable 3D Gaussians in space for explicit scene representation in scene modeling. 3DGS employs an explicit representation and a highly parallelized rasterization approach, which facilitates more efficient computation and rendering, unlike implicit coordinate-based models~\cite{henzler2019escaping,sitzmann2019deepvoxels,mildenhall2020nerf}. The innovation of 3DGS lies in its integration of differentiable pipelines and point-based rendering techniques~\cite{pfister2000surfels,zwicker2001surface,ren2002object,botsch2005high}. Modeling the scenes with learnable 3D Gaussians preserves the robust overfitting capabilities of continuous volumetric radiance fields required for high-quality image synthesis. Simultaneously, it circumvents the computational complexity of NeRF-based methods, such as the computationally expensive ray marching process and redundant calculations in unoccupied space~\cite{10757420}.


%\input{Display_Figures/structure}




The introduction of 3DGS signifies more than just a technical leap forward; it represents a fundamental change in the approach to scene representation and rendering within computer vision and graphics. By facilitating real-time rendering capabilities while maintaining high visual fidelity, 3DGS paves the way for several applications ranging from virtual reality and augmented reality to real-time cinematic rendering and beyond~\cite{jiang2024vr}. This advancement promises to not only enhance current applications but also unlock new ones that were previously hindered by computational limitations~\cite{liu2024georgs,10879794}. Furthermore, the explicit scene representation provided by 3DGS offers unparalleled flexibility in managing objects and scene dynamics, which is essential to handle complex scenarios with intricate geometries and diverse lighting conditions~\cite{chabra2020deep, wang2021learning}. 
This high degree of editability combined with the efficiency of both the training and rendering processes enables 3DGS to have a deep impact on future advancements in different domains~\cite{10900457}. As a relatively recent emergence, within less than a year, the multitude of works on 3DGS underscores its broad applicability across diverse domains such as robotics~\cite{yan2024gs,keetha2024splatam,matsuki2024gaussian,yugay2023gaussian,huang2024photo}, avatars~\cite{li2024animatable,hu2024gauhuman,lei2024gart,yuan2024gavatar,hu2025tgavatar}, endoscopic scene reconstruction~\cite{huang2024endo,liu2024endogaussian,zhao2024hfgs,wang2024endogslam}, and physics~\cite{xie2024physgaussian,liu2024physics3d,borycki2024gasp,huang2024dreamphysics,zhang2024physdreamer}. 

Compared with NeRFs, 3DGS has the advantage of faster rendering speed but at the cost of higher demand of memory with the need to store millions of Gaussians. This limits their application in resource-constrained devices, like VR/AR or game environments. Therefore, there has been a notable increase in research activities focused on compressing 3DGS scenes. With the development of numerous novel compression methods, these efforts have resulted in significant advancements in compression ratios. Consequently, there is a pressing need for a timely review and summary of these representative methods for 3DGS compression. Such a review would help researchers grasp the overall landscape of 3DGS compression, providing a comprehensive and structured overview of current achievements and major challenges in the field.

\input{Display_Figures/3DGS_working}


\noindent
\textbf{Scope:} This survey will explore the compression-specific design of the 3DGS architecture, covering various modules including but not limited to densification of Gaussians, pruning, vector quantization, scalar quantization, Gaussian structure, and point cloud compression.

\noindent
\textbf{Related Surveys: }A few 3DGS surveys exist~\cite{DBLP:journals/corr/abs-2401-03890,fei20243d, bao20243d,wu2024recent}. However, to the best of our knowledge, only one survey focuses on the compression of 3DGS. 3DGS.zip~\cite{bagdasarian20243dgs} provides an overview of existing compression techniques, with its primary contribution being the establishment of a unified evaluation standard.  In contrast, our work systematically categorizes different compression methods within a proposed taxonomy (Table~\ref{tab:Taxonomy}, Figure~\ref{fig:taxonomy}) of structured and unstructured approaches, analyzing their distinctions and associated challenges. Additionally, we offer insights into future research directions for both structured and unstructured techniques, as well as perspectives from point cloud and NeRF compression, which are missing in the prior survey.  Furthermore, our work is the first comprehensive study to provide an in-depth discussion on the efficiency (rendering speed) of different compression methods.  

\noindent
\textbf{Highlighted Features: } The major features of this survey include (1) Highlighting Compression Potential: This survey underscores the potential of 3DGS to be highly compressed with minimal quality loss. We demonstrate that 3DGS is compatible with various compression methodologies and their combinations. For the first time, we provide a comprehensive understanding of different 3DGS compression methodologies from a topological perspective. (2) Key Concepts and Improvements: We discuss the essential concepts involved in compressing 3DGS and outline strategies for further improvements. This includes an in-depth examination of current techniques and their impact on compression efficiency and quality preservation. (3) Guidelines for Future Research: Drawing from recent advancements, we extract pivotal ideas from state-of-the-art compression methodologies. Based on these insights, we propose a set of guidelines for future research to enhance 3DGS compression pipelines. This includes best practices and innovative approaches to be incorporated in future studies.

% \textbf{Contributions: } The main contributions of our survey are as follows.
As the pioneering attempt to present a comprehensive survey on 3DGS compression, our survey aims to help the readers of interest quickly grasp its development. Overall, the contributions of our survey are summarized as follows:

(1) The paper offers a detailed taxonomy of 3DGS compression methods, categorizing them into structured and unstructured approaches, and provides an in-depth analysis of their methodologies, performance trade-offs, and limitations. % (Section~\ref{sec:compression}).

(2) We systematically analyze existing compression techniques, highlighting key challenges such as scalability constraints in large-scale scenes, dependence on vector quantization, suboptimal loss function designs, and limitations in deploying 3DGS on resource-constrained hardware.

(3) We provide insights for advancements including scalar quantization for efficient hardware compatibility, hybrid frameworks that integrate structured and unstructured compression strategies, and leveraging insights from NeRF and point cloud compression to enhance performance and adaptability.


% (2) In Section~\ref{sec:struc_vs_unstruc} we highlight critical challenges in 3DGS compression, such as scalability for large scenes, reliance on vector quantization, and underexplored loss function optimization, while emphasizing the need for solutions suitable for resource-constrained environments.

% (3) The survey paper also proposes future directions, including scalar quantization for efficient hardware deployment, hybrid frameworks that integrate structured and unstructured methods, and optimizing loss functions to balance compression and quality. It also emphasizes real-world deployment challenges and applications, such as VR/AR and edge computing, while drawing inspiration from advancements in NeRFs and point cloud compression techniques to inform future innovations (Section~\ref{sec:future_works}).
%For a detailed background and explanation of 3DGS, please refer to the supplementary material. The remainder of the paper is structured as follows: Section II introduces the problem statement for 3DGS compression. Sections III and IV discuss unstructured and structured compression methods, respectively. Section V provides a comparative analysis of both techniques. Section VI explores future directions inspired by NeRFs and point cloud compression. Finally, Section VII concludes the paper.  

The remainder of the paper is structured as follows: Section II presents a detailed background on 3DGS and its working principles. Section III introduces the problem statement for 3DGS compression. Sections IV and V discuss unstructured and structured compression methods, respectively. Section VI provides a comparative analysis of both techniques. Section VII explores future directions inspired by NeRFs and point cloud compression. Finally, Section VIII concludes the paper.  
\input{Sections/Preliminaries_arxiv}

%However, neural implicit field methods heavily depend on volumetric rendering to generate rendered images. This process involves sampling numerous points along each ray and passing them through the neural network to produce the final image. As a result, rendering a single 1080p image can require approximately \(10^8\) neural network forward passes, often resulting in rendering times of several seconds. Although some approaches utilize explicit, discretized structures to represent continuous 3D fields, which reduces reliance on neural networks and speeds up the query process [9], [10], [11], the extensive number of sampling points still results in high rendering costs. Consequently, methods reliant on volumetric rendering cannot achieve real-time performance, limiting their applicability for real-time or interactive applications.
%\input{Sections/Preliminaries}
 \section{3DGS Compression}
 \label{sec:compression}
%3DGS has rapidly gained prominence in the vision and graphics community due to its simplicity and effectiveness, finding applications in areas such as Simultaneous Localization and Mapping (SLAM)~\cite{tosi2024nerfs,yan2024gs,keetha2024splatam,matsuki2024gaussian}, Dynamic Scene Reconstruction~\cite{yang2023real,yang2024deformable,wu20244d,lin2024gaussian}, AI-Generated Content (AIGC)~\cite{tang2023dreamgaussian,yi2024gaussiandreamer,tang2024lgm,zhou2024dreamscene360}, Endoscopic Scene Reconstruction~\cite{huang2024endo, liu2024endogaussian,zhu2024deformable,zhao2024hfgs}, and Large-scale Scene Reconstruction~\cite{kerbl2024hierarchical,liu2024citygaussian,lin2024vastgaussian,ren2024octree}. For detailed information on these applications, please refer to the relevant articles~\cite{DBLP:journals/corr/abs-2401-03890,bao20243d}. Despite its advantages, 3DGS encounters significant scalability challenges compared to NeRFs. While NeRFs require only the storage of weight parameters for a multi-layer perceptron (MLP), 3DGS necessitates storing millions of Gaussians per scene. This issue becomes more critical in large, complex scenes, where computational and memory demands increase exponentially.  Consequently, optimizing both memory usage and computational efficiency for storage and training is crucial.

3DGS faces significant scalability challenges compared to NeRFs. While NeRFs require only the storage of weight parameters for a multilayer perceptron (MLP), 3DGS necessitates storing the parameters of millions of Gaussians per scene. This issue becomes especially critical in large, complex scenes, where computational and memory demands increase significantly. The number of Gaussians is directly proportional to storage and computational complexity and inversely proportional to rendering efficiency. Therefore, optimizing memory usage and computational efficiency for both storage and rendering is essential to improve the scalability of 3DGS-based methods.

\noindent
\textbf{3DGS Attributes: }The input signal to be compressed consists of $N$ Gaussians, each characterized by multiple attributes: $3\times1$ position vectors ($\mu$), $3\times1$  scale vector and $4\times1$  rotation quaternion vector, scalar opacity values and spherical harmonics (SH) coefficients for view-dependent RGB color modeling. For degree $3$ SH, this requires $48$ coefficients per Gaussian ($16$ per RGB channel). Each parameter has a bit depth of 32-bit floating point. 


\noindent
\textbf{Evaluation Metrics:} The compression cost is quantified either as the bit count of the compressed representation or its compression ratio compared to the baseline 3DGS-30k (trained for $30,000$ iterations). The performance evaluation of 3DGS compression relies on image-based fidelity metrics such as PSNR (Peak Signal-to-Noise Ratio), SSIM (Structural Similarity Index Measure), and LPIPS (Learned Perceptual Image Patch Similarity), and its computational efficiency is measured in terms of Frames per second (FPS). 

\noindent
\textbf{Datasets:} Similar to NeRF-based rendering methods, 3DGS-based methods are commonly evaluated on 9 scenes from Mip-NeRF360~\cite{barron2022mip}, which includes both indoor and outdoor scenes, two scenes from Tanks\&Temples~\cite{knapitsch2017tanks}, and the Deep Blending~\cite{hedman2018deep} dataset. Figure~\ref{fig:dataset} shows a sample image of each scene from all the datasets. To ensure consistent benchmarking studies typically adhere to the train-test split used in Mip-NeRF360~\cite{barron2022mip} and 3DGS where every 8th image must be selected for testing.

\input{Tables/Unstruct_table}


\noindent
 \textbf{Categorization of 3DGS Compression Methods:}
There has been a plethora of works focusing on the compression of 3DGS. In contrast to the structured feature grids used in NeRF-based methods, the 3D Gaussians employed in 3DGS are sparse and lack organization, which causes significant difficulties in establishing structural relations~\cite{chen2024hac}. Consequently, compression strategies for 3DGS can be categorized into two groups: \newline i) \textbf{Unstructured Compression:} Those primarily concerned with compressing the "value" of model parameters $N$, utilizing methods like pruning~\cite{fan2023lightgaussian,lee2023compact}, quantization~\cite{fan2023lightgaussian,lee2023compact,navaneet2023compact3d,niedermayr2024compressed}, and entropy constraints~\cite{girish2023eagles} without considering the relationship between the Gaussians. \newline ii) \textbf{Structured Compression:} those exploring compression techniques that consider the relationships between Gaussians~\cite{lu2023scaffold,chen2024hac}.

Figure~\ref{fig:taxonomy} presents a detailed taxonomy of 3DGS compression methods, while Table~\ref{tab:Taxonomy} lists representative publications categorized according to their taxonomy classification. The following sections provide an overview of unstructured and structured compression methods, discussing their variations and the challenges associated with each approach.

\vspace{-0.15cm}
\section{Unstructured 3DGS Compression} 
Compression methods built on top of the baseline 3DGS that exploit the sparse nature of Gaussians without altering the fundamental structure of 3D Gaussians or considering their interrelationships fall into this category. These approaches apply techniques such as pruning, quantization, and entropy coding within the existing 3DGS framework, making minimal modifications to the underlying architecture.  The primary objective of these methods is to reduce memory and computational costs while preserving the core advantages of 3DGS, ensuring efficient storage and faster processing without degrading scene representation quality. In this section, based on the taxonomy presented in Figure~\ref{fig:taxonomy} and Table~\ref{tab:Taxonomy}, we provide an in-depth analysis of unstructured compression methods, discussing their performance, challenges, and potential future directions.  
%Compression methods built on top of the baseline 3DGS that leverage the sparse nature of Gaussians, without altering the fundamental structure of 3D Gaussians, fall into this category. These approaches employ techniques such as pruning, quantization, and entropy coding on the existing 3DGS framework with minimal modifications to the underlying architecture. The primary goal of these methods is to reduce memory and computational requirements while preserving the core benefits of 3DGS, ensuring efficient storage and faster processing without compromising the quality of the scene representation. In this section based on the taxonomy presented in Figure~\ref{fig:taxonomy}, we first discuss unstructured compression methods utilizing pruning, followed by quantization and entropy encoding strategies.


\subsection{Pruning}
%Pruning techniques in 3DGS focus on removing redundant Gaussians which results in storage optimization and also improves rendering efficiency. Different pruning strategies utilize specific attributes of Gaussians, enabling a more compact representation while preserving visual fidelity.
Pruning techniques in 3DGS aim to reduce the number of Gaussians resulting in storage optimization and rendering efficiency while maintaining rendering fidelity. These approaches target different Gaussian attributes, utilizing structural, statistical, and learned information to optimize scene representation. The pruning strategies can be broadly classified into size-based, gradient-based, opacity-based, spatial-based, and significance-scoring-based techniques.


\noindent
\textbf{Size-based Pruning:} This method eliminates Gaussians that are structurally redundant due to their small size, as they contribute minimally to scene reconstruction. CompGS~\cite{navaneet2023compact3d} and Papantonakis et al.~\cite{papantonakis2024reducing} apply size-based pruning to remove such Gaussians, improving efficiency while maintaining reconstruction quality.

\noindent
%\textbf{Gradient-based Pruning: }This method removes Gaussians that contribute minimally to optimization by evaluating the magnitude of gradients associated with each Gaussian during training. EfficientGS utilizes cumulative gradient sum analysis to halt unnecessary densification and applies pruning to eliminate redundant Gaussians. GDGS reduces Gaussian density by modeling scene gradients, enhancing compactness without explicit Gaussian removal. Trimming the Fat applies gradient-based pruning, removing 75\% of Gaussians while maintaining high visual quality. Kim et al. extend this approach by incorporating SH gradients alongside positional gradients, further refining the pruning process.
\textbf{Gradient-based Pruning:} This method removes Gaussians that contribute minimally to optimization by evaluating the magnitude of gradients associated with each Gaussian during training. EfficientGS~\cite{liu2024efficientgs} utilizes cumulative gradient sum analysis to halt unnecessary densification and applies pruning to eliminate redundant Gaussians. GDGS~\cite{gong2024gdgs} reduces Gaussian density by modeling scene gradients, enhancing compactness. Trimming the Fat~\cite{salman2024trimming} and ELMGS~\cite{ali2024elmgs} applies gradient-based pruning, removing 75\% of Gaussians while maintaining high visual quality. Kim et al.~\cite{kim2024color} extend this approach by incorporating SH gradients alongside positional gradients, further refining the pruning process.

\input{Display_Figures/unstruct_fps_vs_psnr}

\noindent
%\textit{Opacity-based Pruning:} This method removes Gaussians with low opacity values, as they contribute minimally to the final rendered image. Trimming the Fat and ELMGS employs opacity-based pruning in combination with gradient-based pruning to optimize Gaussian selection.
\textbf{Opacity-based Pruning:} This method eliminates Gaussians with low opacity values, as they contribute minimally to scene reconstruction. Trimming the Fat~\cite{salman2024trimming} and ELMGS~\cite{ali2024elmgs} apply opacity-based pruning alongside gradient-based pruning, effectively removing floaters and redundant Gaussians. CompGS~\cite{navaneet2023compact3d}, in combination with size-based pruning, employs a learnable opacity masking approach, dynamically removing Gaussians with persistently low opacity throughout training. Figure~\ref{fig:opacity_gradient_pruning_comparison} presents a qualitative comparison between pruning based solely on opacity and pruning that incorporates both opacity and gradient information. The results highlight the effectiveness of opacity and gradient-informed pruning in preserving scene details while achieving better compression efficiency.

\noindent
\textbf{Significance-based pruning:} This approach incorporates explicit scoring functions to regulate pruning decisions, preventing excessive removal of Gaussians that could degrade scene fidelity. LightGaussian~\cite{fan2023lightgaussian} employs a significance-driven pruning approach that evaluates each Gaussian’s contribution to rendering based on its projection onto camera viewpoints, ensuring minimal perceptual degradation. The significance score is computed from the frequency of Gaussian intersections with rays across all training views. EAGLES~\cite{girish2023eagles} adopts a coarse-to-fine pruning strategy, eliminating Gaussians with the least contribution to reconstruction quality, thereby enhancing training and inference speeds. Papantonakis et al.~\cite{papantonakis2024reducing} combine size-based and significance-based pruning, dynamically adapting SH coefficients to remove structurally redundant Gaussians. SafeguardGS~\cite{lee2024safeguardgs} introduces a pruning score function to ensure optimal Gaussian selection, mitigating the risk of catastrophic scene degradation. LP-3DGS~\cite{zhang2024lp} adopts a trainable binary mask approach that automatically determines the optimal pruning ratio, leveraging Gumbel-Sigmoid-based gradient approximation to maintain compatibility with existing 3DGS training pipelines.

\input{Display_Figures/unstruct_mem_vs_psnr}


\noindent
\textbf{Spatial-based Pruning:} This method removes Gaussians based on scene location, preserving detail in important regions while reducing redundancy elsewhere. PUP 3D-GS~\cite{hanson2024pup} employs a second-order reconstruction error approximation to selectively prune Gaussians with minimal impact on scene reconstruction. RTGS~\cite{lin2024rtgs}, using a foveated rendering (FR)~\cite{guenter2012foveated,patney2016towards} approach for Point-Based Neural Rendering (PBNR)~\cite{kerbl20233d}, prunes Gaussians based on pixel eccentricity~\cite{wandell1995foundations}, maintaining high-density in critical regions while sparsifying peripheral areas. This approach optimizes memory usage and rendering speed while preserving perceptual consistency, making it particularly effective for real-time rendering, VR, and AR applications.


%\textbf{Spatial-based pruning} selectively removes Gaussians based on their spatial importance within the scene. PUP 3D-GS implements a second-order reconstruction error approximation to guide pruning decisions, ensuring that Gaussians in critical regions are retained while those in less significant regions are removed.

By integrating these diverse pruning methodologies, 3DGS achieves substantial memory reduction and enhanced rendering speeds, making possible real-time Gaussian rendering across various applications, including VR/AR~\cite{zhai2024splatloc}, mobile deployment~\cite{lin2024rtgs}, and autonomous systems~\cite{zhou2024drivinggaussian}. 
However, even after removing redundant Gaussians through pruning, millions of Gaussians are still required for accurate scene reconstruction. To further reduce the memory and storage complexity of these essential Gaussians, quantization techniques are employed.

\subsection{Quantization}
%To further minimize the memory and computational footprint of 3DGS, quantization strategies are employed.
Quantization plays a crucial role in 3DGS compression by reducing the bit precision of Gaussian attributes while maintaining rendering fidelity. By encoding Gaussian parameters more compactly, quantization significantly decreases storage requirements and computational costs. Several works integrate quantization within their compression pipelines, either in isolation or combined with pruning, to achieve higher efficiency. Quantization can be broadly categorized into scalar quantization and vector quantization. Scalar quantization compresses individual attributes independently, while vector quantization groups multiple attributes into a shared codebook, enabling more efficient compression and reduced storage overhead.

\noindent
\textbf{Vector Quantization (VQ):} VQ is widely used in 3DGS compression due to its higher compression efficiency, achieved by clustering similar Gaussians and encoding them through compact indices. LightGaussian~\cite{fan2023lightgaussian} and CompGS~\cite{navaneet2023compact3d} employ codebook-based vector quantization to identify shared Gaussian parameters, further compressing indices via run-length encoding. Niedermayr et al.~\cite{niedermayr2024compressed} introduce sensitivity-aware vector clustering combined with quantization-aware training, optimizing directional color and Gaussian parameters. EAGLES~\cite{girish2023eagles} integrates quantized embeddings, significantly reducing per-point memory requirements while accelerating training and inference.


\noindent
\textbf{Scalar Quantization (SQ):} Although VQ is widely used in 3DGS-based methods, recent advances suggest that SQ offers better hardware efficiency, particularly for deployment in edge devices~\cite{gholami2022survey}. ELMGS~\cite{ali2024elmgs} used learned step-size-based uniform quantization~\cite{esser2019learned} for quantization. However, uniform SQ suffers from a performance drop at lower bit-depths due to the non-uniform distribution of 3DGS attributes such as opacity as seen in Figure~\ref{fig:opacity_distribution}~\cite{esser2019learned}. The distribution of opacity in 3DGS is highly non-uniform, with peaks at both lower and higher opacity levels. This underscores the necessity for non-uniform SQ methods specifically tailored for 3DGS quantization, ensuring better preservation of scene fidelity even at extremely low bit-depths.



\subsection{Entropy Encoding}
After quantization, entropy encoding further compresses Gaussian attributes by eliminating redundancy at the storage level, ensuring a compact representation. CompGS, ELMGS, and Niedermayr et al. apply run-length encoding and entropy-based compression to minimize storage overhead. RDO-Gaussian~\cite{wang2024end} is among the first to introduce an end-to-end rate-distortion framework, dynamically adjusting compression based on a quality-loss trade-off. Morgenstern et al.~\cite{morgenstern2023compact} propose a 2D-grid-based entropy encoding that efficiently organizes Gaussian attributes, enabling parallelized encoding and decoding during rendering.

Entropy encoding serves as a crucial final step in 3DGS compression, significantly enhancing compression efficiency by further reducing storage redundancy. However, it introduces additional computational complexity during decoding. Methods such as RDO-Gaussian, which integrate entropy encoding with quantization and pruning, offer the most efficient end-to-end compression pipelines, balancing compression ratio, and computational complexity.


% \subsubsection{State of the Art}
% The subsequent works highlight prominent contributions in unstructured compression, focusing on their unique methodologies, performance trade-offs, and impact on real-world deployment. These works represent the state-of-the-art in addressing the challenges of compressing 3DGS.

% \textit{LightGaussian~\cite{fan2023lightgaussian}} utilizes pruning, quantization, and knowledge distillation to compress the Gaussians effectively. LightGaussian~\cite{fan2023lightgaussian} identifies Gaussians that have minimal impact on scene reconstruction and applies a pruning and recovery process to effectively reduce redundancy in the number of Gaussians while maintaining visual quality. Additionally, LightGaussian~\cite{fan2023lightgaussian} uses knowledge distillation to transfer spherical harmonics coefficients to a lower degree, facilitating the conversion of knowledge into more compact representations without compromising the appearance of the scene. Moreover, they introduce Gaussian Vector Quantization based on the global significance of Gaussians to quantize all redundant attributes, leading to lower bit-width representations with minimal accuracy loss. In summary, LightGaussian~\cite{fan2023lightgaussian} achieves an average compression rate of over 15$\times$ while increasing the frames per second (FPS) from 119 to 209 on Mip-NeRF360 and Tanks\&Temples dataset. 

% \textit{Compact 3D~\cite{lee2023compact}} introduces a learnable mask strategy that significantly decreases the number of Gaussians while maintaining high performance. They also developed a compact yet effective method for representing view-dependent colors by using a grid-based neural field instead of spherical harmonics. Additionally, they employ codebooks to represent the geometric attributes of Gaussians through vector quantization efficiently. Utilizing model compression techniques such as quantization and entropy coding, they achieved over 25× reduced storage and enhanced rendering speed, while preserving the quality of the scene representation compared to the 3DGS baseline.

% \textit{Navaneet \textit{et al.}~\cite{navaneet2023compact3d}} observed that a large number of Gaussians might share similar parameters. To address this, they introduced a straightforward vector quantization method based on the K-means algorithm to quantize the Gaussian parameters. They stored a small codebook along with the index of the code for each Gaussian and further compressed the indices by sorting them and using a method similar to run-length encoding. This simple strategy could reduce the storage cost of the original 3DGS method by nearly 20$\times$, with only a minimal decrease in the quality of rendered images.

% \textit{Niedermayr \textit{et al.}~\cite{niedermayr2024compressed}} proposed a compressed 3DGS representation that employs sensitivity-aware vector clustering for pruning, combined with quantization-aware training to compress directional colors and Gaussian parameters. The learned codebooks feature low bitrates and achieve a compression rate of up to 31$\times$ on real-world scenes with minimal visual quality degradation. This compressed splat representation can be efficiently rendered using hardware rasterization on lightweight GPUs, resulting in up to 4× higher framerates compared to the baseline 3DGS.

% \textit{EAGLES~\cite{girish2023eagles}} introduced a technique that uses quantized embeddings to substantially decrease per-point memory storage requirements, along with a coarse-to-fine training strategy to enable faster and more stable optimization of Gaussian point clouds. Their approach includes a pruning stage that accelerates training times and rendering speeds for real-time rendering of high-resolution scenes while significantly reducing memory storage by more than an order of magnitude. This method maintains high reconstruction quality while consuming 10-20× less memory and achieving faster training and inference speeds.

% \textit{Papantonakis et al.~\cite{papantonakis2024reducing}} identified three critical factors that could significantly reduce the memory complexity of 3DGS: (1) the number of Gaussians, (2) the number of spherical harmonics used to represent color, and (3) the optimal precision bits required to store 3D Gaussian features. To address these issues, they proposed a comprehensive solution. First, they introduced a pruning method that effectively reduces the number of Gaussians by half. Second, they developed a technique to adaptively adjust the number of coefficients for spherical harmonic (SH) features for each 3D Gaussian. Lastly, they implemented codebook quantization combined with a 16-bit float representation to further decrease memory complexity. These modifications collectively achieved a compression ratio of approximately 27$\times$ compared to the original 3DGS, along with a frame-per-second (FPS) gain of about 1.7$\times$.

% \textit{Trimming the Fat~\cite{salman2024trimming}} is another pruning-based approach designed to remove redundant Gaussians from 3DGS. This method prunes Gaussians based on their opacity and gradient information, eliminating those below a certain threshold. Remarkably, Trimming the Fat can remove about 75\% of the Gaussians while maintaining performance on benchmark datasets and can achieve rendering speeds of up to 600 FPS. When combined with the approach by Neidermayr~\cite{niedermayr2024compressed}, Trimming the Fat can result in approximately 50$\times$ compression gains compared to the baseline 3DGS, significantly enhancing memory efficiency and computational performance.

% \textit{SafeguardGS~\cite{lee2024safeguardgs}} offers a comprehensive analysis of various pruning methods applied to 3DGS and introduces a score function designed to regulate the pruning process. This score function is crucial in preventing excessive pruning that could lead to the destruction of the entire scene. Additionally, SafeguardGS analyzes the performance differences among various pruning functions and examines how these methods impact Gaussian features. 

% \textit{GDGS~\cite{gong2024gdgs}} introduced an innovative approach to reducing the density of Gaussians in 3DGS. Instead of directly modeling the scene, GDGS focuses on modeling the gradients of the scene. This method significantly decreases storage requirements and reduces both computational and memory complexity. The original scene can be accurately reconstructed by solving a Poisson equation, which operates with linear complexity~\cite{farbman2011convolution,gong2015spectrally}. 

% \begin{figure*}[t]
%     \centering
%     % Placeholder for a figure
%     \rule{6cm}{6cm}  % Width x Height of the placeholder
%     \caption{Figure: Big Picture of the Survey Figure}
%     \label{fig:placeholder}
% \end{figure*}

% \begin{table*}[]
%     \caption{Performance and compression comparison of 3DGS baseline with unstructured compression methods on benchmark datasets.}
%     \label{tab:stru_compression_comp}
%     \centering
%     \small
%     \resizebox{0.60\textwidth}{!}{
%     \begin{tabular}{l|ccccc}
%     \toprule
%      \multicolumn{6}{c}{\textbf{Mip-NeRF360~\cite{barron2022mip}}} \\
%      \midrule \midrule
%     \textbf{Model} & \textbf{SSIM$^\uparrow$} & \textbf{PSNR$^\uparrow$} & \textbf{LPIPS$^\downarrow$} & \textbf{FPS}$^\uparrow$ & \textbf{Mem.}$^\downarrow$ \\
%     \midrule




% 3DGS-7k~\cite{kerbl20233d} & 0.770 & 25.60 & 0.279 & 160 & 523 \\
% 3DGS-30k~\cite{kerbl20233d} & 0.815 & 27.21 & 0.214 & 134 & 734 \\
% LightGaussian~\cite{fan2023lightgaussian} & 0.805 & 27.28 & 0.243 & 209 & 42 \\
% Compact3D~\cite{lee2023compact} & 0.798 & 27.08 & 0.247 & 128 & 49 \\
% CompGS 16K~\cite{navaneet2023compact3d} & 0.804 & 27.03 & 0.243 & 346 & 18 \\
% CompGS 32K~\cite{navaneet2023compact3d} & 0.806 & 27.12 & 0.240 & 344 & 19 \\
% Niedermayr et al.~\cite{niedermayr2024compressed}  & 0.801 & 26.98 & 0.238 & - & 29 \\
% EAGLES~\cite{girish2023eagles}  & 0.810 & 27.23 & 0.240 & 131 & 54 \\
% Papantonakis et al.~\cite{papantonakis2024reducing}   & 0.809 & 27.10 & 0.226 & 284 & 29 \\
% Trimming the Fat~\cite{salman2024trimming}  & 0.798 & 27.13 & 0.248 & 210 & 20 \\
% Efficientgs~\cite{liu2024efficientgs}  & 0.817 & 27.38 & 0.216 & 218 & 98 \\
% RDO-Gaussian~\cite{wang2024end}  & 0.802 & 27.05 & 0.239 & 191 & 24 \\
% PUP 3D-GS~\cite{hanson2024pup}  & 0.792 & 26.83 & 0.268 & 244 & 86 \\
% Kim et al~\cite{kim2024color}  & 0.797 & 27.07 & 0.249 & 166 & 73 \\

%    \midrule    \midrule

%    \multicolumn{6}{c}{\textbf{Tanks\&Temples~\cite{knapitsch2017tanks}}}\\
%    \midrule    \midrule

% 3DGS-7k~\cite{kerbl20233d} & 0.767 & 21.20 & 0.280 & 197 & 270 \\
% 3DGS-30k~\cite{kerbl20233d} & 0.841 & 23.14 & 0.183 & 154 & 411 \\
% LightGaussian~\cite{fan2023lightgaussian} & 0.817 & 23.11 & 0.231 & 209 & 22 \\
% Compact3D~\cite{lee2023compact} & 0.831 & 23.32 & 0.201 & 185 & 39 \\
% CompGS 16K~\cite{navaneet2023compact3d} & 0.836 & 23.39 & 0.200 & 479 & 12 \\
% CompGS 32K~\cite{navaneet2023compact3d} & 0.838 & 23.44 & 0.198 & 475 & 13 \\
% Niedermayr et al.~\cite{niedermayr2024compressed} & 0.832 & 23.32 & 0.194 & - & 17 \\
% EAGLES~\cite{girish2023eagles} & 0.840 & 23.37 & 0.200 & 227 & 29 \\
% Papantonakis et al.~\cite{papantonakis2024reducing} & 0.840 & 23.57 & 0.188 & 433 & 14 \\
% Trimming the Fat~\cite{salman2024trimming} & 0.831 & 23.69 & 0.210 & 510 & 9 \\
% Efficientgs~\cite{liu2024efficientgs} & 0.837 & 23.45 & 0.197 & 439 & 33 \\
% RDO-Gaussian~\cite{wang2024end} & 0.835 & 23.34 & 0.195 & 269 & 12 \\
% PUP 3D-GS~\cite{hanson2024pup} & 0.807 & 23.03 & 0.245 & 418 & 50 \\
% Kim et al~\cite{kim2024color} & 0.830 & 23.18 & 0.198 & 231 & 42 \\

%     \midrule    \midrule

%     \multicolumn{6}{c}{\textbf{Deep Blending}}\\
%     \midrule    \midrule

% 3DGS-7k~\cite{kerbl20233d} & 0.875 & 27.78 & 0.317 & 172 & 386 \\
% 3DGS-30k~\cite{kerbl20233d} & 0.903 & 29.41 & 0.243 & 137 & 676 \\

% Compact3D~\cite{lee2023compact} & 0.901 & 29.79 & 0.258 & 181 & 43 \\
% CompGS 16K~\cite{navaneet2023compact3d} & 0.906 & 29.90 & 0.252 & 485 & 12 \\
% CompGS 32K~\cite{navaneet2023compact3d} & 0.907 & 29.90 & 0.251 & 484 & 13 \\
% Niedermayr et al.~\cite{niedermayr2024compressed} & 0.898 & 29.38 & 0.253 & - & 25 \\
% EAGLES~\cite{girish2023eagles} & 0.910 & 29.86 & 0.250 & 130 & 52 \\
% Papantonakis et al.~\cite{papantonakis2024reducing} & 0.902 & 29.63 & 0.249 & 360 & 18 \\
% Trimming the Fat~\cite{salman2024trimming} & 0.897 & 29.43 & 0.267 & 440 & 13 \\
% Efficientgs~\cite{liu2024efficientgs} & 0.903 & 29.63 & 0.251 & 401 & 40 \\
% RDO-Gaussian~\cite{wang2024end} & 0.902 & 29.63 & 0.252 & 207 & 18 \\
% PUP 3D-GS~\cite{hanson2024pup} & 0.881 & 28.61 & 0.305 & 296 & 81 \\
% Kim et al~\cite{kim2024color} & 0.902 & 29.71 & 0.255 & 208 & 72 \\




%     \bottomrule
%     \end{tabular}
%     }
% \end{table*}


% \begin{table*}[]
%     \caption{Performance and compression comparison of 3DGS baseline with unstructured compression methods on Mip-NeRF360 and Tanks\&Temples datasets.}
%     \label{tab:unstruc_mip_tandt}
%     \centering
%     \small
%     \resizebox{0.95\textwidth}{!}{
%     \begin{tabular}{l|ccccc|ccccc}
%     \toprule
%     &  \multicolumn{5}{c}{\textbf{Mip-NeRF360~\cite{barron2022mip}}} & \multicolumn{5}{c}{\textbf{Tanks\&Temples~\cite{knapitsch2017tanks}}} \\
%     \textbf{Model} & \textbf{SSIM$^\uparrow$} & \textbf{PSNR$^\uparrow$} & \textbf{LPIPS$^\downarrow$} & \textbf{FPS}$^\uparrow$ & \textbf{Mem.}$^\downarrow$ & \textbf{SSIM$^\uparrow$} & \textbf{PSNR$^\uparrow$} & \textbf{LPIPS$^\downarrow$} & \textbf{FPS}$^\uparrow$ & \textbf{Mem.}$^\downarrow$\\
%     \midrule

% 3DGS-7k~\cite{kerbl20233d} & 0.770 & 25.60 & 0.279 & 160 & 523.0 & 0.767 & 21.20 & 0.280 & 197 & 270.0 \\ 
% 3DGS-30k~\cite{kerbl20233d} & \cellcolor{yellow!25}0.815 & 27.21 & \cellcolor{red!25}0.214 & 134 & 734.0 & \cellcolor{red!25}0.841 & 23.14 & \cellcolor{red!25} 0.183 & 154 & 411.0 \\
% \midrule
% LightGaussian~\cite{fan2023lightgaussian} & 0.805 & \cellcolor{yellow!25} 27.28 & 0.243 & 209 & 42.0 & 0.817 & 23.11 & 0.231 & 209 & 22.0 \\
% Compact3D~\cite{lee2023compact} & 0.798 & 27.08 & 0.247 & 128 & 48.8 & 0.831 & 23.32 & 0.201 & 185 & 39.4 \\ 
% CompGS 16K~\cite{navaneet2023compact3d} & 0.804 & 27.03 & 0.243 & \cellcolor{yellow!25}346 & \cellcolor{red!25}18.0 & 0.836 & 23.39 & 0.200 & \cellcolor{yellow!25} 479 & \cellcolor{yellow!25} 12.0 \\ 
% CompGS 32K~\cite{navaneet2023compact3d} & 0.806 & 27.12 & 0.240 & \cellcolor{red!25}344 & \cellcolor{yellow!25}19.0 & 0.838 & 23.44 & 0.198 & \cellcolor{green!25} 475 & \cellcolor{green!25}13.0 \\ 
% Niedermayr et al.~\cite{niedermayr2024compressed} & 0.801 & 26.98 & 0.238 & 113 & 28.8 & 0.832 & 23.32 & \cellcolor{green!25} 0.194 & 149 & 17.3 \\ 
% EAGLES~\cite{girish2023eagles} & \cellcolor{green!25}0.810 & \cellcolor{green!25}27.23 & 0.240 & 131 & 54.0 & \cellcolor{green!25}0.840 & 23.37 & 0.200 & 227 & 29.0 \\ 
% Papantonakis et al.~\cite{papantonakis2024reducing} & 0.809 & 27.10 & \cellcolor{green!25}0.226 & \cellcolor{green!25}284 & 29.0 & \cellcolor{yellow!25}0.840 & \cellcolor{yellow!25}23.57 & \cellcolor{yellow!25} 0.188 & 433 & 14.0 \\ 
% Trimming the Fat~\cite{salman2024trimming} & 0.798 & 27.13 & 0.248 & 210 & \cellcolor{green!25}20.1 & 0.831 & \cellcolor{red!25} 23.69 & 0.210 & \cellcolor{red!25}510 & \cellcolor{red!25} 8.6 \\ 
% Efficientgs~\cite{liu2024efficientgs} & \cellcolor{red!25}0.817 & \cellcolor{red!25}27.38 & \cellcolor{yellow!25}0.216 & 218 & 98.0 & 0.837 & \cellcolor{green!25}23.45 & 0.197 & 439 & 33.0 \\ 
% RDO-Gaussian~\cite{wang2024end} & 0.802 & 27.05 & 0.239 & 191 & 23.5 & 0.835 & 23.34 & 0.195 & 269 & \cellcolor{yellow!25} 12.0 \\ 
% PUP 3D-GS~\cite{hanson2024pup} & 0.792 & 26.83 & 0.268 & 244 & 86.3 & 0.807 & 23.03 & 0.245 & 418 & 50.1 \\ 
% Kim et al.~\cite{kim2024color} & 0.797 & 27.07 & 0.249 & 166 & 73.0 & 0.83 & 23.18 & 0.198 & 231 & 42.0 \\ 




%     \bottomrule
%     \end{tabular}
%     }
% \end{table*}





% \begin{table}[]
%     \caption{Performance and compression comparison of 3DGS baseline with unstructured compression methods on Deep Blending dataset.}
%     \label{tab:unstruc_db}
%     \centering
%     \small
%     \resizebox{0.49\textwidth}{!}{

%     \begin{tabular}{l|ccccc}
%     \toprule
%     &  \multicolumn{5}{c}{\textbf{Deep Blending~\cite{hedman2018deep}}}  \\
%     \textbf{Model} & \textbf{SSIM$^\uparrow$} & \textbf{PSNR$^\uparrow$} & \textbf{LPIPS$^\downarrow$} & \textbf{FPS}$^\uparrow$ & \textbf{Mem.}$^\downarrow$ \\
%     \midrule
% 3DGS-7k~\cite{kerbl20233d} & 0.875 & 27.78 & 0.317 & 172 & 386.0 \\
% 3DGS-30k~\cite{kerbl20233d} & 0.903 & 29.41 & \cellcolor{red!25} 0.243 & 137 & 676.0 \\
% \midrule
% Compact3D~\cite{lee2023compact} & 0.901 & \cellcolor{green!25} 29.79 & 0.258 & 181 & 43.2 \\
% CompGS 16K~\cite{navaneet2023compact3d} & \cellcolor{green!25} 0.906 & \cellcolor{red!25}29.90 & 0.252 & \cellcolor{red!25} 485 & \cellcolor{red!25}12.0 \\
% CompGS 32K~\cite{navaneet2023compact3d} & \cellcolor{yellow!25} 0.907 & \cellcolor{red!25} 29.90 & 0.251 & \cellcolor{yellow!25} 484 & \cellcolor{green!25} 13.0 \\
% Niedermayr et al.~\cite{niedermayr2024compressed} & 0.898 & 29.38 & 0.253 &128 & 25.3 \\
% EAGLES~\cite{girish2023eagles} & \cellcolor{red!25} 0.910 & \cellcolor{yellow!25} 29.86 & \cellcolor{green!25} 0.250 & 130 & 52.0 \\
% Papantonakis et al.~\cite{papantonakis2024reducing} & 0.902 & 29.63 & \cellcolor{yellow!25} 0.249 & 360 & 18.0 \\
% Trimming the Fat~\cite{salman2024trimming} & 0.897 & 29.43 & 0.267 & \cellcolor{green!25} 440 & \cellcolor{yellow!25} 12.5 \\
% Efficientgs~\cite{liu2024efficientgs} & 0.903 & 29.63 & 0.251 & 401 & 40.0 \\
% RDO-Gaussian~\cite{wang2024end} & 0.902 & 29.63 & 0.252 & 207 & 18.0 \\
% PUP 3D-GS~\cite{hanson2024pup} & 0.881 & 28.61 & 0.305 & 296 & 80.8 \\
% Kim et al.~\cite{kim2024color} & 0.902 & 29.71 & 0.255 & 208 & 72.0 \\ 


%     \bottomrule
%     \end{tabular}
% }
% \end{table}






% \textit{EfficientGS~\cite{liu2024efficientgs}} introduced a pruning method and an enhanced densification strategy to address the overexpansion of Gaussians seen in the baseline 3DGS model. The densification process was refined by halting unnecessary cloning and splitting of Gaussians based on the cumulative gradient sum, thereby preventing the creation of redundant Gaussians. This was followed by pruning to remove excess Gaussians and reduce redundancy in the SH features of the remaining Gaussians. Additionally, EfficientGS proposed a technique to lower the SH order for redundant Gaussians, further optimizing the model. These improvements led to a significant reduction in training time and a faster rendering rate, achieving approximately a 10$\times$ compression ratio compared to the baseline 3DGS.

% \textit{RDO-Gaussian~\cite{wang2024end}}, inspired by advancements in learned image compression (LIC)~\cite{balle2016end,ali2024towards}, was among the first to introduce an end-to-end compression method with dynamic rate control specifically for 3DGS. This approach implemented a dynamic pruning method coupled with an entropy-constrained vector quantization (ECVQ) module, which jointly optimized both the rate (compression efficiency) and distortion (quality loss). Additionally, RDO-Gaussian employed learnable parameters to model the colors of different regions, enhancing the overall fidelity of the compressed representation. The proposed method achieved a substantial compression rate of approximately 40× compared to the baseline 3DGS, significantly reducing storage requirements while maintaining high-quality rendering.

% \textit{RTGS~\cite{lin2024rtgs}} is a 3DGS based Point-Based Neural Rendering (PBNR) system, pioneering the delivery of neural rendering on edge devices while maintaining high fidelity. RTGS incorporates efficiency-aware pruning techniques to enhance rendering speed, making it suitable for resource-constrained environments. Additionally, it introduces a Foveated Rendering (FR)~\cite{guenter2012foveated, patney2016towards} method, which focuses computational resources on areas of the image that are within the viewer's direct gaze, further boosting FPS. According to human evaluations, RTGS was able to achieve over 100 FPS on the NVIDIA Jetson Xavier without any perceptual loss in video quality, demonstrating its effectiveness for real-time applications on edge devices.

% \textit{Kheradmand et al.~\cite{kheradmand20243d}} reinterpreted 3D Gaussians as samples from a probability distribution representing the underlying scene, akin to a Markov Chain Monte Carlo (MCMC) process. With this perspective, the update of Gaussians is performed using Stochastic Gradient Langevin Dynamics (SGLD)~\cite{kheradmand2024accelerating,brosse2018promises}, which introduces noise to the optimization process. In this framework, the traditional pruning and densification steps are reimagined: pruning becomes a regularization process that removes less important Gaussians, while densification is replaced by a relocalization scheme, adjusting the Gaussians' positions. This approach enhances rendering quality by offering better control over both the initialization and the total number of Gaussians.

% \textit{PUP 3D-GS~\cite{hanson2024pup}} introduced a score-based post-hoc pruning method that leverages spatial sensitivity to optimize Gaussian pruning. This method calculates a second-order approximation of the reconstruction error concerning the spatial parameters of each Gaussian on training views. Additionally, PUP 3D-GS proposed a multi-round prune-refine pipeline that operates without modifying the training process, making it compatible with any pre-trained 3DGS model. Using this approach, PUP 3D-GS was able to prune 88.44\% of Gaussians, resulting in a 2.65$\times$ increase in rendering speed.

% \textit{LP-3DGS~\cite{zhang2024lp}} introduced a learning-to-prune technique that utilizes a trainable binary mask applied to the importance score to automatically determine the optimal pruning ratio for 3DGS. Unlike the traditional straight-through estimator (STE) method, LP-3DGS modifies the masking function to leverage the Gumbel-Sigmoid approach, allowing for a more accurate gradient approximation while maintaining compatibility with the existing 3DGS training process. This approach allows LP-3DGS to determine the optimal Gaussian point size for each scene in a single training session, rather than relying on a fixed model size.

% \textit{Morgenstern et al.~\cite{morgenstern2023compact}} introduced a compact scene representation technique that arranges the 3DGS parameters into a 2D grid based on local homogeneity, significantly reducing storage requirements without compromising rendering quality. Their method capitalizes on the perceptual overlaps inherent in natural scenes, where various Gaussian parameter combinations can represent the scene similarly. To maintain the neighborhood structure and organize the high-dimensional Gaussian parameters into a 2D grid, they proposed a novel highly parallel method called Parallel Linear Assignment Sorting. This approach reinforces local smoothness between the grid's sorted parameters during training. The uncompressed Gaussians maintain compatibility with standard renderers, as they adhere to the original 3DGS structure. For complex scenes, their method achieves a reduction in size by 17$\times$ to 42$\times$ while maintaining the same training time.

% \textit{Kim et al.~\cite{kim2024color}} addressed the over-densification issue in 3DGS by developing a more compact Gaussian model that maintains image quality while reducing data size and GPU memory usage. Their approach introduces the use of color cues by incorporating the SH gradient alongside the 2D position gradient, which was the focus of the original method. By leveraging both positional and color information, the proposed method resolves the inefficiencies found in the original densification process. This strategy aligns with an expanded densification scheme, enabling a reduction in data size by at least 9$\times$ while preserving perceptual quality. Additionally, it cuts GPU memory utilization by 1.5$\times$ and enhances both training time efficiency and rendering performance.

% \textit{Mini-Splatting~\cite{fang2024mini}} identifies two critical issues in the vanilla 3DGS: ``overlapping'' and ``under-reconstruction''. These problems result in an inefficient distribution of Gaussians, which ultimately limits both the rendering quality and speed. The challenge lies in achieving an optimal, minimal Gaussian representation without compromising the quality of rendering. Instead of relying on explicit pruning, Mini-Splatting introduces a novel approach that reorganizes the spatial positions of Gaussians through densification and simplification techniques. The densification process includes ``blur split'' and ``depth reinitialization'', which enhance the density of Gaussians by adjusting their distribution based on screen-space and world-space information. This ensures that the Gaussians are more effectively spread around the object, addressing under-reconstruction issues. The simplification process involves ``intersection preservation'' and ``Gaussian sampling'', which help to maintain a balance between the number of Gaussians and the quality of the rendered scene. By combining these densification and simplification strategies with related additional processing, Mini-Splatting achieves a balanced trade-off between rendering quality, resource usage, and storage. This approach leads to a more efficient and effective Gaussian representation, improving both rendering speed and quality while optimizing resource consumption.


\input{Sections/Unstructured_Compression}
% \subsection{Discussion} 
% Tables~\ref{tab:unstruc_mip_tandt} and~\ref{tab:unstruc_db} compare unstructured compression methods across various datasets. EfficientGS and EAGLES consistently achieve high SSIM and PSNR scores across all benchmarks. On Mip-NeRF360, EfficientGS attains the highest PSNR (27.38) with an SSIM of 0.817, while EAGLES achieves a PSNR of 27.23 and an SSIM of 0.810. LightGaussian also demonstrates strong fidelity (SSIM = 0.805, PSNR = 27.28), indicating that its compression strategy effectively preserves scene details.
% In the Tanks\&Temples dataset, which features complex real-world scenes, EfficientGS achieves the highest PSNR (23.45), closely followed by Papantonakis et al. (PSNR = 23.69) and EAGLES (PSNR = 23.37). SSIM values remain high across these methods, with EAGLES achieving the best perceptual similarity (SSIM = 0.840). On the Deep Blending dataset, EAGLES (SSIM = 0.910, PSNR = 29.63) and CompGS 16K (SSIM = 0.906, PSNR = 29.90) outperform most other approaches, effectively balancing scene fidelity and perceptual distortion through vector quantization and entropy-aware pruning.
% For LPIPS Compact3D and LightGaussian demonstrated lower scores than other methods. EAGLES, EfficientGS, and CompGS variants maintain competitive LPIPS values, ensuring minimal perceptual artifacts. In contrast, methods that aggressively prune Gaussians, such as Trimming the Fat, exhibit slightly higher LPIPS values, highlighting the trade-off between compression ratio and perceptual fidelity.
% Memory efficiency is a critical factor in 3DGS compression, particularly for large-scale scene rendering. EfficientGS (8.6MB), Trimming the Fat (10.8MB), and Papantonakis et al. (20.1MB) achieve the highest compression rates on the Tanks\&Temples dataset, significantly reducing memory usage compared to 3DGS baselines (270MB for 3DGS-7k and 411MB for 3DGS-30k). Similarly, in the Deep Blending dataset, CompGS 16K (12MB) and Trimming the Fat (10.8MB) achieve the lowest memory footprints, making them well-suited for resource-constrained environments. These findings highlight the importance of entropy-constrained quantization and aggressive pruning in reducing storage requirements while maintaining rendering quality.
% Overall, EfficientGS and EAGLES strike the best balance between reconstruction fidelity and compression efficiency, maintaining high SSIM and PSNR values while minimizing memory consumption. CompGS 16K emerges as a strong performer on the Deep Blending dataset, while Trimming the Fat achieves the most aggressive compression, albeit with slightly higher perceptual distortion. These results underscore the effectiveness of hybrid pruning-quantization approaches in optimizing 3DGS representations for memory-efficient real-time rendering.



% Most of the works discussed above in unstructured compression have followed a similar pipeline involving pruning, quantization, and entropy encoding, albeit with some minor variations. Despite being unstructured, these compression techniques have achieved substantial scene compression (up to 30$\times$) and significantly enhanced rendering speeds as seen from the results in the Table~\ref{tab:unstruc_mip_tandt} and~\ref{tab:unstruc_db} on Mip-Nerf360~\cite{barron2021mip}, Tanks\&Temples~\cite{knapitsch2017tanks} and Deep Blending~\cite{hedman2018deep} datasets.

% \noindent
%\textbf{Identifying Redundancy in 3DGS: }
% Papantonakis et al.~\cite{papantonakis2024reducing} identified the primary causes of redundancy in 3DGS as the excessive number of Gaussians, SH coefficients, and the use of full precision for Gaussian features. To address these issues, various methods have been proposed, including pruning, quantization, entropy encoding, and knowledge distillation. Among these, pruning has emerged as the most common technique for Gaussian removal, with many approaches being closely related in their methodology.

% \noindent
% \textbf{Gaussian Pruning Techniques:} Several methods, such as LightGaussian~\cite{fan2023lightgaussian}, EAGLES~\cite{girish2023eagles}, EfficientGS~\cite{liu2024efficientgs}, and RDO-Gaussian~\cite{wang2024end}, employ a weight-based metric to assess the importance of individual Gaussians. These methods prune Gaussians based on their calculated weight scores, which consider factors like contribution to each pixel, opacity, scale, and transmittance. 

% Other approaches differ slightly in their pruning criteria. For example, CompGS~\cite{navaneet2023compact3d} prunes Gaussians solely based on opacity values, while Trimming the Fat integrates gradient information with opacity values to make more informed pruning decisions. On the other hand, Compact3D~\cite{lee2023compact} combines opacity and scale values, operating on the observation that Gaussians with smaller scales tend to be redundant. Niedermayr et al.~\cite{niedermayr2024compressed} introduce a sensitivity-aware clustering approach to prune less important Gaussians, though their pruning ratio remains relatively modest.

% Papantonakis et al.~\cite{papantonakis2024reducing} propose a distinct approach, focusing on the redundancy score of Gaussians. Instead of relying solely on weight-based metrics, they calculate the redundancy score based on the number of overlaps between Gaussians. If a Gaussian overlap exceeds a specific threshold, it is pruned, reducing redundancy more effectively while maintaining scene fidelity. This method represents a novel direction to address the inherent redundancy in 3DGS.

% \noindent
% \textbf{Impact of Pruning on Rendering Speed: }
% The reduction in the number of Gaussians directly impacts rendering speed, as fewer Gaussians require less computational overhead during rendering. Methods that efficiently remove a large number of Gaussians tend to achieve significantly higher rendering speeds. This correlation is evident from the results in Table~\ref{tab:unstruc_mip_tandt} and~\ref{tab:unstruc_db}, where CompGS~\cite{navaneet2023compact3d}, Trimming the Fat~\cite{salman2024trimming}, Papantonakis et al.~\cite{papantonakis2024reducing}, and EfficientGS~\cite{liu2024efficientgs} demonstrate markedly higher rendering speeds compared to other methods. These approaches excel in pruning redundant or less significant Gaussians, resulting in both optimized memory usage and faster rendering performance.




% \noindent
% \textbf{Integrating Pruning and Quantization: }Integrating various pruning methodologies can significantly improve the efficiency and effectiveness of 3DGS. By combining the post-hoc pruning strategies used in Trimming the Fat~\cite{salman2024trimming}, CompGS~\cite{navaneet2023compact3d}, and Compact3D~\cite{lee2023compact} which focus on opacity, gradient, and scale—one can develop a more nuanced approach that removes Gaussians redundant across multiple dimensions. This can be further refined with sensitivity-aware clustering methods like those proposed by EAGLES~\cite{girish2023eagles}  and Niedermayr et al.~\cite{niedermayr2024compressed}, which identify and prune clusters of minimally contributing Gaussians. Furthermore, incorporating the redundancy score method from Papantonakis et al.~\cite{papantonakis2024reducing}, which evaluates Gaussian overlaps, provides an additional layer of pruning that targets excessive redundancy. This comprehensive approach, starting with post-hoc pruning, followed by sensitivity-aware clustering, and finalized with redundancy scoring, can lead to a more substantial reduction in Gaussian numbers, significantly improving the rendering speed and memory efficiency of 3DGS while maintaining high-quality scene representation.


% To reduce the bit widths of Gaussian features, many of the aforementioned methods have not only employed pruning but also applied codebook vector quantization~\cite{gray1984vector}. The primary advantage of vector quantization over scalar quantization lies in its ability to significantly reduce the size of the quantized models. Vector quantization groups multiple values into vectors before quantizing them, which allows for more efficient compression and thus a smaller memory footprint. Given the objective of minimizing the memory usage of Gaussians, all the discussed approaches have opted for vector codebook quantization to achieve this goal effectively~\cite{fan2023lightgaussian,lee2023compact,navaneet2023compact3d,niedermayr2024compressed,girish2023eagles,papantonakis2024reducing,wang2024end}. The VQ approach ensures that the memory requirements are kept as low as possible without sacrificing the quality of the 3D scene representation.

% \noindent
% \textbf{Rate-Distortion Optimization: } Aside from RDO-Gaussian~\cite{wang2024end}, most of the other works follow a conventional pipeline of pruning, quantizing, and entropy encoding based on widely used compression algorithms, such as the LZ77 algorithm. This traditional approach focuses on reducing the number of Gaussians, lowering bit widths through vector quantization, and then applying entropy encoding to compress the data further.

% However, RDO-Gaussian~\cite{wang2024end} takes a different approach by designing its entire framework around the rate-distortion optimization (RDO) principle. In this method, they do not just prune Gaussians but also introduce an entropy-focused quantization module that allows them to optimize the Gaussians specifically for different bit rates~\cite{balle2018variational}. 

% Given the advantages of such a rate-distortion framework, it is likely that rate-distortion optimized Gaussians will play a significant role in the future of 3DGS compression. This approach offers a more sophisticated and adaptive means of balancing the compression rate with the quality of the rendered scenes, making it a promising direction for future research and development in the field.

\noindent
\textbf{Challenges and Future Direction}
Despite substantial progress in compressing Gaussian splats, the majority of research has primarily concentrated on reducing the storage footprint of 3DGS. A critical challenge that remains unaddressed is the densification of 3DGS, particularly for large scenes like those in the Mip-NeRF dataset~\cite{barron2022mip}, such as the \texttt{garden} and \texttt{bicycle} scenes, which can demand up to 15GB of GPU memory for training and rendering. This level of scaling is unsustainable for large-scale scenes, indicating a pressing need for unstructured 3DGS compression techniques to tackle this issue.

Furthermore, most of the existing compression methods rely on vector quantization. However, recent advances in model compression for deep learning have demonstrated that scalar quantization is more favorable and easier to implement in hardware, especially for low-powered edge devices~\cite{gholami2022survey,nascimento2023hyperblock}. Therefore, developing specialized scalar quantization techniques for efficiently rendering Gaussian splats on such devices should be a priority.

Additionally, none of the current compression works have investigated the behavior of loss functions in relation to different compression methods. In image compression, it has been shown that altering the loss function can significantly impact compression performance~\cite{ali2024towards}. Thus, future research should explore the effects of various loss functions, such as perceptual loss and edge-based loss, on the performance of 3DGS compression. This could lead to more efficient and perceptually optimized compression techniques for 3DGS.

\input{Tables/struct_table}

\input{Sections/Structured_Compression}


\noindent
\textbf{Challenges and Future Direction: }
Structured compression organizes sparse Gaussians, offering significant memory footprint reduction as discussed in earlier sections. However, the added complexity from hashing~\cite{chen2024hac}, offsetting~\cite{lu2023scaffold}, encoding, and decoding~\cite{liu2024compgs} introduces computational overhead, which impacts rendering efficiency. Unlike unstructured compression, where compression gains typically lead to faster rendering, structured methods do not inherently translate compression efficiency into rendering efficiency. %Future research should focus on reducing the computational complexity of structured approaches to ensure that compression gains also improve rendering performance.

%Structured compression introduces organization to the sparse Gaussians in the baseline 3DGS framework, leading to notable benefits, as demonstrated by HAC, ContextGS, and CompGS. These methods achieve significantly higher compression rates, as shown in Table~\ref{tab:structured_mip_tandt} and~\ref{tab:struct_db}. However, unlike unstructured compression, where compression gains typically result in faster rendering speeds, structured compression methods maintain rendering speeds similar to baseline 3DGS.

One challenge with structured compression lies in the diversity of methodologies employed by different approaches, which complicates their scalability and standardization. Unlike unstructured compression methods, structured techniques cannot be easily integrated into the baseline 3DGS as plug-and-play solutions.

To advance the field, future research should aim to merge insights from unstructured compression into structured approaches, particularly to enhance rendering speed. Given that techniques inspired by LIC have already influenced 3DGS, it is likely that future work will delve deeper into exploring relationships among Gaussians, developing strategies for effective grouping and combining of Gaussians, and optimizing their encoding and decoding processes for greater efficiency and effectiveness.

\begin{figure*}[t]
    \centering
    \includegraphics[width=\linewidth]{Figures/fps_unstruc_vs_struc.pdf}
    \caption{Comparison of PSNR and FPS across structured and unstructured compression techniques benchmarked against the baseline 3DGS. The box represents unstructured compression methods, while the upward triangle denotes the baseline 3DGS-30k. The downward triangle indicates structured compression methods. FPS values are measured on a single NVIDIA A40 GPU.}
    \label{fig:fpsvspsnr}
\end{figure*}

\section{Structured Compression vs Unstructured Compression}
\label{sec:struc_vs_unstruc}
%Both structured and unstructured compression approaches, as discussed earlier, have effectively reduced the memory footprint of 3DGS. However, the choice between these approaches may vary depending on specific requirements. Structured compression methods introduce organization to the sparse Gaussians in the baseline 3DGS framework, resulting in higher compression rates as shown in Figure~\ref{fig:memvspsnr}. However, this added structure may also introduce additional parameters, which can reduce rendering speed as shown in Figure~\ref{fig:fpsvspsnr}. In contrast, unstructured compression methods build directly on top of the baseline 3DGS, making them more adaptable as plug-and-play solutions. Since they do not add extra parameters, unstructured methods are able to significantly increase rendering speed compared to structured compression. 




% Both structured and unstructured compression techniques, as previously discussed, have demonstrated significant reductions in the memory footprint of 3DGS. The selection of a specific approach, however, depends on the application's unique requirements. Structured compression methods introduce the organization to the sparse Gaussians within the baseline 3DGS framework, achieving higher compression rates, as illustrated in Figure~\ref{fig:memvspsnr}. This structural enhancement, however, often comes at the cost of additional parameters, which can adversely impact rendering speed, as shown in Figure~\ref{fig:fpsvspsnr}.
% Conversely, unstructured compression techniques build directly on the baseline 3DGS, making them versatile and straightforward plug-and-play solutions. These methods avoid introducing extra parameters, thereby significantly improving rendering speed, as highlighted in Figure~\ref{fig:fpsvspsnr}. Figure~\ref{fig:fpsvspsnr} further illustrates that while structured compression methods maintain rendering speeds comparable to baseline 3DGS, unstructured methods boost FPS by approximately 4$\times$ to 5$\times$ on average. This higher efficiency and reduced complexity make unstructured compression methods particularly suitable for low-power edge devices.

% Figure~\ref{fig:memvspsnr} presents a comparison of memory usage and PSNR for structured and unstructured methods. Structured approaches, with their added organization, offer better compressibility and superior performance. Therefore, in scenarios demanding lower memory complexity alongside higher performance, structured compression methods are generally more favorable than their unstructured counterparts.

% Despite the significant gains in compression performance, both structured and unstructured approaches still face common challenges. A majority of compression methods rely on vector quantization, which, although providing superior compression rates, is slower compared to scalar quantization. There is also a notable lack of research on optimizing these methods for low-power edge devices. For instance, the rasterization process could be further refined based on the compression technique used. Niedermayr et al.~\cite{niedermayr2024compressed} modified the rasterization method to better suit vector quantization, and similarly, structured compression methods could enhance the rasterization algorithm to boost rendering speed.

% Additionally, there is limited investigation into the impact of different loss functions on the quality of 3DGS. Studies in image compression have shown that the choice of loss function can significantly affect the visual quality of generated images or scenes, a factor that is likely even more pronounced in structured compression approaches. Addressing these areas could lead to more efficient and higher-quality compression methods for 3DGS.

Both structured and unstructured compression techniques significantly reduce the memory footprint of 3DGS, with the choice of method depending on application-specific needs. 

\noindent
\textbf{Fidelity:} Structured compression methods enhance PSNR and SSIM by imposing organization within the sparse Gaussian framework, as seen in ScaffoldGS and HAC-highrate, which achieve PSNR values of 30.21 on Deep Blending and 27.77 on Mip-NeRF360. Unstructured methods, in contrast, preserve the flexibility of baseline 3DGS-30K, offering a more direct adaptation while maintaining competitive fidelity.

\noindent
\textbf{Compression Ratio: } Structured techniques outperform unstructured methods by achieving higher compression rates while retaining visual quality. CompGS (lowrate) and ContextGS (lowrate) achieve 70$\times$ and 113$\times$  compression on Mip-NeRF360 and Deep Blending, respectively, making them highly efficient for memory-constrained settings. Unstructured methods, while not matching these extreme ratios, still achieve significant memory reductions without additional constraints, offering a better balance between compression and flexibility. Figure~\ref{fig:memvspsnr} shows the compression-performance tradeoff of structured and unstructured compression methods.

\noindent
\textbf{FPS: }Structured methods remain comparable to the 3DGS-30K baseline, whereas unstructured techniques achieve 4$\times$  to 5$\times$  FPS improvements, as shown in Figure~\ref{fig:fpsvspsnr}. This makes unstructured compression preferable for real-time and low-power applications, where efficiency is critical. While structured methods introduce additional parameters that can slightly affect rendering speed, they still maintain a high FPS suitable for interactive applications.

\noindent
\textbf{Challenges and Future Direction: }Despite these advancements, challenges remain. Vector quantization, while effective for compression, is computationally expensive compared to scalar quantization~\cite{ali2024elmgs}. Additionally, optimizing structured methods for low-power edge devices remains underexplored. Adaptive rasterization strategies, such as those proposed by Niedermayr et al.~\cite{niedermayr2024compressed}, could enhance rendering efficiency while refining loss functions could further improve 3DGS quality~\cite{ali2024towards}. Addressing these issues will enable more efficient and high-quality 3DGS compression techniques, benefiting both structured and unstructured approaches.




\section{Future Works and Direction}
\label{sec:future_works}
\subsection{Inspiration from NeRFs}
In the years between 2020 and 2023, we have witnessed rapid advancements in NeRFs, as moving through a very steep trajectory, multiple compression techniques have significantly impacted the design of newer generation NeRFs. Recent work on NeRF compression, such as~\cite{tancik2022block} demonstrated how neural network-based approaches can efficiently represent large-scale 3D scenes with compact latent representations. This paradigm suggests that 3DGS compression could similarly benefit from end-to-end deep learning techniques that directly optimize 3D Gaussian representations, rather than relying merely on traditional data compression methods. By learning more efficient latent space representations of 3D objects, neural network-based models like NeRFs have shown the potential to dramatically reduce the storage and transmission requirements for high-fidelity 3D scenes, which could inspire similar methods for compressing 3D Gaussian components.

One of the key contributions of NeRFs to the field of compression is the use of hierarchical representations~\cite{tang2022compressible,zheng2024hpc}. In NeRFs, the scene is encoded in multiple levels of resolution, progressively refining the details of the 3D structure and lighting~\cite{di2025boost}. This hierarchical approach can be applied to 3D Gaussian Splitting by allowing for multi-level Gaussian components to be represented at varying degrees of detail, depending on the importance of different regions of the 3D space. The concept of progressive compression, where data is encoded in multiple stages to maintain high fidelity in key regions while aggressively compressing less critical data, could offer a path forward for improving 3DGS techniques, especially in complex 3D scenes where different regions (eg., background vs. foreground) require different levels of precision.

Additionally, NeRF compression methods such as \cite{tang2022compressible,deng2023compressing} have highlighted the potential of sparsity in 3D data, where significant portions of the scene can be represented with minimal data points. For 3DGS, leveraging sparse representations could lead to substantial gains in compression efficiency, as Gaussian components that are not central to the scene’s overall structure could be pruned or encoded with fewer parameters. This sparsity, combined with efficient encoding methods inspired by NeRFs, could enable next-generation 3DGS algorithms to handle large-scale 3D data more effectively.

Furthermore, techniques like adaptive quantization and neural compression employed in NeRFs open the door for utilizing machine learning models to optimize the encoding of Gaussian components. Such models can automatically adjust the precision of 3D Gaussian parameters based on the local geometric complexity and importance of the regions being encoded, or simply depth, concept explored in~\cite{deng2022depth}. By adopting similar principles, 3DGS compression could be enhanced to dynamically adjust encoding strategies based on the structure of 3D data.


\subsection{Inspiration from Point Cloud Compression}
Point clouds are among the most important and widely used 3D representations in applications such as autonomous driving, robotics, and physics simulation. The output of 3DGS is also a point cloud, making point cloud compression essential for the efficient storage and transmission of 3DGS scenes. To achieve a favorable compression ratio, it is critical to focus on lossy compression methods and address a key question: what properties of point clouds should be preserved within a limited bitrate budget?

Despite the fact that the output of 3DGS is a point cloud, there has been little focus on combining 3DGS compression with dedicated point cloud compression techniques. While the compression methods used in 3DGS result in a compressed point cloud, this is more of a byproduct of those methods rather than a direct effort to compress the point cloud itself. Given the growing importance of 3D representations in various applications, point cloud compression is a popular research area. Inspired by recent advancements in point cloud compression~\cite{he2022density,song2023efficient}, it is worth exploring how these techniques can be integrated into the end-to-end training process of 3DGS or developed as a separate module specifically tailored for compressing the output of 3DGS.

\section{Conclusion}

This survey provides a comprehensive overview of 3DGS compression methods within the framework of the proposed taxonomy. Compression techniques are categorized into unstructured and structured methods, highlighting significant advancements in memory efficiency and computational performance. We evaluate these techniques in terms of fidelity, compression ratios, and rendering speeds.  Both approaches offer distinct advantages and trade-offs. Structured compression methods leverage the relationships between Gaussians to achieve compression ratios of up to 100$\times$ compared to baseline 3DGS while maintaining high fidelity and perceptual quality. However, this comes at the cost of rendering speed, with FPS comparable to baseline 3DGS-30k. In contrast, unstructured compression methods achieve compression ratios of up to 50$\times$, preserving fidelity similar to baseline 3DGS-30k, while significantly improving rendering speeds by up to 7$\times$. These techniques address critical challenges such as storage constraints and computational overhead, further establishing 3DGS as a scalable and efficient representation for applications ranging from virtual reality to autonomous systems.  

Despite these advances, the scalability of 3DGS for large and complex scenes remains a significant challenge, especially for resource-constrained environments like mobile AR/VR devices. The field also lacks a unified framework that integrates the strengths of structured and unstructured compression methods, limiting the adaptability and standardization of 3DGS models. Furthermore, existing research has not sufficiently explored the potential of novel scalar quantization techniques or the optimization of loss functions tailored specifically for 3DGS. Addressing these gaps could unlock higher compression efficiencies, improved rendering speeds, and enhanced fidelity, making 3DGS more practical for real-world deployment. Additionally, interdisciplinary approaches combining insights from NeRFs, point-based rendering, and emerging deep learning paradigms hold promise for overcoming these limitations.

Looking forward, the future of 3DGS lies in developing hybrid compression frameworks, optimizing models for edge devices, and expanding its applications across diverse domains. Scalar quantization techniques, loss function innovations, and hardware-aware optimizations will be critical to enabling real-time rendering on low-power devices. The impact of 3DGS extends beyond academic research to industries such as healthcare, where it can enhance simulation fidelity, and entertainment, where it enables immersive experiences. By addressing current challenges, the transformative potential of 3DGS can be fully realized, redefining how machines and humans interact with 3D environments. Through continued innovation and exploration, 3DGS can become a cornerstone technology in the next generation of 3D scene rendering.

% This survey has provided a comprehensive exploration of 3DGS, emphasizing its transformative impact on 3D scene rendering and representation. Unlike traditional NeRFs, which rely on implicit models, 3DGS utilizes millions of learnable 3D Gaussians for explicit scene representation, enabling real-time rendering with remarkable editability. The review of current compression techniques, categorized into unstructured and structured methods, highlights significant advancements in memory and computational efficiency. Methods such as pruning, quantization, and entropy coding have achieved impressive compression ratios of up to 40$\times$ without substantial degradation in visual fidelity. These techniques address critical bottlenecks, including storage limitations and computational overhead, and have positioned 3DGS as a versatile tool for various applications ranging from virtual reality to autonomous systems.

% Despite these advances, the scalability of 3DGS for large and complex scenes remains a significant challenge, especially for resource-constrained environments like mobile AR/VR devices. The field also lacks a unified framework that integrates the strengths of structured and unstructured compression methods, limiting the adaptability and standardization of 3DGS models. Furthermore, existing research has not sufficiently explored the potential of novel scalar quantization techniques or the optimization of loss functions tailored specifically for 3DGS. Addressing these gaps could unlock higher compression efficiencies, improved rendering speeds, and enhanced quality preservation, making 3DGS more practical for real-world deployment. Additionally, interdisciplinary approaches combining insights from NeRFs, point-based rendering, and emerging deep learning paradigms hold promise for overcoming these limitations.

% Looking forward, the future of 3DGS lies in developing hybrid compression frameworks, optimizing models for edge devices, and expanding its applications across diverse domains. Scalar quantization techniques, loss function innovations, and hardware-aware optimizations will be critical to enabling real-time rendering on low-power devices. The impact of 3DGS extends beyond academic research to industries such as healthcare, where it can enhance simulation fidelity, and entertainment, where it enables immersive experiences. By addressing current challenges, the transformative potential of 3DGS can be fully realized, redefining how machines and humans interact with 3D environments. Through continued innovation and exploration, 3DGS can become a cornerstone technology in the next generation of 3D scene rendering.

%This survey provides a comprehensive overview of the trends, methods, and future directions for 3DGS compression. Given the rapid growth in popularity and the numerous follow-up works focusing on compressing 3D Gaussian Splatting (3DGS), this survey categorizes various compression methodologies, highlighting their advantages, limitations, and areas for improvement. In addition to analyzing the current state of 3DGS compression techniques, we identify key challenges and propose future research directions to address these issues, aiming to guide the development of more efficient and effective compression strategies.


%\textcolor{green}{\section{Figures and Tables to Add}}
% \begin{enumerate}
%     \item \textcolor{green}{Highlight Figure (highlighting number of works in 3DGS in last year)}
%     %\item \textcolor{green}{Main Figure of 3DGS}
%     %\item \textcolor{green}{Working of 3DGS (details of rasterization algorithm)}
%     %\item \textcolor{green}{Taxonomy Figure}
%     %\item \textcolor{green}{Table for Categorizing the Methods}
%     %\item \textcolor{green}{Figure for visual explanation of categorization of 3DGS compression and techniques involved}
%     %\item \textcolor{green}{Qualitative Comparison of Different Figures}
% \end{enumerate}





% \section{Discussion}
% NeRFs revolutionized the field of 3D reconstruction despite being initially slow and challenging to train and render. However, since the pioneering NeRF work in 2020, subsequent research has significantly addressed these issues, with efficient NeRFs now capable of rendering at up to 200 FPS~\cite{garbin2021fastnerf}. Nevertheless, the advent of 3DGS has quickly surpassed the challenges faced by NeRFs and has rapidly become a transformative force in 3D reconstruction. The unparalleled flexibility offered by 3DGS already surpasses the performance of state-of-the-art NeRFs. Considering the multitude of works in 3DGS, we can anticipate its widespread adoption in 3D reconstruction applications in the coming years~\cite{DBLP:journals/corr/abs-2401-03890}. However, a critical factor for its success is dependent upon reducing the memory footprint of 3DGS, making compression of 3DGS an essential topic for ongoing research and development.

% This work aims to provide an excellent starting point for the community aiming to address the challenges of 3DGS, particularly in compression. This paper shall provide a detailed overview of 3DGS, their challenges, and problems, and shall offer an overview of recent compression techniques, and suggests how future research can draw inspiration from advancements in the efficient NeRFs domain for efficient 3DGS compression.
 
 
%The goal of this paper is to inform readers about recent preliminary works focusing on 3DGS compression and to provide insights from efficient NeRF compression techniques and information theory-based compression methods. This foundation aims to support further advancements in the compression of 3DGS models.





\bibliographystyle{ieeetr}
\bibliography{ref}

\end{document}
