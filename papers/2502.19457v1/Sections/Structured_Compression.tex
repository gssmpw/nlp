%

\section{Structured Compression}
Structured compression techniques for 3DGS introduce organization into the otherwise sparse Gaussian representations, enabling more efficient storage and processing. These approaches leverage spatial relationships between Gaussians through anchors, graphs, trees, hierarchical structures, and predictive models. Unlike unstructured methods, which primarily focus on pruning, quantization, and entropy encoding without incorporating the underlying structure of Gaussians, structured approaches introduce architectural constraints to optimize compression efficiency while maintaining reconstruction quality.

\noindent
\subsection{Anchor Based}
Scaffold-GS~\cite{lu2023scaffold} introduces anchor points to structure Gaussians within a scene, ensuring more compact representations while maintaining fidelity (Figure~\ref{fig:scaffoldgs}). Anchors serve as structured reference points, guiding the hierarchical organization and spatial distribution of Gaussians. Unlike traditional 3DGS, where Gaussians freely drift or split, Scaffold-GS employs a grid of anchors, initially derived from SfM points, to provide a region-aware and constrained representation. Each anchor acts as a fixed control center that tethers multiple Gaussians with learnable offsets, enabling local adaptations while preserving structural coherence. Scaffold-GS dynamically predicts Gaussian attributes such as opacity, color, rotation, and scale based on local feature representations and viewing positions. It also employs anchor growing and pruning strategies to refine scene representations—introducing new anchors in underrepresented regions and removing redundant ones. As a foundational method, Scaffold-GS serves as a backbone for subsequent structured compression techniques, providing a reliable framework for further optimization.
HAC (Hash-Grid Assisted Context Modeling)~\cite{chen2024hac}  builds upon Scaffold-GS by incorporating hash grid features to capture spatial dependencies among Gaussians. A hash grid is a structured data representation to efficiently store and query spatial data. HAC uses a binary hash grid to capture spatial consistencies among unorganized 3D Gaussians (or anchors). HAC introduces an Adaptive Scalar Quantization Module (AQM) that dynamically adjusts quantization step sizes for different anchor attributes. HAC queries the hash grid by anchor location to obtain interpolated hash features, which are then used to predict the distribution of anchor attribute values, enabling efficient entropy coding, such as Arithmetic Coding (AE)~\cite{witten1987arithmetic}, for a highly compact model representation. However, HAC encodes all anchors simultaneously, leaving room for further optimization to reduce spatial redundancy.
% Hash-Grid Assisted Context Modeling (HAC)~\cite{chen2024hac}  builds upon Scaffold-GS by incorporating hash grid features to capture spatial dependencies among Gaussians. HAC introduces an Adaptive Scalar Quantization Module (AQM) that dynamically adjusts quantization step sizes for different anchor attributes. HAC queries interpolated hash features to predict anchor attributes, facilitating efficient entropy coding via Arithmetic Coding (AE)~\cite{witten1987arithmetic}. However, HAC encodes all anchors simultaneously, leaving room for further optimization to reduce spatial redundancy.
%HAC (Hash-Grid Assisted Context Modeling)~\cite{} builds upon Scaffold-GS by incorporating hash grid features to capture spatial dependencies among Gaussians. HAC queries interpolated hash features to predict anchor attributes, facilitating efficient entropy coding via Arithmetic Coding (AE)~\cite{witten1987arithmetic}. To further improve representation, HAC introduces an Adaptive Scalar Quantization Module (AQM) that dynamically adjusts quantization step sizes for different anchor attributes, ensuring high fidelity while maintaining compression efficiency. However, HAC encodes all anchors simultaneously, leaving room for further optimization in reducing spatial redundancy.



\noindent
\subsection{Contextual/ Autoregressive (AR) Modeling}
Context models~\cite{minnen2018joint}, commonly used in image compression (LIC) to enhance coding efficiency by predicting the distribution of latent pixels based on already coded ones, inspired ContextGS~\cite{wang2024contextgs}. This approach encodes anchor features autoregressively, predicting anchor points from those already coded at coarser levels. However, compared to LIC methods, the AR-based approach used in ContextGS is significantly faster. ContextGS employs a three-level hierarchical encoding scheme for anchors, where higher-level anchors rely on context from coarser-level anchors for both encoding and decoding. This approach closely mirrors the ChARM~\cite{minnen2020channel} method, making the process more efficient while utilizing the context for compression. Another approach CompGS (Compressed Gaussian Splatting)~\cite{li2017efficient} also utilizes context by introducing a hybrid primitive structure, where sparse anchor primitives serve as reference points for predicting attributes of other Gaussians. 
%ContextGS utilizes AR encoding, a technique commonly used in learned image compression (LIC) \cite{minnen2018joint}. By hierarchically predicting anchor points, ContextGS organizes them into three levels, encoding coarser-level anchors first and using them to predict finer-level anchors. This progressive refinement improves coding efficiency and reduces storage overhead.
%CompGS (Compressed Gaussian Splatting)~\cite{li2017efficient} also utilizes context by introducing a hybrid primitive structure, where sparse anchor primitives serve as reference points for predicting attributes of other Gaussians. This enables a highly compact representation, optimizing the trade-off between compression efficiency and reconstruction quality.

\noindent
\subsection{Graph Based}
Unlike anchor-based methods, graph-based compression treats Gaussians as a graph, leveraging their spatial relationships to optimize compression. Spectrally Pruned Gaussian Fields with Neural Compensation (SUNDAE)~\cite{yang2024spectrally} prunes redundant Gaussians while preserving key scene details. A distinct feature of SUNDAE is its neural compensation head, which shifts from direct GS to feature splatting, enabling lightweight neural network-based feature interpolation. %This approach significantly reduces memory footprint while maintaining high reconstruction quality.
GaussianForest (GF)~\cite{zhang2024gaussian} introduces a tree-structured hierarchical representation for 3D scenes. Unlike traditional unstructured Gaussians, GF assigns explicit attributes (e.g., position, opacity) to leaf nodes, while implicit attributes (e.g., covariance matrix, view-dependent color) are shared across hierarchical levels. Additionally, GF employs adaptive growth and pruning, dynamically adjusting the representation to scene complexities.

\noindent
\subsection{Factorization Approach}
Factorization-based compression techniques introduce mathematical approximations to efficiently represent dense clusters of Gaussians. F-3DGS (Factorized 3D Gaussian Splatting)~\cite{sun2024f} employs matrix and tensor factorization to represent high-dimensional Gaussian parameters using a limited number of basis components per axis. Instead of storing all parameters directly, F-3DGS factorizes attributes such as color, scale, and rotation substantially reducing storage requirements while preserving essential visual attributes. 

\subsection{Discussion}
We also analyze the performance of structured compression techniques for 3DGS on the Mip-NeRF360, Tanks\&Temples, and Deep Blending datasets, focusing on fidelity, compression ratio, and FPS.% Unlike unstructured compression methods, structured approaches impose systematic constraints on the representation, potentially leading to improved storage efficiency while maintaining high reconstruction fidelity.

\begin{figure*}[t]
    \centering
    \includegraphics[width=\linewidth]{Figures/memvspsnr.pdf}
    \caption{Comparison of PSNR and size across structured and unstructured compression techniques. The box represents unstructured compression methods, while the downward triangle represents structured compression methods.}
    \label{fig:memvspsnr}
\end{figure*}

\noindent
\textbf{Fidelity: }
Structured compression methods such as ScaffoldGS, HAC-highrate, and ContextGS (highrate) exhibit strong fidelity across all datasets as shown in Table~\ref{tab:structured_mip_tandt} and Table~\ref{tab:struct_db}. ContextGS-highrate achieves the highest PSNR of 30.39 dB and SSIM of 0.909 on Deep Blending, while HAC-highrate attains a PSNR of 30.34 dB and SSIM of 0.906. ScaffoldGS maintains a competitive PSNR of 30.21 dB and SSIM of 0.906 on Mip-NeRF360.
Interestingly, CompGS-highrate, despite achieving high PSNR, exhibits slightly higher LPIPS score, indicating some perceptual degradation. These results suggest that ScaffoldGS, ContextGS, and HAC-highrate offer the best fidelity, while CompGS provides an optimal balance between compression efficiency and perceptual quality.

\noindent
\textbf{Compression Ratio: }Tables~\ref{tab:structured_mip_tandt} and~\ref{tab:struct_db} show CompGS (lowrate) achieves the highest compression ratio, reducing memory by 83$\times$ on Mip-NeRF360, 70$\times$ on Tanks\&Temples, and 113$\times$ on Deep Blending, while ContextGS (lowrate) reaches 58$\times$ on Mip-NeRF360 and Tanks\&Temples and 188$\times$ on Deep Blending, making them the most storage-efficient techniques with lowest memory footprint compared to the baseline. HAC-lowrate also demonstrates strong compression performance, achieving 48$\times$ reduction on Mip-NeRF360 and 154$\times$ on Deep Blending, with a favorable balance between storage efficiency and fidelity. In contrast, ScaffoldGS and GF, though still reducing memory footprint, operate at relatively lower compression rates (7$\times$–10$\times$).

\noindent
\textbf{FPS: }Structured compression methods, while achieving high compression rates, often maintain FPS similar to or lower than the 3DGS-30k baseline, as shown in Figure~\ref{fig:fpsvspsnr}. GF and HAC, despite their efficient compression, exhibit slower rendering speeds due to high encoding/decoding complexity, which improves compression but reduces rendering efficiency. CompGS, however, demonstrates better rendering speeds than 3DGS-30k, HAC, and GF across all benchmark datasets, making it a more balanced approach between compression efficiency and rendering speed.

Our analysis reveals that HAC-lowrate, CompGS (lowrate), and ContextGS (lowrate) achieve the most aggressive compression ratios, while ScaffoldGS, ContextGS (highrate), and HAC-highrate attain the highest fidelity. Although structured compression techniques offer superior storage efficiency compared to unstructured methods, there remains a trade-off between extreme compression and rendering speeds. 