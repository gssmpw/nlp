\section{Introduction}
\label{sec:intro}

% 3D part segmentation is important: enables machines with human-like ability: an parse objects into parts and generalize to unseen object and facilitates a wide range of applications, such as robotic manipulation, AR/VR, ...
The advancements in 3D technologies have led to an increased demand for automated analysis of 3D shapes. In particular, 3D part segmentation is an important task as it supports a wide spectrum of applications including robotic and AR/VR. 

% Human has more complex and varying geometry, richer semantic meanings, making it different from general object part segmentation
With the introduction of deep neural networks \cite{qi2017pointnet, qi2017pointnet++, thomas2019kpconv, xu2021paconv, zhao2021point, wang2019dynamic} and labeled 3D datasets \cite{wu20153d, chang2015shapenet, mo2019partnet}, 3D part segmentation has seen remarkable progress in recent years through supervised training. Nonetheless, due to limited data, enabling machines with human-like ability to parse objects into semantic parts and generalize to unseen object categories still remains difficult. This is especially the case with 3D humans, which contain more complex geometry with richer semantic attributes than general 3D objects.

% Current human part-specific segmentation run on 3D closed datasets, previous general 3D seg not working well on human data. these methods rely on a predefined set of semantic labels. Due to limited data, previous 3D-based methods are not generalizable to new categories and not suitable for human parts segmentation, which has highly variable combinations.
In contrast to generic shape data, there is also significantly fewer annotated data for 3D humans. Previous human parsing methods have been trained on clothed data \cite{bhatnagar2019multi, musoni2023gim3d, antic2024close}, but due to their inherent closed-set model structure, they can only parse humans into a predefined set of semantic labels. In addition, as existing datasets vary in terms of the labeled categories, content and quality, a model trained on one dataset may not generalize well to others. Although it is plausible to combine multiple datasets into a single taxonomy to enhance the generalization ability, the model will still remain inflexible to unseen classes and is hard to scale. 

% Recent developments in vision-language learning gave rise to many 2D image-based models with extreme zero-shot generalization capabilities. Many open-set segmentation methods are proposed to leverage the knowledge in 2D space. Most of them evaluated on object data and to the best of our knowledge, not working well for human. 
Recent developments in vision-language learning gave rise to many 2D image-based models \cite{radford2021learning, li2022grounded, jia2021scaling, zhai2023sigmoid} with exceptional zero-shot generalization capabilities. To extend to 3D, some works \cite{zhang2022pointclip, zhu2023pointclip, abdelreheem2023satr, liu2023partslip, zhou2023partslip++} have leveraged the knowledge of these models in 2D space and aggregate the multi-view information for the final segmentation result. While these methods have shown promising results on object data, they have not shown the same quality of results on 3D human data.

% we propose a way to transfer knowledge from 2D to 3D through SAM-based part segmentation on rendering and a novel lifting algorithm using finetuned to fuse inconsistent masks and build correlations with desired semantic labels
In this paper, we introduce the first open-vocabulary framework for 3D human parsing by transferring knowledge from 2D to 3D. As a mask-based segmentation method \cite{cheng2021per}, our method first applies SAM to rendered images and lifts to 3D to produce class-agnostic partial masks. In order to fuse the inconsistent masks and build correlations with the desired semantic labels, we leverage a novel HumanCLIP model to extract embeddings for each mask. Since this human-centric vision-language model can produce consistent embeddings for semantically similar masks, it helps with the seamless integration of inconsistent 3D masks. Our experimental results show our framework's flexibility to parse a 3D human with the desired labels and its generalizability to various 3D representations including meshes, point clouds, and 3D Gaussians \cite{kerbl20233d}.

% Efficient & flexible model designï¼š one-time precomputed mask proposal supporting infinite segmentation
In summary, the main contributions of this work are:
\begin{itemize}
    \item The first open-vocabulary framework for 3D humans.
    \item A novel HumanCLIP model capable of extracting accurate CLIP embeddings for human parts.  
    \item Our framework demonstrates generalization ability to various 3D representations including meshes, point clouds, and 3D Gaussians.
\end{itemize}