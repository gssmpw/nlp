@inproceedings{Dukic2024LookingRI,
  title={Looking Right is Sometimes Right: Investigating the Capabilities of Decoder-only LLMs for Sequence Labeling},
  author={Duki{\'c}, David and {\v{S}}najder, Jan},
  booktitle={Annual Meeting of the Association for Computational Linguistics},
  year={2024}
}

@article{aryabumi2024aya,
  title={Aya 23: Open weight releases to further multilingual progress},
  author={Aryabumi, Viraat and Dang, John and Talupuru, Dwarak and Dash, Saurabh and Cairuz, David and Lin, Hangyu and Venkitesh, Bharat and Smith, Madeline and Marchisio, Kelly and Ruder, Sebastian and others},
  journal={arXiv preprint arXiv:2405.15032},
  year={2024}
}

@inproceedings{behnamghader2024llmvec,
    title={{LLM}2Vec: Large Language Models Are Secretly Powerful Text Encoders},
    author={BehnamGhader, Parishad and Adlakha, Vaibhav and Mosbach, Marius and Bahdanau, Dzmitry and Chapados, Nicolas and Reddy, Siva},
    booktitle={First Conference on Language Modeling},
    year={2024},
    url={https://openreview.net/forum?id=IW1PR7vEBf}
}

@inproceedings{dale2023halomi,
    title={HalOmi: A Manually Annotated Benchmark for Multilingual Hallucination and Omission Detection in Machine Translation},
    author={Dale, David and Voita, Elena and Lam, Janice and Hansanti, Prangthip and Ropers, Christophe and Kalbassi, Elahe and Gao, Cynthia and Barrault, Loic and Costa-juss{\`a}, Marta R.},
    booktitle={The 2023 Conference on Empirical Methods in Natural Language Processing},
    year={2023}
}

@article{dubey2024llama,
  title={The llama 3 herd of models},
  author={Dubey, Abhimanyu and Jauhri, Abhinav and Pandey, Abhinav and Kadian, Abhishek and Al-Dahle, Ahmad and Letman, Aiesha and Mathur, Akhil and Schelten, Alan and Yang, Amy and Fan, Angela and others},
  journal={arXiv preprint arXiv:2407.21783},
  year={2024}
}

@article{ji2023ai,
  title={Ai alignment: A comprehensive survey},
  author={Ji, Jiaming and Qiu, Tianyi and Chen, Boyuan and Zhang, Borong and Lou, Hantao and Wang, Kaile and Duan, Yawen and He, Zhonghao and Zhou, Jiayi and Zhang, Zhaowei and others},
  journal={arXiv preprint arXiv:2310.19852},
  year={2023}
}

@article{ji2023survey,
  title={Survey of hallucination in natural language generation},
  author={Ji, Ziwei and Lee, Nayeon and Frieske, Rita and Yu, Tiezheng and Su, Dan and Xu, Yan and Ishii, Etsuko and Bang, Ye Jin and Madotto, Andrea and Fung, Pascale},
  journal={ACM Computing Surveys},
  volume={55},
  number={12},
  pages={1--38},
  year={2023},
  publisher={ACM}
}

@article{kasai2024realtime,
  title={REALTIME QA: what's the answer right now?},
  author={Kasai, Jungo and Sakaguchi, Keisuke and Le Bras, Ronan and Asai, Akari and Yu, Xinyan and Radev, Dragomir and Smith, Noah A and Choi, Yejin and Inui, Kentaro and others},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@inproceedings{kim-etal-2024-analysis,
    title = "An Analysis of Multilingual {FA}ct{S}core",
    author = "Kim, Vu Trong  and
      Krumdick, Michael  and
      Reddy, Varshini  and
      Dernoncourt, Franck  and
      Lai, Viet Dac",
    editor = "Al-Onaizan, Yaser  and
      Bansal, Mohit  and
      Chen, Yun-Nung",
    booktitle = "Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing",
    month = nov,
    year = "2024",
    address = "Miami, Florida, USA",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2024.emnlp-main.247",
    doi = "10.18653/v1/2024.emnlp-main.247",
    pages = "4309--4333",
    abstract = "FActScore has gained popularity as a metric to estimate the factuality of long-form texts generated by Large Language Models (LLMs) in English. However, there has not been any work in studying the behavior of FActScore in other languages. This paper studies the limitations of each component in the four-component pipeline of FActScore in the multilingual setting. We introduce a new dataset for FActScore on texts generated by strong multilingual LLMs. Our evaluation shows that LLMs exhibit distinct behaviors in both fact extraction and fact scoring tasks. No LLM produces consistent and reliable FActScore across languages of varying levels of resources. We also find that the knowledge source plays an important role in the quality of the estimated FActScore. Using Wikipedia as the knowledge source may hinder the true FActScore of long-form text due to its limited coverage in medium- and low-resource languages. We also incorporate 3 mitigations to our knowledge source that ultimately improve FActScore estimation across all languages.",
}

@article{kojima2022large,
  title={Large language models are zero-shot reasoners},
  author={Kojima, Takeshi and Gu, Shixiang Shane and Reid, Machel and Matsuo, Yutaka and Iwasawa, Yusuke},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={22199--22213},
  year={2022}
}

@inproceedings{lattimer2023fast,
  title={Fast and Accurate Factual Inconsistency Detection Over Long Documents},
  author={Lattimer, Barrett and Chen, Patrick and Zhang, Xinyuan and Yang, Yi},
  booktitle={Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing},
  pages={1691--1703},
  year={2023}
}

@inproceedings{li2023halueval,
  title={HaluEval: A Large-Scale Hallucination Evaluation Benchmark for Large Language Models},
  author={Li, Junyi and Cheng, Xiaoxue and Zhao, Wayne Xin and Nie, Jian-Yun and Wen, Ji-Rong},
  booktitle={Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing},
  pages={6449--6464},
  year={2023}
}

@article{li2023label,
  title={Label supervised llama finetuning},
  author={Li, Zongxi and Li, Xianming and Liu, Yuzhang and Xie, Haoran and Li, Jing and Wang, Fu-lee and Li, Qing and Zhong, Xiaoqin},
  journal={arXiv preprint arXiv:2310.01208},
  year={2023}
}

@inproceedings{lin2022truthfulqa,
  title={TruthfulQA: Measuring How Models Mimic Human Falsehoods},
  author={Lin, Stephanie and Hilton, Jacob and Evans, Owain},
  booktitle={Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics},
  pages={3214--3252},
  year={2022}
}

@inproceedings{liu-etal-2022-multi,
    title = "Multi-Stage Prompting for Knowledgeable Dialogue Generation",
    author = "Liu, Zihan and Patwary, Mostofa and Prenger, Ryan and Prabhumoye, Shrimai and Ping, Wei and Shoeybi, Mohammad and Catanzaro, Bryan",
    booktitle = "Findings of the Association for Computational Linguistics: ACL 2022",
    year = "2022",
    pages = "1317--1337"
}

@inproceedings{liu-etal-2022-token,
    title = "A Token-level Reference-free Hallucination Detection Benchmark for Free-form Text Generation",
    author = "Liu, Tianyu and Zhang, Yizhe and Brockett, Chris and Mao, Yi and Sui, Zhifang and Chen, Weizhu and Dolan, Bill",
    booktitle = "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics",
    year = "2022",
    pages = "6723--6737"
}

@inproceedings{manakul-etal-2023-selfcheckgpt,
    title = "{S}elf{C}heck{GPT}: Zero-Resource Black-Box Hallucination Detection for Generative Large Language Models",
    author = "Manakul, Potsawee and Liusie, Adian and Gales, Mark",
    booktitle = "Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing",
    year = "2023",
    pages = "9004--9017"
}

@article{min2023factscore,
  title={Factscore: Fine-grained atomic evaluation of factual precision in long form text generation},
  author={Min, Sewon and Krishna, Kalpesh and Lyu, Xinxi and Lewis, Mike and Yih, Wen-tau and Koh, Pang Wei and Iyyer, Mohit and Zettlemoyer, Luke and Hajishirzi, Hannaneh},
  journal={arXiv preprint arXiv:2305.14251},
  year={2023}
}

@inproceedings{mishra2024finegrained,
    title={Fine-grained Hallucination Detection and Editing for Language Models},
    author={Mishra, Abhika and Asai, Akari and Balachandran, Vidhisha and Wang, Yizhong and Neubig, Graham and Tsvetkov, Yulia and Hajishirzi, Hannaneh},
    booktitle={First Conference on Language Modeling},
    year={2024}
}

@article{ouyang2022training,
  title={Training language models to follow instructions with human feedback},
  author={Ouyang, Long and Wu, Jeffrey and Jiang, Xu and Almeida, Diogo and Wainwright, Carroll and Mishkin, Pamela and Zhang, Chong and Agarwal, Sandhini and Slama, Katarina and Ray, Alex and others},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={27730--27744},
  year={2022}
}

@inproceedings{qiu-etal-2023-detecting,
    title = "Detecting and Mitigating Hallucinations in Multilingual Summarisation",
    author = "Qiu, Yifu and Ziser, Yftah and Korhonen, Anna and Ponti, Edoardo and Cohen, Shay",
    booktitle = "Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing",
    year = "2023",
    pages = "8914--8932"
}

@inproceedings{schmidt-etal-2024-self,
    title = "Self-Distillation for Model Stacking Unlocks Cross-Lingual {NLU} in 200+ Languages",
    author = "Schmidt, Fabian David and Borchert, Philipp and Vuli{\'c}, Ivan and Glava{\v{s}}, Goran",
    booktitle = "Findings of the Association for Computational Linguistics: EMNLP 2024",
    year = "2024",
    address = "Miami, Florida, USA",
    publisher = "Association for Computational Linguistics"
}

@article{vaswani2017attention,
  title={Attention is all you need},
  author={Vaswani, A},
  journal={Advances in Neural Information Processing Systems},
  year={2017}
}

@article{vu2023freshllms,
  title={Freshllms: Refreshing large language models with search engine augmentation},
  author={Vu, Tu and Iyyer, Mohit and Wang, Xuezhi and Constant, Noah and Wei, Jerry and Wei, Jason and Tar, Chris and Sung, Yun-Hsuan and Zhou, Denny and Le, Quoc and others},
  journal={arXiv preprint arXiv:2310.03214},
  year={2023}
}

@article{wei2024long,
  title={Long-form factuality in large language models},
  author={Wei, Jerry and Yang, Chengrun and Song, Xinying and Lu, Yifeng and Hu, Nathan and Tran, Dustin and Peng, Daiyi and Liu, Ruibo and Huang, Da and Du, Cosmo and others},
  journal={arXiv preprint arXiv:2403.18802},
  year={2024}
}

@article{wei2024measuring,
  title={Measuring short-form factuality in large language models},
  author={Wei, Jason and Nguyen, Karina and Chung, Hyung Won and Jiao, Yunxin Joy and Papay, Spencer and Glaese, Amelia and Schulman, John and Fedus, William},
  journal={arXiv preprint arXiv:2411.04368},
  year={2024}
}

@article{yang2023new,
  title={A new benchmark and reverse validation method for passage-level hallucination detection},
  author={Yang, Shiping and Sun, Renliang and Wan, Xiaojun},
  journal={arXiv preprint arXiv:2310.06498},
  year={2023}
}

@article{yang2024qwen2,
  title={Qwen2 technical report},
  author={Yang, An and Yang, Baosong and Hui, Binyuan and Zheng, Bo and Yu, Bowen and Zhou, Chang and Li, Chengpeng and Li, Chengyuan and Liu, Dayiheng and Huang, Fei and others},
  journal={arXiv preprint arXiv:2407.10671},
  year={2024}
}

@article{zhang2023instruction,
  title={Instruction tuning for large language models: A survey},
  author={Zhang, Shengyu and Dong, Linfeng and Li, Xiaoya and Zhang, Sen and Sun, Xiaofei and Wang, Shuhe and Li, Jiwei and Hu, Runyi and Zhang, Tianwei and Wu, Fei and others},
  journal={arXiv preprint arXiv:2308.10792},
  year={2023}
}

@inproceedings{zhou2021detecting,
  title={Detecting Hallucinated Content in Conditional Neural Sequence Generation},
  author={Zhou, Chunting and Neubig, Graham and Gu, Jiatao and Diab, Mona and Guzm{\'a}n, Francisco and Zettlemoyer, Luke and Ghazvininejad, Marjan},
  booktitle={Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021},
  pages={1393--1404},
  year={2021}
}

@article{ziegler2019fine,
  title={Fine-tuning language models from human preferences},
  author={Ziegler, Daniel M and Stiennon, Nisan and Wu, Jeffrey and Brown, Tom B and Radford, Alec and Amodei, Dario and Christiano, Paul and Irving, Geoffrey},
  journal={arXiv preprint arXiv:1909.08593},
  year={2019}
}

