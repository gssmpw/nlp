\section{Related Work}
Conversational Privacy Bots (PriBots) address the growing need for accessible privacy notices by allowing users to pose privacy-related questions in natural language~\cite{harkousPriBotsConversationalPrivacy, grunewald2023enabling}. %Yet, PriBots have seen limited adoption due to implementation complexities and legal challenges. 
So far, efforts to support privacy Q\&A have focused on collecting and annotating privacy policy corpora and applying neural networks to extract answers from privacy policies~\cite{wilsonCreationAnalysisWebsite2016, ravichanderQuestionAnsweringPrivacy2019, ahmadPolicyQAReadingComprehension2020a, aroraTaleTwoRegulatory, sathyendraHelpingUsersUnderstanda}. Notable corpora include the OPP-115 Corpus of website privacy policies~\cite{wilsonCreationAnalysisWebsite2016}, the APP-350 Corpus of annotated Android app policies~\cite{zimmeck2019maps} and a bilingual corpus of mobile app policies~\cite{aroraTaleTwoRegulatory}. Other work has focused on collecting privacy Q\&A specific corpora, e.g., the Policy Q\&A corpus~\cite{ahmadPolicyQAReadingComprehension2020a} and the Privacy Q\&A corpus which uses excerpt-based answers identified by legal experts~\cite{ravichanderQuestionAnsweringPrivacy2019}. Despite these efforts, no privacy Q\&A corpus exists for CAI systems. While existing corpora could be adapted, they rarely cover questions and answers specific to CAI systems, e.g., on voice recordings or text transcripts.
Moreover, pre-trained language models used to directly extract answers from privacy policies were found largely unsuitable and face challenges with responding to unanswerable questions~\cite{ravichanderQuestionAnsweringPrivacy2019, ahmadPolicyQAReadingComprehension2020a, ravichanderBreakingWallsText2021}. Thereby, NLP approaches can produce overly technical and lengthy responses that conflict with conversation design principles such as minimization and user-friendly language~\cite{MooreNCF}. At the same time, responses must accurately reflect the essential content of a privacy policy~\cite{harkousPriBotsConversationalPrivacy}. This urges the need for collaboration between conversational designers and legal experts to ensure answers are both comprehensible and legally precise. This is particularly important, given that both comprehensibility and preciseness are aspects of the principle of transparency~\cite{Article29WP2018}, a legal requirement of the GDPR and global data protection regulations~\cite{gunst2021brusselseffect, ProtectingConsumerPrivacy2012}. 

%We address these gaps by creating a privacy Q\&A dataset specific to CAI systems. Our dataset includes answers validated by legal experts and conversational designers to emphasize comprehensibility and legal preciseness. 

%To meet the growing need for accessible privacy notices, researchers introduced Conversational Privacy Bots (PriBots)~\cite{harkousPriBotsConversationalPrivacy}. PriBots enable users to pose questions about privacy policies and establish preferences through natural language interactions. They can function as standalone tools or be employed alongside a privacy policy, thus allowing users to seek further information. PriBots are based on a retrieval module and a knowledge base containing not only the privacy policy but also other relevant resources. Thereby, the policy can be presented in an unstructured form, using natural language processing (NLP) techniques to extract the relevant parts to the answer, or in a structured and annotated format. Despite their introduction in 2016, PriBots failed to attain widespread adoption due to implementation complexities and legal challenges. Nevertheless, in light of the increasing need for user-friendly privacy notifications and control options in Conversational AI (CAI) systems, PriBots demonstrate the potential to complement traditional approaches.  

%To allow for downstream tasks such as question-answering, automatically checking privacy compliance~\cite{zimmeck2019maps} or helping users to browse privacy policies~\footnote{\url{https://explore.usableprivacy.org/}}, an increasing stream of research has focused on the collection and annotation of privacy policies corpora~\cite{wilsonCreationAnalysisWebsite2016, ravichanderQuestionAnsweringPrivacy2019, ahmadPolicyQAReadingComprehension2020a, aroraTaleTwoRegulatory}. %In particular, the Usable Privacy Policy Project~\footnote{\url{https://usableprivacy.org/}} has significantly contributed to overcoming limitations of current privacy policies. 
%Therefore, numerous datasets of privacy policies were collected and annotated to allow for the development of question-answering methods~\cite{ravichanderQuestionAnsweringPrivacy2019, wilsonCreationAnalysisWebsite2016}. 
%Other studies have focused on the collection of specific corpora to allow for the development of question-answering methods~\cite{harkousPolisisAutomatedAnalysis, ahmadPolicyQAReadingComprehension2020a, ravichanderQuestionAnsweringPrivacy2019}. 
%One privacy Q\&A dataset was collected by crawling user questions and companies' replies from Twitter~\cite{harkousPolisisAutomatedAnalysis}. In addition, the Policy Q\&A corpus consists of questions on website privacy policy and was curated from the OPP-115 corpus~\cite{ahmadPolicyQAReadingComprehension2020a} while the Privacy Q\&A corpus consists of 1750 questions on privacy policies of mobile applications that were collected from crowdworkers~\cite{ravichanderQuestionAnsweringPrivacy2019}. It is worth noting that only the Privacy Q\&A corpus relied on legal experts to identify relevant excerpts in the privacy policy for constructing answers. 

%NLP approaches are their divergence from optimal conversation design practices~\cite{harkousPolisisAutomatedAnalysis}. These responses can be lengthy due to the nature of privacy policies, violating the conversation design principle of minimization~\cite{MooreNCF}. Furthermore, they can incorporate technical and legal terms that are difficult for users to understand and require additional repair and rephrasing techniques~\cite{MooreNCF}. Therefore, the expertise of conversational designers is essential for crafting privacy answers and identifying violations of design principles~\cite{MooreNCF}. At the same time, although it is yet unclear whether privacy answers should be considered legally binding~\cite{harkousPriBotsConversationalPrivacy}, it has to be ensured that they best capture the essential notice of a privacy policy. Therefore, legal experts play a crucial role in safeguarding the legality of privacy answers. 


%Despite the efforts in collecting privacy policy corpora, data for privacy Q\&A for CAI is scarce. This is due to the fact that prior corpora have exclusively concentrated on privacy policies on websites or mobile applications. While models trained on existing corpora could be adapted to the Conversational AI context, questions and answers on voice recordings and text transcripts are only rarely covered. Moreover, previous research has relied on the original privacy policy texts as ground truth for training regardless of the known readability and understandability issues of legal texts~\cite{ravichanderBreakingWallsText2021}. Therefore, there is a need to construct and evaluate user-friendly benchmarks that account for known issues with peoples' comprehension of privacy policies.