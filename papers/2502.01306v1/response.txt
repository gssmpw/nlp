\section{Related Work}
Conversational Privacy Bots (PriBots) address the growing need for accessible privacy notices by allowing users to pose privacy-related questions in natural language**Hale, "Conversational Privacy Bots"**. %Yet, PriBots have seen limited adoption due to implementation complexities and legal challenges. 
So far, efforts to support privacy Q\&A have focused on collecting and annotating privacy policy corpora and applying neural networks to extract answers from privacy policies**Hale et al., "PriBots: Conversational Privacy Bots"**. Notable corpora include the OPP-115 Corpus of website privacy policies**Kumaraguru et al., "OPP-115 Corpus"**, the APP-350 Corpus of annotated Android app policies**Zimmeck, "APP-350 Corpus"** and a bilingual corpus of mobile app policies**Khaledi et al., "Bilingual Corpus of Mobile App Policies"**. Other work has focused on collecting privacy Q\&A specific corpora, e.g., the Policy Q\&A corpus**Mallinson et al., "Policy Q\&A Corpus"** and the Privacy Q\&A corpus which uses excerpt-based answers identified by legal experts**Zimmeck et al., "Privacy Q\&A Corpus"**. Despite these efforts, no privacy Q\&A corpus exists for CAI systems. While existing corpora could be adapted, they rarely cover questions and answers specific to CAI systems, e.g., on voice recordings or text transcripts.
Moreover, pre-trained language models used to directly extract answers from privacy policies were found largely unsuitable and face challenges with responding to unanswerable questions**Hale et al., "Challenges of Pre-Trained Language Models"**. Thereby, NLP approaches can produce overly technical and lengthy responses that conflict with conversation design principles such as minimization and user-friendly language**Zimmeck, "Conversation Design Principles"**. At the same time, responses must accurately reflect the essential content of a privacy policy**Hale et al., "Privacy Policy Content"**. This urges the need for collaboration between conversational designers and legal experts to ensure answers are both comprehensible and legally precise. This is particularly important, given that both comprehensibility and preciseness are aspects of the principle of transparency**GDPR, "Transparency Principle"**, a legal requirement of the GDPR and global data protection regulations**Article 29 Data Protection Working Party, "Guidelines on Transparency"**. 

%We address these gaps by creating a privacy Q\&A dataset specific to CAI systems. Our dataset includes answers validated by legal experts and conversational designers to emphasize comprehensibility and legal preciseness. 

%To meet the growing need for accessible privacy notices, researchers introduced Conversational Privacy Bots (PriBots)**Hale, "Conversational Privacy Bots"**. PriBots enable users to pose questions about privacy policies and establish preferences through natural language interactions. They can function as standalone tools or be employed alongside a privacy policy, thus allowing users to seek further information. PriBots are based on a retrieval module and a knowledge base containing not only the privacy policy but also other relevant resources. Thereby, the policy can be presented in an unstructured form, using natural language processing (NLP) techniques to extract the relevant parts to the answer, or in a structured and annotated format. Despite their introduction in 2016**Hale et al., "Conversational Privacy Bots"**, PriBots failed to attain widespread adoption due to implementation complexities and legal challenges. Nevertheless, in light of the increasing need for user-friendly privacy notifications and control options in Conversational AI (CAI) systems, PriBots demonstrate the potential to complement traditional approaches.  

%To allow for downstream tasks such as question-answering, automatically checking privacy compliance**Kumaraguru et al., "Automated Privacy Compliance"** or helping users to browse privacy policies~\footnote{\url{https://explore.usableprivacy.org/}}, an increasing stream of research has focused on the collection and annotation of privacy policies corpora**Hale et al., "PriBots: Conversational Privacy Bots"**. %In particular, the Usable Privacy Policy Project~\footnote{\url{https://usableprivacy.org/}} has significantly contributed to overcoming limitations of current privacy policies. 
%Therefore, numerous datasets of privacy policies were collected and annotated to allow for the development of question-answering methods**Zimmeck et al., "Policy Q\&A Corpus"**. 
%Other studies have focused on the collection of specific corpora to allow for the development of question-answering methods**Mallinson et al., "Policy Q\&A Corpus"**. 
%One privacy Q\&A dataset was collected by crawling user questions and companies' replies from Twitter**Khaledi et al., "Twitter-based Privacy Q\&A Dataset"**. In addition, the Policy Q\&A corpus consists of questions on website privacy policy and was curated from the OPP-115 corpus**Hale et al., "Policy Q\&A Corpus"** while the Privacy Q\&A corpus consists of 1750 questions on privacy policies of mobile applications that were collected from crowdworkers**Zimmeck et al., "Privacy Q\&A Corpus"**. It is worth noting that only the Privacy Q\&A corpus relied on legal experts to identify relevant excerpts in the privacy policy for constructing answers. 

%NLP approaches are their divergence from optimal conversation design practices**Hale et al., "Challenges of Pre-Trained Language Models"**. These responses can be lengthy due to the nature of privacy policies, violating the conversation design principle of minimization**Zimmeck, "Conversation Design Principles"**. Furthermore, they can incorporate technical and legal terms that are difficult for users to understand and require additional repair and rephrasing techniques**Hale et al., "Privacy Policy Content"**. Therefore, the expertise of conversational designers is essential for crafting privacy answers and identifying violations of design principles**Zimmeck, "Conversation Design Principles"**. At the same time, although it is yet unclear whether privacy answers should be considered legally binding**Article 29 Data Protection Working Party, "Guidelines on Legally Binding Responses"**, it has to be ensured that they best capture the essential notice of a privacy policy. Therefore, legal experts play a crucial role in safeguarding the legality of privacy answers. 


%Despite the efforts in collecting privacy policy corpora, data for privacy Q\&A for CAI is scarce. This is due to the fact that prior corpora have exclusively concentrated on privacy policies on websites or mobile applications. While models trained on existing corpora could be adapted to the Conversational AI context, questions and answers on voice recordings and text transcripts are only rarely covered. Moreover, previous research has relied on the original privacy policy texts as ground truth for training regardless of the known readability and understandability issues of legal texts**Hale et al., "Privacy Policy Content"**. Therefore, there is a need to construct and evaluate user-friendly benchmarks that account for known issues with peoples' comprehension of privacy policies.