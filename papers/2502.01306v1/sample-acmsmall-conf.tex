%%
%% This is file `sample-acmsmall-conf.tex',
%% generated with the docstrip utility.
%%
%% The original source files were:
%%
%% samples.dtx  (with options: `all,proceedings,bibtex,acmsmall-conf')
%% 
%% IMPORTANT NOTICE:
%% 
%% For the copyright see the source file.
%% 
%% Any modified versions of this file must be renamed
%% with new filenames distinct from sample-acmsmall-conf.tex.
%% 
%% For distribution of the original source see the terms
%% for copying and modification in the file samples.dtx.
%% 
%% This generated file may be distributed as long as the
%% original source files, as listed above, are part of the
%% same distribution. (The sources need not necessarily be
%% in the same archive or directory.)
%%
%%
%% Commands for TeXCount
%TC:macro \cite [option:text,text]
%TC:macro \citep [option:text,text]
%TC:macro \citet [option:text,text]
%TC:envir table 0 1
%TC:envir table* 0 1
%TC:envir tabular [ignore] word
%TC:envir displaymath 0 word
%TC:envir math 0 word
%TC:envir comment 0 0
%%
%%
%% The first command in your LaTeX source must be the \documentclass
%% command.
%%
%% For submission and review of your manuscript please change the
%% command to \documentclass[manuscript, screen, review]{acmart}.
%%
%% When submitting camera ready or to TAPS, please change the command
%% to \documentclass[sigconf]{acmart} or whichever template is required
%% for your publication.
%%
%%
\documentclass[manuscript]{acmart}

\usepackage{multirow}
\usepackage{graphicx}
\usepackage{subcaption}
\usepackage{tikz}
\usetikzlibrary{automata,positioning}
\usetikzlibrary{shapes.geometric, arrows}
\usetikzlibrary{calc}
\usetikzlibrary{fit}
\usepackage{pgfplots}
\usepgfplotslibrary{groupplots}
\usepackage{natbib}
\usepackage[most]{tcolorbox}
\usepackage{xcolor} 
\usepackage{mdframed} % For creating boxed content
\usepackage{float}
\usepackage{lscape}
\usepackage{longtable}
\pgfplotsset{compat=1.18} 

%%
%% \BibTeX command to typeset BibTeX logo in the docs
\AtBeginDocument{%
  \providecommand\BibTeX{{%
    Bib\TeX}}}

%% Rights management information.  This information is sent to you
%% when you complete the rights form.  These commands have SAMPLE
%% values in them; it is your responsibility as an author to replace
%% the commands and values with those provided to you when you
%% complete the rights form.
\setcopyright{acmlicensed}
\copyrightyear{2018}
\acmYear{2018}
\acmDOI{XXXXXXX.XXXXXXX}

%% These commands are for a PROCEEDINGS abstract or paper.
\acmConference[Conference acronym 'XX]{Make sure to enter the correct
  conference title from your rights confirmation emai}{June 03--05,
  2018}{Woodstock, NY}
%%
%%  Uncomment \acmBooktitle if the title of the proceedings is different
%%  from ``Proceedings of ...''!
%%
%%\acmBooktitle{Woodstock '18: ACM Symposium on Neural Gaze Detection,
%%  June 03--05, 2018, Woodstock, NY}
\acmISBN{978-1-4503-XXXX-X/18/06}


%%
%% Submission ID.
%% Use this when submitting an article to a sponsored event. You'll
%% receive a unique submission ID from the organizers
%% of the event, and this ID should be used as the parameter to this command.
%%\acmSubmissionID{123-A56-BU3}

%%
%% For managing citations, it is recommended to use bibliography
%% files in BibTeX format.
%%
%% You can then either use BibTeX with the ACM-Reference-Format style,
%% or BibLaTeX with the acmnumeric or acmauthoryear sytles, that include
%% support for advanced citation of software artefact from the
%% biblatex-software package, also separately available on CTAN.
%%
%% Look at the sample-*-biblatex.tex files for templates showcasing
%% the biblatex styles.
%%

%%
%% The majority of ACM publications use numbered citations and
%% references.  The command \citestyle{authoryear} switches to the
%% "author year" style.
%%
%% If you are preparing content for an event
%% sponsored by ACM SIGGRAPH, you must use the "author year" style of
%% citations and references.
%% Uncommenting
%% the next command will enable that style.
%%\citestyle{acmauthoryear}


%%
%% end of the preamble, start of the body of the document source.
\begin{document}

%%
%% The "title" command has an optional parameter,
%% allowing the author to define a "short title" to be used in page headers.
\title{Expert-Generated Privacy Q\&A Dataset for Conversational AI and User Study Insights}

%%
%% The "author" command and its associated commands are used to define
%% the authors and their affiliations.
%% Of note is the shared affiliation of the first two authors, and the
%% "authornote" and "authornotemark" commands
%% used to denote shared contribution to the research.
\author{Anna Leschanowsky}
\email{anna.leschanowsky@iis.fraunhofer.de}

\author{Farnaz Salamatjoo}
\email{farnaz.salamatjoo@iis.fraunhofer.de}

\author{Zahra Kolagar}
\authornote{Now with Aleph Alpha}
\email{zarah.kolagar@iis.fraunhofer.de}

\author{Birgit Popp}
\email{birgit.popp@iis.fraunhofer.de}

\affiliation{%
  \institution{Fraunhofer Institute for Integrated Circuits IIS}
  \city{Erlangen}
  \country{Germany}
}


%%
%% By default, the full list of authors will be used in the page
%% headers. Often, this list is too long, and will overlap
%% other information printed in the page headers. This command allows
%% the author to define a more concise list
%% of authors' names for this purpose.
\renewcommand{\shortauthors}{Leschanowsky et al.}

%%
%% The abstract is a short summary of the work to be presented in the
%% article.
\begin{abstract}
Conversational assistants process personal data and must comply with data protection regulations that require providers to be transparent with users about how their data is handled. Transparency, in a legal sense, demands preciseness, comprehensibility and accessibility, yet existing solutions fail to meet these requirements. To address this, we introduce a new human-expert-generated dataset for Privacy Question-Answering (Q\&A), developed through an iterative process involving legal professionals and conversational designers~\footnote{We make our dataset available through this link \url{https://github.com/audiolabs/Expert-Generated-Privacy-QA-Dataset}}. We evaluate this dataset through linguistic analysis and a user study, comparing it to privacy policy excerpts and state-of-the-art responses from Amazon Alexa. Our findings show that the proposed answers improve usability and clarity compared to existing solutions while achieving legal preciseness, thereby enhancing the accessibility of data processing information for Conversational AI and Natural Language Processing applications.
\end{abstract}

%%
%% The code below is generated by the tool at http://dl.acm.org/ccs.cfm.
%% Please copy and paste the code instead of the example below.
%%
\begin{CCSXML}
<ccs2012>
 <concept>
  <concept_id>00000000.0000000.0000000</concept_id>
  <concept_desc>Do Not Use This Code, Generate the Correct Terms for Your Paper</concept_desc>
  <concept_significance>500</concept_significance>
 </concept>
 <concept>
  <concept_id>00000000.00000000.00000000</concept_id>
  <concept_desc>Do Not Use This Code, Generate the Correct Terms for Your Paper</concept_desc>
  <concept_significance>300</concept_significance>
 </concept>
 <concept>
  <concept_id>00000000.00000000.00000000</concept_id>
  <concept_desc>Do Not Use This Code, Generate the Correct Terms for Your Paper</concept_desc>
  <concept_significance>100</concept_significance>
 </concept>
 <concept>
  <concept_id>00000000.00000000.00000000</concept_id>
  <concept_desc>Do Not Use This Code, Generate the Correct Terms for Your Paper</concept_desc>
  <concept_significance>100</concept_significance>
 </concept>
</ccs2012>
\end{CCSXML}

\ccsdesc[500]{Do Not Use This Code~Generate the Correct Terms for Your Paper}
\ccsdesc[300]{Do Not Use This Code~Generate the Correct Terms for Your Paper}
\ccsdesc{Do Not Use This Code~Generate the Correct Terms for Your Paper}
\ccsdesc[100]{Do Not Use This Code~Generate the Correct Terms for Your Paper}

%%
%% Keywords. The author(s) should pick words that accurately describe
%% the work being presented. Separate the keywords with commas.
\keywords{Privacy QA, Transparency, Privacy Policies, Conversational AI}
%% A "teaser" image appears between the author and affiliation
%% information and the body of the document, and typically spans the
%% page.
\begin{teaserfigure}
  \includegraphics[width=\textwidth]{CollectionOverview2.pdf}
  \caption{Overview of the data collection process in the study and a privacy question-answering example.}
  \Description{}
  \label{fig:CollectionOverview}
\end{teaserfigure}

\received{20 January 2025}
% \received[revised]{12 March 2009}
% \received[accepted]{5 June 2009}

%%
%% This command processes the author and affiliation and title
%% information and builds the first part of the formatted document.
\maketitle

\section{Introduction}

As Conversational AI (CAI) systems collect, process and store personal data, users need to be informed about how their data is handled. Privacy policies aim to ensure transparency and regulatory compliance (e.g, General Data Protection Regulation (GDPR) in the EU~\cite{european_commission_regulation_2016} or ``Notice and Choice" principle in the US~\cite{ProtectingConsumerPrivacy2012}). However, they are often unread and ineffective for promoting transparency~\cite{mcdonaldCostReadingPrivacy2009, cateLimitsNoticeChoice2010,cranorNecessaryNotSufficient2012,schaubDesignSpaceEffective2018}. Alternatives like privacy labels improve accessibility but lack the detail of natural language policies~\cite{barthUnderstandingOnlinePrivacy2022a, kelley2009nutrition, emami2021informative, reinhardt2021visual}, while machine-readable policies enhance auditability~\cite{morelSoKThreeFacets2020a} but fail to inform users appropriately. Transparency challenges are especially significant for voice-based CAI, as they often lack graphical interfaces. Even simplified textual formats like Amazon Alexa's Privacy FAQ, require users to switch modalities, resulting in limited accessibility~\cite{gautamAlexaWeTrust2022}. Privacy question-answering (Q\&A) could enhance transparency and accessibility in CAI systems by enabling them to respond to privacy-related user questions in natural language (see Figure~\ref{fig:CollectionOverview} for an example).  %and add to the need for multi-faceted privacy policies~\cite{morelSoKThreeFacets2020a}. 
Previous research has curated privacy Q\&A corpora based on policy excerpts~\cite{ahmadPolicyQAReadingComprehension2020a, ravichanderQuestionAnsweringPrivacy2019}, but these excerpts remain difficult for non-experts to understand~\cite{ravichanderBreakingWallsText2021}. In addition, questions in these corpora only rarely cover data types relevant to voice-based CAI, such as voice recordings. 

Our research aims to advance privacy Q\&A for CAI by (1) collecting privacy questions for CAI via a scenario-driven survey (Section~\ref{sec:PrivacyQuestions}), (2) analysing the current state-of-the-art by evaluating Amazon Alexa's responses and policy excerpts (Section~\ref{sec:ALexaAnswers} and~\ref{sec:PrivacyPolicyExperts}), (3) developing user-friendly and legally valid answers through collaboration with legal experts and conversational designers (Section~\ref{sec:DesignedAnswers}), and (4) evaluating the three answer types -- Alexa answers, policy excerpts, and our designed answers -- through linguistic analysis and a user study (Section~\ref{sec:LinguisticAnalysis} and~\ref{sec:QualitativeAnalysis}).


\section{Related Work}

Conversational Privacy Bots (PriBots) address the growing need for accessible privacy notices by allowing users to pose privacy-related questions in natural language~\cite{harkousPriBotsConversationalPrivacy, grunewald2023enabling}. %Yet, PriBots have seen limited adoption due to implementation complexities and legal challenges. 
So far, efforts to support privacy Q\&A have focused on collecting and annotating privacy policy corpora and applying neural networks to extract answers from privacy policies~\cite{wilsonCreationAnalysisWebsite2016, ravichanderQuestionAnsweringPrivacy2019, ahmadPolicyQAReadingComprehension2020a, aroraTaleTwoRegulatory, sathyendraHelpingUsersUnderstanda}. Notable corpora include the OPP-115 Corpus of website privacy policies~\cite{wilsonCreationAnalysisWebsite2016}, the APP-350 Corpus of annotated Android app policies~\cite{zimmeck2019maps} and a bilingual corpus of mobile app policies~\cite{aroraTaleTwoRegulatory}. Other work has focused on collecting privacy Q\&A specific corpora, e.g., the Policy Q\&A corpus~\cite{ahmadPolicyQAReadingComprehension2020a} and the Privacy Q\&A corpus which uses excerpt-based answers identified by legal experts~\cite{ravichanderQuestionAnsweringPrivacy2019}. Despite these efforts, no privacy Q\&A corpus exists for CAI systems. While existing corpora could be adapted, they rarely cover questions and answers specific to CAI systems, e.g., on voice recordings or text transcripts.
Moreover, pre-trained language models used to directly extract answers from privacy policies were found largely unsuitable and face challenges with responding to unanswerable questions~\cite{ravichanderQuestionAnsweringPrivacy2019, ahmadPolicyQAReadingComprehension2020a, ravichanderBreakingWallsText2021}. Thereby, NLP approaches can produce overly technical and lengthy responses that conflict with conversation design principles such as minimization and user-friendly language~\cite{MooreNCF}. At the same time, responses must accurately reflect the essential content of a privacy policy~\cite{harkousPriBotsConversationalPrivacy}. This urges the need for collaboration between conversational designers and legal experts to ensure answers are both comprehensible and legally precise. This is particularly important, given that both comprehensibility and preciseness are aspects of the principle of transparency~\cite{Article29WP2018}, a legal requirement of the GDPR and global data protection regulations~\cite{gunst2021brusselseffect, ProtectingConsumerPrivacy2012}. 

%We address these gaps by creating a privacy Q\&A dataset specific to CAI systems. Our dataset includes answers validated by legal experts and conversational designers to emphasize comprehensibility and legal preciseness. 

%To meet the growing need for accessible privacy notices, researchers introduced Conversational Privacy Bots (PriBots)~\cite{harkousPriBotsConversationalPrivacy}. PriBots enable users to pose questions about privacy policies and establish preferences through natural language interactions. They can function as standalone tools or be employed alongside a privacy policy, thus allowing users to seek further information. PriBots are based on a retrieval module and a knowledge base containing not only the privacy policy but also other relevant resources. Thereby, the policy can be presented in an unstructured form, using natural language processing (NLP) techniques to extract the relevant parts to the answer, or in a structured and annotated format. Despite their introduction in 2016, PriBots failed to attain widespread adoption due to implementation complexities and legal challenges. Nevertheless, in light of the increasing need for user-friendly privacy notifications and control options in Conversational AI (CAI) systems, PriBots demonstrate the potential to complement traditional approaches.  

%To allow for downstream tasks such as question-answering, automatically checking privacy compliance~\cite{zimmeck2019maps} or helping users to browse privacy policies~\footnote{\url{https://explore.usableprivacy.org/}}, an increasing stream of research has focused on the collection and annotation of privacy policies corpora~\cite{wilsonCreationAnalysisWebsite2016, ravichanderQuestionAnsweringPrivacy2019, ahmadPolicyQAReadingComprehension2020a, aroraTaleTwoRegulatory}. %In particular, the Usable Privacy Policy Project~\footnote{\url{https://usableprivacy.org/}} has significantly contributed to overcoming limitations of current privacy policies. 
%Therefore, numerous datasets of privacy policies were collected and annotated to allow for the development of question-answering methods~\cite{ravichanderQuestionAnsweringPrivacy2019, wilsonCreationAnalysisWebsite2016}. 
%Other studies have focused on the collection of specific corpora to allow for the development of question-answering methods~\cite{harkousPolisisAutomatedAnalysis, ahmadPolicyQAReadingComprehension2020a, ravichanderQuestionAnsweringPrivacy2019}. 
%One privacy Q\&A dataset was collected by crawling user questions and companies' replies from Twitter~\cite{harkousPolisisAutomatedAnalysis}. In addition, the Policy Q\&A corpus consists of questions on website privacy policy and was curated from the OPP-115 corpus~\cite{ahmadPolicyQAReadingComprehension2020a} while the Privacy Q\&A corpus consists of 1750 questions on privacy policies of mobile applications that were collected from crowdworkers~\cite{ravichanderQuestionAnsweringPrivacy2019}. It is worth noting that only the Privacy Q\&A corpus relied on legal experts to identify relevant excerpts in the privacy policy for constructing answers. 

%NLP approaches are their divergence from optimal conversation design practices~\cite{harkousPolisisAutomatedAnalysis}. These responses can be lengthy due to the nature of privacy policies, violating the conversation design principle of minimization~\cite{MooreNCF}. Furthermore, they can incorporate technical and legal terms that are difficult for users to understand and require additional repair and rephrasing techniques~\cite{MooreNCF}. Therefore, the expertise of conversational designers is essential for crafting privacy answers and identifying violations of design principles~\cite{MooreNCF}. At the same time, although it is yet unclear whether privacy answers should be considered legally binding~\cite{harkousPriBotsConversationalPrivacy}, it has to be ensured that they best capture the essential notice of a privacy policy. Therefore, legal experts play a crucial role in safeguarding the legality of privacy answers. 


%Despite the efforts in collecting privacy policy corpora, data for privacy Q\&A for CAI is scarce. This is due to the fact that prior corpora have exclusively concentrated on privacy policies on websites or mobile applications. While models trained on existing corpora could be adapted to the Conversational AI context, questions and answers on voice recordings and text transcripts are only rarely covered. Moreover, previous research has relied on the original privacy policy texts as ground truth for training regardless of the known readability and understandability issues of legal texts~\cite{ravichanderBreakingWallsText2021}. Therefore, there is a need to construct and evaluate user-friendly benchmarks that account for known issues with peoples' comprehension of privacy policies. 

\section{Privacy Q\&A Dataset}

Figure~\ref{fig:CollectionOverview} shows our data collection process. We first collect 400 privacy questions and narrow them down to 42 most representative ones (Section~\ref{sec:PrivacyQuestions}). We then construct three types of answers -- Amazon Alexa responses, privacy policy excerpts and human-expert-generated answers (Section~\ref{sec:privacyanswers}).

%\begin{figure}
%\begin{tikzpicture}[
%    box/.style={
%    rectangle, 
%    rounded corners, 
%    minimum width=2cm, 
%    minimum height=1cm,
%    text centered, draw=black,
%    }
%]
%    \node (boxQuestions) [box] {\shortstack{Scenario-Driven Survey \\ n=264}};
%    \node (boxQuestions2) [box, right=of boxQuestions, xshift=-0.5cm] %{\shortstack{Privacy \& Policy Q\&A \\ n=136}};
%    \node(TotalQuestions)[box, below=of boxQuestions.south east, xshift=0.25cm, yshift=0.5cm] {\shortstack{Total Question Collection \\ n=400}};
%    \node (FinalQuestions) [box, below=of TotalQuestions, yshift=0.5cm] {\shortstack{Final Question Collection \\ n=42}};
%    \node (PolicyExcerpts) [box, below=of FinalQuestions, yshift=0.5cm] {\shortstack{Privacy Policy Excerpts\\ n=42}};
%    \node (AlexaAnswer) [box, left=of PolicyExcerpts] {\shortstack{Alexa Answers\\ n=42}};
%    \node (InitialDesignedAnswer) [box, right=of PolicyExcerpts] {\shortstack{Initial Set of Privacy Answers \\ n=89}};
%    \node (PrivacyExpert) [box, below=of InitialDesignedAnswer, yshift=0.5cm] {\shortstack{Privacy Expert Revision \\ n=82}};       
%    \node (ConversationalDesigners) [box, below=of PrivacyExpert, yshift=0.5cm] {\shortstack{Conversational Designer Revision \\ n=111}};
%    \node (LegalExpert) [box, below=of ConversationalDesigners, yshift=0.5cm] {\shortstack{Legal Expert Revision \\ n=103}};
%    \node (DesignedAnswers) [box, below=of LegalExpert, yshift=0.5cm] {\shortstack{Total Set of Designed Answers \\ n=84}};
%
%    \draw [-stealth] (boxQuestions.south) -- (TotalQuestions.north);
%    \draw [-stealth] (boxQuestions2.south) -- (TotalQuestions.north);
%    \draw [-stealth] (TotalQuestions.south) -- (FinalQuestions.north);
%    \draw [-stealth] (TotalQuestions.south) -- (FinalQuestions.north);
%    \draw [-stealth] (FinalQuestions.south) -- (PolicyExcerpts.north);
%    \draw [-stealth] (FinalQuestions.south) -- (InitialDesignedAnswer.north);
%    \draw [-stealth] (FinalQuestions.south) -- (AlexaAnswer.north);
%    \draw [-stealth] (InitialDesignedAnswer.south) -- (PrivacyExpert.north);
%    \draw [-stealth] (PrivacyExpert.south) -- (ConversationalDesigners.north);
%    \draw [-stealth] (ConversationalDesigners.south) -- (LegalExpert.north);
%    \draw [-stealth] (LegalExpert.south) -- (DesignedAnswers.north);
%\end{tikzpicture}
%\caption{Overview of the data collection process.}
%\label{fig:CollectionOverview}
%\end{figure}

\subsection{Privacy Questions} 
\label{sec:PrivacyQuestions}

We conducted a scenario-driven survey to collect an initial set of privacy questions (see Appendix~\ref{sec:scenariodriven} for an outline of the survey). Participants were presented with a hypothetical scenario of a privacy breach and asked to generate questions to understand what the CAI system knew about them. Unlike previous privacy Q\&A corpora, which often contain generalized questions about ``data", we aimed to collect questions on nine information types -- commonly collected by smart assistants -- to account for varying degrees of information sensitivity, e.g., voice recordings, contact information and location (see Appendix Table~\ref{tab:datatype} for details)~\cite{smartassistantdatacollection, schomakersInternetUsersPerceptions2019}. In total, we collected 264 questions from 11 internally recruited participants and categorized them into six data practices categories (see Appendix Table~\ref{tab:datapractice} for details) using existing privacy Q\&A annotation schemes~\cite{wilsonCreationAnalysisWebsite2016, aroraTaleTwoRegulatory}. People were not compensated for participation and we did not collect any demographic data. To account for the small sample size and broaden the scope of questions, two of the authors added questions from Privacy Q\&A and Policy Q\&A corpora, resulting in a dataset of 400 questions covering nine information types and six data practice categories~\cite{ahmadPolicyQAReadingComprehension2020a, ravichanderQuestionAnsweringPrivacy2019}.
%In particular, two of the authors agreed on adding multiple questions on the topic of ``location", ``contacts", and ``voice recording" data from the corpora to our collection. As a result, our final question dataset consisted of 400 questions covering nine information types and six data practice categories. 

To generate answers to these questions that are both legally precise and comprehensible, we pursued
an iterative experts-in-the-loop process and recruited legal and dialogue design experts~\cite {kolagar2023experts}. As this expert-in-the-loop approach is time-intensive and experts are difficult to recruit, we selected the most representative question per information type and data practice using Semantic Textual Similarity (STS) with Sentence-BERT~\cite{reimers19sentence}. This minimized the workload for experts, while at the same time maximizing the diversity of the resulting Q\&A dataset. We further excluded questions that could not be sufficiently answered, given the available privacy policy, resulting in 42 final questions relatively equally distributed across data practices and with a stronger focus on voice recordings (see Appendix Table~\ref{tab:datapractice} and~\ref{tab:datatype}). 

%We applied an iterative process including legal experts and voice designers to construct answers to these questions that aim to be more user-friendly and legally valid than simple privacy policy excerpts. Yet, due to this time and labor-intensive approach, we restricted the number of questions by choosing those that best encapsulated the essence of each information type and data practice. To select the most representative answer per information type and data practice, we computed Semantic Textual Similarity (STS) using Sentence-BERT~\cite{reimers19sentence} and manually cross-checked the results of the sentence transformer. While we originally selected one representative question for each information type and data practice, we found some questions to be unanswerable given the available resources (e.g., What do you actually know about me?). While unanswerability is a crucial aspect of privacy questions and has been discussed in more detail in previous studies~\cite{ravichanderQuestionAnsweringPrivacy2019}, our work aims to compare the helpfulness of different types of privacy answers. It is therefore necessary that questions can be sufficiently answered given the available resources such as the privacy policy. This is why, we excluded unanswerable questions from the final collection. Ultimately, our final dataset totaled 42 questions relatively equally distributed across data practices (as shown in Table~\ref{tab:datapractice}) and with a stronger focus on privacy questions related to voice recordings (as shown in Table~\ref{tab:datatype}) as expected for a Conversational assistant specific collection. 

\subsection{Privacy Answers} 
\label{sec:privacyanswers}

Unlike previous research that focused on extracting policy excerpts, we aim to create human-expert-generated user-friendly and legally precise answers to privacy questions. For evaluation, we collect three different types of answers: (1) Amazon Alexa responses (Section~\ref{sec:ALexaAnswers}), (2) excerpts from Amazon's privacy policy and related sources (Section~\ref{sec:PrivacyPolicyExperts}), and (3)  answers created by conversational designers and legal experts (Section~\ref{sec:DesignedAnswers}). 

\subsubsection{Privacy Answers by Amazon Alexa} 
\label{sec:ALexaAnswers}

To evaluate the privacy question-answering capabilities of CAI, we queried Amazon Alexa using the Amazon Alexa App\footnote{Alexa Answers in the dataset were collected in January 2023. To ensure the validity of the answers, we re-evaluated answers in January 2025 and observed no drastic changes in responses.}. We prompted the system to repeat what it heard after posing each question to ensure correct speech recognition and asked questions multiple times to account for variabilities in response behaviour. Despite multiple trials with different people and voices, no response was obtained for five out of 42 questions. We denote these cases with ``No answer" in the dataset (see Appendix~\ref{sec:CategorizationAlexa} for a detailed overview). Most privacy questions could not be answered and relied instead on fallbacks like general excuses or redirection to the help section. Only four questions were ``correctly'' answered by providing control options or privacy information. Notably, questions on voice recordings could be answered, possibly due to public outcry and media coverage on the topic over the last years~\cite{alexaoutcry}. 

\subsubsection{Privacy Policy Excerpts} 
\label{sec:PrivacyPolicyExperts}

In line with previous studies that had legal experts extract answers from privacy policies~\cite{ravichanderQuestionAnsweringPrivacy2019}, we extracted excerpts from the latest Amazon Europe privacy policy~\cite{AmazonAlexaPrivacy} and additional resources like the Alexa and Alexa Device FAQs\footnote{\url{https://www.amazon.com/-/de/gp/help/customer/display.html?nodeId=201602230}} and Alexa Features Help\footnote{\url{https://www.amazon.com/-/de/gp/help/customer/display.html?ref_=hp_bc_nav&nodeId=G201952240}}. These FAQs and help pages were particularly helpful for answering user choice and control related questions. While we explored advanced tools for privacy policy excerpt extraction, we decided on a manual approach. First, tools for extraction like ``PriBot''~\cite{harkousPriBotsConversationalPrivacy} or the machine-annotated privacy policies provided by the Usable Privacy Policy Project\footnote{\url{https://explore.usableprivacy.org/}} were either unavailable to the authors at the time of the study or used outdated privacy policies exclusively applicable to the US. Given our focus on the European privacy policy following the enforcement of GDPR, these tools did not meet our needs. Second, the use of Large Language Models (LLMs), e.g., OpenAI's GPT-4 model, with template prompting, was ineffective as the model produced untruthful and unusable excerpts, relying more on general knowledge than the provided documents.

%Initially, our objective was to expand upon prior research by exploring readily available tools for privacy policy extraction. Although PriBot~\cite{harkousPriBotsConversationalPrivacy} has been successfully implemented and allowed for extracting excerpts from various websites, it was unavailable to the authors during the time of the study. Moreover, we explored machine-annotated privacy policies provided by the Usable Privacy Policy Project~\footnote{\url{https://explore.usableprivacy.org/}}. However, we found that the annotated version of the Amazon privacy policy dates back to 2017 and exclusively encompasses the version applicable to the US. Given our focus on the contemporary European iteration of the privacy policy following the enforcement of GDPR, this resource did not align with our requirements.

%In a second approach, we explored the capabilities of LLMs using a simple template prompting technique to extract relevant parts of the privacy policy. With the rise of large language models (LLMs) influencing numerous domains, it's conceivable that their capabilities could extend to addressing users' privacy-related queries. We adopted a straightforward prompt template, as visually depicted in the appendix~\ref{app:prompt_template}, to generate answers drawing from the latest Amazon Europe privacy policy~\cite{AmazonAlexaPrivacy} and the FAQs. We engaged OpenAI's GPT-4 model, utilizing its capacity of 8000 tokens, and initiated an API request. We employed a temperature setting of zero to ensure minimal deviations in the model's responses to questions, all in accordance with Amazon's privacy documents. However, the responses highlighted certain constraints inherent to LLMs. Our observations unveiled a notable tendency of the model to rely on general knowledge, even though its prompt was specifically designed to draw solely from the provided documents in answering user queries. This phenomenon, often referred to as 'hallucination,' exemplifies one of the limitations prevalent in LLMs and underscores the complexity of leveraging LLMs for privacy question-answering.

%Finally, we relied on a manual approach to extract privacy policy excerpts. Therefore, two of the researchers independently extracted relevant sections from the privacy policy to craft answers to the question's catalog. Following the individual extraction process, they agreed on the finalized excerpt collection in a discussion section. We meticulously retained the exact wording employed within these aforementioned documents. Our approach focused on maintaining the integrity of the original language, thereby guaranteeing that the responses we generated for each question seamlessly mirrored the established privacy discourse articulated in Amazon's official documentation. 

%We also collected privacy excerpts related to each topic, theme, and question from Amazon Privacy Notice (\cite{AmazonAlexaPrivacy}), FAQs, and Amazon Alexa Privacy White Paper (\cite{Amazonwhitepaper}). This meticulous examination aimed to extract content that was not only aligned but fully relevant to the respective questions posed. 

%Various platforms and AI-driven systems may likely leverage LLMs to provide users with answers to their inquiries concerning privacy matters. In a bid to explore and harness these capabilities more comprehensively, we turned to the power of LLMs using a simple template prompting technique.
%These limitations necessitate attention, particularly in scenarios where privacy considerations intersect with legal implications, and where safeguarding user data and well-being is paramount.
%This phenomenon, often referred to as 'hallucination,' exemplifies one of the limitations prevalent in LLMs.
%This insight underscores the complexity of leveraging LLMs in privacy-centric contexts, highlighting the importance of addressing shortcomings and refining methodologies when legal and ethical dimensions are at stake. 

\subsubsection{Privacy Answers Designed by Experts}
\label{sec:DesignedAnswers}

To create comprehensible and legally precise answers, we used an iterative process with legal experts and conversational designers as shown in Figure~\ref{fig:CollectionOverview}~\cite{kolagar2023experts}. Drawing from the previously extracted privacy excerpts (see Section~\ref{sec:PrivacyPolicyExperts}), two researchers independently curated an initial set of privacy answers with two or more answers per question. We explicitly derived the answers from the extracted excerpts to ensure coherence and consistency across answer types. First, we consulted with a trained privacy technologist (CIPT~\footnote{IAPP Certified Information Privacy Technologist (\url{https://iapp.org/certify/cipt/})}) to ensure that responses were privacy-preserving and omitted those that did not satisfy the requirements. Following this, three conversational designers revised the answers focusing on their comprehensibility, conversational flow, and user-friendliness. The experts had diverse backgrounds in conversation design, voice user interface design and linguistics with professional experience ranging from one to five years. Finally, to ensure legal validity, we revised answers based on a legal expert's feedback specializing in data protection and IT law with more than 5 years of experience. Each question was answered in more than one way resulting in one-to-many mapping for each question. This makes sense, as privacy questions can be answered validly by multiple responses, maintaining both legal preciseness and comprehensibility. Given the final set of 103 designed answers -- a set too large to be evaluated in the user study -- we again leveraged STS~\cite{reimers19sentence} to choose the two most distinct answers per question, i.e., ``Designed Answer 1'' and ``Designed Answer 2''.

%In carrying out this study, a primary aim was to create privacy answers that are both user-friendly and legally sound. A common challenge with answers based on NLP approaches are their divergence from optimal conversation design practices~\cite{harkousPolisisAutomatedAnalysis}. These responses can be lengthy due to the nature of privacy policies, violating the conversation design principle of minimization~\cite{MooreNCF}. Furthermore, they can incorporate technical and legal terms that are difficult for users to understand and require additional repair and rephrasing techniques~\cite{MooreNCF}. Therefore, the expertise of conversational designers is essential for crafting privacy answers and identifying violations of design principles~\cite{MooreNCF}. At the same time, although it is yet unclear whether privacy answers should be considered legally binding~\cite{harkousPriBotsConversationalPrivacy}, it has to be ensured that they best capture the essential notice of a privacy policy. Therefore, legal experts play a crucial role in safeguarding the legality of privacy answers. 

\section{Linguistic Analysis of Privacy Answers}
\label{sec:LinguisticAnalysis}

To understand how answers differed objectively, we conducted a linguistic analysis focusing on readability and lexical diversity, characteristics that have been used before to evaluate privacy policies (see Table~\ref{tab:linguisticanswers} for details)~\cite{milne2006longitudinal, cadogan2004imbalance, hamid2023privacylens}. 

\begin{table}[!ht]
    \centering
    \begin{tabular}{lcccc}
        \toprule
        Linguistic Metrics & Alexa Answers & Excerpts & Designed Answers 1 & Designed Answers 2 \\
        \midrule
        \multicolumn{5}{l}{Readability}  \\
        \midrule
        Flesch-Kincaid Grade Level & 3.5 & 11.3 & 8.4 & 8.0 \\
        Flesch Reading Ease & 87.2 & 47.6 & 62.6 & 66.32 \\
%        Dale Chall Readability & 7.9 & 8.9 & 9.7 & 9.1 \\
%        Automated Readability Index & 4.3 & 13.3 & 10.1 & 9.5 \\
%        Coleman Liau Index & 5.6 & 11.6 & 9.9 & 10.0 \\
%        Gunning Fog & 5.4 & 11.45 & 10.0 & 9.63 \\
        Linsear Write Index & 5.0 & 12.75 & 10.4 & 8.4 \\
        \midrule 
        \multicolumn{5}{l}{Lexical Diversity} \\
        \midrule 
        Unique Word Count & 10.0 & 46.5 & 22.0 & 23.5 \\
        Type-Token-Ratio & 1.0 & 0.67 & 0.82 & 0.81 \\
        Measure of Textual Lexical Diversity & 16.0 & 56.75 & 45.17 & 37.99 \\
        \bottomrule
    \end{tabular}
    \caption{We show the median results for the linguistic metrics for each answer type.}
    \label{tab:linguisticanswers}
\end{table}


\noindent\textbf{Readability} Our readability analysis using the Flesch-Kincaid grade level and Flesch reading ease~\cite{flesch1949art} shows that Alexa answers score lowest in readability while excerpts score highest, requiring a grade of 11 on the Flesch-Kincaid scale. However, the low score for Alexa answers is primarily due to brief responses, e.g., ``Sorry, I don't know that.''. Although small differences exist between both sets of designed answers, they are more readable than the excerpts, making them easier for people to understand. Further, we calculated the Linsear Write Readability Index, originally developed to improve government writing~\cite{o1966gobbledygook}. Importantly, the index calculation differs from the Flesch-Kincaid measures as it considers both sentence length and the number of words with three or more syllables. Again, Alexa answers are the easiest while the excerpts contain more difficult words. However, the index also shows a difference between the two designed answer categories, indicating that the first set uses longer words compared to the second set. Despite the iterative process, expert-created answers show some degree of variability if assessed objectively.

\noindent\textbf{Lexical Diversity} As a proxy for technical and legal jargon which contributes to unique and low-frequency words, we compute lexical diversity as a measure of how many different words are used in a text. While low-frequency words can be crucial to understanding privacy policy texts, they can make comprehension challenging~\cite{hiebertunique}. While we compute several metrics such as Type-Token-Ratio (TTR) and measure of textual lexical diversity (MTLD), we rely on MTLD as our main measure as it was found to be least affected by text length~\cite{zenker2021investigating, koizumi2012effects}. In line with readability scores, we find that Alexa Answers are the least diverse while excerpts are the most. Our designed answers show results in between with the first set showing higher MTLD scores in line with the Linsear Write Readability Index results. 

\section{User Study}
\label{sec:QualitativeAnalysis}

\subsection{Experimental Design}

For subjective human evaluation of generated responses, we adopted a mixed-method approach to capture quantitative and qualitative insights on four evaluation criteria, i.e., answer quality, usability, difficulty and lawyerliness, previously used to assess legal documents~\cite{Martinez2023}. Participants rated answers on how well they met their information needs \textbf{(Answer Quality)}, how much they sounded appropriate in style and tone for legal information \textbf{(Lawyerliness)}, how useful they were given the question \textbf{(Usability)} and how complex and difficult they perceived them \textbf{(Complexity/Difficulty)}.

We conducted semi-structured online interviews and recorded and transcribed videos. Best-Worst Scaling (BWS) was chosen to gather quantitative insights~\cite{Cohen2003MaximumDS, louviere2015best}. In each round, participants were presented with five questions, including information-seeking questions, yes/no questions and statements, and covering different information types, i.e., name, contacts, time zone, calendar, and voice recordings (see Appendix Table~\ref{tab:QuestionAnswerUserStudy} for details on questions and answers). %Four types of answers were provided for each question, i.e., Amazon Alexa answers, privacy policy excerpts, and two designed answers by privacy experts and conversational designers. However, we showed participants tuples of three answers at a time. As illustrated in Table~\ref{tab:datatype}, Alexa's answer types varied across the selected questions, including general information, control and choice, forwarding, excuse, and calendar information. 

Participants completed the study in four rounds, each measuring one specific metric. The study was displayed using Amazon Mechanical Turk Sandbox (see Appendix~\ref{fig:AMTInterface} for the interface). In each round, participants rated five questions, each paired with three of the four answer types -- Alexa answers, policy excerpts, and designed answers 1 and 2. In total, participants rated 20 question-answer trials. We randomized the order of questions, answers, and metrics to avoid choice bias. Participants first performed best-worst scaling and rated answers based on the evaluation criteria, then, they provided explanations for their choices. Finally, they were invited to offer general feedback.

\subsection{Participants and Ethical Considerations}

Participants, two males and two females with an average age of 30, had expertise in linguistics which provided valuable insights into how specific language features can influence comprehension and user experience. People were internally recruited and not compensated for participation. Before the interview, we obtained verbal consent for video recording the interview sessions and ensured that their data remained confidential. 

\subsection{Quantitative Results} Figure~\ref{fig:percentages} shows the percentage of trials where each answer type was rated the best, worst or was not chosen per evaluation criterion. Excerpts were rated as the most difficult to understand, while designed answers 1 and 2 were considered the least difficult in 47\% of cases they were shown to participants. Excerpts were also judged the most lawyerly in 93\% of cases, whereas Alexa answers were perceived as the least lawyerly. For quality and usability metrics, designed answer 2 received the highest ratings, being marked as the best in 53\% of trials for both metrics. In contrast, Alexa answers were rated the lowest, with 73\% of trials identifying them as having the least quality and 87\% as having the least usability.


\begin{figure}[!hbt]
    \centering
    \resizebox{0.8\textwidth}{!}{\input{percentages_interviews.pgf}} 
    \caption{Quantitative results comparing the four answer types across the metrics of quality, difficulty, usability, and lawyerliness.}
    \label{fig:percentages}
\end{figure}


\subsection{Qualitative Analysis}

\subsubsection{Coding Strategy}
We explored participants' perceptions of privacy answers by identifying the recurring themes through inductive coding~\cite{thomas2006inductive}. This process involved creating categories of codes based on user feedback and helped capture both positive and negative feedback for each answer type (see Appendix Table~\ref{tab:1} for the codebook). The extracted codes reflect stylistic aspects including informal style, formal style, and instructional clarity, as well as linguistic aspects like semantic complexity, rich syntactic structure, content comprehensiveness, and keyword significance. 

In addition, the codes offered insights into how participants perceived each metric. Figure~\ref{fig:Frequency of Codes} in the Appendix displays the top three most frequently used codes for each metric. For instance, participants associated low-quality and low-usable responses with irrelevant answers, while high-quality and usable responses were linked with straightforward and comprehensive responses. 

\subsubsection{Qualitative Results} \hfill

\noindent\textbf{Alexa Answers} were frequently perceived as irrelevant and lacking sufficient details. Specifically, P1 stated that \textit{``there is nothing on the calendar for the next 30 days is unrelated [to the question]''} and P3 noted that \textit{``it doesn't provide any information at all''}. However, the simplicity of language, short sentences and simple syntactic structures in these answers were positively received by P1 and P2. 

% Chat box for both User and AI
%\begin{tcolorbox}[colframe=black, colback=white, coltitle=black, boxrule=0.3mm, halign=center, left=1mm, right=1mm, top=1mm, bottom=1mm]
%    \textbf{User:} Can the assistant pull information from my phone's calendar? \\
%    \textbf{Alexa Answer:} There's nothing on the calendar for the next 30 days. \\
%\end{tcolorbox}

\noindent\textbf{Privacy Policy Excerpts} were praised for being comprehensive and giving specific responses. Participants stated that their sentence length contributed to the higher quality and more lawyerly tone. As P3 remarked, \textit{``The reason why this one is the most lawyerly is that it's quite verbose because they are being very explicit and making sure that every detail is written down''.} On the other hand, lengthy instructions and difficult semantics and terminology posed challenges for P1, P3, and P4, because they contributed to the complexity of responses. For instance, P3 highlighted \textit{``It provides like good information but it's too long, too complicated''.}   

% Chat box for both User and AI
%\begin{tcolorbox}[colframe=black, colback=white, coltitle=black, boxrule=0.5mm, %halign=center, left=1mm, right=1mm, top=1mm, bottom=1mm]
%    \textbf{User:} Who can access my voice recordings? \\
%    \textbf{Privacy Policy Excerpt:} Using your browser, you can listen to Alexa recordings in the Review Voice History section of Alexa Privacy Settings (amazon.com/alexaprivacysettings). Using the Alexa app, you can listen to Alexa recordings by going to the menu and selecting Settings > Alexa Privacy > Review Voice History. \\
%\end{tcolorbox}

%\begin{quote}
%user question: Who can access my voice recordings?

%privacy policy excerpt: Using your browser, you can listen to Alexa recordings in the Review Voice History section of Alexa Privacy Settings (amazon.com/alexaprivacysettings). Using the Alexa app, you can listen to Alexa recordings by going to the menu and selecting Settings > Alexa Privacy > Review Voice History.

%\end{quote}

\noindent\textbf{Designed Answer 1} were liked for being straightforward, making the answers more useful. One factor which contributed to their ease of understanding was the use of imperative verbs rather than modal verbs. P1 mentioned their preference, pointing out \textit{``I chose this one because it says do this instead of `you can' with the auxiliary.''}. Imperative constructions decreased sentence complexity and offered direct instructions to the user. In contrast, from a negative perspective, these answers were confusing because they lacked specificity, which diminished their clarity and legal tone. All Participants stated that insufficient information would lead to lower quality and usability of answers. P4 commented \textit{``It's not informing me about anything and is very evasive and vague''.} 

% Chat box for both User and AI
%\begin{tcolorbox}[colframe=black, colback=white, coltitle=black, boxrule=0.5mm, halign=center, left=1mm, right=1mm, top=1mm, bottom=1mm]
%    \textbf{User:} I want to change my name. \\
%    \textbf{Designed Answer 1:} Visit the Alexa profile settings on your Alexa app to edit information on your name. \\
%\end{tcolorbox}

%\begin{quote}
%user question: I want to change my name.

%designed answer one: Visit the Alexa profile settings on your Alexa app to edit information on your name.
%\end{quote}

\noindent\textbf{Designed Answer 2} mostly received positive feedback as they were perceived as straightforward and succinct, giving sufficient details without leading to complexity. According to the participants, this feature added to the usability and lawyerliness of the answers, while also reducing the level of difficulty in comprehension. In particular, keywords in some of the answers were considered helpful by all participants in directing their decision-making process. For example, the answer ``You can give permission to Alexa to add, delete, or update your Calendar events'' highlighted the user's authority to grant or withhold consent. P3 appreciated this characteristic, saying, \textit{``It offers a next step of how you might be able to do it.''} Similarly, P1 remarked \textit{``Because of the word permission, I feel like it gives more insight into that. I gave consent to this in a sense.''}. This highlights the semantic feature of the sentence with the word ``permission'' shaping the user's interpretation. Participants criticized a few of these answers for having long sentences, making them harder to retain and follow. The combination of sentence length and the placement of the answer at the end of the sentence hindered comprehension. P2 found it frustrating, that \textit{``You can obtain the time zone information with my usage of Amazon service, but therefore the answer comes at the end.''} Likewise, P1 complained about the answer length, noting \textit{``It's very lengthy, and I don't want my interaction. If I want Alexa to answer the question of can I do this, I prefer not to receive a very lengthy answer.''} Moreover, technical terms such as ``cloud'' were found not to be intuitive for all users and can potentially add to the complexity of the sentence. 


% Chat box for both User and AI
%\begin{tcolorbox}[colframe=black, colback=white, coltitle=black, boxrule=0.5mm, halign=center, left=1mm, right=1mm, top=1mm, bottom=1mm]
%    \textbf{User:} Can the assistant pull information from my phone's calendar? \\
%    \textbf{Designed Answer 2:} When you link your calendar account, a copy of your calendar is stored in the cloud so you can access it using Alexa. 
%\end{tcolorbox}

%\begin{quote}
%
%designed answer two: When you link your calendar account, a copy of your calendar is stored in the cloud so you can access it using Alexa.
%\end{quote}


%Findings from the quantitative analysis highlighted the difficulty and lawyerliness of the excerpts, which were substantiated in the qualitative analysis. While the quantitative data displayed that excerpts were the most lawyerly, the qualitative results elaborated on the difficulty stemming from lengthy responses and intricate terminologies. On the other hand, designed answers 1 and 2, which were rated as least difficult in the quantitative results, were appreciated for having more directness and clarity in the qualitative analysis. 

\section{Discussion and Future Work}

Our linguistic analysis and subjective evaluation show that answers designed by experts differ from current state-of-the-art (Alexa responses and Privacy Policies) and are perceived more positively. The codes provide a framework for mapping the stylistic and linguistic features of the responses to the subjective understanding of the answers. Designed answers are perceived as higher in overall quality and more usable than alternatives. Privacy excerpts are rated as the most lawyerly, which may reflect the difficulty of understanding them. Designed answers are perceived as more lawyerly than responses given by Alexa, yet less complex and easier to understand. In addition, our analysis provides insights into metric definition and understanding (Figure~\ref{fig:Frequency of Codes}). Answer quality and usability were evaluated similarly and associated with the same stylistic and linguistic aspects, suggesting that future research could focus on only one of the two aspects. Our inductively extracted codes show that participants identified specific characteristics when describing high-quality and usable answers, as well as low-quality and unusable ones. Future work could align these characteristics with objective metrics used to evaluate state-of-the-art NLP applications~\cite{srivastava2024towards}. This could help scale our iterative approach in generating comprehensible, legally precise and accessible answers. 

We believe this dataset and the approach of creating gold-standard answers to privacy questions in an iterative expert-in-the-loop approach is a significant step forward compared to the current state-of-the-art Privacy Q\&A datasets. There are three main reasons for this which align with the legal principle of transparency~\cite{Article29WP2018}, underlying international data protection legislations~\cite{coe108plus2018,ccpa2018,lgpd2018}: (1) Accessibility: ``The `easily accessible' element means that the data subject should not have to seek out the information''~\cite{Article29WP2018}. For conversational technology, the most accessible way to provide information is ``as an answer to a natural language question''~\cite{Article29WP2018}. Note, that extractions of privacy policy excerpts can not generally be considered a conversational response as they often do not represent how people speak and respond in conversations. (2) Comprehensibility: ``clear and plain language must be used''~\cite{Article29WP2018}. This is not typically the case for legal texts -- \citet{Martinez2023} find that even legal professionals judge legal texts to be poorly comprehensible. The current state-of-the-art of extracting legal language from privacy notices perpetuates incomprehensibility of data processing information. (3) Preciseness: ``the data subject [...] should not be taken by surprise [...] about the ways in which their personal data has been used''~\cite{Article29WP2018}. Privacy notices are often written in vague, complex and confusing language to obscure the true extent of data processing and give companies broad discretion in handling personal data~\cite{solove2013privacy}. For the creation of our dataset, we recruited multiple, independent (not associated with Amazon) and multi-disciplinary experts into an iterative exchange with the goal to assure both legal precision as well as comprehensibility. Thus we depart from the -- possibly obfuscated -- privacy policies, enrich and interpret the original privacy policy with the help of independent experts to provide answers as truthfully as possible based on the available information.

\section{Limitations}

We acknowledge several limitations in our study. First, the small participant sample in the question collection -- despite supplementing it with questions from existing privacy Q\&A corpora -- and the user study limits the generalizability of our findings. A qualitative study with a larger and more diverse sample, including naive users, could provide deeper insights into answer quality. Second, comprehensibility needs can vary across user groups. For instance, children may require simpler language while users with higher privacy literacy may benefit more from extended privacy Q\&A systems~\cite{ravichanderBreakingWallsText2021}. Future research could instruct conversational designers to construct answers for specific user groups. Finally, legal experts can interpret policy language differently~\cite{reidenberg2015disagreeable, ravichanderBreakingWallsText2021} and thus, may differ in their views on what constitutes legally precise formulations. Our designed answers are likely to reflect such variations, and different experts might have created alternative privacy answers. 

\section{Conclusion}

Our study presents a first step to more comprehensible, accessible, and legally precise privacy answers in CAI systems. Through our expert-driven process, we designed privacy answers that strike a balance between user-friendliness and legal accuracy, addressing gaps in the comprehensibility of existing privacy notices. Quantitative and qualitative evaluations show that our designed answers improve usability and clarity compared to existing solutions while maintaining a lawyerly tone where appropriate. Our approach aligns with key principles of transparency in the GDPR, and international transparency principles, ensuring that users are not left confused or misinformed about data practices. Future research should explore scaling this iterative expert process, accounting for different user needs and contexts, while continuing to focus on accessibility and legal compliance in privacy Q\&A datasets for CAI systems.

\begin{acks}
We would like to thank the conversational designers and legal experts for their time and valuable contribution to the dataset. 
\end{acks}

%%
%% The next two lines define the bibliography style to be used, and
%% the bibliography file.
\bibliographystyle{ACM-Reference-Format}
\bibliography{sample-base}


%%
%% If your work has an appendix, this is the place to put it.
\appendix

\newpage 
\section{Scenario-Driven Survey for Privacy Question Collection}
\label{sec:scenariodriven}

\begin{figure*}[!h]
\begin{mdframed}[
    linecolor=black,
    linewidth=1pt,
    roundcorner=10pt,
    backgroundcolor=white,
    innerleftmargin=15pt,
    innerrightmargin=15pt,
    innertopmargin=15pt,
    innerbottommargin=15pt,
]
\small
\textbf{My Perfect Voice Assistant} \\
You and your husband have recently bought a voice assistant for your house called Silvia Home. 
Since you have started to use it on a daily basis, you have realized how efficient and advanced the system is, and how all these mundane tasks you had to do before, are now a simple command away!

\vspace{5pt} % Adds space between title and content

\textbf{My Mom and Silvia} \\
Yesterday, your mom was giving you a visit and after you told her about Silvia, she became curious on how the system performs, so she started to use the device in the kitchen to set the timer for when she needs to take the food out of the oven, and since she was home alone, she decided to talk to Silvia about her life...

\vspace{5pt} % Adds space between documents section and user query

A few days later ...

\vspace{5pt}

\textbf{How much does Silvia know about us?} \\
As mothers day was approaching, you thought you could order some flowers and have them delivered to your moms home. When you asked Silvia to order roses for mothers day, it said, ``but your mom doesnt like roses.'' You tried to ignore that comment but got concerned when Silvia said, ``but your mom lives on Westfall Avenue.'' These comments made you uncomfortable and curious. You wondered ``how much does Silvia know about me?''

\vspace{5pt} % Adds space between documents section and user query

\textbf{Task Description} \\
We would like you to imagine that you are Maria who is by now concerned about how much `Silvia', the voice assistant, knows about her and her life. Below, we have provided a set of possible topics you can ask Silvia about.  
Your task is to formulate questions for Silvia to learn how much she knows about you. Please keep each topic in mind while formulating your questions to Silvia. 

\end{mdframed}
\end{figure*}

\section{Data Practice and Information Type Categories Covered by the Collected Questions}

\begin{table}[H]
    \begin{tabular}{p{6cm}|p{3.75cm}|p{3.75cm}}
        \toprule
        Data Practice & Proportion of Total Question Collection (N=400) & Proportion of Final Collection (N=42)\\ 
        \midrule
        First-Party Collection/Use - Information Type & 50\% & 17\%\\
        User Rights and Choice/Control & 18\% & 19\%\\
        Third-Party Collection/Use &  13\% & 21\%\\
        First-Party Collection/Use - Purpose & 8\% & 24\%\\
        Data Security and Retention & 9\% & 14\%\\
        Privacy Policy & 2\% & 5\%\\
        \bottomrule
        \end{tabular}
        \caption{Data practice categories and their proportion in the total question collection and the final question collection for the expert-generated Privacy Q\&A dataset. We emphasize the use of a more balanced question collection for the dataset creation.}
    \label{tab:datapractice}
\end{table}

\begin{table}[H]
      \centering
        \begin{tabular}{l|l|l}
        \toprule
        Information Type & Proportion of Total Question Collection (N=400) & Proportion of Final Collection (N=42)\\ 
        \midrule
        Location & 28\% & 12\%\\
        Contacts & 12\% & 14\%\\
        Age & 12\% & 5\%\\
        Voice Recordings & 11\% & 17\%\\
        Name &  11\% & 14\%\\
        Calendar & 10\% & 12\%\\
        Email & 6\% & 7\% \\
        Phone Number & 5\% & 9.5\%\\
        Time Zone & 5\% & 9.5\%\\
        \bottomrule
        \end{tabular}
    \caption{Information type categories and their proportion in the total question collection and the final question collection with a stronger focus on questions related to the topic of voice recordings.} 
    \label{tab:datatype}
\end{table}


\section{Categorization of Alexa Answers}
\label{sec:CategorizationAlexa}

\begin{table}[H]
    \centering
    \begin{tabular}{l|c|p{9cm}}
        \toprule
        Response Type & Proportion (n=42) & Example \\
        \midrule
        Excuse & 28.6\% & Sorry, I don't know that.\\         
        ``No answer" & 11.9\% & - \\         
        Online Reference & 11.9\% & From Redflash.com: Amazon does not provide your email or phone numbers to third-party sellers. \\ 
        Forwarding & 9.5\% & For help with that question go to the help and feedback section of the Alexa App. \\
        Account Information & 9.5\% & I am not sure who's speaking but you're in X account. To teach me to recognize your voice just say ``Learn my voice" \\
        Calendar Information & 9.5\% & There's nothing on the calendar for the next 30 days \\
        General Information & 9.5\% & This device's time zone is Central European Time. \\
        Control \& Choice & 7.2\% & Okay, I'll delete any recordings from the last ten minutes. \\
        Privacy Information & 2.4\% & Your data allows me to respond to you and helps me learn from our interactions so that I can better help you. For example, the more variation in spoken language I learn, the better I'll be at understanding what you mean. You can find settings for how your data is used by visiting amazon.co.uk/alexaprivacysettings or the Privacy Section of the Alexa app. \\  
    \bottomrule
    \end{tabular}
    \caption{Categorization of answers provided by Amazon Alexa to the questions in the final collection and their proportion. We find that the majority of answers provide an excuse. Information on control and choice or privacy information was specifically provided for questions related to the voice recordings.}
    \label{tab:AlexaAnswers}
\end{table}



\section{Questions and Answers in the User Study}

\begin{landscape}
\small
\centering
    \begin{longtable}{|p{0.15\textheight}|p{0.2\textheight}|p{0.3\textheight}|p{0.25\textheight}|p{0.25\textheight}|}
        \toprule
        Question & Alexa Answer & Privacy Policy Excerpt & Designed Answer 1 & Designed Answer 2 \\
        \toprule
        I want to change my name. & You can find and update my wake word in the Alexa app. Select the devices icon, select your device and then select Wake Word. & You can add or update certain information on pages such as those referenced in the Information You Can Access section. When you update information, we usually keep a copy of the previous version for our records. & Visit the Alexa Profile Settings on your Alexa App to edit information on your name. & You can manage your personal information under your profile in your Amazon settings.\\
        Do they keep my contacts' information? & Sorry, I don't have an answer for that. & When you register for Alexa Communication on your Alexa app, you will be asked to import your contacts from your device, which will then appear as contacts in your Alexa app. When you open the Alexa app, your contacts are auto-updated from your tablet or mobile phone. You may disable contact import in the Alexa app. If contact import is disabled, contacts you previously imported from your device will be deleted. You may also manually add contacts to your Alexa contact list in the Alexa app or at https://alexa.amazon.com. You can also delete each contact you manually added by selecting the applicable contact card. & When you register for Alexa Communication on your Alexa app, you will be asked to import your contacts from your device, which will then appear as contacts in your Alexa app. & If you use Alexa Communication to communicate with friends and family via Alexa, you will be asked to import your contacts from your device. They will be updated when you open the Alexa App. To delete contacts you can disable contact import or delete them manually by selecting the corresponding contact card in your Alexa App. \\
        Can the assistant pull information from my phone's calendar? & There's nothing on the calendar for the next 30 days. &To have Alexa add, delete, or update your calendar events, link your calendar in the Alexa app. Note: When you link your calendar account, a copy of your calendar is stored in the cloud so you can access it using Alexa. Content from your calendar might be available to anyone using your Alexa devices. &You can link your calendar account to your Alexa in the Alexa App. This will allow anyone with access to your Alexa devices to manage events. The Alexa Calendar is stored in the cloud. &You can give permission to Alexa to add, delete, or update your Calendar events and also link your calendar in the Alexa app. If anyone else is using your Alexa devices, the content of your calendar might be available to them. \\
        Do you need to know my time zone?  & This devices time zone is Central European Time. & We automatically collect and store certain types of information about your use of Amazon Services, including information about your interaction with products, content, and services available through Amazon Services. Examples of the information we collect and analyze include: version and time zone settings. &We collect your Time Zone automatically to provide you with a more effective experience. & When you interact with our products or services we might automatically receive information on your time zone. In addition, your device's location is used for providing time or weather information. You can change your location at any time by editing your device location on your Alexa App.\\ 
        Who can access my voice recordings? & For help with this question go to the help and feedback section of the Alexa app.& Using your browser, you can listen to Alexa recordings in the Review Voice History section of Alexa Privacy Settings (amazon.com/alexaprivacysettings). Using the Alexa app, you can listen to Alexa recordings by going to the menu and selecting Settings > Alexa Privacy > Review Voice History. & You can access your voice recordings in your Voice History in the Alexa Privacy Settings. & You can review voice recordings of your device in your account. \\
    \bottomrule
    \caption{Questions and Answers displayed in randomized order in the user study.}
    \end{longtable}
    \label{tab:QuestionAnswerUserStudy}
\end{landscape}


\section{Codebook Derived from the Interviews}

\begin{table}[!htb]
    \centering
    \small
    %\resizebox{\textwidth}{!}{
    \begin{tabular}{p{3cm}p{4cm}p{7cm}}
       \toprule
        Codes & Definitions & Examples \\
        \midrule
        \multicolumn{3}{l}{Stylistic}  \\
         \midrule
        Informal Style & conversational or casual speech & This devices time zone is Central European Time\\
        Formal Style & more professional language that avoids directly addressing the user & You can add or update certain information on pages such as those referenced in the Information You Can Access section. When you update information, we usually keep a copy of the previous version for our records\\
        Lengthy Instruction & answers with excessively detailed steps & Using your browser, you can listen to Alexa recordings in the Review Voice History section of Alexa Privacy Settings (amazon.com/alexaprivacysettings). Using the Alexa app, you can listen to Alexa recordings by going to the menu and selecting Settings > Alexa Privacy > Review Voice History\\
        Straightforward & quite short sentences providing quick and direct answers & Visit the Alexa Profile Settings on your Alexa App to edit information on your name\\
         \midrule 
        \multicolumn{3}{l}{Linguistic} \\
        \midrule 
        Difficult Semantics & technical and sophisticated terminology & To have Alexa add, delete, or update your calendar events, link your calendar in the Alexa app. Note: When you link your calendar account, a copy of your calendar is stored in the cloud so you can access it using Alexa. Content from your calendar might be available to anyone using your Alexa devices\\
        Irrelevant & the sentence does not answer the question at all & User: Can the assistant pull information from my phone's calendar? Alexa: There's nothing on the calendar for the next 30 days \\
        Simple Semantics & responses free of technical or convoluted language & You can give permission to Alexa to add, delete, or update your Calendar events and also link your calendar in the Alexa app. If anyone else is using your Alexa devices, the content of your calendar might be available to them\\
        Rich Syntactic Structure & complex and varied grammatical constructions, aimed at providing detailed information & We automatically collect and store certain types of information about your use of Amazon Services, including information about your interaction with products, content, and services available through Amazon Services. Examples of the information we collect and analyze include: version and time zone settings\\
        Comprehensiveness & the answers which in terms of content were long, thorough, and detailed & To have Alexa add, delete, or update your calendar events, link your calendar in the Alexa app. Note: When you link your calendar account, a copy of your calendar is stored in the cloud so you can access it using Alexa. Content from your calendar might be available to anyone using your Alexa devices\\
        Keyword Significance & specific words within sentences shape participants' perceptions and influence their decision-making & You can review voice recordings of your device in your account\\
        \bottomrule
    \end{tabular}%}
    \caption{Codebook presenting the defined codes, their definitions derived from interview feedback, and examples taken from the dataset.}
    \label{tab:1}
\end{table}


\section{Interface of Amazon Mechanical Turk Sandbox Displaying Interview Questions}

\begin{figure}[H]
    \centering\includegraphics[width=0.75\linewidth]{sandbox.png}
    \caption{Example of the questions interface in the Amazon Mechanical Turk Sandbox as seen by participants during the interviews.}
    \label{fig:AMTInterface}
\end{figure}



\section{Frequency of Top Three Codes by Metric}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.75\linewidth]{figure.png}
    \caption{The figure displays the three most frequently occurring codes in the interview feedback for each metric, demonstrating which aspects were most noticeable and important to participants during their subjective evaluation of the answers.}
    \label{fig:Frequency of Codes}
\end{figure}



\end{document}

\endinput
%%
%% End of file `sample-acmsmall-conf.tex'.
