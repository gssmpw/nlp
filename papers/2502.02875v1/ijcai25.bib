@book{ abelson-et-al:scheme,
  author = "Harold Abelson and Gerald~Jay Sussman and Julie Sussman",
  title = "Structure and Interpretation of Computer Programs",
  publisher = "MIT Press",
  address = "Cambridge, Massachusetts",
  year = "1985"
}

@inproceedings{ bgf:Lixto,
  author = "Robert Baumgartner and Georg Gottlob and Sergio Flesca",
  title = "Visual Information Extraction with {Lixto}",
  booktitle = "Proceedings of the 27th International Conference on Very Large Databases",
  pages = "119--128",
  publisher = "Morgan Kaufmann",
  address = "Rome, Italy",
  month = "September",
  year = "2001"
}

@article{ brachman-schmolze:kl-one,
  author = "Ronald~J. Brachman and James~G. Schmolze",
  title = "An overview of the {KL-ONE} knowledge representation system",
  journal = "Cognitive Science",
  volume = "9",
  number = "2",
  pages = "171--216",
  month = "April--June",
  year = "1985"
}

@article{ gottlob:nonmon,
  author = "Georg Gottlob",
  title = "Complexity results for nonmonotonic logics",
  journal = "Journal of Logic and Computation",
  volume = "2",
  number = "3",
  pages = "397--425",
  month = "June",
  year = "1992"
}

@article{ gls:hypertrees,
  author = "Georg Gottlob and Nicola Leone and Francesco Scarcello",
  title = "Hypertree Decompositions and Tractable Queries",
  journal = "Journal of Computer and System Sciences",
  volume = "64",
  number = "3",
  pages = "579--627",
  month = "May",
  year = "2002"
}

@article{ levesque:functional-foundations,
  author = "Hector~J. Levesque",
  title = "Foundations of a functional approach to knowledge representation",
  journal = "Artificial Intelligence",
  volume = "23",
  number = "2",
  pages = "155--212",
  month = "July",
  year = "1984"
}

@inproceedings{ levesque:belief,
  author = "Hector~J. Levesque",
  title = "A logic of implicit and explicit belief",
  booktitle = "Proceedings of the Fourth National Conference on Artificial Intelligence",
  publisher = "American Association for Artificial Intelligence",
  pages = "198--202",
  address = "Austin, Texas",
  month = "August",
  year = "1984"
}

@article{ nebel:jair-2000,
  author = "Bernhard Nebel",
  title = "On the compilability and expressive power of propositional planning formalisms",
  journal = "Journal of Artificial Intelligence Research",
  volume = "12",
  pages = "271--315",
  year = "2000"
}

 @misc{proceedings,
  author = {{IJCAI Proceedings}},
  title = {{IJCAI} Camera Ready Submission},
  howpublished = {\url{https://proceedings.ijcai.org/info}},
}












@inproceedings{son2019qtran,
  title={Qtran: Learning to factorize with transformation for cooperative multi-agent reinforcement learning},
  author={Son, Kyunghwan and Kim, Daewoo and Kang, Wan Ju and Hostallero, David Earl and Yi, Yung},
  booktitle={International conference on machine learning},
  pages={5887--5896},
  year={2019},
  organization={PMLR}
}

@article{sunehag2017value,
  title={Value-decomposition networks for cooperative multi-agent learning},
  author={Sunehag, Peter and Lever, Guy and Gruslys, Audrunas and Czarnecki, Wojciech Marian and Zambaldi, Vinicius and Jaderberg, Max and Lanctot, Marc and Sonnerat, Nicolas and Leibo, Joel Z and Tuyls, Karl and others},
  journal={arXiv preprint arXiv:1706.05296},
  year={2017}
}

@article{rashid2020monotonic,
  title={Monotonic value function factorisation for deep multi-agent reinforcement learning},
  author={Rashid, Tabish and Samvelyan, Mikayel and De Witt, Christian Schroeder and Farquhar, Gregory and Foerster, Jakob and Whiteson, Shimon},
  journal={The Journal of Machine Learning Research},
  volume={21},
  number={1},
  pages={7234--7284},
  year={2020},
  publisher={JMLRORG}
}

@article{yang2020qatten,
  title={Qatten: A general framework for cooperative multiagent reinforcement learning},
  author={Yang, Yaodong and Hao, Jianye and Liao, Ben and Shao, Kun and Chen, Guangyong and Liu, Wulong and Tang, Hongyao},
  journal={arXiv preprint arXiv:2002.03939},
  year={2020}
}

@article{wei2022vgn,
  title={Vgn: Value decomposition with graph attention networks for multiagent reinforcement learning},
  author={Wei, Qinglai and Li, Yugu and Zhang, Jie and Wang, Fei-Yue},
  journal={IEEE Transactions on Neural Networks and Learning Systems},
  year={2022},
  publisher={IEEE}
}

@article{naderializadeh2020graph,
  title={Graph convolutional value decomposition in multi-agent reinforcement learning},
  author={Naderializadeh, Navid and Hung, Fan H and Soleyman, Sean and Khosla, Deepak},
  journal={arXiv preprint arXiv:2010.04740},
  year={2020}
}

@article{rashid2020weighted,
  title={Weighted qmix: Expanding monotonic value function factorisation for deep multi-agent reinforcement learning},
  author={Rashid, Tabish and Farquhar, Gregory and Peng, Bei and Whiteson, Shimon},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={10199--10210},
  year={2020}
}

@inproceedings{wang2021qplex,
title={{\{}QPLEX{\}}: Duplex Dueling Multi-Agent Q-Learning},
author={Jianhao Wang and Zhizhou Ren and Terry Liu and Yang Yu and Chongjie Zhang},
booktitle={International Conference on Learning Representations},
year={2021},
url={https://openreview.net/forum?id=Rcmk0xxIQV}
}

@article{shen2022resq,
  title={ResQ: A Residual Q Function-based Approach for Multi-Agent Reinforcement Learning Value Factorization},
  author={Shen, Siqi and Qiu, Mengwei and Liu, Jun and Liu, Weiquan and Fu, Yongquan and Liu, Xinwang and Wang, Cheng},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={5471--5483},
  year={2022}
}

@article{jiang2018graph,
  title={Graph convolutional reinforcement learning},
  author={Jiang, Jiechuan and Dun, Chen and Huang, Tiejun and Lu, Zongqing},
  journal={arXiv preprint arXiv:1810.09202},
  year={2018}
}

@inproceedings{li2022deconfounded,
  title={Deconfounded value decomposition for multi-agent reinforcement learning},
  author={Li, Jiahui and Kuang, Kun and Wang, Baoxiang and Liu, Furui and Chen, Long and Fan, Changjie and Wu, Fei and Xiao, Jun},
  booktitle={International Conference on Machine Learning},
  pages={12843--12856},
  year={2022},
  organization={PMLR}
}

@inproceedings{liu2023contrastive,
  title={Contrastive identity-aware learning for multi-agent value decomposition},
  author={Liu, Shunyu and Zhou, Yihe and Song, Jie and Zheng, Tongya and Chen, Kaixuan and Zhu, Tongtian and Feng, Zunlei and Song, Mingli},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={37},
  number={10},
  pages={11595--11603},
  year={2023}
}

@article{ding2023multi,
  title={Multi-agent dueling Q-learning with mean field and value decomposition},
  author={Ding, Shifei and Du, Wei and Ding, Ling and Guo, Lili and Zhang, Jian and An, Bo},
  journal={Pattern Recognition},
  volume={139},
  pages={109436},
  year={2023},
  publisher={Elsevier}
}

@article{Son2020QOPTOV,
  title={QOPT: Optimistic Value Function Decentralization for Cooperative Multi-Agent Reinforcement Learning},
  author={Kyunghwan Son and Sungsoo Ahn and Roben Delos Reyes and Jinwoo Shin and Yung Yi},
  journal={ArXiv},
  year={2020},
  volume={abs/2006.12010},
  url={https://api.semanticscholar.org/CorpusID:219965923}
}

@inproceedings{zohar2022locality,
  title={Locality matters: A scalable value decomposition approach for cooperative multi-agent reinforcement learning},
  author={Zohar, Roy and Mannor, Shie and Tennenholtz, Guy},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={36},
  number={8},
  pages={9278--9285},
  year={2022}
}

@article{liu2023learning,
  title={Learning Multi-Agent Cooperation via Considering Actions of Teammates},
  author={Liu, Shanqi and Liu, Weiwei and Chen, Wenzhou and Tian, Guanzhong and Chen, Jun and Tong, Yao and Cao, Junjie and Liu, Yong},
  journal={IEEE Transactions on Neural Networks and Learning Systems},
  year={2023},
  publisher={IEEE}
}

@article{ding2023multiagent,
  title={Multiagent reinforcement learning with graphical mutual information maximization},
  author={Ding, Shifei and Du, Wei and Ding, Ling and Zhang, Jian and Guo, Lili and An, Bo},
  journal={IEEE Transactions on Neural Networks and Learning Systems},
  year={2023},
  publisher={IEEE}
}

@article{pina2022residual,
  title={Residual Q-Networks for Value Function Factorizing in Multiagent Reinforcement Learning},
  author={Pina, Rafael and De Silva, Varuna and Hook, Joosep and Kondoz, Ahmet},
  journal={IEEE Transactions on Neural Networks and Learning Systems},
  year={2022},
  publisher={IEEE}
}

@inproceedings{xu2023haven,
  title={Haven: Hierarchical cooperative multi-agent reinforcement learning with dual coordination mechanism},
  author={Xu, Zhiwei and Bai, Yunpeng and Zhang, Bin and Li, Dapeng and Fan, Guoliang},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={37},
  number={10},
  pages={11735--11743},
  year={2023}
}

@inproceedings{khan2022transformer,
  title={Transformer-based value function decomposition for cooperative multi-agent reinforcement learning in StarCraft},
  author={Khan, Muhammad Junaid and Ahmed, Syed Hammad and Sukthankar, Gita},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence and Interactive Digital Entertainment},
  volume={18},
  number={1},
  pages={113--119},
  year={2022}
}

@book{oliehoek_concise_2016,
	series = {Springer {Briefs} in {Intelligent} {Systems}},
	title = {A {Concise} {Introduction} to {Decentralized} {POMDPs}},
	publisher = {Springer},
	author = {Oliehoek, Frans A. and Amato, Christopher},
	year = {2016},
}

@inproceedings{tan1993multi,
  title={Multi-agent reinforcement learning: Independent vs. cooperative agents},
  author={Tan, Ming},
  booktitle={Proceedings of the 10th international conference on machine learning},
  publisher = {PMLR},
  pages={330--337},
  year={1993}
}

@article{zhang2023deepmag,
    title={DeepMAG: Deep reinforcement learning with multi-agent graphs for flexible job shop scheduling},
    author={Zhang, Jia-Dong and He, Zhixiang and Chan, Wing-Ho and Chow, Chi-Yin},
    journal={Knowledge-Based Systems},
    volume={259},
    pages={110083},
    year={2023},
    publisher={Elsevier}
}

@article{angelotti2023towards,
    title={Towards a more efficient computation of individual attribute and policy contribution for post-hoc explanation of cooperative multi-agent systems using Myerson values},
    author={Angelotti, Giorgio and D{\'\i}az-Rodr{\'\i}guez, Natalia},
    journal={Knowledge-Based Systems},
    volume={260},
    pages={110189},
    year={2023},
    publisher={Elsevier}
}

@inproceedings{xiao2023stochastic,
  title={Stochastic graph neural network-based value decomposition for multi-agent reinforcement learning in urban traffic control},
  author={Xiao, Baidi and Li, Rongpeng and Wang, Fei and Peng, Chenghui and Wu, Jianjun and Zhao, Zhifeng and Zhang, Honggang},
  booktitle={2023 IEEE 97th Vehicular Technology Conference (VTC2023-Spring)},
  pages={1--7},
  year={2023},
  organization={IEEE}
}

@article{huttenrauch2017guided,
  title={Guided deep reinforcement learning for swarm systems},
  author={H{\"u}ttenrauch, Maximilian and {\v{S}}o{\v{s}}i{\'c}, Adrian and Neumann, Gerhard},
  journal={arXiv preprint arXiv:1709.06011},
  year={2017}
}

@inproceedings{jaques2019social,
  title={Social influence as intrinsic motivation for multi-agent deep reinforcement learning},
  author={Jaques, Natasha and Lazaridou, Angeliki and Hughes, Edward and Gulcehre, Caglar and Ortega, Pedro and Strouse, DJ and Leibo, Joel Z and De Freitas, Nando},
  booktitle={International conference on machine learning},
  pages={3040--3049},
  year={2019},
  organization={PMLR}
}

@inproceedings{mei2023mac,
  title={MAC-PO: Multi-Agent Experience Replay via Collective Priority Optimization},
  author={Mei, Yongsheng and Zhou, Hanhan and Lan, Tian and Venkataramani, Guru and Wei, Peng},
  booktitle={Proceedings of the 2023 International Conference on Autonomous Agents and Multiagent Systems},
  pages={466--475},
  year={2023}
}

@article{hernandez2019survey,
  title={A survey and critique of multiagent deep reinforcement learning},
  author={Hernandez-Leal, Pablo and Kartal, Bilal and Taylor, Matthew E},
  journal={Autonomous Agents and Multi-Agent Systems},
  volume={33},
  number={6},
  pages={750--797},
  year={2019},
  publisher={Springer}
}

@article{perrusquia2021multi,
  title={Multi-agent reinforcement learning for redundant robot control in task-space},
  author={Perrusqu{\'\i}a, Adolfo and Yu, Wen and Li, Xiaoou},
  journal={International Journal of Machine Learning and Cybernetics},
  volume={12},
  pages={231--241},
  year={2021},
  publisher={Springer}
}

@ARTICLE{9043893,
  author={Nguyen, Thanh Thi and Nguyen, Ngoc Duy and Nahavandi, Saeid},
  journal={IEEE Transactions on Cybernetics}, 
  title={Deep Reinforcement Learning for Multiagent Systems: A Review of Challenges, Solutions, and Applications}, 
  year={2020},
  volume={50},
  number={9},
  pages={3826-3839},
  doi={10.1109/TCYB.2020.2977374}}

@ARTICLE{9712866,
  author={Zhang, Ruilong and Zong, Qun and Zhang, Xiuyun and Dou, Liqian and Tian, Bailing},
  journal={IEEE Transactions on Neural Networks and Learning Systems}, 
  title={Game of Drones: Multi-UAV Pursuit-Evasion Game With Online Motion Planning by Deep Reinforcement Learning}, 
  year={2023},
  volume={34},
  number={10},
  pages={7900-7909},
  keywords={Games;Reinforcement learning;Physics;Engines;Urban areas;Real-time systems;Trajectory;Multiagent reinforcement learning;multiquadcopter motion planning;pursuit-evasion game;trajectory prediction},
  doi={10.1109/TNNLS.2022.3146976}}

@ARTICLE{10297577,
  author={Chen, Jinchao and Li, Tingyang and Zhang, Ying and You, Tao and Lu, Yantao and Tiwari, Prayag and Kumar, Neeraj},
  journal={IEEE Transactions on Vehicular Technology}, 
  title={Global-and-Local Attention-Based Reinforcement Learning for Cooperative Behaviour Control of Multiple UAVs}, 
  year={2023},
  volume={},
  number={},
  pages={1-13},
  keywords={Autonomous aerial vehicles;Vehicle dynamics;Task analysis;Reinforcement learning;Analytical models;Decision making;Training;Global-and-local attention mechanism;reinforcement learning;cooperative behaviour control;multiple UAVs;multi-constraint decision-making},
  doi={10.1109/TVT.2023.3327571}}

@ARTICLE{10322867,
  author={Xiao, Jiaping and Pisutsin, Phumrapee and Feroskhan, Mir},
  journal={IEEE Transactions on Neural Networks and Learning Systems}, 
  title={Collaborative Target Search With a Visual Drone Swarm: An Adaptive Curriculum Embedded Multistage Reinforcement Learning Approach}, 
  year={2023},
  volume={},
  number={},
  pages={1-15},
  keywords={Drones;Visualization;Task analysis;Collaboration;Visual perception;Reinforcement learning;Optimization;Collaborative target search (CTS);curriculum learning;deep reinforcement learning (DRL);drones;multiagent systems},
  doi={10.1109/TNNLS.2023.3331370}}

@ARTICLE{9354492,
  author={Xu, Xing and Li, Rongpeng and Zhao, Zhifeng and Zhang, Honggang},
  journal={IEEE Transactions on Neural Networks and Learning Systems}, 
  title={Stigmergic Independent Reinforcement Learning for Multiagent Collaboration}, 
  year={2022},
  volume={33},
  number={9},
  pages={4285-4299},
  keywords={Collaboration;Training;Shape;Insects;Task analysis;Intelligent agents;Wireless communication;Artificial intelligence;collective intelligence;multiagent collaboration;reinforcement learning;stigmergy},
  doi={10.1109/TNNLS.2021.3056418}}

@article{yang2023causal,
  title={Causal inference multi-agent reinforcement learning for traffic signal control},
  author={Yang, Shantian and Yang, Bo and Zeng, Zheng and Kang, Zhongfeng},
  journal={Information Fusion},
  volume={94},
  pages={243--256},
  year={2023},
  publisher={Elsevier}
}

@article{wu2022distributed,
  title={Distributed agent-based deep reinforcement learning for large scale traffic signal control},
  author={Wu, Qiang and Wu, Jianqing and Shen, Jun and Du, Bo and Telikani, Akbar and Fahmideh, Mahdi and Liang, Chao},
  journal={Knowledge-Based Systems},
  volume={241},
  pages={108304},
  year={2022},
  publisher={Elsevier}
}

@book{sutton_reinforcement_2018,
	title = {Reinforcement learning: {An} introduction},
	author = {Sutton, Richard S. and Barto, Andrew G.},
	publisher = {MIT press},
	year = {2018}
}

@inproceedings{lowe2017multi,
  title={Multi-agent actor-critic for mixed cooperative-competitive environments},
  author={Lowe, Ryan and Wu, Yi and Tamar, Aviv and Harb, Jean and Abbeel, Pieter and Mordatch, Igor},
  booktitle={Proceedings of the 31st International Conference on Neural Information Processing Systems, {NeurIPS}},
  pages={6382--6393},
  year={2017}
}

@article{rashid_monotonic_2020,
	title = {Monotonic value function factorisation for deep multi-agent reinforcement learning},
	volume = {21},
	number = {178},
	journal = {Journal of Machine Learning Research},
	author = {Rashid, Tabish and Samvelyan, Mikayel and De Witt, Christian Schroeder and Farquhar, Gregory and Foerster, Jakob and Whiteson, Shimon},
	year = {2020},
	pages = {1--51}
}

@inproceedings{hu2023rethinking,
  title={Rethinking the Implementation Tricks and Monotonicity Constraint in Cooperative Multi-agent Reinforcement Learning},
  author={Hu, Jian and Wang, Siying and Jiang, Siyang and Wang, Weixun},
  booktitle={The Second Blogpost Track at ICLR 2023},
  year={2023}
}

@inproceedings{bohmer2020deep,
  title={Deep coordination graphs},
  author={B{\"o}hmer, Wendelin and Kurin, Vitaly and Whiteson, Shimon},
  booktitle={International Conference on Machine Learning},
  pages={980--991},
  year={2020},
  organization={PMLR}
}

@article{wei2018multiagent,
  title={Multiagent soft q-learning},
  author={Wei, Ermo and Wicke, Drew and Freelan, David and Luke, Sean},
  journal={arXiv preprint arXiv:1804.09817},
  year={2018}
}

@article{son2020qtran++,
  title={QTRAN++: improved value transformation for cooperative multi-agent reinforcement learning},
  author={Son, Kyunghwan and Ahn, Sungsoo and Reyes, Roben Delos and Shin, Jinwoo and Yi, Yung},
  journal={arXiv preprint arXiv:2006.12010},
  year={2020}
}

@inproceedings{rashid_qmix_2018,
	title = {{QMIX}: {Monotonic} {Value} {Function} {Factorisation} for {Deep} {Multi}-{Agent} {Reinforcement} {Learning}},
	booktitle = {Proceedings of the 35th {International} {Conference} on {Machine} {Learning}},
	publisher = {PMLR},
	author = {Rashid, Tabish and Samvelyan, Mikayel and Witt, Christian Schröder de and Farquhar, Gregory and Foerster, Jakob N. and Whiteson, Shimon},
	year = {2018},
	pages = {4292--4301}
}


@article{mnih_human-level_2015,
	title = {Human-level control through deep reinforcement learning},
	volume = {518},
	number = {7540},
	journal = {nature},
	author = {Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Rusu, Andrei A. and Veness, Joel and Bellemare, Marc G. and Graves, Alex and Riedmiller, Martin and Fidjeland, Andreas K. and Ostrovski, Georg},
	year = {2015},
	pages = {529--533}
}

@inproceedings{samvelyan_starcraft_2019,
	title = {The {StarCraft} {Multi}-{Agent} {Challenge}},
	booktitle = {Proceedings of the 18th {International} {Conference} on {Autonomous} {Agents} and {MultiAgent} {Systems}, {AAMAS}},
	author = {Samvelyan, Mikayel and Rashid, Tabish and Witt, Christian Schröder de and Farquhar, Gregory and Nardelli, Nantas and Rudner, Tim G. J. and Hung, Chia-Man and Torr, Philip H. S. and Foerster, Jakob N. and Whiteson, Shimon},
	year = {2019},
	pages = {2186--2188}
}

@article{zhang2023policy,
  title={Policy Expansion for Bridging Offline-to-Online Reinforcement Learning},
  author={Zhang, Haichao and Xu, We and Yu, Haonan},
  journal={arXiv preprint arXiv:2302.00935},
  year={2023}
}

@article{sutton1991dyna,
  title={Dyna, an integrated architecture for learning, planning, and reacting},
  author={Sutton, Richard S},
  journal={ACM Sigart Bulletin},
  volume={2},
  number={4},
  pages={160--163},
  year={1991},
  publisher={ACM New York, NY, USA}
}

@inproceedings{silver2008sample,
  title={Sample-based learning and search with permanent and transient memories},
  author={Silver, David and Sutton, Richard S and M{\"u}ller, Martin},
  booktitle={Proceedings of the 25th international conference on Machine learning},
  pages={968--975},
  year={2008}
}

@article{pu2021decomposed,
  title={Decomposed soft actor-critic method for cooperative multi-agent reinforcement learning},
  author={Pu, Yuan and Wang, Shaochen and Yang, Rui and Yao, Xin and Li, Bin},
  journal={arXiv preprint arXiv:2104.06655},
  year={2021}
}

@inproceedings{lee2022offline,
  title={Offline-to-online reinforcement learning via balanced replay and pessimistic q-ensemble},
  author={Lee, Seunghyun and Seo, Younggyo and Lee, Kimin and Abbeel, Pieter and Shin, Jinwoo},
  booktitle={Conference on Robot Learning},
  pages={1702--1712},
  year={2022},
  organization={PMLR}
}

@article{xie2021policy,
  title={Policy finetuning: Bridging sample-efficient offline and online reinforcement learning},
  author={Xie, Tengyang and Jiang, Nan and Wang, Huan and Xiong, Caiming and Bai, Yu},
  journal={Advances in neural information processing systems},
  volume={34},
  pages={27395--27407},
  year={2021}
}

@article{luo2023relay,
  title={Relay Hindsight Experience Replay: Self-guided continual reinforcement learning for sequential object manipulation tasks with sparse rewards},
  author={Luo, Yongle and Wang, Yuxin and Dong, Kun and Zhang, Qiang and Cheng, Erkang and Sun, Zhiyong and Song, Bo},
  journal={Neurocomputing},
  volume={557},
  pages={126620},
  year={2023},
  publisher={Elsevier}
}

@inproceedings{liang2017why,
title={Why Deep Neural Networks for Function Approximation?},
author={Shiyu Liang and R. Srikant},
booktitle={International Conference on Learning Representations},
year={2017},
url={https://openreview.net/forum?id=SkpSlKIel}
}

@article{elfwing2018sigmoid,
  title={Sigmoid-weighted linear units for neural network function approximation in reinforcement learning},
  author={Elfwing, Stefan and Uchibe, Eiji and Doya, Kenji},
  journal={Neural networks},
  volume={107},
  pages={3--11},
  year={2018},
  publisher={Elsevier}
}