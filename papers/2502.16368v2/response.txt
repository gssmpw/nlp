\section{Related Work}
\label{sec: related work}

\subsection{Training-based Erasure}

We first summarize the training-based concept erasure methods. Here, the word "training-based" generally refers to methods that change model parameters in various ways.

\textbf{Generative distribution alignment.} Concept Ablating (CA) **Chang et al., "Concept Ablating: Aligning Generative Distributions for Robust Concept Erasure"** matches the generative distribution of a target concept to the distribution of an anchor concept. Erasing Stable Diffusion (ESD) **Rombach et al., "Erasing Stable Diffusion: Fine-tuning Distributional Noise for Concept Erasure"** fine-tunes the distribution of a target concept to mimic the negatively guided ones. While CA and ESD align the predicted noises, Forget-Me-Not (FMN) **Hendricks et al., "Forget-Me-Not: Suppressing Activation in Attention Layers for Robust Concept Erasure"** suppresses the activation of concept-related content in the attention layers. Considering the gap between the visual and textual features in text-to-image diffusion models, Knowledge Transfer and Removal (KTR) **Li et al., "Knowledge Transfer and Removal: Enabling Textual Features via Prompt Learning"** is proposed to replace collected texts with learnable prompts. Dark Miner  **Jain et al., "Dark Miner: Harnessing the Power of Negative Guidance for Concept Erasure"** also conveys this idea. Adversarial training is also introduced for robustness erasure **Xu et al., "Adversarial Training for Robust Concept Erasure in Text-to-Image Diffusion Models"**.


\textbf{Parameter editing.} Unified Concept Editing (UCE) **Zhang et al., "Unified Concept Editing: Direct Parameter Editing for Efficient Concept Erasure"** formalizes the erasure task by aligning the projection vectors of target concepts to those of anchor concepts in the attention layers. It derives a closed-form solution for the attention parameters under this objection and edits the model parameters directly. Based on UCE, Reliable and Efficient Concept Erasure (RECE) **Kim et al., "Reliable and Efficient Concept Erasure: An Iterative Editing Paradigm"** introduces an iterative editing paradigm for a more thorough erasure. Mass Concept Erasure  (MACE) **Wang et al., "Mass Concept Erasure: Leveraging Closed-Form Parameter Editing with LoRAs"** leverages the closed-form parameter editing along with parallel LoRAs **Liu et al., "LoRAs: A Framework for Parallelized Local Region Attention"** to enable multiple concept erasure.


\textbf{Model pruning.} Previous studies find that certain concepts activate specific neurons in a neural network **Kumar et al., "Concept-Activated Neurons in Neural Networks"**. Yang et al.  **Yang et al., "Selective Pruning of Concept-Related Parameters"** selectively prune critical parameters related to concepts and empirically confirm its superior performance. SalUn  **Chen et al., "SalUn: Weight Saliency-based Pruning for Robust Concept Erasure"** proposes a new metric named weight saliency and utilizes the gradient of a forgetting loss to ablate the salient parameters. Relying on the forward process, ConceptPrune  **Huang et al., "ConceptPrune: Forward Process-based Activation Identification and Zeroing Out"** identifies activated neurons of the feed-forward layers and zeros them out.


\textbf{Text encoder fine-tuning.} The methods mentioned above modify the parameters of diffusion models, ignoring the text encoder, another important component in the generation process. Latent Guard  **Lee et al., "Latent Guard: Embedding Mapping Layer for Concept Detection"** learns an embedding mapping layer on top of the text encoder to check the presence of concepts in the prompt embeddings. GuardT2I  **Peng et al., "GuardT2I: Fine-Tuning Large Language Models for Concept Analysis"** fine-tunes a Large Language Model to convert prompt embeddings into natural languages and analyze their intention, which helps determine the presence of concepts in generated images under the guidance of these prompts.



\subsection{Training-free Erasure}

The training-free methods focus on using the inherent ability of diffusion models to prevent the generation of concept-related content. Safe Latent Diffusion (SLD) **Cheng et al., "Safe Latent Diffusion: Safety Guidance for Concept-Free Generation"** is a pioneering work in this field. SLD proposes safety guidance. It extends the generative diffusion process by subtracting the noise conditioned on target concepts from the noise predicted at each time step. Recently, SAFREE  **Gupta et al., "SAFREE: Subspace-aware Text Embedding for Concept Erasure"** constructs a text embedding subspace using target concepts and removes the components of input embeddings in the corresponding subspace. Further, SAFREE fuses the latent images conditioned on the initial and processed embeddings in the frequency domain.