
\clearpage

\setcounter{section}{0}

\renewcommand\thesection{\Alph{section}}
\renewcommand{\theequation}{S\arabic{equation}}
\renewcommand{\thefigure}{S\arabic{figure}}
\renewcommand{\thetable}{S\arabic{table}}

\twocolumn[{
\renewcommand\twocolumn[1][]{#1}
\maketitlesupplementary
\vspace{-0.5cm}
\begin{center}
    \textcolor{Red}{\textbf{Warning:} This material may contain disturbing, distressing, offensive, or uncomfortable content.}
\end{center}
}]


This supplementary material provides additional details as follows.

\begin{enumerate}
\setlength{\itemsep}{4pt}
    
    \item[\ref{sec: CRA}.] Concept Removal Attention.
    \item[\ref{sec: reproduction details}.] Reproduction Details.
    \item[\ref{sec: instruction}.] Instructions for Prompt Generation.
    \item[\ref{sec: query}.] Query for VLM.
    \item[\ref{sec: negative prompts}.] Negative Concepts.
    \item[\ref{sec: multiple concepts}.] Evaluation on Multiple-Concept Erasure.
    \item[\ref{sec: checkpoint combinations}.] Results of Various Checkpoint Choices.
    \item[\ref{sec: m2}.] Discussion about $\mathcal{M}$.
    \item[\ref{sec: time}.] Time Efficiency.
    \item[\ref{sec: erasure visualization}.] Visualizations.
    \item[\ref{sec: limitations}.] Limitations.
    
    
\end{enumerate}

\newpage

\section{Concept Removal Attention}

\label{sec: CRA}

\subsection{Results of Other Alternatives}
In the main paper, we highlight that existing methods, such as prompt editing and negative guidance, cannot remove the generated concept-related features from intermediate images, leading to concepts still being present in the final outputs. In this subsection, we provide the specific experimental results. Specifically, without changing our pipeline, we replace our proposed Concept Removal Attention with Prompt-to-Prompt [14] and Negative Guidance. The target concept is nudity. For Prompt-to-Prompt, we use GPT-4o to edit the user prompts into the ones without the sexual meaning by instructing it to add, replace, or remove some words. For Negative Guidance, we set ``nudity, nude, naked, sexual, exposed, unclothed'' as the negative prompts. Moreover, we also compare the performance of the two methods without being integrated into our pipeline. The evaluation protocol follows the one reported in the main paper.

\begin{table}[h]
    \centering
    \begin{tabular}{l|c} \toprule
        Method & Nudity $(\%, \downarrow)$ \\ \midrule
        SD v2.1 &  61.5 \\ \midrule
        Negative Guidance & 18.5 \\
        Prompt-to-prompt &  37.5 \\ \midrule
        Ours (+ Negative Guidance) &  48.5 \\
        Ours (+ Prompt-to-Prompt) &  50.0 \\
        Ours &  4.0 \\ \bottomrule
    \end{tabular}
    \caption{The erasure results of Negative Guidance, Prompt-to-Prompt, and the methods which are integrated into our proposed pipeline. The concept is nudity, and the Concept Ratio is reported.}
    \label{tab: ng p2p}
\end{table}

\begin{figure*}
    \centering
    \includegraphics[width=1\linewidth]{vis_compare.pdf}
    \caption{The visualizations of the images with the prompts containing the concept of nudity. NG: Negative Guidance. P2P: Prompt-to-Prompt. Ours (+ NG): Replace Concept Removal Attention with NG in our proposed method. Ours (+ P2P): Replace Concept Removal Attention with P2P in our proposed method.}
    \label{fig: vis_compare}
\end{figure*}


Tab.\ref{tab: ng p2p} presents the results. From the table, we can see that when we integrate Negative Guidance and Prompt-to-Prompt into our proposed generation pipeline, the nudity ratio of the generated images only drops slightly compared with the original model. Fig.\ref{fig: vis_compare} gives some examples. The generated images after their erasure, i.e. Ours (+NG) and Ours (+P2P), are highly similar to the original images. In addition, the prompts only contain the implicit words corresponding to nudity, such as \textit{bathhub}, \textit{underwear}, and \textit{bather}, leading to the difficulty to erase nudity for Prompt-to-Prompt. Even if we apply Negative Guidance and Prompt-to-Prompt from the very beginning of generation, the concept of nudity is still not removed. On the contrary, our proposed method erase the concept successfully, achieving the least nudity ratio among these alternatives.


\subsection{Visualization of \texorpdfstring{ $\mathcal{M}_1$}.}
\label{sec: m1}

\begin{figure}
    \centering
    \includegraphics[width=1.0\linewidth]{mask1.pdf}
    \caption{The examples of the mask $\mathcal{M}_1$ in the paper (concept: nudity). The layers with a \textbf{\underline{green}} background are used in the paper to calculate the masks while the layers with a \textbf{\underline{red}} background are not.}
    \label{fig: mask1}
\end{figure}

\begin{figure}
    \centering
    \includegraphics[width=1.0\linewidth]{mask2.pdf}
    \caption{The examples of the mask $\mathcal{M}_1$ in the paper (concept: bird). The layers with a \textbf{\underline{green}} background are used in the paper to calculate the masks while the layers with a \textbf{\underline{red}} background are not.}
    \label{fig: mask2}
\end{figure}

\begin{figure}
    \centering
    \includegraphics[width=1.0\linewidth]{mask3.pdf}
    \caption{The examples of the mask $\mathcal{M}_1$ in the paper (concept: Van Gogh's painting style). The layers with a \textbf{\underline{green}} background are used in the paper to calculate the masks while the layers with a \textbf{\underline{red}} background are not.}
    \label{fig: mask3}
\end{figure}


In the main paper, we mention that $\mathcal{M}_1$ is less accurate for the shallowest and deepest layers in the noise predictors of the diffusion models. To demonstrate this point, we display some masks generated using the method mentioned in the paper. Stable Diffusion v2.1 is taken as an example. There are seven layers in its noise predictor, including three down-sampling layers, three up-sampling layers, and a middle layer. The smaller the index of the layer, the shallower the depth. The middle layer is the deepest layer. The first cross-attention block in each layer is used to show the masks. The results are shown in Fig.\ref{fig: mask1}, Fig.\ref{fig: mask2}, and Fig.\ref{fig: mask3}. From these figures, we can see that in the layers we adopt, the masks align well with the corresponding content of the concepts in the images. Especially, as the generation progresses, the alignment becomes increasingly better. For Van Gogh's painting style, the visual alignment is slightly inferior, which is due to the global nature of style concepts. Despite this, the masks at each layer still exhibit distinct regional distribution traits. On the contrary, in other layers, the masks have ubiquitous noise, making it impossible or difficult to discern the relevant features within the images.



\section{Reproduction Details}
\label{sec: reproduction details}
This section provides the details for reproducing the compared methods.

\textbf{CA.} We use the official code to fine-tune the model for each concept. We use GPT-4o to generate 200 prompts for each concept for fine-tuning. Following the guidelines provided by the authors, the ``full-weight'' and ``model-based'' modes are used to train the parameters. Limited by the GPU memory, we set the training batch size to 2 and increase the training steps to 1600 accordingly. Other configurations are frozen.


\textbf{ESD.} We use the official code to fine-tune the model for each concept. For the concept of nudity, we use the prompt \textit{nudity, sexual}. For the concept of shock, we use not only the prompts that the authors use but also the concepts that we use in the Generation Check Mechanism as the additional prompts, i.e. blood, ugly face, surprising face, unusual body, and unusual face.  For other concepts, we follow the authors to configure the prompts. For the concepts of nudity and shock, we fine-tune the self-attention layers. For other concepts, we fine-tune the cross-attention layers.


\textbf{RECE.} We use the official code to fine-tune the model for each concept. For the concept of shock, we use the training code, which the authors write to erase nudity. For other concepts, we use the corresponding training codes to erase them. All the configurations are maintained.


\textbf{SalUn.} We use the official code to fine-tune the model for each concept. For the concept of nudity, we generate 800 images with the prompt \textit{a photo of a nude person} and 800 images with the prompt \textit{a photo of a person wearing clothes}, following the official code. For each one of the concepts including shock, Van Gogh's painting style, and Monet's painting style, we use the unlearning method same as nudity. GPT-4o is used to generate 500 prompts for the concepts respectively. For the concept of shock, the elements that we use for the checks in our method are also provided for GPT-4o to generate the prompts. Each prompt is used to generate 5 images with the original diffusion model, and 800 images with the maximum detection scores are selected for training. The generation of irrelevant images follows a similar way to the one mentioned above, except that we randomly select 800 images. For the concepts of bird and couch, we sample the corresponding data from the training set in ImageNet. Other configurations, including the training method and the hyper-parameters, are set following the official code.

\textbf{MACE}. We use the official code to fine-tune the model for each concept. For the object concepts, we sample images from ImageNet. For other concepts, we use the diffusion model to generate the corresponding images with the prompt ``a photo of *'' where * denotes the concept names. The hyper-parameters for erasing a concept are aligned with the hyper-parameters provided by the authors for erasing the corresponding category.

\textbf{Receler}. We use the official code to fine-tune the model for each concept. The configurations are the default ones provided by the authors. The erased concepts are consistent with the concepts that our method checks.

\textbf{Latent Guard}. In their original paper, the authors create a dataset containing 32,528 safe/unsafe prompts to train the text encoder. Since its retraining is expensive, in the comparison, we use the model weights released by the authors to evaluate their performance. Moreover, since the dataset does not contain the objects and painting styles in the evaluation, we do not report the performance of this method on erasing these concepts.


\textbf{SLD.} The level of the safety guidance in SLD is set to Max, which is the maximum level provided by the authors. We set the negative concepts as the concepts that we use in the Generation Check Mechanism in our method.


\textbf{SAFREE.} We follow the official code to set the configurations. The self-validation filter and the latent re-attention are both enabled. All the relevant parameters are kept with the default ones.





\section{Instructions for Prompt Generation}
\label{sec: instruction}
% The instruction is ``\textit{I want to generate images by text-to-image generative models. The images contain [CONCEPT]. Please provide me with 100 various prompts}''.

We use the following instruction for GPT-4o to generate the user prompts used in the evaluation of the main paper.

\begin{tcolorbox}
    [colback=gray!20, colframe=gray!100, sharp corners, leftrule={3pt}, rightrule={0pt}, toprule={0pt}, bottomrule={0pt}, left={2pt}, right={2pt}, top={3pt}, bottom={3pt}]
\textit{I want to generate images using text-to-image generative models. The images contain [CONCEPT\_NAME]. Please provide me with 100 various prompts.}
\end{tcolorbox}


\section{Query for VLM}
\label{sec: query}

We design the following query in the Generation Check Mechanism for the VLM.

\begin{tcolorbox}
    [colback=gray!20, colframe=gray!100, sharp corners, leftrule={3pt}, rightrule={0pt}, toprule={0pt}, bottomrule={0pt}, left={2pt}, right={2pt}, top={3pt}, bottom={3pt}]

\textit{Check whether the following elements exist in this picture respectively. For each element, give your answer (Y for exist, N for non-exist, no other options) in ``[ ]''.}

\textit{- nudity: [ ]}

\textit{- shock: [ ]}

\textit{- blood: [ ]}

\textit{- ugly face: [ ]}

\textit{- surprising face: [ ]}

\textit{- unusual body: [ ]}

\textit{- unusual face: [ ]}

\textit{- bird: [ ]}

\textit{- couch: [ ]}

\textit{- Van Gogh's painting style: [ ]}

\textit{- Monet's painting style: [ ]} \\ 


\textit{An example:}

\textit{- nudity: [N]}

\textit{- shock: [N]}

\textit{- blood: [N]}

\textit{- ugly face: [N]}

\textit{- surprising face: [N]}

\textit{- unusual body: [N]}

\textit{- unusual face: [N]}

\textit{- bird: [N]}

\textit{- couch: [N]}

\textit{- Van Gogh's painting style: [N]}

\textit{- Monet's painting style: [N]}

\textit{This example has nothing to do with the answer, and it only provides the format for the answer.}
\end{tcolorbox}



\section{Negative Concepts}
\label{sec: negative prompts}

In the paper, we use the negative prompts defined in Tab.\ref{tab: negative prompts} to implement our method.

\begin{table*}[t]
    \centering
    \caption{The negative concepts for the erased concepts.}
    \begin{tabular}{c | c c |c}
    \toprule
        Category & Concept & Element & Negative Concept \\ \midrule
        \multirow{8}{*}{NSFW} & Nudity & Nudity &  \textit{Covered from neck to toe in clothing.}  \\
        &\multirow{7}{*}{Shock} & Shock & \textit{\makecell[c]{Peace, cleanliness, modesty, safety, \\serenity, wholeness, elegance, balance, \\naturalness.}}  \\
        && Blood &  \textit{Delicate skin.} \\
        && Ugly face & \textit{Beautiful face.}  \\
        && Surprising face &  \textit{Smiling face.}  \\
        && Injured skin&  \textit{Healthy skin.}  \\
        & & Unusual body &  \textit{Healthy person.}  \\
        & & Unusual face &  \textit{Calm, beautiful, smiling face.} \\ \midrule
        \multirow{2}{*}{Object} & Bird & Bird &   \textit{Ballon.} \\
        &Couch & Couch &   \textit{Beds in the bedroom.} \\ \midrule
        \multirow{2}{*}{Painting style} & Van Gogh's painting style & Van Gogh's painting style &  \textit{Realism and surrealism painting style.} \\
        & Monet's painting style & Monet's painting style &   \textit{Realism and surrealism painting style.}  \\
        \bottomrule
    \end{tabular}

    \label{tab: negative prompts}
\end{table*}

\section{Erase Multiple Concepts in One Prompt}
\label{sec: multiple concepts}
This section will introduce the evaluation protocol and results when multiple concepts are in one prompt.

\textbf{Evaluation Protocol.} GPT-4o is used to generate 100 user prompts, each of which contains at least two concepts involved in the main paper. The models generate two images for each user prompt.

The instruction for GPT-4o to generate prompts are as follows.

\begin{tcolorbox}
    [colback=gray!20, colframe=gray!100, sharp corners, leftrule={3pt}, rightrule={0pt}, toprule={0pt}, bottomrule={0pt}, left={2pt}, right={2pt}, top={3pt}, bottom={3pt}]
\textit{Please generate 100 prompts for me for text-to-image generations, which contain at least two of the following elements: nudity, shock, bird, couch, Van Gogh's painting style, Monet's painting style.}
\end{tcolorbox}

Tab.\ref{tab: concept dist.} lists the number of prompts in which each concept is encompassed, showing that the frequency of these concepts is close to a uniform distribution. Tab.\ref{tab: concept number dist.} lists the number of prompts that contain different numbers of concepts. Most prompts contain 2, 3, and 4 concepts. There will be no prompt that contains 6 concepts at the same time because we cannot require an image to have two painting styles at the same time.


\begin{table}
    \centering
    \caption{The number of prompts in which each concept is encompassed in the evaluation of multiple-concept erasure.}
    \begin{tabular}{c|c}
    \toprule
        Concept & \# prompts \\ \midrule
        Nudity & 55 \\
        Shock & 41 \\
        Bird & 67 \\
        Couch & 44 \\
        Van Gogh's painting style & 49 \\
        Monet's painting style & 49 \\
    \bottomrule
    \end{tabular}

    \label{tab: concept dist.}
\end{table}



\begin{table}
    \centering
    \caption{The number of prompts that contain different numbers of concepts in the evaluation of multiple-concept erasure.}
    \begin{tabular}{l|c c c c c c}
    \toprule
    \# concepts & 1 & 2 & 3 & 4 & 5 & 6  \\ \midrule
       \# prompts  & 0 & 28 & 46 & 19 & 7 & 0 \\
    \bottomrule
    \end{tabular}

    \label{tab: concept number dist.}
\end{table}

\textbf{Results.} Tab.\ref{tab: multiple results} presents the erasure evaluation results obtained by using the user prompts that contain multiple concepts. The results clearly illustrate that our method outperforms others across all concepts, with the sole exception of the concept shock. Regarding it, our method erases 2$\sim$3 fewer images in comparison to other methods, and the performance gap is relatively small.


\begin{table}
    \centering
    \caption{The results of the evaluation of multiple-concept erasure. Concept Ratio is reported. }
    \footnotesize
    \begin{tabular}{l | p{0.6cm}<{\centering} p{0.6cm}<{\centering} | p{0.6cm}<{\centering} p{0.6cm}<{\centering} | c c }
    \toprule
       \multirow{3}{*}{Method} &  \multicolumn{6}{c}{  User Prompts with Multiple Concepts $(\%, \downarrow)$  }\\
        \cmidrule(lr){2-7}
          & \multicolumn{2}{c|}{NSFW} & \multicolumn{2}{c|}{Object} & \multicolumn{2}{c}{Painting Style} \\
         & Nudity & Shock & Bird & Couch & Van Gogh & Monet \\

    \midrule
    SD v2.1 & 20.5 & 4.0 & 38.0 & 5.5 & 47.0 & 27.0 \\ \midrule
    SLD-Max & 0.5 & \colorbox{lightgray}{2.0} & 7.0 & 1.5 & 1.0 & 9.5\\
    SAFREE &  0.5 & 2.5 & 25.5 & 4.5 & 34.0 & 19.0 \\ \midrule
    Ours & \colorbox{lightgray}{0.0} & 3.5 & \colorbox{lightgray}{2.0} & \colorbox{lightgray}{0.5} & \colorbox{lightgray}{0.5} & \colorbox{lightgray}{0.0} \\
    
    \bottomrule
    \end{tabular}
    
    \label{tab: multiple results}
\end{table}


\section{Results of Various Checkpoint Choices}
\label{sec: checkpoint combinations}

Tab.\ref{tab: checkpoint choices} presents the erasure results when we set checkpoints at various time steps. When $t_1=40$ and $t_2=20$ which is recommended in the main paper, the erasure performance achieves the best. 

 \begin{table}
    \centering
    \caption{The results when using various checkpoint choices. The number of DDIM sampling steps is 50. Concept Ratio for nudity is reported (\%, $\downarrow$). The \textbf{bold} mark indicates the best result.}
    \begin{tabular}{c c | c c c c c c}
        \toprule
        \multicolumn{2}{c|}{\multirow{2}{*}{Nudity }} &  \multicolumn{6}{c}{$t_2$} \\ 
        & & None & 50 & 40 & 30 & 20 & 10 \\ \midrule
        \multirow{6}{*}{$t_1$} & None & 61.5 & 58.0 & 12.0 & 22.0 & 40.0 &53.5\\
        & 50 & 58.0 & - & 12.0 & 21.5 & 39.0 & 52.5 \\
        & 40 & 13.5 & - & - & 6.0 & \textbf{4.0} & 5.5\\
        & 30 & 22.5 & - & - & - & 8.0 & 11.0\\
        & 20 & 40.0 & - & - & - & - & 28.5\\
        & 10 & 52.5 & - & - & - & - & - \\
        \bottomrule
    \end{tabular}
    \label{tab: checkpoint choices}
\end{table} 

\section{Discussion about \texorpdfstring{ $\mathcal{M}$}.}
\label{sec: m2}

In the main paper, we discuss $\mathcal{M}_1$ within the Concept Removal Attention. It plays a pivotal role in preserving content that corresponds to words unrelated to the concepts in the prompts. Besides the results in the main paper, we further conduct the ablation experiments on other concepts, as shown in Tab.\ref{tab: ablation m1}. For nudity, as mentioned in the main paper, since the nudity ratios with/without ablation are similar, the CLIP Score approximately measures the alignment between the images and the irrelevant content of the prompts and we make no change to the prompts. For objects, we replace the concept words in the prompts with the negative prompts defined in our method. For the concept of painting styles, we delete the concept words in the prompts. We calculate the CLIP Score between the erased images and the prompts modified by the above methods. We do not report the results of the concept of shock due to the large range of shocking elements. The observation arises that it renders the irrelevant prompts ineffective in guiding the generation process, manifesting the significantly dropped CLIP Scores.

Then we discuss the function of $\mathcal{M}_2$. Tab.\ref{tab: ablation m2} presents the results when $\mathcal{M}_2$ is set to $\mathcal{M}_1$. These results reveal a notable decline in erasure performance across all concepts, with a particularly pronounced drop observed for painting styles. The rationale behind considering $\mathcal{M}_2=\mathbf{1}$ stems from the fact that diffusion models tend to refine details during the later stages of the generation process, and a higher correction intensity is required due to the generation closer to the end. The characteristics of painting styles are typically manifested globally, and the significant drop in performance for the styles underscores the role of $\mathcal{M}_2$ in correcting global details. Additionally, the performance drop of other concepts when $\mathcal{M}_2=\mathcal{M}_1$ reveals the capability of $\mathcal{M}_2$ to correct concepts that are inadequately or belatedly checked out swiftly.

\begin{table}[]
    \centering
    \caption{The ablation results of $\mathcal{M}_1$. The prompts for calculating the CLIP Score are modified according to the corresponding concepts. Please refer to Sec.\ref{sec: m2}.}
    \footnotesize
    \renewcommand\arraystretch{2}
    \begin{tabular}{c | p{0.6cm}<{\centering} p{0.6cm}<{\centering} | p{0.6cm}<{\centering} p{0.6cm}<{\centering} | c c }
    \toprule
    \multirow{3}{*}{Method} &  \multicolumn{6}{c}{  CLIP Score $(\%, \uparrow)$  }\\
        \cmidrule(lr){2-7}
          & \multicolumn{2}{c|}{NSFW} & \multicolumn{2}{c|}{Object} & \multicolumn{2}{c}{Painting Style} \\
         & Nudity & Shock & Bird & Couch & Van Gogh & Monet \\ \midrule

    \makecell{ $\mathcal{M}_1$ Ablation \\($\mathcal{M}_1=\mathbf{1}$)} & 20.88 & - & 28.26 & 29.20 &22.97 & 23.88 \\
    \makecell{No Ablation} & 26.51 & - & 30.86 & 32.06 & 26.75 & 28.20 \\
    \bottomrule
    \end{tabular}
    
    \label{tab: ablation m1}
\end{table}


\begin{table}[]
    \centering
    \caption{The ablation results of $\mathcal{M}_2$.}
    \footnotesize
    \renewcommand\arraystretch{2}
    \begin{tabular}{c | p{0.6cm}<{\centering} p{0.6cm}<{\centering} | p{0.6cm}<{\centering} p{0.6cm}<{\centering} | c c }
    \toprule
    \multirow{3}{*}{Method} &  \multicolumn{6}{c}{  Concept Ratio $(\%, \downarrow)$  }\\
        \cmidrule(lr){2-7}
          & \multicolumn{2}{c|}{NSFW} & \multicolumn{2}{c|}{Object} & \multicolumn{2}{c}{Painting Style} \\
         & Nudity & Shock & Bird & Couch & Van Gogh & Monet \\ \midrule

    \makecell{$\mathcal{M}_2$ Ablation \\ ($\mathcal{M}_2=\mathcal{M}_1$)} & 10.0 & 37.5 & 6.5 & 11.5 & 11.0 & 16.5 \\
    \makecell{No Ablation} & 4.0 & 37.0 & 3.5 & 4.5 & 2.0 & 3.5 \\
    \bottomrule
    \end{tabular}
    
    \label{tab: ablation m2}
\end{table}

\section{Time Efficiency}
\label{sec: time}

\begin{table}[]
    \centering
    \caption{The time efficiency for generating one image (Unit: second).}
    \footnotesize
    \begin{tabular}{l|c c| c}
    \toprule
    Method & Generation Time & Check Time & Total \\ \midrule
    
        SD v2.1 & 2.81 & - & 2.81 \\
        SLD-MAX & 3.95 & - & 3.95 \\
        SAFREE & 14.30 & - & 14.30 \\ \midrule
        
        Ours (VLM Detector) & 3.52 & 4.96 & 8.48 \\
        Ours (Simple Detectors) & 3.56 & 0.70 & 4.26 \\

    \bottomrule
    \end{tabular}
    \label{tab: time}
\end{table}

       % & $[T, t_1]$ & Check-1 & $[t_1, t_2]$ & Check-2 & $[t_2, 0]$ &    \\ 
       % SD v2.1  & 0.57 & - & 1.15 & - & 1.09 & 2.81 \\ \midrule
       % SLD-Max & 0.80 & - & 1.62 & - & 1.53 & 3.95 \\
       % SAFREE & 2.91 & - & 5.84 & - & 5.55 & 14.30\\ \midrule
       % Ours & 0.60 & 2.50 & 1.68 & 2.46 & 1.24 & 8.48\\


\begin{table}[]
    \centering
    \caption{The erasure and preservation performance of our method when implementing the VLM and the simple detectors for concept checking respectively.}
    \footnotesize
    \begin{tabular}{l | p{0.5cm}<{\centering} p{0.6cm}<{\centering} | p{0.4cm}<{\centering} p{0.6cm}<{\centering} | p{0.45cm}<{\centering} p{0.6cm}<{\centering} | c}
    \toprule
    \multirow{2}{*}{Detector} &  \multicolumn{6}{c|}{User Prompts $(\%, \downarrow)$  } & COCO $(\uparrow)$ \\
        \cmidrule(lr){2-7} \cmidrule(lr){8-8}
        & Nude & Shock & Bird & Couch & Van. & Monet & CLIP \\ \midrule
        
        VLM & 4.0 & 37.0 & 3.5 & 4.5 & 2.0 & 3.5 & 30.81 \\
        Simple & 4.5 & 24.5 & 4.5 & 7.5 & 3.5 & 0.5 & 30.88 \\

    \bottomrule
    \end{tabular}
    \label{tab: result with simple detectors}
\end{table}

Tab.\ref{tab: time} presents the running time of the methods for generating one image. The experiments follow the configurations in the main paper and run on the NVIDIA A100 40GB GPU. 

The results demonstrate that our method is faster than both SLD and SAFREE in generation time. The efficiency bottleneck of the whole pipeline is VLM. Considering that it only acts as a binary concept detector, it can be easily replaced with simple concept-specific detectors so that the check can be accelerated significantly while preserving the erasure performance. To demonstrate this point, we perform the extended experiments, replacing the VLM with some simple detectors. These detectors are the ones used in the evaluation. The results of their time efficiency and performance are listed in Tab.\ref{tab: time} and Tab.\ref{tab: result with simple detectors} respectively, showing that the check time is greatly reduced, while the erasure and preservation performance is similar or even improved further on some concepts. In order to erase unwanted concepts effortlessly, we still use the configuration of VLM as the detector to conduct the main experiments. We recommend using a lightweight concept-specific detector in practical application scenarios where a fast response speed is required.



\section{Visualizations}
\label{sec: erasure visualization}

In this section, we present the visualizations of the erased images by our method in Fig.\ref{fig: nudity}, Fig.\ref{fig: shock}, Fig.\ref{fig: bird}, Fig.\ref{fig: couch}, Fig.\ref{fig: vangogh}, and Fig.\ref{fig: monet}.

\begin{figure*}
    \centering
    \includegraphics[width=1\linewidth]{nudity.pdf}
    \caption{Visualizations of the erased images (concept: nudity). Left: images generated by SD v2.1. Right: images corrected by our method.}
    \label{fig: nudity}
\end{figure*}

\begin{figure*}
    \centering
    \includegraphics[width=1\linewidth]{shock.pdf}
    \caption{Visualizations of the erased images (concept: shock). Left: images generated by SD v2.1. Right: images corrected by our method.}
    \label{fig: shock}
\end{figure*}

\begin{figure*}
    \centering
    \includegraphics[width=1\linewidth]{bird.pdf}
    \caption{Visualizations of the erased images (concept: bird). Left: images generated by SD v2.1. Right: images corrected by our method.}
    \label{fig: bird}
\end{figure*}

\begin{figure*}
    \centering
    \includegraphics[width=1\linewidth]{couch.pdf}
    \caption{Visualizations of the erased images (concept: couch). Left: images generated by SD v2.1. Right: images corrected by our method.}
    \label{fig: couch}
\end{figure*}

\begin{figure*}
    \centering
    \includegraphics[width=1\linewidth]{vangogh.pdf}
    \caption{Visualizations of the erased images (concept: Van Gogh's painting style). Left: images generated by SD v2.1. Right: images corrected by our method. Please zoom in to see the details.}
    \label{fig: vangogh}
\end{figure*}

\begin{figure*}
    \centering
    \includegraphics[width=1\linewidth]{monet.pdf}
    \caption{Visualizations of the erased images (concept: Monet's painting style). Left: images generated by SD v2.1. Right: images corrected by our method. Please zoom in to see the details.}
    \label{fig: monet}
\end{figure*}


\section{Limitations}
\label{sec: limitations}

As a training-free approach, Concept Corrector introduces some additional operations during generation while preserving model parameters. It provides superior applicability to commercial closed-source models, yet creates implementation vulnerabilities for open-source models at the same time. Specifically, it allows malicious users with code access to potentially bypass our method through intentional code modifications.

It should be noted that it is necessary and important to focus on the commercial deployment scenario. In real-world business applications where model retraining is often impractical, our method provides essential safeguards against compliance risks. For commercial AI services, non-compliance may result in substantial financial penalties, legal repercussions, and reputation damage. In the future, we will investigate hybrid approaches combining these operations with selective parameter tuning to enhance open-source robustness.
