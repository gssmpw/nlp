@String(PAMI = {IEEE Trans. Pattern Anal. Mach. Intell.})
@String(IJCV = {Int. J. Comput. Vis.})
@String(CVPR= {IEEE Conf. Comput. Vis. Pattern Recog.})
@String(ICCV= {Int. Conf. Comput. Vis.})
@String(ECCV= {Eur. Conf. Comput. Vis.})
@String(NIPS= {Adv. Neural Inform. Process. Syst.})
@String(ICPR = {Int. Conf. Pattern Recog.})
@String(BMVC= {Brit. Mach. Vis. Conf.})
@String(TOG= {ACM Trans. Graph.})
@String(TIP  = {IEEE Trans. Image Process.})
@String(TVCG  = {IEEE Trans. Vis. Comput. Graph.})
@String(TMM  = {IEEE Trans. Multimedia})
@String(ACMMM= {ACM Int. Conf. Multimedia})
@String(ICME = {Int. Conf. Multimedia and Expo})
@String(ICASSP=	{ICASSP})
@String(ICIP = {IEEE Int. Conf. Image Process.})
@String(ACCV  = {ACCV})
@String(ICLR = {Int. Conf. Learn. Represent.})
@String(IJCAI = {IJCAI})
@String(PR   = {Pattern Recognition})
@String(AAAI = {AAAI})
@String(CVPRW= {IEEE Conf. Comput. Vis. Pattern Recog. Worksh.})
@String(CSVT = {IEEE Trans. Circuit Syst. Video Technol.})

@String(SPL	= {IEEE Sign. Process. Letters})
@String(VR   = {Vis. Res.})
@String(JOV	 = {J. Vis.})
@String(TVC  = {The Vis. Comput.})
@String(JCST  = {J. Comput. Sci. Tech.})
@String(CGF  = {Comput. Graph. Forum})
@String(CVM = {Computational Visual Media})


@String(PAMI  = {IEEE TPAMI})
@String(IJCV  = {IJCV})
@String(CVPR  = {CVPR})
@String(ICCV  = {ICCV})
@String(ECCV  = {ECCV})
@String(NIPS  = {NeurIPS})
@String(ICPR  = {ICPR})
@String(BMVC  =	{BMVC})
@String(TOG   = {ACM TOG})
@String(TIP   = {IEEE TIP})
@String(TVCG  = {IEEE TVCG})
@String(TCSVT = {IEEE TCSVT})
@String(TMM   =	{IEEE TMM})
@String(ACMMM = {ACM MM})
@String(ICME  =	{ICME})
@String(ICASSP=	{ICASSP})
@String(ICIP  = {ICIP})
@String(ACCV  = {ACCV})
@String(ICLR  = {ICLR})
@String(IJCAI = {IJCAI})
@String(PR = {PR})
@String(AAAI = {AAAI})
@String(CVPRW= {CVPRW})
@String(CSVT = {IEEE TCSVT})

@inproceedings{rombach2022high,
  title={High-resolution image synthesis with latent diffusion models},
  author={Rombach, Robin and Blattmann, Andreas and Lorenz, Dominik and Esser, Patrick and Ommer, Bj{\"o}rn},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={10684--10695},
  year={2022}
}

@article{saharia2022photorealistic,
  title={Photorealistic text-to-image diffusion models with deep language understanding},
  author={Saharia, Chitwan and Chan, William and Saxena, Saurabh and Li, Lala and Whang, Jay and Denton, Emily L and Ghasemipour, Kamyar and Gontijo Lopes, Raphael and Karagol Ayan, Burcu and Salimans, Tim and others},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={36479--36494},
  year={2022}
}

@inproceedings{nichol2021glide,
  title={{GLIDE}: Towards photorealistic image generation and editing with text-guided diffusion models},
  author={Nichol, Alex and Dhariwal, Prafulla and Ramesh, Aditya and Shyam, Pranav and Mishkin, Pamela and McGrew, Bob and Sutskever, Ilya and Chen, Mark},
  booktitle={International Conference on Machine Learning},
  pages={16784-16804},
  year={2022}
}


@inproceedings{ruiz2023dreambooth,
  title={Dreambooth: Fine tuning text-to-image diffusion models for subject-driven generation},
  author={Ruiz, Nataniel and Li, Yuanzhen and Jampani, Varun and Pritch, Yael and Rubinstein, Michael and Aberman, Kfir},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={22500--22510},
  year={2023}
}

@inproceedings{gal2022image,
  title={An image is worth one word: Personalizing text-to-image generation using textual inversion},
  author={Gal, Rinon and Alaluf, Yuval and Atzmon, Yuval and Patashnik, Or and Bermano, Amit H and Chechik, Gal and Cohen-Or, Daniel},
  booktitle={International Conference on Learning Representations},
  year={2022}
}


@inproceedings{mou2024t2i,
  title={{T2I-Adapter}: Learning adapters to dig out more controllable ability for text-to-image diffusion models},
  author={Mou, Chong and Wang, Xintao and Xie, Liangbin and Wu, Yanze and Zhang, Jian and Qi, Zhongang and Shan, Ying},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={38},
  number={5},
  pages={4296--4304},
  year={2024}
}

@article{zhang2023text,
  title={Text-to-image diffusion models in generative ai: A survey},
  author={Zhang, Chenshuang and Zhang, Chaoning and Zhang, Mengchun and Kweon, In So},
  journal={arXiv preprint arXiv:2303.07909},
  year={2023}
}

@article{cao2024controllable,
  title={Controllable generation with text-to-image diffusion models: A survey},
  author={Cao, Pu and Zhou, Feng and Song, Qing and Yang, Lu},
  journal={arXiv preprint arXiv:2403.04279},
  year={2024}
}


@inproceedings{qu2023unsafe,
  title={Unsafe diffusion: On the generation of unsafe images and hateful memes from text-to-image models},
  author={Qu, Yiting and Shen, Xinyue and He, Xinlei and Backes, Michael and Zannettou, Savvas and Zhang, Yang},
  booktitle={Proceedings of the 2023 ACM SIGSAC Conference on Computer and Communications Security},
  pages={3403--3417},
  year={2023}
}

% methods
% 微调分布
@inproceedings{gandikota2023erasing,
  title={Erasing concepts from diffusion models},
  author={Gandikota, Rohit and Materzynska, Joanna and Fiotto-Kaufman, Jaden and Bau, David},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={2426--2436},
  year={2023}
}

@inproceedings{kumari2023ablating,
  title={Ablating concepts in text-to-image diffusion models},
  author={Kumari, Nupur and Zhang, Bingliang and Wang, Sheng-Yu and Shechtman, Eli and Zhang, Richard and Zhu, Jun-Yan},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={22691--22702},
  year={2023}
}
@article{bui2024removing,
  title={Removing undesirable concepts in text-to-image generative models with learnable prompts},
  author={Bui, Anh and Doan, Khanh and Le, Trung and Montague, Paul and Abraham, Tamas and Phung, Dinh},
  journal={arXiv preprint arXiv:2403.12326},
  year={2024}
}

@article{meng2024dark,
  title={Dark Miner: Defend against unsafe generation for text-to-image diffusion models},
  author={Meng, Zheling and Peng, Bo and Jin, Xiaochuan and Jiang, Yue and Dong, Jing and Wang, Wei and Tan, Tieniu},
  journal={arXiv preprint arXiv:2409.17682},
  year={2024}
}

# 抑制交叉注意力图的激活
@inproceedings{zhang2023forget,
  title={Forget-me-not: Learning to forget in text-to-image diffusion models},
  author={Zhang, Gong and Wang, Kai and Xu, Xingqian and Wang, Zhangyang and Shi, Humphrey},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={1755--1764},
  year={2024}
}


% 权重编辑，闭式解析解
@inproceedings{gandikota2024unified,
  title={Unified concept editing in diffusion models},
  author={Gandikota, Rohit and Orgad, Hadas and Belinkov, Yonatan and Materzy{\'n}ska, Joanna and Bau, David},
  booktitle={Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision},
  pages={5111--5120},
  year={2024}
}
@inproceedings{lu2024mace,
  title={Mace: Mass concept erasure in diffusion models},
  author={Lu, Shilin and Wang, Zilan and Li, Leyang and Liu, Yanzhu and Kong, Adams Wai-Kin},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={6430--6440},
  year={2024}
}

@article{gong2024reliable,
  title={Reliable and efficient concept erasure of text-to-image diffusion models},
  author={Gong, Chao and Chen, Kai and Wei, Zhipeng and Chen, Jingjing and Jiang, Yu-Gang},
  journal={arXiv preprint arXiv:2407.12383},
  year={2024}
}

% 鲁棒性
@article{pham2024robust,
  title={Robust concept erasure using task vectors},
  author={Pham, Minh and Marshall, Kelly O and Hegde, Chinmay and Cohen, Niv},
  journal={arXiv preprint arXiv:2404.03631},
  year={2024}
}
@article{kim2024race,
  title={{RACE}: Robust adversarial concept erasure for secure text-to-image diffusion model},
  author={Kim, Changhoon and Min, Kyle and Yang, Yezhou},
  journal={arXiv preprint arXiv:2405.16341},
  year={2024}
}

@article{zhang2024defensive,
  title={Defensive unlearning with adversarial training for robust concept erasure in diffusion models},
  author={Zhang, Yimeng and Chen, Xin and Jia, Jinghan and Zhang, Yihua and Fan, Chongyu and Liu, Jiancheng and Hong, Mingyi and Ding, Ke and Liu, Sijia},
  journal={arXiv preprint arXiv:2405.15234},
  year={2024}
}

@article{huang2023receler,
  title={Receler: Reliable concept erasing of text-to-image diffusion models via lightweight erasers},
  author={Huang, Chi-Pin and Chang, Kai-Po and Tsai, Chung-Ting and Lai, Yung-Hsuan and Wang, Yu-Chiang Frank},
  journal={arXiv preprint arXiv:2311.17717},
  year={2023}
}




% 权重消融
@inproceedings{fan2023salun,
  title={{SalUn}: Empowering machine unlearning via gradient-based weight saliency in both image classification and generation},
  author={Fan, Chongyu and Liu, Jiancheng and Zhang, Yihua and Wei, Dennis and Wong, Eric and Liu, Sijia},
  booktitle={International Conference on Learning Representations},
  year={2024}
}
@article{yang2024pruning,
  title={Pruning for robust concept erasing in diffusion models},
  author={Yang, Tianyun and Cao, Juan and Xu, Chang},
  journal={arXiv preprint arXiv:2405.16534},
  year={2024}
}

@article{chavhan2024conceptprune,
  title={{ConceptPrune}: Concept editing in diffusion models via skilled neuron pruning},
  author={Chavhan, Ruchika and Li, Da and Hospedales, Timothy},
  journal={arXiv preprint arXiv:2405.19237},
  year={2024}
}

% 纯文本
@inproceedings{liu2025latent,
  title={Latent guard: A safety framework for text-to-image generation},
  author={Liu, Runtao and Khakzar, Ashkan and Gu, Jindong and Chen, Qifeng and Torr, Philip and Pizzati, Fabio},
  booktitle={European Conference on Computer Vision},
  pages={93--109},
  year={2024}
}
@article{yang2024guardt2i,
  title={{GuardT2I}: Defending Text-to-Image Models from Adversarial Prompts},
  author={Yang, Yijun and Gao, Ruiyuan and Yang, Xiao and Zhong, Jianyuan and Xu, Qiang},
  journal={arXiv preprint arXiv:2403.01446},
  year={2024}
}

% 不训练
@inproceedings{schramowski2023safe,
  title={Safe latent diffusion: Mitigating inappropriate degeneration in diffusion models},
  author={Schramowski, Patrick and Brack, Manuel and Deiseroth, Bj{\"o}rn and Kersting, Kristian},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={22522--22531},
  year={2023}
}

@article{yoon2024safree,
  title={{SAFREE}: Training-free and adaptive guard for safe text-to-image and video generation},
  author={Yoon, Jaehong and Yu, Shoubin and Patil, Vaidehi and Yao, Huaxiu and Bansal, Mohit},
  journal={arXiv preprint arXiv:2410.12761},
  year={2024}
}



% attacks

@inproceedings{yang2024mma,
  title={{MMA-Diffusion}: Multimodal attack on diffusion models},
  author={Yang, Yijun and Gao, Ruiyuan and Wang, Xiaosen and Ho, Tsung-Yi and Xu, Nan and Xu, Qiang},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={7737--7746},
  year={2024}
}


@inproceedings{chin2023prompting4debugging,
  title={{Prompting4Debugging}: Red-teaming text-to-image diffusion models by finding problematic prompts},
  author={Chin, Zhi-Yi and Jiang, Chieh Ming and Huang, Ching-Chun and Chen, Pin-Yu and Chiu, Wei-Chen},
  booktitle={International Conference on Machine Learning},
  year={2024}
}


@inproceedings{zhang2023generate,
  title={To generate or not? Safety-driven unlearned diffusion models are still easy to generate unsafe images... for now},
  author={Zhang, Yimeng and Jia, Jinghan and Chen, Xin and Chen, Aochuan and Zhang, Yihua and Liu, Jiancheng and Ding, Ke and Liu, Sijia},
  booktitle={European Conference on Computer Vision},
  pages={385--403},
  year={2024}
}

@inproceedings{tsai2023ring,
  title={{Ring-A-Bell}! {How} reliable are concept removal methods for diffusion models?},
  author={Tsai, Yu-Lin and Hsu, Chia-Yi and Xie, Chulin and Lin, Chih-Hsun and Chen, Jia-You and Li, Bo and Chen, Pin-Yu and Yu, Chia-Mu and Huang, Chun-Ying},
  booktitle={International Conference on Learning Representations},
  year={2024}
}


@inproceedings{hu2021lora,
  title={{LoRA}: Low-rank adaptation of large language models},
  author={Hu, Edward J and Shen, Yelong and Wallis, Phillip and Allen-Zhu, Zeyuan and Li, Yuanzhi and Wang, Shean and Wang, Lu and Chen, Weizhu},
  booktitle={International Conference on Learning Representations},
  year={2021}
}


@inproceedings{wang2022finding,
  title={Finding skill neurons in pre-trained transformer-based language models},
  author={Wang, Xiaozhi and Wen, Kaiyue and Zhang, Zhengyan and Hou, Lei and Liu, Zhiyuan and Li, Juanzi},
  booktitle={Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing},
  pages={11132--11152},
  year={2022}
}



@inproceedings{sohl2015deep,
  title={Deep unsupervised learning using nonequilibrium thermodynamics},
  author={Sohl-Dickstein, Jascha and Weiss, Eric and Maheswaranathan, Niru and Ganguli, Surya},
  booktitle={International Conference on Machine Learning},
  pages={2256--2265},
  year={2015}
}



@article{ho2020denoising,
  title={Denoising diffusion probabilistic models},
  author={Ho, Jonathan and Jain, Ajay and Abbeel, Pieter},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={6840--6851},
  year={2020}
}


@inproceedings{ho2021classifier,
  title={Classifier-Free Diffusion Guidance},
  author={Ho, Jonathan and Salimans, Tim},
  booktitle={NeurIPS 2021 Workshop on Deep Generative Models and Downstream Applications},
  year={2021}
}


@article{jung2024latent,
  title={Latent inversion with timestep-aware sampling for training-free non-rigid editing},
  author={Jung, Yunji and Lee, Seokju and Djanibekov, Tair and Shim, Hyunjung and Ye, Jong Chul},
  journal={arXiv preprint arXiv:2402.08601},
  year={2024}
}

@inproceedings{choi2022perception,
  title={Perception prioritized training of diffusion models},
  author={Choi, Jooyoung and Lee, Jungbeom and Shin, Chaehun and Kim, Sungwon and Kim, Hyunwoo and Yoon, Sungroh},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={11472--11481},
  year={2022}
}

@article{du2022survey,
  title={A survey of vision-language pre-trained models},
  author={Du, Yifan and Liu, Zikang and Li, Junyi and Zhao, Wayne Xin},
  journal={arXiv preprint arXiv:2202.10936},
  year={2022}
}

@article{li2024llava,
  title={Llava-onevision: Easy visual task transfer},
  author={Li, Bo and Zhang, Yuanhan and Guo, Dong and Zhang, Renrui and Li, Feng and Zhang, Hao and Zhang, Kaichen and Li, Yanwei and Liu, Ziwei and Li, Chunyuan},
  journal={arXiv preprint arXiv:2408.03326},
  year={2024}
}


@inproceedings{dong2022survey,
  title={A survey on in-context learning},
  author={Dong, Qingxiu and Li, Lei and Dai, Damai and Zheng, Ce and Ma, Jingyuan and Li, Rui and Xia, Heming and Xu, Jingjing and Wu, Zhiyong and Chang, Baobao and others},
  booktitle={Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing},
  pages={1107--1128},
  year={2024}
}

@inproceedings{ronneberger2015u,
  title={{U-Net}: Convolutional networks for biomedical image segmentation},
  author={Ronneberger, Olaf and Fischer, Philipp and Brox, Thomas},
  booktitle={Medical Image Computing and Computer-Assisted Intervention},
  pages={234--241},
  year={2015}
}

@inproceedings{songdenoising,
  title={Denoising diffusion implicit models},
  author={Song, Jiaming and Meng, Chenlin and Ermon, Stefano},
  booktitle={International Conference on Learning Representations}
}

@article{achiam2023gpt,
  title={Gpt-4 technical report},
  author={Achiam, Josh and Adler, Steven and Agarwal, Sandhini and Ahmad, Lama and Akkaya, Ilge and Aleman, Florencia Leoni and Almeida, Diogo and Altenschmidt, Janko and Altman, Sam and Anadkat, Shyamal and others},
  journal={arXiv preprint arXiv:2303.08774},
  year={2023}
}

@inproceedings{schramowski2022can,
  title={Can machines help us answer question 16 in datasheets, and in turn reflect on inappropriate content?},
  author={Schramowski, Patrick and Tauchmann, Christopher and Kersting, Kristian},
  booktitle={Proceedings of the 2022 ACM Conference on Fairness, Accountability, and Transparency},
  pages={1350--1361},
  year={2022}
}


@misc{nudenet,
  author = {NotAI-Tech},
  title = {{NudeNet}},
  year = {2024},
  publisher = {GitHub},
  journal = {GitHub repository},
  howpublished = {\url{https://github.com/notAI-tech/NudeNet}}
}

@article{zhang2024unlearncanvas,
  title={UnlearnCanvas: A Stylized Image Dataset to Benchmark Machine Unlearning for Diffusion Models},
  author={Zhang, Yihua and Zhang, Yimeng and Yao, Yuguang and Jia, Jinghan and Liu, Jiancheng and Liu, Xiaoming and Liu, Sijia},
  journal={arXiv preprint arXiv:2402.11846},
  year={2024}
}

@inproceedings{radford2021learning,
  title={Learning transferable visual models from natural language supervision},
  author={Radford, Alec and Kim, Jong Wook and Hallacy, Chris and Ramesh, Aditya and Goh, Gabriel and Agarwal, Sandhini and Sastry, Girish and Askell, Amanda and Mishkin, Pamela and Clark, Jack and others},
  booktitle={International Conference on Machine Learning},
  pages={8748--8763},
  year={2021}
}

@inproceedings{lin2014microsoft,
  title={{Microsoft COCO}: Common objects in context},
  author={Lin, Tsung-Yi and Maire, Michael and Belongie, Serge and Hays, James and Perona, Pietro and Ramanan, Deva and Doll{\'a}r, Piotr and Zitnick, C Lawrence},
  booktitle={European Conference on Computer Vision},
  pages={740--755},
  year={2014}
}

@article{schuhmann2022laion,
  title={Laion-5b: An open large-scale dataset for training next generation image-text models},
  author={Schuhmann, Christoph and Beaumont, Romain and Vencu, Richard and Gordon, Cade and Wightman, Ross and Cherti, Mehdi and Coombes, Theo and Katta, Aarush and Mullis, Clayton and Wortsman, Mitchell and others},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={25278--25294},
  year={2022}
}

@inproceedings{2023ImageReward,
 author = {Xu, Jiazheng and Liu, Xiao and Wu, Yuchen and Tong, Yuxuan and Li, Qinkai and Ding, Ming and Tang, Jie and Dong, Yuxiao},
 booktitle = {Advances in Neural Information Processing Systems},
 pages = {15903--15935},
 title = {{ImageReward}: Learning and evaluating human preferences for text-to-image generation},
 volume = {36},
 year = {2023}
}


@inproceedings{chenpixart,
  title={{PixArt-alpha}: Fast Training of Diffusion Transformer for Photorealistic Text-to-Image Synthesis},
  author={Chen, Junsong and Jincheng, YU and Chongjian, GE and Yao, Lewei and Xie, Enze and Wang, Zhongdao and Kwok, James and Luo, Ping and Lu, Huchuan and Li, Zhenguo},
  booktitle={International Conference on Learning Representations},
  year = {2024}
}


@article{li2024playground,
  title={{PlayGround} v2.5: Three insights towards enhancing aesthetic quality in text-to-image generation},
  author={Li, Daiqing and Kamko, Aleks and Akhgari, Ehsan and Sabet, Ali and Xu, Linmiao and Doshi, Suhail},
  journal={arXiv preprint arXiv:2402.17245},
  year={2024}
}


@article{zhao2024unipc,
  title={{UniPC}: A unified predictor-corrector framework for fast sampling of diffusion models},
  author={Zhao, Wenliang and Bai, Lujia and Rao, Yongming and Zhou, Jie and Lu, Jiwen},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
 pages = {49842--49869},
  year={2024}
}



@article{lu2022dpm,
  title={{DPM-Solver}: A fast ode solver for diffusion probabilistic model sampling in around 10 steps},
  author={Lu, Cheng and Zhou, Yuhao and Bao, Fan and Chen, Jianfei and Li, Chongxuan and Zhu, Jun},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={5775--5787},
  year={2022}
}

@inproceedings{lu2022dpm++,
  title={Dpm-solver++: Fast solver for guided sampling of diffusion probabilistic models},
  author={Lu, Cheng and Zhou, Yuhao and Bao, Fan and Chen, Jianfei and Li, Chongxuan and Zhu, Jun},
  booktitle={International Conference on Learning Representations},
  year = {2023}
}


@article{karras2022elucidating,
  title={Elucidating the design space of diffusion-based generative models},
  author={Karras, Tero and Aittala, Miika and Aila, Timo and Laine, Samuli},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={26565--26577},
  year={2022}
}





@inproceedings{hertzprompt,
  title={Prompt-to-Prompt Image Editing with Cross-Attention Control},
  author={Hertz, Amir and Mokady, Ron and Tenenbaum, Jay and Aberman, Kfir and Pritch, Yael and Cohen-or, Daniel},
  booktitle={The Eleventh International Conference on Learning Representations}
}
