\section{Related Work}

% \ajnote{
% \begin{itemize}
%     \item  prediction (transformer-based, MTR) and planning (mostly optimization method?)
%     \item diffusion model and consistency models
%     \item diffusion model for trajectory generation/traffic simulation
% \end{itemize}
% }

% Traditionally, trajectory planning and prediction are often implemented as separate modules in autonomous driving systems.
For trajectory predictions, data-driven methods have shown promising results when trained on large-scale real-world human driving datasets such as Waymo Open Motion Dataset (WOMD) \citep{ettinger2021large}, INTERACTION Dataset \citep{zhan2019interaction}, Argoverse \citep{chang2019argoverse} or nuScenes \citep{caesar2020nuscenes}.
Graph Neural Networks have been used to model the semantic information in traffic scenarios for interactive prediction \citep{hu2022scenario}.
Generative models like Variational Autoencoders and Diffusion Models have also been utilized for multimodal trajectory prediction tasks \citep{salzmann2020trajectron++,jiang2023motiondiffuser}.
Recently, transformers \citep{vaswani2017attention}, particularly Motion Transformers (MTR) \citep{shi2022motion,shi2024mtr++,li2024adaptive} with encoder-decoder architectures, have achieved state-of-the-art results in trajectory prediction \citep{waymo2024motion}.

In trajectory planning, the goal is to determine a feasible and efficient path for the ego vehicle, based on observations of the environment and surrounding agents.
This task is often formulated as a numerical optimization problem, typically decomposed path planning and speed planning to facilitate real-time operation in dynamic environments \citep{xu2012real,xu2021autonomous,anon2024multi}.
Game-theoretic approaches have been explored to model agent interactions \citep{sadigh2016planning}, with efficient computation \citep{fisac2019hierarchical} that considers imperfect traffic agents \citep{tian2021anytime}, safe actions \citep{tian2022safety}, and uncertainty reduction in the estimates of agent behaviors \citep{hu2024active}.  
% \citep{sadigh2016planning,fisac2019hierarchical,tian2021anytime,tian2022safety,hu2024active}.
% Sadigh modeled other agent behavior. 
% Fisac addressed computation with hierarchical decomposition.
% Tian accommodates imperfect actors
% Tian also restrict safe actions
% Hu active uncertainty reduction in estimating the other agents

% \ajnote{Briefly mention previously added references? DRL, NNMPC, Lin, etc}
Beyond standalone planning, preliminary effort has been made to integrate trajectory predictions into planner design for collision avoidance \citep{li2021prediction} and proactive motion planning \cite{bae2022lane, saxena2020driving, song2024efficient}. 
While the aforementioned methods have advanced trajectory prediction and planning performance in dense environments, to our best knowledge, none
% \ajnote{I am not of aware any so I re-phrase it to this. Others can check this?}
% \bae{Do you have any reference for the existing ``very few approaches''? Or do you mean there is no?}
have attempted to unify these two to achieve \textit{human-like} interactive behavior with computational efficiency. 
Instead, our work addresses this gap by presenting a data-driven framework for end-to-end joint prediction and planning with a single inference.

Diffusion models \citep{sohl2015deep,song2020score,ho2020denoising} are generative models capable of producing high-quality samples from complex distributions, initially achieving success in image and video generations \citep{rombach2022high,ho2022video}.
The Denoising Diffusion Probabilistic Model (DDPM) \citep{ho2020denoising} gradually corrupts the training data with Gaussian noise and learns to reverse this process through iterative denoising with deep neural networks.
These models commonly use U-Net \citep{ronneberger2015u} or transformer-based architectures \citep{vaswani2017attention} as backbones.
Conditional sampling in diffusion models is enabled by techniques such as classifier guidance \citep{dhariwal2021diffusion} and classifier-free guidance \citep{ho2022classifier}
However, DDPM requires numerous sampling steps to preserve the sample quality, resulting in significant computational costs.
To address this inefficiency, Denoising Diffusion Implicit Models (DDIM) \citep{song2020denoising} introduces a deterministic generation process that balances sampling quality and speed, while progressive distillation \citep{salimans2022progressive} reduces the number of sampling steps by distilling a pre-trained diffusion model into a more efficient one.
Consistency model \citep{song2023consistency,song2023improved} takes a different approach, directly generating
data from noise.
They can be trained through distillation of a pre-trained diffusion model or a standalone consistency training and outperform distillation methods in one- and few-step sampling \citep{song2023consistency}.

Diffusion and consistency models also have shown success in robotics and autonomous systems for their expressiveness and ability to provide samples from complex distributions.
In robotics, conditional diffusion models have been applied to policy learning \citep{janner2022planning,ajay2022conditional,chi2023diffusion}, with consistency models following similar applications \citep{ding2023consistency,prasad2024consistency}.
Diffusion models have also been adopted for trajectory optimization across various robotics tasks \citep{li2024efficient,li2024constraint}.
In autonomous driving, diffusion models have shown promising results in trajectory prediction \citep{jiang2023motiondiffuser,wang2025optimizing} and controllable traffic simulation or scenario generation \citep{zhong2023guided,xu2023diffscene,chang2023controllable,huang2024versatile}, capturing complex interactive behaviors in traffic scenarios.
However, our work differs fundamentally from these efforts: we focus on developing a predictive trajectory planner with consistency models, leveraging guided sampling to incorporate planning constraints.
Unlike scenario generation tasks, where sampling efficiency is less critical, our consistency model-based predictive planner needs significantly shorter sampling steps to deliver high-quality interactive behaviors compared to diffusion models.

% \di{I think both the intro and related work sections are a bit verbose and can be condensed if space is needed}
% \bae{you may consider having a preliminary section that briefly describes methods that our proposal relies on, e.g., MTR, diffusion model, and consistency model -- then you move Section III-A (motion transformer encoder) and refer to the section as needed (same for other methods).}
