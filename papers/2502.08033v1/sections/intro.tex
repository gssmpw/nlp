\section{Introduction}

% \ajnote{
% \begin{itemize}
%     \item prediction and planning are crucial in interactive environments, but often decoupled, and not fully data-driven
%     \item predicting and planning are not very different. Joint distributions encompass interactive behavior, but are hard to model, 
%     \item diffusion-based models shows potential, classifier guidance imposes constraints, but often in traffic simulation not for planning, due to slow
%     \item we propose consistency model
%     \item State major contributions
% \end{itemize}
% }

\begin{figure*}[!t]
    \centering
\includegraphics[width=0.7\textwidth]{figures/workflow.png}
    \caption{The overview of our method.}
    \label{fig:method workflow}
\end{figure*}

To navigate safely and efficiently in a dynamic environment, autonomous vehicles must effectively predict and interact with diverse road participants, including other vehicles, pedestrians, and cyclists.
This typically requires a prediction module to anticipate other agents' future trajectories and a planning module to generate trajectories for the ego vehicle.
While prediction modules have widely adopted data-driven approaches to learn from human-driving data, planning modules typically rely on optimization-based methods.
These two modules usually operate in a decoupled, alternating manner \citep{li2021prediction,chen2023interactive}.

This decoupled method introduces fundamental limitations.
The interactive behavior generated by the planner is inherently reactive rather than proactive, as the planner responds to other agents without accounting for how they might react to the ego vehicle.
This limitation can lead to the computationally expensive theory of mind (TOM) reasoning \citep{thomaz2016computational,devin2016implemented,gupta2023interaction,gupta2024towards}.
In highly interactive scenarios, such as lane merging where proactive nudging is essential, reactive planning may cause the ego vehicle to be stuck \cite{bae2020cooperation, unstuck}.
Existing solutions either struggle to scale with the number of agents \cite{isele2019interactive} or compromise optimality due to a restrictive exploration of the solution search space \cite{song2024efficient}.

% First, the resulting interactive behavior from the planner is inherently reactive rather than proactive, as the planner can only respond to the predictions generated so far without inferring how other agents might react to its planned future actions â€” a limitation that could lead to the computationally expensive theory of mind (TOM) reasoning \citep{thomaz2016computational,devin2016implemented,gupta2023interaction,gupta2024towards}. \bae{one might ask: why is this a limitation? Adding an example would be good, e.g., navigating highly crowded scene where reactive behaviors may result in being stuck.}
% Moreover, the predictor may fail to leverage the ego vehicle's future plan when predicting surrounding agents' future behaviors. \bae{Still not quite a limitation yet. What's the problem of not leveraging the ego vehicle's future plan? Consider enhancing the motivation of "proactive planning". One suggested story line: proactive planning has been actively studied along with its necessity in highly interactive scenarios, such as lane changing in dense traffic, where reactive planning may result in the ego vehicle being stuck [cite DRL and/or NNMPC]. That being said, the existing solutions suffer from scalability with number of players [cite GT] or optimality resulted by a limited sampling sets [cite Lin's paper, DRL, or NNMPC].}

In addition, modular approaches optimize prediction and planning independently, which often leads to less effective behavior compared to jointly trained, end-to-end frameworks \cite{levine2016end}.
The alternation between prediction and planning modules also introduces latency and computational inefficiency, making it challenging to meet the demands of real-time operation.

% While some work has explored incorporating planning of ego vehicle into prediction \citep{song2020pip}, there is a lack of unified, data-driven frameworks that can jointly learn both prediction and planning from human driving data.
% Such a framework will not only facilitate interactive planning but also alleviate the computational burden of iterative alternation between modules, particularly in multi-agent scenarios.


Our key insight is that modeling the joint distribution of future trajectories for both the ego vehicle and surrounding agents can unify prediction and planning into a single, end-to-end framework. 
In this approach, the ego trajectory, informed by the desired goal location, represents the plan, while the trajectories of surrounding agents serve as predictions. 
Additional planning constraints can be imposed on the ego trajectory as needed. 
When trained on large-scale human driving datasets like the Waymo Open Motion Dataset (WOMD) \citep{ettinger2021large}, this joint distribution naturally captures the complex interactive behaviors observed in real-world scenarios.

Diffusion models \citep{song2020score,ho2020denoising} offer a promising method to sample from this high-dimensional, multimodal joint distribution of ego and surrounding agents' trajectories.
They have demonstrated success in generating high-quality images and videos \citep{rombach2022high,ho2022video} or robot trajectories \citep{rempe2023trace,jiang2023motiondiffuser}.
% from complex, high-dimensional distributions.
Moreover, their ability to model conditional distributions makes them well-suited for trajectory planning applications, as it allows for the incorporation of crucial context for planning and prediction, including trajectory history, map information, ego vehicle's goal locations, etc.
Compared to transformers,
diffusion-based method also supports controllable generation to accommodate additional requirements solely at test time through guided sampling, without any additional training.

However, diffusion models typically require many sampling steps to obtain high-quality samples, making it challenging to meet the demands of real-time operations on autonomous vehicles.
To overcome this limitation, consistency models \citep{song2023consistency} are designed to generate data directly from noise in a single step or a small number of steps, significantly improving sampling efficiency without compromising quality. 

In this paper, we present an end-to-end predictive planner based on consistency models, designed to unify planning and prediction within a single data-driven framework.
Our method samples from the conditional joint distribution of ego and surrounding agents' future trajectories, given encoded map and trajectory history along with the ego vehicle's goal configuration. 
While we use a transformer-based scene encoder \citep{shi2022motion} in our implementation, our approach is encoder-agnostic and can integrate with any suitable scene encoder. 
Trained on WOMD \cite{ettinger2021large}, our method ensures proactive trajectory planning by capturing complex interactions between agents observed in the real world.
Additionally, during online testing, planning constraints are incorporated through guided sampling using our proposed alternating direction method for multi-objective guidance.

Experiments demonstrate that our consistency model-based planner generates effective interactive behaviors with other agents, such as nudging and yielding, through a single inference, eliminating the need for iterative alternation between prediction and planning modules.
It outperforms diffusion models by requiring fewer sampling steps while delivering superior trajectory quality.
Compared to transformer-based models, it enables controllable generation through online guided sampling that significantly improves planning constraint satisfaction.
