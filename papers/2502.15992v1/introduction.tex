\section{Introduction}
\label{introduction}





\begin{figure}[t!]
    \centering
\includegraphics[width=1.0\linewidth]{HuGur_Overview_Figure_Cropped.png}
    \caption{In Human Guided Regression (HuGuR), the user 
    chooses which part of a model to refine (1.), the newly refined model (after step 2.) still has to be parameterized based on the training set (step 3.), the resulting model is validated on the validation set (4.), the performance is monitored and presented to the user (5.). The model refinement goes in cycles. Upon completion, the model chosen as the best is tested on the test set (6.).}
    \label{fig:overview}
\end{figure}

With the steady increase of AI systems that make or support decisions with a potentially high impact on human lives, the need to understand and explain those decisions increases \cite{xai_right}. To achieve this, one can either employ inherently interpretable algorithms, for instance linear models, or incorporate an algorithm that derives explanations and insights from an existing black-box model, for example counterfactuals \cite{counterfactuals},  with the former solution arguably more preferable than the latter in sensitive domains \cite{stop}.



Human-in-the-loop (HIL) machine learning approaches become more and more relevant in machine learning \cite{HILsurvey}, since they allow the incorporation of human knowledge into the learning process. HIL machine learning can be seen as one approach to achieve transparent models. Most HIL machine learning approaches can be categorized into active learning \cite{activelearning}, interactive machine learning \cite{interactivelearning} and machine teaching \cite{machineteaching1}.

The paper presents a new HIL framework called HuGuR (\underline{Hu}man \underline{Gu}ided \underline{R}egression) for building interpretable regression models in domains with structured features. We instantiate the framework for the novel task of what we call {\em permutation regression} in the following: the task of predicting a numerical value for a permutation of a given set of items. This can be applied, for instance, to the problem of predicting the study success of a student solely based on the order of the attended courses, or predicting the performance of a classifier chain\cite{classifierchains}. The task is related to other learning tasks, such as sequence-based prediction -- some reductions are shown in Section 2.3 -- and structured output prediction (SOP) \cite{SOP1}. However, unlike SOP, permutation regression does not require any additional information about the problem besides the permutation itself.
The structured features in our case are constraints on the order of the items. 
The solution (see Figure \ref{fig:overview}) incorporates aspects of transparency and human-understandability coupled with the possibility for the user to interact with the model during its generation. HuGuR combines the transparency of a linear model composed of human-understandable constraints with the possibility for the users to interactively guide the model generation process. In contrast, other interactive machine learning systems \cite{IA1} give the user far less direct control over the model and do not provide a similar level of insight about the model to the user.

In summary, the contributions of this paper are as follows:
\begin{itemize}
    \item[$\bullet$] We introduce the novel task of permutation regression and provide multiple real-world based data sets for it.
    \item[$\bullet$] We present HuGuR, an interactive human-in-the-loop approach based on human-understandable binary features for this task.
    \item[$\bullet$] We conduct a user study to measure HuGuR's performance in its designated field of application. Doing so, we address the research question whether HIL based regression can outperform a pure machine regression, and if so, whether this is dependent on the sample size.
\end{itemize}

The paper is organized as follows: In Section \ref{theory} we define the novel task of permutation regression and introduce our approach to human guided learning of transparent models for permutation regression. In addition, we provide four baseline methods for the task. The real-world based data sets from our experiments are described in Section \ref{data}. The conducted user study and the results are presented in Section \ref{experiments}, before we conclude in Section \ref{conclusion}.