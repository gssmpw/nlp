\section{Emerging Directions and Challenges}
\label{sec:future_direction}

IR systems have become crucial across diverse domains, from retrieval-augmented language modeling~\cite{Khandelwal2020Generalization,borgeaud2022improving} to applications in agents~\cite{wu2023autogen,wang2024llmagentsurvey}, code generation~\cite{wang2024coderag,zhang-etal-2023-repocoder}, robotics~\cite{anwar2024remembr}, medicine~\cite{jeong2024improving}, and protein research~\cite{jumper2021highly}, \interalia. These developments present new challenges for IR research. Drawing from the evolution of IR architectures (\cref{sec:traditional,sec:ltr,sec:neural_ranking,sec:transformer,sec:llm4ir}), we examine emerging trends, open problems, and potential research directions.

\subsection{Better Models for Feature Extraction}
\label{subsec:direction_backbone}

Scaling has been a winning recipe for modern neural networks~\cite[\interalia]{kaplan2020scaling,hoffmann2022training,dehghani2023scaling,fang2024scaling,shao2024scaling}. 
As IR moves toward compute-intensive practices, we identify key areas for model improvement:

\begin{itemize}[leftmargin=*]
    \item \textbf{Parallelizable and low precision training}\,
    Models should support parallel processing and low precision training to reduce costs and accelerate convergence~\cite{pool2021nvidia,fishman2024scaling,liu2024deepseek}.
    \item \textbf{Inference optimization}\, Real-time applications like conversational search~\cite{mo2024survey} and agent-based systems~\cite{yao2023react} require efficient handling of variable-length queries, necessitating advanced compression and optimization techniques~\cite{dettmers2023case,kumar2024scaling,bruch2024efficient}.
    \item \textbf{Data efficiency}\, Current transformer-based IR models demand extensive training data~\cite{fang2024scaling}, making them impractical for many real-world applications. While recent work explores using LLMs for data annotation~\cite{tan2024large,faggioli2023perspectives,clarke2024llm}, developing architectures that can learn effectively from limited data remains crucial.
    \item \textbf{Multimodality and multilinguality}\, Future IR systems must handle diverse content types including images~\cite{ma-etal-2024-unifying}, audio~\cite{pusateri2024retrieval}, and structured data~\cite{tan2024htmlrag,edge2024local}. Recent advances in multimodal retrieval~\cite{ma-etal-2024-unifying,wei2025uniir} and structured data processing~\cite{li2023structure,li2024multi} show promising directions.
    \item \textbf{Transformer alternatives}\, 
    While transformers have dominated recent IR research, their quadratic complexity in attention computation remains a significant bottleneck. Recent advances in linear RNNs~\cite{peng-etal-2023-rwkv,peng2024eagle,qin2024hierarchically}, state space models~\cite{gu2024mamba,dao2024mamba2}, and linear attention~\cite{katharopoulos2020transformers,yang2024gated} offer alternatives with theoretical linear complexity. Although preliminary studies~\cite{xu2024state} show limited gains compared to optimized transformers, developing efficient alternatives architectures for transformers could revolutionize large-scale information retrieval.
\end{itemize}

\noindent
Strong foundation models have proven crucial for IR performance~\cite{neelakantan2022text,ma2024fine}. As IR applications expand, developing foundation models that balance computational efficiency with robust performance across tasks and modalities emerges as a key research priority.

\subsection{Flexible Relevance Estimators}
As discussed in~\cref{sec:transformer}, cross-encoders provide complex non-linear relevance estimation but are computationally expensive. In contrast, bi-encoder architectures used in dense and sparse retrieval rely on simple linear similarity functions (e.g., inner product) to enable fast retrieval through nearest neighbor search and inverted indexing. Finding a balance between complex relevance matching and scalable retrieval remains challenging. \textsc{ColBERT} \cite{khattab2020colbert} addresses this by using document representation matrices with MaxSim operations, while recent work \cite{killingback2025hypencoder} explores Hypernetworks \cite{ha2022hypernetworks} to generate query-specific neural networks for relevance estimation. The design of flexible yet scalable relevance estimators continues to be an active research direction.

\subsection{Open Questions}
The integration of IR systems into other research domains presents new challenges. We discuss key implications for future IR modeling research.

\paragraph{End ``User'' of Retrieval}
While traditional IR systems focus on providing search results to humans, retrieval is increasingly used to support ML models, particularly LLMs, in tasks such as generation~\cite{gao2023retrieval}, reasoning~\cite{yao2024mcqg,islam-etal-2024-open}, and planning~\cite{song2023llm}. This shifting paradigm raises questions about task formulation, evaluation, and system optimization:
\begin{itemize}[leftmargin=*]
    \item Current IR research is grounded in human information-seeking behavior~\cite{wilson2000human}. When the end user becomes another ML model, we must reconsider how to define and assess \textit{relevance}. This question suggests a need for flexible, data-efficient models that are adaptable to various downstream tasks.
    \item Traditional IR metrics, which are designed for human-centric evaluation, may not align with downstream task performance in retrieval-augmented systems. Future IR models should support end-to-end system optimization rather than focusing solely on ranking metrics. 
\end{itemize}

\paragraph{Autonomous Search Agent}
Complex tasks require retrieving long-tail knowledge using lengthy, complex queries~\cite{soudani2024finetuning,su2024bright}, demanding retrieval models capable of instruction following and reasoning~\cite{weller2024followir,ravfogel2024descriptionbased}. 
Future research should focus on developing truly ``intelligent'' IR systems that can ``self-evolve'', such as search agents~\cite{nakano2021webgpt,he2025pasa}. Such agentic systems can synthesize information needs without explicit user input, iteratively reformulate queries and analyze search results, eventually solve complex tasks with minimal human guidance.