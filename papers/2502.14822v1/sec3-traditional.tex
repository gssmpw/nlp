\section{Traditional IR Models}%\todo{probably nitpicking but how about "non-neural IR models? since what's "traditional" always change}
\label{sec:traditional}
In this section, we briefly review the principle of the traditional IR models prior to neural methods. These typical models are built upon the basic unit ``term'' used in the representation~\cite{nie2010cross}.

\paragraph{Boolean Model}
In Boolean Models, a document $\mathcal{D}$ is represented by a set of terms it contains, i.e., $\mathcal{D}=\{t_1, t_2, \dots, t_n\}$. A query $\mathcal{Q}$ is represented as a similar boolean expression of terms. 
A document is considered relevant to a query only if a logical implication $\mathcal{D} \rightarrow \mathcal{Q}$ holds, i.e., the document representation logically implies the query expression. 

\paragraph{Vector Space Model}
In Vector Space Models~\cite{salton1975vector}, the queries and documents are represented by vectors, e.g., $\mathcal{Q}=<q_1, q_2, \dots, q_n>$ and $\mathcal{D} = <d_1, d_2, \dots, d_n>$. 
The vector space $\mathcal{V} = <t_1, t_2, \dots, t_n>$ is formed by all the terms the system recognizes in the documents and each element ($q_i$ or $d_i$, $1 \leq i \leq  n$) in the vectors represents the weight of the corresponding term in the query or the document. 
The weights $q_i$ or $d_i$ could be binary, representing presence or absence. 
Given the vector representations, the relevance score is estimated by a similarity function between the query $\mathcal{Q}$ and the document $\mathcal{D}$.  

\paragraph{Probabilistic Model}
In Probabilistic Model, the relevance score of a document $\mathcal{D}$ to a query $\mathcal{Q}$ depends on a set of events $\{x_i\}_1^{n}$ representing the occurrence of term $t_i$ in this document. 
The simplest probabilistic model is the binary independence retrieval model~\cite{robertson1976relevance}, which assumes terms are independent so only $x_i=1$ and $x_i=0$ exist in the representation. 
Given a set of sample documents whose relevance is judged, the estimation of the relevance score can be derived as 
$\text{Score}(\mathcal{Q},\mathcal{D}) \propto \sum_{(x_i=1)\in\mathcal{D}} \log \frac{r_i(T-n_i-R+r_i)}{(R-r_i)(n_i-r_i)}, $
where $T$ and $R$ are the total number of sampled judged documents and relevant samples, and $n_i$ and $r_i$ denote the number of samples and relevant samples containing $t_i$, respectively.
The smooth mechanisms~\cite{baeza1999modern} are necessary to deal with zero occurrences of the $t_i$.

\paragraph{Statistical Language Model}
The general idea of a statistical language model is to estimate the relevance score of a document $\mathcal{D}$ to a query $\mathcal{Q}$ via $\mathcal{P}(\mathcal{D}|\mathcal{Q})$~\cite{ponte1998language}. 
Based on Bayes Rule, $\mathcal{P}(\mathcal{D}|\mathcal{Q})$ can be derived as directly proportional to $\mathcal{P}(\mathcal{Q}|\mathcal{D})\mathcal{P}(\mathcal{D})$. 
For simplification, most studies assume a uniform distribution for $\mathcal{P}(\mathcal{D})$. 
The main focus is on modeling $\mathcal{P}(\mathcal{Q}|\mathcal{D})$ as a ranking function by treating the query as a set of independent terms as $\mathcal{Q}=\{t_i\}_{i=1}^n$, thus $\mathcal{P}(\mathcal{Q}|\mathcal{D})=\prod_{t_i \in \mathcal{Q}}\mathcal{P}(t_i|\mathcal{D}).$
The probability $\mathcal{P}(t_i|\mathcal{D})$ is determined using a statistical language model $\theta_{D}$ that represents the document, then the relevance is estimated by log-likelihood as
$\text{Score}(\mathcal{Q},\mathcal{D}) = \log\mathcal{P}(\mathcal{Q}|\theta_{D}) = \sum_{t_i \in \mathcal{Q}}\log\mathcal{P}(t_i|\theta_{D}),$
where the estimation of the language model $\theta_{D}$ is usually achieved by maximum likelihood.