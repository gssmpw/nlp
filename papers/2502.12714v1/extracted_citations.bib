@inproceedings{callison2022dungeons,
    title = "{D}ungeons and {D}ragons as a Dialog Challenge for Artificial Intelligence",
    author = "Callison-Burch, Chris  and
      Tomar, Gaurav Singh  and
      Martin, Lara J.  and
      Ippolito, Daphne  and
      Bailis, Suma  and
      Reitter, David",
    editor = "Goldberg, Yoav  and
      Kozareva, Zornitsa  and
      Zhang, Yue",
    booktitle = "Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing",
    month = dec,
    year = "2022",
    address = "Abu Dhabi, United Arab Emirates",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.emnlp-main.637/",
    doi = "10.18653/v1/2022.emnlp-main.637",
    pages = "9379--9393",
    abstract = "AI researchers have posited Dungeons and Dragons (D{\&}D) as a challenge problem to test systems on various language-related capabilities. In this paper, we frame D{\&}D specifically as a dialogue system challenge, where the tasks are to both generate the next conversational turn in the game and predict the state of the game given the dialogue history. We create a gameplay dataset consisting of nearly 900 games, with a total of 7,000 players, 800,000 dialogue turns, 500,000 dice rolls, and 58 million words. We automatically annotate the data with partial state information about the game play. We train a large language model (LM) to generate the next game turn, conditioning it on different information. The LM can respond as a particular character or as the player who runs the game{---}i.e., the Dungeon Master (DM). It is trained to produce dialogue that is either in-character (roleplaying in the fictional world) or out-of-character (discussing rules or strategy). We perform a human evaluation to determine what factors make the generated output plausible and interesting. We further perform an automatic evaluation to determine how well the model can predict the game state given the history and examine how well tracking the game state improves its ability to produce plausible conversational output."
}

@ARTICLE{ellis2017computers,

  author={Ellis, Simon and Hendler, James},

  journal={IEEE Intelligent Systems}, 

  title={Computers Play Chess, Computers Play Go…Humans Play {D}ungeons \& {D}ragons}, 

  year={2017},

  volume={32},

  number={4},

  pages={31-34},

  keywords={Games;Artificial intelligence;Creativity;Complexity theory;Pattern recognition;Cognitive systems;artificial intelligence;game-playing;Dungeons and Dragons;artificial intelligence;intelligent systems},

  doi={10.1109/MIS.2017.3121545}}

@inproceedings{goswami2023weakly,
    title = "Weakly-supervised Deep Cognate Detection Framework for Low-Resourced Languages Using Morphological Knowledge of Closely-Related Languages",
    author = "Goswami, Koustava  and
      Rani, Priya  and
      Fransen, Theodorus  and
      McCrae, John",
    editor = "Bouamor, Houda  and
      Pino, Juan  and
      Bali, Kalika",
    booktitle = "Findings of the Association for Computational Linguistics: EMNLP 2023",
    month = dec,
    year = "2023",
    address = "Singapore",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.findings-emnlp.38/",
    doi = "10.18653/v1/2023.findings-emnlp.38",
    pages = "531--541",
    abstract = "Exploiting cognates for transfer learning in under-resourced languages is an exciting opportunity for language understanding tasks, including unsupervised machine translation, named entity recognition and information retrieval. Previous approaches mainly focused on supervised cognate detection tasks based on orthographic, phonetic or state-of-the-art contextual language models, which under-perform for most under-resourced languages. This paper proposes a novel language-agnostic weakly-supervised deep cognate detection framework for under-resourced languages using morphological knowledge from closely related languages. We train an encoder to gain morphological knowledge of a language and transfer the knowledge to perform unsupervised and weakly-supervised cognate detection tasks with and without the pivot language for the closely-related languages. While unsupervised, it overcomes the need for hand-crafted annotation of cognates. We performed experiments on different published cognate detection datasets across language families and observed not only significant improvement over the state-of-the-art but also our method outperformed the state-of-the-art supervised and unsupervised methods. Our model can be extended to a wide range of languages from any language family as it overcomes the requirement of the annotation of the cognate pairs for training."
}

@inproceedings{huang2023mclf,
    title = "{MCLF}: A Multi-grained Contrastive Learning Framework for {ASR}-robust Spoken Language Understanding",
    author = "Huang, Zhiqi  and
      Chen, Dongsheng  and
      Zhu, Zhihong  and
      Cheng, Xuxin",
    editor = "Bouamor, Houda  and
      Pino, Juan  and
      Bali, Kalika",
    booktitle = "Findings of the Association for Computational Linguistics: EMNLP 2023",
    month = dec,
    year = "2023",
    address = "Singapore",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.findings-emnlp.533/",
    doi = "10.18653/v1/2023.findings-emnlp.533",
    pages = "7936--7949",
    abstract = "Enhancing the robustness towards Automatic Speech Recognition (ASR) errors is of great importance for Spoken Language Understanding (SLU). Trending ASR-robust SLU systems have witnessed impressive improvements through global contrastive learning. However, although most ASR errors occur only at local positions of utterances, they can easily lead to severe semantic changes, and utterance-level classification or comparison is difficult to distinguish such differences. To address the problem, we propose a two-stage multi-grained contrastive learning framework dubbed MCLF. Technically, we first adapt the pre-trained language models to downstream SLU datasets via the proposed multi-grained contrastive learning objective and then fine-tune it on the corresponding dataset. Besides, to facilitate contrastive learning in the pre-training stage, we explore several data augmentation methods to expand the training data. Experimental results and detailed analyses on four datasets and four BERT-like backbone models demonstrate the effectiveness of our approach."
}

@INPROCEEDINGS{lau2004vulnerability,

  author={Yee Wah Lau and Wagner, M. and Tran, D.},

  booktitle={Proceedings of 2004 International Symposium on Intelligent Multimedia, Video and Speech Processing, 2004.}, 

  title={Vulnerability of speaker verification to voice mimicking}, 

  year={2004},

  volume={},

  number={},

  pages={145-148},

  keywords={Databases;Data security;Information security;Speaker recognition;Speech synthesis;Biometrics;Error analysis;Computer security;Speech processing;Parameter estimation},

  doi={10.1109/ISIMP.2004.1434021}}

@inproceedings{lau2005testing,
	address = {Berlin, Heidelberg},
	title = {Testing voice mimicry with the {YOHO} speaker verification corpus},
	isbn = {978-3-540-31997-9},
	abstract = {The aim of this paper is to determine how vulnerable a speaker verification system is to conscious effort by impostors to mimic a client of the system. The paper explores systematically how much closer an impostor can get to another speaker’s voice by repeated attempts. Experiments on 138 speakers in the YOHO database and six people who played a role as imitators showed a fact that professional linguists could successfully attack the system. Non-professional people could have a good chance if they know their closest speaker in the database.},
	booktitle = {Knowledge-{Based} {Intelligent} {Information} and {Engineering} {Systems}},
	publisher = {Springer Berlin Heidelberg},
	author = {Lau, Yee W. and Tran, Dat and Wagner, Michael},
	editor = {Khosla, Rajiv and Howlett, Robert J. and Jain, Lakhmi C.},
	year = {2005},
	pages = {15--21},
    doi={10.1007/11554028_3}
}

@inproceedings{louis2018deep,
    title = "Deep {D}ungeons and {D}ragons: Learning Character-Action Interactions from Role-Playing Game Transcripts",
    author = "Louis, Annie  and
      Sutton, Charles",
    editor = "Walker, Marilyn  and
      Ji, Heng  and
      Stent, Amanda",
    booktitle = "Proceedings of the 2018 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 2 (Short Papers)",
    month = jun,
    year = "2018",
    address = "New Orleans, Louisiana",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/N18-2111/",
    doi = "10.18653/v1/N18-2111",
    pages = "708--713",
    abstract = "An essential aspect to understanding narratives is to grasp the interaction between characters in a story and the actions they take. We examine whether computational models can capture this interaction, when both character attributes and actions are expressed as complex natural language descriptions. We propose role-playing games as a testbed for this problem, and introduce a large corpus of game transcripts collected from online discussion forums. Using neural language models which combine character and action descriptions from these stories, we show that we can learn the latent ties. Action sequences are better predicted when the character performing the action is also taken into account, and vice versa for character attributes."
}

@inproceedings{martin2018dungeons,
title={Dungeons and {DQN}s: Toward Reinforcement Learning Agents that Play Tabletop Roleplaying Games},
author={Martin, Lara J and Sood, Srijan and Riedl, Mark O},
booktitle={Proceedings of the Joint Workshop on Intelligent Narrative Technologies and Workshop on Intelligent Cinematography and Editing},
editor={H. Wu, M. Si, A. Jhala},
location={Edmonton, Canada},
month={November},
year={2018},
publisher={CEUR-WS},
url={https://ceur-ws.org/Vol-2321/paper4.pdf}
}

@mastersthesis{medaramitta2021evaluating,
  author       = {Raveendra Medaramitta},
  title        = {Evaluating the Performance of Using Speaker Diarization for Speech Separation of In-Person Role-Play Dialogues},
  school       = {Wright State University},
  year         = {2021},
  type         = {Master's Thesis},
  month        = {},
  address      = {},
  abstract     = {Development of professional communication skills, such as motivational interviewing, often requires experiential learning through expert instructor-guided role-plays between the trainee and a standard patient/actor. Due to the growing demand for such skills in practices, e.g., for health care providers in the management of mental health challenges, chronic conditions, substance misuse disorders, etc., there is an urgent need to improve the efficacy and scalability of such role-play based experiential learning, which are often bottlenecked by the time-consuming performance assessment process. WSU is developing ReadMI (Real-time Assessment of Dialogue in Motivational Interviewing) to address this challenge, a mobile AI solution aiming to provide automated performance assessment based on ASR and NLP. The main goal of this thesis research is to investigate current commercially available speaker diarization capabilities and evaluate their performance in separating the speeches between the trainee and the standard patient/actor in an in-person role-play training environment where the crosstalk could interfere with the operation and performance of ReadMI. Specifically, this thesis research has: 1.) identified the major commercially-available speaker diarization systems, such as those from Google, Amazon, IBM, and Rev.ai; 2.) designed and implemented corresponding evaluation systems that integrate these commercially available cloud services for operating in the in-person role-play training environments; and, 3.) completed an experimental study that evaluated and compared the performance of the speaker diarization services from Google and Amazon. The main finding of this thesis is that the current speaker diarization capabilities alone are not able to provide sufficient performance for our particular use case when integrating them into ReadMI for operating in in-person role-play training environments. But this thesis research potentially provides a clear baseline reference to future developers for integrating future speaker diarization capabilities into similar applications.},
  pages        = {45},
  department   = {Department of Computer Science and Engineering},
  url={https://corescholar.libraries.wright.edu/etd_all/2517/}
}

@inproceedings{newman2022generating,
    title = "Generating Descriptive and Rules-Adhering Spells for {D}ungeons {\&} {D}ragons {F}ifth {E}dition",
    author = "Newman, Pax  and
      Liu, Yudong",
    editor = "Madge, Chris",
    booktitle = "Proceedings of the 9th Workshop on Games and Natural Language Processing within the 13th Language Resources and Evaluation Conference",
    month = jun,
    year = "2022",
    address = "Marseille, France",
    publisher = "European Language Resources Association",
    url = "https://aclanthology.org/2022.games-1.7/",
    pages = "54--60",
    abstract = "We examine the task of generating unique content for the spell system of the tabletop roleplaying game Dungeons and Dragons Fifth Edition using several generative language models. Due to the descriptive nature of the game Dungeons and Dragons Fifth Edition, it presents a number of interesting avenues for generation and analysis of text. In particular, the {\textquotedblleft}spell{\textquotedblright} system of the game has interesting and unique characteristics as it is primarily made up of high level and descriptive text but has many of the game`s main rules embedded with that text. Thus, we examine the capabilities of several models on the task of generating new content for this game, evaluating the performance through the use of both score-based methods and a survey on the best performing model to determine how the generated content conforms to the rules of the game and how well they might be used in the game."
}

@inproceedings{qamar2023speaking,
    title = "Who is Speaking? Speaker-Aware Multiparty Dialogue Act Classification",
    author = "Qamar, Ayesha  and
      Pyarelal, Adarsh  and
      Huang, Ruihong",
    editor = "Bouamor, Houda  and
      Pino, Juan  and
      Bali, Kalika",
    booktitle = "Findings of the Association for Computational Linguistics: EMNLP 2023",
    month = dec,
    year = "2023",
    address = "Singapore",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.findings-emnlp.678/",
    doi = "10.18653/v1/2023.findings-emnlp.678",
    pages = "10122--10135",
    abstract = "Utterances do not occur in isolation in dialogues; it is essential to have the information of who the speaker of an utterance is to be able to recover the speaker`s intention with respect to the surrounding context. Beyond simply capturing speaker switches, identifying how speakers interact with each other in a dialogue is crucial to understanding conversational flow. This becomes increasingly important and simultaneously difficult to model when more than two interlocutors take part in a conversation. To overcome this challenge, we propose to explicitly add speaker awareness to each utterance representation. To that end, we use a graph neural network to model how each speaker is behaving within the local context of a conversation. The speaker representations learned this way are then used to update their respective utterance representations. We experiment with both multiparticipant and dyadic conversations on the MRDA and SwDA datasets and show the effectiveness of our approach."
}

@inproceedings{qasemi2021paco,
    title = "{P}a{C}o: Preconditions Attributed to Commonsense Knowledge",
    author = "Qasemi, Ehsan  and
      Ilievski, Filip  and
      Chen, Muhao  and
      Szekely, Pedro",
    editor = "Goldberg, Yoav  and
      Kozareva, Zornitsa  and
      Zhang, Yue",
    booktitle = "Findings of the Association for Computational Linguistics: EMNLP 2022",
    month = dec,
    year = "2022",
    address = "Abu Dhabi, United Arab Emirates",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.findings-emnlp.505/",
    doi = "10.18653/v1/2022.findings-emnlp.505",
    pages = "6781--6796",
    abstract = "Humans can seamlessly reason with circumstantial preconditions of commonsense knowledge. We understand that a glass is used for drinking water, unless the glass is broken or the water is toxic. Despite state-of-the-art (SOTA) language models' (LMs) impressive performance on inferring commonsense knowledge, it is unclear whether they understand the circumstantial preconditions. To address this gap, we propose a novel challenge of reasoning with circumstantial preconditions. We collect a dataset, called PaCo, consisting of 12.4 thousand preconditions of commonsense statements expressed in natural language. Based on this dataset, we create three canonical evaluation tasks and use them to examine the capability of existing LMs to understand situational preconditions. Our results reveal a 10-30{\%} gap between machine and human performance on our tasks, which shows that reasoning with preconditions is an open challenge."
}

@inproceedings{rameshkumar2020storytelling,
    title = "Storytelling with Dialogue: a Critical Role {D}ungeons and {D}ragons Dataset",
    author = "Rameshkumar, Revanth  and
      Bailey, Peter",
    editor = "Jurafsky, Dan  and
      Chai, Joyce  and
      Schluter, Natalie  and
      Tetreault, Joel",
    booktitle = "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics",
    month = jul,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2020.acl-main.459/",
    doi = "10.18653/v1/2020.acl-main.459",
    pages = "5121--5134",
    abstract = "This paper describes the Critical Role Dungeons and Dragons Dataset (CRD3) and related analyses. Critical Role is an unscripted, live-streamed show where a fixed group of people play Dungeons and Dragons, an open-ended role-playing game. The dataset is collected from 159 Critical Role episodes transcribed to text dialogues, consisting of 398,682 turns. It also includes corresponding abstractive summaries collected from the Fandom wiki. The dataset is linguistically unique in that the narratives are generated entirely through player collaboration and spoken interaction. For each dialogue, there are a large number of turns, multiple abstractive summaries with varying levels of detail, and semantic ties to the previous dialogues. In addition, we provide a data augmentation method that produces 34,243 summary-dialogue chunk pairs to support current neural ML approaches, and we provide an abstractive summarization benchmark and evaluation."
}

@inproceedings{si2021telling,
    title = "Telling Stories through Multi-User Dialogue by Modeling Character Relations",
    author = "Si, Wai Man  and
      Ammanabrolu, Prithviraj  and
      Riedl, Mark",
    editor = "Li, Haizhou  and
      Levow, Gina-Anne  and
      Yu, Zhou  and
      Gupta, Chitralekha  and
      Sisman, Berrak  and
      Cai, Siqi  and
      Vandyke, David  and
      Dethlefs, Nina  and
      Wu, Yan  and
      Li, Junyi Jessy",
    booktitle = "Proceedings of the 22nd Annual Meeting of the Special Interest Group on Discourse and Dialogue",
    month = jul,
    year = "2021",
    address = "Singapore and Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.sigdial-1.30/",
    doi = "10.18653/v1/2021.sigdial-1.30",
    pages = "269--275",
    abstract = "This paper explores character-driven story continuation, in which the story emerges through characters' first- and second-person narration as well as dialogue{---}requiring models to select language that is consistent with a character`s persona and their relationships with other characters while following and advancing the story. We hypothesize that a multi-task model that trains on character dialogue plus character relationship information improves transformer-based story continuation. To this end, we extend the Critical Role Dungeons and Dragons Dataset (Rameshkumar and Bailey, 2020){---}consisting of dialogue transcripts of people collaboratively telling a story while playing the role-playing game Dungeons and Dragons{---}with automatically extracted relationships between each pair of interacting characters as well as their personas. A series of ablations lend evidence to our hypothesis, showing that our multi-task model using character relationships improves story continuation accuracy over strong baselines."
}

