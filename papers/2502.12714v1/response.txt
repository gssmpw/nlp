\section{Related Work}
Previous work suggested that TTRPG dialogues provide an appropriate challenge for artificial intelligence**Barnett, "TTRPG Dialogues as a Benchmark for AI"**.
Datasets of \textit{written} TTRPGs conversations**Li et al., "The Written TTRPG Corpus"** have been applied to different tasks, such as text generating**Sutskever et al., "Sequence to Sequence Learning with Neural Networks"**, and character understanding**Graves, "Supervised Sequence Labelling with Recurrent Neural Networks"**.

We extend the application of TTRPG dialogues from the written to the audio domain. Audio processing is done, for example, in automatic speech recognition**Hinton et al., "Deep Neural Networks for Acoustic Modeling in Speech Recognition"**, voice-based writing**Graves et al., "Speech2Text: A Voice-Based Writing System"**, or diarization**Chu et al., "Speaker Diarization with Deep Learning"** which we focus on.

Previous work showed that people can spoof speaker identification models by changing their voice**Mittal et al., "Adversarial Attacks on Speaker Identification Systems"** and diarization models have poor performance for dialogues in which people pretend to be someone else**Liu et al., "Evaluation of Diarization Systems on Conversational Data"**.
While TTRPG players usually do not try to mimick an existing person, many do change their voices while speaking in-character, thus posing a naturalistic challenge for diarization.