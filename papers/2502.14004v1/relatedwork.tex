\section{Related Works}
\label{sec:Related Work}
\bfsection{Static 3D Reconstruction}
Recent advances in implicit 3D reconstruction, particularly with neural radiance fields (NeRFs)~\cite{nerf}, have enabled high-quality novel view generation by predicting volume density and radiance from 3D coordinates and viewpoint directions. Variants like mip-NeRF~\cite{mip360} optimize performance in more complex scenarios. 3D Gaussian splatting~\cite{3DGS} uses a set of Gaussian primitives with learnable parameters, \ie positions, covariance matrices, opacity, and spherical harmonics coefficients, and differentiable tile rasterizer to improve synthesis quality and training speed. However, these methods primarily focus on modeling static objects and can only be applied to a single state of a human-interactive object. To model all possible states, a series of independent 3D models would be required, significantly increasing computational costs and failing to ensure consistency across states.

% often neglecting the challenges posed by movable parts in dynamic objects. These techniques typically suffer from ghosting artifacts when trying to represent movable components.


\bfsection{Dynamic 4D Reconstruction}
Dynamic 4D reconstruction methods, such as K-Plane~\cite{kplane}, D-NeRF~\cite{dnerf}, and 4D Gaussians~\cite{4dgaussian}, extend vanilla NeRFs or Gaussian splatting by incorporating motion factors to model geometric and texture changes of time-varying objects. 
These methods excel at modeling dynamic objects with continuous states and synthesizing novel views of the training states. However, our approach focuses on modeling human-interactive objects with numerous discrete states and emphasizes novel state synthesis, a task that is infeasible for these methods.


% Our work addresses these limitations by introducing a benchmark specifically designed for human-interactive 3D object reconstruction, with a focus on discrete motion states and the complexities of modeling interactions between multiple movable parts. Leveraging the Space Discrepancy Tensor and Mutual State Regularization, our approach provides an efficient solution to these challenges, extending the scope of 3D reconstruction to objects with discrete and combinatorial states.


\begin{figure}[!t]
 \centering
  \includegraphics[width=\linewidth, keepaspectratio]{pdf/3.pdf}
   \vspace{-4mm}
    \caption{Data collection example of the object \textbf{Car} in our human-interactive benchmark \textit{\name{}}. A sequence of forward-facing images are captured for the canonical state $S_0$ with doors closed, the state $S_1$ with the front door open, and the state $S_2$ with the rear door open.}
  \label{fig:3}
  \vspace{-4mm}
\end{figure}