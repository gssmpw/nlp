\section{Introduction}
Humans consistently rely on their physical agility to walk, squat to specific heights, and manipulate objects when performing tasks such as transferring goods in warehouses. While humanoid robots are expected to eventually take over these labor-intensive tasks, achieving full autonomy remains a significant challenge. In the interim, a robust teleoperation system is essential, enabling operators to seamlessly control robots for complex loco-manipulation tasks. These systems not only allow humans to guide robots with precision and fluidity but also serve as a critical tool for collecting high-quality demonstrations to advance autonomous capabilities. Two indispensable components are required to realize this vision: (1) a robust loco-manipulation policy that enables robots to extend operational workspace; (2) a method that allows a single operator to precisely control the robot's upper-body manipulation and lower-body locomotion simultaneously.

However, most existing efforts to teleoperate humanoid robots focus solely on controlling the upper body~\cite{cheng2024open,yang2024ace,ze2024humanoid_manipulation,qin2023anyteleop,iyer2024open}. This restriction significantly limits the robot's operational workspace, as it prevents the robot from moving freely or adjusting its posture (e.g., squatting) to adapt to different task requirements. While some researchers have explored equipping humanoids with loco-manipulation capabilities through reinforcement learning (RL)~\cite{fu2024humanplus,he2024learning,he2024omnih2o,cheng2024express,ji2024exbody2,lu2024pmp}, these approaches often fail to achieve the necessary range of motion, such as squatting to specific heights, which is critical for many real-world tasks. Additionally, many humanoid whole-body teleoperation methods require operators to physically move to control the robot's motion, making it challenging to maintain precise and stable full-body control over extended distances. Mainstream teleoperation systems typically rely on vision-based methods~\cite{cheng2024open,ze2024humanoid_manipulation,qin2023anyteleop,iyer2024open} or heterogeneous exoskeletons~\cite{yang2024ace} to determine end-effector poses, followed by inverse kinematics (IK) to compute joint positions. Nonetheless, both pose estimation and IK solving introduce inaccuracies, which compromises the precision and reliability of teleoperation.

To address these issues, we introduce \ourshort, a novel humanoid teleoperation cockpit composed of a humanoid loco-manipulation policy and an exoskeleton-based hardware system. This cockpit enables a single operator to precisely and efficiently control a humanoid robot's full-body movements for diverse loco-manipulation tasks. Integrated into simulation environments, our cockpit also enables seamless teleoperation in virtual settings. Specifically, we introduce three core techniques to our RL-based training framework: upper-body pose curriculum, height tracking reward, and symmetry utilization. These components collectively enhance the robot's physical agility, enabling robust walking, rapid squatting to any required heights, and stable balance maintenance during dynamic upper-body movements, thereby significantly expanding the robot's operational workspace beyond existing solutions. Unlike previous whole-body control methods that depend on motion priors derived from motion capture (MoCap) data~\cite{AMASS}, our framework eliminates this dependency, resulting in a more efficient pipeline. Our hardware system features isomorphic exoskeleton arms, a pair of motion-sensing gloves, and a pedal. The pedal design for locomotion command acquisition liberates the operator's upper body, enabling simultaneous acquisition of upper-body poses. Since the exoskeleton arms are isomorphic to the controlled robot and each glove has 15 degrees of freedom (DoF), which is more than most existing dexterous hands, we can directly set upper-body joint positions from the exoskeleton readings, dispensing with IK and achieving faster and more accurate teleoperation. Moreover, our gloves can be detached from the arms, allowing them to be reused in systems isomorphic to different robots. The total cost of the hardware system is only \$0.5k, which is significantly lower than that of MoCap devices~\cite{wang2024dexcap}.

Through ablation experiments, we validate the effectiveness of each technique in our training framework and demonstrate the robustness of the resulting policies across different robots. Our evaluation shows that the hardware system supports 200\% faster and more accurate pose acquisition than previous methods, enabling operators to complete tasks more efficiently than virtual reality (VR)-based approaches. Real-world studies confirm that the trained policies can be deployed directly in the real world, allowing robots to perform diverse loco-manipulation tasks stably in complex environments. We further show that real-world data collected via~\ourshort can be effectively used by imitation learning (IL) algorithms, allowing humanoid robots to autonomously execute tasks. 
 
In summary, our core contributions are three-fold:
\begin{enumerate}
    \item We propose~\ourshort, the first implementation of a cockpit for humanoid whole-body loco-manipulation teleoperation enables a single operator to fully control the robot and execute diverse tasks seamlessly.
    \item We first achieve robust humanoid loco-manipulation including squatting under arbitrary continuous changing upper-body poses without using any motion prior.
    \item Our hardware system supports more precise and rapid whole-body control of humanoids than previous works, reducing task completion times by nearly half.

\end{enumerate}