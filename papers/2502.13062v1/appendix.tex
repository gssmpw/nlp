\section{On Standardized Features} \label{app:general}

\begin{lemma} \label{thm:standardized-ftrs}
    Let $\{z_i\}_{i=1}^n$ be independent random variables, with known means $\{\mu_i\}_{i=1}^n$ and known finite standard deviations $\{\sigma_i\}_{i=1}^n$, and let $y = a_0 + \sum_{i=1}^n a_i z_i$ be a linear combination of the features that we are willing to represent, for $a_i \in 	\mathbb{R}$ for all $i \in [n]$. Then, w.l.o.g., we can assume $\mu_i = 0$ and $\sigma_i = 1$ for all $i \in [n]$.
\end{lemma}

\begin{proof}
    For all $i$, we use $x_i(z_i)=(z_i - \mu_i) / \sigma_i$. Therefore, the distribution of $x_i$ has zero mean and unit variance. 
    We use coefficients $a'_i$ as follows: $a'_0 = a_0 + \sum_{i=1}^n \mu_i a_i$, and for all $i \in [n]$, $a'_i = \sigma_i a_i$.
    Now, we have: 

    $$y =  a_0 + \sum_{i=1}^n a_i z_i = a_0 + \sum_{i=1}^n \mu_i a_i + \sum_{i=1}^n \sigma_i \cdot a_i (z_i - \mu_i) / \sigma_i = a'_0 + \sum_{i=1}^n a'_i x_i = y'$$
    
    Thus, when the means and standard deviations of the $z_i$'s are known, using the standardized features is simply a change of variables that does not change the problem.
    
\end{proof}








\section{Figure for the Example in Section \ref{sec:example-learning}} \label{app:fig-theory-fit-simulation}


\begin{figure}[ht]
        \centering
\includegraphics[width=0.5\textwidth]{"figures/delta_w_theory_t200_mse_ratioa1.00.4h-0.50.75.png"}
     
    % Problem parameters: two features, with algorithm's estimates of $a=(1, 0.4)$, human's beliefs are $h=(-0.5,0.75)$, and a budget of $k=1$.}
%White region is where always selecting the more informative feature (which the human is very wrong about) leads to lower discounted loss than always selecting the less informative feature feature 2 (which the human is more accurate about).}
        
    % \hfill
    \caption{The transition curve for the example in Section \ref{sec:example-learning}: For $\delta$ values to the right of this curve, selecting the more informative feature (of the two) is preferred, while for $\delta$ values to the left of this curve, the less divergent feature is preferred. 
    The plot demonstrates that the empirical curve in Figure \ref{fig:w-delta-heatmap} coincides with the theoretical curve derived in \cref{clm:educating-two-features}.
    }
    \label{fig:theory-fit-simulation}
\end{figure}

\FloatBarrier