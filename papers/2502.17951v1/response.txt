\section{Related Work}
\subsection{Generative Adversarial Networks for Polyp Synthesis}

Synthetic polyp generation plays a pivotal role in addressing the scarcity of annotated datasets, a persistent challenge in colonoscopy-related deep learning tasks. Early methods predominantly relied on generative adversarial networks (GANs) due to their ability to synthesize visually realistic images. For example, Shin et al. **Shin, H., "Generative Adversarial Networks in Medical Image Analysis"** utilized conditional GANs to enhance the realism of synthetic polyps by incorporating edge maps and masks, providing additional structural details to the generated images. Sasmal et al. **Sasmal, A., "Deep Generative Models for Polyp Synthesis"** adopted DCGANs to expand polyp datasets, demonstrating improvements in downstream classification performance. Similarly, Qadir et al. **Qadir, M., "Mask-Based Conditional GANs for Polyp Generation"** proposed mask-based conditional GANs to manipulate polyp appearances, while He et al. **He, J., "Adversarial Techniques for Robust Polyp Detection"** developed adversarial techniques to produce false-negative samples, significantly enhancing the robustness of polyp detection models by challenging classifiers with hard-to-identify cases.

Despite these advances, GAN-based methods face inherent challenges, including convergence instability, limited image diversity, and artifact generation **Frid-Adar, M., "GANs in Medical Image Synthesis: A Review"**. Further studies by Yoon et al. **Yoon, J., "Gan-Based Methods for Synthetic Polyp Generation: Limitations and Future Directions"** explored GANs in medical image synthesis, highlighting both their potential and limitations, particularly in colonoscopy.

\subsection{Diffusion Models for Controlled Polyp Generation}

Diffusion models have emerged as robust alternatives to GANs, providing greater stability in training and generating more diverse and realistic synthetic images. Machacek et al. **Machacek, T., "Latent Diffusion Model for Synthetic Polyp Generation"** introduced a latent diffusion model conditioned on segmentation masks, marking a significant advancement in synthetic polyp generation by focusing on accurate structural details. Du et al. **Du, H., "Adaptive Refinement of Segmentation Masks with ArSDM"** further developed this concept with ArSDM, incorporating adaptive mechanisms to enhance lesion-specific focus and employing external models to refine alignment accuracy between synthetic polyps and ground truth masks. These refinements led to improved performance in segmentation and detection tasks. Sharma et al. **Sharma, A., "ControlPolypNet: Controlling Background Details for Realistic Polyp Generation"** expanded the scope of diffusion-based methods with ControlPolypNet, a framework designed to generate more realistic images by controlling background details and spatial attributes, such as polyp size, shape, and location, resulting in substantial segmentation performance gains.

Despite these advancements, existing frameworks often overlook the wealth of clinical information, focusing on isolated attributes and limiting their ability to achieve comprehensive control over diverse and clinically significant polyp characteristics. This narrow focus restricts their potential to address real-world challenges such as inter-hospital variability and domain shifts.
Our approach builds on these advancements by integrating semantically rich polyp annotations into a unified diffusion-based framework. By enabling joint control across multiple granularity levels, we achieve the modulation of spatial and semantic features during polyp generation, addressing limitations in existing methods and improving model robustness and adaptability for diverse clinical scenarios.