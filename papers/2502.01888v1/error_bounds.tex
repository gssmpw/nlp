\section{Error bounds}
In this section, we establish error bounds for \Cref{alg:krylow}. We break the analysis into two parts. First, in \Cref{section:inexact_projections}, we derive general error bounds for approximations to $f(\bm{A})$ when projections $\bm{Q} \bm{Q}^\T f(\bm{A}) \bm{Q} \bm{Q}^\T$ cannot be computed exactly. In \Cref{section:structural} we provide structural bounds for the errors $\|f(\bm{A})- \bm{Q}_s \bm{Q}_s^\T f(\bm{A}) \bm{Q}_s \bm{Q}_s^\T\|_{\F}$ and $\|f(\bm{A})- \bm{Q}_s \llbracket \bm{Q}_s^\T f(\bm{A}) \bm{Q}_s\rrbracket_k \bm{Q}_s^\T\|_{\F}$ that hold with probability $1$, and in \Cref{section:probabilistic} we derive the corresponding probabilistic bounds. Next, in \Cref{section:krylow} we combine the results from \Cref{section:inexact_projections,section:structural,section:probabilistic} to derive end-to-end error bounds for \Cref{alg:krylow}, which involves approximate projection onto $\bm{Q}_s \bm{Q}_s^\T$. %Finally, in \Cref{section:exponential} we apply our bounds to the matrix exponential as an illustrative example.
\subsection{Error bounds for inexact projections}\label{section:inexact_projections}
In this section we will derive error bounds for $\|f(\bm{A}) - \bm{Q} \bm{X} \bm{Q}^\T\|_{\F}$ and $\|f(\bm{A}) - \bm{Q} \llbracket \bm{X} \rrbracket_k \bm{Q}^\T\|_{\F}$ where $\bm{Q}$ is \textit{any} orthonormal basis and $\bm{X}$ is \textit{any} matrix. By \cite[Lemma 3.3]{funnystrom2} we know that the optimal choice of $\bm{X}$ is $\bm{X} = \bm{Q}^\T f(\bm{A}) \bm{Q}$. However, since $\bm{Q}^\T f(\bm{A}) \bm{Q}$ can only be computed approximately, we need to show that the errors $\|f(\bm{A}) - \bm{Q} \bm{Q}^\T f(\bm{A}) \bm{Q} \bm{Q}\|_{\F}$ and $\|f(\bm{A}) - \bm{Q} \llbracket \bm{Q}^\T f(\bm{A}) \bm{Q} \rrbracket_k \bm{Q}\|_{\F}$ are robust against perturbations in $\bm{Q}^\T f(\bm{A}) \bm{Q}$. \Cref{theorem:robust} provides such a result. 
%Note that we consider matrix functions $f(\bm{A})$ when we state the theorem, since this is the focus of this paper. However, \Cref{theorem:robust} remains true for arbitrary square matrices. 
\begin{theorem}\label{theorem:robust}
    Given an orthonormal basis $\bm{Q}$ and an approximation $\bm{X}$ to $\bm{Q}^\T f(\bm{A}) \bm{Q}$. Then,
    \begin{equation}\label{eq:robustness1}
        \|f(\bm{A}) - \bm{Q} \bm{X}\bm{Q}^\T\|_{\F}^2 = \|f(\bm{A}) - \bm{Q}\bm{Q}^\T f(\bm{A})\bm{Q}\bm{Q}^\T\|_{\F}^2 + \|\bm{Q}^\T f(\bm{A})\bm{Q} - \bm{X}\|_{\F}^2,
    \end{equation}
    and
    \begin{equation}\label{eq:robustness2}
        \|f(\bm{A}) - \bm{Q} \llbracket \bm{X} \rrbracket_k \bm{Q}^\T\|_{\F} \leq \|f(\bm{A}) - \bm{Q}\llbracket\bm{Q}^\T f(\bm{A})\bm{Q} \rrbracket_k\bm{Q}^\T\|_{\F} + 2\|\bm{Q}^\T f(\bm{A})\bm{Q} - \bm{X}\|_{\F}.
    \end{equation}
\end{theorem}
% \begin{remark}
%     Note that one can derive a similar bound to \textit{(\ref*{item:truncated})} by using the triangle inequality and obtaining a bound for $\|(f(\bm{T})_{1:d_s,1:d_s})_{(k)}-(\bm{Q}_1^\T f(\bm{A}) \bm{Q}_1)_{(k)}\|_{\F}$. Treating $f(\bm{T})_{1:d_s,1:d_s}$ as a perturbation of $\bm{Q}_1^\T f(\bm{A}) \bm{Q}_1$ would lead to an unfortunate dependence of the singular value gap of $f(\bm{A})$. Our analysis avoids any dependence on gaps. 
% \end{remark}
\begin{proof}
%     We begin with proving \eqref{eq:robustness1}. Note that for any matrix $\bm{B}$ we have $\langle f(\bm{A})-\bm{Q} \bm{Q}^\T f(\bm{A})\bm{Q} \bm{Q}^\T, \bm{Q} \bm{B}\bm{Q} \rangle = 0$. Hence, by the Pythagorean theorem, we have
% \begin{align*}
%     \|f(\bm{A}) - \bm{Q}\bm{X} \bm{Q}^\T\|_{\F}^2 &= \|f(\bm{A}) -\bm{Q} \bm{Q}^\T f(\bm{A})\bm{Q} \bm{Q}^\T + \bm{Q}(\bm{Q}^\T f(\bm{A})\bm{Q} - \bm{X})\bm{Q}^\T\|_{\F}^2 \\&= 
%     \|f(\bm{A}) -\bm{Q} \bm{Q}^\T f(\bm{A})\bm{Q} \bm{Q}^\T\|_{\F}^2 + \|\bm{Q}^\T f(\bm{A})\bm{Q} - \bm{X}\|_{\F}^2,
% \end{align*}
% as required.
\eqref{eq:robustness1} is immediate due to the Pythagorean theorem.

We now proceed with proving \eqref{eq:robustness2} using a similar argument to \cite[Proof of Theorem 5.1]{tropp2016randomized}. Define $\bm{C} = f(\bm{A}) - \bm{Q} \bm{Q}^\T f(\bm{A}) \bm{Q} \bm{Q}^\T + \bm{Q} \bm{X}\bm{Q}^\T$. Note that $\|\bm{C} - f(\bm{A})\|_{\F} = \|\bm{Q}^\T f(\bm{A}) \bm{Q} - \bm{X}\|_{\F}$ and $\bm{Q}^\T \bm{C} \bm{Q} =  \bm{X}$. Hence,
    \begin{align*}
        \|f(\bm{A}) - \bm{Q} \llbracket\bm{X}\rrbracket_k\bm{Q}^\T\|_{\F} &= \|f(\bm{A}) - \bm{Q}\llbracket \bm{Q}^\T \bm{C} \bm{Q}\rrbracket_k\bm{Q}^\T\|_{\F} 
        \\&\leq 
        \|f(\bm{A}) - \bm{C}\|_{\F} + \|\bm{C} - \bm{Q}\llbracket \bm{Q}^\T \bm{C} \bm{Q}\rrbracket_k\bm{Q}^\T\|_{\F} 
        \\&=
        \|\bm{Q}^\T f(\bm{A})\bm{Q}-\bm{X}\|_{\F} + \|\bm{C} - \bm{Q}\llbracket \bm{Q}^\T \bm{C} \bm{Q}\rrbracket_k\bm{Q}^\T\|_{\F}. \numberthis \label{eq:first_ineq}
    \end{align*}
    %Choose an orthogonal projector $\bm{P}$ so that $\range(\bm{P}) \subseteq \range(\bm{Q})$ and $\bm{Q} \llbracket \bm{Q}^\T f(\bm{A})\bm{Q}\rrbracket_k \bm{Q}^\T = \bm{P} f(\bm{A}) \bm{P}$.
    Since $\bm{Q}\llbracket \bm{Q}^\T \bm{C} \bm{Q}\rrbracket_k\bm{Q}^\T$ is the best rank $k$ approximation whose range is contained in $\range(\bm{Q})$ \cite[Lemma 3.3]{funnystrom2} (a similar result is given in \cite[Theorem 3.5]{gu_subspace}), we have
    \begin{align*}
        %\hspace{5em}&\hspace{-5em}
        \|\bm{C} - \bm{Q}\llbracket \bm{Q}^\T \bm{C} \bm{Q}\rrbracket_k\bm{Q}^\T\|_{\F} 
         \leq&\|\bm{C} - \bm{Q}\llbracket \bm{Q}^\T f(\bm{A}) \bm{Q}\rrbracket_k\bm{Q}^\T\|_{\F} \\
         \leq& \|\bm{Q}^\T f(\bm{A})\bm{Q}-\bm{X}\|_{\F} + \|f(\bm{A}) - \bm{Q}\llbracket \bm{Q}^\T f(\bm{A}) \bm{Q}\rrbracket_k\bm{Q}^\T\|_{\F}\numberthis \label{eq:final_ineq},
    \end{align*}
    % \begin{align*}
    %     \hspace{5em}&\hspace{-5em}\|\bm{C} - \bm{Q}\llbracket \bm{Q}^\T \bm{C} \bm{Q}\rrbracket_k\bm{Q}^\T\|_{\F} 
    %     \leq \|\bm{C} - \bm{P} \bm{C} \bm{P}\|_{\F} 
    %     \\&=
    %     \|(f(\bm{A}) - \bm{C}) - \bm{P}(f(\bm{A}) - \bm{C}) \bm{P}\|_{\F} + \|f(\bm{A}) - \bm{P} f(\bm{A}) \bm{P}\|_{\F} \\&\leq
    %     \|f(\bm{A}) - \bm{C}\|_{\F} + \|f(\bm{A}) - \bm{Q}\llbracket \bm{Q}^\T f(\bm{A}) \bm{Q}\rrbracket_k\bm{Q}^\T \|_{\F} 
    %     \\&=
    %     \|\bm{Q}^\T f(\bm{\bm{A}})\bm{Q}-\bm{X}\|_{\F} + \|f(\bm{A}) - \bm{Q}\llbracket \bm{Q}^\T f(\bm{A}) \bm{Q}\rrbracket_k\bm{Q}^\T \|_{\F}, \numberthis \label{eq:final_ineq}
    % \end{align*}
    % where the second inequality is due to the fact that for any matrix $\bm{D}$ one has $\|\bm{D} - \bm{P} \bm{D} \bm{P}\|_{\F} \leq \|\bm{D}\|_{\F}$. 
    where the second inequality is due to the fact that $\|f(\bm{A})-\bm{C}\|_\F =\|\bm{Q}^\T f(\bm{A})\bm{Q}-\bm{X}\|_{\F}$. Combining \eqref{eq:first_ineq} and \eqref{eq:final_ineq} yields the desired inequality.
\end{proof}

A corollary of \Cref{theorem:robust} is that the error of the approximation from \Cref{alg:krylow} will always be bounded from above by the error of the approximation from \Cref{alg:rsvd_matfun}, up to a polynomial approximation error of $f$:
\begin{corollary}
\label{corr:early_bigger_subspace}
    Let $\lambda_{\max}$ and $\lambda_{\min}$ be the largest and smallest eigenvalues of $\bm{A}$. Let $\bm{Q}_s$ and $\bm{X}$ be the output from \Cref{alg:krylow} and let $\bm{W}$ and $\widetilde{\bm{X}}$ be the output from \Cref{alg:rsvd_matfun} with the same input parameters and the same sketch matrix $\bm{\Omega}$. Then,
    \begin{align*}
        &\|f(\bm{A}) - \bm{Q}_s \llbracket\bm{X}\rrbracket_k \bm{Q}_s^\T\|_\F 
        \\&\hspace{2em}
        \leq \|f(\bm{A}) - \bm{W} \llbracket\widetilde{\bm{X}}\rrbracket_k \bm{W}^\T\|_\F + 4\sqrt{\ell s}  \inf\limits_{p \in \mathbb{P}_{2r+1}}\|f(x)-p(x)\|_{L^{\infty}([\lambda_{\min},\lambda_{\max}])}.
    \end{align*}
\end{corollary}
\begin{proof}
    Since $\range(\bm{Q}_s) \subseteq \range(\bm{W})$ we have
    \begin{align*}
        &\|f(\bm{A}) - \bm{Q}_s\llbracket\bm{Q}_s^\T f(\bm{A})\bm{Q}_s \rrbracket_k\bm{Q}_s^\T\|_{\F} 
        \\&\hspace{7em}\leq \|f(\bm{A}) - \bm{W}\llbracket\bm{W}^\T f(\bm{A})\bm{W} \rrbracket_k\bm{W}^\T\|_{\F} 
        \\&\hspace{14em}\leq 
        \|f(\bm{A}) - \bm{W}\llbracket\widetilde{\bm{X}}\rrbracket_k\bm{W}^\T\|_{\F},
    \end{align*}
    where we used that $\bm{W}\llbracket\bm{W}^\T f(\bm{A})\bm{W} \rrbracket_k\bm{W}^\T$ is the best rank $k$ approximation to $f(\bm{A})$ whose range and co-range is contained in $\range(\bm{W})$ \cite[Lemma 3.3]{funnystrom2}. Hence, by \Cref{theorem:robust} we have
    \begin{align*}
        \|f(\bm{A}) - \bm{Q}_s \llbracket \bm{X} \rrbracket_k \bm{Q}_s^\T\|_{\F} 
        &\leq \|f(\bm{A}) - \bm{Q}_s\llbracket\bm{Q}_s^\T f(\bm{A})\bm{Q}_s \rrbracket_k\bm{Q}_s^\T\|_{\F} + 2\|\bm{Q}_s^\T f(\bm{A})\bm{Q}_s - \bm{X}\|_{\F} 
        \\&\leq 
        \|f(\bm{A}) - \bm{W}\llbracket\widetilde{\bm{X}}\rrbracket_k\bm{W}^\T\|_{\F} + 2\|\bm{Q}_s^\T f(\bm{A})\bm{Q}_s - \bm{X}\|_{\F}.
    \end{align*}
    Applying \Cref{lemma:2_times_polynomial_approx} yields the desired result. 
\end{proof}
\Cref{corr:early_bigger_subspace} already shows why we expect the Krylov-aware approach in \Cref{alg:krylow} to outperform a naive combination of Krylov subspace methods and the randomized SVD in \Cref{alg:rsvd_matfun}. In fact, we might expect a major improvement, since $\range(\bm{Q}_s)$ is a significantly larger subspace than $\range(\bm{W})$. In the subsequent sections we will derive stronger bounds for the approximation returned by \Cref{alg:krylow} to better justify this intuition.

\subsection{Structural bounds}\label{section:structural}
We next derive structural bounds for $\|f(\bm{A})- \bm{Q}_s \bm{Q}_s^\T f(\bm{A}) \bm{Q}_s \bm{Q}_s^\T\|_{\F}$ and $\|f(\bm{A})- \bm{Q}_s \llbracket \bm{Q}_s^\T f(\bm{A}) \bm{Q}_s\rrbracket_k \bm{Q}_s^\T\|_{\F}$ that is true for \textit{any} sketch matrix $\bm{\Omega}$ as long as $\bm{\Omega}_k$ defined in \eqref{eq:omega_partition} has rank $k$. These bounds will allow us to obtain probabilistic bounds on the error of approximating $f(\bm{A})$, at least under the assumption that $\bm{Q}_s \bm{Q}_s^\T f(\bm{A}) \bm{Q}_s \bm{Q}_s^\T$ and $\bm{Q}_s \llbracket \bm{Q}_s^\T f(\bm{A}) \bm{Q}_s\rrbracket_k \bm{Q}_s^\T$ are computed exactly. As a reminder, we will remove this assumption in \Cref{section:krylow} using the perturbation bounds from \Cref{section:inexact_projections}.
%\David{I just realized that we need to comment on what happens when $\rank(f(\bm{A})) < k$. This is not a problem, and there is a way to fix it. I just need to think what the best way of doing that is. }

To state our bounds, we introduce the quantity
\begin{equation}
\label{eqn:min_ratio_omega}
    \mathcal{E}_{\bm{\Omega}}(s;f) =
    \min\limits_{p \in \mathbb{P}_{s-1}}\left[\|p(\bm{\Lambda}_{n \setminus k}) \bm{\Omega}_{n \setminus k} \bm{\Omega}_k^{\dagger}\|_{\F}^2\max\limits_{i=1,\ldots,k} \left|\frac{f(\lambda_i)}{p(\lambda_i)}\right|^2\right],
\end{equation}
which quantifies the extent to which an $(s-1)$ degree polynomial can be large (relative to $f$) on the eigenvalues $\lambda_1, \ldots, \lambda_k$ and small on the remaining eigenvalues. Recall that we order $\bm{A}$'s eigenvalues with respect to $f$, so $|f(\lambda_1)| \geq |f(\lambda_1)| \geq \ldots \geq |f(\lambda_n)|$.
\begin{lemma}\label{lemma:structural}
    Consider $\bm{A} \in \mathbb{R}^{n \times n}$ as defined in \eqref{eq:A}. Assuming $\bm{\Omega}_k$ in \eqref{eq:omega_partition} has rank $k$, for all functions $f: \mathbb{R} \to \mathbb{R}$, we have
    \begin{align}\label{eq:structural}
        \begin{split}
        &\|f(\bm{A}) - \bm{Q}_s  \bm{Q}_s^\T f(\bm{A})\bm{Q}_s \bm{Q}_s^\T \|_{\F}^2 
        \\&\hspace{7em}\leq \|f(\bm{A}) - \bm{Q}_s \llbracket \bm{Q}_s^\T f(\bm{A})\bm{Q}_s\rrbracket_k \bm{Q}_s^\T\|_{\F}^2 
        \\&\hspace{14em}\leq
        \|f(\bm{\Lambda}_{n \setminus k})\|_{\F}^2 + 5 \mathcal{E}_{\bm{\Omega}}(s;f).
        \end{split}
    \end{align}
\end{lemma}
From this bound, we can further see why \Cref{alg:krylow} should be preferred over directly applying the randomized SVD to $f(\bm{A})$. As an extreme case, consider when $f$ is a polynomial of degree at most $s-1$. Then the standard randomized SVD bound \cite[Theorem 9.1]{rsvd} essentially replaces $p$ with $f$ in $\mathcal{E}_{\bm{\Omega}}(s;f)$ in \eqref{eq:structural}:
\begin{equation*}
    \|f(\bm{A}) - \bm{W} \llbracket \bm{W}^T f(\bm{A}) \bm{W} \rrbracket_k \bm{W}\|_\F^2 \leq \|f(\bm{\Lambda}_{n \setminus k})\|_\F^2 + 5 \|f(\bm{\Lambda}_{n \setminus k}) \bm{\Omega}_{n \setminus k} \bm{\Omega}_k^{\dagger}\|_\F^2,
\end{equation*}
where $\bm{W}$ is an orthonormal basis for $\range(f(\bm{A}) \bm{\Omega})$. Since $\mathcal{E}_{\bm{\Omega}}(s;f)$ minimizes over \emph{all} degree $s-1$ polynomials, it is always smaller than  $\|f(\bm{\Lambda}_{n \setminus k}) \bm{\Omega}_{n \setminus k} \bm{\Omega}_k^{\dagger}\|_\F^2$. So, the approximation returned by \Cref{alg:krylow} is expected to be more accurate compared to the randomized SVD. When $f$ is not a polynomial, the error of the randomized SVD roughly corresponds to plugging a good polynomial approximation for $f$ into \cref{eqn:min_ratio_omega}, but again there might  be a better choice to minimize $\mathcal{E}_{\bm{\Omega}}(s;f)$.

Indeed, in many cases, we find that the improvement obtained from effectively optimizing over all possible degree $s-1$ polynomials is significant -- there is often a much better choice of polynomial than a direct approximation to $f$ for \cref{eqn:min_ratio_omega}. This is reflected in our experiments (\Cref{sec:experiments}) and we also provide a concrete analysis involving the matrix exponential in \Cref{section:exponential}.


% \begin{lemma}\label{lemma:structural}
%     Consider $\bm{A} \in \mathbb{R}^{n \times n}$ as defined in \eqref{eq:A}. Assuming $\bm{\Omega}_1$ in \eqref{eq:omega_partition} has rank $k$ and let $\bm{Q}_s$ be as in \Cref{alg:krylow}. Then for all functions $f: \mathbb{R} \mapsto \mathbb{R}$ we have
%     \begin{align}\label{eq:structural}
%     \begin{split}
%         \hspace{3em}&\hspace{-3em}\|f(\bm{A}) - \bm{Q}_s \bm{Q}_s^\T f(\bm{A})\bm{Q}_s \bm{Q}_s^\T\|_{\F}^2 \leq \|f(\bm{A}) - \bm{Q}_s \llbracket \bm{Q}_s^\T f(\bm{A})\bm{Q}_s\rrbracket_k \bm{Q}_s^\T\|_{\F}^2 
%         \\&\leq
%         \|f(\bm{\Lambda}_{n \setminus k})\|_{\F}^2 + 5 \min\limits_{p \in \mathbb{P}_{s-1}}\left[\|p(\bm{\Lambda}_{n \setminus k}) \bm{\Omega}_{n \setminus k} \bm{\Omega}_k^{\dagger}\|_{\F}^2 \cdot \max\limits_{i = 1,\ldots,k} \left|\frac{f(\lambda_i)}{p(\lambda_i)}\right|^2\right].
%         \end{split}
%     \end{align}
% \end{lemma}
\begin{proof}[Proof of \Cref{lemma:structural}]
The first inequality is due to the fact that $\bm{Q}_s\bm{Q}_s^{\T}f(\bm{A})\bm{Q}_s\bm{Q}_s^{\T}$ is the nearest matrix to $f(\bm{A})$ in the Frobenius norm whose range and co-range is contained in $\range(\bm{Q}_s)$ \cite[Lemma 3.3]{funnystrom2}. 
We proceed with proving the second inequality. 

To do so, it of course suffices to prove the inequality where $\mathcal{E}_{\bm{\Omega}}(s;f)$ is replaced with $\|p(\bm{\Lambda}_{n \setminus k}) \bm{\Omega}_{n \setminus k} \bm{\Omega}_k^{\dagger}\|_{\F}^2\cdot \max_{i=1,\ldots,k} \left|{f(\lambda_i)}/{p(\lambda_i)}\right|^2$ for any choice of $p \in \mathbb{P}_{s-1}$.
Note that if we choose $p$ so that $p(\lambda_i) = 0$ for some $i = 1,\ldots,k$ then the right hand side of \eqref{eq:structural} is infinite and the bound trivially holds. 
Hence, we may assume that $p(\lambda_i) \neq 0$ for $i = 1,\ldots,k$.
Consequently, $p(\bm{\Lambda}_k)$ is non-singular.
Define $\bm{Z} = p(\bm{A}) \bm{\Omega} \bm{\Omega}_k^{\dagger} p(\bm{\Lambda}_k)^{-1}$ and let $\widetilde{\bm{P}}$ be the orthogonal projector onto $\range(\bm{Z}) \subseteq \range(\bm{Q}_s)$.
Note that $\rank(\bm{Z}) \leq k$ and $\bm{Q}_s \llbracket\bm{Q}_s^\T f(\bm{A})\bm{Q}_s\rrbracket_{k} \bm{Q}_s^\T$ is the best rank $k$ approximation to $f(\bm{A})$ whose range and co-range is contained in $\range(\bm{Q}_s)$ \cite[Lemma 3.3]{funnystrom2}.
Hence,
\begin{equation*}
    \|f(\bm{A}) - \bm{Q}_s \llbracket\bm{Q}_s^\T f(\bm{A})\bm{Q}_s\rrbracket_{k} \bm{Q}_s^\T \|_{\F}^2 \leq \|f(\bm{A}) - \widetilde{\bm{P}}f(\bm{A})\widetilde{\bm{P}} \|_{\F}^2.
\end{equation*}
Now define $\widehat{\bm{P}} = \bm{U}^\T \widetilde{\bm{P}} \bm{U}$, which is the orthogonal projector onto $\range(\bm{U}^\T \bm{Z})$. By the unitary invariance of the Frobenius norm we have
\begin{equation*}
    \|f(\bm{A}) - \widetilde{\bm{P}}f(\bm{A})\widetilde{\bm{P}} \|_{\F}^2 = \|f(\bm{\Lambda}) - \widehat{\bm{P}} f(\bm{\Lambda}) \widehat{\bm{P}}\|_{\F}^2.
\end{equation*}
Furthermore, by Pythagorean theorem,
\begin{equation}\label{eq:two_terms}
    \|f(\bm{\Lambda}) - \widehat{\bm{P}} f(\bm{\Lambda}) \widehat{\bm{P}}\|_{\F}^2 = \|(\bm{I} - \widehat{\bm{P}}) f(\bm{\Lambda})\|_{\F}^2 + \|\widehat{\bm{P}} f(\bm{\Lambda})(\bm{I}-\widehat{\bm{P}})\|_{\F}^2.
\end{equation}
We are going to bound the two terms on the right hand side of \eqref{eq:two_terms} separately. 
Our analysis for the first is similar to the proof of \cite[Theorem 9.1]{rsvd}.

Note that since $\rank(\bm{\Omega}_k) = k$ we have $\bm{\Omega}_k \bm{\Omega}_k^{\dagger} = \bm{I}$. Hence,
\begin{equation*}
    \bm{U}^\T\bm{Z} = \bm{U}^\T p(\bm{A}) \bm{\Omega} \bm{\Omega}_k^{\dagger} p(\bm{\Lambda}_k)^{-1} = \begin{bmatrix} \bm{I} \\ p(\bm{\Lambda}_{n \setminus k}) \bm{\Omega}_{n \setminus k} \bm{\Omega}_k^{\dagger} p(\bm{\Lambda}_k)^{-1}\end{bmatrix} =: \begin{bmatrix} \bm{I} \\ \bm{F} \end{bmatrix}. 
\end{equation*}
Hence, 
\begin{align*}
    \bm{I}-\widehat{\bm{P}} &= \begin{bmatrix} \bm{I} - (\bm{I}+\bm{F}^\T \bm{F})^{-1} & -(\bm{I}+\bm{F}^\T \bm{F})^{-1}\bm{F}^\T \\ -\bm{F}(\bm{I}+\bm{F}^\T \bm{F})^{-1} & \bm{I} - \bm{F}(\bm{I}+\bm{F}^\T \bm{F})^{-1}\bm{F}^\T\end{bmatrix} \\
    &\preceq \begin{bmatrix} \bm{F}^\T \bm{F} & -(\bm{I}+\bm{F}^\T \bm{F})^{-1}\bm{F}^\T \\ -\bm{F}(\bm{I}+\bm{F}^\T \bm{F})^{-1} & \bm{I}\end{bmatrix},
\end{align*}
where the inequality is due to \cite[Proposition 8.2]{rsvd}. Consequently,
\begin{align*}
     \|(\bm{I} - \widehat{\bm{P}}) f(\bm{\Lambda})\|_{\F}^2 &= \tr(f(\bm{\Lambda})(\bm{I} - \widehat{\bm{P}})f(\bm{\Lambda})) 
     \\&\leq
      \|f(\bm{\Lambda}_{n \setminus k})\|_{\F}^2 + \|\bm{F}f(\bm{\Lambda}_k)\|_{\F}^2 \\&\leq
     \|f(\bm{\Lambda}_{n \setminus k})\|_{\F}^2 + \|p(\bm{\Lambda}_{n \setminus k})\bm{\Omega}_{n \setminus k} \bm{\Omega}_k^{\dagger}\|_{\F}^2\|p(\bm{\Lambda}_k)^{-1}f(\bm{\Lambda}_k)\|_2^2  
     \\&= \|f(\bm{\Lambda}_{n \setminus k})\|_{\F}^2 + \|p(\bm{\Lambda}_{n \setminus k})\bm{\Omega}_{n \setminus k} \bm{\Omega}_k^{\dagger}\|_{\F}^2 \max\limits_{i=1,\ldots,k} \left|\frac{f(\lambda_i)}{p(\lambda_i)}\right|^2. \numberthis \label{eq:first_term}
\end{align*}

We proceed with bounding the second term in \eqref{eq:two_terms}.
Our analysis is similar to the proof of \cite[Lemma 3.7]{persson_kressner_23}. 
By the triangle inequality we have 
\begin{equation*}
    \|\widehat{\bm{P}} f(\bm{\Lambda})(\bm{I}-\widehat{\bm{P}})\|_{\F} \leq \left\|\begin{bmatrix} \bm{0} & \\ & f(\bm{\Lambda}_{n \setminus k})\end{bmatrix} \widehat{\bm{P}}\right\|_{\F} + \left\|(\bm{I} - \widehat{\bm{P}}) \begin{bmatrix} f(\bm{\Lambda}_k) & \\ & \bm{0}\end{bmatrix}\right\|_{\F}.
\end{equation*}
Using a similar argument as in \eqref{eq:first_term} we have
\begin{equation}
    \left\|(\bm{I} - \widehat{\bm{P}}) \begin{bmatrix} f(\bm{\Lambda}_k) & \\ & \bm{0}\end{bmatrix} \right\|_{\F} \leq \|p(\bm{\Lambda}_{n \setminus k})\bm{\Omega}_{n \setminus k} \bm{\Omega}_k^{\dagger}\|_{\F}\max\limits_{i=1,\ldots,k} \left|\frac{f(\lambda_i)}{p(\lambda_i)}\right|,\label{eq:second_term}
\end{equation}
and since $\bm{F}(\bm{I}+\bm{F}^\T \bm{F})^{-1}\bm{F}^\T \preceq \bm{F}\bm{F}^\T$ we have
\begin{align*}
    \left\|\begin{bmatrix} \bm{0} & \\ & f(\bm{\Lambda}_{n \setminus k})\end{bmatrix} \widehat{\bm{P}}\right\|_{\F}^2 
    &= \tr\left(\begin{bmatrix} \bm{0} & \\ & f(\bm{\Lambda}_{n \setminus k})\end{bmatrix} \widehat{\bm{P}}\begin{bmatrix} \bm{0} & \\ & f(\bm{\Lambda}_{n \setminus k})\end{bmatrix}\right) 
    \\&=\tr(f(\bm{\Lambda}_{n \setminus k})\bm{F}(\bm{I} + \bm{F}^\T \bm{F})^{-1}\bm{F}^\T f(\bm{\Lambda}_{n \setminus k}))
    \\&\leq
    \tr(f(\bm{\Lambda}_{n \setminus k})\bm{F}\bm{F}^\T f(\bm{\Lambda}_{n \setminus k}))
    =
    \|f(\bm{\Lambda}_{n \setminus k}) \bm{F}\|_{\F}^2 
    \\&\leq \|f(\bm{\Lambda}_{n \setminus k})\|_2^2 \|p(\bm{\Lambda}_k)^{-1}\|_2^2 \|p(\bm{\Lambda}_{n \setminus k}) \bm{\Omega}_{n \setminus k} \bm{\Omega}_k^{\dagger}\|_{\F}^2 
    \\&\leq 
    \|p(\bm{\Lambda}_{n \setminus k})\bm{\Omega}_{n \setminus k} \bm{\Omega}_k^{\dagger}\|_{\F}^2\max\limits_{i=1,\ldots,k} \left|\frac{f(\lambda_i)}{p(\lambda_i)}\right|^2.\numberthis \label{eq:third_term}
\end{align*}
Inserting the bounds \eqref{eq:first_term}, \eqref{eq:second_term}, and \eqref{eq:third_term} into \eqref{eq:two_terms} and optimizing over $\mathbb{P}_{s-1}$ yields the desired inequality. 
\end{proof}

\subsection{Probabilistic bounds}\label{section:probabilistic}
%\David{Explain here that this is why this is much better than the randomized SVD}
With the structural bound available, we are ready to derive probabilistic bounds for $\|f(\bm{A})- \bm{Q}_s \bm{Q}_s^\T f(\bm{A}) \bm{Q}_s \bm{Q}_s^\T\|_{\F}$ and $\|f(\bm{A})- \bm{Q}_s \llbracket\bm{Q}_s^\T f(\bm{A}) \bm{Q}_s\rrbracket_k \bm{Q}_s^\T\|_{\F}$. Note that by \Cref{lemma:structural} it is sufficient to derive a probabilistic bound for $\mathcal{E}_{\bm{\Omega}}(s;f)$ defined in \cref{eqn:min_ratio_omega}. 


We will bound $\mathcal{E}_{\bm{\Omega}}(s;f)$ in terms of a deterministic quantity
\begin{equation}
\label{eqn:min_ratio}
    \mathcal{E}(s;f) =
    \min\limits_{p \in \mathbb{P}_{s-1}}\left[\|p(\bm{\Lambda}_{n \setminus k}) \|_{\F}^2\max\limits_{i=1,\ldots,k} \left|\frac{f(\lambda_i)}{p(\lambda_i)}\right|^2\right] ,
\end{equation}
which again quantifies how large a polynomial can be (relative to $f$) on the eigenvalues $\lambda_1, \ldots, \lambda_k$ and small on the remaining eigenvalues. However, $\mathcal{E}(s;f)$ does not depend on the randomness used by the algorithm.
\begin{lemma}\label{lemma:probabilistic}
    If $\bm{\Omega}$ is a standard Gaussian matrix, $\bm{\Omega}_k$ and $\bm{\Omega}_{n \setminus k}$ are as defined as in \eqref{eq:omega_partition}, and $\mathcal{E}_{\bm{\Omega}}(s;f)$ and $\mathcal{E}(s;f)$ are as defined in \cref{eqn:min_ratio_omega,eqn:min_ratio}, then
    \begin{enumerate}[(i)]
        \item for any $u,t\geq 0$, with probability at least $1-e^{-(u-2)/4} - \sqrt{\pi k} \left(\frac{t}{e}\right)^{-(\ell -k + 1)/2}$,
        \begin{align*}
            \mathcal{E}_{\bm{\Omega}}(s;f)\leq \frac{ut k}{\ell - k + 1} \mathcal{E}(s;f);
        \end{align*}\label{item:tailbound}
        \item if $\ell -k \geq 2$ we have \begin{align*}
            \mathbb{E}[\mathcal{E}_{\bm{\Omega}}(s;f)] 
            \leq \frac{k}{\ell-k-1} \mathcal{E}(s;f).
        \end{align*}\label{item:expectationbound}
    \end{enumerate}
\end{lemma}
% \begin{lemma}\label{lemma:probabilistic}
%     If $\bm{\Omega}$ is a standard Gaussian matrix, and $\bm{\Omega}_k$ and $\bm{\Omega}_{n \setminus k}$ are defined as in \eqref{eq:omega_partition}, then
%     \begin{enumerate}[(i)]
%         \item for any $u,t\geq 0$, with probability at least $1-e^{-(u-2)/4} - \sqrt{\pi k} \left(\frac{t}{e}\right)^{-(\ell -k + 1)/2}$ we have
%         \begin{align*}
%             \hspace{8em}&\hspace{-8em}\min\limits_{p \in \mathbb{P}_{s-1}}\left[\|p(\bm{\Lambda}_{n \setminus k}) \bm{\Omega}_{n \setminus k} \bm{\Omega}_k^{\dagger}\|_{\F}^2\max\limits_{i=1,\ldots,k} \left|\frac{f(\lambda_i)}{p(\lambda_i)}\right|^2\right] 
%             \\&\leq \frac{ut k}{\ell - k + 1} \min\limits_{p \in \mathbb{P}_{s-1}} \left[\|p(\bm{\Lambda}_{n \setminus k})\|_{\F}^2\max\limits_{i=1,\ldots,k} \left|\frac{f(\lambda_i)}{p(\lambda_i)}\right|^2 \right];
%         \end{align*}\label{item:tailbound}
%         \item if $\ell -k \geq 2$ we have \begin{align*}
%             \hspace{8em}&\hspace{-8em}\mathbb{E}\left[\min\limits_{p \in \mathbb{P}_{s-1}}\|p(\bm{\Lambda}_{n \setminus k}) \bm{\Omega}_{n \setminus k} \bm{\Omega}_k^{\dagger}\|_{\F}^2 \max\limits_{i=1,\ldots,k} \left|\frac{f(\lambda_i)}{p(\lambda_i)}\right|^2\right] 
%             \\&\leq \frac{k}{\ell-k-1} \min\limits_{p \in \mathbb{P}_{s-1}} \left[\|p(\bm{\Lambda}_{n \setminus k})\|_{\F}^2\max\limits_{i=1,\ldots,k} \left|\frac{f(\lambda_i)}{p(\lambda_i)}\right|^2\right].
%         \end{align*}\label{item:expectationbound}
%     \end{enumerate}
% \end{lemma}
\begin{proof}
\textit{(\ref*{item:tailbound})}: For any polynomial $p \in \mathbb{P}_{s-1}$ by \cite[Proposition 8.6]{tropp2023randomized} we have with probability at least $1-e^{-(u-2)/4} - \sqrt{\pi k} \left(\frac{t}{e}\right)^{-(\ell -k + 1)/2}$
\begin{equation*}
    \left[\|p(\bm{\Lambda}_{n \setminus k}) \bm{\Omega}_{n \setminus k} \bm{\Omega}_k^{\dagger}\|_{\F}^2\max\limits_{i=1,\ldots,k} \left|\frac{f(\lambda_i)}{p(\lambda_i)}\right|^2\right] \leq \frac{ut k}{\ell - k + 1}\left[\|p(\bm{\Lambda}_{n \setminus k})\|_{\F}^2\max\limits_{i=1,\ldots,k} \left|\frac{f(\lambda_i)}{p(\lambda_i)}\right|^2 \right].
\end{equation*}
The inequality is respected if we minimize both sides over all polynomials.

\textit{(\ref*{item:expectationbound})}: This is proven in an identical fashion utilizing the expectation bound in \cite[Proposition 8.6]{tropp2023randomized}.
\end{proof}

\subsection{Error bounds for Krylov aware low-rank approximation}\label{section:krylow}
% With the results in \Cref{section:inexact_projections}-\Cref{section:probabilistic} we are ready to start deriving a probabilistic error bound for the \Cref{alg:krylow}. We begin with a standard bound on how accurately we can compute the projection $\bm{Q}_s^\T f(\bm{A}) \bm{Q}_s$.
% \begin{lemma}\label{lemma:2_times_polynomial_approx}
% Let $\lambda_{\max}$ and $\lambda_{\min}$ denote the largest and smallest eigenvalue of $\bm{A}$. Let $\bm{T}_q$ and $\bm{Q}_s$ be as in \cref{alg:krylow}. Then, 
% \begin{align*}
%     &\|\bm{Q}_s^\T f(\bm{A})\bm{Q}_s - f(\bm{T}_q)_{1:d_s,1:d_s}\|_{\F} \leq 2\sqrt{d_s} \inf\limits_{p \in \mathbb{P}_{2r+1}}\|f(x)-p(x)\|_{L^{\infty}([\lambda_{\min},\lambda_{\max}])}.
% \end{align*}
% \end{lemma}
% \begin{proof}
% By \cite[Lemma 3.1]{chen_hallman_23} we know that for any polynomial $p \in \mathbb{P}_{2r+1}$ we have $\bm{Q}_s^\T p(\bm{A}) \bm{Q}_{s} = p(\bm{T}_q)_{1:d_s,1:d_s}$. Therefore,
% \begin{align*}
%     \|\bm{Q}_s^\T f(\bm{A})\bm{Q}_s - f(\bm{T}_q)_{1:d_s,1:d_s}\|_{\F}
%     &= \|\bm{Q}_1^\T f(\bm{A}) \bm{Q}_1 - \bm{Q}_1^\T p(\bm{T}) \bm{Q}_1 + p(\bm{T})_{1:d_s,1:d_s} - f(\bm{T})_{1:d_s,1:d_s} \|_{\F} 
%     \\&\leq \|\bm{Q}_1^\T f(\bm{A}) \bm{Q}_1 - \bm{Q}_1^\T p(\bm{A}) \bm{Q}_1 \|_{\F} +  \|(p(\bm{T}) - f(\bm{T}) )_{1:d_s,1:d_s} \|_{\F} 
%     \\&\leq \sqrt{d_s} \left( \|f(\bm{A}) - p(\bm{A}) \|_2 +  \| p(\bm{T})  - f(\bm{T}) \|_2\right)
%     \\&\leq 2 \sqrt{d_s} \|f(x) - p(x)\|_{L^{\infty}([\lambda_{\min},\lambda_{\max}])},
% \end{align*}
% where the last inequality is due to the fact that the spectrum of $\bm{T}$ is contained in $[\lambda_{\min},\lambda_{\max}]$.
% Optimizing over $p\in\mathbb{P}_{2r+1}$ gives the result.
% %Applying \cref{thm:lanczos_exact} with $\bm{Q}_s$ as the starting block and running block-Lanczos for $r+1$ iterations we have that, for any $p\in\mathbb{P}_{2r+1}$, $\bm{Q}_s^\T p(\bm{A}) \bm{Q}_s = p(\bm{T})_{1:d_s,1:d_s}$.
% %Therefore,
% %\begin{align*}
%     %\varepsilon_r
%     %&= \|\bm{Q}_1^\T f(\bm{A}) \bm{Q}_1 - \bm{Q}_1^\T p(\bm{T}) \bm{Q}_1 + p(\bm{T})_{1:d_s,1:d_s} - f(\bm{T})_{1:d_s,1:d_s} \|_{\F} 
%     %\\&\leq \|\bm{Q}_1^\T f(\bm{A}) \bm{Q}_1 - \bm{Q}_1^\T p(\bm{A}) \bm{Q}_1 \|_{\F} +  \|(p(\bm{T}) - f(\bm{T}) )_{1:d_s,1:d_s} \|_{\F} 
%     %\\&\leq \sqrt{d_s} \left( \|f(\bm{A}) - p(\bm{A}) \|_2 +  \| p(\bm{T}) \bm{E}_1 - f(\bm{T}) \|_2\right)
%     %\\&\leq 2 \sqrt{d_s} \|f(x) - p(x)\|_{L^{\infty}([\lambda_{\min},\lambda_{\max}])},
% %\end{align*}
% %where the last inequality is due to the fact that the spectrum of $\bm{T}$ is contained in $[\lambda_{\min},\lambda_{\max}]$.
% %Optimizing over $p\in\mathbb{P}_{2r-1}$ gives the result.
% \end{proof}


%\subsection{Bounds for computing quadratic forms}
%Consider the error 
%\begin{equation}\label{eq:error}
 %   \varepsilon_r := \|\bm{Q}_1^\T f(\bm{A}) \bm{Q}_1 - f(\bm{T})_{1:d_s, 1:d_s}\|_{\F}.
%\end{equation}
%If $f\in\mathbb{P}_{2r+1}$ then $\epsilon_r = 0$. 
%In fact, if $f$ is near to a degree $2r+1$ polynomial, then $\epsilon_r$ is small.

%\begin{remark}
%Suppose that $f(x)^s$ is approximated well with a degree $q$ polynomial $\tilde{p}_q$. Then, define
%\begin{equation*}
    %p_q(x) = f(\lambda_{k}) \frac{\tilde{p}_q(x)}{f(\lambda_{k}) ^s}\approx f(\lambda_{k}) \frac{f(x)^s}{f(\lambda_{k}) ^s}.
%\end{equation*}
%In this case, we can set $\delta_{q}(x) \approx f(\lambda_{k}) \frac{f(x)^s}{f(\lambda_{k}) ^s}$, which would give subspace iteration.

%\end{remark}



%\tyler{if $f$ is operator monotone, can we show $\epsilon_r$ is on the order of $\|f(\bm{\Lambda}_2)\|$}

%\hrulefill

%\begin{proof}
%Note that it suffices to show the statement whenever $f$ is a monomial of degree at most $2r+3$. For any polynomial of degree $0$ the statement is trivial. Hence, we proceed with monomials of degree at least $1$. Note that we have the following recurrence relation
%\begin{equation*}
 %   \bm{A}\bm{Q} = \bm{Q}\bm{T} + \bm{Q}_{q+1}\bm{R}_{q+1} \bm{E}_{q+1}^\T,
%\end{equation*}
%where
%\begin{equation*}
 %   \bm{E}_{q+1} = \begin{bmatrix} \bm{0}_{\ell q \times \ell} \\ \bm{I}_{\ell \times \ell} \end{bmatrix}.
%\end{equation*}
%By induction one can show that 
%\begin{equation*}
    %\bm{A}^d \bm{Q}\bm{E}_i = \bm{Q}\bm{T}^d \bm{E}_i + \sum\limits_{j=0}^{d-1}\bm{A}^{d-j-1}\bm{Q}_{q+1}\bm{R}_{q+1}\bm{E}_{q+1}^\T\bm{T}^j \bm{E}_i.
%\end{equation*}
%Note that $\bm{T}$ is a block tridiagonal matrix with blocks of sizes $\ell \times \ell$. Consequently, the $\ell-$block bandwidth of $\bm{T}^j$ is equal to $j$. Hence, whenever $q+1-i > j$ we have that $\bm{E}_{q+1}^\T\bm{T}^j \bm{E}_i = \bm{0}$. Consequently, whenever $q+1-i \geq d$ we have
%\begin{equation*}
    %\bm{A}^d\bm{Q}_i = \bm{A}^d \bm{Q}\bm{E}_i = \bm{Q}\bm{T}^d \bm{E}_i = \bm{Q}(\bm{T}^r)_{:,((i-1)\ell+1):i\ell}.
%\end{equation*}
%Hence, whenever $q-s+1 \geq d$
%\begin{equation*}
%    \bm{A}^d \bm{Q}_{:,1:\ell s} = \bm{Q}_{:,1:\ell s}(\bm{T}^d)_{:,1:\ell s}.
%\end{equation*}
%Hence,
%\begin{align*}
    %&\bm{Q}^\T_{:,1:ks} \bm{A}^{2d}\bm{Q}^\T_{:,1:ks} = (\bm{T}^{2r})_{1:\ell s,1:\ell s};\\
    %&\bm{Q}^\T_{:,1:ks} \bm{A}^{2d+1}\bm{Q}^\T_{:,1:ks} = (\bm{T}^r)_{:,1:\ell s}^\T\bm{Q}_{:,1:\ell s}^\T \bm{A}\bm{Q}_{:,1:\ell s}(\bm{T}^d)_{:,1:\ell s} = (\bm{T}^{2d+1})_{1:\ell s,1:\ell s},
%\end{align*}
%which implies that for any monomial of degree at most $2(q-s+1)+1 = 2r+3$ the result holds, as required. 

%\end{proof}


% \Chris{This corollary would only be immediate if you know the prior work. My experience in the past is many people in NLA don't know the triangle inequality analysis of Lanczos. I also don't see a Lemma 2.2 in  \cite{chen_hallman_23}. What is the correct number? We should remind them what $d_s$ is, especially since the corollary doesn't define $s$.} \David{REMINDER: check if Lemma 2.2 is in the Arxiv version. }
% \tyler{I think its still immediate even if you don't know it. we will update arxiv whenever the paper is published so that the numbers match. I think we can just use $s$ instead for simplicity since $d_s\leq s$ (and probably is typically equal).}
%We have the following immediate corollary.
%\begin{corollary}\label{corollary:best_poly_approx}
%Let $\lambda_{\max}$ and $\lambda_{\min}$ denote the largest and smallest eigenvalue of $\bm{A}$. Then, under the assumptions of \Cref{lemma:krylov_nested} we have
%\begin{align*}
 %   &\varepsilon_r \leq 2\sqrt{d_s} \inf\limits_{p \in \mathbb{P}_{2r+1}}\|f(x)-p(x)\|_{L^{\infty}([\lambda_{\min},\lambda_{\max}])}.
%\end{align*}
%\end{corollary}
%\begin{proof}
%Note that $\varepsilon_r \leq \sqrt{d_s}\|\bm{Q}_1^\T f(\bm{A})\bm{Q}_1 - f(\bm{T})_{1:\ell s,1:\ell s}\|_2$. The result is obtained by applying \cref{thm:lanczos_exact}.
%Hence, it suffices to show the result for the operator norm. By Lemma~\ref{lemma:polynomial_exactness} we have
%\begin{align*}
 %    &\|\bm{Q}_{:,1:ks}^\T f(\bm{A})\bm{Q}_{:,1:ks} - f(\bm{T})_{1:ks,1:ks}\|_2 =\\ &\|\bm{Q}_{:,1:ks}^\T f(\bm{A})\bm{Q}_{:,1:ks} - \bm{Q}_{:,1:ks}^\T p(\bm{A})\bm{Q}_{:,1:ks} + \bm{Q}_{:,1:ks}^\T p(\bm{A})\bm{Q}_{:,1:ks} - f(\bm{T})_{1:ks,1:ks}\|_2 \leq \\
  %  &\|\bm{Q}_{:,1:ks}^\T f(\bm{A})\bm{Q}_{:,1:ks} - \bm{Q}_{:,1:ks}^\T p(\bm{A})\bm{Q}_{:,1:ks} + p(\bm{T})_{1:ks,1:ks} - f(\bm{T})_{1:ks,1:ks}\|_2 \leq \\
   % &\|\bm{Q}_{:,1:ks}^\T f(\bm{A})\bm{Q}_{:,1:ks} - \bm{Q}_{:,1:ks}^\T p(\bm{A})\bm{Q}_{:,1:ks}\|_2 + \|p(\bm{T})_{1:ks,1:ks} - f(\bm{T})_{1:ks,1:ks}\|_2 \leq \\
    %&\|f(\bm{A}) - p(\bm{A})\|_2 + \|p(\bm{T}) - f(\bm{T})\|_2 \leq 2\mathcal{E}(2r+3, \Lambda(\bm{A}),f).
%\end{align*}
%The result follows since $p$ was arbitrary. 
%\end{proof}
%\subsection{Low rank approximation bounds}
%\begin{remark}
 %   Mention that we want to have bounds when we truncate because we might want to use it  downstream for matvecs and the rank can be quite large since $f$ can be arbitrary. 
%\end{remark}
%\Chris{I also just think we should set up the problem from the beginning that of low-rank approximation of matrix functions, so our goal is to output a fixed rank approximation.}
%\Chris{I would probably seperate out the claims in this Lemma to faciliate easier discussion of why that are interesting claims.}
%\begin{lemma}\label{lemma:structural}
 %    Consider $\bm{A} \in \mathbb{R}^{n \times n}$ as defined in \eqref{eq:A} and a matrix function $f: \mathbb{R} \mapsto \mathbb{R}$. Assuming $\bm{\Omega}_1$ in \eqref{eq:omega_partition} has rank $k$ and assume that $\bm{Q}_1$ and $\bm{T}$ are as in \Cref{alg:krylow}. Then the following hold
     %\begin{enumerate}[(i)]
      %   \item $\|f(\bm{A}) - \bm{Q}_1f(\bm{T})_{1:d_s,1:d_s} \bm{Q}_1^\T\|_{\F}^2 = \|f(\bm{A}) - \bm{Q}_1 \bm{Q}_1^\T f(\bm{A})\bm{Q}_1 \bm{Q}_1^\T\|_{\F}^2 + \varepsilon_r^2$; \label{item:untruncated}
       %  \item $\|f(\bm{A}) - \bm{Q}_1(f(\bm{T})_{1:d_s,1:d_s} )_{(k)}\bm{Q}_1^\T\|_{\F} \leq  \|f(\bm{A}) - \bm{Q}_1 (\bm{Q}_1^\T f(\bm{A})\bm{Q}_1)_{(k)} \bm{Q}_1^\T\|_{\F} + 2\varepsilon_r$; \label{item:truncated}
        % \item $\|f(\bm{A}) - \bm{Q}_1 \bm{Q}_1^\T f(\bm{A})\bm{Q}_1 \bm{Q}_1^\T\|_{\F} \leq \|f(\bm{A}) - \bm{Q}_1 (\bm{Q}_1^\T f(\bm{A})\bm{Q}_1)_{(k)} \bm{Q}_1^\T\|_{\F}$; \label{item:exact_comparison}
       %  \item $\|f(\bm{A}) - \bm{Q}_1 (\bm{Q}_1^\T f(\bm{A})\bm{Q}_1)_{(k)} \bm{Q}_1^\T\|_{\F}^2 \leq \|f(\bm{\Lambda}_2)\|_{\F}^2 + 5 \min\limits_{p \in \mathbb{P}_{s-1}}\left[\|p(\bm{\Lambda}_2) \bm{\Omega}_2 \bm{\Omega}_1^{\dagger}\|_{\F}^2 \cdot \max\limits_{i = 1,\ldots,k} \left|\frac{f(\lambda_i)}{p(\lambda_i)}\right|^2\right]$.\label{item:exact_truncated_bound}
     %\end{enumerate}
%\end{lemma}
%\begin{proof}
%\textit{(\ref*{item:untruncated})} Since $\bm{Q}_1 \bm{Q}_1^\T f(\bm{A})\bm{Q}_1 \bm{Q}_1^\T$ is the nearest matrix to $f(\bm{A})$ whose range and co-range is contained in $\bm{Q}_1$ \textcolor{red}{cite this} we know that $\langle f(\bm{A})-\bm{Q}_1 \bm{Q}_1^\T f(\bm{A})\bm{Q}_1 \bm{Q}_1^\T, \bm{Q}_1 \bm{B}\bm{Q}_1 \rangle = 0$ for any matrix $\bm{B}$. Hence, by Pythagoras theorem we have
%\begin{align*}
 %   &\|f(\bm{A}) - \bm{Q}_1f(\bm{T})_{1:d_s,1:d_s} \bm{Q}_1^\T\|_{\F}^2 = \|f(\bm{A}) -\bm{Q}_1 \bm{Q}_1^\T f(\bm{A})\bm{Q}_1 \bm{Q}_1^\T + \bm{Q}_1(\bm{Q}_1^\T f(\bm{A})\bm{Q}_1 - f(\bm{T})_{1:d_s,1:d_s})\bm{Q}_1^\T\|_{\F}^2 = \\
  %  &\|f(\bm{A}) -\bm{Q}_1 \bm{Q}_1^\T f(\bm{A})\bm{Q}_1 \bm{Q}_1^\T\|_{\F}^2 + \|\bm{Q}_1^\T f(\bm{A})\bm{Q}_1 - f(\bm{T})_{1:d_s,1:d_s}\|_{\F}^2=\|f(\bm{A}) -\bm{Q}_1 \bm{Q}_1^\T f(\bm{A})\bm{Q}_1 \bm{Q}_1^\T\|_{\F}^2 + \varepsilon_r^2,
%\end{align*}
%as required.

%\textit{(\ref*{item:truncated})}: Define $\bm{B} = f(\bm{A}) - \bm{Q}_1 \bm{Q}_1^\T f(\bm{A}) \bm{Q}_1 \bm{Q}_1^\T + \bm{Q}_1 f(\bm{T})_{1:d_s, 1:d_s}\bm{Q}_1^\T$. Note that $\|\bm{B} - f(\bm{A})\|_{\F} = \varepsilon_r$ and $\bm{Q}_1\bm{Q}_1^\T \bm{B} \bm{Q}_1\bm{Q}_1^\T = \bm{Q}_1 f(\bm{T})_{1:d_s, 1:d_s} \bm{Q}_1^\T$.\footnote{This shows that Lanczos exactly computes a quadratic form of a matrix $\bm{B}$ which is near to $f(\bm{A})$. } Hence,
 %   \begin{align*}
  %      &\|f(\bm{A}) - \bm{Q}_{1} (f(\bm{T})_{1:d_s,1:d_s})_{(k)}\bm{Q}_{1}^\T\|_{\F} = \|f(\bm{A}) - (\bm{Q}_{1}\bm{Q}_{1}^\T \bm{B} \bm{Q}_{1}\bm{Q}_{1}^\T)_{(k)}\|_{\F} \leq \\
   %     & \|f(\bm{A}) - \bm{B}\|_{\F} + \|\bm{B} - (\bm{Q}_{1}\bm{Q}_{1}^\T \bm{B} \bm{Q}_{1}\bm{Q}_{1}^\T)_{(k)}\|_{\F} =\\
    %    &\varepsilon_r + \|\bm{B} - (\bm{Q}_{1}\bm{Q}_{1}^\T \bm{B} \bm{Q}_{1}\bm{Q}_{1}^\T)_{(k)}\|_{\F}. \numberthis \label{eq:first_ineq}
    %\end{align*}
    %Choose an orthogonal projector $\bm{P}$ so that $\range(\bm{P}) \subseteq \range(\bm{Q}_1)$ and $(\bm{Q}_1 \bm{Q}_1^\T f(\bm{A})\bm{Q}_1 \bm{Q}_1^\T)_{(k)} = \bm{P} f(\bm{A}) \bm{P}$. Since $(\bm{Q}_{1}\bm{Q}_{1}^\T \bm{B} \bm{Q}_{1}\bm{Q}_{1}^\T)_{(k)}$ is the best rank $k$ approximation whose range is contained in $\range(\bm{Q}_1)$ \textcolor{red}{cite this}, we have
    %\begin{align*}
     %   &\|\bm{B} - (\bm{Q}_{1}\bm{Q}_{1}^\T \bm{B} \bm{Q}_{1}\bm{Q}_{1}^\T)_{(k)}\|_{\F} \leq \|\bm{B} - \bm{P} \bm{B} \bm{P}\|_{\F} = \\
      %  & \|(f(\bm{A}) - \bm{B}) - \bm{P}(f(\bm{A}) - \bm{B}) \bm{P}\|_{\F} + \|f(\bm{A}) - \bm{P} f(\bm{A}) \bm{P}\|_{\F} \leq\\
       % &\|f(\bm{A}) - \bm{B}\|_{\F} + \|f(\bm{A}) - \bm{Q}_1(\bm{Q}_1^\T f(\bm{A}) \bm{Q}_1)_{(k)}\bm{Q}_{1}^\T \|_{\F} =\\
        %&\varepsilon_r + \|f(\bm{A}) - \bm{Q}_1(\bm{Q}_1^\T f(\bm{A}) \bm{Q}_1)_{(k)}\bm{Q}_{1}^\T \|_{\F}. \numberthis \label{eq:final_ineq}
    %\end{align*}
    %Combining \eqref{eq:first_ineq} and \eqref{eq:final_ineq} yields the desired inequality.

    %\textit{(\ref*{item:exact_comparison})}: Let $\bm{P}$ be the proj ector from the proof of \textit{(\ref*{item:truncated})}. Hence, $\range(\bm{P}) \subseteq \range(\bm{Q}_1)$. Since $\bm{Q}_1 \bm{Q}_1^\T f(\bm{A}) \bm{Q}_1 \bm{Q}_1^\T$ is the nearest matrix to $f(\bm{A})$ whose range and co-range is contained in $\range(\bm{Q}_1)$ and $\bm{P} f(\bm{A}) \bm{P}$ is a matrix whose range and co-range is contained in $\range(\bm{Q}_1)$ we have
    %\begin{equation*}
     %   \|f(\bm{A}) - \bm{Q}_1 \bm{Q}_1^\T f(\bm{A})\bm{Q}_1 \bm{Q}_1^\T\|_{\F} \leq \|f(\bm{A}) - \bm{Q}_1 (\bm{Q}_1^\T f(\bm{A})\bm{Q}_1)_{(k)} \bm{Q}_1^\T\|_{\F},
    %\end{equation*}
    %as required.

    %\textit{(\ref*{item:exact_truncated_bound})}: Choose any $p \in \mathbb{P}_{s-1}$. Note that if we choose $p$ so that $p(\lambda_i) = 0$ for some $i = 1,\ldots,k$ then the right hand side of \textit{(\ref*{item:exact_truncated_bound})} is infinity and the bound trivially holds. Hence, we may assume that $p(\lambda_i) \neq 0$ for $i = 1,\ldots,k$. Consequently, $p(\bm{\Lambda}_1)$ is non-singular. Define $\bm{Z} = p(\bm{A}) \bm{\Omega} \bm{\Omega}_1^{\dagger} p(\bm{\Lambda}_1)^{-1}$ and let $\widetilde{\bm{P}}$ be the orthogonal projector onto $\range(\bm{Z}) \subseteq \range(\bm{Q}_1)$. Note that $\rank(\bm{Z}) \leq k$ and $\bm{Q}_1 (\bm{Q}_1^\T f(\bm{A})\bm{Q}_1)_{(k)} \bm{Q}_1^\T$ is the best rank $k$ approximation to $f(\bm{A})$ whose range and co-range is contained in $\range(\bm{Q}_1)$. Hence,
%\begin{equation*}
 %   \|f(\bm{A}) - \bm{Q}_1 (\bm{Q}_1^\T f(\bm{A})\bm{Q}_1)_{(k)} \bm{Q}_1^\T \|_{\F}^2 \leq \|f(\bm{A}) - \widetilde{\bm{P}}f(\bm{A})\widetilde{\bm{P}} \|_{\F}^2.
%\end{equation*}
%Now define $\widehat{\bm{P}} = \bm{U}^\T \widetilde{\bm{P}} \bm{U}$, which is the orthogonal projector onto $\range(\bm{U}^\T \bm{Z})$. By the unitary invariance of the Frobenius norm we have
%\begin{equation*}
 %   \|f(\bm{A}) - \widetilde{\bm{P}}f(\bm{A})\widetilde{\bm{P}} \|_{\F}^2 = \|f(\bm{\Lambda}) - \widehat{\bm{P}} f(\bm{\Lambda}) \widehat{\bm{P}}\|_{\F}^2.
%\end{equation*}
%Furthermore,
%\begin{equation}\label{eq:two_terms}
 %   \|f(\bm{\Lambda}) - \widehat{\bm{P}} f(\bm{\Lambda}) \widehat{\bm{P}}\|_{\F}^2 = \|(\bm{I} - \widehat{\bm{P}}) f(\bm{\Lambda})\|_{\F}^2 + \|\widehat{\bm{P}} f(\bm{\Lambda})(\bm{I}-\widehat{\bm{P}})\|_{\F}^2.
%\end{equation}
%We are going to bound the two terms on the right hand side of \eqref{eq:two_terms} separately. We begin with the first term. 

%Note that 
%\begin{equation*}
 %   \bm{U}^\T\bm{Z} = \bm{U}^\T p(\bm{A}) \bm{\Omega} \bm{\Omega}_1^{\dagger} p(\bm{\Lambda}_1)^{-1} = \begin{bmatrix} \bm{I}_k \\ p(\bm{\Lambda}_2) \bm{\Omega}_2 \bm{\Omega}_1^{\dagger} p(\bm{\Lambda}_1)^{-1}\end{bmatrix} := \begin{bmatrix} \bm{I}_k \\ \bm{F} \end{bmatrix}. 
%\end{equation*}
%Hence, 
%\begin{align*}
 %   \bm{I}-\widehat{\bm{P}} &= \begin{bmatrix} \bm{I}_k - (\bm{I}_k+\bm{F}^\T \bm{F})^{-1} & -(\bm{I}_k+\bm{F}^\T \bm{F})^{-1}\bm{F}^\T \\ -\bm{F}(\bm{I}_k+\bm{F}^\T \bm{F})^{-1} & \bm{I}_{n-k} - \bm{F}(\bm{I}_k+\bm{F}^\T \bm{F})^{-1}\bm{F}^\T\end{bmatrix} \preceq \\
  %  &\begin{bmatrix} \bm{F}^\T \bm{F} & -(\bm{I}_k+\bm{F}^\T \bm{F})^{-1}\bm{F}^\T \\ -\bm{F}(\bm{I}_k+\bm{F}^\T \bm{F})^{-1} & \bm{I}_{n-k}\end{bmatrix},
%\end{align*}
%where the inequality is due to \cite[Proposition 8.2]{rsvd}. Consequently,
%\begin{align*}
 %    &\|(\bm{I} - \widehat{\bm{P}}) f(\bm{\Lambda})\|_{\F}^2 = \tr(f(\bm{\Lambda})(\bm{I} - \widehat{\bm{P}})f(\bm{\Lambda})) \leq\\& \|\bm{F}f(\bm{\Lambda}_1)\|_{\F}^2 + \|f(\bm{\Lambda}_2)\|_{\F}^2 \leq \|f_2(\bm{\Lambda}_2)\|_{\F}^2 + \|p(\bm{\Lambda}_2)\bm{\Omega}_2 \bm{\Omega}_1^{\dagger}\|_{\F}^2\|p(\bm{\Lambda}_1)^{-1}f(\bm{\Lambda}_1)\|_2^2  = \\
  %   & \|f_2(\bm{\Lambda}_2)\|_{\F}^2 + \|p(\bm{\Lambda}_2)\bm{\Omega}_2 \bm{\Omega}_1^{\dagger}\|_{\F}^2 \max\limits_{i=1,\ldots,k} \left|\frac{f(\lambda_i)}{p(\lambda_i)}\right|^2. \numberthis \label{eq:first_term}
%\end{align*}

%We proceed with bounding the second term in \eqref{eq:two_terms}. By the triangle inequality we have 
%\begin{equation*}
 %   \|\widehat{\bm{P}} f(\bm{\Lambda})(\bm{I}-\widehat{\bm{P}})\|_{\F} \leq \|\begin{bmatrix} \bm{0} & \\ & f(\bm{\Lambda}_2)\end{bmatrix} \widehat{\bm{P}}\|_{\F} + \|(\bm{I} - \widehat{\bm{P}}) \begin{bmatrix} f(\bm{\Lambda}_1) & \\ & \bm{0}\end{bmatrix}\|_{\F}.
%\end{equation*}
%Using a similar argument as in \eqref{eq:first_term} we have
%\begin{equation}
 %   \|(\bm{I} - \widehat{\bm{P}}) \begin{bmatrix} f(\bm{\Lambda}_1) & \\ & \bm{0}\end{bmatrix}\|_{\F} \leq \|p(\bm{\Lambda}_2)\bm{\Omega}_2 \bm{\Omega}_1^{\dagger}\|_{\F}\max\limits_{i=1,\ldots,k} \left|\frac{f(\lambda_i)}{p(\lambda_i)}\right|,\label{eq:second_term}
%\end{equation}
%and since $\bm{F}(\bm{I}_k+\bm{F}^\T \bm{F})^{-1}\bm{F}^\T \preceq \bm{F}\bm{F}^\T$ we have
%\begin{align*}
 %   &\|\begin{bmatrix} \bm{0} & \\ & f(\bm{\Lambda}_2)\end{bmatrix} \widehat{\bm{P}}\|_{\F} \leq \|f(\bm{\Lambda}_2) \bm{F}\|_{\F} \leq \|f(\bm{\Lambda}_2)\|_2^2 \|p(\bm{\Lambda}_1)^{-1}\|_2 \|p(\bm{\Lambda}_2) \bm{\Omega}_2 \bm{\Omega}_1^{\dagger}\|_{\F} \leq \\
  %  &\|p(\bm{\Lambda}_2)\bm{\Omega}_2 \bm{\Omega}_1^{\dagger}\|_{\F}\max\limits_{i=1,\ldots,k} \left|\frac{f(\lambda_i)}{p(\lambda_i)}\right|.\numberthis \label{eq:third_term}
%\end{align*}
%Inserting the bounds \eqref{eq:first_term}, \eqref{eq:second_term}, and \eqref{eq:third_term} into \eqref{eq:two_terms} yields the desired inequality. 
%\end{proof}

%To obtain probabilistic bounds we only need to obtain bounds for $\|p(\bm{\Lambda}_2) \bm{\Omega}_2 \bm{\Omega}_1^{\dagger}\|_{\F}^2$, but these are classical results in the randomized low rank approximation literature. \textcolor{red}{say something about Jensen's inequality for expectation bounds.}

%\begin{lemma}\label{lemma:constrained_best_rank_k}
%Let $\bm{Q} \in \mathbb{R}^{n \times \ell}$ be an orthormal basis. Then
%\begin{equation*}
 %   \|\bm{A}-\bm{Q}(\bm{Q}^\T \bm{A}\bm{Q})_k\bm{Q}^\T\|_{\F} = \min\limits_{\bm{C} = \bm{B}^\T, \rank(\bm{C}) \leq k}\|\bm{A} - \bm{Q} \bm{C}\bm{Q}^\T\|_{\F}^2
%\end{equation*}
%\end{lemma}
%\begin{proof}
%We have
%\begin{align*}
 %   &\|\bm{A} - \bm{Q} \bm{C}\bm{Q}^\T \|_{\F}^2 = \|\bm{A}- \bm{Q}\bm{Q}^\T \bm{A}\bm{Q}\bm{Q}^\T + \bm{Q}\bm{Q}^\T \bm{A}\bm{Q}\bm{Q}^\T - \bm{Q}\bm{C}\bm{Q}\|_{\F}^2 = \\
  %  & \|\bm{A} - \bm{Q}\bm{Q}\bm{A}\bm{Q}\bm{Q}^\T\|_{\F}^2 + \|\bm{Q}^\T \bm{A}\bm{Q} - \bm{C}\|_{\F}^2 + 2\tr((\bm{A} - \bm{Q}\bm{Q}\bm{A}\bm{Q}\bm{Q}^\T)(\bm{Q}\bm{Q}\bm{A}\bm{Q}\bm{Q}^\T - \bm{Q}\bm{C}\bm{Q}^\T))=\\
   % = &\|\bm{A} - \bm{Q}\bm{Q}\bm{A}\bm{Q}\bm{Q}^\T\|_{\F}^2 +\|\bm{Q}^\T \bm{A}\bm{Q} - \bm{C}\|_{\F}^2,
%\end{align*}
%The choice of $\bm{C}$ that minimizes this expression is $\bm{C} = (\bm{Q}^\T \bm{A} \bm{Q})_k$. 
%\end{proof}
%\begin{lemma}\label{lemma:exact_constrained}
%We have
 %   \begin{align*}
  %      &\|f(\bm{A}) - \bm{Q}_{:,1:\ell s}(\bm{Q}_{:,1:\ell s}^\T f(\bm{A}) \bm{Q}_{:,1:\ell s})_k\bm{Q}_{:,1:\ell s}^\T \|_{\F}^2 \leq \\
        %&\|f(\bm{\Lambda}_2)\|_{\F}^2 + 5 \min\limits_{p \in \mathbb{P}_{s-1}}\left[\|p(\bm{\Lambda}_2) \bm{\Omega}_2 \bm{\Omega}_1^{\dagger}\|_{\F}^2 \cdot \max\limits_{i = 1,\ldots,k} \left|\frac{f(\lambda_i)}{p(\lambda_i)}\right|^2\right].
    %\end{align*}
%\end{lemma}
%\begin{proof}
%Let $\bm{X} = p(\bm{A}) \bm{\Omega} \bm{\Omega}_1^{\dagger} p(\bm{\Lambda}_1)^{-1}$. We have
%\begin{equation*}
 %   \range(\bm{X}) \subseteq \range(p(\bm{A}) \bm{\Omega}) \subseteq \range(\bm{Q}_{:,1:\ell s}).
%\end{equation*}
%By Lemma~\ref{lemma:constrained_best_rank_k} we know 
%\begin{equation*}
 %   \|f(\bm{A}) - \bm{Q}_{:,1:\ell s}(\bm{Q}_{:,1:\ell s}^\T f(\bm{A}) \bm{Q}_{:,1:\ell s})_k\bm{Q}_{:,1:\ell s}^\T \|_{\F} \leq 
  %  \|f(\bm{A}) - \bm{P}_{\bm{X}} f(\bm{A}) \bm{P}_{\bm{X}}\|_{\F}.
%\end{equation*}
%The rest of the proof follows the proof of Lemma~\ref{lemma:structural}.
%\end{proof}

%\subsection{Krylov aware Nyström approximation}

%\begin{algorithm}
%\caption{Krylov aware Nyström approximation}
%\label{alg:krylow_nystrom}
%\textbf{input:} Symmetric $\bm{A} \in \mathbb{R}^{n \times n}$. Rank $k$. Oversampling parameter $\ell -k$. Number of iterations $q = s + r$. Positive matrix function $f: \mathbb{R} \mapsto \mathbb{R}$.\\
%\textbf{output:} Rank $k$ approximation of %$f(\bm{A})$ in factored form %$\widehat{\bm{U}} \widehat{\bm{D}} %\widehat{\bm{U}}^\T$. 
%\begin{algorithmic}[1]
 %   \State Sample a standard Gaussian $n \times \ell $ matrix $\bm{\Omega}$.
  %  \State Run Algorithm~\ref{alg:block_lanczos} to obtain an orthonormal basis $\bm{Q}_1 \in \mathbb{R}^{n \times d_s}$ for $\mathcal{K}_{s}(\bm{A},\bm{\Omega})$, an orthonormal basis $\bm{Q} = \begin{bmatrix} \bm{Q}_1 & \bm{Q}_2 \end{bmatrix} \in \mathbb{R}^{n \times d_{s+r}}$ of $\mathcal{K}_{s+r}(\bm{A},\bm{\Omega})$, and block tridiagonal matrix $\bm{T} \in \mathbb{R}^{qd_{s+r} \times qd_{s+r}}$.
   % \State Compute $\bm{X} = f(\bm{T})$. 
    %\State Compute the eigenvalue decomposition of $\bm{X}_{1:d_s, 1:d_s} = \bm{V} \bm{D} \bm{V}^\T$.
    %\State Compute $\bm{B} = \bm{Q} \bm{X} \bm{V} (\bm{D}^{1/2})^{\dagger}$.
    %\State Compute the singular value decomposition of $\bm{B} = \bm{W} \bm{S} \bm{Q}^\T$.
    %\State \textbf{return} $\widehat{\bm{U}} = \bm{Q} \bm{W}_{:,1:k}$ and $\widehat{\bm{D}} = \bm{S}^2_{1:k,1:k}$. 
%\end{algorithmic}
%\end{algorithm}

%\begin{remark}
 %   Think about Nystrom versions! Note that if $f$ is positive then $\bm{B} \succeq \bm{0}$ since $\bm{Q}_1^\T \bm{B} \bm{Q}_1^\T = \bm{Q}_1 f(\bm{T})_{1:\ell s, 1:\ell s} \bm{Q}_1^\T \succeq \bm{0}$ and if $\bm{Q}_{\bot}$ is orthogonal to $\bm{Q}_1$ we have $\bm{Q}_{\bot}^\T \bm{B} \bm{Q}_{\bot} = \bm{Q}_{\bot}^\T f(\bm{A}) \bm{Q}_{\bot} \succeq \bm{0}$. 
%\end{remark}

With \Cref{theorem:robust}, \Cref{lemma:structural}, and \Cref{lemma:probabilistic} we can now derive a probabilistic error bound for $\ALG_k(s,r;f)$, the output of \Cref{alg:krylow}. By an almost identical argument one can obtain a similar bound for $\ALG(s,r;f)$, but we omit the details. 


%Before giving our bound, we introduce the quantity
%\begin{equation}\label{eqn:eps1}
%\epsilon_1(r;f) = 4\sqrt{\ell s}  \inf\limits_{p \in \mathbb{P}_{2r+1}}\|f(x)-p(x)\|_{L^{\infty}([\lambda_{\min},\lambda_{\max}])},
%\end{equation}
%which controls the accuracy of the approximation of the quadratic form $\bm{Q}_s^\T f(\bm{A})\bm{Q}_s$.
%Note that if we know that $\|f(\bm{T}_q)_{1:d_s,1:d_s} - \bm{Q}_s^\T f(\bm{A}) \bm{Q}_s\|_{\F} \leq \epsilon$ almost surely then the $\epsilon_1(s;f)$ can be replaced with $2 \epsilon$. However, as is common with bounds for Krylov subspace methods, we opt to provide a bound which does not depend on the quantity $\bm{T}_q$ explicitly. 

\begin{theorem}\label{theorem:krylov_aware}
Consider $\bm{A} \in \mathbb{R}^{n \times n}$ as defined in \eqref{eq:A} with smallest and largest eigenvalues $\lambda_{\min}$ and $\lambda_{\max}$ respectively.
Then, with $\mathcal{E}(s;f)$ %and $\epsilon_1(r;f)$ 
as defined in \cref{eqn:min_ratio} %\cref{eqn:min_ratio,eqn:eps1}
\begin{enumerate}[(i)]
        \item with probability at least $1-e^{-(u-2)/4} - \sqrt{\pi r} \left(\frac{t}{e}\right)^{-(\ell -k + 1)/2}$, %simultaneously for all functions $f: \mathbb{R} \mapsto \mathbb{R}$,
        \begin{align*}
        \|f(\bm{A}) - \ALG_k(s,r;f) \|_{\F} \leq &4\sqrt{\ell s}  \inf\limits_{p \in \mathbb{P}_{2r+1}}\|f(x)-p(x)\|_{L^{\infty}([\lambda_{\min},\lambda_{\max}])}+\\%\epsilon_1(r;f) +
        &\sqrt{\|f(\bm{\Lambda}_{n \setminus k })\|_{\F}^2 +  \frac{5ut k}{\ell - k + 1} \mathcal{E}(s;f)};
        \end{align*}\label{item:krylov_aware_tailbound}
        \item if $\ell -k \geq 2$ that
        \begin{align*}
        \mathbb{E}\|f(\bm{A}) - \ALG_k(s,r;f) \|_{\F} \leq &4\sqrt{\ell s}  \inf\limits_{p \in \mathbb{P}_{2r+1}}\|f(x)-p(x)\|_{L^{\infty}([\lambda_{\min},\lambda_{\max}])}+\\%\epsilon_1(r;f) +
        &\sqrt{\|f(\bm{\Lambda}_{n \setminus k })\|_{\F}^2 +  \frac{5k}{\ell - k - 1} \mathcal{E}(s;f)}.        \end{align*}\label{item:krylov_aware_expectationbound}
    \end{enumerate}
\end{theorem}

% \begin{theorem}\label{theorem:krylov_aware}
% Consider $\bm{A} \in \mathbb{R}^{n \times n}$ as defined in \eqref{eq:A} and fix a function . Let $\bm{Q}_s$ and $\bm{T}_q$ be as in \cref{alg:krylow}. Then, for all functions $f: \mathbb{R} \mapsto \mathbb{R}$ we have
% \begin{enumerate}[(i)]
%         \item with probability at least $1-e^{-(u-2)/4} - \sqrt{\pi r} \left(\frac{t}{e}\right)^{-(\ell -k + 1)/2}$ that
%         \begin{align*}
%         &\|f(\bm{A}) - \bm{Q}_s \llbracket f(\bm{T}_q)_{1:d_s,1:d_s}\rrbracket_{k} \bm{Q}_s^\T\|_{\F} \leq 4\sqrt{d_s} \inf\limits_{p \in \mathbb{P}_{2r+1}}\|f(x)-p(x)\|_{L^{\infty}([\lambda_{\min},\lambda_{\max}])} +\\
%         &\sqrt{\|f(\bm{\Lambda}_{n \setminus k })\|_{\F}^2 +  \frac{5ut k}{\ell - k + 1} \min\limits_{p \in \mathbb{P}_{s-1}} \left[\|p(\bm{\Lambda}_{n \setminus k})\|_{\F}^2\max\limits_{i=1,\ldots,k} \left|\frac{f(\lambda_i)}{p(\lambda_i)}\right|^2 \right]};
%         \end{align*}\label{item:krylov_aware_tailbound}
%         \item if $\ell -k \geq 2$ that
%         \begin{align*}
%         &\mathbb{E}\|f(\bm{A}) - \bm{Q}_s \llbracket f(\bm{T}_q)_{1:d_s,1:d_s}\rrbracket_{k} \bm{Q}_s^\T\|_{\F} \leq 4\sqrt{d_s} \inf\limits_{p \in \mathbb{P}_{2r+1}}\|f(x)-p(x)\|_{L^{\infty}([\lambda_{\min},\lambda_{\max}])} +\\
%         &\sqrt{\|f(\bm{\Lambda}_{n \setminus k })\|_{\F}^2 +  \frac{5k}{\ell - k + 1} \min\limits_{p \in \mathbb{P}_{s-1}} \left[\|p(\bm{\Lambda}_{n \setminus k})\|_{\F}^2\max\limits_{i=1,\ldots,k} \left|\frac{f(\lambda_i)}{p(\lambda_i)}\right|^2 \right]}.        \end{align*}\label{item:krylov_aware_expectationbound}
%     \end{enumerate}
% \end{theorem}
\begin{proof}
\textit{(\ref*{item:krylov_aware_tailbound})}: By applying \Cref{theorem:robust}, \Cref{lemma:structural}, and \Cref{lemma:2_times_polynomial_approx} we obtain the following structural bound %\David{I changed some stuff here. I used the notation that Tyler defined.}  
\begin{align}
\begin{split}
        \|f(\bm{A}) - \bm{Q}_s \llbracket f(\bm{T}_q)_{1:d_{s,\ell},1:d_{s,\ell}}\rrbracket_{k} \bm{Q}_s^\T\|_{\F} \leq &4\sqrt{\ell s}  \inf\limits_{p \in \mathbb{P}_{2r+1}}\|f(x)-p(x)\|_{L^{\infty}([\lambda_{\min},\lambda_{\max}])} +\\
        &\sqrt{\|f(\bm{\Lambda}_{n \setminus k })\|_{\F}^2 +  5 \mathcal{E}_{\bm{\Omega}}(s;f)}.
        \end{split}\label{eq:krylov_aware_structural}
\end{align}
Applying \Cref{lemma:probabilistic} yields \textit{(\ref*{item:krylov_aware_tailbound})} directly. 
\textit{(\ref*{item:krylov_aware_expectationbound})} follows from \Cref{lemma:probabilistic} and an application of Jensen's inequality.
\end{proof}

We conclude this section by commenting on the three terms appearing in the bounds in \Cref{theorem:krylov_aware}. 
The dependence on $4\sqrt{\ell s}  \inf\limits_{p \in \mathbb{P}_{2r+1}}\|f(x)-p(x)\|_{L^{\infty}([\lambda_{\min},\lambda_{\max}])}$ captures the inherent cost of approximating a quadratic form with $f(\bm{A})$ using the Lanczos method, as in done in Line 3 of \Cref{alg:krylow}. A similar term would also arise in an analysis of the Randomized SVD when matvecs are computed approximately using a Krylov subspace method.
The $\|f(\bm{\Lambda}_{n \setminus k})\|_{\F}$ term is due to the fact that our error can never be below the optimal rank $k$ approximation error. Finally, $\mathcal{E}(s;f)$ tells us that $\bm{Q}_s$ is a good orthonormal basis for low-rank approximation if there is a polynomial of degree at most $s-1$ that is large on the eigenvalues $\lambda_1,\ldots,\lambda_k$ (which correspond to the top subspace of $f(\bm{A})$) and is small on the eigenvalues $\lambda_{k+1},\ldots,\lambda_n$. 

As discussed in \Cref{section:structural}, one possible choice of polynomial would be an approximation to $f$, in which case $\mathcal{E}(s;f)$ would be close to $\|f(\bm{\Lambda}_{n \setminus k})\|_{\F}$. In this case, ignoring the polynomial approximation term, we would recover a bound almost identical to the standard Randomized SVD error bound. In particular, when matvecs with $f(\bm{A})$ are implemented exactly, Randomized SVD can be shown to have expected error \cite{rsvd}:
\begin{align*}
\sqrt{\|f(\bm{\Lambda}_{n \setminus k})\|_{\F}^2 + \frac{k}{\ell-k-1}\|f(\bm{\Lambda}_{n \setminus k})\|_{\F}^2}.
\end{align*}
However, other possibly polynomials can also be chosen, so we might have $\mathcal{E}(s;f)  \ll \|f(\bm{\Lambda}_{n \setminus k})\|_{\F}$. In the next section, we give an example involving the matrix exponential to better illustrate why this is often the case. 

% Such a polynomial effectively denoises the contribution from the small eigenvalues of $f(\bm{A})$. A similar intuition underlies standard analyses of randomized Krylov subspace methods for low-rank approximation of a simple matrix $\bm{A}$ \cite{MM15,tropp2023randomized}. 

% Note that if we know that $\|f(\bm{T}_q)_{1:d_{s,\ell},1:d_{s,\ell}} - \bm{Q}_s^\T f(\bm{A}) \bm{Q}_s\|_{\F} \leq \epsilon$ almost surely then this term can be replaced with $2 \epsilon$.

% {\color{blue}\textbf{Tyler: let me try again}}

% In some applications we care not just about a single function, but about an infinite family of functions.
% For example, in quantum thermodynamics, the functions $f(x) = \exp(-\beta x)$, for a range of $\beta>0$ are of interest; see for example \cref{section:quantum_spin}.
% As a corollary to the previous proof, we also obtain \emph{uniform bounds} for certain classes of functions, including monotonically decreasing functions.
% \begin{corollary}
% Consider $\bm{A} \in \mathbb{R}^{n \times n}$ as defined in \eqref{eq:A}.
% Fix a susbset $\Lambda_k$ of $k$ eigenvalues of $\bm{A}$ (repeated eigenvalues treated as distinct elements) and let $\Lambda_{n\setminus k} = \Lambda \setminus \Lambda_k$.
% Define $\mathcal{F}$ as the set of functions $f:\mathbb{R}\to\mathbb{R}$ such that $\forall \lambda\in\Lambda_k, \lambda'\in\Lambda_{n\setminus k}: f(\lambda) \geq f(\lambda')$/ 
% Then, with $\mathcal{E}(s;f)$ and $\epsilon_1(r;f)$ as defined in 
%     with probability at least $1-e^{-(u-2)/4} - \sqrt{\pi r} \left(\frac{t}{e}\right)^{-(\ell -k + 1)/2}$, simultaneously for all functions $f\in\mathcal{F}$,
%         \begin{align*}
%         &\|f(\bm{A}) - \ALG_k(s,r;f) \|_{\F} \leq \epsilon_1(r;f) +
%         \sqrt{\|f(\bm{\Lambda}_{n \setminus k })\|_{\F}^2 +  \frac{5ut k}{\ell - k + 1} \mathcal{E}(s;f)}.
%         \end{align*}
% \end{corollary}

% \begin{proof}
%     For all functions, the structural bound is the same as the preceding proof.
%     By construction, $\bm{\Omega}_k$ and $\bm{\Omega}_{n\setminus k}$ are same for all functions $f\in\mathcal{F}$, so we only need to apply \Cref{lemma:probabilistic}~\textit{(\ref*{item:tailbound})} once.
% \end{proof}
%{\color{blue}{


% -------- MATRIX EXPONENTIAL BOUNDS HERE --------


\subsection{Example bounds for the matrix exponential}\label{section:exponential}
One matrix function for which it is often desirable to obtain a low-rank approximation is the matrix exponential, $\exp(\bm{A})$. This task arises in tasks ranging from network analysis \cite{hpp}, to quantum thermodynamics \cite{chen_hallman_23,epperly2023xtrace}, to solving PDEs \cite{persson_kressner_23}. In this section, we do a deeper dive into our main bounds for Krylov aware low-rank approximation when applied to the matrix exponential to better understand how they compare to bounds obtainable using the more naive approach of directly combining the randomized SVD with a black-box matrix-vector product approximation algorithm for $\exp(\bm{A})$.  For conciseness of exposition, we focus on expectation bounds, and defer details of proofs to \Cref{section:appendix}.

We first demonstrates that, as discussed in the previous section, by choosing $p$ in $\mathcal{E}(s;\exp(x))$ to be a polynomial approximation to $\exp(x)$, we can recover the bounds of the randomized SVD \cite[Theorem 10.5]{rsvd}, up to small factors accounting for the fact that $\exp(x)$ is not a polynomial. %The proof is deferred to \Cref{section:appendix}.



% By constructing particular polynomials of degree $<s$, we can obtain more explicit bounds that depend only on how accurately $f(x)$ can be approximated by polynomials. 
% These bounds are reminiscent of standard bounds that might be obtained if we could do exact matvecs with $f(\bm{A})$, except that they have small error terms accounting for the fact that $f(x)$ might not be a polynomial. We will provide such bounds for $\exp(\bm{A})$. For simplicity, we focus on expectation bounds. However, using an almost identical argument, one can obtain the corresponding tailbounds.

% We begin with the following result, which shows that by \Cref{theorem:krylov_aware} can recover the bounds of the randomized SVD \cite[Theorem 10.5]{rsvd}. The proof of deferred to the appendix for clarity of exposition. 

\begin{corollary}\label{theorem:rsvd_like_bound}
Consider the setting of \Cref{theorem:krylov_aware} with $f(x) = \exp(x)$. Then, if $\ell-k\geq 2$ and $\gamma_{1,n} := \lambda_{\max} - \lambda_{\min} = \lambda_1-\lambda_n$, and $s \geq e\gamma_{1,n}$ we have
\begin{align*}
     &\mathbb{E}\|\exp(\bm{A}) - \ALG_k(s,r;\exp(x))\|_{\F} 
     \\&\hspace{2em}
     \leq  \frac{\sqrt{\ell s}\gamma_{1,n}^{2r+2}}{2^{4r+1}(2r+2)!}\|\exp(\bm{A})\|_2 + \sqrt{1 +  \frac{1}{(1-\frac{\gamma_{1,n}^s}{s!})^2}\frac{5k}{\ell - k - 1}} \|\exp(\bm{\Lambda}_{n \setminus k })\|_{\F}.
\end{align*}
\end{corollary}
%\tyler{if we're doing a specific example idk if we need the previous one as well?}
Note that as $\frac{\sqrt{\ell s}\gamma_{1,n}^{2r+2}}{2^{4r+1}(2r+2)!}\|\exp(\bm{A})\|_2 \to 0$ and $\frac{\gamma_{1,n}^s}{s!} \to 0$, we recover the classical bound for the randomized SVD \cite[Theorem 10.5]{rsvd}. Furthermore, these two terms converge \emph{superexponentially} to $0$ as $s,r \to +\infty$. However, due to the $\frac{5k}{\ell -k -1}$, the above bound only implies a subexponential convergence to the error of the optimal rank $k$ approximation error, $\|\exp(\bm{\Lambda}_{n \setminus k })\|_{\F}$, in terms of the number of required matrix-vector products with $\bm{A}$, which scales as $\ell (r+s)$.

% To prove \Cref{theorem:rsvd_like_bound} we chose $p$ in $\mathcal{E}(s;\exp(x))$ to be a polynomial approximation to $\exp(x)$. 
However, as argued in \Cref{section:structural} there are other polynomials that can achieve a significantly tighter upper bound of $\mathcal{E}(s;\exp(x))$. For example, by choosing $p$ in $\mathcal{E}(s;\exp(x))$ to be a scaled and shifted Chebyshev polynomial we can show the output of \Cref{alg:krylow} converges \emph{exponentially} in $s$ to the optimal low-rank approximation of $\exp(\bm{A})$, even if $\ell$ stays fixed. 
 This demonstrates why \Cref{alg:krylow} is expected to return a better low-rank approximation compared to applying the randomized SVD immediately on $\exp(\bm{A})$. In particular, we have the following result. 

\begin{corollary}\label{theorem:fast_convergence}
Consider the setting of \Cref{theorem:krylov_aware} with $f(x) = \exp(x)$. Define $\gamma_{i,j} = \lambda_{i} - \lambda_{j}$ to be the gap between the $i^{\text{th}}$ and $j^{\text{th}}$ largest eigenvalues. Then, if $\ell-k\geq 2$ and $s \geq 2 + \frac{\gamma_{1,k}}{\log\left(\frac{\gamma_{1,n}}{\gamma_{k,n}}\right)}$%$\gamma = \lambda_{\max} - \lambda_{\min} = \lambda_1 - \lambda_n$, and $\beta = \frac{\lambda_{k} - \lambda_{k+1}}{\lambda_{k} + \lambda_{k+1} - 2\lambda_{\min}}$ we have
\begin{align*}
     &\mathbb{E}\|\exp(\bm{A}) - \ALG_k(s,r;\exp(x))\|_{\F} 
     \leq  \frac{\sqrt{\ell s}\gamma_{1,n}^{2r+2}}{2^{4r+1}(2r+2)!}\|\exp(\bm{A})\|_2 
     \\&\hspace{5em}+ \sqrt{1 +  \exp(2\gamma_{k,n}) \cdot 2^{-2(s-2)\sqrt{\min\left\{1, 2 \frac{\gamma_{k,k+1}}{\gamma_{k+1,n}}\right\}}}\frac{80k}{\ell - k - 1}} \|\exp(\bm{\Lambda}_{n \setminus k })\|_{\F}.
\end{align*}
\end{corollary}
% \begin{proof}
%     Bounding $4\sqrt{\ell s}\inf\limits_{p \in \mathbb{P}_{2r+1}}\|\exp(x)-p(x)\|_{L^{\infty}([\lambda_{\min},\lambda_{\max}])}$ is done identical to as done in \Cref{theorem:rsvd_like_bound}. We proceed with bounding $\mathcal{E}(s;\exp(x))$ by choosing the polynomial $p(x) = (1+x-\lambda_{\min})T_{s-2}\left(\frac{x-\lambda_{\min}}{\lambda_{k+1}-\lambda_{\min}}\right)$, where $T_{s-2}$ is the Chebyshev polynomial of degree $s-2$. Hence,
%     \begin{align*}
%         \mathcal{E}(s;\exp(x)) 
%         &\leq \|p(\bm{\Lambda}_{n \setminus k})\|_{\F}^2 \max\limits_{i=1,\ldots,k} \left|\frac{\exp(\lambda_i)}{p(\lambda_i)}\right|^2 
%         \\&\leq 
%         \|\exp(\bm{\Lambda}_{n \setminus k} - \lambda_{\min}\bm{I})\|_{\F}^2 \left\|T_{s-2}\left(\frac{\bm{\Lambda}_{n \setminus k}-\lambda_{\min}\bm{I}}{\lambda_{k+1}-\lambda_{\min}}\right)\right\|^2 \exp(2\lambda_{\min}) \max\limits_{i=1,\ldots,k} \left|\frac{\exp(\lambda_i-\lambda_{\min})}{p(\lambda_i)}\right|^2 
%         \\&\leq 
%         \|\exp(\bm{\Lambda}_{n \setminus k})\|_{\F}^2\max\limits_{i=1,\ldots,k} \left|\frac{\exp(\lambda_i-\lambda_{\min})}{p(\lambda_i)}\right|^2 
%         \\&\leq 
%         \|\exp(\bm{\Lambda}_{n \setminus k})\|_{\F}^2\max\limits_{i=1,\ldots,k} \left|\frac{\exp(\lambda_i-\lambda_{\min})}{T_{s-2}\left(\frac{x-\lambda_{\min}}{\lambda_{k+1}-\lambda_{\min}}\right)}\right|^2 
%         \\&\leq 
%         \|\exp(\bm{\Lambda}_{n \setminus k})\|_{\F}^2 \frac{e^{2\gamma}}{T_{s-2}\left(\frac{\lambda_k-\lambda_{\min}}{\lambda_{k+1}-\lambda_{\min}}\right)^2} 
%         \\&\leq 
%         4\|\exp(\bm{\Lambda}_{n \setminus k})\|_{\F}^2 e^{2\gamma-4(s-2)\sqrt{\gamma}},
%     \end{align*}
%     where the second inequality uses $0\leq 1+x \leq e^x$ for $x \geq 0$, the third inequality uses $|T_{s-2}(x)| \leq 1$ for $x \in [0,1]$, the fourth inequality uses $\frac{e^x}{1+x} \leq e^x$ for $x \geq 0$, the fifth inequality uses that $T_{s-2}(x)$ is increasing for $x \geq 1$, and the final inequality uses \cite[Lemma 9.3]{tropp2023randomized}. Plugging this inequality into \Cref{theorem:krylov_aware} yields the desired inequality. 
%     \end{proof}


%     \tyler{the inequalities above are very long. how about this which emphasizes what is changing each line so the lines are shorter? Might want to reorder it a bit?}\hrulefill

%     \begin{proof}
%     Bounding $4\sqrt{\ell s}\inf\limits_{p \in \mathbb{P}_{2r+1}}\|\exp(x)-p(x)\|_{L^{\infty}([\lambda_{\min},\lambda_{\max}])}$ is done identical to as done in \Cref{theorem:rsvd_like_bound}. We proceed with bounding $\mathcal{E}(s;\exp(x))$. Define $\gamma(x) = \frac{x-\lambda_{k+1}}{\lambda_{k+1} - \lambda_n}$. Define the polynomial $p(x) = (1+x-\lambda_{n})T_{s-2}\left(1 + 2 \gamma(x)\right)$, where $T_{s-2}$ is the Chebyshev polynomial of degree $s-2$. 
%     Hence, recalling the definition \cref{eqn:min_ratio} of $\mathcal{E}(s;\exp(x))$, since $0\leq 1+x \leq e^x$ for $x\geq 0$ and $|T_{s-2}(x)| \leq 1$ for $x \in [-1,1]$ we have,
%     \[
%     \|p(\bm{\Lambda}_{n \setminus k})\|_{\F}
%     \leq \|\exp(\bm{\Lambda}_{n \setminus k} - \lambda_{n}\bm{I})\|_{\F}\]
%     Hence, using that $\frac{e^x}{1+x} \leq e^x$ for $x \geq 0$ we get
%     \begin{align}
%         \mathcal{E}(s;\exp(x)) 
%         &\leq \|p(\bm{\Lambda}_{n \setminus k})\|_{\F}^2 \max\limits_{i=1,\ldots,k} \left|\frac{e^{\lambda_i}}{p(\lambda_i)}\right|^2 
%         \nonumber\\&\leq 
%         \|\exp(\bm{\Lambda}_{n \setminus k}-\lambda_{n}\bm{I})\|_{\F}^2\max\limits_{i=1,\ldots,k} e^{2\lambda_{n}} \left|\frac{e^{\lambda_i-\lambda_{n}}}{p(\lambda_i)}\right|^2 
%         \nonumber\\&=\|\exp(\bm{\Lambda}_{n \setminus k})\|_{\F}^2\max\limits_{i=1,\ldots,k} \left|\frac{e^{\lambda_i-\lambda_{n}}}{p(\lambda_i)}\right|^2
%         \nonumber\\&\leq\|\exp(\bm{\Lambda}_{n \setminus k})\|_{\F}^2\max\limits_{i=1,\ldots,k} \left|\frac{e^{\lambda_i-\lambda_{n}}}{T_{s-2}\left(1 + 2 \gamma(\lambda_i)\right)}\right|^2.
%         \label{eqn:Esexp_bd}
%     \end{align}
%     First note that for $|x| \geq 1$ we have
%     \begin{equation*}
%         T_{s-2}(x) = \frac{1}{2}\left(\left(x + \sqrt{x^2-1}\right)^{s-2} + \left(x - \sqrt{x^2-1}\right)^{s-2} \right).
%     \end{equation*}
%     Hence, for $\gamma \geq 0$ we have $|T_{s-2}(1+2\gamma)| \geq \frac{1}{2}(1+2\gamma + 2\sqrt{\gamma + \gamma^2})^{s-2} =: \frac{1}{2}h(\gamma)^{s-2}$. Therefore,
%     \begin{align*}
%         \max\limits_{i=1,\ldots,k} \left|\frac{e^{\lambda_i-\lambda_{n}}}{T_{s-2}\left(1 + 2 \gamma(\lambda_i)\right)}\right|^2 &\leq 4 \max\limits_{i=1,\ldots,k} \left|\frac{e^{\lambda_i-\lambda_{n}}}{h(\gamma(\lambda_i))^{s-2}}\right|^2\\
%         &= 4 \max\limits_{i=1,\ldots,k} \left(e^{\lambda_i - \lambda_n - (s-2)\log(h(\gamma(\lambda_i)))}\right)^2.
%     \end{align*}
%     Note that the function 
%     \begin{equation*}
%         g(x) := x - \lambda_n - (s-2)\log(h(\gamma(\lambda_i)))
%     \end{equation*}
%     is convex in $[\lambda_k,\lambda_1]$. Hence, the maximum of $g$ on the interval $[\lambda_k,\lambda_1]$ is attained at either $x = \lambda_k$ or $x = \lambda_1$. The maximum of $g$ is attained at $x = \lambda_k$ whenever $g(\lambda_1) \leq g(\lambda_k)$ which happens whenever
%     \begin{equation}\label{eq:scondition}
%         \frac{\lambda_1 - \lambda_k}{\log\left(\frac{h(\gamma(\lambda_1))}{h(\gamma(\lambda_k))}\right)} + 2 \leq s.
%     \end{equation}
%     Note that we have whenever $x \geq y \geq 0$ we have $\frac{h(x)}{h(y)} \geq \frac{1 + x}{1+y}$. Hence, \eqref{eq:scondition} holds whenever
%     \begin{equation*}
%         \frac{\lambda_1 - \lambda_k}{\log\left(\frac{\lambda_1 - \lambda_{k+1}}{\lambda_k - \lambda_{k+1}}\right)} + 2  \leq s,
%     \end{equation*}
%     which is our assumption on $s$. Hence, 
%     \begin{equation}\label{eq:upperbound}
%          \max\limits_{i=1,\ldots,k} \left|\frac{e^{\lambda_i-\lambda_{n}}}{T_{s-2}\left(1 + 2 \gamma(\lambda_i)\right)}\right|^2 \leq 4 \frac{e^{2(\lambda_k - \lambda_n)}}{h(\gamma(\lambda_k))^{2(s-2)}}.
%     \end{equation}
%     Now we use the argument from \cite[p.21]{MM15}, which shows that $h(\gamma) \geq 2^{\sqrt{\min\{1,2\gamma\}}q}$. Plugging this inequality into \cref{eq:upperbound} and then \cref{eqn:Esexp_bd} into \cref{theorem:krylov_aware} yields the desired inequality. 
%     % Bounding $4\sqrt{\ell s}\inf\limits_{p \in \mathbb{P}_{2r+1}}\|\exp(x)-p(x)\|_{L^{\infty}([\lambda_{\min},\lambda_{\max}])}$ is done identical to as done in \Cref{theorem:rsvd_like_bound}. We proceed with bounding $\mathcal{E}(s;\exp(x))$ by choosing the polynomial $p(x) = (1+x-\lambda_{\min})T_{s-2}\left(\frac{x-\lambda_{\min}}{\lambda_{k+1}-\lambda_{\min}}\right)$, where $T_{s-2}$ is the Chebyshev polynomial of degree $s-2$. 
%     % Hence, recalling the definition \cref{eqn:min_ratio} of $\mathcal{E}(s;\exp(x))$, since $0\leq 1+x \leq e^x$ for $x\geq 0$,
%     % \[
%     % \|p(\bm{\Lambda}_{n \setminus k})\|_{\F}
%     % \leq \|\exp(\bm{\Lambda}_{n \setminus k} - \lambda_{\min}\bm{I})\|_{\F} \left\|T_{s-2}\left(\frac{\bm{\Lambda}_{n \setminus k}-\lambda_{\min}\bm{I}}{\lambda_{k+1}-\lambda_{\min}}\right)\right\|^2.
%     % \]
%     % Hence, using that $|T_{s-2}(x)\leq 1$ for $x\in[0,1]$,
%     % \begin{align}
%     %     \mathcal{E}(s;\exp(x)) 
%     %     &\leq \|p(\bm{\Lambda}_{n \setminus k})\|_{\F}^2 \max\limits_{i=1,\ldots,k} \left|\frac{e^{\lambda_i}}{p(\lambda_i)}\right|^2 
%     %     \nonumber\\&\leq 
%     %     \|\exp(\bm{\Lambda}_{n \setminus k}-\lambda_{\min}\bm{I})\|_{\F}^2\max\limits_{i=1,\ldots,k} e^{2\lambda_{\min}} \left|\frac{e^{\lambda_i-\lambda_{\min}}}{p(\lambda_i)}\right|^2 
%     %     \nonumber\\&=\|\exp(\bm{\Lambda}_{n \setminus k})\|_{\F}^2\max\limits_{i=1,\ldots,k} \left|\frac{e^{\lambda_i-\lambda_{\min}}}{p(\lambda_i)}\right|^2.
%     %     \label{eqn:Esexp_bd}
%     % \end{align}
%     % Finally, using that $\frac{e^x}{1+x} \leq e^x$ for $x \geq 0$,that $T_{s-2}(x)$ is increasing for $x \geq 1$, and \cite[Lemma 9.3]{tropp2023randomized} we have
%     % \begin{align*}
%     %     \max\limits_{i=1,\ldots,k} \left|\frac{e^{\lambda_i-\lambda_{\min}}}{p(\lambda_i)}\right|^2 
%     %     &\leq 
%     %     \max\limits_{i=1,\ldots,k} \left|\frac{e^{\lambda_i-\lambda_{\min}}}{T_{s-2}\big(\frac{x-\lambda_{\min}}{\lambda_{k+1}-\lambda_{\min}}\big)}\right|^2 
%     %     \\&\hspace{5em}\leq \frac{e^{2\gamma}}{T_{s-2}\big(\frac{\lambda_k-\lambda_{\min}}{\lambda_{k+1}-\lambda_{\min}}\big)^2} 
%     %     \leq 
%     %     4 e^{2\gamma-4(s-2)\sqrt{\gamma}},
%     % \end{align*}
%     % Plugging this inequality into \cref{eqn:Esexp_bd} and then \cref{eqn:Esexp_bd} into \cref{theorem:krylov_aware} yields the desired inequality. 
% \end{proof}
%}}

% {\color{red}{
% \subsubsection{Simplified bounds}
% By constructing particular polynomials of degree $<s$, we can obtain more explicit bounds that depend only on how accurately $f(x)$ can be approximated by polynomials. 
% These bounds are reminiscent of standard bounds that might be obtained if we could do exact products with $f(\bm{A})$, except that they have small error terms accounting for the fact that $f(x)$ might not be a polynomial. 
% For example, by taking $p(x)$ as the best approximation to $f(x)$, shifted up to be above $f(x)$, we can obtain a bound like what one might obtain the the randomized SVD. For simplicity, we focus on expectation bounds. However, using an almost identical argument, one can obtain the corresponding tailbounds.

% We will use the quantity
% \begin{equation}\label{eqn:eps2}
% \epsilon_2(s;f) = \min_{p\in\mathbb{P}_{s-1}} \|f(x) - p(x)\|_{L^{\infty}(\Lambda)} 
% \end{equation}
% which relates to how well $f$ can be approximated by polynomials on the \emph{eigenvalues} $\Lambda$ of $\bm{A}$. Such bounds can often be much smaller than the corresponding bounds on an interval containing the eigenvalues.


% \begin{corollary}\label{theorem:rsvd_like_bound}
% Consider the setting of \Cref{theorem:krylov_aware}. Suppose $f(\lambda_i) \geq 0$ for all $i=1, \dots, n$ and define $\Lambda = \{\lambda_1,\ldots,\lambda_n\}$.
% Then, if $\ell-k\geq 2$, with $\epsilon_1(r;f)$ and $\epsilon_2(s;f)$ as defined in \cref{eqn:eps1,eqn:eps2}, we have
% \begin{align*}
%      \mathbb{E}\|f(\bm{A}) - \ALG_k(s,r;f)\|_{\F} 
%      &\leq 
%      \epsilon_1(r;f) + 2\sqrt{\frac{5nk}{\ell - k + 1}} \epsilon_2(s;f)
%      \\&\hspace{6em} + \sqrt{1 +  \frac{5k}{\ell - k + 1}} \|f(\bm{\Lambda}_{n \setminus k })\|_{\F}.
% \end{align*}
% \end{corollary}

% A similar approach allows us to obtain bounds reminiscent of what one might obtain for the randomized block Krylov algorithm with exact products with $f(\bm{A})$.
% If $s$ is chosen sufficiently large and there is a low-degree polynomial that can accurately find the gap between $f(\lambda_k)$ and $f(\lambda_{k+1})$, the \Cref{alg:krylow} satisfies bounds that are similar to \cite[Theorem 9.2]{tropp2023randomized}. 

% % define
% % \[
% % \epsilon_3 = \min_{p\in\mathbb{P}_{\lfloor (s-1)/q \rfloor}} \|f(x) - p(x)\|_{L^{\infty}(\Lambda)}.
% % \]
% %{\color{blue} TODO: double check the statement, the epsilon 2 was missing in the middle and I just put it back in without checking.}\David{We used $q = s+r$ before. I replaced $q$ with $m$.}
% \begin{corollary}
% \label{theorem:rbki_like_bound}
% Consider the setting of \Cref{theorem:rsvd_like_bound}.
% Fix $m \geq 1$ and with $\epsilon_1(r;f)$ and $\epsilon_2(\lfloor (s-1)/m \rfloor;f)$ as defined in \cref{eqn:eps1,eqn:eps2}, define a gap parameter
% \[
% \gamma_{\epsilon}
% = \frac{f(\lambda_k) - (f(\lambda_{k+1})+2\epsilon_2(\lceil (s-1)/m \rceil;f))}{f(\lambda_k) + f(\lambda_{k+1})+2\epsilon_2(\lceil (s-1)/m \rceil;f)},
% \]
% and assume that $\gamma_{\epsilon} > 0$. 
% Then, if $\ell-k\geq 2$, we have
% \begin{align*}
%     \mathbb{E}\|f(\bm{A}) - \ALG_k(s,r;f)\|_{\F} &\leq 
%     \epsilon_1(r;f) + 4 \sqrt{\frac{5nk}{\ell-k+1}}e^{-2(m-1)\sqrt{\gamma_{\epsilon}}} \epsilon_2(\lceil (s-1)/m \rceil;f) 
%     \\&\hspace{6em}+ \sqrt{1+ \frac{20k}{\ell - k + 1} e^{-4(m-1) \sqrt{\gamma_\epsilon}}} \|f(\bm{\Lambda}_{n \setminus k })\|_{\F}.
% \end{align*}
% \end{corollary}

% Note that when $f(x) = x$ we have $\epsilon_1 = \epsilon_2 = 0$ and \Cref{theorem:rbki_like_bound} recovers \cite[Theorem 9.2]{tropp2023randomized}.
% Furthermore, it is worth pointing out that in the special case where For $f(x) = 1/x$ and $\bm{A}$ is positive definite, the optimality of conjugate gradient allows $\epsilon_1$ to also be upgraded to a bound on the eigenvalues of $\bm{A}$. 
% We now proceed with proving \Cref{theorem:rsvd_like_bound,theorem:rbki_like_bound}. 

% \begin{proof}[Proof of \cref{theorem:rsvd_like_bound}]
% Let $\hat{p}(x)$ be a degree $s-1$ polynomial such that $\|f(x) - \hat{p}(x)\|_{L^{\infty}(\Lambda)} = \epsilon_2(s;f)$, and define $p(x) = \hat{p}(x) + \epsilon_2(s;f)$.
% Note that for any $i=1,\ldots, k$, $p(\lambda_i) \leq f(\lambda_i) + 2\epsilon_2(s;f)$ so
% \[
% \|p(\bm{\Lambda}_{n \setminus k})\|_{\F}^2
% \leq \|f(\bm{\Lambda}_{n \setminus k}) + 2\epsilon_2(s;f) \bm{I}\|_{\F}^2.
% \]
% In addition, since $f(\lambda_i) \leq p(\lambda_i)$,
% \[
% \max\limits_{i=1,\ldots,k} \left|\frac{f(\lambda_i)}{p(\lambda_i)}\right|^2
% \leq 1.
% \]
% Combining these results gives the specified bound for a particular degree $s-1$ polynomial $p(x)$ and thus 
% \[
% \min\limits_{p \in \mathbb{P}_{s-1}} \left[\|p(\bm{\Lambda}_{n \setminus k})\|_{\F}^2\max\limits_{i=1,\ldots,k} \left|\frac{f(\lambda_i)}{p(\lambda_i)}\right|^2 \right]
% \leq  \|f(\bm{\Lambda}_{n \setminus k}) + 2\epsilon_2(s;f) \bm{I}\|_{\F}^2.
% \]
% Combining this inequality with \cref{theorem:krylov_aware} and applying the triangle inequality gives the result.
% \end{proof}

% \begin{proof}[Proof of \cref{theorem:rbki_like_bound}]
% Let $\hat{p}(x)$ be a degree $\lfloor (s-1)/m \rfloor = \lceil (s-1)/m \rceil-1$ polynomial such that $\|f(x) - \hat{p}(x)\|_{L^{\infty}(\Lambda)} =\epsilon_2(\lceil (s-1)/m \rceil) :=\epsilon_2$ and define $\tilde{p}(x) = \hat{p}(x) + \epsilon_2$.
% Set $p(x) = \tilde{p}(x)\tilde{T}_{m-1}(\tilde{p}(x))$, where $\tilde{T}_{m-1}(x) = T_{m-1}(x / (f(\lambda_{k+1})+2\epsilon_2))$ is the degree $m-1$ scaled Chebyshev polynomial. Note that for $i=k+1, \ldots, n$, since $\tilde{p}(\lambda_i) \in [0,f(\lambda_{k+1}) + 2\epsilon_2]$ we have by \cite[Chapter 2]{chebyshevpolynomials} that $|\tilde{T}_{m-1}(\tilde{p}(\lambda_{i}))| \leq 1$.
% Thus, using that $p(\lambda_i) \leq f(\lambda_i) + 2\epsilon_2$,
% \[
% \|p(\bm{\Lambda}_{n \setminus k})\|_{\F}^2 
% \leq \|\tilde{p}(\bm{\Lambda}_{n \setminus k}) \|_{\F}^2 \|\tilde{T}_{m-1}(\tilde{p}(\bm{\Lambda}_{n \setminus k}))\|_{2}^2
% \leq \|f(\bm{\Lambda}_{n \setminus k}) + 2\epsilon_2\bm{I}\|_{\F}^2.
% \]
% Now, fix $i=1,\ldots, k$.
% Since $\gamma_{\epsilon}>0$ we have $f(\lambda_i) \geq f(\lambda_{k+1}) + 2\epsilon_2$.
% Thus, since $f(\lambda_i)\leq \tilde{p}(\lambda_i)$ and that $T_{m-1}(x)$ is monotonically increasing for $x \geq 1$ we have that $p(\lambda_i) = \tilde{p}(\lambda_{i})\tilde{T}_{m-1}(\tilde{p}(\lambda_{i})) \geq f(\lambda_{i})\tilde{T}_{m-1}(f(\lambda_{i}))$.
% This implies that
% \[
% \max\limits_{i=1,\ldots,k} \left|\frac{f(\lambda_i)}{p(\lambda_i)}\right|^2
% \leq \max\limits_{i=1,\ldots,k} \left|\frac{f(\lambda_i)}{\tilde{T}_m(f(\lambda_i))}\right|^2
% \leq \tilde{T}_{m-1}(f(\lambda_k))^{-2}.
% \]
% Using basic properties of Chebyshev polynomials \cite[Lemma 9.3]{tropp2023randomized},
% %\tyler{I just tried to pattern match from p46, need to check more carefully}
% \[
% \tilde{T}_{m-1}(f(\lambda_k))
% = T_{m-1}\left(\frac{f(\lambda_k)}{f(\lambda_{k+1}+2\epsilon_2)}\right)
% = T_{m-1}\left( \frac{1+\gamma_\epsilon}{1-\gamma_\epsilon} \right)
% \geq \frac{1}{2}e^{2(m-1) \sqrt{\gamma_\epsilon}}.
% \]
% Combining these results gives the specified bound for a particular degree $\lfloor(s-1)/1\rfloor \leq s-1$ polynomial $p(x)$ and thus
% \[
% \min\limits_{p \in \mathbb{P}_{s-1}} \left[\|p(\bm{\Lambda}_{n \setminus k})\|_{\F}^2\max\limits_{i=1,\ldots,k} \left|\frac{f(\lambda_i)}{p(\lambda_i)}\right|^2 \right]
% \leq  4\|f(\bm{\Lambda}_{n \setminus k}) + 2\epsilon_2\bm{I}\|_{\F}^2 e^{-4(m-1) \sqrt{\gamma_\epsilon}}.
% \]
% Combining this inequality with \cref{theorem:krylov_aware} and applying the triangle inequality gives the result.
% \end{proof}

% % {\color{blue}
% % \tyler{I didn't check these that carefully yet.} \David{I have cleaned up the section a bit. We can uncomment the blue stuff below. }

% % By constructing particular polynomials of degree $<s$, we can obtain more explicit bounds that depend only on how accurately $f(x)$ can be approximated by polynomials. 
% % These bounds are reminiscent of standard bounds that might be obtained if we could do exact products with $f(\bm{A})$, except that they have small error terms accounting for the fact that $f(x)$ might not be a polynomial. 
% % For example, by taking $p(x)$ as the best approximation to $f(x)$, shifted up to be above $f(x)$, we can obtain a bound like what one might obtain the the randomized SVD.
% % \begin{corollary}\label{theorem:rsvd_like_bound2}
% % Suppose $f(\lambda_i) \geq 0$ for all $i=1, \dots, n$ and define
% % \[
% % \epsilon_1 = \min_{p\in\mathbb{P}_{2r+1}} \|f(x) - p(x)\|_{L^{\infty}([\lambda_{\min},\lambda_{\max}])}
% % ,\quad
% % \epsilon_2 = \min_{p\in\mathbb{P}_{s-1}} \|f(x) - p(x)\|_{L^{\infty}(\Lambda)}.
% % \]
% % Then, if $\ell-k\geq 2$, the expected error $\mathbb{E}\|f(\bm{A}) - \bm{Q}_s \llbracket f(\bm{T}_q)_{1:d_s,1:d_s}\rrbracket_{k} \bm{Q}_s^\T\|_{\F}$ is bounded by
% % \[
% % 4\sqrt{d_s} \epsilon_1 +
% % \sqrt{\|f(\bm{\Lambda}_{n \setminus k })\|_{\F}^2 +  \frac{5k}{\ell - k + 1} \|f(\bm{\Lambda}_{n \setminus k}) + 2\epsilon_2 \bm{I}\|_{\F}^2}.
% % \]
% % \end{corollary}
% % A similar approach allows us to obtain bounds reminiscent of what one might obtain for the randomized block Krylov algorithm with exact products with $f(\bm{A})$.
% % For clarity we consider the gaped case where $f(\lambda_k) - f(\lambda_{k+1}) > 0$.
% % \begin{corollary}
% % \label{theorem:rbki_like_bound2}
% % Suppose $f(\lambda_i) \geq 0$ for all $i=1, \dots, n$, fix $q>0$, and define
% % \[
% % \epsilon_1 = \min_{p\in\mathbb{P}_{2r+1}} \|f(x) - p(x)\|_{L^{\infty}([\lambda_{\min},\lambda_{\max}])}
% % ,\quad
% % \epsilon_2 = \min_{p\in\mathbb{P}_{\lfloor (s-1)/q \rfloor}} \|f(x) - p(x)\|_{L^{\infty}(\Lambda)}.
% % \]
% % Define a gap parameter
% % \[
% % \gamma_{\epsilon}
% % = \frac{f(\lambda_k) - (f(\lambda_{k+1})+2\epsilon_2)}{f(\lambda_k) + f(\lambda_{k+1})+2\epsilon_2}.
% % \]
% % Then, if $\ell-k\geq 2$, the expected error $\mathbb{E}\|f(\bm{A}) - \bm{Q}_s \llbracket f(\bm{T}_q)_{1:d_s,1:d_s}\rrbracket_{k} \bm{Q}_s^\T\|_{\F}^2$ is bounded by
% % \[
% % 4\sqrt{d_s} \epsilon_1 +
% % \sqrt{\|f(\bm{\Lambda}_{n \setminus k })\|_{\F}^2 +  \frac{20k}{\ell - k + 1} \|f(\bm{\Lambda}_{n \setminus k}) + 2\epsilon_2\bm{I}\|_{\F}^2 e^{-4(q-1) \sqrt{\gamma_\epsilon}} }.
% % \]
% % \end{corollary}
% % Critically, note that we do not have to choose $q$ a priori. 
% % Thus, we ``automatically'' get the best possible bounds without having to decide how accurately we should approximate products with $f(\bm{A})$.

% % It is worth pointing out that in both \cref{theorem:rsvd_like_bound,theorem:rbki_like_bound}, $\epsilon_2$ depends on the best polynomial approximation to $f(x)$ \emph{on the eigenvalues of $\bm{A}$}.
% % Such bounds can often be much smaller than the corresponding bounds on an interval containing the eigenvalues.
% % In fact, in the special case where For $f(x) = 1/x$ and $\bm{A}$ is positive definite, the optimality of conjugate gradient allows $\epsilon_1$ to also be upgraded to a bound on the eigenvalues of $\bm{A}$.



% % Something about when $f(x) = x$,  we in fact recover standard bounds. 
    

% % \begin{proof}[Proof of \cref{theorem:rsvd_like_bound}]
% % Let $\hat{p}(x)$ be a degree $s-1$ polynomial such that $\|f(x) - \hat{p}(x)\|_{L^{\infty}(\Lambda)} = \epsilon_2$, and define $p(x) = \hat{p}(x) + \epsilon_2$.
% % Note that for any $i=1,\ldots, k$, $p(\lambda_i) \leq f(\lambda_i) + 2\epsilon_2$ so
% % \[
% % \|p(\bm{\Lambda}_{n \setminus k})\|_{\F}^2
% % \leq \|f(\bm{\Lambda}_{n \setminus k}) + 2\epsilon_2 \bm{I}\|_{\F}^2.
% % \]
% % In addition, since $f(\lambda_i) \leq p(\lambda_i)$,
% % \[
% % \max\limits_{i=1,\ldots,k} \left|\frac{f(\lambda_i)}{p(\lambda_i)}\right|^2
% % \leq 1.
% % \]
% % Combining these results gives the specified bound for a particular degree $s-1$ polynomial $p(x)$ and thus 
% % \[
% % \min\limits_{p \in \mathbb{P}_{s-1}} \left[\|p(\bm{\Lambda}_{n \setminus k})\|_{\F}^2\max\limits_{i=1,\ldots,k} \left|\frac{f(\lambda_i)}{p(\lambda_i)}\right|^2 \right]
% % \leq  \|f(\bm{\Lambda}_{n \setminus k}) + 2\epsilon_2 \bm{I}\|_{\F}^2.
% % \]
% % Combining with \cref{theorem:krylov_aware} gives the result.
% % \end{proof}

% % \begin{proof}[Proof of \cref{theorem:rbki_like_bound}]
% % Let $\hat{p}(x)$ be a degree $\lfloor (s-1)/q \rfloor$ polynomial such that $\|f(x) - \hat{p}(x)\|_{L^{\infty}(\Lambda)} = \epsilon_2$ and define $\tilde{p}(x) = \hat{p}(x) + \epsilon_2$.
% % Set $p(x) = \tilde{p}(x)\tilde{T}_{q-1}(\tilde{p}(x))$, where $\tilde{T}_{q-1}(x) = T_{q-1}(x / (f(\lambda_{k+1})+2\epsilon_2))$ is the degree $q-1$ Chebyshev polynomial scaled to start jumping at $f(\lambda_{k+1})+2\epsilon_2$.

% % Note that for $i=k+1, \ldots, n$, since $\tilde{p}(\lambda_i) \in [0,f(\lambda_{k+1}) + 2\epsilon_2]$, $\tilde{T}_{q-1}(\tilde{p}(\lambda_{i})) \leq 1$.
% % Thus, using that $p(\lambda_i) \leq f(\lambda_i) + 2\epsilon_2$,
% % \[
% % \|p(\bm{\Lambda}_{n \setminus k})\|_{\F}^2 
% % \leq \|\tilde{p}(\bm{\Lambda}_{n \setminus k}) \|_{\F}^2 \|\tilde{T}_{q-1}(\tilde{p}(\bm{\Lambda}_{n \setminus k}))\|_{2}^2
% % \leq \|f(\bm{\Lambda}_{n \setminus k}) + 2\epsilon_2\bm{I}\|_{\F}^2.
% % \]
% % Now, fix $i=1,\ldots, k$.
% % If $\gamma_k\in[0,1]$ then $f(\lambda_i) \geq f(\lambda_{k+1}) + 2\epsilon_2$.
% % Thus, since $f(\lambda_i)\leq \tilde{p}(\lambda_i)$, $p(\lambda_i) = \tilde{p}(\lambda_{i})\tilde{T}_{q-1}(\tilde{p}(\lambda_{i})) \geq f(\lambda_{i})\tilde{T}_{q-1}(f(\lambda_{i}))$.
% % This implies that
% % \[
% % \max\limits_{i=1,\ldots,k} \left|\frac{f(\lambda_i)}{p(\lambda_i)}\right|^2
% % \leq \max\limits_{i=1,\ldots,k} \left|\frac{f(\lambda_i)}{\tilde{T}_q(f(\lambda_i))}\right|^2
% % \leq T_{q-1}(f(\lambda_k))^{-2}.
% % \]
% % Using basic properties of Chebyshev polynomials \cite[Lemma 9.3]{tropp2023randomized},
% % \tyler{I just tried to pattern match from p46, need to check more carefully}
% % \[
% % \tilde{T}_{q-1}(f(\lambda_k))
% % = T_{q-1}\left(\frac{f(\lambda_k)}{f(\lambda_{k+1}+2\epsilon_2)}\right)
% % = T_{q-1}\left( \frac{1+\gamma_\epsilon}{1-\gamma_\epsilon} \right)
% % \geq \frac{1}{2}e^{2(q-1) \sqrt{\gamma_\epsilon}}.
% % \]
% % Combining these results gives the specified bound for a particular degree $\lfloor(s-1)/1\rfloor \leq s-1$ polynomial $p(x)$ and thus
% % \[
% % \min\limits_{p \in \mathbb{P}_{s-1}} \left[\|p(\bm{\Lambda}_{n \setminus k})\|_{\F}^2\max\limits_{i=1,\ldots,k} \left|\frac{f(\lambda_i)}{p(\lambda_i)}\right|^2 \right]
% % \leq  4\|f(\bm{\Lambda}_{n \setminus k}) + 2\epsilon_2\bm{I}\|_{\F}^2 e^{-4(q-1) \sqrt{\gamma_\epsilon}}.
% % \]
% % Combining with \cref{theorem:krylov_aware} gives the result.
% % \end{proof}

% % }

% % We proceed with commenting on the three terms appearing in the bounds in \Cref{theorem:krylov_aware}. 
% % The $4\sqrt{d_s} \inf\limits_{p \in \mathbb{P}_{2r+1}}\|f(x)-p(x)\|_{L^{\infty}([\lambda_{\min},\lambda_{\max}])}$ term tells us that the approximation of the quadratic form $\bm{Q}_s^\T f(\bm{A})\bm{Q}_s$ needs to be approximated accurately. If we know that $\|f(\bm{T}_q)_{1:d_s,1:d_s} - \bm{Q}_s^\T f(\bm{A}) \bm{Q}_s\|_{\F} \leq \Delta$ almost surely then the $4\sqrt{d_s} \inf\limits_{p \in \mathbb{P}_{2r+1}}\|f(x)-p(x)\|_{L^{\infty}([\lambda_{\min},\lambda_{\max}])}$ term appearing in \Cref{theorem:krylov_aware} can be replaced with $2 \Delta$. The $\|f(\bm{\Lambda}_{n \setminus k})\|_{\F}$ term tells us that the error can never be below the optimal rank $k$ approximation error. Finally, $\min\limits_{p \in \mathbb{P}_{s-1}} \left[\|p(\bm{\Lambda}_{n \setminus k}) \bm{\Omega}_{n \setminus k} \bm{\Omega}_k^{\dagger}\|_{\F}^2\max\limits_{i=1,\ldots,k} \left|\frac{f(\lambda_i)}{p(\lambda_i)}\right|^2\right]$ tells us that $\bm{Q}_s$ is a good orthonormal basis for low-rank approximation if there is a polynomial of degree at most $s-1$ that is very large on the large eigenvalues $\lambda_1,\ldots,\lambda_k$ and is very small on the small eigenvalues $\lambda_{k+1},\ldots,\lambda_n$, which effectively denoises the contribution from the small eigenvalues of $f(\bm{A})$. A similar intuition was used in \cite{MM15,tropp2023randomized}.

% Furthermore, note that when $f$ is a monotonic function one can derive even stronger bounds by choosing $p$ to be a scaled and shifted Chebyshev polynomial that is small on the eigenvalues in $\bm{\Lambda}_{n \setminus k}$ and large on the eigenvalues in $\bm{\Lambda}_k$. We omit a detailed discussion. }}

% \David{In my opinion, this section is redundant now and should be removed. }
% Furthermore, to obtain explicit bounds one must obtain an upper bound for the optimization problem
% \begin{equation*}
%      \min\limits_{p \in \mathbb{P}_{s-1}} \left[\|p(\bm{\Lambda}_2)\|_{\F}\max\limits_{i=1,\ldots,k} \left|\frac{f(\lambda_i)}{p(\lambda_i)}\right| \right].
% \end{equation*}
% This is a non-trivial task without any assumptions on $f$ and the spectrum of $\bm{A}$. However, when $f$ is a monotonic function that does not change sign one can obtain some explicit bounds. In this case all the eigenvalues in $\bm{\Lambda}_k$ are contained in a closed interval $I_k$ and all eigenvalues in $\bm{\Lambda}_{n \setminus k}$ in a closed interval $I_{n \setminus k}$, where $I_k$ and $I_{n \setminus k}$ can intersect in at most one point, which happens if $f(\lambda_k) = f(\lambda_{k+1})$. In this case one can choose $p$ to be a scaled and shifted Chebyshev polynomial of degree $s-1$ so that $|p(x)| \leq 1$ for $x \in I_{n \setminus k}$ and $p(x)$ grows quickly for $x \in I_{k}$. In this case we obtain 
% \begin{equation}\label{eq:upperbound}
%     \|p(\bm{\Lambda}_2)\|_{\F}\max\limits_{i=1,\ldots,k} \left|\frac{f(\lambda_i)}{p(\lambda_i)}\right| \leq \sqrt{n} \max\limits_{i=1,\ldots,k}\left|\frac{f(\lambda_i)}{p(\lambda_i)}\right|.
% \end{equation}
% While the upper bound is easier to work with, it is still difficult to obtain a tight upper bound without any assumptions on $f$. One can derive an upper bound for special functions, such as $f(x) = \exp(x)$, but we omit details. 

% \subsection{Explicit bounds}
% Deriving tight upper bounds for the objective value of the optimization problem
% \begin{equation}\label{eq:difficult_optim_problem}
%     \min\limits_{p \in \mathbb{P}_{s-1}} \left[\|p(\bm{\Lambda}_2)\|_{\F}\max\limits_{i=1,\ldots,k} \left|\frac{f(\lambda_i)}{p(\lambda_i)}\right| \right]
% \end{equation}
% is a difficult task without any assumptions on $f$ and the spectrum of $\bm{A}$. Instead, we will focus on a certain classes of functions.
% \subsubsection{Functions that are well approximated by polynomials}
% Suppose that there exists a polynomial $p \in \mathbb{P}_{s-1}$ so that
% \begin{equation*}
%     \|p(\bm{A}) - f(\bm{A})\|_2 \leq \delta_{s-1}.
% \end{equation*}
% Then, $f(\bm{A}) \preceq p(\bm{A}) + \delta_{s-1} \bm{I} \preceq f(\bm{A}) + 2 \delta_{s-1} \bm{I}$, and
% \begin{equation*}
%     \min\limits_{p \in \mathbb{P}_{s-1}} \left[\|p(\bm{\Lambda}_2)\|_{\F}\max\limits_{i=1,\ldots,k} \left|\frac{f(\lambda_i)}{p(\lambda_i)}\right| \right] \leq \|f(\bm{\Lambda}_2)\|_{\F} + 2n \delta_{s-1}.
% \end{equation*}
% However, in most cases this will be a significant overestimation of \eqref{eq:difficult_optim_problem}.
% \subsubsection{Monotonic functions that do not change sign}
%  When $f$ is a monotonic function that does not change sign all the eigenvalues in $\bm{\Lambda}_1$ are contained in a closed interval $I_1$ and all eigenvalues in $\bm{\Lambda}_2$ in a closed interval $I_2$ and $I_1 \cap I_2 = \emptyset$. Furthermore, we may also assume without loss of generality that $f$ is positive. If $f$ is negative we consider $g = -f$ and the similar bounds derived in this section still hold. 

% One can upper bound \eqref{eq:difficult_optim_problem} with
% \begin{equation}\label{eq:upper_bound1}
%     \min\limits_{p \in \mathbb{P}_{s-1}} \left[\|p(\bm{\Lambda}_2)\|_{\F}\max\limits_{i=1,\ldots,k} \left|\frac{f(\lambda_i)}{p(\lambda_i)}\right| \right] \leq \sqrt{n} \min\limits_{p \in \mathbb{P}_{s-1}} \left[\|p\|_{L^{\infty}(I_2)} \left\|\frac{f}{p}\right\|_{L^{\infty}(I_1)}\right]. 
% \end{equation}
% By shifting $f$ and the eigenvalues of $\bm{\Lambda}$\footnote{Recall that we ordered the eigenvalues of $\bm{\Lambda}$ so that $\lambda_1 \geq \lambda_2 \geq \ldots \geq \lambda_n$ if $f$ is increasing and $\lambda_1 \leq \lambda_2 \leq \ldots \leq \lambda_n$ if $f$ is decreasing}
% \begin{align*}
%     &g(x) = f(x + \lambda_n) \text{ and } \mu_i = \lambda_i - \lambda_n \quad \text{if } f \text{ is increasing};\\
%     &g(x) = f(\lambda_1 - x) \text{ and } \mu_i = \lambda_1 - \lambda_{i} \quad \text{if } f \text{ is decreasing};
% \end{align*}
% so that $g$ is increasing, $\mu_1 \geq \mu_2 \geq \ldots \geq \mu_n \geq 0$, and $g(\mu_i) = f(\lambda_i)$. Furthermore, we have
% \begin{equation}\label{eq:upper_bound2}
%     \min\limits_{p \in \mathbb{P}_{s-1}} \left[\|p\|_{L^{\infty}(I_2)} \left\|\frac{f}{p}\right\|_{L^{\infty}(I_1)}\right] = \min\limits_{p \in \mathbb{P}_{s-1}} \left[\|p\|_{L^{\infty}([0,\mu_{k+1}])} \left\|\frac{g}{p}\right\|_{L^{\infty}([\mu_{k},\mu_1])}\right],
% \end{equation}
% By setting $p(x) = T_{s-1}\left(\frac{x}{\mu_{k+1}}\right)$ we know that $|p(x)| \leq 1$ for $x \in [0,\mu_{k+1}]$ \textcolor{red}{cite this} and $p(x)$ is increasing for $x \geq \mu_{k+1}$. Hence, 
% \begin{equation}\label{eq:upper_bound3}
%     \min\limits_{p \in \mathbb{P}_{s-1}} \left[\|p\|_{L^{\infty}([0,s_{k+1}])} \left\|\frac{g}{p}\right\|_{L^{\infty}([\mu_{k},\mu_1])}\right] \leq \frac{ \|f(\bm{A})\|_2}{T_{s-1}\left(\frac{\mu_k}{\mu_{k+1}}\right)}.
% \end{equation}
% Note that for $x \geq 1$ we have
% \begin{equation}\label{eq:chebyshev_upper_bound}
%     T_{q}(x) = \frac{1}{2}\left((x + \sqrt{x^2-1})^q + (x + \sqrt{x^2-1})^{-q}\right) \geq \frac{1}{2} (2x-1)^q.
% \end{equation}
% Hence, by combining \eqref{eq:upper_bound1}, \eqref{eq:upper_bound2},\eqref{eq:upper_bound3}, and \eqref{eq:chebyshev_upper_bound} we have
% \begin{equation}\label{eq:upper_bound4}
%     \min\limits_{p \in \mathbb{P}_{s-1}} \left[\|p(\bm{\Lambda}_2)\|_{\F}\max\limits_{i=1,\ldots,k} \left|\frac{f(\lambda_i)}{p(\lambda_i)}\right| \right] \leq \frac{2\sqrt{n}\|f(\bm{A})\|_2}{(2 \frac{\mu_k}{\mu_{k+1}} - 1)^{s-1}}.
% \end{equation}
% \textcolor{red}{maybe we should use a different upper bound for the Chebyshev polynomials.}

% \subsubsection{Monotonic functions that do not change signs and are log-convex functions}
% \eqref{eq:upper_bound4} can still be loose for many functions. Under some additional assumptions on $f$ one can derive tigher bounds for \eqref{eq:upper_bound1}, and one such assumption is that $f$ is log-convex. A function $f$ is log-convex if it can be written as $f(x) = \exp(h(x))$ for a convex function $h$. $f(x) = \exp(\beta x)$ for $\beta \in \mathbb{R}$ and $f(x) = \frac{1}{x^c}$ for $c \geq 0$ are examples of log-convex functions. 

% Using \eqref{eq:upper_bound1}, \eqref{eq:upper_bound2}, and \eqref{eq:chebyshev_upper_bound} we have
% \begin{equation*}
%     \min\limits_{p \in \mathbb{P}_{s-1}} \left[\|p(\bm{\Lambda}_2)\|_{\F}\max\limits_{i=1,\ldots,k} \left|\frac{f(\lambda_i)}{p(\lambda_i)}\right| \right] \leq \sqrt{n}\exp\left(\sup\limits_{x \in [\mu_k,\mu_1]} \left\{h(x) -(s-1) \ln\left(2\frac{x}{\mu_{k+1}}-1\right)\right\}\right).
% \end{equation*}
% Since $h(x) - (s-1)\ln\left(2\frac{x}{\mu_{k+1}}-1\right)$ is a convex function it attains its maximum on the boundary of $[\mu_{k},\mu_1]$. Furthermore, one can also show that if $s\geq \log\left(\frac{g(\mu_1)}{g(\mu_{k})}\right) /\log\left(\frac{2\mu_1 - \mu_{k+1}}{2\mu_k - \mu_{k+1}}\right)+1$ that the maximum is attained at $x = \mu_k$. Hence, in this case we have
% \begin{equation*}
%     \min\limits_{p \in \mathbb{P}_{s-1}} \left[\|p(\bm{\Lambda}_2)\|_{\F}\max\limits_{i=1,\ldots,k} \left|\frac{f(\lambda_i)}{p(\lambda_i)}\right| \right] \leq \sqrt{n} \frac{f(\mu_k)}{\left(\frac{2\mu_k}{\mu_{k+1}} - 1\right)^{s-1}}.
% \end{equation*}