\section{Numerical experiments}
\label{sec:experiments}
In this section we compare the Krylov aware low-rank approximation (\Cref{alg:krylow}) and \Cref{alg:rsvd} (assuming exact matvecs with $f(\bm{A})$) and \Cref{alg:rsvd_matfun} (inexact matvecs with $f(\bm{A})$). All experiments have been performed in MATLAB (version 2020a) and scripts to reproduce the figures are available at \url{https://github.com/davpersson/Krylov_aware_LRA.git}.

\subsection{Test matrices}
We begin with outlining the test matrices and matrix functions used in our examples. 



\subsubsection{Exponential integrator}\label{section:exponential_integrator}
The following example is taken from \cite{persson_kressner_23}. Consider the following parabolic differential equation
\begin{align*}
\begin{split}
    &u_t = \kappa \Delta u + \lambda u \text{ in } [0,1]^2 \times [0,2]\\
    &u(\cdot,0) = \theta \text{ in } [0,1]^2\\
    &u = 0 \text{ on } \Gamma_1\\
    & \frac{\partial u}{\partial \bm{n}} = 0 \text{ on } \Gamma_2
\end{split}
\end{align*}
for $\kappa, \lambda > 0$ and $\Gamma_2 = \{(x,1) \in \mathbb{R}^{2} : x \in [0,1] \}$ and $\Gamma_1 = \partial \mathcal{D} \setminus \Gamma_2$. By discretizing in space using finite differences on a $100 \times 100$ grid we obtain an ordinary differential equation of the form
\begin{align}
\begin{split}
    \dot{\bm{u}}(t) &= \bm{A} \bm{u}(t) \text{ for } t \geq 0,\\
    \bm{u}(0) &= \bm{\theta}, \label{eq:ode}
\end{split}
\end{align}
for symmetric matrix $\bm{A} \in \mathbb{R}^{9900 \times 9900}$. It is well known that the solution to \eqref{eq:ode} is given by $\bm{u}(t) = \exp(t\bm{A})\bm{\theta}$. Suppose that we want to compute the solution for $t \geq 1$. One can verify that 
\begin{equation*}
    \max\limits_{t \geq 1} \frac{\|\exp(t\bm{A}) - \llbracket\exp(t\bm{A})\rrbracket_{k}\|_{\F}}{\|\exp(t\bm{A})\|_{\F}} = \frac{\|\exp(\bm{A}) - \llbracket\exp(\bm{A})\rrbracket_{k}\|_{\F}}{\|\exp(\bm{A})\|_{\F}},
\end{equation*}
and it turns out that $\exp(\bm{A})$ admits a good rank $60$ approximation
\begin{equation*}
    \frac{\|\exp(\bm{A}) - \llbracket\exp(\bm{A})\rrbracket_{60}\|_{\F}}{\|\exp(\bm{A})\|_{\F}} \approx 4 \times 10^{-4}.
\end{equation*}
Hence, we can use \Cref{alg:krylow} to compute $\bm{Q}_s$ and $\bm{T}_q$ and use them to efficiently construct a rank $60$ approximation to $\exp(t\bm{A})$ for any $t$ \emph{with almost no additional cost}. 

In the experiments we set $\kappa = 0.01$ and $\lambda = 1$. 
\subsubsection{Estrada index}\label{section:estrada}
For an (undirected) graph with adjacency matrix $\bm{A}$ the Estrada index is defined as $\tr(\exp(\bm{A}))$. It is used to measure the degree of protein folding \cite{estrada}. One can estimate the Estrada index of a network by the Hutch++ algorithm or its variations \cite{chen_hallman_23,epperly2023xtrace,hpp,ahpp}, which requires computing a low-rank approximation of $\exp(\bm{A})$. Motivated by the numerical experiments in \cite{hpp} we let $\bm{A}$ be the adjacency matrix of Rogetâ€™s Thesaurus semantic graph \cite{roget}. 

\begin{figure}[ht]
\begin{subfigure}{.5\textwidth}
  \centering
  \includegraphics[width=.9\linewidth]{imgs/exponential_integrator}  
  \caption{Example from \Cref{section:exponential_integrator}}
\end{subfigure}
\begin{subfigure}{.5\textwidth}
  \centering
  \includegraphics[width=.9\linewidth]{imgs/estrada} 
  \caption{Example from \Cref{section:estrada}}
\end{subfigure}
\begin{subfigure}{.5\textwidth}
  \centering
  \includegraphics[width=.9\linewidth]{imgs/quantum_spin}  
  \caption{Example from \Cref{section:quantum_spin}}
\end{subfigure}
\begin{subfigure}{.5\textwidth}
  \centering
  \includegraphics[width=.9\linewidth]{imgs/synthetic_log}  
  \caption{Example from \Cref{section:synthetic_log}}
\end{subfigure}
\caption{Comparing relative error \eqref{eq:relative_error} for the the approximations returned by \Cref{alg:krylow} without truncation (untruncated), \Cref{alg:krylow} with truncation back to rank $k$ (truncated), \Cref{alg:rsvd_matfun}, and \Cref{alg:rsvd}. The black line shows the optimal rank $k$ approximation relative Frobenius norm error. The rank parameter $k$ is visible as titles in the figures. In all experiments we set $\ell = k$. }
\label{fig:relative_errors}
\end{figure}

\subsubsection{Quantum spin system}\label{section:quantum_spin}
We use an example from \cite[Section 4.3]{epperly2023xtrace}, a similar example is found in \cite{chen_hallman_23}, in which we want to approximate $\exp(-\beta \bm{A})$ where 
\begin{equation*}
    \bm{A} = -\sum\limits_{i=1}^{N-1} \bm{Z}_i\bm{Z}_{i+1} -h\sum\limits_{i=1}^N \bm{X}_i \in \mathbb{R}^{n \times n},
\end{equation*}
where
\begin{equation*}
    \bm{X}_i = \bm{I}_{2^{i-1}} \otimes \bm{X} \otimes \bm{I}_{2^{N-i}}, \quad \bm{Z}_i = \bm{I}_{2^{i-1}} \otimes \bm{Z} \otimes \bm{I}_{2^{N-i}}
\end{equation*}
where $\bm{X}$ and $\bm{Z}$ are the Pauli operators
\begin{equation*}
    \bm{X} = \begin{bmatrix} 0 & 1 \\ 1 & 0 \end{bmatrix}, \quad \bm{Z} = \begin{bmatrix} 1 & 0 \\ 0 & -1 \end{bmatrix}.
\end{equation*}
Estimating the partition function $Z(\beta) = \tr(\exp(-\beta \bm{A}))$ is an important task in quantum mechanics \cite{pfeuty1970one}, which once again can benefit from computing a low-rank approximation of $\exp(-\beta \bm{A})$.

In the experiments we set $N = 14$ so that $n = 2^{14}$, $\beta = 0.3$, and $h = 10$.  



\subsubsection{Synthetic example for the matrix logarithm}\label{section:synthetic_log}
We generate a symmetric matrix $\bm{A} \in \mathbb{R}^{5000 \times 5000}$ with eigenvalues $\lambda_i = \exp(\frac{1}{i^2})$ for $i = 1,\ldots,n$. We let $f(x) = \log(x)$ so that the eigenvalues of $f(\bm{A})$ are $f(\lambda_i) = \frac{1}{i^2}$ for $i = 1,\ldots,n$.
%\subsubsection{Synthetic example for the inverse}
%We generate a matrix $\bm{A} \in \mathbb{R}^{5000 \times 5000}$ with eigenvalues $\lambda_i = i^2$ for $i = 1,\ldots,n$. We let $f(x) = \frac{1}{x}$ so that the eigenvalues of $f(\bm{A})$ are $f(\lambda_i) = \frac{1}{i^2}$ for $i = 1,\ldots,n$.


\begin{figure}[ht]
\begin{subfigure}{.5\textwidth}
  \centering
  \includegraphics[width=.9\linewidth]{imgs/exponential_integrator_p=5}  
  \caption{Example from \Cref{section:exponential_integrator}}
\end{subfigure}
\begin{subfigure}{.5\textwidth}
  \centering
  \includegraphics[width=.9\linewidth]{imgs/estrada_p=5} 
  \caption{Example from \Cref{section:estrada}}
\end{subfigure}
\begin{subfigure}{.5\textwidth}
  \centering
  \includegraphics[width=.9\linewidth]{imgs/quantum_spin_p=5}  
  \caption{Example from \Cref{section:quantum_spin}}
\end{subfigure}
\begin{subfigure}{.5\textwidth}
  \centering
  \includegraphics[width=.9\linewidth]{imgs/synthetic_log_p=5}  
  \caption{Example from \Cref{section:synthetic_log}}
\end{subfigure}
\caption{Comparing relative error  \eqref{eq:relative_error} for the the approximations returned by \Cref{alg:krylow} without truncation (untruncated), \Cref{alg:krylow} with truncation back to rank $k$ (truncated), \Cref{alg:rsvd_matfun}, and \Cref{alg:rsvd}. The black line shows the optimal rank $k$ approximation relative Frobenius norm error. The rank parameter $k$ is visible as titles in the figures. In all experiments we set $\ell = k+5$. }
\label{fig:relative_errors2}
\end{figure}

\subsection{Comparing relative errors}
In this section we compare the error returned by \Cref{alg:krylow},  \Cref{alg:rsvd}, and \Cref{alg:rsvd_matfun}. If $\bm{C}$ is a low-rank approximation returned by one of the algorithms then we compare the relative error
\begin{equation}\label{eq:relative_error}
    \frac{\|f(\bm{A}) - \bm{C}\|_{\F}}{\|f(\bm{A})\|_{\F}}.
\end{equation}
In all experiments we set the parameters in \Cref{alg:krylow} and \Cref{alg:rsvd_matfun} to be $\ell = k$ or $\ell = k + 5$ and $s = r$ so that the total number of matrix vector products with $\bm{A}$ is $2\ell s$. 
When we run \Cref{alg:rsvd_matfun} we compute matvecs with $f(\bm{A})$ exactly, which cannot be done in practice. Hence, the results from this algorithm are only used as a reference for \Cref{alg:krylow} and \Cref{alg:rsvd_matfun}.
The results are presented in \Cref{fig:relative_errors} for $\ell = k$ and \Cref{fig:relative_errors2} for $\ell = k + 5$. All results confirm that \Cref{alg:krylow} returns a more accurate approximation than \Cref{alg:rsvd_matfun}, and can even be more accurate than the \Cref{alg:rsvd}. Note that for the example given in \Cref{section:quantum_spin} the error for the untruncated version of the approximation returned by \Cref{alg:krylow} stagnates. This is because the error from the approximation of the quadratic form dominates the error. In this case, $r$ should be chosen larger than $s$. However, we leave it as an open research question to determine the optimal balancing of $s$ and $r$.  

