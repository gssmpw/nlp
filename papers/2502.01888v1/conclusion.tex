\section{Conclusion}
In this work we have provided an analysis of the Krylov-aware low-rank approximation presented in \cite{chen_hallman_23}. In particular, we have shown that the Krylov-aware low-rank approximation to $f(\bm{A})$ is never worse than the approximation returned by the randomized SVD on $f(\bm{A})$, up to a polynomial approximation error factor. Furthermore, the numerical experiments demonstrate that the Krylov-aware low-rank approximation is significantly more accurate than the approximation returned by the randomized SVD on $f(\bm{A})$. 

\begin{paragraph}{Acknowledgements}
This work was done while David Persson was a PhD-student at EPFL and supported by the SNSF research project \textit{Fast algorithms from low-rank updates}, grant number: 200020\_178806. This work is also contained in his PhD-thesis \cite{thesis}. Tyler Chen and Christopher Musco were partially supported by NSF Award \#2045590. The authors thank Daniel Kressner for helpful comments on this work. 
\end{paragraph}


%In this work we have provided an analysis of the Krylov-aware low-rank approximation presented in \cite{chen_hallman_23}. We have provided error bounds that align with our intuition of Krylov subspace methods and we therefore shed light on the good performance of the Krylov-aware method. 