\section{Conclusion}
\label{sec: conclusion}

We propose an evolution-based algorithm for VLMs to progressively refine prompts from task-specific to class-specific levels. To save generation costs, ProAPO uses several edit- and evolution-based operators to create candidate prompts with a prompt library. Results show that our fitness score mitigates overfitting in class-specific prompts. We empirically verify that two sampling strategies improve performance and save iteration times. Extensive experiments on thirteen datasets reveal that ProAPO consistently outperforms SOTA textual prompt-based methods on low-shot tasks. Moreover, our method effectively improves adapter-based and description-based methods and easily transfers across different backbones. We hope ProAPO could provide new insight into adapting VLMs from the textual side.

% Qualitative results show that ProAPO filters ambiguous and retains discriminative prompts. 
