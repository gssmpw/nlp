\section{Related Work}
\label{sec: related_work}

% ---------------------------------------------------- % 
%                   VLMs 的相关工作
% ---------------------------------------------------- %
% \noindent 
% \textbf{Large-scale vision-language models}
% like CLIP~\cite{CLIP} have shown promising performance on various tasks. They align visual and textual spaces to a joint space via training on millions of image-text pairs from the web. Other work~\cite{Align, DEFILIP, DeClip, FILIP, BLIP, Flamingo, SLIP, EVA-01, EVA-02} has furthered this paradigm to learn more accurate semantic alignment in joint space. 
% In this work, we advance VLMs for downstream tasks by progressively learning optimal class-specific prompts with minimal supervision and no human intervention. 

% contrastive learning

% ---------------------------------------------------- % 
%            加强 VLMs 用于下游任务的相关工作
% ---------------------------------------------------- %
\noindent 
\textbf{Adaptation of VLMs for image classification tasks.} 
Inspired by successes in VLMs, recent works aim to adapt them for image classification tasks. Some works utilize lightweight linear layers~\cite{CLIP, AMU-Tuning, LP++, LFA, FD-Align, TMM_SelfAlign, T2VIndexer}, adapters~\cite{CLIP_Adapter, VDT_2023_ICCV}, visual prompting~\cite{VP, BlackVIP, VPT}, or cache models~\cite{Tip, APE, Tip-X} to enhance visual features. Other works aim to improve the quality of prompts. Manual prompt engineering~\cite{CLIP, DeClip, DEFILIP} applies task-specific information in prompt templates to enhance performance. However, templates need to be hand-written and lack fine-grained details~\cite{DCLIP, CuPL, P_N, CoOp, VDT_2023_ICCV}. Prompt tuning methods~\cite{CoOp, CoCoOp, PLOT, ProGrad, CPT, prompt_distribution, prompt_variation, TPT, MaPLe, PromptSRC, Visual_in_context_learn} learn task-specific context by a set of learnable tokens. However, they need additional training and lack interpretability~\cite{DCLIP, P_N, WaffleCLIP}. In contrast, LLM-generated description methods~\cite{DCLIP, CuPL, GPT4Vis, VDT_2023_ICCV, VDT_2023_NIPS_Hierarchical, AWT, MPVR, AdaptCLIP, EmDepart, I2MVFormer} exploit implicit knowledge in LLMs to generate visual descriptions for each category. They enrich semantics in prompts and offer interpretable predictions. In this work, we aim to further improve description quality through an evolution process.


% Some works utilize parameter-efficient fine-tuning by lightweight linear layers~\cite{CLIP, AMU-Tuning, LP++, LFA}, adapters~\cite{CLIP_Adapter, VDT_2023_ICCV}, visual prompting~\cite{VP, BlackVIP, VPT}, or cache models~\cite{Tip, APE, Tip-X} for enhancing few-shot classification. 

% For instance, ``\texttt{a photo of a \{class\}, a type of flower.}'' is used to recognize fine-grained flower categories. 

% ---------------------------------------------------- % 
%          LLM-generated Descriptions 的相关工作
% ---------------------------------------------------- %
\noindent 
\textbf{LLM-generated description methods} apply class-specific descriptions to language prompts to adapt VLMs for classification. DCLIP~\cite{DCLIP} and CuPL~\cite{CuPL} design prompts such as ``\texttt{What does a \{class\} look like?}'' to instruct LLMs to generate category descriptions. GPT4Vis~\cite{GPT4Vis} and VDT~\cite{VDT_2023_ICCV} use GPT-4~\cite{GPT4_Tech} for rich and diverse descriptions. Some work utilizes LLM-generated hierarchy labels~\cite {CHiLS} or descriptions~\cite{VDT_2023_NIPS_Hierarchical} to recognize images from coarse to fine-grained levels. However, due to the hallucination in LLMs, generated descriptions might be inaccurate, non-visual, and lack discrimination~\cite{DCLIP, WaffleCLIP, VDT_2023_NIPS_Hierarchical}. To this end, we propose ProAPO to iteratively remove ambiguous and retain discriminative prompts. Moreover, category names, ignored in previous methods, are equally crucial for improving accuracy and are introduced in our optimization.

% Several methods~\cite{I2MVFormer, EmDepart, AdaptCLIP} use generated descriptions as auxiliary semantic information to improve generalization in specific-domain models. Most methods

% ---------------------------------------------------- % 
%        Automatic Prompt Optimization 的相关工作
% ---------------------------------------------------- %
\noindent \textbf{Automatic prompt optimization} aims to automatically find optimal prompts for language tasks, overcoming the time-consuming issue in manual prompt methods~\cite{survey_APO}. Early methods~\cite{autoprompt, RLPrompt, GrIPS} generate discrete prompts by filling templates with trigger tokens, iteratively refining prompts by mining, generation, or paraphrasing. Recently, chat-based LLMs have been applied as prompt engineers~\cite{ProTeGi, GA_NLP, APE_NLP, Promptbreeder, OPRO, EVOPrompt}, using a meta-prompt with task information to find optimal prompt design. PN~\cite{P_N} is the first to instruct LLMs to optimize templates on multimodal tasks, which feeds visual feedback of the best and worst templates to guide. However, these methods only optimize task-specific templates. iCM~\cite{iCM} is somewhat similar to ours, optimizing class-specific prompts with chat-based LLMs. However, it uses the whole validation set as supervision. In contrast, we optimize prompts with one-shot supervision and propose solutions to solve high generation costs, long iteration times, and overfitting in class-specific optimization.


% optimizing class-specific prompts in an evolution-based way
% from the vocabulary


% Recent methods~\cite{ProTeGi, GA_NLP, APE_NLP, Promptbreeder, OPRO, EVOPrompt} regard chat-based LLMs as human-level prompt engineers. They design a meta-prompt to describe the task information and instruct LLMs to identify the optimal direction for prompt optimization. 


% our ProAPO, in the one-shot classification setting, generates class-specific prompts with offline LLMs to save computation and introduces a novel fitness score to reduce overfitting.
% Besides, a novel sampling strategy is proposed to reduce the number of class-specific prompts traversed.
% is proposed in natural language processing to automatically find optimal natural language (or hard, discrete)

% and return a complete language prompt with the best accuracy


% Unlike automatic prompt optimization algorithms in previous methods only for task-specific prompt, we need to consider the prompt candidate at the class-specific level. 
