\section{Method}
\label{sec: method}


% ---------------------------------------------------- % 
%                  本文方法的模型图
% ---------------------------------------------------- %
\begin{figure*}[t]
\centering
\includegraphics[width=0.88\linewidth]{Images/Method.pdf}
\vspace{-0.05 in}
\caption{
\textbf{Overview of our ProAPO algorithm}. We progressively refine prompts from task-specific (\textbf{\textcolor{Template}{green lines}}) to class-specific (\textbf{\textcolor{Description}{brown lines}}) levels. Specifically, we first explore the best template by an iterative optimization process (\cref{sec: template_optim}). For each iteration, ProAPO generates a set of candidate templates by several operators (\cref{sec: prompt_generate}) and filters/refines templates by a fitness score (\cref{sec: score_function}). After several iterations, we choose the top-scoring template for description initialization. Subsequently, we introduce two sampling strategies to find a better initial point and reduce traversed categories (\cref{sec: sample_strategy}). Similar iterative optimization is then applied to class-specific descriptions.
}
\label{fig: Method}
\vspace{-10pt}
\end{figure*}


% ProAPO first queries LLMs one time to build a prompt library during initialization. 
% Iterative optimization by our APO algorithm is introduced in templates and descriptions. For each iteration, we generate candidate prompts by several operators. Then, we evaluate them by a fitness score and retain the top-scoring ones for the next generation. Two sampling strategies are introduced to find a better initial point and reduce traversed categories. Finally, the best prompt is returned for classification.

% ---------------------------------------------------- % 
%                       总览的话
% ---------------------------------------------------- %
Our ProAPO algorithm is shown in~\cref{fig: Method} and summarized in Alg.~\ref{alg: ProAPO}. We first describe iterative optimization in templates (\cref{sec: template_optim}). For each iteration, candidates are generated by several operators (\cref{sec: prompt_generate}) and then evaluated by a fitness score (\cref{sec: score_function}). Afterward, similar iterative optimization is applied in descriptions, where we introduce two sampling strategies to save iteration costs (\cref{sec: sample_strategy}).

% In this section, 
% edit-based and evolution-based 

% ---------------------------------------------------- % 
%                  本文方法的算法流程图
% ---------------------------------------------------- %
% \setlength{\textfloatsep}{-21pt} 
\begin{algorithm}[t]
\caption{Our \textit{Progressively Automatic Prompt Optimization} (\texttt{ProAPO}) for visual classification, which iteratively refines prompts from task-specific to class-specific. }
\label{alg: ProAPO}
\begin{algorithmic}[1]
\REQUIRE  $\mathcal{D} \leftarrow \{{(x, y)}\}_n$: training samples, $F:  \mathcal{D} \times P \to \mathbb{R}$: score function
\STATE \textbf{Initialize Template}: $\mathcal{U}_t \leftarrow \{P_0\}$ % \hfill $\triangleright$ Sec.~\ref{sec: template_init}
\STATE \textbf{Build Template Library}: $B_t \leftarrow \{ {d}_1, \cdots, {d}_n \}$ 
\STATE \textbf{Iterative Optimization}: $\mathcal{U}_t \leftarrow \texttt{APO}(\mathcal{D}, F, \mathcal{U}_t, B_t)$  % \hfill $\triangleright$ Sec.~\ref{sec: APO_for_VLM}
\STATE $P_t^* \leftarrow \arg \max_{P \in \mathcal{U}_t} F(\mathcal{D}, P)$
\STATE \textbf{Initialize Description}: $\mathcal{U}_c \leftarrow \{\hat{P}_0 \} $, initializing with $P_t^*$ and prompt sampling strategy% \hfill $\triangleright$ Sec.~\ref{sec: class_specific_init}
\STATE \textbf{Group Sampling}: Sample $S$ groups by class salience % \hfill $\triangleright$ Sec.~\ref{sec: class_specific_init}
\FOR{$s = 1$ to $S$} 
    \STATE \textbf{Build Description Library}: $B_s \leftarrow \{ \hat{d}_1, \cdots, \hat{d}_q \}$
    \STATE \textbf{Iterative Optimization}: $\mathcal{U}_c \leftarrow \texttt{APO}(D, F, \mathcal{U}_c, B_s)$
\ENDFOR
\STATE ${P}^* \leftarrow \arg\max_{{P} \in \mathcal{U}_c} F(\mathcal{D}, {P})$
\RETURN candidate prompt with the highest score ${P}^*$
\end{algorithmic}
\end{algorithm}


% ---------------------------------------------------- % 
%                    Preliminaries
% ---------------------------------------------------- %
% \noindent 
\textbf{Preliminaries.}
Given an image, CLIP~\cite{CLIP} predicts by selecting the highest similarity between the image and category prompt. The category prompt is a human-readable natural language associated with a category, which contains a template, \textit{e.g.}, ``\texttt{a photo of a bird: \{class\}. \{description\}.}'', and class-specific descriptions, \textit{e.g.}, class name ``\texttt{Laysan Albatross}'' and its descriptions ``\texttt{It has white with black wings.}''. Some categories may use multiple prompts with varied templates or descriptions, \textit{i.e.}, prompt ensembling. We denote the prompt set that includes all categories in the task as a candidate prompt $P$. A score function $F: \mathcal{D} \times P \rightarrow \mathbb{R}$ is introduced in~\cref{sec: score_function} to evaluate the candidate prompt $P$ on a limited training set $\mathcal{D} = \{{(x, y)}\}_n$ with one-shot supervision, where $x$ is an image and $y$ is its label. Finally, we use a test set to evaluate optimized prompts.
\textbf{Our goal} is to refine prompts in the natural language space to achieve superior performance in per training sample $(x, y)$: 
% \vspace{-5pt}
\setlength{\abovedisplayskip}{3pt}
\setlength{\belowdisplayskip}{3pt}
\begin{equation}
   \argmax_P F(\mathcal{D}, P) = \argmax_P \mathbb{E}_{(x, y)} [F(\{ (x, y) \}, P)].
\end{equation}
\vspace{-15pt}
% ---------------------------------------------------- % 
%                      APO 算法
% ---------------------------------------------------- %
\setlength{\textfloatsep}{10pt} 
\begin{algorithm}[t]
\caption{\textit{Automatic Prompt Optimization} (\texttt{APO}) algorithm for VLMs - Lines 3 and 9 of Alg.~\ref{alg: ProAPO}, $\texttt{APO}(\mathcal{D}, F, \mathcal{U}, B)$.}
\label{alg: APO}
\begin{algorithmic}[1]
\REQUIRE  $\mathcal{D} \leftarrow \{{(x, y)}\}_n$: training samples, $F: \mathcal{D} \times P \to \mathbb{R}$: score function, $\mathcal{U}$ : candidate prompt set,  $B$: template or description library
\STATE \textbf{Initialize Evaluation Score}: $\mathcal{S} \leftarrow \{F(\mathcal{D}, P)\}_{P \in \mathcal{U}}$
% \WHILE {not converged}
\FOR{$t=1$ to $T$}
\STATE $ \mathcal{U}_{g} \leftarrow \emptyset $
\FORALL{$P \in \mathcal{U}$}
  \STATE \textbf{Edit-based Generate}: $\mathcal{U}_{g} \leftarrow \mathcal{U}_{g} \cup \texttt{GEN}(P, B) $ % \hfill $\triangleright$ Edit-based
\ENDFOR
    \STATE \textbf{Evaluate}: $\mathcal{S}_{g} \leftarrow \{ F(\mathcal{D}, P') \}_{P' \in \mathcal{U}_{g}}$ % \hfill $\triangleright$ Sec.~\ref{sec: score_function}
    \STATE \textbf{Update}: $\mathcal{U} \leftarrow \{ \mathcal{U}, \mathcal{U}_{g} \}$ and $\mathcal{S} \leftarrow \{\mathcal{S}, \mathcal{S}_{g} \}$, retaining the top-$k$ of candidate prompts with high scores % \hfill $\triangleright$ Sec. \ref{sec: score_function}
  % \ENDFOR 
  \STATE \textbf{Evolution-based Generate}: $\mathcal{U}_e \leftarrow \texttt{EVO} (\mathcal{U}, B)$  % \hfill $\triangleright$ Evolution-based
  \STATE \textbf{Evaluate}: $\mathcal{S}_{e} \leftarrow \{ F(\mathcal{D}, P') \}_{P' \in \mathcal{U}_{e}}$ % \hfill $\triangleright$ Sec.~\ref{sec: score_function}
  \STATE \textbf{Update}: $\mathcal{U} \leftarrow \{ \mathcal{U}, \mathcal{U}_{e} \}$ and $\mathcal{S} \leftarrow \{\mathcal{S}, \mathcal{S}_{e} \}$, retaining the top-$k$ of candidate prompts with high scores
% \ENDWHILE
\ENDFOR
\RETURN the latest candidate prompt set $\mathcal{U}$
\end{algorithmic}
\end{algorithm}
% \vspace{-15pt}

% ---------------------------------------------------- % 
%                Template Optimization
% ---------------------------------------------------- %
\subsection{Automatic Template Optimization}
\label{sec: template_optim}
% **************************** % 
%           总述的话
% **************************** %
To mitigate issues of semantic ambiguity caused by class names, we first iteratively optimize the template to provide better task-specific contextual information. 

% An shown in Lines 1-4 of Alg.~\ref{alg: ProAPO}, it contains template initialization, template library building, and iterative optimization process.

% **************************** % 
%        Template 初始化
% **************************** %
% \noindent 
\textbf{Template initialization} offers a candidate prompt $P_0$ as a starting point in the language search space (Line 1 of Alg.~\ref{alg: ProAPO}). Similar to PN~\cite{P_N}, we use ``\texttt{a photo of a \{class\}}.'' filling with class names in the dataset as $P_0$.


% **************************** % 
%     构建 Template Library
% **************************** %
% \noindent 
\textbf{Building template library} aims to provide a set of templates (Line 2 of Alg.~\ref{alg: ProAPO}) for subsequent prompt generation. We denote template library as $B_t = \{d_1, \cdots, d_n\}$, where $d$ is a single template. Similar to PN~\cite{P_N}, we can instruct LLMs with a one-time query to generate a set of templates as the library. Pre-defined templates, \textit{e.g.}, Template-80 provided in CLIP~\cite{CLIP}, can also be used. Inspired by description-based methods~\cite{WaffleCLIP, VDT_2023_ICCV}, we also supplement templates with dataset domain information generated by LLMs, such as ``\texttt{flower}'' for FLO and ``\texttt{bird}'' for CUB. 

% (only query once instead of all iterations to save costs)

% and $n$ is the number of templates
% Notably, we only query LLMs once instead of all iterations to save generation costs. 


% **************************** % 
%        迭代优化的介绍
% **************************** %
% \noindent 
\textbf{Iterative optimization}.
Automatic prompt optimization (APO) algorithm is introduced to refine template set $\mathcal{U}_t$ by an evolution-based process (Line 3 of Alg.~\ref{alg: ProAPO}). As summarized in Alg.~\ref{alg: APO}, each iteration of APO contains the process of: 
(1) \textbf{Generate new candidate prompts} $\mathcal{U}_g$ and $\mathcal{U}_e$ by several edit-based (Lines 4-6) and evolution-based (Line 9) operations based on the set $\mathcal{U}$ and library $B$. 
(2) \textbf{Evaluate each new candidate prompt} (Lines 7 and 10) by a score function. We regard this score as an implied ``gradient''. 
(3) \textbf{Update the prompt set} $\mathcal{U}$ based on score (Lines 8 and 11). This process retains the top-$k$ of prompts with high scores to explore the search space around the current best candidates. Finally, we return the latest candidate set $\mathcal{U}$.

% select the candidate prompt with the highest score as the final prompt.

% ---------------------------------------------------- % 
%                      GEN 算法
% ---------------------------------------------------- %
\begin{algorithm}[t]
\caption{Edit-based prompt generation algorithm - Line 5 of Alg.~\ref{alg: APO}, $\texttt{GEN}(P, B)$.}
\label{alg: prompt_generate}
\begin{algorithmic}[1]
\REQUIRE  $P \leftarrow \{ \hat{d}_1, \cdots, \hat{d}_i \}$: a candidate prompt, $B \leftarrow \{ d_1, \cdots, d_j \}$: template or description library
\STATE $ \mathcal{U}_{g} \leftarrow \emptyset $
\FOR{$m = 1$ to $M$} 
    \STATE $d_{add} \leftarrow \texttt{Select}(B)$ 
    \STATE $P_{add} \leftarrow P \cup \{ d_{add} \} $ \hfill $\triangleright$ Add
    \STATE $d_{del} \leftarrow \texttt{Select}(P)$ 
    \STATE $P_{del} \leftarrow P \setminus \{ d_{del} \} $ \hfill $\triangleright$ Delete
    \STATE $d_{in} \leftarrow \texttt{Select} (B)$
    \STATE $d_{out} \leftarrow \texttt{Select} (P)$ 
    \STATE $P_{rep} \leftarrow (P \cup  \{ d_{in} \} ) \setminus \{ d_{out} \} $ \hfill $\triangleright$ Replace
    \STATE $\mathcal{U}_g \leftarrow \mathcal{U}_g \cup \{ P_{add}, P_{del}, P_{rep} \}$ 
\ENDFOR
\RETURN the generated candidate prompt set $\mathcal{U}_g$
\end{algorithmic}
\end{algorithm}


% ---------------------------------------------------- % 
%                Prompt Generation 算法
% ---------------------------------------------------- %
\subsection{Prompt Generation by Several Operators}
\label{sec: prompt_generate}

% **************************** % 
%           总述的话
% **************************** %
Due to the explosion of class-specific prompts, it is costly and time-intensive to generate new prompts exclusively with LLMs like previous methods~\cite{P_N, iCM}. To this end, we introduce edit-based and evolution-based operators to generate diverse candidate prompts from the library. 
% Moreover, prompt ensembling is introduced to offline generate prompts 

% **************************** % 
%    Edit-based Generation
% **************************** %
% \noindent 
\textbf{Edit-based generation} is introduced to create a set of new candidate prompts by several simple arithmetic operators. As shown in Alg.~\ref{alg: prompt_generate}, we iteratively operate a candidate prompt $P$ with the library $B$, where $\hat{d}$ in $P$ and $d$ in $B$ denotes a single template or description. The $\texttt{Select}(\cdot)$ operator samples an element from a given prompt set. Three operations are then applied to $P$ in each iteration: (1) \textbf{Add} a new element $d_{add}$ to $P$. (2) \textbf{Remove} an existing element $d_{del}$ from $P$. (3) \textbf{Replace} an element $d_{out}$ in $P$ with a new element $d_{in}$ in $B$. These new candidates are ensembled around the current high-score candidate $P$, which makes them more likely to succeed. Moreover, selecting elements from the library ensures differences between generated candidates. After $M$-times steps, we return the latest set $\mathcal{U}_g$.


% **************************** % 
%  Evolution-based Generation
% **************************** %
% \noindent 
\textbf{Evolution-based generation} is introduced to improve search efficiency over random steps, as shown in Alg.~\ref{alg: prompt_evolution}. Inspired by widely used Generic Algorithm~\cite{GA_1975, GA_1992, GA_1998}, we introduce crossover and mutation operators to enhance candidate generation. \textbf{Crossover} operator aims to find the optimal direction quickly by combining high-scoring candidate prompts. We randomly take the concatenation of two candidates $P_{c1}$ and $P_{c2}$ sampled from the current optimal set $\mathcal{U}$, yielding a new candidate $P_c$. \textbf{Mutation} operator aims to prevent convergence to local optima by introducing variations. We randomly add new elements selected from library $B$ into the candidate $P_c$, yielding mutation candidate $P_m$. After $N$-times steps, we return the generated set $\mathcal{U}_e$.

% (Lines 3-5)
% (Lines 6-7)

% \textbf{Evolution-based generation} is introduced to optimize more efficiently than random search steps
% Notably, edit-based operators are also considered the mutation process, except that here, the mutation operator is performed on the prompt candidate with more dominant fused (\textit{i.e.},  crossover candidate $p_c$).

% Empirically, the efficiency of evolution-based operators is shown in Section X.

% ---------------------------------------------------- % 
%                      EVO 算法
% ---------------------------------------------------- %
\begin{algorithm}[t]
\caption{Evolution-based generation algorithm - Line 9 of Alg.~\ref{alg: APO}, $\texttt{EVO}(\mathcal{U}, B)$.}
\label{alg: prompt_evolution}
\begin{algorithmic}[1]
\REQUIRE $\mathcal{U} \leftarrow \{ P_1, \cdots, P_n \}$: candidate prompt set, $B \leftarrow \{ d_1, \cdots, d_j \}$: template or description library
\STATE $\mathcal{U}_e \leftarrow \emptyset $
\FOR{$n = 1$ to $N$} 
\STATE $P_{c1} \leftarrow \texttt{Select}(\mathcal{U})$
\STATE $P_{c2} \leftarrow \texttt{Select}(\mathcal{U})$
\STATE $P_{c} \leftarrow P_{c1} \cup P_{c2}$ \hfill $\triangleright$ Crossover
\STATE $P_{all} \leftarrow B \cup P_c$
\STATE $P_m \leftarrow \textsc{RandomSelect}(P_{all}, \text{len}(P_c) )$\hfill $\triangleright$ Mutation
\STATE $\mathcal{U}_e \leftarrow \mathcal{U}_e \cup \{ P_c, P_m \}$
\ENDFOR
\RETURN the generated candidate prompt set $\mathcal{U}_e$
\end{algorithmic}
\end{algorithm}

% ---------------------------------------------------- % 
%                  缓解过拟合的得分函数
% ---------------------------------------------------- %
\subsection{Score Functions}
\label{sec: score_function}


% **************************** % 
%           总述的话
% **************************** %
To measure candidate prompts, we introduce a fitness score to approximately obtain the ``gradient'' used for optimization. It contains the accuracy and an entropy constraint.

% **************************** % 
%        Accuracy 的计算
% **************************** %
% \noindent
\textbf{Accuracy.}
Given an image $x$, we obtain a prediction $\text{pred}(x)$ that yields the highest cosine similarity:
\setlength{\abovedisplayskip}{3pt}
\setlength{\belowdisplayskip}{3pt}
\begin{align}
    s(x, c) &= \frac{1}{|D(c)|} \sum_{d \in D(c)} \text{cos}(I(x), T(d)). \\
    \text{pred}(x) &= \argmax_{c \in C} s(x, c),
\end{align}
where $D(c) \in P$ is a set with all prompts describing the category $c$ in candidate prompt $P$, and $C$ is the entire category in the dataset. $I$ and $T$ are image encoder and text encoder, respectively. The accuracy is formulated as follows:
\begin{equation}
    \text{Acc} = \mathbb{E}_{(x, y) \in \mathcal{D}} [\mathbb{I}(\text{pred}(x) = y)], 
\end{equation}
where $\mathcal{D}$ is the training set and $\mathbb{I}(\cdot)$ is an indicator function.

% **************************** % 
%        Entropy 约束的计算
% **************************** %
% \noindent
\textbf{Entropy constrain.} Previous methods~\cite{P_N, iCM} only use accuracy as the evaluation metric. However, the overfitting problem appears as shown in~\cref{fig: Problem}(c). To this end, we include a simple entropy constrain, which penalizes the model to predict a higher probabilistic score in the true label $y$:
\begin{equation}
    H = \mathbb{E}_{(x, y) \in \mathcal{D}}[-\log(s(x, y))].
\end{equation}
The final score is formulated as follows: 
\begin{equation}
    F(\mathcal{D}, P) = \text{Acc} + \alpha H.
    \label{eq: score_function}
\end{equation}
where $\alpha$ is a scalar to balance them. In~\cref{sec: ablation_study}, we empirically show that this score effectively reduces overfitting.


% \begin{equation}
%     s(x, c) = \frac{1}{|D(c)|} \sum_{d \in D(c)} \text{cos}(I(x), T(d)).
% \end{equation}
% \begin{equation}
%     \text{pred}(x) = \arg \max_{c \in C} s(x, c),
% \end{equation}

% As shown in Figure X, we empirically show that the simple score function better evaluate the performances of candidate prompts than accuracy metric with minimal overfitting.


% ---------------------------------------------------- % 
%                  采样策略的介绍
% ---------------------------------------------------- %
\subsection{Sampling Strategy for Initialization}
\label{sec: sample_strategy}
After exploring the best template, we continue to optimize the class-specific descriptions. To save iteration costs, we introduce a prompt sampling strategy to find a better start point and a grouping sampling strategy to select some salient categories instead of all for iterative optimization.

% Since the number of labels in a dataset might be huge, \textit{e.g.}, ImageNet~\cite{Imagenet}, plus the fact that there are also many corresponding descriptions for each category, estimating the candidate prompts by considering all the categories simultaneous is expensive and time-consuming.


% **************************** % 
%      Prompt Sampling 策略
% **************************** %
% \noindent 
\textbf{Prompt sampling strategy} aims to initialize the class-specific candidate prompt $\hat{P}_0$ with the optimized template $P_t^*$ and high-score descriptions (Line 5 of Alg.~\ref{alg: ProAPO}). Similar to description-based methods~\cite{DCLIP, CuPL}, we instruct LLM to generate a set of visual descriptions for each class. Besides, we replace the class name with its synonyms generated by LLMs to increase the number of descriptions. To obtain a better initial point, we randomly sample descriptions of each category to obtain multiple candidate prompts and select the one with the highest score as $\hat{P}_0$. It ensures that subsequent optimization is around candidates with relatively high scores. More details are shown in~\cref{sec_supp: prompt_sampling}.

% previous description-based methods

% aims to initialize the candidate prompt with high-quality class-specific prompts by multiple random sample initializations (Line 5 of Algorithm~\ref{alg: ProAPO}).

% Each prompt is formated with ``\{template\} \{class name\}. \{descriptions\}.'', such as ``A photo of a flower: oenothera speciosa. It has pink petals.''.

% **************************** % 
%      Group Sampling 策略
% **************************** %
% \noindent 
\textbf{Group sampling strategy} aims to explore several salient categories into groups for optimization (Line 6 of Alg.~\ref{alg: ProAPO}). We consider two ways to sample categories. First, we select the groups with the lowest top-$n_{wst}$ accuracy and its misclassified categories. Moreover, we also choose salient groups by the category with the top-$n_{sln}$ result gains after adding descriptions and its misclassified categories. In the end, We use $S = n_{wst} + n_{sln}$ groups for optimization. More details are shown in~\cref{sec_supp: group_sampling}. In~\cref{sec: ablation_study}, experiments show that optimizing these selected categories can effectively improve performance and save costs.

% $n_{wst}$
% $n_{sln}$ 

% to save costs 
% Moreover, we also add descriptions for each category to the original CLIP, choosing $n_{sln}$ salient groups by the category with the enormous gains and corresponding ambiguous categories (obtained by the K-means algorithm) for optimization.

% (The number of optimized categories is much smaller than the total number of.)

% As shown in Figure X, we analyze the reason for performance improvement caused by generated descriptions. We argue that categories with poor performance in the original CLIP are those with significant gains after adding visual descriptions.
% Inspired by this, 


% **************************** % 
%   Description 优化的特殊处理
% **************************** %
% \noindent 
\textbf{Building Library and Iterative Optimization for Descriptions.} In Lines 7-10 of Alg.~\ref{alg: ProAPO}, we iteratively optimize the class-specific description in selected groups. Similar to template optimization, we first build the description library, which contains visual descriptions for categories in the specific group. Then, we apply \texttt{APO} algorithm to refine descriptions automatically. After several iterations, we use the candidate $P^*$ with the highest score as the final prompt.
