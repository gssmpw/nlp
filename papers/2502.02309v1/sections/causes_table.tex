
\begin{table*}[!h]
    \renewcommand{\arraystretch}{1.1}
\centering
{
\scriptsize
\begin{tabular}{l l p{1.7cm} p {1.7cm}  p{8.25cm} }
%
\toprule 
\textbf{Reference}            & \textbf{Year}  & \textbf{Dataset} & \textbf{Attribute} & \textbf{Summary}    \\ 
\midrule
Krishnapriya \etal \cite{krishnapriya2020issues} & 2020  & MORPH & ET, ST & Demonstrated demographic disparities in FMR and FNMR, with African-American cohorts having higher FMR and Caucasian cohorts higher FNMR. \\
NIST FRVT \cite{frvt3}     & 2019   & Private & ET, GN, AG, + & Reported increased false positives in women, children, and elderly, and higher false negatives in underrepresented groups. \\
Klare \etal \cite{klare2012face} & 2012   & PCSO & ET, GN, AG & Advocated for balanced datasets and exclusive cohorts to improve face recognition performance. \\
Cavazos \etal \cite{cavazos2020accuracy} & 2020 &  GBU & ET & Highlighted how dataset complexity and thresholds affect racial bias, requiring higher thresholds for East-Asian faces. \\
Gwilliam \etal \cite{gwilliam2021rethinking} & 2021  & BUPT, RFW & ET & Showed that skewed distributions favoring African faces can mitigate racial bias better than balanced datasets. \\
Wu and Bowyer \cite{wu2023should} & 2023  & DemogPairs, RFW, BFW, & ET, GN, + & Emphasized that balancing identities and images alone is insufficient, stressing brightness and head pose considerations. \\
Wang \etal \cite{wang2019racial} & 2019  & RFW & ET & Observed that race-balanced datasets do not fully eliminate bias, suggesting inherent challenges in recognizing certain ethnicities. \\
Kolla and Savadamuthu \cite{kolla2023impact} & 2023 & RFW & ET  & Highlighted the influence of facial quality and racial feature gradations on fairness in face recognition models. \\
Muthukumar \etal \cite{muthukumar2018understanding} & 2018 & PPB & GN, ST  & Identified structural facial features as primary contributors to intersectional bias for dark-skinned females. \\
Cook \etal \cite{cook2019demographic} & 2019 & Private & ET, GN, AG, +  & Analyzed image acquisition conditions, noting the impact of skin reflectance and environmental factors on darker-skinned individuals. \\
%
\midrule
%
Muthukumar \etal \cite{muthukumar2018understanding} & 2018 &  PPB & GN, ST & Identified structural facial features and skin tone as key factors for dark-skinned females' underperformance. \\
Buolamwini and Gebru \cite{buolamwini18a} & 2018 &  IJB-A, Adience & GN, ST & Demonstrated lowest classifier performance for darker-skinned females using the Fitzpatrick system.             \\
Krishnapriya \etal \cite{krishnapriya2020issues}    & 2020 & MORPH & ET, ST & Examined FMR and FNMR across skin tones but found no direct causation between darker skin tone and higher errors.\\
Cook \etal \cite{cook2019demographic}  & 2019 & Private & ET, GN, AG, +  & Highlighted skin reflectance as a major predictor of FR disparities and emphasized acquisition methods' role.   \\
Lu \etal \cite{lu2019experimental}  & 2019 & IJB-B, IJB-C & AG, GN, ST, + & Quantified performance variations across skin tone groups, noting challenges with darker skin tones.            \\
%
\midrule
%
Phillips \etal \cite{phillips2011other} & 2011 &  FRVT & ET & Identified the ``other-race effect," where algorithms performed better on their respective majority racial groups. \\
Klare \etal \cite{klare2012face}       & 2012 & PCSO & ET, GN, AG & Highlighted recognition challenges for female, Black, and younger cohorts, improved with exclusive group training.   \\
Nagpal \etal \cite{nagpal2019deep}     & 2019 &  MORPH, RFW, CACD, + & ET, AG & Showed that deep learning models encode in-group biases, mirroring own-race and own-age human biases. \\    %MORPH, RFW, Adience, MultiPIE, CACD
Wang \etal \cite{wang2019racial}  & 2019 & RFW & ET & Demonstrated racial bias using the RFW dataset, with higher error rates for African faces compared to Caucasians.    \\
Serna \etal \cite{serna2019algorithmic} & 2019 & DiveFace & ET, GN & Highlighted significant performance gaps across demographic groups, calling for fairness-aware algorithm designs.    \\
Albiero \etal \cite{albiero2020analysis} & 2020 & AFD, MORPH, Notre Dame & GN & Found gender-based biases in score distributions, with lower accuracy for women across balanced datasets.            \\
Ricanek \etal \cite{ricanek2015review} & 2015 & ITWCC & AG & Observed challenges in recognizing children's faces due to structural changes with age, affecting algorithm accuracy. \\
%
\midrule
%
Cavazos \etal \cite{cavazos2020accuracy} & 2020 & GBU & ET & Highlighted dataset complexity and decision thresholds' impact on racial bias and accuracy.     \\
MdTF \cite{cook_tbiom,cook2023demographic} & 2023 & Private & ET, GN, AG, + & Found lower skin reflectance correlated with reduced accuracy and higher transaction times.     \\
Wu \etal \cite{wu2023face}   & 2023 & MORPH & ET, GN, + & Demonstrated how brightness inconsistencies increase FMRs and diminish similarity scores.       \\
Krishnapriya \etal \cite{vangara2019characterizing} & 2019 & MORPH & ET &Showed improving image quality reduces performance gaps between African-American and Caucasian cohorts. \\
Albiero \etal \cite{albiero2020analysis} & 2020 & AFD, MORPH, Notre Dame & GN & Linked gender-based disparities to score distributions and identified confounding factors like cosmetics. \\
Lu \etal \cite{lu2019experimental} & 2019 & IJB-B, IJB-C & AG, GN, ST, + & Analyzed multiple covariates; noted lighter skin tones consistently outperformed medium-dark tones. \\
%
\midrule
%
Vera-Rodriguez \etal \cite{vera2019facegenderid} & 2019 & VGGFace2 & GN & Highlighted gender as a covariate, with males consistently outperforming females across demographics. \\
Ricanek \etal \cite{ricanek2015review} & 2015 &  ITWCC & AG & Discussed recognition challenges due to structural changes in children's facial features over time.   \\
Best-Rowden \etal \cite{best2017longitudinal} & 2017 & LEO\_LS, PCSO\_LS & AG, GN & Found that males generally have higher genuine scores, but their performance declines faster with age.\\
Sarridis \etal \cite{sarridis2023towards}      & 2023 & RFW & ET, GN, AG & Reported high mistreatment rates for African females over 60 years, highlighting compounded biases.   \\
El Khiyari \etal \cite{el2016face}    & 2016 & MORPH & ET, GN, AG & Observed lower face verification accuracy in younger individuals, females, and Black racial groups.   \\
FRVT report \cite{frvt3}    & 2021 &  Private & ET, GN, AG, + &  Noted elevated false positives for children and elderly, especially among Asian and American Indian groups.\\
Cook \etal \cite{cook2023demographic} & 2023 & Private & ET, GN, AG, + & Demonstrated that age and skin lightness significantly influence recognition scores, compounded by illumination.\\
%
\bottomrule

\end{tabular}

\caption{Summary of works delving into various causes of demographic
bias in face recognition. As several works have identified multiple causes of bias, we have categorized the works based on their primary focus or inference. For details, readers are encouraged to refer to the source materials. The demographic factors of primary interest are denoted as \textsf{ET}: Ethnicity or race, \textsf{GN}: gender or sex, \textsf{AG}: age; whereas \textsf{+} indicates study of more attributes.
\label{tab:causes}
}
} % scriptsize ends
\end{table*}


%---    

