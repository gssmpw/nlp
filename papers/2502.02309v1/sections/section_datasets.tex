\section{Datasets for Demographic Bias}
\label{sec:datasets}

In evaluating and mitigating demographic bias in FR systems, the selection of
suitable datasets plays an important role. Although numerous FR datasets exist,
those specifically intended for bias and fairness-related tasks must include
demographic labels associated with each subject or identity. The datasets
designed for tasks such as race, gender, ethnicity, or age estimation are
particularly useful when they include demographic labels, as such factors are
critical for assessing fairness. For certain tasks (related to estimation or
classification of attributes), having a single image per subject may suffice, as
training and testing can be conducted separately for each image. However, FR
models, especially state-of-the-art systems, benefit from having multiple images
(variations) of each identity to train more robust feature extractors. The
testing phase (verification or identification) requires multiple images per
identity, where one image serves as the gallery/ template and the others are
used as test or probe samples. Occasionally, the gallery is also composed of
more than one image per subject. 

% dataset dist
\input{sections/table_datasets}

These requirements significantly reduce the availability of datasets suitable
for assessing demographic bias, as most FR datasets do not provide adequate
demographic labels or have highly skewed distributions of subjects across
different demographic groups. In this section, we outline recent and commonly
used publicly available datasets that are relevant for assessing and addressing
demographic bias in FR systems.

%---
\begin{itemize}

\item \textbf{MORPH} \cite{bingham2017morph}:
The MORPH is one of the largest facial image datasets available in several
variants and versions. MORPH-II is the most commonly referred
academic version, comprising more than 55,000 images from more
than 13,000 subjects. Despite its usefulness, it should be noted that the
dataset is highly skewed in terms of gender and ethnicity, with
a significant over-representation of male subjects (more than
46,000 images) and a limited number of female subjects
(approximately 8,500 images). Race labels are also provided,
with categories including Black, White, Asian, Hispanic, and
others. However, due to the demographic imbalance, this dataset
may introduce bias in FR tasks focused on fairness and equity.

\item \textbf{AFD (Asian Faces Dataset - Curated)}\cite{kai_curation_method}: 
The Asian Faces Dataset (AFD) was developed using images scraped from the web,
with a focus on frontal face images~\cite{xiong2018asian}. The curated version,
provided by Zhang \etal~\cite{kai_curation_method} includes over
42,000 images of 911 males and 49,000 images of
967 females. A gender classifier was used to filter out
mislabelled images, and duplicate or near-duplicate images were
removed. This curated dataset is useful for studying gender
and ethnic bias in FR systems, specifically for models focused
on the Asian demographic.  

\item \textbf{VGGFace2} \cite{cao2018vggface2}:
The VGGFace2 is a large-scale FR dataset containing over 3.31 million images of
9,131 subjects. This dataset was annotated for gender (Male,
Female) and ethnicity (Asian, Black, Indian, White) labels by
Idiap Research Institute\footnote{\href{https://gitlab.idiap.ch/bob/bob.bio.face/-
/blob/ master/src/bob/bio/face/database/vgg2.py}{Annotations for
VGGFace2 Dataset}} making it useful for bias related tasks. The
dataset has been noted to have a bias towards White and male
subjects, which should be considered when using it for fairness
and bias studies. The access to original download location has
been removed by its creators as of 2024.

        
\item \textbf{DemogPairs} \cite{hupont2019demogpairs}:
DemogPairs is a validation set containing 10.8K images, divided into six
demographic folds: Asian females, Asian males, Black females,
Black males, White females, and White males. The dataset was
specifically designed to evaluate the demographic bias in FR
models, offering 58.3 million evaluation pairs, including
cross-demographic, cross-gender, and cross-ethnicity pairs.
The DemogPairs dataset was constructed with rigorous demographic annotation
and is a useful resource for testing the generalization of FR
systems across diverse demographic groups.

\item \textbf{Racial Faces in-the-Wild (RFW)} \cite{wang2019racial}:
RFW is a benchmarking dataset designed to study racial bias in FR
systems. It consists of four subsets (African, Asian, Caucasian, and Indian),
each containing about 3,000 individuals and 6,000
image pairs (these pairs have been defined by its creators). The dataset is
specifically used for face verification tasks and includes balanced pairs of
genuine (mated) and imposter (non-mated) images. The RFW dataset has been widely
adopted by the research community to evaluate and compare the
performance of FR algorithms across different racial groups.

\item \textbf{BUPT-BalancedFace} \cite{wang2020mitigating}:
The BUPT-BalancedFace dataset was constructed to address demographic bias by
ensuring race balance across the dataset. It contains approximately 1.3 million
images from 28,000 celebrities, with a balanced distribution of 7,000 identities
per race. The dataset was selected from MS-Celeb-1M~\cite{guo2016ms} through
the FreeBase and Face++ APIs, although it has been noted that the labels may
contain noise. Due to its size and balanced nature, the BUPT-BalancedFace dataset has become
a popular resource for training and fine-tuning FR models while mitigating
race-related biases.

%-------------------------------------
\begin{figure*}[h]
\centering
\begin{subfigure}{0.98\columnwidth}
\includegraphics[width=\columnwidth]{images/dataset_dist_race}
\caption{}
\label{fig:race11}
\end{subfigure}
%
\hfill
%
\begin{subfigure}{0.98\columnwidth}
\includegraphics[width=\columnwidth]{images/dataset_dist_gender}
\caption{}
\label{fig:gender11}
\end{subfigure}
%    
\caption{Distribution of images of commonly used FR datasets considering
(a) \textit{race} and (b) \textit{gender} as demographic factors. The details of distribution have
been used from original sources (wherever available) or from other
works contributing to this information; while the naming convention has
been altered for unified representation aligning to the convention used
by most datasets.}
\label{fig:dataset_dist}
\end{figure*}
%-------------------------------------
        

\item \textbf{DiveFace} \cite{morales2020sensitivenets}:
DiveFace is a dataset generated from the Megaface dataset (now
decommissioned)~\cite{kemelmacher2016megaface}, containing over 120,000 images
from 24,000 identities. The dataset includes two gender and three ethnicity
classes, allowing for detailed demographic analysis. Annotations were made using
a semi-automatic process, followed by manual inspection. This dataset is useful for
studying the impact of gender and ethnicity in FR tasks, although it may exhibit
bias in some groups. It should also be noted that in DiveFace dataset, the
subjects of Indian and African ethnicities have been grouped together-- which
can make it difficult to use it in conjunction with other datasets that
typically do not follow such grouping.

\item \textbf{Multiple Encounter Dataset (MEDS-II)} \cite{founds2011nist}:
MEDS-II is an extension of the MEDS-I dataset and was created to assist with the
NIST Multiple Biometric Evaluation. The dataset includes over 1,300 images of
518 subjects, with many subjects having only a single image, limiting its
usefulness for verification tasks. The MEDS-II is dominated by male subjects of
White and Black ethnicities. Despite its limitations in demographic diversity,
it remains a useful resource for testing FR systems in real-world scenarios,
especially where multiple encounters of a subject are available.

        
\item \textbf{BFW (Balanced Faces in the Wild)} \cite{robinson2023balancing} \cite{robinson2020face}:
The BFW dataset was designed to provide a more balanced evaluation of FR systems
by creating subgroups that are evenly split across gender and ethnicity. The
dataset is compiled from VGGFace2 \cite{cao2018vggface2} and offers a refined
approach to subgroup analysis with less overlap between training and testing
data. The corresponding demographic labels were generated using
ethnicity~\cite{fu2014learning} and gender \cite{levi2015age} classifiers,
followed by manual validation.  Additionally, the BFW dataset is also balanced
with respect to the number of images, subjects, and the (ratio of) images per
subject; making it particularly useful for evaluating the demographic fairness
of FR models, offering a more balanced alternative to other datasets. 


\item \textbf{CASIA-Face-Africa}~\cite{muhammad2021casia}:
The CASIA-Face-Africa dataset is the first large-scale face dataset of African
subjects-- comprising 38,546 images from 1,183 individuals, captured under
varying illumination conditions using multi-spectral cameras. It includes
detailed demographic attributes and facial expressions along with manually
annotated with facial key points. The dataset exhibits a well-distributed age
representation, with a significant portion belonging to the subjects upto 40
years, aligning with the majority workforce demographics. Additionally, it
maintains an almost balanced gender ratio (48\% male, 52\% female), making it
useful for geneder-based analysis as well. In terms of ethnic variations, the
dataset includes multiple African ethnic groups, with a notable dominance of the
Hausa ethnic group. 

\item \textbf{CausalFace}~\cite{liang2023benchmarking}:
It is a large-scale dataset of synthetically generated faces comprising 48,000
synthetic face image pairs generated from 10,200 unique identities, along with
555,000 human annotations covering individual attributes and pairwise identity
comparisons. The dataset is constructed using EG3D~\cite{chan2022efficient}, a
state-of-the-art GAN framework that allows explicit control over geometry and
pose. In terms of demographic attributes, the CausalFace dataset includes six
demographic groups created by combining three ethnicities (White, Black, and
East Asian) and two genders (male  and female). Using a GAN-based generator,
face images were systematically modified across unprotected attributes such as
pose, age, expression, and lighting while maintaining identity consistency. The
dataset images were selected on the basis of perceived matching scores provided
by human annotators. 

\end{itemize}

The datasets are summarized in Table~\ref{tab:datasets}, while
Fig.~\ref{fig:dataset_dist} illustrates an overview of the demographic
distribution, with race and gender as demographic variables, for the datasets
reviewed in this section.


%-----

