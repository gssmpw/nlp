\section{Conclusion}
\label{sec:conc}

In this work, we have systematically explored the issue of demographic bias in
FR through different yet interrelated sections: causes, datasets, assessment
metrics, and mitigation strategies. The section on causes delves into the
underlying factors, categorizing them into aspects such as imbalances in
training datasets, variability of skin-tones, algorithmic sensitivities, image
quality and covariates, and combined demographic factors. The discussion on
datasets presents an overview of existing resources and their demographic
distributions, Furthermore, we reviewed state-of-the-art metrics for evaluating
bias, ranging from traditional statistical measures to advanced fairness
indicators, highlighting differences in demographic performance and outcomes
across demographic groups. The mitigation section highlights diverse
approaches, including preprocessing, in-processing, and post-processing
techniques, offering a comprehensive overview of existing work in this area.

In addition to summarizing existing research, we identified emerging challenges
including the fairness implications of lightweight models, the role of synthetic
datasets, the complexities of remote identity verification systems, and
intersectional bias. These challenges reflect the evolving nature of FR
technologies and underscore the need for innovative strategies to ensure
equitable and reliable outcomes in real-world applications.

%---
   
