@article{HaCohen2024LTXVideo,
  title={LTX-Video: Realtime Video Latent Diffusion},
  author={HaCohen, Yoav and Chiprut, Nisan and Brazowski, Benny and Shalem, Daniel and Moshe, Dudu and Richardson, Eitan and Levin, Eran and Shiran, Guy and Zabari, Nir and Gordon, Ori and Panet, Poriya and Weissbuch, Sapir and Kulikov, Victor and Bitterman, Yaki and Melumian, Zeev and Bibi, Ofir},
  journal={arXiv preprint arXiv:2501.00103},
  year={2024}
}

@article{chen2023control,
  title={Control-a-video: Controllable text-to-video generation with diffusion models},
  author={Chen, Weifeng and Ji, Yatai and Wu, Jie and Wu, Hefeng and Xie, Pan and Li, Jiashi and Xia, Xin and Xiao, Xuefeng and Lin, Liang},
  journal={arXiv preprint arXiv:2305.13840
        
        
        
        
        
        
        
        },
  year={2023}
}

@article{chen2023videocrafter1,
  title={Videocrafter1: Open diffusion models for high-quality video generation},
  author={Chen, Haoxin and Xia, Menghan and He, Yingqing and Zhang, Yong and Cun, Xiaodong and Yang, Shaoshu and Xing, Jinbo and Liu, Yaofang and Chen, Qifeng and Wang, Xintao and others},
  journal={arXiv preprint arXiv:2310.19512
        
        
        
        
        
        
        
        },
  year={2023}
}

@article{hong2022cogvideo,
  title={CogVideo: Large-scale Pretraining for Text-to-Video Generation via Transformers},
  author={Hong, Wenyi and Ding, Ming and Zheng, Wendi and Liu, Xinghan and Tang, Jie},
  journal={arXiv preprint arXiv:2205.15868
        
        
        
        
        
        
        
        
        
        },
  year={2022}
}

@inproceedings{hong2023large,
  title={Large language models are frame-level directors for zero-shot text-to-video generation},
  author={Hong, Susung and Seo, Junyoung and Shin, Heeseong and Hong, Sunghwan and Kim, Seungryong}

@article{kondratyuk2023videopoet,
  title={Videopoet: A large language model for zero-shot video generation},
  author={Kondratyuk, Dan and Yu, Lijun and Gu, Xiuye and Lezama, Jos{\'e} and Huang, Jonathan and Schindler, Grant and Hornung, Rachel and Birodkar, Vighnesh and Yan, Jimmy and Chiu, Ming-Chang and others},
  journal={arXiv preprint arXiv:2312.14125
        
        
        
        
        
        
        
        
        
        },
  year={2023}
}

@article{kong2024hunyuanvideo,
  title={Hunyuanvideo: A systematic framework for large video generative models},
  author={Kong, Weijie and Tian, Qi and Zhang, Zijian and Min, Rox and Dai, Zuozhuo and Zhou, Jin and Xiong, Jiangfeng and Li, Xin and Wu, Bo and Zhang, Jianwei and others},
  journal={arXiv preprint arXiv:2412.03603
        
        
        
        
        
        
        
        
        
        },
  year={2024}
}

@article{maaz2023video,
  title={Video-chatgpt: Towards detailed video understanding via large vision and language models},
  author={Maaz, Muhammad and Rasheed, Hanoona and Khan, Salman and Khan, Fahad Shahbaz},
  journal={arXiv preprint arXiv:2306.05424
        
        
        
        
        
        
        
        
        
        },
  year={2023}
}

@article{singer2022make,
  title={Make-a-video: Text-to-video generation without text-video data},
  author={Singer, Uriel and Polyak, Adam and Hayes, Thomas and Yin, Xi and An, Jie and Zhang, Songyang and Hu, Qiyuan and Yang, Harry and Ashual, Oron and Gafni, Oran and others},
  journal={arXiv preprint arXiv:2209.14792
        
        
        
        
        
        
        
        
        
        
        
        },
  year={2022}
}

@inproceedings{wang2024gpt4video,
  title={Gpt4video: A unified multimodal large language model for lnstruction-followed understanding and safety-aware generation},
  author={Wang, Zhanyu and Wang, Longyue and Zhao, Zhen and Wu, Minghao and Lyu, Chenyang and Li, Huayang and Cai, Deng and Zhou, Luping and Shi, Shuming and Tu, Zhaopeng},
  booktitle={Proceedings of the 32nd ACM International Conference on Multimedia},
  pages={3907--3916},
  year={2024}
}

@article{yang2024cogvideox,
  title={CogVideoX: Text-to-Video Diffusion Models with An Expert Transformer},
  author={Yang, Zhuoyi and Teng, Jiayan and Zheng, Wendi and Ding, Ming and Huang, Shiyu and Xu, Jiazheng and Yang, Yuanming and Hong, Wenyi and Zhang, Xiaohan and Feng, Guanyu and others},
  journal={arXiv preprint arXiv:2408.06072
        
        
        
        
        
        
        
        
        
        
        
        },
  year={2024}
}

@inproceedings{zhao2023learning,
  title={Learning video representations from large language models},
  author={Zhao, Yue and Misra, Ishan and Kr{\"a}henb{\"u}hl, Philipp and Girdhar, Rohit},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={6586--6597},
  year={2023}
}

