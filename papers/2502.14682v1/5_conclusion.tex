\section{Conclusion}

In this paper, we analyze and identify two important gaps between questions and SQL queries: the structural mapping gap and the lexical mapping gap. 
% We proposed a multi-step approach, \model, which emphasizes and simplifies database schema information to achieve superior SQL generation capabilities. 
We propose \model, an efficient SQL generation pipeline based on LLMs, which alleviates two gaps through Abstract Query Pattern and Contextual Schema Markup. 
Our method achieves leading execution accuracy on the Spider and BIRD datasets. 
% Our findings highlight the importance of training corpora and model scaling, as well as the necessity of optimizing token efficiency in prompting engineering.
Our findings highlight the importance of training corpora. 
We hope that these insights will provide valuable guidance for further research and practical applications in the Text-to-SQL field, and will help to advance its development.

\section{Limitations}
In our work, we do not decompose test questions into sub-questions. When test questions are overly complex, such as those with multiple nested sub-questions, generating the correct SQL becomes more challenging. Additionally, although the training sets of BIRD and Spider are significantly larger than the test sets, this does not guarantee that the training set's AQP can cover all the AQP of the test set questions. If the training set lacks data that matches the AQP of the current test question, performance is adversely affected.