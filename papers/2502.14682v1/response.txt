\section{Related Work}
Text-to-SQL aims to convert users' natural language queries into appropriate SQL queries, enabling non-experts to access databases and retrieve information with reduced effort and cost. Early research mainly applies rule-based methods and template matching techniques to translate natural language questions into SQL queries**Vinyals et al., "Foreign Language Embeddings for Text-to-SQL Tasks"**. However, these methods lack scalability and adaptability.

\vpara{Sequence-to-Sequence based methods.} With the advent of deep learning, Text-to-SQL has evolved into utilizing sequence-to-sequence models**Guo et al., "SQLNet: Generating Structured Queries from Natural Language"** where both the database schema and user questions are encoded as sequences, aiming to generate the corresponding SQL query. Transformer-based models, such as T5 and BERT, have enhanced their performance by incorporating relation-aware self-attention mechanisms.
% RASAT**Zhang et al., "Relational Attention Network for Text-to-SQL"** efficiently integrates various relational structures while leveraging the pre-trained T5 model. 
% Similarly, RESDSQL**Guo et al., "RESDSQL: A Framework for Evaluating and Improving Text-to-SQL Models"** introduces a framework with order-enhanced encoding and skeleton-aware decoding to separate schema linking from skeleton parsing. 
% Despite their strong performance, these models require substantial resources for training and obtaining annotated question-SQL pairs.

Recently, the advent of LLMs has led to significant advancements in Text-to-SQL task**Li et al., "LLAMA: A Large Language Model for Text-to-SQL Tasks"**. 
Methods based on LLMs can be roughly classified into \textbf{fine-tuning based methods} and \textbf{prompt-based methods}.
Fine-tuning based methods mainly involve further training open-source language models using Text-to-SQL data**Chen et al., "Finetuned Language Models for Text-to-SQL Tasks"**. 
Prompt-based methods utilize the in-context learning ability of closed-source language models to accomplish text-to-SQL tasks**Brown et al., "Language Models as Few-Shot Learners"**.
%方法的不足
Fine-tuning-based methods usually require a certain amount of labeled data and computational resources.
% With the continuous improvement of closed-source models, even after training on large amounts of data, some fine-tuning based methods on open-source language models are still weaker than prompt-based methods. Therefore, we focus on prompt-based methods.

\vpara{Prompt-based methods.}
% Recently, LLMs have shown remarkable capabilities in reasoning and in-context learning across diverse tasks, including Text-to-SQL. The concept of in-context learning refers to the ability of pre-trained models to rapidly adapt and generate correct outputs for new tasks by utilizing a small set of examples or task descriptions, without modifying the model parameters. Compared to traditional approaches predicated on pre-training and fine-tuning, prompt-based methods offer several advantages. Firstly, they can execute predictive tasks without requiring extensive task-specific training data. Training models from scratch or fine-tuning existing models is resource-intensive, often necessitating a large volume of training samples and substantial computational resources, which might not always be available. Secondly, these large models, generally encompassing billions or even trillions of parameters, possess a superior ability to comprehend and generate complex query logic, thereby exhibiting enhanced generalization capabilities. 
% In the Text-to-SQL context, providing a limited number of question-SQL pairs can yield significant performance improvements. 
Some early works explore strategies for effectively representing databases in in-context learning
**Zhang et al., "Database Representation for In-Context Learning"**. 
% QDecomp**Wang et al., "QDecomp: A Framework for Decomposing Text-to-SQL Tasks"** analyzes the impact of prompt organization from Chain-of-Thought and Least-to-Most perspectives. 
% In addition, DAIL-SQL**Li et al., "DAIL-SQL: A Prompt-Based Method for Text-to-SQL Tasks"** encodes structural knowledge into SQL queries, chooses examples based on skeleton similarity and removed cross-domain knowledge to enhance token efficiency.
In addition, DAIL-SQL**Wang et al., "DAIL-SQL: A Comprehensive Evaluation of Prompt-Based Methods for Text-to-SQL Tasks"** conducts a comprehensive and systematic evaluation of prompt-based methods, including different forms of information organization and various few-shot retrieval methods.
Subsequent work breaks down this task into multiple stages for solving.
DIN-SQL**Chen et al., "DIN-SQL: A Decomposition-Based Method for Text-to-SQL Tasks"** breaks down the Text-to-SQL task into smaller subtasks with specific prompts, then guides GPT-4 to complete each subtask, and eventually form a complete SQL query. 
TA-SQL**Zhang et al., "TA-SQL: Task Alignment for Text-to-SQL Tasks"** introduces Task Alignment, a strategy that enhances large language models' performance and reliability in text-to-SQL tasks by mitigating hallucination through schema linking and logical synthesis.
SuperSQL**Li et al., "Supersql: A Multi-Faceted Framework for Evaluating Natural Language to SQL Methods"** presents NL2SQL360, a multi-faceted framework for evaluating and comparing natural language to SQL methods to help researchers and practitioners identify optimal solutions for specific needs. 

However, these studies often focus on prompt organization or task decomposition and do not consider the gap between few-shot examples and test questions, which leads to inefficient in-context learning. 
% Furthermore, the direct generation of SQL from user queries without intermediate steps impedes the model’s learning process. 
To mitigate these challenges, we propose \model, a SQL generation workflow tailored for real-world and complex database environments.