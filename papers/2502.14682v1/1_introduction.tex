\section{Introduction}
%介绍第一段：任务的定义；任务的大背景；任务的意义价值；最早期的一类方法；早期方法的缺点
% Text-to-SQL aims to transform natural language questions into executable SQL queries on databases~\citep{deng2022recent,qin2022survey}.
With the widespread use of electronic devices, tables have become a common format for storing structured data from various sources, such as databases and spreadsheets~\citep{lu2024large}.
Natural language interfaces can help more non-technical users access the data while skilled professionals can efficiently access this data through Structured Query Language (SQL)~\citep{codd1974seven, deng2022recent,qin2022survey}.
Therefore, Text-to-SQL --- transforms natural language questions into executable SQL queries on databases --- has received extensive attention from both industry and academia~\citep{deng2022recent,qin2022survey,katsogiannis2023survey}.
% This process reduces the cognitive and operational load on users for extracting information from databases. 
% Early approaches, due to the heterogeneous nature of database schemas, required professionals well-versed in database-specific details to manually write SQL queries, which were often error-prone in complex scenarios. This issue worsened with the increasing complexity of databases. 
Early methods primarily relied on rule-based systems that generate SQL queries through schema and template matching~\citep{androutsopoulos1995natural,zelle1996learning}, while these methods lack scalability and adaptability.
%近期方法介绍
Recent methods aim to enhance domain independence by employing supervised models trained across different domains and datasets~\citep{scholak2021picard,qi2022rasat}. Nonetheless, this category of approaches suffers from poor generalization capacity and necessitates retraining when adapted to various databases. 

\begin{figure}[tbp]
    \centering
    \includegraphics[width=0.9\linewidth]{image/problemv2.pdf}
    \caption{\model alleviates gaps through AQP and CSM. AQP and CSM denote Abstract Query Pattern and Contextual Schema Markup respectively.}
    \label{fig:enter-label}
    \vspace{-6mm}
\end{figure}

Recently, the advent of LLMs has led to significant advancements in Text-to-SQL task~\citep{rajkumar2022evaluating,ni2023lever,gao2024text}. 
Methods based on LLMs can be roughly classified into fine-tuning based methods and prompt-based methods.
Fine-tuning based methods mainly involve further training open-source language models using Text-to-SQL data~\citep{li2024codes,pourreza2024dts}. 
Prompt-based methods utilize in-context learning ability of closed-source language models to accomplish text-to-SQL tasks~\citep{pourreza2024din,gao2024text,li2024dawn,qu2024before}.
%方法的不足
Fine-tuning-based methods usually require a certain amount of labeled data and computational resources.
With the continuous improvement of closed-source models, even after training on large amounts of data, some fine-tuning based methods on open-source language models are still weaker than prompt-based methods. Therefore, we focus on prompt-based methods.

Although prompt-based methods have achieved excellent performance on Text-to-SQL, their performance still has a significant gap compared to human performance, especially on complex questions.
We analyze and find that as the complexity of questions increases, the complexity of the corresponding SQLs also increases, and the gap between questions and SQLs becomes larger and larger.
We regard Text-to-SQL as a natural language to SQL translation task and identify two gaps from the perspective of translation: \textbf{(1) Structural mapping gap}. 
By removing the database-related information from the question and SQL, we can obtain the structural information of the question and the SQL. 
% We find that there is a correspondence between the question structure and the SQL structure. 
To generate SQL, the model needs to learn the mapping from the question structure to the SQL structure. As the complexity of the question increases, the structural mapping gap widens, making it more difficult for the model to learn.
\textbf{(2) Lexical mapping gap}. The more complex the question, the more database tables and columns are involved in the question, making it significantly more difficult to correctly map database-related text to the database schemas.


% We analyze that the performance gap mainly comes from two aspects: \textbf{(1) Syntax-wise differences},
% The complexity of the generated SQL statements is high because the model does not efficiently link user queries to database schema information. 
% The model directly targets complex natural language queries that embed specific database details. 
% \textbf{(2) Structure-wise differences}, the mismatch between databases used in examples and those in test questions creates a gap, resulting in inefficient contextual learning for LLMs. 
% Under these circumstances, the model finds it challenging to extract general SQL generation logic from few-shot examples, resulting in the subpar performance of LLMs on the Text-to-SQL task.

%方法
To tackle these two gaps, we propose \model, a Text-to-SQL system designed for complex and real-world databases. \model introduces a scalable and efficient SQL generation pipeline based on LLMs, consisting of four components: \textit{Abstract Query Pattern (AQP), Contextual Schema Markup (CSM), Constructing Demonstrations, Generating and Correcting SQL}.
%解决的问题（大致流程）
AQP aims to obtain the structural pattern of the question by removing database-related information.
Specifically, we mask database-related information in the question using placeholders (e.g., [TABLE], [COLUMN], and [VALUE]) to obtain AQP representation.
The AQP representation of the question provides a database-agnostic representation that focuses on structure, which enables us to find structurally similar demonstrations, independent of the specific database. 
CSM aims to associate database-related text span in the question with specific tables or columns in the database to obtain CSM representation.
The CSM representation provides an effective method for integrating relevant database schema in the question, which alleviates the lexical mapping gap.
We process question-SQL pairs to obtain AQP and CSM demonstrations through the AQP and CSM modules.

To utilize AQP and CSM demonstrations to alleviate the two gaps, the generation process is divided into three steps: first, generate the AQP; next, generate the CSM; and finally, generate the SQL based on the AQP and CSM.
% We then restore the masked components, forming a mapping between the information in the question and the database schema, resulting in CSM representation. 
% Although the examples and the question originate from different databases, this mapping method enables the large model to learn and leverage these mapping relationships to reduce the impact of database schema discrepancies.
% In order to better extract general SQL generation logic from few-shot examples, we decompose the Text-to-SQL task into four steps: Text-AQP-CSM-SQL. 
% By dividing the task into these steps, we enhance the linkage between examples and queries, enabling the model to better extract general SQL generation logic from few-shot examples.
%解决fewshot相似度问题
% To maximize relevance between \Dan{**} and **, we retrieve relevant examples based on AQP and CSM stages. 
% During the AQP stage, we utilize the similarity of the original query. In contrast, during the CSM stage, we employ the AQP results to identify the most analogous examples in the training set. This staged retrieval strategy optimizes the relevance between examples and queries, which we will analyze in subsequent experiments.
Specifically, when generating the CSM representation of a test question, we retrieve structurally similar demonstrations as few-shot examples based on the AQP representation to assist in CSM generation.
%Cot
% LLMs can also achieve robust benchmark performance using only a few examples (few-shot) or Chain-of-Thought (CoT) without the need for fine-tuning, attributed to their strong in-context learning capabilities~\Dan{cite} to handle corresponding problems.
% Additionally, some methods classify questions~\citep{pourreza2024din,gao2024text} or use Chain-of-Thought to decompose questions~\cite{tai2023exploring} and design different prompts to handle corresponding problems.
% Additionally, 
Inspired by the Chain of Thought (CoT) approach and aware of the high token consumption, we propose the CoT version, which generates AQP, then CSM, and finally SQL in a step-by-step way. 
% This method significantly reduces the number of input tokens while incurring minimal performance loss.
We conduct extensive experiments on two datasets and our proposed method achieves an accuracy of 64.67\% on the BIRD dev set and 87.9\% on the Spider dev set.
%贡献

Our key contributions can be summarized as follows:
\begin{itemize}[leftmargin=*,itemsep=0pt,parsep=0.5em,topsep=0.3em,partopsep=0.3em] 
% \item We decompose the Text-to-SQL task into more manageable steps to enhance the LLMs' ability to generalize SQL generation logic from few-shot examples.
\item We identify two important gaps when generating SQL queries for complex questions: the structural mapping gap and the lexical mapping gap.
% \item We handle the training set and test set in almost the same manner to align few-shot learning with downstream tasks, thereby narrowing the gap between them.
\item We propose an efficient SQL generation pipeline, which effectively alleviates the two gaps through Abstract Query Pattern and Contextual Schema Markup module.
\item \model achieves impressive results, with an execution accuracy of 64.67\% on the BIRD dev set and 87.9\% on the Spider dev set.
% achieving state-of-the-art performance at the time of writing.
\end{itemize}