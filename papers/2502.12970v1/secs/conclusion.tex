\section{Conclusion}
In this paper, we introduce a novel training paradigm, \textbf{\textit{Reasoning-to-Defend}}~(\texttt{R2D}), that equips LLMs with safety-aware reasoning capabilities. We propose unlocking these reasoning abilities through SwaRD, while further enhancing the LLMsâ€™ capacity to self-assess the safety of each reasoning step via CPO. Our experimental results and ablation studies show that by leveraging these reasoning capabilities, \texttt{R2D}-enabled LLMs consistently achieve lower ASRs compared to those using previous defense approaches, validating the effectiveness of the different components of \texttt{R2D}. A detailed analysis also confirms that \texttt{R2D} does not lead to over-refusals, which is particularly important for real-world applications.