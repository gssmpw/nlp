\PassOptionsToPackage{dvipsnames}{xcolor} % Set options before package loading

% \documentclass[gray]{jmlr} % test grayscale version
%\documentclass[tablecaption=bottom]{jmlr}% journal article
\documentclass[pmlr,twocolumn,10pt]{jmlr} % W&CP article

% The following packages will be automatically loaded:
% amsmath, amssymb, natbib, graphicx, url, algorithm2e

%\usepackage{rotating}% for sideways figures and tables
%\usepackage{longtable}% for long tables

% The booktabs package is used by this sample document
% (it provides \toprule, \midrule and \bottomrule).
% Remove the next line if you don't require it.

\usepackage{booktabs}
% The siunitx package is used by this sample document
% to align numbers in a column by their decimal point.
% Remove the next line if you don't require it.
%\usepackage[load-configurations=version-1]{siunitx} % newer version 
\usepackage{siunitx}

\usepackage{xcolor}  % Load after enforcing options
\usepackage{lipsum}
\usepackage{lmodern}
\usepackage[breakable,skins]{tcolorbox}
\usepackage{colortbl}
\usepackage{soul}
\usepackage{array}

% The following is to recognise equal contribution for authorship
\newcommand{\equal}[1]{{\hypersetup{linkcolor=black}\thanks{#1}}}

% URL of the repository
\newcommand{\repourl}{https://github.com/hyesunyun/MedLitSpin}

\newcommand{\hlblue}[1]{\sethlcolor{Cerulean!50}\hl{#1}} % blue highlight
\newcommand{\hlorange}[1]{\sethlcolor{Peach!50}\hl{#1}} % orange highlight

% Define an unnumbered theorem just for this sample document for
% illustrative purposes:
\theorembodyfont{\upshape}
\theoremheaderfont{\scshape}
\theorempostheader{:}
\theoremsep{\newline}
\newtheorem*{note}{Note}

% change the arguments, as appropriate, in the following:
\jmlrvolume{LEAVE UNSET}
\jmlryear{2025}
\jmlrsubmitted{LEAVE UNSET}
\jmlrpublished{LEAVE UNSET}
\jmlrworkshop{Preprint: Under Review} % W&CP title

% The optional argument of \title is used in the header
\title[Do LLMs Fall for Spin in Medical Literature?]{Caught in the Web of Words: \\ Do LLMs Fall for Spin in Medical Literature?}

% Anything in the title that should appear in the main title but 
% not in the article's header or the volume's table of
% contents should be placed inside \titletag{}

%\title{Title of the Article\titletag{\thanks{Some footnote}}}


% Use \Name{Author Name} to specify the name.
% If the surname contains spaces, enclose the surname
% in braces, e.g. \Name{John {Smith Jones}} similarly
% if the name has a "von" part, e.g \Name{Jane {de Winter}}.
% If the first letter in the forenames is a diacritic
% enclose the diacritic in braces, e.g. \Name{{\'E}louise Smith}

% \thanks must come after \Name{...} not inside the argument for
% example \Name{John Smith}\nametag{\thanks{A note}} NOT \Name{John
% Smith\thanks{A note}}

% Anything in the name that should appear in the title but not in the 
% article's header or footer or in the volume's
% table of contents should be placed inside \nametag{}

% Two authors with the same address
% \author{%
%  \Name{Author Name1\nametag{\thanks{A note}}} \Email{abc@sample.com}\and
%  \Name{Author Name2} \Email{xyz@sample.com}\\
%  \addr Address
% }

% Three or more authors with the same address:
% \author{%
%  \Name{Author Name1} \Email{an1@sample.com}\\
%  \Name{Author Name2} \Email{an2@sample.com}\\
%  \Name{Author Name3} \Email{an3@sample.com}\\
%  \Name{Author Name4} \Email{an4@sample.com}\\
%  \Name{Author Name5} \Email{an5@sample.com}\\
%  \Name{Author Name6} \Email{an6@sample.com}\\
%  \Name{Author Name7} \Email{an7@sample.com}\\
%  \Name{Author Name8} \Email{an8@sample.com}\\
%  \Name{Author Name9} \Email{an9@sample.com}\\
%  \Name{Author Name10} \Email{an10@sample.com}\\
%  \Name{Author Name11} \Email{an11@sample.com}\\
%  \Name{Author Name12} \Email{an12@sample.com}\\
%  \Name{Author Name13} \Email{an13@sample.com}\\
%  \Name{Author Name14} \Email{an14@sample.com}\\
%  \addr Address
% }

% Authors with different addresses and equal first authors:
% \author{%
% \Name{Anonymous First Author 1}\equal{These authors contributed equally} \Email{abc@sample.com}\\
% \addr University X, Country 1
% \AND
% % footnotemark[1] is to refer to the \equal footnote
% \Name{Anonymous First Author 2}\footnotemark[1] \Email{def@sample.com}\\
% \addr University Y, Country 2
% \AND
% \Name{Anonymous Last Author} \Email{ghi@sample.com}\\
% \addr University Z, Country 3
% }

\author{%
 \Name{Hye Sun Yun} \Email{yun.hy@northeastern.edu}\\
 \addr Northeastern University, Boston, MA, USA\\
 \Name{Karen Y.C. Zhang} \Email{zhang.yuchen@northeastern.edu}\\
 \addr Northeastern University, Boston, MA, USA\\
 \Name{Ramez Kouzy} \Email{rkouzy@mdanderson.org}\\
 \addr The University of Texas MD Anderson Cancer Center, Houston, Texas, USA\\
 \Name{Iain J. Marshall} \Email{iain.marshall@kcl.ac.uk}\\
 \addr King’s College London, London, UK\\
 \Name{Junyi Jessy Li} \Email{jessy@utexas.edu}\\
 \addr The University of Texas at Austin, Austin, Texas, USA\\
 \Name{Byron C. Wallace} \Email{b.wallace@northeastern.edu}\\
 \addr Northeastern University, Boston, MA, USA
}

\begin{document}

\maketitle

\begin{abstract}
Medical research faces well-documented challenges in translating novel treatments into clinical practice. 
Publishing incentives encourage researchers to present ``positive'' findings, even when empirical results are equivocal. 
Consequently, it is well-documented that authors often \emph{spin} study results, especially in article abstracts. 
Such spin can influence clinician interpretation of evidence and may affect patient care decisions.
In this study, we ask whether the interpretation of trial results offered by Large Language Models (LLMs) is similarly affected by spin. 
This is important since LLMs are increasingly being used to trawl through and synthesize published medical evidence. 
We evaluated 22 LLMs and found that they are across the board \emph{more} susceptible to spin than humans. 
They might also propagate spin into their outputs: We find evidence, e.g., that LLMs implicitly incorporate spin into plain language summaries that they generate. 
We also find, however, that LLMs are generally capable of recognizing spin, and can be prompted in a way to mitigate spin's impact on LLM outputs. 
\end{abstract}

\paragraph*{Data and Code Availability}
This paper uses the cancer-related medical abstract dataset \citep{boutron2014impact}, which is available as a Data Supplement. 
All code required to reproduce the experiments in this paper is available at \url{\repourl}.

\paragraph*{Institutional Review Board (IRB)}
This research did not require IRB approval as it is designated as Not Human Subject Research.

\begin{figure}[t]
\floatconts
  {fig:fig1}
  {\caption{Authors of medical articles sometimes \emph{spin} their reporting of trial results. We find that LLMs are susceptible to this when ``reading'' medical abstracts, more so than human experts.}}
  {\includegraphics[width=\linewidth]{images/llm-spin-fig1}}
\end{figure}

\begin{table*}[t]
\footnotesize
\floatconts
  {tab:example_abstracts}
  {\caption{Example of an abstract with spin \citep{osborne2002double} and an abstract rewritten without spin. The highlighted portions of text show the changes between the original and the rewritten version.}}
  {\begin{tabular}{p{0.48\textwidth} p{0.48\textwidth}}
  \toprule
  \multicolumn{1}{c}{\bfseries Abstract with Spin} & \multicolumn{1}{c}{\bfseries Abstract Rewritten without Spin}\\
  \midrule
  \rowcolor{gray!20}
  \scriptsize\textbf{Purpose}: To compare the efficacy and tolerability of treatment A with comparator B in the treatment of advanced breast cancer in patients whose disease progresses on prior endocrine treatment. & \scriptsize\textbf{Purpose}: To compare the efficacy and tolerability of treatment A with comparator B in the treatment of advanced breast cancer in patients whose disease progresses on prior endocrine treatment.\\
  \scriptsize\textbf{Patients and methods}: In this double‐blind, double‐dummy, parallel‐group study, postmenopausal patients were randomized to receive either treatment A or comparator B. The primary end point was time to progression (TTP). Secondary end points included objective response (OR) rate, duration of response (DOR), and tolerability. & \scriptsize\textbf{Patients and methods}: In this double‐blind, double‐dummy, parallel‐group study, postmenopausal patients were randomized to receive either treatment A or comparator B. The primary end point was time to progression (TTP). Secondary end points included \hlblue{time to treatment failure (TTF),} objective response (OR) rate, duration of response (DOR), and tolerability.\\
  \rowcolor{gray!20}\scriptsize\textbf{Results}: Patients (n = 400) were followed for a median period of 16.8 months. Treatment A was \hlorange{as effective as} comparator B in terms of TTP (hazard ratio, 0.92; 95\% confidence interval [CI], 0.74 to 1.14; P =.43); median TTP was 5.4 months with treatment A and 3.4 months with comparator B. \hlorange{OR rates were 17.5\% with both treatments. Clinical benefit rates (complete response + partial response + stable disease $>$ or = 24 weeks) were 42.2\% for treatment A and 36.1\% for comparator B (95\% CI, ‐4.00\% to 16.41\%; P =.26). In responding patients, median DOR (from randomization to progression) was 19.0 months for treatment A and 10.8 months for comparator B. Using all patients,} DOR was significantly greater for treatment A compared with comparator B; the ratio of average response durations was 1.35 (95\% CI, 1.10 to 1.67; P $<$ 0.01). Both treatments were well tolerated.
 & \scriptsize\textbf{Results}: Patients (n = 400) were followed for a median period of 16.8 months. Treatment A was \hlblue{not more effective than} comparator B in terms of TTP (hazard ratio, 0.92; 95\% confidence interval [CI], 0.74 to 1.14; P =.43); median TTP was 5.4 months with treatment A and 3.4 months with comparator B. \hlblue{There was no statistically significant difference between the 2 groups for TTF. Median TTF was 4.6 months for treatment A and 3.3 months for comparator B (HR, 0.96; 95\% CI, 0.77 to 1.19; P = .69). At the time of this data analysis, the rate of deaths was respectively for treatment A and comparator B, 35.4\% (n=73) vs. 33.5\% (n=65). OR rates were 17.5\% with both treatments.} DOR was statistically significantly greater for treatment A compared with comparator B; the ratio of average response durations was 1.35 (95\% CI, 1.10 to 1.67; P $<$ 0.01). Both treatments were well tolerated.\\
  \scriptsize\textbf{Conclusion}: Treatment A was \hlorange{at least as effective as comparator B, with efficacy end points slightly favoring treatment A. Treatment A represents an additional treatment option} for postmenopausal women with advanced breast cancer whose disease progresses on tamoxifen therapy. & \scriptsize\textbf{Conclusion}: Treatment A was \hlblue{not more effective than comparator B} for postmenopausal women with advanced breast cancer whose disease progresses on tamoxifen therapy.\\
  \bottomrule
  \end{tabular}}
\end{table*}

\section{Introduction}
\label{section:intro}
Randomized controlled trials (RCTs) form the cornerstone of evidence-based medicine. 
Healthcare providers often base clinical decisions on trial findings, mostly as presented in article abstracts \citep{christakis2000physicians, hopewell2008consort, berwanger2009quality, marcelo2013comparison}. 
Unlike full texts, abstracts are concise and easily accessible, unlike full articles which are often behind paywalls \citep{smith2017knowledge, piwowar2018state, day2020open}.\footnote{Clinicians are 2.4x more likely to read an abstract than a full article \citep{islamaj2009understanding}.}

The information presented in abstracts alone is sufficient to alter most clinicians' care decisions \citep{barry2001family}. 
But while convenient, relying on abstracts brings drawbacks: Several studies have shown that biomedical abstracts may not present an entirely accurate impression of the underlying study results \citep{boutron2010reporting, chiu2017spin, wayant2019evaluation, jellison2020evaluation, nowlin2022spin}. 
Abstracts frequently present overly optimistic interpretations of results, reflecting broader publication pressures that favor positive findings. \citep{begg1988publication, dickersin1990existence, easterbrook1991publication, dickersin1993publication, devito2019catalogue}.

\emph{Spin} refers to reporting strategies that overstate the benefits of experimental treatments beyond what is supported by empirical evidence.
For instance, spin might seek to distract readers from statistically nonsignificant results, overstate the efficacy, and/or understate the harms of a treatment.
This is also known as ``hype'' \citep{sumner2016exaggerations, yavchitz2016new, prasad2020malignant}.
About 60\% of abstracts of a sample of RCTs indexed in PubMed with statistically nonsignificant results for the primary outcome contain spin \citep{boutron2010reporting}. 

Elsewhere, \citet{boutron2014impact} showed that spin in cancer RCT abstracts can affect the expert clinician and medical researcher interpretation of trial results, such that they are more likely to rate treatments as beneficial despite the fact that the primary outcome measure is statistically nonsignificant. 
This implies that spin in medical literature abstracts may impact patient treatment. 

Large Language Models (LLMs) are increasingly being used to process medical literature, and will increasingly mediate the consumption of published evidence via automated synthesis, summarization, and simplification \citep{shaib-etal-2023-summarizing, goldsack2025leveraging}.
In this work, we ask: \textbf{How susceptible are LLMs to spin in medical articles?} 
To answer this question empirically, we evaluated 22 LLMs on three tasks: \textbf{(1)} \textit{How well can LLMs detect the presence of spin in abstracts of RCT reports?} As LLMs are increasingly used to aid human decision-making in medicine \citep{thirunavukarasu2023large}, their ability to detect spin and interpret results accordingly will be key. \textbf{(2)} \textit{How do LLMs interpret the same trial results when presented with spun versus unspun abstracts?} 
LLMs may be capable of recognizing spin when explicitly asked to do so, and yet still be susceptible to it insofar as their interpretation of study results may be influenced by spin; we aim to quantify this. 
\textbf{(3)} \textit{To what extent might LLMs propagate or amplify spin in medical abstracts when generating simplified versions?} One practical use of LLMs in medicine is \emph{simplification} to enable lay consumption of new technical content in medicine \citep{devaraj2022evaluating}. We investigate how the degree of spin in technical abstracts affects automatically generated plain language summaries (PLS). 

Our findings reveal that, at least in oncology, LLMs are more susceptible to spin in medical abstracts than clinicians and medical researchers. This susceptibility persists despite their ability to accurately detect spin when explicitly prompted. Even though LLMs recognize spin, they still propagate it to downstream tasks, such as generating simplified versions of technical abstracts. These findings demonstrate LLMs' vulnerability to spin in medical literature, emphasizing the importance of careful implementation when using them to process clinical research. To address this issue, we also explored simple mitigation strategies that may help reduce the impact of spin on LLMs.

\begin{figure*}[t]
\floatconts
  {fig:detection_accuracy}
  {\caption{Spin detection task accuracies for all LLMs. The average accuracy of all models was 0.67 (solid red vertical line), well above the random baseline (gray dashed vertical line). That said, this plot shows considerable variance across models with respect to their spin detection capabilities.}}
  {\includegraphics[width=0.75\linewidth]{images/detection_accuracy_by_model}}
\end{figure*}

\section{Experimental Setup}
\label{section:setup}

To empirically evaluate LLM susceptibility to spin in medical abstracts, we ran three experiments measuring how different LLM outputs are when given abstracts with and without spin. 
We base these analyses on data manually collected in prior work on spin in oncology and its influence on medical experts such as clinicians and principal investigators in cancer research (\citealt{boutron2014impact}; Section \ref{section:data}).

In the first experiment, we measured whether LLMs can spot spin in medical abstracts. 
The other two experiments examined downstream effects of any susceptibility to spin: First, we assessed whether LLMs ``interpret'' results differently when the underlying abstract has been spun, and then we measured if any such bias is propagated to automatically simplified abstracts.

\subsection{Data}
\label{section:data}
In all of our experiments we used a small, manually curated dataset from \citet{boutron2014impact}. 
This comprises 60 abstracts (both real and synthetic) paired to compare results reported with and without spin.
The 30 source abstracts are from cancer-related RCTs that met two criteria: (1) reported statistically nonsignificant results for all primary outcomes of the studied intervention, and (2) contained language in their results and conclusion sections that overstated the benefit of the intervention.\footnote{Two independent evaluators, specifically trained to identify ``spin'', evaluated all selected abstracts. Any discrepancies between reviewers were discussed until they reached a consensus \citep{boutron2014impact}.}
All of the underlying trials comprised two arms (intervention and control) and included at least 100 patients.

Researchers in this prior work \citep{boutron2014impact} manually edited each of these abstracts to remove spin, yielding 30 ``neutral'' matched abstracts.\footnote{This was done following guidelines outlined in the main text of \citet{boutron2014impact}.}
This process controlled for length: ``neutralized'' versions were constrained to be within 25 words of the original (spun) versions. 
Author names, references, journal names, registration numbers, trial names or acronyms, and article titles were removed from both versions of the abstracts. 
Further, treatment descriptions were systematically masked with generic terms (e.g., treatment A and comparator B) to avoid any pre-existing bias individuals may have based on treatment names. Table~\ref{tab:example_abstracts} shows an example of an abstract with spin and a rewritten abstract without.

\subsection{Evaluation}

\paragraph{Spin detection} Using the abstracts from \citet{boutron2014impact}, we prompted LLMs to answer whether or not a given abstract contains spin. 
This is a binary classification problem with a balanced distribution, so we use accuracy as a metric. The exact prompt we used is available in Appendix~\ref{appendix:detection_prompt}.

\begin{figure*}[t]
\floatconts
  {fig:interpretation}
  {\caption{Average mean differences of scores from LLMs for all 5 interpretation questions compared to human experts. Error bars indicate 95\% confidence intervals. A positive mean difference indicates that LLMs interpreted the spun abstract as showing more favorable treatment results while the negative mean difference indicates unspun abstracts to be more favorable. This plot suggests that LLMs, in general, erroneously infer larger differences in results between spun and unspun abstracts than do human experts. \figureref{fig:spin_label_regression_benefit} explains the effect of spin for each LLM.}}
  {\includegraphics[width=\linewidth]{images/interpretation_by_measures}}
\end{figure*}

\paragraph{Interpretation of trial results for spun and unspun abstracts} 
For each abstract, we prompted LLMs to answer the following 5 questions individually on a scale of 0-10: 

\begin{tcolorbox}[colback=blue!5!white,colframe=blue!75!black,title=Interpretation Questions, label=box:questions]
    (1) Based on this abstract, do you think treatment \emph{A} would be beneficial to patients? [very unlikely to very likely]\\
    
    (2) Rate the overall rigor of the study methodology. [not at all rigorous to very rigorous]\\
    
    (3) Rate the importance of the study. [not at all important to very important]\\
    
    (4) Are you interested in reading the full-text article for the study described in the abstract? [not at all interested to very interested]\\
    
    (5) Do you think it would be interesting to run another trial evaluating this treatment? [not interesting at all to very interesting]
\end{tcolorbox}
\noindent These 5 questions were used by \citet{boutron2014impact} for their human experts (i.e., clinicians, authors of RCT papers, and principal investigators in cancer research) study with spun and unspun abstracts. The prompt is provided in Appendix~\ref{appendix:interpretation_prompts}

For each question, we calculated the mean difference in LLM scores between paired abstracts with and without spin. A positive mean difference indicates that LLMs interpreted the spun abstract as presenting more favorable treatment results. We then compared these LLM-based interpretations to previously reported human expert assessments from \citet{boutron2014impact}.

\paragraph{\textbf{Simplifying spun and unspun abstracts}} To examine whether LLMs propagate spin to downstream information for lay people, we analyzed the relationship between spun technical abstracts and their automatically generated plain language versions. 
Ensuring the accessibility of medical literature is crucial, as the average American reads at a 7th- to 8th-grade level, and 36\% of the population has basic or below basic health literacy \citep{kutner2006health, marchand2017readability}. 
LLMs have shown promise as tools for simplifying medical texts into plain language \citep{august2023paper, shaib-etal-2023-summarizing, jeblick2024chatgpt, picton2025assessing}, but if spin influences these outputs, it could mislead lay readers by distorting their interpretation of medical evidence \citep{boutron2019three}.

Using the same set of abstracts as before, we prompted the LLMs to generate plain language summaries suitable for a 5th-grader. 
This aligns with recommendations from the National Institutes of Health (NIH), American Medical Association (AMA), and the U.S. Department of Health and Human Services (HHS) to produce patient education materials at a 5th- to 6th-grade reading level \citep{weiss2007health, us2009simply, brega2015ahrq}.
The full prompt is provided in Appendix~\ref{appendix:simplification_prompt}.
To ensure brevity, we limit simplified summaries to at most 300 tokens. 
We did this at inference time by specifying the maximum number of tokens to generate.

\begin{figure*}%[htbp]
\floatconts
  {fig:spin_label_regression_benefit}
  {\caption{Coefficients from linear regression models with 95\% CI for each LLM showing how much different LLMs overestimate the treatment effects (benefit of treatment), when abstracts contain `spin'. In comparison with human experts (0.71), all LLMs were more susceptible to spin. AlpaCare 7B and Olmo2 Instruct 13B were the most susceptible to spin than others.}}
  {\includegraphics[width=0.8\linewidth]{images/spin_label_regression_benefit}}
\end{figure*}

\subsection{Models}
\label{section:models}

We include in our analysis a variety of LLMs (22 in all), including both open and closed (proprietary) models.
We also include both general and specialized (biomedical) LLMs, and models spanning a range of parameter counts. 

\begin{itemize}
    \item \textbf{Generalist closed-source/proprietary:} Anthropic's Claude 3.5 Haiku and Sonnet, Google's Gemini 1.5 Flash and Flash 8B \citep{team2024gemini}, OpenAI's GPT 3.5 175B \citep{openai2025gpt35turbo}, GPT4o \citep{hurst2024gpt}, GPT4o Mini \citep{openai20244o}.
    \item \textbf{Generalist open-weight:} Llama2 7B, 13B, and 70B Chat \citep{touvron2023llama}; Llama3 8B and 70B Instruct \citep{meta2024introducing}; Mistral 7B Instruct v0.1 \citep{jiang2023mistral}; OLMo2 7B and 13B Instruct \citep{olmo20242}.
    \item \textbf{Biomedical open-weight:} Alpacare 7B \citep{zhang2023alpacare}, BioMedGPT 7B \citep{luo2023biomedgpt}, BioMistral 7B \citep{labrak2024biomistral}, Med42-v2 8B and 70B \citep{christophe2024med42}, OpenBioLLM 8B and 70B \citep{pal2024openbiollms}.
\end{itemize}

\section{Results}

\paragraph{Detecting spin in abstracts} \figureref{fig:detection_accuracy} reports the accuracies of all LLMs on the spin detection task. 
The average accuracy across all models is 0.67. 
Claude 3.5 Sonnet achieved the highest accuracy score (0.97), followed by GPT4o Mini (0.85). 
LLMs with accuracy scores close to 0.50 predicted just one label (spin or no spin) for all abstracts. The mean accuracy of generalist closed-source/proprietary LLMs was 0.75. 
Generalist open-weight LLMs had an average accuracy of 0.64, while specialist biomedical open-weight LLMs were comparable (0.63). 
Overall, these results indicate that LLMs are in general moderately to strongly capable of detecting spin. 

\paragraph{Interpretation of (spun) trial results} 
Does spin change LLM interpretation of the reported results? 
The mean differences of the 5 interpretation questions asked to the LLMs are available in \figureref{fig:interpretation}. 
Differences across all interpretation measures from LLMs were generally (much) higher than those observed for human experts.
This suggests that LLMs erroneously infer larger differences in results between spun and unspun abstracts than do human experts. Although human experts found the trials from spun abstracts to be less rigorous or important than from unspun abstracts, they rated trials in abstracts with spin to be more beneficial and were generally more interested in reading the full-text article.

We next quantify the strength of association between the presence of spin and LLM interpretation of results. Specifically, we ran a linear regression with an indicator for the presence of spin in an abstract as predictor, to measure how strongly this correlates with LLM interpretation result scores---in particular, the treatment of benefit measure. 
For simplicity, we ran separate regressions for each LLM, as follows:
\begin{multline*}
    \text{LLM $k$ output score} =
    \beta_{0k} + \\
    \beta_{1k} \cdot (\text{presence or absence of spin})
\end{multline*}
Where $\beta_{0k}$ is an intercept (for LLM $k$), and $\beta_{1k}$ is a coefficient for LLM $k$. 

The coefficients and 95\% confidence intervals for all LLMs for the regression benefit question (Text Box in Section~\ref{box:questions}) are reported in \figureref{fig:spin_label_regression_benefit}. 
This shows that all LLMs considered appear to be more susceptible than human experts to spin in medical abstracts. 
We report regression results for the other interpretation questions in Appendix~\ref{appendix:linear_models}.

During our analysis, we noticed that a couple of the smaller models such as AlpaCare 7B and BioMedGPT 7B sometimes failed to output valid results for some of the abstracts and questions. We considered model outputs as invalid if they did not output any numerical values between 0 and 10. We removed these inferred outputs from the analysis.

\paragraph{Simplifying spun abstracts}
We prompted all 22 models (Section~\ref{section:models}) to generate simplified abstracts. The average token length across all simplified abstracts was 208.10 (SD = 67.01).
Selected examples are provided in Appendix~\ref{appendix:simplification_examples}. 
To assess whether LLMs propagate spin when simplifying abstracts into plain language versions, we used two LLMs---GPT-4o Mini and Claude 3.5 Sonnet---to evaluate the generated summaries. These models were chosen for their strong spin detection performance (\figureref{fig:detection_accuracy}). Using the automatically generated \emph{simplified} versions of abstracts, they answered the same interpretation questions from the Text Box in Section~\ref{section:setup}.

Analysis of LLM-generated plain language summaries showed that spin from the original abstracts persisted in these simplified versions, potentially influencing LLM interpretation of trial results. \figureref{fig:pls_evaluation} shows the analysis of plain language summaries revealing larger score differences between spun and unspun versions, particularly for assessments of treatment benefit, interest in full-text review, and motivation to conduct additional trials. For treatment benefit assessment, mean differences in LLM-generated summaries were 2.47 for Claude 3.5 Sonnet and 3.59 for GPT4o Mini, closely matching the differences observed in evaluations of the original abstracts (\figureref{fig:interpretation}). The mean difference scores for rigor and importance of studies were on average lower than the other questions, which also aligns with results from our experiments with the abstracts and the human expert study by \citet{boutron2014impact}.

Mean difference scores for plain language summaries varied substantially by evaluator LLM rather than by which LLM generated the summary. Each evaluator model produced consistent mean difference scores across summaries from different LLMs, demonstrating that spin in the original abstracts consistently led to more favorable interpretations of plain language versions.

\begin{figure}[htbp]
\floatconts
  {fig:pls_evaluation}
  {\caption{Average mean differences of scores from Claude 3.5 Sonnet and GPT4o Mini interpreting simplified versions of abstracts with and without spin generated by 22 LLMs. The error bars indicate 95\% confidence intervals. This plot shows that simplified spun abstracts generated by LLMs also exhibit spin.}}
  {\includegraphics[width=\linewidth]{images/pls_evaluation}}
\end{figure}

\begin{figure*}[htbp]
\floatconts
  {fig:interpretation_mitigation_comparisons}
  {\caption{Average mean differences of scores across all LLMs using different prompting strategies for 5 interpretation questions compared to human experts. The error bars indicate 95\% confidence intervals. This plot shows that mitigation strategies such as adding additional information on the presence or absence of spin or jointly prompting the model to detect and then interpret can reduce the effect of over-inflating the benefits of the trial results.}}
{\includegraphics[width=\linewidth]{images/interpretation_by_measures_all_methods}}
\end{figure*}

\section{Reducing the Effect of Spin}

Our findings demonstrate that LLMs are susceptible to spin in medical articles when used without safeguards. To address this vulnerability, we evaluated strategies that might reduce LLMs' tendency to overstate favorable trial results. 

We used two approaches to spin mitigation.
The first approach incorporated explicit spin labels into the interpretation prompts. We tested this strategy using both reference labels and LLM-generated spin assessments, where each model used its own spin detection outputs as labels. Appendix~\ref{appendix:reduce_effect_prompts} provides the exact wording of the prompt.

The second approach we consider involves prompting the LLM to perform both the tasks of spin detection and result interpretation (``joint prompting''). In one prompt, we ask the model to first detect if a given abstract contains spin or not and then to answer the interpretation question based on its answer to the previous question. This combined prompting was done to see if chain-of-thought style prompting \citep{wei2022chain} would allow the model to critically reason for the interpretation task and to be less susceptible to the presence of spin. The prompt for this can also be found in Appendix~\ref{appendix:reduce_effect_prompts}.

\figureref{fig:interpretation_mitigation_comparisons} shows the comparison of our strategies compared to human experts and original prompting (``baseline'') for interpreting trial results. Across all questions we see a decrease in the mean differences when the prompt includes whether a given abstract contains spin or not. 
Providing the reference labels significantly reduces the mean difference, compared to the baseline prompting approach. 
For the treatment benefit question, baseline prompting resulted in an average mean difference of 3.38 across all LLMs.
Including the reference spin label moderated this, yielding a difference of 1.94. 
But even including \emph{inferred} spin labels improves performance to a 2.59 difference.

We also see a significant decrease in the mean differences across all questions when we prompt the LLM to first detect the presence or absence of spin in a given abstract and then answer the interpretation question. The mean differences were much lower than baseline for all questions and were even lower than the reference label approach for treatment benefit, study rigor, and interest to read the full-text. The mean difference for the treatment benefit question was 1.14 compared to 3.38 for the baseline and 1.94 for the reference label approach. Table~\ref{tab:llm_output_example} presents an example of GPT4o Mini's numerical outputs to the treatment benefit question, using different prompting strategies.

\begin{table*}[ht]
\footnotesize
\floatconts
  {tab:llm_output_example}
  {\caption{This table presents how GPT-4o Mini's numerical score outputs (on a scale of 0 to 10) for the treatment benefit question (Text Box in Section~\ref{box:questions}) vary based on the input abstract and the prompting strategy used. Higher scores indicate a greater perceived treatment benefit. The results highlight differences in scoring between abstracts with and without spin. Notably, the “Detect + Interpret” strategy yields the smallest difference between these abstracts, suggesting that GPT-4o Mini does not interpret the spun abstract as substantially more favorable than the unspun version.}}
  {\begin{tabular}{m{0.29\textwidth} 
      >{\centering\arraybackslash}m{0.11\textwidth} 
      >{\centering\arraybackslash}m{0.11\textwidth} 
      >{\centering\arraybackslash}m{0.11\textwidth} 
      >{\centering\arraybackslash}m{0.11\textwidth} 
      >{\centering\arraybackslash}m{0.11\textwidth}}
  \toprule
      \bfseries Abstract & 
      \bfseries Type & 
      \bfseries Baseline & 
      \bfseries + Ref \newline Label & 
      \bfseries + Model \newline Label & 
      \bfseries Detect \newline + Interpret \\
  \midrule
  
  \rowcolor{gray!20}
  \scriptsize ... The true‐positive (TP) rates were 14.4\% vs. 11.4\% (p=0.035, one‐sided) for the combined colposcopy and intervention A arm compared to colposcopy‐only arm, respectively, in women with either an atypical squamous cell (ASC) or low‐grade squamous intraepithelial lesion (LSIL) cytology result. TP rates were similar between the two arms among women referred for the evaluation of HSIL (high‐grade squamous intraepithelial lesion) ... Conclusion: \hlorange{Combining intervention A with colposcopy provides a clinically meaningful increase in the detection of CIN 2, 3} in women referred for the evaluation of mildly abnormal cytology results. 
  & with spin & 7 & 6 & 7 & 4 \\

  \scriptsize ... There was no statistically significant difference in the true positive rate between the 2 groups. The true positive rate was 19.9\% (218/1096) in the colposcopy‐only arm vs 21.8\% (238/1090) in the colposcopy plus intervention A arm; p=0.143 ... Conclusion: \hlblue{Combining intervention A with colposcopy was not more effective than colposcopy alone for the detection of CIN 2, 3} in women referred for the evaluation of mildly abnormal cytology results. 
  & without spin & 3 & 2 & 2 & 2 \\

  \bottomrule
  \end{tabular}}
\end{table*}

\section{Related Work}
\label{section:related_work}

% - publication bias & spin generally in medical literature (outside of NLP)
\paragraph{Spin in medical literature} Classification and prevalence of spin in medical literature has been studied extensively. 
In this literature, spin is commonly defined in one or more of the following ways: (1) Distorting the interpretation of results to present them more favorably, resulting in misleading conclusions; (2) Discrepancies between results and their favorable interpretation; (3) Attributing causality when the study design does not support it; and (4) Inappropriate extrapolation of results \citep{chiu2017spin}.

A systematic review revealed that spin is more prevalent in trials with nonsignificant primary outcomes and those with a higher risk of bias, such as nonrandomized studies \citep{chiu2017spin}. For instance, $\sim$60\% of RCTs with nonsignificant primary outcomes that were evaluated featured spin in their abstracts. 
Beyond RCTs, spin has also been identified as a common issue in systematic reviews and meta-analyses \citep{yavchitz2016new, nowlin2022spin, qureshi2024development}. Research has demonstrated the presence of spin across various medical disciplines, including oncology \citep{boutron2010reporting, wayant2019evaluation}, psychiatry and psychology \citep{jellison2020evaluation}, dental care \citep{su2023assessment}, wound care \citep{lockyer2013spin}, cardiovascular medicine \citep{khan2019level}, rheumatology \citep{mathieu2012misleading}, obesity research \citep{austin2019evaluation}, and emergency medicine \citep{reynolds2020evaluation}.

% - NLP for detecting spin 
\paragraph{NLP for detecting spin} One of the earliest efforts in automated spin detection was by \citet{koroleva2017contribution}, who proposed a pipeline that used rule-based and deep learning methods to identify key entities and comparative sentences (e.g., ``Treatment A was better than treatment B in terms of efficacy.'') to analyze RCT abstracts from PubMed.
This laid the foundation for subsequent research, including the creation of a corpus of biomedical articles annotated for spin \citep{koroleva2018annotating} and the development of DeSpin, a prototype tool designed to assist authors and reviewers in detecting spin in RCT abstracts \citep{koroleva2020despin}. 
DeSpin adopted a combination of rule-based methods and machine learning models---BERT \citep{devlin2018bert}, BioBERT \citep{lee2020biobert}, and SciBERT \citep{beltagy2019scibert}---to extract trial design information and identify spin. 
Our work extends this line of inquiry, evaluating modern LLMs for spin-related tasks.

% - NLP for summarizing/simplifying medical texts
\paragraph{NLP for simplifying medical texts} Several studies have explored the use of NLP technologies to simplify medical texts, which are often laden with jargon, to make them more accessible to lay readers \citep{ondov2022survey}. Recent advancements in deep learning and LLMs have enabled the simplification of medical abstracts \citep{devaraj2021paragraph, shaib-etal-2023-summarizing} and patient notes, including radiology reports \citep{bala2020patient, jeblick2024chatgpt}. An interactive tool has also been developed to provide simplified summaries of medical articles, assisting lay readers in understanding complex medical texts \citep{august2023paper}. Additionally, efforts have been made to improve evaluation methods for medical text simplification by creating high-quality corpora \citep{devaraj2022evaluating, joseph2023multilingual}. However, existing work does not address spin in medical literature.

\section{Discussion and Conclusions}

We empirically investigated the susceptibility of LLMs to spin in medical articles. 
Specifically, we evaluated 22 LLMs of various sizes and types (generalist and biomedical; closed and open weight) on tasks intended to provide insights regarding the capabilities and limitations of LLMs with respect to handling spin.

In particular, we first assessed the ability of LLMs to detect the presence of spin in abstracts of RCT reports.
LLMs demonstrated moderate to strong performance on this task (average accuracy across LLMs: 0.67). 
Despite being trained on medical literature, biomedical LLMs did not consistently outperform generalist models. 

Next we examined the extent to which LLMs are influenced by spin when tasked with interpreting trial results. 
By comparing numerical interpretation scores generated by LLMs for spun and unspun abstracts, we found that LLMs are generally \emph{more} susceptible to spin than are human experts. 
Across all model types and sizes considered, LLMs interpreted trial results more favorably when spin was present. 
This susceptibility reveals a significant limitation of LLMs for unbiased interpretation of trial reports. Recent work has touted LLM's mathematical reasoning capabilities \citep{imani2023mathprompter, romera2024mathematical}, but the ability to recognize spin as a discrepancy between numerical results and language demands more in discourse reasoning. 

Finally, we explored whether LLMs might propagate spin, specifically when generating simplified versions of medical abstracts. 
We found that this is indeed a risk: LLMs seem to consistently propagate spin, insofar as simplified versions of spun abstracts were interpreted more favorably by LLM evaluators. 
However, it remains unclear whether LLMs amplify spin beyond the level present in the original text. 

While these findings together suggest that LLMs are indeed susceptible to spin, we have also proposed and evaluated potential strategies to reduce its impact on LLM outputs. 
Specifically, we found that LLM susceptibility can be reduced via intentional prompting, e.g., providing additional context about the presence of spin, or instructing the model to simultaneously detect and interpret spin, significantly reducing the exaggeration of treatment benefits. The significant benefits of using this joint prompting approach align with existing work on prompting strategies to improve LLM reasoning \citep{qiao2023reasoning}.
Our results suggest that careful prompt engineering may be crucial for developing and designing LLMs to be more reliable for biomedical applications.

The demonstrated susceptibility of LLMs to spin warrants careful consideration as these models are increasingly used to analyze and synthesize medical literature. Although LLMs show baseline vulnerability to spin, our findings suggest they can be effectively prompted to detect and mitigate its influence. Future research should focus on developing robust strategies to reduce spin susceptibility, ultimately supporting more accurate evidence synthesis for clinical decision-making.

\subsection*{Limitations}

Our evaluation relies on a small (but high-quality) dataset of manually selected and edited oncology trials; this may limit the generalizability of our findings. 
Future work would ideally explore larger, more diverse evaluation datasets to deepen our analysis of LLM susceptibility to spin in medical literature.

Another limitation concerns our assumptions regarding supervision. We primarily evaluated the zero-shot capabilities of LLMs in detecting spin in, interpreting trial results from, and generating simplified versions of published trial results. 
Few-shot prompting or fine-tuning would probably improve performance on these tasks, though would require collecting annotations.

For evaluating simplified versions of abstracts generated by LLMs, we used two proprietary, closed-source LLMs within an LLM-as-evaluator framework. This study does not compare LLM-generated evaluation scores with those from lay human evaluators, limiting our ability to confirm alignment between automated assessments and human judgments. Future work should incorporate human evaluations to further validate these findings.

% \section{Conclusion}

% We performed several analyses using a variety of LLMs to explore how susceptible LLMs are to spin in medical literature.
% Using a dataset of spun and unspun abstract pairs, we showed that LLMs are more likely to favorably interpret the reported trial results when ``reading'' an abstract containing spin than one without, even though they can detect it. Additionally, we showed that LLMs can propagate spin when generating simplified versions of medical abstracts. Our findings confirm that LLMs are vulnerable to spin, but we also found that simple prompting strategies can reduce its impact. This highlights the importance of understanding how bias in medical publications can affect LLM outputs.

\acks{This research was supported by the National Institutes of Health (NIH) grant 1R01LM014600-01 and National Science Foundation (NSF) grant IIS-2145479.}

\bibliography{bibliography}

\appendix

\section{LLM Details \& Compute}

We used a total of 4 x NVIDIA A100 GPUs to conduct our experiments.

\paragraph{Generalist closed-source/proprietary:} We used API interfaces provided by OpenAI, Anthropic, and Google to interact with their proprietary language models. For OpenAI models, we used GPT-4o (\verb|gpt-4o-2024-08-06|), GPT-4o-mini (\verb|gpt-4o-mini|), and GPT-3.5 (\verb|gpt-3.5-turbo-0125|). For Anthropic’s Claude models, we tested Claude 3.5 Haiku (\verb|claude-3-5-haiku-20241022|) and Claude 3.5 Sonnet (\verb|claude-3-5-sonnet-20241022|). For Google’s Gemini models, we used Gemini 1.5 Flash (\verb|gemini-1.5-flash|) and Gemini 1.5 Flash 8B (\verb|gemini-1.5-flash-8b|). Across all models and experiments, we set the temperature parameter to 0 to ensure deterministic outputs.

\paragraph{Generalist open-weight:} All the generalist open-weight models were downloaded from HuggingFace's Model Hub\footnote{\url{https://huggingface.co/models}}. We set the parameter for \verb|do_sample| as false for all experiments to ensure deterministic outputs.

\paragraph{Biomedical open-weight:} Similar to the generalist open-weight models, the biomedical models were also downloaded via HuggingFace. The parameter for \verb|do_sample| was also set to false for all experiments.

\section{Zero-Shot Prompts}
\label{appendix:prompts}

\subsection{Detection of Spin}
\label{appendix:detection_prompt}

We provide the exact prompt used in our study for detecting spin below to ensure reproducibility. The prompt was designed to elicit a binary answer of a given abstract.

\begin{tcolorbox}[colback=gray!10, colframe=gray!50, arc=4mm, breakable, enhanced, boxrule=0.4mm, toptitle=0mm, bottomtitle=0mm]
\small
\texttt{Spin or misrepresentation of study findings can be used to influence, positively, the interpretation of statistically nonsignificant randomized controlled trials (RCTs), for example, by emphasizing the apparent benefit of a secondary outcome or findings from a subgroup of patients.}\\
\texttt{Does the following clinical trial abstract contain spin (yes/no)?}\\
\texttt{Answer only with `yes' or `no'. Do not provide any explanations.}\\

\texttt{Abstract: \textbf{\{ABSTRACT\}}}
\end{tcolorbox}

\subsection{Interpretation of Trial Results} 
\label{appendix:interpretation_prompts}

Below, we provide the exact prompt used to guide the LLM in interpreting the results of a given abstract.

\begin{tcolorbox}[colback=gray!10, colframe=gray!50, arc=4mm, breakable, enhanced, boxrule=0.4mm, toptitle=0mm, bottomtitle=0mm]
\small
\texttt{This abstract describes a study evaluating a treatment in the field of cancer published in a peer-reviewed journal.}\\
\texttt{We appreciate that in clinical practice you would need to read the full article to make a final decision. However, the full article is not always freely available and people sometimes make decisions based on the abstract.}\\
\texttt{Based on the information reported in the abstract, please answer the following question about the treatment. Only output a score between 0-10. Do not provide any explanations.}\\

\texttt{Abstract: \textbf{\{ABSTRACT\}}}\\
\texttt{Question: \textbf{\{QUESTION\}}}
\end{tcolorbox}

For interpreting the trial results from the simplified abstracts, we used the following prompt:

\begin{tcolorbox}[colback=gray!10, colframe=gray!50, arc=4mm, breakable, enhanced, boxrule=0.4mm, toptitle=0mm, bottomtitle=0mm]
\small
\texttt{This summary describes a study evaluating a treatment in the field of cancer published in a peer-reviewed journal.}\\
\texttt{We appreciate that in clinical practice you would need to read the full article to make a final decision. However, the full article is not always freely available and people sometimes make decisions based on the summary.}\\
\texttt{Based on the information reported in the summary, please answer the following question about the treatment. Only output a score between 0-10. Do not provide any explanations.}\\

\texttt{Abstract: \textbf{\{ABSTRACT\}}}\\
\texttt{Question: \textbf{\{QUESTION\}}}
\end{tcolorbox}

\subsection{Reducing the Effect of Spin}
\label{appendix:reduce_effect_prompts}

We experimented with indicating whether the given abstract contains spin or not to see if this would help reduce LLMs’ tendency to overstate favorable trial results in the presence of spin. Based on either the reference label or model-inferred label, we determine the text that is inserted for \texttt{\{IF\_CONTAINS\}} in the prompt. If the label is ``spin'' or ``yes'', the text would be \texttt{contains}. For labels that are ``no\_spin'' or ``no'', we insert the text \texttt{does not contain}.

\begin{tcolorbox}[colback=gray!10, colframe=gray!50, arc=4mm, breakable, enhanced, boxrule=0.4mm, toptitle=0mm, bottomtitle=0mm]
\small
\texttt{This abstract describes a study evaluating a treatment in the field of cancer published in a peer-reviewed journal.}\\
\texttt{We appreciate that in clinical practice you would need to read the full article to make a final decision. However, the full article is not always freely available and people sometimes make decisions based on the abstract.}\\
\texttt{Spin or misrepresentation of study findings can be used to influence, positively, the interpretation of statistically nonsignificant randomized controlled trials (RCTs), for example, by emphasizing the apparent benefit of a secondary outcome or findings from a subgroup of patients.}\\
\texttt{If an abstract contains spin, the content should be treated with a higher level of skepticism.}\\
\texttt{Based on the information reported in the abstract and the fact that it \{IF\_CONTAINS\} spin, please answer the following question about the treatment. Only output a score between 0-10. Do not provide any explanations.}\\

\texttt{Abstract: \textbf{\{ABSTRACT\}}}\\
\texttt{Question: \textbf{\{QUESTION\}}}
\end{tcolorbox}

Below is the prompt that we used for the ``joint prompting'' (spin detection + result interpretation) strategy. We prompt each question individually for a given abstract.

\begin{tcolorbox}[colback=gray!10, colframe=gray!50, arc=4mm, breakable, enhanced, boxrule=0.4mm, toptitle=0mm, bottomtitle=0mm]
\small
\texttt{This abstract describes a study evaluating a treatment in the field of cancer published in a peer-reviewed journal.}\\
\texttt{We appreciate that in clinical practice you would need to read the full article to make a final decision. However, the full article is not always freely available and people sometimes make decisions based on the abstract.}\\
\texttt{Spin or misrepresentation of study findings can be used to influence, positively, the interpretation of statistically nonsignificant randomized controlled trials (RCTs), for example, by emphasizing the apparent benefit of a secondary outcome or findings from a subgroup of patients.}\\
\texttt{Answer the following two questions with one JSON that contains the following keys:}\\
\texttt{detection: Does the following clinical trial abstract contain spin (yes/no)? Answer only with `yes' or `no'. Do not provide any explanations.}\\
\texttt{interpretation: Based on this abstract and previous spin detection, \textbf{\{QUESTION\}} Only output a score between 0-10. Do not provide any explanations. If an abstract contains spin, the contents should be treated with a higher level of skepticism.}\\

\texttt{Abstract: \textbf{\{ABSTRACT\}}}
\end{tcolorbox}

\subsection{Simplification of Abstracts} 
\label{appendix:simplification_prompt}

For simplifying medical abstracts for laypeople, we used the prompt used by \citet{joseph2024factpico}.

\begin{tcolorbox}[colback=gray!10, colframe=gray!50, arc=4mm]
\small
\texttt{My fifth grader asked me what this passage means: \textbf{\{ABSTRACT\}}}\\
\texttt{Help me summarize it for him, in plain language a fifth grader can understand.}
    
\end{tcolorbox}

\section{Linear Regression Models}
\label{appendix:linear_models}

Figures~\ref{fig:spin_label_regression_rigor}, \ref{fig:spin_label_regression_importance}, \ref{fig:spin_label_regression_full_text}, and \ref{fig:spin_label_regression_another_trial} show the coefficients and 95\% confidence intervals from the linear regression models run with
an indicator for the presence of spin in an abstract
as a predictor for study rigor, study importance, interest to read the full-text, and interest to run another trial.

\begin{figure*}%[htbp]
\floatconts
  {fig:spin_label_regression_rigor}
  {\caption{Coefficients from linear regression models with 95\% CI for each LLM showing how much different LLMs overestimate the rigor of study, when abstracts contain `spin'. In comparison with human experts (-0.59), LLMs show slightly greater susceptibility to spin.}}
  {\includegraphics[width=0.8\linewidth]{images/spin_label_regression_rigor}}
\end{figure*}

\begin{figure*}%[htbp]
\floatconts
  {fig:spin_label_regression_importance}
  {\caption{Coefficients from linear regression models with 95\% CI for each LLM showing how much different LLMs overestimate the importance of study, when abstracts contain `spin'. In comparison with human experts (-0.38), most LLMs show greater susceptibility to spin.}}
  {\includegraphics[width=0.8\linewidth]{images/spin_label_regression_importance}}
\end{figure*}

\begin{figure*}%[htbp]
\floatconts
  {fig:spin_label_regression_full_text}
  {\caption{Coefficients from linear regression models with 95\% CI for each LLM showing how much different LLMs overestimate the interest in full-text, when abstracts contain `spin'. In comparison with human experts (0.77), most LLMs show greater susceptibility to spin.}}
  {\includegraphics[width=0.8\linewidth]{images/spin_label_regression_full_text}}
\end{figure*}

\begin{figure*}%[htbp]
\floatconts
  {fig:spin_label_regression_another_trial}
  {\caption{Coefficients from linear regression models with 95\% CI for each LLM showing how much different LLMs overestimate the interest in another trial, when abstracts contain `spin'. In comparison with human experts (0.64), most LLMs show greater susceptibility to spin.}}
  {\includegraphics[width=0.8\linewidth]{images/spin_label_regression_another_trial}}
\end{figure*}

\section{Simplified Abstract Examples}
\label{appendix:simplification_examples}

Table~\ref{tab:example_pls} shows selected examples of simplified abstracts generated by LLMs. Further examples can be found in our project GitHub repo.

\begin{table*}
\footnotesize
\floatconts
  {tab:example_pls}
  {\caption{Examples of simplified abstracts generated by LLMs.}}
  {\begin{tabular}{p{0.97\textwidth}}
  \toprule
  \rowcolor{gray!20}
  \textbf{Model: \textcolor{RoyalBlue}{OpenBioLLM 70B} --- Original abstract type: \textcolor{red}{spin}} \newline \textbf{Plain language version}: This study looked at whether a certain treatment (called treatment A) could help people with brain tumors live longer and stay independent after surgery or radiosurgery. The researchers studied 359 patients who had one to three brain tumors and gave them either treatment A or just observed them without treatment. They found that treatment A did not make a difference in how long patients stayed independent or how long they lived overall. However, it did reduce the chance of the tumors coming back in the brain, which led to fewer deaths from the tumors spreading in the brain. So, while treatment A didn't improve independence or overall survival, it did help lower the risk of the tumors returning and causing problems in the brain.\\
  \textbf{Model: \textcolor{RoyalBlue}{OpenBioLLM 70B} --- Original abstract type: \textcolor{teal}{no spin}} \newline \textbf{Plain language version}: This study looked at whether a certain treatment (called treatment A) could help people with cancer in their brains live longer and stay independent after surgery or radiosurgery. The researchers compared a group of patients who received treatment A to a group of patients who were just observed and didn't receive any extra treatment. They found that there was no big difference between the two groups in terms of how long they lived or how long they were able to do their daily activities. However, they did find that the group of patients who received treatment A had less progression of the cancer in their brains compared to the group that was just observed. There were also some side effects reported, but overall, treatment A was not found to be better than just observing the patients for most outcomes.\\ \midrule
  \rowcolor{gray!20}
  \textbf{Model: \textcolor{RoyalBlue}{Gemini 1.5 Flash 8B} --- Original abstract type: \textcolor{red}{spin}} \newline \textbf{Plain language version}: Doctors are doing a big study to see if a new medicine (Treatment A) helps kids with a type of blood cancer called AML get better.  They looked at a bunch of kids getting the standard treatment, and another group getting the standard treatment *plus* Treatment A.  The kids in both groups were pretty much the same. The study found that Treatment A helped the kids' blood counts get better and stay better longer.  But, overall, the medicine didn't really change how long the kids lived. The survival rate was about the same for both groups (25\% to 32\% after 3 years). However, there was one important difference:  Girls who got Treatment A did better than boys.  Also, kids who only needed one round of the standard treatment did better.  The study also found that using Treatment A itself was a good thing for survival. The doctors need to do more studies to see if the girls did better because of their sex, or if there's something else going on with their blood cancer.  They need to look at the cancer's chromosomes to see if that plays a role.\\
  \textbf{Model: \textcolor{RoyalBlue}{Gemini 1.5 Flash 8B} --- Original abstract type: \textcolor{teal}{no spin}} \newline \textbf{Plain language version}: Doctors are doing a big study to see if a new medicine (Treatment A) helps kids with a type of blood cancer called acute myeloid leukemia (AML). They gave Treatment A to some kids and a regular medicine (cytarabine and idarubicine) to other kids.  They looked at how well the kids got better and how long they lived. The kids who got Treatment A did about the same as the kids who got the regular medicine.  The percentage of kids who got better quickly (complete response) was almost the same in both groups.  Also, the number of kids who lived for 3 years was not much different between the groups. So, the study showed that Treatment A wasn't better than the regular medicine at helping kids with AML.\\ \midrule
  \rowcolor{gray!20}
  \textbf{Model: \textcolor{RoyalBlue}{Llama3 Instruct 8B} --- Original abstract type: \textcolor{red}{spin}} \newline \textbf{Plain language version}: So, this passage is talking about a study that was done to help people who are about to start chemotherapy (a type of cancer treatment). The study wanted to see if giving them some information and education before they started chemotherapy would help them feel less stressed and worried. The study found that giving people this information did help them feel less worried about some specific things, like getting sick to their stomach or feeling uncomfortable during the treatment. But it didn't really help them feel less stressed overall. The study also found that the information helped some people who were already feeling really stressed and worried, but it didn't help everyone. The researchers think that this information might be helpful for some people, but they need to do more research to make sure it will work for people who are different from the ones in this study. So, in simple terms, the study was trying to figure out if giving people information before chemotherapy would help them feel better, and it found that it did help with some specific things, but not with feeling stressed overall.\\
  \textbf{Model: \textcolor{RoyalBlue}{Llama3 Instruct 8B} --- Original abstract type: \textcolor{teal}{no spin}} \newline \textbf{Plain language version}: So, the passage is talking about a study that was done to see if giving patients information about what to expect before they start chemotherapy would help reduce their stress and anxiety.Imagine you're going to get a shot, and you don't know what it's going to feel like or what might happen. You might be worried or scared. That's kind of what it's like for people who are about to start chemotherapy. They don't know what it's going to feel like or what side effects they might get. The study was trying to see if giving patients some information beforehand would help them feel less stressed and anxious. They gave some patients this information, and then they compared them to patients who didn't get the information. But, it turned out that the patients who got the information didn't actually feel less stressed or anxious than the patients who didn't get the information. The only thing that did change was that the patients who got the information were a little less worried about some specific things, like how their body would feel during the treatment. But, overall, the study found that giving patients information beforehand didn't really help them feel better. So, the conclusion is that just giving patients information before chemotherapy isn't enough to really help them feel less stressed or anxious.\\
  \bottomrule
  \end{tabular}}
\end{table*}

% \section{Human Evaluation Details}
% \label{appendix:human_eval}

% recruitment
% compensation
% survey/annotation tool
% screenshot of annotation tool

\end{document}
