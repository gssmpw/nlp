\begin{figure*}[t]
    \centering
    \hspace*{5em} 
    \includegraphics[width=.8\linewidth]{images/model_comparison_attack.png}
    \caption{Attack success rate for multi-dimensional cones for Gemma 2, Qwen 2.5 and Llama 3. The cone performance is measured via the performance of Monte Carlo samples which are depicted as boxplot.}
    \label{fig:subspace_model_comparison}
\end{figure*}
\section{Multi-dimensional Refusal Cones}\label{sec:cones}
\begin{graybox}
    Research Question: Is refusal in LLMs governed by a single direction, or does it emerge from a more complex underlying geometry?
\end{graybox}

We extend \oursacro to higher dimensions by searching for regions in activation space where all vectors control refusal behavior. For this, we optimize an orthonormal basis $\basis = [\basisvec_1, \dots, \basisvec_N]$ spanning an $N$-dimensional polyhedral cone $\mathcal{R}_N = \{\sum_{i=1}^N \lambda_i \basisvec_i \;|\; \lambda_i \geq 0\} \backslash \{\mathbf{0}\}$, where all directions \smash{$\direction \in \mathcal{R}_N$} satisfy the refusal properties (\Cref{def:refusal-properties}). Since all directions in the cone correspond to the same refusal concept, we also refer to this as a \emph{concept cone}.
The constraint $\lambda_i \geq 0$ ensures that all directions within the cone consistently strengthen refusal behavior. Without this constraint, allowing negative coefficients could introduce opposing effects, reducing the overall effectiveness. Enforcing orthogonality of the basis vectors prevents finding co-linear directions.
Note that in practice, directions in activation space cannot be scaled arbitrarily high without model degeneration, which effectively bounds $\lambda_i$. 
\setlength{\textfloatsep}{8pt}
\begin{algorithm}
\caption{Refusal Cone Optimization (RCO)}
\label{algo:subspace}
\input{algorithms/subspace}
\end{algorithm}

In \Cref{algo:subspace}, we describe the procedure to find the cone's basis vectors. The basis vectors are initialized randomly and iteratively optimized using projected gradient descent. We compute the previous losses defined in \Cref{algo:single_direction} on Monte Carlo samples from the cone, as well as on the basis vectors themselves. Computing the loss on the basis vectors improves both stability and the lower bounds of the ASR. This is because the basis vectors are the boundaries of the cone and thus tend to degrade first. After each step, we project the basis back onto the cone using the Gram-Schmidt orthogonalization procedure.
Because the directional ablation operation uses the normalized $\normdirection$ rather than $\direction$, sampling convex combinations of the basis vectors and normalizing them 
 would introduce a bias towards the basis vectors themselves.
Instead, we sample unit vectors in the cone uniformly to ensure better coverage of the space. %

\begin{figure*}[t]
    \centering
   \hspace*{5em} 
    \includegraphics[width=.9\linewidth]{images/qwen_attack.png}
    \caption{Refusal evaluation for different cone dimensions for the Qwen2.5 model family. The cone performance for models with fewer parameters degrades faster with increasing cone dimension compared to larger models.}
    \label{fig:subspace_modelsize}
\end{figure*}
\textbf{Can we find refusal concept cones?}
We train cones of increasing dimensionality using the same experimental setup as described in \Cref{sec:gradient-based-directions}. We measure the cone's effectiveness in mediating refusal by sampling 256 vectors from each cone and computing the ASRs of the samples for directional ablation. We show the results in \Cref{fig:subspace_model_comparison} and confirm that the directions in the cones have the desired refusal properties in \Cref{fig:refusal_properties}. Notably, we identify refusal-mediating cones with dimensions up to five across all tested models. This suggests that the activation space in language models exhibits a general property where refusal behavior is encoded within multi-dimensional cones rather than a single linear direction.

\textbf{Do larger models contain higher-dimensional cones?}\\
In \Cref{fig:subspace_modelsize}, we evaluate the effect of model size within the Qwen 2.5 family. We observe that across all model sizes, the lower bounds of cone performance degrade significantly as dimensionality increases. In other words, a higher number of sampled directions have low ASR.
Larger models appear to support higher-dimensional refusal cones. A plausible explanation is that models with larger residual stream dimensions (e.g., 5120 for the 14B model vs. 1536 for the 1.5B model) allow for more distinct and orthogonal directions that mediate refusal. Finally, in \Cref{fig:subspace-induce}, we confirm that directions sampled from these cones effectively induce refusal behavior, further supporting the notion that multiple axes contribute to the modelâ€™s refusal decision.
 
\textbf{Do different directions uniquely influence refusal?}\\
To further investigate the role of different vectors, we assess whether multiple sampled cone directions influence the model in complementary ways. Specifically, we sample varying numbers of directions from Gemma-2-2B's four-dimensional refusal cone and, for each prompt, select the most effective one under directional ablation (more details in \Cref{app:setup-details}). To ensure a fair comparison, we use temperature sampling with the single-dimension \oursacro direction to generate the same number of attacks and similarly select the most effective instance. We study Gemma 2 2B and sample from its four-dimensional cone, since performance degrades significantly for larger dimensions (see \Cref{fig:gemma-cones}).

\Cref{fig:asr_over_sampling} shows that sampling multiple directions leads to higher ASR compared to sampling with various temperatures in the low-sample regime. For a higher number of samples, the randomness dominates the success of the attack. However, the higher ASR in the low-sample regime suggests that different directions capture distinct, complementary aspects of the refusal mechanism. Additionally, \Cref{fig:asr_given_conedim}
reveals that ASR increases with cone dimensionality but plateaus at four dimensions. This trend indicates that higher-dimensional cones offer an advantage over single-direction manipulation, likely by influencing complementary mechanisms. The plateau likely occurs because the model does not support higher-dimensional refusal cones.
\begin{figure}[h]
    \centering
    \includegraphics[width=0.85\linewidth]{images/temperature_vs_subspace.png}
    \caption{ASR for best-of-N sampling using $N$ samples from the 4-dimensional refusal cone of Gemma-2-2B, compared to best-of-N sampling with temperature $T$ using the single-dimension \oursacro.}
    \label{fig:asr_over_sampling}
\end{figure}
\begin{mybox}
    \textbf{Key Takeaways.} We show that refusal mechanisms in LLMs span high-dimensional polyhedral cones, capturing diverse aspects of refusal behavior. This highlights their geometric complexity and demonstrates the effectiveness of our gradient-based method in identifying intricate structures.
\end{mybox}
