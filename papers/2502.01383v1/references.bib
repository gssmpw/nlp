@article{kozachenko1987entropy_of_random_vector,
    title = {Sample Estimate of the Entropy of a Random Vector},
    author = {L. F. Kozachenko and N. N. Leonenko},
    journal = {Problems Inform. Transmission},
    pages = {95--101},
    year = {1987},
    volume = {23},
    issue = {2},
}

@article{linsker1988self-organisation,
    author={Linsker, R.},
    journal={Computer}, 
    title={Self-organization in a perceptual network}, 
    year={1988},
    volume={21},
    number={3},
    pages={105-117},
    keywords={Intelligent networks;Biological information theory;Circuits;Biology computing;Animal structures;Neuroscience;Genetics;System testing;Neural networks;Constraint theory},
    doi={10.1109/2.36}
}

@article{bell1995infomax,
    title     = "An information-maximization approach to blind separation and
                 blind deconvolution",
    author    = "Bell, A J and Sejnowski, T J",
    abstract  = "We derive a new self-organizing learning algorithm that
                 maximizes the information transferred in a network of nonlinear
                 units. The algorithm does not assume any knowledge of the input
                 distributions, and is defined here for the zero-noise limit.
                 Under these conditions, information maximization has extra
                 properties not found in the linear case (Linsker 1989). The
                 nonlinearities in the transfer function are able to pick up
                 higher-order moments of the input distributions and perform
                 something akin to true redundancy reduction between units in the
                 output representation. This enables the network to separate
                 statistically independent components in the inputs: a
                 higher-order generalization of principal components analysis. We
                 apply the network to the source separation (or cocktail party)
                 problem, successfully separating unknown mixtures of up to 10
                 speakers. We also show that a variant on the network
                 architecture is able to perform blind deconvolution
                 (cancellation of unknown echoes and reverberation in a speech
                 signal). Finally, we derive dependencies of information transfer
                 on time delays. We suggest that information maximization
                 provides a unifying framework for problems in ``blind'' signal
                 processing.",
    journal   = "Neural Comput.",
    publisher = "MIT Press - Journals",
    volume    =  7,
    number    =  6,
    pages     = "1129--1159",
    month     =  nov,
    year      =  1995,
    language  = "en"
}

@article{kraskov2004KSG,
    title = {Estimating mutual information},
    author = {Kraskov, Alexander and St\"ogbauer, Harald and Grassberger, Peter},
    journal = {Phys. Rev. E},
    volume = {69},
    issue = {6},
    pages = {066138},
    numpages = {16},
    year = {2004},
    month = {Jun},
    publisher = {American Physical Society},
    doi = {10.1103/PhysRevE.69.066138},
    url = {https://link.aps.org/doi/10.1103/PhysRevE.69.066138}
}

@book{cover2006information_theory,
    author = {Cover, Thomas M. and Thomas, Joy A.},
    title = {Elements of Information Theory (Wiley Series in Telecommunications and Signal Processing)},
    year = {2006},
    publisher = {Wiley-Interscience},
    address = {USA}
}

@article{lecun2010mnist,
    title={MNIST handwritten digit database},
    author={LeCun, Yann and Cortes, Corinna and Burges, CJ},
    journal={ATT Labs [Online]. Available: http://yann.lecun.com/exdb/mnist},
    volume={2},
    year={2010}
}

@article{tishby2015bottleneck_principle,
    title={Deep learning and the information bottleneck principle},
    author={Naftali Tishby and Noga Zaslavsky},
    journal={2015 IEEE Information Theory Workshop (ITW)},
    year={2015},
    pages={1-5}
}

@inproceedings{chen2016infogan,
    author       = {Xi Chen and
                    Yan Duan and
                    Rein Houthooft and
                    John Schulman and
                    Ilya Sutskever and
                    Pieter Abbeel},
    editor       = {Daniel D. Lee and
                    Masashi Sugiyama and
                    Ulrike von Luxburg and
                    Isabelle Guyon and
                    Roman Garnett},
    title        = {InfoGAN: Interpretable Representation Learning by Information Maximizing
                    Generative Adversarial Nets},
    booktitle    = {Advances in Neural Information Processing Systems 29: Annual Conference
                    on Neural Information Processing Systems 2016, December 5-10, 2016,
                    Barcelona, Spain},
    pages        = {2172--2180},
    year         = {2016},
    url          = {https://proceedings.neurips.cc/paper/2016/hash/7c9d0b1f96aebd7b5eca8c3edaa19ebb-Abstract.html},
    timestamp    = {Mon, 16 May 2022 15:41:51 +0200},
    biburl       = {https://dblp.org/rec/conf/nips/ChenCDHSSA16.bib},
    bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{xu2017IT_analysis,
    author = {Xu, Aolin and Raginsky, Maxim},
    booktitle = {Advances in Neural Information Processing Systems},
    editor = {I. Guyon and U. Von Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett},
    pages = {},
    publisher = {Curran Associates, Inc.},
    title = {Information-theoretic analysis of generalization capability of learning algorithms},
    url = {https://proceedings.neurips.cc/paper_files/paper/2017/file/ad71c82b22f4f65b9398f76d8be4c615-Paper.pdf},
    volume = {30},
    year = {2017}
}

@article{berrett2017independence_testing,
    author = {Berrett, Thomas and Samworth, Richard},
    year = {2017},
    month = {11},
    pages = {},
    title = {Nonparametric independence testing via mutual information},
    volume = {106},
    journal = {Biometrika},
    doi = {10.1093/biomet/asz024}
}

@inproceedings{sen2017conditional_independence_test,
    author = {Sen, Rajat and Suresh, Ananda Theertha and Shanmugam, Karthikeyan and Dimakis, Alexandros G and Shakkottai, Sanjay},
    booktitle = {Advances in Neural Information Processing Systems},
    editor = {I. Guyon and U. Von Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett},
    pages = {},
    publisher = {Curran Associates, Inc.},
    title = {Model-Powered Conditional Independence Test},
    url = {https://proceedings.neurips.cc/paper_files/paper/2017/file/02f039058bd48307e6f653a2005c9dd2-Paper.pdf},
    volume = {30},
    year = {2017}
}

@inproceedings{belghazi2018mine,
    title = {Mutual Information Neural Estimation},
    author = {Belghazi, Mohamed Ishmael and Baratin, Aristide and Rajeshwar, Sai and Ozair, Sherjil and Bengio, Yoshua and Courville, Aaron and Hjelm, Devon},
    booktitle = {Proceedings of the 35th International Conference on Machine Learning},
    pages = {531--540},
    year = {2018},
    editor = {Dy, Jennifer and Krause, Andreas},
    volume = {80},
    series = {Proceedings of Machine Learning Research},
    month = {07},
    publisher = {PMLR},
    pdf = {http://proceedings.mlr.press/v80/belghazi18a/belghazi18a.pdf},  url = {https://proceedings.mlr.press/v80/belghazi18a.html},
    abstract = {We argue that the estimation of mutual information between high dimensional continuous random variables can be achieved by gradient descent over neural networks. We present a Mutual Information Neural Estimator (MINE) that is linearly scalable in dimensionality as well as in sample size, trainable through back-prop, and strongly consistent. We present a handful of applications on which MINE can be used to minimize or maximize mutual information. We apply MINE to improve adversarially trained generative models. We also use MINE to implement the Information Bottleneck, applying it to supervised classification; our results demonstrate substantial improvement in flexibility and performance in these settings.}
}

@article{weglarczyk2018kde_review,
    author = {Weglarczyk, Stanislaw},
    year = {2018},
    month = {01},
    pages = {00037},
    title = {Kernel density estimation and its application},
    volume = {23},
    journal = {ITM Web of Conferences},
    doi = {10.1051/itmconf/20182300037}
}

@article{kairen2018individual_neurons,
    author={Amjad, Rana Ali and Liu, Kairen and Geiger, Bernhard C.},
    journal={IEEE Transactions on Neural Networks and Learning Systems}, 
    title={Understanding Neural Networks and Individual Neuron Importance via Information-Ordered Cumulative Ablation}, 
    year={2022},
    volume={33},
    number={12},
    pages={7842-7852},
    doi={10.1109/TNNLS.2021.3088685}
}

@inproceedings{hjelm2018deep_infomax,
    title={Learning deep representations by mutual information estimation and maximization},
    author={R Devon Hjelm and Alex Fedorov and Samuel Lavoie-Marchildon and Karan Grewal and Phil Bachman and Adam Trischler and Yoshua Bengio},
    booktitle={International Conference on Learning Representations},
    year={2019},
    url={https://openreview.net/forum?id=Bklr3j0cKX},
}

@inproceedings{stratos2019infomax,
    title = "Mutual Information Maximization for Simple and Accurate Part-Of-Speech Induction",
    author = "Stratos, Karl",
    editor = "Burstein, Jill  and
      Doran, Christy  and
      Solorio, Thamar",
    booktitle = "Proceedings of the 2019 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)",
    month = jun,
    year = "2019",
    address = "Minneapolis, Minnesota",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/N19-1113/",
    doi = "10.18653/v1/N19-1113",
    pages = "1095--1104",
    abstract = "We address part-of-speech (POS) induction by maximizing the mutual information between the induced label and its context. We focus on two training objectives that are amenable to stochastic gradient descent (SGD): a novel generalization of the classical Brown clustering objective and a recently proposed variational lower bound. While both objectives are subject to noise in gradient updates, we show through analysis and experiments that the variational lower bound is robust whereas the generalized Brown objective is vulnerable. We obtain strong performance on a multitude of datasets and languages with a simple architecture that encodes morphology and context."
}

@inproceedings{bachman2019DIM_across_views,
    author = {Bachman, Philip and Hjelm, R Devon and Buchwalter, William},
    booktitle = {Advances in Neural Information Processing Systems},
    editor = {H. Wallach and H. Larochelle and A. Beygelzimer and F. d\textquotesingle Alch\'{e}-Buc and E. Fox and R. Garnett},
    pages = {},
    publisher = {Curran Associates, Inc.},
    title = {Learning Representations by Maximizing Mutual Information Across Views},
    url = {https://proceedings.neurips.cc/paper_files/paper/2019/file/ddf354219aac374f1d40b7e760ee5bb7-Paper.pdf},
    volume = {32},
    year = {2019}
}

@inproceedings{petar2019DGI,
    title={Deep Graph Infomax},
    author={Petar Veličković and William Fedus and William L. Hamilton and Pietro Liò and Yoshua Bengio and R Devon Hjelm},
    booktitle={International Conference on Learning Representations},
    year={2019},
    url={https://openreview.net/forum?id=rklz9iAcKQ},
}

@misc{oord2019infoNCE,
      title={Representation Learning with Contrastive Predictive Coding}, 
      author={Aaron van den Oord and Yazhe Li and Oriol Vinyals},
      year={2019},
      eprint={1807.03748},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/1807.03748}, 
}

@inproceedings{goldfeld2019estimating_information_flow,
    title={Estimating Information Flow in Deep Neural Networks},
    author={Ziv Goldfeld and Ewout van den Berg and Kristjan H. Greenewald and Igor V. Melnyk and Nam H. Nguyen and Brian Kingsbury and Yury Polyanskiy},
    booktitle={ICML},
    year={2019}
}

@article{berrett2019efficient_knn_entropy_estimation,
    author = {Berrett, Thomas B. and Samworth, Richard J. and Yuan, Ming},
    doi = {10.1214/18-AOS1688},
    fjournal = {Annals of Statistics},
    journal = {Ann. Statist.},
    month = {02},
    number = {1},
    pages = {288--318},
    publisher = {The Institute of Mathematical Statistics},
    title = {Efficient multivariate entropy estimation via $k$-nearest neighbour distances},
    url = {https://doi.org/10.1214/18-AOS1688},
    volume = {47},
    year = {2019}
}

@inproceedings{tschannen2020on_DIM,
    title={On Mutual Information Maximization for Representation Learning},
    author={Michael Tschannen and Josip Djolonga and Paul K. Rubenstein and Sylvain Gelly and Mario Lucic},
    booktitle={International Conference on Learning Representations},
    year={2020},
    url={https://openreview.net/forum?id=rkxoh24FPH}
}

@article{goldfeld2020convergence_of_SEM_entropy_estimation,
    author={Z. {Goldfeld} and K. {Greenewald} and J. {Niles-Weed} and Y. {Polyanskiy}},
    journal={IEEE Transactions on Information Theory}, 
    title={Convergence of Smoothed Empirical Measures With Applications to Entropy Estimation}, 
    year={2020},
    volume={66},
    number={7},
    pages={4368-4391},
    doi={10.1109/TIT.2020.2975480}
}

@InProceedings{mcallester2020limitations_MI,
    title = 	 {Formal Limitations on the Measurement of Mutual Information},
    author =       {McAllester, David and Stratos, Karl},
    booktitle = 	 {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},
    pages = 	 {875--884},
    year = 	 {2020},
    editor = 	 {Chiappa, Silvia and Calandra, Roberto},
    volume = 	 {108},
    series = 	 {Proceedings of Machine Learning Research},
    month = 	 {08},
    publisher =    {PMLR},
    pdf = 	 {http://proceedings.mlr.press/v108/mcallester20a/mcallester20a.pdf},
    url = 	 {https://proceedings.mlr.press/v108/mcallester20a.html},
    abstract = 	 {Measuring mutual information from finite data is difficult. Recent work has considered variational methods maximizing a lower bound. In this paper, we prove that serious statistical limitations are inherent to any method of measuring mutual information. More specifically, we show that any distribution-free high-confidence lower bound on mutual information estimated from N samples cannot be larger than O(ln N).}
}

@inproceedings{ardizzone2020training_normflows,
    author = {Ardizzone, Lynton and Mackowiak, Radek and Rother, Carsten and K\"{o}the, Ullrich},
    booktitle = {Advances in Neural Information Processing Systems},
    editor = {H. Larochelle and M. Ranzato and R. Hadsell and M.F. Balcan and H. Lin},
    pages = {7828--7840},
    publisher = {Curran Associates, Inc.},
    title = {Training Normalizing Flows with the Information Bottleneck for Competitive Generative Classification},
    url = {https://proceedings.neurips.cc/paper_files/paper/2020/file/593906af0d138e69f49d251d3e7cbed0-Paper.pdf},
    volume = {33},
    year = {2020}
}

@InProceedings{abernethy2020reasoning_conditional_MI,
    title = 	 {{R}easoning {A}bout {G}eneralization via {C}onditional {M}utual {I}nformation},
    author =       {Steinke, Thomas and Zakynthinou, Lydia},
    booktitle = 	 {Proceedings of Thirty Third Conference on Learning Theory},
    pages = 	 {3437--3452},
    year = 	 {2020},
    editor = 	 {Abernethy, Jacob and Agarwal, Shivani},
    volume = 	 {125},
    series = 	 {Proceedings of Machine Learning Research},
    month = 	 {09--12 Jul},
    publisher =    {PMLR},
    pdf = 	 {http://proceedings.mlr.press/v125/steinke20a/steinke20a.pdf},
    url = 	 {https://proceedings.mlr.press/v125/steinke20a.html},
    abstract = 	 { We provide an information-theoretic framework for studying the generalization properties of machine learning algorithms. Our framework ties together existing approaches, including uniform convergence bounds and recent methods for adaptive data analysis. Specifically, we use Conditional Mutual Information (CMI) to quantify how well the input (i.e., the training data) can be recognized given the output (i.e., the trained model) of the learning algorithm. We show that bounds on CMI can be obtained from VC dimension, compression schemes, differential privacy, and other methods. We then show that bounded CMI implies various forms of generalization.}
}

@inproceedings{song2020understanding_limitations,
    title={Understanding the Limitations of Variational Mutual Information Estimators},
    author={Jiaming Song and Stefano Ermon},
    booktitle={International Conference on Learning Representations},
    year={2020},
    url={https://openreview.net/forum?id=B1x62TNtDS}
}

@inproceedings{rhodes2020telescoping,
    author = {Rhodes, Benjamin and Xu, Kai and Gutmann, Michael U.},
    booktitle = {Advances in Neural Information Processing Systems},
    editor = {H. Larochelle and M. Ranzato and R. Hadsell and M.F. Balcan and H. Lin},
    pages = {4905--4916},
    publisher = {Curran Associates, Inc.},
    title = {Telescoping Density-Ratio Estimation},
    url = {https://proceedings.neurips.cc/paper_files/paper/2020/file/33d3b157ddc0896addfb22fa2a519097-Paper.pdf},
    volume = {33},
    year = {2020}
}


@InProceedings{baram2021action_redundancy,
    title = 	 {Action redundancy in reinforcement learning},
    author =       {Baram, Nir and Tennenholtz, Guy and Mannor, Shie},
    booktitle = 	 {Proceedings of the Thirty-Seventh Conference on Uncertainty in Artificial Intelligence},
    pages = 	 {376--385},
    year = 	 {2021},
    editor = 	 {de Campos, Cassio and Maathuis, Marloes H.},
    volume = 	 {161},
    series = 	 {Proceedings of Machine Learning Research},
    month = 	 {27--30 Jul},
    publisher =    {PMLR},
    pdf = 	 {https://proceedings.mlr.press/v161/baram21a/baram21a.pdf},
    url = 	 {https://proceedings.mlr.press/v161/baram21a.html},
    abstract = 	 {Maximum Entropy (MaxEnt) reinforcement learning is a powerful learning paradigm which seeks to maximize return under entropy regularization. However, action entropy does not necessarily coincide with state entropy, e.g., when multiple actions produce the same transition. Instead, we propose to maximize the transition entropy, i.e., the entropy of next states. We show that transition entropy can be described by two terms; namely, model-dependent transition entropy and <b>action redundancy</b>. Particularly, we explore the latter in both deterministic and stochastic settings and develop tractable approximation methods in a near model-free setup. We construct algorithms to minimize action redundancy and demonstrate their effectiveness on a synthetic environment with multiple redundant actions as well as contemporary benchmarks in Atari and Mujoco. Our results suggest that action redundancy is a fundamental problem in reinforcement learning.}
}

@inproceedings{goldfeld2021sliced_MI,
    title={Sliced Mutual Information: A Scalable Measure of Statistical Dependence},
    author={Ziv Goldfeld and Kristjan Greenewald},
    booktitle={Advances in Neural Information Processing Systems},
    editor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},
    year={2021},
    url={https://openreview.net/forum?id=SvrYl-FDq2}
}

@article{Ao_Li_2022entropy_estimation_normflows,
    title={Entropy Estimation via Normalizing Flow},
    volume={36},
    url={https://ojs.aaai.org/index.php/AAAI/article/view/21237},
    DOI={10.1609/aaai.v36i9.21237},
    abstractNote={Entropy estimation is an important problem in information theory and statistical science. Many popular entropy estimators suffer from fast growing estimation bias with respect to dimensionality, rendering them unsuitable for high dimensional problems. In this work we propose a transformbased method for high dimensional entropy estimation, which consists of the following two main ingredients. First by modifying the k-NN based entropy estimator, we propose a new estimator which enjoys small estimation bias for samples that are close to a uniform distribution. Second we design a normalizing flow based mapping that pushes samples toward a uniform distribution, and the relation between the entropy of the original samples and the transformed ones is also derived. As a result the entropy of a given set of samples is estimated by first transforming them toward a uniform distribution and then applying the proposed estimator to the transformed samples. Numerical experiments demonstrate the effectiveness of the method for high dimensional entropy estimation problems.},
    number={9},
    journal={Proceedings of the AAAI Conference on Artificial Intelligence},
    author={Ao, Ziqiao and Li, Jinglai},
    year={2022},
    month={Jun.},
    pages={9990-9998}
}

@inproceedings{goldfeld2022k_sliced_MI,
    title={\$k\$-Sliced Mutual Information: A Quantitative Study of Scalability with Dimension},
    author={Ziv Goldfeld and Kristjan Greenewald and Theshani Nuradha and Galen Reeves},
    booktitle={Advances in Neural Information Processing Systems},
    editor={Alice H. Oh and Alekh Agarwal and Danielle Belgrave and Kyunghyun Cho},
    year={2022},
    url={https://openreview.net/forum?id=L-ceBdl2DPb}
}

@InProceedings{cunningham2022principal_component_flows,
    title = 	 {Principal Component Flows},
    author =       {Cunningham, Edmond and Cobb, Adam D and Jha, Susmit},
    booktitle = 	 {Proceedings of the 39th International Conference on Machine Learning},
    pages = 	 {4492--4519},
    year = 	 {2022},
    editor = 	 {Chaudhuri, Kamalika and Jegelka, Stefanie and Song, Le and Szepesvari, Csaba and Niu, Gang and Sabato, Sivan},
    volume = 	 {162},
    series = 	 {Proceedings of Machine Learning Research},
    month = 	 {17--23 Jul},
    publisher =    {PMLR},
    pdf = 	 {https://proceedings.mlr.press/v162/cunningham22a/cunningham22a.pdf},
    url = 	 {https://proceedings.mlr.press/v162/cunningham22a.html},
    abstract = 	 {Normalizing flows map an independent set of latent variables to their samples using a bijective transformation. Despite the exact correspondence between samples and latent variables, their high level relationship is not well understood. In this paper we characterize the geometric structure of flows using principal manifolds and understand the relationship between latent variables and samples using contours. We introduce a novel class of normalizing flows, called principal component flows (PCF), whose contours are its principal manifolds, and a variant for injective flows (iPCF) that is more efficient to train than regular injective flows. PCFs can be constructed using any flow architecture, are trained with a regularized maximum likelihood objective and can perform density estimation on all of their principal manifolds. In our experiments we show that PCFs and iPCFs are able to learn the principal manifolds over a variety of datasets. Additionally, we show that PCFs can perform density estimation on data that lie on a manifold with variable dimensionality, which is not possible with existing normalizing flows.}
}

@article{duong2023normflows_for_conditional_independence_testing,
    author = {Duong, Bao and Nguyen, Thin},
    year = {2023},
    month = {08},
    pages = {},
    title = {Normalizing flows for conditional independence testing},
    volume = {66},
    journal = {Knowledge and Information Systems},
    doi = {10.1007/s10115-023-01964-w}
}

@inproceedings{czyz2023beyond_normal,
    title={Beyond Normal: On the Evaluation of Mutual Information Estimators},
    author={Pawe{\l} Czy{\.z} and Frederic Grabowski and Julia E Vogt and Niko Beerenwinkel and Alexander Marx},
    booktitle={Thirty-seventh Conference on Neural Information Processing Systems},
    year={2023},
    url={https://openreview.net/forum?id=25vRtG56YH}
}

@inproceedings{kristjan2023smoothed_entropy_PCA,
    author       = {Kristjan H. Greenewald and
                    Brian Kingsbury and
                    Yuancheng Yu},
    title        = {High-Dimensional Smoothed Entropy Estimation via Dimensionality Reduction},
    booktitle    = {{IEEE} International Symposium on Information Theory, {ISIT} 2023,
                    Taipei, Taiwan, June 25-30, 2023},
    pages        = {2613--2618},
    publisher    = {{IEEE}},
    year         = {2023},
    url          = {https://doi.org/10.1109/ISIT54713.2023.10206641},
    doi          = {10.1109/ISIT54713.2023.10206641},
    timestamp    = {Mon, 28 Aug 2023 17:20:14 +0200},
    biburl       = {https://dblp.org/rec/conf/isit/GreenewaldKY23.bib},
    bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{tsur2023max_sliced_MI,
    title={Max-Sliced Mutual Information},
    author={Dor Tsur and Ziv Goldfeld and Kristjan Greenewald},
    booktitle={Thirty-seventh Conference on Neural Information Processing Systems},
    year={2023},
    url={https://openreview.net/forum?id=ce9B2x3zQa}
}

@inproceedings{fayad2023optimal_sliced_MI,
    title={On Slicing Optimality for Mutual Information},
    author={Ammar Fayad and Majd Ibrahim},
    booktitle={Thirty-seventh Conference on Neural Information Processing Systems},
    year={2023},
    url={https://openreview.net/forum?id=JMuKfZx2xU}
}

@article{stimper2023normflows, 
    author = {Vincent Stimper and David Liu and Andrew Campbell and Vincent Berenz and Lukas Ryll and Bernhard Schölkopf and José Miguel Hernández-Lobato}, 
    title = {normflows: A PyTorch Package for Normalizing Flows}, 
    journal = {Journal of Open Source Software}, 
    volume = {8},
    number = {86}, 
    pages = {5361}, 
    publisher = {The Open Journal}, 
    doi = {10.21105/joss.05361}, 
    url = {https://doi.org/10.21105/joss.05361}, 
    year = {2023}
}

@article{duong2023dine,
    title={Diffeomorphic Information Neural Estimation},
    volume={37},
    url={https://ojs.aaai.org/index.php/AAAI/article/view/25908},
    DOI={10.1609/aaai.v37i6.25908},
    abstractNote={Mutual Information (MI) and Conditional Mutual Information (CMI) are multi-purpose tools from information theory that are able to naturally measure the statistical dependencies between random variables, thus they are usually of central interest in several statistical and machine learning tasks, such as conditional independence testing and representation learning. However, estimating CMI, or even MI, is infamously challenging due the intractable formulation. In this study, we introduce DINE (Diffeomorphic Information Neural Estimator)–a novel approach for estimating CMI of continuous random variables, inspired by the invariance of CMI over diffeomorphic maps. We show that the variables of interest can be replaced with appropriate surrogates that follow simpler distributions, allowing the CMI to be efficiently evaluated via analytical solutions. Additionally, we demonstrate the quality of the proposed estimator in comparison with state-of-the-arts in three important tasks, including estimating MI, CMI, as well as its application in conditional independence testing. The empirical evaluations show that DINE consistently outperforms competitors in all tasks and is able to adapt very well to complex and high-dimensional relationships.},
    number={6},
    journal={Proceedings of the AAAI Conference on Artificial Intelligence},
    author={Duong, Bao and Nguyen, Thin},
    year={2023},
    month={Jun.},
    pages={7468-7475}
}

@misc{federici2023hybrid_MI_estimation,
    title={On the Effectiveness of Hybrid Mutual Information Estimation}, 
    author={Marco Federici and David Ruhe and Patrick Forré},
    year={2023},
    eprint={2306.00608},
    archivePrefix={arXiv},
    primaryClass={stat.ML},
    url={https://arxiv.org/abs/2306.00608}, 
}

@inproceedings{nandwani2023PMI_NLP,
    title={Pointwise Mutual Information Based Metric and Decoding Strategy for Faithful Generation in Document Grounded Dialogs},
    author={Yatin Nandwani and Vineet Kumar and Dinesh Raghu and Sachindra Joshi and Luis A. Lastras},
    booktitle={The 2023 Conference on Empirical Methods in Natural Language Processing},
    year={2023},
    url={https://openreview.net/forum?id=NAmRjAIMkz}
}

@inproceedings{franzese2024minde,
    title={{MINDE}: Mutual Information Neural Diffusion Estimation},
    author={Giulio Franzese and Mustapha BOUNOUA and Pietro Michiardi},
    booktitle={The Twelfth International Conference on Learning Representations},
    year={2024},
    url={https://openreview.net/forum?id=0kWd8SJq8d}
}

@inproceedings{butakov2024normflows,
    title={Mutual Information Estimation via Normalizing Flows},
    author={Ivan Butakov and Alexander Tolmachev and Sofia Malanchuk and Anna Neopryatnaya and Alexey Frolov},
    booktitle={The Thirty-eighth Annual Conference on Neural Information Processing Systems},
    year={2024},
    url={https://openreview.net/forum?id=JiQXsLvDls}
}

@misc{yu2024leveraging_superfluous_information,
    title={Leveraging Superfluous Information in Contrastive Representation Learning}, 
    author={Xuechu Yu},
    year={2024},
    eprint={2408.10292},
    archivePrefix={arXiv},
    primaryClass={cs.LG},
    url={https://arxiv.org/abs/2408.10292}, 
}

@inproceedings{butakov2024lossy_compression,
    title={Information Bottleneck Analysis of Deep Neural Networks via Lossy Compression},
    author={Ivan Butakov and Alexander Tolmachev and Sofia Malanchuk and Anna Neopryatnaya and Alexey Frolov and Kirill Andreev},
    booktitle={The Twelfth International Conference on Learning Representations},
    year={2024},
    url={https://openreview.net/forum?id=huGECz8dPp}
}

@InProceedings{bounoua2024_O_information,
    title = 	 {S$\omega$I: Score-based O-{INFORMATION} Estimation},
    author =       {Bounoua, Mustapha and Franzese, Giulio and Michiardi, Pietro},
    booktitle = 	 {Proceedings of the 41st International Conference on Machine Learning},
    pages = 	 {4444--4471},
    year = 	 {2024},
    editor = 	 {Salakhutdinov, Ruslan and Kolter, Zico and Heller, Katherine and Weller, Adrian and Oliver, Nuria and Scarlett, Jonathan and Berkenkamp, Felix},
    volume = 	 {235},
    series = 	 {Proceedings of Machine Learning Research},
    month = 	 {21--27 Jul},
    publisher =    {PMLR},
    pdf = 	 {https://raw.githubusercontent.com/mlresearch/v235/main/assets/bounoua24a/bounoua24a.pdf},
    url = 	 {https://proceedings.mlr.press/v235/bounoua24a.html},
    abstract = 	 {The analysis of scientific data and complex multivariate systems requires information quantities that capture relationships among multiple random variables. Recently, new information-theoretic measures have been developed to overcome the shortcomings of classical ones, such as mutual information, that are restricted to considering pairwise interactions. Among them, the concept of information synergy and redundancy is crucial for understanding the high-order dependencies between variables. One of the most prominent and versatile measures based on this concept is <em>O-information</em>, which provides a clear and scalable way to quantify the synergy-redundancy balance in multivariate systems. However, its practical application is limited to simplified cases. In this work, we introduce <b>S$\Omega$I</b>, which allows to compute <em>O-information</em> without restrictive assumptions about the system while leveraging a unique model. Our experiments validate our approach on synthetic data, and demonstrate the effectiveness of <b>S$\Omega$I</b> in the context of a real-world use case.}
}

@misc{wang2024IT_alignment,
      title={Information Theoretic Text-to-Image Alignment}, 
      author={Chao Wang and Giulio Franzese and Alessandro Finamore and Massimo Gallo and Pietro Michiardi},
      year={2024},
      eprint={2405.20759},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2405.20759}, 
}

@misc{yang2024diverse_policies_recovering_PMI,
    title={Diverse Policies Recovering via Pointwise Mutual Information Weighted Imitation Learning}, 
    author={Hanlin Yang and Jian Yao and Weiming Liu and Qing Wang and Hanmin Qin and Hansheng Kong and Kirk Tang and Jiechao Xiong and Chao Yu and Kai Li and Junliang Xing and Hongwu Chen and Juchao Zhuo and Qiang Fu and Yang Wei and Haobo Fu},
    year={2024},
    eprint={2410.15910},
    archivePrefix={arXiv},
    primaryClass={cs.LG},
    url={https://arxiv.org/abs/2410.15910}, 
}

@book{polyanskiy2024information_theory,
    title={Information Theory: From Coding to Learning},
    author={Polyanskiy, Y. and Wu, Y.},
    isbn={9781108832908},
    url={https://books.google.ru/books?id=CySo0AEACAAJ},
    year={2024},
    publisher={Cambridge University Press}
}

@misc{kappen2024lectures,
    author        = {Kappen, Bert},
    title         = {Lecture notes in CDS Machine Learning},
    month         = {September},
    year          = {2024},
    publisher={SNN Adaptive Intelligence}
}

@article{czyz2025PMI,
    title={On the Properties and Estimation of Pointwise Mutual Information Profiles},
    author={Pawe{\l} Czy{\.z} and Frederic Grabowski and Julia E Vogt and Niko Beerenwinkel and Alexander Marx},
    journal={Transactions on Machine Learning Research},
    issn={2835-8856},
    year={2025},
    url={https://openreview.net/forum?id=LdflD41Gn8},
    note={}
}


# Diffusion Bridges citations

@inproceedings{goodfellow2014generative,
  title={Generative adversarial nets},
  author={Goodfellow, Ian and Pouget-Abadie, Jean and Mirza, Mehdi and Xu, Bing and Warde-Farley, David and Ozair, Sherjil and Courville, Aaron and Bengio, Yoshua},
  booktitle={Advances in neural information processing systems},
  pages={2672--2680},
  year={2014}
}

@inproceedings{amos2022amortizing,
  title={On amortizing convex conjugates for optimal transport},
  author={Amos, Brandon},
  booktitle={The Eleventh International Conference on Learning Representations},
  year={2022}
}

@article{nguyen2020approximation,
  title={Approximation by finite mixtures of continuous density functions that vanish at infinity},
  author={Nguyen, T Tin and Nguyen, Hien D and Chamroukhi, Faicel and McLachlan, Geoffrey J},
  journal={Cogent Mathematics \& Statistics},
  volume={7},
  number={1},
  pages={1750861},
  year={2020},
  publisher={Taylor \& Francis}
}

@article{yan2024perflow,
  title={Perflow: Piecewise rectified flow as universal plug-and-play accelerator},
  author={Yan, Hanshu and Liu, Xingchao and Pan, Jiachun and Liew, Jun Hao and Liu, Qiang and Feng, Jiashi},
  journal={arXiv preprint arXiv:2405.07510},
  year={2024}
}

@inproceedings{liu2023instaflow,
  title={Instaflow: One step is enough for high-quality diffusion-based text-to-image generation},
  author={Liu, Xingchao and Zhang, Xiwen and Ma, Jianzhu and Peng, Jian and others},
  booktitle={The Twelfth International Conference on Learning Representations},
  year={2023}
}

@inproceedings{song2021sde,
  title={Score-Based Generative Modeling through Stochastic Differential Equations},
  author={Song, Yang and Sohl-Dickstein, Jascha and Kingma, Diederik P and Kumar, Abhishek and Ermon, Stefano and Poole, Ben},
  booktitle={International Conference on Learning Representations},
  year={2021}
}


@article{posner1975random,
  title={Random coding strategies for minimum entropy},
  author={Posner, Edward},
  journal={IEEE Transactions on Information Theory},
  volume={21},
  number={4},
  pages={388--391},
  year={1975},
  publisher={IEEE}
}

@inproceedings{saharia2022palette,
  title={Palette: Image-to-image diffusion models},
  author={Saharia, Chitwan and Chan, William and Chang, Huiwen and Lee, Chris and Ho, Jonathan and Salimans, Tim and Fleet, David and Norouzi, Mohammad},
  booktitle={ACM SIGGRAPH 2022 Conference Proceedings},
  pages={1--10},
  year={2022}
}

@article{lecun2006tutorial,
  title={A tutorial on energy-based learning},
  author={LeCun, Yann and Chopra, Sumit and Hadsell, Raia and Ranzato, M and Huang, Fujie},
  journal={Predicting structured data},
  volume={1},
  number={0},
  year={2006}
}


@inproceedings{
su2023dual,
title={Dual Diffusion Implicit Bridges for Image-to-Image Translation},
author={Xuan Su and Jiaming Song and Chenlin Meng and Stefano Ermon},
booktitle={The Eleventh International Conference on Learning Representations },
year={2023},
url={https://openreview.net/forum?id=5HLoTvVGDe}
}

@inproceedings{rombach2022high,
  title={High-resolution image synthesis with latent diffusion models},
  author={Rombach, Robin and Blattmann, Andreas and Lorenz, Dominik and Esser, Patrick and Ommer, Bj{\"o}rn},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={10684--10695},
  year={2022}
}



@inproceedings{genevay2019sample,
  title={Sample complexity of sinkhorn divergences},
  author={Genevay, Aude and Chizat, L{\'e}naic and Bach, Francis and Cuturi, Marco and Peyr{\'e}, Gabriel},
  booktitle={The 22nd international conference on artificial intelligence and statistics},
  pages={1574--1583},
  year={2019},
  organization={PMLR}
}

@article{ho2020denoising,
  title={Denoising diffusion probabilistic models},
  author={Ho, Jonathan and Jain, Ajay and Abbeel, Pieter},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={6840--6851},
  year={2020}
}


@article{bianchini2014existence,
  title={Existence and uniqueness of the gradient flow of the Entropy in the space of probability measures},
  author={Bianchini, Stefano and Dabrowski, Alexander and others},
  journal={RENDICONTI DELL'ISTITUTO DI MATEMATICA DELL'UNIVERSIT{\`A} DI TRIESTE},
  volume={46},
  number={1},
  pages={43--70},
  year={2014}
}

@article{choi2023generative,
  title={Generative Modeling through the Semi-dual Formulation of Unbalanced Optimal Transport},
  author={Choi, Jaemoo and Choi, Jaewoong and Kang, Myungjoo},
  journal={arXiv preprint arXiv:2305.14777},
  year={2023}
}


@inproceedings{bonneel2023survey,
  title={A survey of Optimal Transport for Computer Graphics and Computer Vision},
  author={Bonneel, Nicolas and Digne, Julie},
  booktitle={Computer Graphics Forum},
  volume={42},
  number={2},
  pages={439--460},
  year={2023},
  organization={Wiley Online Library}
}


@article{khamis2023earth,
  title={Earth Movers in The Big Data Era: A Review of Optimal Transport in Machine Learning},
  author={Khamis, Abdelwahed and Tsuchida, Russell and Tarek, Mohamed and Rolland, Vivien and Petersson, Lars},
  journal={arXiv preprint arXiv:2305.05080},
  year={2023}
}


@article{flamary2021pot,
  author  = {R{\'e}mi Flamary and Nicolas Courty and Alexandre Gramfort and Mokhtar Z. Alaya and Aur{\'e}lie Boisbunon and Stanislas Chambon and Laetitia Chapel and Adrien Corenflos and Kilian Fatras and Nemo Fournier and L{\'e}o Gautheron and Nathalie T.H. Gayraud and Hicham Janati and Alain Rakotomamonjy and Ievgen Redko and Antoine Rolet and Antony Schutz and Vivien Seguy and Danica J. Sutherland and Romain Tavenard and Alexander Tong and Titouan Vayer},
  title   = {POT: Python Optimal Transport},
  journal = {Journal of Machine Learning Research},
  year    = {2021},
  volume  = {22},
  number  = {78},
  pages   = {1-8},
  url     = {http://jmlr.org/papers/v22/20-451.html}
}

@inproceedings{dvurechensky2018computational,
  title={Computational optimal transport: Complexity by accelerated gradient descent is better than by Sinkhorn’s algorithm},
  author={Dvurechensky, Pavel and Gasnikov, Alexander and Kroshnin, Alexey},
  booktitle={International conference on machine learning},
  pages={1367--1376},
  year={2018},
  organization={PMLR}
}


@article{gelbrich1990formula,
  title={On a formula for the L2 Wasserstein metric between measures on Euclidean and Hilbert spaces},
  author={Gelbrich, Matthias},
  journal={Mathematische Nachrichten},
  volume={147},
  number={1},
  pages={185--203},
  year={1990},
  publisher={Wiley Online Library}
}

@article{cuesta1996lower,
  title={On lower bounds for the L2-Wasserstein metric in a Hilbert space},
  author={Cuesta-Albertos, Juan Antonio and Matr{\'a}n-Bea, C and Tuero-Diaz, A},
  journal={Journal of Theoretical Probability},
  volume={9},
  number={2},
  pages={263--284},
  year={1996},
  publisher={New York: Plenum Press, c1988-}
}


@inproceedings{chen2021likelihood,
  title={Likelihood Training of Schr{\"o}dinger Bridge using Forward-Backward SDEs Theory},
  author={Chen, Tianrong and Liu, Guan-Horng and Theodorou, Evangelos},
  booktitle={International Conference on Learning Representations},
  year={2021}
}

@article{de2021diffusion,
  title={Diffusion Schr{\"o}dinger bridge with applications to score-based generative modeling},
  author={De Bortoli, Valentin and Thornton, James and Heng, Jeremy and Doucet, Arnaud},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={17695--17709},
  year={2021}
}

@article{gazdieva2022unpaired,
  title={Unpaired image super-resolution with optimal transport maps},
  author={Gazdieva, Milena and Rout, Litu and Korotin, Alexander and Filippov, Alexander and Burnaev, Evgeny},
  journal={arXiv preprint arXiv:2202.01116},
  year={2022}
}

@inproceedings{bunne2023schrodinger,
  title={The Schr{\"o}dinger Bridge between Gaussian Measures has a Closed Form},
  author={Bunne, Charlotte and Hsieh, Ya-Ping and Cuturi, Marco and Krause, Andreas},
  booktitle={International Conference on Artificial Intelligence and Statistics},
  pages={5802--5833},
  year={2023},
  organization={PMLR}
}
@article{peluchetti2023diffusion,
  title={Diffusion bridge mixture transports, Schr{\"o}dinger bridge problems and generative modeling},
  author={Peluchetti, Stefano},
  journal={Journal of Machine Learning Research},
  volume={24},
  number={374},
  pages={1--51},
  year={2023}
}
@article{dowson1982frechet,
  title={The Fr{\'e}chet distance between multivariate normal distributions},
  author={Dowson, DC and Landau, BV666017},
  journal={Journal of multivariate analysis},
  volume={12},
  number={3},
  pages={450--455},
  year={1982},
  publisher={Elsevier}
}


@article{chen2016relation,
  title={On the relation between optimal transport and Schr{\"o}dinger bridges: A stochastic control viewpoint},
  author={Chen, Yongxin and Georgiou, Tryphon T and Pavon, Michele},
  journal={Journal of Optimization Theory and Applications},
  volume={169},
  pages={671--691},
  year={2016},
  publisher={Springer}
}


@inproceedings{
  korotin2022wasserstein,
  title={Wasserstein Iterative Networks for Barycenter Estimation},
  author={Alexander Korotin and Vage Egiazarian and Lingxiao Li and Evgeny Burnaev},
  booktitle={Thirty-Sixth Conference on Neural Information Processing Systems},
  year={2022},
  url={https://openreview.net/forum?id=GiEnzxTnaMN}
}



@inproceedings{wang2021deep,
  title={Deep generative learning via schr{\"o}dinger bridge},
  author={Wang, Gefei and Jiao, Yuling and Xu, Qian and Wang, Yang and Yang, Can},
  booktitle={International Conference on Machine Learning},
  pages={10794--10804},
  year={2021},
  organization={PMLR}
}

@article{vargas2021solving,
  title={Solving schr{\"o}dinger bridges via maximum likelihood},
  author={Vargas, Francisco and Thodoroff, Pierre and Lamacraft, Austen and Lawrence, Neil},
  journal={Entropy},
  volume={23},
  number={9},
  pages={1134},
  year={2021},
  publisher={MDPI}
}



@article{brenier1991polar,
  title={Polar factorization and monotone rearrangement of vector-valued functions},
  author={Brenier, Yann},
  journal={Communications on pure and applied mathematics},
  volume={44},
  number={4},
  pages={375--417},
  year={1991},
  publisher={Wiley Online Library}
}

@InProceedings{xie2019scalable,
  title = {On Scalable and Efficient Computation of Large Scale Optimal Transport},
  author = {Xie, Yujia and Chen, Minshuo and Jiang, Haoming and Zhao, Tuo and Zha, Hongyuan},
  pages = {6882--6892},
  year = {2019},
  editor = {Kamalika Chaudhuri and Ruslan Salakhutdinov}, volume = {97},
  series = {Proceedings of Machine Learning Research}, address = {Long Beach, California, USA},
  month = {09--15 Jun},
  publisher = {PMLR},
  pdf = {http://proceedings.mlr.press/v97/xie19a/xie19a.pdf},
  url = {http://proceedings.mlr.press/v97/xie19a.html}, 
}

@article{pearlmutter1994fast,
  title={Fast exact multiplication by the Hessian},
  author={Pearlmutter, Barak A},
  journal={Neural computation},
  volume={6},
  number={1},
  pages={147--160},
  year={1994},
  publisher={MIT Press}
}

@article{peyre2018mathematical,
  title={Mathematical Foundations of Data Sciences},
  author={Peyr{\'e}, Gabriel},
  journal={def},
  volume={1},
  number={2$\pi$},
  pages={2$\pi$},
  year={2018}
}

@article{milgrom2002envelope,
  title={Envelope theorems for arbitrary choice sets},
  author={Milgrom, Paul and Segal, Ilya},
  journal={Econometrica},
  volume={70},
  number={2},
  pages={583--601},
  year={2002},
  publisher={Wiley Online Library}
}


@article{fenchel1949conjugate,
  title={On conjugate convex functions},
  author={Fenchel, Werner},
  journal={Canadian Journal of Mathematics},
  volume={1},
  number={1},
  pages={73--77},
  year={1949},
  publisher={Cambridge University Press}
}


@article{chartrand2009gradient,
  title={A gradient descent solution to the Monge-Kantorovich problem},
  author={Chartrand, Rick and Wohlberg, Brendt and Vixie, Kevin and Bollt, Erik},
  journal={Applied Mathematical Sciences},
  volume={3},
  number={22},
  pages={1071--1080},
  year={2009}
}

@article{kakade2009duality,
  title={On the duality of strong convexity and strong smoothness: Learning applications and matrix regularization},
  author={Kakade, Sham and Shalev-Shwartz, Shai and Tewari, Ambuj},
  journal={Unpublished Manuscript, http://ttic. uchicago. edu/shai/papers/KakadeShalevTewari09. pdf},
  volume={2},
  number={1},
  year={2009}
}

@article{chen2018optimal,
  title={Optimal control via neural networks: A convex approach},
  author={Chen, Yize and Shi, Yuanyuan and Zhang, Baosen},
  journal={arXiv preprint arXiv:1805.11835},
  year={2018}
}

@book{villani2003topics,
  title={Topics in optimal transportation},
  author={Villani, C{\'e}dric},
  number={58},
  year={2003},
  publisher={American Mathematical Soc.}
}

@misc{kingma2017adam,
    title={Adam: A Method for Stochastic Optimization}, 
    author={Diederik P. Kingma and Jimmy Ba},
    year={2017},
    eprint={1412.6980},
    archivePrefix={arXiv},
    primaryClass={cs.LG}
}

@book{rockafellar1970convex,
  title={Convex analysis},
  author={Rockafellar, R Tyrrell},
  volume={28},
  year={1970},
  publisher={Princeton university press}
}

@article{rockafellar1966characterization,
  title={Characterization of the subdifferentials of convex functions},
  author={Rockafellar, Ralph},
  journal={Pacific Journal of Mathematics},
  volume={17},
  number={3},
  pages={497--510},
  year={1966},
  publisher={Mathematical Sciences Publishers}
}

@inproceedings{seguy2017large,
  title={Large Scale Optimal Transport and Mapping Estimation},
  author={Seguy, Vivien and Damodaran, Bharath Bhushan and Flamary, Remi and Courty, Nicolas and Rolet, Antoine and Blondel, Mathieu},
  booktitle={International Conference on Learning Representations},
  year={2018}
}

@inproceedings{li2017mmd,
  title={{MMD} {GAN}: Towards deeper understanding of moment matching network},
  author={Li, Chun-Liang and Chang, Wei-Cheng and Cheng, Yu and Yang, Yiming and P{\'o}czos, Barnab{\'a}s},
  booktitle={Advances in Neural Information Processing Systems},
  pages={2203--2213},
  year={2017}
}

@article{taghvaei20192,
  title={2-{W}asserstein Approximation via Restricted Convex Potentials with Application to Improved Training for {GAN}s},
  author={Taghvaei, Amirhossein and Jalali, Amin},
  journal={arXiv preprint arXiv:1902.07197},
  year={2019}
}


@article{mccann1995existence,
  title={Existence and uniqueness of monotone measure-preserving maps},
  author={McCann, Robert J and others},
  journal={Duke Mathematical Journal},
  volume={80},
  number={2},
  pages={309--324},
  year={1995},
  publisher={Durham, NC: Duke University Press, 1935-}
}


@inproceedings{rakhlin2013online,
  title={Online Learning with Predictable Sequences.},
  author={Rakhlin, Alexander and Sridharan, Karthik},
  booktitle={COLT},
  pages={993--1019},
  year={2013}
}

@article{mirza2014conditional,
  title={Conditional generative adversarial nets},
  author={Mirza, Mehdi and Osindero, Simon},
  journal={arXiv preprint arXiv:1411.1784},
  year={2014}
}

@inproceedings{chen2019gradual,
  title={A gradual, semi-discrete approach to generative network training via explicit {W}asserstein minimization},
  author={Chen, Yucheng and Telgarsky, Matus and Zhang, Chao and Bailey, Bolton and Hsu, Daniel and Peng, Jian},
  booktitle={International Conference on Machine Learning},
  pages={1071--1080},
  year={2019},
  organization={PMLR}
}


@inproceedings{heusel2017gans,
  title={{GAN}s trained by a two time-scale update rule converge to a local nash equilibrium},
  author={Heusel, Martin and Ramsauer, Hubert and Unterthiner, Thomas and Nessler, Bernhard and Hochreiter, Sepp},
  booktitle={Advances in neural information processing systems},
  pages={6626--6637},
  year={2017}
}

@article{bellemare2017cramer,
  title={The cramer distance as a solution to biased {W}asserstein gradients},
  author={Bellemare, Marc G and Danihelka, Ivo and Dabney, Will and Mohamed, Shakir and Lakshminarayanan, Balaji and Hoyer, Stephan and Munos, R{\'e}mi},
  journal={arXiv preprint arXiv:1705.10743},
  year={2017}
}

@article{daskalakis2017training,
  title={Training {GAN}s with optimism},
  author={Daskalakis, Constantinos and Ilyas, Andrew and Syrgkanis, Vasilis and Zeng, Haoyang},
  journal={arXiv preprint arXiv:1711.00141},
  year={2017}
}

@article{yadav2017stabilizing,
  title={Stabilizing adversarial nets with prediction methods},
  author={Yadav, Abhay and Shah, Sohil and Xu, Zheng and Jacobs, David and Goldstein, Tom},
  journal={arXiv preprint arXiv:1705.07364},
  year={2017}
}

@inproceedings{mescheder2017numerics,
  title={The numerics of {GAN}s},
  author={Mescheder, Lars and Nowozin, Sebastian and Geiger, Andreas},
  booktitle={Advances in Neural Information Processing Systems},
  pages={1825--1835},
  year={2017}
}



@inproceedings{li2015generative,
  title={Generative moment matching networks},
  author={Li, Yujia and Swersky, Kevin and Zemel, Rich},
  booktitle={International Conference on Machine Learning},
  pages={1718--1727},
  year={2015}
}


@inproceedings{gulrajani2017improved,
  title={Improved training of {W}asserstein {GAN}s},
  author={Gulrajani, Ishaan and Ahmed, Faruk and Arjovsky, Martin and Dumoulin, Vincent and Courville, Aaron C},
  booktitle={Advances in Neural Information Processing Systems},
  pages={5767--5777},
  year={2017}
}


@article{yarotsky2017error,
  title={Error bounds for approximations with deep ReLU networks},
  author={Yarotsky, Dmitry},
  journal={Neural Networks},
  volume={94},
  pages={103--114},
  year={2017},
  publisher={Elsevier}
}

@inproceedings{tolstikhin2017adagan,
  title={Ada{GAN}: Boosting generative models},
  author={Tolstikhin, Ilya O and Gelly, Sylvain and Bousquet, Olivier and Simon-Gabriel, Carl-Johann and Sch{\"o}lkopf, Bernhard},
  booktitle={Advances in Neural Information Processing Systems},
  pages={5424--5433},
  year={2017}
}


@article{grnarova2017online,
  title={An online learning approach to generative adversarial networks},
  author={Grnarova, Paulina and Levy, Kfir Y and Lucchi, Aurelien and Hofmann, Thomas and Krause, Andreas},
  journal={arXiv preprint arXiv:1706.03269},
  year={2017}
}


@article{arjovsky2017towards,
  title={Towards principled methods for training generative adversarial networks},
  author={Arjovsky, Martin and Bottou, L{\'e}on},
  journal={arXiv preprint arXiv:1701.04862},
  year={2017}
}

@article{arora2017generalization,
  title={Generalization and equilibrium in generative adversarial nets ({GAN}s)},
  author={Arora, Sanjeev and Ge, Rong and Liang, Yingyu and Ma, Tengyu and Zhang, Yi},
  journal={arXiv preprint arXiv:1703.00573},
  year={2017}
}


@article{cuturi2014fast,
  title={Fast computation of {W}asserstein barycenters},
  author={Cuturi, Marco and Doucet, Arnaud},
  year={2014},
  publisher={Journal of Machine Learning Research}
}

@article{solomon2018optimal,
  title={Optimal transport on discrete domains},
  author={Solomon, Justin},
  journal={AMS Short Course on Discrete Differential Geometry},
  year={2018}
}

@article{solomon2015convolutional,
  title={Convolutional {W}asserstein distances: Efficient optimal transportation on geometric domains},
  author={Solomon, Justin and De Goes, Fernando and Peyr{\'e}, Gabriel and Cuturi, Marco and Butscher, Adrian and Nguyen, Andy and Du, Tao and Guibas, Leonidas},
  journal={ACM Transactions on Graphics (TOG)},
  volume={34},
  number={4},
  pages={1--11},
  year={2015},
  publisher={ACM New York, NY, USA}
}

@article{li2020continuous,
  title={Continuous Regularized {W}asserstein Barycenters},
  author={Li, Lingxiao and Genevay, Aude and Yurochkin, Mikhail and Solomon, Justin},
  journal={arXiv preprint arXiv:2008.12534},
  year={2020}
}

@inproceedings{genevay2016stochastic,
  title={Stochastic optimization for large-scale optimal transport},
  author={Genevay, Aude and Cuturi, Marco and Peyr{\'e}, Gabriel and Bach, Francis},
  booktitle={Advances in neural information processing systems},
  pages={3440--3448},
  year={2016}
}


@article{mroueh2019wasserstein,
  title={Wasserstein style transfer},
  author={Mroueh, Youssef},
  journal={arXiv preprint arXiv:1905.12828},
  year={2019}
}

@article{agueh2011barycenters,
  title={Barycenters in the {W}asserstein space},
  author={Agueh, Martial and Carlier, Guillaume},
  journal={SIAM Journal on Mathematical Analysis},
  volume={43},
  number={2},
  pages={904--924},
  year={2011},
  publisher={SIAM}
}

@inproceedings{rabin2011wasserstein,
  title={Wasserstein barycenter and its application to texture mixing},
  author={Rabin, Julien and Peyr{\'e}, Gabriel and Delon, Julie and Bernot, Marc},
  booktitle={International Conference on Scale Space and Variational Methods in Computer Vision},
  pages={435--446},
  year={2011},
  organization={Springer}
}


@article{rabin2011transportation,
  title={Transportation distances on the circle},
  author={Rabin, Julien and Delon, Julie and Gousseau, Yann},
  journal={Journal of Mathematical Imaging and Vision},
  volume={41},
  number={1-2},
  pages={147},
  year={2011},
  publisher={Springer}
}


@inproceedings{mroueh2017fisher,
  title={Fisher {GAN}},
  author={Mroueh, Youssef and Sercu, Tom},
  booktitle={Advances in Neural Information Processing Systems},
  pages={2513--2523},
  year={2017}
}


@article{mroueh2017sobolev,
  title={Sobolev {GAN}},
  author={Mroueh, Youssef and Li, Chun-Liang and Sercu, Tom and Raj, Anant and Cheng, Yu},
  journal={arXiv preprint arXiv:1711.04894},
  year={2017}
}


@article{sonderby2016amortised,
  title={Amortised map inference for image super-resolution},
  author={S{\o}nderby, Casper Kaae and Caballero, Jose and Theis, Lucas and Shi, Wenzhe and Husz{\'a}r, Ferenc},
  journal={arXiv preprint arXiv:1610.04490},
  year={2016}
}

@inproceedings{johnson2016perceptual,
  title={Perceptual losses for real-time style transfer and super-resolution},
  author={Johnson, Justin and Alahi, Alexandre and Fei-Fei, Li},
  booktitle={European conference on computer vision},
  pages={694--711},
  year={2016},
  organization={Springer}
}


@article{burt1983laplacian,
  title={The Laplacian pyramid as a compact image code},
  author={Burt, Peter and Adelson, Edward},
  journal={IEEE Transactions on communications},
  volume={31},
  number={4},
  pages={532--540},
  year={1983},
  publisher={IEEE}
}


@incollection{spence1978job,
  title={Job market signaling},
  author={Spence, Michael},
  booktitle={Uncertainty in economics},
  pages={281--306},
  year={1978},
  publisher={Elsevier}
}

@article{carpenter2017stan,
  title={Stan: A probabilistic programming language},
  author={Carpenter, Bob and Gelman, Andrew and Hoffman, Matthew D and Lee, Daniel and Goodrich, Ben and Betancourt, Michael and Brubaker, Marcus and Guo, Jiqiang and Li, Peter and Riddell, Allen},
  journal={Journal of statistical software},
  volume={76},
  number={1},
  year={2017},
  publisher={Columbia Univ., New York, NY (United States); Harvard Univ., Cambridge, MA~…}
}

@article{arjovsky2017wasserstein,
  title={Wasserstein {GAN}},
  author={Arjovsky, Martin and Chintala, Soumith and Bottou, L{\'e}on},
  journal={arXiv preprint arXiv:1701.07875},
  year={2017}
}

@article{weed2019sharp,
  title={Sharp asymptotic and finite-sample rates of convergence of empirical measures in {W}asserstein distance},
  author={Weed, Jonathan and Bach, Francis and others},
  journal={Bernoulli},
  volume={25},
  number={4A},
  pages={2620--2648},
  year={2019},
  publisher={Bernoulli Society for Mathematical Statistics and Probability}
}

@article{dowson1982frechet,
  title={The Fr{\'e}chet distance between multivariate normal distributions},
  author={Dowson, DC and Landau, BV},
  journal={Journal of multivariate analysis},
  volume={12},
  number={3},
  pages={450--455},
  year={1982},
  publisher={Elsevier}
}


@article{liang2017well,
  title={How Well Can Generative Adversarial Networks ({GAN}) Learn Densities: A Nonparametric View},
  author={Liang, Tengyuan},
  journal={arXiv preprint arXiv:1712.08244},
  year={2017}
}

@inproceedings{liu2019wasserstein,
  title={Wasserstein {GAN} with quadratic transport cost},
  author={Liu, Huidong and Gu, Xianfeng and Samaras, Dimitris},
  booktitle={Proceedings of the IEEE International Conference on Computer Vision},
  pages={4832--4841},
  year={2019}
}

@article{stanczuk2021wasserstein,
  title={Wasserstein {GAN}s Work Because They Fail (to Approximate the {W}asserstein Distance)},
  author={Stanczuk, Jan and Etmann, Christian and Kreusser, Lisa Maria and Schonlieb, Carola-Bibiane},
  journal={arXiv preprint arXiv:2103.01678},
  year={2021}
}

@article{mallasto2019q,
  title={(q, p)-{W}asserstein {GAN}s: Comparing Ground Metrics for {W}asserstein {GAN}s},
  author={Mallasto, Anton and Frellsen, Jes and Boomsma, Wouter and Feragen, Aasa},
  journal={arXiv preprint arXiv:1902.03642},
  year={2019}
}

@article{barron2017continuously,
  title={Continuously differentiable exponential linear units},
  author={Barron, Jonathan T},
  journal={arXiv preprint arXiv:1704.07483},
  year={2017}
}


@article{alvarez2016fixed,
  title={A fixed-point approach to barycenters in {W}asserstein space},
  author={{\'A}lvarez-Esteban, Pedro C and Del Barrio, E and Cuesta-Albertos, JA and Matr{\'a}n, C},
  journal={Journal of Mathematical Analysis and Applications},
  volume={441},
  number={2},
  pages={744--762},
  year={2016},
  publisher={Elsevier}
}

@inproceedings{staib2017parallel,
  title={Parallel streaming {W}asserstein barycenters},
  author={Staib, Matthew and Claici, Sebastian and Solomon, Justin M and Jegelka, Stefanie},
  booktitle={Advances in Neural Information Processing Systems},
  pages={2647--2658},
  year={2017}
}

@inproceedings{nhan2019threeplayer,
  title={Threeplayer {W}asserstein {GAN} via amortised duality},
  author={Nhan Dam, Quan Hoang and Le, Trung and Nguyen, Tu Dinh and Bui, Hung and Phung, Dinh},
  booktitle={Proc. of the 28th Int. Joint Conf. on Artificial Intelligence (IJCAI)},
  year={2019}
}

@inproceedings{roth2017stabilizing,
  title={Stabilizing training of generative adversarial networks through regularization},
  author={Roth, Kevin and Lucchi, Aurelien and Nowozin, Sebastian and Hofmann, Thomas},
  booktitle={Advances in neural information processing systems},
  pages={2018--2028},
  year={2017}
}

@inproceedings{nowozin2016f,
  title={f-{GAN}: Training generative neural samplers using variational divergence minimization},
  author={Nowozin, Sebastian and Cseke, Botond and Tomioka, Ryota},
  booktitle={Advances in neural information processing systems},
  pages={271--279},
  year={2016}
}

@inproceedings{rezende2015variational,
  title={Variational inference with normalizing flows},
  author={Rezende, Danilo and Mohamed, Shakir},
  booktitle={International conference on machine learning},
  pages={1530--1538},
  year={2015},
  organization={PMLR}
}


@inproceedings{salimans2016improved,
  title={Improved techniques for training {GAN}s},
  author={Salimans, Tim and Goodfellow, Ian and Zaremba, Wojciech and Cheung, Vicki and Radford, Alec and Chen, Xi},
  booktitle={Advances in neural information processing systems},
  pages={2234--2242},
  year={2016}
}

@article{schrieber2016dotmark,
  title={Dotmark--a benchmark for discrete optimal transport},
  author={Schrieber, J{\"o}rn and Schuhmacher, Dominic and Gottschlich, Carsten},
  journal={IEEE Access},
  volume={5},
  pages={271--282},
  year={2016},
  publisher={IEEE}
}

@article{alfonsi2020squared,
  title={Squared quadratic {W}asserstein distance: optimal couplings and Lions differentiability},
  author={Alfonsi, Aur{\'e}lien and Jourdain, Benjamin},
  journal={ESAIM: Probability and Statistics},
  volume={24},
  pages={703--717},
  year={2020},
  publisher={EDP Sciences}
}


@article{liang2018well,
  title={On How Well Generative Adversarial Networks Learn Densities: Nonparametric and Parametric Results},
  author={Liang, Tengyuan},
  journal={arXiv preprint arXiv:1811.03179},
  year={2018}
}

@article{mallasto2019well,
  title={How Well Do {WGAN}s Estimate the {W}asserstein Metric?},
  author={Mallasto, Anton and Mont{\'u}far, Guido and Gerolin, Augusto},
  journal={arXiv preprint arXiv:1910.03875},
  year={2019}
}

@article{gangbo1995optimal,
  title={Optimal maps in Monge's mass transport problem},
  author={Gangbo, Wilfrid and McCann, Robert J},
  journal={Comptes Rendus de l'Academie des Sciences-Serie I-Mathematique},
  volume={321},
  number={12},
  pages={1653},
  year={1995},
  publisher={Paris: Gauthier-Villars, c1984-c2001.}
}


@article{kantorovitch1958translocation,
  title={On the translocation of masses},
  author={Kantorovitch, Leonid},
  journal={Management Science},
  volume={5},
  number={1},
  pages={1--4},
  year={1958},
  publisher={INFORMS}
}

@inproceedings{pinetz2019estimation,
  title={On the estimation of the {W}asserstein distance in generative models},
  author={Pinetz, Thomas and Soukup, Daniel and Pock, Thomas},
  booktitle={German Conference on Pattern Recognition},
  pages={156--170},
  year={2019},
  organization={Springer}
}

@inproceedings{zhang2018unreasonable,
  title={The unreasonable effectiveness of deep features as a perceptual metric},
  author={Zhang, Richard and Isola, Phillip and Efros, Alexei A and Shechtman, Eli and Wang, Oliver},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={586--595},
  year={2018}
}


@article{nguyen2010estimating,
  title={Estimating divergence functionals and the likelihood ratio by convex risk minimization},
  author={Nguyen, XuanLong and Wainwright, Martin J and Jordan, Michael I},
  journal={IEEE Transactions on Information Theory},
  volume={56},
  number={11},
  pages={5847--5861},
  year={2010},
  publisher={IEEE}
}

@article{sanjabi2018convergence,
  title={On the convergence and robustness of training {GAN}s with regularized optimal transport},
  author={Sanjabi, Maziar and Ba, Jimmy and Razaviyayn, Meisam and Lee, Jason D},
  journal={arXiv preprint arXiv:1802.08249},
  year={2018}
}

@inproceedings{dvurechenskii2018decentralize,
  title={Decentralize and randomize: Faster algorithm for {W}asserstein barycenters},
  author={Dvurechenskii, Pavel and Dvinskikh, Darina and Gasnikov, Alexander and Uribe, Cesar and Nedich, Angelia},
  booktitle={Advances in Neural Information Processing Systems},
  pages={10760--10770},
  year={2018}
}

@article{chewi2020gradient,
  title={Gradient descent algorithms for Bures-{W}asserstein barycenters},
  author={Chewi, Sinho and Maunu, Tyler and Rigollet, Philippe and Stromme, Austin J},
  journal={arXiv preprint arXiv:2001.01700},
  year={2020}
}

@inproceedings{
  korotin2019wasserstein,
  title={Wasserstein-2 Generative Networks},
  author={Alexander Korotin and Vage Egiazarian and Arip Asadulaev and Alexander Safin and Evgeny Burnaev},
  booktitle={International Conference on Learning Representations},
  year={2021},
  url={https://openreview.net/forum?id=bEoxzW_EXsa}
}

@inproceedings{amos2017input,
  title={Input convex neural networks},
  author={Amos, Brandon and Xu, Lei and Kolter, J Zico},
  booktitle={Proceedings of the 34th International Conference on Machine Learning-Volume 70},
  pages={146--155},
  year={2017},
  organization={JMLR. org}
}

@article{peyre2019computational,
  title={Computational optimal transport},
  author={Peyr{\'e}, Gabriel and Cuturi, Marco and others},
  journal={Foundations and Trends{\textregistered} in Machine Learning},
  volume={11},
  number={5-6},
  pages={355--607},
  year={2019},
  publisher={Now Publishers, Inc.}
}



@article{henry2019martingale,
  title={(Martingale) Optimal Transport and Anomaly Detection with Neural Networks: A Primal-Dual Algorithm},
  author={Henry-Labordere, Pierre},
  journal={Available at SSRN 3370910},
  year={2019}
}


@book{alexandrov2005convex,
  title={Convex polyhedra},
  author={Alexandrov, Aleksandr D},
  year={2005},
  publisher={Springer Science \& Business Media}
}


@inproceedings{makkuva2020optimal,
  title={Optimal transport mapping via input convex neural networks},
  author={Makkuva, Ashok and Taghvaei, Amirhossein and Oh, Sewoong and Lee, Jason},
  booktitle={International Conference on Machine Learning},
  pages={6672--6681},
  year={2020},
  organization={PMLR}
}





@book{villani2008optimal,
  title={Optimal transport: old and new},
  author={Villani, C{\'e}dric},
  volume={338},
  year={2008},
  publisher={Springer Science \& Business Media}
}


@article{singh2018nonparametric,
  title={Nonparametric Density Estimation under Adversarial Losses},
  author={Singh, Shashank and Uppal, Ananya and Li, Boyue and Li, Chun-Liang and Zaheer, Manzil and P{\'o}czos, Barnab{\'a}s},
  journal={arXiv preprint arXiv:1805.08836},
  year={2018}
}

@article{liang2018interaction,
  title={Interaction matters: A note on non-asymptotic local convergence of generative adversarial networks},
  author={Liang, Tengyuan and Stokes, James},
  journal={arXiv preprint arXiv:1802.06132},
  year={2018}
}


@article{luise2018differential,
  title={Differential Properties of Sinkhorn Approximation for Learning with {W}asserstein Distance},
  author={Luise, Giulia and Rudi, Alessandro and Pontil, Massimiliano and Ciliberto, Carlo},
  journal={arXiv preprint arXiv:1805.11897},
  year={2018}
}

@inproceedings{lee2018minimax,
  title={Minimax statistical learning with {W}asserstein distances},
  author={Lee, Jaeho and Raginsky, Maxim},
  booktitle={Advances in Neural Information Processing Systems},
  pages={2688--2698},
  year={2018}
}

@article{lei2019mode,
  title={Mode collapse and regularity of optimal transportation Maps},
  author={Lei, Na and Guo, Yang and An, Dongsheng and Qi, Xin and Luo, Zhongxuan and Yau, Shing-Tung and Gu, Xianfeng},
  journal={arXiv preprint arXiv:1902.02934},
  year={2019}
}

@article{lu2020large,
  title={Large-Scale Optimal Transport via Adversarial Training with Cycle-Consistency},
  author={Lu, Guansong and Zhou, Zhiming and Shen, Jian and Chen, Cheng and Zhang, Weinan and Yu, Yong},
  journal={arXiv preprint arXiv:2003.06635},
  year={2020}
}

@article{liu2021learning,
  title={Learning High Dimensional {W}asserstein Geodesics},
  author={Liu, Shu and Ma, Shaojun and Chen, Yongxin and Zha, Hongyuan and Zhou, Haomin},
  journal={arXiv preprint arXiv:2102.02992},
  year={2021}
}

@article{leygonie2019adversarial,
  title={Adversarial computation of optimal transport maps},
  author={Leygonie, Jacob and She, Jennifer and Almahairi, Amjad and Rajeswar, Sai and Courville, Aaron},
  journal={arXiv preprint arXiv:1906.09691},
  year={2019}
}


% -------------- DENIS --------------

@article{radford2015unsupervised,
  title={Unsupervised representation learning with deep convolutional generative adversarial networks},
  author={Radford, Alec and Metz, Luke and Chintala, Soumith},
  journal={arXiv preprint arXiv:1511.06434},
  year={2015}
}

@article{karras2017progressive,
  title={Progressive growing of {GAN}s for improved quality, stability, and variation},
  author={Karras, Tero and Aila, Timo and Laine, Samuli and Lehtinen, Jaakko},
  journal={arXiv preprint arXiv:1710.10196},
  year={2017}
}

@article{lei2019geometric,
  title={A geometric view of optimal transportation and generative model},
  author={Lei, Na and Su, Kehua and Cui, Li and Yau, Shing-Tung and Gu, Xianfeng David},
  journal={Computer Aided Geometric Design},
  volume={68},
  pages={1--21},
  year={2019},
  publisher={Elsevier}
}


@inproceedings{ledig2017photo,
  title={Photo-realistic single image super-resolution using a generative adversarial network},
  author={Ledig, Christian and Theis, Lucas and Husz{\'a}r, Ferenc and Caballero, Jose and Cunningham, Andrew and Acosta, Alejandro and Aitken, Andrew and Tejani, Alykhan and Totz, Johannes and Wang, Zehan and others},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={4681--4690},
  year={2017}
}


@inproceedings{yeh2017semantic,
  title={Semantic image inpainting with deep generative models},
  author={Yeh, Raymond A and Chen, Chen and Yian Lim, Teck and Schwing, Alexander G and Hasegawa-Johnson, Mark and Do, Minh N},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={5485--5493},
  year={2017}
}


@inproceedings{zhu2017unpaired,
  title={Unpaired image-to-image translation using cycle-consistent adversarial networks},
  author={Zhu, Jun-Yan and Park, Taesung and Isola, Phillip and Efros, Alexei A},
  booktitle={Proceedings of the IEEE international conference on computer vision},
  pages={2223--2232},
  year={2017}
}


@article{reed2016generative,
  title={Generative adversarial text to image synthesis},
  author={Reed, Scott and Akata, Zeynep and Yan, Xinchen and Logeswaran, Lajanugen and Schiele, Bernt and Lee, Honglak},
  journal={arXiv preprint arXiv:1605.05396},
  year={2016}
}

@inproceedings{isola2017image,
  title={Image-to-image translation with conditional adversarial networks},
  author={Isola, Phillip and Zhu, Jun-Yan and Zhou, Tinghui and Efros, Alexei A},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={1125--1134},
  year={2017}
}

@inproceedings{liu2016coupled,
  title={Coupled generative adversarial networks},
  author={Liu, Ming-Yu and Tuzel, Oncel},
  booktitle={Advances in neural information processing systems},
  pages={469--477},
  year={2016}
}

@inproceedings{liu2022flow,
  title={Flow Straight and Fast: Learning to Generate and Transfer Data with Rectified Flow},
  author={Liu, Xingchao and Gong, Chengyue and others},
  booktitle={The Eleventh International Conference on Learning Representations},
  year={2022}
}

@inproceedings{koshizuka2022neural,
  title={Neural Lagrangian Schr$\backslash$"$\{$o$\}$ dinger Bridge: Diffusion Modeling for Population Dynamics},
  author={Koshizuka, Takeshi and Sato, Issei},
  booktitle={The Eleventh International Conference on Learning Representations},
  year={2022}
}

@article{sauer2023stylegan,
  title={Stylegan-t: Unlocking the power of gans for fast large-scale text-to-image synthesis},
  author={Sauer, Axel and Karras, Tero and Laine, Samuli and Geiger, Andreas and Aila, Timo},
  journal={arXiv preprint arXiv:2301.09515},
  year={2023}
}

@inproceedings{radford2021learning,
  title={Learning transferable visual models from natural language supervision},
  author={Radford, Alec and Kim, Jong Wook and Hallacy, Chris and Ramesh, Aditya and Goh, Gabriel and Agarwal, Sandhini and Sastry, Girish and Askell, Amanda and Mishkin, Pamela and Clark, Jack and others},
  booktitle={International conference on machine learning},
  pages={8748--8763},
  year={2021},
  organization={PMLR}
}




@book{schrodinger1931umkehrung,
  title={{\"U}ber die umkehrung der naturgesetze},
  author={Schr{\"o}dinger, Erwin},
  year={1931},
  publisher={Verlag der Akademie der Wissenschaften in Kommission bei Walter De Gruyter u~…}
}

@inproceedings{schrodinger1932theorie,
  title={Sur la th{\'e}orie relativiste de l'{\'e}lectron et l'interpr{\'e}tation de la m{\'e}canique quantique},
  author={Schr{\"o}dinger, Erwin},
  booktitle={Annales de l'institut Henri Poincar{\'e}},
  volume={2},
  number={4},
  pages={269--310},
  year={1932}
}


@article{metz2016unrolled,
  title={Unrolled generative adversarial networks},
  author={Metz, Luke and Poole, Ben and Pfau, David and Sohl-Dickstein, Jascha},
  journal={arXiv preprint arXiv:1611.02163},
  year={2016}
}


@article{hutter2021minimax,
  title={Minimax estimation of smooth optimal transport maps},
  author={H{\"u}tter, Jan-Christian and Rigollet, Philippe},
  year={2021}
}

@article{pooladian2021entropic,
  title={Entropic estimation of optimal transport maps},
  author={Pooladian, Aram-Alexandre and Niles-Weed, Jonathan},
  journal={arXiv preprint arXiv:2109.12004},
  year={2021}
}

@article{manole2021plugin,
  title={Plugin estimation of smooth optimal transport maps},
  author={Manole, Tudor and Balakrishnan, Sivaraman and Niles-Weed, Jonathan and Wasserman, Larry},
  journal={arXiv preprint arXiv:2107.12364},
  year={2021}
}

@article{deb2021rates,
  title={Rates of estimation of optimal transport maps using plug-in estimators via barycentric projections},
  author={Deb, Nabarun and Ghosal, Promit and Sen, Bodhisattva},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={29736--29753},
  year={2021}
}

@article{ReinhardAGS01,
  author    = {Erik Reinhard and
               Michael Ashikhmin and
               Bruce Gooch and
               Peter Shirley},
  title     = {Color Transfer between Images},
  journal   = {{IEEE} Computer Graphics and Applications},
  volume    = {21},
  number    = {5},
  pages     = {34--41},
  year      = {2001},
  url       = {https://doi.org/10.1109/38.946629},
  doi       = {10.1109/38.946629},
  timestamp = {Sat, 20 May 2017 00:25:50 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/cga/ReinhardAGS01},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{PapadakisPC11,
  author    = {Nicolas Papadakis and
               Edoardo Provenzi and
               Vicent Caselles},
  title     = {A Variational Model for Histogram Transfer of Color Images},
  journal   = {{IEEE} Trans. Image Processing},
  volume    = {20},
  number    = {6},
  pages     = {1682--1695},
  year      = {2011},
  url       = {https://doi.org/10.1109/TIP.2010.2095869},
  doi       = {10.1109/TIP.2010.2095869},
  timestamp = {Wed, 14 Nov 2018 10:38:23 +0100},
  biburl    = {https://dblp.org/rec/bib/journals/tip/PapadakisPC11},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{NeumannN05,
  author    = {Attila Neumann and
               L{\'{a}}szl{\'{o}} Neumann},
  title     = {Color Style Transfer Techniques using Hue, Lightness and Saturation
               Histogram Matching},
  booktitle = {Computational Aesthetics 2005: Eurographics Workshop on Computational
               Aesthetics in Graphics, Visualization and Imaging 2005, Girona, Spain,
               May 18-20, 2005},
  pages     = {111--122},
  year      = {2005},
  url       = {https://doi.org/10.2312/COMPAESTH/COMPAESTH05/111-122},
  doi       = {10.2312/COMPAESTH/COMPAESTH05/111-122},
  timestamp = {Thu, 25 May 2017 00:43:04 +0200},
  biburl    = {https://dblp.org/rec/bib/conf/cae/NeumannN05},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{PouliR11,
  author    = {Tania Pouli and
               Erik Reinhard},
  title     = {Progressive color transfer for images of arbitrary dynamic range},
  journal   = {Computers {\&} Graphics},
  volume    = {35},
  number    = {1},
  pages     = {67--80},
  year      = {2011},
  url       = {https://doi.org/10.1016/j.cag.2010.11.003},
  doi       = {10.1016/j.cag.2010.11.003},
  timestamp = {Wed, 17 May 2017 10:56:17 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/cg/PouliR11},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{korotin2019integral,
  title={Integral Mixability: a Tool for Efficient Online Aggregation of Functional and Probabilistic Forecasts},
  author={Korotin, Alexander and V'yugin, Vladimir and Burnaev, Evgeny},
  journal={arXiv preprint arXiv:1912.07048},
  year={2019}
}

@inproceedings{
    korotin2023kernel,
    title={Kernel Neural Optimal Transport},
    author={Korotin, Alexander and Selikhanovych, Daniil and Burnaev, Evgeny},
    booktitle={International Conference on Learning Representations},
    year={2023},
    url={https://openreview.net/forum?id=Zuc_MHtUma4}
}

@article{sejdinovic2013equivalence,
  title={Equivalence of distance-based and RKHS-based statistics in hypothesis testing},
  author={Sejdinovic, Dino and Sriperumbudur, Bharath and Gretton, Arthur and Fukumizu, Kenji},
  journal={The annals of statistics},
  pages={2263--2291},
  year={2013},
  publisher={JSTOR}
}


@article{
fan2021scalable,
    title={Neural Monge Map estimation and its applications},
    author={Jiaojiao Fan and Shu Liu and Shaojun Ma and Hao-Min Zhou and Yongxin Chen},
    journal={Transactions on Machine Learning Research},
    issn={2835-8856},
    year={2023},
    url={https://openreview.net/forum?id=2mZSlQscj3},
    note={Featured Certification}
}


@inproceedings{rout2021generative,
  title={Generative Modeling with Optimal Transport Maps},
  author={Rout, Litu and Korotin, Alexander and Burnaev, Evgeny},
  booktitle={International Conference on Learning Representations},
  year={2021}
}


@article{korotin2021neural,
  title={Do neural optimal transport solvers work? a continuous wasserstein-2 benchmark},
  author={Korotin, Alexander and Li, Lingxiao and Genevay, Aude and Solomon, Justin M and Filippov, Alexander and Burnaev, Evgeny},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={14593--14605},
  year={2021}
}

@inproceedings{
korotin2022kantorovich,
title={Kantorovich Strikes Back! Wasserstein {GAN}s are not Optimal Transport?},
author={Alexander Korotin and Alexander Kolesov and Evgeny Burnaev},
booktitle={Thirty-sixth Conference on Neural Information Processing Systems Datasets and Benchmarks Track},
year={2022},
url={https://openreview.net/forum?id=VtEEpi-dGlt}
}


@inproceedings{
korotin2021continuous,
title={Continuous Wasserstein-2 Barycenter Estimation without Minimax Optimization},
author={Alexander Korotin and Lingxiao Li and Justin Solomon and Evgeny Burnaev},
booktitle={International Conference on Learning Representations},
year={2021},
url={https://openreview.net/forum?id=3tFAs5E-Pe}
}

@article{srivastava2018scalable,
  title={Scalable Bayes via barycenter in {W}asserstein space},
  author={Srivastava, Sanvesh and Li, Cheng and Dunson, David B},
  journal={The Journal of Machine Learning Research},
  volume={19},
  number={1},
  pages={312--346},
  year={2018},
  publisher={JMLR. org}
}



@article{santambrogio2015optimal,
  title={Optimal transport for applied mathematicians},
  author={Santambrogio, Filippo},
  journal={Birk{\"a}user, NY},
  volume={55},
  number={58-63},
  pages={94},
  year={2015},
  publisher={Springer}
}

@inproceedings{srivastava2015wasp,
  title={WASP: Scalable Bayes via barycenters of subset posteriors},
  author={Srivastava, Sanvesh and Cevher, Volkan and Dinh, Quoc and Dunson, David},
  booktitle={Artificial Intelligence and Statistics},
  pages={912--920},
  year={2015}
}

@article{huang2020convex,
  title={Convex Potential Flows: Universal Probability Distributions with Optimal Transport and Convex Optimization},
  author={Huang, Chin-Wei and Chen, Ricky TQ and Tsirigotis, Christos and Courville, Aaron},
  journal={arXiv preprint arXiv:2012.05942},
  year={2020}
}

@inproceedings{luo2018wgan,
  title={W{GAN} domain adaptation for EEG-based emotion recognition},
  author={Luo, Yun and Zhang, Si-Yang and Zheng, Wei-Long and Lu, Bao-Liang},
  booktitle={International Conference on Neural Information Processing},
  pages={275--286},
  year={2018},
  organization={Springer}
}

@article{liu2016stein,
  title={Stein variational gradient descent: A general purpose bayesian inference algorithm},
  author={Liu, Qiang and Wang, Dilin},
  journal={arXiv preprint arXiv:1608.04471},
  year={2016}
}


@article{cao2019multi,
  title={Multi-marginal {W}asserstein {GAN}},
  author={Cao, Jiezhang and Mo, Langyuan and Zhang, Yifan and Jia, Kui and Shen, Chunhua and Tan, Mingkui},
  journal={arXiv preprint arXiv:1911.00888},
  year={2019}
}

@inproceedings{liu2018two,
  title={A two-step computation of the exact {GAN} {W}asserstein distance},
  author={Liu, Huidong and Xianfeng, GU and Samaras, Dimitris},
  booktitle={International Conference on Machine Learning},
  pages={3159--3168},
  year={2018},
  organization={PMLR}
}



@inproceedings{wu2018wasserstein,
  title={Wasserstein divergence for {GAN}s},
  author={Wu, Jiqing and Huang, Zhiwu and Thoma, Janine and Acharya, Dinesh and Van Gool, Luc},
  booktitle={Proceedings of the European Conference on Computer Vision (ECCV)},
  pages={653--668},
  year={2018}
}

@inproceedings{shen2018wasserstein,
  title={Wasserstein distance guided representation learning for domain adaptation},
  author={Shen, Jian and Qu, Yanru and Zhang, Weinan and Yu, Yong},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={32},
  number={1},
  year={2018}
}

@incollection{robert1999metropolis,
  title={The metropolis—hastings algorithm},
  author={Robert, Christian P and Casella, George},
  booktitle={Monte Carlo Statistical Methods},
  pages={231--283},
  year={1999},
  publisher={Springer}
}

@inproceedings{liu2015faceattributes,
 title = {Deep Learning Face Attributes in the Wild},
 author = {Liu, Ziwei and Luo, Ping and Wang, Xiaogang and Tang, Xiaoou},
 booktitle = {Proceedings of International Conference on Computer Vision (ICCV)},
 month = {December},
 year = {2015} 
}

@article{cohen2020estimating,
  title={Estimating Barycenters of Measures in High Dimensions},
  author={Cohen, Samuel and Arbel, Michael and Deisenroth, Marc Peter},
  journal={arXiv preprint arXiv:2007.07105},
  year={2020}
}

@inproceedings{lucic2018gans,
  title={Are {GAN}s created equal? a large-scale study},
  author={Lucic, Mario and Kurach, Karol and Michalski, Marcin and Gelly, Sylvain and Bousquet, Olivier},
  booktitle={Advances in neural information processing systems},
  pages={700--709},
  year={2018}
}

@article{fan2020scalable,
  title={Scalable Computations of {W}asserstein Barycenter via Input Convex Neural Networks},
  author={Fan, Jiaojiao and Taghvaei, Amirhossein and Chen, Yongxin},
  journal={arXiv preprint arXiv:2007.04462},
  year={2020}
}

@inproceedings{rabin2014adaptive,
  title={Adaptive color transfer with relaxed optimal transport},
  author={Rabin, Julien and Ferradans, Sira and Papadakis, Nicolas},
  booktitle={2014 IEEE International Conference on Image Processing (ICIP)},
  pages={4852--4856},
  year={2014},
  organization={IEEE}
}

@article{HeLCYS19,
  author    = {Mingming He and
               Jing Liao and
               Dongdong Chen and
               Lu Yuan and
               Pedro V. Sander},
  title     = {Progressive Color Transfer With Dense Semantic Correspondences},
  journal   = {{ACM} Trans. Graph.},
  volume    = {38},
  number    = {2},
  pages     = {13:1--13:18},
  year      = {2019},
  url       = {https://doi.org/10.1145/3292482},
  doi       = {10.1145/3292482},
  timestamp = {Thu, 09 Jan 2020 08:16:33 +0100},
  biburl    = {https://dblp.org/rec/bib/journals/tog/HeLCYS19},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{paty2019regularity,
  title={Regularity as Regularization: Smooth and Strongly Convex Brenier Potentials in Optimal Transport},
  author={Paty, Fran{\c{c}}ois-Pierre and d'Aspremont, Alexandre and Cuturi, Marco},
  journal={arXiv preprint arXiv:1905.10812},
  year={2019}
}

@article{courty2016optimal,
  title={Optimal transport for domain adaptation},
  author={Courty, Nicolas and Flamary, R{\'e}mi and Tuia, Devis and Rakotomamonjy, Alain},
  journal={IEEE transactions on pattern analysis and machine intelligence},
  volume={39},
  number={9},
  pages={1853--1865},
  year={2016},
  publisher={IEEE}
}


@inproceedings{courty2017joint,
  title={Joint distribution optimal transportation for domain adaptation},
  author={Courty, Nicolas and Flamary, R{\'e}mi and Habrard, Amaury and Rakotomamonjy, Alain},
  booktitle={Advances in Neural Information Processing Systems},
  pages={3730--3739},
  year={2017}
}


@article{redko2018optimal,
  title={Optimal transport for multi-source domain adaptation under target shift},
  author={Redko, Ievgen and Courty, Nicolas and Flamary, R{\'e}mi and Tuia, Devis},
  journal={arXiv preprint arXiv:1803.04899},
  year={2018}
}


@inproceedings{bhushan2018deepjdot,
  title={Deepjdot: Deep joint distribution optimal transport for unsupervised domain adaptation},
  author={Bhushan Damodaran, Bharath and Kellenberger, Benjamin and Flamary, R{\'e}mi and Tuia, Devis and Courty, Nicolas},
  booktitle={Proceedings of the European Conference on Computer Vision (ECCV)},
  pages={447--463},
  year={2018}
}

@article{chen2021stochastic,
  title={Stochastic control liaisons: Richard sinkhorn meets gaspard monge on a schrodinger bridge},
  author={Chen, Yongxin and Georgiou, Tryphon T and Pavon, Michele},
  journal={SIAM Review},
  volume={63},
  number={2},
  pages={249--313},
  year={2021},
  publisher={SIAM}
}

@article{pavon2021data,
  title={The Data-Driven Schr{\"o}dinger Bridge},
  author={Pavon, Michele and Trigila, Giulio and Tabak, Esteban G},
  journal={Communications on Pure and Applied Mathematics},
  volume={74},
  number={7},
  pages={1545--1573},
  year={2021},
  publisher={Wiley Online Library}
}

@article{gozlan2017kantorovich,
  title={Kantorovich duality for general transport costs and applications},
  author={Gozlan, Nathael and Roberto, Cyril and Samson, Paul-Marie and Tetali, Prasad},
  journal={Journal of Functional Analysis},
  volume={273},
  number={11},
  pages={3327--3405},
  year={2017},
  publisher={Elsevier}
}

@article{backhoff2019existence,
  title={Existence, duality, and cyclical monotonicity for weak transport costs},
  author={Backhoff-Veraguas, Julio and Beiglb{\"o}ck, Mathias and Pammer, Gudmun},
  journal={Calculus of Variations and Partial Differential Equations},
  volume={58},
  number={6},
  pages={1--28},
  year={2019},
  publisher={Springer}
}

@inproceedings{kantorovich1942translocation,
  title={On the translocation of masses},
  author={Kantorovich, Leonid V},
  booktitle={Dokl. Akad. Nauk. USSR (NS)},
  volume={37},
  pages={199--201},
  year={1942}
}

@article{mallasto2022entropy,
  title={Entropy-regularized 2-Wasserstein distance between Gaussian measures},
  author={Mallasto, Anton and Gerolin, Augusto and Minh, H{\`a} Quang},
  journal={Information Geometry},
  volume={5},
  number={1},
  pages={289--323},
  year={2022},
  publisher={Springer}
}

@article{paty2022algorithms,
  title={Algorithms for Weak Optimal Transport with an Application to Economics},
  author={Paty, Fran{\c{c}}ois-Pierre and Chon{\'e}, Philippe and Kramarz, Francis},
  journal={arXiv preprint arXiv:2205.09825},
  year={2022}
}

@inproceedings{
    asadulaev2022neural,
    title={Neural Optimal Transport with General Cost Functionals},
    author={Arip Asadulaev and Alexander Korotin and Vage Egiazarian and Petr Mokrov and Evgeny Burnaev},
    booktitle={The Twelfth International Conference on Learning Representations},
    year={2024},
    url={https://openreview.net/forum?id=gIiz7tBtYZ}
}

@article{cuturi2013sinkhorn,
  title={Sinkhorn distances: Lightspeed computation of optimal transport},
  author={Cuturi, Marco},
  journal={Advances in neural information processing systems},
  volume={26},
  year={2013}
}

% inproceedings{cuturi2014fast,
%  title={Fast computation of Wasserstein barycenters},
  author={Cuturi, Marco and Doucet, Arnaud},
  booktitle={International conference on machine learning},
  pages={685--693},
  year={2014},
  organization={PMLR}
}

@article{dvurechenskii2018decentralize,
  title={Decentralize and randomize: Faster algorithm for Wasserstein barycenters},
  author={Dvurechenskii, Pavel and Dvinskikh, Darina and Gasnikov, Alexander and Uribe, Cesar and Nedich, Angelia},
  journal={Advances in Neural Information Processing Systems},
  volume={31},
  year={2018}
}

@article{staib2017parallel,
  title={Parallel streaming Wasserstein barycenters},
  author={Staib, Matthew and Claici, Sebastian and Solomon, Justin M and Jegelka, Stefanie},
  journal={Advances in Neural Information Processing Systems},
  volume={30},
  year={2017}
}


@article{daniels2021score,
  title={Score-based generative neural networks for large-scale optimal transport},
  author={Daniels, Max and Maunu, Tyler and Hand, Paul},
  journal={Advances in neural information processing systems},
  volume={34},
  pages={12955--12965},
  year={2021}
}

@article{janati2020entropic,
  title={Entropic optimal transport between unbalanced Gaussian measures has a closed form},
  author={Janati, Hicham and Muzellec, Boris and Peyr{\'e}, Gabriel and Cuturi, Marco},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={10468--10479},
  year={2020}
}

@book{karatzas2012brownian,
  title={Brownian motion and stochastic calculus},
  author={Karatzas, Ioannis and Shreve, Steven},
  volume={113},
  year={2012},
  publisher={Springer Science \& Business Media}
}


@article{backhoff2022applications,
  title={Applications of weak transport theory},
  author={Backhoff-Veraguas, Julio and Pammer, Gudmund},
  journal={Bernoulli},
  volume={28},
  number={1},
  pages={370--394},
  year={2022},
  publisher={Bernoulli Society for Mathematical Statistics and Probability}
}

@article{petersen2008matrix,
  title={The matrix cookbook},
  author={Petersen, Kaare Brandt and Pedersen, Michael Syskind and others},
  journal={Technical University of Denmark},
  volume={7},
  number={15},
  pages={510},
  year={2008}
}

@article{kingma2018glow,
  title={Glow: Generative flow with invertible 1x1 convolutions},
  author={Kingma, Durk P and Dhariwal, Prafulla},
  journal={Advances in neural information processing systems},
  volume={31},
  year={2018}
}


@inproceedings{
    gazdieva2023extremal,
    title={Extremal Domain Translation with Neural Optimal Transport},
    author={Milena Gazdieva and Alexander Korotin and Daniil Selikhanovych and Evgeny Burnaev},
    booktitle={Thirty-seventh Conference on Neural Information Processing Systems},
    year={2023},
    url={https://openreview.net/forum?id=vZRiMjo826}
}

@inproceedings{yang2018scalable,
  title={Scalable Unbalanced Optimal Transport using Generative Adversarial Networks},
  author={Yang, Karren D and Uhler, Caroline},
  booktitle={International Conference on Learning Representations},
  year={2018}
}




@article{fortet1940resolution,
  title={R{\'e}solution d'un syst{\`e}me d'{\'e}quations de M. Schr{\"o}dinger},
  author={Fortet, Robert},
  journal={Journal de Math{\'e}matiques Pures et Appliqu{\'e}es},
  volume={19},
  number={1-4},
  pages={83--105},
  year={1940}
}

@article{vargas2023transport,
  title={Transport, Variational Inference and Diffusions: with Applications to Annealed Flows and Schr$\backslash$" odinger Bridges},
  author={Vargas, Francisco and N{\"u}sken, Nikolas},
  journal={arXiv preprint arXiv:2307.01050},
  year={2023}
}

@article{dempster1977maximum,
  title={Maximum likelihood from incomplete data via the EM algorithm},
  author={Dempster, Arthur P and Laird, Nan M and Rubin, Donald B},
  journal={Journal of the royal statistical society: series B (methodological)},
  volume={39},
  number={1},
  pages={1--22},
  year={1977},
  publisher={Wiley Online Library}
}


@article{ruschendorf1995convergence,
  title={Convergence of the iterative proportional fitting procedure},
  author={Ruschendorf, Ludger},
  journal={The Annals of Statistics},
  pages={1160--1174},
  year={1995},
  publisher={JSTOR}
}


@article{kullback1968probability,
  title={Probability densities with given marginals},
  author={Kullback, Solomon},
  journal={The Annals of Mathematical Statistics},
  volume={39},
  number={4},
  pages={1236--1243},
  year={1968},
  publisher={JSTOR}
}



@phdthesis{genevay2019entropy,
  title={Entropy-regularized optimal transport for machine learning},
  author={Genevay, Aude},
  year={2019},
  school={Paris Sciences et Lettres (ComUE)}
}

@book{bishop2006pattern,
  title={Pattern recognition and machine learning},
  author={Bishop, Christopher M and Nasrabadi, Nasser M},
  volume={4},
  number={4},
  year={2006},
  publisher={Springer}
}

@article{song2021train,
  title={How to train your energy-based models},
  author={Song, Yang and Kingma, Diederik P},
  journal={arXiv preprint arXiv:2101.03288},
  year={2021}
}

@article{chen2020controlling,
  title={Controlling uncertainty: Schr{\"o}dinger’s inference method and the optimal steering of probability distributions},
  author={Chen, Y and Georgiou, TT and Pavon, M},
  journal={IEEE Control Syst. Mag},
  year={2020}
}

@article{pariset2023unbalanced,
  title={Unbalanced Diffusion Schr$\backslash$" odinger Bridge},
  author={Pariset, Matteo and Hsieh, Ya-Ping and Bunne, Charlotte and Krause, Andreas and De Bortoli, Valentin},
  journal={arXiv preprint arXiv:2306.09099},
  year={2023}
}


@article{chen2015optimal,
  title={Optimal steering of a linear stochastic system to a final probability distribution, Part I},
  author={Chen, Yongxin and Georgiou, Tryphon T and Pavon, Michele},
  journal={IEEE Transactions on Automatic Control},
  volume={61},
  number={5},
  pages={1158--1169},
  year={2015},
  publisher={IEEE}
}



@inproceedings{gushchin2023building,
  title={Building the Bridge of Schr$\backslash$" odinger: A Continuous Entropic Optimal Transport Benchmark},
  author={Gushchin, Nikita and Kolesov, Alexander and Mokrov, Petr and Karpikova, Polina and Spiridonov, Andrey and Burnaev, Evgeny and Korotin, Alexander},
  booktitle={Thirty-seventh Conference on Neural Information Processing Systems Datasets and Benchmarks Track},
  year={2023}
}

@article{rigollet2022sample,
  title={On the sample complexity of entropic optimal transport},
  author={Rigollet, Philippe and Stromme, Austin J},
  journal={arXiv preprint arXiv:2206.13472},
  year={2022}
}

@inproceedings{stromme2023sampling,
  title={Sampling From a Schr{\"o}dinger Bridge},
  author={Stromme, Austin},
  booktitle={International Conference on Artificial Intelligence and Statistics},
  pages={4058--4067},
  year={2023},
  organization={PMLR}
}


@inproceedings{fatras2020learning,
  title={Learning with minibatch Wasserstein: asymptotic and gradient properties},
  author={Fatras, Kilian and Zine, Younes and Flamary, R{\'e}mi and Gribonval, Remi and Courty, Nicolas},
  booktitle={International Conference on Artificial Intelligence and Statistics},
  pages={2131--2141},
  year={2020},
  organization={PMLR}
}



@article{rizzo2016energy,
  title={Energy distance},
  author={Rizzo, Maria L and Sz{\'e}kely, G{\'a}bor J},
  journal={wiley interdisciplinary reviews: Computational statistics},
  volume={8},
  number={1},
  pages={27--38},
  year={2016},
  publisher={Wiley Online Library}
}


@inproceedings{karras2019style,
  title={A style-based generator architecture for generative adversarial networks},
  author={Karras, Tero and Laine, Samuli and Aila, Timo},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={4401--4410},
  year={2019}
}

@book{mohri2018foundations,
  title={Foundations of machine learning},
  author={Mohri, Mehryar and Rostamizadeh, Afshin and Talwalkar, Ameet},
  year={2018},
  publisher={MIT press}
}



@article{xie2022accelerated,
  title={An accelerated stochastic algorithm for solving the optimal transport problem},
  author={Xie, Yiling and Luo, Yiling and Huo, Xiaoming},
  journal={arXiv preprint arXiv:2203.00813},
  year={2022}
}

@inproceedings{
    latorre2021the,
    title={The Effect of the Intrinsic Dimension on the Generalization of Quadratic Classifiers},
    author={Fabian Latorre and Leello Tadesse Dadi and Paul Rolland and Volkan Cevher},
    booktitle={Advances in Neural Information Processing Systems},
    editor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},
    year={2021},
    url={https://openreview.net/forum?id=_hKvtsqItc}
}

@book{shalev2014understanding,
  title={Understanding machine learning: From theory to algorithms},
  author={Shalev-Shwartz, Shai and Ben-David, Shai},
  year={2014},
  publisher={Cambridge university press}
}

@article{chen2023provably,
  title={Provably Convergent Schr{\"o}dinger Bridge with Applications to Probabilistic Time Series Imputation},
  author={Chen, Yu and Deng, Wei and Fang, Shikai and Li, Fengpei and Yang, Tianjiao Nicole and Zhang, Yikai and Rasul, Kashif and Zhe, Shandian and Schneider, Anderson and Nevmyvaka, Yuriy},
  year={2023}
}


@article{nguyen2022unbalanced,
  title={On Unbalanced Optimal Transport: Gradient Methods, Sparsity and Approximation Error},
  author={Nguyen, Quang Minh and Nguyen, Hoang H and Zhou, Yi and Nguyen, Lam M},
  journal={arXiv preprint arXiv:2202.03618},
  year={2022}
}



@book{kloeden1992,
author = {Kloeden, Peter E.},
address = {Berlin},
booktitle = {Numerical solution of stochastic differential equations},
isbn = {0387540628},
keywords = {Stochastic differential equations -- Numerical solutions},
language = {eng},
publisher = {Springer},
series = {Applications of mathematics; v. 23},
title = {Numerical solution of stochastic differential equations / Peter E. Kloeden, Eckhard Platen},
year = {1992},
}


@inproceedings{pidhorskyi2020adversarial,
  title={Adversarial latent autoencoders},
  author={Pidhorskyi, Stanislav and Adjeroh, Donald A and Doretto, Gianfranco},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={14104--14113},
  year={2020}
}


@inproceedings{
    korotin2023neural,
    title={Neural Optimal Transport},
    author={Korotin, Alexander and Selikhanovych, Daniil and Burnaev, Evgeny},
    booktitle={International Conference on Learning Representations},
    year={2023},
    url={https://openreview.net/forum?id=d8CBRlWNkqH}
}

@inproceedings{gushchin2023entropic,
  title={Entropic neural optimal transport via diffusion processes},
  author={Gushchin, Nikita and Kolesov, Alexander and Korotin, Alexander and Vetrov, Dmitry and Burnaev, Evgeny},
  booktitle={Advances in Neural Information Processing Systems},
  year={2023}
}

@inproceedings{
    mokrov2023energy,
    title={Energy-guided Entropic Neural Optimal Transport},
    author={Petr Mokrov and Alexander Korotin and Alexander Kolesov and Nikita Gushchin and Evgeny Burnaev},
    booktitle={The Twelfth International Conference on Learning Representations},
    year={2024},
    url={https://openreview.net/forum?id=d6tUsZeVs7}
}

@article{leonard2013survey,
  title={A survey of the schr$\backslash$" odinger problem and some of its connections with optimal transport},
  author={L{\'e}onard, Christian},
  journal={arXiv preprint arXiv:1308.0215},
  year={2013}
}

@book{williams2006gaussian,
  title={Gaussian processes for machine learning},
  author={Williams, Christopher KI and Rasmussen, Carl Edward},
  volume={2},
  number={3},
  year={2006},
  publisher={MIT press Cambridge, MA}
}

@article{tong2023simulation,
  title={Simulation-free Schr$\backslash$" odinger bridges via score and flow matching},
  author={Tong, Alexander and Malkin, Nikolay and Fatras, Kilian and Atanackovic, Lazar and Zhang, Yanlei and Huguet, Guillaume and Wolf, Guy and Bengio, Yoshua},
  journal={arXiv preprint arXiv:2307.03672},
  year={2023}
}

@inproceedings{bunne2022proximal,
  title={Proximal optimal transport modeling of population dynamics},
  author={Bunne, Charlotte and Papaxanthos, Laetitia and Krause, Andreas and Cuturi, Marco},
  booktitle={International Conference on Artificial Intelligence and Statistics},
  pages={6511--6528},
  year={2022},
  organization={PMLR}
}

@inproceedings{tong2020trajectorynet,
  title={Trajectorynet: A dynamic optimal transport network for modeling cellular dynamics},
  author={Tong, Alexander and Huang, Jessie and Wolf, Guy and Van Dijk, David and Krishnaswamy, Smita},
  booktitle={International conference on machine learning},
  pages={9526--9536},
  year={2020},
  organization={PMLR}
}

@incollection{PINSKY2011391,
title = {8 - Brownian Motion and Related Processes},
editor = {Mark A. Pinsky and Samuel Karlin},
booktitle = {An Introduction to Stochastic Modeling (Fourth Edition)},
publisher = {Academic Press},
edition = {Fourth Edition},
address = {Boston},
pages = {391-446},
year = {2011},
isbn = {978-0-12-381416-6},
doi = {https://doi.org/10.1016/B978-0-12-381416-6.00008-3},
url = {https://www.sciencedirect.com/science/article/pii/B9780123814166000083},
author = {Mark A. Pinsky and Samuel Karlin}
}

@inproceedings{
    shi2023diffusion,
    title={Diffusion Schr\"odinger Bridge Matching},
    author={Yuyang Shi and Valentin De Bortoli and Andrew Campbell and Arnaud Doucet},
    booktitle={Thirty-seventh Conference on Neural Information Processing Systems},
    year={2023},
    url={https://openreview.net/forum?id=qy07OHsJT5}
}

@inproceedings{
    kim2023unpaired,
    title={Unpaired Image-to-Image Translation via Neural Schr\"odinger Bridge},
    author={Beomsu Kim and Gihyun Kwon and Kwanyoung Kim and Jong Chul Ye},
    booktitle={The Twelfth International Conference on Learning Representations},
    year={2024},
    url={https://openreview.net/forum?id=uQBW7ELXfO}
}

@article{bunne2021learning,
  title={Learning single-cell perturbation responses using neural optimal transport},
  author={Bunne, Charlotte and Stark, Stefan G and Gut, Gabriele and del Castillo, Jacobo Sarabia and Lehmann, Kjong-Van and Pelkmans, Lucas and Krause, Andreas and R{\"a}tsch, Gunnar},
  journal={bioRxiv},
  pages={2021--12},
  year={2021},
  publisher={Cold Spring Harbor Laboratory}
}

@article{liu2023_i2isb,
  title={I$^2$SB: Image-to-Image Schr$\backslash$" odinger Bridge},
  author={Liu, Guan-Horng and Vahdat, Arash and Huang, De-An and Theodorou, Evangelos A and Nie, Weili and Anandkumar, Anima},
  journal={arXiv preprint arXiv:2302.05872},
  year={2023}
}

@article{gushchin2024adversarial,
  title={Adversarial Schr$\backslash$" odinger Bridge Matching},
  author={Gushchin, Nikita and Selikhanovych, Daniil and Kholkin, Sergei and Burnaev, Evgeny and Korotin, Alexander},
  journal={arXiv preprint arXiv:2405.14449},
  year={2024}
}

@inproceedings{somnath2023aligned,
  title={Aligned diffusion Schr{\"o}dinger bridges},
  author={Somnath, Vignesh Ram and Pariset, Matteo and Hsieh, Ya-Ping and Martinez, Maria Rodriguez and Krause, Andreas and Bunne, Charlotte},
  booktitle={Uncertainty in Artificial Intelligence},
  pages={1985--1995},
  year={2023},
  organization={PMLR}
}

@article{chen2023schrodinger,
  title={Schrodinger bridges beat diffusion models on text-to-speech synthesis},
  author={Chen, Zehua and He, Guande and Zheng, Kaiwen and Tan, Xu and Zhu, Jun},
  journal={arXiv preprint arXiv:2312.03491},
  year={2023}
}

@inproceedings{tong2024simulation,
  title={Simulation-Free Schr{\"o}dinger Bridges via Score and Flow Matching},
  author={Tong, Alexander Y and Malkin, Nikolay and Fatras, Kilian and Atanackovic, Lazar and Zhang, Yanlei and Huguet, Guillaume and Wolf, Guy and Bengio, Yoshua},
  booktitle={International Conference on Artificial Intelligence and Statistics},
  pages={1279--1287},
  year={2024},
  organization={PMLR}
}

@inproceedings{igashovretrobridge,
  title={RetroBridge: Modeling Retrosynthesis with Markov Bridges},
  author={Igashov, Ilia and Schneuing, Arne and Segler, Marwin and Bronstein, Michael M and Correia, Bruno},
  booktitle={The Twelfth International Conference on Learning Representations},
  year={2024}
}

%article{de2021diffusion,
%  title={Diffusion schr{\"o}dinger bridge with applications to score-based generative modeling},
  author={De Bortoli, Valentin and Thornton, James and Heng, Jeremy and Doucet, Arnaud},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={17695--17709},
  year={2021}
}

%%article{liu2022flow,
%  title={Flow straight and fast: Learning to generate and transfer data with rectified flow},
  author={Liu, Xingchao and Gong, Chengyue and Liu, Qiang},
  journal={arXiv preprint arXiv:2209.03003},
  year={2022}
}

@article{esser2024scaling,
  title={Scaling rectified flow transformers for high-resolution image synthesis},
  author={Esser, Patrick and Kulal, Sumith and Blattmann, Andreas and Entezari, Rahim and M{\"u}ller, Jonas and Saini, Harry and Levi, Yam and Lorenz, Dominik and Sauer, Axel and Boesel, Frederic and others},
  journal={arXiv preprint arXiv:2403.03206},
  year={2024}
}

@article{peluchetti2024bm,
  title={BM$^2$: Coupled Schr$\backslash$"$\{$o$\}$ dinger Bridge Matching},
  author={Peluchetti, Stefano},
  journal={arXiv preprint arXiv:2409.09376},
  year={2024}
}

@article{de2024schr,
  title={Schr$\backslash$" odinger Bridge Flow for Unpaired Data Translation},
  author={De Bortoli, Valentin and Korshunova, Iryna and Mnih, Andriy and Doucet, Arnaud},
  journal={arXiv preprint arXiv:2409.09347},
  year={2024}
}

@inproceedings{karimi2024sinkhorn,
  title={Sinkhorn Flow as Mirror Flow: A Continuous-Time Framework for Generalizing the Sinkhorn Algorithm},
  author={Karimi, Mohammad Reza and Hsieh, Ya-Ping and Krause, Andreas},
  booktitle={International Conference on Artificial Intelligence and Statistics},
  pages={4186--4194},
  year={2024},
  organization={PMLR}
}

%%% article{kullback1968probability,
%%  title={Probability densities with given marginals},
  author={Kullback, Solomon},
  journal={The Annals of Mathematical Statistics},
  volume={39},
  number={4},
  pages={1236--1243},
  year={1968},
  publisher={JSTOR}
}

@inproceedings{
vargas2024transport,
title={Transport meets Variational Inference: Controlled Monte Carlo Diffusions},
author={Francisco Vargas and Shreyas Padhy and Denis Blessing and Nikolas N{\"u}sken},
booktitle={The Twelfth International Conference on Learning Representations},
year={2024},
url={https://openreview.net/forum?id=PP1rudnxiW}
}

@inproceedings{ronneberger2015u,
  title={U-net: Convolutional networks for biomedical image segmentation},
  author={Ronneberger, Olaf and Fischer, Philipp and Brox, Thomas},
  booktitle={Medical image computing and computer-assisted intervention--MICCAI 2015: 18th international conference, Munich, Germany, October 5-9, 2015, proceedings, part III 18},
  pages={234--241},
  year={2015},
  organization={Springer}
}

@inproceedings{mescheder2018training,
  title={Which training methods for GANs do actually converge?},
  author={Mescheder, Lars and Geiger, Andreas and Nowozin, Sebastian},
  booktitle={International conference on machine learning},
  pages={3481--3490},
  year={2018},
  organization={PMLR}
}

@inproceedings{xiaotackling,
  title={Tackling the Generative Learning Trilemma with Denoising Diffusion GANs},
  author={Xiao, Zhisheng and Kreis, Karsten and Vahdat, Arash},
  booktitle={International Conference on Learning Representations}
}

@inproceedings{liu2022let,
  title={Let us Build Bridges: Understanding and Extending Diffusion Generative Models},
  author={Liu, Xingchao and Wu, Lemeng and Ye, Mao and others},
  booktitle={NeurIPS 2022 Workshop on Score-Based Methods}
}
@inproceedings{jayasumana2024rethinking,
  title={Rethinking fid: Towards a better evaluation metric for image generation},
  author={Jayasumana, Sadeep and Ramalingam, Srikumar and Veit, Andreas and Glasner, Daniel and Chakrabarti, Ayan and Kumar, Sanjiv},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={9307--9315},
  year={2024}
}
@article{leonard2014reciprocal,
  title={Reciprocal processes. A measure-theoretical point of view},
  author={L{\'e}onard, Christian and R{\oe}lly, Sylvie and Zambrini, Jean-Claude},
  journal={Probability Surveys},
  volume={11},
  pages={237--269},
  year={2014}
}

@inproceedings{brekelmans2023schrodinger,
  title={On Schr{\"o}dinger Bridge Matching and Expectation Maximization},
  author={Brekelmans, Rob and Neklyudov, Kirill},
  booktitle={NeurIPS 2023 Workshop Optimal Transport and Machine Learning},
  year={2023}
}

@book{ibe2013markov,
  title={Markov processes for stochastic modeling},
  author={Ibe, Oliver},
  year={2013},
  publisher={Newnes}
}
@article{peluchetti2023non,
  title={Non-denoising forward-time diffusions},
  author={Peluchetti, Stefano},
  journal={arXiv preprint arXiv:2312.14589},
  year={2023}
}
@article{meng2021sdedit,
  title={Sdedit: Guided image synthesis and editing with stochastic differential equations},
  author={Meng, Chenlin and He, Yutong and Song, Yang and Song, Jiaming and Wu, Jiajun and Zhu, Jun-Yan and Ermon, Stefano},
  journal={arXiv preprint arXiv:2108.01073},
  year={2021}
}
@article{song2020denoising,
  title={Denoising diffusion implicit models},
  author={Song, Jiaming and Meng, Chenlin and Ermon, Stefano},
  journal={arXiv preprint arXiv:2010.02502},
  year={2020}
}
@inproceedings{wolf2020transformers,
  title={Transformers: State-of-the-art natural language processing},
  author={Wolf, Thomas and Debut, Lysandre and Sanh, Victor and Chaumond, Julien and Delangue, Clement and Moi, Anthony and Cistac, Pierric and Rault, Tim and Louf, R{\'e}mi and Funtowicz, Morgan and others},
  booktitle={Proceedings of the 2020 conference on empirical methods in natural language processing: system demonstrations},
  pages={38--45},
  year={2020}
}

@inproceedings{zhoudenoising,
  title={Denoising Diffusion Bridge Models},
  author={Zhou, Linqi and Lou, Aaron and Khanna, Samar and Ermon, Stefano},
  booktitle={The Twelfth International Conference on Learning Representations},
  year={2024}
}

@article{de2023augmented,
  title={Augmented Bridge Matching},
  author={De Bortoli, Valentin and Liu, Guan-Horng and Chen, Tianrong and Theodorou, Evangelos A and Nie, Weilie},
  journal={arXiv preprint arXiv:2311.06978},
  year={2023}
}
@article{huang2024schrodinger,
  title={Schr{\"o}dinger-F{\"o}llmer Sampler},
  author={Huang, Jian and Jiao, Yuling and Kang, Lican and Liao, Xu and Liu, Jin and Liu, Yanyan},
  journal={IEEE Transactions on Information Theory},
  year={2024},
  publisher={IEEE}
}
@article{vargas2023bayesian,
  title={Bayesian learning via neural Schr{\"o}dinger--F{\"o}llmer flows},
  author={Vargas, Francisco and Ovsianas, Andrius and Fernandes, David and Girolami, Mark and Lawrence, Neil D and N{\"u}sken, Nikolas},
  journal={Statistics and Computing},
  volume={33},
  number={1},
  pages={3},
  year={2023},
  publisher={Springer}
}
@inproceedings{gushchin2024light,
  title={Light and Optimal Schr{\"o}dinger Bridge Matching},
  author={Gushchin, Nikita and Kholkin, Sergei and Burnaev, Evgeny and Korotin, Alexander},
  booktitle={Forty-first International Conference on Machine Learning},
  year={2024},
}
@article{leonard2014some,
  title={Some properties of path measures},
  author={L{\'e}onard, Christian},
  journal={S{\'e}minaire de Probabilit{\'e}s XLVI},
  pages={207--230},
  year={2014},
  publisher={Springer}
}
@book{oksendal2003stochastic,
  title={Stochastic differential equations},
  author={{\O}ksendal, Bernt},
  year={2003},
  publisher={Springer}
}
@article{palmowski2002technique,
  title={A Technique for Exponential Change of Measure for Markov Processes},
  author={Palmowski, Zbigniew and Rolski, Tomasz},
  journal={Bernoulli},
  pages={767--785},
  year={2002},
  publisher={JSTOR}
}
@inproceedings{ho2021classifier,
  title={Classifier-Free Diffusion Guidance},
  author={Ho, Jonathan and Salimans, Tim},
  booktitle={NeurIPS 2021 Workshop on Deep Generative Models and Downstream Applications},
  year={2021}
}
@inproceedings{
bortoli2024schrodinger,
title={Schrodinger Bridge Flow for Unpaired Data Translation},
author={Valentin De Bortoli and Iryna Korshunova and Andriy Mnih and Arnaud Doucet},
booktitle={The Thirty-eighth Annual Conference on Neural Information Processing Systems},
year={2024},
url={https://openreview.net/forum?id=1F32iCJFfa}
}
@inproceedings{
    kim2024simplereflow_thorton,
    title={Simple ReFlow: Improved Techniques for Fast Flow Models},
    author={Kim, Beomsu and Hsieh, Yu-Guan and Klein, Michal and Cuturi, Marco and Ye, Jong Chul and Kawar, Bahjat and Thornton, James},
    booktitle={The Thirteenth International Conference on Learning Representations},
    year={2025},
    url={https://openreview.net/forum?id=fpvgSDKXGY}
}
@article{yoon2023score_levy,
  title={Score-based generative models with L{\'e}vy processes},
  author={Yoon, Eun Bi and Park, Keehun and Kim, Sungwoong and Lim, Sungbin},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  pages={40694--40707},
  year={2023}
}
@inproceedings{bounoua2024somegai_franceze_O_info,
  title={S$\Omega$I: Score-based O-Information Estimation},
  author={Bounoua, Mustapha and Franzese, Giulio and Michiardi, Pietro},
  booktitle={ICML 2024, 41st International Conference on Machine Learning},
  year={2024}
}
@article{runge2019inferring,
  title={Inferring causation from time series in Earth system sciences},
  author={Runge, Jakob and Bathiany, Sebastian and Bollt, Erik and Camps-Valls, Gustau and Coumou, Dim and Deyle, Ethan and Glymour, Clark and Kretschmer, Marlene and Mahecha, Miguel D and Mu{\~n}oz-Mar{\'\i}, Jordi and others},
  journal={Nature communications},
  volume={10},
  number={1},
  pages={2553},
  year={2019},
  publisher={Nature Publishing Group UK London}
}
@article{dosi2019more,
  title={More is different... and complex! the case for agent-based macroeconomics},
  author={Dosi, Giovanni and Roventini, Andrea},
  journal={Journal of Evolutionary Economics},
  volume={29},
  pages={1--37},
  year={2019},
  publisher={Springer}
}
@article{xu2017information,
  title={Information-theoretic analysis of generalization capability of learning algorithms},
  author={Xu, Aolin and Raginsky, Maxim},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}