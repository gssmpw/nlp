\begin{table*}[t]
  \centering
  \begin{adjustbox}{width=0.95\linewidth}
  \begin{tabular}{@{}lcccccc@{}}
    \toprule
    \textbf{Method}      &      On-device LLM Size      &               STEM          &      Humanities      &      Social Sciences      &      Other      &      Average  \\ \cmidrule(lr){1-7}
    LLaMA                &        7B            &                 27.8        &         33.2         &           30.9            &      33.0       &       31.0    \\
    LLaMA (few-shot)\textsuperscript{\textdagger}& 7B&            30.5        &         34.0         &           38.3            &      38.1       &       35.1    \\
    LLaMA                &        13B           &                 35.0        &         43.5         &           45.9            &      42.6       &       41.1    \\ 
    LLaMA (few-shot)\textsuperscript{\textdagger}& 13B&           35.8        &         45.0         &           53.8            &      53.3       &       46.9    \\ \cmidrule(lr){1-7}
    Single LoRA         &        7B + 14M            &                  33.2        &         44.6         &           43.4            &      44.6       &       40.7    \\
    Single LoRA (few-shot)      &        7B + 14M            &          29.7        &         33.1         &           33.1            &      39.2       &      33.5 \\
    %LoRA($r=128$)        &        7B            &           7.3\%          &       39.2           &         53.7         &           52.9            &      50.7       &       48.2    \\
    % LoRA($r=4$)          &        7B            &           0.2\%          &       33.4           &         43.9         &           43.3            &      40.3       &       39.6    \\
    % LoRA($r=4$)          &        7B            &           0.2\%          &       31.5           &         43.0         &           41.8            &      42.6       &       39.0    \\
    % LoRA($r=4$)          &        7B            &           0.2\%          &       32.1           &         43.4         &           40.3            &      38.6       &       38.0    \\
    LoraHub\textsuperscript{\textdaggerdbl}& 7B + 14M&                35.1         &         47.3         &           46.2            &      44.1       &       42.4    \\ \cmidrule(lr){1-7}
    \alg                 &        7B + 14M           &                36.1         &         50.0         &           49.8            &      46.0       &       44.6    \\ 
    \alg + Hybrid(20\%)        &        7B + 14M      &      \textbf{38.6}          &         \textbf{53.6}         &           \textbf{57.6}            &      \textbf{48.6}      &       \textbf{47.6}    \\
    % LoRA                 &        7B            &                         &       34.50          &         47.32        &           44.66           &      42.45      &       41.52   \\ 
   
    \bottomrule
    
    \end{tabular}
    \end{adjustbox}
  \caption{\textbf{Acc (\%) for MMLU tasks.} \textdagger{} indicates the reported performance from original paper~\cite{touvron2023llama} that utilize few-shot learning by following ~\cite{hendrycks2020measuring}. \textdaggerdbl{} mostly follows ~\cite{huang2023lorahub}, but we modify the base model (FLAN-T5 $\xrightarrow{}$ LLaMA-7B) and upstream tasks (BBH $\xrightarrow{}$ \{SIQA, MCQA, OBQA\}). For more details, see \autoref{sec:app:baselines}.
  } 
  \label{tab:mmlu_mainresults}
\end{table*}