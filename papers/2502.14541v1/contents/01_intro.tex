\section{Introduction} 

The rapid advancement of Large Language Models (LLMs) \cite{touvron2023llama, dubey2024llama, achiam2023gpt, team2024gemma} has significantly impacted various domains, such as text summarization \cite{lewis2019bart} and search~\cite{karpukhin2020dense}. Recent studies leverage LLMs in recommender systems for their human-like reasoning and external knowledge integration through in-context learning \cite{brown2020language} and retrieval-augmented generation \cite{lewis2020retrieval}. As such, LLMs exhibit the potential to be used as \emph{zero-shot} recommendation models without conventional training, which traditionally relies on explicit user-item interactions and training data \cite{he2017neural, kang2018self, he2020lightgcn}. 

%LLMs have recently gained attention in the field of recommender systems. %Initially, applying LLMs directly to recommendation tasks poses several challenges. To address this, 
% Several studies have explored LLM-based recommendation models, leveraging in-context learning \cite{brown2020language} and retrieval-augmented generation (RAG) \cite{lewis2020retrieval} techniques to enhance recommendation quality.


%However, most of these works rely solely on users' past purchase history or rating, leaving significant room for improvement by incorporating additional user-generated textual information, including user reviews and produce descriptions, which have yet to be fully leveraged.

\begin{figure*}[t]
\centering
\begin{minipage}{0.98\linewidth}
\centering
\includegraphics[width=\linewidth]{figures/final_figure.pdf}
\vspace*{-2em}
\caption{\textbf{Overall system of \myalg.} \textcolor{Blue}{\myalg{}} incorporates reviews, ratings, and item interactions, whereas \textcolor{Orange}{LLM Recommender} handles only item interactions. By using the "\textit{Review Extractor}" to identify key information and the "\textit{Profile Updater}" to refine the user profile, \myalg{} addresses scalability issue (\ie growth of input token size).}
\label{fig:intro}
\end{minipage}
\vspace*{-1em}
\end{figure*}

%Traditional recommender systems~\cite{he2017neural, kang2018self, he2020lightgcn} 
%focus on constructing collaborative knowledge from a limited number of user-item interactions. To improve performance, previous approaches have trained embedding models using various modalities, such as product names and ratings. Recently, pre-trained LLM-based recommender systems ~\cite{bao2023tallrec, kim2024large} suggested. However, the authors~\cite{hou2024large} proposed an LLM-based recommender system that utilizes users' purchase history without additional training. 
%

Despite the advanced capability of LLMs, most recent works \cite{hou2024large, wei2024llmrec, ren2024representation, he2023large, zhai2023knowledge} rely solely on users' past purchase history (\ie list of purchased items). This leaves significant room for further improvement by incorporating additional user-generated textual information, such as user reviews and product descriptions, which have yet to be fully leveraged.
%
In other words, they still fail to fully leverage various text data due to their inability to retain and process the increasing contextual information as users continue to make purchases, leading to longer recommendation sessions. This issue is primarily attributed to the \emph{omission} of the context, either due to the information loss within the LLM's memory \cite{liu2024lost} or the memory capacity by the token limit \cite{li2024survey, ding2024longrope}. 
%While this method introduces LLM-driven recommendation strategies, it does not leverage user reviews, which are a rich source of preference signals. The primary reason for this omission is the inherent token limitation of LLMs, making it infeasible to incorporate all reviews into a prompt.
Thus, extracting key features from a user's diverse textual sources is essential, as demonstrated in MemoryBank~\cite{zhong2024memorybank}, a framework that enhances LLMs with \emph{long-term} memory by summarizing key information from conversations and updating user profiles. 

Building on this foundation, we take the first step in extending LLMs' long-term memory beyond conversations in MemoryBank, adapting it to the evolving dynamics of recommendation systems.
%
We propose \myalg{}, a novel LLM-based \underline{\textbf{P}}rofile \underline{\textbf{U}}pdate for \underline{\textbf{RE}}commender that constructs user profile by integrating users' purchase history and reviews, which naturally expand as the recommendation sessions progress. Designed specifically for recommendation in~\autoref{fig:intro}, \myalg{} systematically extracts user preferences, dislikes, and key features from reviews and integrates them into structured user profiles.
%Unlike MemoryBank, which focuses on conversation-based memory, our method is tailored for the recommendation domain, extracting user preferences, dislikes, and key features from reviews and systematically integrating them into structured user profiles.
%
Specifically, \myalg{} consists of three main components: \underline{\emph{"Review Extractor"}}, which analyzes user reviews to identify and extract user preferences, dislikes, and preferred product features, referred to as "key features", offering a comprehensive view of user interests and purchase-driving attributes; \underline{\emph{"Profile Updater"}}, which refines newly extracted representations by eliminating redundancies and resolves conflicts with the existing user profile, ensuring a compact and coherent user profile; and \underline{\emph{"Recommender"}}, which utilizes the most up-to-date user profile for  recommendation task. %with high precision.

Our main contributions are as follows: 
(1) We propose \myalg{}, a novel framework that systematically extracts, summarizes, and stores key information from user reviews, optimizing LLM memory management for the recommendation. %As user-generated data continues to grow, our approach ensures that only the most relevant key features for recommendation are retained, enabling the system to scale effectively without exceeding token constraints, 
(2) We validate the effectiveness of \myalg{} by introducing a more realistic sequential recommendation setting, where reviews are incrementally added over time, allowing the model to update user profiles and predict the next purchase continuously. This setup more accurately reflects real-world recommendation scenarios compared to prior works, which assume all past purchases are provided at once, ignoring the evolving nature of user preferences. 
(3) We empirically show that \myalg{} surpasses existing LLM-based recommendation methods on Amazon data, demonstrating its effectiveness in leveraging lengthy purchase history and user reviews.


% To alleviate this limitation, inspired by MemoryBank~\cite{}, we introduce \myalg{} that designs the user profile memory based on the users' purchase history and reviews, and it retains the useful information to predict the next purchase.


% \begin{itemize} 
%     \item{We introduce a novel framework that systematically summarizes and stores key information from reviews, addressing LLMs' token limitations while preserving essential details. As user-generated data continues to grow, our approach ensures that only the most relevant key features for recommendation are retained, enabling the system to scale effectively without exceeding token constraints.}
%     \item{To validate the effectiveness of \myalg{}, we introduce a more realistic sequential recommendation setting, where reviews are incrementally added over time, and the model continuously updates user profiles to predict the next purchase. This setup better reflects real-world recommendation scenarios compared to prior works, which assume that all past purchases are given at once without considering the evolving nature of user preferences.}
%     \item{We empirically demonstrate that \myalg{} outperforms existing LLM-based recommendation methods on the Amazon dataset, showcasing its effectiveness in leveraging both purchase history and user reviews.}
% \end{itemize}
