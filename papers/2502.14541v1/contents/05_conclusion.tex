\vspace*{-0.1cm}
\section{Conclusion}
\vspace*{-0.1cm}
 We present \myalg{}, a novel framework for LLM-based recommendation that builds and maintains evolving user profiles by systematically extracting and summarizing user representations from reviews. By introducing a continuous sequential recommendation task, we demonstrated how updating user profiles improves recommendation quality while addressing token limitation challenges.
 
% We propose \myalg{}, a train-free LLM-based recommendation system that operates within a limited input token budget, offering flexibility without task-specific training. \myalg{} reduces computational costs compared to train-based systems and adapts to various domains. Additionally, we introduce a new sequential recommendation task to better model the evolving nature of user preferences over time, moving beyond conventional sequential setups. This work highlights the potential of train-free LLMs in real-world recommendation scenarios.
% We proposed \myalg{}, a highly efficient train-free LLM-based recommendation system designed to operate within a limited input token budget. \myalg{} significantly reduces computational costs for training compared to train-based recommendation systems. By eliminating the need for task-specific training, it offers greater flexibility and adaptability, without being constrained by domain-specific data. Furthermore, we introduced a more realistic sequential recommendation task, which goes beyond the conventional snapshot recommendation setup. This approach better reflects real-world scenarios by modeling the evolving nature of user preferences over time. Our work paves the way for future research on train-free LLM-based recommendation systems and highlights the potential of LLMs in complex, real-world recommendation settings.

\section{Limitations} 
A notable limitation of our approach is the tendency of the LLM to exhibit hallucination by occasionally recommending items beyond the predefined candidate set, even when explicitly instructed to select from it. This phenomenon underscores the inherent difficulty in imposing strict constraints within LLM-based recommendation models while maintaining flexibility and accuracy. Also, our study was constrained by the inability to utilize datasets containing a larger number of user reviews, which may have provided richer context.
% Our model is expected to perform more effectively in scenarios where more extensive review data is available.

\section{Potential Risks}
A potential risk associated with our approach is the possibility that user reviews may contain personal information, making data management and privacy protection critical concerns. Ensuring secure handling and anonymization of such data is essential to prevent breaches of user privacy.

\section{Ethical Statement}
This study used Amazon datasets which is publicly available. The dataset does not contain any personal identifiable information (PII), ensuring user privacy and ethical compliance. To ensure fair and accurate evaluation, we customized the baseline models by incorporating both item interactions and user reviews, enabling a more balanced comparison with our proposed approach. Lastly, our research aims to advance the development of recommendation systems while avoiding potential negative impacts such as bias or misuse.

\section*{Acknowledgments}
This work was mainly supported by Institute of Information \& communications Technology Planning \& Evaluation (IITP) grant funded by the Korea goverment (MSIT) (No. RS-2024-00445087, Enhancing AI Model Reliability Through Domain-Specific Automated Value Alignment Assessment) and by the National Research Foundation of Korea (NRF) grant funded by the Korea government (MSIT) (No. RS-2024-00334343). 

Additionally, this work utilized GPU infrastructure supported by Artificial Intelligence industrial convergence cluster development project funded by the Ministry of Science and ICT (MSIT, Korea) \& Gwangju Metropolitan City (No. BA00001698).